---
title: "ODDPub Validation for SocArXiv and arXiv"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
library(tidyverse)

arxiv_open_data_results <- 
  read_csv(here::here("outputs/data/arxiv_open_data_results.csv"))
# all_arxiv_results <- 
#   read_csv(here::here("outputs/data/arxiv_results.csv")) # All COVID arXiv papers (3,812)
arxiv_2019_open_data_results <- 
  read_csv(here::here("outputs/control-data/arxiv_2019_open_data_results.csv"))
# all_arxiv_2019_results <- 
#   read_csv(here::here("outputs/control-data/arxiv_data_2019.csv"))

# "attributes.has_data_links" gives indication of data availability
socarxiv_open_data_results <- 
  read_csv(here::here("outputs/data/socarxiv_open_data_results.csv"))
socarxiv_2019_open_data_results <- 
  read_csv(here::here("outputs/control-data/socarxiv_2019_open_data_results.csv"))
# socarxiv_metadata_2019 <- 
#   read_csv(here::here("outputs/control-data/socarxiv_metadata_2019.csv"))
```

# SocArXiv

## 2019

### Data

Under "attributes.has_data_links", "available" means data link exists, everything else means data link does not exist. NA appears to be the same as "not_applicable", meaning no data link and no justification (i.e. "attributes.why_no_data" is also NA). "no" means data was used but is not available. Justification should be provided in "attributes.why_no_data".

Since ODDPub does not check for areas where open data is not applicable, we should go by 0/1 according to attributes.data_links being populated (i.e. "data_link_available" as defined above).

We assume the attributes.data_links to be the "Gold Standard", i.e. indicating the true availability of data. It is possible, however, that some authors failed to indicate their data availability in the proper field upon posting to SocArXiv, and this some of the "false positive" may in fact be true positives.

```{r confusion-matrix-2019}
# SocArXiv 2019 Confusion Matrix
soc_2019_check <- socarxiv_2019_open_data_results %>%
  mutate(data_link_available = case_when(is.na(attributes.data_links) ~ "No data linked", TRUE ~ "Data linked")) %>%
  count(data_link_available, is_open_data) %>%
  pivot_wider(names_from = data_link_available, values_from = n) %>%
  mutate(is_open_data = case_when(is_open_data == 1 ~ "Open data detected", TRUE ~ "No open data detected")) %>%
  rename(Predicted = is_open_data) %>%
  arrange(desc(Predicted))
soc_2019_check
```

```{r accuracy-2019}
soc_2019_accuracy <- as.numeric(soc_2019_check[1,2] + soc_2019_check[2,3])/nrow(socarxiv_2019_open_data_results)
soc_2019_sensitivity <- as.numeric(soc_2019_check[1,2])/sum(soc_2019_check$`Data linked`) %>% as.numeric()
soc_2019_specificity <- as.numeric(soc_2019_check[2,3])/sum(soc_2019_check$`No data linked`)

tibble(Metric = c("Accuracy", "Sensitivity", "Specificity"),
      Value = c(soc_2019_accuracy, soc_2019_sensitivity, soc_2019_specificity))
```

```{r false-negatives-2019, eval = FALSE}
socarxiv_2019_open_data_results %>%
  filter(is_open_data == 0 & !is.na(attributes.data_links)) %>%
  select(title, links.preprint_doi, attributes.has_data_links, attributes.why_no_data, attributes.data_links, is_open_data, open_data_category, open_data_statements)
```


```{r false-positives-2019, eval = FALSE}
socarxiv_2019_open_data_results %>%
  filter(is_open_data == 1 & is.na(attributes.data_links)) %>%
  select(title, links.preprint_doi, attributes.has_data_links, attributes.why_no_data, attributes.data_links, is_open_data, open_data_category, open_data_statements)
```

### Code




## 2020/2021

Code was not manually verified for COVID-19 related papers.

```{r confusion-matrix-2020}
# SocArXiv 2019 Confusion Matrix
soc_2020_check <- socarxiv_open_data_results %>%
  mutate(data_link_available = case_when(is.na(attributes.data_links) ~ "No data linked", TRUE ~ "Data linked")) %>%
  count(data_link_available, is_open_data) %>%
  pivot_wider(names_from = data_link_available, values_from = n) %>%
  mutate(is_open_data = case_when(is_open_data == 1 ~ "Open data detected", TRUE ~ "No open data detected")) %>%
  rename(Predicted = is_open_data) %>%
  arrange(desc(Predicted))
soc_2020_check
```

```{r accuracy-2020}
soc_2020_accuracy <- as.numeric(soc_2020_check[1,2] + soc_2020_check[2,3])/nrow(socarxiv_open_data_results)
soc_2020_sensitivity <- as.numeric(soc_2020_check[1,2])/sum(soc_2020_check$`Data linked`) %>% as.numeric()
soc_2020_specificity <- as.numeric(soc_2020_check[2,3])/sum(soc_2020_check$`No data linked`)

tibble(Metric = c("Accuracy", "Sensitivity", "Specificity"),
      Value = c(soc_2020_accuracy, soc_2020_sensitivity, soc_2020_specificity))
```
```{r false-negatives-2020, eval = FALSE}
socarxiv_open_data_results %>%
  filter(is_open_data == 0 & !is.na(attributes.data_links)) %>%
  select(title, links.preprint_doi, attributes.has_data_links, attributes.why_no_data, attributes.data_links, is_open_data, open_data_category, open_data_statements)
```

```{r false-positives-2020, eval = FALSE}
socarxiv_open_data_results %>%
  filter(is_open_data == 1 & is.na(attributes.data_links)) %>%
  select(title, links.preprint_doi, attributes.has_data_links, attributes.why_no_data, attributes.data_links, is_open_data, open_data_category, open_data_statements)
```



# ArXiv

## 2019

We verified the accuracy of the ODDPub algorithm on a subset of our analyzed pre-prints from 2019 from arXiv. We took a simple random sample of 100 papers. In the original validation process, the annotators stratified by detection status prior to sampling to ensure relatively high representation of papers where open data/code was detected. Since the major concern for our manual verification is potential false negatives, this biased representation was unnecessary. Open data and code status were verified first via the "Code & Data" tab on each pre-print's page on the arXiv website, and then via checking for an explicit data availability section within the PDF and keyword search. Results were recorded manually in Excel (arxiv_2019_validation_sample.csv). This mimics the procedure outlined for the original validation of ODDPub.

Many of the pre-prints in arXiv did not use data or code, namely those from pure mathematics and physics. There were also several that reused other publicly or privately available data sets, and regardless of whether or not they were shared alongside the paper, these do not count as open data according to [ODDPub standards](https://www.biorxiv.org/content/10.1101/2020.05.11.088021v1.full.pdf).
```{r arxiv-2019-verification-sample, eval = FALSE}
set.seed(100)
arxiv_2019_sample <- arxiv_2019_open_data_results[sample.int(nrow(arxiv_2019_open_data_results), 100),] %>%
  select(id, title, link_pdf, link_abstract, is_open_data:open_data_statements) %>%
  mutate(file_path = paste0(id, ".pdf"), .before = id) %>%
  mutate(manual_open_data = NA, manual_data_statement = NA, manual_open_code = NA, manual_code_statement = NA, note = NA) # added for validation process
arxiv_2019_sample
# write_csv(arxiv_2019_sample, here::here("validation", "arxiv_2019_validation_sample.csv"))

open_pdf <- function(x){
  system2('open', args = here::here("outputs", "control-data", "pdf-arxiv", x))
}

open_link <- function(x){
  system2('open', args = x)
}

# Open pdfs in sets of 10 (run one at a time)
# lapply(arxiv_2019_sample$file_path[1:10], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[1:10], open_link)
# 
# lapply(arxiv_2019_sample$file_path[11:20], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[11:20], open_link)
# 
# lapply(arxiv_2019_sample$file_path[21:30], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[21:30], open_link)
# 
# lapply(arxiv_2019_sample$file_path[31:40], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[31:40], open_link)
# 
# lapply(arxiv_2019_sample$file_path[41:50], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[41:50], open_link)
# 
# lapply(arxiv_2019_sample$file_path[51:60], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[51:60], open_link)
# 
# lapply(arxiv_2019_sample$file_path[61:70], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[61:70], open_link)
# 
# lapply(arxiv_2019_sample$file_path[71:80], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[71:80], open_link)
# 
# lapply(arxiv_2019_sample$file_path[81:90], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[81:90], open_link)
# 
# lapply(arxiv_2019_sample$file_path[91:100], open_pdf)
# lapply(arxiv_2019_sample$link_abstract[91:100], open_link)

```

```{r arxiv-confusion-data-2019}
arxiv_2019_manual_results <- read.csv(here::here("validation", "arxiv_2019_validation_sample_COMPLETE.csv"))

arxiv_2019_data_check <- arxiv_2019_manual_results %>%
  count(is_open_data, manual_open_data) %>%
  pivot_wider(names_from = manual_open_data, values_from = n) %>%
  mutate(is_open_data = case_when(is_open_data == 1 ~ "Open data detected", TRUE ~ "No open data detected")) %>%
  select(is_open_data, `1`, `0`) %>%
  rename(Predicted = is_open_data, `Data available` = `1`, `No data available` = `0`) %>%
  arrange(desc(Predicted))

arxiv_2019_data_check

```

```{r arxiv-confusion-code-2019}

arxiv_2019_code_check <- arxiv_2019_manual_results %>%
  count(is_open_code, manual_open_code) %>%
  pivot_wider(names_from = manual_open_code, values_from = n) %>%
  mutate(is_open_code = case_when(is_open_code == 1 ~ "Open code detected", TRUE ~ "No open code detected")) %>%
  select(is_open_code, `1`, `0`) %>%
  rename(Predicted = is_open_code, `Code available` = `1`, `No code available` = `0`) %>%
  arrange(desc(Predicted))

arxiv_2019_code_check
```

```{r arxiv-accuracy-data-2019}
arc_2019_accuracy <- as.numeric(arxiv_2019_data_check[1,2] + arxiv_2019_data_check[2,3])/nrow(arxiv_2019_manual_results)
arc_2019_sensitivity <- as.numeric(arxiv_2019_data_check[1,2])/sum(arxiv_2019_data_check$`Data available`) %>% as.numeric()
arc_2019_specificity <- as.numeric(arxiv_2019_data_check[2,3])/sum(arxiv_2019_data_check$`No data available`)

tibble(Metric = c("Accuracy", "Sensitivity", "Specificity"),
      Value = c(arc_2019_accuracy, arc_2019_sensitivity, arc_2019_specificity))
```
```{r arxiv-accuracy-code-2019}
arc_2019_code_accuracy <- as.numeric(arxiv_2019_code_check[1,2] + arxiv_2019_code_check[2,3])/nrow(arxiv_2019_manual_results)
arc_2019_code_sensitivity <- as.numeric(arxiv_2019_code_check[1,2])/sum(arxiv_2019_code_check$`Code available`) %>% as.numeric()
arc_2019_code_specificity <- as.numeric(arxiv_2019_code_check[2,3])/sum(arxiv_2019_code_check$`No code available`)

tibble(Metric = c("Accuracy", "Sensitivity", "Specificity"),
      Value = c(arc_2019_code_accuracy, arc_2019_code_sensitivity, arc_2019_code_specificity))
```