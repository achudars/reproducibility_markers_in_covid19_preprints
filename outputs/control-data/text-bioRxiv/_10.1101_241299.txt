bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Myopic control of neural dynamics
David Hockera and Il Memming Parka,b,c
a

Department of Neurobiology and Behavior, Stony Brook University, Stony
Brook, NY 11794
b
Department of Applied Mathematics and Statistics, Stony Brook University,
Stony Brook, NY 11794
c
Institute for Advanced Computational Science, Stony Brook University, Stony
Brook, NY 11794
January 15, 2019
Abstract
Manipulating the dynamics of neural systems through targeted stimulation is a
frontier of research and clinical neuroscience; however, the control schemes considered for
neural systems are mismatched for the unique needs of manipulating neural dynamics. An
appropriate control method should respect the variability in neural systems, incorporating
moment to moment “input” to the neural dynamics and behaving based on the current
neural state, irrespective of the past trajectory. We propose such a controller under a
nonlinear state-space feedback framework that steers one dynamical system to function
as through it were another dynamical system entirely. This “myopic” controller is
formulated through a novel variant of a model reference control cost that manipulates
dynamics in a short-sighted manner that only sets a target trajectory of a single time
step into the future (hence its myopic nature), which omits the need to pre-calculate a
rigid and computationally costly neural feedback control solution. To demonstrate the
breadth of this control’s utility, two examples with distinctly different applications in
neuroscience are studied. First, we show the myopic control’s utility to probe the causal
link between dynamics and behavior for cognitive processes by transforming a winnertake-all decision-making system to operate as a robust neural integrator of evidence.
Second, an unhealthy motor-like system containing an unwanted beta-oscillation spiral
attractor is controlled to function as a healthy motor system, a relevant clinical example
for neurological disorders.

1

Introduction

Advances in recording technology are making it possible to gain real-time access to neural
dynamics at different length and time scales [BRAIN, 2014, Jun et al., 2017], allowing us
1

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

to consider the structure of the brain’s operation in ways that were previously inaccessible.
Central to that understanding of neural dynamics is the widely-held belief that dynamical
systems underlie all of the core operations of neural systems [Breakspear, 2017, Fairhall
and Machens, 2017, Sussillo, 2014, Izhikevich, 2006]. Dynamical systems are systems of
time-independent dynamics that drive the evolution of a set latent states that may or may not
be direclty observable, which in neural systems are proposed to account for motor function
[Churchland et al., 2012], cognitive processes [Park et al., 2014, Mante et al., 2013, Jazayeri
and Afraz, 2017], and sensory processing [Li et al., 2017]. The controlled stimulation of
neural systems offers not only a novel tool to perturbatively study the underlying dynamical
systems; but also shows tremendous potential to treat a host of brain disorders, ranging
from movement diseases such as Parkinson’s disease and essential tremor [Deuschl et al.,
2006, Lyons and Pahwa, 2004], epilepsy [Handforth et al., 1998, Morrell, 2011], and even
mood disorders such as severe depression [Ineichen et al., 2016]. In particular, there has been
recent success in combining real-time neural data acquisition with closed-loop stimulation for
treating Parkinson’s disease [Rosin et al., 2011, Malekmohammadi et al., 2016].
Unfortunately, the current framework for manipulating neural systems is not structured
to deal with the unique challenges posed by controlling complex neural dynamics. One of the
central goals of control theory is to manipulate a system to mimic some or all characteristics
of a target system of dynamics, and nearly all control systems accomplish this by controlling
the system state to either track a specified target trajectory or to regulate to a known set
point [Ioannou and Sun, 2012]. Closed-loop control systems specifically designed for neural
systems also operate under this paradigm [Schiff, 2011, Yang and Shanechi, 2016, Newman
et al., 2015], and clinical devices use even more simplistic open-loop or reactive protocols
[Little et al., 2013, Rosin et al., 2011, Morrell, 2011]. If neural systems function as a dynamical
system by nonlinearly filtering signals [Freeman, 1975, Haykin and Principe, 1998], then
significant portions of the observed neural fluctuation would correspond to relevant exogenous
input signals to the system such as volition, memory or sensory information. Such controls
designed to move to or maintain a target state counteract any natural fluctuation in neural
trajectories, and create a rigid system that is no longer dynamically computing. For example,
when building neural prosthetics for an abnormal motor-related brain area, it is crucial for
the controlled neural activity to be close to normal; however, simply controlling it to replay a
fixed motor command would not allow flexibly changing one’s mind mid action. Therefore,
any control objective that only considers externally set constraints through trajectory or
set-point control would be limited both in their application for treating neurodynamic diseases
as well as for studying neural computations in cases where preserving dynamic information
processing capability is important.
Given this perspective, we propose a new control objective called myopic control that
respects the unforeseeable variability in neural systems. The objective of myopic control is
for the controlled system to behave as a target neural dynamical system. This is reminiscent
of a well-developed field in control theory known as model reference control (MRC) [Ioannou
and Sun, 2012], though MRC has been widely used for trajectory-tracking problems. Unlike
MRC, myopic control is independent of the past trajectory and does not account for the

2

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

far future—given the current state of the system, it tries to behave as the target dynamical
system instantaneously.
The qualitative difference between our control scheme and trajectory-tracking methods is
depicted in Fig. 1. Given some target dynamical system, utilizing trajectory control would
force the neural system to follow a target trajectory, although not through the true target
dynamics. Scenarios may arise where trajectory control and myopic control may be very
similar (Fig. 1A), although there can be fundamental, qualitative differences in the presence
of noise or large disturbances due to exogenous inputs (Fig. 1B). In that case, the trajectory
resulting from trajectory control would not be generated from the target dynamics, and
forces the state to evolve toward the pre-computed target state. In this way, our controller
preserves the full neural variability of our target dynamics, ranging from potentially different
trajectories towards the same fixed point to even allowing for potentially different behavior
than expected.

A

G[x]

Target trajectory

←

F[x, u]

Trajectory control

→

G[x]]

B

Myopic control

Figure 1: Qualitative difference between our proposed myopic control of dynamics and
trajectory control. Here F is controlled to perform an example target dynamics G (e.g.,
perform a motor command) , where its gradient flow is given in gray and two attractors are
denoted as circles. A precomputed target trajectory xt through G is shown in black. A) In
the presence of small disturbances, the evolution of trajectory control forces the system back
to xt , whereas myopic control allows for natural deviations. B) A large disturbance away
from xt corresponding to an exogenous input that changes the target attractor mid-trajectory
could lead to entirely different behavior between the two control methods. Only myopic
control would capture the response of this disturbance through the true dynamics of G, while
trajectory control blindly follows xt .
The paper is organized as follows. First, we formulate the goals of our control objective for
manipulating neural systems, then define myopic control for linear and nonlinear dynamics.
3

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Next, we discuss some design features of how to construct the target dynamics of a desired
dynamical system, and what types of difficulties may arise when trying to define healthy
or desired neural dynamics. We then demonstrate this control’s ability to make dynamical
systems act as though they were another system entirely through two relevant examples.
First, a winner-take-all decision-making model is transformed to operate as a robust neural
integrator of information when shown a stimulus in a forced, two-choice decision-making task.
Second, a “diseased” motor system containing an unwanted beta-oscillation state is controlled
to function as a healthy motor system, which is a motivating example for the treatment of
movement disorders or other diseases with an underlying neurological state.

2
2.1

Materials and methods
Myopic dynamics control

Here we discuss the control problem of utilizing a dynamical system to behave as a separate
dynamical system. Using a Bayesian state-space modeling framework[Ogata, 2010], we are
interested in the time evolution of a posterior distribution of time-dependent, n-dimensional
(latent) brain state xt that are governed by (stochastic) dynamics F[xt , ut ] ≡ Ft with an
m−dimensional control signal ut ,
xt+1 = xt + Ft + wt ,

(1)

where wt ∼ N (0, Q) is the state noise upon the dynamics. A second set of target stochastic
dynamics G[xt ] ≡ Gt under which we would like our state to evolve, acts analogously on the
state as
xt+1 = xt + Gt + wt ,

(2)

The noise in both dynamics is the same, as we are considering transforming F into G in
the same physical neural system. In general, the control acts upon the dynamical system
latent states x that may not be directly observable, and would need to be inferred from a set
of observable variable to which the latent states are linked through an observation model.
The influence of the controls would also be manifested in the observed states, though without
loss of generality we have chosen to simplify our dynamics by omitting an observation model.
These dynamics are in general nonlinear, and we denote their Jacobians (linearization at the
current state and stimulus) as

At =

∂F[x, u]
∂x

Ãt =
xt ,ut

∂G[x]
∂x

Bt =
xt

∂F[x, u]
∂u

(3)
xt ,u0

Arguably the most developed form of model-based control occurs for linear systems with
quadratic costs on the state and control, known as linear quadratic gaussian (LQG) control
4

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

[Stengel, 1994]. Finite-time horizon LQG controllers are optimal for costs of the simplified
form

J=

T
X
t=0



2
T
E kxt − xt k + γut ut ,

(4)

x

with linear dynamics F t = Axt + But + wt , and a regularization penalty factor γ is added
onto the control power. The goal of minimizing (4) is to balance tracking along a target
trajectory xt with the cost of implementing a control. The optimal LQG controller form
u∗t = Kt (x − xt ) with gain Kt is found by solving the associated recursive Riccati equation
from an end-point condition, and is a time-dependent controller through the time-dependence
on Kt [Stengel, 1994].
Generating target dynamics is similar in spirit to LQG-type costs, although instead we are
interested in minimizing the difference between the effect of target dynamics and controlled
dynamics alongside control costs. Requesting that the controlled dynamics of Ft act as
through they are in fact Gt can be written in a regularized, stepwise quadratic form as


Jt = E (Ft − G t )T (Ft − G t ) + γuTt ut .

(5)

x

Note that this cost is defined at each time point t, and depends on the current state
(posterior) distribution over xt . Utilizing control to track a defined trajectory that is generated
from an uncontrolled set of target dynamics G is the essence of model reference control (MRC),
[Ioannou and Sun, 2012] although the costs associated with this control design are traditionally
limited to regulation of a controlled trajectory around a set point or tracking of a predefined
target trajectory evolving under G. Our cost in (5) instead seeks a control that effectively
recreates a single step of a target trajectory from G, which to our knowledge is a major
departure the typical use of model reference control. By weighting the difference between
dynamics over a single time step, this myopic (i.e., one-step) form negates the need to solve
the Riccati equations, and the derivative ∂J/∂ut can be straightforwardly calculated to
identify the optimal myopic control.
Our work in this paper focuses primarily on designing a controller that optimizes eq. (5),
which would be optimal for generating target dynamics over a single step. Since the controller
would no longer contain any time dependence (the dynamics Ft and G t are indexed by their
current time, but are dependent upon the state xt only), it would generate a dynamical
system with the same state space. Our controller does not assume the role of performing
the bulk action on the state, which is instead encompassed in the original dynamics F that
presumably perform some form of related dynamics well. This is especially important in the
context of neural dynamics performing a computation, where it would be undesirable for
our controller to first perform the computation itself by tracing out a predefined trajectory
xt . Instead, myopic control will assist that system’s natural ability to perform a neural
computation.
5

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

The qualitative advantages of myopic control are depicted in Figure 1, in which the
evolution of a trajectory-controlled system tracking a defined trajectory xt in a target
dynamical system G is compared to the evolution of a myopically controlled system designed
to perform the target dynamics. In a noiseless environment, both trajectories would be
identical; however, in the presence of small disturbances away from xt , tracking control would
correct the trajectory in a distinctly non-dynamical fashion, evolving not through G but
instead forcing the system back onto xt in an unnatural manner (Fig. 1A). Myopic control
would instead lead trajectory through the natural dynamics of G, which may lead to the
same stable point, but through a distinctly different trajectory. Some disturbances may
lead to different behavior between the two control methods, though. Figure 1B shows this
scenario, in which a disturbance is corrected by trajectory control back toward xt , while
myopic control followed the flow of G, which lead it to a different attractor point. If this target
dynamics were a decision-making computation, for example, myopic control may have lead
to a “wrong” decision; however, allowing a controlled neural system to operate imperfectly in
the perspective of modern control is precisely the type of flexibility that should be achieved
to maintain its natural operation.
In the following sections we derive the form of our myopic controller. Ideally, the controller
formulation will be distinct from the state estimator providing the feedback signal, and leads
us to consider variants of the controller that rely upon different moments of the underlying
state distribution. We first begin with the case of linear dynamics to demonstrate the
simplified form of myopic control and its properties, then move the more applicable nonlinear
case.
2.1.1

Linear dynamics

Here we demonstrate that the myopic controller for linear dynamics depends only upon
the mean of the state distribution, and thus the state estimator and controller design are
separable for myopic control.
Theorem 1. If target and controlled dynamics are linear in state x and control u, then
myopic control depends only upon state mean E[x].
Proof. Let the linear dynamics under control and the target dynamics be
F t = Axt + But + wt
G t = Ãxt + wt ,

(6)
(7)

where the state distribution over x has first and second central moments E[xt ] = µt ,
E[(xt − µt )2 ] = Σt , and the state noise is normal with wt ∼ N (0, Q). Expanding the dynamics
cost in (5) gives

6

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

i
h
J = E |(A − Ã)xt + But )|2 + γuTt ut
x
h
i
2
= Tr |(A − Ã)| Σt + µTt (A − Ã)T But +
uTt B T (A − Ã)µt + uTt (B T B + γIm )ut ,

(8)

where Im is the m × m identity matrix. By examining (8) it is clear that regardless of
the distribution over x, the cost depends only upon the first two moments of the distribution
of x. Maximizing (8) yields the optimal linear myopic controller form u∗tlin , which depends
only upon the state mean,
u∗tlin = −2(B T B + γIm )−1 B T (A − Ã)µt .

2.1.2

(9)

Nonlinear dynamics controller with a moment expansion approximation

For nonlinear dynamics, simply differentiating (5) leads to an ill-suited expression for a
controller, since there is an implicit dependence of the controller upon itself through F.
One approximation to alleviate this is to expand the nonlinear dynamics about null control
(u0 = 0) to first order, with the form
F[xt , ut ] ≈ F[xt , u0 ] + Bt (ut − u0 )
≡ft + Bt ut

(10)

where ft ≡ f [xt ] ≡ F[xt , u0 ] and for the remainder of the work Bt ≡ B[xt , x0 ] is the
Jacobian of F as in eq. (3). This leads to an expression for the derivative of J and myopic
controller as
∂J
≈ E[2(ftT + uTt BtT )Bt − 2G Tt Bt ] + 2γuTt
∂ut
x
∗
ut = −(E[BtT Bt ] + γIm )−1 E[BtT (ft − Gt )].
x

(11)
(12)

x

The expectations in (12) depend upon the state distribution of xt , although it would
be desirable if akin to LQG that the controller was separated from state estimation, and
only depended upon low-order moments of x. To construct such a controller we will expand
Ex [·] in terms of the mean and covariance of xt ; in general, the terms in this expansion will
contain Jacobian matrices, higher order derivatives, and state vectors that are all evaluated
at the distribution mean µt , multiplied by the covariance Σt in some form. For example, the
Jacobian Bt is expanded as
7

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

B[xt ] = B[µt + (xt − µt )]

1
≈ B[µt ] + B 0 [µt ](xt − µt ) + (xt − µt )T B 00 [µt ](xt − µt ),
2

(13)

and would follow similarly for the other terms in Ex [·]. Such an approximation is valid
when the deviations from our estimated state µt are small, and in this regime only low-order
moments are necessary. It is assumed that state estimation to obtain µt and Σt can be
performed regularly enough in practice to operate in the regime such that (13) is valid, and we
will consequently consider two forms of nonlinear myopic control. First-order myopic control
will include only terms dependent upon state mean, just as in the linear dynamics case of the
previous section. Second-order myopic control will analogously depend upon both µt and Σt .
In each controller the terms f, G, B and derivatives Bt0 = ∂Bt /∂xt , Bt00 = ∂ 2 Bt /∂x2t , will all
be evaluated at the distribution mean µt and null control u0 = 0, so we will temporarily drop
the functional dependence of these terms in the notation. The prime notation will indicate a
derivative with respect to state.
The first expectation in (12) includes only terms relating to B. Expanding and keeping
terms up to second order gives
E[B[x]T B[x]] = E[B[µ + (x − µ)]T B[µ + (x − µ)]]
x

x

1
≈B T B + B T Tr3,4 [B00 Σ]+
2
1
Tr3,4 [B00T Σ]B + Tr3,4 [B0T B0 Σ],
2

(14)

where Tr3,4 denotes the partial trace over dimensions 3 and 4. For an (n × m × n × n)
tensor T this operation maps to an (n × m) matrix M = Tr3,4 [T] as
Mj,k =

X

Tj,k,i,i .

(15)

i

Similarly, expanding Ex [BxT (f [x] − G[x])] up to second order yields
E[B T [µ + (x − µ)](f [µ + (x − µ)] − G[µ + (x − µ)])]
x

1
=B T (f − G) + B T Tr2,3 [(f 00 − G 00 )Σ]+
4
1
B T Tr2,3 [B0T (f 0 − G 0 )Σ] + Tr3,4 [B00T Σ](f − G).
2

(16)

(12), (14), and (16) define our second-order nonlinear myopic controller u2nd , and simply
omitting the covariance-dependent terms gives first order controller expansions,
8

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

E[B[x]T B[x]]1st order = B[µ]T B[µ]
x

E[BxT (f [x] − G[x])]1st order = B[µ]T (f [µ] − G[µ]).
x

(17)
(18)

First-order control u1st is attractive for its simplicity, and it is important to ask under
what circumstances would first-order control outperform second-order control? First, if
Tr(Σt ) is very small (i.e., small uncertainty about the state xt ), then second-order terms
are negligible. Second, by noting that nearly all second-order terms contain derivatives of
B, f and G, another regime in which first-order control may be superior is under “super
smooth” dynamics in which the magnitude of successive derivatives is smaller than the
previous one (e.g. kBk > kB 0 k > kB 00 k). Moreover, if the control portion of the Jacobian B
is state-independent, then second-order control only has one covariance-dependent term in
Ex [BxT (f [x] − G[x])],
1
B[µ]T (f [µ] − G[µ]) + B[µ]T Tr2,3 [(f 00 [µ] − G 00 [µ])Σ].
4

2.2

(19)

Evaluating controller performance

The performance of a myopic controller is formally benchmarked by the regularized cost in
(5), although it is important to isolate a cost describing the performance of only the dynamics.
The cost of expected mean performance is denoted by J˜µt , and is given by
J˜µ t = [(F[µ̂t , u∗t ] − G[µ̂t ])T (F[µ̂t , u∗t ] − G[µ̂t ])].

(20)

This cost is easy to compute and provides information about the mean behavior of the
control, although it ignores the variability of the state distribution Σt . A more informative
cost incorporates the impact of the entire distribution of x, denoted by J˜t as
J˜t = E[(F[xt , u∗t ] − G[xt ])T (F[xt , u∗t ] − G[xt ])].
x

(21)

We estimate (21) through Monte Carlo integration assuming the maximum entropy
distribution at each time point given the first two moments, i.e., a normal distribution
N (µ̂t , Σ̂t ).

2.3

Design principles for targeted dynamical systems

Myopic control omits the requirement of supplying a target neural trajectory or set point
in the neural state space, which resonates with our design requirement of a future-agnostic
controller that need not prescribe what the brain should be doing precisely.
9

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Balancing the simplicity and ease of myopic control, though, is the relative complexity
in designing a target dynamical system G t . At first glance, it may seem as though we have
merely shifted complications of controlling neural dynamics. However, this perspective more
clearly frames the goal of neural dynamics control, and we believe that it identifies a general
design question yet to be seriously considered by the neural processing community: Given a
rough sketch of neural dynamics and a desire to change them, what is an appropriate target
dynamical system?
The choice of G can roughly be broken down into three design problems for dynamical
systems: i) removal or avoidance of an unwanted feature, ii) addition of a desired feature, and
iii) modification of an existing feature. For example, there may be attractors (representing
macrostates) in F indicative of a dysfunctional behavior that should be avoided for healthy
brain function, such as limit cycle attractors. Or, one may wish to introduce additional
attractor macrostates in a decision-making system in order to support robust neural integration
of evidence [Koulakov et al., 2002]. We will consider both of these scenarios in the following
sections. Our ideal design approach used here is summarized in Figure 2, which is to use
multiplicative filters upon the controlled dynamics F to preserve desired features, with
the addition of either barrier functions to remove undesirable aspects of F or to prevent
access into that region of state space. Alternatively an additive function could be utilized to
introduce new features. Care must be taken with the shape and positioning of the additive
barrier or extra feature though, as any zero crossings of this additive term will introduce
fixed points into the dynamics. In the example case in Figure 2, a barrier function is used to
remove an undesirable feature of the dynamical system by producing a net rightward gradient
flow in the low x1 region of state space, where the zero crossing of the barrier function is
aligned with other fixed points of the system that are denoted in blue. Under this strategy,
we can also view modification of an existing feature as simply a removing it and replacing it
with the desired one.

2.4

Numerical methods

In the follow sections we detail the dynamics of each dynamical system in the examples.
Since the primary objective of this work is to understand the performance of the myopic
controller, in both examples we used a simple state estimator to calculate x̂t and Σ̂t , employing
extended Kalman filtering (EKF) within Tensorflow assuming a noisy observation of the
state as yt = xt + vt , where vt ∼ N (0, R) and R is a diagonal covariance matrix. For lags in
observations and control signal calculation, state prediction was performed by propagating x̂t
via,
x̂t+1 = x̂t + F[x̂t , ut ],

(22)
(i)

and covariance was estimated through sampling of time-evolved state predictions xt ∼
N (x̂t , Σ̂t ) that also evolve in time using (22),

10

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Original dynamics F
Undesired
feature

x2

Barrier or new feature

x1

×

Target dynamics G

+

Filter

=
x2

0

1

x2
x1

x1

x2

0
x1

Figure 2: Design strategy for creating target dynamics G. Green and blue regions represent
features of the original dynamics F that are to be maintained, while an undesirable feature is
denoted with orange. A multiplicative filter removes the unwanted feature, while an additive
barrier function prevents access to unwanted state space by enforcing a gradient flow toward
desirable regions with well-behaved dynamics.

2.4.1

Σ̂t+1

"M
#" M
#T
X (i)
X (j)
1
=
x − µt+1
xt+1 − µt+1
M − 1 i=1 t+1
j=1

(23)

µt+1

M
1 X (k)
=
x .
M k=1 t+1

(24)

Beta oscillation disease states

The diseased state dynamics are a modification of a dynamical system used to describe linear
integrate-and-fire neurons as a limit cycle attractor [Izhikevich, 2006]. The specific limit
cycle attractor is based upon the post-saddle-node bifurcation behavior at large current in
the INa,p + IK model from Ch. 4 of [Izhikevich, 2006] (eqs. 4.1-4.2). The high-threshold
parameters in [Izhikevich, 2006] were utilized to generate the attractor, and the external
current was tuned to generate a beta oscillation. The beta oscillation dynamics of state
X = [X1 , X2 ]T (omitting state and observation noise, for succinctness) are

11

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Flimit cycle

∂
=
∂t



X1
X2


(25)

∂ X̃1 C1
= (I − gl (X̃1 − El )−
∂t
C0
gN a m∞ (X̃1 − EN a) − gk X2 (X̃1 − Ek ))
∂X2
n∞ − X2
= C2
∂t
τ
1
, p ∈ [m, n]
p∞ =
−X̃1
)
1 + exp( Vp∞
kp∞

(26)
(27)
(28)

with parameters C0 = 1, I = 10, El = −80, EN a = 60, Ek = −90, gN a = 20, gk = 10,
gL = 8, τ = 1, Vm,∞ = −20, Vn,∞ = −25, km∞ = 15, kn∞ = 5. The original dynamics for
X2 corresponded to an activation variable in an integrate-and-fire model, and as such were
scaled to operate at the order of magnitude X2 ∈ [0, 1]; however, X1 was originally a voltage
variable, and we rescaled it such that X̃1 = 180X1 − 80. The magnitude of these dynamics
were also scaled with C1 = 0.88 and C2 = 160 to reflect this change in X1 .
The three stable points of the dynamics were added to the limit cycle attractor dynamics
as two sets of gaussian-weighted Gabor functions centered at the three stable points m1 =
[0.9, 0.25], m2 = [0.9, 0.50], m3 = [0.9, 0.75] with a width of the gaussian envelope L = 0.2.
This portion of the dynamics was structured and scaled as

Fa =

3
X
i=1


−



 

π(X1 −mi,1 )
200 sin
L


π(X2 −mi,2 )
100 sin
L

 e−

2(X−mi )T (X−mi )
L2

.

(29)

To combine the stable attractors and limit cycle attractors in a smooth fashion we
adopted our design strategy of filtering out regions of the limit cycle attractor in the stable
attractors regions around m1 , m2 , and m3 , and added in the stable attractors. Finally, the
state-independent control signal was added linearly to give the controlled dynamics with
∆t = 10−4 s as
Fdiseased [X, u] = ∆t(Flimit cycle Π3i=1 Bi (X) + Fa ) + u(t)


2(X − mi )T (X − mi )
Bi (X) = 1 − exp −
.
(1.5L)2

(30)
(31)

The healthy dynamics were designed by using the approach of Section 2.3 to encourage
the dynamics to stay near stable attractors, and avoid the limit-cycle attractor. We designed
a hyperbolic tangent filter function F F preserve the stable points, and a barrier function B
to encourage state movement away from the limit cycle
12

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.



1 tanh(a(x − mi,1 )) + 1
0
FF =
0
tanh(a(x − mi,1 )) + 1
2


1 tanh(−a(x − mi,1 )) + 1
B=
.
0
2

(32)
(33)

Both the filtering function and barrier function have their zeros at the intersection of
the stable points, to avoid introducing additional unwanted stable points. The scale factor
a = 20π creates a steep barrier. The healthy dynamics are then calculated by filtering on
null-controlled unhealthy dynamics as
Fhealthy = F F (Fdiseased [X, u = 0]) + B.

(34)

The state noise covariance Q = 10−5 I2 was chosen to allow for noise-assisted departure of
the uncontrolled dynamics from the stable points an into the limit cycle attractor. Observation
noise covariances R ∈ [10−6 I2 , 10−5 I2 , 10−4 I2 ] were used.
2.4.2

Winner-take-all and robust neural integrator dynamics

The Winner-take-all dynamics are based upon the state-space description in [Wong and
Wang, 2006], in which two sub-populations of excitatory neurons X1 and X2 have a reducedstate dynamical description for decision-making of the direction of a random moving dot
visual stimulus. The dynamics for the two-dimensional state driven by control signals
u(t) = [u1 (t), u2 (t)]T are given by
dXi
Xi
+ α(1 − Xi )Hi
=−
dt
τs
axi − b
Hi =
1 − exp[−d(axi − b)]
x1 = J11 X1 − J12 X2 + I0 + u1 (t) + I1
x1 = J22 X2 − J21 X1 + I0 + u2 (t) + I2 .

(35)
(36)
(37)
(38)

The visual stimulus is represented as input current I1 and I2 to each population with
stimulus strength µ0 = 30Hz and directional percent of coherence c0 ,


c0
Ii = JA µ0 1 ±
.
100

(39)

High activity of a state X1 corresponds to decision due to activity of that sub-population
of neurons with positive-signed coherence of the stimulus, and X2 alternative has high activity
for negative-sign coherence of the stimulus, indicating the direction of the stimulus. Parameter
13

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

values reported in [Wong and Wang, 2006] were used. The controls to the system u1 (t) and
u2 (t) were modeled as additional input currents to the sub-populations.
The target neural dynamics of a robust neural integrator are based conceptually upon
[Koulakov et al., 2002], and their state space description is modeled as a set of hyperbolic
tangents that generate interwoven nullclines. The two states X1 and X2 have gradients given
by
h
π

i
dXi
= τ tanh
[±u − 2(X̃2 − 0.5)] + BCi + Ii
dt
 a

(n − 1)π
u = a sin
X̃1 + π , i ∈ [1(+), 2(−)].
L

(40)

The nullcline shapes u are defined by n − 1 nodes over a length L, and have a hyperbolic
tangent on each side in state space. (40) use a rotated set of state-space coordinates X̃i given
by a rotation matrix [X̃1 , X̃2 ]T = M ([X1 , X2 ]T − R0 ), where M rotates by the angle π/4 and
R0 = [L/2, 1]T . The boundary conditions BC1 and BC2 enforce the final fixed points of the
neural integrator line to be global attractors, and are given by additional hyperbolic tangents
of the form

(n − 1)π
(X1 + c) −
BC1 =10 tanh −
b


(n − 1)π
10 tanh −
(X1 − [c + L + a/4])
(41)
b
 π

BC2 =10 tanh − (X2 + c) +
d

 π
(42)
10 tanh − (X2 − [L + c]) .
d
The parameters of the model were chosen to roughly match the magnitude and fixed-point
locations of the winner-take-all dynamics. τ = 1e−3 (i.e., 1ms timesteps), a = 0.2, n = 7,
L = 0.7, b = 4/3, c = 0.083, d = 1.2. The stimuli to the robust neural integrator I1 and I2
were given by


[I1 , I2 ] = sign(c0 )[δ(1 + |c0 |/100), −δ(1 + |c0 |/100)],

(43)

where δ = 7.5e − 4. The state noise covariance Q = 5 × 10−5 I2 was chosen to allow
the robust neural integrator to utilize the state noise to transition from one stable point to
another, and observation noise covariances R ∈ [10−6 I2 , 10−5 I2 , 10−4 I2 ] were used.

3

Results

In the following examples we demonstrate the ability of myopic control to match the dynamics
of several relevant dynamical systems for neural computations. Simulations to benchmark
14

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

the performance of myopic control were conducted using Tensorflow (Python API). System
details can be found in the methods section, and code for the myopic controller is available
at https://github.com/catniplab/myopiccontrol.

3.1

Robust neural integration from winner-take-all dynamics

We first deal with controlling neural computations for decision making, and demonstrate how
myopic control can be used to change a winner-take-all (WTA) decision-making dynamics and
convert it into a robust neural integrator (RNI). WTA dynamics for a simple, forced two-choice
decision-making process function through a dynamical system where stimulus modulates
the dynamics to flow toward one of two stable attractors. As time progresses, the neural
state is driven toward one of the two stable attractors, each comprising a separate decision.
In contrast, a robust neural integrator has multiple fixed points in between those two final
stable attractors that allow for a stable, intermediate representation of accumulated evidence—
creating robustness against uncertainty in stimulus and small internal perturbations.
We implemented a well-known approximation of a WTA dynamical system underlying
two populations of spiking, excitatory neurons connected through strong recurrent inhibitory
neurons, and our control for this system is an external injected current into each excitatory
population [Wong and Wang, 2006]. Our target dynamics embody a low-dimensional analogue
of the robust neural integration model suggested by Koulakov and coworkers [Koulakov et al.,
2002]. Our RNI dynamical system is conceptually quite simple: Two sinusoidal nullclines
that are interwoven can generate alternating stable and unstable fixed points, and with the
addition of boundary conditions on the final stable fixed points can generate a dynamical
system with a line of stable fixed points. The phase portraits for each system are shown in
Figure 3.
A comparison between first-order myopic control and a trajectory control approach (i.e.,
a control optimized for (4)) is presented in Figure 4. Specifically, we show that trajectory
control possess shortcomings when dealing with particular decision-making tasks. Trajectory
control approaches have an additional hurdle above myopic control in that there must be
some policy in place to decide to which target xt should evolve. The only way that trajectory
control can help the neural system make an informed decision is by integrating the stimulus,
itself, which assumes a role in the neural computation. Here, we allow the controller to observe
and integrate 20ms of coherence at the beginning of the trial, and then use that information
to prescribe a target point in state space (either the final + or − coherence decision points in
Fig. 3). In this simulation the time-varying stimulus c0 is initially uncertain, beginning with
a small positive coherence for 500 ms and then changing to negative coherence for 500 ms,
finally settling to a stronger negative coherence of c0 = −12% for the remainder of a 1s trial,
shown inset in Fig. 4. Both the target dynamics of robust neural integrator and myopic
control to mimic it can adequately handle this “change-of-mind" in stimulus and eventually
evolve its neural state to the negative coherence choice, but trajectory control system instead
incorporates only the initial stimulus to incorrectly choose the positive coherence choice.
Furthermore, it then holds it there with control, in spite of receiving new stimulus information
that in some cases could have even been caught in the WTA system (Fig. 4, green).
15

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Figure 3: Phase portraits for the A) winner-take-all dynamics and B) robust neural integrator.
The magnitude is plotted on a logarithmic scale for easier visualization, and arrows give
gradient direction. Streamlines are depicted in cyan. The nullclines of each dynamical system
are shown in black. The RNI system is formulated as an extension of the tangling of nullclines
in the WTA dynamics, where additional crossings of the nullclines result in stable points.
An intuitive way to compare the performance of trajectory control vs. myopic control for
decision making is to count the number of correct decisions made, which is summarized in
Table 1, alongside the total power of the controls, calculated as
X
P =
|um (ti )|2 .
(44)
i,m

Accuracy for each control type calculated as percentage of correct fixed points chosen
(noted in Fig. 3), and percentage decided as number of trials in which the state evolved to
within a close radius of a decision point (radius = 0.15). Examining the accuracy of each
method in the table, it is clear that this is an extreme case of how poorly trajectory control
can perform, where even uncontrolled dynamics sometimes was able to change its mind and
choose the correct stimulus. This is a specific example of our qualitative arguments against
trajectory control that were shown in Fig. 1, in which markedly different behavior can be
artificially enforced. Moreover, the total power required by the control signals is comparable,
indicating that myopic control did not require substantially more power to perform the target
dynamics
Quantitative performance of myopic control of a sample of 500 trials is summarized in
Figure 5. Sample trajectories for uncontrolled, first-order controlled, and healthy dynamics
are shown in Fig. 5A under the influence of an increasingly stronger time-dependent stimulus,
denoted by coherence c0 . Both the RNI and controlled system linger at an intermediate stable
nodes before coherence has increased enough to make a more informed decision, indicated by
the progression to the decision node. In contrast, the uncontrolled trajectory evolves straight
to the decision without any intermediate stability at low coherence.
16

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Table 1: Accuracy of decision making for an uncertain stimulus .
Dynamics
Accuracy % decisions made control power P (mean ± std)
1.
2.
3.
4.

RNI
Myopic control
Uncontrolled
Trajectory control

91 %
92 %
41 %
0%

91
92
89
99

%
%
%
%

2.05 ± 0.87
1.65 ± 0.42

Importantly, the controlled dynamics demonstrate the intermediate stability behavior
found in robust neural integrators. Figure 5B summarizes the log-cost of 500 trials of firstorder control with a fixed stimulus coherence of c0 = −6%, where prototypical trials are shown
in gray alongside the trial average in black. The control signals for the increasing coherence
demonstration (Fig. 5A) and for the benchmark trajectories (Fig. 5B) are plotted in 5C and
5D, respectively. Again, promising and modest control amplitudes are observed in both cases.
Finally, figures 5E and 5F show the time-averaged, log-performance for varying observation
lag and noise strengths. Comparable to the previous section we see that second order control
performs equivalently to first order across increasing observation lag and noise. However,
the time-averaged distributions at low observation lag have quite long-tailed, unimodal
distributions, and have negligible performance at a lag of 50 steps (note that ∆t is an order
of magnitude higher for this system, which corresponds to a 50ms-ahead prediction). There
is some change to a bimodal distribution for increasing observation noise in this system, but
the notable feature is the increasingly long distribution tail for second-order control, which
gives the opportunity for inferior performance as compared to first-order control.

3.2

Avoiding beta-oscillation disease states

Here, we aim to preserve an original set of dynamical features in F while avoiding an
unwanted regime of state space containing undesirable dynamics. This paradigm can act
as the basis of state-space control for neurological disorders, where regions of state space
may be associated with disease symptoms [Watter et al., 2015, Little and Brown, 2012].
Utilizing myopic control as a therapy for neurological disorders lends itself to considering
which features of neural dynamics are undesirable, rather than discerning which features of
the dynamical system are lacking. For example, tremors in Parkinson’s disease (PD) are
associated with a characteristic beta oscillation (i.e., 13-30 Hz) of the local field potential in
the subthalamic nucleus, and state-of-the art feedback control strategies use this signal to
trigger deep brain stimulation (DBS) until the beta oscillation subsides [Malekmohammadi
et al., 2016]. Similar neural signatures are also present for epilepsy [Handforth et al., 1998,
Morrell, 2011]. A model “diseased” system with three stable fixed points representing three
possible voluntary movement command was constructed with an additional, unwanted spiral
attractor representing the beta oscillation macrostate. Difficulty in initiating voluntary
motion (bradykinesia) in PD patients could be due to strong attractive macrostate [Nini
et al., 1995, Little and Brown, 2014]. Using myopic control, we manipulated the dynamics to
17

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Evidence accumulation, change of mind stimulus

1

Target dynamics, RNI
Myopic control, first order
Uncontrolled dynamics, WTA
Trajectory control

0.8

change of mind stimulus signal

10

0.6
X2

5

c’

0

-5

0.4
-10

-15

0

1000

1500

2000

time (ms)

0.2

0

500

0

0.2

0.4

0.6

0.8

1

X1
Figure 4: Example trajectories of controlled dynamics for an initially uncertain stimulus
(inset). Trajectory controls with a policy to decide which decision to make by integrating
the initial few ms of coherence signal not only steal the role of computational integration
from the dynamical system, but in the presence of an initially uncertain stimulus perform
poorly by making the wrong decision (red) where even a WTA system (green) can somewhat
cope with a changing stimulus. Myopic control (blue) can integrate the incoming information
just as the target RNI dynamics (black). inset: coherence for the change of mind stimulus. a
final decision would be made by integrating the signal, signified by the gray region. Vertical
line at 20ms indicates the portion of the signal integrated to decide on a target point for
trajectory control.
match the target dynamics of a healthy system structured using the design principles from
section 2.3 to avoid the avoid beta oscillation state while preserving the fixed points of the
system. The phase portrait of the target dynamics are shown in Figure 6.
The overall performance of myopic control is summarized in Fig. 7. A sample of 500 trials
points was initialized in the asymptotic distribution of the PD limit-cycle attractor, and state
estimation was performed for 100ms in the absence of control before the control was switched

18

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

on. Monitoring log[J˜t ] in Figure 7A, individual trials reflect the initial oscillatory behavior
of being in the disease state before sharply declining, whereas the trial-averaged behavior
shows the overall improvement due to control. This remarkable removal of disease-state
behavior is further demonstrated in state-space trajectory of a typical trial (Fig. 7B). Once
control is switched on the target dynamics successfully lead it out of the limit cycle and into
a stable attractor point. A spectrogram of the state X1 for an analogous, longer simulation
is shown in Fig. 7 D. There, a beta oscillation endured for 1s, and then myopic control was
switched on to evolve to a stable point. The spectrogram reflects the oscillations during
the uncontrolled period, and once the control is switched on it subsides and leaves only
low-frequency components as it moves toward the stable point. The optimal control signal
for the colored trajectory in Fig7A in shown in Fig. 7C. it is modest in amplitude relative to
the magnitude of the dynamics, and has a straightforward waveform, demonstrating that
given only minimal additional consideration to constraints on the control signal that myopic
control could feasibly, efficiently, and safely be implemented in living subjects.
Finally, we benchmarked the performance of first- and second-order control as compared
to
PT
˜
uncontrolled dynamics by calculating distributions of the time-averaged log-cost i=1 log(Jt )
for varying lags between state observation and control signal calculation (Fig. 7E), and
for different observation noise strength (Fig. 7F). While there is a interesting trend in the
stretching of bimodal distribution into a near unimodal one at high observation lag, we
observed no impactful difference between first- and second-order control with an increasing
delay of observations. Similarly, there is a transition to a distinct bimodal distribution at
large signal to noise, though both controllers perform similarly.

4

Discussion

Here we developed a perspective on what features are necessary for a flexible control of any
dynamical system underlying neural computation. The controller should function to assist
the dynamical system performing the computation, not taking on the role of a dynamical
system, itself. In order for the controlled dynamics to function as a separate dynamical
system on its own, we proposed a myopic control scheme that alternatively manipulates
the dynamics to function as a set of target dynamics over a single time step, as opposed to
trajectory-tracking controllers that function over a finite time horizon and must first perform
the neural computation on their own. We developed an approximation of this control for
nonlinear dynamics that is separable from state estimation, provided direction about design
principles for how to construct a targeted dynamical system, and demonstrated its application
in two varied scenarios. In both examples, first order control performed comparably to
second-order control, showing the potential to generate feasible control signals that function
under practical conditions.
The base of our controller formulation is reminiscent of the model-based control and model
reference (adaptive) control (MRAC). Utilizing model-based control alongside quality state
estimation [Watter et al., 2015] to manipulate neural dynamics is an attractive strategy that
can harness machine learning methods to build effective, patient-specific statistical models
19

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

of the brain by using real-time patient data, which could then be used as precision medical
treatment [Collins and Varmus, 2015, Ozomaro et al., 2013]. The initial efforts of MRAC
focused heavily on adaptive update rules for estimating the parameters of different forms
of target plants (dynamics, in our work), and predominantly one adaptive controller form
was utilized: strictly positive real (SPR) Lyapunov design. This form of controller depended
on a SPR transfer function formulation of its plant dynamics, as was designed to guarantee
bounded control signals that can track target trajectories or regulate to a fixed point from a
target plant. Our controller structure is similar in form to SPR control and could benefit from
the similar extensions that took place in MRAC, such as analysis of the Lyapunov stability
to rigorously establish safe bounds on the control [Ioannou and Sun, 2012] and the use of
neural networks capable of handling nonlinear plant dynamics [Narendra and Parthasarathy,
1990, Hagan et al., 2002].
This is not the first neural controller to consider neural variability as an important
component to preserve in neural systems. Todorov and Jordan suggested a “minimal intervention principle” for neural systems that allows for deviations from a target trajectory,
provided that they do not interfere with the target task [Todorov and Jordan, 2013]. The
target was considered as a single point in state space, and their formulation allowed for
high redundancy in the number of optimal trajectories that reached the target with the
same cost. Their controller only corrects the trajectory when failing to act would result in a
worse-than-optimal cost. While this is the only instance of control that acknowledges and
respects neural variability during control, even prescribing a single point in state space as a
target falls short of the general goals accomplished by myopic control to generate an entire
target dynamics. For example, returning to the qualitative operation of myopic control in Fig.
1B, minimal intervention control would perform comparably to trajectory control by forcing
state evolution in a non-dynamical fashion, while also restricting the neural variability that
lead to an alternative fixed point.
An important feature of myopic control was its modular design. We studied a form in
which only low-order moments of the state distribution were used in the controller, which
decoupled the controller form from state estimation and allowed for any state estimator to be
implemented. First-order control is considerably more straightforward to use because of its
lack of higher-order derivatives on the dynamics, which may also come with a benefit being a
more robust controller during practical instances in which the dynamics must be inferred
from data. Operating in the perturbative regime x − x̂t through regular state estimation
small would ensure that first-order methods are successful.
A key issue that dictates myopic control’s qualitative success is the choice or design of
target dynamics. Target dynamics could be designed by modifying the current dynamics
through either addition, removal, or modification of specific features in the state space. There
is an appeal to omitting features, as this approach resembles lesioning studies that aim to
infer causal importance to behavior.
In our beta oscillation example, omitting the limit cycle appeared to be the safest and
most practical approach. However, if more experimentally accurate understanding of the
Parkinsonian dynamics suggests that omitting a limit cycle could introduce unwanted behavior,

20

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

it may be more prudent to modify the limit cycle with an exit pathway. Still, one may wish
to study the extent of a neural system’s computational flexibility by adding features as we
did with our decision-making example.
It should be noted the adding in new features can be a tedious process in practice, as it took
considerable parameter tuning to create our robust neural integrator system. Additionally,
we considered only two-dimensional systems, but interesting dynamical systems may in fact
lie in higher dimensions [Park et al., 2014]. Our design approach of filtering functions is
general enough to extend to high dimensions, though implementing them in practice may
take additional care. Removing features with smoothed versions of step functions would still
work, as would adding stable points with gabor functions, though they would need to be
high-dimensional analogues. Visualization and analysis tools for high-dimensional spaces
could help determine the hypervolumes to omit, and how (an)isotropic the features must be.
Myopic control is certainly not the only form of controlled stimulation of neural systems,
and it is important to note how these methods differ from our perspective. One of most
successful applications of neural stimulation is in the field of neuroprosthetics, where implants
mimic afferent sensory inputs such as cochlear or retinal implants, or translate efferent outputs
into motor actions for artificial limbs [Sanchez, 2015]. The control strategies behind these
technologies are complex and varied compared to myopic control [Schiff, 2011], though this is
required in part because the goal of neuroprosthetics is distinctly different: the controlled
(de)coding of these neural signals do not constitute a dynamical system, but rather interacts
with the pre-existing normal neural dynamics of the area as inputs. Neural prosthetics for
cognitive function, for example, memory processing in hippocampus [Berger et al., 2011],
are much more amenable to myopic control scheme, since the normal function of the neural
system constitutes a dynamical system.
Deep brain stimulation (DBS) for neurological disorders (e.g., Parkinson’s disease) is a
control application within the scope of myopic control, as we demonstrated with our first
example study. A recent approach to DBS that harnesses neural recordings uses a model-free
method to simply reduce beta-band oscillations seen in local field potential recordings in
the basal ganglia [Malekmohammadi et al., 2016], a potential neural signal related to PD
symptoms [Quinn et al., 2015, Trager et al., 2016]. The disadvantage to such a heuristic
approach is that the link between beta oscillations in basal ganglia and cortex, let alone its
relationship to actual PD symptoms, is still not fully understood. Moreover, other feedback
targets are being actively considered as well [Rosin et al., 2011, Little and Brown, 2012].
Myopic control allows us to causally investigate the role of neural signatures correlated with
the disease—we can specifically target fixes to the abnormal dynamics for beta oscillations,
for example, and improve our understanding of the disease and also improve treatments.
Our first example was motivated from a position of understanding neural dynamical
systems for evidence accumulation and decision making, and more generally to demonstrate
its application as a tool to causally investigate cognitive processes. Several models of evidence
accumulation have been considered in the context of using variability in spiking dynamics of
lateral intraparietal cortex (LIP) in monkeys [Churchland et al., 2011, Huk and Shadlen, 2005,
Resulaj et al., 2009], and one future experiment could attempt myopic control using different

21

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

models for the control systems to produces a given target system, say RNI. Performing
myopic control in that context would be a more powerful approach than perturbative, random
stimulation of the system to simply infer parameters of an underlying dynamical model
represented in LIP. Additionally, a more sophisticated experiment could attempt to utilize
controlled stimulation to force the opposite decision of a target dynamics; the success of
which would not only provide evidence that the controller is operating based upon the correct
dynamical systems model, but would also constitute a substantial advance in the control of
cognitive dynamics.
The history of advances in model reference adaptive control (MRAC) provides a strong
template for how myopic controllers for neural dynamics control could be developed. Our
work here assumed a known model for the controlled dynamics, and future work should
integrate adaptive estimation of the controlled dynamics, themselves, into the controller. In
particular, as an extension of the initial neural network structures used to perform MRAC
[Narendra and Parthasarathy, 1990, Hagan et al., 2002], there is opportunity to utilize deep
networks that accomplish adaptive estimation these dynamics and their states within a
neural-network myopic controller architecture [Zhao and Park, 2018, 2017, Sussillo et al.,
2017].
A larger and more immediate question is what steps must be taken to implement myopic
control experimentally? The most important underlying component is access to quality neural
measurements. That is why recent work combining neural stimulation and observation as in
[Tan et al., 2018] is so vital. In our work we assumed that the ground-truth neural dynamics
for both the controlled dynamics F and the target dynamics G were known, but in practice
they must estimated from neural measurements. We demonstrated that first-order myopic
control can function well, which necessitates estimation of only the state mean over higher
order moments, but first order control also requires estimating the full dynamics in (18).
The timescale of the underlying neural computation also suggests practical consideration.
Since myopic control is designed as an online control, the state estimations and estimation
of the dynamics must be fast in order to implement in real time. Longer time constants
for processes that are characterized by a smaller total dynamics Ft lead to slower changes
in neural state, which allow for more accurate online state estimation, and thus a more
accurate control signal. Akin to a slower moving target in state space, the less the dynamics
have progressed, the more up-to-date that state information will be, and the better the
control performance for slower dynamical processes. This motivated our demonstration that
myopic control can still function well with a lag between neural observations and control
implementation.
Moreover, estimating latent state dynamics is a difficult task altogether [Breakspear,
2017], and would likely need to be performed prior to control use, with adaptive updates to
the dynamics estimation occurring online. Taking into consideration a generic framework
i) signal processing (e.g., spike sorting), ii) control signal calculation, and iii) delivery of
stimulation; it seems reasonable to assume ∼5 ms of time required for myopic control, which
is comparable to other closed-loop control estimates [Ciliberti et al., 2018]. In this regime
of time lags of less than 5 ms, myopic control was demonstrated to perform well, which is

22

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

promising for its implementation.

23

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

A Evidence accumulation for increasing coherence

B

1

Time-dependent loss, WTA to RNI
-12

0.9
-14

0.8

-16

~
log(Jt )

0.7

X2

0.6
0.5

-20

0.4
WTA
RNI
Controlled

0.3
0.2

-22
-24

0.1
0

0

0.2

0.4

X1

0.6

0.8

-26

1

D
c(t) (nA)

0.02
0
-0.02
-0.04

c1
c2

-0.06
0

2

6

4

-10

800

1000

c1
c2

0

200

400

600

800

1000

time (ms)

Average performance, observation delay

F

Average performance, noise strength
-11

mean
median

-12

**

*

*

*

*
*

*

-13

-13

~
log(Jt )

~
log(Jt )

600

-0.05

-12

-14
-15

-14
-15
-16

-16
-17

-17

-18

-18

-19

400

0

10

8

mean
median

-11

200

Representative control, performance evaluation

0.05

time (s)

E

0

time (ms)

Control, evidence accumulation

C
c(t) (nA)

-18

1st 2nd 1st 2nd 1st 2nd 1st 2nd 1st 2nd

0

1
5
10
lag in observations,ms

20

-19

1st 2nd

50

null

1st

17

2nd

null

1st

2nd

null

7
Signal to noise ratio (dB)

1st

2nd

-3

Figure 5: A) Example trajectory of controlled dynamics for evidence accumulation. Nullclines
and stable points (dots) of the neural integrator shown in black, with unstable nodes shown
as diamonds. B) Average time dependence of log-performance of expected cost in eq. (20)
for winner-take-all to robust neural integrator dynamics with first-order control, SNR of 7dB,
and fixed coherence c0 = −6%. Example trials are shown in gray, and trial-averaged mean
plotted in black. C) Control signals during the evidence accumulation with first-order control.
D) Similar control signals for fixed-coherence trial. E) Violin plots showing distribution of
time-averaged, log-performance for a lag in observations. F) Similar violin plots as in E), but
for for varying observation noise strength, shown by signal-to-noise ratios (SNR) of system
noise to observation noise, and including null control (ct = 0). In both E) and F) * indicates
p < 0.001 for a two-sample t-test. Unless otherwise noted, samples are not significantly
different. ** : p = 0.009.
24

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Figure 6: Phase portraits for diseased and healthy dynamical systems. Color denotes the
magnitude of the dynamics F and G, and the direction is shown by the arrows. Streamlines
are shown in cyan. The diseased system contains three stable points, but also a spiral
attractor at small values of X1 and X2 . The target healthy dynamics has been designed to
contain slightly repulsive dynamics in the original spiral attractor region, but still maintains
its stable points.

25

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

A

B

Time-dependent loss
diseased to healthy dynamics

0.6

-6
Control
switched on

-8

Uncontrolled
Controlled

0.5

-10

~
log(Jt )

Representative trajectory
uncontrolled & controlled dynamics

0.4
Control switched on

-12

x

2

0.3

-14

Initial point

0.2
-16
0.1

-18

C

50

-0.1
100

time (ms)

150

D

Representative first-order control signal

c(t)

0.1
c 1 (t)
c 2 (t)

0.05
0
-0.05

0

50

100

0

200

150

200

time, (ms)

-6

0.8

1

Spectrogram of X1 , uncontrolled 1s, controlled 1s
-20
-40
-60
-80
-100
-120
-140

30
20
10

mean
median

-2

0.5

1

1.5

Time (s)
Average performance, noise strength
mean
median

-4

-8

*

*

*

*

*

*

-6

-10

~

log(Jt )

~
log(Jt )

0.6

x1

40

F

Average performance, observation delay

0.4

50

0

E

0.2

Power/frequency (dB/Hz)

0

Frequency (Hz)

-22

0

Trial averaged
Representative
sample

-20

-12

*

-14

-8
-10
-12

-16

-14

-18

-16

1st 2nd 1st 2nd 1st 2nd 1st 2nd 1st 2nd 1st 2nd

0

0.1

0.5

1

2

null

5

1st

10

lag in observations, ms

2nd

null

1st

2nd

null

1st

0

2nd

-10

Signal to noise ratio (dB)

Figure 7: A) Time-dependent performance of first-order control for small observation noise
(SNR 10dB). Instances of simulations are shown in gray, while the mean behavior is given
in black. A representative trial has been singled out in blue and red for additional analysis.
Initial trajectories are uncontrolled (blue), and allowed to fall into the asymptotic distribution
of the limit cycle before control is switched on (red). Costs are plotted as time-locked 100ms
before the control is switched on. B) Trajectory of typical trial through state space shown
before and after the control is implemented, demonstrating a move back towards healthy state
space. C) Control signal of a representative trial. D) Spectrogram of X1 for an analogous,
longer simulation of uncontrolled evolution for 1s (noted by vertical line), and myopic control
for final 1s . E) Violin plots showing distribution of time-averaged log-performance for a
lag in observations, requiring state prediction. Horizontal line corresponds to the average
log-loss of null control. F) Similar violin plots as in E), but for for varying observation noise
strength, and including null control (ut = [0, 0]). In both E) and F) * indicates p < 0.001 for
a two-sample t-test. Unless otherwise noted, samples are not significantly different.
26

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Acknowledgments
This work was supported by the Thomas Hartman Center for Parkinson’s Research (64249).

References
Theodore W. Berger, Robert E. Hampson, Dong Song, et al. A cortical neural prosthesis for
restoring and enhancing memory. Journal of Neural Engineering, 8(4):046017+, August
2011. ISSN 1741-2560.
BRAIN. Brain research through advancing innovative neurotechnologies (BRAIN) working
group report to the advisory committee to the director, NIH. Technical report, National
Institute of Health, 2014.
Michael Breakspear. Dynamic models of large-scale brain activity. Nat Neurosci, 20(3):
340–352, 03 2017.
Anne. K. Churchland, R. Kiani, R. Chaudhuri, et al. Variance as a signature of neural
computations during decision making. Neuron, 69(4):818 – 831, 2011. ISSN 0896-6273.
Mark M. Churchland, John P. Cunningham, Matthew T. Kaufman, et al. Neural population
dynamics during reaching. Nature, 487(7405):51–56, 07 2012.
Davide Ciliberti, Frédéric Michon, and Fabian Kloosterman. Real-time classification of
experience-related ensemble spiking patterns for closed-loop applications. eLife, 7:e36275,
oct 2018. ISSN 2050-084X.
Francis S. Collins and Harold Varmus. A new initiative on precision medicine. New England
Journal of Medicine, 372(9):793–795, 2015. PMID: 25635347.
Günther Deuschl, Carmen Schade-Brittinger, Paul Krack, et al. A randomized trial of
deep-brain stimulation for parkinson’s disease. New England Journal of Medicine, 355(9):
896–908, 2006. PMID: 16943402.
Adrienne Fairhall and Christian Machens. Editorial overview: Computational neuroscience.
Current Opinion in Neurobiology, 2017. ISSN 0959-4388.
Walter J. Freeman. Mass Action in the Nervous System. Academic Press, October 1975.
ISBN 0124120474.
Martin T. Hagan, Howard B. Demuth, and Orlando De Jesús. An introduction to the use of
neural networks in control systems. International Journal of Robust and Nonlinear Control,
12(11):959–985, 2002. ISSN 1099-1239.
A. Handforth, C. M. DeGiorgio, S. C. Schachter, et al. Vagus nerve stimulation therapy for
partial-onset seizures: A randomized active-control trial. Neurology, 51(1):48–55, 1998.
27

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

S. Haykin and J. Principe. Making sense of a complex world [chaotic events modeling]. IEEE
Signal Processing Magazine, 15(3):66–81, May 1998. ISSN 10535888.
Alexander C. Huk and Michael N. Shadlen. Neural activity in macaque parietal cortex reflects
temporal integration of visual motion signals during perceptual decision making. Journal
of Neuroscience, 25(45):10420–10436, 2005. ISSN 0270-6474.
Christian Ineichen, Heide Baumann-Vogel, and Markus Christen. Deep brain stimulation:
In search of reliable instruments for assessing complex personality-related changes. Brain
Sciences, 6(3):40, 09 2016.
Petros Ioannou and Jing Sun. Robust Adaptive Control. Dover, 2012.
Eugene M Izhikevich. Dynamical Systems in Neuroscience: The Geometry of Excitability
and Bursting. MIT Press, 2006.
Mehrdad Jazayeri and Arash Afraz. Navigating the neural space in search of the neural code.
Neuron, 93(5):1003–1014, March 2017. ISSN 08966273.
James J. Jun, Nicholas A. Steinmetz, Joshua H. Siegle, et al. Fully integrated silicon probes
for high-density recording of neural activity. Nature, 551(7679):232–236, November 2017.
ISSN 0028-0836.
Alexei A. Koulakov, Sridhar Raghavachari, Adam Kepecs, and John E. Lisman. Model
for a robust neural integrator. Nature Neuroscience, 5(8):775–782, August 2002. ISSN
1097-6256.
Hsin-Hung Li, James Rankin, John Rinzel, Marisa Carrasco, and David J. Heeger. Attention
model of binocular rivalry. Proceedings of the National Academy of Sciences, 114(30):
E6192–E6201, 2017.
S. Little and P. Brown. Focusing brain therapeutic interventions in space and time for
parkinson’s disease. Current Biology, 24(18):R898–R909, September 2014. ISSN 09609822.
Simon Little and Peter Brown. What brain signals are suitable for feedback control of deep
brain stimulation in parkinson’s disease? Annals of the New York Academy of Sciences,
1265(1):9–24, 2012. ISSN 1749-6632.
Simon Little, Alex Pogosyan, Spencer Neal, et al. Adaptive deep brain stimulation in advanced
parkinson disease. Ann Neurol., 74(3):449–457, September 2013.
K.E. Lyons and R. Pahwa. Deep brain stimulation and essential tremor. J Clin. Neurophysiol.,
2004.
Mahsa Malekmohammadi, Jeffrey Herron, Anca Velisar, et al. Kinematic adaptive deep brain
stimulation for resting tremor in parkinson’s disease. Movement Disorders, 31(3):426–428,
2016. ISSN 1531-8257.
28

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

Valerio Mante, David Sussillo, Krishna V. Shenoy, and William T. Newsome. Contextdependent computation by recurrent dynamics in prefrontal cortex. Nature, 503(7474):
78–84, 11 2013.
Martha J. Morrell. Responsive cortical stimulation for the treatment of medically intractable
partial epilepsy. Neurology, 77(13):1295–1304, 2011.
K. S. Narendra and K. Parthasarathy. Identification and control of dynamical systems using
neural networks. IEEE Transactions on Neural Networks, 1(1):4–27, Mar 1990. ISSN
1045-9227.
Jonathan P Newman, Ming-fai Fong, Daniel C Millard, et al. Optogenetic feedback control
of neural activity. eLife, 4:e07192, jul 2015. ISSN 2050-084X.
A. Nini, A. Feingold, H. Slovin, and H. Bergman. Neurons in the globus pallidus do not
show correlated activity in the normal monkey, but phase-locked oscillations appear in
the MPTP model of parkinsonism. Journal of Neurophysiology, 74(4):1800–1805, October
1995. ISSN 1522-1598.
Katsuhiko Ogata. Modern control engineering. Prentice Hall, 2010. ISBN 9780136156734.
Uzoezi Ozomaro, Claes Wahlestedt, and Charles B. Nemeroff. Personalized medicine in
psychiatry: problems and promises. BMC Medicine, 11(1):132, May 2013. ISSN 1741-7015.
Il Memming Park, Miriam L R Meister, Alexander C Huk, and Jonathan W Pillow. Encoding
and decoding in parietal cortex during sensorimotor decision-making. Nat Neurosci, 17
(10):1395–1403, 10 2014.
Emma J. Quinn, Zack Blumenfeld, Anca Velisar, et al. Beta oscillations in freely moving
parkinson’s subjects are attenuated during deep brain stimulation. Movement Disorders,
30(13):1750–1758, 2015. ISSN 1531-8257.
Arbora Resulaj, Roozbeh Kiani, Daniel M. Wolpert, and Michael N. Shadlen. Changes of
mind in decision-making. Nature, 461:263 EP –, 08 2009.
Boris Rosin, Maya Slovik, Rea Mitelman, et al. Closed-loop deep brain stimulation is superior
in ameliorating parkinsonism. Neuron, 72(2):370 – 384, 2011. ISSN 0896-6273.
Justin Sanchez. Neuroprosthetics: Principles and Applications. CRC Press, 2015.
Steven J. Schiff. Neural Control Engineering: The Emerging Intersection between Control
Theory and Neuroscience. MIT Press, 2011.
E. Stengel. Optimal Control and Estimation,. Dover, 1994.
David Sussillo. Neural circuits as computational dynamical systems. Current Opinion
in Neurobiology, 25:156 – 163, 2014. ISSN 0959-4388. Theoretical and computational
neuroscience.
29

bioRxiv preprint doi: https://doi.org/10.1101/241299; this version posted January 15, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder. All rights reserved. No reuse allowed without permission.

David Sussillo, Rafal Jozefowicz, L. F. Abbott, and Chethan Pandarinath. Lfads - latent
factor analysis via dynamical systems. 2017.
Huiling Tan, Jean Debarros, Alek Pogosyan, et al. Decoding voluntary movements and
postural tremor based on thalamic lfps for closed-loop stimulation for essential tremor.
bioRxiv, 2018.
Emanuel Todorov and Michael I. Jordan. A minimal intervention principle for coordinated
movement. In Obermayer Becker, Thurn, editor, Advances in Neural Information Processing
Systems 15, pages 27–34. 2013.
Megan H. Trager, Mandy M. Koop, Anca Velisar, et al. Subthalamic beta oscillations are
attenuated after withdrawal of chronic high frequency neurostimulation in parkinson’s
disease. Neurobiology of Disease, 96:22–30, December 2016. ISSN 09699961.
Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to
control: A locally linear latent dynamics model for control from raw images. In C. Cortes,
N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural
Information Processing Systems 28, pages 2746–2754. Curran Associates, Inc., 2015.
Kong-Fatt Wong and Xiao-Jing Wang. A recurrent network mechanism of time integration in
perceptual decisions. The Journal of Neuroscience, 26(4):1314–1328, January 2006. ISSN
1529-2401.
Yuxiao Yang and Maryam M Shanechi. An adaptive and generalizable closed-loop system
for control of medically induced coma and other states of anesthesia. Journal of Neural
Engineering, 13(6):066019, 2016.
Yuan Zhao and Il M. Park. Variational joint filtering. ArXiv e-prints, July 2018.
Yuan Zhao and Il Memming Park. Variational latent Gaussian process for recovering singletrial dynamics from population spike trains. Neural Computation, 29(5), May 2017.

30

