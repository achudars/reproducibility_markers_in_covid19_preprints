bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Power, positive predictive value, and sample size calculations
for random eld theory-based fMRI inference
Dirk Ostwald, Sebastian Schneider, Rasmus Bruckner, Lilla Horvath
Arbeitsbereich Computational Cognitive Neuroscience, Department of Education and Psychology,
Freie Universität Berlin, Berlin, Germany

Abstract
Recent discussions on the reproducibility of task-related functional magnetic resonance imaging
(fMRI) studies have emphasized the importance of power and sample size calculations in fMRI
study planning. In general, statistical power and sample size calculations are dependent on the
statistical inference framework that is used to test hypotheses.

Bibliometric analyses suggest

that random eld theory (RFT)-based voxel- and cluster-level fMRI inference are the most commonly used approaches for the statistical evaluation of task-related fMRI data. However, general
power and sample size calculations for these inference approaches remain elusive. Based on the
mathematical theory of RFT-based inference, we here develop power and positive predictive
value (PPV) functions for voxel- and cluster-level inference in both uncorrected single test and
corrected multiple testing scenarios. Moreover, we apply the theoretical results to evaluate the
sample size necessary to achieve desired power and PPV levels based on an fMRI pilot study.

Keywords:

fMRI, random eld theory, statistical power, positive predictive value, sample size

1. Introduction
A fundamental goal of task-related functional magnetic resonance imaging (fMRI) is to identify the cortical correlates of cognition.

An approach routinely used to achieve this goal is

mass-univariate null hypothesis signicance testing in the framework of the general linear model
(Friston et al., 1994; Poline and Brett, 2012; Cohen et al., 2017). In the recent debate on the
reproducibility of research ndings in the life sciences, the statistical practices of fMRI research
have once again taken centre stage in the community discourse (e.g., Eklund et al., 2016; Mumford et al., 2016; Poldrack et al., 2017; Eklund et al., 2019; Flandin and Friston, 2019). Here, a
particular emphasis has been on statistical power and its relation to typical sample sizes in fMRI
group studies (Button et al., 2013; Guo et al., 2014; Szucs and Ioannidis, 2016; Cremers et al.,
2017; Geuter et al., 2018; Turner et al., 2018). In task-related fMRI, statistical power is broadly
dened as the probability of detecting cortical activation, if this activation is indeed present. In
general, statistical power and, consequently, methods for computing the sample sizes necessary
to achieve desired levels of power depend on both the statistical inference framework used and
assumptions about the expected cortical activation.
A prominent statistical inference framework for null hypothesis signicance testing in fMRI
research is based on random eld theory (RFT) (Worsley, 2007; Friston, 2007; Nichols, 2012;
Ostwald et al., 2018).

RFT-based fMRI inference is a parametric framework that allows for

controlling the multiple testing problem inherent in the mass-univariate approach. Technically,
this framework rests on analytical approximations to the exceedance probabilities of topological features of data roughness-adapted random eld null models.

1

RFT-based fMRI inference

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

is implemented in the two major data analysis software packages used by the neuroimaging
community, namely, Statistical Parametric Mapping (SPM) and the Functional Magnetic Resonance Imaging of the Brain (FMRIB) Software Library (FSL). It encompasses up to ve forms
of statistical testing: uncorrected and corrected voxel-level inference, uncorrected and corrected
cluster-level inference, and set-level inference (Friston et al., 1996). With the exception of setlevel inference, all forms are routinely reported in the functional neuroimaging literature. More
specically, bibliometric analyses suggest that RFT-based fMRI inference, especially corrected
cluster-level inference, accounts for approximately 70% of published task-related human fMRI
studies (Supplement S.1).
In light of the widespread use of RFT-based inference, previously proposed approaches for
the calculation of power and sample sizes in fMRI research have a number of shortcomings.
First and foremost, most previously proposed frameworks are not well aligned with the theory
of RFT-based fMRI inference (e.g., Desmond and Glover, 2002; Mumford and Nichols, 2008;
Durnez et al., 2016), rendering them non-applicable for the most commonly employed forms of
fMRI inference. Second, the framework previously proposed by Hayasaka et al. (2007) and Joyce
and Hayasaka (2012) that is aligned with the theory of RFT-based fMRI inference only addresses
voxel-level and not cluster-level inference. Moreover, this framework does not address the variety
of power types that arise in multiple testing scenarios and thus remains imprecise with respect
to the interpretation of its ensuing power and sample size values. Third, all previous frameworks
assume that under the alternative hypothesis, cortical activation is expressed either in a known
region of interest or over the entire cortex.

Notably, neither of these assumptions necessarily

reects common intuitions of neuroimaging researchers. Finally, no previous framework allows
for the necessary sample sizes to be derived based on a desired positive predictive value (PPV),
a novel statistical marker for the quality of empirical research that has risen to prominence over
the last decade (Wacholder et al., 2004; Ioannidis, 2005; Heston and King, 2017; Colquhoun,
2019).
With the current work, we address these shortcomings and report on a novel framework for
power, PPV, and sample size calculations in RFT-based fMRI inference. We rst consider the
framework's theoretical foundations by briey reviewing the notion of power in single test scenarios, the concepts of minimal and maximal power in multiple testing scenarios, the foundations of
the PPV, and the notion of partial alternative hypotheses in Section 2: Theoretical foundations.
We next develop the power and PPV functions for RFT-based fMRI inference on the basis of
the standard fMRI group analysis probabilistic model in Section

3: Methods.

In Section

4:

Results, we then discuss the RFT-based power and PPV functions at both the voxel and cluster level in both the uncorrected single test and corrected multiple testing scenario and discuss
their parametric dependencies. Finally, we apply the proposed framework in a prospective power
analysis based on a pilot fMRI data set and evaluate the sample sizes necessary to obtain desired
power and PPV levels. In Section 5: Discussion, we close with by considering some commonalities and dierences between the proposed framework and previously proposed approaches and
some potential avenues for future research. Throughout, we limit our scope to the evaluation of
contrasts of rst-level GLM parameter estimates (COPEs) at the group level using

T -statistics,

the approach most commonly used for group-level fMRI analyses. The technical foundations of
our framework are detailed in Supplement S.2. All data and software used are available from

https://osf.io/xjcg4/.

2

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

2. Theoretical foundations
Power functions
In single test scenarios, such as testing for the activation of a single voxel, two types of errors
can occur: the test may reject the null hypothesis when it is in fact true, referred to as a Type
I error, and the test may not reject the null hypothesis when in fact the alternative hypothesis
is true, referred to as a Type II error.

From a frequentist perspective, Type I and Type II

errors are associated with their probabilities of occurrence, denoted

α

and

1 − β,

respectively,

and commonly referred to as Type I and Type II error rates. The complementary probability
of a Type II error, i.e., the probability rejecting the null hypothesis if the alternative hypothesis
is true, is referred to as the power

β

of a test.

A fundamental aim of test construction is to

maintain low Type I and Type II error rates. To this end, a desired Type I error rate is usually
selected rst by dening a test signicance level

α0 ,

ensuring a Type I error rate of at most

α0 .

0
For many commonly used tests, the power at a xed signicance level α can then be shown to
be a function

β(n, d)

of an eect size measure

d

and the sample size

n.

An often recommended

n for which, under the
such as β(n, d) = 0.8.

approach in research study design is calculating the necessary sample size
assumption of a xed eect size

d,

the power reaches a desirable level,

Minimal and maximal power functions
In multiple testing scenarios, such as simultaneously testing for cortical activation over many
voxels, a Type I or a Type II error may occur for each of the individual tests involved, inducing
a variety of Type I and Type II error rates. For example, commonly considered Type I error
rates in fMRI research are the

family-wise error rate

(FWER), dened as the probability of

one or more false rejections of the null hypothesis, and the

false discovery rate

(FDR), dened

as the expected proportion of Type I error among the rejected null hypotheses.

Classically,

the FWER has been the prime target for Type I error rate control in fMRI research.

The

prevalence of FWER control derives from the fact that the FWER can be eciently controlled
using maximum statistic-based procedures (e.g., Roy, 1953; Roy and Bose, 1953), which were at
the centre of the early developments of RFT-based fMRI inference (Friston et al., 1991; Worsley
et al., 1992; Friston et al., 1994). Maximum statistic-based multiple testing procedures allow the
FWER to be controlled using a family-wise error signicance level

0
.
αFWE

Just as the multiplicity

of statistical tests in multiple testing scenarios induces a variety of Type I error rates, it also
induces a variety of Type II error rates and hence power types. Power types commonly considered
in multiple testing are

minimal power, dened as the probability of one or more correct rejections
maximal power, dened as the probability of correctly rejecting all

of the null hypothesis, and

false null hypotheses (e.g., Dudoit et al., 2003).

When calculating the sample sizes necessary

for desired power levels in Type I error rate-controlled multiple testing scenarios, it is hence
essential to explicate the power type of interest. As RFT-based fMRI inference naturally lends
itself to the evaluation of the minimal and maximal power functions

βmin (n, d)

and

βmax (n, d),

respectively, we focus on these power types in the current work.

PPV functions
In recent discussions, studies with low power have been related to high probabilities of the
claimed eects to be false positives (cf. Ioannidis, 2005; Button et al., 2013). This relationship
is not inherent in classical frequentist test theory in which Type I and Type II error rates are
conceived independently. Instead, the dependency of Type I error rates on Type II error rates,
and hence power, arises in the context of a probabilistic model that assigns probabilities to the
null hypothesis of being either true or false and the ensuing concept of a test's PPV (Wacholder
et al., 2004) (for an equivalent formulation in terms of false positive risk, see Colquhoun (e.g.

3

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

2017, 2019)). A test's PPV, denoted here by

ψ , is dened as the probability of the null hypothesis

being false given that the test rejects the null hypothesis. As discussed in Supplement S.2, the
PPV depends on both the Type I error rate and the

prior hypothesis parameter π ∈ [0, 1], which

represents the prior probability of the alternative hypothesis being true. For a constant Type I
error rate and prior hypothesis parameter, the PPV is a function of the test's power and, similar
to power, a function

ψ(n, d) of the eect and sample sizes.

Moreover, in multiple testing scenarios,

such PPV functions can be generalized to minimal and maximal PPV functions

ψmax (n, d)

ψmin (n, d)

and

by substitution of the respective minimal and maximal power functions. Similar to

n for
ψ(n, d) = 0.8.

power functions, single test and multiple testing PPV functions allow nding the sample size
which, at a given eect size

d,

the PPV function reaches a desirable level, such as

Partial alternative hypothesis scenarios
Previous approaches to the evaluation of power in fMRI inference have typically relied on the
assumption that the experimental eect of interest is expressed in a known cortical region of
interest, i.e., single test scenarios, (e.g., Desmond and Glover, 2002; Mumford and Nichols, 2008),
or in multiple testing scenarios, across the entire cortical volume (e.g., Hayasaka et al., 2007;
Joyce and Hayasaka, 2012). While there are situations in which prospective power analyses are
reasonable under these assumptions, we here suggest that the evaluation of necessary samples
sizes may often be desired although neither the precise location of an expected activation nor
the activation of the entire cortical sheet is reasonably assumed.

To this end, we propose to

parameterize the power, PPV, and sample size calculations in multiple testing scenarios with a

partial alternative hypothesis parameter λ ∈ [0, 1],
activated brain volume. Intuitively, for example,
of the cortex is truly activated. Formally,

λ

which describes the assumed proportion of

λ = 0.1 corresponds to the assumption that 10%

corresponds to the continuous spatial generalization

of the alternative hypotheses ratio of multiple testing scenarios, as discussed in Supplement S.2.
Note that if

λ = 0,

the minimal and maximal power are necessarily identically zero, as there are

no true activations. Equivalently, if

λ = 1,

the FWER is necessarily zero, as there are no null

activations.

3. Methods
Based on the theoretical foundations discussed above, we next develop the power and PPV
functions for RFT-based fMRI inference on the basis of the standard fMRI group analysis probabilistic model. For a comprehensive review of RFT-based fMRI inference from rst principles
and with a particular focus on its SPM implementation, please refer to Ostwald et al. (2018).
For a comprehensive review of the underlying test theory, please refer to Supplement S.2.

Probabilistic model
Standard fMRI group analysis in the framework of the GLM is based on a two-level summary
statistics approach.

At the rst-level, participant-specic MRI time series are analysed using

voxel-wise convolution-based GLMs.

The resulting participant- and voxel-specic COPEs are

the data used for the second-level, continuous-space, discrete-data point model of RFT-based
fMRI inference,

P (Y1 (x), ..., Yn (x)) , x ∈ S ⊆ R3 ,

(1)

Yi (x) denotes the random variable that models the COPE of the ith of n study participants
at location x in the continuous three-dimensional search space S . In its structural form, the joint

where

distribution of these random variables is dened by

Yi (x) = µ(x) + σZi (x), x ∈ S ⊂ R3 , i = 1, ..., n,
4

(2)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

µ(x) is an unknown value of a space-dependent parameter function µ : R3 → R, σ > 0 is an
unknown standard deviation parameter, and Zi (x) is a Z -eld modelling observation error. The
Zi (x), i = 1, ..., n are assumed to be independent and of identical smoothness. Observed COPE

where

data sets are assumed to represent a lattice approximation to eq. (2) and can be represented by
the discrete-space, discrete-data point model

Yiv = µv + σZiv

for

i = 1, ..., n,

and

v = 1, ..., m,

(3)

µv := µ(xv ) denotes the value of the parameter function µ at voxel location xv , and Ziv :=
denotes the ith Z -eld random variable located at voxel location xv . In the following, we
denote the family of random variables Yiv , i = 1, ..., n, v = 1, ..., m by Y := (Yiv )i=1,...,n,v=1,...,m ,
we summarize the values of the space-dependent eect size parameter function in a vector µ :=
(µ1 , ..., µm )T ∈ Rm , and we denote the ensuing cardinality of the discretized second-level random
eld model and, equivalently, the dimensionality of an observed COPE data set, by k := nm.

where

Zi (xv )

Statistics
RFT-based fMRI inference is based on a set of statistics that map
sets onto lower-dimensional outcome spaces.

k -dimensional

COPE data

Evaluating the probability of observed values of

these statistics under the random eld model of eq. (1) then allows for testing null hypotheses
at desired levels of signicance.

To this end, RFT-based fMRI inference distinguishes single

test scenarios, commonly referred to as

uncorrected inference, based on uncorrected p-values,
corrected inference, based on corrected

and multiple testing scenarios, commonly referred to as

p-values.

Depending on the test scenario and the type of statistic, a specic form of inference

ensues.
In the single test scenario and at the voxel level, the statistics of interest are the voxel height
statistics

Tv (Y ) : Rk → R, y 7→ Tv (Y = y) :=
where

ȳv

and

sv

√

nȳv /sv ,

for

v = 1, ..., m,

v th voxel data,
T -statistics and form so-

denote the sample mean and sample standard deviation of the

respectively. The voxel height statistics thus correspond to standard

statistical parametric maps of T -statistics, sometimes denoted SPM{T}.

called

under the

(4)

T -statistic

Note that because

the Gaussian elds implied by (3) are projected onto a single

T -eld,

the

probabilities of statistics under the probabilistic model of eq. (1) are commonly expressed with
respect to

T -elds.

In the single test scenario and at the cluster level, the statistics correspond to the cluster
extent statistics

Kj (Y ) : Rk → R, y 7→ Kj (Y = y)

for

j = 1, ..., c,

(5)

Kj (Y ) denotes the extent of the j th of c clusters within an excursion set dened by a
u ∈ R. The test statistics Kj (Y ), j = 1, ..., c subsume all data-analytical steps that project

where
CDT

a COPE data set onto the extents of clusters within the excursion set of a statistical parametric
map. These steps comprise but are not limited to thresholding a statistical parametric map at
level

u,

evaluating the entailing clusters using a numerical connectivity scheme, and measuring

the extent of the resulting clusters. Given the complexity of these computational subprocesses,
closed-form expressions for the evaluation of

Kj

imation to the distribution of the test statistics

are not easily provided. Nevertheless, an approx-

Kj (Y ), j = 1, ..., c is routinely used in RFT-based

fMRI inference, as will be discussed below.
In the multiple testing scenario and at the voxel level, the statistics of interest are the
maximum and minimum of the voxel height statistics

Tmax := max Tv
v∈Nm

and

5

Tmin := min Tv ,
v∈Nm

(6)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

respectively. Similarly, in the multiple testing scenario and at the cluster level, the statistics of
interest are the maximum and minimum of the cluster extent statistics

Kmax := max Kj

and

j∈Nc

Kmin := min Kj ,

(7)

j∈Nc

respectively. Consideration of the maximum statistics is warranted by their inherent property
of enabling FWER control and the evaluation of minimal power in multiple testing scenarios.
Consideration of the minimum statistics, in contrast, is warranted by their property of enabling
the evaluation of maximum power in multiple testing scenarios.

In the following, we detail

the distributions of the statistics of eqs. (4)-(7) under the probabilistic model of eq. (1) that
forms the core of RFT-based fMRI inference and the power evaluation framework proposed
here.

The distributions of the statistics will be provided in terms of exceedance probability

functions (EPFs). EPFs are the probabilistic complements of cumulative probability functions
and formulate the probability that a given statistic exceeds (rather than falls below, as in the
case of cumulative probability functions) a given value. The use of EPFs is conventional in RFTbased fMRI inference and is useful in the contexts of false positive control and statistical power,
both of which correspond to probabilities that statistics exceed critical values.

EPFs of RFT-based fMRI inference statistics
The EPFs of the test statistics (4) - (7) are based on (1) the
(2) the

T -eld's

T -eld's search space resel volumes,

EC densities, and (3) three topological feature expectations. We discuss each of

these in turn.
(1) The resel volumes

Rd (S)
of a

T −eld's

search space

S

for

d = 0, 1, 2, 3

(8)

are the search space's roughness-adjusted intrinsic volumes. In the

SPM implementation of RFT-based fMRI inference, the resel volumes of a statistical parametric
map are approximated by combining the values of the map's intrinsic volumes with a standardized
residuals-based roughness estimate using an algorithm originally proposed by Worsley et al.
(1996).
(2) The EC densities of

T -elds

were originally derived as generalizations of the

T -distribution

by Worsley (1994). Based on work by Taylor et al. (2006), Hayasaka (2007) and Hayasaka et al.
(2007) extended the EC densities to their non-central counterparts. The non-central

T -eld

EC

densities relevant for the current work are given by Hayasaka et al. (2007, p.729) as
Z ∞
ρ0 (t; δ, ν) :=

f (τ ; δ, ν) dτ,
t


ρ1 (t; δ, ν) :=

4 ln 2

1
2

2π


ρ2 (t; δ, ν) :=

4 ln 2
2π


ρ3 (t; δ, ν) :=

4 ln 2
2π




√
ν

√
ν

3
2

√
ν

1+

1+

t2
ν

1+

× (ν − 1)(ν − 2)

t2

!
E

ν



−1
U 2 f (t; δ, ν),

!
(ν − 1)
t

2

t2

!1
2

ν



−1
E U
−

1+

t2

!− 1
2

E

ν




−1
U 2 δ  f (t; δ, ν),

!

ν
t2
ν

!


E

U

−3
2


− 2(ν − 1)

t2

!1
2

1+

ν

t2
ν

!− 1

2



−1
E U
δ+

1+

t2
ν

!−1
E






−1
−1
2
U 2 δ −E U 2 

× f (t; δ, ν).
(9)

In eq. (9),

f (t; δ, ν)

denotes the probability density function of a non-central

with non-centrality parameter

δ ∈ R

and

ν > 1
6

T

random variable

degrees of freedom, which is given by (e.g.,

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Lehmann, 1986, p. 254, eq. (80))

2

ν−1
2

Γ

ν
2

∞

Z

1

f (t; δ, ν) :=



τ

1

(νπ) 2

ν−1
2

0

  1
2 !
 τ
1
τ 2
exp −
exp −
t
−δ
dτ.
2
2
ν

(10)

E (U p ) denotes the expected value of the pth power of a non-central chi-squared random variable
U with non-centrality parameter φ = δ 2 and µ = ν + 1 degrees of freedom , which is given by
(e.g., Johnson et al., 1995, p.449, eq. (29.32c))



φ
E (U ) := 2 exp −
2
p

Note that for

δ = 0,

p

the non-central

X
∞
j=0

T -eld

1
j!


 j
Γ p + j + µ2
φ
 .
2
Γ j + µ2

(11)

EC densities (9) are identical to the (central)

T-

eld EC densities as originally reported by Worsley et al. (1996) and Worsley et al. (1996).

T -eld EC densities (9) are evaluated by the function
f (t; δ, ν) using MATLAB's nctpdf.m function, computes the
non-central T -eld EC density using Matlab's nctcdf.m function, and

For the current work, the non-central
r_fun.m. This function computes
integral of the zero-order

approximates the series of eq. (11) by a numerically converging nite sum.
(3) Finally, the EPFs of the test statistics (4) - (7) are based on the following three topological
feature expectations of

T -elds:

the expected volume of an excursion set, the expected number

of clusters within an excursion set, and the expected volume of clusters within an excursion set.
For the non-central

T -eld

EC densities of eq. (9) with non-centrality parameter

degrees of freedom, and for a CDT

u,

√

nd

and

n−1

these expected values are given by

√
E(V ) = R3 (S)ρ0 (u; nd, n − 1),
√
E(C) = R3 (S)ρ3 (u; nd, n − 1),

(12)
and

(13)

E(K) = E(V )/E(C),

(14)

respectively.
With these preliminaries, the following EPFs for the statistics of eqs. (4) - (7) ensue:

◦

T -statistics.
T -eld EC density is identical to the cumulative
density function of a non-central T -distribution, the EPF of the Tv for a non-central T -eld
√
with non-centrality parameter
nd and n − 1 degrees of freedom takes the form

√
P (Tv ≥ t) = ρ0 t; nd, n − 1 .
(15)
The EPF of the voxel height statistics

Tv

follows from the standard theory of

Moreover, because the zero-order non-central

Note that for

d = 0,

the EPF of

Tv

equals the EPF of Student's

T -distribution

with

n−1

degrees of freedom.

◦

Kj

The EPF of the cluster extent test statistics

derives from an approximation for Gaussian

random elds originally proposed by Friston et al. (1994). For a non-central
centrality parameter

√

nd

and

n−1

degrees of freedom, and for a CDT

u,

T -eld

with non-

this approximation

generalizes to



P (Kj ≥ k) = exp −κk

2
3



,

7

where

κ :=

Γ

3
2

+1
E(K)

 ! 23
.

(16)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

◦

Tmax was originally
was generalized to non-central T -elds by Hayasaka
√
nd and n − 1 degrees of
non-centrality parameter

An approximation to the EPF of the maximum voxel height statistic
proposed by Worsley et al. (1996) and
(2007).

For a non-central

T -eld

with

freedom, the approximation is given by

P (Tmax ≥ t) = 1 − exp −

3
X

!

√

Rd (S)ρd (t; nd, n − 1) .

(17)

d=0
Similarly, as shown in Supplement S.3, an approximation to the EPF of the minimum voxel
height statistic

Tmin

can be given as

P (Tmin ≥ t) = exp −

3
X

Rd (S)ρd

!

√
−t; − nd, n − 1 .

(18)

d=0

◦

Finally, an approximation to the maximum cluster-level statistic

Kmax was proposed by Friston

et al. (1994). Based on Hayasaka et al. (2007), this approximation can be generalized to noncentral

T -elds

with non-centrality parameter

as

P (Kmax ≥ k) = 1 − exp −

3
X

√

nd, n − 1

Rd (S)ρd u;

√

degrees of freedom, and a CDT

!

nd, n − 1 P (Kj ≥ k) .

u

(19)

d=0
Similarly, as shown in Supplement S.3, an approximation to the EPF of the minimum cluster
extent statistic

Kmin

can be given as

P (Kmin ≥ k) = exp −

3
X

Rd (S)ρd u;

√

!

nd, n − 1 (1 − P (Kj ≥ k)) .

(20)

d=0
Test-relevant aspects of the EPFs in eqs. (15) - (20) are visualized in Supplement S.4. For all
calculations, eqs. (15) - (20) are evaluated with the function q_fun.m.

Test hypotheses
The use of central

T -eld

EC densities in the EPFs of fMRI inference test statistics reects

the intent to test the complete null hypothesis of zero activation throughout the entire search
space

S.

Similarly, the use of non-central

T -eld

densities in power calculations as proposed by

Hayasaka et al. (2007) and Joyce and Hayasaka (2012) corresponds to the assumption of non-zero
activation throughout the entire search space

S.

For our current work, we complement these

boundary cases with the assumption of a parameterized partial alternative hypothesis scenario
for power calculations. This scenario is based on the convex bipartition

Rd (S) = (1 − λ)Rd0 (S) + λRd1 (S)

for

d = 0, 1, 2, 3

and

λ ∈ [0, 1]

(21)

Rd0 (S), d = 0, 1, 2, 3
1
for which the null hypothesis of zero activation holds and resel volumes Rd (S), d = 0, 1, 2, 3 for

of the search space's resel volumes

Rd (S), d = 0, 1, 2, 3

into resel volumes

which the alternative hypothesis of non-zero activation and with eect size parameter
Note that for

λ = 0,

δ 6= 0 holds.

the partial alternative hypothesis scenario (21) corresponds to the complete

null hypothesis of standard RFT-based fMRI inference, whereas for

λ = 1,

it corresponds to

the complete alternative hypothesis scenario of Hayasaka et al. (2007) and Joyce and Hayasaka
(2012). Intuitively, the value of

λ thus corresponds to the proportion of the brain that is assumed

to be activated for a given COPE. Formally, this proportion can be considered equivalent to

8

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

the alternative hypothesis ratio in discrete multiple testing developed in Supplement S.2, eq.
(S2.21). Specically, for a partial alternative hypothesis parameter

Rd , d = 0, 1, 2, 3,

λ

and a set of resel volumes

the expected Euler characteristic

E

:=

3
X

Rd ρd (t; δ, ν)

for

δ ∈ R, ν > 1

(22)

d=0
that combines resel volumes and EC densities in the EPFs of the RFT-based fMRI test statistics
(4) - (7) takes the form

E

λ

:= (1 − λ)

3
X

Rd (S)ρd (t; 0, ν) + λ

3
X

d=0

Rd (S)ρd (t; δ, ν),

for

δ ∈ R, δ 6= 0, ν > 1.

(23)

d=0

For eqs. (12) and (14), only the respective zero- and third-order terms are considered.

Tests and power functions
With the test statistics and hypotheses in place, we next formalize the single test and multiple
testing scenario for voxel- and cluster-level inference and document the power functions that
result from the EPFs (15) - (20).

(1) Single test (uncorrected) voxel- and cluster-level inference
The aim of voxel-level inference in the single test scenario is to evaluate the null hypothesis of
zero activation at the

v th

voxel location using the voxel height statistic

Tv

for the test

φ(Y ) : Rk → {0, 1}, y 7→ φ(Y ) := 1{Tv ≥c} ,
where

1{·}

denotes the indicator function and

(24)

c denotes the test's critical value.
tα0 such that

The Type I error

rate of this test is controlled by choosing a critical value

PΘ0 (Tv ≥ tα0 ) ≤ α0
and the test obtains a signicance level

α0 .

With the EPF of

(25)

Tv ,

it then follows that the power

function for voxel-level inference in the single test scenario is given by


√
β : N≥2 × R → [0, 1], (n, d) 7→ β(n, d) := ρ0 tα0 ; nd, n − 1 .
This power function corresponds to the standard power function for one-sample

(26)

T -tests

and is

visualized in Figure 1A and Figure 1B. Note that the dependency of eq. (26) on the critical value

tα0

is commonly expressed indirectly in terms of the dependency of

tα0

on

α0

(cf. Figure 1B).

The aim of cluster-level inference in the single test scenario is to evaluate the null hypothesis
of zero activation over the extent of the

j th

cluster using the cluster extent statistic

Kj

for the

test

φ(Y ) : Rk → {0, 1}, y 7→ φ(Y ) := 1{Kj ≥k} ,
where

k

denotes the test's critical value.

choosing a critical value

k

α0

(27)

The Type I error rate of this test is controlled by

such that

PΘ0 (Kj ≥ kα0 ) ≤ α0
and the test obtains a signicance level

α0 .

With the EPF of

(28)

Kj ,

it then follows that the power

function for the cluster-level inference in the single test scenario is given by



2
2
3
3
β : N≥2 × R → [0, 1], (n, d) 7→ β(n, d) := exp − (Γ (3/2 + 1) /E(K)) kα0 ,
9

(29)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

where

√
R3 (S)ρ0 (u; nd, n − 1)
√
E(K) =
R3 (S)ρ3 (u; nd, n − 1)

(30)

denotes the expected volume of a cluster in an excursion set at level

u.

This power function is

visualized in Figure 1B.

(2) Multiple testing (corrected) voxel- and cluster-level inference
The aim of voxel-level inference in the multiple testing scenario is to evaluate the null hypothesis of zero activation at the

v th

voxel location while accounting for the multiplicity of tests

over voxels using the multiple test

Φ(Y ) : Rk → {0, 1}m , y 7→ Φ(Y ) := 1{Tv ≥cv }


v=1,...,m

.

(31)

The FWER of this test is controlled based on the EPF of the maximum voxel height statistic

Tmax

(17) by choosing a common critical value

tα0FWE

such that



0
PΘ0 Tmax ≥ tα0FWE ≤ αFWE
for a desired signicance level

0
αFWE
.

(32)

From the EPF of the maximum voxel height statistic (17),

it then follows, that the minimal power function of voxel-level inference in the multiple testing
scenario under the assumption of a partial alternative hypothesis with parameter

λ

is given by

λ
βmin
: N≥2 × R → [0, 1], (n, d) 7→
λ
βmin
(n, d)

:=1 − exp −λ

3
X

Rd (S)ρd



!

√
.
tα0FWE ; nd, n − 1

(33)

d=0

Similarly, from the EPF (18) of the minimum voxel height statistic

Tmin , it follows that the maxi-

mal power function for voxel-level inference in the multiple testing scenario under the assumption
of a partial alternative hypothesis parameter

λ

is given by

λ
βmax
: N≥2 × R → [0, 1], (n, d) 7→
λ
βmax
(n, d) := exp −λ

3
X

!


√
Rd (S)ρd −tα0FWE ; − nd, n − 1
.

(34)

d=0

The ensuing minimal and maximal power functions for corrected voxel-level inference for

0.1, 0.2, 0.3

λ=

are visualized in Figure 2A.

Finally, the aim of cluster-level inference in the multiple testing scenario is to evaluate the
null hypothesis of zero activation over the extent of the

j th

cluster location while accounting for

the multiplicity of cluster tests using the multiple test



Φ(Y ) : Rk → {0, 1}c , y 7→ Φ(Y ) := 1{Kj ≥kj }

j=1,...,c

.

(35)

The FWER of this test is controlled based on the EPF of the maximum cluster extent statistic

Kmax

(cf. (19)) by choosing a common critical value

kα0FWE

such that



0
PΘ0 Kmax ≥ kα0FWE ≤ αFWE
10

(36)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

for a desired signicance level

0
αFWE
.

From the EPF (19) of

Kmax , it then follows that the minimal

power function of cluster-level inference in the multiple testing scenario under the assumption of
a partial alternative hypothesis parameter

λ

is given by

λ
βmin
: N≥2 × R → [0, 1], (n, d) 7→
λ
βmin
(n, d) := 1 − exp −λ

3
X

Rd (S)ρd u;

√

(37)

!



nd, n − 1 PΘ1 Kj ≥ kα0FWE
,

d=0

where



PΘ1 Kj ≥ kα0FWE



is evaluated according to (16) for resel volumes

Similarly, from the EPF (20) of the minimum cluster extent statistic

Kmin ,

λRd , d = 0, 1, 2, 3.
it follows that the

maximal power function for cluster-level inference in the multiple testing scenario under the
assumption of a partial alternative hypothesis parameter

λ

is given by

λ
βmax
: N≥2 × R → [0, 1], (n, d) 7→
λ
βmax
(n, d)

:= exp −λ

3
X

Rd (S)ρd u;

√

!



nd, n − 1 1 − PΘ1 Kj ≥ kα0FWE
,

(38)

d=0



PΘ1 Kj ≥ kα0FWE is evaluated
λ = 0.1, 0.2, 0.3 are visualized in Figure
where

as for

λ
βmin

above.

The ensuing power functions for

2B.

Note the dierential manner by which the null hypothesis and alternative hypothesis resel
volumes determine the minimal and maximal power functions in the multiple testing scenario: the

tα0FWE and kα0FWE by
(1−λ)Rd (S) for some total resel volumes Rd (S), d = 0, 1, 2, 3.
hypothesis parameter λ here reduces the multiplicity of the

null hypothesis resel volumes aect the determination of the critical values
means of the eective resel volumes
In eect, the partial alternative

multiple testing problem, as a control of the FWER is required (and possible) only over the resel
volume subset (or clusters on this subset) for which the null hypothesis holds true. The alternative
hypothesis resel volumes, in contrast, aect the evaluation of minimal and maximal power by
means of the eective resel volumes
If

λ = 0,

λRd (S) for the same total resel volumes Rd (S), d = 0, 1, 2, 3.

minimal and maximal power are identically zero, as there are no true activations.

Equivalently, if

λ = 1,

there is no multiple testing problem and hence no FWER, as there are no

non-activations. The power functions (26) - (38) are evaluated with the function p_fun.m.

PPV functions
As discussed in Supplement S.2, PPV functions for the ve test scenarios of interest herein can be
specied by means of the respective test's (partial alternative hypothesis parameter-dependent)
power function for sample size and eect size
the prior hypothesis parameter

π

β(n, d),

the test's desired Type I error rate

π

and

and

as

ψ : N≥2 × R → [0, 1], (n, d) 7→ ψ(n, d) :=
where the dependencies on

α0 ,

α0

π
1−π β(n, d)
π
1−π β(n, d)

+ α0

,

(39)

are left implicit. The PPV functions depicted in Figure 1

- Figure 4 then follow directly by substituting the respective test power functions of eqs. (26),
(33), (34), (29), (37), (38) in eq. (39)

11

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

40
35

40

1

35

0.8
0.6

25
20

40
35

15

0

0.4

0.6

0.8

10
0.2

40

1

35

0.8

0.8

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.2

0

0.4

0.6

0.8

25

0

20

40

60

80

0

1

1

0.8

0.8

0.8

0.6

0.6

0.6

0.4

0.4

0.4

0.2

0.2

0.2

1

30
0.6

20

40

60

80

20

40

60

80

25
0.4

20

10
0.2

0.8

0.6

20
0.2

30

15

0.8

25
0.4

10
0.2

1

30

30

15

1

1

20
0.2

15

0

0.4

0.6

0.8

10
0.2

0

0.4

0.6

0.8

0

20

40

60

80

0

Figure 1. Power and PPV functions for voxel- and cluster-level inference in the uncorrected single test scenario.
(A) Power functions for uncorrected voxel-level and cluster-level inference for a given sample size n and eect
size d. For the cluster-level power function, a CDT parameter of u = 4.3 (p = 0.001 for ν = 9 degrees of freedom)
was used. (B) Power dependency on the signicance level α0 and the CDT value u for voxel- and cluster-level
inference, respectively. (C) PPV functions for uncorrected voxel-level and cluster-level inference for a given eect
size d and sample size n for the prior hypothesis parameter set to π = 0.2. (D) Prior parameter dependencies of
the voxel- and cluster-level PPV functions for a xed eect size of d = 0.5. Dots represent the evaluated sample
sizes. For implementational details, please see rftp_gure_1.m.

4. Results
RFT-based fMRI inference power and PPV functions
β(n, d) and ψ(n, d) for voxel- and
α0 . We then consider
λ
λ
λ
λ
the power and PPV functions βmin (n, d), βmax (n, d), ψmin (n, d), and ψmax (n, d) for voxel- and
0
cluster-level inference for xed family-wise error signicance levels αFWE and for xed partial
alternative hypothesis parameters λ. Note that these functions form the essential prerequisites

In the following, we rst discuss the power and PPV functions

cluster-level inference in single test scenarios for xed signicance levels

for calculating the sample sizes necessary to achieve desired levels of power or PPV.

The single test scenario: uncorrected voxel- and cluster-level inference
Figure 1A depicts the power functions

β(n, d)

for voxel- and cluster-level inference in the un-

α0 = 0.05. For voxel-level inference and
sizes of n = 20 to n = 40 are required to

corrected single test scenario at a signicance level of

d = 0.4 to d = 0.6, sample
β(n, d) = 0.8. For cluster-level inference and similar eect sizes, slightly
larger sample sizes of n = 25 to n = 40 are required to achieve similar power levels. Note that in

medium eect sizes of

achieve power levels of

contrast to voxel-level inference, cluster-level inference depends on the value of a cluster-dening
threshold (CDT). For the cluster-level power function depicted in Figure 1A, the CDT was set
to

u = 4.3,

corresponding to a

p-value

of 0.001 at

ν=9

degrees of freedom.

Naturally, varying the CDT impacts power: as shown in the right panel of Figure 1B, increasing the CDT at a constant sample size decreases power. This relationship is intuitive as, all else

12

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

being equal, increasing the CDT will mask out an increasing number of voxels and hence reduce
the chance of detecting a truly activated cluster. Similarly, and more fundamentally, the signicance level impacts power for both voxel- and cluster-level inference: as depicted for voxel-level
inference in the left panel of Figure 1B, decreasing the signicance level decreases power. For
all power curves shown in Figure 1B, the eect size was set to
size, a sample size of approximately

n = 70

d = 0.5.

For this medium eect

is required to achieve a power of

0
uncorrected voxel-level signicance level of α

= 0.001,

β(n, d) = 0.8

at the

which is sometimes used for inference in

empirical studies. Notably, neither uncorrected voxel-level inference nor cluster-level inference
is aected by the search space's resel volumes that relate to the statistical map's roughness:
the RFT-based power function of the voxel-level height statistic (cf.
the power function of a one-sample
volumes

per se.

T -test

eq.

(26)) is identical to

and is hence independent of the search space's resel

The power function of the cluster-extent statistic (cf.

eq.

(29)), however, is

dependent on the expected cluster extent and hence potentially susceptible to variations in the
statistical map's roughness. However, as the third-order resel volume aects both the expected
volume of clusters and the expected number of clusters, and for the evaluation of the expected
cluster extent, RFT-based fMRI inference assumes the independence of these expectations (cf.
eq. (12)), resel volume - and hence roughness - independence ensues.
Figure 1C depicts the PPV functions for voxel- and cluster-level inference in the uncorrected
single test scenario as a function of eect size
parameter of

π = 0.2.

and sample size

n

and for a prior hypothesis

Here, medium eect sizes similar to those of the power functions require

sample sizes on the order of
of

d

n = 10

to

n = 30

and

n = 15

to

n = 35

to achieve PPV levels

ψ(n, d) = 0.8 for voxel- and cluster-level inference, respectively. From the denition of the
ψ(n, d) as a monotonic transformation of a power function β(n, d) (cf. eq. (39)), it

PPV function

follows that the parameter dependencies of the voxel- and cluster-level power functions carry over
to the respective PPV functions. Naturally, PPV functions are additionally strongly dependent
on the value of the prior hypothesis parameter

π:

as shown in Figure 1D, low prior hypothesis

parameter values result in much larger sample sizes necessary to achieve desired PPV levels,
while higher prior hypothesis parameter values have the opposite eect.

The multiple testing scenario: corrected voxel- and cluster-level inference
Figure 2A depicts maximal and minimal power and PPV functions for corrected voxel-level
inference at a signicance level of

0
αFWE
= 0.05.

Specically, the two leftmost panels of Figure 2A

λ (n, d) for corrected voxelβmax
level inference and a partial alternative hypothesis parameter of λ = 0.1. Achieving a minimal
λ
power level of βmin (n, d) = 0.8 for a medium eect size of d = 0.5 requires sample sizes in
the range of n = 15 to n = 30. To achieve similar levels of maximal power βmax (n, d), the
same eect size requires sample sizes of n = 200 to n = 500. As shown in the upper three
panels of Figure 2A, increasing the partial alternative hypothesis parameter to λ = 0.2 and
λ (n, d) = 0.8. For
λ = 0.3 decreases sample sizes necessary to achieve a minimal power of βmin
depict the minimal and maximal power functions

λ (n, d)
βmin

and

maximal power, such a decrease is not observed. Intuitively, this relationship can be understood
as follows:

increasing the proportion of cortical activation increases the chances of detecting

activation at a single cortical location (minimal power) but not of detecting activations at all
locations (maximal power).
of

Finally, for a prior hypothesis parameter of

λ (n, d) = ψ λ (n, d) = 0.8
ψmin
max

π = 0.2,

PPV levels

can be achieved with eect and sample sizes largely similar

to those for minimal and maximal power, as depicted for

λ = 0.3

in the rightmost column of

Figure 2A.
Figure 2B depicts maximal and minimal power and PPV functions for corrected cluster-level
inference at a signicance level of

0
αFWE
= 0.05.

As for voxel-level inference, the leftmost panels

13

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

30
25

30

1
0.8

25

0.6

500
400

15

0.2
0

0.4

0.6

0.8

10
0.2

500

1
0.8

400

100
0.2

25

200

0

0.4

0.6

0.8

100
0.2

25

1
0.8

0

0.4

0.6

0.8

10
0.2

500

1
0.8

400

0

0.4

0.6

0.8

100
0.2

25

1

0.4

0.4

0.4

0.6

0.8

10
0.2

0.8

500

1
0.8

400

0.4

0.6

0.8

0

0.4

0.6

0.8

100
0.2

25

1

0.4

0.6

0.8

10
0.2

1

50

1

0.8

40

0.8

10
0.2

0.6

0

0.4

0.6

0.8

10
0.2

30
0.4

0

0.4

0.6

0.8

10
0.2

0.8

0.6

30
20

0.6

0

40

0.2

0.4

0.2

0

50

20

0.8

0.4

0.8

0.2

0.6

0.6

15

1

20

0.4

0.8

20

40

0.4

0.8

1

50

0.4

0.6

0

0.8

0.6

0.4

0.2

1

30

0.8

0.8

40

0.6

0.6

1

50

30

0.4

0.4

200

0.2

0.2

10
0.2

0

0.6

0.4

0

0.2

300

15
0.2

0

0.6

10
0.2

0.6

15
0.2

0.4

20
0.6

15

0

0.8

20
0.6

0.4

15

0.2

0.4

200

0.8
0.6

300
0.2

1

20

0.6

0.8

20

10
0.2

15

0.2

0.4

0.2

25

0.4

300
0.4

0.8
0.6

0.6

300

30

1

20
0.4

0.6

200

25

20
0.4

10
0.2

0.8
0.6

20
15

30

1

0.4

20

0.2
0

0.4

0.6

0.8

10
0.2

0.2
0

Minimal and maximal power and PPV functions for voxel- and cluster-level inference in the corrected
multiple testing scenario. (A) Minimal and maximal power and PPV functions for corrected voxel-level inference
for a given sample size n, eect size d, and partial alternative hypothesis parameter λ (rst three columns).
The fourth column depicts the corrected voxel-level minimal and maximal PPV functions for a prior hypothesis
parameter of π = 0.2. (B) Minimal and maximal power and PPV functions for corrected cluster-level inference
for a given sample size n, eect size d, and partial alternative hypothesis parameter λ (rst three columns). The
fourth column depicts the corrected cluster-level minimal and maximal PPV functions for a prior hypothesis
parameter of π = 0.2. All cluster-level power functions were evaluated for a CDT of u = 4.3, and all voxel- and
cluster-level power and PPV functions were evaluated for an exemplary resel volume set of R0 = 6, R1 = 33,
R2 = 354, and R3 = 705. For further implementational details, please see rftp_gure_2.m.
Figure 2.

of Figure 2B depict the minimal and maximal power functions for a partial alternative hypothesis

λ (n, d) = 0.8 for a medium eect
λ = 0.1. Here, achieving a minimal power of βmin
size of d = 0.5 requires sample sizes in the range of n = 10 to n = 20, while achieving a maximal
λ
power of βmax (n, d) = 0.8 at the cluster level requires sample sizes of n = 30 to n = 50. As for
corrected voxel-level inference, increasing the partial alternative hypothesis parameter to λ = 0.2
and λ = 0.3 decreases the necessary sample sizes for minimum power but not for maximum power.
λ
λ
Finally, for a prior parameter of π = 0.2, ψmin (n, d) = ψmax (n, d) = 0.8 can also be achieved
parameter of

at the cluster level with eect and sample sizes largely similar to those for power (Figure 2B,
rightmost column).
Naturally, the minimal and maximal power and PPV functions of corrected voxel- and clusterlevel inference exhibit a number of additional parametric dependencies (Figure 3). First, as shown
in Figure 3A, similar to the patterns observed for their uncorrected counterparts, the minimal
and maximal power functions of corrected voxel- and cluster-level inference are aected by the
desired signicance level

0
αFWE
,

with lower values of

14

0
αFWE

implying lower power. Second, and

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

1

1

1

1

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0
10

20

30

40

0
250

0
300

350

400

450

5

10

15

20

25

0
30

1

1

1

1

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0
10

20

30

0
250

0
300

350

400

450

5

10

15

20

0
35

1

1

1

1

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0
5

10

15

20

0
20

0
40

60

5

10

15

20

35

0
20

40

45

40

45

40

60

Parametric dependencies of minimal and maximal power and PPV functions for voxel- and clusterlevel inference in the corrected multiple tesing scenario. Dots depict the evaluated sample sizes, and a medium
eect size of d = 0.5 is considered for all plots. (A) Signicance level dependencies of minimal and maximal
power (λ = 0.1, u = 4.3). (B) Resel volume dependencies of minimal and maximal power (λ = 0.1, u = 4.3). r
denotes the scalar multiple of the exemplary resel volume set of R0 = 6, R1 = 33, R2 = 354, and R3 = 705.
(C) Minimal and maximal cluster-level power dependency on the CDT value u. (D) Prior hypothesis parameter
dependencies of minimal and maximal PPV functions at the cluster level. For implementational details, please
see rftp_gure_3.m.
Figure 3.

in contrast to the patterns observed for their uncorrected counterparts, the power functions in
the corrected scenario are dependent on the data roughness, as expressed by a statistical map's

r,
r = 5,

resel volumes. Figure 3B visualizes this inuence as parameterized by a roughness parameter
where for

r = 1,

the resel volumes are set as in Figure 2, while for

r = 0.5

and

r=2

to

they are decreased or increased by the respective factor. Notably, for both voxel- and clusterlevel inference, changes in the data roughness have opposite eects on minimal and maximal

λ (n, d), while
βmin
λ
results in a decrease of βmax (n, d). The eect

power: for minimal power, an increase in roughness
for maximal power, an increase in roughness

r

r

results in an increase of

of increased roughness on minimal power is familiar from the FWER-controlling features of the
expected Euler characteristic (EC) (Adler, 1981; Worsley et al., 1996): the higher the roughness
of the statistical eld, the higher the probability for the maximum of the statistical eld to exceed
a given value, and hence the lower the statistical signicance of an isolated peak. Because this
relationship is a property of the maximum statistic

Tmax , it is also evident in the case of minimal

power. Intuitively, as the roughness of the statistical eld can be viewed as a measure of the voxel

15

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

1

1

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0
10

15

20

25

0
10

1

1

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

11

12

13

14

15

1
0.8
0.6
0.4
0.2
0

0

50

100

0
200

300

400

500

0
20

30

40

50

60

Exemplary application of the RFT-based power, PPV, and sample size calculation framework. (A)
The upper panel depicts the results of a perceptual decision-making pilot study with n = 10 participants for
contrasting perceptual choices based on high and low visual sensory evidence. The T-values from the identied
cluster in the left medial frontal gyrus were averaged to obtain a raw eect size estimate, which was then adjusted
based on the eect size bias estimates reported in Figure 7 of Geuter et al. (2018) and reproduced in the lower
subpanel of panel (A). (B) Sample size calculations for voxel-level minimal and maximal power and PPV based
on the eect size estimates of the pilot fMRI study. (C) Sample size calculations for cluster-level minimal and
maximal power and PPV based on the eect size estimates of the pilot fMRI study. For implementational details,
please see rftp_gure_4.m.

Figure 4.

height statistics' spatial independence, detecting a single true alternative hypothesis is easier if
it is not correlated with neighbouring height statistics.

In contrast, maximal power increases

with decreasing roughness and hence increasing smoothness. This association is intuitive: the
smoother the statistical eld is, the stronger the spatial covariation of the statistics. Thus, if
a true alternative hypothesis is detected at one location, the other true alternative hypotheses
are also likely to be detected (if, as in the current case, it is assumed that the area of activation
corresponds to a contiguous set).

As in the uncorrected cluster-level scenario, increasing the

value of the CDT decreases power at a constant eect size for both minimal and maximal power
(Figure 3C) because the probability of detecting one or all locations at which the alternative
hypothesis is true decreases with the masking of an increasing number of voxels. Finally, the
prior hypothesis parameter

π

also strongly aects PPV levels in the multiple testing scenario, as

exemplied in Figure 3D for the cluster-level minimal and maximal PPV functions.

Exemplary application
The power and PPV functions presented above imply the sample sizes necessary to achieve
desired power and PPV levels over a broad range of possible eect sizes. To demonstrate the
practical value of these functions, we nally consider their application in the concrete scenario
of determining the sample size necessary to achieve power and PPV levels of 0.8 for a single
eect size estimate. To this end, we re-analysed fMRI data from the rst 10 participants in a
previously reported perceptual decision-making study in which the amount of visual evidence for

16

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

a presented stimulus to depict a face or a car was varied (Ostwald et al., 2012; Georgie et al.,
2018). At the group level, contrasting fMRI activity levels between high and low visual evidence
revealed a cluster of activity in the left medial frontal gyrus, as shown in the upper panel of
Figure 4A (for further details about the experimental and data-analytical procedures, please
see Supplement S.5). Our aim was to use the eect size estimate derived from this cluster to
calculate the sample sizes necessary to achieve minimal and maximal power and PPV levels of

0
αFWE
= 0.05, a partial
alternative hypothesis parameter of λ = 0.1, and a prior hypothesis parameter of π = 0.2. To
this end, we evaluated the average T-values of the cluster, yielding T = 4.65, which translates
√
ˆ = 4.65/ 10 = 1.47. However, it is well known that eect size
into an eect size estimate of d
0.8 for corrected voxel- and cluster-level inference at a signicance level of

estimates resulting from the thresholding of mass-univariate statistical parametric maps exhibit
biases (e.g., Vul et al., 2009; Poldrack et al., 2017). To correct our eect size estimate for this
bias, we capitalized on recent results by Geuter et al. (2018), which are depicted in the lower
panel of Figure 4A. Specically, using task-related fMRI data from the Human Connectome
Project 500 (Van Essen et al., 2013), Geuter et al. (2018) estimated the eect size bias exhibited
by activations detected in random data subsets of 10 to 100 participants from the approximately
500 participants. As reported in Figure 7A of Geuter et al. (2018) and visualized in the lower
panel of Figure 4A, this eect size bias is most severe for small data subsets and decreases
with increasing data subset size. For a data subset of
approximately

∆d = 1. We thus used this
dˆc = dˆ − ∆d = 0.47.

eect size estimate to

n = 10,

the eect size bias amounts to

empirically validated bias estimate to correct our
Using the power and PPV functions discussed in

the previous section, and the sample size calculation algorithms Algorithm A2 and Algorithm
A3 documented in Supplement S.6, we then obtained the following results: at the voxel level,
sample sizes of

n = 19

and

n = 374

are required to achieve minimal and maximal power levels

of 0.8, respectively (Figure 4B). At the cluster level, sample sizes of

n = 12

and

n = 48

are

required to achieve minimal and maximal power levels of 0.8 (Figure 4C), respectively. For all
testing scenarios considered and for the current parameter settings, slightly smaller sample sizes
are required to achieve PPV levels of 0.8.

5. Discussion
In summary, we have developed power and PPV functions for RFT-based fMRI inference,
which represents one of the mainstays of task-related fMRI data analysis.

Further, we have

demonstrated, how these functions can be used to determine the minimal sample sizes necessary
to achieve desired power and PPV levels in study planning.

Based on our example and its

implementation in the MATLAB function rftp_gure_4.m, interested users may readily adapt
the procedures described herein for performing power, PPV, and sample size calculations in
fMRI study planning. In the following, we briey sketch the relation of the current framework to
related approaches in the literature, discuss some potential avenues for future renements of the
approach, and close with some general remarks about statistical testing and power calculations
in fMRI research.
The current framework can be thought of as a direct extension of the work by Hayasaka et al.
(2007) and Joyce and Hayasaka (2012), generalizing the results presented therein to the cluster
level and carefully distinguishing between uncorrected and corrected scenarios and the multiple
power types thereby induced.

As such, the current framework comprises region of interest-

based approaches proposed by Desmond and Glover (2002) and Mumford and Nichols (2008)
and implied in the discussions by Friston (2012) and Lindquist et al. (2013) as special cases.
Specically, in terms of its power function, a region of interest-based approach corresponds to

17

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

uncorrected inference at the voxel level, i.e., a power evaluation for a one-sample

T -test, with the

dierence that in typical region of interest-based approaches, voxel height statistics are spatially
averaged over a set of voxels.

Another power calculation framework that has recently been

popularized is the approach of Durnez et al. (2016). This framework rests on a testing procedure
that considers local maxima of voxel height statistics above a threshold. Under the model by
Durnez et al. (2016), these local maxima are thought to be the outcome of a mixture distribution,
comprising realizations of a null hypothesis exponential distribution and an alternative hypothesis
Gaussian distribution. While the test procedure itself is not explicitly described, the apparent
idea is to reject the null hypothesis of no activation at the location of the local maximum
based on a set of arbitrary selected critical values (Durnez et al., 2016, Section 3.3). Based on
parameter estimates for the alternative hypothesis mixture component and the selected critical
value, Durnez et al. (2016) calculate power and sample sizes.

While an interesting approach

in its own right, the method by Durnez et al. (2016) relates to statistical models and testing
procedures that are specic to the power calculation approach by Durnez et al. (2016) and that
are not routinely used in fMRI data analysis.
The current work implies some potential avenues for further research with the aim of improving power, PPV, and sample size calculations for fMRI inference. First, RFT-based fMRI
inference itself may be further rened, thus entailing an optimization of the power and PPV
framework discussed herein. For example, the approximations to the cluster-level test statistic
distributions remain to be based on the Gaussian random eld approximations by Friston et al.
(1994), while newer results for

T-

and

F -elds

are available (e.g., Cao, 1999).

Similarly, the

notion of resel volumes has been largely superseded by the concept of Lipschitz-Killing curvatures (e.g., Taylor and Worsley, 2007), a theoretical development that has yet to be considered
in standard discussions of RFT-based fMRI inference. Second, it has been observed previously
as well as by us that some of the power functions of the RFT-based inference framework can
behave non-monotonically outside of practically relevant parameter regimes (Hayasaka et al.,
2007). Therefore, it may be desirable to further pursue mathematical analysis of the RFT-based
exceedance probability function approximations and to study their analytic behaviour across parameter regimes. Finally, with respect to the PPV, it may be desirable to diminish the degree of
subjectivity involved in selecting the prior hypothesis parameter. Potential avenues with which
to achieve this goal include basing PPV calculations on empirical priors estimated from fMRI
pilot data and considering the PPV in the more general setting of the false positive risk (e.g.,
Colquhoun, 2017, 2019).
As emphasized throughout, statistical power and PPVs are rooted in statistical testing, i.e.,
the dichotomization of the uncertainty-imbued results of statistical inference. As such, statistical
testing, power and PPV calculations, as well as deriving the sample sizes necessary to achieve
desired power and PPV levels, always generate simplied answers to complex scientic questions
(e.g., Wasserstein et al., 2019). Such simplied answers may not always be desired in a scientic
context, as indicated by recent initiatives to share unthresholded statistical parametric maps
(Gorgolewski et al., 2015). Stated dierently, while many researchers have argued that abandoning statistical testing based on arbitrary signicance thresholds may be a promising avenue for
improving scientic inference, few have argued that the entailing abandonment of power analyses may have similar eects. While we share the hope that the fMRI community will abandon
statistical testing in the long run, we here have provided power, PPV, and sample calculations
applicable to the widely used RFT-based fMRI inference procedures that can be adopted in the
meantime.

18

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Author contributions
D.O. designed and performed the research and analysed the data. D.O. wrote the paper with
input from S.S., R.B., and L.H.

Acknowledgements
We thank Hauke Heekeren for comments on an earlier version of this manuscript.

Data availability
All data used are available at

https://osf.io/xjcg4/.

Software availability
All software used is available at

https://osf.io/xjcg4/.

6. References
Adler, R. J. (1981).

The geometry of random elds.

John Wiley&Sons.

Borghi, J. A. and Van Gulick, A. E. (2018). Data management and sharing in neuroimaging:
Practices and perceptions of mri researchers.

PloS one, 13(7):e0200562.

Button, K. S., Ioannidis, J. P. A., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S. J., and
Munafò, M. R. (2013).
neuroscience.

Power failure: why small sample size undermines the reliability of

Nature Reviews Neuroscience, 14(5):365376.

Cao, J. (1999). The size of the connected components of excursion sets of

Advances in Applied Probability, 31(3):579595.

Carp, J. (2012).

The secret lives of experiments:

Neuroimage, 63(1):289300.

χ

2, t and f elds.

methods reporting in the fmri literature.

Cohen, J. D., Daw, N., Engelhardt, B., Hasson, U., Li, K., Niv, Y., Norman, K. A., Pillow, J.,
Ramadge, P. J., Turk-Browne, N. B., et al. (2017). Computational approaches to fmri analysis.

Nature neuroscience, 20(3):304.
Colquhoun, D. (2017).

The reproducibility of research and the misinterpretation of p-values.

Royal society open science, 4(12):171085.

Colquhoun, D. (2019). The false positive risk: A proposal concerning what to do about p-values.

The American Statistician, 73(sup1):192201.

Cremers, H. R., Wager, T. D., and Yarkoni, T. (2017). The relation between statistical power
and inference in fmri.

PloS one, 12(11):e0184923.

Desmond, J. E. and Glover, G. H. (2002).

Estimating sample size in functional mri (fmri)

neuroimaging studies: statistical power analyses.

Journal of neuroscience methods, 118(2):115

128.
Dudoit, S., Shaer, J. P., Boldrick, J. C., et al. (2003). Multiple hypothesis testing in microarray
experiments.

Statistical Science, 18(1):71103.

Durnez, J., Degryse, J., Moerkerke, B., Seurinck, R., Sochat, V., Poldrack, R., and Nichols, T.
(2016). Power and sample size calculations for fmri studies based on the prevalence of active
peaks.

bioRxiv.

19

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Eklund, A., Knutsson, H., and Nichols, T. E. (2019). Cluster failure revisited: Impact of rst
level design and physiological noise on cluster false positive rates.

Human Brain Mapping,

40(7):20172032.
Eklund, A., Nichols, T. E., and Knutsson, H. (2016). Cluster failure: Why fmri inferences for

Proc Natl Acad Sci U S A, 113(28):79007905.

spatial extent have inated false-positive rates.

Flandin, G. and Friston, K. J. (2019). Analysis of family-wise error rates in statistical parametric
mapping using random eld theory.
Friston, K. (2007).

Human Brain Mapping, 40(7):20522054.

Statistical Parametric Mapping: The analysis of functional brain images,

chapter Topological inference, pages 237  245. Academic Press.
Friston, K. (2012). Ten ironic rules for non-statistical reviewers.

Neuroimage, 61(4):13001310.

Friston, K. J., Frith, C., Liddle, P., and Frackowiak, R. (1991).
images: the assessment of signicant change.

Comparing functional (pet)

Journal of Cerebral Blood Flow & Metabolism,

11(4):690699.
Friston, K. J., Holmes, A., Poline, J.-B., Price, C. J., and Frith, C. D. (1996).
activations in pet and fmri: levels of inference and power.

Detecting

Neuroimage, 4(3):223235.

Friston, K. J., Holmes, A. P., Worsley, K. J., Poline, J.-P., Frith, C. D., and Frackowiak, R. S.
(1994). Statistical parametric maps in functional imaging: a general linear approach.

brain mapping, 2(4):189210.

Georgie, Y., Porcaro, C., Mayhew, S., Bagshaw, A., and Ostwald, D. (2018).
decision making eeg/fmri data set.

Human

A perceptual

bioRxiv doi:http://dx.doi.org/10.1101/253047.

Geuter, S., Qi, G., Welsh, R. C., Wager, T. D., and Lindquist, M. A. (2018). Eect size and
power in fmri group analysis.

bioRxiv, page 295048.

Gorgolewski, K. J., Varoquaux, G., Rivera, G., Schwarz, Y., Ghosh, S. S., Maumet, C., Sochat,
V. V., Nichols, T. E., Poldrack, R. A., Poline, J.-B., et al. (2015).

Neurovault.org: a web-

based repository for collecting and sharing unthresholded statistical maps of the human brain.

Frontiers in neuroinformatics, 9:8.

Guo, Q., Thabane, L., Hall, G., McKinnon, M., Goeree, R., and Pullenayegum, E. (2014). A systematic review of the reporting of sample size calculations and corresponding data components
in observational functional magnetic resonance imaging studies.

Neuroimage, 86:172181.

Hayasaka, S. (2007). Derivation of the euler characteristic densities of non-central t-and f-random
elds.

Technical Bulletin, ANSIR Laboratory. http://www. fmri. wfubmc. edu.

Hayasaka, S., Peier, A. M., Hugenschmidt, C. E., and Laurienti, P. J. (2007). Power and sample
size calculation for neuroimaging studies by non-central random eld theory.

NeuroImage,

37(3):721730.
Heston, T. F. and King, J. M. (2017). Predictive power of statistical signicance.

of methodology, 7(4):112.

Ioannidis, J. P. (2005). Why most published research ndings are false.

20

World journal

PLoS Med, 2(8):e124.

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Johnson, N., Kotz, S., and Balakrishnan, N. (1995).

2.

Continuous Univariate Distributions, Vol.

Wiley Series in Probability and Statistics.

Joyce, K. E. and Hayasaka, S. (2012). Development of powermap: a software package for statistical power calculation in neuroimaging studies.
Lehmann, E. L. (1986).

Neuroinformatics, 10(4):351365.

Testing statistical hypotheses.

Wiley Series in Probability and Statistics.

Lindquist, M. A., Cao, B., and Crainiceanu, C. (2013). Ironing out the statistical wrinkles in
'ten ironic rules'.

Neuroimage, 81:499502.

Mumford, J., Pernet, C., Yeo, B., Nickerson, D., Muhlert, N., Stikov, N., et al. (2016). Keep
calm and scan on.

Organization for Human Brain Mapping (OHBM).

Mumford, J. A. and Nichols, T. E. (2008). Power calculation for group fmri studies accounting
for arbitrary design and temporal autocorrelation.

Neuroimage, 39(1):261268.

Neyman, J. and Pearson, E. (1933). On the problem of the most ecient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London A: Mathematical, Physical
and Engineering Sciences, 231(694-706):289337.

Nichols, T. E. (2012). Multiple testing corrections, nonparametric methods, and random eld
theory.

Neuroimage, 62(2):811815.

Nichols, T. E., Das, S., Eickho, S. B., Evans, A. C., Glatard, T., Hanke, M., Kriegeskorte, N.,
Milham, M. P., Poldrack, R. A., Poline, J.-B., et al. (2017). Best practices in data analysis
and sharing in neuroimaging using mri.

Nature neuroscience, 20(3):299.

Ostwald, D., Porcaro, C., Mayhew, S. D., and Bagshaw, A. P. (2012). Eeg-fmri based information
theoretic characterization of the human perceptual decision system.

PloS one, 7(4):e33896.

Ostwald, D., Schneider, S., Bruckner, R., and Horvath, L. (2018). Random eld theory-based
p-values: a review of the spm implementation.

ArXiv.

Poldrack, R. A., Baker, C. I., Durnez, J., Gorgolewski, K. J., Matthews, P. M., Munafò, M. R.,
Nichols, T. E., Poline, J.-B., Vul, E., and Yarkoni, T. (2017). Scanning the horizon: towards
transparent and reproducible neuroimaging research.

Nature Reviews Neuroscience, 18(2):115.

Poline, J.-B. and Brett, M. (2012). The general linear model and fmri: does love last forever?

Neuroimage, 62(2):871880.

Roy, S. and Bose, R. C. (1953).

Simultaneous condence interval estimation.

Mathematical Statistics, pages 513536.

The Annals of

Roy, S. N. (1953). On a heuristic method of test construction and its use in multivariate analysis.

The Annals of Mathematical Statistics, pages 220238.

Szucs, D. and Ioannidis, J. P. (2016). Empirical assessment of published eect sizes and power
in the recent cognitive neuroscience and psychology literature.
Taylor, J. E. et al. (2006). A gaussian kinematic formula.
158.

21

bioRxiv.

The Annals of Probability, 34(1):122

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Taylor, J. E. and Worsley, K. J. (2007).
application to brain mapping.

Detecting sparse signals in random elds, with an

Journal of the American Statistical Association, 102(479):913

928.
Turner, B. O., Paul, E. J., Miller, M. B., and Barbey, A. K. (2018). Small sample sizes reduce
the replicability of task-based fmri studies.

Communications Biology, 1(1):62.

Van Essen, D. C., Smith, S. M., Barch, D. M., Behrens, T. E., Yacoub, E., Ugurbil, K., Consortium, W.-M. H., et al. (2013).

Neuroimage, 80:6279.

The wu-minn human connectome project:

an overview.

Vul, E., Harris, C., Winkielman, P., and Pashler, H. (2009). Puzzlingly high correlations in fmri
studies of emotion, personality, and social cognition.

Perspectives on psychological science,

4(3):274290.
Wacholder, S., Chanock, S., Garcia-Closas, M., Rothman, N., et al. (2004). Assessing the probability that a positive report is false: an approach for molecular epidemiology studies.

of the National Cancer Institute, 96(6):434442.

Journal

Wasserstein, R. L., Schirm, A. L., and Lazar, N. A. (2019). Moving to a world beyond 'p< 0.05'.
Woo, C.-W., Krishnan, A., and Wager, T. D. (2014). Cluster-extent based thresholding in fmri
analyses: pitfalls and recommendations.
Worsley, K. (2007).

Neuroimage, 91:412419.

Statistical Parametric Mapping: The analysis of functional brain images,

chapter Random eld theory, pages 232  236. Academic Press.
Worsley, K. J. (1994). Local maxima and the expected euler characteristic of excursion sets of

χ

2, f and t elds.

Advances in Applied Probability, pages 1342.

Worsley, K. J., Evans, A. C., Marrett, S., and Neelin, P. (1992).
tical analysis for cbf activation studies in human brain.

Metabolism, 12(6):900918.

A three-dimensional statis-

Journal of Cerebral Blood Flow &

Worsley, K. J., Marrett, S., Neelin, P., Vandal, A. C., Friston, K. J., Evans, A. C., et al. (1996). A
unied statistical approach for determining signicant signals in images of cerebral activation.

Human brain mapping, 4(1):5873.
Yeung, A. W. (2018).
studies.

An updated survey on statistical thresholding and sample size of fmri

Frontiers in human neuroscience, 12:16.

22

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Supplementary Material
S.1. Bibliometrics
Over the past seven years, at least four studies have used bibliometric methods and one study
has used survey methods to assess the use of data analysis software packages and statistical testing procedures in the functional neuroimaging literature (Carp, 2012; Woo et al., 2014; Poldrack
et al., 2017; Borghi and Van Gulick, 2018; Yeung, 2018). The most recent and most comprehensive account is provided by Yeung (2018). In Table S.1, we summarize the reported use of the
SPM and FSL software packages for data analysis, the use of RFT-based methods for multiple
testing control, and the relative prevalences of corrected voxel- and cluster-level inference. Note
that because RFT-based inference is the default option in SPM, it is likely that the choice of
the SPM software often implies the use of RFT-based inference, even if this is not explicitly
stated in the primary research study nor the meta-research studies cited here. Also note that, as
reported in Poldrack et al. (2017, p.123), up to a third of published fMRI studies continue to fail
identifying the method used for multiple testing control, a fact which has prompted initiatives
such as the COBIDAS report to improve reporting standards in the fMRI literature (Nichols
et al., 2017).

Carp (2012)
Woo et al. (2014)
Poldrack et al. (2017)
Borghi et al. (2018)
Yeung (2018)

n

230
484
66
144
388

Years
2007 - 2014
2010 - 2011
2016
2017
2017

SPM
64.3%
62.0%
n.s.
71.7%
52.1%

FSL RFT Voxel Cluster
13.9% n.s.
n.s.
n.s.
14.2% n.s. 19.0%** 75.0%**
n.s. 83.0%* n.s.
n.s.
70.8% n.s.
n.s.
n.s.
20.4% 69.2% 23.7 % 69.6%

Bibliometric and survey data on the use of software packages and statistical inference procedures in
the fMRI literature. All cited meta-research studies focus on human fMRI and assessed data analysis methods
in n = 66 to n = 484 primary research studies published between 2007 and 2017. The study by Borghi and
Van Gulick (2018) is based on survey data, all other studies used bibliometric methods. The study by Poldrack
et al. (2017) assessed the most recently published articles as of May 2016, all other bibliometric studies specify the
exact time range of the evaluated research reports. The prevalence of SPM and FSL use ranges between 52.1%
and 71.7% and 13.9% and 70.8%, respectively. The use of RFT-based fMRI inference is explicitly mentioned in
two of the meta-research studies and accounts for approximately 75% of the reported multiple testing control
methods. Corrected cluster-level inference dominates corrected voxel-level inference by approximately 70% to
20% (n: number of studies or survey participants included, Years: time range of the assessed literature or active
use, SPM: Statistical parametric mapping software, FSL: FMRIB software library, RFT: random eld theory use
for multiple testing control, Voxel: corrected voxel-level inference, Cluster: corrected cluster-level inference, n.s.
: not, or insuciently, specied, *: estimated based on the verbose description on p.122 of Poldrack et al. (2017),
**: based on n = 814 primary research studies).
Table S.1.

1

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.2. Test theory
In this Section we review the formal foundations of test theory. We rst develop the single
hypothesis test scenario and its associated error rates and power function.

We then consider

the multiple testing scenario with a particular emphasis on the notions of partial alternative
hypothesis scenarios as well as minimal and maximal power functions.
discuss the probabilistic foundations of the positive predictive value.

In a third step, we

We close our review by

discussing a single-observation z-test in the context of the single test and the multiple testing
scenario.

S.2.1 The single test scenario
Probabilistic model. To introduce the notion of a single test, we consider a parametric

Pθ (Y )

probabilistic model

that describes the probability distribution of a random entity (i.e., a

random variable or a random vector)
entity

Y

models

data

Y

and that is governed by a parameter

and is assumed to take on values

consider the parameter

θ

y ∈ R n , n ≥ 1.

θ ∈ Θ.

The random

Note that we do not

to be a random entity and thus develop the following theory against

the background of the classical frequentist scenario.

Θ is partitioned into two disjoint
Θ = Θ0 ∪ Θ1 and Θ0 ∩ Θ1 = ∅. A test hypothesis is
governing Pθ (Y ) in relation to these parameter space subsets.

Test hypotheses. In test scenarios, the parameter space

Θ0

subsets, denoted by

and

Θ1 ,

such that

a statement about the parameter
Specically, the statement

θ ∈ Θ0 ⇔ H = 0

null hypothesis

is referred to as the

(S2.1)

and the statement

θ ∈ Θ1 ⇔ H = 1
is referred to as the

alternative hypothesis.

(S2.2)

Note that we are concerned with the Neyman-Pearson

hypothesis testing framework and thus assume that null and alternative hypotheses always exist
in an explicitly dened manner. A number of things are noteworthy. First, a statistical hypothesis
is a statement about the parameter of a probabilistic model. In the following, we will use the
subscript notations
is an element of

Θ0

PΘ0 and PΘ1 to indicate that the parameter θ of the probabilistic model Pθ
or Θ1 , respectively. Second, the term null hypothesis is not necessarily the

statement that some parameter assumes the value zero, even if this is often the case in practice.
Rather, the null hypothesis in a statistical testing problem is the statement about the parameter
one is willing to nullify, i.e., reject. Finally, the expressions

H=0

and

H=1

are not conceived

as realizations of a random variable and hence hypothesis-conditional probability statements are

H = 0 and H = 1 are merely equivalent expressions for θ ∈ Θ0
θ ∈ Θ1 , respectively: H = 0 refers to the true, but unknown, state of the world that the
hypothesis is true and the alternative hypothesis is false (θ ∈ Θ0 ), and H = 1 refers to

not meaningful. The statements
and
null

the true, but unknown, state of the world that the alternative hypothesis is true and the null
hypothesis is false (θ
A

simple hypothesis

example

Θ0 := {θ0 }.

∈ Θ1 ).

In general, hypotheses can be classied as

A

composite hypothesis

more than one element, for example

or

composite.

refers to a subset of parameter space which contains

Θ0 := R≤0 .

The commonly encountered null hypothesis

nil hypothesis, is an example for a simple hypothesis.
Given the test hypotheses scenario introduced above, a test is dened as a mapping from

Θ0 = {0},
Tests.

simple

refers to a subset of parameter space which contains a single element, for

also referred to as

the data outcome space to the set

{0, 1},

formally

φ(Y = ·) : Rn → {0, 1}, y 7→ φ(Y = y).
2

(S2.3)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

φ(Y = y) = 0 represents the act of not
φ(Y = y) = 1 represents the act of rejecting

Here, the test value

rejecting null hypothesis, while

the test value

the null hypothesis.

Rejecting

the null hypothesis is equivalent to accepting the alternative hypothesis, and accepting the null
hypothesis is equivalent to rejecting the alternative hypothesis. In the following and in the main

φ(Y = ·)

text, we suppress the notational dependence of

Y

is a random entity, the expression

φ(Y )

on

y

and write

φ(Y ) instead. Because
φ(Y ) considered in

is also a random entity. All tests

the current study involve the composition of a

test statistic

γ(Y ) : Rn → R,
where

R

(S2.4)

models the test statistic's outcome space, and a subsequent

decision rule

δ(γ(Y )) : R → {0, 1},

(S2.5)

φ(Y ) = δ(γ(Y )) : Rn → {0, 1}.

(S2.6)

such that the test can be written as

Note that, as for the test, we suppress the dependencies of

γ(Y )

and

δ(γ(Y ))

on

y ∈ Rn ,

such

γ(Y ) and δ(γ(Y )) should be read as random entities. The subset of the test statistic's
space for which the test assumes the value 1 is referred to as the rejection region of the

that both
outcome

test. Formally, the rejection region is dened as

R := {γ(Y ) ∈ R|φ(Y ) = 1} ⊂ R.

(S2.7)

φ(Y ) = 1 and γ(Y ) ∈ R are thus equivalent and associated with the same
Pθ (Y ). In a concrete test scenario, it is hence usually the probability distribu-

The random events
probability under

tion of the test statistic that is of principal concern for assessing the test's outcome behaviour.
Finally, all test decision rules considered in the context of the current study are based on the
test statistic exceeding a

critical value u ∈ R.

By means of the indicator function, the tests

considered here can thus be written

φ(Y = ·) : Rn → {0, 1}, y 7→ φ(Y = y) := 1{γ(Y =y)≥u}
Note that (S2.8) describes the situation of

one-sided

(
1,
:=
0,

γ(Y = y) ≥ u
γ(Y = y) < u.

tests. The one-sided one-sample

(S2.8)

T -test

is a

familiar example of the general test structure described by expression (S2.8): using the sample
mean and sample standard deviation, a realization of the random entity

Y

is rst transformed

into the value of the t-statistic, whose size is then compared to a critical value in order to decide
for rejecting the null hypothesis or not.
Tests error probabilities. When conducting a hypothesis test as just described, two kinds

of errors can occur. First, the null hypothesis can be rejected (φ(Y
(θ

∈ Θ0 ).

This error is referred to as the

rejected (φ(Y

II error.

) = 0),

Type I error.

when it is in fact false (θ

∈ Θ1 ).

) = 1),

when it is in fact true

Second, the null hypothesis may not be
The latter error is known as the

Type

The probabilities of Type I and Type II errors under a given probabilistic model are

central to the quality of a test: the probability of a Type I error is called the
is commonly denoted by

α ∈ [0, 1].

size

of the test and

It is dened as

α := PΘ0 (φ(Y ) = 1),

3

(S2.9)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

and also routinely referred to as the

Type I error rate

of the test. Its complementary probability,

PΘ0 (φ(Y ) = 0) = 1 − α,
is known as the

specicity

(S2.10)

of a test. The probability of a Type II error

PΘ1 (φ(Y ) = 0)

(S2.11)

lacks a common denomination. Its complementary probability

β := PΘ1 (φ(Y ) = 1)
is referred to as the

power

(S2.12)

of a test. In words, the power of a test is the probability of accepting the

alternative hypothesis (rejecting the null hypothesis), if

θ ∈ Θ1 , i.e., if the alternative hypothesis

is true. Note that basic introductions to test error probabilities often denote the probability of
a Type II error by

β ∈ [0, 1]

and thus dene power by

1 − β.

For our current purposes, we prefer

the denition of eq. (S2.12), because it keeps the notation concise and is more coherent with
common notations of test quality functions.
Significance level. It is important to distinguish between the size and the signicance level

of a test: a test is said to be of

0
to α , i.e., if

signicance level α0 ∈ [0, 1], if its size α

is smaller than or equal

α ≤ α0 .
If for a test of signicance level

α0

it holds that

(S2.13)

α < α0 ,

the test is referred to as a

conservative

test. If for a test of signicance level α0 it holds that α = α0 , the test is referred to as an exact
test. Tests with an associated signicance level α0 for which α > α0 are sometimes referred to as
liberal tests. Note, however, that such tests are, strictly speaking, not of signicance level α0 .
The test quality function. The size and the power of a test are summarized in the test's

quality function. For a test

φ(Y ),

the

test quality function

is dened as

q : Θ → [0, 1], θ 7→ q(θ) := EPθ (Y ) (φ(Y )).

(S2.14)

In words, the test quality function is a function of the probabilistic model parameter
assigns to each value of this parameter a value in the interval

θ

and

This value is given by the

Pθ (Y ). The denition of the test quality
function is motivated by the value it assumes for θ ∈ Θ0 and θ ∈ Θ1 : because the random
variable φ(Y ) only takes on values in {0, 1}, the expected value EP (Y ) (φ(Y )) is identical to the
θ
probability of the event φ(Y ) = 1 under Pθ (Y ). Thus, for θ ∈ Θ0 , the test quality function
returns the size of the test (eq. (S2.9)) and for θ ∈ Θ1 , the test quality function returns the
expectation of the test

φ

[0, 1].

under the probabilistic model

power of the test (eq. (S2.12)).
The test power function. For

test's

power function

θ ∈ Θ1 ,

the test quality function is also is referred to as the

and is denoted by

β : Θ1 → [0, 1], θ 7→ β(θ) := PΘ1 (φ(Y ) = 1).

(S2.15)

Test construction. In both applications and the theoretical development of statistical tests,

the probability for a Type I error, i.e., the test size, is usually considered to be more important
than the Type II error rate, i.e., the complement of the test's power. In eect, when designing
a test, the test's size is usually xed rst, for example by deciding for a signicance level such
as

α0 = 0.05

and its associated critical value

uα0
4

of the test statistic (cf.

eq.

(S2.8)).

In a

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

second step, dierent tests or dierent probabilistic models are then compared in their ability to
minimize the probability of the test's Type II error, i.e., maximize the test's power. For example,
the celebrated Neyman-Pearson lemma states that for tests of simple hypotheses, the likelihood
ratio test achieves the highest power for a given signicance level over all conceivable statistical
tests (Neyman and Pearson, 1933). Inspired by current discussions about the power of tests in
functional neuroimaging, in the current study we primarily target the sample size as a parameter
of the probabilistic model to optimize dierent tests with respect to their Type II error rates
given prexed Type I error rates.

S.2.2 The multiple testing scenario
Probabilistic model. The notion of a multiple hypothesis test can be developed in analogy

to the single test scenario.

Like the single test scenario, the multiple testing scenario unfolds

Pθ (Y ) that describes the probability
n
entity Y which models observed data taking on values in R . The
is assumed to take values in a parameter space Θ.

against the background of a parametric probabilistic model
distribution of a random
parameter

θ

of the model

m ∈ N tests, the pa(i)
(i)
(i)
(i)
m times into disjoint subsets Θ0 and Θ1 , such that Θ = Θ0 ∪ Θ1
i ∈ I := {1, ..., m} and |I| = m. In analogy to the single test case, the

Multiple test hypotheses. In multiple testing scenarios comprising

rameter space is partitioned
and

(i)

(i)

Θ0 ∩ Θ1 = ∅

for

statements

(i)

θ ∈ Θ0 ⇔ H (i) = 0

and

(i)

θ ∈ Θ1 ⇔ H (i) = 1

(S2.16)

θ are referred to as the ith null and
m null hypotheses and their associated
hypotheses family and the set I is referred to as the

about the true, but unknown, value of the parameter

alternative hypothesis,

respectively.

Collectively, the

alternative hypotheses are referred to as a

hypotheses index set.

In the following, we will be concerned with the following situations

•

all null hypotheses of the hypotheses family are true and all alternative hypotheses are false,

•

some null hypotheses of the hypotheses family are true and the remaining alternative hypotheses are true,

•

all null hypotheses of the hypotheses family are false and all alternative hypotheses are true.

complete null hypothesis, the partial altercomplete alternative hypothesis, respectively. The following notation

For convenience, we will refer to these scenarios as the

native hypothesis,

and the

is helpful to formally express the complete null hypothesis and complete alternative hypothesis
scenarios, respectively:

(i)

θ ∈ Θ0 := ∩i∈I Θ0 ⇔ H (i) = 0
and

(i)

θ ∈ Θ1 := ∩i∈I Θ1 ⇔ H (i) = 1

for all

i∈I

(S2.17)

for all

i ∈ I.

(S2.18)

Note that despite the identical notation, the dierence between the single test scenario null and
alternative hypotheses (S2.1) and (S2.2), and the multiple testing scenario complete null and
complete alternative hypotheses (S2.17) and (S2.18) should in general be clear from the context.
As above, we will use the subscript notations
the probabilistic model

Θ1 ,

Pθ

PΘ0

and

PΘ 1

θ
Θ0

to indicate that the parameter

is an element of the complete null or alternative hypotheses

of
or

respectively. In light of expressions (S2.17) and (S2.18), we denote the partial alternative

hypothesis by

(i)

θ ∈ ∩i∈I1 Θ1

for

I1 ⊂ I
5

with

m1 := |I1 |,

(S2.19)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

and refer to

I1

as the

alternative hypotheses index set.

Given the binary nature of the

ith

null

and alternative hypothesis, it follows immediately that in the case of (S2.19) it holds that

(i)

θ ∈ ∩i∈I0 Θ0
We refer to

I0

as the

for

I0 := I \ I1

with

null hypotheses index set.

|I0 | = m − m1 =: m0 .

(S2.20)

The ratio of the cardinality of the alternative

hypotheses index set and the cardinality of the hypotheses index set will be denoted by

λ=
and will be referred to as the

λ ∈]0, 1[,

λ = 1

Pθ

Note that

λ=0

corresponds to the

corresponds to the complete alternative hypothesis.

PλΘ1

we use the subscript notation

the probabilistic model
hypotheses ratio

(S2.21)

alternative hypotheses ratio.

complete null hypothesis, whereas
Finally, for

m1
,
m

to indicate that the parameter

θ

of

is an element of a partial alternative hypothesis with alternative

λ.

Multiple test. For the multiple testing scenario, let

φi (Y = ·) : Rn → {0, 1}, y 7→ φi (Y = y)
denote a test, such that
and rejecting the
the

ith

ith

φi (Y = y) = 0

for all

i∈I

represents the act of accepting the

alternative hypothesis, while

null hypotheses and accepting the

ith

φi (Y = y) = 1

(S2.22)

ith

null hypothesis

represents the act of rejecting

alternative hypothesis. Then a multiple test is a

mapping

Φ(Y = ·) : Rn → {0, 1}m , y 7→ Φ(Y = y) := (φi (Y = y))i∈I .

(S2.23)

φi (Y = ·), the
probability distribution of which is governed by the parametric probabilistic model Pθ (Y ). As in
the single test scenario, we will suppress the notational dependence of Φ(Y = ·) on y and write
Φ(Y ) instead. Again, because the data Y is modelled as a random entity, the expression Φ(Y )
A multiple test can thus be conceived as an

m-dimensional

vector of single tests

should be read as a random vector. Similarly, as in the single test scenario we are only concerned
with scenarios for which each constituent test

φi (Y )

of

Φ(Y )

is of the form

φi (Y = ·) : Rn → {0, 1}, y 7→ φi (Y = y) := 1{γi (Y =y)≥ui } ,

(S2.24)

γi (Y ) : Rn → R

(S2.25)

where

denotes the

ith

test statistic with

ith

rejection region

Ri := {γi (Y ) ∈ R|φi (Y ) = 1} ⊂ R,
and

ui ∈ R

denotes the

ith

critical value. The multiple one-sided one-sample

(S2.26)

T -tests

commonly

performed for group-level fMRI analyses are a familiar example of the general multiple test structure described by eqs. (S2.23) - (S2.26): using voxel-specic sample means and sample standard
deviations, the data

Y,

usually comprising voxel-wise participant-specic beta parameter esti-

mate contrasts derived from rst-level GLM analyses, is projected onto a set of
The values of these

m T -statistics

m T -statistics.

individually evaluated with respect to appropriately dened

critical values, and for each of the

m

voxels, the null hypothesis of zero activation is either

rejected or not.

6

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

θ∈
θ∈

(i)
Θ0
(i)
Θ1

φi (Y ) = 0

φi (Y ) = 1

M00

M01

m0

M10

M11

m1

M00 + M10

M01 + M11

m

The multiple testing scenario. The numbers m0 and m1 of true null and alternative hypotheses
and θ ∈ Θ(i)
1 , are assumed to be xed and unknown. The outcome of the ith test φi (Y ), and hence also
the aggregate numbers of tests to assume either the value 0 or 1, Mij , i = 0, 1, j = 0, 1, as well as their sums,
M00 + M10 and M01 + M11 are random entities, all of which are governed by the parametric probabilistic model
Pθ (Y ) and the functional forms of the test statistics γi , i = 1, ..., m.

Table S.2.
(i)
θ ∈ Θ0

Multiple test error probabilities. The multiple testing scenario induces a variety of test

error scenarios. While for the single test scenario there exist four possible constellations of true

φ(Y ) = k for j = 0, 1 and k = 0, 1) there exist 4m such
(i)
constellations in the multiple testing scenario (θ ∈ Θj and φi (Y ) = k for i = 1, ..., m, j = 0, 1
and k = 0, 1). In other words, while a single test φ(Y ) may either result in either a Type I
or a Type II error (or a correct result), a multiple test Φ(Y ) may result in the simultaneous
hypotheses and test outcomes (θ

∈ Θj

and

occurrence of Type I errors in some of its constituent single tests and Type II error in others
of its constituents single tests (and correct results in the remaining single tests). This induces
probabilities for the occurrence of a variety of test error scenarios and hence a variety of Type
I and Type II error rates.

As Type II error rates are complementary probabilities of correct

rejections of null hypotheses, dierent Type II error rates correspond to dierent notions of
power.

In the following, we rst review the most commonly considered Type I and Type II

error rates in multiple testing scenarios. In later sections, we then consider the family-wise error
rate, minimal and maximal power and their control and evaluation by means of maximum and
minimum statistics in further detail.
The test error rates of multiple testing scenarios can be developed quantitatively as follows:
as above, let

I0

and

I1

denote the null and alternative hypotheses index sets, respectively (cf.

eqs. (S2.20) and (S2.19)). Note again that the binary single test scenario implies that
and

m0
test

I = I0 ∪ I1

I0 ∩ I1 = ∅ and that it is assumed that the sets I0 and I1 and their respective cardinalities
m1 are true, but unknown, entities. Based on the probabilistic binary outcome of each
constituent φi (Y ), the following quantities are induced at an aggregate level:

and

(i)

•

the number

M00

of tests for which

θ ∈ Θ0

•

the number

M01

of tests for which

θ ∈ Θ0

•

the number

M10

of tests for which

θ ∈ Θ1

•

the number

M11

of tests for which

θ ∈ Θ1

(i)

(i)

(i)

and

φi (Y ) = 0,

and

φi (Y ) = 1,

and

φi (Y ) = 0,

and

φi (Y ) = 1.

and

m, m0 and m1 correspond to true,
Mjk , j = 0, 1, k = 0, 1 correspond to unobservable
random variables, and the quantities M00 +M10 and M01 +M11 , i.e., the total number of accepted

The situation is summarized in Table S.2. Note that the values
but unknown, quantities, the four quantities

and rejected null hypotheses, correspond to observable random variables. Commonly considered
Type I error rates in this scenario are

•

the

family-wise error rate, dened as the probability for the event M01 ≥ 0, i.e., of one or more

Type I errors,

7

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

•

the

per-family error rate, dened as the expectation of the unobservable random variable M01 ,

i.e., the expected number of Type I errors,

•

per-comparison error rate,

the

hypotheses

•

the

m,

dened as the per-family error rate divided by the number of

and

false-discovery rate, dened as the expectation of the random variable M01 /(M01 + M11 ) if

M01 + M11 6= 0

and

0

if

M01 + M11 = 0,

i.e., the expected proportion of Type I errors among

the rejected null hypotheses, or 0, if no hypotheses are rejected.
Notably, in contrast to the Type I error rate in the single test scenario (i.e., the size of a test),
the Type I error rates in the multiple testing scenario refer to either probabilities (such as the
family-wise error rate) or expectations of the counting random variables

Mij , i = 0, 1, j = 0, 1.

In a concrete multiple testing scenario, these probabilities and expectations have to be derived
based on the nature of the probabilistic model and the denition of the multiple test.
As for the generalization of the notion of a Type I error to the multiple testing scenario, the
multiple testing scenario induces a variety of Type II error rates and their respective complementary probabilities, i.e., power types. Commonly considered power types in the multiple testing
scenario are

• minimal power,

dened as the probability of the event

M11 ≥ 1,

i.e., of one or more correct

rejections of the null hypothesis,

• average power,

dened as the expectation of the random variable

M11

divided by

m1 ,

i.e., the

expected proportion of false null hypotheses that are rejected, and

• maximal power,

dened as the probability of the event

M11 = m1 ,

i.e., of correctly rejecting

all false null hypotheses.
Multiple test construction. As in the single test scenario, multiple tests are usually con-

structed to rst and foremost control a chosen Type I error rate at a desired signicance level

α0 .

In a second step, additional test construction measures may then be taken to achieve a

desired level of a chosen power type. The random eld theory-based fMRI inference framework
has traditionally focussed on the family-wise error rate (FWER) as the target for Type I error
rate control.

In the following, we shall thus further elaborate on the denition of the FWER

and establish how the distribution of the maximum statistic can be utilized for its control. Furthermore, we formally develop the notions of minimal and maximal power and their relation to
maximum and minimum statistics, respectively.
Maximum statistic-based FWER control. As introduced above, the FWER of a multiple

test is dened as the probability of one or more Type I errors.

(φi (Y ))i∈I denote a multiple test with with hypotheses index set I
I0 ⊆ I, I0 6= ∅. Then the FWER is dened as the probability
αFWE := P∩

(i)
i∈I0 Θ0

More formally, let

Φ(Y ) =

and null hypotheses index set

(∪i∈I0 φi (Y ) = 1) .

(S2.27)

This expression is to be understood as follows: clearly, the FWER refers to the probability of

φi (Y ) = 1 under the probabilistic
true, i.e., I0 6= ∅. More specically,

events

model for the case that at least one null hypothesis

holds

the intersection subscript

(i)

∩i∈I0 Θ0

qualies that the

parameter of the probabilistic model is such, that all null hypotheses with indices in the set

I0 ⊆ I, I0 6= ∅

hold. Complementary, the union statement

8

∪i∈I0 φi (Y ) = 1

implies that the event

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

φi1 (Y ) = 1 and/or the event φi2 (Y ) = 1, ..., and/or the event φim0 (Y ) = 1 with ij ∈ I0 for
j = 1, 2, ..., m0 occurs, i.e., that at least one, but possible more, events φi (Y ) = 1 with i ∈ I0
occurs. This is equivalent to the probability of the event M01 ≥ 0 as considered above. In
analogy to the signicance level in the single test scenario, a multiple test Φ(Y ) is then said to
0
0
be of family-wise signicance level αFWE , if its FWER is equal to or smaller than αFWE , i.e., if
0
αFWE ≤ αFWE
.

(S2.28)

0
control the FWER at level αFWE
. If for a test Φ(Y ) it holds
0
that αFWE = FWE , we say that Φ(Y ) oers exact control of the FWER at level αFWE . A general

Equivalently, such a test is said to

α0

method to establish FWER control for a multiple test of the form (S2.23) - (S2.26) at a level

αF0 W E

is aorded by consideration of the distribution of the

maximum test statistic

0
γmax
(Y ) := max γi (Y ).

(S2.29)

i∈I0

The method rests on identifying a common critical value

uFWE
∈ R for all constituent tests φi (Y )
α0

of the form (S2.24) that satises

P∩

(i)
i∈I0 Θ0

0
0
(γmax
(Y ) ≥ uFWE
α0 ) ≤ αFWE .

(S2.30)

Intuitively, requirement (S2.30) states that the probability of the maximum of the multiple test's
over
uFWE
α0
0
level αFWE .

test statistics to assume a value larger than or equal to the critical value

the set of

true null hypotheses is smaller or equal to the the desired FWER control

As shown

below, from requirement (S2.30) it readily follows that

P∩

(i)
i∈I0 Θ0

0
(∪i∈I0 φi (Y ) = 1) ≤ αFWE
,

i.e., that the multiple test controls the FWER at level

0
.
αFWE

(S2.31)

From an applied perspective, the

maximum statistic-based FWER control approach entails that the distribution of the maximum
statistic over the set of true null hypotheses needs to be evaluated based on the form of the
probabilistic model and the resulting distributions of the component test statistics
Proof of eq.

γi (Y ).

(S2.31)

for all i ∈ I0 . Further,
Let Φ(Y ) denote a multiple test of the form eqs. (S2.23) - (S2.26), and dene ui := uFWE
α0
0
let the critical value uFWE
be
such
that
with
the
denition
of
the
maximum
statistic
γ
0
max (Y ) in eq. (S2.29) it
α
holds that


0
0
P∩
γmax
(Y ) ≥ uFWE
≤ αFWE
.
(S2.32)
(i)
α0
i∈I Θ
0

0

Then, with the denition of the FWER in eq. (S2.27), it follows that
P∩

(i)
i∈I0 Θ0

(∪i∈I0 φi (Y ) = 1) = 1 − P∩

(∩i∈I0 φi (Y ) = 0)


= 1 − P∩
γi1 (Y ) < uFWE
, γi2 (Y ) < uFWE
, ..., γim0 (Y ) < uFWE
(i)
α0
α0
α0
i∈I0 Θ0


0
= 1 − P∩
γmax
(Y ) < uFWE
(i)
α0
Θ
i∈I0 0


0
FWE
0
γ
(Y
)
≥
u
= P∩
(i)
max
α
Θ
i∈I0

(i)
i∈I0 Θ0

(S2.33)

0

0
≤ αFWE
,

where on the right-hand side of the second equation ij ∈ I0 for j = 1, 2, ..., m0 . In verbose form: the probability
of the event that one or more of the component tests φi (Y ), i ∈ I0 of the multiple test Φ(Y ) evaluate to 1 over
the set of true null hypotheses I0 is equal to the complementary probability of the event that all component tests
evaluate to 0 over the set of true null hypotheses I0 . Given the form of the multiple test Φ(Y ), this probability
in turn corresponds to the probability that all relevant component test statistics assume values smaller than the
9

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

0
. The latter event is identical to the event that the maximum statistic γmax
(Y ) over the set of
critical value uFWE
α0
true null hypotheses is smaller than uFWE
.
The
complementary
probability
of
this
event
then
implies
the validity
0
α
of eq. (S2.31).


A note on the usage of the terms uncorrected single test and corrected multiple testing inference in the main text may be appropriate here: de-facto, FWER control in multiple testing is not
based on some form of correction procedure that turns an uncorrected

p -value,

but the two

p -values

p -value

into a corrected

of uncorrected and corrected inference instead refer to dierent

statistics. Because the notion of correcting for the multiple testing problem using corrected

p -values

is deeply engrained in the fMRI literature, however, we refrain from abandoning this

terminology.
Maximum statistic-based minimal power evaluation. Minimal power can be conceived

of as the mirror analogue of the FWER. As dened above, minimal power is the probability for
one or more correct rejections of the null hypothesis. In analogy to the FWER, minimal power

Φ(Y ) = (φi (Y ))i∈I with
I1 ⊆ I, I1 6= ∅ is formally given as

of a multiple test
index set

hypotheses index set

βmin := P∩

(i)
i∈I1 Θ1

I

and alternative hypotheses

(∪i∈I1 φi (Y ) = 1) .

As for the formal expression of the FWER, the intersection statement

(S2.34)

(i)

∩i∈I1 Θ1

qualies that the

parameter of the probabilistic model is such that all alternative hypotheses with indices in the
set

I1 ⊆ I, I1 6= ∅

and/or the event

∪i∈I1 implies that the event φi1 (Y ) = 1
φim1 (Y ) = 1 with ij ∈ I1 for j = 1, 2, ..., m1
events φi (Y ) = 1 with i ∈ I1 occurs. This

hold true, while the union statement

φi2 (Y ) = 1,

..., and/or the event

occurs, i.e., that at least one, but possible more,
is equivalent to the event

M11 ≥ 1

as considered above.

Minimal power can be evaluated in

a straight-forward fashion for multiple testing procedures that employ a common critical value
and for which the distribution of the maximum statistic is known. Specically, as shown below,
given a test of the form (S2.23) - (S2.26), the denition of the maximum statistic

1
γmax
(Y ) := max γi (Y )

(S2.35)

i∈I1

and a critical value

u ∈ R,

it holds that

βmin = P∩

(i)

i∈I1 Θ1

In the applied context of the current study, eq.


1
γmax
(Y ) ≥ u .

(S2.36)

(S2.36) implies that minimal power can be

evaluated by considering the appropriate maximum statistic distributions of the random-eld
theory-based fMRI inference framework.
Proof of eq.

(S2.36)

1
Let Φ be a multiple test of the form eqs.(S2.23) - (S2.26), let γmax
(Y ) denote the maximum statistic as dened in
eq. (S2.35), and let u ∈ R denote an arbitrary critical value. Then eq. (S2.36) follows in analogy to the derivation
of eq. (S2.31) as follows:

P∩

(i)
i∈I1 Θ1


1
γmax
(Y ) ≥ u = 1 − P∩

(i)
i∈I1 Θ1

= 1 − P∩

(i)
i∈I1 Θ1

= 1 − P∩

(i)
i∈I1 Θ1

= P∩

(i)
i∈I1 Θ1

1
γmax
(Y ) < u



γi1 (Y ) < u, γi2 (Y ) < u, ..., γim1 (Y ) < u
(∩i∈I1 φi (Y ) = 0)

(∪i∈I1 φi (Y ) = 1)

= βmin ,
10



(S2.37)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

where on the right-hand side of the second equation ij ∈ I1 for j = 1, 2, ..., m1 .

Minimum statistic-based maximal power evaluation. In analogy to the formal denition

of minimal power in eq. (S2.34), maximal power can be dened as

βmax := P∩

(i)
i∈I1 Θ1

(∩i∈I1 φi (Y ) = 1) .

(S2.38)

In analogy to the formal FWER and minimal power denitions, the intersection subscript

(i)

∩i∈I1 Θ1

qualies that the parameter of the probabilistic model is such, that all alterantive hy-

I1 ⊆ I, I1 6= ∅ hold, while the intersection statement ∩i∈I1 φi (Y ) =
φi1 (Y ) = 1 and the event φi2 (Y ) = 1, ..., and the event φim1 (Y ) = 1
with ij ∈ I1 for j = 1, 2, ..., m1 occur, i.e., that all events φi (Y ) = 1 with i ∈ I1 occur. This is
equivalent to the probability of the event M11 = m1 as considered above. Moreover, as shown
potheses with indices in the set

1

implies that the events

below, given a test of the form (S2.23) - (S2.26), the denition of the

minimum test statistic

1
γmin
(Y ) := min γi (Y ),

(S2.39)

i∈I1

and a critical value

u ∈ R,

it holds that

βmax = P∩

(i)
i∈I1 Θ1


1
γmin
(Y ) ≥ u .

(S2.40)

In the context of the current study, eq. (S2.40) implies that the evaluation of maximal power
necessitates the availability of the minimum statistics distributions of the random-eld theorybased fMRI inference framework under the appropriate alternative hypotheses scenarios.
Proof of eq.

(S2.40)

1
Let Φ(Y ) denote a multiple test of the form eqs.(S2.23) - (S2.26), let γmin
(Y ) denote the minimum statistic as
dened in eq. (S2.39), and let u ∈ R denote an arbitrary critical value. Then eq. (S2.40) follows in analogy to
the derivation of eq. (S2.36) as follows:

βmax = P∩

(i)
i∈I1 Θ1

(∩i∈I1 φi (Y ) = 1)

= P∩

(i)
i∈I1 Θ1

= P∩

(i)
i∈I1 Θ1

γi1 (Y ) ≥ u, γi2 (Y ) ≥ u, ..., γim1 (Y ) ≥ u

1
γmin
≥u ,



(S2.41)

where on the right-hand side of the second equation ij ∈ I1 for j = 1, 2, ..., m1 .

Power functions. Based on the denitions of the partial alternative hypothesis ratio in eq.

(S2.21), the denitions of minimal and maximal power in eqs. (S2.34) and (S2.38), respectively,
and in analogy to the power function of the single test scenario (S2.15), we dene the following

minimal

and

maximal power functions

of a given multiple test

Φ(Y )

with hypothesis index set

I, I0 ⊂ I, I0 6= ∅:
λ
λ
βmin
: ∩i∈I1 Θ1 → [0, 1], θ 7→ βmin
(θ) := P∩

(i)
i∈I1 Θ1

(∪i∈I1 φi (Y ) = 1)

(S2.42)

and

λ
λ
βmax
: ∩i∈I1 Θ1 → [0, 1], θ 7→ βmax
(θ) := P∩

(i)
i∈I1 Θ1

Note that the assumption
hence

I0 ⊂ I, I0 6= ∅

(∩i∈I1 φi (Y ) = 1) .

implies that neither

λ ∈]0, 1[.
11

I0

nor

I1

(S2.43)

are empty sets and that

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.2.3 Positive predictive value functions
The concept of a positive predictive value (PPV) descends from a framework originally presented
by Wacholder et al. (2004). Specically, it arises in the context of probabilistic models, in which,
in contrast to the classical frequentist test theory discussed thus far, both the test outcomes

and

the hypotheses states are modelled by random variables. In the following, we rst consider the
notion of a PPV in the context of the single test scenario discussed in Section S.2.1 and develop
the notion of a PPV function. In a second step, we then consider the notion of a PPV in the
multiple testing scenario of Section S.2.2 and dene the ensuing minimal and maximal PPV
functions.
The single test scenario. To establish the formal background of the PPV, we consider the

parametric probabilistic model

Pθ (H, φ(Y )),

φ(Y ) models
H = 0 models the case that the null hypothesis is true
and the alternative hypothesis is false, and H = 1 models the case that the null hypothesis is
false and the alternative hypothesis is true (cf. eqs. (S2.1) and (S2.2)). Similarly, φ(Y ) = 0
represents the act of not rejecting the null hypothesis and φ(Y ) = 1 represents the act of
where the random variable

the test state.

H

(S2.44)

models the hypothesis state and the random variable

As in Section S.2.1,

rejecting the null hypothesis (cf. eq. (S2.3)). Note that the distribution of the data is considered
only implicitly in the current probabilistic model, which is justied as we again consider only
deterministic test procedures.
and

φ(Y )

For the development of the PPV, the joint distribution of

is constructed by (1) dening a parameterized marginal distribution for

H

H

and (2)

employing the concepts of a single test's size and power for the denition of the necessary
conditional distributions. Specically, the probability for the alternative hypothesis being true
is parameterized by

π ∈ [0, 1],

inducing the marginal

Pθ (H = 0) := 1 − π,
The required conditional distributions of

φ(Y )

hypothesis prior

distribution

Pθ (H = 1) := π.

(S2.45)

are then constructed by dening

Pθ (φ(Y ) = 1|H = 0) := α,

(S2.46)

Pθ (φ(Y ) = 1|H = 1) := β,

(S2.47)

and

where

α

and

β

refer to the size and the power of the test

φ(Y )

(cf. eqs. (S2.9)) and (S2.12),

respectively. Based on the thus dened joint distribution, the conditional probability of
assume the value

1

given that

φ(Y )

assumes the value

Pθ (H = 1|φ(Y ) = 1) =
Proof of eq.

1

H

to

evaluates to

πβ
.
πβ + α(1 − π)

(S2.48)

(S2.48)

Eq. (S2.48) can be derived by (1) formulating the joint probability distribution Pθ (H, φ(Y )) based on the denition
of the marginal distribution and conditional distributions P (H) and P (φ(Y )|H) in eqs. (S2.45), (S2.46) and
(S2.47), (2) evaluation of the marginal distribution Pθ (φ(Y )), and (3) evaluation of the ensuing conditional
probability (S2.48).
(1) For the joint distribution, we have
P (H = 0, φ(Y ) = 0) = P (H = 0)P (φ(Y ) = 0|H = 0) = (1 − π)(1 − α)
P (H = 0, φ(Y ) = 1) = P (H = 0)P (φ(Y ) = 1|H = 0) = (1 − π)α
P (H = 1, φ(Y ) = 0) = P (H = 1)P (φ(Y ) = 0|H = 1) = π(1 − β)
P (H = 1, φ(Y ) = 1) = P (H = 1)P (φ(Y ) = 1|H = 1) = πβ
12

(S2.49)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

(A) Panel A visualizes the PPV as a function of the hypothesis prior
probability π and the test power β for a xed test size of α = 0.05. At xed prior probability, an increase in
power results in an increase of the PPV. For large prior probabilities, the eect of power on the PPV is negligible,
while for low prior probabilities, the eect of power on the PPV is more pronounced. (B) Panel B visualizes the
PPV for a uniform hypothesis prior probability distribution as a function of test power and test size. Optimal
test properties of α = 0 and β = 1 result in an optimal PPV. For a test size of α = 0, optimal test power of β = 1
yields a PPV corresponding to the hypothesis prior probability π = 0.5. (C) Panel C visualizes the PPV for the
commonly desired power of β = 0.8 as a function of the hypothesis prior probability and the test size. Note that
the hypothesis prior probability dominates both test size and power. For implementational details, please see
rftp_gure_S1.m.

Figure S.1. Positive predictive value.

(2) For the marginal distribution P (φ), we thus have
P (φ(Y ) = 0) = P (H = 1, φ(Y ) = 0) + P (H = 0, φ(Y ) = 0) = π(1 − β) + (1 − π)(1 − α)
P (φ(Y ) = 1) = P (H = 1, φ(Y ) = 1) + P (H = 0, φ(Y ) = 1) = πβ + (1 − π)α

(S2.50)

(3) Finally, for the conditional distribution of the alternative hypothesis being true (H = 1) given a positive test
outcome φ(Y ) = 1, we have
P (H = 1|φ(Y ) = 1) =

P (H = 1, φ(Y ) = 1)
πβ
=
P (φ(Y ) = 1)
πβ + (1 − π)α

which completes the proof.
For the probability
value.

(S2.51)


Pθ (H = 1|φ(Y ) = 1),

Ioannidis (2005) coined the term positive predictive

Intuitively, the PPV is thus the probability of the alternative hypothesis being true,

given a positive test outcome. We visualize the dependency of the PPV on the hypothesis prior
probability

π,

the test power

β,

α in Figure S.1. Fixing one of the three
(α = 0.05, π = 0.5 and β = 0.8) demonstrates

and the test size

parameters of the PPV at a conventional level

that the PPV of a test increases with the hypothesis prior probability and the test power, and
decreases for increases in test size. Note that Ioannidis (2005) and Button et al. (2013) prefer
the formulation of the PPV in terms of the

pre-study odds

ω :=

π
,
1−π

(S2.52)

rather than hypothesis prior probability. In terms of the pre-study odds, the PPV can be reexpressed as

Pθ (H = 1|φ(Y ) = 1) =
Proof of eq.

(S2.53)
13

ωβ
.
ωβ + α

(S2.53)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

With the expression for the conditional probability of H = 1 given φ(Y ) = 1 and the denition of the pre-study
odds of eq. (S2.52), we have
Pθ (H = 1|φ(Y ) = 1) =
=
=
=

πβ
πβ + α(1 − π)
πβ
·
πβ + α(1 − π)

1
1−π
1
1−π

(S2.54)

π
β
1−π
π
β
1−π

1−π
+ α 1−π

ωβ
.
ωβ + α


For a prexed test size, the notions of a single test's power function (cf. eq. (S2.15)) and the
functional form of the PPV (cf. eq. (S2.48)) induce the

function)

positive predictive value function (PPV

ψ : Θ × [0, 1] → [0, 1], (θ, π) 7→ ψ(θ, π) :=
where

β(θ)

denotes the value of the test power function for

function depend on the prexed test size
of the single test power function

β,

α,

πβ(θ)
,
πβ(θ) + α(1 − π)
θ.

(S2.55)

Note that the values of the PPV

the parameters of the probabilistic model by means

and the hypothesis prior probability

π.

The multiple testing scenario. To generalize the notion of a PPV function to the multiple

testing scenario, we dene the

minimal and maximal positive predictive value functions

λ
λ
ψmin
: Θ × [0, 1] → [0, 1], (θ, π) 7→ ψmin
(θ, π) :=

λ (θ)
πβmin
λ (θ) + α(1 − π)
πβmin

(S2.56)

λ
λ
ψmax
: Θ × [0, 1] → [0, 1], (θ, π) 7→ ψmax
(θ, π) :=

λ (θ)
πβmax
,
λ (θ) + α(1 − π)
πβmax

(S2.57)

and

respectively, where

βmin

and

βmax

denote the minimal and maximal power functions as dened

in (S2.42) and (S2.43). Note that in this scenario, the marginal hypothesis parameter

π

repre-

sents the prior probability of the partial alternative hypothesis scenario with partial alternative
hypothesis parameter

λ ∈]0, 1[.

S.2.4 Examples
To illustrate the theoretical concepts of Section S.2.1 to Section S.2.3 and as a conceptual reference point for the random eld theory-based fMRI inference scenarios discussed in the main
text, we next discuss two examples. The rst example concerns a single test scenario, the second
example concerns the extension of the rst example to the multiple testing scenario.

In both

scenarios, we make repeated use of the probability density function of the Gaussian distribution,
which we abbreviate by

−n
2

N (x; µ, Σ) := (2π)
for expectation parameter

µ ∈ Rn

− 21

|Σ|



1
T −1
exp − (x − µ) Σ (x − µ)
2

and positive-denite covariance matrix parameter

14

(S2.58)

Σ ∈ Rn×n .

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

A single-observation z-test
Pθ (Y ) that governs
µ ∈ R and σ 2 > 0, the

Probabilistic model. As a rst example, we consider a probabilistic model

Y

the distribution of a data random variable

taking values in

R.

For

model is assumed to be dened in terms of the probability density function

pθ (y) := N (y; µ, σ 2 ).
Intuitively, a single data point

Y =y

(S2.59)

is thus assumed to have been sampled from a univariate

Gaussian distribution of unknown expectation and known variance. For this model, we assume
that the parameter space of interest is of the form

Θ := R≥0 .

Test hypotheses, statistic, and definition. A single test scenario is then induced by

dening the null and alternative hypotheses

µ ∈ Θ0 := {0}

and

µ ∈ Θ1 := R>0 .

(S2.60)

Furthermore, a test of the form (S2.8) can be constructed by dening the identity test statistic

Z(Y = ·) : R → R, y 7→ Z(Y = y) := y

(S2.61)

φ(Y = ·) : R → {0, 1}, y 7→ φ(Y = y) := 1{Z(Y =y)≥u} .

(S2.62)

and the test

In words, the null hypothesis
given critical value

u ∈ R,

µ ∈ Θ0

is rejected, if the data realization is equal to or exceeds a

otherwise it is not rejected.

Distributions of the test statistic. As discussed in Section S.2.1, to aord Type I error

rate control and to evaluate the power of a thus controlled test, the distributions of the test
statistic under the null and alternative hypotheses are central. The former distribution allows for
identifying a critical value such that the size of the test maximally assumes a certain probability.
The latter distribution allows for evaluating the probability of rejecting the null hypothesis under
the scenario of the alternative hypothesis being true. In the current test scenario, the distribution

θ ∈ Θ0 , and hence also the probabilities for the
Z(Y ) ∈ [u, ∞[ and φ(Y ) = 1, can be readily inferred: because the test statistic
identity mapping, its distribution for µ ∈ Θ0 is given by the probability density

of the test statistic under the null hypothesis
equivalent events
conforms to the
function

pΘ0 (z) = N (z; 0, σ 2 ).
Likewise, the test statistic distribution for

φ(Y ) = 1

θ ∈ Θ1

(S2.63)

and its associated events

Z(Y ) ∈ [u, ∞[

and

is given by the probability density function

pΘ1 (z) = N (z; µ, σ 2 )

with

µ ∈ R>0 .

(S2.64)

Type I error rate control. Given the form (S2.62) of the current test,

an exact test of signicance level

α0

by choosing a critical value

Z
PΘ0 (φ(Y ) = 1) = PΘ0 (Z(Y ) ≥ uα0 ) = 1 −

uα0

uα0

φ(Y ) can be rendered

such that


N x; 0, σ 2 dx = α0 .

(S2.65)

−∞

Note that the required integral corresponds to the cumulative density function of the univariate
Gaussian distribution, for which well-known and widely implemented approximations exist. A
numerical approach for the evaluation of

uα0

based on the probability

discussed in Section S.6.

15

PΘ0 (Z(Y ) ≥ uα0 )

is

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Power and positive predictive value function. Given a critical value

uα0

and the dis-

tribution of the test statistics under the alternative hypothesis scenario as specied by (S2.64),
the probability of the event

φ(Y ) = 1

evaluates to

Z
PΘ1 (φ(Y ) = 1) = PΘ1 (Z(Y ) ≥ uα0 ) = 1 −

uα0


N x; µ, σ 2 dx

for

µ ∈ R>0 .

(S2.66)

−∞

The power function of the test thus takes the form

uα0

Z


N x; µ, σ 2 dx.

β : R>0 → [0, 1], µ 7→ β(µ) := 1 −

(S2.67)

−∞
In applied settings, the parameterization of power functions in terms of the eect size measure

Cohen's d is often preferred.
µ∈R

For a univariate Gaussian distribution with expectation parameter

and variance parameter

σ 2 > 0,

Cohen's

d

d :=

is dened as

µ
.
σ

(S2.68)

For the power function (S2.67), re-parameterization in terms of

Z

uα0

β : R>0 → [0, 1], d 7→ β(d) := 1 −

d

results in


N x; σd, σ 2 dx.

(S2.69)

−∞
Finally, based on the form (S2.69) of the single-observation z-test power function and with the
introduction of a prior hypothesis parameter

π,

the PPV function (cf. eq. (S2.55)) takes the

form

ψ : [0, 1] × R>0 → [0, 1], (π, d) 7→ ψ(π, d) :=

πβ(d)
.
πβ(d) + α0 (1 − π)

(S2.70)

We visualize the single-observation z-test in Figure S.2. Figure S.2A visualizes the exceedance

Pθ (Z ≥ z) as a function of the statistic value z on the x-axis and the eect size d on
y -axis. In addition, the panel indicates the critical value uα0 = 1.645 for a signicance level
0
of α = 0.05 by a red line. The exceedance probabilities for z = uα0 as a function of the eect size
d correspond to power function β , which is visualized in Figure S.2B. Finally, the PPV function
ψ is visualized in Figure S.2C.
probability

the

Multiple single-observation z-tests
Probabilistic model. We next consider the single-observation z-test in a multiple testing sce-

nario. To this end, we assume a parametric probabilistic model
of a random vector

(Y1 , ..., Ym )T . Each component of

Y =

Y

Pθ (Y ) governing the distribution

is conceived as a univariate Gaus-

sian random variable and the components are assumed to be distributed independently and with
identical known variance
on values

y∈

σ 2 > 0.

A probability density function for the distribution of

pθ (y) = N (y; µ, σ 2 Im ),
where

µ ∈ Rm

and

Im

denotes the

covariance matrix parameter

Θ := Rm
≥0

taking

m×m

identity matrix.

(S2.71)

σ 2 Im .

Y
parameter µ

In other words,

according to a multivariate Gaussian distribution with expectation
by

Y

Rm is thus given by

is distributed
and spherical

The parameter space of the model is assumed to be given

and concerns the expectation parameter

16

µ.

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Figure S.2. Exceedance probybility, power, and PPV functions for the single-observation z-test in

(A) The panel depicts the exceedance probability Pθ (Z ≥ z) as a function of the
statistic value z and the eect size d. The red line indicates the critical value uα0 = 1.645 for a signicance level of
α0 = 0.05. (B) The power function of the single observation z-test. The values of the power function correspond
to the the values of the EPFs for the critical value uα0 as depicted in Panel A. Note that for d = 0, the value of
the power function corresponds to the size of the test. (C) The PPV function of the single-observation z-test.
Note that for a hypothesis prior of π = 0, the PPV of the test does not exceed 0.5, while for a hypothesis prior of
π = 1 the PPV of the test, is equal to one, regardless of the eect size. For implementational details, please see
rftp_gure_S2.m.
the single test scenario.

Test hypotheses, statistics, and definition. For an index set

value

θ ∈ R>0

(i)

(i)
µ ∈ Θ0 := {x ∈ Rm
=0
≥0 |xi = 0} ⇔ H
and

(i)

(i)
µ ∈ Θ1 := {x ∈ Rm
=1
≥0 |xi = θ} ⇔ H
where

xi

denotes the

ith

component of

that the ith component of
in

R≥0 ,

I := {1, 2, ..., m}

and a

we consider the family of hypotheses

µ

x ∈ Rm , i = 1, ..., m.

for

i ∈ I,

(S2.72)

for

i ∈ I,

(S2.73)

The

ith

null hypothesis thus states

is zero and the remaining components of

µ

take on arbitrary values

while the ith alternative hypothesis states that the ith component of

and the remaining components of

µ

take on arbitrary values in

R≥0 .

µ

is equal to

θ>0

A multiple test of the form

(S2.23) - (S2.26) can then be constructed by dening the test statistics

Zi (Y = ·) : Rm → R, y 7→ Zi (Y = y) := yi

for

i∈I

(S2.74)

and dening the test

Φ(Y = ·) : Rm → {0, 1}m , y 7→ Φ(Y = y) := 1{Zi (Y =y)≥ui }
The

ith

test statistic thus corresponds to the projection of

Y


i=1,...,m

onto its

i

.

(S2.75)

coordinate. Note that

for the current scenario the dimension of the data outcome space and the number of tested
hypotheses are identical, but this does not necessarily have to be case.
Distributions of the maximum statistic. We next assume that we aim for the maximum

statistic-based control of the FWER of the multiple test dened in eq. (S2.75). As discussed in
Section S.2.2, this entails the evaluation of distribution the maximum statistic

0
Zmax
(Y ) := max Zi (Y ).
i∈I0

17

(S2.76)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

For the current example this distribution can be expressed in terms of the EPF

P∩
Proof of eq.

(i)
i∈I0 Θ0

0
Zmax
(Y

Z



m0

z
2

)≥z =1−

N (x; 0, σ ) dx

.

(S2.77)

−∞

(S2.77)

We have
P∩

(i)
i∈I0 Θ0


0
Zmax
(Y ) ≥ z = 1 − P∩

Zmax (Y )0 < z

(i)
i∈I0 Θ0

= 1 − P∩

Zi1 (Y ) < z, Zi2 (Y ) < z, ..., Zim0 (Y ) < z

(i)
i∈I0 Θ0

=1−

m0
Y

P

j=1

Z

Zij (Y ) < z

(ij )

Θ1

z

N (x; 0, σ 2 ) dx

=1−




(S2.78)



m0
,

−∞

where ij ∈ I0 for j = 1, 2, ..., m0 . The factorization of the joint distribution of the relevant test statistics implied
by the third equation follows from the assumption of a spherical covariance matrix for the probabilistic model,
which for the multivariate Gaussian distribution implies the independence of its component random variables.
The fourth equation follows with the well-known form of the marginal distributions of the multivariate Gaussian
distribution.

Furthermore, we aim for the evaluation of minimal and maximal power functions and their
associated PPV functions.

As discussed in Section S.2.2, this entails the evaluation of the

distributions of

1
Zmax
(Y ) := max Zi (Y )

(S2.79)

1
Zmin
(Y ) := min Zi (Y )

(S2.80)

i∈I1

and

i∈I1

As shown below, these distributions can be expressed in terms of the EPFs

Z

P∩

1
Zmax
(Y

)≥z =1−

P∩

1
Zmin
(Y


Z
)≥z = 1−

(i)
i∈I1 Θ1



m1
N (x; θ, σ ) dx

z

2

with

θ ∈ R>0

(S2.81)

with

θ ∈ R>0 ,

(S2.82)

−∞

and

(i)
i∈I1 Θ1

m1

z
2



N (x; θ, σ ) dx

−∞

respectively.
Proof of eqs.

(S2.81)

and

(S2.82)

The EPF (S2.81) follows as in the proof of (S2.77) by substitution of I1 , Θ(i)
and m1 for I0 , Θ(i)
and m0 ,
1
0
respectively. Similarly, the EPF (S2.82) follows from
P∩

(i)
i∈I1 Θ1


1
Zmin
(Y ) ≥ z = P∩
=

(i)
i∈I1 Θ1

m1
Y
j=1

P


=

(ij )

Θ1

Z

Zi1 (Y ) ≥ z, Zi2 (Y ) ≥ z, ..., Zim1 (Y ) ≥ z
Zij (Y ) ≥ z



z

N (x; θ, σ 2 ) dx

1−



(S2.83)
m1
,

−∞

where ij ∈ I1 for j = 1, 2, ..., m1 .

18

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

6
5

0.8

1

6

1

0.8

5

0.8

4

4

0.6

0.6

3
0.4

0.4

1

0

0.5

1

0.2

0.2

2

4

6

0

8

2

4

5

6

0.8

0.8

4
0.6

0.6

3

0.2

1
0

0

6

0

0

0.5

1

6

1

5

0.8

4
0.6

3
0.4

0.4

1

0

0.5

0.2

0.2

1

0.4

2

2

0
-2

0.4

2

2

0
-2

0.6

3

0
0

2

4

6

8

0

2

4

6

0.2

1

0

0

0.5

1

Figure S.3. Exceedance probability, power, and PPV functions for the single observation z-test in

the multiple testing scenario. (A) Maximum and minimum statistic EPFs for the multiple single-observation
multiple z-test scenario with m := 100 hypotheses and variance parameter σ 2 := 1. Note that when compared to
for a family-wise signicance level of αFWE = 0.050 as indicated
the single test scenario, the critical value uFWE
α0
by the red lines assumes a value approximately twice as large. (B) Minimum and maximal power as functions
of the partial alternative hypothesis parameter λ and the eect size parameter d. Note that to achieve similar
levels, maximal power requires much larger eect sizes than minimal power. (C) Minimal and maximal PPVs
as functions of the prior partial alternative hypothesis parameter and the eect size parameter d for a partial
alternative hypothesis parameter of λ = 0.1. As in the single test scenario, extreme prior alternative hypothesis
parameters render the PPV less dependent on the eect size than medium sized prior alternative hypothesis
parameters. For implementational details, please see rftp_gure_S3.m.

Type I error rate control. As discussed in Section S.2.2, exact FWER control at signi-

cance level

0
αFWE

is aorded by identifying a common critical value

P∩

(i)
i∈I0 Θ0

0
Zmax

uFWE
α0

such that


0
≥ uFWE
= αFWE
.
α0

Given the form (S2.77) of the exceedance probability, the value of

(S2.84)

uFWE
α0

can be evaluated using

the numerical approach discussed in Section S.6.
Power and positive predictive value functions. With the maximum statistic and min-

imum statistic dependencies of minimal and maximal power of eqs.

(S2.36) and (S2.40), the

parametric forms of the respective EPFs of eqs. (S2.81) and (S2.82), and the FWER controlling
critical value (S2.84) it follows that the minimal and maximal power functions for the current
example take the forms

λ
λ
βmin
: R>0 → [0, 1], θ 7→ βmin
(θ) := 1 −

Z

Z
1−

uFWE
α0

−∞
19

!m1
N (x; θ, σ 2 ) dx

(S2.85)

−∞

and

λ
λ
βmax
: R>0 → [0, 1], θ 7→ βmax
(θ) :=

uFWE
α0

!m1
N (x; θ, σ 2 ) dx

.

(S2.86)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

d results in the equivalent

As for the single test scenario, reparameterization in terms of Cohen's
expressions

λ
βmin

: R>0 → [0, 1], d 7→

λ
βmin
(d)

Z
:= 1 −

: R>0 → [0, 1], d 7→

λ
βmax
(d)

!m1
2

N (x; σd, σ ) dx

(S2.87)

−∞

and

λ
βmax

uFWE
α0

Z
1−

:=

uFWE
α0

!m1
2

N (x; σd, σ ) dx

.

(S2.88)

−∞

Finally, the introduction of a partial alternative hypothesis prior

π

induces the minimal and

maximal PPV functions

λ
ψmin
: [0, 1] × R>0 → [0, 1], (π, d) 7→ ψmin (n, d) :=

λ (d)
πβmin
0
+ αFWE
(1 − π)

(S2.89)

λ (d)
πβmin

and

λ
ψmax
: [0, 1] × R>0 → [0, 1], (π, d) 7→ ψmin (n, d) :=

λ (d)
πβmax
.
λ (d) + α0
πβmax
FWE (1 − π)

(S2.90)

We visualize the multiple testing scenario of the single-observation z-test in Figure S.3 for
the case of

m := 100

simultaneously tested hypotheses.

Figure S.3A visualize the exceedance probabilities
in comparison with the

Z

The upper and lower subpanels of

Pθ (Zmax ≥ z)

and

Pθ (Zmin ≥ z).

Note that

statistic of the single test scenario in Figure S.2A, the maximum

z , i.e., the maximum statistic
Zmax has a higher probability to exceed a given z value than the Z statistic, and decays faster.
Similarly, the minimum statistic exceedance probability mass is shifted to lower values of z , with
statistic exceedance probabilities are shifted to larger values of

the same decay as the maximum statistic. In addition, the subpanels of Figure S.3A indicate
the critical value

uFWE
= 3.28
α0

for a signicance level of

α0FWE = 0.05

by a red line. Note that

in comparison to the single test scenario, this critical value is approximately twice as large.
The upper and lower panels of Figure S.3B visualize the ensuing minimal and maximal power

λ , respectively, as a function of the eect size d and the partial alternative
βmax
hypothesis parameter λ ∈]0, 1[. Note that for both power types, a high level of λ implies a small
FWE
value of m0 , which in turn results in a lower critical value uα0 , which for constant signicance
functions

λ
βmin

and

level and eect size, implies a higher value of the respective power function.

This eect is

particularly prominent in the case of maximal power, which for comparable power levels requires
much higher eect size values when compared to minimal power, and exhibits a symmetry about
a partial alternative hypothesis parameter of

λ = 0.5.

Finally, the upper and lower subpanels

of Figure S.3C visualize the minimal and maximal PPV functions

λ
ψmin

and

λ
ψmax

for

λ = 0.1,

respectively. Like for the single test scenario, the introduction of a partial alternative hypothesis
scenario prior probability results in a modulation of the respective power functions, which for
prior parameter values towards the boundaries

π =0

and

π =1

of the prior parameter space

render the PPV function less dependent on eect sizes than in the center of the prior parameter
space around

π = 0.5.

20

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.3. Minimum statistics EPFs
Minimum voxel height statistic EPF
The approximation of the EPF of the minimum voxel height statistic is based on the assumption
that for suciently high degrees of freedom the parametric expression of the expected Euler
characteristic of a non-central

T -eld

(cf. Hayasaka et al. (2007, eq. (4)), Worsley et al. (1996,

eq. (3.1))) can serve both as an approximation for the probability of the maximum voxel height
statistic to exceed a value

t > 0,

as well as as an approximation for the probability of the

minimum voxel height statistic to fall below

P (Tmax ≥ t) ≈

3
X

−t,

i.e.,

Rd (S)ρd (t; δ, ν) ≈ P (Tmin < −t)

for

t > 0.

(S3.1)

d=0
We then have for

t>0

P (Tmin < −t) ≈

3
X

Rd (S)ρd (t; δ, ν) ⇔ P (Tmin < t) ≈

d=0
With the transformation

3
X

Rd (S)ρd (−t; −δ, ν).

(S3.2)

d=0

x ≈ 1−exp(−x) for small x ∈ R that is used in the SPM implementation

of RFT-based fMRI inference (cf. Friston et al. (1996, eq. (5)), Hayasaka et al. (2007, eq. (4)),
Ostwald et al. (2018, eq. (110))), we then have

P (Tmin < t) ≈ 1 − exp −

3
X

!
Rd (S)ρd (−t; −δ, ν)

(S3.3)

d=0
and hence

P (Tmin ≥ t) ≈ exp −

3
X

!
Rd (S)ρd (−t; −δ, ν) .

(S3.4)

d=0

Minimum cluster extent statistic EPF
The approximation of the EPF of the minimum cluster extent statistic can be derived in analogy
to the approximation of the EPF of the maximum cluster extent statistic (cf.
(1994), Ostwald et al. (2018, Section 3.2)).
maxima within an excursion set at level

u

E(Mu ) ≈

Mu
T -eld,

To this end, let

of a non-central

3
X

Friston et al.

denote the number of local
and let

Rd (S)ρd (u; δ, ν)

(S3.5)

d=0
denote the expected Euler characteristic approximation of the number of local maxima within an
excursion set at level

u

that also serves as the approximation to the expected number of clusters

within an excursion set at level

u

C<k,u denote a
level u that have

under RFT-based fMRI inference. Further, let

random variable that models the number of clusters within an excursion set at
an extent smaller than some constant

k.

As for its complement

C≥k,u ,

which forms the basis for

the approximation of the EPF of the maximum cluster extent statistic, we assume that


C<k,u ∼ Poiss λC<k,u ,

(S3.6)

λC<k,u := E(Mu )P (Kj < k) = E(Mu )(1 − P (Kj ≥ k)).

(S3.7)

where

21

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

That is, like the random variable

C≥k,u ,

the random variable

C<k,u

is assumed to be distributed

according to a Poisson distribution, the expectation parameter of which is given by the product

C≥k,u , the probability of a cluster volume
to take on a value smaller than some constant k . Next, let Kj , j = 1, ..., c denote the volumes of
clusters j = 1, ..., c within an excursion set at level u, and let Kmin denote the minimum cluster
extent statistic dened in eq. (7). Then, with the denition of the random variable C<k,u , we
have for k ∈ R
P (Kmin ≥ k) = P (C<k,u = 0) .
(S3.8)

of the expected number of clusters and, in contrast to

In words, the probability that the minimum of the cluster extent statistics

Kj

within an excursion

u is larger than or equal to k is identical to the probability that the number of clusters
k is zero. With the Poisson form of
distribution of C<k,u , it then follows that

set at level

within the excursion set that have a volume smaller than
the

P (Kmin ≥ k) =

λ0C<k,u
0!


exp −λC<k,u = exp (−E(Mu )(1 − P (Kj ≥ k))) .

(S3.9)

and with (S3.5), we obtain

P (Kmin ≥ k) = exp −

3
X

!
Rd (S)ρd (u; δ, ν)(1 − P (Kj ≥ k)) .

d=0

22

(S3.10)

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.4. EPFs visualizations
In this Section, we visualize EPFs of the six test statistics of eqs.

(4) - (7) that underlie

RFT-based fMRI inference and the power, PPV, and sample size calculations reported in the
current work. These visualizations allow for readily relating the respective power functions to the
distributional properties of the test statistics and in this way make the power functions discussed
and documented in the main text accessible.

Single test scenario statistics
As discussed in Methods, the single test statistics of interest in RFT-based fMRI inference are
the voxel height statistics

Tv

(cf. eq. (4)) and the cluster extent statistics

Kj

(cf. eq. (5)) with

EPFs provided in eqs. (15) and (16), respectively. In Figure S.4A we visualize the test-relevant

Tv .

properties of the EPF of

t

α0

Specically, the upper panel of Figure S.4A depicts the critical value

for exact tests with signicance level

by eq.

α0 = 0.05

(15) and evaluated using Algorithm 1.

as a function of the sample size

n

implied

With increasing sample size, the critical value

T -distribution
EPF of Tv as a

decreases, reecting the lighter tail of the probability density function of Student's
for high degrees of freedom. In the lower panel of Figure S.4A, we visualize the
function of eect size

d

and sample sizes

reects a variation of the eect size
top of the stack.

d

n = 10, 15, ..., 40. Here, each
0.2 at the bottom of

between

sample size-specic stack
the stack and

0.8

at the

Naturally, as the eect size increases, more probability mass is allocated to

larger values of the test statistic outcome value

t.

In addition, the lower panel of Figure S.4A

indicates the critical values for an exact test with signicance level

α0 = 0.05

at a given sample

size by a red vertical bar. The value of the EPF at the location of this critical value for a given
combination of sample and eect size corresponds to the power of the uncorrected voxel-level
test as visualized in Figure 1A of the main text.
Similarly, the test-relevant aspects of the EPF of

Kj

are visualized in Figure S.4B for a cluster-

u = 4.3. As for the voxel height statistic, the upper panel of Figure S.4B
kα0 measured in number of voxels for exact tests with signicance level
function of the sample size n implied by eq.(16) and evaluated using Algorithm

dening threshold of

depicts the critical value

α0 = 0.05

as a

1. As sample size increases, the critical cluster extent value decreases as expected. In the lower
panel of Figure S.4B, we visualize the EPF of

n = 10, 15, ..., 40.

Kj

as a function of eect size

d

and sample sizes

As in the lower panel of Figure S.4A, each sample size-specic stack reects

a variation of the eect size

d

0.2
α0 = 0.05

between

exact test with signicance level

(bottom) to

0.8

(top) and the critical values for an

at a given sample size are indicated by red vertical

bars. Like for voxel height statistic, the value of the EPF at the location of the critical values
corresponds to the power of the uncorrected cluster-level test as visualized in Figure 1B of the
main text.

Multiple testing statistics
As discussed in Methods, the multiple testing statistics of interest are the maximum and minimum voxel height statistics

Tmax

and

Tmin

(cf. eq. (6)) with EPFs provided in eqs. (17) and

(16), respectively, as well as the maximum and minimum cluster extent statistics

Kmin

and

Kmax

(cf. eq. (7)), with EPFs provided in eqs. (19) and (20), respectively. As in the main text, we
visualize test-relevant aspects of the EPFs in Figure S.5 based on the resel volumes

R0 (S) = 6,

R1 (S) = 33, R2 (S) = 354, and R3 (S) = 705, and, for the minimum and maximum cluster extent
u = 4.3.
FWE
The left upper panel of Figure S.5A depicts the critical values tα0
that aord FWER control
0
at a signicance level of αFWE = 0.05 as a function of sample size n and the partial alternative
hypothesis parameter λ ∈ [0, 1] for d = 0 and evaluated using Algorithm 1. For λ = 0 the scenario

statistics, a cluster-dening threshold of

23

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

1.86

0.1

0.1

41

1.84
1.82

0.075

40

0.075

1.8
39

1.78
0.05

0.05
1.76

38

1.74
0.025

0.025

1.72

37

1.7
0
10

40
35
30

15

20

25

30

35

0
10

1.68
40

1

15
10
-1

20

25

30

36
40

35

40
35

0.8

30

0.6

25
20

15

25
0.4

20

0.2

15
10

0

0

1

2

3

4

5

6

0

10

20

30

40

50

60

70

80

Figure S.4. Critical values and exceedance probabilities for the single test voxel- and cluster-level statistics Tv
and Kj . The upper subpanels of panels (A) and (B) visualize the critical values tα0 and kα0 for exact single
tests of signicance level α0 = 0.05 as a function of sample size as red lines. These critical values were evaluated
using Algorithm 1. The exceedance probabilities corresponding to these critical values are depicted as blue line
and remain constant, as desired. The lower subpanels of panels (A) and (B) visualize the EPFs of eqs. (15)
and (16) as a function of sample size and eect size d. Specically, for each sample size-specic EPF stack, the
eect size d varies between 0.2 at the bottom of the stack and 0.8 at the top of the stack. Additionally, the
gure depicts the sample size-specic critical values for exact tests with signicance level α0 = 0.05 as red vertical
bars. The exceedance probabilities at the location of the red bars in the respective statistics outcome space
corresponds to the eect and sample size-dependent power values visualized in Figure 1. Note that as discussed
in the main text, neither EPF depends on resel volumes of the search space. For implementational details, please
see rftp_gure_S4.m.

corresponds to the complete null hypothesis, and the critical values increase with decreasing
sample size.
large.

Compared to the single test scenario, the critical values are ve to ten times as

Increasing

λ

and thus reducing the multiplicity of the multiple testing problem results

in a decrease of the critical values, which accelerates as

λ

approaches

1.

In the right upper

panel of Figure S.5A, we visualize the associated exceedance probabilities that remain constant
around 0.05.

Kj ,

Tmax . As for Tv and
n = 10, 15, ..., 40 and within each
(top). For all stacks, λ is set to 1,

The medium panel of Figure S.5A visualizes the EPF of

the EPFs are visualized as sample size-specic stacks for

stack, the eect size

d

varies from 0.2 (bottom) to 0.8

corresponding to the complete alternative hypothesis scenario. The red vertical bars reect the
sample size-specic critical values, and the values of the respective EPFs at the location of the
vertical bars correspond to the minimal power values at the voxel level for
sample size-specic EPFs of

Tmin

λ = 1.

Finally, the

are visualized in the lowermost panel of Figure S.5A. Note

that with respect to both the voxel height statistic (cf. Figure S.4A) and the maximum voxel
height statistic (cf.

Figure S.5A), considerably less probability mass is allocated to positive

values of the statistic outcome value, reecting the lower probability that the minimum of the
voxel height statistics exceeds a given outcome value. As for

Tmax ,

the red vertical bars indicate

the FWER-controlling critical values, and the value that the minimum statistic EPF assumes at

24

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

Figure S.5.
Critical values and EPFs for the multiple testing voxel- and cluster-level statistics. The left
for FWER-controlled voxel- and
and kαFWE
uppermost panels of (A) and (B) visualize the critical values tFWE
0
α0
0
cluster-level tests of signicance level αFWE = 0.05 as a function of sample size n and partial alternative hypothesis
parameter λ ∈ [0, 1], respectively. Their associated exceedance probabilities are visualized in the right upper panels
of (A) and (B). The central panels visualize the EPFs of eqs. (17) and (19) as functions of sample size n and eect
size d. Specically, for each sample size-specic exceedance probability stack, the eect size d varies between 0.2
at the bottom of the stack and 0.8 at the top of the stack. In addition, each panel depicts the sample size-specic
0
= 0.05 as red vertical bars. The color scale depicted for
critical values for exact tests with signicance level αFWE
P (Tmax ≥ t) applies to all four lower subpanels of the gure. The lowermost subpanels of (A) and (B) visualize
the EPFs of eqs. (18) and (20) as functions of sample size n and eect size d as for their maximum counterparts.
For implementational details, please see rftp_gure_S5.m.

the location of these bars corresponds to the sample size- and eect size-specic minimal power
of the FWER-controlled voxel-level test in the complete alternative hypothesis scenario.

The

identical way of portrayal is used in Figure S.5B for the test-relevant aspects of the EPFs of

Kmin

and

Kmax .

Note that in comparison to the single test scenario, the critical values

depicted in the upper left panel of Figure S.5B are up to three times as large.

25

kαFWE
0

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.5. Exemplary data set
The exemplary fMRI data set is part of a perceptual decision making simultaneous EEG/fMRI
data set that has been previously documented and made generally accessible in the standardized
BIDS format (Ostwald et al., 2012; Georgie et al., 2018). In the following, we briey sketch the
experimental procedures and fMRI data analyses that form the basis for the statistical parametric
map depicted in Figure 4.

Experimental procedure
Participants performed a visual perceptual decision task in a 2

×

2 factorial within-participant

design with experimental factors stimulus coherence (with levels low and high) and spatial
prioritization (with level yes and no).

On each trial, a visual stimulus depicting either

a face or a car was presented in one visual hemield.

Individual stimuli were presented for

200 ms and the participant was asked to indicate via a button press whether the stimulus
depicted a face or a car. For the button presses, participants used their right index and middle
nger for the two stimulus categories, and the mapping from stimulus category to response
button was counterbalanced across participants. The informativeness of the visual stimulus was
manipulated by altering the phase coherence of its spatial frequency spectrum resulting in low
and high stimulus coherence trials. On half of the trials, a cueing arrow shown continuously for
1 s prior to the stimulus indicated in which visual hemield the stimulus would be presented.
Participants were asked to allocate their spatial attention to the respective visual hemield,
while maintaining steady central xation (spatial prioritization condition).

On the other half

of the trials, the two-headed cuing arrow was uninformative and the stimulus was presented
randomly in either visual hemield (no spatial prioritization condition).

Face and car stimuli

were equally distributed across the four experimental conditions. The stimulus presentation order
was randomized. Participants were asked to respond as quickly and as accurately as possible with
an emphasis on responding as quickly as possible and to maintain stable xation on the central
xation cross throughout the experiment.

For fMRI data acquisition, data from 90 trials for

each of the four conditions (half of them face stimuli) were recorded with an inter-trial interval
discretely randomized between 10 and 12 s.

The 90 trials per condition were split into ve

experimental runs, each lasting approximately 14 minutes.

fMRI data acquisition and analysis
fMRI data was acquired simultaneously with EEG at the Birmingham University Imaging Centre using a 3T Philips Achieva MRI scanner. T2*-weighted functional data were collected with
an eight-channel phased-array SENSE head coil. EPI data (gradient echo-pulse sequence) were
acquired from 32 slices (3x3x4 mm resolution, TR 2,000 ms, TE 35 ms, SENSE factor 2, ip
angle 80

deg).

Slices were oriented parallel to the AC-PC axis of the participant's brain and

positioned to cover the entire brain space. A mass-univariate summary-statistics GLM analysis
was performed to assess condition-induced eects at the group-level. SPM12 (V6906) was used
for both fMRI data preprocessing and statistical modelling. Prior to GLM parameter estimation
at the participant-level, fMRI data were motion-corrected by realigning EPI volumes to the rst
volume of the rst run of a given participant, normalized to MNI spaced using the SPM MNI-EPI
template, re-interpolated to 2 mm isotropic voxel size, and smoothed using an 8 mm isotropic
Gaussian kernel. The rst-level GLM design matrix for each participant was then specied in
run-wise, block-diagonal form. Here, each block comprised the four condition-specic stimulus
onset functions, convolved with the canonical haemodynamic response function, in the columnwise order: high stimulus coherence/spatial prioritization, high stimulus coherence/no spatial
prioritization, low stimulus coherence/spatial prioritization, low stimulus coherence/no spatial

26

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

prioritization.

Per SPM defaults, the design matrices additionally comprised a constant run

oset and a cosine basis function set implementing a temporal high-pass lter with a cut-o of
frequency 1/128 Hz. High-frequency residual error correlations were accounted for by SPM's default of approximating a rst-order autoregressive process with white noise using parameterized
covariance basis functions. GLM beta and covariance component parameters were then estimated
using SPM's restricted maximum likelihood estimation scheme. Finally, ten participant-specic
COPE images were evaluated for the high stimulus coherence > low stimulus coherence contrast weight vector

(1, 1, −1, −1)

replicated over sessions and padded with zeros for regressors

of no interest. The resulting COPE images are available from the `Contrast Images' folder of
the accompanying OSF project.
using voxel-wise one-sample

Finally, the COPE images were evaluated at the group-level

T -tests,

implemented in rftp_gure_4.m, the resulting statistical

parametric map of which is available from the `One Sample T Test' folder in the accompanying
OSF project.

27

bioRxiv preprint doi: https://doi.org/10.1101/613331; this version posted June 1, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

S.6. Algorithms
Critical value algorithm for a desired signicance level
γ(Y ) and desired signicance level α0 , we use Algorithm 1 to numerically
evaluate the required critical value cα0 for a test that controls the Type I error rate at signicance
0
level α .

For a given test statistic

Algorithm 1 Critical value evaluation for a desired signicance level
Signicance level α0 , step size δ
Output: Critical value cα0
1: Initialization: cα0 := 0, p := PΘ0 (γ(Y ) > cα0 )
2: while p > α0 do
3: cα0 := cα0 + δ
4: p := PΘ0 (γ(Y ) > cα0 )
5: end while
Input:

Algorithm A1 is implemented in the function u_fun.m.

Necessary sample size algorithm for a desired power level
γ(Y ),

For a given test statistic

desired signicance level

α0 ,

eect size

a multiple testing scenario, partial alternative hypothesis parameter

λ,

d

and, in the case of

we use Algorithm 2 to

numerically evaluate the required minimal sample size to achieve a desired power level

β.

Algorithm 2 Necessary sample size evaluation for a desired power level
Signicance level α0 , step size δ , eect size d, partial alternative hypothesis parameter λ, desired power β
Output: minimum required sample size n
1: Initialization: n := 2, cα0 evaluation for n, λ, δ , PΘ1 (γ(Y ) > cα0 ) evaluation for λ, d, and n
2: while PΘ1 (γ(Y ) > cα0 ) ≤ β do
3: n := n + 1
4: cα0 evaluation for n, λ, PΘ1 (γ(Y ) > cα0 ) evaluation for λ, d, and n
5: end while
Input:

Algorithm A2 is implemented in the function n_fun.m.

Necessary sample size algorithm for a desired PPV level
For a given test statistic
eter

λ,

π

γ(Y ), desired signicance level α0 , eect size d, prior hypothesis param-

and, in the case of a multiple testing scenario, partial alternative hypothesis parameter

we use Algorithm 3 to numerically evaluate the required minimal sample size to achieve a

desired PPV level

ψ.

Algorithm 3 Necessary sample size evaluation for a desired PPV level
Signicance level α0 , step size δ , eect size d, partial alternative hypothesis parameter λ, hypothesis prior
parameter π, desired PPV ψ
Output: minimum required sample size n
π P
(γ(Y )>cα0 )
1
evaluation for π, λ, d, and n
1: Initialization: n := 2, cα0 evaluation for n, λ, δ , π1−πPΘ Θ(γ(Y
)>cα0 )+α0
Input:

2:
3:
4:
5:

while

π P
(γ(Y )>cα0 )
1−π Θ1
π P
(γ(Y )>cα0 )+α0
1−π Θ1

n := n + 1
cα0 evaluation for n, λ,

1−π

≤ψ

1

do

π P
(γ(Y )>cα0 )
1−π Θ1
π P
(γ(Y )>cα0 )+α0
1−π Θ1

evaluation for π, λ, d, and n

end while

Algorithm A3 is implemented in the function n_fun.m.

28

