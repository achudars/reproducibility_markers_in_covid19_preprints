Velocity coupling of grid cell modules:
stable embedding of a low dimensional
variable in a high dimensional neural
attractor
Noga Mosheiff1 and Yoram Burak1,2*
1

Racah Institute of Physics, Hebrew University of Jerusalem, Israel; 2 Edmond and Lily
Safra Center for Brain Sciences, Hebrew University of Jerusalem, Israel

Abstract Grid cells in the medial entorhinal cortex (mEC) encode position using a distributed
representation across multiple neural populations (modules), each possessing a distinct spatial
scale. The modular structure of the representation confers the grid cell neural code with large
capacity. Yet, the modularity poses signiÔ¨Åcant challenges for the neural circuitry that maintains
the representation, and updates it based on self motion. Small incompatible drifts in different
modules, driven by noise, can rapidly lead to large, abrupt shifts in the represented position,
resulting in catastrophic readout errors. Here we propose a theoretical model of coupled
modules. The coupling suppresses incompatible drifts, allowing for a stable embedding of a
two dimensional variable (position) in a higher dimensional neural attractor, while preserving
the large capacity. We propose that coupling of this type may be implemented by recurrent
synaptic connectivity within the mEC with a relatively simple and biologically plausible
structure.

Introduction
Much of the research on neural coding in the brain is focused on sensory representations, which
are driven by external inputs that can be precisely controlled experimentally. In comparison,
less is known about neural coding in deep brain structures, in which the dynamics reÔ¨Çect the
outcome of internal computations. A notable exception is the hippocampal formation, where
neural activity has been linked to high level cognitive variables such as an animal‚Äôs estimate of
its position within its environment (O‚ÄôKeefe and Nadel, 1978; Moser et al., 2008; Taube et al.,
1990), or its estimate of elapsed time within a trial of a trained behavioral task (Manns et al.,
2007; Eichenbaum, 2014).
SpeciÔ¨Åcally, the representation of position by grid cells (Hafting et al., 2005) in the medial
entorhinal cortex (mEC) has led to new, unexpected insights on the neural coding of such

1 of 37

quantities: even though position is a low dimensional variable, it is jointly encoded by several distinct populations of cells (modules - Stensola et al. (2012)), exhibiting periodic spatial
responses with varying spatial scales. The spatial responses of all grid cells within a module
are characterized by the same grid spacing and orientation, while differing from each other
only by a rigid translation. The representation of position by each module is ambiguous about
position, but taken together, the joint activity in several modules constitutes a highly eÔ¨Écient
and unambiguous neural code (see Burak (2014)). Due to its distributed organization, the grid
cell code possesses a high dynamic range, greatly exceeding the performance of unimodal
coding schemes such as the representation of position by place cells in the hippocampus (Fiete
et al., 2008; Sreenivasan and Fiete, 2011; Mathis et al., 2012; Wei et al., 2015; Mosheiff et al.,
2017).
Alongside the potential beneÔ¨Åts arising from the combinatorial nature of the grid cell code,
the distributed representation of position over several modules and spatial scales poses a
mechanistic challenge to the underlying neural circuitry. The diÔ¨Éculty lies in the hypothesized
role of the hippocampal formation, and speciÔ¨Åcally the mEC, in maintenance of memory
and spatial computation, as opposed to pure representation. When grid cells update their
activity, e.g., based on self motion, they must do so in a coordinated manner, in order for
them to coherently represent a position in two dimensional space ‚Äì a variable of much lower
dimensionality than the joint activity of all cells.
Neurons within a module maintain strict relationships in their joint activity (Yoon et al.,
2013). These relationships are maintained across environments (Fyhn et al., 2007); under
abrupt distortions of the environment; in novel environments, in which stable place Ô¨Åelds are
absent; under genetic perturbations that disrupt the spatial periodicity in the response of
individual cells (Allen et al., 2014); and in sleep (Trettel et al., 2019; Gardner et al., 2019). The
rigidity of the correlation structure strongly suggests that the neural activity within a module
is tightly coordinated by recurrent connectivity, consistent with attractor models of grid cell
activity (McNaughton et al., 2006; Fuhs and Touretzky, 2006; Guanella et al., 2007; Burak and
Fiete, 2009), which propose that synaptic connectivity restricts the joint activity within a module
to lie on a two dimensional manifold. Additional support for attractor models has been recently
obtained by imaging activity of multiple grid cells using calcium imaging in rats running on
a virtual one dimensional track (Heys et al., 2014; Gu et al., 2018). These studies revealed
a relationship between position on the cortical sheet and the preferred Ô¨Åring locations of
grid cells, as predicted by the variants of attractor models that rely on distance dependent
connectivity.
In contrast to the strong correlation in the activity of neurons within a module, much less is
known about coupling of neurons that belong to different modules. A network of grid cells
organized in ùëö modules, each independently structured as a two dimensional continuous
attractor, possesses a 2ùëö dimensional space of accessible steady states. Yet at any given
time, continuous motion of the animal corresponds to a two dimensional subspace of the
possible local changes in the state of the ùëö modules. Considering that noise may corrupt
the representation of position in each module separately, the maintenance of a coherent

2 of 37

representation of position across modules necessitates some form of coupling between them
(Welinder et al., 2008; Sreenivasan and Fiete, 2011; Burak, 2014). Fig. 1A demonstrates the
need for this coupling: incoherent drifts in the positions represented by different modules,
accrued due to noise, can rapidly produce a joint representation of position that is incompatible
with any position in the close vicinity of the animal. The desired coupling across modules is
more subtle than the one observed within a module: the coupling should restrict changes in
the states of different modules to lie within the two-dimensional sub-space that corresponds
to smooth movement of the animal within its local environment. However, to preserve the
high dynamic range of the code, the coupling should not restrict the dimensionality of the
accessible steady states.
To further illustrate this point, it is instructive to consider an analogy of grid cell coding to
the representation of a one dimensional position by the rotation angles ùúÉ1,2 of two meshing
gears (Fig. 1B). We imagine that motion along the one dimensional axis corresponds to
coordinated rotation of the two gears (Fig. 1B, bottom). If the radii ùëÖ1,2 of the two gears are
incommensurate, a large distance is traversed before the two meshing gears come close to
a previously visited state, thus allowing for a large range of positions to be unambiguously
represented. However, it is crucial in this scheme that during continuous motion, the gears
rotate in a coordinated manner: ùúÉÃá 1 ùëÖ1 = ùúÉÃá 2 ùëÖ2 . This relationship between the phase velocities
ùúÉÃá 1 and ùúÉÃá 2 is enforced by the meshing cogs along the circumference of the two gears. In the
absence of this mechanical constraint, small movement of one gear relative to the other can
abruptly transport the represented position to a distant location, unrelated to the original
position. Note that the absolute angles of the two meshing gears are not constrained: in fact,
the large capacity of the representation relies on the fact that any combination of the two
angles is accessible.
Motivated by this analogy, we ask whether synaptic connectivity between grid cell modules
can enforce a similar dynamic relationship between their states. Below, we identify a simple
form of synaptic connectivity between grid cells that can implement this desired form of
coupling. Next, we show that the recurrent connectivity confers the joint representation of
position with resilience to two types of noise: First, noise in the velocity inputs projecting to
different modules. These may differ in different modules, for example, due to synaptic noise.
Second, noise arising from the stochastic dynamics of spiking neural activity within each module.
The outcome is a continuous-attractor representation of position that achieves two goals: First,
the representation is distributed across several modules with different spatial scales, allowing
for combinatorial capacity by preserving the high dimensionality of the accessible steady
states. Second, the neural circuitry that supports this representation is highly robust to noise
when updating the representation based on self-motion, or while maintaining a persistent
representation in short-term memory.
Alongside the recurrent connectivity, it is plausible that feedforward synaptic projections
from the hippocampus to the entorhinal cortex play a role in shaping the grid cell response
(Kropff and Treves, 2008; Dordek et al., 2016; D‚ÄôAlbis and Kempter, 2017; Weber and Sprekeler,
2018). Thus, hippocampal inputs may aid in coupling the states of different grid cell modules

3 of 37

Figure 1. A. Illustration of the detrimental consequences arising from uncoupled module drifts. Black
dot: location of a static animal. Top panels: schematic representation of the decoded position from the
neural activity in module 1 (left panel) and module 2 (middle panel) at time ùë° = ùë°0 . The shaded areas
(cyan, purple) represent locations whose likelihood, given the neural activity, is high. Top right panel:
overlay of the likelihood read out from module 1 and module 2. The maximal likelihood location, based
on activity in both modules, coincides with the animal‚Äôs position. Bottom panels: decoded position
based on the neural activity at time ùë°1 . Due to independent, noise driven drifts in each module, activity
in module 1 represents positions that are slightly shifted to the left (bottom left), and activity in module
2 represents position that are slightly shifted upward (middle). Even though the shifts are small, the
joint activity in both modules (bottom right) now represents a new maximum likelihood location
(yellow), far away from the true location (black). We refer to such events as catastrophic readout errors.
B. Representation of position along a one dimensional axis (black line) by the rotation angles ùúÉ1,2 of two
meshing gears that rotate in a coordinated manner in response to motion. The angles ùúÉ1 and ùúÉ2 ,
corresponding to each position, are shown along the blue and red lines. If the radii ùëÖ1,2 are
incommensurate, a large range of positions can be unambiguously read out from the combination of
the two angles.

(Welinder et al., 2008; Sreenivasan and Fiete, 2011). In addition, sensory inputs that carry
information about the animal‚Äôs absolute position may contribute as well, through synaptic
projections to the mEC from other cortical areas. However, there are situations in which
these types of inputs to the mEC cannot ensure appropriate coordination between grid cells
modules. First, under conditions in which sensory inputs are absent or weak, the brain must
rely on idiothetic path integration in order to update its estimate of position. Second, in novel
environments, and following global remapping in the hippocampus (Muller and Kubie, 1987),
it is highly unlikely that speciÔ¨Åc connections between place cells and grid cells, that couple
the two spatial representations, are immediately established. Hence, coupling modules via
hippocampal inputs would be ineffective in a novel environment. Thus, in this study we focus
on the ability of recurrent connectivity within the entorhinal cortex to maintain a coherent
representation of position across grid-cell modules.

4 of 37

Results
Theoretical framework
In laying out the principles underlying our proposed synaptic connectivity, we consider Ô¨Årst a
one dimensional analogue of the grid cell representation, inspired by the analogy to meshing
gears discussed above: we imagine that an animal moves in one dimension, and neurons in
each grid cell module ùëñ jointly represent the modulus of position relative to the grid spacing ùúÜùëñ
(for simplicity, from here on, we deÔ¨Åne the phases ùúÉùëñ such that they are in the range [0, 1]):
ùúÉùëñ =

ùë• mod ùúÜùëñ
.
ùúÜùëñ

(1)

We hypothesize that the joint dynamics of all grid cells within a module are restricted to lie
in a one dimensional attractor, which we model as a ring attractor (Ben-Yishai et al., 1995;
Zhang, 1996). More speciÔ¨Åcally, we consider the double-ring architecture (Xie et al., 2002),
which includes a mechanism for updates based on velocity inputs, and was proposed as a
model for integration of angular velocity inputs by head direction cells in rodents. Recent
discoveries in the drosophila melanogaster central complex point to a representation of heading
that is maintained by neural circuitry with close similarity to the this architecture (Seelig and
Jayaraman, 2015; Turner-Evans et al., 2017; Kim et al., 2017; Green et al., 2017). Attractor
models of grid cells in the entorhinal cortex (Fuhs and Touretzky, 2006; Burak and Fiete, 2009)
generalize the double-ring attractor model to motion in two dimensions.
Within the double-ring attractor model (Xie et al., 2002), a module consists of two recurrently connected neural sub-populations, each comprising ùëÅ neurons organized on a ring (left
ring and right ring, Fig. 2A). We denote by
( )
ùë†‚ÉóùëÖ
ùë†‚Éó =
(2)
ùë†‚Éóùêø
the vector of synaptic activations, where ùë†‚ÉóùëÖ and ùë†‚Éóùêø represent the synaptic activation of the
right and left sub-populations respectively. The synaptic activation ùë†ùëñ of neuron ùëñ follows the
dynamics:
( 2ùëÅ
)
‚àë
ùë†ùëñ
ùë†Ãá ùëñ + = ùëüùëñ = ùúô
ùëäùëñùëó ùë†ùëó + ùêº0 ¬± ùëëùêº ,
(3)
ùúè
ùëó=1
where ùúè is the synaptic time constant, ùëüùëñ is the Ô¨Åring rate of neuron ùëñ, ùúô is a nonlinear transfer
function, ùëä is the connectivity matrix (Eqs. 8-9), ùêº0 is a constant input, and +ùëëùêº (‚àíùëëùêº) is the
velocity input to a neuron in the right (left) sub-population. Synaptic weights projecting from
neurons in each ring are shifted clockwise (right) or anti-clockwise (left). When both subpopulations receive identical feed-forward inputs, activity in the network settles on a stationary
bump of activity. However, selective activation of the right (left) sub-population via the feedforward inputs, induces clockwise (anti-clockwise) motion of the activity bump at a phase
velocity proportional to the velocity input ùëëùêº. Hence, in a noise-free network, the position of
the activity bump is an integral of the velocity input.

5 of 37

Figure 2. A. Structure of a single module, consisting of a left ring (red) and a right ring (blue), in
accordance with the double ring model (Xie et al., 2002). The two rings receive external inputs
proportional to velocity, with opposite polarities (purple). Synaptic weights project slightly
anti-clockwise (red) and slightly clockwise (blue) from neurons in the left and right sub-populations. B.
True phase ùúÉ as a function of time (black) in response to an external velocity input, representing a
simulated trajectory, and an estimation of this phase from the velocity approximation ùúî1 (magenta).
Note that ùúÉ is periodic with period 1, but for presentation clarity we unwrap ùúÉ to depict a continuous
path along the real axis. C. The coupling of drifts in two modules is achieved by providing the velocity
approximation ùúî1 as a velocity input to module 2 (and vice versa, not shown). Each module is modelled
as a double ring attractor, as in (A). D. Two coupled modules. The velocity input of each module has
three contributions: The external velocity input (purple), the coupling of velocity from the other module
(green), and the self coupling (orange).

Our goal is to couple several such modules such that they will update their states in a
coordinated manner in the presence of noisy inputs. It is essential to couple the modules
based on their drift velocities and not by their absolute phases, as we want to enable all phase
combinations of the different modules to be possible steady states of the population neural
dynamics. Our proposed coupling requires two ingredients: reading out the phase velocity of
each module, and inducing corresponding phase velocities in the other modules. The double
ring model already contains a mechanism for integration of velocity inputs, and therefore our
main challenge is in reading out the phases velocities.

Simple neural readout of velocity
Our Ô¨Årst goal is to read out the phase velocity of a single module in our system. It is possible
to compute the drift velocity by projecting Eq. 3 on the eigenvector with zero eigenvalue of
the dynamics (see Appendix 1 and Burak and Fiete (2012)). However, this projection cannot
be evaluated linearly from the neural activity, since the projection coeÔ¨Écients depend on the
location of the activity bump. Instead, we seek a simple estimate of the drift velocity, that can
be implemented in a neural circuit with relatively simple architecture in a biologically plausible

6 of 37

manner.
Intuitively, in the described framework, most of the motion arises from the differences in
activity between the right and left sub-populations. Therefore, this difference might be close to
Ãá We Ô¨Ånd, indeed, that the difference between the synaptic activities of the
the drift velocity ùúÉ.
right and left sub-populations,
(
)
‚àë
ùõΩ ‚àë
ùë† ‚àí
ùë†
(4)
ùúî‚â°
ùúè ùëñ‚ààùëÖ ùëñ ùëñ‚ààùêø ùëñ
provides a good approximation for the phase velocity (Fig. 2B), where ùõΩ is a proportionality
Ãá
factor. In Appendix 1 we show mathematically that ùúî ‚âà ùúÉ.

Coupling modules by synaptic connectivity
In order to couple the motion of different modules, we use the readout signal ùúîùëñ of each module
ùëñ (Eq. 4) as a velocity input to all other modules (Fig. 2C-D, green arrows). In addition, we include
negative self coupling within each module using the same readout signal ùúîùëñ (necessary, as
shown below, in order to prevent instabilities that otherwise arise from the positive feedback
generated by the inter-module couplings), Fig. 2D (orange arrows).
Note that ùúîùëñ is a linear function of synaptic activities within the ring network, with coeÔ¨Écients
that do not depend on the position of the activity bump. Thus, the coupling can be implemented
by recurrent connectivity within the mEC, between modules and within a single module.
To understand how the couplings inÔ¨Çuence the joint dynamics of the coupled modules,
we analyze the response of a network, consisting of ùëö coupled modules, to external velocity
‚Éó
inputs, ùëè(ùë°).
The position of the bump in each module can be represented by a phase ùúÉùëñ . We
Ô¨Ånd that the dynamics of these phases are governed by the following set of coupled differential
equations
(
)
Ãá
‚Éó + ùê∂ ùëì ‚àó ùúÉ‚ÉóÃá ,
ùúÉ‚Éó = ùõº ùëè(ùë°)
(5)
where ùê∂ is an ùëö √ó ùëö matrix whose element ùê∂ùëñùëó represents the coupling strength from module ùëó
Ãá
Ãá
to module ùëñ, ùëì ‚àó ùúÉ‚Éó is the convolution of ùúÉ‚Éó with an exponential Ô¨Ålter ùëì with the synaptic time
scale ùúè (Eq. 36), and ùõº is a constant factor (see full derivation of Eq. 5 in Appendix 2). Thus,
the phase of each module is updated in response to two signals: the external velocity input
projecting into the module (Ô¨Årst term in Eq. 5), and the recent history of changes in the phases
of the other modules, conveyed by the coupling signal (second term in Eq. 5).
Much of the system‚Äôs response to external velocity inputs can be understood by considering
its dynamics under the assumption that the motion of the animal is suÔ¨Éciently slow, such
Ãá
that the components of ùúÉ‚Éó vary slowly compared to the synaptic time constant. Under this
assumption, we obtain from Eq. (5)
Ãá
‚Éó ,
ùúÉ‚Éó = ùëã ‚ãÖ ùëè(ùë°)
(6)
where
ùëã ‚â° ùõº(ùêº ‚àí ùê∂)‚àí1

(7)

is the linear response tensor.

7 of 37

For simplicity, let us consider Ô¨Årst only two coupled modules (each of them one dimensional),
with identical self coupling strength ùê∂ùë† for both modules. The eigenvalues of ùëã, denoted by
ùëã+ and ùëã‚àí (Fig. 3A-C and Appendix 2), indicate how strongly the coupled modules respond
to velocity inputs that drive coordinated and relative motion, respectively. If ùëã‚àí is small,
the modules respond weakly to velocity inputs that attempt to update the phases in an
uncoordinated manner. Thus, if ùëã‚àí is much smaller than ùëã+ , we expect the motion of the two
modules to remain coordinated, even if the velocity inputs to the two modules differ.
We choose coupling parameters ùê∂1,2,ùë† such that three requirements are fulÔ¨Ålled (see Appendix 2): First, the modules should respond signiÔ¨Åcantly to inputs that drive coordinated
motion (large ùëã+ , Fig. 3A,C). The response to such inputs should not be suppressed since the
system must be able to update its state based on velocity inputs, to correctly represent the
animal‚Äôs position in its environment. Second, the modules should respond very weakly to
inputs that drive anti-correlated motion (small relative motion ùëã‚àí , Fig. 3B,C). The self negative
coupling ùê∂ùë† enables us to achieve these two requirements while preserving stability (Fig. 3A-C
and Appendices 2- 3). Our last requirement is the maintenance of a speciÔ¨Åc ratio between
the module phase velocities, ùúÜ, that corresponds to the grid spacing ratio between successive
‚àö
modules (we set ùúÜ = 2 for all modules Stensola et al. (2012)).
Fig. 3E-F demonstrates the response of two modules to an external velocity input, representing an animal‚Äôs trajectory (shown in Fig. 3D). The input is given only to module 1. In the the case
of uncoupled modules (ùê∂1,2,ùë† = 0) only module 1 follows the trajectory, as expected (Fig. 3E). In
the case of coupled modules, both of the modules follow the trajectory quite accurately, with
the desired phase velocity ratio ùúÜ. Hence, under these conditions, the two coupled modules
shift in a coordinated manner, even if they receive incompatible velocity inputs. Next, we
generalize these results to multiple modules, and to grid cells in two dimensions.

Generalization to two dimensions and several modules
The coupling of modules, described so far, can be easily extended to grid cell responses in two
dimensions. In accordance with grid cell responses in two dimensional arenas, each module is
structured as a two dimensional attractor, whose state is determined by two periodic phases.
Thus, the steady states of the attractor are arranged on a torus instead of a ring. To obtain this
topology, we use a network architecture in which neurons are arranged on a parallelogram,
corresponding to a unit cell of the hexagonal grid (in similarity to Guanella et al. (2007)). The
synaptic connection between any two neurons depends on their distance on the parallelogram,
deÔ¨Åned using periodic boundary conditions (Fig. 4A and Methods). The position of the activity
bump must be able to shift in response to a two-dimensional velocity input, in any direction in
the plane. To implement this velocity response, each module contains four sub-populations
(right, left, up, and down). The synaptic weights projecting from neurons in each sub-population
are shifted in a corresponding direction within the neural population (Burak and Fiete, 2009).
In addition, we generalize our network to ùëö grid cell modules. The coupling strengths
ùê∂ùëñùëó thus comprise ùëö2 parameters that we are free to adjust to fulÔ¨Åll a set of requirements,
similar to those applied in the case ùëö = 2. Our most important goal is that the motion of

8 of 37

Figure 3. A-B. Velocity response of the coupled system to velocity inputs that drive joint motion ùëã+ (A)
or relative motion ùëã‚àí (B) in two coupled modules, as a function of the coupling strengths. C. ùëã¬± is a
‚àö
function of one parameter that depends on the coupling strengths (ùê∂ùë† ¬± ùê∂1 ùê∂2 ). The magenta and
black circles represent the parameters used in (F), and the corresponding value of ùëã+ and ùëã‚àí . D.
Simulated trajectory, whose derivative is injected as a velocity input only to module 1 in panels (E-F). E.
Response of two uncoupled modules (ùê∂1,2,ùë† = 0): the position represented by module 1 tracks the
velocity inputs, module 2 is unresponsive, and the updates in the two modules are not coordinated, as
expected. F. Same as (E) but the modules are coupled with coupling strengths: ùê∂ùë† = ‚àí20,
ùê∂1 = ‚àíùê∂ùë† ‚àïùúÜ ‚âÉ 14.1, and ùê∂2 = ‚àíùê∂ùë† ‚ãÖ ùúÜ ‚âÉ 28.3. The phases of both modules track the velocity inputs in a
coordinated manner, with the desirable velocity ratio ùúÜ.

9 of 37

all modules should be coordinated, even if the velocity inputs are not identical. To achieve
this goal, we deÔ¨Åne a joint motion vector ùë¢‚Éó, such that ùë¢ùëñ ‚àïùë¢ùëó is the ratio of grid spacings of
modules ùëó and ùëñ. We require that this vector is an eigenvector of the linear response tensor,
and minimize the eigenvalues corresponding to all other eigenvectors. If we were able to obtain
eigenvalues that precisely vanish, the response tensor would be a rank one matrix whose
columns are all proportional to ùë¢‚Éó. Under this idealized outcome, any velocity input, regardless
of its direction in the 2ùëö dimensional input space would result in coordinated motion of the
modules. However, the couplings ùê∂ùëñùëó that precisely achieve this goal diverge, in similarity to the
two-module case (Appendix 2). Thus, we impose a constraint on the strength of the synaptic
connections. Another constraint has to do with the stability of the response to dynamic velocity
inputs. We optimize an appropriate target function under these constraints (Appendix 3).
For ùëö = 2 the optimization results in the same solution of coupling parameters ùê∂ùëñùëó that
we found previously. For ùëö > 2 we Ô¨Ånd that there is considerable freedom in choosing
combinations of ùê∂ùëñùëó that achieve satisfactory coupling (See Appendix 3). One principled way to
reduce this freedom, is to require that there is connectivity only between successive modules.
This choice is compatible with recent observations (Fu et al., 2018) that excitatory synaptic
connectivity within the mEC is relatively short ranged. In our numerical results, we use this
assumption to constrain the structure of the connectivity matrix ùê∂ùëñùëó , but other choices that
include broader connectivity between modules lead to similar coupling between the modules.
To demonstrate how our proposed coupling affects the response of the modules to velocity
inputs, we simulate the described network in two dimensions, with three modules. The
velocity input is a measured rat trajectory from Stensola et al. (2012), with the addition of white
Gaussian noise, drawn independently in the three modules. In a noise-free simulation, the
single cell Ô¨Åring rates form a hexagonal grid pattern as a function of the animal‚Äôs location (Fig.
4B), as expected from the network structure, while the spacing ratio between modules is close
to ùúÜ.
The trajectories of the 2d phases, in response to noisy velocity inputs, are shown, for each
of the three modules, in Fig. 4D (uncoupled modules) and Fig. 4E (coupled modules). In both
cases, the phases follow the animal‚Äôs trajectory (Fig 4C) quite closely, but the phases are much
more similar to each other, and to the original trajectory, in the coupled case. The lack of
deviations between the phase trajectories, seen in the coupled case, is an essential difference
between the dynamics of the coupled and uncoupled modules. As discussed in the Introduction,
we expect this difference to strongly impact the stability of the grid cell code. In the following
section we substantiate this point.

Consequences for spatial representation and readout
We next aim to validate our hypothesis that the coupling of modules stabilizes the grid cell
code, and more speciÔ¨Åcally, prevents catastrophic errors that can be caused by uncoupled drift
in the phases of different modules (Fig. 1A). We simulate the dynamics of our three module
network with noisy velocity inputs based on a measured rat trajectory from Stensola et al.
(2012), as in Fig. 4. We then generate Poisson spikes from the instantaneous Ô¨Åring rates of the

10 of 37

Figure 4. A. The neurons of each sub-population in the two dimensional case (right, left, up and down)
are organized on a neuronal sheet in the shape of a parallelogram with periodic boundary conditions.
B. Simulated Ô¨Åring rate of a single grid cell from each module, as a function of position, evaluated
during response of the network to a rat trajectory lasting 800 s (taken from Stensola et al. (2012)). C.
Measured rat trajectory over an interval of one minute (Stensola et al. (2012)), whose derivative is
injected as a velocity input to all modules in panels (D-E), with addition of uncorrelated noise in each
module. D. Response of three uncoupled modules. E. Response of three coupled modules. The
phases of the three modules approximately track the velocity inputs in both cases, but the coordination
between phases of the three modules is more tight in (E).

11 of 37

neurons, and read out the animal‚Äôs trajectory from the simulated spikes: we do so both for
coupled modules (Fig. 5A) and for uncoupled modules (Fig. 5B). The readout is accomplished
using a decoder that sums spikes from the recent history, with an exponentially decaying
temporal kernel (see Methods and Mosheiff et al. (2017)).
In the case of coupled modules the decoded trajectory is similar to the input (Fig. 5A),
but due to the noise in the inputs, it gradually accrues an error relative to the true trajectory.
Without coupling, the position read out from the network activity diverges sharply from the
true trajectory (Fig. 5B). Moreover, the readout trajectory is often discontinuous in time, and
thus cannot be a good approximation to any reasonable path of the animal. The discontinuity
arises from uncorrelated drifts of the modules which, combined with the periodic nature of the
grid pattern, cause catastrophic readout errors, much larger than the errors accrued in the
phases of each module separately (Fig. 1A).
In order to quantitatively substantiate the relationship between the large deviation of the
decoded trajectory from the true trajectory and the occurrence of catastrophic readout errors,
we repeat the decoding process a hundred times with and without coupling, for a 20 s input
trajectory. In all realizations with coupling, the readout is coordinated with the input trajectory
(Fig. 5C, blue). In contrast, without coupling almost all realizations exhibit discontinuities within
a time interval of 20 s (Fig. 5C, red). The mean square error (MSE) of the decoder increases
as a function of time in the coupled as well as the uncoupled systems (Fig. 5D), as expected
due to noise in the input (as the coupling and inputs are of velocity and not absolute location,
there is no correcting mechanism that can correct coordinated shifts in the phases of all the
modules). However, a few seconds after the start of the simulation, the MSE grows sharply
in the uncoupled system (dashed line in Fig. 5D). The time at which this starts to happen
coincides with the Ô¨Årst appearance of discontinuities in the decoded position (compare Fig.
5 panels C and D). Thus, the dramatic reduction achieved by the coupling between modules
arises primarily from the elimination of catastrophic readout errors.

Intrinsic neural noise
Up to this point we presented a theory of several grid cell modules, coupled to each other by
synaptic connectivity within the mEC, such that the coupling signiÔ¨Åcantly suppresses incompatible drifts caused by noisy inputs to the system. Next, we wish to address another important
source of noise, arising from the variability in the spiking of individual neurons within the
grid cell network (Softky and Koch, 1993; Shadlen and Newsome, 1994; Burak and Fiete, 2009).
In similarity to noise in the inputs, stochasticity of the neurons participating in the attractor
network drives errors that accumulate over time with diffusive dynamics (Burak and Fiete,
2009, 2012). To model this process, we replace the Ô¨Åring rate of each neuron in Eq. 3 by a
Poisson spike train (see Eq. 22).
Since we designed our network to be resilient to noisy inputs, it is not obvious that the same
architecture can also provide resilience to intrinsic noise. To address this question, we revisit
Ô¨Årst the simple case of two coupled modules in one dimension. In Appendix 1 we show that the
simple readout of velocity used to couple the modules (Eq. 4), is a good approximation for the

12 of 37

Figure 5. A. Blue trace: measured rat trajectory over a 20 s interval (taken from Stensola et al. (2012)),
used as a velocity input to three coupled modules. Red trace: readout of position, decoded from
simulated Poisson spikes of the coupled system. The spikes are generated by a Poisson process from
the instantaneous Ô¨Åring rates of all cells in the three modules (see Methods). The decoded position is
continuous and similar to the input trajectory. B. Same as (A), but in a network consisting of three
uncoupled modules: all coupling strengths are set to zero. The decoded position is discontinuous in
time, and often sharply deviates from the input trajectory. C. Percentage of decoding success over time.
We repeated the decoding of the animal‚Äôs trajectory, as in (A-B), over a hundred simulations with
different realizations of the noise. A success at time ùë° is deÔ¨Åned as a trial that did not contain any
discontinuity in the readout up to that time. The success percentage was computed by counting the
number of trials without discontinuities at each time point. The coupled network maintains 100 %
success over time (blue), whereas the success percentage of the uncoupled network decreases
signiÔ¨Åcantly over time: many trials contain discontinuities after a few seconds, and almost all of them
contain discontinuities after 20 s (red). D. Mean square error (MSE) of the decoded trajectory, computed
from the same simulations presented in (C), in the coupled (blue) and uncoupled (red) cases. The
vertical black dashed line in (C-D) represents the Ô¨Årst time in which a discontinuity was observed in any
of the trials of the uncoupled network. From this time point onward, the percentage of success of the
uncoupled network descends, and the MSE sharply increases (note the logarithmic vertical scale).

13 of 37

drift velocity driven by intrinsic neural noise, suggesting that the coupling introduced previously
can help suppress uncoordinated drifts. To quantify the impact of coupling on coordination of
the modules, we compute the diffusion tensor of their phases, using Eq. 25 (the calculation is
based on the theoretical framework laid out in Burak and Fiete (2012), see speciÔ¨Åcally Eq. S24).
In the uncoupled case the diffusion tensor is isotropic as expected (Fig. 6A, blue line). When
the modules are coupled, with the same coupling strengths as in Fig. 3, the diffusion of the two
modules is highly anisotropic (Fig. 6A). The Ô¨Årst principal axis of the diffusion tensor (red ellipse
in Fig. 6A) closely matches the direction of coordinated motion (dashed line in Fig. 6A). The
diffusion coeÔ¨Écient ùê∑‚àí , associated with motion in the orthogonal direction, is much smaller
than the diffusion coeÔ¨Écient ùê∑+ , associated with coordinated motion: ùê∑+ ‚àïùê∑‚àí ‚àº ùëã+ ‚àïùëã‚àí ‚àº 40
(compare Figures 3C and 6A). Thus, the coupling strongly suppresses incompatible diffusion of
the two modules.
Next, we evaluate the consequences for representation and readout, arising from the
suppression of incompatible diffusion arising from intrinsic neural noise. We repeat the
simulation of three coupled modules in two dimensions, this time with stochastic (Poisson)
neurons. Discontinuities in the decoded trajectory occur both in the uncoupled and coupled
networks, but they are much more rare in the coupled network (Fig. 6B). Accordingly, the
readout MSE is reduced dramatically in the coupled network (Fig. 6C, note the logarithmic
scale). Thus, the coupling is effective not only in stabilizing the neural representation in
response to noisy inputs, but also with respect to internal stochasticity within the grid cell
network.
In principle, one could seek coupling parameters such that diffusion would be suppressed
in all directions. However, recall our requirement (1) from section Coupling modules by synaptic
connectivity, that the network must respond with suÔ¨Écient gain to external inputs, to follow an
animal‚Äôs trajectory. As we keep the joint response strong, we cannot reduce the joint diffusion
simultaneously, and we are satisÔ¨Åed with coupling of the diffusive drift, without eliminating
coordinated diffusion.

Discussion
Previous works (Fiete et al., 2008; Mathis et al., 2012; Wei et al., 2015; Mosheiff et al., 2017)
have shown that grid cell activity, viewed as a neural code for position, achieves a high dynamic
range (ratio of capacity and resolution Burak (2014)) due to the splitting of the representation
across multiple modules. In this work we addressed a key diÔ¨Éculty with this idea: the combinatorial nature of the representation, arising from the existence of multiple modules, leads to
high vulnerability to noise. Small uncoordinated errors in the phases of the different modules
can shift the represented position to a far away location. As a possible solution to this diÔ¨Éculty,
we proposed a simple architecture of synaptic connectivity between grid cell modules, that
can suppress incompatible drifts. The functional coupling between modules, arising from our
proposed synaptic connectivity involves velocities, not absolute phases. Consequently, the
coupling does not limit the combinations of possible phases of the different modules, and thus

14 of 37

Figure 6. A. Diffusion tensor of a Poisson spiking neural network, consisting of two modules in one
dimension, computed using Eq. 25, and illustrated as an ellipse. Axes of the ellipse are aligned with the
eigenvectors of the diffusion tensor, and the lengths of each axis represents the diffusion coeÔ¨Écient
along the corresponding direction. Without coupling the diffusion tensor is isotropic (blue circle). When
coupling the modules using the same coupling strengths as in Fig. 3F, the diffusion tensor becomes
highly anisotropic (red ellipse). The diffusion in this case is almost exclusively in the direction of the Ô¨Årst
principal component (major axis of the ellipse). This direction closely matches the direction of
coordinated drift (‚Éóùë¢+ in Eq. 55, dashed line). B.-C. same as Fig. 5C-D, but for the internal noise case.

does not affect the capacity of the code.
Similar principles may apply to storage in working memory and coding of other continuous,
low dimensional variables in the brain. Thus, the main contribution of our work from the
theoretical perspective, is that it identiÔ¨Åes a way to couple several low dimensional continuous
attractors of dimension ùëë (in the case of grid cells, ùëë = 2), to produce a persistent neural
representation of a single, ùëë dimensional variable with high dynamic range. The dynamics of
the network are characterized by two seemingly contradictory features: Ô¨Årst, the steady states
of the system span a space of dimension ùëöùëë, where ùëö is the number of modules. Second,
during maintenance and continuous update of the stored memory, the joint state of the
modules is dynamically restricted to lie in a much smaller, ùëë-dimensional subspace. This
enables the continuous embedding of a ùëë dimensional variable in the larger, ùëöùëë dimensional
space, without allowing for noise to shift the state of the system outside the appropriate, ùëë
dimensional local subspace.
Our proposed mechanism for coupling modules is complementary to another possible
mechanism, of coupling grid cell modules through the reciprocal synaptic connectivity between
the entorhinal cortex and the hippocampus (Welinder et al., 2008; Sreenivasan and Fiete,
2011; Burak, 2014). Since biological systems often harness multiple mechanisms to achieve
the same function, both mechanisms might act in parallel to stabilize the grid cell code against
catastrophic readout errors. As discussed in the introduction, it is highly unlikely that coupling
via the hippocampus could work in a novel environment, following global remapping. On the
other hand, it is of particular importance for the brain to establish a geometric representation
of position, aided by idiothetic path integration, under this scenario. Thus, the velocity coupling
mechanism proposed in this work may play an especially important role in generating a
cognitive map of a novel environment.

15 of 37

A model that involves synaptic coupling between modules, of a different architecture than
the one considered here, has been recently proposed in Kang and Balasubramanian (2018).
This model does not explore the consequences of noise on coding stability, and its primary
goal is to explain the ratios between grid spacings. Hence, Kang and Balasubramanian (2018)
address different questions from those studied in the present work. Nevertheless, it is plausible
that the synaptic connectivity proposed by Kang and Balasubramanian stabilizes the dynamics
against incompatible motion of the modules. An important difference between the network
architecture explored in Kang and Balasubramanian (2018) and the architecture explored here,
is that we consider all to all connectivity between grid cells, which is invariant to any static,
relative shift in the module phases. Hence, all combinations of phases are steady states of
the dynamics. In contrast, the synaptic connectivity considered in Kang and Balasubramanian
(2018) is spatially local. Consequently, it tends to produce interlocked patterns of activity
in adjacent modules, with shared spatial periodicity, and preferred relative spatial phases.
These properties of the activity patterns are expected to limit the representational capacity
of the code. Here we addressed a different computational goal, of stabilizing a distributed
representation of position over multiple modules, without compromising the dynamic range of
the neural coding scheme.
Our focus in this work was on the suppression of relative motion across modules, but noise
in the inputs, or in the intrinsic activity within the network, drives also coordinated motion. It is
possible to suppress the latter type of random motion by increasing the negative feedback in
the system (Fig. 3A,C). In choosing our optimization goal for the coupling parameters, we did
not attempt to suppress coordinated drift for two reasons. First, coordinated drift is much less
detrimental from the coding perspective than relative drifts, as discussed in the introduction.
Second, suppressing the coordinated motion comes with an inevitable cost: a reduction in
the gain of the system‚Äôs velocity response. Nevertheless, it is interesting to consider also the
suppression of coordinated drift. Next, we brieÔ¨Çy discuss the possible implementation of this
goal.
For simplicity, consider a single one dimensional module, structured as a ring attractor:
in this situation, there is only coordinated motion. As in any continuous attractor network,
stochasticity of neural activity within the network introduces random drift (Burak and Fiete,
2012). In the double ring architecture (Xie et al., 2002), much of the drift arises from Ô¨Çuctuations
in the difference of activity between the two sub-populations that drive left and right motion.
Using the negative self-coupling of velocities, introduced in this work, it is possible to suppress
these Ô¨Çuctuations and substantially reduce the noise-driven drift. It is interesting to compare
this mechanism with another proposal (Lim and Goldman, 2014) for stabilization of the memory
stored in a single ring attractor, using negative derivative feedback (Lim and Goldman, 2013).
In Lim and Goldman (2014) the stabilization slows down the dynamics of all neurons in the
network, thereby slowing down the relaxation of any deformation in the shape of the activity
bump ‚Äì not only the position of the activity bump on the ring attractor. In contrast, within the
architecture considered here, the unimodal shape of the activity bump is maintained, while
the velocity feedback mechanism slows down only noise driven diffusion of its position. Thus,

16 of 37

the velocity coupling mechanism identiÔ¨Åed in this work may be relevant to the stabilization of
short-term memory in head directions cells of rodents (Taube, 2007) and insects (Seelig and
Jayaraman, 2015), where there is no evidence for slowly decaying deformations in the shape
of the activity bump.

Experimental predictions
The grid spacing of a single module is determined by the velocity input strength ùõæùúá (Eq. 21):
larger values of ùõæùúá lead to smaller grid spacing. Thus, in an uncoupled network the grid spacing
ratios are determined by the input strengths ùõæùúá . However, in the network of coupled modules
the spacing ratios are determined primarily by the inter-module coupling parameters. Each
velocity input strength ùõæùúá affects all the grid spacings, but has little effect on the spacing ratios.
For example, even if the ùõæùúá s are identical in all modules, or if only one module receives a
velocity input, all modules shift their states with a velocity ratio that matches the desired grid
spacing ratio. An interesting prediction arises under a scenario in which one of the modules is
disconnected from the others. This removes positive couplings from the other modules, but
leaves the negative self coupling within the module intact. Hence, the disconnected module
is expected to weaken its response to velocity inputs, and increase its grid spacing. Similarly,
other grid spacings, of modules that were originally connected to the disconnected module,
are expected to increase as well.
The joint activity of grid cells can be expected to lie within a two dimensional space when
salient sensory cues are available to the animal, regardless of the existence of an inter-module
coupling mechanism. The existence of a coupling mechanism must therefore be tested under
conditions in which external sensory cues are weak (Burak, 2014). It is instructive to compare
this goal with what has been learned about population activity within a single module (Yoon
et al., 2013; Fyhn et al., 2007; Allen et al., 2014; Trettel et al., 2019; Gardner et al., 2019). In
that context, simultaneous recordings from pairs of grid cells were highly informative, since
grid cells from a single module exhibit strong correlations (or anti-correlations) in their joint
spiking activity. The preservation of these correlations, under conditions in which the animal‚Äôs
sense of position is disrupted, supports an interpretation that the correlations are maintained
by recurrent connectivity within each module. In contrast, cells belonging to different modules
are expected to Ô¨Åre together in some positions in space, and refrain from Ô¨Åring together in
other parts of the environment. Averaged over motion in a large environment, cell pairs from
different modules are expected to exhibit weak correlations in their activity, even if the updates
of module phases are fully coordinated.
Analysis of spike correlations in grid cells from different modules (Trettel et al., 2019;
Gardner et al., 2019) conÔ¨Årms this expectation. During free running, spike correlation functions
of grid cells from different modules are much weaker than those observed within a module.
Despite being weak, these correlations can be statistically signiÔ¨Åcant. Their existence originates
from the fact that in any speciÔ¨Åc environment, and especially in small enclosures, the Ô¨Åring
Ô¨Åelds of two grid cells with different spatial scales slightly favor correlated or uncorrelated Ô¨Åring,
depending on the precise overlap between the spatial receptive Ô¨Åelds of the two cells. During

17 of 37

sleep, these weak correlations are signiÔ¨Åcantly reduced (Trettel et al., 2019; Gardner et al.,
2019). A possible interpretation of this result is that there is no coupling between modules
during sleep. However, an alternative explanation is that the reduction in correlations reÔ¨Çects
an increase in the repertoire of positions and environments represented in the sleep state:
regions of joint Ô¨Åring and regions of disjoint Ô¨Åring are expected to average out more evenly
under such circumstances, leading to weaker correlations.
In order to test for the existence of a velocity coupling mechanism, it is desirable to test for
correlations in the updates of phases of different modules, instead of testing for correlations
in their absolute phases. This will require simultaneous recordings from multiple grid cells,
of suÔ¨Écient numbers that will enable reliable tracking of the module phases. Appropriate
recordings are not yet available, but techniques that enable simultaneous monitoring of large
neural populations of the mEC (Jun et al., 2017; Gu et al., 2018; Obenhaus et al., 2018) [CITE:
see comment below] are likely to enable their acquisition in the coming years. In similarity
to the experiments that provided insights on the low dimensionality of activity within each
module, it will be necessary to test for inter-module coupling under conditions in which the
animal‚Äôs internal sense of position is not anchored to salient external cues.
Our model assumes that grid cells in the mEC are involved in idiothetic path integration, and
harnesses ingredients from models of path integration in the grid cell system to generate the
coupling between modules. It is widely hypothesized that grid cells are indeed involved in path
integration (Hafting et al., 2005; McNaughton et al., 2006; Moser et al., 2008; Burak, 2014), but
this involvement is not experimentally established (see, however Gil et al. (2018)). Accordingly,
a speciÔ¨Åc role of any particular cell type within the mEC in idiothetic path integration is not yet
identiÔ¨Åed. A speciÔ¨Åc population of cells that may provide the substrate for the connectivity
proposed in our model are the conjunctive cells observed mostly in layer III and deeper layers
of the mEC (Sargolini et al., 2006), which play a pivotal role in models of path integration in the
grid cell system. We note that these cells are tuned to head direction more closely than heading
(Raudies et al., 2015), a diÔ¨Éculty that faces all models of path integration within the mEC. The
resolution of this diÔ¨Éculty may involve computational elements within the entorhinal circuitry
that have not yet been identiÔ¨Åed. Thus, future experimental Ô¨Åndings concerned with the
mechanisms underlying path integration may call for (and enable) corresponding reÔ¨Ånements
of our model.
Very little is known about synaptic connectivity between grid cells in the mEC, especially for
cells belonging functionally to different modules. An important conclusion of our work is that
synaptic connectivity between different modules may be beneÔ¨Åcial for dynamically stabilizing
the grid cell representation during path integration and memory maintenance. The speciÔ¨Åc
form of connectivity that we identify is appealing for several reasons: Ô¨Årst, it involves broad,
relatively unstructured connectivity between grid cells, that depends only on their preferred
heading preference. A second appealing feature of our proposed architecture is that it is
suÔ¨Écient to couple grid cells from modules with adjacent spacings, to achieve the desired
stabilization of the grid cell representation. Since there is a relationship between grid spacing
and position along the dorsal-ventral axis (Hafting et al., 2005; Stensola et al., 2012), all-to-all

18 of 37

couplings between modules would require long-range connectivity within the mEC. Recent
evidence (Fu et al., 2018) hints that synaptic connections between excitatory cells in the mEC
may be more limited in range, but of suÔ¨Écient spatial extent to allow for coupling of adjacent
modules.

Methods
Model and simulations details
The dynamics of the network are described by Eq. 3 (or by Eq. 22 for the Poisson spiking
neuron case). The synaptic time constant ùúè = 10 ms, the transfer function ùúô(ùë•) = ùúè ‚àí1 max(ùë•, 0),
and ùêº0 = 3. All simulations were done using the Euler method for integration, with a time step
ùëëùë° = 0.1 ms.

One dimensional module
In the one dimensional simulations the synaptic activation vector (Eq. 2) includes synapses
of the right and left sub-populations, each comprising ùëÅ = 1000 neurons. Each neuron has a
preferred phase ùúÉùëñ ‚àà [0, 1], uniformly arranged on a ring. The connectivity matrix ùëä is deÔ¨Åned
by

where

(
)
ùëä+ ùëä‚àí
ùëä =
,
ùëä+ ùëä‚àí

(8)

[
(
)
]
2
(
)
ùëäùëñùëó¬± = ùë§ |ùúÉùëñ ‚àí ùúÉùëó ‚àì ùúë|P , ùë§(ùúÉ) = ùê¥ exp ‚àí ùúÉ 2 ‚àí 1 .
2ùëÅ
2ùúé

(9)

ùëä ¬± is a ùëÅ √ó ùëÅ matrix, ùúë = 0.2, ùê¥ = 200, ùúé 2 = 0.1, and |ùë•1 ‚àí ùë•2 |P is the minimal distance between
two points ùë•1,2 ‚àà [0, 1] with periodic boundary conditions on [0, 1], namely
{
}
|ùë•|P = min |ùë•|mod 1 , 1 ‚àí |ùë•|mod 1 .

(10)

Coupled modules
Consider ùëö coupled modules. The Ô¨Åring rate (Eq. 3) of neuron ùëñ from module ùúá is (Fig. 2D):
ùëüùúá,ùëñ = ùúô

( 2ùëÅ
‚àë
ùëó=1

ùëäùëñùëó ùë†ùúá,ùëó + ùêº0 ¬± ùëèùúá ¬± ùëé

ùëö
‚àë

)
ùê∂ùúáùúå ùúîùúå

,

(11)

ùúå=1

where ùúîùúá is the velocity estimation of module ùúá (Eq. 4) , ùê∂ùúáùúå is the coupling strength from
module ùúå to module ùúá (ùê∂ùúáùúá is the self coupling strength of module ùúá), and the sign ¬± is equal
to + (‚àí) if the neuron ùëñ belongs to a right (left) sub-population. The proportionality factor
[ ‚àë
]‚àí1
‚Ä≤ (ùëîÃÑ )
ùëé = ùõΩ 2ùëÅ
ùúô
is included to simplify the units of the coupling strengths ùê∂ùúáùúå . Note that
ùëñ
ùëñ=1
ùëé ‚ãÖ ùúîùëñ does not depend on the parameter ùõΩ. Thus, the choice of ùõΩ is of no consequence for the
dynamics, and this parameter is included only for the sake of derivation convenience.

19 of 37

The coupling between the modules can be interpreted as arising from synaptic connectivity.
This can be seen by re-writing Eq. 11 as:

ùëüùúá,ùëñ = ùúô

( 2ùëÅ
‚àë

ùëäùëñùëó ùë†ùúá,ùëó + ùëé

ùëó=1

ùëö
‚àë

ùê∂ùúáùúå

ùúå=1

2ùëÅ
‚àë

)
ùëäùëñùëóùëê ùë†ùúá,ùëó

+ ùêº0 ¬± ùëèùúá

,

(12)

ùëó=1

where the 2ùëÅ √ó 2ùëÅ coupling connectivity matrix is:
‚éõ1
‚éú
‚éú‚ãÆ
ùõΩ‚éú1
ùëäùëê = ‚éú
ùúè ‚éú‚àí1
‚éú
‚éú‚ãÆ
‚éú‚àí1
‚éù

1 ‚àí1 ‚ãØ ‚àí1‚éû
‚éü
‚ãÆ
‚ãÆ
‚ãÆ‚éü
‚ãØ 1 ‚àí1 ‚ãØ ‚àí1‚éü‚éü
‚ãØ ‚àí1 1 ‚ãØ 1 ‚éü
‚éü
‚ãÆ
‚ãÆ
‚ãÆ‚éü
‚ãØ ‚àí1 1 ‚ãØ 1 ‚éü‚é†
‚ãØ

(13)

In the case of ùëö = 2 we use the coupling parameters: ùê∂ùë† = ‚àí20, ùê∂12 = ùê∂1 ‚âà 14.14 and ùê∂21 =
ùê∂2 ‚âà 28.3. In the case of ùëö = 3 we use the parameters: ùê∂ùë† = ‚àí20, ùê∂12 ‚âà 14.14, ùê∂21 = ùê∂23 ‚âà 9.4,
ùê∂32 ‚âà 28.3, and ùê∂13 = ùê∂31 = 0. Additional details on the choice of coupling parameters are
provided in Appendices 2 and 3.

Two dimensional modules
In two dimensions each module contains four sub-populations, and the synaptic activation
vector is:
‚éõùë†‚ÉóùëÖ ‚éû
‚éú ùë†‚Éó ‚éü
ùë†‚Éó = ‚éú ùêø ‚éü
(14)
‚éúùë†‚Éóùëà ‚éü
‚éú ‚éü
‚éùùë†‚Éóùê∑ ‚é†
Each sub-population contains ùëÅ 2 = 642 neurons, arranged on a parallelogram. The preferred
phase of the ùëñ‚Äôth neuron in each sub-population is:
( )
( )
( )
0.5
ùúÉ
1
ùë•ùëñ
(15)
ùúÉ‚Éóùëñ =
= ùë•ùëñ ùë¢‚Éó1 + ùë¶ùëñ ùë¢‚Éó2 , ùë¢‚Éó1 =
, ùë¢‚Éó2 = ‚àö3 .
ùúÉùë¶ùëñ
0
2

where ùë•ùëñ and ùë¶ùëñ are distributed uniformly in the interval [0, 1]. The connectivity matrix is now:
‚éõùëä ùëÖ
‚éúùëä ùëÖ
ùëä =‚éú ùëÖ
‚éúùëä
‚éú ùëÖ
‚éùùëä
where
ùëäùëñùëóùëÖ,ùêø

ùëäùêø
ùëäùêø
ùëäùêø
ùëäùêø

ùëäùëà
ùëäùëà
ùëäùëà
ùëäùëà

ùëä ùê∑‚éû
ùëä ùê∑ ‚éü‚éü
,
ùëä ùê∑‚éü
‚éü
ùëä ùê∑‚é†

( )|
( )|
‚éõ||
‚éõ||
‚éû
| ‚éû
ùúë
0 || ‚éü
ùëà
,ùê∑
‚éú
|
|
‚éü
‚éú
|
‚Éó
‚Éó
‚Éó
‚Éó
= ùë§ |ùúÉùëñ ‚àí ùúÉùëó ‚àì
, ùëäùëñùëó = ùë§ |ùúÉùëñ ‚àí ùúÉùëó ‚àì
,
‚éú|
‚éú|
0 || ‚éü
ùúë || ‚éü
‚éù|
‚éù|
|P 2 ‚é†
|P 2 ‚é†

(16)

(17)

20 of 37

and
ùë§(ùúÉ) =

[
(
)
]
ùúÉ2
ùê¥
exp
‚àí
‚àí
1
.
4ùëÅ 2
2ùúé 2

(18)

The distance measure | ‚ãÖ |P2 is deÔ¨Åned using periodic boundary conditions on the parallelogram
(see Fig. 4A): |‚Éó
ùë•1 ‚àí ùë•‚Éó2 |ùëÉ2 is the minimal distance between the two points ùë•‚Éó1 and ùë•‚Éó2 on the
torus that is created
by
gluing the opposite edges of the parallelogram deÔ¨Åned by the vertices
‚àö
‚àö
(0, 0), (1, 0), ( 12 , 23 ), ( 23 , 23 ) (Fig. 4A, compare with Eq. 10, used in the one dimensional case).
The Ô¨Åring rate of neuron ùëñ ‚àà {sub-population R or L} from module ùúá is:
ùëüùúá,ùëñ

2
ùëö
‚éõ4ùëÅ
‚éû
‚àë
‚àë
‚éú
=ùúô
ùëä ùë† + ùêº0 ¬± ùëèùúá,ùë• (ùë°) ¬± ùëé
ùê∂ùúáùúå ùúîùúå,ùë• ‚éü ,
‚éú ùëó=1 ùëñùëó ùúá,ùëó
‚éü
ùúå=1
‚éù
‚é†

where
ùúîùúá,ùë•

ùõΩ
‚â°
ùúè

(

‚àë
ùëñ‚ààùëÖ

ùë†ùúáùëñ ‚àí

‚àë

(19)

)
ùë†ùúáùëñ

.

(20)

ùëñ‚ààùêø

Firing rates of neurons from the up and down sub-populations are obtained from Eqs. 19-20
by replacing ùë• ‚Üí ùë¶, , ùëÖ ‚Üí ùëà , and ùêø ‚Üí ùê∑.
In each module, responses to horizontal and vertical velocity inputs are independent:
the right and left sub-populations respond to the horizontal velocity inputs, and affect ùúÉùë• ,
while the up and down sub-populations respond to the vertical velocity inputs and affect
ùúÉùë¶ . Hence, the two-dimensional response tensor separates into independent, horizontal and
vertical components with the same structure as in the one dimensional case. Since the linear
response tensor (in each direction) is identical to that of the one dimensional case, the coupling
parameters are chosen in the same way in one and two dimensions.

External velocity input
The external velocity input to module ùúá (in two dimensions) in ùëû ‚àà {ùë•, ùë¶} direction is (Eq. 19):
(
)
ùëèùúá,ùëû (ùë°) = ùõæùúá ùë£ùëéùëû (ùë°) + ùúÇùúá,ùëû (ùë°) .
(21)
ùõæùúá is a proportionality factor that depends on the module, ùë£ùëéùëû (ùë°) is a the component of the
animal‚Äôs velocity in the ùëû direction, and ùúÇùúá,ùëû (ùë°) is a white noise process with ‚ü®ùúÇùúá,ùëû (ùë°)ùúÇùúå,ùëû‚Ä≤ (ùë°‚Ä≤ )‚ü© =
ùúÇ 2 ùõøùëûùëû‚Ä≤ ùõøùúáùúå ùõø(ùë° ‚àí ùë°‚Ä≤ ). In Fig. 4B and Fig. 6B-C the external input is not noisy, so ùúÇ = 0. In Fig. 4D-E
and Fig. 5, ùúÇ = 0.02m ‚ãÖ s‚àí0.5 .
In Fig. 3E-F (one dimension) ùõæ1 = 0.06 and ùõæ2 = 0. In the simulations of Figs. 4-6 (two
dimensions) ùõæ1 = 0.06 , ùõæ2 = ùúÜ0.06 , ùõæ3 = ùúÜ2 0.06. Thus, even without coupling of the modules,
the spacing ratio ùúÜ is achieved by the ratios of the inputs strengths ùõæùúá , and therefore we can
compare between the coupled and uncoupled phases and readout (Figs. 4-6).

Spiking network
In the case of spiking Poisson neurons Eq. 3 is replaced by:
‚àë
ùë†
ùë†Ãá ùëñ + ùëñ =
ùõø(ùë° ‚àí ùë°ùõºùëñ ) ,
ùúè
ùõº

(22)

21 of 37

where

‚àë

ùõø(ùë° ‚àí ùë°ùõºùëñ )

(23)

ùõº

is the spike train of neuron ùëñ, and ùë°ùõºùëñ are the spike times. Each neuron ùëñ generates spikes
sampled from a Poisson distribution with a Ô¨Åring rate ùëüùëñ (ùë°), as deÔ¨Åned in Eq. 3 (Stevens and
Zador, 1996; Gerstner and Kistler, 2002; Burak and Fiete, 2012).

Decoding
Decoding of the animal‚Äôs trajectory, based on spike trains, is performed in Figs. 5-6 using a
decoder that sums spikes from recent history with an exponential temporal kernel (Mosheiff
et al., 2017). In Fig. 5 we simulate a spike train for each neuron (Eq. 23), sampled from an
inhomogeneous Poisson process with a Ô¨Åring rate ùëüùëñ (ùë°) (note that the the network dynamics are
deterministic and spikes are used only in the readout process). In Fig. 6 the stochastic spike
train is part of of the dynamics (Eq. 22). In both cases, the decoded location of the animal in
time ùë° is (Eqs. S10, S11 and S13 in Mosheiff et al. (2017)):
(
)
‚àë [
] ùë°
ùë° ‚àí ùë°‚Ä≤ ‚àë
‚Ä≤
ÃÇùë•‚Éó(ùë°) = argmax
ln ùëüÃÑùëñ (‚Éó
ùë•)
ùëëùë° exp ‚àí
ùõø(ùë° ‚àí ùë°ùõºùëñ ) .
(24)
ùë•‚Éó
‚à´
ùúè
‚àí‚àû
ùëë
ùëñ
ùõº
The summation is over all neurons. Here ùúèùëë = 10ms for all modules. The integral in Eq. 24 yields
an effective spike count of neuron ùëñ, weighted in time using a decaying exponential kernel, and
ùëüÃÑùëñ (‚Éó
ùë•) is the receptive Ô¨Åeld of neuron ùëñ at location ùë•‚Éó, measured separately from the Ô¨Åring rate of
each neuron in the steady state of the dynamics.

Diffusion tensor
Consider a system of spiking Poisson neurons, and ùëö one dimensional modules. The internal
noise introduces a diffusive drift. The network is now a single continuous attractor with
dimension ùëö (see Appendix 4). Hence, the diffusion tensor is a ùëö √ó ùëö matrix, that can be
calculated using Eq. S24 in Burak and Fiete (2012), for the dynamics of the ùëö dimensional
attractor (Eqs. 73, 74 and 75 in Appendix 4):
‚Éó =
ùê∑ùúáùúå (ùúÉ)

2ùëÅùëö
1 ‚àë
‚Éó ùúå,ùëñ (ùúÉ)ÃÑ
‚Éó ùëüùëñ (ùúÉ)
‚Éó .
ùúà (ùúÉ)ùúà
2 ùëñ=1 ùúá,ùëñ

(25)

‚Éó is the Ô¨Åring rate of neuron ùëñ in the steady state
where the summation is over all neurons, ùëüÃÑùëñ (ùúÉ)
‚Éó is the left null eigenvector of the dynamics (Eq. 74) corresponding to a
of the system, and ùúàùúá (ùúÉ)
phase shift in the direction of module ùúá (calculated numerically).

Acknowledgments
This research was supported by the Israel Science Foundation grant No. 1745/18 and (in part)
by grant No. 1978/13. We acknowledge support from the Gatsby Charitable Foundation, and
from the Dalia and Dan Maydan Fellowship (NM).

22 of 37

References
Allen K, Gil M, Resnik E, Toader O, Seeburg P, Monyer H. Impaired Path Integration and Grid Cell
Spatial Periodicity in Mice Lacking GluA1-Containing AMPA Receptors. Journal of Neuroscience. 2014;
34(18):6245‚Äì6259. http://www.jneurosci.org/content/34/18/6245, doi: 10.1523/JNEUROSCI.433013.2014.
Ben-Yishai R, Bar-Or RL, Sompolinsky H. Theory of orientation tuning in visual cortex. Proceedings of
the National Academy of Sciences. 1995; 92(9):3844‚Äì3848. https://www.pnas.org/content/92/9/3844,
doi: 10.1073/pnas.92.9.3844.
Burak Y. Spatial coding and attractor dynamics of grid cells in the entorhinal cortex. Current
opinion in neurobiology. 2014 apr; 25:169‚Äì75. http://www.sciencedirect.com/science/article/pii/
S0959438814000282.
Burak Y, Fiete IR. Accurate Path Integration in Continuous Attractor Network Models of Grid Cells. PLoS
Computational Biology. 2009 feb; 5(2):e1000291. http://journals.plos.org/ploscompbiol/article?id=10.
1371/journal.pcbi.1000291.
Burak Y, Fiete IR. Fundamental limits on persistent activity in networks of noisy neurons. Proceedings
of the National Academy of Sciences of the United States of America. 2012 oct; 109(43):17645‚Äì50.
http://www.pnas.org/content/109/43/17645.short.
Dordek Y, Soudry D, Meir R, Derdikman D. Extracting grid cell characteristics from place cell inputs
using non-negative principal component analysis. eLife. 2016 mar; 5:e10094. https://doi.org/10.7554/
eLife.10094, doi: 10.7554/eLife.10094.
D‚ÄôAlbis T, Kempter R. A single-cell spiking model for the origin of grid-cell patterns. PLOS Computational Biology. 2017 10; 13(10):1‚Äì41. https://doi.org/10.1371/journal.pcbi.1005782, doi: 10.1371/journal.pcbi.1005782.
Eichenbaum H. Time cells in the hippocampus: a new dimension for mapping memories. NATURE
REVIEWS NEUROSCIENCE. 2014 NOV; 15(11):732‚Äì744. doi: {10.1038/nrn3827}.
Fiete IR, Burak Y, Brookings T. What grid cells convey about rat location. The Journal of neuroscience :
the oÔ¨Écial journal of the Society for Neuroscience. 2008 jul; 28(27):6858‚Äì71. http://www.jneurosci.
org/content/28/27/6858.abstract.
Fu ML, Zutshi I, Liu S, Leutgeb JK, Lim BK, Leutgeb S. Layer speciÔ¨Åc characterization of local projections
within the medial entorhinal cortex. In: Program No. 510.07. 2018 Neuroscience Meeting Planner. San
Diego, CA: Society for Neuroscience, 2018. Online; 2018. https://www.abstractsonline.com/pp8/#!/4649/
presentation/27531.
Fuhs MC, Touretzky DS. A Spin Glass Model of Path Integration in Rat Medial Entorhinal Cortex.
Journal of Neuroscience. 2006; 26(16):4266‚Äì4276. http://www.jneurosci.org/content/26/16/4266, doi:
10.1523/JNEUROSCI.4353-05.2006.
Fyhn M, Hafting T, Treves A, Moser MB, Moser EI. Hippocampal remapping and grid realignment in
entorhinal cortex. NATURE. 2007 MAR 8; 446(7132):190‚Äì194. doi: {10.1038/nature05601}.
Gardner RJ, Lu L, Wernle T, Moser MB, Moser E I. Correlation structure of grid cells is preserved during
sleep. NATURE NEUROSCIENCE. 2019 APR; 22(4):598+. doi: {10.1038/s41593-019-0360-0}.

23 of 37

Gerstner W, Kistler WM. Spiking neuron models: Single neurons, populations, plasticity. Cambridge
university press; 2002.
Gil M, Ancau M, Schlesiger MI, Neitz A, Allen K, De Marco RJ, Monyer H. Impaired path integration in mice
with disrupted grid cell Ô¨Åring. NATURE NEUROSCIENCE. 2018 JAN; 21(1):81+. doi: {10.1038/s41593017-0039-3}.
Green J, Adachi A, Shah KK, Hirokawa JD, Magani PS, Maimon G. A neural circuit architecture for angular
integration in Drosophila. NATURE. 2017 JUN 1; 546(7656):101+. doi: {10.1038/nature22343}.
Gu Y, Lewallen S, Kinkhabwala AA, Domnisoru C, Yoon K, Gauthier JL, Fiete IR, Tank DW.
A Map-like Micro-Organization of Grid Cells in the Medial Entorhinal Cortex.
Cell. 2018;
175(3):736 ‚Äì 750.e30. http://www.sciencedirect.com/science/article/pii/S009286741831167X, doi:
https://doi.org/10.1016/j.cell.2018.08.066.
Guanella A, Kiper D, Verschure P. A model of grid cells based on a twisted torus topology. International
Journal of Neural Systems. 2007; 17(04):231‚Äì240. https://doi.org/10.1142/S0129065707001093, doi:
10.1142/S0129065707001093, pMID: 17696288.
Hafting T, Fyhn M, Molden S, Moser MB, Moser EI. Microstructure of a spatial map in the entorhinal
cortex. Nature. 2005; 436(7052):801‚Äì806. http://www.nature.com/doiÔ¨Ånder/10.1038/nature03721,
doi: 10.1038/nature03721.
Heys J, Rangarajan K, Dombeck D. The Functional Micro-organization of Grid Cells Revealed by CellularResolution Imaging. Neuron. 2014; 84(5):1079 ‚Äì 1090. http://www.sciencedirect.com/science/article/
pii/S0896627314009684, doi: https://doi.org/10.1016/j.neuron.2014.10.048.
Jun JJ, Steinmetz NA, Siegle JH, Denman DJ, Bauza M, Barbarits B, Lee AK, Anastassiou CA, Andrei A,
Aydin C, Barbic M, Blanche TJ, Bonin V, Couto J, Dutta B, Gratiy SL, Gutnisky DA, Hausser M, Karsh B,
Ledochowitsch P, et al. Fully integrated silicon probes for high-density recording of neural activity.
NATURE. 2017 NOV 9; 551(7679):232+. doi: {10.1038/nature24636}.
Kang L, Balasubramanian V. A geometric attractor mechanism for self-organization of entorhinal grid modules. bioRxiv. 2018; https://www.biorxiv.org/content/early/2018/06/04/338087, doi:
10.1101/338087.
Kim SS, Rouault H, Druckmann S, Jayaraman V. Ring attractor dynamics in the Drosophila central
brain. Science. 2017; 356(6340):849‚Äì853. https://science.sciencemag.org/content/356/6340/849, doi:
10.1126/science.aal4835.
Kropff E, Treves A. The Emergence of Grid Cells: Intelligent Design or Just Adaptation? HIPPOCAMPUS.
2008; 18(12, SI):1256‚Äì1269. doi: {10.1002/hipo.20520}.
Lim S, Goldman MS. Balanced cortical microcircuitry for maintaining information in working memory.
NATURE NEUROSCIENCE. 2013 SEP; 16(9):1306‚ÄìU196. doi: {10.1038/nn.3492}.
Lim S, Goldman MS. Balanced Cortical Microcircuitry for Spatial Working Memory Based on Corrective
Feedback Control. Journal of Neuroscience. 2014; 34(20):6790‚Äì6806. http://www.jneurosci.org/
content/34/20/6790, doi: 10.1523/JNEUROSCI.4602-13.2014.

24 of 37

Manns JR, Howard MW, Eichenbaum H. Gradual Changes in Hippocampal Activity Support Remembering
the Order of Events. Neuron. 2007; 56(3):530 ‚Äì 540. http://www.sciencedirect.com/science/article/pii/
S0896627307006435, doi: https://doi.org/10.1016/j.neuron.2007.08.017.
Mathis A, Herz AVM, Stemmler MB. Resolution of Nested Neuronal Representations Can Be Exponential
in the Number of Neurons. Phys Rev Lett. 2012 Jul; 109:018103. https://link.aps.org/doi/10.1103/
PhysRevLett.109.018103, doi: 10.1103/PhysRevLett.109.018103.
McNaughton BL, Battaglia FP, Jensen O, Moser EI, Moser MB. Path integration and the neural basis of
the ‚Äôcognitive map‚Äô. Nature reviews Neuroscience. 2006 aug; 7(8):663‚Äì78. http://dx.doi.org/10.1038/
nrn1932.
Moser EI, Kropff E, Moser MB. Place Cells, Grid Cells, and the Brain‚Äôs Spatial Representation System.
Annual Review of Neuroscience. 2008; 31(1):69‚Äì89. https://doi.org/10.1146/annurev.neuro.31.061307.
090723, doi: 10.1146/annurev.neuro.31.061307.090723, pMID: 18284371.
Mosheiff N, Agmon H, Moriel A, Burak Y. An eÔ¨Écient coding theory for a dynamic trajectory predicts
non-uniform allocation of entorhinal grid cells to modules. PLOS Computational Biology. 2017 06;
13(6):1‚Äì19. https://doi.org/10.1371/journal.pcbi.1005597, doi: 10.1371/journal.pcbi.1005597.
Muller R, Kubie J. The effects of changes in the environment on the spatial Ô¨Åring of hippocampal
complex-spike cells. Journal of Neuroscience. 1987; 7(7):1951‚Äì1968. http://www.jneurosci.org/
content/7/7/1951, doi: 10.1523/JNEUROSCI.07-07-01951.1987.
Obenhaus HA, Rose T, Zong W, Tsao A, Donato F, H√∏ydal √òA, Goltstein PM, Moser MB, Chen L, Cheng H,
Moser EI, Bonhoeffer T. Miniaturized two-photon microscopy enables the study of functional network
topography in the medial entorhinal cortex. In: Program No. 689.06. 2018 Neuroscience Meeting Planner.
San Diego, CA: Society for Neuroscience, 2018. Online; 2018. https://www.abstractsonline.com/pp8/#!
/4649/presentation/9606.
O‚ÄôKeefe J, Nadel L. The Hippocampus as a Cognitive Map. Oxford University Press; 1978.
Raudies F, Brandon MP, Chapman GW, Hasselmo ME. Head direction is coded more strongly
than movement direction in a population of entorhinal neurons.
Brain Research. 2015;
1621:355 ‚Äì 367.
http://www.sciencedirect.com/science/article/pii/S0006899314014759, doi:
https://doi.org/10.1016/j.brainres.2014.10.053, brain and Memory: Old Arguments and New Perspectives.
Sargolini F, Fyhn M, Hafting T, McNaughton B, Witter M, Moser M, Moser E. Conjunctive representation
of position, direction, and velocity in entorhinal cortex. SCIENCE. 2006 MAY 5; 312(5774):758‚Äì762. doi:
{10.1126/science.1125572}.
Seelig JD, Jayaraman V. Neural dynamics for landmark orientation and angular path integration. NATURE.
2015 MAY 14; 521(7551):186+. doi: {10.1038/nature14446}.
Shadlen MN, Newsome WT. Noise, neural codes and cortical organization. Current Opinion in Neurobiology. 1994; 4(4):569 ‚Äì 579. http://www.sciencedirect.com/science/article/pii/0959438894900590, doi:
https://doi.org/10.1016/0959-4388(94)90059-0.
Softky W, Koch C. The highly irregular Ô¨Åring of cortical cells is inconsistent with temporal integration of
random EPSPs. Journal of Neuroscience. 1993; 13(1):334‚Äì350. http://www.jneurosci.org/content/13/
1/334, doi: 10.1523/JNEUROSCI.13-01-00334.1993.

25 of 37

Sreenivasan S, Fiete I. Grid cells generate an analog error-correcting code for singularly precise neural
computation. Nature neuroscience. 2011 oct; 14(10):1330‚Äì7. http://www.nature.com/neuro/journal/
v14/n10/abs/nn.2901.htmlhttp://dx.doi.org/10.1038/nn.2901.
Stensola H, Stensola T, Solstad T, Fr√∏land K, Moser MB, Moser EI. The entorhinal grid map is discretized.
Nature. 2012; 492(7427):72‚Äì8. http://www.ncbi.nlm.nih.gov/pubmed/23222610, doi: 10.1038/nature11649.
Stevens CF, Zador AM.
When is an Integrate-and-Ô¨Åre Neuron like a Poisson Neuron?
In: Touretzky DS, Mozer MC, Hasselmo ME, editors. Advances in Neural Information Processing Systems 8 MIT Press; 1996.p. 103‚Äì109.
http://papers.nips.cc/paper/
1057-when-is-an-integrate-and-Ô¨Åre-neuron-like-a-poisson-neuron.pdf.
Taube JS. The Head Direction Signal: Origins and Sensory-Motor Integration. Annual Review of
Neuroscience. 2007 jul; 30(1):181‚Äì207. http://www.annualreviews.org/doi/abs/10.1146/annurev.
neuro.29.051605.112854.
Taube J, Muller R, Ranck J. Head-direction cells recorded from the postsubiculum in freely moving
rats. I. Description and quantitative analysis. Journal of Neuroscience. 1990; 10(2):420‚Äì435. http:
//www.jneurosci.org/content/10/2/420, doi: 10.1523/JNEUROSCI.10-02-00420.1990.
Trettel SG, Trimper JB, Hwaun E, Fiete IR, Colgin LL. Grid cell co-activity patterns during sleep reÔ¨Çect
spatial overlap of grid Ô¨Åelds during active behaviors. NATURE NEUROSCIENCE. 2019 APR; 22(4):609+.
doi: {10.1038/s41593-019-0359-6}.
Turner-Evans D, Wegener S, Rouault H, Franconville R, Wolff T, Seelig JD, Druckmann S, Jayaraman V.
Angular velocity integration in a Ô¨Çy heading circuit. ELIFE. 2017 MAY 22; 6. doi: {10.7554/eLife.23496}.
Weber SN, Sprekeler H. Learning place cells, grid cells and invariances with excitatory and inhibitory
plasticity. eLife. 2018 feb; 7:e34560. https://doi.org/10.7554/eLife.34560, doi: 10.7554/eLife.34560.
Wei XX, Prentice J, Balasubramanian V. A principle of economy predicts the functional architecture of
grid cells. eLife. 2015 jan; 4:e08362. http://elifesciences.org/content/early/2015/09/03/eLife.08362.
abstracthttp://elifesciences.org/content/4/e08362.abstract.
Welinder PE, Burak Y, Fiete IR. Grid cells: The position code, neural network models of activity, and the
problem of learning. Hippocampus. 2008; 18(12):1283‚Äì1300. https://onlinelibrary.wiley.com/doi/abs/
10.1002/hipo.20519, doi: 10.1002/hipo.20519.
Xie X, Hahnloser RHR, Seung HS. Double-ring network model of the head-direction system. Phys Rev
E. 2002 Oct; 66:041902. https://link.aps.org/doi/10.1103/PhysRevE.66.041902, doi: 10.1103/PhysRevE.66.041902.
Yoon K, Buice MA, Barry C, Hayman R, Burgess N, Fiete IR. SpeciÔ¨Åc evidence of low-dimensional
continuous attractor dynamics in grid cells. NATURE NEUROSCIENCE. 2013 AUG; 16(8):1077‚ÄìU141.
doi: {10.1038/nn.3450}.
Zhang K. Representation of spatial orientation by the intrinsic dynamics of the head-direction cell
ensemble: a theory. Journal of Neuroscience. 1996; 16(6):2112‚Äì2126. http://www.jneurosci.org/
content/16/6/2112, doi: 10.1523/JNEUROSCI.16-06-02112.1996.

26 of 37

Appendix 1
Readout of the phase velocity
In this Appendix, we derive the relationship between ùúî (Eq. 4) and the phase velocity ùúÉÃá
(Eq. 1) . To simplify the presentation, we consider separately two situations: Ô¨Årst, a noise
free network, in which the phase velocity is driven by velocity inputs. Second, a module
consisting of Poisson spiking neurons where, for simplicity, we set the velocity inputs to
be zero. In the latter case the phase velocity is driven by the stochasticity of the neurons
participating in the network dynamics. From the derivation it is easily seen that in the
general case, and as long as the linearization of the dynamics (forming the basis of the
calculation in both cases) is valid, the phase velocity, as well as ùúî can be expressed as a
sum of independent contributions arising from the two sources considered below.

Phase velocity due to velocity inputs
Consider a single one dimensional module, whose dynamics follow Eq. 3, and whose
synaptic connectivity is described by the double ring model, as speciÔ¨Åed by Eqs. 8-10.
We expand the dynamic equation around a steady state ùë†(ùúÉ),
ÃÑ
so that ùë†ùëñ = ùë†ÃÑùëñ (ùúÉ) + ùõøùë†ùëñ , and
assume small velocity input ùëëùêº(ùë°) (see similar expansion in Burak and Fiete (2012)). After
linearization:
2ùëÅ
‚àë
ùõøùë†Ãá ùëñ =
ùêæùëñùëó (ùúÉ)ùõøùë†ùëó ¬± ùëëùêº(ùë°)ùúô‚Ä≤ (ùëîÃÑùëñ (ùúÉ))
(26)
ùëó=1

where
1
ùêæùëñùëó (ùúÉ) = ‚àí ùõøùëñùëó + ùúô‚Ä≤ (ùëîÃÑùëñ (ùúÉ))ùëäùëñùëó
ùúè

(27)

ùúÉÃá = ùë£ùëá ‚ãÖ ùõø‚ÉóÃáùë† = ùõºùëëùêº(ùë°) ,

(28)

‚àë
and ùëîÃÑùëñ (ùúÉ) = 2ùëÅ
ùëó=1 ùëäùëñùëó ùë†ÃÑùëó + ùêº0 is the synaptic input in the steady state ùë†ÃÑùëñ (ùúÉ). The velocity of
the phase ùúÉ is obtained by projection of Eq. 26 on the left eigenvector of ùêæ with zero
eigenvalue, ùë£(ùúÉ)
‚Éó (Burak and Fiete, 2012). After some algebra we obtain

where
ùõº=

(
‚àë
ùëñ‚ààùëÖ

‚Ä≤

ùë£ùëñ ùúô (ùëîÃÑùëñ ) ‚àí

‚àë

)
‚Ä≤

ùë£ùëñ ùúô (ùëîÃÑùëñ )

.

(29)

ùëñ‚ààùêø

Hence, ùúÉÃá is proportional to the velocity input ùëëùêº(ùë°).

27 of 37

Let us deÔ¨Åne the 2ùëÅ dimensional vector:
‚éõ
‚éú
‚éú
‚éú
ùë£‚Éó0 = ùõΩ ‚éú
‚éú
‚éú
‚éú
‚éú
‚éù

1
...
1
‚àí1
...
‚àí1

‚éû
‚éü
‚éü
‚éü
‚éü,
‚éü
‚éü
‚éü
‚éü
‚é†

(30)

where ùõΩ is a constant, whose value is determined below. The projection of Eq. 26 on ùë£‚Éó0
results in
2ùëÅ
2ùëÅ ùë£2
‚àë
ùë£ùëá0 ‚ãÖ ùõø‚Éóùë† ‚àë
0,ùëñ ‚Ä≤
ùëá
‚Ä≤
Ãá
+
ùúô (ùëîÃÑùëñ ) .
(31)
ùë£0 ‚ãÖ ùõø‚Éóùë† = ‚àí
ùë£0,ùëñ ùúô (ùëîÃÑùëñ )ùëäùëñùëó ùõøùë†ùëó + ùëëùêº(ùë°)
ùúè
ùõΩ
ùëñ=1
ùëñ=1
The second term on the right hand side of Eq. 31 vanishes due to the symmetry of ùúô‚Ä≤ (ùëîÃÑùëñ ) to
exchange of the right and left sub-populations, the antisymmetry of ùë£0 to this exchange,
and the structure of the matrix ùëä . Using the deÔ¨Ånition of ùúî (Eq. 4), we can write:
ùúî=

ùë£ùëá0 ‚ãÖ ùë†‚Éó
ùúè

=

ùë£ùëá0 ‚ãÖ ùõø‚Éóùë†
ùúè

.

(32)

Thus, Eq. 31 becomes:
ùúè ùúîÃá = ‚àíùúî + ùõºùëëùêº(ùë°)
ÃÉ
,

(33)

‚àë

(34)

where
ùõºÃÉ = 2ùõΩ

ùúô‚Ä≤ (ùëîÃÑùëñ ) .

ùëñ‚ààùëÖ

In Eq. 34 we use again the symmetry ùúô‚Ä≤ (ùëîÃÑùëÖ,ùëñ ) = ùúô‚Ä≤ (ùëîÃÑùêø,ùëñ ). We set ùõΩ (Eq. 30) such that ùõºÃÉ = ùõº.
Using Eqs. 29 and 34:
‚àë
‚àë
‚Ä≤
‚Ä≤
ùëñ‚ààùëÖ ùë£ùëñ ùúô (ùëîÃÑùëñ ) ‚àí
ùëñ‚ààùêø ùë£ùëñ ùúô (ùëîÃÑùëñ )
ùõΩ=
.
(35)
‚àë
2 ùëñ‚ààùëÖ ùúô‚Ä≤ (ùëîÃÑùëñ )
From Eq. (33) we see that the readout velocity ùúî is a convolution of ùõºùëëùêº(ùë°), with the Ô¨Ålter
ùëì (ùë°) =

( )
ùë°
1
exp ‚àí
.
ùúè
ùúè

(36)

Combining Eqs. 28 and 33 we conclude that
Ãá .
ùúî(ùë°) = ùëì (ùë°) ‚àó ùúÉ(ùë°)

(37)

Hence, ùúî is equal to the phase velocity, smoothed over a relatively short time scale set by
the synaptic time constant (ùúè = 10ms).

28 of 37

Phase velocity due to internal noise
Consider next a single one dimensional module with Poisson spiking neurons, following
the dynamics of Eq. 22. In the limit of large Ô¨Åring rates, Eq. 22 can be replaced by
ùë†Ãá ùëñ +

ùë†ùëñ
= ùëüùëñ + ùúâ ùëñ ,
ùúè

(38)

where ùúâùëñ is a white noise process with ‚ü®ùúâùëñ (ùë°)ùúâùëó (ùë°‚Ä≤ )‚ü© = ùëüùëñ (ùë°)ùõøùëñùëó ùõø(ùë° ‚àí ùë°‚Ä≤ ) (Burak and Fiete, 2012).
We use a similar expansion as in Appendix 1, and project the linearized dynamics on ùë£(ùúÉ),
‚Éó
the left null eigenvector of ùêæ, to obtain:
ùúÉÃá = ùë£ùëá ‚ãÖ ùõø‚ÉóÃáùë† = ùëëùêº(ùë°)

2ùëÅ
‚àë
ùë£ùëñ ùë£0,ùëñ
ùëñ=1

ùõΩ

ùúô‚Ä≤ (ùëîÃÑùëñ ) + ùë£ùëá ‚ãÖ ùúâ‚Éó .

(39)

The Ô¨Årst term on the right hand side of Eq. 39 is the contribution to the phase velocity
arising from the velocity inputs, discussed above. From here on we assume that the velocity
input vanishes. The only contribution to the phase velocity is then the second term of
Eq. 39, originating from the neural stochasticity. In order to relate this term to ùúî, let us
deÔ¨Åne:
ùë£(ùúÉ)
‚Éó = ùë£‚Éó+ + ùë£‚Éó‚àí
)
)
(
(
ùë£‚ÉóùëÖ ‚àí ùë£‚Éóùêø
1 ùë£‚Éóùêø + ùë£‚ÉóùëÖ
1
, ùë£‚Éó‚àí =
,
ùë£‚Éó+ =
2 ùë£‚Éó ‚àí ùë£‚Éó
2 ùë£‚Éóùêø + ùë£‚ÉóùëÖ
ùêø
ùëÖ

(40)
(41)

where ùë£‚ÉóùëÖ and ùë£‚Éóùêø are the Ô¨Årst or last ùëÅ coordinates of ùë£(ùúÉ),
‚Éó
respectively (Appendix 1 Fig. 1).
Eq. 39 becomes:
ùúÉÃá = (ùë£ùëá‚àí + ùë£ùëá+ ) ‚ãÖ ùúâ‚Éó .
(42)

Appendix 1 Figure 1. A. The left eigenvector of ùêæ with zero eigenvalue, ùë£(ùúÉ
‚Éó = 0.5) (the bump is
centered around ùúÉ = 0.5), computed numerically. The Ô¨Årst ùëÅ coordinates of ùë£‚Éó (right sub-population)
in red, and the last ùëÅ coordinates of ùë£‚Éó (left sub-population) in blue. B. ùë£‚Éó‚àí (red and blue for the right
and left sub-population respectively), and ùë£‚Éó+ (yellow, identical for both of the sub-populations), as
deÔ¨Åned in Eq. 41. The black dashed line represents the Ô¨Åring rate bump of the steady state
(unitless for the sake of comparison with ùë£).
‚Éó

29 of 37

Next, we examine the structure of ùë£‚Éó+ and ùë£‚Éó‚àí . The left and right components of ùë£+ are
spatially antisymmetric with respect to the peak of the activity bump, and precisely vanish
at the center of the bump (yellow trace in Appendix 1 Fig. 1B). The components of ùë£‚àí
are symmetric (blue and red traces). We note that the Poisson noise is expressed only
within the relatively narrow extent of the activity bump (dashed line). Two consequences
follow: Ô¨Årst, ùë£‚Éóùëá+ ‚ãÖ ùúâ‚Éó is very small due to the nearly vanishing values of ùë£+ on the activity bump.
Second, the components of ùë£‚àí are nearly constant in magnitude along the narrow extent
of the bump, but have opposite signs in the left and right sub-populations. This magnitude
can be evaluated by rewriting Eq. 35 as:
ùõΩ

‚àë
ùëñ‚ààùëÖ

ùúô‚Ä≤ (ùëîÃÑùëñ ) =

‚àë

ùë£‚àíùëñ ùúô‚Ä≤ (ùëîÃÑùëñ ) .

(43)

ùëñ‚ààùëÖ

‚Éó
Thus, the magnitude of ùë£‚àí along the activity bump is approximately ùõΩ, and ùë£‚Éóùëá‚àí ‚ãÖ ùúâ‚Éó ‚âà ùë£‚Éóùëá0 ‚ãÖ ùúâ.
Hence, Eq. 42 becomes:
ùúÉÃá ‚âà ùë£ùëá0 ‚ãÖ ùúâ‚Éó .
(44)
We now project the linearized dynamics of Eq. 38 on the vector ùë£‚Éó0 to obtain:
ùúè ùúîÃá = ‚àíùúî + ùë£ùëá0 ‚ãÖ ùúâ‚Éó ‚âà ‚àíùúî + ùúÉÃá .

(45)

Thus, ùúî is a convolution of the velocity phase with the exponential Ô¨Åler ùëì , with the synaptic
time integration ùúè. Therefore:
ùúî = ùëì ‚àó ùúÉÃá ,

(46)

as in the case of phase velocity due to external inputs.

30 of 37

Appendix 2
Linear response tensor
We next wish to understand how our system of coupled modules responds to an external
‚Éó
velocity input ùëè(ùë°).
First, consider two modules, each in one dimension, that follow the
dynamics of Eq. 3. The synaptic activation vector is now 4ùëÅ dimensional and has the form:
( ) ‚éõ
‚éú
ùë†‚Éó1
ùë†‚Éó =
=‚éú
‚éú
ùë†‚Éó2
‚éú
‚éù

ùë†‚Éó1,ùëÖ
ùë†‚Éó1,ùêø
ùë†‚Éó2,ùëÖ
ùë†‚Éó2,ùêø

‚éû
‚éü
‚éü.
‚éü
‚éü
‚é†

(47)

The Ô¨Åring rate of neuron ùëñ from module 1 is (Fig. 2D):
ùëü1,ùëñ = ùúô

( 2ùëÅ
‚àë

)
ùëäùëñùëó ùë†1,ùëó + ùêº0 ¬± ùëè1 ¬± ùëéùê∂1 ùúî2 ¬± ùëéùê∂ùë† ùúî1

,

(48)

ùëó=1

where the total velocity input is ùëëùêº = ùëè1 + ùëéùê∂1 ùúî2 + ùëéùê∂ùë† ùúî1 . A similar equation for the rate ùëü2,ùëñ
is obtained by switching the indices 1 ‚Üî 2 in Eq. 48. The constant
ùëé=
ùõΩ

1
‚àë2ùëÅ

‚Ä≤
ùëñ=1 ùúô (ùëîÃÑùëñ )

=

1
ùõº

(49)

is a proportionality factor that could in principle be absorbed into the deÔ¨Ånition of the
coupling strength parameters, but makes the units of the coupling strengths ùê∂ùúá more
convenient. Substitution of ùëëùêº and Eq. 37 in Eq. 28 yields:
ùúÉÃá 1 = ùõºùëè1 + ùê∂1 ùëì ‚àó ùúÉÃá 2 + ùê∂ùë† ùëì ‚àó ùúÉÃá 1 .

(50)

More generally, for ùëö modules:
Ãá
‚Éó + ùëì ‚àó ùê∂ ùúÉ‚ÉóÃá .
ùúÉ‚Éó = ùõº ùëè(ùë°)

(51)

Thus, the phase velocities are proportional to the external velocity input, plus the velocities
of all other modules Ô¨Åltered in time, and coupled by the matrix C. If we assume that the
velocity is suÔ¨Éciently small, that the position can be regarded as Ô¨Åxed within the synaptic
time scale, the convolution with the Ô¨Ålter ùëì can be omitted (note that the integral of ùëì ,
Eq. 36 , is equal to unity), and we obtain:
Ãá
‚Éó ‚â° ùëã ‚ãÖ ùëè(ùë°)
‚Éó ,
ùúÉ‚Éó = ùõº(ùêº ‚àí ùê∂)‚àí1 ‚ãÖ ùëè(ùë°)

(52)

where ùëã is the linear response tensor.

31 of 37

Two modules
In the case of two modules and identical self coupling strength ùê∂ùë† for both modules, we
can easily Ô¨Ånd the eigenvalues ùëã¬± and eigenvectors of ùëã. The coupling matrix in this case
is:
(
)
ùê∂ùë† ùê∂1
ùê∂=
.
(53)
ùê∂2 ùê∂ùë†
Using Eq. 7 we obtain:
ùëã¬± =
The eigenvectors of ùëã are:

ùõº
ùõº
=
.
‚àö
1 ‚àí ùê∂¬±
1 ‚àí (ùê∂ùë† ¬± ùê∂1 ùê∂2 )
(‚àö )
ùê∂
‚àö1
.
ùë¢‚Éó¬± =
¬± ùê∂2

Thus, the phase motion of the two modules can be represented as:
) ( )
( ) (
ùëã+ 0
ùëè+
ùúÉÃá +
,
=
‚ãÖ
ÃáùúÉ‚àí
ùëè‚àí
0 ùëã‚àí
where

(

ùúÉ+
ùúÉ‚àí

)

(‚àö
)
‚àö
ùê∂2 ùúÉ1 + ùê∂1 ùúÉ2
‚àö
‚àö
= ‚àö
.
ùê∂2 ùúÉ1 ‚àí ùê∂1 ùúÉ2
2 ùê∂1 ùê∂2
1

(54)

(55)

(56)

(57)

Here, ùúÉ¬± are the joint or relative phases of the modules, respectively. We choose parameters
such that ùëã+ is large and ùëã‚àí is small in order to obtain large joint motion and small relative
motion between modules for any external input. Note that ùëã‚àí ‚âà 0 implies that ùúÉÃá ‚àí ‚âà 0 (Eq.
56), and in this case (Eq. 57):
‚àö
ùúÉÃá 1
ùê∂1
‚âà
.
(58)
ùê∂2
ùúÉÃá 2
Thus, we can set the velocity ratio between modules (namely, the spacing ratio ùúÜ), by the
ratio of the coupling parameters, using Eq. 58. We choose
‚àö
‚àö
ùê∂2
= ùúÜ = 2.
(59)
ùê∂1
We choose ùëã+ = ùõº to maintain the same response to coordinated velocity inputs, as
‚àö
in the case of no coupling. Using Eq. 54 we see that this requires ùê∂ùë† + ùê∂1 ùê∂2 = 0, which
implies
ùê∂1 = ‚àíùê∂ùë† ‚àïùúÜ
ùê∂2 = ‚àíùúÜùê∂ùë† ,

(60)

ùõº
1 ‚àí 2ùê∂ùë†

(61)

and
ùëã‚àí =

32 of 37

To obtain small ùëã‚àí , ùê∂ùë† should be negative, with a large absolute magnitude. Note that a
large positive magnitude of ùê∂ùë† , although seems here as a suitable choice, would cause
instability of the system (discussed in Appendix 3).

33 of 37

Appendix 3
Optimization of the coupling strengths for ùëö modules
We now wish to Ô¨Ånd appropriate coupling strengths, ùê∂ùëñùëó , in the general case of ùëö modules,
while allowing for different self couplings in each module. We optimize ùê∂ùëñùëó as follows.
‚Éó The ratios of the compoLet ùë¢‚Éó be a vector in the direction of the mutual motion of ùúÉ.
nents of ùë¢‚Éó are the ratios between corresponding grid spacings. We demand that ùë¢‚Éó is an
eigenvector of ùëã (Eq. 7) with an eigenvalue ùõº. Under this choice, the motion response in
Ãá
‚Éó Eq. 52). Any other
the mutual direction is the same as without coupling (where ùúÉ‚Éó = ùõº ùëè,
eigenvalue of ùëã should be close to zero, such that the motion in any direction, other than
the mutual direction, is small.
Equivalent requirements are that ùë¢‚Éó is an eigenvector of ùê∂ with eigenvalue 0, and any
other eigenvalue of ùê∂ has a large magnitude (see Eq. 52). In addition, as discussed below
(Stability conditions) all the eigenvalues of ùê∂ must be smaller than unity, which excludes
the possibility that they take large positive values. In order to Ô¨Ånd the optimal coupling
parameters we minimize the Lagrangian:
Óà∏ = ùëá ùëü(ùê∂) +

ùëö
‚àë

ùúñùëñ

ùëñ=1

ùëö
‚àë

ùê∂ùëñùëó ùë¢ùëó +

ùëó=1

ùëö
‚àë

ùõæùëñ (ùê∂ùëñùëñ2 ‚àí ùêæ) .

(62)

ùëñ=1

The Ô¨Årst term of the Lagrangian favors negative eigenvalues with large absolute magnitude,
whereas the second term, involving ùëö Lagrange multipliers ùúñùëñ , enforces the existence of
the eigenvector ùë¢‚Éó with eigenvalue 0. As the coupling magnitudes cannot be inÔ¨Ånitely large,
we constrain the self couplings by requiring that ùê∂ùëñùëñ2 < ùêæ , where ùêæ > 0 is a constant. This
constraint is enforced by the third term in Eq. 62, where ùõæùëñ ‚â• 0‚Äôs are Karush-Kuhn-Tucker
multipliers. We demand:
ùúïÓà∏
= 0,
ùúïùê∂ùëñùëó
ùúïÓà∏
= 0,
ùúïùúñùëñ
(
)
ùõæùëñ ùê∂ùëñùëñ2 ‚àí ùêæ = 0 ,
which results in:

(63)
(64)
(65)

‚àö
ùê∂ùëñùëñ = ‚àí ùêæ ‚â° ùê∂ùë† , ùê∂ ùë¢‚Éó = 0 .

(66)

( )
1
For ùëö = 2 and ùë¢‚Éó =
we obtain a single solution:
ùúÜ
(
ùê∂=

ùê∂ùë†
‚àíùê∂ùë† ‚àïùúÜ
‚àíùúÜùê∂ùë†
ùê∂ùë†

)
,

(67)

34 of 37

which is identical to the solution we found in Appendix 2.
For ùëö > 2 and a given vector ùë¢‚Éó there are multiple solutions. For example, for ùëö = 3 and
ùë¢ùëñ = ùúÜùëñ‚àí1 , the solutions are the all ùê∂ùëñùëó ‚Äôs that obey:
ùê∂ùë† + ùúÜùê∂12 + ùúÜ2 ùê∂13 = 0 ,

(68)

ùê∂21 + ùúÜùê∂ùë† + ùúÜ2 ùê∂23 = 0 ,

(69)

ùê∂31 + ùúÜùê∂32 + ùúÜ2 ùê∂ùë† = 0 .

(70)

Making the additional choice that only successive modules are coupled yields the solution:
‚éõ
ùê∂ùë†
‚àíùê∂ùë† ‚àïùúÜ 0 ‚éû
‚éú
‚éü
2
ùê∂ = ‚éú‚àíùúÜùê∂ùë† ‚àí ùúÜ ùê∂23
ùê∂ùë†
ùê∂23 ‚éü ,
‚éú
0
‚àíùúÜùê∂ùë† ùê∂ùë† ‚éü‚é†
‚éù

(71)

where there is a freedom in choosing ùê∂23 . In Figures 4,5 and 6 we chose ùê∂23 = ùê∂21 .
In principle, other constraints on the coupling strengths can be used instead of the
requirement that ùê∂ùëñùëñ < ùêæ for all ùëñ. For example, limiting the magnitude of all the coupling
strengths (ùê∂ùëñùëó2 < ùêæ), instead of only the magnitude of the self couplings, yields solutions
with smaller range of allowed parameters (in the case of multiple solutions), but otherwise
‚àë
2
identical structure. A different possible constraint is of the form ùëö
ùëñ,ùëó=1 ùê∂ùëñùëó < ùêæ. This
ùë¢ùë¢
constraint results in a symmetric solution: ùê∂ùëñùëó ‚àù ‚àëùëñ ùë¢ùëó 2 ‚àí ùõøùëñùëó . We prefer the constraint in Eq.
ùëò ùëò

62 as we do not see a compelling reason to limit all of the coupling parameters together
instead of limiting them separately.

Stability conditions
To map the stability conditions of the coupled network, we consider the dynamics of the
velocity estimation ùúî
‚Éó (Eq. 33). As Eq. 33 is obtained by projecting the full dynamics of the
network on the vector ùë£‚Éó0 , stable network would result in Ô¨Ånite ùúî.
‚Éó We substitute the total
‚Éó
‚Éó
velocity input ùëëùêº = ùëéùê∂ ‚ãÖ ùúî
‚Éó + ùëè(ùë°) in Eq. 33 and obtain:
‚Éó = ‚àí(ùêº ‚àí ùê∂) ‚ãÖ ùúî
‚Éó .
ùúèùúî
‚ÉóÃá = ‚àíùúî
‚Éó +ùê∂ ‚ãÖùúî
‚Éó + ùõº ùëè(ùë°)
‚Éó + ùõº ùëè(ùë°)

(72)

Thus, in order to maintain the stability of ùúî,
‚Éó as well as the stability of the full network, all
eigenvalues of ùê∂ must be smaller than unity, and all eigenvalues of ùëã (Eq. 7) must be
positive.

35 of 37

Appendix 4
The coupled network as a single attractor
In this Appendix we consider the system as a single neural network with recurrent connectivity that includes both the inter- and intra-modular synaptic connections, instead of
thinking of the system as composed of ùëö coupled attractors (modules). The derivation of
the system dynamics presented here, is necessary in order to calculate the diffusion tensor
(Eq. 25). In addition, it offers an alternative approach for obtaining the linear response
tensor ùëã, and provides some additional insights on the behaviour of the network.
We expand the dynamics of Eq. 3 around the steady state ùë†(ùúÉ)
ÃÑ (see similar expansion
in Appendix 1). The dynamics of neuron ùëñ from module ùúá (for simplicity, we assume one
dimensional modules) can be written as:
‚àë

2ùëÅùëö

ùõø ùë†Ãá ùëñ =

[
]
ùêæùëö,ùëñùëó ‚ãÖ ùõøùë†ùëó ¬± ùëèùúá ùúô‚Ä≤ ùëîÃÑùëñ (ùúÉ) ,

(73)

ùëó=1

where the sign ¬± is + (‚àí) if neuron ùëñ belongs to a right (left) sub-population. Here, ùêæùëö is a
2ùëÅùëö √ó 2ùëÅùëö matrix:
ùêµ12
‚ãØ
ùêµ1ùëö ‚éû
‚éõùêæ + ùêµùë†
‚éú ùêµ
ùêæ + ùêµùë†
‚ãÆ ‚éü‚éü
ùêæùëö = ‚éú 21
,
‚éú ‚ãÆ
ùêæ + ùêµùë† ùêµùëö‚àí1,ùëö ‚éü
‚éú
‚éü
‚éù ùêµùëö1
...
ùêµùëö,ùëö‚àí1 ùêæ + ùêµùë† ‚é†

(74)

where ùêæ is deÔ¨Åned in Eq. 27, and

ùêµùúáùúå =

ùëéùê∂ùúáùúå ùõΩ
ùúè

(
)
‚éõ ùúô‚Ä≤ (ùëîÃÑ1 (ùúÉ)) ... ùúô‚Ä≤ (ùëîÃÑ1 (ùúÉ)) ‚éû
‚éü
‚éú
‚àíŒ¶‚Ä≤ Œ¶‚Ä≤
, Œ¶‚Ä≤ = ‚éú
‚ãÆ
‚ã±
‚ãÆ
‚éü.
‚Ä≤
‚Ä≤
Œ¶
‚àíŒ¶
‚éúùúô‚Ä≤ (ùëîÃÑ (ùúÉ)) ... ùúô‚Ä≤ (ùëîÃÑ (ùúÉ))‚éü
ùëÅ
ùëÅ
‚éù
‚é†

(75)

As the system is a continuous attractor of dimension ùëö, there exist ùëö left eigenvectors of
ùêæùëö with zero eigenvalue, ùúà‚Éóùúá (ùúÉùúá ), which we compute numerically. The diffusion tensor is
computed using Eq. 25, using these vectors ùúà‚Éóùúá (ùúÉùúá ).
By projecting Eq. 73 on ùúà‚Éóùúá (ùúÉùúá ) we obtain the linear response tensor ùëã, such that Eq. 6 is
valid. Explicitly:
‚àë
ùëãùúáùúå =
ùúàùúá,ùëñ ùõøùêºùëñ ùúô‚Ä≤ (ùëîÃÑùëñ (ùúÉ)) ,
(76)
ùëñ‚ààùúå

where,
‚éß
‚é™‚àí1 ùëñ ‚àà {lef t}
ùõøùêºùëñ = ‚é®
,
ùëñ ‚àà {right}
‚é™1
‚é©

(77)

36 of 37

and ùëñ ‚àà ùúå means that the ùëñth neuron belongs to module ùúå. Using this approach numerically,
yields nearly identical results as Eq. 52.

37 of 37

