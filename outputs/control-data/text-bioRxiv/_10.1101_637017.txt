bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

1

Motor effort and adaptive sampling in perceptual decision-making

2
3
4
5

Tianyao Zhu1*

6
7
8
9

1

Faculty of Education and Psychology, Eötvös Loránd University, Budapest, Hungary

10
11
12
13

* Corresponding author

14

E-mail: tianyao.a.zhu@gmail.com (TZ)

15

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

16

Abstract

17

People usually switch their attention between the options when trying to make a

18

decision. In our experiments, we bound motor effort to such switching behavior during a two-

19

alternative perceptual decision-making task and recorded the sampling patterns by computer

20

mouse cursor tracking. We found that the time and motor cost to make the decision positively

21

correlated with the number of switches between the stimuli and increased with the difficulty

22

of the task. Specifically, the first and last sampled items were chosen in an attempt to

23

minimize the overall motor effort during the task and were manipulable by biasing the

24

relevant motor cost. Moreover, we observed the last-sampling bias that the last sampled item

25

was more likely to be chosen by the subjects. We listed all possible Bayesian Network models

26

for different hypotheses regarding the causal relationship behind the last-sampling bias, and

27

only the model assuming bidirectional dependency between attention and decision

28

successfully predicted the empirical results. Meanwhile, denying that the current decision

29

variable can feedback into the attention switching patterns during sampling, the conventional

30

attentional drift-diffusion model (aDDM) was inadequate to explain the size of the last-

31

sampling bias in our experimental conditions. We concluded that the sampling behavior

32

during perceptual decision-making actively adapted to the motor effort in the specific task

33

settings, as well as the temporary decision.

34
35

Introduction

36

When people try to choose between two similar products in a shopping center, they

37

often approach each shelf where the products are displayed to have a closer look. If the choice

38

is difficult to make, people may walk back-and-forth the two shelves for a long time. Many

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

39

people will start by examining the product around the entrance of the shop, but choose the one

40

near the checkout counter eventually to save some effort. This daily example suggests that our

41

decisions are not solely shaped by the relative values of the alternatives, but also other factors

42

including the motor effort related to the sampling and the action execution processes.

43

However, sensorimotor aspects have not been integrated into decision-making studies

44

until recently. It is still an on-going controversy whether action is part of decision-making:

45

According to the Embodied Choice model, action execution is part of the decision-making

46

process rather than merely a means to report the decision; in other words, action can feedback

47

into the decision-making process [1]. Researchers have also studied decision-making by

48

analyzing movement patterns [2] and sought neural imaging evidence for the involvement of

49

the sensorimotor system during decision-making [3].

50

Meanwhile, Aczel et al. [4] argued that the observed decision bias was not caused by

51

the movement toward one of the options, as the Embodied Choice model proposed, but rather

52

the difference in the required motor effort during action. Other studies also reported the

53

influence of motor effort during action upon decision-making: For example, perceptual

54

decisions have been observed to be biased by the difference in the motor cost to make the

55

response [5]. Moreover, the exposure to the unequal motor cost also biased the subsequent

56

decisions even when they were vocally reported, indicating that motor effort can affect

57

decision-making at a stage earlier than action execution [6]. De Lange and Fritsche [7]

58

suggested that motor cost can influence decision-making similarly to rewards. Besides, motor

59

effort can also affect changes of mind during decision-making [8].

60

Apart from action, the sampling behavior can be accompanied by motor effort as well,

61

especially when the items to choose from are spatially separated. However, no investigation

62

has focused on the influence of motor effort upon sampling. Although in some paradigms two

63

or more visual stimuli were present, the main form of movement involved during sampling

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

64

was the saccadic eye movement; unlike limb movements, energy costs are not a significant

65

consideration in the planning for saccades [9].

66

Another issue following the separation of the options in space is the attention

67

allocation during sampling. Typically, the decision-maker switches the attention (by the

68

behavior of switching the gaze) between the options at least once, sometimes multiple times.

69

What is the relationship between attention and decision-making? Several results showed that

70

manipulation of attention biased the decision [10-14]. Under the assumption that attention can

71

influence value integration during decision-making, Krajbich et al. [15] proposed the

72

attentional drift-diffusion model (aDDM). Unlike the traditional drift-diffusion model where

73

the relevant evidence accumulates at a constant rate (the drift rate) within one decision, the

74

aDDM allows the drift rate to change with attention: the option currently being attended

75

(gazed at) shall receive more evidence. Such a model has successfully explained the gaze

76

patterns and several gaze-related biases in preferential and perceptual decisions performed by

77

human subjects [15-17].

78

Specifically, the aDDM assumes that attention or gaze switches between the options

79

randomly. In fact, there is rare evidence supporting that temporary choices can influence

80

attention allocation. Shimojo et al. [18] reported the gaze cascade effect that gaze was biased

81

toward the finally chosen item during preferential decision-making, yet Krajbich [19] argued

82

that the phenomenon was readily explained by the aDDM and suggested that gaze or attention

83

has a causal effect on choice, but not vice versa.

84

Under natural circumstances, humans gather information and sample relevant cues

85

with attention and active sensing behaviors (shift of gaze and assisting limb/body movement)

86

[20]. Sampling behavior itself can be regarded as a low-level decision-making process about

87

what information to acquire, as well as where and when [21]. In the current study, we aim to

88

figure out the factors influencing sampling patterns during a basic perceptual decision-making

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

89

task, especially how sampling behavior adapts to the expected motor effort given the specific

90

environment of the task. We designed a paradigm in which motor effort was bind to the

91

sampling and action execution processes, and manipulated the expected motor cost to

92

examine corresponding changes in the sampling patterns. Additionally, we tested the causal

93

relationship between the temporary decision and the attention allocation strategy during

94

sampling by analyzing a Bayesian Network model and simulating an aDDM.

95

96

Methods

97

Paradigm and stimuli

98

The paradigm was based on a two-alternative perceptual decision-making task in

99

which subjects were asked to decide which of the two groups of black and white dots

100

contained more white ones. Two imaginary circles (diameter 3.5 cm) were located

101

horizontally apart on the upper half of the screen (20 cm between their centers), each

102

containing 100 dots. The dots were either black or white on a 50% gray background. In each

103

trial, we randomly set the proportions of white dots in each group with the following method:

104

First, we separately drew an average proportion A from [0.4, 0.6] and a distinction proportion

105

D from [0, 0.3]. The proportions of white dots in the two groups would be A ± 0.5D. Then, we

106

randomly assigned the two calculated proportions to the left and right group, making sure that

107

in 50% trials there were more white dots in the left group.

108

To bind motor effort to the sampling process, we applied an artificial rule that the

109

sampling quality is in proportion to the distance between the agent and the stimulus. In natural

110

circumstances, it is interpreted as ‘the closer one gets to look at an object, the more details

111

will be seen’, and ‘getting closer’ needs motor effort. In our paradigm, the position and color

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

112

of each dot were fixed within the trial, but in each frame (frame rate 60 fps) a different set of

113

randomly selected dots were made invisible so that the dots were ‘blinking’ with varying

114

phase and rate. The number of invisible dots in each frame was in proportion to the current

115

distance between the mouse cursor and each dot stimulus, thus the closer the cursor was to the

116

stimulus, the more dots were visible in a certain period (Fig 1B). When the cursor was moved

117

to the leftmost, the left group of dots would become completely visible and static, while the

118

right group would be completely invisible. Therefore, to get better sampling quality, subjects

119

must make some motor effort to move the cursor closer to the stimulus they want to examine.

120
121

Fig 1. Illustration of the paradigm. (A) A fixation (1000 – 1500 ms) on the start position

122

with the mouse cursor was necessary to trigger each trial. After that, subjects moved the

123

cursor to the stimuli alternatively to sample them. Finally, subjects clicked on the

124

corresponding button to report which stimulus contained more white dots. (B) The number of

125

invisible dots per frame was in proportion to the distance between the cursor and the stimulus.

126

Subjects must move the cursor close to the stimulus to get better sampling quality.

127
128

At the beginning of each trial, a start position was randomly drawn within the central

129

80% range between the boundaries of the two stimuli, marked by a small white square on the

130

screen. Subjects should drag the computer mouse cursor onto the square and stay fixed for a

131

short time (1000 – 1500 ms randomly) to trigger the trial. After the fixation period, the two

132

stimuli would appear, and the subject could start to sample them. Subjects were told to avoid

133

pausing the cursor in the middle of the screen while looking sideways at the stimuli. We set

134

two sampling modes: In the one-switch mode, subjects should and could only make one

135

switching movement between the stimuli, which means they had only one chance to sample

136

each of the alternatives. When the cursor was moved close enough to the stimulus (visible

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

137

dots more than 90% per frame) and then left, that stimulus would be masked and could not be

138

examined again in the current trial. Subjects were instructed not to move their mouse to an

139

already masked stimulus. The length of time to examine each stimulus was not limited. In the

140

unlimited sampling mode, subjects could make as many switches and check each stimulus for

141

as many times as they needed.

142

The motor effort during the action stage took the form of moving the cursor to the

143

corresponding choice button and clicking on it to report the final choice. The choice buttons

144

were two small white squares displayed on the lower half of the screen, vertically 7 cm from

145

the centers of the stimuli. We set two types of trials differentiated by the location of the

146

choice buttons: In the first type, the buttons were horizontally centered, so the motor effort

147

(measured by the moving distance) to drag the cursor from the two stimuli to the buttons was

148

approximately the same. In the second type, the buttons were placed under the right stimulus,

149

so that the required motor effort would be less if the subject sampled the right stimulus last

150

and started from there to reach for the buttons.

151

The display screen size was 28.5 × 18 cm, resolution 1280 × 800 pixels, refresh rate

152

60 Hz. The screen was placed 50 – 70 cm in front of the subjects. System mouse acceleration

153

was disabled to make the cursor movement on the screen linearly map the actual movement of

154

the mouse. Subjects were told not to pick up the mouse from the surface of the desk amid

155

each trial. Mouse trajectory was recorded from the moment the trial was triggered to when a

156

button was clicked (sampling rate 60 Hz). We also recorded the final decision in each trial.

157

The stimuli and mouse tracking codes were programmed in MATLAB Psychtoolbox-3.

158
159

Participants and procedure

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

160

A total of 24 subjects participated in the study (13 females, age 20 – 30); all of them

161

were university students. Subjects wore glasses for vision correction if needed. The research

162

was approved by the institutional ethics committee of Eotvos Lorand University, Hungary.

163

All subjects provided informed written consent, and none declared any history of neurological

164

diseases.

165

To avoid previous experimental processes interfering with later sampling patterns, we

166

divided the subjects into 3 groups, each containing 8 subjects, and each group of subjects only

167

performed in a single experimental condition (Table 1). After 10 practice trials to get familiar

168

with the paradigm, each subject performed 2 blocks of 60 trials. A short break (5 – 10

169

minutes) took place between the blocks. The complete experiment took approximately 40 –

170

60 minutes per subject.

171

Table 1. Details of the experimental condition settings.
Condition

Sampling Mode

Choice Button Position

Female Subjects

Mean Age

Control

unlimited switches

horizontally centered

4/8

25.9

Right-Biased

unlimited switches

under the right stimulus

5/8

26.1

One-Switch

one switch only

horizontally centered

4/8

24.9

172
173

Data analysis

174

Sampling patterns

175

Decision time for a trial was defined as the elapsed time from the onset of the stimuli

176

to when the final decision was made, excluding the time of action execution. The dividing

177

line between the sampling stage and the action stage was the moment when a downward y-

178

axis component of the cursor velocity exceeded the threshold.

179
180

Horizontal moving distance during sampling was defined as the total moving distance
of the cursor on the screen along the x-axis within the sampling stage of a trial.

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

181

To test the linear relationship between the variables depicting sampling patterns, we

182

performed linear mixed-effects regressions with random effects for subject-specific intercepts

183

and slopes.

184

Psychometric curves

185

Psychometric curves were fitted to the data pooled across all subjects within each

186

group or all simulation trials in the same condition using the generalized linear model (GLM)

187

with the logit link function.

188

Comparing lines and curves

189
190

To compare two regression lines, we used a generalized ANCOVA allowing different
slopes and intercepts:

191

Y = β0 + β1 X + I (β2 + β3 X )

192

where β0, β1, β2 and β3 were free parameters, X was the predictor variable, and I was the

193

indicator variable whose value was 0 for the reference group and 1 for the other group.

194
195
196

(1)

To compare two psychometric curves, we fitted the data to the following logistic
function:

Y=

1
1+ e

− ( β0 + β1 X + I ( β2 + β3 X ))

(2)

197

Then, we tested the null hypotheses β2 = 0 and β3 = 0 with the two-tailed one-sample t-test to

198

compare the intercepts and slopes (steepness) of the two curves.

199
200

Bayesian Network modeling

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

201

We listed all three possible Bayesian Network models for different hypotheses

202

regarding the causal relationship between the decision variable before the last sampling, the

203

last sampled item and the final choice in the trial. The conditional probability of choosing the

204

right item given that it is last sampled was calculated under each hypothesis and compared

205

with the empirical results.

206

For mathematical details of the models, see S1 Supporting Information.

207

To calculate the conditional probability p(right chosen | right last sampled) from the

208

behavioral data, we first fitted a psychometric choice curve (probability of choosing the right

209

item vs. difference between the proportions of white dots in the stimuli) to the trials in which

210

the right item was sampled last for each subject individually, and then marginalized the

211

difference between the stimuli. The mean p(right chosen | right last sampled) across the

212

subjects in each group was compared with the value 0.5 (the probability without bias) using

213

the one-tailed one-sample t-test. The One-Switch group and the Right-Biased group were

214

compared with the Control group using Dunnett’s test after a one-way ANOVA.

215
216

aDDM simulation

217

We built our aDDM following Krajbich et al. [15]. We set the relative value (rleft and

218

rright) to the proportion of white dots in each stimulus. The range of rleft and rright in the

219

experiment was [0.25, 0.75]. The decision variable (DV) started from 0 in each simulation

220

trial, and the decision barriers were –1 for the left stimulus and +1 for the right stimulus. We

221

applied the multiplicative model [22]. The drift rates (v) in the model were defined as:

222

⎧ v = d (rleft − θ rright ), left attended
⎨
⎩v = d (θ rleft − rright ), right attended

(3)

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

223

where d was the value scaling parameter, and θ was the multiplicative attentional discounting

224

parameter. Specifically, during the first sampling, the unattended stimulus was assigned a

225

mean value rmean = 0.5 instead of the real value because the subject had not sampled that

226

stimulus yet. Let DVt denote the value of the decision variable at time t. For every time step

227

∆t,

228

DVt +Δt = DVt + vΔt + ε t

229

where εt was drawn from a zero-mean Gaussian distribution with standard deviation σ. We

230

assumed that the first sampling falls on the left stimulus with a fixed probability (Control:

231

0.59, One-Switch: 0.57, from empirical data), its duration drawn from a fixed gamma

232

distribution. Each successive sampling epoch fell alternatively on the left and right stimulus

233

and would continue until it reached a max time limit drawn from another fixed gamma

234

distribution or until the decision variable reached one barrier. The parameters of the two

235

gamma distributions were fitted with maximum likelihood estimation (MLE) to the empirical

236

sampling time data in the Control condition. Time step

237

subjects in the Control group, the max number of switches in a single trial was 10, so we

238

discarded simulations with more than 10 switches.

(4)

∆t was set to 10 ms. For human

239

We fitted the three parameters in the model (θ, d and σ) to the empirical data pooled

240

across all subjects: For each set of parameters, we ran a fixed number of valid simulations

241

(240 for the coarse search and 960 for the finer search) and compared the results with

242

behavioral data using the following error metric:

243

⎛
Err = ⎜
⎝

ya '− ya
ya

⎞
⎟
⎠

2

⎛
+⎜
⎝

yn '− yn
yn

⎞
⎟
⎠

2

(5)

244

where ya = 0.9042 and yn = 2.0698 were the accuracy and the mean number of switches

245

calculated from the 960 trials pooled across the 8 subjects in the Control group, while ya’ and

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

246

yn’ were the accuracy and the mean number of switches across all simulations. We performed

247

a grid search for the best fitting parameters: In the i-th iteration, we tested the parameter sets

248

given by the cross product of {θi1, θi2, θi3}, {di1, di2, di3} and {σi1, σi2, σi3}. Let (θi, di, σi)

249

denote the parameters that generated the smallest Err value, then in the (i+1)-th iteration we

250

tested a finer grid given by the cross product of {θi – 0.5∆θi, θi, θi + 0.5∆θi}, {di – 0.5∆di, di,

251

di + 0.5∆di} and {σi – 0.5∆σi, σi, σi + 0.5∆σi}, where ∆θi, ∆di and ∆σi were the step sizes used

252

in the i-th iteration. The initial values were {0.1, 0.5, 0.9} for θ, {0.001, 0.005, 0.009} for d,

253

and {0.01, 0.05, 0.09} for σ in the coarse search and {0.6, 0.7, 0.8} for θ, {0.004, 0.005, 0.006}

254

for d, and {0.03, 0.04, 0.05} for σ in the finer search. We stopped the iterations when the step

255

sizes became smaller than 0.5% of the parameter values. The final fitting results were θ =

256

0.67, d = 0.0051 and σ = 0.038.

257

For the One-Switch condition, we used the same set of parameters (θ, d and σ) in the

258

Control condition, but only two sampling epochs were allowed. The second sampling would

259

continue until the decision variable reached one barrier. We discarded the simulations in

260

which the second sampling exceeded 3000 ms, which was the max duration of the second

261

sampling for 99.5% empirical trials in the One-Switch condition. The decision time for the

262

simulations was calculated by adding the mean transition time (delay between the sampling

263

epochs) measured from behavioral data to the total time length of the sampling epochs in the

264

simulations.

265

We simulated the model for 960 valid trials (the same sample size as the empirical

266

data pooled across all subjects in each condition) using the best fitting parameters above for

267

the Control condition and the One-Switch condition separately and compared the results with

268

human behavioral data.

269

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

270

Results

271

General sampling patterns

272

Firstly, we studied the general sampling patterns in the Control condition. We plotted

273

the horizontal mouse cursor position recorded during the sampling stage against elapsed time

274

in each trial. Fig 2 shows the time series of the cursor position from a single block performed

275

by one subject: The 60 trials in the block were sorted by the start position. The horizontal

276

positions between the two stimuli were linearly mapped to [0, 1] and shown in a red-blue

277

color scale. The typical sampling pattern was to switch the cursor once or multiple times

278

between the two stimuli. The cursor paused mostly at either the leftmost or the rightmost,

279

meaning that only one of the stimulus was clearly visible at a time. Therefore, we can assume

280

that the eye gaze and the attention of the subject switched between the stimuli together with

281

the cursor, which enables the comparison between our paradigm and former sequential

282

sampling tasks and models.

283
284

Fig 2. Typical time series of the horizontal mouse cursor position during sampling. Data

285

were from a single block (60 trials) performed by one subject in the Control group and sorted

286

by the start position in each trial. Red color indicates that the current cursor position is closer

287

to the right stimulus, while blue indicates that the cursor is closer to the left.

288
289

If a subject made n switches in a trial, there would be n+1 sampling epochs

290

alternatively assigned to the two stimuli. Assuming that each sampling period has

291

approximately the same duration, the decision time should linearly correlate with the number

292

of switches in each trial. Moreover, most of the motor effort during sampling was spent on

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

293

switching the cursor from one stimulus to the other, the distance between them fixed.

294

Therefore, the total motor effort within a trial (measured by the horizontal moving distance of

295

the cursor) should also linearly correlate with the number of switches. Fig 3A shows the

296

histogram of the number of switches made in all 960 trials performed by subjects in the

297

Control group: In 42.5% trials only one switch was made, and the percentage of the trials

298

decreased as the switches made in them increased. Fig 3B and 3C show that the decision time

299

(linear mixed-effects regression: slope = 1276.6 ms, P = 2.8×10–21; Pearson’s r = 0.78) and

300

the horizontal moving distance (linear mixed-effects regression: slope = 17.8 cm, P = 2.6×10–

301

54

; Pearson’s r = 0.90) linearly correlated with the number of switches.

302
303

Fig 3. Number of switches within each trial, and its correlation with decision time and

304

horizontal moving distance. (A) Histogram of the number of switches. (B) Linear

305

correlation between decision time and number of switches during the trials. Mixed-effects

306

regression: slope = 1276.6 ms, P = 2.8×10–21; Pearson’s r = 0.78. (C) Linear correlation

307

between horizontal moving distance and number of switches during the trials. Mixed-effects

308

regression: slope = 17.8 cm, P = 2.6×10–54; Pearson’s r = 0.90. Data included 960 trials

309

pooled across 8 subjects in the Control group.

310
311

Influences of motor effort on sampling patterns

312

The total motor effort within one single trial consisted of three parts: first, to drag the

313

cursor from the start position to the first sampled item; second, to switch between the items

314

one or more times during sampling (each switch took approximately the same moving

315

distance, as discussed previously); third and lastly, to drag the cursor from the last sampled

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

316

item to the choice buttons. We studied how motor cost in the different parts interacted with

317

the decision-making process (Fig 4):

318
319

Fig 4. Right-Biased condition vs. Control condition. (A) Psychometric choice curves. (B)

320

Number of switches against trial difficulty, as measured by the absolute difference between

321

the proportions of white dots in the stimuli. (C) Psychometric curves for the first sampled

322

item. (D) Psychometric curves for the last sampled item. Error bars show 95% confidence

323

intervals. Data included 960 trials pooled across 8 subjects in each condition.

324
325

Fig 4A shows the psychometric choice curves in the Control and the Right-Biased

326

conditions: There was no statistically significant difference between the two curves (intercept:

327

P = 0.0958; slope: P = 0.1358), and the overall accuracy was also similar (Control: 90.4%;

328

Right-Biased: 91.5%; unpaired two-tail t-test between individual subjects in the two groups: P

329

= 0.4599). The difference in motor costs during the action phase did not bias the decisions of

330

the subjects in our experimental paradigm. One possible reason is that the difference was not

331

directly related to the final choice; another possibility is that explicit knowledge of the motor

332

cost would help to avoid integrating irrelevant factors into the decision to maintain high

333

accuracy [23].

334

We plotted the number of switches made in the trials against trial difficulty (measured

335

by the absolute difference between the proportions of white dots in the stimuli) in Fig 4B: In

336

both conditions, the number of switches decreased with trial difficulty (significant slopes in

337

mixed-effects regression: P = 4.8×10–10 for Control and P = 1.9×10–8 for Right-Biased). There

338

was no significant difference between the two conditions (intercept: P = 0.5216; slope: P =

339

0.8516). The motor cost during sampling correlated with the number of switches, therefore we

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

340

concluded that the more difficult the trials were, the more motor effort would be invested into

341

the sampling process.

342

Next, we examined the influences of motor cost upon the first and the last sampled

343

items. Fig 4C shows that the start position and the choice button position both affected the

344

first sampled item: In the Control condition, subjects tended to sample the item closer to the

345

start position, which would reduce the first part of the total motor cost. However, we observed

346

a systematic bias to sample the left item first, which may be related to the cultural habit of

347

dealing with items in left-to-right order (for example, people usually read from left to right).

348

In the Right-Biased condition, subjects showed an extra tendency to go for the left item first

349

(significantly different intercepts: P = 2.9×10–9). The subject was most likely to make only

350

one switch (Fig 3A); in that case, starting from the left item would lead to taking the shorter

351

path from the right item to the buttons, reducing the last part of the motor effort. In Fig 4D we

352

plotted the probability of sampling the right item last against the difference between

353

proportions of white dots in the two stimuli: Generally, subjects were more likely to sample

354

the stimulus with more white dots last. In the Right-Biased condition, subjects preferred to

355

sample the right stimulus last (significantly different intercepts: P = 2.9×10–6), which would

356

reduce the motor cost during the action phase.

357
358

Influences of the decision variable on sampling patterns

359

The last-sampling bias is the phenomenon that subjects are more likely to choose the

360

last sampled stimulus. Such a bias has been reported in several human decision-making

361

studies of both preferential and perceptual decisions [15, 17]. However, the causal

362

relationship behind the last-sampling bias is not completely clear: Do subjects tend to choose

363

a stimulus because it is the last sampled one, or do they tend to sample the particular stimulus

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

364

last because they already want to choose it, or both? According to the aDDM, the evidence

365

accumulation rate for the stimulus not being sampled is discounted, so the decision variable

366

will be more likely to reach the barrier at the last sampled side [15]. Otherwise, the aDDM

367

assumes that the current decision variable has no backward influence upon sampling patterns.

368

There is rare evidence supporting that the temporary decision has a causal effect on the

369

allocation of attention during sampling [19].

370

Bayesian Network modeling

371

To study the causal relationship between the last sampled item and the decision, we

372

built a Bayesian Network model quantifying the size of the last-sampling bias. Fig 5 displays

373

the graphical models for the networks: Naturally, the final decision depends on the decision

374

variable. In the One-Switch condition, the last sampled item is the alternative of the first

375

sampled one, which in turn depends on the motor cost measured by the distance from the start

376

position to the stimulus. In the Right-Biased condition, the last sampled item depends on the

377

motor cost in the action stage. Apart from the common dependency structures described

378

above, there are three possible models with different hypotheses on whether the last sampled

379

item depends on the decision variable and whether the final choice depends on the last

380

sampled item:

381
382

Fig 5. Causal relationship for the last-sampling bias. Graphical models for possible

383

hypotheses regarding the conditional dependency relationship between the decision variable

384

before the last sampling, the last sampled stimulus and the final choice. Arrows show

385

dependency between the events or variables, and dashed arrows show dependency assumed to

386

exist generally but absent in the specific experimental condition.

387

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

388

Model (a)

389

Like the aDDM, the first model assumes that the final decision depends on the last

390

sampled item, but the last sampled item is independent of the decision variable. Therefore, in

391

the Control condition we have:

(

p right chosen right last sampled

392

(

)

)

= ∫ p right chosen DV ,right last sampled p ( DV )dDV

(6)

393

where DV is the value of the decision variable exactly before the last sampling epoch starts.

394

p(right chosen | right last sampled) measures the size of the last-sampling bias. The bias is due

395

to the term p(right chosen | DV, right last sampled), which can be regarded as a function of

396

DV: For each given value of DV, p(right chosen | DV, right last sampled) > p(right chosen |

397

DV). In the aDDM, p(right chosen | DV, right last sampled) is the probability for the decision

398

variable to drift to the right boundary at the end of the last sampling, decided by the aDDM

399

parameters (d, σ and θ) and the relative values for the two stimuli.

400

In the One-Switch condition, the dependency structure between DV, the last sampled

401

item and the final choice remains the same, but the following analysis explains why the size

402

of the last-sampling bias will increase (see our aDDM simulation results): At the beginning of

403

each trial, the decision variable is set to 0; as the sampling time elapses, more drift steps (v∆t

404

+ εt) are added to the decision variable, so its variance increases. When only two sampling

405

epochs are allowed, the elapsed time before the last sampling is shorter, thus p(DV) will have

406

a narrower variance. In that case, the product of a biased p(right chosen | DV, right last

407

sampled) and p(DV) will be larger than that in the Control condition.

408

In the Right-Biased condition, the value of p(right chosen | right last sampled) will not

409

change because no term in Equation (6) depends on the motor cost to reach for the buttons.

410

Model (b)

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

411

On the contrary, the second model assumes that the last sampled item depends on DV,

412

but the final decision is independent of the last sampled item. Therefore, in the Control

413

condition,

414

p (right chosen | right last sampled)
p (right last sampled | DV )
= ∫ p(right chosen | DV )
p( DV )dDV
p (right last sampled)

415

Under that hypothesis, the last-sampling bias is due to the term p(right last sampled | DV),

416

which is also a function of DV: When DV > 0, p(right last sampled | DV) > p(right last

417

sampled); when DV < 0, p(right last sampled | DV) < p(right last sampled).

418

In the One-Switch condition, the last sampled item no longer depends on DV, so:

419
420

(7)

p (right chosen | right last sampled) = ∫ p(right chosen | DV ) p( DV )dDV

(8)

Thus p(right chosen | right last sampled) will fall back to 0.5.

421

In the Right-Biased condition, subjects tend to sample the right item last. We assumed

422

that such a tendency is independent of DV, so the probability p(right last sampled | DV) and

423

p(right last sampled) will rise by the same additive amount. Compared with the Control

424

condition, the term p(right last sampled | DV)p(right last sampled)–1 will become smaller

425

when DV > 0 and larger when DV < 0, resulting in a decreased size of the last-sampling bias.

426

Model (c)

427
428

This model shows a third possibility that the last sampled item depends on DV, and
the final decision also depends on the last sampled item. In the Control condition:
p (right chosen | right last sampled)

429

= ∫ p(right chosen | DV , right last sampled)

p (right last sampled | DV )
p ( DV ) dDV
p(right last sampled)

(9)

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

430

In Equation (9), the total bias in p(right chosen | right last sampled) has two sources: p(right

431

chosen | DV, right last sampled) and p(right last sampled | DV). The last sampled item is more

432

likely to be chosen, and the temporarily winning item is more likely to be sampled last.

433

Under such assumptions, the last-sampling bias should remain in the One-Switch

434

condition because the term p(right chosen | DV, right last sampled) is biased, but the size will

435

decrease because the term p(right last sampled | DV) now disappears.

436

In the Right-Biased condition, p(right chosen | right last sampled) will also become

437

smaller similar to that in Model (b).

438

Model predictions vs. empirical results

439

Let pControl, pOne-Switch and pRight-Biased denote p(right chosen | right last sampled) in each

440

specific experimental condition. We summarized different model predictions and the

441

empirical results in Table 2: Among the three hypotheses, only Model (c) correctly predicted

442

the behavioral data. Therefore, we concluded that the causal relationship between sampling

443

patterns and the decision is bidirectional.

444
445

Table 2. Summary of different model predictions about the last-sampling bias and the

446

empirical results.

(a)

(one-sample t-test, P = 2.0×10–5)

pOne-Switch > pControl (×)

pOne-Switch > 0.5**

pRight-Biased = pControl (×)
pControl > 0.5
(b)

pOne-Switch = 0.5 (×)
0.5 < pRight-Biased < pControl
pControl > 0.5

(c)

pControl > 0.5***

Predictions
pControl > 0.5
Empirical Results

Model

(one-sample t-test, P = 0.0018)

pOne-Switch < pControl***
(Dunnett’s test, P = 5.9×10–4)

pRight-Biased > 0.5**
(one-sample t-test, P = 0.0037)

0.5 < pOne-Switch < pControl

pRight-Biased < pControl**

0.5 < pRight-Biased < pControl

(Dunnett’s test, P = 0.0018)

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

447
448

pControl, pOne-Switch and pRight-Biased denote p(right chosen | right last sampled) in each

449

experimental condition. The conditional probability measures the size of the last-sampling

450

bias, and a value of 0.5 means that there is no bias. **P < 0.01, ***P < 0.001. The cross (×)

451

marks that the prediction contradicted empirical results.

452
453

aDDM simulation

454

On top of the theoretical Bayesian Network analysis, we also ran an aDDM simulation

455

to test whether the decision variable can feedback into the sampling patterns. In our

456

simulations, each sampling epoch was focused alternatively on the two stimuli until it reached

457

a time limit randomly drawn from a distribution fitted to the empirical data. In the One-

458

Switch condition, only one switch of attention was allowed. Each simulation ended when one

459

of the decision boundaries was reached. Therefore, the allocation of attention in the aDDM

460

was independent of the current decision variable. Fig 6 shows the comparison between

461

simulated and empirical results:

462
463

Fig 6. aDDM simulation results vs. empirical data. (A) Psychometric choice curve in the

464

Control condition. (B) Number of switches in the Control group against trial difficulty, as

465

measured by the absolute difference between the proportions of white dots in the stimuli. (C)

466

Last-sampling bias in the Control group. The horizontal axis shows the difference between the

467

proportions of white dots between the last sampled stimulus and the other, while the vertical

468

axis shows the probability of choosing the last sampled stimulus. (D) Psychometric choice

469

curve in the One-Switch condition. (E) Decision time in the One-Switch group against trial

470

difficulty. (F) Last-sampling bias in the One-Switch group. Error bars show 95% confidence

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

471

intervals. Empirical data included 960 trials pooled across 8 subjects in each condition;

472

simulated data included 960 trials in each condition.

473
474

Firstly, we compared the psychometric choice curves: There was no statistically

475

significant difference between the psychometric choice curves for the simulations and the

476

human subjects (intercept: P = 0.0679; slope: P = 0.0610) in the Control condition (Fig 6A).

477

In the One-Switch condition, there was no significant difference between the intercepts of the

478

curves (P = 0.7116), but the slope (steepness) for the simulated data was significantly smaller

479

than that of the empirical data (P = 3.2×10–4), meaning that the overall accuracy in the

480

simulations was lower (Fig 6D). When only one switch was allowed, the choice accuracy of

481

the simulations reduced from 90.1% to 84.4%, while for the human subjects there was no

482

significant reduction (unpaired one-tail t-test between individual subjects in the two groups: P

483

= 0.8082).

484

Next, we compared the number of switches in the Control condition (Fig 6B): There

485

was no statistically significant difference between the simulated and empirical results

486

regarding the number of switches against trial difficulty (intercept: P = 0.2690; slope: P =

487

0.2384). In the One-Switch condition, we compared the decision time instead of the number

488

of switches (for it is constantly 1): There was no significant difference between the simulated

489

and empirical results regarding the decision time against trial difficulty ((Fig 6E, intercept: P

490

= 0.6125; slope: P = 0.2257).

491

Finally, we focused on the last-sampling bias: In Fig 6C and 6E, we plotted the

492

probability of choosing the last sampled item against the difference between the proportions

493

of white dots between the last sampled stimulus and the other. All the curves had an intercept

494

larger than 0.5, showing a tendency to choose the last sampled item, but the sizes of the bias

495

were different: The curve intercept for the simulations was significantly lower than empirical

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

496

(P = 5.8×10–4) in the Control condition and significantly higher than empirical (P = 0.0166) in

497

the One-Switch condition. Denying that subjects would switch back to sample the winning

498

item but assuming random switches all the while, the aDDM underestimated the last-sampling

499

bias in the Control condition and overestimated it in the One-Switch condition. The

500

simulation results matched our Bayesian Network analysis and implied that the current

501

decision had a causal effect on the sampling patterns.

502
503

Discussion

504

In summary, the adaptive sampling behavior during perceptual decision-making

505

exhibited the following patterns: First, the number of switches between the alternatives

506

correlated with the difficulty of the task: the more difficult the task was, the more times the

507

stimuli were resampled. Second, the sampling sequence was decided considering the start

508

position and the choice button position in an attempt to minimize the total motor effort. Third,

509

attention was biased to the eventually chosen item during the last sampling epoch. Combining

510

the modeling results, we concluded that both motor cost and the temporary decision have a

511

causal influence upon the pattern of attention allocation during sampling.

512

Having reviewed recent computational models, behavioral studies and neural

513

recording results, Wispinski et al. [24] concluded that decision-making is a continuous

514

process from the presentation of behaviorally relevant options until movement completion.

515

Previous studies suggested that motor effort related to the action phase can influence the

516

decision [4-6, 8], and our results provided an extended conclusion that sampling behavior was

517

also influenced by the motor effort in different stages of the decision-making process. It

518

supported the idea that sensorimotor aspects should be considered as an actively integrated

519

part of the decision-making process. Further, several studies focused on the representation of

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

520

motor effort and how it is related to cost minimization in decision-making as well as motor

521

control [25, 26]; future studies may quantify the effect of motor cost on sampling behavior

522

with similar methods.

523

The relationship between attention and eye movement during decision-making has

524

been studied abundantly [27], but researches highlighting limb and body movements during

525

the sampling process are rare, even though in naturalistic circumstances such movements

526

usually cooperate with eye movements to sample relevant information better. In our research,

527

we designed a paradigm based on computer mouse tracking in which both gaze shift and hand

528

movement (moving the mouse) were necessary to switch attention between the options.

529

Although mouse tracking and eye tracking are both commonly applied process tracking

530

methods in decision-making research, their original purposes are slightly different: While eye

531

tracking mostly target on attention and information searching strategies, mouse cursor

532

tracking data reflect more about indecision and momentary preference [28]. In our paradigm,

533

however, subjects must move the cursor closer to get a better view of each stimulus, as if

534

approaching a real object to have a better look. In this way, the mouse trajectory can reflect

535

attention during sampling as eye traces did in previous studies. Moreover, our paradigm can

536

be applied to study eye-hand cooperation and coordination during decision-making as well.

537

Traditionally, sequential sampling models assume that during decision-making,

538

subjects sample their options continuously until the relative evidence for one option reaches a

539

predetermined threshold, and such models capture the speed-accuracy trade-off phenomenon

540

well [19, 29, 30]. Interestingly, our results showed that subjects would make extra sampling

541

epochs during which the accuracy of the decision has not been improved significantly. One

542

possible explanation is that subjects were switching back to the previously sampled stimuli

543

again to verify their preliminary decision [31]. Similar to other studies [18, 32, 33], we

544

observed an attentional bias to the finally chosen option during the later sampling epochs.

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

545

Mullett and Stewart [32] suggested that such a bias may be due to a relative instead of

546

absolute stopping rule. According to Krajbich [19], even as the decision variable evolves and

547

one option emerges as the winning one, it is still optimal to continue sampling information

548

randomly instead of favoring the leading option, since the information from both the winning

549

and losing options are of equal importance. However, the accuracy of the decision will not

550

necessarily decrease if the attentional bias happens at the later stage of sampling when the

551

main task is to validate the decision. This validating phase may be longer for perceptual

552

decisions, for people tend to respond with more caution in perceptual decisions than in

553

preferential decisions, especially when the stimuli are ambiguous [34]. Meanwhile, how the

554

sub-thresholds within the preliminary decision phase and the validating phase are determined

555

remains to be discussed.

556

Finally, our study provided evidence for the bidirectional causal relationship between

557

attention and decisions by Bayesian Network modeling. Bayesian Networks have been

558

customarily applied for probabilistic causal dependence assessment and inference in a wide

559

range of areas [35], including life science researches [36, 37]. It is capable of depicting and

560

predicting the conditional dependences between experimental variables through observed

561

data, thus becomes a beneficial tool for psychological studies. In our study, we listed all

562

possible network structures corresponding to different hypotheses on the causal relationship

563

between the last sampled item, the decision variable and the chosen item. Then, we compared

564

the predicted conditional probability of choosing the last sampled item with empirical data.

565

Contrary to previous literature [19], our results imply that rather than randomly switching

566

between the options, attention is drawn to the winning item during sampling. This finding

567

may lead to some modification to the basic assumptions of the aDDM in the future.

568

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

569

Acknowledgements

570

We would like to express our sincere gratitude to Prof. László Mérő’s supervision as

571

well as his support and encouragement. We are also grateful for the help on practical issues

572

from the Faculty of Education and Psychology ELTE and the kind participation of all the

573

subjects in the experiments.

574
575
576

References
1. Lepora NF, Pezzulo G. Embodied choice: how action influences perceptual decision

577

making. PLoS computational biology. 2015 Apr 7;11(4):e1004110. doi:

578

10.1371/journal.pcbi.1004110

579

2. Connors BL, Rende R. Embodied Decision-Making Style: Below and Beyond

580

Cognition. Frontiers in psychology. 2018;9. doi: 10.3389/fpsyg.2018.01123

581

3. Filimon F, Philiastides MG, Nelson JD, Kloosterman NA, Heekeren HR. How

582

embodied is perceptual decision making? Evidence for separate processing of

583

perceptual and motor decisions. Journal of Neuroscience. 2013 Jan 30;33(5):2121-36.

584

doi: 10.1523/JNEUROSCI.2334-12.2013

585

4. Aczel B, Szollosi A, Palfi B, Szaszi B, Kieslich PJ. Is action execution part of the

586

decision-making process? An investigation of the embodied choice hypothesis.

587

Journal of Experimental Psychology Learning Memory and Cognition.

588

2018;44(6):918-926. doi: 10.1037/xlm0000484

589
590
591
592

5. Marcos E, Cos I, Girard B, Verschure PF. Motor cost influences perceptual decisions.
PLoS One. 2015 Dec 16;10(12):e0144841. doi: 10.1371/journal.pone.0144841

6. Hagura N, Haggard P, Diedrichsen J. Perceptual decisions are biased by the cost to act.
Elife. 2017 Feb 21;6:e18422. doi: 10.7554/eLife.18422

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

593

7. de Lange FP, Fritsche M. Perceptual decision-making: picking the low-hanging fruit?.

594

Trends in cognitive sciences. 2017 May 1;21(5):306-7. doi: 10.1016/j.tics.2017.03.006

595

8. Burk D, Ingram JN, Franklin DW, Shadlen MN, Wolpert DM. Motor effort alters

596

changes of mind in sensorimotor decision making. PLoS One. 2014 Mar

597

20;9(3):e92681. doi: 10.1371/journal.pone.0092681

598

9. Harris CM, Wolpert DM. The main sequence of saccades optimizes speed-accuracy

599

trade-off. Biological cybernetics. 2006 Jul 1;95(1):21-9. doi: 10.1007/s00422-006-

600

0064-

601
602
603

10. Armel KC, Beaumel A, Rangel A. Biasing simple choices by manipulating relative
visual attention. Judgment and Decision making. 2008;3(5):396-403.

11. Lim SL, O'Doherty JP, Rangel A. The decision value computations in the vmPFC and

604

striatum use a relative value code that is guided by visual attention. Journal of

605

Neuroscience. 2011 Sep 14;31(37):13214-23. doi: 10.1523/JNEUROSCI.1246-

606

11.2011

607

12. Atalay AS, Bodur HO, Rasolofoarison D. Shining in the center: Central gaze cascade

608

effect on product choice. Journal of Consumer Research. 2012 May 3;39(4):848-66.

609

doi: 10.1086/665984

610

13. Bird GD, Lauwereyns J, Crawford MT. The role of eye movements in decision

611

making and the prospect of exposure effects. Vision Research. 2012 May 1;60:16-21.

612

doi: 10.1016/j.visres.2012.02.014

613

14. Kunar MA, Watson DG, Tsetsos K, Chater N. The influence of attention on value

614

integration. Attention, Perception, & Psychophysics. 2017 Aug 1;79(6):1615-27. doi:

615

10.3758/s13414-017-1340-7

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

616

15. Krajbich I, Armel C, Rangel A. Visual fixations and the computation and comparison

617

of value in simple choice. Nature neuroscience. 2010 Oct;13(10):1292. doi:

618

10.1038/nn.2635

619

16. Krajbich I, Rangel A. Multialternative drift-diffusion model predicts the relationship

620

between visual fixations and choice in value-based decisions. Proceedings of the

621

National Academy of Sciences. 2011 Aug 16;108(33):13852-7. doi:

622

10.1073/pnas.1101328108

623

17. Tavares G, Perona P, Rangel A. The attentional drift diffusion model of simple

624

perceptual decision-making. Frontiers in neuroscience. 2017 Aug 24;11:468. doi:

625

10.3389/fnins.2017.00468

626
627
628
629
630

18. Shimojo S, Simion C, Shimojo E, Scheier C. Gaze bias both reflects and influences
preference. Nature neuroscience. 2003 Dec;6(12):1317. doi: 10.1038/nn1150

19. Krajbich I. Accounting for attention in sequential sampling models of decision making.
Current opinion in psychology. 2018 Oct 13. doi: 10.1016/j.copsyc.2018.10.008

20. Gottlieb J. Understanding active sampling strategies: Empirical approaches and

631

implications for attention and decision research. Cortex. 2018 May 1;102:150-60. doi:

632

10.1016/j.cortex.2017.08.019

633

21. Ludwig CJ, Evens DR. Information foraging for perceptual decisions. Journal of

634

Experimental Psychology: Human Perception and Performance. 2017 Feb;43(2):245.

635

doi: 10.1037/xhp0000299

636
637

22. Smith SM, Krajbich I. Gaze amplifies value in decision making. Psychological science.
2019 Jan;30(1):116-28. doi: 10.1177/0956797618810521

638

23. Hagura N, Diedrichsen J, Haggard P. Action cost biases the perceptual decision

639

making, only when the cost is implicit. Translational and Computational Motor

640

Control, 2013.

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

641

24. Wispinski NJ, Gallivan JP, Chapman CS. Models, movements, and minds: bridging

642

the gap between decision making and action. Annals of the New York Academy of

643

Sciences. 2018 Oct 1. doi: 10.1111/nyas.13973

644

25. Shadmehr R, Huang HJ, Ahmed AA. A representation of effort in decision-making

645

and motor control. Current biology. 2016 Jul 25;26(14):1929-34. doi:

646

10.1016/j.cub.2016.05.065

647

26. Morel P, Ulbrich P, Gail A. What makes a reach movement effortful? Physical effort

648

discounting supports common minimization principles in decision making and motor

649

control. PLoS biology. 2017 Jun 6;15(6):e2001323. doi:

650

10.1371/journal.pbio.2001323

651

27. Orquin JL, Loose SM. Attention and choice: A review on eye movements in decision

652

making. Acta psychologica. 2013 Sep 1;144(1):190-206. doi:

653

10.1016/j.actpsy.2013.06.003

654

28. Schulte-Mecklenbeck M, Johnson JG, Böckenholt U, Goldstein DG, Russo JE,

655

Sullivan NJ, Willemsen MC. Process-tracing methods in decision making: On

656

growing up in the 70s. Current Directions in Psychological Science. 2017

657

Oct;26(5):442-50. doi: 10.1177/0963721417708229

658

29. Heitz RP. The speed-accuracy tradeoff: history, physiology, methodology, and

659

behavior. Frontiers in neuroscience. 2014 Jun 11;8:150. doi:

660

10.3389/fnins.2014.00150

661

30. Forstmann BU, Ratcliff R, Wagenmakers EJ. Sequential sampling models in cognitive

662

neuroscience: Advantages, applications, and extensions. Annual review of psychology.

663

2016 Jan 4;67:641-66. doi: 10.1146/annurev-psych-122414-033645

bioRxiv preprint doi: https://doi.org/10.1101/637017; this version posted August 3, 2019. The copyright holder for this preprint (which was not
certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made available under
aCC-BY 4.0 International license.

664

31. Cassey TC, Evens DR, Bogacz R, Marshall JA, Ludwig CJ. Adaptive sampling of

665

information in perceptual decision-making. PloS one. 2013 Nov 27;8(11):e78993. doi:

666

10.1371/journal.pone.0078993

667
668
669

32. Mullett TL, Stewart N. Implications of visual attention phenomena for models of
preferential choice. Decision. 2016 Oct;3(4):231. doi: 10.1037/dec0000062

33. Onuma T, Penwannakul Y, Fuchimoto J, Sakai N. The effect of order of dwells on the

670

first dwell gaze bias for eventually chosen items. PloS one. 2017 Jul

671

19;12(7):e0181641. doi: 10.1371/journal.pone.0181641

672

34. Dutilh G, Rieskamp J. Comparing perceptual and preferential decision making.

673

Psychonomic bulletin & review. 2016 Jun 1;23(3):723-37. doi: 10.3758/s13423-015-

674

0941-1

675

35. Heckerman D, Breese JS. Causal independence for probability assessment and

676

inference using Bayesian networks. IEEE Transactions on Systems, Man, and

677

Cybernetics-Part A: Systems and Humans. 1996 Nov;26(6):826-31. doi:

678

10.1109/3468.541341

679
680
681

36. Friedman N. Inferring cellular networks using probabilistic graphical models. Science.
2004 Feb 6;303(5659):799-805. doi: 10.1126/science.1094068

37. Yu J, Smith VA, Wang PP, Hartemink AJ, Jarvis ED. Advances to Bayesian network

682

inference for generating causal networks from observational biological data.

683

Bioinformatics. 2004 Jul 29;20(18):3594-603. doi: 10.1093/bioinformatics/bth448

684
685

Supporting information

686

S1 Supporting Information. Mathematical details of the Bayesian Network modeling.

687

S2 Video. Demo trials recorded from the screen.

