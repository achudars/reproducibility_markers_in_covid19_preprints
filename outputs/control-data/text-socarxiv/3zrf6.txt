ASCII Affect:
A comparison of emoticons and facial expressions in affective priming

by
Brittney O'Neill
A thesis submitted in partial fulfillment of the requirements for the degree of
HONOURS BACHELOR OF ARTS
in the Department of Linguistics

Dr. Alexandra D’Arcy (Department of Linguistics)
Supervisor
Dr. Sonya Bird (Department of Linguistics
Supervisor

© Brittney O'Neill, 2013
University of Victoria
All rights reserved. This thesis may not be reproduced in whole or in part, by photocopy
or other means, without permission of the author.

ii

ASCII Affect:
A comparison of emoticons and facial expressions in affective priming

Brittney O'Neill

iii
Abstract
The effects of emoticons in textual computer-mediated communication (CMC)
remain relatively unexplored. CMC researchers have suggested that emoticons behave
much as do facial expressions in face-to-face interaction (e.g. Danet, Ruedenberg-Wright,
& Rosenbaum-Tamari, 1997; Rezabek & Cochenour, 1998; Thompson & Foulger, 1996).
Some fMRI research suggests, however, that there is not a direct neural correspondence
between emoticons and facial expressions, but that emoticons play an important role in
determining the positive or negative valence of an utterance (Yuasa, Saito, & Mukawa,
2011). Following the affective priming paradigm developed by Fazio, Sanbonmatsu,
Powell, and Kardes (1986), this study explores the priming effects of emoticons vis-à-vis
photographs of facial expression and emotional words on valence judgements of
emotionally charged words. Significant main effects of age, prime valence, and target
valence were found. There were also significant interactions between these three factors.
Overall results suggest that younger and older participants have differing experiences of
emoticons, with younger participants experiencing an effect of emoticons that is similar
to the effect of facial expressions while older adults seem to experience emoticons in
ways more like textual information or even just textual nonsense.

iv
Table of Contents
1. Introduction

1

2. Literature Review

2

2.1. Assumed Emotion

2

2.2. Emoticons in Use

4

2.3. Perception of Emoticons

9

2.4. Emoticons in the Brain

11

2.5. Affective Priming

12

3. Research Questions and Hypotheses

14

4. Methodology

16

4.1. Participants

16

4.2. Materials

17

4.3. Procedure

18

5. Results

19

5.1. Demographic Notes

19

5.2. Experimental Results

22

5.2.1. Statistical Analyses

23

5.2.2. Effects of Age

24

5.2.3. Effects of Prime Type

25

5.2.4. Positivity and Other Valence Effects

27

5.3. Revisiting the Research Questions
6. Discussion

33
35

6.1. Emoticons: Effective but not Affective

37

6.2. The Affective Priming Paradigm

38

6.3. Further Research and Limitations

38

7. Conclusion

40

References

42

Appendix A

49

v
List of Tables
Table 1: Accuracy of responses

23

Table 2: RT by prime type

25

Table 3: RT for faces and words by age cohort

26

Table 4: RT by prime type and cohort

26

Table 5: RT for 16-25 year old cohort across target and prime valence

28

Table 6: RT for the 18-25 year old cohort in across prime types over
prime and target valence

29

Table 7: Most effective valence effect by prime type for the
18-25 year-old cohort

30

Table 8: RT for 45-65 year old cohort across target and prime valence

31

Table 9: RT for the 45-65 year old cohort in faces and words over prime

32

and target valence
Table 10: RT for the 45-65 year old cohort in emoticons over prime and
target valence

33

List of Figures
Figure 1: Frequency of use by platform (45-65 year olds)

19

Figure 2: Frequency of use by platform (18-25 year olds)

20

Figure 3: Frequency of emoticon use by platform (45-65 year olds)

21

Figure 4: Frequency of emoticon use by platform (18-25 year olds)

21

The ASCII Affect:
A comparison of emoticons and facial expressions in affective priming

1. Introduction
In an increasingly digital world, ever more social interaction is taking place
online. Between Facebook, Twitter, instant messaging (IM), email, and a plethora of
other social networking tools, more and more of our social lives are being channelled
through devices. Many researchers have investigated the consequences of this shift
towards using CMC, from users’ choice of communication medium (e.g. Riordan &
Kreuz, 2010), to its impact on the academic performance of youth (e.g. Drouin & Davis,
2009; Plester, Wood, & Joshi, 2009), its functional implications within corporations (e.g.
Luor, Wu, Lu, & Tao. 2010; O’Kane & Hargie, 2006), and even impacts on gender
expression and relations (e.g. Baron, 2004; Kapidzic & Herring, 2011). Though many
studies touch on emoticons (e.g. Baron, 2004; Riordan & Kreuz, 2010), few thoroughly
explore and explain their role and nature. In this study, the degree of functional similarity
between American Standard Code for Information Exchange (ASCII) emoticons and
facial expressions was explored through priming, in order to better understand how
emoticons affect our judgements of valence in computer mediated communication
(CMC).
In section 2, a selection of existing literature on studies of emoticons and affective
priming is presented. Following the literature review, in section 3, the questions and
corresponding hypotheses driving this research are laid out. Section 4 describes the

2
methodology while the results are found in section 5. Moving into section 6, the results
and their implications and limitations are discussed. Section 7 presents the conclusion.

2. Literature Review
2.1. Assumed Emotion
It seems to be common practice to assume that emoticons are, as their name
suggests, “emotional icons”. Researchers state that emoticons are “visual cues formed
from ordinary typographical symbols that when read sideways represent feelings or
emotions” (Rezabek & Cochenour, 1998, p. 201), or “icons for the expression of
emotion” (Danet, Ruedenberg-Wright, & Rosenbaum-Tamari, 1997, n.p.) and that they
are used “as surrogates for nonverbal communication” (Thompson & Foulger, 1996, p.
226). A few, however, have sought to investigate the potential illocutionary and verbal
role of emoticons. In the following section we explore their findings.
After a detailed study of emoticon distribution in IM, Garrison, Remley, Thomas,
and Wierszewski (2011) conclude that emoticons are conventionalized paralinguistic
markers in CMC. They argue that emoticons are independent semiotic units that neither
compensate for lack of visual cues, nor act as supplementary icons to the message’s text,
instead they indicate meaning as would a non-emoticon symbol such as a checkmark.
Though Garrison et al. (2011) do not draw conclusions as to the ultimate relationship
between emoticons and facial expression, the notion of emoticons as independent units of
meaning, which may occur with or without linguistic information and which play
important communicative and expressive roles, is strikingly similar to the role of facial
expression in face-to-face (FTF) communication (Buck, 1994).

3
Taking a somewhat different tack, Lo (2008) suggests that emoticons are “quasinonverbal cues” (p. 595), because, though they help convey valence or emotional cues,
they are also typed deliberately and therefore have the intentionality of verbal
information. Authors such as Lo (2008) and Walther and D’Addario (2001) claim that
emoticons are unlike facial expression insofar as they are voluntary and actively
presented, but facial expression can also be voluntarily produced to achieve a
communicative rather than an emotionally expressive goal (e.g. smiling when
encountering an annoying acquaintance to fulfil social expectations). Thus, it seems that
intentionality is insufficient for distinguishing emoticons and facial expression or other
nonverbal cues.
Finally, Dresner and Herring (2010) use Speech Act Theory to frame emoticons
as indicators of illocutionary force rather than solely emotional content. The authors
suggest that emoticons appear in places where the corresponding facial expression would
not, even if said facial expressions were voluntary. Such an argument, though potentially
persuasive, lacks empirical proof and is questioned by the researchers’ own findings that
subjects may smile to lighten an otherwise heavy statement as found in online discussions
of struggles with fibromyalgia. Moreover, despite their efforts to distance emoticons
from “emotional icons”, Dresner and Herring (2010) concede that at least some portion of
the role of emoticons in CMC is that of indicating emotion and standing in for facial
expression.
On the basis of prevailing opinion and the concessions of dissenters, it seems
reasonable to assume that emoticons are at least sometimes representations of emotional
facial expression. However, this is not tantamount to evidence that emoticons act as

4
facial expressions. Researchers have tackled this problem in several ways: by observing
the distribution of emoticons in use in experimentally elicited writing samples or
naturally occurring data, by testing perceptual reaction to emoticons in experimental
stimuli, and by observing subjects’ brain activity while viewing emoticons and text.
2.2. Emoticons in Use
Investigation of naturally occurring data consistently finds three major trends of
emoticon distribution: emoticons do not occur as often as the popular media implies,
women use more emoticons than men, and the most frequently used emoticon is the
smiley :), closely followed by other positive or “joke-y” emoticons such as :P, ;), and :D.
Though not straightforwardly related to the emoticon’s role as an ASCII facial
expression, these trends are sufficiently established to warrant discussion.
Within a corpus of 11, 718 words drawn from the IMs of college students and
recent college graduates, Baron (2004) found only 49 emoticons (0.004% of total).
Similarly, Garrison et al. (2011) found only 301 emoticons in a corpus amounting to a
total of 32,000 words (0.009% of total) drawn from the IMs of college students. Tossell,
Kortum, Shepard, Barg-Walkow, Rahmati, and Zhong’s (2012) study of naturally
occurring text messages from college students found that only 4.24% of 158,098
messages contained emoticons. Such paucity of emoticons seems to call into question
their role as facial expressions as FTF conversation is paired with frequent facial
expressions. Positive or so-called neutral facial expressions were present an average of
62.16% of the time in conversations between the adolescents studied by Turkstra, Ciccia,
and Seaton (2003). Since emoticons are volitionally produced, however, it is possible that
they are limited to expressing only those facial expressions that are also voluntarily

5
displayed. Just as Reisenzein, Bördgen, Holtbernd, and Matz (2006) found that only 425% of participants displayed facial indicators of surprise despite indicating that they felt
surprise during the experiment, users of emoticons may choose to withhold a visual
expression of their feeling. Reisenzein et al. (2006) also found that no participants
displayed the full three part “surprise” expression and so, given that emoticons tend to be
exaggerated and categorical, their use may be similarly limited. Whereas facial
expressions are socio-culturally conditioned (Russell, 1994) and develop prior to
language production (Fogel & Thelen, 1987; Steiner, 1979), emoticons remain a
comparatively new phenomenon developed on message boards in the early 1980’s
(Raymond, 1994); their use in all cases follows literacy. Thus, unlike facial expression,
which is innate, even if sometimes chosen, and well established in human cultures,
emoticons, and CMC in general, are fairly recently learned skills which continue to
undergo “domestication” (Baron, 2007, p. 4), the process by which a new technology
becomes an accepted part of everyday life.
In spite of the generally low frequency of emoticons found in CMC, studies have
also found that women (or users that appear to be women) generally use more emoticons
than their male counterparts. Baron (2004) found a distinct difference between male and
female emoticon use: three quarters of female participants used emoticons while only one
sixth of male participants used them. Wolf (2000) also found that women used more
emoticons in all-female USENET newsgroups than did men in all-male newsgroups.
Interestingly, however, in mixed gender groups, male use increased such that the
difference in emoticon use was not statistically significant. Wolf (2000, p. 832-833) links
this difference in use to women’s extension of emoticon use for purposes of solidarity,

6
support, assertion of positive feelings, and thanks. In FTF self-disclosing and supportive
interactions, people tend to use more supportive and empathetic facial expression and so
emoticons may simply be playing the corresponding supportive role in women’s CMC.
This phenomenon may also be related women’s tendency to be more emotionally
expressive (Buck, Savin, Miller, & Caul, 1972). Therefore, despite the paucity of
emoticons overall, women’s increased emoticon use may be a direct translation from
increased use of emotive facial expression.
Numerous studies have also found that the regular smiley, :), is the most
commonly used emoticon (e.g. Baron, 2004; Wolf, 2000; Garrison et al., 2011; Rezabek
& Cochenour, 1998). A potential explanation for this tendency is suggested by the
findings of Walther and D’Addario (2001). In looking at perceptions of emails with
embedded emoticons, Walther and D’Addario (2001) found that any negative element,
whether verbal or symbolic, caused the entire utterance to be interpreted as negative
regardless of the valence of the other component. It seems that negative items have
sufficient power to control an entire utterance’s valence. Following the Gricean
Cooperative Principle (Grice, 1975), communication is a cooperative enterprise and so,
strongly negative expressions are less favourable than positive or cooperative ones. As
such, negative emoticons may turn up less frequently than positive ones, given the aim of
perpetuating cooperative communication through softening and other cooperative actions
rather than through negativity. Similarly, negative facial expressions tend to be used at
far lower frequencies than positive or neutral facial expressions, especially among
adolescents (Readdick & Mullis, 1997, Turkstra et al., 2003).

7
Following these general trends, it appears that emoticons may, for their producers,
act in much the same way as volitional, facial expressions – especially those that have an
impact upon the interpretation of the message. Nonetheless, understanding of emoticons
is still emergent and an account of CMC users’ actual motivations for emoticon use is
lacking. Entering into finer analyses and more emoticon specific research, studies have
also found a variety of trends in distribution and motivations for use (e.g. Derks, Bos, and
Grumbkow, 2004; Provine, Spencer, and Mandell, 2007).
Studying naturally occurring emoticons on Internet message boards, Provine et al.
(2007) found that emoticons, like laughter in FTF, tend to punctuate strings of text. They
occur almost categorically at utterance or phrase boundaries, unable to interrupt verbal
information, suggesting that they are, like laughter, produced by a separate system
competing with the linguistic system, and coordinated linguistically rather than simply by
allocation of motor systems (Provine et al., 2007, p. 300). If emoticons are distributed so
similarly to laughter, and laughter is a paralinguistic (and therefore non-verbal) act, then
it seems logical to hypothesize that emoticons are also paralinguistic acts and therefore
may be assumed to carry non-verbal information just like laughter and facial expression.
Beyond punctuation, emoticons also seem to function in improving the user
experience by enhancing feelings of solidarity and enjoyment. Huang, Yen, and Zhang’s
(2008) survey of college students indicated that use of emoticons had a generally positive
effect on communication, increasing the user’s “enjoyment, personal interaction,
perceived information richness, and perceived usefulness” (p. 466). Rivera, Cooke, and
Bauhs (1996) found that emoticon users were generally more satisfied with an
experimental CMC system than were non-users. These effects are not dissimilar to those

8
that are generally associated with use of facial expressions. Facial expressions facilitate
communication through the sharing of emotions and the creation of shared intentionality
which allows the receiver to have a concept of their interlocutor’s mind (Tomasello,
Carpenter, Call, Behne, & Moll, 2005).
Emoticons appear to pattern like facial expression in varying socio-emotional
contexts. Derks et al. (2004) found that subjects in an experimental setting used more
emoticons in social versus task-oriented conditions. They argue that this is analogous to
emotional expression as it is “more appropriate to show one’s emotions and feelings
towards friends than towards colleagues” (p. 846). In further work, Derks, Bos, and
Grumbkow (2008b) found that subjects, asked to respond to simulated Internet chats
from either a “friend” or a “stranger”, tended to use more emoticons with friends than
with strangers. Emoticon use was also more frequent in positive contexts than it was in
negative ones. Again, this suggests that CMC participants follow similar norms of
emotional disclosure as is done in FTF interaction—sharing more facial
expression/emoticons with friends than with colleagues (Wagner & Lee, 1999), and
preferring positive expressions (Readdick & Mullis, 1997).
Derks et al. (2008b) also surveyed participants’ motivations for emoticon use.
They found that “emoticons are mostly used to express emotion, to strengthen a message,
and to express humor” (p. 99). This notion of emoticons as expressing emotion is
analogous to the use of facial expression, as confirmed in previous research (e.g. Eckman,
Davidson, & Friesen, 1990; Winkielman & Cacioppo 2001), to convey affective
responses. Similarly, facial expressions, like emoticons, may be used to enhance message
valence strength and to indicate a joke. Thus, in experimental investigations of use,

9
emoticons seem to pattern in similar ways to facial emotional expression, and users seem
to conceive of their emoticon use as quite similar to their use of facial expression.
2.3. Perception of Emoticons
Use alone is half of the emoticon equation. In order for emoticons to be classified
as CMC facial expressions they must cause similar perceptual responses in recipients of a
message. However, there is little research done in this field and there is much
disagreement between those who have explored it.
As discussed above, Walther and D’Addario (2001) used email messages with
embedded valence sentences with or without one of the following emoticons: :), ;), and :(.
They found that messages with any negative component (whether text or emoticon) were
rated negatively; otherwise emoticons were found to have little to no effect on message
interpretation. Walther and D’Addario (2001) argued that this counters the notion of
emoticons as analogous to facial expression as, in FTF, non-verbal cues—especially
facial cues—carry greater weight than does verbal information. However, Walther and
D’Addario (2001) made use of verbal stimuli which carried very strong valences. As such,
the results of the study may warrant scepticism as the sentences may have been too
extreme to be affected by any one paralinguistic cue, whether it be a facial expression or
an emoticon. Supporting this suggestion is the fact that later studies (e.g. Lo, 2008; Derks,
Bos, & Grumbkow, 2008) have found that emoticons do in fact affect the perceived
valence of accompanying text when the text is less absolute in valence.
Lo (2008), for example, focussed on emotionally neutral or ambiguous text and
found that, where readers could not infer the attitude of the writer from text alone, the
addition of an emoticon significantly coloured their perceptions. Therefore, even if

10
emoticons cannot change the interpretation of strongly valenced statements as suggested
by Walther and D’Addario (2001), they are useful in ambiguous contexts. They may, in
fact, compensate for the lack of paralinguistic information, such as vocal tone or facial
expression, in circumstances where the verbal information itself does not provide clear
intent.
Modeled on the work of Walther and D’Addario (2001), Derks et al. (2008) also
added a neutral text condition to explore the role of emoticons outside of strongly
valenced contexts. Though emoticons could not invert the valence of a verbal message,
they intensified verbal content of the same valence. In mixed message conditions, though
no inversion occurred, as would be expected if emoticons behaved exactly as non-verbal
cues in FTF, the messages were rated as significantly more ambiguous than messages
either lacking an emoticon or with an agreeing emoticon. Derks et al. (2008) concluded
that “emoticons can serve as nonverbal surrogates for facial behavior and do have an
impact on message interpretation” (p. 386). Although emoticons may not be as powerful
as FTF non-verbal communication, considering the results of Derks et al. (2008), they do
seem to fulfill the same purposes (if to a somewhat lesser degree).
Guided by the methodology and discoveries of both Walther and D’Addario
(2001) and Derks et al. (2008), Luor et al. (2010) investigated the role of emoticons in
simplex (e.g. scheduling a meeting) and complex (e.g. discussions or requests for
discussions) task-oriented workplace communications. Only neutral verbal messages
were used. Walther and D’Addario’s (2001) negativity effect was supported by the
finding that negative emoticons triggered negative evaluations of both simplex and
complex tasks. Positive emoticons were also found to create positive affect in complex

11
tasks for both genders, but only for women in simplex tasks. This may be supported by
women’s greater use of emoticons (Wolf, 2000), potentially making them more receptive
to the effects of emoticons sent by others. Ultimately, Luor et al. (2010) claimed that
emoticons are communicative and may improve interpersonal relationships, rather like
facial expression and other forms of non-verbal behaviour.
In summary, all but one survey of emoticon perception have found that emoticons
do impact message interpretation, typically in ways similar to facial expressions in FTF
communication. These studies have primarily investigated the perceptions and behaviours
of university undergraduate students and have not explored the role of emoticons
amongst other demographic groups (i.e. older adults). There have also yet to be
naturalistic studies of emoticon reception, but these simulated experimental conditions
focussing on youth offer tantalizing suggestions that emoticons are interpreted in
valenced ways and may be filling the gap left by absent paralinguistic information in
CMC.
2.4. Emoticons in the Brain
Stepping away from the self-reporting and survey paradigms seen in the previous
work on emoticon perception, Yuasa, Saito, and Mukawa (2011b) make use of brain
imaging to explore the connection between emoticons and facial expression. Yuasa et al.
(2011b) used fMRI to measure the neural activity of subjects while reading sentences
with emoticons at the end.1 These sentences lead to activation of subjects’ right inferior
frontal gyrus, a region associated with emotion discrimination tasks. The right fusiform

1

The study was conducted with Japanese emoticons, which focus on eye rather than mouth shape, and
therefore may not be generalizable to Western emoticons. Nonetheless, it remains important to note that
emoticons activate the region responsible for emotional discrimination, but not the one solely activated by
linguistics stimulus.

12
gyrus, which is activated by seeing faces, was not activated, suggesting that emoticons
are not perceived as faces. In addition, the posterior cingulate gyrus, which is used in
discrimination of emotional words, was not lit up. It thus seems that emoticons are an
emotional indicator independent from faces and emotional words. Therefore, in spite of
the reduced detail and realism responsible for activating the right fusiform gyrus in
viewing faces, emoticons may still act as faces in triggering assessments of emotional
valence.
Further work by, Saito, and Mukawa (2011a) found that graphic emoticons
(upright line drawings of major facial features in the constellations of a particular
emotion), which carry more facial detail than ASCII emoticons, triggered not only the
right interior frontal gyrus but also the right fusiform gyrus, though not to the same extent
as a photograph of a face. Thus, it can be suggested that emoticons, cartoon images of
faces, and photos of faces sit along a continuum of activation for the right fusiform gyrus
in order of detail and realism.
This neuropsychological data, combined with the conclusions drawn from the
linguistic research above, strongly suggests that emoticons are perceived in ways very
similar to facial expression in so far as they contribute to emotional valence judgements
and trigger corresponding neural activations. Thus, they ought to behave in ways similar
to facial expressions in priming experiments.
2.5. Affective priming
First developed by Fazio, Sanbonmatsu, Powell, and Kardes (1986) to explore the
affective nature of attitude objects through priming, the affective priming paradigm has
since been used in a wide variety of research contexts, the most relevant to the current

13
question being the use of emotive facial expression to prime word valence judgements
(e.g. Aguado Garcia-Gutierrez, Castaneda, & Saugar, 2007; Andrews, Lipp, Mallan, &
Konig, 2011; Zhang, Li, Gold, & Jiang, 2010). In this paradigm, a photograph or
composite image of a positive or negative facial expression (the prime) is displayed either
above level of consciousness, such that the participant is aware of the image, or below the
level of consciousness, in which case the participant sees the image so briefly that it does
not enter their conscious awareness. A word with either positive or negative valence (the
target) is then displayed and the participant is asked, as quickly as possible, to press one
of two buttons to categorize the word as negative or positive.
There is some debate as to the relative power of masked (below the level of
consciousness) and unmasked (above the level of consciousness) priming. For example,
Murphy and Zajonc (1993), using facial expression primes and Chinese character targets,
found that priming only occurred in conditions where the facial expression was not
consciously seen. In contrast, Andrews et al. (2011), and Hsu, Hetrick, and Pessoa (2008)
both found that increased conscious visibility of a prime improved priming effects and
that primes of low-to-no visibility did not exhibit priming effects. Andrews et al. (2011)
argued that the difference in visibility was best manipulated by masking. This is
contradicted by Hsu et al.’s (2008) findings that priming effects still occur in masked
primes, but the duration of the prime display must be increased from 33ms, to 90ms.
Many researchers (e.g. Aguado et al., 2007; Spruyt, Hermans, De Houwer, & Eelen,
2002) have elected to use an unmasked prime with a short blank display between the
prime and the target. This method presents a compromise between masked priming and

14
unmasked priming—there is no distractor image as in masked priming, and yet there is
still some lag time between seeing the prime and the stimulus.
Another discovery in affective priming was made in Spruyt et al.’s (2002)
investigation of priming modalities, where they found that pictures are significantly more
effective primes than words, regardless of whether the target itself is a word or a picture.
This suggests that if emoticons are perceived as verbal information, like words, they will
be significantly less effective primes than facial expressions and will behave more like
words. In contrast, if emoticons are, as suggested through existing research, a form of
non-verbal information, they should behave much more similarly to photographs of facial
expressions than to words.

3. Research Questions & Hypotheses
The existent literature on emoticons suggests that if emoticons act as textual facial
expressions, they should successfully prime words of the same affective valence to a
greater degree than do words. Thus, for this research, the effects of emoticons, emotional
words, and emotional facial expressions on valence judgements of positive or negative
words are compared. The responses of both a younger and older demographic are
investigated. Considering the findings of Walther and D’Addario (2001), Derks et al.
(2008), and Luor et al. (2010), that emoticons, unlike facial expressions, were unable to
reverse the valence of a strongly positive or negative verbal message, it is reasonable to
hypothesize that emoticons have less affective power than facial expressions. Combined
with the work of Yuasa et al. (2011a) that finds more detailed graphic emoticons create
neural activation more analogous to that created by faces, it is reasonable to suggest that

15
the simplification of features in emoticons may drive their reduced affective influence.
Thus, a reduced priming effect, vis-à-vis faces, is expected.
H1: Emoticons will prime words of a congruent affective valence more strongly than
words will (but they will likely do so somewhat less strongly than do facial expressions).
Donges et al.’s (2012) finding that women perceive positive facial expression
more easily than negative facial expression may also interact with the finding that the
positive emoticon :) is the most commonly used emoticon (e.g. Garrison et al., 2011;
Rezabek & Cochenour, 1998; Wolf, 2000). If there is a preference for use and perception
of positive emoticons, then this, combined with greater exposure, suggests that positive
emoticons will show a stronger priming effect than do negative ones. Nonetheless,
Walther and D’Addario’s (2001) negativity effect (confirmed by Luor et al. 2010)
predicts than any negative element (emoticon or text) in an utterance renders the
perception of the entire utterance as negative. This suggests that, at least in incongruent
pairs, a negative emoticon will show a stronger interference effect than a positive
emoticon will.
H2: Negative and positive emoticons will show different strengths of priming effect.
Finally, exposure effects must be taken into account. Since emoticons were
developed fairly recently, in the 1980s, it is likely that older users are neither as
comfortable nor as familiar with the symbols as are younger users. Thus, older or less
frequent users may not associate the same degree of emotive power with emoticons as
with real world facial expressions. As a result, these users will be expected to experience
a lesser degree of priming from emoticons than from faces.
H3: Older users will not respond as strongly to emoticon primes.

16
4. Methodology
Working within the Affective Priming paradigm established by Fazio et al.
(1986), this study adopts the priming procedure of Aguado et al. (2007) to explore a
three-way contrast between prime-type within a two-way contrast in age. This study has
four independent variables (prime type, prime valence, target valence, and age of
participant). In the model of Aguado et al. (2007), driven by the salience of congruence in
priming paradigms, prime valence and target valence can be reanalyzed as a single
variable, congruence, which parcels valences as congruent (positive/positive and
negative/negative) or incongruent (positive/negative and negative/positive). Thus, the
variables can be represented by the following three-way interaction: 2x3x2 (age: 18-25 or
45-65, prime type: emoticon, photograph of facial expression, or word, and congruence:
prime and target of same valence, or prime and target of opposite valence).
4.1. Participants
The literature suggests that women use more emoticons than men (e.g. Baron,
2004; Tossell et al., 2012; Wolf, 2000) and that they use them for different purposes
(Wolf, 2000) and in different ways (Tossell et al., 2010) than do men. Furthermore,
Donges, Kersting, and Suslow (2012) have found that women perceive positive emotion
more easily than do men in affective priming paradigms. Thus, given these gendered
behaviours, only female participants were selected to remove the confounding variable of
gender from the equation.
In order to explore the effects of age/exposure on emoticon priming effects, 20
female participants were recruited: ten from the 18-25 age range and ten from the 45-60
age range. These age groups were selected to ensure an adequate difference in age of

17
exposure to emoticons and in the likelihood of regular use. Because emoticons were first
developed in 1982, women over the age of 45 were already past the socially powerful
stage of adolescence (wherein there is increased pressure to establish oneself as
belonging to a peer group distinct from both adults and children (Eckert, 2003)) when
emoticons evolved, and most likely were entirely through adolescence before they began
using emoticons. Thus, they were less vulnerable to the introduction of the new form. In
contrast, members of the younger cohort were all born at least 6 years after the emoticon
and likely grew up exposed to and using emoticons. All participants were, however,
computer literate as evidenced by the demographic survey’s finding that all participants
used at least one CMC medium at least once per day and all attested to using CMC for
social purposes though the exact nature of interlocutor was not clear.
Participants were recruited through a combination of word of mouth, in class
recruitment presentations, and distribution of recruitment posters and online posts, all of
which targeted the women belonging to the age groups outlined above.
4.2. Materials
For this experiment, a computer in the University of Victoria Phonetics
Laboratory equipped with E-Prime 2 software was used to administer a priming task.
Two photographs of a young male Caucasian face unfamiliar to the participants were
used for the facial expression primes.2 One photograph showed a smiling face and the
other a frowning face. Other primes were as follows: :), :(, happy, and unhappy3. Ten
words of each valence (positive/negative) adapted from Hsu et al. (2008) and Andrews et
2

The faces used were drawn from the Max Planck Institute’s FACES database (Ebner, Riediger, &
Lindenberger, 2010).
3
The use of the morphologically complex term “unhappy” was later found to be somewhat suspect as the
word primes elicited both higher error rates as well as longer reaction times than the other prime types. For
further discussion, see Section 6.3.

18
al. (2011) were used as targets. Positive targets were: pleasure, ecstasy, happiness, cheer,
delight, cheerful, confident, excellent, praise, good. Negative targets were: rage, terror,
violence, pain, fatal, killer, injury, lethal, bad, anger.
4.3. Procedure
This study, for the most part, followed the unmasked priming methodology of
Aguado et al. (2007). Participants first performed a short training session where they
were asked to identify the valence of presented words after the display of a neutral facial
expression or nonsense string of ASCII. In the actual experimental session, stimuli were
presented in two blocks of 60 trials with an optional break between blocks. Each trial
began with the presentation of a fixation screen (blank white screen with a black + in the
centre) for 500ms. The prime (smiling face, angry face, :), :(, happy, unhappy) was
presented for 250ms, followed by an interval of 300ms in which participants were again
presented with the fixation screen. The target was then displayed until the participant
pressed either the ‘j’ or ‘k’ key to indicate their valence judgement.
Subjects were instructed to determine whether the target was positive or negative
and to press the corresponding key as soon as possible. To prevent handedness effects,
half of the participants were instructed to press ‘j’ for positive and ‘k’ for negative, while
the other half were instructed to press ‘j’ for negative and ‘k’ for positive. E-Prime 2
software recorded response time (RT) and accuracy (ACC) data for each trial.
Upon completing the priming task, subjects completed a short demographic
survey to ascertain age, gender affiliation, degree of experience with CMC and
emoticons, and length of residence within Canada.

19
5. Results
5.1. Demographic Notes
In the demographic survey, participants’ reported use patterns, for the most part,
followed the expected lines of age. Though older women were found to be frequent users
of email (see Figure 1 for details; each bar of the figure shows percentages of the
responses listed to the right, within each medium, to a total of 100%), their use of most
platforms was fairly limited and frequency of texting varied widely across participants.
Figure 1
Frequency of use by platform (45-65 year olds)
100%
80%
60%
40%
20%
0%

>5 times per day
Several times per day
Once a day
Once every few days
Once a week
Once a month
Once a year
Never

In contrast to the older participants, younger participants had overall higher rates
of CMC use (see Figure 2 for details). Fewer members of this cohort reported using email
more than five times per day, but all use it at least once every few days. Unlike the older
cohort, 90% of 18-25 year old participants reported texting more than five times per day.
Because texting is associated with character limits and shorter messages (Ling & Baron,
2007), whereas email is generally unbounded in length, these differing patterns of use
may suggest that younger participants are accustomed to finding ways to express
themselves in fewer characters and, as they are working in a synchronous medium, in
ways that are more analogous to speech than writing though, as Tagliamonte and Denis

20
(2008) argue, CMC is neither truly speech, nor writing-like but is in fact a whole new
hybrid register. Older participants using asynchronous email may, however, still be
writing in more full-form, formal structures (in the model of letter writing) that drives
decreased use of emoticons and less speech-like or CMC forms.
Figure 2
Frequency of use by platform (18-25 year olds)
100%
80%
60%
40%
20%
0%

>5 times per day
Several times per day
Once a day
Once every few days
Once a week
Once a month
Once a year
Never

In terms of emoticon use, around 80% of the 45-65 year olds reported in the
demographic survey that they never, or only rarely, use emoticons in email, forums,
chatrooms, and blogs. Though some older adults attested to using emoticons more
frequently in IM and texting, their use remains comparatively low and is cleanly split
between the majority of rare users and the minority of very frequent4 (2-3 per message
and once per message) users (see Figure 3 for details).

4

All instances of 2-3 per message came from the same participant who also mentioned using CMC to
communicate with her adult child and her grandchildren.

21

Figure 3
Frequency of emoticon use by platform (45-65 year olds)
2-3 per message

100%
80%
60%
40%
20%
0%

Once per message
Once every other message
Once every 5 message
Once every 10 message
Rarely
Never

The 18-25 year-old participants show a much greater range of emoticon use.
Though emoticon use is still fairly infrequent for most users in forums, chatrooms, and
blogs, all participants use emoticons at least once every five messages in texting, and all
use emoticons at least occasionally in email. There is also a much larger presence of users
in the mid frequency categories such as once every other message and once every five
messages (see Figure 4 for details). Overall, the younger cohort of users prove to be
much more frequent users of emoticons than older users.
Figure 4
Frequency of emoticon use by platform (18-25) year olds)
100%
80%
60%
40%
20%
0%

2-3 per message
Once per message
Once every other message
Once every 5 message
Once every 10 message
Rarely
Never

22
In light of CMC and emoticon use patterns across the two age cohorts, the effects
of age found in the priming experiment may actually be effects of regularity of use. Of
course, frequency of use may also be a result of familiarity and exposure as the 18-25
year old cohort has not known a time before emoticons (invented in 1982 by Fahlman
(n.d.)), where the 45-65 year olds came of age in a world devoid of emoticons and are
much less reliant upon CMC.
5.2. Experimental Results
Due to large participant-internal variance in RTs (standard deviations of more
than 40% of the mean RT after removal of outliers and inaccurate responses), the data
from two of the 45-65 year old participants were called into question. These two
participants seemed to experience unusual difficulty with the task, pausing to ask the
researcher questions and seek task clarification mid-experiment. In an independent
samples t-test comparing the two anomalous participants with the remaining 18, these
two participants were found to be significantly different from the rest of the participants
(p<0.001) and so the data from these two participants were excluded. Amongst remaining
participants, data that fell outside of the normal distribution (as defined by explorative
boxplots produced for each permutation of age, prime type, and congruence by SPSS 19),
amounting to 7.1% of accurate responses, were also excluded. Overall, 97.8% of
responses were accurate, and, as seen in Table 1 which shows numbers of accurate and
inaccurate responses as a percentage of the total responses for each age group and prime
type, patterns of accuracy were consistent across age groups. Thus, considering only
accurate results does not conflate disparate groups and so, for the purposes of analysis,
only the RTs from accurate trials were considered. Interestingly, for both groups, an

23
ANOVA, used to pick apart multiple interacting factors, found that prime type was the
only significant main effect in predicting rates of error F(2,2010) = 4.93, p<0.05. A
conservative post hoc Tukey test revealed that words were significantly less accurate than
emoticons (p<0.05). Faces, however were not statistically separable from either
emoticons or words, though the words and faces comparison was much closer to
significance than words and emoticons (p = 0.09 versus p = 0.51) (see Section 6.3 for an
explanation of methodological limitations that may have driven this finding).
Table 1
Accuracy of responses
Age
18-25

45-65

Total:

Prime Type

Accurate

Inaccurate

Emoticon

363

98.6%

5

1.4%

Face

369

98.4%

6

1.6%

Word

352

96.2%

14

3.8%

Total:

1084

97.7%

25

2.3%

Emoticon

300

99.3%

2

0.7%

Face

292

97.7%

7

2.3%

Word

290

96.7%

10

3.3%

Total:

882

97.9%

19

2.1%

1966

97.8%

44

2.2%

5.2.1. Statistical Analyses. For this study, a series of ANOVAs were used to pick
apart the effects and interactions of the range of independent factors in the study (see
Appendix A for a summary table of ANOVA findings). Initial analyses treated age of

24
participant, type of prime, and congruence of prime and target as independent variables in
a 2x3x2 design. Congruence, however, in spite of being frequently assessed as a factor in
affective priming paradigms (e.g. Aguado et al., 2007; Spruyt, Houwer, Hermans, &
Eelen, 2007), was found to be a less accurate predictor of RT trends than either the
valence of the prime or the valence of the target. Thus, analyses were adjusted to consider
the following independent variables in a 2x3x2x2 design: age (18-25, 45-65), prime type
(emoticon, photograph of facial expression, word), prime valence (positive, negative),
and target valence (positive, negative).
Significant main effects were found for age F(1,1966) = 590.00, p<0.001, prime
valence F(1,1966) = 6.06, p<0.05, and target valence F(1,1966) = 8.83, p<0.001. There
was also a significant three-way interaction found between these factors F(1,1966) =
3.95, p < 0.05. Due to the size of the sample (N = 18), only these few factors were
statistically significant and, as such, non-significant trends are also considered and
discussed as predictors of potential significant effects in larger samples.
5.2.2. Effects of age. Age was found to be the best predictor of RT overall with
participants from the 45-65 cohort taking significantly F(1,1966) = 590.00, p<0.001
longer to respond than the participants from the 18-25 cohort (M = 800.20ms, SD =
176.58ms versus M = 623.79ms, SD = 147.04ms). Beyond the raw differences in RT,
response patterns surrounding prime type and valence effects also differ across the two
age cohorts. The younger participants were not only faster overall, but also produced
more interpretable results.

25
5.2.3. Effects of prime type.
Though prime type was not a statistically significant factor5, Table 2 reports the
general trends in terms of mean reaction time for prime type. Overall, faces tended to
result in the fastest RTs (M = 694.69ms, SD = 187.31ms). Emoticons and words elicit
somewhat slower responses at means of 705.65ms (SD = 184.91ms) and 708.61ms (SD =
183.30ms) respectively. Given the large standard deviations and relatively small
difference of means, however, these trends may not hold within a larger sample. In fact,
when the sample is split by age cohort, two separate patterns emerge depending upon the
age of the participant.
Table 2
RT by prime type
Prime Type

Mean

N

Std. Dev.

Emoticon

705.65

663

184.91

Face

694.69

661

187.31

Word

708.61

642

183.30

Though mean times were quite different across cohorts, for both groups, faces
consistently elicited faster response times than words as seen in Table 3 below.
The most interesting difference between the age groups, however, is the difference in the
way that emoticons pattern. Within the 18-25 year-old group emoticons triggered RTs
very similar to those elicited by faces. The mean RT for emoticons was 621.65ms (SD =
150.26ms), while faces elicited a mean RT of 621.09ms (SD = 148.51ms). Though the

5

Prime type was not found to be significant in this study (p = .38, see Table 1 for further statistical details)
but it is expected that, given the variation in mean RT between prime types in both age groups, a larger
sample (potentially even a larger sample from a single age cohort) would bring the RT trends up to the
level of significance.

26
difference in mean RT was not especially large, words did elicit a slower RT (M =
628.82ms, SD = 142.35ms) farther from emoticons than emoticons were from faces.
Table 3
RT for faces and words by age cohort
18-25 Year-old Cohort
Prime Type

Mean

N

45-65 Year-old Cohort

Std. Dev.

Mean

N

Std. Dev.

Face

621.09

369

148.51

787.70

292

190.09

Word

628.82

352

142.35

805.46

290

167.29

Unlike the younger cohort, in the 45-65 year old cohort, emoticons elicited the
slowest response times (M = 807.29ms, SD = 171.56ms), more analogous to words than
to faces. As with the younger cohort, faces elicited the fastest RTs with a mean of
787.70ms (SD = 190.09). Words triggered RTs similar to, but shorter than, emoticons
with a mean RT of 805.46ms (SD = 167.29ms). Thus, as seen in the summary Table 4
below, for the older cohort, emoticons and words lead to similar RTs which are
considerably slower than those triggered by face primes, while for younger participants,
emoticons and faces pattern together with words alone showing a slower RT.
Table 4
RT by prime type and cohort
18-25 Year-old Cohort
Prime Type

Mean

N

45-65 Year-old Cohort

Std. Dev.

Mean

N

Std. Dev.

Face

621.09

369

148.51

787.70

292

190.09

Emoticon

621.65

363

150.26

807.29

300

171.56

Word

628.82

352

142.35

805.46

290

167.29

27
5.2.4. Positivity and other valence effects. As discussed above, the valences of
both prime and target, taken individually, were found to be more accurate predictors of
RT than the standard factor: congruence. Given the significance of age and the presence
of vastly different patterns between the two cohorts, valence effects, though significant
(prime valence F(1,1966) = 6.06, p<0.05, and target valence F(1,1966) = 8.83, p<0.001),
were not especially meaningful when measured over both age groups. When these effects
are considered within each cohort, prime valence ceases to attain statistical significance,
and target valence only remains significant for the younger demographic F(1,1083) =
5.30, p <0.05. Thus the trends are broken down by cohort and further by prime type to
help fully tease apart the effects of valence.
Within the younger cohort, though congruence does seem to play a role, showing
preference for positive/positive or negative/negative pairings, a larger role is played by
positivity which tends to drive faster RTs overall. As seen in Table 5, the fastest RTs are
seen for congruent trials, but the positive/positive trial is faster (M = 592.61ms, SD =
125.38ms) than the negative/negative (M = 626.33, SD = 147.29). Amongst the two
incongruent trials, the trial with a positive target is fastest (M = 634.11ms, SD =
156.60ms) and, if valence trends are compared over targets and primes independently,
positive primes (M = 617.34ms, SD = 141.80ms) and targets (M = 613.59ms, SD =
143.41ms) are consistently associated with faster RTs than negative primes (M =
630.26ms, SD = 151.97ms) or targets (M = 633.91, SD = 150ms).

28
Table 5
RT for 18-25 year old cohort across target and prime valence
Prime Valence Target Valence
Positive

Negative

Total

Mean

N

Std. Dev.

Positive

592.61

267

125.38

Negative

641.26

276

152.49

Total

617.34

543

141.80

Positive

634.11

273

156.60

Negative

626.33

268

147.29

Total

630.26

541

151.97

Positive

613.59

540

143.41

Negative

633.91

544

150.00

Total

623.79

1084

147.04

For all prime types, as shown in Table 6, positive/positive trials were fastest (M =
578.83ms, SD = 119.98ms, M = 610.80ms, SD = 131.32ms, M = 588.46ms, SD =
123.93ms). Negative/negative trials (M = 607.54ms, SD = 152.01ms) were also faster
than negative/positive trials (M = 636.47ms, SD = 145.10ms) for faces. For words,
however, negative/negative and positive/negative trials showed comparable mean
response times (M = 631.46ms, SD = 164.11ms versus M = 631.67ms, SD = 136.61ms).

29
Table 6
RT for the 18-25 year old cohort in across prime types over prime and target valence
Prime Type Prime Valence Target Valence
Face

Positive

Negative

Word

Positive

Negative

Emoticon

Positive

Negative

Mean

N

Std. Dev.

Positive

578.83

89

119.984

Negative

659.29

94

162.337

Positive

636.47

93

145.096

Negative

607.54

93

152.014

Positive

610.80

88

131.324

Negative

631.67

89

136.611

Positive

641.45

89

164.108

Negative

631.24

86

135.278

Positive

588.46

90

123.925

Negative

632.23

93

156.570

Positive

624.53

91

161.598

Negative

641.22

89

152.860

Interestingly, for faces positive/negative trials (M = 659.29ms, SD = 162.34ms)
were slower than negative/positive trials (M = 636.47ms, SD = 145.10ms), both of which
were slower than congruent trials (M = 578.83, SD = 119.98ms and M = 607.54, SD =
154.01ms), suggesting that, for faces, congruence is of primary importance, followed by
target valence, whereas, for words, prime valence is most important to determining speed
of response.

30
Emoticons also provide an interesting pattern in the RTs of the younger cohort.
Though positive/positive is still the fastest by a fairly wide margin6 as noted above,
negative/positive (M = 624.53ms, SD = 161.60ms) is faster than either negative/negative
(M = 641.22ms, SD = 152.86ms) or positive/negative (M = 632.23ms, SD = 156.57ms).
This suggests that target valence is the most important predictor of RT and that positive
words elicit faster response times regardless the positivity or negativity of the emoticon
prime. Contrary to the statistical analyses which showed that target valence was the most
important predictor of RT in the younger age cohort, the trends suggest that words,
emoticons, and faces each rely on a different type of valence effect in determining their
patterns of RTs. As shown in Table 7 below, faces are most affected by congruence (as
predicted by previous affective priming studies (e.g. Aguado et al., 2007), words seem to
be most reliant upon prime valence, and emoticons seem to be affected primarily by
target valence.
Table 7
Most effective valence effect by prime type for the 18-25 year-old cohort
Prime Type

Valence Effect

Faces

Congruence

Words

Prime valence

Emoticons

Target valence

6

Though both prime and target valence were found to be statistically significant (p<0.05 and p<0.001
respectively) in the overall analysis, their interaction neared, but did not reach statistical significance (p =
.06). Thus, it is concluded that seeming effects of congruence wherein positive/positive trials are fastest, are
actually the effects of combining the power of two positive elements rather than the effects of priming or
congruence. In a larger sample however, it may be the case that congruence emerges as a predictive factor
interacting with target and prime valence.

31
In the older demographic, positivity seems to have a considerably larger effect on
RT than does congruence (see Table 8 for details). This is especially clear insofar as the
incongruent negative prime/positive target pairs have a faster mean RT (M = 799.62ms,
SD = 186.10ms) than do the congruent negative/negative pairs (M = 823.50ms, SD =
187.81). The incongruent positive/negative prime/target pair is also associated with a
faster mean RT (M = 800.06ms, SD = 156.94ms) than the negative/negative pair. Despite
these differences, just as with the younger cohort, positive/positive trials still elicit the
fastest RTs at a mean of 778.24ms (SD = 171.71ms).
Table 8
RT for 45-65 year old cohort across target and prime valence
Prime Valence
Positive

Negative

Total:

Target Valence

Mean

N

Std. Dev.

Positive

778.24

225

171.71

Negative

800.06

216

156.94

Total

788.93

441

164.82

Positive

799.62

222

186.10

Negative

823.50

219

187.81

Total

811.48

441

187.12

Positive

788.86

447

179.121

Negative

811.86

435

173.372

Total

800.20

882

176.584

Though valence continues to be the most powerful predictor of RT, in older
participants, there is less evidence that target valence is any more important to prediction

32
of RT than is prime valence. As seen in Table 9, for the 45-65 year old cohort, with
words and faces, positive elements generally tend to lead to shorter RTs.
Table 9
RT for the 45-65 year old cohort in faces and words over prime and target valence
Prime Type
Face

Word

Valence

Mean

N

Std. Dev.

Positive Prime

780.16

146

177.205

Negative Prime

795.23

146

202.485

Positive Target

772.26

149

194.987

Negative Target

803.78

143

184.150

Positive Prime

795.71

146

160.566

Negative Prime

815.35

144

173.832

Positive Target

796.12

145

174.210

Negative Target

814.81

145

160.118

Unlike in other conditions, when 45-65 year olds were exposed to emoticons, the
trends in mean RTs seems to point to a more important role for prime valence, as was
seen with younger participants with word primes. Regardless of congruency, positive
primes are associated with shorter mean RTs than negative primes (M = 790.88ms, SD =
156.88ms and M = 823.49ms, SD = 183.99ms respectively). Within each prime valence,
however, trends differ (see Table 10 for a full breakdown of means). For positive primes,
negative targets have shorter RTs (M = 787.33ms, SD = 148.53ms) than positive targets
(M = 794.29ms, SD = 165.43ms); for negative primes, positive targets (M = 801.96ms,
SD = 169.98ms) are faster than negative ones (M = 845.89ms, SD = 196.17ms). Thus, it

33
seems that for older adults viewing emoticons, there may be an effect of congruence,
whereby incongruent pairings facilitate responses.
Table 10
RT for the 45-65 year old cohort in emoticons over prime and target valence
Prime Type Prime Valence
Emoticon

Positive

Negative

Total:

Target Valence

Mean

N

Std. Dev.

Positive

794.29

76

165.426

Negative

787.33

73

148.532

Total

790.88

149

156.884

Positive

801.96

77

169.978

Negative

845.89

74

196.169

Total

823.49

151

183.990

Positive

798.15

153

167.224

Negative

816.81

147

176.023

Total

807.29

300

171.559

5.3. Revisiting the research questions
Having broken down the data to find trends, it now remains necessary to
reassemble these results to make sense of the initial research questions. These hypotheses
were framed on the assumption, common to affective priming research (e.g. Aguado et
al., 2007), that congruence effects would be found, as a result of positive primes
facilitating responses to positive targets, and negative primes facilitating negative targets,
and therefore the finding that valence is more powerful than congruence somewhat
complicates the response to these hypotheses.

34
H1: Emoticons will prime words of a congruent affective valence more strongly
than words, (but likely somewhat less strongly than facial expressions). Since priming
effects were not found, this question is best answered by reference to general facilitation
of RTs across prime types. Within the younger cohort, emoticons showed mean RTs very
close to those found with faces while words lagged somewhat behind. This suggests that,
as expected, emoticons are facilitating responses in ways more similar to faces than to
words for 18-25 year olds. For the older demographic, however, faces corresponded to
faster RTs while both words and emoticons lagged behind with longer mean RTs. This
suggests that, for older participants less familiar with emoticons, they are received less
like facial expressions and more like verbal expressions of emotion.
H2: Negative and positive emoticons will show different strengths of priming
effect. In the case of valence effects, as discussed above, there is much to say. Within the
younger cohort and across prime types, target valence was found to be a statistically
stronger predictor (p<0.05) of RT (positive target = shorter RT) than prime valence, but
there was nonetheless a clear trend toward positive primes corresponding with shorter
RTs particularly amongst words and to some extent amongst faces. Given the varied
determinants of RT as described by Table 7 above, until a larger sample is tested,
however, it is unclear how large of a role is played by the valence of the prime, especially
within emoticons which seemed to be more consistently driven by target valence than the
other primes. Furthermore the seeming effects of congruence over positivity in the case
of faces must not be disregarded.
Amongst the older participants, the effect of positivity were even less clear but
there did appear to be somewhat more of a balance between the role of prime valence and

35
the role of target valence. This is complicated, however, by 45-65 year olds’ responses to
emoticons wherein, though positive primes did seem to correlate with shorter RTs, the
power of target valence was inverted with negativity (rather than positivity) facilitating
faster RTs. In summary, this hypothesis was not clearly supported, but the variety of
valence trends seen leave much room for further exploration.
H3: Older users will not respond as strongly to emoticon primes. The response of
the older demographic to emoticons both in terms of overall RT facilitation and valence
effects seems to show that they are not as strongly affected by emoticons as their younger
counterparts are. First, for older participants, emoticons pattern with words rather than
faces, resulting in longer overall mean RTs. In contrast, for younger participants,
emoticons pattern alongside faces with faster RTs. Second, older adults, less familiar
with computer use, produced overall significantly longer response times than the younger
cohort regardless of prime type. Third, the trend towards incongruent priming with
emoticons, suggests that older adults are not affected by the affective value of the
emoticon in the same way as the younger participants for whom congruent pairs are faster
than the incongruent pairs within a given prime valence. In fact, this lack of exposure
may have driven the general finding that age is the most clearly significant factor
(p<0.0001) and that when the age groups are split, the younger cohort offers more
interpretable results vis-à-vis the older participants.

6. Discussion
Though statistically significant priming effects were not found in this study, the
results offer interesting possibilities in the form of trends including valence effects.

36
Emoticons seem to behave differently than do either words or faces. Primarily, emoticons
trigger differences in RT on the basis of age, and prime/target valence that are not
necessarily seen with faces or words. For younger participants, emoticons seem to prime
responses to positive targets, regardless the valence of the emoticon.
In contrast, amongst older participants’ responses an incongruence trend with
emoticons is especially interesting. That incongruent pairs are faster than their congruent
counterparts suggests that, as predicted, older users do not respond to emoticons in the
same ways as younger participants do. This suggests that the affective value of ASCII–
based emoticons is derived through socialization and exposure rather than through innate
iconicity. In fact, some older participants mentioned in the debrief following the
experiment that they had not even known what the ASCII emoticons were, believing that
emoticons were only the small yellow cartoon faces made available for insertion by some
CMC systems. If participants were not familiar with emoticons and their social meaning
in the context of CMC, then they were not consistently affected by them. Thus it is clear
that emoticons are not obviously associated with emotional expressions and likely only
become meaningful through exposure. There is nothing about :) that is fundamentally
“happy” and nothing about :( that is innately “sad” or “angry”. This suggests that these
simple ASCII constellations are too simplified7 to represent actual faces and as such only
have meaning for individuals who have been appropriately socialized to the role and
meaning of emoticons in CMC.

7

It is also worth noting that Murray (1997) finds that RTs for object recognition grow progressively longer
as the object is rotated from 0˚ to 180˚. Since ASCII emoticons are a 90˚ rotation of the corresponding
graphic representation  or  it may be the case that older users are simply less responsive to the novel
orientation whereas younger participants have already adapted to the 90˚ rotation and therefor have no
issues with recognition.

37
6.1. Emoticons: effective but not affective
For younger users, who have a greater degree of experience with emoticons, the
presentation of an emoticon prime did seem to speed RTs in the valence decision task.
Positive emoticons were more powerful than negative ones and they seemed to have a
more powerful effect on positive targets. This result may be arising as a result of the
specific participant cohort targeted. Guided by Donges et al.’s (2012) finding that women
have a positivity bias in affective priming research where men do not, only women were
chosen for the study. As a result, it is uncertain whether this power of positivity is an
effect of gender or an effect of age, use norms, or any number of other potential factors.
In fact, this increased power of positive emoticons may also be related to their more
frequent use as found by researchers such as Baron (2004) and Wolf (2000) and their role
in ensuring cooperative communication in line with Grice’s (1975) conversational
maxims.
The lack of affective congruence priming, however, suggests that emoticons do
not have direct correlates in emotional affect. Because faces alone showed trends towards
consistent congruent priming, one may conclude that, like words, emoticons are simply
not as effective in communicating affect as are facial expressions even within the
younger cohort. It must also be noted that older adults did not experience the generalized
facilitation effect of emoticons on valence decision tasks, with only faces enhancing their
RTs. Thus, perhaps we are seeing a progression in the semantic and communicative value
of emoticons. Where for older participants, they are simply symbols which lack
consistent priming effects and which facilitate RTs no more than do words, for younger
participants emoticons begin to facilitate RT generally but are limited to positivity effects

38
in terms of priming. Perhaps then, as emoticons experience further “domestication”
(Baron, 2007, p. 3), their affective priming power will increase and yet younger users will
respond to emoticons in ways ever more similar to faces.
6.2. The affective priming paradigm
This study’s findings regarding the power of prime and target valence over
congruence of prime and target pairs raises questions about the affective priming
paradigm. Though perhaps congruence would have a larger role in a larger sample, the
statistical significance of the valence of individual components, combined with the
positivity effects found by researchers such as Donges et al. (2012), suggest that priming
researchers ought to consider the effects of individual valences rather than assuming that
all effects are related to congruence priming. Certainly the paradigm is well established
(e.g. Aguado Garcia-Gutierrez, Castaneda, & Saugar, 2007; Andrews, Lipp, Mallan, &
Konig, 2011; Zhang, Li, Gold, & Jiang, 2010) but unless the effects of valence are also
explored, such priming effects may warrant further investigation.
6.3. Further research and limitations
Because of the limited sample size of this study, most all of its results and
conclusions would benefit by the addition of further participants’ data. The addition of
male participants may also provide interesting insights into gender differences in
emoticon perception, while perhaps clarifying the nature and distribution of the positivity
effect insofar as other researchers (e.g. Donges et al., 2012) have only found significant
positivity effects with female participants.
To tease apart the interaction between age and familiarity with emoticons through
use, further research could benefit from the inclusion of highly computer literate older

39
adults who make regular use of emoticons across CMC platforms. Older adults that are
highly computer literate are more likely to use CMC forms such as emoticons in ways
analogous to their younger tech savvy peers. Thus, if emoticons are given meaning by
regular use alone, such users would be more likely to respond to emoticons in ways more
like the youth. If however the potency of emoticons relies upon age of exposure and early
adoption in the socially critical life stage, adolescence, then the increase frequency of use
should not yield youth like behaviour in tech literate older adults. This question of
frequency of exposure versus age of exposure—a question which has been extensively
explored in second language acquisition research on learners’ language competence and
development across age of exposure versus length of exposure (e.g. Stevens, 2006;
Babcock, Stowe, Maloof, Brovetto, & Ullman, 2012; Tan, Loker, Dedrick, & Marfo,
2012)—opens up the possibility of much interesting research into differences of stylistic
acquisition across age gradients.
Lastly, in terms of participant manipulations, it would be worthwhile to vary the
age across a spectrum rather than simply delineating cohorts. This sort of spectrum of
participants would better enable exploration of a potential gradient effect of emoticon and
technology exposure.
In terms of the experiment proper, further work may consider the additional
exploration of various kinds of emoticons (e.g. Japanese emoticons, graphic emoticons,
etc.) to explore the gradient “faceness” found by Yuasa et al.’s (2001a) fMRI work on the
neural activation of participants viewing emoticons. Future research would also benefit
by choosing word primes that are not morphologically related. The fact that “unhappy” is
morphologically related to “happy” may have reduced the power of the negative word

40
prime. In accordance with Exemplar Theories (e.g. Pierrehumbert, 2001), which explain
the parsing of lexical stimuli as the activation of clusters or previous encountered stimuli
(exemplars), a complex word form such as “unhappy” will activate exemplars involving
both the “un-“ prefix and the “happy” root. Thus, it potentially primes positive as much
as negative affect. It may also be the case that the more morphologically complex prime,
“unhappy” takes longer for the brain to parse and so leads to longer reaction times in
spite of its potential to activate the positive affect of its root “happy”. The use of two
unrelated and morphologically simple primes, however, would simplify the interpretation
of results by reducing these confounding factors. Nonetheless, it may also be the case that
since they are activating the same modality, textual interpretation, word primes may
interfere with the parsing of the following target regardless of valence as they are tying
up the visual lexical processing system.
As a final note with regards to word primes, future research may wish to further
manipulate the visual difference between the words as primes and the words as targets.
Though the two types of words were different colours and different sizes in the existing
study, there still seems to have been some degree of confusion, perhaps leading to the
higher error rates in word conditions versus face or prime conditions.

7. Conclusion
As an exploratory study in the priming effects of emoticons, this study found age
and valence to be the best predictors of response time. In order to draw conclusions about
the relationship between faces, emoticons, and words, a larger sample is required, but
these preliminary results suggest that, for those more frequently exposed to emoticons,

41
and exposed to emoticons for a greater percentage of their life and exposed to them
earlier in life, the emoticons behave in ways that are more similar to faces than to words.
Emoticons seem to have a unique role to play in CMC, but the exact nature of that role
remains difficult to isolate. This study lays the groundwork for future studies exploring
the affective effects of viewing emoticons in conjunction with textual information, as
commonly occurs in CMC. As more and more interactions are mediated by devices, it
becomes ever more important to understand just how users make up for the paucity of
non-verbal cues while carrying out social and professional activities online.

42
References
Aguado, L., Garcia-Gutierrez, A., Castaneda, E., & Saugar, C. (2007). Effects of prime
task on affective priming by facial expressions of emotion. The Spanish Journal
of Psychology, 10(2), 209-217.
Andrews, V., Lipp, O. V., Mallan, K. M., & Konig, S. (2011). No evidence for
subliminal affective priming with emotional facial expression primes. Motivation
and Emotion, 35, 33-43.
Baron, N. S. (2004). See you online: Gender issues in college student use of instant
messaging. Journal of Language and Social Psychology, 23(4), 397-423.
Baron, N. S. (2007). Always On: Language in an Online and Mobile World. Oxford
University Press USA. Retrieved 20 September 2012, from
<http://lib.myilibrary.com.ezproxy.library.uvic.ca?ID=134199>
Buck, R. (1994). Social and emotional functions in facial expression and communication:
The readout hypothesis. Biological Psychology, 38, 95-115.
Buck, R., Savin, V., Miller, R., & Gaul, W. (1972). Communication of affect through
facial expressions in humans. Journal of Personality and Social Psychology, 23,
362-371.
Danet, B., Ruedenberg-Wright, L., & Rosenbaum-Tamari, Y. (1997). “HMMM . . .
WHERE’S THAT SMOKE COMING FROM?” Writing, play and performance
on Internet Relay Chat. Journal of Computer-Mediated Communication, 2 (4).
Derks, D., Bos, A. E. R., & Grumbkow, J. V. (2004). Emoticons and social interaction on
the Internet: The importance of social context. Computer in Human Behaviour, 23,
842-849.

43
Derks, D., Bos, A. E. R., & Grumbkow, J. V. (2008). Emoticons and online message
interpretation. Social Science Computer Review, 26(3), 379-388.
doi:10.1177/0894439307311611
Derks, D., Bos, A. E. R., & Grumbkow, J. V. (2008b). Emoticons in computer-mediated
communication: Social motives and social context. CyberPsychology & Behaviour,
11(1), 99-101.
Derks, D., Fischer, A.H., & Bos, A.E.R, (2008). The role of emotion in computermediated

communication: A review. Computers in Human Behaviour 24, 766-785.

doi:10.1016/j.chb.2007.04.004
Donges, U., Kersting, A., & Suslow, T. (2012). Women’s greater ability to perceive
happy facial emotion automatically: Gender differences in affective priming. PLoS
ONE, 7(7), 1-5.
Dresner, E. & Herring, S. C. (2010). Functions of the nonverbal in CMC: emotions and
illocutionary force. Communication Theory, 20, 249-268.
Drouin, M. & Davis, C. (2009). R u txting? Is the use of text speak hurting your literacy?
Journal of Literacy Research, 41, 46-67.
Ebner, N., Riediger, M., & Lindenberger, U. (2010). FACES—A database of facial
expressions in young, middle-aged, and older women and men: Development and
validation. Behavior research Methods, 42, 351-362. doi:10.3758
Eckert, P. (2003). Language and adolescent peer groups. Journal of Language and Social
Psychology, 22, 112-118.
Eckman, P., Davidson, R. J., & Friesen, W. V. (1990). The Duchene smile: Emotional
expression and brain physiology II. Journal of Personality & Social Psychology, 58,

44
341-353.
Fahlman, S. E. (n.d.). Original Bboard Thread in which :-) was proposed. Retrieved from
http://www.cs.cmu.edu/~sef/Orig-Smiley.htm
Fazio, R.H., Sanbonmatsu, D.M., Powell, M.C., & Kardes, F.R. (1986). On the automatic
activation of attitudes. Journal of Personality and Social Psychology 50, 229–
238.
Fogel, A. & Thelen, E. (1987). Development of early expressive and communicative
action: Reinterpreting the evidence from a dynamic systems perspective.
Developmental Psychology, 23(6), 747-761.
Garrison, A., Remley, D., Thomas, P., & Wierszewski, E. (2011). Conventional faces:
Emoticons in instant messaging discourse. Computers and Composition, 28, 112115.
Grice, P. (1975). Logic and conversation. In P. Cole & J. Morgan (Eds.), Syntax and
semantics 3: Speech acts (pp. 41–58). New York: Academic Press.
Hsu, S., Hetrick, W. P., & Pessoa, L. (2008). Depth of facial expression processing
depends on stimulus visibility: Behavioral and electrophysiological evidence of
priming effects. Cognitive, Affective & Behavioral Neuroscience, 8(3), 282-292.
Huang, A.H., Yen, D.C., & Zhang, X. (2008). Exploring the potential effects of
emoticons. Information & Management 45, 466-473. doi:10.1016/j.im.2008.07.001
Kapidzic, S. & Herring, S. C. (2011). Gender, communication, and self-preservation in
teen chatrooms revisited: Have patterns changed? Journal of Computer-Mediated
Communication, 17, 39-59.
Ling, R., & Baron, N.S., (2007). Text messaging and IM: Linguistic comparison of

45
American college data. Journal of Language and Social Psychology, 26(3), 291298. doi:10.1177/0261927X06303480
Lo, S. (2008). The nonverbal communication functions of emoticons in computermediated communication. CyberPsychology & Behaviour, 11(5), 595-597.
Luor, T., Wu, L., Lu, H., & Tao, Y. (2010). The effect of emoticons in simplex and
complex task-oriented communication: An empirical study of instant messaging.
Computers in Human Behaviour, 26, 889-895.
Murphy, S. T. & Zajonc, R. B. (1993). Affect, cognition and awareness: Affective
priming with optimal and suboptimal stimulus exposures. Journal of Personality
and Social Psychology, 64, 723–739.
O’Kane, P. & Hargie, O. (2006). Intentional and unintentional consequences of
substituting face-to-face interaction with e-mail: An employee-based perspective.
Interacting with Computers, 19, 20-31.
O’Neill, B. (2010). LOL! (laughing online): An investigation of non-verbal
communication in computer mediated exchanges. Working Papers of the
Linguistics Circle of the University of Victoria, 20(1), 117-123.
Pierrehumbert, J. (2001). Exemplar dynamics: Word frequency, lenition and contrast. In
J.L. Bybee & P. Hopper (eds.), Frequency and the Emergence of Linguistic
Structure (pp. 137-157). Amsterdam: John Benjamins.
Plester, B., Wood, C., & Joshi, P. (2009). Exploring the relationship between children’s
knowledge of text message abbreviations and school literacy outcomes. British
Journal of Developmental Psychology, 27, 145-161.
Provine, R.R., Spencer, R.J., & Mandell, D.L. (2007). Emotional expression online:

46
Emoticons punctuate website text messages. Journal of Language and Social
Psychology, 26(3), 299-307. doi:10.1177/0261927X06303481
Raymond, E.S. (1994). The new hacker’s dictionary. 2nd ed. Cambridge: The MIT Press,
pp. 162–163.
Readdick, C. A. & Mullis, R. L. (1997). Adolescents and adults at the mall: Dyadic
interactions. Adolescence, 32, 313–322.
Reisenzein, R., Bördgen, S., Holtbernd, T., & Matz, D. (2006). Evidence for strong
dissociation between emotion and facial displays: The case of surprise. Journal of
Personality and Social Psychology, 91(2), 295-315.
Rezabek, L. L. & Cochenour, J. J. (1998). Visual cues in computer-mediated
communication: Supplementing text with emoticons. Journal of Visual Literacy,
18(2), 201-215.
Riordan, M. A. & Kreuz, R. J. (2010). Emotion encoding and interpretation in computermediated communication: Reasons for use. Computers in Human Behaviour, 26,
1667-1673.
Rivera, K., Cooke, N. J., & Bauhs, J. A. (1996). The effects of emotional icons on remote
communication. Computer Human Interaction Interactive Poster, 96, 99–100.
Russell, J. A. (1994). Is there universal recognition of emotion from facial expression? A
review of the cross-cultural studies. Psychological Bulletin, 115(1), 102-141.
Spruyt, A., Hermans, D., De Houwer, J., & Eelen, P. (2002). On the nature of the
affective priming effect: Affective priming of naming responses. Social
Cognition, 20, 227–256.

47
Spruyt, A., Hermans, D., De Houwer, J., & Eelen, P. (2007). Affective priming of non
-affective responses. Experimental Psychology, 54(1), 44-53.
Steiner, J. E. (1979). Human facial expressions in response to taste and smell stimulation.
In H. Reese & L. P. Lipsitt (Eds.), Advances in child development and behavior
(Vol. 13, pp. 257-293). New York: Academic Press.
Stevens, G. (2006). The age-length-onset problem in research on second language
acquisition among immigrants. Language Learning, 56(4), 671-692.
Taft, M. (1979). Recognition of affixed words and the word frequency effect. Memory &
Cognition, 7, 263–272
Tagliamonte, S.A. & Denis, D. (2008). Linguistic ruin? Lol!: Instant messaging and teen
language. American Speech, 83(1), 4-34. doi:10.1215/00031283-2008-001
Tan, T. X., Loker, T., Dedrick, R. F., & Marfo, K. (2012). Second-first language
acquisition: Analysis of expressive language skills in a sample of girls adopted
from China. Journal of Child Language, 39(2), 365-382.
Thompson, P. A. & Foulger, D. A. (1996). Effects of pictographs and quoting on flaming
in electronic mail. Computers in Human Behavior, 12, 225-243.
Tomasello, M., Carpenter, M., Call, J., Behne, T., & Moll, H. (2005). Understanding and
sharing intentions: The origins of cultural cognition. Behavioral and Brain
Sciences, 28, 675-735.
Tossell, C. C., Kortum, P., Shepard, C., Barg-Walkow, L. H., Rahmati, A., & Zhong, L.
(2012). A longitudinal study of emoticon use in text messaging from smartphones.
Computers in Human Behaviour, 28, 659-663.
Turkstra, L., Ciccia, A., & Seaton, C. (2003). Interactive behaviors in adolescent

48
conversation dyads. Language, Speech, and Hearing Services in Schools, 34, 117127.
Wagner, H. L. & Lee, V. (1999). Facial behavior alone and in the presence of others. In
P. Philipot, R. S. Feldman, & E. J. Coats (Eds.), The social context of nonverbal
behavior (pp. 262–286). Cambridge: Cambridge University Press.
Walther, J. B. (1995). Relational aspects of computer-mediated communication:
Experimental observations over time. Organizational Science, 6, 186–203.
Walther, J. B., & D’Addario, K. P. (2001). The impacts of emoticons on message
interpretation in computer-mediated communication. Social Science Computer
Review, 19(3), 324-347.
Winkielman, P. & Caccioppo, J.T. (2001). Mina at ease puts a smile on the face:
Psychophysiological evidence that processing facilitation elicits positive affect.
Journal of Personality & Social Psychology, 81, 989-1000.
Wolf, A. (2000). Emotional expression online: Gender difference in emoticon use.
CyberPsychology & Behaviour, 3(5), 827-833.
Yuasa, M., Saito, K., & Mukawa, N. (2011a). Brain activity associated with graphic
emoticons. The effect of abstract faces in communication over a computer
network. Electrical Engineering in Japan, 177(3), 36-44.
Yuasa, M., Saito, K., & Mukawa, N. (2011b). Brain activity when reading sentences and
emoticons: An fMRI study of verbal and nonverbal communication. Electronics
and Communications in Japan, 94(5), 17-24.
Zhang, Q., Li, X., Gold, B. T., & Jiang, T. (2010). Neural correlates of cross-domain
affective priming. Brain Research, 1329, 142-151.

49
APPENDIX A (ANOVA Table)
Test of between subjects effects in RT
Type III Sum of
Source
Squares
Corrected Model
16062024.291a
Intercept
9.855E8
PrimeType
58947.02
Age
15177939.17

Mean
df
Square
23 698348.88
1
9.855E8
2
29473.51
1 15177939.1
7
1 227174.12
1 155760.77
2
13375.53
2
11832.09
2
15305.48
1
673.31
1
9287.17
1
88234.38

TargetValence
227174.12
PrimeValence
155760.77
PrimeType * Age
26751.06
PrimeType * TargetValence
23664.18
PrimeType * PrimeValence
30610.96
Age * TargetValence
673.31
Age * PrimeValence
9287.17
TargetValence *
88234.38
PrimeValence
PrimeType * Age *
13344.93
2
TargetValence
PrimeType * Age *
1070.10
2
PrimeValence
PrimeType * TargetValence
150569.57
2
* PrimeValence
Age * TargetValence *
101480.40
1
PrimeValence
PrimeType * Age *
18649.13
2
TargetValence *
PrimeValence
Error
49958625.71 1942
Total
1.037E9 1966
Corrected Total
66020650.00 1965
a. R Squared = .243 (Adjusted R Squared = .234)

F
27.146
38307.993
1.146
589.999

Sig.
.000
.000
.318
.000

8.831
6.055
.520
.460
.595
.026
.361
3.430

.003
.014
.595
.631
.552
.871
.548
.064

6672.47

.259 .772

535.05

.021 .979

75284.78

2.926 .054

101480.40

3.945 .047

9324.56

.362 .696

25725.35

