Cycles of Invisibility: The Limits of Transparency in Dealing
with Scientific Misconduct

Felicitas Hesselmann
Humboldt-Universität zu Berlin, Deutsches Zentrum für Hochschul- und
Wissenschaftsforschung
hesselmann@dzhw.de

Martin Reinhart
Humboldt-Universität zu Berlin, Deutsches Zentrum für Hochschul- und
Wissenschaftsforschung
martin.reinhart@hu-berlin.de

Abstract: Sanctions for plagiarism, falsification, and fabrication in
research are primarily symbolic. This paper investigates sanctions for
scientific misconduct and their preceding investigation processes as
visible and legitimate symbols. Using three different data sources
(retraction notices, expert interviews, survey of scientists), we show
that sanctions for scientific misconduct operate within a cycle of
visibility, in which sanctions are highly visible, while investigation and
decision-making procedures remain mostly invisible. This corresponds
to high levels of acceptance for sanctions in the scientific community,
but rather low acceptance of the respective authorities. Such a punitivity
in turn exacerbates confidentiality concerns, so that authorities become
even more secretive. We argue that punitivity towards scientific
misconduct is driven by such a cycle of invisibility.

INTRODUCTION

I feel free when I see no one and nobody knows my name.
– Elizabeth Woolridge Grant & Richard Wright Nowels
Sanctions for scientific misconduct are primarily symbolic: Scientists who falsify,
fabricate, or plagiarize usually face sanctions directed at their reputation, instead of
1

prison sentences or monetary penalties. They are reprimanded, forced to retract
publications, or receive temporal bans on submitting papers to certain journals. The
symbolic weight of such “mild” forms of punishment is, nonetheless, considerable
within the scientific community, as the associated loss of reputation can negatively
impact collaborations with colleagues, publication success, or job opportunities,
even to the point of effectively ending research careers. Understanding the
punitiveness of primarily symbolic sanctions in academia, where punishment relates
to practices of knowledge production, requires a concept of visibility (Brighenti
2007), as visibility has been shown to be of central importance both to the labelling
of deviance (Inciardi 1972) from a societal reactions perspective in criminology
(Grattet 2011) and to knowledge production throughout the history of science from
a social studies of science perspective (Daston & Galison 2007). In both domains,
being able to make something visible, be it a scientific fact or a punishment for
misconduct, exemplifies knowledge and power at once (Foucault 1978).
Visibility is also closely tied to the legitimacy of sanctions as well as
authorities: Visibility can help create legitimacy for penal authorities, particularly in
the form of transparency (Mehrpouya & Djelic 2014). It is at the same time also
embedded in particular regimes of visibility (Brighenti 2007) and influenced by
cultural notions about the legitimacy of what can and should be made visible or
presented to public view (Foucault 1977; Pratt 2000; Smith 2008).
The present paper investigates sanctions as visible symbols, looking at the
processes preceding sanctions, such as investigations, trials, and sentencing
decisions. Its focus is on exploring how such processes are shaped by interactions
between visibility and legitimacy. Taking into account the signification practices
preceding symbolic sanctions we ask how coercive acts become legitimated as
punishments through investigations and trials, how punishment retroactively affects

2

the legitimacy of the trial, as well as how acquittals, as the often neglected
counterpart of punishment, fit into such a symbolic conception of penal activity.
We use the investigation and sanctioning of scientific misconduct as an
exemplary case that differs from judicial practices of visibilization in important
respects. Such an investigation poses two challenges: First, institutions for dealing
with scientific misconduct are fairly new and heterogeneous, with little empirical
research on how they operate. Second, sanctions and punishment in science are
issued by numerous actors—universities, journals, funders, etc.—forming a penal
system with limited transparency, i.e. with fragmented patterns of visibility
(Hesselmann et al. 2017), so that knowledge from criminology and the sociology of
deviance is of limited value. Hence, one of the most common assumptions about
penal systems does not hold for the case of science, namely that punishment relates
to a central authority in a national context under the rule of law.
The empirical analyses utilize three different data sources that each provide a
unique perspective on misconduct cases, their investigations and the ensuing
reactions. First, semi-structured interviews with individuals responsible for handling
cases of scientific misconduct at journals, universities, publishers and funders shed
light on the processes behind sanctions such as retractions. Second, semiotic analyses
of retractions and retraction notices provide insight into the symbolic strategies of
the most visible form of sanctions. Third, data from a survey of German researchers
account for the symbolic impact of visible sanctions within the scientific community.
We find that sanctioning practices mainly operate on a case-by-case basis with
enacting individuals that refrain from identifying as a sanctioning authority.
Retractions primarily symbolize that a sanction has been issued and they provide
little transparency as to what processes preceded the formal retraction. Scientists
show exceptionally high approval of retractions in conjunction with a considerable
support for punitive measures in general. We conclude that sanctions for scientific
3

misconduct operate within a cycle of visibility: The challenges in making visible the
processes that precede the sanctions, such as their rare and incidental character, as
well as confidentiality concerns, result in a high visibility for sanctions and a low
visibility for the procedures leading up to them. Sanctions enjoy high support as the
only visible element, leading to a relatively high punitivity in the scientific
community. This punitivity in turn exacerbates the institutions’ concerns with
confidentiality. The lack of a central penal authority strengthens the significance of
symbolic aspects of sanctions to ensure trust in community-controlled forms of
social control.

FROM AN IDEAL TO A DEEPLY CONFLICTED VIEW OF
SCIENCE

Scientists see themselves as less prone to error, bias, and dishonesty and thus as more
rational and objective than the rest of the population. This view is shared by nonscientists, even though they see the difference as less pronounced (Veldkamp et al.
2017). An idealistic image of science seemed to prevail up to the present. Scientific
misconduct was seen as “extremely infrequent” (Merton 1957: 651) and as highly
unexpected behavior from individuals that were generally believed to be superior in
honesty, thus, providing little reason for addressing misconduct as a significant
social problem that would require countermeasures. However, it seems that this
“storybook image of the scientist” (Veldkamp et al. 2017) is about to vane.
Numerous measures to uncover, sanction, or prevent scientific misconduct
have been implemented in the last decade and the rising number of retractions has
been emblematic for this development (Hesselmann et al. 2017). National
organizations for research integrity (e.g. the ORI in the US), online platforms (e.g.
PubPeer, RetractionWatch), ombud systems in research organizations, and codes of

4

conduct in scientific publishing, are becoming more visible within science and in the
public. These initiatives form an emerging judicial or penal system (Cavadino,
Dignan and Mair 2013: 1ff.) within science,1 and despite their emerging and
dynamically changing activities, these initiatives have made increasing numbers of
cases of misconduct visible. As a result, scientific misconduct is beginning to be
treated by many as a widespread phenomenon for which the frequently referenced
image of a “tip of the iceberg” is indicative (Sovacool 2008).
Accepting misconduct as a more widespread phenomenon than traditionally
acknowledged has rendered questions regarding the capability of science to
effectively govern itself (e.g. through peer review) more prevalent (Guston 2000)2.
With respect to misconduct these questions revolve around issues well known to
criminology and the sociology of deviance (Faria 2018; Hesselmann et al. 2014):
detection (e.g. can allegations be made anonymously on social media platforms and
who can investigate?), sentencing (e.g. does a retraction suffice or are criminal
charges necessary?), and reporting (e.g. should punishment for scientific misconduct
be made public or kept confidential?). On the one hand, these issues address practical
concerns, as determining the prevalence of scientific misconduct accurately and
finding best practices to deal with scientific misconduct are relatively new and
difficult. On the other hand, the increased visibility of scientific misconduct forces
scientists and the public alike to make sense of scientific misconduct when the
conventional storybook image of science where misconduct is infrequent (Merton
1957: 651) does not apply anymore. Both aspects, practical concerns and meaning
making, come together in the most frequent stance in current debates, which

1
Judicial and penal system are used in a very broad sense here, as these initiatives are
only partially official, i.e. tied to national or international authorities, and only partially tied
to the conventional criminal justice system.
2
In the wider context, these questions also address perceived problems in
reproducibility (Atmanspacher & Maasen 2016) or translatability (Blümel et al. 2015) of
research.

5

interprets scientific misconduct as something that happens “in the dark” and for
which transparency and public accountability are the most evident countermeasures
(Sovacool 2008).

THEORIZING MISCONDUCT AS AN ISSUE OF VISIBILITY

The idea that transparency fosters accountability has a long and rich history
(Mehrpouya & Djelic 2014). It is commonly accepted in Western Societies that
transparency is closely tied to democratic ideals and legitimizes forms of social
control. Liberalism, and especially Adam Smith (1981, 2004), argued that economic
and political transparency go hand in hand as the market allows for social control by
the many (Mehrpouya & Djelic 2014: 17). However, transparency can also be
invoked to legitimize the control of the many, as e.g. in Jeremy Bentham’s ideas
exemplified by the Panopticon (Bentham 1781, Foucault 1977). While transparency
is generally seen as being good and desirable, it has, however, no clear link to
specific forms of social control and can be invoked to justify different governance
regimes (Mehrpouya & Djelic 2014). The same can be said for visibility as a more
“general category for the social sciences” (Brighenti 2007: 323), in that visibility and
control align in multiple ways, as has been shown in criminology and the sociology
of deviance. Labelling theory has introduced the idea that whether persons and acts
are seen as deviant, is mainly determined by their visibility (Lemert 1967, Inciardi
1972). The work of sanctioning authorities and systems of social control consists
largely of detecting and uncovering previously hidden, invisible acts (crimes) and
making them visible to the public through sanctions, which often entails
stigmatization of the offender, who is pushed from invisibility into a zone of
hypervisibility (Brighenti 2010: 47). More generally, visibility plays a defining role
in any measure to detect, clear up, sanction and prevent misconduct.

6

The relationship between the visibility of sanctions and the visibility of penal
institutions, thus, becomes a central theoretical and empirical issue. A sanction does
not follow naturally from a rule-breaking act, rather, it needs to be created through
processes such as police investigations, court procedures and ultimately convictions.
Sanctions in turn reflect back on the behavior under investigation by visibly
interpreting it as acts of deviance (Kitsuse & Spector 1975). In the case of the modern
Rechtsstaat, this relationship can be described as a high visibility of the judicial
process, including all its decisions, and a very low visibility of the sanction
(McGowen 1994; Pratt 1998). Such a regime of visibility draws meaning and
legitimacy from the aforementioned idea that transparency fosters accountability
(Mehrpouya & Djelic 2014). Here, the legitimacy of the outcome depends on the
judicial process and on the values, such as fairness, equity and formalism, that this
process is believed to embody: “‘rightness’ is automatically conferred on any
decision the system produces” (Fish 1994: 177). The process outshines its outcome,
such that convictions and acquittals signify judicial decision-making rather than guilt
or innocence; and behaviors are not so much interpreted as deviance or integrity, but
as behaviors that are, in principle, liable for trial in a court of justice.
In the case of scientific misconduct and the institutions to uncover and
sanction misconduct, however, this relationship between visibility on the one hand,
and power and control and on the other hand might be less clear-cut. As scientific
institutions, they are doubly concerned with visibility: they are involved in the
production of knowledge, and as institutions of social control they are concerned
with the “visibilization” (Brighenti 2007: 34) of such knowledge production.
Depending on the circumstances, visibility can increase or decrease power and
further or hinder knowledge production. “Visibility is a double-edged sword: it can
be empowering as well as disempowering” (Brighenti 2007: 335). Current societies
have developed more complex lines of sight than the relatively simple visual
7

architecture of the Panopticon in that those watching and those being watched as
well as those in control and those under control are implicated in multipolar regimes
of visibility, i.e. decentralized panoptism (Maasen & Sutter 2016). Both the public
and authorities of social control are involved in creating, demanding, resisting and
overthrowing areas of visibility as well as invisibility. This is also the case with
respect to scientific misconduct. A multiplicity of actors is rendering misconduct
visible by uncovering and sanctioning: journals, whistleblowers, the ORI, ombud
systems, collaborative online platforms, etc. with no discernible central authority.
How visibility and control align in science is thus the open question we address by
analyzing how scientific misconduct is currently made visible.

METHODS

The analysis employed a mixed methods design (Tashakkori & Teddlie 2003),
combining three different data sources and quantitative as well as qualitative
methods. Data sources were chosen in order to provide different strategic
perspectives: A perspective on the processes at place to investigate and sanction
scientific misconduct at scientific organizations (1); a perspective on the way the
outcomes of these processes are communicated to the scientific community (2); and
a perspective on how those processes and sanctions are perceived by the scientific
community (3).
The first dataset consists of 31 semi structured expert interviews with those
responsible to investigate and sanction scientific misconduct at journals, universities,
publishers and funders. The sample comprises 11 officials of German universities, 3
officials at external research institutions, 9 journal editors, 3 officials at publishers,
3 officials at funders, one spokesperson for the Committee of Publications Ethics
(COPE) and the German Ombudsman for Science. Respondents were asked about

8

their previous experience with scientific misconduct cases, their institutions’
procedures for handling cases, their outside communication and their cooperation
with other actors and organizations, and their evaluation of their positions. As the
first step of data analysis, the resulting interview transcripts were analyzed with a
content analytical approach (Mayring 2010). Secondly, specific passages were
selected for a qualitative in-depth analysis along the themes previously identified
through content analysis. These themes comprised segments discussing external
communication strategies, lack of transparency of own or other organization, lack of
control of compliance with policies, and the instrument of publishing bans. The
selected passages were analyzed with a sequential analytic procedure (Maiwald
2005; Keller & Truschkat 2014).
The second dataset consists of 127 retraction notices (see also Hesselmann &
Reinhart forthcoming) that inform readers about articles retracted for fraud,
plagiarism, or honest mistakes. Retraction notices were sampled using the three
databases Web of Science (53), EconBiz (41) and JSTOR (33). Depending on the
characteristics of the respective database, different search strategies were employed:
the Web of Science was searched for (title = retraction, doctype = Correction or
doctype = Correction, Addition), based on a search strategy by Fanelli (2013; see
also Schmidt, 2017). EconBiz and JSTOR were searched for (title = retraction*).
False positives were then manually removed, before sampling notices randomly
stratified by period for JSTOR (1980-1989; 1990-1999; 2000-2014), and for WoS
(1990-1999 and 2000-2014). All 41 notices identified in EconBiz were used. Notices
were analyzed linguistically, with focus on the textual moves (Upton & Cohen 2009)
as well as grammatical agent, voice (Rundblad 2007; Swales 1990), narrative mode,
and authorial references (Harwood 2005; Hyland 2002).
The third dataset includes data from the German Scientists Survey (Neufeld
& Johann 2016). This survey interviewed scientists at German universities at both
9

mid-level and professorial level. The items used in the present analysis concerned
the respondents’ acceptance of the different authorities and procedures dealing with
scientific misconduct, as well as their support for various possible punitive and
corrective measures.

CONCEPTUAL ANALYSIS I: INTERVIEWS

The first perspective is provided by semi-structured interviews with persons
responsible for conducting misconduct investigations at various scientific
organizations. Formally, they are typically the first point of contact for
whistleblowers and other people wanting to report suspected cases. Depending on
the cases, they can decide to dismiss the accusation or carry out investigations,
including sequestering evidence, analyzing data and documents, and interviewing
the involved parties and possible witnesses (see also Horbach, Breit & Mamelund
2018; Wager 2007; Wilson et al. 2007). Additionally, depending on the cases, they
can also try to resolve the matter informally, through providing consultations or
mediations between the parties, an approach that is particularly prevalent with
ombudspersons. Based on the investigations, actors then form an opinion about the
case and can be involved in final decision-making concerning cases to various
degrees: While ombudspersons and investigative committees at universities and
research organizations only issue recommendations to the university’s management
who then are in charge of deciding about punitive or other measures, journal editors
can typically make decisions about corrections and retractions independently. The
interviews conducted here aimed at understanding these processes in more detail
beyond their formal delineation, including the specific understandings the actors
developed of their work. In particular, we were interested in how those actors relate
their investigative work to issues of visibility and legitimacy.

10

Informal Procedures
Most respondents describe misconduct cases as exceptional, non-routine events that
do not allow for the development of standardized courses of action (see table 1 for
an overview of the results). Previous experience with cases varies widely between
respondents: 4 respondents had encountered no cases so far, 13 respondents
encountered between 1 and 10 cases, and 7 respondents encountered more than 10
cases, two of which said they investigated more than 200 cases3. Most respondents
describe their work as very weakly routinized: Cases are perceived as idiosyncratic
and diverse, hence not allowing for catch-all or standard approaches. In addition,
very few respondents report receiving formal training when first acquiring their
position. Rather, they employ a learning-by-doing-approach, which requires
constant adaptation to new cases and problems.
Consequently, processes are frequently described as following a case-by-caselogic rather than having a clear-cut procedure in place. While respondents do report
utilizing institutional policies, flowchart diagrams or other resources and at times
also demonstrate quite extensive knowledge of formal definitions and guidelines,
they also often describe policies as being more in the background and too abstract or
ambiguous to aid decision-making, and sometimes report having no knowledge of
the respective institutional policies at all. Respondents also frequently discuss
situations in which cases reached an impasse and could not be resolved; possibly,
the existing decision-making procedures are insufficient for addressing the high
uncertainty inherent in many cases. Additionally, many respondents resort to
informal networks and solutions to advance investigations.

3

Seven respondents did not give an estimate of the number of cases they
encountered, those include the Committee of Publications Ethics (COPE) and the three
Publishers, all of which presumably have seen (much) more than 10 cases, and two journals
and an ombudsperson, for whom approximations of the number of cases are not possible.

11

Cases sometimes require inter-organizational cooperation, such as between
journal editors and university ombudspersons, to proceed with investigations.
Despite relying on informal networks, respondents frequently mention a lack of
transparency with regard to the responsibilities and processes of other actors,
describing investigations at other institutions as nontransparent and inscrutable.
They discuss situations in which working together or sharing information with other
organizations failed. Communication between organizations is often described as
minimal, providing only short reports on investigation results and almost no insight
into the respective investigative processes. Still, interviews also frequently contain
descriptions of transparent responsibilities and successful cooperation between
actors. A more detailed look at the data reveals that most successful collaborations
involve different actors at the same institution, such as ombudspersons and
investigative committees, while inter-organizational cooperation seems more prone
to failure.
These interviews also highlight that most of the respondents are
fundamentally critical of their own processes and positions, frequently discussing
problems or contradictions they face, lament lack of effectiveness of their
interventions, and dis-identify with their position altogether. To avoid the pitfalls of
highly uncertain and unresolvable cases, respondents describe their preferred course
of action as staying rather passive and not taking a lot of initiative. Misconduct
investigations are thus pictured as highly uncertain, idiosyncratic processes that do
not allow for routines, standardization or professionalized procedures, but that need
to be approached on a case-by-case basis. Formalized policies and guidelines
seemingly provide only minimal orientation, placing high demands on the
respondents' ability to navigate uncertain and highly ambiguous situations. Many
respondents thus express dissatisfaction with their position and their responsibilities,

12

describing them as a necessary but ultimately unpleasant duty to the scientific
community.
The value of transparency
An in-depth analysis into how these actors communicate details about their
investigations to a larger scientific audience and how they in turn get informed about
other actors' investigative processes reveals that respondents recognize the value of
transparency, both for facilitating cooperation between actors and for creating public
trust in misconduct investigations:
"So I mean, a retraction is not good for the reputation, but it … there
can be some recognition for the journal if the retraction is handled
properly and transparently. So the critical thing would be to make sure
there is a due process and that it does make an informed decision and
that that notice is as transparent as possible in terms of what the issues
were. And I think, again, it is due process and transparency. And I think
that, depending on how the issue that arises is handled, it can be actually
not a bad thing for the journal if they are seen as having very robust
processes in place." (Journal 6: 81)
As this quote illustrates, transparency is mostly created on a case-by-casebasis, especially in the event of a retraction. Typically, publicly available
information about investigations differs according to whether they resulted in
findings of misconduct or not. The Office of Research Integrity (ORI), a US
oversight body, for example, only publishes case summaries of cases that resulted in
convictions,

not

of

cases

that

resulted

in

acquittals

(https://ori.hhs.gov/case_summary). Likewise, retractions only publicize cases
which attest to problems with articles (be they misconduct or error), while there is
no publication format for investigations that do not substantiate the original
allegations. Transparency is thus thought of mainly as an event. Consequently,
respondents struggle to make visible their day-to-day activities and even their
existence:

13

"That the work took up so slowly is also partly due to the fact that at
least in the beginning, the visibility of the commission within the
university was not very good. Today, that is a little better, after you start
working with the internet more and more, even though … I will meet
with a colleague in a few days who is also a member of the commission,
we want to improve our online presence, because, simply, if you do not
know anything about the commission, and don't know its name, then it's
very difficult to find it." (Investigative Commission University 5: 79)
Independent of convictions or high-profile scandals, it seems difficult to make
the existing system visible to a wider audience and to prove that it is working
properly. This shows both as a struggle for respondents to make their own positions
known to others and as a difficulty to gain insight into others' processes and
investigations: As discussed above, inter-organizational cooperation is seen as
highly problematic and prone to failure. One of the main reasons for this is a
perceived lack of communication about ongoing investigations and a general lack of
transparency with regard to responsibilities and organizational structures:
"There's a fixed protocol that we publish also on our websites. It's
basically a flowchart. And one of the steps in the flowchart is that you
should always notify the managers of that particular person who is
being investigated, including the university integrity officer, if that
exists. But at the same time, I would say that's one of the big areas where
I see room for improvement because, if you go to a university website,
you can hardly ever find the responsible person for raising these cases.
So universities could make this more visible on their website I think.
And they could be more transparent that they have a role to play and
that they have nominated people to deal with these cases and create a
form of some sort or an email address or whatever and so that people
can report on cases." (Publisher 3: 16f.)
Throughout these complaints, lack of transparency is often equated with lack
of actions taken. The interviews reveal a pervasive suspicion of cover-up and
obfuscation which, perhaps ironically, respondents both hold against other
institutions but also feel threatened by themselves. Lack of publicly available
information about cases by default is taken as a sign that the respective institution
remained inactive and has no interest in getting to the bottom of allegations:

14

"Well with retractions we will also notify the institution, most of the
time. And there isn't much more we can do. Well, if the dean simply
says, 'Okay, I think that's great!' there's not much more I can do, yes?
Yes. [I: In your experience, what is the reaction of universities?] Well,
that also differs. Sometimes you hear back immediately and sometimes
you don't hear anything at all, then there's probably also nothing
happening. Yes." (Journal 7: 101)
In contrast to other calls for transparency that are motivated by the fear that
lack of public oversight increases unwanted action, such as corruption or unusual
punishment, transparency in this case is thought of as a means to compel institutions
to take action, rather than to hinder them. What these excerpts highlight, then, is that
respondents generally acknowledge the value of transparency, even though their
hopes for transparency are often disappointed. They both expect other actors to
provide transparent processes and at times strive to make their own work more
visible and accessible to others.
The value of confidentiality
Despite this general belief in transparency, however, the interviews also show that
at times, respondents also value confidentiality, secrecy, and non-disclosure, thus
actively contributing to an overall lack of transparency. A prominent situation in
which respondents report prioritizing confidentiality over transparency is if
publication of information has the potential to hurt any of the involved parties, such
as the complainant or the defendant:
"Well the idea […] that any institutions are contacted, either
universities or something like that, that does not happen. To me it also
seems to be completely unusual in the entire Anglo-Saxon domain.
When I somehow addressed that [in the editorial meeting] all the
Britons crossed themselves and said: 'That you cannot do!' Because the
consequences are also massive, yes? Well in that case you obviously
also destroy academic careers [I: Yes, yes.]. And nobody really wants
that." (Journal 10: 62 ff.)
As can be seen in this quote, the assessment whether information is potentially
harmful can be quite broad; here, any sharing of information is considered dangerous
15

and even morally reprehensible, thus calling for entirely confidential processes.
Another reason to avoid enforcing transparency is to protect a climate of trust
between scientists. Here, transparency is mostly seen as a form of monitoring and
surveillance that editors, ombudspersons and other officials enact vis-à-vis
researchers and that is mostly portrayed as negative. It is contrasted with a culture of
trust that eliminates the need for constant, ongoing control:
"I also think that you can organize that in a positive way. I also think
it's bad if it eventually looks like every researcher was a potential
fraudster and that I have to assume that in general and… But I'd wish
that we fostered a culture of trust, because it just doesn't work
otherwise. I have to trust things all the time and I also have to be very…
well, if something goes wrong, that does not mean somebody with bad
intentions…" (Ombudsperson University 5: 223)
The lack of transparency that is created out of the concern for others, however,
also gives rise to informal procedures, reduced accountability and a form of secret
knowledge that is only shared among particular circles. Information is shared
strategically, to enable cooperation between certain actors and hinder cooperation
with others. It becomes a tool actors can use to achieve specific goals:
"What we do have is a possibility to flag certain authors to one another.
[…] But it's really on an editor in chief level. We actually sometimes
do it at [publisher level] as well, where we have come across someone
who is, we have a case right now, who has published a lot of articles,
was very prolific. […] And then we see a pattern in those cases. Yeah,
we have to, we then talk to one another internally and say, 'We have
come across this case. At least alert your editor in chief to this particular
person and let him or her investigate as well what has happened for that
particular journal.' And I think that's also our role. It's a bit… you have
to be careful how much information you want to share. This is always
very confidential. And it's making our lives here as a publisher quite
complicated because people expect us to take certain actions. And
sometimes, they don't understand our confidentiality and legal issues
with that." (Publisher 1: 152)
Confidentiality then serves multiple purposes. On the one hand, it protects the
reputation and the careers of third parties involved in investigations and it shields
research staff against constant scrutiny and surveillance. On the other hand, it also
16

helps to create information that is valuable precisely because it is not publicly shared
and that can be used to form alliances, push certain goals and gain comparative
advantages, as in the quotation below:
"Of course we also have databases where we can include comments,
where we can also have authors, when you say there was misconduct,
and then it is also possible that you say, okay, this author gets banned
for a certain amount of time. And that is also included in the databases.
But we refuse to share this database with others and to make it public.
[…] Others will have to find that out themselves." (Publisher 2: 22)
Having access to information becomes a valuable resource as well as a token
of status and power. Respondents' criticism about the lack of transparency that is
directed against other institutions and organizations can also be read as a protest
against being excluded from resources, alliances and suffering disadvantages in the
context of institutional politics. In the quotation below, the respondent laments the
lack of transparency within her own organization:
"When there's a suspicion, for example involving a dissertation, I do not
hear about that. Because I only learned indirectly that somewhere a
doctorate degree was revoked. And… and then I asked if that happened
frequently. Because it was said that it happened a couple of times
recently. But I am not informed of that. It is only if somebody comes to
me with a problem." (Ombudsperson University 4: 47)
The lack of information is seen as a set-back and an undermining of the
respondent's authority as an ombudsperson. Although being able to resort to informal
flows of information, the respondent seems dissatisfied that she is not included in
the official communication chain, which she also sees as a lack of institutional
support for her position. Withholding information thus also creates and enacts
hierarchies both within and between organizations. Notably, it is again only in the
event of a conviction (revocation of a degree) that information about investigations
is shared at all. Even internally, transparency is created in the form of specific events,
rather than as a constant state.

17

The interviews thus reveal that while transparency is seen as a positive goal
in general, it is rarely achieved in misconduct investigations. Besides cases being
idiosyncratic and procedures being messy, which impedes orientation and
transparency, information is also consciously withheld for reasons of confidentiality.
Classified information in turn becomes a tool for actors to further various interests.
It becomes apparent that actors do feel pressured to release information about cases
to prove that they are indeed taking action, but that processes at the same time are
considered highly confidential. Actors do struggle with making visible that they are
getting work done and occasionally develop strategies to communicate their
responsibilities on a more abstract level, such as creating specific websites and
contact-forms for ombudspersons at the university level.
It is only in the moment of conviction and public sanction (like a retraction)
that the institutions' work is made visible and the institutions are provided with a
chance to gain acceptance in the wider community. Thus, the particular ways in
which public sanctions shed light on the investigating authorities behind them are of
central importance when trying to understand the relationship between visibility and
legitimacy. For this reason, the analysis will now move on to retraction notices and
the representation of misconduct investigations they provide.

CONCEPTUAL ANALYSIS II: RETRACTIONS

Retraction notices can serve both as a correction to the literature and as a shame
penalty (Karp 1998) for scientists who committed misconduct. In either case, they
are an important format for communicating details about investigations to a wider
public and hence to contribute to, or to cloud, the transparency of those processes.
As has been shown elsewhere (Hesselmann 2018; Hesselmann & Reinhart
forthcoming), retraction notices are generally short on details and offer only minimal

18

information about the scientific problem under investigation and on the
investigations themselves, often creating ambiguity instead of providing
clarification. The present analysis focuses on the question of how retraction notices
selectively assign authority for specific tasks to specific actors, thereby negotiating
legitimacy.
In general, the text of the notices can be categorized into the four different
processual steps of (1) the detection of the problem, (2) the investigation of the
problem, (3) the decision-making and (4) the implementation of the retraction. In the
texts, those steps are typically associated with different groups of grammatical
agents.
As can be seen from figure 1, grammatical agents can be divided into two
groups with different responsibilities: The first group of actors, comprising authors,
investigative commissions and other external actors (e.g. readers, anonymous
whistleblowers and third parties), is mainly mentioned in the context of detection
and investigation of problems. The second group of actors, mainly actors from the
journals (i.e. journal editors and publishers), and authors, is mainly associated with
decision-making and implementing retractions. Journal editors (and publishers)
seem to take on a very specific responsibility, as they are most often assigned the
responsibility of deciding upon retraction and subsequently enacting this decision
and are hence most often associated with the role of the sanctioning authority.
Authors on the contrary are the only actors that belong to both groups, so their role
in retraction notices seems less clearly defined then for the other actors.
However, the data reveal a third category of “no agents” that warrants specific
attention: This category comprises segments that only use agentless passive clauses,
dummy it-subjects, metonymies or noun phrases. These clauses appear most often in
the context of the implementation of the retraction, such as in these examples:

19

“We are therefore informing our readers that this article has been
retracted.” (WOS51)
“This article has been retracted due to plagiarism.” (WOS35)
"In consequence, the article must be withdrawn." (JSTOR4)
As can be seen in figure 1, the detection of problems also frequently features
linguistic strategies that obscure the responsible actors:
“Concerns were raised about […]” (WOS66)
"Shortly following publication it was brought to the attention of the
editors that […]" (ZBW36)
It thus often remains unclear how investigations were first set in motion, and
who took on the responsibility of retracting the article in the end. The only fact
clearly discernible is that the article has been retracted, leaving the retraction as the
sanction as the only visible sign. The procedures and especially the authorities
behind the sanction on the other hand remain invisible in many cases. This finding
in turn begs two questions: How are those vague and rather obfuscating retractions
perceived in the scientific community? And how legitimate do the often invisible
authorities appear to be?

CONCEPTUAL ANALYSIS III: SURVEY

To answer those questions, we turn to the third perspective from survey data from
the German Scientists Survey 2016 that is concerned with the scientific community‘s
view of institutions and measures dealing with misconduct. As part of the survey
respondents were asked the following question: "Regardless of how serious the
academic misconduct may be: in your opinion, which measures are appropriate in
principle as sanctions against academic misconduct?" Results (see table 2) show that
retractions enjoy exceptional levels of support, as 81.8% of respondents consider
retractions to be an adequate reaction to misconduct in any case, with the revocation
of funding decisions as the second ranking intervention only reaching an acceptance
20

rate of about 40.3%, and the debarment from funding at 37.8%. There are relatively
high rates of conditional support for the termination of employment and other legal
consequences according to public services law, with 72.2% and 62.0% of
respondents finding them appropriate under certain circumstances, respectively. The
reactions considered the least acceptable are discussions on social media, with
almost 45% of respondents finding them entirely inappropriate, followed by
informal reactions, which gain ambivalent levels of acceptance: While 32.8% of
respondents think informal reactions suitable in any case, 23.1% think they are
completely inappropriate.
A second issue concerned the acceptance of different authorities, which was
measured by the following survey question: "A range of very different institutions
and persons is involved with examining and sanctioning academic misconduct. In
relation to academic misconduct in general: in your opinion, which of the following
persons or institutions are suitable for the work of exposing, examining and
sanctioning misconduct?" Taking a closer look at the respective areas of
responsibility (see table 3), three distinct groups of institutions emerge, depending
on which of the areas gains the most acceptance: The first group contains actors that
are seen as responsible for the detection of misconduct cases, those are the reviewers,
colleagues and superiors, internet-based initiatives, Editors, and the general media.
Such diversity also mirrors the wide range of actors that retraction notices report as
initiating investigations. The second group contains actors that enjoy support for
being involved in investigations; these are investigative committees, university
ombudspersons, and the German Research Ombudsman. The third group comprises
only two actors, department leaders and law enforcement authorities, which are seen
as legitimate authorities for the punishment of misconduct.
Summing up the support for institutions across the different areas of
responsibility (detection, investigation, punishment), investigative committees take
21

the lead, followed by department leaders and superiors and colleagues. In contrast,
institutions that are mainly active outside of science, such as internet-based
initiatives and the general media only garner very low levels of support. A notable
exception here are journal editors: Despite journal editors typically being highly
regarded in the scientific community, about 30% of respondents believe that editors
neither have a legitimate role in the detection, the investigation, nor the punishment
of scientific misconduct. Reviewers as well have rather low levels of overall support,
though a large majority (77.5%) believes they have a legitimate role in the detection
of misconduct cases, with the other two areas gaining rather low acceptance.
Comparing acceptance levels thus does not yield a clear pattern: While the
low levels of support for social media discussions are in line with the meagre
legitimacy of the respective institutions (internet initiatives and general media), there
is a striking difference between the surprisingly high support for retractions and the
low support for Editors (especially when considering the area of punishment).
Journal editors do not enjoy high support by the scientific community when it comes
to dealing with misconduct. Their rates of disapproval are even slightly higher than
those of internet-based initiatives. Likewise, the relatively high levels of opposition
to informal reactions conflict with the preference for informal solutions expressed
by the responsible authorities in the interview data. Still, the vast majority of
respondents are in favor of sanctions, with 90.4% believing refraining from sanctions
is never appropriate. This strong overall favor for sanctions does not seem to stem
from a general support for punishment authorities but seems rather surprising given
the highly differentiated and often critical view scientists hold of the various
authorities and their ascribed areas of responsibility.

22

DISCUSSION

Comparing these different data sources allows us to trace the creation (and
prevention) of transparency in weakly standardized procedures and to investigate its
consequences for public support for the respective authorities. Because misconduct
cases are rare events that are each experienced as idiosyncratic and one-of-a-kind,
most actors solve this problem by falling back on case-by-case approaches that make
investigations seem highly unplanned, unstructured and almost erratic. At the same
time, confidentiality presents a central concern, as some of the identities of the
involved need to be protected, investigations are carried out occluded from public
view. Furthermore, confidentiality is not just a necessary requirement but provides
valuable resources in the form of confidential information for those that need to
handle and decide upon misconduct cases. In this situation, it is only through
sanctions that the highly inscrutable system of social control in science becomes
visible at all. Sanctions present a way for actors dealing with deviance to prove that
they are indeed performing the task they were mandated with, instead of remaining
passive and sweeping problems under the rug. For the wider community, sanctions
present both a way to generate knowledge about deviance, which otherwise occurs
only in secret, and to verify that the responsible actors are working appropriately.
They are hence the only events that generate a form of retrospective transparency for
a system that otherwise remains confidential and rather secretive.
The specific relation between visibility of the penal procedures and visibility
of the ensuing sanctions that is encountered here differs markedly from the model of
the Rechtsstaat. Here, only convictions and the ensuing sanctions are visible to the
wider public, while the investigations and trials are not made transparent. There are
a number of reasons for such a lack of transparency. When particularly sensitive
information is involved, confidentiality concerns arise. The benefit of transparency
is also relative to a specific point of view: while for the general public transparency
23

is usually empowering, the actors and authorities involved in the processes under
question are typically much more critical of claims for transparency (Ringel 2018),
because they see it as threatening their autonomy and subjecting them to additional
control (Florini 2000). Legitimacy of these processes seems much more problematic
and depends to a large part on the specific outcome of the procedures. The conviction
and specifically the ensuing sanction retrospectively and selectively shed light on
their own process of production. Sanctions serve as the only kind of reliable
information communicated to the public and thus confer a sense of legitimacy on the
processes that produced them. In this scenario, acquittals appear as very problematic.
Acquittals as non-decisions, as decisions not to decide (Derrida 2005: 15), seem like
non-results of investigations and trials, and produce a sort of twilight visibility for
the processes and authorities issuing them: While the authorities become visible in
principle, they have nothing to show for their work, and it seems dubious whether a
proper investigation was even performed at all. The process is not legitimized and
falls apart into decisions that are neither transparent nor comprehensible and that are
thus particularly difficult to justify. Acquittals also fail to give meaning to the
behavior under question, as they do not clearly mark it as deviance on the one hand
but also fail to obscure the traces of the investigation process on the other hand and
hence also cannot eliminate doubt concerning innocence: If there really was no
transgression to begin with, why was it even necessary to open an investigation?
Our empirical analysis of the procedures surrounding scientific misconduct
suggests that in science, visibilization mainly relies on sanctions. Such a finding may
be intuitive and counter-intuitive at the same time. The intuitive part comes from the
fact that visibility is not only related to phenomena of social control and power but
also to knowledge, as in order to know something it has to be seen (Daston & Galison
2007). Modern western societies insist on the necessity to render things visible to be
valid knowledge (or legitimate power). Scientific norms and values reflect this by
24

demanding not only that knowledge claims have to be communicated openly but also
that the process producing new knowledge be, at least in principle, retraceable and
reproducible (Merton 1973). The need to balance transparency and opacity lies at the
heart of the politics of science (see the debates on open access, open data, or
responsible research and innovation) and justifies regimes of social control. In
science, such regimes of control are conceived as mechanisms of quality control,
such as peer review (Shapin & Schaffer 1985, Biagioli 2002, Reinhart 2012),
effectively rendering control over scientists and their practices as issues of the
quality of knowledge. However, these regimes also create opacity or limit access to
only a select few, for instance by blinding and anonymizing in peer review
procedures and excluding the public from the decision making process.
Such an overreliance on sanctions to generate visibility, and consequently,
legitimacy, translates into a rather punitive climate within the scientific community,
who constantly calls for more and more sanctions. While the authorities themselves
enjoy very variable levels of support, sanctions are seen as the go-to solution for the
problem of scientific misconduct. Support is especially high for sanctions such as
retractions that shed a (momentary) light on these authorities, even though the
insights they provide into penal processes remain limited and highly selective It is
only in these moments of sanctions that authorities seem somewhat transparent and
amenable to public control. Sanctions, that are confidential or that are not made
visible to a wider audience by contrast, such as informal reactions or various legal
consequences are mostly not seen as helpful. Likewise, sanctions that do not provide
a glimpse of the associated actors and authorities are not very well received:
Discussions on Social Media and other web-based platforms often involve
anonymous and pseudonymous participants, which is heavily criticized. Here, the
sanction violates confidentiality, but without also providing a however fleeting

25

insight into the system of social control that produced it. Consequently, it is seen as
doing more harm than good to the community.

CONCLUSION

The regime of visibility found here can be described as circular and retractions serve
as a characteristic illustration of this circularity: The procedures to uncover, to
handle, and ultimately to sanction scientific misconduct need to be kept mostly
confidential. In the case of retractions, there is little that can be inferred from
retraction notices as to the work of investigation committees or editorial offices that
led up to the decision to retract. Since the invisibility of dealing with misconduct
raises the suspicion of inactivity, or worse, cover-up, sanctions obtain central
importance. When procedures result in sanctions, these are highly visible either
because, as a rare event, deviance is sensationalized in mass media, or, as with
retractions, publically communicated in the scientific literature. The high visibility
of these sanctions serves, on the one hand, to legitimize the actors who enforce
sanctions and, on the other hand, to suggest to the public that deviance is a serious
(and increasing) problem. Both prompt more investigations and more sanctions to
give this visibility cycle an upward trend. The rising number of retractions and the
rising number of journals issuing retractions (Fanelli 2013) is an example of such a
process.
The punitivity found in the scientific community then seems to be less of a
result of individual attitudes or moral inclinations; rather it emerges as a result of the
problems related to making visible actions that are rare and incidental. Sanctions are
the sole events that bind together the actions of social control institutions with the
resulting symbols, thus creating a sense of transparency and accountability in the
wider community. They are the only visible proof that authorities of social control

26

are taking action when that action cannot be embedded in structures, positions and
routines that could function as permanent symbols of penal authority.

27

REFERENCES

Atmanspacher, Harald, and Sabine Maasen. 2016. Reproducibility: Principles,
Problems, Practices, and Prospects. 1. Hoboken, New Jersey: Wiley.
Bentham, Jeremy. 1781. An Introduction to the Principles of Morals and Legislation.
Mineola, N.Y: Dover Philosophical Classics.
Biagioli, Mario. 2002. “From Book Censorship to Academic Peer Review.”
Emergences: Journal for the Study of Media & Composite Cultures 12 (1): 11–45.
Blümel, Clemens, Stephan Gauch, Barbara Hendriks, Anne K. Krüger, and Martin
Reinhart. 2015. ‘In Search of Translational Research: Report on the Development
and Current Understanding of a New Terminology in Medical Research and
Practice’. IFQ-BIH-Report. Berlin: Institute for Research Information and Quality
Assurance; Humboldt-University Berlin. Brighenti, Andrea. 2007. “Visibility: A
Category for the Social Sciences.” Current Sociology 55 (3): 323–342.
doi:10.1177/0011392107076079.
Brighenti, Andrea. 2010. Visibility in Social Theory and Social Research. Basingstoke;
New York: Palgrave Macmillan.
Cavadino, Michael, James Dignan, and George Mair. 2013. The Penal System: An
Introduction. Fifth Edition. Sage.
Daston, Lorraine, and Peter Galison. 2007. Objectivity. Cambridge, MA: MIT University
Press.
Derrida, Jacques. 2005. Préjugés: Vor dem Gesetz. Translated by Peter Engelmann,
Detlef Otto, and Axel Witte. 3rd ed. Wien: Passagen.
Fanelli, Daniele. 2013. “Why Growing Retractions Are (Mostly) a Good Sign.” PLoS
Medicine 10 (12): e1001563. doi:10.1371/journal.pmed.1001563.
Faria, Rita. Research Misconduct as White-Collar Crime - A Criminological Approach.
New York: Palgrave Macmillan, 2018.
Fish, Stanley. 1994. There’s No Such Thing As Free Speech: And It’s a Good Thing,
Too. Oxford: Oxford Paperbacks.
Florini, Ann M. 2000. “Does the Invisible Hand Need a Transparent Glove?” Annual
World Bank Conference on Development Economics, 1999: April 28-30,
Washington DC: Proceedings, January, 163–184.
Foucault, Michel. 1977. Discipline and Punish: The Birth of the Prison. New York:
Random House.
Foucault, Michel. 1978. The History of Sexuality, Volume I: An Introduction. Translated
by Robert Hurley. New York: Pantheon Books.
Grattet, Ryken. 2011. “Societal Reactions to Deviance.” Annual Review of Sociology 37:
185–204.
Guston, David H. 2000. Between Politics and Science: Assuring the Integrity and
Productivity of Research. Cambridge University Press.
Harwood, Nigel. 2005. “‘We Do Not Seem to Have a Theory … The Theory I Present
Here Attempts to Fill This Gap’: Inclusive and Exclusive Pronouns in Academic
Writing.” Applied Linguistics 26 (3): 343–375. doi:10.1093/applin/ami012.
Hesselmann, Felicitas. 2018. “Punishing Crimes of the Mind: Sanctions for Scientific
Misconduct as a Case for the Cultural Theory of Punishment.” Theoretical
Criminology, February, 1362480618756365. doi:10.1177/1362480618756365.
Hesselmann, Felicitas, Verena Graf, Marion Schmidt, and Martin Reinhart. 2017. “The
Visibility of Scientific Misconduct: A Review of the Literature on Retracted
Journal Articles.” Current Sociology 65 (6): 814–845.
doi:10.1177/0011392116663807.

28

Hesselmann, Felicitas, Verena Wienefoet, and Martin Reinhart. 2014. “Measuring
Scientific Misconduct—Lessons from Criminology.” Publications 2 (3): 61–70.
doi:10.3390/publications2030061.
Horbach, Serge P. J. M., Eric Breit, and Svenn-Erik Mamelund. “Organisational
Responses to Alleged Scientific Misconduct: Sensemaking, Sensegiving, and
Sensehiding.” Science and Public Policy, 2018.
https://doi.org/10.1093/scipol/scy068.
Hyland, Ken. 2002. “Authority and Invisibility: Authorial Identity in Academic
Writing.” Journal of Pragmatics 34 (8): 1091–1112. doi:10.1016/S03782166(02)00035-8.
Inciardi, James A. 1972. “Visibility, Societal Reaction, and Criminal Behavior.”
Criminology 10 (2): 217–233. doi:10.1111/j.1745-9125.1972.tb00556.x.
Karp, David R. 1998. “The Judicial and Judicious Use of Shame Penalties.” Crime &
Delinquency 44 (2): 277–294. doi:10.1177/0011128798044002006.
Keller, Reiner, and Inga Truschkat. 2014. “Angelus Novus: Über Alte Und Neue
Wirklichkeiten Der Deutschen Universitäten. Sequenzanalyse Und
Deutungsmusterrekonstruktion in Der Wissenssoziologischen Diskursanalyse.” In
Diskursforschung Ein Interdisziplinäres Handbuch. Berlin, Boston: De Gruyter.
Kitsuse, John I., and Malcolm Spector. 1975. “Social Problems and Deviance: Some
Parallel Issues.” Social Problems 22 (5): 584–594. doi:10.2307/799692.
Lemert, Edwin. 1967. Human Deviance, Social Problems, and Social Control.
Englewood Cliffs: Prentice-Hall.
Maasen, Sabine, and Barbara Sutter. 2016. “Dezentraler Panoptismus.” Geschichte Und
Gesellschaft 42 (1): 175–194.
Maiwald, Kai-Olaf. 2005. “Competence and Praxis: Sequential Analysis in German
Sociology.” Forum Qualitative Sozialforschung / Forum: Qualitative Social
Research 6 (3). http://www.qualitative-research.net/index.php/fqs/article/view/21.
Mayring, Philipp. 2010. Qualitative Inhaltsanalyse: Grundlagen Und Techniken.
McGowen, Randall. 1994. “Civilizing Punishment: The End of the Public Execution in
England.” Journal of British Studies 33 (3): 257–282.
Mehrpouya, Afshin, and Marie-Laure Djelic. 2014. “Transparency: From Enlightenment
to Neoliberalism or When a Norm of Liberation Becomes a Tool of Governing.”
HEC Paris Research Paper, no. ACC-2014-1059.
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2499402.
Merton, Robert K. 1957. “Priorities in Scientific Discovery: A Chapter in the Sociology
of Science.” American Sociological Review 22 (6): 635–659.
Merton, Robert K. 1973. “The Normative Structure of Science.” In The Sociology of
Science: Theoretical and Empirical Investigations, edited by Norman W. Storer,
267–279. University of Chicago Press.
Neufeld, Jörg, and David Johann. “German Scientists Survey 2016,
http://www.forschungsinfo.de/Publikationen/Download/DZHW_WB_2016_Metho
den-v1_2.pdf.
Pratt, John. 1998. “Towards the ‘Decivilizing’ of Punishment?” Social & Legal Studies
7 (4): 487–515. doi:10.1177/096466399800700402.
Pratt, John. 2000. “Emotive and Ostentatious Punishment Its Decline and Resurgence in
Modern Society.” Punishment & Society 2 (4): 417–439.
doi:10.1177/14624740022228088.
Reinhart, Martin. 2012. Soziologie Und Epistemologie Des Peer Review. 1. Auflage.
Wissenschafts- Und Technikforschung, Band 10. Baden-Baden: Nomos.
Ringel, Leopold. 2018. “Unpacking the Transparency-Secrecy Nexus. Frontstage and
Backstage Behaviour in a Political Party.” Organization Studies. https://pub.unibielefeld.de/record/2919921.

29

Rundblad, Gabriella. 2007. “Impersonal, General, and Social: The Use of Metonymy
Versus Passive Voice in Medical Discourse.” Written Communication 24 (3): 250–
277. doi:10.1177/0741088307302946.
Schmidt, Marion. 2017. “An Analysis of the Validity of Retraction Annotation in
Pubmed and the Web of Science.” Journal of the Association for Information
Science and Technology, n/a-n/a. doi:10.1002/asi.23913.
Shapin, Steven, and Simon Schaffer. 1985. Leviathan and the Air-Pump: Hobbes, Boyle,
and the Experimental Life. Princeton University Press.
Smith, Adam. 1981. An Inquiry into the Nature and Causes of the Wealth of Nations.
Edited by R.H. Campbell, A.S. Skinner, and W.B. Todd. 2 vols. Indianapolis:
Liberty Press.
Smith, Adam. 2004. The Theory of Moral Sentiments. Edited by Knud Haakonssen.
Cambridge University Press.
Smith, Philip. 2008. Punishment and Culture. Chicago: University Of Chicago Press.
Sovacool, Benjamin K. 2008. “Exploring Scientific Misconduct: Isolated Individuals,
Impure Institutions, or an Inevitable Idiom of Modern Science?” Journal of
Bioethical Inquiry 5 (4): 271–282. doi:10.1007/s11673-008-9113-6.
Swales, John. 1990. Genre Analysis: English in Academic and Research Settings.
Cambridge University Press.
Tashakkori, Abbas, and Charles Teddlie. 2003. Handbook of Mixed Methods in Social &
Behavioral Research. London: Sage.
Upton, Thomas A., and Mary Ann Cohen. 2009. “An Approach to Corpus-Based
Discourse Analysis: The Move Analysis as Example.” Discourse Studies 11 (5):
585–605.
Veldkamp, Coosje L. S., Chris H. J. Hartgerink, Marcel A. L. M. van Assen, and Jelte
M. Wicherts. 2017. “Who Believes in the Storybook Image of the Scientist?”
Accountability in Research 24 (3): 127–151. doi:10.1080/08989621.2016.1268922.
Wager, Elizabeth. 2007. “What Do Journal Editors Do When They Suspect Research
Misconduct?” Medicine and Law 26, no. 3: 535–44.
Wilson, Kenneth, Alan Schreier, Angel Griffin, and David Resnik. 2007. “Research
Records and the Resolution of Misconduct Allegations at Research Universities.”
Accountability in Research 14, no. 1: 57–71.
https://doi.org/10.1080/08989620601126017.

30

TABLES

Table 1
RESULTS OF THE CONTENT ANALYSIS OF THE SEMI-STRUCTURED INTERVIEWS
RESPONCODES
Cases
none
1-5
6-10
More than 10
No routinization
learning-by-doing
Individual cases
Routinization
Professional Standards

Formal Training

Own Routines,
Experience
Negative Evaluation
Lack of effectiveness

Passivity

Contradictions and
problems in procedures

Dis-Identification

EXAMPLES

“I mean, in a way, it was on the job and on a percase basis type of training.” (Journal 6)
“So the problem with this is that no two cases are
alike.” (ERC)
“And in all of these, the thing that we do in an
overarching way is that we try to be very
professional with our members.” (COPE)
“There is a specific course which is meant for
people in publishing that talks about misconduct.
And I did that course.” (Publisher 1)
“As we have 60-70 cases per year, there is a
certain store of knowledge … that you can then
pass on.” (German Research Ombudsman)
“It is difficult. I mean, such a committee hardly
has any investigative powers.” (Investigative
Committee Research Institute)
“We are not the police. It is not that if you find
something like that, you will pro-actively get
involved. That is also not how I would see (…)
my role as an Ombudsperson” (Ombudsperson
Reseach Institute)
“[I: And in your experience, how is the response
of universities if you do reach a person?] Again, I
would be somewhat critical in that I've rarely had
a good outcome there.” (Publisher 3)
“And it's tough. All editors hate to deal with it,
just hate to deal with it. They'd rather just not look
at it and not see it.” (Journal 5)

CODINGS

DENTS

93
38

4
8
5
7
28
25

55

22

48
6

18
4

10

7

32

16

171
19

29
12

55

22

43

20

54

21

31

Positive Evaluation
Trust in own processes

Identification

Difficult Collaborations
No/failed collaboration

No exchange of
information
Lack of transparency

Successful Collaborations
Clear outside
communication

Successful collaboration

Exchange of information

Well-defined, transparent
responsibilities

Vague procedures and policies
No Policies

“[I: If I understood you correctly, [cases] seem
quite clear-cut, so you can resolve them quickly?]
I’d like to think so, yes.” (Ombudsperson
University 2)
“I think we do have a role. I think we have a role
in creating awareness with our editors in chief. I
think what we – we should definitely make certain
things possible.” (Publisher 1)
“Our Committee cannot somehow suggest to the
journal to proceed in any which way regarding
authorship. We are not competent in that way.”
(Investigative Committee University 1)
“Because everything was handed over to the
university, the university kept a very low profile.”
(Investigative Committee Research Institute)
“But at the same time, I would say that's one of
the big areas where I see room for improvement
because, if you go to a university Website, you
can hardly ever find the – yeah, the responsible
person for raising these cases.” (Publisher 3)
“In the journal I work on specifically, […] we try
to have very clear outside-facing and publicfacing guidelines as to what the expectations are,
the policies are, and all that.” (Journal 6)
“Our chairman is working very closely with the
Ombudsperson here, and we were able to resolve
many cases at an early stage.” (Investigative
Committee University 1)
“So our Ombudspersons, especially one of them,
is regularly taking part in those events of the
German Research Ombudsman, where they
exchange insights and also include international
experiences.” (Investigative Committee
University 5)
“We would then bring [the case] to the publisher.
However, I would do it through my – basically,
like management process. So I mean, that's how I
raise it.” (Journal 6)
“[I: Do you have any policies or guidelines that
[…] you could fall back on if you have any
doubts?] No.” (Journal 10)

80
41

24
21

39

13

143
48

30
22

41

20

54

23

239
28

31
16

82

27

101

26

28

15

245
2

31
1

32

Unknown Policies

Ambiguous Rules and
Definitions

Case-by-case approaches
Abstract Policies

Unresolved Cases

Informal Networks

Clear Procedures and Policies
Familiar with Policies

Well-defined Procedures

Utilizing Policies and
other Resources

“[I: Do you issue any recommendations for
possible punishments?] It is possible. But I am not
even sure we do that in every case, I have to
admit. I don’t recall exactly.” (Investigative
Committee University 3)
“Is that a case of deliberate misconduct, or is that
an accidental misconduct? And that's an area
where I think the community has not really come
up with very good guidelines.” (Publisher 3)
“It really depends on – we look at it on a case-bycase basis.” (Publisher 1)
“The policies we already had […] although it
turned out that they again are so abstract that
when you try and translate them into daily
practice, or work instructions, that doesn’t work.“
(Investigative Committee Research Institute)
“And to me, the weakness is that, as an external
funding body, this feeling that after all these
months of work, sometimes, you do not know if
there has been any consequence.“ (ERC)
“And in some cases when we do suspect multiple
cases, then sometimes we just informally talk to
colleagues and hear from each other.” (Publisher
3)
“In the COPE guidelines, they mention, if
someone is senior, then you need to contact the
institute because these people should know
better.” (Publisher 1)
“And so for example, if somebody's making a lot
of trivial allegations across a whole load of
different journals, you know, you can see, to be
honest, that they're not ones that are going to hold
up. But even so, you tell the journals that they
shouldn't dismiss the matter at hand. You should
have a process for triaging them.” (COPE)
“Yeah, I mean, this – so first of all, we have our
own Website with a flowchart for, let's say, eight
or so most common incidences. So first of all, you
would go to the flowchart specifically for author
disputes or figure manipulation or text plagiarism.
So you're already directed in a certain way by just
following those flowcharts.” (Publisher 3)

18

10

46

20

64

28

37

20

32

17

46

18

141
40

25
20

45

17

56

18

33

Table 2
ACCEPTANCE OF SANCTIONS AGAINST ACADEMIC MISCONDUCT
APPROPRIATE
APPROPRIATE IN
ENTIRELY

N

IN ANY CASE

CERTAIN CASES

INAPPROPRIATE

Retraction

81.8%

16.2%

2.0%

2238

Revocation of Funding Decisions

40.3%

51.6%

8.1%

2167

Debarment from Funding
Public Services Law
Consequences
Informal Reactions

37.8%

54.2%

8.1%

2129

35.6%

62.0%

2.5%

2193

32.8%

44.0%

23.1%

2105

Discussions on Social Media

22.2%

32.9%

44.9%

2059

Termination of Employment

20.4%

72.2%

7.4%

2182

No Sanctions

0.5%

9.1%

90.4%

2089

Table 3
ACCEPTANCE OF INSTITUTIONS HANDLING ACADEMIC MISCONDUCT
COMBINED
YES

DETECTION
YES

INVESTIGATION
YES

SANCTION
YES

NEITHER

N

Investigative Committee

147.6%

25.5%

85.3%

36.7%

5.6%

1381

Department Leaders
Superiors and
Colleagues
Ombudsperson
Law Enforcement
Authorities
German Research
Ombudsman
Reviewer

137.9%

25.4%

47.1%

65.4%

13.2%

1333

114.6%

69.4%

32.0%

13.2%

18.8%

1367

112.2%

23.1%

69.1%

20.0%

16.7%

1367

107.7%

10.4%

32.9%

64.4%

27.1%

1305

102.4%

20.7%

60.2%

21.5%

24.7%

1355

101.8%

77.5%

19.8%

4.5%

14.5%

1367

Editor

92.7%

54.0%

21.6%

17.1%

29.8%

1354

Internet-based Initiatives

88.1%

66.1%

20.0%

2.0%

29.3%

1347

General Media

63.9%

49.0%

11.0%

3.8%

45.7%

1341

NOR

34

FIGURES

Detection

Investigation

Decision

Implementation

External Actors

Commissions

Original Authors

Journals

No agents

Fig. 1: Relationships between actors and processual steps in retraction notices; boxes indicate
strong associations

35

