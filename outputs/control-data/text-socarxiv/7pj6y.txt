Collisions between Institutional and Populist Risk Imaginaries:
the “dark side” of negative asymmetric thinking
Ryan Hagen1

Abstract
Expert knowledge informs the construction of public problems from gun violence
to disease epidemics to climate change, and institutional actors draw on this
knowledge to implement public policy to mitigate or repair the related harms. The
expanding role of experts and institutions in managing risks has come at a time of
declining public trust in institutions and a legitimacy crisis around expert
knowledge. What happens when these tendencies collide? Previous scholarship has
examined how disaster arises through failures of foresight, and how culturalcognitive biases can prevent actors from seeing disasters coming. Less is known
about the mobilization of resistance against risk management policies. This
theoretical essay examines a particular category of that resistance: conspiracist
discourse that frames risk as emanating primarily from perceived secret agendas of
institutions and experts that explicitly claim to be acting in the public interest.
This essay argues that conspiracy thinking can be best understood as rooted in a
“populist risk imaginary,” which is rooted in negative asymmetry, a culturalcognitive bias that foregrounds the possibility of worst-case outcomes. Conspiracy
discourse can be understood as the “dark side” of negative asymmetry, which is
otherwise used by service-oriented professionals to sharpen their foresight in
preempting future dangers.
KEYWORDS: risk; politics; culture and cognition; the future.

1

Department of Sociology, Columbia University, 606 W 122nd Street, New York, New York 10027; e-mail:
ryan.a.hagen@columbia.edu

“The thought keeps suggesting itself (the ‘insane’ thought par
excellence) that, perhaps, the bright reality of everyday life is but
an illusion, to be swallowed up at any moment by the howling
nightmares of the other, the night-side of reality.” – Berger and
Luckmann, The Social Construction of Reality.

INTRODUCTION
The term “resistance” in U.S. popular political discourse since the 2016 election has been
associated primarily with left-wing protest against President Donald Trump and his
agenda. Among the most striking early examples of this were the Women’s March that
followed Trump’s inauguration in January 2017, and the mass mobilizations at U.S.
airports later that month to protest the new administration’s harsh restrictions on refugees
and travelers from seven majority-Muslim countries. The work in this special issue has
mostly explored progressive resistance amid the broader reactionary political climate of
recent years.
In this essay I direct our attention to a different mode of resistance, in the form of
populist dissent against expert knowledge and institutions. Rather than contesting public
policy – for example whether or not abortion should be legal, whether the U.S. should be
involved in foreign wars, or the appropriate level of taxation – this mode of resistance
contests the fundamental legitimacy of the expert knowledge claims that underpin much
of common political discourse itself. What is specifically populist about this mode of
resistance is that its adherents portray experts as not simply wrong or out of touch, but
as morally corrupt, or even predatory, as defined against the virtuous common sense of

1

everyday people (Mudde 2004; Bonikowski and Gidron 2016; Brubaker 2017). Prominent
within this resistance is conspiracy thinking: the notion that an elite cabal is secretly
working to undermine the will and wellbeing of the people. This conspiracy thinking
primarily seeks to delegitimize institutions and experts, the political philosophers Russell
Muirhead and Nancy Rosenblum argue, denying them their “standing in the political
world to argue, explain, persuade, and decide” (Muirhead and Rosenblum 2019).
The belief in conspiracies as a driving force in history is broadly present in the U.S.
population. A national survey in 2012 found that 30 percent of Americans agreed explicitly
that “big events like wars, the current recession, and the outcomes of elections are
controlled by small groups of people who are working in secret against the rest of us,”
while another 38 percent neither agreed nor disagreed (Uscinski and Parent 2014). A 2013
survey found that 37 percent of Americans believed the Food and Drug Administration
was deliberately withholding natural cures for cancer under pressure from profit-seeking
pharmaceutical companies; 20 percent believed physicians and government officials
advocated vaccination even though they knew vaccines caused autism and other disorders;
12 percent believed the development of genetically modified crops was part of a secret
plot by the Rockefeller and Ford foundations to shrink the global population. These beliefs
shaped behavior. Reported belief in more than one conspiracy theory was associated with
resistance to routine medical interventions including flu vaccination, annual physical
examinations and dental visits (Oliver and Wood 2014). More generally, belief in

2

conspiracy theories has been shown to decrease civic engagement and depress other prosocial behavior (Jolley and Douglas 2014; van der Linden 2015; Jolley et al. 2019).
How can we make sense of this phenomenon sociologically? The phrase “conspiracy
theorist” is commonly deployed as a tool of dismissal and exclusion (Husting and Orr
2007), and much of the previous literature on this topic either focuses on psychological
factors or the political determinants and consequences of conspiracism (DiGrazia 2017).
Instead, in this theoretical essay I take conspiracy theorizing seriously as a form of cultural
cognition. For analytical leverage, and to move away from the pejorative term “conspiracy
theorizing,” I develop the notion of a “populist risk imaginary” that positions elites and
institutions – corrupt, predatory, and omnipotent – as the motive force behind risk and
disaster in the modern world. I use the term populism in line with recent work framing
populism as a style of mobilization and rhetoric rather than a specific ideology or political
program (Brubaker 2017). Populism is a style of rhetoric, discourse, and thought that
“mobilizes ordinarily marginalized social sectors into publicly visible and contentious
political action, while articulating an anti-elite, nationalistic rhetoric that valorizes
ordinary people” (Jansen 2011: 82). The populist risk imaginary is a mode of thought that
defines itself against what can be called the institutional risk imaginary, which conceives
of risk and disaster as public problems that can be detected, measured, and managed
through expert systems, instruments, and organized social control.
The populist risk imaginary arises from what Karen Cerulo has called “negative
asymmetric thinking,” described as an “emancipating structure” that allows actors to
3

deviate from preconceptions that would blind them to the possibility of negative outcomes
(Cerulo 2006). Negative-asymmetric thinkers foreground the worst-case scenarios that
without preemptive action might confront them in the future. Similarly, the populist risk
imaginary promises emancipation through foregrounding the worst possible outcomes of
and motives for institutional risk management.
Where the institutional risk imaginary perceives a rise in mass shootings and invites
debate over the appropriate scope of Second Amendment rights to gun ownership, the
populist risk imaginary frames mass shooting events themselves as hoaxes perpetrated by
shadowy figures in the service of authoritarian ends. Similarly, debate over the correct
policy responses to the threat of terrorism becomes in the populist risk imaginary a debate
over whether or not events like the 9/11 attacks were “false flag operations” carried out
or enabled by government elites specifically in order to justify intrusive security and
surveillance measures. Scientific knowledge claims about global climate change are
dismissed as not simply mistaken, but as maliciously fabricated by elite scientists
conspiring in pursuit of a liberal agenda (Gauchat 2015). In the realm of public health,
some strands of resistance against vaccination have in recent years taken on a similar
populist aspect – a belief that medical experts, scientists and regulators are conspiring
with the pharmaceutical industry to push vaccines they know to be unsafe and ineffective
in order to enrich themselves (Reich 2016).
That people believe duplicitous elites are conspiring to cause harm in the world is
not itself new. In the 1960s Richard Hofstadter demonstrated the persistence of what he
4

called the “paranoid style” in American political culture, tracing a connection from 17th
Century fears about global Freemasonry through to elaborate stories of communist
infiltration in the middle of the 20th Century (Hofstadter 1996). At least two recent
developments however are worth considering. The first is the consistent and successful
use of rhetoric appealing to the populist risk imaginary by a major party presidential
nominee, who continues to deploy it while in office. This comes against the background
of the second development: the expanding role of institutional risk management in public
life, which is to say the growth of the institutional risk imaginary.
In the years leading up to his campaign for the presidency, Donald Trump routinely
promoted or endorsed conspiracy theories: that President Barack Obama was secretly
born outside the United States; that climate change was a hoax perpetrated by the
Chinese government; that vaccination caused autism. A central theme in his campaign
was that hidden global forces were conspiring to undermine American interests: that the
Mexican government was intentionally sending criminals across the border into the U.S.
for example, that his opponent Hillary Clinton was working with — in his words — “a
global financial elite to plot the destruction of U.S. sovereignty,” (Hochschild 2016) or
that unspecified enemies would carry out voter fraud to deprive him of victory in the
election.
This departure from normally accepted political rhetoric was key to Trump’s
political appeal (Wagner-Pacifici and Tavory 2017). Embracing conspiracy theories that
were outside the bounds of respectable politics was part and parcel with the Trump
5

campaign’s resonance with disaffected voters as “a vacation from a politics of bureaucratic
rules, forms, and policies that promised melioration but were often experienced as
obstacles” (Wagner-Pacifici and Tavory 2017: 318). Indeed, on the eve of the 2016 election,
Arlie Hochschild wrote that many of the Louisiana conservatives she came to the know
in the process of researching her book Strangers in Their Own Land had been drawn to
Trump exactly because of this style of rhetoric. They supported him “because of his
penchant for conspiracies, not in spite of it” (Hochschild 2016).
The success of Trump’s populist attacks came amid a decades-long erosion of public
trust in institutions (Twenge et al. 2014) and a sense among voters that public issues are
unfolding in a space “beyond their reach” (Perrin and Vaisey 2008: 782). At the same
time, institutions and experts have assumed an ever-expanding role in detailing the risks
we face and intervening in everyday life to manage them. Public health experts monitor
disease outbreaks and warn that we are unprepared for the “next pandemic” (Lakoff 2017);
counterterrorism and security experts warn about the need for preparedness against the
“next terrorist attack” (Aradau and van Munster 2012; Molotch 2012; Stampnitzky 2013);
meteorologists issue increasingly long-term and detailed forecasts of severe weather (Fine
2007; Daipha 2015) while climatologists describe the dangers of a climate destabilized by
human carbon emissions (Dunlap and Brulle 2015). These are some facets of the
reorganization of public life around risk consciousness described by Ulrich Beck and
Anthony Giddens as the Risk Society (Giddens 1990; Giddens 1991; Beck 1992; Beck
2009). Under the Risk Society, institutions have oriented their risk management strategies
6

around anticipation and preemption, rather than insurance and recovery (Collier 2008;
Anderson 2010). Faced with risks that are uninsurable, governments and corporations
increasingly look to mitigate future dangers through anticipatory governance, in an “effort
to transform encounters with risk into routine, formalizable processes – literally to
organize uncertainty” (Power 2005: 147).
It should perhaps be no surprise that these two attitudes towards risk – the elite
belief that future disasters can in a meaningful way be controlled and the populist belief
that elites control disastrous events – sometimes collide head on. That is to say, in a
cultural milieu in which risk and disaster are perceived as increasing alongside the
broadening scope of institutional risk management, some people draw the conclusion that
these institutions are intentionally creating danger, rather than preventing or ameliorating
it.
For example, when in 2017 the Federal Emergency Management Agency announced
it would conduct an exercise simulating the government’s response to a small-scale nuclear
attack on the New York City area, the popular conspiracy site InfoWars, whose publisher
Alex Jones has been praised by Trump, posted an item speculating that the exercise could
be cover for a real nuclear attack on the country, perpetrated by the government as an
excuse to implement martial law2. The story extended a long-running and highly

2

InfoWars. “Operation Gotham Shield: U.S. Gov’t To ‘Simulate Nuke Blast Over Manhattan’ As Actual
War Nears.” https://www.infowars.com/operation-gotham-shield-u-s-govt-to-simulate-nuke-blast-overmanhattan-as-actual-war-nears/

7

elaborated set of narratives that have been broadly held among right-wing fringe groups
since the early 1980s. In these narratives, FEMA’s disaster preparedness activities are
reimagined as methodical preparations for an authoritarian takeover of the country from
within (Barkun 2006; Keller 2010).
The case of the Holy Fire, a wildfire that burned more than 20,000 acres in
Southern California in August and September of 2018, provides a more acute example. In
the period leading up to the fire, California had faced two consecutive years of recordsetting wildfire damage, provoking a sustained response from the state, and claims from
the scientific community that global warming was a contributing factor. Meanwhile,
stories circulating online claimed to unmask a conspiracy by the government to
deliberately set the wildfires as a pretext for enacting land use reforms under the
authoritarian influence of the United Nations. This theory built on a broader family of
narratives centered around the idea that the U.N.’s Agenda 21 sustainable development
program is in fact a sinister plot to undermine U.S. sovereignty through local and regional
land use planning measures. This idea has been adopted by conservative activists, who
have mobilized around it to derail local sustainable development projects across the
country (Norton 2014; Trapenberg Frick et al. 2015). The idea that the state was
intentionally setting wildfires was explicitly referenced on social media by the California
man who, authorities allege, set the Holy Fire himself. The alleged arsonist, shortly before
the fire started, contacted the chief of the local volunteer fire department, sending him a

8

text message reading “it’s all going to burn like you planned” (Cosgrove et al. 2018;
Dalrymple II 2018).
These two examples are indicative of a broader worldview in which institutions
that claim to be acting in the public interest to manage risk are instead understood as the
primary sources of risk in society. In the remainder of this essay I will argue that this
populist risk imaginary emerges as a form of negative-asymmetric thinking that sets itself
in opposition to the professional fields of institutional risk management. Just as
bureaucracy has both a “bright side” that brings benefits and a “dark side” that leads to
unintended harms (Vaughan 1999), negative asymmetric thinking has a dark side, in this
case unified around the idea that the greatest dangers we face come from the institutions
that claim to be keeping us safe. By understanding conspiracist belief as populist risk
cognition emerging from negative asymmetric thinking, we can better see the holders of
these beliefs as knowledgeable actors in the social construction of reality rather than as
political dupes who are simple victims of misinformation. Prior research has shown how
fringe ideas move towards mainstream acceptance through appeals to fear and anger (Bail
2012; Bail 2014). But we have more to learn about how that fear is structured, and why
these appeals resonate with some people more than others. The concept of the populist
risk imaginary suggests a way forward in that regard.

9

ASYMMETRIES IN FUTURE PROJECTION
While it is a sociological commonplace that action in the present is shaped by
circumstances “directly encountered, given and transmitted from the past” (Marx 2008:
15), recent scholarship has turned to investigate how these encounters, these gifts, these
transmissions might also arrive from the future, inscribed in the present by coordinated
predictions about the outcome of purposive action. How are people’s actions influenced
by their projections of the future (Mische 2014)? How are everyday interactions between
people shaped by the necessary work of coordinating expectations for what will happen in
the near-, intermediate-, and long-term (Tavory and Eliasoph 2013)? A particular area of
interest is how and why individuals and organizations fail to productively anticipate
significantly disruptive events. Time and again, following natural disasters, jetliner
crashes, or economic crises, how can it be said that the relevant actors “never saw it
coming” (Cerulo 2006)?
One hypothesis is that a cultural bias towards positive outcomes systematically
blinds actors to detailed projections of undesirable futures, precluding thinking that might
allow these outcomes to be avoided. Applied to social life broadly, Karen Cerulo’s concept
of “positive asymmetry” suggests that most actors operate under a cultural tendency to
project the best possible future results of present action, while clouding negative or worstcase outcomes. Within organizations, planners faced with the possibility of unmanageable
catastrophe may offer up “fantasy documents,” detailed plans that narrate a rational,
effective response to future calamity, but which are in fact “no more than vague hopes for
10

remote futures [having] virtually no known connection with human capacity or will”
(Clarke 1999: 16). Such plans may be strategically useful for defusing opposition to certain
near-term actions on the grounds of their uncertain potential produce negative outcomes
in the future. Over the long term however fantasy documents increase the likelihood of
calamity by foreclosing the possibility of frank and detailed thinking about expectations
of danger and the limits of knowledge and control. A recent application of the concept to
the financial crisis of 2008 showed how positive asymmetric thinking caused Federal
regulators to systematically underestimate the possibility that the crisis building in
financial markets might spill over into the broader economy with catastrophic
consequences (Fligstein et al. 2017).
Certain professional knowledge systems, Cerulo argues, free actors from the
limitations of positive asymmetry by forcing a foregrounding of negative outcomes and
worst-case scenarios. Medical practitioners and computer systems technicians, for
example, focus on the detailed identification of dysfunctions and failures that lead to
negative outcomes. These professionals produce prognoses of undesirable futures based on
the ideal-typical worst outcomes and “think backward” to the symptoms that indicate
these trajectories (Cerulo 2006:169). That is to say a doctor in a physical exam confronted
with a patient complaining of chest pains will not ask if the patient’s heart has been
beating smoothly, or inquire about other signs of good health, but will rather focus on
detecting specific signs of an impending heart attack. To this list of professional knowledge
systems we might add meteorologists, who work with detailed models of atmospheric
11

events for the purposes of predicting and warning against a set of ideal-typical dangers
(Fine 2007; Daipha 2015). We might also consider disaster risk managers who, working in
public health agencies, the Department of Homeland Security, or emergency management
agencies at the local, state, and federal level, are charged with imagining worst-case
scenarios in detail to prevent them or to mitigate their effects (Fosher 2009).
Cerulo posits four traits that, when present in combination in a professional field,
serve as emancipating structures allowing for the emergence of negative asymmetric
thinking. These are:
1) Service orientation: a dedication to improving the lot of others; in Weberian terms,
a basic professional grounding in substantive rationality (value rationality) rather
than formal rationality (amoral calculation).
2) A formal knowledge base: practitioners operate from a “set of explicit beliefs about
the way in which elements of the world work [forming] a script for action that is
highly articulated and self-consciously invoked … [which is] understood as a
product of continual discovery” (Cerulo 2006:189) as opposed to basing action on
“traditional” or “common sense” knowledge.
3) Porous boundaries: the field encourages the free flow of information, people, and
resources into and out of the community. This is often coupled with the first trait
– information is freely shared with the public as a service aimed at improving
health, safety, or quality of life.

12

4) Professional autonomy: a relative freedom to work and make decisions with little
restriction from external authority.

These traits combine in organizations or communities that feature a web-like
hierarchical structure that allows for low-friction multi-directional communication
between an organizational core and the periphery, as opposed to a more vertical “M-form”
hierarchy dominated by a central command peak that dominates the chain of command
and is subject to control by external authorities. In combination, these traits may “loosen
the hold of routine cultural practices, freeing groups and communities to pursue
unanticipated problems and creative solutions” (Cerulo 2006:194).
The bright side of negative asymmetry is the potential for actors to productively
envision negative outcomes so as to avoid them. Scholars of High Reliability Organizations
showed as much in their studies of systems like air traffic control and nuclear-powered
warships in which a preoccupation with failure, deference to local expertise, and constant
multi-directional communication are cultural practices seen to reduce the risk of failure in
complex, high-risk operations (Weick 1987; Roberts 1990; Bierly III 1995; Vogus et al.
2014).
The dark side, on a psychological level, is intractable pessimism, a crippling
tendency to focus on negative outcomes to the exclusion of the achievement of positive
goals. On a social level, it may generate apocalyptic cults, or violent extremists. For
instance, the anthropologist Mark Juergensmeyer, in his comparative study of religious
13

violence, argued that an animating feature of the logic of religious terror was the
construction of social reality as a “cosmic war” between believers and non-believers, a state
in which the forces of good are under siege by the forces of evil (Juergensmeyer 2003).
A middle ground between individual depressives and apocalyptic cults may be the
everyday conspiracists who embrace the populist risk imaginary. An Alex Jones
progenitor, Mae Brussell, who rose to prominence in the 1970s as a radio host who spun
elaborate theories to account for the assassination of President John F. Kennedy,
inadvertently made the case for negative asymmetric thinking in explaining her career to
a journalist: “[After the JFK assassination] I wanted to find out if there had been a coup,
if the United States was going fascist. Would I be like Anne Frank’s father, who told his
family that things were OK and that people were basically good—while they were living
their last days? With a family of five children, my husband and myself, I had an obligation
to understand the world outside my home” (Brussell 2014). The populist risk imaginary
promises to emancipate its adherents from the naively optimistic belief that disasters are
accidents of history, when they are—according to this construction of reality—always the
deliberate consequences of elite power.

NEGATIVE-ASYMMETRIC TRAITS OF THE POPULIST RISK IMAGINARY
Service Orientation
Mae Brussell’s insistence that she set out to uncover “the truth” about the Kennedy
assassination out of an obligation to protect her family hints at the presence of a service
14

orientation in the populist risk imaginary. This is consistent with the claims populists
more generally make that they are protecting “the people,” however that group is defined,
from outside threats (Brubaker 2017). Here, the act of protection consists mainly in raising
awareness – warning others of the covert plots around them. Hofstadter described the selfconception of the ideal-typical conspiracy theorist as “a member of the avant-garde who
is capable of perceiving the conspiracy before it is fully obvious to an as yet unaroused
public … a militant leader” (Hofstadter 1996: 30-31). More recently the political scientists
Joseph Uscinski and Joseph Parent argued that conspiracy discourse, deployed by
members of groups who feel themselves disadvantaged or under threat, “has a strategic
logic. Sharing conspiracy theories provides a way for groups falling in the pecking order
to revamp and recoup from losses, close ranks, staunch losses, overcome collective action
problems, and sensitize minds to vulnerabilities” (Uscinski and Parent 2014: 132).
This notion of liberation through the sharing of secret knowledge is captured in the
term “red pilling,” used commonly in online communities on boards like 4chan and Reddit
as a metaphor for consciousness raising among the uninitiated (Marwick and Lewis 2017).
The term originates from the 1999 science fiction film The Matrix, in which the
protagonist, Neo, discovers that the reality he has been experiencing is in fact a computer
simulation meant to pacify an enslaved human race. Neo’s discovery begins with a gift
from a stranger. He is given the choice of swallowing either a red pill, which will reveal
the hidden forces that imprison him, or a blue one, which will allow him to continue living

15

in his uneventful, deceived reality. What the term “red pilling” connotes here is a sense of
duty to pass on the gift of knowledge – to recruit others into their skeptical worldview.
In its service orientation, the populist risk imaginary is doubly empowering. First,
as a way of providing individuals who feel powerless in the face of the sprawling,
impersonal institutions and power structures of modernity a coherent narrative: they are
protagonists who have unmasked a plot against themselves and their community.
Secondly, it empowers them as agents of liberation, awakening others to their newly
discovered reality. This proselytizing logic ensures that narratives rooted in the populist
risk imaginary will be circulated.

Formal Knowledge Base
The revelatory nature of conspiracy narratives rooted in the populist risk imaginary points
to a second characteristic also common to sites of negative asymmetry: the prevalence of
formal knowledge. Formal knowledge within the populist risk imaginary comes as a
framework of evidence, terms, and connections between events and actors that collectively
purport to undermine the “official story” of some historical event or traditional
understanding of power and threat in society. It is self-consciously evoked as nontraditional, as overturning common-sense explanations of how the world works. Terms
like “The New World Order,” “The Illuminati,” and “false flag” carry special significance
within these communities, used as components in the weaving together of conspiracy
narratives (Barkun 2006).
16

As Hofstadter argued, an identifying trait of conspiracy theory is “the quality of
pedantry … the elaborate concern with demonstration it almost invariably shows”
(Hofstadter 1996: 36). Formal knowledge supporting the populist risk imaginary is highly
flexible, insofar as it is able to incorporate new information in pursuit of elaborating and
protecting its core assumptions. Indeed failed predictions and contradicting evidence are
often incorporated into the narratives themselves as proof of a cover-up. This accounts
for the often baroque nature of conspiracy narratives, as alternate explanations, facts, and
modifications accumulate in defense of the theoretical claims (Clarke 2002).
This obsession with the accumulation of evidence is especially apparent on online
discussion boards where conspiracy theory groups congregate. Following the bulk release
of emails hacked from Clinton campaign chairman John Podesta in 2016, users of the
online forums Reddit and 4chan began to collaboratively sift through the archive in search
of incriminating evidence. Seizing on what they interpreted as coded language within the
emails, which was later combined with a heterogeneous mixture of verifiable and
fantastical information available on the internet, they gradually assembled a theory
linking Podesta, Clinton, and the Democratic Party establishment to what they imagined
to be an occult child sex trafficking operation run out of the basement of a Washington,
D.C. pizza restaurant. Members of the boards understood themselves as progressively
uncovering a world-shattering scandal concealed by a corrupt elite. Referencing the
Watergate scandal of the Nixon era, they called their project “Pizzagate” (Aisch et al.
2016). The theory was taken seriously enough by members of the online community that
17

in December of 2016 one of them drove six hours from his home in North Carolina to the
restaurant to investigate the claims in person. He came armed with a rifle, and opened
fire in the restaurant before being arrested by police.

Porous Boundaries
The service orientation that animates the populist risk imaginary – the imperative to
protect others by circulating claims of covert institutional predation – is closely linked to
the porous boundaries of communities embracing this style of thought. Knowledge is
exported prolifically, through professional media channels like InfoWars and documentary
films like “Vaxxed: From Coverup to Catastrophe,” directed by the disgraced
gastroenterologist Andrew Wakefield, which argues that the Centers for Disease Control
corruptly hid evidence of a link between autism and the MMR vaccine. Official public
conferences are organized and held for networking and consciousness raising – among the
most high-profile of these was the first annual “Flat Earth Conference,” held in Raleigh,
North Carolina in 2017, a two-day event dedicated to exposing a purported conspiracy
among scientists to deceive people about the shape of the planet. While the conference
focused on the supposed sinister lie of heliocentrism, the boundaries between different
narratives within the populist risk imaginary are easily crossed, and different strands of
conspiracy narratives are commonly woven together. One speaker at the event described
his intellectual journey to belief in the Flat Earth story through the consumption of online
video:
18

We went from one thing to another to another—Sandy Hook, 9/11,
false flags … We got into the Bilderberg, Rothschilds, Illuminati. All
these general things that one ends up looking into when you go on
here, because you look at one video and then another suggestion pops
up along the same lines. … Each thing started to make that much
more sense I was already primed to receive the whole flat-Earth idea,
because we had already come to the conclusion that we were being
deceived about so many other things. So of course they would lie to
us about this. (Burdick 2018)

This suggests a broader disposition to attribute the causation of everyday events
to the hidden forces of corrupt elites. This has been a finding of psychological research
into conspiracy belief. As Viren Swami and colleagues reported, in a survey study of
British and Austrian public opinion: “the strongest predictor of whether or not an
individual will ultimately accept a conspiracy theory is the presence of earlier conspiracist
ideation” (Swami et al. 2011: 459).
The passage above also highlights the key role of social media platforms in
recruiting new adherents to the populist risk imaginary and in circulating information to
new audiences. These platforms, built around unrestricted interconnection and community
building, have long had a reputation for democratizing discourse, both of which resonate
with populism’s suspicion of mediated communication. They encourage the kind of
disciplinary boundary crossing characteristic of negative asymmetry. The researcher
Rebecca Lewis documented one such online community: influential producers of fringe
right-wing content on YouTube (Lewis 2018). The community is linked through “guest
appearances,” conversations, and multi-party debates between video commentators on one

19

another’s channels. The resulting network constitutes an alternative source of information,
putting news and political commentary alongside conspiracy theorizing, across “a range of
political positions from mainstream versions of libertarianism and conservativism to overt
white nationalism” (Lewis 2018: 10). The relative ideological diversity of this community,
paired with the recommendation algorithm of the platform, makes it easy for new viewers
to be exposed to increasingly radical content.
On social media, information with an element of novelty spreads most quickly and
widely, which means that unverified rumors, along with misinformation and
disinformation, are more broadly consumed than corrections or incremental updates to
existing stories (Vosoughi et al. 2018). The incentive to post novel information can be an
incentive to cognitive deviance generally, and negative asymmetry in particular: stories
that provoke anger or outrage, for example at elite corruption, are more likely to be
engaged with and spread.

Autonomy
The final trait of negative asymmetric thinking is generally associated with professional
fields: individual autonomy. Professionals in fields where negative asymmetry thrives have
high degrees of individual freedom of choice over how they carry out their work. On a
larger scale, organizational structures that provide smaller units and divisions greater
autonomy, rather than tight hierarchical integration, tend to facilitate negativeasymmetric thinking. Communities embracing the populist risk imaginary do show high
20

levels of autonomy, in part because no professional field, and so no recognized constraining
authority, is present. It would be difficult to argue that conspiracy theorizing is a
profession. Media figures, like Alex Jones, Glenn Beck, and Mae Brussel before them, who
formulate and propagate conspiracy narratives are perhaps best categorized as media
professionals who operate within a specific style. Politicians, like Donald Trump, who
draw on and appeal to the populist risk imaginary in their rhetoric, are likewise more
usefully considered as politicians rather than professional conspiracists.
But populism highly values individual autonomy, distrusting institutions and
mediating organizations of all kinds, and experimenting with horizontal and broadly
participatory forms of involvement and cooperation (Brubaker 2017: 366). Furthermore,
it could be that people with an affinity for the populist risk imaginary are characterized
by too much autonomy: the marginalized, people who experience alienation and anomie.
Cerulo notes that negative asymmetry emerges from a general structure composed
of traits in combination, rather than a set of characteristics bound up in professional
identity, leaving open the possibility that beyond professional fields “any group or
community structured in this way can leave positive asymmetry behind.” (Cerulo 2006:
193).

21

DISCUSSION AND CONCLUSION
The abuse of power by elite institutions, especially when that abuse is directed at
vulnerable populations they are supposed to serve and protect, is a worst-case scenario.
Positivity bias might blind actors to patterns of abuse and misconduct by institutions or
individuals in positions of power. Negative asymmetric thinking, emerging from the
combination of a service orientation, formal knowledge base, porous boundaries, and
autonomy, can set groups free of perceptual biases that blind them to the possibility of
certain negative outcomes. At its best, this style of cultural-cognitive deviance uncovers
abuse, and exposes wrongdoing. After all, conspiracies and cover-ups do happen. And
indeed the argument of this essay is not to cast all skepticism of scientific knowledge as
fringe and cognitively suspect. Contests over the legitimacy of scientific and medical risk
knowledge are routine features of a risk society (Wynne 1989; Cable et al. 2008). What I
mean to draw attention to is a mode of resistance against institutional risk management
projects that has a uniquely anti-elite character, seeking to mobilize “ordinary people”
against the far-reaching covert plots of corrupt elites to harm them.
Negative asymmetry has a dark side, introducing corrosive skepticism against wellmeaning institutions and exacerbating social distrust and the crisis in expertise. In a
political moment in which the President of the United States routine invokes conspiracy
theories to explain the actions of his own government, his political opponents, and the
news media, negative asymmetry becomes a source of divisiveness and social instability.
Like the “fantasy documents” that paint unrealistically rosy but strategically useful future
22

projections of organizational performance under disaster conditions, conspiracy narratives
conceived within the populist risk imaginary have strategic usefulness in mainstream
politics. Dark fantasies about the United Nations’ Agenda 21 were adopted and spread by
Tea Party activists and used as the basis for anti-sustainability legislation introduced in
nearly half of U.S. state legislatures (Trapenberg Frick et al. 2015). Republican politicians
courted conspiracy theories about the Affordable Care Act, the legitimacy of Barack
Obama’s birth certificate, and the attacks on U.S. facilities in Benghazi, Libya, as a means
to mobilize their supporters and muddy the public debate around President Obama’s
agenda (Warner and Neville-Shepard 2014; Miller et al. 2016).
Closer to the present, when calls for gun control regulation flooded the public
sphere following the mass shooting at Marjory Stoneman Douglas High School in Florida
in February 2018, narratives circulated online speculated that the shooting had been
staged as a pretext for authoritarian measures to strip gun owners of their firearms. For
a time, following the shooting, the most recommended video on YouTube was a clip
claiming that student survivors of the event were “crisis actors” paid to fake the event
(Herrman 2018). The video built on narratives previously circulated by Alex Jones that
the 2012 school shooting in Newtown, Connecticut, was also a media spectacle staged by
the government to build support for disarming its citizens (Williamson 2018).
This essay has tried to take conspiracy thinking seriously as a structured form of
cultural cognition, as a manifestation of a populist risk imaginary arrayed against
institutional risk management. Framing the phenomenon this way provides an analytical
23

lever into understanding the sources and meaning of a significant variety of political
opinion and mobilization in the early 21st Century.
There is a dearth of empirical research on people and groups that embrace
conspiracy theories. Much of what does exist is in the political science and psychology
literature. Future research within sociology might examine the perception and use of
conspiracy theories by political actors (Nefes 2013), or how actors push fringe narratives
into the mainstream in support of their agenda (Bail 2012). By examining how people
with conspiracist beliefs reconcile them with more conventional aspects of social reality,
we can gain valuable insights into the construction and maintenance of political beliefs
and intersubjective reality more generally (Hoffman 2016; Garrido 2017). There is more
to learn about how institutions understand populist resistance to their agendas and how
that affects public policy. Likewise, there is much to be gained by understanding how the
conspiracy theorizing intersects with race and class, and how belief in conspiracy theories
can be helpful or harmful to disadvantaged or oppressed communities (Simmons and
Parsons 2005). While this essay has focused on the U.S. political sphere, comparative
studies across national boundaries could illuminate the influences of specific political
cultures and histories on the efficacy, extent, and content of thinking within the populist
risk imaginary.
Future work would also be based on a more systematic dataset to examine the
rhetoric and nature of the populist risk imaginary. Online forums like 4chan, 8chan, and
Reddit, or social media platforms like Twitter and YouTube could provide rich sets of
24

textual and network data. Letters to the editor and comments on mainstream media
websites would also be potentially useful sources of data. In-depth interviews with
propagators and believers of conspiracy theories could qualitatively deepen our
understanding of the meaning-making at work among social actors.
However future work proceeds, it is important that we look more closely at a
phenomenon that so clearly influences political culture.

25

REFERENCES
Aisch, Gregor, Jon Huang, and Cecilia Kang. 2016. “Dissecting the #PizzaGate
Conspiracy Theories.” The New York Times.
Anderson, Ben. 2010. “Preemption, precaution, preparedness: Anticipatory action and
future geographies.” Progress in Human Geography. 34 (6):777-798.
Aradau, Claudia and Rens van Munster. 2012. “The Time/Space of Preparedness:
Anticipating the “Next Terrorist Attack”.” Space and Culture. 15 (2):98-109.
Bail, Christopher A. 2012. “The Fringe Effect: Civil Society Organizations and the
Evolution of Media Discourse about Islam since the September 11th Attacks.”
American Sociological Review. 77 (6):855-879.
———. 2014. Terrified: How Anti-Muslim Fringe Organizationas Became Mainstream.
Princeton and Oxford: Princeton University Press.
Barkun, Michael. 2006. A Culture of Conspiracy: Apocalyptic Visions in Contemporary
America: University of California Press.
Beck, Ulrich. 1992. Risk society: Towards a new modernity: Sage Publications Limited.
———. 2009. World at Risk. Malden, MA: Polity Press.
Bierly III, Paul E. 1995. “Culture and High Reliability Organizations: The Case of the
Nuclear Submarine.” Journal of Management. 21 (4):639-656.
Bonikowski, Bart and Noam Gidron. 2016. “The Populist Style in American Politics:
Presidential Campaign Discourse, 1952–1996.” Social Forces. 94 (4):1593-1621.
Brubaker, Rogers. 2017. “Why populism.” Theory and Society. 46 (5):357-385.
Brussell, Mae. 2014. The Essential Mae Brussell: Investigations of Fascism in America.
Edited by Alex Constantine: Feral House.
Burdick, Alan. 2018. “Looking for Life on a Flat Earth.” The New Yorker.
Cable, Sherry, Thomas E Shriver, and Tamara L Mix. 2008. “Risk Society and
Contested Illness: The Case of Nuclear Weapons Workers.” American Sociological
Review. 73 (3):380-401.
Cerulo, Karen. 2006. Never Saw it Coming: Cultural Challenges to Envisioning the
Worst. Chicago, IL: University of Chicago Press.
Clarke, Lee. 1999. Mission Improbable: Using fantasy documents to tame disaster.
Chicago: University of Chicago Press.
Clarke, Steve. 2002. “Conspiracy theories and conspiracy theorizing.” Philosophy of the
Social Sciences. 32 (2):131-150.
Collier, Stephen J. 2008. “Enacting catastrophe: preparedness, insurance, budgetary
rationalization.” Economy and Society. 37 (2):224-250.
Cosgrove, Jaclyn, Alejandra Reyes-Velarde, and Alene Tchekmedyian. 2018. “‘It’s all
going to burn:’ Man accused of setting Holy fire was a well-known troublemaker,
neighbors say.” Los Angeles Times.
Daipha, Phaedra. 2015. Masters of Uncertainty: Weather Forecasters and the Quest for
Ground Truth. Chicago, IL: Chicago University Press.

26

Dalrymple II, Jim. 2018. “The Man Arrested For Allegedly Starting A Massive Wildfire
Pushed Rightwing Conspiracy Theories.” Buzfeed.
DiGrazia, Joseph. 2017. “The social determinants of conspiratorial ideation.” Socius.
3:2378023116689791.
Dunlap, Riley E and Robert J Brulle, ed. 2015. Climate Change and Society. New York:
Oxford University Press.
Fine, Gary Alan. 2007. Authors of the Storm: Meteorologists and the Culture of
Prediction. Chicago: University of Chicago Press.
Fligstein, Neil, Jonah Stuart Brundage, and Michael Schultz. 2017. “Seeing Like the
Fed: Culture, Cognition, and Framing in the Failure to Anticipate the Financial
Crisis of 2008.” American Sociological Review. 82 (5):879-909.
Fosher, Kerry. 2009. Under Construction: Making Homeland Security at the Local Level.
Chicago: University of Chicago Press.
Garrido, Marco. 2017. “Why the poor support populism: the politics of sincerity in
Metro Manila.” American Journal of Sociology. 123 (3):647-685.
Gauchat, G. 2015. “The Political Context of Science in the United States: Public
Acceptance of Evidence-Based Policy and Science Funding.” Social Forces.
Gibson, David R. 2011. “Avoiding Catastrophe: The Interactional Production of
Possibility during the Cuban Missile Crisis.” American Journal of Sociology. 117
(2):361-419.
Giddens, Anthony. 1990. The Consequences of Modernity. Stanford, CA: Stanford
University Press.
———. 1991. Modernity and self-identity: Self and society in the late modern age.
Cambridge: Polity Press.
Herrman, John. 2018. “The Making of a No. 1 YouTube Conspiracy Video After the
Parkland Tragedy.” The New York Times.
Hochschild, Arlie Russell. 2016. “Donald Trump loves conspiracy theories. So do his
supporters.” The Washington Post. PostEverything.
Hoffman, Steve G. 2016. “The Practical Use of Other Realities: Taking Berger and
Luckmann into the Wild.” Cultural Sociology. 10 (1):109-124.
Hofstadter, Richard. 1996. “The Paranoid Style in American Politics.” Pp. 1-40 in The
Paranoid Style in American Politics and Other EssaysCambridge, MA: Harvard
University Press.
Husting, Ginna and Martin Orr. 2007. “Dangerous Machinery: “Conspiracy Theorist” as
a Transpersonal Strategy of Exclusion.” Symbolic Interaction. 30 (2):127-150.
Jansen, Robert S. 2011. “Populist mobilization: A new theoretical approach to
populism.” Sociological theory. 29 (2):75-96.
Jolley, Daniel, Karen M. Douglas, Ana C Leite, and Tanya Schrader. 2019. “Belief in
conspiracy theories and intentions to engage in everyday crime.” British Journal of
Psychology.

27

Jolley, Daniel and K. M. Douglas. 2014. “The social consequences of conspiracism:
Exposure to conspiracy theories decreases intentions to engage in politics and to
reduce one’s carbon footprint.” British Journal of Psychology. 105 (1):35-56.
Juergensmeyer, Mark. 2003. Terror in the Mind of God: The Global Rise of Religious
Violence: University of California Press.
Keller, Larry. 2010. “Fear of FEMA.” Intelligence Report.
Lakoff, Andrew. 2017. Unprepared: Global Health in a Time of Emergency. Oakland:
University of California Press.
Marwick, Alice and Rebecca Lewis. 2017. “Media manipulation and disinformation
online.” Data & Society Research Institute.
Marx, Karl. 2008. The Eighteenth Brumaire of Louis Bonaparte. New York:
International Publishers Co., Inc.
Miller, Joanne M, Kyle L. Saunders, and Christina E Farhart. 2016. “Conspiracy
endorsement as motivated reasoning: The moderating roles of political knowledge
and trust.” American Journal of Political Science. 60 (4):824-844.
Mische, Ann. 2014. “Measuring futures in action: projective grammars in the Rio + 20
debates.” Theory and Society. 43 (3-4):437-464.
Molotch, Harvey. 2012. Against Security: How We Go Wrong at Airports, Subways, and
Other Sites of Ambiguous Danger. Princeton, NJ: Princeton University Press.
Mudde, Cas. 2004. “The Populist Zeitgeist.” Government and Opposition. 39 (4):541563.
Muirhead, Russell and Nancy L. Rosenblum. 2019. A Lot of People Are Saying: The
New Conspiracism and the Assault on Democracy: Princeton University Press.
Nefes, Türkay Salim. 2013. “Political Parties’ Perceptions and Uses of Anti-Semitic
Conspiracy Theories in Turkey.” The Sociological Review. 61 (2):247-264.
Norton, Richard K. 2014. “Agenda 21 and Its Discontents: Is Sustainable Development a
Global Imperative or Globalizing Conspiracy.” The Urban Lawyer. 46 (2):325-360.
Oliver, J. Eric and Thomas Wood. 2014. “Medical conspiracy theories and health
behaviors in the United States.” JAMA Intern Med. 174 (5):817-818.
Perrin, Andrew J. and Stephen Vaisey. 2008. “Parallel public spheres: Distance and
discourse in letters to the editor.” American Journal of Sociology. 114 (3):781-810.
Power, Michael. 2005. “Organizational responses to risk: the rise of the chief risk officer.”
Pp. 132-148 in Organizational Encounters with Risk, edited by Bridget Hutter and
Michael Power. New York: Cambridge University Press.
Lewis, Rebecca. 2018. “Alternative Influence: Broadcasting the Reactionary Right on
YouTube.” Data & Society Research Institute.
Reich, Jennifer A. 2016. Calling the shots: Why parents reject vaccines. New York: NYU
Press.
Roberts, Karlene H. 1990. “Some Characteristics of One Type of High Reliability
Organization.” Organization Science. 1 (2):160-176.

28

Simmons, William Paul and Sharon Parsons. 2005. “Beliefs in conspiracy theories among
African Americans: A comparison of elites and masses.” Social Science Quarterly.
86 (3):582-598.
Stampnitzky, Lisa. 2013. Disciplining Terror: How Experts Invented “Terrorism”. New
York: Cambridge University Press.
Swami, Viren, Rebecca Coles, Stefan Stieger, Jakob Pietschnig, Adrian Furnham, Sherry
Rehim, and Martin Voracek. 2011. “Conspiracist ideation in Britain and Austria:
evidence of a monological belief system and associations between individual
psychological differences and real-world and fictitious conspiracy theories.” British
Journal of Psychology. 102 (3):443-463.
Tavory, Iddo and Nina Eliasoph. 2013. “Coordinating Futures: Toward a Theory of
Anticipation.” American Journal of Sociology. 118 (4):908-942.
Trapenberg Frick, Karen, David Weinzimmer, and Paul Waddell. 2015. “The politics of
sustainable development opposition: State legislative efforts to stop the United
Nation’s Agenda 21 in the United States.” Urban Studies. 52 (2):209-232.
Twenge, Jean M., W. Keith Campbell, and Nathan T. Carter. 2014. “Declines in trust in
others and confidence in institutions among American adults and late adolescents,
1972-2012.” Psychol Sci. 25 (10):1914-1923.
Uscinski, Joseph E. and Joseph M. Parent. 2014. American Conspiracy Theories. New
York: Oxford University Press.
van der Linden, Sander. 2015. “The conspiracy-effect: Exposure to conspiracy theories
(about global warming) decreases pro-social behavior and science acceptance.”
Personality and Individual Differences. 87:171-173.
Vaughan, Diane. 1999. “The Dark Side of Organizations: Mistake, Misconduct, and
Disaster.” Annual Review of Sociology. 25:271-305.
Vogus, Timothy J., Naomi B. Rothman, Kathleen M. Sutcliffe, and Karl E. Weick.
2014. “The affective foundations of high-reliability organizing.” J. Organiz. Behav.
35 (4):592-596.
Vosoughi, Soroush, Deb Roy, and Sinan Aral. 2018. “The spread of true and false news
online.” Science. 359 (6380):1146-1151.
Wagner-Pacifici, Robin and Iddo Tavory. 2017. “Politics as a vacation.” American
Journal of Cultural Sociology. 5 (3):307-321.
Warner, Benjamin R. and Ryan Neville-Shepard. 2014. “Echoes of a Conspiracy:
Birthers, Truthers, and the Cultivation of Extremism.” Communication Quarterly.
62 (1):1-17.
Weick, Karl E. 1987. “Organizational Culture as a Source of High Reliability.” California
Management Review. 29 (2):112-127.
Williamson, Elizabeth. 2018. “Truth in a Post-Truth Era: Sandy Hook Families Sue
Alex Jones, Conspiracy Theorist.” The New York Times.

29

Wynne, Brian. 1989. “Sheepfarming after Chernobyl: A case study in communicating
scientific information.” Environment: Science and Policy for Sustainable
Development. 31 (2):10-39.

30

