Effect of changes in response options on reported pregnancy intentions: Findings from a
natural experiment in the United States
Isaac Maddow-Zimet and Kathryn Kost
Working paper, last revised 3/11/19

Abstract
Objectives: The Pregnancy Risk Assessment Monitoring System (PRAMS), conducted by the
Centers for Disease Control in collaboration with state health departments, is the largest statelevel surveillance system that includes a question on the intention status of pregnancies leading
to live birth. In 2012, the question was changed with the inclusion of an additional response
option describing uncertainty about pregnancy desire prior to the pregnancy. This analysis
investigates how this additional response option affected women’s responses.
Methods: We use the change in the pregnancy intention question in 2012 as a natural
experiment, taking advantage of relatively stable distributions of pregnancy intentions over
short periods of time within states. Using PRAMS data from 2009-2014 (N=222,781), we employ
a regression discontinuity design to test for differences in the proportion of women choosing
each response option in the periods pre- and post-question change.
Results: In the years 2012-2014, 13-15% of women chose the new answer option, “I wasn’t sure
what I wanted”. The addition had a substantial impact on distributions of pregnancy intentions,
drawing responses away from all answer choices except for “I wanted to become pregnant
then.” Effects were not uniform across age, parity and race combined with Hispanic ethnicity,
as well as across states.
Conclusions: These effects could impact estimated levels and trends of the proportion of births
that are characterized as intended, mistimed or unwanted, as well as estimates of differences
between demographic groups. These findings will help to inform new strategies for measuring
women’s pregnancy and childbearing desires.

Main Text
Virtually all population-based surveys of individual-level fertility experiences include
retrospective ‘intention’ questions on past pregnancies. These questions ask women to recall
how they had felt, prior to the pregnancy, about becoming pregnant or having a baby. The
research field has traditionally labeled these reports ‘pregnancy intentions’ even though
women are usually not asked about their intentions, but about their desires.
A growing body of research suggests that measures of pregnancy intentions should allow for a
wider and more realistic range of potential responses, particularly the ability to characterize
prior feelings as ambivalent or unformed.1–9 To address this, some surveys have added
additional response options to the pregnancy intention measure.10,11 This strategy was recently
adopted by the Pregnancy Risk Assessment Monitoring System (PRAMS) surveys conducted
annually by the Centers for Disease Control (CDC) in collaboration with individual state health
departments. In this paper we investigate how the change in response options has affected
reporting of pregnancy intentions in the state-specific populations covered by PRAMS, with a
particular focus on comparability over time. More broadly, we explore how the addition of a
response option that allows women to report having been uncertain prior to their pregnancy
may affect measurement of pregnancy intentions.

Background
Pregnancy intentions on the PRAMS questionnaire are obtained by asking respondents to think
back to the time just before their pregnancy and to recall how they felt about becoming

pregnant at that time.* The response options, shown below, were unchanged for more than a
decade (from 2000 to 2011).†
Thinking back to just before you got pregnant with your new baby, how did you feel
about becoming pregnant? (Check one answer)


I wanted to be pregnant sooner



I wanted to be pregnant later



I wanted to be pregnant then



I didn’t want to be pregnant then or any time in the future

Traditionally, researchers refer to pregnancies for which the women selected the first or third
response options – indicating she had wanted the pregnancy to occur sooner than it did or at
the time it occurred – as “intended.” “Mistimed” pregnancies are those for which she had
wanted the pregnancy to occur later, and “unwanted” are those for which she responded that
she didn’t want to become pregnant then or any time in the future. Because the mistimed and
unwanted categories imply that the pregnancy was not desired at the time it occurred or at all,
these two groups are often combined and termed “unintended” pregnancies.
Each state participating in PRAMS administers a set of “core” questions on their survey, uniform
across states, and has the option of including some additional “standard” questions, as well as
questions of their own design. The pregnancy intention question has always been included as
*

The National Survey of Family Growth asks a similar but slightly different question which asks women to recall
how they had felt about having a baby (or, another baby) just before they became pregnant.

part of the core set of questions. Beginning with the 2012 version of the survey (Phase 7),
PRAMS added a fifth response option to the core pregnancy intention question: “I wasn’t sure
what I wanted”.‡ It’s important to note that this option specifically refers to uncertainty in the
respondent’s feelings immediately prior to the pregnancy, not at the time of the survey. This
differs from other surveys (such as the National Survey of Family Growth), in which respondentvolunteered “not sure” or “don’t know” options may refer to uncertainty at the time the
question was asked.
The addition of this answer option responds to concerns that survey questions meant to
measure whether a woman had wanted to become pregnant are insufficient for capturing
important variation in how women think about their reproductive lives and experiences. In
particular, the original question did not include an answer option for women who had not
formed clear desires or intentions prior to the pregnancy, or who had had mixed feelings. The
addition of the fifth answer option in PRAMS expands the traditional measure of pregnancy
intentions to include these women. Prior surveys that included this option found that
significant proportions of women chose it.10,11
When women have five answer options, the proportion choosing each option will be smaller
than a question with only four answer options. However, what is unknown is how the
additional response category will affect the relative proportion of women choosing the
previously existing response categories. For example, women who would have responded that
they “wanted to become pregnant later” if they had been presented with only four answer

‡

The order of response categories was also changed slightly, with “I wanted to become pregnant later” moving
from the second to the first response category (i.e., followed by “I wanted to become pregnant sooner”).

choices may be more likely to choose the new option (“I wasn’t sure what I wanted”) than
women who would have responded that they “wanted to become pregnant then.”
Understanding the effects of the change in response options is critical because changes in the
proportion of women who select each response category could affect the comparability of
estimates of the proportion of births in the state that are identified as intended, mistimed or
unwanted across time. This is of special concern given the wide use of these surveys in both
tracking statistics over time,12–15 as well as investigating associations between pregnancy
intention and other maternal health behaviors and infant outcomes, which often involves
pooling data across years.16–19 Even if the relative proportions selecting each response category
did not shift in the overall population, there may have been differential shifts across population
groups; if women with specific demographic characteristics were more likely to select the “I
wasn’t sure” option (and thus were less likely to select one of the other options), this could
affect patterns of group differentials, as well as reported associations with other behaviors.
In this analysis, we use the 2012 change in the PRAMS pregnancy intention question as a
natural experiment, taking advantage of the fact that, within states, the distribution of
pregnancy intentions among women having births has been fairly stable over short periods of
time. After describing overall changes in the proportion of women reporting each response
category, we use a regression discontinuity design to formally test for differences between the
periods immediately pre- and post-question change. We then examine whether the change had
differential effects across demographic groups.

Methods
Data
The PRAMS questionnaire is mailed to women who have had a recent live birth (usually within 2
to 6 months after delivery), with each state’s sample drawn from vital records, and including
oversampling by specific characteristics to create annual, representative data at the state level
of all women delivering in that year.20 As of the end of 2018, forty-seven states, New York City,
Puerto Rico, the District of Columbia and the Great Plains Tribal Chairmen’s Health Board
(GPTCHB) participated in PRAMS, covering approximately 83% of all live births in the United
States.21
We limit the analytical sample to jurisdictions with data for at least one year in the period 20092014, and with response rates not less than 65% in a given year. In total, our sample is
comprised of 222,781 women from 36 states and New York City.§ Not all states contributed
data in each of the six years. For all analyses, we performed sensitivity tests using only states
with data for all 6 years; these analyses have a sample size of 168,462 women from 16 states.
All analyses were conducted using Stata 15.1, with weighted data and the svy prefix to adjust
for the complex sample design of the PRAMS surveys.

§

New York state (exclusive of New York City) and New York City field separate PRAMS surveys. Both are included in
these analyses.

Measures
We examine pregnancy intention in relation to a limited set of measures from the PRAMS
surveys: the year of interview (2009, 2010, 2011, 2012, 2013 or 2014), age at which the woman
gave birth, her number of prior live births (zero, one, two or more) and her reported race
crossed with Hispanic ethnicity (non-Hispanic white, non-Hispanic black, Hispanic, and nonHispanic other; the latter includes all non-Hispanic women who reported races other than
white or black, or reported multiple races). We focus on three commonly used demographic
measures – age, parity, and race/ethnicity – because pregnancy intentions are known to vary
widely by these characteristics. We reasoned that the extent to which the impact of the
question change varies by these three core demographic measures would be sufficient to
demonstrate the need for careful consideration of any future analyses using these data; while
other measures are also relevant to pregnancy intentions, a comprehensive investigation of
differential impacts by other demographic characteristics – and the reasons why they vary – is
beyond the scope of this analysis.

Analysis
We first investigate changes in pregnancy intentions over the three years preceding the
question wording change (2009-2011) and the three years following it (2012-2014). This
approach has two advantages over a simple comparison of the distributions of responses to the
pregnancy intention question in 2011 (pre-question change) to those in 2012 (post-question
change). First, and most important, is that changes between 2011 and 2012 could be partially

or entirely a reflection of longer-term shifts in the proportion of women in each response
category. While this is addressed formally in our regression discontinuity model, visual
inspection of trends over a longer period can give a sense of the degree to which effects of the
question wording change may be confounded with larger trends over time. Second, including a
broader set of years allows us to leverage data from more states, as only a smaller pool (25
states) have data available in both 2011 and 2012.
All descriptive statistics are produced by logistic regressions predicting the proportion of
women reporting each of the response categories in each year; results are presented as
predicted probabilities from these regressions. Because some differences could be driven by
which states fielded surveys in which year (as the proportion of women reporting each
response category varies substantially by state), we included state fixed effects in each
regression to control for the fact that data for each year in the sample is contributed by a
different set of states.
In survey design research, changes in question wording is often evaluated using randomized
experiments, in which respondents are randomly assigned by the researchers to receive
different versions of the questionnaire. The mean difference in responses between the groups
is typically defined as an estimate of the “average treatment effect”, or ATE, where the
“treatment” is exposure to a different version of the questionnaire. PRAMS, however, is an
observational dataset, not a randomized experiment; in place of randomization, starting in
2012, all respondents in all states were administered the version of the question with the
additional response option included.

Consequently, we use a quasi-experimental approach employing a regression discontinuity
model. Regression discontinuity designs take advantage of sharp cut-off points that determine
which respondents were assigned different versions of the treatment of interest. They
fundamentally rely on the assumption that respondents on either side of the cut-off are similar
in all ways save treatment assignment; in other words, that assignment of the treatment was
“as good as random,” and that differences between the groups can be solely attributed to the
treatment in question.22 In our case, respondents were “assigned” to a different treatment
based on the year in which they were surveyed. The model assumes that respondents on either
side of the cut-off year – those interviewed in 2009-2011 and those interviewed in 2012-2014 –
are similar in all ways except for the question version they received.
In order to make this assumption plausible, we need to account for trends over time in the
responses within the pre and post periods; we also need to control for any other factors likely
to be confounded with the question change. This latter condition motivates our use of state
fixed effects (although it is important to note that these control for the presence or absence of
a given state in the sample in any year, but not shifts in the demographic composition of
women giving birth within a state, which we feel is unlikely to have shifted drastically over the
short time period under study.)
The log odds of selecting each intention question response option were predicted using an
equation of the form:
𝑝
ln (
) = 𝛽0 + 𝛽1 𝑌𝐸𝐴𝑅 + 𝛽2 𝑃𝑂𝑆𝑇 + 𝛽3 𝑃𝑂𝑆𝑇 ∗ 𝑌𝐸𝐴𝑅 + 𝛽𝑗 𝛾𝑗
1 − 𝑝)

Where YEAR represents year of the survey, POST is an indicator variable marking whether the
respondent was asked the intention question pre- or post- response option change, and 𝛾𝑗 is a
vector of dummy variables indicating each state (to capture state fixed effects). We also include
an interaction term between POST and YEAR to allow the slopes within the two time periods
(pre- and post-) to differ.** Without the inclusion of this interaction term, the model would
constrain trends over time in the proportion of respondents choosing a given response option
to be identical in the pre (2009-2011) and post (2012-2014) periods.
A major assumption of regression discontinuity designs is that the functional form of the
assignment variable (in this case, year of the survey) is correctly specified. In other words, in
order to be able to compare 2009-2011 to 2012-2014, we need to have correctly modeled time
trends in both these periods, so that we are comparing the mean response net of those trends.
If we didn’t do this, any changes between the pre and post periods could just be a reflection of
longer term trends; for example, if the proportion of women responding that they “wanted to
become pregnant later” had been declining over time (and this decline was not accounted for
in our model) we could falsely ascribe these declines to the treatment (i.e., the question
change). We opted to use linear time trends based on visual inspection of the trends in our first
descriptive model (which were highly linear in both the pre- and post- period); we also tested
the addition of higher order terms, but none significantly improved model fit.
The model described above estimates an average treatment effect: the impact of the question
change averaged across all respondents. It is possible, however, that the addition of a response

**

The YEAR variable is centered at 2011 in order to make this interaction term more easily interpretable.

category affected different groups of women in different ways; in other words, that there is
heterogeneity of treatment effects across population groups. We tested for this by running
models with interaction terms between the treatment assignment variable and demographic
covariates. Specifically, we present findings testing interactions by age, race combined with
Hispanic ethnicity, parity and state of residence. Age and parity are highly correlated; therefore,
in order to identify differences in average treatment effects by parity net of differences by age,
we control for age in models testing interactions by parity. In models of the interactions with
state of residence, we include controls for both age and race combined with Hispanic ethnicity
to account for variation across states in demographic composition. In the models estimating
interactions by state we also limited our sample to states contributing data for all six years
(2009-2014).
Finally, given the large sample size of the pooled PRAMS surveys, we chose to use a more
conservative alpha level of .001 for evaluation of statistical significance in all analyses. For all
analyses, we also tested an alternate specification (not shown) in which we restricted our
sample to only states with data for all six years; results were substantively unchanged.

Findings
Predicted proportion of each response category, by year of survey
Table 1 shows the percent distribution of responses across the pregnancy intention question
for each year of the PRAMS surveys, from 2009 to 2014. The categories shown in Table 1

appear in the same order as they appeared on the 2012 questionnaire. We include “missing” as
a valid response to examine item non-response rates pre and post question change.
Women’s responses to the pregnancy intention question were stable over the period 20092011, with each response category changing by no more than one percentage point over the
three year period. Just less than one-third (31-32%) of women reported that they had wanted
the pregnancy to occur later; 17-18% said they had wanted it to occur sooner; 39%-40% said
they had wanted it to occur then; and, 9-10% said they did not want to be pregnant then or at
any time in the future. Around 2% of women skipped the question entirely; this proportion
remained stable over the full 2009-2014 year period.
After the introduction of the additional response category in 2012, 13-15% of women selected
this option in 2012-2014. This drew responses away from all other categories except “I wanted
to become pregnant then,” which remained stable. The proportion responding that they had
wanted the pregnancy to occur later dropped seven percentage points between 2011 and 2012
(from 31% to 24%), the proportion responding that they had wanted the pregnancy to occur
sooner dropped five percentage points (18% to 13%), and the proportion stating that they did
not want the pregnancy then or at any time in the future dropped four percentage points (10%
to 6%). As in the period 2009-2011, the proportion of respondents selecting each category
remained largely stable in the years 2012-2014, varying by no more than one or two percentage
points over the three year period.

Selection of “not sure” category by characteristics of women
There were substantial differences across demographic groups in which women were most
likely to select the response “I was not sure if I wanted to become pregnant”. Figures 1a-c show
differentials by age, by race and ethnicity, and by parity.
Women in the three youngest age groups (15-17, 18-19 and 20-24) were significantly more
likely than women aged 25-29 to select the “I was not sure” category to describe their intention
at the time of the pregnancy (Figure 1a). Women in the oldest age category were also
significantly more likely to respond “I was not sure”; no other age groups were significantly
different from 25-29 year olds at p<.001.
Non-Hispanic black and non-Hispanic women of races other than black or white were
significantly more likely to respond “I was not sure” than non-Hispanic white women (Figure
1b). There were no significant differences between non-Hispanic white women and Hispanic
women in the proportion reporting this “I was not sure” category.
Finally, women with two or more prior births were much more likely to select the “I was not
sure” response than women with zero or one live birth prior to the pregnancy (Figure 1c).
Overall effects of question change
Table 2 shows the results of our regression discontinuity models for each question response
category (these results are also expressed graphically in Figure 2). In Table 2, the coefficients
associated with the treatment variable correspond to the estimated average treatment effect
of the question change on the log odds of selecting each answer choice. For example, a

significant negative coefficient means that respondents given the post-change questionnaire
were less likely to choose that answer choice than those given the pre-change questionnaire.
The coefficients associated with year (and their interactions with treatment) represent the
linear trends in the log odds of each response over time.
After the question change in 2012, women were significantly less likely to respond that they
wanted to become pregnant “later” (b=-.30) or “sooner” (b=-.33). They also were significantly
less likely to respond that they “did not want to become pregnant then or at any time in the
future” (b=-.43). There was no significant change in women’s odds of selecting the option “I
wanted to become pregnant then.” Linear time trends were also not significant for any of the
response categories, suggesting there were no changes in the proportions of women choosing
each category within the pre- and post- periods, respectively.
Effects of question change by age, race and Hispanic ethnicity, and parity
Average treatment effects by age, race and Hispanic ethnicity, and parity are shown graphically
in Figure 3; full results from the models that produced them are shown in Appendix Tables 1-3.
Figure 3 shows the average treatment effect for each category of the demographic
characteristic (e.g. age groups), and can be interpreted as the predicted effect of the change in
the question on the odds of women in that demographic group choosing the specified response
category relative to the odds that women with that same characteristic would have chosen it in
the survey periods before the question change. Significance tests for interaction effects –
shown in Appendix Tables 1-3 and described below – describe differences in these average
treatment effects between demographic groups.

There were no significant interactions between treatment and age for any intention category
except “I wanted to become pregnant then.” Younger women (those <=17 and those aged 1819) had significantly larger treatment effects than women aged 25-29. These younger women
were less likely to select this option post-2012 than they were in the period before the question
change (with changes in log odds of -.69 and -.22, respectively; Appendix Table 1) while older
women had no change in their odds.
In contrast, there were no significant interactions between treatment and race combined with
Hispanic ethnicity for any intention response category except “I wanted to become pregnant
sooner” (Figure 2 and Appendix Table 2). Hispanic women had significantly smaller treatment
effects than non-Hispanic white women (reference group).†† For all non-Hispanic women (of
any race) the question change had a significantly negative effect on their odds of selecting this
category. For Hispanic women, the effect of the question change was statistically
indistinguishable from zero.
There were also significant interactions between treatment and parity, even after adjusting for
mother’s age (Figure 2 and Appendix Table 3). Higher parity women (two or more births prior to
the pregnancy) saw steeper declines in the odds of choosing “I wanted to become pregnant
later” after the question change (b=-.45) as compared to women with zero (b=-.27) or only one
(b= -.28) prior birth. There were no significant differences in estimated treatment effects on the
other intention response categories.

††

In fact, Hispanic women had significantly smaller treatment effects compared to non-Hispanic black and nonHispanic other women as well (not shown).

Effects of question change by state
Finally, using a sample limited to 16 states that contributed data in all six years (2009-2014), we
estimated models predicting each response category while allowing for interactions between
state of residence and a dichotomous indicator of treatment (absence or presence of the
additional “not sure” response category). These models adjusted for both age and race
combined with Hispanic ethnicity, and joint hypothesis tests were used to evaluate the stateindicator interaction terms as a block, to test if any of the state interaction terms were
significantly different from zero. Figure 4 shows estimated effects of the question change on
the proportion of women choosing each response category by state, along with associated 95%
confidence intervals. There was significant heterogeneity in the estimated effects of the
question change by state within each of the response categories except “I did not want to
become pregnant then or at any time in the future”.
Limitations
This paper attempts to infer causal effects from observational data. Some important and
unobserved factors may not be adequately accounted for in our analyses, although regression
discontinuity designs are generally robust to omission of unobservables as long as the
functional form is correctly specified.22
In particular, if there were specific events that occurred at the beginning of 2012 (coinciding
with the question change in PRAMS) that affected how all women in the country, or all women
in a particular state, might respond to questions characterizing their desires prior to pregnancy,
then our results could be confounded with that change. However, we know of no national or

state policy changes that went into effect at that time that would have had a substantial impact
on women’s responses.
Finally, while we focus only on the impact of the addition of a fifth response category, it is
unknown whether the slight re-ordering of the answer categories in 2012 had any impact on
the proportions selecting each option. The reordering affected only the first and second
response options and respondents were able to see all answer options simultaneously, so we
expect that the reordering likely had little impact. However, because both changes occurred
simultaneously – reordering of the answer categories, and the addition of the “I wasn’t sure”
category – we have no way of distinguishing the relative impact of each.

Discussion
Expanding the measure of pregnancy intentions in the PRAMS surveys to include a response
option for women who recall having been unsure of their desire for pregnancy prior to their
most recent pregnancy appears to offer a more salient answer category for a significant
proportion of women than the more limited options available in prior surveys. In the years 2012
to 2014, 13-15% of women whose pregnancy led to a live birth chose the new answer option, “I
wasn’t sure what I wanted”.
It was inevitable that the addition of another response option would impact the proportions of
respondents choosing the existing options. However, the addition did not affect the likelihood
of women selecting all other options equally. Instead, it drew responses away from all answer
choices except for “I wanted to become pregnant then.” The more limited construct of the

pregnancy intentions question may have been constraining women’s responses, by failing to
recognize uncertainty as a valid state of mind prior to pregnancy and thereby forcing
respondents to choose among answer choices that may not have accurately represented how
they recall their attitudes toward pregnancy.
The impact on the proportion of women who said “I wanted to become pregnant sooner”
suggests that this group may be heterogeneous in their pregnancy desires. Past research has
typically paid little attention to this group, or characterized them as women who were having
difficulty conceiving9 or had been trying to get pregnant and conceived later than they
preferred. Because of this, these pregnancies are often interpreted as an unambiguously
positive – and wanted – experience. But, the substantial shift away from this category when
the “not sure” option is included suggests this may not be true for all women in this group. For
example, it is possible some women who responded that they had wanted to become pregnant
sooner are actually reflecting on a better time in their life for that pregnancy to have occurred
rather than a strong desire for pregnancy. In addition, not all women have clear preferences or
plans for the timing of their pregnancies as demonstrated in prior qualitative work in this
area.23 Other research suggests that uncertainty and variation in pregnancy intentions across
the life course is common.24–26
The new answer category also drew more women from some population groups than from
others. For example, women in the youngest and oldest age groups (15-17, 18-19, 20-24 and
40-44) were more likely than women aged 25-29 and women aged 30-34 to select the “not
sure” answer option. Similarly, non-Hispanic black women and non-Hispanic women of other

races were more likely to select the “not sure” option than non-Hispanic white women and
Hispanic women.
Further, the effect of the new question option was not uniform across demographic groups. For
example, among the youngest women (<20 years of age), the “not sure” category drew
responses away from the category typically classified as intended pregnancies (“wanted the
pregnancy then”). And, for all non-Hispanic women—regardless of their race—the new
question option significantly reduced their odds of selecting the “I wanted to become pregnant
sooner” option, while it had no effect on Hispanic women’s odds of selecting that option. We
examined only three key demographic measures, but the evidence of significant variation in the
impact of the question change suggests that even more variation may exist among other
socioeconomic and demographic factors we didn’t examine. It’s also possible that the patterns
we found for age, race and Hispanic ethnicity, and parity are not stable across states, especially
given the wide variation in the effect of the question change across states. Consequently, it may
be especially difficult to predict the specific impact of the question change in ways that could
allow researchers to make prior estimates of pregnancy intentions comparable.
Differential impacts of the question change by age, race and Hispanic ethnicity, and parity also
suggest that the change may affect estimates of trends in differences between demographic
groups, if researchers are comparing estimates pre- and post-2012. Separately, research
examining the relationship between pregnancy intentions and other measures will be affected
by the question change. We only looked at three demographic characteristics in this analysis,
but there are likely differences in treatment effects of the question change across other
characteristics as well; consequently, estimates of the association between respondent

characteristics and pregnancy intention will be affected in potentially unpredictable ways.
Another implication of these findings is that researchers should not pool PRAMS surveys across
the year in which the question change occurred if the measure of pregnancy intentions is used
in analyses.
The question change is likely to have substantial impacts on state-level estimates of the percent
of births from pregnancies categorized as unintended (mistimed and unwanted). In particular,
estimates of unintended pregnancy from the 2012 surveys and later are likely to be lower than
those from prior years. In many cases, the proportion of births resulting from unintended
pregnancies will appear to have declined from 2011 to 2012, but the decrease may be entirely
attributable to the addition of the new answer option. This issue is complicated by the fact that
the impact of the question change varies substantially by state of residence. For example, if one
was to recalculate unintended pregnancy rates for the year 2011 substituting in the proportion
of births in each response category from 2012,‡‡ unintended pregnancy rates in 2011 would be
16% lower, on average; percent declines would range from 3% (in Maine) to close to 30% (in
Georgia). Thus, any ongoing surveillance of pregnancy intentions at the state-level should not
consider estimates to be comparable pre and post-2012.
Conclusions
The effects of the question change identified in this analysis underscores the need for further
work on how best to characterize women’s childbearing desires. Our results do not suggest

‡‡

Calculated among states with data in both 2011 and 2012; for details on the calculation of unintended
pregnancy rates for each state see Kost K, Unintended Pregnancy Rates at the State Level: Estimates for 2010 and
Trends Since 2002, New York: Guttmacher Institute, 2015.

that research using the “new” pregnancy intention question in PRAMS are less valid than prior
analyses; in fact, the substantial proportions of women selecting “I was not sure if I wanted to
become pregnant” implies latent demand for an option describing uncertainty around fertility
intentions prior to pregnancy. Changes in how we measure important demographic measures
can be significant contributions to advance science and measurement, and the addition of the
response option in PRAMS to capture uncertainty related to pregnancy desires has likely
improved the measure. In this analysis, we find that the question change leads to insights about
how response option selection may change when additional ones are offered, how this
movement may alter our interpretations of the existing response options, and caution that
researchers using these data should be aware of the impact of that change for further work
using this measure.

Acknowledgements
We would like to thank Sarah Cowan, Liza Fuentes, Megan Kavanaugh and Shivani Kochhar for
review and comments on drafts of this manuscript, as well as Sarah Hayford, in her role as
discussant of this paper at the annual conference of the Population Association of America. We
also gratefully acknowledge Anne Radigan, PRAMS coordinator at the New York State
Department of Health for special tabulations from the state’s Phase 2, 3 and 4 surveys, and the
PRAMS Working Group and the Centers for Disease Control for collection and provision of the
data used in our analyses.

References
1.

Aiken ARA, Dillaway C, Mevs-Korff N. A blessing I can’t afford: factors underlying the
paradox of happiness about unintended pregnancy. Soc Sci Med 1982. 2015;132:149-155.
doi:10.1016/j.socscimed.2015.03.038

2.

Stanford JB, Hobbs R, Jameson P, DeWitt MJ, Fischer RC. Defining dimensions of pregnancy
intendedness. Matern Child Health J. 2000;4(3):183-189.

3.

Higgins JA, Popkin RA, Santelli JS. Pregnancy Ambivalence and Contraceptive Use Among
Young Adults in the United States. Perspect Sex Reprod Health. 2012;44(4):236-243.
doi:10.1363/4423612

4.

Kavanaugh ML, Schwarz EB. Prospective Assessment of Pregnancy Intentions Using a
Single- Versus a Multi-Item Measure. Perspect Sex Reprod Health. 2009;41(4):238-243.
doi:10.1363/4123809

5.

Moos MK, Petersen R, Meadows K, Melvin CL, Spitz AM. Pregnant women’s perspectives
on intendedness of pregnancy. Womens Health Issues Off Publ Jacobs Inst Womens
Health. 1997;7(6):385-392.

6.

Schwartz A, Peacock N, McRae K, Seymour R, Gilliam M. Defining new categories of
pregnancy intention in African-American women. Womens Health Issues Off Publ Jacobs
Inst Womens Health. 2010;20(6):371-379. doi:10.1016/j.whi.2010.06.005

7.

Barrett G, Wellings K. What is a “planned” pregnancy? Empirical data from a British study.
Soc Sci Med 1982. 2002;55(4):545-557.

8.

Edin K, Kefalas MJ. Promises I Can Keep: Why Poor Women Put Motherhood Before
Marriage. 1 edition. Berkeley: University of California Press; 2005.

9.

Santelli J, Rochat R, Hatfield-Timajchy K, et al. The Measurement and Meaning of
Unintended Pregnancy. Perspect Sex Reprod Health. 2003;35(2):94-101.
doi:10.1363/3509403

10. California Maternal, Child, Adolescent Health Program. 2011 MIHA County Report: A
Summary Report of County Snapshots and Geographic Comparisons from the Maternal
and Infant Health Assessment Survey. Sacramento: California Department of Public Health,
Maternal, Child and Adolescent Health Program; 2013.
https://www.cdph.ca.gov/Programs/CFH/DMCAH/MIHA/CDPH%20Document%20Library/
MIHA-AnnualReport-2011-County.pdf. Accessed March 9, 2018.
11. Hollingsworth D. South Dakota Perinatal Health Risk Assessment Report 2009. 2010:77.

12. Kost K. Unintended Pregnancy Rates at the State Level: Estimates for 2010 and Trends
Since 2002. New York: Guttmacher Institute; 2015.
http://www.guttmacher.org/pubs/StateUP10.pdf.
13. Maternal and Child Health Assessment. Maternal and Child Health Data Report:
Unintended Pregnancy.; 2010:3.
https://www.doh.wa.gov/DataandStatisticalReports/MaternalandChildHealth/Maternalan
dChildHealthDataReports.
14. West Virginia Department of Health and Human Resources, Office of Maternal, Child and
Family Health. Pregnancy Risk Assessment Monitoring System (PRAMS) 2009-2011
Surveillance Report.; 2016.
http://www.wvdhhr.org/wvprams/pdf/2009_2011_prams_annual_report.pdf. Accessed
August 29, 2018.
15. Zheng Q, Williamson DE, Donald CM, Woolbright LA. PRAMS Surveillance Report Alabama
2011. 2013:91.
16. Cheng D, Schwarz EB, Douglas E, Horon I. Unintended pregnancy and associated maternal
preconception, prenatal and postpartum behaviors. Contraception. 2009;79(3):194-198.
doi:10.1016/j.contraception.2008.09.009
17. Lindberg L, Maddow-Zimet I, Kost K, Lincoln A. Pregnancy Intentions and Maternal and
Child Health: An Analysis of Longitudinal Data in Oklahoma. Matern Child Health J.
2015;19(5):1087-1096. doi:10.1007/s10995-014-1609-6
18. Mohllajee AP, Curtis KM, Morrow B, Marchbanks PA. Pregnancy intention and its
relationship to birth and maternal outcomes. Obstet Gynecol. 2007;109(3):678-686.
doi:10.1097/01.AOG.0000255666.78427.c5
19. Terplan M, Cheng D, Chisolm MS. The relationship between pregnancy intention and
alcohol use behavior: an analysis of PRAMS data. J Subst Abuse Treat. 2014;46(4):506-510.
doi:10.1016/j.jsat.2013.11.001
20. Centers for Disease Control. PRAMS model surveillance protocol, 2015 version. 2015.
https://www.cdc.gov/prams/methodology.htm.
21. Centers for Disease Control. Participating PRAMS States, Territory and Tribe.
https://www.cdc.gov/prams/states.htm. Published November 29, 2017. Accessed March
9, 2018.
22. Hausman C, Rapson DS. Regression Discontinuity in Time: Considerations for Empirical
Applications. National Bureau of Economic Research; 2017. doi:10.3386/w23602

23. Borrero S, Nikolajski C, Steinberg JR, et al. “It just happens”: A qualitative study exploring
low-income women’s perspectives on pregnancy intention and planning. Contraception.
2015;91(2):150-156. doi:10.1016/j.contraception.2014.09.014
24. Jones RK. Are Uncertain Fertility Intentions a Temporary or Long-term Outlook? Findings
from a Panel Study. Womens Health Issues Off Publ Jacobs Inst Womens Health.
2017;27(1):21-28. doi:10.1016/j.whi.2016.10.001
25. Zabin LS. Ambivalent feelings about parenthood may lead to inconsistent contraceptive
use--and pregnancy. Fam Plann Perspect. 1999;31(5):250-251.
26. Klerman LV. The intendedness of pregnancy: a concept in transition. Matern Child Health J.
2000;4(3):155-162.

Table 1. Percent distribution of intention status by year, PRAMS 2009‐2014
Year
Intention
2009
2010
2011 2012
I wanted to be pregnant later
32%
31%
31%
24%
I wanted to be pregnant sooner
17%
17%
18%
13%
I wanted to be pregnant then
39%
40%
40%
41%
I didn't want to be pregnant then or at any
time in the future
10%
9%
10%
6%
I wasn't sure what I wanted
na
na
na
13%
Missing/blank
2%
2%
2%
2%
Total
100% 100%
100% 100%

2013
23%
14%
41%

2014
22%
14%
42%

6%
14%
2%
100%

6%
15%
2%
100%

Notes: na = not applicable. Proportions predicted from logistic regression models including state
fixed effects to control for annual differences in sets of states contributing data.

0

.1

Proportion
.2

.3

.4

Figure 1a. Proportion of women reporting ''I was not sure'' by maternal age
adjusted for state and year of survey, pooled 2012-2014 PRAMS

<=17

18-19

20-24

25-29
30-34
Maternal age

35-39

40+

0

.1

Proportion
.2

.3

.4

Figure 1b. Proportion of women reporting ''I was not sure'' by race and ethnicity
adjusted for state and year of survey, pooled 2012-2014 PRAMS

White, NH

Hispanic
Black, NH
Race and ethnicity

Other, NH

0

.1

Proportion
.2

.3

.4

Figure 1c. Proportion of women reporting ''I was not sure'' by parity
adjusted for state and year of survey, pooled 2012-2014 PRAMS

0

1
Parity

2+

Table 2. Logistic regressions predicting pregnancy intention from year and question wording, adjusting for state fixed effects,
PRAMS 2009‐2014
Pregnancy intention

Covariate
Year (centered)
Treatment
Year x Treatment

I wanted to be pregnant
later
b
p‐value
‐0.02
0.12
‐0.30
<.001
‐0.03
0.15

I wanted to be pregnant
sooner
b
p‐value
0.02
0.30
‐0.33
<.001
‐0.01
0.80

I wanted to be pregnant
then
b
p‐value
0.02
0.13
0.04
0.21
‐0.01
0.43

Note: All models also include state dummy variables in order to adjust for variation across states.

I didn't want to be
pregnant then or at any
time in the future
b
p‐value
‐0.03
0.18
‐0.43
<.001
0.00
0.91

0

.1

Proportion
.2
.3

.4

.5

Figure 2. Predicted probabilities of pregnancy intention
from regression discontinuity model, pooled PRAMS 2009-2014

2009

2010

2011
Later
Then

2012
Sooner
Did not want

2013

2014

Figure 3. Predicted treatment effect (with 95% CI) by demographic categories, PRAMS 2009-2014
Later

Sooner

Age
15-17
18-19
20-24
25-29
30-34
35-39
40+

Age
15-17
18-19
20-24
25-29
30-34
35-39
40+

Race and Ethnicity
White, NH
Hispanic
Black, NH
Other, NH

Race and Ethnicity
White, NH
Hispanic
Black, NH
Other, NH

Parity
0
1
2+

Parity
0
1
2+
-1

-.5

0
Treatment effect (log odds)

.5

-1

-.5

Then
Age
15-17
18-19
20-24
25-29
30-34
35-39
40+

Race and Ethnicity
White, NH
Hispanic
Black, NH
Other, NH

Race and Ethnicity
White, NH
Hispanic
Black, NH
Other, NH

Parity
0
1
2+

Parity
0
1
2+
-.5

0
Treatment effect (log odds)

.5

Did not want

Age
15-17
18-19
20-24
25-29
30-34
35-39
40+

-1

0
Treatment effect (log odds)

.5

-1

-.5

0
Treatment effect (log odds)

.5

Figure 4. Predicted treatment effect (with 95% CI) by state, PRAMS 2009-2014, among states with data for all years
Later

Sooner

DE
HI
MA
MD
ME
MO
NE
NJ
OK
PA
RI
UT
VT
WA
WV
WY

DE
HI
MA
MD
ME
MO
NE
NJ
OK
PA
RI
UT
VT
WA
WV
WY
-1

-.5

0
Treatment effect (log odds)

.5

-1

-.5

Then

0
Treatment effect (log odds)

.5

Did not want

DE
HI
MA
MD
ME
MO
NE
NJ
OK
PA
RI
UT
VT
WA
WV
WY

DE
HI
MA
MD
ME
MO
NE
NJ
OK
PA
RI
UT
VT
WA
WV
WY
-1

-.5

0
Treatment effect (log odds)

.5

-1

-.5

0
Treatment effect (log odds)

.5

Appendix Table 1. Logistic regressions predicting pregnancy intention from year and question wording, with
interactions by maternal age groups, PRAMS 2009‐2014
Pregnancy intention

Year (centered)
Treatment
Year x Treatment

I wanted to be
pregnant later
b
p‐value
0.00 0.81
‐0.30 <.001
‐0.04 0.08

I wanted to be
pregnant sooner
b
p‐value
0.00 0.96
‐0.35 <.001
0.00 0.93

I wanted to be
pregnant then
b
p‐value
0.01 0.63
0.07 0.054
‐0.01 0.50

I didn't want to be
pregnant then or at
any time in the future
b
p‐value
‐0.03 0.19
‐0.46 <.001
0.00 0.97

Age
15‐17
18‐19
20‐24
25‐29 (ref)
30‐34
35‐39
40+

1.63
1.34
0.80
0.00
‐0.50
‐1.02
‐1.47

<.001
<.001
<.001

‐1.96
‐1.25
‐0.63
0.00
0.29
0.56
0.93

<.001
<.001
<.001

‐1.45
‐0.95
‐0.54
0.00
0.15
0.06
‐0.46

<.001
<.001
<.001

0.43
0.07
0.14
0.00
0.10
0.53
1.17

<.001
0.399
0.01

Age x Treatment
15‐17 x Treatment
18‐19 x Treatment
20‐24 x Treatment
25‐29 x Treatment (ref)
30‐34 x Treatment
35‐39 x Treatment
40+ x Treatment

‐0.04
‐0.07
‐0.04
0.00
0.01
0.00
‐0.19

0.70
0.35
0.33

‐0.03
0.06
‐0.02
0.00
0.04
‐0.06
‐0.06

0.91
0.71
0.80

‐0.77
‐0.30
‐0.08
0.00
0.00
‐0.04
0.05

<.001
<.001
0.06

0.08
0.13
‐0.03
0.00
‐0.01
0.13
0.02

0.64
0.34
0.72

Covariate

<.001
<.001
<.001

0.81
0.96
0.31

<.001
<.001
<.001

0.38
0.32
0.50

<.001
0.074
<.001

0.91
0.39
0.58

Note: All models also include state dummy variables in order to adjust for variation across states.
Average treatment eﬀects by age (with 95% CIs)†
Age
ATE 95% CI
ATE
95% CI
ATE 95% CI
ATE
15‐17
‐0.34 (‐0.56, ‐0.13) ‐0.38 (‐0.96, 0.19) ‐0.69 (‐1.02, ‐0.37) ‐0.38
18‐19
‐0.37 (‐0.51, ‐0.23) ‐0.29 (‐0.61, 0.02) ‐0.22 (‐0.39, ‐0.06) ‐0.33
20‐24
‐0.34 (‐0.44, ‐0.25) ‐0.37 (‐0.50, ‐0.24) ‐0.01 (‐0.09, 0.08) ‐0.49
‐0.46
25‐29
‐0.30 (‐0.39, ‐0.21) ‐0.35 (‐0.45, ‐0.25) 0.07 (0.00, 0.15)
30‐34
‐0.29 (‐0.39, ‐0.19) ‐0.31 (‐0.41, ‐0.21) 0.07 (‐0.01, 0.15) ‐0.46
35‐39
‐0.31 (‐0.45, ‐0.16) ‐0.41 (‐0.53, ‐0.29) 0.03 (‐0.06, 0.13) ‐0.33
40+
‐0.49 (‐0.85, ‐0.13) ‐0.41 (‐0.60, ‐0.23) 0.12 (‐0.05, 0.30) ‐0.44
† Also shown in Figure 2
ATE = Average treatment effect

0.05
<.001
<.001

0.91
0.13
0.89

95% CI
(‐0.71, ‐0.04)
(‐0.59, ‐0.07)
(‐0.64, ‐0.33)
(‐0.61, ‐0.30)
(‐0.62, ‐0.31)
(‐0.49, ‐0.16)
(‐0.68, ‐0.20)

Appendix Table 2. Logistic regressions predicting pregnancy intention from year and question wording, with interactions by maternal race
and Hispanic ethnicity, PRAMS 2009‐2014
Pregnancy intention

Year (centered)
Treatment
Year x Treatment

I wanted to be
pregnant later
b
p‐value
‐0.02 0.21
‐0.28 <.001
‐0.04 0.08

I wanted to be
pregnant sooner
b
p‐value
0.01 0.44
‐0.35 <.001
0.00 0.97

I wanted to be
pregnant then
b
p‐value
0.02 0.17
0.05 0.154
‐0.01 0.57

I didn't want to be
pregnant then or at
any time in the future
b
p‐value
‐0.03 0.25
‐0.46 <.001
0.00 0.94

Race and Hispanic ethnicity
White, not Hispanic (ref)
Hispanic
Black, not Hispanic
Other, not Hispanic

0.00
0.48 <.001
0.70 <.001
0.06 0.09

0.00
‐0.61 <.001
‐0.66 <.001
0.27 <.001

0.00
‐0.18 <.001
‐0.89 <.001
‐0.35 <.001

0.00
0.23 <.001
1.07 <.001
0.27 <.001

Race and Hispanic ethnicity x Treatment
White, not Hispanic X Treatment (ref)
Hispanic x Treatment
Black, not Hispanic x Treatment
Other, not Hispanic x Treatment

0.00
0.00 0.96
‐0.11 0.02
0.05 0.31

0.00
0.22 <.001
‐0.05 0.49
‐0.17 0.00

0.00
‐0.09 0.04
‐0.04 0.39
0.05 0.26

0.00
0.21 0.01
‐0.03 0.64
0.00 0.99

Covariate

Note: All models also include state dummy variables in order to adjust for variation across states.
Average treatment eﬀects by race and ethnicity (with 95% CIs)†
Race and ethnicity
ATE 95% CI
ATE 95% CI
ATE 95% CI
ATE 95% CI
White, not Hispanic
‐0.28 (‐0.36, ‐0.21) ‐0.35 (‐0.43, ‐0.26)
0.05 (‐0.02, 0.11) ‐0.46 (‐0.59, ‐0.32)
Hispanic
‐0.28 (‐0.38, ‐0.18) ‐0.12 (‐0.26, 0.01)
‐0.04 (‐0.13, 0.05) ‐0.25 (‐0.42, ‐0.07)
Black, not Hispanic
‐0.40 (‐0.50, ‐0.29) ‐0.39 (‐0.53, ‐0.25)
0.01 (‐0.10, 0.11) ‐0.49 (‐0.64, ‐0.33)
Other, not Hispanic
‐0.23 (‐0.34, ‐0.12) ‐0.52 (‐0.64, ‐0.40)
0.10 (0.00, 0.20)
‐0.46 (‐0.64, ‐0.27)
† Also shown in Figure 2
ATE = Average treatment effect

Appendix Table 3. Logistic regressions predicting pregnancy intention from year and question wording, with
interactions by maternal parity, PRAMS 2009‐2014
Pregnancy intention

Year (centered)
Treatment
Year x Treatment

I wanted to be
pregnant later
b
p‐value
0.00 0.91
‐0.27 <.001
‐0.04 0.10

I wanted to be
pregnant sooner
b
p‐value
0.00 0.99
‐0.38 <.001
0.00 0.95

I wanted to be
pregnant then
b
p‐value
0.01 0.64
0.05 0.20
‐0.01 0.55

I didn't want to be
pregnant then or at
any time in the future
b
p‐value
‐0.03 0.23
‐0.50 <.001
0.00 0.98

Parity
0 (ref)
1
2+

0.00
0.02
0.34

0.00
‐0.37 <.001
‐1.06 <.001

0.00
0.08 0.002
‐0.30 <.001

0.00
0.41
1.55

<.001
<.001

Parity x Treatment
0 x Treatment (ref)
1 x Treatment
2+ x Treatment

0.00
‐0.01 0.84
‐0.18 <.001

0.00
0.03
0.05

0.00
0.01 0.69
‐0.07 0.06

0.00
0.03
0.08

0.69
0.24

Covariate

0.56
<.001

0.47
0.30

Note: All models also include state dummy variables in order to adjust for variation across states, as well as
controls for age.
Average treatment effects by parity (with 95% CIs)†
Parity
ATE 95% CI
ATE 95% CI
ATE 95% CI
ATE 95% CI
0
‐0.27 (‐0.35, ‐0.19) ‐0.38 (‐0.48, ‐0.29) 0.05 (‐0.02, 0.12) ‐0.50 (‐0.65, ‐0.34)
1
‐0.28 (‐0.37, ‐0.19) ‐0.35 (‐0.45, ‐0.25) 0.06 (‐0.01, 0.13) ‐0.46 (‐0.62, ‐0.31)
2+
‐0.45 (‐0.55, ‐0.36) ‐0.33 (‐0.44, ‐0.22) ‐0.02 (‐0.10, 0.05) ‐0.42 (‐0.55, ‐0.28)
† Also shown in Figure 2
ATE = Average treatment effect

