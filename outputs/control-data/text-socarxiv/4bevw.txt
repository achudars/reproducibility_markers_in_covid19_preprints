This is an Accepted Manuscript of an article published by Taylor & Francis in Journal of
Community Archaeology and Heritage on 31 May 2019, available online:
https://www.tandfonline.com/doi/full/10.1080/20518196.2019.1625190.

Event review: “Archaeology Education: Building a Research Base.” Symposium at the
Society for American Archaeology 84th Annual Meeting, Albuquerque, New Mexico, USA,
12th April 2019.
Elizabeth Reetz (M.A., M.Ed.), University of Iowa Office of the State Archaeologist. elizabethreetz@uiowa.edu

Notes on Contributor: Elizabeth Reetz is the Director of Strategic Initiatives at the University of
Iowa Office of the State Archaeologist where she develops and manages statewide, all-ages
initiatives in public archaeology, environmental education, and science communication. She
began her archaeology career in 2001 and transitioned to education in 2011, with a focus on
connecting youth to nature through archaeology and place-based education. Reetz currently
chairs the Society for American Archaeology’s Public Education Committee.

As the push to institutionalize archaeology and heritage education has gained traction over the
past few years, archaeologists and educators alike have been stressing the importance of building
a research base to strengthen that traction and provide a model for others (see King 2016).
Afterall, if we’re not implementing public programmes based on well-researched best practices,
are our efforts worthwhile? Likewise, if we don’t evaluate or assess that programming, we really
cannot understand its effectiveness, value, or impact beyond the anecdotal. Yet despite this
common-sense approach, and the fact that archaeology is a discipline based on developing a
strong research design and the interpretation of evidence, many archaeologists do not consider
research-based approaches to delivering public programming. Even fewer have the skills to

assess the learning of their participants or evaluate the effectiveness of their programming, which
are both incredibly important components of building this research base. Ellenberger and
Richardson (2018) point out that many professional archaeological organizations in the USA and
UK are quiet on the matter of evaluation and outcomes of public archaeology in their ethics
statements, particularly regarding community collaborations, and no organization explicitly
mentions the need to evaluate public projects and share best practice. As a result, this work is
underrepresented in published academic work. The papers in this session, when published, will
make some much needed contributions to the comparative literature.
Presenters at the session, of course, were preaching to the choir, not unlike me writing
this review to an audience of community archaeology peers! Those who made the effort to attend
this 8:00 am session were primarily archaeology educators who knew each other well, as well as
some new faces. The presentations covered a wide range of public programming involving K-12 i
classroom curricula, school excavations, Girl Scout camps, archaeology field schools,
avocationals and collectors, and professional development for educators.
Many of the presentations outlined some significant findings that we wouldn’t know if no
assessment was done. Jeanne Moe of Project Archaeology presented on a 4th grade school-yard
excavation that she observed, and her data showed that the students understood that archaeology
was ‘not just digging’ and ‘you need a good reason’ for a ground-disturbing excavation.
However, they had a lot of misconceptions about what happens to the artefacts afterward and
were just generally confused about the entire archaeological process. More importantly, students
thought that an excavation was the only way to provide the full picture of archaeology, and the
teacher likewise thought that digging was the most important part of the process. This is a
problem.

Nichole Tramel's (Project Archaeology) results on a new curriculum pilot test indicated
that every student who participated increased their understandings of ecosystems, archaeology,
the inquiry process, and stewardship. However, some students still had misconceptions about
how people affect ecosystems. Now that the curricula team knows that, they address how to
better communicate that concept.
Karin Larkin (University of Colorado, Colorado Springs) and Michelle Slaughter
(Metcalf Archaeological Consultants, Inc.) teamed up for an academic-CRM collaboration to
explore how field schools prepare students for CRM work. Turns out, most academics think that
students leave field schools prepared for working in CRM, yet CRM archaeologists didn’t agree.
They didn’t strongly disagree; they just were not convinced. The results also showed what most
CRM archaeologists are looking for in new hires, and field schools are only scratching the
surface of these skills – like technical writing. This study exposed some pretty big disconnects
between what skills we are teaching and what we desire in employees. This is a huge red flag,
and this type of assessment needs to be replicated to see if the results hold beyond this one case
study.
The highlight of the session, hands-down, was the presentation given by local
Albuquerque-area 5th graders. I wish the whole conference could have seen this presentation!
Their teacher, John Turrietta (Rio Rancho Public Schools), is a Project Archaeology Leadership
Academy graduate. The students read, ‘Sallie Fox: The Story of a Pioneer Girl,’ about a 12-yearold girl on a wagon trail in 1858-59, then learned about and visited a site with rock art and
historical inscriptions associated with that trail. The students took surveys before and after their
lesson and explained the data results to the session attendees. The power of their place-based

experience and respect for the past was clear in their results, and the presentation was nothing
short of remarkable.
Carrying out an evaluation plan is not easy, as many of the presenters acknowledged.
Sometimes you cannot control time or other factors and you get few responses or participants,
and as mentioned above, we don’t yet have those institutionalized best practices. Presenters like
Tramel, Samantha Kirkley (Southern Utah University), and Erika Malo (Project Archaeology)
talked about the challenges with their assessments, and this transparency was important. The fact
that assessment can be frustrating is what keeps many from attempting to carry it out, but the
more we communicate our challenges, the better others can prepare their own initiatives.
Additionally, assessment best practices dictate that your goals and objectives determine which
data collection instrument(s) are the best tools for the task. I think because we’re still learning
how to do this, archaeologists tend to default to questionnaires and surveys. They’re seemingly
easy to create (although bad questions lead to bad data) and administer. Questionnaires were
used effectively in the presentations given today, but I look forward to a growing research base
that diversifies and strengthens the comparative literature with mixed methods studies.
As Elizabeth Pruitt (Society for American Archaeology) stated in her discussion, ‘Doing
assessment of public programming is ethical archaeology, just as public archaeologists have been
saying about doing public archaeology for decades.’ Assessment is good science. If we can
successfully measure success or impact, we strengthen our tools for advocacy and the protection
of cultural resources, justify funding for public programming, and ultimately positively impact
public perceptions of preservation and heritage. Due to lack of funding and resources, we’re
stretching ourselves to do education and outreach. We stretch ourselves even further to
incorporate basic assessment and evaluation, and further still to create and implement a thorough

evaluation plan. It’s hard, and I don’t have any good advice or words of wisdom for creating the
magical balance needed to consistently and effectively carry out this work.
Another interesting point brought up by Pruitt and agreed upon by the participants was
accounting for ego. Doing educational assessment might mean asking questions we don’t want
the answers to. Changing our culture is daunting and exhausting. Do we want to know that our
tried and true methods for field schools are not likely leaving students prepared for careers in our
field? If teachers have no use for the lessons and curricula, we write for them? If people leave
our community lectures bored and not caring about what we discussed? That we are failing to
teach children and the public that archaeology isn’t just digging? Acknowledging a lack of
success is a hard pill to swallow, and the status quo is comfortable! In reality, we need to know,
and we need the data to support these findings. There needs to be a sea change, and that will take
both time and a culture shift within the field. I whole-heartedly applaud both the presenters and
attendees in this session for making the early morning effort to nudge for this sea change. ‘An
avalanche starts with one pebble.’

Reference List
King, Eleanor M. (guest editor). 2016. “Designing and Assessing Public Education Programs in
Archaeology.” Advances in Archaeological Practice 4(4). doi:
https://doi.org/10.1017/S2326376800001005
Ellenberger, Katharine, and Richardson, Lorna-Jane. 2018. “Reflecting on Evaluation in Public
Archaeology.” AP: Online Journal in Public Archaeology 8:65-94. doi:
http://dx.doi.org/10.23914/ap.v8i1.141
The expression “K-12” is short for “kindergarten through twelfth grade” in the United States public education
system, which is basically equivalent to the start of primary education through the end secondary education.

i

