How to design institutions that foster cooperation
Arunas L. Radzvilavicius1,∗ , Taylor A. Kessinger1,∗ , Joshua B. Plotkin1,†
1

Department of Biology, University of Pennsylvania, Philadelphia, PA, USA
∗

Equal contribution † E-mail: jplotkin@sas.upenn.edu

November 6, 2020

Abstract
Humans typically consider altruism a moral good and condition their social behavior on the
moral reputations of others. Indirect reciprocity explains how social norms and moral reputations can collectively support cooperation: members of the society cooperate who others who
are considered good. But the theory of indirect reciprocity requires institutions that monitor and publicly broadcast moral reputations. Here we study evolution of adherence to public
monitoring in societies where individuals are, at first, independently responsible for evaluating
the moral reputations of their peers. We show that adherence to a public institution of moral
assessment can evolve and promote cooperation under all simple social norms, depending upon
the institution’s tolerance to occasional antisocial behavior. We specify how an institution’s size
and its degree of tolerance towards antisocial behavior can be designed to dramatically increase
cooperation rates, even for social norms that previous studies have found to perform poorly.
Public monitoring serves to eliminate disagreements about reputations in the population, which
in turn increases cooperation and individual payoffs, so that adherence to the public institution
can evolve by social contagion. Adherence is then robust to invasion, and it tends to crowd out
internal mechanisms that could alternatively support cooperation. These results help explain
why societies tend to elect centralized institutions to provide top-down moral governance of
their individual behavior.

Introduction
Social norms, reputations, and institutions of moral assessment are critical to cooperation in human societies [Alexander, 1985, Elster, 1989, Kandori, 1992, Tomasello and Vaish, 2013, Hechter,
2018, Curry et al., 2019]. People typically consider altruistic behavior a moral good [Rand et al.,
2013], and they tend to be more cooperative when being observed by others [Rege and Telle, 2004,
Bereczkei et al., 2007]. Moral reputations are directly related to cooperation, and cooperation in
turn can lead to higher social status [von Rueden et al., 2019], while kindness towards people of bad
moral standing is sometimes punished [Martin et al., 2019]. Interactions in modern societies often
involve cooperation with strangers, and so people must rely on moral reputation scores provided
by institutions or third parties, for instance, in e-commerce interactions [Utz et al., 2009, Hechter,
2018]. Historically, communities have constructed institutions that broadcast information about
others’ prior behavior so that all reputations are publicly available [Milgrom et al., 1990, Greif,
2004].
Evolutionary game theory provides a convenient framework for studying human behavior
governed by social norms, reputations, and community enforcement [Nowak and Sigmund, 2005].
In such models of indirect reciprocity, a donor’s action (to cooperate or not) depends on the
recipient’s moral reputation (“good” or “bad”). Reputations are updated according to a social
1

