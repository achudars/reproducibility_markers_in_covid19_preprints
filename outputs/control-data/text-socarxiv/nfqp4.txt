A closer look at fixed effects regression in
structural equation modeling using lavaan
Henrik Kenneth Andersen
2020-06-21
Abstract
This article provides an in-depth look at fixed effects regression in the
structural equation modeling (SEM) framework, specifically the application
of fixed effects in the lavaan package for R. It is meant as a applied guide
for researchers, covering the underlying model specification, syntax, and
summary output. Online supplementary materials further discuss various
common extentsions to the basic fixed-effect model, demonstrating how
to relax model assumptions, deal with measurement error in both the
dependent and independent variables, and include time-invariant predictors
in a type of hybrid fixed-/ random effects model.
Keywords: Fixed effects, structural equation modeling, lavaan, R,
panel analysis

1

Introduction

Several years ago, Curran and Bauer (2011) reflected positively on the growing
use of panel studies in empirical social research. Some of the strengths of panel
data are well-known, e.g., the ability to establish temporal precedence, increased
statistical power and the reduction of potential alternative models. However,
perhaps the greatest strength of panel data is that they allow for a more rigorous
testing of substantive theories. Panel data, i.e., repeated measures of the same
observed units (people, schools, firms, countries, etc.), allow researchers to
decompose the error term into a part that stays constant within units and the
part that changes over time. The part that does not change over time can be
seen as the combined effect of all time-invariant influences (e.g., sex, date of
birth, nationality) on the dependent variable. Fixed effects (FE) regression
involves controlling for these time-invariant influences via a number of various
methods. It thus drastically reduces the number of potential confounders of the
relationship between variables of interest.
Structural equation modeling (SEM) is a popular regression framework. One of
its main strengths is its flexibility. Not only can complex causal structures with
multiple dependent variables be tested simultaneously, but in longitudinal (and,
more generally, hierarchical) studies both time-varying and invariant predictors
can be included, and effects can easily be allowed to vary over time. Thus
researchers can allow for and study effects that increase or fade over time, or that
appear only in specific periods. Beyond that, with the use of latent variables,
SEM provides a way to deal with measurement error and get closer to the true
underlying constructs of interest.
There are a number of articles describing basic concept of panel model regression,
and FE regression in SEM (e.g., Allison 2011; Bollen and Brand 2010; Teachman
et al. 2001). This article is intended as a practical guide for researchers looking
for in-depth help with specifying FE models in SEM. It focuses on the lavaan
(Rosseel 2012) package for R (R Core Team 2017). While Mplus (Muthén and
1

Muthén, n.d.) is arguably the most robust SEM software currently available (in
terms of features like alignment, latent variable interactions, for example) , the
lavaan package has many benefits. First, it and R are open source and completely
free. For researchers dipping their toes into SEM, there is no financial barrier to
try, and no risk if they decide it is not for them. Second, the implementation of
lavaan in the larger R environment is an enormous advantage. Instead of poring
over reams of plain text, copying out coefficients by hand, every part of the
lavaan output is available as an object. This means that all aspects of the model,
from fit indices, to coefficients and standard errors, to the model matrices, can
be accessed and easily integrated into tables and plots. Furthermore, R can be
used for a great deal of applications. It can be used to manage and manipulate
as well as simulate data, perform symbolic algebra, run more traditional analyses
(e.g., multiple regression, logistic regression, principal component analysis), etc.
Once one is comfortable using R, there is no longer any need to switch between
different software for data preparation and analysis.
The following article outlines the basic idea of FE regression, the particularities
of FE in SEM, and shows its implementation in lavaan. Using simulated data, it
demonstrates and annotates the code for the most basic FE model and provides
an overview of the summary output. A number of potential extensions to the
basic model, including relaxing various assumptions, dealing with measurement
error in both the independent and dependent variables, as well as the inclusion
of time-invariant predictors in the form of a hybrid fixed-/ random effects model,
are shown in detail in the form of online supplementary materials.

2

Panel models

To begin, let us start by reviewing a general panel model (Bollen and Brand
2010), also referred to as the ‘unobserved effects model’ (Wooldridge 2012) (we
will return to this model in the online section of the article when we discuss
loosening assumptions)
2

yit = xit β + zi γ + αi + εit

(1)

where yit is the dependent variable for unit i, i = 1, ..., N at time t, t = 1, ..., T ,
xit is a 1 × K vector of time-varying covariates (which could include a constant)
linked to the dependent variable by the K × 1 vector of coefficients β. zi is a
1 × M vector of time-invariant covariates linked to the dependent variable by
the M × 1 vector of coefficients in γ, αi represents the combined effect of all
unobserved unit-specific variables affecting the dependent variable and εit is the
idiosyncratic error.
We can make stating some of the model assumptions easier by rewriting it in
matrix notation

yi = Xi β + Zi γ + ιT αi + εi
where yi and εi are T × 1 vectors, Xi and Zi are T × K and T × M matrices,
respectively, ιT is a T ×1 vector of ones and αi is a scalar. β and γ are unchanged
from Equation (1).
We typically make the following assumptions (see, e.g., Wooldridge 2002; Schmidheiny 2019) about this model:
• Linearity: the model is linear in its parameters and E[εit ] = 0 and E[αi ] = 0.
• Independence: the observations are independent across individuals (assured
by random sampling in the cross-section), but not necessarily across time.
• Strict exogeneity: E[εit |Xi , zi , αi ] = 0, i.e., the idiosyncratic error at each
point in time is mean independent of Xi at all points in time, t = 1, ..., T ,
as well as zi and αi .

• Error variance: homoscedastic and non-serially correlated errors, i.e.,
Var(εi |Xi , zi , αi ) = σε2 I.
3

2.1

Random effects

If we are willing to make some assumptions about the distribution of the
individual effects and, more importantly, their lack of a relationship with the
observed time-varying covariates, we are left with the random effects model
(Wooldridge 2002, 2012; Schmidheiny 2019; Skrondal and Rabe-Hesketh 2004).
Namely, we assume the individual effects are normally distributed, with a
constant (homoscedastic) variance conditional on the model covariates, i.e.,
αi |Xi , zi ∼ N (0, σα2 ).1 Further, we assume that the expectation of the individual
effects conditional on the model covariates is zero, i.e., E[αi |Xi , zi ] = 0, which
implies they are also uncorrelated.
The random effects model works by defining a composite error term: νit = αi +εit
and rewriting the model in Equation (1) as

yit = xit β + zi γ + νit , or
yi = Xi β + Zi γ + νi .
By adding the individual effects to the composite error in each time period,
the composite error becomes serially correlated over time, to give the following
conditional covariance matrix for the errors,


Ων 1
 ..
 .

Var(ν|X, z) = Ων = 
 0
 .
 ..
0

...
..
.
...
..
.
...

0
..
.
Ωνi
..
.
0

...
..
.
...
..
.
...


0
.. 
. 

0 

.. 
. 
ΩνN

with typical elements
1 As long as X contains a constant, the assumption that α has a mean of zero is unprobi
i
lematic (Wooldridge 2012).

4

σν2
σα2

= .
 ..


Var(νi |Xi , zi ) = Ωνi

σα2

σα2
σν2
..
.
σα2


. . . σα2
. . . σα2 

.. 
..
. . 
. . . σν2

(2)

where σν2 = σα2 + σε2 . This means that in the conditional covariance matrix
of the errors, given the time-varying and -invariant covariates, units over time
will be correlated due to the individual effects. We should keep the covariance
structure of the errors in mind as it will help make sense of the use of latent
variables to decompose the dependent variable into between- and within-variance
components, discussed below in Section 3.

2.2

Fixed effects

What if the individual effects are not independent of the observed time-varying
covariates, i.e., E[αi |Xi ] 6= 0? Then grouping them in with the error will cause
β to be biased (Wooldridge 2002, 2012). In order to drop assumptions involving
the individual effects, a number of methods are available (e.g., differencing, least
squares dummy variable regression), but the most common approach is to demean
the equation (Brüderl and Ludwig 2015). Demeaning involves subtracting the
per-unit, over-time average from each of the model terms, i.e.,

(yit − ȳi ) = (xit − x̄i )β + (zi − z̄i )γ + (αi − ᾱi ) + (εit − ε̄i )
ÿit = ẍit β + ε̈it , or
ÿi = Ẍi β + ε̈i
where, for example, ȳi = T −1

(3)
PT

i=1

yit (and the other over-time means are

calculated analogously), and the variables with the dots above them represent
the demeaned versions. Because the average of something that does not change is
that thing itself, the individual effects, along with any time-invariant predictors,
get wiped out by the demeaning. This means that no assumptions about the

5

relatedness of the model covariates and the unit-specific portion of the error are
needed. The unbiasedness of the estimate is related solely to the strict exogeneity
assumption imposed on the idiosyncratic errors, i.e., E[ε̈it |ẍit ] = E[ε̈it ] = 0 which
also implies E[ẍ|is ε̈it ] = 0, ∀ s, t = 1, ..., T (Brüderl and Ludwig 2015; Wooldridge
2002). The downside to this approach is that no time-invariant predictors can
be included in the model. In the online section, it will be discussed how to get
around this restriction using SEM.

3

Fixed effects in structural equation modeling

Moving from the conventional methods outlined above to SEM, we must state
the FE model in a different way. We turn to latent variables to account for timeinvariant unobserved heterogeneity. In fact, besides accounting for measurement
error and the representation of abstract hypothetical concepts, unobserved
heterogeneity has historically been one of the main uses of latent variables in
SEM (Skrondal and Rabe-Hesketh 2004).

3.1

Modeling time-invariant unobserved heterogeneity as
a latent variable

We first need to convert the data from stacked, long-format vectors of length
N T into T individual vectors of length N . To see why this is necessary, consider
what effect this has on the vector of responses yit . Let us, for a minute ignore any
covariates and focus just on the dependent variable (a so-called ‘intercept-only’
model) so that we have yit = αi + εit . When we convert the data to wide-format,
we get T individual equations,

y1i = αi + ε1i
y2i = αi + ε2i
..
.
yT i = αi + εT i .
6

(4)

Because the idiosyncratic errors are assumed to be uncorrelated across units
and across time, the covariance between any two of the new wide vectors
Cov(yti , ysi ) = Var(αi ), t 6= s.

Otherwise, when t = s, the covariance

Cov(yti , yti ) = Var(αi ) + Var(εti ). This is the structure we saw above in a
typical element of Ων .
And in fact this is exactly how a latent variable is used to account for timeinvariant unobserved heterogeneity. The dependent variable at each timepoint
is regressed onto the latent variable, see Figure 1. Here, the regression weights
or ‘factor loadings’ are fixed to one to represent our assumption that the effect
of the time-invariant unobserved heterogeneity is constant over time. It also
means that the estimated variance of the latent variable is equal to the average
covariance between the wide-format columns of the dependent variable over time.
If yit = αi + εit is the true data generating process, then the relationship between
two units over time is just α, regardless of the time distance. Referring back to
the random effects structure of Ωνi in Equality (2) for a generic unit i, we see
the covariance on all of the off-diagonals is σα2 . And, as we know, the average of
something that does not change is that thing itself. I.e., if T (T − 1)/2 = h is
the number of elements on either the upper- or lower triangle of Ωνi , then we
Ph
hσ 2
have h−1 i=1 σα2 = hα = σα2 .
To show this, consider the following matrix equation of the variances and the
nonredundant covariances in a three-wave intercept-only model that follows
directly from Equation (4) (assuming Cov(εt1 , εsi ) = 0, t 6= s), and which we
can solve easily with least squares:

7

b = Ax
ψ


Var(y1 )
y12
1
Cov(y2 , y1 )
y2 y1  1



Cov(y3 , y1 )
1

 = y3 y1 

 Var(y2 ) 
y22  1


Cov(y3 , y2 )
y3 y2  1
Var(y3 )
y32
1


φ1
1
0
0
0
0
0

φ2
0
0
0
1
0
0

φ3

0  
0 ψ
 φ 
0 
1
 
0 φ2 
0  φ3
1

where ψ = Var(α), φt = Var(εt ). We can solve this equation to show

b = Ax
(A A)
|

−1

A b = (A| A)−1 A| Ax
|

(A| A)−1 A| b = x
  
ψ
.33 Cov(y2 , y1 ) + .33 Cov(y3 , y1 ) + .33 Cov(y3 , y2 )




φ
Var(y
)
−
ψ
1
 =  1 .


 φ2 
Var(y2 ) − ψ
Var(y3 ) − ψ
φ3


This shows that if our assumption of constant covariances between the dependent
variable across time holds, the estimated variance of α is just what it should be:
the average covariance between units of y over time. Once we add in observed
covariates, the estimated covariance of α then become the conditional covariance
of y over time, given those covariates.

3.2

Model notation

Having explained how a latent variable is used to estimate the individual effects,
we need to state the FE model using SEM-compatible matrix notation. There
are a number of different model notations (see, for example Bollen (1989) for an
overview), but the one that will serve us best is one that was proposed by Graff
(1979):

8

+
y + = Λ+
yη ,

η + = Bη + + ζ + ,
where η + = (y, x, η, ξ)| , ζ + = (ε, δ, ζ, ξ)| , y + = (y, x)| . y is a vector of
observed dependent variables and x is a vector of observed independent variables.
η is a vector of the latent dependent variables and ξ is a vector of latent
independent variables. ε and δ are vectors of the errors of the observed dependent
and independent variables, respectively, and ζ is a vector of the errors, or
disturbances, of the latent variables. Notice the

+

symbol is just meant to

differentiate the vectors with them from those without them. That means, η + is
a vector that holds the observed and latent variables, both dependent (in SEM
they are referred to as ‘endogenous’) and independent (i.e., ‘exogeneous’)2 , ζ +
holds the errors for the observed variables and the disturbances of the latent
variables. y + holds just the observed variables, both dependent and independent,
and Λ+
y is a matrix of ones and zeros that selects the observed variables from
η + . Lastly B is a matrix that holds the regression coefficients.
If we say that p and q stand for the number of observed dependent and independent variables, respectively, and m and n stand for the number of latent dependent
and independent variables, respectively, then η + and ζ + are p + q + m + n, y + is
p + q, Λ+
y is (p + q) × (p + q + m + n) and B is (p + q + m + n) × (p + q + m + n)
(Bollen 1989).
This notation may be confusing at first, but it has advantages. First, it allows
us the flexibility we need for the models. For example, it allows observed x to
directly influence observed y (more common notation assumes that substantive
effects occur only between latent variables, observed ones are only used as
indicators, see for example Bollen (1989), Kline (2016)). It also allows ξ, i.e., any
latent exogenous variables, to influence y directly. These two scenarios cover the
2 For our purposes, the terms endogenous and dependent, on the one hand, and exogenous
and independent, on the other, can be used interchangeably.

9

traditional FE model with observed variables, and one in which latent variables
are used to account for measurement error in the independent variables. It is also
consistent with the notation used for these models in lavaan. In fact, lavaan
switches automatically between matrix notations depending on the specified
model. That means the matrix representation of the model one sees if they type
in lavInspect(model, what = "est") after specifying their model in lavaan
will match up with the notation used here.3 It does have a potential disadvantage
however. Besides being less intuitive than the typical η = Bη + Γξ + ζ notation,
it means that by including the observed covariates in the stacked long vector y + ,
they are treated as another response variable with variances and covariances to
be estimated by the model (instead of just using the sample statistics). This
means that the assumption of multivariate normality (otherwise just imposed
on the dependent variables) also applies to the independent ones (Skrondal and
Rabe-Hesketh 2004, 75). This can be problematic for noncontinuous independent
variables like sex, nationality dummies, marriage status (married/unmarried),
etc. See Skrondal and Rabe-Hesketh (2004) for more on this topic.
Let us, however, make things more concrete and take a look at a simple, threewave version of the typical FE-SEM using this notation (shown graphically in
Figure 1). For that, we have:

+
y + = Λ+
yη





y1
 y2 
 
 y3 
 =
x1 
 
x2 
x3
3 In

y1
y2
y3
x1
x2
x3

y1
1
0

0

0
0
0


y2
0
1
0
0
0
0

y3
0
0
1
0
0
0

x1
0
0
0
1
0
0

x2
0
0
0
0
1
0

x3
0
0
0
0
0
1

α y 
 1
0 y 
2
0 

y
 3

0 
x1 
,


0 x 

2


0 
x3 
0
α

(5)

Mplus, the model matrices can be requested by including OUTPUT: TECH1 in the input

file.

10

η + = Bη + + ζ +

y1
 y2 
 
 y3 
 
x1  =
 
x2 
 
x3 
α


y1
y2
y3
x1
x2
x3
α

y1

0
0

0

0

0
0
0

y2
0
0
0
0
0
0
0

y3
0
0
0
0
0
0
0

x1
β
0
0
0
0
0
0

x2
0
β
0
0
0
0
0

x3
0
0
β
0
0
0
0

α   

 y
ε1
1
1


y2 
1 
  ε2 




1  y3   ε3 
 x  + x = δ 
 (6)
1
1 .
1
0 


 x  x = δ 
2
0 
 2  2
0 x3  x3 = δ3 
α=ξ
α
0

Notice in ζ + , for the independent variables we could either write, for example
x1 or δ1 . As mentioned above, this is due to the model notation treating the
independent variables like dependent variables with variances/covariances to
be estimated. For the sake of simplicity, we will ignore this subtlety and refer
to the observed variable from now on, keeping in mind that if the multivariate
normality assumption holds, the estimated statistics will likely be sufficiently
close to the sample ones for it to not make much of a difference.
Admittedly, Equations (5) and (6) may not look like much yet. We can remedy
this by first putting the equation for η + in reduced form, i.e., by getting rid of
the dependent variable on the r.h.s.:

η + = Bη + + ζ +
η + − Bη + = ζ +
(I − B)η + = ζ +
η + = (I − B)−1 ζ + ,
where I is the identity matrix. By substituting this back into the equation for
−1 +
the observed variables we get y + = Λ+
ζ ], which works out to:
y [(I − B)

11


 
α + βx1 + ε1
y1
 y2  α + βx2 + ε2 

  
 y3  α + βx3 + ε3 
,
 =

 x1  
x1

  

 x2  
x2
x3
x3


which is of course exactly what we should expect given Equation (3)4 .

x1

x2

x3

α
1

β
y1
1
ε1

1

β
1
y2

β
y3

1

1

ε2

ε3

Figure 1: Typical three-wave FE-SEM model with contemporary effects

3.3

Assumptions

What essentially differentiates an FE from a random effects (RE) model is our
assumption concerning the relationship between the unobserved individual effects
and the model covariates (Bollen and Brand 2010). The FE model assumes that
E[αxt ] 6= 0. As such, if we fail to control for the correlation of the covariate
and the time-invariant part of the error, then the coefficient of interest, here
β, will be biased. Our assumption regarding whether the individual effects are
correlated with the model covariates occurs in E[ζ + ζ +| ] = Ψ, the covariance
matrix of the errors
4 We can use the sympy package in python to verify and show the steps for this and other
examples, see the supplementary materials for the code.

12

−1 +
−1 + |
y + y +| = E[(Λ+
ζ )(Λ+
ζ ) ]
y (I − B)
y (I − B)
−1 +
= E[(Λ+
ζ )(ζ +| (I − B)−1| Λ+|
y (I − B)
y )]
−1
= Λ+
E[ζ + ζ +| ](I − B)−1| Λ+|
y (I − B)
y
−1
= Λ+
Ψ(I − B)−1| Λ+|
y (I − B)
y .

In the case of an FE model, Ψ will reflect our belief that the individual effects are
correlated with the model covariates, here again for demonstration the three-wave
model:

ε1
ε2
ε3
Ψ = x1
x2
x3
α

ε1
ε21
0

0

0

0
0
0

ε2

ε3

x1

x2

x3

α




ε22
0
0
0
0
0

ε23
0
0
0
0

x21
x2 x1
x3 x1
αx1

x22
x3 x2
αx2

x23
αx3




.




α2

Knowing this, we can work out the equation for the coefficient of interest, β.
For the sake of simplicity, assume here and throughout mean-centered variables:

Cov(yt , xt ) = E[yt xt ]
= E[(α + βxt + εt )xt ]
= E[αxt + βx2t + εt xt ]
= Cov(α, xt ) + β Var(xt )
β̂ =

Cov(yt , xt ) − Cov(α, xt )
.
Var(xt )

This should make intuitive sense. From the observed covariance between the
dependent and the independent variable, we are partialling out the part that
is due to the covariance between the independent variable and the individual
effects per unit, and then dividing by the variance of the independent variable,
as usual. For the RE model, we assume E[αxt ] = 0 and the equation reduces
to β̂ = Cov(yt , xt )/ Var(xt ). The rest of the model-implied covariance matrix
13

results from y + y +| .

4

Fixed effects in lavaan

The package lavaan needs to be installed once with install.packages("lavaan").
To be able to use it, we need to load it for every new R session:
library( lavaan)
For users unfamiliar with R, SEM analyses can be carried out with almost no
knowledge of the language. Typically, someone unfamiliar with R would prepare
their data using some other statistical software, and then save the intended
dataset as a .csv, .xlsx, .dta, .sav, etc. file. The user must then import the
data, preferably as a dataframe, and the rest occurs using the lavaan syntax.5
Specifying the most basic fixed effects model, like the one shown in Bollen and
Brand (2010) (the same model as Equation (3) but with just one time-varying
predictor) involves four components. First, we define the latent individual effects
variable using the =~ ‘measured by’ or ‘manifested by’ (Rosseel 2012) operator
at the same time constraining the factor loadings at each timepoint to one. I
will call the latent variable a to stand for α. Constraining all of the factor
loadings to one reflects our implicit assumption that the combined effect of
the unit-specific unobserved factors is constant over time. This is the default
behaviour of traditional POLS-based approaches to FE that use the stacked
long-format data.
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
Second, we regress the dependent variable on the independent variable using
the ~ regression operator. With stacked, long-format data, only one regression
coefficient is estimated over all observed timepoints. To have our FE-SEM model
mimic this behaviour, we need to constrain the the estimated coefficient to equal
5 There are many online tutorials for importing data in various formats, see, for example
some from datacamp or Quick-R, or any of the many posts on stackoverflow.

14

over time. We do so by adding the same label to the regression coefficient at
every time point. We will use the label b (this label was chosen arbitrarily, we
could have used any letter or string of characters) and have it act as an equality
constraint for the regression coefficient of interest β:
y1
y2
y3
y4
y5

~
~
~
~
~

b*x1
b*x2
b*x3
b*x4
b*x5

The key to a FE model, as opposed to an RE model are our assumptions about
the relatedness of our covariate and the individual effects, i.e., E[xt α]. For a FE
model, we want to partial out any potential covariance between the independent
variable and the individual effects. This accounts for any linear relationship
between xt and the unit-specific characteristics influencing the dependent variable.
Further, allowing unrestricted covariances between the independent variable
itself over time will not affect how the coefficient β is estimated, but will have
an effect on the standard errors. To mimic the behaviour of a conventional FE
model, we allow the independent variable to be correlated with the individual
effects and itself over time. Covariances (including covariances between a variable
and itself, i.e., variances) are specified using the ~~ operator:
a ~~ x1 + x2 + x3 + x4 + x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
The last component of our code involves the variances of the residuals. This
component is optional, but we can constrain the residual variances to be equal
over time to again mimic the behaviour of a conventional FE model using POLS
on stacked data. Here, again, we use labels to make equality constraints. Because
yt is endogenous, the ~~ operator specifies the variances of residuals, i.e. t .

15

y1
y2
y3
y4
y5

5

~~
~~
~~
~~
~~

e*y1
e*y2
e*y3
e*y4
e*y5

A simulated example

To demonstrate the application of FE models in SEM, a dataset can be simulated
that embodies the FE assumptions. Again, the code for data simulation can be
found in the online supplementary materials.
To show that the latent individual effects variables represent the combined effect
of all time-invariant characteristics, the dependent variable will be influenced
by two separate unit-specific variables, which we can call α1 and α2 . We will
construct the simulated data such that the independent variable is correlated
with both of the time-invariant variables. This means that approaches that fail
to account for this confounding influence, such as pooled ordinary least squares
(POLS) or RE, will be biased.
The wide-format equations for the data generating process can be described as:

xt = α1 βxt ,α1 + α2 βxt ,α2 + δt ,
yt = xt βyt ,xt + α1 βyt ,α1 + α2 βyt ,α2 + εt
where, for the sake of simplicity, α1 , α2 , δt and εt are ∼ N (0, 1).
For the following example, a sample size of 1,000, observed over five waves, was
chosen. The unique variance of x, as well as both the individual-effect variables
is also ∼ N (0, 1). The coefficient of interest, βy,x is set to be equal to 0.3. A
correlation between x and the individual effects is induced through βx,α1 = 0.85
and βx,α1 = 0.50. With the variances above set to one, the covariances will
be roughly Cov(xt , α1 ) = 0.85 and Cov(xt , α2 ) = 0.5. The dependent variable
16

is also influenced by the individual effects variables with βyt ,α1 = 0.75 and
βyt ,α2 = 0.45 These values were chosen arbitrarily.
Now, we run the FE-SEM in lavaan.
fe_sem <- '
# Define individual effects variable
a =~ 1*y1 + 1*y2 + 1*y3 + 1*y4 + 1*y5
# Regressions, constrain coefficient to be equal over time
y1 ~ b*x1
y2 ~ b*x2
y3 ~ b*x3
y4 ~ b*x4
y5 ~ b*x5
# Allow unrestricted correlation between eta and covariates
a ~~ x1 + x2 + x3 + x4 + x5
x1 ~~ x2 + x3 + x4 + x5
x2 ~~ x3 + x4 + x5
x3 ~~ x4 + x5
x4 ~~ x5
# Constrain residual variances to be equal over time
y1 ~~ e*y1
y2 ~~ e*y2
y3 ~~ e*y3
y4 ~~ e*y4
y5 ~~ e*y5
'
fe_sem.fit <- sem(model = fe_sem,
data = dfw,
estimator = "ML")

We can get a summary of the model with summary(). The first portion of the
summary output gives an overview of some basic information and fit statistics.
The maximum likelihood estimator is the default, so it did not have to be
explicitly selected in the fitting function call. Other estimators are available,
including generalized and unweighted least squares (GLS and ULS, respectively),
robust standard errors maximum likelihood (MLM) and several others (see the
lavaan online tutorial for more).
This part of the summary output also tells us that the analysis is based on 1,000
observations (missings would be shown here as well if there were any), and that

17

the χ2 statistic is 30.138 based on 32 degrees of freedom (55 observed covariances
minus 1 error variance, 1 coefficient, 1 latent variable variance, 5 exogenous
variable variances and 15 covariances for 55 − 23 = 32 df). The p-value on the χ2
statistic is not significant with p = 0.561 which tells us the differences between
the model-implied and observed covariance matrices are likely due to chance, and
that the model fits the data well (given how the data was generated, it would
be surprising if this were not the case). Other fit measures including typical
comparative fit indices can be requested by either adding fit.measures = TRUE
as a secondary argument to the summary() call, or by asking for a complete
list of all available fit statistics using lavInspect(model, "fit") where model
stands for the name of the fitted model, in this case fe_sem.fit.
summary(fe_sem.fit)
## lavaan 0.6-6 ended normally after 37 iterations
##
##
Estimator
ML
##
Optimization method
NLMINB
##
Number of free parameters
31
##
Number of equality constraints
8
##
##
Number of observations
1000
##
## Model Test User Model:
##
##
Test statistic
30.138
##
Degrees of freedom
32
##
P-value (Chi-square)
0.561
##
## Parameter Estimates:
##
##
Standard errors
Standard
##
Information
Expected
##
Information saturated (h1) model
Structured
...
Next the summary output shows the measurement models for the latent variables,
if any. In this case the latent variable a for α is measured by each of the five
observed dependent variables with factor loadings fixed to 1.0.
...
18

## Latent Variables:
##
##
a =~
##
y1
##
y2
##
y3
##
y4
##
y5
...

Estimate

Std.Err

z-value

P(>|z|)

1.000
1.000
1.000
1.000
1.000

The regressions are shown next. Here, because we have constrained the regression
coefficients to be equal over time (the equality constraint label (b) is listed to
the left of the estimates), the estimate of β = 0.294 (0.016) is repeated five times.
The corresponding z- and p-values show that the coefficient is, unsurprisingly,
significant.
...
## Regressions:
##
##
y1 ~
##
x1
##
y2 ~
##
x2
##
y3 ~
##
x3
##
y4 ~
##
x4
##
y5 ~
##
x5
...

Estimate

Std.Err

z-value

P(>|z|)

(b)

0.294

0.016

18.809

0.000

(b)

0.294

0.016

18.809

0.000

(b)

0.294

0.016

18.809

0.000

(b)

0.294

0.016

18.809

0.000

(b)

0.294

0.016

18.809

0.000

Next, the covariance estimates are listed. First, the covariances between the
latent individual effects variable and the independent variable over time are
shown, and then the covariances between the independent variable with itself
over time.
One should always take care to double-check that there are no unintended covariances listed here. Like Mplus, the lavaan package estimates some covariances
per default, without the user explicitly having to add them to the model syntax.
For example, covariances between latent variables are estimated per default. If
one does not wish for them to covary, it must be explicitly stated, e.g., with f1

19

~~ 0*f2, assuming the latent variables are called f1 and f2, or by overriding the
default behaviour for the entire model by adding orthogonal = TRUE (which
sets the correlation between all latent variables to zero) to the fitting call.6
...
## Covariances:
##
##
a ~~
##
x1
##
x2
##
x3
##
x4
##
x5
##
x1 ~~
##
x2
##
x3
##
x4
##
x5
##
x2 ~~
##
x3
##
x4
##
x5
##
x3 ~~
##
x4
##
x5
##
x4 ~~
##
x5
...

Estimate

Std.Err

z-value

P(>|z|)

0.844
0.867
0.845
0.822
0.820

0.055
0.056
0.055
0.053
0.053

15.355
15.441
15.400
15.455
15.572

0.000
0.000
0.000
0.000
0.000

0.908
0.935
0.921
0.914

0.070
0.069
0.067
0.067

12.900
13.466
13.661
13.716

0.000
0.000
0.000
0.000

0.889
0.922
0.889

0.070
0.069
0.068

12.675
13.423
13.165

0.000
0.000
0.000

0.865
0.901

0.067
0.066

12.976
13.554

0.000
0.000

0.850

0.064

13.285

0.000

Finally, the variance estimates are listed. Here, we see that in order to mimic the
behaviour of a traditional FE model, the error variances over time were specified
to be equal using the equality constraint (e). Notice the . beside y1, y2, etc.:
this indicates that the listed variance refers to an endogenous variable, and that
it is thus an error variance. In this case, these refer to the variances of εt . After
that, the variances of the exogenous variables, both observed and unobserved
are listed.
...
## Variances:
##
##
.y1
##
.y2

(e)
(e)

Estimate
1.022
1.022

Std.Err
0.023
0.023

z-value
44.721
44.721

P(>|z|)
0.000
0.000

6 This is at least the current behaviour of both the cfa and sem wrappers. In fact, both
wrappers seem to be identical in terms of the default settings, see Rosseel et al. (2020).

20

##
##
##
##
##
##
##
##
##

6

.y3
.y4
.y5
x1
x2
x3
x4
x5
a

(e)
(e)
(e)

1.022
1.022
1.022
1.986
2.079
1.987
1.860
1.814
0.799

0.023
0.023
0.023
0.089
0.093
0.089
0.083
0.081
0.052

44.721
44.721
44.721
22.361
22.361
22.361
22.361
22.361
15.310

0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000

Conclusion

Fixed effects regression in SEM has been outlined in well-known articles by
(Allison 2011; Bollen and Brand 2010; Teachman et al. 2001). This article
provides a focused look at the implementation of the basic model, as well as
common extensions using the lavaan package in R.
The benefits of FE-SEM as opposed to traditional OLS-based FE-models are
largely the same ones that apply to the SEM framework in general: for one,
SEM allows for a great deal of flexibility. For example, it is easy to loosen
model constraints as necessary. Measurement error in both the dependent and
independent variables can be dealt with using latent variables to achieve unbiased
and more efficient results. Researchers interested in time-invariant predictors
can integrate them into a hybrid FE/RE model with ease. Further extensions,
like measurement invariance testing (Schoot, Lugtig, and Hox 2012; Millsap
2011; Steenkamp and Baumgartner 1998) as well as lagged dependent variables
(Bollen and Brand 2010; Allison, Williams, and Moral-Benito 2017) for example,
can also be implemented in a straightforward fashion.
The most basic FE-SEM is furthermore the basis for a variety of currently
popular extended models, such as Latent Curve Models in general (Curran
and Bollen 2001; Bollen and Curran 2004), as well as special implementations
like the Dynamic Panel Model (Allison, Williams, and Moral-Benito 2017), the
Random-Intercept Cross-Lagged Panel Model (Hamaker, Kuiper, and Grasman
2015) and the Latent Curve Model with Structured Residuals (Curran et al.
21

2014). For this reason it is all the more important for researchers to have a good
grasp on the method of applying FE-SEM. This article is meant to serve as a
consolidated resource for researchers looking for concrete advise on specifying
FE and more general panel models in SEM.

22

References
Allison, Paul. 2011. Fixed Effects Regression Models. Thousand Oaks: Sage
Publications.
Allison, Paul, Richard Williams, and Enrique Moral-Benito. 2017. “Maximum
Likelihood for Cross-Lagged Panel Models with Fixed Effects.” Socius 3: 1–17.
https://doi.org/10.1177/2378023117710578.
Bollen, Kenneth. 1989. Structural Equations with Latent Variables. New York,
Chichester: Wiley.
Bollen, Kenneth, and Jennie Brand. 2010. “A General Panel Model with
Random and Fixed Effects: A Structural Equations Approach.” Social Forces
89(1): 1–34.
Bollen, Kenneth, and Patrick Curran. 2004. “Autoregressive Latent Trajectory
(ALT) Models: A Synthesis of Two Traditions.” Sociological Methods and
Research 32(3): 336–83. https://doi.org/10.1177/0049124103260222.
Brüderl, Josef, and Volker Ludwig. 2015. “Fixed-Effects Panel Regression.”
In The Sage Handbook of Regression Analysis and Causal Inference, edited
by Henning Best and Christof Wolf, 327–57. London, Thousand Oaks: Sage
Publications.
Curran, Patrick, and Daniel Bauer. 2011. “The Disaggregation of Within-Person
and Between-Person Effects in Longitudinal Models of Change.” Annual Review
of Psychology 62: 583–619.
Curran, Patrick, and Kenneth Bollen. 2001. “The Best of Both Worlds: Combining Autoregressive and Latent Curve Models.” In New Methods for the Analysis
of Change, edited by L. Collins and A. Sayer, 107–35. Washington, DC: American
Psychological Press. https://doi.org/%20doi:10.1037/10409-004.
Curran, Patrick, Andrea Howard, Sierra Bainter, Stephanie Lane, and James
McGinley. 2014. “The Separation of Between-Person and Within-Person Com-

23

ponents of Individual Change over Time: A Latent Growth Curve Model with
Structured Residuals.” Journal of Consulting and Clinical Psychology 82(5):
879–94. https://doi.org/10.1037/a0035297.
Graff, J. 1979. “Verallgemeinertes LISREL-Modell.” Mannheim, Germany.
Hamaker, Ellen, Rebecca Kuiper, and Raoul Grasman. 2015. “A Critique of
the Cross-Lagged Panel Model.” Psychological Methods 20(1): 102–16. https:
//doi.org/10.1037/a0038889.
Kline, Rex. 2016. Principles and Practice of Structural Equation Modeling.
Fourth Edition. New York: The Guilford Press.
Millsap, Roger. 2011. Statistical Approaches to Measurement Invariance. New
York, London: Routledge.
Muthén, Linda, and Bengt Muthén. n.d. Mplus User’s Guide. Eighth Edition.
Los Angeles, California: Muthén & Muthén.
R Core Team. 2017. R: A Language and Environment for Statistical Computing.
Vienna, Austria: R Foundation for Statistical Computing. https://www.Rproject.org/.
Rosseel, Yves. 2012. “lavaan: An R Package for Structural Equation Modeling.”
Journal of Statistical Software 48 (2): 1–36. http://www.jstatsoft.org/v48/i02/.
Rosseel, Yves, Terrence D. Jorgensen, Daniel Oberski, Jarrett Byrnes, Leonard
Vanbrabant, Victoria Savalei, Ed Merkle, et al. 2020. Lavaan: Latent Variable
Analysis. https://CRAN.R-project.org/package=lavaan.
Schmidheiny, Kurt. 2019. “Panel Data: Fixed and Random Effects.” Unversität
Basel.
Schoot, Rens van de, Peter Lugtig, and Joop Hox. 2012. “A Checklist for Testing
Measurement Invariance.” European Journal of Developmental Psychology 9(4):
486–92.
Skrondal, Anders, and Sophia Rabe-Hesketh. 2004. Generalized Latent Variable
24

Modeling. Boca Raton, London, New York, Washington, D.C.: Chapman &
Hall/CRC.
Steenkamp, Jan-Benedict, and Hans Baumgartner. 1998. “Assessing Measurement Invariance in Cross-National Consumer Research.” Journal of Consumer
Research 25(1): 78–90.
Teachman, Jay, Greg Duncan, Jean Yeung, and Dan Levy. 2001. “Covariance
Structure Models for Fixed and Random Effects.” Sociological Methods and
Research 30(2): 271–88.
Wooldridge, Jeffery. 2002. Econometric Analysis of Cross Sectional and Panel
Data. Cambridge, Massachusetts: The MIT Press.
———. 2012. Introductory Econometrics: A Modern Approach, 5th Edition.
Mason, Ohio: Thomson South-Western.

25

