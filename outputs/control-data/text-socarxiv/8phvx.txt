Bias from network misspecification under spatial dependence⇤
Timm Betz †

Scott J. Cook‡

Florian M. Hollenbach§

Abstract
The pre-specification of the network is one of the biggest hurdles for applied researchers in undertaking spatial analysis. In this letter, we demonstrate two results. First, we derive bounds for
the bias in non-spatial models with omitted spatially-lagged predictors or outcomes. These bias
expressions can be obtained without prior knowledge of the network, and are more informative
than familiar omitted variable bias formulas. Second, we derive bounds for the bias in spatial
econometric models with non-differential error in the specification of the weights matrix. Under these conditions, we demonstrate that an omitted spatial input is the limit condition of
including a misspecificed spatial weights matrix. Simulated experiments further demonstrate
that spatial models with a misspecified weights matrix weakly dominate non-spatial models.
Our results imply that, where cross-sectional dependence is presumed, researchers should pursue spatial analysis even with limited information on network ties.
Key Words: spatial dependence, bounds, omitted variables, measurement error

Conditionally Accepted at Political Analysis

An earlier version of this paper benefited from feedback at the 2017 Annual Meeting for the Society of Political
Methodology. We particularly thank Andrew Bridy, three anonymous reviewers, and the editor for their useful advice.
All remaining errors are ours alone. Authors are listed in alphabetical order, equal authorship is implied. For further
questions contact Scott J. Cook. Portions of this research were conducted with high performance research computing
resources provided by Texas A&M University (http://hprc.tamu.edu). The replication materials for this paper
can be found at Hollenbach, Betz and Cook (2019).
†
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: timm.betz@tamu.edu, URL: www.people.tamu.edu/˜timm.betz
‡
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: sjcook@tamu.edu, URL: scottjcook.net
§
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: fhollenbach@tamu.edu, URL: fhollenbach.org
⇤

Across the social sciences, theories involve cross-unit interactions resulting from spillovers in
predictors (e.g., externalities) or outcomes (e.g., interdependence). Where researchers are explicitly interested in cross-unit relationships, spatial econometric models are widely used (Anselin,
1988; Franzese and Hays, 2007). Even if researchers are otherwise uninterested in these relationships, however, accounting for spatial dependence is often necessary to recover unbiased estimates.
With a variety of spatial models to select from and widely-available software routines, estimating spatial models is easier than ever. Yet, one prerequisite for spatial analysis continues to
frustrate applied researchers: the specification of the spatial weights matrix. Specifying the spatial weights matrix requires additional theories and data for cross-unit relations (Neumayer and
Plümper, 2016). Researchers, however, often lack theory-backed information to motivate this
choice (Corrado and Fingleton, 2012). As a result, any spatial weights matrix can be contested and
the value of the resulting estimates disputed. This may lead researchers away from spatial econometric models and toward models that ignore spatial relationships – especially when understanding
spatial relationships is not the primary concern.
In this note, we consider the consequences from ignoring spatial interactions outright and from
introducing them with error in the weights matrix. We first derive bounds for the bias from ignoring spatial dependence. Exploiting several features unique to spatial relationships, we obtain
bounds that are more informative than common expressions for omitted variables bias. We then
demonstrate that omitting spatial terms produces worse results than estimation based on a misspecified network under non-differential error. As such, we argue that researchers should prefer spatial
models, even when they possess limited knowledge of the network.

1

Confounding from omitted spatial dependence

We consider two spatial processes: spillovers of predictors across units, in the form of a spatial
lag of X (SLX) model; 2) outcome interdependence between units, in the form of a spatial autoregressive (SAR) model.

1

Consider a SLX data-generating process:

y = ↵ + x + Wx✓ + ✏,

(1)

where y, x, and ✏ are N -length vectors of the outcome, predictor, and error term, respectively.
W is an N -by-N spatial weights matrix specifying network ties between units. We make usual
assumptions about W: it has zeroes along the diagonal, non-negative elements, and is normalized
using row-standardization or min-max normalization. Interest is in estimating the coefficient .
Omitting Wx results in standard omitted variables bias:

plimn!1 ˆOLS

=✓

cov(Wx, x)
.
var(x)

(2)

Our goal is to identify, for given sample realizations of W and x, more informative bounds for the
bias than expression (2).1 Usually, the omitted variable bias formula does not offer much leverage,
because the covariances involving the omitted terms are unknown. When the omitted variable is a
spatial lag of a predictor, however, we have more information, because Wx is a linear combination
of the values of x. Consequently, knowledge of x is sufficient to produce empirical bounds.
Specifically, for a large class of common weights matrices,2
cov(Wx, x)
 1.
var(x)

(3)

Under these conditions, the upper bound of the bias in equation (2) is ✓. In many contexts, ownunit values of a predictor can be reasonably assumed to have a larger effect than other-unit values,
1

The standard errors are also biased (Franzese and Hays, 2007). A similar approach to ours may extend to the
variance-covariance matrix, which we leave to future work.
2
We provide full results in the Appendix. For intuition, note that W often induces averaging of the values of the
original vector x, thereby reducing the variance. A sufficient condition for inequality (3) to hold is that Moran’s I
in the sample is bounded by [ 1, 1], which generally holds except “for an irregular pattern” (Cliff and Ord, 1981).
We demonstrate that this inequality holds for any symmetric weights matrix; for any spectral weights matrix; and for
any doubly-stochastic weights matrix. This includes all matrices based on the attributes of undirected dyads, such
as inverse distance, bilateral flows, threshold models, and contiguity. For arbitrary combinations of W and x the
inequality may no longer hold. We derive worst-case bounds for arbitrary W that can be calculated from the sample,
and show that inequality (3) holds for any arbitrary weights matrix when x is binary.

2

such that | |

|✓|. This implies that the maximum asymptotic bias is .3

Thus, for any given sample,

provides an upper bound on the bias in ˆOLS , and, asymptoti-

cally, ˆOLS is in the interval [0, 2 ]. Except for randomness, therefore, we should not observe sign
switches as a consequence of omitting Wx. Moreover, given a potentially biased estimate ˆOLS ,
we can estimate the lower bound of

as

ˆOLS
.
2

This lower bound shifts closer toward ˆOLS as the

magnitude of spillovers decreases, allowing for assessment of the sensitivity of substantive effects.
As an illustrative example, consider economic voting: how do economic conditions shape voting behavior? In addition to local GDP growth, growth in neighboring units can matter for evaluations of incumbents through benchmarking effects (Kayser and Peress, 2012). Arel-Bundock,
Blais and Dassonneville (2019) demonstrate that many of these theories translate into SLX models: ✓, the coefficient on Wx, captures benchmarking effects;

, the coefficient on x, captures

conventional economic voting.
It is difficult to imagine a scenario under which growth in neighboring countries has a larger
effect on vote choices than domestic growth, so | |

|✓| seems reasonable. We estimate three

models using the Kayser and Peress (2012) data, assuming that their network specification captures
the true W: 1) incumbent vote share regressed on growth (x), plus controls, 2) incumbent vote
share regressed on growth (x) and trade-weighted global growth (Wx), plus controls; 3) tradeweighted global growth regressed on growth, plus controls. The first model yields a potentially
biased estimate ˆ (0.530), the second model yields estimates for

(0.577) and ✓ (-0.173) that we

treat as ‘true’, and the third model yields an estimate (0.270) of Cov(x, Wx)/Var(x).
This demonstrates that the main conditions necessary for our bound are plausible (and conservative) in real-world data: |✓| = 0.173 < | | = 0.577, and Cov(x, Wx)/Var(x) = 0.270  1.
Additionally, the lower bound on

estimated from the biased ˆ – i.e.,

ˆ
2

=

0.530
2

= 0.265 – holds

because the bias, in this case, was attenuating. However, this lower bound also holds for alternative
W’s that we have not considered. That is, we do not need to assume that trade is the appropriate
link when making cross-country economic evaluations.
3

The plausibility of | | |✓| depends on the specific application. We believe it is defensible in most contexts our
note addresses: researchers consider spatial effects a nuisance and have little prior information about W.

3

Similar results follow for the SAR data-generating process,
(4)

y = ↵ + x + ⇢Wy + ✏.
Omitting the spatial lag of the outcome (Wy) induces bias
plimn!1 ˆOLS

=⇢

cov(Wy, x)
.
var(x)

(5)

Using condition (3) and the derivation detailed in Betz, Cook and Hollenbach (2019), this expression can be rewritten as
plimn!1 ˆOLS



⇢
1

⇢

,

(6)

with ˆOLS in [0, 1).4
These results have several implications. First, asymptotically, an omitted spatial lag of the
outcome cannot produce a sign reversal on the estimated coefficient. Moreover, the bias is proportional to , the true effect.
Second, our assumptions have been purposefully weak. Restricting the domain of ⇢ yields
tighter bounds. For example, with ⇢ < 0.5 – which still implies strong spatial interdependence
– the bounds on

OLS

are identical to those derived earlier, [0, 2 ]. Additionally, expression (6)

allows for a simple form of sensitivity analysis by determining permissible values of ⇢ for a desired
lower bound on , or to graph the lower bound of

given ⇢.

Finally, the bias can again be expressed with data on hand. As we demonstrate in the Appendix,
empirical bounds can be calculated from the sample data for arbitrary W, which will be tighter
than implied by (6) because they yield a finite upper bound on cov(Wy, x).
4

in the SAR model reflects the pre-spatial (i.e., partial equillibrium) effect of xi on yi . Total effects also involve
spatial spillovers and feedback (LeSage and Pace, 2009). The quantity we consider is similar to that obtained by spatial
filtering.

4

2

Bias from a misspecified network

Omitting relevant spatial inputs induces bias, yet we can still infer substantively relevant information from such results. Modeling these spatial terms explicitly promises greater gains. To do
so, researchers must pre-supply the weights matrix. In applied work, researchers often fear that
they do not have sufficient information to accurately specify W, which may cause them to forgo
modeling spatial terms at all. Returning to the example of economic voting, Arel-Bundock, Blais
and Dassonneville (2019) note that the existing literature provides no theoretically grounded argument for a specific choice of W. Perhaps as a consequence, few studies of conventional economic
voting account for benchmarking effects.
Given the centrality of the specification of W, these concerns have received considerable attention (Corrado and Fingleton, 2012; Neumayer and Plümper, 2016). Researchers have suggested
that uncertainty over competing W’s can be assessed using information criteria (Halleck Vega and
Elhorst, 2015), modeled using Bayesian model averaging (Juhl, N.d.), and may be less essential
than presumed because of the high degree of correlation among different W’s (LeSage and Pace,
2014). We demonstrate that spatial models with misspecified weights matrices weakly dominate
non-spatial models under random measurement error of the weights matrix.
f
First, consider a SLX process. Suppose instead of W we possess a noisy W,
f = Wx + e,
Wx

(7)

where Wx ? e, indicating that the spatial lag suffers from classical, non-differential measurement
error. Estimating a SLX model yields
plimn!1 ✓ˆSLX = ✓
where

2
Wx|x

2
Wx|x
2
Wx|x

+

2
e

=✓ ,

is the residual variance of regressing Wx on x, and

(Carroll et al., 2006). Because

(8)

is the bivariate reliability ratio

is bounded on the unit interval, equation (8) indicates the usual

5

attenuation bias.
The corresponding bias in the estimate of
plimn!1 ˆSLX

is

= ✓(1

)

cov(Wx, x)
.
var(x)

(9)

This expressions corresponds to the omitted variables bias in equation (2) weighted by (1- ). Thus,
the bias in equation (9) can be no greater than the bias in equation (2). Omitting a spatial predictor
provides the limit condition of including a spatial predictor with a misspecificed weights matrix.
Because ˆSLX is less biased than ˆOLS , the implied lower bound on

is also more informative.

For the SAR model, estimation is more complicated: the simultaneity of y and Wy necessitates
maximum likelihood or instrumental variable (IV) methods (Anselin, 1988). While IV strategies
typically offer relief from measurement error, this is not the case for spatial models where the
instruments are spatially-lagged realizations of the predictors. Because these are generated using
the same weights matrix as the outcome, they inherit – and are correlated with – the measurement
error. Thus, misspecifying the weights matrix results in asymptotically biased estimates (see the
Appendix).
To derive the bias expression in the SAR model, we consider a just identified IV model where
f is used as an instrument for Wy.
f Analogously to the SLX model, the IV estimation produces
Wx
plimn!1 ˆIV

= ⇢(1

)

cov(Wy, x)
.
var(x)

(10)

As before, the bias in equation (10) can be no greater than the bias in equation (6). Consequently, a
misspecified weights matrix induces bias in the estimation, but improves over the omitted variable
bias from ignoring spatial interdependence.
This should encourage researchers to consider spatial models even where knowledge of the
unit ties is imperfect. Not only do spatial estimators of

weakly dominate those from non-spatial

models, but researchers also obtain sample estimates of ✓ or ⇢. This allows calculating post-spatial
and total effects of x (Franzese and Hays, 2007; LeSage and Pace, 2009), yielding a more complete
6

understanding of the relationship of interest.

3

Simulation

The following simulations demonstrate the small sample performance of spatial models when W
is misspecified. We focus on the SAR model, which is the most widely used spatial model in
applied research.5 We generate data where both y and x are governed by SAR processes:

y = (I

⇢y W) 1 [↵ + x + ✏],

(11a)

x = (I

⇢x W) 1 u,

(11b)

where u and ✏ are N -length vectors with elements drawn from N (0, 1).

reflects the direct (i.e.,

pre-spatial) effect of x on y, while ⇢y and ⇢x determine the strength of the spatial autocorrelation
in y and x.6
We hold W and u fixed across simulations. Locations for observations are determined by
drawing vertical and horizontal coordinates from U (0, 5). Based on these coordinates, we generate
a binary 10-nearest-neighbor W matrix. We fix

at 2 and the number of observations to 150 across

experiments, focusing on variation in the spatial autoregressive parameters ⇢x and ⇢y , which we
vary between 0 (i.e., no spatial interdependence), 0.3, and 0.6 (i.e., high spatial interdependence).
For each of these 9 experimental settings, we simulate 2, 000 data sets.
f used in the estimation, we generate a second conTo induce misspecification in the matrix W

nectivity matrix (M) based on a new random draw of locations. M is therefore independent of the
true W used in the data-generating process. We then generate the set of connectivity matrices used

f as a mixture of the true (W) and false (M) matrices. Specifically, the
in the model estimation (W)
5

In the Appendix, we present results for a SLX model.
It is not necessary that the spatial dependence in x is generated via a spatial autoregressive process. Any alternative
which produces spatial correlation in x (along W) would induce the types of biases we consider.
6

7

elements w
ei,j are determined as
w
ei,j =

8
>
>
<wi,j ,

>
>
:mi,j ,

if d = 0 where d ⇠ Bern(p)
otherwise

where p is the probability of misclassification, which we increase from 0 (no error) to 1 (all error)
in increments of 0.05. In total, this produces 21 connectivity matrices used in estimation, which
are all normalized using min-max normalization.7
Using the simulated data for y and x, we estimate a non-spatial linear model (via OLS) and
f of varying accuracy (decreasing in p, the probability of misspecSAR models (via ML) using W’s
ification). For each model, we record ˆ to assess performance. Figure 1 shows the results for the
simulations of the SAR process based on 10-nearest neighbors and min-max normalization. Each
cell presents the results for one combination of ⇢x and ⇢y ; ⇢x increases from 0 to 0.6 going from
left to right, ⇢y increases moving from top to bottom. In each, we plot the densities of coefficient
estimates at different levels of the misspecification probability p. Darker shading indicates higher
levels of misspecification. The densities of ˆ’s for non-spatial models are plotted in black. The
bias in both the non-spatial models and misspecified spatial models increases in ⇢y and ⇢x , being
largest in the bottom right cell.
f increases, the bias in
The results underscore three points. First, as the misspecification of W

ˆ increases. Yet even with high interdependence and mismeasured (or omitted) W, the observed

bias is much smaller than the bounds derived above. Second, the SAR model weakly dominates
f does no worse than omitthe non-spatial model. Even a SAR model estimated with a random W
ting the spatial term. Finally, the simulation results confirm our analytical results. For example,

inequality (6) implies a maximum bias of 3. The bias in the simulations clearly maintains that
bound. Moreover, with ⇢y = ⇢x = 0.6, on average we obtain

cov(Wy,x)
var(x)

= 1.45. Equation (5) thus

implies an OLS estimate of 2.87, identical to the average OLS estimate in the simulations. Tables
C.1 and C.2 in the Appendix report these quantities for all simulation scenarios.
7

In the Appendix we provide results for row-normalization.

8

ρx = 0

ρx = 0.3

ρx = 0.6

ρ

y

=

0

4

2

0

3

4
ρ

y

=

0.

Density
2

0

Misspecification
Probability
1
0.75
0.5
0.25
0

ρ

y

=

0.
6

4

2

0
1.0

1.5

2.0

2.5

3.0

3.5 1.0

1.5

2.0

2.5

3.0

3.5 1.0

Coefficient Estimates

1.5

2.0

2.5

3.0

3.5

Figure 1: Coefficients with misspecification of W in SAR models based on 10-nearest-neighbors
with min-max normalization (colored) and OLS model omitting spatial lag (black).

4

Conclusion

Researchers frequently suspect spatial dependence in their data, but lack knowledge of the precise
network. Fearing that selecting the wrong network may open them to criticism, researchers may
forgo spatial models altogether. Here we have demonstrated the potential biases introduced from
omitting spatial terms outright versus including them with error. Our results should encourage
the estimation of spatial models even if researchers have imperfect information. As researchers
in these settings likely lack strong theory-based specifications, we point to Griffith’s five rules of
thumb for specifying weights matrices (Griffith, 1996).
We emphasize that our results do not hold under differential measurement error. We suspect
that differential measurement error is most likely for network ties that violate the exogeneity assumption for spatial weights – implying that traditional spatial econometric models would be inappropriate. However, we hope that future work extends our results to other contexts and more
9

complex forms of measurement error. Several of the features identified here may be useful in these
efforts. First, prior research focuses on misspecification in the weights matrix, yet errors manifest
in the empirical model as vectors. Second, restrictions on x – such as limiting the analysis to
binary x – imply restrictions on Wx. Finally, row and min-max normalization imply bounds for
the vector range and vector sum. Recognizing these attributes could be of potential use in new
analytical and empirical approaches in future research.

References
Anselin, L. 1988. Spatial Econometrics: Methods and Models. Vol. 4 Springer Science & Business
Media.
Arel-Bundock, Vincent, Andre Blais and Ruth Dassonneville. 2019. “Do Voters Benchmark
Economic Performance?” British Journal of Political Science. Advance online publication.
doi:10.1017/S0007123418000236.
Betz, Timm, Scott J. Cook and Florian M. Hollenbach. 2019. “Spatial interdependence and instrumental variable models.” Political Science Research and Methods. Advance online publication.
doi:10.1017/psrm.2018.61.
Carroll, Raymond J, David Ruppert, Leonard A Stefanski and Ciprian M Crainiceanu. 2006. Measurement error in nonlinear models: a modern perspective. Chapman and Hall/CRC.
Cliff, Andrew David and JK Ord. 1981. Spatial Processes Models and Applications. Pion Ltd.
Corrado, Luisa and Bernard Fingleton. 2012. “Where is the economics in spatial econometrics?”
Journal of Regional Science 52(2):210–239.
Franzese, Robert J. Jr. and Jude C. Hays. 2007. “Models of Cross-Sectional Interdependence in
Political Science Panel and Time-Series-Cross-Section Data.” Political Analysis 15(2):140–164.
Griffith, Daniel A. 1996. Some guidelines for specifying the geographic weights matrix contained
in spatial statistical models. In Practical handbook of spatial statistics, ed. Sandra L. Arlinghaus.
Boca Raton, FL: CRC press pp. 65–82.
Halleck Vega, Solmaria and J Paul Elhorst. 2015. “The SLX model.” Journal of Regional Science
55(3):339–363.
Hollenbach, Florian M., Timm Betz and Scott J. Cook. 2019. Replication Data for: Bias due to
network misspecification under spatial dependence. Harvard Dataverse.
URL: https://doi.org/10.7910/DVN/UBNPPI
Juhl, Sebastian. N.d. “The Sensitivity of Spatial Regression Models to Network Misspecification.”
Political Analysis. Forthcoming.
10

Kayser, Mark Andreas and Michael Peress. 2012. “Benchmarking across Borders: Electoral Accountability and the Necessity of Comparison.” American Political Science Review 106(3):661–
684.
LeSage, James and R Pace. 2014. “The biggest myth in spatial econometrics.” Econometrics
2(4):217–249.
LeSage, James and Robert Kelley Pace. 2009. Introduction to spatial econometrics. Chapman and
Hall/CRC.
Neumayer, Eric and Thomas Plümper. 2016.
4(1):175–193.

“W.” Political Science Research and Methods

11

Online Appendix:
Bias due to network misspecification under spatial dependence
Timm Betz ⇤

Scott J. Cook†

Florian M. Hollenbach‡

⇤
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: timm.betz@tamu.edu, URL: www.people.tamu.edu/˜timm.betz
†
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: sjcook@tamu.edu, URL: scottjcook.net
‡
Assistant Professor of Political Science, Department of Political Science, Texas A&M University, College Station,
TX 77843. Email: fhollenbach@tamu.edu, URL: fhollenbach.org

Appendix A Deriving the Bounds of the Bias in Non-Spatial Models
In the following we derive the bounds given in Betz, Cook, Hollenbach (n.d.). In keeping with the
literature, we assume the weights matrix is a fixed, hollow matrix (no self ties) with exogenously
determined non-negative elements. We consider both symmetric and asymmetric spatial weights
matrices W that have been row standardized or scalar normalized using min-max normalization.
To ease notation, we assume that x has mean zero. In detailing our derivation, it is more convenient
to re-express the bias expression from the SLX model from the manuscript (equation 2) as1
(x0 x) 1 x0 Wx  1.

(1)

For those familiar with spatial models, the parallel to Moran’s I will be obvious, as it is the same
ratio used in that measure. There are three virtues of this parallel for our purposes. First, for
non-technical readers, it allows us to simplify our bounding condition as being satisfied whenever
Moran’s I produces values between -1 and 1, which is generally the case (Cliff and Ord, 1981).2
Second, in our technical derivation, we are able to borrow from the literature on Moran’s I in detailing the regularity conditions (i.e., assumptions) necessary for this inequality to obtain. Finally,
when this condition is not satisfied, it typically also implies that the process is not stationary, meaning the straight-forward application of spatial econometric methods would be ill-advised without
additional transformations of the data.
To identify the conditions for inequality (1) to hold, it is useful to distinguish between symmetric and non-symmetric W matrices. We first show that the condition holds for any arbitrary
symmetric W, and then detail sufficient conditions under which it holds for non-symmetric W.
1

We focus on the case where x0 Wx is positive, but the same conditions which ensure inequality (1) to hold also
ensure that (x0 x) 1 x0 Wx
1.
2
Moran’s I includes a scaling factor as well, which is the sample size N divided by the sum of all elements of W.
After row or min-max normalization, this ratio is always larger than one. The sum of all elements of W is equal to
the sum of all row sums as well as to the sum of all column sums. With row-normalization, this sum is identical to N ;
with min-max normalization, it is at most N .

1

Symmetric W
Our derivation uses that, for any non-zero vector x, the expression (x0 x) 1 x0 Wx takes on values
within the field of values (or the numerical range) of the matrix W. For symmetric W, the numerical range is on the real line, with endpoints determined by the largest and the smallest eigenvalues
of W. De Jong, Sprenger and Van Veen (1984), for example, use this feature when showing that
for symmetric W, (x0 x) 1 x0 Wx lies within the smallest and largest eigenvalue of W. Therefore, applying any familiar normalization strategy (row standardization, min-max, spectral) to a
symmetric weights matrix (including common constructions based on contiguity, inverse distance,
block group, common border length, fixed buffer) ensures that condition (1) holds, since the maximum eigenvalue of the normalized matrix is 1 (this is also the largest eigenvalue in absolute terms,
that is, no eigenvalue is smaller than -1; and note that for real symmetric matrices, no eigenvalues
are complex).
Using a different approach, we prove this independently by right multiplying and subtracting
both sides by x0 x. Re-arranging terms this can now be written as:
x0 (W

(2)

I)x  0,

where I is an identity matrix of size N . This expression is now in the more-familiar quadratic form
– i.e., x0 Ax, where x is a vector and A = (W

I) is a symmetric matrix – allowing us to exploit

well-known results.
By definition, the expression in (2) is satisfied whenever A is negative semi-definite. As such,
we need only demonstrate the conditions under which A = W

I is negative semi-definite to

prove (1). One way to prove that A is negative semi-definite is to show that all eigenvalues of A are
non-positive or, equivalently, that the largest eigenvalues of W is at most one. From Gershgorin’s
circle theorem, this condition holds for all W that have been normalized using min-max or rownormalization.3 To see why, note that Gershgorin’s circle theorem implies that all eigenvalues
3

one.

of

Note that this is true trivially for spectral normalization, which normalizes W to ensure its largest eigenvalue is

2

W are located in discs with origin wii , such that:

|

wii | 

X
j6=i

(3)

|wij |.

Since wii = 0 for all i and the off-diagonal elements are non-negative, this is equivalent to

| |

X

wij ,

(4)

i

which implies that the absolute value of the largest eigenvalue of W is bounded by the largest
row-sum. Moreover, because eigenvalues are identical for the transpose of a matrix, Gershgorin’s
circle theorem implies that all eigenvalues must also be bounded by the largest column-sum. The
minimum of the largest row-sum and the largest column-sum therefore provides a bound on the
P
P
largest eigenvalue of W. More simply, note that for symmetric matrices, j6=i wij = i6=j wij ,
such that row- and column-sums are identical. For min-max normalization it follows that the

largest eigenvalue is bounded by one.4 Similarly, for row-normalization, the largest eigenvalue
is one, because all row-sums are equal to one (Ord, 1975). This proves that condition (1) holds
for any symmetric W. Note that inequality (4) also rules out eigenvalues smaller than

1, which

ensures that the bound in condition (1) also holds when covariance between Wx and x is negative.
Before proceeding, we note that symmetric spatial weights matrices are frequently suggested
from theoretical models, and commonly used in applied work. They include any matrix that is
based on (undirected) attributes of pairs of observations, such as contiguity matrices, inverse distance matrices, matrices based on bilateral trade flows, and matrices based on distance thresholds.
Non-symmetric W
Extending this approach directly to non-symmetric matrices (as found in network-based ties)
proves more challenging. Above we used the fact that negative semi-definite matrices always
⇥
0⇤
satisfy (1). For non-symmetric matrices B, the quadratic form is instead given by x0 B+B
x,
2
4

Alternatively, note that because the largest eigenvalue is bounded by the minimum of the largest row-sum and
largest column-sum, spectral normalization ensures a smaller normalization factor than min-max normalization.

3

such that our condition becomes

x

0



W + W0
2

(5)

I x  0.

As before, the goal is to identify which W satisfy this condition. Above, the corresponding condition (4) held anytime the row sums or column sums of the non-diagonal elements were one or less,
which was guaranteed by min-max and row-normalization. Relying again on Gershgorin’s circle
theorem, the non-symmetric case instead requires that, for all eigenvalues

| |

P

j6=i

wij +
2

P

i6=j

wij

 1.

of

W+W0
,
2

(6)

That is, the non-symmetric case requires that the sum of the row and column sums needs to be less
than 2 for each unit or that the largest eigenvalue of

W+W0
2

is bounded by one. Note that, for non-

symmetric matrices, it is not the case that the eigenvalues of the sum of matrices are identical to
the sum of the eigenvalues. Condition (6) therefore does not hold in general after normalization of
W. However, it is satisfied in many cases, and in particular for common spatial weights matrices.
First, the above condition holds for all matrices that are doubly-stochastic, such that a unit’s
column sum equals its row sum, with elements adding up to one. These matrices need not be symmetric, but they ensure that the largest eigenvalue of

W+W0
2

is bounded by one, which in turn guar-

antees that our condition holds. Doubly-stochastic matrices comprise a large number of weights
matrices and are commonly used in theoretical work on the properties of spatial econometric estimators. They imply that each element of Wx is a weighted average of x, where each x has the
same total influence on the network (note that this influence can be distributed arbitrarily across
units). Among others, and in addition to all symmetric variants of doubly-stochastic matrices
(including inverse distance and contiguity matrices), this applies to many potentially asymmetric
weights matrices based on nearest neighbors (LeSage and Pace, 2014). Indeed, the class of matrices that satisfy our bounds is more general than this and includes all line-sum symmetric matrices,
such that the sum of elements in each row equals the sum of elements in each column (but row
4

sums need not be identical to each other).
Second, a set of possibly asymmetric matrices that satisfies the above conditions are spectral
matrices. Min-max, row, and spectral normalization all ensure that the largest eigenvalue of W is
at most one; this holds for arbitrary W. For spectral matrices, the largest eigenvalue is identical
to the numerical radius, and normalization thus ensures that x0 Wx  x0 x. Spectral matrices
include all symmetric matrices (providing another approach to prove the above result for symmetric
matrices), but they also include a large class of asymmetric matrices (for a characterization, see,
e.g., Goldberg and Zwas 1975).
Third, note that for scalar normalizations, condition (6) always holds if we normalize by the
maximum row or column sum – that is, the max-max. While not common to the literature, Kelejian and Prucha (2010) emphasize that any matrix norm ||W|| – e.g., the maximum eigenvalue,
the maximum absolute row sum, the maximum absolute column sum, etc. – serves as a useful
normalization factor since it bounds the spectral radius. The choice between different norms is
theoretically arbitrary, since each is proportionally equivalent.
Fourth, a vast literature addresses the distribution of Moran’s I. Cliff and Ord (1981) demonstrate that generally “the upper bound for |I| will be less than unity, although it could exceed unity
for an irregular pattern of weights if [observations] with extreme values of zi are heavily weighted.”
Put differently, to obtain bounds of Moran’s I larger than one in absolute value requires not only
an unusual composition of W, but that unusual W must also coincide in predictable ways with the
structure of x. In deriving the feasible range for Moran’s I for tessellations, Boots and Tiefelsdorf
(2000) have shown this rarely occurs. This is because the combinations of a matrix W and predictor x are so atypical that they are unlikely to hold in reasonable observational settings. Conversely,
if W is sufficiently dense, these atypical cases cannot arise, because W effectively averages over
xi .
Importantly, if Moran’s I is bounded by one – and we are outside the realm of ‘irregular’ cases

5

– our condition always holds. To see why, note that Moran’s I is defined as
I=

N cov(Wx, x)
,
S
var(x)

(7)

where N is the sample size N as before and S is the sum of all elements of W. For rownormalization and min-max normalization, S  N because both normalizations ensure that either
each row-sum or each column sum is at most one. Because the sum of all elements of W is at most
the sum of all row-sums or the sum of all column sums, it follows that S  N . It follows that if
Moran’s I is bounded by 1 that

cov(Wx,x)
var(x)

 1 must hold as well. In other words, the matrices that

spatial econometric models typically envision ensure that our bounds hold.
Finally, and building on this notion of extreme and unusual cases, we can establish bounds for
these outlier scenarios. Because these outlier scenarios depend on the specific realizations of x,
we can calculate a bound based on the sample. Observe that the worst case for our bounds is a
scenario that creates the largest possible value for cov(Wx, x). With the mean of x being zero,
P
PN
this expression is identical to N1 N
i=1 xi
j=1 wij xj and is maximized if the most extreme values
P
of xi are paired with the largest values that can be produced by N
j=1 wij xj .

First consider a row-normalized W or W such that min-max normalization results in row-

sums that are at most one. Note that in both cases, W preserves the range of x. Then, cov(Wx, x)
takes its maximum value if W is such that each observation is exclusively connected to one of
the two most extreme cases realized in the sample – i.e., max{xi } and min{xi }. This corresponds
to a weights matrix that has almost all zero elements. We emphasize that these matrices present
extreme forms of asymmetry (in particular, after normalization, the largest row-sum is one while
the the largest column sum is N

1), violate standard assumptions about W (e.g., those presented

in Anselin (1988)), and also represent a network with almost no interdependence: the two largest
observations on x determine the values of Wx of all other observations in the sample, with no
observation being exposed to more than one observation, and no path of any length that connects
the two most extreme observations.

6

To obtain a bound for cov(Wx, x), sort x such that x1
that for i  k, xi

x2

x3 . . .

xN . Then, let k such

0 and for i > k, xi < 0. Then we have that
" N
#
N
X
1 X
cov(Wx, x) =
xi
wij xj
N i=1
j=1

(8)

k
N
1 X
1 X

xi x1 +
xi xN ,
N i=1
N i=k+1

(9)

which can be calculated in any given sample as an upper bound on cov(Wx, x). Note that
Pk
PN
PN
i=1 xi =
i=k+1 xi because
i=1 xi = 0 (which implies that the largest positive covariance is identical to the largest negative covariance, such that we do not have to consider these
cases separately).
This bound can be larger than one, but it need not be. For example, it is easy to verify that for
any binary x,5 this expression simplifies to cov(Wx, x)  1. That the bound is always smaller
than one for binary x, but not more generally, also reinforces the earlier point: for our main condition to fail, we would need to have a specific constellation of W and x. Moreover, this bound
allows calculating the largest possible value of cov(Wx, x) in any given sample and, from that,
the minimum value of ⇢ that would be necessary to obtain a bias larger than .
To obtain more intuition for the inequality for our worst-case bounds, we can also write


cov(Wx, x)
(x1 xN )2 E[xi |xi

var(x)
4var(x)

0] + E[xi |xi < 0]
,
x1 xN

The first term in this expression is a Popoviciu ratio: it shows how close var(x) is to its possible
maximum based on the largest and smallest value of x. This ratio is at least one and attains the
lower bound of 1 if x is dichotomous. The second term is an indicator of how spread out x is over
its interior. This ratio is at most 1 and attains its upper bound again if x is dichotomous.
We next consider the case where W has been normalized with min-max normalization that resulted in column-sums of at most one but potentially larger row-sums (because the largest column5

Recall that we assume that x has mean zero, which implies that a binary x takes on values 1
is the proportion of positive observations in the sample.

7

p and

p, where p

sum was smaller than the largest row-sum). The key here is to observe that in this case, each unit
has a total influence of at most one on the entire network. Thus, the largest possible value for
cov(Wx, x) is obtained if W is a matrix that sums all positive values of x and associates them
with x1 and that sums all negative values of x and associates them with xN . Put differently,
" N
#
N
X
1 X
cov(Wx, x) =
xi
wij xj
N i=1
j=1

k
N
1 X
1 X

xi x1 +
xi xN ,
N i=1
N i=k+1

which is identical to the expression in (9).
Recall that these bounds would imply that all units are only connected to the most extreme
observations. If this were unreasonable, as it often is, tighter bounds would obtain. For example, if
one is willing to assume that each unit is connected to a minimum number of observations, tighter
bounds can be derived. Consequently, in almost all practical examples the bounds given by (1) will
give a more typical approximation than those given by (9) – as we demonstrate using simulations
for k-nearest neighbors and row standardization in the appendix. However, for completeness, we
have presented both sets of bounds here.
SAR: powers of matrices and bounds
For any (symmetric or non-symmetric) matrix that satisfies cov(Wx, x)/var(x)  1, it follows that cov(Wk x, x)/var(x)  1 for k = 1, 2, 3, . . .. To prove this, note that the maximum of cov(Wk x, x)/var(x) is equal to the numerical radius of W. Denoting the numerical
radius with r(W), the Halmos inequality establishes that r(Wk )  rk (W) – see, e.g., Goldberg and Zwas (1975). If r(W)  1, it follows that r(Wk )  rk (W)  1, which proves that
cov(Wk x, x)/var(x)  1 whenever cov(Wx, x)/var(x)  1.
Alternatively, an analogous approach to above can be used to derive bounds from the sample
data on x and y to calculate a bound on the covariance cov(Wy, x) for arbitrary W. For W
such that normalization results in a largest row-sum of at most one, the largest possible value for

8

cov(Wy, x) obtains if W matches all positive xi with the largest value of y and all negative values
of xi with yT = min{0, min{yi }}. Note that if yi > 0 for all i, this implies a matrix W such that
observations with xi < 0 are ‘islands’, with only zero elements in the corresponding rows (which
is inconsistent with a large class of standard spatial weights matrices and hence results in a bound
larger than what those matrices would permit). Then, defining k as before such that xi

0 for

i  k and xi < 0 for i > k,
" k
#
N
X
1 X
cov(Wy, x) <=
ymax xi +
yT xi ,
N i=1
i=k+1
which can be calculated from the data. A similar expression follows for W if normalization results
in a column sum of at most one. The larger of the two expressions can then be used to derive an
upper bound for the bias in the SAR case.

9

Appendix B

Propagation of Measurement Error in the IV Estimation

To see that the measurement error in W is not solved by instrumental variable estimation of the
SAR model, consider that pre-multiplying both sides of equation (4) by W and using repeated
substitution for Wy yields
Wy = Wx + ⇢W2 x + ⇢2 W3 x + . . . + W✏ + ⇢W2 ✏ + ⇢2 W3 ✏ . . . ,

(10)

which demonstrates how Wx and its powers have strength as instruments for Wy. However, if
f from equation (8) we obtain:
we rely on W

f = Wx
f + ⇢W
f 2 x + ⇢2 W
f 3 x + . . . + W✏
f + ⇢W
f 2 ✏ + ⇢2 W
f 3✏ . . .
Wy

(11)

f the instrument Wx
f is related to the measurement error
Due to the common transformation via W,

f IV estimation will resolve the simultaneity bias – the usual concern with spatially-lagged
in Wy.
outcomes – but not the bias due to measurement error.

10

Appendix C Additional Simulation Results
C.1 Additional SAR Simulation Results
In this section, we present results from the additional simulations of the SAR process.6 First,
Figure C.1 shows the results from the simulations where W is based on 10-nearest-neighbors but
is row-normalized. Again, spatial dependence in X increases from left to right, while the spatial
parameter of Y increases from zero for simulation results depicted in the top row to 0.6 in the
bottom row. The results are quite similar to those presented in the paper. The biases in the standard
linear models and the misspecified SAR models increase with higher spatial dependence in both
X and Y. Again, under all scenarios, the bias misspecified in SAR models is bounded from above
by the bias in the non-spatial models.
ρx = 0

ρx = 0.3

ρx = 0.6

ρ

y

=

0

4

2

0

3

4
ρ

y

=

0.

Density
2

0

Misspecification
Probability
1
0.75
0.5
0.25
0

ρ

y

=

0.

6

4

2

0
1.0

1.5

2.0

2.5

3.0

3.5 1.0

1.5

2.0

2.5

3.0

3.5 1.0

Coefficient Estimates

1.5

2.0

2.5

3.0

3.5

Figure C.1: Misspecification of W in SAR models – KNN & Row-Normalization
6

The replication materials for the results presented both here and in the main text can be found at Hollenbach, Betz
and Cook (2019).

11

The derivation of our analytical bounds allows us to calculate the expected bias for SAR models. In particular, equation 5 in the manuscript can be rearranged such that we can derive an
expected ˆ given the simulated scenarios: plimn!1 ˆOLS =

+ ⇢ cov(Wy,x)
.
var(x)

In Table C.1, we compare the expected ˆ given our analytical derivation to the average OLS
estimate in our simulations given combinations of the spatial parameters in the simulations based
on 10-nearest-neighbors and min-max normalization. The first two columns show the variation
in the simulated spatial dependence (⇢x and ⇢y ), next we calculate the average cov(Wy, x), and
var(x), and their ratio from the simulations. Based on the ratio

cov(Wy,x)
var(x)

and true

= 2, we can

then calculate the expected ˆ given the analytical results. In contrast, the last column shows the
average ˆ estimated in the standard linear model at a given scenario. As one can see, the analytical
results and the simulated quantities are effectively the same.
Table C.1: Analytical ˆ & Mean ˆ in Simulations – SAR
⇢x

⇢y

cov(Wy, x)

var(x)

cov(Wy,x)
var(x)

0.00
0.00
0.00
0.30
0.30
0.30
0.60
0.60
0.60

0.00
0.30
0.60
0.00
0.30
0.60
0.00
0.30
0.60

0.00
0.07
0.22
0.17
0.30
0.56
0.69
1.00
1.71

0.91
0.91
0.91
0.94
0.94
0.94
1.18
1.18
1.18

0.00
0.08
0.24
0.18
0.32
0.59
0.58
0.85
1.45

Expected ˆ Mean ˆOLS
2.00
2.02
2.14
2.00
2.09
2.36
2.00
2.26
2.87

2.00
2.03
2.14
2.00
2.10
2.35
2.00
2.26
2.87

C.2 Additional SLX Simulation Results
To simulate the SLX models we begin with the following data generating process:

y = ↵ + x + ✓Wx + ✏,
x = (I

⇢x W) 1 u,

where u and ✏ are N (0, 1). The effect paramaters are , ✓x , and ⇢x , with
12

(12a)
(12b)
reflecting the direct

(i.e., pre-spatial) effect of x on y, ✓x the spillover effect, and ⇢x the spatial interdependence in x.
As in the main text, the binary W matrix is generated with ones assigned to each observation’s ten
nearest neighbors. We again hold W,

= 2, N = 150, and u fixed across the simulations, focusing

on variation in the spatial parameters ⇢x and ✓. We vary ⇢x from 0 (no spatial interdependence)
over 0.3 to 0.6 (high spatial interdependence). ✓ takes on the following values: 0, 1, and 2.7 For
each of these 9 experimental settings, we simulate 2, 000 data sets, which leads to 18, 000 in total.
We again undertake the simulation excercise with W matrices normalized using two methods:
row- and min-max normalization.
Using these simulated data for y and x, we estimate a non-spatial linear model (via OLS) and
f i.e., the user-specificed weights matrix of varying accuracy
the SLX models with the different W’s,
(i.e., decreasing in p – the probability of misspecification). We record the estimated ˆ based on the
model’s coefficient to assess potential bias.
Figure C.2 shows the results of the SLX simulation analysis for W based on 10 nearest neighbors and min-max normalization. Each cell in the plot shows the result for one experimental
condition, ⇢x increases from 0 to 0.6 in cells going from left to right, while ✓x increases in cells
moving from top to bottom. Each cell shows the densities of coefficient estimates for models estimated with OLS or SLX models at different levels of the misspecification probability p, where
darker shading is indicative of higher levels of misspecification. The densities for the OLS models
are plotted in black. As one can see, the bias in misspecified models increases in both ✓ and ⇢x ,
being largest in the bottom right cell. Again, the estimates of SLX models become increasingly
worse with higher levels of misspecification, but is bounded from above by the standard linear
model estimate.
Figure C.3 shows the simulation results when the 10-NN matrix is standardized using rownormalization. The results across these specifications are effectively the same as in the SAR process simulations.
Lastly, we again calculate the expected ˆ based on our analytical derivation for the SLX model
7

The parameter values from ✓ are larger than ⇢y in the main text because the implied effect on y from changes to
Wx are much smaller than from changes to Wy.

13

ρx = 0

ρx = 0.3

ρx = 0.6

θx

=

0

4
2
0

4
θx

=

1

Density
2
0

Misspecification
Probability
1
0.75
0.5
0.25
0

θx

=

2

4
2
0
1.0

1.5

2.0

2.5

3.0

3.5 1.0

1.5

2.0

2.5

3.0

3.5 1.0

Coefficient Estimates

1.5

2.0

2.5

3.0

3.5

Figure C.2: Misspecification of W in SLX models – KNN & Min-Max Normalization

(equation 2 in the manuscript) for different scenarios in the simulation with 10 nearest neighbors
and min-max normalization. Re-writing equation 2, we can express the expected estimate from the
standard linear model as: plimn!1 ˆOLS =

+ ✓ cov(Wx,x)
. As above, we calculate the expected ˆ
var(x)

and compare it to the average OLS estimate for each combination of parameters in the simulation.
As shown in Table C.2 the average simulation results for ˆ are again quite similar to those derived
analytically.

14

ρx = 0

ρx = 0.3

ρx = 0.6

θx

=

0

4
2
0

4
θx

=

1

Density
2
0

Misspecification
Probability
1
0.75
0.5
0.25
0

θx

=

2

4
2
0
1.0

1.5

2.0

2.5

3.0

3.5 1.0

1.5

2.0

2.5

3.0

3.5 1.0

Coefficient Estimates

1.5

2.0

2.5

3.0

3.5

Figure C.3: Misspecification of W in SLX models – KNN & Row Normalization

Table C.2: Analytical ˆ & Mean ˆ in Simulations – SLX
⇢x

✓

cov(Wx, x)

var(x)

cov(Wx,x)
var(x)

0.00
0.00
0.00
0.30
0.30
0.30
0.60
0.60
0.60

0.00
1.00
2.00
0.00
1.00
2.00
0.00
1.00
2.00

0.00
0.00
0.00
0.09
0.09
0.09
0.34
0.34
0.34

0.91
0.91
0.91
0.94
0.94
0.94
1.18
1.18
1.18

0.00
0.00
0.00
0.09
0.09
0.09
0.29
0.29
0.29

15

Expected ˆ Mean ˆOLS
2.00
2.00
2.00
2.00
2.09
2.18
2.00
2.29
2.59

2.00
2.01
2.00
2.00
2.10
2.18
2.00
2.29
2.58

References
Anselin, L. 1988. Spatial Econometrics: Methods and Models. Vol. 4 Springer Science & Business
Media.
Boots, Barry and Michael Tiefelsdorf. 2000. “Global and local spatial autocorrelation in bounded
regular tessellations.” Journal of Geographical Systems 2(4):319–348.
Cliff, Andrew David and JK Ord. 1981. Spatial Processes Models and Applications. Pion Ltd.
De Jong, P, C Sprenger and F Van Veen. 1984. “On extreme values of Moran’s I and Geary’s c.”
Geographical Analysis 16(1):17–24.
Goldberg, Moshe, Tadmor Eitan and Gideon Zwas. 1975. “The Numerical Radius and Spectral
Matrices.” Linear and Multilinear Algebra 2(4):317–326.
Hollenbach, Florian M., Timm Betz and Scott J. Cook. 2019. Replication Data for: Bias due to
network misspecification under spatial dependence. Harvard Dataverse.
URL: https://doi.org/10.7910/DVN/UBNPPI
Kelejian, Harry H. and Ingmar R Prucha. 2010. “Specification and estimation of spatial autoregressive models with autoregressive and heteroskedastic disturbances.” Journal of econometrics
157(1):53–67.
LeSage, James and R Pace. 2014. “The biggest myth in spatial econometrics.” Econometrics
2(4):217–249.
Ord, Keith. 1975. “Estimation methods for models of spatial interaction.” Journal of the American
Statistical Association 70(349):120–126.

16

