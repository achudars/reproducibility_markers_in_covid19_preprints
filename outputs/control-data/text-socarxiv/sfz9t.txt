Displaying spatial epistemologies on web GIS: using visual materials from the Chinese
local gazetteers as an example
Nung-yao Lin, Shih-pei Chen, Sean Wang, Calvin Yeh
Max Planck Institute for the History of Science
Abstract
In this paper, we introduce a web GIS platform created expressly for exploring and
researching a set of 63,497 historical maps and illustrations extracted from 4,000 titles of
Chinese local gazetteers. We layer these images with a published, geo-referenced
collection of Land Survey Maps of China (1903-1948), which includes the earliest largescaled maps of major cities and regions in China that are produced with modern
cartographic techniques. By bringing together historical illustrations depicting spatial
configurations of localities and the earliest modern cartographic maps, researchers of
Chinese history can study the different spatial epistemologies represented in both
collections. We report our workflow for creating this web GIS platform, starting from
identifying and extracting visual materials from local gazetteers, tagging them with
keywords and categories to facilitate content search, to georeferencing them based on
their source locations. We also experimented with neural networks to train a tagger with
positive results. Finally, we display them in the web GIS platform with two modes,
Images in Map (IIM) and Maps in Map (MIM), and with content- and location-based
filtering. These features together enable researchers easy and quick exploration and
comparison of these two large sets of geospatial and visual materials of China.
1. Introduction
It is increasingly common for text-based projects in digital humanities to incorporate GIS and other
geovisualization techniques for data exploration and search-result displays. Conversely, imagebased projects from fields such as digital art history often require text-based finding aids (such as
metadata and keywords) to facilitate data discovery. Working at the intersection between spatial
humanities and geohumanities, we believe that techniques associated with historical GIS could
well integrate these two approaches for data discovery and exploration. In this paper, we introduce
a web GIS platform created expressly for exploring and researching—based on content and source
locations—a set of 63,497 historical figures and illustrations. These figures and illustrations are
extracted from a larger set of four million scanned pages from 4,000 titles of Chinese local
gazetteers (difangzhi).1 Local gazetteer is a genre of Chinese local history produced between the
8th and the 19th centuries. It recorded local knowledge about places and its geographical, temporal,
and jurisdictional coverages as a genre are pervasive across historical China at all scales. To date,
a significant portion of extant local gazetteers has been digitized as scanned pages and have
become searchable full texts. Elsewhere, we have built a set of digital tools to work with these full
texts and to display search results on an interactive geovisualization.2
While primarily a textual genre, the Chinese local gazetteers also contain a number of figures and
illustrations, such as maps, plants, ritual objects and so on. However, there has been little scholarly
effort to work with these visual materials due to a lack of systematic tools.3 Since 2017, we have

1

begun identifying such visual materials from the scanned pages of local gazetteers. This collection
of extracted visual materials from local gazetteers is unprecedented and will offer new possibilities
for research in Chinese history. Moreover, since a majority of these materials (e.g., administrative
maps, military maps, city layouts landscape drawings, astronomy figures 4 ) depict spatial
configurations of places, together they reflect how government officials and local elites in
historical China thought about and described their localities and provide invaluable resources for
those interested in historical geohumanities.
To provide an image-based finding aid for exploring this set of visual materials in local gazetteers
alongside existing text-based tools, we devised a strategy that harnesses techniques and interests
from both spatial humanities and geohumanities at two separate levels and that takes advantage of
Chinese local gazetteers’ inherent geographical character. To be specific, this collection of visual
materials is distinctive from other image collections in two ways. First, each visual material is
associated with a coordinate (i.e., it is extracted from a title of local gazetteer that was compiled
for a specific locality in historical China), which means that we can roughly georeference it.
Second, many materials in this collection are what could be considered maps of some kind, but
they largely reflect different spatial perspectives from later Chinese maps made with Western
cartographic principles and techniques. To elaborate, they are hand-drawn and subjective, even for
those intended to be for official purposes. For instance, administrative maps were not scaled
according to distance but by relative positions of natural landscapes, which often highlight certain
geographical entities but eliminate unimportant ones. Therefore, by combining image-based
finding aids with georeferenced visual materials via a web GIS platform, combined with base
layers of later Chinese maps, we open up new ways of studying historical localities by making
explicit the tensions between spatial epistemologies across time and space.
In this paper, we summarize our workflow for creating this web GIS platform, from identifying
and extracting visual materials from local gazetteers, tagging them with keywords and categories
to facilitate content search, then finally georeferencing them on a web GIS platform for exploration
based on both contents and coordinates. We also experimented with using neural networks to train
image tagging with positive results, which led us to propose an image categorization workflow
combining manual tagging and machine learning that is potentially applicable to other large image
collections. In our web GIS platform, aside from content- and location-based filtering, we also
created two modes, Images in Map (IIM) and Maps in Map (MIM), to display the local gazetteers
images on base layers for making apparent the tension between these spatial epistemologies across
time and space, which would then enable comparisons between the historical and modern spatial
epistemologies.
2. Literature
Digitization of cultural heritage has produced large quantities of digital images from scanning or
photographical artefacts. Therefore, resource owners often create web interfaces for researchers
and the general public to explore such image collections. Digital images, unlike digital texts,
cannot be easily searched by their contents. Therefore, major finding aids for large image
collections are usually based on metadata. 5 The same situation also occurs in GIS projects. 6
Browsing large image collections can be realized using categorical metadata fields, such as sources,
temporal periods, places or geographical regions, or thematic categorization schemes designed by

2

owners or researchers. Keyword search on metadata is another important way to find images
relevant to users’ interests. However, creating metadata for each image to facilitate search can be
very costly, and normally only large institutions can afford such investment. And although space
is an important dimension for organizing knowledge and would be useful as a metadata field,
unfortunately not every image collection possesses strong geospatial attributes. Therefore,
displaying images according to meaningful geolocations is not always achievable.
Coming from another direction, historians who work with digitized sources have long sought to
relate them to space and time, and historical GIS have provided many techniques on how to
integrate spatial concepts in historical studies. Nonetheless, many scholars still struggle with
locating spatial descriptions in historical sources, whether textual or visual and situating them in
GIS.7 For historical maps specifically, those made without modern cartographic techniques require
locating their precise location by other means before any GIS modeling.
Two examples illustrate difficulties with this type of research. In the first one, Ya-Ni Huang
studied the accuracy of hand-illustrated maps from the Qing dynasty (1644-1911) by representing
these illustrated, imprecise maps in GIS. 8 However, this process was time-consuming and
resource-intensive. It required manual examination of every potential inaccuracy in the illustrated
maps. As a result, Huang was able to complete GIS modeling for only two maps from the TanHsin Archives. In the second, the research team behind the Virtual Kyoto project collected a
massive amount of information and investigated their locations by referencing each other in order
to recover the precise locations of archival materials. 9 Using georeferenced archival materials,
such as current digital maps, old topographic maps, cadastral maps, aerial photos, picture maps,
street photos, landscape paintings, archaeological sites data, and historical documents, the team
reconstructed a ‘virtual Kyoto’ in a specific time and area. These two projects demonstrate that it
is time-consuming and resource-intensive to represent historical maps and that this process
requires humanities scholars to collaborate with GIS experts. In fact, among the 200 papers
published in the last two decades on historical GIS in Taiwan, most of the efforts were spent on
investigating detailed changes in spatial boundaries, which proves that it is important but yet
difficult to restore historical maps that were made without modern cartography in GIS.10
In web applications, there has been also a spatial turn.11 For example, private firm Panoramio
started a service in 2005 where user’s photos were displayed on a web GIS platform using userspecified geolocated tags or GPS headers embedded in the photos. Google later acquired this
service and, based on it, and started Google Street View. In Google Street View, user’s photos
were collected and combined to produce a panorama. This service is not based on geotagging.
Rather, it successfully combines photos with their geolocations and provides a better user
experience. Google Indoor Map and Business View are further advances from this technology and
provide panoramas for indoor spaces.12
In this paper, we propose a method that combines historical visual materials within a GIS
environment, where historical maps made with modern cartographic techniques are used as
contextual base-maps and other visual materials are overlaid on top. This method can extend the
spatial scope of research and reduce work by humans while producing results applicable in largescale web GIS and interactive query systems.

3

3. Method
In order to provide an image-based finding aid for exploring the visual materials in local gazetteers,
we first identified and extracted visual materials from four million scanned pages of Chinese local
gazetteers via a semi-automatic method. We found 63,498 pages containing visual materials and
invited a group of historians to work on them. We also developed corresponding digital tools with
keywords-tagging and annotation functions based on their research needs.13 While the scholars
only tagged images relevant to their specific research interests, we realized that a basic knowledge
organization is essential to facilitate content-based search. Therefore, we organized all 63,498
images with 16 predefined tags (see Table 1). To fully describe each image’s content, we allow an
image to have multiple tags.
Table 1. Tags for visual materials of Chinese local gazetteers
Type

Spatial

Non-spatial
Total amount

Tag

Amount

Amount used for training

Administrative map

20,119

24

City layout map

10,542

22

Military map

1,677

-

Landscape

14,631

-

Building or building
complex

11,241

24

Layout diagram

926

24

Astronomy star map

1,082

22

Ritual

1,200

-

Musical

394

-

Agricultural

495

21

Military

103

-

Human figure

631

28

Objects

874

-

Flora and fauna

162

23

Chart or graph

22

Photograph

63,498

210

While results from manual tagging are satisfactory, it is not surprising that some are inconsistent.
Therefore, we started to experiment with machine learning and neural networks for a more
consistent tagging model, described in §3.1. Our results not only helped to systematically identify
instances of inconsistency but also led to a tagging workflow (combining manual and machine

4

learning techniques) that is applicable to other large image collections. Based on this workflow,
we built a web GIS finding aid that allows for both content- and location-based search (see §3.2).
We also built novel features for exploration that emphasize the spatial dimension as well as the
interchange between relative and absolute spatial representations of locations.
3.1 Automatic image tagging with neural networks
Through our image tagging process, we learned that human tagging is time-consuming and the
results are likely to be inconsistent. Therefore, we explored ways to automate tagging and
experimented with neural networks. Our results were surprisingly good, which led us to propose a
web-based tool and workflow that would allow users to define a project-specific tagging scheme,
train automatic neural network models based on a small set of manual tagging, and propagate
consistent tagging to the rest of the image collection.
In 2015, researchers at the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) first
reported that software exceeded human ability in image recognition. 14 In 2017, 29 of the 38
ILSVRC’s competing teams achieved <5% error rate, which was lower than human’s. In order to
increase tagging consistency, reduce human labor, and batch-process automatically, we decided to
use a machine learning method - Neural Network approach. Artificial Neural Networks (NN) are
computing systems inspired by the biological neural networks that constitute animal brains. 15
TensorFlow is an open-source software library for machine learning applications (including NN).16
Here we use a Convolutional Neural Network (CNN) as our model. 17 We use TensorFlow to
experiment with automatic tagging of our images. TensorFlow contains two steps: first, it uses a
small set of images to train a Neural Network model, which captures the decision-making
procedure behind our image tagging; second, it then uses the trained model to tag images that were
not in the training set.
3.1.1 Training images
We manually selected high-quality training images from our manually tagged images. We chose
210 images from a total of 9 tags, about 20 images per tag (see Table 1). We also selected a few
test images to verify the obtained neural network model. The 9 tags that we have chosen out of 16
tags are those with distinct features. For example, the tag “human” and the tag “agriculture” do
not have much in common, thus allowing classification with high efficacy. Meanwhile, the “ritual”
tag is not selected because in Chinese rituals, often there are musical instruments, dancer and
animal sacrifices involved. This could lead to undesired tag assignment with our current NN.
Hence, a different design of NN should be deployed for this purpose.
3.1.2 Accuracy of validation
The validation module provided in TensorFlow shows that our model yielded 87.1% accuracy rate
of prediction. Its high rate encouraged us to apply this model to the rest of our 63,498 images for
alternative tag suggestions. By comparing the tags assigned manually and the ones suggested by
the model, we were easily able to find inconsistencies and proceed to more suitable tags.
3.1.3 Examples

5

Below we show some examples of our result. Figure 1 gives the thumbnails of 28 training images
for the tag “Human figure.” Ten of them are portraits and photos. The rest are illustrations of
human figures of full body-length. We then used the image of a man in full body-length on the left
to test our model. The highest tag suggested by our model for this image is “Human figure” with
a probability of 0.955, while the second and third highest tags are “Flora and fauna” with 0.029
probability and “Agriculture” with 0.007. The most likely tag for this image out-scored the rest.

Figure 1. Training data (right) and test image (left) for tag “Human figure”
In the second test, we chose an image that in fact contains two separate images (on the left in
Figure 2). One is a farmhouse and the other contains three human figures. The top three tags given
by our model are: “Building or building complex” (with probability 0.271), “Human figure” (0.258)
and “Agriculture” (0.148). While the top two tags are with relatively low probabilities (around
0.25), this result correctly reflects the situation.

6

Figure 2. The 2nd (left) and 3rd (right) test images
We chose the third image from “Ritual” (on the right in Figure 2). Note that no images with this
tag were included in our training dataset. This image contains four human figures demonstrating a
ritual performance, where the performer holds a long ritual object that appears to be a large feather
or plant. The top three tags given by our model are: “Flora and fauna” (with probability 0.864),
“Human figure” (0.067), and “Agriculture” (0.029). This result very closely reflects the image
content.
3.1.4 A semi-automatic image tagging system
Our experiment demonstrated the feasibility of combining manual tagging and neural networks to
quickly propagate the model trained from a small set of manually tagged to the rest of the collection.
With a friendly enough web user interface, the whole process of human tagging, training neural
network models, validation and testing (of a trained model), and automatic tagging of the rest of
the collection can be realized seamlessly. Such a semi-automatic tagging system might only need
a small set of training images by human taggers, and thus could be an efficient basis for providing
content-based search and exploration for large image collections.
3.2. Web GIS-based finding aid
In order to explore and study these local gazetteer images and to easily contextualize them in space,
we implemented a web GIS with content- and location-based finding aids. Furthermore, our web
GIS is analogous to the relationship between Google Street View and Google Maps, where users
could toggle between the close and relative illustrations of space found in local gazetteers as popups, with a set of precise and scientifically produced historical maps of China as base layers.

7

Overlaying the two would help examine how local communities in historical China thought about
and described their lands and living spaces in relation to modern depictions of space.
We used a published collection of Land Survey Maps of China produced between the late 19th
and early 20th century as the precise base-maps. From the last decades of the Qing dynasty (16441911) to the end of the Republican era (1912-1949), China’s central and provincial governments
and the Land Survey Department of the Japanese Army conducted geographical surveys across the
country and produced maps that contain detailed topographical and administrative information.
Over 4,000 of these maps were compiled and published by the Japanese publisher Kagaku Shoin
between 1986 and 1998.18 They are the earliest maps of China produced with modern cartographic
techniques, and they cover most of China's major cities and counties. More importantly, these
maps provide a cartographic snapshot closest to an undeveloped historical China, due to the limited
progress of architectural technology before China’s full modernization.19
We designed this web GIS using the JavaScript library Leaflet. Users can search images from local
gazetteers by tag filtering (see Table 1). The tagged images are displayed on web GIS (and
clustered when appropriate) according to the geographic coordinates of their specific gazetteer title.
In addition, users can also zoom to a particular region, and our tool would return images from that
region. Therefore, this web GIS functions as both content- and location-based finding aids.
We provide two novel modes of displaying images to make this web GIS more useful for research
purposes (see Figure 3). We call them ‘Images in Map’ (IIM) and ‘Maps in Map’ (MIM). IIM
displays the thumbnails of image search results directly on a modern base-map. Through IIM,
researchers can see not only the geographical distribution of the search results but also the images
directly. It allows researchers to easily observe patterns and identity phenomena across
geographical regions. For example, filtering for the “Human figure” tag, one can see all such
images displayed on the map and can immediately observe the styles of illustrating human figures
or the styles of their clothing from different regions of China.

8

Figure 3. Examples of Images in Map (left) and Maps in Map (right) display modes
If images from search results are about spatial configurations or geographical in nature, they will
be displayed as MIM. These search results would be overlaid on the land survey maps of China in
order to provide more context. For example, a user can zoom to a historical city. Our interface
would then show the corresponding portion of the Land Survey Maps, which are overlaid with
spatial representations about this city from local gazetteers, such as city layout map and detailed
buildings complex (see the right-hand side of Figure 2). Since many images from local gazetteers
depict spatial configurations of places, MIM is especially useful for researchers to quickly compare
the spatial depictions from the relative, illustrative historical maps given in local gazetteers and
the absolute, scientific historical maps given by the Land Survey Maps. While the georeferenced
Land Survey Maps represent China from the 1930s in GIS, the non-precise maps from local
gazetteers actually provide more subjective details about the city, such as the relative positions of
elements of the city that were important to the editors and the building facades. Therefore, the
spatial visual materials from local gazetteers, despite being relative and non-precise, nonetheless
provide additional details, while the Land Survey Maps, due to their consistent city layouts for
military purposes, also help researchers to find the precise locations of buildings and other
elements illustrated in local gazetteers.
There are also some spatial images in the local gazetteers that have even higher resolution. For
example, some images depict objects for ritual ceremonies, laid out inside a temple-schoolgovernment building complex or some building interior. This level of granularity is not found in
the Land Survey Maps or other scientifically produced historical maps either.
In summary, by providing both content- and location-based finding aids for historical images,
displaying image thumbnails directly, and by bringing different spatial epistemologies together in
one environment, we believe our web GIS interface is not just a way to digitally represent these
images. Rather, it is a research tool to allow exploration of large image collections according to
the spatial and bibliographical dimensions, to allow contextualization of historical images through
different levels of spatial configurations, and to allow discovery of patterns. It can help scholars
achieve new understandings about visual materials in local gazetteers and can inspire new research
questions by treating all the images together and by putting them back into historical contexts.
4. Displaying spatial epistemologies: an example
In this section, we use an example to illustrate how our web GIS allows researchers to study
historical China by displaying different spatial epistemologies together: namely, the modern
spatial understanding of current China based on GIS and modern base maps, the georeferenced
Land Survey Maps produced in the early 20th century by modern cartography, and the historical
maps and spatial representations in local gazetteers.
We chose the city of Yuyao as our example. Yuyao is near Hangzhou Bay, on the south bank of
the Yangzi River and is 130 kilometers south of Shanghai. The historical Yuyao was built north
of the Yao River since at least the first century, and by the mid-16th century the portion on the
southern bank of river was annexed.20 Today, satellite imagery shows that Yuyao has grown into
a large city that encompasses land around the Yao River’s various tributaries (Figure 4). However,

9

it is difficult to find traces of the city’s historical boundaries from the satellite imagery, except for
the mountain in city center north of the river.
In our web GIS, we can zoom to Yuyao’s current location and see how the surrounding region was
depicted by the Land Survey Maps from the early 20th century. Figure 4 shows that in the early
20th century Yuyao remained a city divided into northern and southern parts by the Yao River,
which matches the historical description from the 18th-century gazetteer. In the city map, one can
find the notation of a mountain on the northern part of the city to its southwest, which provides a
reference between the modern satellite imagery and the Land Survey Maps.

Figure 4. Birds-eye view of Yuyao city (left c.2018, right c.1916)
We can now compare the spatial images of Yuyao from local gazetteers. The 1781 Yuyao Local
Gazetteer contains a sequence of hand-drawn maps (Figure 5). They are: an administrative map of
the greater Yuyao region, depicting the city relative to surrounding rivers, lakes, mountains, and
military bases; a city layout map depicting important elements, such as city wall, gates, roads,
mountains, and buildings; layout maps of the local government building complex and the
Confucius school complex; a detailed illustration of the mountain in the city; and illustrations of
other surrounding mountains. Our interface can display all these spatial illustrations together with
the 20th-century land survey maps. By overlaying them, researchers can switch from a modern
GIS to an early modern spatial depiction of the city, then to a set of earlier historical spatial
depictions about the same place. When traveling back in time, the interface could also display
spatial information at different granularities.

10

Figure 5. Spatial images in the Yuyao Local Gazetteer, 1781
From a close examination of, and comparison between, the contents of the land survey map and
the city layout map from the Yuyao Local Gazetteer, we can find corresponding elements between
the two. First of all, we now know more precise positions of the elements from local gazetteers
and how the historical depictions are distorted from modern cartography. Second, the illustrations
from local gazetteers add different layers of details to the 20th century land survey map. Since the
Land Survey Maps were produced mainly for military purposes, they omit certain details and
replace them with a set of symbology. For example, the identity of buildings is as important as the
routes to navigate the troops among them. Unfortunately, the symbology used in the Land Survey
Maps has not been studied. The detailed illustrations in local gazetteers like administration maps,
city layout maps, and buildings could actually help researchers decode the symbology used in these
maps. For example, through examining the maps of Yuyao, we found that the “✉” symbol in the
Land Survey Maps should denote post offices, “文” should mean schools, and “帀” and “卐” might
denote Confucius and Buddhist temples respectively. Interpreting the symbols from Land Survey
Maps and finding corresponding buildings from local gazetteers would further help find precise
locations of buildings and advance our understanding of the city’s history. There are still symbols
used in Land Survey Maps that are unidentified, and further work from historians of cartography,
local history, and geographers is necessary to unravel the full spectrum of these maps and images.
5. Discussion and Conclusion
In this paper, we made several major contributions in creating tools and methods for historians to
explore a large image collection from Chinese local gazetteers. First, in order to provide contentbased finding aids for this collection, we defined sixteen tags and finished tagging for our 63,489
images by human taggers within some months. Such tags serve as categories and help to retrieve

11

images for a certain type. We argue that this alternative solution is less expensive and less labor
intensive compared with creating detailed metadata for each image in a large collection, an
approach often adopted by libraries and museums. We further experimented with semi-automatic
tagging by training a neural network using 210 images from 9 categories. Our positive results
demonstrate a feasible workflow that could be applied to other large image collections to use tags
as the basic content finding aid. The project owner will need to find experts to manually tag a small
set of training images, but then the model can be propagated to the rest of the collection effectively
and efficiently.
Based on the tags and the geographical coordinates that each image inherits from the local
gazetteer to which it belongs, we built a WebGIS interface to help researchers to explore this large
image collection. By displaying these historical, hand-illustrated images on modern GIS
environments in the modes of Images In Map (IIM) and Maps in Map (MIM) and by allowing
content- and location based filtering, our web GIS interface equips researchers with useful tools to
explore this large set of images. Moreover, by bringing together spatial images given in local
gazetteers and maps produced by modern cartographic techniques, researchers can study these
images with different spatial epistemological backgrounds. We believe that our web GIS interface
is a useful research tool that goes beyond finding aids to help researchers discover spatial patterns
from this large set of local gazetteers images and to answer or raise research questions.
In the past, much of digital humanities scholarship has focused on texts, but now, by foregrounding
the spatial attributes of images, we can extend the scope of research into visual materials. Machine
learning can help image owners to process large number of images with relatively low cost and
this makes the approach feasible for even large image collections. We also think that more machine
learning methods should be explored for our images in the future, such as image recognition, image
clustering (based on similarity), and search by image, especially when the cost of applying
machine learning techniques decrease dramatically. By that time, we would be able to provide
more ways for researchers to explore large set of images.
1

This set of digitized local gazetteers is published by the Beijing Erudition Digital Technology Research
Center and was made available via Staatsbibliothek zu Berlin’s CrossAsia portal.
2
Shih-Pei Chen et al., “Compiling a Database on Historical China from Local Records: The Local
Gazetteers Project at MPIWG,” in Proceedings of Digital Humanities Conference (Kraków: Jagiellonian
University and Pedagogical University, 2016), https://dh2016.adho.org/abstracts/160.
3
Cf. Qi Luo, “Research on the Illustrations of Chinese Local Gazetteers: Overview, Evaluation, and
Potential Approach for Future Study,” in Proceedings the 2nd International Conference on Social Sciences,
http://ase-scoop.org/papers/IWAHS-2016/5.Luo_IWAHS.pdf.
4
Editors of Chinese local gazetteers used stars in the sky to identify the position of a place on earth.
Therefore, these astronomy figures also represent a birds-eye view of local spatial configurations.
5
For example, large digital image collections such as Europeana, the Library of Congress, the Vatican
Library, the Kyoto University Library, and the Harvard University Library, all use some form of textbased finding aid based on metadata filtering; cf. Florian Windhager et al., “Visualization of Cultural
Heritage Collections Data: State of the Art and Future Challenges,” IEEE Transactions on Visualization
and Computer Graphics 25, no. 6 (June 2019).
6
Jennifer Marina Titus, “Peoples of Washington Historical Geographic Information System: Geocoding
Culture using Archival Standards” (PhD diss., University of Southern California, 2016), 58; Jeanine
Scaramozzino et al., “Map Room to Data and GIS Services: Five University Libraries Evolving to Meet

12

Campus Needs and Changing Technologies,” Journal of Map and Geography Libraries 10, no. 1 (2014):
15.
7
Chung-Hsin Li and Ya-Wen Ku, “Retrospect and Prospect: Application of Historical GIS to Taiwan
Regional History Studies in the Last 20 Years,” Taiwan Historical Research 21, no. 2 (2014): 167; May
Yuan, “Temporal GIS for Historical Research,” in Spatio-Temporal Narratives: Historical GIS and the
Study of Global Trading Networks, ed. Ana Crespo Solana (Newcastle upon Tyne: Cambridge Scholars
Publishing, 2014), 45.
8
Ya-Ni Huang, “Planimetric Accuracy of Old Maps: Tan-Hsin Archives Maps” (master’s thesis, National
Taiwan University, 2011).
9
Keiji Yano et al., “Virtual Kyoto: 4DGIS Comprising Spatial and Temporal Dimensions,” Journal of
Geography 117, no. 2 (2008).
10
Li Zongxin 李宗信 and Gu Yawen 顧雅文, “近二十年來應用歷史地理資訊系統的回顧與展望：以
臺灣區域史研究為例” [Retrospect and Prospect: Application of Historical GIS to Taiwan Regional
History Studies in the Last 20 Years], 臺灣史研究 [Taiwan History Research] 21, no. 2 (2014): 171.
11
Trevor M. Harris, “From PGIS to Participatory Deep Mapping and Spatial Storytelling: An Evolving
Trajectory in Community Knowledge Representation in GIS,” The Cartographic Journal 53, no. 4
(2016): 322.
12
For more comprehensive histories of Google Street View, see Ben Campkin and Rebecca Ross,
“Negotiating the City through Google Street View,” in Camera Constructs: Photography, Architecture
and the Modern City, eds. Andrew Higgott and Timothy Wray (London: Ashgate, 2012); Dragomir
Anguelov et al., “Google Street View: Capturing the World at Street Level,” Computer 43, no. 6 (June
2010).
13
The working group includes four historians with their own research projects looking at visual materials
from different periods and of different types; see https://www.mpiwg-berlin.mpg.de/research/projects/tutu-local-gazetteers.
14
See http://image-net.org/challenges/LSVRC/.
15
Warren S. McCulloch and Walter Pitts, “A Logical Calculus of the Ideas Immanent in Nervous
Activity,” The Bulletin of Mathematical Biophysics 5, no. 4 (1943).
16
Martín Abadi et al., “Tensorflow: A System for Large-scale Machine Learning,” (paper, the 12th
USENIX Symposium, 2016), https://www.usenix.org/conference/osdi16/technicalsessions/presentation/abadi.
17
Yoon Kim, “Convolutional Neural Networks for Sentence Classification,” Proceedings of the 2014
Conference on Empirical Methods in Natural Language Processing (2014),
https://www.aclweb.org/anthology/D14-1181/.
18
Chūgoku Tairiku Gomanbun No Ichi Chizu shūsei, Vol. 1-8 (Tokyo: Kagaku Shoin, 1986).
19
Fuwu Luo, “Historical Development of Civil Engineering,” Architecture Technology 33 (2002): 460.
20
Translated from the Yuyao Local Gazetteer published in 1781: “Jiajing 36th year [1557]: Due to pirate
invasion, a new city was built on the south bank of Yao river. The old and new cities are connected by
Tongji Bridge, and the municipal administration expanded to cover both the south and north banks of Yao
river.”

13

