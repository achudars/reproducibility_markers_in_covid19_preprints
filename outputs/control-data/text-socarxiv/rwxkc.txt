Elements of a Design Theory of Nano-Viral Messages:
A Case Study of #Solar Nanovirals
Nick V. Flor
Marketing, Info. & Decision Sciences Dept.
University of New Mexico
nickflor@unm.edu
Abstract
Viral messages reach a large number of people at almost no cost. However, the
majority of viral messages are based on shocking or entertaining content. Is it
possible to make other kinds of content go viral, such as science and technology
news? I use conceptual blending analysis to analyze five representative, very small
messages about solar technology that went viral (nanovirals). I identify four distinct
viral strategies that vary according to the number of belief systems used, and
whether the viral message confirmed or contradicted central beliefs. Finally, I use
information systems modeling to depict a common viral mechanism underlying the
strategies. I conclude with a practical heuristic to guide the design of nanoviral
messages. The key finding is that messages spread virally because they confirm core
beliefs in an in-group’s shared belief system or they contradict core beliefs in an outgroup’s shared belief system.
Keywords: viral messages, viral advertising, viral marketing, word-of-mouth, memes,
design science, conceptual blending analysis, information systems modeling
Introduction
One of the challenges that technologists and scientists face is informing the general
public about their innovations and discoveries. One solution is to conduct a national
advertising campaign. However, for small businesses and most researchers, such
campaigns are prohibitively expensive.
One promising, and low-cost alternative to a national advertising campaign is to use
viral messages on social media to spread news about innovations and discoveries.
Viral messages can reach a wide audience in a relatively short amount of time, with
almost no cost except the time needed to develop the message. However, most
messages that go viral contain shocking or humorous content.
Figure 1 is an example of a typical viral message with shocking content that was
seen by over a hundred thousand individuals in a single day.
The research question I explore in this paper is: can you design a viral message
around technology content rather than shocking or entertaining content?
Technology content can include announcements of new technology, reports of
adoption, and both discoveries of the beneficial uses of technology, as well as
findings of the detrimental effects.
To answer the research question, I analyze tiny messages about solar technology
that have gone viral. Before describing the method, I review the literature on the

spreading of viral messages, and briefly clarify my distinction between viral
messages and nanovirals.

Figure 1. An example of a typical viral message (Michael, 2017).

Literature Review
Business and management researchers have explored a number of different issues
related to sharing viral messages including: motivation (Berger, 2014; Ho and
Dempsey, 2010; Pescher, Reichhart, and Spann, 2014); social network characteristics
(Bampo, Ewing, Mather, Stewart, and Wallace, 2008; Hinz, Skiera, Barrot, and
Becker, 2011; Leskovec, Adamic, and Huberman, 2007; Liu-Thompkins and
Rogerson, 2012; Smith, Coyle, Lightfoot, and Scott, 2007); interpersonal factors (Cho,
Huh, and Faber, 2014; De Bruyn and Lilien, 2008; Harvey, Stewart, and Ewing, 2011;
Hayes, King, and Ramirez, 2016); personality (Chiu, Hsieh, Kao, and Lee, 2007);
meta- and para-textual features (Blichfeldt and Smed, 2015; Seo, Li, Choi, and Yoon,
2018); and sharing mechanism details (Aral and Walker, 2011; Schulze, Schöler, and
Skiera, 2014).
Particularly relevant to this paper are the attributes of viral content. Message
content influences sharing behavior (San Jose-Cabezudo and Camarero-Izquierdo,
2012), with positive attitudes towards an advertisement’s content predicting
sharing (Ketelaar et al, 2016; Petrescu, Korgaonkar, and Gironda, 2015). More
specifically, people share messages with positive content more than negative
content, and messages that evoke high-arousal positive or high-arousal negative
emotions are shared more than articles that evoke low-arousal emotions (Berger
and Milkman, 2012; Heimbach and Hinz, 2016). Messages with strong emotional
content including humor, fear, sadness, or inspiration, are more likely to be shared
than those evoking other emotions (Phelps, Lewis, Mobilio, Perry, and Raman 2004).

The positive emotions of awe and affection specifically serve as triggers for active
viral sharing (Nikolinakou and King, 2018). Humorous message spread virally and,
when coupled with high levels of violence or severe consequences, result in higher
ad engagement and a higher chance of sharing (Brown, Bhadury, and Pope, 2010).
Generally, messages containing emotional appeals and emotion-evoking strategies
are more likely to be shared than information appeals that focus on product features
(Akpina and Berger, 2017). Finally, for highly interactive content like games,
playfulness increased viral sharing (Zhao and Renard, 2018).
The research in this paper builds on the extant literature, contributing to our
understanding of the types of content that go viral, with an emphasis on nanoviral
message content. Unlike the majority of the business and management research on
viral messages, which use correlational or experimental quantitative methods, I
employ a case-based, qualitative method. More case-based research is needed to
study social media topics (Gordon, 2016). Technology has given us innovative and
unprecedented ways to connect (Wadhwa & Palvia), and case-based research can
discover and document these mechanisms.
Background: Viral Messages and Nanovirals
A viral message is information that spreads freely from person-to-person within a
population often, but not necessarily, via social media. By “freely”, I mean that
people spread the information naturally — they do not have to be incentivized
artificially to do so. A single viral message can reach hundreds of thousands to
millions of people (see Figure 1).
Viral messages differ in length. Viral news articles and viral videos are on the high
end of the spectrum, and viral messages on micro-blogging, social media platforms
like Twitter are on the low-end. My research focuses on very small viral messages,
which I call nanoviral messages, or nanovirals for short. Figure 2 is an example of
the smallest nanoviral — a single emoji depicting an expressionless face.

Figure 2. The smallest viral message—a single emoji (Durant, 2017). “Nanovirals” are viral messages less than
several hundred characters.

While “very small” is relative, generally, nanovirals are distinguished from longer
viral messages in terms of length and operation — their length is typically less than
several hundred characters, and they rely more on retrieving existing experiences to
generate sudden insight, a process I call apperception shift, when compared to
longer viral message which focus on creating an experience in a receiver via
comprehension.

As suggested by Figure 2, where the text is only a single emoji, the key to a message
going viral is understanding the subtext of the message. A method is needed that
helps discover the subtext from the text of a message.
Method
One method used in cognitive linguistics for analyzing the underlying meaning, or
subtext, of a message is conceptual blending analysis (Fauconnier and Turner,
2002). It is based on the idea that people integrate elements of different beliefs
mentally, to arrive at the meaning of a statement. The aim of conceptual blending
analysis is to reconstruct how people mentally integrate elements of beliefs to arrive
at meanings. In business and management research, it has been applied to analyze
consumer aesthetics experience (Joy, Sherry, Mick, and Arnould, 2003), user
knowledge in online communities (Flor, 2006), meaning in advertisements (Joy,
Sherry, and Deschenes, 2009) and the generation of theories in organizational
management (Cornelissen and Durand, 2012; Oswick, Fleming, and Hanlon, 2011).
Figure 3 depicts conceptual blending analysis as a hybrid class-communication
model.

Figure 3. Conceptual blending analysis depicted as a hybrid class-communication model

Briefly, the unit of analysis is a statement. The analyst typically denotes the
statement in propositional form, using the rules of predicate calculus. For example,
the statement “Fred gave a rock to Wilma” in propositional form would be:
Gave(fred, wilma, rock), where Gave is the predicate, and fred, wilma, and rock are
terms.
Next, the analyst posits beliefs that the receiver of a message recalls in association
with the message. These beliefs are also denoted in propositional form. The beliefs
are put in a multi-column table, where each column denotes a mental space. Beliefs
that have common (or synonymous) predicates or terms, are said to have a
pragmatic connection, and are lined up row-wise in the table. Beliefs with pragmatic
connections are special because their elements (predicates and terms) can
substitute for one another in the blend.
Finally, the analyst selectively projects beliefs from the mental spaces into the
blended space (or simply the “blend”) to show the underlying meanings, the various
subtexts, of the original statement. The blend is usually the last row in the table. An
example should help clarify.
An Example of a Conceptual Blending Analysis
Table 1 depicts a conceptual blending analysis for the Kevin Durant tweet in Figure
2. The timestamp of the tweet indicates that he posted it during ESPN’s annual

award show, the ESPY. During this show the emcee, Peyton Manning, made fun of
Kevin Durant for switching teams in order to win a championship. When the camera
panned to Kevin Durant he was not smiling, suggesting that he was mad, but one
could not be certain based on the brief camera shot.
Table 1. Conceptual blending analysis for the Kevin Durant single-emoji tweet
Message (Tweet) Space
During(tweet, espy)

Belief (ESPY) Space
peyton-manning
kevin-durant
P1: MadeFun(peyton-manning,
kevin-durant)

ExpressionLess(emoji)

¬Smiling(kevin-durant)
R1: P1 & ¬Smiling(kevin-durant)
→ Mad(kevin-durant)

BLEND
// Subtext: Kevin Durant is mad at Peyton Manning
//
for making fun of him
//
//
Derived by substituting ExpressionLess(emoji) for
//
¬Smiling(kevin-durant), and projecting the substituted
//
rule, R1, into the blend:
P1 & Expressionless(emoji) → Mad(kevin-durant)

Propositions representing the message are shown in the left column: the message
(tweet) space. Possible beliefs retrieved by a reader, as a consequence of the tweet
occurring during the ESPY, are shown in the right column: the belief (ESPY) space.
This belief includes the rule that if Kevin Durant is not smiling, he must be mad: …
¬Smiling(kevin-durant) → Mad(kevin-durant). There is a pragmatic connection
between the expressionless emoji, ExpressionLess(emoji), and the proposition that
Kevin Durant is not smiling, ¬Smiling(kevin-durant). In the blend, the expressionless
emoji is substituted for this proposition, and readers of the tweet conclude that
Kevin Durant is mad at Peyton Manning, which confirms their belief from watching
the telecast.
Figure 4 depicts conceptual blending analysis as part of an iterative process for
generating hypotheses and building theories. While conceptual blending analysis is
a qualitative method, and the analyst’s descriptions are fundamentally interpretive,
by making the interpretations explicit and situating them within a logical
framework, like predicate calculus, one can derive hypotheses and theories that are
falsifiable and extendible by other researchers. This kind of exploratory research,
which concludes with models, hypotheses, and theories, contrasts with
confirmatory research, which often starts with models and hypotheses that are
informed by existing theories.

Figure 4. Communication-object diagram depicting conceptual blending analysis as part of an iterative process of
hypothesis and theory generation

Data & Apparatus
The data analyzed consisted of 330,827 tweets from the social media platform
Twitter containing the hashtag #solar. I used SMEDA (Flor, 2016) as the social
media scraping software. SMEDA is a custom module I wrote for Excel that scrapes
tweets into an Excel worksheet. In addition to scraping functions, it contains macros
for organizing and sorting tweet content, and for building social network edges.
SMEDA has been used by researchers in a variety of domains, including augmented
reality and video games (Li, Gupta, Zhang, & Flor, 2018), social media activism
(Sanchez, 2018), and e-learning (Gunawardena, Flor, Gomez, & Sanchez, 2016).
Procedure
SMEDA was run daily, over a two-month period, from July 1, 2017 to August 31,
2017. A total of 330,827 tweets were collected (N:330,827; µ: 5335.92 tweets per
day, σ: 1950.40). After the collection period, SMEDA was then used to sort tweets in
descending order based on the number of retweets (shares). Tweets containing
#solar, but unrelated to solar technology were thrown out. For example, there was a
Korean music group who had a singer named Solar, and who would tag their tweets
with #solar. All such tweets were deleted from the data set analyzed.
Procedure: Operationalizing Viral
Unlike viral messages containing entertaining or shocking content which receive
thousands of retweets, messages with the #solar hashtag never received over a
thousand retweets during the period scraped. Thus, rather than go with an absolute
value to classify a tweet as viral, I used a relative measure. Specifically, given the
author of a top-sorted tweet, I calculated the mean number of retweets over a week
and the standard deviation. If the number of retweets was over one standard
deviation, I defined that as viral for that author, and the tweet was analyzed.
Figure 5 depicts the specific hypothesis and theory building process for this
research. While conceptual blending analysis is a qualitative method, through
iteration and triangulation, viral hypotheses, design heuristics, and falsifiable
theories can result.

Figure 5. The iterative procedure using conceptual blending analysis on twitter viral messages

It is beyond the scope of this paper to show every top tweet analyzed. Thus, in the
results section I present just the analysis of five representatives of the top tweets.
Results
Representative 1: Fact Confirmation & Contradiction in Two Different Belief Systems
— Progressive Version
The first tweet analyzed is a finding from the DiCaprio Foundation (@dicapriofdn)
about the benefits of the solar industry to employment (see Figure 6). The literal
meaning of the text is clear: the solar industry hires more people involved in
generating electricity than the fossil fuel industries combined.

Figure 6. Viral message from @DiCaprioFDN (Dicaprio Foundation, 2017).

The tweet contains: hashtags for solar, electricity, oil, coal, and gas; a link to a
Forbes news article for more information; and a user tag for @cleantechnica. The

text of the tweet is taken from the title of the Forbes article that the tweet links to.
Hashtags help spread the tweet to users searching on those tags, and a user tag
displays the tweet on that user’s mention-timeline. Finally, there is a picture with a
bar chart showing the number of people employed in the solar industry versus the
fossil fuel industries. The picture sources the data to the Department of Energy.
As described in the method, I use conceptual blending analysis to discover possible
subtext underlying the literal meaning of the text (refer to Table 2). The left-hand
column contains propositions in predicate calculus form that correspond to the key
content of the tweet. The right-hand column contains beliefs, both predicates and
propositions (recall propositions are predicates filled-in with values), that the
reader of the viral message could recall in association with the text.
For example, the text mentions solar and fossil fuels. It is likely that readers will
think of the beliefs of proponents of both solar and fossil fuels. If the reader is a
renewable energy proponent, as many progressives are, a common belief is “solar is
more important than fossil fuels”, or in predicate calculus: Progressive(p) →
MoreImportant(solar, fossil). The opposite is true if the reader is a fossil-fuel
proponent, as many conservatives are: “fossil fuels are more important than solar”,
Conservative(c) → MoreImportant(fossil, solar). A reader may also recall general rules
suggested by the text, in this case, “if some product x is more important than some
other product y, more people will be employed making x than y”; in predicate
calculus form: MoreImportant(x, y) → More(Employed(x), Employed(y)).
Table 2. Conceptual blending analysis for the @DicaprioFdn message
Message Space
More(Employed(solar),
Employed(fossil))

Belief Space
Progressive(p) → MoreImportant
(solar, fossil)

Employed(solar, 373K)
Employed(fossil, 187K)

Conservative(c) → MoreImporant
(fossil, solar)
MoreImportant(x, y) → More
(Employed(x), Employed(y))

Blend Space: Agreement, Disagreement
// Fact from message
More(Employed(solar), Employed(fossil)) // fact in message
// Subtext 1: Progressives beliefs about solar energy are correct
//
via chaining to a proposition that agrees with fact
Progressive(p) → MoreImportant (solar, fossil-fuel) → More (Employed
(solar), Employed(fossil)) // agrees with fact in message
// Subtext 2: Conservatives beliefs about solar energy are incorrect
//
via chaining to a proposition that disagrees with fact
Conservative(c) → MoreImportant (solar, fossil-fuel) → More (Employed
(fossil), Employed(solar)) // disagrees with fact in message

In the blend space the reader projects the “fact”, or more precisely “a proposition
with high certainty due to the source”, that more people are employed in the solar
than in the fossil fuel industry. The reader chains the propositions for both
progressives and conservatives, with the general rule about product importance and

employment, yielding a proposition that agrees with the facts in the case of the
progressive belief, and disagrees with the facts in the case of the conservative belief.
Subtext confirming or discrediting widely-held, central beliefs is one of the most
common occurrences in nanoviral messages, where I define “central belief” in terms
of centrality in a network of propositions — a proposition that occurs in many of the
propositional chains that constitute a belief system, c.f., node centrality in social
networking theory. I call this the confirm and contradict strategy.
Representative 2: Fact Confirmation & Contradiction in Two Different Belief Systems—
Conservative Version
The next example is a discovery of the detrimental effects of solar technology. The
example shows a variation of the confirmation and contradiction strategy.
@AndrewCFollet’s viral message (see Figure 7) is about old solar panels causing
environment problems in China. Although lacking details about how the solar panels
are causing problems, the literal meaning of the text is clear. The structure of the
message is similar to the first one analyzed, namely, the user repeats the headline of
an article in the text, includes hashtags, links to an article, and tags users. However,
instead of creating hashtags from the title the user specified tcot (Top Conservatives
On Twitter), tlot (Top Libertarians On Twitter), and AGW (Anthropogenic Global
Warming). The picture caption elaborates on the meaning of “environmental crisis”,
stating that “Old Solar Panels … in two or three decades will wreck the
environment”.

Figure 7. Viral message from @AndrewCFollett (Follett, 2017).

As in the previous analysis, we can represent the key propositions from the message
in the left column of our conceptual blending analysis table (refer to Table 3), and
possible propositions in the right column. The bottom row blends elements from
both columns. The key proposition in the message text is: ¬Helps(OldSolar(panel),

Environment(china)). While the predicates Wrecks or Hurts could have been used
instead of ¬Helps, it saves time in the analysis from writing synonym propositions.
The possible beliefs include: old solar panels are solar panels; solar panels produce
solar energy; progressives believe that solar energy helps the environment;
conservatives believe the US should not focus on solar energy; and we should not
focus on energy technologies that harm the environment. These beliefs, stated as
propositions in predicate form, are in the right column.
Table 3. Conceptual blending analysis for the @AndrewCFollett message
Message Space
Environment(china)

Belief Space
Environment(us)

¬Helps (OldSolar(panel),
Environment(china))

Old(Solar(panel))→Solar(panel)
Solar(panel) → Solar(energy)
Progressive(p) →
Helps(Solar(energy),
Environment(us))
Conservative(c) →
¬Focus(Solar(energy))
¬Helps(x, Environment(x))→
¬Focus(x)

Blend Space: Contradiction & Confirmation
// Subtext 1: Old Solar Panels won’t help the US environment either
//
Derived via substitution from fact in Tweet space
¬Helps (OldSolar(panel), Environment(china)) →
¬Helps (OldSolar(panel), Environment(us)) // substitution
// Subtext 2: Solar Energy won’t help the US environment
//
Derived via substitution of Solar(Energy) for Solar(Panel)
Old(Solar(panel))→ Solar(panel) → Solar(energy)
¬Helps (Solar(energy), Environment(china)) // substitution
¬Helps (Solar(energy), Environment(us)) // substitution
// Subtext 3: Progressives are wrong about solar energy helping
//
the environment
Progressive(p) →
Helps(Solar(energy), Environment(us)) // contradicts Subtext 1
// Subtext 4: Conservatives are right not to focus on solar energy
¬Helps(x, Environment(x))→ ¬Focus(x)
¬Helps (Solar(energy), Environment(us)) → ¬Focus(SolarEnergy)
Conservative(c) → ¬Focus(SolarEnergy) // confirms belief

In the blend, the subtext includes: solar energy hurts the environment of the United
States; progressives are wrong about solar energy benefiting the environment; and
conservatives are right not to focus on solar energy. Unlike the previous example,
this viral message contains a proposition that contradicts a widely-held progressive
belief, while supporting a widely-held conservative one.
Although the details of the blending differ — both chaining propositions and
substituting elements of propositions — the outcome of the blending is the same: a
confirmation of a central belief in one belief system, and a contradiction of a central
belief in another, opposing, belief system.

Representative 3: Confirmation and Counterfactual in a Single Belief System
The third example announces the adoption of technology by a city. Some users were
particularly adept at creating viral messages. One user, @MikeHudema, often
started off his tweets with the phrase “As Trump tweets” (see Figure 8). In this case,
the literal meaning of the text, masks complex subtext aimed at denigrating the
current president via contrast with a former president. The structure of the tweet is:
message, hashtags, link to news article, and picture from news article. The hashtag
#resist refers to a movement consisting of individuals against current-president
Trump.

Figure 8. Viral message from @MikeHudema (Hudema, 2017)

In the message space (refer to Table 4, left column), you have two actors, Trump and
ex-president Jimmy Carter. There are also propositions that denote Trump tweets,
that Jimmy Carter built a solar farm, and that the solar farm powers half the city. In
the belief space (right column) you have the fact that Trump is president, and a
progressive belief that Trump tweeting is a useless activity. There is a pragmatic
connection between the solar farm powering half the city and the city using the
solar farm. Finally, you also have the general belief that if someone builds something
used by others, then the builder is useful.
Table 4. Conceptual blending analysis for the @MikeHudema message
Message Space
trump
Tweets(trump)
FormerPresident(carter)
Build(carter, Solar(farm))
Powers(Solar(farm), Half(city))

Belief Space
President(trump)
Progressive(p) →
Tweets(trump) →
Useless(trump)
Build(b,y)
Using(y, x)

Build(b,y) & Using(y,x) →
Useful(b)
Blend Space: Confirmation & Counterfactual
// Subtext 1: Current President is Useless
//
Derived by substitution into Progressive Tweets belief
Progressive(p)→ Tweets(trump)→ Useless(trump) →
Useless(President(trump))
// Subtext 2: Former president jimmy carter is useful
//
Derived by substituting predicate Power for Using
//
and parameter substitution
Build(carter, Solar(farm)) & Using(Solar(farm), Half(city)) →
Useful(carter) →
Useful(FormerPresident(carter))
// Subtext 3: if Trump built a solar farm he’d be useful
//
Derived by parameter substitution of Trump for Carter
//
and parameter substitution
Build(trump, Solar(farm)) & Using(Solar(farm), Half(city)) →
Useful(trump) // Counterfactual

The blend contains three pieces of subtext. The first is that the current president is
useless, which confirms a progressive belief. This is contrasted with the second
subtext, which states that the former president is useful. The second subtext is
important because it provides a kind of proof that progressives can cite if challenged
on why they believe the current president is useless. Finally, we know that people
constantly engage in counterfactual thought, and that it can result in negative
emotions like anger and regret (Roese, 1997; Epstude and Roese, 2008). The third
subtext is the counterfactual: if current-president Trump had only built a solar farm,
he would be useful.
Unlike the previous two examples — which employed two belief systems,
confirmations, and a contradictions — this viral message employed a single belief
system, confirmations, and a counterfactual. While one may argue that a
counterfactual is a contradiction, I reserve the use of counterfactual for those
contradictions involving the substitution of people and technologies in action
propositions that have positive or negative consequences. I call this the confirmation
and counterfactual strategy.
Representative 4: Wrong Economic Belief Indicating Technology Adoption
The fourth example reports an economic finding and depicts another common type
of viral message that employed economic subtext (see Figure 9). The literal
meaning is straightforward: renewable energy will be cheaper than fossil fuels
across the world in 3 years, according to the Morgan Stanley consulting firm. The
structure of this message is like the previous examples, with the exception that the
hashtags do not target specific political groups, and no other users are tagged.

Figure 9. Viral message from @OurCarbon (Ream, 2017).

The message space (refer to Table 5, left column) contains the proposition that the
price of wind and solar will be less than the price of price of coal and gas in three
years. The belief space (right column) includes the widely-held belief that
renewable energies like wind and solar will always be more expensive than fossilfuels, synonyms for renewables and fossil fuels, and the general belief that if the
price of two equivalent items are similar, one should adopt the least expensive item.
Table 5. Conceptual blending analysis for the @OurCarbon message
Message Space
Ɐc ∈ countries, t ∈ date+3,
Price(wind, solar, c, t) <
Price(coal, gas, c, t)

Belief Space
Ɐc ∈ countries
Price(wind, solar, c, ∞) >
Price(coal, gas, c, ∞)
wind, solar = renewables
coal, gas = fossil-fuels

Price(x)< Price(y) → adopt (x)
Blend
// Subtext: You are wrong to believe coal & gas are cheaper than
//
wind and solar
//
Derived by sample fact contradicting belief
Ɐt ∈ date+3, Price(wind, solar, c, t) < Price(coal, gas, c, t) // fact
Price(wind, solar, c, ∞) > Price(coal, gas, c, ∞) // contradiction
// Subtext: You should adopt renewables
//
Derived by equating wind & solar with renewables,
//
projecting the time conditions, and
//
substituting solar & renewables into general adopt rule
Ɐc ∈ countries, t ∈ date+3, Price(x)< Price(y) → adopt (x)

The blend contains two subtexts. First, that it is wrong to believe coal & gas will
always be cheaper than wind & solar; second, that renewables should be adopted in
three years.
In the case of this viral message, contradicting a widely-held belief leads to a
conclusion to adopt a technology. I label this strategy present economic case.
Representative 5: Argument from Majority
The final kind of viral message that one finds about solar, are those that provide
news about other groups of people creating, using, or adopting a technology. In this
example it is Australian households adopting solar panels (see Figure 10). The
structure of the message is similar to the previous example: text, hashtags, a link to
a news article, and a picture.

Figure 10. Viral message from @Takvera (Englart, 2017).

In the message space (see Table 6, left column) are the propositions derived from
the message, in particular that 25% Australian households have adopted solar
panels. When a person reads such a message, it is natural to think of beliefs that
compare or contrast the person’s own group to the other group. In predicate
calculus this is denoted by substituting predicates and parameters. Since the source
group was Australian households, if the reader is American, the reader thinks of
American households, and the fact that most American houses do not have solar
panels installed. Whether or not this is bad depends on if these households are part
of advanced nations, which in the case of Australia and America is true. Finally,
there is the general belief that if an advanced nation is behind another advanced

nation, it should catch up. Table 6, right column, summarizes potential propositions
in the belief space.
Table 6. Conceptual blending analysis for the @takvera message (assumes reader is American)
Message Space
Australian(households)

Belief Space
American(households)

Have(Australian (households),
Solar(panels), 25%)

Have(American (households),
Solar(panels), LessThan(25%))
Have(x,y,z) &
Have(a,y,LessThan(z) &
AdvancedNation(x) &
AdvancedNation(a) →
Behind(a,x,y)
Behind(a,x,y) → Catchup(a,y)

Blend
// Subtext: American households are behind Australian households
//
in adopting solar panels and should catch up
//
Derived by substitution and chaining
Have(Australian (households), Solar(panels), 25%) &
Have(American (households), Solar(panels), LessThan(25%)) &
AdvancedNation(Australian (households)) &
AdvancedNation(American (households)) → Behind(American
(households), Australian (households) Solar(panels)) →
Catchup(American(households), Solar(Panels))

In the blend, the subtext is that American households are behind Australians in
terms of solar panel adoption and, being an advanced nation, should catch up. The
viral message creates a new belief based on propositions from the message
combined with existing beliefs about progress. I label this strategy the catchup
strategy.
Discussion: Strategies & Common Mechanism
We have examined five different viral messages that appear to use four seemingly
different strategies. Next, we use systems modeling techniques to triangulate to a
common underlying viral mechanism that will serve as the basis for a design theory
of nanovirals.
Modeling: The Physical Dataflow
In systems analysis, physical dataflow diagrams depict a system as is, with the
agents (both actors and technologies) exchanging data. Initially I assumed a model
of viral messages with the following data flow (see Figure 11):

Figure 11. Initial physical dataflow diagram

However, the analysis showed that news about events in the world was a central
piece of every viral message. This news, created by some journalist and posted on a
news website, can be understood as an input to the viral writer, and a key element
of the viral creative process. Figure 12 depicts the revised diagram.

Figure 12. Revised physical dataflow diagram based on the analysis

This revised diagram includes the viral writer’s computer because it is a crucial tool
used by the writer to search and organize news, as well as to compose the viral
message. Note also that the diagram shows viral elements going from the writer to
social media rather than a viral message. This is because the analysis made it
apparent that social media formatted the final message viewed by users, which
included the user’s picture and information about date posted, retweets and likes.
From this diagram’s inputs and outputs, we can delineate four abstract processes to
model: event, news, viral creation, and viral spreading (see Figure 13). Finally,
although not depicted explicitly in the process model, social media provides an
input to the viral writer, serving as another source in the viral creation process.

Figure 13. The four processes to model. Messages from social media to the viral writer are implied but not shown.

To help construct a design theory of nanoviral messages, we will model two objects
in two separate processes: the social media user in the viral spreading process, and
the viral writer in the viral-creation process.
Modeling: The Social Media User in the Viral Spreading Process
Is there a common underlying mechanism in all the viral messages studied, which
we can model? The analysis suggests, yes.

One can represent a viral message as a set of propositions. These propositions,
through an associative mental process, retrieve beliefs from belief systems, which
one can also represent as propositions.
Some of these beliefs are central to belief systems, e.g., “renewal energy is better
than fossil fuel energy” in a progressive belief system, and vice-versa in a
conservative belief system. I term such beliefs central beliefs, or central
propositions. The intuition is that people use central beliefs to support explanations,
predictions or actions. One can use centrality formulas from networking analysis to
operationalize this term.
A social media user, given message propositions and central beliefs, will share a
message if at least one of the propositions confirms or contradicts a central belief
and the social media user determines that the confirmation or contradiction is not
shared by his or her followers.
Figure 14 captures the main objects and the main information exchanged between
objects.

Figure 14. Hybrid class-communication diagram for a social media user. The diagram depicts just two of many
possible belief systems.

Once shared, a message will continue to be shared if the belief systems of the
followers (the message receivers) are consistent with the those of the sharer. This is
likely why there are an abundance of political messages that go viral — progressive
and conservative belief systems are consistent across followers, who in turn have
followers with those belief systems.
A message can both confirm and contradict central beliefs in separate belief
systems, e.g., confirm a progressive belief while simultaneously contradicting a
conservative one and vice versa, as the first two analyses showed. The decision rule
for sharing is the same: if the sharer believes the confirmation and contradiction is
not believed by followers, the message is shared.
Modeling: The Viral Writer in the Viral Spreading Process
The conceptual blending analysis analyzed the viral messages from the standpoint
of a social media user reading them. While we did not analyze the viral creation
process, it is possible that the same mechanism for comprehending a viral message,

is used by a viral message writer to compose a viral message. Comprehension
drives composition.
The primary difference is in input and output. An event happens in the world, which
the viral writer either experiences directly or learns about via the news or social
media. The viral writer represents the events, news, or social media messages as
propositions, and if certain propositions confirm or contradict central beliefs, those
propositions along with the central beliefs are the ingredients of a potential viral.
The decision to compose a viral message from those ingredients is similar to the
sharing decision. A viral writer will create a viral message based on a contradiction
or confirmation if the viral writer determines it is not shared by his or her followers.
The process of composing a viral message takes the confirmation or contradiction
from the conceptual blending process and adds: supporting links, media (e.g.,
pictures and videos), user mentions, and hashtags. These viral elements are then
sent to social media.
Figure 15 depicts how the viral creation process can leverage the viral spread
process. To summarize, the viral message writer contextualizes information from
events, from news articles, or from social media messages (that may in turn be viral
messages the writer disagrees or agrees with), according to his or her belief
systems. The result is a tweet — containing a synthesis of propositions, links,
media, mentions, and hashtags — that when read by users may blend a confirmation
or contradiction in their own belief systems.

Figure 15. Hybrid class-communication diagram for a viral writer. This composition process leverages the same
conceptual blending & belief systems as the social media user.

Both the model of the user and the model of the viral writer depict conceptual
processing, with social media serving as a communication channel for the inputs
and outputs of this processing. This leads to the hypothesis that for spreading
information about a technology virally, regardless of the specific social media
platform, the underlying processes remain the same.
This paper analyzed representative viral messages about one particular technology,
solar, with the main finding and hypothesis that messages spread virally because they
confirm or contradict central beliefs in a belief system shared by a large number of
receivers. The belief systems included political (representatives 1-3), economic

(representative 4), and national advancement (representative 5). It is not
surprising that three of the five representatives leveraged political belief systems, as
the adoption of solar energy is a politically sensitive topic, and users with different
political affiliations hold different beliefs about the value of solar.
A key question is: does the viral process of confirming or contradicting central
beliefs apply to technologies that are less politically sensitive? This is an important
question to answer for companies that want to adopt a viral advertising strategy,
but do not want to alienate potential customers by posting messages with explicit
political content. Although it may be difficult to entirely separate the influence of
politics on beliefs, the last two solar representatives analyzed suggest the
hypothesis that there are belief systems, which are relatively neutral politically, that
one can leverage to promote technology virally. Although neutral, the analyses
showed that the confirmation or contradiction of central beliefs was still the
common underlying mechanism.
To summarize, this research established that there are ways to make messages
spread virally that do not rely on shocking or entertaining content, but rather on
content that users interpret as confirming or contradicting central beliefs in a
shared belief system. One might ask if there are similarities in process for viral
messages containing shocking or entertaining content. An attribute of shocking or
entertaining content is unexpectedness, which users would interpret as adding
beliefs to an existing belief system. I hypothesize that shocking or entertaining
content spreads virally because it adds — versus confirms or contradicts — useful
beliefs to shared belief systems.
Conclusion: A Heuristic and Future Research
In the old days of advertising, copywriters used formulas to help them write ads —
Attention-Interest-Desire-Action (AIDA) was one, Picture-Promise-Prove-Push
(PPPP) was another. There are analogous formulas for writing novels, screen plays,
and video games as well.
In the language of design science, these formulas are more properly thought of as
“heuristics”, because they don’t guarantee success so much as they help focus one’s
effort in generating and in sequencing ideas for composition.
My analysis suggested the following heuristic—Check, Confirm | Contradict,
Compose (CCCC):
•
•
•
•

Check for news and other events, and based on that news
Confirm central beliefs in shared belief systems, or
Contradict central beliefs in shared belief systems.
Compose viral message around the confirmation or contradiction, adding in
hash tags, mentions, media, and links.

The principle underlying the sharing of viral messages seems to be the conservation
of consistency in belief systems. Messages are shared because they confirm beliefs
that may be uncertain or, in the case of viral messages that show contradictions,

they point out inconsistencies that must be repaired to maintain a consistent belief
system.
Social media managers in firms can adapt the CCCC heuristic to promote
technologies by checking news daily for events that contain information, which
confirm or contradict central beliefs in the target demographics. Given a
confirmation or contradiction, they can compose a viral message around it, using
hashtags and @mentions for seeding, along with media and links for more
information. The main challenge for social media managers is developing a
psychographic profile of the target users’ belief systems.
The viral writer model in Figure 15 suggests several areas for future research, which
can help expand the theory. The first area is in terms of the source materials used
by viral writers. For my #solar tweets, the source material was always a news article
on some website. But the source could be a message read on social media from
another user, or an event experienced firsthand, or even a sudden realization of
some confirmation or contradiction in one or more belief systems.
The second area of future research is belief systems. How does one determine the
content of a group’s shared-belief system, and whether an individual is a member of
a group? Given the dynamically shifting nature of beliefs, analysts could benefit from
automated methods, which determine beliefs systems or group membership, based
on user profiles and postings, versus empirical survey methods. Metadata
associated with a post, including likes, shares, views, and other engagement data,
can help validate potential beliefs. Lastly, the viral messages analyzed in this paper
relied on just two belief systems. Studies of viral messages that use more than two
belief systems may suggest other viral design strategies.
Process is the third area of future research. The viral rule in the data analyzed was:
the confirmation or contradiction of central beliefs. But the data also showed
different ways for a news proposition to confirm a central belief, including early and
late in a causal chain of propositions. The same was true of contradictions,
especially in the use of counterfactual blends. More research is needed in specifying
the details through which central beliefs get confirmed or contradicted. Finally,
more research is needed to discover other rules beyond confirmation and
contradiction, e.g., the connection of central beliefs from different belief systems.
The last area is composition. Future research is needed to clarify steps in this
heuristic, especially the composition step. In particular, given a confirmation or a
contradiction, or some other rule, what is the best way to state it and to support it
with hashtags, mentions, media, and links. More research is needed on the role of
hashtags and mentions in making a message go viral, especially if the viral writer
does not have a large follower base.
In conclusion, I focused my analysis on viral messages for the hashtag #solar, in an
attempt to discover a way of spreading information virally about science and
technologies. I discovered that it was not the existence of a new discovery, or a new
innovation that made the news spread, nor was the spread due to a description of
how it worked, or what it could do for the reader. Rather, information spread if it
confirmed or contradicted widely-held, central beliefs. Furthermore, the belief

systems may have very little to do with the discovery or innovation, as was the case
with the progressive and conservative belief systems, which were political.
Scientists who want to spread discoveries may want to focus less on describing the
details of their findings, or less on describing future benefits, and more on how the
discovery confirms or contradicts existing, widely-shared belief systems, which may
not have much in common with the discovery.
There are many more kinds of viral messages to study: humorous and shocking
stories, political messages, picture memes, and many other categories — all far
more likely to go viral than technology and science messages. One can use the
method in this paper —a combination of conceptual blending analysis and
information systems modeling techniques — to analyze these other kinds of viral
messages as well and to help build a general theory of viral messages.
Acknowledgments
This material is based partly upon work supported by the National Science
Foundation (NSF) under CMMI –1635334. Any opinions, findings, and conclusions
or recommendations expressed in this material are those of the author and do not
necessarily reflect the views of the NSF.
References
Akpinar, E., & Berger, J. (2017). Valuable virality. Journal of Marketing Research, 54,
318–330.
Aral, S., & Walker, D. (2011). Creating social contagion through viral product design:
A randomized trial of peer influence in networks. Management Science, 57,
1623–1639.
Bampo, M., Ewing, M. T., Mather, D. R., Stewart, D., & Wallace, M. (2008). The effects
of the social structure of digital networks on viral marketing performance.
Information Systems Research, 19, 273–290.
Berger, J. (2014). Word of mouth and interpersonal communication: A review and
directions for future research. Journal of Consumer Psychology, 24, 586–607.
Berger, J., & Milkman, K. (2012). What makes online content viral? Journal of
Marketing Research, 49, 192–205.
Blichfeldt, B., & Smed, K. (2015). “Do it to Denmark”: A case study on viral processes
in marketing messages. Journal of Vacation Marketing, 21, 289–301.
Brown, M., Bhadury, R., & Pope, N. (2010). The impact of comedic violence on viral
advertising effectiveness. Journal of Advertising, 39, 49–66.
Chiu, H., Hsieh, Y., Kao, Y., & Lee, M. (2007). The determinants of email receivers’
disseminating behaviors on the internet. Journal of Advertising Research, 47,
524–534.

Cho, S., Huh, J., & Faber, R. (2014). The influence of sender trust and advertiser trust
on multistage effects of viral advertising. Journal of Advertising, 43, 100–114.
Cornelissen, J., & Durand, R. (2012). More than just novelty: Conceptual blending
and causality. Academy of Management Review, 37, 152–154.
De Bruyn, A., & Lilien, G. (2008). A multi-stage model of word-of-mouth influence
through viral marketing. International Journal of Research in Marketing, 25, 151–
163.
Dicaprio Foundation. (2017, August 1). #Solar Employs More People In U.S.
#Electricity Generation Than #Oil, #Coal And #Gas Combined
https://www.forbes.com/sites/niallmccarthy/2017/01/25/u-s-solar-energyemploys-more-people-than-oil-coal-and-gas-combinedinfographic/#24349f3e2800 … @cleantechnicapic.twitter.com/vU2z2u4EFn
[Tweet]. Retrieved May 28, 2019, from @dicapriofdn website:
https://twitter.com/dicapriofdn/status/892417404428460032
Durant, K. (2017, July 12). 😑 [Tweet]. Retrieved May 28, 2019, from @KDTrey5
website: https://twitter.com/KDTrey5/status/885318651728904192
Englart, J. (2017, July 8). Australians voting with their wallets: 25% of households
have installed #solar panels #renewables #climate
http://reneweconomy.com.au/one-quarter-of-australian-homes-now-havesolar-70886/ … [Tweet]. Retrieved May 28, 2019, from @takvera website:
https://twitter.com/takvera/status/883929972812808193
Epstude, K., & Roese, N. J. (2008). The functional theory of counterfactual thinking.
Personality and Social Psychology Review, 12, 168-192.
Fauconnier, G., & Turner, M. (2002). The way we think: Conceptual blending and the
mind's hidden complexities. New York: Basic Books.
Flor, N. (2006). Addressing the problem of content restrictions in online community
forums. Journal of Information Technology Case and Application Research, 8, 7–
33.
Flor, N. (2016). SMEDA — Social Media Exploratory Data Analytics Software. GitHub
Repository, https://github.com/professorf/smeda
Follett, A. (2017, August 1). Old Solar Panels Causing An Environmental Crisis In
China http://dailycaller.com/2017/08/01/old-solar-panels-causing-anenvironmental-crisis-in-china/?utm_source=site-share … Via @dailycaller #tcot
#solar @EnergyBrief #AGW #tlot [Tweet]. Retrieved May 28, 2019, from
@AndrewCFollett website:
https://twitter.com/AndrewCFollett/status/892432713667547136
Gordon, S. (2016). Prospects for case-based research on social media. Journal of
Information Technology Case and Application Research, 18, 193–199.

Gunawardena, C. N., Flor, N. V., Gómez, D., & Sánchez, D. (2016). Analyzing social
construction of knowledge online by employing interaction analysis, learning
analytics, and social network analysis. Quarterly Review of Distance Education,
17, 35-60.
Harvey, C., Stewart, D., & Ewing, M. (2011). Forward or delete: What drives peer-topeer message propagation across social networks? Journal of Consumer
Behaviour, 10, 365–372.
Hayes, J., King, K., & Ramirez, A. (2016). Brands, friends, & viral advertising: A social
exchange perspective on the ad referral processes. Journal of Interactive
Marketing, 36, 31–45.
Heimbach, I., & Hinz, O. (2016). The impact of content sentiment and emotionality
on content virality. International Journal of Research in Marketing, 33, 695–701.
Hinz, O., Skiera, B., Barrot, C., & Becker, J. (2011). Seeding strategies for viral
marketing: An empirical comparison. Journal of Marketing, 75, 55–71.
Ho, J., & Dempsey, M. (2010). Viral marketing: Motivations to forward online
content. Journal of Business Research, 63, 1000–1006.
Hudema, M. (2017, July 12). As Trump tweets, Former President Jimmy Carter Just
Built a #Solar Farm to Power Half His City http://buff.ly/2ugxJwV #renewables
#resistpic.twitter.com/6Kv0cVhLmo [Tweet]. Retrieved May 28, 2019, from
@MikeHudema website:
https://twitter.com/MikeHudema/status/885139695377797121
Joy, A., Sherry, J., & Deschenes, J. (2009). Conceptual blending in advertising. Journal
of Business Research, 62, 39–49.
Joy, A., Sherry Jr., J., Mick, D., & Arnould, J. (2003). Speaking of art as embodied
imagination: A multisensory approach to understanding aesthetic experience.
Journal of Consumer Research, 30, 259–282.
Ketelaar, P., Janssen, L., Vergeer, M., van Reijmersdal, E., Crutzen, R., & van ‘t Riet, J.
(2016). The success of viral ads: Social and attitudinal predictors of consumer
pass-on behavior on social network sites. Journal of Business Research, 69, 2603–
2613.
Leskovec, J., Adamic, L., & Huberman, B. (2007). The dynamics of viral marketing.
ACM Transactions on the Web, 1, 1-46.
Li, H., Gupta, A., Zhang, J., & Flor, N. (in press). Who will use augmented reality? An
integrated approach based on text analytics and field survey. European Journal
of Operational Research.
Liu-Thompkins, Y., & Rogerson, M. (2012). Rising to stardom: An empirical
investigation of the diffusion of user-generated content. Journal of Interactive
Marketing, 26, 71–82.

Michael, J. (2017, August 27). Believe it or not, this is a shark on the freeway in
Houston, Texas. #HurricaneHarvypic.twitter.com/ANkEiEQ3Y6 [Tweet].
Retrieved May 28, 2019, from @Jeggit website:
https://twitter.com/Jeggit/status/902048241646280704
Nikolinakou, A., & King, K. W. (2018). Viral video ads: Emotional triggers and social
media virality. Psychology & Marketing, 35, 715–726.
Oswick, C., Fleming, P., & Hanlon, G. (2011). From borrowing to blending: Rethinking
the processes of organizational theory building. Academy of Management
Review, 36, 318–337.
Pescher, C., Reichhart, P., & Spann, M. (2014). Consumer decision-making processes
in mobile viral marketing campaigns. Journal of Interactive Marketing, 28, 43–54.
Petrescu, M., Korgaonkar, P., & Gironda, J. (2015). Viral advertising: A field
experiment on viral intentions and purchase intentions. Journal of Internet
Commerce, 14, 384–405.
Phelps, J., Lewis, R., Mobilio, L., Perry, D., & Raman, N. (2004). Viral marketing or
electronic word-of-mouth advertising: Examining consumer responses and
motivations to pass along email. Journal of Advertising Research, 44, 333–348.
Ream, T. (2017, July 8). Yes! Morgan Stanley says #wind and #solar will beat #coal
and #natgas on price in almost every country in 3
years.http://www.businessinsider.com/solar-power-energy-renewablescheapest-power-says-morgan-stanley-2017-7 … [Tweet]. Retrieved May 28,
2019, from @ourcarbon website:
https://twitter.com/ourcarbon/status/883742030072922112
Roese, N. (1997). Counterfactual thinking. Psychological Bulletin, 121, 133-148.
Sánchez, D. (2018). Concientization among people in support and opposition of
President Trump. Educational Technology & Society, 21, 237-247.
San Jose-Cabezudo, R., & Camarero-Izquierdo, C. (2012). Determinants of openingforwarding e-mail messages. Journal of Advertising, 41, 97–112.
Schulze, C., Schöler, L., & Skiera, B. (2014). Not all fun and games: viral marketing for
utilitarian products. Journal of Marketing, 78, 1–19.
Seo, Y., Li, X., Choi, Y., & Yoon, S. (2018). Narrative transportation and paratextual
features of social media in viral advertising. Journal of Advertising, 47, 83–95.
Smith, T., Coyle, J., Lightfoot, E., & Scott, A. (2007). Reconsidering models of
influence: The relationship between consumer social networks and word-ofmouth effectiveness. Journal of Advertising Research, 47, 387–397.
Wadhwa, V., & Palvia, S. (2018). Is information technology hacking our happiness?
Journal of Information Technology Case and Application Research, 20, 151–157.

Zhao, Z., & Renard, D. (2018). Viral promotional advergames: How intrinsic
playfulness and the extrinsic value of prizes elicit behavioral responses. Journal
of Interactive Marketing, 41, 94–103.
Notes on contributors
Nick Flor is an Associate Professor of Information Systems at the University of New
Mexico, in the Anderson School of Management’s Department of Marketing,
Information Systems, Information Assurance, and Operations Management. His
research applies cognitive methods, exploratory data analytics, and visualizations to
study viral processes, informal learning, and dynamic organization on social media.
Dr. Flor’s work is published in journals, which include Communications of the ACM,
International Journal of Human-Computer Studies, and Knowledge-Based Systems. He
is author of the book Web Business Engineering by Addison-Wesley publishing. Dr.
Flor is principal or co-principal investigator on several Federal Grants, sponsored by
the National Science Foundation, the Defense Intelligence Agency, and Sandia
National Labs. He is director of the Research Analytics & Virtual Environments
Laboratory at UNM. Dr. Flor holds a PhD in Cognitive Science from the University of
California San Diego.

