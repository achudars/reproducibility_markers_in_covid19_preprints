Machine learning the computational cost of
quantum chemistry

arXiv:1908.06714v2 [physics.chem-ph] 19 Dec 2019

Stefan Heinen, Max Schwilk, Guido Falk von Rudorff, and O. Anatole von
Lilienfeld∗
Institute of Physical Chemistry and National Center for Computational Design and
Discovery of Novel Materials (MARVEL), Department of Chemistry, University of Basel,
Klingelbergstrasse 80, CH-4056 Basel, Switzerland
E-mail: anatole.vonlilienfeld@unibas.ch

1

Abstract
Computational quantum mechanics based molecular and materials design campaigns consume increasingly more high-performance compute resources, making improved job scheduling
efficiency desirable in order to reduce carbon footprint or wasteful spending. We introduce
quantum machine learning (QML) models of the computational cost of common quantum
chemistry tasks. For 2D non-linear toy systems, single point, geometry optimization, and
transition state calculations the out of sample prediction error of QML models of wall times
decays systematically with training set size. We present numerical evidence for a toy system
containing two functions and three commonly used optimizer and for thousands of organic
molecular systems including closed and open shell equilibrium structures, as well as transition
states. Levels of electronic structure theory considered include B3LYP/def2-TZVP, MP2/6311G(d), local CCSD(T)/VTZ-F12, CASSCF/VDZ-F12, and MRCISD+Q-F12/VDZ-F12. In
comparison to conventional indiscriminate job treatment, QML based wall time predictions
significantly improve job scheduling efficiency for all tasks after training on just thousands of
molecules. Resulting reductions in CPU time overhead range from 10% to 90%.

2

1

Introduction

allows to build extremely energy efficient exascale computers, by the end of the year. 7 Compute applications on such machines commonly
rely on schedulers optimizing the simultaneous
work load of thousands of calculations. While
these schedulers are highly optimized to reduce
overhead, there is still potential for application
domain specific improvements, mostly due to
indiscriminate and humanly biased run time estimates specified by users. The latter is particularly problematic when it comes to ensemble
set-ups characteristic for molecular and materials design compute campaigns with very heterogeneous compute needs of individual instances.
One could use the scaling behaviour of methods to get sorted lists w.r.t wall times and improve scheduling by grouping the calculations
by run time. For example the bottleneck of a
multi-configuration self-consistent field calculation (MCSCF) is in general the transformation
of the Coulomb and exchange operator matrices into the new orbital basis during the macroiterations. This step scales as nm4 with n the
number of occupied orbitals and m the number of basis functions. All Configuration Interaction Singles Doubles (CISD) schemes that
are based on the Davidson algorithm 8 scale formally as n2 m4 , where n the number of correlated occupied orbitals and m the number of
basis functions. 9 As these methods (and basis
sets) contain different scaling laws and geometry optimizations additionally depend on the
initial geometry, a more sophisticated approach
was applied: In this paper, we show how to use
quantum machine learning (QML) to more accurately estimate run times in order to improve
overall scheduling efficiency of quantum based
ensemble compute campaigns.
Since the early 90’s, an increasing number
of research efforts from computer science has
dealt with optimizing the execution of important standard classes of algorithms that occur
in many scientific applications on HPC platforms, 10–12 but also with predicting memory
consumption, 13 or, more generally, the computational cost itself (see Refs. 14,15 for two recent reviews). Such predictive models may even
comprise direct minimization of the estimated
environmental impact of a calculation as the

Solving Schrödinger’s equation, arguably one of
the most important compute tasks for chemistry and materials sciences, with arbitrary accuracy is a NP hard problem. 1 This leads to
the ubiquitous limitation that accurate quantum chemistry calculations typically suffer from
computational costs scaling steeply and nonlinearly with molecular size. Therefore, even if
Moore’s law was to stay approximately valid, 2
scarcity in compute hardware would remain a
critical factor for the foreseeable future. Correspondingly, chemistry and materials based compute projects have been consuming substantial
CPU time at academic high-performance compute centers on national and local levels worldwide. For example, in 2017 research projects
from chemistry and materials sciences used ∼25
and ∼35% of the total available resources at
Argonne Leadership Computing Facility 3 and
at the Swiss National Supercomputing Center (CSCS), 4 respectively. In 2018, ∼30% of
the resources at the National Energy Research
Scientific Computing Center 5 were dedicated
to chemistry and materials sciences and even
∼50% of the resources of the ARCHER 6 super computing facility over the past month
(May 2019). Assuming a global share of ∼35%
for the usage of the Top 500 super computers (illustrated in Figure 1) over the last 25
years, this would currently correspond to ∼0.5
exaFLOPS (floating point operations per seconds) per year. But also on most of the local
medium to large size university or research center compute clusters, atomistic simulation consumes a large fraction of available resources.
For example, at sciCORE, the University of
Basel’s compute cluster, this fraction typically
exceeds 50%. Acquisition, usage, and maintenance of such infrastructures require substantial financial investments. Conversely, any improvements in the efficiency with which they are
being used would result in immediate savings.
Therefore a lot of work is done to constantly
improve hardware and software of HPCs, e.
g. at the International Supercomputing Conference NVIDIA announced the support of the
Advanced RISC Machines (Arm) CPUs, which
3

target quantity in the model. 16 ML has already
successfully been applied, however, towards
improving scheduling itself, 17 or entire compute work flows. 18,19 Furthermore, a potentially
valuable application in the context of quantum
chemistry may be the run time optimization of
a given tensor contraction scheme on a specific
hardware by predictive modelling techniques. 20
Another noteworthy effort has been the successful run time modeling and optimization of a
self-consistent field (SCF) algorithm on various
computer architectures in 2011 21 using a simple
linear model depending on the number of retired instructions and cache misses. Already in
1996, Papay et al. contributed a least square fit
of parameters in graph based component-wise
run time estimates in parallelized self consistent
field computations of atoms. 22 Other noteworthy work in the field of computational chemistry
is the prediction of the run time of a molecular dynamics code, 23 or the prediction of the
success of density functional theory (DFT) optimizations of transition metal species as a classification problem by Kulik and coworkers. 24 In
the context of quantum chemistry and quantum mechanical solid state computations, very
little literature on the topic is found. This may
seem surprising, given the significant share of
this domain on the overall HPC resource consumption (cf. Figure 1). To the best of our
knowledge, there is no (Q)ML study that predicts the computational cost (wall time, CPU
time, FLOP count) of a given quantum chemical method across chemical space.
Today, a large number of QML models
relevant to quantum chemistry applications
throughout chemical space exists. 25–27 Common
regressors include Kernel Ridge Regression 28–33
(KRR), Gaussian Process Regression 34 (GPR),
or Artificial Neural Networks 33,35–39 (ANN). For
the purpose of estimating run times of new
molecules, and contrary to pure computer science approaches, we use the same molecular
representations (derived solely from molecular
atomic configurations and compositions) in our
QML models as for modeling quantum properties. As such, we view computational cost
as a molecular “quasi-property” that can be inferred for new, out-of-sample input molecules,

in complete analogy to other quantum properties, such as the atomization energy or the
dipole moment.
In general, a quantum chemistry SCF calculation optimizes the parameters of a molecular
wave function with a clear minimum in the selfconsistent system of non-linear equations. I. e.,
the computational cost of a single point quantum chemistry calculation should be a reasonably smooth property over the chemical space.
Pathological cases of SCF convergence failure
are normally avoided by the careful choice of the
quantum chemistry method for the single point
(SP) calculation of a given chemical system.
For geometry optimization (GO) and transition
state (TS) searches on the other hand it is much
harder to control the convergence, as a multitude of local minima and saddle points may exist on the potential energy surface defined by
the degrees of freedom of the atomic coordinates in the molecule.
We therefore first investigated the performance of ML models to learn the number of
discrete steps of common optimizers applied to
the minimum search of non-linear 2D functions
that are known to cause convergence problems
for many standard optimizers. In a second step,
we investigated the capabilities of QML to learn
the computational cost for a representative set
of quantum chemistry tasks, including SP, GO,
and TS calculations. To provide numerical evidence for hardware independence of the cost of
quantum chemistry calculations, we trained a
model on FLOPS as a “clean” measurement.

2

Data

All QML approaches rely on large training data
sets. Comprehensive subsets of the chemical
space of closed shell organic molecules have
been created in the past. The QM9 41 data
set of DFT optimized 3D molecular structures
was derived from the GDB17 42 data set of
Simplified Molecular Input Line Entry System
(SMILES) strings. 43,44 This data set contains
drug like molecules of broad scientific interest.
GDB17 is an attempt to systematically generate molecules as mathematical graphs based
4

Performance [petaFLOPS]

10

3

10

2

10

1

10

0

10

1

10

2

10

3

the fundamental question of learning computational cost of a non-linear optimization problem outside the added complexity of quantum
chemistry calculations. We then have generated measures of the computational cost associated to seven tasks which reflect variances of
three common use cases: single point (SP), geometry optimization (GO) and transition state
(TS) search calculations.

1.4 103 petaFLOPS

0.5 103 petaFLOPS

2.1

To demonstrate that it is possible to learn the
number of steps of an optimization algorithm,
we apply our machine learning method to two
cases from function optimization theory: quantifying the number of steps for an optimizer.
The functions in question are the Rosenbrock
function 59

Total
Chemistry and
Materials

2000

2010
Year

Toy System

2020

Figure 1: Compute resource growth of 500
fastest public supercomputers. 40 Estimated use
by chemistry and materials sciences corresponds to 35%, corresponding to 2017 usage on
Swiss National Supercomputing Center. 4

f (x, y) = (1 − x)2 + 100(y − x2 )2

(1)

and the Himmelblau function 60
f (x, y) = (x2 + y − 11)2 + (x + y 2 − 7)2 (2)

on rules of medicinal chemistry, removing the
bias of pre-existing building blocks in structure selection. QM9 itself is a well established benchmark data set for quantum machine
learning where many different ML models were
tested on 28,31,38,45–53 and also contains many
molecules which are commercially available and
reported on many chemical data bases. Further relevant data sets in the literature include,
among others, reaction networks, 54 closed shell
ground state organometallic compounds, 55 or
non-equilibrium structures of small closed shell
organic molecules. 56 Yet, regions of chemical
space that may involve more sophisticated and
costly quantum chemistry methods, such as
open shell and strongly correlated systems 57,58
or chemical reaction paths, are still strongly underrepresented. For this study, we first generated two toy systems of non-linear functions
known to be difficult for many standard optimization methods. We used KRR to predict
the number of optimization steps needed to find
the functions’ closest minimum for a systematically chosen set of starting points. The test
case of optimizing analytical functions explores

The fucntions are shown in the top row of Figure 4 b) and c). We applied three representative optimizers in their SciPy 1.3.1 61 implementation on both functions: the “NM” simplex algorithm (Nelder-Mead 62 ), the gradient
based “BFGS” algorithm, 63 and an algorithm
using gradients and hessians (Conjugate Gradient with Newton search “N-CG” 64 ). For every
function and optimizer we performed 10200 optimizations from different starting points on a
cartesian grid over the domain −5 ≤ x, y ≤ 5 in
steps of 0.1. The minimum of the Rosenbrock
function and the four minima of the Himmelblau function lie within this domain. Figure 4
b) row two, three, and four show a heatmap
of the number of optimization steps for NM,
BFGS, and N-CG, respectively, for Rosenbrock (left column) and Himmelblau (right column). Generally, the minimum searches on
the Himmelblau function required much fewer
steps (mostly reached after a few tens of iterations). While the gradient based optimizer
BFGS clearly outperforms NM for both functions, the N-CG optimization of the Rosen5

brock function did not converge with a iteration limit of 400 for a set of points in the region
of x < −0.5 and y > 2.5. A very small step
size for the N-CG algorithm implementation in
SciPy in the critical region is responsible for the
slow convergence.

2.2

timings are subject of a separate publication. 68
QM9SP
CC/TZ 3497 PNO-LCCSD(T)-F12/VTZF12 single point energy timings.
QMspinSP
MRCI 2732 single point calculations
using MRCISD+Q-F12/VDZ-F12. 69–72
Details of the calculation results other
than timings are subject of a separate
publication. 73

Quantum Data Sets

We have considered coordinates coming from
three different data sets (QM9, QMspin, QMrxn) corresponding to five levels of theory
(CCSD(T), MRCI, B3LYP, MP2, CASSCF)
and four basis set sizes. Molecules in the three
different data sets consist of the following:

QM9GO
B3LYP 3724 geometry optimization timings with initial B3LYP/6-31G* 74,75 geometries optimizing at the B3LYP/def2TZVP level of theory.

i) QM9 contains 134k small organic
molecules in the ground state local minima with up to nine heavy atoms which
are composed of H, C, N, O, and F. All coordinates were published in 2014. 41 Here,
we also report the relevant timings.

QMrxnGO
MP2 8148 geometry optimization timings on MP2/6-311G(d) level of theory.
QMspinGO
CASSCF 1595 CASSCF(2e,2o)[Singlet]/VDZF12 76,77 geometry optimization timings.
QMrxnTS
MP2 1561 timings of transition state
searches on MP2 level of theory.

ii) QMspin consists of carbenes derived from
QM9 molecules containing calculations of
the singlet and triplet state, respectively,
with a state-averaged CASSCF(2e,2o) reference wave function (singlet and triplet
ground states with equal weights). The entirety of this data set will be published elsewhere, here we only provide timings and
QM9 labels.

Further details on the data sets can be found
in section 1 of the supporting information (SI).
A distribution of the properties (wall times) of
the seven tasks is illustrated in Figure 2. Single
point calculations (the two QM9SP
CC tasks) and
the geometry optimization (task QM9GO
B3LYP )
have wall times smaller than half an hour. In
general, the smaller the variance in the data,
the less complex the problem and the easier it
is for the model to learn the wall times. For
geometry optimizations and more exact (also
more expensive) methods (task QMspinSP
MRCI
and QMspinGO
)
the
average
run
time
is ∼
CASSCF
9 hours. With a larger variance in the data the
problem is more complex (higher dimensional)
and the learning is more difficult (higher offset).

iii) QMrxn consists of reactants and SN 2 transition states of small organic molecules
with a scaffold of C2 H6 which was functionalized with the following substituents:
-NO2 , -CN, -CH3 , -NH2 , -F, -Cl and -Br.
The entirety of this data set will be published elsewhere, here we only provide timings and geometries.

2.3

Quantum Chemistry Tasks

2.4

The three data sets were then divided into the
seven following tasks for which timings were obtianed (See also Table 1):

Timings, Code, and Hardware

The calculations were run on three compute
clusters, namely our in-house compute cluster, the Basel University cluster (sciCORE) and
the Swiss national supercomputer Piz Daint at

QM9SP
CC/DZ 5736
65–67

PNO-LCCSD(T)-F12/VDZF12
single point energy timings. Details of the calculation results other than
6

Table 1: Seven tasks used in this work generated from three data sets (QM9, QMspin, QMrxn),
using three use cases (SP, GO, TS) on different levels of theory and basis sets.
QM9SP
CC/DZ

Task

QM9SP
CC/TZ

QMspinSP
MRCI

QM9GO
B3LYP

SP

Use case
QM9

Data set

QMrxnGO
MP2

QMspinGO
CASSCF

GO

QMrxnTS
MP2
TS

QMspin

QM9

QMrxn

QMspin

QMrxn

CCSD(T)

CCSD(T)

MRCI

B3LYP

MP2

CASSCF

MP2

VDZ-F12 78

VTZ-F12 78

VDZ-F12 78

def2-TZVP 79,80

6-311G(d) 81–83

VDZ-F12 78

6-311G(d) 81–83

Size

5736

3497

2732

3724

8148

1595

1561

Code

Molpro

Molpro

Molpro

Molpro

ORCA

Molpro

ORCA

Level
Basis set

3

22.5

Frequency [a.u.]

0.25

QM9SP
CC/DZ
QM9SP
CC/TZ
QM9GO
B3LYP

20.0

17.5

15.0

12.5

0.20

0.15

10.0

QMspinSP
MRCI
QMrxnGO
MP2
QMspinGO
CASSCF
QMrxnTS
MP2

3.1

5.0

0.05

2.5

0.1

0.3

0 10
Wall times [h]
0.00

Quantum Machine Learning

In this study, we used kernel based machine
learning methods which were initially developed
in the 1950s 88 and belong to the supervised
learning techniques. In ridge regression, the
input is mapped into a feature space and fitting is applied there. However, the best feature space is a priori unknown, and its construction is computationally hard. The “kernel
trick” offers a solution to this problem by applying a kernel k on a representation space R
that yields inner products of an implicit high
dimensional feature space: the Gram matrix elements k(xi , xj ) of two representations x ∈ R
between two input molecules i and j are the
inner products hi, ji in the feature space. For
example,


||xi − xj ||1
(3)
k(xi , xj ) = exp −
σ

0.10

7.5

0.0

Methods

20

Figure 2: Wall time distribution of all tasks
using kernel density estimation.
CSCS. We used two electronic structure codes
to generate timings. Molpro 84 was used to extract both CPU and wall times for data sets i)
and ii), and ORCA 85 was used to extract wall
times for data set iii). Further information of
the data sets, the hardware, and the calculations can be found in section 3 to 4 of the SI.
The retired floating point operations (FLOP)
count of the local coupled cluster calculation
task QM9SP
CC/DZ was obtained as follows: The
number of FLOPs have been computed with
the perf Linux kernel profiling tool 86 for data
set QM9SP
CC/DZ . perf allows profiling of the
kernel and user code at run time with little
CPU overhead and can give FLOP counts with
reasonable accuracy. FLOP count is an adequate measure of the computational cost when
the program execution is CPU bound by numerical operations, which is given in the PNOLCCSD(T)-F12 implementation 65–67,87 in Molpro.

or



||xi − xj ||22
k(xi , xj ) = exp −
2σ 2

(4)

α = (K + λI)−1 y

(5)

with σ as the length scale hyperparameter,
represent commonly made kernel choices, the
Laplacian (eq. 3) or Gaussian kernel (eq. 4).
Fitting coefficients α can then be computed in
input space via the inverse of the kernel matrix
[K]ij = k(xi , xj ):

7

training points used: 90

where λ is the regularization strength, typically
very small for calculated noise-free quantum
chemistry data.
Hence, kernel ridge regression (KRR) learns
a mapping function from the inputs xi , in this
case the representation of the molecule, to a
property yqest (xq ), given a training set of N reference pairs {(xi , yi )}N
i=1 . Learning in this context means interpolation between data points
of reference data {(xi , yi )} and target data
{(xq , yqest )}. A new property yqest can then be
predicted via the fitting coefficients and the kernel:
N
X
yqest (xq ) =
αi · k(xi , xq )
(6)

MAE ≈ a/N b

(7)

The learning curves should then result in a decreasing linear curve with slope b and offset
log a:
log(MAE) ≈ log(a) − b log(N )

(8)

where a is the target similarity which gives an
estimate of how well the mapping function describes the system 31 and b is the slope being
an indicator for the effective dimensionality. 91
Therefore, good QML models are linearly decaying, have a low offset log(a) (achieved by using more adequate representations and/or baseline models 92 ), and have steep slopes (large b).

i

For the toy systems, a Laplacian kernel was
used, the representation corresponding simply
to the starting point (x = (x, y)) of the optimization runs. For the purpose of learning of
the run times, we used two widely used representations, namely Bag of Bonds (BoB) 45 with
a Laplacian kernel. BoB is a vectorized version
of the Coulomb Matrix (CM) 28 that takes the
Coulomb repulsion terms for all atom to atom
distances and packs them into bins, scaled by
the product of the nuclear charges of the corresponding atoms. This representation does not
provide a strictly unique mapping 31,89 which
may deteriorate learning in some cases (vide
infra). The second representation used was
atomic FCHL 50 with a Gaussian kernel. FCHL
accounts for one-, two-, and three-body terms
(whereas BoB only contains two-body terms).
The one-body term encodes group and period
of the atom, the two-body term contains interatomic distances R, scaled by R−4 , and the
three-body terms in addition contain angles between all atom triplets scaled by R−2 .
To determine the hyperparameters σ and λ,
the reference data was split into two parts, the
training and the test set. The hyperparameters were optimized only within the training
set using random sub-sampling cross validation.
To quantify the performance of our model, the
test errors, measured as mean absolute errors
(MAE), were calculated as a function of training set size. The leading error term is known
to be inversely proportional to the amount of

For each task, QML models of wall times
were trained and subsequently tested on out-ofsample test set which was not part of the training. As input for the representations the initial
geometries of the calculations were used. To
improve the predictions of geometry optimizations for the task QMspinGO
CASSCF , we split
the individual optimization steps into the first
step (GO1) and the subsequent steps (GO2),
because the first step takes on average ∼20%
more time than the following steps (for more
details we refer to section 1.4 of the SI). For
learning the timings of the geometry optimization task GO2, we took the geometries obtained
after the first optimization step.
As input for the properties, wall times were
normalized with respect to the number of electrons in the molecules. Figure 3 shows the
wall time overhead (CPU time to wall time ratio) for calculations run with Molpro. To remove runs affected by heavy I/O, wall time
overheads higher than 3%, 5%, 10%, 30%, and
50% were excluded from the tasks QM9SP
CC/DZ ,
SP
SP
GO
QM9CC/TZ , QMspinMRCI , QMspinCASSCF ,
and QM9GO
B3LYP , respectively. In order to generate learning curves for all the seven tasks, all
timings were normalized with respect to the median of the test set to get comparable normalized mean absolute errors (MAE). The resulting
wall time out-of-sample predictions were used
8

inefficiencies for the scheduler since the individual wall time estimate of each job needs to be
(close to) the maximum job duration.
In the second approach, there are only few
jobs submitted to the scheduler and tasks are
executed in parallel as job steps. The first approach has little overhead with the jobs themselves but can lead to inefficiencies. The second approach yields inefficiencies due to lack
of load balancing. These two common methods
require no knowledge of the individual run time
of each task, and usually rely on a conservative
run time estimate in practice.

as input for the scheduling algorithm. Whenever the QML model predicted negative wall
times, the predictions were replaced by the median of all non-negative predictions.
All QML calculations have been carried out
with QMLcode. 93 Wall times and CPU times
(Molpro) and wall times (ORCA) for all the
seven tasks, as well as QML scripts can be
found in the SI.

QM9SP
CC/DZ
QM9SP
CC/TZ

80

60

QMspinSP
MRCI

7

6

5

3.2.2

4

40

Frequency [a.u.]

3

Scheduling Simulator

2

Using the QML based estimated absolute timings turns the scheduling of the remaining calculations into a bin packing problem. For this
problem we used the heuristic first fit decreasing (FFD) algorithm which takes all run time
estimates for all tasks, sorts them in decreasing order and chooses the longest task that fits
into the remaining time of a compute job (for
more details on FFD, see section 2 in the SI). If
there is no task left that is estimated to fit into
a gap, then no task is chosen and resources are
released early.
We implemented a job scheduling simulator
assuming idempotent uninterruptible tasks for
all three job schedulers: Conventional job arrays, conventional job steps, and our new QML
based job scheduler. Using a simulator is particularly useful because the duration of the job array and job step approaches depend on the (random) order of the jobs, and therefore requires
averaging over multiple runs. We used this simulator in the context of two environments: our
university cluster sciCORE (denoted S ) where
users are allowed to submit single-core jobs and
the Swiss national supercomputer (CSCS, denoted L) where users are only allowed to allocate entire compute nodes of 12 cores. In all
cases, we assumed that starting a new job via
the scheduler takes 30 seconds and that every
job queues for one hour. These numbers have
been observed for queuing statistics of sciCORE
and CSCS.

20

1

0

0

1.0

1.2

1

4.0

2

3

2.00

QM9GO
B3LYP

3.5

1.50

2.5

1.25

2.0

1.00

1.5

0.75

1.0

0.50

0.5

0.25

0.0

QMspinGO
CASSCF

1.75

3.0

0.00

1.0

1.5

5

10

Wall time overhead
Figure 3: Wall to CPU time ratio (using kernel
density estimation) for Molpro calculations to
identify runs with high wall time overhead due
to heavy I/O load on clusters.

3.2
3.2.1

Application: Optimal Scheduling
Job Array and Job Steps

In many cases, efforts in computational chemistry or materials design require the evaluation
of identical tasks on different molecules or materials. Distributing those tasks across a compute cluster is typically done in one of two
ways. When using job arrays, the scheduler
assigns compute resources to each calculation
separately, such that the individual calculation
is queued independently. This approach typically extends the total wall time, and has little
overhead with the jobs themselves but leads to
9

4
4.1

Results and Discussion

cussed, the learning of the corresponding CPU
times has also been investigated and results
of the latter are given in the SI. Figure 5
(left) shows the performance of QML models of
wall times using learning curves for the SP use
case. For the two similar tasks QM9SP
CC/DZ and
SP
QM9CC/TZ , the timings of the smaller basis
set was consistently easier to learn, i.e. smaller
training set required to reach similar predictive
accuracy. Similarly to physical observables, 50
the use of the FCHL representation results in
systematically improved learning curve off-set
with respect to BoB. It is substantially more
difficult to learn timings of multi-reference calculations (task QMspinSP
MRCI ), nevertheless,
learning is achieved, and BoB initially also exhibits a larger off-set than FCHL, but the learning curves of the respective two representations
converge for larger training set sizes. More
specifically, for training set size N = 1’600,
BoB/FCHL based QML models reach an accuracy of 3.1/1.8, 4.3/2.4, and 33.7/31.8 % for
SP
SP
QM9SP
CC/DZ , QM9CC/TZ , and QMspinMRCI ,
respectively. Corresponding respective average
wall times in our data-sets, distributions shown
in Fig. 2, average at ∼6, 15, and 480 minutes.
To the best of our knowledge, such predictive
power in estimating compute timings has not
yet been demonstrated for common quantum
chemistry tasks.
The extraordinary accuracy that our model
can reach in the prediction of the wall times
SP
for the QM9SP
CC/DZ and QM9CC/TZ quantum
chemistry tasks may be explained by the undlying quantum chemical algorithm. The tensor
contractions in the local coupled cluster algorithm are sensitively linked to the chemically
relevant many-body interactions expressed in
the basis of localized orbitals. Therefore, the
computational cost can be suitably encoded by
atom-based machine learning representations.
In order to investigate the relative performance of BoB vs. FCHL further, we have performed a principal component analysis (PCA)
on the respective kernels (training set size N =
2’000) for task QMspinSP
MRCI . The projection
onto the first two components is shown in Figure 6, color-coded by the training instance specific wall times, and with eigen-value spectra as

Toy System

From the total data set (10200 optimizations)
3200 were chosen randomly for every combination of optimizer and function and the prediction error was computed for different training
set sizes N . Figure 4 a) shows the learning
curves for the Rosenbrock (“Rosen”) and the
Himmelblau (“Him”) functions. Well behaved
learning curves were obtained for both functions and all optimizers. The ML models for
Him-BFGS and Him-N-CG have a lower offset
because the variance of the data set is smaller
(between 0 and 25 optimization steps) than for
the others (∼50-120 steps). The offset of RosenNewton-CG can be explained by the truncated
runs which caused a non smooth area in the
function space (x < −0.5 and y > 2.5) which
leads to higher errors.
In addition to the learning curves, we computed the relative prediction errors of the different optimization runs. These results are shown
in Figure 4 c). As expected, the errors get larger
when the starting point is close to a saddle
point: small changes in the starting point coordinates may lead to very different optimization
paths. These discontinuities naturally occur for
any optimizer based on the local information
at the starting point and can be consistently
observed in Figure 4 b). Additional discontinuities can also be observed depending on the
optimizer. For all these regions larger relative
errors for KRR can be observed [shown in Figure 4 c)] illustrating that small prediction errors
rely on a reasonably smooth target function. In
summary, we can show that KRR is capable
of learning the discrete number of optimization
steps which is a strong indication that the computational cost of quantum chemistry geometry optimization and transition state searches
should be learnable in principle .

4.2
4.2.1

Quantum Machine Learning
Single Point (SP) Wall Times

In the following, learning of the wall times for
the different quantum chemistry tasks is dis10

Figure 4: 2D non-linear toy systems consisting of the Rosenbrock (“Rosen”) and Himmelblau (“Him”)
functions and minimum search with three optimizers (Nelder-Mead (NM), BFGS, and Newton-CG
(N-CG)). a) Learning curves showing the prediction error of KRR for Rosen (solid lines) and Him
(dashed lines) function using starting point (x, y) as representation input. b) Top row shows the
function values for Rosen (left) and Him (right). Row two, three, and four show the number of
optimization steps (encoded in the heat map) for 10200 starting points for NM, BFGS, and N-CG,
respectively. c) Row two, three, and four show the relative prediction error of the ML model trained
on the largest training set size N = 3200 for NM, BFGS, and N-CG, respectively.
Table 2: QML results (normalized prediction errors) for seven task and both representations (BoB
and FCHL) for largest training set size (N max ).
Calculation

SP

GO

TS

Label

QM9SP
CC/DZ

QM9SP
CC/TZ

QMspinSP
MRCI

QM9GO
B3LYP

QMrxnGO
MP2

QMspinGO
CASSCF

QMrxnTS
MP2

Nmax

5000

3200

2000

3200

6400

1200

1000

BoB [%]

2.0

3.3

32.7

42.5

40.5

47.8

32.9

FCHL [%]

1.3

1.6

30.9

37.6

38.9

39.8

27.0

insets. For FCHL, the decay of the eigenvalues
is very rapid (tenth eigenvalue already reaches
0.1). From the PCA projection, the number
of heavy atoms emerges as a discrete spectrum
of weights for the first principal component.
The second principal component groups constitutional isomers. This reflects the importance
of the one-body terms in the FCHL representation. The data covers well both components
and the color various monotonically. All of
this indicates a rather low dimensionality in the
FCHL feature space which facilitates the learning. The kernel PCA plot of the FCHL representation shows that the learning problem is

smooth in representation space and that there
is a correlation between the property (computational cost) and the representation space. By
contrast, the BoB’s PCA projection onto the
first two components displays a star-wise pattern with linear segments which indicate that
more dimensions are required to turn the data
into a monotonically varying hypersurface. The
eigenvalue spectrum of BoB decays much more
slowly with even the 100th eigenvalue still far
above 1.0. All of this indicates that learning
is more difficult, and thereby explains the comparatively higher off-set.

11

SP

GO

64
100

32

MAE [%]

QM9GO
B3LYP
QMrxnGO
MP2
QMspinGO
CASSCF

8

QMrxnTS
MP2

60

80

QM9SP
CC/DZ
QM9SP
CC/TZ
QMspinSP
MRCI

16

TS

80

60

40

4
2
10

2

10

N

30

40
2
10

3

10

N

3

10

2

N

10

3

Figure 5: Learning curves showing normalized test errors (cross validated MAE divided by median
of test set) for seven tasks using BoB (solid) and FCHL (dashed) representations. The model was
trained on wall times normalized w.r.t. number of electrons. Horizontal lines correspond to the
performance estimating all calculations have mean run time (standard deviation divided by mean
wall time of the task).

BoB

FCHL
0.7

20

0.6

0

15

0.5
0.4

2 100
0

100
No. of EV

00

40

00

00

PCA 1

5

0 100
No. of EV

30

0

103
100

20

2

0.3

10
EV [a.u.]

EV [a.u.]

1 101

Wall time [h]

PCA 2

1

Figure 6: PCA plots of kernel elements for
BoB (left) and FCHL (right) for data set
QMspinSP
MRCI . The weights of the two first
principal components for the molecules in the
data sets are plotted against each other and
corresponding wall times are encoded as a heat
map. Insets show the first 100 eigenvalues on a
log scale.
4.2.2

Geometry Optimization
Wall Times

(GO)

Learning curves in Figure 5 (middle) shows
that it is, in general, possible to build QML
12

models of GO timings for the tasks considered. We obtained accuracies for BoB/FCHL
for N = 800 of 50.0/43.3, 61.7/57.6, and
GO
50.7/41.2% for tasks QM9GO
B3LYP , QMrxnMP2 ,
and QMspinGO
CASSCF , respectively.
Interestingly, the comparatively larger off-set
in the learning curves, however, indicates that
it is more difficult to learn GO timings than SP
timings. This is to be expected since GO timings involve not only SP calculations for various geometries but also geometry optimization
steps. In other words, the QML model has to
learn the quality of the initial guesses for subsequent GO optimizations. This can not be
expected to be a smooth function in chemical
space. Furthermore, the mapping from an initial geometry (used in the representation for the
QML model) to the target geometry can vary
dramatically when the initial geometry happens
to be close to a saddle point (or a second order saddle point in the case of TS searches, see
next section): Very slight changes in the initial geometry (or in the setup of the geometry
optimization) may lead to convergence to very
different stationary points on the potential energy surface. This makes the statistical learning

problem much less well conditioned than for single point calculations, which also reflects in the
larger variance of the geometry optimization
timings compared to single point calculations.
As such, GO timings represent a substantially
more complex target function to learn than SP
timings. Note that for any task (even for the
toy system applications) we require a different
QML model. The cost of the GO depends on
the initial geometry and the convergence criteria. The latter varies only slightly within a
data set. The former is part of the representation of the molecular structure and therefore
captured by our model. The input structures
for the task QMrxnGO
MP2 are derived from the
same molecular skeleton and are therefore very
similar. The same holds for task QM9GO
B3LYP
and QMspinGO
which
are
derived
from
CASSCF
QM9 molecules. The convergence criteria also
stay the same for all calculations within a data
set and would only cause a more difficult learning task if a machine was trained over several
different data sets. We also showed with the toy
system that it is possible to learn the number
of steps for different optimizer starting from different areas on the surface (see Figure 4 b)). To
further improve the performance of our model
of task QMspinGO
CASSCF , we split the GO into
the first GO step (GO1) and all subsequent
steps (GO2). This choice has been motivated
by our observation that most of the variance
stemmed from the first GO step (requiring to
build the wave-function from scratch), while the
subsequent steps for themselves have a substantially smaller variance. The resulting learning
curves are shown in Figure 7 and justify this
separation in leading to an improvement of the
QML model to reach errors of less than 25% at
N = 800 (rather than more than 40%), as well
as further improved job scheduling optimization
(shown below in Figure 10).
4.2.3

GO1
45

QMspinGO
CASSCF

60
50

GO2
QMspinGO
CASSCF

MAE [%]

40

35

30

25
20
2
10

20

N

10

3

15 2
10

N

10

3

Figure 7: Learning curves showing normalized
test errors (cross validated MAE divided by median of test set) for the first two geometry optimization steps on task QMspinGO
CASSCF using BoB and FCHL as representations. The
model was trained on CPU times divided by
the number of electrons. Horizontal lines correspond to the performance estimating all calculations have mean run time (standard deviation
divided by the mean wall time of the data set).
and reduced the off-set by ∼ 10% compared to
learning curves for the GO use case. As already
discussed in the previous section, the run time
of GO and TS timings not only scales with the
number of electrons but also depends on the initial structure. For the transition state search,
the scaffold (which is close to a transition state)
was functionalized with the different functional
groups. Since the initial structures were closer
to the final TS the offset of the learning curves
is lower than for learning curves of the GO use
case, where the initial geometries were generated with a semi empirical method (PM6) for
task QMrxnGO
MP2 , carbenes were derived from
QM9 molecules for task QMspinGO
CASSCF , and
GO
geometries for task QM9B3LYP were obtained
with a different basis set.
A summary of the results for all tasks for the
largest training set size (N max ) can be found in

Transition State (TS) Wall Times

Transition state search timings were slightly
easier to learn than geometry optimization timings (see Figure 5 (right)). Particularly for
the larges training set size (Nmax = 1000) for
BoB/FCHL we obtained MAEs of 32.9/27.0%
13

Table 2.
4.2.4

4.2.5

Single Point (SP) FLOPs

To provide unequivocal numerical proof that
it is justifiable to learn wall times we applied our models to FLOP counts for the task
QM9SP
CC/DZ , shown in Figure 8. FLOP count
as a “clean” measurement (almost no noise) for
computational cost was slightly easier to learn
than wall times and the learning curves show
similar behaviour: The model trained on the
same task QM9SP
CC/DZ reaches ∼4% MAE already with just 400 training samples, while
∼1000 training samples were required in the
case of wall times using BoB. For FCHL, the
performance is similar but the slope is steeper
for the FLOP model which indicates a faster
learning or less noise.

Timings, Code, Hardware

Regarding hardware dependent models, within
one data set we only used one electronic structure code which is also consistent with the general handling of the data set generation. The
noise that is generated using different infrastructures affects the learning only in a negligible
amount in our case, since the difference in hardware capabilities is minimal. When looking at
the task QMrxnTS
MP2 where we used five different CPU types on two clusters (Table 1 in the
SI), we could not find any evidence that different hardware affects the learning compared to
other GO tasks that ran on only one CPU type
and cluster. However the hardware for these
calculations is still very similar. When it differs to a greater extant, the noise level will rise.
The noise does not only depend on the cluster itself but also on other calculations running
on the cluster which is non-deterministic and
will limit the transferability of the ML models.
For this reason we removed some of the timings
with large I/O overhead using Figure 3. For
the QM9SP
CC tasks, the run time difference using the Intel MKL 2019 library 94 and OpenBlas
0.2.20 95 were computed for a few cases and are
found to be only within a few percents of the
wall time. Furthermore, run times of a native
build of the Molpro software package version
2018.3 with OpenMPI 3.0.1, 96 GCC 7.2.0, 97
and GlobalArrays 5.7 98,99 and the shipped executable were compared and yielded run times
within a few percents of difference. The FLOP
calculations on the QM9SP
CC data set have been
performed on a compute node with 24 processors [Intel(R) Xeon(R) CPU E5-2650 v4 @
2.20GHz (Broadwell)]. The significant part of
the FLOP clock cycles constituted of vectorized double precision FLOP on the full 256 bit
FLOP register, i. e. the essential numerical operations of the quantum chemistry algorithm
were directly measured. Hence, FLOP count
constitutes a valuable measure of the compute
cost in our case. 100 We anticipate that Hardware specific QML models will be used in practice.

BoB

MAE [%]

16

FLOPS
Wall times

FCHL
16

FLOPS
Wall times

8

8

4
3

4
3

2

2

101 102 103

N

101 102 103

N

Figure 8: Learning curves showing normalized
prediction errors (cross validated MAE divided
by median of test set) for FLOP count and
wall times on task QM9SP
CC/DZ using BoB and
FCHL representations.

4.3
4.3.1

Application: Optimal Scheduling
Job Array and Job Steps

For the scheduling optimization for all
seven tasks (QM9SP
QM9SP
CC/DZ ,
CC/DT ,
SP
GO
QMspinMRCI , QM9B3LYP , QMrxnGO
MP2 ,
14

QMspinGO
QMrxnTS
the QML
CASSCF ,
MP2 ),
model with the best representation (lowest MAE with maximum number of training
points) was used which in all cases was FCHL.
For the FFD algorithm absolute timing predictions are needed to make good decisions.
The lower panel of Figure 9 shows the accuracy
of the QML predictions. While the individual predictions (absolute not relative) are in
many cases not perfect and partially still exhibit a significant MAE (cf. Figure 5), this
level of accuracy is already sufficient to reduce
the overhead of the job scheduling. The lower
panel of Figure 9 shows the accuracy of the
QML predictions. While the individual predictions (absolute not relative) are in many cases
not perfect and partially still exhibit a significant MAE (cf. Figure 5), this level of accuracy
is already sufficient to reduce the overhead or
the wall time limits of the job scheduling. In
particular, in the limit of a large number of
cores working in parallel, our approach typically halved the computational overhead (data
sets with closed shell systems and TS searches)
while also reducing the time to solution by reducing the total wall time. This shows that
for the scheduling efficiency problem, it is not
required to obtain perfect estimates for the individual job durations, but rather reasonably
accurate estimates. However, if there was the
need for better accuracy, by virtue of the ML
paradigm (prediction error decay systematically with training set size) this could easily
be accomplished by decreasing the error simply
through the addition of more training data.
When comparing the different methods in the
upper panel of Figure 9, we see that the job array approach had no overhead for cases where
single-core jobs can be submitted separately.
While this is true it means that every job needs
to wait in the queue again, thus increasing the
total time to solution. For large task durations,
this effect is less pronounced but typically the
job array approach doubles the wall time which
renders this approach unfavourable.
Using job steps alone becomes inefficient if
the task durations are long, since the assumption that all tasks are roughly of identical duration will mean that interruptions of unfinished

calculations occur more often. Having a more
precise estimate allows for more efficient packing. This becomes important on large compute clusters where only full nodes can be allocated: In this case, the imbalance of the durations of calculations running in parallel further increases the overhead. Our method typically gave a parallelization overhead of 10-15%
for a range of data sets. For example, in the
task QMrxnGO
MP2 , our approach allowed us to
go to two orders of magnitude more compute resources and have the same overhead as job step
parallelization. This is a strong case for using
QML based timing estimates in a production
environment – in particular, since the number
of training data points required is very limited
(see Figure 5).
4.3.2

Geometry Optimization Steps

Given that the number of steps of a geometry
optimization is difficult to learn (see lower panel
of Figure 9), the ability to accurately predict
the duration of a single geometry optimization
step allows to increase efficiency via another
route. On hybrid compute clusters, the maximum duration of a single compute job is limited. We suggest to check during the course of
a geometry optimization whether the remaining time of the current compute job is sufficient
to complete another step. If not, it is more efficient to relinquish the compute resources immediately rather than committing them to the
presumably futile undertaking of computing the
next step. We refer to these strategies as the
“simple approach” (take all CPU time you can,
give nothing back) and the “QML approach”
(give up resources early). Figure 10 shows the
advantage of the QML approach: it allows to go
towards shorter compute jobs and reduces the
CPU time overhead by up to 90% for small wall
time limits using the job array approach. This
is more efficient for the scheduler and increases
the likelihood of the job being selected by the
backfiller, further shortening the wall time. Using the QML approach does not severely affect
the wall time, i.e. the time-to-solution. This
is largely independent of the extent of parallelization employed in the calculation (see right
15

ML L

Estimated
Duration

CPU Time
Overhead [%]

QMrxnGO
MP2/ 24h

Job Steps L
QMrxnTS
MP2/ 24h

Job Array L
QM9SP
CC/DZ/

2h

QM9SP
CC/TZ/

ML S
6h

QM9GO
B3LYP/

Job Steps S
2h

Job Array S

GO
QMspinSP
MRCI/ 24h QMspinCASSCF/ 24h

40
20
0
2 8 32 128 2 8 32 128 2 8 32 128 2 8 32 128 2 8 32 128 2 8 32 128 2 8 32 128
# nodes or cores
mean:
mean:
mean:
mean:
mean:
mean:
mean:
3.2h
3.4h
4.8m
14.5m
4.4m
7.5h
4.1h

7h

18h

5h

12h

2m

6m

6m 16m
Real Duration

15m 36m

7h

18h

5h

13h

Figure 9: Scheduling efficiencies for the seven different tasks (columns) assuming a certain perjob wall time limit specified in column title. Infrastructure assumptions correspond to either a
large (solid lines, L) compute center or a small (dashed lines, S) university compute center. Top
row reports CPU time overhead reduction when using the QML based (blue) rather than the
conventional (green, orange) packing. Results are given relative to the total CPU time needed
for the calculations of each data set for established methods (job array and jobs steps, see text)
and our suggested method (QML). Bottom row shows actual vs. predicted times (using FCHL as
representation) for all calculations in each data set using maximum training set size.

16

ML
simple

10
5
0

0

10
20
Wall time Limit [h]

Walltime / ML Walltime

CPU Time Overhead [%]

15

0

1 core
4 cores
8 cores
16 cores

10
20
Wall time Limit [h]

tional cost is learnable by QML models, it is
a reasonably smooth function in the variety of
chemical spaces that we considered. This is a
fundamental result.
Our approach succeeds in estimating realistic timings of a broad variety of representative calculations commonly used in quantum
chemistry work-flows: single-point calculations,
geometry optimizations, and transition state
searches with very different levels of theory and
basis sets. The machine learning performance
depends on the quantum chemistry method
and on the type of computational cost that is
learned (FLOP, CPU, wall time). While the accuracy of the prediction is shown to be strongly
dependent on the computational method, we
could typically predict the total run time with
an accuracy between 2% and 30%.
Exploiting QML out-of-sample predictions,
we have demonstrably used compute clusters
more efficiently by reordering jobs rather than
blindly assuming all calculations of one kind to
fit into the same time window. Without significant changes in the time-to-solution, we reduced the CPU time overhead by 10% to 90%
depending on the task. With the scheme presented in this work, compute resource usage can
be significantly optimized for large scale chemical space compute campaigns. To support this
case, all relevant code, data, and a simple-touse interface is made available to the community online. 101
We believe that our findings are important
since it is not obvious that established QML
models, designed for estimating physical observables, are also applicable to more implicit
quantities such as computational cost.

1.1
1.0
0.9

Figure 10: CPU time overhead and wall time
for geometry optimizations compared between
the simple approach and the QML approach.
See text for details of the strategies. CPU time
overhead given in percent relative to the bare
minimum of CPU time needed. Wall time given
relative to the wall time resulting from using
the QML approach. All geometry optimizations
come from task QM9GO
CASSCF .
hand side plot in Figure 10). We suggest to implement an optional stop criterion in quantum
chemical codes where an external command can
prematurely stop the progress of the geometry
optimization to be resumed in the next compute job. This change can drastically improve
computational efficiency on large scale projects.
Estimating the current consumption to be on
the order of at least 5·105 petaFLOPS (see discussion above in section 1) for computational
chemistry and materials science this approach
may lead to potentially large savings in economical cost.

5

Conclusion

We have shown that the computational complexity of quantum chemistry calculations can
be predicted across chemical space by QML
models. First we looked at a 2D non-linear toy
system consisting of example functions which
are known to be difficult to optimize. Using
these test functions and three optimizers, we
build a first ML model and the learning curves
show that it is possible to learn the number of
optimization steps using only the starting position (x, y). Representations are designed to
efficiently cover all relevant dimension in the
given chemical space. Hence, if the computa-

Acknowledgement
M. S. would like to acknowledge Dr. Peter
Zaspel for helpful discussions on the FLOP
measurement and the setup of the native program builds. This work was supported by
a grant from the Swiss National Supercomputing Centre (CSCS) under project ID s848.
Some calculations were performed at sciCORE
(http://scicore.unibas.ch/) scientific computing core facility at University of Basel. We
17

acknowledge funding from the Swiss National
Science foundation (No. 407540_167186 NFP
75 Big Data, 200021_175747) and from the
European Research Council (ERC-CoG grant
QML). This work was partly supported by the
NCCR MARVEL, funded by the Swiss National
Science Foundation.

real-symmetric matrices. J. Comp. Phys.
1975, 17, 87 – 94.
(9) Sherrill, C. D. Computational Scaling of the Configuration Interaction
Method with System Size. 1996;
http://vergil.chemistry.gatech.
edu/notes/ciscale/ciscale.html,
Accessed: 03/06/19.

Data availability statement
Any data (except the carbene data set) that
support the findings of this study are included
within the article. The carbene data set is available from the corresponding author upon reasonable request.

(10) Singh, K.; Ipek, E.; McKee, S. A.;
de Supinski, B. R.; Schulz, M.; Caruana, R. Predicting parallel application
performance via machine learning approaches. Concurrency and Computation: Practice and Experience 2007, 19,
2219–2235.

References

(11) Malakar, P.; Balaprakash, P.; Vishwanath, V.; Morozov, V.; Kumaran, K.
Benchmarking Machine Learning Methods for Performance Modeling of Scientific Applications. 2018 IEEE/ACM Performance Modeling, Benchmarking and
Simulation of High Performance Computer Systems (PMBS). 2018; pp 33–44.

(1) Garey, M. R.; Johnson, D. S. Computers
and Intractability; A Guide to the Theory
of NP-Completeness; W. H. Freeman &
Co.: New York, NY, USA, 1990.
(2) Track, E.; Forbes, N.; Strawn, G. The
End of Moore’s Law. Comput. Sci. Eng.
2017, 19, 4–6.

(12) Wang, Y.; Qiao, J.; Lin, S.; Zhao, T. An
Approximate Optimal Solution to GPU
Workload Scheduling. Comput. Sci. Eng.
2018, 20, 63–76.

(3) Argone Leadership Computing Facility, https://www.alcf.anl.gov/, Accessed: 05.06.2019.
(4) Swiss
National
Supercomputing Center, Annual Report 2017,
https://www.cscs.ch.,
Accessed:
26.04.2019.

(13) Rodrigues, E. R.; Cunha, R. L.;
Netto, M. A.; Spriggs, M. Helping HPC
users specify job memory requirements
via machine learning. 2016 Third International Workshop on HPC User Support Tools (HUST). 2016; pp 6–13.

(5) National
Energy
Research
Scientigic
Computing
Center,
https://www.nersc.gov/., Accessed:
02.06.2019.

(14) Witt, C.; Bux, M.; Gusew, W.; Leser, U.
Predictive performance modeling for distributed batch processing using black box
monitoring and machine learning. Information Systems 2019, 33–52.

(6) Archer,
http://www.archer.ac.uk/,
Accessed: 05.06.2019.
(7) NVIDIA
enabling
new
path
to
exascale
supercomputing,
https://nvidianews.nvidia.com,
Accessed: 24.06.2019.

(15) Nemirovsky,
D.;
Arkose,
T.;
Markovic, N.; Nemirovsky, M.; Unsal, O.; Cristal, A.; Valero, M. A general
guide to applying machine learning to
computer architecture. Supercomputing
Frontiers and Innovations 2018, 5,
95–115.

(8) Davidson, E. R. The iterative calculation of a few of the lowest eigenvalues
and corresponding eigenvectors of large
18

(16) Garg, S. K.; Yeo, C. S.; Anandasivam, A.; Buyya, R. Environmentconscious scheduling of HPC applications
on distributed cloud-oriented data centers. J. Parallel Distrib. Comput. 2011,
71, 732–749.

TADSim: Discrete event-based performance prediction for temperatureaccelerated dynamics. ACM Transactions on Modeling and Computer Simulation (TOMACS) 2015, 25, 15.
(24) Duan, C.; Janet, J. P.; Liu, F.;
Nandy, A.; Kulik, H. J. Learning from
Failure: Predicting Electronic Structure Calculation Outcomes with Machine
Learning Models. J. Chem. Theory Comput. 2019,

(17) Nemirovsky,
D.;
Arkose,
T.;
Markovic, N.; Nemirovsky, M.; Unsal, O.; Cristal, A.; Valero, M. A deep
learning mapper (DLM) for scheduling on heterogeneous systems. Latin
American High Performance Computing
Conference. 2017; pp 3–20.

(25) von Lilienfeld, O. A. First principles
view on chemical compound space: Gaining rigorous atomistic control of molecular properties. International Journal of
Quantum Chemistry 2013, 113, 1676–
1689.

(18) Kousalya, G.;
Balakrishnan, P.;
Raj, C. P. Automated Workflow Scheduling in Self-Adaptive Clouds; Springer,
2017; pp 119–135.
(19) Sahni, J.; Vidyarthi, D. P. A costeffective deadline-constrained dynamic
scheduling algorithm for scientific workflows in a cloud environment. IEEE
Transactions on Cloud Computing 2018,
6, 2–18.

(26) von Lilienfeld, O. A. Quantum Machine Learning in Chemical Compound Space. Angewandte Chemie
International Edition 2018, 57, 4164,
http://dx.doi.org/10.1002/anie.201709686.
(27) Rupp, M.; von Lilienfeld, O. A.;
Burke, K. Guest Editorial: Special Topic
on Data-Enabled Theoretical Chemistry.
J. Chem. Phys. 2018, 148, 241401.

(20) Liu, H.; Zhao, R.; Nie, K. Using Ensemble Learning to Improve Automatic
Vectorization of Tensor Contraction Program. IEEE Access 2018, 6, 47112–
47124.

(28) Rupp, M.; Tkatchenko, A.; Müller, K.R.; von Lilienfeld, O. A. Fast and accurate modeling of molecular atomization
energies with machine learning. Phys.
Rev. Lett. 2012, 108, 058301.

(21) Antony, J.; Rendell, A. P.; Yang, R.;
Trucks, G.; Frisch, M. J. Modelling the
runtime of the gaussian computational
chemistry application and assessing the
impacts of microarchitectural variations.
Procedia Computer Science 2011, 4,
281–291.

(29) Hansen, K.; Montavon, G.; Biegler, F.;
Fazli, S.; Rupp, M.; Scheffler, M.;
von Lilienfeld, O. A.; Tkatchenko, A.;
Müller, K.-R. Assessment and Validation of Machine Learning Methods for
Predicting Molecular Atomization Energies. J. Chem. Theory Comput. 2013, 9,
3404–3419.

(22) Papay, J.; Atherton, T. J.; Zemerly, M. J.; Nudd, G. R. Performance
Prediction of Parallel Self Consistent
Field Computation. Parallel Algorithms
and Applications 1996, 10, 127–143.

(30) Ramakrishnan, R.; von Lilienfeld, O. A.
Many Molecular Properties from One
Kernel in Chemical Space. CHIMIA
2015, 69, 182.

(23) Mniszewski, S. M.; Junghans, C.;
Voter, A. F.; Perez, D.; Eidenbenz, S. J.

19

(31) Huang, B.; von Lilienfeld, O. A. Communication: Understanding molecular representations in machine learning: The
role of uniqueness and target similarity.
J. Chem. Phys. 2016, 145 .

(39) Unke, O. T.; Meuwly, M. A reactive, scalable, and transferable model for molecular energies from a neural network approach based on local information. The
Journal of Chemical Physics 2018, 148,
241708.

(32) Ramakrishnan, R.; von Lilienfeld, O. A.
Reviews in Computational Chemistry;
John Wiley & Sons, Inc., 2017; Vol. 30;
pp 225–256.

(40) List of top 500 super
http://www.top500.org,
24/04/19.

computers
Accessed:

(41) Ramakrishnan, R.; Dral, P.; Rupp, M.;
von Lilienfeld, O. A. Quantum chemistry structures and properties of 134
kilo molecules. Scientific Data 2014, 1,
140022.

(33) Faber, F. A.; Hutchison, L.; Huang, B.;
Gilmer, J.; Schoenholz, S. S.; Dahl, G. E.;
Vinyals, O.; Kearnes, S.; Riley, P. F.;
von Lilienfeld, O. A. Prediction errors of
molecular machine learning models lower
than hybrid DFT error. J. Chem. Theory
Comput. 2017, 13, 5255–5264.

(42) Ruddigkeit, L.; van Deursen, R.;
Blum, L.; Reymond, J.-L. Enumeration
of 166 billion organic small molecules in
the chemical universe database GDB-17.
J. Chem. Inf. Model. 2012, 52, 2684.

(34) Rasmussen, C. E.; Williams, C. K. I.
Gaussian Processes for Machine Learning; The MIT Press, 2006; see
http://www.gaussianprocess.org.

(43) Weininger, D. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding
rules. J. Chem. Inform. Comput. Sci.
1988, 28, 31–36.

(35) Montavon, G.; Rupp, M.; Gobre, V.;
Vazquez-Mayagoitia, A.; Hansen, K.;
Tkatchenko, A.; Müller, K.-R.; von
Lilienfeld, O. A. Machine learning of
molecular electronic properties in chemical compound space. New Journal of
Physics 2013, 15, 095003.

(44) Weininger,
D.;
Weininger,
A.;
Weininger, J. SMILES. 2. Algorithm for
generation of unique SMILES notation.
J. Chem. Inf. Model. 1989, 29, 97–101.

(36) Smith, J. S.; Isayev, O.; Roitberg, A. E.
ANI-1: An extensible neural network potential with DFT accuracy at force field
computational cost. Chem. Sci. 2017, 8,
3192–3203.

(45) Hansen, K.;
Biegler, F.;
von
Lilienfeld, O. A.;
Müller, K.-R.;
Tkatchenko, A. Interaction potentials
in molecules and non-local information
in chemical space. J. Phys. Chem. Lett.
2015, 6, 2326.

(37) Schütt, K. T.;
Arbabzadah, F.;
Chmiela,
S.;
Müller,
K.
R.;
Tkatchenko,
A.
Quantum-chemical
insights from deep tensor neural networks. Nat. Commun. 2017, 8, 13890.

(46) Faber, F. A.; Hutchison, L.; Huang, B.;
Gilmer, J.; Schoenholz, S. S.; Dahl, G. E.;
Vinyals, O.; Kearnes, S.; Riley, P. F.;
von Lilienfeld, O. A. Prediction Errors
of Molecular Machine Learning Models
Lower than Hybrid DFT Error. Journal of Chemical Theory and Computation
2017, 13, 5255–5264.

(38) Schütt, K. T.; Sauceda, H. E.; Kindermans, P.-J.; Tkatchenko, A.; Müller, K.R. SchNet - A deep learning architecture
for molecules and materials. The Journal
of Chemical Physics 2018, 148, 241722.

(47) Schütt, K. T.;
Arbabzadah,
Chmiela,
S.;
Müller,
K.
20

F.;
R.;

Tkatchenko,
A.
Quantum-chemical
insights from deep tensor neural networks. Nature Communications 2017,
8.

(56) Smith, J. S.; Isayev, O.; Roitberg, A. E.
ANI-1, A data set of 20 million calculated off-equilibrium conformations for
organic molecules. Scientific data 2017,
4, 170193.

(48) Gilmer, J.; Schoenholz, S. S.; Riley, P. F.;
Vinyals, O.; Dahl, G. E. Neural Message
Passing for Quantum Chemistry. ArXiv
2017, abs/1704.01212 .

(57) Janet, J. P.; Kulik, H. J. Predicting electronic structure properties of transition
metal complexes with neural networks.
Chem. Sci. 2017, 8, 5137–5152.

(49) Bartók, A. P.; De, S.; Poelking, C.; Bernstein, N.; Kermode, J. R.; Csányi, G.;
Ceriotti, M. Machine learning unifies the
modeling of materials and molecules. Science Advances 2017, 3, e1701816.

(58) Li, Z.; Omidvar, N.; Chin, W. S.;
Robb, E.; Morris, A.; Achenie, L.;
Xin, H. Machine-Learning Energy Gaps
of Porphyrins with Molecular Graph
Representations. J. Phys. Chem. A
2018, 122, 4571–4578, PMID: 29688014.

(50) Faber, F. A.; Christensen, A. S.;
Huang, B.; von Lilienfeld, O. A. Alchemical and structural distribution based representation for universal quantum machine learning. The Journal of Chemical
Physics 2018, 148, 241717.

(59) Rosenbrock, H. H. An Automatic
Method for Finding the Greatest or
Least Value of a Function. The Computer Journal 1960, 3, 175–184.

(51) Unke, O. T.; Meuwly, M. A reactive, scalable, and transferable model for molecular energies from a neural network approach based on local i nformation. The
Journal of Chemical Physics 2018, 148,
241708.

(60) Himmelblau, D. M. Applied Nonlinear Programming; McGraw-Hill, 1972;
ISBN-13: 978-0070289215.
(61) Jones, E.; Oliphant, T.; Peterson, P.
SciPy: Open source scientific tools
for Python. 2001–; http://www.scipy.
org/, [Version: 1.3.1].

(52) Lubbers, N.; Smith, J. S.; Barros, K. Hierarchical modeling of molecular energies
using a deep neural network. The Journal
of Chemical Physics 2018, 148, 241715.

(62) Nelder, J. A.; Mead, R. A Simplex Method for Function Minimization.
Comput. J. 1965, 7, 308–313.

(53) Eickenberg, M.;
Exarchakis, G.;
Hirn, M.; Mallat, S.; Thiry, L. Solid harmonic wavelet scattering for predictions
of molecule properties. The Journal of
Chemical Physics 2018, 148, 241732.

(63) Byrd, R. H.; Lu, P.; Nocedal, J.; Zhu, C.
A Limited Memory Algorithm for Bound
Constrained Optimization. SIAM Journal on Scientific Computing 1995, 16,
1190–1208.

(54) Simm, G. N.; Reiher, M. ErrorControlled Exploration of Chemical Reaction Networks with Gaussian Processes. J. Chem. Theory Comput. 2018,
14, 5238–5248.

(64) Nash, S. G. Newton-Type Minimization
via the Lanczos Method. SIAM Journal
on Numerical Analysis 1984, 21, 770–
788.
(65) Schwilk, M.; Ma, Q.; Köppl, C.;
Werner, H.-J. Scalable electron correlation methods. 3. Efficient and accurate parallel local coupled cluster with
pair natural orbitals (PNO-LCCSD). J.

(55) B. Meyer, S. H. O. A. v. L., B. Sawatlon; Corminboeuf, C. Machine learning
meets volcano plots: computational discovery of cross-coupling catalysts. Chem.
Sci. 2018, 35, 7069 – 7077.
21

Chem. Theory Comput. 2017, 13, 3650–
3675.

electron density. Phys. Rev. B 1988, 37,
785–789.

(66) Ma, Q.; Schwilk, M.; Köppl, C.;
Werner, H.-J. Scalable electron correlation methods. 4. Parallel explicitly correlated local coupled cluster with pair
natural orbitals (PNO-LCCSD-F12). J.
Chem. Theory Comput. 2017, 13, 4871–
4896.

(76) Werner, H.; Knowles, P. J. A second
order multiconfiguration SCF procedure
with optimum convergence. J. Chem.
Phys. 1985, 82, 5053–5063.
(77) Busch, T.; Esposti, A. D.; Werner, H.
Analytical energy gradients for multiconfiguration self-consistent field wave functions with frozen core orbitals. J. Chem.
Phys. 1991, 94, 6708–6715.

(67) Ma, Q.; Werner, H.-J. Scalable electron
correlation methods. 5. Parallel perturbative triples correction for explicitly correlated local coupled cluster with pair
natural orbitals. J. Chem. Theory Comput. 2018, 14, 198–215.

(78) Peterson, K. A.;
Adler, T. B.;
Werner, H.-J. Systematically convergent
basis sets for explicitly correlated wavefunctions: The atoms H, He, B-Ne, a
and Al-Ar. J. Chem. Phys. 2008, 128,
084102.

(68) Schwilk, M.; Zaspel, P.; von Lilienfeld, O. A.; Harbrecht, H. to be published
2019,

(79) Weigend, F.; Ahlrichs, R. Balanced basis sets of split valence, triple zeta valence and quadruple zeta valence quality for H to Rn: Design and assessment
of accuracy. Physical Chemistry Chemical Physics 2005, 7, 3297.

(69) Knowles, P. J.; Werner, H.-J. An efficient
method for the evaluation of coupling coefficients in configuration interaction calculations. Chem. Phys. Lett. 1988, 145,
514 – 522.
(70) Werner, H.; Knowles, P. J. An efficient
internally contracted multiconfigurationreference
configuration
interaction
method. J. Chem. Phys. 1988, 89,
5803–5814.

(80) Weigend, F. Accurate Coulomb-fitting
basis sets for H to Rn. Physical Chemistry Chemical Physics 2006, 8, 1057.
(81) Binkley, J. S.; Pople, J. A.; Hehre, W. J.
Self-consistent molecular orbital methods. 21. Small split-valence basis sets for
first-row elements. J. Am. Chem. Soc.
1980, 102, 939–947.

(71) Shiozaki, T.; Knizia, G.; Werner, H.J. Explicitly correlated multireference
configuration interaction: MRCI-F12. J.
Chem. Phys. 2011, 134, 034113.

(82) Petersson, G. A.; Bennett, A.; Tensfeldt, T. G.; Al-Laham, M. A.;
Shirley, W. A.; Mantzaris, J. A complete basis set model chemistry. I. The
total energies of closed-shell atoms and
hydrides of the first-row elements. The
Journal of Chemical Physics 1988, 89,
2193–2218.

(72) Shiozaki, T.; Werner, H.-J. Multireference explicitly correlated F12 theories.
Mol. Phys. 2013, 111, 607–630.
(73) Tahchieva, D. N.; Schwilk, M.; von
Lilienfeld, O. A. to be published 2019,
(74) Becke, A. D. Density-functional thermochemistry. III. The role of exact exchange. J. Chem. Phys 1993, 98, 5648.

(83) Petersson, G. A.; Al-Laham, M. A. A
complete basis set model chemistry. II.
Open-shell systems and the total energies
of the first-row atoms. The Journal of
Chemical Physics 1991, 94, 6081–6090.

(75) Lee, C.; Yang, W.; Parr, R. G. Development of the Colle-Salvetti correlationenergy formula into a functional of the
22

(84) Werner, H.-J.; Knowles, P. J.; Knizia, G.;
Manby, F. R.; Schütz, M.; and others,
MOLPRO, a package of ab initio programs. see http://www.molpro.net.

The ∆-Machine Learning Approach. J.
Chem. Theory Comput. 2015, 11, 2087.
(93) Christensen, A. S.; Faber, F. A.;
Huang, B.;
Bratholm, L. A.;
Tkatchenko, A.; Müller, K.-R.; von
Lilienfeld, O. A. QML: A Python
Toolkit for Quantum Machine Learning,
https://github.com/qmlcode/qml. 2017;
http://www.qmlcode.org.

(85) Neese, F. 2006, ORCA 2.8, An ab initio, density functional and semiempirical program package, University of Bonn,
Germany.
(86) Perf of the linux kernel version 3.10.0327.el7.x86_64 tools was used. Perf
measures the number of retired FLOP (as
a certain amount of speculative executions may be negated, given that logical
branches cannot be evaluated between
instructions within a clock cycle).

(94) Intel Corporation, Intel Math Kernel Library. 2018; https://software.intel.
com/en-us/mkl, Accessed: 11/20/2018.
(95) Xianyi, Z.; Qian, W.; Saar, W. OpenBLAS, An optimized BLAS library. 2017;
http://www.openblas.net/, Accessed:
11/16/18.

(87) Ma, Q.; Werner, H.-J. Explicitly correlated local coupled-cluster methods using
pair natural orbitals. WIRES COMPUT
MOL SCI 8, e1371.

(96) Open MPI: Open Source High Performance Computing. 2018; https://www.
open-mpi.org/, Accessed: 11/15/18.

(88) Krige, D. G. A Statistical Approaches to
Some Basic Mine Valuation Problems on
the Witwatersrand. Journal of the Chemical, Metallurgical and Mining Society of
South Africa 1951, 52, 119–139.

(97) Free Software Foundation, Inc., GCC,
the GNU Compiler Collection. 2017;
https://gcc.gnu.org/,
Accessed:
11/14/18.
(98) Global Arrays Programming Models.
2018;
http://hpc.pnl.gov/
globalarrays/, Accessed: 11/16/18.

(89) von Lilienfeld, O. A.; Ramakrishnan, R.;
Rupp, M.; Knoll, A. Fourier series of
atomic radial distribution functions: A
molecular fingerprint for machine learning models of quantum chemical properties. Int. J. Quantum Chem. 2015, 115,
1084, http://arxiv.org/abs/1307.2918.

(99) Nieplocha, J.; Palmer, B.; Tipparaju, V.;
Krishnan, M.; Trease, H.; Apra, E. Advances, Applications and Performance of
the Global Arrays Shared Memory Programming Toolkit. Int. J. High Perf.
Comp. Appl. 2006, 20, 203–231.

(90) Müller, K. R.; Finke, M.; Murata, N.;
Schulten, K.; Amari, S. A numerical
study on learning curves in stochastic
multilayer feedforward networks. Neural
Comp. 1996, 8, 1085.

(100) Due to non-deterministic run time behaviour of the CPU, as well as measurement errors of perf, the FLOP count
varies within a few tenth of percent for
consecutive runs of the same calculation.

(91) Huang, B.; von Lilienfeld, O. A. The
“DNA” of chemistry: Scalable quantum
machine learning with “amons”. arXiv
preprint arXiv:1707.04146 2017, submitted to Nature.

(101) Raw data for this work and sample implementations for easy use can be found on
https://github.com/ferchault/mlscheduling.

(92) Ramakrishnan, R.; Dral, P.; Rupp, M.;
von Lilienfeld, O. A. Big Data meets
Quantum Chemistry Approximations:
23

Graphical TOC Entry

24

Supporting Information to Machine learning
the computational cost of quantum chemistry

arXiv:1908.06714v2 [physics.chem-ph] 19 Dec 2019

Stefan Heinen,†,‡ Max Schwilk,† Guido Falk von Rudorff,† and O. Anatole von
Lilienfeld∗,†,‡
†Institute of Physical Chemistry, Department of Chemistry, University of Basel,
Klingelbergstrasse 80, CH-4056 Basel, Switzerland
‡National Center for Computational Design and Discovery of Novel Materials (MARVEL)
E-mail: anatole.vonlilienfeld@unibas.ch
This material is available free of charge
via the Internet at http://pubs.acs.org/.
Code and raw data is available on GitHub
https://github.com/ferchault/mlscheduling

Additional details on the data
sets

search was performed on the unsubstituted case
and from the found TS the chemical space
was spanned by exchanging the hydrogen atoms
with functional groups. The following timings
(using ORCA 4.0.1) and the initial geometries
of the TS search form the data set QMrxnTS
MP2 .

QM9GO
B3LYP
The QM9 data set contains geometries optimized with B3LYP/6-31G*. 5001 out of these
134k molecules were further optimized with a
larger basis set (def2-TZVP) using Molpro to
obtain data set QM9GO
B3LYP .

Table 1 shows additional information regarding
the used hardware.

QMrxnGO
MP2
The initial reactant geometries from the reaction data set were obtained by generating
the unsubstituted molecule (hydrogen atoms instead of functional groups and Fluor as leaving group) without the nucleophile. Subsequently substituting the hydrogen atoms with
functional groups span the chemical space. For
every reactant a conformer search on PM6-D3
level was performed using ORCA. The lowest
lying conformer geometries were then further
optimized on MP2/6-31G* level of theory which
resulted in the data set set QMrxnGO
MP2 .

GO
QMspinSP
MRCI and QMspinCASSCF

For the geometry optimization of data set
QMspinGO
CASSCF we use the CASSCF single
point energy ? and energy gradient implementation ? in Molpro. The calculations have been
run on one compute core per job and similar
amounts of run time are spent for the wave
function computation and the energy gradient.
When performing a geometry optimization, the
CASSCF wave function of a previous step is
used as a starting guess for the CASSCF wave
functions of the new geometry. For that reason,
the first step of a geometry optimization takes
significantly longer than the following steps.
We take this aspect into account in our ML
model as well as in our scheduling model.

QMrxnTS
MP2
The starting geometries for the transition state
(TS) search were obtained in a similar way
as described in section . A transition state
1

Table 1: Data sets of calculations used in this work: Software used for calculations, number of
cores used per calculation, and CPU types the calculation ran on as well as details of the ML
hyperparameter.
Calculation
Data set
# Cores

24

CPU Types

E5-2680v3

σBoB
σFCHL
λBoB
λFCHL

SP

204.8
12.8
1e-7
1e-7

QM9

24

QMspin
1

E5-2650v2
E5-2680v3 E5-2640v3
E5-2630v4
204.8
12.8
1e-7
1e-7

51.2
51.2
1e-7
1e-7

QM9
1
E5-2630v4
51.2
409.6
1e-7
1e-7

GO
QMrxn
1

QMspin
1

E5-2650v2
E5-2640v3
E5-2640v3
E5-2650v4
E5-2630v4
102.4
51.2
1e-7
1e-9

51.2
51.2
1e-5
1e-5

TS
QMrxn
1
E5-2650v2
E5-2680v3
E5-2640v3
E5-2630v4
E5-2650v4
204.8
51.2
1e-7
1e-7

First fit decreasing algorithm

Learning curves

The bin packing problem is NP-hard, ? i. e., the
search for the optimal solution to the problem
is prohibitively expensive for real-world workloads of thousands of jobs even if the time estimates were arbitrarily accurate. ? ? ? First Fit
Decreasing (FFD) is one of the many heuristic algorithms ? that exists for the bin packing
problem. It has been shown that for practical purposes the FFD algorithm is close to the
optimal solution, as for q compute jobs as it
uses at most 11/9q + 1 jobs, ? but typically is
within a few percent of the optimal solution. ?
In all cases, we calculate the total core hours
and the total duration from the first to the last
job. The total core hours divided by the sum of
the real run times define the compute overhead.
The total duration from first to last job should
not be exceedingly high compared to other approaches, since this metric is about enabling science: if the calculations would take too long,
a research project would not be started. The
ideal approach therefore reduces the overhead
while keeping the total wall time at least comparable to established approaches.

In the following we compare models with respect to different training inputs. We trained
models on CPU, normalized (by number of electrons) CPU, wall, and normalized wall times.
For CPU times only calculations done with
Molpro could be considered because ORCA
output files only contain total (wall) times.
Best performance was reached with models
trained on normalized CPU times. The differences are small (around 1% to 4%). For predictions normalized wall times were used because
of their application to the scheduling. For the
GO
test sets QMspinSP
MRCI and QMspinCASSCF
we also training on CPU times normalized by
the formal scaling of the method, this did neither lead to significant changes in the training
model (results not shown).

2

SP

QM9GO
B3LYP
QMrxn19GO
MP2
QMspin19GO
CASSCF

32

32
QM9SP
CC/DZ
QM9SP
CC/TZ
QMspin19SP
MRCI

8

MAE [%]

80

16

QM9GO
B3LYP
QMspin19GO
CASSCF

60

2

2
10

N

40

3

10

2

N

10

100

32

80

QMrxn19TS
MP2

60

40

60

30
2

10

N

40
2
10

3

10

N

3

10

2

10

N

3

Figure 3: Learning curves showing normalized
test errors (cross validated MAE divided by median of test set) using BoB and FCHL as representations. The model was trained on wall
times. Horizontal lines correspond to the performance assuming all calculations have mean
run time (standard deviation divided by the
mean wall time of the data set.

SP

GO

64

TS

80

80

QMspin19SP
MRCI

10

3

Figure 1: Learning curves showing normalized
test errors (cross validated MAE divided by median of test set) using BoB and FCHL as representations. The model was trained on CPU
times. Horizontal lines correspond to the performance assuming all calculations have mean
run time (standard deviation divided by the
mean wall time of the data set.

SP

QM9SP
CC/DZ
QM9SP
CC/TZ

8

4

2

100

16

4

10

GO
QMspin19SP
MRCI

64

100
80

16

QM9SP
CC/DZ
QM9SP
CC/TZ
QMspin19SP
MRCI

8

MAE [%]

MAE [%]

GO

64

100

64

MAE [%]

SP

GO

QM9GO
B3LYP
QMspin19GO
CASSCF

60

60

40

4
2

32

40
10

2

10

N

3

10

2

N

10

3

40
10

2

N

10

3

QMspin19GO
CASSCF

10

2

N

10

3

Figure 4: Learning curves showing normalized
test errors (cross validated MAE divided by median of test set) using BoB and FCHL as representations. The model was trained on normalized (number of occupied orbitals to the power
of 2 times number of basis functions to the
power of 4) wall times. Horizontal lines correspond to the performance assuming all calculations have mean run time (standard deviation
divided by the mean wall time of the data set.

Figure 2: Learning curves showing normalized
test errors (cross validated MAE divided by median of test set) using BoB and FCHL as representations. The model was trained on normalized (by number of electrons) CPU times.
Horizontal lines correspond to the performance
assuming all calculations have mean run time
(standard deviation divided by the mean wall
time of the data set.

3

