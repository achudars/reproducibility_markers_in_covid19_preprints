Automated Text Summarization for the Enhancement of Public Services
Xingbang Liu, Janyl Jumadinova
Allegheny College
Department of Computer Science
Meadville, PA 16335

Abstract
Natural language processing and machine learning algorithms have been shown to be effective in a variety of applications. In this work, we contribute to the area of AI adoption in the public sector. We present an automated system
that was used to process textual information, generate important keywords, and automatically summarize key elements
of the Meadville community statements. We also describe
the process of collaboration with My Meadville administrators during the development of our system. My Meadville,
a community initiative, supported by the city of Meadville
conducted a large number of interviews with the residents of
Meadville during the community events and transcribed these
interviews into textual data files. Their goal was to uncover
the issues of importance to the Meadville residents in an attempt to enhance public services. Our AI system cleans and
pre-processes the interview data, then using machine learning
algorithms it finds important keywords and key excerpts from
each interview. It also provides searching functionality to find
excerpts from relevant interviews based on specific keywords.
Our automated system allowed the city to save over 300 hours
of human labor that would have taken to read all interviews
and highlight important points. Our findings are being used
by My Meadville initiative to locate important information
from the collected data set for ongoing community enhancement projects, to highlight relevant community assets, and to
assist in identifying the steps to be taken based on the concerns and areas of improvement identified by the community
members.

Introduction
Following the successful implementation of Artificial Intelligence (AI) technologies in the private sector companies, the government agencies have started to adopt AI techniques for different applications such as health care (Sun and
Medaglia 2019), public safety (Kouziokas 2017), social welfare (Capgemini 2017), and education (Timms 2016). These
AI applications have benefits of cost savings, increase of
public employees’ productivity by reduction of their workload, new employment opportunities, solutions to the resource allocation problems and enhancement of citizens’
satisfaction, but they also present challenges in their successful implementation and use (Wirtz, Weyerer, and Geyer
Copyright c 2019, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.

2019). AI in the public sector is still a young, emerging field
of research and continued extensive research is needed to
fully explore the full potential of AI in the public sector,
and leverage various AI technologies to address important
problems/needs. A report by Harvard (Mehr, Ash, and Fellow 2017) specifies six types of government problems that
could benefit from AI applications the most: resource allocation, large data sets, experts shortage, predictable scenarios, procedural and repetitive tasks, diverse data aggregation
and summarization. This paper makes a contribution in this
direction: we present an intelligent system for knowledge
extraction from a large textual data set to address the important issue of public service enhancement. We also demonstrate a successful application of this AI technology in the
city of Meadville and discuss the process of engaging various stakeholders in the city government and the challenges
that we have encountered during this process.
The city of Meadville located in in Northwestern Pennsylvania has faced many of the same issues challenging small
rural towns across our country, such as population decline, a
dwindling tax base and economic turbulence. In order to investigate and combat some of these issues, in 2015 the City
of Meadville applied for and received a grant from the Pennsylvania Humanities Council and the Orton Family Foundation. The goals of the grant were to build a greater connection with Meadville residents, develop a stronger sense
of community identity, and a vision for the future rooted in
what matters most to community members. My Meadville
Heart and Soul initiative was formed to accomplish the aims
identified in this work. Hosted by the Redevelopment Authority of the City of Meadville, the My Meadville Heart and
Soul initiative interviewed over 700 Meadville residents to
learn which places, issues and services residents care about
the most. The recorded interviews were then transcribed and
collected into a single data set.
In this project, we first cleaned the data procured by My
Meadville initiative and then used it in our knowledge extraction system. Our goal was to develop a system that could
be used by the city of Meadville and relevant community
members and organizations to get insight and context into
the good and important work that is being done in Meadville,
and uncover ways to improve public relations and services
that are meaningful to Meadville residents. Using natural
language processing techniques, such as sentiment analy-

sis and named entity recognizer, and machine learning algorithms, our system processes community statements provided by My Meadville, finds important keywords, and then
produces a summary of the key excerpts from the data. With
the support of the City of Meadville and City Council, our
findings are used as an aid by My Meadville initiative to develop community value statements, highlight relevant community assets and to develop an action plan based on the
concerns and areas of improvement identified by the community members. An example of the value statement is as
follows:
Children and Youth: We value youth-centered programming and safe, accessible spaces that support
youth and prepare them for a fulfilling future.
Supporting Data:
Youth-Centered Programming:
“... Value diverse accessible opportunities for children
to engage in and build community.”
“... Appreciates a community that connects resources to
education to families to concerns about the whole child
through multiple systems ... ”
“... Cares about options for youth activities that keep
youth occupied, such as a skating rink or pool hall ...”
“... Appreciates teen-friendly activities that are affordable, diverse, and purposeful ...”
Safe and accessible spaces:
“... Values playgrounds and other safe places for kids
to play ...”
‘... Treasures a community that offers a variety of safe
inside and outside recreational activities for the children and youth of Meadville.”
“... Appreciates activities out of school for students to
do so they do not get involved with criminal activities.”
“... Appreciates safe community events, places, and activities for families that bring people together ...”
“... Appreciates walkable options for youth engagement
so that families don’t stress over transportation ...”
Support Youth:
“... Values a community that appreciates the voices and
input of our youth and nurtures their new ideas ...”
“... Appreciates the local opportunities for youth engagement and the ways in which they are connected
to each other ...”
“... Appreciates a community that values the voices
of children and youth and provides avenues for them
to show their giftedness and to express themselves in
meaningful and beneficial ways ...”
Some examples of the Action Plan items related to the
action plan above include:
1. Create a group dedicated to creating an empowered
network of teens within the community.
2. Sustain the summer parks program.
3. Create a map of public parks.
4. Increase available transportation for youth.
We also developed a searching functionality of our automatically generated summary of the community statements,

where various organizations and city governmental agencies
are able to search the summaries for specific information.
We then trained My Meadville administrator to use our system with this searching functionality, which automatically
generates a Markdown file on the web for easy access and
interpretation of the search results. In 2019, this extended
functionality was utilized to gain insight into the previous
summer parks program in Meadville from the residents’ stories and to use that information to revitalize and enhance
this program in Meadville. Additionally, a separate research
study into the museum creation used our system to uncover
the need and desire for such a project in Meadville.
To summarize, the contributions of our work presented in
this article are as follows:
• An automated system that can process textual information, generate important keywords, and automatically
summarize key findings of the large amounts of text.
• An additional search tool that allows users to search the
text for specific information and generates results in an
easily readable format.
• A use case of our system by My Meadville initiative to aid
in generating value statements and action plans and by the
city administrators to study the development of specific
projects in the city of Meadville.
• A description of the process of collaboration with the public officials and My Meadville volunteers to ensure transparency and to build trust.

Related Work
AI in the public sector is a relatively young field but there
have been a number of articles demonstrating its use and
outlining potential challenges. For example, in (Androutsopoulou et al. 2019), the authors present a new approach
in the use of chatbots in the public sector to improve the
communication between the government and citizens. The
presented approach is built using natural language processing, machine learning and data mining technologies and it
develops a digital channel of communication between the
government and citizens. This digital channel uses existing
data collected from documents containing legislation and directives, structured data from government agencies’ operational systems, and social media data to facilitate and promote information seeking and conducting of transactions.
The presented approach was validated through a series of application cases with the cooperation of the three Greek government agencies. Given a number of interesting research
articles such as the one described above, which demonstrate
successful deployment of AI in the public sector, Wirtz et
al. (Wirtz, Weyerer, and Geyer 2019) analyzed and summarized scientific literature related to AI applications in the
public sector. They categorize the research of AI in the public sector as follows: (1) AI government service, (2) working and social environment influenced by AI, (3) public order and law related to AI, (4) AI ethics, and (5) AI government policy. They also identify specific AI applications
that are valuable for the public sector and present a FourAI-Challenges Model that incorporates main aspects of AI
challenges. Valle-Cruz (Valle-Cruz et al. 2019) investigate

the AI trends in the public sector by surveying 78 recent
papers related to this area. Their findings indicate that only
normative and exploratory research articles have been published so far and that many public policy challenges face
this research area. The authors, however, also outline various
benefits of AI application in public health, policies on climate change, public management and decision-making, improving government-citizen interaction, personalization of
services, analyzing large amounts of data, detecting abnormalities and patterns, and discovering new solutions through
modeling and simulations.
There have also been a number of articles proposing some
theoretical frameworks for the successful adoption of AI in
the public sector. Chen et al. (Chen, Ran, and Gao 2019)
presents a four-stage model for AI development in the public sector in order to guide public administrators in its use
and navigate the impact AI would have on their organizations. The authors present an application case of AI for delivering public services in local government in China. The
outcomes of their application of AI in the local government
in China could present the research community with the longitudinal study for AI in the public sector. In (Engin and Treleaven 2019), the authors present a taxonomy of government
services to provide an overview of data science automation
being deployed by governments world-wide. They present
a review of the studies and projects across the world and
propose a technological framework on the development of
the AI technologies to transform the public sector. Our work
belongs to the category of research articles that describe
the successful development and deployment of AI technology for the public sector use. Our developed AI technology builds upon several existing natural language processing techniques, such as lemmatization and the named entity
recognition, uses a number of machine learning algorithms
for sentiment analysis and word, phrase and sentence extraction, and builds upon existing open-source projects, such as
PyTextRank (Nathan 2016).
Automatic keyword and keyphrase extraction is the process of selecting words and phrases from the text that can
project the core sentiment of the whole text automatically,
and it has become one of the fundamental steps in information retrieval, text mining, and natural language processing applications (Siddiqi and Sharan 2015). In (Beliga,
Meštrović, and Martinčić-Ipšić 2015), the authors present
the survey for the task of the keyword extraction, concentrating on the graph-based methods. Graph-based representation of text allows for the document to be modeled as a
graph, where words are represented as nodes and their relations are represented as edges. They find that graph-based
keyword extraction techniques are domain and language independent, thus making them robust and easy to apply to
knowledge extraction problems, such as text classification,
search, and summarization.
Text summarization is a process of extracting the most
important features of a text and compiling it into a short text
(Eduard and Lin 1998). Various approaches to text summarization have been proposed (Aggarwal and Zhai 2012). In a
query-based text summarization a specific portion of the text
is utilized to extract the essential keyword from input doc-

ument to make the summary of corresponding document.
Extractive text summarization process identifies important
information (words or sentences) from the input text using
statistical and linguistic features of the sentences and makes
the summary of the corresponding document using the most
relevant sentences (Gupta and Lehal 2010). Similar to this
technique, abstractive text summarization finds the important sentences in the text but it uses new concepts and expressions to describe it by generating a new shorter text that
conveys the most important information from the original
text document.
Supervised and unsupervised machine learning techniques have been used for the text summarization task. In
supervised learning based text summarization labeled data
sets are used for training. For example, in (Thomas, Bharti,
and Babu 2016), the authors used a hidden Markov model to
automatically extract keywords for text summarization and
used human annotated keyword data set to train their model.
However, it is often difficult to find enough labeled data for
training, thus, Wong et al. (Wong, Wu, and Li 2008) developed a semi-supervised learning method for co-training
by combining labeled and unlabeled data. They demonstrate
that their method is comparable to the supervised learning
approach but it only requires about half of the labeling time
cost. Unsupervised learning based text summarization does
not require any labeled data to be used in training. For example, in (Garcı́a-Hernández et al. 2008), the authors used a
k-means clustering algorithm to generate groups of similar
sentences and the most representative sentence was further
selected for the summary.
In our work, we use graph-based keyword, keyphrase
and sentence extraction technique and use an unsupervised learning based method for text summarization of My
Meadville community statements provided in the interview
data.

AI System for My Meadville Interviews
Development Process
After the data was collected by My Meadville we were approached to find ways of automating the process of knowledge extraction. With over 700 text documents, the scarcity
of trained volunteers and the lack of funding for professional
help, they were seeking ways to make the knowledge extraction from this data feasible. In our initial discussions we
identified the goals that the City of Meadville had and possible technological solutions for the data knowledge extraction. We decided to follow an agile development method,
with a feedback loop for My Meadville administrators at the
design stage and various development stages. Over a period
of a year in 2018, we continued to meet with My Meadville
initiative administrators and adjust our development given
their feedback. Once our system was fully implemented and
tested we gave a demonstration to the My Meadville committee. We then discussed various avenues for adoption and
extended use of our system. Following these discussions we
prepared and conducted training for the My Meadville committee and its volunteers on using our system and interpreting its results.

Input files
.docx files

Pre-processing

Processing

Summarization

Convert DOCX
files to TXT files

Extract responses
in the input files

Rank all words,
phrases and sentences

Combine excerpts
and keywords

Remove special
signs and new lines
from responses

Use sentiment
analysis to detect
strong feelings

Convert summary
into Markdown
format for easy access

Convert texts
to json objects

Find organization names

Figure 1: Different stages of our system

My Meadville Interview Data

relationships that make such work possible.

In 2015, My Meadville initiative committee members recruited and trained dozens of volunteers to perform interviews and to transcribe them. Then, for a period of two
years the volunteers conducted interviews with hundreds
of Meadville residents at various community events, local
schools, businesses and organizations. These audio interviews were manually transcribed into Word text files by the
volunteers and compiled into a data set that was then used
by our system.
Upon reviewing the data set we found that the interview
transcriptions did not conform to a single format. For example, in some transcriptions the responses were identified as
such, and in others they were not, and we needed to read
the document to decide which text was the interviewer comments and questions and which belongs to the interviewee.
Since the goal of My Meadville was to extract information
from the interviewees, our system only uses the responses in
the interviews. Therefore, before using the collected data set
in our system we manually looked through each document
and whenever necessary made appropriate tags to identify
the interviewee response so that it could be recognized by
our system.
All participants whose voices are included in the final data
set have signed a waiver that allows My Meadville to use
their stories to continue to strengthen the values and visions
of our community. Also, all data is anonymous, where all
identifying information in the interviews was removed. The
hope of My Meadville was that the collected information
can provide insight and context into the good and meaningful work that is being done in Meadville, and that this data
can be used as a tool to improve the efficiency, purpose, and

Intelligent Text Extraction and Summarization
Our AI system processes the textual My Meadville community statements, finds important keywords, and then produces a summary of the key excerpts from all data. It utilizes
several open source projects, such as Stanford Named Entity
Recognizer (NER), Scikit-learn Sentiment Analysis, and PyTextRank, and consists of multiple stages as identified in
Figure 1. The text documents provided by My Meadville
were saved as .docx files. We first automatically convert
them to .txt files (extractdocx 2016). Then we go through
a pre-processing stage, where the responses are extracted
from the interviews, and then cleaned by removing special
characters, signs, etc. Finally, the pre-processed interview
responses are converted to JSON files for use in the subsequent stages.
During the processing stage the text is analyzed and ranking and sentiment analysis are conducted. The text rank
layer builds a word graph for voting on the importance of the
word based on the baseline approach outlined in (Mihalcea
and Tarau 2004). This graph model has the ability to extract
key phrases and rank the phrases and sentences. Ranking is
done through the idea of voting, where a vote is a connection of one node to another, that is when one node links to
another node it is essentially voting for that node. The higher
the number of votes for a node, the higher the importance of
the node. The model also takes the account the information
on the importance of the vote itself, with the TextRank score
of a node being calculated based on the votes it receives and
the score of the nodes voting for that node.
We build our system based on the implementation of the
TextRank method (Nathan 2016) with modifications. This

Layer 1:

Layer 2:

Layer 3:

Figure 2: Example: TextRank layers
implementation is written in Python and uses spaCy (Honnibal and Montani 2017), NetworkX (NetworkX developer
team 2014), datasketch (datasketch 2018) tools. The importance calculation is performed in three layers. In the first
layer, statistical parsing and tagging is performed on a document in a JSON format. An example output of this layer
can be seen from the top image in Figure 2. The second
layer collects and normalizes the key phrases from the document produced by the previous step. Finally, during the third
layer a score for each sentence is calculated using the Jaccard distance between key phrases determined by TextRank
and each of its sentences. The middle and bottom images
in Figure 2 show example outputs of the second and third
layers.

The feature vectors built by the text ranking method produced ranked key phrases and sentences as seen in Figure 2. This output was combined with the output from the
sentiment analysis to determine top ranked sentences to be
used in extractive summarization of the document. Scikitlearn machine learning library (Scikit-learn 2018) was used
to perform sentiment analysis and to produce a sentiment
score. First, training on the data from Twitter and UCI machine learning database was done with the use of the pickle
module to store the trained model. The UCI data contains
sentiment labeled sentences from Amazon, Yelp, and IMDB
contained in positive.txt and negative.txt files.
In order to split the data into training and testing sets, we
calculated the frequency distribution of each word for both
positive and negative sentences. The top 5,000 words were
kept as features, then the features were pickled into one file
and shuffled. The testing data included the last 10,000 features, whereas the training data included the previous 10,000
features. Once the training was performed, six algorithms
were used for testing, including naive Bayes, multinomial

naive Bayes, Bernoulli naive Bayes, logistic regression, linear support vector clustering, and stochastic gradient descent
classifier. These algorithms were used to predict the sentiment of the text. In this work we considered text important
(high rank) if the outcome of sentiment learning indicated
that the text has strong feelings (high score). The sentiment
score was represented as a floating-point number and ranged
from 0 (negative) to 1 (positive), where having a score closer
to 0 or 1 indicated strong feelings. For each classifier we obtained the accuracy score from nltk and the results from
the best algorithm were chosen, where the key phrases and
sentences with strong positive or negative feelings were selected to be included in the summary.
We also leveraged the Named Entity Recognition technique before producing the summarization of the document. Stanford Named Entity Recognizer (NER) (Finkel,
Grenager, and Manning 2005) uses an advanced statistical
learning algorithm to extract named entities. The NER has
three classes, including person, organization, and location
entities. In our application, upon consultation with the My
Meadville administrators, only organization entities were
detected.
After text ranking, sentiment analysis and named entity
recognition, all key phrases and sentences determined to be
important by these three techniques are extracted for summarization.

Experimental Results
Data set
Average interview
Shortest interview
Longest interview

706 interviews
9,161 words
334 words
30,465 words

Table 1: Information about the data set used in the experiments
The implementation of our system was written in Python
3.6.7 and the experiments were run on Ubuntu Linux 4.15.0.
The overview of the data set used in our experiments is
shown in Table 1. To evaluate the correctness of our system, we have first tested it on five text documents randomly
selected from our data set. We carefully read and annotated
the text and then manually compared the output produced by
our system with our annotations to verify its accuracy.
After manual testing, we ran our system on a complete
data set, which produces a textual summary and a list of
keywords for each interview document. Two examples of the
output produced by our system are shown in Figure 3, where
extracted summary and a list of keywords are included for
each of the two documents. The top output corresponds to
the interview with 1,274 words and the second interview
document contains 2,842 words.

Searching Functionality
The summary and keyword information produced by our
system was very well received by My Meadville. In our
discussions with them we have estimated savings of over
300 hours of human labor when reading condensed summaries and keywords instead of the complete interviews during their work of compiling value statements and locating

Keywords: family, fun things, friends, strong little community, fun games, baseball, taxes, more jobs, Baldwin
Reynolds house, park, history, houses
Summary: I love all the fun things you can do with friends
and family and I feel it’s like a strong little community, we
all work together and have fun . What matters to me most
is my friends here. My favorite memory about living in
Meadville is probably playing baseball and doing all these
fun games at baseball. Some stuff to make living here easier would be cutting taxes, creating more jobs , and making
it so we’re more of a strong economy. All the history we
have is important , because our history dates clear back to
the 1700s . And there ’s just so many things you can do
like the Baldwin Reynolds House, and even Diamond Park
is history. My one wish for Meadville would be to make all
the houses look nice.
Keywords: community, larger town, great education system, crawford county fair, family-friendly town, great family atmosphere, economy, jobs, newer buildings, good honest living, historical places
Summary: What I love most about the city of Meadville is
that it has all of the attractions and items of a much larger
town, but it has a very small-town, family-friendly oriented
community . What matters most to me is having a great
education system for my children. My favorite memory
would probably have to be the Crawford County Fair. Having a great family atmosphere and a family-friendly town
was important to us as we raised our family. Our families
grew up here in this area and we ’re happy to be around
them, and stay in a great community . Seeing a good, solid
base in the economy would be something that would make
us stay here. So between a strong education system and
also jobs that people can have that people can make a good
honest living off of will keep people here, and keep the
town thriving . What draws us here and keeps us here is all
the items of a large town but in a much smaller community
oriented town. I would probably go with newer buildings
versus all the effort and time and money that it would take
to restore a lot of these historical places.
Figure 3: Example output produced by our system for two
interview documents.
supporting data. During one of our feedback discussions,
My Meadville administrators requested a possibility of implementing the searching functionality to locate specific information in the summarized output quickly. This was especially important because of a number of new research and
community projects in the city that could benefit from the
data.
We built a supplemental searching tool to accompany our
text extraction system that allows the user to search for specific keywords. This tool goes through each output (summary and keywords) produced by our system and tries to
match the keyword specified by the user with one of the
keywords identified by our system. If there is a match, the
keyword, the interview document name, and the text sur-

rounding the keyword is reported in a Markdown file. After
the output of all documents has been checked, the Markdown file is uploaded to the GitHub repository, which can
be viewed by the relevant parties. An example of an automatically generated and uploaded search result file is shown
in Figure 4, where partial results for the “park” keyword are
shown. Overall, the searching functionality added to our system was proven to be very useful and it allowed the city and
the local community to utilize the data for specific projects
as needed.

Conclusion and Future Directions
In this paper we describe an intelligent text summarization
system that also identifies important keywords and allows to
search results for use-specified keywords. We also present an
application of this system to the interview data collected by
My Meadville initiative, which was supported by the city of
Meadville and the City Council and hosted by the Redevelopment Authority of the City of Meadville. Our experimental results were run on over 700 transcribed interviews and
the output containing an extracted summary and keywords
for each interview were shared with My Meadville committee, which they used in their work of developing community
value statements, followed by action plan items. The community work on talking to the Meadville residents continues
and more documents are added as the new interviews are
transcribed. The searching functionality of our system has
been utilized in several community projects, including the
study on the enhancement of the city’s summer parks program and the feasibility study on the creation of a Community Museum of Science, Industry, and Culture.
We encountered a few challenges in our work of AI system application in the public sphere. First of all, we came
into the project after the data was collected and hence could
not provide input into the transcription format of the interviews and the importance of consistency across transcriptions. Since the interviews were conducted and transcribed
by dozens of different volunteers, the structure and the format of the interviews and transcriptions varied greatly. We
spent a number of hours manually parsing through interview
documents and editing documents that did not identify the
interviewee responses easily. Secondly, we found that deploying the system for the use by My Meadville committee
was challenging. My Meadville administrators and most of
its volunteers had no computing training and were uncomfortable setting up and running programs. Therefore, they
relied on us to gather the summary and keywords results. We
did successfully train My Meadville administrators in using
the searching functionality as that implementation did not
rely on many libraries. We also successfully trained them to
use GitHub, where we shared the source code, output files,
etc. through private repositories.
In the future, we would like to extend our system to a
container-based set up, where all dependencies will be included for the user in a container and they will not need to
download all the dependencies before using our system. We
would also like to create a web-based tool for our searching functionality instead of having an executable file that the
users have to click on. Finally, we will continue to coordi-

Figure 4: An example of the searching output.

nate with the City of Meadville in different uses of our system and its further development in order to accomplish their
goals of public service enhancements in Meadville.

References
[Aggarwal and Zhai 2012] Aggarwal, C. C., and Zhai, C.
2012. Mining text data. Springer Science & Business Media.
[Androutsopoulou et al. 2019] Androutsopoulou, A.; Karacapilidis, N.; Loukis, E.; and Charalabidis, Y. 2019. Transforming the communication between citizens and government through ai-guided chatbots. Government Information
Quarterly 36(2):358–367.
[Beliga, Meštrović, and Martinčić-Ipšić 2015] Beliga,
S.; Meštrović, A.; and Martinčić-Ipšić, S. 2015. An
overview of graph-based keyword extraction methods and
approaches. Journal of information and organizational
sciences 39(1):1–20.
[Capgemini 2017] Capgemini.
2017.
Unleashing the
potential of artificial intelligence in the public sector.
https://www.capgemini.com/consulting/
wp-content/uploads/sites/30/2017/10/
ai-in-public-sector.pdf.
[Chen, Ran, and Gao 2019] Chen, T.; Ran, L.; and Gao, X.
2019. Ai innovation for advancing public service: The case
of china’s first administrative approval bureau. In 20th Annual International Conference on Digital Government Research, 100–108. ACM.
[datasketch 2018] datasketch.
2018.
datasketch: Big
data looks small. https://github.com/ekzhu/
datasketch.
[Eduard and Lin 1998] Eduard, H., and Lin, C.-Y. 1998. Automated text summarization and the summarist system. In
Proceedings of a workshop on held at Baltimore.
[Engin and Treleaven 2019] Engin, Z., and Treleaven, P.
2019. Algorithmic government: Automating public services
and supporting civil servants in using data science technologies. The Computer Journal 62(3):448–460.
[extractdocx 2016] extractdocx. 2016. Simple function to
extract text from ms xml word document (.docx) without any dependencies. https://gist.github.com/
etienned/7539105. Accessed: 2018-05-30.
[Finkel, Grenager, and Manning 2005] Finkel,
J.
R.;
Grenager, T.; and Manning, C. 2005. Incorporating
non-local information into information extraction systems
by gibbs sampling. Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics 363370.
[Garcı́a-Hernández et al. 2008] Garcı́a-Hernández, R. A.;
Montiel, R.; Ledeneva, Y.; Rendón, E.; Gelbukh, A.; and
Cruz, R. 2008. Text summarization by sentence extraction
using unsupervised learning. In Mexican International Conference on Artificial Intelligence, 133–143. Springer.
[Gupta and Lehal 2010] Gupta, V., and Lehal, G. S. 2010. A
survey of text summarization extractive techniques. Journal
of emerging technologies in web intelligence 2(3):258–268.
[Honnibal and Montani 2017] Honnibal, M., and Montani, I.
2017. spaCy 2: Natural language understanding with Bloom

embeddings, convolutional neural networks and incremental
parsing. To appear.
[Kouziokas 2017] Kouziokas, G. N. 2017. The application of
artificial intelligence in public administration for forecasting
high crime risk transportation areas in urban environment.
Transportation research procedia 24:467–473.
[Mehr, Ash, and Fellow 2017] Mehr, H.; Ash, H.; and Fellow, D. 2017. Artificial intelligence for citizen services
and government. Ash Cent. Democr. Gov. Innov. Harvard
Kennedy Sch., no. August 1–12.
[Mihalcea and Tarau 2004] Mihalcea, R., and Tarau, P. 2004.
Textrank: Bringing order into text. In Proceedings of the
2004 conference on empirical methods in natural language
processing.
[Nathan 2016] Nathan, P. 2016. Pytextrank, a python implementation of textrank for text document nlp parsing
and summarization. https://github.com/ceteri/
pytextrank/.
[NetworkX developer team 2014] NetworkX
developer
team. 2014. Networkx.
[Scikit-learn 2018] Scikit-learn.
2018.
Creating a module for sentiment analysis with
nltk.
https://pythonprogramming.net/
sentiment-analysis-module-nltk-tutorial/.
[Siddiqi and Sharan 2015] Siddiqi, S., and Sharan, A. 2015.
Keyword and keyphrase extraction techniques: a literature
review. International Journal of Computer Applications
109(2).
[Sun and Medaglia 2019] Sun, T. Q., and Medaglia, R. 2019.
Mapping the challenges of artificial intelligence in the public sector: Evidence from public healthcare. Government
Information Quarterly 36(2):368–383.
[Thomas, Bharti, and Babu 2016] Thomas, J. R.; Bharti,
S. K.; and Babu, K. S. 2016. Automatic keyword extraction
for text summarization in e-newspapers. In Proceedings of
the international conference on informatics and analytics,
86. ACM.
[Timms 2016] Timms, M. J. 2016. Letting artificial intelligence in education out of the box: educational cobots and
smart classrooms. International Journal of Artificial Intelligence in Education 26(2):701–712.
[Valle-Cruz et al. 2019] Valle-Cruz,
D.;
Alejandro
Ruvalcaba-Gomez, E.; Sandoval-Almazan, R.; and Ignacio Criado, J. 2019. A review of artificial intelligence in
government and its potential from a public policy perspective. In 20th Annual International Conference on Digital
Government Research, 91–99. ACM.
[Wirtz, Weyerer, and Geyer 2019] Wirtz, B. W.; Weyerer,
J. C.; and Geyer, C. 2019. Artificial intelligence and the
public sector - applications and challenges. International
Journal of Public Administration 42(7):596–615.
[Wong, Wu, and Li 2008] Wong, K.-F.; Wu, M.; and Li, W.
2008. Extractive summarization using supervised and semisupervised learning. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1,
985–992. Association for Computational Linguistics.

