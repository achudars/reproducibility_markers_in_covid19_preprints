Equal-Subset-Sum Faster Than the Meet-in-the-Middle

arXiv:1905.02424v2 [cs.DS] 3 Jul 2019

Marcin Mucha∗

Jesper Nederlof†

Jakub Pawlewicz‡

Karol Węgrzycki§

In the Equal-Subset-Sum problem, we are given a set S of n integers and the problem is
to decide if there exist two disjoint nonempty subsets A, B ⊆ S, whose elements sum up to the
same value. The problem is NP-complete. The state-of-the-art algorithm runs in O∗ (3n/2 ) ≤
O∗ (1.7321n ) time and is based on the meet-in-the-middle technique. In this paper, we improve
upon this algorithm and give O∗ (1.7088n ) worst case Monte Carlo algorithm. This answers a
question suggested by Woeginger in his inspirational survey.
Additionally, we analyse the polynomial space algorithm for Equal-Subset-Sum. A naive
polynomial space algorithm for Equal-Subset-Sum runs in O∗ (3n ) time. With read-only access
to the exponentially many random bits, we show a randomized algorithm running in O∗ (2.6817n )
time and polynomial space.

∗

Institute of Informatics, University of Warsaw, Poland, mucha@mimuw.edu.pl. Supported by project TOTAL that
has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research
and innovation programme (grant agreement No 677651).
†
Eindhoven University of Technology, The Netherlands, j.nederlof@tue.nl. Supported by the Netherlands Organization for Scientific Research under project no. 024.002.003 and the European Research Council under project
no. 617951.
‡
Institute of Informatics, University of Warsaw, Poland, pan@mimuw.edu.pl.
§
Institute of Informatics, University of Warsaw, Poland, k.wegrzycki@mimuw.edu.pl. Supported by the grants
2016/21/N/ST6/01468 and 2018/28/T/ST6/00084 of the Polish National Science Center and project TOTAL that
has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research
and innovation programme (grant agreement No 677651).

1

Introduction

In the Subset-Sum problem, we are given as input a set S of n integers a1 , . . . , an and a target
t. The task is to decide if there exists a subset of S, such that a total sum of the numbers in this
subset is equal to t. This can be formulated in the following form:
n
X

xi ai = t

i=1

and the task is to ﬁnd xi ∈ {0, 1}. Subset-Sum is one of the fundamental NP-complete
problems. Study on the exact complexity of Subset-Sum led to the discovery of one of the most
fundamental algorithmic tool: meet-in-the-middle. Horowitz and Sahni [24] used this technique to
give a O∗ (2n/2 ) algorithm for Subset-Sum in the following way: First, rewrite the Subset-Sum
equation:
⌊n/2⌋

X
i=1

xi ai = t −

n
X

x i ai .

⌊n/2⌋+1

Then enumerate all O(2n/2 ) possible values of the left side L(x1 , . . . , x⌊n/2⌋ ) and O(2n/2 ) possible
values of the right side R(x⌊n/2⌋+1 , . . . , xn ). After that, it remains to look for the value that occurs
in both L and R, i.e., meeting the tables L and R. One can do that eﬃciently by sorting (see [24]
for details). To summarize, meet-in-the-middle technique is based on rewriting the formula as an
equation between two functions and eﬃciently seeking any value that occurs in both of their images.
Later, Schroeppel and Shamir [38] observed that space usage of meet-in-the-middle can be
improved to O∗ (2n/4 ) by using space-eﬃcient algorithm for 4-SUM. However, the time complexity
remains unchallenged and one of the most prominent open problem in the area of exact algorithms
is to improve upon meet-in-the-middle for Subset-Sum:
Open Question 1. Can Subset-Sum be solved in O∗ (2(0.5−δ)n ) time for some constant δ > 0?
In this paper, we consider the Equal-Subset-Sum problem. We are given a set S of n integers
and the task is to decide if there exist two disjoint nonempty subsets A, B ⊆ S, whose elements
sum up to the same value. Similarly to Subset-Sum, this problem is NP-complete [44]. In the
inspirational survey, Woeginger [43] noticed Equal-Subset-Sum can be solved by using meet-inthe-middle and asked if it can be improved: 1
Open Question 2 (c.f., [42],[43]). Can we improve upon the meet-in-the-middle algorithm for
Equal-Subset-Sum?
The folklore meet-in-the-middle algorithm for Equal-Subset-Sum (that we will present in the
next paragraph) works in O∗ (3n/2 ) time.
Folklore algorithm for Equal-Subset-Sum First, we arbitrarily partition S into S1 =
{a1 , . . . , a⌊n/2⌋ } and S2 = {a⌊n/2⌋+1 , . . . , an }. Recall that in Equal-Subset-Sum we seek two
subsets A, B ⊆ S, such that A ∩ B = ∅ and Σ(A) = Σ(B). We can write the solution as 4 subsets:
A1 = A∩S1 , A2 = A∩S2 , B1 = B ∩S1 and B2 = B ∩S2 , such that: Σ(A1 )+Σ(A2 ) = Σ(B1 )+Σ(B2 ).
In particular, it means that: Σ(A1 ) − Σ(B1 ) = Σ(B2 ) − Σ(A2 ). So, the problem reduces to ﬁnding
two vectors x ∈ {−1, 0, 1}⌊n/2⌋ and y ∈ {−1, 0, 1}⌈n/2⌉ , such that:
1

[42, 43] noticed that 4-SUM gives O∗ (2n ) algorithm, but it actually gives a O∗ (3n/2 ) algorithm, see Appendix C.

1

⌊n/2⌋

X
i=1

xi ai =

⌈n/2⌉

X

yi ai+⌊n/2⌋ .

i=1

We can do this in O∗ (3n/2 ) time as follows. First, enumerate and store all 3⌊n/2⌋ possible values
of the left side of the equation and all 3⌈n/2⌉ possible values of the right side of the equation. Then
look for a value that occurs in both tables (collision) in time O∗ (3n/2 ) by sorting the values. The
total running time is therefore O∗ (3n/2 ). Analogously to Subset-Sum, one can improve the space
usage of the above algorithm to O∗ (3n/4 ) (see Appendix C).
A common pattern seems unavoidable in algorithms for Subset-Sum and Equal-SubsetSum: we have to go through all possible values of the left and the right side of the equation. This
enumeration dominates the time used to solve the problem. So, it was conceivable that perhaps
no improvement for Equal-Subset-Sum could be obtained unless we improve an algorithm for
Subset-Sum ﬁrst [42, 43].

1.1

Our Contribution

While the meet-in-the-middle algorithm remains unchallenged for Subset-Sum, we show that,
surprisingly, we can improve the algorithm for Equal-Subset-Sum. The main result of this paper
is the following theorem.
Theorem 1.1. Equal-Subset-Sum can be solved in O∗ (1.7088n ) time with high probability.
This positively answers Open Question 2. To prove this result we observe that the worst case for
the meet-in-the-middle algorithm is that of a balanced solution, i.e., when |A| = |B| = |S \(A∪B)| ≈
n/3. We propose a substantially diﬀerent algorithm, that runs in O∗ (22/3n ) time for that case. The
crucial insight of the new approach is the fact that when |A| ≈ |B| ≈ n/3, then there is an abundance
of pairs X, Y ⊆ S, X 6= Y with Σ(X) = Σ(Y ). We use the representation technique to exploit this.
Interestingly, that technique was initially developed to solve the average case Subset-Sum [9, 25].
Our second result is an improved algorithm for Equal-Subset-Sum running in polynomial
space. The naive algorithm in polynomial space works in O∗ (3n ) time by enumerating all possible
disjoint pairs of subsets of S. This algorithm is analogous to the O∗ (2n ) polynomial space algorithm
for Subset-Sum. Recently, Bansal et al. [6] proposed a O∗ (20.86n ) algorithm for Subset-Sum on
the machine that has access to the exponential number of random bits. We show that a similar idea
can be used for Equal-Subset-Sum.
Theorem 1.2. There exists a Monte Carlo algorithm which solves Equal-Subset-Sum in polynomial space and time O∗ (2.6817n ). The algorithm assumes random read-only access to exponentially
many random bits.
This result is interesting for two reasons. First, Bansal et al. [6] require nontrivial results in
information theory. Our algorithm is relatively simple and does not need such techniques. Second,
the approach of Bansal et al. [6] developed for Subset-Sum has a barrier, i.e., signiﬁcantly new
ideas must be introduced to get an algorithm running faster than O∗ (20.75n ). In our case, this
corresponds to the algorithm running in O∗ (21.5n ) ≤ O∗ (2.8285n ) time and polynomial space (for
elaboration see Section 4). We show that relatively simple observations about Equal-Subset-Sum
enable us to give a slightly faster algorithm in polynomial space.

2

1.2

Related Work

The Equal-Subset-Sum was introduced by Woeginger and Yu [44] who showed that the problem
is NP-complete. This reduction automatically excludes 2o(n) algorithms for Equal-Subset-Sum
assuming ETH (see Appendix B), hence for this problem we aspire to optimize the constant in the
exponent. The best known constant comes from the meet-in-the-middle algorithm. Woeginger [43]
asked if this algorithm for Equal-Subset-Sum can be improved.
Exact algorithms for Subset-Sum: Nederlof et al. [35] proved that in the exact setting Knapsack and Subset-Sum problems are equivalent.
Schroeppel and Shamir [38] showed that the meet-in-the-middle algorithm admits a time-space
tradeoﬀ, i.e., T S 2 ≤ O∗ (2n ), where T is the running time of the algorithm and S ≤ O∗ (2n/2 ) is
the space of an algorithm. This tradeoﬀ was improved by Austrin et al. [2] for almost all tradeoﬀ
parameters.
Austrin et al. [3] considered Subset-Sum parametrized by the maximum bin size β and obtained
algorithm running in time O∗ (20.3399n β 4 ). Subsequently, Austrin et al. [4] showed that one can get
a faster algorithm for Subset-Sum than meet-in-the-middle if β ≤ 2(0.5−ε)n or β ≥ 20.661n . In this
paper, we use the hash function that is based on their ideas. Moreover, the ideas in [3, 4] were used
in the recent breakthrough polynomial space algorithm [6] running in O∗ (20.86n ) time.
From the pseudopolynomial algorithms perspective Knapsack and Subset-Sum admit O(nt)
algorithm, where t is a value of a target. Recently, for Subset-Sum the pseudopolynomial algorithm
e
e √nt) time by Koiliaris and Xu [29] and randomized O(n+t)
was improved to run in deterministic O(
time by Bringmann [11] (and simpliﬁed, see [27, 30]). However, these algorithms have a drawback
of running in pseudopolynomial space O∗ (t). Surprisingly, Lokshtanov and Nederlof [32] presented
e 3 t) and space O(n
e 2 ) which was later improved to O(nt)
e
an algorithm running in time O(n
time and
e
O(n log t) space assuming the Extended Riemann Hypothesis [11].
0.99 ) exists for Subsete
From a lower bounds perspective, no algorithm working in O(poly(n)t
Sum assuming SETH or SetCover conjecture [18, 1].
Approximation: Woeginger and Yu [44] presented the approximation algorithm for EqualSubset-Sum with the worst case ratio of 1.324. Bazgan et al. [7] considered a diﬀerent formulation
of approximation for Equal-Subset-Sum and showed an FPTAS for it.
Cryptography and the average case complexity: In 1978 Knapsack problems were introduced into cryptography by Merkle and Hellman [34]. They introduced a Knapsack based public
key cryptosystem. Subsequently, their scheme was broken by using lattice reduction [39]. After
that, many knapsack cryptosystems were broken with low-density attacks [31, 17].
More recently, Impagliazzo and Naor [26] introduced a cryptographic
is provably
P scheme that
→
−
→
−
l(n)
as secure as Subset-Sum. They proposed a function f ( a , S) = a , i∈S ai (mod 2 ), i.e., the
→
function which concatenates −
a with the sum of the ai ’s for i ∈ S. Function f is a mapping of an
→
n bit string S to an l(n) bit string and −
a are a ﬁxed parameter. Our algorithms can be thought of
as an attempt to ﬁnd a collision of such a function in the worst case.
However, in the average case more eﬃcient algorithms are known. Wagner [41] showed that
when solving problems involving sums of elements from lists, one can obtain faster algorithms when
there are many possible solutions. In the breakthrough paper, Howgrave-Graham and Joux [25] gave
O∗ (20.337n ) algorithm for an average case Subset-Sum. It was subsequently improved by Becker
et al. [9] who gave an algorithm running in O∗ (20.291n ). These papers introduced a representation
technique that is a crucial ingredient in our proofs.
3

Total search problems: The Number Balancing problem is: given
P n realPnumbers a1 , . . . , an ∈
[0, 1], ﬁnd two disjoint subsets I, J ⊆ [n], such that the diﬀerence | i∈I ai − j∈J aj | is minimized.
The pigeonhole principle and
the Chebyshev’s inequality guarantee that there exists a solution
√
n
with diﬀerence at most O( 2n ). Karmarkar and Karp [28] showed that in polynomial time one can
produce a solution with diﬀerence at most n−Θ(log n) , but since then no further improvement is
known.
Papadimitriou [36] considered the problem Equal Sums: given n positive integers such that their
total sum is less than 2n − 1, ﬁnd two subsets with the same sum. By the pigeonhole principle the
solution always exists, hence the decision version of this problem is obviously in P. However the
hard part is to actually ﬁnd a solution. Equal Sums is in class PPP but it remains open to show
that it is PPP-complete. Recently, this question gained some momentum. Hoberg et al. [23] showed
that Number Balancing is as hard as Minkowski. Ban et al. [5] showed the reduction from Equal
Sums to Minkowski and conjectured that Minkowski is complete for the class PPP. Very recently,
Sotiraki et al. [40] identiﬁed the ﬁrst natural problem complete for PPP.
In Appendix E we show that our techniques can also be used to solve Number Balancing for
integers in O∗ (1.7088n ) time.
Combinatorial Number Theory: If Σ(S) < 2n − 1, then by the pigeonhole principle the answer to the decision version of Equal-Subset-Sum on S is always YES. In 1931 Paul Erdős was
interested in the smallest maximum value of S, such that the answer to Equal-Subset-Sum on S
is NO, i.e., he considered the function:
f (n) = min{max{S} | all subsets of S are distinct, |S| = n, S ⊆ N}
√
and showed f (n) > 2n /(10 n) [19]. The ﬁrst nontrivial upper bound on f was f (n) ≤ 2n−2 (for
suﬃciently large n) [16]. Subsequently, Lunnon [33] proved that f (n) ≤ 0.2246 · 2n and Bohman
[10] showed f (n) ≤ 0.22002 · 2n . Erdős [20] oﬀered 500 dollars for proof or disproof of conjecture
that f (n) ≥ c2n for some constant c.
Other Variants: Equal-Subset-Sum has some connections to the study of the structure of
DNA molecules [14, 15, 12]. Cieliebak et al. [13] considered k-Equal-Subset-Sum, in which we
need to ﬁnd k disjoint subsets of a given set with the same sum. They obtained several algorithms
that depend on certain restrictions of the sets (e.g., small cardinality of a solution). In the following
work, Cieliebak et al. [15] considered other variants of Equal-Subset-Sum and proved their NPhardness.

2

Preliminaries

e
Throughout the paper we use the O∗ notation to hide factors polynomial in the input size and the O
notation to hide factors logarithmic in the input size. We also use [n] to denoteP
the set {1, . . . , n}.
If S = {a1 , .P
. . , an } is a set of integers and X ⊆ {1, . . . , n}, then ΣS (X) :=
i∈X ai . Also, we
use Σ(S) = s∈S s to denote the sum of the elements of the set. We use the binomial coeﬃcient

notation for sets, i.e., for a set S the symbol Sk = {X ⊆ S | |S| = k} is the set of all subsets of the
set S of size exactly k.
We may assume that the input to Equal-Subset-Sum has the following properties:
• the input set S = {a1 , . . . , an } consists of positive integers,
4

•

Pn

i=1 ai

< 2τ n for a constant τ < 10,

• integer n is a multiple of 12.
These are standard assumptions for Subset-Sum (e.g., [3, 22]). For completeness, in Appendix A we prove how to apply reductions to Equal-Subset-Sum to ensure these properties.
We need the following theorem concerning the density of prime numbers [21, p. 371, Eq.
(22.19.3)].
Lemma 2.1. For a large enough integer b, there exist at least 2b /b prime numbers in the interval
[2b , 2b+1 ].
The binary entropy function is h(α) = −α log2 α − (1 − α) log 2 (1 − α) for α ∈ (0, 1) and
h(0) = h(1) = 0. For all integers n ≥ 1 and α ∈ [0, 1] such
that σn is an integer, we have the
n
following upper bound on the binomial coeﬃcient [37]: αn ≤ 2h(α)n . We also need a standard
p
bound on binary entropy function h(x) ≤ 2 x(1 − x).
Throughout this paper all logarithms are base 2.

3

Faster Exponential Space Algorithm

In this section, we improve upon the meet-in-the-middle algorithm for Equal-Subset-Sum.
Theorem 3.1. Equal-Subset-Sum can be solved in O∗ (1.7088n ) time with high probability.
Theorem 3.1 is proved by using two diﬀerent algorithms for Equal-Subset-Sum. To bound
the trade-oﬀ between these algorithms we introduce the concept of a minimum solution.
Definition 3.2 (Minimum Solution). For a set S of positive integers we say that a solution A, B ⊆ S
is a minimum solution if its size |A| + |B| is smallest possible.
We now assume that the size of the minimum solution has even size for simplicity of presentation.
The algorithm and analysis for the case of odd-sized minimum solution is similar, but somewhat
more messy due to all the ﬂoors and ceilings one needs to take care of.
In Section 3.1 we prove that the meet-in-the-middle approach for Equal-Subset-Sum already
gives algorithm running in time O∗ ((3 − ε)n/2 ) if the minimum solution A, B is unbalanced, i.e.,
′
′
||A ∪ B| − 2n
3 | > ε n for some ε > 0 depending on ε. Subsequently, in Section 3.2 we propose
an algorithm for balanced instances, i.e., when the size of a minimum solution is close to 2/3. In
2
particular, we show how to detect sets A, B with Σ(A) = Σ(B) and |A| ≈ |B| ≈ n3 , with an O∗ (2 3 n )
time algorithm. By bounding trade-oﬀ between the algorithms from Section 3.1 and Section 3.2 we
prove Theorem 3.1 and bound the running time numerically.

3.1

Equal-Subset-Sum for unbalanced solutions via meet-in-the-middle

Theorem 3.3. If S is a set of n integers
with a minimum solution of size ℓ, then Equal-Subset-Sum
 ℓ/2
2
) time with high probability.
with input S can be solved in O∗ ( n/2
ℓ/2
Proof of Theorem 3.3. Algorithm 1 uses the meet-in-the-middle approach restricted to solutions of
size ℓ. We will show that this algorithm solves Equal-Subset-Sum in the claimed running time.
The algorithm starts by randomly partitioning the set S into two equally sized sets S1 , S2 . Let
A, B be a ﬁxed minimum solution of size |A ∪ B| = ℓ. We will later show that with Ω(1/poly(n))
5

Algorithm 1 UnbalancedEqualSubsetSum(S, ℓ)
1: Randomly split S into two disjoint S1 , S2 ⊆ S, such that |S1 | = |S2 | = n/2
2: Enumerate C1 = {Σ(A1 ) − Σ(B1 ) | A1 , B1 ⊆ S1 , A1 ∩ B1 = ∅, |A1 | + |B1 | = ℓ/2}
3: Enumerate C2 = {Σ(A2 ) − Σ(B2 ) | A2 , B2 ⊆ S2 , A2 ∩ B2 = ∅, |A2 | + |B2 | = ℓ/2}
4: if ∃x1 ∈ C1 , x2 ∈ C2 such that x1 + x2 = 0 then
5:
Let A1 , B1 ⊆ S1 be such that x1 = Σ(A1 ) − Σ(B1 )
6:
Let A2 , B2 ⊆ S2 be such that x2 = Σ(A2 ) − Σ(B2 )
7:
return (A1 ∪ A2 , B1 ∪ B2 )
8: end if
9: return NO
probability |(A ∪ B) ∩ S1 | = |(A ∪ B) ∩ S2 | = ℓ/2. We assume this is indeed the case and proceed
with meet-in-the-middle. For S1 we will list all A1 , B1 that could possibly be equal to S1 ∩ A and
S1 ∩ B, i.e. disjoint and with total size ℓ/2. We compute x = Σ(A1 ) − Σ(B1 ) and store all these in
C1 . We proceed analogously for S2 .
We then look for x1 ∈ C1 and x2 ∈ C2 such that x1 + x2 = 0. If we ﬁnd it then we identify the
sets A1 and B1 that correspond to x1 and sets A2 and B2 that correspond to x2 (the easiest way to
do that is to store with each element of C1 and C2 the corresponding pair of sets when generating
them). Finally we return (A1 ∪ A2 , B1 ∪ B2 ).
Probability of a good split: We now lower-bound the probability of S1 and S2 splitting
A ∪ B
n
ℓ 
n−ℓ
in half. There are n/2
possible equally sized partitions. Among these there are ℓ/2
(n−ℓ)/2
partitions that split A ∪ B in half. The probability that a random partition splits A and B in half
is:
ℓ 
n−ℓ 
1
2ℓ 2n−ℓ
ℓ/2 (n−ℓ)/2
=
≥
n 
2 2n
(n
+
1)
(n
+
1)2
n/2

n
2n
because n+1
≤ n/2
≤ 2n .
Running time: To enumerate C1 and C2 we need O∗ (

n/2 ℓ/2
2 )
ℓ/2

time, because ﬁrst we guess set

S1 ∩ (A ∪ B) of size ℓ/2 and then split between A and B in at most 2ℓ/2 ways. We then check the
existence of x1 ∈ C1 and x2 ∈ C2 such that x1 + x2 = 0 in O∗ ((|C1 | + |C2 |) log (|C1 | + |C2 |)) time
by sorting.
We can amplify the probability of a good split to O(1) by repeating the whole algorithm polynomially many times.
Correctness: With probability Ω(1/poly(n)) we divide the A ∪ B equally between S1 and S2 . If
that happens the set C1 contains x1 such that x1 = Σ(A∩S1 )−Σ(B ∩S1 ) and the set C2 contains x2
that x2 = Σ(A∩S2 )−Σ(B ∩S2 ). Note that x1 +x2 = Σ(A∩S1 )+Σ(A∩S2 )−Σ(B ∩S1 )−Σ(B ∩S2 ) =
Σ(A) − Σ(B) which is 0, since A, B is a solution. Therefore Algorithm 1 ﬁnds a solution of size ℓ
(but of course, it could be diﬀerent from A,B).

3.2

Equal-Subset-Sum for balanced solutions

Theorem 3.4. Given a set S of n integers with a minimum solution size ℓ ∈ ( 12 n, (1 − ε)n] for
some constant ε > 0, Equal-Subset-Sum can be solved in time O∗ (2ℓ ) w.h.p.
6

We use Algorithm 2 to prove Theorem 3.4. In this algorithm, we ﬁrst pick a random prime p
in the range [2n−ℓ , 2n−ℓ+1 ], as well as an integer t chosen uniformly at random from [1, 2n−ℓ ]. We
then compute the set C = {X ⊆ S | Σ(X) ≡p t}. In the analysis, we argue that with Ω(1/poly(n))
probability C contains two diﬀerent subsets X, Y of S with Σ(X) = Σ(Y ). To identify such pair it
is enough to sort the set |C| in time O(|C| log |C|), and then scan it. We return X \ Y and Y \ X
to guarantee that the returned sets are disjoint.
Algorithm 2 BalancedEqualSubsetSum(a1 , . . . , an , ℓ)
1:
2:
3:
4:
5:
6:

Pick a random prime p in [2n−ℓ , 2n−ℓ+1 ]
Pick a random number t in [1, 2n−ℓ ]
Let C = {X ⊆ S | Σ(X) ≡p t} be the set of candidates
with probability Ω(1/poly(n)).
Enumerate and store all elements of C
Find X, Y ∈ C, such that Σ(X) = Σ(Y )
return (X \ Y, Y \ X)

⊲ C contains two sets with equal sum
⊲ In time O∗ (|C| + 2n/2 )
⊲ In time O∗ (|C|)

We now analyse the correctness of Algorithm 2. Later, we will give a bound on the running time
and conclude the proof Theorem 3.4. First, observe the following:
Lemma 3.5. Let S be a set of n positive integers with minimum solution size of ℓ. Let
Ψ = {Σ(X) | X ⊆ S and ∃Y ⊆ S such that X 6= Y and Σ(X) = Σ(Y )} .

(1)

If ℓ > n2 , then |Ψ| ≥ 2n−ℓ (note that all elements in Ψ are different).
A

X

B

S
Figure 1: Scheme presents the set S of positive integers and two disjoint subsets A, B ⊆ S. The
point is that if Σ(A) = Σ(B) then for any subset X ⊆ S \ (A ∪ B) we have a guarantee that
Σ(A ∪ X) = Σ(B ∪ X).
Proof. Let A, B ⊆ S be a ﬁxed minimum solution to S. We know that ℓ = |A ∪ B|, Σ(A) = Σ(B)
and A ∩ B = ∅. With this in hand we construct set Ψ of 2n−ℓ pairs of diﬀerent X, Y ⊆ S with
Σ(X) = Σ(Y ).
Consider set Z = S \ (A ∪ B). By the bound on the size of A and B we know that |Z| = n − ℓ.
Now we construct our candidate pairs as follows: take any subset Z ′ ⊆ Z and note that X ∪ Z ′
and Y ∪ Z ′ satisfy Σ(X ∪ Z ′ ) = Σ(Y ∪ Z ′ ). There are 2|Z| possible subsets of set Z and the claim
follows.
Now we will prove that if ℓ > n2 then all subsets of Z have a diﬀerent sum. Assume for a
contradiction that there exist Z1 , Z2 ⊆ Z, such that Σ(Z1 ) = Σ(Z2 ) and Z1 6= Z2 . Then Z1 \ Z2 and
Z2 \ Z1 would give a solution smaller than A, B, because |Z| < ℓ. This contradicts the assumption
about the minimality of A, B. It follows that if ℓ > 12 n then all constructed pairs have a diﬀerent
sum.

7

Now, we consider the hashing function ht,p (x) = x + t (mod p). We prove that if the set Ψ (see
Equation 1) is suﬃciently large, then for a random choice of t, at least one element of set Ψ is in
the congruence class t.
Lemma 3.6. Let S be the set of n positive integers bounded by 2O(n) with minimum solution
of size ℓ and ℓ > n2 . For a random prime p ∈ [2n−ℓ , 2n−ℓ+1 ] and a random t ∈ [1, 2n−ℓ ] let
Ct,p = {X ⊆ S | Σ(X) ≡p t }. Then,
i
h
Pt,p ∃X, Y ∈ Ct,p Σ(X) = Σ(Y ), X 6= Y ≥ Ω(1/n2 ).

Proof. Let Ψ be the set deﬁned in (1). So Ψ ⊆ {1, . . . , 2O(n) }, and |Ψ| ≥ 2n−ℓ . It is suﬃcient to
bound the probability, that there exists an element a ∈ Ψ such a ≡p t. Let a1 , a2 ∈ Ψ be two
distinct elements.
Pp [a1 ≡p a2 ] = Pp [p divides |a1 − a2 |] ≤ O(n(n − ℓ)/2n−ℓ ).
This is because |a1 − a2 | can only have O(n) prime divisors, and we are sampling p from the set
of at least 2n−ℓ /(n − ℓ) primes by Lemma 2.1. Let k be the number of pairs a1 , a2 ∈ Ψ such that
2
a1 ≡p a2 . We have E [k] ≤ O(|Ψ| + (|Ψ|n)2 /2n−ℓ ). We know that |Ψ| ≥ 2n−ℓ , so 2|Ψ|
n−ℓ ≥ |Ψ| which
means that E [k] ≤ O((|Ψ|n)2 /2n−ℓ ). Hence, by Markov’s inequality k is at most O((|Ψ|n)2 /2n−ℓ )
with at least constant probability. If this does indeed happen, then


|Ψ|2
|Ψ|2
|{a (mod p) | a ∈ Ψ}| ≥
≥Ω
≥ Ω(2n−ℓ /n2 ),
k
(|Ψ|n)2 /2n−ℓ
and the probability that t chosen uniformly at random from [1, 2n−ℓ ] will be among one of the
elements of set {a (mod p) | a ∈ Ψ} is |{a (mod p) | a ∈ Ψ}|/2n−ℓ ≥ Ω(1/n2 ).
Proof of correctness of Algorithm 2. By Lemma 3.6, after choosing a random prime p and random
number t ∈ [1, 2n−ℓ ] the set C = {X ⊆ S | Σ(X) ≡p t} contains at least two subsets X, Y ⊆ S,
such that Σ(X) = Σ(Y ) with probability Ω(1/poly(n)). Algorithm 2 computes the set C and ﬁnds
X ′ , Y ′ ⊆ S, such that Σ(X ′ ) = Σ(Y ′ ). Then it returns the solution X ′ \ Y ′ , Y ′ \ X ′ .
Now we focus on bounding the running time of Algorithm 2. We start by bounding the size of
the candidate set C.
Claim 3.7. Let S be the set of n non-negative integers bounded by 2O(n) with a minimum solution
of size ℓ such that ℓ ≤ (1 − ε)n for some constant ε > 0 (think of ε = 1/100). For a random prime
p ∈ [2n−ℓ , 2n−ℓ+1 ] and a random number t ∈ [1, 2n−ℓ ] let Ct,p = {X ⊆ S | Σ(X) ≡p t }. Then
E [|Ct,p |] ≤ O∗ (2ℓ )
Proof. By the linearity of expectations:
E [|Ct,p |] =

X

X⊆S

Pt,p [p divides Σ(X) − t]

For the remaining part of the proof we focus on showing Pt,p [p divides Σ(X) − t] ≤ O∗ (2ℓ−n )
for a ﬁxed X ⊆ S. It automatically ﬁnishes the proof, because there are 2n possible subsets X.
8

We split the terms into two cases. If Σ(X) = t, then p divides Σ(X) − t with probability 1.
1
) because t is a random number
However, for a ﬁxed X ⊆ S, the probability that Σ(X) = t is O( 2n−ℓ
n−ℓ
n−ℓ
from [1, 2 ] and p ≥ 2 .
On the other hand, if Σ(X) 6= t, then by the assumption, the set S consists of non-negative
integers bounded by 2τ n for some constant τ > 0. In particular, |Σ(X) − t| ≤ 2τ n . This means that
τn
≤ τε = O(1) prime factors of size at least 2n−ℓ . Any prime number p
|Σ(X) − t| has at most n−ℓ
that divides Σ(X) − t must therefore be one of these numbers. By Lemma 2.1 there are at least
2n−ℓ /(n − ℓ) prime numbers in range [2n−ℓ , 2n−ℓ+1 ]. Hence, for a ﬁxed X ⊆ S the probability that
p divides Σ(X) − t is bounded by O(n2ℓ−n ).


Lemma 3.8. The set Ct,p can be enumerated in time O∗ max |Ct,p |, 2n/2 .
The proof of the above lemma is based on Schroeppel and Shamir [38] algorithm for SubsetSum. For a full proof of Lemma 3.8 see, e.g., Section 3.2 of [9]. Observe, that for our purposes the
running time is dominated by O∗ (|Ct,p |).

Proof of the running time of Algorithm 2. To enumerate the set Ct,p we need O∗ (|C| + 2n/2 ) time
(see Lemma 3.8). To ﬁnd two subsets X, Y ∈ C, such that Σ(X) = Σ(Y ) we need O∗ (|C| log |C|)
time: we sort C and scan it.
The prime number p is at most 2n−ℓ+1 and the expected size of C is O∗ (2ℓ ). Because we assumed
that ℓ > n2 the expected running time is O∗ (2ℓ ) (we can terminate algorithm when it exceeds O∗ (2ℓ )
to Monte Carlo guarantees). The probability of success is Ω(1/poly(n)). We can amplify it with
polynomial overhead to any constant by repetition.
This concludes the proof of Theorem 3.4.

3.3

Trade-off for Equal-Subset-Sum

In this section, we will proof the Theorem 3.1 by combining Theorem 3.4 and Theorem 3.3.
Proof of Theorem 3.1. Both Theorem 3.4 and Theorem 3.3 solve Equal-Subset-Sum. Hence, we
can focus on bounding the running time. By the trade-oﬀ between Theorem 3.4 (which works for
ℓ ∈ ( n2 , (1 − ε)n) and Theorem 3.3 the running time is:








n/2 ℓ/2
n/2 ℓ/2 ℓ
∗
O
max
2
+
max
min
2 ,2
ℓ/2
ℓ/2
ℓ∈[1,n/2]∪[(1−ε)n,n]
ℓ∈(n/2,(1−ε)n)
For simplicity of analysis we bounded the sums by the maximum (note that O∗ notation hides
polynomial factors). When ℓ ≤ n/2, the running time is maximized for ℓ = n/2, because (let
ℓ = αn):




 n
n/2 ℓ/2
∗
O
2
= O∗ 2 2 (h(α)+α)
ℓ/2

and the entropy function h(x) is increasing in range [0, 0.5). For ℓ = n2 the running time is
O∗ (20.75n ) ≤ O∗ (1.682n ). Similarly, p
we get a running time superior to the claimed one when
ℓ ∈ [(1 − ε)n, n]. Note that h(x) ≤ √
2 x(1 − x), which means that the running time is bounded
n
n
by O∗ (2 2 (h(1−ε)+(1−ε)) ) ≤ O∗ (2 2 (1+2 ε) ) which is smaller than our running time for a suﬃciently
small constant ε.
Finally, when ℓ ∈ [n/2, (1 − ε)n] we upper bound the running time by the:
9

O∗



max

ℓ∈[n/2,(1−ε)n)

oo
n
n n
.
min 2 2 (h(α)+α) , 2αn

The above expression is maximized when h(α) = α. By numeric calculations α < 0.77291, which
gives the ﬁnal running time O∗ (2αn ) ≤ O∗ (1.7088n ).

4

Polynomial Space Algorithm

The naive algorithm for Equal-Subset-Sum in polynomial space works in O∗ (3n ) time. We are
given a set S. We guess a set A ⊆ S and then guess a set B ⊆ S \ A. Finally, we check if
Σ(A) = Σ(B). The running time is:
 

|S|
|S| − |A|
∗
O
≤ O∗ (3n ).
|A|
|B|
Known techniques for Subset-Sum allow us to get an algorithm running in O∗ (21.5n ) and
polynomial space.

Theorem 4.1. There exists a Monte Carlo algorithm which solves Equal-Subset-Sum in polynomial space and O∗ (21.5n ) ≤ O∗ (2.8285n ) time. The algorithm assumes random read-only access
to exponentially many random bits.
A crucial ingredient of Theorem 4.1 is a nontrivial result for the Element Distinctness problem [6,
8]. In this problem, one is given read-only access to the elements of a list x ∈ [m]n and the task is
to ﬁnd two diﬀerent elements of the same value. The problem can be naively solved in O(n2 ) time
e
and O(1) space by brute force. Also by sorting, we can solve Element Distinctness in O(n)
time
3/2
e
e
and O(n)
space. Beame et al. [8] showed that the problem can be solved in O(n
) randomized
e
time and O(1)
space. The algorithm assumes access to a random hash function f : [m] → [n].

Proof of Theorem 4.1. We can guarantee random access to the list L = 2S of all subsets of the set
S = {a1 , . . . , an } on the ﬂy. Namely, for a pointer x ∈ {0, 1}n we can return an element of the list
L that corresponds to x in O∗ (1) time by choosing elements ai for which xi = 1. More precisely:
L(x1 , . . . , xn ) = {ai | i ∈ [n], xi = 1}.
Now to decide Equal-Subset-Sum on set S we execute the Element Distinctness algorithm
on the list L of sums of subsets. The list has size 2n , hence the algorithm runs in O∗ (21.5n ) time.
Element Distinctness uses only polylogarithmic space in the size of the input, hence our algorithm
uses polynomial space.
Quite unexpectedly we can still improve upon this algorithm.

4.1

Improved Polynomial Space Algorithm

In this section, we show an improved algorithm.
Theorem 4.2. There exists a Monte Carlo algorithm which solves Equal-Subset-Sum in polynomial space and time O∗ (2.6817n ). The algorithm assumes random read-only access to exponentially
many random bits.

10

Similarly to the exponential space algorithm for Equal-Subset-Sum, we will combine two
algorithms. We start with a generalization of Theorem 4.1 parametrized by the size of the solution.
Lemma 4.3. Let S be a set of n positive integers, A, B ⊆ S be the solution to Equal-Subset-Sum
(denote a = |A| and b = |B|). There exists a Monte Carlo algorithm which solves Equal-SubsetSum in polynomial space and time
   1.5 !
n
n
∗
O
.
+
a
b
The algorithm assumes random read-only access to exponentially many random bits.
Proof. The proof is just a repetition of the proof
of Theorem 4.1 for a ﬁxed sizes of solutions. Our

S
S
list L will consists of all subsets a and b . Then we run Element Distinctness algorithm, ﬁnd
any sets A, B ∈ L such that Σ(A) = Σ(B) and return A \ B, B \ A to make them disjoint.
e 1.5 ) and polylog(n)
The running time follows because Element Distinctness runs in time O(n
space.

Note that the runtime of Lemma 4.3 is maximized when |A| = |B| = n/2. The next algorithm
gives improvement in that case.
Lemma 4.4. Let S be a set of n positive integers, A, B ⊆ S be the solution to Equal-Subset-Sum
(denote a = |A| and b = |B|). There exists a Monte Carlo algorithm which solves Equal-SubsetSum in polynomial space and time

 
 

n 0.75(n−a) n 0.75(n−b)
∗
O min
2
,
2
.
a
b
The algorithm assumes random read-only access to exponentially many random bits.

Proof of Lemma 4.4. Without loss of generality, we focus on the case a ≤ b. First we guess a
solution set A ⊆ S. We answer YES if we ﬁnd set B ⊆ S \ A such that Σ(A) = Σ(B) or ﬁnd two
disjoint subsets with equal sum in S \ A. We show that we can do it in O∗ (20.75(|S\A|) ) time and
polynomial space which ﬁnishes the proof.
First, we arbitrarily partition set S \ A into two equally sized sets S1 and S2 . Then we create
a list L1 = [Σ(X) | X ⊆ S1 ] and list L2 = [Σ(A) − Σ(X) | X ⊆ S2 ]. We do not construct them
explicitly because it would take exponential space. Instead we provide a read-only access to them
(with the counter technique). We run Element Distinctness on concatenation of L1 and L2 . If
element distinctness found x ∈ L1 and y ∈ L2 such that x = y, then we backtrack and look for
X ⊆ S1 , such that Σ(X) = x and Y ⊆ S2 , such that Σ(Y ) = Σ(A) − y and return (A, X ∪ Y ) which
is a good solution, because Σ(Y ) + Σ(X) = Σ(A).
In the remaining case, i.e. when Element Distinctness ﬁnds a duplicate only in one of the lists
then, we get a feasible solution as well. Namely, assume that Element Distinctness ﬁnds x, y ∈ L1
such that x = y (the case when x, y ∈ L2 is analogous). Then we backtrack and look for two
corresponding sets X, Y ⊆ L1 such that X 6= Y and Σ(X) = Σ(Y ) = x. Finally we return
(X \ Y, Y \ X).
For the running time, note that the size of the list |L1 | = |L2 | = 20.5|S\A| . Hence Element
Distinctness runs in time O∗ ((|L1 | + |L2 |)1.5 ) = O∗ (20.75(n−a) ). The backtracking takes time
O∗ (|L1 | + |L2 |) and polynomial space because we scan through all subsets of S1 and all subsets
of S2 and look for a set with sum equal to the known value.

11

Proof of Theorem 4.2. By trade-oﬀ between Lemma 4.4 and Lemma 4.3 we get the following running
time:
(
(   
))!
 
1.5  
n
n
n
n
max
min
O∗
,
+
20.75(n−a) ,
20.75(n−b)
1≤a,b≤n
a
a
b
b
By symmetry this expression is maximized when a = b. Now we will write the exponents by
using entropy function (let a = αn):

oo
n
n
∗
1.5h(α)n (h(α)+0.75(1−α))n
O
,2
max min 2
α∈[0,1]

The expression is maximized when 1.5h(α) = h(α) + 0.75(1 − α), By numerical computations
α < 0.36751, which means that the running time is O∗ (21.42312n ) ≤ O∗ (2.6817n ).

5

Conclusion and Open Problems

In this paper, we break two natural barriers for Equal-Subset-Sum: we propose an improvement
upon the meet-in-the-middle algorithm and upon the polynomial space algorithm. Our techniques
have additional applications in the problem of ﬁnding collision of hash function in cryptography
and the number balancing problem (see Appendix E).
We believe that our algorithms can potentially be improved with more involved techniques.
However, getting close to the running time of Subset-Sum seems ambitious. In Appendix B we
show that a faster algorithm than O∗ (1.1893n ) for Equal-Subset-Sum would yield a faster than
O∗ (2n/2 ) algorithm for Subset-Sum. It is quite far from our bound O∗ (1.7088n ). The main open
problem is therefore to close the gap between upper and lower bounds for Equal-Subset-Sum.

6

Acknowledgment

The authors would like to thank anonymous reviewers for their remarks and suggestions. This
research has been initiated during Parameterized Algorithms Retreat of University of Warsaw 2019,
Karpacz, 25.02-01.03.2019.

References
[1] A. Abboud, K. Bringmann, D. Hermelin, and D. Shabtay. Seth-based lower bounds for subset
sum and bicriteria path. In T. M. Chan, editor, Proceedings of the Thirtieth Annual ACMSIAM Symposium on Discrete Algorithms, SODA 2019, San Diego, California, USA, January
6-9, 2019, pages 41–57. SIAM, 2019.
[2] P. Austrin, P. Kaski, M. Koivisto, and J. Määttä. Space-time tradeoﬀs for subset sum: An
improved worst case algorithm. In F. V. Fomin, R. Freivalds, M. Z. Kwiatkowska, and D. Peleg, editors, Automata, Languages, and Programming - 40th International Colloquium, ICALP
2013, Riga, Latvia, July 8-12, 2013, Proceedings, Part I, volume 7965 of Lecture Notes in
Computer Science, pages 45–56. Springer, 2013.

12

[3] P. Austrin, P. Kaski, M. Koivisto, and J. Nederlof. Subset sum in the absence of concentration.
In E. W. Mayr and N. Ollinger, editors, 32nd International Symposium on Theoretical Aspects
of Computer Science, STACS 2015, March 4-7, 2015, Garching, Germany, volume 30 of LIPIcs,
pages 48–61. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2015.
[4] P. Austrin, P. Kaski, M. Koivisto, and J. Nederlof. Dense subset sum may be the hardest.
In N. Ollinger and H. Vollmer, editors, 33rd Symposium on Theoretical Aspects of Computer
Science, STACS 2016, February 17-20, 2016, Orléans, France, volume 47 of LIPIcs, pages
13:1–13:14. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.
[5] F. Ban, K. Jain, C. H. Papadimitriou, C. Psomas, and A. Rubinstein. Reductions in PPP. Inf.
Process. Lett., 145:48–52, 2019.
[6] N. Bansal, S. Garg, J. Nederlof, and N. Vyas. Faster space-eﬃcient algorithms for subset sum
and k-sum. In H. Hatami, P. McKenzie, and V. King, editors, Proceedings of the 49th Annual
ACM SIGACT Symposium on Theory of Computing, STOC 2017, Montreal, QC, Canada,
June 19-23, 2017, pages 198–209. ACM, 2017.
[7] C. Bazgan, M. Santha, and Zs. Tuza. Eﬃcient approximation algorithms for the subset-sums
equality problem. In International Colloquium on Automata, Languages, and Programming,
pages 387–396. Springer, 1998.
[8] P. Beame, R. Cliﬀord, and W. Machmouchi. Element distinctness, frequency moments, and
sliding windows. In 54th Annual IEEE Symposium on Foundations of Computer Science, FOCS
2013, 26-29 October, 2013, Berkeley, CA, USA, pages 290–299. IEEE Computer Society, 2013.
[9] A. Becker, J. Coron, and A. Joux. Improved generic algorithms for hard knapsacks. In K. G.
Paterson, editor, Advances in Cryptology - EUROCRYPT 2011 - 30th Annual International
Conference on the Theory and Applications of Cryptographic Techniques, Tallinn, Estonia,
May 15-19, 2011. Proceedings, volume 6632 of Lecture Notes in Computer Science, pages 364–
385. Springer, 2011.
[10] T. Bohman. A sum packing problem of Erdős and the Conway-Guy sequence. Proceedings of
the American Mathematical Society, 124(12):3627–3636, 1996.
[11] K. Bringmann. A near-linear pseudopolynomial time algorithm for subset sum. In Proceedings
of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA ’17, pages
1073–1084, Philadelphia, PA, USA, 2017. Society for Industrial and Applied Mathematics.
[12] M. Cieliebak. Algorithms and hardness results for DNA physical mapping, protein identification,
and related combinatorial problems. PhD thesis, ETH Zürich, 2003.
[13] M. Cieliebak, S. Eidenbenz, and A. Pagourtzis. Composing equipotent teams. In International
Symposium on Fundamentals of Computation Theory, pages 98–108. Springer, 2003.
[14] M. Cieliebak, S. Eidenbenz, and P. Penna. Noisy data make the partial digest problem np-hard.
In International Workshop on Algorithms in Bioinformatics, pages 111–123. Springer, 2003.
[15] M. Cieliebak, S. Eidenbenz, A. Pagourtzis, and K. Schlude. On the complexity of variations of
equal sum subsets. Nord. J. Comput., 14(3):151–172, 2008.
[16] J. H. Conway and R. K. Guy. Sets of natural numbers with distinct subset sums. Notices
Amer. Math. Soc, 15:345, 1968.
13

[17] M. J. Coster, A. Joux, B. A. LaMacchia, A. M. Odlyzko, C. Schnorr, and J. Stern. Improved
low-density subset sum algorithms. Computational Complexity, 2:111–128, 1992.
[18] M. Cygan, H. Dell, D. Lokshtanov, D. Marx, J. Nederlof, Y. Okamoto, R. Paturi, S. Saurabh,
and M. Wahlström. On problems as hard as CNF-SAT. In Proceedings of the 27th Conference
on Computational Complexity, CCC 2012, Porto, Portugal, June 26-29, 2012, pages 74–84.
IEEE Computer Society, 2012.
[19] P. Erdős. Problems and results in additive number theory. Journal London Wash. Soc, 16:
212–215, 1941.
[20] P. Erdős. A survey of problems in combinatorial number theory. Annals of Discrete Mathematics, 6:89–115, 1980.
[21] G. H. Hardy, E. M. Wright, et al. An introduction to the theory of numbers. Oxford university
press, 1979.
[22] D. Harnik and M. Naor. On the compressibility of NP instances and cryptographic applications.
SIAM J. Comput., 39(5):1667–1713, 2010.
[23] R. Hoberg, H. Ramadas, T. Rothvoss, and X. Yang. Number balancing is as hard as Minkowski’s
theorem and shortest vector. 10328:254–266, 2017.
[24] E. Horowitz and S. Sahni. Computing partitions with applications to the knapsack problem.
J. ACM, 21(2):277–292, 1974.
[25] N. Howgrave-Graham and A. Joux. New generic algorithms for hard knapsacks. In H. Gilbert,
editor, Advances in Cryptology - EUROCRYPT 2010, 29th Annual International Conference on
the Theory and Applications of Cryptographic Techniques, Monaco / French Riviera, May 30 June 3, 2010. Proceedings, volume 6110 of Lecture Notes in Computer Science, pages 235–256.
Springer, 2010.
[26] R. Impagliazzo and M. Naor. Eﬃcient cryptographic schemes provably as secure as subset sum.
J. Cryptology, 9(4):199–216, 1996.
[27] C. Jin and H. Wu. A simple near-linear pseudopolynomial time randomized algorithm for
subset sum. In J. T. Fineman and M. Mitzenmacher, editors, 2nd Symposium on Simplicity
in Algorithms, SOSA@SODA 2019, January 8-9, 2019 - San Diego, CA, USA, volume 69 of
OASICS, pages 17:1–17:6. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2019.
[28] N. Karmarkar and R. M. Karp. An eﬃcient approximation scheme for the one-dimensional binpacking problem. In 23rd Annual Symposium on Foundations of Computer Science, Chicago,
Illinois, USA, 3-5 November 1982, pages 312–320. IEEE Computer Society, 1982.
[29] K. Koiliaris and C. Xu. A faster pseudopolynomial time algorithm for subset sum. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA ’17,
pages 1062–1072, Philadelphia, PA, USA, 2017. Society for Industrial and Applied Mathematics.
[30] K. Koiliaris and C. Xu. Subset sum made simple. CoRR, abs/1807.08248, 2018.
[31] J. C. Lagarias and A. M. Odlyzko. Solving low-density subset sum problems. J. ACM, 32(1):
229–246, 1985.
14

[32] D. Lokshtanov and J. Nederlof. Saving space by algebraization. In L. J. Schulman, editor,
Proceedings of the 42nd ACM Symposium on Theory of Computing, STOC 2010, Cambridge,
Massachusetts, USA, 5-8 June 2010, pages 321–330. ACM, 2010.
[33] W. F. Lunnon. Integer sets with distinct subset-sums. Mathematics of Computation, 50(181):
297–320, 1988.
[34] R. C. Merkle and M. E. Hellman. Hiding information and signatures in trapdoor knapsacks.
IEEE Trans. Information Theory, 24(5):525–530, 1978.
[35] J. Nederlof, E. J. van Leeuwen, and R. van der Zwaan. Reducing a target interval to a few
exact queries. In B. Rovan, V. Sassone, and P. Widmayer, editors, Mathematical Foundations
of Computer Science 2012 - 37th International Symposium, MFCS 2012, Bratislava, Slovakia,
August 27-31, 2012. Proceedings, volume 7464 of Lecture Notes in Computer Science, pages
718–727. Springer, 2012.
[36] C. H. Papadimitriou. On the complexity of the parity argument and other ineﬃcient proofs of
existence. J. Comput. Syst. Sci., 48(3):498–532, 1994.
[37] H. Robbins. A remark on Stirling’s formula. The American mathematical monthly, 62(1):26–29,
1955.
[38] R. Schroeppel and A. Shamir. A t=o(2n/2 ), s=o(2n/4 ) algorithm for certain np-complete
problems. SIAM J. Comput., 10(3):456–464, 1981.
[39] A. Shamir. A polynomial-time algorithm for breaking the basic merkle-hellman cryptosystem.
IEEE Trans. Information Theory, 30(5):699–704, 1984.
[40] K. Sotiraki, M. Zampetakis, and G. Zirdelis. Ppp-completeness with connections to cryptography. In M. Thorup, editor, 59th IEEE Annual Symposium on Foundations of Computer Science,
FOCS 2018, Paris, France, October 7-9, 2018, pages 148–158. IEEE Computer Society, 2018.
[41] D. A. Wagner. A generalized birthday problem. In M. Yung, editor, Advances in Cryptology CRYPTO 2002, 22nd Annual International Cryptology Conference, Santa Barbara, California,
USA, August 18-22, 2002, Proceedings, volume 2442 of Lecture Notes in Computer Science,
pages 288–303. Springer, 2002.
[42] G. J. Woeginger. Space and time complexity of exact algorithms: Some open problems (invited
talk). In R. G. Downey, M. R. Fellows, and F. K. H. A. Dehne, editors, Parameterized and
Exact Computation, First International Workshop, IWPEC 2004, Bergen, Norway, September
14-17, 2004, Proceedings, volume 3162 of Lecture Notes in Computer Science, pages 281–290.
Springer, 2004.
[43] G. J. Woeginger. Open problems around exact algorithms. Discrete Applied Mathematics, 156
(3):397–405, 2008.
[44] G. J. Woeginger and Z. Yu. On the equal-subset-sum problem. Inf. Process. Lett., 42(6):
299–302, 1992.

15

A

Preprocessing and Randomized Compression for Equal-SubsetSum

We will repeat the arguments from [22]. Similar arguments are also present in [3, 4].
Theorem A.1. Given set S of n integers a1 , . . . , an ∈ {−2m , . . . , 2m } (with m ≫ n). In O(poly(n, m))
time we can construct a set S ′ that consists of n positive integers in {1, . . . , 28n } such that:
∃X, Y ⊆ S, such that Σ(X) = Σ(Y ) iff ∃X ′ , Y ′ ⊆ S ′ such that Σ(X ′ ) = Σ(Y ′ )

with probability at least 1−2−n or we will solve Equal-Subset-Sum on that instance in polynomial
time.
Proof. If 0 ∈ S, then we immediately answer YES, because sets A = {0} and B = ∅ are a proper
solution to Equal-Subset-Sum. If m ≥ 2n , then the algorithm running in time O(m4n ) ≥ O(m3 )
runs in polynomial time of the instance size. Hence we can assume that m < 2n and 0 ∈
/ S.
7n
8n
Pick a random prime p ∈ [2 , 2 ]. We will transform our original instance S into an instance
S ′ in the following way:
a′i ≡ ai (mod p)

for all i ∈ [n]. In particular it means that all numbers in S ′ are positive and smaller than 28n .
Observe, that if there is a solution for Equal-Subset-Sum on instance S, then the same set of
indices is also a solution for Equal-Subset-Sum on instance S ′ . On the other hand, we want to
show that if an answer to Equal-Subset-Sum on original instance S was NO, then for all pairs of
subsets A, B ⊆ S ′ it will hold that Σ(A) P
6= Σ(B). P
P
P
′
′
For some I, J ⊆ [n], in order
i∈I ai =
j∈J aj , while
i∈I ai 6=
j∈J aj , it must be
Pto get P
that p is a divisor of D(I, J) = i∈I ai − j∈J aj . We will call such prime numbers bad.
There are 22n possible pairs of I, J ⊆ [n]. For a ﬁxed I, J ⊆ [n] there are at most log (n2m ) bad
primes (because D(I, J) ≤ n2m ). Hence there are at most:
22n log (n2m ) ≤ 22n (m + log n) ≤ 24n
possible bad primes. By Lemma 2.1, the prime number p is taken from the range containing at
least 27n primes. Therefore, for every I, J ⊆ [n] it holds that:


X
X
Pp 
a′i =
a′j  ≤ 2−3n .
i∈I

j∈J

By talking union bound over all possible 22n pairs of I, J ⊆ [n] the probability of error is bounded
by 2−n .

What is left to prove, is that we can assume, that n is divisible by 12. By the above Lemma we
know that S consists of only positive numbers. Let M be Σ(S) + 1. Observe that we can always
add numbers from set Z = {M, 2M, 4M, 8M . . . , } and the answer to Equal-Subset-Sum on the
modiﬁed instance will not change because numbers in Z always have a diﬀerent sum. Moreover,
none of the subset of S can be used with numbers from Z, because Σ(S) < M . Hence we can always
guarantee that n is divisible by 12 by adding appropriate amount of numbers from Z. Namely, note
that if n ≡ k (mod 12), for some k 6= 0, then we can add k numbers to the original instance S and
the answer to the Equal-Subset-Sum will not change.
16

B

Sharper Reduction from Subset-Sum

In this section, we show a direct reduction from Subset-Sum. As far as we know, it is slightly
sharper than currently known reduction [44] (in terms of constants in the exponent).
Theorem B.1. If Equal-Subset-Sum can be solved in time O∗ ((2 − ε)0.25n ) for some ε > 0 then
Subset-Sum can be solved in time O∗ ((2 − ε′ )0.5n ) for some constant ε′ > 0.
Proof. Assume that we have a black-box access to the algorithm for Equal-Subset-Sum running
in time O∗ ((2 − ε)0.25n ) for some ε > 0. We will show how to use it to get an algorithm for
Subset-Sum running in time O∗ ((2 − ε)0.5n ).
Given an instance S, t of Subset-Sum such that S = {a1 , . . . , an }, we will construct an equivalent instance S ′ of Equal-Subset-Sum such that S ′ = {s1 , . . . , s2n+1 }. Note, that for the running
time this will be enough. The construction is as follows:
• for 1 ≤ i ≤ n, let si = ai · 10n+1 + 2 · 10i ,
• for 1 ≤ i ≤ n, let si+n = 1 · 10i ,
P
• let s2n+1 = t · 10n+1 + ni=1 1 · 10i .

First let us prove that if (S, t) is a YES instance of Subset-Sum
then S ′ is a YES instance
P
for Equal-Subset-Sum. Namely let X ⊆ [n], such that i∈X ai = t. Then, sets A = {si | i ∈
X} ∪ {si+n | i ∈
/ X} andP
B = {si+n
P | i ∈ X} ∪ {s2n+1 } are a good solution to Equal-Subset-Sum
on instance S ′ , because (A) = (B) and A ∩ B = ∅.
Now for other direction, we will prove that if S ′ is a YES instance of Equal-Subset-Sum then
(S, t) is a YES instance of Subset-Sum. Assume that S ′ is a YES instance and a pair A, B ⊆ S ′
is a correct solution. Observe that if for some i ≤ n element si ∈ A then s2n+1 ∈ B. It is because
the sets A, B have an equal sum and only elements si , si+n , s2n+1 have something nonzero at the
i-th decimal place. Moreover all smaller decimal places of all numbers sum up to something smaller
than 10i and therefore cannot interfere with the place 10i .
Finally observe, that numbers si+n for i ∈ [n] cannot produce a YES instance on their own.
Hence sets A ∪ B contain at least one number si for i ∈ [n]. WLOG let A be the set that contains
such an si . ThenP
set B has to contain
s2n+1 . It means that set B cannot contain any siPfor i ∈ [n].
P
In particular (A)/10n+1 = (B)/10n+1
si for i ∈ [n] contribute to (A)/10n+1
P. Only numbers
n+1 . Hence there exists a subset Z ⊆ S, such
and only
P number s2n+1 contributes to the (B)/10
that (Z) = t.

C

Folklore Equal-Subset-Sum by 4-SUM with better memory

Theorem C.1. Equal-Subset-Sum can be solved in deterministic O∗ (3n/2 ) time and O∗ (3n/4 )
space.
Proof. First, we arbitrarily partition S into S1 = {a1 , . . . , an/4 }, S2 = {an/4+1 , . . . , an/2 } S3 =
{an/2+1 , . . . , a3n/4 } and S4 = {a3n/4+1 , . . . , an }. Denote the vectors that correspond to these sets
by a1 , . . . , a4 ∈ Zn/4 , i.e.,
ai = (a(i−1)n/4+1 , a(i−1)n/4+2 , . . . , ain/4 ) for i ∈ {1, 2, 3, 4}.
Recall that in Equal-Subset-Sum we were looking for two subsets A, B ⊆ S, such that A∩B =
∅ and Σ(A) = Σ(B). We can split the solution to 8 subsets:
17

Ai := Si ∩ A and Bi := Si ∩ B for i ∈ {1, 2, 3, 4}.
Then, the equation for the solution is:
Σ(A1 ) + Σ(A2 ) + Σ(A3 ) + Σ(A4 ) = Σ(B1 ) + Σ(B2 ) + Σ(B3 ) + Σ(B4 ).
We can rewrite it as:
(Σ(A1 ) − Σ(B1 )) + (Σ(A2 ) − Σ(B2 )) + (Σ(A3 ) − Σ(B3 )) + (Σ(A4 ) − Σ(B4 )) = 0
Observe, that by deﬁnition Ai ∩ Bi = ∅ for all i ∈ {1, 2, 3, 4}. So the problem reduces to ﬁnding
4 vectors x1 , x2 , x3 , x4 ∈ {−1, 0, 1}n/4 , such that:
a1 · x1 + a2 · x2 + a3 · x3 + a4 · x4 = 0.

(2)

because a term Σ(Ai ) − Σ(Bi ) corresponds to ai · xi (1’s from xi correspond to the elements of
Ai and −1’s from xi correspond to the elements of Bi ).
Now, the algorithm is as follows. First enumerate all possible values of ai ·xi for all i ∈ {1, 2, 3, 4}
and store them in a table Ti . Along the way of value of ai · xi we store corresponding vector
x. Note, that |Ti | = O∗ (3n/4 ). Now run 4-SUM on input tables Ti for i ∈ {1, 2, 3, 4}, ﬁnd xi
such that Equation (2) is satisﬁed. Then we ﬁnd the corresponding sets Ai and Bi and return
(A1 ∪ A2 ∪ A3 ∪ A4 , B1 ∪ B2 ∪ B3 ∪ B4 ). The 4-SUM ﬁnds vectors that sum to 0 from 4 diﬀerent
input sets. Because we enumerated all possibilities the correctness follows.
e 2 ) time and O(|I|)
e
4-SUM runs in O(|I|
space where |I| is the size of the input instance. In our
∗
n/4
case |I| = O (3 ) and the running time and space complexity of the algorithm follows.

D

Time-Space Tradeoff for Equal-Subset-Sum

Schroeppel and Shamir [38] gave a time-space tradeoﬀ for Subset-Sum, such that T S 2 ≤ O∗ (2n )
where T is a running time and S is the space of the algorithm for Subset-Sum and S ≤ O∗ (2n/4 ).
In this section we observe that similar relation is true for Equal-Subset-Sum:
Theorem D.1. For all S ≤ O∗ (3n/4 ), Equal-Subset-Sum can be solved in space S and time
n
T ≤ O∗ ( S3 2 ).
Proof. Let S be the input instance of Equal-Subset-Sum and β ∈ [0, 1] be our trade-oﬀ parameter.
By A, B we will denote a solution to Equal-Subset-Sum, i.e., Σ(A) = Σ(B) and A ∩ B = ∅.
Intuitively, for β = 1 we will use a polyspace algorithm running in time O∗ (3n ) and for β = 0
we will use a meet in the middle algorithm running in O∗ (3n/2 time and O∗ (3n/4 ) space. First we
arbitrarily choose a set X of βn elements of S. Then we guess set A ∩ X and set B ∩ X. Finally
we execute Equal-Subset-Sum meet-in-the-middle algorithm for an instance (S \ X) ∪ {Σ(A ∩
X), Σ(B ∩ X)} of n(1 − β) + 2 elements. The correctness follows because we checked all possible
splits of X into sets A and B and put them into the solution. We did not increase possible solutions
hence if the answer to Equal-Subset-Sum was NO then we will always answer NO. Similarly if
the answer was YES, and the sets A, B ⊆ S are a good solution, then for correctly guess A ∩ X and
B ∩ X the constructed instance is a YES instance.
The algorithm runs in time T (n, β) = O∗ (3βn · T (n(1 − β)) ≤ O∗ (3βn 3(1−β)n/2 ) and space
S(n, β) = O∗ (S((1 − β)n) ≤ O∗ (3(1−β)n/4 ) (see Appendix C). It follows that:
T (n, β)S(n, β)2 ≤ O∗ (3n )
18

Which gives us the ﬁnal time-space tradeoﬀ.

E

Exact algorithm for Number Balancing

Recall, that in the Number Balancing problem you are given n real numbers
an ∈ [0, 1].
P a1 , . . . , P
The task is to ﬁnd two disjoint subsets I, J ⊆ [n], such that the diﬀerence | i∈I ai − j∈J aj | is
minimized. In this Section we show that our techniques transfer to the exact algorithm for Number
Balancing. To alleviate problems with the deﬁnition of the computational model for real numbers,
we will be solving the following problem:
Definition E.1 (Integer Number Balancing). In the Integer Number Balancing problem, we are
given a set S of n integers a1 , . . . , an ∈ {0, . . . , 2O(n) }. The task is to find two disjoint subsets
P
P
I, J ⊆ [n], such that the difference
i∈I ai −
j∈J aj is minimized.

Note, that Karmarkar and Karp [28] deﬁned Number Balancing for reals because they were
interested in approximation algorithms. For our purposes it is convenient to assume that numbers
are given as integers bounded by 2O(n) . For unbounded integers, some additional factors due to the
arithmetic operations may occur.
Theorem E.2. Integer Number Balancing can be solved in O∗ (1.7088n ) time with high probability.
It is convenient to work with the following decision version of the problem:

Definition E.3 (Integer Number Balancing, decision version). In the decision version of Integer
Number Balancing, we are given a set S of n integers a1 , . . . , an ∈ {0, . . . , 2O(n) } and integer κ. The
P
P
task is decide if there exist two disjoint subsets I, J ⊆ [n], such that
i∈I ai −
j∈J aj ∈ [0, κ].
The above decision version and minimization version are equivalent up to polynomial factors:
we use a binary search to for the smallest κ, for which answer to the decision version of Integer
Number Balancing is YES. The target κ ∈ [0, 2O(n) ] so we need at most polynomial number of calls
to the oracle.

E.1

Proof of Theorem E.2

First we observe, that our techniques also work for the generalization of Equal-Subset-Sum.
Definition E.4 (Target Equal-Subset-Sum problem). In the Target Equal-Subset-Sum problem, we are given a set S of n integers and integer κ. The task is to decide if there exist two disjoint
nonempty subsets A, B ⊆ S, such that |Σ(A) − Σ(B)| = κ.
Theorem E.5. Target Equal-Subset-Sum problem in O∗ (1.7088n ) time with high probability.
We give a sketch of the proof in Section E.2.
Now, we use an algorithm for Target Equal-Subset-Sum to give an algorithm for Integer
Number Balancing. The observation is that decision version of Integer Number Balancing (see
Deﬁnition E.3) asks if there exist two subsets X, Y ⊆ S such that |Σ(X) − Σ(Y )| ∈ [0, κ]. However
Theorem E.5 gives us an access to the oracle that determines if there exist two subsets X, Y ⊆ S,
such that |Σ(X) − Σ(Y )| = κ. The following Lemma gives us tool for such a reduction:

19

Lemma E.6 (Shrinking Intervals, Theorem 1 from [35]). Let U be a set of cardinality n, let ω :
U → {−W, . . . , W } be a weight function, and let l < u be integers with u − l > 1. Then, there is
a polynomial-time algorithm that returns a set of pairs Ω = {(ω1 , v1 ), . . . , (ωT , vT )} with ωi : U →
{−W, . . . , W } and integers v1 , . . . , vT ∈ {−W, . . . , W }, such that:
• T is at most O(n log (u − l)), and:
• for every set X ⊆ U it holds that ω(X) ∈ [l, u] if and only if there exist an index i ∈ [T ] such
that ωi (X) = vi .
Note, that the corresponding Theorem in [35] was stated for weight function ω : U → {0, . . . , W }.
However, the proof in [35] does not need that assumption. For clarity, in [35] weight functions
ω
Pi : U → {−W, . . . , W } are of the following form: for set X ⊆ U the function is always ωi (X) =
x∈X wx for some weights wi ∈ Z.
With Lemma E.6 in hand we can now prove Theorem E.2.
Proof of Theorem E.2. Let S be the set of n integers {a1 , . . . , an } as in Deﬁnition E.3 and a target
κ. Let U = {−n, . . . , −1} ∪ {1, . . . , n}. For z ∈ Z, let sgn(z) be sign function, i.e., sgn(z) = −1
when
z < 0, sgn(0) = 0 and sgn(z) = 1 when z > 0. Moreover, for any X ⊆ U let ω(X) =
P
x∈X sgn(x)a|x| .
We are given black-box access to the Theorem E.5, i.e., for a given set S ′ of integers we can decide
if there exist two subsets X, Y ⊆ S ′ , such that |Σ(X) − Σ(Y )| = κ in time O∗ (1.7088n ). We show
that we can solve Integer Number Balancing by using polynomial number of calls to Theorem E.5.
First, observe that universe set U and the weight function ω(X) satisfy the conditions of
Lemma E.6. Moreover, let u = κ and l = −κ. Lemma E.6 works in polynomial time and outputs pairs P = {(ω1 , v1 ), . . . , (ωT , vT )}. Now, the answer to the decision version of Integer Number
Balancing on S is YES iﬀ there exists index i ∈ [T ] such that an answer to Target Equal-SubsetSum on instance (ωi , vi ) is YES by Lemma E.6.
For the running time observe, that the numbers are bounded by 2O(n) , so T = O(poly(n)).
Hence, we execute polynomial number of calls to Theorem E.5 and the running time follows.

E.2

Proof of Theorem E.5

What is left is to sketch that our techniques also apply to a more general version of the problem.
We are given a set S of n integers and a target κ. We need to ﬁnd X, Y ⊆ S, such that
Σ(X) − Σ(Y ) = κ. First of all the deﬁnition of minimum solution for a target easily generalizes,
i.e., we say that a solution A, B ⊆ S such that Σ(A) − Σ(B) = κ is a minimum solution if its size
|A| + |B| is smallest possible.
Note, that the meet-in-the-middle algorithm for Equal-Subset-Sum works for Target EqualSubset-Sum (see Theorem 3.3 and Algorithm 1). The only diﬀerence is that in Algorithm 1, we
need to determine if there exist x1 ∈ C1 , x2 ∈ C2 such that x1 + x2 = κ. The running time and
analysis is exactly the same in that case.
The main diﬀerence comes in the analysis of balanced case, i.e., Theorem 3.4. In that case we
need to enumerate two sets Ct,p and Ct−κ,p (see Algorithm 3)
What is left is to show, that Algorithm 3 has the running time O∗ (2ℓ ) and ﬁnds a solution to
Target Equal-Subset-Sum with probability Ω(1/poly(n)). The rest of the proof and analysis is
exactly the same as the proof of Theorem 3.4.
For the running time, note that E [|C1 |] ≤ O∗ (2ℓ ) and E [|C2 |] ≤ O∗ (2ℓ ) because these sets are
chosen in exactly the same way as set C in Lemma 3.7. Moreover, we can enumerate both of them
20

Algorithm 3 BalancedEqualSubsetSumTarget(a1 , . . . , an , ℓ, κ)
1:
2:
3:
4:
5:
6:
7:

Pick a random prime p in [2n−ℓ , 2n−ℓ+1 ]
Pick a random number t ∈ [1, 2n−ℓ ]
Let C1 = {X ⊆ S | Σ(X) ≡p t}
Let C2 = {X ⊆ S | Σ(X) ≡p t − κ}
Enumerate and store all elements of C1 and C2
Find X ∈ C1 and Y ∈ C2 , such that Σ(X) − Σ(Y ) = κ
return (X \ Y, Y \ X)

⊲ In time O∗ (|C1 | + |C2 | + 2n/2 )
⊲ In time O∗ (|C1 | + |C2 |)

in time O∗ (|C1 | + |C2 | + 2n/2 ) ≤ O∗ (2ℓ ) by using Lemma 3.8 (recall that ℓ > n/2). Finally we can
ﬁnd X ∈ C1 and Y ∈ C2 , such that Σ(X) − Σ(Y ) = κ (if such X, Y exist) in time O∗ (2ℓ ) by solving
2SUM. Hence, the running time of Algorithm 3 is O∗ (2ℓ ).
For the correctness, observe that an analog of Lemma 3.5 holds:
Lemma E.7. Let S be a set of n positive integers with minimum solution size of ℓ. Let
Ψ = {Σ(X) | ∃Y ⊆ S such that X 6= Y and Σ(X) − Σ(Y ) = κ} .

(3)

If ℓ > n2 , then |Ψ| ≥ 2n−ℓ (note that all elements in Ψ are different).

Proof of Lemma E.7. Similarly to the proof of Lemma E.7 we assume, that there exist A, B ⊆ S,
such that A∩B = ∅, |A|+|B| = ℓ and Σ(A)−Σ(B) = t. Then we construct our set Ψ be considering
every subset Z ⊆ S \ (A ∪ B) and observing that:
• Σ(A ∪ Z) − Σ(B ∪ Z) = κ, and
• there are 2n−ℓ possible choices of set Z, and
• by the minimality of A, B all sets Z have a diﬀerent sum.

And with that Lemma in hand we can prove the analogous to Lemma 3.6.
Lemma E.8. Let S be the set of n positive integers bounded by 2O(n) with minimum solution A, B,
Σ(A) − Σ(B) = κ of size ℓ and ℓ > n2 . For a random prime p ∈ [2n−ℓ , 2n−ℓ+1 ] and a random
t ∈ [1, 2n−ℓ ] let Ct,p = {X ⊆ S | Σ(X) ≡p t }. Then,
i
h
Pt,p ∃X ⊆ Ct,p , Y ⊆ Ct−κ,p Σ(X) − Σ(Y ) = κ, X 6= Y ≥ Ω(1/n2 ).

Proof of Lemma E.8. Recall Ψ from Lemma E.7. Note, that it is suﬃcient to show that there exist
an element a ∈ Ψ, such that a ≡p t with constant probability. Namely, if that is true, then a ∈ Ct,p
and by the deﬁnition of Ψ, there exists set B ⊆ S, such that a − Σ(B) = κ. Hence, Σ(B) ∈ Ct−κ,p
and the claim follows.
The rest of the proof, i.e., showing that a ≡p t with constant probability is analogous to the
proof of Lemma 3.6.
With that in hand the correctness is analogous to the proof of correctness of Theorem 3.4.

21

