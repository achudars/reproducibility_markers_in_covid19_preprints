Detection and Isolation of Adversaries in
Decentralized Optimization for
Non-Strongly Convex Objectives ?
Nikhil Ravi ‚àó Anna Scaglione ‚àó

arXiv:1910.13020v1 [eess.SY] 29 Oct 2019

‚àó

School of Electrical, Computer and Energy Engineering,
Arizona State University, Tempe, AZ 85281 USA
(e-mail: {Nikhil.Ravi,Anna.Scaglione}@asu.edu).

Abstract: Decentralized optimization has found a significant utility in recent years, as a
promising technique to overcome the curse of dimensionality when dealing with large-scale
inference and decision problems in big data. While these algorithms are resilient to node and link
failures, they however, are not inherently Byzantine fault-tolerant towards insider data injection
attacks. This paper proposes a decentralized robust subgradient push (RSGP) algorithm for
detection and isolation of malicious nodes in the network for optimization non-strongly convex
objectives. In the attack considered in this work, the malicious nodes follow the algorithmic
protocols, but can alter their local functions arbitrarily. However, we show that in sufficiently
structured problems, the method proposed is effective in revealing their presence. The algorithm
isolates detected nodes from the regular nodes, thereby mitigating the ill-effects of malicious
nodes. We also provide performance measures for the proposed method.
Keywords: decentralized optimization, multi-agent systems, byzantine fault-tolerance,
adversarial optimization, gradient-based metric
1. INTRODUCTION
A number of machine learning and big data problems can
be generalized to take the following form:
N
1 X
min F (x) = min
fi (x),
(1)
x‚ààRd
x‚ààRd N
i=1
where F (¬∑) : Rd ‚Üí R is the global objective which the
nodes are trying to collectively minimize. However, the
nodes only have access to their own private cost functions,
fi (¬∑) : Rd ‚Üí R. There is a large class of decentralized
peer-to-peer algorithms for solving such decomposable optimization problems via peer-to-peer consensus protocols,
see Tsitsiklis et al. (1986); NedicÃÅ and Ozdaglar (2009) for
early contributions and see Boyd et al. (2011); NedicÃÅ et al.
(2018) for extensive literature surveys.
While these algorithms are resilient to node or edge failures, they are not however inherently resilient to insiderbased data injection attacks (see e.g. Gentz et al. (2015);
Blanchard et al. (2017); Gentz et al. (2016); Wu et al.
(2018); Sundaram and Gharesifard (2018)). This has
spurred significant interest on robust decentralized optimization algorithms. In literature, broadly speaking, there
are two schools of solutions. In the first set of works,
authors propose methods to regularize the objective by
relaxing the hard consensus constraints, typically by using
? This research was supported in part by Cybersecurity for Energy
Delivery Systems program, of the U.S. Department of Energy, under
contract DOE0000780 and the National Science Foundation CCFBSF 1714672 grant. Any opinions, and findings expressed in this
material are those of the authors and do not necessarily reflect those
of the sponsors.

TV norm regularization scheme, see Ben-Ameur et al.
(2016); Koppel et al. (2017); Xu et al. (2018). Even if
the adversarial environment can be studied similarly to
the non-adversarial case, such approaches do not admit
the same solutions as the original problem even when the
attackers are not present at all. Also, their performance is
highly dependent on the attack scenario, the choice of the
regularizing function, and the regularizing parameter.
These issues are not shared by the second set of works,
where each node builds a score about their neighbors‚Äô
updates and uses this score to detect their potential
malicious intent, see VukovicÃÅ and DaÃÅn (2014); Su and
Vaidya (2015a,b); Su and Shahrampour (2018); Sundaram
and Gharesifard (2018); Ravi et al. (2019). These scores
can then be used by regular nodes to dynamically sever ties
with suspicious peers and continue to run the algorithm,
see Ravi et al. (2019). As long as the network remains
strongly connected and set of the isolated nodes includes
all the malicious nodes, the network converges to optimum
solution of the objective that only includes the nodes that
are not isolated. This is possible for appropriate peerto-peer optimization algorithms because they can restore
normal operations by isolating the attackers while the
algorithm is running.
The literature considers a number of attack models that
differ based on the structure of the data injected by the
malicious nodes. This paper focuses on attacks that involve coordinated malicious agents that follow algorithmic
protocols while manipulating their private cost functions
arbitrarily. We consider a network of nodes that are collectively solving problem (1) by implementing the Push-Sum

algorithm proposed in Kempe et al. (2003). Concurrently,
the regular nodes maintain a maliciousness score about
their neighbors as a function of the local neighborhood
data. The idea is to sever ties with those deemed to be malicious and then continuing the updates according to PushSum. This approach leverages the self-healing property
of the gradient-based Push-Sum algorithm where nodes
dynamically sever ties with those neighbors that are more
likely to be malicious. The paper is organized as follows.
In Section 2, the system model and the attack characteristics are described. In Section 3, we introduce the
Robust Subgradient Push algorithm and its consequences.
In Section 4, we present some simulation results that
demonstrate the effectiveness of the proposed approach.
We conclude in Section 5.
Notations: Boldfaced lower-case (resp. upper-case) letters denote vectors (resp. matrices) and xi (Xij ) denotes
the ith element of a vector x (the ijth entry of a matrix
X). Calligraphic letters are sets and |A| denotes the cardinality of a set A; difference between two sets A and B is
denoted by A \ B.

Before moving on to describe the characterization of
malicious nodes, we introduce a few assumptions.
Assumption 1. (Strong Connectivity) The sequence of
graphs, {G(t)}, induced by the dynamic in- and outneighborhoods over time is strongly connected.
Assumption 2. (Convexity) Each of the functions fi , ‚àÄi ‚àà
V, is convex over the Rd .
Assumption 3. (Bounded Subgradients) All the subgradients of each of the functions fi , ‚àÄi ‚àà V, are bounded. That
is, ‚àÉ li < ‚àû such that kgi k ‚â§ li , ‚àÄi ‚àà V, for all subgradients
gi of fi (x) and for all x ‚àà Rd .
Assumption 4. (Malicious nodes) Let us suppose that the
sequence of graphs {G(t)} is (2Œ∫ + 1)-strongly connected.
Then there exists at most Œ∫ adversaries in the whole
network, i.e., |Vm | ‚â§ Œ∫. This also implies that there exists
at most Œ∫ adversaries in a node‚Äôs in-neighborhood, i.e.,
|Ni‚àí ‚à™ Vm | ‚â§ Œ∫, ‚àÄi ‚àà V.
If assumptions 1-3 hold and under no interference from
malicious nodes, the convergence of the original GradientPush was proven in NedicÃÅ and Olshevsky (2015), i.e.,
‚àó
x‚àû
i , lim xi (t) = x = arg min F (x), ‚àÄ i ‚àà V
t‚Üí‚àû

x‚ààRd

2. SYSTEM MODEL
2.1 Attack characterization
The set of nodes in the system are modeled by a directed
graph G(V, E), where V is the set of nodes and E is the set
of edges that represent the communication links between
the nodes. To describe the adversarial environment, the
set V is partitioned into two subsets, namely: the set
Vr of regular nodes (RNs) with Nr := |Vr |, and the set
Vm of malicious nodes (MNs) with Nm := |Vm |, so that
V = Vr ‚à™ Vm . Similarly, the edge set E is also partitioned
E = Er ‚à™ Em , where Er is the set of links emanating from
RNs, while Em is the set of links emanating from the MNs.
The set Er is further partitioned Em = Emr ‚à™ Emm , while
Emm is the set of links emanating and ending at MNs.
The goal of the RNs is to identify and sever all the edges
belonging to Emr . Let Ni‚àí be the set of all nodes that can
send information to node i and Ni+ be the set of all nodes
that can receive information from node i.
Problem Statement: In the presence of adversaries
in a network, the benchmark for th performance is the
analogous problem as in (1), where the graph is replaced
with the graph formed by the regular nodes only, i.e.,
1 X
minimize
fi (xi ) s.t. xi = xj ‚àÄ ij ‚àà Err ,
(2)
{xi ,i‚ààV r } |Vr |
i‚ààVr

where fi : Rd ‚Üí R is the private cost/loss function only
available at node i and the constraint enforces consensus in
the network‚Äôs neighborhoods. Decentralized optimization
algorithms designed for arbitrary network topologies require doubly-stochastic weight matrices. Techniques such
as Subgradient-Push (SGP) relax this requirement NedicÃÅ
et al. (2018). Further improvements in the convergence
rates algorithms for directed graphs are presented in DEXTRA (Xi and Khan (2017)) and ADD-OPT/Push-DIGing
(Xi et al. (2018)). However, these algorithms require each
node to know its out-degrees (the number of its outneighbors) which is not a realistic assumption in general,
and is even more problematic in an adversarial environment.

Let F r (x) be the cost and x‚àó the solution of (2), i.e.:
X
1 X
F r (x) ,
fi (x) , x‚àó , arg min
fi (x). (3)
|Vr |
x
i‚ààVr

i‚ààVr

The performance of any algorithm that is resilient towards
an attack can be measured using several metrics that
capture the deviation of the limiting state from the ideal
asymptotic condition in (3), for example:
‚Ä¢ Average solution difference:
1 X ‚àû
p ,
kxi ‚àí x‚àó kp
|Vr |

(4)

‚Ä¢ Average cost increase:
1 X
r
‚àó
%,
fi (x‚àû
i ) ‚àí F (x )
|Vr |

(5)

i‚ààVr

i‚ààVr

‚Ä¢ Average deviation from consensus:
1 X ‚àû
1 X ‚àû
kxi ‚àí x‚àû k , x‚àû ,
x` (6)
Œ≥,
|Vr |
|Vr |
i‚ààVr

`‚ààVr

It is a well established that the presence of even a single
malicious node will lead the convergence of the algorithm
astray (see e.g. Figure 1). The type of attack that is considered in our paper, represents the case where the regular
nodes‚Äô functions fi (x), i ‚àà Vr have common statistical
characteristics. The attacker follows the algorithm as well,
however, its intent is to alter the solution, which requires
altering the statistics of the function and its gradient.
For example, this situation arises when the distributed
optimization objective is to solve a regression problem
where, in normal conditions, the sensors cooperatively are
trying to estimate a vector xo based on a noisy observation
model:
si = hi (xo ) + wi ‚àà R
(7)
for all i ‚àà V where wi are independent identically distributed noise samples. The regression can be formulated

no sensor is attacked, as more observations improve the
estimation error performance.

4
Regular Nodes
Malicious Node(s)
Optimal
Attacker‚Äôs target

xi (t)

2

0

‚àí2

50

100

150
200
Time (t)

250

300

Fig. 1. Consensus without attacker detection with adversaries following algorithmic protocols but modifying
their local cost functions dynamically to reach their
intended target (in black). Here, the regular nodes
in blue converge to the attacker‚Äôs (in red) target. In
the example a set of nodes (1 ‚àí 10) are trying to
solve problem 1 using the standard Sub-gradient push
(SGP) in a static network. However, a malicious node
drives the network towards its target, xa .
as the minimization of the sum of fi (x) = ksi ‚àí hi (x)k2 ,
which amounts to seeking the maximum x. To be concrete, we will focus on Gaussian independent identically
distributed (i.i.d.) noise case wi ‚àº N (0, œÉ 2 ) in which case:
fi (x) = ksi ‚àí hi (x)k2
(8)
1
and the gradient is:
gi (x) = 2‚àáhi (x)(si ‚àí hi (x))
(9)
The attack can be caused by a spoofing attack to a set of
sensors:
sam = sm + Œ¥sm m ‚àà Vm
(10)
a
(x) =
Under this attack, the gradient of the functions fm
ksam ‚àí hm (x)k2 is, therefore perturbed:
gm (x) =2‚àáhm (x)(sam ‚àí hm (x)) = gm (x) + Œ¥gm (x) (11)
Under such an attack, a strongly connected network will
converge to consensus on the following solution:
!
X
|V
|
1
r
xa = arg min
F r (x) +
fia (x)
(12)
|V|
|V|
x
i‚ààVm

with average deviation from consensus Œ≥ = 0 and average
solution difference and cost deviation, respectively:
p = kxa ‚àí x‚àó kp , % = F r (xa ) ‚àí F r (x)
(13)
In the context of this type of attack, the percentage increase the additional average error relative to the latent
parameter xo measures the damage caused by the malicious agents as well, that is for instance:
P
1
‚àû
i‚ààV kxi ‚àí xo kp
|V|
(14)
Œæp ,
kx‚àó ‚àí xo kp
where a significant damage comes from a large value of Œæp
in the presence of an attack; since when the attack is fully
successful there is consensus on xa the value of Œæp is:
a
Œæp = kx ‚àí xo kp/kx‚àó ‚àí xo kp
(15)
Of course, the quantity that we consider a benchmark
kx‚àó ‚àíxo kp itself represents a loss relative to the case where
1 Note that in this case, given that the noise terms are non bounded,
the condition stated as Assumption 3 of bounded gradients can only
be guaranteed with high probability. To avoid complications in the
discussion we will discuss convergence as if the condition is met.

In our previous work Ravi et al. (2019) we noted that
staging a sufficiently strong attack in terms of p , requires
either sufficiently large gradients for the malicious nodes,
or a special choice for the target point xa . In fact, since
xa is the stationary point for the problem in (12), we have
P
P
a
a
i‚ààVr gi (x ) +
i‚ààVm gi (x ) = 0.
Let Hi (x) be the Hessian of the function fi (x) and H r (x)
the Hessian of the function F r (x); then:
P
P
a
‚àó
‚àó
a
‚àó
i‚ààVm gi (x ) ‚âà ‚àí
i‚ààVr gi (x ) + Hi (x )(x ‚àí x ) (16)
= ‚àíH r (x‚àó )(xa ‚àí x‚àó ).
(17)
The last equation implies that the most effective attacks
can be staged when the malicious nodes can be selected
so that the Hessian H r (x‚àó ) is singular, compromising the
convergence of the algorithm even if the malicious nodes
were isolated and the network of regular nodes remains
strongly connected.
This requires us to state the following assumption:
Assumption 5. The Hessian H r (x‚àó ) of F r (x) is positive
definite.
Proposition 1. (Ravi et al. (2019)). Under Assumption 5,
the nodes achieve consensus (i.e. Œ≥ = 0), and the average
solution difference is such that:
P
r
‚àó
a 2
(18)
i‚ààVm gi (x ) 2 & 2 Œªmin (H (x )).
3. ROBUST SUBGRADIENT PUSH
The basic idea of this paper is to leverage the structure of
the problem, as well as the need of the malicious agents
to use large gradients to influence the result, as it is made
apparent by equation (18). We wish to use this fact to
design a score Sij (t) that each node updates ‚àÄj ‚àà Ni and
uses to detect and then reject updates from a specific node.
In this paper we propose a modified version of the
Subgradient-Push (NedicÃÅ and Olshevsky (2015)) that is
based on the original Push sum algorithm (Kempe et al.
(2003)), see algorithm 1. This algorithm differs from the
original Subgradient-Push in the fact that at all times
t > 0, the out-degree of all the nodes is 2, i.e., instead
of a broadcast communication model, each node chooses
one of its out-neighbors uniformly at random and sends its
information to that node and to itself. This eliminates the
necessity of each node knowing its out-degree, the trade-off
being a slower convergence rate. The algorithm converges
even when the functions are non strongly convex, which is
the typical scenario of interest in a network of sensors that
collect a scalar measurement while the goal is to estimate
a d-dimensional vector parameter xo .
We name it Robust Subgradient-Push (RSGP). In RSGP
each node i maintains a set of variables, zi (t), vi (t) ‚àà Rd
and yi (t) ‚àà R, at all times t ‚â• 0. The algorithm starts with
an arbitrarily initiated xi (0) ‚àà Rd , and with yi (0) = 1
at each node i, and is descried in Algorithm 1. Here,
gi (t) = ‚àáfi (xi (t)) is a subgradient of fi (¬∑) calculated at
xi (t), and Œ∑t > 0 is the step-size that decays with time
such that
P
P 2
(23)
t Œ∑t = ‚àû,
t Œ∑t < ‚àû.

xj (t) = vj (t)/yj (t) ‚âà xa

Algorithm 1 Robust Subgradient-Push (RSGP)
1:

2:
3:
4:
5:
6:
7:

Initialize: ‚àÄj ‚àà Ni‚àí
zi (0) ‚àà Rd arbitrarily, yi (0) = 1,
SÃÉij (0) = 0
Ensure:
{Œ∑}t satisfies condition (23) and Œ± < 1
for t ‚â• 0 do
for i ‚àà V do
Let {zj (t), yj (t)}, ‚àÄj ‚àà Ni‚àí (t) ‚äÜ Ni‚àí , be the
pairs of data sent to node i at time t
Send {zi (t), yi (t)} to i itself and a node k ‚àà Ni+
chosen uniformly at random; Ni+ (t) = {i, k}
Update vi , yi , xi and zi as follows:
1 X
vi (t + 1) =
zj (t)
(19)
2
‚àí
j‚ààNi (t)

yi (t + 1) =

8:
9:
10:
11:
12:
13:
14:

1
2

X

yj (t)

(20)

j‚ààNi‚àí (t)

xi (t + 1) = vi (t + 1)/yi (t + 1)
(21)
zi (t + 1) = vi (t + 1) ‚àí Œ∑t+1 gi (t + 1)
(22)
if i ‚àà Vr then
for all j ‚àà Ni‚àí do
Calculate the score SÃÉij (t) from equation (31).
Calculate œái (t) from equation (32).
for all j ‚àà Ni‚àí do
if SÃÉij (t) > œá(t) then
Ni‚àí ‚Üê Ni‚àí \ j and Ni+ ‚Üê Ni+ \ j

3.1 Detection and Isolation via a Neighborhood Score
Crucial to RSGP is the definition of the score that shall reveal the malicious nodes. We note that each node receives
its neighbors‚Äô zi (t) and yi (t) state variables when they
communicate. The variable yi (t) of node i is a function of
the number of instantaneous in-neighbors i receives at any
particular time instant. Importantly, it does not depend
on node i‚Äôs gradient, which is what the sensor spoofing
attack manipulates. The iterative update of variable zi (t),
however, includes a gradient step. Thus, we define a maliciousness score Sij (t) that can be maintained by each
regular node i about their neighbors Ni‚àí . As the nodes
approach consensus, their direction of descent is typically
dominated by the malicious nodes‚Äô gradients. The intuition
is that node i can use:
xÃÇj (t) := zj (t)/yj (t)
(24)
to track neighbor j‚Äôs instantaneous gradient. From the
bound in Equation (18), we hypothesize that the malicious
nodes will appear as outliers relative to the rest of the
nodes in the neighborhood, as long as they are sufficiently
outnumbered. The instantaneous score we propose is:
2

1
Sij (t) , 2
Œ∑t

X

(xÃÇj (t) ‚àí xÃÇ` (t))

`‚ààNi‚àí (t)\j

.

(25)

2

To gain some intuition, suppose the nodes are approaching
consensus. At this point the values of yi (t) are likely to
have converged as well, and:

In this case:

vj (t) v` (t)
‚àí
‚àí Œ∑t (gj (t) ‚àí g` (t))
yj (t)
y` (t)
‚âà Œ∑t (g` (t) ‚àí gj (t)) ,
(26)
which indicates that the score is essentially comparing the
disparity in the gradients and:
xÃÇj (t + 1) ‚àí xÃÇ` (t + 1) =

2

Sij (t) ‚âà

X

(g` (t) ‚àí gj (t))

`‚ààNi‚àí (t)\j

(27)
2
2

X

=

g` (t) ‚àí (di (t) ‚àí 1)gj (t)

`‚ààNi‚àí (t)\j

.

(28)

2

Let us consider for simplicity the presence of only one
malicious agent in the ith node neighborhood. In the
following, we denote node i degree by di (t) = |Ni (t)|. The
last equation, together with the observation in Proposition
1, implies that the score for a malicious neighbor m, for t
sufficiently large is approximately:
Sim (t) ‚âà (di (t) ‚àí 1)2 kgm (t)k22 .
(29)
On the other hand, it is not difficult to show expanding
the norm squared in (28) that:
X
1 X
Sij (t) = di (t)
kgi (t)k2 +
(30)
di
i‚ààNi (t)

i‚ààNi (t)

2


‚àí 2‚àí

1
di (t)



X

gi (t)

/ di (t)kgm (t)k22

i‚ààNi (t)

which suggests that, as long as (di (t) ‚àí 1)2 > di (t) (which
happens as long as di (t) ‚â• 4) the malicious agent score
will tend to dominate the average of the scores of the
neighborhood. Considering the randomness that exist in
the protocol iterations, the score used to detect the agents
is averaged over time. In fact, RSGP uses a cumulative
score is given by:
t
X
SÃÉij (t) =
Œ±œÑ Sij (œÑ ) = SÃÉij (t ‚àí 1) + Œ±t Sij (t),
(31)
œÑ =1

where 0 < Œ± < 1. The weighted average is designed in such
a manner that older instantaneous scores are given lower
weights than newer ones, for which (26) is more accurate.
Regular Nodes can then dynamically isolate those neighbors whose score cross a certain threshold, œái (t). Let SÃÉi (t)
be the vector of scores at node i. In our implementation
we choose œái (t) as follows:




œái (t) = avg SÃÉi (t) + Œ≤ √ó std SÃÉi (t)
(32)
where avg(a) and std(a) are sample average and sample
standard deviation of vector a entries. The parameter Œ≤
controls the aggressiveness of the edge severing strategy.
It is important to note that as a result of edge severing,
depending on the aggressiveness of the isolation strategy,
some regular nodes might also get isolated from the rest of
the regular nodes. This may result as a consequence of the
regular node being slow in isolating neighboring malicious
node(s). In another scenario, the algorithm might give
rise to a splintering in the network to multiple connected

subgraphs G ` , thereby leading to polarities in the final
convergence points of such subgraphs to x‚àû
` . Ideally, the
RSGP at the optimum value of Œ≤ separates G into Gr
made up solely of the regular nodes, and if the malicious
nodes are coordinating (which they are in this paper),
into Gm made up solely of the malicious nodes. If the
malicious nodes are not cooperating, then we may see
further splintering in Gm . The various scenarios and their
error plots are discussed in section 4.

xi (t)

0

‚àí1
Malicious Node(s)
Regular Nodes
Optimal
Attacker‚Äôs target

‚àí2
‚àí3

1,000 2,000 3,000 4,000 5,000
Time (t)

(a)

(b)

4. NUMERICAL RESULTS WITH A CASE STUDY

i‚ààVr

Let us assume without loss of generality that Vr =
= [h1 , . . . , hNr ] .
{1, . . . , Nr } and define the matrix AT
‚àí1 T r
‚Ä†
T
Denoting by Ar := Ar Ar
Ar , which is the pseudoinverse of matrix Ar , the minimizer for this problem
is known in closed-form and given by
‚àí1 T
x‚àó = A‚Ä†r sr = xo + AT
A r wr .
r Ar
and AT
r Ar is the Hessian, which under Assumption 5 is
full rank. The cost is:
F r (x‚àó ) = k(I ‚àí A‚Ä†r Ar )sk2 = k(I ‚àí A‚Ä†r Ar )wk2
(33)
Now, let x‚àû
i , ‚àÄi ‚àà Vr , be the points at which the regular
nodes converge at the end of RSGP. The average solution
error with respect to x‚àó is given by p from equation (4).
The average cost increase of RSGP is given by % from
equation (5). We can also define a regret in the errors as
Œæp from equation (14), which compares the error under
attack and the error without an attack. We redefine the
terms for ease of reading:
1 X ‚àû
1 X
‚àó
p ,
kxi ‚àí x‚àó kp , % ,
(fi (x‚àû
i ) ‚àí fi (x ))
Nr
Nr
i‚ààVr
i‚ààVr
P
1
‚àû
X
1
i‚ààVr kxi ‚àí xo kp
Nr
‚àû
‚àû
kxi ‚àí x kp , Œæp ,
,
Œ≥p ,
Nr
kx‚àó ‚àí xo kp
i‚ààVr
P
where x‚àû , |V1r | `‚ààVr x‚àû
` and p = 2.
The figures in Figure 2 show the performance of RSGP
and compares it with the methods proposed in Ben-Ameur
et al. (2016) and Sundaram and Gharesifard (2018). The
system setup is as follows. We consider multiple realization
of ErdoÃãs‚ÄìReÃÅnyi networks with N = 20 nodes and p =
3 log(N )/N . Without loss of generality, the node sets Vr =
{1, . . . , 17} and Vm = {18, 19, 20} are kept the same for
every montecarlo trial, but the edge set E is changed. The
vector zi ‚àº N (0, I) ‚àà Rd (d = 2) is drawn randomly at the

2

4

%

Œæ2

Œ≥2

s2

2

4

3

%

Œæ2

Œ≥2

0.3

0.4

0.5

3
errors

errors

To illustrate our approach, let us consider a parameter
estimation problem where the observation model is given
d
by si = hT
i xo + wi , where hi ‚àà R , wi ‚àà R represents
i.i.d noise samples drawn from a normal distribution with
mean zero and variance œÉi2 , for all i ‚àà V. Then the local
linear least square loss function may be written as:
2
fi (x) = (hT
i xi ‚àí si ) .
P
The global cost function is F (x) = (1/|V|) i‚ààV fi (x) when
all the nodes are performing regularly. However, when
certain nodes are attacked or are malicious, the regular
nodes estimate x‚àó by solving the following problem
1 X T
min F r (x) = min
(hi xi ‚àí si )2 .
x
x |Vr |

2
1

2
1

0

0
0.5

1

1.5
Œ≤

(c)

2

2.5

0

0.1

0.2
Œª

(d)

Fig. 2. (a) ErdoÃãs‚ÄìReÃÅnyi network under consideration. (b)
Convergence to optimal consensus point x‚àó . (c) Average Residual as a function of Œ≤; s2 is the solution
difference for the algorithm in Sundaram and Gharesifard (2018). (d) Average Residual as a function of Œª
for the method in Ben-Ameur et al. (2016).
start of each montecarlo trial for all i ‚àà V. The following
parameters/system variables remain the same for all the
montecarlo trials; xo ‚àº N (0, I) ‚àà Rd , hi ‚àº N (0, œÉ 2 I) ‚àà
Rd , si = hT
i xo + wi , wi ‚àº N (0, 1), ‚àÄi ‚àà Vr . Note that
xo was initialized to [0.0859, ‚àí1.4916]T , and the malicious

nodes (i ‚àà Vm ) alter their hi as (1/Nr )1T Ar ‚àí 5 and
si as (1/Nr )1T sr + 5 . One such realization is shown in
figure 2a. In this network, nodes in color red are attacking
the network by altering the parameters of its loss function
fi , ‚àÄi ‚àà Vm . Let us suppose that the regular nodes keep
a track of the metric in equation (31) over time. Each
node isolates those neighbors that exceed the threshold
in equation (32) with Œ≤ = 1.5. Figure 2b shows the
convergence of RSGP. At time t = 401 (indicated in
magenta), all the nodes with the malicious node(s) in
their neighborhood have successfully isolated the malicious
agents. We then see the self-healing property of distributed
consensus algorithm come into play and the regular nodes
converge at the optimal consensus point in blue.
In Figure 2c, we plot 2 , %, Œæ2 , and Œ≥p as functions of Œ≤,
averaged over multiple montecarlo trials for realizations of
G. We see that at lower values of Œ≤, where nodes sever
ties rather aggressively, the network is broken into multiple strongly connected subgraphs or into a completely
disconnected network. This results in errors greater than
zero. Whereas, at the intermediate values of Œ≤, where the
regular nodes sever ties in a relatively passive manner,
RSGP isolates almost all, if not all, the malicious nodes
in the network and thus, we see a decrease in the errors.
At the optimum choice for Œ≤ (Œ≤ ‚àó ‚àà (1.4, 1.6) in this
setup), the RSGP algorithm almost certainly disconnects
the malicious nodes from the regular nodes and thus the
errors reduce to zero. However, as Œ≤ increases past this

region, the nodes start to become highly conservative in
their cutting, leaving almost all the malicious nodes still
connected to the network. Thus, we see an increase in the
errors and after a certain value of Œ≤, when no edge cutting
takes place, the errors saturate. The solution difference for
the method in Sundaram and Gharesifard (2018) is plotted
as s2 . In this algorithm, nodes communicate with their
neighbors at all time steps, but only use those neighbors‚Äô
data which are not among the extremes in the sorted set of
neighborhood data points. Notice here that the malicious
nodes might persist in the filtered neighborhood of regular
nodes over time. Thus, this algorithm can only guarantee
convergence in the convex hull of the minimizers of the
regular nodes‚Äô private functions.
In Figure 2d, we plot the errors produced by the algorithm
proposed in (Ben-Ameur et al., 2016, Algorithm 1), where
the authors replace the consensus constraint in the problem in (1) with a TV norm regularizer to the objective,
thereby penalizing nodes for not being in consensus with
their neighbors. The problem is given by:
X
1 X
min
fi (xi ) + Œª
(xi ‚àí xj ),
(34)
x‚ààRd |V|
i‚ààV

ij‚ààE

where Œª is the regularization parameter which controls the
strength of magnitude of the penalty. If Œª = 0, consensus
among the nodes is not enforced, thereby leading the nodes
to their individual local minimizers, a node i converges
to the minimizer of fi , ‚àÄi ‚àà V. As Œª increases past
zero, the consensus constraint is enforced, indicated by Œ≥2
reaching zero. While this method is successful in imposing
consensus among the regular nodes, it can not, unlike
RSGP, reduce the p to zero.
5. CONCLUSION
A robust decentralized optimization algorithm (RSGP) resilient to malicious Byzantine agents is proposed. This algorithm forgoes the need for the knowledge of out-degrees
and works even for non-strongly convex loss functions.
The algorithm dynamically isolates malicious nodes in the
system thereby leading the system to convergence at the
optimum consensus point. The isolation strategy is local to
each node, is independent of the network topology and the
attack strategy, and leverages the structure of the regular
nodes in the system.
REFERENCES
Ben-Ameur, W., Bianchi, P., and Jakubowicz, J. (2016).
Robust Distributed Consensus Using Total Variation. IEEE Transactions on Automatic Control. doi:
10.1109/TAC.2015.2471755.
Blanchard, P., Guerraoui, R., Stainer, J., and others
(2017). Machine learning with adversaries: Byzantine
tolerant gradient descent. In Advances in Neural Information Processing Systems, 119‚Äì129.
Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J.
(2011). Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.
Foundations and Trends in Machine learning, 3(1), 1‚Äì
122. doi:10.1561/2200000016.
Gentz, R., Wu, S.X., Wai, H.T., Scaglione, A., and
Leshem, A. (2016). Data injection attacks in randomized gossiping. IEEE Transactions on Signal and

Information Processing over Networks, PP(99), 1. doi:
10.1109/TSIPN.2016.2614898.
Gentz, R., Wai, H.T., Scaglione, A., and Leshem, A.
(2015). Detection of data injection attacks in decentralized learning. In 2015 49th Asilomar Conference on
Signals, Systems and Computers, 350‚Äì354. IEEE.
Kempe, D., Dobra, A., and Gehrke, J. (2003). GossipBased Computation of Aggregate Information. In Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, 482‚Äì491.
Koppel, A., Sadler, B.M., and Ribeiro, A. (2017). Proximity without consensus in online multiagent optimization.
IEEE Transactions on Signal Processing, 65(12), 3062‚Äì
3077. doi:10.1109/TSP.2017.2686368.
NedicÃÅ, A., Olshevsky, A., and Rabbat, M. (2018). Network
topology and communication computation trade-offs in
decentralized optimization. In Proceedings of the IEEE,
volume 106, 953‚Äì976.
NedicÃÅ, A. and Olshevsky, A. (2015). Distributed Optimization over Time-varying Directed Graphs. IEEE
Transactions on Automatic Control, 60(3), 601‚Äì615.
NedicÃÅ, A. and Ozdaglar, A. (2009). Distributed subgradient methods for multi-agent optimization. IEEE
Transactions on Automatic Control, 54(1), 48‚Äì61.
Ravi, N., Scaglione, A., and NedicÃÅ, A. (2019). A case
of distributed optimization in adversarial environment.
In ICASSP 2019 - 2019 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP),
5252‚Äì5256. doi:10.1109/ICASSP.2019.8683442.
Su, L. and Shahrampour, S. (2018). Finite-time guarantees
for byzantine-resilient distributed state estimation with
noisy measurements. CoRR, abs/1810.10086.
Su, L. and Vaidya, N. (2015a). Byzantine multi-agent
optimization: Part I. CoRR, abs/1506.04681.
Su, L. and Vaidya, N.H. (2015b). Fault-tolerant distributed optimization (part IV): constrained optimization with arbitrary directed networks. CoRR,
abs/1511.01821.
Sundaram, S. and Gharesifard, B. (2018). Distributed optimization under adversarial nodes. IEEE Transactions
on Automatic Control. doi:10.1109/TAC.2018.2836919.
Tsitsiklis, J., Bertsekas, D., and Athans, M. (1986). Distributed asynchronous deterministic and stochastic gradient optimization algorithms. IEEE transactions on
automatic control, 31(9), 803‚Äì812.
VukovicÃÅ, O. and DaÃÅn, G. (2014). Security of fully distributed power system state estimation: Detection and
mitigation of data integrity attacks. IEEE Journal on
Selected Areas in Communications, 32(7), 1500‚Äì1508.
Wu, X., Wai, H.T., Scaglione, A., Leshem, A., and NedicÃÅ,
A. (2018). Data Injection Attack on Decentralized
Optimization. In International Conference on Acoustic
Speech and Signal Processing. IEEE.
Xi, C. and Khan, U.A. (2017). DEXTRA: A fast algorithm
for optimization over directed graphs. IEEE Transactions on Automatic Control, 62(10), 4980‚Äì4993.
Xi, C., Xin, R., and Khan, U.A. (2018). ADD-OPT:
Accelerated distributed directed optimization. IEEE
Transactions on Automatic Control, 63(5), 1329‚Äì1339.
Xu, W., Li, Z., and Ling, Q. (2018).
Robust
decentralized dynamic optimization at presence of
malfunctioning agents.
Signal Processing.
doi:
10.1016/j.sigpro.2018.06.024.

