Analysis of Global Fixed-Priority Scheduling for Generalized
Sporadic DAG Tasks
Son Dinh, Christopher Gill, Kunal Agrawal
Washington University in Saint Louis,
Department of Computer Science and Engineering
sonndinh,cdgill,kunal@wustl.edu

arXiv:1905.05119v1 [cs.DC] 13 May 2019

ABSTRACT
We consider global fixed-priority (G-FP) scheduling of parallel tasks,
in which each task is represented as a directed acyclic graph (DAG).
We summarize and highlight limitations of the state-of-the-art analyses for G-FP and propose a novel technique for bounding interfering workload, which can be applied directly to generalized DAG
tasks. Our technique works by constructing optimization problems
for which the optimal solution values serve as safe and tight upper
bounds for interfering workloads. Using the proposed workload
bounding technique, we derive a response-time analysis and show
that it improves upon state-of-the-art analysis techniques for G-FP
scheduling.

1

INTRODUCTION

With the prevalence of multiprocessor platforms and parallel programming languages and runtime systems such as OpenMP [23],
Cilk Plus [13, 17], and Intel’s Threading Building Blocks [18], the
demand for computer programs to be able to exploit the parallelism offered by modern hardware is inevitable. In recent years,
the real-time systems research community has worked to address
this trend for real-time applications that require parallel execution
to satisfy their deadlines, such as real-time hybrid simulation of
structures [11], and autonomous vehicles [19].
Much effort has been made to develop analysis techniques and
schedulability tests for scheduling parallel real-time tasks under
scheduling algorithms such as Global Earliest Deadline First (GEDF), and Global Deadline Monotonic (G-DM). However, schedulability analysis for parallel tasks is inherently more complex than for
conventional sequential tasks. This is because intra-task parallelism
is allowed within individual tasks, which enables each individual
task to execute simultaneously upon multiple processors. The parallelism of each task can also vary as it is executing, as it depends
on the precedence constraints imposed on the task. Consequently,
this raises questions of how to account for inter-task interference
caused by other tasks on a task and intra-task interference among
threads of the task itself.
In this paper, we consider task systems that consist of parallel tasks scheduled under Global Fixed-Priority (G-FP), in which
each task is represented by a Directed Acyclic Graph (DAG). Our
analysis is based on the concepts of critical interference and critical
chain [8, 9, 22], which allow the analysis to focus on a special chain
of sequential segments of each task, and hence enable us to use
techniques similar to the ones developed for sequential tasks [2, 4–
6].
The contributions of this paper are as follows:

• We summarize the state-of-the-art analyses for G-FP and
highlight their limitations, specifically for the calculation
of interference of carry-in jobs and carry-out jobs.
• We propose a new technique for computing upper-bounds
on carry-out workloads, by transforming the problem into
an optimization problem that can be solved by modern
optimization solvers.
• We present a response-time analysis, using the workload
bound computed with the new technique. Experimental
results for randomly generated DAG tasks confirm that
our technique dominates existing analyses for G-FP.
The rest of this paper is organized as follows. In Sections 2 and 3
we discuss related work and present the task model we consider
in this paper. Section 4 reviews the concepts of critical interference
and critical chain and discusses a general framework to bound
response-time. Section 5 summarizes the most recent analyses of GFP, and also highlights limitations of those analyses. In Section 6 we
propose a new technique to bound carry-out workload. A responsetime analysis and a discussion of the complexity of our method
are given in Section 7. Section 8 presents the evaluation of our
method for randomly generated DAG tasks. We conclude our work
in Section 9.

2

RELATED WORK

For the sequential task model, Bertogna et al. [4] proposed a responsetime analysis that works for G-EDF and G-FP. They bound the
interference of a task in a problem window by the worst-case workload it can generate in that window. The worst-case workload is
then bounded by considering a worst-case release pattern of the
interfering task. This technique was later extended by others to
analyze parallel tasks, as is done in this work. Bertogna et al. [6]
proposed a sufficient slack-based schedulability test for G-EDF
and G-FP in which the slack values for the tasks are used in an
iterative algorithm to improve the schedulability gradually. Later,
Guan et al. [14] proposed a new response-time analysis for both
constrained-deadline and arbitrary-deadline tasks.
Initially, simple parallel real-time task models were studied, such
as the fork-join task model and the synchronous task model. Lakshmanan et al. [20] presented a transformation algorithm to schedule
fork-join tasks where all parallel segments of each task must have
the same number of threads, which must be less than the number
of processors. They also proved a resource augmentation bound
of 3.42 for their algorithm. Saifullah et al. [24] improved on that
work by removing the restriction on the number of threads in parallel segments. They proposed a task decomposition algorithm and
proved resource augmentation bounds for the algorithm under GEDF and Partitioned Deadline Monotonic (P-DM) scheduling. Axer

We consider a set τ of n real-time parallel tasks, τ = {τ1 , τ2 , ..., τn },
scheduled preemptively by a global fixed-priority scheduling algorithm upon m identical processors. Each task τi is a recurrent, sporadic process which may release an infinite sequence of jobs and is
modeled by τi = {G i , D i ,Ti }, where D i denotes its relative deadline
and Ti denotes the minimum inter-arrival time of two consecutive
jobs of τi . We assume that all tasks have constrained deadlines,
i.e., D i ≤ Ti , ∀i ∈ [1, n]. Each task τi is represented as a Directed
Acyclic Graph (DAG) G i = (Vi , Ei ), where Vi = {vi,1 , vi,2 , ..., vi,ni }
is the set of vertices of the DAG G i and Ei ⊆ (Vi × Vi ) is the set
of directed edges of G i . In this paper, we also use subtasks and
nodes to refer to the vertices of the tasks. Each subtask vi,a of G i
represents a section of instructions that can only be run sequentially. A subtask vi,a is called a predecessor of vi,b if there exists an
edge from vi,a to vi,b in G i , i.e., (vi,a , vi,b ) ∈ G i . Subtask vi,b is
then called a successor of vi,a . Each edge (vi,a , vi,b ) represents a
precedence constraint between the two subtasks. A subtask is ready
if all of its predecessors have finished. Whenever a task releases a
job, all of its subtasks are released and have the same deadline as
the job’s deadline. We use Ji to denote an arbitrary job of τi which
has release time r i and absolute deadline di .
Each subtask vi,a has a worst-case execution time (WCET), denoted by Ci,a . The sum of WCETs of all subtasks of τi is the
worst-case execution time of the whole task, and is denoted by
Í
Ci = vi, a ∈Vi Ci,a . The WCET of a task is also called its work. A sequence of subtasks (vi,u1 , vi,u2 , ..., vi,ut ) of τi , in which (vi,u j , vi,u j+1 ) ∈
Ei , ∀1 ≤ j ≤ t − 1, is called a chain of τi and is denoted by λi . The
length of a chain λi is the sum of the WCETs of subtasks in λi and
Í
is denoted by len(λi ), i.e., len(λi ) = vi,u ∈λi Ci,u j . A chain of τi
j
which has the longest length is a critical path of the task. The length
of a critical path of a DAG is called its critical path length or span,
and is denoted by Li . Figure 1 illustrates an example DAG task
τi with 6 subtasks, whose work and span are Ci = 13 and Li = 8,
respectively. In this paper, we consider tasks that are scheduled
using a preemptive, global fixed-priority algorithm where each task
is assigned a fixed task-level priority. All subtasks of a task have
the same priority as the task. Without loss of generality, we assume
that tasks have distinct priorities, and τi has higher priority than
τk if i < k.

et al. [1] presented a response-time analysis for fork-join tasks
under Partitioned Fixed-Priority (P-FP) scheduling. Chwa et al. [9]
developed an analysis for synchronous parallel tasks scheduled
under G-EDF. They introduced the concept of critical interference
and presented a sufficient test for G-EDF. Maia et al. [21] reused
the concept of critical interference to introduce a response-time
analysis for synchronous tasks scheduled under G-FP. A general
parallel task model was presented by Baruah et al. [3] in which
each task is modeled as a Directed Acyclic Graph (DAG) and can
have an arbitrary deadline. They presented a polynomial test and
a pseudo-polynomial test for a DAG task scheduled with EDF and
proved their speedup bounds. However, they only considered a
single DAG task. Bonifaci et al. [7] later developed feasibility tests
for task systems with multiple DAG tasks, scheduled under G-EDF
and G-DM.
Melani et al. [22] proposed a response-time analysis for conditional DAG tasks where each DAG can have conditional vertices.
Their analysis utilizes the concepts of critical interference and critical chain, and works for both G-EDF and G-FP. However, the bounds
for carry-in and carry-out workloads are likely to be overestimated
since they ignore the internal structures of the tasks. Chwa et
al. [8] extended their work in [9] for DAG tasks scheduled under
G-EDF. They proposed a sufficient, workload-based schedulability
test and improved it by exploiting slack values of the tasks. Fonseca
et al. [12] proposed a response-time analysis for sporadic DAG
tasks scheduled under G-FP that improves upon the response-time
analysis in [22]. They improve the upper bounds for interference
by taking the DAGs of the tasks into consideration. In particular,
by explicitly considering the DAGs the workloads generated by the
carry-in and carry-out jobs can be reduced compared to the ones
in [22], and hence schedulability can be improved. The carry-in
workload is bounded by considering a schedule for the carry-in job
with unrestricted processors, in which subtasks execute as soon as
they are ready and for their full WCETs. The carry-out workload is
bounded for a less general type of DAG tasks, called nested forkjoin DAGs. We discuss the state-of-the-art analyses for G-FP and
differentiate our work in detail in Section 5.

3

SYSTEM MODEL

4

In this section we discuss the concept of critical interference that
our work is based on, and present a general framework to bound
response-times of DAG tasks scheduled under G-FP. In the next
section, we summarize the state-of-the-art analyses for G-FP and
give an overview of our method.

Ci =13, Li = 8
Vi, 2

Vi, 1

Ci,1 = 2

Ci,2 = 3

Vi, 6

Li

Vi, 4

Ci,4 = 3

Vi, 3

Ci,3 = 2

Ci,6 = 1

4.1

Critical Chain and Critical Interference

The notions of critical chain and critical interference were introduced
by Chwa et al. [8, 9] for analyzing parallel tasks scheduled with
G-EDF. Unlike sequential tasks, analysis of DAG tasks with internal
parallelism is inherently more complicated: (i) some subtasks of a
task can be interfered with by other subtasks of the same task (i.e.,
intra-task interference); (ii) subtasks of a task can be interfered with
by subtasks of higher-priority tasks (i.e., inter-task interference);
and (iii) the parallelism of a DAG task may vary during execution,

Vi, 5

Ci,5 = 2

Di

BACKGROUND

Ti

Figure 1: An example DAG task.
2

critical chain. Thus the scheduling window of a critical chain of Jk —
i.e., from the release time of its first subtask to the completion time
of its last subtask — is also the scheduling window of job Jk — i.e.,
from the job’s release time to its completion time. Third, consider
a critical chain λk of Jk : at any instant during the scheduling
window of Jk , either a critical subtask of λk is executed or a critical
subtask of λk is ready but not executed because all m processors are
busy executing subtasks not belonging to λk , including non-critical
subtasks of job Jk and subtasks from other tasks (see Figure 2).
Therefore, the response-time of a critical chain of Jk is also the
response-time of Jk . Hence if we can upper-bound the responsetime of a critical chain for any job Jk of τk , that bound also serves
as an upper-bound for the response-time of τk .
The third property of the critical chain suggests that we can
partition the scheduling window of a job Jk into two sets of intervals.
One includes all intervals during which critical subtasks of Jk are
executed and the other includes all intervals during which a critical
subtask of Jk is ready but not executed. The total length of the
intervals in the second set is called the critical interference of Jk . We
include definitions for critical interference and interference caused
by an individual task on τk as follows.

subject to the precedence constraints imposed by its graph. The
critical chain and critical interference concepts alleviate the complexity of the analysis by focusing on a special chain of subtasks
of a task which accounts for its response time, thus bringing the
problem closer to a more familiar analysis technique for sequential
tasks. Although they were originally proposed for analysis of GEDF [8, 9], these concepts are also useful for analyzing G-FP. We
therefore use them in our analysis and include a discussion of them
in this section.
Consider any job Jk of a task τk and its corresponding schedule. A last-completing subtask of Jk is a subtask that completes
last among all subtasks in the schedule of Jk . A last-completing
predecessor of a subtask vk,a is a predecessor that completes last
among all predecessors of vk,a in the schedule of Jk . Note that
a subtask can only be ready after a last-completing predecessor
finishes, since only then are all the precedence constraints for the
subtask satisfied. Starting from a last-completing subtask of Jk , we
can recursively trace back through all last-completing predecessors
until we reach a subtask with no predecessors. If during that process, a subtask has more than one last-completing predecessors, we
arbitrarily pick one. The chain that is reconstructed by appending
those last-completing predecessors and the last-completing subtask
is called a critical chain of job Jk . We call the subtasks that belong
to a critical chain critical subtasks.

Definition 4.2. Critical interference Ik (a, b) on a job Jk of task τk
is the aggregated length of all intervals in [a, b) during which a
critical subtask of Jk is ready but not executed.
Definition 4.3. Critical interference Ii,k (a, b) on a job Jk of task τk
due to task τi is the aggregated processor time from all intervals
in [a, b) during which one or more subtasks of τi are executed and
a critical subtask of Jk is ready but not executed.

: Execution of critical subtasks of Jk
: Execution of non-critical subtasks of Jk
: Execution of jobs of other tasks
Jk’s arrival

Jk’s finishing time Jk’s deadline

In Figure 2, the critical interference Ik (0, 14) of Jk is the sum
of the lengths of intervals [0, 2), [4, 5), [7, 9), and [11, 13) which
is 7. The critical interference Ii,k (0, 14) caused by a task τi is the
total processor time of τi in those four intervals. Note that τi may
execute simultaneously on multiple processors, and we must sum
its processor time on all processors. From the definition of critical
interference, we have:
1 Õ
Ik (a, b) =
I (a, b).
(1)
m τ ∈τ i,k

Vk, 4
Vk, 2

m
cores

Vk, 5

Vk,2
Vk, 1

vk,6

Vk, 3
0

2

4

5

7

9

11

13 14

15

Critical interference Ik(0, 14)

i

Figure 2: Critical chain and critical interference of Jk .

4.2
Example 4.1. Figure 2 presents an example of a critical chain of
a job Jk of task τk , which has the same DAG as shown in Figure 1.
In Figure 2, boxes with bold, solid borders denote the execution of
critical subtasks of Jk ; boxes with bold, dashed borders denote the
execution of the other subtasks of Jk . The other boxes are for jobs
of other tasks. Subtask vk,6 is a last-completing subtask. A lastcompleting predecessor of vk,6 is vk,5 . Similarly, a last-completing
predecessor of vk,5 is vk,3 , and a last-completing predecessor of
vk,3 is vk,1 . Hence a critical chain of Jk is (vk,1 , vk,3 , vk,5 , vk,6 ).

A General Method for Bounding
Response-Time

We now discuss a general framework for bounding response-time
in G-FP that is used in this work and was also employed by the
state-of-the-art analyses [12, 22]. Based on the definitions of critical
chain and critical interference, the response-time Rk of Jk is:
Rk = len(λk ) + Ik (r k , r k + Rk ),
where λk is a critical chain of Jk and len(λk ) is its length (see
Figure 2 for example). Applying Equation 1 we have:
 1

Õ
1
Rk = len(λk )+ Ik,k (r k , r k +Rk ) +
Ii,k (r k , r k +Rk ),
m
m

The critical chain concept has a few properties that make it
useful for schedulability analysis of parallel DAG tasks. First, the
first subtask of any critical chain of a job is ready to execute as
soon as the job is released, since it does not have any predecessor.
Second, when the last subtask of a critical chain completes, the
corresponding job finishes — this is from the construction of the

τi ∈hp(τk )

(2)
where hp(τk ) is the set of tasks with higher priorities than τk ’s. Thus
if we can bound the right-hand side of Equation 2, we can bound
the response-time of τk . To do so, we bound the contributions to
3

Ti

Body jobs

Di

Carry-out job

Ri
Li
vi,5

vi,5

vi, 2
vi, 1

vi, 3

ΔiCI

vi,5

vi, 2
vi, 4

vi,6

vi, 1

vi, 3

vi,5

vi, 2
vi, 4

vi, 1

vi,6

Carry-in job

vi, 3

vi, 2
vi, 4

vi,6

vi, 1

vi, 3

vi, 4

vi,6

ΔiCO

Δ
Δ

Figure 3: Workload generated by an interfering task τi in an interval of length ∆.
Jk ’s response-time caused by subtasks of Jk itself and by jobs of
higher-priority tasks separately.

1I
4.2.1 Intra-Task Interference. The sum len(λk )+ m
k,k (r k , r k +

Rk ) , which includes the intra-task interference on the critical chain
of Jk caused by non-critical subtasks of Jk , is bounded by Lemma
V.3 in [22]. We include the bound below.

However, unlike sequential tasks, analysis for parallel DAG tasks
is more challenging in two aspects. First, it is not obvious which
schedule for the subtasks of the carry-in (carry-out) job would
generate maximum carry-in (carry-out) workload. This is because
the parallelism of a DAG task can vary depending on its internal
graph structure. Second, for the same reason, aligning the problem
window’s start time with the start time of the carry-in job of τi may
not correspond to the maximum workload generated by τi . For
instance, in Figure 3 if we shift the problem window to the right 2
time units, the carry-in job’s workload loses 2 time units but the
carry-out job’s workload gains 5 time units. The total workload thus
increases 3 time units. Therefore in order to compute the maximum
workload generated by τi we must slide the problem window to find
a position that corresponds to the maximum sum of the carry-in
workload and carry-out workload. We discuss an existing method
for computing carry-in workload in Section 5 and our technique
for computing carry-out workload in Section 6. In Section 7, we
combine those two bounds in a response-time analysis and explain
how we slide problem windows to compute maximum workloads.
We note that the maximum workload generated by each body
job does not depend on the schedule of its subtasks and is simply its
total work. Furthermore, regardless of the position of the problem
window, the workload contributed by the body jobs, denoted by
WiBO (∆), is bounded as follows.

Lemma 4.4. The following inequality holds for any task τk scheduled by any work-conserving algorithm:
1
1
I (r , r + Rk ) ≤ Lk + (Ck − Lk )
m k,k k k
m
4.2.2 Inter-Task Interference. Now we need to bound the intertask interference on the right-hand side of Equation 2. Since the
interference caused by a task in an interval is at most the workload generated by the task during that interval, we can bound
Ii,k (a, b), ∀τi ∈ hp(τk ) using the bound for the workload generated by τi in the interval [a, b). Let Wi (a, b) denote the maximum
workload generated by τi in the interval [a, b). Let Wi (∆) denote
the maximum workload generated by τi in any interval of length
∆. The following inequality holds for any τi :
len(λk ) +

Ii,k (r k , r k + Rk ) ≤ Wi (r k , r k + Rk ) ≤ Wi (Rk ).

(3)

Let the problem window be the interval of interest with length ∆.
The jobs of τi that may generate workload within the problem window are classified into three types: (i) A carry-in job is released
strictly before the problem window and has a deadline within it,
(ii) A carry-out job is released within the problem window and has
its deadline strictly after it, and (iii) body jobs have both release
time and deadline within the problem window. Similar to analyses for sequential tasks (e.g., Bertogna et al. [4]), the maximum
workload generated by τi in the problem window can be attained
with a release pattern in which (i) jobs of τi are released as quickly
as possible, meaning that the gap between any two consecutive
releases is exactly the period Ti , (ii) the carry-in job finishes as
late as its worst-case finishing time, and (iii) the body jobs and the
carry-out job start executing as soon as they are released. Figure 3
shows an example of such a job-release pattern of an interfering
task τi with the DAG structure shown in Figure 1.

Lemma 4.5. The workload generated by the body jobs of task τi in
a problem window with length ∆ is upper-bounded by
n j∆ −L +R k
o

i
i
WiBO (∆) = max
− 1 Ci , 0 .
Ti
Proof. Consider the case where the start of the problem window
is aligned with the starting time of the carry-in job,jas shownk in

Figure 3. The number of body jobs is at most max ∆−LTii+Ri −
1, 0 . Thus for this case the workload of the body jobs is at most
 j ∆−Li +Ri k

− 1 Ci , 0 .
max
Ti
Shifting the problem window to the left or right can change the
workload contributed by the carry-in and carry-out jobs but does
not increase the maximum number of body jobs or their workload.
The bound thus follows.

4

Vi, 1

Vi, 6
Vi, 2

Vi, 9
Vi, 8

Vi, 5
Vi, 4

Vi, 3

Let the carry-in window and carry-out window be the intervals
within the problem window during which the carry-in job and
the carry-out job are executed, respectively. Intuitively, the carryin window spans from the start of the problem window to the
completion time of the carry-in job; the carry-out window spans
from the starting time of the carry-out job to the end of the problem
window. We denote the lengths of the carry-in window and carryI
CO respectively. The sum of
out window for task τi by ∆C
i and ∆i
C
I
CO
∆i and ∆i is:
I
CO
∆C
= Li + (∆ − Li + Ri ) mod Ti
i + ∆i

Vi, 1

Vi, 3
Vi, 1

Vi, 6
Vi, 2

Vi, 9
Vi, 8

Vi, 5
Vi, 4

(b) A nested fork-join DAG task.
Vi, 3

Vi, 7

Figure 5: Example for a general DAG task and a nested forkVi, 6
Vi, 9
i, 1
join DAGVtask.
Vi, 2

Vi, 5

Vi, 8

Fonseca et al. [12] later considered a task model similar to the
Vi, 4 a method to improve the bounds
one in this paper and proposed
for carry-in and carry-out workloads by explicitly considering the
DAGs. The carry-in workload was bounded using a hypothetical
schedule for the carry-in job, in which the carry-in job can use as
many processors as it needs to fully exploit its parallelism. They
proved that the carry-in workload of the hypothetical schedule is
maximized when: (i) the hypothetical schedule’s completion time
is aligned with the worst-case completion time of the interfering
task, (ii) every subtask in the hypothetical schedule starts executing
as soon as all of its predecessors finish, and (iii) every subtask
in the hypothetical schedule executes for its full WCET. Figure 3
shows the hypothetical schedule of the carry-in job for the task
in Figure 1. In this paper, we adopt their method for computing
carry-in workload. In particular, the carry-in workload of task τi
I
with a carry-in window of length ∆C
i , i.e., from the start of the
problem window to the completion time of the carry-in job (see
Figure 3), is computed as follows.
Õ

I
I
max Ci,k − max(Li − Si,k − ∆C
WiC I (∆C
i )=
i , 0), 0 . (6)

Body jobs
Carry-out job

m

Carry-in job

Vi, 7

(4)

THE STATE-OF-THE-ART ANALYSIS FOR
G-FP

Ri

Vi, 8

Vi, 5

(a) A non-nested-fork-join DAG task.

(5)
I
CO (∆CO ), we can
Therefore if we can bound WiC I (∆C
i ) and Wi
i
bound the inter-task interference of τi on τk and thus the responsetime of τk .

Ti

Vi, 9

Vi, 4

I
CO satisfy Eq. 4
∆C
i , ∆i

Di

Vi, 6
Vi, 2

I
Let WiC I (∆C
i ) be the maximum carry-in workload of τi for a carryI
CO (∆CO ) be the maxiin window of length ∆C
i . Similarly, let Wi
i
mum carry-out workload of τi for a carry-out window of length
∆CO
i . The maximum workload generated by τi in any problem
window of length ∆ can be computed by taking the maximum over
I
CO that satisfy Equation 4:
all ∆C
i and ∆i
n
o
I
CO CO
Wi (∆) = WiBO (∆) +
max
WiC I (∆C
(∆i ) .
i ) +Wi

5

Vi, 7

Δ

Figure 4: Workload generated by an interfering task τi in
Melani et al. [22].
Melani et al. [22] proposed a response-time analysis for G-FP
scheduling of conditional DAG tasks that may contain conditional
vertices, for modeling conditional constructs such as if-then-else
statements. They bounded the interfering workload by assuming
that jobs of the interfering task execute perfectly in parallel on all m
processors. Their bound for the interfering workload is computed
as follows.
j ∆ + R − C /m k

i
i
Wi (∆) =
Ci +min Ci , m((∆+Ri −Ci /m) mod Ti ) .
Ti
Figure 4 illustrates the workload computation for an interfering
task τi given in [22]. As shown in this figure, both carry-in and
carry-out jobs are assumed to execute with perfect parallelism
upon m processors. Thus their workload contributions in the considered window are maximized. This assumption simplifies the
workload computation as it ignores the internal DAG structures
of the interfering tasks. However, assuming that DAG tasks have
such abundant parallelism is likely unrealistic and thus makes the
analysis pessimistic.

v i,k ∈Vi

In Equation 6, Si,k is the start time of subtask vi,k in the hypothetical schedule for the carry-in job described above. It can be
computed by taking a longest path among all paths from source
subtasks to vi,k and adding up the WCETs of the subtasks along
that path excluding vi,k itself.
For the carry-out workload, [12] considered a subset of generalized DAG tasks, namely nested fork-join DAG (NFJ-DAG) tasks. A
NFJ-DAG is constructed recursively from smaller NFJ-DAGs using
two operations: series composition and parallel composition. Figure 5b shows an example NFJ-DAG task. Figure 5a shows a similar
DAG with one more edge (vi,7 , vi,8 ). The DAG in Figure 5a is not
a NFJ-DAG due to a single cross edge (vi,7 , vi,8 ). To deal with a
non NFJ-DAG, [12] first transforms the original DAG to a NFJ-DAG
by removing the conflicting edges, such as (vi,7 , vi,8 ) in Figure 5.
5

SCH E CO (τi ). This means vi,k must have started executing earlier
in SCH E ∗ than it have in SCH E CO (τi ). Hence, vi,k must have
started its execution before all of its predecessors have finished in
SCH E ∗ . This is impossible and the lemma follows.


Then they compute the upper-bound for the carry-out workload
using the obtained NFJ-DAG. The computed bound is proved to be
an upper-bound for the carry-out workload. We note that the transformation removes some precedence constraints from the original
DAG, and thus the resulting NFJ-DAG may have higher parallelism
than the original DAG. Hence, computing the carry-out workload
of a generalized DAG task via its transformed NFG-DAG may be
pessimistic, especially for a complex DAG, as the transformation
may remove many edges from the original DAG.
In this paper, we propose a new technique to directly compute
an upper-bound for the carry-out workload of generalized DAG
task. The high level idea is to frame the problem of finding the
bound as an optimization problem, which can be solved effectively
by solvers such as the CPLEX [16], Gurobi [15], or SCIP [25]. The
solution of the optimization problem then serves as a safe and tight
upper-bound for the carry-out workload. In the next section we
present our method in detail.

6

CO

BOUND FOR CARRY-OUT WORKLOAD
ΔiCO

ΔiCO

vi,5

2

4

vi,2

vi,2
vi,4

vi,4vi,1 vi,6vi,3
06

2 8

4

6

ΔiCO

vi,5

vi,5

vi,2
vi,3

Unlike the carry-in workload, the carry-out workload generated
when all subtasks execute for their full WCETs is not guaranteed to
be the maximum. Consider an interfering task τi shown in Figure 1
and a carry-out window of length 3 time units. If all subtasks of the
carry-out job of τi execute for their WCETs, the carry-out workload
would be 4 time units, as shown in Figure 6a. However, if subtask
vi,1 finishes immediately, i.e., executes for 0 time units, the carryout workload would be 7 time units, as shown in Figure 6b. From
Lemma 6.1 and the discussion above, to compute an upper-bound
for carry-out workload we must consider all possible execution
times of the subtasks and subtasks must execute as soon as they
are ready.
For each subtask vi,a of the carry-out job of an interfering task τi ,
we define two non-negative integer variables X i,a ≥ 0 andWi,a ≥ 0.
X i,a represents the actual execution time of subtask vi,a in the
carry-out job and Wi,a denotes the contribution of subtask vi,a to
the carry-out workload. Let ∆CO be an integer constant denoting
the length of the carry-out window. Then the carry-out workload is
vi,5
the sum of the contributions of all subtasks in SCH E CO (τi ), which
is upper-bounded by the maximum of the following optimization
objective function:
vi,4 vi,6
Õ
obj(τi , ∆CO ) ,
Wi,a .
(7)

8

(a) Carry-out workload when all
subtasks execute for WCETs.

vi,4

vi,3

vi,6
0

vi,2

2

4 0

vvi,6
i,3
62

4

(b) Carry-out workload
when
subtasks
may
execute less than WCETs.

6

v i, a ∈Vi

The optimal value for the above objective function gives the
actual maximum workload generated by the carry-out job with
unrestricted number of processors. We now construct a set of
constraints on the contribution of each subtask in SCH E CO (τi )
to the carry-out workload. From the definitions of X i,a and Wi,a ,
we have the following bounds for them.

Figure 6: An illustration of generating the maximum carryout workload.

Constraint 1. For any interfering task τi :

In this section we propose a method to bound the carry-out
workload that can be generated by a job of task τi by constructing
an integer linear program (ILP) for which the optimal solution
value is an upper-bound of the carry-out workload.
Consider a carry-out job of task τi , which is scheduled with
an unrestricted number of processors, meaning that it can use as
many processors as it requires to fully exploit its parallelism. Each
subtask of the carry-out job executes as soon as it is ready, i.e.,
immediately after all of its predecessors have finished. We label
such a schedule for the carry-out job SCH E CO (τi ). We prove in
the following lemma that the workload generated by SCH E CO (τi )
is an upper-bound for the carry-out workload.

∀vi,a ∈ Vi : 0 ≤ X i,a ≤ Ci,a .
Constraint 2. For any interfering task τi :
∀vi,a ∈ Vi : 0 ≤ Wi,a ≤ X i,a .
These two constraints come from the fact that the actual execution time of subtask vi,a cannot exceed its WCET, and each subtask
can contribute at most its whole execution time to the carry-out
workload. Let Si,a be the starting time of vi,a in SCH E CO (τi ) assuming that the carry-out job starts at time instant 0. For simplicity
of exposition, we assume that the DAG G i has exactly one source
vertex and one sink vertex. If this is not the case, we can always add
a couple of dummy vertices, vi,sour ce and vi,sink , with zero WCETs
for source and sink vertices, respectively. Then we add edges from
vi,sour ce to all vertices with no predecessors in the original DAG G i ,
and edges from all vertices with no successors in G i to vi,sink . Without loss of generality, we assume that vi,1 and vi,ni are the source
p
vertex and sink vertex of G i , respectively. Let σi,a denote a path

Lemma 6.1. For specific values of the execution times for the subtasks of τi , workload generated by SCH E CO (τi ) in a carry-out window of length ∆CO
is an upper-bound for the carry-out workload
i
generated by τi with the given subtasks’s execution times.
Proof. We prove by contradiction. Consider a schedule SCH E ∗
for the carry-out job in which subtasks execute for the same lengths
as in SCH E CO (τi ). Suppose subtask vi,k is the first subtask in
time order that produces more workload in SCH E ∗ than it does in

p

from the source vi,1 to vi,a : σi,a , (vi, j1 , ..., vi, jp ), where j 1 = 1,
6

jp = a, and (vi, j x , vi, j x +1 ) is an edge in G i ∀1 ≤ x < p. Let P(vi,a )
p
denote the set of all paths from vi,1 to vi,a in G i : P(vi,a ) , {σi,a }.
P(vi,a ) for all subtasks can be constructed by a graph traversal
algorithm. For instance, a simple modification of depth-first search
would accomplish this.
p
For a particular path σi,a , the sum of execution times of all subtasks in this path, excluding vi,a is called the distance to vi,a with
p
respect to this path. We let D i,a be a variable denoting the distance

Based on Lemmas 6.2 and 6.3, we have the following constraint
for the starting time of vi,a .
Constraint 5. For any interfering task τi :
p

Proof. We prove that this constraint requires that Si,a of evp
ery subtask vi,a for which maxσ p ∈ P(v ) D i,a < ∆CO satisfies
i, a

p

p

constraints on D i,a based on its definition.
Constraint 3. For any interfering task τi :
p

p

Õ

X i, j x .

p
v i, j x ∈ {σi, a \v i, a }

Constraint 4. For any interfering task τi :
p

p

Õ

∀vi,a ∈ Vi , ∀σi,a ∈ P(vi,a ) : D i,a ≥

X i, j x .

p

v i, j x ∈ {σi, a \v i, a }

i, a

τi :
p

∀vi,a ∈ Vi , ∀σi,a ∈ P(vi,a ) : Si,a ≥ D i,a .
p∗

Proof. We prove by contradiction. Let σi,a be a path so that the

p∗
starting time Si,a is smaller than D i,a .

Subtask vi,a must be ready to
start execution, meaning all of its predecessors must finish, at time
p∗
p∗
Si,a . Since Si,a < D i,a , there must be a subtask vi, j x ∈ {σi,a \vi,a }
executing (and thus not finished) at time Si,a . Then vi,a cannot be
ready at time Si,a since it depends on vi, j x . This contradicts the
assumption that vi,a is ready at Si,a and the lemma follows.

In fact, in the schedule SCH E (τi ) the starting time Si,a of
vi,a is equal to the longest distance among all paths to it.
Lemma 6.3. In the schedule SCH E CO (τi ) of any interfering task
τi :
max

p

The workload
 contributed by a subtask vi,a is:
Wi,a = min max{∆CO − Si,a , 0}, X i,a . The second part of the
outer minimization has been taken care of by Constraint 2. We
now construct constraints to impose the first part of the minimization. Let Mi,a be an integer variable representing the expression
max{∆CO −Si,a , 0}. Let Ai,a be a binary variable which takes value
either 0 or 1. We have the following constraints.

CO

p

i, a

∗ = max p
are done. Suppose instead that Si,a
σi, a ∈ P(v i, a ) D i,a + ϵi,a ,
ϵi,a > 0 for some vi,a ∈ Qi . Let Q 0i denote the set of such subtasks.
We construct a solution π 0 to the optimization problem from π ∗
as follows. Consider a first subtask vi,a ∈ Q 0i in time. We reduce
0 = S ∗ − ϵ . Since v
its starting time by ϵi,a : Si,a
i,a
i,a is the first
i,a
delayed subtask, doing this does not violate the precedence constraints for other subtasks. We iteratively perform that operation
for other subtasks in Q 0i in increasing time order. The solution π 0
constructed in this way yields a larger carry-out workload since
more workload from individual subtasks can fit in the carry-out
window. Therefore π 0 is a better solution, which contradicts the
assumption that π ∗ is an optimal solution.


Lemma 6.2. In the schedule SCH E CO (τi ) of any interfering task

σi, a ∈ P(v i, a )

i, a

vi,a since any solution to the optimization problem satisfies this conp
∗ = max p
straint. If Si,a
σ ∈ P(v ) D i,a for any vi,a ∈ Qi , then we

In the schedule SCH E (τi ), the starting time Si,a of a subtask
p
vi,a cannot be smaller than the distance to vi,a in any path σi,a .
We prove this as follows.

∀vi,a ∈ Vi : Si,a =

p

i, a

CO

p

i, a

Lemma 6.3, that is Si,a = maxσ p ∈ P(v ) D i,a . (Recall that ∆CO is
i, a
i, a
a constant denoting the carry-out window’s length.) In other words,
we prove that it requires that every subtask vi,a , which would start
executing within the carry-out window in an unrestricted-processor
schedule SCH E CO (τi ), gets exactly the same starting time from
the solution to the optimization problem. Let Qi denote the collection of such subtasks — the ones that would start executing within
the carry-out window in SCH E CO (τi ).
∗ be the
Let π ∗ be the solution to the optimization problem and Si,a
corresponding value for the starting time of any subtask vi,a ∈ Qi
p
∗ ≥ max p
in the solution π ∗ . Obviously Si,a
σ ∈ P(v ) D i,a for any

to vi,a in path σi,a . We impose the following two straightforward

∀vi,a ∈ Vi , ∀σi,a ∈ P(vi,a ) : D i,a ≤

p

∀vi,a ∈ Vi , ∀σi,a ∈ P(vi,a ) : Si,a ≥ D i,a .

p

D i,a .

Constraint 6. For any interfering task τi :

p∗

∀vi,a ∈ Vi : Wi,a ≤ Mi,a .

Proof. Consider a path σi,a constructed as follows. First we
take a last-completing predecessor of vi,a , say vi, j x . Since vi,a
executes as soon as it is ready, it executes immediately after vi, j x
finishes. We recursively trace back through the last-completing
predecessors in that way until we reach the source vertex vi,1 . Path
p∗
σi,a is then constructed by chaining the last-completing prede-

Constraint 7. For any interfering task τi :
∀vi,a ∈ Vi : Mi,a ≥ 0.
Constraint 8. For any interfering task τi :

p∗
in σi,a

cessors together with vi,a . We note that any subtask vi, j x
executes as soon as its immediately preceding subtask finishes, since
no other predecessors of vi, j x finish later than it does. Therefore,
p∗
p∗
Si,a = D i,a . From Lemma 6.2, σi,a must have the longest distance
to vi,a among all paths in P(vi,a ). Thus the lemma follows.


∀vi,a ∈ Vi : Mi,a ≤ (∆CO − Si,a )Ai,a .
Constraints 7 and 8 bound the value for Mi,a and Constraint 6
enforces another upper bound for the workloadWi,a . If ∆CO < Si,a ,
Ai,a can only be 0 in order to satisfy both Contraints 7 and 8. If
7

∆CO = Si,a , the value of Ai,a does not matter. In both cases, these
three constraints together with Constraint 2 bound Wi,a to zero
contribution of vi,a to the carry-out workload. If ∆CO > Si,a , the
maximizing process enforces that Ai,a takes value 1. Therefore in
any case Constraints 2, 6, 7, and 8 enforce a correct value for the
workload contribution Wi,a of vi,a .
We have constructed an ILP with a quadratic constraint (Constraint 8) for each vi,a , for which the optimal solution value is an
upper bound for the carry-out workload. The carry-out workload of
τi in a carry-out window of length ∆CO can also be upper-bounded
by the following straightforward lemma.

Algorithm 1 Response-Time Analysis
1:

2:

3:
4:
5:
6:
7:

Lemma 6.4. The carry-out workload of an interfering task τi scheduled by G-FP in a carry-out window of length ∆CO is upper-bounded
by m∆CO .

8:
9:

Lemma 6.4 follows directly from the fact that the carry-out job
can execute at most on all m processors of the system during the
carry-out window. Since the carry-out workload of τi is upperbounded by both the maximum value returned for the optimization
problem and Lemma 6.4, it is upper-bounded by the minimum of
the two quantities.

10:
11:
12:
13:
14:
15:

Theorem 6.5. The carry-out workload of an interfering task τi
scheduled by G-FPn in a carry-outowindow of length ∆CO is upperbounded by: min OBJ , m∆CO , where OBJ is the maximum
value returned for the maximization problem (Equation 7).

RESPONSE-TIME ANALYSIS

From the above calculations for the bounds of intra-task interference and inter-task interference on τk , we have the following
theorem for the response-time bound of τk .
Theorem 7.1. A constrained-deadline task τk scheduled by a
global fixed-priority algorithm has response-time upper-bounded by
the smallest integer Rub
that satisfies the following fixed-point iterak
tion:
1
1
Rub
k ← Lk + m (Ck − Lk ) + m

Õ
τi ∈hp(τk )

for τk from τ2 to τn do
Calculate Rub
in Theorem 7.1
k
if Rub
>
D
then
k
k
Return Unschedulable
end if
end for
Return Schedulable
end procedure

In Theorem 7.1, Wi (Rub
) is computed using Equation 5 for all
k
carry-in and carry-out windows that satisfy Equation 4. For specific carry-in and carry-out window lengths, the carry-in workload is bounded using Equation 6 and the carry-out workload is
bounded as discussed in Section 6. The lengths for carry-in winI
CO are varied as follows. Let
dow ∆C
i and carry-out window ∆i
I
Γ denote the right-hand side of Equation 4. First ∆C
i takes its
C
I
CO
largest value: ∆i ← min{Γ, Li }, and ∆i takes the remaining
I
CI
sum: ∆CO
← min{Γ − ∆C
i
i , Li }. Then in each subsequent step, ∆i
CO
CO
is decreased and ∆i is increased until ∆i takes its largest value
I
and ∆C
i takes the remaining value. We note that if at the first step
C
both ∆i I and ∆CO
are greater than or equal to Li , the carry-in
i
I
workload and carry-out workload are bounded by min(Ci , m∆C
i )
CO
C
I
and min(Ci , m∆i ), respectively. Similarly, if the sum of ∆i and
∆CO
is 0 in Equation 4, both the carry-in workload and the carryi
out workload are 0. We also note that for the highest priority task,
there is no interference from any other task, and thus its response1 (C − L ) .
time bound can be computed simply by: Rub
← Lk + m
k
k
k
Using the above response-time bound, we derive a schedulability
test, shown in Algorithm 1. First we initialize the response-times
−L k 
for the tasks to be Lk + Ckm
for all tasks τk . If for any task, the
initial response-time is larger than its relative deadline, then the task
set is deemed unschedulable (lines 2-7). Otherwise, we repeatedly
compute the response-time bound for each task in descending order
of priority using the fixed-point iteration in Theorem 7.1 (line 9).
After the computation for each task finishes, we check whether
the response-time bound is larger than its deadline. If it is, then
the task set is deemed unschedulable (lines 10-12). Otherwise, the
task set is deemed schedulable after all tasks have been checked
(line 14).
As expected for response-time analysis, for each task τi the
number of iterations in the fixed-point equation (Theorem 7.1) is

As discussed in Section 5, the technique proposed by Fonseca et
al. [12] can be applied directly for NFJ-DAGs but not for general
DAGs. For a general DAG, the procedure to transform the general
DAG to an NFJ-DAG will likely inflate the carry-out workload
bound as it removes some precedence constraints between subtasks
and enables a higher parallelism (and thus a greater interfering
workload) for the carry-out job. In contrast, our method directly
bounds the carry-out workload for any DAG and the optimal value
obtained is the actual maximum carry-out workload. Hence, our
method theoretically yields better schedulability than [12]’s for
general DAGs. The cost of our method is higher time complexity
for computing carry-out workload due to the hardness of the ILP
problem. However, it can be implemented and works effectively
with modern optimization solvers, as we show in our experiments
(Section 8).

7

procedure SchedulabilityTest(τ )
. Without loss
of generality, assuming tasks are sorted in decreasing order of
priority
for Each τk ∈ τ do
. Initialize the values for
response-time bounds
1 (C − L )
Rub
←
L
+
k
k
k
m
k
if Any Rub
> D k then
k
Return Unschedulable
end if
end for

Wi (Rub
k ).

Proof. This follows from Equation 2, Lemma 4.4 and the fact
that the inter-task interference of τi on τk is bounded by the workload generated by τi (Equation 3).

8

pseudo-polynomial in the task’s deadline D i (line 9). In each iteration of the fixed-point equation and for each interfering task, we
consider all combinations of carry-in and carry-out window lengths
that satisfy Equation 4 to compute the maximum interfering workload. There are O(Li ) such combinations, and thus the ILP for the
carry-out workload is solved O(Li ) times. The maximum workload
over all combinations of carry-in and carry-out window lengths
gives an upper-bound for the interfering workload generated by
the given interfering task.

8

in [22], denoted by MBB-RTA. For all generated task sets, priorities
were assigned in Deadline Monotonic order — studying an efficient
priority assignment scheme for G-FP is beyond the scope of this
paper.
Figures 7a, 7b, 7c, and 7d show representative results for our
experiments. In Figure 7a and 7b, we fixed the total number of
processors m = 16 and varied the total utilization from 1.0 to 14.0.
The minimum task utilization β was set to 0.2 and 0.4 in these two
experiments, respectively. Unsurprisingly, DGA-RTA dominates
MBB-RTA, as also observed in [12]. Notably, its schedulability
ratios for some configurations are two times or more greater than
MBB-RTA, e.g., for total utilizations of 8.0, 9.0 in Figure 7a, and
7.0, 8.0 in Figure 7b. In Figures 7c and 7d, we fixed the normalized
total utilization and varied the number of processors m from 2 to 36.
For each value of m, we generated task sets with total utilization
U = 0.5m or U = 0.7m for these two experiments, respectively.
Similar to the previous experiments, the schedulability ratios of the
generated task sets were improved significantly using DGA-RTA
compared to MBB-RTA.
To provide a trade-off between computational complexity and
accuracy of schedulability test, one can employ our analysis in
combination with the analysis presented in [12] by first applying
their response-time analysis and then using our analysis if the task
set is deemed unschedulable by [12]. In this way, one can get the
best result from both analyses.

EVALUATION

As we discussed in Sections 5 and 6, we apply a similar, high-level
framework for analyzing schedulability of G-FP scheduling to the
one used by Fonseca et al. [12] — i.e., accounting for the interfering
workloads caused by the body jobs, the carry-in and carry-out jobs
separately, and maximizing the interference by sliding the problem window. However, unlike [12] our technique for bounding
carry-out workload works directly for general DAGs and does not
introduce pessimism due to the removal of precedence constraints
between subtasks, as presented in [12]. Though for carry-in workload, we reuse the result from [12]. Hence, we consider our work
as a generalization/extension of [12] that can be applied for general
sporadic DAG tasks. The performance of our method in term of
schedulability ratio is compatible with [12]’s — it theoretically is at
least as good as [12] for NFJ-DAGs and is better than [12] for non
NFJ-DAGs. We thus focus on measuring the performance of our
method and use the work by Melani et al. [22] as a reference for
evaluating the improvement of our method upon their simple one.
We applied the Erdős-Rényi G(n, p) method, described in [10],
to generate DAG tasks. In this method the number of subtasks,
given by parameter n in G(n, p), is first fixed. Then, directed edges
between pairs of vertices are added with probability p. Since the obtained DAG may not necessarily be connected, we added a minimum
number of edges to make it weakly connected. In our experiments,
the probability for a directed edge to be added is p = 0.2. We chose
the number of subtasks uniformly in the range [10, 20]. Other parameters for each DAG task τi were generated similarly to [22]. In
particular, the WCETs of subtasks of τi were generated uniformly
in the range [1, 100]. After that, the work Ci and span Li were
calculated. τi ’s utilization was generated uniformly in the range
[β, Ci /Li ], where β ≤ 1 is a parameter to control the minimum
task’s utilization and Ci /Li represents the degree of parallelism of
task τi . τi ’s deadline D i was generated using a normal distribution
Ti −L i
i
with mean equal to ( Ti +L
2 ) and standard deviation equal to ( 4 ).
We kept generating the relative deadline until a value in the range
[Li ,Ti ] was obtained.
To generate a task set for a given total utilization, we repeatedly
add DAG tasks to the task set until the desired utilization is reached.
The utilization (and period) of the last task may need to be adjusted
to match the total utilization. We used the SCIP solver [25] with
CPLEX [16] as its underlying LP-solver to compute the bound for
carry-out workload. For our experiments, we set the default minimum utilization of individual tasks β to 0.1. For each configuration
we generated 500 task sets and recorded the ratios of task sets that
were deemed schedulable. We compare our response-time analysis,
denoted by DGA-RTA, with the response-time analysis introduced

9

CONCLUSION

In this paper we consider constrained-deadline, parallel DAG tasks
scheduled under a preemptive, G-FP scheduling algorithm on multiprocessor platforms. We propose a new technique for bounding
carry-out workload of interfering task by converting the calculation
of the bound to an optimization problem, for which efficient solvers
exist. The proposed technique applies directly to general DAG tasks.
The optimal solution value for the optimization problem serves as
a safe and tight upper bound for carry-out workload. We present a
response-time analysis for G-FP based on the proposed workload
bounding technique. Experimental results affirm the dominance of
the proposed approach over existing techniques. There are a couple
of open questions that we would like to address in future. They
include bounding carry-in and carry-out workloads for the actual
number of processors m of the system and designing an efficient
priority assignment scheme for parallel DAG tasks scheduled under
G-FP algorithm.

REFERENCES
[1] Philip Axer, Sophie Quinton, Moritz Neukirchner, Rolf Ernst, Björn Döbel, and
Hermann Härtig. 2013. Response-time analysis of parallel fork-join workloads
with real-time constraints. In 25th Euromicro Conference on Real-Time Systems,
2013. IEEE, 215–224.
[2] Theodore Baker. 2003. Multiprocessor EDF and deadline monotonic schedulability analysis. In 24th Real-Time Systems Symposium, 2003. IEEE, 120–129.
[3] Sanjoy Baruah, Vincenzo Bonifaci, Alberto Marchetti-Spaccamela, Leen Stougie,
and Andreas Wiese. 2012. A generalized parallel task model for recurrent realtime processes. In 33rd Real-Time Systems Symposium, 2012. IEEE, 63–72.
[4] Marko Bertogna and Michele Cirinei. 2007. Response-time analysis for globally scheduled symmetric multiprocessor platforms. In 28th Real-Time Systems
Symposium, 2007. IEEE, 149–160.
[5] Marko Bertogna, Michele Cirinei, and Giuseppe Lipari. 2005. Improved schedulability analysis of EDF on multiprocessor platforms. In 17th Euromicro Conference
on Real-Time Systems, 2005. IEEE, 209–218.
9

1

1

DGA-RTA
MBB-RTA

Ratio of Schedulable Task Sets

Ratio of Schedulable Task Sets

DGA-RTA
MBB-RTA

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

0.3

0.3

0.2

0.2

0.1

0.1

0
1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0

0
1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 13.0 14.0

Total Utilization of Task Set

Total Utilization of Task Set

(a) Result for m = 16, minimum task utilization β = 0.2, and
varying total utilization.

(b) Result for m = 16, minimum task utilization β = 0.4, and
varying total utilization.

Ratio of Schedulable Task Sets

DGA-RTA
MBB-RTA

Ratio of Schedulable Task Sets

DGA-RTA
MBB-RTA

0.8

0.5

0.7

0.4

0.6
0.5

0.3

0.4

0.2

0.3
0.2

0.1

0.1
0

2

4

6

0

8 10 12 14 16 18 20 22 24 26 28 30 32 34 36

Total Number of Processors

(c) Result for total utilization U = 0.5m, minimum utilization
β = 0.1, and varying m.

2

4

6

8

10 12 14 16 18 20 22 24 26 28 30

Total Number of Processors

(d) Result for total utilization U = 0.7m, minimum utilization
β = 0.1, and varying m.

Figure 7: Ratio of schedulable task sets for varying total utilization and varying number of processors.
on Embedded Software. ACM, 1–10.
[12] José Fonseca, Geoffrey Nelissen, and Vincent Nélis. 2017. Improved response
time analysis of sporadic DAG tasks for global FP scheduling. In Proceedings
of the 25th International Conference on Real-Time Networks and Systems. ACM,
28–37.
[13] Matteo Frigo, Charles E Leiserson, and Keith H Randall. 1998. The implementation
of the Cilk-5 multithreaded language. ACM Sigplan Notices 33, 5, 212–223.
[14] Nan Guan, Martin Stigge, Wang Yi, and Ge Yu. 2009. New response time bounds
for fixed priority multiprocessor scheduling. In 30th Real-Time Systems Symposium, 2009. IEEE, 387–397.
[15] Gurobi Solver. 2019. http://www.gurobi.com/index.
[16] IBM ILOG CPLEX Optimizer. 2019.
https://www.ibm.com/analytics/
cplex-optimizer.
[17] Intel Cilk Plus. 2019. https://www.cilkplus.org/.
[18] Intel Threading Building Blocks. 2019. https://www.threadingbuildingblocks.
org/.
[19] Junsung Kim, Hyoseung Kim, Karthik Lakshmanan, and Ragunathan Raj Rajkumar. 2013. Parallel scheduling for cyber-physical systems: Analysis and case
study on a self-driving car. In Proceedings of the ACM/IEEE 4th International
Conference on Cyber-Physical Systems. ACM, 31–40.
[20] Karthik Lakshmanan, Shinpei Kato, and Ragunathan Raj Rajkumar. 2010. Scheduling parallel real-time tasks on multi-core processors. In 31st IEEE Real-Time

[6] Marko Bertogna, Michele Cirinei, and Giuseppe Lipari. 2009. Schedulability
analysis of global scheduling algorithms on multiprocessor platforms. IEEE
Transactions on parallel and distributed systems 20, 4 (2009), 553–566.
[7] Vincenzo Bonifaci, Alberto Marchetti-Spaccamela, Sebastian Stiller, and Andreas Wiese. 2013. Feasibility analysis in the sporadic DAG task model. In 25th
Euromicro Conference on Real-Time Systems, 2013. IEEE, 225–233.
[8] Hoon Sung Chwa, Jinkyu Lee, Jiyeon Lee, Kiew-My Phan, Arvind Easwaran,
and Insik Shin. 2017. Global EDF schedulability analysis for parallel tasks on
multi-core platforms. IEEE Transactions on Parallel and Distributed Systems 28, 5
(2017), 1331–1345.
[9] Hoon Sung Chwa, Jinkyu Lee, Kieu-My Phan, Arvind Easwaran, and Insik Shin.
2013. Global EDF schedulability analysis for synchronous parallel tasks on
multicore platforms. In 25th Euromicro Conference on Real-Time Systems, 2013.
IEEE, 25–34.
[10] Daniel Cordeiro, Grégory Mounié, Swann Perarnau, Denis Trystram, Jean-Marc
Vincent, and Frédéric Wagner. 2010. Random graph generation for scheduling
simulations. In Proceedings of the 3rd international ICST conference on simulation
tools and techniques. ICST (Institute for Computer Sciences, Social-Informatics
and Telecommunications Engineering), 60.
[11] David Ferry, Gregory Bunting, Amin Maghareh, Arun Prakash, Shirley Dyke,
Kunal Agrawal, Chris Gill, and Chenyang Lu. 2014. Real-time system support for
hybrid structural simulation. In Proceedings of the 14th International Conference
10

Systems Symposium, 2010. IEEE, 259–268.
[21] Cláudio Maia, Marko Bertogna, Luı́s Nogueira, and Luis Miguel Pinho. 2014.
Response-time analysis of synchronous parallel tasks in multiprocessor systems.
In Proceedings of the 22nd International Conference on Real-Time Networks and
Systems. ACM, 3.
[22] Alessandra Melani, Marko Bertogna, Vincenzo Bonifaci, Alberto MarchettiSpaccamela, and Giorgio C Buttazzo. 2015. Response-time analysis of conditional
DAG tasks in multiprocessor systems. In 27th Euromicro Conference on Real-Time
Systems, 2015. IEEE, 211–221.
[23] OpenMP. 2019. https://www.openmp.org/.
[24] Abusayeed Saifullah, Jing Li, Kunal Agrawal, Chenyang Lu, and Christopher
Gill. 2013. Multi-core real-time scheduling for generalized parallel task models.
Real-Time Systems 49, 4 (2013), 404–435.
[25] SCIP Solver. 2019. http://scip.zib.de/.

11

