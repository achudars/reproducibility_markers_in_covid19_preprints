1

Distributed Attack-Robust Submodular
Maximization for Multi-Robot Planning

arXiv:1910.01208v3 [cs.RO] 1 Nov 2020

Lifeng Zhou, Student Member, IEEE, Vasileios Tzoumas, Member, IEEE, George J. Pappas, Fellow, IEEE,
and Pratap Tokekar, Member, IEEE

Abstract—In this paper, we design algorithms to protect
swarm-robotics applications against attacks that result in robot
removals. We focus on applications requiring the robots to
jointly select actions, e.g., which trajectory to follow, among
a set of available ones. Such applications are central in largescale robotic applications, such as multi-robot motion planning
for target tracking. But the current attack-robust algorithms
are centralized. In this paper, we propose a general-purpose
distributed algorithm towards robust optimization at scale, with
local communications only. We name it Distributed Robust Maximization (DRM). DRM proposes a divide-and-conquer approach
that distributively partitions the problem among cliques of robots.
Then, the cliques optimize in parallel, independently of each
other. We prove DRM achieves a close-to-optimal performance. We
demonstrate DRM’s performance in both Gazebo and MATLAB
simulations, in scenarios of active target tracking with swarms of
robots. In the simulations, DRM achieves computational speedups, being 3-4 orders faster than the centralized algorithms; yet,
it nearly matches the tracking performance of the centralized
counterparts. However, DRM overestimates the number of attacks
in each clique. To amend this conservativeness of DRM, in
this paper we also introduce an Improved Distributed Robust
Maximization (IDRM) algorithm. IDRM infers the number of
attacks in each clique less conservatively than DRM by leveraging
3-hop neighboring communications. We verify IDRM improves
DRM’s performance in simulations.
Index Terms—Distributed optimization, robust optimization,
submodular optimization, approximation algorithm, adversarial
attacks, multi-robot planning, target tracking.

I. I NTRODUCTION
Safe-critical tasks of surveillance and exploration often
require mobile agility, and fast capability to detect, localize,
and monitor. For example, consider the tasks:
• Adversarial target tracking: Track adversarial targets
that move across an urban environment, aiming to escape; [1]
L. Zhou was with the Department of Electrical and Computer Engineering,
Virginia Tech, Blacksburg, VA, USA when part of the work was completed.
He is currently with the GRASP Laboratory, University of Pennsylvania,
Philadelphia, PA, USA (email: lfzhou@seas.upenn.edu).
V. Tzoumas is with the Laboratory of Information and Decision Systems,
Massachusetts Institute of Technology, Cambridge, MA 02139 USA (email:
vtzoumas@mit.edu).
G. J. Pappas is with the Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA 19104 USA (email:
pappagsg@seas.upenn.edu).
P. Tokekar is with the Department of Computer Science, University of
Maryland, College Park, MD 20742, USA (email: tokekar@umd.edu).
This work is supported by the ARL CRA DCIST, the National Science
Foundation under Grant No. 479615, and the Office of Naval Research under
Grant No. N000141812829.

Fig. 1. Targets’ attacks can block robots’ field-of-view: in target tracking
with aerial robots, the robots are mounted with down-facing cameras to track
mobile targets (depicted as dots).

• Search and rescue: Explore a burning building to
localize any people trapped inside. [2]

Such scenarios can greatly benefit from teams of mobile
robots that are agile, act as sensors, and plan their actions
rapidly. For this reason, researchers are (i) pushing the frontier
on robotic miniaturization and perception [1]–[7], to enable
mobile agility and autonomous sensing, and (ii) developing
distributed coordination algorithms [8]–[12], to enable multirobot planning, i.e., the joint optimization of robots’ actions.
Particularly, distributed planning algorithms are important
when one wishes to deploy large-scale teams of robots; e.g.,
at the swarm level of tens or hundreds of robots. One reason
is that distributed algorithms scale better for larger numbers of
robots than their centralized counterparts [8]. Additionally, in
large-scale teams, it is infeasible for all robots to communicate
with each other; typically, each robot can communicate only
with the robots within a certain communication range.
However, the safety of the above critical scenarios can be
at peril. Robots operating in adversarial scenarios may get
cyber-attacked or simply face failures, resulting in a temporary
withdrawal of robots from the task (e.g., because of temporary
deactivation of their sensors, blockage of their field of view,
among others; cf. Fig. 1). We refer to such attacks as Denialof-Service (DoS). Hence, in such adversarial scenarios, distributed attack-robust planning algorithms become necessary.1
In this paper, we formalize a general framework for distributed attack-robust multi-robot planning for tasks that require the maximization of submodular functions, such as active
1 We henceforth consider the terms attack and failure equivalent, both
resulting in robot withdrawals from the task at hand.

2

target tracking with multiple-robots [13].2 Particularly, we
focus on worst-case attacks that can result in up to α robot
withdrawals from the task at each time step.
Attack-robust multi-robot planning is computationally hard
and requires accounting for all possible α withdrawals, a
problem of combinatorial complexity. Importantly, even in
the presence of no withdrawals, the problem of multi-robot
planning is NP-hard [15], [16]. All in all, the necessity for
distributed attack-robust algorithms, and the inherent computational hardness motivates our goal in this paper: to provide a distributed, provably close-to-optimal approximation
algorithm. To this end, we capitalize on recent algorithmic
results on centralized attack-robust multi-robot planning [17]
and present a distributed attack-robust algorithm.
Related work. Researchers have developed several distributed, but attack-free, planning algorithms, such as [8]–[12].
For example, [8] developed a decentralized algorithm, building
on the local greedy algorithm proposed in [18, Section 4],
which guarantees a 1/2 suboptimality bound for submodular
objective functions. Particularly, in [8] the robots form a string
communication network, and sequentially choose an action,
given the actions of the robots that have chosen so far. In [11],
the authors proposed a speed-up of [8]’s approach, by enabling
the greedy sequential optimization to be executed over directed
acyclic graphs, instead of string ones. In scenarios where the
robots cannot observe all the chosen actions so far, distributed,
but still attack-free, algorithms for submodular maximization
are developed in [19], [20]. Other distributed, attack-free
algorithms are developed in the machine learning literature on
submodular maximization, towards sparse selection (e.g., for
data selection, or sensor placement) [21], instead of planning.
Researchers have also developed robust planning algorithms [17], [22]–[27]. Among these, [22]–[24] focus on
deceptive attacks, instead of DoS attacks. In more detail, [22],
[23] provide distributed resilient formation control algorithms
to deal with malicious robots in the team, that share deceptive
information. Similarly, [24] provides a distributed resilient
state estimation algorithm against robots executing Byzantine
attacks by sending differing state estimates or not transmitting
any estimates. In contrast to [22]–[24], the [17], [25] consider
DoS attacks in multi-robot motion planning, but in centralized
settings: [25] provides centralized attack-robust algorithms for
active information gathering, and [17] for target tracking. The
algorithms are based on the centralized algorithms proposed
in [26], [27]. Additional attack-robust algorithms are proposed
in [28], [29], which, however, are valid for only a limited
number of attacks. For a thorough literature review on attackrobust combinatorial algorithms, we refer the reader to [30].
Contributions. All in all, towards enabling attack-robust
planning in multi-robot scenarios requiring local communication among robots, we make the following contributions:
A. We present the algorithm Distributed Robust Maximization (DRM): DRM distributively partitions the problem among
cliques of robots, where all robots are within communication
2 Submodularity is a diminishing returns property [14], capturing the intuition that the more robots participate in a task, the less the gain (return) one
gets by adding an extra robot towards the task.

range. Then, naturally, the cliques optimize in parallel, using [17, Algorithm 1]. We prove (Section IV):
• System-wide attack-robustness: DRM is valid for any number α of worst-case attacks;
• Computational speed-up: DRM is faster up to a factor
1/K 2 than its centralized counterparts in [17], where K
is the number of cliques chosen by DRM. K depends on
the inter-robot communication range, denoted henceforth
by rc , which is given as input to DRM (and, as a result,
by changing rc one controls K).
• Near-to-centralized approximation performance: Even
though DRM is a distributed algorithm, and faster than
algorithm its centralized counterpart [17, Algorithm 1],
DRM achieves a near-to-centralized performance, having
a suboptimality bound equal to [17, Algorithm 1]’s.
B. We design an Improved Distributed Robust Maximization
(IDRM) algorithm to relax the conservativeness of DRM in
inferring the number of attacks against each cliques (Section V); specifically, DRM assumes that the number of attacks
against each clique is equal to α, the total number of attacks
against all robots. Instead, in IDRM, robots communicate
with their 3-hop neighbors in the communication network
of all robots to infer the number of attacks.3 IDRM has the
same approximation performance as DRM; and, in practice, it
maintains a comparable running time to DRM (Section V-B).
Notably, the proposed algorithms in this paper allow for the
communication graph to be disconnected.
Numerical evaluations. First, we present Gazebo and
MATLAB evaluations of DRM, in scenarios of active target
tracking with swarms of robots (Section VI-A). All simulation
results demonstrate DRM’s computational benefits: DRM runs
3 to 4 orders faster than its centralized counterpart in [17],
achieving running times 0.5msec to 1.5msec for 100 robots.
And, yet, DRM exhibits negligible deterioration in performance
(in terms of number of targets covered). Second, we compare
the performance of DRM and IDRM through Matlab simulations
(Section VI-B). We show that IDRM performs better than
DRM in practice (higher target coverage), while maintaining
a comparable running time.
Comparison with the preliminary results. Preliminary results were presented in [31], [32]. In this paper, we present for
the first time the algorithm Improved Distributed Robust Maximization (Section V). Moreover, the corresponding Matlab
simulations are new (Section VI-B). Also, we present a formal
analysis of DRM’s approximation performance (Appendix).
II. P ROBLEM F ORMULATION
We formalize the problem of distributed attack-robust submodular maximization for multi-robot planning. At each timestep, the problem asks for assigning actions to the robots, to
maximize an objective function despite attacks. For example,
in active target tracking with aerial robots (see Fig. 1).
The robots’ possible actions are their motion primitives; the
objective function is the number of covered targets; and the
attacks are field-of-view blocking attacks.
3 A robot’s 3-hop neighbors are its neighbors, its neighbors’ neighbors, and
its neighbors’ neighbors’ neighbors.

3

Fig. 2.
Robots choose trajectories from a set of motion primitives: at
each time step, each robot has a set of motion primitives to choose as its
trajectory (each covering different targets, depicted as dots). For example,
robot 1 has 3 motion primitives, {x11 , x21 , x31 }, and robot 2 has 4 motion
primitives, {x12 , x22 , x32 , x42 }, where x11 covers 2 targets, {t2 , t3 }, and x22
covers 4 targets, {t1 , t2 , t3 , t4 }. In combination, however, the two motion
primitives totally cover 4 targets, {t1 , t2 , t3 , t4 }.

We next introduce our framework in more detail:4
a) Robots: We consider a multi-robot team R. At a given
time-step, pi is robot i’s position in the environment (i ∈ R).
We define P , {p1 , . . . , p|R| }.
b) Communication graph: Each robot communicates
only with those robots within a prescribed communication
range. Without loss of generality, we assume all robots to have
the same communication range rc . That way, an (undirected)
communication graph G = {R, E} is induced, with nodes
the robots R, and edges E such that (i, j) ∈ E if and only
if kpi − pj k2 ≤ rc . The neighbors of robot i are all robots
within the range rc , and are denoted by Ni .
c) Action set: Each robot i has an available set of actions
to choose from; we denote it by Xi . The robot can choose at
most 1 action at each time, due to operational constraints; e.g.,
in motion planning, Xi denotes robot i’s motion primitives, and
the robot can choose only 1 motion primitive at a time to be its
trajectory. For example, in Fig. 2-(b) we have 2 robots, where
X1 = {x11 , x21 , x31 } (and robot 1 chooses x11 as its trajectory)
x42 } (and robot 2 chooses x22 as its
and X2 = {x12 , x22 , x32 ,S
trajectory). We let X , i∈R Xi . Also, S ⊆ X denotes a valid
assignment of actions to all robots. For instance, in Fig. 2-(b),
S = {x11 , x22 }.
d) Objective function: The quality of each S is quantified
by a non-decreasing and submodular function f : 2X → R.
For example, this is the case in active target tracking with
mobile robots, when f is the number of covered targets [16].
As shown in Fig. 2-(b), the number of targets covered by the
chosen actions, S = {x11 , x22 }, is f (S) = 4.
e) Attacks: At each time step, we assume the robots
encounter worst-case attacks. Each attack results in a single
robot removal (at least temporarily, i.e., for the current time
step). In this paper, we study the case where the maximum
number of attacks at each time step is known, per Problem 1
below; we denote the maximum number of attacks by α.
Problem 1 (Distributed attack-robust submodular maximization for multi-robot planning). At each time step, the robots, by
exchanging information only over the communication graph G,
Calligraphic fonts denote sets (e.g., A). 2A denotes A’s power
set, and |A| its cardinality. A \ B are the elements in A not in B.
4 Notations.

Algorithm 1: Distributed robust maximization (DRM).
Input: Robots’ available actions Xi , i ∈ R; monotone and
submodular f ; attack number α.
Output: Robots’ actions S.
1: Partition G to cliques C1 , . . . , CK by calling DCP(P, rc );
2: Sk ← ∅ for all k = {1, . . . , K};
3: for each clique Ck in parallel, do
4:
if α < |Ck | then
S
5:
Sk = central-robust( i∈Ck Xi , f, α);
6:
else
S
7:
Sk = central-robust( i∈Ck Xi , f, |Ck |);
SK
8: return S = k=1 Sk .

assign an action to each robot i ∈ R to maximize f against α
worst-case attacks/failures (each resulting in a robot removal):
max min f (S \ A)
S⊆X

A⊆S

(1)

s.t. |S ∩ Xi | = 1, for all i ∈ R, |A| ≤ α,
where A corresponds to the actions of the attacked robots.5
Problem 1 is equivalent to a two-stage perfect information
sequential game [33, Chapter 4] between the robots and an
attacker. Particularly, the robots first select S, and, then, the
attacker, after observing S, selects the worst-case A.
III. A D ISTRIBUTED A LGORITHM : DRM
We present Distributed Robust Maximization (DRM), a distributed algorithm for Problem 1 for the case where α is known
(Algorithm 1). DRM executes sequentially two main steps:
distributed clique partition (DRM’s line 1), and per clique
attack-robust optimization (DRM’s lines 2-8). During the first
step, the robots communicate with their neighbors to partition
G into cliques of maximal size (using Algorithm 2, named
DCP in DRM’s line 1).6 During the second step, each clique
computes an attack-robust action assignment (in parallel with
the rest), using the centralized algorithm in [17] —henceforth,
we refer to the algorithm in [17] as central-robust.
central-robust takes similar inputs to DRM: a set of
actions, a function, and a number of attacks.
We describe DRM’s two steps in more detail below; and
quantify its running time and performance in Section IV.
A. Distributed clique partition (Step-1 of DRM)
We present the first step of DRM, distributed clique partition, which is inspired by [34, Algorithm 2] (DRM’s line 1, that
calls DCP, whose pseudo-code is presented in Algorithm 2).
The problem distributed clique partition is inapproximable in
polynomial time, since finding even a single clique of a desired
size is inapproximable [35], even by centralized algorithms.
DCP requires three rounds of communications among neighboring robots to form separate cliques. In the first round,
each robot i communicates to find its neighbors (Algorithm 2,
5 The constraint in eq. (1) ensures that each robot chooses 1 action per time
step (e.g., 1 trajectory among a set of primitive trajectories.)
6 A clique is a set of robots that can all communicate with each other.

4

Fig. 3. DCP partitions a graph of 6 robots into 2 separate cliques. Particularly,
after clique computation, robots 1 ∼ 6 obtain cliques {1, 2, 3}, {1, 2, 3},
{3, 4, 5, 6}, {3, 4, 5, 6}, {3, 4, 5, 6}, and {3, 4, 5, 6}. Then in the third
communication round, robot 3 shares its cliques with its neighbors (i.e., tells
its neighbors {1, 2} that it joins clique {3, 4, 5, 6}), and robots 1 and 2 reset
their cliques as {1, 2} and {1, 2}.

line 3). In the second round, it shares its augmented neighbor
set Ni+ (containing its neighbors and itself) with its neighbors,
and receives its neighbors’ sets {Nj+ } (Algorithm 2, line 4).
Then robot i intersects its augmented neighbor set Ni+ with
each of its neighbors’ augmented neighbor sets Nj+ , and lets
the largest intersection as its clique (Algorithm 2, line 5).
The aforementioned clique computation of DCP differs from
[34, Algorithm 2] in that in [34, Algorithm 2] each robot i
computes its clique as the intersection of Ni+ and Nj+ where j
is the neighbor with the largest degree in Ni , whereas in DCP’s
line 5, each robot i computes its clique as the intersection
of Ni+ and Nj+ , where j instead is the neighbor with the
largest neighborhood overlap with i. That way, DCP is more
likely to obtain larger cliques for each robot. Also, the cliques
returned by [34, Algorithm 2] can overlap with each other.
In order to form separate cliques, DCP executes the third
round of communication to share the computed cliques among
neighbors (Algorithm 2, line 6). Specifically, each robot i tells
its neighbors which clique it will join. If the clique of some
neighboring robot j contains robot i but robot i chooses to join
a different clique (by Algorithm 2, line 5), its neighboring
robot j will update its clique by removing robot i from it.
In this way, each robot i will eventually belong to a single
clique, and thus non-overlapping cliques can be generated. An
illustrative example of DCP is shown in Fig. 3.
B. Per clique attack-robust optimization (Step-2 of DRM)
We now present DRM’s second step: per clique attackrobust optimization (DRM’s lines 2-8). Since the step calls
central-robust as subroutine, we recall here its steps
from [17]: central-robust takes as input S
the available
actions of a set of robots R0 ⊆ R (i.e., the i∈R0 Xi ), a
monotone submodular f , and a number of attacks α0 ≤ α, and
constructs an action assignment S 0 by following a two-step
process. First, it tries to approximate the anticipated worstcase attack to S 0 , and, to this end, builds a “bait” set as
part of S 0 . Particularly, the bait set is aimed to attract all
attacks at S 0 , and for this reason, it has cardinality α0 (the
same as the number of anticipated attacks). SIn more detail,
central-robust includes an action x ∈ i∈R0 Xi in the
bait set (at most 1 action per robot, per
S Problem 1) only if
f ({x}) ≥ f ({x0 }) for any other x0 ∈ i∈R0 Xi . That is, the

Algorithm 2: Distributed clique partition (DCP).
Input: Robots’ positions P; communication range rc .
Output: Clique partition of graph G.
1: Given P and rc , find communication graph G;
2: for each robot i do
3:
Find robot i’s neighbor set Ni within rc ; {1st round
communication}
4:
Share Ni+ := {i, Ni } with robot i’s neighbors, and
receives all Nj+ from its neighbors, j ∈ Ni ; {2nd
round communication}
5:
Intersects Ni+ with every Nj+ , and set the largest
intersection as robot i’s clique,
T i.e.,
C i = argmaxN + T N + |Ni+ Nj+ |, j ∈ Ni ;
i
j
6:
Share Ci with robot i’s neighbors; {3rd round
communication}
7: return Generated cliques.

bait set is composed of the “best” α0 single actions. In the
second step, central-robust a) assumes the robots in the
bait set are removed from R0 , and then b) greedily assigns
actions to the rest of the robots using the centralized greedy
in [18, Section 2] which ensures a near-optimal assignment
(at least 1/2 close to the optimal).
In this context, DRM’s second step is as follows: assuming
the clique partition step returns K cliques (DRM’s line 1), now
each clique in parallel with the others computes an attackrobust assignment for its robots using central-robust
(DRM’s lines 3-8). To this end, the cliques need to assess how
many of the α attacks each will incur. If there is no prior on the
attack generation mechanism, then we consider a worst-case
scenario where each clique incurs all the α attacks. Otherwise,
we consider there is a prior on the attack mechanism such
that each clique k infers it will incur αk ≤ α attacks. Without
loss of generality, in DRM’s pseudo-code in Algorithm 1 we
present the former scenario, where αk = α across all cliques;
notwithstanding, our theoretical resultsP
on DRM’s performance
K
(Section IV) hold for any αk such that k=1 αk ≥ α. Overall,
DRM’s lines 3-8 are as follows (cf. example in Fig. 4):
a) DRM’s lines 4-5 (α < |Ck |): If α is less than the
clique’s size (DRM’s line 4), then the clique’s robots choose
actions by executing central-robust on the clique assuming α attacks (DRM’s line 5).
b) DRM’s lines 6-7 (α ≥ |Ck |): But if α is larger than
the clique’s size (DRM’s line 6), then the clique’s robots
choose actions by executing central-robust on the clique
assuming |Ck | attacks (DRM’s line 5); i.e., assuming that all
clique’s robots will be attacked.
c) DRM’s line 9: All in all, now all robots have assigned
actions, and S is the union of all assigned actions across all
cliques (notably, the robots of each clique k know only Sk ,
where Sk is per the notation in DRM).
Finally, DRM is valid for any number of attacks.
IV. P ERFORMANCE A NALYSIS OF DRM

5

(a) A communication graph G of 15 robots

(b) DCP partitions G into 5 cliques

(c) Each clique runs central-robust

Fig. 4. Qualitative description of DRM’s steps over the communication graph G in subfigure (a), composed of 15 robots. The number of anticipated attacks
is considered to be α = 2. In the first step, we assume DCP (DRM’s line 1) partitions G into 5 cliques, as shown in subfigure (b). In the second step, all 5
cliques perform central-robust in parallel. Particularly, the cliques {(1, 2), (8)}, since α is larger than or equal to their size, consider that all of their
robots will be attacked, and as a result they select all of their robots as baits (depicted with red in subfigure (c)), per central-robust. In contrast, the
remaining 3 cliques, since α is smaller than their size, they select α of their robots as baits. The remaining robots (depicted with blue in subfigure (c)) of
each clique choose their actions greedily, independently of the other cliques, and assuming that the red robots in their clique do not exist.

We now quantify DRM’s performance, by bounding its
computational and approximation performance. To this end,
we use the following notion of curvature for set functions.
A. Curvature
Definition 1 (Curvature [36]). Consider non-decreasing submodular f : 2X 7→ R such that f (x) 6= 0, for any x ∈ X \ {∅}
(without loss of generality). Also, denote by I the collection
of admissible sets where f can be evaluated at. Then, f ’s
curvature is defined as
νf , 1 − min min
S∈I x∈S

f (S) − f (S \ {x})
.
f (x)

(2)

The curvature, νf , measures how far f is from being
additive. Particularly, Definition
1 implies 0 ≤ νf ≤ 1, and
P
if νf = 0, then f (S) = x∈S f ({x}) for all S ∈ I (f is
additive). On the other hand, if νf = 1, then there exist S ∈ I
and x ∈ X such that f (S) = f (S \{x}) (x has no contribution
in the presence of S \ {x}).
For example, in active target tracking, f is the expected
number of covered targets (as a function of the robot trajectories). Then, f has curvature 0 if each robot covers different
targets from the rest of the robots. In contrast, it has curvature
1 if, e.g., two robots cover the exact same targets.
B. Running time and approximation performance
We present DRM’s running time and suboptimality bounds.
To this end, we use the notation:
• M is the set of robots composing G’s largest clique;
• XM is the set of possible actions of all robots in M; that
is, XM , ∪i∈M Xi ;
?
• f is the optimal value of Problem 1;
?
• A (S) is a worst-case removal from S (a removal from
S corresponds to a set of robot/sensor attacks); that is,
A? (S) ∈ arg minA⊆S,|A|≤α f (S \ A).
Theorem 1 (Computational performance).
O(|R|) + O(|XM |2 ) time.

DRM runs in

O(|R|) corresponds to DRM’s clique partition step (DRM’s
line 1), and O(|XM |2 ) corresponds to DRM’s attack-robust

step (DRM’s lines 2-8). Typically, O(|R|) is smaller than
O(|XM |2 ), since the latter grows quadratically fast. Henceforth ignore the former’s contribution in the running time.
In contrast, the centralized [17, Algorithm 1] runs in
O(|X |2 ) time. Thus, when XM ⊂ X (which happens when
G is partitioned into at least 2 cliques), DRM offers a computational speed-up. The reasons are two: parallelization of
action assignment, and smaller clique size. Particularly, DRM
splits the action assignment among multiple cliques, instead
of performing the assignment in a centralized way, where
all robots form one large clique (the R). That way, DRM
enables each clique to work in parallel, reducing the overall
running time to that of the largest clique M (Theorem 1).
Besides parallelization, the smaller clique size also contributes
to the computational reduction. To illustrate this, assume G is
partitioned to K cliques of equal size, and all robots have
the same number of actions (|Xi | = |Xj | for all i, j ∈ R).
Then, O(|XM |2 ) = O(|X |2 )/K 2 , that is, DRM’s running time
is reduced by the factor K 2 .
Theorem 2 (Approximation performance of DRM).
returns a feasible action-set S such that
f (S \ A? (S))
1 − νf
≥
.
f?
2

DRM

(3)

From eq. (3), we conclude that even though DRM is a
distributed, faster algorithm than its centralized counterpart,
it still achieves a near-to-centralized performance. Generally,
Theorem 2 implies DRM guarantees a close-to-optimal value
for any submodular f with curvature νf < 1.
Remark 1. A myopic algorithm that selects actions for
each robot independently of all other robots (in contrast to
DRM, whose subroutine central-robust accounts for the
other robots’ actions during the greedy action assignment),
guarantees the approximation bound 1 − νf (Algorithm 4 in
Appendix C). However, being exclusively myopic, Algorithm 4
has worse practical performance than DRM.
In Appendix-C, we also show Algorithm 4 is equivalent to
central-robust (cf. Section III-B) when applied to R,
under the assumption that all robots in R are attacked. This
further reveals the practical inefficiency of Algorithm 4.

6

V. I MPROVED D ISTRIBUTED ROBUST M AXIMIZATION
In DRM, each clique Ck assumes that the number of attacks
αk against the clique is either equal to the total number of
attacks α, or equal to its size |Ck | (when α ≥ |Ck |). Even
though this strategy guarantees a close-to-optimal approximation performance (cf. Section IV), it is conservative,
since the
P
total number of attacks that all cliques infer ( k αk ) can be
much larger than the real number of attacks α for the team. In
this section, we design a strategy to amend this conservativeness. Particularly, we present an Improved Distributed Robust
Maximization algorithm (IDRM), and analyze its performance
in terms of approximation performance and running time.
A. Improved inference of each clique’s attack number
The number of attacks in each clique αk can be inferred by
leveraging neighboring communications. First, note that robots
can communicate with all their neighbors within communication range even though these neighbors are in different cliques.
For example, in Fig. 4, robot 2 can still communicate with
robots 4 and 8 even though they are partitioned into different
cliques. However, in DRM, this available communication is
ignored. Second, besides the 3-hop communications required
for the execution of distributed clique partition (DCP; cf. Algorithm 2), the robots can also share their action sets with their
3-hop neighbors. Evidently, while DRM assumes robots to share
action sets with their 1-hop neighbors within the same clique,
sharing the action sets among 3-hop neighbors can give a better
inference of αk , and, consequently, better performance.
Recall that DRM sets αk equal to α (or to |Ck |, when
α ≥ |Ck |) for each clique Ck . Therefore, DRM selects a bait
set of αk robots in each clique (cf. Section III-B). Evidently,
some of these “bait” robots may not be among the α “bait”
robots that central-robust would have selected if it
would have been applied directly to R (assuming centralized
communication among all robots).7 This can be checked by
communicating action sets among 3-hop neighbors. Particularly, if some robot is not one of the top α robots among its
3-hop neighbors, it is impossible that it is in the top α robots
among the entire team. Thus, this robot can be marked as
“unselected” and αk can be reduced. Based on this rule, we
describe our αk inferring strategy in detail in Algorithm 3.
We use Fig. 4 to illustrate how Algorithm 3 works with an
example. When α = 2, clique C1 := {1, 2} first infers α̂1 = 2,
and robots 1 and 2 are selected. Then, robot 1 communicates
with its 1-hop, 2-hop, and 3-hop neighbors ({2}, {4, 8}, {3,
5, 6, 7, 9, 10, 11, 12}). If robot 1 is not one of the top 2
robots among its 3-hop neighbors, robot 1 will be marked as
“unselected” and α̂1 will be reduced by 1 (α̂1 = 1). Similarly,
if robot 2 is not one of the top 2 robots among its 3-hop
neighbors, α̂1 will be further reduced by 1 (α̂1 = 0). This
way, instead of picking out 6 robots from 3 cliques (Fig. 4c), only 2 robots {4, 14} will be selected. All in all, by
using Algorithm 3, we can reduce DRM’s conservativeness in
inferring the number of attacks in each clique.
7 We refer to any robot in the selected bait set of a clique k as a top α
k
robot in the clique; similarly, when we consider the set of all robots R, the
top α robots are the robots in the bait set selected by a central-robust
applied to R (when the number of attacks against R is α).

Algorithm 3: Algorithm to approximate the number of
attacks αk against a clique k, given a known number
of attacks α against all robots in R.
Input: Robots’ available actions Xi , i ∈ R; monotone and
submodular f ; attack number α.
Output: Number of attacks α̂k for clique Ck ,
k ∈ {1, . . . , K}.
1: if |Ck | > α then
2:
α̂k = α;
3: else
4:
α̂k = |Ck |;
α̂
5: Each clique selects the top α̂k robots as Ck k ;
α̂k
6: for each robot i ∈ Ck do
7:
if robot i is not one of the top α robots in its 3-hop
neighbors then
8:
α̂k = α̂k − 1;
9: return α̂k .

B. Performance analysis of IDRM
The robots of each clique k, using the number of attacks
α̂k generated by Algorithm 3, choose actions Sk by executing
central-robust [17], that is,
[
Sk = central-robust(
Xi , f, α̂k ).
i∈Ck

Approximation performance of IDRM. IDRM has the same
approximation bound as that of DRM (cf. eq. 3). Notwithstanding, as we demonstrate in our numerical evaluations (cf. Section VI-B), IDRM performs better than DRM in practice, since
IDRM utilizes more information (action sets shared among all
3-hop neighbors). Notably, however, when the communication
graph G only has non-overlapping cliques (i.e., the robots of
each clique can communicate only with their neighbors within
the clique), IDRM and DRM will exhibit the same performance.
Computational performance of IDRM. IDRM runs in more
time than DRM, since each robot needs to verify if it belongs to
the top α robots among its 3-hop neighbors instead of its 1-hop
neighbors within its clique as in DRM. But this verification only
takes linear time. Thus, the running time of IDRM is similarly
dominated by the central-robust operating in all cliques
as in DRM. Also, each robot only needs to share with its 3hop neighbors the function value (e.g., the number of targets
covered) of its best action instead of that of each action. Thus,
IDRM keeps the computational advantage of DRM.
VI. N UMERICAL E VALUATIONS
We first present DRM’s Gazebo and MATLAB evaluations
in scenarios of active target tracking with swarms of robots.
Then we illustrate the advantages of IDRM by comparing it
to DRM. The implementations’ code is available online.8 We
run the code on a ThinkPad laptop with Intel Core i7 CPU @
2.6 GHz × 8 and 62.8 GB Memory by using Matlab 2018b
and ROS Kinetic installed on Ubuntu 16.04. Due to the limited
computer resources, we approximate the running time of these
8 https://github.com/raaslab/distributed

resilient target tracking.git

7

(a) Gazebo environment

(b) Rviz environment

Fig. 5. Gazebo simulation setup: 10 aerial robots and 50 ground mobile
targets: (a) Gazebo environment; and (b) Rviz environment. Each robot is
color-coded, along with its coverage region. All robots in the same clique
have the same color. The targets are depicted as white cylindrical markers.

distributed algorithms by the total running time divided by the
number of cliques, since all the cliques perform in parallel.

that trajectory. Thus, each trajectory has a rectangular tracking
region with length lt = lf + lo and width lo . We set the
tracking length lt = 6, and tracking width lo = 3 for all
robots. We assume robots obtain noisy position measurements
of the targets, and then use a Kalman filter to estimate the
target’s position. We consider f to be the expected number of
targets covered, given all robots chosen trajectories.
For each of the compared algorithms, at each round, each
robot picks one of its 4 trajectories. Then, the robot flies a
lf = 3 meters along the selected trajectory.
When an attack happens, we assume the attacked robot’s
tracking sensor (e.g., camera) to be turned-off; nevertheless,
we assume it can be active again at the next round. The attack
is a worst-case attack, per Problem 1’s framework. Particularly,
we compute the attack via a brute-force algorithm, which is
viable for small-scale scenarios (as this one).
We repeat for 50 rounds. A video is available online.9
Results. The results are reported in Fig. 6. We observe:

0.05

A. Robust multi-robot target tracking

26

Number of targets tracked

0.04
0.035

Running time

Compared algorithms. We compare DRM with two algorithms. First, the centralized counterpart of DRM in [17],
named central-robust (its near-optimal performance has
been extensively demonstrated in [17]). The second algorithm is the centralized greedy algorithm in [18], named
central-greedy. The difference between the two algorithms is that the former is attack-robust, whereas the latter
is attack-agnostic. For this reason, in [17] we demonstrated,
unsurprisingly, that central-greedy has inferior performance to central-robust in the presence of attacks.
However, we still include central-greedy in the comparison, to highlight the differences among the algorithms both
in running time and performance.
1) Gazebo evaluation over multiple steps with mobile targets: We use Gazebo simulations to evaluate DRM’s performance across multiple rounds (time-steps). That way, we take
into account the kinematics and dynamics of the robots, as
well as, the fact that the actual trajectories of the targets,
along with the sensing noise, may force the robots to track
fewer targets than expected. The motion model for the moving
targets is known to the robots but it is corrupted with Gaussian
noise. Therefore, the robots use a Kalman Filter to estimate the
positions of the targets at each step. Due to the running efficacy
of Gazebo (which is independent of DRM), we focus on smallscale scenarios of 10 robots. In the MATLAB simulation, we
focus instead on larger-scale scenarios of 100 robots.
Simulation setup. We consider 10 aerial robots that are
tasked to track 50 ground mobile targets (Fig. 5-(a)). We set the
number of attacks α equal to 4, and the robots’ communication
range to be rc = 5 meters. We also visualize the robots,
their field-of-view, their cliques, and the targets using the Rviz
environment (Fig. 5-(b)). Each robot i has 4 candidates trajectories, Xi = {forward, backward, left, right},
and flies on a different fixed plane (to avoid collision with
other robots). Each robot has a square filed-of-view lo × lo .
Once a robot picks a trajectory, it flies a distance lf along

28

0.045

0.03
0.025
0.02
0.015
0.01

24
22
20
18
16
14

0.005
12
0
Centralized greedy Centralized robust Distributed robust

(a) Running time

Centralized greedy Centralized robust Distributed robust

(b) Number of targets tracked

Fig. 6.
Gazebo evaluation (averaged across 50 rounds): The tracking
performance is captured by the number of covered targets per round.

a) Superior running time: DRM runs considerably faster than
both central-robust and central-greedy: 3 orders
faster than the former, and 4 than the latter, with average
running time 0.1msec (Fig. 6-(a)).
b) Near-to-centralized tracking performance: Despite that
DRM runs considerably faster, it maintains near-to-centralized
performance: DRM covers on average 20 targets per round,
while central-robust covers 20.2 (Fig. 6-(b)). As expected, the attack-agnostic central-greedy performs
worse than all algorithms, even being centralized.
2) MATLAB evaluation over one step with static targets:
We use MATLAB simulations to evaluate DRM’s performance
in large-scale scenarios. Specifically, we evaluate DRM’s running time and performance for various numbers of robots
(from 10 to 100) and communication ranges (resulting from
as few as 5 cliques to as many as 30 cliques). We compare
all algorithms over a single execution round.
Simulation setup. We consider N mobile robots, and 100
targets. We vary N from 10 to 100. For each N , we set the
number of attacks equal to bN/4c, bN/2c and b3N/4c.
Similarly to the Gazebo simulations, each robot moves on
a fixed plane, and has four possible trajectories: forward,
9 https://youtu.be/aDFDHO8b0y4

8

100

100

200

90

90

180

80

80

160

70

70

140

60

60

120

50

50

100

40

40

80

30

30

60

20

20

40

10

10

0

20
0

0
0

10

20

30

40

50

60

70

80

90

(a) 10 robots with rc = 120
Fig. 7.

100

0

10

20

30

40

50

60

70

80

90

100

(b) 15 robots with rc = 60

0

50

100

150

(c) 30 robots with rc = 90

200

(d) 100 robots with rc = 50

MATLAB evaluation: Examples of clique formulations (Algorithm 2) across various numbers of robots and communication ranges rc .

backward, left and right. We set lt = 10 and lo = 3 for all
robots. We randomly generate the positions of the robots and
targets in a 2D space of size [0, 200]×[0, 200]. Particularly, we
generate 30 Monte Carlo runs (for each N ). We assume that
the robots have available estimates of targets’ positions. For
each Monte Carlo run, all compared algorithms are executed
with the same initialization (same positions of robots and
targets). DRM is tested across four communication ranges:
rc = 30, 50, 70, 90. For a visualization of rc ’s effect on the
formed cliques, see Fig. 7, where we present two of the
generated scenarios. All algorithms are executed for one round
in each Monte Carlo run.
Notably, since we consider large-scale scenarios (up to
N = 100 robots, and up to 75 attacks, when N = 100, and
α = b3N/4c), computing the worst-case attack via a bruteforce algorithm is now infeasible. Particularly, given a trajectory assignment S to all robots, the problem of computing a
worst-case attack is equivalent to minimizing a non-increasing
submodular function, an NP-hard problem [37]. Hence, we
consider the attacker to use a greedy heuristic to attack the
robots, instead of executing the worst-case attacks. Proposed
greedy approaches can be found in [37].10
Results. The results are reported in Fig. 8, where we make
the same qualitative conclusions as in the Gazebo evaluation:
a) Superior running time: DRM runs several orders faster
than both central-robust and central-greedy:
3 to 4 orders, achieving running time from 0.5msec
to 1.5msec (Figs. 8-(a-d)). Notably, we also observe
central-robust runs faster as α increases, which
is due to how central-robust works, that causes
central-robust to become faster as α tends to N [17]).
b) Near-to-centralized tracking performance: Although DRM
runs considerably faster, it retains a tracking performance
close to the centralized one (Figs. 8-(e-h)). Unsurprisingly, the
attack-agnostic greedy performs worse than all algorithms.
To summarize, in all simulations above, DRM offered significant computational speed-ups, and, yet, still achieved a
tracking performance that matched the performance of the
centralized, near-optimal algorithm in [17].
10 Alternative algorithms, along with approximate guarantees, to approximate the worst-case attacks can be found in [38]–[40].

B. Improved multi-robot target tracking
Compared algorithms. We compare IDRM with DRM. The
performance of the algorithms is evaluated through Matlab
simulations on active target tracking scenarios. We compare
the algorithms in terms of the total number of attacks inferred,
running time, and number of targets covered after α attacks.
α is known to both IDRM with DRM. The algorithms are
compared over a single execution for 30 trials.
Simulation setup. We consider N mobile robots, and 100
targets. We set N as 20 and 100 for small-scale and large-scale
evaluations, respectively. For evaluating the algorithms in the
large-scale case (e.g., N = 100), we approximate the worstcase attack by a greedy attack since computing the worst-case
attack requires exponential time. The total number of attacks
α is set as 6 when N = 20, and as 30 when N = 100. The
communication range rc is set as rc = 120 for N = 20, and
rc = 70 for N = 100. The remaining settings are the same as
in the Matlab simulation setup of Section VI-A.
Results. The results are reported in Fig. 9 and Fig. 10:
a) Conservativeness relaxing performance: Fig. 9-(a) and
Fig. 10-(a) show that IDRM relaxes the conservativeness of
inferring number of attacks α in both small-scale (N = 20,
α = 6) and large-scale (N = 100, α = 30) cases. Notably,
when the communication range is smaller (e.g., rc = 70
in Fig. 10-(a)), the inferred number of attacks by DRM is
much larger than the real number of attacks (α = 30). That
is because, with a smaller communication range, the graph
is likely to be partitioned into more and smaller cliques by
Algorithm 2, which increases the conservativeness of inferring
α in DRM. While IDRM gracefully relaxes this conservativeness
through 3-hop neighboring communications (Algorithm 3).
Particularly, in some trials of both small-scale and large-scale
evaluations, the number of attacks inferred by IDRM is very
close to the real number of attacks α.
b) Superior tracking performance: Because of the conservativeness relaxing, IDRM tracks more targets than DRM (Fig. 9(b) and Fig. 10-(b)) since it reduces the unnecessary coverage
overlaps induced by conservative estimate of α.
c) Comparative running time: Fig. 9-(c) and Fig. 10-(c)
show that both DRM and IDRM run very fast (e.g., averaged
running time is less than 0.005 seconds). That is because, in
IDRM, after robots share the number of targets covered by their

9

(a) α = bN/4c, rc = 30

(b) α = bN/2c, rc = 50

(c) α = bN/2c, rc = 70

(d) α = b3N/4c, rc = 90

(e) α = bN/4c, rc = 30

(f) α = bN/2c, rc = 50

(g) α = bN/2c, rc = 70

(h) α = b3N/4c, rc = 90

Fig. 8. MATLAB evaluations (averaged across 30 Monte Carlo runs): (a)-(d) depict running time results, for various α and rc values; and (e)-(h) depict
corresponding tracking performance results.

10-3

18

DRM
IDRM

7

30

14

12

10

8

28

6

26

5

Running time

Number of targets tracked

Number of attacks inferred

16

24
22
20

1

14

0

6
5

10

15

20

25

30

Trial ID

(a) Number of attacks inferred, α = 6

3
2

18
16

0

4

DRM

IDRM

(b) Number of targets covered

DRM

IDRM

(c) Running time

Fig. 9. MATLAB evaluations with N = 20, α = 6, and rc = 120: comparison of number of attacks inferred, number of targets covered, and running time
for DRM and IDRM in small-scale case. The number of target tracked of these two algorithms are calculated after applying 6 worst-case attacks.

best actions and infer a less conservative αk (Algorithm 3),
all cliques run central-robust in parallel as well.
VII. C ONCLUSION
We worked towards securing swarm-robotics applications
against worst-case attacks resulting in robot withdrawals. Particularly, we proposed DRM, a distributed robust submodular
optimization algorithm. DRM is general-purpose: it applies to
any Problem 1’s instance. We proved DRM runs faster than its
centralized counterpart, without compromising approximation

performance. We demonstrated both its running time and nearoptimality in Gazebo and MATLAB simulations of active
target tracking. However, in DRM, each clique assumes the
number of attacks αk to be the total number of attacks α,
which can be too conservative if the robots are partitioned into
many small-size cliques. To relax this conservativeness, we
leveraged the 3-hop neighboring communications to present
an improved version of DRM, called IDRM. We showed that
IDRM improves the target-tracking performance of DRM with
comparative running time.
A future direction is to secure the team performance when

10

10-3

100

70

12

80

DRM
IDRM
70

60

50

10
65

Running time

Number of targets tracked

Number of attacks inferred

90

60

8
6
4

55

2

40

50
0

30
0

5

10

15

20

25

30

Trial ID

(a) Number of attacks inferred, α = 30

DRM

IDRM

DRM

(b) Number of targets covered

IDRM

(c) Running time

Fig. 10. MATLAB evaluations with N = 100, α = 30, and rc = 70: comparison of number of attacks inferred, number of targets covered, and running
time for DRM and IDRM in large-scale case. The number of target tracked of these two algorithms are calculated after applying 30 greedy attacks.

the number of worst-case attacks is unknown or partially
known. A second future avenue is to investigate other attack
or failure models, e.g., random failures [41], [42], and design
corresponding distributed robust algorithms.
ACKNOWLEDGMENTS
We thank Micah Corah from the Carnegie Mellon University for pointing out that the myopic Algorithm 4, stated
in Appendix C, achieves the performance bound 1 − νf
(Theorem 3 in Appendix C). The observation led to Remark 1.
A PPENDIX

Sk = Skb ∪ Skg . If α ≥ |Ck |, then Skg = ∅. Henceforth, we let
S be the action assignment given by DRM to all robots in R.
Also, we let W be remaining robots after the attack A? (S);
i.e., W , R \ R(A? (S)). Further, we let Wk , W ∩ Ck ,
Wkb , Wk ∩ R(Skb ), and Wkg , Wk ∩ R(Skg ). Finally, we let
0
Wkb denote the remaining robots in Wkb after removing from
it any subset of robots with cardinality |R(Skg ) \ Wkg |.
Now the proof follows from the steps:

f (S(r))

(4)

r∈W

A. Proof of Theorem 1
Proof: DRM’s running time is equal to DCP’s plus the
time for all cliques to execute central-robust in parallel.
Particularly, in DCP, each robot first finds its maximal clique
using PerVrtx-MaxClique, which runs in O(|R|). Then,
it shares its maximal clique with its neighbors for graph
partition, which also takes O(|R|) time. Thus, DCP runs in
O(|R|). Next, since all cliques perform in parallel, the running
time depends on the largest clique, which gives a O(|XM |2 )
time. In total, Algorithm 1 runs in O(|R|) + O(|XM |2 ) time.

X

f (S \ A? (S)) ≥ (1 − νf )
= (1 − νf )

K X
X

f (S(r))

(5)

k=1 r∈Wk

= (1 − νf )

K
X


X

K
X

f (S(r))

(6)

r∈Wkg

r∈Wkb


X

f (S(r))+


k=1

X

f (S(r)) +


k=1

≥ (1 − νf )



0

r∈Wkb


X

Proof: We prove Theorem 2, i.e., DRM’s approximation
bound, by following the steps of [27, Proof of Theorem 1].
We introduce the notation: S ? denotes an optimal solution
to Problem 1. Given an action assignment S to all robots in
R, and a subset of robots R0 , we denote by S(R0 ) the actions
of the robots in R0 (i.e., the restriction of S 0 to R0 ). And
vise versa: given an action assignment S 0 to a subset R0 of
robots, we let R(S) denote this subset (i.e., R(S 0 ) = R0 ).
Additionally, we let Sk , S(Ck ); that is, Sk is the restriction of
S to the clique CSk selected by DRM’s line 1 (k ∈ {1, . . . , K});
K
evidently, S = k=1 Sk . Moreover, we let Skb correspond to
bait actions chosen by central-robust in Ck , and Skg
denote the actions for the remaining robots in Ck ; that is,

f (S(r)) +

r∈R(Skg )\Wkg

B. Proof of Theorem 2

= (1 − νf )

K
X

≥ (1 − νf )

K
X

≥ (1 − νf )

K
X

1 − νf
2

K
X
k=1

(7)


X

f (S(r)) +

X

f (S(r))

(8)

r∈R(Skg )

0
r∈Wkb




X

f (S(r)) + f (Skg )

(9)

0
r∈Wkb





1
f (S ? (r)) + f (S ? (R(Skg ))) (10)
2
b0

X


k=1

≥




k=1

f (S(r))

r∈Wkg


k=1

X

r∈Wk

f (S ? (Wk ))

(11)

11

C. Myopic optimization yields tighter approximation performance, yet worse practical performance
The myopic Algorithm 4, according to which each robot
selects its best action independently, guarantees a tighter
approximation bound than that of DRM:

However, Algorithm 4 performs in practice worse than DRM
because: (i) it chooses actions for each robot independently
of the actions of the rest of the robots (instead, DRM takes
into account other robots’ actions to intentionally reduce the
performance redundancy among these robots); and (ii) it is
equivalent to central-robust but under the assumption
the number of attacks is equal to the number of robots, which
is, evidently, conservative; DRM instead is less conservative
assuming at most α attacks per clique).
An evaluation of the practical performance of Algorithm 4
in comparison to DRM’s is made in Fig. 11. The figures
clearly show that in both small-scale and large-scale cases,
DRM outperforms Algorithm 4.

36

95

Number of targets tracked

1 − νf
f (S ? (W))
(12)
2
1 − νf
≥
f (S ? \ A? (S ? )).
(13)
2
Ineq. (4) follows from the definition of νf (see [27, Proof
of Theorem 1]). Eqs. (5) and (6) follow from the notation we
introduced above. Ineq. (7) is implied by the fact that any
action in S(Wkb ) is a bait. Eq. (8) holds from the notation.
Ineq. (9) holds by the submodularity of f , which implies
f (A) + f (B) ≥ f (A ∪ B) for any sets A, B [14]. Ineq. (10)
holds since a) with respect to the left term in the sum, the
robots in the sum correspond to robots whose actions are
baits; and b) with respect to the right term in the sum, the
greedy algorithm that has assigned the actions Skg guarantees
at least 1/2 the optimal [18]. Ineq. (11) holds again due to
the submodularity of f , as above. The same for ineq. (12).
Ineq. (13) follows from [27, Proof of Theorem 1] because of
the worst-case removal.
≥

the best action for each robot (Algorithm 4, line 3). Ineq. (17)
holds due to the submodularity of f . Ineq. 18 follows from
[27, Proof of Theorem 1] because of the worst-case removal.

Number of targets tracked

Algorithm 4: Myopic algorithm for Problem 1.
Input: Robots’ available actions Xi , i ∈ R; monotone and
submodular f .
Output: Robots’ actions S.
1: S ← ∅;
2: for i ∈ R do
3:
s ← argmaxs∈Xi f (s);
4:
S ← S ∪ {s};
5: return S.

34
32
30
28
26
24

90

85

80

75

22
MO

DRM

IDRM

(a) N = 20

MO

DRM

IDRM

(b) N = 100

Fig. 11. MATLAB evaluations: comparison of number of targets covered
by Algorthm 4 (called MO), DRM, IDRM in (a) small-scale and (b) largescale cases. The simulation settings follow the Matlab simulation setup of
Section VI-A. In (a) small-scale case with N = 20, α = 4, and rc = 120,
the number of target tracked by these three algorithms are calculated after
applying 4 worst-case attacks. In (b) large-scale case with N = 100, α = 10,
and rc = 70, the number of target tracked by these three algorithms are
calculated after applying 10 greedy attacks.

Theorem 3 (Approximation performance of Algorithm 4).
Algorithm 4 returns a feasible action-set S such that
f (S \ A? (S))
≥ 1 − νf .
f?

(14)

Proof: We split S generated by Algorithm 4 into S1
and S2 , with S1 denoting the action set selected by the top
α robots, and S2 denoting the action set selected by the
remaining |R|−α robots. Denote S2? as the action set selected
by R(S2 ) to maximize f (A), A ∈ I, A ⊆ X (R(S2 )).
f (S \ A? (S)) ≥ (1 − νf )

X

f (s)

(15)

s∈S2

≥ (1 − νf )
≥ (1 −
≥ (1 −

X

f (s? )

s∈S2?
νf )f (S2? )
νf )f (S ? \

(16)
(17)

?

?

A (S )).

(18)

Ineq. (15) follows from the definition of νf (see [27, Proof
of Theorem 1]). Ineq. (16) holds since Algorithm 4 selects

R EFERENCES
[1] C. Nieto-Granda, J. G. Rogers III, and H. Christensen, “Multi-robot
exploration strategies for tactical tasks in urban environments,” in
Unmanned Systems Technology XV, vol. 8741, 2013, p. 87410B.
[2] V. Kumar and N. Michael, “Opportunities and challenges with autonomous micro aerial vehicles,” in Robot. Research, 2017, pp. 41–58.
[3] M. Michini, M. A. Hsieh, E. Forgoston, and I. B. Schwartz, “Robotic
tracking of coherent structures in flows,” IEEE Transactions on Robotics,
vol. 30, no. 3, pp. 593–603, 2014.
[4] S. Karaman and E. Frazzoli, “High-speed flight in an ergodic forest,” in
IEEE Intern. Confer. on Robotics and Automation, 2012, pp. 2899–2906.
[5] C. Cadena, L. Carlone, H. Carrillo, Y. Latif, D. Scaramuzza, J. Neira,
I. Reid, and J. J. Leonard, “Past, present, and future of simultaneous
localization and mapping: Toward the robust-perception age,” IEEE
Transactions on Robotics, vol. 32, no. 6, pp. 1309–1332, 2016.
[6] T. Cieslewski, E. Kaufmann, and D. Scaramuzza, “Rapid exploration
with multi-rotors: A frontier selection method for high speed flight,” in
IEEE/RSJ Int. Conf. on Intel. Robots and Systems, 2017, pp. 2135–2142.
[7] M. Santos, Y. Diaz-Mercado, and M. Egerstedt, “Coverage control
for multirobot teams with heterogeneous sensing capabilities,” IEEE
Robotics and Automation Letters, vol. 3, no. 2, pp. 919–925, 2018.
[8] N. Atanasov, J. Le Ny, K. Daniilidis, and G. J. Pappas, “Decentralized
active information acquisition: Theory and application to multi-robot
slam,” in 2015 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2015, pp. 4775–4782.

12

[9] B. Schlotfeldt, D. Thakur, N. Atanasov, V. Kumar, and G. J. Pappas,
“Anytime planning for decentralized multirobot active information gathering,” IEEE Robotics and Automation Letters, vol. 3, no. 2, pp. 1025–
1032, 2018.
[10] R. Khodayi-mehr, Y. Kantaros, and M. M. Zavlanos, “Distributed
state estimation using intermittently connected robot networks,” IEEE
Transactions on Robotics, 2019.
[11] M. Corah and N. Michael, “Distributed matroid-constrained submodular maximization for multi-robot exploration: Theory and practice,”
Autonomous Robots, vol. 43, no. 2, pp. 485–501, 2019.
[12] G. Best, O. M. Cliff, T. Patten, R. R. Mettu, and R. Fitch, “DecMCTS: Decentralized planning for multi-robot active perception,” The
International Journal of Robotics Research, vol. 38, no. 2-3, pp. 316–
337, 2019.
[13] P. Dames, P. Tokekar, and V. Kumar, “Detecting, localizing, and tracking
an unknown number of moving targets using a team of mobile robots,”
The International Journal of Robotics Research, vol. 36, no. 13-14, pp.
1540–1553, 2017.
[14] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher, “An analysis of approximations for maximizing submodular set functions–I,” Mathematical
programming, vol. 14, no. 1, pp. 265–294, 1978.
[15] U. Feige, “A threshold of ln n for approximating set cover,” Journal of
the ACM (JACM), vol. 45, no. 4, pp. 634–652, 1998.
[16] P. Tokekar, V. Isler, and A. Franchi, “Multi-target visual tracking with
aerial robots,” in IEEE/RSJ International Conference on Intelligent
Robots and Systems, 2014, pp. 3067–3072.
[17] L. Zhou, V. Tzoumas, G. J. Pappas, and P. Tokekar, “Resilient active
target tracking with multiple robots,” IEEE Robotics and Automation
Letters, vol. 4, no. 1, pp. 129–136, 2018.
[18] M. L. Fisher, G. L. Nemhauser, and L. A. Wolsey, “An analysis
of approximations for maximizing submodular set functions–II,” in
Polyhedral combinatorics, 1978, pp. 73–87.
[19] B. Gharesifard and S. L. Smith, “Distributed submodular maximization
with limited information,” IEEE Transactions on Control of Network
Systems, vol. 5, no. 4, pp. 1635–1645, 2018.
[20] D. Grimsman, M. S. Ali, J. P. Hespanha, and J. R. Marden, “The impact
of information in greedy submodular maximization,” IEEE Transactions
on Control of Network Systems, 2018.
[21] B. Mirzasoleiman, A. Karbasi, R. Sarkar, and A. Krause, “Distributed
submodular maximization: Identifying representative elements in massive data,” in Advances in Neural Information Processing Systems, 2013,
pp. 2049–2057.
[22] K. Saulnier, D. Saldana, A. Prorok, G. J. Pappas, and V. Kumar, “Resilient flocking for mobile robot teams,” IEEE Robotics and Automation
Letters, vol. 2, no. 2, pp. 1039–1046, 2017.
[23] D. Saldana, A. Prorok, S. Sundaram, M. F. Campos, and V. Kumar,
“Resilient consensus for time-varying networks of dynamic agents,” in
American Control Conference, 2017, pp. 252–258.
[24] A. Mitra, J. A. Richards, S. Bagchi, and S. Sundaram, “Resilient
distributed state estimation with mobile agents: Overcoming Byzantine
adversaries, communication losses, and intermittent measurements,”
Autonomous Robots, vol. 43, no. 3, pp. 743–768, 2019.
[25] B. Schlotfeldt, V. Tzoumas, D. Thakur, and G. J. Pappas, “Resilient
active information gathering with mobile robots,” in IEEE/RSJ International Conference on Intelligent Robots and Systems, 2018, pp. 4309–
4316.
[26] V. Tzoumas, K. Gatsis, A. Jadbabaie, and G. J. Pappas, “Resilient
monotone submodular function maximization,” in IEEE Conference on
Decision and Control, 2017, pp. 1362–1367.
[27] V. Tzoumas, A. Jadbabaie, and G. J. Pappas, “Resilient nonsubmodular maximization over matroid constraints,” arXiv preprint
arXiv:1804.01013, 2018.
[28] J. B. Orlin, A. S. Schulz, and R. Udwani, “Robust monotone submodular
function maximization,” Mathematical Programming, vol. 172, no. 1-2,
pp. 505–537, 2018.
[29] I. Bogunovic, S. Mitrović, J. Scarlett, and V. Cevher, “A distributed
algorithm for partitioned robust submodular maximization,” in IEEE
7th International Workshop on Computational Advances in Multi-Sensor
Adaptive Processing, 2017, pp. 1–5.
[30] V. Tzoumas, A. Jadbabaie, and G. J. Pappas, “Robust and adaptive
sequential submodular optimization,” arXiv preprint arXiv: 1909.11783,
2019.
[31] L. Zhou and P. Tokekar, “An approximation algorithm for distributed
resilient submodular maximization,” in 2019 International Symposium
on Multi-Robot and Multi-Agent Systems (MRS). IEEE, 2019, pp. 216–
218.

[32] L. Zhou, V. Tzoumas, G. J. Pappas, and P. Tokekar, “Distributed attackrobust submodular maximization for multi-robot planning,” in 2020
IEEE International Conference on Robotics and Automation (ICRA).
IEEE, 2020, to appear.
[33] R. B. Myerson, Game theory. Harvard university press, 2013.
[34] B. Pattabiraman, M. M. A. Patwary, A. H. Gebremedhin, W.-K. Liao,
and A. Choudhary, “Fast algorithms for the maximum clique problem on
massive sparse graphs,” in International Workshop on Algorithms and
Models for the Web-Graph, 2013, pp. 156–169.
[35] D. Zuckerman, “Linear degree extractors and the inapproximability of
max clique and chromatic number,” in ACM Symposium on Theory of
Computing, 2006, pp. 681–690.
[36] M. Conforti and G. Cornuéjols, “Submodular set functions, matroids and
the greedy algorithm: tight worst-case bounds and some generalizations
of the rado-edmonds theorem,” Discrete applied mathematics, vol. 7,
no. 3, pp. 251–274, 1984.
[37] R. Iyer, S. Jegelka, and J. Bilmes, “Fast semidifferential-based submodular function optimization,” in International Conference on Machine
Learning, 2013, pp. 855–863.
[38] D. M. Topkis, “Minimizing a submodular function on a lattice,” Operations research, vol. 26, no. 2, pp. 305–321, 1978.
[39] A. Schrijver, “A combinatorial algorithm minimizing submodular functions in strongly polynomial time,” Journal of Combinatorial Theory,
Series B, vol. 80, no. 2, pp. 346–355, 2000.
[40] S. Jegelka, H. Lin, and J. A. Bilmes, “On fast approximate submodular
minimization,” in Advances in Neural Information Processing Systems,
2011, pp. 460–468.
[41] H. Park and S. Hutchinson, “Robust rendezvous for multi-robot system
with random node failures: an optimization approach,” Autonomous
Robots, pp. 1–12, 2018.
[42] L. Zhou and P. Tokekar, “An approximation algorithm for risk-averse
submodular optimization,” in International Workshop on the Algorithmic
Foundations of Robotics. Springer, 2018, pp. 144–159.

Lifeng Zhou is a Postdoctoral Researcher in the
GRASP Lab at the University of Pennsylvania. He
received his Ph.D. degree in Electrical & Computer
Engineering at Virginia Tech. He obtained his master’s degree in Automation from Shanghai Jiao Tong
University, China in 2016, and his Bachelor’s degree
in Automation from Huazhong University of Science
and Technology, China in 2013.
His research interests include multi-robot coordination, approximation algorithms, combinatorial optimization, deep learning, model predictive control,
and resilient and risk-aware decision making.

13

Vasileios Tzoumas received his Ph.D. in Electrical
and Systems Engineering at the University of Pennsylvania (2018). He holds a Master of Arts in Statistics from the Wharton School of Business at the
University of Pennsylvania (2016); a Master of Science in Electrical Engineering from the University of
Pennsylvania (2016); and a diploma in Electrical and
Computer Engineering from the National Technical
University of Athens (2012). Vasileios starts as an
Assistant Professor in the Department of Aerospace
Engineering, University of Michigan, Ann Arbor, in
January 2021. Currently, he is a research scientist in the Department of Aeronautics and Astronautics, and the Laboratory for Information and Decision
Systems (LIDS), at the Massachusetts Institute of Technology (MIT), where
he previously was a post-doctoral associate for one year (2018-2019). In 2017,
he was a visiting Ph.D. student at the Institute for Data, Systems, and Society
(IDSS) at MIT. Vasileios works on control, learning, and perception, as well
as combinatorial and distributed optimization, with applications to robotics,
cyber-physical systems, and self-reconfigurable aerospace systems. He aims
for trustworthy collaborative autonomy. His work includes foundational results
on robust and adaptive combinatorial optimization, with applications to multirobot information gathering for resiliency against robot failures and adversarial
removals. Vasileios is a recipient of the Best Paper Award in Robot Vision at
the 2020 IEEE International Conference on Robotics and Automation (ICRA),
and was a Best Student Paper Award finalist at the 2017 IEEE Conference in
Decision and Control (CDC).

George J. Pappas (S’90-M’91-SM’04-F’09) received the Ph.D. degree in electrical engineering
and computer sciences from the University of California, Berkeley, CA, USA, in 1998. He is currently the Joseph Moore Professor and Chair of the
Department of Electrical and Systems Engineering,
University of Pennsylvania, Philadelphia, PA, USA.
He also holds a secondary appointment with the
Department of Computer and Information Sciences
and the Department of Mechanical Engineering and
Applied Mechanics. He is a Member of the GRASP
Lab and the PRECISE Center. He had previously served as the Deputy
Dean for Research with the School of Engineering and Applied Science. His
research interests include control theory and, in particular, hybrid systems,
embedded systems, cyberphysical systems, and hierarchical and distributed
control systems, with applications to unmanned aerial vehicles, distributed
robotics, green buildings, and biomolecular networks. Dr. Pappas has received
various awards, such as the Antonio Ruberti Young Researcher Prize, the
George S. Axelby Award, the Hugo Schuck Best Paper Award, the George
H. Heilmeier Award, the National Science Foundation PECASE award and
numerous best student papers awards.

Pratap Tokekar is an Assistant Professor in the
Department of Computer Science at the University
of Maryland. Previously, he was a Postdoctoral
Researcher at the GRASP lab of University of
Pennsylvania. Between 2015 and 2019, he was an
Assistant Professor at the Department of Electrical
and Computer Engineering at Virginia Tech. He
obtained his Ph.D. in Computer Science from the
University of Minnesota in 2014 and Bachelor of
Technology degree in Electronics and Telecommunication from College of Engineering Pune, India in
2008. He is a recipient of the NSF CISE Research Initiation Initiative award
and an Associate Editor for the IEEE Robotics and Automation Letters and
Transactions of Automation Science and Engineering.

