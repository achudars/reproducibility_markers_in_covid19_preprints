Collective marks and first passage times

arXiv:1908.04370v1 [math.PR] 12 Aug 2019

Yiping ZHANGa
Myron HLYNKAa
Percy H. BRILLa,b
Department of Mathematics and Statisticsa
School of Businessb
University of Windsor
Windsor, Ontario, Canada N9B 3P4
Abstract
Probability generating functions for first passage times of Markov
chains are found using the method of collective marks. A system of
equations is found which can be used to obtain moments of the first
passage times.

AMS Subject Classification: 60J05, 60J22
Keywords: Markov chains, first passage times, collective marks

1

Introduction

Suppose we have a Markov chain with n states labeled 1, 2, . . . , n.
Define the random variable Xij to be the number of steps needed to move
from state i to state j for the first time. We refer to Xij as the first passage
time. Define the first passage probability as fij (k) = P (Xij = k). There
are several ways to compute the first passage probabilities. For example, see
Hunter ([2]) and Kao ([3]). First passage probabilities are important as they
can be used to control processes and determine when to implement parameter
changes.
Suppose we have a probability mass function for a discrete random variable
X that takes on value k with probability pk for k =P
0, 1, . . . . Define the
∞
k
probability generating function for X to be ψX (z) =
k=0 pk z . Alfa ([1],
p. 76) gives an expression for the probability generating function of the first
passage probabilities from state i to state j as follows.
ψij (z) =
where Pij (z) =
(k)
values pij .

(k) k
k=1 pij z .

P∞

Pij (z)
1 − Pij (z)

But this is not a closed form since we need the

2

Yiping ZHANG, Myron HLYNKA, Percy H. BRILL

The method of collective marks was originated by van Dantzig ([6]), and
discussed in Runnenburg ([5]) and Kleinrock ([4], chapter 7). The method
gives
P
k
p
a probabilistic interpretation of a probability generating function ∞
k=0 k z .
Let z be the probability that an item is “marked.” Then pk z k represents the
probability that random variable X takes on the value k and each of the k
counts is marked. Summing over all k gives the total probability that all items
from a single realization of the random variable X are marked.
In this paper, we use the collective marks method to find the probability
generating function for first passage probabilities, in a closed form for a fixed
number of states n. We find expressions for moments of the first passage times.
We present a method to find probability generating functions of second passage
times.

2

Computing first passage probabilities

Theorem 2.1. Let ψij (z) be the probability generating function for the first
passage random variable from i to j for an n state Markov chain. Then we
obtain an equation,
X
pik zψkj (z)
ψij (z) = pij z +
k:k6=j

Proof. By the method of collective marks, ψij (z) represents the probability
that the path starting from i and reaching j for the first time has all of its steps
receiving a mark. Here the probability of a step being marked is assumed to be
z. The first step may enter state j immediately and this occurs with probability
pij . The probability that the singleton path is marked is z. So pij z is the
probability that the first passage probability consists of 1 step and is marked.
Otherwise, the process goes to some other state k with probability pik and that
step is marked with probability z. From the new position k, the process moves
to state j eventually with each step being marked with probability generating
function ψkj (z). Summing over all cases gives the result.
Note: The equation in our theorem involves the generating functions ψkj (z)
(for all k) and we can get a similar equation for each of these. For fixed j, this
will give us a linear system of equations in the variables ψ1j (z), . . . , ψnj (z),
which can be solved to get any particular first passage generating function
desired as a non linear function of z. The coefficients in the system of equations
may involve z as well as constants.
Theorem 2.2. Let ψ13 (z) be the probability generating function for the first
passage random variable from 1 to 3 for an 3 state Markov chain. Then
ψ13 (z) =

p13 z + (p12 p23 − p13 p22 )z 2
1 − (p11 + p22 )z + (p11 p22 − p12 p21 )z 2

First Passage and Collective Marks

3

Proof. From Theorem 2.1, we have
ψ13 (z) = p11 zψ13 (z) + p12 zψ23 (z) + p13 z
ψ23 (z) = p21 zψ13 (z) + p22 zψ23 (z) + p23 z
Solving this system of two equations in two unknowns gives our result.
Note:
(a) A similar result holds for any pair, not just (i, j).
(b) Our method manages to obtain a closed form for the probability generating
function of the first passage times for 3 state Markov chains
(c) Theorem 2.2 can be extended to a larger number number of states as we
still essentially get a linear system to solve.
(d) Although the system of equations is linear in the ψij (z) unknowns, the
coefficients involve the variable z, the the resulting expressions are nonlinear
functions of z.

3

Example



.2 .4 .4
Example 3.1. Consider the Markov transition matrix P = .3 .3 .4 We
.5 .4 .1
will compute first passage probability generating functions for ψ13 (z), ψ23 (z) ,
and ψ33 (z). For the first two we use theorem 2.2 (with appropriate changes for
ψ23 (z), and for the third, we get a separate equation.
According to Theorem 2.2, the probability generating function for the first
passage probabilities from state 1 to state 3 is given by
ψ13 (z) =

.4z + (.4 ∗ .4 − .4 ∗ .3)z 2
.4z + .04z 2
=
1 − (.2 + .3)z + (.2 ∗ .3 − .4 ∗ .3)z 2
1 − .5z − .06z 2

We use the Maple command
0.4 z+0.04 z 2
, z, 8)
series( 1−0.5
z−0.06 z 2
to find the Taylor expansion and get results.
ψ13 (z) = 0.4z+0.24z 2 +0.144z 3 +0.0864z 4 +0.05184z 5 +0.031104z 6 +0.0186624z 7+. . .
This result agrees with other methods.
In a similar manner, we find
ψ23 (z) =

.4z + (.3 ∗ .4 − .4 ∗ .2)z 2
.4z + .04z 2
=
1 − (.3 + .2)z + (.3 ∗ .2 − .3 ∗ .4)z 2
1 − .5z − .06z 2

4

Yiping ZHANG, Myron HLYNKA, Percy H. BRILL

Finally,
ψ33 (z) = p33 z + p31 zψ13 (z) + ψ32 zψ23 (z) = .1z + .5ψ13 (z) + .4ψ23 (z)
.1z + .31z 2 + .03z 3
.1z − .05z 2 − .006z 3 + .2z 2 + .02z 3 + .16z 2 + .016z 3
=
=
1 − .5z − .06z 2
1 − .5z − .06z 2

4

Moments of first passage times

Theorem 2.2 gives an expression for ψij (z) so we can find the moments of
the first passage probabilities by simply taking derivatives and evaluating the
expressions at z = 1, making any additional computations needed. But this
explicitly requires solving for ψij (z) which can be a somewhat burdensome task
as the coefficients of the linear system involve the variable z.
Theorem 2.1 gives an equation for ψij (z) involving the probability generating function of first passage times from i to j and since we have similar
expressions for ψkj (z) (for k 6= j), we have a system of equations that we can
work with. We can take the derivative of the SYSTEM of equations, and then
substitute z = 1 into the system to create a much more tractible system of
equations. Of course, ψij (1) = 1 and ψij′ (1) = µij where µij = E(Xij , where
Xij is the number of steps needed to reach state j from state i for the first
(2)
time. Also, ψij (1) = E(Xij (Xij − 1)).
Example 4.1. We use the same 3 × 3 transition matrix as in Example 3.1
The system of equations from Theorem 2.1 is
ψ13 (z) = .2zψ13 (z) + .4zψ23 (z) + .4z
ψ23 (z) = .3zψ13 (z) + .3zψ23 (z) + .4z
Taking derivatives gives
′
′
′
ψ13
(z) = .2ψ13 (z) + .2zψ13
(z) + .4ψ23 (z) + .4zψ23
(z) + .4
′
′
′
ψ23 (z) = .3ψ13 (z) + .3zψ13 (z) + .3ψ23 (z) + .3zψ23 (z) + .4

Evaluating at z = 1 gives
µ13 = .2 + .2µ13 + .4 + .4µ23 + .4 = 1 + .2µ13 + .4µ23
µ23 = .3 + .3µ13 + .3 + .3µ23 + .4 = 1 + .3µ13 + .3µ23

Solving these gives µ13 = 2.5 and µ23 = 2.5.

First Passage and Collective Marks

5

5

Second passage times

Theorem 5.1. Let Yij be the random variable representing the number of steps
needed to move from i to j for the second time. Then the probability generating
function for Yij is ψij (z)ψjj (z)
Proof. Yij = Xij + Xjj where Xij is the first passage random variable, so Yij
is just the convolution of two independent random variables. Since the pgf of
a convolution is the product of the pgf’s of each part, the result follows.
Example 5.1. We will compute the second passage time
 from state
 1 to state
.2 .4 .4
3 in the Markov chain with transition matrix P = .3 .3 .4 We earlier
.5 .4 .1
calculated
.1z + .31z 2 + .03z 3
.4z + .04z 2
and
ψ
(z)
=
so
ψ13 (z) =
33
1 − .5z − .06z 2
1 − .5z − .06z 2
(.4z + .04z 2 )(.1z + .31z 2 + .03z 3 )
ψsecond (z) =
. If we expand this (using MAPLE)
(1 − .5z − .06z 2 )2
into a Taylor series, we get
ψsecond (z) = 0.04z 2 + 0.168z 3 + 0.1872z 4 + 0.16416z 5 + . . .
Thus, for example, the probability of moving from 1 to 3 for the second time
on step 4 is 0.1872.
In a similar manner,we can obtain higher order passage probabilities.
Acknowledgments. We acknowledge funding and support from NSERC
(Natural Sciences and Engineering Reseach Council of Canada).

References
[1] A.S. Alfa. Applied Discrete-time Queues, second edition. Springer. 2014
[2] J.J. Hunter, Mathematical Techniques of Applied Probability Vol. 1. Academic Press. 1983
[3] E. Kao. An Introduction to Stochastic Processes. Duxbury Press. 1996
[4] L. Kleinrock. Queueing Systems, Volume 1. Chapter 7. Wiley. 1975
[5] J.T. Runnenburg. On the use of Collective Marks in Queueing Theory. In
W.L. Smith and W.E. Wilkinson, editors, Congestion Theory. pp. 399-438.
University of North Carloina Press. 1965.
[6] D. Van Dantzig. Sur methode des fonctions generatrices. Colloques internationaux du CNRS, 13: 29-45, 1949

