Towards Semantic Big Graph Analytics for CrossDomain Knowledge Discovery
Feichen Shen
School of Computing and Engineering,
University of Missouri- Kansas City

Abstract. In recent years, the size of big linked data has grown rapidly
and this number is still rising. Big linked data and knowledge bases
come from different domains such as life sciences, publications, media,
social web, and so on. However, with the rapid increasing of data, it is
very challenging for people to acquire a comprehensive collection of
cross domain knowledge to meet their needs. Under this circumstance,
it is extremely difficult for people without expertise to extract
knowledge from various domains. Therefore, nowadays human limited
knowledge can’t feed the high requirement for discovering large
amount of cross domain knowledge. In this research, we present a big
graph analytics framework aims at addressing this issue by providing
semantic methods to facilitate the management of big graph data from
close domains in order to discover cross domain knowledge in a more
accurate and efficient way.

1. Problem Statement
Today, the main challenge we are facing in knowledge discovery research is the big
data problem associated with large, complex, and dynamic variation of format. Increasingly, we are also seeing the emergence of cross domain among different datasets. In this drive, the large amounts of data have been specified and shared via machine-readable formats, such as a Resource Description Framework (RDF) [1] and
Ontology Web Language (OWL) [2].
However, with increasing research in big data, more and more datasets from different domains have been added to the existing linked open data (e.g., Bio2RDF [3]),
which makes the highly complex relationships and condensed interlinks among the
large number of these knowledge bases. To some extent, the speed of data growing in
terms of multiple domains is much faster than that of the large amount of knowledge
people can acquire and consume in their daily lives. In other words, since cross domain datasets are physically grouped instead of semantically clustered, it is extremely
difficult for people without expertise to extract knowledge from various domains
nowadays. Therefore, there is a big gap between human limited knowledge and the
large amount of cross domain knowledge that can be discovered from this huge
amount of data.
For example, in life science research, a researcher expertise on disease A wants to
find the corresponding ensemble genome G for the gene symbol and marker that re-

lated to disease A as well as the drug D for disease A. In this use case, A, G and D
represent three different domains, such as Disease Ontology [4], Gene Ontology [5],
and DrugBank [6]. More knowledge bases and ontology exist in the life science domain, including the Human Phenotype Ontology [7], the Mammalian Phenotype Ontology [8, 9], the Pharmacogenetics Knowledge Base (PharmGKB) [10], the Onine
Mendeian Inheritance in Man (OMIM) [11], the Database of Chromosomal Imbalance
and Phenotypc in Humans Using Ensembl Resources (DECIPHER) [12], the Orphanet [13] and so on. With tremendous heterogeneous knowledge graphs, it is very difficult for researchers who only know disease domain to make a query to discover
knowledge across different domains in a comprehensive way.
The problem we intended to address is to fill the gap between human limited
knowledge with the huge amount of cross-domain knowledge by providing semantic
methods to facilitate the partition and management of big cross-domain data in a more
accurate and efficient way. We assume that each output group of our approach contains knowledge sources that have most closeness relationship. We can design crossdomain query based on each group to dig the comprehensive relationship among
knowledge sources in it to fully discover cross-domain knowledge.

2. Relevancy
The problem is directly relevant to graph partition and graph analytics with an emphasis on semantic knowledge discovery [14-19] and graph based reasoning [20-22].
In graph partition, domain knowledge in RDF format can be partitioned not only
physically but also semantically. Fuzzy partition is proposed in this research, which
means that overlap of nodes is permitted since a same node can be reused for multiple
domains. In graph analytics, how to group different domain knowledge together is
based on graph measurement and analysis (e.g., distance, similarity). A semantic
based similarity measurement is proposed in this research and unsupervised clustering
approach is used to form different groups of close domain knowledge.

3. Related Work
In this section, we present previous work in graph schema partition and analytics.
3.1 Graph schema partition
SEDGE [23] provides a complementary partition approach to eliminate cross domain
edges to facitilty query performance. SEDGE also proposed an on-demand parititon
to handle unbalanced query workload. Unfortunately, the partition is mainly based on
physical relationships rather than semantic relationships.
Mizzan [24] made improvements based on Pregel [25] that is built on Bulk Synchronous Parallel (BSP) [26] programming model. Mizzan focuses on dynamically
efficient load balancing in terms of computation and communication among all worker nodes. It achieved load balancing by using fine-grained vertex migration in a distributed manner. However, Mizzan designed a vertex centric model, mainly focused
on the size balance load of the graph rather than the semantic data migration.

Goffish [27] is a distributed sub-graph centric approach using a connected component approach to make abstraction for a large scale graph in order to do efficient
graph analytics. This model combined the advantages of both a vertex centric approach and shared-memory algorithms. However, Goffish did not mention semantic
cross domain issues. In Similarity-Driven Semantic Role Induction via Graph Partitioning [28], authors proposed a vertex centric unsupervised method for semantic role
induction. But they did not mention cross domain issues. In this sense, our approach
provides a better solution to partition large graphs by grouping semantically related
content together in sub-graphs.
3.2 Graph Analytics
We	   categorize research in this area into two parts: query generation and query processing. For query generation, SP2Bench [29] proposed a query design system focusing on generating queries with combination of different operations. But this query
generation was not designed from a semantic perspective for cross domain. LUBM
[30] and BSBM [31] generated benchmarks on university and ecommerce respectively, but neither benchmark was based on more than one domain. FedBench [32] provided a benchmark suite for federated queries on semantic data which can cover semantic multiple domain data use cases. However, query benchmarks were manually
generated by authors. Our approach provides a way to automatically help people find
the semantic relationship without acquiring knowledge explicitly. MedTQ provided a
dynamic topic query generation approach over medical ontologies [33]. BmQGen [34,
35] supported query generation for a specific biomedical detecting task on postsurgical complications [36]. Zhu et al. investigated the usage of the PharmGKB knowledge
base for searching and inferring repositioning breast cancer drugs [37].
	  	  	  	  	  For query processing, H2RDF+ [38] provided a scalable distributed RDF store to
facilitate query processing performance. Trinity [39] presented a RDF management
framework over a distributed in-memory key-value store. There are still some other
indexing approaches for speeding query processing like RDF-3X [40] and gStore
[41], which can reduce graph searching space and avoid looking up unnecessary
blocks. However, neither of them works on a cross domain and semantic perspective.
Indexing technology in our approach provides semantic meaning for graphs.

4. Research Questions
The main goal of my doctoral research is to build a big graph analytics framework for
cross-domain knowledge discovery. In order to achieve this goal, the research will
give answers to the following research questions:
(i)
How to provide an effective and accurate semantic partitioning scheme
to discover knowledge?
(ii)
For RDF data, how can we determine the closeness relationships, e.g.,
based on predicate-predicate or subject/object-subject/object relationships?
(iii)
How to build a scalable framework to process and manage large data?

5. Hypotheses
The main hypotheses related to my research are:
- Any normailized RDF data from heterogeneous resources can be the input of
our framework
- Edge centric similarity results represent similarity of knowledge domain.
- Different knowledge sources belong to one of the clustering types must have
a closer relationsihp than the ones not in the same cluster/group.
- Data is big and increases infinitely, there is no way to handle that huge
amounts of data in a standalone machine.

6. Approach
We found out that predicates play an important role as hubs to share information and
connect entities among heterogeneous data. Therefore, we hypothesize that graphs
can be fuzzy clustered based on a predicate sharing and distance measurement, and
data in the same clustered group have closer relationships than when separate.
In this drive, we defined an edge centric neighboring algorithm to determine the
closeness of any two predicates. The formal definition is shown in Definition 1.
Definition 1: Given a directed graph G (V, E), vertices Vs, Vp, Vo denote subject,
predicate, and object nodes in the RDF schema graph, respectively. Let d (Vpi,Vpj)
represent the shortest path between Vpi and Vpj, r (Vpi,Vpj) determines the reachability
between Vpi and Vpj, n (Vpi, Vpj) indicates the neighbors’ closest level between Vpi and
Vpj:
n 𝑉!" , 𝑉!" =

  1,                                            𝑖𝑓  𝑑 𝑉!" , 𝑉!" = 1                                                                                                                            
𝐿,                                           𝑖𝑓  𝑑 𝑉!" , 𝑉!" = 𝐿   𝐿 > 1 𝐴𝑁𝐷  𝑟 𝑉!" , 𝑉!" = 𝑡𝑟𝑢𝑒

After assigning levels to different pair of predicates, we utilize the clustering approach for discovering the predicate association patterns from the ontologies. The
similarity based distance measurement for the clustering algorithm varies based on
different neighboring levels for each pair of predicates. Basically, we give higher
weights to closer predicates and lower weights to further predicates. That is, for any
two predicates in level 1 relationship, we assign a probability based similarity score to
them. The definition is given in Definition 2.
Definition 2: Given Vpi and Vpj in a directed RDF schema Graph G (V, E). Let A
and B denote the number of entity (subject or object) directed connected to Vpi and Vpj
regardless of the direction respectively. ps (Vpi, Vpj) indicates the probability based
similarity between Vpi and Vpj:

𝑝𝑠(𝑉!" , 𝑉!"   ) =

𝐴∩𝐵 𝐴∩𝐵
	  *	  
𝐴
𝐵

Moreover, assigning the same similarity score for different level of neighboring relationship is unfair. In this case, we define a dynamic weight for probability based
similarity in different levels in Definition 3.

Definition 3: Denote n (Vpi, Vpj) = m (m>1), and n (Vpi, Vpk) = p (1≤p<m), n (Vpk,
Vpj) = q (1≤q<m)

  𝑝𝑠 𝑉!" , 𝑉!" =

  𝑝𝑠 𝑉!" , 𝑉!" ∗ 𝑝𝑠(𝑉!" , 𝑉!" ),                                  𝑖𝑓  𝑚 = 2  
𝑀𝑎𝑥(𝑝𝑠 𝑉!" , 𝑉!" , 𝑝𝑠(𝑉!" , 𝑉!" ))                  𝑖𝑓  𝑚 > 2  

After we get the similarity score for all pairs of predicates, we use formula in Definition 4 to generate a distance matrix for clustering.
Definition 4: Given distance matrix CM and total number of predicate n. Denote
𝑝𝑠!" as the probability-based similarity score between predicates pi and pj based on
different levels, so that:
𝑃𝑆!" ,                                𝑖𝑓  𝑝!    ≠    𝑝! , 0 ≤ 𝑖 ≤ 𝑛, 0 ≤ 𝑗 ≤ 𝑛                                              
CM 𝑝! , 𝑝! =
    1                                        𝑖𝑓  𝑝!    =    𝑝! , 0 ≤ 𝑖 ≤ 𝑛, 0 ≤ 𝑗 ≤ 𝑛                                        
To discover the correlation between predicates, we used an innovative Hierarchical
Fuzzy C-means (HFCM) clustering algorithm. We created HFCM algorithm and
made a functional extension based on a Fuzzy C-means clustering algorithm. In general, we set a machine capacity threshold to denote a certain number of triplets that
each machine can hold. In addition, we continue applying an HFCM algorithm on
each cluster until the number of triplets for each cluster is less than or equal to the
threshold or no further change of numbers of elements for each cluster can be made.
Moreover, to get the optimal number of clusters, we use Silhouette Width to evaluate
different results and choose the one with the biggest score.

7. Preliminary Results
The preliminary evaluation is conducted in terms of the validation of clustering result
and justified query benchmark generation. We used eight ontologies from Bio2RDF
release 3 to evaluate our system. Detailed is given in Table 1. In addition, we eliminated some RDF built-in predicates and types for getting the best clustering result.
The total number of predicate for HFCM reduced from 1099 to 1064.
Table 1: Bio2RDF Datasets

Ontology
Biomodels
BioPortal
[42]
DrugBank
GOA
HGNC
[43]
MGI [44]

Triples#
2 million
20 million

# of Unique Triple Schema
478
8259

# of Unique Predicates
18
867

3 million
97 million
3 million

737
75
57

68
17
18

8 million

95

19

OMIM
Pharmgkb
Total

8 million
270 million
411 million

261
396
10258

39
53
1099

Firstly, we conduct heuristic comparison experiments among different clustering
algorithms to choose an appropriate approach to get the best number of clusters. Figure 1 shows an edge centric clustering results for probability based similarity in terms
of running five different clustering algorithms (Fuzzy C-means, K-means, Clara, Pam
and Hierarchical Clustering) on the input data. We used silhouette width as the validation method to do evaluation. As a result, Clara, Pam and hierarchical algorithms give
a relative stable silhouette width for each number of clusters. This means there is no
optimal cluster number for these cases. Both Fuzzy C-means and K-means give the
highest silhouette width 0.95 when the cluster number is 5. However, we choose
Fuzzy C-means because it gives additional soft partition information for each cluster,
which could be useful for distributed query processing.

Fig. 1. Edge Centric Clustering Results for Probability based Similarity

After finalizing Fuzzy C-means with a probability based similarity score as the
measurement approach, we apply a hierarchical Fuzzy C-means (HFCM) algorithm to
the dataset trying to partition each cluster into an indivisible unit. For each level of
processing, we still used silhouette width to determine the proper number of clusters.
As Figure 2 shows, in first level running of HFCM, we get five clusters. Then in second level running of HFCM, only cluster 2 (C2) and cluster 3 (C3) can be further
clustered. According to silhouette width, we get the best number of cluster 2 for C2
and 4 for C3 respectively. As a result, after level 2 running, we get 9 different clusters. Because the number of cluster does not change as we run the 3rd level HFCM, the
algorithm stops here. The solutions from the algorithm yield the number of clusters as
9.

Fig. 2. Edge Centric Clustering for Hierarchical Fuzzy C-Means

Fig. 3. Cluster Coverage of Domain Knowledge

We conducted a domain coverage evaluation for each cluster. Figure 3 shows
such results with histogram. It is obvious that bio-portal is the hub in life science
cross domains. Cluster 1 and cluster 9 include specific semantic knowledge about bioportal and gene ontology, while other clusters contain a relative comprehensive
knowledge for each domain from different perspectives. Moreover, the visualization
for each query has been implemented using CytoScape [45] in Figure 4.

Fig. 4. Eight Queries with Query Graphs

8. Evaluation Plan
For future work, we plan to compare our proposed methods with previously developed tool BioBroker [46] with the fuzzy c-means clustering algorithm [47-49] on
graph partition with semantic correlation. In addition, more biomedical heterogeneous
ontologies and clinical narratives/literature will be incorporated to discover
knowledge across biomedical and clinical domains [50-55]. Moreover, we will enable
large graph analysis and process through adopting cloud computing techniques as
well as distributed graph process [56].
For the future evaluation, there are three main lines of interests.
Validation The proposed approach will be validated by comparing with more
existing algorithm and framework
Scalability Indexing approach will be applied to facilitate the management of big
data. All datasts from Bio2RDF will be used to test the scalability of the proposed
framework
Benchmark The existing Bio2RDF query sets will be analyzed to compare with
our benchmark generation scheme in order to improve the coverage and semantic for
each cluster association.

9. Reflections
Our approach overcomes the difficulties of less semantic across different knowledge
domains by providing a new semantic distance measurement and clustering design.
This way, we achieve grouping close domain knowledge together in order to help user
design comprehensive query to fully discover cross-domain knowledge.

References
[1] Klyne G, et al. Resource description framework (RDF): Concepts and abstract
syntax. 2006.
[2] McGuinness DL, et al. OWL web ontology language overview. W3C
recommendation. 2004;10:2004.

[3] Belleau F, et al. Bio2RDF: towards a mashup to build bioinformatics knowledge
systems. Journal of biomedical informatics. 2008;41:706-16.
[4] Schriml LM, et al. Disease Ontology: a backbone for disease semantic integration.
Nucleic acids research. 2011;40:D940-D6.
[5] Ashburner M, et al. Gene Ontology: tool for the unification of biology. Nature
genetics. 2000;25:25.
[6] Wishart DS, et al. DrugBank: a comprehensive resource for in silico drug
discovery and exploration. Nucleic acids research. 2006;34:D668-D72.
[7] Köhler S, et al. The Human Phenotype Ontology project: linking molecular
biology and disease through phenotype data. Nucleic acids research. 2013;42:D966D74.
[8] Smith CL, et al. The mammalian phenotype ontology: enabling robust annotation
and comparative analysis. Wiley Interdisciplinary Reviews: Systems Biology and
Medicine. 2009;1:390-9.
[9] Smith CL, et al. The Mammalian Phenotype Ontology as a tool for annotating,
analyzing and comparing phenotypic information. Genome biology. 2005;6:R7.
[10] Hewett M, et al. PharmGKB: the pharmacogenetics knowledge base. Nucleic
acids research. 2002;30:163-5.
[11] Hamosh A, et al. Online Mendelian Inheritance in Man (OMIM), a
knowledgebase of human genes and genetic disorders. Nucleic acids research.
2005;33:D514-D7.
[12] Firth HV, et al. DECIPHER: database of chromosomal imbalance and phenotype
in humans using ensembl resources. The American Journal of Human Genetics.
2009;84:524-33.
[13] Rath A, et al. Representation of rare diseases in health information systems: the
Orphanet approach to serve a wide range of end users. Human mutation.
2012;33:803-8.
[14] Dasgupta S, et al. SMARTSPACE: Multiagent based distributed platform for
semantic service discovery. IEEE Transactions on Systems, Man, and Cybernetics:
Systems. 2014;44:805-21.
[15] Vaka P, et al. PEMAR: A pervasive middleware for activity recognition with
smart phones. 2015 IEEE International Conference on Pervasive Computing and
Communication Workshops (PerCom Workshops): IEEE; 2015. p. 409-14.
[16] Zhang Y, et al. An integrative computational approach to identify diseasespecific networks from PubMed literature information. 2013 IEEE International
Conference on Bioinformatics and Biomedicine: IEEE; 2013. p. 72-5.
[17] Shen F, et al. SAMAF: Situation aware mobile apps framework. 2015 IEEE
International Conference on Pervasive Computing and Communication Workshops
(PerCom Workshops): IEEE; 2015. p. 26-31.
[18] Shen F. Situation Aware Mobile Apps Framework: University of Missouri-Kansas City; 2012.
[19] Peng S, et al. Leveraging Association Rule Mining to Detect Pathophysiological
Mechanisms of Chronic Kidney Disease Complicated by Metabolic Syndrome. 2018
IEEE International Conference on Bioinformatics and Biomedicine (BIBM): IEEE;
2018. p. 1302-9.

[20] Shen F, et al. Using semantic web technologies for quality measure phenotyping
algorithm representation and automatic execution on EHR data. IEEE-EMBS
International Conference on Biomedical and Health Informatics (BHI): IEEE; 2014.
p. 531-4.
[21] Tao C, et al. Phenotyping on EHR data using OWL and semantic web
technologies. International Conference on Smart Health: Springer; 2013. p. 31-2.
[22] Peterson KJ, et al. Mining Hierarchies and Similarity Clusters from Value Set
Repositories.
AMIA Annual Symposium Proceedings: American Medical
Informatics Association; 2017. p. 1372.
[23] Yang S, et al. Towards effective partition management for large graphs.
Proceedings of the 2012 ACM SIGMOD International Conference on Management of
Data: ACM; 2012. p. 517-28.
[24] Khayyat Z, et al. Mizan: a system for dynamic load balancing in large-scale
graph processing. Proceedings of the 8th ACM European Conference on Computer
Systems: ACM; 2013. p. 169-82.
[25] Malewicz G, et al. Pregel: a system for large-scale graph processing.
Proceedings of the 2010 ACM SIGMOD International Conference on Management of
data: ACM; 2010. p. 135-46.
[26] Gerbessiotis AV, et al. Direct bulk-synchronous parallel algorithms. Journal of
parallel and distributed computing. 1994;22:251-67.
[27] Simmhan Y, et al. Goffish: A sub-graph centric framework for large-scale graph
analytics. European Conference on Parallel Processing: Springer; 2014. p. 451-62.
[28] Lang J, et al. Similarity-driven semantic role induction via graph partitioning.
Computational Linguistics. 2014;40:633-69.
[29] Schmidt M, et al. SP^ 2Bench: a SPARQL performance benchmark. 2009 IEEE
25th International Conference on Data Engineering: IEEE; 2009. p. 222-33.
[30] Guo Y, et al. LUBM: A benchmark for OWL knowledge base systems. Web
Semantics: Science, Services and Agents on the World Wide Web. 2005;3:158-82.
[31] Bizer C, et al. The berlin sparql benchmark. International Journal on Semantic
Web and Information Systems (IJSWIS). 2009;5:1-24.
[32] Schmidt M, et al. Fedbench: A benchmark suite for federated semantic data
query processing. International Semantic Web Conference: Springer; 2011. p. 585600.
[33] Shen F, et al. MedTQ: Dynamic Topic Discovery and Query Generation for
Medical Ontologies. arXiv preprint arXiv:180203855. 2018.
[34] Shen F, et al. BmQGen: Biomedical query generator for knowledge discovery.
2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM):
IEEE; 2015. p. 1092-7.
[35] Shen F, et al. Predicate oriented pattern analysis for biomedical knowledge
discovery. Intelligent information management. 2016;8:66.
[36] Shen F, et al. Detection of Surgical Site Infection Utilizing Automated Feature
Generation in Clinical Notes. Journal of Healthcare Informatics Research. 2018:1-16.
[37] Zhu Q, et al. Exploring the pharmacogenomics knowledge base (PharmGKB) for
repositioning breast cancer drugs by leveraging Web ontology language (OWL) and
cheminformatics approaches. Biocomputing 2014: World Scientific; 2014. p. 172-82.

[38] Papailiou N, et al. H 2 RDF+: High-performance distributed joins over largescale RDF graphs. 2013 IEEE International Conference on Big Data: IEEE; 2013. p.
255-63.
[39] Zeng K, et al. A distributed graph engine for web scale RDF data. Proceedings
of the VLDB Endowment: VLDB Endowment; 2013. p. 265-76.
[40] Neumann T, et al. RDF-3X: a RISC-style engine for RDF. Proceedings of the
VLDB Endowment. 2008;1:647-59.
[41] Zou L, et al. gStore: answering SPARQL queries via subgraph matching.
Proceedings of the VLDB Endowment. 2011;4:482-93.
[42] Noy NF, et al. BioPortal: ontologies and integrated data resources at the click of
a mouse. Nucleic acids research. 2009;37:W170-W3.
[43] Povey S, et al. The HUGO gene nomenclature committee (HGNC). Human
genetics. 2001;109:678-80.
[44] Bult CJ, et al. The Mouse Genome Database (MGD): mouse biology and model
systems. Nucleic acids research. 2008;36:D724-D8.
[45] Shannon P, et al. Cytoscape: a software environment for integrated models of
biomolecular interaction networks. Genome research. 2003;13:2498-504.
[46] Shen F, et al. Biobroker: Knowledge discovery framework for heterogeneous
biomedical ontologies and data. Journal of Intelligent Learning Systems and
Applications. 2018;10:1.
[47] Shen F, et al. Knowledge discovery from biomedical ontologies in cross
domains. PloS one. 2016;11:e0160005.
[48] Shen F. A pervasive framework for real-time activity patterns of mobile users.
2015 IEEE International Conference on Pervasive Computing and Communication
Workshops (PerCom Workshops): IEEE; 2015. p. 248-50.
[49] Shen F. A Graph Analytics Framework For Knowledge Discovery 2016.
[50] Li D, et al. Towards a multi-level framework for supporting systematic review—
A pilot study. 2014 IEEE International Conference on Bioinformatics and
Biomedicine (BIBM): IEEE; 2014. p. 43-50.
[51] Li D, et al. A text-mining framework for supporting systematic reviews.
American journal of information management. 2016;1:1.
[52] Shen F, et al. Phenotypic Analysis of Clinical Narratives Using Human
Phenotype Ontology. Studies in health technology and informatics. 2017;245:581-5.
[53] Shen F, et al. Using Human Phenotype Ontology for Phenotypic Analysis of
Clinical Notes. Studies in health technology and informatics. 2017;245:1285-.
[54] Son JH, et al. Deep phenotyping on electronic health records facilitates genetic
diagnosis by clinical exomes. The American Journal of Human Genetics.
2018;103:58-73.
[55] Rastegar-Mojarad M, et al. Need of informatics in designing interoperable
clinical registries. International journal of medical informatics. 2017;108:78-84.
[56] Chen Z, et al. Collaborative mobile-cloud computing for civil infrastructure
condition inspection. Journal of Computing in Civil Engineering. 2013;29:04014066.

