1

Persuasion-based Robust Sensor Design Against
Attackers with Unknown Control Objectives

arXiv:1901.10618v2 [eess.SY] 11 Sep 2020

Muhammed O. Sayin and Tamer Başar, Life Fellow, IEEE

Abstract—In this paper, we introduce a robust sensor design
framework to provide “persuasion-based” defense in stochastic
control systems against an unknown type attacker with a control
objective exclusive to its type. For effective control, such an
attacker’s actions depend on its belief on the underlying state
of the system. We design a robust “linear-plus-noise” signaling
strategy to encode sensor outputs in order to shape the attacker’s
belief in a strategic way and correspondingly to persuade the
attacker to take actions that lead to minimum damage with
respect to the system’s objective. The specific model we adopt is
a Gauss-Markov process driven by a controller with a (partially)
“unknown” malicious/benign control objective. We seek to defend
against the worst possible distribution over control objectives
in a robust way under the solution concept of Stackelberg
equilibrium, where the sensor is the leader. We show that a
necessary and sufficient condition on the covariance matrix of
the posterior belief is a certain linear matrix inequality and
we provide a closed-form solution for the associated signaling
strategy. This enables us to formulate an equivalent tractable
problem, indeed a semi-definite program, to compute the robust
sensor design strategies “globally” even though the original
optimization problem is non-convex and highly nonlinear. We
also extend this result to scenarios where the sensor makes
noisy or partial measurements. Finally, we analyze the ensuing
performance numerically for various scenarios.
Index Terms—Stackelberg games, Stochastic control, Security,
Sensor placement, Semi-definite programming.

I. I NTRODUCTION
YBER connectedness of control systems has brought in
new security challenges where attackers can manipulate
control systems at unprecedented levels with various malicious
tasks on their agenda [1]–[3]. We can view such intelligent
attackers as decision makers that take actions driven by and
compatible with their own objective and information available
to them. This implies that the kind of information available to
an attacker has an indirect impact on what actions the attacker
would take. Correspondingly, it is intuitively expected that if
we can manipulate the information available to attackers, then
we can persuade them to attack the system in a way in line
with the system’s objective to the extent possible, so that the
attack would cause minimum damage to the system.
There are certain distinct challenges for persuasion-based
defense measures. For example, attackers make their decisions
based on the belief they have formed using the information

C

This research was supported by the U.S. Office of Naval Research (ONR)
MURI grant N00014-16-1-2710.
Muhammed O. Sayin is with Laboratory for Information and Decision
Systems at MIT, Cambridge, MA 02139. E-mail: sayin@mit.edu
Tamer Başar is with the Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA.
E-mail: basar1@illinois.edu

available to them. A challenge is how to shape that belief
in a desired way by controlling the information available to
the attacker. The first requirement (and challenge) here is to
be able to identify how an attacker would form its belief.
However, when an attacker forms its belief strategically, there
might be multiple Nash equilibria in a general-sum setting1 , as
shown in the strategic information transmission framework [4].
In that case how an attacker forms its belief is not well defined
since the attacker might be forming its belief differently at
different equilibria and whether (and which) equilibrium will
be realized would not be known, and constitutes an uncertainty. Furthermore, even when there exists a well-defined
characterization of how an attacker would form its belief,
another challenge is what decision the attacker would make
based on that belief, since that decision would depend on the
attacker’s malicious objective. This implies that persuasionbased defense is attack-specific. Therefore another challenge
is how to persuade an attacker whose objective is not known
to act in a certain way.
Before addressing these challenges, let us briefly review
the literature from a broader perspective where a decision
maker seeks to induce another one to take certain actions. A
closely related framework is Bayesian persuasion, introduced
by Kamenica and Gentzkow in their seminal paper [5]. They
addressed how a sender could persuade a receiver to take
certain actions under the solution concept of Stackelberg
equilibrium [6] where the sender (the receiver) is the leader
(the follower). In other words, the receiver is aware of the
sender’s signaling strategy while taking its actions. Such a
leader-follower scheme creates an environment where the
receiver’s actions are not strategic, and therefore there is a
well-defined characterization for how the belief is formed.
In Bayesian persuasion framework, a necessary and sufficient condition is that mean of posterior belief must be equal
to the prior belief. This enables us to formulate an equivalent
problem over distributions over posterior beliefs under a
linear equality constraint. The authors provided a geometrical
interpretation to compute the solution, which necessitates
computation of a convex envelope of a function. Although this
interpretation provides essential insight for designing signaling
strategies and has led to various applications (see the recent
survey on Bayesian persuasion [7] and the references therein),
it is viable only for scenarios where the state space is very
1 In a zero-sum setting, there exists a unique “babbling equilibrium” where
the attacker forms a belief independent of the information provided by a
defender (since the defender would not share anything useful) whereas the
defender just makes irrelevant information available to the attacker (since a
more informed attacker would not cause less damage to the system).

2

small.
We emphasize that [5] studies the Bayesian persuasion
problem in a very general framework, where the underlying
distribution is arbitrary as long as its support set is compact,
cost functions are arbitrary, and the signaling strategy is any
stochastic kernel (between the state space and the signal
space). Therefore if we consider specific distributions and
cost functions, we should be able to obtain more tractable
solutions. For example in [8], the author addressed Bayesian
persuasion problem for multi-variate Gaussian information and
quadratic cost functions, and provided a closed-form solution
for the optimal signaling strategy, which turns out to be a
linear function. We note that the studies [5], [8] focused
on static systems. To be able to adopt this framework to
control systems, an important step would be to extend the
framework to dynamic systems. In [9], we have extended the
results in [8] to dynamic environments where the underlying
information is a discrete-time Gauss Markov process. We
showed that there exists a linear signaling strategy optimal
within the general class of measurable policies and provided
a semi-definite program (SDP) to compute optimal signaling
strategies numerically.
Before delving into persuasion-based defense measures in
control systems, let us also review the literature on security of
control systems. To this end, we selectively focus on studies
where an attacker can monitor and intervene the links from
sensor to controller and from controller to actuator so that there
would be an information flow to the attacker who monitors
these links. In [10], the authors showed that an attacker can
lead to unbounded estimation error by injecting false data into
the link from sensor to controller when there exists a certain
threshold-based detector monitoring the link. In [11], [12], the
authors characterized the reachable set to which an evasive
attacker can drive the system by injecting data into both links
jointly. In [13], [14], the authors analyzed attacks where an
attacker seeks to drive the state of the system according to
his/her adversarial goal evasively by injecting data into both
links jointly. In [15], the authors have analyzed optimal attack
strategies to maximize quadratic cost of a system with linear
Gaussian dynamics by injecting false data into the link from
controller to actuator without being detected.
As seen in the literature reviewed above, an attacker can
monitor and intervene the links in a control system, e.g., as
illustrated in Fig. 1 for a linear quadratic Gaussian (LQG)
control system. This implies that an attacker can bypass the
controller of a system by monitoring and intervening both links
jointly. Then the attacker would receive the sensor outputs
and could generate its own control inputs to conduct its
malicious control objective similar to the controller of the
system. From this viewpoint, within the Bayesian persuasion
framework, we can encode the sensor outputs to persuade
the attacker to generate control inputs that would minimize
the system’s very own control objective as much as possible.
We partially addressed this challenge in [9], [16], [17]. In
[9], we formulated an optimal linear signaling rule in an
LQG setting when attacker’s control objective is known to
the sensor. This limits applicability of the solution since the
sensor must know when there is an attack and what the control

Measurement
yk

Sensor

Signal
Encoder

s k = ηk (yy1:k )

Might be corrupted
by Attacker

y 1:k−1

Dynamic System

wk
x k+1 = Axxk + Buuk +w

Unknown-type
Attacker

Controller

?

Control Input

uk = γk (ss1:k )
Actuator

Physical Plant

When there is an attack, Controller
does not actuate the system anymore

Fig. 1: A discrete-time LQG control system where an
(unknown-type) attacker can monitor and intervene the links
from sensor to controller, and from controller to actuator
jointly in order to drive the system according to its malicious
control objective. The attacker might also corrupt the data
received by the controller of the system to evade a detector
monitoring that data. Details of how an attacker can evade
detection by corrupting that data has earlier been studied
in the literature, e.g., [10]–[14], and is out of the scope of
this paper since here we focus on adopting persuasion-based
defense against attackers with unknown control objectives.
Furthermore, the results of this paper hold for any strategy
that the attacker can use to evade such detectors as long as
those strategies do not impact how the attacker constructs its
control inputs.

objective of the attacker is beforehand. In the follow-up papers
[16], [17], we showed that this limitation could be relaxed
in a straightforward way if the sensor knows the distribution
over the control objectives of attackers that may attack the
system and at what probability there might be an attack.
Correspondingly, a risk-neutral sensor could minimize the
expected damage with respect to that distribution. However,
this still limits its applicability since the sensor must know
the underlying distribution over the attack space.
Although it is not a persuasion-based defense, it is worth
noting that in [18], the authors proposed linear encoding
schemes2 for sensor outputs in an LQG control problem in
order to enhance detectability of false data injection attacks
under an essential assumption that the encoding matrix is
oblivious to attackers. In that respect, the encoding scheme
could be viewed as corrupting the information available to
attackers (without impacting the information flowing to the
controller of the system) in order to limit the attacker’s
capability to evade detection rather than persuading the attacker to attack in a certain way. And this security measure
becomes undermined completely once the encoding scheme is
compromised.
Coming to the specifics of this paper, we also consider
a discrete-time LQG control problem, similar to the studies
reviewed above [13]–[18], but with important differences. We
2 We use the terminologies encoding scheme and signaling rule/strategy
interchangeably.

3

particularly seek to design linear-plus-noise signaling rules
for persuasion-based robust sensor design against an unknown
type attacker with a control objective exclusive to its type.
It is robust in the sense that sensor outputs are designed
against the worst possible distribution over all possible control
objectives of the attacker. We consider the scenario where
the set of types is finite and known to the system. Under
the solution concept of Stackelberg equilibrium, we consider
the setting where the sensor is the leader and the attacker is
the follower. This yields that the underlying encoding scheme
is not necessarily oblivious to the attacker. Furthermore, we
address the scenarios where the sensor can have partial or
noisy measurements different from the models in [9], [16],
[17]. Note that the worst case distribution over the type set
turns out to be not necessarily a degenerate distribution, i.e.,
defending only against the (strongest) type of attack that leads
to largest cost for the system is not necessarily optimal with
respect to the system’s objective.
Due to the underlying leader-follower setting, the response
of the follower (the attacker) is non-strategic and the problem
faced by the leader (the sensor) turns out to be an optimization
problem rather than a fixed-point problem. By using the classical method of completion of squares [19], we can show that the
objective function in that optimization problem is linear in the
covariance matrix of the posterior estimate of the underlying
(control-free) state. However that covariance matrix depends
on the encoding scheme in a nonlinear way, which leads to
a non-convex and highly nonlinear optimization problem, to
be solved globally in order to compute robust sensor design
strategies. In [9], our previous inspection revealed a necessary
condition on this covariance matrix, which is just a linear
matrix inequality. Here we show that this necessary condition
is also a sufficient condition when the sensor selects linear plus
noise signaling strategies. Furthermore for any matrix satisfying the necessary condition, we provide a closed-form solution
for the associated linear plus noise signaling rule. Therefore
instead of trying to solve a non-convex and highly nonlinear
optimization problem, we are able to bring the problem to
one of solving a linear optimization problem under linear
matrix inequality constraints, which can be done numerically
using existing SDP solvers effectively, e.g., [20], [21]. This
solution concept can be seen to have similar flavor with our
previous paper [9], reviewed above. However, here we develop
and present a completely new and more comprehensive set of
technical tools since the results of [9] cannot be adopted for the
general setting of this paper. The reader can refer to Appendix
A for a detailed discussion on this matter.
We now highlight the main contributions of this paper as
follows:
• We show that a necessary and sufficient condition on the
covariance matrix of the posterior estimate of controlfree state is a certain linear matrix inequality. This result
is important by itself since it yields a tractable solution
concept to design sensor outputs in general settings not
limited to the special setting studied in this paper.
• Based on this necessary and sufficient condition, we
provide an SDP equivalent to the original optimization
problem faced by the sensor, which is non-convex and

highly nonlinear, while the SDP could be solved globally
using existing powerful computational tools effectively
[20], [21]. Furthermore, this result can be extended to
scenarios where there are partial or noisy measurements.
• We note that robust signaling rule can dictate sensors to
introduce irrelevant information into sensor outputs quite
contrary to other settings, e.g., when there is no uncertainty
(or there is imperfect information) on attacker’s type. This
observation enables us to draw the following conclusions:
– The equivalence result does not necessarily hold if the
sensor can only use linear signaling rules.
– Based on Blackwell’s Irrelevant Information Theorem
[22, Theorem D.1.1], linear signaling strategies are not
the best one within the general class of measurable
strategies in this robust setting.
The paper is organized as follows: In Section II, we formulate the robust sensor design game. In Section III, we
analyze the equilibrium of the robust sensor design game under
perfect measurements. In Section IV, we extend the results
to the cases where there are partial or noisy measurements.
In Section V, we examine numerically the performance of
the proposed scheme for various scenarios. We conclude
the paper in Section VI with several remarks and possible
research directions. An appendix provides further discussion
on related literature, proofs of all technical results in the
order they appear throughout the paper, and some closed-form
expressions for the reader’s reference.
Notation: We denote a collection of parameters via a
subscript, e.g., {xk }, by dropping the subscript, e.g., x, for
notational brevity. For a vector x and a matrix A, x0 and A0
denote their transposes, and kxk denotes the Euclidean (L2 )
norm of the vector x. For a matrix A, Tr{A} and rank{A}
denote its trace and rank, respectively. We denote the identity
and zero matrices with the associated dimensions by I and O,
respectively. We denote the set of m-by-m symmetric, positive
semi-definite, and positive definite matrices by Sm , Sm
+ , and
†
Sm
++ , respectively. For a matrix A, A denotes its MoorePenrose inverse. For positive semi-definite matrices A and B,
A  B means that A − B is also a positive semi-definite matrix.
We denote the Kronecker product of matrices A and B by
A ⊗ B.
We denote an ordered set {xk , . . . , x1 } and its augmented
0
vector version, xk0 · · · x10 , by x1:k , by some abuse of
notation. N (0, .) denotes the multivariate Gaussian distribution with zero mean and designated covariance matrix. We
denote random variables by bold lower case letters, e.g., x .
We denote expectation and (co)variance of a random variable
x by E{xx} and cov{xx}, respectively. For random variables x
and y , E{xx|yy} denotes the expectation of x with respect to the
random variable y . We denote the set of all possible probability
distributions over a set Ω by ∆(Ω).

II. P ROBLEM F ORMULATION
Consider a control system, as illustrated in Fig. 1, whose
underlying state dynamics and sensor measurements are de-

4

scribed, respectively, by:

B. Attack Model

wk ,
x k+1 = Axxk + Buuk +w
y k = Cxxk +vvk ,
where3

Rm×m , B

Rm×r ,

(1)
(2)
Rn×m ,

for k = 1, . . . , κ,
A∈
∈
and C ∈
and the initial state x 1 ∼ N (0, Σ1 ). The additive state and
wk } and {vvk }, respectively, are
measurement noise sequences {w
white Gaussian vector processes, i.e., w k ∼ N (0, Σw ) and v k ∼
N (0, Σv ); and are independent of the initial state x 1 and of
each other.
As seen in Fig. 1, measurements y 1:k ∈ Rnk are encoded into
a signal s k ∈ Rm through a signaling strategy ηk (·), which
is a stochastic kernel, and s k = ηk (yy1:k ) almost everywhere
over Rm . We specifically consider “linear plus noise” signaling
rules such that the signal s k is given by
ϑ k,
s k = ηk (yy1:k ) = Lk0 y 1:k +ϑ

(3)

almost everywhere over Rm , where Lk ∈ Rnk×m can be any
nk-by-m deterministic matrix, and ϑ k ∼ N (0, Θk ) is a zero
mean multivariate Gaussian noise independent of every other
parameter, and its covariance matrix Θk ∈ Sm
+ can be any mby-m positive semi-definite matrix. We denote the set of such
signaling rules by ϒk , i.e., ηk ∈ ϒk . Furthermore, the closedloop control input u k ∈ Rr is given by
u k = γk (ss1:k ),

(4)

almost everywhere over Rr , where γk (·) can be any Borel
measurable function from Rmk to Rr . We denote the set of
such control policies by Γk , i.e., γk ∈ Γk . For notational brevity,
let us denote signaling (control) strategies and the associated
sets across the horizon by η and ϒ (γ and Γ), respectively.
A. Defense Model
We consider an LQG control problem, where the controller
of the system selects a measurable control strategy γ ∈ Γ in
order to minimize
κ

∑ Ekxxk+1 k2Q + Ekuuk k2R ,

(5)

k=1
r
where4 Q ∈ Sm
+ and R ∈ S++ . As illustrated in Fig. 1, we
consider the encoder of the system as a decision maker,
denoted by PS . PS selects the signaling strategy η ∈ ϒ in
order to minimize the same objective with the controller, (5).
Note that if there were no attacks, identity function, where
the measurements are shared with the controller fully, would
be an optimal encoding scheme due to the data processing
inequality [23, Theorem 2.8.1]. However, we consider here
the scenarios where there can be an attack with an unknown
control objective. Correspondingly there might be encoding
schemes that do not share the measurements fully and can
lead to better performance with respect to (5).
3 Even

though we consider time-invariant matrices A, B, and C, for notational
simplicity, the provided results could be extended to time-variant cases rather
routinely. Furthermore, we consider all the random parameters to have zero
mean; however, the derivations can be extended to non-zero mean case in a
straight-forward way.
4 For notational simplicity, we consider time-invariant Q and R. However,
the results provided could be extended to the general time-variant case rather
routinely.

We consider an attacker who is aware of the underlying state
dynamics, i.e., gain matrices A, B, and C; covariance matrices
Σ1 , Σw , and Σv ; and the encoding scheme, i.e., η. The attacker
is of an unknown type, which determines its control objective.
Let us denote the set of all possible types by Ω. We suppose
that Ω is finite and known by the system. We seek to provide a
compact and unified analysis. Therefore we consider that the
control objective of type ω ∈ Ω is given by
κ

∑ Ekxxωk+1 k2Qω + Ekuuωk k2Rω ,

(6)

k=1
ω
r
where Qω ∈ Sm
+ and R ∈ S++ are exclusive to the type ω.
Note that when there is an attack, the attacker selects a control
strategy γ ω ∈ Γ in order to construct its control input u ω
k
and correspondingly its control objective includes the term
2
Ekuuω
k kRω . We also denote the state driven by type-ω attacker
ω
by x k , to make it explicit.

Remark 1 (Versatility of Control Objectives). We model the
control objectives of the system and the attacker by (5) and
(6), respectively, within a unified framework. However, arbitrariness of weight matrices in the control objectives (5) and
(6) brings in flexibility to model various attack scenarios (that
are not in the exact form of (6)) through the transformation
of the underlying state space as exemplified in Section V. 
C. Game Model
We analyze the interaction between the attacker and PS
under the solution concept of Stackelberg equilibrium where
PS is the leader. Note that from the viewpoint of PS , either
the controller of the system is receiving the sensor output and
driving the state or there is an unknown type attack, and it is
getting the sensor output and it is generating the control input.
Since whether there is an attack or not is also an uncertainty,
let us view the attacker and the controller of the system as
a single player in a unified way, denoted by PC , with an
unknown type from the extended type set Ωo := Ω ∪ {ωo },
where type-ωo corresponds to the controller of the system, i.e.,
Qωo = Q and Rωo = R. Therefore, we consider a Stackelberg
game between the leader PS and the follower PC (of an
unknown type).
We note that depending on its type, PC selects different
control policies, which lead to different control inputs, and
ω
states. Therefore for type-ω PC , we use γkω , x ω
k and u k . The
objective of type-ω PC is given by
κ

UCω (η, γ ω ) :=

∑ Ekxxωk+1 k2Qω + Ekuuωk k2Rω .

(7)

k=1

On the other hand, the objective of PS is given by
(
κ

US (η, {γ ω }ω∈Ωo ) := max

p∈∆(Ωo )
κ

+pωo

∑
k=1

∑

pω

ω∈Ω

2
Ekxxω
∑
k0 +1 kQωo
0

k =1

)
2
o
Ekxxω
k+1 kQωo


o 2
+ Ekuuω
k kRωo

, (8)

5

where ∆(Ωo ) denotes all possible distributions over the extended type set Ωo . Note that the maximization in (8) computes
the cost of PS for the worst case distribution over Ωo .
Before describing the game formally, let us take a closer
look at PS ’s objective (8). We can view (8) consisting of two
parts, one of which is
κ

pωo

∑


2
o
o 2
uω
Ekxxω
k+1 kQωo + Eku
k kRωo ,

(9)

k=1

where pωo corresponds to the probability that the controller of
the system drives the state under the worst case distribution
and the summation is identical to (5) since Qωo = Q and Rωo =
R. The other part is
κ

∑

pω

ω∈Ω

∑
0

2
Ekxxω
k0 +1 kQωo ,

(10)

k =1

which implies that PS seeks to minimize
when type-ω attacker drives the state. Note that it includes
only the first term in (5) since we consider that PS would not
necessarily want the attacker to have small size control inputs.
2
∑κk=1 Ekxxω
k+1 kQωo

Definition (Robust Sensor Design Game). The robust sensor
design game
w1:κ ,vv1:κ )
G := (ϒ, Γ,xx1 ,w
(11)
is a Stackelberg game between the leader PS and the follower
PC . Objectives of PC and PS are given by (7) and (8),
respectively. Then a tuple of strategies (η, {γ ω }ω∈Ωo ) attains
the Stackelberg equilibrium provided that

η ∈ argmin US η 0 , {γ ω (η 0 )}ω∈Ωo
(12a)
η 0 ∈ϒ


γ ω (η) ∈ argmin UCω η, γ(η) .

(12b)

γ∈Γ

where, by an abuse of notation, we denote type-ω PC ’s strategy γ ω by γ ω (η) to show its dependence on PS ’s signaling
rules due to the leader-follower scheme, explicitly.
Note that there might be multiple best responses by PC
for a signaling strategy. Correspondingly (12a) would not be
well defined if these best responses lead to different costs for
PS . However, as we will show later in detail, reaction set of
type-ω PC turns out to be an equivalence class such that all
γ ω in the reaction set lead to the same control input almost
surely, and correspondingly lead to the same cost for PS .
III. ROBUST S ENSOR D ESIGN F RAMEWORK
In this section, we consider the special case where PS has
access to perfect measurements, i.e., y k = x k for k = 1, . . . , κ;
the general noisy/partial measurements case will be addressed
later in Section IV. To compute the equilibrium of the game G ,
we first focus on best response strategy of PC for a given signaling strategy. This enables us to formulate the optimization
problem faced by PS to compute robust signaling strategies.
Even though this is a finite-dimensional optimization problem,
further inspection reveals that it is highly nonlinear and nonconvex. Therefore a generic approach would not be able
to address it globally. To mitigate this issue, we formulate
a tractable problem equivalent to the original optimization

problem. We can solve this tractable problem globally using
existing computational tools effectively. Given that solution,
we also show how we can compute the associated signaling
strategies. We now provide the details of these steps.
An important challenge in the design of encoding schemes
in control systems compared to communication systems is that
the underlying state depends on control inputs. To mitigate this
issue, we introduce control-free state {xxok } evolving according
to
wk ,
x ok+1 = Axxok +w
(13)
and x o1 = x 1 . As shown in [24], the routine technique of
completion of squares yields that
κ

∑ Ekxxk+1 k2Qω + Ekuuk k2Rω =
k=1

κ

∑ Ekuuok + Kkω x ok k2∆ωk + δ0ω ,

(14)

k=1

ω
where the matrices Kkω , ∆ω
k , and scalar δo are given by
−1 0 ω
Kkω = (∆ω
k ) B Q̃k+1 A
0 ω
ω
∆ω
k = B Q̃k+1 B + R
κ

δ0ω = Tr{Qω Σ1 } + ∑ Tr{Q̃ω
k+1 Σw }
k=1

{Q̃ω
k}

and
satisfies the following discrete-time dynamic Riccati
equation
ω
0
ω
ω
ω −1 0 ω
Q̃ω
k = Q + A (Q̃k+1 − Q̃k+1 B(∆k ) B Q̃k+1 )A
ω
o
and Q̃ω
κ+1 = Q . Furthermore u k depends on the control inputs
through the following transformation:

u ok = u k + Kkω Buuk−1 + . . . + Kkω Ak−2 Buu1 .
Note that ∆ω
k is positive definite for all k.
Contrary to team problems (where all decision makers have
the same objective), as studied in [24], in non cooperative
settings, (14) does not imply that a control input leading to
u ok = −Kkω E{xxok |ss1:k } is optimal since control inputs can have
an impact on the signals that will be generated in future
stages. However, as we will show below, PC cannot impact
the signals generated in future stages when PS uses linear plus
noise signaling strategies only. To show this, we let the gain
matrix Lk ∈ Rnk×m in signaling
strategy ηk , as described in (3),
 0
0
0
· · · Lk,1
be partitioned as Lk = Lk,k
, where Lk, j ∈ Rn×m .
Then, signal s k can be written as
0
0
0
0
ϑk
ϑ k = Lk,k
x 1 +ϑ
x ok + . . . + Lk,1
x o1 +ϑ
Lk,k
x k + . . . + Lk,1
n
o
0
k−2
0
0
+ Lk,k Buuk−1 + . . . + (Lk,k A + . . . + Lk,2 )Buu1 ,

where the term in-between {·} is σ -ss1:k−1 measurable. Similar
to5 [9, Lemma 12], this yields that
E{xxok |ss1:k } = E{xxok |sso1:k },

(15)

ϑ k . Correspondingly, since ∆ω
where we define s ok := Lk0 x o1:k +ϑ
k
is positive definite for all k, right-hand sides of (14) and (15)
yield that optimal reaction of type-ω PC is indeed the one
that leads to
(16)
u ok = −Kkω E{xxok |ss1:k },
5 We note that [9, Lemma 12] shows a result similar to (16) when the sender
selects only linear and memoryless signaling strategies.

6

almost everywhere over Rr , since E{xxok |ss1:k } does not depend
on u 1:k . This shows that all strategies in the best reaction set
of type-ω PC lead to (16) and therefore lead to the same cost
for PS .
Based on (16), the following lemma shows that we can
write the optimization objective in (8) as a linear function of
the covariance matrix of the posterior estimate of control-free
state, i.e.,6
Hk := cov{E{xxok |ss1:k }},
for k = 1, . . . , κ.
Lemma 1. The problem faced by PS , i.e., (12a), can be
written as
!

certain number of matrices, it is a highly nonlinear and nonconvex optimization problem due to the matrix inversion in
(18). Therefore it is difficult to obtain a global solution through
a generic attempt, e.g., genetic algorithm [25] or particle
swarm optimization [26]. On the other hand, the following
proposition shows that there is a computationally tractable
relationship between the covariance matrix and linear plus
noise signaling strategies.
Proposition 1 (A Necessary and Sufficient Condition). For
any signaling rule η ∈ ϒ, covariance matrix of posterior
estimate of the control-free state, {Hk = cov{E{xxok |ss1:k }}},
satisfies
Σo1  H1  O,

κ

min max

∑

η∈ϒ p∈∆(Ωo ) ω∈Ωo

pω

ω

ξ +∑

Tr {Hk Ξω
k}

,

(17)

k=1

where Ξω
k is a certain symmetric matrix, described in (50), that
does not depend on the optimization arguments, and ξ ω ∈ R,
described in (44) and (49), is a certain fixed scalar.
We emphasize that complexity of the objective functions (5)
ω
and (8) is buried in fixed parameters {{Ξω
k }, ξ }. Based on
this observation, we make the following remarks:
Remark 2 (Versatility of the results with respect to PC ’s
objective). The problem faced by PS is a linear function of the
covariance matrices {Hk } since optimal reaction of PC turns
out to be linear in the posterior estimate of the control-free
state, i.e., E{xxok |ss1:k }, as seen in (16). Therefore the results
henceforth hold for any other scenarios where PC has any
other objective in which optimal reaction of PC still turns
out to be a linear function of the posterior estimate. Note that
ω
we need to compute the associated {{Ξω
k }, ξ } accordingly.

Remark 3 (Versatility of the results with respect to PS ’s
objective). We motivate and consider the case where PS has
objective (8). However, the results henceforth would also hold
for scenarios where PS ’s objective is any other (convex or
non-convex) quadratic function of the state and control input.
ω
Note that we also need to compute the associated {{Ξω
k }, ξ }
accordingly.

Compared to original form of the optimization problem
(12a), the optimization problem (17) has a concrete structure
showing that the optimization function depends on the signaling strategy through the covariance matrix only, and it is a
linear function of the covariance matrix. Therefore it is instructive to study the relationship between the covariance matrix
and the signaling strategy. Since the underlying distributions
are all jointly Gaussian, we can express the covariance matrix
in closed form:
Hk = E{xxoks 01:k }E{ss1:ks 01:k }† E{xxoks 01:k }0

Σok

(19b)

Σo1  S1  O,

(20a)

Σok  Sk  ASk−1 A0 , for k > 1,

(20b)

there exists a (memoryless) linear-plus-noise signaling strategy8 η ∈ ϒ such that Sk = Hk .
In the following, we provide a description of signaling
strategies9 that lead to covariance matrices matching with a
given collection of positive semi-definite matrices S1:κ satisfying (35). To this end, we let


Λ̄k O 0
0
o
Σk − ASk−1 A = Ūk
Ū
O O k
t

k
be the eigen-decomposition such that Λ̄k ∈ S++
, where tk =
o
0
rank{Σk − ASk−1 A }. Furthermore, we let
 1/2 
h
i
Λ̄
1/2
0
0
Tk := Λ̄k
O Ūk (Sk − ASk−1 A )Ūk k
O

have the eigen-decomposition Tk = Uk ΛkUk0 with eigenvalues,
e.g., λk,1 , . . . , λk,tk . We note that λk,t turns out to be in [0, 1].
Then, the associated signaling strategy is given by
0
ϑ k,
s k = Lk,k
x k +ϑ

(21)

2 , . . . , θ 2 , 0, . . . , 0},
where ϑ k ∼ N (0, Θk ) with Θk = diag{θk,1
k,tk
and the gain matrix Lk,k is given by
 −1/2

o O
Λ̄
U
Λ
k
k
k
Lk,k = Ūk
,
O
O
o , . . . , λ o } is a diagonal matrix such that
where Λok := diag{λ1,1
1,tk
t
o , θ 2 } k satisfies
{λk,i
k,i i=1

(18)

o )2
(λk,i
o )2 + θ 2
(λk,i
k,i

= λk,i , ∀ i = 1. . . . ,tk .

the definition of Σok , we have Σok = AΣok A0 + Σw .
a signaling strategy is described in (21) later.
9 A derivation of the associated signaling strategies can be found in the
constructive proof of Proposition 1, which is provided in Appendix C.
7 By

we say “covariance matrix” instead of “covariance matrix of
posterior estimate of control-free state”, and we say “posterior” instead of
“posterior estimate of control-free state”.

 Hk  AHk−1 A , for k > 1,

where7 Σok := E{xxok (xxok )0 }.
Furthermore for any collection of positive semi-definite
matrices S1:κ satisfying

and the signal s k is given by (3). This yields that even though
computing robust signaling strategies would mean finding a
6 Henceforth

(19a)
0

8 Such

7

The following corollary to Proposition 1 provides a problem
equivalent to (17).
Corollary 1 (Equivalence Result). The problem faced by PS ,
i.e., (8), is equivalent to
!
κ

minm

max

∑ o pω

{Sk ∈S+ } p∈∆(Ωo ) ω∈Ω

ξ ω + ∑ Tr{Sk Ξω
k} ,

(22)

k=1

subject to the following linear matrix inequalities:
Σo1  S1  O
Σok

(23a)
0

 Sk  ASk−1 A , for k > 1.

(23b)

And given a solution S1:κ , an associated signaling strategy can
be computed according to (21).
Henceforth, we will be working with (22) instead of (17)
while analyzing the equilibrium of the game G . Furthermore,
for brevity of presentation, let us introduce


 ω

Sκ
Ξκ

 ω


..
..
S := 
 , Ξ := 
,
.
.
Ξω
1

S1

∑ o pω (ξ ω + Tr {SΞω }) .

S∈Ψ p∈∆(Ωo ) ω∈Ω

(24)

The following proposition addresses the existence of an
equilibrium for the game G .
Proposition 2 (Existence Result). There exists at least one
tuple of strategies (η, {γ ω (η)}ω∈Ωo ) attaining the equilibrium
of the Stackelberg game G , i.e., satisfying (12).
It is instructive to examine whether optimal signaling strategies end up using irrelevant information or not. The inner
optimization problem in (24)
max

∑

p∈∆(Ωo ) ω∈Ωo

pω (ξ ω + Tr{SΞω })

ω0

since the optimization objective in (24) is a linear function of
p ∈ ∆(Ωo ). Based on the observation (26) and the assumption
that the type set Ωo is finite, the following theorem provides
an algorithm to compute robust sensor outputs.
Theorem 1 (Computing the Equilibrium). The value of the
Stackelberg equilibrium (24) is given by µ = minω∈Ωo {µω },
where



µω := min ξ ω + Tr Ξω S
(27)
S∈Ψ

0
0
s.t. Tr S(Ξω − Ξω ) ≥ ξ ω − ξ ω ∀ω 0 ∈ Ωo .
Furthermore, let µω ∗ = µ and



S∗ ∈ argmin ξ ω + Tr Ξω S

(28)

S∈Ψ

and Ψ ⊂ Smκ
+ be the set corresponding to the constraints (23) in
this new high-dimensional space, i.e., Rmκ×mκ . With this new
notation, the problem faced by PS , i.e., (22), can be written
as
min max

according to (24), given S ∈ Ψ, maximizing p∗ ∈ ∆(Ωo ) is
given by

p∗ ∈ p ∈ ∆(Ωo ) | pω = 0 provided that

 0
0
(26)
(ξ ω + Tr{SΞω }) < max ξ ω + Tr{SΞω }

(25)

is a convex function of S ∈ Ψ since the maximum of any
family of linear/affine functions is a convex function [27].
Therefore, there might be examples where any extreme point
of the constraint set Ψ is not a solution for (24). Correspondingly, optimal signaling strategy can turn out to be including
irrelevant information. This is interesting in view of Blackwell’s Irrelevant Information Theorem [22, Theorem D.1.1].
Particularly, the theorem says that given a cost measure, for
any Borel measurable function that uses irrelevant information,
there exists another Borel measurable function that does not
use any irrelevant information and can lead to a cost less
than or equal to the one attained with the former function.
Therefore we can conclude that in this robust setting, linear
signaling strategies are not the best one within the general
class of measurable strategies.
Next, we seek to compute the equilibrium of G . To this end,
we examine the equilibrium conditions further. In particular,


0
0
s.t. Tr S(Ξω − Ξω ) ≥ ξ ω − ξ ω ∀ω 0 ∈ Ωo .
Then, given S∗ ∈ Ψ, an associated linear-plus-noise signaling
strategy η ∈ ϒ can be computed according to (21).
For the reader’s reference, in the following, we list the steps
to compute robust sensor design strategies:
• We first compute the matrices Ξω
k , described in (50),
and scalars ξ ω , described in (44) and (49), for each
type of control objectives, ω ∈ Ωo . This step includes
computation of gain matrices of optimal control input,
e.g., (16), in an LQG control problem.
ω
• Given computed {{Ξω
k , ξ }}, we solve SDP, described
in (27), for each type by using an SDP solver, e.g., [20],
[21], numerically.
• When we compute S∗ according to (28), we can compute the associated signaling strategies according to
(30). Note that this step includes computation of eigendecomposition of some matrices.
We re-emphasized that we provide an algorithm to compute
robust signaling strategies globally even though the problem
is highly nonlinear and non-convex. There is, however, still
room to develop computationally more efficient approaches.
And the solution concept proposed in the paper can be used as
a benchmark to evaluate performance of such computationally
efficient algorithms.
IV. N OISY OR PARTIAL M EASUREMENTS
In this section, we seek to obtain robust signaling strategies
under noisy or partial (i.e., imperfect) measurements of the
type (2). To this end, we turn the problem to the same structure
with the case under perfect measurements based on a recent
result from [28] and then invoke the results from the previous
section.
There are several challenges in robust sensor design under
imperfect measurements. For example, Proposition 1 does

8

not hold anymore. To obtain a result similar to Proposition
1, a first attempt would be to focus on the covariance matrix of the posterior estimate of control-free measurements,
i.e., cov{E{yyok |ss1:k }}, where y ok := Cxxok + v k , instead of Hk =
cov{E{xxok |ss1:k }}. Quite contrary to the control-free state {xxok },
however, control-free measurements {yyok } do not necessarily
constitute a Markov process since in general E{yyok |yyo1:k−1 } 6=
E{yyok |yyok−1 }. Therefore, we focus on the augmented vector of
measurements y o1:k ∈ Rnk .
Since the measurements are jointly Gaussian, we have
E{yyok |yyo1:k−1 } = E{yyok (yyo1:k−1 )0 }E{yyo1:k−1 (yyo1:k−1 )0 }†y o1:k−1 .
This implies that the augmented measurements {yy1:k }k≥0
evolve according to
y o1:k = Aky o1:k−1 +eek ,

(29)

where we define


E{yyok (yyo1:k−1 )0 }E{yyo1:k−1 (yyo1:k−1 )0 }†
Ak :=
,
I
 o

y − E{yyok |yyo1:k−1 }
ek := k
0

Lemma 2. Let us denote signaling strategies when s k ∈ Rnk
by η̃k and the associated strategy space by ϒ̃k . Then for any
{η̃k ∈ ϒ̃k }, there exists a {ηk ∈ ϒk } such that they both lead to
the same control strategy and correspondingly the same cost
for PS . And such a signaling strategy {ηk ∈ ϒk } is given by
ηk (yy1:k ) = E{xxok |η̃1 (yy1 ), . . . , η̃k (yy1:k )}, ∀k ≥ 1.

Note that neither Ak ∈ Rnk×n(k−1) nor e k ∈ Rnk depend on
signaling or control strategies. Furthermore, similar to (15),
it can be shown that
E{yyo1:k |ss1:k } = E{yyo1:k |sso1:k },

where we define10 Wkω := D0k Ξω Dk , which can be viewed
as the counterpart of Ξω
k under imperfect measurements. We
remark the resemblance between (17) and (32), where we have
Yk instead of Hk and Wkω instead of Ξω
k.
Recall that yk ∈ Rn , which yields that y1:k ∈ Rnk . Under
the assumption that sk ∈ Rnk instead of sk ∈ Rm (so that
PS can disclose the auxiliary y1:k perfectly), we would have
transformed the problem under imperfect measurements into
a problem under perfect measurements, and correspondingly
we could have invoked the results from the previous section
directly. The following lemma shows that results for the case
where s k ∈ Rnk would also hold for the case where s k ∈ Rm
even when nk > m.

(30)

(33)

Based on Lemma 2, the following corollary to Proposition
1 provides a tractable necessary and sufficient condition on
{Yk }.
Corollary 2 (A Necessary and Sufficient Condition Under
Imperfect Measurements). For any signaling rule η ∈ ϒ,
covariance matrix of posterior estimate of the control-free
measurements, {Yk = cov{E{yyo1:k |ss1:k }}}, satisfies
Σy1  Y1  O,

ϑ k.
where we now have s ok = Lk0 y o1:k +ϑ
Since s o1:k is σ -yy1:k measurable, x ok and s o1:k are independent
of each other conditioned on y o1:k . This implies that x ok , y o1:k ,
and s o1:k can be viewed as forming a Markov chain in the order
x ok → y o1:k → s o1:k . In that respect, [28, Lemma 1] shows that
when {xxok ,yyo1:k ,ss1:k } are jointly Gaussian and form a Markov
chain in the order x ok → y o1:k → s o1:k , there exists a linear relation
between E{xxok |sso1:k } and E{yyo1:k |sso1:k } irrespective of s o1:k , and
the relation is given by

where
:= E{yyo1:k (yyo1:k )0 }.
Furthermore for any collection of positive semi-definite
matrices S1:κ satisfying

E{xxok |sso1:k } = Dk E{yyo1:k |sso1:k },

there exists a linear-plus-noise signaling strategy η ∈ ϒ such
that Sk = Yk .

(31)

where Dk ∈ Rm×nk is defined by

Σyk

Under imperfect measurements, counterpart of the covariance matrix Hk = cov{E{xxok |ss1:k }} is the covariance matrix
of the posterior estimate of control-free augmented measurements, denoted by

Σy1  S1  O,
Σyk

for k > 1,

max

∑ o pω

p∈∆(Ωo ) ω∈Ω
{Sk ∈Skn
+}

Σyk

Correspondingly, (17), i.e., the problem faced by PS , can be
written as
!
κ

k=1

(35b)

κ

min

ξ ω + ∑ Tr {SkWkω } ,

(36)

k=1

Σy1  S1  O,

Hk = DkYk D0k .

η∈ϒ p∈∆(Ωo ) ω∈Ω

(35a)

 Sk  Ak−1 Sk−1 A0k−1 ,

Corollary 3. The problem faced by PS , i.e., (32), is equivalent
to
!

Based on (30) and (31), we have

ξ ω + ∑ Tr {YkWkω } ,

(34b)

subject to the following linear matrix inequalities:

Yk := cov{E{yyo1:k |ss1:k }}.

∑ o pω

for k > 1,

Σyk

The following corollary provides a problem equivalent to
(32).

Dk := E{xxok (yyo1:k )0 }E{yyo1:k (yyo1:k )0 }† .

min max

(34a)

 Yk  Ak−1Yk−1 A0k−1 ,

(32)

 Sk  Ak−1 Sk−1 A0k−1 ,

(37a)
for k > 1.

(37b)

Furthermore, given as solution {S1:κ } for (36), we can
compute an optimal signaling strategy for (32), as follows:
• Compute signaling strategies η̃ ∈ ϒ̃ as if signal s k can be
nk dimensional, i.e., s k ∈ Rnk , according to (21), where
10 We

use the cyclic property of the trace operator.

9

•

we have Σyk instead of Σok , Ak instead of A, and y 1:k instead
of x k .11
For computed η̃ ∈ ϒ̃, compute associated signaling strategies η ∈ ϒ according to (33).

We remark that under imperfect measurements optimal
signaling strategies are not necessarily memoryless anymore.
Through a similar notational convention as in the previous
section, we can write (36) as
min maxo

∑

S∈Ψ̄ p∈Ω ω∈Ωo

pω (ξ ω + Tr {SW ω }) ,

(38)

where we let Ψ̄ ⊂ Smκ(κ+1)/2 be the set corresponding to the
constraints (37). Then, based on Corollary 3, the following
corollary to Theorem 1 provides a computationally tractable
way to compute robust sensor outputs under imperfect measurements.
Corollary 4 (Computing the Equilibrium Under Imperfect
Measurements). The value of the Stackelberg equilibrium (38)
is given by µ = minω∈Ωo {µω }, where



µω := min ξ ω + Tr W ω S
(39)
S∈Ψ̄

0
0
s.t. Tr (W ω −W ω )S ≥ ξ ω − ξ ω ∀ω 0 ∈ Ωo .
Furthermore, let µω ∗ = µ and



S∗ ∈ argmin ξ ω + Tr W ω S

(40)

S∈Ψ̄


0
0
s.t. Tr (W ω −W ω )S ≥ ξ ω − ξ ω ∀ω 0 ∈ Ωo .
Then, given S∗ ∈ Ψ̄, an associated linear-plus-noise signaling
strategy η ∈ ϒ can be computed according to Corollary 3.
V. I LLUSTRATIVE E XAMPLES
In this section, we examine the performance of the proposed
defense measure over various attack scenarios. As an illustrative example, we set length of the time horizon at κ = 10,
dimension of state m = 2, and dimension of control input r = 2.
We consider the scenario where the system’s control objective
is to track an exogenous process {zzk } evolving according to

Correspondingly (41) can be written as
κ

∑ Ekx̃x̃k+1 k2Q + Ekuuk k2 ,
k=1

where




I2 
I
Q :=
−I2 2


−I2 .

As examples of attack scenarios, we consider a type set
Ω
 = {ωa , ω
0b , ωc }. Let us partition the underlying state x k =
0
x k,1 x k,2 and the exogenous process z k = z k,1 z k,2 ,
where x k,1 and z k,1 (or x k,2 and z k,2 ) correspond to the
first (or the second) entries of the state and the exogenous
process, respectively. We assume that type-ωa attacker seeks
to make {xxk,1 } track {−zzk,1 } instead of {zzk,1 } whereas it is not
interested in {xxk,2 }. Then its control objective can be written
as
κ

UCωa (η, γ ωa ) =

a
a 2
− (−zzk+1,1 )k2 + Ekuuω
∑ Ekxxωk+1,1
k k .

k=1

Similarly type-ωb attacker seeks to make {xxk,2 } track {−zzk,2 }
instead of {zzk,2 } whereas it is not interested in {xxk,1 }. Then
its control objective can be written as
κ

ω

UC b (η, γ ωb ) =

b
− (−zzk+1,2 )k2 + Ekuuk b k2 .
∑ Ekxxk+1,2

ω

ω

k=1

On the other hand, type-ωc attacker is interested in both
entries and seeks to make the entire state {xxk } track {−zzk }.
Accordingly, its control objective can be written as
UCωc (η, γ ωc ) =

wzk ∼ N (0, I2 )} is a white Gaussian
where z 1 ∼ N (0, I2 ), and {w
noise process, and they are independent of each other and
every other parameter. Correspondingly, the system’s control
objective can be written as
κ

o 2
o
−zzk+1 k2 + Ekuuω
∑ Ekxxωk+1
k k .

and augmented measurements are then given by

   
C O xk
v
ỹ k =
+ kz .
O Cz z k
vk

κ

wzk ,
z k+1 = Azz k +w

UCωo (η, γ ωo ) =

where {vvzk } is a white Gaussian measurement noise independent of every other parameter.
Note that the control objective is not in the form of (5);
however, we can transform it into
of (5) by intro the form
0
ducing the augmented state x̃k := x0k z0k evolving according
to

 
   
 
x k+1
I O xk
I
w
=
+
u k + zk
z k+1
O I zk
O
wk

(41)

k=1



1 1
while Σ1 = I2 and Σw = I2 .
0 1
The sensor has access to the measurements:

We set A = Az = I2 and B =

y k = Cxxk +vvk
y zk = Czz k +vvzk ,
11 We provide closed-form expressions for the auxiliary parameters Σy , A ,
k k
and Dk in Appendix G for the reader’s reference.

c
c 2
− (−zzk+1 )k2 + Ekuuω
∑ Ekxxωk+1
k k .

k=1

We note that numerical simulations show that mixtures of
types ωa , ωb and ωc can lead to larger costs for the system
than any single type, including type-ωc . In the following,
we examine the cost of PS under perfect and imperfect
measurements separately.
Under perfect measurements, the sensor has access to
ỹ k = x̃ k . Note that perfect measurements provide the utmost
freedom for PS to shape the belief of the attacker. For any
cost that PS can attain under imperfect measurements, PS
can select a signaling strategy under perfect measurements to
attain the same cost. Therefore, PS attains the lowest possible
cost under perfect measurements in the robust sensor design
framework.
In Table I, we tabulate the cost to PS for the scenarios
where i) there is no attack, i.e., type of PC is ωo ; ii) there

10

TABLE I: Under perfect measurements, i.e., ỹ k = x̃ k , comparison of the costs to PS , i.e., US as described in (8), over
various scenarios. Entries at each row corresponds to the cost
to PS for different types of PC when it constructs the sensor
outputs according to the extended type set Ωo . And the last
column provides the maximum cost of PS across all types of
PC .

TABLE II: Under imperfect measurements, comparison of the
costs to PS , i.e., US as described in (8), over various scenarios.
Entries at each row corresponds to the cost to PS for different
types of PC when it constructs the sensor outputs according
to the extended type set Ωo . And the last column provides the
maximum cost of PS across all types of PC .
Ωo

ωo

ωa

ωb

ωc

Max

Max

{ωo }

112.39

326.21

324.82

403.09

403.09

352.65

354.02

{ωa }

171.64

209.99

259.51

242.26

259.56

246.30

351.85

{ωb }

167.80

269.60

195.90

254.20

269.60

267.35

320.81

{ωc }

187.26

211.62

201.94

199.51

211.62

224.77

137.71

224.77

{ωo , ωa }

171.40

209.99

260.40

242.97

260.40

191.12

351.11

245.95

351.11

{ωo , ωb }

167.53

270.40

195.90

255.04

270.40

115.29

321.56

185.63

267.93

321.56

{ωo , ωc }

187.26

211.62

201.94

199.51

211.62

{ωo , ωc }

106.26

202.40

224.77

137.71

224.77

{ωo , ωa , ωb , ωc }

185.48

210.00

210.00

202.77

210.00

{ωo , ωa , ωb , ωc }

81.17

199.46

199.46

166.68

199.46

Ωo

ωo

ωa

ωb

{ωo }

43.03

323.70

354.02

{ωa }

122.31

191.12

351.85

{ωb }

119.09

320.81

185.63

{ωc }

106.26

202.40

{ωo , ωa }

119.65

{ωo , ωb }

ωc

is an attack by type-ωa attacker, i.e., type of PC is ωa ; iii)
there is an attack by type-ωb attacker, i.e., type of PC is ωb ;
and iv) there is an attack by type-ωc attacker, i.e., type of PC
is ωc . Cost to PS varies depending on the type of PC and
how prepared PS is while constructing the sensor outputs. In
other words, PS constructs the sensor outputs according to an
extended type set.
For example, PS would have constructed signaling strategies according to Ωo = {ωo } if it views that there would not
be any attack. Correspondingly, if there is no attack, then the
cost would be 43.03. However, if there is an attack by, e.g.,
type-ωb attacker, then the cost would be 354.02, which is
significantly higher compared to 43.03. Next, consider that PS
has constructed the sensor outputs according to Ωo = {ωb }.
Then, the system would be prepared against an attack by
type-ωb attacker, and the cost would be 185.63 when typeωb attacker attacks. This is significantly lower than the cost
354.02 obtained when PS constructs sensor outputs without
any concern about possible attacks. However, now the cost
to PS is 119.09 if there is no attack and the type of PC is
ωo . This is also higher than the cost 43.3 obtained when PS
constructs sensor outputs without any concern about possible
attacks. It is an uncertainty whether there will be an attack
or not. Correspondingly, if PS constructs the sensor outputs
according to Ωo = {ωo , ωb }, then the cost would be 115.29
when there is no attack. It is lower than the cost 119.09
obtained before. On the other hand, the cost would still be
around 185.63 when type-ωb attacker attacks the system.
Even though PS is prepared to an attack by type-ωb attacker
by constructing the sensor outputs according to Ωo = {ωo , ωb },
there can be an attack by another type attacker, e.g., type-ωa .
Then the cost would be 321.56, which is significantly higher
than the cost 185.63 that would be obtained when type-ωb
attacker attacks. The system can decrease this cost by also
considering the possibility of attacks by type-ωa attacker while
constructing the sensor outputs. For example, if PS constructs
the sensor outputs by taking into account types ωa , ωb , and
ωc attacks, then the cost would be at most 199.46 if any of

those types of attacks occurs and the cost would be 81.17 if
there is no attack. These examples show the importance of
constructing sensor outputs in a robust way.
As an example for imperfect measurements, we take y k =
x k,1 + x k,2 + v k , where v k ∼ N (0, 1), and y zk = z k + v zk , where
{vvzk ∼ N (0, I2 )}. In Table II, we tabulate the costs to PS
over various scenarios, similar to Table I. Table II shows that
imperfect measurements lead to larger cost for the system
when there is no attack, as to be expected. However, at
certain scenarios, imperfect measurements can lead to better
performance for the system. For example, when PS constructs
sensor outputs by considering that there would not be any
attack, i.e., according to Ωo = {ωo }, and there is an attack by
type-ωb attacker, the cost would be 324.82, which is lower
than the cost 354.02 obtained under perfect measurements.
For this scenario, imperfect measurements end up obfuscating
type-ωb attacker and lead to lower cost. In that respect, robust
sensor outputs can be viewed as optimal imperfect measurements that lead to minimum cost for the system. Furthermore,
the cost to PS increases under imperfect measurements over
the scenarios where it is prepared. In Table II, we highlight
those scenarios by shading their cells. A comparison of shaded
cells of Tables I and II verifies the observation emphasized
above, i.e., imperfect measurements limit PS ’s ability to
persuade PC .
VI. C ONCLUDING REMARKS
In this paper, we have proposed and addressed persuasionbased robust sensor design as a security measure in control
systems against attackers with unknown control objectives.
By designing sensor outputs cautiously in advance, we have
sought to shape attackers’ believes about the underlying state
of the system in order to induce them to act/attack to the
system in line with the system’s normal operation. We have
modeled the problem formally under the solution concept
of Stackelberg equilibrium where the defender/sensor is the
leader. Non-strategic reaction of the follower/attacker implies
that the defender faces an optimization problem while seeking
to design robust sensor strategies. We have shown that the

11

optimization problem is non-convex and highly nonlinear. To
mitigate this issue, we have formulated a tractable problem
equivalent to that problem and shown how to compute the associated signaling strategies. We have also extended the results
to scenarios where there are imperfect measurements of the
underlying state. Finally, we have examined the performance
of the proposed framework across various attack scenarios.
Future directions of research on this topic include development of computationally efficient algorithms to compute
optimal signaling rules and developing persuasion-based sensor design strategies for scenarios where attackers have partial
information about the underlying state dynamics instead of full
knowledge of it or have side information about the state instead
of relying on sensor outputs only. Another interesting research
direction would be its application on sensor placement or
sensor selection.
Furthermore, even though we have motivated the framework
by relating it to security, the framework could also address
strategic information disclosure over multi-agent control networks where agents have different control objectives. Particularly, independent of how we motivate and set up the signaling
problem (e.g., a security application or a multi-agent noncooperative control network), the solution concept developed
can be adopted in various settings in a straightforward way
provided that
• Information of interest and all random variables/vectors
are jointly Gaussian
• There is a single sender and possibly multiple receivers
• Optimal reaction of each receiver is linear in its posterior
belief
• The sender’s objective depends on receivers’ reactions
only through an arbitrary quadratic function of their
posterior beliefs
In this paper, we have used this result to address uncertainties
regarding attackers’ (or receivers’) objectives in the security
of control systems over a finite horizon. However, the result
could be adopted in several other scenarios as well, such as:
• over infinite horizon (as we did in [29])
• when there are additional tractable constraints on the
covariance of the posterior belief (as we did in [28] for
a power constraint over the signals when there is an
additive Gaussian noise channel between the sender and
the receiver)
Furthermore, the ability to turn signaling problems (which
lead to highly nonlinear and non-convex optimization problems) into linear optimization problems (over the space of
positive-semi definite matrices with linear matrix inequality
constraints) facilitates analysis of problems over more complex
settings, e.g., where
• There can be multiple controllers seeking to drive the
same system
• There can be multiple senders that compete with each
other to induce a controller to take certain actions
A PPENDIX A
N OVELTY R ELATIVE TO R EFERENCE [9]
In Reference [9], we formulated an SDP equivalent to the
original optimization problem in scenarios where there is no

uncertainty on the attacker’s objective. Although it may seem
to have a similar flavor, in [9] we used different technical tools
and these tools cannot be adopted for the settings of this paper.
Particularly, in [9] we exploited the fact that a solution of a
linear optimization problem over a compact convex set lies at
extreme points12 of the constraint set. Even though we were
able to characterize the extreme points of the constraint set
for the specific optimization problem in [9], characterization
of extreme points is challenging in general, e.g., see [30].
Furthermore, in the settings of this paper, the associated
optimization problem includes an inner maximization induced
by the sensor’s robustness concern. Therefore the techniques
developed in [9] cannot be used in this setting since the objective function is no longer linear in the optimization arguments
due to the inner maximization. It is indeed a convex function
since maximum of any family of linear/affine functions is a
convex function [27]. Correspondingly, the solution does not
necessarily lie at an extreme point of the constraint set. To be
able to solve this optimization problem globally, in this paper
we have shown that those linear matrix inequalities provide not
only necessary but also sufficient conditions. This leads to a
more comprehensive solution concept since it can be adopted
in other sensor design settings in a straightforward way in
order to obtain an equivalent tractable optimization problem,
e.g., for the settings over imperfect measurements as we did
here, infinite horizon as shown in [29] (based on the results
of this paper), and several others.
A PPENDIX B
P ROOF OF L EMMA 1
Based on (16) and (12a), we obtain (17) through some
algebra as detailed below. We focus on i) part of the cost
induced by the controller of the system, e.g., (9), and ii) part
of the cost induced by the attacker, e.g., (10), separately.
Part-i) For notational brevity, let us first introduce the
following matrices


I Kκω B Kκω AB · · · Kκω Aκ−2 B
ω B · · · K ω Aκ−3 B

I
Kκ−1
κ−1


ω Aκ−4 B

ω
I
· · · Kκ−2
Φ := 



..
..


.
.
I
 ω

 ω

Kκ
∆κ
 ω



..
..
K ω := 
 , ∆ := 
.
.
.
K1ω

∆ω
1

Then, the right hand side of (14) can be written in a compact
form as
kΦω u + K ω x o k2∆ω + δ0ω

0
in terms of the augmented vectors u = u0κ · · · u01 and


0
x o = (xxoκ )0 · · · (xxo1 )0 . Correspondingly, for type-ω PC ,
we obtain
u ω = −(Φω )−1 K ω x̂ o ,
(42)
12 We say that a point in a convex set is an extreme point if it cannot be
expressed as a convex combination of any other two points in the set.

12


0
where x̂ o := E{xxoκ |ss1:κ }0 · · · E{xxo1 |ss1 }0 is the augmented
vector of posteriors. Related to (9), this yields
κ

ωo o
o
o 2
x − x̂ o )k2∆ωo + δoωo
k2Qωo + Ekuuω
∑ Ekxxωk+1
k kRωo = EkK (x
k=1

= Tr{HV ωo } + ξ ωo ,

A PPENDIX C
P ROOF OF P ROPOSITION 1
The necessity condition has been shown in [9, Lemma 3].
In order to show the sufficiency of the condition, suppose
that a collection of positive semi-definite matrices S1:κ satisfying (35) is given. Then S1 ∈ Sm satisfies
Σo1  S1  O.

where we define Σo := E{xxo (xxo )0 },
V ωo := −(K ωo )0 ∆ωo K ωo ,

(43)

ξ ωo := δoωo − Tr{Σo Ξωo },

(44)

and H := E{x̂x̂o (x̂x̂o )0 }, which follows since E{xxo (x̂x̂o )0 } =
E{x̂x̂o (x̂x̂o )0 } due to the law of iterated expectations.
Part-ii) The state x k can be written in terms of control-free
state x ok and control inputs u 1:k as follows:
k−2

wk−1 + ∑ Ai Buuk−i−1 .
x k = Axxok−1 +w

(45)

i=0

Let us define

B


Z := 


AB
B

···
···
..
.


Aκ−1 B
Aκ−2 B

..  .
. 
B

Then (42) and (45) yield that for ω ∈ Ω, we have
κ

∑ Ekxxωk+1 k2Qωo = EkĀxxo +ww − T ω x̂ o k2Q̄ωo

(46)

k=1

= Tr{HV ω } + ξ ω ,
(47)
 0

0
where w := w κ · · · w 01 , Ā := Iκ ⊗ A, T ω := Z(Φω )−1 K ω ,
ω
ω
Q̄ o = Iκ ⊗ Q o , and for all ω ∈ Ω we define
V ω := (T ω )0 Q̄ωo T ω − (T ω )0 Q̄ωo Ā − Ā0 Q̄ωo T ω ,
ω

o 0

ωo

ωo

ξ := Tr{Σ Ā Q̄ Ā} + κTr{Σw Q }.

(48)
(49)

wk } is a white noise and T ω
Note that (47) follows since {w
turns out to be an upper triangular (block) matrix.
Combining Parts i) and ii) together, we obtain that PS faces
the following problem:

∑

pω (Tr{HV ω } + ξ ω ),

ω∈Ωo

where V ω and ξ ω for ω ∈ Ωo are as described in (43), (44),
(48), and (49). Based on the definition of H, it can be shown
that


Hκ
AHκ−1
· · · Aκ−1 H1
 Hκ−1 A0
Hκ−1
Aκ−2 H1 


H =
..
..  .
..

.
.
. 
κ−1
0
κ−2
0
H1 (A ) H1 (A ) · · ·
H1
m
Therefore, the corresponding Ξω
k ∈ S in (17) is defined by
κ
ω
Ξω
k := Vk,k +

∑

ω l−k
ω
Vk,l
A + (Al−k )0Vl,k
,

(50)

l=k+1
ω ∈ Rm×m is an m × m block of V ω , with indexing
where Vk,l
from the right-bottom to the left-top.

(51)

o
o
Note
 that Σ1  O can be singular. Therefore let Σ1 =
Λ̄1 O 0
Ū1
Ū be the eigen-decomposition such that Λ̄1 ∈
O O 1
t1
S++ and t1 := rank{Σo1 }. When we multiply the terms in (51)
from right by the unitary matrix Ū1 and from left by the
transpose of the unitary matrix, i.e., Ū10 , we obtain


Λ̄1 O
 Ū10 S1Ū1  O,
O O

which implies that

Λ̄1
O

 

O
M1,1 M1,2
−
 O,
(52)
O
M2,1 M2,2


M1,1 M1,2
where we let Ū10 S1Ū1 =
be the corresponding
M2,1 M2,2
t
partitioning, e.g., M1,1 ∈ S 1 .
Since Ū10 S1Ū1  O, we have M2,2  O [31, Observation
7.1.2]. However, the bottom-right block of the positive semidefinite matrix (the whole term) on the left-hand-side of the
inequality (52), i.e., −M2,2 , must also be a positive semidefinite matrix, which implies O  M2,2 . Therefore we can
conclude that M2,2 = O.
0 = O.
Next we invoke [32, Lemma 3] yielding M1,2 = M2,1
Therefore (52) can be written as

 

Λ̄1 O
M
O
− 1,1
 O.
(53)
O O
O
O
−1/2

−1/2

We define T1 := Λ̄1 M1,1 Λ̄1 , let T1 = U1 Λ1U10 be its eigendecomposition, and let λ1,1 , . . . , λ1,t1 be its eigenvalues. Then
(53) yields that It1  T1  Ot1 and correspondingly It1  Λ1 
O, which implies that λ1,i ∈ [0, 1] for all i = 1, . . . ,t1 .
1/2
1/2
Since M1,1 = Λ̄1 T1 Λ̄1 , M1,2 = M2,1 = O, and M2,2 = O,
S1 can be written as
 1/2

1/2
O Ū 0 .
(54)
S1 = Ū1 Λ̄1 T1 Λ̄1
O
O 1
1
Since Λ̄1 ∈ St++
is not a singular matrix, (54) yields that there
exists a bijective relation between S1 ∈ Sm and T1 ∈ St1 , i.e.,
given S1 , we can compute T1 and vice versa. Therefore, we
can just focus on T1 instead of S1 . To this end, consider a
ϑ 1 , where ϑ 1 ∼ N(0, Θ1 ). Then,
signaling strategy s 1 = L10 x 1 +ϑ
the covariance matrix H1 is given by

H1 = Σo1 L1 (L10 Σo1 L1 + Θ1 )† L10 Σo1 .

(55)

Note that we can set L1 ∈ Rm×m and Θ1 ∈ Sm
+ arbitrarily. Given
theeigenvalues of T1 ; it can be verified that if we set L1 =
−1/2
o
Ū1 Λ̄1 U1 Λ1 O and Θ1  O such that
O
O
o
o
Λo1 = diag{λ1,1
, . . . , λ1,t
},
1
2
2
Θ1 = diag{θ1,1
, . . . , θ1,t
, 0, . . . , 0}
1

13

o , θ 2 } satisfy
and the entries {λ1,i
1,i
o )2
(λ1,i
o )2 + θ 2
(λ1,i
1,i

= λ1,i , for i = 1, . . . ,t1 ,

(56)

then we obtain H1 = S1 exactly. Particularly, for such L1,1
and Θ1 , eigen-decomposition of Σo1 yields that L10 Σ1 L1 can be
written as




 −1/2



−1/2
Λ̄1 O 0
Λo1U10
Λ̄1
O 0
Λ̄1 
U
Λo1 O

1

Ū Ū1
Ū Ū1
O O 1
O
O 1
O
O
 o 2

(Λ̄1 ) O
=
O
O
since unitary matrices satisfy Ū1Ū10 = Ū10 Ū1 = I. On the other
hand, Σo1 L1 can be written as

 −1/2


 1/2

o
o
Λ̄ O 0
Ū1 1
Ū1Ū1 Λ̄1 U1 Λ1 O = Ū1 Λ̄1 U1 Λ1 O .
O O
O
O
O
O
Therefore Σo1 L1 (L10 Σo1 L1 + Θ1 )† L10 Σo1 can be written as
 1/2
 o 2
† 

1/2
o
(Λ̄1 ) + Θ1 O
Λo1U10 Λ1
O Ū 0
Ū1 Λ̄1 U1 Λ1 O
O
O
O
O
O
O 1
 1/2

0 1/2 O
= Ū1 Λ̄1 U1 Λ1U1 Λ1
Ū 0 , (57)
O
O 1
which follows from (56). Recall that T1 = U1 Λ1U10 . Therefore
(57) is equivalent to (54), which verifies the claim. Note also
o , θ 2 } satisfying (56) since λ ∈
that there always exist {λ1,i
1,i
1,i
[0, 1] for all i = 1, . . . ,t1 .
We have shown that given S1 ∈ Sm satisfying (51), we can
select a signaling strategy such that H1 = S1 exactly. Next, by
following similar lines, we compute the associated signaling
strategies for k > 1 under the assumption that we have obtained
them up to k − 1.
Suppose that H j = S j for j < k. Then, Sk ∈ Sm satisfies
Σok  Sk  ASk−1 A0 ,
which is equivalent to
Σok − AHk−1 A0  Sk − AHk−1 A0  O.

(58)

0
Correspondingly, Σok − AHk−1
 A  O can be singular. Let
Λ̄
O
Σok − AHk−1 A0 = Ūk k
Ū 0 be the eigen-decomposition
O O k
tk
such that Λ̄k ∈ S++
and tk := rank{Σok − AHk−1 A0 }. When we
multiply the terms in (58) from right by the unitary matrix Ūk
and from left by the transpose of the unitary matrix, i.e., Ūk0 ,
we obtain


Λ̄k O
 Ūk0 (Sk − AHk−1 A0 )Ūk  O.
(59)
O O

Following the same reasons for the case k = 1, [32, Lemma 3]
yields that there exists a symmetric matrix Tk ∈ Stk such that
 1/2

1/2
Λ̄
T
Λ̄
O
0
k
k
Sk = AHk−1 A + Ūk k
Ū 0
(60)
O
O k
and there exists a bijective relation between Tk and Sk −
AHk−1 A0 . Similarly, (59) and (60) yield that Itk  Tk  Otk ,
which implies that Tk ∈ Stk has eigenvalues in the closed

interval [0, 1]. Let Tk = Uk ΛkUk0 be the eigen decomposition
and λk,1 , . . . , λk,tk ∈ [0, 1] be the associated eigenvalues.
Furthermore, consider a signaling strategy s k = Lk0 x k + ϑ k ,
where ϑ k ∼ N(0, Θk ). Then, the covariance matrix Hk is given
by
Hk = AHk−1 A0 + (Σok − AHk−1 A0 )Lk
×(Lk0 (Σok − AHk−1 A0 )Lk + Θk )† Lk0 (Σok − AHk−1 A0 ),
which follows since
cov{E{xxok |ss1:k }} = cov{E{xxok |ss1:k−1 }}
+ cov{E{xxok |ssk − E{ssk |ss1:k−1 }}},
due to the independence of the jointly Gaussian s 1:k−1 and
s k − E{ssk |ss1:k−1 }. We can again set Lk ∈ Rm×m and Θk ∈ Sm
+
arbitrarily. Given 
the eigenvalues of
Tk , it can be verified that

−1/2
o
if we set Lk = Ūk Λ̄k Uk Λk O and Θk  O such that
O
O
o
o
, . . . , λk,t
},
Λok = diag{λk,1
k
2
2
Θk = diag{θk,1
, . . . , θk,t
, 0, . . . , 0}
k
o , θ 2 } satisfy
and the entries {λk,i
k,i
o )2
(λk,i
o )2 + θ 2
(λk,i
k,i

= λk,i , for i = 1, . . . ,tk ,

then we would obtain Hk = Sk exactly. Therefore, by induction,
we conclude that for any S1:κ satisfying (35), there exists a
certain signaling strategy η ∈ ϒ such that Hk = Sk for all k =
1, . . . , κ.
A PPENDIX D
P ROOF OF P ROPOSITION 2
Since the objective function in (24) is continuous in the
optimization arguments, and the constraint sets are decoupled
and compact, the extreme value theorem and maximum theorem (showing the continuity of parametric maximization under
certain conditions [33]) yields the existence of a solution to
(24).
A PPENDIX E
P ROOF OF T HEOREM 1
Based on the existence result in Proposition 2, suppose that
S∗ solves (24) and p∗ is the maximizer of (25) for S∗ . Since
p∗ ∈ ∆(Ωo ), there must be at least one type with positive
weight. For example, suppose positive weight for the type
ω ∈ Ωo , i.e., pω > 0. This implies that
0

0

ξ ω + Tr{S∗ Ξω } ≥ ξ ω + Tr{S∗ Ξω } ∀ω 0 ∈ Ωo
 0

0
since ξ ω +Tr{S∗ Ξω } = maxω 0 ∈Ωo ξ ω + Tr{S∗ Ξω } by (26).
Furthermore, this also implies that
 0

0
ξ ω + Tr{S∗ Ξω } = ∑ p∗ω 0 ξ ω + Tr{S∗ Ξω }
ω 0 ∈Ωo

14

0

0

since ξ ω + Tr{S∗ Ξω } = ξ ω + Tr{S∗ Ξω } if p∗ω 0 > 0. These
necessary conditions yield that (24) is equivalent to
min [ξ ω + Tr{SΞω }]
S∈Ψ

0

0

s.t. Tr{S(Ξω − Ξω )} ≥ ξ ω − ξ ω ∀ω 0 ∈ Ωo
which is an SDP isolated from the distribution over the
extended type set. Therefore, by searching over the extended
type set Ωo , we can compute the minimum of (24), which is
the minimum over Ωo . Once the minimum value is computed,
S∗ can be computed according to the corresponding type, i.e.,
(28).
A PPENDIX F
P ROOF OF L EMMA 2
For a signaling strategy as described in (33), we would have
E{xxok |η1 (yy1 ), . . . , ηk (yy1:k )}
= E{xxok |E{xxo1 |η̃1 (yy1 )}, . . . , E{xxok |η̃1 (yy1 ), . . . , η̃k (yy1:k )}}
= E{xxok |η̃1 (yy1 ), . . . , η̃k (yy1:k )},
where the last line follows since E{xxol |η̃1 (yy1 ), . . . , η̃l (yy1:l )}, for
l ≤ k, is just a measurable function of {η̃1 (yy1 ), . . . , η̃l (yy1:l )}}
while E{xxok |η̃1 (yy1 ), . . . , η̃k (yy1:k )} is already conditioned on
{η̃1 (yy1 ), . . . , η̃k (yy1:k )}. This yields that they both would lead
to the same posterior. Recall that the best reaction of PC is
linear function of E{xxok |ss1:k } as described in (16). Therefore
they both would lead to the same control inputs almost surely
and therefore the same cost for PS .
A PPENDIX G
C LOSED -F ORM E XPRESSIONS FOR AUXILIARY
PARAMETERS U NDER I MPERFECT M EASUREMENTS
Note that Σyk ∈ Snk , Ak ∈ Rnk×n(k−1) , and Dk ∈ Rm×nk can
be written as




O
Σyk = O Ik ⊗C Σo
+ Ik ⊗ Σv ,
Ik ⊗C0




 o

O
y
†
O
C
O
Σ
(Σ
)
n×(k−1)n
k−1  ,
Ik−1 ⊗C0
Ak =  n×(κ−k)n
I(k−1)n



 o
O
Dk = Om×(κ−k)m Im Om×(k−1)m Σ
(Σyk )† .
Ik ⊗C0
R EFERENCES
[1] J. Giraldo, E. Sarkar, A. A. Cardenas, M. Maniatakos, and M. Kantarcioglu, “Security and privacy in cyber-physical systems: A survey of
surveys,” IEEE Design & Test, vol. 34, pp. 7–17, 2017.
[2] A. Humayed, J. Lin, F. Li, and B. Luo, “Cyber-physical systems security
– A survey,” IEEE Internet of Things Journal, vol. 4, no. 6, 2017.
[3] N. Nelson, “The impact of Dragonfly malware on industrial control
systems,” The SANS Institute, 2016.
[4] V. Crawford and J. Sobel, “Strategic information transmission,” Econometrica, vol. 50, no. 6, pp. 1431–1451, 1982.
[5] E. Kamenica and M. Gentzkow, “Bayesian persuasion,” American Economic Review, vol. 101, pp. 25 090–2615, 2011.
[6] T. Başar and G. J. Olsder, Dynamic Noncooperative Game Theory.
Society for Industrial Mathematics (SIAM) Series in Classics in Applied
Mathematics, 1999.
[7] E. Kamenica, “Bayesian persuasion and information design,” Annual
Review of Economics, vol. 11, 2019.

[8] W. Tamura, “A theory of multidimensional information disclosure,”
Working paper, available at SSRN 1987877, 2014.
[9] M. O. Sayin, E. Akyol, and T. Başar, “Hierarchical multistage Gaussian
signaling games in noncooperative communication and control systems,”
Automatica, vol. 107, pp. 9–20, 2019.
[10] Y. Liu, P. Ning, and M. K. Reiter, “False data injection attacks against
state estimation in electric power grids,” ACM Trans. Information and
System Security, vol. 14, no. 1, 2009.
[11] Y. Mo and B. Sinopoli, “Integrity attacks on cyber-physical systems,”
in Proc. 1st ACM Int. Conf. High Confidence Networked Systems, 2012,
pp. 47–54.
[12] ——, “On the performance degradation of cyber-physical systems under
stealthy integrity attacks,” IEEE Trans. Autom. Control, vol. 61, no. 9,
pp. 2618–2624, 2016.
[13] Y. Chen, S. Kar, and J. M. F. Moura, “Cyber physical attacks with
control objectives and detection constraints,” in Proc. 55th IEEE Conf.
on Decision and Control (CDC), 2016, pp. 1125–1130.
[14] ——, “Cyber physical attacks constrained by control objectives,” in
Proc. Americal Control Conference (ACC), 2016, pp. 1185–1190.
[15] R. Zhang and P. Venkitasubramaniam, “Stealthy control signal attacks
in linear quadratic Gaussian control systems: Detectability reward tradeoff,” IEEE Trans. Inf. Forensics and Security, vol. 12, no. 7, pp. 1555–
1570, 2017.
[16] M. O. Sayin and T. Başar, “Secure sensor design for cyber-physical
systems against advanced persistent threats,” in Proceedings of International Conference on Decision and Game Theory for Security on Lecture
Notes in Computer Science, S. Rass, B. An, C. Kiekintveld, F. Fang, and
S. Schauder, Eds., vol. 10575. Vienna, Austria: Springer, Oct. 2017,
pp. 91–111.
[17] ——, “Secure sensor design against undetected infiltration: Minimum
impact-minimum damage,” arXiv:1801.01630, 2018.
[18] F. Miao, Q. Zhu, M. Pajic, and G. J. Pappas, “Coding schemes for
securing cyber-physical systems against stealthy data injection attacks,”
IEEE Trans. Autom. Control, vol. 4, no. 1, pp. 106–117, 2017.
[19] P. R. Kumar and P. Varaiya, Stochastic Systems. Prentice-Hall, 1986.
[20] M. Grant and S. Boyd, “CVX: Matlab software for disciplined convex
programming, version 2.1,” http://cvxr.com/cvx, mar 2014.
[21] ——, “Graph implementations for nonsmooth convex programs,” in
Recent Advances in Learning and Control. Springer-Verlag Limited,
2008, pp. 95–110.
[22] S. Yüksel and T. Başar, Stochastic Networked Control Systems.
Birkhäuser/Springer, 2013, vol. 10.
[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. WileyInterscience, 2006.
[24] R. Bansal and T. Başar, “Simultaneous design of measurement and
control strategies for stochastic systems with feedback,” Automatica,
vol. 25, no. 5, pp. 679–694, 1989.
[25] J. Sadeghi, S. Sadeghi, and S. T. A. Niaki, “Optimizing a hybrid vendormanaged inventory and transportation problem with fuzzy demand: An
improved particle swarm optimization algorithm,” Information Sciences,
vol. 272, pp. 126–144, 2014.
[26] J. Kennedy and R. Eberhart, “Particle swarm optimization,” in Proc.
IEEE Int. Conf. Neural Networks, 1995, pp. 1942–1948.
[27] S. Boyd and L. Vandenberghe, Convex Optimization.
Cambridge
University Press, 2004.
[28] M. O. Sayin and T. Başar, “Deceptive multi-dimensional information
disclosure over a Gaussian channel,” in Proceedings of the American
Control Conference (ACC), 2018, pp. 6545–6552.
[29] ——, “On the optimality of linear signaling to deceive Kalman filters
over finite/infinite horizons,” in Proceedings of International Conference
on Decision and Game Theory for Security on Lecture Notes in Computer Science, T. Alpcan, Y. Vorobeychik, J. S. Baras, and G. Dan, Eds.,
vol. 11836. Stockholm, Sweden: Springer, 2019, pp. 459–478.
[30] M. Jerison, “A property of extreme points of compact convex sets,” Proc.
Amer. Math. Soc., vol. 5, pp. 782–783, 1954.
[31] R. A. Horn and C. R. Johnson, Matrix Analysis. Cambridge University
Press, 1985.
[32] M. O. Sayin and T. Başar, “Dynamic information disclosure for deception,” in Proceedings of the 57th IEEE Conference on Decision and
Control (CDC), 2018, pp. 1110–1117.
[33] E. Ok, Real Analysis with Economics Applications. Princeton University
Press, 2007.

15

Muhammed O. Sayin received the B.S. and M.S. degrees in electrical and
electronics engineering from Bilkent University, Ankara, Turkey, in 2013 and
2015, respectively. He received the Ph.D. degree in electrical and computer
engineering from the University of Illinois at Urbana-Champaign (UIUC) in
2019. He is currently a Postdoctoral Associate at Laboratory for Information
and Decision Systems (LIDS) at MIT. His current research interests include
dynamic games and decision theory, information design problems, and multiagent systems.

Tamer Başar (S’71-M’73-SM’79-F’83-LF’13) is with the University of
Illinois at Urbana-Champaign, where he holds the academic positions of
Swanlund Endowed Chair; Center for Advanced Study Professor of Electrical
and Computer Engineering; Research Professor at the Coordinated Science
Laboratory; and Research Professor at the Information Trust Institute. He is
also the Director of the Center for Advanced Study.
He received B.S.E.E. from Robert College, Istanbul, and M.S., M.Phil, and
Ph.D. from Yale University. He is a member of the US National Academy
of Engineering, member of the European Academy of Sciences, and Fellow
of IEEE, IFAC (International Federation of Automatic Control) and SIAM
(Society for Industrial and Applied Mathematics), and has served as president
of IEEE CSS (Control Systems Society), ISDG (International Society of
Dynamic Games), and AACC (American Automatic Control Council). He has
received several awards and recognitions over the years, including the highest
awards of IEEE CSS, IFAC, AACC, and ISDG, the IEEE Control Systems
Award, and a number of international honorary doctorates and professorships.
He has over 900 publications in systems, control, communications, and
dynamic games, including books on non-cooperative dynamic game theory,
robust control, network security, wireless and communication networks, and
stochastic networked control. He was the Editor-in-Chief of Automatica
between 2004 and 2014, and is currently editor of several book series. His
current research interests include stochastic teams, games, and networks;
distributed algorithms; security; and cyber-physical systems.

