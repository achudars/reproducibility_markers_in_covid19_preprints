A Hybrid Traffic Speed Forecasting Approach Integrating Wavelet Transform
and Motif-based Graph Convolutional Recurrent Neural Network
1,2

Na Zhang1, Xuefeng Guan2*, Jun Cao3, Xinglei Wang4, Huayi Wu5
State Key Laboratory of Information Engineering in Survey, Mapping and Remote Sensing,
zngis@whu.edu.cn, guanxuefeng@whu.edu.cn

Abstract
Traffic forecasting is crucial for urban traffic management and guidance. However, existing methods
rarely exploit the time-frequency properties of traffic speed observations, and often neglect the propagation of traffic flows from upstream to downstream road segments. In this paper, we propose a
hybrid approach that learns the spatio-temporal
dependency in traffic flows and predicts short-term
traffic speeds on a road network. Specifically, we
employ wavelet transform to decompose raw traffic
data into several components with different frequency sub-bands. A Motif-based Graph Convolutional Recurrent Neural Network (Motif-GCRNN)
and Auto-Regressive Moving Average (ARMA) are
used to train and predict low-frequency components
and high-frequency components, respectively. In
the Motif-GCRNN framework, we integrate Graph
Convolutional Networks (GCNs) with local
sub-graph structures – Motifs – to capture the spatial correlations among road segments, and apply
Long Short-Term Memory (LSTM) to extract the
short-term and periodic patterns in traffic speeds.
Experiments on a traffic dataset collected in
Chengdu, China, demonstrate that the proposed
hybrid method outperforms six state-of-art prediction methods.

1

Introduction

Predicting large-scale traffic conditions in urban areas is of
paramount importance in traffic management and travel
planning, and a key part of Intelligent Transportation Systems [Mori et al., 2015]. In this paper, we aim to predict
short-term traffic speeds in a road network using historical
traffic speed observations. Such network-wide traffic forecasting is a challenging task due to the complexity of spatial
and temporary dependencies.
The traffic condition on one road segment is affected by its
locally adjacent road segments, and nearby segments have a
stronger influence on a given segment than more distant
segments. In addition, the influence between two adjacent
roads is directional: traffic flow on an upstream road spreads

to downstream roads and congestion on a downstream road
can cause vehicles to decelerate on upstream roads, resulting
in delayed congestion on these upstream roads.
Traffic speed time series data exhibits a strong daily periodicity due to human travelling routines (e.g., rush hours
when people go to work at morning and go home at evening),
which can be referred to as a daily period dependence. Furthermore, the traffic speed during one certain time interval is
dependent on traffic conditions on that road segment and its
neighbors at a recent time, which can be referred to as a
recent trend dependence.
Learning the complex spatial-temporal dependencies between road segments captures the inherent properties of
traffic speeds, that enables accurate forecasting.
In existing studies, there are two kinds of approaches for
traffic prediction: time-series analysis based on a statistical
approach and data-driven methods based on machine learning. Statistical approaches such as Linear Regression
[Nikovski et al., 2005], Kalman Filtering [Chien Steven et al.,
2003] and Auto-Regressive Integrated Moving Average
(ARIMA) [Lippi et al., 2013] have been widely used in traffic prediction and achieve promising results. However, these
models rely on stationary assumptions and have a limited
ability to capture complex nonlinear correlations in traffic
data. With the increase of traffic datasets and the development of computational power, many research focus on machine learning approaches, such as K-Nearest Neighbors
(KNN) [Rice et al., 2004], Support Vector Regression (SVR)
[Chun-Hsin et al., 2004] and Neural Networks (NNs)
[Lingras et al., 2002]. These methods can capture complex
non-linear relations in traffic data but still cannot effectively
model spatial-temporal dependencies found in actual traffic.
More recently, deep learning methods have been widely
applied in traffic prediction because of their powerful ability
to learn high dimensional features and express nonlinear
processes. For instance, a Convolutional Neural Network
(CNN) captured the spatial dependencies in traffic flow [Ma
et al., 2017], while a Recurrent Neural Network (RNN) [van
Lint et al., 2005] and Long Short-Term Memory network
(LSTM) [Zhao et al., 2017] were employed to extract the
temporal dependencies of traffic flows. Approaches integrating CNN and RNN captured both temporal and spatial
features [Lv et al., 2018; Yu et al., 2017]. Road networks

typically have irregular and non-Euclidean structures, however, standard CNN is restricted to processing regular grid
structures (e.g., images and videos). Thus, these methods
based on CNN are not appropriate for capturing the complicated spatial correlations underlying a road network.
In order to model traffic conditions on the topological
structures of road networks, a graph structure was introduced
to represent a road network and Graph Convolution Network
(GCN) [Defferrard et al., 2016] was used to capture spatial
correlations of traffic data [Yu et al., 2018]. However, the key
drawback of GCN is the explicit assumption of an undirected
graph, which neglects the directed propagation of traffic flow
under the topological structures of road networks, and
therefore is unable to express the adjacent upstream and
downstream relations in local areas.
Previous studies show that the decomposition-based hybrid methods can effectively improve the prediction accuracy
and thus become a popular tool in hydrological and water
resources forecasting. Discrete Wavelet Transform (DWT),
the most-widely used decomposition method, can decompose
the raw data into separate sub-time series and provide a more
coherent structure on time-frequency properties of complex
time series. This method has also been investigated in recent
traffic and passenger forecasting researches. Sun et al. employed DWT to decompose the passenger flow data into
different high-frequency and low-frequency series and then
predict each frequency series with support vector machines
(SVM) [Sun et al., 2015]. Xie et al. utilized DWT to denoise
raw traffic volume data and obtained an improved forecasting performance using Kalman filter [Xie et al., 2007].
However, existing deep learning methods rarely exploit these
time-frequency properties of traffic speeds when perform
forecasting tasks for a whole road network, and therefore
cannot extract spatio-temporal patterns from multiple frequency components.
To address these issues, we consider a road network as a
directed graph and propose a hybrid prediction method that
effectively learns the spatial and temporal dependencies of
traffic speeds. The main contributions of this paper can be
summarized as follows:
(1) We use discrete wavelet transform (DWT) to decompose raw traffic data into several frequency components, which enables us to exploit time-frequency
properties of traffic speeds with different prediction
methods.
(2) We employ motifs (local sub-graph structures [Benson
et al., 2016]) to define topological structures, especially the downstream and upstream relations in road
networks, and integrate these motifs with GCN to
construct a motif-based convolution (MGC) filter for
directed graphs that captures the spatial correlations of
traffic speeds on a road network.
(3) We construct a spatio-temporal network, called Motif-based Graph Convolutional Recurrent Neural
Network (Motif-GCRNN) to predict low frequency
components of traffic speeds. By incorporating MGC
layers and LSTM, Motif-GCRNN is able to extract

complex traffic evolution patterns.
(4) Our experimental results on real-world transportation

networks demonstrate that the proposed hybrid method
outperforms existing baseline methods when forecasting traffic speeds across an entire road network.

2

Preliminaries

2.1 Problem Formulation
We use an directed graph G = (V, E, A) with N nodes to
describe the road network, where nodes vi  V denote road
segments, edges (vi , vj)  E indicates the directed connectedness from node vi to node vj and A  R N  N ( AT  A )
represents the adjacency matrix. When there is an edge from
node vi to node v j , Aij  1 otherwise, Aij  0 ( Aii  0 ). We
v
use xt i to represent the average traffic speed on road segment vi at the time interval t for traffic speed observations.
Considering the whole road network, we define a speed
v
v
v
vector Xt = [ xt 0 , xt 1 ,..., xt N 1 ] to represent the speed information of all road segments at the time interval t,
Given the historical speed observations until time interval t
on road segments in the road network, the task aims to predict
traffic speeds at time interval t+1, which can be formulated
as:

X t 1  F  X t T ,..., X t  2 , X t 1 , X t  , G V , E , A  

(1)

where T is the length of historical observations, G is the
directed Graph built with the road network, and F is the
prediction function that must be learned.

2.2 Graph Convolution Network
There are currently two basic approaches to implement graph
convolution: the spatial approach and the spectral approach.
Spatial approaches rearrange the vertices into the form of a
grid, processed by regular convolutional operations. This
provides accurate filter localization due to the finite size of
the kernel but faces the challenge of matching local neighborhoods [Niepert et al., 2016]. Spectral approaches define
the convolution operation via a graph Fourier transform in
the spectral domain. Bruna et al. designed graph convolution
neural networks based on the spectrum of the graph Laplacian, however their approach has high computational complexity (O(n2)) due to the cost of computing a graph Fourier
transform [Bruna et al., 2014]. Defferrard et al. considered
the spectral GCN framework with polynomial filters represented by the Chebyshev polynomial (referred to as ChebNet), and can be efficiently computed by applying powers of
the graph Laplacian [Defferrard et al., 2016].The spectral
graph convolution can be written as,
K

 

y  g  L  x    k Tk L x
k 0

(2)

where L  2 L / max  I n is the rescaled Laplacian matrix
with maximum Eigenvalue max , the parameter   R K is a
vector of Chebyshev coefficients, and Tk  L   R nn is the
Chebyshev polynomial of order k. K is the number of successive filtering operations or convolutional layers and K

localized convolutions effectively exploits the information
from the K  1 -order neighborhood of a node.

2.3 Discrete Wavelet Transform
Wavelet transform (WT) is often used to extract information
in the analysis of non-stationary data. This transform provides localization properties in both time and frequency
domains [Morlet et al., 1982]. In our approach, discrete
wavelet transform (DWT) is employed to decompose raw
traffic speed data. An effective way to perform DWT is
through the Mallat algorithm [Mallat, 1989] that passes data
through a series of low-pass and high-pass filters as shown in
Equation (3) and (4):

A



 S  k    2n  k 

k 

D

l

(3)

k 

h

(b) reconstruction results

Figure 1: Discrete Wavelet Transform

3

Methodology

3.1 Overview



 S  k    2n  k 

(a) decomposition process

(4)

where S is the original signal, l is low-pass filter and  h is
high-pass filter, and A and D are the outputs of low-pass and
high-pass filters, called approximation and detail coefficients, respectively.
Figure 1(a) illustrates the process of Mallat algorithm with
three-level decompositions. The original time series data S is
firstly passed through both low-pass and high-pass filters and
sub-sampled by two to obtain the approximation and detail
coefficients (i.e., A1 and D1) at the first level. The obtained
approximation coefficient A1 is then passed through both
filters again to obtain two coefficients, A2 and D2, at the
second level. This process is repeated until the specified level
has been reached. The last approximation coefficient A3 and
all detail coefficients are retained after the decomposition
process and wavelet reconstruction is performed on each of
these coefficients. Specifically, when reconstructing time
series from one coefficient, all coefficients except this one
are set as zero values, and fed into the reconstruction algorithm (i.e., inverse discrete wavelet transform, IDWT) to
obtain the reconstructed components related to the selected
coefficient. As shown in Figure 1(b), the low-frequency
component rA3 is reconstructed using the approximation
coefficient A3, which exhibits a smooth trend in fluctuation,
and high-frequency components with different frequency
sub-bands are obtained from reconstruction results of the
detail coefficients, which show stochastic change patterns.

Figure 2 presents the flow chart of our hybrid forecasting
method. Original traffic speed data are processed by discrete
wavelet transform (DWT) to obtain multiple frequency
components for each road segment. A spatial-temporal prediction network – Motif-GCRNN is proposed to capture
traffic evolution patterns of the low-frequency components
for all road segments, and auto-regressive moving average
(ARMA) models are employed to simulate stochastic deterring occurred in the high frequency components. Outputs of
different frequency components are added by road segment
to obtain the final prediction results.
Figure 3 illustrates the architecture of Motif-GCRNN. As
shown in the middle part, we construct motif-based graph
convolutional (MGC) layers that capture spatial correlations
among road segments and use a recurrent layer with two
LSTM that learns temporal dependency of traffic dynamics.
At each time interval, the data is a speed vector of all road
segments, represented by a simplified notation of a graph to
this speed vector as shown in the yellow and blue squares, in
Figure 3. We select historical speeds over the past few time
intervals and speeds at the same time over the past few days
as input to predict the speed at the next time interval. These
two parts of input are fed into MGC layers respectively, and
then spatial features extracted are reshaped to feed into
LSTM for learning short-term and periodic patterns respectively (i.e., recent trend and daily period). These two types of
temporal features are concatenated and fed into a fully connected layer for the prediction outputs.

Figure 2: the flow chart of the proposed hybrid prediction method. DWT: Discrete Wavelet Transform; IDWT: Inverse Discrete Wavelet
Transform; ARMA: Auto-Regressive Moving Average. Motif-GCRNN: Motif-based Graph Convolutional Recurrent Neural Network.

Figure 4: Motifs in Road Networks

that stores the high-order spatial information of a road network. We use an un-weighted directed graph to represent this
road network. For each edge (vi , vj)  E , let wk,ij denote the
number of times the edge (vi, vj) participates in Mk
( k  {1,5,8,9,10}). The motif-based adjacency matrix WM is
defined as:
Figure 3: the architecture of Motif-GCRNN. MGC: Motif-based
Graph Convolution; LSTM: Long Short-Term Memory; FC: Fully
Connected.

3.2 Motif-based Graph Convolutional Layer
In a road network, the speed prediction for one road must
account for the traffic conditions on adjacent roads. However,
existing forecasting methods based on GCN only capture a
rough spatial correlation in local areas, neglecting the influence of road direction on traffic flows. Therefore, we
introduce a set of special graph structures – motifs into directed graphs to describe local structures in a road network,
and we integrate these motifs with spectral GCNs to capture
high-order spatial patterns of traffic flows. As traffic speeds
in two opposite directions of the same road could differ
greatly at the same time interval, they must be predicted
separately. Thus in this study, all road segments are assumed
to be unidirectional; any road with two lanes going in opposite directions is considered as two unidirectional roads.
Motifs. Motifs - small network sub graphs, are considered as
fundamental units of complex network and used for exploring certain meaningful connectivity patterns [Benson et al.,
2016]. Five motifs with only unidirectional edges among
thirteen types of 3-node motifs, as shown in Figure 4, were
selected to represent possible local structures in urban road
networks. The blue nodes in these motifs are anchor nodes
and regarded as the target road segments. More complex road
structures can be described by combination of these five
motifs.
Motif-based Adjacency Matrix. Taking advantage of these
sub graphs, we constructed a motif-based adjacent matrix WM

(a) road network

WM ij   wk ,ij

(5)

k

Each weight in matrix WM is a statistical value that records
the degree of involvement of an edge related to these five
motifs for constructing a graph. In a road network, the weight
describes the selection probability of vehicles for the connection between two roads, which can be indirectly used to
evaluate the importance of this connection in the whole road
network. Taking the structure in Figure 5(a) for example,
there are three upstream roads (green arrows) and three
downstream roads (blue arrows) connecting to the center
road with ID of 4. As shown in Figure 5(b), these six edges
participate in different motifs according to their context, thus
forming different weights for edges as shown in Figure 5(c).
Motif-based Convolution on Directed Graphs. Through
the weights derived from the adjacency matrix, a local convolution filter can effectively integrate the effects of diverse
traffic conditions occurring on upstream and downstream
roads to forecast traffic speeds on the central road. Based on
the convolution operation as shown in Equation 2, we define
the motif Laplacian associated with the adjacency matrix WM
as   I  D 1/2WM D 1/2 ( D is the degree matrix of WM),
which acts anisotropically in a preferred direction along
structures associated with the motifs. We use this Laplacian
to calculate the motif convolution on the directed road graphs
G (V, E, A) with signal X and a filter  :
 K

ht  Θ  X t , G     k Tk  X t 
(6)
 k 0

where K is the size of filters’ reception fields,  is the activation function (e.g., ReLU),   R k n is the trainable parameters and Tk is the Chebyshev polynomial of order k.

(b) directed graph

 

(c) motif-based adjacency matrix

Figure 5. Expression of Spatial Relations in Motif-based Adjacency Matrix .

3.3 Recurrent Layer
The dynamic trend over a recent time interval and the periodic repetitions at a daily scale in traffic speed data show
strong regularity. Taking full advantage of these temporal
patterns can help improve prediction performance. As Long
Short-Term Memory (LSTM) [Hochreiter et al., 1997] is a
powerful deep learning method capable of learning long-term
temporal patterns of a time series, we use a recurrent layer
with two LSTM to explore the short-term and periodic dependency of traffic speeds, what we term the recent trend and
daily period, respectively. Before using the recurrent layer,
we reshape the spatial features extracted by MGC layers in
the past m time intervals and the same time interval of past n
days into the input form of LSTM separately. In LSTM, the
gates structure and the hidden state are unchanged, only the
input is replaced by these spatial features. Assume the predicted speed is at the t time interval of the d day, the recent
trend and daily period are defined as:



Ytrend  LSTM htdm ,..., htd2 , htd1 





(7)



Yperiod  LSTM ht d -n ,..., ht d 2 , ht d 1 
(8)
To fuse these two types of spatio-temporal features for
future traffic prediction, we concatenate them as YC.

3.4 Regression Layer
We use a fully connected layer to learn the comprehensive
impact affected by recent trend and daily period:

Yt  tanh WFC YC  bFC 

(9)

where is the element-wise multiplication operator, WFC
indicates the learnable parameters, and bFC represents the
bias in the fully connected layer.
The Motif-GCRNN can be trained to predict Yt by minimizing mean squared error between predicted traffic speed
vectors and true traffic speed vectors:

   ||Yt  Yt ||2

(10)

t

where  are all learnable parameters in Motif-GCRNN.

3.5 ARMA Model
Through discrete wavelet transform, the high-frequency
components decomposed from original series show a strong
random pattern. Since ARMA is one of the most common
models used in stationary stochastic process analysis in the
time series domain [Ahmed et al., 1979], we employ it to
train and predict the high-frequency components of traffic
speeds. The outputs will be added together to form the final
prediction results. ARMA consists of two polynomials, one
for the auto-regression (AR) and the second for the moving
average (MA). The calculation process can be represented as.
p

q

i 1

i 1

Yt  c   t   i X t i   i t i

(11)

Figure 6: Road network for testing

where c is a constant,  is the random error and distributed
as a Gaussian white noise,  ,  are parameters of AR and
MA part, p and q are integers showing the orders of AR and
MA part, respectively.

4

Experiments

4.1 Dataset Description
We verified the proposed approach using a taxi GPS dataset
collected from 1st November 2016 to 30th November 2016
(30 days) in Chengdu, China. The highlighted roads in Figure
6 constitute the road network to be predicted, which consists
of 156 unidirectional road segments. We calculated the
travelling speed between two continuous GPS points of one
car as a speed record at a road segment. All speed records
during 30 days were aggregated into a 15 min interval, and
the traffic speed of each road segment at each time interval
was then obtained by averaging the speed records within this
time interval for each road segment. In our experiment, data
from the first 24 days are used as training data, and the remaining six days as test data.

4.2 Experimental Settings
Baselines. We compare our approach with the following
baseline methods: (1) Auto-Regressive Moving Average
(ARMA); (2) Support Vector Regression (SVR); (3)
Space-Time Convolutional Neural Network (ST-CNN) [Ma
et al., 2017], which uses a speed matrix with x-axis of time
and y-axis of roads to rep-resent the spatio-temporal change
of traffic speeds; (4) Long Short-Term Memory (LSTM)
with two recurrent layers; (5) Graph Convolution Network
(GCN) in spectral domain with pooling and fully-connected
layers; (6) Graph Convolutional Recurrent Neural Network
(GCRNN) [Seo et al., 2018], which integrates GCN and
LSTM that exploits both graph spatial and dynamic information to predict structured sequence data..
Parameter settings. In our approach, we use one convolutional layer with 32 filters and a max-pooling layer at a size
of 2×2. The size of filter reception field K varies from one to
five for motif-based convolutional layers, the number of
recent trend intervals varies from one to eight (15min to 2
hours) and the size of daily period intervals varies from one
to eight days for LSTM layers. The filter reception fields K
was set to three, the number of recent trend intervals to two
(half an hour) and daily period intervals were set to seven as
default parameters. For DWT, we select level j = 3, and used

Model
ARMA
SVR
ST-CNN
GCN
LSTM
GCRNN
Motif-GCRNN
Proposed Method

MAE
3.952
3.708
3.624
3.600
3.566
3.508
3.499
3.287

MAPE (%)
14.135
13.905
13.471
13.468
13.178
13.120
13.035
12.112

RMSE
5.308
5.244
5.211
5.191
5.176
5.116
5.098
4.700

(a) varing filter size

Table 1：Performance comparison of different models

DB4 as mother wavelet, to obtain three high-frequency
components and one low frequency sequence.
We selected Mean Absolute Error (MAE), Mean Absolute
Percentage Error (MAPE), and Root Mean Squared Error
(RMSE) to evaluate the performance of the tested methods.
All neural network based approaches were implemented
using Tensorflow, and trained using the SGD optimizer.

4.3 Experiment Results
Table 1 illustrates the performance results of our method and
other baselines. In the Motif-GCRNN model, the original
traffic speed data were directly trained and predicted by
Motif-GCRNN without wavelet transform and reconstruction.
We analyzed the results in Table 1 and found that overall,
our proposed hybrid prediction method significantly improved performance with the lowest test error among the six
other benchmarks tested, according to three metrics. These
results verify the effectiveness and superiority of our method.
In contrast to Motif-GCRNN, our method achieved higher
accuracy for all three metrics, indicating that wavelet transform is valid and the accuracy of speed prediction can be
improved by capturing time-frequency properties of traffic
speed data. The Motif-GCRNN, GCN, LSTM, ST-CNN and
GCRNN comparative results show that Motif-GCRNN has
stronger ability to learn spatio-temporal dependency of traffic speeds. Furthermore, Motif-GCRNN outperformed
GCRNN, which indicates that motif-based graph convolution
extracts more effective high-order spatial features than general graph convolution. We observed that the accuracy of all
neural-network based models are higher than ARMA and
SVR, which indicates deep learning methods are more suitable for simulating nonlinear spatio-temporal processes than
general machine learning methods and traditional statistical
methods.
Effect of different parameters: Figure 7 shows the effect of
different size of filters’ reception fields K as well as different
number of recent trend intervals and daily period intervals.
As shown in figure 7(a), the RMSE of our method gradually decreases and then fluctuates slightly with an increase of
K. The best prediction performance occurred when K =3.
Intuitively, this may be because a larger K enables the model
to capture the broad spatial dependency between the predicted segment and its adjacent road segments.

(b) varing the number
of time intervals relat
-ed to recent trend

(c) varing the number
of historical days rela
-ted to daily period

Figure 7. Varying different parameters

However, the spatial dependency becomes weaker when the
involved road segments within the reception field get farther
from the predicted segment, indicating that the spatial information of distant road segments with higher adjacent
order does not improve the prediction performance.
As shown in figure 7(b), the model achieves the best performance when speed data of previous two time intervals (30
min) are fed into recurrent layers. Then, the MAPE goes up
with an increase in historical information. This result indicates that traffic dynamics have a strong short-term temporal
dependency, and this dependency is concentrated over a short
period in the past. Remote historical information therefore, is
less valuable when capturing the temporal patterns of traffic
speeds.
As shown in figure 7(c), the prediction accuracy is improved by adding periodic data to the recurrent layer with the
increase of historical days. The MAE reaches a relatively low
level when the length of daily period intervals is more than
five. This result shows that traffic conditions at the same time
interval during past days can be used to predict the possible
traffic conditions in future days. The increase of test error
occurred when the length of daily period intervals is eight;
this may be due to insufficient training samples with the need
for so much historical data input.

5

Conclusion and Future Work

In this paper, we propose a novel hybrid method for traffic
speed forecasting. The wavelet transform is used to decompose different time-frequency components of raw traffic data.
We constructed a spatio-temporal network – Motif-GCRNN
to predict the low frequency component and employed
ARMA to model high frequency components. In Motif-GCRNN, we learned the road network as a directed graph
and defined motif-based traffic graph convolution to capture
spatial correlations of traffic speeds among adjacent roads. A
recurrent layer with two LSTM is used to learn short-term
and periodic information, respectively. The proposed approach outperformed other state-of-the-art methods on a
large-scale real-world traffic dataset collected in Chengdu,
China.
In future work, we will move forward to explore the performance of different types of mother wavelets in the wavelet
transform process, and apply the proposed hybrid method to
other spatial-temporal forecasting tasks.

References
[Ahmed et al., 1979]Ahmed, Mohammed S and Allen R
Cook. Analysis of freeway traffic time-series data by
using box-jenkins techniques. 1979.
[Benson et al., 2016] Benson, Austin R., David F. Gleich and
Jure Leskovec. Higher-order organization of complex
networks. Science, 353(6295):163. 2016.
[Bruna et al., 2014]Bruna, Joan, Wojciech Zaremba, Arthur
Szlam and Yann Lecun. Spectral networks and locally
connected networks on graphs. In International Conference on Learning Representations (ICLR2014), CBLS,
April 2014. 2014.
[Chien Steven et al., 2003] Chien Steven, I. Jy and Mouly
Kuchipudi Chandra. Dynamic travel time prediction with
real-time and historic data. Journal of Transportation
Engineering, 129(6):608-616. 2003.
[Chun-Hsin et al., 2004] Chun-Hsin, Wu, Ho Jan-Ming and
D. T. Lee. Travel-time prediction with support vector
regression. IEEE Transactions on Intelligent Transportation Systems, 5(4):276-281. 2004.
[Defferrard et al., 2016]Defferrard, Michaël, Xavier Bresson
and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In
Advances in Neural Information Processing Systems. pp:
3844-3852, 2016.
[Hochreiter et al., 1997] Hochreiter, Sepp and Jürgen
Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780. 1997.
[Lingras et al., 2002] Lingras, Pawan, Satish Sharma and
Ming Zhong. Prediction of recreational travel using genetically designed regression and time-delay neural network models. Transportation Research Record: Journal of
the Transportation Research Board(1805):16-24. 2002.
[Lippi et al., 2013] Lippi, M., M. Bertini and P. Frasconi.
Short-term traffic flow forecasting: An experimental
comparison of time-series analysis and supervised
learning. IEEE Transactions on Intelligent Transportation
Systems, 14(2):871-882. 2013.
[Lv et al., 2018]Lv, Zhongjian, Jiajie Xu, Kai Zheng,
Hongzhi Yin, Pengpeng Zhao and Xiaofang Zhou. Lc-rnn:
A deep learning model for traffic speed prediction. In
IJCAI. pp: 3470-3476, 2018.
[Ma et al., 2017] Ma, Xiaolei, Zhuang Dai, Zhengbing He,
Jihui Ma, Yong Wang and Yunpeng Wang. Learning
traffic as images: A deep convolutional neural network
for large-scale transportation network speed prediction.
Sensors, 17(4):818. 2017.
[Mallat, 1989] Mallat, Stephane G. A theory for multiresolution signal decomposition: The wavelet representation.
IEEE Transactions on Pattern Analysis & Machine Intelligence(7):674-693. 1989.
[Mori et al., 2015] Mori, Usue, Alexander Mendiburu, Maite
Álvarez and Jose A Lozano. A review of travel time es-

timation and forecasting for advanced traveller information systems. Transportmetrica A: Transport Science,
11(2). 2015.
[Morlet et al., 1982] Morlet, Jean, G Arens, E Fourgeau and
D Glard. Wave propagation and sampling theory—part i:
Complex signal and scattering in multilayered media.
Geophysics, 47(2):203-221. 1982.
[Niepert et al., 2016]Niepert, Mathias, Mohamed Ahmed and
Konstantin Kutzkov. Learning convolutional neural
networks for graphs. In International conference on machine learning. pp: 2014-2023, 2016.
[Nikovski et al., 2005]Nikovski, D., N. Nishiuma, Y. Goto
and H. Kumazawa. Univariate short-term prediction of
road travel times. In Proceedings. 2005 IEEE Intelligent
Transportation Systems, 2005. pp: 1074-1079, 2005.
[Rice et al., 2004] Rice, J. and E. van Zwet. A simple and
effective method for predicting travel times on freeways.
IEEE Transactions on Intelligent Transportation Systems,
5(3):200-207. 2004.
[Seo et al., 2018]Seo, Youngjoo, Michaël Defferrard, Pierre
Vandergheynst and Xavier Bresson. Structured sequence
modeling with graph convolutional recurrent networks. In
International Conference on Neural Information Processing. Springer: pp: 362-373, 2018.
[Sun et al., 2015] Sun, Yuxing, Biao Leng and Wei Guan. A
novel wavelet-svm short-time passenger flow prediction
in beijing subway system. Neurocomputing, 166:109-121.
2015.
[van Lint et al., 2005] van Lint, J. W. C., S. P. Hoogendoorn
and H. J. van Zuylen. Accurate freeway travel time prediction with state-space neural networks under missing
data. Transportation Research Part C: Emerging Technologies, 13(5):347-369. 2005.
[Xie et al., 2007] Xie, Yuanchang, Yunlong Zhang and
Zhirui Ye. Short‐ term traffic volume forecasting using
kalman filter with discrete wavelet decomposition.
Computer‐ Aided Civil and Infrastructure Engineering,
22(5):326-334. 2007.
[Yu et al., 2018] Yu, Bing, Haoteng Yin and Zhanxing Zhu.
Spatio-temporal graph convolutional networks: A deep
learning framework for traffic forecasting. IJCAI. 2018.
[Yu et al., 2017] Yu, Haiyang, Zhihai Wu, Shuqin Wang,
Yunpeng Wang and Xiaolei Ma. Spatiotemporal recurrent convolutional networks for traffic prediction in
transportation networks. Sensors, 17(7). 2017.
[Zhao et al., 2017]Zhao, Zheng, Weihai Chen, Xingming Wu,
Peter C. Y. Chen and Jingmeng Liu. Lstm network: A
deep learning approach for short-term traffic forecast. In
IET Intelligent Transport Systems. Institution of Engineering and Technology: pp: 68-75, 2017.

