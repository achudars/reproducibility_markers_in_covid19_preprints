EVA: An Encrypted Vector Arithmetic Language and Compiler for
Efficient Homomorphic Computation
Roshan Dathathri* , Blagovesta Kostova† , Olli Saarikivi‡ , Wei Dai‡ , Kim Laine‡ , and Madanlal Musuvathi‡

arXiv:1912.11951v2 [cs.CR] 26 Jun 2020

* University

of Texas at Austin, USA
roshan@cs.utexas.edu
† EPFL, Switzerland
blagovesta.pirelli@epfl.ch
‡ Microsoft Research, USA
{olsaarik,wei.dai,kilai,madanm}@microsoft.com
Abstract
Fully-Homomorphic Encryption (FHE) offers powerful capabilities by enabling secure offloading of both storage and
computation, and recent innovations in schemes and implementations have made it all the more attractive. At the same
time, FHE is notoriously hard to use with a very constrained
programming model, a very unusual performance profile,
and many cryptographic constraints. Existing compilers for
FHE either target simpler but less efficient FHE schemes or
only support specific domains where they can rely on expertprovided high-level runtimes to hide complications.
This paper presents a new FHE language called Encrypted
Vector Arithmetic (EVA), which includes an optimizing compiler that generates correct and secure FHE programs, while
hiding all the complexities of the target FHE scheme. Bolstered by our optimizing compiler, programmers can develop
efficient general-purpose FHE applications directly in EVA.
For example, we have developed image processing applications using EVA, with a very few lines of code.
EVA is designed to also work as an intermediate representation that can be a target for compiling higher-level domainspecific languages. To demonstrate this, we have re-targeted
CHET, an existing domain-specific compiler for neural network inference, onto EVA. Due to the novel optimizations
in EVA, its programs are on average 5.3× faster than those
generated by CHET. We believe that EVA would enable a
wider adoption of FHE by making it easier to develop FHE
applications and domain-specific FHE compilers.

1. Introduction
Fully-Homomorphic Encryption (FHE) allows arbitrary computations on encrypted data without requiring the decryption
key. Thus, FHE enables interesting privacy-preserving capabilities, such as offloading secure storage and secure computation to untrusted cloud providers. Recent advances in
FHE theory [12, 11] along with improved implementations
have pushed FHE into the realm of practicality. For instance,

with appropriate optimization, we can perform encrypted
fixed-point multiplications within a few microseconds, which
matches the speed of 8086 processors that jumpstarted the
computing revolution. Future cryptographic innovations will
further reduce the performance gap between encrypted and
unencrypted computations.
Despite the availability of multiple open-source implementations [40, 27, 37, 24], programming FHE applications remains
hard and requires cryptographic expertise, making it inaccessible to most programmers today. Furthermore, different FHE
schemes provide subtly different functionalities and require
manually setting encryption parameters that control correctness, performance, and security. We expect the programming
complexity to only increase as future FHE schemes become
more capable and performant. For instance, the recently invented CKKS scheme [12] supports fixed-point arithmetic operations by representing real numbers as integers with a fixed
scaling factor, but requires the programmer to perform rescaling operations so that scaling factors and the cryptographic
noise do not grow exponentially due to multiplications. Moreover, the so-called RNS-variant of the CKKS scheme [11]
provides efficient implementations that can use machine-sized
integer operations as opposed to multi-precision libraries, but
imposes further restrictions on the circuits that can be evaluated on encrypted data.
To improve the developer friendliness of FHE, this paper
proposes a new general-purpose language for FHE computation called Encrypted Vector Arithmetic (EVA). EVA is also
designed to be an intermediate representation that is a backend
for other domain-specific compilers. At its core, EVA supports
arithmetic on fixed-width vectors and scalars. The vector instructions naturally match the encrypted SIMD – or batching
– capabilities of FHE schemes today. EVA includes an optimizing compiler that hides all the complexities of the target
FHE scheme, such as encryption parameters and noise. It ensures that the generated FHE program is correct, performant,
and secure. In particular, it eliminates all common runtime
exceptions that arise when using FHE libraries.

EVA implements FHE-specific optimizations, such as optimally inserting operations like rescaling and modulus switching. We have built a compiler incorporating all these optimizations to generate efficient programs that run using the
Microsoft SEAL [40] FHE library which implements the
RNS-variant of the CKKS scheme. We have built an EVA
executor that transparently parallelizes the generated program
efficiently, allowing programs to scale well. The executor also
automatically reuses the memory used for encrypted messages,
thereby reducing the memory consumed.
To demonstrate EVA’s usability, we have built a Python
frontend for it. Using this frontend, we have implemented
several applications in EVA with a very few lines of code and
much less complexity than in SEAL directly. One application
computes the length of a path in 3-dimensional space, which
can be used in secure fitness mobile applications. We have
implemented some statistical machine learning applications.
We have also implemented two image processing applications,
Sobel filter detection and Harris corner detection. We believe
Harris corner detection is one of the most complex programs
that have been evaluated using CKKS.
In addition, we have built a domain-specific compiler on top
of EVA for deep neural network (DNN) inference. This compiler takes programs written in a higher-level language as input
and generates EVA programs using a library of operations on
higher-level constructs like tensors and images. In particular,
our DNN compiler subsumes the recently proposed domainspecific compiler called CHET [17]. Our DNN compiler uses
the same tensor kernels as CHET, except that it generates EVA
programs instead of generating SEAL programs. Nevertheless,
the optimizing compiler in EVA is able to outperform CHET
in DNN inference by 5.3× on average.
In summary, EVA is a general-purpose language and an
intermediate representation that improves the programmability
of FHE applications by guaranteeing correctness and security,
while outperforming current methods.
The rest of this paper is organized as follows. Section 2
gives background on FHE. Section 3 presents the EVA language. Section 4 gives an overview of the EVA compiler. We
then describe transformations and analysis in the compiler
in Sections 5 and 6 respectively. Section 7 briefly describes
the domain-specific compilers we built on top of EVA. Our
evaluation is presented in Section 8. Finally, related work and
conclusions are presented in Sections 9 and 10 respectively.

schemes, for example, BGV [6], BFV [18], and CKKS [12],
are constructed on the Ring Learning with Errors (RLWE)
problem [33]. At the time of key generation, a polynomial
ring of degree N with integer coefficients modulo Q must be
chosen to represent ciphertexts and public keys according to
the security standard [1]. We call Q the ciphertext modulus.
A message is encoded to a polynomial, and subsequently encrypted with a public key or a secret key to form a ciphertext
consisting of two polynomials of degree up to N − 1. Encryption also adds to a ciphertext a small random error that is later
removable in decryption.
FHE schemes are malleable by design. From the perspective
of the user, they offer a way to encrypt integers (or fixedpoint numbers in CKKS — see the next section) such that
certain arithmetic operations can be evaluated on the resulting
ciphertexts. Evaluation primarily includes four operations:
addition of ciphertexts, addition of a ciphertext and a plaintext,
multiplication of ciphertexts, and multiplication of a ciphertext
and a plaintext. Decrypting (with a secret key) and decoding
reveals the message, as if the computation was performed on
unencrypted data.
Many modern FHE schemes also include a SIMD-like feature known as batching which allows a vector of values to be
encrypted as a single ciphertext (N/2 values in CKKS). With
batching, arithmetic operations happen in an element-wise
fashion. Batching-compatible schemes can evaluate rotations
which allow data movement inside a ciphertext. But evaluating
each rotation step count needs a distinct public key.
2.2. Challenges in Using FHE
Programmers using FHE face significant challenges that must
be overcome for correct, efficient, and secure computation.
We discuss those challenges here to motivate our work.
Depth of Computation: Computations on ciphertexts increase the initially small error in them linearly on the number
of homomorphic additions and exponentially on the multiplicative depth of the evaluation circuit. When the errors get too
large, ciphertexts become corrupted and cannot be decrypted,
even with the correct secret key. This bound is in turn determined by the size of the encryption parameter Q. Thus, to
support efficient homomorphic evaluation of a circuit, one
must optimize the circuit for low depth.

2.1. Fully-Homomorphic Encryption (FHE)

Relinearization: Each ciphertext consists of 2 or more polynomials (freshly encrypted ciphertexts consist of only 2 polynomials). Multiplication of two ciphertexts with k and l polynomials yields a ciphertext with k + l + 1 polynomials. To
prevent the number of polynomials from growing indefinitely,
an operation called relinearization is performed to reduce it
back to 2. Relinearization from each distinct number of polynomials to 2 requires a distinct public key. Relinearization is
costly and their optimal placement is an NP-hard problem [10].

An FHE scheme includes four stages: key generation, encryption, evaluation, and decryption. Most of the efficient FHE

CKKS and Approximate Fixed-Point: The CKKS [12]
scheme introduced an additional challenge by only providing

2. Background and Motivation
In this section, we describe FHE (Section 2.1) and the challenges in using it (Section 2.2). We also describe an implementation of FHE (Section 2.3). Finally, we present the threat
model assumed in this paper (Section 2.4).

2

approximate results (but much higher performance in return).
There are two main sources of error in CKKS: (i) error from
the encoding of values to polynomials being lossy, and (ii)
the noise added in every homomorphic operation being mixed
with the message. To counter this, CKKS adopts a fixed-point
representation by associating each ciphertext with an unencrypted scaling factor. Using high enough scaling factors
allows the errors to be hidden.
CKKS further features an operation called rescaling that
scales down the fixed-point representation of a ciphertext.
Consider a ciphertext x that contains the encoding of 0.25
multiplied by the scale 210 (a relatively low scale). x2 encodes
0.0625 multiplied by the scale 220 . Further powers would
rapidly overflow modest values of the modulus Q, requiring impractically large encryption parameters to be selected.
Rescaling the second power by 210 will truncate the fixed-point
representation to encode the value at a scale of 210 .
Rescaling has a secondary effect of also dividing the ciphertext’s modulus Q by the same divisor as the ciphertext itself.
This means that there is a limited “budget” for rescaling built
into the initial value of Q. The combined effect for CKKS is
that log Q can grow linearly with the multiplicative depth of
the circuit. It is common to talk about the level of a ciphertext
as how much Q is left for rescaling.
A further complication arises from the ciphertext after
rescaling being encrypted under fundamentally different encryption parameters. To apply any binary homomorphic operations, two ciphertexts must be at the same level, i.e., have
the same Q. Furthermore, addition and subtraction require
ciphertexts to be encoded at the same scale due to the properties of fixed-point arithmetic. CKKS also supports a modulus
switching operation to bring down the level of a ciphertext
without scaling the message. In our experience, inserting the
appropriate rescaling and modulus switching operations to
match levels and scales is a significantly difficult process even
for experts in homomorphic encryption.
In the most efficient implementations of CKKS (so called
RNS-variants [11]), the truncation is actually performed by
dividing the encrypted values by prime factors of Q. Furthermore, there is a fixed order to these prime factors, which
means that from a given level (i.e., how many prime factors are
left in Q) there is only one valid divisor available for rescaling.
This complicates selecting points to rescale, as doing so too
early might make the fixed-point representation so small that
the approximation errors destroy the message.

Table 1: Types of values.

Type

Description

Cipher
Vector
Scalar
Integer

An encrypted vector of fixed-point values.
A vector of 64-bit floating point values.
A 64-bit floating point value.
A 32-bit signed integer.

tions, which typically means upper-bounding Q for a given N.
2.3. Microsoft SEAL
Microsoft SEAL [40] is a software library that implements
the RNS variant of the CKKS scheme. In SEAL, the modulus
Q is a product of several prime factors of bit sizes up to 60
bits, and rescaling of ciphertexts is always done by dividing
away these prime factors. The developer must choose these
prime factors and order them correctly to achieve the desired
rescaling behavior. SEAL automatically validates encryption
parameters for correctness and security.
2.4. Threat Model
We assume a semi-honest threat model, as is typical for homomorphic encryption. This means that the party performing the
computation (i.e., the server) is curious about the encrypted
data but is guaranteed to run the desired operations faithfully.
This model matches for example the scenario where the server
is trusted, but a malicious party has read access to the server’s
internal state and/or communication between the server and
the client.

3. EVA Language
The EVA framework uses a single language as its input format, intermediate representation, and executable format. The
EVA language abstracts batching-compatible FHE schemes
like BFV [18], BGV [6], and CKKS [12, 11], and can be
compiled to target libraries implementing those schemes. Input programs use a subset of the language that omits details
specific to FHE, such as when to rescale. In this section, we
describe the input language and its semantics, while Section 4
presents an overview of the compilation to an executable EVA
program.
Types and Values: Table 1 lists the types that values in EVA
programs may have. The vector types Cipher and Vector
have a fixed power-of-two size for each input program. The
power-of-two requirement comes from the target encryption
schemes.
We introduce some notation for talking about types and
values in EVA. For Vector, a literal value with elements ai is
written [a1 , a2 , . . . , ai ] or as a comprehension [ai for i = 1 . . . i].
For the ith element of Vector a, we write ai . For the product
type (i.e., tuple) of two EVA types A and B, we write A × B,
and write tuple literals as (a, b) where a ∈ A and b ∈ B.

Encryption Parameters: In CKKS, all of the concerns
about scaling factors, rescaling, and managing levels are intricately linked with selecting encryption parameters. Thus, a
typical workflow when developing FHE applications involves
a lot of trial-and-error, and repeatedly tweaking the parameters to achieve both correctness (accuracy) and performance.
While some FHE libraries warn the user if the selected encryption parameters are secure, but not all of them do, so a
developer may need to keep in mind security-related limita3

Table 2: Instruction opcodes and their semantics (see Section 2 for details on semantics of the restricted instructions).

Opcode

Signature

Description

Restrictions

N EGATE
A DD
S UB
M ULTIPLY

Cipher → Cipher
Cipher × (Vector|Cipher) → Cipher
Cipher × (Vector|Cipher) → Cipher
Cipher × (Vector|Cipher) → Cipher

ROTATE L EFT

Cipher × Integer → Cipher

ROTATE R IGHT

Cipher × Integer → Cipher

Negate each element of the argument.
Add arguments element-wise.
Subtract right argument from left one element-wise.
Multiply arguments element-wise (and multiply
scales).
Rotate elements to the left by given number of indices.
Rotate elements to the right by given number of
indices.

R ELINEARIZE
M OD S WITCH
R ESCALE

Cipher → Cipher
Cipher → Cipher
Cipher × Scalar → Cipher

Apply relinearization.
Switch to the next modulus in the modulus chain.
Rescale the ciphertext (and divide scale) with the
scalar.

Instructions: Programs in EVA are Directed Acyclic
Graphs (DAGs), where each node represents a value available
during execution. Example programs are shown in Figures 2(a)
and 3(a). Nodes with one or more incoming edges are called
instructions, which compute a new value as a function of its
parameter nodes, i.e., the parent nodes connected to it. For
the ith parameter of an instruction n, we write n.parmi and the
whole list of parameter nodes is n.parms. Each instruction n
has an opcode n.op, which specifies the operation to be performed at the node. Note that the incoming edges are ordered,
as it corresponds to the list of arguments. Table 2 lists all the
opcodes available in EVA. The first group are opcodes that
frontends may generate, while the second group lists FHEspecific opcodes that are inserted by the compiler. The key to
the expressiveness of the input language are the ROTATE L EFT
and ROTATE R IGHT instructions, which abstract rotation (circular shift) in batching-compatible FHE schemes.

Not in input
Not in input
Not in input

easy, as every plaintext operation is its own homomorphic
counterpart. Given a map I : Inputs → Vector, let Eid (n) be
the function that computes the value for node n recursively by
using n.value or I(n) if n is a constant or input respectively
and using n.op and Eid () on n.parms otherwise. Now for
a program P, we further define its reference semantic as a
function Pid , which given a value for each input node maps
each output node in P to its resulting value:
Pid : ×ni ∈Inputs ni .type → ×no ∈Outputs Vector
|Inputs|

Pid (I(n1i ), . . . , I(ni

|Outputs|

)) = (Eid (n1o ), . . . , Eid (no

))

These execution semantics hold for any encryption scheme,
except that output is also encrypted (i.e., Cipher type).
Discussion on Rotation and Vector Sizes: The EVA language restricts the size for any Cipher or Vector input to
be a power-of-2 so as to support execution semantics of
ROTATE L EFT and ROTATE R IGHT instructions.
The target encryption schemes use the same vector size
se (= N/2) for all Cipher values during execution. However, the vector size si for an input could be different from
se . Nevertheless, the target encryption scheme and the EVA
language enforce the vector sizes se and si , respectively, to
be powers-of-2. EVA chooses encryption parameters for the
target encryption scheme such that for all inputs i, si ≤ se (because N can be increased trivially without hurting correctness
or security — note that increasing N will hurt performance).
For a Cipher or Vector input i such that si < se , EVA constructs a vector (before encryption for Cipher) i0 with se /si
copies of the vector i contiguously such that s0i = se , and replaces i with i0 in the program. For example, if an input
a = [a1 , a2 ] and se = 4, then EVA constructs a0 = [a1 , a2 , a1 , a2 ]
and replaces a with a0 . ROTATE R IGHT or ROTATE R IGHT instruction on the original vector i and the constructed larger
vector i0 have the same result on their first si elements. This is

Inputs: A node with no incoming edges is called a constant
if its value is available at compile time and an input if its
value is only available at run time. For a constant n, we write
n.value to denote the value. Inputs may be of any type, while
constants can be any type except Cipher. This difference
is due to the fact that the Cipher type is not fully defined
before key generation time, and thus cannot have any values
at compile time. The type is accessible as n.type.
Program: A program P is a tuple (M, Insts, Consts, Inputs,
Outputs), where M is the length of all vector types in P; Insts,
Consts and Inputs are list of all instruction, constant, and input
nodes, respectively; and Outputs identifies a list of instruction
nodes as outputs of the program.
Execution Semantics: Next, we define execution semantics
for EVA. Consider a dummy encryption scheme id that instead
of encrypting Cipher values just stores them as Vector values.
In other words, the encryption and decryption are the identity
function. This scheme makes homomorphic computation very
4

1

syntax = ‘‘proto3’’;

3

37

package EVA;

38

4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

39

enum OpCode {
UNDEFINED_OP = 0;
NEGATE = 1;
ADD = 2;
SUB = 3;
MULTIPLY = 4;
SUM = 5;
COPY = 6;
ROTATE_LEFT = 7;
ROTATE_RIGHT = 8;
RELINEARIZE = 9;
MOD_SWITCH = 10;
RESCALE = 11;
NORMALIZE_SCALE = 12;
}

22
23
24
25
26
27
28
29

41
42
43

32
33

45
46
47
48
49

message Input {
Object obj = 1;
ObjectType type = 2;
double scale = 3;
}

50
51
52
53
54
55

enum ObjectType {
UNDEFINED_TYPE = 0;
SCALAR_CONST = 1;
SCALAR_PLAIN = 2;
SCALAR_CIPHER = 3;
VECTOR_CONST = 4;
VECTOR_PLAIN = 5;
VECTOR_CIPHER = 6;
}

56

message Constant {
Object obj = 1;
ObjectType type = 2;
double scale = 3;
Vector vec = 4;
}

57
58
59
60
61

message Output {
Object obj = 1;
double scale = 2;
}

62
63
64
65

message Object {
uint64 id = 1;
}

66
67
68

34
35

message Vector {
repeated double elements = 1;
}

44

30
31

}

40

20
21

Object output = 1;
OpCode op_code = 2;
repeated Object args = 3;

36

2

69

message Program {
uint64 vec_size = 1;
repeated Constant constants = 2;
repeated Input inputs = 3;
repeated Output outputs = 4;
repeated Instruction insts = 5;
}

message Instruction {

Figure 1: The EVA language definition using Protocol Buffers.

feasible because si divides se . EVA thus ensures that the execution semantics of the EVA program holds for any encryption
scheme.

in the SEAL library [40]. Targeting EVA for other FHE libraries [27, 24, 37] implementing CKKS [12, 11] would be
straightforward. The EVA compiler can also be adapted to support other batching-compatible FHE schemes like BFV [18]
and BGV [6].

Implementation: As shown in Figure 1, the EVA language
has a serialized format defined using Protocol Buffers [22], a
language and platform neutral data serialization format. Additionally, the EVA language has an in-memory graph representation that is designed for efficient analysis and transformation,
which is discussed in Section 4.

The EVA compiler takes a program in the EVA language as
input. Along with the program, it needs the fixed-point scales
or precisions for each input in the program and the desired
fixed-point scales or precisions for each output in the program.
The compiler then generates a program in the EVA language
as output. In addition, it generates a vector of bit sizes that
must be used to generate the encryption parameters as well as
a set of rotation steps that must be used to generate the rotation
keys. The encryption parameters and the rotations keys thus
generated are required to execute the generated EVA program.

4. Overview of EVA Compiler
In this section, we describe how to use the EVA compiler
(Section 4.1). We then describe the constraints on the code
generated by EVA (Section 4.2). Finally, we give an overview
of the execution flow of the EVA compiler (Section 4.3).

While the input and the output programs are in the EVA
language, the set of instructions allowed in the input and the
output are distinct, as listed in Table 2. The R ELINEARIZE,
R ESCALE, and M OD S WITCH instructions require understanding the intricate details of the FHE scheme. Hence, they are

4.1. Using the Compiler
In this paper, we present the EVA compiler for the RNS
variant of the CKKS scheme [11] and its implementation
5

Figure 2: x2 y3 example in EVA: (a) input; (b) after ALWAYS-RESCALE; (c) after ALWAYS-RESCALE & MODSWITCH; (d) after
WATERLINE-RESCALE; (e) after WATERLINE-RESCALE & RELINEARIZE (S: R ESCALE, M: M OD S WITCH, L: R ELINEARIZE).

omitted from the input program. Note that we can make these
instructions optional in the input and the compiler can handle
it if they are present, but for the sake of exposition, we assume
that the input does not have these instructions.
The input scales and the desired output scales affect the
encryption parameters, and consequently, the performance
and accuracy of the generated program. Choosing the right
values for these is a trade-off between performance and accuracy (while providing the same security). Larger values
lead to larger encryption parameters and more accurate but
slower generated program, whereas smaller values lead to
smaller encryption parameters and less accurate but faster generated program. Profiling techniques like those used in prior
work [17] can be used to select the appropriate values.

for the binary instructions involving two ciphertexts:
n.parm1 .modulus = n.parm2 .modulus
if n.op ∈ {A DD, S UB, M ULTIPLY}

(1)

n.parm1 .scale = n.parm2 .scale
if n.op ∈ {A DD, S UB}

(2)

In the rest of this paper, whenever we mention A DD regarding
constraints, it includes both A DD and S UB.
Consider the example to compute x2 y3 for ciphertexts x and
y in Figure 2 (viewed as a dataflow graph). Constraint 2 is trivially satisfied because they are no A DD instructions. Only
R ESCALE and M OD S WITCH instructions modify q. Constraint 1 is also trivially satisfied due to the absence of these
instructions. Nonetheless, without the use of R ESCALE instructions, the scales and the noise of the ciphertexts would
grow exponentially with the multiplicative depth of the program (i.e., maximum number of M ULTIPLY nodes in any path)
and consequently, the log2 of the coefficient modulus product
Q required for the input would grow exponentially. Instead,
using R ESCALE instructions ensures that log2 Q would only
grow linearly with the multiplicative depth of the program.
In Figure 2, the output has a scale of 260 ∗260 ∗230 ∗230 ∗230
(with x.scale = 260 and y.scale = 230 ). This would require
Q to be at least 2210 ∗ so , where so is the user-provided desired output scale. To try to reduce this, one can insert
R ESCALE after every M ULTIPLY, as shown in Figure 2(b).
However, this yields an invalid program because it violates
Constraint 1 for the last (bottom) M ULTIPLY (and there is
no way to choose the same q for both x and y). To satisfy
this constraint, M OD S WITCH instructions can be inserted, as
shown in Figure 2(c). Both R ESCALE and M OD S WITCH drop
the first element in their input q (or consume the modulus),
whereas R ESCALE also divides the scale by the given scalar
(which is required to match the first element in q). The output

4.2. Motivation and Constraints
There is a one-to-one mapping between instructions in the
EVA language (Table 2) and instructions in the RNS-CKKS
scheme. However, the input program cannot be directly executed. Firstly, encryption parameters are required to ensure
that the program would be accurate. EVA can simply determine the bit sizes that is required to generate the parameters.
However, this is insufficient to execute the program correctly
because some instructions in the RNS-CKKS scheme have
restrictions on their inputs. If these restrictions are not met,
the instructions would just throw an exception at runtime.
Each ciphertext in the RNS-CKKS scheme has a coefficient
modulus q (Q = ∏ri=1 qi )1 and a fixed-point scale associated
with it. All freshly encrypted ciphertexts have the same q but
they may have different scale. The following constraints apply
1 In SEAL, if the coefficient modulus q is {q , q , ..., q }, then q is a prime
r
i
1 2
close to a power-of-2. EVA compiler (and the rest of this paper) assumes qi is
the corresponding power-of-2 instead. To resolve this discrepancy, when a
R ESCALE instruction divides the scale by the prime, the scale is adjusted (by
the EVA executor) as if it was divided by the power-of-2 instead.

6

Algorithm 1: Execution of EVA compiler.

1
2
3
4
5

Figure 3: x2 + x example in EVA: (a) input; (b) after ALWAYSRESCALE & MODSWITCH; (c) after MATCH-SCALE.

260

In the SEAL library, s f = 260 (which enables a performant
implementation by limiting scales to machine-sized integers).
To summarize, FHE schemes (or libraries) are tedious for
a programmer to reason about, due to all their cryptographic
constraints. Programmers find it even more tricky to satisfy
the constraints in a way that optimizes performance. The EVA
compiler hides such cryptographic details from the programmer while optimizing the program.

∗ 230 .

now has a scale of
This would require choosing
q = {230 , 230 , 260 , 260 , 230 , so }. Thus, although Figure 2(c) executes more instructions than Figure 2(a), it requires the same
Q. A better way to insert R ESCALE instructions is shown in
Figure 2(d). This satisfies Constraint 1 without M OD S WITCH
instructions. The output now has a scale of 260 ∗ 230 . We can
choose q = {260 , 260 , 230 , so }, so Q = 2150 ∗ so . Hence, this
program is more efficient than the input program.
If the computation was modified to x2 + y3 in Figure 2(d),
then the last (bottom) M ULTIPLY would be replaced by A DD
and the program would violate Constraint 2 as A DD would
have operands with scales 260 and 230 . Consider a similar but simpler example of x2 + x in Figure 3(a). One way
to satisfy Constraints 1 and 2 is by adding R ESCALE and
M OD S WITCH, as shown in Figure 3(b), which would require
q = {230 , 230 , so }. Another way is to introduce M ULTIPLY
of x and a constant 1 with 230 scale to match the scale of
A DD operands, as shown in Figure 3(c), which would require
q = {260 , so }. Although the product Q = 260 ∗ so is same in
both cases, the modulus length r is different. Hence, the program in Figure 3(c) is more efficient due to a smaller r.
M ULTIPLY has another constraint. Each ciphertext consists
of 2 or more polynomials. M ULTIPLY of two ciphertexts
with k and l polynomials yields a ciphertext with k + l + 1
polynomials. Nevertheless, fewer the polynomials faster the
M ULTIPLY, so we enforce it to be the minimum:
∀i n.parmi .num_polynomials = 2
if n.op ∈ {M ULTIPLY}

4.3. Execution Flow of the Compiler
As mentioned in Section 3, the in-memory internal representation of the EVA compiler is an Abstract Semantic Graph,
also known as a Term Graph, of the input program. In the
rest of this paper, we will use the term graph to denote an
Abstract Semantic Graph. In this in-memory representation,
each node can access both its parents and its children, and
for each output, a distinct leaf node is added as a child. It
is straightforward to construct the graph from the EVA program and vice-versa, so we omit the details. We use the terms
program and graph interchangeably in the rest of the paper.
Algorithm 1 presents the execution flow of the compiler.
There are four main steps, namely transformation, validation,
parameters selection, and rotations selection. The transformation step takes the input program and modifies it to satisfy
the constraints of all instructions, while optimizing it. In the
next step, the transformed program is validated to ensure that
no constraints are violated. If any constraints are violated,
then the compiler throws an exception. By doing this, EVA
ensures that executing the output program will never lead
to a runtime exception thrown by the FHE library. Finally,
for the validated output program, the compiler selects the bit
sizes and the rotation steps that must be used to determine
the encryption parameters and the public keys required for
rotations respectively, before executing the output program.
The transformation step involves rewriting the graph, which is
described in detail in Section 5. The other steps only involve
traversal of the graph (without changing it), which is described
in Section 6.

(3)

R ELINEARIZE reduces the number of polynomials in a ciphertext to 2. This constraint guarantees that any relinearization
in the program would reduce the number of polynomials in
a ciphertext from 3 to 2, thereby ensuring that only one public key is sufficient for all relinearizations in the program.
R ELINEARIZE can be inserted in the program in Figure 2(d)
to satisfy this constraint, as shown in Figure 2(e).
Finally, we use s f to denote the maximum allowed rescale
value in the rest of this paper (log2 s f is also the maximum bit
size that can be used for encryption parameters), i.e.,
n.parm2 .value ≤ s f
if n.op ∈ {R ESCALE}

Input :Program Pi in EVA language
Input :Scales Si for inputs in Pi
Input :Desired scales Sd for outputs in Pi
Output :Program Po in EVA language
Output :Vector Bv of bit sizes
Output :Set Rs of rotation steps
Po = Transform(Pi , Si )
if Validate(Po ) == Failed then
Throw an exception
Bv = DetermineParameters(Po , Si , Sd )
Rs = DetermineRotationSteps(Pi , Si )

5. Transformations in EVA Compiler
In this section, we describe the key graph transformations in
the EVA compiler. We first describe a general graph rewrit-

(4)

7

ALWAYS − RESCALE

n ∈ Insts
Insts ← Insts ∪ {ns }

WATERLINE − RESCALE

LAZY − MODSWITCH

EAGER − MODSWITCH

n ∈ Insts
n.op = M ULTIPLY
Nck = {(nc , k) | nc .parmk = n}
(n.parm1 .scale ∗ n.parm2 .scale)/s f ≥ max(∀n j ∈ {Consts, Inputs}, n j .scale)
Insts ← Insts ∪ {ns }

n ∈ Insts

ns .op ← R ESCALE
ns .parm1 ← n
∀(nc , k) ∈ Nck , nc .parmk ← ns

n.op ∈ {A DD, S UB, M ULTIPLY}

Insts ← Insts ∪ {nm }

nm .op ← M OD S WITCH

ns .parm2 ← s f

n.parmi .level > n.parmj .level
nm .parm1 ← n.parmj

n.parmj ← nm

n ∈ {Insts, Consts, Inputs}
n1c .parmi = n
n2c .parmj = n
n1c .parmi .rlevel > n2c .parmj .rlevel
Nck = {(nc , k) | nc .parmk = n ∧ nc .parmk .rlevel = n2c .parmj .rlevel}
Insts ← Insts ∪ {nm }

MATCH − SCALE

RELINEARIZE

Nck = {(nc , k) | nc .parmk = n}

n.op = M ULTIPLY

ns .op ← R ESCALE
ns .parm1 ← n
ns .parm2 ← min(∀ j, n.parmj .scale)
∀(nc , k) ∈ Nck , nc .parmk ← ns

n ∈ Insts

nm .op ← M OD S WITCH

n ∈ Insts

nm .parm1 ← n

n.op ∈ {A DD, S UB}

n.parmi .scale > n.parmj .scale

Insts ← Insts ∪ {nt }
Consts ← Consts ∪ {nc }
nt .op ← M ULTIPLY
nt .parm1 ← n.parmj
n.op = M ULTIPLY

Insts ← Insts ∪ {nl }

nc .value ← n.parmi .scale/n.parmj .scale
nt .parm2 ← nc
n.parmj ← nt

n.parm1 .type = n.parm2 .type = Cipher

nl .op ← R ELINEARIZE

∀(nc , k) ∈ Nck , nc .parmk ← nm

nl .parm1 ← n

Nck = {(nc , k) | nc .parmk = n}

∀(nc , k) ∈ Nck , nc .parmk ← nl

Figure 4: Graph rewriting rules (each rule is a transformation pass) in EVA (s f : maximum allowed rescale value).

ing framework (Section 5.1). Then, we describe the graph
transformation passes (Sections 5.2 and 5.3).

EVA includes a graph rewriting framework for arbitrary
rewrite rules for a subgraph that consists of a node along
with its parents or children. The rewrite rules for each graph
transformation pass in EVA are defined in Figure 4. A single backward pass is sufficient for EAGER-MODSWITCH,
while a single forward pass is sufficient for the rest. The
rewrite rules assume the passes are applied in a specific
order: WATERLINE-RESCALE, EAGER-MODSWITCH,
MATCH-SCALE, and RELINEARIZE (ALWAYS-RESCALE
and LAZY-MODSWITCH are not used but defined only for
clarity). For the sake of exposition, we will first describe
RELINEARIZE pass before describing the other passes.

5.1. Graph Rewriting Framework
A graph transformation can be captured succinctly using graph
rewrite rules (or term rewrite rules). These rules specify the
conditional transformation of a subgraph (or an expression)
and the graph transformation consists of transforming all applicable subgraphs (or expressions) in the graph (or program).
The graph nodes have read-only properties like the opcode and
number of parents. In a graph transformation, some state or
data may be stored on each node in the graph and the rewrite
rules may read and update the state.
The rewrite rules specify local operations on a graph and
the graph transformation itself is composed of applying these
operations wherever needed. The schedule in which these
local operations are applied may impact the correctness or
efficiency of the transformation. Consider two schedules:
1. Forward pass from roots to leaves of the graph: a node
is scheduled for rewriting only after all its parents have
already been rewritten.
2. Backward pass from leaves to roots of the graph: a node
is scheduled for rewriting only after all its children have
already been rewritten.
Note that the rewriting operation may not do any modifications
if its condition does not hold. In forward pass, state (or data)
flows from parents to children. Similarly, in backward pass,
state (or data) flows from children to parents. In general,
multiple forward or backward passes may be needed to apply
the rewrite rules until quiescence (no change).

5.2. Relinearize Insertion Pass
Each ciphertext is represented as 2 or more polynomials. Multiplying two ciphertexts each with 2 polynomials yields a
ciphertext with 3 polynomials. The R ELINEARIZE instruction
reduces a ciphertext to 2 polynomials. To satisfy Constraint 3,
EVA must insert R ELINEARIZE after M ULTIPLY of two nodes
with Cipher type and before another such M ULTIPLY.
The RELINEARIZE rewrite rule (Figure 4) is applied for
a node n only if it is a M ULTIPLY operation and if both its
parents (or parameters) have Cipher type. The transformation
in the rule inserts a R ELINEARIZE node nl between the node
n and its children. In other words, the new children of n will
be only nl and the children of nl will be the old children of n.
For the example graph in Figure 2(d), applying this rewrite
rule transforms the graph into the one in Figure 2(e).
Optimal placement of relinearization is an NP-hard problem [10]. Our relinearization insertion pass is a simple way to
8

A rescale chain c of a node n and c0 of a node n0 are equal
if (|c| = |c0 | and (∀0 ≤ i < |c|, ci = c0i or ci = ∞ or c0i = ∞)).
A rescale chain c of a node n ∈ V is conforming if ∀ rescale
chain c0 of n, c is equal to c0 .

enforce Constraint 3. More advanced relinearization insertion,
with or without Constraint 3, is left for future work.
5.3. Rescale and ModSwitch Insertion Passes
Goal: The R ESCALE and M OD S WITCH nodes (or instructions) must be inserted such that they satisfy Constraint 1, so
the goal of the R ESCALE and M OD S WITCH insertion passes
is to insert them such that the coefficient moduli of the parents
of any A DD and M ULTIPLY node are equal.
While satisfying Constraint 1 is sufficient for correctness,
performance depends on where R ESCALE and M OD S WITCH
are inserted (as illustrated in Section 4.2). Different choices
lead to different coefficient modulus q = {q1 , q2 , ..., qr }, and
consequently, different polynomial modulus N for the roots
(or inputs) to the graph (or program). Larger values of N
and r increase the cost of every FHE operation and the memory of every ciphertext. N is a non-decreasing function of
Q = ∏ri=1 qi (i.e., if Q grows, N either remains the same or
grows as well). Minimizing both Q and r is a hard problem to
solve. However, reducing Q is only impactful if it reduces N,
which is unlikely as the threshold of Q, for which N increases,
grows exponentially. Therefore, the goal of EVA is to yield the
optimal r, which may or may not yield the optimal N.

Note that all the roots in the graph have the same coefficient
modulus. Therefore, for nodes n1 and n2 , the coefficient modulus of the output of n1 is equal to that of n2 if and only if
there exists conforming rescale chains for n1 and n2 , and the
conforming rescale chain of n1 is equal to that of n2 . Thus, we
need to solve two problems simultaneously:
• Constraints: Ensure the conforming rescale chains of the
parents of any M ULTIPLY or A DD node are equal.
• Optimization: Minimize the length of the rescale chain of
every node.
Outline: In general, the constraints problem can be solved
in two steps:
• Insert R ESCALE in a pass (to reduce exponential growth of
scale and noise).
• Insert M OD S WITCH in another pass so that the constraints
are satisfied.
The challenge is in solving this problem in this way, while
yielding the desired optimization.

Constrained-Optimization Problem: The only nodes that
modify a ciphertext’s coefficient modulus are R ESCALE and
M OD S WITCH nodes; that is, they are the only ones whose
output ciphertext has a different coefficient modulus than that
of their input ciphertext(s). Therefore, the coefficient modulus
of the output of a node depends only on the R ESCALE and
M OD S WITCH nodes in the path from the root to that node. To
illustrate their relation, we define the term rescale chain.

Always Rescale Insertion: A naive approach of inserting
R ESCALE is to insert it after every M ULTIPLY of Cipher
nodes. We call this approach as always rescale and define
it in the ALWAY-RESCALE rewrite rule in Figure 4. Consider
the example in Figure 2(a). Applying this rewrite rule on this
example yields the graph in Figure 2(b). For some M ULTIPLY
nodes (e.g., the bottom one), the conforming rescale chains
of their parents do not exist or do not match. To satisfy these
constraints, M OD S WITCH nodes can be inserted appropriately,
as shown in Figure 2(c) (we omit defining this rule because
it would require multiple forward passes). The conforming
rescale chain length for the output is now more more than the
multiplicative depth of the graph. Thus, always rescale and
its corresponding modswitch insertion may lead to a larger
coefficient modulus (both in the number of elements and their
product) than not inserting any of them.

Definition 1 Given a directed acyclic graph G = (V, E):
For n1 , n2 ∈ V , n1 is a parent of n2 if ∃(n1 , n2 ) ∈ E.
A node r ∈ V is a root if r.type = Cipher and @n ∈ V s.t. n
is a parent of r.
Definition 2 Given a directed acyclic graph G = (V, E):
A path p from a node n0 ∈ V to a node n ∈ V is a sequence
of nodes p0 , ..., pl s.t. p0 = n0 , pl = n, and ∀0 ≤ i < l, pi ∈ V
and pi is a parent of pi+1 . A path p is said to be simple if
∀0 < i < l, pi .op 6= R ESCALE and pi .op 6= M OD S WITCH.

Insight: Consider that all the roots in the graph have the
same scale s. For example in Figure 2(a), let x.scale = 230
instead of 260 . Then, after always rescale (replace 260 with
230 in Figure 2(b)), the only difference between the rescale
chains of a node n would be their length and not the values in
it. This is the case even when roots may have different scales
as long as all R ESCALE nodes rescale by the same value s.
Then, a conforming rescale chain cn for n can be obtained by
adding M OD S WITCH nodes in the smaller chain(s). Thus, |cn |
would not be greater than the multiplicative depth of n. The
first key insight of EVA is that using the same rescale value
for all R ESCALE nodes ensures that |co | cannot be greater
than the multiplicative depth of o (a tight upper bound). The
multiplicative depth of a node n is not a tight lower bound

Definition 3 Given a directed acyclic graph G = (V, E):
A rescale path p to a node n ∈ V is a sequence of nodes
p0 , ..., pl s.t. (∀0 ≤ i ≤ l, pi .op ∈ {R ESCALE, M OD S WITCH}),
∃ a simple path from a root to p0 , ∃ a simple path from pl to
n, (∀0 ≤ i < l, ∃ a simple path from pi to pi+1 ), and (n.op =
R ESCALE or n.op = M OD S WITCH) =⇒ (pl = n) .
A rescale chain of a node n ∈ V is a vector c s.t. ∃ a rescale
path p to n and (∀0 ≤ i < |p|, (pi .op = M OD S WITCH =⇒
ci = ∞) and (pi .op = R ESCALE =⇒ ci = pi .parm2 .value)).
Note that ∞ is used here to distinguish M OD S WITCH from
R ESCALE in the rescale chain.
9

or more efficient code than lazy insertion.
Matching Scales: As illustrated in Section 4.2, it is easy
to match scales of parents of A DD by multiplying one of
the parents and 1 with the appropriate scale. The MATCHSCALE rewrite rule (Figure 4) takes this simple approach
to satisfy Constraint 2 while avoiding introduction of any
additional R ESCALE or M OD S WITCH. For the example graph
in Figure 3(a), applying this rewrite rule transforms the graph
into the one in Figure 3(c).

Figure 5: x2 + x + x in EVA: (a) after WATERLINE-RESCALE
(b) after WATERLINE-RESCALE & LAZY-MODSWITCH; (c) after
WATERLINE-RESCALE & EAGER-MODSWITCH.

Optimality: EVA selects encryption parameters (see Seco
e),
tion 6.2) s.t. r = max(∀o ∈ {Out puts}, 1 + |co | + d o.scale∗s
sf
where so is the desired scale for the output o. WATERLINERESCALE is the only pass that determines |co | and o.scale
for any output o (neither LAZY-MODSWITCH nor MATCHSCALE modify that). If |co | is decreased by 1 (an element
s f from co is removed), then o.scale would increase by at
least s f , so it would not decrease r. Due to waterline rescale,
o.scale < sw ∗ s f , so R ESCALE cannot be inserted to reduce
o.scale by at least s f (because the minimum required scale is
sw ). Thus, EVA yields the minimal or optimal r.

for |cn |, as shown in Figure 2(d). The second key insight of
EVA is that using the maximum rescale value s f (satisfying
Constraint 4) for all R ESCALE nodes minimizes |co | because
it minimizes the number of R ESCALE nodes in any path.
Waterline Rescale Insertion: Based on our insights, the
value to rescale is fixed to s f (= 260 in SEAL). That does not
address the question of when to insert R ESCALE nodes. If the
scale after R ESCALE becomes too small, then the computed
message may lose accuracy irrevocably. We call the minimum
required scale as waterline and use sw to denote it. We choose
sw to be maximum of the scales of all roots. Consider a
M ULTIPLY node n whose scale after multiplication is sn . Then,
a R ESCALE in inserted between n and its children only if the
scale after R ESCALE is above the waterline, i.e., (sn /s f ) ≥ sw .
We call this approach as waterline rescale and define the
WATERLINE-RESCALE rewrite rule in Figure 4. This rule
(assuming sw = 230 instead of 260 ) transforms the graph in
Figure 2(a) to the one in Figure 2(d).

6. Analysis in EVA Compiler
In this section, we briefly describe our graph traversal framework (Section 6.1) and a few analysis passes (Section 6.2).
6.1. Graph Traversal Framework and Executor
EVA’s graph traversal framework allows either a forward
traversal or a backward traversal of the graph. In the forward traversal pass, a node is visited only after all its parents
are visited. Similarly, in the backward traversal pass, a node
is visited only after all its children are visited. Graph traversals do not modify the structure of the graph (unlike graph
rewriting) but a state on each node can be maintained during
the traversal. A single pass is sufficient to perform forward or
backward data-flow analysis of the graph because the graph is
acyclic. Execution of the graph is a forward traversal of the
graph, so uses the same framework.

ModSwitch Insertion: For a node n, let n.level denote its
conforming rescale chain length. Let n.rlevel denote the conforming rescale chain length of n in the transpose graph.
A naive way to insert M OD S WITCH is to find a A DD or
M ULTIPLY node for which level of the parents do not match
and insert the appropriate number of M OD S WITCH nodes between one of the parents and the node. We call this lazy
insertion and define the LAZY-MODSWITCH rewrite rule
in Figure 4. We call inserting it at the earliest feasible edge
in the graph as eager insertion. The EAGER-MODSWITCH
rewrite rule (Figure 4) finds a node for which rlevel of the
children do not match and inserts the appropriate number of
M OD S WITCH nodes between some of the children and itself.
If the rlevel of the roots do not match, then there is another
rule (omitted in Figure 4 for brevity) that inserts the appropriate M OD S WITCH nodes between some of the roots and their
children.
Consider the x2 +x+x example in Figure 5(a). Applying the
LAZY-MODSWITCH and EAGER-MODSWITCH rewrite
rules yields the graphs in Figures 5(b) and (c) respectively. The
operands of A DD after eager insertion use a smaller coefficient
modulus than after lazy insertion, so A DD would be faster if
eager insertion is used. Thus, eager insertion leads to similar

Parallel Implementation: We implement an executor for
the generated EVA program using the traversal framework.
A node is said to be ready or active if all its parents (or children) in forward (or backward) pass have already been visited.
These active nodes can be scheduled to execute in parallel as
each active node only updates its own state (i.e., there are no
conflicts). For example in Figure 2(e), the parents of the bottom M ULTIPLY can execute in parallel. Each FHE instruction
(node) can take a significant amount of time to execute, so it
is useful to exploit parallelism among FHE instructions. The
EVA executor automatically parallelizes the generated EVA
program by implementing a parallel graph traversal using the
Galois [36, 19] parallel library.
A node is said to retire if all its children (or parents) in
forward (or backward) pass have already been visited. The
10

state for the retired nodes will no longer be accessed, so it can
be reused for other nodes. In Figure 2(e), the ciphertext for x2
can be reused after the R ELINEARIZE is executed. The EVA
executor automatically reuses the memory used for encrypted
messages, thereby reducing the memory consumed.

1
2
3
4
5
6

6.2. Analysis Passes
Validation Passes: We implement a validation pass for each
of the constraints in Section 4.2. All are forward passes. The
first pass computes the rescale chains for each node and asserts
that it is conforming. It also asserts that the conforming rescale
chains of parents of A DD and M ULTIPLY match, satisfying
Constraint 1. The second and third passes compute a scale and
num_polynomials for each node respectively and assert that
Constraint 2 and 3 is satisfied respectively. If any assertion
fails, an exception in thrown at compile-time. Thus, these
passes elide runtime exceptions thrown by SEAL.

7
8
9
10
11
12
13
14
15
16
17
18
19

Encryption Parameter Selection Pass: Akin to encryption
selection in CHET [17], the encryption parameter selection
pass in EVA computes the conforming rescale chain and the
scale for each node. For each leaf or output o after the pass,
let co be the conforming rescale chains of o without ∞ in it
and let s0o = so ∗ o.scale, where so is the desired output scale.
s0o is factorized into s0 ∗ s1 ∗ ... ∗ sk such that sk is a power-oftwo, sk ≤ s f (= 260 in SEAL), and ∀0 ≤ i < k, si = s f . Let
|s0o | denote the number of factors of s0o . Then EVA finds the
output m with the maximum |cm | + |s0m |. The factors of sm are
appended to cm and s f (the special prime that is consumed
during encryption) is inserted at the beginning of cm . For each
element s in cm , log2 s is applied to obtain a vector of bit sizes,
which is then returned.

20
21
22

from EVA import *
def sqrt(x):
return x*constant(scale, 2.214) +
(x**2)*constant(scale, -1.098) +
(x**3)*constant(scale, 0.173)
program = Program(vec_size=64*64)
scale = 30
with program:
image = inputEncrypted(scale)
F = [[-1, 0, 1],
[-2, 0, 2],
[-1, 0, 1]]
for i in range(3):
for j in range(3):
rot = image << (i*64+j)
h = rot * constant(scale, F[i][j])
v = rot * constant(scale, F[j][i])
first = i == 0 and j == 0
Ix = h if first else Ix + h
Iy = v if first else Iy + v
d = sqrt(Ix**2 + Iy**2)
output(d, scale)

Figure 6: PyEVA program for Sobel filtering 64 × 64 images.
The sqrt function evaluates a 3rd degree polynomial approximation of square root.

context and additionally returns an instance of class Expr,
which stores a reference to the input node. The expression
additionally overrides Python operators to provide the simple
syntax seen here.
7.2. EVA for Neural Network Inference
CHET [17] is a compiler for evaluating neural networks on
encrypted inputs. The CHET compiler receives a neural network as a graph of high-level tensor operations, and through
its kernel implementations, analyzes and executes these neural
networks against FHE libraries. CHET lacks a proper backend
and operates more as an interpreter coupled with automatically
chosen high-level execution strategies.
We have obtained the CHET source code and modified it to
use the EVA compiler as a backend. CHET uses an interface
called Homomorphic Instruction Set Architecture (HISA) as
a common abstraction for different FHE libraries. In order
to make CHET generate EVA programs, we introduce a new
HISA implementation that instead of calling homomorphic
operations inserts instructions into an EVA program. This
decouples the generation of the program from its execution.
We make use of CHET’s data layout selection optimization,
but not its encryption parameter selection functionality, as this
is already provided in EVA. Thus, EVA subsumes CHET.

Rotation Keys Selection Pass: Similar to rotation keys selection in CHET [17], EVA’s rotation keys selection pass computes and returns the set of unique step counts used among all
ROTATE L EFT and ROTATE R IGHT nodes in the graph.

7. Frontends of EVA
The various transformations described so far for compiling an
input EVA program into an executable EVA program make up
the backend in the EVA compiler framework. In this section,
we describe two frontends for EVA, that make it easy to write
programs for EVA.
7.1. PyEVA
We have built a general-purpose frontend for EVA as a DSL
embedded into Python, called PyEVA. Consider the PyEVA
program in Figure 6 for Sobel filtering, which is a form of
edge detection in image processing. The class Program is a
wrapper for the Protocol Buffer [22] format for EVA programs
shown in Figure 1. It includes a context manager, such that
inside a with program: block all operations are recorded in
program. For example, the inputEncrypted function inserts
an input node of type Cipher into the program currently in

8. Experimental Evaluation
In this section, we first describe our experimental setup (Section 8.1). We then describe our evaluation of homomorphic
neural network inference (Section 8.2) and homomorphic arith11

Table 3: Deep Neural Networks used in our evaluation.

Network
LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNetCIFAR

No. of layers

# FP

Accu-

Conv

FC

Act

operations

racy(%)

2
2
2
5
10

2
2
2
2
0

4
4
4
6
9

159960
5791168
21385674
37759754

98.45
99.11
99.30
79.38

Table 5: Average latency (s) of CHET and EVA on 56 threads.

Model
LeNet-5-small
LeNet-5-medium
LeNet-5-large
Median
SqueezeNet-CIFAR

Input Scale (log P) Output Accuracy(%)
Cipher Vector Scalar Scale CHET EVA

LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

25
25
25
30
25

15
15
20
15
15

10
10
10
10
10

30
30
25
30
30

98.42
99.07
99.34
79.31

EVA

Speedup from EVA

3.7
5.8
23.3
70.4
344.7

0.6
1.2
5.6
9.6
72.7

6.2
4.8
4.2
7.3
4.7

in Table 3:
• The three LeNet-5 networks are all for the MNIST [31]
dataset, which vary in the number of neurons. The largest
one matches the one used in the TensorFlow’s tutorials [41].
• Industrial is a network from an industry partner for privacysensitive binary classification of images.
• SqueezeNet-CIFAR is a network for the CIFAR-10
dataset [30] that uses 4 Fire-modules [14] and follows the
SqueezeNet [26] architecture.
We obtain these networks (and the models) from the authors
of CHET, so they match the networks evaluated in their paper [17]. Industrial is a FHE-compatible neural network that
is proprietary, so the authors gave us only the network structure without the trained model (weights) or the test datasets.
We evaluate this network using randomly generated numbers
(between -1 and 1) for the model and the images. All the other
networks were made FHE-compatible by CHET authors using
average-pooling and polynomial activations instead of maxpooling and ReLU activations. Table 3 lists the accuracies we
observed for these networks using unencrypted inference on
the test datasets. We evaluate encrypted image inference with
a batch size of 1 (latency).

Table 4: Programmer-specified input and output scaling factors used for both CHET and EVA, and the accuracy of homomorphic inference in CHET and EVA (all test inputs).

Model

CHET

98.45
99.09
99.32
79.34

metic, statistical machine learning, and image processing applications (Section 8.3).
8.1. Experimental Setup
All experiments were conducted on a 4 socket machine with
Intel Xeon Gold 5120 2.2GHz CPU with 56 cores (14 cores per
socket) and 190GB memory. Our evaluation of all applications
uses GCC 8.1 and SEAL v3.3.1 [40], which implements the
RNS variant of the CKKS scheme [11]. All experiments use
the default 128-bit security level.
We evaluate a simple arithmetic application to compute the
path length in 3-dimensional space. We also evaluate applications in statistical machine learning, image processing, and
deep neural network (DNN) inferencing using the frontends
that we built on top of EVA (Section 7). For DNN inferencing,
we compare EVA with the state-of-the-art compiler for homomorphic DNN inferencing, CHET [17], which has been shown
to outperform hand-tuned codes. For the other applications, no
suitable compiler exists for comparison. Hand-written codes
also do no exist as it is very tedious to write them manually.
We evaluate these applications using EVA to show that EVA
yields good performance with little programming effort. For
DNN inferencing, the accuracy reported is for all test inputs,
whereas all the other results reported are an average over the
first 20 test inputs. For the other applications, all results reported are an average over 20 different randomly generated
inputs.

Scaling Factors: The scaling factors, or scales in short,
must be chosen by the user. For each network (and model),
we use CHET’s profiling-guided optimization on the first 20
test images to choose the input scales as well as the desired
output scale. There is only one output but there are many
inputs. For the inputs, we choose one scale each for Cipher,
Vector, and Scalar inputs. Both CHET and EVA use the same
scales, as shown in Table 4. The scales impact both performance and accuracy. We evaluate CHET and EVA on all test
images using these scales and report the accuracy achieved by
fully-homomorphic inference in Table 4. There is negligible
difference between their accuracy and the accuracy of unencrypted inference (Table 3). Higher values of scaling factors
may improve the accuracy, but will also increase the latency
of homomorphic inference.
Comparison with CHET Compiler: Table 5 shows that
EVA is at least 4× faster than CHET on 56 threads for all
networks. Note that the average latency of CHET is slower
than that reported in their paper [17]. This could be due to
differences in the experimental setup. The input and output
scales they use are different, so is the SEAL version (3.1 vs.
3.3.1). We suspect the machine differences to be the primary
reason for the slowdown because they use smaller number of

8.2. Deep Neural Network (DNN) Inference
Networks: We evaluate five deep neural network (DNN) architectures for image classification tasks that are summarized
12

LeNet-5-medium

LeNet-5-large

Table 6: Encryption parameters selected by CHET and EVA
(where Q = ∏ri=1 Qi ).

256
32
64
8

Average Latency (s)

CHET

Model
log2 N
LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

16
2
Industrial

SqueezeNet-CIFAR

15
15
15
16
16

log2 Q

EVA
r

log2 N

log2 Q

r

480 8
480
8
740 13
1222 21
1740 29

14
14
15
15
16

360
360
480
810
1225

6
6
8
14
21

2048
128

large. Reducing N and r reduces the cost (and the memory)
of each homomorphic operation (and ciphertext) significantly.
In CHET, R ESCALE and M OD S WITCH used by the experts
for a given tensor kernel may be sub-optimal for the program.
On the other hand, EVA performs global (inter-procedural)
analysis to minimize the length of the coefficient modulus,
yielding much smaller encryption parameters.

512
32
128
2

8

32

2

Threads
CHET

8

32

EVA

To understand the differences in parallelization, we evaluated CHET and EVA on 1, 7, 14, 28, and 56 threads. Figure 7
shows the strong scaling. We omit LeNet-5-small because it
takes too little time, even on 1 thread. It is apparent that EVA
scales much better than CHET. The parallelization in CHET
is within a tensor operation or kernel using OpenMP. Such
static, bulk-synchronous schedule limits the available parallelism. In contrast, EVA dynamically schedules the directed
acyclic graph of EVA (or SEAL) operations asynchronously.
Thus, it exploits the parallelism available across tensor kernels, resulting in much better scaling. The average speedup of
EVA on 56 threads over EVA on 1 thread is 18.6× (excluding
LeNet-5-small).

Figure 7: Strong scaling of CHET and EVA (log-log scale).

heavier cores (16 3.2GHz cores vs. 56 2.2GHz cores). In any
case, our comparison of CHET and EVA is fair because both
use the same input and output scales, SEAL version, ChannelHeight-Width (CHW) data layout, and hardware. Both CHET
and EVA perform similar encryption parameters and rotation
keys selection. The differences between CHET and EVA are
solely due to the benefits that accrue from EVA’s low-level
optimizations.
CHET relies on an expert-optimized library of homomorphic tensor kernels, where each kernel (1) includes FHEspecific instructions and (2) is explicitly parallelized. However,
even experts cannot optimize or parallelize across different
kernels as that information is not available to them. In contrast,
EVA uses a library of vectorized tensor kernels and automatically (1) inserts FHE-specific instructions using global analysis and (2) parallelizes the execution of different instructions
across kernels. Due to these optimizations, EVA is on average
5.3× faster than CHET. On a single thread (Figure 7), EVA
is on average 2.3× faster than CHET and this is solely due to
better placement of FHE-specific instructions. The rest of the
improvement on 56 threads (2.3× on average) is due to better
parallelization in EVA.
Both CHET and EVA have similar R ELINEARIZE placement. However, they differ in the placement of the other FHEspecific instructions — R ESCALE and M OD S WITCH. These
instructions directly impact the encryption parameters (both
CHET and EVA use a similar encryption parameter selection
pass). We report the encryption parameters selected by CHET
and EVA in Table 6. EVA selects much smaller coefficient
modulus, both in terms of the number of elements r in it
and their product Q. Consequently, the polynomial modulus
N is one power-of-2 lower in all networks, except LeNet-5-

Comparison with Hand-Written LoLa: LoLa [7] implements hand-tuned homomorphic inference for neural networks,
but the networks they implement are different than the ones
we evaluated (and the ones in CHET). Nonetheless, they implement networks for the MNIST and CIFAR-10 datasets.
For the MNIST dataset, LoLa implements the highly-tuned
CryptoNets [20] network (which is similar in size to LeNet5-small). This implementation has an average latency of 2.2
seconds and has an accuracy of 98.95%. EVA takes only 1.2
seconds on a much larger network, LeNet-5-medium, with a
better accuracy of 99.09%. For the CIFAR-10 dataset, LoLa
implements a custom network which takes 730 seconds and
has an accuracy of 74.1%. EVA takes only 72.7 seconds on a
much larger network with a better accuracy of 79.34%.
LoLa uses SEAL 2.3 (which implements BFV [18]) which
is less efficient than SEAL 3.3.1 (which implements RNSCKKS [11]) but much more easier to use. EVA is faster
because it exploits a more efficient FHE scheme which is
much more difficult to manually write code for. Thus, EVA
outperforms even highly tuned expert-written implementations
like LoLa with very little programming effort.
13

9. Related Work

Table 7: Compilation, encryption context (context), encryption,
and decryption time for EVA.

Libraries for FHE SEAL [40] implements RNS variants of
two FHE schemes: BFV [18] and CKKS [12, 11]. HElib [24]
implements two FHE schemes: BGV [6] and CKKS. PALISADE [37] is a framework that provides a general API for
multiple FHE schemes including BFV, BGV, and CKKS. For
BFV and CKKS, PALISADE is similar to SEAL as it only
implements lower-level FHE primitives. On the other hand,
EVA language abstracts batching-compatible FHE schemes
like BFV, BGV, and CKKS while hiding cryptographic details
from the programmer. Although EVA compiler currently generates code targeting only CKKS implementation in SEAL,
it can be adapted to target other batching-compatible FHE
scheme implementations or FHE libraries.

Time (s)

Model

Compilation Context Encrypt Decrypt
LeNet-5-small
LeNet-5-medium
LeNet-5-large
Industrial
SqueezeNet-CIFAR

0.14
1.21
0.50
1.26
1.13
7.24
0.59 15.70
4.06 160.82

0.03
0.03
0.08
0.12
0.42

0.01
0.01
0.02
0.03
0.26

Table 8: Evaluation of EVA for fully-homomorphic arithmetic,
statistical machine learning, and image processing applications on 1 thread (LoC: lines of code).

Application
3-dimensional Path Length
Linear Regression
Polynomial Regression
Multivariate Regression
Sobel Filter Detection
Harris Corner Detection

Vector Size

LoC

Time (s)

4096
2048
4096
2048
4096
4096

45
10
15
15
35
40

0.394
0.027
0.104
0.094
0.511
1.004

General-Purpose Compilers for FHE To reduce the burden of writing FHE programs, general-purpose compilers have
been proposed that target different FHE libraries. These
compilers share many of the same goals as ours. Some
of these compilers support general-purpose languages like
Julia (cf. [2]), C++ (cf. [13]), and R (cf. [3]), whereas
ALCHEMY [15] is the only one that provides its own generalpurpose language. Unlike EVA, none of these languages are
amenable to be a target for domain-specific compilers like
CHET [17] because these languages do not support rotations
on fixed power-of-two sized vectors. Nonetheless, techniques
in these compilers (such as ALCHEMY’s static type safety
and error rate analysis) are orthogonal to our contributions in
this paper and can be incorporated in EVA.
All prior general-purpose compilers target (libraries implementing) either the BFV scheme [18] or the BGV scheme [6].
In contrast, EVA targets (libraries implementing) the recent
CKKS scheme [12, 11], which is much more difficult to write
or generate code for (compared to BFV or BGV). For example, ALCHEMY supports the BGV scheme and would require
significant changes to capture the semantics (e.g., R ESCALE)
of CKKS. ALCHEMY always inserts M OD S WITCH after every ciphertext-ciphertext multiplication (using local analysis),
which is not optimal for BGV (or BFV) and would not be
correct for CKKS. EVA is the first general-purpose compiler
for CKKS and it uses a graph rewriting framework to insert R ESCALE and M OD S WITCH operations correctly (using
global analysis) so that the modulus chain length is optimal.
These compiler passes in EVA can be incorporated in other
general-purpose compilers (to target CKKS).

Compilation Time: We present the compilation time, encryption context time, encryption time, and decryption time
for all networks in Table 7. The encryption context time includes the time to generate the public key, the secret key, the
rotation keys, and the relinearization keys. This can take a
lot of time, especially for large N, like in SqueezeNet-CIFAR.
Compilation time, encryption time, and decryption time are
negligible for all networks.
8.3. Arithmetic, Statistical Machine Learning, and Image
Processing
We implemented several applications using PyEVA. To illustrate a simple arithmetic application, we implemented an
application that computes the length of a given encrypted 3dimensional path. This computation can be used as a kernel in
several applications like in secure fitness tracking on mobiles.
For statistical machine learning, we implemented linear regression, polynomial regression, and multi-variate regression
on encrypted vectors. For image processing, we implemented
Sobel filter detection and Harris corner detection on encrypted
images. All these implementations took very few lines of code
(< 50), as shown in Table 8.
Table 8 shows the execution time of these applications on
encrypted data using 1 thread. Sobel filter detection takes half
a second and Harris corner detection takes only a second. The
rest take negligible time. We believe Harris corner detection
is one of the most complex programs that have been evaluated
using CKKS. EVA enables writing advanced applications in
various domains with little programming effort, while providing excellent performance.

Domain-Specific Compilers for FHE Some prior compilers for DNN inferencing [17, 5, 4] target CKKS. CHET [17]
is a compiler for tensor programs that automates the selection of data layouts for mapping tensors to vectors of vectors.
The nGraph-HE [5] project introduced an extension to the
Intel nGraph [16] deep learning compiler that allowed data
scientists to make use of FHE with minimal code changes.
The nGraph-HE compiler uses run-time optimization (e.g.,
detection of special plaintext values) and compile-time opti14

mizations (e.g., use of ISA-level parallelism, graph-level optimizations). nGraph-HE2 [4] is an extension of nGraph-HE
that uses a hybrid computational model – the server interacts with the client to perform non-HE compatible operations,
which increases the communication overhead. Moreover, unlike CHET and EVA, neither nGraph-HE nor nGraph-HE2
automatically select encryption parameters.
To hide the complexities of FHE operations, all existing
domain-specific compilers rely on a runtime of high-level kernels which can be optimized by experts. However, experts
are limited to information within a single kernel (like convolution) to optimize insertion of FHE-specific operations and
to parallelize execution. In contrast, EVA optimizes insertion
of FHE-specific operations by using global analysis and parallelizes FHE operations across kernels transparently. Therefore,
CHET, nGraph-HE, and nGraph-HE2 can target EVA instead
of the FHE scheme directly to benefit from such optimizations
and we demonstrated this for CHET.

unmodified version by 5.3× on average. EVA provides a solid
foundation for a richer variety of FHE applications as well as
domain-specific compilers and auto-vectorizing compilers for
computing on encrypted data.

Acknowledgments
This research was supported by the NSF grants 1406355,
1618425, 1705092, 1725322, and by the DARPA contracts
FA8750-16-2-0004 and FA8650-15-C-7563. We thank Keshav
Pingali for his support. We thank the anonymous reviewers
and in particular our shepherd, Petar Tsankov, for their many
suggestions in improving this paper.

References
[1] Martin Albrecht, Melissa Chase, Hao Chen, Jintai Ding, Shafi Goldwasser, Sergey Gorbunov, Shai Halevi, Jeffrey Hoffstein, Kim Laine,
Kristin Lauter, Satya Lokam, Daniele Micciancio, Dustin Moody,
Travis Morrison, Amit Sahai, and Vinod Vaikuntanathan. Homomorphic encryption security standard. Technical report, HomomorphicEncryption.org, Toronto, Canada, November 2018.
[2] David W. Archer, José Manuel Calderón Trilla, Jason Dagit, Alex Malozemoff, Yuriy Polyakov, Kurt Rohloff, and Gerard Ryan. Ramparts:
A programmer-friendly system for building homomorphic encryption
applications. In Proceedings of the 7th ACM Workshop on Encrypted
Computing &#38; Applied Homomorphic Cryptography, WAHC’19,
pages 57–68, New York, NY, USA, 2019. ACM.
[3] Louis JM Aslett, Pedro M Esperança, and Chris C Holmes. A review
of homomorphic encryption and software tools for encrypted statistical
machine learning. arXiv preprint arXiv:1508.06574, 2015.
[4] Fabian Boemer, Anamaria Costache, Rosario Cammarota, and Casimir
Wierzynski. nGraph-HE2: A high-throughput framework for neural network inference on encrypted data. In Proceedings of the 7th
ACM Workshop on Encrypted Computing & Applied Homomorphic
Cryptography, 2019.
[5] Fabian Boemer, Yixing Lao, Rosario Cammarota, and Casimir
Wierzynski. nGraph-HE: A graph compiler for deep learning on
homomorphically encrypted data. In Proceedings of the 16th ACM
International Conference on Computing Frontiers, 2019.
[6] Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. (Leveled)
fully homomorphic encryption without bootstrapping. In Shafi Goldwasser, editor, ITCS 2012: 3rd Innovations in Theoretical Computer
Science, pages 309–325, Cambridge, MA, USA, January 8–10, 2012.
Association for Computing Machinery.
[7] Alon Brutzkus, Ran Gilad-Bachrach, and Oren Elisha. Low latency
privacy preserving inference. In Kamalika Chaudhuri and Ruslan
Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, ICML, 2019.
[8] Hervé Chabanne, Amaury de Wargny, Jonathan Milgram, Constance
Morel, and Emmanuel Prouff. Privacy-preserving classification on
deep neural network. IACR Cryptology ePrint Archive, page 35, 2017.
[9] Nishanth Chandran, Divya Gupta, Aseem Rastogi, Rahul Sharma, and
Shardul Tripathi. Ezpc: Programmable and efficient secure two-party
computation for machine learning. In IEEE European Symposium on
Security and Privacy, EuroS&P, 2019.
[10] Hao Chen. Optimizing relinearization in circuits for homomorphic
encryption. CoRR, abs/1711.06319, 2017. https://arxiv.org/
abs/1711.06319.
[11] Jung Hee Cheon, Kyoohyung Han, Andrey Kim, Miran Kim, and Yongsoo Song. A full RNS variant of approximate homomorphic encryption.
In Carlos Cid and Michael J. Jacobson Jr:, editors, SAC 2018: 25th
Annual International Workshop on Selected Areas in Cryptography,
volume 11349 of Lecture Notes in Computer Science, pages 347–368,
Calgary, AB, Canada, August 15–17, 2019. Springer, Heidelberg, Germany.
[12] Jung Hee Cheon, Andrey Kim, Miran Kim, and Yong Soo Song. Homomorphic encryption for arithmetic of approximate numbers. In
Tsuyoshi Takagi and Thomas Peyrin, editors, Advances in Cryptology –
ASIACRYPT 2017, Part I, volume 10624 of Lecture Notes in Computer
Science, pages 409–437, Hong Kong, China, December 3–7, 2017.
Springer, Heidelberg, Germany.
[13] Cingulata. https://github.com/CEA-LIST/Cingulata, 2018.

Compilers for MPC Multi-party computation (MPC) [21,
43] is another technique for privacy-preserving computation.
The existing MPC compilers [23] are mostly general-purpose
and even though it is possible to use them for deep learning
applications, it is hard to program against a general-purpose
interface. The EzPC compiler [9] is a machine learning compiler that combines arithmetic sharing and garbled circuits and
operates in a two-party setting. EzPC uses ABY [34] as a
cryptographic backend.
Privacy-Preserving Deep Learning CryptoNets [20], one
of the first systems for neural network inference using FHE and
the consequent work on LoLa [7], a low-latency CryptoNets,
show the ever more practical use of FHE for deep learning.
CryptoNets and LoLa however use kernels for neural networks
that directly translate the operations to the cryptographic primitives of the FHE schemes. There are also other algorithms
and cryptosystems specifically for deep learning that rely on
FHE (CryptoDL [25], Chabanne et al. [8], Jiang et al. [28]),
MPC (Chameleon [38], DeepSecure [39], SecureML [35]),
oblivious protocols (MiniONN [32]), or on hybrid approaches
(Gazelle [29], SecureNN [42]). None of these provide the
flexibility and the optimizations of a compiler approach.

10. Conclusions
This paper introduces a new language and intermediate representation called Encrypted Vector Arithmetic (EVA) for
general-purpose Fully-Homomorphic Encryption (FHE) computation. EVA includes a Python frontend that can be used
to write advanced programs with little programming effort,
and it hides all the cryptographic details from the programmer.
EVA includes an optimizing compiler that generates correct,
secure, and efficient code, targeting the state-of-the-art SEAL
library. EVA is also designed for easy targeting of domain specific languages. The state-of-the-art neural network inference
compiler CHET, when re-targeted onto EVA, outperforms its
15

[14] David Corvoysier.

Squeezenet for CIFAR-10.
https:
//github.com/kaizouman/tensorsandbox/tree/master/
cifar10/models/squeeze, 2017.

[29] Chiraag Juvekar, Vinod Vaikuntanathan, and Anantha Chandrakasan.
GAZELLE: A low latency framework for secure neural network inference. In William Enck and Adrienne Porter Felt, editors, USENIX
Security 2018: 27th USENIX Security Symposium, pages 1651–1669,
Baltimore, MD, USA, August 15–17, 2018. USENIX Association.
[30] Alex Krizhevsky. The CIFAR-10 dataset. https://www.cs.
toronto.edu/~kriz/cifar.html, 2009.
[31] Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. The
MNIST database of handwritten digits. http://yann.lecun.com/
exdb/mnist/.
[32] Jian Liu, Mika Juuti, Yao Lu, and N. Asokan. Oblivious neural network
predictions via MiniONN transformations. In Bhavani M. Thuraisingham, David Evans, Tal Malkin, and Dongyan Xu, editors, ACM CCS
2017: 24th Conference on Computer and Communications Security,
pages 619–631, Dallas, TX, USA, October 31 – November 2, 2017.
ACM Press.
[33] Vadim Lyubashevsky, Chris Peikert, and Oded Regev. On ideal lattices
and learning with errors over rings. In Henri Gilbert, editor, Advances
in Cryptology – EUROCRYPT 2010, volume 6110 of Lecture Notes
in Computer Science, pages 1–23, French Riviera, May 30 – June 3,
2010. Springer, Heidelberg, Germany.
[34] Payman Mohassel and Peter Rindal. ABY3 : A mixed protocol framework for machine learning. In David Lie, Mohammad Mannan,
Michael Backes, and XiaoFeng Wang, editors, ACM CCS 2018: 25th
Conference on Computer and Communications Security, pages 35–52,
Toronto, ON, Canada, October 15–19, 2018. ACM Press.
[35] Payman Mohassel and Yupeng Zhang. SecureML: A system for scalable privacy-preserving machine learning. In 2017 IEEE Symposium
on Security and Privacy, pages 19–38, San Jose, CA, USA, May 22–26,
2017. IEEE Computer Society Press.
[36] Donald Nguyen, Andrew Lenharth, and Keshav Pingali. A Lightweight
Infrastructure for Graph Analytics. In Proceedings of the TwentyFourth ACM Symposium on Operating Systems Principles, SOSP ’13,
pages 456–471, New York, NY, USA, 2013. ACM.
[37] Palisade homomorphic encryption software library. https://
palisade-crypto.org/, 2020.
[38] M. Sadegh Riazi, Christian Weinert, Oleksandr Tkachenko, Ebrahim M.
Songhori, Thomas Schneider, and Farinaz Koushanfar. Chameleon:
A hybrid secure computation framework for machine learning applications. In Jong Kim, Gail-Joon Ahn, Seungjoo Kim, Yongdae Kim,
Javier López, and Taesoo Kim, editors, ASIACCS 18: 13th ACM Symposium on Information, Computer and Communications Security, pages
707–721, Incheon, Republic of Korea, April 2–6, 2018. ACM Press.
[39] Bita Darvish Rouhani, M. Sadegh Riazi, and Farinaz Koushanfar.
Deepsecure: Scalable provably-secure deep learning. In Proceedings of the 55th Annual Design Automation Conference, DAC ’18,
pages 2:1–2:6, New York, NY, USA, 2018. ACM.
[40] Microsoft SEAL (release 3.3). https://github.com/Microsoft/
SEAL, June 2019. Microsoft Research, Redmond, WA.
[41] LeNet-5-like
convolutional
MNIST
model
example.

[15] Eric Crockett, Chris Peikert, and Chad Sharp. Alchemy: A language
and compiler for homomorphic encryption made easy. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, page 1020–1037, New York, NY, USA, 2018.
Association for Computing Machinery.
[16] Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla, Jayaram
Bobba, Matthew Brookhart, Avijit Chakraborty, William Constable,
Christian Convey, Leona Cook, Omar Kanawi, Robert Kimball, Jason
Knight, Nikolay Korovaiko, Varun Kumar Vijay, Yixing Lao, Christopher R. Lishka, Jaikrishnan Menon, Jennifer Myers, Sandeep Aswath
Narayana, Adam Procter, and Tristan J. Webb. Intel ngraph: An intermediate representation, compiler, and executor for deep learning.
CoRR, abs/1801.08058, 2018.
[17] Roshan Dathathri, Olli Saarikivi, Hao Chen, Kim Laine, Kristin Lauter,
Saeed Maleki, Madanlal Musuvathi, and Todd Mytkowicz. Chet:
An optimizing compiler for fully-homomorphic neural-network inferencing. In Proceedings of the 40th ACM SIGPLAN Conference on
Programming Language Design and Implementation, 2019.
[18] Junfeng Fan and Frederik Vercauteren. Somewhat practical fully homomorphic encryption. Cryptology ePrint Archive, Report 2012/144,
2012. https://eprint.iacr.org/2012/144.
[19] Galois system, 2019.
[20] Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin E. Lauter,
Michael Naehrig, and John Wernsing. Cryptonets: Applying neural
networks to encrypted data with high throughput and accuracy. In
Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages
201–210, 2016.
[21] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to play any
mental game or A completeness theorem for protocols with honest
majority. In Alfred Aho, editor, 19th Annual ACM Symposium on
Theory of Computing, pages 218–229, New York City, NY, USA,
May 25–27, 1987. ACM Press.
[22] Protocol
buffer.
https://developers.google.com/
protocol-buffers. Google Inc.
[23] Marcella Hastings, Brett Hemenway, Daniel Noble, and Steve
Zdancewic. SoK: General purpose compilers for secure multi-party
computation. In 2019 IEEE Symposium on Security and Privacy,
pages 1220–1237, San Francisco, CA, USA, May 19–23, 2019. IEEE
Computer Society Press.
[24] Helib. https://github.com/homenc/HElib, 2020.
[25] Ehsan Hesamifard, Hassan Takabi, and Mehdi Ghasemi. Cryptodl:
Deep neural networks over encrypted data. CoRR, abs/1711.05189,
2017.
[26] Forrest N. Iandola, Matthew W. Moskewicz, Khalid Ashraf, Song
Han, William J. Dally, and Kurt Keutzer. Squeezenet: Alexnet-level
accuracy with 50x fewer parameters and <1mb model size. CoRR,
abs/1602.07360, 2016. https://arxiv.org/abs/1602.07360.
[27] Cryptography Lab in Seoul National University. Homomorphic encryption for arithmetic of approximate numbers (heaan). https:
//github.com/snucrypto/HEAAN.
[28] Xiaoqian Jiang, Miran Kim, Kristin E. Lauter, and Yongsoo Song. Secure outsourced matrix computation and application to neural networks.
In David Lie, Mohammad Mannan, Michael Backes, and XiaoFeng
Wang, editors, ACM CCS 2018: 25th Conference on Computer and
Communications Security, pages 1209–1222, Toronto, ON, Canada,
October 15–19, 2018. ACM Press.

https://github.com/tensorflow/models/blob/v1.9.0/
tutorials/image/mnist/convolutional.py, 2016.

[42] Sameer Wagh, Divya Gupta, and Nishanth Chandran. SecureNN: 3party secure computation for neural network training. Proceedings on
Privacy Enhancing Technologies, 2019(3):26–49, July 2019.
[43] Andrew Chi-Chih Yao. How to generate and exchange secrets (extended abstract). In 27th Annual Symposium on Foundations of Computer Science, pages 162–167, Toronto, Ontario, Canada, October 27–
29, 1986. IEEE Computer Society Press.

16

