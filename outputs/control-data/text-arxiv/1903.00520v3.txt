arXiv:1903.00520v3 [cs.SY] 4 Jun 2019

A Reachability Method for Verifying Dynamical
Systems with Deep Neural Network Controllers
Kyle D. Julian

Mykel J. Kochenderfer

Department of Aeronautics and Astronautics
Stanford University
Stanford, CA 94305
Email: kjulian3@stanford.edu

Department of Aeronautics and Astronautics
Stanford University
Stanford, CA 94305
Email: mykel@stanford.edu

Abstract—Deep neural networks can be trained to be efficient
and effective controllers for dynamical systems; however, the
mechanics of deep neural networks are complex and difficult to
guarantee. This work presents a general approach for providing
guarantees for deep neural network controllers over multiple
time steps using a combination of reachability methods and
open source neural network verification tools. By bounding the
system dynamics and neural network outputs, the set of reachable
states can be over-approximated to provide a guarantee that the
system will never reach states outside the set. The method is
demonstrated on the mountain car problem as well as an aircraft
collision avoidance problem. Results show that this approach can
provide neural network guarantees given a bounded dynamic
model.

I. I NTRODUCTION
Neural networks are global function approximators that
can efficiently and accurately represent any target domain. In
recent years, neural networks have become widely used for
decision making and control in dynamical systems such as
pendulums [1], video games [2], autonomous vehicles [3], and
aircraft collision avoidance systems [4]. Neural network controllers can be generated in many ways, including supervised
learning to compress existing controllers [5], Neural Fitted Q
Iteration [1], and deep Q-learning [2].
In some domains, neural network controllers can make
decisions better than human experts, but guarantees about
their performance are difficult to prove, inhibiting their use
in safety-critical systems. Whereas traditional model checking techniques may be sufficient to verify logic-based controllers [6], new verification techniques are required to ensure
that complex and non-linear neural network controllers will
always generate safe trajectories.
Recent advancements in neural network verification tools
have yielded many options for proving bounds on neural
network outputs [7]. Given some region of the input space,
these verification tools define what values could be given
by the neural network and provide either a guarantee of a
correct output or a counterexample. Some tools work layer
by layer through the network to compute a reachable set of
each layer, ending with the reachable output of the network
given the input region [8], [9]. Other tools formulate neural
network verification as a mixed-integer linear programming
and use optimization methods to find counterexamples [10],

[11]. Tools such as Reluplex [12] and Sherlock [13] convert
neural networks into linear programs and systematically search
for a satisfying counterexample. While these tools ensure that
input regions satisfy some network output property for a single
evaluation, ensuring safety for multiple network evaluations
over time remains difficult due to system dynamics and
uncertainties.
Recent work involved developing methods for the verification of neural network controllers for agents acting in an
environment. These methods use a reachability approach that
computes the set of states the system can reach given an
initial set of states and a controller. Akintunde, Lomuscio,
Maganti, et al. [14] formulate neural agents and their dynamics as a large mixed-integer linear program, which can
be solved to verify the agent’s safety. This method requires
linearly-definable dynamics, but non-linear dynamics can be
approximated by a neural network with arbitrary precision.
Ivanov, Weimer, Alur, et al. [15] formulate sigmoid-activated
neural networks with one hidden layer as a hybrid system to
compute reachability sets over time. Xiang, Lopez, Musau, et
al. [16] train neural networks to output the next state in a
nonlinear system instead of a control input. They compute an
over-approximation of the reachable set at each time step to
bound the trajectories of state variables. In addition, Xiang
and Johnson [17] bound the neural network output over small
hyper-rectangular input sets and use reachability tools for
linear systems to compute reachable sets for a trajectory.
This work builds upon prior work and uses a general
reachability algorithm for an agent controlled by a neural
network. Whereas many previous approaches combine the
neural network controller output with a dynamics model, we
separate the two components and analyzes each individually.
Our method is applicable to any network architecture or activation function, and any existing neural network verification
tool can be used. Furthermore, by analyzing the dynamics
separately, our method can consider complex actions that are
not well represented by linear models. While Xiang and
Johnson [17] demonstrate their approach on continuous-time
linear control systems, our experiments use discrete control
actions. Additionally, our work considers the degree of
uncertainty that can be present in the system dynamics before
safety can no longer be guaranteed, allowing us to make claims

about how a real system with errors will be able to maintain
safety. A mountain car example is provided to illustrate the
approach on a classic problem. In addition, an aircraft collision
avoidance problem inspired by the next-generation system
ACAS X [18] demonstrates how the approach can handle
complex and real-world systems. Our experimental results
provide performance and safety guarantees from any initial
starting point in the full input space.
II. A PPROACH
This section describes the reachability method used to
provide guarantees about neural network controlled systems.
First, the neural network is over-approximated in order to
bound the outputs given in different regions of the state space.
Then a general reachability method is formulated that uses
the network bounds to over-approximate the system’s set of
reachable states, which provides a guarantee that states outside
the set cannot be achieved. If unsafe states lie entirely outside
the reachable set, then the system is safe.
A. Neural Network Over-approximation
Neural network controllers give control actions a = f (s) for
states s ∈ S, where S is the controller state space. Because the
neural network function can be highly nonlinear, predicting the
neural network output can be difficult. However, many tools
have been developed recently to verify neural networks, which
can bound the behavior of neural networks. For a small set of
states S ⊂ S, tools such as Reluplex [12], Sherlock [13],
Reluval [19], and Verisig [15] can be used to guarantee that
f (s) ∈ AS ∀ s ∈ S, where AS is a bound on the neural
network output in set S. For neural networks with discrete
outputs, AS represents the set of all discrete actions that
could be chosen by the neural network for some point in S.
For neural networks with n continuous control outputs, AS
represents some n-dimensional polytope. If S is divided into
N small subsets, or cells, then A = {AS1 , AS2 , . . . , ASN }
bounds the neural network output. By assuming that the neural
network can give any action a ∈ AS from any point s ∈ S,
the neural network controller is over-approximated.
B. Reachability Method
Let SN = {S1 , S2 , . . . , SN } be the set of all N cells
that divide S, and define Rt ⊆ SN to be the set of cells
reachable at time t. The initial reachable set R0 is problem
specific and can include all or some specific subset of SN .
The reachability method iteratively computes Rt+1 given Rt
and A. To compute Rt+1 , first compute the region of state
space RS ⊆ S that can be reached at the next time step from
S with control inputs from AS . With system dynamics g(s, a)
for state s and control input a, RS can be defined as
RS = {g(s, a) : s ∈ S, a ∈ AS }

(1)

In general, there may be uncertainty surrounding g(s, a).
Factors such as modeling errors, disturbances, or human error
may cause the dynamics of real systems to differ from ideal
equations. This work considers these errors to obtain safety

Algorithm 1 Reachability for networks with discrete actions
Input: R0 , SN , T
Output: {R1 , R2 , . . . , RT }
1: for t = 1 to T
2:
Rt ← ∅
3:
for S ∈ Rt−1
4:
Compute AS using neural network verification tool
5:
for a ∈ AS
6:
Compute RS using state dynamics
7:
for S 0 ∈TSN
8:
if S 0 RS 6=S∅
9:
Rt ← Rt S 0
10: return {R1 , R2 , . . . , RT }

guarantees considering some level of error in g(s, a). One way
to incorporate these errors is to expand RS to include all states
that could be reached with error in the dynamics.
Next, the set of cells that could be reached from cell Si ∈
Rt is calculated as
i
Rst+1
= {S : S ∈ SN , S ∩ RSi 6= ∅}

(2)

Equation (2) over-approximates RS by including all cells
that have some intersection with RS . Lastly, the set of cells
reachable at the next time step from any cell in Rt is
[
i
Rt+1 =
RSt+1
(3)
Si ∈Rt

Algorithm 1 outlines the steps for this method.
Because the neural network and system dynamics are overapproximated, this method will over-approximate the reachable set at each time step. As a result, all states outside the
reachable set at time t are impossible to reach from the initial
set of states. If the reachable set is contained within a goal
set or excludes a failure set, then this method verifies that the
neural network controller will be safe at time t.
C. Implementation Considerations
Although the proposed method can verify neural network
controllers, its implementation may raise a few concerns. First,
neural network verification tools can be slow, so checking
each discrete cell may seem slow especially as the number of
cells grows. However, many neural network verification tools
run faster as input bounds become tighter, so checking many
small regions may not be slower than checking fewer large
regions. Furthermore, computing RS becomes more complicated with higher-dimensional state spaces. In two dimensions
with linear dynamics and rectangular cells, computing RS is
straightforward, but more complicated dynamic models for
higher-dimensional spaces can prove challenging. Fortunately
many tools exist to perform reachability over-approximations
for complex problems, such as SpaceEx, which uses lazy set
computation with Zonotopes for efficient computation with
hundreds of state variables [20]. Another tool, JuliaReach, uses
the high performance Julia language to compute reachable sets

·10−2

u = 1 (Right)

Speed

5

0

u = −1 (Left)

Fig. 1: Mountain car problem [22] with goal state marked by the flag

assuming convex sets and currently supports linear dynamics [21]. These tools provide efficient methods for reachable
set estimation that can be used to enable this approach for
complex neural network systems.
Additionally, if a cell S ∈ Rt is also in Rt+1 given control
inputs AS , then S will remain in all future reachable sets,
which could be problematic if S is in an undesirable area
of the state space. This problem can be caused by overapproximation errors, which can be improved by shrinking
the cells. However, making cells smaller can quickly lead to
an explosion in the number of cells to consider, especially at
higher dimensions. It is important to reduce cell size in critical
areas of the state space without generating so many cells that
reachability computation becomes too slow.
III. M OUNTAIN C AR E XAMPLE
To demonstrate the approach, we consider the classic
mountain car problem depicted in Figure 1, where a onedimensional car must climb to the top of a hill [23]. However,
the car’s acceleration cannot overcome gravity, so the car must
rock between two hills to gain enough momentum to reach the
top of the hill. The system has two state variables, position
p and velocity v, and one control input, u. We consider the
same dynamic model as used by Ivanov, Weimer, Alur, et
al. [15] but with uniformly distributed random disturbance
δu ∼ U(−w, w) added to the control input, where w is the
maximum disturbance. The state variables are updated as
 


p
p+v
←
(4)
v
v + 0.0015(u + δu ) − 0.0025 cos(3p)
This formulation uses discrete actions, u ∈ {−1, 0, 1},
instead of continuous values. The range of positions and
velocities is p ∈ [−1.2, 0.6] and v ∈ [−0.07, 0.07] respectively,
and the goal of the car is to reach p = 0.6 as quickly as
possible.
A. Neural Network Controller
This section presents a method for generating neural network controllers, though there are many other methods that
could be used with this reachability approach. To generate
a neural network controller, the problem was first solved as
a discrete Markov decision process using POMDPs.jl [24].

−5

−1

−0.5

0

0.5

Position

Fig. 2: Mountain car neural network controller policy

In a Markov decision process, an agent in state s ∈ S takes
action a ∈ A, receives reward r(s, a), and transitions to a new
state s0 with probability T (s, a, s0 ), where T is the transition
function [25]. Discrete value iteration was used to compute
policy π that maximizes the accumulation of reward overtime.
In discrete value iteration, Q-values are associated with each
state-action pair, with initial Q0 (s, a) = 0. The Q-values are
updated according to the finite-horizon Bellman equation as
X
Qt+1 (s, a) = r(s, a) + max
T (s, a, s0 )Qt (s0 , a0 ) (5)
0
a

s0

After the Q-values converge, the policy is computed as π(s) =
arg maxa Q(s, a). For the mountain car problem, s = (p, v), S
is the Cartesian product of 100 uniformly distributed positions
and velocities, a = u, r(s, a) = −1(p < 0.6), and T (s0 , a, s)
has 1/3 probability for each of the next states calculated with
δu as -0.5, 0.0, and 0.5, which encourages the computed policy
to be robust to noisy accelerations. Multilinear interpolation
is used to compute the Q(s0 , a0 ) when s0 does not fall on one
of the points in the grid.
After computing the Q-values for the optimal policy, a
neural network is trained through supervised learning to approximate the Q-values. The neural network has an input
variable for each state dimension and an output variable
associated with each action. An asymmetric loss function that
penalizes under-valuing the optimal action or over-valuing the
suboptimal actions was used, which encourages the network
to approximate both the Q-values and policy well [4]. For
the mountain car problem, the neural network uses ReLU
activations and has five hidden layers of 30 units each. The
neural network was trained for 1000 epochs using Adamax
optimization [26], and the trained network predicts actions
with 97.80% accuracy and an average absolute error of 5.69.
The the policy of the trained network is shown in Figure 2,
which shows that the neural network does not recommend
u = 0 actions often if at all.

TABLE I: Mountain car neural network approximation results

·10−2
5

4

Speed

3
0
2

1
−5

Number of Nearby Cells (Thousands)

Method
5

Num. Actions

Runtime (s)

Complete

344126
344127
344130

172.9
72.99
57360

No
Yes
Yes

Sampling
ReluVal
Reluplex

discretized, then over-approximation errors would show the
car getting stuck on the side of the hill if the right action is
chosen. The final state space discretization contains 341523
hyper-rectangular cells.
C. Neural Network Approximation

−1

−0.5

0

0.5

0

Position

Fig. 3: Grid discretization for mountain car problem

B. State Space Discretization
The discretization of the input space into cells has a
significant impact on the performance of this algorithm. First,
a larger number smaller cells requires checking more queries
to with neural network verification tools, which may increase
computation time to approximate the neural network controller. In addition, using larger numbers of cells will increase
the amount of computation required to compute reachable
sets. However, larger cells lead to more over-approximation
errors, which can prevent the algorithm from proving the
desired closed-loop property. For the mountain car problem,
we wish to show that all initial starting conditions will reach
the goal. If over-approximation errors result in a cell being in
its reachable set at the next time step, then we cannot prove
that the controller will move the car away from the cell and
towards the goal. Therefore, if a cell is within its reachable
set, the cell should be divided until it is no longer a member
of its reachable set.
Selecting a good state space discretization is important for
many reachability algorithms. One method for discretization
uses a tree representation and refines leaf nodes as needed [27].
Similarly, we iteratively refined the grid when cells were
computed to be in their own reachable set. Figure 3 shows
a heat map of the final discretization used for the mountain
car problem, where the value at each pixel corresponds to
the number of grid cells within a small region around the
pixel. The discretization is uniform in most locations, but a
few key areas are more heavily discretized. First, regions with
low magnitude velocity are more heavily discretized because
the position does not change much when velocity is small. In
addition, the region around p = −0.45 is refined because this
location is the bottom of the hill where the cos(3p) gravity
term is small. Lastly, the region around p = 0.4 is refined.
In this region, selecting the action to move right has just
enough power to overcome the gravity term, resulting in a
slow climb up the hill. However, if this region is not finely

Three methods were used to approximate the neural network
policy as described in Section II-A: 100 random samples,
Reluplex [12], and ReluVal [19]. Reluplex is an SMT solver
that extends the simplex method to handle ReLU activations
and check if a set of input variables in the input region can
satisfy an output constraint [12].
ReluVal uses symbolic
interval analysis and iteratively tightens the bound until the
output property is verified or a counterexample is found [19].
To use Reluplex and ReluVal, the property we want to hold
must be negated and checked for a counterexample. For a
discrete action neural network, the action associated with the
highest network output value is used. Therefore, to check if
an action is given, the output constraint is that the value of the
target action must be less than the value of all other actions. If
a counterexample is found, then there exists a point in the input
set where the target action is given. Otherwise, if the solvers
return UNSAT, then we are guaranteed the target action is not
given within the input region. For every input region to be
checked, we target each possible action to see if that action
could be given by the neural network.
Table I reports the results where the number of actions is
the sum of the number of actions found in all cells, and the
run time reported uses a single CPU, though all methods are
easily parallelized to decrease runtime. The sampling method
misses an action in one of the cells, and Reluplex finds three
spurious actions that occur very close to the cell but outside
the cell boundaries. Decreasing the boundary error tolerance
removes these spurious actions. ReluVal identifies all actions
given within each cell and performs faster than both Reluplex
and sampling approaches.
D. Reachability Results
First, we need to compute bounds on the reachable set of
next states RS from a given set of initial states S. For a given
hyper-rectangular initial set, the input variables are bounded
by p ∈ [pmin , pmax ] and v ∈ [vmin , vmax ], and the disturbance
term is bounded by δu ∈ [−w, w]. Although the dynamics
include a nonlinear cos(3p) term, we can bound the function
as
cos(3p) ∈ [cpmin , cpmax ]

(6)

Time Steps: 0
·10−2

Time Steps: 10

Time Steps: 40

Time Steps: 80

Time Steps: 130

Reachable

5
Velocity

Time Steps: 100

0
Unreachable
−5
−1 −0.5

0

0.5

−1 −0.5

Position

0

0.5

−1 −0.5

Position

0

0.5

−1 −0.5

Position

0

0.5

−1 −0.5

Position

0

0.5

Position

−1 −0.5

0

0.5

Position

Fig. 4: Mountain car reachable set over time without disturbances

Maximum Steps to Reach Goal

·10−2
2.25

Velocity

2.2
2.15
2.1
2.05
2
0.22

S
RS
RS
Random samples
Updated samples

Reachability
MC worst
MC random

300

200

100
0

0.225

0.23

0.235

0.24

0.245

0.2

0.4

0.6

0.8

1

w

0.25

Position

Fig. 6: Mountain car maximum time to reach goal with disturbances

Fig. 5: Mountain car reachable sets and randomly sampled points
from initial cell

where
cpmin =
cpmax =

min

cos(3p)

(7)

cos(3p)

(8)

p∈[pmin ,pmax ]

max
p∈[pmin ,pmax ]

As a result, we can compute minimum and maximum
bounds for the state variables at the next time step (p0 , v 0 )
as
p0 ≥ pmin + vmin
0

(9)

p ≤ pmax + vmax

(10)

v 0 ≥ vmin − 0.0025cpmax + 0.0015(u − w)

(11)

0

v ≤ vmax − 0.0025cpmin + 0.0015(u + w)

(12)

Lastly, by subtracting p0 from v 0 , we get v 0 − p0 = −p −
0.0025 cos(3p) + 0.0015(u + δu ). We can bound this term as
v 0 − p0 ≥ −pmax − 0.0025cpmax + 0.0015(u − w)
0

0

v − p ≤ −pmin − 0.0025cpmin + 0.0015(u + w)

(13)
(14)

Using these six inequalities, we can compute a convex
polygon that contains all possible variables at the next time
step from some initial set. Figure 5 shows an example with
w = 0.5 and u = 1.0. In addition, 500 random points are

initially sampled from the input region and updated with the
mountain car dynamics. All 500 points are bounded by the
convex polygon RS . Then, RS is derived as the set of cells
in the state space that overlap with RS .
Initially, the car could be in any state, so R0 = SN . For
each cell in R0 , the set of cells that could be reached at the
next time step is computed as illustrated in Figure 5, and R1
is computed as the union of reachable cells for any of the
cells’ possible actions. Figure 4 shows the evolution of overapproximated reachable set over time using the neural network
controller. Over time the reachable set diminishes to include
only states where p = 0.6, which proves that the car will
always reach the goal when using the neural network controller
regardless of initial condition. The runtime required to evolve
reachable sets is on the order of a couple seconds, much faster
than the time required to over-approximate the neural network
controller.
Reachable sets were also computed with different levels
of dynamic disturbance to study how errors in the dynamics
effect verification. The reachability method was compared to
two Monte Carlo simulations that use worst-case and random
disturbances. The worst-case disturbance is δu = −sign(u)w
so that the disturbance always opposes the car’s acceleration,
while random disturbances are sampled from U(−w, w) at
each time step. For both Monte Carlo methods, 10000 sim-

ulations from random starting locations were evaluated, and
the maximum number of time steps to reach the goal state
was recorded. Figure 6 summarizes the results and shows that
the reachability method guarantees that the car will reach the
goal up to disturbance level w = 0.25; however, worst-case
Monte Carlo simulations show that the car will reach the goal
for w ≤ 0.5. Over-approximation errors contribute to the size
of the gap between the two approaches, and decreasing the
cell sizes to reduce over-approximation error could decrease
this gap. Random Monte Carlo simulations show no difference
for different levels of disturbances. Since the disturbance
distribution has zero mean, the disturbance has no effect
in expectation. Verifying safety in critical systems means
ensuring failures do not occur even with low probability, which
requires firm bounds on dynamic uncertainties to prevent large
disturbances from having non-zero probability.
IV. A IRCRAFT C OLLISION AVOIDANCE S YSTEM E XAMPLE
The second example considers commercial aircraft, which
are required to operate with a collision avoidance system
that gives vertical climbrate advisories to pilots to prevent
near midair collisions (NMACs). An NMAC occurs when the
aircraft are separated by less than 100 ft vertically and 500 ft
horizontally. An aircraft collision avoidance system called
ACAS X uses Q-values to represent much of the decision
making logic [18]. It uses a large table of state-action Qvalues to make decisions, but Julian, Lopez, Brush, et al. [4]
explored compressing the table using a neural network. This
section presents a notional example based loosely on an early
prototype of ACAS X [18].
A. System Description
The example collision avoidance system, referred to as
VerticalCAS, considers two aircraft: an ownship aircraft
equipped with VerticalCAS, and an intruder aircraft. In this
formulation, the intruder is assumed to maintain level flight,
but future work can relax this assumption. The system uses
four variables to describe the encounter with the intruder
aircraft:
1) h (ft): Intruder altitude relative to ownship
[−3000, 3000]
2) ḣ0 (ft/min): Ownship vertical climbrate [−2500, 2500]
3) τ (s): Time to loss of horizontal separation [0, 40]
4) sadv : Previous advisory from VerticalCAS
The first two state variables describe the encounter geometry
vertically. The τ variable condenses the horizontal geometry
into a single variable by providing a countdown until the
intruder will no longer be separated horizontally, at which
point the ownship must be vertically separated to avoid an
NMAC. These geometric variables are depicted in Figure 7.
The sadv variable is categorical and can be any one of the
nine possible advisories given by the system, and conditioning
the next advisory on the current advisory allows the system to
maintain consistency when alerting pilots. The nine possible
advisories are
1) COC: Clear of Conflict

Intruder
h

ḣ0
τ
Ownship

Fig. 7: Aircraft encounter geometry for VerticalCAS example

2) DNC: Do Not Climb
3) DND: Do Not Descent
4) DES1500: Descend at least 1500 ft/min
5) CL1500: Climb at least 1500 ft/min
6) SDES1500: Strengthen Descent to at least 1500 ft/min
7) SCL1500: Strengthen Climb to at least 1500 ft/min
8) SDES2500: Strengthen Descent to at least 2500 ft/min
9) SCL2500: Strengthen Climb to at least 2500 ft/min
Each advisory instructs the pilot to accelerate until complying with the specified climb or descent rate, except for COC,
which allows the pilot freedom to choose any acceleration
ḧ0 ∈ [−g/8, g/8], where g is the sea-level gravitational
acceleration constant, 32.2 ft/s2 . For advisories DNC, DND,
DES1500, and CL1500, the pilot is assumed to accelerate in
the range |a| ∈ [g/4, g/3] with the sign of ḧ0 determined by
the specific advisory. If the pilot is already compliant with
the given advisory, then the pilot is assumed to continue at
the current climbrate. For advisories SDES1500, SCL1500,
SDES2500, and SCL2500, the pilot as assumed to accelerate
at ±g/3 until compliance. For example, a pilot receiving the
CL1500 advisory while descending at −500 ft/min is assumed
to begin accelerating upwards with some acceleration between
g/4 and g/3 and then maintaining a constant climbrate upon
reaching the 1500 ft/min climbrate.
New advisories s0adv are given once each second (∆t = 1),
and the state variables are updated as




h
h − ḣ0 ∆t − 0.5ḧ0 ∆t2
 ḣ0 


ḣ0 + ḧ0 ∆t




(15)
 τ ←

τ − ∆t
sadv
s0adv
The reward structure contains penalties for NMACs at τ =
0 s, giving non-COC advisories, and reversing/strengthening
an advisory. Advisories that transition from a previous weak
advisory like COC or DNC to a strong advisory like SCL1500
or SDES2500 are also penalized. The reward structure contains
many terms, and Kochenderfer describes in greater detail the
reward function used here [18]. This problem was optimized
using discrete value iteration and compressed with a neural
network in the same was as described in Section III-A.
Since sadv is discrete, nine separate networks were trained,
one for each sadv . Each network has three inputs for the three
geometric state variables, five ReLU-activated hidden layers of
20 units each, and nine outputs representing the score of each
of the nine advisories. VerticalCAS recommends the highest
scoring action to the pilot. An example policy plot is shown

τ =40 s

τ =18 s

τ =6 s

τ =12 s

τ =0 s

1,000
Reachable
500
h (ft)

Unreachable
0
Unsafe Region
−500
−1,000
−2,000

0

2,000 −2,000

ḣ0 (ft/min)

0

2,000 −2,000

ḣ0 (ft/min)

2,000 −2,000

0
ḣ0 (ft/min)

2,000 −2,000

0
ḣ0 (ft/min)

0

2,000

ḣ0 (ft/min)

Fig. 8: VerticalCAS reachable set over time

1,000

1,000

h (ft)

500
500

h (ft)

DES1500

0
−500

SDES1500
0

−1,000
−2,000
SCL1500

0
ḣ0 (ft/min)

−500

2,000

−2,000

0

2,000

ḣ0 (ft/min)

COC

Fig. 10: Reachable sets for τ = 0 s,  = 3 s without (left) and with
(right) an online cost to prevent multiple reversals
−1,000

0

10

20

30

40

τ (s)

Fig. 9: VerticalCAS policy with ḣ0 = −900 ft/min, sadv = DES1500

in Figure 9, which shows that the system tends to strengthen
the previous advisory in order to avoid collisions. However, if
the intruder is well below the aircraft, then descending could
result in an NMAC, so the system reverses the advisory and
strengthens to SCL1500.
B. Reachability Results
To define SN , we first note that sadv is discrete with
nine values, and τ acts independently and can be discretized
to {0, 1, . . . , 40}. The remaining variables, h and ḣ0 , are
continuous and need to be discretized to define cells. Because
we are interested in the NMAC region where |h| ≤ 100 ft,
low magnitude h values were more finely discretized to limit
over-approximation errors in that region of the state space.
The final discretization used 231 points for h and 44 for ḣ0 ,
resulting in 3.65 million discrete cells. Reluplex was used
to approximate the neural networks, generating 32.8 million
queries in order to check for each of the nine advisories in all
discrete cells. Reluplex took 175 CPU-hours to complete, an
order of magnitude longer than for the mountain car example.
After approximating the neural networks, the reachable
sets can be computed. The reachable region RS was overapproximated by computing the minimum and maximum h

and ḣ0 values achievable from cell s given the acceleration
constraints. The initial reachable set is all cells at τ = 40 s
with sadv = COC. Each new reachable set counts down τ
until eventually τ = 0 s and the aircraft must be separated
by 100 ft vertically to avoid an NMAC. As seen in Figure 8,
the neural network controller causes the ownship to climb or
descend in order to avoid the unsafe NMAC set. This method
guarantees that no collision will occur when using the neural
network collision avoidance system, given that assumptions
made to constrain the acceleration hold. If the acceleration
limits are relaxed such that the pilot can accelerate up to
g/2, for example, then the reachable set will overlap with the
NMAC region, and safety cannot be guaranteed.
C. Pilot Delay
Assuming that a human pilot will react immediately to
collision avoidance advisories from the neural network system
is unreasonable. In reality, there will be some amount of pilot
delay when following the advisories. For maximum pilot delay
, the pilot could choose to follow any of the advisories of
the previous  seconds. Pilot delay can be incorporated into
the reachable set formulation by tracking the  most recent
advisories that result in reaching each cell. A union of cells
reachable using all possible delayed advisories is used to
compute Rt+1 instead of using the current advisory.
For a pilot delay of three seconds, safety is no longer
guaranteed, as seen in the left plot of Figure 10. For example,
consider an ownship slightly below the intruder. VerticalCAS

would alert the ownship to descend to avoid an NMAC, but
with pilot delay, the ownship could climb for  seconds instead.
At this point, the ownship could be above the intruder aircraft
in a region where VerticalCAS would reverse the advisory
to make the ownship continue climbing and gain further
separation. However, with pilot delay, the pilot could begin
following the stale descend advisories and descend instead.
The cycle repeats indefinitely, resulting in an NMAC.
One solution to fix such issues uses online costs to penalize
undesirable behavior [18]. For example, an online cost could
be applied to prevent the system from reversing the direction
of given advisories more than once. A count of reversals can
be tracked along with the previous advisories given to reach
each cell. As shown in Figure 10, preventing double reversals
is sufficient to prevent an NMAC. This reachability method
allows complex systems involving neural network controllers
alongside other variables and penalties to be analyzed to
ensure safety.

[3]

V. C ONCLUSIONS
Guaranteeing the performance of neural network controllers
in the presence of uncertainty is paramount to incorporating
such controllers in safety critical systems. We presented a
general method that uses existing neural network verification
tools to constrain the neural network output before computing
over-approximated reachable sets of system states. If the overapproximated set does not contain any unsafe states, then the
system is guaranteed to be safe. A mountain car example
demonstrated the approach and provided guarantees on time
to reach the goal for different levels of disturbances. A collision avoidance example demonstrated how complex systems
involving human delay and online costs could be modeled
and shown to be safe. The proposed method is flexible and
applicable to any neural network controller of a dynamical
system. Future work will explore higher dimensional problems
along with open source reachable set libraries in order to
decrease computation time.

[8]

ACKNOWLEDGMENTS
This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE−1656518. Any opinion, findings, and
conclusions or recommendations expressed in this material are
those of the authors and do not necessarily reflect the views
of the National Science Foundation.

[4]

[5]

[6]
[7]

[9]

[10]

[11]

[12]

[13]

[14]

R EFERENCES
[1]

M. Riedmiller, “Neural fitted Q iteration – first experiences with a data efficient neural reinforcement learning
method,” in European Conference on Machine Learning
(ECML), Springer, 2005, pp. 317–328.
[2] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J.
Veness, M. G. Bellemare, A. Graves, M. Riedmiller,
A. K. Fidjeland, G. Ostrovski, et al., “Human-level
control through deep reinforcement learning,” Nature,
vol. 518, no. 7540, pp. 529–533, 2015. DOI: 10.1038/
nature14236.

[15]

[16]

M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner,
B. Flepp, P. Goyal, L. D. Jackel, M. Monfort, U. Muller,
J. Zhang, et al., “End to end learning for self-driving
cars,” ArXiv preprint arXiv:1604.07316, 2016.
K. D. Julian, J. Lopez, J. S. Brush, M. P. Owen, and
M. J. Kochenderfer, “Policy compression for aircraft
collision avoidance systems,” in Digital Avionics Systems Conference (DASC), 2016. DOI: 10.1109/DASC.
2016.7778091.
K. D. Julian and M. J. Kochenderfer, “Neural network
guidance for UAVs,” in AIAA Guidance, Navigation,
and Control Conference (GNC), 2017, p. 1743. DOI:
10.2514/6.2017-1743.
K. L. McMillan, “Symbolic model checking,” in Symbolic Model Checking, Springer, 1993, pp. 25–60.
C. Liu, T. Arnon, C. Lazarus, C. Barrett, and M. J.
Kochenderfer, “Algorithms for verifying deep neural
networks,” ArXiv preprint arXiv:1903.06758, 2019.
T. Gehr, M. Mirman, D. Drachsler-Cohen, P. Tsankov,
S. Chaudhuri, and M. Vechev, “Ai2: Safety and robustness certification of neural networks with abstract
interpretation,” in Symposium on Security and Privacy
(SP), IEEE, 2018, pp. 3–18.
W. Xiang, H.-D. Tran, and T. T. Johnson, “Reachable set computation and safety verification for neural networks with ReLU activations,” ArXiv preprint
arXiv:1712.08163, 2017.
A. Lomuscio and L. Maganti, “An approach to reachability analysis for feed-forward ReLU neural networks,”
ArXiv preprint arXiv:1706.07351, 2017.
V. Tjeng, K. Xiao, and R. Tedrake, “Evaluating robustness of neural networks with mixed integer programming,” ArXiv preprint arXiv:1711.07356, 2017.
G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J.
Kochenderfer, “Reluplex: An efficient smt solver for
verifying deep neural networks,” in International Conference on Computer Aided Verification, Springer, 2017,
pp. 97–117. DOI: 10.1007/978-3-319-63387-9\ 5.
S. Dutta, S. Jha, S. Sankaranarayanan, and A. Tiwari,
“Output range analysis for deep feedforward neural networks,” in NASA Formal Methods Symposium, Springer,
2018, pp. 121–138.
M. Akintunde, A. Lomuscio, L. Maganti, and E.
Pirovano, “Reachability analysis for neural agentenvironment systems,” in International Conference on
Principles of Knowledge Representation and Reasoning,
2018.
R. Ivanov, J. Weimer, R. Alur, G. J. Pappas, and I.
Lee, “Verisig: Verifying safety properties of hybrid systems with neural network controllers,” ArXiv preprint
arXiv:1811.01828, 2018.
W. Xiang, D. M. Lopez, P. Musau, and T. T. Johnson,
“Reachable set estimation and verification for neural
network models of nonlinear dynamic systems,” in Safe,
Autonomous and Intelligent Vehicles, Springer, 2019,
pp. 123–144.

[17]

[18]

[19]

[20]

[21]

[22]

W. Xiang and T. T. Johnson, “Reachability analysis and
safety verification for neural network control systems,”
ArXiv preprint arXiv:1805.09944, 2018.
M. J. Kochenderfer, “Optimized airborne collision
avoidance,” in Decision Making under Uncertainty:
Theory and Application, MIT Press, 2015, ch. 10,
pp. 249–273.
S. Wang, K. Pei, J. Whitehouse, J. Yang, and S. Jana,
“Formal security analysis of neural networks using
symbolic intervals,” in Security Symposium ({USENIX}
Security 18), 2018, pp. 1599–1614.
G. Frehse, C. Le Guernic, A. Donzé, S. Cotton, R.
Ray, O. Lebeltel, R. Ripado, A. Girard, T. Dang, and
O. Maler, “Spaceex: Scalable verification of hybrid
systems,” in International Conference on Computer
Aided Verification, Springer, 2011, pp. 379–395.
S. Bogomolov, M. Forets, G. Frehse, K. Potomkin,
and C. Schilling, “JuliaReach: A toolbox for set-based
reachability,” ArXiv preprint arXiv:1901.10736, 2019.
G. Brockman, V. Cheung, L. Pettersson, J. Schneider,
J. Schulman, J. Tang, and W. Zaremba, Openai gym,
2016. eprint: arXiv:1606.01540.

[23]

[24]

[25]

[26]

[27]

A. Moore, “Efficient memory-based learning for robot
control,” PhD thesis, Carnegie Mellon University, Pittsburgh, PA, 1991.
M. Egorov, Z. N. Sunberg, E. Balaban, T. A. Wheeler,
J. K. Gupta, and M. J. Kochenderfer, “POMDPs.jl:
A framework for sequential decision making under
uncertainty,” Journal of Machine Learning, vol. 18, no.
26, pp. 1–5, 2017. [Online]. Available: http://jmlr.org/
papers/v18/16-300.html.
M. J. Kochenderfer, “Sequential problems,” in Decision
Making under Uncertainty: Theory and Application,
MIT Press, 2015, ch. 4, pp. 77–112.
D. Kingma and J. Ba, “Adam: A method for stochastic
optimization,” in International Conference on Learning Representations (ICLR), 2015. [Online]. Available:
https://arxiv.org/abs/1412.6980.
T. Han, J.-P. Katoen, and A. Mereacre, “Approximate parameter synthesis for probabilistic time-bounded
reachability,” in Real-Time Systems Symposium, IEEE,
2008, pp. 173–182.

