arXiv:1908.09295v3 [math.OC] 1 Feb 2021

A Complete Algebraic Solution to the Optimal Dynamic
Rationing Policy in the Stock-Rationing Queue
with Two Demand Classes
Quan-Lin Lia , Yi-Meng Lib , Jing-Yu Mab , Heng-Li Liub
a

School of Economics and Management

Beijing University of Technology, Beijing 100124, China
b

School of Economics and Management

Yanshan University, Qinhuangdao 066004, China
February 2, 2021

Abstract
In this paper, we study a stock-rationing queue with two demand classes by means
of the sensitivity-based optimization, and develop a complete algebraic solution to
the optimal dynamic rationing policy. We show that the optimal dynamic rationing
policy must be of transformational threshold type. Based on this finding, we can refine
three sufficient conditions under each of which the optimal dynamic rationing policy
is of threshold type (i.e., critical rationing level). To do this, we use the performance
difference equation to characterize the monotonicity and optimality of the long-run
average profit of this system, and thus establish some new structural properties of the
optimal dynamic rationing policy by observing any given reference policy. Finally,
we use numerical experiments to demonstrate our theoretical results of the optimal
dynamic rationing policy. We believe that the methodology and results developed in
this paper can shed light on the study of stock-rationing queues and open a series of
potentially promising research.
Keywords: Stock-rationing queue; inventory rationing; multiple demand classes;
optimal dynamic rationing policy; sensitivity-based optimization; Markov decision
process.

1

1

Introduction

In this paper, we consider a stock-rationing queueing problem of a warehouse with one type
of products and two classes of demands, which may be viewed as coming from retailers
with two different priority levels. Now, such a stock-rationing warehouse system becomes
more and more important in many large cities under the current COVID-19 environment.
For example, Beijing has seven super-large warehouses, which always supply various daily
necessities (e.g., vegetables, meat, eggs, seafood and so on) to more than 40 million people
every day. In the warehouses, each type of daily necessities are supplied by lots of different
companies in China and the other countries, which lead to that the successive supply
stream of each type of products can be well described as a Poisson process. In addition, the
two retailers may be regarded as a large supermarket group and another community retail
store group. Typically, the large supermarket group has a higher supply priority than the
community retail store group. When the COVID-19 at Beijing is at a serious warning, the
stock-rationing management of the warehouses and their optimal stock-rationing policy
plays a key role in strengthening the fine management of the warehouses such that every
family at Beijing can have a very comprehensive life guarantee.
From the perspective of practical applications, such a stock-rationing queueing problem
with multiple demand classes can always be encountered in many different real areas, for
example, assemble-to-order systems, make-to-stock queues and multiechelon inventory
systems by Ha [39]; multi-echelon supply chains by Raghavan and Roy [75] and Huang
and Iravani [44]; manufacturing by Zhao et al. [95]; military operations by Kaplan [51];
airline by Lee and Hersh [55]; maritime by John [50]; hotel by Bitran and Mondschein
[8]; rental business by Papier and Thonemann [72, 73] and Jain et al. [49]; health care
by Papastavrou et al. [71]; and so forth. This shows that the stock-rationing queues
with multiple demand classes are not only necessary and important in many practical
applications, but also have their own theoretical interest.
In the stock-rationing queueing systems, the stock rationing policies always assign
different supply priorities to multiple classes of demands. In the early literature, the
so-called critical rationing level was imagined intuitively, and its existence was further
proved, e.g., see Veinott Jr [85] and Topkis [81]. Once the critical rationing level is
given and the on–hand inventory falls below the critical rationing level, a low priority
demand may be either rejected, back-ordered or discarded such that the left on–hand

2

inventory will be reserved to supply the future high priority demands. Thus designing
and optimizing the critical rationing levels becomes a basic management way of inventory
rationing across multiple demand classes. So far, analysis of the critical rationing levels has
still been interesting but difficult and challenging in the study of stock-rationing queues
with multiple demand classes. Therefore, this motivates us in the paper to be interested
in the following questions:
(P-a) Does such a critical rationing level exist?
(P-b) If yes, what are the sufficient (or necessary) conditions for its existence?
(P-c) If no, which useful characteristics can be further found to study the optimal
rationing policy?
It is interesting and challenging to give a complete answer for the above three problems
. For Problems (P-a) and (P-b), there have been some research on the the optimal policy
of critical rationing levels in inventory rationing with multiple demand classes. However,
so far quite few studies have focused on Problem (P-c), since nobody know from what
point of view and how to approach Problem (P-c). Fortunately, this paper proposes and
develops an algebraic method to be able to solve Problem (P-c). Also, this paper uses the
algebraic method to be able to further deal with Problems (P-a) and (P-b) as a special
example. Therefore, this paper can further sharpen those important results given in the
literature.
Different from the submodular (or supermodular) technique of the Markov decision
processes (MDPs) developed in the inventory rationing literature (e.g., see Ha [39, 40, 41]),
this paper applies the sensitivity-based optimization to develop an algebraic method in the
study of stock-rationing queues with multiple demand classes. The key of the algebraic
(d)

method is to discuss the solution Pi

of the linear equation G(d) (i) + b = 0 with respect

to a basic economic factor (i.e., price, cost and reward), where G(d) (i) is the perturbation
(d)

realization factor given in (31). We show that for any given policy d, the solutions Pi

for 1 ≤ i ≤ K play a key role in solving the above three problems: (P-a) to (P-c). See
Theorem 10 in Subsection 7.3 for more details.
So far some research has applied the MDPs to discuss inventory rationing (and stockrationing queues) across multiple demand classes by means of the submodular (or supermodular) technique, among which important examples include Ha [39, 40, 41], Gayon et
al. [37], Benjaafar and ElHafsi [4] and Nadar et al. [67]. To do this, it is a key that the
structural properties of the optimal policy need to be identified by using a set of struc3

tured value functions that is preserved under an optimal operator. Based on this finding,
the optimal rationing policy of the inventory rationing across multiple demand classes can
be further described and expressed by means of the structural properties. In many more
general cases, it is not easy and even very difficult to set up the structural properties of
the optimal policy. For this, some stronger model assumptions have to be further added
to guarantee the existence of structural properties of the optimal policy. The purpose
of improving the applicability of the MDPs motivates us to propose another algebraic
method in this paper to develop a complete algebraic solution to the optimal policy by
means of the sensitivity-based optimization.
The sensitivity-based optimization may be regarded as a new research branch of the
MDPs, which grows out of infinitesimal perturbation analysis of discrete event dynamic
systems, e.g., see Cao [10, 11]. Note that one key of the sensitivity-based optimization
is to set up and use the so-called performance difference equation, which is based on the
perturbation realization factor as well as the performance potential related to the Poisson
equation. To the best of our knowledge, this paper is the first to apply the sensitivitybased optimization to study the stock-rationing queues with multiple demand classes. On
such a research line, there are only a few closely related works in the recent literature,
for example, the energy-efficient data centers by Ma et al. [60] and the group-server
queues by Xia et al. [92]. Different from Ma et al. [60] and Xia et al. [92], this paper
develops a complete algebraic solution to the optimal dynamic rationing policy of the
stock-rationing queue with multiple demand classes, and shows that the optimal dynamic
rationing policy must be of transformational threshold type, which can lead to refining
three sufficient conditions under each of which the optimal dynamic rationing policy is of
threshold type (see Theorem 10 in Subsection 7.3). In addition, it is worthwhile to note
that our transformational threshold type results are sharper than the bang-bang control
given in Ma et al. [60], Xia et al. [92] and others. Therefore, our algebraic method
provides not only a necessary complement of policy spatial structural integrity but also
a new way of optimality proofs when comparing to the frequently-used submodular (or
supermodular) technique of MDPs. Also, the complete algebraic solution to the optimal
dynamic rationing policy can provide more effective support for numerical computation
of the optimal policy and the optimal profit of this system.
Note that the Poisson equations always play a key role in the study of MDPs. To the
best of our knowledge, this paper provides a new general solution with two free constants:
4

A potential displacement constant, and another solution-free constant (see Theorem 1 in
Section 5). In addition, it is clear that such a general solution of the Poisson equations
can be further extended and generalized to a block structure of more general models by
means of the RG-factorizations (see Li [56]). For the Poisson equations, readers may refer
to, such as Bhulai [6], Makowski and Shwartz [61], Asmussen and Bladt [3], Bini et al. [7]
and Ma et al. [60] for more details.
Based on the above analysis, we summarize the main contributions of this paper as
follows:
(1) A complete algebraic solution: We study a stock-rationing queue with two demand
classes by means of the sensitivity-based optimization, and provide a complete algebraic solution to the optimal dynamic rationing policy. We first show that the
optimal dynamic policy must be of transformational threshold type. Then we refine
three sufficient conditions under each of which the optimal dynamic rationing policy
is of threshold type. See Theorem 10 in Subsection 7.3 for details.
(2) A unified computational framework: To the best of our knowledge, this paper is
the first to apply the sensitivity-based optimization to analyze the stock-rationing
queues with multiple demand classes. Thus it is necessary and useful to describe the
three key steps: (a) Setting up a policy-based Markov process. (b) Constructing a
policy-based Poisson equation, whose general solution can be used to characterize
the monotonicity and optimality of the long-run average profit of this system. (c)
Finding the optimal dynamic rationing policy in the three different areas of the
penalty cost. In addition, the computational framework can sufficiently support
numerical solution of stock-rationing queues with multiple demand classes while the
submodular (or supermodular) technique of MDPs is very difficult to deal with more
general stock-rationing queues.
(3) A difficult area of the penalty cost is solved: In our algebraic method, it is a key to
set up a linear equation: G(d) (i) + b = 0 in the penalty cost P for 1 ≤ i ≤ K.
(d)

We show that the solution Pi

of G(d) (i) + b = 0 for 1 ≤ i ≤ K plays a key
(d)

role in finding the optimal dynamic rationing policy. By using the solution Pi

for

1 ≤ i ≤ K, two key indices PL (d) and PH (d) are defined in (46) and (47) such that
the range of the penalty cost P is divided into three different areas: (a) P ≥ PH (d);

5

(b) PL (d) > 0 and 0 < P ≤ PL (d); and (c) PL (d) < P < PH (d). In the first
two areas, we show that the optimal dynamic rationing policy is of threshold type;
while for the third area, it is more difficult to analyze the optimal dynamic rationing
policy so that the bang-bang control is always suggested as a rough result for this
case in the literature, e.g., see Ma et al. [60] and Xia et al. [92]. Unlike those,
this paper provides a detailed analysis for the difficult area: PL (d) < P < PH (d),
characterizes the monotonicity and optimality of the long-run average profit of this
system, and further establish some new structural properties of the optimal dynamic
rationing policy by observing any given reference policy. This leads to a complete
algebraic solution to the optimal dynamic rationing policy.
(4) Two different methods can sufficiently support each other: Note that our algebraic
method sets up a complete algebraic solution to the optimal dynamic rationing policy, thus it can provide not only a necessary complement of policy spatial structural
integrity but also a new way of optimality proofs when comparing to the frequentlyused submodular (or supermodular) technique of MDPs. On the other hand, since
our algebraic method and the submodular (or supermodular) technique are all important parts of the MDPs (the former is to use the poisson equations; while the
latter is to apply the optimality equation), it is clear that the two different methods will sufficiently support each other in the study of stock-rationing queues (and
rationing inventory) with multiple demand classes.
The remainder of this paper is organized as follows. Section 2 provides a literature
review. Section 3 gives model description for the stock-rationing queue with two demand
classes. Section 4 establishes an optimization problem to find the optimal dynamic rationing policy, in which we set up a policy-based birth-death process and define a more
general reward function. Section 5 establishes a policy-based Poisson equation and provides its general solution with two free constants. Section 6 provides an explicit expression
for the perturbation realization factor G(d) (i), and discusses the solution of the linear
equation G(d) (i) + b = 0 in the penalty cost P for 1 ≤ i ≤ K. Section 7 discusses the
monotonicity and optimality of the long-run average profit of this system, and finds the
optimal dynamic rationing policy in three different areas of the penalty cost. Section 8
analyzes the stock-rationing queue under a threshold type (statical) rationing policy. Section 9 uses numerical experiments to demonstrate our theoretical results of the optimal
6

dynamic rationing policy. Finally, some concluding remarks are given in Section 10.

2

Literature Review

Our current research is related to three literature streams: The first is the research on
stock-rationing queues, critical rationing levels and their MDP proofs. The second is on
the static rationing policy and the dynamic rationing policy in inventory rationing across
multiple demand classes. The third is on a simple introduction to the sensitivity-based
optimization.
The inventory rationing across multiple demand classes was first analyzed by Veinott
Jr [85] in the context of inventory control theory. From then on, some authors have
discussed the inventory rationing problems. So far such inventory rationing has still been
interesting and challenging. Readers may refer to a book by Möllering [64]; survey papers
by Kleijn and Dekker [52] and Li et al. [59]; and a research classification by Teunter and
Haneveld [80], Möllering and Thonemann [65], Van Foreest and Wijngaard [83] and Alfieri
et al. [1].
(a) Stock-rationing queues, critical rationing levels and their MDP proofs
In a rationing inventory system, a critical rationing level was imagined from early
research and practical experience. Veinott Jr [85] first proposed such a critical rationing
level; while Topkis [81] proved that the critical rationing level really exists and it is an
optimal policy. Similar results were further developed for two demand classes by Evans
[33] and Kaplan [51].
It is a most basic problem how to mathematically prove whether a rationing inventory
system has such a critical rationing level. Ha [39] made a breakthrough by applying
the MDPs to analyze the inventory rationing policy for a stock-rationing queue with
exponential production times, Poisson demand arrivals, lost sales and multiple demand
classes. He proved that the optimal rationing policy is of critical rationing levels, and
showed that not only do the critical rationing levels exist, but also they are monotone
and stationary. Therefore, the optimal rationing policy was characterized as a monotone
constant sequence of critical rationing levels corresponding to the multiple demand classes.
Since the seminal work of Ha [39], it has been interesting to extend and generalize
the way to apply the MDPs to deal with the stock-rationing queues and the rationing
7

inventory systems. Important examples include the Erlang production times by Ha [41]
and Gayon et al. [37]; the backorders with two demand classes by Ha [40] and with multiple
demand classes by de Véricourt [19, 20]; the parallel production channels by Bulut and
Fadiloğlu [9]; the batch ordering by Huang and Iravani [45], the batch production by Pang
et al. [70]; the utilization of information by Gayon et al. [36] and ElHafsi et al. [29]; an
assemble-to-order production system by Benjaafar and ElHafsi [4], ElHafsi [27], ElHafsi
et al. [28, 30], Benjaafar et al. [5] and Nadar et al. [67]; a two-stage tandem production
system by Xu [93], supply chain by Huang and Iravani [44] and van Wijk et al. [84];
periodic review by Frank et al. [35] and Chen et al. [15]; dynamic price by Ding et al.
[24, 25], Schulte and Pibernik [76]; and so forth.
Different from those works in the literature, this paper applies the sensitivity-based
optimization to study a stock-rationing queue with two demand classes, and provides a
complete algebraic solution to the optimal dynamic rationing policy. To this end, this
paper first shows that the optimal dynamic policy must be of transformational threshold
type. Then it refines three sufficient conditions under each of which the optimal dynamic
rationing policy is of threshold type. In addition, this paper uses the performance difference equation to characterize the monotonicity and optimality of the long-run average
profit of this system, and establish some new structural properties of the optimal dynamic
rationing policy by observing any given reference policy.
(b) Inventory rationing across multiple demand classes
In the inventory rationing literature, there exist two kinds of rationing policies: The
static rationing policy, and the dynamic rationing policy. Note that the dynamic rationing
policy allows a threshold rationing level to be able to change in time, depending on the
number and ages of outstanding orders. In general, the static rationing policy is possible to
miss some chances to further improve system performance, while the dynamic rationing
policy should reflect better by means of various continuously updated information, the
system performance can be improved dynamically. Deshpande et al. [23] indicated that
the optimal dynamic rationing policy may significantly reduce the inventory cost compared
with the static rationing policy.
If there exist multiple replenishment opportunities, then the ordering policies are taken
as two different types: Periodic review and continuous review. Therefore, our literature
analysis for inventory rationing focuses on four different classes through combining the
8

rationing policy (static vs. dynamic) with the inventory review (continuous vs. periodic)
as follows: Static-continuous, static-periodic, dynamic-continuous, and dynamic-periodic.
(b-1) The static rationing policy (periodic vs. continuous)
The periodic review: Veinott Jr [85] is the first to introduce an inventory rationing
across different demand classes and to propose a critical rationing level (i.e., the static
rationing policy) in a periodic review inventory system with backorders. Subsequent research further investigated the periodic review inventory system with multiple demand
classes, for example, the (s, S) policy by Cohen et al. [18] and Tempelmeier [79]; the
(S − 1, S) policy by de Véricourt [20] and Ha [39, 40]; the lost sales by Dekkeret et al.
[21]; the backorders by Möllering and Thonemann [65]; and the anticipated critical levels
by Wang et al. [88].
The continuous review: Nahmias and Demmy [68] is the first to propose and develop
a constant critical level (Q, r, C) policy in a continuous review inventory model with
multiple demand classes, where Q is the fixed batch size, r is the reorder point and
C = (C1 , C2 , . . . , Cn−1 ) is a set of critical rationing levels for n demand classes. From
that time on, some authors have discussed the constant critical level (Q, r, C) policy in
continuous review inventory systems. Readers may refer to recent publications for details,
among which are Melchiors et al. [63], Dekkeret et al. [22], Deshpande et al. [23], Isotupa
[48], Arslan et al. [2], Möllering and Thonemann [65, 66] and Escalona et al. [32, 31].
In addition, the (S − 1, S, C) inventory system was discussed by Dekkeret et al. [21],
Kranenburg and van Houtum [53] and so on.
(b-2) The dynamic rationing policy (continuous vs. periodic)
The continuous review: Topkis [81] is the first to analyze the dynamic rationing policy, and to indicate that the optimal rationing policy is a dynamic policy. Evans [33]
and Kaplan [51] obtained similar results as that in Topkis [81] for two demand classes.
Melchiors [62] considered a dynamic rationing policy in a (s, Q) inventory system with
a key assumption that there was at most one outstanding order. Teunter and Haneveld
[80] developed a continuous time approach to determine the dynamic rationing policy for
two Poisson demand classes, analyzed the marginal cost to determine the optimal remaining time for each rationing level, and expressed the optimal threshold policy through a
schematic diagram or a lookup table. Fadıloğlu and Bulut [34] proposed a dynamic rationing policy: Rationing with Exponential Replenishment Flow (RERF), for continuous
review inventory systems with either backorders or lost sales. Wang et al. [87] developed
9

a dynamic threshold mechanism to allocate backorders when the multiple outstanding
orders for different demand classes exist for the (Q, R) inventory system.
The periodic review: For the dynamic rationing policy in a periodic review inventory
system, readers may refer to, such as two demand classes by Sobel and Zhang [77], Frank
et al. [35] and Tan et al. [78]; dynamic critical levels and lost sales by Haynsworth and
Price [42]; multiple demand classes by Hung and Hsiao [47]; two backorder classes by
Chew et al. [17]; general demand processes by Hung et al. [46]; mixed backorders and
lost sales by Wang and Tang [86]; uncertain demand and production rates by Turgay et
al. [82]; and incremental upgrading demands by You [94].
(c) The sensitivity-based optimization
In the early 1980s, Ho and Cao [43] proposed and developed infinitesimal perturbation
method of discrete event dynamic systems (DEDSs), which is a new research direction
for online simulation optimization of DEDSs since the 1980s. Readers may refer to the
excellent books by, such as Cao [10], Glasserman [38] and Cassandras and Lafortune [14].
Cao et al. [13] and Cao and Chen [12] published a seminal work that transforms
the infinitesimal perturbation, together with the MDPs and the reinforcement learning,
into the sensitivity-based optimization. On this research line, the excellent book by Cao
[11] summarized the main results in the study of sensitivity-based optimization. Li and
Liu [58] and Chapter 11 in Li [56] further extended and generalized the sensitivity-based
optimization to a more general framework of perturbed Markov processes. In addition,
the sensitivity-based optimization can be effectively developed by means of the matrixanalytic method by Neuts [69], Latouche and Ramaswami [54], and the RG-factorizations
of block-structured Markov processes by Li [56] and Ma et al. [60].
So far some research has applied the sensitivity-based optimization to analyze the
MDPs of queues and networks, e.g., see Xia and Cao [89], Xia and Shihada [91], Xia et
al. [90, 92], Ma et al. [60] and a survey paper by Li et al. [59].
Finally, to the best of our knowledge, this paper is the first to apply the sensitivitybased optimization to analyze the stock-rationing queues with multiple demand classes.
Our algebraic method sets up a complete algebraic solution to the optimal dynamic rationing policy, thus it provides not only a necessary complement of policy spatial structural
integrity but also some new proofs of monotonicity and optimality. Note that our alge10

braic method and the submodular (or supermodular) technique are all important parts
of the MDPs. The former is to mainly use the poisson equations, which are well related
to Markov (reward) processes; while the latter is to focus on the optimality equation by
applying the monotonous operator theory to prove the optimality. Therefore, it is clear
that the two different methods can sufficiently support each other in the study of stockrationing queues with multiple demand classes. We believe that the methodology and
results developed in this paper can be applicable to the study of stock-rationing queues
and open a series of potentially promising research.

3

Model Description

In this section, we describe a stock-rationing queue with two demand classes, in which
a single class of products are supplied to stock at a warehouse, and the two classes of
demands come from two retailers with different priorities. In addition, we provide system
structure, operational mode and mathematical notations.
A stock-rationing queue: The warehouse has the maximal capacity N to stock a
single class of products, and the warehouse needs to pay a holding cost C1 per product per
unit time. There are two classes of demands to order the products, in which the demands
of Class 1 have a higher priority than that of Class 2, such that the demands of Class 1
can be satisfied in any non-zero inventory; while the demands of Class 2 may be either
satisfied or refused based on the inventory level of the products. Figure 1 depicts a simple
physical system to understand the stock-rationing queue.

Figure 1: A stock-rationing queue with two demand classes
The supply process: The supply stream of the products to the warehouse is a Poisson

11

process with arrival rate λ, where the price of per product is C3 paid by the warehouse
to the external product supplier. If the warehouse is full of the products, then any new
arriving product has to be lost. In this case, the warehouse will have an opportunity cost
C4 per product rejected into the warehouse.
The service processes: The service times provided by the warehouse to satisfy the
demands of Classes 1 and 2 are i.i.d. and exponential with service rates µ1 and µ2 ,
respectively. The service disciplines for the two classes of demands are all First Come
First Serve (FCFS). The warehouse can obtain the service price R when one product is
sold to Retailer 1 or 2. Note that each demand of Class 1 or 2 is satisfied by one product
every time.
The stock-rationing rule: For the two classes of demands, each demand of Class
1 can always be satisfied in any non-zero inventory; while for satisfying the demands of
Class 2, we need to consider three different cases as follows:
Case one: The inventory level is zero. In this case, there is no product in the warehouse. Thus any new arriving demand has to be rejected immediately. This leads to the
the lost sales cost C2,1 (resp. C2,2 ) per unit time for any lost demand of Class 1 (resp. 2).
We assume that C2,1 > C2,2 , which is used to guarantee the higher priority service for the
demands of Class 1 when comparing to the lower priority for the demands of Class 2.
Case two: The inventory level is low. In this case, the number of products in the
warehouse is not more than a key threshold K, where the threshold K is subjectively
designed by means of some real experience. Note that the demands of Class 1 have a
higher priority to receive the products than the demands of Class 2. Thus the warehouse
will not provide any product to satisfy the demands of Class 2 under an equal service
condition if the number of products in the warehouse is not more than K. Otherwise,
such a service priority is violated (i.e., the demands of Class 2 are satisfied from a low
stock), so that the warehouse must pay a penalty cost P per product supplied to the
demands of Class 2 at a low stock. Note that the penalty cost P measures different
priority levels to provide the products between the two classes of demands.
Case three: The inventory level is high. In this case, the number of products in the
warehouse is more than the threshold K. Thus the demands of Classes 1 and 2 can be
simultaneously satisfied thanks to enough products in the warehouse.
Independence: We assume that all the random variables defined above are independent of each other.
12

In what follows, we use Table 1 to further summarize some above notations.
Table 1: Some costs and prices in the stock-rationing queue
C1

4

The holding cost per unit time per product stored in the warehouse

C2,1

The lost sales cost of each lost demand of Class 1

C2,2

The lost sales cost of each lost demand of Class 2

C3

The price of per product paid by the warehouse to the external product supplier

C4

The opportunity cost per product rejected into the warehouse

P

The penalty cost per product supplied to the demands of Class 2 at a low stock

R

The service price of the warehouse paid by each satisfied demand

Optimization Model Formulation

In this section, we establish an optimization problem to find the optimal dynamic rationing
policy in the stock-rationing queue. To do this, we set up a policy-based birth-death
process, and define a more general reward function with respect to both states and policies
of the policy-based birth-death process.
To study the stock-rationing queue with two demand classes, we first need to define
both ‘states’ and ‘policies’ to express stochastic dynamics of the stock-rationing queue.
Let I(t) be the number of products in the warehouse at time t. Then it is regarded as
the state of this system at time t. Obviously, all the cases of State I(t) form a state space
as follows:
Ω = {0, 1, 2, . . . , N }.
Also, State i ∈ Ω is regarded as an inventory level of this system.
From the states, some policies are defined with a little bit more complexity. Let di
be a policy related to State i ∈ Ω, and it expresses whether or not the warehouse prefers
to supply some products to the demands of Class 2 when the inventory level is not more
than the threshold K for 0 < K ≤ N .



 0,
di =
0, 1,



1,

Thus, we have
i = 0,
i = 1, 2, . . . , K,
i = K + 1, K + 2, . . . , N,

13

(1)

where di = 0 and 1 represents that the warehouse rejects and satisfies the demands of
Class 2, respectively. Obviously, not only does the policy di depend on State i ∈ Ω, but
also it is controlled by the threshold K. Of course, for a special case, if K = N , then
di ∈ {0, 1} for 1 ≤ i ≤ N .
Corresponding to each state in Ω, we define a time-homogeneous policy of the stockrationing queue as
d = (d0 ; d1 , d2 , . . . , dK ; dK+1 , dK+2 , . . . , dN ).
It follows from (1) that
d = (0; d1 , d2 , . . . , dK ; 1, 1, . . . , 1).

(2)

Thus Policy d depends on di ∈ {0, 1}, which is related to State i for 1 ≤ i ≤ K. Let
all the possible policies of the stock-rationing queue, given in (2), form a policy space as
follows:
D = {d : d = (0; d1 , d2 , . . . , dK ; 1, 1, . . . , 1), di ∈ {0, 1} , 1 ≤ i ≤ K} .
Remark 1 In general, the threshold K is subjective and is designed by means of the real
experience of the warehouse manager. If K = N , then the policy is expressed as
d = (0; d1 , d2 , . . . , dN ).
Thus our K-based policy d = (0; d1 , d2 , . . . , dK ; 1, 1, . . . , 1) is more general than Policy
d = (0; d1 , d2 , . . . , dN ).
Let I (d) (t) be the state of the stock-rationing queue at time t under any given policy

d ∈ D. Then I (d) (t) : t ≥ 0 is a continuous-time policy-based Markov process on the
state space Ω whose state transition relations are depicted in Figure 2.
O

O

0

1
P1  d1P2

O
2

P1  d 2 P2

...
P1  d3 P2

O

O

O
K

P1  d K P2

K+1

P1  P2

P1  P2

O

O

...

N-1
P1  P2

N

P1  P2

Figure 2: State transition relations of the policy-based Markov process

14

It is easy to see from Figure 2 that



I (d) (t) : t ≥ 0

is a policy-based birth-death

process. Based on this, the infinitesimal generator of the policy-based birth-death process
 (d)
I (t) : t ≥ 0 is given by


B(d)

−λ

λ


 v (d1 ) − [λ + v (d1 )]
λ


.
.
..

..
..
.



v (dK )
− [λ + v (dK )]
λ

=

v (1)
− [λ + v (1)]
λ


.
.
..

..
..
.



v (1)
− [λ + v (1)]
λ

v (1)
−v (1)












,









(3)

where v (di ) = µ1 + di µ2 for i = 1, 2, . . . , K, and v (1) = µ1 + µ2 . It is clear that v (di ) > 0
for i = 1, 2, . . . , K. Thus the policy-based birth-death process B(d) must be irreducible,
aperiodic and positive recurrent for any given policy d ∈ D. In this case, we write the

stationary probability vector of the policy-based birth-death process I (d) (t) : t ≥ 0 as


π (d) = π (d) (0); π (d) (1), . . . , π (d) (K); π (d) (K + 1), . . . , π (d) (N ) .

(4)

Obviously, the stationary probability vector π (d) is the unique solution to the system of
linear equations: π (d) B(d) = 0 and π (d) e = 1, where e is a column vector of ones with a
suitable dimension. We write

and

ξ0 = 1,






(d)
ξi =






i = 0,
i
Q

λi

,

i = 1, 2, . . . , K,

v(dj )

j=1

λi

K
Q

(µ1 +µ2 )i−K

, i = K + 1, K + 2, . . . , N,

(5)

v(dj )

j=1

(d)

h

=1+

N
X

(d)

ξi .

i=1

It follows from Subsection 1.1.4 of Chapter 1 in Li [56] that

 1 ,
i=0
h(d)
π (d) (i) =
(d)
 1 ξ , i = 1, 2, . . . , N.
h(d)

i

15

(6)

By using the policy-based birth-death process B(d) , now we define a more general
reward function in the stock-rationing queue. It is seen from Table 1 that the reward
function with respect to both states and policies is defined as a profit rate (i.e. the total
system revenue minus the total system cost per unit time). By observing the impact of
Policy d on the profit rate, the reward function at State i under Policy d is given by

f (d) (i) = R µ1 1{i>0} + µ2 di − C1 i − C2,1 µ1 1{i=0} − C2,2 µ2 (1 − di )
− C3 λ1{i<N } − C4 λ1{i=N } − P µ2 di 1{1≤i≤K} ,

(7)

where, 1{·} represents the indicator function whose value is one when the event occurs;
otherwise it is zero. By using the indicator function, satisfying and rejecting the demands
of Class 1 are expressed as 1{i>0} and 1{i=0} , respectively; the external products enter
or are lost by the warehouse according to 1{i<N } and 1{i=N } , respectively; and a penalty
cost paid by the warehouse is denoted by means of 1{1≤i≤K} due to that the warehouse
supplies the products to the demands of Class 2 at a low stock.
For the convenience of readers, it is necessary and useful to explain the reward function
(7) from four different cases as follows:
Case (a): For i = 0,
f (0) = −C2,1 µ1 − C2,2 µ2 − C3 λ.

(8)

In Case (a), there is no product in the warehouse, thus it has to reject any demand of
Classes 1 and 2.
Case (b): For 1 ≤ i ≤ K,
f (d) (i) = R (µ1 + µ2 di ) − C1 i − C2,2 µ2 (1 − di ) − C3 λ − P µ2 di .

(9)

In Case (b), since the inventory level is low for 1 ≤ i ≤ K, the penalty cost is paid by the
warehouse when it supplies the products to the demands of Class 2.
Differently from Cases (a) and (b), the inventory level is high for K + 1 ≤ i ≤ N in
Cases (c) and (d), thus it can synchronously satisfy the demands of Classes 1 and 2.
Case (c): For K + 1 ≤ i ≤ N − 1,
f (i) = R (µ1 + µ2 ) − C1 i − C3 λ.

(10)

f (N ) = R (µ1 + µ2 ) − C1 N − C4 λ.

(11)

Case (d): For i = N ,

16

Note that C3 is the price per product paid by the warehouse to the external product
supplier; while C4 is the opportunity cost per product rejected into the warehouse.
Based on the above analysis, we define an (N + 1)-dimensional column vector composed of the elements f (0) , f (d) (i) for 1 ≤ i ≤ K, and f (j) for K + 1 ≤ j ≤ N as
follows:

T
f (d) = f (0) ; f (d) (1) , f (d) (2) , . . . , f (d) (K) ; f (K + 1) , f (K + 2) , . . . , f (N ) . (12)
Now, we consider the long-run average profit of the stock-rationing queue (or the

continuous-time policy-based birth-death process I (d) (t) : t ≥ 0 ) under any given policy

d. Let

d

η = lim E
T →∞



1
T

Z

T

f

(d)

0


 
(d)
I (t) dt .

Then from Section 1 of Chapter 9 of Li [56], we obtain
η d = π (d) f (d) ,

(13)

where π (d) and f (d) are given by (4) and (12), respectively.
To further observe the long-run average profit η d , here we show how η d depends on
the penalty cost P , and particularly, η d is linear in P . To do this, we write that for i = 0,
A0 = 0, B0 = −C2,1 µ1 − C2,2 µ2 − C3 λ;
for i = 1, 2, . . . , K,
(d)

Ai

(d)

= µ2 di , Bi

= R (µ1 + µ2 di ) − C1 i − C2,2 µ2 (1 − di ) − C3 λ;

for i = K + 1, K + 2, . . . , N − 1,
Ai = 0, Bi = R (µ1 + µ2 ) − C1 i − C3 λ;
for i = N,
Ai = 0, BN = R (µ1 + µ2 ) − C1 N − C4 λ.
Then it follows from (8) to (11) that for i = 0,
f (0) = B0 ;

(14)

for i = 1, 2, . . . , K,
(d)

f (d) (i) = Bi

17

(d)

− P Ai ;

(15)

for i = K + 1, K + 2, . . . , N,
f (i) = Bi .

(16)

It follows from (6) and (14) to (16) that
η d = π (d) f (d)
=π

(d)

(0) f (0) +

K
X

π

(d)

(i) f

(d)

N
X

(i) +

i=1

π (d) (i) f (i)

i=K+1

= D (d) − P F (d) ,
where
D (d) = π (d) (0) B0 +

(17)
K
X

(d)

π (d) (i) Bi

+

i=1

and

F (d) =

N
X

π (d) (i) Bi

i=K+1

K
X

(d)

π (d) (i) Ai .

i=1

Hence the long-run average profit η d is linear in the penalty cost P .
We observe that when the inventory level is low, supplying the products to the demands
of Class 2 leads to that both the total system revenue and the total system cost increase
synchronously, and vice versa. Thus there is a tradeoff between the total system revenue
and the total system cost. This motivates us to find an optimal dynamic rationing policy
such that the warehouse has the maximal profit. Therefore, our objective is to find an
optimal dynamic rationing policy d∗ such that the long-run average profit η d is maximal
for d = d∗ , that is,

n o
d∗ = arg max η d .

(18)

d∈D

In fact, it is more difficult and challenging not only to analyze some interesting structural properties of the optimal rationing policies d∗ , but also to provide some effective
algorithms for computing the optimal dynamic rationing policy d∗ .
In the remainder of this paper, we apply the sensitivity-based optimization to study
the optimal policy problem (18), where the Poisson equations will play a key role in the
study of MDPs (and sensitivity-based optimization).

5

A Policy-Based Poisson Equation

In this section, for the stock-rationing queue, we set up a policy-based Poisson equation
which is derived by means of the law of total probability and analysis on some stopping
18

times of the policy-based birth-death process

 (d)
I (t) , t ≥ 0 . It is worth noting that

the policy-based Poisson equation provides a useful relation between the sensitivity-based
optimization and the MDPs, see, e.g. Puterman [74] and Cao [11].

For any given policy d ∈ D, it follows from Chapter 2 in Cao [11] that for the

continuous-time policy-based birth-death process I (d) (t) , t ≥ 0 , we define the perfor-

mance potential as
g

(d)

(i) = E

Z

0

+∞ h

f

(d)


i


(d)
d
(d)
I (t) − η dt I (0) = i ,

(19)

where η d is defined in (13). It is seen from Cao [11] that for Policy d ∈ D, g(d) (i) quantifies
the contribution of the initial State i to the long-run average profit of the stock-rationing
queue. Here, g(d) (i) is also called the relative value function or the bias in the traditional
MDP theory, see, e.g. Puterman [74]. We further define a column vector g(d) as

T
g(d) = g(d) (0) ; g (d) (1) , . . . , g (d) (K) ; g(d) (K + 1) , . . . , g (d) (N ) .

(20)

To compute the vector g(d) , we define the first departure time of the policy-based

birth-death process I (d) (t) : t ≥ 0 beginning from State i as
n
o
τ = inf t ≥ 0 : I (d) (t) 6= i ,

where I (d) (0) = i. Clearly, τ is a stopping time of the policy-based birth-death process
 (d)
I (t) : t ≥ 0 . Based on this, if i = 0, then it is seen from (3) that State 0 is a boundary

state of the policy-based birth-death process B(d) , hence I (d) (τ ) = 1. Similarly, for each
State i ∈ Ω, a basic relation is established as follows:


i = 0,

 1,
(d)
I (τ ) =
i − 1 or i + 1, i = 1, 2, . . . , N − 1,



N − 1,
i = N.

(21)

To compute the column vector g(d) , we derive a policy-based Poisson equation in terms

of both the stopping time τ and the basic relation (17). By using a similar computation to
that in Li and Cao [57], we set up the poisson equation according to four parts as follows:

19

Part (a): For i = 0, we have

 Z +∞ h


i
(d)
(d)
d
(d)
(d)
f
I (t) − η dt I (0) = 0
g (0) = E
0

 Z +∞ h
i


i
n
oh
f (d) I (d) (t) − η d dt I (d) (τ )
= E τ I (d) (0) = 0 f (0) − η d + E
τ

 Z +∞ h
i


i
1h
(d)
d
(d)
(d)
d
=
I (t) − η dt I (0) = 1
f
f (0) − η + E
λ
0
i
1h
=
f (0) − η d + g (d) (1) ,
λ

where for the policy-based birth-death process I (d) (t) : t ≥ 0 , it is easy to see from

Figure 2 that by using I (d) (t) = 0 for 0 ≤ t < τ,
Z τh
i
i
h


f (d) I (d) (t) − η d dt = τ f (0) − η d ,
0
n
o 1
E τ I (d) (0) = 0 = .
λ
We obtain
− λg (d) (0) + λg (d) (1) = η d − f (0) .

(22)

Part (b): For i = 1, 2, . . . , K, it is easy to see from Figure 2 that

 Z +∞ h


i
f (d) I (d) (t) − η d dt I (d) (0) = i
g (d) (i) = E
0

 Z +∞ h
i


i
n
oh
(d)
d
(d)
(d)
(d)
(d)
d
I (t) − η dt I (τ )
f
= E τ I (0) = i f (i) − η + E
τ

i
h
1
f (d) (i) − η d
=
v (di ) + λ

 Z +∞ h
i


λ
(d)
d
(d)
(d)
I (t) − η dt I (0) = i + 1
+
f
E
v (di ) + λ
0

 Z +∞ h
i


v (di )
(d)
d
(d)
(d)
+
I (t) − η dt I (0) = i − 1
f
E
v (di ) + λ
0
i
h
λ
v (di )
1
f (d) (i) − η d +
g(d) (i + 1) +
g (d) (i − 1) ,
=
v (di ) + λ
v (di ) + λ
v (di ) + λ

where

We obtain

n
o
E τ I (d) (0) = i =

1
.
v (di ) + λ

v (di ) g(d) (i − 1) − [v (di ) + λ] g(d) (i) + λg (d) (i + 1) = η d − f (d) (i) .

20

(23)

Part (c): For i = K + 1, K + 2, . . . , N − 1, by using Figure 2 we have

 Z +∞ h
i


f (d) I (d) (t) − η d dt I (d) (0) = i
g (d) (i) = E
0

 Z +∞ h
i


i
oh
n
(d)
d
(d)
(d)
(d)
d
I (t) − η dt I (τ )
f
= E τ I (0) = i f (i) − η + E
τ

i
h
1
=
f (i) − η d
µ1 + µ2 + λ

 Z +∞ h
i


λ
(d)
d
(d)
(d)
+
I (t) − η dt I (0) = i + 1
f
E
µ1 + µ2 + λ
0

 Z +∞ h
i


µ1 + µ2
(d)
d
(d)
(d)
I (t) − η dt I (0) = i − 1
f
E
+
µ1 + µ2 + λ
0
i
h
1
λ
µ1 + µ2
=
f (i) − η d +
g(d) (i + 1) +
g(d) (i − 1) ,
µ1 + µ2 + λ
µ1 + µ2 + λ
µ1 + µ2 + λ

where

We obtain

o
n
E τ I (d) (t) = i =

1
.
µ1 + µ2 + λ

(µ1 + µ2 ) g(d) (i − 1) − (µ1 + µ2 + λ) g(d) (i) + λg (d) (i + 1) = η d − f (i) .

(24)

Part (d): For i = N , by using Figure 2 we have

 Z +∞ h


i
f (d) I (d) (t) − η d dt I (d) (0) = N
g (d) (N ) = E
0

 Z +∞ h
i


i
n
oh
(d)
(d)
d
(d)
(d)
d
I (t) − η dt I (τ )
f
= E τ I (0) = N
f (N ) − η + E
τ

 Z +∞ h
i


i
h
1
(d)
d
(d)
(d)
d
=
I (t) − η dt I (0) = N − 1
f
f (N ) − η + E
µ1 + µ2
0
i
h
1
=
f (N ) − η d + g(d) (N − 1) ,
µ1 + µ2
where

We obtain

o
n
E τ I (d) (t) = N =

1
.
µ1 + µ2

(µ1 + µ2 ) g(d) (N − 1) − (µ1 + µ2 ) g (d) (N ) = η d − f (N ) .

(25)

Thus it follows from (22), (23), (24) and (25) that
− B(d) g(d) = f (d) − η d e,
where B(d) , f (d) and η d are given in (3), (12) and (13), respectively.
21

(26)

In what follows we provide an effective method to solve the policy-based Poisson equation, and show that there exist infinitely-many solutions with two free constants of additive
terms. This leads to a general solution with the two free constants of the policy-based
Poisson equation.


To solve the system of linear equations (26), it is easy to see that rank B(d) = N

and det B(d) = 0 due to the fact that the size of the matrix B(d) is N + 1. Hence, this
system of linear equations (26) exists infinitely-many solutions with a free constant of an
additive term.
Let B be a matrix obtained through omitting the first row and the first column vectors
of the matrix B(d) . Then,

− [λ + ν (d1 )]
λ


ν (d2 )
− [λ + ν (d2 )]
λ


..
..
..

.
.
.



ν (dK )
− [λ + ν (dK )]
λ

B=

ν (1)
− [λ + ν (1)]
λ


..
..
..

.
.
.



ν (1)
− [λ + ν (1)]
λ

ν (1)
−ν (1)

Obviously, rank(B) = N. Since the size of the matrix B is N , the matrix B is invertible,
and (−B)−1 > 0.

Let H(d) and ϕ(d) be two column vectors of size N obtained through omitting the first
elements of the two column vectors f (d) − η d e and g(d) of size N + 1, respectively. Then,
i 
i
h

 
  h
(d)
(d)
(d)
B1 − D (d) − P A1 − F (d)
H1
f (d) (1) − η d

 
  h
i 
i
h


 

(d)
(d)
(d) 
 H2
  f (d) (2) − η d   B2 − D (d) − P A2 − F (d) 

 
 

..
..

 
 

..

 
 

.
.
.

 
  h
i 
i
h






(d)
(d)
(d) − P A(d) − F (d)
H(d) =  HK
 =  f (d) (K) − η d  =  BK

−
D
K

 
 





 (d)  



 HK+1   f (K + 1) − η d   BK+1 − D (d) − P AK+1 − F (d) 

 
 

..
..

 
 

.
.

 
 

.
.
.

 
 





(d)
d
(d)
(d)
HN
f (N ) − η
BN − D
− P AN − F

and

(d)

ϕ


T
(d)
(d)
(d)
(d)
(d)
(d)
= g (1) , g (2) , . . . , g (K) ; g (K + 1) , g (K + 2) , . . . , g (N ) .
22












.









Therefore, it follows from (26) that
− Bϕ(d) = H(d) + ν (d1 ) e1 g(d) (0) ,

(27)

where e1 is a column vector with the first element be one and all the others be zero. Note
that the matrix −B is invertible and (−B)−1 > 0, thus the system of linear equations (27)
always has one unique solution
ϕ(d) = (−B)−1 H(d) + ν (d1 ) (−B)−1 e1 · ℑ,

(28)

where g(d) (0) = ℑ is any given constant. Let’s take a convention


a

 = (a, b)T ,
b
where b may be a column vector. Then we have

T

g(d) = g(d) (0) , ϕ(d)

T
= ℑ, (−B)−1 H(d) + ν (d1 ) (−B)−1 e1 · ℑ
T 

T
= 0, (−B)−1 H(d) + 1, ν (d1 ) (−B)−1 e1 ℑ.

(29)

Note that B(d) e = 0, thus a general solution to the policy-based Poisson equation is
further given by
T 
T

g(d) = 0, (−B)−1 H(d) + 1, ν (d1 ) (−B)−1 e1 ℑ + ξe,

(30)

where ℑ and ξ are two free constants.
Based on the above analysis, the following theorem summarizes the general solution
of the policy-based Poisson equation.
Theorem 1 For the Poisson equation −B(d) g(d) = f (d) − η d e, there exists a key special
T

d = 0, (−B)−1 H(d)
, and its general solution is related to two free constants
solution gSp
ℑ and ξ such that

g

(d)

=

d
gSp

T

−1
+ 1, ν (d1 ) (−B) e1 ℑ + ξe,

where ξ is a potential displacement constant, and ℑ is a solution-free constant.
Remark 2 (1) To our best knowledge, this is the first to provide the general solution of
the Poisson equations in the MDPs by means of two different free constants.
23

(2) Note that π (d) g(d) = η d and the matrix −B(d) +eπ (d) is invertible, thus the Poisson
equation −B(d) g(d) = f (d) − η d e can become


−B(d) + eπ (d) g(d) = f (d) .

This gives a solution of the Poisson equation as follows:
−1

g(d) = −B(d) + eπ (d)
f (d) + ξe,

which is a special solution of the Poisson equation by comparing with that in Theorem 1.

6

Impact of the Penalty Cost

In this section, we provide an explicit expression for the perturbation realization factor of
the policy-based birth-death process. Based on this, we can set up a linear equation in the
penalty cost, which is well related to the performance difference equation. Furthermore,
we discuss some useful properties of policies in the set D by means of the solution of the
linear equation in the penalty cost.

6.1

The perturbation realization factor

We define a perturbation realization factor as
def

G(d) (i) = g(d) (i − 1) − g (d) (i) , i = 1, 2, . . . , N.

(31)

It is easy to see from Cao [11] that G(d) (i) quantifies the difference among two adjacent
performance potentials g(d) (i) and g (d) (i − 1), and measures the effect on the long-run
average profit of the stock-rationing queue when the system state is changed from State i−1
to State i. By using the policy-based Poisson equation (26), we can derive a new system of
linear equations, which can be used to directly express the perturbation realization factor
G(d) (i) for i = 1, 2, . . . , N .
By using (30), we can directly express the perturbation realization factor G(d) (i) for
i = 1, 2, . . . , N . On the other hand, by observing the special structure of the policy-based
Poisson equation (26), we can propose a new method of sequence to set up an explicit
expression for G(d) (i).
For i = 1, it follows from (22) that
h
i
(d)
(d)
−λ g (0) − g (1) = −λG(d) (1) ,
24

we have
λG(d) (1) = f (0) − η d .

(32)

For i = 2, 3, . . . , K, it follows from (23) that
h
i
h
i
v (di ) g(d) (i − 1) − g (d) (i) − λ g (d) (i) − g(d) (i + 1)

= v (di ) G(d) (i) − λG(d) (i + 1) ,
this gives

λG(d) (i + 1) = v (di ) G(d) (i) + f (d) (i) − η d .

(33)

For i = K + 1, K + 2, . . . , N − 1, it follows from (24) that
h
i
h
i
(µ1 + µ2 ) g (d) (i − 1) − g (d) (i) − λ g(d) (i) − g (d) (i + 1)

= (µ1 + µ2 ) G(d) (i) − λG(d) (i + 1) ,
we obtain

λG(d) (i + 1) = (µ1 + µ2 ) G(d) (i) + f (i) − η d .

(34)

For i = N , it follows from (25) that
(µ1 + µ2 ) G(d) (N ) = η d − f (N ) .

(35)

By using (32), (33), (34) and (35), we obtain a new system of linear equations satisfied by
G(d) (i) as follows:

(d)
d


 λG (1) = f (0) − η ,


 λG(d) (i + 1) = v (d ) G(d) (i) + f (d) (i) − η d ,
i


λG(d) (i + 1) = (µ1 + µ2 ) G(d) (i) + f (i) − η d ,




(µ1 + µ2 ) G(d) (N ) = η d − f (N ) ,

i = 1,
i = 2, 3, . . . , K,
i = K + 1, K + 2, . . . , N − 1,

(36)

i = N.

Fortunately, the following theorem can provide an explicit expression for the pertur-

bation realization factor G(d) (i) for 1 ≤ i ≤ N .
Theorem 2 For any given policy d, the perturbation realization factor G(d) (i) is given
by
(a) for 1 ≤ i ≤ K,
i−1
i−1
i−1
i Y
h
iY
h
X
λr−i f (d) (r) − η d
v (dk ) ;
G(d) (i) = λ−i f (0) − η d
v (dk ) +
k=1

r=1

25

k=r+1

(37)

(b) for K + 1 ≤ i ≤ N ,
(d)

G

(i) = λ

−i

+

h

f (0) − η

K−1
X

d

K
iY

v (dk ) [v (1)]i−K−1

k=1

h

λr−K f (d) (r) − η d

r=1

K
i Y

v (dk ) +

i−1
X

r=K

k=r+1

i
h
λr−i f (r) − η d [v (1)]i−r−2 .

Proof: We only prove (a), since the proof of (b) is similar.
It follows from (36) that
G(d) (1) =

f (0) − η d
.
λ

Similarly, we obtain
G(d) (i + 1) =

f (d) (i) − η d
v (di ) (d)
G (i) +
, i = 1, 2, . . . , K.
λ
λ

By using (1.2.4) in Chapter 1 of Elaydi [26], we can obtain the explicit expression of the
perturbation realization factor as follows:
i−1
i−1
i−1
iY
h
i Y
h
X
G(d) (i) = λ−i f (0) − η d
v (dk ) +
λr−i f (d) (r) − η d
v (dk )
r=1

k=1

k=r+1

for i = 1, 2, . . . , K. This completes the proof.

6.2

The performance difference equation

For any given policy d ∈ D, the long-run average profit of the stock-rationing queue is
given by
η d = π (d) f (d) ,
and the policy-based Poisson equation is given by
B(d) g(d) = η d e − f (d) .
It is seen from (3) and (12) that Policy d directly affects not only the elements of the
infinitesimal generator B(d) but also the reward function f (d) . Based on this, if Policy d
changes to d′ , then the infinitesimal generator B(d) and the reward function f (d) can have
′

′

their corresponding changes B(d ) and f (d ) , respectively.
The following lemma provides a useful equation (called performance difference equa′

tion) for the difference η d −η d corresponding to any two different policies d, d′ ∈ D. Here,
we only restate the performance difference equation without proof, readers may refer to
Cao [11] or Ma et al. [60] for more details.
26

Lemma 1 For any two policies d, d′ ∈ D, we have
′

′

η d − η d = π (d )

h

i

 ′
′
B(d ) − B(d) g(d) + f (d ) − f (d) .

(38)

By using the performance difference equation (38), we can set up a partial order
relation for the policies in the policy set D as follows. For any two policies d, d′ ∈ D, we
′

′

′

write that d′ ≻ d if η d > η d ; d′ ≈ d if η d = η d ; and d′ ≺ d if η d < η d . Also, we write
′

′

that d′  d if η d ≥ η d ; and d′  d if η d ≤ η d .
Under this partial order relation, our research target is to find the optimal policy
d∗ ∈ D such that d∗  d for any policy d ∈ D, i.e.,
n o
d∗ = arg max η d .
d∈D

Note that the policy set D and the state set Ω are all finite, thus an enumeration method
using finite comparisons is feasible for finding the optimal policy d∗ in the policy set D.
To find the optimal policy d∗ , we define two policies d and d′ with an interrelated
structure at Position i as follows:

d = 0; d1 , d2 , . . . , di−1 , di , di+1 , . . . , dK ; 1, 1, . . . , 1 ,


d′ = 0; d1 , d2 , . . . , di−1 , d′i , di+1 , . . . , dK ; 1, 1, . . . , 1 ,

where d′i , di ∈ {0, 1} with d′i 6= di . Clearly, if the two policies d and d′ have an interrelated
structure at Position i, then only the difference between the two policies d and d′ is at
their ith elements: di and d′i .
Lemma 2 For the two policies d and d′ with an interrelated structure at Position i: di
and d′i , we have
′

′

η d − η d = µ2 π (d ) (i) d′i − di
where b = R + C2,2 − P .

h

i
G(d) (i) + b ,

(39)

Proof: For the two policies d and d′ with an interrelated structure at Position i: di
and d′i , we have

d = 0; d1 , d2 , . . . , di−1 , di , di+1 , . . . , dK ; 1, 1, . . . , 1 ,


d′ = 0; d1 , d2 , . . . , di−1 , d′i , di+1 , . . . , dK ; 1, 1, . . . , 1 .
27

It is easy to check from (3) that

0


.
 0 ..


..

.
0

(d′ )
(d) 
B
− B =
(d′i − di ) µ2 − (d′i − di ) µ2



0







0
..
.

..

.

0

0

Also, from the reward function (9), we obtain









.








(40)

f (d) (i) = (R + C2,2 − P ) µ2 di + Rµ1 − C1 i − C2,2 µ2 − C3 λ
and
′

f (d ) (i) = (R + C2,2 − P ) µ2 d′i + Rµ1 − C1 i − C2,2 µ2 − C3 λ.
This gives


T
′
f (d ) − f (d) = 0, 0, . . . , 0, bµ2 d′i − di , 0, . . . , 0 .

Thus, it follows from Lemma 1, (40) and (41) that
i

 ′
h
′
′
′
η d − η d = π (d ) B(d ) − B(d) g(d) + f (d ) − f (d)
i
h
′
= µ2 π (d ) (i) d′i − di g(d) (i − 1) − g (d) (i) + b
i
h
′
= µ2 π (d ) (i) d′i − di G(d) (i) + b .

(41)

(42)

This completes the proof.

For d′i , di ∈ {0, 1} with d′i 6= di , we have

 1, d′ = 1, d = 0;
i
i
d′i − di =
′
 −1, d = 0, di = 1.
i
′

Therefore, it is easy to see from (39) that to compare η d with η d , it is necessary to further
analyze the sign of function G(d) (i) + b. This will be developed in the next subsection.

6.3

The sign of G(d) (i) + b
′

As seen from (42), the sign analysis of the performance difference η d −η d directly depends
on that of G(d) (i) + b. Thus, this subsection provides the sign analysis of G(d) (i) + b with
respect to the penalty cost P .
28

Suppose that the inventory level is low. If the service priority is violated (i.e. the
demands of Class 2 are served at a low stock), then the warehouse has to pay the penalty
cost P for each product supplied to the demands of Class 2. Based on this, we study the
influence of the penalty cost P on the sign of G(d) (i) + b.
Substituting (14), (15), (16) and (17) into (37), we obtain that for 1 ≤ i ≤ K,
(d)

G

−i

(i) + b = R + C2,2 + λ

−P

(

1+λ

−i

h

h

B0 − D

(d)

i−1
iY

i−1
X

v (dk ) +

A0 − F

i−1
iY

λ

r=1

k=1

(d)

r−i

v (dk ) +

i−1
X

λ

r−i

r=1

k=1

h

h

Br(d)

A(d)
r

−D

(d)

i−1
i Y

v (dk )

k=r+1

−F

(d)

i−1
i Y

)

v (dk ) ,

k=r+1

(43)

which is linear in the penalty cost P .
From G(d) (i) + b = 0, we have
(
)
i−1
i−1
i−1
i Y
iY
h
h
X
(d)
(d)
(d)
r−i
−i
Ar − F
A0 − F
λ
P 1+λ
v (dk )
v (dk ) +
r=1

k=1

h

= R + C2,2 + λ−i B0 − D (d)

i−1
iY

v (dk ) +

k=r+1

i−1
X

h

λr−i Br(d) − D (d)

r=1

k=1

i−1
i Y

v (dk ) ,

(44)

k=r+1

thus, the unique solution of the penalty cost P to Equation (44) is given by

(d)

Pi

=

i i−1
i−1

 i−1
Q
P r−i h (d)
Q
v (dk )
v (dk ) +
Br − D (d)
λ
R + C2,2 + λ−i B0 − D (d)
r=1

k=1

1+

λ−i



A0 −

F (d)



i−1
Q

v (dk ) +

r=1

k=1
(d)

It’s easy to see from (43) that if Pi

i−1
P

λr−i

h

k=r+1

(d)
Ar

−F

i i−1
Q
(d)

. (45)

v (dk )

k=r+1

(d)

> 0 and 0 ≤ P ≤ Pi , then G(d) (i) + b ≥ 0; while

(d)

(d)

if P ≥ Pi , then G(d) (i) + b ≤ 0. Note that the equality can hold only if P = Pi
(d)

To understand the solution Pi

for 1 ≤ i ≤ K, we use a numerical example to show

the solutions in Table 2. To do this, we take the system parameters: λ = 3, µ1 = 4,
µ2 = 2, C1 = 1, C2,1 = 4, C2,2 = 1, C3 = 5 and C4 = 1. Further, we observe three
different policies:
d1 = (0; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1; 1, 1, 1, 1, 1) ,
d2 = (0; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0; 1, 1, 1, 1, 1) ,
d3 = (0; 0, 0, 0, 0, 0, 1, 1, 1, 1, 1; 1, 1, 1, 1, 1) .
29

In the stock-rationing queue, we define two critical values related to the penalty cost
P as

o
n
(d)
(d)
(d)
PH (d) = max 0, P1 , P2 , . . . , PK ,

(46)

o
n
(d)
(d)
(d)
PL (d) = min P1 , P2 , . . . , PK .

(47)

d∈D

and

d∈D

From Table 2, we see that it is possible to have PL (d) < 0 for Policy d = d2 or d = d3 .
The following proposition uses the two critical values PH (d) and PL (d), together
with the penalty cost P , to provide some sufficient conditions under which the function
G(d) (i) + b is either positive, zero or negative.
Proposition 1 (1) If P ≥ PH (d) for any given policy d ∈ D, then for each i =
1, 2, . . . , K,
G(d) (i) + b ≤ 0.
(2) If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d ∈ D, then for each
i = 1, 2, . . . , K,
G(d) (i) + b ≥ 0.
Proof: (1) For any given policy d ∈ D, if P ≥ PH (d), then it follows from (46) that
for each i = 1, 2, . . . , K,
(d)

P ≥ Pi ,
this leads to that G(d) (i) + b ≤ 0.
(2) For any given policy d ∈ D, if PL (d) > 0 and 0 ≤ P ≤ PL (d), then it follows from
(47) that for each i = 1, 2, . . . , K,
(d)

0 ≤ P ≤ Pi ,
this gives that G(d) (i) + b ≥ 0. This completes the proof.

Table 2: Numerical analysis of solutions for three different policies
(d)
Pi

i= 0

1

2

3

4

5

6

7

8

9

10

d1

11

11

38.3

20.7

21.4

21.3

20.9

20.7

20.4

20.1

19.8

d2

11

11

-6.5

14.3

88.4

384.9

1.5e3

5.6e3

2.1e4

7.5e4

2.6e5

d3

11

11

-7.1

23.0

-181.4

-80.4

-68.6

15.0

13.7

13.3

13.1

30

However, for the case with PL (d) < P < PH (d) for any given policy d ∈ D, it is a
little bit complicated to determine the sign of G(d) (i) + b for each i = 1, 2, . . . , K. For
this reason, our discussion will be left in the next section.
For any two policies d, c ∈ D,
d = (0; d1 , d2 , . . . , di−1 , di , di+1 , . . . , dK ; 1, 1, . . . , 1) ,
c = (0; c1 , c2 , . . . , ci−1 , ci , ci+1 , . . . , cK ; 1, 1, . . . , 1) .
we write
S (d, c) = {i : di 6= ci , i = 1, 2, . . . , K − 1, K}
and its complementary set
S (d, c) = {i : di = ci , i = 1, 2, . . . , K − 1, K} .
Then
S (d, c) ∪ S (d, c) = {1, 2, . . . , K − 1, K} .
The following lemma sets up a policy sequence such that any two adjacent policies of
them have the difference at the corresponding position of only one element. The proof is
easy and is omitted here.
Lemma 3 For any two policies d, c ∈ D, S (d, c) = {i1 , i2 , i3 , . . . , in−1 , in }, then there
exist a policy sequence: d(k) for k = 1, 2, 3, . . . , n − 1, n, such that


S d, d(1) = {j1 } ,


S d(1) , d(2) = {j2 } ,
..
.


S d(n−1) , d(n) = {jn } ,

where d(n) = c, and {i1 , i2 , i3 , . . . , in−1 , in } = {j1 , j2 , j3 , . . . , jn−1 , jn }. Also, for k =
1, 2, 3, . . . , n − 1, n, we have


S d, d(k) = {j1 , j2 , j3 , . . . , jk } .

The following theorem provides a class property of the policies in the set D by means
of the function G(c) (i) + b for any policy c ∈ D and for each i ∈ S (d, c), where Policy d
is any given reference policy in the set D. Note that the class property will play a key role
in developing some new structural properties of the optimal dynamic rationing policy.
31

Theorem 3 (1) If P ≥ PH (d) for any given policy d, then for any policy c ∈ D and for
each i ∈ S (d, c),
G(c) (i) + b ≤ 0.
(2) If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then for any policy c ∈ D
and for each i ∈ S (d, c),
G(c) (i) + b ≥ 0.
Proof: We only prove (1), while (2) can be proved similarly.
If P ≥ PH (d) for any given policy d, then it follows from (1) of Proposition 1 that for
i = 1, 2, . . . , K,
G(d) (i) + b ≤ 0.
From Policy d, we observe any different policy c ∈ D. If the two policies d and c have
n different elements: dil 6= cil for l = 1, 2, . . . , n, then S (d, c) = {il : l = 1, 2, . . . , n}.
Note that the performance difference equation (39) can only be applied to two policies
d′ and d with an interrelated structure at Position i : d′i , di ∈ {0, 1} with d′i 6= di , thus for
a policy c ∈ D with S (d, c) = {i1 , i2 , i3 , . . . , in−1 , in }, our following discussion needs to
use the policy sequence: d(k) for k = 1, 2, 3, . . . , n − 1, n, given in Lemma 3. To this end,
our further proof is to use the mathematical induction in the following three steps:
Step one: Analyzing the two policies d and d(1) .


For each j1 ∈ {i1 , i2 , i3 , . . . , in−1 , in }, we take S d, d(1) = {j1 }. It follows from the

performance difference equation (39) that
η

d(1)

 (1)
h
i
(d )
d(1) )
(
− dj1 G(d) (j1 ) + b .
(j1 ) dj1
− η = µ2 π
d

(48)

Similarly, we have
d

η −η

d(1)

= µ2 π

(d)



(d(1) )
(j1 ) dj1 − dj1

h

i
(1)
G(d ) (j1 ) + b .

(49)

It is easy to see from (48) and (49) that
(1)
i
π (d ) (j1 ) h (d)
d(1) )
(
G (j1 ) + b ≤ 0.
(j1 ) + b = (d)
G
π (j1 )

(50)

(1)
Therefore, for Policy d(1) ∈ D, G(d ) (j1 ) + b ≤ 0 for each j1 ∈ {i1 , i2 , i3 , . . . , in−1 , in }.

Step two: Analyzing the two policies d(1) and d(2) .

32



For each j2 ∈ {i1 , i2 , i3 , . . . , in−1 , in }, we take S d(1) , d(2) = {j2 }. It is easy to see

from (50) that

(2)
i
π (d ) (j2 ) h (d(1) )
d(2) )
(
G
(j
)
+
b
≤ 0.
G
(j2 ) + b =
2
(1)
π (d ) (j2 )

(2)
Therefore, for Policy d(2) ∈ D, G(d ) (j2 ) + b ≤ 0 for each j2 ∈ {i1 , i2 , i3 , . . . , in−1 , in }.

Step three: Assume that for l = 3, 4, . . . , k − 2, k − 1, we have obtained that for Policy


(l)
d(l) ∈ D with S d(l−1) , d(l) = {jl }, G(d ) (jl )+b ≤ 0 for each jl ∈ {i1 , i2 , i3 , . . . , in−1 , in }.
Now, we prove the next case with l = k.



For each jk ∈ {i1 , i2 , i3 , . . . , in−1 , in }, we take S d(k−1) , d(k) = {jk }. It is easy to see

from (50) that

(k)
i
π (d ) (jk ) h (d(k−1) )
d(k) )
(
(jk ) + b =
G
(j
)
+
b
≤ 0.
G
k
(k−1)
) (j )
π (d
k
(k)
This gives that for Policy d(k) ∈ D, G(d ) (jk )+b ≤ 0 for each jk ∈ {i1 , i2 , i3 , . . . , in−1 , in }.

Thus, this result holds for the case with l = k.
Following the above analysis, we can prove by induction that for Policy d(n) ∈ D,
(n)
G(d ) (jn ) + b ≤ 0 for each jn ∈ {i1 , i2 , i3 , . . . , in−1 , in }. Since c = d(n) , we obtain that
for Policy c ∈ D, G(c) (i) + b ≤ 0 for each i ∈ {i1 , i2 , i3 , . . . , in−1 , in }. This completes the
proof.

7

Monotonicity and Optimality

In this section, we analyze the optimal dynamic rationing policy in the three different
areas of the penalty cost: P ≥ PH (d); PL (d) > 0 and 0 < P ≤ PL (d); and PL (d) < P <
PH (d), which are studied as three different subsections, respectively. For the three areas,
some new structural properties of the optimal dynamic rationing policy are given by using
our algebraic method. Also, it is easy to see that for the first two areas: P ≥ PH (d);
and PL (d) > 0 and 0 < P ≤ PL (d), the optimal dynamic rationing policy is of threshold
type; while for the third area: PL (d) < P < PH (d), it may not be of threshold type but
must be of transformational threshold type.
′

As seen from Lemma 2, to compare η d with η d , our aim is to focus on only Position
i with d′i 6= di for d′i , di ∈ {0, 1}. Also, Lemma 3 provides a useful class property of the
policies in the set D under the function G(c) (i) + b for any policy c, d ∈ D and for each
i ∈ S (d, c). The two lemmas are very useful for our research in the next subsections.
33

7.1

The penalty cost P ≥ PH (d)

In this subsection, for the area of the penalty cost: P ≥ PH (d) for any given policy d,
we find the optimal dynamic rationing policy of the stock-rationing queue, and further
compute the maximal long-run average profit of this system.
The following theorem uses the class property of the policies in the set D, given in (1)
of Theorem 3, to set up some basic relations between any two policies. Thus, we find the
optimal dynamic rationing policy of the stock-rationing queue.
Theorem 4 If P ≥ PH (d) for any given policy d, then the optimal dynamic rationing
policy of the stock-rationing queue is given by
d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1) .
This shows that if the penalty cost is higher with P ≥ PH (d) for any given policy d, then
the warehouse can not supply any product to the demands of Class 2.
Proof: If P ≥ PH for any given policy d, then our proof will focus on that for any
policy c ∈ D, we can have
d∗  c.
Based on this, we need to study some useful relations among the three policies: d, c
and d∗ , where d∗ is deterministic with d∗i = 0 for each i = 1, 2, . . . , K − 1, K.
∗

To compare η c with η d , let S (d∗ , c) = {nl : l = 1, 2, . . . , n} for 1 ≤ n ≤ K. Then
cnl = 1 for l = 1, 2, . . . , n, since d∗i = 0 for each i = 1, 2, . . . , K − 1, K.
For the two policies d and c, we have di , ci ∈ {0, 1}. Further, for the three elements:
di , ci and d∗i = 0 for i ∈ S (d∗ , c), we need to consider four different cases as follows:
Case one: di = ci = d∗i = 0. Since ci = d∗i , this case does not require any analysis by
using Lemma 2.
Case two: di = 1 and ci = d∗i = 0. Since ci = d∗i , this case does not require any
analysis by using Lemma 2.
Case three: ci = 1 and di = d∗i = 0. Note that ci 6= di , by using (1) of Theorem 3,
we obtain that G(c) (i) + b ≤ 0. On the other hand, since ci 6= d∗i , it follows from the
performance difference equation (39) that for each i ∈ S (d∗ , c),
h
i
∗
∗
η d − η c = µ2 π (d ) (i) (d∗i − ci ) G(c) (i) + b
h
i
∗
= −µ2 π (d ) (i) G(c) (i) + b ≥ 0.
34

∗

Thus η d ≥ η c , this gives d∗  c.
Case four: di = ci = 1 and d∗i = 0. Note that d∗i 6= di , by using (1) of Theorem 3,
∗

we obtain that G(d ) (i) + b ≤ 0. On the other hand, since ci 6= d∗i , it follows from the
performance difference equation (39) that for each i ∈ S (d∗ , c),

∗

h
i
∗
∗
η c − η d = µ2 π (c) (i) (ci − d∗i ) G(d ) (i) + b
h
i
∗
= µ2 π (c) (i) G(d ) (i) + b ≤ 0.

Thus η d ≥ η c , this gives d∗  c.

Based on the above four discussions, we obtain that d∗  c for any policy c ∈ D. This
completes the proof.
For d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1), let d(n) be a policy in the policy set D with


S d∗ , d(n) = {il : l = 1, 2, . . . , n}



for 1 ≤ n ≤ K. To understand Policy d(n) , we take three examples: S d∗ , d(1) = {i1 },






S d∗ , d(2) = {i1 , i2 }, S d∗ , d(3) = {i1 , i2 , i3 }. Also, S d(n−1) , d(n) = {in } for 1 ≤
n ≤ K. Note that

d(K) == (0; 1, 1, . . . , 1; 1, 1, . . . , 1) .
The following corollary provides a set-structured decreasing monotonicity of the policies d(n) ∈ D for n = 1, 2, . . . , K − 1, K. In fact, this monotonicity is guaranteed by the
class property of policies in the set D, given in (1) of Theorem 3. The proof is easy by
using a similar analysis to that in Theorem 4, thus it is omitted here.
Corollary 5 If P ≥ PH (d) for any given policy d, then
d∗  d(1)  d(2)  d(3)  · · ·  d(K−1)  d(K) .
In what follows we compute the maximal long-run average profit of the stock-rationing
queue.
When P ≥ PH (d) for any given policy d, the optimal dynamic rationing policy is
given by
d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1) ,

35

thus it follows from (5) that
ξ0 = 1,
i = 0,

 αi ,
i = 1, 2, . . . , K,
(d∗ )
 K
ξi
=
 α
β i , i = K + 1, K + 2, . . . , N,
β

and
(d∗ )

h

=1+

N
X
i=1

(d∗ )
ξi


  K K+1
β
1 − β N −K
α 1 − αK
α
+
,
=1+
1−α
β
1−β

where α = λ/µ1 and β = λ/ (µ1 + µ2 ) . It follows from (6) that

 1∗ ,
i = 0,
∗
h(d )
π (d ) (i) =
∗)
(d
 1∗ ξ
, i = 1, 2, . . . , N.
h(d

)

i

At the same time, it follows from (8) to (11) that
f (0) = −C2,1 µ1 − C2,2 µ2 − C3 λ,

i = 0;

∗

f (d ) (i) = Rµ1 − C1 i − C2,2 µ2 − C3 λ,

1 ≤ i ≤ K;

f (i) = R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N } , K + 1 ≤ i ≤ N.
Since
η

d∗

=

N
X

∗

∗

π (d ) (i) f (d ) (i) ,

(51)

i=0

we obtain
η

d∗

=

1
∗
h(d )

+

(

− (C2,1 µ1 + C2,2 µ2 + C3 λ) +

N
X

i=K+1

(

K
X

(Rµ1 − C1 i − C2,2 µ2 − C3 λ) αi

i=0



R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N }



 K )
α
βi
β
#

"


α 1 − αK
α 1 − αK
KαK+1
−
− C1
= (d∗ ) −γ1 + γ2
1−α
1−α
h
(1 − α)2

 K
β K+1 1 − β N −K
α
γ3
+
β
1−β
"
 #)
 K
K+1
α
Kβ
− N β N +1 β K+1 1 − β N −K
−
,
C1
+
β
1−β
(1 − β)2
1

where
γ1 = C2,1 µ1 + C2,2 µ2 + C3 λ,
γ2 = Rµ1 − C2,2 µ2 − C3 λ,
γ3 = R (µ1 + µ2 ) − C3 λ1{i<N } − C4 λ1{i=N } .
36

7.2

The penalty cost PL (d) > 0 and 0 ≤ P ≤ PL (d)

In this subsection, we consider the area of the penalty cost: PL (d) > 0 and 0 ≤ P ≤ PL (d)
for any given policy d. We first find the optimal dynamic rationing policy of the stockrationing queue. Then we compute the maximal long-run average profit of this system.
The following theorem finds the optimal dynamic rationing policy of the stock-rationing
queue in the area of the penalty cost: PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy
d. The proof is similar to that of Theorem 4.
Theorem 6 If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then the optimal
dynamic rationing policy of the stock-rationing queue is given by
d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1) .
This shows that if the penalty cost is lower with PL (d) > 0 and 0 ≤ P ≤ PL (d), then the
warehouse would like to supply the products to the demands of Class 2.
Proof: If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then we prove that
for any policy c ∈ D,
d∗  c.
For this, we need to consider the three policies: d, c and d∗ , where d∗ is deterministic
with d∗i = 1 for each i = 1, 2, . . . , K − 1, K.
∗

To compare η c with η d , let S (d∗ , c) = {nl : l = 1, 2, . . . , m} for 1 ≤ m ≤ K. Then
cnl = 0 for l = 1, 2, . . . , m, since d∗i = 1 for each i = 1, 2, . . . , K − 1, K.
For the two policies d and c, we have di , ci ∈ {0, 1}. Based on this, for the three
elements: di , ci and d∗i = 1 for i ∈ S (d∗ , c), we need to consider four different cases as
follows:
Case one: di = ci = d∗i = 1. Since ci = d∗i , this case does not require any analysis
according to Lemma 2.
Case two: di = 0 and ci = d∗i = 1. Since ci = d∗i , this case does not require any
analysis by using Lemma 2.
Case three: ci = 0 and di = d∗i = 1. Note that ci 6= di , by using (2) of Theorem 3,
we obtain that G(c) (i) + b ≥ 0. On the other hand, since ci 6= d∗i , it follows from the

37

performance difference equation (39) that for each i ∈ S (d∗ , c),
h
i
∗
∗
η d − η c = µ2 π (d ) (i) (d∗i − ci ) G(c) (i) + b
h
i
∗
= µ2 π (d ) (i) G(c) (i) + b ≥ 0.

∗

Thus η d ≥ η c , this gives d∗  c.

Case four: di = ci = 0 and d∗i = 1. Note that d∗i 6= di , by using (2) of Theorem 3,
∗

we obtain that G(d ) (i) + b ≥ 0. On the other hand, since ci 6= d∗i , it follows from the
performance difference equation (39) that for each i ∈ S (d∗ , c),
h
i
∗
∗
η c − η d = µ2 π (c) (i) (ci − d∗i ) G(d ) (i) + b
h
i
∗
= −µ2 π (c) (i) G(d ) (i) + b ≤ 0.

∗

Thus η d ≥ η c , this gives d∗  c. This completes the proof.

For d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1), let d(n) be a policy in the policy set D with


S d∗ , d(n) = {kl : l = 1, 2, . . . , n} for 1 ≤ n ≤ K, where
e (K) = (0; 0, 0, . . . , 0; 1, 1, . . . , 1) .
d

The following corollary provides a set-structured decreasing monotonicity of the policies d(n) ∈ D for n = 1, 2, . . . , K − 1, K. This monotonicity comes from the class property
of the policies in the set D, given in (2) of Theorem 3. The proof is easy and omitted here.
Corollary 7 If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then
d∗  d(1)  d(2)  d(3)  · · ·  d(K−1)  d(K) .
If PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then the optimal dynamic
rationing policy is given by
d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1) .
In this case, we obtain
ξ0 = 1,
(d∗ )
ξi
= βi,
and
(d∗ )

h

=1+

N
X

i = 0,
i = 1, 2, . . . , N,

(d∗ )
ξi

i=1

38


β 1 − βN
.
=1+
1−β

It follows from Subsection 1.1.4 of Chapter 1 in Li [56] that

 1∗
i = 0,
∗
h(d )
π (d ) (i) =
i
 β ∗ , i = 1, 2, . . . , N,
h(d )
At the same time, it follows from (8) to (11) that
f (0) = −C2,1 µ1 − C2,2 µ2 − C3 λ,

i = 0;

f

(d∗ )

(i) = R (µ1 + µ2 ) − C1 i − C3 λ − P µ2 ,

f

(d∗ )

(i) = R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N } , K + 1 ≤ i ≤ N.

1 ≤ i ≤ K;

Thus we obtain
η

d∗

=

1
h(d∗ )
+

(

− (C2,1 µ1 + C2,2 µ2 + C3 λ) +

N
X

i=K+1

(

K
X

[R (µ1 + µ2 ) − C1 i − C3 λ − P µ2 ] β i

i=1





R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N } β i

)

#
"


β 1 − βK
β 1 − βK
Kβ K+1
= (d∗ ) −γ1 + γ4
− C1
−
1−β
1−β
h
(1 − β)2
"

 #)
β K+1 1 − β N −K
Kβ K+1 − N β N +1 β K+1 1 − β N −K
+ γ3
− C1
+
,
1−β
1−β
(1 − β)2
1

where
γ1 = C2,1 µ1 + C2,2 µ2 + C3 λ,
γ2 = Rµ1 − C2,2 µ2 − C3 λ,
γ3 = R (µ1 + µ2 ) − C3 λ1{i<N } − C4 λ1{i=N } ,
γ4 = R (µ1 + µ2 ) − C3 λ − P µ2 .

7.3

The penalty cost PL (d) < P < PH (d)

In this subsection, we discuss the third area of the penalty cost: PL < P < PH for
any given policy d. Note that this analysis is a little more complicated than those in
the previous two areas. To this end, we propose a new algebraic method to find the
optimal dynamic rationing policy of the stock-rationing queue. Based on this, we show
that the optimal dynamic rationing policy may not be of threshold type, but it must be
of transformational threshold type.

39

For the convenience of readers, it is necessary and useful to simply recall several previous results as follows.
For any given policy d = (0; d1 , d2 , . . . , . . . , dK−1 , dK ; 1, 1, . . . , 1), the unique solution
of the linear equation G(d) (i) + b = 0 in the penalty cost P is given by

(d)

Pi

=

i i−1
i−1

 i−1
P r−i h (d)
Q
Q
v (dk ) +
v (dk )
λ
Br − D (d)
R + C2,2 + λ−i B0 − D (d)
r=1

k=1

1+

λ−i



A0 −

F (d)



i−1
Q

v (dk ) +

i−1
P

λr−i

r=1

k=1

which is a fixed real number for 1 ≤ i ≤ K.
(d)

(d)

We introduce a convention: If Pn−1 < Pn

h

k=r+1

(d)
Ar

−F

i i−1
Q
(d)

,

v (dk )

k=r+1

(d)

(d)

(d)

= Pn+1 = · · · = Pn+i = c and Pn−1 <

P ≤ c, then we write
(d)

(d)

(d)

Pn−1 < P ≤ P(d)
n = Pn+1 = · · · = Pn+i ,
that is, the penalty cost P is written in front of all the equal elements in the sequence
o
n
(d)
Pk : n ≤ k ≤ n + i .
o
n
(d)
For the sequence Pk : 1 ≤ k ≤ K , we set up a new permutation from the smallest
to the largest as follows:

(d)

(d)

(d)

(d)

Pi1 ≤ Pi2 ≤ · · · ≤ PiK−1 ≤ PiK ,
(d)

(d)

= PL (d) and PiK = PH (d). For the convenience of descripn
o
(d)
tion, for the incremental sequence Pij : 1 ≤ j ≤ K , we write its subscript vector as

it is clear that Pi1

(i1 , i2 , . . . , iK−1 , iK ). Note that the subscript vector (i1 , i2 , . . . , iK−1 , iK ) depends on Policy d.
n

The following lemma shows how the penalty cost P is distributed in the sequence
o
:1≤k≤K .

(d)
Pk

Lemma 4 If PL (d) < P < PH (d) for any given policy d, then there exists the minimal
positive integer n0 ∈ {1, 2, . . . , K} such that either
(d)

(d)

Pin < P = Pin

0 +1

0

or
(d)

(d)

Pin < P < Pin

0 +1

0

40

.

Proof: Note that
o
n
(d)
(d)
(d)
PH (d) = max 0, P1 , P2 , . . . , PK
d∈D

and

o
n
(d)
(d)
(d)
PL (d) = max P1 , P2 , . . . , PK ,
d∈D

it is easy to see that PH (d) and PL (d) are two fixed real numbers. If PL < P < PH (d)
for Policy d, then there exists the minimal positive integer n0 ∈ {1, 2, . . . , K − 1, K} such
that
(d)

(d)

PL (d) ≤ Pin < P ≤ Pin

0 +1

0

(d)

This shows that either for P = Pin

0 +1

,
(d)

(d)

Pin < P = Pin

0 +1

0

(d)

or for P < Pin

0 +1

< PH (d) .

;

,
(d)

(d)

Pin < P < Pin

0 +1

0

.

This completes the proof.
Now, our task is to develop a new method for finding the optimal dynamic rationing
policy by means of the following two useful information: (a) The incremental sequence
(d)

(d)

(d)

(d)

PL (d) = Pi1 ≤ Pi2 ≤ · · · ≤ PiK−1 ≤ PiK = PH (d) ;
(d)

(d)

and (b) the penalty cost P has a fixed position: Pin < P ≤ Pin

0 +1

0

, where n0 is the

minimal positive integer in the set {1, 2, . . . , K − 1, K}.
In what follows we discuss two different cases: A simple case and a general case.
Case one: A simple case with
(d)

PL (d) = P1

(d)

≤ P2

(d)

(d)

≤ · · · ≤ PK−1 ≤ PK = PH (d) .

(52)

In this case, the subscript vector is expressed as {1, 2, 3, . . . , K − 1, K} depending on Policy
d.
If PL (d) < P < PH (d) for any given policy d, then there exists the minimal positive
integer n0 ∈ {1, 2, . . . , K − 1, K} such that
(d)

PL (d) = P1

(d)

(d)

≤ · · · ≤ Pn0 −1 < P ≤ P(d)
n0 ≤ · · · ≤ PK = PH (d) .

41

Based on this, we take two different sets
n
o
(d)
(d)
(d)
Λ1 = P1 , P2 , . . . , Pn0 −1
and

o
n
(d)
(d)
.
Λ2 = P(d)
n0 , Pn0 +1 , . . . , PK

By using the two sets Λ1 and Λ2 , we write

P H (d;1 → n0 − 1) =

max

1≤i≤n0 −1

and
P L (d;n0 → K) =

min

n0 ≤j≤K

(d)

n

o
n
(d)
Pi
(d)

Pj

o

.
(d)

It is clear that P H (d;1 → n0 − 1) = Pn0 −1 and P L (d;n0 → K) = Pn0 .
For this simple case, the following theorem finds the optimal dynamic rationing policy,
which is of threshold type.
Theorem 8 For the simple case with PL (d) < P < PH (d) for any given policy d, if
there exists the minimal positive integer n0 ∈ {1, 2, . . . , K − 1, K} such that
(d)

PL (d) = P1

(d)

(d)

≤ · · · ≤ Pn0 −1 < P ≤ P(d)
n0 ≤ · · · ≤ PK = PH (d) ,

then the optimal dynamic rationing policy is given by


(53)



d∗ = 0; 0, 0, . . . , 0, 1, 1, . . . , 1 ; 1, 1, . . . , 1 .
| {z } | {z }
n0 −1 zeros K−n0 +1 ones

Proof: The proof follows that in Theorems 4 and 6.

On the one hand, in the set Λ1 , it is easy to see from (53) that P > P H (d;1 → n0 − 1)
for Policy d. Now, our aim is to focus on a sub-policy
e a = (0; d1 , d2 , . . . , dn −1 , ∗, ∗, . . . , ∗; 1, 1, . . . , 1) .
d
0

For the sub-policy (d1 , d2 , . . . , dn0 −1 ), it is easy to see from the set Λ1 that P > P H (d;1 → n0 − 1).
Thus it follows from Theorem 4 that the optimal dynamic rationing sub-policy is given by
e ∗ = (0; 0, 0, . . . , 0, ∗, ∗, . . . , ∗; 1, 1, . . . , 1) .
d
a
42

On the other hand, it is seen from the set Λ2 that 0 ≤ P ≤ P L (d;n0 → K) for Policy
d. We consider another sub-policy
e b = (0; ∗, ∗, . . . , ∗, dn , dn +1 , . . . , dK ; 1, 1, . . . , 1) .
d
0
0

For the sub-policy (dn0 , dn0 +1 , . . . , dK ), it is easy to see from the set Λ2 that 0 ≤ P ≤
P L (d;n0 → K). Thus it is easy to see from Theorem 6 that the optimal dynamic rationing
sub-policy is given by
e ∗ = (0; ∗, ∗, . . . , ∗, 1, 1, . . . , 1; 1, 1, . . . , 1) .
d
b

Based on the above two discussions, from the total set Λ1 ∪ Λ2 , by observing the total
policy (d1 , d2 , . . . , dn0 −1 ; dn0 , dn0 +1 , . . . , dK ) or Policy d, the optimal dynamic rationing
policy is given by


]∗ ]∗
e∗ = d
e ∗ = 0; 0, 0, . . . , 0, 1, 1, . . . , 1 ; 1, 1, . . . , 1 .
d∗ = d
a
b
| {z } | {z }
b
a
n0 −1 zeros K−n0 +1 ones

This completes the proof.

Remark 3 It is easy to see that in Theorems 4, 6 and 8, the optimal dynamic rationing
policy is of threshold type (i.e., critical rationing level).
Case two: A general case with
(d)

(d)

(d)

(d)

PL (d) = Pi1 ≤ Pi2 ≤ · · · ≤ PiK−1 ≤ PiK = PH (d) .
For the incremental sequence

n

o
(d)
Pij : j = 1, 2, . . . , K , we write its subscript vector as

(i1 , i2 , . . . , iK−1 , iK ), which depends on Policy d. In the general case, we assume that
(i1 , i2 , . . . , iK−1 , iK ) 6= (1, 2, . . . , K − 1, K).

If PL (d) < P < PH (d) for any given policy d, then there exists the minimal positive
integer n0 ∈ {1, 2, . . . , K − 1, K} such that
(d)

(d)

PL (d) = Pi1 ≤ · · · ≤ Pin

0 −1

(d)

(d)

< P ≤ Pin ≤ · · · ≤ PiK = PH (d) .
0

Based on this, we take two sets
n
o
(d)
(d)
(d)
ΛG
1 = Pi1 , Pi2 , . . . , Pin −1
0

43

and

o
n
(d)
(d)
(d)
.
ΛG
2 = Pin , Pin +1 , . . . , PiK
0

0

G
For the two sets ΛG
1 and Λ2 , we write
G

P H (d;1 → n0 − 1) =
and
G
P L (d;n0

→ K) =

G

max

1≤k≤n0 −1

o
n
(d)
Pik

o
n
(d)
min
Pik ,

n0 ≤k≤K
G

(d)

It is clear that P H (d;1 → n0 − 1) = Pin

(d)

and P L (d;n0 → K) = Pin .
o
n0
(d)
Corresponding to the subscript vector of the incremental sequence Pik : 1 ≤ k ≤ K ,
0 −1

we transfer Policy

d = (0; d1 , d2 , . . . , dn0 −1 , dn0 , dn0 +1 , . . . , dK ; 1, 1, . . . , 1)
into a new transformational policy

d (Transfer) = 0; di1 , di2 , . . . , din0 −1 , din0 , din0 +1 , . . . , diK ; 1, 1, . . . , 1 .

Therefore, a transformation of the optimal dynamic policy d∗ is

(1, 2, . . . , K − 1, K) ⇒ (i1 , i2 , . . . , iK−1 , iK ) ;
and an inverse transformation of the optimal transformational dynamic policy d∗ (Transfer)
is
(i1 , i2 , . . . , iK−1 , iK ) ⇒ (1, 2, . . . , K − 1, K) .
For the general case, the following theorem finds the optimal dynamic rationing policy,
which may not be of threshold type, but must be of transformational threshold type.
Theorem 9 For the general case with PL (d) < P < PH (d) for any given policy d, if
there exists the minimal positive integer n0 ∈ {1, 2, . . . , K − 1, K} such that
(d)

(d)

PL (d) = Pi1 ≤ · · · ≤ Pin

0 −1

(d)

(d)

< P ≤ Pin ≤ · · · ≤ PiK = PH (d) ,
0

then the optimal transformational dynamic rationing policy is given by



d∗ (Transfer) = 0; 0, 0, . . . , 0, 1, 1, . . . , 1 ; 1, 1, . . . , 1 .
| {z } | {z }
n0 −1 zeros K−n0 +1 ones

44

G

Proof: From the set ΛG
1 , it is easy to see that P > P H (d;1 → n0 − 1). Hence we
consider the transformational sub-policy

e a (Transfer) = 0; di , di , . . . , di
d
1
2
n0 −1 , ∗, ∗, . . . , ∗; 1, 1, . . . , 1 .


G
By observing the transformational sub-policy di1 , di2 , . . . , din0 −1 related to P > P H (d;1 →
n0 − 1), it is easy to see from the proof of Theorem 4 that the optimal transformational
dynamic rationing sub-policy is given by
e ∗ (Transfer) = (0; 0, 0, . . . , 0, ∗, ∗, . . . , ∗; 1, 1, . . . , 1) .
d
a
G

Similarly, from 0 ≤ P ≤ P L (d;n0 → K) in the set ΛG
2 , we discuss the transformational
sub-policy

e b (Transfer) = 0; ∗, ∗, . . . , ∗, di , di
d
n0
n0 +1 , . . . , diK ; 1, 1, . . . , 1 .

By observing the transformational sub-policy (dn0 , dn0 +1 , . . . , dK ) related to 0 ≤ P ≤
G

P L (d;n0 → K), it is easy to see from the proof of Theorem 6 that the optimal transformational dynamic rationing sub-policy is given by
e ∗ (Transfer) = (0; ∗, ∗, . . . , ∗, 1, 1, . . . , 1; 1, 1, . . . , 1) .
d
b

Therefore, by observing the total transformational sub-policy (di1 , di2 , . . . , din0 −1 , din0 , din0 +1 ,
G
. . . , diK ) in the total set ΛG
1 ∪ Λ2 , the optimal transformational dynamic rationing policy

is given by



∗
∗
^
^
∗
∗
e
e
d (Transfer) = da (Transfer) (Transfer) = db (Transfer) (Transfer)
b
a


∗

= 0; 0, 0, . . . , 0, 1, 1, . . . , 1 ; 1, 1, . . . , 1 .
| {z } | {z }
n0 −1 zeros K−n0 +1 ones

This completes the proof.

Remark 4 (1) For the general case, although the optimal dynamic rationing policy is not
of threshold type, we show that it must be of transformational threshold type. Thus the
optimal transformational dynamic policy of the stock-rationing queue has a beautiful form
as follows:





d∗ (Transfer) = 0; 0, 0, . . . , 0, 1, 1, . . . , 1; 1, 1, . . . , 1 .
| {z } | {z }
n0 −1 zeros

45

K−n0 ones

(2) We use an inverse transformation of d∗ (Transfer) to be able to restore the original
optimal dynamic policy d∗ , since d∗ (Transfer) is always obtained easily. To indicate such
an inverse process, we take a simple example:
(d)

P1

(d)

≤ P3

(d)

≤ P4

(d)

≤ P7

(d)

< P ≤ P2

(d)

≤ P5

(d)

≤ P6

(d)

≤ P8 ,

it is easy to check that
d∗ = (0; 0, 1, 0, 0, 1, 1, 0, 1; 1, 1, 1, 1) .
Remark 5 The transformational version d∗ (Transfer) of the optimal dynamic rationing
policy d∗ plays a key role in the applications of the sensitivity-based optimization to the
study of stock-rationing queues. On the other hand, it is worthwhile to note that the RGfactorization of block-structured Markov processes can be extended and generalized to a
more general optimal transformational version d∗ (Transfer) in the study of stock-rationing
block-structured queues. See Li [56] and [60] for more details.
Remark 6 The bang-bang control is an effective method to roughly describe the optimal
dynamic policy, e.g., see Xia et al. [90, 92] and Ma et al. [60]. However, our optimal
transformational dynamic policy d∗ (Transfer) provides a more detailed result, and also
can restore the original optimal dynamic policy d∗ by means of an inverse transformation:
(i1 , i2 , . . . , iK−1 , iK ) ⇒ (1, 2, . . . , K − 1, K). Therefore, our optimal transformational dynamic rationing policy is superior to the bang-bang control.
The following theorem provides a useful summarization for Theorems 4 to 9, this
shows that we provide a complete algebraic solution to the optimal dynamic policy of the
stock-rationing queue. Therefore, Problems (P-a) to (P-c) proposed in Introduction are
completely solved by means of our algebraic method.
Theorem 10 For the stock-rationing queue with two demand classes, there must exist an
optimal transformational dynamic rationing policy




d∗ (Transfer) = 0; 0, 0, . . . , 0, 1, 1, . . . , 1; 1, 1, . . . , 1 .
| {z } | {z }
n0 −1 zeros

K−n0 ones

Based on this finding, we can achieve the following two useful results:

(a) The optimal dynamic rationing policy d∗ is of critical rationing level (i.e., threshold
type) under each of the three conditions: (i) P ≥ PH (d) for any given policy d; (ii)
46

PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d; and (iii) PL (d) < P < PH (d) with
the subscript vector (1, 2, . . . , K − 1, K) depending on Policy d.
(b) The optimal dynamic rationing policy is not of critical rationing level (i.e., threshold
type) if PL (d) < P < PH (d) with the subscript vector (i1 , i2 , . . . , iK−1 , iK ) 6= (1, 2, . . . , K − 1, K)
depending on Policy d.

7.4

A global optimal analysis

In this subsection, for a fixed penalty cost P , we discuss how to find a global optimal
policy of the stock-rationing queue with two demand classes by means of Theorem 10.
Note that if d∗ is a global optimal policy of this system, then d∗  c for any c ∈ D. Also,
we provide a simple effective method to be able to find the global optimal policy from the
policy set D.
In the policy set D, we define two key policies:
d1 = (0; 0, 0, . . . , 0; 1, 1, . . . , 1)
and
d2 = (0; 1, 1, . . . , 1; 1, 1, . . . , 1) .
Note that there are 2k different policies in the set D, we write

D = d1 , d2 ; c3 , c4 , . . . , c2k −1 , c2k .

The following theorem describes a useful characteristics of the two key policies d1 and
d2 by means of the class property of the policies in the set D, given in Theorem 3. This
characteristics makes us to be able to find the global optimal policy of the stock-rationing
queue.
Theorem 11 (1) If a fixed penalty cost P ≥ PH (d) for any given policy d, then P ≥
PH (d1 ).
(2) If a fixed penalty cost PL (d) > 0 and 0 ≤ P ≤ PL (d) for any given policy d, then
PL (d2 ) > 0 and 0 ≤ P ≤ PL (d2 ).
Proof: We only prove (1), while (2) can be proved similarly.
We assume the penalty cost: P < PH (d1 ) for Policy d1 = (0; 0, 0, . . . , 0; 1, 1, . . . , 1).
Then there exists the minimal positive integer n0 ∈ {1, 2, . . . , K − 1, K} such that
(d )

(d )

0 < P ≤ Pin 1 ≤ · · · ≤ PiK1 = PH (d1 ) ,
0

47

and also there exists at least a positive integer m0 ∈ {n0 + 1, n0 + 2, . . . , K − 1, K} such
that
(d )

(d )

Pim1 −1 < Pim1 .

(54)

0

0

Let
o
n
G
(d )
(d )
(d )
(d1 )
(d )
, PiK1 = Pin 1 > 0.
P L (d1 , n0 → K) = min Pin 1 , Pin 1+1 , . . . , PiK−1
0

0

0

G

Then from 0 ≤ P ≤ P L (d1 , n0 → K), we discuss the transformational sub-policy

g
(d
1 )b (Transfer) = 0; ∗, ∗, . . . , ∗, din0 , din0 +1 , . . . , diK ; 1, 1, . . . , 1 .

By observing the transformational sub-policy (dn0 , dn0 +1 , . . . , dK ) related to 0 ≤ P ≤
G

P L (d1 , n0 → K), it is easy to see from the proof of Theorem 6 that the optimal transformational dynamic rationing sub-policy is given by

This gives

∗
g
(d
1 )b (Transfer) = (0; ∗, ∗, . . . , ∗, 1, 1, . . . , 1; 1, 1, . . . , 1) .
∗
∗
g
(d
1 )b (Transfer) ≻ d1 = d

(55)

by using (54), where d∗ is given in Theorem 4.

Since for a fixed penalty cost P ≥ PH (d) for Policy d, it follows from Theorem 4 that
the optimal dynamic rationing policy of the stock-rationing queue is given by
d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1) .
By using (54), we obtain
∗
∗
g
(d
1 )b (Transfer) ≺ d .

(56)

This makes a contradiction between (55) and (56), thus our assumption on the penalty
cost: P < PH (d1 ) should not be correct. This completes the proof.
Theorem 11 shows that to find the optimal dynamic rationing policy of the stockrationing queue, our first step is to check whether there exists (a) the penalty cost P ≥
PH (d1 ), or (b) the fixed penalty cost PL (d2 ) > 0 and 0 ≤ P ≤ PL (d2 ). Thus, the two
special policies d1 and d2 are chosen as the first observation of our algebraic method on
the the optimal dynamic rationing policy.
The following theorem provides the global optimal solution to the optimal dynamic
rationing policy of the stock-rationing queue.
48

Theorem 12 In the stock-rationing queue with two demand classes, we have
(1) If a fixed penalty cost P ≥ PH (d1 ), then d∗ = d1  c for any c ∈ D.
(2) If a fixed penalty cost PL (d2 ) > 0 or 0 ≤ P ≤ PL (d2 ), then d∗ = d2  c for any
c ∈ D.
(3) If a fixed penalty cost P satisfies P < PH (d1 ) and P > PL (d2 ), then
n
o
∗
∗
∗
g
g
d∗ = max (d
)
(Transfer)
,
(d
)
(Transfer)
,
(c
)
(Transfer)
for
k
=
3,
4,
.
.
.
,
K
1 b
2 a
k

and d∗  c for any c ∈ D.

Proof: We only prove (3), while (1) and (2) are provided in those of Theorem 11.
If P < PH (d1 ) or P > PL (d2 ), then both d1 and d2 are not the optimal dynamic
rationing policy of the system. In this case, by using Theorem 10, we indicate that the
optimal dynamic rationing policy must be of transformational threshold type. Thus we
have
o
n
∗
∗
g∗
g
d∗ = max (d
1 )b (Transfer) , (d2 )a (Transfer) , (ck ) (Transfer) for k = 3, 4, . . . , K ,

which is of transformational threshold type, since K is a finite positive integer. It is clear
that d∗  c for any c ∈ D. This completes the proof.

8

The Static Rationing Policies

In this section, we analyze the static (i.e., threshold type) rationing policies of the stockrationing queue with two demand classes, and discuss the optimality of the static rationing
policies. Furthermore, we provide a necessary condition under which a static rationing
policy is optimal. Based on this, we can intuitively understand some differences between
the optimal static and dynamic rationing policies.
To study static rationing policy, we define a static policy subset of the policy set D
as follows. For θ = 1, 2, . . . , K, K + 1, we write d△,θ as a static rationing policy d with
di = 0 if 1 ≤ i ≤ θ − 1 and di = 1 if θ ≤ i ≤ K. Clearly, if θ = 1, then
d△,1 = (0; 1, 1, . . . , 1; 1, 1, . . . , 1) ;
if θ = K, then
d△,K = (0; 0, 0, . . . , 0, 1; 1, 1, . . . , 1) ;
49

and if θ = K + 1, then
d△,K+1 = (0; 0, 0, . . . , 0; 1, 1, . . . , 1) .
Let
D ∆ = {d△,θ : θ = 1, 2, . . . , K, K + 1} .
Then





D ∆ = 0; 0, 0, . . . , 0, 1, 1, . . . , 1; 1, 1, . . . , 1 : θ = 1, 2, . . . , K, K + 1 .
| {z }


θ−1 zeros

It is easy to see that the static rationing policy
set D ∆ ⊂ D.




For a static rationing policy d△,θ = 0; 0, 0, . . . , 0, 1, 1, . . . , 1; 1, 1, . . . , 1 with θ =
| {z }
θ−1 zeros

1, 2, . . . , K, K + 1, it follows from (5) that

ξ0 = 1,
i = 0;

i
 α,
i = 1, 2, . . . , θ − 1;
(d
)
 θ−1
ξi △,θ =
 α
β i , i = θ, θ + 1, . . . , N.
β

and

h(d△,θ ) = 1 +

N
X

(d△,θ )

ξi

i=1

  θ−1 θ

α 1 − αθ−1
β 1 − β N −θ+1
α
=1+
+
.
1−α
β
1−β
It follows from (6) that

π

(d△,θ )

(i) =











1
h

(d△,θ )

1
h

(d△,θ )

h

(d△,θ )

1

,

i = 0;

αi ,
 θ−1

i = 1, 2, . . . , θ − 1;

α
β

β i , i = θ, θ + 1, . . . , N.

On the other hand, it follows from (8) to (11) that for i = 0
f (0) = −C2,1 µ1 − C2,2 µ2 − C3 λ;
for i = 1, 2, . . . , θ − 1,
f (d△,θ ) (i) = Rµ1 − C1 i − C2,2 µ2 − C3 λ;
50

for i = θ, θ + 1, . . . , K,
f (d△,θ ) (i) = R (µ1 + µ2 ) − C1 i − C3 λ − P µ2 ;
and for i = K + 1, K + 2, . . . , N,
f (i) = R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N } .
Note that
η d△,θ = π (d△,θ ) (0) f (0) +

θ−1
X

π (d△,θ ) (i) f (d△,θ ) (i)

i=1

+

K
X

π (d△,θ ) (i) f (d△,θ ) (i) +

N
X

π (d△,θ ) (i) f (i) ,

i=K+1

i=θ

we obtain an explicit expression for the long-run average profit of the stock-rationing queue
under the static rationing policy d△,θ as follows:
(
θ−1
X
1
d△,θ
η
= (d ) − (C2,1 µ1 + C2,2 µ2 + C3 λ) +
αi (Rµ1 − C1 i − C2,2 µ2 − C3 λ)
△,θ
h
i=1
K  θ−1
X
α
β i [R (µ1 + µ2 ) − C1 i − C3 λ − P µ2 ]
+
β
i=θ
)
 θ−1
N
X


α
+
β i R (µ1 + µ2 ) − C1 i − C3 λ1{i<N } − C4 λ1{i=N }
β
i=K+1
#
"
(


α 1 − αθ−1
α 1 − αθ−1
(θ − 1) αθ
1
− C1
−
= (d ) −γ1 + γ2
1−α
1−α
h △,θ
(1 − α)2
"
#

 θ−1
α
(θ − 1) β θ − N β N +1 β θ 1 − β N −θ+1
−
C1
+
β
1−β
(1 − β)2
  θ−1
 )
 θ−1
β θ 1 − β K−θ+1
β K+1 1 − β N −K
α
α
γ4
+
γ3
.
+
β
1−β
β
1−β
Let

o
n
d∗△,θ = arg max η d△,θ
d△,θ ∈D ∆

and

o
n
d△,θ∗ = arg max η d△,θ .
1≤θ≤K+1

Then

d∗△,θ

= d△,θ∗ . Hence we call

d∗△,θ

(or d△,θ∗ ) the optimal static rationing policy in

the static rationing policy set D ∆ . Since D ∆ ⊂ D, the partially ordered set D shows that
51

D ∆ is also a partially ordered set. Based on this, it is easy to see from the two partially
ordered sets D and D ∆ that
∗

∗

η d△,θ ≤ η d , or d∗△,θ  d∗ ,
where d∗ is the optimal dynamic rationing policy in the set D.
∗

∗

If η d△,θ = η d , then the optimal static rationing policy d∗△,θ is also optimal in the policy
∗

∗

set D, thus the optimal dynamic rationing policy is of threshold type. If η d△,θ < η d , then
the optimal static rationing policy d∗△,θ is not optimal in the static rationing policy subset
D ∆ , i.e., it is also suboptimal in the policy set D, thus the optimal dynamic rationing
policy is not of threshold type.
Now, we set up some conditions under which the optimal static rationing policy d∗△,θ
is suboptimal in the dynamic rationing policy set D.
In the static rationing policy subset D ∆ , it is easy to see that there must exist a
minimal positive integer θ ∗ ∈ {1, 2, . . . , K, K + 1} such that




d∗△,θ = d△,θ∗ = 0; 0, 0, . . . , 0,1, 1, . . . , 1; 1, 1, . . . , 1 .
| {z }
θ ∗ −1 zeros

By using the optimal static rationing policy d∗△,θ (or d△,θ∗ ), the following theorem
determines the sign of the function G(d△,θ ) (θ) + b in the three different points: θ =
θ ∗ − 1, θ ∗ , θ ∗ + 1. This may be useful for us to understand how to use Proposition 1 to
give the optimal long-run average profit of this system.
Theorem 13 In the stock-rationing queue, the static rationing policies d△,θ∗ −1 , d△,θ∗
and d△,θ∗ +1 satisfy the following conditions:
G(d△,θ∗ −1 ) (θ ∗ − 1) + b ≤ 0, G(d△,θ∗ ) (θ ∗ − 1) + b ≤ 0,
and
G(d△,θ∗ ) (θ ∗ ) + b ≥ 0, G(d△,θ∗ +1 ) (θ ∗ ) + b ≥ 0.
Proof: We consider three static rationing policies with an interrelated structure as

52

follows:




d△,θ∗ −1 = 0; 0, 0, . . . , 0,1, 1, 1, 1, . . . , 1; 1, 1, . . . , 1 ,
| {z }


θ ∗ −2 zeros



d△,θ∗ = 0; 0, 0, . . . , 0, 0,1, 1, 1, . . . , 1; 1, 1, . . . , 1 ,
{z
}
|


θ ∗ −1 zeros



d△,θ∗ +1 = 0; 0, 0, . . . , 0, 0, 0,1, . . . , 1; 1, 1, . . . , 1 .
|
{z
}
θ ∗ zeros

Note that d△,θ∗ is the optimal static rationing policy, and d∗△,θ = d△,θ∗ . It is clear that
d△,θ∗  d△,θ∗ −1 and d△,θ∗  d△,θ∗ +1 . Thus it follows from (39) that
i
h
η d△,θ∗ +1 − η d△,θ∗ = −µ2 π (d△,θ∗ +1 ) (θ ∗ ) G(d△,θ∗ ) (θ ∗ ) + b ,
which, together with η d△,θ∗ +1 − η d△,θ∗ ≤ 0, leads to
G(d△,θ∗ ) (θ ∗ ) + b ≥ 0.
On the other hand, it follows from (39) that
i
h
η d△,θ∗ − η d△,θ∗ +1 = µ2 π (d△,θ∗ ) (θ ∗ ) G(d△,θ∗ +1 ) (θ ∗ ) + b ,
this gives
G(d△,θ∗ +1 ) (θ ∗ ) + b ≥ 0
Similarly, by using η d△,θ∗ ≥ η d△,θ∗ −1 and
η

d△,θ∗

−η

d△,θ∗ −1

i
h
d△,θ∗ −1 )
d△,θ∗ )
∗
∗
(
(
(θ − 1) + b ,
(θ − 1) G
= −µ2 π

this gives
G(d△,θ∗ −1 ) (θ ∗ − 1) + b ≤ 0;
and

we obtain

i
h
η d△,θ∗ −1 − η d△,θ∗ = µ2 π (d△,θ∗ −1 ) (θ ∗ − 1) G(d△,θ∗ ) (θ ∗ − 1) + b ,
G(d△,θ∗ ) (θ ∗ − 1) + b ≤ 0.

This completes the proof.

53

9

Numerical Experiments

In this section, by observing several different penalty costs, we conduct numerical experiments to demonstrate our theoretical results and to gain insights on the optimal dynamic
and static rationing policies in the stock-rationing queue.
In Examples 1 to 4, we take some common parameters in the stock-rationing queue
with two demand classes as follows:
C1 = 1, C2,1 = 4, C2,2 = 1, C3 = 5, C4 = 1, R = 15, N = 100.
In Examples 1 and 2, we analyze some difference between the optimal static and
dynamic rationing policies, and use the optimal static rationing policy to show whether
or not the the optimal dynamic rationing policy is of threshold type.
Example 1. We give some useful comparisons of the optimal long-run average profit
between two different penalty costs, and further verify how the optimality depends on
the penalty cost in Theorems 4 and 6 for the the optimal dynamic rationing policy. To
this end, we further take the system parameters as λ = 3, µ1 = 4, µ2 = 2, K = 15 and
1 ≤ i ≤ 15.
Case one: A higher penalty cost
We take a higher penalty cost P = 10. If d∗i = 0 for 1 ≤ i ≤ 15 such that a
possible optimal dynamic rationing policy d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1), then we obtain
∗

η d = 22.3. On the other hand, if d′∗
i = 1 for 1 ≤ i ≤ 15 such that another possible
′∗

optimal dynamic rationing policy d′∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1), then we get η d = 13.
∗

′∗

By comparing η d = 22.3 with η d

= 13, it is easy to see that the possible optimal

dynamic rationing policy should be d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1).
Case two: A lower penalty cost
We choose a lower penalty cost P = 0.1. If d∗i = 1 for 1 ≤ i ≤ 15 such that a possible
∗

optimal dynamic rationing policy d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1), then we obtain η d =
22.9. On the other hand, if d′∗
i = 0 for 1 ≤ i ≤ 15 such that another possible optimal dy′∗

namic rationing policy d′∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1), then we get η d = 22.3. Obviously,
the possible optimal dynamic rationing policy should be d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1).
Example 2. We use the numerical example to demonstrate whether or not the optimal
static rationing policy is suboptimal in the policy set D. If yes, then we show that the
optimal dynamic rationing policy is not of threshold type. To this end, we take some
54

system parameters: λ = 3, µ1 = 4, µ2 = 2, K = 15, 1 ≤ θ ≤ 15. These parameters are
the same as those in Example 1.
In what follows our observation is to focus on the higher penalty cost P = 10 and the
lower penalty cost P = 0.1, respectively.
Case one: A higher penalty cost
∗

We observe how the optimal long-run average profit η d depends on the threshold
from θ = 1 to θ = 15. From Figure 3, it is seen that the optimal threshold is θ ∗ = 9
∗

and η d∆,θ∗ = 21.4. However, from Case one of Example 1, η d = 22.3. Thus we obtain
∗

that η d∆,θ∗ = 21.4 < η d = 22.3. This shows that the optimal static rationing policy
is suboptimal in the policy set D, and the optimal dynamic rationing policy is not of
threshold type. Thus, d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1), given in Example 1, is not the
optimal dynamic rationing policy yet.
22
20

ηd*

18
16
14
12

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
θ
∗

Figure 3: The optimal long-run average profit η d vs. the threshold θ
Case two: A lower penalty cost
From Figure 4, it is seen that the optimal threshold is θ ∗ = 3 and η d∆,θ∗ = 22.9. From
∗

∗

Case two of Example 1, we obtained η d = 22.9. This gives that η d∆,θ∗ = η d = 22.9.
Therefore, the optimal static rationing policy is the same as the optimal dynamic rationing
policy, and it is optimal in the policy set D, and the optimal dynamic rationing policy is of
threshold type. Thus, d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1), given in Example 1, is the optimal
dynamic rationing policy.
Example 3. We analyze how the optimal long-run average profit of the stock-rationing

55

23

ηd*

22.5
22
21.5
21

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
θ
∗

Figure 4: The optimal long-run average profit η d vs. the threshold θ
queue depends on the arrival rate. Our observation focuses on the higher penalty cost
P = 10 and the lower penalty cost P = 0.1, respectively. To do this, we further take the
system parameters: µ1 = 30, µ2 = 40 and the threshold: K = 5, 6, 10.
Case one: A higher penalty cost
Let P = 10 and d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1). From Figure 5, it is seen that the
∗

optimal long-run average profit η d increases as λ increases. In addition, with the threshold
∗

K increases, the optimal long-run average profit η d increases less slowly as λ increases.
2.5

×1023
K=5
K=6
K=10

2

ηd*

1.5
1
0.5
0
47

48

49

50

λ
∗

Figure 5: η d vs. λ under three different thresholds K
Case two: A lower penalty cost
56

Let P = 0.1 and d∗ = (0; 1, 1, . . . , 1; 1, 1, . . . , 1). We discuss how the optimal long-run
∗

average profit η d depends on λ for λ ∈ (65, 80). From Figure 6, it is seen that the optimal
∗

long-run average profit η d increases as λ increases. In addition, with the threshold K
∗

increases, the optimal long-run average profit η d increases less slowly as λ increases.
10

×1036
K=5
K=6
K=10

8

ηd*

6
4
2
0
65

70

75

80

λ
∗

Figure 6: η d vs. λ under three different thresholds K
Example 4. Our observation is to focus on how the penalty cost P influences the
long-run average profit η d for any given policy d. From (17), it is easy to see that for any
given policy d, the long-run average profit η d is linear in the penalty cost P . To show this,
we take the system parameters: P ∈ (0, 50), µ1 = 4, µ2 = 2, λ = 3 and K = 15. In this
case, we observe the special policy: d1 = d∗ = (0; 0, 0, . . . , 0; 1, 1, . . . , 1). Figure 7 shows
∗

that for the special policy d1 = d∗ , the long-run average profit η d linearly decreases as
P increases.

10

Concluding Remarks

In this paper, we highlight intuitive understanding on the optimal dynamic rationing policy
of the stock-rationing queue with two demand classes by means of the sensitivity-based
optimization. To find the optimal dynamic rationing policy, we establish a policy-based
birth-death process and a more general reward function such that the long-run average
profit of the stock-rationing queue is expressed explicitly. Furthermore, we set up a policybased Poisson equation and provide an explicit expression for its solution. Based on this,
we derive a performance difference equation between any two policies such that we can
57

1000

ηd*

500
0
-500
-1000

0

5 10 15 20 25 30 35 40 45 50
P
∗

Figure 7: The long-run average profit η d vs. the penalty cost P
find the optimal dynamic rationing policy and compute the maximal long-run average
profit from three different areas of the penalty costs. Therefore, we provide an algebraic
method to set up a complete algebraic solution to the optimal dynamic rationing policy.
We show that the optimal dynamic policy must be of transformational threshold type,
which leads to refining three simple sufficient conditions under each of which the optimal
dynamic policy is of threshold type. In addition, we develop some new structural properties
(e.g., set-structured monotonicity, and class property of policies) of the optimal dynamic
rationing policy. Therefore, we believe that the methodology and results developed in
this paper can be applicable to analyzing more general stock-rationing queues, and open
a series of potentially promising research.
Along such a line, there are a number of interesting directions for potential future
research, for example:
• Extending to the stock-rationing queues with multiple demand classes, multiple types
of products, backorders, batch order, batch production, and so on.
• Analyzing non-Poisson input, such as Markovian arrival processes (MAPs); and/or
non-exponential service times, e.g. the PH distributions.
• Discussing how the long-run profit can be influenced by some concave or convex
reward functions.
• Studying individual or social optimization for stock-rationing queues from a perspective of game theory by means of the sensitivity-based optimization.

58

Acknowledgements
The authors thank the associate editor and two anonymous reviewers for their many valuable comments to improve the presentation of this paper. Quan-Lin Li thanks Shaohui
Zheng at Hong Kong University of Science and Technology (HKUST) for providing the
inventory control problem during his visiting Professor Zheng in 2007. Furthermore, the
authors gratitude Xi-Ren Cao at HKUST, Li Xia at Sun Yat-sen University and Xiaole Wu
at Fudan University for their valuable discussion and suggestions. Quan-Lin Li was supported by the National Natural Science Foundation of China under grants No. 71671158
and 71932002 and by the Beijing Social Science Foundation Research Base Project under
grant No. 19JDGLA004.

References
[1] Alfieri, A., Pastore, E., Zotteri, G. (2017). Dynamic inventory rationing: How to
allocate stock according to managerial priorities. An empirical study. International
Journal of Production Economics, 189, 14–29.
[2] Arslan, H., Graves, S. C., Roemer, T. A. (2007). A single-product inventory model for
multiple demand classes. Management Science, 53(9), 1486–1500.
[3] Asmussen, S., Bladt, M. (1994). Poisson’s equation for queues driven by a Markovian
marked point process. Queueing Systems, 17(1-2), 235–274.
[4] Benjaafar, S., ElHafsi, M. (2006). Production and inventory control of a single product
assemble-to-order system with multiple customer classes. Management Science, 52(12),
1896–1912.
[5] Benjaafar, S., ElHafsi, M., Lee, C. Y., Zhou, W. (2011). Optimal control of an assembly
system with multiple stages and multiple demand classes. Operations Research, 59(2),
522–529.
[6] Bhulai, S. (2002). Markov Decision Processes: The Control of High-dimensional Systems. Ph.D. Thesis, Vrije Universiteit Amsterdam. Universal Press, The Netherlands.

59

[7] Bini, D. A., Dendievel, S. Latouche, G., Meini, B. (2016). General solution of the
Poisson equation for quasi-birth-and-death processes. SIAM Journal on Applied Mathematics, 76(6), 2397–2417.
[8] Bitran, G. R., Mondschein, S. V. (1995). An application of yield management to the
hotel industry considering multiple day stays. Operations Research, 43(3), 427–443.
[9] Bulut, Ö, Fadiloğlu, M. M. (2011). Production control and stock rationing for a maketo-stock system with parallel production channels. IIE Transactions, 43(6), 432–450.
[10] Cao, X. R. (1994). Realization Probabilities: The Dynamics of Queuing Systems. New
York: Springer-Verlag.
[11] Cao, X. R. (2007). Stochastic Learning and Optimization: A Sensitivity-Based Approach. Springer.
[12] Cao, X. R., Chen, H. F. (1997). Perturbation realization, potentials, and sensitivity
analysis of Markov processes. IEEE Transactions on Automatic Control, 42(10), 1382–
1393.
[13] Cao, X. R., Yuan, X. M., Qiu, L. (1996). A single sample path-based performance sensitivity formula for Markov chains. IEEE Transactions on Automatic Control, 41(12),
1814–1817.
[14] Cassandras, C. G., Lafortune, S. (2008). Introduction to Discrete Event Systems.
Springer.
[15] Chen, S., Xu, J., Feng, Y. (2010). A partial characterization of the optimal ordering/rationing policy for a periodic review system with two demand classes and backordering. Naval Research Logistics, 57(4), 330–341.
[16] Cheng, T. C. E., Gao, C., Shen, H. (2011). Production and inventory rationing in a
make-to-stock system with a failure-prone machine and lost sales. IEEE transactions
on automatic control, 56(5), 1176–1180.
[17] Chew, E. P., Lee, L. H., Liu, S. (2013). Dynamic rationing and ordering policies for
multiple demand classes. OR spectrum, 35(1), 127–151.

60

[18] Cohen, M. A., Kleindorfer, P. R., Lee, H. L. (1988). Service constrained (s, S) inventory systems with priority demand classes and lost sales. Management Science, 34(4),
482–499.
[19] de Véricourt, F., Karaesmen, F., Dallery, Y. (2001). Assessing the benefits of different stock-allocation policies for a make-to-stock production system. Manufacturing &
Service Operations Management, 3(2), 105–121.
[20] de Véricourt, F., Karaesmen, F., Dallery, Y. (2002). Optimal stock allocation for a
capacitated supply system. Management Science, 48(11), 1486–1501.
[21] Dekker, R., Hill, R. M., Kleijn, M. J., Teunter, R. H. (2002). On the (S − 1, S) lost
sales inventory model with priority demand classes. Naval Research Logistics, 49(6),
593–610.
[22] Dekker, R., Kleijn, M. J., De Rooij, P. J. (1998). A spare parts stocking policy based
on equipment criticality. International Journal of Production Economics, 56, 69–77.
[23] Deshpande, V., Cohen, M. A., Donohue, K. (2003). A threshold inventory rationing
policy for service-differentiated demand classes. Management Science, 49(6), 683–703.
[24] Ding, Q., Kouvelis, P., Milner, J. M. (2006). Dynamic pricing through discounts for
optimizing multiple-class demand fulfillment. Operations Research, 54(1), 169–183.
[25] Ding, Q., Kouvelis, P., Milner, J. M. (2016). Inventory rationing for multiple class demand under continuous review. Production and Operations Management, 25(8), 1344–
1362.
[26] Elaydi, S. N. (1996). Dynamics of first order difference equations. In: An Introduction
to Difference Equations, Pages 1–48. Springer.
[27] ElHafsi, M. (2009). Optimal integrated production and inventory control of an
assemble-to-order system with multiple non-unitary demand classes. European Journal
of Operational Research, 194(1), 127–142.
[28] ElHafsi, M., Camus, H., Craye, E. (2008). Optimal control of a nested-multipleproduct assemble-to-order system. International Journal of Production Research,
46(19), 5367–5392.
61

[29] ElHafsi, M., Camus, H., Craye, E. (2010). Managing an integrated production inventory system with information on the production and demand status and multiple
non-unitary demand classes. European Journal of Operational Research, 207(2), 986–
1001.
[30] Elhafsi, M., Zhi, L., Camus, H., Craye, E. (2015). An assemble-to-order system with
product and components demand with lost sales. International Journal of Production
Research, 53(3), 718–735.
[31] Escalona, P., Ordóñez, F., Kauak, I. (2017). Critical level rationing in inventory
systems with continuously distributed demand. OR Spectrum, 39(1), 273–301.
[32] Escalona, P., Ordóñez, F., Marianov, V. (2015). Joint location-inventory problem
with differentiated service levels using critical level policy. Transportation Research
Part E: Logistics and Transportation Review, 83, 141–157.
[33] Evans, R. V. (1968). Sales and restocking policies in a single item inventory system.
Management Science, 14(7), 463–472.
[34] Fadıloğlu, M. M., Bulut, Ö. (2010). A dynamic rationing policy for continuous-review
inventory systems. European Journal of Operational Research, 202(3), 675–685.
[35] Frank, K. C., Zhang, R. Q., Duenyas, I. (2003). Optimal policies for inventory systems
with priority demand classes. Operations Research, 51(6), 993–1002.
[36] Gayon, J. P., Benjaafar, S., De Véricourt, F. (2009). Using imperfect advance demand information in production-inventory systems with multiple customer classes.
Manufacturing & Service Operations Management, 11(1), 128–143.
[37] Gayon, J. P., De Vericourt, F., Karaesmen, F. (2009). Stock rationing in an M/Ek /1
multi-class make-to-stock queue with backorders. IIE Transactions, 41(12), 1096–1109.
[38] Glasserman, P. (1991). Gradient Estimation via Perturbation Analysis. Springer.
[39] Ha, A. Y. (1997). Inventory rationing in a make-to-stock production system with
several demand classes and lost sales. Management Science, 43(8), 1093–1103.
[40] Ha, A. Y. (1997). Stock-rationing policy for a make-to-stock production system with
two priority classes and backordering. Naval Research Logistics, 44(5), 457–472.
62

[41] Ha, A. Y. (2000). Stock rationing in an M/Ek /1 make-to-stock queue. Management
Science, 46(1), 77–87.
[42] Haynsworth, H. C., Price, B. A. (1989). A model for use in the rationing of inventory
during lead time. Naval Research Logistics, 36(4), 491–506.
[43] Ho, Y. C., Cao, X. R. (1991). Perturbation Analysis of Discrete-Event Dynamic Systems. Kluwer Academic Publisher.
[44] Huang, B., Iravani, S. M. (2006). Optimal production and rationing decisions in
supply chains with information sharing. Operations Research Letters, 35(5), 669–676.
[45] Huang, B., Iravani, S. M. (2008). A make-to-stock system with multiple customer
classes and batch ordering. Operations Research, 56(5), 1312–1320.
[46] Hung, H. C., Chew, E. P., Lee, L. H., Liu, S. (2012). Dynamic inventory rationing
for systems with multiple demand classes and general demand processes. International
Journal of Production Economics, 139(1), 351–358.
[47] Hung, Y. F., Hsiao, J. Y. (2013). Inventory rationing decision models during replenishment lead time. International Journal of Production Economics, 144(1), 290–300.
[48] Isotupa, K. S. (2006). An (s, Q) Markovian inventory system with lost sales and two
demand classes. Mathematical and Computer Modelling, 43(7-8), 687–694.
[49] Jain, A., Moinzadeh, K., Dumrongsiri, A. (2015). Priority allocation in a rental model
with decreasing demand. Manufacturing & Service Operations Management, 17(2),
236–248.
[50] John, M. (1994). The case for using cost benefit analysis to evaluate the supply of
public goods in the maritime industry. Maritime Policy and Management, 21(1), 3–13.
[51] Kaplan, A. (1969). Stock rationing. Management Science, 15(5), 260–267.
[52] Kleijn, M. J., Dekker, R. (1999). An overview of inventory systems with several
demand classes. In: New trends in distribution logistics, Pages 253–265. Springer.
[53] Kranenburg, A. A., van Houtum, G. J. (2007). Cost optimization in the (S − 1, S)
lost sales inventory model with multiple demand classes. Operations research letters,
35(4), 493–502.
63

[54] Latouche, G., Ramaswami, V. (1999). Introduction to Matrix Analytic Methods in
Stochastic Modeling. SIAM.
[55] Lee, T. C., Hersh, M. (1993). A model for dynamic airline seat inventory control with
multiple seat bookings. Transportation Science, 27(3), 252–265.
[56] Li, Q. L. (2010). Constructive Computation in Stochastic Models with Applications:
The RG-Factorizations. Springer.
[57] Li, Q. L., Cao, J. H. (2004). Two types of RG-factorizations of quasi-birth-and-death
1015 processes and their applications to stochastic integral functionals. Stochastic Models, 20(3), 299–340.
[58] Li, Q. L., Liu, L. M. (2004). An algorithmic approach on sensitivity analysis of perturbed QBD processes. Queueing Systems, 48(3-4), 365–397.
[59] Li, Q. L., Ma, J. Y., Fan, R. N., Xia, L. (2019). An overview for Markov decision processes in queues and networks. In: Stochastic Models in Reliability, Network Security
and System Safety, Pages 44–71. Springer.
[60] Ma, J. Y., Xia, L., Li, Q. L. (2019). Optimal energy-efficient policies for data centers through sensitivity-based optimization. Discret. Discrete Event Dynamic Systems,
29(4), 567–606.
[61] Makowski, A. M., Shwartz, A. (2002). The Poisson Equation for Countable Markov
Chains: Probabilistic Methods and Interpretations. In: Handbook of Markov Decision
Processes, Pages 269–303. Kluwer Academic Publishers.
[62] Melchiors, P. (2003). Restricted time-remembering policies for the inventory rationing
problem. International Journal of Production Economics, 81, 461–468.
[63] Melchiors, P., Dekker, R., Kleijn, M. J. (2000). Inventory rationing in an (s, Q)
inventory model with lost sales and two demand classes. Journal of the Operational
Research Society, 51(1), 111–122.
[64] Möllering, K. (2007). Inventory Rationing: A New Modeling Approach Using Markov
Chain Theory. Springer.

64

[65] Möllering, K. T., Thonemann, U. W. (2008). An optimal critical level policy for
inventory systems with two demand classes. Naval Research Logistics, 55(7), 632–642.
[66] Möllering, K. T., Thonemann, U. W. (2010). An optimal constant level rationing
policy under service level constraints. OR Spectrum, 32(2), 319–341.
[67] Nadar, E., Akan, M., cheller-Wolf, A. (2014). Optimal structural results for assembleto-order generalized M-systems. Operations Research, 62(3), 571–579.
[68] Nahmias, S., Demmy, W. S. (1981). Operating characteristics of an inventory system
with rationing. Management Science, 27(11), 1236–1245.
[69] Neuts, M. F. (1981). Matrix-Geometric Solutions in Stochastic Models: An Algorithmic Approach. The Johns Hopkins University Press.
[70] Pang, Z., Shen, H., Cheng, T. C. E. (2014). Inventory rationing in a make-to-stock
system with batch production and lost sales. Production and Operations Management,
23(7), 1243–1257.
[71] Papastavrou, E., Andreou, P., Efstathiou, G. (2014). Rationing of nursing care and
nurse–patient outcomes: a systematic review of quantitative studies. The International
Journal of Health Planning and Management, 29(1), 3–25.
[72] Papier, F., Thonemann, U. W. (2010). Capacity rationing in stochastic rental systems
with advance demand information. Operations Research, 58(2), 274–288.
[73] Papier, F., Thonemann, U. W. (2011). Capacity rationing in rental systems with two
customer classes and batch arrivals. Omega, 39(1), 73–85.
[74] Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic
Programming. John Wiley & Sons.
[75] Raghavan, N. R. S., Roy, D. (2005). A stochastic Petri Net approach for inventory
rationing in multi-echelon supply chains. Journal of Heuristics, 11, 421–446.
[76] Schulte, B., Pibernik, R. (2017). Profitability of service-level-based price differentiation with inventory rationing. Production and Operations Management, 26(5), 903–923.
[77] Sobel, M. J., Zhang, R. Q. (2001). Inventory policies for systems with stochastic and
deterministic demand. Operations Research, 49(1), 157–162.
65

[78] Tan, T., Güllü, R., Erkip, N. (2009). Using imperfect advance demand information
in ordering and rationing decisions. International Journal of Production Economics,
121(2), 665–677.
[79] Tempelmeier, H. (2006). Supply chain inventory optimization with two customer
classes in discrete time. European Journal of Operational Research, 174(1), 600–621.
[80] Teunter, R. H., Haneveld, W. K. K. (2008). Dynamic inventory rationing strategies
for inventory systems with two demand classes, Poisson demand and backordering.
European Journal of Operational Research, 190(1), 156–178.
[81] Topkis, D. M. (1968). Optimal ordering and rationing policies in a nonstationary
dynamic inventory model with n demand classes. Management Science, 15(3), 160–
176.
[82] Turgay, Z., Karaesmen, F., Örmeci, E. L. (2015). A dynamic inventory rationing
problem with uncertain demand and production rates. Annals of Operations Research,
231(1), 207–228.
[83] Van Foreest, N. D., Wijngaard, J. (2014). On optimal policies for productioninventory systems with compound Poisson demand and setup costs. Mathematics of
Operations Research, 39(2), 517–532.
[84] van Wijk, A. C. C., Adan, I. J., van Houtum, G. J. (2019). Optimal lateral transshipment policies for a two location inventory problem with multiple demand classes.
European Journal of Operational Research, 272(2), 481–495.
[85] Veinott Jr, A. F. (1965). Optimal policy in a dynamic, single product, nonstationary
inventory model with several demand classes. Operations Research, 13(5), 761–778.
[86] Wang, D., Tang, O. (2014). Dynamic inventory rationing with mixed backorders and
lost sales. International Journal of Production Economics, 149, 56–67.
[87] Wang, D., Tang, O., Huo, J. (2013). A heuristic for rationing inventory in two demand
classes with backlog costs and a service constraint. Computers & Operations Research,
40(12), 2826–2835.

66

[88] Wang, Y., Zhang, S. H., Sun, L. (2013). Anticipated rationing policy for two demand
classes under service level constraints. Computers & Industrial Engineering, 65(2),
331–340.
[89] Xia, L., Cao, X. R. (2012). Performance optimization of queueing systems with perturbation realization. European Journal of Operational Research, 218(2), 293–304.
[90] Xia, L. He, Q. M., Alfa, A. S. (2017). Optimal control of state-dependent service rates
in a MAP/M/1 queue. IEEE Transactions on Automatic Control, 62(10), 4965–4979.
[91] Xia, L., Shihada, B. (2013). Max-Min optimality of service rate control in closed
queueing networks. IEEE Transactions on Automatic Control, 58(4), 1051–1056.
[92] Xia, L., Zhang, Z. G., Li, Q. L., Glynn, P. W. (2018). A c/µ-rule for service resource
allocation in group-server queues. arXiv preprint arXiv:1807.05367, Pages 1–54.
[93] Xu, J., Serrano, A., Lin, B. (2017). Optimal production and rationing policy of twostage tandem production system. International Journal of Production Economics, 185,
100–112.
[94] You, P. S. (2003). Dynamic rationing policies for product with incremental upgrading
demands. European Journal of Operational Research, 144(1), 128–137.
[95] Zhao, H., Deshpande, V., Ryan, J. K. (2005). Inventory sharing and rationing in
decentralized dealer networks. Management Science, 51(4), 531–547.

67

