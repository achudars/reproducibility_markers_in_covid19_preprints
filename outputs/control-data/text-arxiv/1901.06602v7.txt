A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

arXiv:1901.06602v7 [math.NT] 20 Mar 2021

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI
Dedicated to Wolfgang M. Schmidt on the occasion of his 85th birthday
A BSTRACT. We extend the parametric geometry of numbers (initiated by Schmidt and
Summerer, and deepened by Roy) to Diophantine approximation for systems of m linear
forms in n variables, and establish a new connection to the metric theory via a variational
principle that computes fractal dimensions of a variety of sets of number-theoretic interest. The proof relies on two novel ingredients: a variant of Schmidt’s game capable of
computing the Hausdorff and packing dimensions of any set, and the notion of templates,
which generalize Roy’s rigid systems. In particular, we compute the Hausdorff and packing
dimensions of the set of singular systems of linear forms and show they are equal, resolving a conjecture of Kadyrov, Kleinbock, Lindenstrauss and Margulis, as well as a question
of Bugeaud, Cheung and Chevallier. As a corollary of Dani’s correspondence principle,
the divergent trajectories of a one-parameter diagonal action on the space of unimodular
lattices with exactly two Lyapunov exponents with opposite signs has equal Hausdorff and
packing dimensions. Other applications include quantitative strengthenings of theorems
due to Cheung and Moshchevitin, which originally resolved conjectures due to Starkov and
Schmidt respectively; as well as dimension formulas with respect to the uniform exponent
of irrationality for simultaneous and dual approximation in two dimensions, completing
partial results due to Baker, Bugeaud, Cheung, Chevallier, Dodson, Laurent and Rynne.

C ONTENTS

1.
2.
3.

4.

Part 1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Readers’ Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Conventions and Glossary of Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Statements of Main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1. Dani correspondence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2. Dimensions of very singular matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3. 1 × 2 and 2 × 1 matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4. Singularity on average . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5. Starkov’s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6. Schmidt’s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The variational principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1

3
3
4
7
8
11
14
16
16
17
18

2

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

4.1. Successive minima functions and templates . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2. New proofs of old results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5. Directions to further research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1. Exact Hausdorff and packing dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2. Quantitative Schmidt’s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3. Regularity of dimension functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4. Intersecting standard and uniform exponent level sets . . . . . . . . . . . . . . . . .
5.5. Precise dimension formulas for uniform exponent level sets . . . . . . . . . . . .
5.6. Metric theory for ε-Dirichlet improvable matrices . . . . . . . . . . . . . . . . . . . . . .
5.7. Weighted singular matrices and general diagonal flows . . . . . . . . . . . . . . . .
5.8. Inhomogeneous Diophantine approximation . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.9. Parametric geometry of numbers in arbitrary characteristic. . . . . . . . . . . . .
6. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18
26
27
27
27
28
28
28
29
29
29
30
30

Part 2. Proof of main theorems using the variational principle . . . . . . . . . .
Leitfaden to Part 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of (7.1) + Theorem 3.5, upper bound for packing dimension . . . . . . . . . . .
Proof of (7.2) + Theorem 3.5, first formula, lower bound for Hausdorff
dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.5, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.5, second formula, lower bound for Hausdorff dimension
Proof of Theorem 3.8, lower bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.8, upper bound when n ≥ 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.9. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.6, lower bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, lower bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.6, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, upper bound for packing dimension . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

31
31
32

7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.

35
39
42
43
47
50
53
53
54
55
56
56
64
65
65
67
68
68

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Part 3. Dimension games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27. Preliminaries on measures and dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28. A characterization of Hausdorff and packing dimensions using games . . . . . . .
29. Playing games with Diophantine targets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

70
70
71
77

Part 4. Proof of the variational principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
30. Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
31. Proof of Theorem 4.6, lower bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
31.1. Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
31.2. Mini-strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
31.3. Error correction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104
31.4. Uniform error bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .110
32. Proof of Theorem 4.6, upper bound. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .116
Part 5. Appendix and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Appendix A. Translating between Schmidt–Summerer’s notation and ours . . . . . . .122
References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123

Part 1. Introduction
1. R EADERS ’ G UIDE
The following brief guide will aid non-linear navigation across the paper. To prevent misunderstanding, the reader should first acquaint themselves with Conventions
1 through 7, which may be found at the start of Section §2. The conventions are followed by a glossary of notation (in the order of their appearance), which may be skipped
on a first reading. After the conventions one must read Section §3 (Main Results) and
Section §4 (The Variational Principle), which contain statements of all the main theorems as well as fundamental definitions that are germane to the sequel. Section §5
contains a sample of future research directions. The several theorems of Section §3 are
all consequences of a single variational principle in the parametric geometry of numbers,
which provides a unifying perspective to both old and new results in the metric theory of
Diophantine approximation. Theorem 4.6 in Section §4 is the version of this variational
principle we prove in the sequel.
At this stage, there are a few potential routes ahead. Readers keen to get directly to
the various applications in Section §3 could take the variational principle (Theorem 4.6)

4

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

for granted and move directly to Part 2 (Proofs of main theorems using the variational principle). This allows one to better familiarize themselves with how to apply the
variational principle before entering the myriad details that its intricate proof entails.
An alternate route would be to skip the proofs of the applications in Part 2, and instead
move straight to the heart of the paper, viz. our proof of the variational principle (Theorem 4.6). This proof involves reading Part 3 (Dimension games) and Part 4 (Proof of
the variational principle) in order. We note that the proof of the upper bound in Section
§32 is significantly shorter than that of the lower bound in Section §31.
Readers particularly interested in our variant of Schmidt’s game (that computes the
Hausdorff and packing dimensions of any Borel set in a doubling metric space) may
read Section §27 (Preliminaries on measures and dimensions) and Section §28 (A
characterization of Hausdorff and packing dimensions using games) (both in Part 3)
independently of all other sections in the paper.
2. C ONVENTIONS

AND

G LOSSARY

OF

N OTATION

We begin with our most important conventions, which should not be skipped and may
be especially useful for a non-linear reader.
def

Convention 1. We denote the nonnegative integers as N = {0, 1, 2, . . .}.
def

Convention 2. Where applicable, the nonzero integers m, n, and d = m + n are treated
as constant.
Convention 3. All measures and sets are assumed to be Borel, and measures are assumed
to be locally finite. Sometimes we restate these hypotheses for emphasis.
Convention 4. Given a vector space V and some index set I we use the notation
hxi ∈ V : i ∈ Ii
to mean the set generated by {xi ∈ V : i ∈ I}, or the smallest subspace containing
{xi ∈ V : i ∈ I}.
Convention 5. We use uppercase letters X, Y, . . . for matrices and bold letters x, y, . . .
for vectors.
Convention 6. In what follows, A . B means that there exists a constant C (the implied
constant) such that A ≤ CB. A ≍ B means A . B . A. Similarly, A .+ B means that
A ≤ B + C for some constant C. When we write A .β B or A .+,β B this signifies
that the implied constant depends on β. We use A ≍+ B to mean A .+ B and B .+ A.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

5

For instance, this allows us to write A ≍+ B = C ≍+ D without having to write O(1)
everywhere, which would obscure some of the information and also be more cluttered.
Convention 7. Recall that Θ(x) denotes any number such that x/C ≤ Θ(x) ≤ Cx for
some uniform constant C. Similarly, Ω(x) and O(x) denote numbers such that x/C ≤
Ω(x) and |O(x)| ≤ Cx for some uniform positive constant C, respectively.

Glossary of Notation. For the reader’s convenience we summarize a partial list of notations and terminology in the order that they appear in the sequel.
•
•
•
•
•
•
•
•
•
•

M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The space of m × n matrices with real entries
Sing(m, n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The set of singular m × n matrices

def
1
δm,n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . δm,n = mn 1 − m+n
BA(m, n) . . . . . . . . . . . . . . . . . . . . . . . . . The set of badly approximable m × n matrices
VWA(m, n) . . . . . . . . . . . . . . . . . . . . The set of very well approximable m × n matrices
dimH (S) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Hausdorff dimension of a set S
dimP (S) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The packing dimension of a set S
Ik . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The k-dimensional identity matrix
def
d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .d = m + n
λj (Λ) (1 ≤ j ≤ d) . . . . . . . . . . . . . . . . . . . . . . . . . . The jth minimum of a lattice Λ ⊆ Rd



t/m
 e Im

• gt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . For t ∈ R, gt = 
def

e−t/n In



 ∈ SLd (R)




I A 
def  m
 ∈ SLd (R)
• uA . . . . . . . . . . . . . . . . . . . . . . . . . . For an m × n matrix A, uA = 


In

• ω
b (A) . . . . . . . . . . . . . . . . The uniform exponent of irrationality of an m × n matrix A
• VSing(m, n) . . . . . . The set of very singular m × n matrices, i.e. {A : ω
b (A) > n/m}
def
−1
• τb(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . τb(A) = lim inf t→∞ t log λ1 (gt uA Zd )
• τ ................................................................... τ =
def

n
1 ω− m
n ω+1

• Singm,n (ω) . . . . . . . . . . . . . . . . . . . . . . Singm,n (ω) = {A : ω
b (A) = ω} = {A : τb(A) = τ }
• trivially singular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Section § 3.2.1
def
• Sing∗m,n (ω) . . . . . . . . . . . Sing∗m,n (ω) = {A ∈ Singm,n (ω) : A is not trivially singular}


def
• P(A) . . . . . . . . . . . . . . . P(A) = limε→0 lim inf T →∞ T1 λ t ∈ [0, T ] : λ1 (gt uA Zd ) ≤ ε
• singular on average . . . . . . . . . . . . . . . . . . . . . . . . A is singular on average if P(A) = 1

6

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

• k-singular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .See Definition 3.13
• {x} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . {x} denotes the fractional part of x ∈ R
 km  kn
def
• fm,n (k) . . . . . . . . . . . . . . . . . . . . . . . . . . . . fm,n (k) = mn − k(m+n−k)mn
− m+n
(m+n)2
m+n
def

• h, hA , hi (t) . . . . . . . . . . . h = hA = (h1 , . . . , hd ) : [0, ∞) → Rd , hi (t) = log λi (gt uA Zd )
def
• Vj,t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Vj,t = spanR{r ∈ Zd : kgt uA rk ≤ λj (gt uA Zd )}
def
• Fj,I (t) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .n. . . . . . . . . . . Fj,I (t) = log kgt uA (Vj,t ∩ Zd )k
o
def

Z(j) . . . . . . . . . . . . . . . . . . . . . . . . . . Z(j) = Lm+ − Ln− : L± ∈ [0, d± ]Z, L+ + L− = j
template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
balanced template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
partial template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
Tm,n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .The space of m × n templates
def P
Fj . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Fj = 0<i≤j fi for a map f : [0, ∞) → Rd
convexity condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Fj is convex when fj < fj+1
quantized slope condition . . . Slopes of the pieces of Fj are in Z(j) when fj < fj+1
def
def
f0 , fd+1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . f0 = − ∞ and fd+1 = + ∞
def
D(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D(f) = {A : hA ≍+ f}
def S
D(F ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D(F ) = f ∈F D(f)
L± = L± (f, I, q) . . . . . . . . . . . . . Chosen so that L+ + L− = q and Fq′ = Lm+ − Ln− on I
M± = M± (f, I, p, q) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . M± (p, q) = L± (q) − L± (p)
δ(f), δ(f) . . . . . . . . . . . . . . Lower and upper average contraction rates of a template f
def
f (t)
τb(f) . . . . . . . . . . . . . The uniform dynamical exponent of f: τb(f) = lim inf t→∞ −1
t 1
∗
∗
def
g
g
b (A) ≥ ω, A not trivially singular}
• Singm,n (ω) . . . . . . . . . . . . . . . . Singm,n (ω) = {A : ω
s
• H (A) . . . . . . . . . . . . . . . . . . . . The s-dimensional Hausdorff measure of a set A ⊆ Rd
• P s (A) . . . . . . . . . . . . . . . . . . . . . . . The s-dimensional packing measure of a set A ⊆ Rd
• dimH (A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Hausdorff dimension of a set A ⊆ Rd
• dimP (A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The packing dimension of a set A ⊆ Rd
• B(x, ρ) . . . . . . . . . . . . . . . . . . . . . . The closed ball centered at x ∈ Rd with radius ρ > 0
• N (A, ε) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The ε-neighborhood of a set A ⊆ Rd
def
• dimx (µ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . dimx (µ) = lim inf ρ→0 log µ(B(x, ρ))/ log ρ
def
• dimx (µ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . dimx (µ) = lim supρ→0 log µ(B(x, ρ)) log ρ
P
def
• δ(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .δ(A) = lim inf k→∞ k1 ki=0 − log #(Ai )/ log(β)
P
def
• δ(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . δ(A) = lim supk→∞ k1 ki=0 − log #(Ai )/ log(β)
• h(Λ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (log λ1 (Λ), . . . , log λd (Λ))
• Λ-rational . . . . . . . . . . . . . . A subspace V ⊆ Rd is Λ-rational if V ∩ Λ is a lattice in V
• Vq (Λ) . . . . . . . . . . . . . . . . . . . . . . . . . Set of all q-dimensional Λ-rational subspaces of Rd
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

•
•
•
•
•
•
•
•
•
•
•

7

kV k . . . . . . . . . . . . . . . . Covolume of V ∩ Λ in V , where Λ is understood from context
def
L . . . . . . . . . . . . . . . . . . L = {0} × Rn is the subspace of Rd contracted by the (gt ) flow
C(V, ε) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Conical ε-neighborhood of a subspace V ⊆ Rd
η-integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . see Def. 31.1
splits, mergers, transfers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.2
simple . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.2
convex hull function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.6
b-perturbation of f at t0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Lemma 31.14
G = G(d, n) . . . . . . . . . . The Grassmannian variety of n-dimensional subspaces of Rd
standard template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 9.1
s[(tk , −εk ), (tk+1, −εk+1 )] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 9.1
3. S TATEMENTS

OF

M AIN

RESULTS

The notion of singularity (in the sense of Diophantine approximation) was introduced
by Khintchine, first in 1937 in the setting of simultaneous approximation [41], and later
in 1948 in the more general setting of matrix approximation [42]. Since then this notion
has been studied within Diophantine approximation and allied fields, see Moshchevitin’s
excellent yet far from comprehensive 2010 survey [51].
Let M denote the set of all m × n matrices with real entries. A matrix A ∈ M is called
singular if for all ε > 0, there exists Qε such that for all Q ≥ Qε , there exist integer vectors
p ∈ Zm and q ∈ Zn such that
kAq + pk ≤ εQ−n/m

and

0 < kqk ≤ Q.

Here and from now on k · k is used to denote two fixed norms1, one on Rm and the other
on Rn . We denote the set of singular m × n matrices by Sing(m, n). For 1 × 1 matrices
(i.e. numbers), being singular is equivalent to being rational, and in general any matrix
A which satisfies an equation of the form Aq = p, with p, q integral and q nonzero,
is singular. However, Khintchine proved that there exist singular 2 × 1 matrices whose
entries are linearly independent over Q [40, Satz II]2, and his argument generalizes to
the setting of m × n matrices for all (m, n) 6= (1, 1). The name singular derives from the
fact that Sing(m, n) is a Lebesgue nullset for all m, n, see e.g. [41, p.431] or [13, Chapter
1

Note that many definitions, such as the one above, and all our main theorems, are insensitive to the choice
of these norms. In some cases, e.g. in the course of a proof, we specify a particular norm for computational
convenience.
2
Although Khintchine’s seminal 1926 paper [40] includes a proof of the existence of 2×1 and 1×2 matrices
possessing a certain property which clearly implies that they are singular, it does not include a definition
of singularity nor discuss any property equivalent to singularity.

8

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

5, §7]. Note that singularity is a strengthening of the property of Dirichlet improvability
introduced by Davenport and Schmidt [22].
In contrast to the measure zero result mentioned above, the computation of the Hausdorff dimension of Sing(m, n) has been a challenge that so far only met with partial
progress. The first breakthrough was made in 2011 by Cheung [16], who proved that
the Hausdorff dimension of Sing(2, 1) is 4/3; this was extended in 2016 by Cheung and
Chevallier [17], who proved that the Hausdorff dimension of Sing(m, 1) is m2 /(m + 1) for
all m ≥ 2; while most recently Kadyrov, Kleinbock, Lindenstrauss, and Margulis (KKLM)

def
1
,
[38] proved that the Hausdorff dimension of Sing(m, n) is at most δm,n = mn 1 − m+n
and went on to conjecture that their upper bound is sharp for all (m, n) 6= (1, 1) (see also
[11, Problem 1]).
Cheung and Chevallier’s result for singular vectors was an equality and they needed to
develop separate tools to deal with upper and lower bounds. They developed the notion
of best approximation vectors and a multidimensional extension of Legendre’s theorem
on convergents of real continued fraction expansions, as well as the notion of self-similar
coverings that construct Cantor sets with “inhomogeneous” tree structures. On the other
hand, though KKLM were only able to prove an upper bound rather than an equality,
their methods, which were orthogonal to those of Cheung and Chevallier, leveraged the
technology of integral inequalities developed by Eskin, Margulis and Mozes [26] and
extend Cheung and Chevallier’s upper bound to the matrix framework.
Completely independent of the aforementioned results and techniques, we prove (as
announced in [21]) that KKLM’s conjecture is correct, and further that the packing dimension of Sing(m, n) is the same as its Hausdorff dimension, thus answering a question
of Bugeaud, Cheung, and Chevallier [11, Problem 7]. To summarize:

Theorem 3.1. For all (m, n) 6= (1, 1), we have
def

dimH (Sing(m, n)) = dimP (Sing(m, n)) = δm,n = mn 1 −

1
m+n


,

where dimH (S) and dimP (S) denote the Hausdorff and packing dimensions of a set S, respectively.

3.1. Dani correspondence. The set of singular matrices is linked to homogeneous dynamics via the Dani correspondence principle [19, 44]. For each t ∈ R and for each matrix

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

A ∈ M, let



t/m

e
def 
gt = 




Im
e−t/n In


,




9



I
A 
def  m
,
uA = 


In
def

where Ik denotes the k-dimensional identity matrix. Finally, let d = m + n, and for each
j = 1, . . . , d, let λj (Λ) denote the jth minimum of a lattice Λ ⊆ Rd , i.e. the infimum of
λ such that the set {r ∈ Λ : krk ≤ λ} contains j linearly independent vectors. Then the
Dani correspondence principle is a dictionary between the Diophantine properties of a
matrix A on the one hand, and the dynamical properties of the orbit (gt uA Zd )t≥0 on the
other.
Recall that an m×n matrix A is called badly approximable if there exists c > 0 such that
n
for all integer vectors p ∈ Zm and q ∈ Zn \ {0} we have kAq+ pk ≥ ckqk− m ; and is called
very well approximable if there exist ε > 0 and infinitely many integer vectors p ∈ Zm and
n
q ∈ Zn \ {0} such that kAq + pk ≤ kqk−( m +ε) . Such classes have been intensively studied
within the field of metric Diophantine approximation [5, 10, 24].
Diophantine properties of A Dynamical properties of (gt uA x0 )t≥0
A is badly approximable

(gt uA x0 )t≥0 is bounded

A is singular

(gt uA x0 )t≥0 is divergent

A is very well approximable

lim supt→∞ 1t d(x0 , gt uA x0 ) > 0

We denote the sets of badly approximable, singular, and very well approximable matrices by BA(m, n), Sing(m, n), and VWA(m, n), respectively. Using the Dani correspondence principle, the fact that they are all Lebesgue null sets can now be seen to follow
from the ergodicity of the (gt)-action (see [3, Corollary 2.2 in Chapter III]). Indeed, in
each case it suffices to show that any trajectory that equidistributes is not in the respective set. An equidistributed trajectory is not bounded because the orbit must be dense,
proving that BA(m, n) is Lebesgue null. An equidistributed trajectory is not divergent
because that would imply escape of mass, proving that Sing(m, n) is Lebesgue null. Finally, an equidistributed trajectory does not escape to infinity at a linear rate because this
would imply that it spends a proportionally long time near infinity infinitely often, which
would imply escape of mass (along a subsequence); thereby proving that VWA(m, n) is
Lebesgue null.

10

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

It follows from the Dani correspondence principle that Theorem 3.1 implies that the
set of divergent trajectories of the one-parameter diagonal (gt )-action (on the space of
unimodular lattices that has exactly two Lyapunov exponents with opposite signs) has
equal Hausdorff and packing dimensions. In the sequel, we focus on Diophantine statements and leave it to the interested reader to translate our results in the language of
homogeneous dynamics.
Let us precisely state the result mentioned in the middle row of the table above as it is
particularly germane to our theme.
Theorem 3.2 ([19, Theorem 2.14]). A matrix A ∈ M is singular if and only if the trajectory (gt uA Zd )t≥0 is divergent in the space of unimodular lattices in Rd , or equivalently (via
Mahler’s compactness criterion [25, Theorem 11.33]) if
lim λ1 (gt uA Zd ) = 0.

t→∞

It is natural to ask about the set of matrices such that the above limit occurs at a
prescribed rate, such as the set of matrices such that − log λ1 (gt uA Zd ) grows linearly with
respect to t. This question is closely linked with the concept of uniform exponents of
irrationality. The uniform exponent of irrationality of an m × n matrix A, denoted ω
b (A),
is the supremum of ω such that for all Q sufficiently large, there exist integer vectors
p ∈ Zm and q ∈ Zn such that
kAq + pk ≤ Q−ω and 0 < kqk ≤ Q.
By Dirichlet’s theorem ([23] or [59, Theorem 1E in §II]), every m × n matrix A satisfies
n
ω
b (A) ≥ m
. Moreover, it is immediate from the definitions that any matrix A satisfying
n
b (A) >
ω
b (A) > m is singular. We call a matrix very singular if it satisfies the inequality ω
n
, in analogy with the set of very well approximable matrices, which satisfy a similar
m
inequality for the regular (non-uniform) exponent of irrationality. We denote the set of
very singular m×n matrices by VSing(m, n). The relationship between uniform exponents
of irrationality and very singular matrices on the one hand, and homogeneous dynamics
on the other, is given as follows:
Theorem 3.3. A matrix A is very singular if and only if τb(A) > 0, where

−1
log λ1 (gt uA Zd ).
t→∞
t
Moreover, the quantities τ = τb(A) and ω = ω
b (A) are related by the formula
def

τb(A) = lim inf

(3.1)

n
1ω− m
·
τ=
n ω+1

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

11

This theorem is a straightforward example of the Dani correspondence principle and is
probably well-known, but we have not been able to find a reference.
Proof. The first assertion follows from (3.1), so it suffices to prove (3.1). Let ω = ω
b (A),
and let τ be given by (3.1); then we need to prove that τb(A) = τ . We prove the ≥
direction; the ≤ direction is similar. Fix ε > 0 and t ≥ 0, and let Q = e(1/n−τ )t . By
the definition of ω, if t (and thus Q) is sufficiently large then there exist p, q such that
kAq + pk ≤ Q−ω+ε and 0 < kqk ≤ Q. Now let
r = gt uA (p, q) = (et/m (Aq + p), e−t/n q).
Then
λ1 (gt uA Zd ) ≤ krk ≍ max(et/m kAq + pk, e−t/n kqk)
≤ max(et/m Q−ω+ε , e−t/n Q)

= max(et/m e(1/n−τ )(−ω+ε) , e−τ t )

= exp −t min τ, n1 − τ (ω − ε) −

Since t was arbitrary, it follows that

1
m




−1
log λ1 (gt uA Zd ) ≥ min τ, n1 − τ (ω − ε) −
t→∞
t
Taking the limit as ε → 0 we get


τb(A) ≥ min τ, n1 − τ ω − m1 = min(τ, τ ) = τ.
τb(A) = lim inf

.

1
m



.



3.2. Dimensions of very singular matrices. Perhaps unsurprisingly, the set of very singular matrices has the same dimension properties as the set of singular matrices.
Theorem 3.4. For all (m, n) 6= (1, 1), we have
dimH (VSing(m, n)) = dimP (VSing(m, n)) = δm,n .

One can also ask for more precise results regarding the function ω
b . Specifically, for
3
n
each ω > m we can consider the levelset
(3.2)

def

def

Singm,n (ω) = {A : ω
b (A) = ω} = {A : τb(A) = τ } = Singm,n (τ ),

where τ is given by (3.1). Elements of the set above are called ω-singular or τ -singular.
It would be desirable to obtain precise formulas for the Hausdorff and packing dimensions of Singm,n (ω) in terms of ω, m, and n, see e.g. [11, Problem 2]. However, this
appears to be extremely challenging at the present juncture. We have made significant
3

For results considering the superlevelset, see Theorem 4.9.

12

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

progress towards this question: solving it completely in the cases (m, n) = (1, 2) and
(m, n) = (2, 1), and for packing dimension in the case where n ≥ 2. See Theorems 3.8
and 3.10 for details.
In general, we have obtained asymptotic formulas of two types: estimates valid when
ω is small and estimates valid when ω is large. Note that while the minimum value of ω
b
n
is always m (corresponding to τb = 0), the maximum value depends on whether or not n
is at least 2. If n ≥ 2, then the maximum value of ω
b is ∞ (corresponding to τb = n1 ), while
if n = 1, then the maximum value of ω
b (excluding rational points) is 1 (corresponding to
m−1 4
τb = 2m ). Consequently, we have two different asymptotic estimates of the dimensions
of Singm,n (ω) when ω is large corresponding to these two cases. In all of the formulas
below, τ is related to ω by the formula (3.1).
Theorem 3.5. Suppose that (m, n) 6= (1, 1). Then for all ω >
have
q
ω−
√ 
= δm,n − Θ τ

dimH (Singm,n (ω)) = δm,n − Θ

n
m



n
m

sufficiently close to

n
,
m

we


dimP (Singm,n (ω)) = δm,n − Θ ω −

n
m




dimP (Singm,n (ω)) = δm,n − Θ ω −

n
m



= δm,n − Θ (τ )

unless (m, n) = (2, 2), in which case


dimH (Singm,n (ω)) = δm,n − Θ ω −

n
m

= δm,n − Θ (τ )



= δm,n − Θ (τ ) .

In the sequel, we refer to the dimension formulas in the case (m, n) ∈
/ {(1, 1), (2, 2)} as “the
first case of Theorem 3.5”, and to the dimension formulas in the case (m, n) = (2, 2) as “the
second case of Theorem 3.5”.
Theorem 3.6. Suppose that n ≥ 2. Then for all ω < ∞ sufficiently large, we have
dimH (Singm,n (ω)) = mn − 2m + Θ
= mn − 2m + Θ

1
ω
1
n



−τ



dimP (Singm,n (ω)) = mn − m.

Theorem 3.7. Suppose that n = 1 and m ≥ 2. Then for all ω < 1 sufficiently close to 1, we
have
4

The reason for this is that if n = 1, then for trivial reasons the value of ω
b at a point x ∈ Rm is at most the
minimum value of ω
b over the coordinates x1 , . . . , xm , and if x is irrational, then for some i = 1, . . . , m, xi
is irrational and therefore (since we are in one dimension) satisfies ω
b (xi ) = 1.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

dimH (Singm,n (ω)) = Θ (1 − ω)


= Θ m−1
−
τ
2m

13

dimP (Singm,n (ω)) = 1.

Beyond the results above, we have a precise formula for the packing dimension when
n ≥ 2, which remains a lower bound when n = 1.
Theorem 3.8. Define the function
mn
mn 1 + mτ
def
δ m,n (τ ) = max mn − m, δm,n −
(d + m)τ, mn −
mn
τ
m+n
m + n 1 − m−1

!

·

Then we have
dimP (Singm,n (τ )) ≥ δ m,n (τ ),

(3.3)

with the understanding that the last piece of δ m,n (τ ) is ignored if m = 1. If n ≥ 2, then
equality holds in (3.3).
Remark. The cases of the maximum correspond to τ ∈ [τ2 , n1 ], τ ∈ [τ1 , τ2 ], and τ ∈ [0, τ1 ],
m
m2 −d
and τ2 = n(m+d)
. Note that τ1 > 0 if and only if m2 > d.
respectively, where τ1 = mn(d+m)
When τ1 ≤ 0, then the second case of the maximum holds for all τ ∈ [0, τ2 ].
When n = 1, the inequality (3.3) is strict for some values of τ , as shown by the following theorem:
Theorem 3.9. We have
dimP (Singm,1 (τ )) ≥ 1

for all 0 < τ ≤

dimP (Singm,1 (τ )) ≥ m − 1

for all 0 < τ ≤

m−1
,
2m

and

1
.
m2

Remark. To see that Theorem 3.9 implies that the inequality (3.3) in Theorem 3.8 is
strict for some values of τ , note that δ m,1 ( m−1
) = 12 < 1. For m ≥ 3, we have
2m
 
1
1
=m−1− 2
< m − 1.
δ m,1
2
m
m −m−1
When m = 2, we instead have

 

1
1
m−1
=
=
< 1 = m − 1.
δ m,1
δ
m,1
m2
2m
2
3.2.1. Trivially singular matrices. Call a matrix A trivially singular if there exists j =
1, . . . , d − 1 such that
log λj+1(gt uA Zd ) − log λj (gt uA Zd ) → ∞ as t → ∞.

14

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Then all of the formulas above in Theorems 3.5-3.9 remain true if Singm,n (ω) is replaced
by the set
def
Sing∗m,n (ω) = {A ∈ Singm,n (ω) : A is not trivially singular}.
Similarly, the formulas in Theorems 3.1 and 3.4 above and in Theorems 3.10-3.14 below
remain true if we restrict to the respective sets of matrices that are not trivially singular. The reason for this is since while proving lower bounds none of the templates (see
Definition 4.1) we construct are trivially singular.
Moreover, for n ≥ 2 we have
dimH (Sing∗m,n (∞)) = mn − 2m

dimP (Sing∗m,n (∞)) = mn − m

and for n = 1, m ≥ 2 we have
dimH (Sing∗m,n (1)) = 0

dimP (Sing∗m,n (1)) = 1.

Note that the class of trivially singular matrices is smaller than the class of matrices
with degenerate trajectories in the sense of [19, Definition 2.8], but larger than the class
considered in [11, p.2] consisting of matrices A such that the group AZn + Zm does not
have full rank. A d × 1 or 1 × d matrix is trivially singular if and only if it is contained in
a rational hyperplane of Rd .

3.3. 1 × 2 and 2 × 1 matrices. Beyond our asympototic formulas stated in the previous section, we obtain precise formulas for the Hausdorff and packing dimensions of
Singm,n (ω) for the cases (m, n) = (1, 2) and (m, n) = (2, 1). Our dimension formulas complete a cornucopia of bounds due to Baker, Bugeaud–Laurent, Laurent, Dodson, Yavid,
Rynne, and Bugeaud–Cheung–Chevallier (1977–2016). We refer to [11] for a detailed
history of the prior results.
Theorem 3.10. For all ω ∈ (2, ∞) (corresponding to τ ∈ (0, 1/2)) we have

 4 − 4 √τ − 6τ 3 + 4τ 4 − 2τ + 8 τ 2 if τ ≤ τ def
0 =
3
dimH (Sing1,2 (ω)) = 3 3
 1−2τ
if τ ≥ τ0
1+τ

1
 4−8τ if τ ≤ τ def
1 = 8
3
dimP (Sing1,2 (ω)) =
1
if τ ≥ τ1

(cf. Figure 1).

√
3 2−2
14

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

15

(0, 34 )
( 81 , 1)

1

f1 (τ ) = dimP (Sing1,2 (ω))
√

(3

0.5

2−2
,2
14

−

√

2)

f2 (τ ) = dimH (Sing1,2 (ω))

0

0

0.1

0.2

0.3

0.4

0.5

F IGURE 1. Graphs of the dimension functions
def

def

f1 (τ ) = dimP (Sing1,2 (ω)) and f2 (τ ) = dimH (Sing1,2 (ω)).
The packing dimension function f1 is linear on the intervals [0, 1/8] and
[1/8, 1/2], while the Hausdorff dimension function
f2 is real-analytic on the
√
intervals [0, τ0 ] and [τ0 , 1/2], where τ0 = (3 2 − 2)/14 ∼ 0.1602.
Remark. There had been a lot of partial progress towards the Hausdorff dimension part
of Theorem 3.10. In particular, the ≥ direction follows from [11, Corollary 2 and Theorem 3]. For τ ≥ τ0 the upper bound follows from [11, Corollary 2] and for τ < τ0 , a
non-optimal upper bound is given in [11, Theorem 1].

Remark. By Jarnı́k’s identity [37] (see also [31, Theorem A]), for all ω ∈ [2, ∞) we have
Sing1,2 (ω) = Sing2,1 (ω ′ )
where ω ′ = 1 −

1
ω

, and
Sing1,2 (∞) = Sing2,1 (1) ∪ Sing2,1 (∞).

Thus by applying an appropriate substitution to the above formulas and using the fact
that Sing2,1 (∞) is countable (it is the set of rational points), it is possible to get explicit
formulas for dimH (Sing2,1 (ω ′ )) and dimP (Sing2,1 (ω ′)), either in terms of ω ′ or in terms of
ω ′ − 21
τ
=
·
τ = ′
ω +1
1 + 2τ
′

16

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

However, the resulting formulas are not very elegant so we omit them.
√
Remark. The transition point τ0 = (3 2 − 2)/14 in the above formula for Hausdorff
dimension corresponds to
√
√
√
√
ω0 = 2 + 2 , ω0′ = 2/2 , τ0′ = (4 − 3 2)/2 , and dimH (Sing1,2 (ω0 )) = 2 − 2.
The transition point τ1 = 1/8 for packing dimension corresponds to
ω1 = 3 , ω1′ = 2/3 , τ1′ = 1/10 , and dimP (Sing1,2 (ω1 )) = 1.
Remark. Theorem 3.10 implies that dimH (Sing1,2 (ω)) < dimP (Sing1,2 (ω)) for all ω ∈
(2, ∞). This answers the first part of [11, Problem 7] in the affirmative.
3.4. Singularity on average. A different way of quantifying the notion of singularity is
the notion of singularity on average introduced in [38]. Given a matrix A, we define the
proportion of time spent near infinity to be the number

1 
def
P(A) = lim lim inf λ t ∈ [0, T ] : λ1 (gt uA Zd ) ≤ ε ∈ [0, 1],
ε→0 T →∞ T
where λ denotes Lebesgue measure. The matrix A is said to be singular on average if
P(A) = 1. Clearly, every singular matrix is singular on average.
Theorem 3.11. For all p ∈ [0, 1], we have
dimH ({A : P(A) = p}) = dimP ({A : P(A) = p}) = pδm,n + (1 − p)mn.
In particular, the dimension of the set of matrices singular on average is δm,n .
Note that the Hausdorff dimension part of this theorem proves the conjecture stated in
[38, Remark 2.1], where the upper bound was proven. However, we give an independent
proof of the upper bound. Also note that when p = 1, the lower bound for Hausdorff
dimension follows from Theorem 3.1.
3.5. Starkov’s conjecture. In [63, p.213], Starkov asked whether there exists a singular
vector (i.e. m × 1 singular matrix) which is not very well approximable. Here, we recall
n
, there exist infinitely
that a matrix A is called very well approximable if for some ω > m
many pairs (p, q) ∈ Zm × Zn such that
(3.4)

kAq + pk ≤ kqk−ω ,

or equivalently in terms of the Dani correspondence principle, a matrix A is very well
approximable if lim supt→∞ − 1t log λ1 (gt uA Zd ) > 0. This question was answered affirmatively by Cheung [16, Theorem 1.4] in the case m = 2. In fact, Cheung showed that if

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

17

ψ is any function such that q 1/2 ψ(q) → 0 as q → ∞, then there exists a 2 × 1 singular
vector which is not ψ-approximable. Here, a matrix A is called ψ-approximable if there
exist infinitely many pairs (p, q) ∈ Zm × Zn such that q 6= 0 and
kAq + pk ≤ ψ(kqk).
The following theorem improves on Cheung’s result both by generalizing it to the case of
arbitrary m, n (i.e. to the matrix approximation framework), and also by computing the
dimension of the set of matrices with the given property:
Theorem 3.12. If ψ is any function such that q n/m ψ(q) → 0 as q → ∞, then the set of m×n
singular matrices that are not ψ-approximable has Hausdorff dimension δm,n . Equivalently,
if φ is any function such that φ(t) → ∞ as t → ∞, then the set of m × n singular matrices A
such that − log λ1 (gt uA Zd ) ≤ φ(t) for all t sufficiently large has Hausdorff dimension δm,n .
The same is true for the packing dimension.
Note that this theorem is optimal in the sense that if ψ(q) ≥ cq −n/m for some constant
c, then it is easy to check that every singular m × n matrix is ψ-approximable.
3.6. Schmidt’s conjecture. In [60, p.273], Schmidt conjectured that for all 2 ≤ k ≤ m,
there exists an m × 1 matrix A such that
(3.5)

λk−1 (gt uA Zd ) → 0 and λk+1(gt uA Zd ) → ∞ as t → ∞.

This conjecture was proven by Moshchevitin [52], who constructed an m × 1 matrix A
satisfying (3.5) and not contained in any rational hyperplane5 (see also [39, 56]). To
extend this discussion to the matrix framework, we make the following definition.
Definition 3.13. An m × n matrix A is k-singular for 2 ≤ k ≤ m + n − 1 if
(3.6)

λk−1 (gt uA Zd ) → 0 and λk+1(gt uA Zd ) → ∞ as t → ∞.

(Note that any matrix satisfying (3.6) is singular by Theorem 3.2.)
We improve Moshchevitin’s result by computing a lower bound on the Hausdorff dimension of the set of matrices witnessing Schmidt’s conjecture in the matrix framework:
5

As observed by Moshchevitin [52, Corollary 2], proving Schmidt’s conjecture by constructing an m × 1
matrix A satisfying (3.5) which is contained in a rational hyperplane is actually trivial: let A = (x, 0)
where x ∈ Rk−1 or x ∈ Rk−2 is a badly approximable vector. We assume that if Schmidt had noticed this
example, he would have included in his conjecture the requirement that A should not be contained in a
rational hyperplane.

18

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Theorem 3.14. For all (m, n) 6= (1, 1) and for all 2 ≤ k ≤ m + n − 1, the Hausdorff
dimension of the set of matrices A that satisfy (3.6) is at least
max(fm,n (k), fm,n (k − 1))
where
(3.7)

k(m + n − k)mn
fm,n (k) = mn −
−
(m + n)2
def



km
m+n



kn
m+n



·

Here {x} denotes the fractional part of a real number x. The same formula is valid for the
set of matrices A that satisfy (3.6) and are not trivially singular.
Remark. The function fm,n satisfies fm,n (m + n−k) = fm,n (k) and fm,n (1) = fm,n (m + n−
1) = δm,n . Moreover, for all 1 ≤ k ≤ m + n − 1 we have fm,n (k) ≤ δm,n . It follows that
when k = 2 or m + n − 1, the Hausdorff and packing dimensions of the set of matrices A
that satisfy (3.6) are both equal to δm,n .
Remark. When m = 1 or n = 1, the fractional parts appearing in (3.7) can be computed
explicitly, leading to the formula
fm,n (k) = mn −

k(m + n − k)
·
m+n

However, this formula is not valid when m, n ≥ 2.
We conjecture that the lower bound in Theorem 3.14 is optimal for both the Hausdorff
and packing dimensions (see Conjecture 5.1 below).
4. T HE

VARIATIONAL PRINCIPLE

4.1. Successive minima functions and templates. All the theorems in the previous
section (with the exception of Theorems 3.2 and 3.3) are consequences of a single variational principle in the parametric geometry of numbers. This variational principle is a
quantitative analogue of theorems due to Schmidt and Summerer [61, §2] and Roy [53,
Theorem 1.3]. However, we will state their results in language somewhat different from
the language used in their papers, due to the fact that the fundamental object we consider is the one-parameter family of unimodular lattices (gt uA Zd )t≥0 used by the Dani
correspondence principle, rather than a one-parameter family of (non-unimodular) convex bodies as is done in [61, 53]. We leave it to the reader to verify that the theorems
we attribute below to [61] and [53] are indeed faithful translations of their results to our
setting.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

19

The fundamental question of our version of the parametric geometry of numbers will be
as follows: given a matrix A, what does the function h = hA = (h1 , . . . , hd ) : [0, ∞) → Rd
defined by the formula
def

hi (t) = log λi (gt uA Zd )

(4.1)

look like? The function hA will be called the successive minima function of the matrix A.
The Dani correspondence principle shows that many interesting Diophantine questions
about the matrix A are equivalent to questions about its successive minima function.
Thus the dictionary in §3.1 may be translated as follows.
Diophantine properties of A Asymptotic properties of hA,1
A is badly approximable

lim sup −hA,1 (t) < ∞
t→∞

A is singular
A is very well approximable

lim inf −hA,1 (t) = ∞
t→∞

lim sup
t→∞

−hA,1 (t)
>0
t

The main restriction on the successive minima function comes from an application of
Minkowski’s second theorem on successive minima (see Theorem 30.1 below) to certain
subgroups of the lattice gt uA Zd . Specifically, fix j = 1, . . . , d − 1 and let I be an interval
such that hj (t) < hj+1 (t) for all t ∈ I. For each t ∈ I, let6
def

Vj,t = hr ∈ Zd : kgt uA rk ≤ λj (gt uA Zd )i ⊆ Rd .
Then the map t 7→ Vj,t is continuous, and therefore constant, on I. By Minkowski’s second
theorem (Theorem 30.1), we have
X
def
hi (t) ≍+ Fj,I (t) = log kgt uA (Vj,t ∩ Zd )k,
i≤j

where kΓk denotes the covolume of a discrete group Γ ⊆ Rd (relative to its linear span).
Now an argument based on the exterior product formula for covolume and the definition
of gt (see Lemma 31.8) shows that Fj,I ≍+ Gj,I for some convex, piecewise linear function
Gj,I whose slopes are in the set
o
n
def
(4.2)
Z(j) = Lm+ − Ln− : L± ∈ [0, d± ]Z, L+ + L− = j ,
6

Here, Vj,t is the smallest subspace containing {r ∈ Zd : kgt uA rk ≤ λj (gt uA Zd )}. See Convention 4.

20

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

where for convenience we write
def

d+ = m,

def

def

[a, b]Z = [a, b] ∩ Z.

d− = n,

This suggests that h can be approximated by a piecewise linear function f such that
P
whenever fj < fj+1 on an interval I, the function Fj := i≤j fi is convex and piecewise
linear on I with slopes in Z(j). Moreover, it is obvious that h1 ≤ · · · ≤ hd , and the
formula for gt implies that for all i, we have − n1 ≤ h′i ≤ m1 wherever hi is differentiable.
We therefore make the following definition:
Definition 4.1. An m × n template is a piecewise linear7 map f : [0, ∞) → Rd with the
following properties:
(I) f1 ≤ · · · ≤ fd .
(II) − n1 ≤ fi′ ≤ m1 for all i.
(III) For all j = 0, . . . , d and for every interval I such that fj < fj+1 on I, the function
X
def
Fj =
fi
0<i≤j

is convex and piecewise linear on I with slopes in Z(j). Here we use the convention that f0 = −∞ and fd+1 = +∞. We will call the assertion that Fj is convex
the convexity condition, and the assertion that its slopes are in Z(j) the quantized
slope condition.
When m = 1, templates are a slight generalization of reparameterized versions of the
rigid systems of [53]. We denote the space of m × n templates by Tm,n .
A template f will be called balanced if Fd = f1 + . . . + fd = 0. Note that every template
is equal to a constant plus a balanced template, since by condition (III), Fd is piecewise
linear with slopes in Z(d) = {0}, and thus constant. So for most purposes the distinction
between balanced and unbalanced templates is irrelevant, but in some places it will make
a difference. A partial template is a piecewise linear map f satisfying (I)-(III) whose
domain is a closed, possibly infinite, subinterval of [0, ∞). An example of a (partial)
template is shown in Figure 2.
The fundamental relation between templates and successive minima functions is given
as follows:
Theorem 4.2.

7

(i) For every m × n matrix A, there exists an m × n template f such that hA ≍+ f.
(ii) For every m × n template f, there exists an m × n matrix A such that hA ≍+ f.
In this paper, piecewise linear functions are assumed to be continuous.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

21

F IGURE 2. The joint graph of a 1 × 2 partial template f = (f1 , f2 , f3 ), where
the joint graph of a template is the union of the graphs of its component
functions.

In the case m = 1, Theorem 4.2 follows from [53, Theorem 1.3] (cf. [54, Corollary
4.7] for part (ii)).
Theorem 4.2(ii) asserts that for every template f, the set
def

D(f) = {A : hA ≍+ f}
is nonempty. It is natural to ask how big this set is in terms of Hausdorff and packing
dimension. Moreover, given a collection of templates F , we can ask the same question
about the set
[
def
D(F ) =
D(f).
f ∈F

It turns out to be easier to answer the second question than the first, assuming that the
collection of templates F is closed under finite perturbations. Here, F is said to be closed
under finite perturbations if whenever g ≍+ f ∈ F , we have g ∈ F .
Theorem 4.3 (Variational principle, version 1). Let F be a (Borel) collection of templates
closed under finite perturbations. Then

(4.3)

dimH (D(F )) = sup δ(f),
f ∈F

dimP (D(F )) = sup δ(f),
f ∈F

where the functions δ, δ : Tm,n → [0, mn] are as in Definition 4.5 below.

22

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Corollary 4.4. With F as above, we have
(4.4)

dimH (D(F )) = sup dimH (D(f)),

dimP (D(F )) = sup dimP (D(f)).

f ∈F

f ∈F

However, note that Theorem 4.3 does not imply that dimH (D(f)) = δ(f) for an individual template f, since the family {f} is not closed under finite perturbations. And indeed,
since the function δ is sensitive to finite perturbations, the formula dimH (D(f)) = δ(f)
cannot hold for all f ∈ Tm,n .
Definition 4.5. We define the lower and upper average contraction rate of a template f
as follows. Let I be an open interval on which f is linear. For each q = 1, . . . , d such that
fq < fq+1 on I, let L± = L± (f, I, q) ∈ [0, d± ]Z be chosen to satisfy L+ + L− = q and
(4.5)

Fq′

=

q
X

fi′ =

i=1

L+ L−
−
on I,
m
n

as guaranteed by (III) of Definition 4.1. An interval of equality for f on I is an interval
(p, q]Z, where 0 ≤ p < q ≤ d satisfy
(4.6)

fp < fp+1 = · · · = fq < fq+1 on I.

As before, we use the convention that f0 = −∞ and fd+1 = +∞. Note that the collection
of intervals of equality forms a partition of [1, d]Z. If (p, q]Z is an interval of equality for f
on I, then we let M± (p, q) = M± (f, I, p, q), where
(4.7)

M± (f, I, p, q) = L± (f, I, q) − L± (f, I, p),

or equivalently, M± (p, q) are the unique integers such that
M+ + M− = q − p and

q
X

fi′ =

i=p+1

M+ M−
−
on I.
m
n

Note that we have M± ≥ 0 by (II) of Definition 4.1.8 Next, let
[

(4.8)
p, p + M+ (p, q) Z
S+ = S+ (f, I) =
(p,q]Z

(4.9)

8

Indeed, we have

S− = S− (f, I) =

[

p + M+ (p, q), q

(p,q]Z

q
X
q−p
q−p
m+n
fi′ ≥ −
M+ −
=
mn
n
n
i=p+1

on I, and thus M+ ≥ 0, and similarly M− ≥ 0.



Z

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

23

where the unions are taken over all intervals of equality for f on I. Note that S+ and S−
are disjoint and satisfy S+ ∪ S− = [1, d]Z, and that #(S+ ) = m and #(S− ) = n. Next, let
(4.10)

δ(f, I) = #{(i+ , i− ) ∈ S+ × S− : i+ < i− } ∈ [0, mn]Z,

and note that
(4.11)

mn − δ(f, I) = #{(i+ , i− ) ∈ S+ × S− : i+ > i− }.

The lower and upper average contraction rates of f are the numbers
(4.12)

def

def

δ(f) = lim inf ∆(f, T ),

δ(f) = lim sup ∆(f, T ),

T →∞

T →∞

where

ˆ
1 T
∆(f, T ) =
δ(f, t) dt.
T 0
Here we abuse notation by writing δ(f, t) = δ(f, I) for all t ∈ I. We will also have occasion
later to use the notations
ˆ T2
1
δ(f, t) dt
∆(f, [T1 , T2 ]) =
T2 − T1 T1
def

and
(4.13)

δ(T+ , T− ) = #{(i+ , i− ) ∈ T+ × T− : i+ < i− } ∈ [0, mn]Z.

Note that according to (4.13), δ(f, I) = δ(S+ , S− ).
Definition 4.5 can be understood intuitively in terms of a simple version of one-dimensional
physics with sticky collisions and conservation of momentum; cf. Figure 3. Suppose that
we observe particles P1 , . . . , Pd travelling along trajectories f1 , . . . , fd during a time interval I along which f is linear, and we want to infer the velocities of these particles before
they collided, based on the following background information: before the collision m of
the particles were travelling upwards at a speed of m1 , and n of the particles were travelling downwards at a speed of n1 . When particles collide (that is, when the velocities of the
particles of lower index are more upwards than the velocities of the particles of higher
index at the same location), they join forces to move as a unit, and their new velocity
is determined by conservation of momentum. However, we can still think of the group
as being composed of a certain number of “upwards” particles and a certain number of
“downwards” particles.
The equations (4.8) and (4.9) can be understood as suggesting a particular solution to
this problem of inference: assume that within each group, all of the upwards-travelling
particles started out below all of the downwards-travelling particles. This is not the only

24

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

↓ ↓
↑
l
↓

↑

↓
↓

1

1

0

1

2

2

F IGURE 3. The joint graph in Figure 2, with an illustration of the sets
S± (f, I) and the contraction rates δ(f, I) for each interval of linearity I.
The “one-dimensional physics” interpretation of templates can be seen in
this picture as follows: first one particle is going up while two are going
down; then the top two collide into each other and their new velocity is determined by conservation of momentum; then they split apart again. Given
this interpretation of the motion occurring in I as being the result of “collisions” between m particles going up and n particles going down, δ(f, I)
counts the number of particle pairs that are “moving towards” each other
(including particles “colliding” with each other).
possible solution but it is the nicest one for certain purposes. Specifically, we can imagine
a force of “gravity” attempting to bring all of the particles together, which acts between
any two particles by imposing a fixed energy cost if the two particles are travelling away
from each other.9 The total energy cost is then the codimension mn − δ(f, I) defined by
(4.11). The equations (4.8) and (4.9) can then be thought of as giving the solution that
minimizes this cost.
The idea of codimension as an energy cost is also useful for computing the suprema
(4.3) in certain circumstances, since it suggests principles like the conservation of energy.
However, one needs to be careful since the stickiness of collisions means that some naive
formulations of conservation of energy are violated.
In most cases of interest, the collection F in Theorem 4.3 is defined by some Diophantine condition. In this case, generally rather than D(F ) the set we are really interested
9

This is of course unlike real gravity, which imposes an energy cost that varies with respect to distance.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

25

in is the set of all matrices whose corresponding successive minima functions satisfy the
same Diophantine condition. Although these two sets are a priori different, Theorem
4.2(i) implies that they are the same and thus Theorem 4.3 is equivalent modulo Theorem 4.2(i) to the following:
Theorem 4.6 (Variational principle, version 2). Let S be a (Borel) collection of functions
from [0, ∞) to Rd which is closed under finite perturbations, and let
def

D(S) = {A : hA ∈ S}.

(4.14)
Then
(4.15)

dimH (D(S)) =

sup

δ(f),

f ∈S∩Tm,n

dimP (D(S)) =

sup

δ(f)

f ∈S∩Tm,n

with the understanding that dimH () = dimP () = sup() = −∞ (or 0 if desired).
In fact, Theorem 4.6 will be the version of the variational principle that we prove.
Proof of equivalence. Theorem 4.6 implies Theorem 4.3 since we can take S = {g : g ≍+
f ∈ F }. Conversely, Theorem 4.3 implies Theorem 4.6 modulo Theorem 4.2(i) since we
can take F = S ∩ Tm,n .

Theorem 4.6 can be thought of as a quantitative strengthening of Theorem 4.2, as
shown by the following equivalent formulation:
Theorem 4.7 (Variational principle, version 3).
(i) Let S be a (Borel) set of m × n matrices of Hausdorff (resp. packing) dimension > δ.
Then there exist a matrix A ∈ S and a template f ≍+ hA whose lower (resp. upper)
average contraction rate is > δ.
(ii) Let f be a template whose lower (resp. upper) average contraction rate is > δ. Then
there exists a (Borel) set S of m × n matrices of Hausdorff (resp. packing) dimension
> δ, such that hA ≍+ f for all A ∈ S.
Proof of equivalence. Part (i) is equivalent to the ≤ direction of (4.15), and part (ii) to the
≥ direction. For the first equivalence, for the forwards direction take S = {A : hA ∈ S},
and for the backwards direction take S = {g : g ≍+ hA , A ∈ S}. For the second
equivalence, for the backwards direction take S = D(f) and S = {g : g ≍+ f}.

It is worth stating the special case of Theorem 4.6 that occurs when the collection S
is defined by the Diophantine conditions defining Singm,n (ω) and Sing∗m,n (ω) for some
n
ω≥ m
. Thus, we define the uniform dynamical exponent of a map f : [0, ∞) → Rd to be

26

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

the number

−1
f1 (t).
t→∞
t
Moreover, f is said to be trivially singular if fj+1 (t) − fj (t) → ∞ as t → ∞ for some
j = 1, . . . , d − 1. Letting S = {f : τb(f) = τ } or S = {f : τb(f) = τ, f not trivially singular}
in Theorem 4.6 yields the following result:
def

τb(f) = lim inf

Theorem 4.8 (Special case of variational principle). For all ω ≥

n
,
m

we have

dimH (Singm,n (ω)) = sup{δ(f) : f ∈ Tm,n , τb(f) = τ }
dimP (Singm,n (ω)) = sup{δ(f) : f ∈ Tm,n , τb(f) = τ }

dimH (Sing∗m,n (ω)) = sup{δ(f) : f ∈ Tm,n , τb(f) = τ, f not trivially singular}
dimP (Sing∗m,n (ω)) = sup{δ(f) : f ∈ Tm,n , τb(f) = τ, f not trivially singular}

where τ is as in (3.1).
Theorem 4.6 can also be used to compute the dimensions of the set
[
g ∗ (ω) def
Sing∗m,n (ω ′ ).
=
{A
:
ω
b
(A)
≥
ω,
A
not
trivially
singular}
=
Sing
m,n
ω ′ ≥ω

Theorem 4.9 (Special case of variational principle). For all ω ≥

n
,
m

we have

g ∗ (ω)) = sup dimH (Sing∗ (ω ′))
dimH (Sing
m,n
m,n
ω ′ ≥ω

g ∗ (ω)) = sup dimP (Sing∗ (ω ′ )).
dimP (Sing
m,n
m,n
ω ′ ≥ω

(Theorem 4.9 is also true with the stars removed, but in that case it is not as interesting
because dimH (Singm,n (∞)) is “too large”, whereas dimH (Sing∗m,n (∞)) is the “correct” size
according to §3.2.1.)
It is natural to expect that the map ω 7→ dimH (Sing∗m,n (ω)) is monotonically decreasing,
in which case Theorem 4.9 would imply that
∗

∗
g
dimH (Sing
m,n (ω)) = dimH (Singm,n (ω)).

4.2. New proofs of old results. In addition to our new results, our techniques now provide a uniform framework to prove classical results in metric Diophantine approximation.
The following result was proven in the one-dimensional setting by Jarnı́k (1928) and in
the matrix setting by Schmidt (1969).
Theorem 4.10 (Jarnı́k–Schmidt, [35, 58]). The Hausdorff dimension of the set of badly
approximable matrices is mn.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Recall that for each ω >

n
,
m

27

we say that a matrix A is ω-approximable if

lim sup sup
|q|→∞ p∈Zm

− log kAq − pk
≥ ω.
log kqk

It follows from the Dani correspondence principle that A is ω-approximable if and only if
lim sup
t→∞

−hA,1 (t)
≥τ
t

where τ is as in (3.1).
The following theorem was proven in the one-dimensional case independently by
Jarnı́k (1929) and Besicovitch (1934), and in the matrix case by Bovey and Dodson
(1986).
Theorem 4.11 (Jarnı́k–Besicovitch–Bovey–Dodson, [36, 6, 8]). The Hausdorff dimension
of the set of ω-approximable matrices is mn(1 − τ ). In particular, the Hausdorff dimension
of the very well approximable matrices is mn.
We provide proofs of these theorems in Sections 25 and 26 respectively.
5. D IRECTIONS

TO FURTHER RESEARCH

We conclude our introduction with a small sample of problems and research directions,
which we hope will illustrate the wide scope awaiting future exploration.
5.1. Exact Hausdorff and packing dimensions. Determine whether an appropriate
gauge function exists with respect to which the Hausdorff measure of the singular matrices have positive and finite measure. The same question for packing measures is also
open. It would be natural to expect that the δm,n -dimensional Hausdorff measure of
Sing(m, n) is zero, and that the δm,n -dimensional packing measure of Sing(m, n) is infinite. In general, determining exact dimensions for any of the sets we have studied in this
paper would be an interesting challenge.
5.2. Quantitative Schmidt’s conjecture. We conjecture that the inequality in Theorem
3.14 is actually an equality:
Conjecture 5.1. For 2 ≤ k ≤ m + n − 1, the Hausdorff and packing dimensions of the set
of k-singular m × n matrices (see Definition 3.13) are both equal to
max(fm,n (k), fm,n (k − 1)), where
kmn
fm,n (k) = mn −
m+n
def


1−

k
m+n



−



km
m+n



kn
m+n



·

28

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Here, {x} denotes the fractional part of a real number x.
Remark 5.2. When k = 2 or m + n − 1, the Hausdorff and packing dimensions of the set
of k-singular matrices are both equal to δm,n .
5.3. Regularity of dimension functionals.
Problem 5.3. Determine when/whether the functions
ω 7→ dimH (Singm,n (ω)),

ω 7→ dimP (Singm,n (ω))

are decreasing and continuous.
Although it is natural to suspect that these functions are in fact decreasing and continuous for all (m, n) 6= (1, 1), Theorem 3.9 seems to suggest otherwise: it suggests that
the function τ 7→ dimP (Singm,1 (τ )) may have a discontinuity at τ = 1/m2 for all m ≥ 3.
Indeed, the proof of Theorem 3.9 gives us no reason to suspect that the inequality is strict
in Theorem 3.8 for τ slightly greater than 1/m2 . If in fact equality holds for such τ , then
there is a discontinuity! If this were the case, it would show that the conjecture we made
in the announcement of this paper [21, Conjecture 2.10] was too optimistic.
5.4. Intersecting standard and uniform exponent level sets. Let ω(A) and ω
b (A) denote the standard and uniform exponents of irrationality of a matrix A, respectively:
def

ω
b (A) = lim inf
Q→∞

def

ω(A) = lim sup
Q→∞

sup

sup

0<kqk≤Q

p

sup

sup

0<kqk≤Q

p

− log kAq + pk
log Q

− log kAq + pk
log Q

The Hausdorff dimensions of the levelsets of ω are well-known, and we have provided
many results on the Hausdorff dimensions of the levelsets of ω
b . However, it is natural to
ask about the dimension of the intersection of two such sets:
Question 5.4. What is the behavior of the function

(ω, ω
b ) 7→ dimH ({A : ω(A) = ω, ω
b (A) = ω
b })?

5.5. Precise dimension formulas for uniform exponent level sets. As mentioned previously, it is very challenging to obtain precise formulas for the Hausdorff and packing
dimensions of Singm,n (ω) = {A : ω
b (A) = ω} in terms of ω, m, and n. Though we
have completely solved (see Theorems 3.8 and 3.10 for details) this problem in the cases
(m, n) = (1, 2) and (m, n) = (2, 1), and for packing dimension in the case where n ≥ 2, it
is plausible that finding a closed form expression in all scenarios is hopeless. To express

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

29

the limit of our current understanding, note that we do not have conjectural formulas for
Hausdorff dimension even for the cases when (m, n) ∈ {(1, 3), (3, 1), (2, 2)} at present.
5.6. Metric theory for ε-Dirichlet improvable matrices. Given 0 < ε < 1, an m × n
matrix A is called ε-Dirichlet improvable (see [22]) if for all sufficiently large Q, there
exists (p, q) ∈ Zm+n such that
kAq − pk ≤ εQ−n/m and 0 < kqk < Q.
An m×n matrix A is Dirichlet improvable if it is ε-Dirichlet improvable for some 0 < ε < 1.
Singular matrices are ε-Dirichlet improvable for all 0 < ε < 1.
Question 5.5. How do the Hausdorff and packing dimensions of the set of ε-Dirichlet
improvable m × n matrices vary as functions of ε? It would already be interesting just to
give estimates on these dimensions, if not precisely determine them.
5.7. Weighted singular matrices and general diagonal flows. In the parametric geometry of numbers and the Dani correspondence principle we are generally concerned
with the (gt ) flow as defined in §3.1. What happens if the (gt ) flow is replaced by some
other diagonal flow (ht ), for example
ht = diag(ea1 t , . . . , eam t , e−b1 t , . . . , e−bn t ) ∈ SLm+n (R)
where a1 , . . . , am , b1 , . . . , bn are positive real numbers? For example, is it possible to compute the Hausdorff and packing dimensions of the set of m × n matrices A such that
the trajectory (ht uA Zm+n )t≥0 is divergent as a function of a1 , . . . , am , b1 , . . . , bn ? When
m = 2 and n = 1, this question in case of the Hausdorff dimension has been addressed by
Liao, Shi, Solan, and Tamam [47]. Without obtaining dimension formulas, Guan and Shi
proved that the Hausdorff dimension of the set of divergent-on-average trajectories for a
one-parameter subgroup action on a finite-volume homogeneous space is not full, [32].
5.8. Inhomogeneous Diophantine approximation. Our results fall within the domain
of homogeneous Diophantine approximation. It would be of interest to investigate analogues of our results in the frameworks of inhomogeneous approximation, see [12, 13,
46]. In this setting, given an m × n matrix A and x ∈ Rm , the pair (A, x) is called singular
if for all ε > 0, there exists Qε such that for all Q ≥ Qε , there exist integer vectors p ∈ Zm
and q ∈ Zn such that
kAq + p + xk ≤ εQ−n/m

and

0 < kqk ≤ Q.

30

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

It is also natural to study the inhomogeneous approximation frameworks where we fix
one coordinate of the pair (A, x) and let the other vary. Extending our variational principle (Theorem 4.6) and its corollaries to such inhomogeneous frameworks would be a
natural next step. When m = n = 1, this question in case of the Hausdorff dimension has
been recently investigated by Kim and Liao [43].

5.9. Parametric geometry of numbers in arbitrary characteristic. It would be of interest to develop the technology introduced in this work to study questions of Diophantine
approximation in the function field setting, see Roy and Waldschmidt [55].

6. A CKNOWLEDGEMENTS
This research began on 28th November 2016 when the authors met at the American
Institute of Mathematics in San Jose, California, via their SQuaRE program. We thank
the institute and their staff for their hospitality and excellent working conditions. In
particular, we thank Estelle Basor for her singular encouragement and support. The
first-named author was supported in part by a 2017-2018 Faculty Research Grant from
the University of Wisconsin-La Crosse. The second-named author was supported in part
by the Simons Foundation grant #245708. The third-named author was supported in
part by the EPSRC Programme Grant EP/J018260/1, and is currently supported by a
Royal Society University Research Fellowship. The fourth-named author was supported
in part by the NSF grant DMS-1361677. We thank Pieter Allaart, Valérie Berthé, Nicolas
Chevallier, Elon Lindenstrauss, Seonhee Lim, Antoine Marnat, Damien Roy, Johannes
Schleischitz and Hao Xing for helpful comments and clarifying questions. In particular,
we thank Damien Roy for his meticulous reading and criticism, as well as for pointing out
several translations between the notation in his papers and those of Schmidt–Summerer
and ours. This eventually led to the inclusion of Appendix A. We also thank Lingmin
Liao for their punctilious reading and several discussions that greatly helped improve
the exposition. Finally, we thank an anonymous referee for their extremely scrupulous
report, which helped us improve several points throughout the paper, and pushed us to
clarify many facts that were previously “tacitly assumed and never spelled out”. The
quest of refereeing a long and at times necessarily arduous paper is largely a thankless
endeavor for which we are greatly appreciative.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

31

Part 2. Proof of main theorems using the variational principle
7. L EITFADEN

TO

PART 2

In this part we prove all the theorems of Section 3 (with the exception of Theorems
3.2 and 3.3) as well as Theorem 4.2 from Section 4, making full use of the variational
principle that has been proven in Part 4.
For reference, the following theorems are proven in the following subsections:
• Theorems 3.1 and 3.4 are proved in §8 and §9.
To prove Theorems 3.1 and 3.4 it suffices10 to show that
(7.1)

dimP (Sing(m, n)) ≤ δm,n ,

(7.2)

dimH (VSing(m, n)) ≥ δm,n .
We prove these inequalities first (in §8 and §9 respectively), since their proofs
provide the best basic illustration of our techniques.
• Theorem 3.8 is proven in §13 and §12.
The packing dimension upper bound (valid for n ≥ 2) is proven in §13. The
packing dimension lower bound is proven in §12.
• Theorem 3.9 is proven in §14.

• Theorem 3.5 is proven in §8, §9, §10, §11, and §12.
In §8, after proving (7.1), we obtain the upper bound for packing dimension in
Theorem 3.5. The packing dimension lower bound in Theorem 3.8 (proven in
§12) implies the packing dimension lower bound in Theorem 3.5. This completes
the proof for the packing dimension asymptotic formula. Regarding the Hausdorff
dimension, there are two asymptotic formulas that have to be proved. For the first
case of Theorem 3.5: the lower bound for Hausdorff dimension is obtained in
§9, after proving (7.2); and the upper bound for Hausdorff dimension is proven
in §10. For the second case of Theorem 3.5: the lower bound for Hausdorff
dimension is proven in §11; and the upper bound for Hausdorff dimension follows
from that for packing dimension (proven in §8).
• Theorem 3.6 is proven in §13 §12, §15, and §17.
Theorem 3.8 (proven in §13 and §12) implies the packing dimension formula in
Theorem 3.6. The upper and lower bounds for the Hausdorff dimension formula
in Theorem 3.6 are proven in §15 and §17, respectively.
10

This follows from the monotonicity of the Hausdorff and packing dimensions, and the fact that the latter
is bounded below by the former (see Section 27).

32

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

• Theorem 3.7 is proven in §14,§16, §18, and §19 .
The packing dimension upper bound in Theorem 3.7 is proven in §19. The packing dimension lower bound is implied by Theorem 3.9 (proven in §14). The
lower and upper bounds for the Hausdorff dimension formula in Theorem 3.7
are proven in §16 and §18, respectively.
• Theorem 3.10 is proven in §20.
• Theorem 3.11 is proven in §21.
• Theorem 3.12 is proven in §22.
• Theorem 3.14 is proven in §23.
• Theorem 4.2 is proven in §24.
8. P ROOF

OF

(7.1) + T HEOREM 3.5,

UPPER BOUND FOR PACKING DIMENSION

In some sense, the variational principle means that it is harder to prove upper bounds
on dimension than lower bounds: for a lower bound one only needs to exhibit a template
or sequence of templates with the appropriate dimension properties, while for an upper
bound one needs to prove something about all possible templates. This is in contrast to
the usual situation in which it is easier to prove upper bounds. Our technique for proving
upper bounds is based on continuing the analogy with physics (cf. Figure 3 and the three
paragraphs following Definition 4.5) by defining a function that measures the “potential
energy” of any configuration of particles: the potential energy is larger the farther apart
the particles are. We then prove an inequality relating the change in potential energy and
the contraction rate. Integrating this inequality gives a relation between the potential
energy at a given point in time, which is always positive, and the average contraction
rate up to that time. This then yields a bound on the average contraction rate up to any
point in time.
Let f : [0, ∞) → Rd be a balanced11 template (cf. Definition 4.5). We define the
“potential energy of f at time t” to be the number

 2
mn2
mn
|f1 (t)|,
|fd (t)| .
(8.1)
φ(t) = φf (t) = max
m+n
m+n
Note that φ(t) ≥ 0 for all t ≥ 0. The motivation for the definition of φ is the following
lemma:

11

Since any template can be written as a translation of a balanced template, we can without loss of generality consider only balanced templates in what follows.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

33

Lemma 8.1. Let I be an interval of linearity12 for f such that φ′ (t) is well-defined for all
t ∈ I, and such that f(t) 6= 0 for all t ∈ I. Then
φ′ (t) ≤ δm,n − δ(f, I)

(8.2)

for t ∈ I. Equality holds in precisely the following cases:
1. S+ (f, I) = {1, . . . , m};
2. S+ (f, I) = {1, . . . , m − 1, m + 1}, and f1 = . . . = fm and fm+1 = . . . = fm+n on I
(and in particular since f is balanced we have m|f1 | = n|fd | on I);
3a. S+ (f, I) = {2, . . . , m + 1}, and m|f1 | ≥ n|fd | on I;
3b. S+ (f, I) = {1, . . . , m − 1, m + n}, and n|fd | ≥ m|f1 | on I.
If equality does not hold, then the difference between the two sides of (8.2) is at least
1/ max(m, n).
Note that when m = 1, cases 2 and 3a are equivalent, and when n = 1, cases 2 and 3b
are equivalent.
Proof. Note that the cases 3a and 3b are symmetric with respect to the operation of
replacing the m × n template f by the n × m template −f, while the other two cases
are individually symmetric with respect to this operation. Thus, we may without loss of
generality suppose that
(8.3)

φ=

m2 n
|f1 |
m+n

i.e.

m|f1 | ≥ n|fd |

on I. Let j ≥ 1 be the largest number such that
fj = f1 on I.
Note that since f is balanced and f(t) 6= 0 for all t ∈ I, (8.3) implies that j ≤ m.
Since I is an interval of linearity for f, it follows that fj < fj+1 on I. Accordingly, let
L± = L± (f, I, j) and S± = S± (f, I). Then by (8.3) and (4.5) we have


m2 n −Fj′ (t)
L− L+
m2 n
′
φ (t) =
=
−
m+n j
(m + n)j n
m
and on the other hand, by (4.11) we have
(8.4)
12



mn − δ(f, I) ≥ # S− ∩ (0, j] · # S+ ∩ (j, d] = L− (m − L+ )

I.e. an interval on which f is linear. If I is an interval of linearity for f , we will denote the constant value
of f ′ on I by f ′ (I).

34

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

and thus
δm,n − δ(f, I) ≥ L− (m − L+ ) −

mn
·
m+n

So to demonstrate (8.2) it suffices to show that


m2 n
L− L+
mn
≤ L− (m − L+ ) −
−
·
(m + n)j n
m
m+n
Indeed, since L+ + L− = j, we have


 


m2 n
m2 n
j
L− m
L− L+
1
1
mn
=
L−
−
=
−
+
−
(m + n)j n
m
(m + n)j
m n
m
j
m+n
so we need to show that
(8.5)

L− m
≤ L− (m − L+ ).
j

If L− = 0, then this inequality is trivial (and equality holds). So suppose that L− > 0.
Since j = L− + L+ ≤ m, we have L+ < j ≤ m, so (j − 1)(m − L+ − 1) ≥ 0, and thus
(8.6)

m ≤ j + (m − L+ ) − 1 ≤ j(m − L+ ),

and rearranging yields (8.5). This completes the proof of (8.2).
Now suppose that equality holds in (8.2). The equality in (8.4) implies that
S+ = {1, . . . , L+ } ∪ {j + 1, . . . , j + m − L+ }.
On the other hand, the equality in (8.5) implies that either L− = 0, or equality holds in
(8.6). In the latter case we have L− = j − L+ = 1, and either j = 1 or m − L+ = 1, from
the left and right hand sides of (8.6), respectively. So there are three cases:
1. If L− = 0, then S+ = {1, . . . , m}.
2. If L− = 1 and m − L+ = 1, then S+ = {1, . . . , m − 1, m + 1}. In this case j = m, i.e.
f1 = . . . = fm on I. Combining with (8.3) and using the fact that f is balanced
shows that fm+1 = . . . = fm+n on I.
3a. If L− = 1 and j = 1, then S+ = {2, . . . , m + 1}.
Note that the case 3b does not appear in this list due to the fact that we made the
assumption (8.3) without loss of generality, using the fact that 3a and 3b are symmetric.
The converse direction can be proved similarly.
Finally, suppose that equality does not hold in (8.2). Note that the difference between
the two sides of (8.2) is the sum of the difference between the two sides of (8.4) and
those of (8.5), i.e. mn − δ(f, I) − L− m/j. Since this is a positive rational number with
denominator j, it must be ≥ 1/j ≥ 1/ max(m, n).


A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

35

Now suppose that the template f is singular, i.e. satisfies f1 (t) → −∞ as t → ∞. Then
f(t) 6= 0 for all sufficiently large t. So by Lemma 8.1, (8.2) holds for almost all sufficiently
large t, and thus for all sufficiently large T we have
ˆ T
0 .+ φ(T ) − φ(0) .+
[δm,n − δ(f, t)] dt = T [δm,n − ∆(f, T )].
0

It follows that



φ(T )
φ(T )
= δm,n − lim inf
≤ δm,n ,
δ(f) = lim sup ∆(f, T ) ≤ lim sup δm,n + O(1/T ) −
T →∞
T
T
T →∞
T →∞

and applying Theorem 4.6 to the set
S = {f : [0, ∞) → Rd | f1 (t) → −∞ as t → ∞}
yields (7.1). Note that if f is τ -singular, i.e. |f1 (t)| ≥ τ t for all sufficiently large t, then
φ(T ) ≥

m2 n
τT
m+n

for all sufficiently large T , and thus
δ(f) ≤ δm,n −

m2 n
τ.
m+n

Applying Theorem 4.8 yields the upper bound of the packing dimension assertion of
Theorem 3.5.
9. P ROOF

OF

(7.2) + T HEOREM 3.5,

FIRST FORMULA , LOWER BOUND FOR

H AUSDORFF

DIMENSION

Lemma 8.1 provides motivation for how to construct a template yielding the lower
bound (7.2). Namely, the template f should be constructed in a way such that most of
the time, one of the four cases for the possible value of S+ (f, I) listed in Lemma 8.1
holds. For example, there may be two consecutive intervals of linearity I1 and I2 such
that S+ (f, I1 ) = {2, . . . , m + 1} and S+ (f, I2 ) = {1, . . . , m}; cf. Figure 4.
In contrast to the picture in Figure 4, if we want the template f to be singular then
we need f(t) 6= 0 for all t, so we will need to “cut off” a small part of the picture. By
“gluing” infinitely many of these pictures together we will get a singular template of large
Hausdorff dimension; cf. Figure 5.
To make the idea conveyed in Figure 5 rigorous, we introduce the notion of the
standard template defined by two points (tk , −εk ) and (tk+1 , −εk+1 ). The idea is that
f : [tk , tk+1] → Rd should satisfy f1 (ti ) = f2 (ti ) = −εi for i = k, k + 1, and f1 should be as
small as possible given this restriction. Finally, the template should be chosen so that fd

36

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

t0

t1

t2

δ(f, Ii )

mn − m

mn

|Ii |/|I|

n
m+n

m
m+n

F IGURE 4. The joint graph of a partial template f such that S+ (f, I1 ) =
{2, . . . , m + 1} and S+ (f, I2 ) = {1, . . . , m}, where I1 = (t0 , t1 ) and I2 =
n
(t1 , t2 ). In this picture we have f(t0 ) = f(t2 ) = 0, and thus |I1 | = m+n
|I| and
m
|I2 | = m+n |I|, where I = (t0 , t2 ). Consequently,
ˆ
n
m
1
δ(f, t) dt =
(mn − m) +
(mn) = δm,n
|I| I
m+n
m+n
i.e. the average contraction rate of f over I is δm,n . Note that this partial
template is exactly the standard template defined by the points (t0 , 0) and
(t2 , 0) (cf. Definition 9.1).

F IGURE 5. The joint graph of a template f designed to be a singular template of large Hausdorff dimension. The gray regions represent intervals
where the precise value of the template is irrelevant; what matters is that
the template stays away from 0 on these regions.
is as small as possible, given the previous restrictions. Formally we make the following
definition:
Definition 9.1. Fix 0 ≤ tk < tk+1 and εk , εk+1 ≥ 0 and let ∆t = ∆tk = tk+1 − tk and
∆ε = ∆εk = εk+1 − εk . Assume that the following formulas hold:
(9.1)

−

1
∆t
m

≤ ∆ε ≤ n1 ∆t,

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

(9.2)
(9.3)

∆t if m = 1 and ∆ε ≤
∆ε ≥ − n−1
2n
either (n − 1)

1
∆t
n

m−1
∆t
2m


− ∆ε ≥ dεk or (m − 1)

37

if n = 1,

1
∆t
m


+ ∆ε ≥ dεk+1 .

Then the standard template defined by the two points (tk , −εk ) and (tk+1 , −εk+1) is the
partial template f : [tk , tk+1 ] → Rd defined as follows:

• Let g1 , g2 : [tk , tk+1 ] → R be piecewise linear functions such that gi (tj ) = −εj ,
and gi has two intervals of linearity: one on which gi′ = m1 and another on which
gi′ = − n1 . For i = 1 the latter interval comes first while for i = 2 the former
interval comes first; cf. Figure 6. The existence of such functions g1 and g2 is
guaranteed by (9.1). Finally, let g3 = . . . = gd be chosen so that g1 + . . . + gd = 0.
• For each t ∈ [tk , tk+1 ] let f(t) = g(t) if g2 (t) ≤ g3 (t); otherwise let f1 (t) = g1 (t) and
let f2 (t) = . . . = fd (t) be chosen so that f1 + . . . + fd = 0.

We will sometimes denote the standard template defined by (tk , −εk ) and (tk+1 , −εk+1 )
by s[(tk , −εk ), (tk+1 , −εk+1 )].

(t1 , −ε1 )

(t2 , −ε2 )

F IGURE 6. The joint graphs of f and g on the interval [t1 , t2 ], where f is the
standard template s[(t1 , −ε1 ), (t2 , −ε2 )] as in Definition 9.1. The map g is
shown dotted while f is shown solid.
Lemma 9.2. A standard template is indeed a balanced partial template.
Proof. We show where the formulas (9.2) and (9.3) are needed, leaving the rest of the
proof as an exercise to the reader. The condition (9.3) is equivalent to the assertion that
g2 (t) ≥ g3 (t) where t is the location of the maximum of g2 . This implies that f2 (t) =
f3 (t), guaranteeing that the convexity condition (cf. Definition 4.1) is satisfied at t. The
condition (9.2) is equivalent to the assertion that there is no interval on which f1′ = f2′ =
±1. If such an interval exists, then f cannot be a template because if it were, we would
have {1, 2} ⊆ S± but #(S± ) = d± = 1, a contradiction. Conversely, if there is no such

38

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

interval then the sets S± can be computed in a consistent way on any interval of linearity
for f.

Example 9.3. The inequalities (9.1)-(9.3) always hold when εk = εk+1 = 0. In this case,
the standard template f defined by the points (tk , 0) and (tk+1 , 0) has only two intervals
of linearity, and the average value of δ(f, ·) on [tk , tk+1 ] is equal to δm,n ; see Figure 4.
Definition 9.4. Let (tk )∞
0 be an increasing sequence of nonnegative real numbers, and
let εk ≥ 0 for each k. The standard template defined by the sequence of points (tk , −εk ) is
the partial template produced by gluing together the standard templates defined by the
pairs of points (tk , −εk ) and (tk+1 , −εk+1 ) for each k. The standard template defined by
two parameters τ ≥ 0 and λ > 1, denoted f[τ, λ], is the one defined by the sequence of
points (tk , εk )k∈Z, where tk = λk and εk = τ tk for all k. Note that in this case, (9.1)-(9.3)
become
τ ≤ n1 ,

(9.4)
τ≤

(9.5)
(9.6)

either (n − 1)

1
n


−τ ≥

m−1
2m

if n = 1,

1
dτ
λ−1

or (m − 1)

1
m


+τ ≥

λ
dτ.
λ−1

We refer to f[τ, λ] as being exponentially λ-equivariant, viz. that f(λt) = λf(t) for all t ≥ 0.
√
√
Now fix τ > 0 small and let λ = 1 + τ (or more generally λ = 1 + Θ( τ )), and
note that (9.4)-(9.6) hold. Let f = f[τ, λ] and tk , εk be as above. Now since the map
(ε1 , ε2 ) 7→ ∆(s[(0, −ε1 ), (1, −ε2 )], 1) is Lipschitz continuous, it follows that
∆(f, [tk , tk+1 ]) = ∆(s[(tk , −εk ), (tk+1, −εk+1 )], [tk , tk+1])
 h
 
i 
εk+1
εk
= ∆ s 0, − ∆t
,
1,
−
,1
∆tk
k


= ∆(s[(0, 0), (1, 0)], 1) − O max(ε∆tk ,εk k+1 )

√
τ
= δm,n − O λ−1
= δm,n − O( τ )

and thus for sufficiently large k

√
∆(f, tk ) = δm,n − O( τ ).
Given T large, let k be chosen so that tk ≤ T < tk+1 . Then


√
k
= O(λ − 1) = O( τ )
∆(f, T ) − ∆(f, tk ) = O T −t
tk

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

and thus

39

√
∆(f, T ) = δm,n − O( τ ).

Taking the limit as T → ∞ shows that

√
dimH (Singm,n (τ )) ≥ δ(f) = δm,n − O( τ ),

and taking the limit as τ → 0 completes the proof of (7.2), as well as of the lower bound
for Hausdorff dimension in the first case of Theorem 3.5.
√
Remark 9.5. The O( τ ) term in the above proof comes from combining two sources of
√
τ
). We chose λ = 1 + Θ( τ ) so as to
error: one of size O(λ − 1) and another of size O( λ−1
minimize the sum of these two error terms.
Remark 9.6. Via a more careful argument one could exactly compute δ(f[τ, λ]) in terms
of τ and λ for the template f described above. Using calculus one could then optimize
over the variable λ to get a lower bound which is the best possible using this technique.
10. P ROOF

OF

T HEOREM 3.5,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a τ -singular template such that δ(f) > δm,n − z, where z > 0 is small. We aim
to show that τ = O(z 2 ) if (m, n) 6= (2, 2). Indeed, let φ be as in (8.1), and let
def

E = {t ≥ 0 : φ′ (t) < δm,n − δ(f, t)}.

(10.1)
By Lemma 8.1, we have



φ′ (t) ≤ δm,n − δ(f, t) − max(m, n)−1 t ∈ E

for all t sufficiently large. Here [t ∈ E] denotes 1 if t ∈ E and 0 otherwise. Integrating
over [0, T ] gives


φ(T ) − φ(0) ≤ T δm,n − ∆(f, T ) − max(m, n)−1 λ E ∩ [0, T ] ,

where λ denotes Lebesgue measure. On the other hand, since δ(f) > δm,n − z, we have
∆(f, T ) ≥ δm,n − z for all sufficiently large T , and thus rearranging the previous equation
and using the fact that φ(T ) ≥ 0 gives

(10.2)
λ E ∩ [0, T ] = O(zT )
and

(10.3)

φ(T ) = O(zT )

assuming T is sufficiently large. The trick now is that we also know φ(T ) = Ω(τ T ) since
f is τ -singular (which means that |f1 (t)| ≥ τ t for all sufficiently large t). So the question

40

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

is what kind of templates satisfy both an upper bound and a lower bound for φ, but for
which the exceptional set E is not large. The answer is given by the following lemma, in
which the problem has been rescaled so that the upper bound for φ is just 1:
def

Lemma 10.1. Suppose that (m, n) 6= (2, 2), and fix x > 0. Let f : I = [t− , t+ ] → Rd be
a partial template such that x ≤ φ(t) ≤ 1 for all t ∈ I. Then if |I| is sufficiently large
depending on m, n, then
λ(E) & x,
where the exceptional set E is as in (10.1).
def

Proof. Let y = λ(E); we need to show that either φ(t) . y for some t ∈ I, or else |I| =
O(1).
Throughout this proof, we will call an interval J a Type 1 interval if case 1 of Lemma
8.1 holds along it; we define Type 2/3a/3b intervals similarly. The basic idea is to reduce
to the case of a Type 2 interval to the left of a Type 3 interval to the left of a Type 1
interval, modulo a small perturbation. Since f cannot be static on any interval of fixed
Type, the bound on φ implies a bound on the length of each interval and thus on the
length of the whole interval I. The proof now splits into two cases.
Case 1: Suppose first that there is some Type 1 interval which is to the left of a Type
2/3a/3b interval. Without loss of generality, we may assume that there are no Type
(1/2/3a/3b) intervals between them. It follows that if the two intervals are I1 = (t1 , t2 )
and I2 = (t3 , t4 ), respectively, then we have 0 ≤ t3 − t2 ≤ y.
If I2 is Type 2, then f1 (t3 ) = . . . = fm (t3 ) and fm+1 (t3 ) = . . . = fm+n (t3 ). On the other
hand, by the convexity condition we have fm (s) = fm+1 (s) for some s ∈ [t2 , t3 ]. It follows
that |fm+1 (t3 ) − fm (t3 )| . y and thus φ(t3 ) ≍ |f(t3 )| . y.
If I2 is Type 3a, then m|f1 (t3 )| ≥ n|fd (t3 )|. On the other hand, by the convexity condition, for each j = 1, . . . , m there exists sj ∈ [t2 , t3 ] such that fj (sj ) = fj+1 (sj ). It follows
that |fj+1(t3 ) − fj (t3 )| . y, so
(m + 1)|f1(t3 )| = −

m+1
X
i=1

fi (t3 ) + O(y) =

m+n
X

fi (t3 ) + O(y)

i=m+2

≤ n|fd (t3 )| + O(y) ≤ m|f1 (t3 )| + O(y)
and thus φ(t3 ) ≍ |f(t3 )| . y. A similar argument applies if I2 is Type 3b.
Case 2: On the other hand suppose that no Type 1 interval is to the left of any Type
2/3a/3b interval. Now let
def
ψ(t) = m|f1 (t)| − n|fd (t)|

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

41

and let J be a Type 2/3a/3b interval. If J is Type 2, then ψ = 0 on J and thus ψ ′ = 0.
1
,
Suppose that J is Type 3a. Then on J we have m|f1 | ≥ n|fd |, f1′ = − n1 , and fd′ ≤ n(m+n−1)
from which it follows that
1
def m
ψ ′ ≥ cm,n =
−
·
n
m+n−1

Note that cm,n > 0 unless m = 1, in which case cm,n = 0. Similar logic shows that if J is
Type 3b, then ψ ′ ≥ cn,m on J.
Now let Ai denote the union of the Type i intervals in I. Note that A1 ∪ A2 ∪ A3 ∪ E = I
def
def
except for finitely many points. We can assume that t0 = sup(A2 ) ≤ t1 = inf(A1 ) and
sup(A3 ) ≤ t1 , as otherwise we are in Case 1 and we are done by the preceding argument.
Since t0 is the endpoint of a Type 2 interval, we have ψ(t0 ) = 0. On the other hand, we
have
ˆ t0


ψ ′ (t) dt ≥ cm,n λ [t− , t0 ] ∩ A3a + cn,m λ [t− , t0 ] ∩ A3b − O(y)
ψ(t0 ) ≥
t−



so we have λ [t− , t0 ] ∩ A3a = O(y) if m ≥ 2 and λ [t− , t0 ] ∩ A3b = O(y) if n ≥ 2,
respectively. On the other hand, if m = 1 then A3a = A2 and if n = 1 then A3b = A2 .
Consequently

λ [t− , t0 ] ∩ A3 \ A2 = O(y)
and thus since φ′ = δm,n − (mn − 1) on A2 , we have
ˆ t0
φ′ (t) dt
0 ≍+ φ(t0 ) − φ(t− ) =
t−



= [δm,n − (mn − 1)]λ [t− , t0 ] ∩ A2 − O λ [t− , t0 ] ∩ E ∪ A3 \ A2


mn
= 1−
(t0 − t− ) − O(y)
m+n

Since (m, n) 6= (2, 2) by assumption, we have (m − 1)(n − 1) 6= 1 and thus
mn
6= 0
1−
m+n
2

m
and thus t0 − t− = O(1). Similarly, since φ′ = δm,n − (mn − m) = m+n
on A3a and
n2
′
φ = δm,n − (mn − n) = m+n on A3b , and since (t0 , t1 ) ⊆ A3 ∪ E, we have

0 &+

min(m, n)2
(t1 − t0 ) − O(y).
m+n

mn
Since φ′ = δm,n − mn = − m+n
on A1 , and since (t1 , t+ ) ⊆ A1 ∪ E, we have

0 ≍+ −

mn
(t+ − t1 ) + O(y).
m+n

42

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Thus t1 − t0 = O(1) and t+ − t1 = O(1), so combining gives |I| = t+ − t− = O(1).



Let C > 0 be the constant such that Lemma 10.1 is true whenever |I| ≥ C. Notice that
any partial template whose domain has length ≥ C can be split up into partial templates
whose domains have length = C which cover the majority of the original domain. It
follows that in the context of Lemma 10.1, in general we have
λ(E) & x|I| as long as |I| ≥ C,
where I is the domain of a partial template f satisfying x ≤ φ ≤ 1. Applying a scaling
argument yields:
Lemma 10.2. Suppose that (m, n) 6= (2, 2), and fix 0 < x0 ≤ x1 and I ⊆ R such that
|I| ≥ Cx1 . Let f : I → Rd be a partial template such that x0 ≤ φ(t) ≤ x1 for all t ∈ I. Then
λ(E) &

x0 |I|
·
x1

Now fix T large, let I = [T /2, T ], and let x0 = inf I φ, x1 = supI φ. Since f is τ -singular
we have x0 & τ T > 0, while by (10.3) we have x1 = O(zT ). In particular, if z is
sufficiently small then T ≥ Cx1 . Consequently, by Lemma 10.2 and (10.2),

τ T 2 = O(x0 T ) = O x1 λ(E ∩ I) = O(zT )2 ,
which implies τ = O(z 2 ).
√
It follows that if f is a τ -singular template, then δ(f) ≤ δm,n − Θ( τ ), since otherwise
we can take z = 2(δm,n − δ(f)) and apply the above argument. Taking the supremum over
f and applying Theorem 4.8 shows that

√
dimH Singm,n (τ ) ≤ δm,n − Θ( τ ) if (m, n) 6= (2, 2).

When (m, n) = (2, 2), the upper bound for Hausdorff dimension follows from the upper
bound for packing dimension which we proved in §8.
11. P ROOF

OF

T HEOREM 3.5,

SECOND FORMULA , LOWER BOUND FOR

H AUSDORFF

DIMENSION

In this proof, we will employ a variant of the notion of a standard template defined by
two parameters, as in Definition 9.4, by introducing a third parameter.
Let m = n = 2, and fix 0 < τ < n1 = 21 . Fix λ > 1 and let tk = λk and εk = τ tk . However,
rather than letting f = f[τ, λ] (as in Definition 9.4), we will introduce a new parameter
γ ∈ [1 + 6τ + 2λτ, λ]. We define f as follows:

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

43

• On [1, γ], we have f = s[(1, −τ ), (γ, −λτ )]. Note that (9.3) is satisfied due to the
lower bound on γ.
• Extend f to [γ, λ] via the requirement that f is constant on [γ, λ]: f1 = f2 = −λτ
and f3 = f4 = λτ on [γ, λ].
• Extend f to [0, ∞) via exponential equivariance13, i.e. so that f(λt) = λf(t) for all
t ≥ 0.

For simplicity of calculation, we set γ = 1 − 2τ + 10λτ (this is possible as long as 1 − 2τ +
10λτ ≤ λ), since this means that f has only three intervals of linearity on [1, γ] (otherwise
f has four intervals of linearity on [1, γ]):

1 1


(− 2 , 2 , 0, 0) 1 < t < 1 + 4τ
f ′ (t) = (− 21 , 16 , 61 , 61 ) 1 + 4τ < t < 1 − 2τ + 6λτ


 1 1
( 2 , − 2 , 0, 0) 1 − 2τ + 6λτ < t < 1 − 2τ + 10λτ = γ
(cf. Figure 7). It follows that


2
δ(f, t) =
3

1 < t < 1 − 2τ + 6λτ
1 − 2τ + 6λτ < t < λ

and thus if we let r = 1 − 2τ + 6λτ , then the minima of the exponentially λ-periodic14
function ∆(f, ·) occur at λk r for k ∈ Z. It follows that
δ(f) = ∆(f, r) = ∆(f, [λ−1 r, r])
3(1 − λ−1 r) + 2(r − 1)
r−1
=
=
3
−
r − λ−1 r
r − λ−1 r
6λτ − 2τ
=3−
−1
(1 − λ )(1 − 2τ + 6λτ )
= 3 − Θ(τ ),

where the implied constant of Θ can depend on λ. This completes the proof. Note that
as in §9, one can optimize over the parameter λ to get the best possible bound using
templates of this form, but we omit the required calculations.
12. P ROOF

OF

T HEOREM 3.8,

LOWER BOUND

We consider a two-parameter standard template f[τ, λ] (as in Definition 9.4). Fix 0 <
τ < 1/n, such that τ < m−1
if n = 1. Now if λ is sufficiently large, then (9.4)-(9.6) are
2m
13

Note that we form infinitely many periods when extending f backwards from 1 to 0, and so f now has
infinitely many intervals of linearity in [0, 1]. However, this does not cause any problems in what follows.
14
Meaning that ∆(f , λT ) = ∆(f , T ) for all T > 0.

44

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

F IGURE 7. A period of an exponentially equivariant 2 × 2 template, with
γ = 1 − 2τ + 10λτ . Here a template is called exponentially equivariant if it
is equal to a scaled copy of itself; the “period” is an interval which is long
enough to recover the template from this self-similarity property.

satisfied (the left half of (9.6) if n ≥ 2, and the right half if n = 1), and thus there is a
standard template f = fλ = f[τ, λ] defined by the sequence of points (tk , −εk )∞
0 , where
k
tk = λ and εk = τ tk .

def

Claim 12.1. Let g = s[(0, 0), (1, −τ )] (as in Definition 9.1). As λ → ∞, the upper average
contraction rate of fλ tends to
(12.1)
sup ∆(g, T ) = δ m,n (τ )
0<T ≤1

mn
mn 1 + mτ
= max mn − m, δm,n −
(d + m)τ, mn −
mn
m+n
m + n 1 − m−1
τ

def

!

.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

45

1
1
, . . . , n(d−1)
) on
Proof. Indeed, first let γ > 0 be small enough so that g′ = (− n1 , n(d−1)
(0, 2γ); the definition of g guarantees that such γ exists. Since fλ is exponentially λequivariant and since [γ, λγ] is a period of fλ we have

δ(fλ ) = sup ∆(fλ , T ).
T ∈[γ,λγ]

Next, we extend g to [0, ∞) by stipulating that g1′ = − n1 on [1, ∞) and then defining
g2 , . . . , gd on [1, ∞) in the same way as for standard templates (as in Definition 9.1).
Now since fλ′ → g′ almost everywhere as λ → ∞, it follows that ∆(fλ , ·) → ∆(g, ·)
uniformly on [γ, λγ], i.e. for every ε > 0 there exists λ0 such that for all λ ≥ λ0 we have
|∆(fλ , ·) − ∆(g, ·)| < ε on [γ, λγ]. Thus, we have that
lim δ(fλ ) = sup ∆(g, T ).

λ→∞

T ∈[γ,∞)

But since δ(g, t) = mn − m for all t ∈ [0, γ] ∪ [1, ∞), it follows that ∆(g, T ) ≤ max(mn −
m, ∆(g, 1)) = max(∆(g, γ), ∆(g, 1)) for all T ∈ [0, γ] ∪ [1, ∞), and thus
sup ∆(g, T ) = sup ∆(g, T ).
T ∈[γ,∞)

0<T ≤1

To complete the proof, we need to show that (12.1) holds, i.e. that sup0<T ≤1 ∆(g, T ) =
δ m,n (τ ). Indeed, from the definition of g, it follows that there exist intervals Ii = (ti , ti+1 ),
i = 0, 1, 2, with t0 = 0, t3 = 1, as follows:

I0

(g1′ , g2′ )

S+ (g, ·)

mn − δ(g, ·)

1
)
(− n1 , n(d−1)

{2, . . . , m + 1}

m

{3, . . . , m + 2}

2m

I1 (case 1) (− n1 , − n1 )

1
I1 (case 2) ( m1 , − m(d−1)
) {1, . . . , m}

I2
TABLE

0

( m1 , − n1 )
{1, 3, . . . , m + 1} m − 1
1. Two cases for the intervals of linearity of g. See Figure 8.

m−1
m−1
, while case 2 holds when τ ≤ n(d+m−1)
. (When
Here case 1 holds when τ ≥ n(d+m−1)
equality holds, I1 is empty and so the cases are compatible.) Now let 0 < T ≤ 1 be
maximal such that ∆(g, ·) attains its maximum at T . Then δ(g, t) ≥ ∆(g, T ) for t slightly
less than T , while δ(g, t) < ∆(g, T ) for t slightly greater than T . Thus T = ti for some
i = 1, 2, 3. But if case 1 holds, then ∆(g, t2 ) < mn − m = ∆(g, t1 ), so if T = t2 then case

46

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

F IGURE 8. The joint graph of g in Case 1 and Case 2, respectively. Note
that the slope of the last top segment may be either negative or positive
according to whether m < n or m > n, respectively (in the picture we have
m = n which corresponds to a horizontal slope).
2 holds. Now it can be checked by direct calculation15 that
∆(g, t1 ) = mn − m,

mn 1 + mτ
if case 2 holds,
mn
τ
m + n 1 − m−1
mn
(d + m)τ,
∆(g, t3 ) = δm,n −
m+n
∆(g, t2 ) = mn −

which implies (12.1), since if τ ≥
mn −

m−1
n(d+m−1)

then

1 + mτ
mn
≤ mn − m,
·
mn
τ
m + n 1 − m−1

and thus when case 1 holds, the last term on the right-hand side of (12.1) does not
contribute to the maximum16. This concludes the proof of the claim.

Applying the variational principle (Theorem 4.6) to fλ gives us that
dimP (Singm,n (τ )) ≥ lim δ(fλ ) = sup ∆(g, T ) = δ m,n (τ ).
λ→∞

15

0<T ≤1

The calculation of ∆(g, t3 ) is somewhat tedious and it is easier to use the equality case of Lemma 13.1
mn
below instead of performing a direct computation, since ψg (1) = m+n
(d + m)τ . Some other formulas
n
mn
useful for the calculations: when case 2 of Table 1 holds we have t1 = m+n
(1 + mτ ) and t2 = 1 − m−1
τ.
16
Note that when m = 1, case 1 holds for all τ ≥ 0 and thus again the last term on the right-hand side of
(12.1) can be ignored.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

47

This completes the proof of the lower bound in Theorem 3.8.

13. P ROOF

OF

T HEOREM 3.8,

UPPER BOUND WHEN

n≥2

To prove the upper bound when n ≥ 2 in Theorem 3.8, i.e. equality holds in (3.3), we
need a different definition of “potential energy” (cf. Section 8). Let f : [0, ∞) → Rd be a
balanced m × n template. For each t ≥ 0 let


mn2
mn
def
ψ(t) = ψf (t) = max
(m + 1)f1 (t) + (d − 1)f2 (t) ,
|fd (t)| .
m+n
m+n
Note that since f is balanced,
(m + 1)f1 (t) + (d − 1)f2 (t) ≤ (m + 1)f1 (t) + f2 (t) + . . . + fd (t) = mf1 (t) ≤ 0
and thus ψ(t) ≥ φ(t) ≥ 0 for all t ≥ 0. The analogous result to Lemma 8.1 is stated as
follows:
Lemma 13.1. Suppose that n ≥ 2. Let I be an interval of linearity for f such that ψ ′ (t) is
well-defined for all t ∈ I, and such that f(t) 6= 0 for all t ∈ I. Then
(13.1)

ψ ′ (t) ≤ δm,n − δ(f, t)

for t ∈ I. Equality holds in the following (non-exhaustive) cases:
1. when f1 < f2 = fd on I,
2. when f1 < f2 < f3 = fd , and f2′ = −1/n on I.
Note that there is no symmetry here, unlike in the proof of Lemma 8.1, since ψ is not
symmetric with respect to f 7→ −f.
Proof. The proof is similar to that of Lemma 8.1. We can suppose that
(13.2)

(m + 1)f1 (t) + (d − 1)f2 (t) ≥ n|fd (t)|

for t ∈ I, since otherwise ψ = φ on I and Lemma 8.1 implies the conclusion. Let j ≥ 2
be the largest number such that
f2 = fj on I.
Since I is an interval of linearity for f, we have fj < fj+1 on I. Let L± = L± (f, I, j) and
S± = S± (f, I). The proof now splits into two cases, first if f1 < f2 on I, and second if
f1 = f2 on I.

48

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Case 1: Suppose first that f1 < f2 on I. Let A± = L± (f, I, 1) and B± = L± − A± . By
(4.5), on I we have
j
m+n
−
L−
m
mn
m+n
1
−
A−
f1′ =
m
mn


mn
d−1 ′
′
′
′
ψ =−
(m + 1)f1 +
(F − f1 )
m+n
j −1 j
(m + d)n
d−1
=−
+ (m + 1)A− +
B−
d
j−1

Fj′ =

and on the other hand, by (4.11) we have




mn − δ(f, t) ≥ # S− ∩ {1} · # S+ ∩ (1, d] + # S− ∩ (1, j] · # S+ ∩ (j, d]
(13.3)
= mA− + B− (m − L+ )
and thus
δm,n − δ(f, t) ≥ mA− + B− (m − L+ ) −

mn
·
d

So to demonstrate (13.1), it suffices to show that
−n + (m + 1)A− +

d−1
B− ≤ mA− + B− (m − L+ ).
j−1

Rearranging gives the equivalent formulation

d−1
B− ≤ (n − A− ) + B− (m − L+ ).
j−1

If B− = 0 this is obviously true (and since n ≥ 2 by assumption, the inequality is strict
in this case), and therefore if we backtrack we get that (13.1) is true as well in this case.
Otherwise, assume that B− > 0. Then we can rearrange again to get
d−1
n − A−
≤
+ m − L+ ,
B+ + B−
B−
and subtracting 1 from both sides gives
(13.4)

(n − L− ) + (m − L+ )
n − L−
≤
+ m − L+ .
B+ + B−
B−

1
≤ min( B1− , 1), and so backtracking shows that (13.1) is
This formula is true since B+ +B
−
true as well. If f2 = fd on I, then j = d and thus L+ = m, L− = n and so equality holds
(in (13.4) and equivalently) in (13.1). Similarly, if f1 < f2 < f3 = fd and f2′ = −1/n on
I, then j = 2 and B+ = 0, so B− = B+ + B− = j − 1 = 1 and thus equality holds. This
completes the proof of Case 1.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

49

Case 2: Next suppose that f1 = f2 on I. Then on I we have
ψ′ = −

(m + d)n m + d
mn m + d ′
Fj = −
+
L−
m+n j
d
j

and on the other hand, as in (8.4) we have
δm,n − δ(f, I) ≥ L− (m − L+ ) −

(13.5)

mn
d

so to demonstrate (13.1), it suffices to show that
−n +

m+d
L− ≤ L− (m − L+ ).
j

If L− = 0 this is obvious (and the inequality is strict), so assume that L− > 0. Then
rearranging gives the equivalent formulation
2m + n
n
≤
+ m − L+ .
L+ + L−
L−
Write M+ = m − L+ and M− = n − L− . Then subtracting 1 from both sides gives
M−
L+ + 2M+ + M−
≤
+ M+
L+ + L−
L−

and multiplying by L+ + L− and rearranging gives
L+ ≤

(13.6)

M− L+
+ M+ (L+ + L− − 2).
L−

We now demonstrate (13.6). First, note that since L+ + L− = j ≥ 2, both terms on the
right-hand side are nonnegative. So if either term is individually at least L+ , then (13.6)
holds. In particular, if L− ≤ M− , then the first term is ≥ L+ , and if L− ≥ 2 and M+ ≥ 1,
then the second term is ≥ L+ . Also, if L+ = 0 then (13.6) obviously holds. So assume
that L+ > 0, that L− > M− , and that either L− ≤ 1 or M+ = 0.
If L− ≤ 1, then since L− > M− , we have M− = 0. But since n = L− + M− , this
contradicts our assumption that n ≥ 2.
If M+ = 0, then
j = L+ + L− > L+ +
and thus

n
d−j

>2>

m+d
.
j

L− + M−
2L+ + 2M+ + L− + M−
2m + n
=
=
2
2
2

Since f is balanced, this implies

nfd + (m + 1)f1 + (d − 1)f2 = nfd + (m + d)fj
≥

m+d
n
(fj+1 + . . . + fd ) +
(f1 + . . . + fj ) > 0,
d−j
j

50

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

contradicting (13.2). Thus neither L− ≤ 1 nor M+ = 0 can hold, and so (13.6) holds,
and backtracking yields (13.1). This completes our proof of Case 2, and thus completes
the proof of Lemma 13.1.

We are now ready to prove the upper bound in Theorem 3.8. Let f ∈ Singm,n (τ ), i.e.
|f1 (t)| ≥ τ t for all sufficiently large t, be a balanced template, and let T be a time such
that δ(T ) > mn − m. Note that this implies that 1 ∈ S+ (f, T ). Let T ′ be the largest
time such that f1′ = 1/m on (T, T ′ ). If T ′ > T , then the convexity condition implies that
f1 (T ′) = f2 (T ′ ). On the other hand, if T = T ′ , then f1′ (T ) < 1/m, and since 1 ∈ S+ (f, T ),
this implies that f1 (T ) = f2 (T ). So either way f1 (T ′ ) = f2 (T ′ ).
Let g : [0, T ′ ] → Rd be the standard template defined by the points (0, 0) and (T ′ , f1 (T ′ ))
(cf. Definition 9.1). Then f1 (T ) = g1 (T ) while f2 (T ) ≤ g2 (T ). Since f is balanced, using
the definition of g this implies that fd (T ) ≥ gd (T ). Consequently ψf (T ) ≥ ψg (T ) and
hence


−f1 (T ′ )
∆(f, T ) ≤ δm,n − ψf (T ) ≤ δm,n − ψg (T ) = ∆(g, T ) = δ m,n
.
T′
The first equality holds because for g defined as above, on each interval of linearity one
of the conditions 1,2 is satisfied (cf. Table 1), and the second equality is a restatement of
(12.1).
Thus for all T such that δ(T ) > mn − m, we have



−f1 (T ′ )
,
δ m,n
∆(f, T ) ≤ max mn − m, max
T ′ ≥T
T′
and it follows that the same is true for all T . Taking the limsup gives

δ(f) ≤ max mn − m, δ m,n (τ ) ,

where f ∈ Singm,n (τ ). Taking the supremum over all f and applying Theorem 4.8 completes the proof.

14. P ROOF

OF

T HEOREM 3.9

The proof is similar to that in Section 11. Assume n = 1. There are two cases to
and when τ < m12 .
consider, when 0 < τ < m−1
2m
. Fix λ > 1 and let tk = λk and εk = τ tk . However, rather
Case 1. Fix 0 < τ < m−1
2m
than letting f = f[τ, λ], we will introduce a new parameter γ > 0 (which we think of as
being independent of λ), small enough so that s[(γ, −ε), (1, −τ )] is well-defined for all

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

(γ, −ε)

51

(1, −τ )

F IGURE 9. The joint graph of f = s[(γ, −ε), (1, −τ )] with m = 2 and n = 1.
0≤ε≤

m−1
γ
2m

m−1
(it suffices to take γ ≤ m4m
2 −1 ( 2m − τ )). Let


τ + (λ − 1) m−1
2m
ε=
γ.
λ

We define f as follows:
• On [γ, 1], we have f = s[(γ, −ε), (1, −τ )] (cf. Figure 9 for an example with m = 2).
• Extend f to [1, γλ] via the requirements that f1′ = f2′ = − m−1
and f3 = . . . = fd on
2m
[1, γλ].
• Extend f to [0, ∞) via exponential equivariance. This is possible by the definition
of ε.
Now since δ(f, ·) = 1 on [1, γλ], we have
∆(f, γλ) ≥

γλ−1
·
γλ

52

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Taking the supremum over f and applying Theorem 4.8 yields
dimP (Singm,n (τ )) ≥

γλ−1
·
γλ

Taking λ → ∞ completes the proof.
< m1 . For each λ > 1 let
Case 2. Now suppose that τ < m12 , and let τ ′ = (m−1)τ
1−mτ
fλ = f[τ ′ , λ] be the standard 1 × m template defined by τ ′ and λ (as in Definition 9.4).
Claim 12.1 shows that
lim δ(fλ ) = δ1,m (τ ′ ) ≥ mn − n = m − 1.

λ→∞

Now the m × 1 template −fλ has the same upper average contractivity as fλ . Thus to
complete the proof, it suffices to show that
τ (−fλ ) = τ
for all sufficiently large λ. Indeed,
τ (−fλ ) = lim inf 1t fd (t) =
t→∞

1
f (t ),
t0 d 0

2
2
where t0 > 1 is the smallest time such that f2 (t0 ) = f3 (t0 ). Since f(1) = (−τ, −τ, m−1
τ, . . . , m−1
τ)
1
1
1
′
and f = (− m , 1, − m , . . . , − m ) on (1, t0 ) (cf. Figure 10), we have that

fd (t0 ) = −τ ′ + (t0 − 1) =

2
τ′
m−1

−

1
(t
m 0

− 1).

Thus
t0 = 1 +
fd (t0 ) =
τ (−f(λ)) =

m
τ′
m−1

1
τ′
m−1
1
τ′
fd (t0 )
= m−1m ′ = τ.
t0
1 + m−1 τ

This completes the proof in the case τ < m12 .
and τ = m12 as exercises for the reader.
Finally, we leave the equality cases τ = m−1
2m
Specifically, one glues together partial templates corresponding to a sequence of values
τk → τ to get a template which is τ -singular but has the desired packing dimension
property.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

53

(t0 , fd (t0 ))
(λ, −τ ′ λ)
(1, −τ ′ )

F IGURE 10. The joint graph of fλ = f[τ ′ , λ] on the interval [1, λ], as in
Definition 9.4.
15. P ROOF

OF

T HEOREM 3.6,

LOWER BOUND FOR

H AUSDORFF

DIMENSION

Assume n ≥ 2, and fix 0 < τ < n1 . As in Section §12 we consider a two-parameter
standard template f[τ, λ] (as in Definition 9.4). Now if λ is sufficiently large, then (9.4)(9.6) are satisfied, and thus there is a standard template f = fλ = f[τ, λ] defined by the
k
sequence of points (tk , −εk )∞
0 , where tk = λ and εk = τ tk .
Modifying the proof of Claim 12.1 yields
lim δ(fλ ) = inf ∆(g, T ),
0<T ≤1

λ→∞
def

where g = s[(0, 0), (1, −τ )] (as in Definition 9.1). Applying the variational principle (Theorem 4.6) to fλ gives us that
dimH (Singm,n (τ )) ≥ inf ∆(g, T ).
0<T ≤1

Now δ(g, t) ≥ mn − 2m for all t, and δ(g, t) ≥ mn − m for all t ≤ n(d−1)
[ n1 − τ ]. It follows
d
that


mn(d − 1) 1
−τ
∆(g, T ) ≥ mn − 2m +
d
n
for all 0 < T ≤ 1.
16. P ROOF

OF

T HEOREM 3.7,

Assume n = 1, and fix 0 < τ <
(16.1)

LOWER BOUND FOR

m−1
,
2m

H AUSDORFF

DIMENSION

and let λ be minimal such that (9.6) holds, i.e.
−1
def
−
τ
.
λ = 1 + dτ2 m−1
2m

As usual we let tk = λk , εk = τ tk , and f = f[τ, λ].

54

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Fix t ≥ 0. If δ(f, t) = 0, then S− (f, t) = {1} and thus f1′ (t) = −1, while if δ(f, t) ≥ 1
then we have the trivial bound f1′ (t) ≤ m1 . Combining these two results into one formula
yields
δ(f, t) for all t.
f1′ (t) ≤ −1 + m+1
m
Thus
< −τ = f1 (1) ≤ −1 +
− m−1
2m

m+1
∆(f, 1),
m

and rearranging gives
∆(f, 1) > 21 .
1
1
It follows that ∆(f, T ) ≥ 2T
≥ 2λ
for all T ∈ [1, λ]. The exponential equivariance of f
1
then implies that ∆(f, T ) ≥ 2λ for all T > 0. So

1
= 12 − Θ m−1
−τ
δ(f) ≥ 2λ
2m
(16.1)

and applying Theorem 4.8 completes the proof.

17. P ROOF

OF

T HEOREM 3.6,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a τ -singular template which is not trivially singular, i.e. |f1 (t)| ≥ τ t for all
sufficiently large t, and fj+1(t) − fj (t) 9 ∞ as t → ∞ for all j = 1, . . . , d − 1. Then
there exists a constant C such that f2 (T ) ≤ f1 (T ) + C infinitely often. Fix T such that
f2 (T ) ≤ f1 (T ) + C. Since f is τ -singular, we have f2 (T ) ≤ f1 (T ) + C ≤ −τ T + C.
Since 1, 2 ∈ S− (f, t)
For all t such that f1′ (t) = f2′ (t) = − n1 , we have
mn − δ(f, t) ≥ 2m
and for all t such that fi′ (t) > − n1 for some i = 1, 2, we have


1
1
n
m+n
1
′
=− +
−
fi (t) ≥
n+1 m n
n mn(n + 1)
and thus

m+n
2
+
n mn(n + 1)
and at the same time mn − δ(f, t) ≥ 0. Combining these two cases we have


2m2 n(n + 1) 2
′
′
mn − δ(f, t) ≥ 2m −
+ f1 (t) + f2 (t)
m+n
n
f1′ (t) + f2′ (t) ≥ −

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

55

and averaging over the interval [0, T ] gives



2m2 n(n + 1) 2 f1 (T ) f2 (T )
mn − ∆(f, T ) ≥ 2m −
+
+
m+n
n
T
T


2
4m n(n + 1) 1
C
≥ 2m −
.
−τ +
m+n
n
2T

Taking the liminf as T → ∞ and applying Theorem 4.8 completes the proof.
18. P ROOF

OF

T HEOREM 3.7,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a τ -singular m × 1 template, i.e. |f1 (t)| ≥ τ t for all sufficiently large t. The
proof spilts in two cases.
Case 1. First suppose that both f1 = f2 and f2 = f3 infinitely often.
Fix T1 > 0 such that f2 (T1 ) = f3 (T1 ), and let T ≥ T1 be minimal such that f1 (T ) =
− τ > 0. For each t, let j(t) denote the unique element of S− (f, t).
f2 (T ). Let x = m−1
2m
Then

= 1 − 1
j(t) = 1, 2
m
′
′
f1 (t) + f2 (t)
≥ 1 − 1 + α j(t) > 2
m

where α > 0 is a constant. On the other hand,

1
1
− 1 + 2x.
f1 (T ) + f2 (T ) ≤ −2τ =
T
m
It follows that
λ({t ≤ T : j(t) > 2}) = O(xT )

where λ is Lebesgue measure. Consequently fi (t) = mt + O(xT ) for all i > 2 and t ∈ [0, T ].
On the other hand, since f2′ ≥ −1 it follows that for t ∈ [0, T ] we have


m+1
m−1
−x T +T −t=
T − t + O(xT ),
f2 (t) ≤ f2 (T ) + T − t ≤ −
2m
2m
and thus we have f2 < f3 for all t ∈ I := (T /2 + cxT, T ), where c > 0 is a constant. In
particular we have T1 ≤ T /2 + cxT . By the minimality of T , it follows that f1 < f2 on
I. Using the convexity condition it is possible to prove that j(t) = 2 for all t ∈ I. Thus
f1′ = m1 on I and thus
f1 (T /2) = f1 (T ) −

1
(T /2)
m

+ O(xT ) ≤ −τ T −

1
(T /2)
m

+ O(xT ) = −(T /2) + O(xT ).

Consequently,
(18.1)

λ({t ≤ T /2 : j(t) > 1}) = O(xT )

and thus ∆(f, T /2) = O(xT ).

56

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Case 2a. Now if f1 < f2 for all sufficiently large times, then it follows from the
convexity condition that j(t) = 1 for all sufficiently large times, and thus δ(f) = 0.
Case 2b. If f2 < f3 for all sufficiently large times, then it follows from the convexity
condition that j(t) ≤ 2 for all sufficiently large times, and thus
2f1 (t) ≤ f1 (t) + f2 (t) = −

m−1
t+C
m

for some constant C. This demonstrates that τ ≥ m−1
. Since equality holds infinitely
2m
m−1
m−1
often, we have τ = 2m . Thus for τ < 2m , we have f2 = f3 infinitely often.
19. P ROOF

OF

T HEOREM 3.7,

UPPER BOUND FOR PACKING DIMENSION

Let T1 > 0 be a local maximum of ∆(f, ·), and by contradiction suppose that ∆(f, T1 ) >
1. Then δ(f, I) > 1, where I is the interval of linearity for f whose right endpoint is T1 .
Equivalently, j > 2 on I, where j is as in §18. Let T be as in §18. Since f1 < f2 on
(T1 , T ), by the convexity condition we have j > 1 on (T1 , T ) and thus by (18.1) we have
T1 = T /2 + O(xT ). But then by the argument of §18, we have
∆(f, T1 ) = ∆(f, T /2) + O(x) = O(x)
and thus if x is sufficiently small, then ∆(f, T1 ) < 1, a contradiction.
20. P ROOF

OF

T HEOREM 3.10

Note that the packing dimension formula in Theorem 3.10 follows immediately from
Theorem 3.8. Thus, we prove only the Hausdorff dimension formula. However, note that
the first part of the proof could apply to the computation of packing dimension as well.
Fix τ > 0, and let f be a 1 × 2 template which satisfies τ (f) = τ but is not trivially
singular. We claim that
(20.1)

δ(f) ≤ δ(τ ),

where δ(τ ) is the right-hand side of the first formula of Theorem 3.10. This will prove
the upper bound of that formula. Indeed, since f is not trivially singular, the sets F− =
{t ≥ 0 : f1 (t) = f2 (t)} and F+ = {t ≥ 0 : f2 (t) = f3 (t)} are both unbounded. Since f is
piecewise linear, we can write F− ∪ F+ as the union of a sequence of intervals [s1 , t1 ] <
[s2 , t2 ] < . . .
Claim 20.1. We can assume without loss of generality that
F+ = [s1 , t1 ] ∪ [s3 , t3 ] ∪ . . . and F− = [s2 , t2 ] ∪ [s4 , t4 ] ∪ . . .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

57

Proof. First, since F− and F+ are disjoint, for each k we have either [sk , tk ] ⊆ F− or
[sk , tk ] ⊆ F+ . Now let g : [0, ∞) → R3 be defined by the formulas


1
1

−
f
if t ∈ (tk , sk+1), [sk , tk ], [sk+1 , tk+1] ⊆ F−
3 (t), − 2 f3 (t), f3 (t), . . . , f3 (t)

2


g(t) =
if t ∈ (tk , sk+1), [sk , tk ], [sk+1 , tk+1] ⊆ F+
f1 (t), − 21 f1 (t), . . . , − 21 f1 (t)



f(t)
otherwise.

Then δ(g, t) ≥ δ(f, t) for all t ≥ 0, so δ(g) ≥ δ(f) and δ(g) ≥ δ(f). Moreover, since the
minima of the functions
−g1 (t)
−f1 (t)
and t 7→
t 7→
t
t
on an interval of the form [tk , sk+1] are always attained at one of the endpoints of the
interval, we have τ (g) = τ (f). So it suffices to prove (20.1) with f replaced by g. Now
the corresponding sets F− and F+ defined in terms of g are clearly of the desired form,
with the exception that the roles of F− and F+ may be switched; this exception can be
dealt with by truncating the template from the left so as to cut out the interval [s1 , t1 ]. 

We observe that f1 and f2 “split” at times t2k and “merge” at times s2k , while f2 and f3
“split” at times t2k+1 and “merge” at times s2k+1 . Consequently
′ +
f1′ (t+
2k ) < f2 (t2k ),

′ +
f2′ (t+
2k+1 ) < f3 (t2k+1 ),

′ −
f1′ (s−
2k ) > f2 (s2k ),

′ −
f2′ (s−
2k+1 ) > f3 (s2k+1 ).

It follows that if j(t) denotes the unique element of S+ (f, t), then
−
j(s+
2k ) = j(t2k ) = 1,

−
j(t+
2k ) = j(s2k+1 ) = 2,

−
j(s+
2k+1 ) = j(t2k+1 ) = 2,

Thus by the convexity condition,
s2k+2 such that













′
f (t) =













−
j(t+
2k+1 ) = 3 > j(s2k+2 ) = 1.

there exists sequences of numbers t2k+1 < ak ≤ rk <
− 21 , 1, − 21

− 12 , 41 , 41

− 12 , − 12 , 1






1

− 12 , 1, − 2

1, − 12 , − 12

1 1
1
,
,
−
4 4
2

(cf. Figure 11). Evidently, we have

t2k < t < s2k+1
s2k+1 < t < t2k+1
t2k+1 < t < ak
ak < t < rk
rk < t < s2k+2
s2k+2 < t < t2k+2

58

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

t2k s2k+1 t2k+1

s2k+2

ak rk

t2k+2

F IGURE 11. A piece of an arbitrary 1 × 2 template.


1




0
δ(f, t) = 3 − j(f, t) =


1




2

t2k < t < t2k+1
t2k+1 < t < ak
ak < t < rk
rk < t < t2k+2 .

Now let Ak , Bk , Ck , Dk ∈ R be chosen so that

f1 (t) = Ak − 21 t for all t ∈ [t2k , rk ],
f1 (t) = Bk + t for all t ∈ [rk , s2k+2],
f3 (t) = Ck + t for all t ∈ [t2k+1 , ak ],

f3 (t) = Dk − 12 t for all t ∈ [ak , s2k+3].
Then the set of parameters



Ak , Bk , Ck , Dk



k∈N

is a necessary and sufficient set of parameters for f in the following sense: the map
sending f to this set of parameters is injective, and its image is the set of all sequences of

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

59

parameters that satisfy the following inequalities:
(20.2)
(20.3)

sk ≤ tk < sk+1,
t2k+1 < ak ≤ rk < s2k+2

where sk , tk , ak , rk are defined by the equations
(20.4)
(20.5)
(20.6)
(20.7)
(20.8)
(20.9)

0 = (Ak − 12 rk ) − (Bk + rk )

0 = (Ck + ak ) − (Dk − 12 ak )


0 = 2 Ak − 12 t2k + Dk−1 − 12 t2k


0 = 2 Bk + s2k+2 + Dk − 21 s2k+2


0 = Ak − 12 t2k+1 + 2 Ck + t2k+1


0 = Ak − 12 s2k+1 + 2 Dk−1 − 12 s2k+1

The idea now is to take a function f defined by a sequence of parameters satisfying
(20.2)-(20.3), and to replace it by a function e
f defined by a sequence of parameters


ek , B
ek , C
ek , D
ek
A
.
k∈N

If we can show that ∆(e
f, T ) ≥ ∆(f, T ) for all T , while τb(e
f) = τb(f), then it suffices to
e
prove (20.1) for f . A change that satisfies this inequality will be called an allowable
change. Note that if a change only affects the value of δ(f, ·) on two intervals I1 , I2 such
that max(I1 ) < min(I2 ), increasing it on I1 and decreasing it on I2 , with greater total area
for the effect on I1 , then the change is allowable. We now show that we can make some
allowable changes to simplify the structure of the template f.
Claim 20.2. We can without loss of generality assume that ak = rk for all k.

Proof. We claim that decreasing Ck by ε while leaving all other parameters fixed is an
allowable change. Indeed, this change will have the effect of increasing t2k+1 by 34 ε while
increasing ak by 23 ε. This means that δ(f, ·) is increased by 1 on an interval of length 34 ε
around t2k+1 , but decreased by 1 on an interval of length 23 ε around ak . Thus, the change
is allowable, and applying the maximum value of ε = 32 (rk − ak ) completes the proof. 
From now on we will not treat Ck as an independent parameter, but rather assume that
it is given by (20.5) together with the formula ak = rk . Note that in this case, (20.4),
(20.5), and (20.8) combine to form the equation


(20.10)
0 = Ak − 21 t2k+1 + 2 Dk − Ak + Bk + t2k+1 .

60

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Claim 20.3. The following set of parameter changes is allowable:
ek = Ak + ε
A

ek−1 = Bk−1 + ε
B

e k−1 = Dk−1 − ε
D

Proof. These changes lead to the following changes to tk , rk :
•
•
•
•
•

no change to t2k−1
decrease rk−1 by 23 ε (thus increasing δ(f, ·) by 2 on an interval of this length)
increase t2k by 32 ε (thus increasing δ(f, ·) by 1 on an interval of this length)
increase t2k+1 by 23 ε (thus increasing δ(f, ·) by 1 on an interval of this length)
increase rk by 32 ε (thus decreasing δ(f, ·) by 2 on an interval of this length)

The changes to sk can be ignored as they do not affect δ(f, ·), except to note that ∆sk =
sek − sk is always negative and so e
tk − sek ≥ tk − sk ≥ 0. The only decreasing effect, due to
the change on rk , is dominated by the increasing effect due to the change on rk−1 . Thus
the changes are allowable.

Now for each k, choose the maximum value of ε such that the changes lead to parameters satisfying (20.2)-(20.3) as well as the inequality
f1 (t) ≤ −τ t for all t,
where τ < τb(f) is arbitrary. Note that by piecewise linearity, this inequality is equivalent
to saying that for all k we have
f1 (t2k ) ≤ −τ t2k .

(20.11)

Then after the changes, (20.11) will be satisfied with equality for every k. Equivalently,
Ak − 12 t2k = −τ t2k .

(20.12)
Let uk = t2k , and note that

f(uk ) = (−τ uk , −τ uk , 2τ uk ) .
This equality implies that for each k, we can define a template g(k) by letting g(k) = f on
[uk , uk+1] and then extending by exponential equivariance:
g(k) (λt) = λg(k) (t) where λ = uk+1/uk .
Note that clearly, τ (g(k) ) = τ for all k. From now on we will specialize to the Hausdorff
dimension case of Theorem 3.10.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

61

Claim 20.4. We have
δ(f) ≤ sup δ(g(k) ).

(20.13)

k

Proof. Fix ε > 0. Then there exist infinitely many k such that ∆(f, uk+1 ) ≥ ∆(f, uk ) − ε.
For such a k, we have
∆(g(k) , uk ) = ∆(f, [uk , uk+1]) ≥ ∆(f, uk ) − O(ε)
since uk+1 /uk is bounded away from 1. Thus
inf

T ∈[uk ,uk+1 ]

∆(f, T ) ≤

inf

T ∈[uk ,uk+1 ]

∆(g(k) , T ) + O(ε) = δ(g(k) ) + O(ε).

Taking the liminf over k and then letting ε → 0 gives (20.13).



Thus, we can without loss of generality assume that f is exponentially equivariant, i.e.
that
(20.14)

Ak = λk A,

Bk = λk B,

Dk = λ k D

for some A, B, D > 0 and λ > 1. Now by rescaling, we can without loss of generality
assume that u0 = 1. Plugging k = 0 into the formulas (20.4)-(20.9), (20.10), and
(20.12), and solving for the appropriate variables yields
A=

1
2

−τ

D = λ( 23 − 2A) = λ( 21 + 2τ )
t0 = 1
s1 = 32 (A + 2λ−1 D) = 2 − 2A = 1 + 2τ
t1 = 23 (A − 2D − 2B)

r0 = 32 (A − B)

s2 = − 32 (2B + D)
t2 = λ.
On the interval [u0 , u1 ] = [1, λ], the behavior of δ(f, ·) is as follows:



1 1 < t < t1
(20.15)
δ(f, t) = 0 t1 < t < r0



2 r0 < t < λ.

e = B − ε. This change increases t1 by 4 ε and increases r0 by
Now consider the change B
3
2
4
ε, this increasing δ(f, ·) by 1 on an interval of length 3 ε around t1 and decreasing δ(f, ·)
3

62

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

t2k s2k+1

rk

t2k+1

t2k+2

F IGURE 12. A period of an exponentially periodic 1 ×2 template, simplified
using the arguments of this section.

by 2 on an interval of length 23 ε around r0 . Thus the change is allowable, and by taking
the maximum possible value of ε = 43 (t2 − s2 ), we can without loss of generality assume
that s2 = t2 , or equivalently that
B = − 43 λ − 12 D = λ(A − 23 ) = −λ(1 + τ )
(cf. Figure 12). Note that this implies
t1 = 32 A + 34 λA.
Now it is a problem of one-variable calculus: λ is the only free parameter, and we must
optimize δ(f). Note that λ is subject to the restriction
λ≥

3/2 − 2A
1/2 + 2τ
=
A
1/2 − τ

which comes from the inequality s1 ≤ t1 . Now from (20.15), we have
δ(f) = ∆(f, r0 ) = ∆(f, [λ−1 r0 , r0 ]) =

1(t1 − 1) + 2(1 − λ−1 r0 )
·
r0 − λ−1 r0

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

63

On the other hand,
t1 = 32 A + 43 λA,

r0 = 32 A − 32 λA + λ.

Let x = τ and y = 31 (λ − 1). Then
t1 = ( 13 − 23 x)(3 + 6y) = (1 − 2x)(1 + 2y),

r0 = 1 + 3y − ( 31 − 32 x)(3y) = 1 + (2 + 2x)y,

λ(t1 − 1) + 2(λ − r0 )
r0 (λ − 1)
(1 + 3y)(−2x + (2 − 4x)y) + (2 − 4x)y
=
(1 + (2 + 2x)y)(3y)
2
def 2 −x + (2 − 7x)y + (3 − 6x)y
= fx (y) = ·
·
3
y + (2 + 2x)y 2

δ(f) =

x
, ∞), assuming
We now need to find the maximum of the function fx on the interval [ 1/2−x
that 0 < x < 1/2. The function fx has two critical points, given by the formulas17

0 = x + (4x + 4x2 )y + (−1 + 4x + 14x2 )y 2
√
x
ε x − 6x3 + 4x4 + 2x + 2x2
= √
y=
2
3
1 − 4x − 14x
ε x − 6x + 4x4 − 2x − 2x2
8
4 4 √
fx (y) = − ε x − 6x3 + 4x4 − 2x + x2
3 3
3
where ε = ±1. Note that since the critical point corresponding to ε = −1 is negative, it
is not in the domain and so can be ignored. The critical point corresponding to ε = +1
√
2−2
is positive if and only if 1 − 4x − 14x2 > 0, which in turn is true if and only if x < 3 14
.
In this case, it is easy to check that this critical point is in the domain of fx , and that the

17

Note that we found it easier to do these calculations first for the general case
f (y) =

−A + By + Cy 2
,
Dy + Ey 2

then plug in the values A = x, B = 2 − 7x, C = 3 − 6x, D = 1, and E = 2 + 2x, and finally multiply by 23 .
In the general case the formulas are
0 = AD + 2AEy − (BE − CD)y 2
√
ε Q + AE
AD
y=
= √
where Q = (AE)2 + (AD)(BE − CD)
BE − CD
ε Q − AE
p

1
f (y) = 2 2AE + BD − 2ε A2 E 2 + ABDE − ACD2 .
D

64

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

critical point is a maximum. Thus in this case
4 4√
8
sup fx (y) = fx (ycrit) = −
x − 6x3 + 4x4 − 2x + x2 .
3 3
3
y
√

2−2
, then this critical point is negative or undefined, and thus
On the other hand, if x ≥ 3 14
fx has no critical points on its domain. It can be verified that fx is increasing in this case,
so its supremum is equal to its limiting value:

sup fx (y) = lim fx (y) =
y

y→∞

2 3 − 6x
1 − 2x
·
=
·
3 2 + 2x
1+x

Since δ(f) ≤ supy fx (y), this completes the proof of the upper bound. To prove the lower
x
bound, note that if y ∈ [ 1/2−x
, ∞), then there is a unique exponentially periodic template
f satisfying the formulas appearing in the above proof, and this template satisfies δ(f) =
fx (y). Thus dimH (Sing1,2 (ω)) ≥ fx (y), and taking the supremum over y proves the lower
bound. Note that the exponentially periodic template f is the same as the standard
template defined by the sequence of points (tk , −εk ) = (λk , −τ λk ), where τ = x and
λ = 1 + 3y.
21. P ROOF

OF

T HEOREM 3.11

Let f be a template, and let φ be as in §8. We claim that
mn
g(t),
φ′ (t) ≤ δm,n − δ(f, t) +
m+n
where g(t) = 1 if f(t) = 0 and g(t) = 0 otherwise. Indeed, when f(t) 6= 0, this follows
from Lemma 8.1, and when f(t) = 0 it follows from direct calculation using the fact that
φ′ (t) = 0 and δ(f, t) = mn. Now fix T > 0. Integrating over [0, T ] gives



ˆ T
mn
mn
0 .+ φ(T )−φ(0) ≤
δm,n − δ(f, t) +
g(t) dt = T δm,n − ∆(f, T ) +
G(T ) ,
m+n
m+n
0
where G(T ) is the average of g on [0, T ]. It follows that


mn
mn
δ(f) ≤ lim sup δm,n +
G(T ) = δm,n +
lim sup G(T ) = P(f)δm,n +(1−P(f))mn,
m+n
m + n T →∞
T →∞
where
def

P(f) = lim inf (1 − G(T ))
T →∞

is the proportion of time spent near infinity. Applying Theorem 4.6 gives
dimH ({A : P(A) = p}) ≤ dimP ({A : P(A) = p}) ≤ pδm,n + (1 − p)mn.
For the reverse direction, fix p and ε > 0 small. Define f on [1, 1 + ε] as follows:

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

65

• Let f = g[(0, 0), (1 + pε, 0)] on [1, 1 + pε]
• Let f(t) ≡ 0 on [1 + pε, 1 + ε]
and extend by exponential equivariance. It is easy to see that P(f) = p and
dimP (D(f)) ≥ dimH (D(f)) ≥ pδm,n + (1 − p)mn − O(ε).
This completes the proof.
22. P ROOF

OF

T HEOREM 3.12

Let φ be a function such that φ(t) → ∞ as t → ∞, and without loss of generality
suppose that φ is increasing. Let (tk , −εk ) be a sequence of points such that:
(i)
(ii)
(iii)
(iv)

∆tk ≤ 12 φ(tk ) for all k;
εk ≤ 12 φ(tk ) for all k;
εk → ∞ as k → ∞;
εk /∆tk → 0 and εk+1/∆tk → 0 as k → ∞.

Then let f be the standard template defined by the sequence of points (tk , −εk ). Conditions (i) and (ii) imply that f1 (t) ≥ −φ(tk ) ≥ −φ(t) for all k ∈ N and t ∈ [tk , tk+1 ].
Condition (iii) implies that f is singular. Finally, condition (iv) implies that δ(f) = δm,n ,
since
 
 
 
εk+1
εk
, 0, −
,1
∆(f, [tk , tk+1 ]) = ∆ s 0, −
∆tk
∆tk
→ ∆(s[(0, 0), (1, 0)], 1) = δm,n as k → ∞.

23. P ROOF

OF

T HEOREM 3.14

Fix 2 ≤ k ≤ d − 1 and j ∈ {k − 1, k}, and let f be a template with the following
properties:
(23.1)

fk−1 (t) → −∞ as t → ∞,

(23.2)

fk+1 (t) → +∞ as t → ∞,

(23.3)
(23.4)

1
f(t) → 0 as t → ∞,
t

1
λ [0, T ] ∩ (Sj+ ∪ Sj− ) → 1 as T → ∞,
T

where Sj+ (resp. Sj− ) is the set of all times t ≥ 0 such that the following hold:
• f1 (t) = . . . = fj (t) < fj+1 (t) = . . . = fd (t),
⌉, ⌊ jn
⌋) (resp. (L+ , L− ) = (⌊ jm
⌋, ⌈ jn
⌉)), where L± = L± (f, t, j).
• (L+ , L− ) = (⌈ jm
d
d
d
d

66

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Such a template can be constructed by alternating long Sj± intervals with short intervals
along which fk crosses 0 and returns, in a manner consistent with the rule on changes of
slopes (cf. Figure 13). The key point is that if t ∈ Sj+ then f1′ (t) ≥ 0, but if t ∈ Sj− then
is an integer). Note that the template f is not
f1′ (t) ≤ 0 (with equality if and only if jm
d
trivially singular.

F IGURE 13. A piece of a template f with the desired properties, as described in §23 (Proof of Theorem 3.14). The triangular portion of the figure
can be made arbitrarily small in proportion to the rest.

To compute the lower contractivity of f, we observe that for t ∈ Sj+ , we have
"
#
jm
jn
⌉
⌋
⌈
⌊
1
def
d
f1′ (Sj+ ) = f1′ (t) =
− d
j
m
n
"
#
jm
jn
jm
jn
+
{−
}
−
{
}
1 d
d
d
− d
=
j
m
n
 
1 m + n jn
=
j mn
d
 


jn
jm
+ def
mn − δ(f, Sj ) = mn − δ(f, t) = L− (m − L+ ) =
m−
d
d

  


jm
jn
jm
jn
m−
−
− −
=
d
d
d
d
   2
jn
j(d − j)mn (d − j)m + jn jn
+
.
−
=
2
d
d
d
d

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Similarly, for t ∈ Sj− we have
def
f1′ (Sj− ) =

mn −

def
δ(f, Sj− ) =

f1′ (t)

1m+n
=−
j mn



jm
d



j(d − j)mn (d − j)m + jn
mn − δ(f, t) =
+
d2
d

On the other hand, for t ∈
/ Sj+ ∪ Sj− we have − n1 ≤ f1′ (t) ≤
is an integer, then by (23.4) we have

1
m



jm
d



+

67



jm
d

2

.

and 0 ≤ δ(f, t) ≤ mn. If

jm
d

δ(f, Sj+ ) = δ(f, Sj− ) = fm,n (j)
and we are done. Otherwise, by (23.3) and (23.4) we have

1
λ [0, T ] ∩ Sj± → α± as T → ∞,
T
where α+ + α− = 1 and
α+ f1′ (Sj+ ) + α− f1′ (Sj− ) = 0.
It follows that
+

α =



jm
d



−

,

α =



jn
d



,

and thus
δ(f) = α+ δ(f, Sj+ ) + α− δ(f, Sj− ) = fm,n (j).
This completes the proof.
24. P ROOF

OF

T HEOREM 4.2

Part (i) follows directly from Lemma 31.8, since we can take Λ = uA Zd where A
is the matrix in question. To prove part (ii), consider the template f that we need to
approxiomate by a successive minima function hA . If δ(f) > 0, then by Theorem 4.6, the
packing dimension of D(f) is positive and thus D(f) is nonempty. If we take A ∈ D(f),
then hA ≍+ f. On the other hand, suppose that δ(f) = 0, and consider the set
Z = {t ≥ 0 : ∆(f, t) > 0}
Then the density of Z is zero, i.e. limT →∞ T1 |Z ∩ [0, T ]| = 0, where | · | denotes 1dimensional Lebesgue measure. On the other hand, for all t ∈
/ Z we must have f ′ (t) =
(− n1 , . . . , − n1 , m1 , . . . , m1 ). It follows that fn (t) < fn+1 (t) for all sufficiently large t. Then
the convexity and quantized slope conditions (see Definition 4.1) imply that Fn must
be piecewise linear with only finitely many intervals of linearity. Now it follows, using

68

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

the fact that Z has zero density, that Fn′ (t) = −1 for all sufficiently large t, which in
turn implies that f(t) ≍+ (− n1 , . . . , − n1 , m1 , . . . , m1 )t. Now there exist matrices A such that
hA (t) ≍+ (− n1 , . . . , − n1 , m1 , . . . , m1 )t (for example, matrices with rational entries) and so
this completes the proof.
25. P ROOF

OF

T HEOREM 4.10

A matrix A is badly approximable if and ony if its successive minima function hA is
bounded. Thus, by Theorem 4.6, the Hausdorff dimension of the set of badly approximable matrices is equal to the supremum of δ over bounded templates. Since δ(0) = mn
and δ(f) ≤ mn for all templates f, this supremum is equal to mn.
26. P ROOF

OF

T HEOREM 4.11

Analogously to the uniform dynamical exponent, we define the regular (non-uniform)
dynamical exponent of a map f : [0, ∞) → Rd to be the number
def

τ (f) = lim sup
t→∞

−1
f1 (t).
t

Now let f be a template with τ (f) = τ ∈ [0, n1 ] and consider the potential function
φ(t) = φf (t) = mn|f1 (t)|.
Lemma 26.1. Let I be an interval of linearity for f. Then
φ′ (I) ≤ mn − δ(I),
with equality in the following cases:
• f = 0 on I
• f1′ = − n1 and f2 = fd on I.
Proof. Let j be the largest value such that f1 = fj on I, and let L± = L± (f, I, j). Then


1 L− L+
′
−
φ (I) = mn
j n
m
while
mn − δ(I) ≥ L− (m − L+ ).
So we need to show that
1
[mL− − nL+ ] ≤ L− (m − L+ ).
j

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

69

Indeed, since L− ≤ n and j ≥ 1, we have

1
1
1
[mL− − nL+ ] ≤ [mL− − L− L+ ] = L− (m − L+ ) ≤ L− (m − L+ ).
j
j
j

Equality holds when L+ = m and L− = n, and when L+ = 0 and L− = 1.

⊳

Integrating gives
φ(T ) = mn|f1 (T )| ≤ T (mn − ∆(T )).
Dividing by T and then taking the limsup gives
mnτ ≤ mn − δ(f).
Rearranging gives
δ(f) ≤ mn(1 − τ ).
Thus, by Theorem 4.6, we have
dimH ({ω-approximable matrices}) = sup δ(f) ≤ mn(1 − τ ).
f :τ (f )=τ

Let us now show the reverse inequality. For each λ > (1 + τ /m)/(1 − τ /n), let fλ be
as in Figure 14, i.e. fλ is exponentially λ-periodic and fλ,1 is maximal with respect to the
restriction fλ,1 (1) = −τ . Then τ (fλ ) = τ , while δ(fλ ) = mn(1 −τ )/(1 −λ−1 ). So as λ → ∞,
we have δ(fλ ) → mn(1 − τ ) and the proof is complete.

F IGURE 14. The joint graph of fλ as described above.

70

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Part 3. Dimension games
27. P RELIMINARIES

ON MEASURES AND DIMENSIONS

We first recall the basics of Hausdorff and packing measures and dimensions, [7, 28].
Hausdorff measure and dimension were introduced in 1918 by Hausdorff [33], while
packing measure and dimension were introduced by Tricot in 1982 [65]. Sullivan independently re-invented packing measures and dimensions when studying the limit sets of
geometrically finite Kleinian groups in 1984 [64].
The s-dimensional Hausdorff measure of a set A ⊆ RD is
(∞
)
∞
(U
)
is
a
countable
cover
of
A
X
i
1
def
H s (A) = sup inf
(diam(Ui ))s :
·
ε>0
with diam(Ui ) ≤ ε ∀i
i=1
Dual to the Hausdorff measure, which is defined via economical coverings by small balls,
it is natural to define a measure in terms of dense packings by small disjoint balls. This
leads to the notion of the s-dimensional packing measure of a set A ⊆ RD , which is defined
as
(∞
)
∞
X
[
def
fs (Ai ) : A ⊆
P s (A) = inf
P
Ai ,
i=1

where

def

fs (A) = inf sup
P
ε>0

(

∞
X

(diam(Bj ))s :

j=1

i=1

)
(Bj )∞
1 is a countable disjoint collection of balls
with centers in A and with diam(Bj ) ≤ ε ∀j

·

Given the measures defined above, we define the Hausdorff dimension and packing dimension of a set A ⊆ RD as follows:
def

dimH (A) = inf{s : H s (A) = 0} = sup{s : H s (A) = ∞}
def

dimP (A) = inf{s : P s (A) = 0} = sup{s : P s (A) = ∞}.
We recall two basic facts (see [28, § 3.2 and § 3.5]) about these dimensions. First, they
are both monotonic, i.e. if E ⊆ F ⊆ RD , then dimH (E) ≤ dimH (F ) and dimP (E) ≤
dimP (F ). Second, the packing dimension is bounded below by the Hausdorff dimension,
i.e. for F ⊆ RD , we have dimH (F ) ≤ dimP (F ).
In the sequel we will apply the following consequence of the Rogers–Taylor–Tricot
density theorem for Hausdorff and packing measures [62, Theorem 2.1], which provides
a method of computing the Hausdorff and packing dimensions of a Borel set in terms of
local geometric-measure-theoretic information. For each point x ∈ RD define the lower

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

71

and upper pointwise dimensions of a measure µ at x by
def

dimx (µ) = lim inf
ρ→0

log µ(B(x, ρ))
log µ(B(x, ρ))
def
and dimx (µ) = lim sup
·
log ρ
log ρ
ρ→0

Note that the limits may be replaced by limits over any sequence ρn → 0 such that ρn /ρn+1
is bounded, without affecting the values.
Theorem 27.1. Fix D ∈ N and let µ be a locally finite Borel measure on RD . Then for every
Borel set A ⊆ RD ,
•
•
•
•

If dimx (µ) ≥ s for all x ∈ A and µ(A) > 0, then dimH (A) ≥ s.
If dimx (µ) ≤ s for all x ∈ A, then dimH (A) ≤ s.
If dimx (µ) ≥ s for all x ∈ A and µ(A) > 0, then dimP (A) ≥ s.
If dimx (µ) ≤ s for all x ∈ A, then dimP (A) ≤ s.

The statement above is closest to [27, Proposition 2.3]. Readers interested in studying
further refinements are referred to Cutler’s weak and strong duality principles in [18,
Theorems 1.4 and 1.5]. See [49, §8] for a self-contained proof of the density theorem for
measures in the setting of metric spaces.
28. A

CHARACTERIZATION OF

H AUSDORFF

AND PACKING DIMENSIONS USING GAMES

Schmidt’s game is a two-player topological game introduced in a seminal paper of
Wolfgang M. Schmidt in 1966 [57] as a technique to analyze Diophantine sets that are
exceptional with respect to both measure and category. Schmidt’s paper led to a plethora
of applications at the interface of dynamical systems, Diophantine approximation and
fractal geometry, which often involve various modifications of his eponymous game. For
a small sample of such research, see [20, 50, 45, 9, 15, 1, 4, 30, 2].
The proof of our variational principle is based on a new variant of Schmidt’s game
which is in principle capable of computing the Hausdorff and packing dimensions of any
Borel set. In Schmidt’s original game, players take turns choosing a descending sequence
of balls and compete to determine whether or not the intersection point of these balls is
in a certain target set. The key feature of our new variant is that instead of requiring the
rate at which the players’ moves contribute information to the game to be constant, the
new variant allows the rate of information transfer to be variable, with the first player,
Alice, getting to choose the rate of information transfer. However, Alice is penalized if
she exerts too much control over the game over long periods of time without giving her
opponent Bob a chance to exert control over the game.

72

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

F IGURE 15. Three consecutive rounds of the Hausdorff/packing game. On
each round Alice presents Bob with a set of balls to choose between (represented by the set of centers of those balls), and Bob chooses one of the
balls, which are colored/shaded above.
Definition 28.1. Given 0 < β < 1 and δ > 0, Alice and Bob play the δ-dimensional
Hausdorff (resp. packing) β-game as follows:
• The turn order is alternating, with the first turn being the 0th turn and Alice
playing first. Thus, Bob’s kth turn occurs after Alice’s kth turn and before Alice’s
(k + 1)st turn.
• Alice begins by choosing a starting radius ρ0 > 0.
• On the kth turn, Alice chooses a nonempty finite 3ρk -separated set18 Ak ⊆ RD , and
def
def
Bob responds by choosing a ball Bk = B(xk , ρk ), where xk ∈ Ak and ρk = β k ρ0 .
(We can think of Alice’s choice Ak as representing the collection of balls {B(x, ρk ) :
x ∈ Ak } from which Bob chooses his ball.)
• On the 0th turn, there is no further restriction on Alice’s choice A0 , but on each
subsequent turn (k + 1), she must choose Ak+1 so as to satisfy
(28.1)

Ak+1 ⊆ B(xk , (1 − β)ρk ).
Note that this condition guarantees (see Figure 15) that
B0 ⊇ B1 ⊇ B2 ⊇ · · ·

After infinitely many turns have passed, the point
(28.2)

x∞ = lim xk ∈
k→∞

∞
\

Bk

k=0

is computed (note that the right-hand side is always a singleton). It is called the outcome
of the game. Also, we let A = (Ak )k∈N, and we compute the number
k

(28.3)
18

1 X log #(Ai )
δ(A) = lim inf
k→∞ k
− log(β)
i=0
def

A set A is called ρ-separated if d(x, y) ≥ ρ for all distinct x, y ∈ A.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

73

resp.
k

(28.4)

1 X log #(Ai )
δ(A) = lim sup
,
k→∞ k i=0 − log(β)
def

which represents Alice’s score. Alice’s goal will be to ensure that the outcome is in a
certain set S, called the target set, and simultaneously to guarantee that her score is at
least δ. To be precise, a set S ⊆ RD is said to be δ-dimensionally Hausdorff (resp. packing)
β-winning if Alice has a strategy to simultaneously ensure that the outcome x∞ is in S,
and that her score δ(A) (resp. δ(A)) is at least δ. The set S is said to be δ-dimensionally
Hausdorff (resp. packing) winning if it is δ-dimensionally Hausdorff (resp. packing) βwinning for all sufficiently small β > 0. (Equivalently, we could say that Alice’s score is
automatically set equal to zero whenever x∞ ∈
/ S, in which case we would say that S is
δ-dimensionally Hausdorff β-winning if Alice has a strategy to ensure that her score is at
least δ.)
The following result is one of the key ingredients in the proof of the variational principle:
Theorem 28.2. The Hausdorff (resp. packing) dimension of a Borel set S ⊆ RD is the
supremum of δ such that S is δ-dimensionally Hausdorff (resp. packing) winning.
Remark 28.3. The theorem remains true (with the same proof) if RD is replaced by any
doubling19 metric space.
A key fact used in the proof is that since S is Borel, the Borel determinacy theorem
[48] implies that for all δ, β, the δ-dimensional Hausdorff and packing β-games are determined, meaning that either Alice or Bob has a winning strategy. This follows from
[29, Theorem 3.1], since the games can be viewed as “games played on complete metric spaces” in the language of [29], specifically with X = RD × NN (the latter factor
representing the number of balls that Alice chooses in each step).
Proof. We prove the theorem for the case of Hausdorff dimension; the argument in the
case of packing dimension is nearly identical.
We begin by proving the lower bound. Suppose that S is δ-dimensionally Hausdorff winning, and we must show that dimH (S) ≥ δ. Fix β > 0 such that S is δ-dimensionally
19

A metric space is doubling if there exists constants C, r0 such that every ball of radius 0 < r ≤ r0 can be
covered by at most C balls of radius r/2.

74

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Hausdorff β-winning, and consider a strategy for Alice to win the δ-dimensional Hausdorff β-game with target set S. Now for each k ≥ 0, let Ek denote the union of all sets Ak
that Alice might choose according to her strategy in response to some possible sequence
of moves that Bob could play, and let ρk = β k ρ0 . Then the set
def

C=

∞ [
\

B(xk , ρk )

k=0 xk ∈Ek

is the set of all possible outcomes of the game when Alice plays her winning strategy. It
is a closed and totally disconnected set, contained entirely in S. Note that by induction
and the restrictions on Alice’s possible moves, for all k, Ek is 3ρk -separated.
To bound the Hausdorff dimension of C, we introduce a probability measure on C by
considering the scenario where Alice plays according to her winning strategy and Bob
plays randomly: on the kth turn, Bob chooses the point xk ∈ Ak uniformly at random,
independently of all previous choices. This yields a random game whose outcome is
distributed according to some probability measure µ on C. Now fix x ∈ C, and for each
k ≥ 0 let xk ∈ Ek be chosen so that x ∈ B(xk , ρk ). Then since Ek is 3ρk -separated, if Bob
plays in a way such that the final outcome is in B(x, ρk ), then on the kth turn he must
choose the ball B(xk , ρk ). It follows that
B(x, ρk ) ∩ C ⊆ B(xk , ρk )
and thus
µ(B(x, ρk )) ≤ µ(B(xk , ρk )) =
So the lower pointwise dimension of µ at x is
log µ(B(x, ρ))
log ρ
log µ(B(x, ρk ))
= lim inf
k→∞
log ρk
log µ(B(xk , ρk ))
≥ lim inf
k→∞
log ρk
Pk
− i=0 log #(Ai )
= lim inf
k→∞
k log β + log ρ0

k
Y
i=0

#(Ai )

!−1

.

def

dimx (µ) = lim inf
ρ→0

(since ρk = β k ρ0 )

= δ(A) ≥ δ

since Alice is using a winning strategy. Since x ∈ C was arbitrary and µ(C) = 1, applying
the Rogers–Taylor–Tricot Theorem 27.1 proves the lower bound dimH (S) ≥ δ.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

75

To prove the upper bound, suppose that S is not δ-dimensionally Hausdorff winning,
and we will show that dimH (S) ≤ δ. Fix 0 < β ≤ 1/2 small enough so that S is not
δ-dimensionally Hausdorff β-winning. Then Alice does not have a winning strategy for
the δ-dimensional Hausdorff β-game with target set S. Since this game is determined as
we mentioned earlier, we know that Bob must have a winning strategy for it, which we
now fix.
Fix a radius ρ0 > 0, and for each k ∈ N
• let Ek be a maximal 31 β k ρ0 -separated subset of RD , and
S
(1)
(p)
(i)
• let Ek , . . . , Ek be disjoint 3β k ρ0 -separated subsets of Ek such that Ek = pi=1 Ek .
Since RD is a doubling metric space (see Footnote 19), it is possible to choose p to be
independent of k and β. We define a family of strategies for Alice as follows. Consider
the kth turn for some k ∈ N, and if k ≥ 1 then let Bk−1 = B(xk−1 , ρk−1 ) be the move that
Bob just played. Let

B(x , (1 − β)ρ ) k ≥ 1
k−1
k−1
e
Bk−1 =
,
B(0, κ + ρ0 )
k=0
where κ > 0 is a large constant. Next let
ek−1 ,
Xk = Ek ∩ B
(i)

(i)

(i)

(i,j)

From then on, we define the moves Ak
(i,j)

• if Ak

(i)

Nk = #(Xk ),
(i,j)

and Bk

(i)

(i,Nk )

Ak

(i)

= Xk .

by backwards recursion as follows:

is defined for some j ≥ 1, then
(i,j)

Bk

(i,j)

= B(xk , ρk )
(i,j)

is Bob’s response if Alice plays Ak .
(i,j)
(i,j)
(i,j)
• if Ak and Bk = B(xk , ρk ) are both defined for some j ≥ 1, then
(i,j−1) def

Ak
(i,j)

(i,j)

= Ak

(i,j)

\ {xk }.

(i)

Note that #(Ak ) = j for all j = 0, . . . , Nk .
Now consider the scenario where Bob plays according to his winning strategy and Alice
(i ,j )
plays randomly: on the kth turn, Alice chooses a move Ak k k where the integers ik and
jk are chosen independently of previous choices i1 , i2 , . . . , ik−1 and j1 , j2 , . . . , jk−1 of with
respect to a probability distribution satisfying
(28.5)

P(ik = i, jk = j) ≥ cj −(1+ε) ,

76

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

where ε > 0 is fixed and c > 0 is a constant depending on ε and p. By the Kolmogorov
extension theorem, this yields a random sequence of plays whose outcome is distributed
according to some probability measure µ on RD .
ρ .
Now fix x ∈ S∩B(0, κ). For each k ∈ N, there exists xk ∈ Ek such that d(x, xk ) ≤ 1−β
1+β k
Note that x0 ∈ B(0, κ + ρ0 ), and xk+1 ∈ B(xk , (1 − β)ρk ) for all k. It follows that Alice
(I ,J )
can guarantee that the outcome is equal to x by playing the move Ak = Ak k k on the
kth turn for some sequences of integers (Ik )k∈N, (Jk )k∈N. Since Bob’s strategy is winning
and x ∈ S, it follows Alice’s score is less than δ, i.e.
δ(A) < δ.
Let G1 denote the sequence of plays described above, and let G2 be a sequence of plays
(i ,j )
where on the kth turn, Alice chooses a set Ak k k , and Bob responds according to his
winning strategy, such that ik = Ik and jk = Jk for all k ∈ {0, . . . , ℓ}. Then the ℓth ball of
G2 is equal to the ℓth ball of G1 , and thus the outcome of G2 is within 2ρℓ of the outcome
of G1 , i.e. x. Thus if we think of G2 as being chosen randomly, then


µ B(x, 2ρℓ ) ≥ P ik = Ik , jk = Jk ∀k ≤ ℓ
≥

ℓ
Y

−(1+ε)

cJk

k=0

= cℓ exp −(1 + ε)
and so
dimx (µ) = lim inf
ℓ→∞

ℓ
X

log #(Ak )

k=0

!

log µ(B(x, 2ρℓ ))
log(2ρℓ )

P
ℓ log(c) + (1 + ε) ℓk=0 − log #(Ak )
≤ lim inf
ℓ→∞
ℓ log β + log(2ρ0 )
log(c)
=
+ (1 + ε)δ(A)
log(β)
log(c)
<
+ (1 + ε)δ.
log(β)
Since x ∈ S was arbitrary, applying the Rogers–Taylor Theorem 27.1 again yields
dimH (S) ≤
Letting β, ε → 0 completes the proof.

log(c)
+ (1 + ε)δ.
log(β)



A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

29. P LAYING

GAMES WITH

D IOPHANTINE

77

TARGETS

In practice, when we play the Hausdorff or packing game with a target set defined in
terms of the parametric geometry of numbers, it is helpful to use a different formalism to
encode Alice and Bob’s moves. First of all, note that for each k, the ball Bk = B(xk , ρk ) is
homeomorphic to the unit ball B(0, 1) via the similarity transformation
Tk (z) = xk + ρk z.
By replacing Ak+1 and xk+1 by their preimages under Tk , and leaving A0 and x0 the same,
we can see that we can make the following changes to the rules of the δ-dimensional
Hausdorff (resp. packing) β-game without affecting the existence of winning strategies
for either player:20
• For k ≥ 1, instead of requiring that Alice’s choice Ak is 3ρk -separated, we require
that it is 3β-separated.
• Instead of (28.1), Alice must choose Ak+1 to satisfy
Ak+1 ⊆ B(0, 1 − β).

(29.1)

• The outcome of the game, instead of being computed by (28.2), is computed by
the formula
∞
X
def
β k ρ−1 xk ,
(29.2)
x∞ = x0 +
k=1

def

where ρ−1 = β −1 ρ0 (using the definition of ρk in Definition 28.1).
We will call the version of the Hausdorff (resp. packing) game resulting from these rule
changes the modified Hausdorff (resp. packing) game. It will be the version we use in the
proof of Theorem 4.6 (Variational principle, version 2) in Part 4.
Let D = mn in Section 28, and let us identify RD with M, the space of m × n matrices
with real entries. Further, we will assume that the target set is of the form (recalling
notation from below Theorem 4.2)
[
[
S = D(S) =
D(f) =
{A ∈ M : hA ≍+ f}
f ∈S

f ∈S

for some collection S of functions from [0, ∞) to Rd closed under finite perturbations
(i.e. if whenever f ∈ S and g ≍+ f, we have g ∈ S). In this case, we can track the
“progression” of the game by associating a unimodular lattice to each turn of the game.
20

ek and x
ek are related to the analogous moves Ak and xk in the
The moves in the new modified game A
P
ek and xk = x0 + k β i ρ−1 x
ei .
original game via the formulas Ak = xk−1 + ρk−1 A
i=1

78

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Specifically, for each k ≥ 0 let
k

(29.3)

def

m+n

Λk+1 = g−α log(β k+1 ρ−1 ) uYk Z

X
mn
def
, where α =
and Yk = X0 +
β i ρ−1 Xi .
m+n
i=1
def

Here, we use uppercase letters (X, Y ) instead of bold letters (x, y) because we are working with matrices rather than with vectors. Then for k ≥ 1, Λk and Λk+1 are related by
the formula
Λk+1 = g−α log(β) uXk Λk .

(29.4)
This is because

uX g−α log(λ) = g−α log(λ) uλX for all λ, X.

(29.5)

Notation 29.1. To simplify the notation in (29.4), we let
def

def

γ = − α log(β) > 0,

g = gγ ,

so that
Λk+1 = guXk Λk .
Intuitively, this means that Λk is well-defined at the start of turn k, and that Alice and
Bob’s choices on turn k can be thought of as a process of choosing Λk+1 indirectly by
choosing Xk .
The significance of the sequence of lattices (Λk )∞
1 is given by the following lemma:
Lemma 29.2. Let j : [0, ∞) → Rd be the function defined on γZ by the formula
def

j(kγ) = h(Λk )
and extended to [0, ∞) via linear interpolation. Then
j ≍+ hX∞
where X∞ is as in (29.2). In particular, X∞ ∈ D(S) if and only if j ∈ S.
Here we use the notation
def

h(Λ) = (log λ1 (Λ), . . . , log λd (Λ)).
Proof. Fix k, and write
def

Zk =

∞
X

β i Xk+i .

i=0

Then

uZk Λk = g−α log(ρ−1 )+kγ uX∞ Zm+n .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

79

Since Zk ∈ B(0, 1), this implies that
f(kγ) = h(Λk ) ≍+ h(uZk Λk ) = h(g−α log(ρ−1 )+kγ uX∞ Zm+n ) = hX∞ (−α log(ρ−1 ) + kγ)
and thus f ≍+ hX∞ . Since S is closed under finite perturbations, it follows that f is in S

if and only if hX∞ is, i.e. if and only if X∞ ∈ D(S).
Part 4. Proof of the variational principle
def P
Throughout Part 4, k · k denotes the Euclidean norm, i.e. kxk2 = i x2i . This is allowed
since the variational principle (Theorem 4.6) is independent of the choice of norm. In
def
certain places we will use the max norm, i.e. kxk∞ = maxi |xi |.

30. P RELIMINARIES
This section collects various notation and lemmata employed in our proof of the variational principle, viz. Theorem 4.6. Though some of these results may be considered
elementary by experts familiar with the geometry of numbers, we include such for the
benefits of self-containment. Thus, for instance, we begin by recalling Minkowski’s second theorem on successive minima for the reader’s convenience.
Theorem 30.1 (Minkowski, [14, Theorem V in §VIII.4.3]). Let Λ be a lattice in a vector
space V ⊆ Rd . Then
dim(V )
Y
λj (Λ) ≍ kΛk,
j=1

where kΛk denotes the covolume of Λ, and λj (Λ) is the jth minimum of Λ with respect to
the unit ball of V .
Definition 30.2. Let Λ ⊆ Rd be a lattice. A subspace V ⊆ Rd is called Λ-rational if V ∩ Λ
is a lattice in V . Denote the set of all q-dimensional Λ-rational subspaces of Rd by Vq (Λ).

Notation 30.3. If V is a Λ-rational subspace of Rd , we denote the covolume of V ∩ Λ in
V , with respect to the Euclidean metric on V inherited from Rd , by kV k. Although this
notation is misleading since kV k depends on Λ and not just on V , in practice this should
not be a problem as it should generally be clear what Λ is (for instance, if V is Λ-rational,
then gV is gΛ-rational, so we can take kgV k to be the covolume of g(V ∩ Λ)).
Notation 30.4. We denote the subspace of Rd contracted by the (gt ) flow (defined in §
3.1) by L, i.e.
def
L = {0} × Rn .

80

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

The conical ε-neighborhood of a subspace V ⊆ Rd will be denoted
C(V, ε) = {r : d(r, V ) ≤ εkrk}
where d denotes infimal distance. Given 0 < β < 1 in the definition of the δ-dimensional
Hausdorff (resp. packing) β-game (see Definition 28.1), and following Notation 29.1 and
(29.3) from Section 29, we write
mn
γ=−
log(β),
g = gγ .
m+n
Following Definition 4.1, we write
Fq =

q
X

fi .

i=1

The following lemmas will be used in the proof of Theorem 4.6.
Lemma 30.5. Let Λ ≤ Rd be a lattice. Then there exists a basis {r1 , . . . , rd } of Λ such that
P
if Vq = qi=1 Rri , then
q
X
log λi (Λ).
log kVq k ≍+
i=1

Moreover,

log kri k ≍+ log λi (Λ) for all i.

(30.1)

Proof. Let {r1 , . . . , rd } be a Minkowski reduced basis of Λ (see [34, Proposition 5.3]).
Now let h be the change of basis matrix changing {e1 , . . . , ed } into {r1 , . . . , rd } and write
h = kan where k ∈ SO(d), a is a diagonal matrix, and n is an upper triangular matrix.
Since {r1 , . . . , rd } is a Minkowski reduced basis, n is bounded and thus g = k(ana−1 ) is
also bounded. Note that ri = gaei for all i. Then for all i,
kri k ≍ ai = λi (aZd ) ≍ λi (gaZd ) = λi (Λ).
On the other hand, for each q = 1, . . . , d, we have
log kVq k ≍+ log kaEq k = log(a1 . . . aq ) =
where Eq =

Pq

i=1

Rei .

q
X
i=1

log(ai ) ≍+

q
X

log λi (Λ),

i=1



Lemma 30.6. Let Λ ≤ Rd be a lattice, and let Vq be as in Lemma 30.5. Then
(30.2)

log kVq′ k

&+

q−1
X
i=1

log λi (Λ) + log λq+1 (Λ) for all Vq′ ∈ Vq (Λ) \ {Vq }.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

81

Proof. Fix Vq′ ∈ Vq (Λ) \ {Vq }. By Minkowski’s second theorem (Theorem 30.1), we have
(30.3)

log kVq′ k

≍+

For all i = 1, . . . , q − 1, we have
(30.4)

q
X
i=1

λi (Λ ∩ Vq′ ).

λi (Λ ∩ Vq′ ) ≥ λi (Λ).

For the i = q term, we use a different argument to get a better bound. Let E (resp. E ′ )
be a spanning set for Λ ∩ Vq (resp. Λ ∩ Vq′ ). Then E ∪ E ′ is a spanning set for Λ ∩ (Vq + Vq′ ).
Since dim(Vq + Vq′ ) ≥ q + 1, it follows that
max krk ≥ λq+1 (Λ).

r∈E∪E ′

Taking the infimum over all E, E ′ gives

max λq (Λ ∩ Vq ), λq (Λ ∩ Vq′ ) ≥ λq+1 (Λ).

On the other hand, it follows from (30.1) that λq (Λ ∩ Vq ) ≍+ λq (Λ) ≤ λq (Λ ∩ Vq′ ). Thus,
λq (Λ ∩ Vq′ ) &+ λq+1 (Λ).
Combining with (30.3) and (30.4) yields (30.2).


def

Lemma 30.7. Recall that d+ = m and d− = n. Fix L± ∈ [0, d± ] ∩ Z and let q = L+ + L− .
Let Λ be a lattice and let V be a q-dimensional Λ-rational subspace such that
L− ≥ sup dim(uY V ∩ L).
kY k≤β

Then for all t ≥ 0,
(30.5)

log kgt V k − log kV k &+,β



L+ L−
−
m
n



t.

The reverse inequality holds if dim(V ∩ L) = L− .
Proof. Define a linearly independent sequence (ri )k1 in V recursively as follows: if ri =
(pi , qi ) ∈ V has been defined for i = 1, . . . , j, then let
def

rj+1 = (pj+1 , qj+1) ∈ Wj = V ∩

j
\

(pi , 0)⊥

1

be chosen so that kpj+1 k ≥ βkqj+1k. Continue until it is not possible to continue further;
then for all r = (p, q) ∈ Wk , we have kpk ≤ βkqk. It follows that there exists kY k ≤ β

82

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

such that uY Wk ⊆ L, which implies that
q − k = dim(Wk ) = dim(uY Wk ) ≤ dim(uY V ∩ L) ≤ L− .
Rearranging gives k ≥ L+ . Finally, let (ri )qk+1 be an arbitrary basis of Wk . Then there
exists a constant α > 0 such that
kV k = αkr1 ∧ · · · ∧ rq k
and
kgt V k = αkgt r1 ∧ · · · ∧ gt rq k.
In particular
kV k ≤ αkr1 k · · · krk k · krk+1 ∧ · · · ∧ rq k .β αkp1 k · · · kpk k · krk+1 ∧ · · · ∧ rq k
while
kgt V k = αket/m [(p1 , 0) + oβ (kp1 k)] ∧ · · · ∧ et/m [(pk , 0) + oβ (kpk k)] ∧ gt rk+1 ∧ · · · ∧ gt rq k.
Since (pi )k1 are orthogonal to each other and also to rk+1 , . . . , rq , it follows that if t is
sufficiently large in comparison to β we have
kgt V k & αekt/m kp1 k · · · kpk k · kgt rk+1 ∧ · · · ∧ gt rq k

& αekt/m kp1 k · · · kpk k · e−(q−k)t/n krk+1 ∧ · · · ∧ rq k
&β ekt/m−(q−k)t/n kV k.

Since k ≥ L+ , this completes the proof of (30.5).
Now suppose dim(V ∩ L) = L− , and we will show that the reverse inequality of (30.5)
L
holds. Let (ri )1 − be an orthonormal basis of V ∩ L, and extend to an orthonormal basis
(ri )q1 of V . Then
kgt V k
≍ kgt r1 ∧ · · · ∧ gt rq k
kV k
. kgt r1 k · · · kgt rq k

≤ (e−t/n kr1 k) · · · (e−t/n krL− k)(et/m krL− +1 k) · · · (et/m krq k)

 
L+ L−
≍ exp
t .
−
m
n
This completes the proof.



A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

83

We finish with an elementary observation about the slopes of line segments appearing
in templates (see Definition 4.1) that is used in proving Lemma 31.14, which in turn is
needed in the proof of the lower bound of the variational principle.
Observation 30.8. If f is a template then for all t ≥ 0 we have
fj′ (t) − fi′ (t) ∈ 1q Z for some q ≤ mnd2 .
Proof. For all i, t we have
fi′ (t) =

p
mnq

for some p ∈ Z and q = 1, . . . , d. So we have
p2
p1
p
fj′ (t) − fi′ (t) =
−
=
mnq2 mnq1
mnq1 q2
and we have mnq1 q2 ≤ mnd2 .
31. P ROOF


OF

T HEOREM 4.6,

LOWER BOUND

Let f be a template. We must show that
(31.1)

dimH (D(f)) ≥ δ(f),

dimP (D(f)) ≥ δ(f).

To this end, we will play the modified Hausdorff and packing games with target set
S = D(f). It turns out that the same strategy will work for Alice in both games.
The proof can be divided into four basic stages:
1. Reduction: We can without loss of generality assume that the template f appearing
in the statement of the theorem is in a special form which is convenient to the later
argument.
2. Mini-strategy: For any template g (not necessarily the same as the f appearing in the
theorem), Alice can guarantee that if A is the outcome of the game, then the successive
minima function hA remains close to g for a certain interval of time before diverging
from it. This interval can be an interval of linearity of g, or the union of any fixed
number of intervals of linearity. However, the upper bound on |hA − g| rapidly grows
as the allowed number of intervals of linearity increases.
3. Error correction: If the value of the successive minima function hA at a certain time t
is slightly off from the value of f at t, then we can perturb f into a partial template g
such that g(t) = hA (t). Alice can then follow the perturbed template g rather than the
original template f.
4. Uniform error bounds: The error correction techniques from stage (3) are sufficient to
guarantee that the final successive minima function hA remains a bounded distance

84

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

from the desired template f, and that the inequalities δ(A) ≥ δ(f) − ε and δ(A) ≥
δ(f) − ε are satisfied.
Stage 2 is in some sense the most important one because it makes the connection
between the parametric geometry of numbers and the theory of templates. In the other
stages, for the most part we do not deal with parametric geometry of numbers directly.
31.1. Reduction. There are two key features we would like to assume of our template
f: its corner points21 should be appropriately spaced, and each corner point should have
only one “purpose”.
Definition 31.1. Given η > 0, a template f is η-integral if
(I) its corner points are multiples of η, and
η
Z for all 1 ≤ i ≤ d.
(II) for all t ∈ ηN we have fi (t) ∈ mnd!
By the quantized slope condition (see Definition 4.1) it suffices to check (II) for t = 0.
Definition 31.2 (Cf. Figure 16). Let f be a template, let t > 0 be a corner point of f, and
let I− , I+ be the two intervals of linearity for f such that I− = (t− , t) and I+ = (t, t+ ) for
some t− < t < t+ .
• We call t a split (resp. merge) if there exists q = 1, . . . , d − 1 such that fq (t) =
fq+1 (t), but fq < fq+1 on I+ (resp. on I− ).
• We call t a transfer if there exists q = 1, . . . , d − 1 such that fq (t) < fq+1 (t) and
L+ (f, I+ , q) > L+ (f, I− , q) (equiv. Fq′ (I+ ) > Fq′ (I− )).
Finally, we call the template f simple if the sets of splits, merges, and transfers are pairwise
disjoint.
Remark 31.3. In any template, every corner point is either a split, a merge, or a transfer.
We now show that we can assume without loss of generality that the template f appearing in the statement of Theorem 4.6 is both simple and integral.
Lemma 31.4. For every η > 0 and for every template f, there exists a simple η-integral
template g which approximates f to within an additive constant, i.e. satisfies g ≍+ f. The
implied constant depends on η but not on f. Moreover, g can be chosen so that for all q, t, t′
such that gq (t) < gq+1 (t) and |t′ − t| ≤ η, we have fq+1 (t′ ) − fq (t′ ) ≥ η and G′q (t) ≥ Fq′ (t′ ).
Consequently,
(31.2)
21

δ(g) ≥ δ(f),

I.e. points where the derivative of f is undefined.

δ(g) ≥ δ(f).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

t0

t1

t2

t3 t4

85

t5

F IGURE 16. In this figure of a portion of an arbitrary 1 × 2 template, the
corner points t0 and t2 are splits, t1 and t5 are merges, and t3 and t4 are
transfers.

Proof. Since a similar argument will be needed for the proof of the upper bound of Theorem 4.6 (specifically, showing that a successive minima function can always be approximated by a template (cf. Lemma 31.8 below)), we prove this lemma in slightly greater
generality than may appear to be necessary. Fix η > 0, and let f : [0, ∞) → Rd be a map
(not necessarily a template) satisfying the following conditions:
(I) f1 ≤ · · · ≤ fd .
(II) For all t1 < t2 and i = 1, . . . , d we have
−

fi (t2 ) − fi (t1 )
1
1
≤
≤ ·
n
t2 − t1
m

(III) For all q = 1, . . . , d and for every interval I such that
(31.3)

fq+1 > fq on I,

86

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

there exists a convex, piecewise linear function Fq,I : I → R with slopes in Z(q) (cf.
(4.2)) which satisfies
def

Fq =

(31.4)

q
X
i=1

and if f is a template, then

fi ≍+ Fq,I on I

′
Fq,I
≥ Fq′ on I.

(31.5)

Note that any template satisfies these conditions (and in fact, one can take Fq,I = Fq in
(III)).
Let δ∗ = d · (d2 )!η ∈ ηN, and let δ∗∗ = mnd4d δ∗ . Fix q = 1, . . . , d, and let Iq be the
collection of all intervals satisfying (31.3) whose endpoints are in δ∗∗ N ∪ {∞}, and which
are maximal with respect to these two properties. For each I ∈ Iq , let Fq,I : I → R be a
convex, piecewise linear function as in (III).
By first moving the corner points of Fq,I to the left and then increasing Fq,I by an
additive constant, we may without loss of generality suppose that the following hold:
(IV) the corner points of Fq,I are all integer multiples of δ∗∗ ; and
(V) the values of Fq,I at integer multiples of δ∗∗ are all in the set (d4(d−q) + d4d Z)δ∗ .
(The displacement term d4(d−q) will help us guarantee that the resulting template
g is simple.)
1
Z for all q, to ensure that the conditions are
Here, we have used the fact that Z(q) ⊆ mn
not inconsistent. Moving the corner points to the left rather than to the right guarantees
that (31.5) is still satisfied. We can also assume that Fd,I∗ ≡ 0, where I∗ = [0, ∞) is the
unique element of Id .

Claim 31.5. There exist collections of intervals Ieq and functions Feq,Ie satisfying (III)-(V) and
the following: For all 1 ≤ q1 < q2 ≤ d, I1 ∈ Ieq1 , and I2 ∈ Ieq2 , we have

(31.6)

−

Feq′ ,I − Feq′1 ,I1
1
1
≤ 2 2
≤
on I1 ∩ I2 .
n
q2 − q1
m

Proof. Fix a constant C2 > 0 to be determined, and let C1 = 2d2 C2 . Let Jq = {I ∈ Iq :
S S
|I| > C1 } and S = q I∈Jq Sq,I ∩ I, where Sq,I is the set of corner points and end points
of Fq,I . Let σ : S → S be defined as follows: σ(t) is the smallest element of S that can be
reached from t by jumps of size ≤ C2 , and if the right endpoint of I can be reached from
t by jumps of size ≤ C2 , then let σ(t) be the right endpoint of I. For each q = 1, . . . , d and
I ∈ Jq , let Feq,I be a piecewise linear function which is equal to Fq,I at the left endpoint

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

87

of I, such that if (a, b) ⊆ I is a maximal interval of linearity for Fq,I of slope z, then
(σ(a), σ(b)) is a maximal interval of linearity for Feq,I of slope z.
We claim that |σ(a) − a| ≤ C1 for all a ∈ S. Indeed, otherwise there exist points
t0 < . . . < t2d2 in S such that ti+1 −ti ≤ C2 for all i. By the pigeonhole principle there exists
S
q = 1, . . . , d such that #( I∈Jq Sq,I ∩ [t0 , t2d2 ]) ≥ 2d + 1. Since #(Sq,I ) ≤ #(Z(q)) + 1 =
min(q, d − q) + 1 ≤ d for all I ∈ Iq , applying the pigeonhole principle again shows that
there exist at least 3 intervals I ∈ Jq such that I ∩ [t0 , t2d2 ] 6= . But then the middle
interval is a subset of [t0 , t2d2 ], which contradicts I ∈ Jq , since t2d2 − t0 ≤ 2d2 C2 = C1 . It
follows that Feq,I ≍+ Fq,I for all q, I. Thus, (31.4) holds with F replaced by Fe. Moreover,
since σ(S) ⊆ S ⊆ δ∗∗ Z, condition (IV) holds for Fe. Also, by translating each Feq,I by a
constant if necessary, we can without loss of generality assume that condition (V) holds
for Fe.
Finally, we need to show that (31.6) holds for Fe. Indeed, let (σ(a), σ(b)) ⊆ I1 ∩ I2 be a
maximal interval of linearity for Feq,I2 − Feq,I1 . Since σ(a) < σ(b), we have b − a ≥ C2 . Let
k = q2 − q1 . Then by condition (II) we have
q2
X
k
fi (b) − fi (a)
k
≤
− ≤
n i=q +1
b−a
m
1

and thus if z is the constant value of Fq′2 ,I2 − Fq′1 ,I1 on (a, b), then
−

k
k 4C3
4C3
≤z≤
−
+
n
C2
m
C2

1
where C3 is the implied constant of (31.4). On the other hand, we have z ∈ mn
Z by
condition (III). So if we choose C2 > 4mnC3 , then we get −k/n ≤ z ≤ k/m, completing
the proof.
⊳

Next, let Fq,∗ : [0, ∞) → R ∪ {∗} be defined by the formula

Fe (t) if t ∈ I for some I ∈ Ie
q,I
q
Fq,∗ (t) =
∗
otherwise,

and let Gq,∗ (t) = Fq,∗ (t) + q(d − q)C4 , where C4 ∈ d4d δ∗ N is large to be determined. Let
G0,∗ (t) = 0 ∈ (d4(d−0) +d4d Z)δ∗ for all t, and note that Gd,∗ (t) = δ∗ for all t by our condition
on Fd,I∗ . In what follows we let ∗ + x = ∗ + ∗ = ∗.
At this point, the intuitive idea is to try to define the template g by solving the equations

Pq g (t) if g (t) < g (t)
q
q+1
i=1 i
(31.7)
Gq,∗ (t) =
∗
if gq (t) = gq+1 (t).

88

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

However, the formula (31.7) is not necessarily solvable with respect to g, due to the fact
that the natural candidate for a solution does not necessarily satisfy g1 (t) ≤ · · · ≤ gd (t).
To address this issue, we introduce the concept of the convex hull function of a set:
Definition 31.6. The convex hull function of a set Γ ⊆ R2 is the largest convex function
h : I → R such that h(x) ≤ y for all (x, y) ∈ Γ, where I is the smallest interval containing
the projection of Γ onto the first coordinate.

F IGURE
17. The
convex
hull
function
h
of
the
set
{(0, 0), (1, −1), (2, 1), (4, 0)}. Since 1 > h(2) = −2/3, the convex hull
function does not change when the point (2, 1) is removed.
We can now define g via the formula
gq (t) = ht (q) − ht (q − 1),
where ht : [0, d] → R is the convex hull function of the set
Γ(t) = {(q, Gq,∗(t)) : q = 0, . . . , d, Gq,∗ (t) 6= ∗}.
To complete the proof, we must show
• that g = (g1 , . . . , gd ) is a simple η-integral template,
• that g ≍+ f,
• that if f is a template, then for all q, t, t′ such that gq (t) < gq+1(t) and |t′ − t| ≤ η,
we have fq+1 (t′ ) − fq (t′ ) ≥ η and G′q (t) ≥ Fq′ (t′ ), and consequently (31.2) holds.
Claim 31.7. For all q = 1, . . . , d − 1 and t ≥ 0 such that Gq,∗ (t) = ∗, we have fq (t) ≍+
fq+1 (t).
Proof. Let t ∈ I = (kη, (k + 2)η) for some k ∈ N. If (31.3) holds, then there exists J ∈ Iq
such that I ⊆ J, which contradicts Gq,∗ (t) = ∗. Thus (31.3) does not hold, and so there
exists t′ ∈ I such that fq (t′ ) = fq+1 (t′ ). By condition (II), this implies fq (t) ≍+ fq+1 (t).
⊳
We next show that g is continuous. From this it is easy to see that it is piecewise linear,
the first step to proving that it is a template. Fix t > 0, and write h(t± ) = lims→t± h(s).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

89

Let
Γ(t± ) = lim± Γ(s) = {(q, Gq,∗(t± )) : q = 0, . . . , d, Gq,∗ (t± ) 6= ∗}.
s→t

We need to show that Γ(t− ) and Γ(t+ ) have the same convex hull function. For this
purpose, it suffices to show that any point in one of these sets but not the other is not an
element of the graph of the corresponding convex hull function (which implies that the
convex hull function does not change when the point is removed).
Indeed, fix q = 1, . . . , d−1 and suppose that Gq,∗(t+ ) 6= ∗ but Gq,∗ (t− ) = ∗. Let 0 ≤ p < q
and d ≥ r > q be maximal and minimal, respectively, such that Gp,∗(t+ ), Gr,∗ (t+ ) 6= ∗.
Then by Claim 31.7 we have
fp+1 (t) ≍+ . . . ≍+ fq (t) ≍+ fq+1 (t) ≍+ . . . ≍+ fr (t)
and thus by (31.4),
Fr,∗ (t+ ) − Fq,∗ (t+ )
Fq,∗ (t+ ) − Fp,∗ (t+ )
≍+ fq (t) ≍+ fq+1 (t) ≍+
·
q−p
r−q

It follows that


r(d − r) − q(d − q) q(d − q) − p(d − p)
Gr,∗ (t+ ) − Gq,∗ (t+ ) Gq,∗ (t+ ) − Gp,∗ (t+ )
C4
−
≍+
−
r−q
q−p
r−q
q−p
= −(r − p)C4 ≤ −2C4 .

So if C4 is sufficiently large, then
Gr,∗ (t+ ) − Gq,∗(t+ )
Gq,∗ (t+ ) − Gp,∗(t+ )
<
r−q
q−p

i.e. the slope of the line from (q, Gq,∗(t+ )) to (r, Gr,∗ (t+ )) is less than the slope of the line
from (p, Gp,∗(t+ )) to (q, Gq,∗ (t+ )). It follows that (q, Gq,∗(t+ )) lies above the graph of the
convex hull function of Γ(t+ ). Since q was arbitrary, this shows that Γ(t− ) and Γ(t+ ) have
the same convex hull function. Thus g(t− ) = g(t+ ), and g is continuous at t.
We next demonstrate that g satisfies conditions (I)-(III) of Definition 4.1. (I) follows
from the fact that convex hull functions are convex, while (II) follows from Claim 31.5.
To demonstrate (III), fix q = 1, . . . , d and let I be an interval of linearity for g such that
gq < gq+1 on I. Fix t ∈ I. Since ht (q) − ht (q − 1) < ht (q + 1) − ht (q) (with the convention
ht (d + 1) = +∞), the point (q, ht (q)) is an extreme point of the convex hull of Γ(t) and
thus (q, ht (q)) ∈ Γ(t), i.e. Gq,∗ (t) = ht (q). It follows that
(31.8)

q
X
i=1

gi = Gq,∗ on I.

90

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Since Gq,∗ ↿ I is convex and piecewise linear with slopes in Z(q), it follows that the same
P
is true for q1 gi ↿ I. Thus, g is a template.
To show that g is simple and η-integral, we first observe that by construction, all transfers occur at integer multiples of δ∗∗ . Let t be a split or a merge with corresponding index
q. Then (q, Gq,∗(s)) is an extreme point of the convex hull of Γ(s) when s approaches t
from one side, but not from the other side. So there exist 0 ≤ p < q < r ≤ d such that the
point (q, Gq,∗(t)) lies on the line segment connecting (p, Gp,∗(t)) and (r, Gr,∗ (t)). Thus, we
have Φ(t) = 0 where
Φ(s) = (r − q)Gp,∗ (s) + (q − p)Gr,∗ (s) − (r − p)Gq,∗ (s).
Write t = t′ + t′′ where t′ is a multiple of δ∗∗ and 0 ≤ t′′ < δ∗∗ . Then by assumption
Gj (t′ ) ∈ (d4(d−j) + d4d Z)δ∗ for all j. Thus δ1∗ Φ(t′ ) ∈ Z, and furthermore
1
Φ(t′ )
δ∗

≡ (r − q)d4(d−p) + (q − p)d4(d−r) − (r − p)d4(d−q)

≡ (q − p)d4(d−r)

(modulo d4(d−q) ).

6≡ 0

In particular Φ(t′ ) 6= 0 = Φ(t), so t′′ > 0 and thus t is not a transfer. Thus, the set of splits
and the set of merges are both disjoint from the set of transfers.
Since Gp,∗, Gq,∗ , Gr,∗ are linear on [t′ , t′ + δ∗∗ ], so is Φ. Let z denote the constant value
of Φ′ on [t′ , t′ + δ∗∗ ], and note that
i
h
0 6= z = m1 + n1 (r − q)L+ (p) + (q − p)L+ (r) − (r − p)L+ (q)


∈ m1 + n1 {−(r − p)q, . . . , (r − q)p + (q − p)r} ⊆ m1 + n1 {−d2 , . . . , d2 }.
Thus

t′′ = −

Φ(t′ )
∈
z

1
m

δ∗ Z
δ∗ Z

⊆
,
1
2
d · (d2 )!
+ n (d )!

so by letting δ∗ = d · (d2 )!η we can guarantee that t′′ ∈ Zη. Since transfers also occur
at integer multiples of η, this implies that condition (I) of Definition 31.1 is satisfied. To
check condition (II), note that we have Gq,∗ (t) ∈ δ∗ Z whenever t ∈ δ∗∗ N, and thus since
η
1
Z, we have Gq,∗ (t) ∈ mn
Z whenever t ∈ ηN. Now for each
Gq,∗ has slopes in Z(q) ⊆ mn
q = 1, . . . , d and t ∈ ηN, there exist p < q ≤ r such that
gq (t) =
Thus g is η-integral.

Gr,∗ (t) − Gp,∗ (t)
η
∈
Z.
r−p
mnd!

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

91

Next, since t′′ > 0, it follows that Φ is linear in a neighborhood of t, and thus there
exist points near t for which Φ is strictly negative. At these points, we have gq = gq+1 . It
follows that t is not both a split and a merge with respect to the same index q.
By contradiction, suppose that t is both a split and a merge, with corresponding indices
q1 6= q2 . We can apply the above argument twice: for each i = 1, 2 we get indices
0 ≤ pi < qi < ri ≤ d, a function Φi , and a slope zi . We have
−
and thus

Φ2 (t′ )
Φ1 (t′ )
= t′′ = −
z1
z2

Φ1 (t′ )
·
δ∗

z2
1
+
m

1
n

Φ2 (t′ )
·
=
δ∗

1
m

z1
·
+ n1

So there exist a1 , a2 ∈ {−d2 , . . . , d2} \ {0} such that

a1 [(r1 − q1 )d4(d−p1 ) + (q1 − p1 )d4(d−r1 ) − (r1 − p1 )d4(d−q1 ) ]

≡ a2 [(r2 − q2 )d4(d−p2 ) + (q2 − p2 )d4(d−r2 ) − (r2 − p2 )d4(d−q2 ) ]

(modulo d4d ).

Comparing the base d4 expansions of both sides shows that (p1 , q1 , r1 ) = (p2 , q2 , r2 ), contradicting that q1 6= q2 . Thus, the set of splits and the set of merges are disjoint.
We next show that g ≍+ f. Indeed, fix t ≥ 0. Let h1 , h2 , and h3 be the convex hull
functions of Γ(t), {(q, Fq (t)) : Gq,∗ (t) 6= ∗}, and {(q, Fq (t)) : q = 0, . . . , d}, respectively.
Since Gq,∗ (t) ≍+ Fq (t) for all q such that Gq,∗(t) 6= ∗, we have h1 ≍+ h2 , and by Claim
31.7, we have h2 ≍+ h3 . Moreover, since f1 (t) ≤ · · · ≤ fd (t), the map q 7→ Fq (t) is convex
and thus h3 (q) = Fq (t). But then gq (t) = h1 (q) − h1 (q − 1) ≍+ h3 (q) − h3 (q − 1) = fq (t) for
all q, i.e. g(t) ≍+ f(t).
Next, suppose that f is a template, and fix q, t, t′ such that gq (t) < gq+1 (t) and |t′ −t| ≤ η.
We will show that fq+1 (t′ ) − fq (t′ ) ≥ η and G′q (t) ≥ Fq′ (t′ ). Indeed, by (31.8) we have
Gq (t) = Gq,∗ (t) = Fq,∗ (t) + q(d − q)C4 = Fq (t) + q(d − q)C4
and on the other hand Gq±1 (t) ≤ Gq±1,∗ (t) = Fq±1 (t) + (q ± 1)(d − q ∓ 1)C4 . Consequently,
fq+1 (t) − fq (t) = Fq+1 (t) + Fq−1 (t) − 2Fq (t)
≥ Gq+1 (t) + Gq−1 (t) − 2Gq (t) + 2C4 ≥ 2C4 .
It follows that fq+1 (t′ ) − fq (t′ ) ≥ 2C4 − η. Choosing C4 ≥ η, we get fq+1 (t′ ) − fq (t′ ) ≥ η.
′
On the other hand, since Fq,∗
= G′q,∗ near t, by (31.5) we have G′q (t) ≥ Fq′ (t).
Finally, to demonstrate (31.2), let I be an interval on which both f and g are linear.
For all q such that gq < gq+1 on I, the previous argument gives G′q ≥ Fq′ on I, and thus
L+ (g, I, q) ≥ L+ (f, I, q) (the right-hand side being well-defined since fq < fq+1 on I). It

92

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

follows that
(31.9)



# S+ (g, I) ∩ (0, q]Z ≥ # S+ (f, I) ∩ (0, q]Z

for all q such that gq < gq+1 on I (cf. Definition 4.5). Combining with (4.8) shows that
(31.9) holds for all q = 1, . . . , d, and thus since
 
d−1
X

m
,
δ(f, I) =
# S+ (f, I) ∩ (0, q]Z −
2
q=1
we have δ(g, I) ≥ δ(f, I). Since I was arbitrary, we get (31.2).



Lemma 31.8. If Λ is a unimodular lattice in Rd , then the successive minima function h =
(h1 , . . . , hd ), where
hi (t) = log λi (gt Λ),
satisfies conditions (I)-(III)f =h appearing in the proof of Lemma 31.4, meaning that it can
be approximated by a template.
Proof. Condition (I) is immediate from the definition, while condition (II) follows from
some simple calculations which we leave to the reader. To demonstrate property (III), fix
j = 1, . . . , d − 1 and an interval [T1 , T2 ] such that hj+1 (t) > hj (t) for all t ∈ [T1 , T2 ]. For
each t ∈ [T1 , T2 ] let22
Vj (t) = hr ∈ Λ : kgt rk ≤ ehj (t) i = hr ∈ Λ : kgt rk < ehj+1 (t) i.
The assumption on [T1 , T2 ] guarantees that the map t 7→ Vj (t) is continuous on this interval, and since this map takes only rational values, it is therefore constant. So Vj (t) is
independent of t. By Minkowski’s second theorem (Theorem 30.1), for all t ∈ [T1 , T2 ] we
have
j
Y
λi (gt Λ) ≍ Covol(gt Vj (t)) = Covol(gt Vj ).
i=1

To continue further, we use the exterior product formula for covolume:
Covol(gt Vj ) = kgt v1 ∧ · · · ∧ gt vj k

where v1 , . . . , vj is a basis of Vj ∩ Λ. The expression on the right-hand side is a member
V
of the space j Rd , which has a basis of the form {eS : S ⊆ {1 . . . , d}, #(S) = j}. Thus,
Covol(gt Vj ) ≍ max hgt v1 ∧ · · · ∧ gt vj , eS i = max Covol(πS gt Vj ),
#(S)=j

22

#(S)=j

Here, Vj (t) is the smallest subspace containing {r ∈ Λ : kgt rk ≤ ehj (t) }. See Convention 4.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

93

where πS denotes the coordinate projection from Rd to RS . The logarithm of the righthand side is the maximum of linear maps whose slopes are in the set Z(j). Thus, the
function
def
Fj,[T1 ,T2 ] (t) = max log Covol(πS gt Vj )
#(S)=j

satisfies the appropriate conditions, cf. (31.4).



31.2. Mini-strategy. Suppose that Alice and Bob have played the first k turns of the
modified Hausdorff game, and that Alice wants to play so as to guarantee that the successive minima function of the outcome will be close to a given template g for some short
period of time starting at kγ. Whether or not she can do this depends both on the template g and on the lattice Λk given by (29.3). Intuitively, we expect that she can do it if
h(Λk ) is close to g(kγ), and Λk is “positioned in a way so as to allow Alice to continue
this correspondence for larger values of k”. If the lattice Λk is positioned appropriately,
we will call it a C-match for g at time kγ. We give the formal definition as follow:
Definition 31.9. Let g be a γ-integral partial template, and fix C > 0. A lattice Λ ⊆ Rd is
a C-match for g at time t ∈ γN if
(I) We have

kh(Λ) − g(t)k < C.

(31.10)

(II) There is a family of nested Λ-rational subspaces (Vq )q∈Q(t) , where
def

Q(t) = {q : gq (t) < gq+1 (t)},
such that for all q ∈ Q(t), we have dim(Vq ) = q,
log λi (Λ ∩ Vq ) − hi (Λ) ≤ C for all 1 ≤ i ≤ q,

(31.11)
and
(31.12)

dim(Vq ∩ L) ≥ L− (g, I, q),
where I is an interval of linearity for g whose left endpoint is t.

Fix C1 > 0. We now show that if Λk1 is a C1 -match for g at time t1 = k1 γ, then it is
possible for Alice to follow g for any fixed number of intervals of linearity to within an
additive constant depending on C1 :
Lemma 31.10. Fix k1 , k2 ∈ N with k2 > k1 and let ti = ki γ. Let g : [t1 , ∞) → Rd be a
γ-integral partial template, and let N be the number of maximal intervals of linearity of the
function g ↿ (t1 , t2 ). Suppose that on the k1 th turn of the dynamical game, Λk1 is a C1 -match

94

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

for g at time t1 . Then Alice has a strategy for turns k1 , . . . , k2 − 1 of the dynamical game
guaranteeing the following:
(i) For all k ∈ [k1 , k2 ]Z,
h(Λk ) ≍+,C1 ,N,β g(kγ).

(31.13)

(ii) The final lattice Λk2 is a C2 -match for g at time t2 , where C2 is a constant depending
only on C1 , N and β.
(iii) We have
kX
2 −1

1
log #(Ak )
∆(A, [k1 , k2 ]) =
= δ(g, [t1 , t2 ]) + O γ1 +
k2 − k1 k=k − log(β)
def

1

1
k2 −k1



,

where the implied constant may depend on C1 and N but does not depend on β.
Proof. By induction, it suffices to prove the lemma in the case where N = 1, i.e. where g
is linear on I = (t1 , t2 ).
def
Let Λ = Λk1 , and let
def

def

Q′ = {q : gq (t1 ) < gq+1 (t1 )},

Q = {q : gq < gq+1 on I}.

Note that using the notation from Definition 31.9, we have
Q′ = Q(t1 ) ⊆ Q(t1 ) ∪ Q(t2 ) = Q.
In the sequel, for each q ∈ Q′ , let Vq be as in Definition 31.9.
Claim 31.11. If β is sufficiently small, then there exists a family of Λ-rational subspaces
(Vq )q∈Q extending (Vq )q∈Q′ with the following properties:
(i)
(ii)
(iii)
(iv)

dim(Vq ) = q for all q ∈ Q.
Vp ⊆ Vq for all p, q ∈ Q such that p < q.
P
log kVq k ≍+ q1 gi (t1 ) for all q ∈ Q, where the implied constant may depend on C1 .
There exists X ∈ BM (0, 1 − β) such that for all q ∈ Q,
def

dim(uX Vq ∩ L) = L− (q) = L− (g, I, q).
and
dim(uX+Y Vq ∩ L) ≤ L− (q) for all kY k ≤ 2β 1/2 .
Proof. Fix ε > 0 small and independent of β, and let S± = S± (g, I). We will define the family (Vq )q∈Q and a sequence of linearly independent lattice vectors (ri )i∈S−
by simultaneous recursion: Fix j ∈ S− and suppose that ri has been defined for all

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

95

i ∈ S− (j) := {i ∈ S− : i < j}. Let q ∈ Q and r ∈ Q′ be maximal and minimal, respectively, such that q < j ≤ r. If Vq has not been defined yet, then let Vq ⊆ Vr be a Λ-rational
subspace of dimension q such that
(31.14)

Vp ⊆ Vq

∀p < q,

ri ∈ Vq

∀S− ∋ i ≤ q,

chosen so as to minimize kVq k subject to these restrictions. Then
dim(Vr ∩ L) ≥ L− (r) = #(S− (r + 1)) > #(S− (j)).
(31.12)

Further, we observe that

since



dim Vq +



P
dim(Vr ) > dim Vq + i∈S− (j) Rri
P

i∈S− (j)



Rri ≤ q + #(S− (j)) − #(S− (q + 1))
≤ q + j − (q + 1)
< j ≤ r.

Thus it is possible to choose rj ∈ Λ ∩ Vr such that 23
(31.15)
(31.16)

∡(rj , L) ≤ ε,


P
∡ rj , Vq + i∈S− (j) Rri ≥ ε2 ,

∡(ri , rj ) ≥ π/2 − ε

∀i ∈ S− (j),

log krj k .+ gj (t1 ).

Indeed, one produces rj by first choosing a unit vector
\
u1 ∈ Vr ∩ L ∩
r⊥
i ,
i∈S− (j)

choosing a second unit vector u2 ∈ Vr so that24



B(u2 , ε/3) ⊆ RB∡ (u1 , ε) \ N Vq +

X

i∈S− (j)

and finally choosing



Rri , ε2  ,

rj ∈ Λ ∩ Vr ∩ B(τ u2 , τ ε/3),
where τ = Cλr (Λ ∩ Vr ) for a constant C large enough to guarantee that Λ ∩ Vr is a
(τ ε/3)-net in Vr . Now both sides of (31.15) follow since rj ∈ RB∡ (u1 , ε). The left-hand
23

In the equations below, ∡ denotes the angle between two vectors, or between a vector and a vector
subspace.
24
We use N (A, ε) to denote the ε-neighborhood of a set A ⊆ Rd .

96

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

P
side of (31.16) follows since rj ∈
/ N (Vq + i∈S− (j) Rri , ε2 ). The right-hand side of (31.16)
follows from the fact that log λr (Λ ∩ Vr ) ≍+ gj (t1 ). Note that by construction, the family
(Vq )q∈Q satisfies (i) and (ii).
To demonstrate (iii), first we observe that it holds for q ∈ Q′ by Minkowski’s second
theorem (Theorem 30.1). By induction, suppose that (iii) holds for all p < q, where
q ∈ Q \ Q′ , and let p ∈ Q and r ∈ Q′ be maximal and minimal, respectively, such that
p < q ≤ r. Then by (31.16), we have
log Vp +

X

i∈S− (p,q)

Rri ≤ log kVp k +

X

i∈S− (p,q)

log kri k .+

X
i≤p

gi (t1 ) +

X

gi (t1 ),

i∈S− (p,q)

where S− (p, q) = {i ∈ S− : p < i ≤ q}. Thus by (31.10), it is possible to choose a
P
Λ-rational subspace Vq ⊆ Vr satisfying (31.14) such that log kVq k .+
i≤q gi (t1 ). The
reverse inequality follows directly from Minkowski’s second theorem (Theorem 30.1).
P
To demonstrate (iv), let L′ = j∈S− Rrj . Then (31.15) implies that dG (L, L′) = O(ε),
where dG denotes distance in the Grassmannian variety of n-dimensional subspaces of Rd ,
that we denote by G = G(d, n). It follows that if ε is sufficiently small, then there exists
X ∈ BM (0, 1 − β) such that u−X L = L′ . Then for all q ∈ Q, by (31.14) we have
dim(uX Vq ∩ L) = dim(Vq ∩ L′ ) ≥ #{i ∈ S− : i ≤ q} = L− (q).
Conversely, fix kY k ≤ 2β 1/2 and q ∈ Q. Let us define
X
def
W = u Y Vq ∩
Rri
S− ∋i>q

Then
dim(uX+Y Vq ∩ L) = dim(uY Vq ∩ L′ ) ≤ L− (q) + dim(W ).
Thus if dim(W ) = 0, then we are done with proving (iv). So by contradiction, suppose
that dim(W ) > 0, i.e. that there exists
0 6= r ∈ W.

P
Write r = S− ∋i>q ci ri for some constants ci ∈ R. Let S− ∋ j > q be chosen so as to
maximize θ−j |cj | · krj k, where θ > 0 is small. Since r 6= 0, we have ci 6= 0 for some i, and
thus θ−j |cj | · krj k ≥ θ−i |ci | · kri k > 0. Then
!
X
1
r−
ci r i
rj =
cj
i6=j

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

and thus

97

"
#

X
P
1
1 
kr − u−Y rk +
|ci | · kri k
d rj , Vq + i∈S− (j) Rri ≤
krj k
|cj | · krj k
i>j
.

kY k · krk X i−j
+
θ
|cj | · krj k
i>j

. 2β 1/2 max
i

|ci | · kri k
+θ
|cj | · krj k

. θ1−d β 1/2 + θ.
def

def

Letting θ = β 1/(2d) = ε3 gives



P
∡ rj , Vq + i∈S− (j) Rri . ε3 ,

which contradicts the first half of (31.16) if ε (or equivalently β) is sufficiently small.
This completes the proof of (iv), and thus of Claim 31.11.
⊳

Now for the purposes of defining Alice’s strategy, fix k = k1 , . . . , k2 − 1, and suppose
that the game has progressed to turn k, so that the matrices Xk1 , . . . , Xk−1 ∈ BM (0, 1 − β)
have all been defined. For each q ∈ Q let
def

Vq(k) = (guXk−1 ) · · · (guXk1 )Vq ,
where g = gγ and γ is as in Notation 29.1. By the definitions of Λ and Vq , Vq is Λk1 (k)
rational, and thus Vq is Λk -rational.
Now let (p, q]Z be an interval of equality for g on I, and consider the quotient lattice
def

Γk = Λk ∩ Vq(k) /Vp(k)
(k)

(more precisely, Γk is the image of Λk under the quotient map Vq
(k)
(ri )1q−p be a basis for Γk such that

(k)

(k)

kri k ≍ λi (Γk ) for all 1 ≤ i ≤ q − p.
For each j = 1, . . . , q − p let
(k)
Vp+j

=

Vp(k)

+

j
X

(k)

→ Vq /Vp ). Let

(k)

Rri .

i=1

Next, a matrix X will be called good on turn k if for all j = 1, . . . , d we have

def
(k)
(31.17)
dim uX Vj ∩ L = L− (j) = #(S− ∩ [1, j])

98

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

and
(31.18)

(k)

dim uX+Y Vj


∩ L ≤ L− (j) for all kY k ≤ 2β 1/2 .

Alice’s strategy on turn k can now be given as follows:

Let Ak be a maximal 3β-separated subset of the set of matrices
in BM (0, 1 − β) that are good on turn k.
Note that by Claim 31.11(iv), we have Ak 6= .
Now, to prove that Alice’s strategy guarantees (i)-(iii) in Lemma 31.10, consider a
2 −1
possible sequence of responses from Bob, i.e. a sequence (Xk )kk=k
such that for each k,
1
we have Xk ∈ Ak . For each k = k1 , . . . , k2 let
def

Zk =

k−1
X

ℓ=k1

so that for all q ∈ Q,

β ℓ−k1 Xℓ ∈ B(0, 1),

Vq(k) = g k−k1 uZk Vq
def

(cf. (29.5)). Now fix q ∈ Q, and let L± = L± (g, I, q). Fix k = k1 + 1, . . . , k2. Since Xk−1 is
good, we have
dim(uZk Vq ∩ L) = dim(Vq(k) ∩ L) = L−
and since Xk1 +1 is good and β 2 < 2β 1/2 (since β < 1), we have

dim uZk +Y Vq ∩ L ≤ L− for all kY k ≤ β 2 .
Now by Lemma 30.7, these two formulas imply that

log kVq(k) k − log kVq k ≍+ log kg k−k1 uZk Vq k − log kuZk Vq k


L+ L−
≍+,β
(k − k1 )γ
−
m
n
q
q
X
X
gi (t1 ).
gi (kγ) −
=
i=1

i=1

Combining with condition (iii) of Claim 31.11 shows that
(31.19)

log kVq(k) k

≍+,β

q
X

gi (kγ).

i=1

Now let (p, q]Z be an interval of equality for g on I, and let
def

Γk = Γk (p, q) = Λk ∩ Vq(k) /Vp(k)

(by (4.5))

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

99

as above.
Claim 31.12. We have
log λj (Γk ) ≍+,β gp+j (kγ)
for all j = 1, . . . , q − p and k = k1 , . . . , k2 .
Proof. Write
def

ηj (k) = log λj (Γk ) − gp+j (kγ).
By (31.19) and Minkowski’s second theorem (Theorem 30.1), we have
(31.20)

q−p
X
i=1

ηi (k) ≍+,β log kΓk k −

q
X

i=p+1

gi (kγ) ≍+ 0.

First suppose that M− = 0, where M± = M(g, I, p, q). Then for all j, k we have
(k − k1 )γ
≥ log λj (Γk ) − log λj (Γk1 ),
m
and (31.20) implies that approximate equality holds. Similar logic works if M+ = 0.
So suppose that M+ , M− > 0. Let K be a large constant. To complete the proof of
Claim 31.12 we will show that
K
K
≤ ηj (k) ≤
(31.21)
−
M+
M−
gp+j (kγ) − gp+j (k1 γ) =

for all j = 1, . . . , q − p and k = k1 , . . . , k2 , by induction on k. Indeed, suppose that (31.21)
holds for k, and we will prove that it holds for k ′ = k + ℓ0 , where ℓ0 is a large integer. By
(31.20), we have
jηj (k) ≥

j
X
i=1

ηi (k) ≍+,β −

q−p
X

i=j+1

ηi (k) ≥ −

(q − p − j)K
·
M−

Letting j = M+ + 1 shows that
ηM+ +1 (k) &+,β −

M− − 1 K
K
=−
+ αK,
M− M+ + 1
M+

where α > 0 is a positive constant.
Note that since gp+j (t) = gq (t) for all t ∈ I and j = 1, . . . , q −p, we have η1 ≤ · · · ≤ ηq−p ,
so if (31.21) fails for k ′ = k + ℓ0 , then either η1 (k ′ ) < −K/M+ or ηq−p (k ′ ) > K/M− . By
contradiction suppose that η1 (k ′ ) < −K/M+ (the other case is similar). Then η1 (k) ≍+,ℓ0 ,β
−K/M+ and thus
ηM+ +1 (k) − η1 (k) &+,ℓ0 ,β αK.

100

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

If K is sufficiently large in comparison to ℓ0 , then it follows that there exists j = 1, . . . , M+
such that
αK
(31.22)
ηj+1 (k) − ηj (k) ≥
.
M+ + 1
It follows from (31.22) that
(ℓ)

Vj

(k)

= bk,ℓ Vj

for all ℓ = k, . . . , k ′

def

where bk,ℓ = (guXℓ−1 ) · · · (guXk ). Thus since Xk , . . . , Xℓ−1 are good, Lemma 30.7 shows
that


L+ (p + j) L− (p + j)
(k ′ )
(k)
′
log kVp+j k − log kVp+j k ≍+,β (k − k)γ
.
−
m
n
Subtracting (31.19) (with q = p) and using the asymptotic
(ℓ)
log kVp+j k

−

log kVp(ℓ) k

and the relations

≍+,β

j
X

L+ (p + j) = L+ (p) + j,

log λi (Γℓ )

i=1

L− (p + j) = L− (p)

(valid since j ≤ M+ ) show that
j
X
i=1

log λi (Γk′ ) −

j
X
i=1

log λi (Γk ) ≍+,β (k ′ − k)γ

On the other hand, since log kbk,k′ k .+ (k ′ − k)γ/m, we have
log λi (Γk′ ) − log λi (Γk ) .+ (k ′ − k)γ
and thus
log λi (Γk′ ) − log λi (Γk ) ≍+,β (k ′ − k)γ
In particular
′

η1 (k ) − η1 (k) ≍+,β



1
m

1
for all i = 1, . . . , j.
m

1
1
(k − k)γ
−
m M+ + M−
′

j
·
m



M+ M−
−
m
n



.

The right-hand side is strictly positive, so if ℓ0 is sufficiently large, then the left-hand side
is also positive. But this contradicts our assumption that η1 (k ′ ) < −K/M+ ≤ η1 (k), thus
demonstrating (31.21). This concludes the proof of Claim 31.12.
⊳

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

101

Next, note that for any 1 ≤ i ≤ q we have that
λq′ −p′ (Γk (p′ , q ′)),
λi (Γk (p, q)) ≤ λp+i (Λk ∩ Vq(k) ) . max
′ ′
(p ,q ]
q ′ ≤q

where the maximum is taken over all intervals of equality (p′ , q ′ ] for g that satisfy q ′ ≤ q.
Indeed, the first inequality can be demonstrated by observing that the projection of a set
of p + i linearly independent vectors in Λk ∩ Vq contains a linearly independent set of i
vectors in Γk (p, q). For the second inequality, denote the right-hand side by λ and note
that by pulling back vectors appropriately, we can recursively construct bases of Λk ∩ Vq′
for all q ′ ≤ q, such that the largest vector in each basis has norm . λ.
Now using Claim 31.12, we have that

gq′ (kγ) = gq (kγ) = gp+i (kγ),
gp+i (kγ) .+,β log λp+i (Λk ∩ Vq(k) ) .+,β max
′ ′
(p ,q ]
q ′ ≤q

where the maximum is taken as before. Thus we have that for p < j ≤ q
(31.23)

log λj (Λk ∩ Vq ) ≍+,β gj (kγ).
(k)

To demonstrate (31.10) and (31.11), we pick r ∈ Λk \Vp . Now consider the projection
map
π : Vq → Vq /Vp
and note that
krk ≥ kπ(r)k ≥ λ1 (Γk (p, q)) ≍×,β exp(gp+1 (kγ)).
Therefore we have that log λp+1 (Λk ) &+,β gp+1(kγ). Thus for p < j ≤ q, we also have
log λj (Λk ) &+,β gj (kγ).
On the other hand, by the monotonicity of the successive mimina functional we have
log λj (Λk ∩ Vq ) ≥ log λj (Λk ).
Therefore, using (31.23) and the previous two display equations, we get
gj (kγ) ≍+,β log λj (Λk ∩ Vq ) ≍+,β log λj (Λk ),
and thus (31.10), (31.11) and (31.13) hold with Λ = Λk2 and t = t2 , as long as C is
sufficiently large. This completes the proof of condition (i) of Lemma 31.10.
We proceed to prove conditions (ii) and (iii). By (31.13), (31.10) holds with Λ = Λk2 ,
t = t2 , and C = C2 , where C2 is the implied constant of (31.13). Observe that by (31.12)
we have
dim(Vq (Λk2 ) ∩ L) = dim(Vq(k2 ) ∩ L) ≥ L− (g, I, q) ≥ L− (g, I+ , q),

102

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

where I+ is the interval of linearity for g whose left endpoint is t2 . Note that the last
inequality is due to the assumption of convexity in (III) of Definition 4.1. It follows that
condition (II) of Definition 31.9 holds with Λ = Λk2 and t = t2 , which completes the
proof of (ii).
To demonstrate (iii), it suffices to show that
(a) #(Ak1 ) ≥ 1, and
(b) #(Ak ) & β −δ for all k > k1 , where δ = δ(g, I).
Note that (a) is true by part (iv) of Claim 31.11. To demonstrate (b), fix k > k1 , and
observe that since Xk−1 is good on turn k − 1, for all q ∈ Q we have
(31.24)

dim(Vq(k) ∩ L) = L− (q)

and
dim(uY Vq(k) ∩ L) ≤ L− (q)

We now construct a basis of Rd as follows.

∀ Y ∈ BM (0, β −1/2 ).

Claim 31.13. There exists an almost orthonormal basis (ri )d1 of Rd (meaning that ri · rj =
δij + o(1) as β → 0 for all i, j), which contains a subset that is an orthonormal basis of L.
def

Proof. Let (p, q]Z be an interval of equality for g on I, and let M± = M± (p, q) (as defined
p+M
in (4.7)). Let (ri )p+1 + be an orthonormal basis of
def

W+ (p, q) = Vq(k) ∩ (Vp(k) )⊥ ∩ (Vq(k) ∩ L)⊥
and let (ri )qp+M+ +1 be an orthonormal basis of
def

W− (p, q) = Vq(k) ∩ L ∩ (Vp(k) ∩ L)⊥ .
Such bases exist because (31.24) allows us to compute the dimensions of these spaces.
Then we claim that (ri )d1 is an almost orthonormal basis of Rd (meaning that ri · rj =
δij + o(1) as β → 0 for all i, j), and that (ri )i∈S− is an orthonormal basis of L (where S−
is defined in (4.9)).
Indeed, to see why (ri )d1 is almost orthonormal, we consider four cases:
(31.25)

ri ∈ W+ (p1 , q1 ), rj ∈ W+ (p2 , q2 )

(31.26)

ri ∈ W+ (p1 , q1 ), rj ∈ W− (p2 , q2 )

(31.27)

ri ∈ W− (p1 , q1 ), rj ∈ W+ (p2 , q2 )

(31.28)

ri ∈ W− (p1 , q1 ), rj ∈ W− (p2 , q2 )

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

103

for p1 ≤ q1 and p2 ≤ q2 . In the three cases (31.25), (31.27) and (31.28), we have that
ri · rj = δij by part (ii) of Claim 31.11. Note that since W− (p, q) ⊆ L, it follows from
(31.28) that (ri )i∈S− is an orthonormal basis of L.
So we are left to consider the case (31.26). Note that in this case we may assume that
p1 < q1 ≤ p2 < q2 (since if p1 = q1 and p2 = q2 , then (31.26) reduces to (31.27)).
def
(k)
Let V = Vp2 . Then ri ∈ W+ (p1 , q1 ) ⊆ V ∩ (V ∩ L)⊥ and rj ∈ W− (p2 , q2 ) ⊆ L ∩ (V ∩ L)⊥ .
Write ri = (p, q′ ) and rj = (0, q). Now let
def

Yv= −

(q′ · v)
p.
(q′ · q′ )

Then note that uY (p, q′ ) ∈ L and uY (V ∩ L) = V ∩ L. Therefore we have that
dim(uY (V ) ∩ L) > dim(V ∩ L).
Thus by part (iv) of Claim 31.11, we have that
kY k > 2β −1/2 .
Since kY k ≤ 1/kq′k2 it follows that kq′ k < β 1/4 . Therefore
|ri · rj | = |q · q′ | ≤ kq′ k < β 1/4 .
Thus ri · rj = δij + o(1) as β → 0 for all i, j as claimed. This concludes the proof of Claim
31.13.
⊳
Let Z be the space of all d × d matrices X such that for all i, j such that Xi,j 6= 0, we
have i > j, i ∈ S− , and j ∈ S+ . Evidently, dim(Z) = δ(g, I). Now let R be the matrix
whose column vectors are r1 , . . . , rd . Then for all Z ∈ Z, the matrix R · (I + Z) · R−1
(k)
preserves the subspaces (Vq )q∈Q . Now define a map Φ : Z → M as follows: for each
Z ∈ Z, X = Φ(Z) is the unique matrix such that
uX L = R · (I + Z) · R−1 L.
It is easy to check that in a neighborhood of the origin, Φ is a bi-Lipschitz embedding
with bi-Lipschitz constant depending only on max(kRk, kR−1k). But since the basis (ri )d1
is almost orthonormal as proved in Claim 31.13, there is a uniform bound on this constant
as long as β is sufficiently small.
Thus, let C be the bi-Lipschitz constant of Φ. Let A′k be a maximal 3Cβ-separated
subset of BZ (0, 1/C). Then Ak = Φ(A′k ) is a 3β-separated subset of B(0, 1) consisting
entirely of matrices good on turn k. It follows that
#(Ak ) = #(A′k ) ≍ β −δ .

104

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

This concludes the proof of condition (iii) of Lemma 31.10, and therefore of the entire
lemma.

31.3. Error correction. Fix η > 0, let f be a simple η-integral template, fix t0 ∈ ηN, and
let b = (b1 , . . . , bd ) ∈ Rd be a vector such that bi ≤ bi+1 for all i such that fi (t0 ) = fi+1 (t0 ).
Such a vector will be called a perturbation vector of f at t0 . For convenience, for each
k ∈ N let tk = t0 + kη. We define the function a : N ∪ {−1} → Rd recursively as follows:
• a(−1) = b.
• Fix k ≥ 0 such that a(k − 1) has been defined, and let Ik = (tk , tk+1). If (p, q]Z is
an interval of equality for f on Ik (cf. Definition 4.5), then for all i = p + 1, . . . , q,
we let

′


if fp+1
= . . . = fq′ ∈ { m1 , − n1 } on (t0 , tk+1 )
ai (k − 1)
q
(31.29)
ai (k) =
1 X

aj (k − 1) otherwise.

q − p
j=p+1

The idea is that we will construct a new template by displacing f by a(k) on each interval
Ik , and then changing the resulting function into a template by modifying it slightly
to deal with the issues that arise near multiples of η. The motivation for the equation
(31.29) will become apparent when we analyze when it is possible to perform such a
modification. Note that by induction, for all k we have
ka(k)k∞ ≤ kbk∞

(31.30)
and
(31.31)

ai (k) ≤ ai+1 (k) whenever fi = fi+1 on Ik .

Lemma 31.14. Let the notation be as above. If kbk∞ < Cη =
partial template g : [t0 , ∞) → Rd such that

η
, then there exists a
2mnd!

g(t0 ) = f(t0 ) + b

(31.32)
and such that for all k, we have
(31.33)
where a is as above, and


def
g = f + a(k) on Iek = tk + s, tk+1 − s ,
def

s = 2mnd2 kbk∞ .

Moreover, we have
(31.34)

δ(g, t) = δ(f, t) for t ∈ Iek .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

105

The partial template g constructed in the proof below will be called the b-perturbation
of f at t0 .
Proof. We will first show that for all k ≥ 0, if g is any function satisfying (31.33), then
g ↿ Iek is a partial template. Indeed, since g is linear on Iek , it suffices to check conditions
(I) and (II) of Definition 4.1, along with the following weakening of condition (III):
(III′ ) For all j = 1, . . . , d − 1 such that gj < gj+1 on Iek , we have G′j (Iek ) ∈ Z(j).

Condition (II) is obvious, so we check (I) and (III′ ).

Proof of (I). Fix i = 1, . . . , d − 1, and we will show that gi ≤ gi+1 on Iek . There are three
cases:

• If fi = fi+1 on Ik , then by (31.31) we have ai (k) ≤ ai+1 (k) and thus gi ≤ gi+1 on
Iek .
′
• If fi (tk ) = fi+1 (tk ) but fi < fi+1 on Ik , then we have fi′ (Ik ) < fi+1
(Ik ), and thus
′
fi+1 − fi > (fi+1
(Ik ) − fi′ (Ik ))s

≥

1
s
mnd2

(on Iek )

(by Observation 30.8)

= 2kbk∞
≥ |ai+1 (k) − ai (k)|,

(by (31.30))

so gi < gi+1 on Iek . Similar logic applies if fi (tk+1 ) = fi+1 (tk+1 ) but fi < fi+1 on Ik .
• If fi (tk ) < fi+1 (tk ) and fi (tk+1 ) < fi+1 (tk+1 ), then since f is η-integral we have

fi+1 − fi ≥ min fi+1 (tk ) − fi (tk ), fi+1 (tk+1 ) − fi (tk+1 )
(on Ik )
≥

η
mnd!

(by Definition 31.1)

= 2Cη
> 2kbk∞
≥ |ai+1 (k) − ai (k)|
and thus gi < gi+1 on Iek .

(by hypothesis)
(by (31.30))

Proof of (III′ ). Fix j = 1, . . . , d − 1 such that gj < gj+1 on Iek . There are two cases:

⊳

• If fj < fj+1 on Ik , then G′j (Iek ) = Fj′ (Ik ) ∈ Z(j).
• If fj = fj+1 on Ik , then aj (k) < aj+1 (k). Moreover, j and j + 1 are in the same
′
interval of equality (p, q]Z ∋ j, j + 1 for f on Ik . By (31.29) we have fp+1
(Ik ) =
1
1
′
. . . = fq′ (Ik ) ∈ { m , − n }. Without loss of generality suppose that fp+1
(Ik ) = . . . =

106

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

fq′ (Ik ) =

1
.
m

Then we have

L+ (f, Ik , p) + (j − p) L− (f, Ik , p)
G′j (Iek ) = Fj′ (Ik ) =
−
∈ Z(j).
m
n

(The intuition behind this calculation is that m1 and − n1 are “free slopes” that can
be used by an individual fj without the need for averaging; cf. the model of
“particle physics” described in the paragraph below Definition 4.5.)
⊳
Next, we demonstrate (31.34). Let (p, q]Z be an interval of equality for f on Ik . By the
proof of (I) above, we have gp < gp+1 and gq < gq+1 on Iek . Let
M± = M± (f, Ik , p, q) = L± (g, Iek , q) − L± (g, Iek , p).

If M+ > 0 and M− > 0, then ap+1 (k) = . . . = aq (k) and thus (p, q]Z is an interval of
equality for g on Iek , which implies that S+ (f, Ik ) ∩ (p, q]Z = S+ (g, Iek ) ∩ (p, q]Z. On the
other hand, if M+ = 0, then S+ (f, Ik ) ∩ (p, q]Z =  = S+ (g, Iek ) ∩ (p, q]Z, and if M− = 0,
then S+ (f, Ik ) ∩ (p, q]Z = (p, q]Z = S+ (g, Iek ) ∩ (p, q]Z. Since (p, q]Z was arbitrary we have
S+ (f, Ik ) = S+ (g, Iek ) and thus δ(f, Ik ) = δ(g, Iek ).
Finally, we describe how to define g on an interval of the form

 t − s, t + s if k > 0
k
k
def
(31.35)
Jk = 
 t0 , t0 + s
if k = 0
We now consider two cases:

Case 1. If a(k − 1) = a(k), then we can continue to use the formula g = f + a(k) on
Jk . Minor modifications to the previous argument show that g ↿ Iek−1 ∪ Jk ∪ Iek is a partial
template (where we use the convention that Ie−1 = ).

Case 2. Suppose that a(k − 1) 6= a(k). By (31.29), this means that tk is either a merge,
a transfer, or t0 . We restrict our attention to the case where tk is a merge; the other cases
are similar. Define g on Jk as follows: Let (p, q]Z be an interval of equality for f on Ik
which is not an interval of equality for f on Ik−1 , and let M± = M± (f, Ik , p, q), so that
′
= fq′ ∈
M+ + M− = q − p. Note that M+ , M− > 0, as otherwise we would have fp+1
{ m1 , − n1 } on Ik−1 , and thus (p, q]Z would be an interval of equality for f on Ik−1 . We define
the piecewise linear functions gp+1, . . . , gq on Jk by imposing the following conditions:
• We have
(31.36)

g(min(Jk )) = f(min(Jk )) + a(k − 1).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

• We have
(31.37)

q
X

i=p+1

gi′

=

q
X

fi′ =

i=p+1

107

M+ M−
−
on Jk
m
n

(the second equality holds because tk cannot be a transfer, since f is simple).
• For all p < i ≤ p + M+ and t ∈ Jk , we have gi′ (t) = m1 unless gi (t) = gp+M+ +1 (t), in
which case gi′ (t) = z(t).
• For all p + M+ < i ≤ q and t ∈ Jk , we have gi′ (t) = − n1 unless gi (t) = gp+M+ (t), in
which case gi′ (t) = z(t).
The number z(t) appearing in the last two conditions can be computed by plugging the
values of gi′ appearing in those conditions into (31.37) and then solving for z(t). In all of
the above formulas, derivatives should be assumed to be taken from the right.
It is easy to check that these conditions uniquely determine the functions gp+1 , . . . , gq
on the interval Jk . To ensure that this does not lead to an inconsistency with (31.33), we
need to check that
(31.38)

g(max(Jk )) = f(max(Jk )) + a(k).

Since tk is not a split, by (31.29) the map i 7→ fi (max(Jk )) + ai (k) is constant on (p, q]Z.
def
Suppose first that the map i 7→ gi (max(Jk )) is also constant on (p, q]Z. Let h(t) = (Gq −
Pq
Gp )(t) − (Fq − Fp )(t). Then (31.36) implies that h(min(Jk )) =
p+1 ai (k − 1). Now
Pq
′
by (31.29) this gives h(min(Jk )) =
p+1 ai (k), and so using (31.36) we have h = 0
Pq
and thus h(max(Jk )) = p+1 ai (k). Rearranging gives the sum of the ith coordinate of
(31.38) over i ∈ (p, q]Z.
On the other hand, suppose that i 7→ gi (max(Jk )) is not constant on (p, q]Z. Suppose
not. Then either there exists p < i ≤ p + M+ such that gi (t) < gp+M+ +1 (t) for all t ∈ Jk ,
or there exists p + M+ < i ≤ q such that gi (t) > gp+M+ (t) for all t ∈ Jk . Without loss of
generality suppose the first case holds. Then gp+1 (t) < gp+M++1 (t) for all t ∈ Jk , and thus
′
gp+1
(t) = m1 for all t ∈ Jk . Now let
def

F (t) =

q
X


i=p+1
def

G(t) =

q
X


i=p+1


fi (t) − fp+1 (t) ,


gi (t) − gp+1 (t) .

Then F (t), G(t) ≥ 0, F (tk ) = 0, and




q−p
1
1
M+ M−
def
′
′
−
.
−
= −M−
+
F (t) ≥ G (t) = −Z =
m
n
m
m n

108

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

It follows that
0 ≤ G(max(Jk )) = G(min(Jk )) − Z|Jk |
≤ F (min(Jk )) + 2dkbk∞ − Z|Jk |


≤ F (tk ) + Z k > 0 s + 2dkbk∞ − Z|Jk | = 2dkbk∞ − Zs < 0,

where the last inequality follows from the definition of s and the inequality M− ≥ 1. This
is a contradiction, and therefore (31.38) holds and so g is continuous in a neighborhood
of max(Jk ).
Thus g is continuous on [t0 , ∞). Indeed, we have that g is piecewise linear on Jk
by definition and on Iek by (31.33). Further, g is continuous at the transition points
min(Jk ) ∈ Iek−1 ∩ Jk and max(Jk ) ∈ Jk ∩ Iek . The former follows from (31.36) and the
latter from (31.38).
Recall that we have previously shown that g ↿ Iek is a partial template. We leave the
verification of the other conditions of Definition 4.1 as an exercise to the reader. This
concludes the proof of Lemma 31.14.

Now we combine the concept of perturbation vectors with the concept of C-matches
introduced in §31.2. The following lemma shows that by perturbing a template, it is
possible to improve the constant C appearing in Definition 31.9:
Lemma 31.15. Let Λ be a Cη -match for an η-integral template f at t0 ∈ ηN, and let g be
the b-perturbation of f at t0 , where b ∈ (d3 )!γZd is a perturbation vector such that
(31.39)

h(Λ) − [f(t0 ) + b]

∞

< C1

for some constant C1 ≤ Cη . Suppose that t0 is not a split with respect to f. Then g is
γ-integral and Λ is a C1 -match for g at t0 .
Proof. To show that g is γ-integral, we need to check both conditions (I) and (II) of
Definition 31.1. To show (II), we note that since f is η-integral and b ∈ (d3 )!γZd , it
follows by (31.32) that for all 1 ≤ i ≤ d we have
γ
gi (t0 ) ∈
Z.
mnd!
This is sufficient by the remark at the end of Definition 31.1. To show (I), we need to
prove that all the corner points of g are multiples of γ. Suppose that t is a corner point
def
for g. Then t ∈ Jk for some k (cf. (31.35)), and we let t∗ = min(Jk ). Now on the interval
(t∗ , t), for some i ≤ p + M+ < j, the slopes of gp+1, ..., gi are all equal to 1/m, the slopes

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

109

of gj+1 , ..., gq are all equal to −1/n. We can without loss of generality assume that
gi+1 (t) = ... = gj (t) = z(t)
and
gi (t) = z(t) or gj+1(t) = z(t).
Note that we may choose gi (t) = z(t) over gj+1(t) = z(t), without any loss of generality.
def
(Here z(t) is the same as in proof of Lemma 31.14.) Then, letting ∆t = t − t∗ , on the one
hand we have that
q
X

gk (t) =

p+1

i
X
p+1

gk (t) +

q
X
j+1

gk (t) + (j − i)gi (t)



q
∆t X
∆t
∆t
=
gk (t∗ ) + (i − p)
,
gk (t∗ ) − (q − j)
+
+ (j − i) gi (t∗ ) +
m
n
m
p+1
j+1
i
X

while, on the other, using (31.37), we have that


q
q
X
X
M+ M−
∆t.
−
gk (t∗ ) +
gk (t) =
m
n
p+1
p+1
Solving for ∆t gives us that
(A/m + A/n)∆t ∈ (d3 )!γZ
def

where A = j − (p + M+ ) ∈ (0, M− ]Z, and therefore that
(m + n)A(t − t∗ ) ∈ (d3 )!γZ.
It thus follows that t ∈ γZ. This completes the proof that g is γ-integral.
Since g(t0 ) = f(t0 ) + b, (31.39) implies that condition (I) of Definition 31.9 holds with
C = C1 and t = t0 . Let I+ be an interval of linearity for both f and g whose left endpoint
is t0 , and let (p, q]Z be an interval of equality for f on I+ . Then fq (t) < fq+1 (t), so since f
is η-integral, by (31.39) we have hq (Λ) < hq+1 (Λ). For each j ∈ (p, q]Z ∩ Q(t0 ), let Vj be a
Λ-rational subspace of the linear span of {r ∈ Λ : krk ≤ λj (Λ)} of dimension j. Then

dim(Vj ∩ L) ≥ max dim(Vp ∩ L), dim(Vq ∩ L) − (q − j)

≥ max L− (f, I+ , p), L− (f, I+ , q) − (q − j) = L− (f, I+ , j) = L− (g, I+ , j),

where the second-to-last equality follows from the assumption that t0 is not a split for f.
This concludes the proof of Lemma 31.15.


110

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

31.4. Uniform error bounds. We are now ready to complete the proof of (31.1). First,
by Lemma 31.4 we can without loss of generality assume that f is simple and that its
corner points are all multiples of 2η, where η = kη γ, kη ∈ N is large to be determined,
and γ is as above. After translating by η, we can assume that the corner points are at odd
multiples of η instead of even multiples. We can now define Alice’s strategy as follows:
Fix ℓ ∈ N and let kℓ = 2ℓkη , and suppose that the game has progressed to turn kℓ . This
means that the lattice Λ(ℓ) := Λkℓ has already been defined.
• If Λ(ℓ) is not a Cη -match for f at tℓ := kℓ γ = 2ℓkη γ, then Alice resigns on turn kℓ .
• Suppose that Λ(ℓ) is a Cη -match for f at tℓ . Let b = b(ℓ) be the element of (d3 )!γZd
closest to h(Λ(ℓ) ) − f(tℓ ) (using any tiebreaking mechanism). Then b is a perturbation vector satisfying (31.39) with Λ = Λ(ℓ) , t0 = tℓ , and C1 = (1/2)(d3)!γ. Let
g = g(ℓ) be the b-perturbation of f at tℓ . Then by Lemma 31.15, g is γ-integral
and Λ(ℓ) is a C1 -match for g. This allows us to apply Lemma 31.10 (setting k1
and k2 Lemma 31.10 to be kℓ and kℓ+1 , respectively), and on turns kℓ , . . . , kℓ+1 − 1
Alice plays the strategy given by this lemma.
We assume that Alice does not resign at turn kℓ . Let t′ℓ := (2ℓ + 1)η. Since f is linear
(ℓ)
(ℓ)
on I0 := [tℓ , t′ℓ ] and I1 := [t′ℓ , tℓ+1 ], it follows that g is linear on [tℓ + s, t′ℓ − s] and
[t′ℓ + s, tℓ+1 ]. On the other hand, note that in the proof of Lemma 31.14, (31.37) and the
following bullet points imply that on each interval Jk = [tℓ , tℓ + s] or [t′ℓ − s, t′ℓ + s], g only
changes slopes at points t such that gi < gj on (min(Jk ), t) and gi = gj on (t, max(Jk ))
for some i < j. It follows that g has at most d − 1 maximal intervals of linearity on Jk ,
and thus at most 2d maximal intervals of linearity on Iℓ . In particular we have N ≤ 2d in
Lemma 31.10.
To compute the relation between b(ℓ) and b(ℓ+1) , we let a(ℓ) : N ∪ {−1} → Rd be the
function defined in §31.3, so that a(ℓ) (−1) = b(ℓ) . Then we have
g(ℓ) = f + a(ℓ) (0) on Ie0 = [tℓ + s, t′ℓ − s],
(ℓ)

(ℓ)
(ℓ)
(ℓ)
g(ℓ) = f + a(ℓ) (1) on Ie1 ∪ J2 ∪ Ie2 = [t′ℓ + s, t′ℓ+1 − s].
(ℓ)

The second equality follows from the fact that t2 = tℓ+1 is not a corner point, so a(ℓ) (1) =
a(ℓ) (2) and thus Case 1 of the proof of Lemma 31.14 applies. In particular, we have
g(ℓ) (tℓ+1 ) = f(tℓ+1 ) + a(ℓ) (1).
On the other hand, according to part (ii) of Lemma 31.10, Λ(ℓ+1) := Λkℓ+1 is a C2 -match
for g(ℓ) at tℓ+1 , where C2 is a constant depending only on C1 . Thus, using (I) of Definition

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

111

31.9, we have
h(Λ(ℓ+1) ) − [f(tℓ+1 ) + a(ℓ) (1)]

and so by the definition of b(ℓ+1) , we have

∞

≤ C2 ,

kb(ℓ+1) − a(ℓ) (1)k∞ ≤ C2 + C1 ,

(31.40)

assuming that Alice does not resign on turn kℓ+1 .
Assume now that there exists a constant B > 0 (which is independent of Bob’s strategy)
such that
(31.41)

kb(ℓ) k∞ ≤ B for all ℓ such that Alice does not resign on or before turn kℓ .

Fix ℓ such that Alice does not resign on or before turn kℓ . Then Λ(ℓ+1) is a C2 -match for
g(ℓ) at tℓ+1 , and is therefore a (C2 +B)-match for f at tℓ+1 , since ka(ℓ) (1)k∞ ≤ kb(ℓ) k∞ ≤ B.
Letting kη be large enough so that η ≥ 4mnd!(C2 + B), we see that Λ(ℓ+1) is a Cη -match
for f at tℓ+1 , and thus Alice does not resign on turn kℓ+1 . So by induction Alice never
resigns.
So for all ℓ ∈ N, Λ(ℓ) is a C-match for f at tℓ , where C := C2 + B. It follows from
Definition 31.9 that for all ℓ ∈ N
kh(Λℓ ) − f (tℓ )k ≤ C
and so using Lemma 29.2 gives us that the final outcome X∞ (as defined by (29.2)) is in
the target set D(f).
To compute Alice’s score, we use part (iii) of Lemma 31.10 to get that

1X
1X
∆(A, [0, kℓ ]) =
∆(A, [kj , kj+1]) =
δ(f, [tj , tj+1]) + O γ1 +
ℓ j=0
ℓ j=0


1
1
= δ(f, [0, tℓ ]) + O γ + kη
ℓ−1

ℓ−1

and thus after taking liminfs on both sides we have

δ(A) = δ(f) + O γ1 +

1
kη



1
2kη



.

Given ε > 0, we can choose β small enough (and so γ large enough) and kη large enough
so that the last term is less than ε, which shows that δ(A) ≥ δ(f) − ε, and thus D(f)
is (δ(f) − ε)-dimensionally Hausdorff β-winning. Applying Theorem 28.2 shows that
dimH (D(f)) ≥ δ(f) − ε. Now in the above argument we can replace all δs by δs, and
all liminfs by limsups, to prove that dimP (D(f)) ≥ δ(f) − ε. This completes the proof of
(31.1) assuming (31.41). In what follows we will prove (31.41).

112

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Given q = 0, . . . , d, an interval [ℓ1 , ℓ2 ] will be called a q-interval if either
fq < fq+1 on (t′ℓ1 −1 , t′ℓ2 )
or
′
= c on (t′ℓ1 −1 , t′ℓ2 ), where c ∈ { m1 , − n1 }·
fq′ = fq+1

Note that every interval is both a 0-interval and a d-interval (according to our convention
that f0 = −∞ and fd+1 = +∞).
Claim 31.16. Fix q = 1, . . . , d − 1 and let [ℓ1 , ℓ2 ] be a q-interval. Then there exists a constant
α = α(q, ℓ1, ℓ2 ) such that for all ℓ = ℓ1 , . . . , ℓ2 , we have
q
X

(31.42)

i=1

(ℓ)

bi ≍+,β α(q, ℓ1 , ℓ2 ).

Proof. First suppose that fq < fq+1 on (t′ℓ1 −1 , t′ℓ2 ). Since Λ(ℓ) is a C2 -match for g(ℓ) at tℓ , we
have
q
q
X
X
(ℓ)
hi (Λ(ℓ) ) − Fq (tℓ ).
bi ≍+,β
i=1

i=1

Let V

(ℓ)

=

(ℓ)
Vq

be as in Lemma 30.5 (applied to the lattice Λ(ℓ) ), and recall we have
q
X
i=1

hi (Λ(ℓ) ) ≍+ log kV (ℓ) k.

Since fq < fq+1 on (t′ℓ1 −1 , t′ℓ2 ), we have guXℓ V (ℓ) = V (ℓ+1) for all ℓ.
Since we know that Alice is following her strategy, as defined in the proof of Lemma
31.10, then for each turn k = kℓ1 − kη , . . . , kℓ2 + kη the matrix Xk is good on turn k (as
defined in (31.17)-(31.18)). Thus the hypotheses of Lemma 30.7 are satisfied, and it
then follows that
′
log kV (ℓ ) k − log kV (ℓ) k ≍+,β (tℓ′ − tℓ )z

for any ℓ < ℓ′ such that Fq′ = z on (tℓ , tℓ′ ). Note that a similar argument appeared earlier
in the paragraph containing (31.19). Now since Fq is piecewise linear on (t′ℓ1 −1 , t′ℓ2 ) with
a bounded number of intervals of linearity, it follows that
ˆ tℓ
(ℓ)
(ℓ1 )
log kV k − log kV k ≍+,β
Fq′ = Fq (tℓ ) − Fq (tℓ1 ).
tℓ1

Thus, letting
def

α(q, ℓ1 , ℓ2 ) = log kV (ℓ1 ) k − Fq (tℓ1 )

completes the proof of the claim in the case fq < fq+1 on (t′ℓ1 −1 , t′ℓ2 ).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

113

′
Now suppose that fq = fq+1 and fq′ = fq+1
= m1 on I0 = (t′ℓ1 −1 , t′ℓ2 ) (the case where
′
fq′ = fq+1
= − n1 on I0 proceeds similarly). For each interval of linearity I ⊆ I0 and for
each t ∈ I, let (p(t), r(t)]Z be the interval of equality for I that contains q. Since m1 is
′
the maximum possible derivative for any fj and since fq′ = fq+1
= m1 on I0 , it follows
that fq = fq+1 can only merge with fj if j > q + 1, and can only split from fj if j < q;
equivalently, p and r are increasing functions. Since p, r are integer-valued, it follows that
I0 can be decomposed into a bounded number of intervals on which p, r are constant. So
we can without loss of generality suppose that p and r are constant. But then by the same
logic as before we have
′

log kVp(ℓ ) k − log kVp(ℓ) k ≍+,β (tℓ′ − tℓ )zp ,
′

log kVr(ℓ ) k − log kVr(ℓ) k ≍+,β (tℓ′ − tℓ )zr ,
where zp , zr ∈ [− n1 , m1 ] satisfy
zr − zp =

(31.43)

r−p
·
m

Now let
def

(ℓ)

and note that hVj

h = (guXℓ′−1 ) · · · (guXℓ )

(ℓ′ )

= Vj

. Furthermore, we have

khk . exp 2(ℓ′ − ℓ)kη · m1 = exp (tℓ′ − tℓ ) ·
(ℓ)

(ℓ)

where k · k denotes the operator norm. Letting h : Vq /Vp
map, we have khk ≤ khk and thus

1
m



(ℓ′ )

→ Vq

(ℓ′ )

/Vp

be the induced

 (ℓ) (ℓ)
′
′
kVq(ℓ ) /Vp(ℓ ) k . khkq−p kVq(ℓ) /Vp(ℓ) k . exp (tℓ′ − tℓ ) q−p
kVq /Vp k.
m

Since the covolume of a quotient space is the quotient of the covolumes, taking logarithms
gives
′

′

log kVq(ℓ ) k − log kVq(ℓ) k .+ log kVp(ℓ ) k − log kVp(ℓ) k + (tℓ′ − tℓ ) q−p
m

q−p
≍ (tℓ′ − tℓ ) zp + m

A similar argument shows that
′

log kVq(ℓ ) k − log kVq(ℓ) k &+ (tℓ′ − tℓ ) zr −
Next, we observe that (31.43) can be rearranged to yield
def

zq = zp +

q−p
m

= zr −

r−q
m

r−q
m



.

114

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

and thus we have
′

log kVq(ℓ ) k − log kVq(ℓ) k ≍+ (tℓ′ − tℓ )zq .
The proof can be continued in the same way as in the earlier case. A similar argument
′
applies if fq′ = fq+1
= − n1 on (t′ℓ1 −1 , t′ℓ2 ). This concludes the proof of Claim 31.16.

Now fix ℓ ∈ N and q = 1, . . . , d − 1. If ℓ is contained in a q-interval then we let
α(q, ℓ) = α(q, ℓ1 , ℓ2 ),
where [ℓ1 , ℓ2 ] is the longest q-interval containing ℓ. Otherwise, we let α(q, ℓ) = ∗. Next,
we let c(ℓ) ∈ Rd be the unique vector such that
(31.44)

q
X

(ℓ)

when α(q, ℓ) ∈ R,

ci = α(q, ℓ)

i=1

(31.45)

(ℓ)

c(ℓ)
q = cq+1

when α(q, ℓ) = ∗.

Then by (31.29) and (31.42), we have
c(ℓ) ≍+,β b(ℓ) .
For convenience, we introduce a slightly modified version of intervals of equality (see
Definition 4.5). We call an interval (p, q]Z an interval of mixing for f on I if either
• (p, q]Z is an interval of equality for f on I, and fq′ ∈
/ { m1 , − n1 } on I, or
• q = p + 1 and fq′ ∈ { m1 , − n1 } on I.

Note that if (p, q]Z is an interval of mixing for f on Iℓ := (t′ℓ−1 , t′ℓ ), then [ℓ, ℓ] is both a
p-interval and a q-interval.
(ℓ−1)
Let (p, q]Z be an interval of mixing for f on Iℓ . Then by (31.29), we have ai
(1) = a
(ℓ)
for all i ∈ (p, q]Z, where a is a constant. By (31.40), we have |bi − a| ≤ C2 + C1 for all
(ℓ)
i ∈ (p, q]Z, and thus by (31.29), we have |ai (0) − a| ≤ C2 + C1 for all i ∈ (p, q]Z. On the
(ℓ)
other hand, for i = 1, . . . , d such that fi′ ∈ { m1 , − n1 } on Iℓ , (31.29) implies that ai (0) = bi .
Thus
ka(ℓ) (0) − b(ℓ) k ≤ 2(C2 + C1 )
and consequently a(ℓ) (0) ≍+,β c(ℓ) . On the other hand, by (31.40) we have a(ℓ) (1) ≍+,β
c(ℓ+1) , so by (31.29), for every interval of mixing (p, q]Z for f on Iℓ+1 , we have

(31.46)

(ℓ+1)
ci

≍+,β

q
1 X (ℓ)
c .
q − p j=p+1 j
(ℓ)

(ℓ)

Let B be a large number, fix ε ∈ {±1}, and write ci = B + εci . We claim that there
exist constants C(1), . . . , C(d) ≥ 0, independent of B, such that if B ≥ maxi C(i)/i, then

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

115

for all j < k and ℓ ∈ N we have
k
X

(31.47)

(ℓ)

i=j+1

ci ≥ C(k − j).

P
(ℓ)
Indeed, when ℓ = 0, we have c(0) = 0 and thus ki=j+1 ci = (k − j)B ≥ C(k − j). For
the inductive step, fix ℓ ∈ N and suppose that (31.47) holds for all j < k. Fix j < k, and
we will show that
k
X

(31.48)

(ℓ+1)

ci

i=j+1

≥ C(k − j).

Case 1. Suppose that [ℓ, ℓ + 1] is both a j-interval and a k-interval. Then α(j, ℓ) =
α(j, ℓ + 1) ∈ R and similarly for k. So
k
X

i=j+1

(ℓ)

ci = α(k, ℓ) − α(j, ℓ) = α(k, ℓ + 1) − α(j, ℓ + 1) =

and thus

k
X

(ℓ+1)

ci

=

k
X

(ℓ+1)

ci

i=j+1

(ℓ)

i=j+1

i=j+1

k
X

ci ≥ C(k − j).

Case 2. Suppose that [ℓ, ℓ + 1] is a j-interval but not a k-interval. Let (p, q]Z ∋ k be an
interval of mixing for f on either Iℓ or Iℓ+1 . Then by (31.46), we have
(ℓ+1)
ci

(31.49)

≍+,β

q
1 X (ℓ)
c for all i ∈ (p, q]Z.
q − p i=p+1 i

In the latter case this follows directly from (31.46), while if (p, q]Z is an interval of mixing
(ℓ)
for f on Iℓ , then by (31.46) we have ci ≍+,β c for all i ∈ (p, q]Z for some constant c, and
applying (31.46) again gives (31.49). On the other hand, since [ℓ, ℓ + 1] is a j-interval we
have j ≤ p, and thus the previous case gives
p
X

i=j+1

(ℓ)

ci =

p
X

(ℓ+1)

ci

.

i=j+1

So
k
X

i=j+1

(ℓ+1)
ci

≍+,β

p
X

i=j+1

(ℓ)
ci

q
k+1
k − p X (ℓ) 1 X (ℓ) 1
+
ci ≥
c ≥ C(k + 1 − j).
q − p i=p+1
d i=j+1 i
d

116

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Let C denote the implied constant of the asymptotic, and let C(1), . . . , C(d) be defined
by the recursive formula
def

def

C(1) = 0,

C(k + 1) = d(C(k) + C).

Then we have demonstrated (31.48), completing the inductive step.
Case 3. If [ℓ, ℓ + 1] is a k-interval but not a j-interval, or is neither a j-interval nor a
k-interval, then the proof is similar to Case 2. We leave the details to the reader.
This completes the proof of (31.47), which in turn implies (31.41), thereby completing
the proof of (31.1). Thus, we have completed proving the lower bounds in Theorem 4.6.

32. P ROOF

OF

T HEOREM 4.6,

UPPER BOUND

Let S be a class of functions from [0, ∞) to Rd closed under finite perturbations. We
claim that
dimH (S) ≤

sup

δ(f),

f ∈S∩Tm,n

dimP (S) ≤

sup

δ(f),

f ∈S∩Tm,n

where S = D(S) is as in (4.14). As in the proof of the lower bounds, we will play the
modified Hausdorff and packing games with target set S and parameter 0 < β < 1. This
time, we will define a strategy for Bob for sufficiently small β.
Definition of the strategy. Suppose that the game has progressed to turn k, with
corresponding lattice Λk as in §29. Let {r1 , . . . , rd } be a Minkowski basis of Λk (cf. Lemma
P
30.5), and for each q = 0, . . . , d let Vq = qi=1 Rri . Essentially, Bob’s strategy will be to
“push the subspaces Vq away from L as much as possible given Alice’s move”. To make
this precise, fix X ∈ BM (0, 1 − β), and for each q = 0, . . . , d let
(32.1)

def

−
L−
q = Lq (k, X) =

sup dim(uX+Y Vq ∩ L),

kY k≤2β

def

−
L+
q = q − Lq .

Let
def

+
−
−
S+ = S+ (k, X) = {q = 1, . . . , d : L+
q = Lq−1 + 1 and Lq = Lq−1 },
def

−
+
+
S− = S− (k, X) = {q = 1, . . . , d : L−
q = Lq−1 + 1 and Lq = Lq−1 },

and note that S+ ∪ S− = (0, d]Z and #(S± ) = d± , where d+ = m, d− = n (see (4.2)). Also
note that L±
q = #(S± ∩ (0, q]Z) for all q = 1, . . . , d. Finally, let δ(k, X) = δ(S+ , S− ), where

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

117

as in (4.13),
def

δ(T+ , T− ) = #{(i+ , i− ) ∈ T+ × T− : i+ > i− }.
Bob’s strategy on turn k can now be given as follows: If Alice makes the move Ak ⊆
BM (0, 1 − β), then Bob responds by choosing Xk ∈ Ak so as to maximize δ(k, Xk ).
Note that larger values of δ(k, Xk ) correspond to larger values of L+
q and correspond−
ingly smaller values of Lq , which in turn correspond to the intuitive idea of “pushing Vq
away from L (by a distance of at least 2β)”.
The following claim will be used to relate scores in the Hausdorff and packing games
with the dimensions of templates.
Claim 32.1. For all k we have
#(Ak ) . β −δ(k,Xk ) .
Proof. Let δ = δ(k, Xk ). Clearly,
[ 
Ak ⊆ {X : δ(k, X) ≤ δ} ⊆
X : L−
q (X) ≥ #(T− ∩ (0, q]Z) for all q = 1, . . . , d ,
T+ ,T−

where the union is taken over all sets T+ , T− ⊆ (0, d]Z such that T+ ∩ T− = , T+ ∪ T− =
(0, d]Z, #(T± ) = d± , and
δ(T+ , T− ) ≤ δ.
b− = #(T− ∩ (0, q]Z). We need to
Fix T+ , T− as above, and for each q = 1, . . . , d let L
q
estimate the size of the set

Since Ak =

S

T+ ,T−

def
b−
Ak (T+ , T− ) = {X ∈ Ak : L−
q (X) ≥ Lq for all q}.

Ak (T+ , T− ), to complete the proof it suffices to show that
#(Ak (T+ , T− )) . β −δ .

b−
Note that for each X ∈ BM (0, 1 − β) and q = 1, . . . , d, we have L−
q (X) ≥ Lq if and only
if X is in the 2β-neighborhood of the algebraic set
b− } ⊆ M.
Zq = {X : dim(uX Vq ∩ L) ≥ L
q

Thus,

Ak (T+ , T− ) ⊆
Let Z =
(32.2)

Td

q=1

Zq . We claim that
d
\

q=1

d
\

q=1

N (Zq , 2β).

N (Zq , 2β) ⊆ N (Z, Cβ)

118

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

for some uniform constant C. Indeed, fix X ∈
choose Xq ∈ Zq ∩ B(X, 2β), and let

T

q

N (Zq , 2β). For each q = 1, . . . , d,

Vbq = uXq Vq ∩ L.

Next, for q = 1, . . . , d we recursively define
c⊥ ,
Wq = Vbq ∩ W
q−1

cq = W1 + . . . + Wq ,
W

c0 = {0}. Note that since Xq ∈ Zq ,
with the understanding that W

cq ) = dim W
cq−1 + (Vbq ∩ W
c ⊥ ) ≥ dim(Vbq ) ≥ L
b− .
dim(W
q−1
q

Let Z be the unique matrix such that u−Z v = u−Xq v for all q = 1, . . . , d and v ∈ Wq .
cd = W1 + . . . + Wd is an orthogonal decomposition, such a Z exists, and we
Since L = W
have kZ − Xk ≤ Cβ for some constant C. Now fix q = 1, . . . , d. For all p = 1, . . . , q and
cq ⊆ Vq and thus
v ∈ Wp , we have u−Z v = u−Xp v ∈ Vp ⊆ Vq . This implies that u−Z W
cq ) ≥ L
b− ,
dim(uZ Vq ∩ L) ≥ dim(W
q

so Z ∈ Zq . Since q was arbitrary, we have Z ∈ Z, and thus X ∈ N (Z, Cβ), where C is
the constant above. This completes the proof of (32.2).
So Ak (T+ , T− ) ⊆ N (Z, Cβ), where Ak (T+ , T− ) is a 3β-separated set and Z is an algebraic set whose diagram in the sense of [66, Definition 4.2] is constant (i.e. independent
of k and β). By [66, Corollary 5.7], it follows that
#(Ak (T+ , T− )) . β − dim(Z) ,
whereas we wish to show that #(Ak (T+ , T− )) . β −δ . So to complete the proof we must
show that dim(Z) ≤ δ.
Consider first the case where the subspaces Vq (q = 1, . . . , d) are all coordinate subP
b−
spaces, i.e. Vq = i∈Iq Rei for some Iq ⊆ (0, d]Z, and where dim(Vq ∩ L) = L
q for all q.
P
−
In this case, we write I = {m + 1, . . . , d}, so that L = i∈I − Rei . Let σ be the unique
permutation of (0, d]Z such that for each q = 1, . . . , d, we have Iq = {σ(1), . . . , σ(q)}. Then
since
b−
#(Iq ∩ I− ) = L
q = #(T− ∩ (0, q]Z) for all q,
we have I− = σ(T− ).
It is readily verified that X ∈ Z if and only if Xi,j = 0 for all i = 1, . . . , m and j =
1, . . . , n such that
σ −1 (i) > σ −1 (m + j).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

119

Thus, dim(Z) is equal to the number of pairs (i, j) ∈ {1, . . . , m} × {1, . . . , n} such that
σ −1 (i) < σ −1 (m + j), or equivalently the number of pairs (i+ , i− ) ∈ T+ × T− such that
i+ < i− . In other words, dim(Z) = δ(T+ , T− ) ≤ δ.
For the general case, note that the map X 7→ u−X L is a coordinate chart for the
Grassmannian variety G = G(d, n) of n-dimensional subspaces of Rd . So it suffices to
show that dim(Z ′ ) ≤ δ, where
b−
Z ′ = {W ∈ G : dim(Vq ∩ W ) ≥ L
q for all q}.

Let W be a smooth point of Z ′ (i.e. a point where the tangent space to Z ′ at W is defined)
b−
such that the local dimension of Z ′ at W is equal to dim(Z ′ ). Then dim(Vq ∩ W ) = L
q
for all q. Moreover, there is a basis of Rd such that the subspaces Vq (q = 1, . . . , d) and W
are all coordinate subspaces with respect to this basis. So from the previous argument, it
follows that dim(Z ′ ∩ U) = δ, where U is a neighborhood of W (depending on the basis).
Since the local dimension of Z ′ at W is equal to dim(Z ′ ), this shows that dim(Z ′ ) = δ. 
Now suppose that the game is played according to Bob’s strategy, let A denote the
outcome, and suppose that the corresponding successive minima function hA is in S. By
Lemma 31.4, there exists a template g such that g ≍+ hA . Fix a large constant C1 ≥ γ.
Applying Lemma 31.4 again, there exists a template f such that f ≍+,C1 g and such that
for all q, t, t′ such that fq (t) < fq+1 (t) and |t′ − t| ≤ C1 , we have gq+1(t′ ) − gq (t′ ) ≥ C1 and
Fq′ (t) ≥ G′q (t′ ). Since hA ∈ S and S is closed under finite perturbations, we have f ∈ S.
Claim 32.2. We have
δ(f) ≥ δ − O(1/ log β),

δ(f) ≥ δ − O(1/ log β),

where δ and δ denote Alice’s scores (see Definition 28.1) in the Hausdorff and packing games,
respectively.
Proof. It suffices to show that for all k ∈ N and t′ ∈ [kγ, (k + 1)γ],
δ(f, t′ ) ≥

log #(Ak ) − O(1)
·
− log(β)

Indeed, fix such k, t′ , and let t = kγ. By Claim 32.1, we have
δ(k, Xk ) ≥

log #(Ak ) − O(1)
,
− log(β)

so to complete the proof it suffices to show that
δ(f, t′ ) ≥ δ(k, Xk ).

120

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

Indeed, fix q = 1, . . . , d − 1 such that fq (t′ ) < fq+1 (t′ ), and we will show that
L+ (f, t′ , q) ≥ L+
q .

(32.3)

Indeed, first note that by assumption, and since C1 ≥ γ, the inequality fq (t′ ) < fq+1 (t′ )
implies that gq+1 (t) − gq (t) ≥ C1 . Now by the definition of g and Lemma 29.2, we have
g(t) ≍+ hA (t) ≍+ h(Λk )
and thus we in fact get log λq+1 (Λk ) − log λq (Λk ) &+ C1 .
Now let
∞
X
Zk =
β ℓ−k Xℓ ∈ BM (Xk , β) ⊆ BM (0, 1).
ℓ=k

By (32.1), we have

sup dim(uZk +Y Vq ∩ L) ≤ L−
q .

kY k≤β

Thus by Lemma 30.7, for all s ≥ 0, we have
log kgs uZk Vq k &+,β log kVq k +

(32.4)



L+
L−
q
q
−
m
n



s.

On the other hand, since log λq+1 (Λk ) − log λq (Λk ) &+ C1 , for all Vq′ ∈ Vq (Λk ) \ {Vq }, by
Lemma 30.6 we have
log kVq′ k − log kVq k &+ C1
and thus for all 0 ≤ s ≤

mn
C,
qd 1

since log kgs−1k ≤ s/n, we have

q
q
log kgs uZk Vq′ k &+ log kVq′ k − s &+ log kVq k + C1 − s
n
n

 +
L
L−
q
q
q
≥ log kVq k + s ≥ log kVq k +
s.
−
m
m
n

Combining with (32.4) gives
inf

Vq′ ∈Vq (Λk )

log kgs uZk Vq′ k

&+,β log kVq k +



L−
L+
q
q
−
m
n



s.

On the other hand, since g ≍+ hA , by Lemmas 30.5 and 29.2, we have
log kVq k ≍+
inf

Vq′ ∈Vq (Λk )

log kgs uZk Vq′ k ≍+

q
X
i=1
q

X
i=1

log λi (Λk ) ≍+ Gq (t),
log λi (gs uZk Λk ) ≍+ Gq (t + s),

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

so
Gq (t + s) &+,β Gq (t) +
Rearranging gives
ˆ
Suppose that G′q <

L+
q
m

−

L−
q
n

t+s
t

&+,β



L+
L−
q
q
−
m
n

L−
L+
q
q
−
m
n





s.

s.

on [t, t + s]. Then since g is a template,

G′q ≤
and thus

G′q



121

L+
L−
q −1
q +1
−
on [t, t + s]
m
n


 +

Lq
L−
L−
L+
q +1
q
q −1
s &+,β
s
−
−
m
n
m
n
which implies s ≍+,β 0, i.e. |s| ≤ C2 for some constant C2 . Let C1 , s be chosen so that
C ) and γ ≤ C1 . Then the inequality |s| ≤ C2 contradicts the
C2 < s ≤ min(C1 , mn
qd 1


definition of s, so the hypothesis that G′q <
L+
q
m

L−
q
n

L+
q
m

−

L−
q
n

on [t, t + s] must be incorrect, i.e. we

must have G′q (t′′ ) ≥
−
for some t′′ ∈ [t, t + s]. Now since t′ , t′′ ∈ [t, t + C1 ], we have
|t′′ − t′ | ≤ C1 , and thus by our assumptions on f we have
L+
L−
L+ (f, t′ , q) L− (f, t′ , q)
q
q
′ ′
′ ′′
−
= Fq (t ) ≥ Gq (t ) ≥
−
m
n
m
n
demonstrating (32.3).
To summarize, we have


# S+ (f, t′ ) ∩ (0, q]Z ≥ # S+ (k, Xk ) ∩ (0, q]Z

for all q such that fq (t′ ) < fq+1 (t′ ). It follows from (4.8) that the same inequality holds
for all q = 1, . . . , d − 1. Since
 
d−1
X

m
,
δ(T+ , T− ) =
# T+ ∩ (0, q] −
2
q=1
(where δ is as in (4.13)), we have

δ(f, t′ ) = δ(S± (f, t′ )) ≥ δ(S± (k, Xk )) = δ(k, Xk ).



Fix δ > supf ∈S∩Tm,n δ(f). Then by the previous Claim 32.2, we have δ > δ as long as β
is sufficiently small. So by Theorem 28.2, we have δ ≥ dimH (S). Since δ was arbitrary,
we have
dimH (S) ≤ sup δ(f).
f ∈S∩Tm,n

122

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

A similar argument gives the bound for the packing dimension, thereby completing the
proof of the upper bounds in Theorem 4.6.

Part 5. Appendix and references
A PPENDIX A. T RANSLATING

BETWEEN

S CHMIDT–S UMMERER’ S

NOTATION AND OURS

This appendix explains the relations between certain concepts and notation in our
paper and in Schmidt–Summerer’s [61] to provide a guide for readers of both.
Schmidt–Summerer are working in the framework of simultaneous approximation, so
n = 1 for them, and further: their n is our d = m + 1, their y is our r, their ξ is our A. In
particular, note that they have r = (q, p) instead of r = (p, q). Their Λ(ξ) would translate
to uA Zd in our paper, and what they call K(Q) is what we would call g−t B, where Q = et
and B = [−1, 1]d . Finally, their T is our g−1 .
Schmidt–Summerer’s set-up encodes the same geometric information as ours since
λi (gt uA Zd , B) = λi (uA Zd , g−t B).
Therefore, in their notation the right-hand side is λi (Λ(ξ), K(Q)). Similarly, Li (q) in their
notation is the same as hi (t) in our notation, where q = t/(n−1). The connection between
our notion of a template (see Definition 4.1) and Schmidt–Summerer’s (n, γ)-systems (see
[61, §2]) is as follows: if P is an (n, 0)-system then
h(t) =

n
t
P (t) −
n−1
n−1

is an (n − 1) × 1 template.
We further remark that after Schmidt–Summerer consider the limiting case of an (n, 0)system in [61, §3], they go on, in [61, §4, pg. 62], to conjecture that the study of these
systems should suffice to determine the spectra of the family of exponents of approximation that they are interested in. The rest of their paper develops a theory of covers of
an (n, γ)-system, which is then applied to prove relations between several exponents of
approximation.
Interested readers are also referred to Roy’s paper [53] for translating between Schmidt–
Summerer’s notation and his. In contrast to Schmidt–Summerer who work in the simultaneous approximation framework, Roy works in the dual framework of approximation
by linear forms. Roy defines the notion of a rigid system (a special case of (n, 0)-systems)
in the introduction of [53] and goes on to prove that every (n, γ)-system can be approximated by a rigid system up to bounded additive difference (see [53, Theorem 1.3]). Roy’s
rigid systems translate to our η-integral templates (see Definition 31.1).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

123

R EFERENCES
1. Jinpeng An, 2-dimensional badly approximable vectors and Schmidt’s game, Duke Math. J. 165 (2016),
no. 2, 267–284. MR 3457674
2. Dzmitry Badziahin, Stephen Harrap, Erez Nesharim, and David Simmons, Schmidt games and Cantor
winning sets, https://arxiv.org/abs/1804.06499, preprint 2018.
3. M. Bachir Bekka and Matthias Mayer, Ergodic theory and topological dynamics of group actions on
homogeneous spaces, London Mathematical Society Lecture Note Series, vol. 269, Cambridge University
Press, Cambridge, 2000. MR 1781937
4. Victor Beresnevich and Sanju Velani, Arbeitsgemeinschaft: Diophantine Approximation, Fractal Geometry
and Dynamics, Oberwolfach Rep. 13 (2016), no. 4, 2749–2792, Abstracts from the Working Session
held October 9–14, 2016, Organized by Victor Beresnevich and Sanju Velani. MR 3757056
5. Vasiliı̆ Ivanovich Bernik and Michael Maurice Dodson, Metric Diophantine approximation on manifolds, Cambridge Tracts in Mathematics, vol. 137, Cambridge University Press, Cambridge, 1999.
MR 1727177
6. A. S. Besicovitch, Sets of fractional dimensions (IV): On rational approximation to real numbers, J.
London Math. Soc. 9 (1934), no. 2, 126–131.
7. Christopher J. Bishop and Yuval Peres, Fractals in probability and analysis, Cambridge Studies in Advanced Mathematics, vol. 162, Cambridge University Press, Cambridge, 2017. MR 3616046
8. John Bovey and Maurice Dodson, The Hausdorff dimension of systems of linear forms, Acta Arith. 45
(1986), no. 4, 337–358.
9. Ryan Broderick, Lior Fishman, Dmitry Kleinbock, Asaf Reich, and Barak Weiss, The set of badly approximable vectors is strongly C 1 incompressible, Math. Proc. Cambridge Philos. Soc. 153 (2012), no. 2,
319–339. MR 2981929
10. Yann Bugeaud, Approximation by algebraic numbers, Cambridge Tracts in Mathematics, vol. 160, Cambridge University Press, Cambridge, 2004.
11. Yann Bugeaud, Yitwah Cheung, and Nicolas Chevallier, Hausdorff dimension and uniform exponents in
dimension two, Math. Proc. Cambridge Philos. Soc. 167 (2019), no. 2, 249–284. MR 3991371
12. Yann Bugeaud and Michel Laurent, On exponents of homogeneous and inhomogeneous Diophantine approximation, Mosc. Math. J. 5 (2005), no. 4, 747–766, 972. MR 2266457
13. John W. S. Cassels, An introduction to Diophantine approximation, Cambridge Tracts in Mathematics
and Mathematical Physics, No. 45, Cambridge University Press, New York, 1957.
, An introduction to the geometry of numbers. Corrected reprint of the 1971 edition, Classics in
14.
Mathematics, Springer-Verlag, Berlin, 1997.
15. Jonathan Chaika, Yitwah Cheung, and Howard Masur, Winning games for bounded geodesics in moduli
spaces of quadratic differentials, J. Mod. Dyn. 7 (2013), no. 3, 395–427. MR 3296560
16. Yitwah Cheung, Hausdorff dimension of the set of singular pairs, Ann. of Math. (2) 173 (2011), no. 1,
127–167.
17. Yitwah Cheung and Nicolas Chevallier, Hausdorff dimension of singular vectors, Duke Math. J. 165
(2016), no. 12, 2273–2329. MR 3544282
18. Colleen D. Cutler, Strong and weak duality principles for fractal dimension in Euclidean space, Math.
Proc. Cambridge Philos. Soc. 118 (1995), no. 3, 393–410. MR 1342960

124

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

19. S. G. Dani, Divergent trajectories of flows on homogeneous spaces and Diophantine approximation, J.
Reine Angew. Math. 359 (1985), 55–89. MR 794799
20. Shrikrishna Gopal Dani, On badly approximable numbers, Schmidt games and bounded orbits of flows,
Number theory and dynamical systems (York, 1987), London Math. Soc. Lecture Note Ser., vol. 134,
Cambridge Univ. Press, Cambridge, 1989, pp. 69–86. MR 1043706
21. Tushar Das, Lior Fishman, David Simmons, and Mariusz Urbański, A variational principle in the parametric geometry of numbers, with applications to metric Diophantine approximation, C. R. Math. Acad.
Sci. Paris 355 (2017), no. 8, 835–846. MR 3693502
22. Harold Davenport and Wolfgang M. Schmidt, Dirichlet’s theorem on diophantine approximation. II, Acta
Arith. 16 (1969/1970), 413–424. MR 0279040
23. P. G. Lejeune Dirichlet, Verallgemeinerung eines Satzes aus der Lehre von den Kettenbrüchen nebst einige
Anwendungen auf die Theorie der Zahlen, S.-B. Preuss. Akad. Wiss (1842), 93–95 (German).
24. M. Maurice Dodson and Simon Kristensen, Hausdorff dimension and Diophantine approximation, Fractal geometry and applications: a jubilee of Benoı̂t Mandelbrot. Part 1, Proc. Sympos. Pure Math.,
vol. 72, Amer. Math. Soc., Providence, RI, 2004, pp. 305–347. MR 2112110
25. Manfred Einsiedler and Thomas Ward, Ergodic theory with a view towards number theory, Graduate
Texts in Mathematics, vol. 259, Springer-Verlag London, Ltd., London, 2011. MR 2723325
26. Alex Eskin, Grigoriı̆ Aleksandrovitch Margulis, and Shahar Mozes, Upper bounds and asymptotics in
a quantitative version of the Oppenheim conjecture, Ann. of Math. (2) 147 (1998), no. 1, 93–141.
MR 1609447
27. Kenneth Falconer, Techniques in fractal geometry, John Wiley & Sons, Ltd., Chichester, 1997.
MR 1449135
, Fractal Geometry, Mathematical Foundations and Applications, Third ed., John Wiley & Sons,
28.
Ltd., Chichester, 2014. MR 3236784
29. Lior Fishman, Tue Ly, and David Simmons, Determinacy and indeterminacy of games played on complete
metric spaces, Bull. Aust. Math. Soc. 90 (2014), 339–351.
30. Lior Fishman, David Simmons, and Mariusz Urbański, Diophantine approximation and the geometry of
limit sets in Gromov hyperbolic metric spaces, Mem. Amer. Math. Soc. 254 (2018), no. 1215, v+137.
MR 3826896
31. Oleg N. German, On Diophantine exponents and Khintchine’s transference principle, Mosc. J. Comb.
Number Theory 2 (2012), no. 2, 22–51. MR 2988525
32. Lifan Guan and Ronggang Shi, Hausdorff dimension of divergent trajectories on homogeneous spaces,
Compos. Math. 156 (2020), no. 2, 340–359. MR 4044467
33. Felix Hausdorff, Dimension und äußeres Maß, Math. Ann. 79 (1918), no. 1-2, 157–179. MR 1511917
34. Bettina Helfrich, Algorithms to construct Minkowski reduced and Hermite reduced lattice bases, Theoret.
Comput. Sci. 41 (1985), no. 2-3, 125–139 (1986). MR 847673
35. Vojtěch Jarnı́k, Zur metrischen Theorie der diophantischen Approximationen, Prace mat. fiz. 36 (1928),
91–106 (German).
, Diophantische Approximationen und Hausdorffsches Mass, Mat. Sb. 36 (1929), 371–382 (Ger36.
man).
37.
, Zum Khintchineschen “Übertragungssatz”, Trav. Inst. Math. Tbilissi 3 (1938), 193–212 (German).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

125

38. Shirali Kadyrov, Dmitry Kleinbock, Elon Lindenstrauss, and Grigoriı̆ Aleksandrovitch Margulis, Singular
systems of linear forms and non-escape of mass in the space of lattices, J. Anal. Math. 133 (2017), 253–
277. MR 3736492
39. Aminata Keita, On a conjecture of Schmidt for the parametric geometry of numbers, Mosc. J. Comb.
Number Theory 6 (2016), no. 2-3, 166–176.
40. Aleksandr Khinchin, Über eine Klasse linearer diophantischer Approximationen, Rend. Circ. Mat. Palermo
50 (1926), 170–195 (German).
, Über singuläre Zahlensysteme, Compositio Math. 4 (1937), 424–431. MR 1556985
41.
, Regular systems of linear equations and a general problem of Čebyšev, Izvestiya Akad. Nauk
42.
SSSR. Ser. Mat. 12 (1948), 249–258. MR 0025513
43. Dong Han Kim and Lingmin Liao, Dirichlet uniformly well-approximated numbers, Int. Math. Res. Not.
IMRN (2019), no. 24, 7691–7732. MR 4043832
44. Dmitry Ya. Kleinbock and Grigoriı̆ Aleksandrovitch Margulis, Flows on homogeneous spaces and Diophantine approximation on manifolds, Ann. of Math. (2) 148 (1998), no. 1, 339–360. MR 1652916
45. Dmitry Ya. Kleinbock and Barak Weiss, Modified Schmidt games and Diophantine approximation with
weights, Adv. Math. 223 (2010), no. 4, 1276–1298. MR 2581371
46. Michel Laurent, On inhomogeneous Diophantine approximations and the Hausdorff dimension, Fundam.
Prikl. Mat. 16 (2010), no. 5, 93–101. MR 2804895
47. Lingmin Liao, Ronggang Shi, Omri Solan, and Nattalie Tamam, Hausdorff dimension of weighted singular vectors in R2 , J. Eur. Math. Soc. (JEMS) 22 (2020), no. 3, 833–875. MR 4055990
48. Donald A. Martin, A purely inductive proof of Borel determinacy, Recursion theory (Ithaca, N.Y., 1982),
Proc. Sympos. Pure Math., vol. 42, Amer. Math. Soc., Providence, RI, 1985, pp. 303–308. MR 791065
49. R. Daniel Mauldin, Tomasz Szarek, and Mariusz Urbański, Graph directed Markov systems on Hilbert
spaces, Math. Proc. Cambridge Philos. Soc. 147 (2009), no. 2, 455–488. MR 2525938
50. Curtis Tracy McMullen, Winning sets, quasiconformal maps and Diophantine approximation, Geom.
Funct. Anal. 20 (2010), no. 3, 726–740. MR 2720230
51. Nikolay Moshchevitin, Khintchine’s singular Diophantine systems and their applications, Russian Math.
Surveys 65 (2010), no. 3, 433–511.
, Proof of W. M. Schmidt’s conjecture concerning successive minima of a lattice, J. Lond. Math.
52.
Soc. (2) 86 (2012), no. 1, 129–151. MR 2959298
53. Damien Roy, On Schmidt and Summerer parametric geometry of numbers, Ann. of Math. (2) 182 (2015),
no. 2, 739–786. MR 3418530
, Spectrum of the exponents of best rational approximation, Math. Z. 283 (2016), no. 1-2, 143–
54.
155. MR 3489062
55. Damien Roy and Michel Waldschmidt, Parametric geometry of numbers in function fields, Mathematika
63 (2017), no. 3, 1114–1135. MR 3731317
56. Johannes Schleischitz, Diophantine approximation and special Liouville numbers, Commun. Math. 21
(2013), no. 1, 39–76. MR 3067121
57. Wolfgang M. Schmidt, On badly approximable numbers and certain games, Trans. Amer. Math. Soc. 123
(1966), 27–50.
, Badly approximable systems of linear forms, J. Number Theory 1 (1969), 139–154. MR 248090
58.

126

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBAŃSKI

59. Wolfgang M. Schmidt, Diophantine approximation, Lecture Notes in Mathematics, vol. 785, Springer,
Berlin, 1980. MR 568710
60. Wolfgang M. Schmidt, Open problems in Diophantine approximation, Diophantine approximations and
transcendental numbers (Luminy, 1982), Progr. Math., vol. 31, Birkhäuser Boston, Boston, MA, 1983,
pp. 271–287. MR 702204
61. Wolfgang M. Schmidt and Leonhard Summerer, Diophantine approximation and parametric geometry
of numbers, Monatsh. Math. 169 (2013), no. 1, 51–104. MR 3016519
62. David Simmons, On interpreting Patterson–Sullivan measures of geometrically finite groups as Hausdorff
and packing measures, Ergodic Theory Dynam. Systems 36 (2016), no. 8, 2675–2686. MR 3570029
63. Alexander Starkov, Dynamical systems on homogeneous spaces, Translations of Mathematical Monographs, vol. 190, American Mathematical Society, Providence, RI, 2000, Translated from the 1999
Russian original by the author. MR 1746847
64. Dennis P. Sullivan, Entropy, Hausdorff measures old and new, and limit sets of geometrically finite
Kleinian groups, Acta Math. 153 (1984), no. 3-4, 259–277. MR 766265
65. Claude Tricot, Jr., Two definitions of fractional dimension, Math. Proc. Cambridge Philos. Soc. 91
(1982), no. 1, 57–74. MR 633256
66. Yosef Yomdin and Georges Comte, Tame geometry with application in smooth analysis, Lecture Notes in
Mathematics, vol. 1834, Springer-Verlag, Berlin, 2004. MR 2041428
U NIVERSITY OF W ISCONSIN -L A C ROSSE , D EPARTMENT OF M ATHEMATICS & S TATISTICS , 1725 S TATE
S TREET, L A C ROSSE , WI 54601, USA
Email address: tdas@uwlax.edu
URL: https://sites.google.com/a/uwlax.edu/tdas/
U NIVERSITY OF N ORTH T EXAS , D EPARTMENT
TON , TX 76203-5017, USA
Email address: lior.fishman@unt.edu
URL: http://math.unt.edu/lior-fishman

OF

M ATHEMATICS , 1155 U NION C IRCLE #311430, D EN -

U NIVERSITY OF Y ORK , D EPARTMENT OF M ATHEMATICS , H ESLINGTON , Y ORK YO10 5DD, UK
Email address: david9550@gmail.com
URL: https://sites.google.com/view/davidsimmonsmath2/home
U NIVERSITY OF N ORTH T EXAS , D EPARTMENT
TON , TX 76203-5017, USA
Email address: urbanski@unt.edu
URL: http://www.urbanskimath.com/

OF

M ATHEMATICS , 1155 U NION C IRCLE #311430, D EN -

