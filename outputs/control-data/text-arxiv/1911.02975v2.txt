Further Results and Discussions on Random Cayley Graphs
Jonathan Hermon Sam Olesker-Taylor

arXiv:1911.02975v2 [math.PR] 4 Feb 2021

Abstract
Consider the random Cayley graph of a finite group G with respect to k generators chosen
uniformly at random, with 1 ≪ k . log |G|. The results of this article supplement those in the
three main papers on random Cayley graphs, namely [13, 14, 16]. The majority of the results
are inspired by a ‘universality’ conjecture of Aldous and Diaconis [2].
To start, we study the limit profile of cutoff for the simple random walk on this random
graph, as well as a detailed investigation into mixing properties when G = Zdp with p prime.
We then exposit a proof of Diaconis and Saloff-Coste [10] establishing lack of cutoff when
k ≍ 1. We move onto discussing material from [14] on matrix groups. We then study distance
of a typical element of G from the identity in an Lq -type graph distance in the Abelian set-up.
Finally, we give necessary and sufficient conditions for k independent uniform elements of G to
generate G, ie for the random Cayley graph to be connected, based on work of Pomerance [24].
The aforementioned results all hold with high probability over the random Cayley graph.
Keywords: cutoff, mixing times, random walk, random Cayley graphs, universality, entropy
MSC 2020 subject classifications: 05C12, 05C80, 05C81; 20D15; 60J27, 60K37

Contents
1 Introduction and Statement of Results

2

2 Cutoff: Limit Profile for Random Walks on Abelian Groups

7

3 Cutoff: A Detailed Investigation of Zdp

14

4 Cutoff: No Cutoff When k Is Constant

20

5 Cutoff: Difficulties Arising for High-Dimensional Matrices

21

6 Cutoff: From Upper Triangular Matrices to Nilpotent Groups

22

7 Typical Distance: Generalised Graph Distance

23

8 Generating the Group with Uniform, Independent Generators

29

References

31

Jonathan Hermon
Sam Olesker-Taylor
jhermon@math.ubc.ca, math.ubc.ca/∼jhermon/
sam.ot@posteo.co.uk, mathematicalsam.wordpress.com
University of British Columbia, Vancouver, Canada
Department of Mathematical Sciences, University of Bath, UK
Supported by EPSRC EP/L018896/1 and an NSERC Grant Supported by EPSRC Grants 1885554 and EP/N004566/1
The vast majority of this work was undertaken while both authors were at the University of Cambridge

1

1

Introduction and Statement of Results

1.1
1.1.1

Motivation, Brief Overview of Results and Notation
Motivating Conjecture of Aldous and Diaconis

We analyse properties of the random walk (abbreviated RW ) on a Cayley graph of a finite
group. The generators of this graph are chosen independently and uniformly at random. Precise
definitions are given in §1.4.1; for now, let G be a finite group, let k be an integer (allowed to
depend on G) and denote by Gk the Cayley graph of G with respect to k independently and
uniformly random generators. We consider values of k with 1 ≪ log k ≪ log |G| for which Gk is
connected with high probability (abbreviated whp), ie with probability tending to 1 as |G| grows.
Since pioneering work of Erdős, it has been understood that the typical behaviour of random
objects in some class can shed valuable light on the class as a whole. Thus, when considering some
class of combinatorial objects, it is natural to ask questions such as the following.
· What does a typical object in this class ‘look like’ ?
· If an object is chosen uniformly at random, which properties hold with high probability?
Aldous and Diaconis [2] applied this philosophy to the study of random walks on groups.
Aldous and Diaconis [2, 3] coin the phrase cutoff phenomenon: this occurs when the total
variation distance (TV) between the law of the RW and its invariant distribution drops abruptly
from close to 1 to close to 0 in a time-interval of smaller order than the mixing time. The material
in this article is motivated by a conjecture of theirs regarding ‘universality of cutoff’ for the RW
on the random Cayley graph Gk ; it is given in [2, Page 40], which is an extended version of [3].
Conjecture (Aldous and Diaconis, 1985). For any group G, if k ≫ log |G| and log k ≪ log |G|,
then the random walk on Gk exhibits cutoff whp. Further, the cutoff time, to leading order, is
independent of the algebraic structure of the group: it can be written as a function only of k and |G|.
This conjecture spawned a large body of work, including [11, 12, 18, 19, 20, 25, 28]; see §1.3.
It has been established in the Abelian set-up by Dou and Hildebrand [12, 18]; see §1.3.1 and §7.2
where we give a short proof. Save [20] which considers the cyclic group Zp for prime p and [28]
which considers Zd2 (which enforces k & log |G|), focus has been on k ≫ log |G|.
We extend consideration to 1 ≪ k . log |G|, establishing cutoff and the limit profile for a large
class of Abelian groups. We study other statistics, of a geometric flavour, in this regime too.
1.1.2

Brief Overview of Results

Our focus is on mixing (for the RW) and geometric properties of the random Cayley graph. We
consider the limit as n := |G| → ∞ under the assumption that 1 ≪ log k ≪ log |G|. The condition
1 ≪ log k ≪ log |G| is necessary for cutoff on G±
k for all nilpotent G; see Remark A.2.

· Limit Profile. For k & log |G|, under some conditions on the group, we find the limit profile
of the convergence to equilibrium of the RW. (We cover the case 1 ≪ k ≪ log |G| in [13, §2].)

· Detailed Investigation of Zdp . For 1 ≪ k . log |G| and G := Zdp with p prime, we analyse some
cases not covered by the previous cutoff analysis of [13]. Eg, we allow k to be very close to d.
· Lq -Type Typical Distances. For 1 ≪ k . log |G|, we study an Lq -type graph distance between
a typical point U ∼ Unif(G) and the identity in the random Cayley graph.

· Additional Discussions. We explain briefly how to adapt our cutoff arguments for the upper
triangular group studied in [14, §3] can be extended to other, more general, nilpotent groups
and how there is no cutoff when k ≍ 1 (which is a result due to Diaconis and Saloff-Coste [10]).
For Abelian groups, we give (simple) necessary and sufficient conditions on k in terms of G
for the group to be generated by independent, uniform generators (based on Pomerance [24]).
Introduced by Aldous and Diaconis [2], there has been a great deal of research into these random
Cayley graphs. Motivation for this model and an overview of historical work is referenced in §1.3.

2

1.1.3

Notation and Terminology

−
Cayley graphs are either directed or undirected; we emphasise this by writing G+
k and Gk ,
±
−
+
respectively. When we write Gk or Gk , this means “either Gk or Gk ”, corresponding to the undirected, respectively directed, graphs with generators chosen independently and uniformly at random.
Conditional on being simple, G+
k is uniformly distributed over the set of all simple degree-k
Cayley graphs. Up to a slightly adjusted definition of simple for undirected Cayley graphs, our
results hold with Gk replaced by a uniformly chosen simple Cayley graph of degree k; see §1.4.2.
Our results are for sequences (GN )N ∈N of finite groups with |GN | → ∞ as N → ∞. For ease of
presentation, we write statements like “let G be a group” instead of “let (GN )N ∈N be a sequence
of groups”. Likewise, the quantities d(G), p and, of course, k appearing in the statements all
correspond to sequences, which need not be fixed (or bounded) unless we explicitly say otherwise.
In the same vein, an event holds with high probability (abbreviated whp) if its probability tends to 1.
We use standard asymptotic notation: “≪” or “o(·)” means “of smaller order”; “.” or O(·)”
means “of order at most”; “≍” means “of the same order”; “h” means “asymptotically equivalent”.

1.2

Statements of Main Results

We analyse mixing in the total variation (abbreviated TV ) distance. The uniform distribution
on G, denoted πG , is invariant for the RW. Let S = (S(t))t≥0 denote the RW on Gk ; its law is
denoted PGk (S(t) ∈ ·). For t ≥ 0, denote the TV distance between the law of S(t) and πG by


PGk S(t) ∈ A − |A|/|G| .
dGk (t) := PGk S(t) ∈ · − πG TV = max
A⊆G

Throughout, unless explicitly specified otherwise, we use continuous time: t ≥ 0 means t ∈ [0, ∞).
1.2.1

Cutoff: Limit Profile for Random Walks on Abelian Groups

We use standard notation and definitions for mixing and cutoff ; see, eg, [21, §4 and §18].
Definition. A sequence (X N )N ∈N of Markov chains is said to exhibit cutoff when, in a short
time-interval, known as the cutoff window, the TV distance of the distribution of the chain from
equilibrium drops from close to 1 to close to 0, or more precisely if there exists (tN )N ∈N with


lim inf dN tN (1 − ε) = 1 and lim sup dN tN (1 + ε) = 0 for all ε ∈ (0, 1),
N →∞
N →∞

where dN (·) is the TV distance of X N (·) from its equilibrium distribution for each N ∈ N.
We say that a RW on a sequence of random graphs (HN )N ∈N exhibits cutoff around time
(tN )N ∈N whp if, for all fixed ε, in the limit N → ∞, the TV distance at time (1 + ε)tN converges
in distribution to 0 and at time (1 − ε)tN to 1, where the randomness is over HN .

We use an entropic method, which involves defining entropic times; see [13, §1.3.5] for a highlevel description of the method and §2.1 for a more specific description. The main idea is to use an
auxiliary process W to generate the walk S; one then studies the entropy of the process W . Here,
Wi (t) is, for each i, the number of times generator Zi has been applied minus the number of times
Zi−1 has been applied; W is a rate-1 RW on Zk . Then S(t) = W (t) · Z when the group is Abelian.
For undirected graphs, W is the usual simple RW (abbreviated SRW ): a coordinate is selected
uniformly at random and incremented/decremented by 1 each with probability 21 . For directed
graphs, inverses are never applied, so a step of W is as follows: a coordinate is selected uniformly
at random and incremented by 1; we term this the directed RW (abbreviated DRW ).
For t ≥ 0, write µt for the law of W (t). Define Q(t) := − log µt (W (t)).
Definition A. For all k, n ∈ N and all α ∈ R, define tα := tα (k, n) so that
√ 


E Q(tα ) = log n + α vk where v := Var Q(t0 ) /k.

We call t0 the entropic time and the {tα }α∈R cutoff times.
An asymptotic evaluation of these times is given in Proposition 2.2.
3

For an Abelian group G, write d(G) for the minimal size of a generating subset of G and

m∗ (G) := max minj∈[d] mj ⊕d1 Zmj is a decomposition of G .

R∞
2
Also write Ψ : R → (0, 1) for the standard Gaussian tail: Ψ(α) := (2π)−1/2 α e−x /2 dx for α ∈ R.
Recall that 1 ≪ log k ≪ log |G| is necessary for cutoff for nilpotent G, eg Abelian G; see
Remark A.2. A more refined statement is given in Theorem 2.4.
Theorem A. Let G be an Abelian group. Suppose that k & log |G|, log k ≪ log |G|, d(G) ≤
1
:= tα (k, |G|) for all α ∈ R.
5 log |G|/ log log k and m∗ (G) ≥ log |G|/ log log |G|. Abbreviate tα
Then, whp, the RW on Gk exhibits cutoff at t0 with Gaussian profile given by {tα }α∈R :
dGk (tα ) →P Ψ(α)
t0 ≍ k

(in probability) for all α ∈ R;
√
and |tα − t0 | ≍ αt0 / k ≪ t0 for all α ∈ R.

Remark A.1. We can write the cutoff statement in terms of the mixing time, rather than the TV
distance: writing tmix (ε) for the ε-mixing time, for all ε ∈ (0, 1), we have

tmix (ε) − t0 /w →P Ψ−1 (ε),

where t0 is the mixing time and w is the cutoff window defined via {tα −t0 }α∈R . For a more explicit
△
formula, using asymptotic evaluation of the cutoff times, see Remark 2.5.

Remark A.2. This article establishes cutoff in a variety of set-ups, but always in the regime 1 ≪
log k ≪ log |G|. This leaves the regimes k ≍ 1 and log k ≍ log |G|, for which there is no cutoff for any
choice of generators: when k ≍ 1, this holds whenever the group is nilpotent; when log k ≍ log |G|,
this holds for all groups. The former result is due to Diaconis and Saloff-Coste [10]; we give a short
exposition of this in §4 below. The latter result is proved in [13, §7.2]; the mixing time is order 1.
△
Dou [11, Theorems 3.3.1 and 3.4.7] establishes a more general result for log k ≍ log |G|.
1.2.2

Cutoff: A Detailed Investigation of Zdp

For our next theorem, we specialise to the case G := Zdp with p prime. This specialisation allows
us to derive some very refined results. In particular, before we could not allow d to be very close
to k; here we consider any k ≥ d. Now every element of G has order p; as such, need only consider
the auxiliary W mod p. We redefine the entropic times to take this into account.
Definition B. Define t0 := t0 (k, p, d) to be the time at which the entropy of the RW on Zkp is log(pd ).
An asymptotic evaluation of this time is given in Proposition 3.2.
A more refined statement is given in Theorem 3.4. In particular, by defining tα appropriately,
we can also also consider the cutoff window; see Definition 3.1 and Theorem 3.2.
Theorem B. Let G := Zdp with p prime. Assume that 1 ≪ k . log |G| = d log p. Then, whp, the
RW on Gk exhibits cutoff at time t0 conditional on generating the group, ie hZ1 , ..., Zk i = G.
Further, if (k − d)p ≫ 1 then the group is generated whp.
Remark B. The RW on the usual degree-d Cayley graph of G := Zdp exhibits cutoff at the same
time 12 d log d/(1 − cos(2π/p)) as for the random degree-k Cayley graph above with k − d ≍ 1.
This is not overly surprising: one can check that, for p prime, if hZ1 , ..., Zk i = G then there
exists an I ⊆ [k] with |I| = d such that hZi ii∈I = G and the Cayley graph G([Zi ]i∈I ) is isomorphic
to the usual degree-d Cayley graph. Thus, conditional on generating the group, the random Cayley
graph is simply the usual one with an additional k − d ≍ 1 uniformly chosen generators.
△

4

1.2.3

Cutoff: No Cutoff when k Is Constant

It is natural to ask what happens when k is a fixed constant. This regime has already been
analysed by Diaconis and Saloff-Coste [10]. We give an exposition of their results, using the language
which we have developed. We emphasise that this is a result of Diaconis and Saloff-Coste.
A more refined statement is given in Corollary 4.5.
Theorem C (cf [10, Corollary 5.3]). Let G be a finite, nilpotent group of bounded step. Suppose
that k ≍ 1. Then the RW on G− (Z) does not exhibit cutoff for any choice of Z with |Z| = k.
1.2.4

Typical Distance: Generalised Graph Distance

Our final result regards graph distances between the identity and a uniformly chosen element
of G. For a Cayley graph G, for R ≥ 0 and β ∈ [0, 1], define the β-typical distance DG (β) via


BG (R) := x ∈ G dist(id, x) ≤ R
and DG (β) := min R ≥ 0 |BG (R)| ≥ β|G| .

Locally, when log k ≪ log |G|, typical degree-k Cayley graphs of an Abelian group look like Zk .
In a lattice, graph distance corresponds to L1 distance; this can be extended to an Lq distance, for
q ∈ [1, ∞]. Analogously, we can extend the usual L1 graph distances to an Lq -type, for q ∈ [1, ∞].
Consider a collection z = [z1 , ..., zk ] of generators and distances in the Cayley graph G(z). For
a path ρ in G(z), for each i ∈ [k], write ρi,+ for the number of times zi is used, ρi,− for the number
of times zi−1 is used (if in the undirected case, otherwise ρi,− := 0) and ρi := ρi,+ − ρi,− . The path
Pk
connects the identity with ρ · z. Then the (L1 ) graph distance of ρ is kρk1 := 1 (ρi,+ + ρi,− ).
P
k
For any q ∈ [1, ∞), define the Lq graph distance of ρ by kρkqq := 1 (ρqi,+ + ρqi,− ). For the L∞
graph distance, define kρk∞ := maxi {ρi,+ + ρi,− }. (The usual graph distance is given by q = 1.)
For Abelian groups, clearly for any q ∈ [1, ∞) an Lq geodesic, ie a path of minimal Lq weight,
will only use either zi or zi−1 , not both (since the terms in the product can be reordered), ie
Pk
ρi,+ ρi,− = 0 for all i. Thus kρkqq = 1 |ρi |q . Similarly, any L∞ geodesic ρ can be adjusted into a
new path ρ′ with ρ · z = ρ′ · z and kρk∞ = kρ′ k∞ satisfying ρ′i,+ ρ′i,− = 0 for all i.
We define the Lq typical distance DG(z),q (·) analogously to DG(z) (·), ie the q = 1 case.
For an Abelian group G, we write d(G) for the minimal size of a generating subset of G and

m∗ (G) := max minj∈[d] mj ⊕d1 Zmj is a decomposition of G .

Finally we set up a little more notation. Make the following definitions for q ∈ [1, ∞]:
Cq− := 2 Γ(1/q + 1)(qe)1/q ,

Cq+ := 21 Cq−

1/q 1/k
and D±
n /Cq± ,
q (k, n) := k

−
1/k
where the case q = ∞ is to be interpreted as the limit q → ∞; eg, C∞
= 2 and D+
.
∞ (k, n) = n
1/∞ :=
A more refined statement is given in Theorem 7.1. Use the convention k
1.

Theorem D. Let G be an Abelian group and q ∈ [1, ∞]. Suppose that 1 ≪ k ≪ log |G|. Suppose
that m∗ (G) ≫ k 1/q |G|1/k and if q ∈ (1, ∞) then additionally require k ≤ log |G|/ log log |G|.
Suppose that lim sup d(G)/k < 1 for undirected graphs and lim sup d(G)/k < 21 for directed graphs.
Then, whp, the Lq typical distance on Gk concentrates at D±
q , namely
±
P
DG
(β)/D±
q → 1 (in probability) for all β ∈ (0, 1).
k ,q

(The randomness is over the uniform choice of generators Z = [Z1 , ..., Zk ].)

1.3

Historic Overview

The study of these random Cayley graphs has a rich history. Rather than repeat it here, we
refer the reader to the appropriate points in the main articles.
· For motivation, discussions and history on universality of cutoff for this model, and a conjecture of Aldous and Diaconis [2, 3] which inspired this work, see [13, §1.3.1] and [14, §1.3.1].
· For discussions on using an entropic method to establish cutoff for ‘generic’ instances of
Markov chains, see [13, §1.3.5].
· For history of diameter-flavour results, see [16, §1.3.3] or [14, §1.3.4].
5

1.4
1.4.1

Additional Remarks
Precise Definition of Cayley Graphs

Consider a finite group G. Let Z be a multisubset of G. We consider geometric properties,
namely through distance metrics and the spectral gap, of the Cayley graph of (G, Z); we call Z
the generators. The undirected, respectively directed, Cayley graph of G generated by Z, denoted
G− (Z), respectively G+ (Z), is the multigraph whose vertex set is G and whose edge multiset is




{g, g · z} | g ∈ G, z ∈ Z , respectively (g, g · z) | g ∈ G, z ∈ Z .

(We do not assume that the Cayley graph is connected; that is, Z may not generate G.) If the
walk is at g ∈ G, then a step in G+ (Z), respectively G− (Z), involves choosing a generator z ∈ Z
uniformly at random and moving to gz, respectively one of gz or gz −1 each with probability 12 .
We focus attention on the random Cayley graph defined by choosing Z1 , ..., Zk ∼iid Unif(G);
−
−
+
when this is the case, denote G+
k := G (Z) and Gk := G (Z). While we do not assume that the
Cayley graph is connected (ie, Z may not generate G), in the Abelian set-up the random Cayley
graph Gk is connected whp whenever k − d(G) ≫ 1; see Lemma 8.1 below. In the nilpotent set-up,
this is the case whenever k − d(G/[G, G]) ≫ 1; see [14, Remark E.1].
The graph depends on the choice of Z. Sometimes it is convenient to emphasise this; we use a
subscript, writing PG(z) (·) if the graph is generated by the group G and multiset z. Analogously,
PGk (·) stands for the random law PG(Z) (·) where Z = [Z1 , ..., Zk ] with Z1 , ..., Zk ∼iid Unif(G).
1.4.2

Typical and Simple Cayley Graphs

The directed Cayley graph G+ (z) is simple if and only if no generator is picked twice, ie zi 6= zj
for all i 6= j. The undirected Cayley graph G− (z) is simple if in addition no generator is the inverse
of any other, ie zi 6= zj−1 for all i, j ∈ [k]. In particular, this means that no generator is of order 2,
as any s ∈ G of order 2 satisfies s = s−1 —this gives a multiedge between g and gs for each g ∈ G.
The RW on G− (z) is equivalent to an adjusted RW on G+ (z) where, when a generator s ∈ z
is chosen, instead of applying a generator s, either s or s−1 is applied, each with probability 12 .
Abusing terminology, we relax the definition of simple Cayley graphs to allow order 2 generators,
ie remove the condition zi 6= zi−1 for all i.
Given a group G and an integer k, we are drawing the generators Z1 , ..., Zk independently and
uniformly at random. It is not difficult to see that the probability of drawing a given multiset
depends only on the number of repetitions in that multiset. Thus, conditional
p on being simple, Gk
is uniformly distributed on all simple degree-k Cayley graphs. Since k ≪ |G|, the probability of
simplicity tends to 1 as |G| → ∞. So when we say that our results hold “whp (over Z)”, we could
equivalently say that the result holds “for almost all degree-k simple Cayley graphs of G”.
Our asymptotic evaluation does not depend on the particular choice of Z, so the statistics in
question depend very weakly on the particular choice of generators for almost all choices. In many
cases, the statistics depend only on G via |G| and d(G). This is a strong sense of ‘universality’.
1.4.3

Overview of Random Cayley Graphs Project

This paper is one part of an extensive project on random Cayley graphs. There are three main
articles [13, 14, 16], this technical report [15] and a supplementary document [17]. Each main
article is readable independently.
The main objective of the project is to establish cutoff for the random walk and determining
whether this can be written in a way that, up to subleading order terms, depends only on k and
|G|; we also study universal mixing bounds, valid for all, or large classes of, groups. Separately,
we study the distance of a uniformly chosen element from the identity, ie typical distance, and the
diameter; the main objective is to show that these distances concentrate and to determine whether
the value at which these distances concentrate depends only on k and |G|.
[13] Cutoff phenomenon (and Aldous–Diaconis conjecture) for general Abelian groups; also, for
nilpotent groups, expander graphs and comparison of mixing times with Abelian groups.
[16] Typical distance, diameter and spectral gap for general Abelian groups.

6

[14] Cutoff phenomenon and typical distance for upper triangular matrix groups.
[15] Additional results on cutoff and typical distance for general Abelian groups.
[17] Deferred technical results mainly regarding random walk on Z and the volume of lattice balls.
1.4.4

Acknowledgements

This whole random random Cayley graphs project has benefited greatly from advice, discussions
and suggestions of many of our peers and colleagues. We thank a few of them specifically here.
· Allan Sly for suggesting the underlying entropy idea for cutoff (used in §2 and §3).
· Justin Salez for reading this paper in detail and giving many helpful and insightful comments
as well as stimulating discussions ranging across the entire random Cayley graphs project.
· Itai Benjamini for discussions on typical distance.
· Péter Varjú for multiple insightful discussions on mixing for the upper triangular group and
for more general nilpotent groups, particularly other step-2 nilpotent groups.
· Evita Nestoridi and Persi Diaconis for general discussions, consultation and advice.

2

Cutoff: Limit Profile for Random Walks on Abelian Groups

In [13, Theorem A] we established cutoff for arbitrary Abelian groups when 1 ≪ log k ≪ log |G|
and k − d(G) ≫ 1. (The subregime where k ≫ log |G| was already established.) Further, in [13,
Theorem 2.4] we determined cutoff profile when some conditions on k were imposed:
p
to consider any k − d(G) ≫ 1, we needed k ≪ log |G|/ log log log |G|;
to consider any k − d(G) ≍ k, we needed k ≪ log |G|/ log log log |G|;
to consider any k ≪ log |G|,

we needed d ≪ log |G|/ log log log |G|;

see [13, Hypothesis A and Remark 2.5]. In particular, we could never consider general k & log |G|.
Recall that cutoff had already been established for arbitrary Abelian groups when k ≫ log |G|, but
the window, never mind the profile, was not known. In this section, we outline how to alleviate the
conditions on k, at the cost of some conditions on the group.

2.1

Entropic Times: Methodology, Definition and Concentration

We use an ‘entropic method’, as mentioned in §1.2.1; cf [6, 7, 8, 9]. The method is fairly general;
we now explain the specific application in a little more depth.
We define an auxiliary random process (W (t))t≥0 , recording how many times each generator
has been used: for t ≥ 0, for each generator i = 1, ..., k, write Wi (t) for the number of times that it
has been picked by time t. By independence, W (·) forms a rate-1 DRW on Zk+ . For the undirected
case, recall that we either apply a generator or its inverse; when we apply the inverse of generator
i, increment Wi → Wi − 1 (rather than Wi → Wi + 1). In this case, W (·) is a SRW on Zk .
Since the underlying group is Abelian, the order in which the generators are applied is irrelevant
and generator-inverse pairs cancel; hence we can write
Pk
S(t) = i=1 Wi (t)Zi = W (t) · Z.
Recall that the invariant distribution is uniform on G, giving mass 1/n to each vertex. The
proposed mixing time is then the time at which the auxiliary process W obtains entropy log n.
This time can be calculated fairly precisely in many situations; see Proposition 2.2.

We now define precisely the notion of entropic times. Write µt , respectively νs , for the law of
⊗k
W (t), respectively W1 (sk); so µt = νt/k
. Define

Qi (t) := − log νt/k Wi (t) ,

 Pk
and set Q(t) := − log µt W (t) = 1 Qi (t).

So E(Q(t)) and E(Q1 (t)) are the entropies of W (t) and W1 (t), respectively. Observe that t 7→
E(Q(t)) : [0, ∞) → [0, ∞) is a smooth, increasing bijection.
7

Definition 2.1 (Entropic and Times). For all k, n ∈ N and all α ∈ R, define tα := tα (k, n) so that
√ 


E Q1 (tα ) = log n + α vk /k and sα := tα /k, where v := Var Q1 (t0 ) ,
√
assuming that log n + α vk ≥ 0. We call t0 the entropic time and the {tα }α∈R cutoff times.
Direct calculation with the Poisson distribution and SRW on Z gives the following relations. A
sketch is given below; the rigorous details are given in [17, §A].
Proposition 2.2 (Entropic and Cutoff Times, [17, Proposition A.2]). Assume that 1 ≪ log k ≪ log n.
Write κ := k/ log n. For all α ∈ R, we have tα h t0 and furthermore, for some functions f and g
and all λ > 0, the following relations hold:
√ √
if k ≪ log n,
then tα h k · n2/k /(2πe) and (tα − t0 )/t0 h α 2/ k;
(2.1a)
√
if k h λ log n, then tα h k · f (λ)
and (tα − t0 )/t0 h αg(λ)/ k;
(2.1b)
p
√
if k ≫ log n,
then tα h k · 1/(κ log κ) and (tα − t0 )/t0 h α κ log κ/ k.
(2.1c)
Moreover, f, g : (0, ∞) are continuous bijections, whose value differs between SRW and DRW.

Sketch of Proof. In [13, §2.3], we sketched the argument for k ≪ log n. For k ≍ log n, the target
entropy is order 1, and so all the random variables are bounded in probability, away from both 0
and ∞. For k ≫ log n, we have t0 ≪ k, so approximate the RW by a Bernoulli distribution (with a
uniformly chosen sign for the SRW); in [13, §2.3], for k ≪ log n, we had t0 ≫ k and so approximated
by a normal distribution. With this adaptation, the sketch from [13, §2.3] passes over.
Since the Wi , and hence the Qi , are iid, Q is a sum of k iid random variables. Also, it turns out
that Var(Q(t)) h Var(Q(t0 )) ≫ 1 where t h t0 ; see [17, Corollary A.7]. It then stands to reason
Pk
that a CLT holds for Q = 1 Qi ; this is indeed the case. The following CLT, which will be of great
importance, is proved in [17, §A].
Proposition 2.3 ([17, Proposition A.3]). Assume that 1 ≪ log k ≪ log n. For all α ∈ R, we have

1/4
= (vk)1/4 .
P Q(tα ) ≤ log n ± ω → Ψ(α) for ω := Var Q(t0 )
(There is no specific reason for choosing this ω. We just need some ω with 1 ≪ ω ≪ (vk)1/2 .)

2.2

Precise Statement and Remarks

In this section we give the more refined version of Theorem A. Recall that, for an Abelian group
G, we write d(G) for the minimal size of a generating subset of G and

m∗ (G) := max minj∈[d] mj ⊕d1 Zmj is a decomposition of G .

Hypothesis A. The sequence (kN , GN )N ∈N satisfies Hypothesis A if |GN | → ∞ as N → ∞ and
there exists a constant c > 0 so that the following inequalities hold for all N ∈ N:
kN ≥ c log |GN |,

m∗ (GN ) ≥ log kN / log log kN

and d(GN ) ≤

1
5

log |GN |/ log log kN .

±
Recall that we write d±
Gk ,N (t) for the TV distance from uniform at time t for the walk on Gk
and Ψ for the standard Gaussian tail. Throughout the proofs, we drop the subscript-N from the
notation, considering sequences implicitly. We now state the main theorem of this section.

Theorem 2.4. Let (kN )N ∈N be a sequence of positive integers and (GN )N ∈N a sequence of finite,
Abelian groups; for each N ∈ N, define Z(N ) := [Z1 , ..., ZkN ] by drawing Z1 , ..., ZkN ∼iid Unif(GN ).
Suppose that the sequence (kN , GN )N ∈N satisfies Hypothesis A. For all α ∈ R and N ∈ N,
write tα,N := tα (kN , |GN |). Then, for all α ∈ R, we have
tα,N /t0,N → 1

P
and d±
Gk ,N (tα,N ) → Ψ(α) (in probability) as N → ∞.

8

That is, whp there is cutoff at time t0 with profile given by {tα }α∈R : for all ε ∈ (0, 1), the difference
in the mixing times tmix (ε)−tmix( 12 ) is given, up to subleading order terms, by tΨ−1 (ε) −t0 . Moreover,
the implicit lower bound on the TV distance holds deterministically, ie for all choices of generators.
Remark 2.5. We can write the cutoff statement, emphasising the N -dependence, in the form

P
−1
(ε) for all ε ∈ (0, 1),
tZ,N
mix (ε) − t0,N /wN → Ψ

where (t0,N )N ∈N is the mixing time and (wN )N ∈N is the window, defined by Proposition 2.2.
Namely, for all λ ∈ (0, ∞) and all ε ∈ (0, 1), combining Proposition 2.2 and Theorem 2.4, we have
tZ
mix (ε) − f (λ)k
√
→ Ψ−1 (ε) for all ε ∈ (0, 1) where
g(λ) k

k h λ log |G|.

△

Remark. The CLT, Proposition 2.3, gives the dominating term in the TV distance Theorem 2.4:
· on the event {Q(tα ) ≤ log n − ω}, we lower bound the TV distance by 1 − o(1);
· on the event {Q(tα ) ≥ log n + ω}, we upper bound the expected TV distance by o(1).
Combined with the CLT, we deduce that the dGk (tα ) → Ψ(α) in probability.
△
Remark. The regime k ≍ log n is of particular interest. It can be thought of as a ‘critical regime’:
if k ≪ log n, then tmix ≫ k; if k ≍ log n, then tmix ≍ k; if k ≫ log n, then tmix ≪ k.
From [13, Theorem A], the following statements hold. In order to have the cutoff time independent of the algebraic structure of the group, for k with 1 ≪ log k ≪ log n, it is sufficient to have
either k ≫ log n or d(G) ≪ log n. Further, there exist counter-examples when k ≍ log |G| ≍ d(G):
r
eg, the mixing times for Z2r
2 and Z4 are different if k h log n, but not if k ≫ 2 log2 n; note that
2r
2r
r
d(Z2 ) = 2r = log2 |Z2 | and d(Z4 ) = r = 12 log2 |Zr4 |. In this article, we place additional conditions
on the group which are sufficient for us to not only establish cutoff but further obtain the limit
profile, which is again independent of the algebraic structure of the group.
△

2.3

Outline of Proof

The outline here is very similar to that from the main article. For a detailed outline, see [13,
§2.5] there; here we outline the difference. Note that the lower bound in [13, §2.6] was valid for all
groups; we repeat it here for convenience.
For the upper bound, we were trying to bound the expectation of a d-th power of a gcd. Issues
arose when k became too large while k − d is fairly small; see the proof of [13, Corollary 2.15]. This
arose from the fact that we used the following estimate from [13, Lemma 2.14]:



P V1 ∈ γZ ≤ P V1 ∈ γZ | V1 6= 0 + P V1 = 0 ≤ 1/γ + 2/n1/k .

The second term becomes an issue when k gets close to log n—eg if k & log n then n1/k is a
constant and the upper bound is simply “at most some constant”, rather than decaying like 1/γ.
We alleviate this by defining

I := i ∈ [k] | Vi 6= 0

and studying P(Vi ∈ γZ | i ∈ I); the problematic term 2/n1/k then does not exist as we consider
only non-zero coordinates of V . If G = ⊕d1 Zmj , then we are actually interested in Vi mod mj for
each j. Recall that m∗ = minj mj . ‘Typically’, one has |Vi | ≤ m∗ . We suppose initially that m∗ is
large enough so that maxi |Vi | < m∗ whp. Thus looking at Vi = 0 or Vi ≡ 0 mod mj is no different.
For large |I|, the gcd analysis goes through similarly to before. When |I| is small, eg smaller
than d, it is more difficult to control; in this case, we use a fairly naive bound on the gcd, but
control carefully the probability of realising such an I. The case I = ∅ corresponding to V = 0, is
handled using the concentration around the entropic time in exactly the same way as before.

2.4

Lower Bound on Mixing

In this subsection, we prove the lower bound on mixing, which holds for every choice of Z.

9

In [13, §2], we only considered 1 ≪ k ≪ log n. As such, we only stated the entropic results
for this regime. Above, in Propositions 2.2 and 2.3, we stated analogous results for the full regime
1 ≪ log k ≪ log n. In the lower bound given in [13, §2.6], valid for arbitrary groups, there were no
conditions on k beyond those required for the entropic concentration, namely [13, Proposition 2.3].
As such, the identical proof passes over to the full regime 1 ≪ log k ≪ log n unchanged. We include
it below for completeness.
Proof of Lower Bound in Theorem 2.4. For this proof, assume that Z is given, and suppress it.
We convert the CLT, Proposition 2.3, from a concentration statement about Q into one about
W : for all α ∈ R, by the CLT, we have




P Eα h Ψ(α) where Eα := µ W (tα ) ≥ n−1 eω = Q(tα ) ≤ log n − ω ;

recall that ω ≫ 1. Fix α ∈ R. Consider the set

Aα := x ∈ G ∃ w ∈ Zd st µtα (w) ≥ n−1 eω and x = w · Z .

Since we use W to generate S, we have P(S(tα ) ∈ Aα | Eα ) = 1. Every element x ∈ Aα can be
realised as x = wx · Z for some wx ∈ Zk with µtα (wx ) ≥ n−1 eω . Hence, for all x ∈ Aα , we have


P S(tα ) = x ≥ P W (tα ) = wx = µtα (wx ) ≥ n−1 eω .
From this we deduce that

P
1 ≥ x∈Aα P S(tα ) = x ≥ |Aα | · n−1 eω ,

and hence

|Aα |/n ≤ e−ω = o(1).

Finally we deduce the lower bound from the definition of TV distance:


P S(tα ) ∈ · | Z − πG TV ≥ P S(tα ) ∈ Aα − πG (Aα ) ≥ P(Eα ) − n1 |Aα | ≥ Ψ(α) − o(1).

2.5

Upper Bound on Mixing

Throughout this section we implicitly assume the conditions of Hypothesis A, without repeating
this in the statements below. Similarly, we implicitly assume that n = |G| is sufficiently large.
We use a modified L2 calculation, as in Lemma 3.6 and Definition 3.7 in §3.5 above. There
we only bounded the order of the cutoff window; now we desire the profile. We use definitions
analogous to [13, Lemma 2.6 and Definition 2.7 in §2.7], where the profile is studied. Herein, we
often suppress the time and α-subscripts, eg writing W for W (tα ) or W (t), depending on context.
Let W ′ be an independent copy of W ; then S ′ := W ′ · Z is an independent copy of S. We recall
the modified L2 calculation; the following lemma is the same as Lemma 3.6.
Lemma 2.6. For all t ≥ 0 and all W ⊆ Zk , the following inequalities hold:



/W ;
PZ S(t) ∈ · − πG TV ≤ PZ S(t) ∈ · | W (t) ∈ W − πG TV + P W (t) ∈


2 
4 E PZ S(t) ∈ · | W (t) ∈ W − πG TV ≤ P S(t) = S ′ (t) | W (t), W ′ (t) ∈ W − 1.

(2.2a)
(2.2b)

We now make the specific choice of the ‘typical’ set W; we make a different choice for each
α ∈ R. Write Ψ for the standard Gaussian tail. The collection {Wα }α∈R of sets will satisfy

P W (tα ) ∈
/ Wα h Ψ(α),
using the CLT (Proposition 2.3). We show that the expression in (2.2b) is o(1). Then applying
(2.2a) gives dGk (tα ) ≤ Ψ(α) + o(1) whp. This matches the lower bound in §2.4.
By considering all α ∈ R, we are able to find the shape of the cutoff. If we only desire the order of
the window, then we need only consider the limit α → ∞; in this case, P(W (tα ) ∈
/ Wα ) ≈ Ψ(α) ≈ 0,
which explains the use of the word ‘typically’ in describing Wα .
In order to define precisely the set Wα here, we first define two parameters, rα and pα .

10

Definition 2.7a. For all α ∈ R, define rα (k, n) and pα (k, n) as follows:



rα (k, n) := min r ∈ Z+ P W1 (tα ) − E W1 (tα ) > r ≤ 1/k 3/2 ;



pα (k, n) := min P W1 (tα ) − E W1 (tα ) = j |j| ≤ rα (k, n) .

Also define r∗ (k, n) :=

1
2

log k and p∗ (k, n) := k −2 . (We consider k & log n ≫ 1 in any application.)

The typicality conditions will be a combination of ‘local’ (coordinate-wise) and ‘global’ ones.
Definition 2.7b. For all α ∈ R, define the local and global typicality conditions, respectively:


Wα,ℓ := w ∈ Zk wi − E W1 (tα ) ≤ rα ∀ i = 1, ..., k ;


Wα,g := w ∈ Zk P W (tα ) = w ≤ n−1 e−ω .

Define Wα := Wα,ℓ ∩ Wα,g , and say that w ∈ Zk is (α-)typical if w ∈ Wα .
The following proposition says that rα ≥ r∗ and pα ≥ p∗ .

Proposition 2.8a ([17, Proposition C.3 and Remark C.4]). For all α ∈ R, we have
rα (k, n) ≥ r∗ (k, n)

and pα (k, n) ≥ p∗ (k, n).

(2.3)

(Recall that here we are considering k & log n ≫ 1, by Hypothesis A.)
Proof. This follows from standard large deviation theory. Its proof can be found in [17, §C].
The following proposition determines the probability that W (tα ) lies in Wα , ie of typicality.
Proposition 2.8b. For each α ∈ R, we have

P W (tα ) ∈
/ Wα → Ψ(α).

Proof. The probability that the global conditions hold converges to 1 − Ψ(α) by our CLT, Proposition 2.3. The probability that a single coordinate fails the local condition is at most k −2 by
Definition 2.7a and Proposition 2.8a. Thus the probability that local typicality fails to hold is then
at most k −1 = o(1) by the union bound. The claim follows.
Herein, we fix α ∈ R and frequently suppress the tα from the notation, eg writing W· for W· (tα )
or W for Wα . Let V := W − W ′ , so {W · Z = W ′ · Z} = {V · Z = 0}. Write


D := Dα := n P V (tα ) · Z = 0 | typα − 1 where typ := typα := W (tα ), W ′ (tα ) ∈ Wα ) .
It remains to show that Dα = o(1) for all α ∈ R. Recall the conditions of Hypothesis A:
minj mj ≫ log k,

k & log |G|

and d ≤

1
30

log |G|/ log k.

Proposition 2.9. Suppose that (k, G) jointly satisfy Hypothesis A. (Recall that, implicitly, (k, G)
is a sequence of Abelian groups and integers.) Then, for all α ∈ R, we have Dα = o(1).
Given this proposition, we can prove the upper bound in the main theorem, Theorem 2.4.
Proof of Upper Bound in Theorem 2.4 Given Proposition 2.9. Hypothesis A implies that conditions required for Proposition 2.9. Apply the modified L2 calculation, Lemma 2.6 and Definition 2.7b, and use Propositions 2.8b and 2.9 to control the two resulting terms. Combined, these
says that dGk (tα ) ≤ Ψ(α) + o(1) whp.
It remains to prove Proposition 2.9, ie to bound the modified L2 distance. The remainder of
the section is dedicated to this goal.
Clearly we need to control the law of V · Z. First we analyse the case V = 0, which immediately
implies that V · Z = 0. The global typicality condition is designed precisely to handle this. The
proof of the following lemma is deferred until the end of the subsection.
11

Lemma 2.10. We have


n P V = 0 | typ ≤ e−ω /P(typ)

We move onto V 6= 0. Linear combinations of independent uniform random variables in an
Abelian group are themselves uniform on their support. Hence the distribution of v · Z is uniform
on gcd(v1 , ..., vk , n)G. Here we are using the convention gcd(r1 , ..., rℓ , 0) := gcd(|r1 |, ..., |rℓ |) for
r1 , ..., rℓ ∈ Z \ {0}. The following lemma is proved rigorously in [17, Lemma F.1].
Lemma 2.11. For all v ∈ Zk , we have

v · Z ∼ Unif γG where γ := gcd(v1 , ..., vk , n).

We thus need to control |γG|, since Lemma 2.11 implies that

 P
P V · Z = 0 | typ = γ∈N P(g = γ | typ)/|γG| where g := gcd V1 , ..., Vk , n .

Lemma 2.12. For all Abelian groups G and all γ ∈ N, we have
|G|/|γG| ≤ γ d(G) .

Proof. Decompose G as ⊕d1 Zmj with d = d(G) and some m1 , ..., md ∈ N. Then γG can be
Qd
Qd
decomposed as ⊕d1 gcd(γ, mj )Zmj . Hence |γG| = 1 (mj / gcd(γ, mj )) ≥ 1 (mj /γ) = |G|/γ d .
These lemmas combine to produce a simple, but key, corollary.

Corollary 2.13. We have


n P V · Z = 0, V 6= 0 | typ ≤ E gd(G) 1(V 6= 0) | typ .

Proof. The conditioning does not affect Z. The corollary follows from Lemmas 2.11 and 2.12.
Up to here, the proof has been very similar to that given in [13, §3.7]. Here it diverges somewhat,
in the analysis of this gcd in Corollary 2.13. The conclusion is the same, though.
Whether a coordinate is non-zero plays a major role in controlling this gcd. We introduce the
following notation, designed to handle the number of non-zero coordinates. For v ∈ Zk , write

I(v) := i ∈ [k] vi 6≡ 0 mod mj for all j = 1, ..., d .

We always consider V conditioned on typicality. We have |Vi | ≤ 2r∗ = log k < mj for all i and j
local typicality and Hypothesis A Thus, conditioned on local typicality, we have

I(V ) = i ∈ [k] Vi 6= 0 ; abbreviate I := I(V ).
We end up needing to separate the concepts of local and global typicality: define


and typg := W, W ′ ∈ Wg ; then typ = typℓ ∩ typg .
typℓ := W, W ′ ∈ Wℓ

We control the gcd via we determine the probability an individual coordinate is a multiple of a
given number in the following auxiliary lemma; it is taken from [13, §2.7]. Write α ≀ β if α divides β.
Lemma 2.14. For all non-empty I ⊆ [k] with {I = I} ∩ typ 6= ∅ and all γ ∈ N, we have

P γ ≀ Vi ∀ i ∈ I | I = I, typℓ ≤ γ −|I| .

Proof. The coordinates are independent and local typicality merely conditions each coordinate to
lie in a certain interval centred at 0. The claim now follows immediately from [13, Lemma 2.14].

From this, using the conditions of Hypothesis A, we can deduce that E(gd(G) 1(V 6= 0) | typ) =
1 + o(1). We refer to it as a “corollary”, since its proof is purely technical, not relying on any
properties of the RW or the generators, just algebraic manipulations. Its proof is briefly deferred.
12

Corollary 2.15. Given Hypothesis A, we have E(gd(G) 1(V 6= 0) | typ) = 1 + o(1).
Proposition 2.9 now follows immediately from Lemma 2.10 and Corollaries 2.13 and 2.15.
Proof of Proposition 2.9. By Lemma 2.10 and Corollaries 2.13 and 2.15, we have



n P V · Z = 0 | typ ≤ n P V = 0 | typ + n P V · Z = 0, V 6= 0 | typ


≤ n P V = 0 | typ + E gd(G) 1(V 6= 0) | typ = 1 + o(1).
We now prove Corollary 2.15. Abbreviate d := d(G). We use the decomposition

 P
E gd 1(V 6= 0) typ = ∅6=I⊆[k] E gd 1(V 6= 0)1(I = I) typ .

First we analyse ‘large’ I. We defer the proof of the next lemma to the end of the subsection.
Lemma 2.16. For all I ⊆ [k] with {I = I} ∩ typ 6= ∅ and |I| ≥ d + 2, we have


E gd I = I, typ ≤ 1 + 3 · 2d−|I| /P typg | I = I, typℓ .
An easy corollary of this controls the expectation when I is ‘large’.

Corollary 2.17. Let L ≥ d + 2. We have

P
n |I|≥L E gd(G) 1(I = I) typ ≤ 1 + 3 · 2d−L /P(typ).

Proof of Corollary 2.17. Recall Bayes’s rule, specifically the fact that P(B | C)/P(C | B) =
P(B)/P(C) for non-null events B and C. By Lemma 2.16, for L ≥ d + 2, we deduce that

P
n |I|≥L E gd 1(I = I) typ



P
≤ |I|≥L P I = I typ + 3 · 2d−|I| P I = I /P(typ)



≤ P |I| ≥ L typ + 3 · 2d−L P |I| ≥ L /P(typ) ≤ 1 + 3 · 2d−L /P typ .

Next we analyse ‘small’ I. This is somewhat more delicate: we use the trivial bound g ≤ r∗ =
log k (conditional on typicality) and carefully P(I = I | typ) using global typicality. Again, we
defer the proof of the next lemma to the end of the subsection.
Lemma 2.18. For all I ⊆ [k], we have

|I|
P I = I typ ≤ n−1 e−ω /p∗ /P(typ) = e−ω n−1 k 2|I| /P(typ)

(2.4)

An easy corollary of this controls the expectation when I is ‘small’.

Corollary 2.19. Set L :=

1
5

log n/ log k. We have


P
d(G)
1(I = I) typ = o 1/P(typ) .
1≤|I|≤L E g

Proof. Apply Lemmas 2.16 and 2.18 for I with 1 ≤ |I| ≤ L:
 P
P
P(typ) 1≤|I|≤L E gd 1(I = I) typ ≤ 1≤|I|≤L (log k)d · e−ω n−1 k 2|I|

≤ Lk L · (log k)d · e−ω n−1 k 2L ≤ e−ω · log n · n3/5 · n1/5 · n−1 = o(1),

since the number of I ⊆ [k] with |I| = ℓ is kℓ ≤ k ℓ and d ≤ 15 log n/ log log k by Hypothesis A.
We now have all the ingredients required to prove Corollary 2.15 .

Proof of Corollary 2.15. Combining Corollaries 2.17 and 2.19 with the decomposition

 P
E gd(G) 1(V 6= 0) typ = ∅6=I⊆[k] E gd(G) 1(V 6= 0)1(I = I) typ ,

gives E(gd(G) 1(V 6= 0) typ) = 1 + o(1/P(typ)). Proposition 2.8b states that P(typ) ≍ 1.
13

It remains to give the deferred proofs of Lemmas 2.10, 2.16 and 2.18.
Proof of Lemma 2.10. By direct calculation, we have


P V = 0, typ = P W = W ′ , W ∈ W


 P
P
= w∈W P W = w P W ′ = w = w∈W P W = w 2 ,

since W and W ′ are iid copies. Recall global typicality: P(W = w) ≤ n−1 e−ω for all w ∈ W. Thus




P
n P I = ∅ | typ ≤ n w∈W P W = w 2 /P typ ≤ e−ω /P typ .

Proof of Lemma 2.16. Local typicality applies coordinatewise and so conditioning on it does not
break independence. This is not the case for global typicality. We thus move from global to local:




E gd I = I, typ = 1 + E gd − 1 I = I, typ = 1 + E gd − 1 I = I, typℓ /P typg I = I, typℓ .

Write PI (·) and EI (·) to denote probability and expectation, respectively, conditioned on I = I
and typℓ (ie local typicality). If the gcd equals γ, then certainly γ divides each coordinate. Thus


 P
P
EI gd = γ≥2 γ d PI g = γ + 1 ≤ γ≥2 γ d PI γ ≀ Vi ∀ i ∈ I + 1.
Applying Lemma 2.14, for I with {I = I} ∩ typ 6= ∅ and |I| ≥ d + 2, we obtain



P
E gd I = I, typ ≤ 1 + γ≥2 γ d−|I|/PI typg ≤ 1 + 3 · 2d−|I| /PI typg .

Proof of Lemma 2.18. Requiring I = I places restrictions on the coordinates in I c , but not on
the coordinates of I other than that they are non-zero; we ignore the latter to get an upper bound
(see below). For a vector w ∈ Zk , write

WI (w) := w′ ∈ Zk | I(w − w′ ) = I .
Using the independence of W and W ′ , we have


 P
P I = I, W ∈ W = w∈W P W = w P W ′ ∈ WI (w) .

Hence, using the independence of the coordinates of W ′ , given w ∈ W we have
 Y

 Y P(Wi′ 6= wi )
1
≤ P W′ = w ·
.
P W ′ ∈ WI (w) = P W ′ = w ·
′
′
P(Wi = wi )
P(Wi = wi )
i∈I

i∈I

An immediate consequence of the definitions of r and p, in Definition 2.7a, is the following:


for all α ∈ R, if w1 − E W1 (tα ) ≤ rα (k, n) then P W1 (tα ) = w1 ≥ pα (k, n).

By Definition 2.7a and Proposition 2.8a, we have pα ≥ p∗ = k −2 . Hence, for w ∈ W, we obtain

 |I|
|I|
P W ′ ∈ WI (w) ≤ P W ′ = w /p∗ ≤ n−1 e−ω /p∗ = n−1 e−ω /k 2|I|

From this and the sum above, Lemma 2.18 follows by summing over all w ∈ W:



P
P I = I, typ ≤ P I = I, W ∈ W ≤ n−1 e−ω k 2|I| w∈W P W = w ≤ n−1 e−ω k 2|I| .

3

Cutoff: A Detailed Investigation of Zdp

In this section we perform a detailed analysis of the behaviour of the mixing time for the
random walk on the uniform random Cayley graph of degree k of Zdp , proving Theorem B. In [13]
we established cutoff, under the assumption that k − d ≫ 1. If G = Zdp for p prime, then



γG | γ ≀ n = γG | γ ≀ p = {G} ∪ {pG} = {G, {id}};
14

that is, the only options are the group itself and the trivial group, corresponding to γ = 1 and γ = p,
respectively. Thus, applying [13, Theorem 3.6], we deduce that there is cutoff at the entropic time
t0 (p, |G|) = t0 (p, pd ), ie the time at which the entropy of the RW on Zkp becomes log |G| = d log p.
In this exposition, we consider some cases not covered in [13]. In particular, we allow k − d to be
a fixed constant, not diverging. When this is the case and p diverges, it can be shown that choosing
k elements Z1 , ..., Zk ∼iid Unif(Zdp ) generates the group whp. On the other hand, if p is also a fixed
constant, then this is not the case; we establish cutoff conditional on generating the group. See
Lemma 8.1 for a dichotomy giving necessary and sufficient conditions to generate the group.
To ease notation, we drop completely any p-s, and often drop the p; to be explicit, we state in
the next subsection precisely what notation we are going to use.

3.1

Entropic Times: Methodology, Definition and Concentration

We use an ‘entropic method’; for further details, see [13]. To make this as self-contained as
possible, we now explain the specific application in a little more depth.
We define an auxiliary random process (W (t))t≥0 , recording how many times, mod p, each
generator has been used: for t ≥ 0, for each generator i = 1, ..., k, write Wi (t) for the number of
times that it has been picked by time t. By independence, W (·) forms a rate-1 DRW on Zkp . For the
undirected case, recall that we either apply a generator or its inverse; when we apply the inverse
of generator i, increment Wi → Wi − 1 (rather than Wi → Wi + 1). In this case, W (·) is a SRW
(rather than DRW) on Zkp . Note that every element of G = Zdp has order p, since p is prime. Hence
it suffices to look at the walk W mod p, ie on Zkp , rather than on Zk .
Since the underlying group is Abelian, the order in which the generators are applied is irrelevant
and generator-inverse pairs cancel; hence we can write
Pk
S(t) = i=1 Wi (t)Zi = W (t) · Z.
Recall that the invariant distribution is uniform on G, giving mass 1/n to each vertex. The
proposed mixing time is then the time at which the auxiliary process W obtains entropy log n.
This time will be calculated fairly precisely in many situations; see Proposition 3.2.
⊗k
. Define
Write µt , respectively νs , for the law of W (t), respectively W1 (sk); so µt = νt/k


Q(t) := − log µt Wi (t) and Qi (t) := − log νt/k Wi (t) ;

then, Qi forms an iid sequence over i ∈ [k], and
Q(t) =

Pk

i=1

Qi (t),



h(t) := E Q(t) and H(s) := E Q1 (sk) .

So h(t) and H(s) are the entropies of W (t) and W1 (sk), respectively. Note that h(t) = kH(t/k)
and that h : [0, ∞) → [0, log(pk )) is a strictly increasing bijection.
While all our results can be phrased in terms of (Shannon) entropy, from a technical point of
view it will be convenient to define the relative entropy:
R(s) := log p − H(s).
The maximal entropy of a random variable on Zp is log p, obtained uniquely by the uniform
distribution. Since the RW converges to the uniform distribution, R(s) → 0 as s → ∞. Of great
importance will be the parameter
ζ := k1 (k − d) log p = log p −

1
k

log n

Definition 3.1. Define ζ := k1 (k − d) log p = log p −
p

ζα := ζ 1 − 2α/ ζk(ζ ∨ 1) ,

1
k

where n := |Zdp | = pd .

log n, and, for α ∈ R, define

sα := H −1 (ζα )

15

and tα := sα k.

3.2

Entropic Times: Evaluation and Concentration

In this subsection, we estimate the entropic times in different regimes, and give a concentration
result. The proofs are given in [17, §B.4]; precise references are given at the appropriate times.
Importantly, the arguments for Propositions 3.2 and 3.3 do not require p to be prime.
The first proposition estimates the entropic times t0 and the difference tα − t0 ; the second gives
concentration of the Q random variable around these times. Recall that ζ = k1 (k − d) log p.
Proposition 3.2a ([17, Proposition B.25a]). Suppose that 1 ≪ k . d log p. The following hold:

if ζ ≪ 1, then t0 /k = s0 h 21 log(1/ζ)/ 1 − cos(2π/p) ;
if

ζ & 1, then t0 /k = s0 ≍ p2 e−2ζ = (pd )2/k ;

further, if in fact 1 ≪ k ≪ d log p, then
if

ζ ≫ 1, then t0 /k = s0 h p2 e−2ζ /(2πe) = (pd )2/k /(2πe).

Note that 1 − cos(2π/p) hp→∞ 2π 2 /p2 = 2π 2 p−2d/k e2ζ .
Proposition 3.2b ([17, Proposition B.25b]). Suppose that 1 ≪ k . d log p and (k − d)p ≫ 1, ie
ζ ≫ 1/k. Then, for all α ∈ R, we have tα h t0 and furthermore the following hold:
p

if ζ . 1, then (tα − t0 )/t0 . 1/ ζk log((1/ζ) ∨ e) = o(1);
√
if ζ ≫ 1, then (tα − t0 )/t0 . 1/ k = o(1) for the SRW.
Proposition 3.3 (Concentration, [17, Proposition B.27]). For α ∈ R, define
p
p
−
Q+
α := {Q(tα ) ≥ d log p + α k(ζ ∧ 1)} and Qα := {Q(t−α ) ≤ d log p − α k(ζ ∧ 1)};

c
−2
.
For all α ∈ (0, ∞) with |ζα − ζ0 | ≤ 12 ζ0 , we have P((Q±
α) ) . α

3.3

Precise Statement and Remarks

Recall that dGk (t) is the TV distance from uniform after time t for the RW on Gk .
Theorem 3.4 (Cutoff). Let G be a finite, Abelian group admitting a decomposition G := Zdp with
p prime. Assume that 1 ≪ k . d log p. Define the entropic times {tα }α∈R as in Definition 3.1. The
entropic times are asymptotically evaluated in Proposition 3.2.
Suppose that (k − d)p ≫ 1, ie ζk ≫ 1. Then the RW on Gk exhibits cutoff whp at t0 . More precisely, choose a sequence (βN )N ∈N ⊆ RN
+ with βN → ∞ (arbitrarily slowly) and let c ∈ {±1}. Then
P
d±
Gk ,N (tcβN ) → 1(c = −1) (in probability) as N → ∞.

Moreover, the implicit lower bound holds deterministically, ie for all choices of generators.
Also, if 0 ≤ (k − d)p . 1, then, conditional that the uniformly chosen multisubset [Z1 , ..., Zk ]
generates the group, there is cutoff whp at time 21 d log d/(1 − cos(2π/p)).
Remark 3.5. The outline of the proof is the same for all ζ with ζk ≫ 1; we assume this initially.
We also consider the case where 0 ≤ k−d = O(1) conditional on generating the group. This uses
a standard argument for the case k = d, and then compares the walk which uses Z = [Z1 , ..., Zk ]
with another walk using a subset Z ′ of size d which generates the group.
△
We explain how to do this at the end of the section in §3.6.
Remark. Prior to our work, cutoff had already been established for any Abelian group when
k ≫ log n, with an explicit mixing time; see [13, §1.3.1]. Although our technique can be adapted to
allow k & log n (when n = |Zdp |, this is equivalent to k & d log p), we do not give details here. △
16

Lower Bound on Mixing for Zdp

3.4

In this subsection, we prove the lower bound on mixing, which holds for every choice of Z.
(This argument is almost identical to the one which we give in [13, §2.6].)
Proof of Lower Bound. For this proof, we assume that Z is given, and suppress it.
The concentration result Proposition 3.3 gives P(Q−
α ) → 1 as α → ∞. Consider the set

Aα := x ∈ G ∃ w ∈ Zd st µtα (w) ≥ n−1 eω and x = w · Z .

Since we use W to generate S, we have P(S(tα ) ∈ Aα | Eα ) = 1. Every element x ∈ Aα can be
realised as x = wx · Z for some wx ∈ Zk with µtα (wx ) ≥ n−1 eω . Hence, for all x ∈ Aα , we have


P S(tα ) = x ≥ P W (tα ) = wx = µtα (wx ) ≥ n−1 eω .
From this we deduce that

P
1 ≥ x∈Aα P S(tα ) = x ≥ |Aα | · n−1 eω ,

and hence

|Aα |/n ≤ e−ω = o(1).

Finally we deduce the lower bound from the definition of TV distance:
 1


P S(tα ) ∈ · | Z − πG TV ≥ P S(tα ) ∈ Aα − πG (Aα ) ≥ P Q−
α − n |Aα | = 1 − o(1).

Upper Bound on Mixing for Zdp for (k − d)p ≫ 1

3.5

This subsection is devoted to the upper bound.
Outline of Proof. Consider α with α → ∞, but arbitrarily slowly. We show that the TV distance
+
from uniform is o(1) on the event Q+
α (whp over Z) and that P(Qα ) = 1 − o(1), using similar
techniques to those in [13, §2.7]. Theorem 3.4 follows from this and Propositions 3.2 and 3.3. △
We now make this outline precise and rigorous. Herein, we frequently suppress the time and
α-subscripts, eg writing W for W (tα ) or W (t), depending on context.
Key is a ‘modified L2 calculation’; cf [13, Lemma 2.6]. In short, one condition that W is ‘typical’
(in some precise sense), and then applies the standard TV–L2 calculation on the conditioned law.
Let W ′ be an independent copy of W ; then S ′ := W ′ · Z is an independent copy of S.
Lemma 3.6. For all t ≥ 0 and all W ⊆ Zkp , the following inequalities hold:


/W ;
≤ PZ S(t) ∈ · | W (t) ∈ W − πG TV + P W (t) ∈


2 
S(t) ∈ · | W (t) ∈ W − πG TV ≤ n P S(t) = S ′ (t) | W (t), W ′ (t) ∈ W − 1.


P S(t) ∈ · | Z − πG

4E

PZ

TV

(3.1a)
(3.1b)

Proof. The first claim follows immediately from the triangle inequality. For the second, using
Cauchy–Schwarz, we upper bound the TV distance of the conditioned law by its L2 distance:


2
P
2
4 PZ S ∈ · | W ∈ W − πG TV ≤ n x PZ S = x | W ∈ W − n1


P
P
= n x PZ S = x | W ∈ W 2 − 1 = n x PZ S = S ′ = x | W, W ′ ∈ W − 1,

as S = W · Z, S ′ = W ′ · Z and V = W − W ′ . The claim follows from Jensen’s inequality.

We now make the specific choice of the ‘typical’ set W; we make a different choice for each
α ∈ R. Cf [13, Definition 2.7]. The collection {Wα }α∈R will satisfy

P W (tα ) ∈
/ Wα ≈ 0 for large α,

using the concentration result Proposition 3.3. We show that the expression (3.1b) is o(1). Then
applying (3.1a) gives dGk (tα ) ≈ 0 whp, for large α.

17

p
Definition 3.7. For all α ∈ R, define ωα := α k(ζ ∧ 1) ≫ 1,



Wα := w ∈ Zkp | P W (tα ) = w ≤ n−1 e−ωα
and typα := W (tα ), W ′ (tα ) ∈ Wα .

The following proposition determines the probability that W (tα ) lies in Wα , ie of typicality.

Proposition 3.8. For all α ∈ (0, ∞) with |ζα − ζ0 | ≤ 12 ζ0 , we have

P W (tα ) ∈
/ Wα . α−2 .

Proof. The lemma follows immediately from Proposition 3.3, since {W (tα ) ∈ Wα } = Q+
α.
Herein, inside proofs we often drop the time dependence and α-subscripts from the notation,
eg writing W for W (tα ) and W for Wα or typ for typα . The ‘typical set’ W is designed precisely
so that the following lemma holds.
Lemma 3.9. For all α ∈ (0, ∞), we have


P W (tα ) = W ′ (tα ) | typα ≤ n−1 e−ωα /P typα ≪ n−1 .

Proof. By direct calculation, using independence of W and W ′ , we have


 P
P W = W ′ , typ = P W = W ′ , W ∈ W = w∈W P W = w 2 ≤ n−1 e−ω ,
with the final inequality using global typicality. The result follows by Bayes’s rule.

When W = W ′ , we necessarily have S = S ′ (since the group is Abelian). Now consider when
W 6= W ′ . The following lemma is a special case of [13, Lemma 2.11].
Lemma 3.10 ([13, Lemma 2.11]). For any v ∈ Zkp \ {0}, we have v · Z ∼ Unif(G).
Corollary 3.11. For all α ∈ R, we have

P S(tα ) = S ′ (tα ), W (tα ) 6= W ′ (tα ) | typα ≤

1
n.

Proof. Condition on W = w and W ′ = w′ with w 6= w′ and w, w′ ∈ W. This conditioning is
independent of Z. Hence S − S ′ = (w − w′ ) · Z ∼ Unif(G) by Lemma 3.10. The claim follows.
Proof of Upper Bound in Theorem 3.4 Given Propositions 3.2 and 3.3. We are assuming that
(k − d)p ≫ 1, ie ζk ≫ 1. This means that |ζα − ζ0 | ≤ 12 ζ0 for all α ∈ R. Choose α with α → ∞,
arbitrarily slowly. We need to show that dGk (tα ) = o(1) whp.
Apply Lemma 3.9 and Corollary 3.11 to deduce that P(S = S ′ | typ) = o(1). Apply the modified
L2 calculation of Lemma 3.6 using Definition 3.7 for the definition of typicality. Bound the ‘error
term’ using Proposition 3.8. This gives dGk (tα ) = o(1) whp.

3.6

Removing the Condition (k − d)p ≫ 1

In this subsection, we explain how to remove the condition (k − d)p ≫ 1 in Theorem 3.4 under
the conditioning that the group is generated, as referenced in Remark 3.5. There are two cases to
consider: k = d with p arbitrary (allowed to diverge) and 0 < k − d = O(1) with p a fixed prime.
Case k = d. Here we do not need to assume that p is prime. Note also that d = k ≫ 1. The
occurrence of cutoff in this set-up is not difficult. As we could not find a proof in the literature—
note that p is not assumed to be fixed—we give the details.
A key observation is that if Z ′ is a set of size d that generates Zdp , then the Cayley graph
with respect to it is isomorphic to the Cayley graph with respect to the standard basis {e1 , ..., ed }.
Namely, it is the d-fold Cartesian product chain of the p-cycle with itself.
For the lower bound, we combine the method of distinguishing statistics and Wilson’s method
[29]. Let f2 (y) := cos(2πy/p) and λp := cos(2π/p). Then λp is the second largest eigenvalue of the
18

transition matrix of SRW on Zp , and the corresponding eigenvector is f2 . Then f (x1 , ..., xd ) :=
1 Pd
d
i=1 f2 (xi ) is an eigenvector of the transition matrix of SRW on Zp with eigenvalue
d
Λp,d := (d − 1)/d + λp /d = 1 − (1 − λp )/d.

We use initial state (0, ..., 0). To apply the method of distinguishing statistics, we need to bound
both the expectation and the variance of f , both under the uniform and the RW distributions (at
time t); write these as π and µt , respectively. Under the uniform distribution, since the coordinates
are independent and |f2 (z)| ≤ 1 for all z ∈ Zp , we have Varπ (f ) ≤ d1 ; similarly, we have Varµt (f ) ≤
1
−(1−Λp,d )t
. Applying the
d . Also, since f is an eigenvector, we have Eπ (f ) = 0 and Eµt (f ) = e
method of distinguishing
statistics, eg as stated in [21, Proposition 7.12], for all ε ∈ (0, 1), whenever
√
e−(1−Λp,d )t ≥ Cε / d, for a sufficient
√ large constant Cε , we have t ≤ tmix (1 − ε).
Rearranging e−(1−Λp,d )t ≥ Cε / d and recalling the definitions of Λp,d and λp , we obtain
t≤

1
2

log d − log Cε
=
1 − Λp,d

1
2 d log d

1

− d log Cε
d log d
= 2
· 1 − o(1) .
1 − λp
1 − λp

We now prove a matching upper bound on the mixing time. Let Pt be the time-t transition
probabilities of the walk on Zdp . We identify this walk with the aforementioned d-fold Cartesian
product of the p-cycle with itself. Using independence of the coordinates, we have
d
pd P2t (x, x) − 1 = p Q2t/d (0, 0) − 1,

where Qs is the time-s transition kernel for a rate-1 SRW on Zp . This is the L∞ distance at time
2t, and hence the square of the L2 distance at time t. Let ε > 0 be a constant. Using the fact that
(1 + 21 ε2 /d)d ≤ ε2
when ε is sufficiently small, we have
pd P2t (x, x) − 1 ≤ ε

where p Q2t/d (0, 0) − 1 ≤ 12 ε2 /d.

Using the eigenvalue representation,
if

2t/d ≥ (1 + ε) log(2d/ε2 )/(1 − λp ),

then p Q2t/d (0, 0) − 1 ≤ 12 ε2 /d,

and hence pd P2t (x, x) − 1 ≤ ε2 . Thus
if t ≥

1
2 (1

1

+ ε)d log d + 12 (1 + ε)d log(2/ε2 )
d log d
= 2
· 1 + o(1)
1 − λp
1 − λp

then d2 (t) ≤ ε,

provided ε is sufficiently small. This upper bound matches our lower bound.
Case 0 < k − d = O(1). When p ≫ 1, we already established cutoff, and so the group is generated, whp. Thus we may assume that both p and k − d are fixed, but k ≥ d ≫ 1.
The following statement is key: if Z1 , ..., Zk generate Zdp for p prime, then there exists a set
S ⊆ [k] such that |S| = d and {Zℓ }ℓ∈S generate Zdp . This is immediate by viewing Zdp as a vector
space over the field Fp and noting that a set generates Zdp if and only if it spans it.
We begin by obtaining an upper bound. Choose a subset of generators of size d which generate
the group. We consider the walk on the Cayley graph corresponding to this subset of generators. In
the natural realisation of this walk, each coordinate is updated at rate 1/d; we want it to be updated
at rate 1/k. If this walk is mixed, then since the walk on Gk is obtained by a random independent
shift of that walk, the walk on Gk is also mixed. Hence the previous entropic upper bound on the
mixing time from the case k = d is still valid, after multiplication by k/d = 1 + O(1/d) = 1 + o(1),
due to replacing the rate 1/d by 1/k.
We now turn to the lower bound. Set ζ := k1 (k − d) log p ≍ 1/k ≪ 1. Since k > d, we can apply
our argument from §3.4. To bound the variance, we can no longer assume that |ζα −ζ0 | ≤ 21 ζ0 = 21 ζ,
since ζk ≍ 1. (Recall the definition of ζα from Definition 3.1.) This means that there is an extra
19

√
factor of ζα /ζ0 = 1 − 2α/ ζk ≍ 1 multiplying the variance. For the lower bound, we need only
consider α < 0 with |α| large. Multiplying the variance by a constant only changes the window by
a constant; in particular it does not affect the occurrence of cutoff. Hence the entropic time lower
bound is still valid. Also, as k/d = 1 + o(1), multiplying it by k/d does not affect the leading order.
Finally we must asymptotically evaluate this entropic time when 0 < (k − d)p = O(1). Up to
subleading order terms, by Proposition 3.2 it equals the desired time:



−1
1
/ log p / 1 − cos(2π/p) h 21 d log d/ 1 − cos(2π/p) ,
2 k log k(k − d)

4

Cutoff: No Cutoff When k Is Constant

Throughout the paper we have always been assuming that k → ∞ as n → ∞. It is natural to ask
what happens when k does not diverge. This case has actually already been covered by Diaconis
and Saloff-Coste [10], using their concept of moderate growth. Here we give a short exposition
of their results leading to the conclusion that, for nilpotent groups of bounded step, there is no
cutoff—for any choice of generating set, not only when one draws the Cayley graph uniformly.
Recall that a group G is called nilpotent of step at most L if its lower central series terminates
in the trivial group after at most L steps: G0 := G and Gℓ := [Gℓ−1 , G] for ℓ ∈ N with GL = {id}.
Definition 4.1 ([10]). Let G be a finite group. Let Z be a symmetric generating subset; that is,
{z1 · · · zr | r ∈ N0 , z1 , ..., zr ∈ Z} = G and if z ∈ Z then z −1 ∈ Z also. For R ∈ N0 , let B(R) denote
the R-ball around the identity in G. Write ∆ := inf{R ∈ N0 | |B(R)| = |G|} for the diameter of
G(Z). We say that G(Z) is of (A, d)-moderate growth if |B(R)| ≥ A−1 |G|(R/∆)d for all R ∈ N0 .
The main abstract result of Diaconis and Saloff-Coste [10] considers simple random walks on
general Cayley graphs of moderate growth; see [10, Theorem 3.1] for a slight extension, considering
more general random walks, which fundamentally gives the same conclusion.
Theorem 4.2 ([10, Theorem 1.2]). Let G(Z) be a Cayley graph of (A, d)-moderate growth; write
∆ := diam G(Z). For t ∈ N0 , let dTV (t) denote the TV distance between the law of the lazy SRW
run for t steps and the uniform distribution. Let c > 0. Then the following hold:

dTV 2(1 + c)|Z|∆2 ≤ Be−c where B := A1/2 2d(d+3)/4 ;

dTV c∆2 /(24d+1 A2 ) ≥ 12 e−c .
Further, the corresponding relaxation time t∗rel satisfies t∗rel ≥ ∆2 /(42d+1 A2 ).

The claim on the spectral is not included in the statements of Diaconis and Saloff-Coste [10].
However, the lower bound is proved precisely via the standard eigenvalue analysis; [10, (3.2)] gives
the required inequality (in the notation there β1 is the largest non-trivial eigenvalue).
Diaconis and Saloff-Coste then make the following observation, formalised below.
Corollary 4.3. Let A, d > 0. Let (GN (Z(N ) ))N ∈N be a sequence of finite, undirected Cayley graphs
of (A, d)-moderate growth and with supN |Z(N ) | < ∞. Then the corresponding sequences of lazy
simple random walks does not exhibit the cutoff phenomenon; in fact,



2
tmix GN (Z(N ) ) /kN . diam GN (Z(N ) ) . t∗rel GN (Z(N ) ) . tmix GN (Z(N ) ) as N → ∞.
Diaconis and Saloff-Coste apply this to nilpotent groups of bounded step.

Theorem 4.4 ([10, Lemma 5.1 and Theorem 5.2]). Let G be a nilpotent group of step L. Let Z
be a symmetric set of generators for G. Then G(Z) is of (A, log2 A)-moderate growth for some
A := A(|Z|, L), depending only on the number of generators |Z| and the step L.
As a corollary of this, if the number of generators is bounded and the underlying group is
nilpotent of bounded step, then the corresponding simple random walks do not exhibit cutoff.
20

For a Cayley graph G(Z), use the following notation. Write ∆ := diam G(Z) for its diameter.
For the lazy simple random walk on G(Z), write trel := trel (G(Z)) for the relaxation time (ie inverse
of the spectral gap) and tmix := tmix (ε; G(Z)) for the (TV) ε-mixing time, for ε ∈ (0, 1). When
considering sequences (GN (Z(N ) ))N ∈N , add an N -sub/superscript.
Corollary 4.5 (cf [10, Corollary 5.3]). Let (GN )N ∈N be a sequence of finite, nilpotent groups. For
each N ∈ N, let Z(N ) be a symmetric generating set for GN and write LN for the step of GN .
2
N
N
Suppose that supN |Z(N ) | < ∞ and supN LN < ∞. Then tN
mix /kN . ∆N . trel . tmix as N → ∞;
N
in particular, (tmix )N ∈N does not exhibit the cutoff phenomenon

5

Cutoff: Difficulties Arising for High-Dimensional Matrices

This section is an extension of [14, §7.3]. There we consider cutoff for the RW on Gk with
G ∈ {Up,d , Hp,d } with either p small (eg p ≍ 1) or k close to d(Gab ). It is not intended to be read
independently of the referenced section. In particular, we use terminology and notation with which
a reader of [14] should be familiar by that point of the article.
Denote by S ab (t) the location S(t) of the RW projected to the Abelianisation Gab . Since Gab
is Abelian, S ab (t) depends only on the final count W (t), not the order in which the generators are
chosen. Now, Gab = Zrp , where r ∈ {d − 1, 2d − 4} (depending on whether G = U or G = H). In
particular, every element is of order p. Thus we need only know W (t) with each coordinate taken
mod p. Defining W to be a rate-1 RW on Zkp (while W is a RW on Zk ), an identical lower bound
to that given in §3.3 shows that one must wait for W to have entropy log |Gab | (while before we
waited for W to have this entropy). If p is small, eg p = 2, then the entropy of W may grow
significantly more slowly than that of W . Even when k − d(Gab ) ≍ k, the entropic time for W
can be a constant factor larger than that for W . When k − d(Gab ) ≪ k, it can be of larger order.
Thus it is not sufficient to simply work with W ; one needs W . (In [13, Theorem A], we extend this
concept further and establish cutoff for all Abelian groups A when k − d(A) ≫ 1.)
If p ≫ 1 (diverging arbitrarily slowly) and k − d(Gab ) ≍ k, then one can check that the entropic
times agree asymptotically. Potentially, one can then with W rather than W . This is could very
beneficial for the Heisenberg group, since we can already handle any Hm,d with m fixed (not
ab
necessarily prime) and k − d(Hp,d
) ≫ 1. For the upper triangular group, however, we do not have
such a result. However, it is distinctly possible that there are cases where the entropic times agree
asymptotically and yet one should still work with W , rather than W .
Another obstacle, potentially more substantial, is the following. As part of our typicality conditions, we ensured that |Ci,j | < p, at least for many pairs. This was crucial in controlling the error
probability q(t). If p ≍ 1, then this is not actually an issue. Indeed, when k & log |Gab |, we found
that in fact at least a constant proportion of generators are picked precisely once. In this case,
sufficiently many (i, j) satisfy |Ci,j | = 1. We used this when extending from p prime to general m;
ab
ab
) = 2d − 4 ≍ log |Hp,d
|, so we always fall into this set-up.
see §4.1. If p ≍ 1, then k ≥ d(Hp,d
For the Heisenberg group Hp,d , we already handled p ≍ 1. Unfortunately, another issue arises
for the upper triangular group Up,d . We partitioned the generators according to the columns, so as
to get some desired independence: see the analysis leading up to (3.35); key in this is the factor 2
in (3.33). If we could remove this factor 2 (or replace it with 1 + o(1/d)), then we believe that the
analysis from §3.6 would pass through to handle p ≍ 1. The only change would be to restrict to
those generators picked at most once, exactly as we did in §4.1. However, we do not know how to
replace 2 with 1 + o(1), never mind 1 + o(1/d). (It seems plausible that 2/p could be replaced with
1/p + 1/p2 ; however, for p ≍ 1, this is not sufficient.) It thus appears that if one can do something
more creative than simply partitioning the generators, then the case of p ≍ 1—even Um,d with
m ≍ 1 not necessarily prime—could be handled. Such an argument eludes us—for now at least.
Recall from Lemma 3.14 the expression for a product of upper triangular matrices. We only
analysed the first (corresponding to the Abelianisation) and second (corresponding to Ci,j ) order
terms, discarding the remaining ‘higher order terms’. For d = 3, these non-existent. There are more
and more of them, however, as d grows. Discarding them may be too crude when p ≍ 1.
For any p ≫ 1, the regime 1 ≪ k ≪ log |Gab | is non-empty. If p diverges sufficiently slowly
and, eg, r > 12 k, then the assumption does not hold. Indeed, E(|W1 |) ≍ t0 (k, pr )/k ≍ p2r/k ≥ p if
21

k − d(Gab ) ≍ k. Thus is cannot be the case that E(|C1,2 |) ≪ p. This is a serious problem for our
method of controlling q(t) in this regime—and it exists whichever of W or W is used.
Multiple of the above suggested solutions require k − d(Gab ) ≍ k. When this does not hold,
things can be significantly more difficult. Using the RW W on Zkp , rather than the RW W on Zk ,
seems unavoidable. Indeed, the entropic time for the former will, if k − d(Gab ) ≪ k/ log p, be of
larger order for W than for W . This is perhaps not such a substantial problem though: it is clear
what the correction is (ie replace W with W ). More substantial is that in many cases one cannot
assume that |Ci,j | < p. One needs to study the ‘wrap around’ effect of taking Ci,j mod p. If one
tries to replace prime p by general m, the gcd analysis may get even more complicated.

6

Cutoff: From Upper Triangular Matrices to Nilpotent Groups

Most of the following discussion is based on observations made by Péter Varjú during discussions
of our work with him. A group is nilpotent of step at most ℓ if all iterated commutators of order
at least ℓ + 1 vanish necessarily. For example, step-1 is Abelian; step-2 has [[g1 , g2 ], g3 ] = id for
all g1 , g2 and g3 , ie the commutator subgroup is central. Our analysis has focussed on unit upper
triangular matrix groups; these are a canonical class of nilpotent groups. However, some of our
analysis does extend somewhat to more general nilpotent.
Recall that we wrote S for the location of the walk and W for its auxiliary variable; let W ′ be
an independent copy of W , and define S ′ correspondingly. As previously, we work in the directed
regime; so in the word S there are no inverses. Recall the definition of Ci,j from [14, (3.8)]:
Ci,j :=

PN

ℓ=1

1 Gℓ = j

 Pℓ−1

m=1

1 Gm = i



and Ci,i := 0 for all i, j ∈ [k],

where there are N steps and Gm is the index of the generator chosen in step m.
Lemma 6.1. Up to multiplication by an element of [G, Gcom ], we can express S as
S=

Qk
1


 Q
−1
−1 −Ci,j
ZiWi ·
i<j [Zi , Zj ]

If G is step-2 nilpotent then [G, Gcom ] = {id} is the trivial group.
(The second product is unordered, since we are working up to an element of [G, Gcom ], and so
we may assume that commutators commute with any element of G; the first is ordered i = 1, ..., k.)
Sketch of Proof. Writing a rigorous proof of this lemma is technical, and can obscure what is
going on; we use an example to demonstrate how to prove the lemma. In essence, we wish to move
all the Z1 -s to the left, then all the Z2 -s to the left-but-one and so on. To reverse the order terms,
we use the fact that hg = ghh−1 g −1 gh = gh[h−1 , g −1 ] and [h−1 , g −1 ] = [g −1 , h−1 ]−1 . For example,
ghhg = gh · gh[g −1 , h−1 ]−1 = g · gh[g −1 , h−1 ]−1 · h[g −1 , h−1 ]−1 = g 2 h2 [g −1 , h−1 ]−2 .
To move Zi past Zj , with i < j, for each occurrence of Zi we need to count the number of times
that Zj appears before it in the word; this is precisely (the definition of) Ci,j .
Expressing S −1 S ′ as a similar product, it is straightforward to see what we get when W = W ′ .
(We actually only need Wi ≡ Wi′ mod ord Zi for each i, but W = W ′ is generally easier to analyse.)
Corollary 6.2. If W = W ′ , then S −1 S ′ ∈ [G, G]/[G, [G, G]]. The converse holds in the free group,
ie when considering Z1 , ..., Zk as formal variables (ie with no relations between them).
If W = W ′ , then, up to multiplication by an element of [G, Gcom ], we can express S −1 S ′ as
Q
′
; write D := (Di,j )i,j .
S −1 S ′ = i<j [Zi−1 , Zj−1 ]Di,j where Di,j := Ci,j − Ci,j

′
In particular, if Ci,j = Ci,j
for all i and j (which implies that Wi = Wi′ for all i by taking i = j),
then S −1 S ′ ∈ [G, Gcom ]; if the group is step-2 nilpotent, then [G, Gcom ] = {id}, and hence S = S ′ .

22

Consider now step-2 nilpotent groups, of which the 3 × 3 matrices is an example. We are
interested in analysing P(S = S ′ | typ); typicality will primarily involve entropic considerations.
For ease of presentation, here we drop typ from the notation. As in [14, §3], we note that




P S = S ′ ≤ P S = S ′ | W = W ′ P W = W ′ + P S = S ′ | W 6= W ′ .
Typicality (entropy) bounds P(W = W ′ ) ≪ 1/|Gab | = |Gcom |/|G|, as for upper triangular groups.
Assume that t ≪ k, and that every generator is picked at most once—eg, this is the case if
k ≫ log n. The assumption means that some generator is picked once in S and never in S ′ (or vice
versa); this will allow us to deduce that S −1 S ′ ∼ Unif(G), and hence P(S = S ′ | W 6= W ′ ) = 1/n.
Since S = S ′ when Di,j = 0 for all i and j, we have



P S = S ′ | W = W ′ ≤ P S = S ′ | W = W ′ , D 6= 0 + P D = 0 .

When the nilpotent group is of higher step, the bound P(S = S ′ | D = 0) ≤ 1 may be too crude. We
analysed P(D = 0) in [14, §3], obtaining P(D = 0) ≈ 1/t!. We desire this to be close to 1/|Gcom|.
We wish to get P(S = S ′ | W = W ′ , D 6= 0) close to 1/|Gcom |. To do this, write

Di,j
Q
S −1 S ′ = i<j:Di,j 6=0 Zi−1 , Zj−1
.
′

While these commutators are neither uniformly random nor independent, we aim to have suitably
many Di,j 6= 0 so that the commutator product is sufficiently close to uniform (on Gcom ).
If “close” can mean “up to a sufficiently small factor”, then combining all these bounds gives
P(S = S ′ , W = W ′ ) ≪ 1/n. The modified L2 distance is then given by n P(S = S ′ ) − 1 = o(1).

We can apply the method for nilpotent groups of greater step, by quotienting out [G, Gcom ].
However, as the step increases the bounds become more crude: we could have P(S = S ′ ) ≪
P(S −1 S ′ ∈ [G, Gcom ]), which would be bad for this method. This is, in essence, what we did for
the d × d matrices; it is one of the main reasons why our analysis does not work well for large d.
The analysis also applies to non-nilpotent groups, for which such issues can be even worse.

7

Typical Distance: Generalised Graph Distance

This section focusses on distances from a fixed point in the uniform random Cayley graph of
degree k of an Abelian group G. The analysis is very similar to that of [16, §3] where the same
statistic was studied; here we are more general. In particular, there we only considered k ≍ log |G|.
Here we adapt that analysis to consider 1 ≪ k ≪ log |G|; we also extend the concept of graph
distance from an L1 -type concept to an Lq -type, for general q ∈ [1, ∞].

7.1

Definition of Lq Typical Distance

Graphs distances in Cayley graphs have some special properties. Consider a collection z =
[z1 , ..., zk ] of generators and distances in the Cayley graph G(z). For a path ρ in G(z), for each
i ∈ [k], write ρi,+ for the number of times zi is used, ρi,− for the number of times zi−1 is used (if
in the undirected case otherwise ρi,− := 0) and ρi := ρi,+ − ρi,− . The path connects the identity
Pk
with ρ · z. Then the length, in the usual graph distance, of ρ is kρk1 := 1 (ρi,+ + ρi,− ).
P
For any q ∈ [1, ∞), define the Lq graph distance of ρ by kρkqq := k1 (ρqi,+ + ρqi,− ). For the L∞ graph distance, define kρk∞ := maxi (ρi,+ + ρi,− ). (The usual graph distance is given by q = 1.)
For Abelian groups, clearly for any q ∈ [1, ∞) an Lq geodesic, ie a path of minimal length, will
only use either zi or zi−1 , not both (since the terms in the product can be reordered), ie ρi,+ ρi,− = 0
P
for all i. Thus kρkqq = k1 |ρi |q . Similarly, any L∞ -geodesic ρ can be adjusted into a new path ρ′
with kρk∞ = kρ′ k∞ and ρ′i,+ ρ′i,− = 0 for all i.
We define the Lq typical distance DG(z),q (·) analogously to DG(z) (·), ie the q = 1 case. When the
±
k generators are chosen uniformly at random, we write DG
(·), with the ±-superscript indicating
k ,q
whether or not the Cayley graph is directed.

23

7.2

Precise Statement

For an Abelian group, we define the dimension and minimal side-length, respectively, as follows:

d(G) := min d ∈ N ⊕d1 Zmj is a decomposition of G ;

m∗ := max minj=1,...,d mj ⊕d1 Zmj is a decomposition of G .

It can be shown that there exists an optimal decomposition {mj }d1 for m∗ with d = d(G). Our
main constraints will be lim sup d/k < 1 and k 1/q n1/k /m∗ ≪ 1.
Hypothesis B. The sequence (kN , GN )N ∈N and q ∈ [1, ∞] jointly satisfy Hypothesis B if the
following conditions hold (defining k 1/∞ := 1 for k ∈ N):
lim

k
N →∞ N
if

= ∞,

lim

k / log |GN |
N →∞ N

= 0 and

lim k 1/q |GN |1/kN /m∗ (GN )
N →∞ N

= 0;

q ∈ (1, ∞) then additionally kN ≤ log |GN |/ log log |GN | for all N ∈ N;
(
d
1 for undirected graphs,
N
lim sup
< 1
N →∞ kN
for directed graphs.
2

Finally we set up a little more notation. Make the following definitions:
Cq− := 2 Γ(1/q + 1)(qe)1/q ,

Cq+ := 12 Cq−

1/q 1/k
and D±
n /Cq± ,
q (k, n) := k

−
1/k
where the case q = ∞ is to be interpreted as the limit q → ∞; eg, C∞
= 2 and D+
.
∞ (k, n) = n
±
:=
D
(k
,
|G
When these are sequences (kN , GN )N ∈N , for N ∈ N and q ∈ [1, ∞], write D±
N
N |).
q
N,q
Similarly, for a sequence (GN )N ∈N of finite groups with corresponding multisubsets (Z(N ) )N ∈N
±
:= DG± (Z(N ) ) (β).
of sizes (kN )N ∈N , for N ∈ N, β ∈ [0, 1] and q ∈ [1, ∞], define DN,q
N

Theorem 7.1. Let (kN )N ∈N be a sequence of positive integers and (GN )N ∈N a sequence of finite,
Abelian groups; for each N ∈ N, define Z(N ) := [Z1 , ..., ZkN ] by drawing Z1 , ..., ZkN ∼iid Unif(GN ).
Suppose that the sequence (kN , GN )N ∈N satisfies Hypothesis B. Then, for all β ∈ (0, 1), we have
±
P
DN,q
(β)/D±
N,q → 1

(in probability) as N → ∞.

Moreover, the implicit lower bound holds for all choices of generators and for all Abelian groups,
only requiring the conditions in Hypothesis B which depend only on (kN , |GN |)N ∈N and q.
Remark. We initially prove this theorem for undirected Cayley graphs. In §7.6, we explain how
to adapt the proof from the undirected case to the directed case. Doing this, rather than making
every statement apply for both the un- and directed cases, significantly increases the readability. In
particular, when we speak of Z we are referring to the set of all integers, positive and negative. △
Remark. We use the same methodology as [16, §3]. An outline of the proof is given in [16, §3.2]. △

7.3

Size of Ball Estimates and Lower Bound

In the lemmas below, used to prove this theorem, instead of writing one lemma with multiple
parts, we split into separate lemmas according to q and k, eg q ∈ (1, ∞) or k ≍ log n; these parts
are indexed with letters, eg Lemmas 7.2a, 7.2b and 7.2c.
We wish to determine the size of the Lq balls in Rk . This is done by Lemmas 7.2 and 7.4; the
statements are given below, with proofs are deferred to the supplementary material, [17, §E].
For q ∈ [1, ∞), write Vk,q (R) for the (Lebesgue) volume of the Lq ball of radius R in Rk , ie

Vk,q (R) := vol x ∈ Rk kxkq ≤ R ;

also write Vk,q := Vk,q (1) and note that Vk,q (R) = Rk Vk,q . It is known (see [27]) that
Vℓ,q = 2ℓ Γ(1/q + 1)ℓ /Γ(ℓ/q + 1).
24

(7.1)

We can use this, along with Lemma 7.2b below, to well-approximate |Bk,q (R)| when q ∈
/ {1, ∞};
for q = 1 we directly bound |Bk,1 (·)|, while for q = ∞ we have an exact expression.
Lemma 7.2a. For q = 1 and all R ≥ 0, we have

k
2k ⌊R⌋
k 1(R ≥ k) ≤ Bk,1 (R) ≤ 2

⌊R⌋+k
k

Lemma 7.2b. For q ∈ (1, ∞) and all R ≥ k 1+1/q , we have


.

(7.2a)


Bk,q (R) = Vk,q (R) 1 + O k 1+1/q /R .

(7.2b)

k
Bk,∞ (R) = 2⌊R⌋ + 1 .

(7.2c)

Lemma 7.2c. For q = ∞ and all R ≥ 0, we have

We use this lemma to find an M so that |Bk,q (M )| ≈ n.

Definition 7.3. Set ω := max{(log k)2 , k/n1/(2k) }, and choose Mk,q to be the minimal integer
satisfying |Bk,q (Mk,q )| ≥ neω . Note that ω satisfies 1 ≪ ω ≪ k if k ≪ log n.
Recall that Mk,q = k 1/q n1/k /Cq , and that Cq = 2 Γ(1/q + 1)(qe)1/q . The next lemma shows
that the difference between M and M is only by subleading order terms. Also, let K be a constant,
assumed to be as large as required, and let ξ := 1 − e−Kω/k .
Lemma 7.4a. For k ≪ log n and q = 1, we have


Mk,1 ≤ Mk,1 (1 + ξ) and


Bk,1 Mk,1 (1 − ξ) ≪ n.

Lemma 7.4b. For k ≤ log n/ log log n and all q ∈ [1, ∞), we have



Mk,q ≤ Mk,q (1 + ξ) and Bk,q Mk,q (1 − ξ) ≪ n.
Lemma 7.4c. For q = ∞, we have


Mk,∞ = 12 n1/k eω/k − 21

and

Moreover, if k ≪ log n then Mk,∞ h Mk,∞ .

7.4


Bk,∞ Mk,∞ (1 − ξ) ≪ n.

(7.3a)

(7.3b)

(7.3c)

Lower Bound on Typical Distance

From this lemma, it is straightforward to deduce the lower bound in Theorem 7.1.
Proof of Lower Bound in Theorem 7.1. Observe that |Bk,q (M )| ≤ |Bk,q (M )|. By Lemma 7.4, the
right-hand side is o(n) when M := Mk,q (1 − ξ) when k ≪ log n. Thus DGk ,q (β) ≥ M for all Z.

7.5

Upper Bound on Typical Distance

The outline of this subsection follows closely that of [16, §3.5].
Proposition 7.5. Let q ∈ [1, ∞]. Suppose that k ≪ log n. If q ∈ (1, ∞), then further restrict to
k ≤ log n/ log log n. Suppose also that lim sup d/k < 1. Then E(kP(W · Z = · | Z) − πG k22 ) = o(1).
Once we prove these propositions, we have all we need to prove Theorem 7.1.
Proof of Theorem 7.1 Given Lemma 7.4 and Proposition 7.5. If kP(A · Z = · | Z) − πG k2 ≤ ε,
then the support S of A · Z satisfies πG (S c ) ≤ ε. Combining this with Lemma 7.4 and Proposition 7.5, we deduce the upper bound in Theorem 7.1.

25

Remark. Proposition 7.5 actually holds even if η := 1 − d/k ↓ 0, provided it does
√ so sufficiently
slowly and k/ log n is sufficiently small. It turns out that k/ log n ≪ η and η ≫ 1/ k is sufficient;
this allows k very close to both d and log n.
△
Let W, W ′ ∼iid Unif(Bk,q (M )), and let V := W − W ′ . Then we have
E


PGk W · Z ∈ · − πG

2
2




= E n P V · Z = 0 | Z − 1 = n P V · Z = 0 − 1.

First, it is immediate to see that P(W = W ′ ) = |Bk,q (M )|−1 ≤ n−1 e−ω . Analogously in §2, the
side-lengths {mj }d1 satisfy minj mj > 2M . Then we have


I := i ∈ [k] Vi 6≡ 0 mod mj ∀ j = 1, ..., d = i ∈ [k] Wi 6= Wi′ .
Lemma 7.6a. For all k and all q, we have

P I = ∅ ≤ n−1 e−ω .

(7.4a)

Lemma 7.6b. Suppose that k ≪ log n and q ∈ [1, ∞). If q ∈ (1, ∞), then restrict further to
k ≤ log n/ log log n. Then, for all I ⊆ [k], we have

P I = I ≤ ek(1/(eq)+ξq ) n−1+|I|/k
(7.4b)

where ξq := Kq ω/k ≪ 1, for some constant Kq .

Lemma 7.6c. For q = ∞, for all I ⊆ [k], we have

P I = I ≤ e−ω(1−|I|/k) n−1+|I|/k ≤ n−1+|I|/k

(7.4c)

While we have been stating results for undirected graphs, Lemma 7.6 holds in the directed case
too. Contrastingly, the following lemma distinguishes between the directed and undirected graphs
at one point. A proof of the lemma can be found in [16, Lemma 3.9] in the main article. (There,
while we studied both undirected and directed graphs, it was sufficient to use the worst-case bound
for both; there we need the slightly more refined statement. The identical proof works.) Define

g := gcd V1 , ..., Vk , n .

Lemma 7.7. For all I ⊆ [k], we have



n P V · Z = 0 | I = I ≤ E gd | I = I .

Further, there exists a constant C so that,


C2d (2M )d−|I|+2



E gd | I = I ≤ 1 + 3 · 2d−|I|


1 + 5 · ( 3 )2d−|I|
2

(7.5)

for all I ⊆ [k], we have
where |I| ≤ d + 1;

where |I| ≥ d + 2 for undirected grahs,

where |I| ≥ d + 2 for directed graphs.

(7.6a)
(7.6b)
(7.6c)

The idea behind (7.5) is that linear combinations of independent uniform random variables
are uniform on their support. Writing G = ⊕d1 Zmj , we obtain V · Z ∼ Unif(⊕d1 gj Zmj ) where
gj := gcd(V1 , ..., Vk , mj ) ≤ g. For a rigorous argument, see [16, Lemma 3.8] in the main article.
When |I| is large, if g > 1 then we are asking that a large number of coordinates have a common
divisor; naturally this decays exponentially in |I|. Using this decay, we can sum over all “large I”.
Remark 7.8. We firmly believe that the stronger (7.6c) should hold for both the undirected and
directed graphs (ie (7.6b) is unnecessary). It is merely a technical hurdle which is holding us
back from proving this. When q = ∞, the coordinates of V are independent; in this case, we can
prove that (7.6b) holds for both the undirected and directed graphs. As a result, we can relax
lim sup d/k < 21 to lim sup d/k < 1 for q = ∞.
△
26

Corollary 7.9. For any L with L ≥ d + 2, we have
n



P

|I|≥L P V · Z = 0, I = I ≤

(

1 + 3 · 2d−L
1+5·

( 32 )2d−L

for undirected graphs

(7.7a)

for directed graphs

(7.7b)

Proof. This proof is a direct calculation. By (7.6b, 7.5), using Bayes’s rule, specifically the fact
that P(B | C)/P(C | B) = P(B)/P(C) for non-null events B and C, for L ≥ d + 2 we deduce that



P
P
n |I|≥L P V · Z = 0, I = I | typ = n |I|≥L P V · Z = 0 | I = I, typ P I = I | typ



P
≤ |I|≥L P I = I | typ + 3 · 2d−|I| P I = I /P typ




≤ P |I| ≥ L | typ + 3 · 2d−L P |I| ≥ L /P typ ≤ 1 + 3 · 2d−L /P typ
for undirected graphs. The case of directed graphs follows analogously.

We first prove the results on P(I = I). For a set I ⊆ [k] and W ∈ Zk , write WI = (Wi )i∈I and
W\I = WI c . Recall that if C ⊆ C ′ and U ∼ Unif(C ′ ), then (U | U ∈ C) ∼ Unif(C). Hence we have

′
P W\I = W\I
=

|B|I|,q (M )|
P(W = W ′ )
|Bk,q (M )|−1
=
≤
. (7.8)
′
′
−1
P(WI = WI | W\I = W\I )
E(|B|I|,q (M − kA\I k1 )| )
|Bk,q (M )|

Write ℓ := |I|. Recall that, by choice of M , we have |Bk,q (M )| ≥ neω , and so

′
P W\I = W\I
≤ n−1 e−ω Bℓ,q (M ) .

Proof of Lemma 7.6a. Recall the choice of Mk,q , from Definition 7.3. Then (7.4a) follows:


P I = ∅ = P W = W ′ = Bk,q (Mk,q )

−1

≤ n−1 e−ω .

Proof of Lemma 7.6b. Consider first q = 1. From Lemma 7.4a, recall that M1 ≤ (2e)−1 kn1/k eξ
with ξ ≍ ω/k. Using Lemma 7.2a, for ℓ ≤ k, we have
Bℓ,1 (M1 ) ≤ 2ℓ

M1 +ℓ
ℓ



ℓ
≤ 2e(M1 /ℓ + 1) ≤ eξℓ (k/ℓ)ℓ nℓ/k ≤ ek(1/e+ξ) nℓ/k ,


using the fact that Nℓ ≤ (eN/ℓ)ℓ , that ℓ 7→ (k/ℓ)ℓ is maximised by ℓ = k/e and that 1 + x ≤ ex .
The proof is completed by noting that {I = I} ⊆ {A\I = A′\I }, and applying (7.8).

Now consider q ∈ (1, ∞). Justified by Lemma 7.2b and Lemma 7.4b, which shows that Mk,q ≫
k 1+1/q for all q, we replace this discrete ball by the continuous ball, and lose only a factor 1 + o(1);
for readability, we do not carry this factor in subsequent formulae.
Using Stirling’s formula and the upper for Mk,q from Lemma 7.4b gives
Vℓ,q (Mk,q ) ≤ Vℓ,q · (1 + ξ)k 1/q n1/k /Cq

ℓ

≤ q 1/2 eKq ω (k/ℓ)ℓ/q nℓ/k .

From this, similarly to in Lemma 7.6a, using (7.8), we deduce that

′
≤ q 1/2 eKq ω (k/ℓ)ℓ/q n−1+ℓ/k ≤ ek(1/(eq)+ξ) n−1+ℓ/q ,
P W\I = W\I


where ξ := Kq ω/k ≪ 1, using again the fact that Nℓ ≤ (eN/ℓ)ℓ and that ℓ 7→ (k/ℓ)ℓ is maximised
′
by ℓ = k/e The proof is completed by noting that {I = I} ⊆ {W\I = W\I
}.
Proof of Lemma 7.6c. The coordinates of W satisfy Wi ∼iid Unif({0, ±1, ..., ±M∞}), for i =
1, ..., k. Write ℓ := |I|. Hence, by (7.8) and (7.4a), we have

′
≤ Bℓ,∞ (M∞ ) / Bk,∞ (M∞ ) = (2M∞ + 1)ℓ−k .
P W\I = W\I
By (7.3c), we have 2M∞ + 1 ≥ n1/k eω/k . Hence


P I = I ≤ P A\I = A′\I ≤ eω(−1+ℓ/k) n−1+ℓ/k .
27

We have now done all the hard work in proving Proposition 7.5, from which we deduced
Theorem 7.1. It remains to go through the details of how to combine the previous results; there
are no more interesting ideas to prove the propositions, but the details are quite technical.
Similarly to the mixing proof, we use an L2 calculation:
E


P W · Z = · | Z − πG

2
2

=n

P

I⊆[k]


P V · Z = 0, I = I − 1.

(7.9)

Proof of Proposition 7.5 (when q < ∞). Recall that here k ≪ log n. For undirected graphs, we
have lim sup d/k < 1; for directed, lim sup d/k < 12 . Set η − := 1 − lim sup d/k > 0 and η + :=
1
− :=
d + 14 η − (k − d) and L+ := 2d + 41 η + (k − 2d). Use L− for undirected
2 − lim sup d/k; set L
+
graphs and L for directed. Then
lim sup L± /k ≤ 14 η ± + (1 − 41 η ± )(1 − η ± ) ≤ 1 − 32 η ± < 1;
also, L− − d ≫ 1 and L+ − 2d ≫ 1. Suppress the ±-superscript: write L := L± . By Lemma 7.4,
recalling that Cq = 2 Γ(1/q + 1) (qe)1/q , for some εq = O(ω/k) = o(1), we can write
M = (1 + εq )k 1/q n1/k /Cq .
It can be shown that Cq ≥ 2 for all q ∈ [1, ∞], and hence
2M ≤ eεq k 1/q n1/k .

(7.10)

Recall that when we consider q = 1, we only require k ≪ log n; when we consider q ∈ (1, ∞), we
require further that k ≤ log n/ log log n. Note that if I = ∅ then B = 0, and so B · Z = 0. Hence


n P B · Z = 0 | I = ∅ = n P I = ∅ ≤ e−ω ,

by the choice of the radius Mk,q .
Consider I ⊆ [k] with 1 ≤ ℓ = |I| ≤ d + 1. There are at most 2k such sets I. Recall ξq given in
Lemma 7.6b, and that ξq = O(ω/k) = o(1). Applying (7.4b, 7.5, 7.6a, 7.10), we obtain

n P V · Z = 0, I = I ≤ C2d ekεq ekξq k (d+2−ℓ)/q n(d+2−ℓ)/k · ek/(eq) n−1+ℓ/k ;

algebraic manipulations using the fact that lim sup d/k < 1 and 2d = no(1) then give

n P V · Z = 0, I = I = 2−k o(1).

(7.11)

similar algebraic manipulations to those used when 1 ≤ |I| ≤ d + 1 give

n P V · Z = 0, I = I = 2−k o(1).

(7.12)

Consider I ⊆ [k] with d + 2 ≤ ℓ = |I| ≤ L = d. Applying (7.4b, 7.5, 7.6b, 7.6c), we obtain

n P V · Z = 0, I = I ≤ 15 · ek(1/(eq)+ξq ) n−1+ℓ/k ;

We now sum over all I with 1 ≤ |I| ≤ L, using (7.11, 7.12):

P
n 1≤|I|≤L P V · Z = 0, I = I = o(1).

(7.13)

Finally we consider I ⊆ [k] with L ≤ |I| ≤ k. By Corollary 7.9, we have

n

X

L≤|I|≤k



P V · Z = 0, I = I ≤

(

1 + 3 · 2d−L = 1 + o(1)
1+5·

( 23 )2d−L

for undirected graphs,

= 1 + o(1) for directed graphs.

This last result actually holds for all q ∈ [1, ∞] and all 1 ≪ k ≪ log n.
The proof is completed by combining (7.14, 7.13) with (7.9).

28

(7.14a)
(7.14b)

Proof of Proposition 7.5 (when q = ∞). Recall that here k ≪ log n. As discussed in Remark 7.8,
here (7.6c) holds for both the undirected and directed balls (ie (7.6b) is unnecessary); we only
assume that lim sup d/k < 1 in either case. Set η := 1 − lim sup d/k > 0.
By (7.3c), we have 2Mk,∞ ≤ n1/k eω/k + 1. Consider I ⊆ [k] with 1 ≤ ℓ = |I| ≤ d + 1. There
are at most 2k such sets I. Applying (7.3c, 7.4c, 7.5, 7.6a), we obtain

n P V · Z = 0, I = I ≤ C2d n(d−ℓ+2)/k eω(d+2−ℓ)/k (1 + e−ω/k /n1/k )d+2−ℓ · e−ω(1−ℓ/k) n−1+ℓ/k ;

algebraic manipulations using the fact that lim sup d/k < 1 and 2d = no(1) then give

n P V · Z = 0, I = I = 2−k o(1).

For I ⊆ [k] with d + 2 ≤ ℓ = |I| ≤ (1 − η)k =: L, applying (7.4c, 7.5, 7.6b) gives

n P V · Z = 0, I = I ≤ 15 n−1+ℓ/k ≤ 2−k n−1+L/k+o(1) ,

since k ≪ log n. We now sum over the I with 1 ≤ |I| ≤ L = (1 − η)k, using (7.15, 7.16):

P
n 1≤|I|≤L P V · Z = 0, I = I ≤ 2k · 2−k n−1+L/k+o(1) ≤ n−η+o(1) = o(1).

(7.15)

(7.16)

(7.17)

Finally we consider I ⊆ [k] with L ≤ |I| ≤ k. As above, by Corollary 7.9, we have
n

X

L≤|I|≤k



P V · Z = 0, I = I ≤

(

1 + 3 · 2d−L = 1 + o(1)
1+5·

( 23 )2d−L

for undirected graphs,

= 1 + o(1) for directed graphs.

(7.18a)
(7.18b)

The proof is completed by combining this with (7.17) and (7.9).

7.6

Adapting Proof to Directed Cayley Graphs

Where the random variable A was uniform on a certain undirected lattice ball, it is now uniform
on a directed ball (of a different radius). Other than this, the only adaptation that needs be made
is in determining the sizes of the discrete lattice balls: now instead of being a subset of Zk , for some
k, they are restricted to the first quadrant, ie to Zk+ . Assuming that their radius is large enough,
this simply reduces their size by a factor (roughly) 2k .
Since all the sizes in question scale like Rk when the ball-radius is R, when k ≪ log n (and
so R ≫ 1), the desired radius for the directed ball is twice that of the
 undirected ball. When
k ≍ log n (and we consider the L1 ball), the directed ball has size R+k
, so we are still interested
k
in R ≍ k ≍ log n, just the constant is different for directed compared with directed.
Finally, for directed graphs, we have a slightly weakened bound on the expected gcd, ie E(gd |
I = I); see Lemma 7.7. We addressed this in the proof of Proposition 7.5 at the time.

8

Generating the Group with Uniform, Independent Generators

In this short section, we discuss (almost exclusively for Abelian groups) conditions on the
number k of generators chosen so that these elements actually generate the group—that is, the
graph Gk is connected. First we discuss the independent, uniform choice of generators, which has
been our focus in the entire random Cayley graphs project. Then we briefly discuss conditions used
by other authors who have studied such Cayley graphs when k ≍ 1 (ie does not grow as |G| → ∞).

8.1

Independent, Uniform Generators

Write ϕk (G) for the probability that k independent, uniform elements of G generates the group.
To start, we state a worst-case result proved by Pak [23, Lecture 1, Theorem 6]: if |G| ≤ 2d then
ϕk (G) ≥ ϕk (Zd2 ) for all k; in words, Zd2 is the hardest group to generate. As Zd2 forms a vector
space, one can calculate the probability ϕk (Zd2 ) explicitly; see (8.1, 8.2) below.
We now move onto Abelian groups. Recall that we write d(G) for the minimal size of a generating
set of G; abbreviate d := d(G). Clearly (by definition) we need k ≥ d. Draw Z1 , Z2 , ... ∼ Unif(G).
29

Pomerance [24] shows that the expected number of independent, uniform generators required to
generate the group is at most d(G) + 3. As such, by Markov’s inequality, k − d(G) ≫ 1 is always
sufficient to generate the group whp. It is trivial that this is necessary for some groups: using the
explicit expression for ϕk (Zd2 ), it is easy to see that there exists a continuous, decreasing function
f : [0, ∞) → (0, 1) so that ϕd+C (Zd2 ) ≥ f (⌈C⌉) for all C ∈ N0 . Interestingly, for general Abelian
groups, when k − d(G) ≫ 1 is not required, k = d(G) + 1 is sufficient—there is no middle ground.
Recall that any group can be written as a direct product of p-groups; when the group is Abelian,
this turns into a direct sum of Abelian p-groups. Further, up to reordering, this decomposition is
unique. Use the following notation for such a decomposition: G = ⊕p∈P Gp ; abbreviate dp := d(Gp ).
Lemma 8.1. Use the notation established above. The following dichotomy holds.
· If there exists p ∈ P with p ≍ 1 ≍ d − dp , then k − d ≫ 1 is necessary for ϕk (G) = 1 − o(1).
· If there exists ω ≫ 1 with minp∈P∩[1,ω] (d − dp ) ≫ 1, then ϕd+1 (G) = 1 − o(1).

Remark. Our proof is strongly based on Pomerance [24, Equations 2 and 4]; see (8.1, 8.2) below.
The argument given in [24] is simple and well-known; [24, Equation 2] is in essence Acciaro [1,
Lemma 1]. To be self-contained, we repeat it here. Our proof should not be thought of as novel,
but rather combining already-established ideas to give a statement of the form we desire.
△
Proof of Lemma 8.1. Draw Z1 , ..., Zk ∼iid Unif(G). For each i ∈ [k] and p ∈ P, let Zi (p) be the
projection of Zi to the p-group Gp . Then Zi = (Zi (p))p∈P where we identify G with ⊕p∈P Gp .
Then (Zi (p) | i ∈ [k], p ∈ P) are jointly independent. For different p ∈ P, the events
Ap,k := {Gp is generated by [Z1 (p), ..., Zk (p)]}
are independent. Since
{G is generated by [Z1 , ..., Zk ]} = ∩p∈P Ap,k ,
we deduce that
ϕk (G) =

Q

p∈P

ϕk (Gp ).

(8.1)

We now find an expression for ϕk (Gp ) for a (prime) Abelian p-group. We claim that
ϕk (Gp ) =

Q dp

ℓ=1


1 − p−(k−dp )−ℓ .

(8.2)

To see this, note first that Gp is isomorphic to the vector space of dimension dp over (the field)
Zp , under vector addition. The process of generating this may be thought of as passing a series of
tests: first we must choose a non-zero vector; next we must choose a vector not in the subspace
generated by the previous one; next we must choose a vector not in the subspace generated by the
previous two; etc. If the dimension of the subspace already generated is ℓ and ℓ < dp , then the
probability of choosing a vector not in this subspace is 1 − pℓ−dp . From this, one obtains (8.2).
We now consider the first claim of the lemma. From (8.1, 8.2), it is immediate that
ϕk (G) ≤ ϕk (Gp ) ≤ 1 − p−(k−dp )−1 .
Thus, using the hypotheses of this part, we have 1 − ϕk (G) ≥ p−(k−dp )−1 ≍ 1, as required.
For the second part, we desire a lower bound on ϕk (Gp ). From (8.2), we obtain
1 − ϕk (Gp ) = 1 −

Q dp

ℓ=1


Pdp −1 −ℓ
1 − p−(k−dp )−ℓ ≤ p−(k−dp )−1 ℓ=0
p ≤ 2p−(k−dp )−1 .

(In essence this, and the following, are union bounds.) Plugging this into (8.1), we obtain

P
P
Q
1 − ϕd+1 (G) = 1 − p∈P ϕd+1 (Gp ) ≤ p∈P 1 − ϕd+1 (Gp ) ≤ 2 p∈P p−(d−dp)−2 .

Separating this sum into p ∈ P with p ≤ ω and with p ≥ ω and applying the hypotheses of this
part, we see that it is o(1). That is, ϕd+1 (G) = 1 − o(1), as required.
30

8.2

Generating a Group with Order 1 Generators

As mentioned in [14, §1.3.4] and [16, §1.3.3], previous work on distance-metrics in random
Abelian Cayley graphs had focussed on the case where k is some fixed number, not diverging
as |G| → ∞. The previous section shows that in general the Abelian group will not be generated
by this many independently and uniformly chosen generators. Take, eg, Z2n : to generate this group,
at least one of the generators must be odd; however, the probability that none are odd is 2−k ≍ 1.
For each of the works which we referenced, we describe briefly the adaptations which they make
to ensure that the group is generated (whp).
· Amir and Gurel-Gurevich [4] studied cyclic groups of prime order. In this case (due to the
primality of the order), every element generates the group. Thus no conditions are required.
· Marklof and Strömbergsson [22] studied cycling groups of order n (for a random n) without
any primality assumption. The elements which they draw are chosen uniformly at random
conditional on being jointly coprime with each other and with n. (Note that d(Zn ) = 1.)
· Shapira and Zuck [26] studied Abelian groups of arbitrary (fixed, ie not diverging) rank
without any primality assumption. The elements which they draw are chosen uniformly at
random conditional on jointly generating the group. (Note that they may have d(G) > 1, but
it must be bounded—d(G) ≤ rank(G), by definition.)
· El-Baz and Pagano [5] determine, for fixed k, the diameter of various finite nilpotent groups
of fixed step, including the upper triangular group which we study. They require that the
rank be fixed and that k be strictly larger than the rank. They sample uniformly conditional
on generating the group. (It is standard that for a collection Z to generate a nilpotent group
G, it suffices for the projection of Z to the Abelianisation Gab to generate Gab .)

References
[1]

V. Acciaro (1996). The Probability of Generating Some Common Families of Finite Groups. Utilitas
Mathematica. 49 (243–254) MR1396305

[2]

D. Aldous and P. Diaconis (1985). Shuffling Cards and Stopping Times. Technical Report 231, Department of Statistics, Stanford University. Available online

[3]

D. Aldous and P. Diaconis (1986). Shuffling Cards and Stopping Times. Amer. Math. Monthly. 93.5
(333–348) MR841111 DOI

[4]

G. Amir and O. Gurel-Gurevich (2010). The Diameter of a Random Cayley Graph of Zq . Groups Complex.
Cryptol. 2.1 (59–65) MR2672553 DOI

[5]

D. El-Baz and C. Pagano (2021). Diameters of Random Cayley Graphs of Finite Nilpotent Groups.
Journal of Group Theory (to appear). arXiv:2002.08870

[6]

N. Berestycki, E. Lubetzky, Y. Peres and A. Sly (2018). Random Walks on the Random Graph. Ann.
Probab. 46.1 (456–490) MR3758735 DOI

[7]

C. Bordenave, P. Caputo and J. Salez (2019). Cutoff at the “Entropic Time” for Sparse Markov Chains.
Probab. Theory Related Fields. 173.1-2 (261–292) MR3916108 DOI

[8]

C. Bordenave and H. Lacoin (2018). Cutoff at the Entropic Time for Random Walks on Covered Expander
Graphs. arXiv:1812.06769

[9]

G. Conchon–Kerjan (2019). Cutoff for Random Lifts of Weighted Graphs. arXiv:1908.02898

[10]

P. Diaconis and L. Saloff-Coste (1994). Moderate Growth and Random Walk on Finite Groups. Geom.
Funct. Anal. 4.1 (1–36) MR1254308 DOI

[11]

C. Dou (1992). Studies of Random Walks on Groups and Random Graphs. Thesis, Massachusetts
Institute of Technology MR2716375

[12]

C. Dou and M. Hildebrand (1996). Enumeration and Random Random Walks on Finite Groups. Ann.
Probab. 24.2 (987–1000) MR1404540 DOI

[13]

J. Hermon and S. Olesker-Taylor (2021). Cutoff for Almost All Random Walks on Abelian Groups.
Available on arXiv

31

[14]

J. Hermon and S. Olesker-Taylor (2021). Cutoff for Random Walks on Upper Triangular Matrices.
Available on arXiv

[15]

J. Hermon and S. Olesker-Taylor (2021). Further Results and Discussions on Random Cayley Graphs.
Available on arXiv

[16]

J. Hermon and S. Olesker-Taylor (2021). Geometry of Random Cayley Graphs of Abelian Groups. Available on arXiv

[17]

J. Hermon and S. Olesker-Taylor (2021). Supplementary Material for Random Cayley Graphs Project.
Available on arXiv

[18]

M. Hildebrand (1994). Random Walks Supported on Random Points of Z/nZ. Probab. Theory Related
Fields. 100.2 (191–203) MR1296428 DOI

[19]

M. Hildebrand (2005). A Survey of Results on Random Random Walks on Finite Groups. Probab. Surv.
2 (33–63) MR2121795 DOI

[20]

R. Hough (2017). Mixing and Cut-Off in Cycle Walks. Electron. J. Probab. 22 (Paper No. 90, 49 pp.)
MR3718718 DOI

[21]

D. A. Levin, Y. Peres and E. L. Wilmer (2017). Markov Chains and Mixing Times. Second ed., American
Mathematical Society, Providence, RI, USA MR3726904 DOI

[22]

J. Marklof and A. Strömbergsson (2013). Diameters of Random Circulant Graphs. Combinatorica. 33.4
(429–466) MR3133777 DOI

[23]

I. Pak (2001). Combinatorics, Probability, and Computations on Groups Lecture Notes. Available at
www.math.ucla.edu/~pak/courses/pg.html

[24]

C. Pomerance (2001). The Expected Number of Random Elements to Generate a Finite Abelian Group.
Period. Math. Hungar. 43.1-2 (191–198) MR1830576 DOI

[25]

Y. Roichman (1996). On Random Random Walks. Ann. Probab. 24.2 (1001–1011) MR1404541 DOI

[26]

U. Shapira and R. Zuck (2019). Asymptotic Metric Behavior of Random Cayley Graphs of Finite Abelian
Groups. Combinatorica. 39.5 (1133–1148) MR4039604 DOI

[27]

X. Wang (2005). Volumes of Generalized Unit Balls. Mathematics Magazine. 78.5 (390–395) JSTOR30044198
DOI

[28]

D. B. Wilson (1997). Random Random Walks on Zd2 . Probab. Theory Related Fields. 108.4 (441–457)
MR1465637 DOI

[29]

D. B. Wilson (2004). Mixing Times of Lozenge Tiling and Card Shuffling Markov Chains. Ann. Appl.
Probab. 14.1 (274–325) MR2023023 DOI

32

