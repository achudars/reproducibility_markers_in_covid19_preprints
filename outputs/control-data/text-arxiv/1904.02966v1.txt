Rare Event Simulation for Steady-State Probabilities
via Recurrency Cycles∗

arXiv:1904.02966v1 [math.PR] 5 Apr 2019

Krzysztof Bisewski†1 , Daan Crommelin1,2 and Michel Mandjes2
1

2

Centrum Wiskunde & Informatica, Amsterdam
Korteweg de Vries Institute for Mathematics, University of Amsterdam

April 8, 2019
Abstract
We develop a new algorithm for the estimation of rare event probabilities associated
with the steady-state of a Markov stochastic process with continuous state space Rd and
discrete time steps (i.e. a discrete-time Rd -valued Markov chain). The algorithm, which
we coin Recurrent Multilevel Splitting (RMS), relies on the Markov chain’s underlying
recurrent structure, in combination with the Multilevel Splitting method. Extensive
simulation experiments are performed, including experiments with a nonlinear stochastic model that has some characteristics of complex climate models. The numerical
experiments show that RMS can boost the computational efficiency by several orders of
magnitude compared to the Monte Carlo method.

1

Introduction

Many stochastic processes have a ‘stable regime’, in the sense that with time their distribution
converges to a so-called steady-state. The steady-state (or stationary, equilibrium, ergodic)
probability distribution captures the long-term behavior of the process; the steady-state
probability of an arbitrary event (or set) B is equal to the fraction of time the process spends
in B in the long run (irrespective of the process’ initial value). In many application domains
steady-state probabilities are of crucial interest; think of physics (e.g. particle systems),
chemistry (e.g. reaction networks), and operations research (e.g. queueing systems). Within
this context of steady-state distributions, an important subdomain concerns the analysis of
rare events. Particularly when it concerns rare events with a potentially catastrophic impact,
there is a clear need to accurately estimate their likelihood (earthquakes, extreme weather
conditions, simultaneous failure of multiple components of a machine, etc.). As examples, we
refer to Ragone et al. (2018) for rare-event simulation methods in the climate context, and to
Rubino and Tuffin (2009) for a textbook treatment covering applications in e.g. engineering,
chemistry, and biology.
Despite the evident importance of being able to estimate steady-state rare-event probabilities,
relatively little attention has been paid to the development of efficient algorithms; rare-event
∗ This

article may be downloaded for personal use only. Any other use requires prior permission of the
author and AIP Publishing. This article appeared in K. Bisewski et al., Chaos: An Interdisciplinary Journal
of Nonlinear Science 29, no. 3 (2019): 033131. and may be found at https://doi.org/10.1063/1.5080296.
† Email: bisewski@cwi.nl

1

simulation in a finite-time horizon context received considerably more attention (focusing
e.g. on the estimation of the probability to hit a set B1 before hitting another set B2 ). The
main contribution of this paper concerns the development of a broadly applicable rare-event
simulation method that is tailored to the estimation of small steady-state probabilities.
In our setup we focus on discrete-time Rd -valued Markov chains. This framework covers
a wide class of intensively used stochastic models. It for instance includes the numerical
solutions to stochastic differential equations (SDEs), see e.g. Kloeden and Platen (1992). In
addition, various (inherently discrete-time) standard models from e.g. finance, biology, and
econometrics fall under this umbrella. The main advantage of our proposed algorithm is its
broad applicability, the fact that it does not require detailed knowledge of the system under
study, and that it is fairly straightforward to implement. In the sequel, we let (Xn )n∈N be
our d-dimensional Markov chain, which we assume to admit the stationary distribution µ.
We are interested in the probability that in steady-state the process attains a value in the
set B, i.e.,
N
1 X
γ := µ(B) = lim
1{Xn ∈ B}
(1.1)
N →∞ N
n=1
Throughout, the event B is assumed to be rare, entailing that γ is very small, typically of
order 10−4 or less (depending on the application at hand).
Our interest lies in estimating rare-event probabilities in the context of models, so in principle
we can do more than applying statistical methods of extreme value analysis to model data; cf.
Coles et al. (2001) for a textbook on Extreme Value Analysis. In our setup, the steady-state
distribution is not explicitly known; one therefore has to resort to simulation. The naı̈ve,
Monte Carlo estimator for γ is
γ
bMC

N
1 X
:=
1{Xn ∈ B},
N n=1

i.e., the average number of visits to set B until time N , which is known to be extremely
inefficient when B is rare; see e.g. Asmussen and Glynn (2007). Informally, one needs prohibitively many samples in order to obtain a reasonably accurate estimate of γ; the number
of samples required to obtain an estimate of given precision is inversely proportional to γ. In
many cases, especially while working with complex or high-dimensional systems, where the
integration of the model is time consuming, such computation might not be feasible.
An additional complication is that sampling directly from the steady-state distribution can be
challenging. In our new method, we settle this issue by dissecting the paths of the underlying
Markov chain into recurrency cycles. For an arbitrary set A, we say that a recurrency occurs
each time (Xn )n∈N crosses A inwards, i.e., each time the event {Xn−1 6∈ A, Xn ∈ A} occurs.
Assuming the process is in stationarity, γ is equal to the average amount of time spent in B
between two visits to the set A, divided by the average length of a recurrency cycle.
An example of a recurrency cycle is shown in Figure 1. It starts at P1 and ends at P5 ; the
time spent in set B is the time spent between states P3 and P4 . Note that recurrency is
defined with respect to A; it is not necessary that the system enters B during a recurrency
cycle.
In our algorithm we separately estimate the numerator (expected time spent in B during a
single recurrency cycle) and the denominator (expected length of a single recurrency cycle).
Here, two challenges arise. The first concerns the choice of the set A. Any A could in principle

2

B

A
Figure 1: An example of a recurrency cycle. The cycle begins at P1 , where the Markov chain
enters the set A from the outside, and ends at P5 where the chain enters A again (and the
next recurrency cycle begins).

be used, but in order to maximize the efficiency of the algorithm, it should be chosen so as to
minimize the expected time spent between visits to the set A. The second challenge is posed
by the rarity of visiting B within a cycle. To tackle this issue, we propose the use of Multilevel
Splitting (MLS), see Garvels (2000), Rubino and Tuffin (2009), but we remark that instead
of MLS other methods could be chosen. These alternatives include Genealogical Particle
Analysis (see e.g. Del Moral and Garnier (2005)), RESTART (see e.g. Villén-Altamirano
and Villén-Altamirano (2011)), Adaptive Multilevel Splitting (see e.g. Cérou and Guyader
(2007)), fixed-effort and fixed number of successes versions of Multilevel Splitting (see e.g.
Amrein and Künsch (2011)) and Importance Sampling (see e.g. Heidelberger (1995)). We
emphasize that we do not seek to compete with any of the aforementioned methods but
rather introduce a new overarching framework, in which all these methods can be used to
assess stationary performance metrics. We have chosen to work with MLS mostly for its
conceptual simplicity and intuitive use.
The algorithm we propose is inspired by expressions for steady-state probabilities resulting
from the theory of regenerative processes. Regeneration instances dissect the path of the
process into probabilistically identical, independent segments. For regenerative processes we
have that γ equals the average amount of time spent in B in a regeneration cycle divided
by the average length of a regeneration cycle. For more background we refer to Crane
and Iglehart (1975) and Asmussen (2008), or (in a more informal language) Henderson and
Glynn (1999). In our setup, with its uncountable state space and a steady-state distribution
potentially lacking atoms, we cannot straightforwardly construct regeneration points. We
therefore develop an approach that relies on the recurrency cycles introduced above, so as
to set up a scheme that yields probabilistically identical (but not necessarily independent)
cycles. We refer to Goyal et al. (1992) for an algorithm corresponding to the setting in which
the set A consists of finitely many elements (which inspired us to develop our algorithm). We
also mention that a large subclass of general (continuous) state-space Markov chains, called

3

positive Harris, is regenerative. However, constructing regeneration cycles in this context is
typically technically difficult, and in addition the implementation may be computationally
inefficient due to excessively long cycle lengths; see Henderson and Glynn (2001).
The manuscript is organized as follows. In Section 2 we discuss preliminaries, such as basic
theory of general state-space Markov chains. We also give an alternative representation
of the parameter γ based on the recurrent structure of a Markov Chain in Theorem 1.
Relying on this alternative representation, in Section 3, we introduce a new algorithm for
the estimation of γ, which we coin Recurrent Multilevel Splitting (RMS). In Section 4, we
establish (in a simplified setting) the optimal parameters for the RMS algorithm, and provide
implementation-related guidelines. Theorem 3 in Appendix C establishes the asymptotic
efficiency of the RMS algorithm. A technical derivation of the optimal parameters is given
in Appendix B. In Section 5 we test the method on a set of numerical examples, we discuss
which factors affect the method’s performance, and provide heuristics. Finally, in Section 6
we discuss possible extensions of the algorithm and give a summary. Appendix A consists of
a collection of required technical results.

2

Preliminaries

Here we introduce concepts used later in Section 3 such as (Harris) recurrence, the stationary
measure and recurrency cycles.

2.1

Continuous State-Space Markov Chains

In this subsection we provide some background on the (well-established) theory of stability of
discrete-time Markov chains with a general (continuous) state-space. The underlying theory
can be found in textbooks on Markov chains; our notation is in line with the one used in
Meyn and Tweedie (2012).
The theory of stability for general state-space time-discrete Markov chains differs from the
one for its finite (or countable) state-space counterpart. Due to the continuous state space,
multiple visits to the same state may happen with probability 0. This explains why the
classic notion of irreducibility and recurrence of states has been generalized to sets (rather
than states). In this setting one typically works with the concept of so-called positive Harris
recurrent chains: sets of states are guaranteed to be visited infinitely often, with in addition
a finite expected return time. Effectively all Markov chains with an invariant probability
distribution are positive Harris (with an exception of pathological, custom-made examples);
see (Meyn and Tweedie, 2012, Section 9) for a rigorous treatment of the topic.
Let (Xn )n∈N be a Markov chain taking values in Rd with a transition kernel P (x, dy), meaning
that the distribution of Xn+1 conditional on Xn = x is given by
Z
P(Xn+1 ∈ A | Xn = x) =
P (x, dy)
(2.1)
A
d

R
for measurable sets A ⊆ R . We denote P (x, A) := A P (x, dy). Then, the stationary
distribution µ satisfies the relation
Z
µ(A) =
µ(dx)P (x, A).
Rd

For an arbitrary probability measure ν, we define the conditional probability and expectation
by Pν (·) = P(· | X0 ∼ ν) and Eν (·) = E(· | X0 ∼ ν), respectively. In particular, when ν
4

corresponds to a point mass at x, we use the compact notations Px (·) = P(· | X0 = x) and
Ex (·) = E(· | X0 = x), respectively.

2.2

Recurrent Structure of a Markov Chain

As mentioned in the introduction, a large class of general state-space Markov chains (more
specifically, the class of positive Harris recurrent Markov chains) allows a regenerative structure; see e.g. Henderson and Glynn (2001). However, for application purposes, it is often
difficult to sample the regeneration times. Moreover, even when it is possible to sample
these, the implementation is often inefficient due to the long cycle lengths — in fact, the
regeneration may be a rare event itself.
There are many other ways to decompose a Markov chain into cycles. In this paper we
propose to work with cycles that start with an inward crossing of a set A (i.e., entering A
from the outside). We denote the time of the (k + 1)-th inward crossing by Sk , i.e.,
Sk := inf{n > Sk−1 : Xn−1 6∈ A, Xn ∈ A}.
with S−1 := 0. Then, we define the paths within the cycles through

Ck := Xn : Sk−1 ≤ n < Sk − 1 .

(2.2)

With a k-th cycle we associate the cycle length and the cycle origin (or starting point),
XkA := XSk−1 .

Lk := Sk − Sk−1 ,

(2.3)

We call A the recurrency set and C1 , C2 , . . . recurrency cycles. Under the assumption that
the process (Xn )n∈N starts in a cycle-stationary regime (that is X0 ∼ µ and S0 = 1.), the
pairs (C1 , L1 ), (C2 , L2 ), . . . are identically distributed. However, the cycles (2.2) are generally
A
not independent, as two distinct cycle origins XkA , Xm
separated by a short time period
Sm−1 − Sk−1 tend to be located within the same subregion of the recurrency set. Because of
this dependence, the decomposition into recurrency cycles is neither classic nor wide sense
regenerative, see Definition 3.1 and 3.3 in Kalashnikov (1994). The way we define cycles
is a special case of the almost regenerative cycles introduced by Gunther and Wolff (1980).
The interested reader is referred to the introduction of Calvin et al. (2006), where a more
exhaustive account of different regeneration-type methods is outlined.
A single recurrency cycle reflects the behavior of the process in steady-state. To make this
claim more precise, define the total time spent in the set B within the k-th cycle:
Rk :=

SX
k −1

1{Xn ∈ B}.

(2.4)

n=Sk−1

Since (in a cycle-stationary regime) the cycles in (2.2) are identically distributed, so are
R1 , R2 , . . .. The following theorem states that the total fraction of time that the process (Xn )
spends in the set B is proportional to the expected time spent in B between two consecutive
inward crossings into A. Define the frequency of recurrence αA := Pµ (X0 6∈ A, X1 ∈ A).
Theorem 1. Let (Xn )n∈N be a positive Harris recurrent Markov chain and let µ denote its
unique stationary probability measure. Let A, B be measurable sets such that µ(A) ∈ (0, 1).
Let L1 be as defined in (2.3), R1 as defined in (2.4), and TB := Eµ R1 . Then Eµ L1 < ∞,
µ(B) = αA · TB
and αA = (Eµ L1 )−1 .
5

(2.5)

Proof. See Appendix A.
The factorization (2.5) of γ from Theorem 1 is the starting point from which we develop our
steady-state rare-event simulation algorithm in Section 3.
We note that an analogue of Theorem 1 holds for regenerative processes. Dissection of a
Markov chain into regeneration cycles has one clear advantage over dissection into recurrency
cycles, namely, the regeneration cycles are independent. Using this independence, one can
easily infer the variance of an estimator based on regeneration cycles. Nonetheless, it is more
attractive to use recurrency cycles than regeneration, as the latter is harder to implement
and has a (much) longer expected cycle length. Moreover, in situations where it is possible
to sample from the stationary distribution µ, one can simulate independent paths until the
first recurrency cycle has ended, such that the resulting cycles will be independent as well.

3

Recurrent Splitting Algorithm

Our algorithm essentially relies on the result from Theorem 1, namely the representation of
γ as a product of two quantities. Thus, we divide our algorithm into two stages: first there
is the estimation of αA (the frequency of recurrence, equal to the reciprocal of the expected
cycle length), and secondly the estimation of TB (the expected time spent in set B within a
recurrency cycle).

3.1

Estimation of αA

While it is relatively straightforward to estimate αA (for example with a crude Monte Carlo
method), the choice of the recurrency set A is non-trivial. In this section we assume that A
has already been chosen; the choice of A is discussed in Section 4.2.
In typical situations one can generate sample paths of Xn by simulation but it is not possible
to exactly sample from the stationary distribution. Even though the law of Xn converges to
µ weakly, as n → ∞, at any fixed time n, the law of Xn is not exactly µ. Perhaps the most
straightforward method to estimate αA in this setting is the method of batch-means. It relies
on dissecting a path of the Markov chain of length N into m ∈ N batches of equal length,
and calculating the sample frequency of entering the set A for each batch. More specifically,
with M := [N/m],
kM
X
1
α
bk :=
1{Xn−1 6∈ A, Xn ∈ A},
M
n=(k−1)M +1

and then the batch-means estimator is
m

BM
α
bA
:=

1 X
α
bk .
m

(3.1)

k=1

Let s2BM be the sample variance of α
b1 , . . . , α
bm and tm−1 a Student’s t distribution with
m − 1 degrees of freedom. Then, due to the ‘near independence’ between the batches, under
appropriate regularity assumptions,
√

d

BM
m(b
αA
− α)/sBM −
→ tm−1 ,

d

(3.2)

as N → ∞, with ‘−
→’ denoting convergence in distribution. For more details and background,
we refer to e.g. Asmussen and Glynn (2007).
6

We remark that when an exact sampling procedure from µ is available, then it might be more
efficient to use the following Monte Carlo estimator. Generate M independent pairs
(1)

(1)

(M )

(X0 , X1 ), . . . , (X0
(i)

(M )

, X1

)

(i)

with (for all i = 1, .., M ) X0 ∼ µ and X1 distributed according to the dynamics of the
(i)
Markov chain (2.1) conditional on the value of X0 . The Monte Carlo estimator
MC
α
bA
:=

M
1 X
(i)
(i)
1{X0 6∈ A, X1 ∈ A}
M i=1

(3.3)

MC
is unbiased, Var α
bA
= αA (1 − αA )/M , and, as M → ∞,

√

d

MC
M (b
αA
− α)/sMC −
→ N (0, 1),

(3.4)

with s2MC the sample variance.
Whether exact simulation from µ is available or not, both methods allow for the construction
of confidence intervals based on the weak convergence results (3.2) and (3.4). It should be
clear that the set A should be chosen such that αA is not prohibitively small, so that the
methods (3.1) and (3.3) are computationally efficient. Otherwise, the estimation of αA would
be a rare event simulation problem itself (which we obviously want to avoid).

3.2

Estimation of TB

The second stage of the algorithm concerns the estimation of TB , as defined in Theorem 1.
This step is the more challenging one, as the quantity TB is expected to be very small. We
resort to rare-event simulation methods. For clarity of exposition, throughout this section
we assume that the chain (Xn )n∈N is stationary, S0 = 0 and we drop the subscript in Pµ
and Eµ (i.e., we write simply P and E, respectively). We also assume that we can sample
from the distribution of the cycle starting point X1A (note that X1A , X2A , ... are all identically
distributed). If we can not, then we sample from X1A approximately; this is discussed in
Section 3.3. We first introduce some notation; we define pB := P(τB < τAin ), with
τB := inf{n > 0 : Xn ∈ B},

τAin := S1 = inf{n > 0 : Xn−1 6∈ A, Xn ∈ A},

and
d

R+ := R1 | R1 > 0)

(3.5)

d

with ‘=’ denoting equality in distribution. Note that τAin − 1 marks the end of the first
recurrency cycle. Since {R1 > 0} = {τB < τAin }, pB is the probability of reaching B within a
cycle, and R+ is a random variable distributed as the total time spent in the set B within a
cycle conditioned on the cycle reaching set B. As was noted in Garvels (2000),
E(R1 ) = P(R1 > 0) · E(R1 | R1 > 0).
This entails that
TB = P(τB < τAin ) · E(R1 | τB < τAin ) = pB · ER+

(3.6)

The estimation of pB is a classic rare-event simulation problem, for which various methods
have been developed. Following Garvels (2000), we propose to use a Multilevel Splitting
(MLS) algorithm to estimate TB (but, as we mentioned before, other approaches could be
7

followed as well). There are a number of variations of the MLS algorithm; we chose to rely on
its simplest version (called ‘Fixed Splitting’). The following exposition aligns with Amrein
and Künsch (2011).
As mentioned, the naı̈ve Monte Carlo method is inefficient for the estimation of small probabilities, because of the computational effort wasted on simulating irrelevant paths. The
core idea behind the MLS method is to split the path of the process when it approaches B.
This way, we have more control over the simulation, by forcing the process into interesting
regions. In order to implement the MLS algorithm, one must first choose an importance
function H : Rd → [0, 1] which assigns an importance value to every possible state. H should
be chosen such that H(x) = 1 if and only if x ∈ B and H(x) = 0 for x ∈ A. We postpone
the discussion about the choice of the importance function to Section 4.2.
We now formally introduce the MLS algorithm. First divide the interval [0, 1] into m subintervals with endpoints:
0 = `0 < `1 < . . . < `m = 1,
and define the corresponding stopping times and events
τk := inf{n ≥ 0 : H(Xn ) ≥ `k }, Dk := {τk < τAin };

(3.7)

for k ∈ {0, . . . , m}. Note that τk is the first time an importance value greater or equal to `k
d
has been reached; in particular τm = τB and τ0 = 0, so that Xτ0 = X1A . Finally let
pk := P(Dk | Dk−1 ), k ∈ {1, . . . , m},
and p0 = 1, to which we refer as conditional probabilities. From the definition (3.7) we have
P(Dm ) = pB and since D0 ⊆ D1 ⊆ . . . ⊆ Dm , we conclude
pB =

m
Y

pk .

k=0

Finally, define splitting factors n0 , n1 , . . . , nm ∈ N, representing the number of independent
continuations of the process that are sampled when reaching the respective importance levels.
Here n0 plays a special role, as it is a number of independent MLS estimators; the final
estimator will be a mean of n0 independent MLS estimators. By virtue of this independence,
we are able to estimate the variance of the final estimator. For simplicity, in the following it
is assumed that n0 = 1.
Algorithm 1 (Multilevel Splitting).
1. Set k := 0, r0 := 1, sample X01 ∼ X1A .
2. In the k-th stage we have a sample of rk entrance states (Xk1 , . . . , Xkrk ), where we denote
Xki := Xτi i .
k

For each state Xki generate nk independent path continuations until min{τk+1 , τAin }.
The number of paths for which the event Dk+1 occurred is denoted by rk+1 . Store all
i
rk+1 states Xk+1
, for which the event Dk+1 occurred, in memory.
3. If rk+1 = 0, then stop the algorithm and put pbB := 0, TbB := 0.

8

4. If k < m − 1, then increase k by one and go back to step 2; otherwise put
rm
pbB := Qm−1

nk

k=0

.

(3.8)

i
5. If rm = 0, then return TbB = 0; otherwise, for each state Xm
generate nm independent
in
path continuations until τA . For each of these rm nm continuations record the time
spent in set B:
in
τA
−1
X
(j)
b
R+ :=
1{Xk ∈ B}.
k=τm

Calculate the total time spent in B by
rm+1 :=

rm
nm
X

b(j)
R
+

j=1

6. The final estimator is

rm+1
TbB := Qm
k=0 nk

(3.9)

Theorem 2. The estimators pbB and TbB , as defined in (3.8) and (3.9), are unbiased estimators for pB and TB respectively.
The following proof is based on notes of the Summer School in Monte Carlo Methods for Rare
Events that took place at Brown University, Providence RI, USA in June 2016 (authored by
J. Blanchet, P. Dupuis, and H. Hult). It is noted that various alternative derivations can be
constructed; see e.g. Asmussen and Glynn (2007).
Proof of Theorem 2. Let X i,j be labeling all descendants of the original particle, with i indexing time and j indexing the descendant. All descendants X ·,j are identically distributed
(but not independent). Now suppose that each particle has an evolving weight wi,j . Concretely, this means that when a particle crosses a threshold `k , it is split into nk particles
and its weight is divided equally among its descendants (i.e., each of them obtaining a share
1/nk of wi,j ). Each particle that reaches the set B has been split m times, and its weight is
Qm
thus 1/ k=1 nk . For particles that did not reach set B, we artificially split these particles
(keeping them in A) for the remaining thresholds so that the total number of particles is
Qm
k=1 nk , each of equal weight. Then, using the fact that the descendants are identically
distributed, we obtain
Qm

Xnk

k=1

ETbB = E

Qm
j=1

!

1
k=1

X
nk

1{X i,j ∈ B}

i

=E

X

1{X i,1 ∈ B} = TB .

i

Analogously, Eb
pB = pB , which ends the proof.
We remark that, with r1 , . . . , rm as defined in Algorithm 1, the same arguments as the ones
featuring in the proof of Thm. 2 imply the unbiasedness of the estimators for P(Dk ):


rk
E Qk−1
= P(Dk ) = p1 · · · pk .
(3.10)
i=0 ni

9

3.3

Estimation of γ

As already mentioned at the beginning of Section 3, the final estimator for γ is the product
γ
b := α
bA · TbB . In the description the MLS algorithm, in Step 1, we tacitly assumed that
we can sample the recurrency cycle origin X1A . As this is typically not the case, we sample
X1A approximately, in the following way. During the estimation of αA with the batch-means
method (3.1) we store each inwards crossing to the set A and we bootstrap these states in
Step 1 of Algorithm 1. We thus end up with the following algorithm for estimating the
rare-event probability γ, as defined in (1.1).
Algorithm 2 (Recurrent Multilevel Splitting).
1. Choose a recurrency set A satisfying the assumptions of Theorem 1 and an importance
function H : Rd → [0, 1].
2. Estimate αA using the batch-means method (3.1), and return α
bA . Store the locations
of the cycle origins in the set Srec := {X1A , X2A , . . .}.
3. Estimate TB using the Multilevel Splitting algorithm (Algorithm 1); in Step 1 sample
the origin X01 uniformly from Srec . The output is TbB .
4. The final estimator is
γ
b := α
bA · TbB

(3.11)

It is assumed that the set Srec is ‘representative enough’ to make sure that resampling from
Srec can be interpreted as taking i.i.d. samples of X1A in the stationary regime. Under this
assumption, the estimators α
bA , TbB are independent and the variance of γ
b can be inferred
using the sample variance of α
bA and TbB . However, in our numerical experiments in Section
5 we do not assume this independence to get an estimate of the variance. Instead we run
Algorithm 2 multiple times, resulting in multiple estimates γ
b from which we obtain a reliable
estimate for the variance of γ
b. For implementation details, see Section 5.1.

4

Choice of Parameters

In a rare-event setting, both the expectation and the variance of an estimator are very small,
so that the variance itself is not a meaningful measure of accuracy. Instead, it makes sense
to look at its value relative to the expectation, i.e., the Relative Error (RE):
RE2 (b
γ ) := E(b
γ − γ)2 /γ 2 .
An estimator with a lower relative error is not necessarily preferred; a more meaningful
criterion involves the corresponding total computational time (or: workload), which we denote
W (b
γ ); see the beginning of Section 5.1 for more details. In the following section we consider
a setting, in which we can derive optimal parameters of the MLS estimator by minimizing
the workload under a constraint on the relative error (i.e., RE2 (b
γ ) ≤ ρ for a given accuracy
ρ > 0).

4.1

Simplified Setting

Due to possible dependencies between the number of successes r1 , . . . , rm , there is no tractable
general expression for the variance of MLS estimator. A typical assumption made in the
literature is to assume some sort of independence between them, and to study the variance
afterwards. With τk , Dk defined as in (3.7) and R+ as defined in (3.5), we assume
10

(I) for all k ∈ {1, . . . , m},
P(Dk | Dk−1 , Xτk−1 ) ≡ P(Dk | Dk−1 ) = pk
(II) for all Xτm ,
 d
R1 | R1 > 0, Xτm = (R1 | R1 > 0) =: R+
Assumption (I) has been proposed in Amrein and Künsch (2011). It states that the probability of reaching the k-th importance level, given the (k − 1)-st level has been reached, is
constant over all possible entrance states. Assumption (II) states that the time spent in the
rare set B within a cycle, conditioned on the set B has been reached, does not depend on
the position of the entrance state to B. In principle, we have the possibility to choose the set
A and the importance function H(·) such that Assumption (I) is satisfied; see the discussion
in Section 4.2. Whether Assumption (II) holds or not is effectively problem specific, in the
sense that we do not have control over it due to the fact that the set B is given. We argue
that for a large class of problems there exists a most likely point of entry XτB to B, which
implies (II) approximately. We emphasize that Assumptions (I-II) are not required for the
RMS algorithm to work, but if they are fulfilled, optimality results can be derived. Under
(I-II) we find the squared relative error of TbB :
RE2 (TbB ) =

m
X
(1 − pk )/pk
RE2 (R+ )
Q
.
+
Qk−1
m
j=0 nj pj
j=0 nj pj
k=1

(4.1)

We derive (4.1) in Appendix A. Following the approach of Amrein and Künsch (2011), in Appendix B we derive the optimal parameters m, p1 , . . . , pm , n0 , . . . , nm for the MLS algorithm;
here, optimality refers to the property that the expected computational time is minimized
under the constraint for the relative error RE2 (TbB ) ≤ ρ for a given accuracy ρ > 0. It is
worth noting that the optimal number of thresholds m is roughly equal to | log pB | with conditional probabilities pk all equal to approximately 0.2. What is more, the optimal solution
satisfies nk pk+1 = 1 for k ∈ {1, . . . , m − 1}, so we can choose nk = 5. This so-called balanced
growth (see Garvels (2000)) ensures that, on average, n0 paths are sampled in each stage of
the algorithm (with an exception of the last stage, which corresponds to the estimation of
R+ ). The optimal workload reads
2

1 c | log pB |
√
+ RE(R+ )
(4.2)
W (TbB ) =
q
2c − 1
with a constant c defined as below display (B.2). As already mentioned, a rigorous derivation
of this result can be found in Appendix B, and the exact values of the optimal parameters
m, p1 , . . . , pm , n0 , . . . , nm in Eq. (B.2). In all our numerical experiments in Section 5, we
spend an initial portion of computational time on a rough estimation of pB and RE(R+ ) in
order to find a sufficiently accurate approximation of the optimal parameters. See Section
5.1 for a more detailed account of the implementation details.
The optimal workload in (4.2) is proportional to (log pB )2 , which offers a huge gain in efficiency, compared with the Monte Carlo method (C.4) (whose workload is inversely proportional to pB ). We derive efficiency results in Appendix C; in particular, Theorem 3 proves
that RMS is logarithmically efficient under specific assumptions.

4.2

Choice of Recurrency Set and Importance Function

In Section 4.1 we have seen that under Assumptions (I-II), the MLS method is particularly
efficient. As already mentioned, the level up to which Assumption (I) is fulfilled depends on
11

both the choice of the recurrency set and the importance function; we thus aim to choose
A and H(·) in such a way that (I) is approximately satisfied. At the same time, we would
like to choose A so as to maximize αA , so that the batch-means estimator α
bA (as defined in
(3.1)) is computationally efficient as well. These two requirements are often conflicting and
one must in the end strike a proper balance between them.
For each k, Assumption (I) concerns the choices of both A and H(·). However, it implies a
property that relates to the choice of A only, namely, the probability of reaching set B within
a recurrency cycle is independent of the initial point:
P(τB < τAin | X1A ) ≡ pB .
Thus, Assumption (I) implies that

d
A
X1A = X1A | R1 > 0 =: X+
;

(4.3)

informally, there is independence between the origin of the cycle on one hand, and the random
variable 1{R1 > 0} (indicating whether set B has been reached within a cycle) on the other
hand. Intuitively, the smaller the set A is, the more closely (4.3) is satisfied but also, the
smaller αA is. In particular, (4.3) trivially holds when A consists of one point only, but then
αA = 0. In Section 5.2.3 we give an example of a setting in which (4.3) is violated, but one
can imagine that in many situations (4.3) ‘roughly holds’. Thus, for practical purposes, it
is desirable that the set A maximizes αA while it also approximately satisfies (4.3). In full
generality, it is not an easy task to fulfill both aims.
A poorly chosen importance function will lead the split particles into uninteresting regions,
or it will force the paths to hit the rare set in an unlikely fashion. This potentially leads to
low efficiency of the MLS algorithm. Given that we have already chosen a set A satisfying
(4.3), there exists an importance function guaranteeing (I) to be satisfied:
H(x) := Px (τB ≤ τAin ),
Of course this insight is of theoretical value only: if we knew the quantity on the right hand
side, then we would not even have to use the MLS algorithm. However, also
Hg (x) := g(Px (τB ≤ τAin )),
with g : [0, 1] → R any increasing function, satisfies (I). This already gives a helpful guideline
for the choice of H. Namely, the states from which it is more likely to visit B before returning
to A should have larger importance. When an approximation or asymptotic behavior of
Px (τB ≤ τAin ) is available it might be useful to use it as an importance function. In Dean
and Dupuis (2009) a large-deviations based approach to the choice of importance function is
discussed.
Sometimes, a so-called distance-based importance function can be a good choice. This function is basically
H(x) := dist(x, B) = inf{kx − ak : a ∈ B},
normalized in such a way that H(x) = 1 iff x ∈ B and H(x) = 0 for x ∈ A. This importance
function can be a good choice for systems whose paths conditioned on {τB < τAin } are effectively gradually driven towards B. In contrast, distance-based importance function will be
a poor choice for systems for which it is most likely to reach rare set B by first getting away
from it. In Section 5 we include examples of problems for which a distance-based importance
function is a good choice, but also one in which it does not work well.
12

In some cases we may have already chosen a particular shape of the set A (e.g. an ellipsoid,
half-space, or multidimensional cube) which can be parametrized by a single parameter ` ∈ R.
Even better, if we have already chosen an importance function, then a level set
A(`) = {x ∈ Rd : H(x) ≤ `}
could be a good choice. In any case, we should choose ` to maximize αA(`) . We propose to
use a crude estimator to find `∗ : we find a maximizer of αA(`) by putting
`b∗ := arg max

X
N

1{Xn 6∈ A(`), Xn+1


∈ A(`)} .

(4.4)

n=0

Quantile validation. While it is not clear in general how to choose A such that it satisfies
(4.3), one can statistically test whether (4.3) holds after the choice of A has been made. We
now propose one particular method to do so that can be used in combination with the RMS
algorithm. In Step 2 of Algorithm 2 calculate and store the maximum importance attained
within cycles, i.e.,
Hkmax := max{H(x) : x ∈ Ck },
with Ck as defined in (2.2). Assuming a good importance function has been chosen, the cycle
origins corresponding to the highest importance should also be approximately distributed as
A
A
. Let Nrec be the
. This gives us means of comparing the distributions of X1A and X+
X+
A
max
total number of pairs (Xk , Hk ) obtained in Step 2 of Algorithm 2. Let
σ : {1, . . . , Nrec } → {1, . . . , Nrec }
be a permutation ordering (Hkmax )1≥k≥Nrec into a non-decreasing sequence, i.e.,
max
max
max
Hσ(1)
≤ Hσ(2)
≤ . . . ≤ Hσ(N
rec )

Now choose a q ∈ (0, 1) and let
 A
q
A
Srec
:= Xσ([(1−q)N
, . . . , Xσ(N
rec ])
rec )

(4.5)

q
is a subset of Srec which contains the cycle origins corresponding to the fraction
That is, Srec
1
q
q of values with highest importance. In particular Srec
= Srec . Then Srec and Srec
(for small
A
A
q) can be thought of as sets of samples from the random variables X1 and X+ , respectively.
Various tests can now be performed, to compare e.g. the means or variances; alternatively
QQ-plots can be made, or histograms can be compared.

5

Numerical Experiments

The aim of this section is to test the RMS method on a series of specific examples. The
examples range from simple cases, where the ground truth is known, to more complicated
dynamical systems, where the ground truth is unknown and we can only compare to estimates
obtained with Monte Carlo (MC) methods. In Section 5.2.3 we also carefully look into an
example where the RMS method (with a naı̈ve choice of the importance function) does not
perform that well; we discuss why this was to be expected. It will be seen throughout that
RMS is superior to MC in terms of the computational time needed to achieve a desired
level of accuracy; in extreme cases, like in Section 5.3, the RMS method can be three orders
of magnitude faster than MC (and the efficiency gain is expected to be even greater as γ
decreases).
13

5.1

Implementation Details

As already mentioned in Section 4, the relative error of an estimator is not always a meaningful measure of its performance, as it does not take the workload into account. We therefore
compare RMS with MC using the ratio of work normalized squared relative errors; see e.g.
Kroese et al. (2013). In particular, we define
Eff(b
γ) =

W (b
γ MC ) RE2 (b
γ MC )
·
.
W (b
γ)
RE2 (b
γ)

(5.1)

This value can be interpreted as the ratio of the computational cost of MC to the cost of
RMS when both methods reach the same accuracy (same relative error). Clearly, the larger
Eff(b
γ ) is, the more efficient the RMS method is in comparison with Monte Carlo.
In each of our experiments, the underlying Markov chain (Xn )n∈N represents the numerical
solution to a d-dimensional Stochastic Differential Equation (SDE) using an explicit Euler
scheme, with time step h > 0; see e.g. Kloeden and Platen (1992). We remark that the time
discretization potentially has a significant effect on a the underlying value of γ, especially in
the rare-event setting; see the recent systematic study Bisewski et al. (2018). However, in
the context of this article we only focus on discrete recursions that arise from numerical time
integration schemes. For these recursions we compare RMS with the corresponding Monte
Carlo results; we do not aim at studying the behavior as h ↓ 0.
Notice that our method relies on properties of discrete-time processes, in particular in the
definition of the recurrency cycles. More specifically, in the corresponding continuous-time
model recurrency cycles are ill-defined, as a set may be entered and left infinitely often in
a time interval of finite length. This feature could potentially lead to computational issues
when working with a small time step h. However, one can easily circumvent the problem and
still integrate the process with arbitrarily small h0 but store values every h > h0 . Note that
the discretization error depends only on h0 (and not h), since h0 determines the stationary
distribution. In fact, this is what we do in Section 5.3, where the process is integrated with
h0 = 10−4 but it is stored only every h = 10−2 .
In each experiment the rare event B is a half-space parametrized by u ∈ R:
B(u) = {(x1 , . . . , xd ) ∈ Rd : x1 ≥ u}.
In other words, the probability under consideration corresponds to the the first dimension
attaining high values in stationarity:
γ(u) := Pµ (X0 ∈ B(u))

(5.2)

for large u. Furthermore, in each experiment we choose the recurrency set A to be a half-space
parametrized by ` (where the value of ` is chosen depending on the particular experiment):
A(`) = {(x1 , . . . , xd ) ∈ Rd : x1 ≤ `}.
We use a distance-based importance function, i.e.,



0,
H(x1 , . . . , xd ) =

x1 /u,


1,

(5.3)

x1 ≤ 0
x1 ∈ (0, u)

(5.4)

x1 ≥ u

We now provide more details on our implementation of Algorithm 2. In Step 2, we estimate
αA using the method of batch means as in (3.1); the number of iterations of the Markov
14

chain N is chosen such that Srec consists of roughly 104 inwards crossings of A. In Step 3,
we want to choose parameters m, n0 , . . . , nm , `1 , . . . , `m for the Multilevel Splitting in such a
way that the workload is minimized and the resulting estimator satisfies
RE(TbB ) = 5 · 10−3 .

(5.5)

We run a pilot MLS with many intermediate thresholds (m = 20). The pilot gives us rough
estimates of pB , TB and RE(R+ ). We put the number of thresholds m and splitting factors
n0 , . . . , nm as in (B.2); we emphasize that the optimal n0 is also determined by the desired
squared relative error ρ. We find the intermediate thresholds `1 , . . . , `m following the loglinear interpolation approach from Wadman et al. (2014). Assuming (I-II) are satisfied, the
MLS method with these parameters should give the desired relative error, as in (5.5). We
note that in the pilot we use the variant of MLS called ‘Fixed Number of Successes’ developed
by Amrein and Künsch (2011).
The final estimator γ
b is the mean of N = 100 independent replicas γ
b(1) , . . . , γ
b(N ) of the RMS
estimator (3.11) with parameters as discussed above; i.e.
γ
b :=

N
1 X (i)
γ
b
N i=1

This additional ‘Monte Carlo wrapper’ around the RMS method enables us to approximate
the relative error RE(b
γ ) with
N

RE2 (b
γ) ≈

1 X
N − 1 i=1



2
γ
b(i)
−1 ,
γ
b

(5.6)

and we can approximate RE(b
αA ) and RE(TbB ) in a similar way. For each experiment we
present a table with results corresponding to multiple values of the threshold u. Each table
displays the final estimator γ
b as well as its estimate for RE(b
γ ), as in (5.6), and Eff(b
γ ), as in
MC
(5.1) based on the run of an MC estimator γ
b .
Various checks can be done in order to assess the reliability of the estimator γ
b. In each table
b
we additionally give the estimate for RE(TB ); if it matches the desired relative error, i.e.
RE(TbB ) ≈ 5 · 10−3 , then this is an indication that Assumptions (I-II) are satisfied. When
RE(TbB ) is larger than desired, it might be a result of poorly chosen intermediate thresholds
`1 , . . . , `m ; we propose to verify, after the algorithm has been executed, whether the estimates
for all the intermediate probabilities p1 , . . . , pm roughly equal the optimal popt ≈ 0.20. If this
is the case and we still get a particularly large RE(TbB ), this is an indication that either the
recurrency set or the importance function have not been properly chosen. In case of violation
of the former, in Section 4.2 we proposed a test for the appropriateness of the choice of the set
A. Additional verification can be performed to assess whether resampling from the set Srec
obtained in Step 2 of the RMS algorithm is a good approximation of taking i.i.d. samples
of X1A . This implies that α
bA and TbB are independent, but if they are independent then
necessarily
RE2 (b
γ ) = RE2 (b
αA ) + RE2 (TbB ) .
(5.7)
Thus, if (5.7) is not approximately satisfied, it is an indication that Srec does not represent
the distribution of X1A well. We emphasize that the relative error of γ
b presented in the tables
is calculated as in (5.6).

15

5.2

Ornstein-Uhlenbeck Process

Let (Xt )t≥0 be a d-dimensional Ornstein-Uhlenbeck process (d-dim OU), i.e., a process taking
values in Rd solving the SDE
dXt = −QXt dt + dWt
(5.8)
with Q ∈ Rd×d and (Wt )t≥0 denoting a standard d-dimensional Wiener process. Applying
the explicit Euler numerical scheme to (5.8), with time step h > 0 yields
Xn+1 = (I − Qh)Xn + Zn ,

(5.9)

with I the d-dimensional identity matrix I, and Z1 , Z2 , . . . i.i.d. d-dimensional standard
normal random variables. It is known Schurz (1999) that the stationary distribution µ of
(5.9) exists if there exists a positive-definite matrix M = (Mij )i,j∈N solving
M = (I − Qh)M (I − Qh)> + hI;

(5.10)

then the stationary distribution µ is d-dimensional centered normal with covariance matrix
M . The rare event of our interest is the exceedance of a high threshold in the first dimension
under the stationary distribution (of the discrete-time Markov chain in (5.9)), as in (5.2).
Eq. (5.10) is a well-known Sylvester equation and its solution M can be found numerically,
so that γ(u) can be evaluated as
p
γ(u) = Φ(−u/ M11 ),
(5.11)
with Φ(·) the standard normal cdf. Knowing the ground truth γ(u) gives us means to
determine how accurate the RMS estimator γ
b is.
In the following three subsections we study the OU process with different sets of parameters
but with the same choice of the recurrency set and importance function, as in (5.3) and
(5.4). First, we study the simplest case of a one-dimensional OU process. This is an ‘ideal’
example in the sense that Assumptions (I-II) are (approximately) satisfied. Second, we
study a multidimensional OU process; while the simplifying assumptions do not seem to be
satisfied, they are ‘close enough’ for the RMS method to give satisfactory results. The third
case describes a two-dimensional OU process with the matrix Q chosen such that Assumptions
(I-II) are not satisfied for our choice of the recurrency set and the importance function.
5.2.1

1-dim OU

In this experiment we put d = 1, Q = 1, h = 0.01. The recurrency set A(`) and importance
function H(·) are as in (5.3) with ` = 0 and (5.4) respectively.
If we would study the stationary distribution of the original SDE driven by (5.8) (rather
than the time-discrete numerical solution in (5.9)), then the paths of the process would be
continuous and thus X1A = 0 a.s. Moreover, because of their continuity, these paths must
cross all intermediate states x ∈ (0, u) before reaching B. Therefore x 7→ Px (τB < τAin ) is an
increasing function, implying that the distance-based importance function satisfies (I) in the
continuous-time case. By similar arguments, XτB = u a.s., and hence (II) is satisfied as well
in that case.
The Markov chain driven by (5.9) is a discrete-time approximation of (5.8), so the assumptions will not be satisfied exactly. In particular, we note that for any time step h > 0, the
support of XτB is the entire halfline [u, ∞) because in principle the process can exceed the
threshold u by any positive value upon the first entry. This shows that Assumption (II)
16

γ(u)

10−3

10−4

10−5

10−6

10−7

γ
b

9.94 · 10−4

9.93 · 10−5

9.96 · 10−6

9.96 · 10−7

9.96 · 10−8

RE(b
γ)

3.95e-03

5.45e-03

6.53e-03

6.31e-03

5.49e-03

Eff(b
γ)

4.1

8.9

45.2

378.9

1836.2

RE(TbB )

3.90e-03

4.99e-03

6.42e-03

6.30e-03

5.32e-03

Table 1: RMS algorithm for an 1-dim OU process. Parameters: Q = 1, A = {x1 ≤ 0},
B = {x1 ≥ u}; u has been chosen using (5.11) to match the values of γ in the first row. We
have α
bA = 0.0225 and RE(b
αA ) = 1.66 · 10−3 .
is not satisfied. An analogous argument can be used to show that Assumption (I) is not
satisfied either. Nonetheless, for a small time step h > 0, extreme overshooting upon the
first entry (i.e., XτB being significantly larger than u, or Xτk significantly larger than `k u) is
very unlikely. We conclude that the assumptions are satisfied approximately.
Since the value of γ(u) can be evaluated using (5.11), we chose the thresholds u to match the
desired value of γ(u), as in Table 1. The results show that RE(TbB ) ≈ 5 · 10−3 , as desired in
(5.5); this is a good indication that Assumptions (I-II) are satisfied. Also, the relative error
calculated under the independence assumption via (5.7) matches the estimated RE(b
γ ).
Conclusions. In this setting the RMS algorithm is very efficient, as compared with MC. The
numerical results agree very well with the theoretical outcomes, confirming our observation
that Assumptions (I-II) are approximately satisfied.
5.2.2

10-dim OU, Q with real eigenvalues

In this experiment we put d = 10, h = 0.01. The matrix Q = (Qij )i,j∈{1,...,d} is randomly
generated such that all its eigenvalues are real. The recurrency set A(`) and importance
function H(·) are as in (5.3) with ` = 0 and (5.4) respectively.
In Fig. 2 we plot four randomly chosen recurrency cycles, projected onto the first and second
dimension, which have reached the rare event B. These conditional paths seem to follow
a linear pattern; similar behavior is seen in other projections (not shown). This indicates
that attaining high values in the first dimension is coupled with attaining high values in the
second dimension (and similar statements can be made about other dimensions). Therefore,
the distance-based importance function is not expected to satisfy (I), as it does not take
this behavior into account; an ideal importance function should give larger importance to
states which attain simultaneously high values in the first and second dimension. While the
distance-based importance function is not the most appropriate choice, it is still expected to
give satisfactory results, as it drives the paths gradually towards the rare event.
The results of the RMS algorithm are presented in Table 2. It can be seen that the values of
RE(TbB ) do not exactly match the desired value 5 · 10−3 in (5.5), which in view of the earlier
discussion is not surprising, as we did not expect Assumptions (I-II) to hold. However, the
estimates γ
b are still very accurate, and the efficiency is still excellent (relative to the MC
method).
Conclusions. This experiment shows that the RMS algorithm can be effectively implemented
in a multidimensional setting, even when Assumptions (I-II) are violated. This underscores
the robustness of the distance-based importance function.

17

12

10

8

X (2)
t

6

4

2

0

-2
-1

0

1

2

3

4

5

6

7

X (1)
t

Figure 2: 10-dim OU process. Four random realizations of recurrency cycles conditioned
on reaching the rare set. The cycles have been plotted until the first hitting time of B.
Parameters: A = {x1 ≤ 0}, B = {x1 ≥ u} with u ≈ 6.4 such that and γ(u) = 10−6 .
γ(u)

10−3

10−4

10−5

10−6

10−7

γ
b

1.00 · 10−3

9.95 · 10−5

1.02 · 10−5

9.92 · 10−7

1.00 · 10−7

RE(b
γ)

7.84e-03

1.03e-02

1.35e-02

1.12e-02

1.49e-02

Eff(b
γ)

0.8

2.4

9.3

34.9

180.5

RE(TbB )

7.87e-03

1.02e-02

1.35e-02

1.12e-02

1.49e-02

Table 2: RMS algorithm for a 10-dim OU process. Parameters: Q is a matrix with only real
eigenvalues, A = {x1 ≤ 0}, B = {x1 ≥ u}; u has been chosen using (5.11) to match the
values of γ in the first row. We have α
bA = 0.0124, RE(b
αA ) = 2.46 · 10−3 .
5.2.3

2-dim OU, Q with complex eigenvalues

In this experiment we put d = 2, h = 0.01. We choose Q to have non-real eigenvalues: for a
positive θ,
"
#
1 θ
.
(5.12)
Q(θ) =
−θ 1
The drift generates a rotating (or spiraling) motion of the paths, with the speed of rotation
increasing as θ increases. We compare the efficiency of the RMS method for increasing values
of θ. The recurrency set A(`) and importance function H(·) are as in (5.3) with ` = 0 and
(5.4) respectively.
The results are presented in Table 3. We see that for most values of θ, RMS outperforms the
Monte Carlo, but the larger θ is, the lower the efficiency ratio Eff(b
γ ) becomes. At the same
b
time, as θ grows, the value of RE(TB ) deviates more and more from the desired target 5·10−3 ,
as in (5.5). This indicates a violation of Assumptions (I-II). We note that the estimates γ
b
18

3

2

1

X (2)
t

0

-1

-2

-3

-4
-3

-2

-1

0

1

2

3

4

X (1)
t

Figure 3: 2-dim OU process. Five random realizations of recurrency cycles conditioned
on reaching the rare set. The cycles have been plotted until the first hitting time of B.
Parameters: A = {x1 ≤ 0}, θ = 3, B = {x1 ≥ u} with u ≈ 3.4 such that γ(u) = 10−6 .
are quite accurate nonetheless, with a minor relative error of a few percent visible for larger
values of θ.
In Fig. 3 we plot five random recurrency cycles conditioned on reaching the rare set B. We
see that the paths do not gradually drift towards B, but rather first move far away from B,
due to the drift-induced rotation. This hints that the distance-based importance function
might be a poor choice. Fig. 4 shows that even property (4.3) seems to be violated. In this
q
in order to compare the distributions of
figure we compare the histograms of Srec and Srec
A
A
has more probability
(see the discussion Section 4.2). The figure shows that X+
X1A and X+
A
mass in the sets {x2 ≤ −1} or {x2 ≥ 1} than X1 .
Conclusions. When Q has non-real eigenvalues, the naı̈ve choice of the recurrency set and
the distance-based importance function (i.e., (5.3) and (5.4)) seems inadequate and leads to
a relative error higher than expected. This underscores the fact that one has to be careful
with the choice of A and H(·) and verify whether Assumptions (I-II) are satisfied; this can
be done e.g. by the means described in Section 4.2. Despite violation of Assumptions (I-II),
RMS still gives rather accurate estimates of γ, and outperforms Monte Carlo for small θ.

5.3

Franzke (2012) Stochastic Climate Model

As our final example, we consider the low-order stochastic climate model presented by Franzke
(2012). This is a 4-dimensional SDE with certain key features that are also present in
more complex climate models, including nonlinear (quadratic) drift terms that are energyconserving. We refer to Franzke (2012) for a more detailed discussion of the physical interpretation of this model.
The model is given by the following set of SDEs. It uses a standard, two-dimensional Wiener
(1)
(2)
(i)
(i)
(i)
process (Wt , Wt ). We write xi := Xt , yi := Yt and Wi := Wt to simplify notation.

19

q
Figure 4: 2-dim OU process, θ = 3. Marginal histograms of Srec
projected onto the second
dimension. The histograms have been normalized to a probability density function.

θ

0.5

1

1.5

2

3

γ
b

9.91 · 10−7

1.00 · 10−6

1.00 · 10−6

9.73 · 10−7

9.60 · 10−7

RE(b
γ)

8.20e-03

1.05e-02

2.34e-02

2.66e-02

4.01e-02

Eff(b
γ)

31.9

27.9

7.1

5.8

1.0

RE(TbB )

7.63e-03

1.05e-02

2.37e-02

2.67e-02

4.01e-02

Table 3: RMS algorithm applied to 2-dim OU process. Parameters: Q(θ) as in (5.12),
A = {x1 ≤ 0}, B = {x1 ≥ u}; u has been chosen depending on θ such that in every case
γ(u) = 10−6 .

We consider the system
dx1 = µ − x2 (L12 + a1 x1 + a2 x2 ) + d1 x1 + F1

1
2
2
+ L13 y1 + B123
x2 y1 + (B131
+ B113
)x1 y1 dt
dx2 = µ + x1 (L21 + a1 x1 + a2 x2 ) + d2 x2 + F2

1
3
3
+ L24 y2 + B213
x1 y1 + (B242
+ B224
)x2 y2 dt

1
2
dy1 = µ − L13 x1 + B312
x1 x2 + B311
x21 + F3 − γε1 y1 dt +

3
σ2
dy2 = µ − L24 x2 + B422
x2 x2 + F4 − γε2 y2 dt + √
dW2
ε

σ1
√
dW1
ε

When the parameter ε is set to a small value, a separation of timescales is created between
the variables x1 , x2 (slow) and y1 , y2 (fast). The main interest is in the behavior of the slow
variables x1 , x2 .
The parameters we use match those used in Franzke (2012). This means that we set µ = 1, the
1
1
1
2
2
2
B-coefficients are given by B123
= 4, B213
= 4, B312
= −8, B131
= 0.25, B113
= 0.25, B311
=
3
3
3
−0.5, B242 = −0.3, B224 = −0.4, B422 = 0.7, the L-coefficients by L13 = −L24 = −0.2, and
20

0.06

4
0.05

3
2

0.04

1
0.03

0
-1

0.02

-2
0.01

-3
0

-2

0

2

4

6

8

10

12

Figure 5: Contour plot of the marginal stationary density of slow variates (x1 , x2 ) of the
model of Franzke (2012).
the other parameters by ω = 1, a1 = 1, a2 = −1, d1 = −0.2, d2 = −0.1, γ1 = γ2 = 1, σ1 = 3,
σ2 = 1. In addition we put L12 = −L21 = 1, ε = 0.2. The forcing vector (F1 , F2 , F3 , F4 ) is
given by (−0.25, 0, 0, 0).
Since this process is non-standard, in order to build intuition, we first generated a contour
plot of the estimated stationary density of (x1 , x2 ); see Fig. 5. The process turns out to
randomly switch between two modes: one mode with x1 ≤ x2 and a second mode with
x1 ≥ x2 . The estimated density function in Fig. 5 shows that the process is more likely to
be in the second mode.
We use the explicit Euler scheme with h0 = 10−4 but we store the values of the process every
h = 0.01. The small integration time step h0 is needed for numerical stability. Similar to
the previous examples, the rare event we study is the exceedance of a high threshold by x1
under the stationary distribution, cf. (5.2). We choose the recurrency set A(`) as in (5.3)
with `∗ = 7.9 suggested by the algorithm (4.4). The importance function H(·) is as in (5.4).
The results of the RMS method are outstanding, see Tab. 4. For u = 18.5, when γ(u) ≈ 10−7 ,
we find Eff(b
γ )≈ 1522. In other words, the RMS algorithm is more than 1500 times faster
than MC. The values of RE(TbB ) match the desired 5 · 10−3 (see (5.5)) very closely even for
very high thresholds, indicating that Assumptions (I-II) are satisfied. A random realization
of a cycle reaching the rare event, shown in Fig. 6, is yet another indication that the distancebased importance function is a good choice, as the path seems to gradually drift towards the
rare event.
Conclusions. This example shows a successful application of the RMS algorithm to a multidimensional nonlinear stochastic-dynamical model with characteristics of complex climate
models. We find that RMS is up to three orders of magnitude faster than MC in this example,
and the efficiency gain is expected to be even larger for higher thresholds u.

6

Summary

In this manuscript we have proposed a new algorithm for the estimation of small steady-state
probabilities γ = µ(B), as in (1.1), of Markov processes with continuous state space. Our
approach, which we have called the Recurrent Multilevel Splitting (RMS) algorithm, is based
21

3

2

1

x2

0

-1

-2

-3

-4
8

10

12

14

16

18

x1

Figure 6: The model of Franzke (2012). A random realization of a recurrency cycle conditioned on reaching the rare set. The cycle has been plotted until the first hitting time of B.
Parameters: A = {x1 ≤ 7.9}, B = {x1 ≥ 17.5}, γ(17.5) ≈ 1.14 · 10−6 .
on the alternative representation (2.5) of γ (as given in Theorem 1). This representation is
obtained by dissecting the path of the Markov process into recurrency cycles, each cycle beginning with an inwards crossing of a set A. It allows to transform the problem of estimating
γ essentially into the problem of estimating TB , the expected time spent in the set B in a
recurrency cycle.
In order to efficiently estimate TB we use Multilevel Splitting (MLS), but we emphasize that
other rare event simulation methods could have been used instead (such as Genealogical
Particle Analysis or Importance Sampling). We have derived optimal parameters for the
MLS in Appendix B, and we have shown (Theorem 3) that under simplifying assumptions,
a suitable choice of the recurrency set A in combination with the optimal choice of the
parameters leads to logarithmic efficiency of the RMS algorithm.

u

14

15

16

17.5

18.5

γ
b

1.08 · 10−3

1.99 · 10−4

3.00 · 10−5

1.14 · 10−6

9.78 · 10−8

RE(b
γ)

6.1e-03

7.2e-03

7.4e-03

7.4e-03

5.8e-03

γ
bMC

1.08 · 10−3

2.00 · 10−4

2.98 · 10−5

1.12 · 10−6

8.85 · 10−8

RE(b
γ MC )

1.4e-03

2.9e-03

6.5e-03

2.7e-02

8.5e-02

Eff(b
γ)

1.9

8.6

32.1

269.9

1521.8

RE(TbB )

5.1e-03

6.4e-03

7.2e-03

6.6e-03

5.4e-03

Table 4: RMS algorithm applied to the model of Franzke (2012). Parameters: A = {x1 ≤
7.9}, B = {x1 > u}. We have α
bA = 0.0124, RE(b
αA ) = 2.83 · 10−3 .

22

In Section 5, four numerical studies were presented, where we used the RMS algorithm to
estimate steady state probabilities of high threshold exceedances for various SDEs discretized
in time. The experiments demonstrate that RMS gives accurate results. Furthermore, they
unanimously show the efficiency gain of RMS compared to Monte Carlo; in the most notable
case of the Franzke (2012) model (Section 5.3), RMS outperforms MC by up to three orders
of magnitude.
One of the numerical experiments (Section 5.2.3) was designed to give suboptimal results,
with an SDE displaying rotating motion so that the most straightforward choices of the
recurrency set and importance function (as used in the experiments) were expected to be
not very suitable. Although the estimates obtained with RMS were still quite accurate, the
efficiency gain of RMS compared to MC was decreasing as the rotation speed was increasing.
This example showed how the choice of the recurrency set and the importance function can
impact the performance of the algorithm.
In light of this example, an interesting topic for future research is the choice of the recurrency
set A. As already mentioned in Section 4.2, a good choice of A should be a suitable compromise between visiting A relatively often and (4.3) being (approximately) met. We have
proposed a method of optimizing A(`) parametrized by ` in (4.4), and pointed out a method
of testing whether A satisfies (4.3) through a quantile validation (4.5). Further development
of these ideas to construct an optimal A is a challenging open research topic.

Acknowledgments
We thank the organizers of the Summer School in Monte Carlo for Rare Events (June 2016
at Brown University) for making lecture notes available. This work is part of the research
programme ‘Mathematics of Planet Earth’ which was funded by the Netherlands Organisation
for Scientific Research (NWO), grant number 657.014.003. Michel Mandjes’ research is partly
funded by the NWO Gravitation Programme NETWORKS, grant number 024.002.003.

A

Technical Results

Proof of Theorem 1. Define a new Markov chain Zn := (Xn−1 , Xn ); it is also positive Harris
with a stationary measure µ
e satisfying, for measurable sets C0 , C1 ,
µ
e(C0 , C1 ) = P(X0 ∈ C0 , X1 ∈ C1 | X0 ∼ µ).
We see that the stopping times Sn coincide with the times the process Zn visits a set A :=
(Ac , A), with Ac := Rd \ A. Since µ(A) ∈ (0, 1) we have
αA = Pµ (X0 ∈ A, X1 ∈ Ac ) > 0.
According to Meyn and Tweedie (2012, Thm. 10.4.9) we have, with τA := inf{n > 0 : Zn ∈
A},
Z
τX
A −1
µ
e(Rd , B) =
µ
e(dx, dy) Ex
1{Zn ∈ (Rd , B)}.
A

d

n=0

d

Due to µ
e(R , B) = µ(B), {Zn ∈ (R , B)} = {Xn ∈ B}, and µ
e(A) = αA , it follows that
 τX

A −1
µ(B) = αA · E
1{Xn ∈ B} | Z0 ∼ µ
e, Z0 ∈ A .
n=0

23

Finally, we recognize that the conditioning above is equivalent to X0 being distributed as an
initial point of a recurrency cycle X1A in stationarity, so that we conclude (2.5). Similarly,
one can show that αA = (Eµ L1 )−1 by considering the expected time spent in (Rd , Rd ) within
a recurrency cycle.
Derivation of (4.1). Notice that (I) implies that the number of times the k-th threshold rk is
hit, is distributed as a sum of nk−1 rm−1 independent Bernoulli trials, each with probability
of success pk :
 d
rk | rk−1 = Bin(nk−1 rk−1 , pk );
(A.1)
here Bin(n, p) denotes a Binomial distribution with n trials with success probability p, with
the convention that Bin(0, p) ≡ 0. Similarly, (II) implies that the total time spent in the rare
set is distributed as a sum of nm rm independent copies from the distribution R+ :
m rm
 d nX
(k)
rm+1 | rm =
R+ ,

(A.2)

k=1
(1)

(2)

where R+ , R+ , . . . are i.i.d. copies of R+ (with the empty sum being defined as 0). Using
(A.1) and the law of total variance we obtain, for k ∈ {1, . . . m},
Var(rk ) = E(Var(rk |rk−1 )) + Var(E(rk |rk−1 ))
= E(nk−1 rk−1 pk (1 − pk )) + Var(nk−1 rk−1 pk )
= nk−1 pk (1 − pk )E(rk−1 ) + n2k−1 p2k Var(rk−1 ).
Similarly, using (A.2) we obtain
Var(rm+1 ) = nm E(rm )Var(R+ ) + n2m (ER+ )2 Var(rm ).
Combining these results with (3.10) yields (4.1).

B

Derivation of Optimal Parameters

Following Amrein and Künsch (2011), we assume that the computational effort wk in the
k-th stage of Algorithm 1 (to sample a path starting from Xτk until min{τk+1 , τAin }) does not
depend on the entry state Xτk . Simplifying this further, we assume that wk does not depend
on k, so without loss of generality,
wk ≡ 1, k ∈ {0, . . . , m}.

(B.1)

A more general cost wk can be considered for particular problems, see e.g. Lagnoux (2006).
Let Nk := nk rk , for k ∈ {0, . . . , m}, be the number of paths simulated in the k-th stage of
the algorithm, with r0 := 1. Then the average total workload equals
W :=

m
X

ENk ,

k=0

and since Erk = p1 · · · pk , cf. (3.10), we conclude
ENk =

k
Y
j=0

24

nj pj .

Finally, we formulate the minimization problem
minimize

W :=

with respect to:

Pm Qk
k=0

j=0

nj pj

m, p1 , . . . , pm , n0 , . . . , nm


RE2 (TbB ) ≤ ρ,



Qm



 k=1 pk = pB ,

subject to:

m ∈ N,




pk ∈ (0, 1), k ∈ {1, . . . , m},



n ∈ N, k ∈ {0, . . . , m}.
k

In our simplified setting, i.e., under Assumptions (I-II), we have derived a formula for the
corresponding squared relative error in (4.1). We are able to solve the optimization problem
above under the additional relaxation that the nk and m are real and positive. To this end,
it is helpful to denote
ck :=

Qk−1

k ∈ {1, . . . , m + 1},

j=0 nj pj ,

ak := (1 − pk )/pk , k ∈ {1, . . . m},
am+1 := RE2 (R+ ).
Then we can write
W =

m+1
X

ck

and

RE2 (TbB ) =

k=1

m+1
X
k=1

ak
.
ck

We want to minimize the workload W under the constraint that
RE2 (TbB ) ≤ ρ.
We do this in steps. First, we fix m and the conditional probabilities p1 , . . . , pm , so that
a1 , . . . , am are fixed (recall that am+1 is not a parameter of the algorithm). We relax the
problem and let the splitting factors nk be allowed to attain any real, positive value. This
means that we wish to solve (over c1 , . . . , cm+1 > 0)
minimize
subject to:

Pm+1
W (c1 , . . . , cm+1 ) := k=1 ck
(
Pm+1
g(c1 , . . . , cm+1 ) := k=1 ackk ≤ ρ,
ck > 0, k ∈ {1, . . . , m + 1}.

The corresponding Karush–Kuhn–Tucker conditions are


∇W + µ∇g = 0,

µ(g − ρ) = 0,


µ ∈ [0, ∞).

with the gradient ‘∇’ taken with respect to vector (c1 , . . . , cm+1 ). These are solved by
ck :=

m+1
1√ X √
ak
aj ,
ρ
j=1

25

with the optimal workload
1
W =
ρ

 m+1
X

√

2
aj

.

j=1

In the next step, we keep m fixed and minimize over a1 , . . . , am . Notice that 1 + ak = 1/pk ,
so that our minimization problem takes the form
Pm+1 √ 2
minimize: W (a1 , . . . , am ) := ρ1
ak
k=1
(
Qm
h(a1 , . . . , am ) := k=1 (1 + ak ) = p−1
B ,
subject to:
ak > 0, k ∈ {1, . . . , m}.
Not surprisingly, this system is solved by
−1/m

a1 = . . . = am = pB

− 1,

so that the optimal intermediate probabilities coincide:
1/m

pk = pB , k ∈ {1, . . . , m},
with the optimal workload being
W (m) =

1
ρ

 q
2
√
−1/m
− 1 + am+1 .
m pB

The final step is finding the optimal number of thresholds m. We see that the minimizer of
W (m) is also a minimizer of
p
m exp(− log(pB )/m) − 1.
Again, we relax this problem, allowing m to be any real, positive number. Finally, the
optimal parameters are:
m = c | log pB |
2c − 1
≈ 0.2032, k ∈ {1, . . . , m},
pk = popt :=
2c

1
c | log pB |
n0 = √
· √
+ RE(R+ ) ,
ρ 2c − 1
2c − 1

(B.2)

nk = 1/pk+1 = 1/popt , k ∈ {1, . . . , m − 1},
2c
nm = RE(R+ ) · √
.
2c − 1
with c ≈ 0.6275 solving exp(1/c) = 2c/(2c − 1) and the optimal workload reads as in (4.2).
Since m, nk must be integers, we propose to simply round the optimal parameters to the
closest integer. A similar result (but without the last splitting stage, in which we estimate
the time spent in the set B) has been presented in (Lagnoux, 2006, Example 3.2.).

C

Logarithmic Efficiency of the RMS Algorithm

In this section we study the efficiency of the RMS method, in the asymptotic regime that
the rare event probability (1.1) tends to 0 (i.e. γ → 0). First, we notice that if we fix the
recurrency set A, then αA does not change as γ → 0; hence we only have that TB → 0.
26

This indicates that asymptotic efficiency properties of RMS will be closely related to those
of MLS. In order to study the performance of the estimator, we first introduce the concepts
of strong and logarithmic efficiency.
b ` be a family of unbiased estimators for Ψ` > 0, parametrized by ` such that Ψ` → 0,
Let Ψ
b ` ) denote the computation time corresponding to Ψ
b ` . The estimator Ψ`
as ` → ∞. Let W (Ψ
is called strongly efficient if
lim sup
`→∞

b ` ) · Var(Ψ
b `)
W (Ψ
< ∞;
2
Ψ`

(C.1)

and logarithmically efficient if
b ` ) · Var(Ψ
b `)
W (Ψ
= 0, for all ε > 0.
2−ε
`→∞
Ψ`
lim

(C.2)

Strong efficiency implies that the workload needed to estimate the quantity of interest Φ`
with a desired accuracy RE2 (Ψ` ) ≤ ρ is uniformly bounded as ` → ∞. Logarithmic efficiency
implies that workload needed to achieve the accuracy RE2 (Ψ` ) = ρ is increasing slower than
Ψ−ε
for any ε > 0, as ` → ∞. Evidently, strong efficiency implies logarithmic efficiency.
`
Before we prove the logarithmic efficiency of RMS in Theorem 3 we show an inefficiency
result for the Monte Carlo estimator for TB . Let TbBMC be a sample mean of N independent
copies of R1 . We then have
1 − pB + RE2 (R+ )
.
RE2 (TbBMC ) =
pB N

(C.3)

Now to achieve a desired level of accuracy RE2 (TbBMC ) ≤ ρ, assuming (B.1), the total required
workload is
1 1 − pB + RE2 (R+ )
W (TbBMC ) := ·
.
(C.4)
q
pB
As already noted in Section 4.1, W (TbBMC ) is inversely proportional to pB and so it follows
that the Monte Carlo estimator is not logarithmically efficient.
We have seen, cf. (4.2), that the workload of the MLS estimator with the optimal parameters
W (TbB ) is proportional to (log(pB ))2 . It turns out that under mild additional assumption,
the MLS algorithm is logarithmically efficient and thus so is RMS. We make this rigorous in
the following theorem.
Theorem 3 (Logarithmic Efficiency of RMS). Fix the recurrency set A and let the set B`
be parametrized by `, such that γ` := µ(B` ) → 0 as ` → ∞. Assume
◦ that the estimators α
bA and TbB` are independent;
◦ that Assumptions (I-II) are valid for each `;
◦ that the workload satisfies (B.1);
◦ and that, for δ > 0 sufficiently small,
lim sup
`→∞

Var(R+ )
< ∞,
(ER+ )2

lim TB` · p−δ
B` = 0.

`→∞

(C.5)

Then the RMS estimator γ
b` for γ` , with the optimal choice of the parameters (B.2), is
logarithmically efficient.
27

We point out that the first part of the assumption (C.5) is equivalent to strong efficiency
of the crude Monte Carlo estimator for R+ , under the workload assumption (B.1). This is
not too restrictive, as often the main difficulty when estimating TB lies in the fact that pB
is extremely small (and does not relate to the large variance of R+ .) Since γ` → 0 and A
is fixed then necessarily TB` → 0. In the second part of (C.5) we require that there exists
a δ > 0 such that ER+ p1−δ
B` → 0. Loosely speaking, it means that pB` converges to 0 at
least polynomially faster than ER+ grows to infinity; this is trivially satisfied when ER+ is
bounded.
Proof of Theorem 3. Since the recurrency set A is fixed, the quantities α
bA , RE(b
αA ) and
W (b
αA ) do not depend on `. In addition, αA · TB` = µ(B` ) → 0 is equivalent to TB` → 0.
Moreover, since TB` = pB` · ER+ , cf. (3.6), and ER+ ≥ 1, we necessarily have pB` → 0, as `
grows. Observe that
W (b
γ` )Var(b
γ` )
W (b
αA ) + W (TbB` ) Var(b
αA · TbB` )
=
·
−ε
2−ε
2
αA · TB2 `
γ`
γ`


= γ`ε W (b
αA ) + W (TbB ) · RE(b
αA ) + RE(TbB )
`

`

(C.6)

We put RE(TbB` ) = q. Then the workload W (TbB` ) is given as in (4.2), and we see that
ε ε
γ`ε W (TbB` ) = αA
TB` ·

∼


2
1 c | log pB` |
√
+ RE(R+ )
q
2c − 1

ε
ε
(TB` p−δ
c2 αA
B` )
2
· pδε
B` (log pB` ) ,
q(2c − 1)

where δ > 0 is as in (C.5). Now since pB` → 0, we also have
2
pδε
B` (log pB` ) → 0,

and γ`ε W (TbB` ) → 0, which applied to (C.6) finishes the proof.

References
M. Amrein and H. R. Künsch. A variant of importance splitting for rare event estimation:
Fixed number of successes. ACM Transactions on Modeling and Computer Simulation
(TOMACS), 21(2):13, 2011.
S. Asmussen. Applied Probability and Queues, volume 51. Springer Science & Business Media,
2008.
S. Asmussen and P. W. Glynn. Stochastic Simulation: Algorithms and Analysis, volume 57.
Springer Science & Business Media, 2007.
K. Bisewski, D. Crommelin, and M. Mandjes. Simulation-based assessment of the stationary
tail distribution of a stochastic differential equation. In Proceedings of the 2018 Winter
Simulation Conference, pages 1742–1753, 2018.
J. M. Calvin, P. W. Glynn, and M. K. Nakayama. The semi-regenerative method of simulation
output analysis. ACM Transactions on Modeling and Computer Simulation (TOMACS),
16(3):280–315, 2006.
28

F. Cérou and A. Guyader. Adaptive multilevel splitting for rare event analysis. Stochastic
Analysis and Applications, 25(2):417–443, 2007.
S. Coles, J. Bawa, L. Trenner, and P. Dorazio. An Introduction to Statistical Modeling of
Extreme Values, volume 208. Springer, 2001.
M. A. Crane and D. L. Iglehart. Simulating stable stochastic systems: III. Regenerative
processes and discrete-event simulations. Operations Research, 23(1):33–45, 1975.
T. Dean and P. Dupuis. Splitting for rare event simulation: A large deviation approach to
design and analysis. Stochastic Processes and their Applications, 119(2):562–587, 2009.
P. Del Moral and J. Garnier. Genealogical particle analysis of rare events. The Annals of
Applied Probability, 15(4):2496–2534, 2005.
C. Franzke. Predictability of extreme events in a nonlinear stochastic-dynamical model.
Physical Review E, 85(3):031134, 2012.
M. J. J. Garvels. The Splitting Method in Rare Event Estimation. PhD thesis, University
of Twente, Twente, Netherlands, 2000. Available via http://doc.utwente.nl/29637/1/
t0000013.pdf.
A. Goyal, P. Shahabuddin, P. Heidelberger, V. F. Nicola, and P. W. Glynn. A unified framework for simulating Markovian models of highly dependable systems. IEEE Transactions
on Computers, 41(1):36–51, 1992.
F. Gunther and R. Wolff. The almost regenerative method for stochastic system simulations.
Operations Research, 28(2):375–386, 1980.
P. Heidelberger. Fast simulation of rare events in queueing and reliability models. ACM
Transactions on Modeling and Computer Simulation (TOMACS), 5(1):43–85, 1995.
S. G. Henderson and P. W. Glynn. Can the regenerative method be applied to discrete-event
simulation? In Proceedings of the 31st Winter Simulation Conference, pages 367–373,
1999.
S. G. Henderson and P. W. Glynn. Regenerative steady-state simulation of discrete-event
systems. ACM Transactions on Modeling and Computer Simulation (TOMACS), 11(4):
313–345, 2001.
V. V. Kalashnikov. Topics on Regenerative Processes. CRC Press, 1994.
P. E. Kloeden and E. Platen.
Springer, 1992.

Numerical Solution of Stochastic Differential Equations.

D. P. Kroese, T. Taimre, and Z. I. Botev. Handbook of Monte Carlo methods, volume 706.
John Wiley & Sons, 2013.
A. Lagnoux. Rare event simulation. Probability in the Engineering and Informational Sciences, 20(1):45–66, 2006.
S. P. Meyn and R. L. Tweedie. Markov Chains and Stochastic Stability. Springer, 2012.
F. Ragone, J. Wouters, and F. Bouchet. Computation of extreme heat waves in climate
models using a large deviation algorithm. Proceedings of the National Academy of Sciences,
115(1):24–29, 2018.
29

G. Rubino and B. Tuffin. Rare Event Simulation using Monte Carlo Methods. John Wiley
& Sons, 2009.
H. Schurz. The invariance of asymptotic laws of stochastic systems under discretization.
ZAMM-Zeitschrift fur Angewandte Mathematik und Mechanik, 79(6):375–382, 1999.
M. Villén-Altamirano and J. Villén-Altamirano. The rare event simulation method restart:
efficiency analysis and guidelines for its application. In Network performance engineering,
pages 509–547. Springer, 2011.
W. Wadman, D. Crommelin, and J. Frank. A separated splitting technique for disconnected
rare event sets. In Proceedings of the 46th Winter Simulation Conference, pages 522–532,
2014.

30

