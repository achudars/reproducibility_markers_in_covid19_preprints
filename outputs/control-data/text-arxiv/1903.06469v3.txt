Using Data Science to Understand the Film
Industry’s Gender Gap

arXiv:1903.06469v3 [cs.SI] 6 Aug 2019

Dima Kagan∗1 , Thomas Chesney†2 , and Michael Fire‡1
1

Department of Software and Information Systems Engineering,
Ben-Gurion University of the Negev
2
Nottingham University Business School
August 7, 2019

Abstract
Data science can offer answers to a wide range of social science questions. Here we turn attention to the portrayal of women in movies, an
industry that has a significant influence on society, impacting such aspects
of life as self-esteem and career choice. To this end, we fused data from
the online movie database IMDb with a dataset of movie dialogue subtitles to create the largest available corpus of movie social networks (15,540
networks). Analyzing this data, we investigated gender bias in on-screen
female characters over the past century.
We find a trend of improvement in all aspects of women‘s roles in
movies, including a constant rise in the centrality of female characters.
There has also been an increase in the number of movies that pass the
well-known Bechdel test, a popular—albeit flawed—measure of women in
fiction. Here we propose a new and better alternative to this test for
evaluating female roles in movies. Our study introduces fresh data, an
open-code framework, and novel techniques that present new opportunities in the research and analysis of movies.

Keywords: Data Science, Network Science, Gender Gap, Social Networks

1

Introduction

∗ kagandi@post.bgu.ac.il
† thomas.chesney@nottingham.ac.uk
‡ mickyfi@post.bgu.ac.il

1

2

The film industry is one of the strongest branches of the media, reaching
billions of viewers worldwide [13, 19]. Now more than ever, the media has a
major influence on our daily lives [45], significantly influencing how we think
[30], what we wear [49], and our self-image [43]. In particular, the representation
of women in media has an enormous influence on society. As just one example,
a new study shows that “women who regularly watch The X-Files are more
likely to express interest in STEM, major in a STEM field in college, and work
in a STEM profession than other women in the sample” [18].
Movies are the fulfillment of the vision of the movie director, who controls
all aspects of the filming. It is well known that movie directors are primarily
white and male [9]. With such a gender bias, it is not surprising that there is a
male gender dominance in movies [7]. Studies from the past two decades have
confirmed that women in the film industry are both underrepresented [23, 37]
and portrayed stereotypically [50]. A recent study found that the underrepresentation is so sizeable that there are twice as many male speaking characters
as female in the average movie [1].
While the gender gap in the film industry is a well-known issue [1, 11, 22,
37, 50], there is still much value in researching this topic. Most previous gender
studies can be categorized into two types: the first type offers simple statistics
from the data to emphasize the gender gap [37]; and the second type introduces
more advanced analytical methods, yet generally uses only a small amount of
data [25, 32].
In this study, we present Subs2Network, a novel algorithm to construct
a movie character’s social network. We demonstrate possible utilizations of
Subs2Network by employing the latest data science tools to comprehensively
analyze gender in movies (see Figure 11 ). This is the largest study to date that
uses social network analysis (SNA) to investigate the gender gap problem in the
film industry and how it evolved.
The study’s primary goals are to answer the following four questions:
Question 1: Are there movie genres that do not exhibit a gender gap?
Question 2: What do characters’ relationships reveal about gender, and how
has this changed over time?
Question 3: Are women receiving more central movie roles today than in the
past?
Question 4: How has the fairness of female representation in movies changed
over the years?
To answer these questions, we first analyzed movie subtitles using textprocessing algorithms and a list of movie characters’ names (see Figure 2). We
then developed Subs2Network to construct a movie character’s social network.
We created an open-source code framework to collect and analyze movie data,
1 The

Star Wars icons were created by Filipe de Carvalho and are licensed under CC BY-NC

4.0

3

and we used this framework to construct the largest existing open movie social
network dataset that exists today.
Using the constructed movie social networks, we extracted dozens of topological features that characterized each movie. By analyzing these features, we
could observe the gender gap across movie genres and over the last 99 years.
Moreover, by utilizing the dataset, we developed a machine-learning classifier,
which is able to assess, with precision at 200 of 0.94, how fairly women are
represented in movies (i.e., if a movie passes the Bechdel test [26]).
Our results demonstrate that in most movie genres there is a statistically
significant difference between men and women in centrality features like betweenness and closeness. These differences indicate that men are getting more central
roles in movies than women (see Figures 2a and 2b, and Section 4). Another
sign of the underrepresentation of women in movies is found by analyzing interactions among three characters: only 3.57% of the interactions are among three
women, while 40.74% are among three men. These results strengthen previous
studies‘ results that women play fewer central roles [25, 37], and indicates that
on average women have more minor roles. Our results highlight how and where
gender bias manifests in the film industry and provides an automatic way to
evaluate it over time.
The key contributions presented in this paper are fivefold:
• A novel algorithm (see Section 3) which utilizes movie subtitles and character lists to automatically construct a movie’s social network (see Section 3.1 and Figure 2).
• The largest open movie social network dataset, 21 times larger than the
previous dataset [35] (see Section 3.2). Our dataset contains 15,540 dynamic networks of movies (937 of these networks are networks of biographic movies, which have information about real world events).
• An open-source framework for movie analysis. The code contains a framework to generate additional social networks of movies, facilitating research
by creating and analyzing larger amounts of data than ever before.
• A machine-learning classifier that can predict if a movie passes the Bechdel
test (see Section 3.4.3) and can evaluate the change in gender bias in
thousands of movies over several decades (see Section 4).
• Our new and alternative automated Bechdel test to measure female representation in movies. This new test overcomes the weaknesses of the
original Bechdel test.
Our study demonstrates that inequality is still widespread in the film industry. In movies of 2018, a median of 30% women and a mean of 33% were found
in each movie’s top-10 most central roles. That being said, there is evidence
that the gender gap is improving (see Figure 6).
The remainder of this paper is organized as follows: In Section 2, we present
an overview of relevant studies. In Section 3, we describe the datasets, methods, algorithms, and experiments used throughout this study. In Section 4, we
4

present our results. Then, in Section 5, we discuss the obtained results. Lastly,
in Section 6, we present our conclusions from this study and offer future research
directions.

2
2.1

Related Work
Movie Social Networks

In the past decade, the study of social networks has gained massive popularity. Researchers have discovered that social network analysis techniques can be
used in many domains that do not have explicit data with a network structure.
One such domain is the film industry. Researchers have applied social network
analysis to analyze movies, gaining not only new insights about specific movies
but also about the film industry in general. For example, using social networks
makes it possible to empirically analyze social ties between movie characters.
In 2009, Weng et al. [48] presented RoleNet, a method to convert a movie
into a social network. The RoleNet algorithm builds a network by connecting
links between characters that appear in the same scene. RoleNet is based on
using image processing for scene detection and face recognition to find character
appearances. Weng et al. evaluated their method on 10 movies and 3 TV shows.
The method was used to perform semantic analysis of movies, find communities,
detect leading roles, and determinine story segmentation.
In 2012, Park et al. [42] developed Character-net, another method to convert
movies to networks. Character-net builds the social network based on dialog
between characters, using script-subtitle alignment to extract who speaks to
whom in the scene. Park et al. evaluated their method on 13 movies [42].
Similar to RoleNet, Character-net was used to detect leading roles and to cluster
communities.
In 2014, Agrawal et al. [24] presented a method for parsing screenplays by
utilizing machine-learning algorithms instead of using regular expressions. Their
study showed that the parsed screenplay can be used to create a social network of
character interactions. In 2015, Tran and Jung [46] developed the CoCharNet,
a method which adds weight to a link in the interaction network, where the
weight is a function of the number of times two characters appear together.
Tran and Jung used CoCharNet to evaluate the importance of characters in
movies. They demonstrated that network centrality features such as closeness
centrality, betweenness centrality, and weighted degree can be used to classify
minor and main characters in a movie. For instance, they detected the main
characters using closeness centrality with a precision of 74.16%.
In 2018, Lv et al. [39] developed an algorithm to improve the accuracy of
creating social networks of movies. They presented StoryRoleNet, which combines video and subtitle analysis to build a more accurate movie social network.
The subtitles were used to add additional links that the video analysis might
miss. Similar to RoleNet and Character-net, Lv et al. used the movie social
networks to cluster communities and to detect important roles. They evalu-

5

ated the StoryRoleNet method on 3 movies and one TV series, for which they
manually created baseline networks [39].
Also in 2018, a dataset from Moviegalaxies [35]2 was released. Moviegalaxies
is a website that displays social networks of movie characters. The dataset
contains 773 movie social networks that were constructed based on movie scripts.
However, Moviegalaxies did not disclose the exact methods which were used for
the construction of the networks.

2.2

Evaluating the Gender Gap

In recent years, there have been many studies that attempt to evaluate the
gender gap between males and females across various domains [34, 36, 37, 47].
For example, in 2018 the World Bank evaluated that the costs of gender bias
are vast; gender inequality results in an estimated $160.2 trillion loss in human
capital wealth [20].
Over the years, researchers have discovered many manifestations of the gender gap in our society. Lariviere et al. [36] discovered that scientific articles with
women in dominant author positions receive fewer citations. Wagner et al. [47]
observed that men and women are covered equally on Wikipedia, but they also
discovered that women on Wikipedia are portrayed differently from men. Jia et
al. [34] found that in online newspapers, women are underrepresented both in
text and images.
The state of women in the film industry is similar to other domains: women
are underrepresented and badly portrayed [37, 50]. The Boxed In 2017-18 report [37] observed a 2% decline in female major characters across all platforms,
compared to the previous year.
To tackle the underrepresentation of women in movies in 1985, the cartoonist
Alison Bechdel published a test in her comic strip Dykes to Watch Out For to
assess how fairly women are presented in filmed media. The Bechdel-Wallace
test [26] (denoted as the Bechdel test) has three rules that a movie has to pass
to be considered “women friendly”:
1. It has to have at least two women in it.
2. The women have to talk to each other.
3. The women must talk about something besides a man.
Only 57% of current movies pass this test. To Bechdel’s surprise, the media adopted her joke, and today it is a standard for female representation in
movies [3, 4, 6, 10, 12].
The Bechdel test is also used by researchers. In recent years, studies have
utilized the test to evaluate gender bias in movies. In 2014, Garcia et al. [32]
quantified the Bechdel test and also applied it to social media. They joined
YouTube trailers, movie scripts, and Twitter data, which resulted in 704 trailers for 493 movies and 2,970 Twitter shares. Garcia et al. created a social
2 http://www.moviegalaxies.com

6

network of dialogues for these movies. Additionally, they constructed a network
of dialogues between Twitter users who discussed the trailers. They mapped
dialogues between men who were referring to women and between women who
were referring to men. This mapping was used to calculate the Bechdel score.
They found that trailers of movies which are male biased are more popular.
Also, they discovered that Twitter dialogues have a similar bias to movie dialogues [32].
In 2015, Agarwal et al. [25] studied the differences between movies that
pass and fail the Bechdel test. Similar to Garcia et al., Agarwal et al. also
constructed social networks using screenplays. They created a classifier to automate the Bechdel test, which was trained on 367 movies and evaluated on 90.
In the evaluation, they discovered that network-based features perform better
than linguistic features. Additionally, they discovered that movies that fail the
Bechdel test tend to have women in less central roles [25]. With this being said,
the Bechdel test has several major flaws. The test does not take into account
if women are represented stereotypically [21]. Additionally, there are movies
that are considered feminist but do not pass the test [2]. Moreover, the test is
considered to be a low threshold since a film can pass the test with a single line
of dialogue between two women [10].

2.3

Graph Features and Named Entity Recognition

Data science tools and techniques have evolved rapidly in the past couple of
years [29]. In this study, we primarily utilized data science algorithms from the
domains of Natural Language Processing (NLP) and Social Network Analysis
to computationally analyze movie content, movie social network structure, and
how movie features change over time.
Namely, we used NLP to extract character names from the movie subtitles
by utilizing Named Entity Extraction (NER) algorithms [41]. We used both
Stanford Named Entity Recognizer [31] and spaCy Python Package [33] to find
where characters appear in the text.
To match characters’ names in the subtitles with characters’ full names, we
utilized FuzzyWuzzy [16], a Python package for fuzzy string matching. Specifically, we used FuzzyWuzzy’s WRatio [8], a method for measuring the similarity between strings. WRatio uses several different preprocessing methods that
rebuild the strings and compare them using Levenshtein distance [38]. Also,
WRatio takes into account the ratio between the string lengths.
After extracting the movie characters, we constructed the movie social networks and used various graph centrality algorithms, such as closeness, betweenness, degree centrality, and PageRank [27] to identify the most central characters
in each constructed movie network.

7

3

Methods and Experiments

3.1

Constructing Movie Social Networks

One of this study’s primary goals was to develop a straightforward algorithm
that would construct the social network of character interaction within a given
movie. We achieved this goal by utilizing movie subtitles3 and a list of movie
character names. Namely, given a movie, we constructed the movie social network G :=< V, E >, where V is the network’s vertices set, and E is the set
of links among the network’s vertices. Each vertex v ∈ V is defined to be a
character in the movie. Each link e := (u, v, w) ∈ E is defined as the interaction
between two movie characters u and v, w times.

(a) NER

(b) Character list

(c) Graph update

Figure 2: Turning subtitles into a network, step by step: (a) perform named entity recognition on the subtitles; (b) match the entities to the movie characters;
and (c) link the characters and increase the edge weight by one.
For a movie with a given subtitle text and a given character list, we constructed the movie’s social network using the following steps (see Figure 2):
1. First, we detected when each character appeared in the subtitles. To
extract the characters from the subtitles we used NER, extracting all the
entities which were labeled as a person or an organization. Additionally,
for each entity, we stored the time the entity appeared in the movie.
2. Next, we matched the entities found in the subtitles with the character
list. It worth mentioning that it is not possible to map one-to-one between the characters in the character list and the characters extracted
from the subtitle. For example, in the movie The Dark Knight, Bruce
Wayne was referred to as “Bruce Wayne” 3 times, as “Bruce” 16 times,
and as “Wayne” 20 times.
3. To address the matching problem, we proposed the following mapping
heuristic (see Algorithm 1). First, we split all the roles into first and last
names and linked them to the actor and the character’s full name (line
2). Then, if there was only one character with a certain first or last name
3 Many of the used movies’ subtitles were created by crowd-sourcing, i.e., by people who
volunteered to create the subtitle.

8

(one-to-one match), we linked to the character all its occurrences in the
subtitles (lines 3-5). However, if we had several characters with the same
first or last name, we did not always know who was referred to in the text.
For example, in the movie Back to The Future there are three characters
with the last name McFly; where only ”McFly” was mentioned in the
text, we could not determine which character was referenced. Another
challenge we encountered was when only part of the character’s name
was used. For instance, in the movie The Godfather, the main character
is Don Vito Corleone, but he was never mentioned once by his full name
because he usually was referred to as ”Don Corleone.” Moreover, there are
other Corleone family members in the movie. To overcome this challenge,
we used WRatio to compare strings and match parts of a name to the
full name. Using WRatio, we chose the highest matching character that
received a score higher than T hreshold (line 6).
Algorithm 1: Matching entities in the movie subtitles with the characters.
Data: PersonName,Roles,Threshold
Result: Matched character
1 N ames ← P ersonN ame.split();
2 foreach Ni ∈ N ames do
3
if Roles[Ni ].length = 1 then
4
return Roles[Ni ];
5
end
6
return M axW Ratio(P ersonN ame, Roles[Ni ], T hreshold)
7 end
4. In fact, we were able to overcome many of these problems by using hearingimpaired subtitles. In many hearing-impaired subtitles, the name of the
speaking character is part of the text. This property allowed us to avoid
most the problems we described earlier and gain additional information.
For instance, the movie The Matrix has a scene in which Morpheus calls
Neo, and we can know this only because of the tag [PHONE RINGS].
Afterward, there is an annotation ”MORPHEUS:” which tells us that
Morpheus is the one calling. Without this annotation, we could not know
who is on the other end of the line (see Figure 3).
5. Using the matched characters, we created a link between characters u and
v if they appeared in the movie in a time interval less than t seconds. For
each such appearance, we increased the weight w between u and v by one.
Since in subtitles we do not have an indication of when each scene begins
and ends, we used a heuristic to model the interaction between characters.
We assumed that two characters who appear one after another in a short
period of time probably relate. For example, in Figure 2 we have part of
the subtitles from the movie The Matrix. Morpheus introduces himself to
Neo, and we know that Morpheus and Neo are talking within an interval
of 5 seconds. If t is larger than 5 seconds, we increase the link weight
9

Figure 3: Hearing-impaired subtitles for the movie The Matrix.
between Morpheus and Neo by one.
6. To reduce the number of false positive edges, we filtered all the edges with
weight lower than wmin . There were two main reasons for the formation of
edges that did not exist in the movie. The first case was when we matched
an entity to the wrong character. The second case happened when in the
interval of t seconds there was more than one scene. These kinds of false
positive links add noise to the graph. Most of these links have a very low
weight; hence, filtering edges with weight lower than wmin helps remove
false positive links.
3.1.1

Evaluations of Constructed Networks

In addition to constructing movie social networks, we also empirically quantified
the quality of these networks. To evaluate the quality of the constructed networks, we compared them to other publicly available movie network datasets.
Since it is challenging to manually annotate movies, most of the studies only
compared their networks to a handful of manually annotated ground truth networks (see Section 2). Comparison to manually annotated networks can only be
done at a very modest scale and does not necessarily represent the whole data.
In this study, to the best of our knowledge, we performed the first large-scale,
fully-automatic comparison between movie networks. For the comparison, we
used a dataset published in 2018 by Kaminski et al. [35] (denoted as ScriptNetwork ); this is the only other publicly available movie social network dataset.
The ScriptNetwork dataset is based on screenplays and can be considered as
much easier content to parse than subtitles. Screenplays have additional information such as the exact name of the character who speaks in the scene even if
this character is unnamed. For example, freckled kid is a character in the X-Men
(2000) screenplay; unnamed characters like freckled kid are almost impossible
to detect in regular texts like books or subtitles. Screenplays can be considered
very close to the ground truth. However, screenplays sometimes have big differences with the final movie. For instance, in many screenplays, there are missing
and even additional characters (see Section 5).

10

To evaluate Subs2Network -constructed networks, we performed two types of
evaluations:
• Central Character Analysis - We tested if the most central roles in Subs2Network
are actually the most central roles in the movie. As a ground truth, we
used the IMDb ranking list similarly to Trans et al. [46]. We tested if the
top-5 and top-10 ranked nodes (characters) at Subs2Network are the top-5
and top-10 ranked on IMDb. Additionally, we performed the same test on
networks constructed from screenplays [35]. Our motivation behind this
experiment was to verify that Subs2Network’s networks contain the most
significant characters in the movie.
• Network Coverage - We tested if the edges in Subs2Network are the same
edges as in other movie networks. For each movie, we created two subgraphs containing the characters that exist in both networks. Then we
calculated the edge coverage in the created sub-graphs. Given two graphs
∩EH |
G and H, we define the edge coverage as CoverageH (G) = |EG
|EH | .
We
calculated
CoverageSubs2N etwork (ScriptNetwork)
and
CoverageScriptN etwork (Subs2N etwork).

3.2

Datasets

To evaluate and test our movie social network construction algorithm described
above on real-world data, we assembled large-scale datasets of movie subtitles
and movie character lists. In addition, we collected movie character lists from
the IMDb (Internet Movie Database) website4 and movie subtitles from 15,540
movies. Furthermore, we also used data from Bechdel test scores of 4,658 movies.
In the following subsections, we describe in detail the datasets we used.
3.2.1

IMDb Dataset

To collect movie and actor data, we used IMDb, which is an online site that
contains information related to movies, TV series, video games, etc [14]. IMDb
data is contributed by users worldwide. It contains 5,487,394 titles from which
505,380 are full-length movies [15]. In this study, we used the official IMDb
dataset.5 From the IMDb dataset, which contains only a subset of the IMDb
database, we mainly used movies’ titles, crews, and ratings data.
3.2.2

Subtitle Dataset

To analyze movies’ content, we decided to extract information out of subtitles.
Subtitles are freely and widely available online on numerous sites. For instance,
OpenSubtitles.org6 alone hosts more than 500,000 English subtitles [17] that
4 https://www.imdb.com/
5 https://www.imdb.com/interfaces/
6 https://www.opensubtitles.org

11

were manually created by the community. We collected the subtitles using Subliminal7 , a Python library for searching and downloading subtitles. Subliminal
downloads subtitles from multiple sources, and using an internal scoring method,
it decides which subtitles are the best for a specific movie. Using Subliminal,
we downloaded subtitles for 15,540 movies.
3.2.3

Bechdel Test Dataset

Bechdel test data is available at Bechdel Test Movie List8 , which is a communityoperated website where people can label movies’ Bechdel scores. Using the
Bechdel Test Movie List API, we downloaded a dataset that contains 7,871
movies with labeled Bechdel scores, from which only 7,322 are full-length movies.
Even for humans, it is a challenging task to determine if a movie actually passes the Bechdel test; Bechdeltest.com has a comments section where
users discuss the scores and their disagreements [25]. For example, according
to Bechdeltest.com, the movie The Dark Knight Rises failed the test. However,
by taking a closer look at the community comments,9 we noticed users arguing
regarding the test results, which are hard to determine.

3.3

Dataset Preprocessing

The most critical part of building a social network of characters’ interaction is
mapping correctly between the characters in subtitles and the characters in the
character list. The IMDb character data includes data on even the most minor
roles such as a nurse, guard, and thug #1. These nameless minor characters are
almost impossible to map correctly to their subtitle appearances. Usually, they
just add false positive edges and do not add additional information.
To clean the data from nameless characters, we created a blacklist of minor
characters (for a detailed explanation of the blacklist construction process see
Section A.1). Additionally, to validate the characters’ names we used TMDb
(The Movie Database)10 , another community-built movie database. For each
character, we matched the IMDb and TMDb data by the actor name. Then,
we compared the lengths of the character names and kept the longer one.

3.4
3.4.1

Analyzing Movie Social Networks to Identify Gender
Bias
Network Features

To study gender bias in movies, we calculated five types of features: vertex
features, network features, movie features, gender representation features, and
actor features. Through the study, we analyzed how these features change
7 https://github.com/Diaoul/subliminal
8 https://bechdeltest.com/. Note the site uses the Bechdel test variation where women
have to have names.
9 https://bechdeltest.com/view/3437/the_dark_knight_rises/
10 https://www.themoviedb.org

12

over time. Additionally, we used these features to construct machine-learning
classifiers. To create a ground truth for actors’ gender, we had to determine
whether each actor was male or female. For most of the characters, we extracted
the gender from IMDb similarly to Danescu et al. [28]. IMDb has an attribute
of “actor” or “actress,” which allowed us to identify gender. As we mentioned
earlier, the IMDb dataset is only partial, so to overcome this issue we used a
dataset that maps the first name to the gender.11 In the rest of this section, we
supply the definitions of these features.
Vertex Features: For a given v ∈ V , a neighborhood is defined as a set of v
friends, Γ(v). Following are the formal definitions of the vertex-based features:
• Total Weight - the total weight of all the edges, which represents the number
of Pcharacter
v
appearances
in
the
movie,
T otalw (v) = {(v,u,w)|((v,u,w)∈E} w.
• Closeness Centrality - the inverse value of the total distance to all the
nodes in the graph. It is based on the idea that a node closer to other nodes
is more central, Cc (v) = P 1d(v,u) [27], where d(v, u) is the shortest
v∈V
distance between v and u.
• Betweenness Centrality - represents the number of times that a node is a
part of the shortest path between two nodes [27]. A junction (node) that
P
is part of more paths is more central, Cb (v) = s,t∈V σ(s,t|v)
σ(s,t) [27], where
v 6= s 6= t, σ(s, t) is the number of shortest paths between s and t , and
(s, t|v) is the number of those paths passing through some node v.
• Degree Centrality - a node that has a higher degree is considered more
|Γ(v)|
central, Cd (v) = |V
|−1 [27].
• Clustering - measures link formation between neighboring nodes, C(v) =
2T (v)
|Γ(v)|(|Γ(v)|−1) [44], where T (v) is defined as the number of triangles through
vertex v where a triangle is a closed triplet (three vertices that each connect to the other two).
• Pagerank - a node centrality measure that takes into account the number
and the centrality of the nodes pointing to the current node [27].
Network Features:
• Edge Number - the number of edges in the network |E|.
• Vertex Number - the number of vertices in the network |V |.
• Number of Cliques - the number of maximal cliques in the network [27].
11 http://www.ise.bgu.ac.il/faculty/fire/computationalgenealogy/first_names.html

13

• Statistical Network Features - set of features which are based on the vertex features. From these features, we calculate statistical features for the
entire network. We calculate the mean, median, standard deviation, minimum, maximum, first quartile, and third quartile.
Gender Representation Features:
• Gender Count - the number of actors of a specific sex in the movie,
Gc (G, Sex) = |{v|v ∈ V gender(v) = Sex}.
• Triangles with N Women - the number of triangles that contain N females
and 3-N males, where N ∈ 1, 2, 3.
• Percent of Triangles with N Women - the percent of triangles that contain
N females and 3-N males, where N ∈ 1, 2, 3.
• Females in Top-10 Roles - the number of females in top-10 roles ordered
by PageRank.
• Male Count - the number of male actors in the movie.
• Female Count - the number of female actors in the movie.
Movie Features:
• Release Year - the year when the movie was first aired.
• Movie Rating - the rating the movie has on IMDb.
• Runtime - the movie total runtime in minutes.
• Genres - the movie genre by IMDb.
• Number of Votes - number of votes by which the rating was calculated on
IMDb.
Actor Features:
• Actor Birth Year - the year the actor was born.
• Actor Death Year - the year the actor died.
• Actor Age Filming - the age of the actor when the movie was released
(ReleaseY ear − ActorBirthY ear).
3.4.2

Network Feature Analysis

To examine the state of the gender gap, in movies generally and by genre in
particular, we analyzed only the most popular movies (movies which had more
than n votes on IMDb). To answer our first research question – if there are
genres that do not show a gender gap (see Section 1) – we calculated vertex
and actor features (see Section 3.4.1) for all the roles. Next, we split the data
14

by gender and movie genre. Finally, we utilized a Mann-Whitney U [40] test on
these features to check if there are statistical differences between the male and
female roles in different genres.
To study relationships in movies, and to answer our second question regarding what relationships reveal about gender, we calculated all the relationship
triangles in the network and grouped them by the number of women in each triangle. Afterward, we segmented the triangles by genres and how they changed
over time.
To investigate the role of centrality by gender, our third research question
regardong the centrality of female roles, we calculated PageRank for the nodes
in all our movie networks. We analyzed the number of men and women in the
top-10 characters in movies and examined how this number has changed over
the years.
3.4.3

Constructing the Bechdel Test Classifier

As we described in Section 2, the Bechdel test is used to assess how fairly women
are represented in a movie. The test has three criteria:
1. Are there at least two named women in the movie?
2. Do the women talk to each other?
3. Do the women talk about something other than men?
These criteria are hierarchical; hence, if a movie passes the last test, it has
passed all of the tests.
To train the classifier, we extracted all the network, vertex, and gender
representation features (see Section 3.4.1). For testing the trained model, we
used the n newest movies in the Bechdel test dataset. The rest of the movies
were used as the training set. Additionally, to standardize metrics such as AUC,
we evaluated the classifier performance by the Precision at k (P@k) metric. P@k
presents how many of the results the classifier is confident it classified correctly.
To answer the fourth research question regarding the fairness of female representation, we analyzed the change in the average probability of a movie passing
the Bechdel test over time. Finally, we analyzed the change over time by genre.

4

Results

To analyze the gender gap in the film industry, we analyzed subtitles of movies
that had at least 1,000 votes on IMDb. This resulted in a dataset containing
15,540 movies, which is a dataset 20 times bigger than the largest movie dataset
currently available [35].
First, we analyzed the gender gap, in general, and by genres, in particular
(see Tables 6-10). We found that the genre with the largest number of features
that are distributed similarly between men and women is Musicals. In musical
movies, 9 out of 10 features distribute similarly; only the clustering coefficient
15

distributes differently between men and women. In terms of features, Total
Weight is the feature that distributes most similarly between the genders, with
9 out of 21 genres distributing the same. On the other side of the scale, Age
Filming is the feature that distributes least similarly, with 0 out of 21 genres
distributing similarly.
Second, to examine relationships among characters, we analyzed relationship
triangles in the networks. We found that most triangles have three men, and
triangles with three women are the least common (see Table 1). Out of 21
genres, in 8 genres the most common type of triangle is 3 men (without any
women) and in all the others it is 2 men and a woman. According to the
results, Romance is the genre with the most interaction among women and War
is the genre where women have the least interaction. Inspecting the change in
the number of triangles over time (see Figure 4), we can observe that in many
genres there is an equalizing improvement over the years, but there are genres
like Sport without a significant change.
Table 1: Relationship triangles in the social network.
Females in triangle
All
Action
Adventure
Animation
Biography
Comedy
Crime
Drama
Family
Fantasy
Film-Noir
History
Horror
Music
Musical
Mystery
Romance
Sci-Fi
Sport
Thriller
War
Western

0
40.74%
45.85%
43.36%
34.48%
45.49%
33.71%
42.54%
35.50%
33.04%
34.24%
35.97%
53.10%
24.71%
37.60%
19.59%
28.78%
21.29%
35.59%
57.43%
36.34%
64.24%
55.08%

1
36.56%
40.01%
40.97%
44.36%
36.74%
41.93%
40.59%
40.01%
40.52%
42.25%
45.59%
34.02%
43.62%
40.00%
45.60%
43.56%
43.61%
44.71%
32.60%
42.65%
25.46%
35.54%

2
19.14%
12.59%
13.97%
18.44%
15.09%
20.53%
14.76%
20.46%
21.52%
20.10%
16.59%
11.30%
26.31%
18.78%
29.13%
23.27%
29.03%
17.49%
8.27%
18.24%
8.73%
8.50%

3
3.57%
1.55%
1.70%
2.72%
2.69%
3.83%
2.10%
4.03%
4.93%
3.41%
1.85%
1.58%
5.36%
3.62%
5.68%
4.39%
6.07%
2.21%
1.70%
2.77%
1.57%
0.87%

Third, we analyzed how characters are ranked in terms of centrality (see
Tables 2a and 2b). We found that among central roles, there are considerably
more men than women. For example, men have about twice the roles that
ranked in the top-10 most central roles than women. In all top-10 most central
16

Figure 4: Relationship triangles change over time by different genres.
roles, the female percentage is the same except for the most central role.
Fourth, we analyzed the gender composition of the top-10 central roles in
movies (see Figure 5). We discovered that most of the movies have more men in
central roles than women. Moreover, from the data, we can observe that there
are almost no movies with no men and 10 women in the top-10 roles. Also,
there are a considerable number of movies where the majority of the top-10
most central roles are men.
Fifth, we wanted to observe how the percentage of women in top 1, 3 and 10
most central roles has evolved over time. We analyzed the change in this metric

17

Table 2: The percent of characters by gender, ranked by Degree Centrality in
table (a) and PageRank in table (b).
(b) PageRank

(a) Degree Centrality

Rank
1
2
3
4
5
6
7
8
9
10

F%
28.22%
32.19%
32.84%
32.56%
32.54%
32.65%
32.46%
32.16%
31.46%
32.60%

M%
71.78%
67.81%
67.16%
67.44%
67.46%
67.35%
67.54%
67.84%
68.54%
67.40%

Rank
1
2
3
4
5
6
7
8
9
10

F%
28.02%
32.24%
32.84%
32.11%
32.63%
32.81%
32.04%
32.88%
32.14%
32.28%

M%
71.98%
67.76%
67.16%
67.89%
67.37%
67.19%
67.96%
67.12%
67.86%
67.72%

(a) The percentage of movies where out of (b) The number of movies where out of
top-10 role N are of a specific gender.
top-10 role N are of a specific gender.

Figure 5: The distribution of movies by gender of the top-10 most central characters.
over almost a century (see Figure 6). It can be seen from the network that there
is a constant rise in the number of women in top-10 most central roles.
Sixth, to create an automatic classifier that can assess the fairness of female
representation in movies, we created the Bechdel test classifier. Our classifier
achieved an AUC of 0.81. To check real-world usage of the classifier, we cal18

Figure 6: The change in the percentage of women in top 1,3, and 10 most central
roles over time.
culated precision at K (P@K) (see Figure 9). We can observe that in the first
200 movies in the validation set, we achieved high precision above 0.9. We also
inspected which feature was more important (see Table 5). Seven of ten features
were triangle-based features. Moreover, all the features in the table are a subset
of the Gender Representation Features (see Section 3.4.1)
Next, we trained our automated Bechdel test classifier on all the labeled
data and calculated the average probability of the classifier by decade on all the
unlabeled data (see Figure 7). We can see that there is a trend of growth. Also,
we examined how the probability changed by genres (see Figure 8). Comparing
our results to Agarwal et al. [25] (see Table 4), we found that our classifier
performs better than Agarwal’s in terms of F1 score.
Finally, we analyzed the quality of the constructed social networks by comparing Subs2Network with the ScriptNetwork -released networks [35]. We observed that the Subs2Network dataset contains 628 out of the 773 networks that
appear in the ScriptNetwork dataset. In terms of central characters, on average
Subs2Network had more central characters than ScriptNetwork (see Table 3); for
instance, in the top-10 characters Subs2Network matched 6.06 characters while
ScriptNetwork matched 5.35 characters. In terms of edge coverage, we found
that Subs2Network covered 65.4% of the edges in ScriptNetwork networks and
ScriptNetwork covered 65.1% of the edges in Subs2Network networks.

5

Discussion

In this study, we present a method that converts movie subtitles into social
networks, and we analyze these networks to study gender disparities in the film
industry. Using this method, we created the largest available corpus of movie

19

Top-5
Top-10

ScriptNetwork
2.7
5.35

Subs2Network
2.8
6.06

Table 3: The average number of Top-5,10 most central characters in the movie
graph by degree centrality which are also in top-5,10 IMDb most central characters.

Agrawal et al.
Current study

Precision
0.42
0.718

Fail
Recall
0.84
0.757

F1
0.56
0.737

Precision
0.9
0.74

Pass
Recall
0.55
0.73

F1
0.68
0.72

Table 4: 5-fold cross-validation of the Bechdel test classifier and comparison to
the results of Agrawal et al. [25]

Table 5: Top-10 most important features in the gender Bechdel test classifier
Feature
Percent of Triangles of 2
Percent of Triangles of 0
Females in Top 10 Roles
Percent of Triangles of 3
Triangles of 3 Women
Triangles of 2 Women
Female Count
Triangles of 0 Woman
Percent of Triangles of 1
Triangles of 1 Women

20

Women
Women
Women

Woman

Importance
0.157974
0.14502
0.136595
0.120586
0.07433
0.054393
0.040251
0.030095
0.027671
0.008216

(a) The average probability of passing the (b) Trend line of probability of passsing
Bechdel test by decade.
the Bechdel test in the past 60 years.

Figure 7: Probability of a movie passing the Bechdel test by decade.
character social networks. The method and the corpus are available for use by
other researchers to study additional movies and even TV shows, and it has the
potential to revolutionize the study of filmed media.
When looking at relationship triangles, we can see that in 77% of all triangles
men are in the majority. In an equal society, we would expect to find that the
number of triangles with three men, with three women, and with two men and
two women would be the same. However, we discovered that, on average, there
are 11.4 times more triangles with three men than with three women, and almost
twice as many triangles with two men than two women. At a deeper level of
granularity, we can see a difference in the number of triangles between different
movie genres. The Romance genre has the highest number of triangles that
have two and three women. On the other side of the scale, 90.6% of triangles in
the War genre have a majority of men. This result makes sense intuitively. By
looking at Figure 10, we can see that genres with a higher percentage of movies
that pass the Bechdel test also have a higher percentage of triangles with a
majority of women.
In terms of centrality (see Table 2a), we can see that men have more central
roles than women. We expected to find more females in less central roles, but
the percentage of females distributes evenly in the top-10 most central roles. We
believe that these results correspond to the total percentage of women in the
dataset, which is 32.3%. This number is still lower than the total percentage of
female roles in IMDb, which is 37.2%.
We also analyzed how many roles in a movie’s top-10 most central roles are
those of women. Unsurprisingly, there is a dominance of movies with a majority
of men. For instance, all Lord of the Rings movies have 10 men in the top-10
roles. We found only 5 films where all top-10 roles were female, and each of
21

Figure 8: The average probability of a movie passing the Bechdel test by decade
and genre.
these featured only women (one of these films is called The Women, another
movie Caged is about a women’s prison, and the movie The Trouble with Angels
is about a girls’ school).
We also presented an automated Bechdel test classifier that can help assess
the fairness of how women are presented in movies. We trained our model on
data collected from bechdeltest.com, and we have indications that our model
is even more accurate than the above presented results. We found that many
movies on bechdeltest.com are misclassified. For example, The Young Offenders
passes the test on bechdeltest.com (although the site does state this result is
‘dubious’), but our work classifies it as a fail. The reverse is true for the movie
Never Let Go. Based on these observations and on the P@K metric, we believe
that our classifier can automatically classify movies with high confidence in

22

Figure 9: Precision at K of the Bechdel test classifier.
the classification. Moreover, while the Bechdel test is certainly a useful and
important test, it fails to account for many parameters such as the centrality
of the characters, repression, etc. Basically, if there is a movie with only two
women who appear in one scene and talk about something other than men for 2
seconds, then the movie will pass the traditional Bechdel test. However, this is
the only test that has data that can be used to train a classifier. Our classifier
partially tackles this problem since it calculates a score of how strongly the
movie passes the test.
To truly solve the issues of the Bechdel test, a better test should be created. We believe that a good test can be created by comparing the number of
interactions according to each gender. Hence, we propose an interaction test
by comparing the total degree of male and female nodes in our movie social
networks. In only 16.7% of movies do female characters have an equal or higher
total degree than male characters. Moreover, in 55.8% of movies the total degree of male characters is at least twice as high as female characters. We think
otalDegreeF
< 1.2. Such
that a good rule of thumb for a movie should be 0.8 < TTotalDegree
M
a test would not be male nor female biased; sadly today only 12% of all movies
pass this test. In future work, we are planning to perform statistical tests to
compare the distributions of the degrees of male and female nodes and present
a more accurate test.
We also calculated the average probability of passing the Bechdel test for all
the movies in our dataset that do not have a Bechdel test score. Afterward, we
inspected the change in the average probability of movies passing the test over
a long period of time and by different genres. In almost all genres there is a
trend of improvement, and there is a correlation between relationship triangles
and the Bechdel score. Looking at Figure 8, we see that historically war movies
have the lowest probability of passing the Bechdel test.
There are many factors that affect our method’s accuracy. The most critical

23

factor is the quality of both the subtitles and the cast information from IMDb.
In movies where the name of the character in the subtitles does not correspond
to IMDb data, the actor cannot be linked to a character. During our study, we
stumbled upon subtitles with spelling mistakes and other inconsistencies. Also,
in some movies like superhero movies, we did not know how to link the different
identities of a character with names such as “Captain America,” that potentially
could be filtered because it looks like a nameless character. In addition, nameless characters like “Street Pedestrian” sometimes eluded our cleaning process.
There is a balance between cleaning the IMDb data too much and not enough.
We observed that more accurate networks were in movies that had hearingimpaired subtitles since they have additional data and are less affected by the
NER accuracy. Some of these limitations will be addressed in future research.
Additionally, there are many different improvements that can done to increase
the accuracy of the networks; for instance, it is possible to use co-reference
resolution, train an NER for subtitles, etc.
One of the biggest challenges of this study was to evaluate the quality of the
constructed movie networks. For the evaluation, we compared the networks created by our algorithm with the networks created by screenplay analysis. Screenplays have easier content to analyze than subtitles, and they contain plenty of
structured information, such as character names, scenes, etc. However, there
are also some shortcomings in using screenplays. First, only a small fraction of
movies have screenplays available online. Currently, the Internet Movie Script
Database (IMSDb)12 has only 1198 scripts, while there are hundreds of thousands of movies’ subtitles available online. Moreover, many publicly available
screenplays are drafts and have major differences from the actual movies. For
instance, the Minority Report 13 screenplay used by Kaminski et al. is completely different from the movie; almost all the characters’ names are different.
Another example can be found in the X-Men (2000) movie where the character
Beast appears in the screenplay. However, due to over-budget concerns, Beast
was cut from the movie. From inspecting screenplays we discovered many additional examples of extra, missing, and renamed characters. These problems
show that comparing subtitles to screenplays is like comparing apples to oranges.
The comparison indicates that there is a similarity between the networks, but
it cannot be used as a precise measure of accuracy.
There is no doubt that the presented method is not perfect. For instance, in
the film Star Wars: Episode VI - Return of the Jedi (see Figure 1), Princess Leia
never meets Obi Wan Kenobi. Obi Wan Kenobi only talks with Luke about her,
which created an edge in the graph. Nonetheless, from the network evaluation,
we learn that the constructed networks represent the movie and have enough
correct data to supply insights. Moreover, many calibrations to the method can
be made to improve its accuracy; for instance, we can manually select better
subtitles to get more accurate networks. Such calibrations are out of the scope
of this study, but in future studies we will explore such options.
12 https://www.imsdb.com/
13 https://www.imsdb.com/scripts/Minority-Report.html

24

Besides utilizing subtitles and screenplays, there are other possible ways to
analyze movie content. The first option is to analyze movie videos as Weng
et al. did [48]. The problem with video analysis is that it is an expensive
process which requires high computational power, especially when the plan is to
analyze thousands of full-length movies. Moreover, most movies are copyrighted
and not freely available online. The second option is to use speech recognition
to extract information, which is what Park et al. did. [42]. However, this option
has similar drawbacks.

6

Conclusions

Data science can provide great insights into many problems, including the gender gap in movies. In this work, we created a massive dataset of movie character
interactions to present the largest-to-date social network analysis of gender disparities in the film industry. We constructed this dataset by fusing data from
multiple sources, and then we analyzed the movie gender gap by examining
multiple parameters over the past century.
Our results demonstrate that a gender gap remains in nearly all genres of
the film industry. For instance, 3.5 times more relationship triangles in movies
have a majority of men. In terms of top-10 most central movie roles, again there
is a majority of men. However, we also saw an improvement in equality over the
years. Today, women have more important movie roles than in the past, and
our Bechdel test classifier quantifies this improvement over time by calculating
a movie’s overall score. In a future study, we plan to analyze TV series, actors’
careers, and directors’ careers in a similar in-depth manner. We also plan to
implement the tests that were proposed in [5] as well as develop new tests to
gain further insight into how genders are represented in the film industry.

7

Data and Code Availability

This study is reproducible research. Therefore, the anonymous versions of the
social network datasets and the study’s code, including implementation, are
available on the project’s website14 and repository15 .

8

Acknowledgements

We would like to thank Carol Teegarden for editing and proofreading this article to completion. Also, we thank Sean McNaughton Mandy Henner, Sergey
Korotchenko, and Ariel Plotkin for their help.
14 http://data4good.io/dataset.html#Movie-Dynamics
15 https://github.com/data4goodlab/subs2network

25

References
[1] 2017 its a mans celluloid world report 3.pdf. https://womenintvfilm.
sdsu.edu/wp-content/uploads/2018/03/2017_Its_a_Mans_
Celluloid_World_Report_3.pdf. (Accessed on 01/05/2019).
[2] 22 movies that dont pass the bechdel test but are still pretty darn feminist.
https://www.bustle.com/p/22-movies-that-dont-pass-thebechdel-test-but-are-still-pretty-darn-feminist-16961528. (Accessed on 07/02/2019).
[3] The bechdel test, and other media representation tests, explained.
https://lifehacker.com/the-bechdel-test-and-other-mediarepresentation-tests-1819324045. (Accessed on 01/23/2019).
[4] Comic-con vs. the bechdel test.
https://web.archive.org/web/
20150316161800/http://www.sdcitybeat.com/sandiego/article13243-comic-con-vs-the-bechdel-test.html.
(Accessed
on
01/25/2019).
[5] Creating the next bechdel test — fivethirtyeight. https://projects.
fivethirtyeight.com/next-bechdel/. (Accessed on 01/16/2019).
[6] The dollar-and-cents case against hollywoods exclusion of women —
fivethirtyeight. https://fivethirtyeight.com/features/the-dollarand-cents-case-against-hollywoods-exclusion-of-women/.
(Accessed on 01/23/2019).
[7] full-study-gender-disparity-in-family-films-v2.pdf.
https://seejane.
org/wp-content/uploads/full-study-gender-disparity-in-familyfilms-v2.pdf. (Accessed on 01/05/2019).
[8] fuzzywuzzy/fuzz.py at df5b67a32d7ddaf2e86fe1247b6ff7e3b57e0805 seatgeek/fuzzywuzzy.
https://github.com/seatgeek/fuzzywuzzy/blob/
df5b67a32d7ddaf2e86fe1247b6ff7e3b57e0805/fuzzywuzzy/fuzz.py#
L224. (Accessed on 02/17/2019).
[9] Inclusion in the directors chair 2007 to 2017.
http://assets.
uscannenberg.org/docs/inclusion-in-the-directors-chair-20072017.pdf. (Accessed on 01/05/2019).
[10] media-research shift7. https://shift7.com/media-research. (Accessed
on 01/23/2019).
[11] One female director for every 22 men: Hollywood’s stark diversity
problem — film — the guardian. https://www.theguardian.com/film/
2018/jan/04/hollywood-diversity-sees-no-improvement-in-2017report-finds. (Accessed on 12/16/2018).

26

[12] Oscars 2017: Half of the best picture nominees fail this test for gender
equality. https://www.globalcitizen.org/en/content/oscars-bestpicture-bechdel-test/. (Accessed on 01/23/2019).
[13] Powerpoint presentation.
https://www.mpaa.org/wp-content/
uploads/2018/04/MPAA-THEME-Report-2017_Final.pdf.
(Accessed
on 01/05/2019).
[14] Press room - imdb. https://www.imdb.com/pressroom/?ref_=helpms_
ih_gi_whatsimdb. (Accessed on 12/15/2018).
[15] Press room - imdb. https://www.imdb.com/pressroom/stats/. (Accessed on 12/17/2018).
[16] seatgeek/fuzzywuzzy: Fuzzy string matching in python. https://github.
com/seatgeek/fuzzywuzzy. (Accessed on 02/04/2019).
[17] Subtitles - download movie and tv series subtitles.
https://www.
opensubtitles.org/en/statistics. (Accessed on 12/15/2018).
[18] The scully effect: I want to believein stem in stem.
https:
//impact.21cf.com/wp-content/uploads/sites/2/2018/03/
ScullyEffectReport_21CF_1-1.pdf. (Accessed on 01/17/2019).
[19] Unic ar2018 online.pdf.
https://www.unic-cinemas.org/fileadmin/
user_upload/wordpress-uploads/2017/06/UNIC_AR2018_online.pdf.
(Accessed on 01/05/2019).
[20] Unrealized potential: The high cost of gender inequality in earnings.
https://www.worldbank.org/en/topic/gender/publication/
unrealized-potential-the-high-cost-of-gender-inequality-inearnings. (Accessed on 12/09/2018).
[21] Why the bechdel test fails feminism — huffpost. https://www.huffpost.
com/entry/why-the-bechdel-test-fails-feminism_b_7139510. (Accessed on 07/02/2019).
[22] Women and hollywood sexism in the film industry problem.
https://www.refinery29.com/en-us/2017/10/175956/melissasilverstein-women-hollywood-gender-inequality.
(Accessed on
12/17/2018).
[23] Women remain underrepresented in hollywood,
study
https://phys.org/news/2017-09-women-underrepresentedhollywood.html. (Accessed on 12/07/2018).

shows.

[24] A. Agarwal, S. Balasubramanian, J. Zheng, and S. Dash. Parsing screenplays for extracting social networks from movies. In Proceedings of the
3rd Workshop on Computational Linguistics for Literature (CLFL), pages
50–58, 2014.
27

[25] A. Agarwal, J. Zheng, S. Kamath, S. Balasubramanian, and S. A. Dey.
Key female characters in film have more to talk about besides men: Automating the bechdel test. In Proceedings of the 2015 Conference of the
North American Chapter of the Association for Computational Linguistics:
Human Language Technologies, pages 830–840, 2015.
[26] A. Bechdel. The rule. Dykes to Watch Out For, 1985.
[27] U. Brandes and T. Erlebach. Network analysis. lncs, vol. 3418, 2005.
[28] C. Danescu-Niculescu-Mizil and L. Lee. Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in
dialogs. In Proceedings of the 2nd Workshop on Cognitive Modeling and
Computational Linguistics, pages 76–87. Association for Computational
Linguistics, 2011.
[29] D. Donoho. 50 years of data science. URL http://courses. csail. mit.
edu/18, 337:2015, 2015.
[30] R. M. Entman. How the media affect what people think: An information
processing approach. The journal of Politics, 51(2):347–370, 1989.
[31] J. R. Finkel, T. Grenager, and C. Manning. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd annual meeting on association for computational linguistics,
pages 363–370. Association for Computational Linguistics, 2005.
[32] D. Garcia, I. Weber, and V. R. K. Garimella. Gender asymmetries in reality
and fiction: The bechdel test of social media. In ICWSM, pages 131–140,
2014.
[33] M. Honnibal and I. Montani. spacy 2: Natural language understanding
with bloom embeddings, convolutional neural networks and incremental
parsing. To appear, 2017.
[34] S. Jia, T. Lansdall-Welfare, S. Sudhahar, C. Carter, and N. Cristianini. Women are seen more than heard in online newspapers. PloS one,
11(2):e0148434, 2016.
[35] J. Kaminski, M. Schober, R. Albaladejo, O. Zastupailo, and C. Hidalgo.
Moviegalaxies-social networks in movies. 2018.
[36] V. Larivière, C. Ni, Y. Gingras, B. Cronin, and C. R. Sugimoto. Bibliometrics: Global gender disparities in science. Nature News, 504(7479):211,
2013.
[37] M. M. Lauzen. Boxed in 2017-18: Women on screen and behind the scenes
in television. 2018. (Accessed on 12/07/2018).
[38] V. I. Levenshtein. Binary codes capable of correcting deletions, insertions,
and reversals. In Soviet physics doklady, volume 10, pages 707–710, 1966.
28

[39] J. Lv, B. Wu, L. Zhou, and H. Wang. Storyrolenet: Social network construction of role relationship in video. IEEE Access, 2018.
[40] H. B. Mann and D. R. Whitney. On a test of whether one of two random
variables is stochastically larger than the other. The annals of mathematical
statistics, pages 50–60, 1947.
[41] D. Nadeau and S. Sekine. A survey of named entity recognition and classification. Lingvisticae Investigationes, 30(1):3–26, 2007.
[42] S.-B. Park, K.-J. Oh, and G.-S. Jo. Social network analysis in a movie using
character-net. Multimedia Tools and Applications, 59(2):601–627, 2012.
[43] M. Polce-Lynch, B. J. Myers, W. Kliewer, and C. Kilmartin. Adolescent
self-esteem and gender: Exploring relations to sexual harassment, body
image, media influence, and emotional expression. Journal of Youth and
Adolescence, 30(2):225–244, 2001.
[44] J. Saramäki, M. Kivelä, J.-P. Onnela, K. Kaski, and J. Kertesz. Generalizations of the clustering coefficient to weighted complex networks. Physical
Review E, 75(2):027105, 2007.
[45] R. Silverstone. Television and everyday life. Routledge, 2003.
[46] Q. D. Tran and J. E. Jung. Cocharnet: Extracting social networks using
character co-occurrence in movies. J. UCS, 21(6):796–815, 2015.
[47] C. Wagner, D. Garcia, M. Jadidi, and M. Strohmaier. It’s a man’s
wikipedia? assessing gender inequality in an online encyclopedia. In
ICWSM, pages 454–463, 2015.
[48] C.-Y. Weng, W.-T. Chu, and J.-L. Wu. Rolenet: Movie analysis from
the perspective of social networks. IEEE Transactions on Multimedia,
11(2):256–271, 2009.
[49] J. D. Wilson and M. S. MacGillivray. Self-perceived influences of family,
friends, and media on adolescent clothing choice. Family and Consumer
Sciences Research Journal, 26(4):425–443, 1998.
[50] J. T. Wood. Gendered media: The influence of media on views of gender.
Gendered lives: Communication, gender and culture, pages 231–244, 1994.

A
A.1

Appendix
Character Blacklist Construction

1. First, we initialized a list of all characters from the IMDb dataset (see
Section 3.2.

29

2. To remove all named characters, we downloaded the U.S Social Security
baby name dataset16 and the U.S Census surname dataset.17 We removed
all the characters whose names matched the names in these datasets.
3. Next, we grouped all the characters by name and actor, and we filtered
all characters portrayed by the same actor in more than one film.
4. Afterward, we aggregated the remaining characters by their names and
counted the number of appearances and the average order of appearance.
We removed all the character names that on average placed in the first
three positions in the cast list. The IMDb cast order mostly represents
the importance of the characters, but we noticed some anomalies in the
ordering. In this study, we assumed that the first three roles on IMDb are
the main characters.
5. Finally, we removed all character names that appeared only once. Generic
character names like Mom, Dad, Policeman, etc., appear in multiple unrelated movies. A character name that appears only in one film has a higher
probability of being an important character.
6. All the remaining character names were blacklisted.

A.2

Figures and Tables

Feature
Age Filming
Betweenness
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Weighted Betweenness
Weighted Pagerank
Total Weight

U
44918391.50
62658633.50
64487986.00
64536999.50
66190111.50
64208427.50
64940724.50
66888718.00
63235436.00
67797466.00

Median(M)
42.00
0.08
0.75
0.56
7.00
0.69
0.11
0.11
0.14
104.00

Median(F)
33.00
0.05
0.72
0.62
7.00
0.63
0.11
0.09
0.12
95.00

Table 6: MannWhitney U test between men and women.

16 https://www.ssa.gov/oact/babynames/names.zip
17 https://www2.census.gov/topics/genealogy/2010surnames/names.zip

30

p-value
0
2.96E-54
6.31E-34
1.62E-33
1.17E-19
1.12E-36
1.18E-29
4.06E-15
4.99E-47
7.47E-10

Genre
Action
Action
Action
Action
Action
Action
Action
Action
Action
Action
Adventure
Adventure
Adventure
Adventure
Adventure
Adventure
Adventure
Adventure
Adventure
Adventure
Animation
Animation
Animation
Animation
Animation
Animation
Animation
Animation
Animation
Animation
Biography
Biography
Biography
Biography
Biography
Biography
Biography
Biography
Biography
Biography
Comedy
Comedy
Comedy
Comedy
Comedy
Comedy
Comedy
Comedy
Comedy
Comedy
Crime
Crime
Crime
Crime
Crime
Crime
Crime
Crime
Crime
Crime

Feature
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight

U
1141522.5
1857629
2043730
1941924.5
2037316.5
2077375
1925104
1931693
1888486.5
2138621
668865.5
1018363
1146136.5
1056896.5
1082650
1114523
1051316
1073820
1015396.5
1132409.5
26773
39955
40912.5
38732.5
42076.5
39161
38499
41147.5
37378
35999
225818.5
278486
287077
286549
289311.5
274713
287900
302390
290355
285146.5
7323590.5
9596319
10212374.5
9649651.5
9913519.5
10274875
9604776
9586716
9358473.5
10277578.5
1608067.5
2317850
2534976
2419778.5
2381780.5
2500022.5
2403978.5
2413828
2309188
2574489.5

Median(M)
43
0.090891053
0.111111111
0.75
0.533333333
7
0.666666667
0.113907479
0.140696271
91
43
0.072065437
0.1
0.75
0.580882353
7
0.666666667
0.109176206
0.136392253
105
46
0.055810878
0.071428571
0.75
0.636363636
7
0.666666667
0.106196092
0.129233386
112
41
0.074104894
0.111111111
0.722222222
0.5
9
0.625
0.09683747
0.115042243
124
41
0.088888889
0.115384615
0.765686275
0.555555556
8
0.7
0.115125241
0.147601675
121
42
0.084900202
0.107142857
0.75
0.545454545
7
0.666666667
0.112332161
0.140377213
108

Median(F)
32
0.036363636
0.072727273
0.692307692
0.636363636
6
0.571428571
0.096573682
0.104831315
76
33
0.042779044
0.078472222
0.714285714
0.65447861
7
0.6
0.098911737
0.107955414
90
38
0.033617725
0.095238095
0.714285714
0.666666667
6
0.6
0.100198011
0.101397903
69.5
35
0.049692308
0.089404919
0.7
0.555555556
7
0.578947368
0.095406148
0.10650003
102.5
34
0.051340073
0.091666667
0.722222222
0.611111111
7
0.625
0.103417249
0.120580764
109.5
33
0.041666667
0.080645855
0.714285714
0.658241758
7
0.6
0.099630832
0.107617666
95

p-value
1.06E-155
1.41E-26
5.24E-11
1.78E-18
2.53E-11
6.82E-09
6.08E-20
2.44E-19
2.57E-23
8.66E-06
4.97E-93
2.61E-14
0.002577084
6.02E-10
1.43E-07
3.85E-05
1.63E-10
2.53E-08
1.38E-14
0.000513202
1.35E-15
0.029420016
0.072545277
0.007374173
0.181192059
0.012322396
0.005459331
0.091332701
0.001124444
0.000114125
1.21E-20
0.000146971
0.003482307
0.003033074
0.007117802
2.98E-05
0.004666262
0.147192227
0.009751414
0.001908454
8.79E-160
1.99E-23
5.99E-08
1.23E-21
2.94E-14
7.87E-07
4.62E-23
1.32E-23
1.08E-31
9.22E-07
3.36E-121
1.57E-20
5.32E-07
4.29E-13
1.19E-15
1.38E-08
4.08E-14
1.86E-13
4.10E-21
2.52E-05

Table 7: MannWhitney U test between men and women and by movie genre.

31

Genre
Family
Family
Family
Family
Family
Family
Family
Family
Family
Family
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Fantasy
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
Film-Noir
History
History
History
History
History
History
History
History
History
History
Horror
Horror
Horror
Horror
Horror
Horror
Horror
Horror
Horror
Horror
Music
Music
Music
Music
Music
Music
Music
Music
Music
Music

Feature
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight

U
109501
135028.5
152510.5
142036
137921.5
150287
141678
132781
127825
147673
145618
210166.5
216448.5
215782.5
224803
219762.5
212925.5
218093.5
213766
225173
7954
18890.5
19222.5
19247
18698
17960.5
19209
21070.5
18199
18142.5
55474
79958.5
79259.5
84682.5
83098.5
84944
84356.5
84616.5
82926
86931
232696.5
391571.5
376206.5
400103
388844.5
392754
400763.5
393557
392331.5
376062
36852
43732.5
46984.5
42434.5
48215
47201
42609
43775
43148
46491

Median(M)
43
0.069483182
0.083333333
0.769230769
0.6
8
0.7
0.107232427
0.129170457
126
42
0.088690476
0.116666667
0.75
0.533333333
7
0.6875
0.114703841
0.140384021
104
39
0.050614478
0.044444444
0.875
0.722222222
7
0.857142857
0.13009992
0.174634239
184
41
0.078484848
0.102941176
0.708333333
0.522875817
8
0.6
0.09843372
0.115658997
82
43
0.063369963
0.091911765
0.75
0.642857143
6
0.684210526
0.120876857
0.142857143
83
38
0.105603656
0.137362637
0.761904762
0.523809524
7
0.7
0.120154842
0.151410784
107

Median(F)
35
0.038628118
0.091666667
0.75
0.666666667
7
0.666666667
0.092132022
0.10137092
115
32
0.044191919
0.075757576
0.714285714
0.636363636
7
0.6
0.103376407
0.113793873
93
30
0.034864872
0.090013228
0.851648352
0.780952381
6
0.825757576
0.130010016
0.147592919
137
34
0.043158605
0.053571429
0.689903846
0.6
7
0.571428571
0.08690905
0.097958953
83
33
0.048636364
0.066666667
0.764705882
0.666666667
6
0.7
0.119215309
0.141634331
95
31
0.067424242
0.104166667
0.708333333
0.558080808
7
0.6
0.10723231
0.119035137
94

p-value
3.19E-17
0.00010327
0.307231891
0.007884111
0.000755546
0.182202283
0.006574201
2.04E-05
2.74E-07
0.083404211
4.16E-37
6.54E-06
0.000188026
0.000150319
0.007070388
0.000947644
3.39E-05
0.000460687
5.39E-05
0.008206218
1.95E-26
0.029698627
0.047625203
0.053007773
0.020820651
0.004192441
0.049777976
0.442810363
0.007634682
0.00673959
1.05E-20
0.001836765
0.001008279
0.047765001
0.018700742
0.054633765
0.039914883
0.046129716
0.01688756
0.139541929
5.66E-51
0.202004507
0.012800634
0.472054474
0.141097096
0.233654523
0.495519182
0.257037519
0.223161186
0.013573873
6.12E-09
0.00281239
0.083124805
0.00045222
0.196817044
0.098921715
0.000588954
0.003033951
0.001300769
0.056285977

Table 8: MannWhitney U test between men and women and by movie genre.

32

Genre
Musical
Musical
Musical
Musical
Musical
Musical
Musical
Musical
Musical
Musical
Mystery
Mystery
Mystery
Mystery
Mystery
Mystery
Mystery
Mystery
Mystery
Mystery
Romance
Romance
Romance
Romance
Romance
Romance
Romance
Romance
Romance
Romance
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sci-Fi
Sport
Sport
Sport
Sport
Sport
Sport
Sport
Sport
Sport
Sport
Thriller
Thriller
Thriller
Thriller
Thriller
Thriller
Thriller
Thriller
Thriller
Thriller

Feature
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight

U
18923.5
31309
31851.5
31085
31953.5
30671.5
31199
31495
32155
31556
299382
511460.5
534156
512182.5
502014.5
503329.5
510327.5
535135.5
526377.5
519828
2419166
3387209.5
3509329.5
3321353
3481520
3575369
3322731
3346711.5
3310323.5
3539603.5
87562
159099.5
168266.5
166190.5
163459
168407.5
165481.5
170767
166915
177776
18836.5
19327.5
23440
20763
20805
22075.5
20514
21340.5
19037
21747
821514
1363220
1435399
1454175
1374376
1409367.5
1447459.5
1457615
1432682
1494900.5

Median(M)
39
0.044642857
0.066666667
0.8
0.690909091
6
0.75
0.123660566
0.155498559
139
44
0.064229055
0.081818182
0.760952381
0.6
7
0.692307692
0.111685765
0.135672521
105.5
39
0.083333333
0.109090909
0.777777778
0.582117882
7
0.722222222
0.121533126
0.15475242
112
42
0.078979592
0.100088183
0.769230769
0.583333333
7
0.705882353
0.115872323
0.144101358
103
41
0.088212251
0.116506785
0.75
0.514928699
9
0.666666667
0.096916494
0.124949309
135
43
0.082063492
0.10651341
0.75
0.566666667
7
0.666666667
0.115274452
0.141588868
95

Median(F)
30
0.054444444
0.079861111
0.833333333
0.691666667
7
0.80625
0.123992966
0.161792306
152.5
33
0.049481074
0.089285714
0.75
0.666666667
7
0.666666667
0.110774791
0.127442474
100.5
32
0.070011338
0.100608466
0.75
0.6
7
0.666666667
0.114621794
0.140722332
113
32
0.045436508
0.071428571
0.729020979
0.666666667
7
0.642857143
0.106716646
0.122172161
97.5
34
0.016666667
0.049206349
0.647058824
0.666666667
7
0.5
0.071477478
0.065430363
83
33
0.05042735
0.088888889
0.733333333
0.619047619
6
0.648648649
0.110779371
0.130622185
94

p-value
6.24E-17
0.147010043
0.22699751
0.117765111
0.251068339
0.076823319
0.131591811
0.174486394
0.290705413
0.183798689
4.66E-66
0.025836206
0.376526415
0.029565805
0.004400255
0.005779962
0.021679249
0.404877623
0.192731844
0.090631078
8.11E-94
0.000238122
0.089109724
1.68E-06
0.033891956
0.431392273
1.89E-06
1.37E-05
6.71E-07
0.211472324
4.15E-51
3.96E-05
0.00548229
0.002240595
0.000543829
0.006140502
0.001579692
0.016493957
0.003192407
0.146996378
6.96E-11
4.07E-10
0.000113214
6.87E-08
7.52E-08
3.57E-06
3.02E-08
4.30E-07
1.54E-10
1.44E-06
4.09E-113
9.61E-08
0.00187596
0.011591221
6.56E-07
0.000101276
0.006457798
0.015474972
0.001550184
0.168138507

Table 9: MannWhitney U test between men and women and by movie genre.

33

Genre
War
War
War
War
War
War
War
War
War
War
Western
Western
Western
Western
Western
Western
Western
Western
Western
Western

Feature
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight
Age Filming
Betweenness
Betweenness Weight
Closeness
Clustering
Degree
Degree Centrality
Pagerank
Pagerank Weight
Total Weight

U
30898.5
37718.5
41149
39490
37769
39975.5
39158
42655
40452
42494
14158
22532.5
29978
26103.5
25525.5
29057
25809.5
24152
22135.5
29501

Median(M)
41
0.074074074
0.107142857
0.75
0.571428571
7
0.666666667
0.11552946
0.138445796
75.5
44
0.074814815
0.075
0.818181818
0.618181818
7
0.777777778
0.12060091
0.155330491
97

Median(F)
33
0.045687364
0.084453782
0.695804196
0.660606061
5
0.591666667
0.108120324
0.121234365
59.5
32
0.013333333
0.066666667
0.733333333
0.727272727
6
0.636363636
0.096258617
0.099394992
78

p-value
2.86E-09
0.001715764
0.071879433
0.015530336
0.001883618
0.025438765
0.010772123
0.211011012
0.04062021
0.191689163
3.93E-24
1.04E-08
0.053066361
0.000119929
3.40E-05
0.018342698
6.39E-05
1.24E-06
3.53E-09
0.032522865

Table 10: MannWhitney U test between men and women and by movie genre.

34

Figure 10: The distribution of the label in Bechdel dataset .
35

