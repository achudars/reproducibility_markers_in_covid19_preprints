Eigenvalue Repulsion and Eigenfunction Localization in Sparse Non-Hermitian
Random Matrices
Grace H. Zhang and David R. Nelson

arXiv:1909.08741v2 [cond-mat.dis-nn] 3 Nov 2019

Department of Physics, Harvard University, Cambridge, MA 02138, USA.
(Dated: November 5, 2019)
Complex networks with directed, local interactions are ubiquitous in nature, and often occur with
probabilistic connections due to both intrinsic stochasticity and disordered environments. Sparse
non-Hermitian random matrices arise naturally in this context, and are key to describing statistical
properties of the non-equilibrium dynamics that emerges from interactions within the network structure. Here, we study one-dimensional (1d) spatial structures and focus on sparse non-Hermitian
random matrices in the spirit of tight-binding models in solid state physics. We first investigate
two-point eigenvalue correlations in the complex plane for sparse non-Hermitian random matrices
using methods developed for the statistical mechanics of inhomogeneous 2d interacting particles.
We find that eigenvalue repulsion in the complex plane directly correlates with eigenvector delocalization. In addition, for 1d chains and rings with both disordered nearest neighbor connections and
self-interactions, the self-interaction disorder tends to de-correlate eigenvalues and localize eigenvectors more than simple hopping disorder. However, remarkable resistance to eigenvector localization
by disorder is provided by large cycles, such as those embodied in 1d periodic boundary conditions under strong directional bias. The directional bias also spatially separates the left and right
eigenvectors, leading to interesting dynamics in excitation and response. These phenomena have
important implications for asymmetric random networks and highlight a need for mathematical
tools to describe and understand them analytically.

I.

INTRODUCTION

First suggested for the heavy nuclei problem in the
mid-twentieth century [1], random matrix theory has
been an important, constantly evolving tool in the studies of large systems with otherwise intractable numbers
of degrees of freedom. The first random matrix ensembles, motivated by applications to quantum many-body
systems, imposed Hermitian symmetry and all-to-all interactions. However, the past two decades have seen a
surge of theoretical and experimental progress identifying
and understanding the structure and dynamics of a much
wider variety of real-world complex systems. Because interactions within these systems often have a directional
bias and depend on spatial or functional locality, their
representations as networks and graphs require matrices
that are both asymmetric and sparse [2–6].
The spectral characteristics of sparse non-Hermitian
random matrices provide information on the stability,
susceptibility to perturbations, and synchronization of
biological networks [6–13], guide the construction of practical methods such as graph partitioning and community detection [14, 15], and help evaluate search algorithms [16–18]. In addition, advancements in technology in recent years have mapped out the connectivity of
large biological systems, such as neural and gene regulatory networks [19–22]. These developments motivate the
study of sparse random matrices with spatial structure.
For example, in neural networks, the anatomical or functional distance between neurons or neural clusters significantly affects their connection probabilities [12, 23].
Likewise, layered or recurrent architectures of artificial
neural networks can also be trained by exploiting existing knowledge about the network structure.

Unfortunately, classic random matrix theory tools,
originally developed for symmetric matrices with dense
connectivity [24–27], are not always directly applicable to
these problems. Thus, a better understanding of sparse
non-Hermitian random matrices not only provides rich
opportunities for analyzing and constructing complex
networks, but also opens new doors in mathematics. Recent theoretical progress includes analytical formulations
for the spectral distribution and its support, as well as
statistics of eigenvalue outliers and their corresponding
eigenvector probability distribution [28]. However, one
key spectral observable that has received less attention
is the two-point eigenvalue correlation, which controls
the interplay between eigenmodes central to the behavioral response to external perturbations and small fluctuations.

In this work, we uncover connections between twopoint eigenvalue correlations and the localization of
eigenvectors of structured sparse non-Hermitian random
matrices. We focus here on matrices with the structure of
one-dimensional (1d) tight-binding models in solid state
physics [29], which arise naturally in, e.g., ring attractor neural nets [23, 30] and in more highly connected
networks that nevertheless contain a spatial scale over
which the connections fall off [31]. We also focus on the
effect of random self-interactions on the eigenvalues and
eigenvectors, for both undirected and directed ring networks.

2
A.

Structured sparse non-Hermitian matrices and
neural networks

In general, statistics about the eigenspectra and eigenfunctions are critical for understanding the dynamics of
any system in a linear regime that can be described by
a coupled system of differential equations, which we’ll
represent by a random matrix M. When only a dilute
concentration of weakly localized states are activated, the
eigenfunctions can also be useful for describing the nonlinear dynamics [32]. Of course, level statistics have different physical meanings depending on the specific type
of system being modeled. In this paper, for concreteness,
we will motivate our results in terms of a continuous time
recurrent neural network (CTRNN). If M represents the
connectivity matrix of the neurons, the full nonlinear firing rate model is,


X
dri (t)
Mij rj (t) ,
= −ri (t) + f hi (t) +
τ
dt
j

(1)

where ri is the deviation from the background firing rate
of the neuron on the i-th site, τ is the relaxation time
scale for the local firing rate, hi is the external input
to the i-th neuron (from, say, a sensory system), Mij
describes what is in general an asymmetric connectivity
matrix from neuron j to neuron i, and f [·] is a nonlinear
activation function (often with a sigmoidal shape).
When neural activities are not near saturation, it is
convenient to take an activation function of the “threshold linear” form, f (x) = (x + 1)Θ(x + 1) ≡ [x + 1]+
[30, 33]. When the stimuli exceeds the threshold (x + 1 >
0) so as to trigger a response, the firing model describes
a linear recurrent neural network [23, 31],

τ

X
dri (t)
= −ri (t) + hi (t) +
Mij rj (t),
dt
j

(2)

where the Heavyside function Θ is implied and the offset
can be taken to be 0 without loss of generality by redefining hi (t) → hi (t) + 1. Such a linearized model is capable
of both selective amplification and input integration [23].
Each eigenmode of the matrix M corresponds to a different neural firing pattern; the corresponding complex
eigenvalues indicate the frequency and growth/decay of
the firing pattern, while the spatial support of the eigenvector indicates the spatial distribution of the active neural cluster. In the simplest models, the eigenfunction corresponding to the eigenvalue with the largest real part
dominates the sustained activity. More generally, the
superposition of firing patterns corresponding to nearby
eigenvalues in spectral space typically controls the information transfer and computation carried out by the
neural network in response to various external stimuli.

FIG. 1: Left: Schematic representation of Eq. (3)
studied in this work. The parameters s+ , s− , and d
denote site-specific random variables whose
distributions describe the randomness of the
counterclockwise connections, clockwise connections,
and self-interactions, respectively. Right: The form of
the independent probability distributions for s+ , s−
(Pu (s)) and d (Pv (d)), where the half-box widths u and
v control the ratio of the variance of the connectivity
strengths to their mean magnitude.

B.

Random matrix models

We study one-dimensional networks, whose interactions are dominated by local spatial couplings. As shown
schematically in Fig. 1, this connection scheme corresponds to a banded matrix, familiar in condensed matter
physics as a tight-binding model, written here in a compact Dirac bra-ket notation as
M=

N
X



g
− −g
s+
|jihj + 1| + dj |jihj| ,(3)
j e |j + 1ihj| + sj e

j=1

−
where s+
j , sj , and dj are random variables that can take
on both positive and negative values (thus allowing for
both excitatory and inhibitory connections), g controls
a potential asymmetry of the hopping directional bias
(g > 0 indicates stronger connections in a counterclockwise direction for ring geometries), and  controls the
strength of the random self interactions relative to the
random nearest-neighbor connections. Following previous works [34], we assume balanced inhibition and excitation and investigate symmetric bimodal double-box
probability distributions centered on ±1, for both the diagonal and off diagonal randomness, with box half-widths
u and v as tuning parameters (Fig. 1). As presented in
Eq. (3), this class of models appears to violate Dale’s law
(connections originating from the same neuron must be
all excitatory or all inhibitory [10]). However, as shown in
Ref. [31], the spectra for Eq. (3) are identical with those
of related models that do obey the constraint. Moreover,
if each site in Eq. (3) is regarded as a coarse-grained
representation of a cluster of neurons, we expect that
the same site can exhibit both excitatory and inhibitory
characteristics.

3
In Sec. II to Sec. IV, we study the spectra of Eq. (3)
both with and without disordered self-interactions ( > 0
and  = 0) but no directional bias (g = 0). An important
parameter in the problem then becomes the ratio  of the
self-interaction strength to the neighboring interaction
strength. In the limit of  = 0 with zero variance in the
magnitude of the hopping interaction Pu=0 (s), Eq. (3)
is the random sign model, first proposed in Ref. [35].
We find that its spectrum (shown in Fig. 2) is a fractal
and, via the box-counting algorithm [36], calculate its
boundary fractal dimension to be Dbound = 1.086 ± 0.004
and its area fractal dimension to be Darea = 1.912 ±
0.003. (For comparison, the Hausdorff dimension of the
Julia boundary set for f (z) = z 2 + 14 and the Sierpinski
carpet are 1.082 and 1.8928, respectively [36].)
In Sec. V, we examine Eq. (3) in the case of strong
directional bias g  1 both with and without periodic
boundary conditions, |ni = |N + ni. In particular, we
study a “one-way” model, such that counterclockwise interactions on the subdiagonal vanish. We find particularly striking spectra in the limit when the strengths of
the diagonal and superdiagonal randomness are equal,
for which eigenvalues condense onto the infinity symbol
(lemniscate) curve in the complex plane, along which
there is a continuous variation in the spatial extent of
both the left and right eigenfunctions.

C.

Summary of main results

This paper focuses on three main themes: 1) eigenvalue repulsion in the complex plane and how it correlates with eigenvalue delocalization in 1d non-Hermitian
random matrices; 2) what happens when random selfinteractions are added to random nearest-neighbor interactions in 1d tight-binding random matrices; and 3) the
effect of directional bias on the localization and spatial
separation of the left and right eigenvectors.
We find that significant eigenvalue repulsion in the
complex plane only occurs in the presence of eigenfunction delocalization, and vice versa. Similar results were
obtained for localized and extended states in Hermitian
tight binding models with diagonal disorder in both three
and two dimensions by Shklovskii et al. [37]. We demonstrate this remarkable correlation numerically for 1d nonHermitian matrices described by Eq. (3) with neither selfinteraction nor directional bias in Sec. II and Sec. III, but
emphasize that similar results are obtained for all 1d nonHermitian random matrices we have examined. In Sec. II
and Appendix A, we describe the procedure used for extraction of the local pair correlation function, whose behavior as a function of the eigenvalue separation depends
on the region of the complex spectrum being sampled. In
Sec. III, we discuss the relation between the size of the
eigenvalue correlation hole in the complex plane and the
eigenvector localization length.
Second, we find that adding disordered selfinteractions reduces eigenvalue correlations and enhances

FIG. 2: Top: Spectrum from a single N = 5000
realization of the random sign model (Eq. (3) with
random sign connection probability distribution
Pu=0 (s), and no self-interaction and directional bias
( = g = 0). Bottom: Spectra in the first quadrant of
the complex plane, averaged over 18000 realizations of
N = 5000 matrices. Color indicates the natural
logarithm of the spectral density. Calculation via the
box-counting algorithm [36] gives its boundary fractal
dimension to be Dbound = 1.086 ± 0.004 and its area
fractal dimension as Darea = 1.912 ± 0.003.

eigenvector localization more than random nearestneighbor connections alone in Eq. (3). We study this phe-

4
nomenon for systems both with and without directional
bias, and with and without periodic boundary conditions.
Along the way, we make several interesting observations:
In Sec. IV, upon adding disordered self-interactions to
zero directional bias random nearest neighbor connections, we observe the formation of intricate spectral horns
in the complex plane, which elucidates the nature of level
mixing under increasing inter-site interactions. First order perturbation theory about basis sets focused on collections of self-inhibiting and self-exciting nodes successfully captures eigenvalue spreading in the limit of weak
interactions, and we observe a two-dimensional analog of
electronic band structure in the complex plane for this
disordered system.
Finally, in Sec. V, we study the interplay between
directional bias and boundary effects. The large cycle
embodied in a ring with periodic boundary conditions,
coupled with strong directional bias, leads to eigenvalues confined to a collection of one-dimensional spectral
curves with a nontrivial continuous spectral flow connected with eigenvector localization. We identify the
spectral curves with equipotential surfaces, generated by
charges placed in the complex plane according the probability distribution of the diagonal coefficients. Interestingly, nonzero directional bias leads to the spatial separation of left and right eigenvectors with the same eigenvalue. The formal and physical implications of the asymmetry between left and right eigenvectors is explored in
Appendix B.
This paper concludes with a discussion of the physical
implications of these results as well as open mathematical
questions.

II.
A.

EIGENVALUE CORRELATIONS

Random matrix eigenliquid and the statistical
mechanics of interacting particles

To identify two-point eigenvalue correlations, we treat
the eigenvalues as interacting particles in the complex
plane and utilize concepts from statistical mechanics. In
this section, we outline and demonstrate this method using the complex Ginibre ensemble. The reader is referred
to Appendix A for more details.
The complex Ginibre ensemble [24] consists of random
matrices whose every element has real and imaginary
parts separately drawn from independent Gaussian distributions (Mjk = Mx,jk + iMy,jk where P (Mx/y,jk ) ∼
2
exp(−Mx/y,jk
/2)). Its eigenvalue joint probability distribution function (JPDF) is known analytically:




N
X
X
1
1
P ({λ}) ∼ exp −βN 
|λi |2 −
ln |λi − λj |
(4)
,
2
2N
i=1

FIG. 3: (a) Left: spectrum of a single N = 1000
realization of the complex Ginibre ensemble, where the
real and imaginary parts of every matrix element are
independently drawn from a Gaussian distribution with
mean 0 and variance 1/2N . Right: pair correlation
function g(r), where ~r = (Re(λ − λ0 ), Im(λ − λ0 )) is the
separation between two eigenvalues λ and λ0 on the
complex plane, numerically extracted from and
averaged over 20 realizations of N = 5000 matrices from
the Ginibre ensemble. Blue shading describes a
correlation hole between g(r) and 1 when g(r) < 1; red
shading highlights the small region between g(r) and 1
where g(r) > 1. The radial distribution function g(r)
vanishes quadratically as r → 0, indicating logarithmic
inter-particle repulsion at short distances with β = 2,
and eventually approaches 1 as r increases, indicating
the decay of correlations at large separation distances.
The black dashed line plots the analytical expression
obtained from direct mapping to a one-component
two-dimensional (2d) plasma, as shown in Ref. [38]. (b)
Left: spectrum of a single N = 1000 realization of a
random matrix where the real and imaginary parts of
every matrix element is independently drawn from a
uniform distribution with mean 0 and variance 1/2N .
The spectrum looks qualitatively similar to that of the
Ginibre ensemble. Right: pair correlation function g(r),
averaged over 20 realizations of N = 5000 random
matrices draw from the uniform distribution. The g(r)
curve follows the same functional form as that of the
Ginibre ensemble in (a), illustrating the universality of
the correlations embodied in Eq. (4).

i6=j

where the inverse temperature β √= 2 and the eigenvalues have been scaled as λi → λi / 2N . From Eq. (4), it
is apparent that the eigenvalue distribution map exactly

onto a 2d Coulomb gas under a central harmonic potential. The resulting spectrum follows a “Circular Law”,
in the sense that eigenvalues are uniformly distributed

5
inside a unit circle in the complex plane, with the fraction of eigenvalues lying outside the circle vanishing in
the limit N → ∞ (see Fig. 3a) [38]. As also shown in
Fig. 3b, similar results are obtained when the Gaussian
distribution is replaced by a box distribution, illustrating that the results for the Ginibre ensemble are universal
for a large collection of random matrices with all-to-all
connectivities [39].
Within the uniform disk, however, Eq. (4) predicts that
eigenvalues experience logarithmic inter-particle repulsion. The key quantity used to characterize correlations
among interacting particles in equilibrium statistical mechanics is the radial distribution function (or pair correlation function) g(r), defined in two dimensions as [40]
*
+
1 X
ρg(r) = ρ(r) =
δ(r − |~ri − ~rj |) ,
(5)
N
i6=j

where ρ =

DP

j

E

δ(~r − ~rj ) is the average single particle

density and the brackets h· · · i denote average over different realizations of the particle positions {~rj }. For a
particular realization of an ensemble, g(r) indicates the
probability of finding a second particle a distance r away
from some first particle, given that the first particle exists
in that realization.
By generating multiple realizations, and upon identifying a two-dimensional vector ~rn = (Reλn , Imλn ) with
each complex eigenvalue λn , we can count all eigenvalue
pairs within a range of separation distances. After properly normalizing, we obtain numerically the radial distribution function for the Ginibre ensemble. As seen in
Fig. 3a, g(r) for the Ginibre ensemble contains a√correlation hole at small r, with a size that scales as 1/ N , the
typical separation distance between the rescaled eigenvalues in the complex plane. In fact, g(r) vanishes quadratically as r → 0, consistent with the logarithmic interparticle repulsion in Eq. (4) with β = 2. As r increases,
g(r) grows and approaches 1, indicating the decay of correlations at long separation distances, at which particles
no longer affect each other. These behaviors are con2
sistent with the analytical expression g(r) = 1 − e−N r ,
derived from direct mapping onto a one-component 2d
plasma [38]. Note the qualitatively similar behavior for
the box distribution shown in Fig. 3b, again illustrating
the universality of the Ginibre results for large rank random matrices with independent elements selected from
two different probability distributions.
In evaluating the pair correlation function g(r) for the
Ginibre ensemble, we were able to assume a uniform
~ = ρ ∀R
~ ∈ unit disk).
ensemble-averaged density (hρ(R)i
However, as seen in Fig. 2, the eigenspectra of the random
sign model corresponds to a 2d fluid with both anisotropy
~
and an inhomogeneous density ρ(R).
In this case, the
pair correlation function does not depend only on the
distance between two particles, but more generally also
on the global coordinates of the two particles (~r1 , ~r2 ).
Thus, we will now let g(r) → g(r)R~ , which describes the

probability of finding a particle at ~r2 a distance r away
from some particle at ~r1 , given that there is a particle
at ~r1 and the mean location of the eigenvalue pair is
~ ≡ (~r1 + ~r2 )/2.
R

B.

Level repulsion in nearest neighbor hopping
models in one dimension

We first examine a nearest neighbor hopping model
in 1d with no directional bias and no self-interaction
(g =  = 0 in Eq. (3)), while varying the box-width parameter u of the probability distribution for the hopping
term Pu (s) (Fig. 1) from u = 0 (random sign model) to
u = 1 (single box model). The reason for these choices
of parameters will become clear in Sec. III; the resulting
spectra strongly suggest that our findings apply more
generally to a broad class of sparse non-Hermitian random matrices.
Due to a singular spike in eigenvalue densities on the
real and imaginary axes (see Fig. 2 and Ref. [31]), we extract our local pair correlation function g(r)R~ (denoted as
g(r) henceforth) for the bulk eigenvalues inside quadrants
I–IV and along the real and imaginary axes separately.
We treat the former as a two-dimensional inhomogeneous
fluid and the latter as a one-dimensional inhomogeneous
fluid (see Appendix A for details on numerical methods
and normalization procedure). We approximate the 2d
eigenfluid inside the various quadrants to be isotropic and
justify this approximation in Appendix A 3 by examining
the weak directional variation of g(r) when r is fr from
the coordinate axes. Each local pair correlation function g(r) shown in Figs. 4 and 5 is averaged over a small
region of the spectrum within which the eigenvalue density is approximately homogeneous. The right column of
Fig. 4 shows the spectra for u = (0, 0.1, 0.5, 0.9), averaged over 100 realizations for each value of u. As u
increases, one can observe that the exact and statistical
symmetries of the eigenvalue distribution, as well as its
overall diamond-like shape, stay the same [31], but details
of the fractal edges become smeared out. Our findings
for two-point eigenvalue correlations are as follows:
First, eigenvalues at a distance sufficiently far from the
origin, and also not too close to the spectral edges so as
to experience boundary effects, are uncorrelated (as in an
ideal gas) for all values of u. However, eigenvalues close
to the origin behave differently. For u = 0, where the
nearest neighbor matrix elements are randomly chosen
to be ±1, g(r) dips significantly below 1 as r approaches
0 and vanishes for r = 0, whereas for large r, g(r) grows
and plateaus to 1 (Fig. 5 and Fig. 4). This behavior is
reminiscent of that of the bulk eigenvalues of the Ginibre
ensemble in Fig. 3. In other words, we discover that
for the random sign model, eigenvalues near the origin
experience inter-particle repulsion.
The exact form of the repulsion is different from that
of the Ginibre ensemble, as g(r) approaches 0 for small r
with a different functional form than the quadratic van-

6
ishing we see in Fig. 3 (Sec. III). The left of Fig. 4 shows
examples of g(r) for the eigenvalues close to the origin,
averaged over (710770, 54000, 54000, 423000) realizations
for u = (0, 0.1, 0.5, 0.9), respectively. The regions of
the spectra for which we evaluate the local g(r) are indicated by small, white, off-center squares on the right
of Fig. 4. As the box-width u increases, the region near
the origin of the complex plane in which eigenvalue pairs
experience repulsion with each other shrinks. When u
is large enough, the eigenvalues are entirely uncorrelated
and the correlations approximate those of an ideal gas
everywhere in the spectrum.
We have applied the same analysis to eigenvalues on
the real and imaginary axes, treating them as 1d ensembles. The statistical symmetry of the spectra under 90◦
rotation [31] insures identical behavior on these two axes.
Since axial eigenvalues near the edge of the spectra exhibit fractal modulations in the eigenvalue density, we
examine axial eigenvalues in the region near the origin of
the complex plane, where the average eigenvalue density
increases linearly along the axis, with increasing distance
from the origin [31]. The behavior of g(r) for the axial
eigenvalues in this region, as a function of probability
distribution box-width u, is qualitatively consistent with
that of the bulk correlations. Specifically, the range and
strength of 1d eigenvalue repulsion along the axes, as well
as the radial extent along the axes in which eigenvalues
experience that repulsion, are largest for u = 0 and decreases as u increases. The correlations vanish as u → 1.
Finally, we also examined the evolution of the eigenspectra under other balanced bimodal distributions,
specifically a bimodal Gaussian distribution centered at
±1. The results are qualitatively similar: as the variance
of the Gaussian increases, delocalized states and eigenvalue repulsion both disappear.

III. EIGENVALUE REPULSION AND
EIGENFUNCTION DELOCALIZATION

What determines the regions in the eigenspectra over
which the eigenvalues experience inter-particle repulsion?
To better understand our findings in the previous section,
we examine the localization properties of the eigenfunctions.
The main metric we use to characterize the degree of
localization of an eigenfunction is the Inverse Participation Ratio (IPR), defined as follows: For the n-th eigenvalue λn , the IPR of the right eigenfunction ψnR is
" P
 #−1
R
2 2
i |ψn (i)|
P R 4
IPR(λn ) ≡
,
(6)
i |ψn (i)|
where |ψnR (i)| is the amplitude of the n-th right eigenfunction at site i. Here, we focus on localization properties of the right eigenfunctions of the asymmetric random
matrices. The left eigenfunctions, as well as the the inner product of the left and right eigenfunctions, behave

FIG. 4: Eigenvalue pair correlation functions (left) and
eigenvalues colored according to the IPR of their
corresponding eigenvectors (right) for zero diagonal
randomness ( = 0) and no directional bias (g = 0) in
Eq. (3). Correlation functions and IPR values are
averaged over (710770, 54000, 54000, 423000) and (100,
100, 100, 100) realizations of rank N = 5000 matrices,
respectively, for random hopping strength variance
u = (0.0, 0.1, 0.5, 0.9) (see Fig. 1 for Pu (s)). For each
value of u (increasing from top to bottom), the pair
correlation function g(r), with mean eigenvalue pair
~ within the small white box on each spectrum,
location R
is plotted. For small u, the region near the origin of the
eigenspectra contains more highly delocalized
eigenstates; eigenvalues in that region experience
inter-particle repulsion. As u increases, the localization
lengths near the origin of the complex plane decrease
and the eigenvalues there become de-correlated.

7

FIG. 5: (a): Local pair correlation functions g(r)
examined for eigenvalue pairs in the 9 (0.05 × 0.05)
square grids closest to the origin of the complex plane,
enclosed by the magenta box in the u = 0 random sign
spectra [colored by average eigenvalue density (left) and
eigenvector IPR (right)]. (b): Numerical correlation
data of the random
sign
h 
α ispectra fit to
r
gs (r) = 1 − exp − rcorr
. (c): Quantities
corresponding to eigenvalues in each of the 9 squares
grids. As eigenvalue magnitude increases, the
correlation hole width rcorr decreases, the exponent α
decreases, and the average IPR of the corresponding
eigenvectors increases. (d): Logarithm of the inverse
−1
correlation hole width rcorr
versus IPR, corresponding
to eigenvalues in the 16 square grids closest to the
origin of the complex plane (including the 9 shown in
(b) and (c)). The linear fitting shows exponential
dependence, from which Eq. (8) follows.

in a similar fashion for g = 0 (see Appendix B). The IPR
varies from being O(1/N ) for eigenfunctions spread uniformly across all sites, to O(1) for those localized near a
specific site. For each spectrum examined in this work,
we have also calculated the Lyapunov exponents and confirmed that they are consistent with the behavior of the
IPR.
Heat maps of the IPR for the random hopping eigenspectra with box-widths u = (0.0, 0.1, 0.5, 0.9) are shown
on the right of Fig. 4. For u = 0, the localization
lengths of the eigenfunctions diverge as their eigenvalues approach the origin, as analyzed in detail in Ref. [31].
More generally, for small u, there is a region near the origin of the eigenspectra that contains rather delocalized
eigenstates. Note that as u increases, the region of extended states centered at the origin of the complex plane
shrinks and disappears, such that the complex plane is
eventually populated entirely by localized eigenstates as
u → 1.
These findings correlate strongly with our results on
eigenvalue repulsion from the previous section: the eigenvalue repulsion near the origin is only present when the
more extended eigenvectors are also present. Conversely,
when states are highly localized, as near the edge of the
spectrum for u = 0, or everywhere in the complex plane
for u = 0.9, there is no level repulsion and the eigenvalues
behave like an ideal gas. We have observed this connection between eigenvalue repulsion and extended eigenstates for all non-Hermitian random matrices we have
examined. There is no way for highly localized eigenfunctions at very different locations in a one-dimensional
lattice to know about each other, so it is plausible that
their eigenvalues are uncorrelated. Similar correlations
for eigenvalue spacings along the 1d real axis and Anderson localization have been seen in various Hermitian disordered systems by studying the nearest-neighbor spacing distribution (see for example [37, 41]). We conjecture
here, for non-Hermitian random matrices with a complex spectrum, that when the eigenfunctions are delocalized, their complex eigenvalues repel each other, and
conversely, when eigenvalues repel each other, their eigenfunctions are delocalized.
We can make this connection more precise using the
spectra of the u = 0 random sign model. Fig. 5 shows
the local correlation functions g(r) in the 9 (0.05 × 0.05)
square grids closest to the origin of the complex plane,
enclosed by the magenta box in the spectra shown in the
top panel. Motivated by the correlation function of the
Ginibre ensemble gG (r) = 1 − exp(−N r2 ) (Fig. 3), we
fit the numerical correlation data of the spectra for the
u = 0 random sign model to the following function,
 
α 
r
gs (r) = 1 − exp −
,
(7)
rcorr
which allows us to extract the width of the correlation
hole rcorr and the exponent α characterizing the vanishing of the correlations as r goes to 0. As shown in Fig. 5c,
as the magnitude of the eigenvalue (i.e. its distance

8
from the origin) increases, the correlation hole rcorr decreases (the spatial extent of the inter-particle repulsion
shrinks) and the exponent α decreases (the correlation
function g(r) approaches 1 more sharply as r increases).
−1
Furthermore, the inverse correlation hole width rcorr
appears to depend exponentially on the IPR (Fig. 5d). In
one-dimensional systems, the IPR is in fact just the inverse of the localization
length lloc [42]. Upon√rescaling
√
r̄corr = rcorr N and ¯lloc = lloc /N , where 1/ N is the
average interparticle spacing of N eigenvalues spanning a
2d complex spectrum of area O(1) and ¯lloc measures the
fraction of the N -site ring occupied by an eigenfunction,
we find that the eigenvalue correlation hole width r̄corr
and the eigenvector localization length ¯lloc are related as
follows:


c2
r̄corr = c1 exp − ¯
,
(8)
lloc
where c1 = 2.4±0.2 and c2 = 0.196±0.005. According to
the conjecture embodied in Eq. (8), r̄corr vanishes in the
limit of strongly localized eigenvectors (¯lloc → 0) and increases when eigenvectors become more delocalized (¯lloc
increases) .
The interpretation of this relation between eigenvalue
repulsion and eigenvector delocalization for neural networks is as follows: The n-th eigenmode of the connectivity matrix M in a dynamical model like Eq. (1) corresponds to a firing pattern ψn (i); the pattern is selectively
distributed over certain neurons according to the sites
i at which the eigenfunction amplitude is nonzero, and
these neurons collectively fire, with growth or decay, and
oscillations of the firing rates controlled by the complex
eigenvalue λn . Given two distinct firing patterns corresponding to two eigenmodes of the connectivity matrix
M, the higher the number of active neurons participating in each of these firing patterns (i.e. the more delocalized the normal modes), the more separated their firing
frequencies and growth/decay rates, represented by the
eigenvalues in the complex plane.
We also comment on the universality of eigenvalue correlations for large rank random matrices. First, recall
that, as illustrated in Fig. 3, eigenvalue correlations of
dense non-Hermitian random matrices are insensitive to
changes in the specific shape of the matrix element probability distribution. For example, in the Ginibre ensemble,
each matrix element is independently drawn from a Gaussian distribution, yielding the correlations in Fig. 3a. If
the elements were instead drawn from a box distribution with the same mean, the pair correlation function
g(r) does not change except up to a possible rescaling of
r [43], as illustrated in Fig. 3b. In contrast, the sparse
one-dimensional non-Hermitian random matrices studied
here are more sensitive to variations in the matrix element probability distribution (see Fig. 4). The eigenvalue
correlations change qualitatively with the parameter u in
the matrix element probability distribution. Nevertheless, the behavior of the spectra for the large N random
one-dimensional hopping models considered so far are in-

variant to changes in boundary conditions (open or periodic). This insensitivity to boundary conditions will be
violated dramatically for the models with directional bias
examined in Sec. V of this paper.

IV.

EFFECTS OF SELF INTERACTION

FIG. 6: Top: Spectra of Eq. (3) with random sign
nearest-neighbor coupling probability Pu=0 (s) and
random sign self-interactions distribution Pv=0 (d) as
the self interaction strength  is tuned from 0 to 1.
Bottom: Spectra of Eq. (3) when random
self-interaction and random hopping have equal
strengths, with g = 0 and  = 1. Eigenvalues form four
new horn-like boundaries hovering above and below ±1
along the real axis, which are the values of the diagonal
elements ±. Compared to the random sign hopping
spectrum at the top of Fig. 4, the addition of random
on-site disorder removes both the eigenvalue repulsion
and the weakly localized eigenstates near the origin of
the complex plane. The lower inset shows the radial
~ in
distribution function g(r) with mean pair location R
the small white box near the origin, averaged over 9000
realizations of N = 5000 matrices. The pair correlation
function g(r) is a flat line at 1, showing the eigenvalues
behaving like an ideal gas with no correlations.
Generally,
network models incorporate selfinteractions via nonzero diagonal elements. In biological
networks, these feedback effects are referred to as
“self-inhibition” (or “self-regulation”) when the diagonal
matrix element is negative, and “self-excitation” when

9
the diagonal matrix element is positive. In condensed
matter physics, such couplings are exemplified by
“onsite-disorder” [44]. In this section, we take  > 0,
the strength of the diagonal disorder in Eq. (3), in
order to study the effects of self-interactions through
probabilistic on-site elements with random signs in the
connectivity matrix M of, say, a neural network. In
general, one could consider a wide variety of probability
distributions for the self-interacting coefficients. We
focus our attention here on the case of the random sign
distribution Pv=0 (d) for the diagonal matrix elements
(identical in form to the probability distribution Pu=0 (s)
for the random nearest-neighbor connections), because it
exhibits important new features and is tractable enough
for analysis.

A.

Eigenfunctions in an eigengas generated by
diagonal disorder are localized.

How do disordered self-interactions affect the spectrum
and the localization of its eigenfunctions compared to
the hopping-only random sign model? To answer this
question, we first study Eq. (3), with g = 0 and strictly
bimodal ±1 interactions for both the hopping and diagonal matrix elements, i.e. with probability distributions
Pu=0 (s) and Pv=0 (d) shown in Fig. 1. However, we now
vary the relative magnitude of the diagonal disorder by
tuning the parameter  > 0.
Upon turning on the random self-interaction strength
 with diagonal probability distribution Pv=0 (d) (i.e. the
diagonal matrix elements are ±, each with probability
1/2), the nearly extended states shown near the origin
at the top panel of Fig. 4 start to disappear. By the
time  reaches 1, such that the self-interactions have the
same level of disorder as the hopping interactions, all
eigenstates are strongly localized. The resulting eigenvalue distribution and variation in eigenvector localization, averaged over 200 realizations, are shown in Fig. 6.
Examination of eigenvalue correlations reveal the radial
distribution function g(r) ≈ 1 for all regions in the complex plane within the spectral support. An example is
shown in the inset of Fig. 6. In other words, the addition
of strong diagonal randomness decorrelates all eigenvalues; the eigenfluid studied in Sec. II has lost its interparticle interactions and behaves instead as a 2d ideal
gas. We performed the same analysis for nonzero distribution box-width u > 0, and found the same results
qualitatively—eigenvalues do not experience correlations
and all eigenvectors are strongly localized. These results
are consistent with our findings from Sec. III, and confirms our conjecture that localized eigenfunctions lead to
no level repulsion.

B.

Spectral horn formation and complex level
mixing in the complex plane

The second intriguing feature of Fig. 6 is the accumulation of eigenvalues onto a pattern of spectral “horns”,
whose real parts are predominantly at ±1 on the complex
plane. (For large N random matrices with g = 0, these
and other features of the spectra described here and in
the following are insensitive to applying open or periodic
boundary conditions, as for the random hopping model.)
It is useful to observe the formation of these spectral horns from a different regime, starting with strong
self-interactions and negligible interactions between sites
( → ∞). As  is gradually reduced, the random hopping terms, with probability distribution Pu=0 (s), become more important, and the eigenspectra evolve as in
Fig. 7. The spectral horns at ± emerge because the selfinteraction coefficients are distributed at ±. When hopping interactions are turned on, eigenvalues bloom from
their degenerate point condensations on the real line into
almost-continuous patches in the complex plane. This
phenomenon is the non-Hermitian analog of band theory in quantum condensed matter, where, when isolated
identical atoms are brought closer together and begin interacting as they do in dense solids, single-atom energy
levels broaden into a continuous electronic band structure.
In the context of neural networks, the atomic orbitals
which lead to discrete energy levels are replaced by selfinhibiting and self-exciting neurons. For large , if one
scales out , these neurons at first do not interact with
each other, and exhibit locally either purely growing and
saturating or purely decaying firing rates. As  is decreased and connections between neurons become more
important, the eigenspectrum expands about ± on the
real axis, and the firing patterns each spread out over
more participating neurons (marked by the small but
noticeable decrease in the IPR for eigenfunctions with
eigenvalues close to the origin in Fig. 6) and experience a richer set of oscillatory and growth/decay behavior. However, the presence of self-inhibition and selfexcitation still dominates the dynamics. For the situation shown in Fig. 7, with the spectrum centered on the
origin, the eigenmodes separate into a group of mostly
growing modes and a group of mostly decaying modes,
as indicated by the high density patches of eigenvalues
within the spectral horns centered at ±. We study this
phenomena quantitatively and extract further physical
insights using a perturbative approximation in the following section.

C.

Perturbation theory in 1/

Given a connectivity matrix M, one can always reshuffle the basis to restructure M in terms of the following
matrix blocks: the matrix of all connections between neurons that are self-excitatory M+1 , the matrix of connec-

10
in block diagonal form. Upon comparing the eigenvalues
of Eq. (??) to those from the exact diagonalization of the
full matrix M, we see that this perturbative approximation captures the start of the spectral bloom perfectly
(top right panel of Fig. 7).
For neural networks, this approximation implies that
when the random hopping interaction strengths are weak
compared to the self-interactions, the neural network
can be approximated by two sub-networks of only selfexciting neurons and only self-inhibiting neurons, and
connections between the subnetworks can be neglected
(see schematic at top left of Fig. 7).

V.

FIG. 7: Spectra of Eq. (3) with random sign hopping
−
Pu=0 (s) (i.e. s+
j and sj = ±1 with equal probabilities)
and random sign self-interactions Pv=0 (d), where the
self-interaction strength is much greater than the
hopping interaction strength,   1. The clustering of
eigenvalues around the spectral horns at ± is due to
the self-interaction coefficients being distributed at
these values. When hopping interactions are turned on,
eigenvalues bloom from their degenerate point
condensations at ± on the real line into two
almost-continuous patches in the complex plane. Top
right: First order perturbation theory in 1/ about a
system of two disconnected sub-networks, consisting of
only self-exciting neurons or only self-inhibiting neurons,
captures the start of the spectral blooms at  = 104 .
The neural connections kept in this approximation are
shown schematically in the upper left.
tions between all neurons that are self-inhibitory M−1
(we explicitly exclude diagonal matrix elements from
M+1 and M−1 ), the matrix of connections from selfexciting neurons to self-inhibiting neurons C+− , and the
matrix of connections from self-inhibiting neurons to selfexciting neurons C−+ :

 

1 +
0
M+1 C+−
M= N
+
,
(9)
0 −1N −
C−+ M−1
where N + and N − is the number of self-exciting and selfinhibiting neurons, respectively, and M±1 and C±∓ all
contain elements of order O(1). For 1/  1, one can
neglect the off-diagonal matrices C+− and C−+ , since
their contribution to the eigenvalue vanishes to first order in perturbation theory. M can then be approximated

COUPLING SELF-INTERACTIONS WITH
STRONG DIRECTIONAL BIAS

Thus far, we have examined Eq. (3) for different scenarios all without directional bias (i.e. g = 0 in Eq. (3)).
The parameter g controls the directionality, or orientability, of the network, and has been examined in the context
of random hopping models motivated by vortex physics in
high temperature superconductors and neural networks
[31, 45]. In this section, we study the infinite bias limit
of an oriented network (the “one-way” model of Feinberg and Zee [35]) with the addition of random selfinteractions.
Mathematically, an “oriented graph” is a graph where
there can only exist one directed connection between any
pair of nodes. In the language of the matrix model in
Eq. 3, only one of Mij and Mji can be nonzero. In the
case of a 1d ring network, the most interesting case is
when all connections are pointed in the same direction.
If the directionality is counter-clockwise, M has only a
nonzero superdiagonal and a zero subdiagonal, as well as
a nonzero corner matrix element in the lower left. (Clockwise directionality leads to similar structure on the subdiagonal and in the upper right corner.) Such systems can
be understood via the recursion relation for the cofactor
expansion of a cyclic, tridiagonal matrix, from which one
can easily show that the eigenvalues all condense onto ±
for all other cases. A schematic of such a network, which
we examine in the following subsections, is shown at the
top left of Fig. 10.

A.

From resolvent to eigenvalue distribution: an
electrostatics connection

There are well-known connections [28, 32, 46] between
non-Hermitian random matrix theory and 2d electrostatics in the complex plane. For example, the trace of the
resolvent (or Green’s function) of a random matrix M,
G(z) =

1
,
M−z

(10)

is related to an electrostatics potential φ, whose corresponding charge distribution gives us the eigenvalue den-

11
sity of states ρ(z) in the complex plane:
∂2
4
∂z̄ Tr G(z) = −
φ(x, y)
N
∂z∂ z̄
 2

∂
∂2
=−
+
φ = −4πρ(z),
∂x2
∂y 2

(11)
(12)

where x and y respectively denote the real coordinate and
the imaginary coordinate, and z and z̄ denote a complex
number x + iy and its conjugate. Note that TrG(z) is
itself closely related to the electric field associated with
the charge distribution ρ(z). For sparse, oriented, and
locally tree-like graphs with no cycles, the trace of the
resolvent can be calculated via the cavity method [28]:
Tr G(z) =

N
X
j=1

1
.
dj − z

(13)

Note that this result depends on the random diagonal
elements of M, and is independent of any random offdiagonal elements of M. According to Gauss’s law of
electrostatics, the charge distribution on an equipotential
surface generates, in the region of space that is otherwise
without charge, the same electric field that results when
all charges act as if they are concentrated at the origin
of the complex plane.
For a bidiagonal “one-way” matrix M (accessible by
taking an appropriate g → ∞ limit in Eq. (3), see below)
with no corner element (i.e. Eq. (3) without periodic
boundary conditions) and hence no cycles, Eq. (13) tells
us that ρ(z) = 0 for |z| > maxj dj [28]. This conclusion
also holds for any non-cyclic bidiagonal matrix, where
the eigenvalues simply take on the values of the diagonal
elements λj = dj .
However, upon imposing periodic boundary conditions, the spectral distribution changes dramatically and
leads to a rich variety of eigenvalue correlations and
eigenvector localization within the spectrum. In the next
subsection, we examine the model in Eq. (3) with selfinteractions  ≥ 0 and strong (counter-clockwise) directional bias g → +∞. To have a well-defined limit, we
rescale the matrix M in Eq. (3), and study the properties of M0 = e−g M in the limit g → ∞, setting 0 = e−g .
Thus, we shall be interested in the spectra and eigenvalues of
X

0
M0 =
s+
(14)
j |j + 1ihj| +  dj |jihj| ,

FIG. 8: Left: When the network in Eq. (3), rescaled as
M0 in Eq. 14, has absolute directionality (the limit
g → +∞ in Eq. (3) up to rescalings), the eigenvalue
spectrum collapses onto a 1d curve that corresponds
exactly to an equipotential surface resulting from a set
of charges placed on the complex plane according to the
probability distribution of the diagonal coefficients
Pv (d). The potential V of the spectral curve is
determined by ln 0 (Eq. (18)). Equipotential curves
with negative potentials V = ln 0 < 0 expand outwards
away from the two central charges and, in the limit of
0  1, recovers the radially symmetric eigenvalue
distribution for a zero-diagonal one-way hopping
matrix. Top left: The diagonal coefficients follow the
random sign distribution. In the limit of large N , the
spectra correspond to the equipotential surfaces
resulting from two like charges placed at ±1 on the real
line. Bottom left: The distribution of diagonal
coefficients corresponds to placing four like charges at
±1 and ±0.5 on the real line. Right panels: Inverse
participation ratios, as random self-interactions start to
dominate over hopping disorder (0  1), the spectrum
becomes more localized with the most localized states
occuring near the central charges; each equpotential
curve is colored according to eigenvector IPR averaged
over 20 realizations of matrices with rank N = 300.

j


where 0 is fixed and s+
and {dj } are random numbers
j
drawn from the bimodal probability distributions Pu (s)
and Pv (d) displayed in Fig. 1.
B.

Spectral curve confinement: another
electrostatics connection

As shown in Fig. 8, upon imposing absolute directionality onto the network in Eq. (3), the spectrum becomes

confined to a one-dimensional locus in the 2d complex
plane. As we now show, this curve is exactly the equipotential surface resulting from a charge distribution placed
in the complex plane according to the probability distribution of the diagonal elements Pu (d), with the potential
determined by the log-mean of ratio of the superdiagonal hopping magnitude s+ to the strength of the rescaled
diagonal disorder 0 , hln |s+ /0 |i.
To derive this result, consider the oriented random connectivity matrix M0 defined by Eq. (14) as displayed be-

12
low,
 0

 d1 s+
0
1
 0 0 d2 s+

0
2




.
.
.. ..




+
0
 , (15)
0

d
s
M0 = 
j
j+1




.
.
..
..




+
0

0
0  dN −1 sN −1 
s+
0
0 dN
N
and use a cofactor expansion to calculate the characteristic polynomial for the eigenvalues,
!

N 
N
Y
Y
s+
λ
j
N −1
dj − 0 = (−1)
.
(16)

0
j=1
j=1
We first multiply Eq. (16) by its complex conjugate, and
then take the square root and logarithm of both sides.
We then note that


N
1 X
s+
s+
lim
ln 0 ≡ ln 0
,
(17)
N →∞ N


j=1
where the RHS results from application of the law of large
numbers. In the continuous limit, relabeling dj → d, and
λ
rescaling 0 → λ, we find that the spectral curves of

Fig. 8 satisfy


Z
s+
1
= − ln 0
dd0 ρ(d0 ) ln 0
≡ V, (18)
|d − λ|

where ρ(d0 ) ≡ Pv (d0 ) is the probability distribution of the
diagonal random variable.
From Eq. (18), an analogy with two-dimensional electrostatics is immediately apparent: ρ(d) is the distribution of like charges in the complex plane, while the potential V experienced by a test charge on the equipotential surface is given by the log-mean of the absolute value of the hopping variable times the ratio of
the hopping Dinteraction
E strength and the self-interaction
s+
strength: − ln 0 . In the special case of the bimodal
box distribution Pu (s) with box distributions centered at
±1 for the hopping matrix elements, hln |s+ |i = 0, and
the potential determining the spectral curve is just ln 0 .
This connection is explicitly illustrated in Fig. 8. For
a random sign diagonal distribution Pv=0 (d) and bimodal hopping term distribution Pu (s) with equal selfinteractions and hopping strengths 0 = 1, ρ(d) ≡
Pv=0 (d) = 12 [δ(d − 1) + δ(d + 1)] and Pu (s+ ) = U(−1 −
u, −1+u)+U(1−u, 1+u), where U denotes the bounded
uniform distribution shown in Fig. 3. Eq. (18) for the
eigenvalue distribution then assumes a particularly simple form,
1
(ln |1 − λ| + ln |1 + λ|) = 0,
2

(19)

which explains the infinity-shaped spectral shapes shown
in the top panels of Fig. 8. This relation holds true regardless of the value of the box-width u of bimodal distribution of the nearest neighbor connections s+ , as long
as N is large enough for central limit theorem to apply.
Eq. (19) reveals that the complex eigenvalues must lie on
the V = 0 equipotential surface resulting from two like
charges placed at ±1 on the real line.
On the other hand, if the random self-interaction
strength becomes stronger than the hopping strength
0 > 1, then the potential V of the equipotential curve as
indicated on the RHS of Eq. (18) becomes positive. With
increasing 0 , the eigenvalues condense onto equipotential
surfaces ever-closer to the central source charges on the
real line.
When the nearest-neighbor connections instead exceed
the self-interaction strength, 0 < 1, the potential V of
the equipotential curve decreases to negative values and
the spectral curves expand farther away from the charges
determined by the diagonal elements. In the limit of
0  1, i.e. V → −∞, the complex eigenvalues are large
enough so that the charge distribution created by the
diagonal disorder appears as a single point charge at the
origin, which recovers the radially symmetric eigenvalue
distribution for a zero-diagonal one-way hopping matrix
[31].
Eq. (18) holds true for any probability distribution ρ(d) of the diagonal element.
The
bottom panels of Fig. 8 show the evolution of
equipotential spectral curves for variable Pu (s) and
with
the diagonal probability distribution

 ρ(d) =
1
1
1
)
+
δ(d
+
)
+
δ(d
+
1)
δ(d
−
1)
+
δ(d
−
.
4
2
2
It is important to note, however, that although
Eq. (18) tells us where the eigenvalues are allowed to be—
on an equipotential curve–it does not reveal how they are
distributed on the curve, nor does it reveal how the IPR
behaves on this curve. These issues are addressed in the
next section.
C. Continuous evolution of eigenvector localization
length and eigenvalue correlations along the spectral
curve

It is known that the eigenspectra for the directional
networks, with s+
j = ±1 random hopping but no disorder
on the diagonal, have strongly delocalized eigenvectors
similar to plane waves [31]. Indeed, after making a simple similarity transformation determined by the paricular
realization of the superdiagonal disorder, eigenvalues and
eigenvectors can be found analytically to be
λkn = eg+ikn
1
hx|ψkn i = √ eikn x
N

(20)
(21)

where
kn =

2πn
,
N

n = 0, 1, 2, · · · , N − 1.

(22)

13

FIG. 9: (a) and (b): The evolution of eigenvalue
positions (left) and right eigenvector localization
measured by the IPRR (right) are shown for a fixed set
of ±1 self-interacting and ±1 hopping elements
(N = 300 matrices drawn from Pv=0 (d) and Pu=0 (s)),
but with the relative strength of the self-interactions 0
tuned from 0 (green points) to 1 (purple points).
(c)–(f): The eigenfunction localization behavior,
quantified by ln IPRR (λkn ), as a function of 0 , following
seven individual eigenvalue trajectories originating from
four distinct wave numbers kn in the 0 = 0 spectrum.
These images suggest that the 0 = 0 wavenumbers play
a role in “assigning” localization properties to the
eigenvectors of certain eigenvalues as the nonzero
self-interactions are turned on. The eigenvector of the
eigenvalue with the largest real part localizes drastically.
On the other hand, The eigenvector of the eigenvalue
closest to 0 stays delocalized. The family of curves at
the bottom show the evolution of ln IPRR (λkn ) for all
kn values as 0 increases from 0 to 1.

Note that Eq. (20) and (21) imply extended eigenfunctions and a spectrum with an elliptical shape in the complex plane in the limit 0 → 0.

FIG. 10: (a): Comparison of the spectra under open
boundary conditions (OBC) and periodic boundary
conditions (PBC) corresponding to one realization
(N = 300) of the matrix M0 shown in Eq. (14), which
arose from the large g limit of Eq. (3), with equal
strength random hopping and random self-interactions
(0 = 1). Breaking a single link of the ring (shown
schematically as the dashed arrows in the top left)
changes the spectrum entirely; the spectrum condenses
onto two points with degeneracy N/2 when the cycle is
broken. Eigenfunction amplitudes of right and left
eigenvectors |ψ R | and |ψ L | corresponding to (b) an
eigenvalue close to 0 and (c) the eigenvalue with the
largest real part in the spectrum corresponding to
periodic boundary condition (PBC). The eigenvectors in
(b) and (c) show a drastic difference in their degrees of
localization. In addition, the left and right eigenvectors
corresponding to the same eigenvalue show different
centers of localization.

Remarkably, however, upon incorporating nonzero selfinteractions with strength 0 = 1 with a random sign
distribution Pv=0 (d), we find that the spectra not only
transforms into the distinct shape of an infinity symbol
(as shown in Fig. 8), but also acquire right eigenstates
with an entire range of localization lengths (see the two
eigenfunctions shown in Fig. 10). The top of Fig. 9 shows,
for a fixed set of ±1 self-interactions and ±1 hopping
elements drawn from Pv=0 (d) and Pu=0 (s) respectively,
the variation in eigenvalue position (left) and eigenvector localization (right) as the self interaction strength 0
is tuned from 0 to 1. The rest of Fig. 9 shows how the localization indicator ln |IPRR (λkn )| evolves as a function
of 0 for seven individual trajectories originating from
four distinct wave numbers kn , shown in Eq. (22) for
the 0 = 0 spectrum. Similar to the winding numbers
studied in Ref. [32], these wavenumbers can be used to
classify localization properties of the eigenvectors in the
presence of nonzero self-interactions. Importantly, when
self-interactions are incorporated into the oriented ring
network, the principal eigenvector (the eigenvector cor-

14
responding to the eigenvalue with the largest real part),
transforms from being completely delocalized to being
highly localized (see Fig. 10c and Fig. 9). Such eigenvectors dominate long term dynamics of systems linearized
about some equilibrium state (see next section and Appendix B). As shown for the ring network studied in
Ref. [23], the principal eigenvector of the connectivity
matrix of a neural network dictates the sustained activity
associated with short term memory, and the presence of
a localized principal eigenvector is associated with short
term memory storage of information regarding a specific
spatial direction.
We leave for future work an elucidation of both the
density of states along this family of continued spectral
curves and the intriguing continuous variation of eigenvector localization properties. We emphasize again that
both strong directionality and cycle lengths of the order
of the system size appear to be necessary ingredients for
producing these striking spectra.

D.

Consequences of nontrivial distinction between
left and right eigenvectors

In this work, we have focused on the localization
properties of the right eigenvectors ψnR (j), which appear naturally in, say, neural dynamics problems such
as Eq. (2) P
when the firing rate is expanded according
to rj (t) = n cn ψnR (j)eλn t . In systems with no directional bias (e.g. the random sign model examined in
Sec. II), we find that the left and right eigenvectors are
identical (see Appendix B). However, when nonzero directionality bias is present, left and right eigenfunctions
corresponding to the same eigenvalue can differ in both
localization lengths and the positions of their centers of
localization (see Fig. 10). This dichotomy has interesting
consequences, both formally and physically. Formally,
the distinction between left and right eigenvectors means
that one can define an alternative metric of localization
using left-right eigenvector inner products,
" P
2 #−1
L
R
i ψn (i)ψn (i)
IP RLR (λn ) = P
,
(23)
2
L
R
i |ψn (i)ψn (i)|
which yields different results from the IPR defined by
Eq. (6) for systems with nonzero directional bias. Physically, the spatial separation between left and right eigenvectors manifests in a nontrivial distance between the response and excitation signals in a neural network. This
can be seen via the signal propagator. For zero input hi (t) in Eq. (2), the propagator takes the following
form [47]
Gij (t) =

N
−1
X

ψnR (i)ψnL (j)eλn t−t/τ .

(24)

ψnR (i)ψnL (j) = δi,j , one can verify that Eq. 24 reduces
to the Kronecker delta function δi,j at t = 0. As seen in
Eq. (24), for a pair of right and left eigenvectors peaked
respectively at i and j, an excitation signal at j triggers a
response at i. When directional bias is nonzero, the right
and left eigenvectors peak at different locations separated
in space. Thus, even when the left and right eigenvectors
are individually localized, they can communicate over a
large spatial region. Various aspects of the left and right
eigenvectors are further explored in Appendix B.
P

n

VI.
A.

DISCUSSION AND OUTLOOK

Implications for more complicated networks

Knowledge of the spectral properties of sparse nonHermitian random matrices is critical for determining the
behavior of real-world networks and also necessary for devising practical methods for understanding network data.
In this paper, we briefly highlighted the implications of
our results for the dynamics of a ring neural network.
However, spectral properties of eigenvalues and eigenvectors can be key for analyzing other types of networks, including those with a percolation threshold and networks
where the relative importance (centrality) of nodes plays
a key role [4].
Focusing on a simple one-dimensional network allowed us to identify important network ingredients, such
as random nearest neighbor connections, random selfinteractions, large loop structure, and strong directional
bias. Ideas and results from this paper may shed light,
on different levels, on more general networks with higher
node degrees (dimensionality) and structure types, as
summarized below.

1.

Eigenvalue repulsion and eigenvector localization

The phenomena of eigenvalue repulsion arising only for
more extended eigenstates (Sec. III) might conceivably
be a property of all non-Hermitian random matrices, regardless of their degree of sparsity and underlying spatial
structure. Although the numerical evidence in this paper is consistent with this conjecture, new mathematical
tools may be necessary to prove this connection convincingly. Note that although the inverse participation ratio
(IPR) may no longer be precisely the inverse of a physical localization length outside of strictly one-dimensional
networks, it can still be used as a measure of the inverse
cluster size for eigenmodes in more general sparse networks.

2.

Properties of random 1d systems

n=0

Upon applying the biorthogonality property of left
and right eigenvectors with proper normalization

In Sec. III and Sec. IV, we studied how nonzero random
self-interactions and a spreading distribution in nearest

15
neighbor connection strengths lead to eigenvector localization and eigenvalue decorrelation for one-dimensional
models. When randomness in the self-interactions is
strong enough, all eigenvectors become highly localized
and there are negligible correlations among the eigenvalues in the spectra, though strong directional bias (large
g in Eq. (3)) makes the system more resistant to this
outcome.
Unlike the more general conjectures in the section immediately above, our computations focused on a onedimensional network represented by a tridiagonal random
matrix, with corner matrix elements used to implement
periodic boundary conditions. Random graphs with this
structure can arise in the analysis of certain complex systems, which contains spatial scales where spatially-local
couplings are prevalent. Examples include biological networks such as the ring attractor neural network [30], matrices that describe DNA single-nucleotide polymorphism
data [48], and even complex systems in economics, which
can sometimes be approximated by decomposable matrices [49–51]. An alternative set of unidimensional systems
also arise naturally in the temporal ordering of time series
data [52]. In these areas, eigenvector localization properties are critical to the functioning of different spectral
algorithms used for detecting network boundaries and
temporal patterns [51, 53–55].

3.

Extendibility to low-dimensional graphs

It would be interesting to explore whether the results of
the one-dimensional models studied in this paper are extendible to similarly-structured networks with more degrees of freedom associated with each node, similar to
the 3 sites per node model studied in Ref. [31]. More
generally, we can ask: What is the effect of competing self-interaction disorder and connectivity disorder on
eigenvector localization and eigenvalue repulsion in lowdimensional graphs?
Low-dimensional graphs are ubiquitous in nature and
appear often in the form of planar networks, such as leaf
vasculature and water networks [56]. Both diffusion between nodes (analogous to the hopping terms in Eq. (3))
and directed motion (controlled by the parameter g for
Eq. (3)) appear naturally in these models. The higherdimensional connectivity embodied in the branching networks, however, raises interesting questions, such as different ways of distributing the connection number per
node within a connected space.

B.

Challenges in mathematics

Rigorous results for sparse non-Hermitian matrices are
difficult to obtain since it is challenging to apply standard
random matrix theory tools, and proofs of convergence
for eigenvalues and eigenvectors in the thermodynamic
limit of large rank matrices remain elusive [28].

In this work, we explored properties of sparse nonHermitian random matrices, predominantly through numerical random matrix experiments that highlight the
need for more precise mathematical descriptions.
One question is: How can we derive a mathematical
description of the relation between complex eigenvalue
repulsion and eigenstate delocalization? Eigenvalue repulsion and eigenstate delocalization with interactions
in sparse Hermitian systems are currently of interest in
quantum many-body systems [57, 58]; it would be interesting to see if methods developed for quantum systems
could be carried over to non-Hermitian systems.
Another question is, what is the effect of large cycles
on the spectral properties of sparse random matrices?
An important technique used for calculating the spectral density of sparse non-Hermitian random matrices
is the cavity method [7], which has been successful in
determining the spectral gap and distribution of outlier
eigenvalues and eigenvectors. The presence of large cycles, however, breaks the method’s assumption of a local
tree-like structure. Another potential analytical relation
is the non-Hermitian generalization of the Thouless relation relating the localization length and the density of
states [42], which also exploits an electrostatics analogy
(in terms of the Lyapunov exponent) for random onedimensional systems [46]. However, it may be challenging to apply this method in the combined presence of
periodic boundary conditions and delocalized eigenfunctions. Many works have examined the effects of small
cycles (cycles with constant number of nodes that do not
grow with system size) [59–62]. Nevertheless, as shown
in this paper, the presence of a single large cycle on a
sparse graph can drastically change the system’s spectral correlation and localization behavior, making large
cycles a worthwhile problem for future studies.

ACKNOWLEDGMENTS

It is a pleasure to acknowledge helpful conversations
with A. Amir, J. Kates-Harbeck, and B. Shklovskii.
We also thank A. Amir for a critical reading of the
manuscript. G.H.Z. acknowledges support by the National Science Foundation Graduate Research Fellowship
under Grant No. DGE1745303. This work was also
supported by the National Science Foundation, primarily through Grant No. DMR-1608501 and through the
Harvard Materials Science and Engineering Center, via
Grant No. DMR-1420570.

Appendix A: Pair correlation function g(r)
calculation for eigenfluids

In this section, we describe in detail our numerical extraction of pair correlation functions. We first review the
pair correlation function for a homogeneous fluid, appropriate for the Ginibre random matrix “eigenliquid”, and

16
then generalize the procedure for inhomogeneous eigenvalue distributions.
1. Pair correlation function of the homogeneous
eigenliquid generated by the Ginibre ensemble

For an isotropic homogeneous fluid, the particle density of one realization is given by
ρ(r) = ρg(r),

(A1)

where ρ is the average density of eigenvalues in the complex plane, and g(r) is the probability of finding a particle
distance r away from a reference particle at the origin in
one realization of the ensemble. Upon integrating ρ(r)
over a ring of small width dr at distance r away from the
central particle, we have
n(r)dr ≈ ρg(r)2πrdr,

(A2)

where n(r)dr is the number of particles between r and
r + dr about the central particle. For N total particles
in the realization, the number of particle pairs that are
separated by distances between r and r + dr, which we
denote G(r, dr), is then given by
G(r, dr) =

N
N
n(r)dr = ρg(r)2πrdr.
2
2

(A3)

Thus, the pair correlation function (or radial distribution function) g(r) is given by [40],
g(r) =

G(r, dr)
,
N ρπrdr

(A4)

where we found G(r, dr) numerically using a binary
search tree (CKD Tree python package). We tested this
procedure for the Ginibre ensemble, for which the scaled
eigenvalues are contained in a disk of radius 1, and the
eigenvalue density is ρ = N/π everywhere inside this unit
disk. Then, Eq. A4 leads to a radial distribution function
for the Ginibre ensemble gG (r) given by
gG (r) =

GG (r, dr)
,
N 2 rdr

(A5)

which we used to obtain the pair correlation function
shown in Fig. 3.

realization. Upon performing a change of coordinates
~ = (~r1 + ~r2 )/2), where ~r
from (~r1 , ~r2 ) to (~r = ~r2 − ~r1 , R
~
is the separation vector between the two particles and R
is the mean location of particle pair, we consider eigen~ over which
value correlations in a small area about R,
the eigenvalue density is appropriately constant. Following the same procedure as in the previous section, for
sufficiently isotropic correlations where the angular dependence can be neglected (see Sec. A 3 below), we arrive
at
~ =
g(r, R)

~
G(r, dr, R)
,
~
r
~
N ρ(R − )πrdr

~ is the
where the local pair correlation function g(r, R)
probability of finding two particles distance r apart given
~ and N is the number of
that their mean location is R,
eigenvalues in the reference area.
To properly examine the local correlation function av~ ∆R , the box size
eraged over a small grid in space, g(r, R)
∆R should be much larger than the average particle spacing but small enough such that the fluid contained in the
box is approximately homogeneous. In this case, we can
apply Eq. (A4) and obtain,
~ ∆R ≈
G(r, dr, R)

2
NR,∆R
~

∆R2

Pair correlation function of inhomogeneous
eigenfluids

For an inhomogeneous, anisotropic fluid in two dimensions, the particle density of a single realization takes a
more general form
ρ(~r2 ) = ρ(~r1 )g(~r1 , ~r2 − ~r1 ),

(A6)

where g(~r1 , ~r2 ) is a probability distribution that depends
on 4 coordinates, and ρ(~r2 ) is the chance of finding a particle at ~r2 given that there is a particle at ~r1 in the same

~ ∆R , (A8)
πrdr × g(~r, R)

where NR,∆R is the number of particles in the box of
~ and G(r, dr, R)
~ ∆R is the total
size ∆R centered at R,
number of particle pairs separated by distances between
r and r + dr, averaged over mean locations inside the
reference box.
Partitioning of the eigenfluid into smaller, approximately homogeneous boxes requires averaging over many
realizations of the ensemble (diagonalization of many matrices) in order to achieve an adequate amount of statistics. Then, obtaining the proper normalization via comparison to an uncorrelated eigenfluid,
PM
(j)
2
1
j=1 (NR,∆R )
~
G0 (r, dr, R)∆R =
2πrdr, (A9)
M
2∆R2
where M is the total number of realizations, the local
pair correlation function is
~ ∆R ≡
g(r, R)

2.

(A7)

2

~ ∆R
G(r, dr, R)
.
~ ∆R
G0 (r, dr, R)

(A10)

~ ∆R , the probability of finding partiTo calculate g(r, R)
cles with separation distances ∈ [r, r + dr) given that the
mean locations of the particle pairs are within a box of
~ we thus find the numerator nusize ∆R centered at R,
merically via binary search trees, and calculate the denominator from Eq. (A9).
~ ∆R
For this method to work, we require that g(r, R)
does not change significantly with the box size ∆R. If
∆R is too large, we average over areas with significantly
different correlations (or eigenvalue densities), and the

17
homogeneity assumption fails. We also avoid applying
this method near the fractal edges of the random sign
spectrum (see Fig. 2), where the density of states change
abruptly, and there are fine, singular density spikes in
the spectrum.

3.

Angular dependence of the pair correlation
function

In deriving Eq. (A7), we assumed that the angular de~ =
pendence of the local pair correlation function g(~r, R)
~
~
g(r, θ, R) ≈ g(r, R) can be neglected, thus improving our
statistics by counting all particle pairs separated by distance r regardless of the direction of their separation vector. More generally, however, there could exist eigenfluids where correlations between particles can have significant dependence on the direction. Here, we explore angular dependence of the pair correlation function for the
random sign model studied in Sec. II, and show that the
angular dependence of the correlations is weak, justifying
the approximation leading to Eq. (A7).
To test for directional variation of the two-point eigenvalue correlations, we again examine correlations of
eigenvalue pairs within the 9 (0.05 × 0.05) square grids
closest to the origin in the first quadrant, examined previously in Fig. 5. The top left spectrum of Fig. 11 shows
these regions enclosed by a magenta box. We bin eigenvalue pairs in these regions, based on the angle θ characterizing each of their separation vectors ~r, into four angular sectors (see top right of Fig. 11). Since eigenvalue
correlations should be symmetric under θ ↔ −θ, we only
study θ spanning a range of π. In the bottom plots,
the color of each line then corresponds to the pair correlation function derived from counting eigenvalue pairs
within that angular range, normalized as in Eq. (A10)
and multiplied by 4 (since we are binning into four angular sectors). The black smooth line is the fitting function
gs (r) used in Fig. 5, i.e. the rotationally averaged pair
correlation function, obtained by counting all eigenvalue
pairs of separation r regardless of direction. Although the
colored angular counts are noisier due to the reduction in
sample size, we find no significant angular dependence.
Finding and examining spectra for which the two-point
eigenvalue correlations do exhibit nontrivial angular dependence would be an interesting topic for future investigations.

FIG. 11: Directional variation of the pair correlation
function in the first quadrant of the random sign model,
obtained from counting eigenvalue pairs centered in the
9 (0.05 × 0.05) square grids closest to the origin,
enclosed by the magenta box in the top left spectra.
The top right schematic shows four different angular
sectors (centered at 0, π/4, π/2, and 3π/4) within
which the angle of an eigenvalue pair separation θ can
be binned. In the bottom plots, the color of each line
corresponds to the pair correlation function derived
from counting eigenvalue pairs within that angular
range. The smooth black line is the fit of the functional
form gs (r) shown in Fig. 5, i.e. angular-averaged pair
correlation function. Since the colored lines do not
deviate significant from the black line, isotropy of the
eigenvalue correlations appears to be a reasonable
approximation for the random sign model.

Appendix B: Eigenstate localization for nonidentical
left and right eigenvectors
1.

Left and right eigenvectors with directional bias
but no diagonal disorder

For a non-Hermitian matrix, the left and right eigenvectors are in general not identical. There then exist

three distinct ways to measure localization for an eigenstate, by using the magnitude of the right eigenvector

18

FIG. 13: IPRR (top) and IPRLR (bottom) as a
function of the eigenvalue magnitude (distance away
from the origin) for eigenvalues around the 45◦ line in
the complex plane, as indicated by the colored portions
of the spectrum (left). Data extracted from 150
diagonalizations of the random sign hopping matrix
N = 500 (right) show that IPRR decreases gradually as
the eigenvalue gets closer to the rim, while IPRLR
abruptly drops when the eigenvalue is right at the rim.
(Eq. (6)), by using the magnitude of the left eigenvector,

 −1
P
2 2
L
(i)
ψ
n
i


IP RL (λn ) =  P
,
(B1)
4 
L
i |ψn (i)|

FIG. 12: Comparison of IP RR and |ψ R | and |ψ L |
(top), and IP RLR and |ψ L ψ R |1/2 (bottom)
corresponding to the principal eigenvalue for one
realization of the asymmetric random sign model with
no self-interaction disorder, with increasing g. As g
increases from 0, the spectrum exhibits a band gap at
the origin of the complex plane with a rim of weakly
delocalized states, and the right and left eigenvectors
spatially separate and gradually spread out. When g is
sufficiently large such that the spectral rim reaches the
principal eigenvalue, the left and right eigenvectors
experience a jump in separation and the left-right inner
product |ψ R | and |ψ L | are abruptly delocalized.

or by using the product of the left and right eigenvectors [47],
" P
 #−1
L R 2
ψ
ψ
i
i
IP RLR (λn ) = Pi
,
(B2)
L R 2
i ψi ψi
where i labels the i-th site of the left or right eigenvector.
In the one-dimensional systems that we study using
Eq. (3), the left and right eigenvectors can be related
through the equation,
ψ L (g) = ψ R (−g)SST ,

(B3)

whererS is a diagonal matrix with elements Sjj =
Qj−1 s−
i
, responsible for transforming M into a symi
s+
i

metric matrix [31]. When there is no directional bias in
Eq. (3) (i.e. g = 0), and the hopping probability distribution is narrow, the left and right eigenvectors are
identical up to sign flips at each site,
ψnL (i) = ±ψnR (i),

(B4)

where i labels some site index and the ±1 is determined
by the matrix SST , which in turn depends on the particular realization of the disorder. Thus, without directional

19
bias, the left and right eigenvectors with the same eigenvalue have the same magnitude at each site, and hence
share the same localization properties. In this case, all
three defintions of IPR (Eq. (6), (B1), and (B2)) give the
same result for every eigenvalue in the spectrum. However, when there is nonzero directional bias (g 6= 0 in
Eq. (3)), the left and right eigenvectors separate spatially,
and the results change. As shown explicitly in Sec. V D,
the left and right eigenvectors corresponding to the same
eigenvalue can take on entirely different shapes. Fig. 10
shows the spectra of the one way hopping (infinite directional bias) and random sign self-interaction model,
where the right and left eigenvectors can be separated by
a significant distance on the ring. In these cases, IPRLR
returns significantly different values compared to IPRR
and IPRL .
Fig. 12 compares the magnitude of the left eigenvector and the right eigenvector, and the square root of the
product of left and right eigenvectors for the asymmetric random sign model with no self-interaction disorder.
The localization properties of this spectrum for just the
right eigenvectors were studied in detail in Ref. [31]. We
show a sequence of spectra with increasing g, focusing
in particular on the eigenvalue with the largest real part
and the three eigenvector quantities associated with it,
|ψ L |, |ψ R |, and |ψ L ψ R |1/2 . When g = 0 (no directional
asymmetry), all three quantities are identically localized.
However, when g becomes nonzero, a hole opens up in
the middle of the spectrum, converting the eigenvalues
originally near the origin of the complex plane into a
band gap with an expanding rim of weakly delocalized
eigenstates. As g increases (counterclockwise hopping
bias), the eigenvalue with the largest real part initially
stays the same, despite the changes in the middle of the
spectrum, but the peaks of the localized right and left
eigenvectors start to separate in opposite directions, and
gradually widen as well. When g reaches a high enough
value such that the rim of the hole envelopes the principal eigenvalue, the separation between the left and right
eigenvector peaks experiences a sudden jump, while the
peak widths continue to gradually spread out. On the
other hand, the profile of the product of the left and right
eigenvectors (Fig. 12b) does not change at all when g initially increases from 0, provided that the location of the
principal eigenvalue remains fixed in the complex plane.
However, when the expanding rim reaches the principal
eigenvalue, |ψ L ψ R |1/2 suddenly becomes completely delocalized.
The behavior of the three eigenvector quantities for
the principal eigenvalue as a function of g, namely the
gradual spreading of |ψ L | and |ψ R | as g increases, and
the sudden complete delocalization of |ψ L ψ R |1/2 when
the eigenvalue is enveloped by the opening rim, is in fact
experienced by all eigenvalues in the spectrum. A related
phenomenon appears when IPRR , IPRL , and IPRLR are
evaluated for all eigenvalues as a function of their distance from the expanding rim, at a fixed value of g.
Fig. 13 plots IPRR and IPRLR as a function of the

eigenvalue magnitude (distance away from the origin) for
eigenvalues around the 45o line in the complex plane, as
indicated by the colored portions of the spectrum on the
left. The data is extracted from 150 diagonalizations of
the random sign hopping matrix N = 500. Although
these plots are rather noisy, IPRR decreases gradually
as the eigenvalue gets closer to the rim, while IPRLR
abruptly drops when the eigenvalue is right at the rim.
Insight into these two behaviors follows from approximating the wavefunction magnitudes as wavepackets
exponentially decreasing from their centers of localization [45]. Then, using the similarity transformation in
Ref. [31], in a convenient continuum notation, we have,
ψnR (x, g) ∼ e−κn |x−xn |+gx
ψnL (x, g)

∼e

−κn |x−xn |−gx

(B5)
,

(B6)

where n labels the eigenfunction corresponding to the nth eigenvalue, xn denotes the center of localization for
g = 0, and κn is the Lyapunov exponent characterizing
the exponential decay of the right and left eigenfunctions
at g = 0. An approximate inverse participation ratio (i.e.
effective Lyaupnov exponent κef f ) can then be calculated
using Eq. (6) and (B2),
R +∞
−∞

IPRR (λn ) ≈ R
+∞
−∞

R +∞
−∞

IPRLR (λn ) ≈ R
+∞
−∞

R (x, g)|4
dx|ψn
ef f,R
2 ≡ κn
R
2
dx|ψn (x, g)|

(B7)

R (x, g)ψ L (x, g)|2
dx|ψn
n
ef f,LR
,(B8)
2 ≡ κn
R
L (x, g)|
dx|ψn (x, g)ψn

with the results
κ2n − g 2
κn
∼ κn .

f,R
κef
∼
n
f,LR
κef
n

(B9)
(B10)

f,R
vanishes continuously as g → κ−
Thus, κef
n , while
n
ef f,LR
appears independent of g. Of course, we must reκn
member that the approximate wavefunctions in Eq. (B5)
become unormalizable when g = κn and therefore
f,LR
κef
and IPRLR must cease to exist when g = κn .
n
These rough arguments are consistent with the continuous evolution of IPRR as a function of g and the distance
of the eigenvalue from the spectral rim (Fig. 13a and 13a,
respectively) and the sudden change in IPRLR (g) and
IPRLR (|λ|) (Fig. 13b and 13b). Although the delocalization of the left and right eigenvectors is more gradual
as g → κ−
n , they nevertheless mediate the sudden delocalization transition of the left-right inner product IPRLR ,
when they leave the Hilbert space of localized states.

2.

Consequences of directionality bias on dynamics

In this final section, we comment briefly on the dynamics of a signal propagating in the one-dimensional
one-way hopping model (large g limit of Eq. (3)) with
and without disordered self-interactions.

20
study would allow for multiple eigenvalues with positive
real parts and include the effects of nonlinearities [23].
For the random sign hopping model studied in Sec. II,
the sub-diagonal terms (clockwise connections) are to
first order negligible in the large-g limit. One can then
“gauge away” the random signs on the counter-clockwise
connections through a similarity transformation, and find
the eigenvalues λn and the strongly delocalized left and
right eigenvectors ψnL and ψnR analytically (see also Sec. V
Eq. (22)) [31],
λn (g) = eikn +g
ψnL ∼ e−ikn j
ψnR ∼ eikn j ,

(B11)
(B12)
(B13)

where
2π
n, n = 0, 1, · · · , N − 1.
(B14)
N
Let φ0 (x) denote a spatially localized signal at time
t = 0. Then, by expanding this initial state in a complex
set of right eigenvectors, and then using the left eigenvectors to project out the expansion coefficients, we find
the average position of the wave packet at time t,
kn =

L

Z
hxit ∼

dx x
0

X

R
ψn
(x)eλn (g)t

L

Z

L 0
dx0 ψn
(x )φ0 (x0 ).(B15)

0

n

Since the integral over x0 does not depend on x, we denote
Z L
fn ≡
dx0 ψnL (x0 )φ0 (x0 )
(B16)
0

in all subsequent equations. Normalizing Eq. (B15) then
gives the following,
RL
PN −1 R
λn (g)t
dx x
fn
n=0 ψn (x)e
0
. (B17)
hxit = R L
PN −1 R
λn (g)t f
dx
n
n=0 ψn (x)e
0
Upon integrating by parts, we find
FIG. 14: IPRR and |ψR | and |ψL | (top), and IPRLR
and |ψR ψL |1/2 (bottom) corresponding to the principal
eigenvalue of one realization of the one-way hopping
model and random sign connections (Eq. (14)) with
decreasing 0 , the ratio between the disordered
self-interaction strength and the strength of the
one-way connection disorder. At large 0 , the spatially
separated left and right eigenvectors are fairly localized,
spreading out more as 0 decreases. Meanwhile, the
left-right inner product is delocalized at all values of 0
for the one-way model.

a.

Signal current and eigenvalue velocity in the absence of
diagonal disorder

We first study the behavior of the mean and variance
of a signal location in space as it propagates on a ring in
the large-g limit without onsite disorder (Eq. (14) with
0 = 0). We study a simple linear model like Eq. (3),
with M replaced by M0 in Eq. (14). A more complete

hxit − hxi0 = −λ0 (g)t = −eg t = −t

dλ0
,
dg

(B18)

where λ0 denotes the “ground state” eigenvalue corresponding to the lowest wave number k0 , which for this
problem is the eigenvalue with the largest real part. The
minus sign is present in Eq. (B18) because the hopping
is biased in the counterclockwise direction.
The time evolution of the second moment associated
with this initial condition is found from
RL
PN −1 R
λn (g)t
dx x2
fn
n=0 ψn (x)e
2
0
hx it = R L
, (B19)
PN −1 R
λ
(g)t
n
dx
fn
n=0 ψn (x)e
0
which leads to
hx2 it − hx2 i0 = tλ0 (g) (1 + λ0 (g)t) .

(B20)

After incorporating Eq. (B18), we find that the variance
describing the spreading of this wave packet grows linearly in time


dλ0
hx2 it − hxi2t − hx2 i0 − hxi20 = t
. (B21)
dg

21
One can also obtain the same behavior by directly calculating the signal at time t, φt (x), starting with a Gaussian
initial condition φ0 (x) ∼ exp(−x2 /2a) at t = 0 .
To summarize, a signal propagating on the ring with
one-way random sign hopping and no onsite disorder
travels with a constant speed
eg , and has a standard de√ g/2
viation that increases as te . In the long time limit,
the signal stops spreading when it covers the entire ring
and converges to a flat stationary state, given by ψ0R in
Eq. (B13).

In addition to localization effects, the response of hopping models with directional bias has an additional interesting property that is not present in non-biased hopping
models. Because of the separation of the left and right
eigenvectors when there is nonzero directional bias, a localized response (at the peak of the right eigenvector) can
be triggered at a considerable distance away from the location of the excitation signal (at the peak of the left
eigenvector) via the propagator of the dynamical models
associated with matrices M0 studied in Sec. V,
G(x, x0 , t) =

b.

Localized response mediated by spatially separated left
and right eigenvectors with diagonal disorder

N
−1
X

ψnR (x)ψnL (x0 )eλn t .

(B22)

n=0

In the previous section, we saw that regardless of the
initial condition (excitation signal), the one-way hopping
model without onsite disorder allows a signal to propagate and spread out on a ring of connections as a function
of time, eventually converging to a stationary delocalized
state. However, this behavior is dominated by delocalized
eigenvectors. When self-interaction disorder is incorporated, the dynamics is quite different, because a large
portion of the spectrum exhibits localized eigenvectors
in the presence of onsite disorder, even for models with
one-way connections.

Fig. 14a shows the left and right eigenvectors corresponding to the principal eigenvalue, for one realization
of the random sign one-way hopping model (Eq. (14)).
Here, the tuning parameter is 0 , the ratio between the
disordered self-interaction strength and the strength of
the one-way connection disorder. Even at large 0 , although the onsite disorder essentially pins down the signal such that it does not travel or spread, the system
can nevertheless sense the excitation signal and respond
at distances on the order of the system size. Interestingly, as shown in Fig. 14b, the product of the left and
right eigenvector |ψ R ψ L |1/2 is completely delocalized for
all eigenvalues in the spectra at all values of 0 .

[1] M. L. Mehta, Random matrices, Vol. 142 (Elsevier, 2004).
[2] S. N. Dorogovtsev, A. V. Goltsev, J. F. F. Mendes, and
A. N. Samukhin, Spectra of complex networks, Phys.
Rev. E 68, 046109 (2003).
[3] S. N. Dorogovtsev and J. F. Mendes, Evolution of networks: From biological nets to the Internet and WWW
(OUP Oxford, 2013).
[4] M. Newman, Networks: an introduction (Oxford university press, 2010).
[5] A.-L. Barabási et al., Network science (Cambridge university press, 2016).
[6] A. Barrat, M. Barthelemy, and A. Vespignani, Dynamical
Processes on Complex Networks (Cambridge University
Press, Cambridge, 2008).
[7] T. Rogers and I. P. Castillo, Cavity approach to the spectral density of non-Hermitian sparse matrices, Physical
Review E 79, 012101 (2009).
[8] I. Neri and F. L. Metz, Spectra of Sparse Non-Hermitian
Random Matrices: An Analytical Solution, Physical Review Letters 109, 030602 (2012).
[9] S. Allesina and S. Tang, The stability–complexity relationship at age 40: a random matrix perspective, Population Ecology 57, 63 (2015).
[10] K. Rajan and L. F. Abbott, Eigenvalue Spectra of Random Matrices for Neural Networks, Physical Review Letters 97, 188104 (2006).
[11] Y. Ahmadian, F. Fumarola, and K. D. Miller, Properties
of networks with partially structured and partially random connectivity, Physical Review E 91, 012820 (2015).
[12] J. Aljadeff, D. Renfrew, M. Vegué, and T. O. Sharpee,

Low-dimensional dynamics of structured random networks, Physical Review E 93, 022302 (2016).
L. M. Pecora and T. L. Carroll, Master stability functions for synchronized coupled systems, Physical Review
Letters 80, 2109 (1998).
F. Krzakala, C. Moore, E. Mossel, J. Neeman, A. Sly,
L. Zdeborová, and P. Zhang, Spectral redemption in
clustering sparse networks, Proceedings of the National
Academy of Sciences 110, 20935 (2013).
C. Bordenave, M. Lelarge, and L. Massoulié, Nonbacktracking spectrum of random graphs: community
detection and non-regular ramanujan graphs, in 2015
IEEE 56th Annual Symposium on Foundations of Computer Science (IEEE, 2015) pp. 1347–1357.
A. N. Langville and C. D. Meyer, Google’s PageRank and
beyond: The science of search engine rankings (Princeton
University Press, 2011).
L. Ermann, K. M. Frahm, and D. L. Shepelyansky,
Google matrix analysis of directed networks, Reviews of
modern physics 87, 1261 (2015).
J. D. Noh and H. Rieger, Random walks on complex networks, Physical Review Letters 92, 118701 (2004).
D. Kleinfeld, A. Bharioke, P. Blinder, D. D. Bock, K. L.
Briggman, D. B. Chklovskii, W. Denk, M. Helmstaedter,
J. P. Kaufhold, W.-C. A. Lee, H. S. Meyer, K. D.
Micheva, M. Oberlaender, S. Prohaska, R. C. Reid, S. J.
Smith, S. Takemura, P. S. Tsai, and B. Sakmann, Largescale automated histology in the pursuit of connectomes.,
The Journal of neuroscience : the official journal of the
Society for Neuroscience 31, 16125 (2011).

[13]

[14]

[15]

[16]

[17]

[18]
[19]

22
[20] H. Ko, S. B. Hofer, B. Pichler, K. A. Buchanan, P. J.
Sjöström, and T. D. Mrsic-Flogel, Functional specificity
of local synaptic connections in neocortical networks, Nature 473, 87 (2011).
[21] G. Karlebach and R. Shamir, Modelling and analysis of
gene regulatory networks, Nature Reviews Molecular Cell
Biology 9, 770 (2008).
[22] K. Chung and K. Deisseroth, CLARITY for mapping the
nervous system, Nature Methods 10, 508 (2013).
[23] H. Tanaka and D. R. Nelson, Non-hermitian quasilocalization and ring attractor neural networks, Phys. Rev. E
99, 062406 (2019).
[24] J. Ginibre, Statistical Ensembles of Complex, Quaternion, and Real Matrices, Journal of Mathematical
Physics 6, 440 (1965).
[25] P. J. Forrester and T. Nagao, Eigenvalue Statistics of
the Real Ginibre Ensemble, Physical Review Letters 99,
050603 (2007).
[26] G. Akemann and E. Kanzieper, Integrable Structure of
Ginibre’s Ensemble of Real Random Matrices and a Pfaffian Integration Theorem, Journal of Statistical Physics
129, 1159 (2007).
[27] A. Zabrodin and P. Wiegmann, Large-N expansion for
the 2D Dyson gas, Journal of Physics A: Mathematical
and General 39, 8933 (2006).
[28] F. L. Metz, I. Neri, and T. Rogers, Spectral Theory
of Sparse Non-Hermitian Random Matrices, Journal of
Physics A: Mathematical and Theoretical (2019).
[29] N. Ashcroft and N. Mermin, Solid State Physics, HRW international editions (Holt, Rinehart and Winston, 1976).
[30] S. S. Kim, H. Rouault, S. Druckmann, and V. Jayaraman, Ring attractor dynamics in the drosophila central
brain, Science 356, 849 (2017).
[31] A. Amir, N. Hatano, and D. R. Nelson, Non-hermitian
localization in biological networks, Physical Review E 93,
042310 (2016).
[32] N. M. Shnerb and D. R. Nelson, Winding numbers, complex currents, and non-hermitian localization, Physical
Review Letters 80, 5172 (1998).
[33] P. Dayan and L. F. Abbott, Theoretical neuroscience:
computational and mathematical modeling of neural systems, .
[34] T. P. Vogels, K. Rajan, and L. F. Abbott, Neural network
dynamics, Annu. Rev. Neurosci. 28, 357 (2005).
[35] J. Feinberg and A. Zee, Non-Hermitian localization and
delocalization, Physical Review E 59, 6433 (1999).
[36] J. Feder, Fractals (Springer Science & Business Media,
2013).
[37] B. I. Shklovskii, B. Shapiro, B. R. Sears, P. Lambrianides, and H. B. Shore, Statistics of spectra of disordered
systems near the metal-insulator transition, Phys. Rev.
B 47, 11487 (1993).
[38] P. J. Forrester and A. Mays, Log-gases and random matrices (2010).
[39] T. Tao, V. Vu, and M. Krishnapur, Random matrices:
Universality of ESDs and the circular law, The Annals of
Probability 38, 2023 (2010).
[40] D. McQuarrie, Statistical Mechanics (University Science
Books, 2000).
[41] B. Shklovskii, Repulsion of energy levels and conductivity of small metal samples, Sov. Phys. JETP 64.1, 127
(1986).
[42] D. J. Thouless, A relation between the density of states
and range of localization for one dimensional random sys-

[43]

[44]

[45]

[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]

[54]

[55]

[56]
[57]

[58]
[59]
[60]

[61]

tems, Journal of Physics C: Solid State Physics 5, 77
(1972).
T. Tao, V. Vu, et al., Random matrices: universality of
local eigenvalue statistics, Acta mathematica 206, 127
(2011).
B. I. Shklovskii and A. L. Efros, Electronic properties of
doped semiconductors, Vol. 45 (Springer Science & Business Media, 2013).
N. Hatano and D. R. Nelson, Vortex pinning and nonHermitian quantum mechanics, Physical Review B 56,
8651 (1997).
B. Derrida, J. L. Jacobsen, and R. Zeitak, Lyapunov Exponent and Density of States of a One-Dimensional NonHermitian Schrödinger Equation, Journal of Statistical
Physics 98, 31 (2000).
N. Hatano and D. R. Nelson, Non-hermitian delocalization and eigenfunctions, Physical Review B 58, 8384
(1998).
P. Paschou, E. Ziv, E. G. Burchard, S. Choudhry,
W. Rodriguez-Cintron, M. W. Mahoney, and P. Drineas,
Pca-correlated snps for structure identification in worldwide human populations, PLoS genetics 3, e160 (2007).
H. A. Simon and A. Ando, Aggregation of variables in
dynamic systems, Econometrica: journal of the Econometric Society , 111 (1961).
C. Meyer and C. Wessell, Stochastic data clustering,
SIAM Journal on Matrix Analysis and Applications 33,
1214 (2012).
M. Cucuringu, V. D. Blondel, and P. Van Dooren, Extracting spatial information from networks with loworder eigenvectors, Phys. Rev. E 87, 032803 (2013).
M. Cucuringu and M. W. Mahoney, Localization
on low-order eigenvectors of data matrices, CoRR
abs/1109.1355 (2011), arXiv:1109.1355.
T. Martin, X. Zhang, and M. E. J. Newman, Localization and centrality in networks, Phys. Rev. E 90, 052808
(2014).
D. Mavroeidis, L. Batina, T. van Laarhoven, and
E. Marchiori, Pca, eigenvector localization and clustering
for side-channel attacks on cryptographic hardware devices, in Machine Learning and Knowledge Discovery in
Databases, edited by P. A. Flach, T. De Bie, and N. Cristianini (Springer Berlin Heidelberg, Berlin, Heidelberg,
2012) pp. 253–268.
D. Taylor, S. Myers, A. Clauset, M. Porter, and
P. Mucha, Eigenvector-based centrality measures for
temporal networks, Multiscale Modeling & Simulation
15, 537 (2017).
E. Katifori and M. O. Magnasco, Quantifying loopy network architectures, PLOS ONE 7, 1 (2012).
R. Nandkishore and D. A. Huse, Many-Body Localization and Thermalization in Quantum Statistical Mechanics, Annual Review of Condensed Matter Physics 6, 15
(2015).
A. Pal and D. A. Huse, Many-body localization phase
transition, Phys. Rev. B 82, 174411 (2010).
F. L. Metz, I. Neri, and D. Bollé, Spectra of sparse regular
graphs with loops, Phys. Rev. E 84, 055101 (R) (2011).
D. Bollé, F. L. Metz, and I. Neri, On the spectra of
large sparse graphs with cycles, Spectral analysis, differential equations and mathematical physics: a festschrift
in honor of Fritz Gesztesys 60th birthday , 35 (2013).
A. Coolen, Replica methods for loopy sparse random
graphs, in Journal of Physics: Conference Series, Vol.

23
699 (IOP Publishing, 2016) p. 012022.
[62] M. E. J. Newman, Spectra of networks contain-

ing short loops,
arXiv:1902.04595.

CoRR

abs/1902.04595

(2019),

