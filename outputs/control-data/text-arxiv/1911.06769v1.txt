Large deviations in a population dynamics with
catastrophes
arXiv:1911.06769v1 [math.PR] 15 Nov 2019

A. Logachov1,2,3 , O. Logachova3,4 , A. Yambartsev5
November 18, 2019
1

Laboratory of Probability Theory and Mathematical Statistics, Sobolev Institute of Mathematrics, Siberi-

ian Branch of the RAS, Koptyuga str. 4, Novosibirsk 630090, RF
E-mail: avlogachov@mail.ru
2

Novosibirsk State University, Pirogova str. 1, Novosibirsk 630090, RF

3

Novosibirsk State University of Economics and Management, Kamenskaya str. 56, Novosibirsk 630099, RF

4

Siberian State University of Geo-systems and Technologies, Plakhotnogo str. 10, 630108 Novosibirsk, RF

E-mail: omboldovskaya@mail.ru
5
Institute of Mathematics and Statistics, University of São Paulo, 1010 Rua do Matão, CEP 05508–090,
São Paulo SP, Brazil
E-mail: yambar@ime.usp.br

Abstract
The large deviation principle on phase space is proved for a class of Markov processes known as random population dynamics with catastrophes. In the paper we
study the process which corresponds to the random population dynamics with linear
growth and uniform catastrophes, where an eliminating portion of the population is
chosen uniformly. The large deviation result provides an optimal trajectory of large
fluctuation: it shows how the large fluctuations occur for this class of processes.

Key words: Population models, Catastrophes, Large Deviation Principle, Local Large
Deviation Principle
2000 MSC: 60F10, 60F15, 60J27.

1

Introduction

Stochastic models with catastrophes are studied since 70’s and recieved a great attention of probability community, see [1] for the probably first systematic review about such
processes, and see [2] for short historical overview and more references. These models are
1

used in analyzing a growth of a population subject to catastrophes due large-scale death or
emigrations of a population. According [1] the population dynamics considered here we will
call population dynamics with linear growth and uniform catastrophes, where the eliminating
portion is chosen uniformly. Typically researchers are interested in extinction probability,
the mean time to extinction, invariant measures, convergence to invariant measures for these
processes.
In [3] for the population dynamic, ξ(t) defined by (1, 2) in the following, with linear
growth and uniform catastrophes we proved the local large deviation principle (LLDP):
we established a rough logarithmic asymptotic for the probability of the scaling version
ξT (t), t ∈ [0, 1], defined by (3), to be in a small neighborhood of a continuous function. Here,
based on the work [3] we established a large deviation principle (LDP) on the state space
at the end of the interval of observation of the process: we find the logarithmic asymptotic
for the probability P(ξT (1) > x). Moreover, our proof also provides an optimal trajectory
– how such deviation occurs taking in account the evolution of the process. As far as our
understanding there are no other large deviations results for such processes.
Throughout the paper we assume that all random elements are defined on a probability
space (Ω, F, P).
We construct our continuous time process ξ(t), t ∈ R+ , in two steps. First, consider the
discrete time Markov chain η(k), k ∈ Z+ , Z+ = {0} ∪ N, with state space Z+ and transition
probabilities
 λ
if j = i + 1,
 λ+µ ,
µ
, if 0 ≤ j < i, i 6= 0,
(1)
P(η(k + 1) = j|η(k) = i) =
 i(λ+µ)
1,
if j = 1, i = 0,
where λ and µ are positive constants. Let η(0) = 0. Second, let ν(t), t ∈ R+ , be the Poisson
process with parameter Eν(t) = αt, where α is positive parameter. Suppose that the process
ν(·) and the chain η(·) are independent. Finally,
ξ(t) := η(ν(t)), t ∈ R+ .

(2)

In order to establish the large deviation result we consider the scaled process
ξT (t) :=

ξ(T t)
, t ∈ [0, 1], as T → ∞.
T

(3)

where T is an increasing parameter, T → ∞. We are interested in LDP for the family of
random variables ξT (1).
In the proof of LDP we use the standard implication (see, for example [4, Lemma
4.1.23]):
LLDP and ET ⇒ LDP,
where LLDP is Local Large Deviation Principle, and ET stands for Exponential tightness.
In the next section we recall definitions and formulate main result. In Section 3 we
prove the main result, Theorem 2.5. Auxiliary results are proved in Section 4.
2

2

Definitions and main results
Recall the definitions we need.

Definition 2.1. A family of random variables ξT (1) satisfies LLDP in R with the rate function I = I(x) : R → [0, ∞] and the normalizing function ψ(T ) :

lim ψ(T ) = ∞, if the

T →∞

following equality holds for any x ∈ R
lim lim sup

ε→0

T →∞

1
1
ln P(ξT (1) ∈ Uε (x)) = lim lim inf
ln P(ξT (1) ∈ Uε (x)) = −I(x),
ε→0 T →∞ ψ(T )
ψ(T )

where Uε (x) := {y ∈ R : |x − y| < ε}.
Definition 2.2. A family of random variables ξT (1) is exponentially tight on R if, for any
c < ∞, there exists a compact set Kc ∈ R such that
lim sup
T →∞

1
ln P(ξT (1) 6∈ Kc ) < −c.
ψ(T )

We denote the closure and interior of the set B by [B] and (B), respectively.
Definition 2.3. A family of random variables ξT (1) satisfies LDP on R with a rate function
I = I(f ) : R → [0, ∞] and the normalizing function ψ(T ) :

lim ψ(T ) = ∞, if for any

T →∞

c ≥ 0 the set {x ∈ R : I(x) ≤ c} is a compact set and, for any set B ∈ B(R) the following
inequalities hold:
1
ln P(ξT (1) ∈ B) ≤ −I([B]),
T →∞ ψ(T )
1
lim inf
ln P(ξT (1) ∈ B) ≥ −I((B)),
T →∞ ψ(T )

lim sup

where B(R) is the Borel σ-algebra on R, I(B) = inf I(x), I(∅) = ∞.
x∈B

Further we will use the following notations: B is a complement of the set B; I(B) is the
indicator function of the set B; [a] is the integer part of the number a.
We recall Low of Large Numbers (LLN), it was proved in [3].
Theorem 2.4. (LLN) For any ε > 0 the following equality holds true


P lim sup ξT (t) > ε = 0.
T →∞ t∈[0,1]

LDP is the main theorem in the paper.

3

Theorem 2.5. (LDP) The family of random variables ξT (1) satisfies LDP with normalized
function ψ(T ) = T and with rate function



 ∞,

x ln λ+µ
,
I(x) =
λ


x(λ+µ)
 x ln
− x + α,
αλ

if x ∈ (−∞, 0),
if x ∈ [0, α),
if x ∈ [α, ∞).

The proof of Theorem 2.5 provides the “most probable” trajectories of large deviations
ξT (1) > x. If x < α then there exists the moment tx,α = 1 − αx ∈ (0, 1) such that the process
ξT (·) stays near the zero up to the time tx,α and after that ξT (t), t ≥ tx,α increases according
the straight line which starts at point (tx,α , 0) and grows up to the point (1, x) with the
slope α, see the function f1 on Figure 1. If x ≥ α then the process grows together with the
straight line starting from origin up to the point (1, x), i.e. its slope is x, the function f2 on
Figure 1.

𝑥
𝑓2 𝑡 = 𝑥𝑡

𝛼

𝑥
𝑓1 𝑡 =
0

𝑡𝑥,𝛼

0, if 𝑡 ∈ 0, 𝑡𝑥,𝛼
𝛼 𝑡 − 𝑡𝑥,𝛼 , if 𝑡 ∈ [𝑡𝑥,𝛼 , 1]

1

Figure 1: The “most probable” trajectories which provide large fluctuations. If x < α then
the large deviation occurs according the function f1 . If x ≥ α, then the large deviation
trajectory is in the neighborhood of the straight line f2 .

3

Proof of Theorem 2.5

Random process ξ(t) we represent in the following way
ν2 (t)

ξ(t) = ν1 (t) −

X
k=0

4

ζk (ξ(τk −)),

(4)

where ν1 (t), ν2 (t) are independent Poisson point processes with parameters
Eν1 (t) =

αλ
αµ
t, Eν2 (t) =
t;
λ+µ
λ+µ

0 = τ0 < τ1 < · · · < τk . . . – jump moments of the process ν2 (t); random variables ζk (m),
k ∈ Z+ , m ∈ Z+ are mutually independent and do not depend on ν1 (t) and ν2 (t); ζ0 (m) = 0,
for all m ∈ Z+ ; for fixed k, m ∈ N the distribution of ζk (m) is given by
P(ζk (m) = r) =

1
, 1 ≤ r ≤ m,
m

and ζk (0) = −1, for all k ∈ N. Using representation (4), we have
ν2 (T t)
1 X
ν1 (T t)
−
ξT (t) =
ζk (ξ(τk −)) := ξT+ (t) − ξT− (t).
T
T k=0

From Theorem 2.4 follows that Theorem 2.5 holds true for x = 0. Prove the theorem for
x > 0. Let us estimate from above P(ξT (1) ≥ x), x > 0. For any δ > 0 and for any n ∈ N
we obtain
ν2 (T )


X
P(ξT (1) ≥ x) = P ν1 (T ) +
ζk (ξ(τk −)) ≥ T x
k=0
ν2 (T )
n−1 
X
X
ζk (ξ(τk −)) ≥ T x,
P ν1 (T ) +
≤
k=0

k=1

ν2 (T )

X
+ P ν1 (T ) +
ζk (ξ(τk −)) ≥ T x,

sup



(5)



ξT (t) ≤ δ := P1 + P2 .

t∈[ n−1
,1]
n

k=0

Estimate from above P1 .

P1 ≤ (n − 1) max P A,
1≤k≤n−1

sup ξT (t) ≤ δ, sup ξT (t) > δ
k
k
t∈[ k−1
t∈( n
,n
,1]
]
n


ξT (t) ≤ δ, inf ξT (t) > δ := (n − 1) max P1k , (6)
k
k
1≤k≤n−1
t∈[ k−1
t∈( n
,n
,1]
]
n
inf

where
ν2 (T )
n
o
X
A := ω : ν1 (T ) +
ζk (ξ(τk −)) ≥ T x .
k=0

Estimate from above P1k . For any c > 0 we have


 k − 1
≥ T (x − δ), Bc
P1k ≤ P ν1 (T ) − ν1 T
n


+ P A, inf ξT (t) ≤ δ, inf ξT (t) > δ, Bc := P11k + P21k ,
k
k
,n
t∈( n
,1]
t∈[ k−1
]
n
where

n
 k
o
Bc := ω : ν2 (T ) − ν2 T
≤ cT .
n
5

(7)

Since ν1 (·) and ν2 (·) are independent, then


 k − 1
≥ T (x − δ) P(Bc ).
P11k = P ν1 (T ) − ν1 T
n

(8)

Estimate from above P21k . For any a > 0 we obtain
P21k



≤ P A,

inf
k
,n
t∈[ k−1
]
n

ξT (t) ≤ δ, inf ξT (t) > δ, Bc ,
k
,1]
t∈( n

[cT ]
X

ζk (ξ(τkl −)) > aT



l=1

[cT ]


X
+ P inf ξT (t) > δ, Bc ,
ζk (ξ(τkl −)) ≤ aT
k
,1]
t∈( n
l=1


 k − 1
≥ T (x + a − δ)
≤ P ν1 (T ) − ν1 T
n
[cT ]


X
+ P inf ξT (t) > δ, Bc ,
ζkl (ξ(τkl −)) ≤ aT
k
,1]
t∈( n
l=1

(9)

[cT ]


[cT
 k − 1
\]
X
≥ T (x + a − δ) + P
Cl , Bc ,
ζkl (ξ(τkl −)) ≤ aT ,
≤ P ν1 (T ) − ν1 T
n
l=1
l=1



where τk1 , . . . , τk[cT ] are the first [cT ] jump times of the process ν2 (T t) for t ∈

k
n


, 1 , and

Cl := {ω : ξT (τkl −) > δ}.

(10)

For T sufficiently large and x + a − δ ≥ 1 we obtain

 k − 1
αλ(n−k+1)
≥ T (x + a − δ) = e− n(λ+µ) T
P ν1 (T ) − ν1 T
n


≤ e−
−

≤e

αλ(n−k+1)
T
n(λ+µ)

αλ(n−k+1)
T
n(λ+µ)





αλ(n − k + 1)T
[T (x + a/2 − δ)]n(λ + µ)

[T a]/2

[T a]/2
2αλ
[(x + a/2 − δ)](λ + µ)

∞
X

(αλ(n − k + 1)T )r
r!nr (λ + µ)r

r=[T (x+a−δ)]+1
∞
X

(αλ(n − k + 1)T )r
r!nr (λ + µ)r

(11)

r=[T (x+a/2−δ)]+1
∞
X

(αλ(n − k + 1)T )r
.
r!nr (λ + µ)r

r=[T (x−δ)]+1

Since there exists a∗ (x, α, δ, λ, µ) such that for all a ≥ a∗ the inequality


2αλ
[(x + a/2 − δ)](λ + µ)

[T a]/2

αµ

≤ e− (λ+µ) T ≤ P(Bc )

holds true, then from inequality (11) it follows that for a > a∗




k−1
≥ T (x + a − δ) ≤ P11k .
P ν1 (T ) − ν1 T
n
6

(12)

From Lemma 4.4 it follows that for any a > 0 and for T sufficiently large
P

 [cT
\]

Cl , Bc ,

[cT ]
X

l=1


ζkl (ξ(τkl −)) ≤ aT


≤

l=1

1
[δT ]

[cT ]

exp(aT ) ≤ P11k .

(13)

Choose a > a∗ . Using (7)–(11), (12), (13), we obtain for sufficiently large T




k−1
1
P1k ≤ 3P1k = 3P ν1 (T ) − ν1 T
≥ T (x − δ) P(Bc ).
n

(14)

From (6), (14) it follows that for all n ∈ N, δ > 0, c > 0




k−1
P1 ≤ 3(n − 1) max P ν1 (T ) − ν1 T
≥ T (x − δ) P(Bc ).
1≤k≤n−1
n
Estimate from above P2 . The following inequalities holds true for n ≥ exp
ν2 (T )



P2 = P ν1 (T ) +

X

ζk (ξ(τk −)) ≥ T x,

k=0

inf
t∈[ n−1
,1]
n

ξT (t) ≤ δ

α
x−δ

(15)




∞

 n − 1
X
αλ
(αλT )k
− n(λ+µ)
T
≥ T (x − δ) = e
≤ P ν1 (T ) − ν1 T
n
k!(n(λ + µ))k
k=[T (x−δ)]+1
 T (x−δ)
∞
∞
X
X
αλ
1
(αλT )k
(αλT )k
− n(λ+µ)
T
−αT
≤e
≤
e
n
k!(λ + µ)k
k!(λ + µ)k



αλ

k=[T (x−δ)]+1
∞
X

αµ

= e− (λ+µ) T e− (λ+µ) T

k=[T (x−δ)]+1

k=[T (x−δ)]+1

(αλT )k
≤ P111 .
k
k!(λ + µ)

Thus, from (5), (15) it follows that for n ≥ exp

α
x−δ




 k − 1

P(ξT (1) ≥ x) ≤ 4(n − 1) max P ν1 (T ) − ν1 T
≥ T (x − δ) P(Bc ).
1≤k≤n−1
n

(16)


α
,
Using Lemma 4.2, Lemma 4.3, Definition 2.3 and inequality (16) we obtain for n ≥ exp x−δ
δ > 0, c > 0



1
(y − δ)(λ + µ)n
lim sup ln P(ξT (1) ≥ x) ≤ max sup − (y − δ) ln
+ (y − δ)
1≤k≤n−1 y≥x
αλ(n − k + 1)
T →∞ T

αλ(n − k + 1) αµ(n − k) αµ(n − k)c
−
−
+
− c ln c .
(λ + µ)n
(λ + µ)n
(λ + µ)n
When δ → 0, c → 0 we obtain




1
y(λ + µ)n
αλ(n − k + 1) αµ(n − k)
lim sup ln P(ξT (1) ≥ x) ≤ max sup −y ln
+y−
−
.
1≤k≤n−1 y≥x
αλ(n − k + 1)
(λ + µ)n
(λ + µ)n
T →∞ T

7

And when n → ∞ we obtain




y(λ + µ)
αλz



αλz
αµz
− y ln
+y−
−
(λ + µ) (λ + µ)




y(λ + µ)
= sup sup − y ln
+ y − αz .
αλz
z∈(0,1) y≥x

1
lim sup ln P(ξT (1) ≥ x) ≤ sup sup
T →∞ T
z∈(0,1) y≥x



Finding the maximum of the function

f (y, z) = −y ln

y(λ + µ)
αλz


+ y − αz

in the domain y ≥ x, z ∈ [0, 1] we obtain
lim sup
T →∞

1
ln P(ξT (1) ≥ x) ≤ −I(x).
T

(17)

Estimate from below P(ξT (1) > x). Since the processes ν1 (·) and ν2 (·) are independent,
each with independent increments, then for all ε > 0, z ∈ (0, 1)


P(ξT (1) > x) = P ν1 (T ) +

ν2 (T )

X

ζk (ξ(τk −)) ≥ T x



k=0




≥ P ξT (1 − z) < ε, ν1 (T ) − ν1 (T (1 − z)) > T x, ν2 (T ) − ν2 (T (1 − z)) = 0



= P ξT (1 − z) < ε P ν1 (T ) − ν1 (T (1 − z)) > T x P ν2 (T ) − ν2 (T (1 − z)) = 0 .
From Theorem 2.4 and Lemma 4.2 it follows that for any z ∈ (0, 1)




αλz
αµz
1
y(λ + µ)
lim inf ln P(ξT (1) > x) ≥ sup − y ln
+y−
−
.
T →∞ T
αλz
(λ + µ)
(λ + µ)
y≥x
Since it holds for any z ∈ (0, 1), then
1
lim inf ln P(ξT (1) > x) ≥ sup sup
T →∞ T
z∈(0,1) y≥x




− y ln

y(λ + µ)
αλz




+ y − αz

= −I(x).

(18)

Let us prove the LLDP for the family of the random variables ξT (1). Applying (17), we
obtain
lim lim sup

ε→0

T →∞


1
1
ln P ξT (1) ∈ (x − ε, x + ε) ≤ lim lim sup ln P(ξT (1) ≥ x − ε)
ε→0 T →∞ T
T
≤ − lim I(x − ε) = −I(x).
ε→0

8

Using (17), (18) and the fact that the function I(x) is continuously differentiable function
for x > 0, we obtain
1
ln P(ξT (1) ∈ (x − ε, x + ε))
ε→0 T →∞ T

1
= lim lim inf ln P(ξT (1) > x − ε) − P(ξT (1) ≥ x + ε)
ε→0 T →∞ T


1
1
P(ξT (1) ≥ x + ε)
= lim lim inf ln P(ξT (1) > x − ε) + lim lim inf ln 1 −
ε→0 T →∞ T
ε→0 T →∞ T
P(ξT (1) > x − ε)


1
1
−T (I(x+ε)−I(x−ε)+o(1))
≥ lim lim inf ln P(ξT (1) > x − ε) + lim lim inf ln 1 − e
ε→0 T →∞ T
ε→0 T →∞ T


1
−T (2εI 0 (x̃)+o(1))
= −I(x),
= −I(x) + lim lim inf ln 1 − e
ε→0 T →∞ T
lim lim inf

where x̃ ∈ (x − ε, x + ε) is the point where I 0 (x̃) = (I(x + ε) − I(x − ε))/2ε. Thus LLDP is
proved.
Exponential tightness follows from (17) and the fact that for any c ≥ 0 the set I(x) ≤ c
is compact. 2

4

Auxiliary results
Here we will prove several auxiliary lemmas.

Lemma 4.1. For any a ∈ R the following inequality holds true
P

X
[cT ]





ζkl ([δT ]) ≤ aT

≤

l=1

1
[δT ]

[cT ]
exp(aT ).

P r o o f. Since ζkl ([δT ]), 1 ≤ l ≤ [cT ] are i.i.d., using Chebyshev inequality we obtain
X


 X


[cT ]
[cT ]
ζkl ([δT ]) ≤ aT = P exp −
ζkl ([δT ]) ≥ exp(−aT )
P
l=1

l=1


E exp


ζkl ([δT ])

l=1

≤
1
[δT ]

[δT
P]

[cT ]


E exp(−ζk1 ([δT ]))
=

exp(−aT )


=

−

[cT
P]

exp(−aT )

[cT ]
exp(−r)

r=1

exp(−aT )

2
9


≤

1
[δT ]

[cT ]
exp(aT ).

1
T

Lemma 4.2. The family of random variables


ν1 (T ) − ν1 (T ∆) , ∆ ∈ [0, 1) satisfies LDP

with normalized function ψ(T ) = T and rate function
(
∞, 

I1 (x) =
x(λ+µ)
− x + αλ(1−∆)
,
x ln αλ(1−∆)
λ+µ
P r o o f. Random variable

1
T

if x ∈ (−∞, 0),
if x ∈ [0, ∞).


ν1 (T ) − ν1 (T ∆) can be represented as a sum of independent

random variables which have the same distribution as ν1 (1 − ∆). Thus from [4, Theorem
2.2.3] it is enough to show that the Legendre transform of exponential moment of random
variable ν1 (1 − ∆) has the following form
Λ(x) = sup xy − ln Ee

yν1 (1−∆)





= x ln

y∈R

Since
yν1 (1−∆)

Ee


= exp

x(λ + µ)
αλ(1 − ∆)


−x+

αλ(1 − ∆)
, x ≥ 0.
λ+µ


αλ(1 − ∆) y αλ(1 − ∆)
e −
,
λ+µ
λ+µ

then the differential calculus finishes the proof. 2
Lemma 4.3. For any c ∈ [0, 1), ∆ ∈ [0, 1] the following inequality holds true
n αµ(1 − ∆)
o

αµ(1 − ∆)c
T+
T − T c ln c .
P ν2 (T ) − ν2 (∆T ) ≤ cT ≤ exp −
λ+µ
λ+µ
P r o o f. For any r > 0 by Chebyshev inequality we have



P ν2 (T ) − ν2 (∆T ) ≤ cT = P exp{−r(ν2 (T ) − ν2 (∆T ))} ≥ exp{−rcT }
n αµ(1 − ∆)
o
E exp{−r(ν2 (T ) − ν2 (∆T ))}
αµ(1 − ∆)
−r
≤
= exp e
T−
T + rcT .
exp{−rcT }
λ+µ
λ+µ
Choosing r = − ln c we obtain inequality (19). 2
Lemma 4.4. The following inequality holds true
P

 [cT
\]
l=1

Cl , Bc ,

[cT ]
X


ζkl (ξ(τkl −)) ≤ aT

l=1


≤

1
[δT ]

[cT ]

where Cl , 1 ≤ l ≤ [cT ] are defined by (10) on the previous section.
P r o o f. Define random variables
(
ζ̃kl (ml ) :=

ζkl (ml ),

if ζkl (ml ) ≤ [δT ],

γl ,

if ζkl (ml ) > [δT ],
10

exp(aT ),

(19)

where random variables γl , 1 ≤ l ≤ [cT ] are mutually independent and do not depend on
r
ζkl (ml ), ξ(τkl −), ml ∈ N, 1 ≤ l ≤ [cT ], ν1 (·), ν2 (·) and P(γl = r) =
, 1 ≤ r ≤ [δT ].
[δT ]
Since ζ̃kl (ξ(τkl −)) ≤ ζkl (ξ(τkl −)), then
P

 [cT
\]

Cl , Bc ,

l=1

[cT ]
X


ζkl (ξ(τkl −)) ≤ aT

≤P

 [cT
\]

l=1

Cl , Bc ,

[cT ]
X


ζ̃kl (ξ(τkl −)) ≤ aT .

(20)

l=1

l=1

Denote
n
o
V := v1 ∈ Z+ , . . . , v[cT ] ∈ Z+ : v1 + · · · + v[cT ] ≤ aT, max vl ≤ [δT ] .
1≤l≤[cT ]

We have
 [cT

[cT ]
\]
X
P
ζ̃kl (ξ(τkl −)) ≤ aT
Cl , Bc ,
l=1

=

l=1

 [cT

\]
Cl , ζ̃k1 (ξ(τk1 −)) = v1 , . . . , ζ̃k[cT ] (ξ(τk[cT ] −)) = v[cT ] , Bc
P

X
v1 ,...,v[cT ] ∈V

=

X

l=1

P

v1 ,...,v[cT ] ∈V

 [cT
\]

[cT ]

Cl ,

l=1

\


Dl , Bc

 [cT

\]
P
(Cl ∩ Dl ) Bc P(Bc ),

X

=

v1 ,...,v[cT ] ∈V

l=1

l=1

where

Dl := ω : ζ̃kl (ξ(τkl −)) = vl ,

1 ≤ l ≤ [cT ].

Let D0 := Ω, C0 := Ω. We will show that for 1 ≤ l ≤ [cT ] the following inequality holds


l−1
\
1
.
(21)
P Dl , Cl
(Cd ∩ Dd ), Bc ≤
[δT ]
d=0
Note that by definition, the family of random variables ζ̃kl (ml ), ml ∈ N do not depend on
ζ̃k1 (m1 ), m1 ∈ N, . . . , ζ̃kl−1 (ml−1 ), ml−1 ∈ N and ξ(τk1 −), . . . , ξ(τkl −), ν2 (·). Thus,

P Dl , Cl

l−1
\


(Cd ∩ Dd ), Bc

d=0


 
l
l−1
\
\
= P Dl
Cd
Dd , Bc P Cl
d=0

=

∞
X

d=0


P ζ̃kl (r) = vl ξ(τkl −) = r,

r=[δT ]

=

∞
X
r=[δT ]


1
P ξ(τkl −) = r
[δT ]

l
\
d=0

l−1
\


(Cd ∩ Dd ), Bc

d=0
l
\

l−1
\

d=0

d=0

d=0

Cd ,

Cd ,

l−1
\



l
l−1
\
\
≤ P Dl
Cd ,
Dd , Bc

 
Dd , Bc P ξ(τkl −) = r


Dd , Bc

d=0

11

=

1
,
[δT ]

d=0
l
\

l−1
\

d=0

d=0

Cd ,


Dd , Bc

where we used the fact that, if r ≥ [δT ], then P(ζ̃kl (r) = vl ) =

P

 [cT
\]
l=1

[cT ]

Cl ,

\


Dl , Bc

l=1

1
. Using (21) we obtain
[δT ]



[cT ]
[cT ] 
l−1
Y
\
1
=
.
P Dl , Cl
(Cd ∩ Dd ), Bc P(Bc ) ≤
[δT ]
l=1
d=0

Thus,
 [cT

[cT ]
\]
X
P
ζ̃kl (ξ(τkl −)) ≤ aT ≤
Cl , Bc ,
l=1



X
v1 ,...,v[cT ] ∈V

l=1

1
[δT ]

[cT ]
=P

X
[cT ]


ζkl ([δT ]) ≤ aT .

l=1

Therefore, from (20) and Lemma 4.1 it follows that
P

 [cT
\]

Cl , Bc

[cT ]
X

l=1


ζkl (ξ(τkl −)) ≤ aT

l=1


≤

1
[δT ]

[cT ]
exp(aT ).

2

Acknowledgments
This work is supported by FAPESP grant 2017/20482-0.
AL supported by RSF according to the research project 18-11-00129. AL thanks Institute of Mathematics and Statistics of University of São Paulo for hospitality. AY thanks
CNPq and FAPESP for the financial support via grants 301050/2016-3 and 2017/10555-0,
respectively.

References
[1] Brockwell, P. J., Gani, J., Resnick, S. I. (1982). Birth, immigration and catastrophe
processes. Advances in Applied Probability, 14(4), 709-731.
[2] Ben-Ari, I., Roitershtein, A., Schinazi, R. B. (2017). A random walk with catastrophes.
arXiv preprint arXiv:1709.04780.
[3] Logachev, A., Logacheva, O., Yambartsev, A. (2018) The local large deviation principle
for random walk with catastrophes. arXiv preprint arXiv:1806.07459.
[4] Dembo, A., Zeitouni, 0. (1998). Large deviations techniques and applications. Applications of Mathematics (New York), 38.

12

