Computational Complexity of Queries Based
on Itemsets

arXiv:1902.00633v1 [cs.CC] 2 Feb 2019

Nikolaj Tatti
HIIT Basic Research Unit, Laboratory of Computer and Information Science,
Helsinki University of Technology, Finland

Abstract
We investigate determining the exact bounds of the frequencies of conjunctions
based on frequent sets. Our scenario is an important special case of some general
probabilistic logic problems that are known to be intractable. We show that despite
the limitations our problems are also intractable, namely, we show that checking
whether the maximal consistent frequency of a query is larger than a given threshold
is NP-complete and that evaluating the Maximum Entropy estimate of a query is
PP-hard. We also prove that checking consistency is NP-complete.
Key words: Computational Complexity, Data Mining, Itemset

1

Introduction

Assume that we have two events, say a and b. Assume further that their
probabilities are P (a) = 0.6 and P (b) = 0.5. What can we say about the
probability of a∧b? We know that the probability must lie within I = [0.1, 0.5].
This interval is tight: For each f ∈ I there is a distribution having f as a
probability of a ∧ b. Also note that the Maximum Entropy estimate in this
case is 0.6 × 0.5 = 0.3.
A more complicated example would be the following: Assume three events
a1 , a2 , and a3 . Assume that we know P (a1 ), P (a2 ), P (a3 ), P (a1 ∧ a2 ) and
P (a1 ∧ a3 ). What can we say about P (a1 ∧ a2 ∧ a3 )?
Let us make these examples more general: A conjunctive query is a boolean
formula having the form a1 ∧ a2 ∧ . . . ∧ aL . Assume that we are given a set F
of conjunctive queries along with their probabilities. Assume also that we are
given a conjunctive query B not belonging to F . What can we tell about the
probability of this query? We know that the possible probabilities of the query
Preprint submitted to Elsevier Science

February 5, 2019

B correspond to some interval. In the paper we show that checking whether
the right side of this interval is larger than some threshold is NP-complete.
We also show that estimating the probability of the query B using Maximum
Entropy is PP-hard.
In the paper we adopt the terminology used in data mining of 0–1 data:
Conjunctive queries are represented by sets of items called itemsets and the
probabilities of conjunctive queries are called itemset frequencies.
Our problems are special cases of much more general problems (see Section 6
for detailed comparison). These general problems are well-studied and they
are all (at least) NP-hard. The difference is that in our work we concentrate
on studying antimonotonic families of itemsets. We should point out that
antimonotonic families are important since they tend to arise frequently in
practice, for example, in mining of frequent itemsets [1,2]. A similar technique
is used in [7] to prove that inference of Belief Networks is NP-hard. The result
of [7] is essentially Theorem 6 (in this paper) though it is in a different context.
The general boolean query scenario is reduced to Linear Programming in [10].
A method worth mentioning is introduced in [15] where the authors estimate
the frequencies using Maximum Entropy.

2

Preliminaries

In this section we give basic definitions used in mining of 0–1 data.
By a binary data set we mean a collection of binary vectors of length K
sampled from some distribution. We define a sample space Ω = {0, 1}K to
be the collection of all possible binary vectors of length K. From now on Ω
will always denote the sample space, K will denote the dimension of binary
vectors. Any distribution given in this paper will be defined on Ω.
It is custom to assign an attribute to each dimension of Ω. Thus, when we
speak of ai we mean the ith dimension. The set of all attributes is A =
{a1 , . . . , aK }. An itemset is a subset of A. Let B = {ai1 , . . . , aiL } be an itemset.
We often use a condensed notation B = ai1 · · · aiL . A family of itemsets is
called antimonotonic if all the subsets of any member are also included.
Let p be a distribution defined on Ω. We use the following notation: Let
B = ai1 · · · aiL be an itemset and let t be a binary vector of length L. Then
we shorten the notation p(ai1 = t1 , . . . , aiL = tL ) by p(B = t). By p(B = 1)
we mean p(B = t), where t contains only ones. The probability p(B = 1) is
called the frequency of B.
2

Assume a family {B1 , . . . , BN } of itemsets and a vector θ of length N. We say
that a distribution p satisfies the frequencies if θi = p(Bi = 1) for i = 1, . . . , N.
We say that these frequencies are consistent if there is a distribution satisfying
them.

3

Maximal Frequency Query is NP-complete

Assume that we want to find the frequency for an itemset B based on some
known family F of itemsets. We know that generally the frequency for B is not
unique: There may be distributions that produce different frequencies for B
but have the same frequencies of F . The set of all the consistent frequencies of
B is an interval [4]. In this section we focus on finding one side of this interval:
Problem 1 (MaxQuery) Assume that we are given an antimonotonic family F having N members along with rational and consistent frequencies θ.
Find the maximal frequency for a given itemset B that can be produced by a
distribution satisfying the frequencies θ.
In other words, we ask ourselves that, if we know the frequencies θ, then what
is the largest consistent frequency for B. Note that the maximal frequency
always exists since the frequencies θ are required to be consistent. Our goal in
this section is to show that in general this problem is intractable. First let us
give an example where the solution can be easily obtained.
Example 1 Assume that a family F contains only the itemsets of size one.
Then the frequency θai is the mean of the attribute ai . The maximal frequency
for an itemset B = b1 b2 · · · bM is min {θbi | i = 1, . . . , M}.
We know that MaxQuery can be solved by using Linear Programming [4]
though the resulting program contains an exponential number of variables.
This reduction along with some results from Linear Programming theory [14]
has important consequences: There is a distribution, say q, producing the
maximal frequency for B and having at most N + 1 non-zero entries. Also,
q has rational entries, and if L is the number of bits needed to specify the
denominator of an element of the frequency vector θ, then the

 number of bits
needed to specify the denominator of an entry of q is log2 (N + 1)3 2N L ∈
O(NL). We call such a distribution canonical.
Since NP is defined for yes/no problems we need the decision version of MaxQuery:
Problem 2 (MaxQueryDec) Assume that we are given an antimonotonic
family F having N members along with rational and consistent frequencies θ.
3

Given an itemset B and a rational threshold b is there a distribution satisfying
the frequencies θ such that the frequency of B is larger than b?
The relation between MaxQuery and MaxQueryDec is the following: Assume that we can solve MaxQuery in polynomial time, then we can clearly
solve MaxQueryDec in polynomial time. Assume now that we can solve
MaxQueryDec in polynomial time. Let f be the solution of MaxQuery.
We can find f using MaxQueryDec and dichotomous search. We know that
f is a rational number between 0 and 1 and that the denominator of f can
be expressed using O(NL) bits. Thus the number of required search steps is
O(NL).
Theorem 2 MaxQueryDec is in NP.

PROOF. Let q be a canonical distribution for MaxQuery. We can represent
this distribution in polynomial space, and hence we can use it as a certificate.
To check the certificate we need to check that q is a real distribution, that
it satisfies the frequencies and that its frequency for B is larger than the
threshold b.

Our next step is to reduce 3SAT to MaxQueryDec. In order to do that we
need the following lemma:
Lemma 3 Assume that two distributions p and q satisfy the frequencies θ of
an antimonotonic family F of itemsets. Let C ∈ F . Then p(C = t) = q(C = t)
for any binary vector t.

PROOF. Fix C = {c1 , . . . , cN } and t. Let U = {ci ∈ C | ti = 1} and let
W
W = C − U. Denote the elements of W by wi . Let p(U = 1, i wi = 1) be the
probability of U being 1 and at least one of wi being 1. We see that
p(C = t) = p(U = 1, W = 0) = p(U = 1) − p(U = 1,

_

wi = 1).

(1)

Let H = {H ⊆ W | H 6= ∅} be the collection of non-empty subsets of W . We
can express the last term of Eq. 1 by using the inclusion-exclusion principle
p(U = 1,

_

wi = 1) =

X

(−1)|H|+1 p(U = 1, H = 1).

(2)

H∈H

By combining Eqs. 1 and 2 we have expressed p(C = t) as a linear combination
of terms having the form p(B = 1) where B ⊆ C. Antimonotonicity implies
that all these frequencies are included in θ. This makes p(C = t) unique and
the lemma follows.
4

Theorem 4 3SAT is polynomial-time reducible to MaxQueryDec.

PROOF. Let R be an instance of 3SAT having L variables and M clauses.
We set the dimension of the sample space to be K = L + M. The first L
items correspond to the variables of R and the last M items correspond to
the clauses. We use the following notation: Let t be a truth assignment and
let Ci be a clause, then Ci (t) is a function resulting 1, if Ci is satisfied by t,
and 0 otherwise. We denote the first L items by vi and the last M items by
ci . We also set V = {v1 , . . . , vL } and W = {c1 , . . . , cM }.
We will now define an antimonotonic family F of itemsets. Let Ci be some
clause and let ci be its corresponding item. Assume that the items corresponding to the variables in Ci are v1 , v2 , and v3 . We add an itemset v1 v2 v3 ci to the
family F along with its subsets. We repeat this procedure to each clause in
R. The resulting family F contains 16M members at maximum.
The following step is to define the frequencies θ. In order to do this we define
a distribution p over the attributes to be

p(V = t, W = u) =



 2−L

0

if for all i we have ui = Ci (t)
otherwise.

That is, the first L items are distributed uniformly and the values of the last
M items are set to correspond to the truth values of the clauses.
We define the frequencies θi = p(Fi = 1), where Fi ∈ F . We note that the
frequencies are rational and consistent. There is a closed formula for evaluating
these frequencies. For example, assume that we have a clause C1 ≡ (v1 ∨v2 ∨v3 ).
The frequency of the itemset v1 v2 v3 c1 is then
X
t,u

p(V = t, W = u) =

1
p(V = t, W = u) = 2L−3 2−L = ,
8
t,ui =Ci (t)
X

where in the first summation t ranges over truth assignments such that t1 =
t2 = t3 = 1 and u ranges over binary vectors of length M such that u1 = 1.
In the second summation t ranges similarly as in the first summation and u is
now set to correspond to the clauses. The frequencies for the other members
of F can be deduced in a similar way. Thus we can obtain the frequencies θ
in polynomial time.
Let f be the maximal frequency for the itemset W . We claim that the formula
R is satisfiable if and only if f > 0.
5

Assume that R is satisfiable by a truth assignment, then we have
f = p(W = 1) ≥ p(V = t, W = 1) = 2−L > 0.
Assume now that there is a distribution q satisfying the frequencies and producing a positive frequency for W . Let t be a truth assignment not satisfying the formula, that is, there is a clause, say C1 = (v1 ∨ v2 ∨ v3 ), that is
not satisfied. Define G = v1 v2 v3 and u = [t1 , t2 , t3 ]. Lemma 3 implies that
q(V = t, W = 1) ≤ q(G = u, c1 = 1) = p(G = u, c1 = 1) = 0. By reversing
this property we get the following: If t is such that
q(V = t, W = 1) > 0

(3)

holds, then t must satisfy R.
By the assumption q(W = 1) > 0 so there exists a truth assignment t such
that Eq. 3 holds. Thus R is satisfiable. The reduction is complete if we set the
query B = W and the threshold b = 0.
Example 5 Consider the formula (v1 ∨ v2 ) ∧ (¬v2 ∨ v3 ). We have two clauses,
C1 and C2 , and three variables, v1 , v2 , and v3 . The itemset family along with
its frequencies (given in parenthesises) is

F=


 
 
 
 
  


1
1
1
1



∅ (1) , v1 2 , v2 2 , v3 2 , v1 v2 4 , v2 v3 14 , 




  

 
 
 
3

1

1

1

c1 4 , v1 c1 2 , v2 c1 2 , v1 v2 c1 4 ,


 
 
 
 



1
1
1
3

c2

4

, v2 c2

4

, v3 c2

2

, v2 v3 c2

4

.








The maximal frequency of c1 c2 for this setup (solved by linear programming)
is 21 . Clearly, the formula is satisfiable.

4

MaxEnt Frequency Query is PP-hard

In the previous section we showed that searching for the maximal frequencies
is a very hard problem. The maximal frequencies, however, are not so useful
if our goal is to estimate boolean queries from a given set of itemsets. A
much more useful approach is to use Maximum Entropy approach. Given a
P
distribution p defined on Ω, the entropy of p is E (p) = − ω∈Ω p(ω) log (p(ω)).
It is custom to define 0 log(0) = 0 so that E (p) is always defined.
Problem 3 (EntrQuery) Assume that we are given an antimonotonic family F having N members along with rational and consistent frequencies θ. Find
6

a frequency for a given itemset B produced by the distribution p satisfying the
frequencies θ and maximising the entropy E (p).
It has been empirically shown that EntrQuery results in a good approximation [15].
Again we need a decision version of the problem:
Problem 4 (EntrQueryDec) Assume that we are given an antimonotonic
family F having N members along with rational and consistent frequencies θ.
Let f be a frequency for a given itemset B produced by a distribution satisfying
the frequencies θ and maximising entropy. Is f larger than a given rational
threshold b?
The following theorem shows that EntrQueryDec is NP-hard.
Theorem 6 3SAT is polynomial-time reducible to EntrQueryDec.

PROOF. Let R be an instance of 3SAT. Let F , θ, V and B be the same
as in the proof of Theorem 4. Let P be the set of distributions satisfying the
frequencies θ. Let q ∈ P. A marginal distribution qV is obtained from q by
keeping only the items included in V . The distribution q has the following
property: The items corresponding to the clauses are completely determined
by the items corresponding to the variables. This implies that the entropy of
E (q) = E (qV ) [11, Theorem 4.2].
Let q̂ ∈ P be the distribution maximising the entropy. Let p ∈ P be the
distribution defined in the proof of Theorem 4. Note that E (q̂V ) = E (q̂) ≥
E (p) = E (pV ). We know that there is no distribution that has larger entropy
than the uniform distribution [11, Theorem 3.1]. Since pV is uniform, we must
have E (q̂V ) = E (pV ). Hence E (q̂) = E (p). We also know that the distribution
maximising entropy is unique [8, Theorem 3.1]. This implies that q̂ = p. To
complete the proof we note that p produces a positive frequency for B if and
only if R is satisfiable.

A problem P is in PP if there is a machine such that an input x is a yesinstance of P iff more than half of the computation paths end up accepting [13]. The class PP is (believed to be) larger than NP. We can show that
EntrQueryDec is PP-hard: In the proof the frequency of B is exactly the
number of satisfying assignments divided by 2−L . Hence, if we set the threshold b = 2−L/2 , the instance will be in EntrQueryDec iff the square root of
the number of assignments satisfy the given 3SAT formula. This problem is
known to be PP-complete [3].
7

5

Checking Consistency is NP-complete

So far we have assumed that the itemset frequencies given in our problems are
consistent. Let us remove this constraint and consider the following problem.
Problem 5 (Consistent) Assume that we are given an antimonotonic family F having N members along with rational frequencies θ. Are the frequencies
θ consistent?
The following theorem proves that Consistent is a very hard problem.
Theorem 7 Consistent is NP-complete.
PROOF. First, we need to show that Consistent is in NP. We know from
Linear Programming theory that if the frequencies are valid then there is a
canonical distribution satisfying the frequencies. This is our certificate and
thus Consistent is in NP.
We now prove that 3SAT is polynomial-time reducible to Consistent. We
use the same construction as in the proof of Theorem 4 with some additions:
We add one special attribute, say c0 , to the set of attributes. We add an
itemset c0 to F , and we also add itemsets having the form c0 ci to F . The
frequencies for the new itemsets are set to be 2−L , where L is the number of
variables appearing in the 3SAT instance R.
Assume that R is satisfiable by a truth assignment t. We define a distribution
q by extending the distribution p to c0 . The extension is done such that c0 is
1 iff V = t. Clearly, q satisfies the frequencies.
To prove the other direction, assume that there exists a distribution, say q,
that satisfies the frequencies. To prove that R is satisfiable we must prove that
q(W = 1) > 0. Select two attributes, say c1 and c2 . Note that q(c0 = 1, c1 =
0) = 0 and q(c0 = 1, c2 = 0) = 0. This implies that q(c0 = 1) = q(c0 = 1, c1 =
1, c2 = 1). We can prove in an iterative fashion that
q(W = 1) ≥ q(c0 = 1, W = 1) = q(c0 = 1) = 2−L .
This proves the result.

6

Connections to Related Work

An NP-complete problem called FreqSat introduced in [5,6] is a generalisation of Consistent — in FreqSat we are allowed to have non-antimonotonic
8

families and inequality constraints. We can transform MaxQueryDec into
FreqSat by changing the query into an inequality constraint. We should also
point out that the proof of NP-hardness of FreqSat given in [5] is (although
not explicitly mentioned) actually a valid proof for Consistent.
An even more general scenario is introduced in [12] in which we are allowed
to have conditional first-order logic sentences as constraints/queries. This scenario can be emulated by itemsets [6]. Also, a famous problem called PSat
in which we are given a CNF-formula, a frequency for each clause, and we are
asked whether there is a distribution satisfying the frequencies is known to be
NP-complete [9].

7

Conclusions

In this paper we studied certain boolean query problems. Our problems were
specialised (but frequently occurring and thus important) problems of much
general scenarios and we showed that despite the limitations our problems
remained intractable. The crux of the paper lies within the construction in
the proof of Theorem 4.
There are some open problems: For example, what is the exact complexity
of MaxQuery? Is it FNP-complete or FPNP -complete? Also, what is the
complexity of the opposite problem MinQuery? In addition, it is worthwhile
to study the conditions under which the boolean query problems can be solved
efficiently.

References
[1] Rakesh Agrawal, Tomasz Imielinski, and Arun N. Swami. Mining association
rules between sets of items in large databases. In Peter Buneman and
Sushil Jajodia, editors, Proceedings of the 1993 ACM SIGMOD International
Conference on Management of Data, pages 207–216, Washington, D.C., 26–
28 1993.
[2] Rakesh Agrawal, Heikki Mannila, Ramakrishnan Srikant, Hannu Toivonen, and
Aino Inkeri Verkamo. Fast discovery of association rules. In U.M. Fayyad,
G. Piatetsky-Shapiro, P. Smyth, and R. Uthurusamy, editors, Advances in
Knowledge Discovery and Data Mining, pages 307–328. AAAI Press/The MIT
Press, 1996.
[3] Delbert D. Bailey, Victor Dalmau, and Phokion G. Kolaitis. Phase transitions
of PP-complete satisfiability problems. In IJCAI, pages 183–192, 2001.

9

[4] Artur Bykowski, Jouni K. Seppänen, and Jaakko Hollmén. Model-independent
bounding of the supports of Boolean formulae in binary data. In Pier Luca
Lanzi and Rosa Meo, editors, Database technologies for data mining. Springer
Verlag, 2003.
[5] Toon Calders. Axiomatization and Deduction Rules for the Frequency of
Itemsets. PhD thesis, University of Antwerp, Belgium, 2003.
[6] Toon Calders. Computational complexity of itemset frequency satisfiability.
In Proceedings of the 23nd ACM SIGMOD-SIGACT-SIGART Symposium on
Principles of Database System, 2004.
[7] Gregory Cooper. The computational complexity of probabilistic inference using
bayesian belief networks. Artificial Intelligence, 42(2–3):393–405, Mar. 1990.
[8] I. Csiszár. I-divergence geometry of probability distributions and minimization
problems. The Annals of Probability, 3(1):146–158, Feb. 1975.
[9] George Georgakopoulos, Dimitris Kavvadias, and Christos H. Papadimitriou.
Probabilistic satisfiability. Journal of Complexity, 4(1):1–11, March 1988.
[10] Theodore Hailperin. Best possible inequalities for the probability of a logical
function of events. The American Mathematical Monthly, 72(4):343–359, Apr.
1965.
[11] Solomon Kullback. Information Theory and Statistics. Dover Publications, Inc.,
1968.
[12] Thomas Lukasiewicz.
Probabilistic logic programming with conditional
constraints. ACM Transactions on Computational Logic (TOCL), 2(3):289–
339, July 2001.
[13] Christos Papadimitriou. Computional Complexity. Addison-Wesley, 1995.
[14] Christos Papadimitriou and Kenneth Steiglitz. Combinatorial Optimization
Algorithms and Complexity. Dover, 2nd edition, 1998.
[15] Dmitry Pavlov, Heikki Mannila, and Padhraic Smyth. Beyond independence:
Probabilistic models for query approximation on binary transaction data. IEEE
Transactions on Knowledge and Data Engineering, 15(6):1409–1421, 2003.

10

