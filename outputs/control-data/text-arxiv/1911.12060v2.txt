1

Reviewing and Improving the Gaussian Mechanism
for Differential Privacy

arXiv:1911.12060v2 [cs.CR] 7 Dec 2019

Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi, Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu

Abstract—Differential privacy provides a rigorous framework
to quantify data privacy, and has received considerable
interest recently. A randomized mechanism satisfying
(ǫ, δ)-differential privacy (DP) roughly means that, except
with a small probability δ, altering a record in a dataset cannot
change the probability that an output is seen by more than a
multiplicative factor eǫ . A well-known solution to (ǫ, δ)-DP is
the Gaussian mechanism initiated by Dwork et al. [1] in 2006
with an improvement byq
Dwork and Roth [2] inq2014, where a
Gaussian noise amount 2 ln 2δ × ∆
of [1] or 2 ln 1.25
× ∆
ǫ
δ
ǫ
of [2] is added independently to each dimension of the query
result, for a query with ℓ2 -sensitivity ∆. Although both classical
Gaussian mechanisms [1], [2] explicitly assume 0 < ǫ ≤ 1
only, our review finds that many studies in the literature have
used the classical Gaussian mechanisms under values of ǫ
and δ where we show the added noise amounts of [1], [2] do
not achieve (ǫ, δ)-DP. We obtain such result by analyzing the
optimal (i.e., least) Gaussian noise amount σDP-OPT for (ǫ, δ)-DP
and identifying the set of ǫ and δ where the noise amounts of
classical Gaussian mechanisms are even less than σDP-OPT . The
inapplicability of mechanisms of [1], [2] to large ǫ can also be
seen from
our result that σDP-OPT for large ǫ can be written as

Θ √1ǫ , but not Θ 1ǫ .
Since σDP-OPT has no closed-form expression and needs to
be approximated in an iterative manner, we propose Gaussian
mechanisms by deriving closed-form upper bounds for σDP-OPT .
Our mechanisms achieve (ǫ, δ)-DP for any ǫ, while the classical
Gaussian mechanisms [1], [2] do not achieve (ǫ, δ)-DP for large
ǫ given δ. Moreover, the utilities of our proposed Gaussian mechanisms improve those of the classical Gaussian mechanisms [1],
[2] and are close to that of the optimal yet more computationally
expensive Gaussian mechanism.
Since most mechanisms proposed in the literature for (ǫ, δ)-DP
are obtained by ensuring a condition called (ǫ, δ)-probabilistic
differential privacy (pDP), we also present an extensive discussion
of (ǫ, δ)-pDP including deriving Gaussian noise amounts to
achieve it.
To summarize, our paper fixes the literature’s long-time misuse
of Gaussian mechanism [1], [2] for (ǫ, δ)-differential privacy and
provides a comprehensive study for the Gaussian mechanisms.
Index Terms—Differential privacy, Gaussian mechanism, probabilistic differential privacy, data analysis.

I. I NTRODUCTION
Differential privacy. Differential privacy [3] has received
considerable interest [1], [4]–[11] since it provides a rigorJun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, and Han Yu are with
Nanyang Technological University, Singapore (Emails: junzhao@ntu.edu.sg,
N1805892E@e.ntu.edu.sg, bait0002@e.ntu.edu.sg, kwokyan.lam@ntu.edu.sg,
han.yu@ntu.edu.sg).
Zhiying Xu and Shuyu Shi are with Nanjing University, China (Emails:
zyxu@smail.nju.edu.cn, ssy@nju.edu.cn).
Xuebin Ren and Xinyu Yang are with Xi’an Jiaotong University, China
(Emails: xuebinren@mail.xjtu.edu.cn, yxyphd@mail.xjtu.edu.cn).
Yang Liu is with WeBank Co Ltd, China (Email: yangliu@webank.com).

ous framework to quantify data privacy. Roughly speaking,
a randomized mechanism achieving (ǫ, δ)-differential privacy
(DP) means that, except with a (typically small) probability
δ, altering a record in a dataset cannot change the probability
that an output is seen by more than a multiplicative factor
eǫ . Formally, for D and D′ iterating through all pairs of
neighboring datasets which differ by one record, and for Y
iterating through all subsets of the output range of a randomized mechanism Y , the mechanism Y achieves (ǫ, δ)-DP if
P [Y (D) ∈ Y] ≤ eǫ P [Y (D′ ) ∈ Y] + δ, where P [·] denotes the
probability, and the probability space is over the coin flips of
the randomized mechanism Y . If δ = 0, the notion of (ǫ, δ)DP becomes ǫ-DP.
Classical Gaussian mechanisms [1], [2] to achieve
(ǫ, δ)-differential privacy. Among various mechanisms to
achieve DP, the Gaussian mechanism for real-valued queries
initiated by [1] has received much attention, where a certain
amount of zero-mean Gaussian noise is added independently
to each dimension of the query result. Below, for a Gaussian
mechanism with parameter σ, we mean that σ is the standard
deviation of the Gaussian noise.
As shown in [1], [2], the noise amount in the Gaussian
mechanism scales with the ℓ2 -sensitivity ∆ of a query, which
is defined as the maximal ℓ2 distance between the true query
results for any two neighboring datasets D and D′ that differ
in one record; i.e., ∆ = maxneighboring D, D′ kQ(D) − Q(D′ )k2 .
We will elaborate the notion of neighboring datasets in Remark 1 on Page 4. For a query with ℓ2 -sensitivity1 ∆, the
noise amount in the first Gaussian mechanism proposed by
Dwork et al. [1] in 2006 to achieve (ǫ, δ)-DP, denoted by
Dwork-2006, is given by
q
(1)
σDwork-2006 := 2 ln δ2 × ∆ǫ .
Improving Dwork-2006 via a smaller amount of noise
addition, the Gaussian mechanism by Dwork and Roth [2]
in 2014, denoted by Dwork-2014, adds Gaussian noise with
standard deviation
q
∆
σDwork-2014 := 2 ln 1.25
(2)
δ × ǫ .

Both Page 6 in [1] for Dwork-2006 and Theorem A.1
on Page 261 in [2] for Dwork-2014 consider ǫ ≤ 1. We
will formally prove that Dwork-2006 and Dwork-2014
fail to achieve (ǫ, δ)-DP for large ǫ given δ. Moreover, we
will show in Section III that many studies [7], [8], [12]–
1 For p = 1, 2, . . ., the ℓ -sensitivity of a query Q is defined as the maximal
p
ℓp distance between the outputs for two neighboring datasets D and D ′ that
differ in one record: ∆Q,p = maxneighboring D, D ′ kQ(D) − Q(D ′ )kp .

2

[21] applying Dwork-2006 and Dwork-2014 neglect the
condition ǫ ≤ 1, and use Dwork-2006 or Dwork-2014
under values of ǫ and δ where the added Gaussian noise
amount actually does not achieve (ǫ, δ)-DP. This renders their
obtained results inaccurate.
One may wonder why we consider both mechanisms since
clearly it holds that
σDwork-2014 in Eq. (2) < σDwork-2006 in Eq. (1).

(3)

The reason is as follows. Although Dwork-2014 achieves
higher utility than that of Dwork-2006 for the set of ǫ and δ
under which they both achieve (ǫ, δ)-DP, Dwork-2006 has
wider applicability than Dwork-2014; i.e., the set of ǫ and
δ where Dwork-2014 achieves (ǫ, δ)-DP is a strict subset
of the set of ǫ and δ where Dwork-2006 achieves (ǫ, δ)-DP.
Given the above, we discuss both mechanisms.
Our contributions. We make the following contributions
in this paper.
1) Failures of classical Gaussian mechanisms for large ǫ.
We prove (in Theorem 1 on Page 4) that the classical Gaussian mechanisms Dwork-2006 of [1] and Dwork-2014
of [2] fail to achieve (ǫ, δ)-DP for large ǫ given δ. In
fact, we prove that for any Gaussian mechanism with noise
amount F (δ) × ∆ǫ for some function F (δ), there exists
a positive function G(δ) for any 0 < δ < 1 such that the
above Gaussian mechanism does not achieve (ǫ, δ)-DP for
any ǫ > G(δ). The above result applies to Dwork-2006
and
F (δ) as
q
q Dwork-2014, where the former specifies
2
1.25
2 ln δ and the latter specifies F (δ) as 2 ln δ .
2) The literature’s misuse of classical Gaussian mechanisms for large ǫ. After a literature review (in Table I
on Page 5), we find that many papers [7], [8], [12]–[21]
use the classical Gaussian mechanism Dwork-2006 or
Dwork-2014 under values of ǫ and δ where the added
noise amount actually does not achieve (ǫ, δ)-DP. This
makes their obtained results inaccurate.

no closed-form expression and needs to be approximated
in an iterative manner. Hence, we propose new Gaussian
mechanisms (Mechanism 1 and Mechanism 2 in Theorems 4 and 5 on Page 6) by deriving closed-form upper
bounds for σDP-OPT . We summarize the advantages of our
Gaussian mechanisms as follows.
i) As discussed, our Gaussian mechanisms have
closed-form expressions and are computationally
efficient than [22]’s optimal Gaussian noise amount,
which has no closed-form expression and needs to
be approximated in an iterative manner. In addition,
both numerical and experimental studies show that the
utilities of our Gaussian mechanisms are close to that
of the optimal yet more computationally expensive
Gaussian mechanism by [22].
ii) Our Gaussian mechanisms all achieve (ǫ, δ)-DP for
any ǫ, while the classical Gaussian mechanisms
Dwork-2006 of [1] and Dwork-2014 of [2] were
proposed for only 0 < ǫ ≤ 1 and we show that they do
not achieve (ǫ, δ)-DP for large ǫ given δ, as noted in
Contribution 1) above.
iii) We prove (in Inequality (10) on Page 7) that the noise
amounts of our Gaussian mechanisms are less than that
of Dwork-2014 (and hence also less than that of
Dwork-2006), for 0 < ǫ ≤ 1 where the proofs of
Dwork-2006 of [1] and Dwork-2014 of [2] require.
iv) For a subset of ǫ > 1 where Dwork-2014 happens
to work (Dwork-2014’s original proof requires ǫ ≤
1), experiments (in Figure 2 on Page 7) show that our
Mechanism 1 often adds noise amount less than that
of Dwork-2014.
5) (ǫ, δ)-Differential privacy versus (ǫ, δ)-probabilistic differential privacy. Since most mechanisms proposed in the
literature for (ǫ, δ)-differential privacy (DP) are obtained
by ensuring a notion called (ǫ, δ)-probabilistic differential
privacy (pDP), which requires the privacy loss random
variable to fall in the interval [−ǫ, ǫ] with probability at
least 1 − δ, we also investigate (ǫ, δ)-pDP, and show its
difference/relationship with (ǫ, δ)-DP (in Section VI on
Page 7). In particular, the minimal Gaussian noise amount
to achieve (ǫ, δ)-pDP given δ scales with 1ǫ as ǫ → 0 (from
Theorem 7 on Page 8), while the minimal Gaussian noise
amount to achieve (ǫ, δ)-DP given δ converges to its upper
∆
as ǫ → 0 (from Theorem 3 on Page 5).
bound 2√2·inverf(δ)
Moreover, while clearly (ǫ, δ)-pDP implies (ǫ, δ)-DP, we
−ǫ∗
)
also prove that (ǫ, δ)-DP implies (ǫ∗ , δ(1+e
1−eǫ−ǫ∗ )-pDP for
any ǫ∗ > ǫ.

3) An ǫ-independent upper bound and asympotics of the
optimal Gaussian noise amount for (ǫ, δ)-DP. We prove
(in Theorem 3 on Page 5) that the optimal (i.e., least)
Gaussian noise amount σDP-OPT for (ǫ, δ)-DP is always
∆
less than 2√2·inverf(δ)
, which does not depend on ǫ, where
inverf() denotes the inverse of the error function. This is
in contrast to the classical Gaussian mechanisms’ noise
amounts σDwork-2006 in Eq. (1) and σDwork-2014 in Eq. (2)
which scale with 1ǫ and tend to ∞ as ǫ → 0. In fact, we
prove that σDP-OPT given a fixed δ converges
 to its upper
∆
2
√
bound 2 2·inverf(δ) as ǫ → 0, and is Θ √1ǫ as ǫ → ∞.
q
 6) Gaussian mechanisms for (ǫ, δ)-probabilistic differenAlso, we show that σDP-OPT given a fixed ǫ is Θ
ln 1δ
tial privacy. For (ǫ, δ)-pDP, we also derive the optimal
Gaussian
mechanism (in Theorem 6 on Page 8) which
as δ → 0.
adds
the
least amount of Gaussian noise (denoted by
4) Our Gaussian mechanisms for (ǫ, δ)-differential priσ
).
However, since σpDP-OPT has no closed-form
pDP-OPT
vacy with closed-form expressions. Although the optimal
expression
and needs to be approximated in an iterative
Gaussian mechanism for (ǫ, δ)-DP has been proposed in
manner,
we
propose Gaussian mechanisms for (ǫ, δ)-pDP
a very recent work [22], its noise amount σDP-OPT has
(Mechanism 3 and Mechanism 4 in Theorems 8 and 9
2 A positive sequence x can be written as Θ (y) for a positive sequence y
on Page 9) by deriving more computationally efficient
if lim inf

x
y

and lim sup

x
y

are greater than 0 and smaller than ∞.

3

upper bounds (in closed-form expressions) for σpDP-OPT .
Organization. The rest of the paper is organized as follows.
• Section II surveys related work.
• In Section III, we elaborate (ǫ, δ)-differential privacy (DP)
and review the literature’s misuse of classical Gaussian
mechanisms.
• In Section IV, we discuss the optimal Gaussian mechanism
for (ǫ, δ)-DP, where the noise amount has no closed-form
expression.
• Section V presents our Gaussian mechanisms for (ǫ, δ)-DP
with closed-form expressions of noise amounts.
• Since most mechanisms proposed in the literature for
(ǫ, δ)-DP are obtained by ensuring a notion called (ǫ, δ)probabilistic differential privacy (pDP), Section VI is devoted to (ǫ, δ)-pDP, where we discuss the difference/relationship between (ǫ, δ)-pDP and (ǫ, δ)-DP, and derive
the optimal Gaussian mechanism for (ǫ, δ)-pDP, where the
noise amount has no closed-form expression. Then we propose Gaussian mechanisms for (ǫ, δ)-pDP with closed-form
expressions of noise amounts.
• In view that concentrated differential privacy [9] and related
notions [10], [23], [24] have recently been proposed as
variants of differential privacy, we show in Section VII
that achieving (ǫ, δ)-DP by ensuring one of these privacy
definitions gives Gaussian mechanisms worse than ours.
• Section VIII presents experimental results.
• We conclude the paper in Section IX.

Due to the space limitation, additional details including the
proofs are provided in the appendices of this supplementary
file.
Notation. Throughout the paper, P [·] denotes the probability, and F [·] stands for the probability density function. The
error function is denotedR by erf(), and its complement is
2
x
erfc(); i.e., erf(x) := √2π 0 e−t dt and erfc(x) := 1 − erf(x).
In addition, inverf() is the inverse of the error function, and
inverfc() is the inverse of the complementary error function.
II. R ELATED W ORK
Differential privacy. The notion of differential privacy
(DP) [3] has received much attention [25]–[30] since it provides a rigorous framework to quantify data privacy. The
Gaussian mechanism to achieve DP has been investigated
in [1], [2], while the Laplace mechanism is introduced in [3]
and the exponential mechanism is proposed in [31]. The Gaussian (resp., Laplace) mechanism adds independent Gaussian
(resp., Laplace) noise to each dimension of the query result,
while the exponential mechanism can address non-numeric
queries. Recently, the following mechanisms to achieve DP
have been proposed: the truncated Laplacian mechanism [32],
the staircase mechanism [33], [34], and the Podium mechanism [35]. Compared with these mechanisms, the Gaussian
mechanism is more friendly for composition analysis since
the privacy loss random variable (defined in Section VI on
Page 7) after composing independent Gaussian mechanisms
follows a Gaussian distribution, whereas the privacy loss
after composing independent truncated Laplacian mechanisms

(staircase mechanisms, or podium mechanisms) has a complicated probability distribution.
Use of Gaussian mechanism. The Gaussian mechanism has been used by Dwork et al. [27] to design algorithms for privacy-preserving principal component analysis.
Nikolov et al. [28] leverage the Gaussian mechanism for
differentially private release of a k-way marginal query. The
Gaussian mechanism is also used by Hsu et al. [29] for
enabling multiple parties to distributedly solve convex optimization problems in a privacy-preserving and distributed
manner. Gilbert and McMillan [36] apply the Gaussian
mechanism to differentially private recovery of heat source
location. Bun et al. [37] employ the Gaussian mechanism to
derive a lower bound on the length of a combinatorial object
called a fingerprinting code, proposed by Boneh and Shaw [38]
for watermarking copyrighted content. Abadi et al. [26] apply
(ǫ, δ)-DP to stochastic gradient descent of deep learning, where
the Gaussian mechanism is used for adding noise to the
gradient. Recently, Liu [39] have presented a generalized
Gaussian mechanism based on the ℓp -sensitivity1 .
Probabilistic differential privacy. Most mechanisms proposed in the literature for (ǫ, δ)-DP are obtained by ensuring a notion called (ǫ, δ)-probabilistic differential privacy
(pDP) [40], which requires the privacy loss random variable
to fall in the interval [−ǫ, ǫ] with probability at least 1 − δ.
For the formal definition and results discussed below, see
Section VI for details, where we present i) relations between
(ǫ, δ)-DP and (ǫ, δ)-pDP, ii) an analytical but not closed-form
expression for the optimal Gaussian mechanism (denoted by
Mechanism pDP-OPT) to achieve (ǫ, δ)-pDP, and iii) Gaussian mechanisms for (ǫ, δ)-pDP, denoted by Mechanism 3
and Mechanism 4, respectively.
Other variants of differential privacy. Different variants of differential privacy have been proposed in the
literature recently, including mean-concentrated differential
privacy (mCDP) [9], zero-concentrated differential privacy
(zCDP) [10], Rényi differential privacy [23] (RDP), and
truncated concentrated differential privacy (tCDP) [24]. These
notions are more complex than (ǫ, δ)-DP, so we believe that
(ǫ, δ)-DP will still be used in many applications. Therefore, any
issue concerning the classical Gaussian mechanism for (ǫ, δ)DP is worthy of serious discussions in the research community.
Moreover, we show in Section VII on Page 10 that achieving
(ǫ, δ)-DP by ensuring one of these privacy definitions (i.e.,
mCDP, zCDP, RDP, and tCDP) gives Gaussian mechanisms
worse than ours.
Composition. One of the appealing properties of differential
privacy is the composition property [2], meaning that the
composition of differentially private algorithms satisfies a
certain level of differential privacy. In Appendix P of this
supplementary file, we provide analyses for the composition
of Gaussian mechanisms. Our result is that for m queries
Q1 , Q2 , . . . , Qm with ℓ2 -sensitivity ∆1 , ∆2 , . . . , ∆m , if the
query result of Qi is added with independent Gaussian noise
of amount (i.e., standard deviation) σi , then the differential
privacy (DP) level for the composition of the m noisy answers
is the same as that of a Gaussian mechanism with noise

4

−1/2
P
m ∆i 2
for a query with ℓ2 -sensitivity points (δ, G∗ (δ)) such that Dwork-2014 does not achieve
amount σ∗ :=
i=1 σi 2
(ǫ, δ)-differential privacy for ǫ > G∗ (δ); e.g., G∗ (10−3 ) =
DP
1. Let σǫ,δ be a Gaussian noise amount which achieves
7.47, G∗ (10−4 ) = 8.00, G∗ (10−5 ) = 8.43, and G∗ (10−6 ) =
(ǫ, δ)-DP for a query with ℓ2 -sensitivity 1, where the expres8.79. For the Gaussian mechanism Dwork-2006 of [1], the
DP
sion of σǫ,δ
can follow from classical Dwork-2006 and
blue line in Figure 1(ii) on Page 5 illustrates all points
Dwork-2014 of [1], [2] (when ǫ ≤ 1), the optimal one (i.e.,
(δ, G# (δ)) such that Dwork-2006 does not achieve (ǫ, δ)DP-OPT), or our proposed mechanisms (i.e., Mechanism 1
differential privacy for ǫ > G# (δ); e.g., G# (10−3 ) = 8.51,
and Mechanism 2). Then the above composition satisfies
G# (10−4 ) = 8.99, G# (10−5 ) = 9.39, and G# (10−6 ) =
DP
(ǫ, δ)-DP for ǫ and δ satisfying σ∗ ≥ σǫ,δ
with σ∗ defined
9.73.
above.
The literature’s misuse of the classical Gaussian mechIII. (ǫ, δ)-D IFFERENTIAL P RIVACY AND U SAGE OF THE
anisms. After a literature review, we find that many paG AUSSIAN M ECHANISM
pers [7], [8], [12]–[21] use the classical Gaussian mechanism
The formal definition of (ǫ, δ)-differential privacy [1] is as Dwork-2006 (resp., Dwork-2014) under values of ǫ and
δ where Dwork-2006 (resp., Dwork-2014) actually does
follows.
not achieve (ǫ, δ)-differential privacy. Table I on Page 5 sumDefinition 1 ((ǫ, δ)-Differential privacy [1]). A randomized marizes selected papers which misuse the classical Gaussian
algorithm Y satisfies (ǫ, δ)-differential privacy, if for any two mechanism Dwork-2006 or Dwork-2014.
neighboring datasets D and D′ that differ only in one record,
Usage of ǫ > 1. Although ǫ ≤ 1 is preferred in practical
and for any possible subset of outputs Y of Y , we have
applications, there are still cases where ǫ > 1 is used, so
P [Y (D) ∈ Y] ≤ eǫ · P [Y (D′ ) ∈ Y] + δ.
(4) it is necessary to have Gaussian mechanisms which apply to
not only ǫ ≤ 1 but also ǫ > 1. We discuss usage of ǫ > 1 as
where P [·] denotes the probability of an event. If δ = 0, Y is follows. First, the references [7], [8], [12]–[21] in Table I have
said to satisfy ǫ-differential privacy.
used ǫ > 1. Second, the Differential Privacy Synthetic Data
Challenge
organized by the National Institute of Standards
Remark 1 (Notion of neighboring datasets). Two datasets
′
and
Technology
(NIST) [41] included experiments of ǫ as
D and D are called neighboring if they differ only in
10.
Third,
for
a
variant of differential privacy called local
one record. There are still variants about this. In the first
′
′
differential
privacy
[42] which is implemented in several
case, the size of D and D differ by one so that D is
industrial
applications,
Apple [43], [44] and Google [45] have
obtained by adding one record to D or deleting one record
′
adopted
ǫ
>
1.
from D. In the second case, D and D have the same size
(say n), and have different records at only one of the n
positions. Finally, the notion of neighboring datasets can also
IV. T HE O PTIMAL G AUSSIAN M ECHANISM FOR
be defined to include both cases above. Our results in this
(ǫ, δ)-D IFFERENTIAL P RIVACY
paper do not rely on how neighboring datasets are specifically
A recent work [22] of Balle and Wang in ICML 2018 andefined. In a differential privacy application, after the notion alyzed the optimal Gaussian mechanism for (ǫ, δ)-differential
of neighboring datasets is defined, what we need is just the ℓ2 - privacy, where “optimal” means that the noise amount is the
sensitivity ∆ of a query Q with respect to neighboring datasets: least among Gaussian mechanisms. This optimal Gaussian
∆ = maxneighboring datasets D, D′ kQ(D) − Q(D′ )k2 .
mechanism is also analyzed by Sommer et al. [46], where
Theorem 1 below shows failures of the classical Gaussian
mechanisms [1], [2] for large ǫ.

the shape of the privacy loss is also discussed. Based on [22],
we present Theorem 2 below.

Theorem 1 (Failures of the classical Gaussian mechanisms
of Dwork and Roth [2] and of Dwork et al. [1] to achieve
(ǫ, δ)-differential privacy for large ǫ). For a positive function
F (δ), consider a Gaussian mechanism which adds Gaussian
noise with standard deviation F (δ) × ∆
ǫ to each dimension
of a query with ℓ2 -sensitivity ∆. With an arbitrarily fixed
0 < δ < 1, as ǫ increases, the above Gaussian mechanism
does not achieve (ǫ, δ)-differential privacy for large enough ǫ
(specifically, for any ǫ > G(δ) with G(δ) being some positive
function). This result applies to the classical Gaussian mechanism Dwork-2014 of Dwork and Roth [2] and mechanism
Dwork-2006
of Dwork et al. [1], where the former q
specifies
q
1.25
F (δ) as 2 ln δ and the latter specifies F (δ) as 2 ln 2δ .

Theorem 2 (Optimal Gaussian mechanism for
(ǫ, δ)-differential privacy). The optimal Gaussian mechanism
for (ǫ, δ)-differential privacy, denoted by Mechanism DP-OPT,
adds Gaussian noise with standard deviation σDP-OPT specified
below to each dimension of a query with ℓ2 -sensitivity ∆.
(i) We derive σDP-OPT as follows based on Theorem 8 of Balle
and Wang [22]:

p
a2 + ǫ = 2δ,
With a satisfying erfc (a) − eǫ erfc
we get σDP-OPT :=

(a+

√
a2 +ǫ )·∆
√
,
ǫ 2

(5)

where erfc() is the complementary error function.
For ǫ ≥ 0.01 and 0 < δ ≤ 0.05, we prove the following
results:
We formally prove Theorem 1 in Appendix B.
(ii) σDP-OPT > √∆2ǫ .
Remark 2. For the Gaussian mechanism Dwork-2014
q
1
√∆
·∆
of [2], the blue line in Figure 1(i) on Page 5 illustrates all (iii) σDP-OPT < 2 ln 2δ
ǫ + 2ǫ .

5

1

1

0.8

0.8

0.6

0.6
10-3

0.4
0.2

10

-4

10

-5

10-3

0.4

10-4
10-5

0.2

10-6
7.5

8

10-6

8.5

8.5

0

9

9.5

0
0

5

10

15

20

(i) Mechanism Dwork-2014 of Dwork and Roth [2]

0

5

10

15

20

(ii) Mechanism Dwork-2006 of Dwork et al. [1]

Fig. 1: The shaded area in each subfigure represents the set of (ǫ, δ) where Mechanism Dwork-2014 (resp., Dwork-2006)
does not achieve (ǫ, δ)-differential privacy.
TABLE I:
Selected papers
Imtiaz and Sarwate [12]
Liu et al. [13]
Wang et al. [14]
Ermis and Cemgil [15]
Liu et al. [16]
Imtiaz and Sarwate [17]
Jälkö et al. [7]
Heikkilä et al. [8]
Imtiaz and Sarwate [18]
Pyrgelis et al. [19]
Wang et al. [21]
Jain and Thakurta [20]

Misuse of the Classical Gaussian Mechanisms in the Literature from 2014 to 2018.
Mechanism
ǫ
δ
The resulting noise amounts The least noise amounts
Dwork-2014
10
0.01
0.3108
0.3501
Dwork-2014
6, 10
0.1
0.3746, 0.2248
0.3813, 0.2818
Dwork-2014 8.87, 9.59
10−5
0.5462, 0.5052
0.5172, 0.5513
−2
Dwork-2014
10
10 , 10−5
0.3108, 0.4845
0.3501, 0.4999
Dwork-2014
8
10−1
0.2809
0.3215
Dwork-2014
10
10−2
0.3108
0.3501
Dwork-2014
10
10−3
0.3776
0.4061
Dwork-2014 10, 31.62
10−4
0.4344, 0.1374
0.1976, 0.4553
Dwork-2006
10
10−2
0.3325
0.3501
Dwork-2006
10
10−1
0.2448
0.2818
Dwork-2006
10
10−1
0.2448
0.2818
−3
Dwork-2006
10
10
0.3898
0.4061

Remark 3. Results (ii) and (iii)
 of Theorem 2 mean that putationally efficient upper bounds for σDP-OPT in Section V.
In Appendix O of this supplementary file, we present
σDP-OPT is in the form of Θ √1ǫ for large ǫ (note 1ǫ is
Algorithm
1 to compute σDP-OPT of Theorem 2.
1
smaller than √ǫ for large ǫ). This further implies the result of
We now analyze the asympotics for the optimal Gaussian
Theorem 1 for 0 < δ ≤ 0.05 (our direct proof for Theorem 1
noise amount σDP-OPT of (ǫ, δ)-differential privacy. As a side
in Appendix B works for any 0 < δ < 1).
∆
result, we prove that σDP-OPT is always less than 2√2·inverf(δ)
√

ǫ
2
Remark 4. With r(u) := erfc (u)−e erfc u + ǫ , the term and hence bounded even for ǫ → 0. This is in contrast to the
a in Eq. (5) satisfies r(a) = 2δ. Then r(u) strictly decreases classical Gaussian mechanisms’ noise amounts σDwork-2006
as u increases given the derivative r′ (u) = √2π exp(−u2 ) × and σDwork-2014 in Eq. (1) and (2) which scale with 1 and
ǫ
√
√
2
u−
√ u +ǫ < 0. Based on this and r(0) = 1 − eǫ erfc ( ǫ), hence tend to ∞ as ǫ → 0.
2
u +ǫ
√
for a in Eq. (5), we obtain a > 0 if 2δ < 1 − eǫ erfc ( ǫ), Theorem 3 (An upper bound and asympotics of the optimal
and a ≤ 0 otherwise. More discussions about Remark 4 are Gaussian noise amount for (ǫ, δ)-differential privacy).
presented in Appendix D of this supplementary file.
① For any ǫ > 0 and 0 < δ < 1, σDP-OPT is less than
√ ∆
, which is the optimal Gaussian noise amount
Remark 5. Mechanism DP-OPT is just the optimal Gaussian
2 2·inverf(δ)
to
achieve
(0,
δ)-differential privacy.
mechanism for (ǫ, δ)-differential privacy in the sense that it
②
Given
a
fixed
0 < δ < 1, σDP-OPT converges to its upper
gives the minimal required amount of noise when the noise
∆
√
as ǫ → 0.
bound
follows a Gaussian distribution. However, it may not be the
2 2·inverf(δ)
 
optimal mechanism for (ǫ, δ)-differential privacy, since there ③ Given a fixed 0 < δ < 1, σDP-OPT is Θ √1 as ǫ → ∞;
ǫ

.
may exist other perturbation methods [32], [35], [47] which
∆
√
= 1.
specifically, limǫ→∞ σDP-OPT
may outperform a Gaussian mechanism under certain utility
2ǫ q

measure [33].
④ Given a fixed ǫ > 0, σDP-OPT is Θ
ln 1δ as δ → 0;
. q

We prove Theorem 2 in Appendix C of this supplementary
∆
1
specifically, limδ→0 σDP-OPT
2
ln
= 1.
ǫ
δ
file.
Intuition of Result ① of Theorem 3 based on Theorem 2.
Since σDP-OPT of Theorem 2 has no closed-form expression
and needs to be approximated in an iterative manner, we first With δ fixed, when ǫ tends to 0, the quantity a in Eq. (5)
provide its asympotics in Theorem 3 and present more com- of Theorem 2 is negative and is close to − inverfc(1 − δ);

6

TABLE II: Different mechanisms to achieve (ǫ, δ)-differential privacy (DP).
Comparison
Common properties
• the optimal Gaussian mechanism to achieve (ǫ, δ)-DP,
• no closed-form expression,
DP-OPT
• computed using the bisection method
Noise amounts σDP-OPT , σMechanism-1 ,
of Theorem 2
with the number of iterations being
and σMechanism-2 are all smaller than
logarithmic in the given error (i.e., tolerance).
σDwork-2014 and σDwork-2006 ,
• closed-form expression involving
for 0 < ǫ ≤ 1 which the proofs of
the complementary error function
Dwork-2014 and Dwork-2006 require
Our Mechanism 1 erfc() and its inverse inverfc(),
(The proof is in Appendix A).
of Theorem 4
• computational complexity: dependent on
erfc() & inverfc() implementations and often very efficient,
• σMechanism-1 is slightly greater than σDP-OPT .
• closed-form expression involving
Our Mechanism 2 only elementary functions,
of Theorem 5
• computed in constant amount of time,
• σMechanism-2 is slightly greater than σMechanism-1 .
DP Mechanisms

We prove Lemma 1 in Appendix G of this supplementary
i.e., inverf(δ), where√we use erfc (−a) = 2 − erfc (a). Then
the numerator (a + a2 + ǫ)∆ of Eq. (5) can be written as file. Theorem 2 and Lemma 1 imply
ǫ∆
ǫ∆
√
and approaches (−a)·2
to scale with ǫ instead of
−a+ a2 +ǫ √
σDP-OPT in Eq. (5) < σMechanism-1 in Eq. (7b) of Theorem 4,
scaling with ǫ as ǫ → 0. As the numerator and denominator
(6)
of Eq. (5) are both Θ(ǫ) as ǫ → 0, σDP-OPT with fixed δ does
where Theorem 4 below presents Mechanism 1 to achieve
not grow unboundedly as ǫ → 0.
We prove Theorem 3 in Appendix E of this supplementary (ǫ, δ)-differential privacy.
file. Theorem 3 provides the first asymptotic results in the Theorem 4 (Gaussian Mechanism 1 for (ǫ, δ)-differential
literature on the optimal Gaussian noise amount for (ǫ, δ)- privacy). (ǫ, δ)-Differential privacy can be achieved by
differential privacy. The proofs delicately bound σDP-OPT to Mechanism 1, which adds Gaussian noise with standard
avoid over-approximation.
deviation σMechanism-1 to each dimension of a query with ℓ2 For clarification, we note that Results ② and ④ of The- sensitivity ∆, for σ
Mechanism-1 given by
orem 3 do not contradict each other since Result ② fixes





0 < δ < 1 and considers ǫ → 0 so that ǫ/δ → 0, while









Result ④ fixes ǫ > 0 and considers δ → 0 so that δ/ǫ → 0. 





2δ



s
inverfc




2

More specifically, to bound σDP-OPT in Result ④, we consider


ǫ erfc (√ǫ)



+ǫ
erfc
inverfc
2δ+e

b :=
(7a)
ǫ > f (δ) for some function f , which clearly holds given a
√
1−eǫ·

2δ+eǫ erfc( ǫ)


√
fixed
ǫ
>
0
and
δ
→
0.
With
ǫ
>
f
(δ),
the
expression


q
q


if 2 − eǫ erfc ( ǫ) > 2δ,



∆
∆
1
1


in
Result
④
is
less
than
,
which
is
2
ln
2
ln


ǫ
δ
f (δ)
δ

0 otherwise;


∆

for suitable f (δ), so Result ② does not
less than 2√2·inverf(δ)
√

2 +ǫ ·∆

)
(b+ b√

.
(7b)
σ
:=
contradict Result ④.
Mechanism-1
ǫ 2
V. O UR P ROPOSED G AUSSIAN M ECHANISMS
(ǫ, δ)-D IFFERENTIAL P RIVACY

FOR

Table II summarizes different mechanisms to achieve (ǫ, δ)differential privacy (DP), including DP-OPT in Theorem 2
of the previous section as well as our Mechanism 1 and
Mechanism 2 to be presented below.
We now detail our Gaussian mechanisms for (ǫ, δ)differential privacy, where the noise amounts have
closed-form3 expressions and are more computationally
efficient than the above Theorem 2’s DP-OPT which has no
closed-form expression. Our idea is to present computationally
efficient upper bounds of σDP-OPT . To this end, we first present
Lemma 1, which upper bounds a in Eq. (5) of Theorem 2.
Lemma 1. a in Eq. (5) is less than b in Eq. (7a).
3 Closed-form

expressions in this paper can include functions erf(), erfc(),
inverf(), and inverfc().

The expression of σMechanism-1 involves the complementary
error function erfc() and its inverse inverfc(). Hence, we further present Lemma 2 below, which will enable us to propose
Mechanism 2. Its noise amount is given by the closed-form
expression of σMechanism-2 and has only elementary functions.
Lemma 2 upper bounds b in Eq. (7a) of Theorem 4.
Lemma 2. b in Eq. (7a) is less than c in Eq. (9).

We prove Lemma 2 in Appendix H of this supplementary
file. Theorem 4 and Lemma 2 imply
σMechanism-1 in Eq. (7b) < σMechanism-2 in Eq. (9),

(8)

where the presented Mechanism 2 in Theorem 5 below is
further simpler than Mechanism 1 as noted above.
Theorem 5 (Gaussian Mechanism 2 for (ǫ, δ)-differential
privacy). For 0 < δ < 0.5, (ǫ, δ)-differential privacy can be
achieved by Mechanism 2, which adds Gaussian noise with

7
6

60

= 0.1

50

1.2

=1

5

=5

1

40
4
30

0.8
3

20
10
10 -7

SDP-OPT
DP-OPT
Dwork-2014
Dwork-2006
Mechanism 1
Mechanism 2
Mechanism 3
Mechanism 4

10 -6

10 -5

10 -4

10 -3

2
10 -7

10 -6

(i)

10 -5

10 -4

10 -3

0.6
10 -7

10 -6

(ii)

10 -5

10 -4

(iii)

0.45

0.35

0.6
0.4

= 15

= 10
0.5

10 -3

0.35

= 20

0.3
0.25

0.3

0.2

0.4
10 -7

10 -6

10 -5

10 -4

10 -3

(iv)

0.25
10 -7

10 -6

10 -5

(v)

10 -4

10 -3

0.15
10 -7

10 -6

10 -5

10 -4

10 -3

(vi)

Fig. 2: The noise amounts of different mechanisms with respect to δ, for ǫ = 0.1, 1, 5, 10, 15 and 20. The meanings of the
legends are as follows.
• pDP-OPT (resp., DP-OPT) is the optimal Gaussian mechanism to achieve (ǫ, δ)-pDP (resp., (ǫ, δ)-DP), where pDP is short
for probabilistic differential privacy, a notion stronger than differential privacy (DP) and to be elaborated in Section VI.
• Dwork-2006 (resp., Dwork-2014) is the Gaussian mechanism proposed by Dwork et al. [1] in 2006 (resp., Dwork and
Roth [2] in 2014) to achieve (ǫ, δ)-DP.
• Mechanism 1 and Mechanism 2, which are our proposals to achieve (ǫ, δ)-DP and discussed in Section V, are simpler
and more computationally efficient than DP-OPT.
• Mechanism 3 and Mechanism 4, which are our proposals to achieve (ǫ, δ)-pDP and will be discussed in Section VI-D,
are simpler and more computationally efficient than pDP-OPT.

standard deviation σMechanism-2 to each dimension of a query
with ℓ2 -sensitivity ∆, for σMechanism-2 given by
√
q
(c+ c√2 +ǫ )·∆
2
; σMechanism-2 :=
. (9)
c := ln √16δ+1−1
ǫ 2

Superiority of our mechanisms. The following discussions
show the superiority of our proposed mechanisms.

i) From
Inequalities
(6)
and
(8),
we
have
σDP-OPT in Eq. (5)
<
σMechanism-1 in Eq. (7b)
<
σMechanism-2 in Eq. (9). Among these noise amounts,
σMechanism-1 and σMechanism-2 are straightforward to
compute, whereas σDP-OPT require higher computational
complexity (a simple approach is the bisection method
in [48, Page 3]. Also, our plots in Figure 2 show
that the noise amounts added by the optimal Gaussian
mechanism DP-OPT and our more computationally
efficient Mechanism 1 are close.
ii) For 0 < ǫ ≤ 1 where the proofs of Dwork-2006 of [1]
and Dwork-2014 of [2] require, we prove in Appendix A
that

differential privacy, σMechanism-1 < σDwork-2014 still holds
as given by Figure 2. Moreover, our Mechanism 1 and
Mechanism 2 apply to any ǫ. A similar discussion holds
for Dwork-2006.
Applications of our mechanisms. Our proposed mechanisms
has the following applications. First, the noise amounts of our
mechanisms can be set as initial values to quickly search
for the optimal value or its tighter upper bound (as the
optimal value has no closed-form expression). We use such
approach in Algorithm 1 of Appendix O of this supplementary
file. In addition, our upper bounds may provide an intuitive
understanding about how a sufficient Gaussian noise amount
changes
to ǫ and δ: given

 according
 δ, a noise amount of
Θ 1ǫ + Θ √1ǫ suffices; i.e., Θ 1ǫ suffices for small ǫ and

Θ √1ǫ suffices for large ǫ. Finally, our mechanisms can
be useful for Internet of Things (IoT) devices with little
power or computational capabilities, since our mechanisms
are more computationally efficient than the optimal Gaussian
mechanism.

VI. (ǫ, δ)-P ROBABILISTIC D IFFERENTIAL P RIVACY:
C ONNECTION TO (ǫ, δ)-D IFFERENTIAL P RIVACY AND
G AUSSIAN M ECHANISMS
In this section, for (ǫ, δ)-probabilistic differential privacy,
iii) From Theorem 1, there exists a function G(δ) such
that Dwork-2014 does not achieve (ǫ, δ)-differential pri- we discuss its connection to (ǫ, δ)-differential privacy and its
vacy for ǫ > G(δ). Figure 1 shows G(10−3 ) = 7.47, Gaussian mechanisms.
G(10−4 ) = 8.00, G(10−5 ) = 8.43, and G(10−6 ) =
8.79. Result ii) above considers 0 < ǫ ≤ 1. For A. (ǫ, δ)-Probabilistic differential privacy
To achieve (ǫ, δ)-differential privacy (formally given in
1 < ǫ ≤ G(δ) which the proof of Dwork-2014 does
not cover but Dwork-2014 happens to achieve (ǫ, δ)- Definition 1 on Page 4), most mechanisms ensure a condition
σMechanism-1 < σMechanism-2 < σDwork-2014 < σDwork-2006 .
(10)

8

1

1

0.8

0.8

0.6
0.4
0.2

0.6

10-3

0.4

10-4
10-5

0.2

Lemma 3. (ǫ, δ)-Probabilistic differential privacy implies
(ǫ, δ)-differential privacy.
−ǫ∗

)
Lemma 4. (ǫ, δ)-Differential privacy implies (ǫ∗ , δ·(1+e
1−eǫ−ǫ∗ )probabilistic differential privacy for any ǫ∗ > ǫ.

10-3

10-4
10-5

While the straightforward Lemma 3 is shown in [2], the
proof of Lemma 4 is not trivial. Although [9] of Dwork
0
5
10
15
20
0
5
10
15
20
and Rothblum, and [10] of Bun and Steinke mention that
differential privacy is equivalent, up to a small loss in pa(i) Mechanism Dwork-2014
(ii) Mechanism Dwork-2006
rameters, to probabilistic differential privacy, [9], [10] do not
Fig. 3: The shaded area in each subfigure represents the set of
present Lemma 4. For completeness, we present the proofs of
(ǫ, δ) where Mechanism Dwork-2014 (resp., Dwork-2006)
Lemmas 3 and 4 in Appendices I and J of this supplementary
does not achieve (ǫ, δ)-probabilistic differential privacy.
file.
Similar to Theorem 1 on Page 4, we show in Figure 3 the
on the privacy loss random variable defined below. Such
failures of the classical Gaussian mechanisms of Dwork and
condition is termed (ǫ, δ)-probabilistic differential privacy [40]
Roth [2] in 2014 and of Dwork et al. [1] in 2006 to achieve
and elaborated below. We will explain that (ǫ, δ)-probabilistic
(ǫ, δ)-probabilistic differential privacy for large ǫ.
differential privacy is sufficient but not necessary for (ǫ, δ)We now present the optimal Gaussian mechanism for (ǫ, δ)differential privacy.
probabilistic
differential privacy.
′
For neighboring datasets D and D , the privacy loss
LY,D,D′ (y) represents the multiplicative difference between
the probabilities that the same output y is observed when the
randomized algorithm Y is applied to D and D′ , respectively. C. An analytical but not closed-form expression for the optimal Gaussian mechanism of (ǫ, δ)-probabilistic differential
Specifically, we define
privacy
F [Y (D) = y]
,
(11)
LY,D,D′ (y) := ln
F [Y (D′ ) = y]
The optimal Gaussian mechanism of (ǫ, δ)-probabilistic
differential
privacy (pDP) is given in Theorem 6 below.
where F [·] denotes the probability density function.
0

10-6
5.2

5.4

5.6

10-6

6.4

6.6

6.8

0

For simplicity, we use probability density function F [·] in Theorem 6 (Optimal Gaussian mechanism for
Eq. (11) above by assuming that the randomized algorithm Y (ǫ, δ)-probabilistic differential privacy). The optimal
has continuous output. If Y has discrete output, we replace Gaussian mechanism for (ǫ, δ)-probabilistic differential
F [·] by probability notation P [·].
privacy, denoted by Mechanism pDP-OPT, adds Gaussian
When y follows the probability distribution of random vari- noise with standard deviation σpDP-OPT to each dimension of
able Y (D), LY,D,D′ (y) follows the probability distribution of a query with ℓ2 -sensitivity ∆, for σpDP-OPT given by

LY,D,D′ (Y (D)), which is the privacy loss random variable.

p

2 + ǫ = 2δ;(13a)
d
Solve
d
such
that
erfc
(d)
+
erfc

As a sufficient condition to enforce (ǫ, δ)-differential privacy,

√

(ǫ, δ)-probabilistic differential privacy of [40] is defined such
d + d2 + ǫ · ∆


that the privacy loss random variable LY,D,D′ (Y (D)) falls
√
.
(13b)
 σpDP-OPT :=
ǫ 2
in the interval [−ǫ, ǫ] with probability at least 1 − δ; i.e.,
P [−ǫ ≤ LY,D,D′ (Y (D)) ≤ ǫ] ≥ 1 − δ. This is equivalent to Remark 6. Mechanism pDP-OPT is just the optimal
the following definition.
Gaussian mechanism for (ǫ, δ)-probabilistic differential privacy
in the sense that it gives the minimal required amount
Definition 2 ((ǫ, δ)-Probabilistic differential privacy [40]).
of
noise
when the noise follows a Gaussian distribution.
A randomized algorithm Y satisfies (ǫ, δ)-probabilistic differHowever,
it may not be the optimal mechanism for (ǫ, δ)ential privacy, if for any two neighboring datasets D and
probabilistic
differential privacy, since there may exist other
′
D (elaborated in Remark 1 on Page 4), we have that for
perturbation
methods
(e.g., adding non-Gaussian noise) which
y following the probabilistic distribution of the output Y (D)
may
outperform
a
Gaussian
mechanism under certain utility
(notated as y ∼ Y (D)),
measure
[47].


F [Y (D) = y]
ǫ
≥ 1 − δ,
(12)
≤
e
Py∼Y (D) e−ǫ ≤
We prove Theorem 6 in Appendix K of this supplementary
F [Y (D′ ) = y]
file. We present the asympotics of σpDP-OPT as Theorem 7
where F [·] denotes the probability density function.
below.
B. Relationships between differential privacy and probabilistic
differential privacy
Lemmas 3 and 4 below present the relationships between
differential privacy and probabilistic differential privacy.

Theorem 7 (The asympotics of the optimal Gaussian noise
amount for (ǫ, δ)-probabilistic differential privacy).

① Given a fixed 0 < δ < 1, σpDP-OPT is Θ 1ǫ
as ǫ → 0. Specifically,
given a fixed 0 < δ < 1,
.
inverfc(δ)·∆
√
limǫ→0 σpDP-OPT
= 1.
ǫ 2

9

TABLE III: Different mechanisms to achieve (ǫ, δ)-probabilistic differential privacy (pDP).
pDP Mechanisms

Comparison
• the optimal Gaussian mechanism to achieve (ǫ, δ)-pDP,
• no closed-form expression,
Our pDP-OPT
• computed using the bisection method with the number of iterations
of Theorem 6
being logarithmic in the given error (i.e., tolerance).
• closed-form expression involving
the complementary error function’s inverse inverfc(),
Our Mechanism 3
• computational complexity: dependent on
of Theorem 8
inverfc() implementations and often very efficient,
• σMechanism-3 is slightly greater than σpDP-OPT .
• closed-form expression involving only elementary functions,
Our Mechanism 4
• computed in constant amount of time,
of Theorem 9
• σMechanism-4 is slightly greater than σMechanism-3 .
 
Result ① of Theorem 7.
② Given a fixed 0 < δ < 1, σpDP-OPT is Θ √1ǫ
as ǫ → ∞. Specifically,
given
a
fixed
0
<
δ
<
1,
.

From Theorem 6, the optimal Gaussian mechanism
√∆
limǫ→∞ σpDP-OPT
= 1.
pDP-OPT
does not have a closed-form expression. In the next
2ǫ
q

subsection, we detail our Gaussian mechanisms for (ǫ, δ)-pDP,
ln δ1
③ Given a fixed ǫ > 0, σpDP-OPT is Θ
as δ → 0. .Specifically,
given a fixed ǫ > 0, where the noise amounts have closed-form expressions and are

 q
more computationally efficient than pDP-OPT.
1
∆
2 ln δ = 1.
limδ→0 σpDP-OPT
ǫ

Theorem 7 is proved in Appendix L of this supplementary
file.

D. Our Gaussian mechanisms for (ǫ, δ)-probabilistic differential privacy with closed-form expressions of noise amounts

Remark 7. From Result ① of Theorem 7, given a fixed
The idea of our Gaussian mechanisms is to present compu0 < δ < 1, σpDP-OPT = Θ 1ǫ → ∞ as ǫ → 0. In contrast,
tationally efficient upper bounds of σpDP-OPT . To this end, we
from Result ① of Theorem 3, given a fixed 0 < δ < 1,
∆
σDP-OPT → 2√2·inverf(δ)
as ǫ → 0. This shows a fundamen- first present Lemma 5, which upper bounds d in Eq. (13a) of
Theorem 6.
tal difference between (ǫ, δ)-differential privacy and (ǫ, δ)Lemma 5. d in Eq. (13a) is greater than inverfc(2δ) and less
probabilistic differential privacy.
than inverfc(δ).
Remark 8. In Lemmas 3 and 4 above, we show the relationship between differential privacy and probabilistic differential
We prove Lemma 5 in Appendix M of this supplementary
privacy that the latter implies the former and the former file. Theorem 6 and Lemma 5 imply an upper bound of
implies the latter up to possible loss in privacy parameters. σpDP-OPT as σMechanism-3 in Theorem 8 below, where we
Given this, one may wonder if this relationship contradicts present Mechanism 3 to achieve (ǫ, δ)-probabilistic differtheir difference discussed in Remark 7 above as ǫ → 0. Below ential privacy.
we explain there is no contradiction, by showing that the
8
(Gaussian
Mechanism 3
for
Gaussian noise amount for probabilistic differential privacy Theorem
(ǫ,
δ)-Probabilistic
differential
privacy).
(ǫ,
δ)-Probabilistic
obtained by first achieving differential privacy is at the same
order as the optimal Gaussian noise amount for probabilistic differential privacy can be achieved by Mechanism 3, which
adds Gaussian noise with standard deviation σMechanism-3
differential privacy when ǫ → 0.
−ǫ
to each dimension of a query with ℓ2 -sensitivity ∆, for
)
From Lemma 4, (0, δ·(1−e
1+e−ǫ )-differential privacy im- σMechanism-3 given by
plies (ǫ, δ)-probabilistic differential privacy. From Result ①

−ǫ
)
f := inverfc(δ);
(14a)

of Theorem 3, (0, δ·(1−e



1+e−ǫ )-differential privacy can be
p
achieved by the Gaussian mechanism with noise amount
f + f2 + ǫ · ∆

∆


√
.
(14b)
σ
:=
.
Hence,
(ǫ,
δ)-probabilistic
differential
√
Mechanism-3
−ǫ
2 2·inverf δ·(1−e−ǫ )
ǫ 2
1+e
privacy can also be achieved by the Gaussian mechanism with

The expression of σMechanism-3 involves the complementary
∆
 , which given δ is Θ 1ǫ as
noise amount √
−ǫ
error
function’s inverse inverfc(). Hence, we further present
2 2·inverf δ·(1−e−ǫ )
1+e
(1−e−ǫ ) 
inverf(x)
Lemma
6 below, which will enable us to propose Mechanism
1
ǫ√→ 0 due to limǫ→0 1+e−ǫ ǫ = 2 and limx→0
=
x
4.
Its
noise
amount is given by the closed-form expression of
π
2 from [49]. From Result ① of Theorem 7, the optimal Gaus- σMechanism-4 and has only elementary functions.
sian noise amount for (ǫ, δ)-probabilistic differential privacy
Lemma 6 upper bounds f in Eq. (14a).
given δ is also Θ 1ǫ as ǫ → 0. Hence, the combination of
Lemma 4 and Result ① of Theorem 3 does not contradict Lemma 6. f in Eq. (14a) is less than g in Eq. (15a).

10

We prove Lemma 6 in Appendix N of this supplementary
file.
Theorem 8 and Lemma 6 imply an upper bound of
σMechanism-3 as σMechanism-4 in Theorem 9 below, where
the presented Mechanism 4 is further simpler than
Mechanism 3 as noted above.
Theorem
9
(Gaussian
Mechanism 4
for
(ǫ, δ)-Probabilistic differential privacy). (ǫ, δ)-Probabilistic
differential privacy can be achieved by Mechanism 4, which
adds Gaussian noise with standard deviation σMechanism-4
to each dimension of a query with ℓ2 -sensitivity ∆, for
σMechanism-4 given by
s


2

 g := ln √
;
(15a)


8δ + 1 − 1


p


g + g2 + ǫ · ∆


 σMechanism-4 :=
√
.
(15b)
ǫ 2

with standard deviation σ achieves ρ-zCDP by [10], where
∆2
that √
the Gausρ = 2σ
2 . Combining these results, we can derive
√

∆·

ln

1
δ+

ln

1
δ +ǫ

√
sian mechanism with standard deviation
2ǫ
achieves (ǫ, δ)-DP. This expression is obtained
q by solving
2
∆
σ which satisfy ρ = 2σ
ρ ln( 1δ ). Such
2 and ǫ = ρ + 2
noise amount is even worse (i.e., higher) than our weakest
√ Mechanism 4 in Theorem 9 on Page 10 in view of
8δ + 1 − 1 > 2δ given 0 < δ < 1. Hence, achieving (ǫ, δ)DP by first ensuring zCDP cannot give Gaussian mechanisms
better than ours.
Relationship between RDP and DP. Mironov [23] shows
that (α, ρα)-RDP implies (ǫ, δ)-DP for ǫ = ρα + ln(1/δ)
α−1 , and
the Gaussian mechanism with standard deviation σ achieves
∆2
(α, ρα)-RDP for ρ = 2σ
2 . Combining these results, we can
also prove
that
the
Gaussian
mechanism with standard devia√

√
∆·

ln

1
δ+

ln

1
δ +ǫ

√
tion
achieves (ǫ, δ)-DP. This expression
2ǫ
is obtained by finding the smallest σ such that there exists
ln(1/δ)
∆2
Table III summarizes different mechanisms to achieve (ǫ, δ)- α > 1 such that ρ = 2σ2 and ǫ = ρα + α−1 (we just
express σ and take its minimum with respect to α). As noted
probabilistic differential privacy discussed above.
above, this noise amount is even worse (i.e., higher) than our
weakest Mechanism 4 in Theorem 9. Thus, achieving (ǫ, δ)VII. C ONCENTRATED D IFFERENTIAL P RIVACY AND
DP by first ensuring RDP cannot give Gaussian mechanisms
R ELATED N OTIONS
better than ours. We emphasize that the comparison may be
Several variants of differential privacy (DP), including different if the RDP paper [23]’s Proposition 3 that (α, ρα)ln(1/δ)
mean-concentrated differential privacy (mCDP) [9], zero- RDP implies (ρα + α−1 , δ)-DP can be improved. Yet, we
concentrated differential privacy (zCDP) [10], Rényi differen- have not been able to find such improvement after checking
tial privacy [23] (RDP), and truncated concentrated differential prior papers related to RDP.
Relationship between tCDP and DP. Bun et al. [24]
privacy (tCDP) [24] have been recently proposed as alternashow that
tives to (ǫ, δ)-DP. Below we show that achieving (ǫ, δ)-DP by 
q (ρ, ω)-tCDP implies (ǫ, δ)-DP for ǫ =
first ensuring one of these privacy definitions (mCDP, zCDP, ρ + 2 ρ ln 1 if ln 1 ≤ (ω − 1)2 ρ,
δ
δ
and the Gaussian
RDP, and tCDP) cannot give Gaussian mechanisms better than 
ln( δ1 )
1
2
ρω
+
if
ln
≥
(ω
−
1)
ρ,
ω−1
δ
ours, based on existing results on the relationships between
mechanism with standard deviation σ achieves (ρ, ω)-tCDP
mCDP, zCDP, RDP, tCDP and DP.
2
∆
for ρ = 2σ
2 . We can see that these results are already
Lemma 7 (Relationship between (ǫ, δ)-DP and covered by the above discussions for the relationship between
(µ, τ )-mCDP). For ǫ > µ, (µ, τ )-mCDP implies (ǫ, δ)- zCDP and DP, and for the relationship between RDP and DP.
probabilistic
privacy
(pDP)
Therefore, achieving (ǫ, δ)-DP by first ensuring tCDP cannot


 for
 differential
(ǫ+µ)2
(ǫ−µ)2
+ exp − 2τ 2 , which further implies give Gaussian mechanisms better than ours.
δ = exp − 2τ 2
(ǫ, δ)-DP.
VIII. E XPERIMENTS
Despite not being presented in [9] which proposes mCDP,
This section presents experiments to evaluate different
the first part of Lemma 7 clearly follows from the definitions
Gaussian
mechanisms for mean estimation and histogram
of mCDP and pDP by using the tail bounds on the privacy loss
estimation
under differential privacy.
random variable of mCDP, while the second part of Lemma 7
is from Lemma 3.
For a query with ℓ2 -sensitivity 1, Theorem 3.2 in [9] A. Mean Estimation
shows that the Gaussian mechanism with standard deviation σ
We evaluate the utility of all mechanisms for the task of
achieves ( 2σ1 2 , σ1 )-mCDP,which based
on
Lemma
7
implies
private
mean estimation using synthetic data. The input dataset



d
(ǫ+ 2σ1 2 )2
(ǫ− 2σ12 )2
x
=
(x
given d,
1 , . . . , xn ) contains n vectors xi ∈ R for a P
+ exp − 2( 1 )2
.
(ǫ, δ)-pDP for δ = exp − 2( 1 )2
σ
σ
and the query for mean computation is Q(x) = (1/n) ni=1 xi .
Expressing σ in terms of ǫ and δ gives σ as σpDP-OPT of We set n = 1000 and sample each dataset x in two steps [39].
Theorem 6. Hence, using the relationship between mCDP and The first step is to sample an initial data center x0 ∈ Rd ,
(p)DP does not give a new mechanism which we have not with each dimension of x0 independently following a standard
presented.
Gaussian distribution with zero mean and variance being
Relationship between zCDP and DP. From Proposition 1. The second step is to construct x = (x1 , . . . , xn ) with
1.3 and Proposition
1.6 in [10], ρ-zCDP implies (ǫ, δ)-DP xi = x0 + ξi , where each ξi ∈ Rd is independently and
q
for ǫ = ρ + 2 ρ ln( δ1 ). Moreover, the Gaussian mechanism identically distributed (i.i.d.) with independent coordinates

11

SDP-OPT

DP-OPT

Dwork-2014

Dwork-2006

Mechanism 1

Mechanism 2

Mechanism 3

Mechanism 4

3000
4

6

4

3

5

3

2

4

2

1

3

1

2
10-8 10-7 10-6 10-5 10-4

0

0
0.1

0.3

0.5

0.7

0.9 1

(a) Error w.r.t. ǫ

4000

10 20 30 40 60






80 100

(b) Error w.r.t. δ
(c) Error w.r.t. dimension d
Fig. 4: Mean estimation.

2000

3000

1000

2000

0
0.1

0.3

0.5

0.7

0.9 1

1000
10-9

10-8

10-7

10-6

(a) Error w.r.t. ǫ
(b) Error w.r.t. δ
Fig. 5: Histogram estimation.

sampled uniformly from the interval [−1/2, 1/2]. We consider while fixing ǫ = 0.1. Both subfigures show that the utilities of
bounded differential privacy, where two neighboring datasets our proposed Gaussian mechanisms are higher than those of
have the same size n, and have different records at only one the classical ones [1], [2] and close to that of the optimal yet
of the n positions. Since the points xi in each dataset all lie in more computationally expensive DP-OPT mechanism.
an √
ℓ∞ -ball of radius 1, the ℓ2 -sensitivity of mean estimation
IX. C ONCLUSION
is d/n, where d is a record’s dimension.
For the above query Q on the dataset x, we consider
Differential privacy (DP) has received considerable interest
different Gaussian mechanisms to achieve (ǫ, δ)-differential recently since it provides a rigorous framework to quane be such a Gaussian mechanism. We report the tify data privacy. Well-known solutions to (ǫ, δ)-DP are the
privacy. Let Q
e
ℓ2 error Q(x)
− Q(x) . The results for different Gaussian Gaussian mechanisms by Dwork et al. [1] in 2006 and by
2
mechanisms are presented in Figure 4. The plots consider Dwork and Roth [2] in 2014, where a certain amount of
ǫ ≤ 1 since this is required by the proofs of Dwork-2006 Gaussian noise is added independently to each dimension
of [1] and Dwork-2014 of [2]. Figure 4-(a) fixes δ = 10−4 of the query result. Although the two classical Gaussian
and varies ǫ; Figure 4-(b) fixes ǫ = 0.1 and varies δ; and mechanisms [1], [2] explicitly state their usage for ǫ ≤ 1
Figure 4-(c) with ǫ = 0.1 and δ = 10−4 evaluates the only, many studies applying them neglect the constraint on
impact of a data record’s dimension d. All subfigures of ǫ, rendering the obtained results inaccurate. In this paper, for
Figure 4 show that our proposed Gaussian mechanisms achieve (ǫ, δ)-DP, we present Gaussian mechanisms which work for
better utilities than the classical Gaussian mechanisms [1], every ǫ. Another improvement is that our mechanisms achieve
[2] Dwork-2014 and Dwork-2006; In fact, Dwork-2014 higher utilities than those of the classical ones [1], [2]. Since
and Dwork-2006 have the largest ℓ2 -errors. Moreover, the most mechanisms proposed in the literature for (ǫ, δ)-DP are
utilities of our proposed mechanisms are close to that of obtained by ensuring a condition called (ǫ, δ)-probabilistic
the optimal yet more computationally expensive Gaussian differential privacy (pDP), we also present the difference/relationship between (ǫ, δ)-DP and (ǫ, δ)-pDP, and Gaussian
mechanism DP-OPT.
mechanisms for (ǫ, δ)-pDP. Our research on reviewing and
improving
the Gaussian mechanisms will benefit differential
B. Histogram Estimation
privacy applications built based on the primitive.
We now run experiments on the Adult dataset from the UCI
machine learning repository4, to evaluate different Gaussian
R EFERENCES
mechanisms for histogram estimation with differential privacy.
[1] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, “Our
The Adult dataset contains census information with 45222
data, ourselves: Privacy via distributed noise generation,” in Eurocrypt,
records and 15 attributes. The attributes include both categor2006, pp. 486–503.
[2] C. Dwork and A. Roth, “The algorithmic foundations of differential
ical ones such as race, gender, and education level, as well as
privacy,” Foundations and Trends in Theoretical Computer Science (FnTnumerical ones such as capital gain, capital loss, and weight.
TCS), vol. 9, no. 3–4, pp. 211–407, 2014.
We consider the combination of all categorical attributes and
[3] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise
to sensitivity in private data analysis,” in Theory of Cryptography
let the histogram query be a vector of the counts. Here we
Conference (TCC), 2006, pp. 265–284.
tackle unbounded differential privacy, where a neighboring
[4] P. Kairouz, S. Oh, and P. Viswanath, “The composition theorem for
dataset is obtained by deleting or adding one record, so the
differential privacy,” IEEE Transactions on Information Theory, vol. 63,
no. 6, pp. 4037–4049, June 2017.
sensitivity of the histogram query is 1. For different Gaussian
[5] S. Song, K. Chaudhuri, and A. D. Sarwate, “Stochastic gradient descent
mechanisms satisfying (ǫ, δ)-differential privacy, we compare
with differentially private updates,” in IEEE Global Conference on
their Mean Squared Error (MSE) and plot the results in
Signal and Information Processing (GlobalSIP), 2013, pp. 245–248.
[6] Y. Wang and A. Anandkumar, “Online and differentially-private tensor
Figure 5.
decomposition,” in Conference on Neural Information Processing SysIn Figure 5-(a), we vary ǫ from 0.1 to 1.0 while fixing
tems (NIPS), 2016, pp. 3531–3539.
−6
−9
−5
δ = 10 . In Figure 5-(b), we vary δ from 10
to 10
[7] J. Jälkö, O. Dikmen, and A. Honkela, “Differentially private variational
4 http://archive.ics.uci.edu/ml

inference for non-conjugate models,” in Conference on Uncertainty in
Artificial Intelligence (UAI), 2017.

10-5

12

[8] M. Heikkilä, E. Lagerspetz, S. Kaski, K. Shimizu, S. Tarkoma, and
A. Honkela, “Differentially private Bayesian learning on distributed
data,” in NIPS, 2017, pp. 3229–3238.
[9] C. Dwork and G. Rothblum, “Concentrated differential privacy,” arXiv
preprint arXiv:1603.01887v1, 2016.
[10] M. Bun and T. Steinke, “Concentrated differential privacy: Simplifications, extensions, and lower bounds,” in Theory of Cryptography
Conference (TCC), 2016, pp. 635–658.
[11] S. Meiser and E. Mohammadi, “Tight on budget? Tight bounds for rfold approximate differential privacy,” in ACM SIGSAC Conference on
Computer and Communications Security (CCS), 2018, pp. 247–264.
[12] H. Imtiaz and A. D. Sarwate, “Distributed differentially-private
algorithms for matrix and tensor factorization,” arXiv preprint
arXiv:1804.10299, 2018.
[13] H. Liu, Z. Wu, Y. Zhou, C. Peng, F. Tian, and L. Lu, “Privacy-preserving
monotonicity of differential privacy mechanisms,” Applied Sciences,
vol. 8, no. 11, p. 2081, 2018.
[14] J. Wang, W. Bao, L. Sun, X. Zhu, B. Cao, and P. S. Yu, “Private model compression via knowledge distillation,” arXiv preprint
arXiv:1811.05072, 2018.
[15] B. Ermis and A. T. Cemgil, “Differentially private variational dropout,”
arXiv preprint arXiv:1712.02629, 2017.
[16] H. Liu, Z. Wu, C. Peng, F. Tian, and L. Lu, “Adaptive Gaussian
mechanism based on expected data utility under conditional filtering
noise.” KSII Transactions on Internet & Information Systems, vol. 12,
no. 7, pp. 3497–3515, 2018.
[17] H. Imtiaz and A. D. Sarwate, “Differentially-private canonical correlation analysis,” in IEEE GlobalSIP, 2017, pp. 283–287.
[18] ——, “Differentially private distributed principal component analysis,”
in IEEE ICASSP, 2018, pp. 2206–2210.
[19] A. Pyrgelis, C. Troncoso, and E. De Cristofaro, “Knock knock, who’s
there? Membership inference on aggregate location data,” arXiv preprint
arXiv:1708.06145, 2017.
[20] P. Jain and A. G. Thakurta, “(Near) dimension independent risk bounds
for differentially private learning,” in International Conference on Machine Learning, 2014, pp. 476–484.
[21] Y. Wang, S. Fienberg, and A. Smola, “Privacy for free: Posterior
sampling and stochastic gradient Monte Carlo,” in ICML, 2015, pp.
2493–2502.
[22] B. Balle and Y.-X. Wang, “Improving the Gaussian mechanism for
differential privacy: Analytical calibration and optimal denoising,” in
ICML, 2018, pp. 403–412.
[23] I. Mironov, “Rényi differential privacy,” in IEEE Computer Security
Foundations Symposium (CSF), 2017, pp. 263–275.
[24] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke, “Composable and
versatile privacy via truncated CDP,” in ACM Symposium on Theory of
Computing (STOC), 2018, pp. 74–86.
[25] R. Shokri and V. Shmatikov, “Privacy-preserving deep learning,” in ACM
CCS, 2015, pp. 1310–1321.
[26] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang, “Deep learning with differential privacy,” in ACM
CCS, 2016, pp. 308–318.
[27] C. Dwork, K. Talwar, A. Thakurta, and L. Zhang, “Analyze Gauss:
Optimal bounds for privacy-preserving principal component analysis,”
in ACM STOC, 2014, pp. 11–20.
[28] A. Nikolov, K. Talwar, and L. Zhang, “The geometry of differential
privacy: The sparse and approximate cases,” in ACM STOC, 2013, pp.
351–360.
[29] J. Hsu, Z. Huang, A. Roth, and Z. S. Wu, “Jointly private convex
programming,” in ACM-SIAM SODA, 2016, pp. 580–599.
[30] T. Elahi, G. Danezis, and I. Goldberg, “PrivEx: Private collection of
traffic statistics for anonymous communication networks,” in ACM CCS,
2014, pp. 1068–1079.
[31] F. McSherry and K. Talwar, “Mechanism design via differential privacy,”
in IEEE FOCS, 2007, pp. 94–103.
[32] Q. Geng, W. Ding, R. Guo, and S. Kumar, “Truncated Laplacian mechanism for approximate differential privacy,” arXiv preprint
arXiv:1810.00877, 2018.
[33] Q. Geng, “The optimal mechanism in differential privacy,” Ph.D. dissertation, University of Illinois at Urbana-Champaign, 2014.
[34] Q. Geng, P. Kairouz, S. Oh, and P. Viswanath, “The staircase mechanism
in differential privacy,” IEEE Journal of Selected Topics in Signal
Processing, vol. 9, no. 7, pp. 1176–1184, 2015.
[35] V. Pihur, “The Podium mechanism: Improving on the Laplace and
Staircase mechanisms,” arXiv preprint arXiv:1905.00191, 2019.

[36] A. Gilbert and A. McMillan, “Local differential privacy for physical
sensor data and sparse recovery,” arXiv preprint arXiv:1706.05916v1,
2017.
[37] M. Bun, J. Ullman, and S. Vadhan, “Fingerprinting codes and the price
of approximate differential privacy,” in ACM Symposium on Theory of
Computing (STOC), 2014, pp. 1–10.
[38] D. Boneh and J. Shaw, “Collusion-secure fingerprinting for digital data,”
IEEE Transactions on Information Theory, vol. 44, no. 5, pp. 1897–1905,
1998.
[39] F. Liu, “Generalized Gaussian mechanism for differential privacy,” IEEE
Transactions on Knowledge and Data Engineering, vol. 31, no. 4, pp.
747–756, 2018.
[40] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke, and L. Vilhuber,
“Privacy: Theory meets practice on the map,” in IEEE International
Conference on Data Engineering (ICDE), 2008, pp. 277–286.
[41] National
Institute
of
Standards
and
Technology
(NIST),
“Differential
privacy
synthetic
data
challenge,”
https://www.challenge.gov/challenge/differential-privacy-synthetic-data-challenge/,
accessed: 2019-11-25.
[42] J. Duchi, M. J. Wainwright, and M. I. Jordan, “Local privacy and
minimax bounds: Sharp rates for probability estimation,” in Conference
on Neural Information Processing Systems (NIPS), 2013, pp. 1529–
1537.
[43] J. Tang, A. Korolova, X. Bai, X. Wang, and X. Wang, “Privacy loss in
Apple’s implementation of differential privacy on macOS 10.12,” arXiv
preprint arXiv:1709.02753, 2017.
[44] Apple,
“Differential
privacy
overview,”
https://www.apple.com/privacy/docs/Differential Privacy Overview.pdf,
accessed: 2019-11-25.
[45] Ú. Erlingsson, V. Pihur, and A. Korolova, “RAPPOR: Randomized
aggregatable privacy-preserving ordinal response,” in Proc. ACM Conference on Computer and Communications Security (CCS), 2014, pp.
1054–1067.
[46] D. M. Sommer, S. Meiser, and E. Mohammadi, “Privacy loss classes:
The central limit theorem in differential privacy,” PoPETS, vol. 2019,
no. 2, pp. 245–269, 2019.
[47] Q. Geng and P. Viswanath, “Optimal noise adding mechanisms for
approximate differential privacy,” IEEE Transactions on Information
Theory, vol. 62, no. 2, pp. 952–969, 2016.
[48] G.
S.
Rao,
Mathematical
Methods.
I.K.
International
Publishing
House
Pvt.
Limited,
2010,
https://books.google.com/books?id=SJKVs7cumsUC&pg=PA3.
[49] L. Carlitz, “The inverse of the error function,” Pacific Journal of
Mathematics, vol. 13, no. 2, pp. 459–470, 1963.
[50] J. Zhao, T. Wang, T. Bai, K.-Y. Lam, X. Ren, X. Yang, S. Shi, Y. Liu,
and H. Yu, “Reviewing and improving the Gaussian mechanism for
differential privacy,” 2019, this is the submitted supplementary file.
[Online]. Available: https://www.ntu.edu.sg/home/junzhao/DP.pdf
[51] G. K. Karagiannidis and A. S. Lioumpas, “An improved approximation
for the Gaussian Q-function,” IEEE Communications Letters, vol. 11,
no. 8, 2007.
[52] M. Abramowitz and I. Stegun, “Handbook of mathematical functions
with formulas, graphs, and mathematical tables,” National Bureau of
Standards, Washington, DC, 1964.
[53] J. Craig, “A new, simple and exact result for calculating the probability
of error for two-dimensional signal constellations,” in IEEE MILCOM,
1991, pp. 571–575.

A PPENDIX
The appendices are organized as follows. Appendices A
and B are also provided in the submission, while other
appendices are given in this submitted supplementary file (the
same as [50]).
• Appendix A presents the proof of
σMechanism-1 < σMechanism-2 < σDwork-2014 < σDwork-2006 .
• Appendix B presents the proof of Theorem 1.
• Appendix C presents the proof of Theorem 2.
• Appendix D presents more discussions about Remark 4 of
Page 5.
• Appendix E presents the proof of Theorem 3.
• Appendix F presents the proof of Lemma 10.

13

• Appendix G proves Lemma 1, which along with Theorem 2
implies Theorem 4.
• Appendix H proves Lemma 2, which along with Theorem 4
implies Theorem 5.
• Appendix I presents the proof of Lemma 3.
• Appendix J presents the proof of Lemma 4.
• Appendix K presents the proof of Theorem 6.
• Appendix L presents the proof of Theorem 7.
• Appendix M proves Lemma 5, which along with Theorem 6
implies Theorem 8.
• Appendix N proves Lemma 6, which along with Theorem 8
implies Theorem 9.
• Appendix O presents Algorithm 1 to compute σDP-OPT of
Theorem 2.
• Appendix P provides analyses for the composition of
Gaussian mechanisms to achieve (ǫ, δ)-DP or (ǫ, δ)-pDP.
• Appendix Q shows Lemma 8, which is used in the proofs
of Lemmas 2 and 6.

A. Proving σMechanism-1 < σMechanism-2 < σDwork-2014 <
σDwork-2006
To prove σMechanism-1 < σMechanism-2 < σDwork-2014 <
σDwork-2006 , from Inequalities (3) and (8), we just need
to establish σMechanism-2 < σDwork-2014 . Recalling Eq. (2)
and (9), we will prove
r
1.25
2 ln
δ
s
s

√
2
2
>
ln √
+ ǫ + ln √
2,
16δ + 1 − 1
16δ + 1 − 1
for ǫ ≤ 1 and 0 < δ < 0.5.

(16)

square on both sides:
1.25
2
− 0.5, for 0 < δ < 0.5.
< ln
ln √
δ
16δ + 1 − 1

(19)

Due to 1.25 × exp(−0.5) ≈ 0.7582 > 0.75, Inequality (19) is
implied by
2
0.75
√
for 0 < δ < 0.5.
<
δ
16δ + 1 − 1

(20)

2
− 0.75
We define f (δ) := √16δ+1−1
δ . Taking the derivative of
f (δ) with respect to δ, we obtain

3
16
√
+
f ′ (δ) = − √
( 16δ + 1 − 1)2 16δ + 1 4δ 2
√
5 16δ + 1 − (8δ + 1)
√
=
8δ 2 16δ + 1
25(16δ + 1) − (8δ + 1)2
√
√
=
8[5 16δ + 1 + (8δ + 1)]δ 2 16δ + 1
64δ(1 − δ) + 320δ + 24
√
√
=
8[5 16δ + 1 + (8δ + 1)]δ 2 16δ + 1
> 0, for 0 < δ < 0.5.

(21)

Hence, f (δ) is strictly increasing for 0 < δ < 0.5, resulting
2
= −0.5 < 0, so
in f (δ) < f (0.5) = √16δ+1−1
− 0.75
δ
that Inequality (20) is proved. Then following the explanation
above, we complete establishing σMechanism-2 < σDwork-2014 .


B. Proof of Theorem 1
From Theorem 2, σDP-OPT is the minimal required amount
of Gaussian noise to achieve (ǫ, δ)-differential privacy. Hence,
to show that the Gaussian noise amount F (δ) × ∆/ǫ is not
sufficient for (ǫ, δ)-differential privacy, we will prove that for
any 0 < δ < 1, there exists a positive function G(δ) such that
for any ǫ > G(δ), we have

Since the term after “>” in Inequality (16) is increasing
with respect to ǫ, we can just let ǫ be 1 in Inequality (16).
Hence, we will obtain Inequality (16) once proving
F (δ) × ∆/ǫ < σDP-OPT .
(22)
r
√
1.25
We can show that the function x+ x2 + ǫ strictly increases
2 ln
δ
as x increases for x ∈ (−∞, ∞) by noting its
s
√ derivative
s

√
1 + √xx2 +ǫ is positive. Also, limx→−∞ (x + x2 + ǫ) =
2
2
√
>
ln √
+ 1 + ln √
2,
limx→−∞ −x+√ǫ x2 +ǫ = 0 and limx→∞ (x + x2 + ǫ) = ∞.
16δ + 1 − 1
16δ + 1 − 1
√
2
for 0 < δ < 0.5.
(17) Hence, the values that x+ x + ǫ for x ∈ (−∞, ∞) can take
constitutes the open interval (0, ∞). Then due to F (δ) > 0,
q
q
2
we
can define h such that
√
and
b
denoting
ln
,
then
With a denoting ln 1.25
δ
√
√ 16δ+1−1
√
√
√
h + h2 + ǫ
Inequality (17) means 2 a > ( b2 + 1 + b )/ 2, which is
√
.
(23)
F
(δ)
=
0.25
equivalent
to√b < √
a − 0.25
2
a√ since setting b as a − a will let
√
√
( b2 + 1 + b )/ 2 be 2 a exactly (note that a − 0.25
a > 0
(a+ a√2 +ǫ )·∆
of (5), clearly
clearly holds for 0 < δ < 0.5). Hence, the desired result From Eq. (23) and σDP-OPT =
√ǫ 2
√
h+ √h2 +ǫ
a+ √a2 +ǫ
Inequality (17) is equivalent to
Inequality (22) is equivalent to
<
and
2
2
s
r
further equivalent to h < a.
2
1.25
0.25
As
shown
Appendix
D,
ln √
< ln
−q
,
√ in

δ
ǫ
16δ + 1 − 1
2+ǫ
ln 1.25
u
strictly
decreases
as
r(u)
:=
erfc
(u)
−
e
erfc
δ
u increases for u ∈ (−∞, ∞). Then h < a is equivalent to
for 0 < δ < 0.5,
(18)
r(h) > r(a). We will prove limǫ→∞ r(h) = 2, which along
which clearly is implied by the following after taking the with r(a) = 2δ in Eq. (5) implies that for any 0 < δ < 1,

14

there exists a positive function G(δ) such that for any
ǫ > G(δ), we have r(h) > r(a) and thus h < a.
From the above discussion, the desired result Eq. (22)
follows once we show limǫ→∞ r(h) = 2. From Eq. (23), it
ǫ √
− F (δ)·2
. Hence, for any ǫ ≥ 4×[F (δ)]2 ,
holds that h = F√(δ)
2
2
ǫ
we have h ≤ − 4√2·F (δ) , which implies
p

eǫ erfc
h2 + ǫ
≤ eǫ erfc (|h|)


ǫ
ǫ
√
≤ e erfc
4 2 · F (δ)

2 !
ǫ
√
≤ eǫ × exp −
4 2 · F (δ)
→ 0, as ǫ → ∞,

2



(24)

where the last “≤” uses erfc (x) ≤ exp −x for
√ x > 0.The
above result Eq. (24) implies limǫ→∞ [eǫ erfc h2 + ǫ ] =
0. Combining this and limǫ→∞ erfc (h) = 2, we derive
limǫ→∞ r(h) = 2. Then as already explained, the desired
result is proved.


C. Proof of Theorem 2
Proving Theorem 2’s Property (i):
The optimal Gaussian mechanism for (ǫ, δ)-differential privacy, denoted by Mechanism DP-OPT, adds Gaussian noise
with standard deviation σDP-OPT to each dimension of a query
with ℓ2 -sensitivity ∆, for σDP-OPT obtained by Theorem 8 of
Balle and Wang [22] to satisfy


ǫσDP-OPT
∆
−
Φ
2σDP-OPT
∆


ǫσDP-OPT
∆
ǫ
= δ,
(25)
−
−e Φ −
2σDP-OPT
∆
where Φ (·) denotes the cumulative distribution function of
the standard univariate Gaussian probability distribution with
mean 0 and variance 1.
We define

1 ǫσDP-OPT
∆
a := √
−
.
(26)
∆
2σDP-OPT
2
√

(a+ a√2 +ǫ )·∆
, as given by Eq. (5).
Then σDP-OPT equals
ǫ 2
√
∆
Also, √12 − 2σDP-OPT
− ǫσDP-OPT
in
Eq.
(25) equals − a2 + ǫ,
∆
2

2

∆
∆
1 ǫσDP-OPT
since 21 − 2σDP-OPT
= ǫ.
−
− ǫσDP-OPT
−
∆
2
∆
2σDP-OPT
Thus, Eq. (25) becomes
 √ 
 p

Φ −a 2 − eǫ Φ − 2(a2 + ǫ) = δ.
(27)
Given

 √  1 1
Φ −a 2 = + erf (−a)
2 2
1 1
= − erf (a)
2 2
1
= erfc (a)
2

(28)

and

 p

Φ − 2(a2 + ǫ)
 p

1 1
= + erf − a2 + ǫ
2 2
p

1 1
= − erf
a2 + ǫ
2 2
p

1
a2 + ǫ .
= erfc
(29)
2
Then
we
write
(25)
as
√
 Eq.
1
ǫ 1
2 + ǫ = δ, so a is given by
a
erfc
(a)
−
e
·
erfc
2
2
Eq. (5).
Proving Theorem 2’s Property (ii):
For ǫ ≥ 0.01 and 0 < δ ≤ 0.05, we know
√ from Appendix D
to be presented soon that 1 − eǫ√erfc ( ǫ) > 2δ and a >
(a+ a√2 +ǫ )·∆
, we clearly have
0. Using this in σDP-OPT :=
ǫ 2
∆
√
σDP-OPT > 2ǫ .
Proving Theorem 2’s Property (iii):
From Theorem 2’s
√ Property
 (ii) proved above, a > 0. Given
erfc (a) − eǫ erfc a2 + ǫ q
= 2δ, we use erfc (a) > 2δ to

derive a < inverfc(2δ) <

1
ln 2δ
, where the last step uses

15

0 < δ ≤ 0.05 and Proposition 1 below. Then we have
√

a + a2 + ǫ · ∆
√
σDP-OPT : =
ǫ 2

p
√ 
a + (a + ǫ)2 · ∆
√
<
ǫ 2
√
(2a + ǫ ) · ∆
√
=
ǫ 2
r
∆
1 ∆
·
+√
< 2 ln
2δ ǫ
2ǫ
q
Proposition 1. inverfc(x) < ln x1 for 0 < x < 1.

√
√
last step holds from erfc ( ǫ) < exp(−ǫ)
, which we obtain
πǫ
√
by replacing x with ǫ in Reference [51]’s Inequality (4):
2
)
√
erfc (x) < exp(−x
.
x π
√
√
Proving Result ii): From erfc ( ǫ) < exp(−ǫ)
given above,
πǫ
√
1
ǫ
√
we have s(ǫ) = e erfc ( ǫ) < πǫ → 0 as ǫ → ∞. Also,
s(0) = 1. Since we know from Result i) that s(ǫ) strictly
decreases as ǫ increases for ǫ > 0, the values that s(ǫ) for
ǫ ∈ (0, ∞) can take constitutes the open interval (0, 1).
(30)


Proof
of Proposition 1. The desired result inverfc(x) <
q
ln x1 follows from Lemma 8 (i.e., inverfc(x) <
q
2
ln √8x+1−1
for 0 < x < 1) and the obvious inequality
√
8x + 1 − 1 > 2x for 0 < x < 1.

Lemma
8. For 0 < y < 1, it holds that inverfc(y) <
q
2
√
ln 8y+1−1 .

E. Proof of Theorem 3
We first present Lemma 10, which is proved in Appendix F
below.
Lemma 10 (Bounds of the optimal Gaussian noise amount
for (ǫ, δ)-differential privacy). Given a fixed 0 < δ < 1, we
have:

∆
∆
For ǫ > 0: σDP-OPT < 2√2·inverfc(1−δ) = 2√2·inverf(δ) ; (31a)


√
inverfc(2δ)+ [inverfc(2δ)]2 +ǫ ·∆

√
For ǫ > 0: σDP-OPT <
. (31b)
ǫ 2

If 0 < δ  < 0.5, with ǫ∗ denoting the solution to
√
eǫ∗ erfc ǫ∗ = 1 − 2δ, we have:

We defer the proof of Lemma 8 to the end (i.e., Ap-
∆
q
;(32a)
For 0<ǫ≤ǫ∗ : σDP-OPT > √
2−2δ 2
pendix Q).
2{inverfc( 2−2δ
eǫ +1 )+ [inverfc( eǫ +1 )] +ǫ}
∆
For ǫ > ǫ : σ
(32b)
∗
DP-OPT > √2ǫ .
D. More discussions about Remark 4 of Page 5
If 0.5 ≤ δ < 1 (which does not hold in practice and is
√

With r(u) := erfc (u) − eǫ erfc u2 + ǫ , the term a presented here only for completeness), with ǫ# denoting the
in Eq. (5) satisfies r(a) = 2δ. We know that r(u) strictly solution to eǫ# erfc √ǫ#  = 1 − δ, we have:
decreases as u increases for u ∈ (−∞,
√ ∞) in view of the 
∆
2
q
;(33a)
√ u +ǫ < 0. Moreover, 
derivative r′ (u) = √2π exp(−u2 ) · u−
For ǫ > 0: σDP-OPT> √2{inverfc( 2−2δ
2−2δ 2
u2 +ǫ
√
eǫ +1 )+ [inverfc( eǫ +1 )] +ǫ}
ǫ
we now√show r(0) = 1 − e erfc ( ǫ) > 0. With s(ǫ) :=
 √ . (33b)
For ǫ > ǫ# : σDP-OPT > 
√ ∆
eǫ erfc ( ǫ), we know from Lemma 9 below that s(ǫ) strictly 
inverf(δ)+ [inverf(δ)]2 +ǫ · 2
decreases as ǫ increases for ǫ > 0. The above analysis induces
We prove Lemma 10 in Appendix F. Below we use
r(0) = 1 − s(ǫ) > 1 − s(0) = 0.
Lemma
10 to show Theorem 3.
Summarizing the
=
2δ,
√ above results, r(a)
Eq.
(31a)
is Result ① of Theorem 3. Eq. (31a) (32a)
ǫ
r(0) = 1 − e erfc( ǫ) > 0, we define ǫ∗ as the solution to
√
and
(33a)
imply
Result ② of Theorem 3. If 0 < δ < 0.5,
ǫ∗
1 − e erfc ǫ∗ = 2δ (ǫ∗ exists for 0 < δ < 0.5 from
Eq.
(31b)
and
(32b)
imply Result ③ of Theorem 3. If 0.5 ≤
Lemma 9 below), and have the following results for a in
δ
<
1,
Eq.
(31b)
and
(33b) imply Result ③ of Theorem 3.
Eq. (5), where “iff” is short for “if and only if”:
√
To
prove
Result
④ of
Theorem
3
(i.e.,
q
.
1) a > 0 iff 1−eǫ erfc (√ǫ) > 2δ (i.e., iff ǫ > ǫ∗ when ǫ∗ exists);
∆
1
=
1),
below
we
use
the
lim
σ
2
ln
δ→0 DP-OPT
ǫ
δ
2) a = 0 iff 1−eǫ erfc (√ǫ) = 2δ (i.e., iff ǫ = ǫ∗ when ǫ∗ exists);
ǫ
3) a < 0 iff 1−e erfc ( ǫ) < 2δ (i.e., iff ǫ < ǫ∗ when ǫ∗ exists). sandwich method. Specifically, we find an upper bound and a
lowerq
bound for σDP-OPT , and show that dividing each bound
In most real-world applications with ǫ√≥ 0.01 and δ ≤ 0.05,
∆
ǫ
by
2 ln δ1 converges to 1 as δ → 0.
case 1) above holds since 1 − e erfc ( ǫ) = 1 − s(ǫ) ≥ 1 −
ǫ
For the upper bound part, given a fixed ǫ > 0, we use
s(0.01) > 0.1 ≥ 2δ, where we use the above result that s(ǫ)
Theorem 2’s Property (iii) to derive
strictly decreases as ǫ increases.
!
r

1
∆
Lemma 9. The following results hold.
2 ln
σDP-OPT
√
ǫ
δ
i) With s(ǫ) := eǫ erfc ( ǫ), s(ǫ) strictly decreases as ǫ
!
!
r
r
increases for ǫ > 0.
∆
∆
1 ∆
1
·
+√
2 ln
2 ln
<
ii) The values that s(ǫ) for ǫ ∈ (0, ∞) can take constitutes
2δ ǫ
ǫ
δ
2ǫ
the open interval (0, 1).
→ 1, as δ → 0.
(34)
Proof of Lemma 9:
Proving Result i): We obtain the desired
The proof for the lower bound part is more complex and is
√ result in view of
the derivative s′ (ǫ) := − √1πǫ + eǫ erfc ( ǫ) < 0, where the presented below.

16

√

We define f (x) = ex erfc a2 + x . Then we have the
first-order derivative f ′ (x) and second-order derivative f ′′ (x)
as follows:
p

exp(−a2 )
f ′ (x) = ex erfc
a2 + x − p
π(a2 + x)

This further induces
exp(−A2 )
√
4A · (A2 + 1)(A2 + 2) π
2δ
·
≤
ǫ · exp(ǫ)
2A2 + 3
√
2δ
≤
· 4A · (0.5A2 + 0.75) π,
ǫ · exp(ǫ)

and

 exp(−a2 )
p
exp(−a2 )
+ √
. where the last step uses
a2 + x − p
π(a2 + x) 2 π(a2 + x)3/2
(A2 + 1)(A2 + 2) − (2A2 + 3)(0.5A2 + 0.75)
We have the following two propositions. After stating their
= −0.25 < 0.
proofs, we continue proving Theorem 2.
Then

(40)

f ′′ (x) = ex erfc

Proposition 2. f ′ (x) < 0 for x ≥ 0.
Proposition 3. f ′′ (x) > 0 for x ≥ 0.
Proof of Proposition 2: From Proposition 3, we have
f ′ (x) ≤ f ′ (0) for x ≥ 0, which along with
2
)
√
f ′ (0) = erfc (|a|) − exp(−a
< 0 from Reference [52]’s In|a| π
′
equality (4) implies f (x) < 0 for x ≥ 0.
Proof
of √ Proposition
3:
We
can
write
f ′′ (x) = ex u( a2 + x) for function u(y) defined by
2
)
√
(1 − 2y12 ). We have u(y) > 0
u(y) := erfc (y) − exp(−y
y π
from the asymptotic expansion (i.e., Inequality 7.12.1 in [52])
of the complementary error function erfc (·). Hence, the
desired result is proved.
Now we continue the proof of Theorem 2.
Propositions 2 and 3 induce f ′ (x) ≤ R f ′ (ǫ) < 0 for
ǫ
x R≥ 0. Then we have f (0) − f (ǫ) = − x=0 f ′ (x) dx ≥
ǫ
− x=0 f ′ (ǫ) dx = −f ′ (ǫ)ǫ, which implies
p
 2δ
exp(−a2 )
−f ′ (ǫ) = p
− eǫ erfc
a2 + ǫ ≤ . (35)
ǫ
π(a2 + ǫ)

For notation convenience, we define
p
A := a2 + ǫ.

(36)

Then

2δ
exp(−A2 )
√
− erfc (A) ≤
.
A π
ǫ · exp(ǫ)

(37)

From the inverse factorial series of the complementary error
function erfc (·) [52], it holds that
erfc (A)


1
exp(−A2 )
1
√
1−
≤
+
A π
2(A2 + 1) 4(A2 + 1)(A2 + 2)


2
2A2 + 3
exp(−A )
√
1−
,
(38)
=
A π
4(A2 + 1)(A2 + 2)
which we use in the above Inequality (37) to obtain
exp(−A2 )
2A2 + 3
2δ
√
·
≤
.
A π
4(A2 + 1)(A2 + 2)
ǫ · exp(ǫ)

(39)

exp(−A2 )
√
2δ
≤
· 4A · (0.5A2 + 0.75) π
ǫ · exp(ǫ)
r
r
i√
1h 
1 2
2δ
ln
≤
+ 0.75 π.
· 4 ln 0.5
ǫ · exp(ǫ)
δ
δ

(41)

(42)

We consider 0 < δ ≤ 0.005. We can assume δ ≤ e−1.5 . For
such δ ≤ e−1.5 , it holds that
r 1 2
r 1 2
ln
ln
0.5
+ 0.75 ≤
,
(43)
δ
δ
which we use in Inequality (42) to derive
r 1 3 √ π
2
ln
exp(−A ) ≤ 8δ
.
(44)
δ ǫ · exp(ǫ)
3 √
q
ln 1δ
π/ǫ ≤ 1, which clearly
Then for δ ≤ e−1.5 and 8δ
holds given a fixed ǫ > 0 and δ → 0, we have
v
u
ǫ · exp(ǫ)
A≥u
3 √
tln q
8δ
ln 1δ
π
s
1
ǫ
1
3
= ǫ + ln + ln √ − ln ln .
(45)
δ
2
δ
8 π
For q
ǫ ≥ 1 and
0 < δ ≤ 0.005, we can verify that • δ ≤ e−1.5 ,
3 √
ln 1δ
π/ǫ ≤ 1, and ln 8√ǫ π − 32 ln ln δ1 ≥ ln 8√1 π −
• 8δ
3
1
2 ln ln 0.005 > 0.0057. Hence,
s
r
1
0.0057
ǫ
3
1
A ≥ ln + ln √ − ln ln > ln
, (46)
δ
8 π
2
δ
δ
which implies
σDP-OPT

√


a2 + ǫ · ∆
√
=
ǫ 2
√

2
A −ǫ + A ·∆
√
=
ǫ 2
!
r
r
1
1
∆
ln + ln 0.0057 − ǫ + ln + ln 0.0057 .
> √
δ
δ
ǫ 2
(47)
q
2 ln 1δ
Clearly, dividing the above lower bound of (47) by ∆
ǫ
a+

17

converges to 1 as δ → 0. Combining this with (34), we
complete proving Result ④ of Theorem 3.

F. Proof of Lemma 10

Proof of Lemma 10’s Eq. (33a) for 0.5 ≤ δ < 1 and ǫ > 0:
The proof is similar to that for Eq. (32a) above. First, with
0.5 ≤ δ < 1 and ǫ > 0, from Appendix D, a in Eq. (5) is
negative. Then similar to the proof of Eq. (50), we have


2 − 2δ
< a < 0.
(52)
− inverfc
eǫ + 1

Proof of Lemma 10’s Eq. (31a) for ǫ > 0:
We write σDP-OPT of Theorem 2 as a function σDP-OPT (ǫ, δ).
Given a fixed 0 < δ < 0.5, clearly σDP-OPT (ǫ, δ) strictly Then we also obtain Eq. (33a) in a way similar to the proof
decreases as ǫ increases, which implies for ǫ > 0 that of Eq. (51).
σDP-OPT (ǫ, δ) is less than limǫ→0 σDP-OPT (ǫ, δ) (if such limit Proof of Lemma 10’s Eq. (33b) for 0.5 ≤ δ < 1 and ǫ > ǫ :
#
√
exists). When ǫ → 0, a in Eq. (5) is negative and satisfies
Since eǫ erfc ( ǫ) strictly decreases as ǫ increases
erfc (a) − erfc (−a) → 2δ so that a → − inverfc(1 − δ) due to
from Lemma 9 on
Page 15, for ǫ# denoting the solution
√ 
erfc (−a) = 2 − erfc (a). This further implies for ǫ → 0 that
ǫ#
ǫ
to
e
erfc
=
1 − δ,
we have for ǫ > ǫ# that
#
√

√
√ 
eǫ erfc ( ǫ) < eǫ# erfc ǫ# = 1 − δ, which gives a lower
a + a2 + ǫ · ∆
√
σDP-OPT (ǫ, δ) =
bound on a of Eq. (5):
ǫ 2
∆
√
 √
=
√ 
−a + a2 + ǫ · 2
a > inverfc 2δ + eǫ erfc ǫ
∆
> inverfc(1 + δ)
→ √
.
(48)
2 2 · inverfc(1 − δ)
= − inverf(δ).
(53)
Hence, for ǫ > 0, we have
Then
σDP-OPT (ǫ, δ) < lim σDP-OPT (ǫ, δ)
σDP-OPT (ǫ, δ)
ǫ→0
√

∆
a + a2 + ǫ · ∆
= √
√
=
2 2 · inverfc(1 − δ)
ǫ 2
∆
∆
.
(49)
= √
√
=
 √
2 2 · inverf(δ)
−a + a2 + ǫ · 2
Proof of Lemma 10’s Eq. (31b) for ǫ > 0: Eq. (31b) follows
∆
 √ .
(54)
> 
p
from Eq. (5) and Lemma 11 presented at the end of this
inverf(δ) + [inverf(δ)]2 + ǫ · 2
subsection.
Proof of Lemma 10’s Eq. (32a) for 0 < δ < 0.5 and 0 <

ǫ ≤ ǫ∗ :
We consider 0 < δ < 0.5 and 0 < ǫ ≤ ǫ∗ here. In this case, Lemma 11. a in Eq. (5) is less than inverfc(2δ).
from Appendix
result follows since Eq. (5) induces
√ D, a in Eq. (5) is negative or zero. Then we Proof of Lemma 11: The
erfc (|a|) = erfc (−a), which along erfc (a) = 2δ +eǫ erfc √a2 + ǫ > 2δ and erfc (·) is a strictly
have erfc a2 + ǫ < √
with erfc (a) − eǫ erfc a2 + ǫ = 2δ and erfc (a) = 2 − decreasing function.
erfc (−a) implies 2 − erfc (−a) − eǫ erfc (−a) < 2δ. Then we
have erfc (−a) > 2−2δ
eǫ +1 , which along with the aforementioned
result a ≤ 0 implies
G. Establishing Lemma 1, which along with Theorem 2 im

plies Theorem 4
2 − 2δ
− inverfc
< a ≤ 0.
(50)
√
eǫ + 1
When eǫ erfc ( ǫ) + 2δ ≥ 2, we have b = 0 from Eq. (7a)
on Page 6 and a ≤ 0 from Appendix D on Page 15, so the
Thus,
desired √
result a ≤ b follows. Below we focus on the case of
σDP-OPT (ǫ, δ)
ǫ
ǫ) + 2δ < 2.
e
erfc
(
√

a + a2 + ǫ · ∆
We use Theorem 2 to prove Theorem 4. In particular, we
√
=
will show that a specified in Eq. (5) is less than b defined
ǫ 2
in Eq. (7a).
∆
√
=
 √
Recall that Eq. (5) presents
−a + a2 + ǫ · 2

p
∆
a2 + ǫ = 2δ.
(55)
erfc (a) − eǫ erfc
q
>√
. (51)
2−2δ 2
2 · {inverfc( 2−2δ
[inverfc(
)
+
)]
+
ǫ}
ǫ
ǫ
e +1
e +1
We will find an upper bound for a and this upper bound will be
Proof of Lemma 10’s Eq. (32b) for 0 < δ < 0.5 and ǫ > ǫ∗ : b. To this
√ end, we will show erfc (a) is at least some fraction of
by i) proving a lower bound
We consider 0 < δ < 0.5 and ǫ > ǫ∗ here. In this case, from erfc a2 + ǫ . This will be done
√
erfc( u2 +ǫ)
Appendix
D,
a
in
Eq.
(5)
is
positive.
Then
σ
(ǫ,
δ)
=
DP-OPT
for a, and ii) showing that
strictly increases as u
√
√
erfc(u)
(a+ a√2 +ǫ )·∆
ǫ·∆
√∆ .
√
increases
for
u
∈
(−∞,
∞).
>
=
ǫ 2
ǫ 2
2ǫ

18

We first give a lower √
bound for
 a. From Eq. (55),
√ we have
erfc (a) = 2δ + eǫ erfc a2√+ ǫ < 2δ + eǫ erfc ( ǫ), which
implies that if 2δ + eǫ erfc ( ǫ) < 2,
√ 
(56)
a > inverfc 2δ + eǫ erfc ǫ ,

where we note that the image domain of erfc (·) is (0, 2) since
the image domain of erf (·) is (−1, 1) and erfc (·) = 1−erf (·).

H. Establishing Lemma 2, which along with Theorem 4 implies Theorem 5
From Eq. (61), it holds that erfc (b) > 2δ, which implies
b < inverfc(2δ). For 0 < δ < 0.5, we replace y in
Lemma
q 8 on Page 15 with 2δ to obtain inverfc(2δ) < c for
2
. Then we have b < c. Thus, Theorem 4
c := ln √16δ+1−1
implies Theorem 5.


√

erfc( u2 +ǫ)
We now prove h(u) :=
strictly increases as u
erfc(u)
increases for u ∈ (−∞, ∞). Taking the derivative of h(u) I. Proof of Lemma 3
with respect to u, we obtain
The sktech of the following proof is given in [2]. We present
√
√


′
2 + ǫ × erfc (u) − erfc
2 + ǫ × erfc′ (u)the full details for completeness.
u
u
erfc
h′ (u) =
Recall that a mechanism Y achieves (ǫ, δ)-differential prierfc2 (u)
vacy
if
2
κ(u)
,
(57)
= √ × exp(−u2 ) ×
π
P [Y (x) ∈ Y] ≤ eǫ P [Y (x′ ) ∈ Y] + δ,
erfc2 (u)

for any output set Y, neighboring datasets x and x′ , (62)

for κ(u) defined by


p
u
the coin flips of the
κ(u) := − exp (−ǫ) × √
u2 + ǫ . where the probability space is over
× erfc (u) + erfc
u2 + ǫ
randomized mechanism Y , D and D′ iterate through all pairs
(58) of neighboring datasets, and Y iterates through all subsets of
the output range.
To achieve (ǫ, δ)-differential privacy, we first show that it
We will prove κ(u) > 0. To this end, we first investigate the
suffices to ensure
monotonicity of κ(u) for u ∈ (−∞, ∞). Taking the derivative


F [Y (x) = y]
ǫ
of κ(u) with respect to u, we get
P
≤ e ≥ 1 − δ,
F [Y (x′ ) = y]

2
u
× √ exp −u2
κ′ (u) = exp (−ǫ) × √
for any output y, neighboring datasets x and x′ ,
(63)
π
u2 + ǫ
√
2
where the probability space is over the coin flips of the
u2 + ǫ − √uu2 +ǫ
×
erfc
(u)
− exp (−ǫ) ×
randomized mechanism Y , D and D′ iterate through all pairs
u2 + ǫ
of neighboring datasets, and y iterates through the output range

2
u
− √ exp −u2 − ǫ × √
O. Specifically, we will prove that Eq. (63) implies Eq. (62).
π
u2 + ǫ
We define set S by
ǫ


= − exp (−ǫ) × 2
× erfc (u)
3/2
F [Y (x) = y]
(u + ǫ)
ǫ
(64)
≤e .
S := y
F [Y (x′ ) = y]
< 0.
(59)
Hence, κ(u) strictly decreases as u increases for u ∈
κ(u)
:= 1 −
(−∞, ∞). Combining this and limu→∞ erfc(u)

κ(u)
>0
exp (−ǫ) > 0, we conclude for u ∈ (−∞, ∞) that erfc(u)
and hence κ(u) > 0. Thus, h′ (u) in Eq. (57) is positive, so that
h(u) is increasing for u ∈ (−∞, ∞). This along with Eq. (56)
implies
√  
h(a) ≥ h inverfc 2δ + eǫ erfc ǫ
.
(60)

From Eq. (55) and (60), and h(a) :=
erfc (a) =

√
erfc( a2 +ǫ)
,
erfc(a)

we derive

2δ
1 − eǫ · h(a)

2δ
√ 
1 − · h inverfc 2δ + eǫ erfc ( ǫ)
= erfc (b) ,
(61)

≥

eǫ

where the last step uses the expression of b in Eq. (7a). Hence,
it holds that a ≤ b. Then we obtain the desired result of
Theorem 2 implying Theorem 4.


Then if Eq. (63) holds, we have
P [Y (x) ∈ S] ≥ 1 − δ.

(65)

With O being the output range, O \ S is the complement set
of S. Then Eq. (65) implies
P [Y (x) ∈ O \ S] = 1 − P [Y (x) ∈ S] ≤ δ.

(66)

To show that Eq. (63) implies Eq. (62), we have
P [Y (x) ∈ Y]

= P [Y (x) ∈ Y ∩ S] + P [Y (x) ∈ Y \ S]
Z
=
F [Y (x) = y] dy + P [Y (x) ∈ Y \ S]
y∈Y∩S
Z
(*)
≤
eǫ F [Y (x′ ) = y] dy + P [Y (x) ∈ O \ S]
y∈Y∩S

(#)

≤ eǫ P [Y (x′ ) ∈ Y ∩ S] + δ
≤ eǫ F [Y (x′ ) ∈ Y] + δ,

(67)

where the above step (*) uses Eq. (64) and Y \ S ⊆ O \ S,
and step (#) uses Eq. (66).


19

J. Proof of Lemma 4
For neighboring datasets D and D′ , the privacy loss
K. Proof of Theorem 6
LY,D,D′ (y) represents the multiplicative difference between
For the proposed Gaussian mechanism, we now prove
the probabilities that the same output y is observed when the


randomized algorithm Y is applied to D and D′ , respectively.
F [Y (D) = y]
ǫ
−ǫ
≥ 1 − δ,
≤
e
P
e
≤
y∼Y (D)
Specifically, we define
F [Y (D′ ) = y]
LY,D,D′ (y) := ln

F [Y (D) = y]
,
F [Y (D′ ) = y]

(68)

where F [·] denotes the probability density function.
For simplicity, we use probability density function F [·] in
Eq. (11) above by assuming that the randomized algorithm Y
has continuous output. If Y has discrete output, we replace
F [·] by probability notation P [·].
When y follows the probability distribution of random
variable Y (D), LY,D,D′ (y) follows the probability distribution
of random variable LY,D,D′ (Y (D)).
We have Lemmas 12 and 13 below, which will be proved
soon.
Lemma 12. Given datasets D, D′ , and an (ǫ, δ)-differentially
private randomized algorithm Y , for any real number t, it
holds that
δ
P [LY,D,D′ (Y (D)) ≥ t] ≤
.
(69)
1 − eǫ−t
Lemma 13. The relationships between privacy loss random
variables LY,D,D′ (Y (D)) and LY,D′ ,D (Y (D′ )) are as follows.
Given datasets D, D′ , and a randomized algorithm Y , for any
real number t, it holds that
−t

′

P [LY,D,D′ (Y (D)) ≤ −t] ≤ e P [LY,D′ ,D (Y (D )) ≥ t] .
(70)
Proof of Lemma 4: The result follows from Lemmas 12
and 13.

Proof of Lemma 12: Since LY,D,D′ (Y (·)) can be seen as postprocessing on Y (·) and hence also satisfies (ǫ, δ)-differential
privacy, we have
P [LY,D,D′ (Y (D)) ≥ t]
≤ δ + eǫ P [LY,D,D′ (Y (D′ )) ≥ t]
Z
ǫ
=δ+e
F [Y (D′ ) = y] P [LY,D,D′ (y) ≥ t] dy
Y


Z
F [Y (D) = y]
= δ + eǫ
F [Y (D′ ) = y] P
dy
≥ et F [Y (D′ ) = y]
Y


Z
F [Y (D) = y]
≤ δ + eǫ
e−t F [Y (D) = y] P
dy
≥ et F [Y (D′ ) = y]
Y
= δ + eǫ−t P [LY,D,D′ (Y (D)) ≥ t]

(71)


Proof of Lemma 13: We have
P [LY,D,D′ (Y (D)) ≤ −t]


Z
F [Y (D) = y]
=
F [Y (D) = y] P
dy
≤ e−t F [Y (D′ ) = y]


ZY
F [Y (D′ ) = y]
e−t F [Y (D′ ) = y] P
≤
dy
≥ et F [Y (D) = y]
Y
= e−t P [LY,D′ ,D (Y (D′ )) ≥ t] .



for any output y, neighboring datasets D and D′ .

(72)

The desired result Eq. (72) can also be written as


F [Y (D) = y]
≤
ǫ
≥ 1 − δ,
Py∼Y (D) ln
F [Y (D′ ) = y]
for any output y, neighboring datasets D and D′ .

(73)

With (ǫ, δ)-differential privacy being translated to Eq. (73), we
will show that the minimal noise amount can be derived, while
the classic mechanism by Dwork and Roth [2] presents only
a loose bound.
Let the output of the query Q on the dataset D be an mdimensional vector. We define notation r1 , . . . , rm such that
y − Q(D) = [r1 , . . . , rm ].

(74)

Since Y (D) is the result of adding a zero-mean Gaussian
noise with standard deviation σ to Q(D), we have

m 
Y
rj 2
1
√
e− 2σ2 .
(75)
F [Y (D) = y] =
2πσ 2
j=1
We introduce notation s1 , . . . , sm such that

Q(D) − Q(D′ ) = [s1 , . . . , sm ].

(76)

From Eq. (74) and (76), it holds that
y − Q(D′ ) = [r1 + s1 , . . . , rm + sm ].

(77)

Since Y (D′ ) is the result of adding a zero-mean Gaussian
noise with standard deviation σ to Q(D′ ), we have

m 
Y
(rj +sj )2
1
√
F [Y (D′ ) = y] =
e− 2σ2
.
(78)
2πσ 2
j=1
The combination of Eq. (75) and (78) induces


rj 2
Qm
− 2σ
2
√ 1
e
j=1
2πσ2
F [Y (D) = y]


= ln
ln
′
(r +s )2
Qm
F [Y (D ) = y]
− j2σ2j
√ 1
e
j=1
2πσ2


m
X
(rj + sj )2
rj 2
=
− 2
2σ 2
2σ
j=1
Pm
Pm
2
j=1 sj
j=1 (sj rj )
+
.
(79)
=
σ2
2σ 2
We define
v
uX
um
S := t
sj 2 ,
(80)
j=1

and

G :=

Pm

j=1 (sj rj )

S

.

(81)

20

From Eq. (76), S is the ℓ2 distance between Q(D) and Q(D′ );
i.e.,
S := kQ(D) − Q(D′ )k2 .

(82)

Note that rj for each j ∈ {1, 2, . . . , m} defined in Eq. (74) is a
zero-mean Gaussian random variable with standard deviation
σ. In addition, r1 , . . . , rm are independent. Hence,
Pm
j=1 (sj rj )
is a zero-mean Gaussian
G defined as
S
Pm
2 2
j=1 (sj σ )
random variable with variance
= σ 2 , (83)
S2
where the last step uses Eq. (80). For notational simplicity, we
write G ∼ Gaussian(0, σ 2 ).
From Eq. (80) and (81), it follows that
ln
Hence, we have

F [Y (D) = y]
S2
GS
= 2 + 2.
′
F [Y (D ) = y]
σ
2σ


F [Y (D) = y]
≤ǫ
Py∼Y (D) ln
F [Y (D′ ) = y]


GS
S2
= PG∼Gaussian(0,σ2 )
+ 2 ≤ǫ .
σ2
2σ

Defining d as
result.

ǫσ2
−∆
∆√
2

σ 2

and solving σ, we obtain the desired


L. Proof of Theorem 7
① Given a fixed 0 < δ < 1, we.
have
 limǫ→0 d= inverfc(δ),
inverfc(δ)·∆
√
which results in limǫ→0 σpDP-OPT
= 1.
ǫ 2
② Given a fixed 0 < δ <
. 1,
 we have limǫ→∞ d = 0, which
√∆
= 1.
leads to limǫ→∞ σpDP-OPT
2ǫ
③ Given a fixed q
ǫ > 0, we use Lemma 5
to
derive
limδ→0 d ln 1δ
=
1
and
thus
. q

∆
1
limδ→0 σpDP-OPT

2 ln δ = 1.
ǫ

(84)

M. Establishing Lemma 5, which along with Theorem 6 implies Theorem 8
From
√ the definition of d in Eq. (13a): erfc (d) +
erfc d2 + ǫ = 2δ, we clearly have δ < erfc (d) < 2δ,
which implies inverfc(2δ) < d < inverfc(δ).


(85)

N. Proving Lemma 6, which along with Theorem 8 implies
Theorem 9



If S > 0, given the result Eq. (81) that G is a zero-mean
Gaussian random variable with standard deviation σ, we obtain


S2
GS
≤
ǫ
+
PG∼Gaussian(0,σ2 )
σ2
2σ 2


2
S
ǫσ 2
S
ǫσ
− ≤G≤
−
=P −
S
2
S
2
!#
"
"
!#
2
ǫσ2
S
− ǫσS − S2
1
1
S − 2
√
√
−
1 + erf
1 + erf
=
2
2
σ 2
σ 2
!
!
S
S
ǫσ2
ǫσ2
−
+
1
1
S
S
√ 2 + erf
√ 2
= erf
2
2
σ 2
σ 2
= fǫ, σ (S),

We can prove that fǫ, σ (S) is a decreasing function of S.
Hence, the optimal Gaussian mechanism to achieve (ǫ, δ)probabilistic differential privacy satisfies fǫ, σ (∆) = 1 − δ.

(86)

q
2
>
To show Lemma 6, it suffices to prove ln √8δ+1−1
inverfc(δ) for 0 < δ < 1. This clearly follows from Lemma 8
proved in Appendix Q by replacing y with δ.
O. Algorithm 1 to compute σDP-OPT of Theorem 2
As discussed at the end of Section V, the noise amounts of
our mechanisms can be set as initial values to quickly search
for the optimal value σDP-OPT . In particular, Algorithm 1 to
compute σDP-OPT will use Lemma 14 below.

Lemma 14. We have the following bounds for a in Eq. (5) of
Theorem 2:
for fǫ, σ (S) defined by

0 < a < b of Eq. (7a)
"
!
!#


√
ǫσ2
ǫσ2
S
S


−
+
1
< c of Eq. (9),
if 1−eǫ erfc ( ǫ)>2δ; (90a)
S
S
√ 2 + erf
√ 2
fǫ, σ (S) :=
erf
, (87) 
√
2
σ 2
σ 2
a=0,
if 1−eǫ erfc ( ǫ)=2δ;(90b)





√
− inverfc 2−2δ
where Eq. (86) uses the cumulative distribution function of a 
if 1−eǫ erfc ( ǫ)<2δ. (90c)
eǫ +1 <a<0,
zero-mean Gaussian random variable G as well as the fact that
Proof of Lemma 14: First, (90a) follows from Lemmas 1
erf(·) is an odd function; i.e., erf(−x) = − erf(x).
and 2. Second, (90b) holds from Eq. (5) and Remark 4. Next,
If S = 0, it is clear that
we prove Eq. (90c) as follows.


GS
S2
From Lemma 9 on Page 15, we have
PG∼Gaussian(0,σ2 )
≤ ǫ = 1.
(88)
+
 If 0.5 ≤ δ < 1,
σ2
2σ 2



The ℓ2 -sensitivity ∆ of the query Q is the maximal 

 then any ǫ >√0 satisfies

ℓ2 distance between the (true) query outputs for any two 
 1 − eǫ erfc ǫ < 2δ.
neighboring datasets D and D′ that differ in one record:
If 0 < δ < 0.5, then 0 < ǫ < ǫ∗ satisfies

∆ = maxneighboring D, D′ kQ(D) − Q(D′ )k2 . From Eq. (82), 


√ 

we have 0 ≤ S ≤ ∆. Then summarizing Eq. (86) and (88), to 
1 − eǫ erfc ǫ < 2δ,



√
guarantee Eq. (73), it suffices to ensure
where ǫ∗ denotes the solution to eǫ∗ erfc ( ǫ∗ ) = 1 − 2δ.
fǫ, σ (S) ≥ 1 − δ, for 0 < S ≤ ∆.
(89) Then we use Eq. (50) and (52) to obtain (90c).


21

Algorithm 1 Computing σDP-OPT of Theorem 2 based on
Lemma 14.
√
1: diff ← 1 − eǫ erfc ( ǫ) − 2δ;
2: if diff = 0 then
3:
a ← 0;
4: else if diff > 0 then
5:
N ← 1;
6:
lower ← 0;
7:
upper ← any one of the following:
b of Eq. (7a) in our Theorem 4 for Mechanism 1,
c of Eq. (9) in our Theorem 5 for Mechanism 2;
8:
while N ≤ the allowed maximum number of iterations
do
9:
if upper − lower < tolerance then
10:
a ← upper;
11:
break
12:
end if
13:
mid ← (lower + upper)/2;

p
mid2 + ǫ = 2δ then
14:
if erfc (mid) − eǫ erfc
15:
a ← mid;
16:
break
p

17:
else if erfc (mid) − eǫ erfc
mid2 + ǫ > 2δ then
18:
lower ← mid;
19:
else
20:
upper ← mid;
21:
end if
22:
N ← N + 1;
23:
end while
24: else
25:
N ← 1;


26:
lower ← − inverfc 2−2δ
eǫ +1 ;
27:
upper ← 0;
28:
while N ≤ the allowed maximum number of iterations
do
29:
if upper − lower < tolerance then
30:
a ← upper;
31:
break
32:
end if
33:
mid ← (lower + upper)/2;
p

34:
if erfc (mid) − eǫ erfc
mid2 + ǫ = 2δ then
35:
a ← mid;
36:
break
p

37:
else if erfc (mid) − eǫ erfc
mid2 + ǫ > 2δ then
38:
lower ← mid;
39:
else
40:
upper ← mid;
41:
end if
42:
N ← N + 1;
43:
end while
44: end if
√
(a+ a√2 +ǫ )·∆
;
45: σDP-OPT ←
ǫ 2
46: return σDP-OPT

Note that in practice, due to ǫ ≥ 0.01 and δ ≤ 0.05, we
have (90a) as explained in Appendix D. We present (90b) and
(90c) for completeness.
To ensure σ returned by Algorithm 1 satisfies
0 ≤ σ − σDP-OPT ≤ ζ for some ζ ≥ 0, we clearly have
the following results on the computational complexity of
Algorithm 1:
√
• If 1 − eǫ erfc ( ǫ) > 2δ, then Algorithm 1 takes at most
b
log2 ζ iterations (resp., log2 ζc ) if Line 7 uses b of Eq. (7a)
(resp., c of Eq. (9)), with each iteration
 having
 O(1)
complexity. The total complexity is O log2 ζb (resp.,


O log2 ζc ).
√
• If 1 − eǫ erfc ( ǫ) < 2δ, then Algorithm 1 takes
2−2δ
inverfc( exp(ǫ)+1
)
at most log2
iterations, with each iteraζ
tion
having
O(1)
complexity.
The total complexity is


2−2δ
inverfc( exp(ǫ)+1
)
.
O log2
ζ
P. Analyses of (ǫ, δ)-Differential Privacy and (ǫ, δ)Probabilistic Differential Privacy for the Composition
of Gaussian Mechanisms
This section provides analyses of (ǫ, δ)-differential privacy
and (ǫ, δ)-probabilistic differential privacy for the composition
of Gaussian mechanisms.
Lemma 15. For m queries Q1 , Q2 , . . . , Qm with ℓ2 -sensitivity
∆1 , ∆2 , . . . , ∆m , if the query result of Qi is added with
independent Gaussian noise of standard deviation σi , we have
the following results.
i) The differential privacy (DP) level for the composition of
the m noisy answers is the same as that of a Gaussian
mechanism with noise amount
!−1/2
m
X
∆i 2
σ∗ :=
(92)
σi 2
i=1

for a query with ℓ2 -sensitivity 1.
ii) The probabilistic differential privacy (pDP) level for the
composition of the m noisy answers is the same as that of
a Gaussian mechanism with noise amount σ∗ in Eq. (92)
for a query with ℓ2 -sensitivity 1.
Remark 9.
DP
• Result i) of Lemma 15 implies the following. Let σǫ,δ
be a Gaussian noise amount which achieves (ǫ, δ)-DP
for a query with ℓ2 -sensitivity 1, where the expression of
DP
σǫ,δ
can follow from classical ones Dwork-2006 and
Dwork-2014 of [1], [2] (when ǫ ≤ 1), the optimal
one DP-OPT of Theorem 2, or our proposed mechanisms
Mechanism 1 of Theorem 4 and Mechanism 2 of
Theorem 5. Then the above composition satisfies (ǫ, δ)-DP
DP
for ǫ and δ satisfying σ∗ ≥ σǫ,δ
with σ∗ defined above.
pDP
• Result ii) of Lemma 15 implies the following. Let σǫ,δ
be
a Gaussian noise amount which achieves (ǫ, δ)-pDP for a
pDP
query with ℓ2 -sensitivity 1, where the expression of σǫ,δ
can follow the optimal one, or our proposed mechanisms.

22

Then the above composition satisfies (ǫ, δ)-pDP for ǫ and
pDP
δ satisfying σ∗ ≥ σǫ,δ
with σ∗ defined above.
Proof of Lemma 15:
We consider m queries Q1 , Q2 , . . . , Qm with ℓ2 -sensitivity
∆1 , ∆2 , . . . , ∆m . The query result of Qi on dataset D is added
with independent Gaussian noise of standard deviation σi , in
e i (D).
order to generate a noisy version Q
We first state a result for a general query Q. Let the query
result of Q on dataset D be added with Gaussian noise of
standard deviation σ, in order to generate a noisy version
e
Q(D).
From Eq. (82) (83) and (84), we obtain:

e
with y following the probability distribution of Q(D)
(i.e., a Gaussian distribution with mean Q(D)
and standard deviation σ),
e
F[Q(D)=y
]
the term ln F Q(D
obeys a Gaussian distribution
[ e ′ )=y]
′
′
)k2 ]2
)k2 ]2
and variance [kQ(D)−Q(D
.
with mean [kQ(D)−Q(D
2σ2
σ2
(93)

e be the composition of mechanisms Q
e1 , Q
e2 , . . . , Q
em .
Let Q
e i (D), and let
Let yi follow the probability distribution of Q
y be the composition of y1 , y2 , . . . , ym , which means that
e
y follow the probability distribution of Q(D).
Following
Eq. (11), the privacy loss function of Q on neighbouring
datasets D and D′ can be defined as
h
i
e
F Q(D)
=y
h
i
LQ,D,D
′ (y) = ln
e
e ′) = y
F Q(D
ii
h
h
e i (D) = yi
Q
F ∩m
i=1
ii .
h
= ln h
(94)
m
e i (D′ ) = yi
F ∩i=1 Q
e 1, Q
e2 , . . . , Q
e m are independent, we further have
Since Q
i
h
e i (D) = yi
m
F Q
X
i.
ln h
(95)
LQ,D,D
′ (y) =
e
e i (D′ ) = yi
F Q
i=1

From

(93),

ln

ei (D)=yi ]
F [Q
e i (D′ )=yi ]
F [Q

distribution with mean
[kQi (D)−Qi (D′ )k2 ]2
.
σi 2

follows

[kQi (D)−Qi (D′ )k2 ]2
2σi 2

a

Gaussian

and variance

Then from (95), LQ,D,D
′ (y) follows a
e
Pm [kQi (D)−Qi (D′ )k2 ]2
Gaussian distribution with mean
i=1
2σi 2
′
2
Pm
i (D )k2 ]
.
and variance i=1 [kQi (D)−Q
σi 2
e both (ǫ, δ)-differential
To account for the privacy level of Q,
privacy and (ǫ, δ)-probabilistic differential privacy can be
given by conditions on LQ,D,D
′ (y) for any pair of neighboring
e
′
e
datasets D and D . In particular, from Theorem 5 of [22], Q
achieves (ǫ, δ)-differential privacy if and only if


Py∼Q(D)
[LQ,D,D
′ (y) > ǫ]
e
e

 ≤ δ,
(96)
−eǫ Py∼Q(D)
[LQ,D,D
′ (y) < −ǫ]
e
e
for any pair of neighboring datasets D and D′ .

e achieves (ǫ, δ)-probabilistic differential
From Definition 2, Q

privacy if and only if
Py∼Q(D)
[ LQ,D,D
′ (y) > ǫ] ≤ δ,
e
e

(97)
′

for any pair of neighboring datasets D and D .

Our analysis above shows that LQ,D,D
′ (y) follows a Gause
′

)
sian distribution with mean A(D, D′ ) and variance A(D,D
2
′
2
P
m
[kQ
(D)−Q
(D
)k
]
i
i
2
for A(D, D′ ) := i=1
. Since kQi (D) −
2σi 2
Qi (D′ )k2 is at most the ℓ2 -sensitivity ∆i of query Qi ,
P
∆i 2
the term A(D, D′ ) is no greater than m
i=1 σi 2 . Lemma 7
of [22] proves that the left hand side of Eq. (96) strictly
e achieves (ǫ, δ)increases when A(D, D′ ) increases. Hence, Q
∗
differential privacy if for L obeying a Gaussian distribution
Pm
2
∗
i
with mean A∗ and variance A2 for A∗ := i=1 ∆
σi 2 , we have

P[L∗ > ǫ] − eǫ P[L∗ < −ǫ] ≤ δ.

(98)

From (93) above and [22]’s Theorem 5, Inequality (98) is
also the condition to ensure that answering a query with ℓ2 sensitivity 1 and Gaussian noise amount √1A∗ satisfies (ǫ, δ)differential privacy.
e achieves (ǫ, δ)-probabilistic differential privacy
Similarly, Q
if for L∗ obeying a Gaussian distribution with mean A∗ and
Pm
2
∗
i
variance A2 for A∗ := i=1 ∆
σi 2 , we have
P[|L∗ | > ǫ] ≤ δ.

(99)

From (93) above, Inequality (99) is also the condition to ensure
that answering a query with ℓ2 -sensitivity 1 and Gaussian noise
amount √1A∗ satisfies (ǫ, δ)-probabilistic differential privacy.
−1/2
P
m ∆i 2
With the above results and √1A∗ =
,
2
i=1 σi
Lemma 15 is proved.

Q. Proof of Lemma 8
Lemma 8 (Restated).
For 0 < y < 1, it holds that
q
2
inverfc(y) < ln √8y+1−1
.
Proof: We define a function g(·) as
1
1
exp(−2x2 ) + exp(−x2 ).
2
2
Then we derive for 0 < y < 1 that
s
2
−1
.
g (y) = ln √
8y + 1 − 1
g(x) =

(100)

(101)

We relate Lemma 8 with the result
erfc(x) < g(x), for x > 0.

(102)

The rest of the proof includes two parts: i) using (102) to show
Lemma 8, and ii) proving (102).
Using (102) to show Lemma 8:
We replace x by g −1 (y) in Eq. (102), and thus obtain
g(g −1 (y)) > erfc(g −1 (y)).

(103)

The term g(g −1 (y)) in Eq. (103) equals y and can also be
written as erfc(inverfc(y)); i.e., we can express Eq. (103) as
follows:
erfc(inverfc(y)) > erfc(g −1 (y)).

(104)

23

As erfc() is a decreasing function, Eq. (104) implies
inverfc(y) < g −1 (y).

(105)

From
Eq. (101), we know that g −1 (y) in Eq. (105) equals
q
2
. Hence, Eq. (105) above means Lemma 8.
ln √8y+1
−1
Proving (102):
The
error function erfc(x) equals
R ∞ complementary
−t2
√2
e
dt.
We
will
prove another form of the
π x
complementary error function for x ≥ 0. Specifically,
we will show


Z π2
x2
2
exp −
dθ, for x ≥ 0. (106)
erfc(x) =
π 0
sin2 θ
The right hand side of Eq. (106) is an alternative form of the
complementary error function, and is known as Craig’s formula [53] in the literature. Yet, to show Eq. (106), Craig [53]
uses empirical arguments and not many studies present a
rigorous proof. Below we formally establish Eq. (106) for
completeness.R
2
∞
Given √2π 0 e−s ds = erfc(0) = 1, we now write erfc(x)
R
2
∞
(i.e., √2π x e−t dt) as follows:
Z ∞
2
2
√
e−t dt
π x
Z ∞
Z ∞
2
2
2
2
e−s ds · √
e−t dt
=√
π 0
π x
Z
Z ∞
2
4 ∞ −s2
e
ds
e−t dt.
(107)
=
π 0
x

We express the integral of Eq. (107) in polar coordinates.
Specifically, under s = r cos θ and t = r sin θ, the intervals
s ∈ [0, ∞) and t ∈ [x, ∞) correspond to r ∈ [x/ sin θ, ∞)
and θ ∈ [0, π2 ]. Also, it holds that dsdt = rdr dθ. Then the
right hand side (RHS) of Eq. (107) is given by
Z ∞
Z π2
2
4
RHS of Eq. (107) =
dθ
re−r dr
π 0
x/ sin θ
 y=∞

Z π2
2
4
1
=
dθ − e−y
π 0
2
y=x/ sin θ


Z π2
2
x2
=
exp −
dθ.
(108)
π 0
sin2 θ
Summarizing Eq. (107) and Eq. (108), we have proved
Eq. (106). To further bound erfc(x) based on Eq. (106), we
obtain for x > 0 that


Z π2
x2
2
exp −
dθ
π 0
sin2 θ


Z π
Z π2
2 4
2
x2
<
dθ
+
exp −
exp(−x2 )dθ
π 0
π π4
sin2 π4
2 π
2 π
= · · exp(−2x2 ) + · · exp(−x2 )
π 4
π 4
= g(x),
which along with Eq. (106) gives (102).
Since we have shown (102) and the result that (102) implies
Lemma 8, we complete proving Lemma 8.


