Exponential ergodicity for diffusions
with jumps driven by a Hawkes process

arXiv:1904.06051v3 [math.PR] 8 Jan 2020

January 9, 2020
Charlotte Dion(1) and Sarah Lemler(2) and Eva Löcherbach(3)
(1)

Sorbonne Université, UMR CNRS 8001, LPSM, 75005 Paris, France
(2) École CentraleSupélec, MICS, 91190 Gif-sur-Yvette, France
(3) Université Paris 1, SAMM EA 4543, 75013 Paris, France

Abstract
In this paper, we introduce a new class of processes which are diﬀusions with jumps driven by a
multivariate nonlinear Hawkes process. Our goal is to study their long-time behavior. In the case of
exponential memory kernels for the underlying Hawkes process we establish conditions for the positive
Harris recurrence of the couple (X, Y ), where X denotes the diﬀusion process and Y the piecewise
deterministic Markov process (PDMP) deﬁning the stochastic intensity of the driving Hawkes. As a
direct consequence of the Harris recurrence, we obtain the ergodic theorem for X. Furthermore, we
provide suﬃcient conditions under which the process is exponentially β−mixing.
AMS Classification: 60J35, 60F99, 60H99, 60G55
Keywords: Diﬀusions with jumps; nonlinear Hawkes process, Piecewise deterministic Markov processes
(PDMP), Ergodicity; Foster-Lyapunov drift criteria; β-mixing.

1
1.1

Introduction
Motivation

In this work, we introduce a new class of continuous time processes X = (Xt )t≥0 taking values in R,
with jumps driven by a multivariate nonlinear Hawkes process N, satisfying the following equation
Xt = X0 +

Z

t

b(Xs )ds +
0

Z

t

σ(Xs )dWs +

0

Z

t

a(Xs− )
0

M
X

dNs(j) ,

(1.1)

j=1

where W is the standard one-dimensional Brownian motion and N is a multivariate Hawkes process
having M components with intensity process λ. N is supposed to be independent from W. We shall
specify the dynamics of N later on, in particular, the precise form of the stochastic intensity process
λ is given in (2.1) below.
The jumps of the Hawkes process impact the dynamic of the diﬀusion process. In this model, the
structure of the jumps is diﬀerent from classical jump-diﬀusion processes with Lévy jumps. Indeed:
1) the intensity of the jump process N does not depend on the dynamic of X,
1

2) the Hawkes process has a special structure of time dependency: the state of the intensity at time t
depends on the entire past,
3) the multidimensional nature of the Hawkes process can be interpreted as the inﬂuence of M subjects
communicating one with each other and impacting the dynamic of X along time.
Our main motivation is to be able to describe systems of interacting neurons, where we are in particular interested in modeling the membrane potential of a single neuron together with the sequence
of spike times of its presynaptic neurons. Indeed, neurons are communicating through the emission of
electrical signals, forming a network. When a (presynaptic) neuron sends a signal to another (postsynaptic) neuron, the membrane potential of the neuron increases sharply, and we say that the neuron
spikes at this time. If we are looking at one ﬁxed neuron at the heart of this network, its activity
between two spikes of one of its presynaptic neurons can be designed by the present model. Indeed,
during this interval the membrane potential can be described by a diﬀusion process inﬂuenced by the
spikes coming from the presynaptic neurons which are modeled by the Hawkes process. Hawkes processes have been studied recently in the context of neurosciences [see 34, 18] to model the interactions
between the neurons within their sequences of spikes. The new model we propose allows to use both
informations: the continuous membrane potential for a ﬁxed neuron together with the spikes of several
other neurons around it.
The aim of the present article is to study the longtime behavior of the process X. Since X is not
Markov on its own, we propose a study of the couple of processes (X, λ) in the case when the intensity
λ of N can be described in terms of a piecewise deterministic Markov process (PDMP) Y, see (2.4)
below. Such a description is possible when the memory kernels are exponential. We prove the positive
Harris recurrence of (X, Y ) together with ergodicity, and we establish the speed of β−mixing. These
are important probabilistic properties which are interesting in its own right but which are also the
key ingredients for the theoretical study of estimators of the model parameters. The estimation of the
coeﬃcients of the process is the issue of the companion paper [11].

1.2

State of the art

Time-homogeneous diﬀusion processes are well known Markov processes that have been widely studied.
Let us cite for example [22] which has initiated the work on Markovian properties of diﬀusion processes
or the by now classical references [21, 33] in which all properties of diﬀusions are summarized. Ergodicity and strong mixing have been established in the pioneering papers [37, 23]. Then, jump-diﬀusion
processes have been introduced, for example in the context of risk management [see 36], either driven
by a Poisson process or more generally by a Lévy process [see 1, for a review]. Their ergodicity and
mixing properties have been studied from a probabilistic point of view by [29].
On the other hand, Hawkes processes [17] have been studied a lot lately. These point processes generalize the Poisson processes by introducing what is commonly called “self-excitation”: Present jumps
are able to trigger (or to inhibit) future jumps, and in this way, correlations between successive jump
events are introduced. [9] gives a precise synthesis of earlier results published by Hawkes. Important
probabilistic results for these mutually exciting point processes, such as stability, limit theorems and
large population limits, have been obtained in [6, 10, 2, 3, 8, 5]. Ergodicity for general non-linear
Hawkes processes with general memory kernels has been recently established by [5]. For linear Hawkes
processes, [15] proves exponential ergodicity, giving very precise estimates on the regeneration times.
Finally [8] establishes exponential ergodicity in the particular case of linear Hawkes processes with
exponential memory kernels.
Relying on one of these recent results on ergodicity of Hawkes processes, it is therefore reasonable
to argue that the solution of (1.1) should be ergodic itself, provided we are able to ensure that the
diﬀusion part of (1.1), that is the dynamic (1.1) with a(·) ≡ 0, driving the motion in between successive
2

jumps, is ergodic.
However, no such general criterion, ensuring that the ergodicity of the underlying jump process
implies the ergodicity of the associated diﬀusion with jumps, exists, at least not to our knowledge.
The present paper proposes therefore a short study of the ergodicity of diﬀusions with jumps driven
by Hawkes processes with exponential memory kernels. In this case, the associated stochastic intensity
processes of the jump part can be expressed in terms of particular Markov processes, PDMP’s, see e.g.
[13]. For these PDMP’s, ergodicity has been established by [8] in the case of linear Hawkes processes,
and by [13] in the case of non-linear Hawkes processes with Erlang kernels. Here, we extend these
results to the general non-linear case, including also inhibitions 1 , and more importantly, we prove the
joint ergodicity as well as the β-mixing property for the couple (X, Y ) in the case of exponential kernel
functions. Finally, we give criteria ensuring that the mixing is exponential.

1.3

Main contributions and plan of the paper

We propose a general study of the longtime behavior of a jump diﬀusion process, where the jumps
are driven by a multivariate non-linear Hawkes process in dimension M, having exponential memory
kernels. Our proof of the Harris recurrence of (X, Y ) follows a well-known scheme, see e.g. [30, 31].
Firstly, we establish a local Döblin lower bound for the transition semigroup of the process (X, Y ),
based on a lower bound of the joint transition density of (X, Y ). This is the content of Theorem 3.1. The
ideas that we use to obtain this lower bound are very natural, and they have appeared independently
of our work already in [8]. They have also been exploited in [13] and in [26]: more precisely, we use M 2
consecutive jumps which are carefully chosen to produce a part of Lebesgue density for the transition
of Y. Once the jump part of the process possesses some part of Lebesgue density, we have to ensure that
this density is preserved by the stochastic ﬂow. This part of the proof relies on ﬁne support properties
of (X, Y ) and provides, as a by-product, a simulation algorithm for the process. In particular we need
to localize the possible positions of the diﬀusion part, conditionally on the jump times of the underlying
Hawkes process that have already been chosen.
In a second step, a Foster-Lyapunov condition (see Proposition 3.4) ensures the control of the return
times to some compact set K. We then use control arguments to deduce from this a precise control of
the hitting times of the set C where the transition densities are lower-bounded according to the local
Döblin lower bound. Both results together imply the positive Harris recurrence of the couple (X, Y ),
as well as the ergodic theorem. This is our ﬁrst main result, stated in Theorem 3.6.
Finally, following the steps of [29] where the ergodicity and exponential β-mixing bounds are
established for diﬀusions with jumps driven by a Lévy process and the general framework of [24], our
second main theorem 3.8 states the mixing property of the process together with a control on the rate
of convergence. To conclude, our Theorem 3.10 provides suﬃcient criteria implying the exponential
control of the β−mixing coeﬃcient of (X, Y ).
Finally, let us mention that it is possible to extend our results to multivariate diﬀusions driven by
Hawkes processes. However, the primary aim of our article is to provide a theoretical probabilistic
foundation for a statistical application where we want to deal with data describing the membrane
potential of one single neuron together with the spike trains (the point process data associated to the
subsequent times of action potentials) of its presynaptic neurons. This is why we concentrate on a
one-dimensional diﬀusion model, driven by a multivariate Hawkes process in this paper. Indeed, in this
modeling context, the joint evolution of the membrane potentials of, say, d neurons, is independent,
conditional on the evolution of the spike trains of their presynaptic neurons. This is due to the fact
that the membrane potential processes of diﬀerent neurons within a network do only interact via the
1

Notice that [7] has obtained a control of the τ -mixing coefficient in the inhibitory case – but this does not imply the
β−mixing property of the process.

3

incoming stimuli, that is, the incoming spike trains of the presynaptic neurons. In other words, their
driving Brownian motions are independent - no interaction is present in their drift nor in their diﬀusion
coeﬃcient.
Our paper is organised as follows. We introduce our model together with all necessary notation
and assumptions in Section 2. Section 2.3 provides a simulation algorithm of the process which is
interesting in its own right. In Section 3, we prove the ergodicity and ﬁnally the exponential β−mixing
of the coupled process (X, Y ).

2

Presentation of the model and first properties

2.1

The model

Throughout this paper we work on a ﬁltered probability space (Ω, F, F). We start by introducing the
jump part of our process, that is, the multivariate Hawkes process.
This process is deﬁned in terms of a collection of jump rate functions fi : R → R+ , 1 ≤ i ≤ M, and
in terms of interaction functions (also called memory kernels) hij : R+ → R, 1 ≤ i, j ≤ M, which are
measurable functions. Let moreover n(i) , 1 ≤ i ≤ M, be discrete point measures on R− satisfying that
Z
|hij |(t − s)n(j) (ds) < ∞ for all t ≥ 0.
R−

We interpret them as initial condition of our process.
Assumption 2.1. We suppose that each fi , 1 ≤ i ≤ M, is Lipschitz continuous with Lipschitz constant
γi .
Definition 2.2. A non-linear Hawkes process with parameters (fi , hij )1≤i,j≤M , and with initial condi(M )
(1)
tion n(i) , 1 ≤ i ≤ M, is a multivariate counting process Nt = (Nt , . . . , Nt ), t ≥ 0, such that
1. P−almost surely, for all i 6= j, N (i) and N (j) never jump simultaneously,
R t (i)
(i)
2. for all 1 ≤ i ≤ M, the compensator of Nt is given by 0 λs ds, where


M Z 0
M Z t−
X
X
(i)
.
hij (t − u)dn(j)
λt = fi 
hij (t − u)dNu(j) +
u
j=1

0

(2.1)

−∞

j=1

If the functions hij are locally integrable, the existence of the process (Nt )t≥0 with the prescribed
intensity (2.1) on ﬁnite time intervals follows from standard arguments, see e.g. [6] or [10].
We consider a jump diﬀusion process X = (Xt )t≥0 taking values in R, whose jumps are governed
by N. More precisely, X is solution of the stochastic diﬀerential equation
Xt = X0 +

Z

t

b(Xs )ds +
0

Z

t

σ(Xs )dWs +

0

Z

t

a(Xs− )
0

M
X

dNs(j) ,

(2.2)

j=1

where X0 is a random variable independent of W and of N. Here W is the standard Brownian motion
in dimension one, independent of the multivariate Hawkes process N having intensity (2.1).
Proposition 2.3. Suppose that Assumption 2.1 holds, that the coefficients b, σ are globally Lipschitz
continuous, that a is measurable and that the memory kernel functions hij are locally integrable. Then
equation (2.2) admits a unique strong solution.
4

Proof. Theorem 6 of [10] implies that for any T > 0, almost surely, Nt has only a ﬁnite number of jumps
on [0, T ]. We can therefore work conditionally with respect to the choice of these jumps and construct
the solution of (2.2) by pasting together trajectories of strong solutions to the diﬀusion equation (that
is, the solution of (2.2) with a(·) ≡ 0) at the successive jump times (see [20] for related ideas).
In the sequel we shall also need estimates on the transition densities of the diﬀusion process underlying (2.2). We want to be able to deal with a general drift term b that is not bounded in order to
include Ornstein-Uhlenbeck type processes to the class of models that we consider. Unbounded drift
coeﬃcients add however a substantial diﬃculty when one wishes to apply techniques from Malliavin
calculus to obtain bounds on the transition densities. Therefore, we impose the following additional
assumptions which are inspired by [14].
Assumption 2.4.

1. a is continuous.

2. b and σ are of class C 2 .
3. There exist positive constants c, q such that for all x ∈ R, |b′ (x)| + |σ ′ (x)| ≤ c and |b′′ (x)| +
|σ ′′ (x)| ≤ c(1 + |x|q ).
4. There exist strictly positive constants σ0 and σ1 such that σ0 ≤ σ 2 (x) ≤ σ1 for all x ∈ R.
Remark 2.5. We do only need the above assumption to obtain good lower bounds on the transition
densities of the underlying non-jumping diffusion process, see (3.3) below.
To study the longtime behavior of X and to ensure its ergodicity, we introduce two additional
conditions which are classical in the study of diﬀusion processes and which are derived from [16], see
also [37].
In the following, we assume we are in one of the following frames.
Assumption 2.6. Exponential frame. There exist d ≥ 0, r > 0 such that for all x satisfying
|x| > r, we have xb(x) ≤ −dx2 . Moreover, one of the two following conditions holds true.
1. For all |x| > r, 2xa(x) + a2 (x) ≤ 0.
2. For all |x| > r, |a(x)| ≤ C|x|η for some η < 1.
Assumption 2.7. Polynomial rate. There exist γ > σ1 /2, r > 0 and m ∈]2, 1 +
all x satisfying |x| > r, we have xb(x) ≤ −γ and |x + a(x)|m − |x|m ≤ 0.

2.2

2γ
[,
σ12

such that for

Markovian framework

Our study relies on the general theory of Markov processes. To be able to work within a Markovian
framework, we impose a special structure on the interaction functions and suppose that
Assumption 2.8. For all 1 ≤ i, j ≤ M,
hij (t) = cij e−αij t , cij ∈ R, αij > 0.
In this case we may introduce the auxiliary Markov process Y = Y (ij) ,
Z t
Z 0
(ij)
Yt = cij
e−αij (t−s) dNs(j) + cij
e−αij (t−s) dn(j)
s , 1 ≤ i, j ≤ M.
0

−∞

5

(2.3)

(2.4)

The intensities can be expressed in terms of sums of these Markov processes, that is, for all 1 ≤ i ≤ M,


M
X
(i)
(ij)
λt = f i 
Yt−  .
j=1

Notice that

(ij)
Y0

=

(ij)
y0

= cij

Z

0

−∞

eαij s dn(j)
s ,

(ij)

and dYt

(ij)

= −αij Yt

(j)

dt + cij dNt .

(2.5)

In particular, the process
(ij)

(Xt , Yt

, 1 ≤ i, j ≤ M )

is a Markov process. Its longtime behavior is determined on the one hand by the longtime behavior
of the underlying Hawkes process Nt and on the other hand on the one of the continuous diﬀusion
process with drift b and diﬀusion coeﬃcient σ. Note also that Nt is an autonomous process, that is, Nt
does not depend on X.

2.3

First properties of the process (X, Y ) and an associated stochastic flow.

In the sequel, we shall denote the whole process by Zt := (Xt , Yt ). It takes values in R × RM ×M .
We write (Pt )t≥0 for its associated transition semigroup and z = (x, y), y = (y (ij) )1≤i,j≤M for generic
elements of its state space.
Proposition 2.9. Grant Assumptions 2.1 and 2.4. Then the process Z is a Feller process, that is,
Pt Φ belongs to Cb (R × RM ×M ) whenever Φ ∈ Cb (R × RM ×M ).
The proof of this result follows from classical arguments, see e.g. the proof of Proposition 4.8 in
[19], or [20]. In what follows we shall give an alternative proof relying on an explicit construction of the
process Z as a stochastic flow. This construction is interesting in its own right and based on the fact
that Z is a piecewise continuous Markov process, that is, a generalization of the piecewise deterministic
Markov processes to those traveling in between successive jumps according to stochastic flows instead
of deterministic ones, see [20]. We start by giving the principal elements needed to construct this ﬂow.
The associated stochastic Brownian flow. Thanks to our assumptions on b and σ, by Theorem 4.2.5
of [25], there exists a unique stochastic ﬂow of homeomorphisms Φt (x) for 0 ≤ t < ∞, x ∈ R, such that
Z t
Z t
σ(Φu (x))dWu .
(2.6)
b(Φu (x))du +
Φt (x) = x +
0

0

In particular, we have that
(t, x) 7→ Φt (x) is continuous (0≤t<∞, x ∈ R).
The stochastic ﬂow Φ describes the evolution of X in between successive jumps of X (or, equivalently,
of N ).
The associated deterministic flow. In between successive jump events of N, the process Y evolves
according to the deterministic ﬂow
(ij)

(ij)

ϕt (y) = (ϕt (y))1≤i,j≤M , where ϕt (y) = e−αij t y (ij) , 1 ≤ i, j ≤ M.
We are now ready to give the simulation algorithm for Z.
6

(2.7)

Simulation algorithm for Z. We propose a simulation algorithm for Z for any family of starting
conﬁgurations z ∈ K1 × K2 , where K1 ⊂ R, K2 ⊂ RM ×M are compact sets. The ﬁrst step is to
construct an upper bound N̄t on the number of jumps of Z, that is, of N, during some ﬁnite time
interval [0, t]. To do so, observe that by Lipschitz continuity of fi with Lipschitz constant γi , we have
for 1 ≤ i ≤ M ,
fi (x) ≤ fi (0) + γi |x|.
Let
γ̄ := max γi , c̄ :=
i

sup
1≤i,j≤M

(2.8)

|cij |.

Consider now the one-dimensional auxiliary linear Hawkes process Nt∗ having intensity λ∗t , t ≥ 0,
where
M
M
X
X
λ∗0 := sup sup
e−αij t y (ij) )
fi (
y∈K2 t≥0 i=1

and

λ∗t = λ∗0 + M γ̄c̄
N∗

Z

t−

0

j=1

∗
, t ≥ 0.
dNu∗ = λ∗0 + M γ̄c̄Nt−

Observe that
is a one dimensional linear Hawkes process with memory kernel h̄(t) = M γ̄c̄1R+ (t).
Obviously, for all t ≥ 0,
M
X
(i)
Nt ≤ Nt∗ .
i=1

Moreover, for all t ≥ 0, Nt∗ < ∞ almost surely. In what follows, we shall write T1∗ < T2∗ < . . . < Tn∗ < . . .
for the successive jump times of N ∗ .
We work conditionally on the realization of N ∗ on [0, t], that is, on the event {Nt∗ = n}, and on a
realization of the associated jump times 0 < t1 < t2 . . . < tn < t. Our goal is to construct a version of
Z, conditionally on these choices, which is continuous in the starting point z. This construction relies
on the classical thinning method, also known as acceptance-rejection method.
During this construction, we choose successively random variables U1 , . . . , Un taking values in
{0, 1, . . . , M } and deﬁne a process zs = zs (z, tn1 , U1n ), depending on these choices, for 0 ≤ s ≤ t.
Here, tn1 = (t1 , . . . , tn ) denotes the choices of the successive jump times and U1n = (U1 , . . . , Un ) the
sequence of indices of jumping particles. This process is deﬁned recursively as follows. Firstly, we put
zs = (xs , ys ) = (Φs (x), ϕs (y)) for all 0 ≤ s < t1 .
Then, conditionally on yt1 − = y1 , we choose a random variable U1 ∈ {0, 1, . . . , M } with law q(y1 , t1 , ·),
where
P
M
X
fi ( j y (ij) )
q(y, t, {i}) =
q(y, t, {i}).
(2.9)
,
1
≤
i
≤
M,
q(y,
t,
{0})
=
1
−
λ∗t
i=1

U1 gives the label of the particle (or component) that will jump at time t1 , if U1 = 0, no jump happens
at this time. More precisely, on {U1 ≥ 1}, we put
(ij)

(ij)

xt1 := x1 + a(x1 ), yt1 := y1

+ cij 1{U1 =j} , for all 1 ≤ i, j ≤ M,

and zt1 := z1 on {U1 = 0}.
Then we put
xs = Φs−t1 (xt1 ), ys = ϕs−t1 (yt1 ) for all t1 ≤ s < t2 ,

7

and we proceed iteratively by choosing, conditionally on yt2 − = y2 , a random variable
U2 ∼ q(y2 , t2 , ·),
and so on. Finally, we obtain a terminal value xt = Φt−tn (xtn ) and yt = ϕt−tn (ytn ). It is easy to check
that
L(zt (z, tn1 , U1n )) = L(Zt |Nt∗ = n, T1∗ = t1 , . . . , Tn∗ = tn ).
The important point is that the above construction ensures the continuity of the application
z 7→ zt (z, tn1 , U1n ).
Alternative proof of Proposition 2.9. Noticing that the law of N ∗ does not depend on the starting point
z but only on an upper bound of the associated intensities, the above construction implies that for any
Φ ∈ Cb (R × RM ×M ), the mapping
K ∋ z 7→ Pt Φ(z) ∈ R
is continuous, implying the assertion of Proposition 2.9. Indeed, we can write
Z
X
∗
L(T1∗ , . . . , Tn∗ |Nt∗ = n)(dt1 , . . . , dtn )
Pt Φ(z) =
P(Nt = n)
n≥0

[0,t]n

M
n X
X

P(U1 = u1 , . . . , Un = un |T1 = t1 , . . . , Tn = tn , Z0 = z)EW Φ(zt (z, un1 )),

i=1 ui =0

where the last expectation EW is only taken with respect to the underlying Brownian motion W.
Suppose now that (z k )k ⊂ K1 × K2 is a sequence of initial conﬁgurations converging to z as k → ∞.
Then, by the structure of (2.9),
P(U1 = u1 , . . . , Un = un |T1 = t1 , . . . , Tn = tn , Z0 = z k ) →
P(U1 = u1 , . . . , Un = un |T1 = t1 , . . . , Tn = tn , Z0 = z),
as k → ∞, by continuity of fi , 1 ≤ i ≤ M, and of z 7→ zs (z, tn1 , U1n ), for all s ≤ t. Moreover, using
dominated convergence, EW Φ(zt (z k , un1 )) → EW Φ(zt (z, un1 )), as k → ∞, implying that Pt Φ(z k ) →
Pt Φ(z), as k → ∞, where we have used dominated convergence once more.

3

Ergodicity of the process (X, Y )

In this section, we start proving the positive Harris recurrence of Zt = (Xt , Yt ) using the regeneration
technique.

3.1

A Döblin type lower bound

The following theorem is the main result of this section. It states a local Döblin lower bound for the
transition semigroup of the process, which is the main ingredient towards ergodicity of the process
(Zt ).
Theorem 3.1. Grant Assumptions 2.4 and 2.8 and suppose moreover that fi (x) > 0 for all 1 ≤ i ≤ M,
for all x ∈ R. Then there exists T > 0 such that for all z ∗ = (x∗ , y ∗ ) ∈ R × RM ×M and for all x∗∗ ∈ R
the following holds. There exist R > 0, open sets I1 ⊂ R and I2 ⊂ RM ×M with strictly positive Lebesgue
measure such that
x∗∗ ∈ I1 ,
(3.1)
8

and a constant β ∈ (0, 1), depending on I1 , I2 , R and the coefficients of the system with
PT (z, dz ′ ) ≥ β1C (z)ν(dz ′ ),

(3.2)

where C = BR (z ∗ ) is the (open) ball of radius R centred at z ∗ , and where ν is the uniform probability
measure on I1 × I2 .
Remark 3.2. 1. Together with a Lyapunov argument implying that the process Z comes back to the
set C infinitely often, the above result will imply the ν−irreducibility of the sampled chain (ZkT )k≥0 .
We want to stress that the above construction implies that for any given x∗∗ ∈ R and some ε > 0
we can construct ν such that Bε (x∗∗ ) lies in the support of the projection on the x−variable of ν. Of
course, this property is related to the support properties of the underlying diffusion process, granted by
Assumption 2.4. It will imply that the invariant density of X is bounded away from 0 on each compact
set, see Proposition 3.7 below.
2. A lower bound of the type (3.2) is trivial if we are only interested in the transitions of the process
X. Indeed, in this case it is sufficient to consider the event where no jump has appeared up to time T
and to use known lower bounds on the transition densities of the diffusion part. However, since X is
not Markov on its own, we do need to work with the couple of processes (X, Y ), and therefore have to
establish such lower bounds for the joint transition of X and Y.
The main idea of the proof is to use the jump noise of M 2 successive jumps of the underlying Hawkes
process to create ﬁrstly a Lebesgue density for the process Y. Such ideas have already been exploited in
[8] and in [13]. The important second step is then to use density estimates of the underlying diﬀusion
to prove that a joint Lebesgue density of (XT , YT ) exists which is strictly lower-bounded on C.
The proof is done in several steps which are the subject of the next subsection.

3.2

Some useful properties of the underlying stochastic flow and proof of Theorem
3.1

We start by collecting useful properties of the stochastic ﬂow governing the evolution of X in between
successive jumps.
Transition densities. Due to our assumptions on b and σ, the stochastic ﬂow Φt (x) given by Equation
(2.6), possesses a transition density x 7→ pt (x, y) with explicit lower bounds. More precisely, Proposition
1.2 of [14] implies that, for some suitable constants c, C,
2 /t

c−1 t−1/2 e−C(x−y)

1

2

2 /t

e−Ctx ≤ pt (x, y) ≤ ct−1/2 e− C (x−y)

2

eCtx .

(3.3)

Here, the constants c and C do only depend on the coeﬃcients b and σ. 2
Support properties. We will use the control theorem which goes back to Stroock and Varadhan
(1972) [35], see also Millet and Sanz-Sole (1994) [32], Theorem 3.5. For some time horizon T1 < ∞
which is arbitrary but ﬁxed, write H for the Cameron-Martin space of measurable functions h : [0, T1 ] →
RT
Rt
R having absolutely continuous components h(t) = 0 ḣ(s)ds with 0 1 (ḣ)2 (s)ds < ∞. For x ∈ R and
h ∈ H, consider the deterministic ﬂow
(h)

(h)

(h)

(h)

(ϕt (x))t≥0 solution to dϕt (x) = b̃(ϕt (x))dt + σ(ϕ(h)t (x))ḣ(t)dt, with ϕ0 (x) = x,

(3.4)

on [0, T1 ]. In the above formula (3.4), b̃ is Stratonovich drift given by
1
b̃(x) = b(x) − σ(x)σ ′ (x).
2
2

It is possible to replace our Condition 2.4 by any other condition ensuring that pt (x, y) is strictly lower bounded on
compact sets for any t > 0 .

9

Denote by QTx1 the law of the solution (Φt (x))0≤t≤T1 . Then for any x ∈ R and h ∈ H,


(h)
ϕt (x)

|t∈[0,T1 ]



∈ supp QTx1 .

(3.5)

We are now able to give the proof of Theorem 3.1.

Proof. We suppose without loss of generality that for all 1 ≤ j ≤ M,
cij 6= 0 for all i, αij 6= αkj , for all 1 ≤ i, k ≤ M, i 6= k.

3

In what follows, we impose ﬁrst M consecutive jumps of N (1) , followed by M jumps of N (2) etc up
to M consecutive jumps of N (M ) , and we suppose that they all happen before time T. Then we can
lower-bound, for all A ∈ B(R), B ∈ B(RM ×M ), z ∈ R × RM ×M ,

(i)
PT (z, A × B) ≥ Ez 1A (XT )1B (YT ), NT = M, ∀1 ≤ i ≤ M,
(1)

T1

(1)

< T2

(2)

(1)

< . . . < TM < T1

(2)

(M )

< . . . < TM < . . . < T1

(M )

< . . . TM

(i)


<T ,

where Tk , k ≥ 1, are the successive jump times of N (i) , 1 ≤ i ≤ M. In what follows we shall write
(i)

AT := {NT = M, ∀1 ≤ i ≤ M,
(1)

T1

(1)

< T2

(2)

(1)

< . . . < TM < T1

(2)

(M )

< . . . < TM < . . . < T1

(M )

< . . . TM

< T }.

Step 1. We ﬁrst deal with the process Yt . This part of the proof follows well-known arguments that
have been developed independently from our work in [8], and that we have also already used in [13]
and [26]. We reproduce the main arguments here since the second step will be a control of the diﬀusion
part conditionally on the results of this ﬁrst step.
Recall that in between successive jump events of N, the process Y evolves according to the deterministic ﬂow ϕt (y) introduced in (2.7) above. Thus, on the event AT , starting from Y0 = y ∈ RM ×M ,
we ﬁrst let the ﬂow ϕ evolve starting from y up to some ﬁrst jump time t1 . At that jump time each
particle having index (i1) gains an additional value ci1 . We then successively choose the following
inter-jump waiting times t2 , . . . , tM 2 under the constraint t1 + . . . + tM 2 < T. We write
s1 = T − t1 , s2 = T − (t1 + t2 ), . . . , sM 2 = T − (t1 + . . . + tM 2 ).
(ij)

Conditionally on Y0 = y, the successive choices of s = (s1 , . . . , s2M ) as above, the position of YT
is given by
γ (ij) (y, s) = e−αij T y (ij) + cij [e−αij sjM −M +1 + . . . + e−αij sjM ].
In what follows we work at ﬁxed y and we write
γy : s 7→ γ(y, s) = (γ (11) , . . . , γ (M 1) , γ (12) , . . . , γ (M 2) , . . . , γ (1M ) , . . . , γ (M M ) )(y, s).

We will use the jump noise which is created by the M 2 jumps, i.e., we will use a change of variables
on the account of s1 , . . . , sM 2 . Therefore, let
∂γy (s) i
∂γy (s) h ∂γy (s)
=
,...,
∂s
∂s1
∂sM 2
3

(i+k),j

Otherwise, if αij = αkj , we introduce the new process Yt

10

:= Ytij + Ytkj which is Markov again.

be the Jacobian matrix of the the map s 7→ γy (s). This matrix does not depend on the initial position
y. Indeed, one easily ﬁnds that
 (1)

C
0
··· 0
0
 0
C (2) 0 · · ·
0 
∂γy (s)


= C(s) =  .
 (s),
.
.
..
..
..
∂s
 ..
.
··· 
0
···
0
0 C (M )
where for each 1 ≤ j ≤ M , C (j) (s) is the M × M matrix

c1j (α1j )−1 e−α1j sjM −M +1
 c2j (α2j )−1 e−α2j sjM −M +1

(j)
C (s) = − 
..

.
cM j (αM j )−1 e−αM j sjM −M +1

given by
...
...
..
.

c1j (α1j )−1 e−α1j sjM
c2j (α2j )−1 e−α2j sjM
..
.

. . . cM j (αM j )−1 e−α2j sjM





.


We have to prove that each C (j) (s) is invertible. This is diﬃcult for general choices of s. But if we choose
t0 such that M 2 t0 < T and then s∗1 = M 2 t0 , s∗2 = (M 2 − 1)t0 , . . . , s∗M 2 = t0 such that sk − sk+1 = t0
for all 1 ≤ k < M 2 , then
!
M
Y
∗
cij (αij )−1 e−αij sjM det V (j) (t0 ),
det C (j)(s∗ ) =
i=1

where





V (j) (t0 ) = 


e−(M −1)α1j t0
e−(M −1)α2j t0
..
.

...
...
..
.

e−2α1j t0
e−2α2j t0
..
.

e−α1j t0
e−α2j t0
..
.

1
1
..
.

e−(M −1)αM j t0

. . . e−2αM j t0

e−αM j t0

1





.


Therefore, det V (j) (t0 ) is a Vandermonde determinant which is diﬀerent from 0 since by assumption
all e−αij t0 and e−αkj t0 are diﬀerent, for all i 6= k.
By continuity we therefore have that for any choice of t0 < T /M 2 there exists ε > 0 such that for
∂γy (s)
is invertible.
all s ∈ Bε (s∗ ), ∂s
It will be proved now that this uniform invertibility of the Jacobian matrix of the map s 7→ γy (s)
implies the ﬁrst part of inequality (3.2). For that sake, we shall also need the following notation. For
each couple (y, s), we write y0 = y, and then deﬁne recursively for all jM − M + 1 ≤ k ≤ jM, where
j varies between 1 ≤ j ≤ M,
(iℓ)
(iℓ)
(3.6)
yk = ϕsk−1 −sk (yk−1 ) + cij 1{ℓ=j} ,
for all 1 ≤ i, ℓ ≤ M, where we put s0 = T.
The sequence y1 , . . . , yM 2 corresponds to the positions of the process Y right after the successive
jumps, starting from the initial location y ∈ RM ×M , induced by the inter-jump waiting times T −
s1 , s1 − s2 , . . . , sM 2 −1 − sM 2 which are determined by s.
Introduce now for each y ∈ RM ×M the total jump rate


M
X
X
fi 
y (ij) 
f¯(y) :=
i=1

j

and for each t ≥ 0, the survival rate

e(y, t) = exp

n

−

Z

11

t
0

 o
f¯ ϕs (y) ds .

(3.7)

We deﬁne for each couple (y, s) (recall that s0 = T ),


jM
−1
M
Y
Y
fj (ϕsk −sk+1 (yk )) e(yk , sk − sk+1 ) e(yM 2 , sM 2 ).
qy (s) = 

(3.8)

j=1 k=jM −M

Since f¯(y) > 0 for all y ∈ RM ×M and from the deﬁnition of e(·, ·), we deduce that for any couple
(y ∗ , s∗ ) there are neighborhoods Ws∗ and Uy∗ of s∗ and y ∗ respectively such that
inf

(y,s)∈Uy ∗ ×Ws∗
∂γ

(3.9)

qy (s) > 0.

∗ (s∗ )

is invertible. By Lemma 6.2 of [4], there exist an
Let us now ﬁx (y ∗ , s∗ ) such that the matrix y∂s
open neighborhood BR (y ∗ ) of y ∗ , an open set I2 ⊂ RM ×M , and for any y ∈ BR (y ∗ ), an open set Wy
such that

W y → I2
γ̃y (s) :
s 7→ γy (s)
is a diﬀeomorphism, with Wy ⊂ Ws∗ , and also
inf

inf

y∈BR (y ∗ ) s∈Wy

 ∂γ (s) −1
y
det
> 0.
∂s

(3.10)

Reducing (if necessary) R, we may assume also that BR (y ∗ ) ⊂ Uy∗ . Thus we have that by (3.9) and
(3.10),
 ∂γ (s) −1
y
> 0.
(3.11)
β1 := inf
inf qy (s) det
∂s
y∈BR (y ∗ ) s∈Wy

Once we have done all these steps we can conclude with the following preliminary result. For any
measurable B ∈ B(RM ×M ) and for any z = (x, y) such that y ∈ BR (y ∗ ), using the change of variables
y = γ̃y (s), we obtain the lower bound



(2)
(M )
(1)
(1)
(i)
Ey 1B (YT ), NT = M, ∀1 ≤ i ≤ M, T1 < . . . < TM < T1 < . . . < TM < T
Z
Z
dy1 . . . dyM 2 . (3.12)
qy (s)1B (γ̃y (s))ds1 . . . dsM 2 ≥ β1
≥
I2 ∩B

Wy

This would establish the desired result if we were only interested in the autonomous process Y.
Step 2. We now deal with the process X. Of course, we still work conditionally on the choice of
s1 , . . . , sM 2 of the ﬁrst step. Analogously to (3.6) we therefore introduce the successive jump positions
of the process X which are given by x0 = x and then for all 1 ≤ k ≤ M 2 ,
xk = Φsk−1 −sk (xk−1 ) + a(Φsk−1 −sk (xk−1 )),

(3.13)

where s0 = T as before.
Conditionally on X0 = x, Y0 = y, the successive choices of s = (s1 , . . . , sM 2 ) as above, the position
of XT is then given by
Γ(z, s) = ΦsM 2 (xM 2 ),
where z = (x, y). Notice that xM 2 depends on the choices of s1 , . . . , sM 2 and of course on the evolution
of the stochastic ﬂow between the successive jump times.

12

Step 3. Therefore, conditioning with respect to XT −sM 2 = xM 2 , we obtain
PT (z, A × B) ≥ Ez (1A (XT )1B (YT ), AT ) x

Z
Z
psM 2 (xM 2 , u)du ds1 . . . dsM 2 , (3.14)
qy (s)1B (γ̃y (s)) E
≥
A

Wy

where psM 2 (xM 2 , u) is the transition density of (3.3).
Notice that in the last line, expectation E is taken with respect to Brownian motion only, that is,
with respect to the law of XT −sM 2 under the Wiener measure, conditionally on the choices s1 , . . . , sM 2 .
The lower bound estimate given in (3.3) implies that for ﬁxed sM 2 and xM 2 , u 7→ psM 2 (xM 2 , u)
is lower bounded in small neighborhoods of xM 2 . Therefore, in what follows we need to localize the
possible positions of xM 2 , conditionally on the choices of the jumps times s1 , . . . , sM 2 .
Step 4. Localization of xM 2 .
We apply the support theorem, that is, (3.5), to our process Xt in between the successive jump
times 0, T1 := t1 , T2 := t1 +t2 , . . . , TM 2 := t1 +. . . tM 2 , by choosing on each time interval [Tn , Tn+1 [, n =
0, . . . , M 2 − 1, the control function h ≡ 0. Consequently, introducing
(0)

(0)

(0)

(0)

x̃1 := ϕt1 (x) + a(ϕt1 (x)), . . . , x̃M 2 := ϕs

M 2 −1 −sM 2

(x̃M 2 −1 ) + a(ϕs

M 2 −1 −sM 2

(x̃M 2 −1 )),

there exists an open neighborhood Ux̃M of x̃M 2 , such that
P(XT −sM 2 ∈ Ux̃M 2 ) > 0.
Notice that x̃M 2 is a continuous function of the starting point x and of s; that is, x̃M 2 = F (x, s) for
some continuous function F. This implies that for any starting point x∗ and for R > 0 suﬃciently
small, reducing Ws∗ if necessary, there exists a compact K = K(x∗ , s∗ ) such that F (x, s) ∈ K for all
x ∈ BR (x∗ ) and for all s ∈ Ws∗ , whence
inf

inf P(XT −sM 2 ∈ J1 ) > 0,

x∈BR (x∗ ) s∈Ws∗

where
J1 =

[

Ux̃M 2 .

x̃M 2 ∈K

Notice that J1 has compact closure.
Let now x∗∗ ∈ R be arbitrarily chosen. The lower bound of (3.3) implies that there exists an open
interval I1 ∋ x∗∗ , such that
inf
psM 2 (x, y) > 0.
x∈J1 ,y∈I1 ,s∈Ws∗

Therefore,
β2 :=

inf

inf

inf

inf

x∈BR (x∗ ) y∈BR (y ∗ ) s∈Wy u∈J1 ,v∈I1

psM 2 (u, v)Px (XT −sM ∈ J1 ) > 0.

(3.15)

Therefore, coming back to (3.14), for all z ∈ BR (x∗ , y ∗ ),


(1)
(i)
(1)
(M )
PT (z, A × B) ≥ Ez 1A (XT )1B (YT ), NT = M, ∀1 ≤ i ≤ M, T1 < T2 < . . . < TM < T


Z
Z
qy (s)1B (γ̃y (s)) E 1{XT −s 2 ∈J1 }
psM 2 (XT −sM 2 , u)du ds1 . . . dsM 2
≥
M

Wy

Z



A

Z



inf psM 2 (x, u)du ds1 . . . dsM 2
qy (s)1B (γ̃y (s)) E 1{XT −s 2 ∈J1 }
M
A∩I1 x∈J1
Z
qy (s)1B (γ̃y (s))ds1 . . . dsM 2
≥ β2 λ(A ∩ I1 )

≥

Wy

≥ β2 λ(A ∩

Wy
I1 )β1 λM ×M (B

∩ I2 ),
13

where we have ﬁnally applied (3.12), and where λ and λM ×M denote the Lebesgue measure on R,
RM ×M , respectively. This implies the desired result putting
β := β1 β2 λ(I1 )λM ×M (I2 ) and ν := UI1 ×I2 ,
the uniform probability law on I1 × I2 .

3.3

A Foster-Lyapunov type condition

In order to prove the positive Harris recurrence of the process Z, we need of course a stability condition
which is a Lyapunov type condition. Notice that the process Zt = (Xt , Yt ) has the following extended
generator, deﬁned for suﬃciently smooth test functions g by
M
X

1
αij y (ij) ∂y(ij) g(x, y) + ∂x g(x, y)b(x) + σ 2 (x)∂x2 g(x, y)
2
i,j=1
!
M
M
X
X
(jk)
fj
[g (x + a(x), y + ∆j ) − g(x, y)] ,
y
+

AZ g(x, y) = −

j=1

k=1

with (∆j )(il) = cij 1{j=l} for all 1 ≤ i, l ≤ M.
To obtain stability we ﬁrst introduce the following classical stability assumption for Hawkes processes. Recall that γi denotes the Lipschitz constant of the rate function fi .
Assumption 3.3. Let H be the M × M −matrix with entries Hij = γj
spectral radius satisfies
ρ := ρ(H) < 1.

|cij |
αij , 1

≤ i, j ≤ M. Then its

Under the above stability condition, let κ ∈ RM
of H, associated to the
+ be a left eigenvector
P
eigenvalue ρ and having non-negative components, that is, for all j, i κi Hij = ρκj ≥ 0. Such a vector
κ exists thanks to the theorem of Perron-Frobenius. Following [8], we introduce a Lyapunov function
by deﬁning mij = ακiji for all 1 ≤ i, j ≤ M and V : R × RM ×M → R+ by
P

V (x, y) = V1 (x) + e

i,j

mij |y (ij) |

(3.16)

,

where V1 : R → R+ will be chosen in the sequel. Notice that V (x, y) ≥ 1 for all x, y.
Proposition 3.4. Grant Assumptions 2.4, 2.6 (Exponential frame) and 3.3. Let V1 (x) = x2 . Then
there exist positive constants d1 , d2 such that the following Foster-Lyapunov type drift condition holds
AZ V ≤ d1 − d2 V.

(3.17)
P

(ij) |

Proof. We write V (x, y) = V1 (x) + V2 (y), where V1 (x) = x2 , V2 (y) = e i,j mij |y
Z
AZ
1 V + A2 V, where
!
M
M
X
X
2
fj
y (jk) [(x + a(x))2 − x2 ]
AZ
1 V (x, y) = 2xb(x) + σ (x) +
j=1

, and AZ V =

k=1

Z
Z
is the diﬀusion part and AZ
2 V = A V − A1 V is the jump part of the generator. The arguments of
the proof of Proposition 4.5 of [8] imply that
Z
AZ
2 V (x, y) = A2 V2 (y) ≤ −c1 V2 (y) + c2 1K1 (y),

14

(3.18)

where
c1 , c2 > 0 and where K1 ⊂ RM ×M is some compact. Moreover, writing for short f¯(y) =
P
P
(ij) ) for the total jump rate,
i fi ( j y
2
2 ¯
AZ
1 V (x, y) = 2xb(x) + σ (x) + (2xa(x) + a(x) )f (y).

(3.19)

Thanks to Assumption 2.7 and bound of σ 2 from Assumption 2.4,
2xb(x) + σ 2 (x) ≤ −c3 x2 + c4 1K2 (x),

(3.20)

where K2 ⊂ R is a compact set. Now, suppose that Assumption 2.6 is satisﬁed. Then for all |x| > r,
(2xa(x) + a(x)2 )f¯(y) ≤ 0 (recall that all f¯ is non-negative) implying that
2
¯
AZ
1 V (x, y) ≤ −c3 x + c4 1K2 (x) + c5 f (y).

This implies (3.17) since
f¯(y) ≤ c6 + c7

X

|y (ij) | ≤ c6 + c̃7 log(V2 (y))

i,j

which is thus negligible with respect to the negative term −c1 V2 (y) of (3.18).
If only Assumption 2.7 holds, then we upper bound the jump part of (3.19) by
(2xa(x) + a(x)2 )f¯(y) ≤ C f¯(y) + C|x|1+η f¯(y).
Choose 1 < p < 2 and q > 2 such that (1 + η)p < 2 and
|x|1+η f¯(y) ≤
Since (1 + η)p < 2, the ﬁrst term

1
p

+

1
q

= 1. Then

1 p(1+η) 1 ¯q
|x|
+ f (y).
p
q

1
C |x|(1+η)p
p

will again be negligible with respect to the negative term −c3 x2 of (3.20). Finally, the second term
¯ + C 1 f¯q (y) is treated as previously. This concludes our proof.
C f(y)
q

Proposition 3.5. Grant Assumptions 2.4, 2.7 (Polynomial frame) and 3.3. Let V1 (x) = 1 + |x|m and
α = 2/m ∈]0, 1[. Then there exist positive constants d1 , d2 such that the following Foster-Lyapunov type
drift condition holds
AZ V ≤ d1 − d2 V 1−α .
(3.21)
Proof. Using the same arguments as in the proof of Proposition 3.4, we have that
Z
AZ
2 V (x, y) = A2 V2 (y) ≤ −c1 V2 (y) + c2 1K1 (y).

Moreover, for all |x| ≥ r, since |x + a(x)|m − |x|m ≤ 0,
M

X
1 2
′′
′
AZ
V
(x,
y)
=
b(x)V
(x)
+
fj
σ
(x)V
(x)
+
1
1
1
2
j=1

M
X
k=1

!

y (jk) [|x + a(x)|m − |x|m ]

1
′′
≤ b(x)V1′ (x) + σ 2 (x)V1 (x).
2
A standard calculus, see e.g. [37] or [28], shows that, for suitable constants e1 , e2 > 0,
1
′′
b(x)V1′ (x) + σ 2 (x)V1 (x) ≤ e1 − e2 V1 (x)1−α .
2
Using that V1 (x) ≥ 1 such that (V1 (x) + V2 (y))1−α ≤ V1 (x)1−α + (1 − α)V2 (y) ≤ V1 (x)1−α + V2 (y), we
deduce from this the drift condition (3.21) as in the proof of Proposition 3.4.
15

3.4

Harris recurrence of Z

We do now possess all ingredients to obtain our main results.
Theorem 3.6. Grant Assumptions 2.4, 2.6, 2.8 and 3.3 and suppose that for all 1 ≤ i ≤ M, fi (x) > 0
for all x ∈ R. Then (Zt )t≥0 is positive Harris recurrent with unique invariant measure π. In particular,
for any starting point z and any positive measurable function g : R × RM ×M → R+ , as T → ∞,
Pz −almost surely,
Z
1 T
g(Zs )ds → π(g).
T 0
Proof of Theorem 3.6. 1) We ﬁx any x∗ ∈ R and we wish to apply Theorem 3.1 with y ∗ = 0 and
x∗ = x∗∗ . Let R be the associated radius.
By Proposition 3.4 or Proposition 3.5, we know that for a suitable compact set K = K1 × K2 , with
K1 ⊂ R, K2 ⊂ RM ×M , Z comes back to K inﬁnitely often almost surely. Moreover,
sup
y∈K2 ,t≥0

kϕt (y)k1 := F < ∞ and

sup kϕt (y)k1 → 0

y∈K2

as t → ∞, by the explicit form of the ﬂow in (2.7). Therefore there exists t∗ such that ϕt (y) ∈ BR (0)
for all t ≥ t∗ , for all y ∈ K2 .
Applying once more the support theorem for diﬀusions and observing that σ is strictly positive,
Equation (3.5) implies that
inf P(Φt∗ +s (x) ∈ BR (x∗ ), 0 ≤ s ≤ 2T ) > 0

x∈K1

and thus
inf Pz (Xt∗ +s ∈ BR (x∗ ), Yt∗ +s ∈ BR (0), 0 ≤ s ≤ 2T ) > 0.

z∈K

Consequently, using a conditional version of the Borel-Cantelli lemma, the sampled Markov chain
(ZkT )k∈N visits BR (x∗ , 0) inﬁnitely often almost surely.
2) The standard regeneration technique (see e.g. [27]) allows to conclude that (ZkT )k∈N and therefore
(Zt )t are Harris recurrent. This concludes the proof.
The following by-product of the above result will prove to be useful when dealing with statistical
inference within this new model class.
Proposition 3.7. Grant all assumptions of Theorem 3.6 andRwrite π X for the projection of the invariant measure π onto the X−coordinate, that is, π X (dx) = RM ×M π(dx, dy). Then π X possesses a
Lebesgue density which is bounded away from zero on each compact of R.
Proof. Let A ∈ B(R). Then for any t > 0,
π X (A) =

Z

R×RM ×M

(j)

π(dz)Ez [1A (Xt )].

(3.22)

Let Lt := sup{s ≤ t : ∃j : ∆Ns = 1} be the last jump time of the process before time t, Lt = 0 if
there is no such jump. Then by Fubini,
Z
Ez [pt−Lt (XLt , y)]dy,
Ez [1A (Xt )] =
A

16

where pt (x, y) is the transition density of (3.3). This implies the existence of the density π X (x) which
is given by
Z
π(dz)Ez [pt−Lt (XLt , x)]
π X (x) =
R×RM ×M

for any t > 0.
Notice that we do not dispose of any regularity results of π X (x) with respect to x. Indeed, the
upper bound in (3.3) does not allow to conclude that the almost sure continuity in x of pt−Lt (XLt , x)
survives the integration π(dz)Ez (. . .).
We are however able to prove that π X is lower bounded on compacts K ⊂ R. For that sake, ﬁx any
x∗∗ ∈ K and apply (3.2) to (x∗ , y ∗ ) ∈ supp(π) such that π(BR (z ∗ )) = π(C) > 0 and to x∗∗ . Then for
any measurable A ⊂ I1 = I1 (x∗∗ ), applying the lower bound of (3.2) to (3.22) and taking t = T,
Z
Z
1
X
π (x)dx ≥ βπ(C)
dx
λ(I1 ) A
A
implying that
inf π X (x) ≥ βπ(C)

x∈I1

1
> 0.
λ(I1 )

Therefore we have just shown that for all x∗∗ ∈ K, there exists an open interval I1 = I1 (x∗∗ ) containing
x∗∗ ∈ I1 such that π X is strictly lower bounded on I1 . Since we can cover the compact K by a ﬁnite
collection of such open intervals I1 (x∗∗ ), this implies the desired lower bound of π X on compacts.
In the sequel, following [31], in any of the two frames (Assumption 2.6 or 2.7) and for the choice of
V as in Proposition 3.4 or Proposition 3.5, we introduce
kµkV := sup |µ(g)|, kµkT V := sup µ(g).
g:|g|≤V

g:|g|≤1

It is now straightforward to obtain our second main result.
Theorem 3.8 (Ergodicity). Grant all assumptions of Theorem 3.6. Then there exist c1 , c2 > 0 such
that for all z ∈ R × RM ×M , under Assumption 2.6,
kPt (z, ·) − πkV ≤ c1 V (z)e−c2 t ,
and under Assumption 2.7,

1

kPt (z, ·) − πkT V ≤ c1 V (z)t α −1 ,

(3.23)
(3.24)

where α is as in Proposition 3.5.
Proof. The sampled chain (ZkT )k≥0 is Feller according to Proposition 2.9. Moreover it is ν−irreducible,
where ν is the measure introduced in Theorem 3.1, associated with the point (x∗ , 0) and x∗∗ , for any
choice of x∗ , x∗∗ ∈ R, used in the proof of Theorem 3.6. Since ν is the uniform measure on some open
set of strictly positive Lebesgue measure, the support of ν has non-empty interior. Theorem 3.4 of [30]
implies that all compact sets are ‘petite’ sets of the sampled chain. Under Condition 2.6, the Lyapunov
condition established in Proposition 3.4 allows to apply Theorem 6.1 of [31] which implies the assertion
in the exponential frame. In the polynomial frame, the assertion follows from Theorem 3.2 of [12] or
from Theorems 1.19 and 1.23 in [24].

17

Remark 3.9. In the above Theorem 3.8, we do only treat two cases for the rate of convergence to
equilibrium: the exponential and the polynomial one. Using slightly different Lyapunov functions, we
could also deal with more general sub-exponential rates of convergence, as they have for example been
considered in Theorem 1.20 in [24]. We do not detail these calculations here since we are mostly
interested in exponential rates of convergence. Finally, notice that it is also possible to interpolate
between the total variation norm considered in (3.24) and the weighted total variation norm k · kV
considered in (3.23), however at the cost of slower rates of convergence. Details can be found in the
very instructive paper [12].

3.5

Exponential β-mixing for Z = (X, Y ).

It is now easy to deduce from the above results the exponentially β-mixing property of the process,
under Condition 2.6. Recall that the β−mixing coeﬃcient of Z is given by
Z
βZ (t) = sup kPt (z, ·) − µPs+t (·)kT V µPs (dz),
s≥0

where µ = L(Z0 ) is the law of the initial conﬁguration and where
kµkT V := sup µ(g)
g:|g|≤1

denotes the total variation distance. Notice that if µ = π, then the process is in its stationary regime,
and
Z
βZ (t) = kPt (z, ·) − πkT V π(dz).

Theorem 3.10. Grant all assumptions of Theorem 3.6 and suppose that Condition 2.6 holds. Then Z
is exponentially β−mixing, that is, there exist constants K, θ > 0 such that for any initial law µ with
µ(V ) < ∞,
βZ (t) ≤ Ke−θt .
R
Proof. Suppose ﬁrstly that µ = π. Then Theorem 4.3 of [31] implies that V dπ < ∞ such that we are
able to integrate (3.23) against π(dx) to obtain
βZ (t) ≤ c1 π(V̄ )e−c2 t .
Putting K := c1 and θ = c2 , this implies the result in this case.
In order to deal with the general non-stationary process, we apply Lemma 3.9 of [29] with h = V̄ ,
δ(t) = c1 e−c2 t and
κ = sup E(V̄ (Zs )),
s≥0

to deduce that
βZ (t) ≤ 2c1 κe−c2 t .
Putting K := 2c1 κ and θ = c2 , this implies the result, if we have already shown that κ is ﬁnite. This
last fact follows immediately from (3.17), following the ﬁrst lines of the proof of Theorem 6.1 of [31].
Indeed, we have by Dynkin’s formula that
eαt Ez (V (Zt )) ≤ V (z) +

β αt
e ,
α

implying that

β
.
α
Integrating this last inequality with respect to µ(dz) implies the result.
Ez (V (Zt )) ≤ e−αt V (z) +

18

References
[1] D. Applebaum. Lévy processes and Stochastic Calculus. Cambridge University Press, 2009.
[2] E. Bacry, S. Delattre, M. Hoﬀmann, and J-F Muzy. Some limit theorems for Hawkes processes and
application to ﬁnancial statistics. Stochastic Processes and their Applications, 123(7):2475–2499,
2013.
[3] E. Bacry and J-F Muzy. Second order statistics characterization of Hawkes processes and nonparametric estimation. arXiv preprint arXiv:1401.0903, 2014.
[4] M. Benaïm, S. Le Borgne, F. Malrieu, and P-A Zitt. Qualitative properties of certain piecewise
deterministic Markov processes. Ann. Inst. H. Poincaré Probab. Statist., 51(3):1040–1075, 08
2015.
[5] M. Bonde Raad. Renewal time points for Hawkes processes. arXiv, 2019.
[6] P. Brémaud and L. Massoulié. Stability of nonlinear Hawkes processes. The Annals of Probability,
pages 1563–1588, 1996.
[7] S. Chen, A. Shojaie, E. Shea-Brown, and D. Witten. The multivariate Hawkes process in high
dimensions: Beyond mutual excitation. arXiv preprint arXiv:1707.04928, 2017.
[8] Simon Clinet and Nakahiro Yoshida. Statistical inference for ergodic point processes and application to limit order book. Stochastic Processes and their Applications, 127(6):1800 – 1839,
2017.
[9] Daryl J. Daley and D. Vere-Jones. An introduction to the theory of point processes: volume II:
general theory and structure. Springer Science & Business Media, 2007.
[10] S. Delattre, N. Fournier, and M Hoﬀmann. Hawkes processes on large networks. The Annals of
Applied Probability, 26(1):216–261, 2016.
[11] C. Dion and S. Lemler. Nonparametric drift estimation for diﬀusions with jumps driven by a
Hawkes process. HAL, 2019.
[12] R. Douc, G. Fort, and A. Guillin. Subgeometric rates of convergence of f-ergodic strong markov
processes. Stochastic Processes and their Applications, 119(3):897 – 923, 2009.
[13] A. Duarte, E. Löcherbach, and G. Ost. Stability, convergence to equilibrium and simulation of
non-linear Hawkes processes with memory kernels given by the sum of Erlang kernels. arXiv
preprint arXiv:1610.03300, 2016.
[14] E. Gobet. Lan property for ergodic diﬀusions with discrete observations. Ann. Inst. H. Poincaré
Probab. Statist., 38(5):711–737, 2002.
[15] C. Graham. Regenerative properties of the linear Hawkes process with unbounded memory. arXiv,
2019.
[16] R.Z. Has’minskii. Stochastic stability of differential equations. Sijthoﬀ & Noordhoﬀ, 1980.
[17] A.G Hawkes. Spectra of some self-exciting and mutually exciting point processes. Biometrika,
58(1):83–90, 1971.

19

[18] P. Hodara and E. Löcherbach. Hawkes processes with variable length memory and an inﬁnite
number of components. Advances in Applied Probability, 49(1):84–107, 2017.
[19] R. Höpfner and E. Löcherbach. Statistical models for Birth and Death on a Flow: Local absolute
continuity and likelihood ratio processes. Scandinavian Journal of Statistics, 26(1):107–128, 1999.
[20] N. Ikeda, M. Nagasawa, and S. Watanabe. A construction of Markov processes by piecing out.
Proc. Japan Acad., 42(4):370–375, 1966.
[21] N. Ikeda and S. Watanabe. Stochastic Differential Equations and Diffusion Processes. NorthHolland Mathematical Library. Elsevier Science, 2014.
[22] K. Ito and H.P McKean. Diﬀusion processes and their sample paths, 1965.
[23] SA. Klokov and A Yu Veretennikov. On subexponential mixing rate for Markov processes. Theory
of Probability & Its Applications, 49(1):110–122, 2005.
[24] Alexei Michajlovič Kulik. Introduction to Ergodic rates for Markov chains and processes with
applications to limit theorems. Potsdam University Press, 2015.
[25] H. Kunita. Stochastic flows and stochastic differential equations. Cambridge University Press,
Cambridge, 1992.
[26] E. Löcherbach. Absolute continuity of the invariant measure in piecewise deterministic Markov
Processes having degenerate jumps. Stoch. Proc. Appl., 128:1797–1829, 2018.
[27] E. Löcherbach and D. Loukianova. On Nummelin splitting for continuous time Harris recurrent
Markov processes and application to kernel estimation for multi-dimensional diﬀusions. Stoch.
Proc. Appl., 118:1301–1321, 2008.
[28] E. Löcherbach and D. Loukianova. Polynomial deviation bounds for recurrent harris processes
having general state space. ESAIM: Probability and Statistics, 17:195–218, 2013.
[29] H Masuda. Ergodicity and exponential β-mixing bounds for multidimensional diﬀusions with
jumps. Stochastic Processes and their Applications, 117(1):35–56, 2007.
[30] S.P. Meyn and R.L. Tweedie. Stability of Markovian processes I : Criteria for discrete-time chains.
Adv. Appl. Probab., 24:542–574, 1992.
[31] S.P. Meyn and R.L. Tweedie. Stability of Markovian processes III : Foster-Lyapunov criteria for
continuous-time processes. Adv. Appl. Probab., 25:487–548, 1993.
[32] A. Millet and M Sanz-Solé. A simple proof of the support theorem for diﬀusion processes. Séminaire de probabilités de Strasbourg, 28:36–48, 1994.
[33] D. Revuz and M. Yor. Continuous martingales and Brownian motion, volume 293. Springer
Science & Business Media, 2013.
[34] P. Reynaud-Bouret, V. Rivoirard, and C. Tuleau-Malot. Inference of functional connectivity in
neurosciences via Hawkes processes. In Global Conference on Signal and Information Processing
(GlobalSIP), 2013 IEEE, pages 317–320. IEEE, 2013.
[35] D.W. Stroock and S. R. S. Varadhan. On the support of diﬀusion processes with applications to
the strong maximum principle. In Proceedings of the Sixth Berkeley Symposium on Mathematical
Statistics and Probability, Volume 3: Probability Theory, pages 333–359, Berkeley, Calif., 1972.
University of California Press.
20

[36] P. Tankov and E. Voltchkova. Jump-diﬀusion models: a practitioner’s guide. Banque et Marchés,
99(1):24, 2009.
[37] A.Yu. Veretennikov. On polynomial mixing bounds for stochastic diﬀerential equations. Stochastic
Processes and their Applications, 70(1):115 – 127, 1997.

21

