Proximal gradient flow and Douglas-Rachford splitting dynamics:
global exponential stability via integral quadratic constraints ⋆
Sepideh Hassan-Moghaddam and Mihailo R. Jovanović a

arXiv:1908.09043v2 [math.OC] 25 Jun 2020

a

Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA 90089

Abstract
Many large-scale and distributed optimization problems can be brought into a composite form in which the objective function
is given by the sum of a smooth term and a nonsmooth regularizer. Such problems can be solved via a proximal gradient method
and its variants, thereby generalizing gradient descent to a nonsmooth setup. In this paper, we view proximal algorithms as
dynamical systems and leverage techniques from control theory to study their global properties. In particular, for problems
with strongly convex objective functions, we utilize the theory of integral quadratic constraints to prove the global exponential
stability of the equilibrium points of the differential equations that govern the evolution of proximal gradient and DouglasRachford splitting flows. In our analysis, we use the fact that these algorithms can be interpreted as variable-metric gradient
methods on the suitable envelopes and exploit structural properties of the nonlinear terms that arise from the gradient of
the smooth part of the objective function and the proximal operator associated with the nonsmooth regularizer. We also
demonstrate that these envelopes can be obtained from the augmented Lagrangian associated with the original nonsmooth
problem and establish conditions for global exponential convergence even in the absence of strong convexity.
Key words: Control for optimization, forward-backward envelope, Douglas-Rachford splitting, global exponential stability,
integral quadratic constraints (IQCs), nonlinear dynamics, nonsmooth optimization, proximal algorithms, primal-dual
methods, proximal augmented Lagrangian.

1

Introduction

Structured optimal control and estimation problems
typically lead to optimization of objective functions that
consist of a sum of a smooth term and a nonsmooth regularizer. Such problems are of increasing importance in
applications and it is thus necessary to develop efficient
algorithms for distributed and embedded nonsmooth
composite optimization [1–4]. The lack of differentiability in the objective function precludes the use of
standard descent methods from smooth optimization.
Proximal gradient method [5, 6] generalizes gradient
descent to nonsmooth context and provides a powerful
tool for solving problems in which the nonsmooth term
is separable over the optimization variable.
Examining optimization algorithms as continuous-time
dynamical systems has been an active topic since the
seminal work of Arrow, Hurwicz, and Uzawa [7]. This
viewpoint can provide important insight into performance of optimization algorithms and streamline their
convergence analysis. During the last decade, it has been
advanced and extended to a broad class of problems including convergence analysis of primal-dual [2,8–12] and
⋆ Supported in part by the National Science Foundation
under awards ECCS-1708906 and ECCS-1809833.
Email addresses: hassanmo@usc.edu (Sepideh HassanMoghaddam), mihailo@usc.edu (Mihailo R. Jovanović).

Preprint submitted to Automatica

accelerated [13–18] first-order methods. Furthermore,
establishing the connection between theory of ordinary
differential equations (ODEs) and numerical optimization algorithms has been a topic of many studies, including [19, 20]; for recent efforts, see [14, 21].
Optimization algorithms can be viewed as a feedback interconnection of linear dynamical systems with nonlinearities that possess certain structural properties. This
system-theoretic interpretation was exploited in [22] and
further advanced in recent papers [11, 23–29]. The key
idea is to exploit structural features of linear and nonlinear terms and utilize theory and techniques from stability analysis of nonlinear dynamical systems to study
properties of optimization algorithms. This approach
provides new methods for studying not only convergence
rate but also robustness of optimization routines [30–33]
and can lead to new classes of algorithms that strike a
desired tradeoff between the speed and robustness.
In this paper, we utilize techniques from control theory
to establish global properties of proximal gradient flow
and Douglas-Rachford (DR) splitting dynamics. These
algorithms provide an effective tool for solving nonsmooth convex optimization problems in which the objective function is given by a sum of a differentiable term
and a nondifferentiable regularizer. When the smooth
term is strongly convex with a Lipschitz continuous gra-

26 June 2020

where µ is a positive parameter and v is a given vector.
It is determined by the resolvent operator associated
with µ∂g, proxµg := (I + µ∂g)−1 , and is a single-valued
firmly non-expansive mapping [6], i.e., for any u and v,

dient, we prove the global exponential stability of both
the proximal gradient flow and the DR splitting dynamics by utilizing the theory of IQCs [34]. We also generalize the Polyak-Lojasiewicz (PL) [35] condition to nonsmooth problems and show global exponential convergence of the forward-backward (FB) envelope [36–38]
even in the absence of strong convexity.

kproxµg (u) − proxµg (v)k22 ≤
u − v, proxµg (u) − proxµg (v) .

Although there are related approaches for studying
optimization algorithms from a control-theoretic perspective, to the best of our knowledge, we are the first to
introduce the continuous forms of proximal gradient and
DR splitting algorithms. We use simple proofs to establish their global stability properties and provide explicit
bounds on convergence rates. Furthermore, standard
forms of these algorithms are obtained via explicit forward Euler discretization of continuous-time dynamics.

The value function of the optimization problem (2) determines the associated Moreau envelope,
Mµg (v) := g(proxµg (v)) +

which is a continuously differentiable function even when
g is not [6], with µ∇Mµg (v) = v − proxµg (v).

The paper is structured as follows. In Section 2, we formulate the nonsmooth composite optimization problem
and provide background material. In Section 3, we establish the global exponential stability of the proximal
gradient flow dynamics for a problem with strongly convex objective function. Moreover, by exploiting the problem structure, we demonstrate the global exponential
convergence of the forward-backward envelope even in
the absence of strong convexity. In Section 4, we introduce a continuous-time gradient flow dynamics based
on the celebrated Douglas-Rachford splitting algorithm
and utilize the theory of IQCs to prove global exponential stability for strongly convex problems. We offer concluding remarks in Section 5.
2

By introducing an auxiliary optimization variable z,
problem (1) can be rewritten as follows,
minimize f (x) + g(z)
x, z

and the associated augmented Lagrangian is given by,
1
kT x−zk22.
Lµ (x, z; y) := f (x) + g(z) + hy, T x − zi + 2µ

The completion of squares yields,
Lµ = f (x) + g(z) +

(1)

µ
2

kyk22

and the evaluation of Lµ along the manifold resulting
from this explicit minimization yields the proximal augmented Lagrangian [11], Lµ (x; y) := Lµ (x, z ⋆ (x, y); y),
Lµ (x; y) = f (x) + Mµg (T x + µy) −

µ
2

kyk22 . (4)

This function is continuously differentiable with respect
to both x and y and it can be used as a foundation for
the development of first- and second-order primal-dual
methods for nonsmooth composite optimization [11,39].
For T = I, the forward-backward envelope [36–38] is
obtained by restricting the proximal augmented Lagrangian Lµ (x; y) along the manifold y ⋆ (x) = −∇f (x)
resulting from the KKT optimality conditions,

Proximal operator and the associated envelopes

The proximal operator of a proper, closed, and convex
function g is defined as


1
2
:=
proxµg (v)
argmin g(z) +
kz − vk2
2µ
z

kz − (T x + µy)k22 −

z ⋆ (x, y) = proxµg (T x + µy)

where x ∈ Rn is the optimization variable, T ∈ Rm×n is
a given matrix, f : Rn → R is a convex function with a
Lipschitz continuous gradient, and g: Rm → R is a nondifferentiable convex function. Such optimization problems arise in a number of applications and depending
on the structure of the functions f and g, different firstand second-order algorithms can be employed to solve
them. We are interested in studying global convergence
properties of methods based on proximal gradient flow
algorithms. In what follows, we provide background material that we utilize in the rest of the paper.
2.1

1
2µ

where y is the Lagrange multiplier. The minimizer of Lµ
with respect to z is

We consider a composite optimization problem,
x

(3)

subject to T x − z = 0

Problem formulation and background

minimize f (x) + g(T x)

1
kproxµg (v) − vk22
2µ

Fµ (x) := Lµ (x; y ⋆ (x)) = Lµ (x; y = −∇f (x))
(2)

= f (x) + Mµg (x − µ∇f (x)) −

2

µ
2

k∇f (x)k22 .

2.2

Strong convexity and Lipschitz continuity

3

In this section, we briefly discuss the Arrow-HurwiczUzawa gradient flow dynamics that can be used to
solve (3) by computing the saddle points of the proximal augmented Lagrangian [11]. We then show that
the proximal gradient method in continuous time can
be obtained from the proximal augmented Lagrangian
method by restricting the dual variable along the manifold y = −∇f (x). Finally, we discuss global stability
properties of proximal algorithms both in the presence
and in the absence of strong convexity.

The function f is mf -strongly convex if
f (x̂) ≥ f (x) + h∇f (x), x̂ − xi +

mf
kx̂ − xk22
2

and its gradient is Lf -Lipschitz continuous if
f (x̂) ≤ f (x) + h∇f (x), x̂ − xi +

Exponential stability of proximal algorithms

Lf
kx̂ − xk22
2

for any x and x̂. When both properties hold we have

Continuous differentiability of the proximal augmented
Lagrangian (4) can be utilized to compute its saddle
points via the Arrow-Hurwicz-Uzawa dynamic,

mf kx − x̂k2 ≤ k∇f (x)−∇f (x̂)k2 ≤ Lf kx − x̂k2 . (5)
and the following inequality is satisfied [40],
mf L f
kx − x̂k22 +
mf + L f
1
k∇f (x) − ∇f (x̂)k22 .
mf + L f
(6)
Furthermore, the subgradient ∂g of a nondifferentiable
function g is defined as the set of points z ∈ ∂g(x) that
for any x and x̂ satisfy,
h∇f (x) − ∇f (x̂), x − x̂i ≥

" #
"
#
ẋ
−µ (∇f (x) + T T ∇Mµg (T x + µy))
=
.
ẏ
µ (∇Mµg (T x + µy) − y)
(11)
As shown in [11], the optimal primal-dual pair (x⋆ , y ⋆ )
is the globally exponentially stable equilibrium point
of (11) and x⋆ is the solution of (1) for convex problems
in which the matrix T T T is invertible and the smooth
part of the objective function f is strongly convex.
For convex problems with T = I in (1),

g(x̂) ≥ g(x) + z T (x̂ − x).

(7)
minimize f (x) + g(x)

2.3

x

Proximal Polyak-Lojasiewicz inequality

the optimality condition is given by

The Polyak-Lojasiewicz (PL) condition can be used to
prove linear convergence of a gradient descent even in
the absence of convexity [41]. For an unconstrained optimization problem with a non-empty solution set and a
twice differentiable objective function f with a Lipschitz
continuous gradient, the PL condition is given by

0 ∈ ∇f (x⋆ ) + ∂g(x⋆ )

0 ∈ [I + µ∂g] (x⋆ ) + µ∇f (x⋆ ) − x⋆ .
Since proxµg is determined by the resolvent operator
associated with µ∂g and is single-valued [6], we have

where γ > 0 and f ⋆ is the optimal value of f . For nonsmooth optimization problem (3) with T = I, the proximal PL inequality holds for µ ∈ (0, 1/Lf ) if there exist
γ > 0 such that

x⋆ − proxµg (x⋆ − µ∇f (x⋆ )) = 0.

1
(x − proxµg (x − µ∇f (x))).
µ


ẋ = − x − proxµg (x − µ∇f (x))

= −µ (∇f (x) + ∇Mµg (x − µ∇f (x))) .

(15)

(9)
Remark 1 Proximal gradient flow dynamics (15) are
different from the subgradient flow dynamics associated
with nonsmooth problem (12). Standard proximal gradient algorithm [5] can be obtained via explicit forward Euler discretization of (15) with the stepsize one, xk+1 =
proxµg (xk − µ∇f (xk )). This should be compared and
contrasted with [6, Section 4.1.1] in which implicit back-

When f is twice continuously differentiable, the FB envelope Fµ is continuously differentiable with [36],
∇Fµ (x) = (I − µ∇2 f (x)) Gµ (x).

(14)

We next demonstrate that (12) can be solved using the
proximal gradient flow dynamics, ẋ = −µ Gµ (x),

(8)

Here, Lf is the Lipschitz constant of ∇f , Fµ is the FB
envelope, and Gµ is the generalized gradient map,
Gµ (x) :=

(13)

Multiplying by µ and adding/subtracting x⋆ yields,

k∇f (x)k22 ≥ γ (f (x) − f ⋆ )

kGµ (x)k22 ≥ γ (Fµ (x) − Fµ⋆ ).

(12)

(10)

3

Moreover, the nonlinear function u(ξ) := proxµg (ξ −
µ∇f (ξ)) is a contraction for µ ∈ (0, 2/Lf ).

LTI dynamics
z

dz
= −z + u
dt

u

PROOF. Since proxµg is firmly nonexpansive [6], it is
also Lipschitz continuous with parameter 1, i.e.,

u(·)

ˆ 2 . (18)
ku − ûk22 ≤ k(ξ − µ∇f (ξ)) − (ξˆ − µ∇f (ξ))k
2

nonlinear term

Expanding the right-hand-side of (18) yields,

Fig. 1. Both the proximal gradient flow dynamics (15) and
the DR splitting dynamics (26) can be represented via feedback interconnections of stable LTI systems with nonlinear
terms that possess certain structural properties.

ˆ 2−
ˆ 2 + µ2 k∇f (ξ) − ∇f (ξ)k
ku − ûk22 ≤ kξ − ξk
2
2
D
E
ˆ
2µ ξ − ξ̂, ∇f (ξ) − ∇f (ξ)

ward Euler discretization of the subgradient flow dynamics associated with (12) was used. We also note that (15)
can be obtained by substituting −∇f (x) for the dual variable y in the x-update step of primal-descent dual-ascent
gradient flow dynamics (11) with T = I.

and utilizing inequality (6) for an mf -strongly convex
function f with an Lf -Lipschitz continuous gradient, the
last inequality can be further simplified to obtain,

In Sections 3.1 and 3.2, we examine properties of system (15), first for strongly convex problems and then for
the problems in which only the PL condition holds.
3.1 Strongly convex problems
We utilize the theory of integral quadratic constraints to
prove global asymptotic stability of the proximal gradient flow dynamics (15) under the following assumption.
Assumption 1 Let f in (12) be mf -strongly convex, let
∇f be Lf -Lipschitz continuous, and let the regularization
function g be proper, closed, and convex.

2 µ mf L f
ˆ2+
) kξ − ξk
2
L f + mf
2µ
ˆ 2.
(µ2 −
) k∇f (ξ) − ∇f (ξ)k
2
L f + mf
(19)
Depending on the sign of µ−2/(Lf + mf ) either lower or
upper bound in (5) can be used to upper bound the second term on the right-hand-side of (19), thereby yielding
ku − ûk22 ≤ (1 −


ˆ 2.
ku − ûk22 ≤ max (1 − µLf )2 , (1 − µmf )2 kξ − ξk
2
(20)
Thus, for σ given by (17b) the nonlinear function u(ξ)
is a contraction if and only if −1 < 1 − µLf < 1 and
−1 < 1 − µmf < 1. Since mf ≤ Lf , these conditions
hold for µ ∈ (0, 2/Lf ) which completes the proof.

As illustrated in Fig. 1, system (15) can be expressed as
a feedback interconnection of an LTI system
ż = A z + B u, ξ = C z
A = −I, B = C = I

(16a)

We next employ [42, Theorem 3] to prove the global exponential stability of the equilibrium point z ⋆ of (16)
with the rate ρ > 0 by verifying the existence of a positive definite matrix P such that,

where z := x, with the nonlinear term,
u(ξ) := proxµg (ξ − µ ∇f (ξ)).

(16b)

"

Lemma 1 combines firm nonexpansiveness of proxµg ,
strong convexity of f , and Lipschitz continuity of ∇f
to characterize nonlinear map (16b) by establishing a
quadratic inequality for u(ξ).
Lemma 1 Let Assumption 1 hold. Then, for any ξ ∈
Rn , ξ̂ ∈ Rn , u := proxµg (ξ − µ ∇f (ξ)), and û :=
ˆ the pointwise quadratic inequality
proxµg (ξˆ− µ ∇f (ξ)),
"

ξ − ξˆ
u − û

#T "

σ2 I 0

#"

ξ − ξ̂

0 −I
u − û
|
{z
}

#

≥ 0

σ = max {|1 − µmf |, |1 − µLf |} .

BT P

0

#

+

"

CT 0
0 I

#

Π

"

C 0
0 I

#

 0, (21)

where Aρ := A + ρI and Π is given by (17a).
Theorem 2 Let Assumption 1 hold and let µ ∈
(0, 2/Lf ). Then, the equilibrium point z ⋆ of the proximal
gradient flow dynamics (16) is globally ρ-exponentially
stable, i.e., there is c > 0 and ρ ∈ (0, 1 − σ] such that,

(17a)

kz(t) − z ⋆ k2 ≤ c e−ρt kz(0) − z ⋆ k2 , ∀ t ≥ 0
where σ is given by (17b). Moreover, x⋆ = z ⋆ is the
optimal solution of (12).

Π

holds, where

ATρ P + P Aρ P B

PROOF. Substituting Π given by (17a) into (21) implies that the condition (21) holds if there exists a posi-

(17b)

4

flow dynamics (15) converge exponentially to Fµ⋆ = F ⋆
with the rate ρ = γµ(1 − µLf ), i.e.,

tive scalar p such that
"

2(1 − ρ)p − σ 2 −p
−p

1

#

 0

(22)

Fµ (x(t)) − Fµ⋆ ≤ e−ρt (Fµ (x(0)) − Fµ⋆ ), ∀ t ≥ 0.
PROOF. For a Lyapunov function candidate,

where the block-diagonal structure of A, B, C, and Π
allows us to choose P = pI without loss of generality.
Condition (22) is satisfied if there is p > 0 such that
p2 − 2(1 − ρ)p + σ 2 ≤ 0

V (x) = Fµ (x) − Fµ⋆

(23)

the derivative of V along the solutions of (15) is given by

where ρ < 1 guarantees positivity of the first element
on the main diagonal of the matrix in (22). For µ ∈
(0, 2/Lf ), Lemma 1 implies σ < 1 and ρ ≤ 1 − σ is required for the existence of p > 0 such that (23) holds.
Thus, z ⋆ is globally exponentially stable with the rate
ρ ≤ 1 − σ. The result follows because the equilibrium
point z ⋆ = x⋆ of (16) satisfies the optimality condition (14) for optimization problem (12).

V̇ (x) = h∇Fµ (x), ẋi
= − ∇Fµ (x), µ(I − µ∇2 f (x))−1 ∇Fµ (x)
= − Gµ (x), µ(I − µ∇2 f (x)) Gµ (x) .
Since the gradient of f is Lf -Lipschitz continuous, i.e.,
∇2 f (x)  Lf I for all x ∈ Rn , Assumption 2 implies
−(I − µ∇2 f (x))  −(1 − µLf )I, and, thus,

Remark 2 For µ = 2/(Lf + mf ), the second term on
the right-hand-side in (19) disappears and σ is given by
σ = (Lf − mf )/(Lf + mf ) = (κ − 1)/(κ + 1) where
κ := Lf /mf is the condition number of the function f
and ρ is upper bounded by 2/(κ + 1). In fact, this is the
best achievable convergence rate for system (15).
3.2 Proximal Polyak-Lojasiewicz condition

V̇ (x) ≤ −µ(1 − µLf ) kGµ (x)k22
≤ −γµ(1 − µLf ) (Fµ (x) − Fµ⋆ )

(24)

is non-positive for µ ∈ (0, 1/Lf ). Moreover, combining
the last inequality with the definition of V yields V̇ ≤
−γµ(1 − µLf )V, which implies

Next, we consider the problems in which the function
f is not strongly convex but the function F := f + g
satisfies the proximal PL condition (8).

Fµ (x(t)) − Fµ⋆ ≤ e−γµ(1−µLf )t (Fµ (x(0)) − Fµ⋆ ).

Assumption 2 Let the regularization function g in (12)
be proper, closed, and convex, let f be twice continuously
differentiable with ∇2 f (x)  Lf I, and let the generalized
gradient map satisfy the proximal PL condition,

Remark 4 When the proximal PL condition is satisfied,
Fµ (x(t))−Fµ⋆ converges exponentially but, in the absence
of strong convexity, the exponential convergence rate cannot be established for kx(t) − x⋆ k2 . Thus, although the
objective function converges exponentially fast, the solution to (15) does not enjoy this convergence rate. To the
best of our knowledge, the convergence rate of x(t) to the
set of optimal values x⋆ is not known in this case.

kGµ (x)k22 ≥ γ (Fµ (x) − Fµ⋆ )
where µ ∈ (0, 1/Lf ), γ > 0, and Fµ⋆ is the optimal value
of the FB envelope Fµ .

4
Remark 3 The proximal gradient algorithm can be interpreted as a variable-metric gradient method on FB envelope and (15) can be equivalently written as

Global exponential stability of the DouglasRachford splitting dynamics

We next introduce a continuous-time gradient flow dynamics based on the well-known Douglas-Rachford splitting algorithm [43] and establish global exponential stability for strongly convex f .

ẋ = −µ (I − µ∇2 f (x))−1 ∇Fµ (x).
Under Assumption 2, I − µ∇2 f (x) is invertible and
the functions F and Fµ have the same minimizers and
the same optimal values [36], i.e., argminx F (x) =
argminx Fµ (x) and F ⋆ = Fµ⋆ . This motivates the analysis of the convergence properties of (15) in terms of the
FB envelope.

4.1

Non-smooth composite optimization problem

The optimality condition for (12) is given by (13), i.e.,
0 ∈ ∇f (x⋆ )+∂g(x⋆ ). Multiplication by µ and addition of
x to the both sides yields 0 ∈ [I + µ∇f ] (x⋆ )+µ∂g(x⋆ )−
x⋆ . Since proxµf := (I + µ∇f )−1 is single-valued [6],
introducing z := x − µ∂g(x) leads to,

Theorem 3 Let Assumption 2 hold. Then the forwardbackward envelope associated with the proximal gradient

x⋆ = proxµf (x⋆ − µ∂g(x⋆ )) = proxµf (z ⋆ ). (25a)

5

where the firm non-expansiveness of proxµf is used in
the last step. Moreover, according to Lemma 1, for µ ∈
(0, 2/Lf ) we have σ < 1, which completes the proof.

Now, adding x to the both sides of the defining equation
for z gives [I + µ∂g] (x⋆ ) = 2proxµf (z ⋆ ) − z ⋆ , i.e.,
x⋆ = proxµg (2 proxµf (z ⋆ ) − z ⋆ ).

(25b)

Lemma 5 Let Assumption 1 hold and let µ ∈ (0, 2/Lf ).
Then, the operator Rµg is firmly non-expansive.

Combining (25a) and (25b) results in the following optimality condition,

PROOF.
kRµg (x) − Rµg (y)k22 = 4kproxµf (x) − proxµf (y)k22 +
kx−yk22 −4 x − y, proxµf (x) − proxµf (y) ≤ kx−yk22 .

proxµf (z ⋆ ) − proxµg (2 proxµf (z ⋆ ) − z ⋆ ) = 0. (25c)
Furthermore, the reflected proximal operators [44],
Rµf (z) := [2 proxµf − I](z) and Rµg := [2 proxµg −
I](z), can be used to rewrite optimality condition (25c) as
z ⋆ − [Rµg Rµf ](z ⋆ ) = 0.

Remark 5 Since Rµg is firmly non-expansive and Rµf
is σ-contractive, the composite operator Rµg Rµf is also
σ-contractive. Moreover, since the operator Rµf and nonlinearity u in (16b) have the same contraction parameters, the quadratic inequality that describes (16b) can be
also used to characterize the composite operator Rµg Rµf .

(25d)

Theorem 6 Let Assumption 1 hold and let µ ∈
(0, 2/Lf ). Then, the equilibrium point z ⋆ of the DR splitting dynamics (26) is globally ρ-exponentially stable,
i.e., there is c > 0 and ρ ∈ (0, 1 − σ) such that,

We are now ready to introduce the continuous-time DR
gradient flow dynamics to compute z ⋆ ,
ż = −z + [Rµg Rµf ](z).

(26)

kz(t) − z ⋆ k ≤ c e−ρt kz(0) − z ⋆ k, ∀ t ≥ 0

Note that the explicit forward Euler discretization
of (26) yields the standard DR splitting algorithm [45].
We view (26) as a feedback interconnection of an LTI
system (16a) with the nonlinear term,
u(ξ) := [Rµg Rµf ](ξ).

where σ is given by (28). Moreover, x⋆ = proxµf (z ⋆ ) is
the optimal solution of (12).
PROOF. Although the nonlinear terms in systems (11)
and (26) are different, they share quadratic characterization (17a) and the LTI dynamics (16a). Thus, the result
follows from the proof of Theorem 2 and the fact that
x⋆ = proxµf (z ⋆ ) satisfies optimality condition (25c).

(27)

We first characterize properties of nonlinearity u in (27)
and then, similar to the previous section, establish global
exponential stability of nonlinear system (26).

4.2

Lemma 4 Let Assumption 1 hold and let µ ∈ (0, 2/Lf ).
Then, the operator Rµf is σ-contractive,

Douglas-Rachford splitting on the dual problem

Even though the DR splitting algorithm cannot be directly used to solve a problem with a more general linear
equality constraint,

kRµf (x) − Rµf (y)k2 ≤ σkx − yk2
where σ is given by

minimize

f (x) + g(z)

subject to

T x + Sz = r

x, z

σ = max {|1 − µmf |, |1 − µLf |} < 1.

(28)

(29)

it can be utilized to solve the dual problem,

PROOF. Given zx := proxµf (x) and zy := proxµf (y),
x and y can be computed as follows

minimize

x = zx + µ ∇f (zx ), y = zy + µ ∇f (zy ).

ζ

Thus,
kRµf (x) − Rµf (y)k2 = k2(zx − zy ) − (x − y)k2 =
k(zx − zy ) − µ (∇f (zx ) − ∇f (zy ))k2 = kzx − zy k2 +
kµ(∇f (zx ) − ∇f (zy ))k2 − 2 µ h∇f (zx ) − ∇f (zy ), zx − zy i

≤ max (1 − µLf )2 , (1 − µmf )2 kzx − zy k2

≤ σ 2 kx − yk2 .

6

f1 (ζ) + g1 (ζ).

(30)

Here, T ∈ Rm×n , S ∈ Rm×n , and r ∈ Rm are the problem parameters, f1 (ζ) := f ⋆ (−T T ζ) + rT ζ, g1 (ζ) :=
g ⋆ (−S T ζ), and h⋆ (ζ) := supx (ζ T x − h(x)) is the conjugate of the function h. It is a standard fact [45, 46]
that solving the dual problem (30) via the DR splitting
algorithm is equivalent to using ADMM for the original problem (29). If Assumption 1 holds and if T is a
full row rank matrix, the global exponentially stability
of the DR gradient flow dynamics associated with (30),
ζ̇ = −ζ + [Rµg1 Rµf1 ](ζ), is readily established.

5

Since Gµ (x) − ∇f (x) ∈ ∂g(x), the subgradient inequality (7) implies

Concluding remarks

We study a class of nonsmooth optimization problems in
which it is desired to minimize the sum of a continuously
differentiable function with a Lipschitz continuous gradient and a nondifferentiable function. For strongly convex problems, we employ the theory of integral quadratic
constraints to prove global exponential stability of proximal gradient flow and Douglas-Rachford splitting dynamics. We also utilize a generalized Polyak-Lojasiewicz
condition for nonsmooth problems to demonstrate the
global exponential convergence of the forward-backward
envelope for the proximal gradient flow algorithm even
in the absence of strong convexity.
A

0 ≤ µ kGµ (x)k22 ≤ g(x) − g(proxµg (x − µ ∇f (x))) +
µ h∇f (x), Gµ (x)i .
(A.5)
Combining (A.4) and (A.5) and taking the sign of µκ− 1
into account yields,
α
kGµ (x)k22 ≥ κ (Fµ (x) − F ⋆ ), α := |µκ − 1|.
2
Furthermore, since [36], argminx F (x) = argminx Fµ (x)
and F ⋆ = Fµ⋆ , Fµ⋆ can be substituted for F ⋆ and we have
kGµ (x)k22 ≥ γ (Fµ (x) − Fµ⋆ ) with γ := 2κ/|µκ − 1|.

Proximal PL condition

References

The generalization of the PL condition to nonsmooth
problems was introduced in [41] and is given by
⋆

Dg (x, Lf ) ≥ 2κ (F (x) − F )

[1] A. Nedić and A. Ozdaglar, “Distributed subgradient methods
for multiagent optimization,” IEEE Trans. on Automat.
Control, vol. 54, no. 1, pp. 48–61, 2009.

(A.1)

[2] J. Wang and N. Elia, “A control perspective for centralized
and distributed convex optimization,” in Proceedings of the
50th IEEE Conference on Decision and Control, 2011, pp.
3800–3805.

where κ is a positive constant, Lf is the Lipschitz constant of ∇f , and Dg (x, α) is determined by
α
ky − xk22 + g(y) − g(x)).
2
(A.2)
Herein, we show that if proximal PL condition (A.1)
holds, there is a lower bound given by (8) on the norm of
the generalized gradient map Gµ (x). For µ ∈ (0, 1/Lf ),
Dg (x, 1/µ) ≥ Dg (x, Lf ), and, thus, inequality (A.1) also
holds for Dg (x, 1/µ). Moreover, from the definition (A.2)
of Dg (x, α), it follows that
− 2α min (h∇f (x), y − xi +

[3] P. Latafat, L. Stella, and P. Patrinos, “New primaldual proximal algorithm for distributed optimization,” in
Proceedings of the 55th IEEE Conference on Decision and
Control, 2016, pp. 1959–1964.

y

Dg (x, 1/µ) =

[4] P. Latafat, N. Freris, and P. Patrinos, “A new
randomized block-coordinate primal-dual proximal algorithm
for distributed optimization,” IEEE Trans. Automat.
Control, 2019, doi:10.1109/TAC.2019.2906924.
[5] A. Beck and M. Teboulle, “A fast iterative shrinkagethresholding algorithm for linear inverse problems,” SIAM
J. Imaging Sci., vol. 2, no. 1, pp. 183–202, 2009.

2
(F (x) − Fµ (x))
µ

[6] N. Parikh and S. Boyd, “Proximal algorithms,” Found.
Trends Opt., vol. 1, no. 3, pp. 123–231, 2013.
[7] K. J. Arrow, L. Hurwicz, and H. Uzawa, “Studies in linear
and non-linear programming,” 1958.

where F := f +g and Fµ is the FB envelope. Substituting
this expression for Dg (x, 1/µ) to (A.1) yields,
1
(F (x) − Fµ (x)) ≥ κ (F (x) − F ⋆ ).
µ

[8] D. Feijer and F. Paganini, “Stability of primal–dual gradient
dynamics and applications to network optimization,”
Automatica, vol. 46, no. 12, pp. 1974–1981, 2010.

(A.3)

[9] A. Cherukuri, E. Mallada, and J. Cortés, “Asymptotic
convergence of constrained primal–dual dynamics,” Syst.
Control Lett., vol. 87, pp. 10–15, 2016.

The smooth part of the objective function f can be written as [36],

[10] A. Cherukuri, E. Mallada, S. Low, and J. Cortes, “The role of
convexity on saddle-point dynamics: Lyapunov function and
robustness,” IEEE Trans. Automat. Control, vol. 63, no. 8,
pp. 2449–2464, 2018.

f (x) = Fµ (x) − g(proxµg (x − µ ∇f (x))) +
µ
kGµ (x)k22
µ h∇f (x), Gµ (x)i −
2

[11] N. K. Dhingra, S. Z. Khong, and M. R. Jovanović, “The
proximal augmented Lagrangian method for nonsmooth
composite optimization,” IEEE Trans. Automat. Control,
vol. 64, no. 7, pp. 2861–2868, July 2019.

and substituting this expression for f to (A.3) yields
(µκ − 1)
2

kGµ (x)k22 ≥ κ (Fµ (x) − F ⋆ ) +

(µκ−1)
µ

[12] G. Qu and N. Li, “On the exponential stability of primaldual gradient dynamics,” IEEE Control Syst. Lett., vol. 3,
no. 1, pp. 43–48, 2018.

g(x) −

[13] W. Su, S. Boyd, and E. Candes, “A differential equation
for modeling Nesterov’s accelerated gradient method: Theory
and insights,” J. Mach. Learn. Res., vol. 17, pp. 1–43, 2016.

(µκ − 1)( µ1 g(proxµg (x − µ ∇f (x))) + h∇f (x), Gµ (x)i).
(A.4)

7

[14] A. Wibisono, A. C. Wilson, and M. I. Jordan, “A variational
perspective on accelerated methods in optimization,” Proc.
Natl. Acad. Sci., vol. 113, no. 47, pp. E7351–E7358, 2016.

[31] H. Mohammadi, M. Razaviyayn, and M. R. Jovanović,
“Performance of noisy Nesterov’s accelerated method for
strongly convex optimization problems,” in Proceedings of
the 2019 American Control Conference, Philadelphia, PA,
2019, pp. 3426–3431.

[15] G. França, D. Robinson, and R. Vidal, “ADMM and
accelerated ADMM as continuous dynamical systems,” 2018,
arXiv:1805.06579.

[32] H. Mohammadi, M. Razaviyayn, and M. R. Jovanović,
“Robustness of accelerated first-order algorithms for strongly
convex optimization problems,” IEEE Trans. Automat.
Control, 2019, submitted; also arXiv:1905.11011.

[16] B. Shi, S. Du, M. I. Jordan, and W. Su, “Understanding
the acceleration phenomenon via high-resolution differential
equations,” 2018, arXiv:1810.08907.

[33] S. Michalowsky, C. Scherer, and C. Ebenbauer, “Robust
and structure exploiting optimization algorithms: An integral
quadratic constraint approach,” 2019, arXiv:1905.00279.

[17] M. Muehlebach and M. I. Jordan, “A dynamical
systems perspective on Nesterov acceleration,” 2019,
arXiv:1905.07436.

[34] A. Megretski and A. Rantzer, “System analysis via integral
quadratic constraints,” IEEE Trans. Autom. Control, vol. 42,
no. 6, pp. 819–830, 1997.

[18] J. I. Poveda and N. Li, “Inducing uniform asymptotic
stability in time-varying accelerated optimization dynamics
via hybrid regularization,” 2019, arXiv:1905.12110.

[35] B.
T.
Polyak,
“Gradient
methods
for
minimizing functionals,” Zhurnal Vychislitel’noi Matematiki
i Matematicheskoi Fiziki, vol. 3, no. 4, pp. 643–653, 1963.

[19] A. Brown and M. Bartholomew-Biggs, “Some effective
methods for unconstrained optimization based on the
solution of systems of ordinary differential equations,” J.
Optimiz. Theory App., vol. 62, no. 2, pp. 211–224, 1989.

[36] P. Patrinos, L. Stella, and A. Bemporad, “Forwardbackward truncated Newton methods for convex composite
optimization,” 2014, arXiv:1402.6655.

[20] J. Schropp and I. Singer, “A dynamical systems approach to
constrained minimization,” Numer. Func. Anal. Opt., vol. 21,
no. 3-4, pp. 537–551, 2000.

[37] L.
Stella,
A.
Themelis,
and
P. Patrinos, “Forward–backward quasi-Newton methods for
nonsmooth optimization problems,” Comput. Optim. Appl.,
vol. 67, no. 3, pp. 443–487, 2017.

[21] J. Zhang, A. Mokhtari, S. Sra, and A. Jadbabaie,
“Direct Runge-Kutta discretization achieves acceleration,” in
Advances in Neural Information Processing Systems, 2018,
pp. 3900–3909.

[38] A. Themelis, L. Stella, and P. Patrinos, “Forward-backward
envelope for the sum of two nonconvex functions: Further
properties and nonmonotone line-search algorithms,” SIAM
J. Optim., vol. 28, no. 3, pp. 2274–2303, 2018.

[22] L. Lessard, B. Recht, and A. Packard, “Analysis and design of
optimization algorithms via integral quadratic constraints,”
SIAM J. Optim., vol. 26, no. 1, pp. 57–95, 2016.

[39] N. K. Dhingra, S. Z. Khong, and M. R. Jovanović, “A
second order primal-dual method for nonsmooth convex
composite optimization,” IEEE Trans. Automat. Control,
2017, submitted; also arXiv:1709.01610.

[23] B. Hu, P. Seiler, and A. Rantzer, “A unified analysis of
stochastic optimization methods using jump system theory
and quadratic constraints,” in Proceedings of the 2017
Conference on Learning Theory, 2017, pp. 1157–1189.

[40] Y. Nesterov, Introductory lectures on convex optimization: A
basic course, 2013, vol. 87.

[24] B. Hu and L. Lessard, “Dissipativity theory for Nesterov’s
accelerated method,” in Proceedings of the 34th International
Conference on Machine Learning, 2017, pp. 1549–1557.

[41] H. Karimi, J. Nutini, and M. Schmidt, “Linear convergence
of gradient and proximal-gradient methods under the PolyakLojasiewicz condition,” in Joint European Conference on
Machine Learning and Knowledge Discovery in Databases,
2016, pp. 795–811.

[25] M. Fazlyab, A. Ribeiro, M. Morari, and V. M. Preciado,
“Analysis of optimization algorithms via integral quadratic
constraints: Nonstrongly convex problems,” SIAM J. Optim.,
vol. 28, no. 3, pp. 2654–2689, 2018.

[42] B. Hu and P. Seiler, “Exponential decay rate conditions
for uncertain linear systems using integral quadratic
constraints,” IEEE Trans. Autom. Control, vol. 61, no. 11,
pp. 3631–3637, 2016.

[26] S. Hassan-Moghaddam and M. R. Jovanović, “Distributed
proximal augmented Lagrangian method for nonsmooth
composite optimization,” in Proceedings of the 2018
American Control Conference, Milwaukee, WI, 2018, pp.
2047–2052.

[43] J. Douglas and H. Rachford, “On the numerical solution of
heat conduction problems in two and three space variables,”
Trans. Amer. Math. Soc., vol. 82, no. 2, pp. 421–439, 1956.

[27] S. Hassan-Moghaddam and M. R. Jovanović, “On the
exponential convergence rate of proximal gradient flow
algorithms,” in Proceedings of the 57th IEEE Conference on
Decision and Control, Miami, FL, 2018, pp. 4246–4251.

[44] P. Giselsson and S. Boyd, “Linear convergence and metric
selection for Douglas-Rachford splitting and ADMM,” IEEE
Trans. Automat. Control, vol. 62, no. 2, pp. 532–544, 2017.

[28] D. Ding, B. Hu, N. K. Dhingra, and M. R. Jovanović,
“An exponentially convergent primal-dual algorithm for
nonsmooth composite minimization,” in Proceedings of the
57th IEEE Conference on Decision and Control, Miami, FL,
2018, pp. 4927–4932.

[45] J. Eckstein and D. P. Bertsekas, “On the Douglas-Rachford
splitting method and the proximal point algorithm for
maximal monotone operators,” Math. Program., vol. 55, no.
1-3, pp. 293–318, 1992.

[29] J. Seidman, M. Fazlyab, V. Preciado, and G. Pappas, “A
control-theoretic approach to analysis and parameter selection
of Douglas-Rachford splitting,” 2019, arXiv:1903.11525.
[30] H. Mohammadi, M. Razaviyayn, and M. R. Jovanović,
“Variance amplification of accelerated first-order algorithms
for strongly convex quadratic optimization problems,” in
Proceedings of the 57th IEEE Conference on Decision and
Control, Miami, FL, 2018, pp. 5753–5758.

8

[46] D. Gabay, “Applications of the method of multipliers to
variational inequalities,” in Studies in Mathematics and its
Applications, 1983, vol. 15, pp. 299–331.

