Spike-Based Winner-Take-All Computation:
Fundamental Limits and Order-Optimal Circuits

arXiv:1904.10399v1 [q-bio.NC] 21 Apr 2019

Lili Su
Computer Science & Artificial Intelligence Laboratory
Massachusetts Institute of Technology
lilisu@mit.edu
Chia-Jung Chang
Brain and Cognitive Sciences
Massachusetts Institute of Technology
chiajung@mit.edu
Nancy Lynch
Computer Science & Artificial Intelligence Laboratory
Massachusetts Institute of Technology
lynch@csail.mit.edu
April 24, 2019
Abstract
Winner-Take-All (WTA) refers to the neural operation that selects a (typically small) group of neurons
from a large neuron pool. It is conjectured to underlie many of the brain’s fundamental computational
abilities. However, not much is known about the robustness of a spike-based WTA network to the inherent
randomness of the input spike trains. In this work, we consider a spike-based k–WTA model wherein n
randomly generated input spike trains compete with each other based on their underlying statistics, and
k winners are supposed to be selected. We slot the time evenly with each time slot of length 1 ms, and
model the n input spike trains as n independent Bernoulli processes. The Bernoulli process is a good
approximation of the popular Poisson process but is more biologically relevant as it takes the refractory
periods into account. Due to the randomness in the input spike trains, no circuits can guarantee to
successfully select the correct winners in finite time. We focus on analytically characterizing the minimal
amount of time needed so that a target minimax decision accuracy (success probability) can be reached.
We first derive an information-theoretic lower bound on the decision time. We show that to have a
(minimax) decision error ≤ δ (where δ ∈ (0, 1)), the computation time of any WTA circuit is at least
((1 − δ) log(k(n − k) + 1) − 1)TR ,
where TR is a difficulty parameter of a WTA task that is independent of δ, n, and k. We then design a
simple WTA circuit whose decision time is
  


1
O
log
+ log k(n − k) TR .
δ
It turns out that for any fixed δ ∈ (0, 1), this decision time is order-optimal in terms of its scaling in n,
k, and TR .

1

Introduction

Humans and animals can form a stable perception and make robust judgments under ambiguous conditions. For example, we can easily recognize a dog in a picture regardless of its posture, hair color, and
1

whether it stands in the shadow or is occluded by other objects. One fundamental feature of brain computation is its robustness to the randomness introduced at different stages, such as sensory representations
[KK01, HW59], feature integration [KTA+ 03, MCM07], decision formation [PG99, SN01], and motor planning [HW98, LCG+ 15]. It has been shown that neurons encode information in a stochastic manner in the
brain [BAB+ 97, KRR00, MA09, FDMM18]; even when the exact same sensory stimulus is presented or when
the same kinematics are achieved, no deterministic patterns in the spike trains exist. Facing environmental
ambiguity, humans and animals adaptively refine their behaviors by incorporating prior knowledge with
their current sensory measurements [FSW08, KP04, SS06, EB02, KW04]. Nevertheless, it remains relatively
unclear how neurons carry out robust computation facing ambiguity. Sparse coding is a common strategy in
brain computation; to encode a task-relevant variable, often only a small group of neurons from a large neuron pool are activated [OF04, POMT+ 02, HDZ08, QKKF08, KF08, RPG99]. Understanding the underlying
neuron selection mechanism is highly challenging.
Winner-Take-All (WTA) is a hypothesized mechanism to select proper neurons from a competitive network of neurons, and is conjectured to be a fundamental primitive of cognitive functions such as attention and
object recognition [RP99, IKN98, YG98, Maa00]. Among these studies, it is commonly assumed that neurons
transmit information with a continuous variable such as the firing rate. This assumption, however, ignores
how temporal coding may additionally contribute to cortical computations. For example, some neurons in the
auditory cortex will respond to auditory events with bursts at a fixed latency [GKvHW96, Nel04]. This phaselocking property is also observed in the hippocampus as well as the prefrontal cortex [SLW05, HSM06, BC95].
Another feature that has been neglected in a rate-based model is the inherent noise in the inputs. Although
some studies used additive Gaussian noise [KCF17, LLW13, LIKB99, RV06] to account for input randomness, such WTA circuits are very sensitive to noise and could not successfully select even a single winner
unless extra robustness strategy such as an additional nonlinearity is introduced into the dynamics [KCF17].
Last but not least, neurons have a refractory period, which prevents spikes from back propagating in axons
[BIM98], and such a feature is usually neglected in the rate-based models. In contrast, a spike-based model
may capture these neglected features. Nevertheless, how WTA computation can be implemented and its
algorithmic characterization remains relatively under-explored.
In this paper, we study a spike-based k-WTA model wherein n randomly generated input spike trains are
competing with each other with their underlying statistics, and the true winners are the k input spike trains
whose underlying statistics are higher than others. More precisely, we slot the time evenly with each time
slot of length 1 ms. We assume that these n input spike trains are generated by n independent Bernoulli
processes with different rates. An abstract example is depicted in Figure 1. We use Bernoulli processes to
capture the randomness in the input spike trains rather than using the popular Poisson processes because a
Bernoulli process can be viewed as the time-slotted version of a refractory-period-modified Poisson process;
it is well-known that due to the existence of refractory periods, a neuron cannot spike twice within 1 ms.
We focus on analytically characterizing the minimal amount of time needed so that a target minimax
decision accuracy (success probability) can be reached. We first derive a lower bound on the decision time
for a given decision accuracy. We show that no WTA circuits can have a computation time strictly less than
((1 − δ) log(k(n − k) + 1) − 1)TR ,

(1)

where TR is a parameter defining the difficulty to distinguish between two spike trains with different statistics
in a WTA task, n is the number of input spike trains, k is the number of winners, and δ is the given target
decision accuracy. In many practical settings we care about the sparse coding region where k  n. Our
lower-bound is obtained by an information-theoretic argument, and holds for all WTA circuits without
restricting their circuit architectures and their adopted activation functions. Throughout this paper, we are
interested in the decision time’s scaling in n, k, and TR , while treating δ ∈ (0, 1) as a fixed small constant.
Not surprisingly, the above lower bound grows with the network size n when other parameters are fixed. This
is because the larger n, the noisier the WTA competition. Similarly, when n and k are fixed, the easier to
distinguish two spike trains with different statistics (i.e., the smaller TR ), the shorter the necessary decision
time is.
We construct a simple circuit whose decision time is
 
  
1
+ log k(n − k) TR .
O
log
δ
2

Input spike train 1
Input spike train 2

.
.
.

a WTA circuit

output

k selected
winners

Input spike train n
Figure 1: In this figure, n randomly generated input spike trains are fed to a WTA circuit as the circuit
input. Clearly, no deterministic patterns can be read off from these spike trains. Here, we do not specify
the output of a WTA circuit because the detailed specifications of the circuits’ outputs might vary with the
corresponding applications.
It turns out that for any fixed δ ∈ (0, 1), this decision time is order-optimal in terms of its scaling in n,
k, and TR , i.e., its decision time matches the lower-bound in (1) up to a constant multiplicative factor. In
our circuit, each output neuron is a thresholded accumulator unit whose threshold is determined by δ, k, n,
and TR , and the circuit’s output is the first group of k output neurons that spike in the same time. The
typical dynamics under our circuit are: the number of output neurons that spike simultaneously (i.e., spike
at the same time) is monotonically increasing until exactly k output neurons spike simultaneously. The
simultaneous spikes of these k output neurons cause strong inhibition of other output neurons;
 in particular,
no other output neuron can spike within a sufficiently long period Ω log 1δ + log k(n − k) TR .
In addition, our results also give a set of testable hypotheses on neural recordings and humans’/animals’
behaviors in decision-making. For instance, given the number of input spike trains and the number of true
winners, our results can provide an estimate of the minimum decision time needed, which can provide some
insights on the efficiency of a WTA circuit in terms of decision time. As another example, when two animals
are involved in the same experiment, if both animals reach the same accuracy in discriminating two objects,
does the animal that decides faster have more heterogeneous distributions of input spiking activities, i.e.,
smaller TR ? Our results provide partial answers to this question.

2

Computational Model: Spiking Neuron Networks

In this section, we provide a general description of the computation model used. There is much freedom in
choosing the detailed specification of the model. In particular, in Section 5 we provide a circuit construction
(for solving the k–WTA competition) under this computation model.

2.1

Network Structure

A spiking neuron network (SNN) N = (U, E) consists of a collection of neurons U that are connected through
synapses E. We assume that a SNN can be conceptually partitioned into three non-overlapping layers: input
layer Nin , hidden layer Nh , and output layer Nout ; the neurons in each of these layers are referred to as input
neurons, hidden neurons, and output neurons, respectively. The synapses E are essentially directed edges, i.e,
E := {(ν, ν 0 ) : ν, ν 0 ∈ U }. For each ν ∈ U , define PREν := {ν 0 : (ν 0 , ν) ∈ E} and POSTν := {ν 0 : (ν, ν 0 ) ∈ E}.
Intuitively, PREν is the collection of neurons that can directly influence neuron ν; similarly, POSTν is the
collection of neurons that can be directly influenced by neuron ν. 1 We assume that the input neurons cannot
be influenced by other neurons in the network, i.e., PREν = ∅ for all ν ∈ Nin . Each edge (ν, ν 0 ) in E has
a weight, denoted by w(ν, ν 0 ). The strength of the interaction between neuron ν and neuron ν 0 is captured
1 In the languages of computational neuroscience, the incoming neighbors and outgoing neighbors are often referred to as
pre-synaptic units and post-synaptic units.

3

...

Input layer

Hidden layer

...

Output layer

Figure 2: A SNN consists of three layers: the input layer, the output layer, and the hidden layer. The hidden
neurons might connect to both the input neurons and the output neurons to assist the computation of the
neuron network. Neurons are connected through synapses. WTA circuits is a family of SNNs in which the
number of output neurons equals the number of the input neurons.
as |w(ν, ν 0 )|. The sign of w(ν, ν 0 ) indicates whether neuron ν excites or inhibits neuron ν 0 : In particular, if
neuron ν excites neuron ν 0 , then w(ν, ν 0 ) > 0; if neuron ν inhibits neuron ν 0 , then w(ν, ν 0 ) < 0. The set
E might contain self-loops with w(ν, ν) capturing the self-excitatory/self-inhibitory effects. An example of
SNNs can be found in Figure 2.
Generic network structure for WTA circuits The family of WTA circuits under consideration is
rather generic. We only assume that |Nin | = |Nout | = n the numbers of the input neurons and of the output
neurons are equal. For ease of exposition, denote
Nin = {u1 , · · · , un } , and Nout = {v1 , · · · , vn } .
The hidden neuron subset Nh can be arbitrary. The output neurons and the hidden neurons may be
connected to each other in an arbitrary manner.

2.2

Network State

In a SNN, the communication among neurons is abstracted as spikes. We assume each neuron ν has two local
variables: spiking state variable S(ν) and memory state variable M (ν). Nevertheless, for input neurons, we
only consider their spiking states, assuming that their memory states are not influenced by the dynamics of
the spiking neuron network under consideration. We slot the time evenly with each time slot of length 1 ms.
Let t = 1, 2, · · · be the indices of the time slots. Henceforth, by saying time t, we mean the time interval
[t − 1, t) ms. For t ≥ 1, let St (ν) ∈ {0, 1} be the spiking state of neuron ν at time t indicating whether neuron
ν spikes at time t or not. By convention, S0 (ν) := 0. For a non-input neuron ν and for t ≥ 1, let Mt (ν) be
the memory state of neuron ν at time t summarizing the cumulative influence caused by the spikes of the
neurons in PREi during the most recent m times, i.e., times t − 1, t − 2, · · · , t − m. Concretely, let Vt (ν) be
the charge of (non-input) neuron ν at time t (for t ≥ 1) defined as
X
Vt (ν) :=
w(ν 0 , ν)St (ν 0 ).
ν 0 ∈PREν

Clearly, V0 (ν) = 0. Let Vtν be the sequence of length m such that
Vtν := [Vt (ν), · · · , Vt−m+1 (ν)] ,
and let St (ν) be the sequence of length m such that
Stν := [St (ν), · · · , St−m+1 (ν)] .
4

By convention, when 0 ≤ t ≤ m, let
Vtν := [Vt (ν), · · · , V0 (ν), 0, · · · , 0]
and
Stν := [St (ν), · · · , S0 (ν), 0, · · · , 0] .
ν
ν
For t ≥ 1, define the memory variable Mt (ν) as a pair of vectors St−1
and Vt−1
, i.e.,

ν
ν
Mt (ν) := St−1
, Vt−1
.

By convention, let M0 (ν) := (0, 0), where 0 is the length m zero vector.
At time t + 1, the memory variable Mt+1 (ν) is updated by shifting the two sequences forwards by one
time unit – fetching in St (ν) and Vt (ν), respectively, and removing St−m (ν) and Vt−m (ν), respectively. The
memory state Mt (ν) is known to neuron ν only, and it can influence the probability of generating a spike at
time t through an activation function φν , i.e.,
St (ν) = φν (Mt (ν)) , ∀ t ≥ 0.

(2)

Notably, φν might be a random function.
In most neurons, the synaptic plasticity time window is about 80 -120 msec, but could also vary across
brain regions, and vary across different time scales under different behavioral contexts. In a sense, the
synaptic plasticity time window is closely related to m. As can be seen in Section 5, our order-optimal WTA
circuit construction requires m to be sufficiently high. Nevertheless, this does not exclude the application of
our WTA circuit to the contexts where m is small. This is because the memory variable can be implemented
by a chain of hidden neurons near neuron ν. The detailed implementation of the local memory does not
affect the order optimality of our WTA circuit.

3
3.1

Minimax Decision Accuracy/Success Probability
Random Input Spike Trains

We study the k–WTA model, wherein n randomly generated input spike trains are competing with each
other, and, as a result of this competition, k out of them are selected to be the winners. In contrast, most
existing works [VRP+ 18, Maa97, LMP16] assume deterministic input spike trains.
Recall that time is slotted into intervals of length 1 ms. We assume that the n input spike trains are
generated from n independent Bernoulli processes with unknown parameters p1 , · · · , pn , respectively. We
refer to p = [p1 , · · · , pn ] as a rate assignment of the WTA competition. For example, suppose there are
2 input spike trains with rates 0.6 and 0.8, respectively, i.e., n = 2 and p = [0.6, 0.8]. In each time, with
probability 0.6 the first input spike train has a spike independently from whether the second input spike
train has a spike or not; similarly for the second input spike train.
Note that in the most general scenario the spikes of the input neurons might be correlated; see Section
6 for detailed comments. We would like to explore the more general input spikes in our future work.

3.2

Minimax Performance Metric

We adopt the minimax framework [Wu17] (in which the circuit designer and nature play games against each
other) to evaluate the performance (decision accuracy versus decision time) of a WTA circuit.
Let R ⊆ [c, C] be an arbitrary but finite set of rates where c and C are two absolute constants such
that 0 < c < C < 1. A rate assignment p is chosen by nature from Rn for which there exists a subset of
[n] := {1, · · · , n}, denoted by W(p), such that
|W(p)| = k, and pi > pj ∀ i ∈ W(p), j ∈
/ W(p)

5

(3)

– recall that |·| is the cardinality of a set. We refer to set W(p) as the true winners with respect to the rate
assignment p. For example, suppose n = 5, k = 2, and
p = [p1 = 0.2, p2 = 0.1, p3 = 0.2, p4 = 0.8, p5 = 0.85] .
Here the true winners are 4 and 5, i.e., W(p) = {4, 5}. In this paper, we consider the following collection of
rate assignments, denoted by AR:
AR := {p : p ∈ Rn , & ∃W(p) ⊆ [n] s.t. |W(p)| = k, and pi > pj ∀ i ∈ W(p), j ∈
/ W(p)} .

(4)

For each of reference, we refer to an element in AR as an admissible rate assignment. Recall that the input
T
of a WTA circuit is a collection of n independent spike trains. For a given rate assignment p, let {St (ui )}t=1
denote the spike train of length T at input neuron ui . The circuit designer wants to design a WTA circuit
d of W(p) for any choice of rate assignment p in AR. Note that
that outputs a good guess/estimate win
conditioning on
i
h
T
T
S := {St (u1 )}t=1 , · · · , {St (un )}t=1 ,
d is independent of p. Here S is used with a little abuse of notation as this notation hides
the estimate win
its connection with T and the rate parameter p. 2 Later, we use the same notation to denote the n spike
trains with random rate assignment, i.e., where p is randomly generated. Nevertheless, this abuse of notation
significantly simplifies the exposition without sacrificing clarity. In particular, we will specify the underlying
rate assignment when it is not clear from the context.
Under minimax framework, we are interested in the minimax error probability 3
n
o
d (S) 6= W(p) .
min max P win
(5)
d p∈AR
win

d
For a given ndeterministic WTA
o circuit win (i.e., the activation functions used are deterministic), the probd (S) 6= W(p) is taken w.r.t. the randomness in the stochastic spikes of each input neuron;
ability in P win
d (i.e., the activation functions are stochastic), in addition to the aforemenfor a randomized WTA circuit win
n
o
d (S) 6= W(p) is also taken w.r.t. the randomness in
tioned source of randomness, the probability in P win
the activation functions. In (5), the performance metric of a WTA circuit is the worst-case error probability
n
o
d (S) 6= W(p) .
max P win
p∈AR

Essentially, the statistical inference problem can be viewed as a game between the circuit designer and
nature.

4

Information-Theoretic Lower Bound on Decision Time

In this section, we provide a lower bound on the decision time for a given decision accuracy. The lower
bounds derived in this section hold universally for all possible network structures (including the hidden
layer), synapse weights, and the activation functions.
One observation is that the decision time is naturally lower bounded by the sample complexity, which
is closely related to the Kullback-Leibler (KL) divergence4 between two Bernoulli distributions. The KL
divergence between Bernoulli random variables with parameters r and r0 , respectively, is defined as


r
1−r
0
,
(6)
d(r k r ) := r log 0 + (1 − r) log
r
1 − r0
h
i
T
more rigorous notation should be S(T, p) := {St (u1 )}T
t=1 , · · · , {St (un )}t=1 . We use S for S(T, p) for ease of exposition.
3 In the following expression, the min should really be an inf, but we abuse notation here for ease of exposition. In addition,
the max really is a max as the set R under consideration is of finite size.
4 The Kullback-Leibler (KL) divergence gauges the dissimilarity between two distributions.
2A

6

where, by convention, log 00 := 0. Notably, d(· k ·) is not symmetric in r and r0 . In addition, when r 6= 0
and r0 = 0 or 1, d(r k r0 ) = ∞. Recall that set R is an arbitrary but finite set that are contained in the
interval [c, C], where c, C ∈ (0, 1). It holds that d(r k r0 ) < ∞ for all r, r0 ∈ R. For the more general
distributions over a common discrete alphabet A, say distributions P and Q, the Kullback-Leibler (KL)
divergence between P and Q is defined as follows.
Definition 1 (KL-divergence). Let A be a discrete alphabet (finite or countably infinite), and P and Q be
two distributions over A. Then define


X
P (a)
,
D(P k Q) :=
P (a) log
Q(a)
a∈A

where 0 · log


0
0

= 0 by convention.

Note that D(P k Q) ≥ 0 and D(P k Q) = 0 if and only if P = Q almost surely. Similar to d(· k ·),
D(P k Q) is not symmetric in P and Q. In this paper, we choose the base to be 2. 5 Recall that the set of
admissible rate assignments AR is defined in (4).
Lemma 2. Fix a finite set R. Let p = [p1 , · · · , pn ] and q = [q1 , · · · , qn ] be two rate assignments in AR.
Let PS and QS be the distributions of the n spike sequences of the input neurons under rate assignments p
and q, respectively. Then,
n
X
D(PS k QS ) = T
d(pi k qi ).
i=1

Lemma 2 is proved in Appendix B.
For the given R, define task complexity TR as
TR :=

max

r1 ,r2 ∈R s.t. r1 6=r2

1
.
d(r2 k r1 ) + d(r1 k r2 )

(7)

It is closely related to the smallest KL divergence between two distinct statistics in R. The task complexity
TR kicks in due to the adoption of minimax decision framework (5).
The following lemma is used in the proof of our information-theoretic lower bound. This is a technical
supporting lemma, and the choice of the specific rate assignments is due to some technical convenience in
proving Theorem 4.


Lemma 3. For any finite set R, let r1 , r2 ∈ R such that r1 6= r2 . Let p0 = p01 , · · · , p0n be
(
r1 ,
if ` = 1, · · · , k;
p0` =
(8)
r2 ,
otherwise.
For i = 1, · · · , k and j = k + 1, · · · , n, define rate assignment pij as

0

if ` 6= i, 6= j;
p` ,
ij
0
p` = pj ,
if ` = i;

 0
pi ,
if ` = j.
Let Xp be a random rate assignment. If Xp is uniformly distributed over

{p0 } ∪ pij : i = 1, · · · , k, & j = k + 1, · · · , n ,
then the mutual information I(Xp ; S) satisfies the following:
I(Xp ; S) ≤ T (d(r2 k r1 ) + d(r1 k r2 )) .
5 Note

that any base would work, see [PW14, Chapter 1.1].

7

See Appendix A for definition of I(· ; ·). The proof of Lemma 3 can be found in Appendix C.
It turns out that if the input spike train length T is not sufficiently large (specified in Theorem 4), no
matter how elegant the design of a WTA circuit is (no matter which activation function we choose, how many
hidden neurons we use, and how we connect the hidden neurons and output neurons), its actual decision
accuracy is always lower than the target decision accuracy 1 − δ.
Theorem 4. For any 1 ≤ k ≤ n − 1 and any set R and any δ ∈ (0, 1), if
T ≤ ((1 − δ) log(k(n − k) + 1) − 1) TR ,
then
n
o
d (S) 6= W(p) ≥ δ,
min max P win
d p∈AR
win

where the min is taken over all possible WTA circuits with different choices of activation functions and
circuit architectures.
Theorem 4 says that if T < ((1 − δ) log(k(nn− k) + 1) − 1) TRo
, the worst case probability error of any
d
WTA circuit is greater than δ, i.e., maxp∈AR P win (S) 6= W(p) > δ. Theorem 4 is proved in Appendix
E.
Remark 5 (Tightness of the lower bound in Theorem 4). Following our line of argument, by considering
a richer family of critical rate assignments in Lemma 3, we might be able to obtain a tighter lower bound.
Nevertheless, the constructed WTA circuit in Section 5 turn out to be order-optimal – its decision time
matches the lower bound in Theorem 4 up to a multiplicative constant factor. This immediately implies
that the lower bound obtained in Theorem 4 is tight up to a multiplicative constant factor.

5

Order-Optimal WTA Circuits

In Section 2.1, we provided a general description of the computation model we are interested in. In this
section, we construct a specific WTA circuit under this general computation model. This WTA circuit turns
out to be order-optimal in terms of decision time – the decision time of our WTA circuit matches the lower
bound in Section 4 up to a multiplicative constant factor. To do that, we need to specify (1) the network
structure, including the number of hidden neurons, the collection of synapses (directed communication links)
between neurons, and the weights of these synapses; (2) the memorization capability of each neuron, i.e.,
the magnitude of m; and (3) φν – the activation function used by neuron ν.

5.1

Circuit Design

In our designed circuit, there are four parameters R, m, b, and δ, where R ⊆ [c, C] 6 is a finite set from
which the pi ’s of the input spike trains are chosen, m is the memory range and b is the bias at the non-input
neurons, and (1 − δ) is the target decision accuracy (i.e., success probability). Here, we assume that every
non-input neuron has the same bias, i.e., bν = b for all non-input neurons ν. The four parameters R, m,
b, and δ can be viewed as some prior knowledge of the WTA circuit; they might be learned through some
unknown network development procedure which is outside the scope of this work. In Sections 5.1.1, 5.1.3,
and 5.1.4, we present the network structure and the activation functions adopted, and the requirement on
m. For completeness, we specify the local memory update (in particular the vector V ) separately in Section
5.1.2. The dynamics of our WTA circuit is summarized in Section 5.1.5.
5.1.1

Network structure:

We propose a WTA circuit with the following network structure:
6 Recall that c, C ∈ (0, 1) are two absolute constants, i.e., they do not change with other parameters of the WTA circuit
such as n, k, and δ.

8

• All output neurons are connected to each other by a complete graph. That is, (vi , vj ) ∈ E for all
vi , vj ∈ Nout such that vi 6= vj ;
• Each edge from an input neuron to an output neuron has weight 1, i.e., w(ui , vi ) = 1 for all ui ∈
Nh , vi ∈ Nout .
• All edges among the output neurons have weights − k1 . That is, w(vi , vj ) = − k1 for all vi , vj ∈ Nout
such that vi 6= vj .
• There are no hidden neurons, i.e., Nh = ∅;
5.1.2

Update local charge vector:

With the above choice of network structure, the charge Vt−1 (vi ) at the output neuron vi at time t − 1 is
Vt−1 (vi ) = St−1 (ui ) −

1
k

X

St−1 (vj ).

j:1≤j≤n,& j6=i

Notably, Vt−1 (vi ) ∈ [−1, 1] for all t ≥ 1 and output neuron vi . When k = 1, the above update becomes
X
Vt−1 (vi ) = St−1 (ui ) −
St−1 (vj ).
j:1≤j≤n,& j6=i

which can be viewed as a spike model counterpart of the potential update under the traditional continuous
rate model [KCF17, MM07] with lateral inhibition.
It is easy to see the following claims hold. For brevity, their proofs are omitted.
P
Claim 6. For t ≥ 1 and for i = 1, · · · , n, Vt−1 (vi ) > 0 if and only if St−1 (ui ) = 1 and j:1≤j≤n,& j6=i St−1 (vj ) ≤
k − 1, i.e., at time t − 1, input neuron ui spikes, and fewer than k − 1 other output neurons spike.
P
Claim 7. For t ≥ 1 and for i = 1, · · · , n, Vt−1 (vi ) ≤ −1 only if j:1≤j≤n,& j6=i St−1 (vj ) ≥ k, i.e., at time
t − 1, more than k other output neurons spike.
P
Note P
that j:1≤j≤n,& j6=i St−1 (vj ) ≥ k is not a sufficient condition to have Vt−1 (vi ) ≤ −1. To see this,
suppose j:1≤j≤n,& j6=i St−1 (vj ) = k and St−1 (ui ) = 1. In this case it holds that Vt−1 (vi ) = 0.
Claim 8. For t ≥ 1 and
P for i = 1, · · · , n, if Vt−1 (vi ) = 0, one of the following holds:
(1) St−1 (ui ) = 1 and j:1≤j≤n,& j6=i St−1 (vj ) = k, i.e., at time t − 1, input neuron ui spikes, and exactly k
other output neurons spike;
P
(2) St−1 (ui ) = 0 and j:1≤j≤n,& j6=i St−1 (vj ) = 0, i.e., at time t − 1, input neuron ui does not spike, and
no other output neurons spike.
5.1.3

Activation functions:

There are many different choices of activation functions; see [wik] for a detailed list. In our construction, we
use a simple threshold activation function, i.e.,
(
Pm

Pm
1, if (b − 1)1{St−1 (vi )=1} +
r=1 1{Vt−r (vi )>0} − m
r=1 1{Vt−r (vi )≤−1} + ≥ b;
St (vi ) =
0, otherwise,
[·]+ = max [·, 0], and b > 0 is the bias at neuron vi for i = 1, · · · , n. It is easy to see that this activation
function falls under the general form given by (2).
Remark 9. If the output neuron vi does not spike at time t − 1, i.e., St−1 (vi ) = 0, then in order for vi to
spike at time t, the following needs to hold:
"m
#
m
X
X
1{Vt−r (vi )>0} − m
1{Vt−r (vi )≤−1}
≥ b.
r=1

r=1

9

+

In contrast, if the output neuron vi does spike at time t − 1, i.e., St−1 (vi ) = 1, then
"m
#
m
X
X
1{Vt−r (vi )>0} − m
≥1
1{Vt−r (vi )≤−1}
r=1

r=1

+

is enough for vi to spike at time t. That is, under our activation rule, St−1 (vi ) = 1 makes the activation of
vi much easier in the next round. However, if there exists r ∈ {1, 2, · · · , m} such that
1{Vt−r (vi )≤−1} = 1,
then
m
X

1{Vt−r (vi )>0} − m

m
X

r=1

1{Vt−r (vi )≤−1} ≤

r=1

m
X

1{Vt−r (vi )>0} − m

r=1

≤ m − m = 0.
Thus,
"
(b − 1)1{St−1 (vi )=1} +

m
X

1{Vt−r (vi )>0} − m

m
X

#
1{Vt−r (vi )≤−1}

r=1

r=1

+

= (b − 1)1{St−1 (vi )=1} + 0
≤ b − 1 < b,
i.e., the output neuron vi does not spike at time t. In other words, as long as there exists r ∈ {1, 2, · · · , m}
such that 1{Vt−r (vi )≤−1} = 1, the activation of vi is inhibited at time t.
5.1.4

Local memorization capability:

In our proposed circuit, we require that m satisfies the following:
  

3
8C 2 (1 − c)
log
+ log k(n − k) TR := m∗
m≥ 2
c (1 − C)
δ

(9)

for target decision accuracy 1 − δ ∈ (0, 1). In addition, we set b = cm∗ . Recall that c, C ∈ (0, 1) are two
absolute constants that are lower bound and upper bound of any R, respectively.
Intuitively, when other parameters are fixed, the higher the desired accuracy (i.e., the smaller δ) , the
larger m∗ , i.e., the more memory is needed for selecting the winners in our WTA circuit. Similarly, the easier
to distinguish two spike trains with different statistics (i.e., the lower TR ), the smallerm∗ . Interesting, with
other parameters fixed, m∗ depends
on k as follows: m∗ is increasing in k when k ∈ 1, · · · , b n2 c , and m∗
 n
is decreasing in k when k ∈ d 2 e, · · · , n − 1 . In many practical settings we care about the region where
k  n. Besides, with the choice of bias b = cm∗ , the larger m∗ also implies longer time is needed for our
WTA circuit to declare k winners; details can be found (1) in Theorem 10.
On the other hand, in most neurons the synaptic plasticity time window is about 80-120 ms, and it is
unclear whether (9) can be immediately satisfied or not. Fortunately, even if (9) is not immediately satisfied
by a neuron due to its local bio-plausibility, it is possible that its local memory might be realized using a
chain of hidden neurons.
5.1.5

Algorithm 1

The dynamics of our WTA circut is summarized in Algorithm 1, which is fully determined by what has been
described in Sections 5.1.1, 5.1.2, 5.1.3, and 5.1.4. For Algorithm 1, we declare the first k output neurons
that spike simultaneously to be winners.

10

Algorithm 1: k–WTA
1

Input: R, m, b, and δ.

2

for t ≥ 1 do
P
At output neuron vi for i = 1, · · · , n: Vt−1 (vi ) ← St−1 (ui ) − k1 j:1≤j≤n,&j6=i St−1 (vj );
Vt−1 (vi ) ← [Vt−1 (vi ), Vt−2 (vi ), · · · , Vt−m (vi )];
St−1 (vi ) ← [St−1 (vi ), St−2 (vi ), · · · , St−m (vi )];
Mt (vi ) ← (Vt−1 (vi ), St−1 (vi ));

Pm
Pm
if (b − 1)1{St−1 (vi )=1} +
r=1 1{Vt−r (vi )≤−1} + ≥ b then
r=1 1{Vt−r (vi )>0} − m
St (vi ) ← 1.
else
St (vi ) ← 0.

3
4
5
6
7
8
9
10

5.2

Circuit Performance

Recall that W(p) and m∗ are defined in (3) and (9), respectively.
Theorem 10. Fix δ ∈ (0, 1], and 1 ≤ k ≤ n − 1. Choose m ≥ m∗ and b = max {cm∗ , 2}. Then for any
admissible rate assignment p, with probability at least 1 − δ, the following hold:
(1) There exist k output neurons that spike simultaneously by time m∗ .
(2) The first set of such k output neurons are the true winners W(p).
(3) From the first time in which these k output neurons spike simultaneously, these k output neurons spike
consecutively for at least b times, and no other output neurons can spike within b times.
The proof of Theorem 10 can be found in Appendix F. The first bullet in Theorem 10 implies that our
WTA circuit can provide an output (a selection of k output neurons) by time m∗ ; the second bullet in
Theorem 10 says that the circuit’s output indeed corresponds to the k true winners; and the third bullet
says that the k simultaneous spikes of the selected winners are stable – the k selected winners continue to
spike consecutively for at least b times. The proof of Theorem 10 essentially says that with high probability,
under Algorithm 1, the number of output neurons that spike simultaneously is monotonically increasing until
it reaches k. Upon the simultaneous spike of k output neurons, by our threshold activation rule, we know
that the other output neurons are likely to be inhibited. In particular, if these k output neurons are the first
k output neurons that spike simultaneously, then the activation of the other output neurons are likely to be
inhibited for at least b times.
Remark 11 (Controlling stability). As can be seen from the proof of Theorem 10, in the activation function
of Algorithm 1
"m
#
m
X
X
(b − 1)1{St−1 (vi )=1} +
1{Vt−r (vi )>0} − m
1{Vt−r (vi )≤−1}
≥b
r=1

r=1

+

the first term (b − 1)1{St−r (vi )=1} is crucial in achieving (3) in Theorem 10. In fact, we can increase the
stability period by introducing a stability parameter s such that 1 < s ≤ m and modifying the activation
rule. Details can be found in Algorithm 2. It is easy to see that the activation function falls under the general
form in (2). In the new activation function in Algorithm 2, for output neuron vi , once it spikes, it continues
to spike for at least s times. Following our line of analysis in the proof of Theorem 10, it can be seen that
the declared k winners, from the first time they spike simultaneously, continue to spike consecutively for at
least s times.
Remark 12 (Order-optimality). The decision time performance stated in (1) of Theorem 10 matches the
information-theoretical lower bound in Theorem 4 up to a multiplicative constant factor both (a) when δ is
sufficiently small and does not depend on n, k, TR , c, and C, and (b) when δ decays to zero at a speed at
1
most (k(n−k))
c0 where c0 > 0 is some fixed constant. The detailed order-optimality argument is given next.
11

Algorithm 2: k–WTA
1

Input: R, m, b, δ, and s where 1 < s ≤ m.

2

for t ≥ 1 do

3
4
5
6
7
8
9
10
11
12
13
14

At output neuron vi for i = 1, · · · , n:
P
Vt−1 (vi ) ← St−1 (ui ) − k1 j:1≤j≤n,&j6=i St−1 (vj );
Vt−1 (vi ) ← [Vt−1 (vi ), Vt−2 (vi ), · · · , Vt−m (vi )];
St−1 (vi ) ← [St−1 (vi ), St−2 (vi ), · · · , St−m (vi )] ;
M
t (vi ) ← (Vt−1 (vi ), St−1 (vi )).

P
Pm
m
if
r=1 1{Vt−r (vi )>0} − m
r=1 1{Vt−r (vi )≤−1} + ≥ b then
St (vi ) ← 1.
else
if St−1 (vi ) = 1 and ∃ r ∈ {2, · · · , s} such that St−r (vi ) = 0 then
St (vi ) ← 1.
else
St (vi ) ← 0.

Suppose that δ is sufficiently small and does not depend on n, k, TR , c, and C Here, for ease of
exposition, we illustrate the order-optimality with a specific choice of δ. In fact, the order-optimality holds
generally for constant δ ∈ (0, 1) as long as it does not depend on n, k, TR , c, and C.
Suppose the target decision accuracy is 1 − δ = 0.9, i.e., δ = 0.1. Then as long as n ≥ 31, for any
1 ≤ k ≤ n − 1,


8C 2 (1 − c)
3
16C 2 (1 − c)
m∗ = 2
log
+ log k(n − k) TR ≤ 2
log k(n − k)TR .
c (1 − C)
0.1
c (1 − C)
On the other hand, recall from Theorem 4 that to have δ = 0.1, the decision time is no less than
((1 − δ) log(k(n − k) + 1) − 1) TR ≥

1
1
log(k(n − k) + 1)TR ≥ log k(n − k)TR
2
2

where the first inequality holds as long as n ≥ 8. Thus, when n ≥ 31, in order to achieve the decision
accuracy 1 − δ = 0.9, the decision time of our WTA circuit is on the same order of the information-theoretic
lower bound in Theorem 4.
Suppose δ decays to zero at a moderate speed The decision time of our WTA circuit is order-optimal
3
even for diminishing decision error δ as long as δ = Ω( (k(n−k))
c0 ) where c0 > 0 – it does not decay to zero
3
“too fast” in k(n − k). To see this, let δ = (k(n−k))c0 for some constant c0 > 0. We have
8C 2 (1 − c)
c2 (1 − C)

log

3

!

3
(k(n−k))c0

!
+ log k(n − k) TR =

8C 2 (1 − c)(c0 + 1)
log k(n − k)TR .
c2 (1 − C)

(10)

Resetting circuit when the input spike trains become quiescent In Algorithm 1, if the input spike
trains become quiescent, then the corresponding circuits also become quiescent despite some delay in this
response.
Lemma 13. If all input neurons are quiescent at time t0 , and remain to be quiescent for all t ≥ t0 , then
Vt (vi ) = 0 and St (vi ) = 0 for any t > t0 + m.
Lemma 13 is proved in Appendix D.

12

6

Discussion

In this paper, we investigated how k-WTA computation is robustly achieved in the presence of inherent
noise in the input spike trains. In a spike-based k-WTA model, n randomly generated input spike trains are
competing with each other, and the top k neurons with highest underlying statistics are the true winners.
Given the stochastic nature of the spike trains, it is not trivial to properly select winners among a group
of neurons. We derived an information-theoretic lower bound on the decision time for a given decision
accuracy. Notably, this lower bound holds universally for any WTA circuit that falls within our model
framework, regardless of their circuit architectures or their adopted activation functions. Furthermore, we
constructed a circuit whose decision time matches this lower bound up to a constant multiplicative factor,
suggesting that our derived lower bound is order-optimal. Here the order-optimality is stated in terms of its
scaling in n, k, and TR .

6.1

Comparison to previous WTA models

Randomness is introduced at different stages of brain computation and the stochastic nature of the spike
trains are well observed [BAB+ 97, KRR00, MA09, FDMM18]. In our work, we focused on how to robustly
achieve k-WTA computation in face of the intrinsic randomness in the spike trains. A common WTA
model assumes that neurons transmit information by a continuous variable such as firing rate [DA01], which
ignores the intrinsic randomness in spiking trains. Although some studies used additive Gaussian noise
[KCF17, LLW13, LIKB99, RV06] in their rate-based WTA circuits to account for input randomness, these
circuits are usually very sensitive to noise and could not successfully select even a single winner unless
additional non-linearity is added [KCF17]. In fact, a neuron with a second non-linearity is similar to an
output neuron in our constructed WTA circuit in that they both integrate their local inputs. Unfortunately,
only simulation results were provided in [KCF17]; a theoretical justification of why such second non-linearity
makes their WTA circuit robust to input noise is lacking. Though we focused on spike-based model, we hope
our results can provide some insights for the rate-based model as well. On top of that, a rate-based model
would require a high communication bandwidth, yet communication bandwidth is limited in the brain. Our
spiking neural network model captures this feature by having a low communication cost, since it broadcasts
1 bit only.
However, we did not try to model every biologically relevant feature. In several studies using spiking
network models, individual units are often modeled with details like ion channels and specific synaptic
connectivity. Though more biologically relevant than our spiking neuron network model, those details significantly complicate the analysis. In fact, it could be challenging and intricate to move beyond computer
simulation to characterize the model dynamics (such as the spiking nature of each unit, the time it takes to
stabilize, etc.) analytically.

6.2

Potential applications for physiological experiments

Our work further provided testable hypotheses on how network size, similarities between input spike trains,
and synaptic memory capacity would affect this lower bound. For example, in behavioral experiments
using electrolytic lesions or pharmacological inhibition [CMA+ 03, HDS06, YLS13, KYPH16], the changes
in performance are often highly variable and nonlinear. One possible reason comes from the difficulty of
precisely manipulating network size as well as a lack of theoretical description of the relationship between
network size and performance. With our analytical characterization, one might be able to estimate changes
in the effective network size given performance in a decision-making task.
Besides the effect of network size, the distribution of feature representations (i.e., different set Rs of
different individual animals) could be used to account for between-subject variability in decision making.
Consider a random-dot coherent motion task where animals need to decide which of two directions the
majority of dots are moving [SN01]. In this task, performance accuracy and reaction time vary across
animals. If we perform neural recordings in their visual cortex (i.e., to record their Rs), we might be able
to decode their reaction time or accuracy, given population representations of dot motion in these cortical
neurons [SN96, JM06]. For example, an animal whose stimulus-evoked responses are more heterogeneous in
the visual cortex might be able to react faster given the same accuracy, governed by our derived lower-bound.

13

Last but not least, our work also offered predictions on how local memory capacity could affect performance in decision-making. For example, when there is more ambiguity in input representations, to obtain the
same performance (both accuracy and decision time), a larger time window for memory storage in synapses
[KPS10] is required. From previous experimental work [BMG+ 17], we know that synaptic plasticity has time
scale ranging from milliseconds to seconds across different brain regions, and such plasticity could efficiently
store entire behavioral sequences within synaptic weights. Combining with our analytical characterization,
when performance accuracy changes over time, assuming other parameters such as input statistics, decision
time and network size are fixed, one might be able to predict how synaptic plasticity changes. Overall, our
work not only provided a theoretical framework, but also provided a set of testable hypotheses on neural
recordings and behaviors in decision-making under ambiguity.

6.3

Limitations and extensions

When δ is a constant, our lower bound is order-optimal in terms of its scaling in n, k, and TR . Nevertheless,
the scaling of the derived lower bound in terms of δ is not tight. It would be interesting to know the optimal
scaling in δ when other parameters (n, k, and TR ) are fixed. We leave it as one future direction.
To simplify complexity, our model posed a few assumptions that ignored some features in the brain. One
of these assumptions is that each input neuron is independent. However, various degrees of average noise
correlations between cortical neurons have been reported. For example, average noise correlations in primary
visual cortex could be close to 0.1 [SSB+ 15], 0.18 [SK08], or even much larger as 0.35 [GD08]. Similarly, noise
correlations have been observed in other sensory brain regions [CK11]. In our work, we ignored correlations
between these neurons, but it would be interesting as a future direction to extend in our spiking network
model.
Second, our model used a threshold activation function by assuming the synaptic transmission is basically
noise-free and that the only noise source comes from the input in this paper. However, synaptic transmission
is highly unreliable in biological networks [AS94, FSW08, Bor10], and a deterministic activation function
would fail to capture this feature compared to a stochastic activation function. Moreover, failure in synaptic
transmission could serve a computational role [BS09, Maa97].
Another assumption in our circuit is that the output neurons can inhibit each other. In common scenarios, an output neuron is usually excitatory, and does not inhibit other neurons directly without recruiting
inhibitory cells. We incorporate stability in these output neurons by assuming they can inhibit each other
in our circuit implementation. For a model where an output neuron is limited to be excitatory only, we can
add a chain of inhibitory neurons to achieve stability WTA computation.
Last but not least, in our k-WTA circuit, the number of output neurons that spike simultaneously
increases monotonically until there are exactly k output neurons that spike simultaneously. We acknowledge
that this might not be biologically plausible in most cases in the brain. From large-scale neural recordings,
we know that the number of neurons that spike simultaneously is usually variable, so this could be a future
direction to construct a circuit that better matches experimental observations.

Acknowledgement
We would like to thank Christopher Quinn at Purdue University and Zhi-Hong Mao at University of Pittsburgh for the helpful discussions and references.

References
[AS94]

Christina Allen and Charles F Stevens. An evaluation of causes for unreliability of synaptic
transmission. Proceedings of the National Academy of Sciences, 91(22):10380–10383, 1994. 14

[BAB+ 97]

Roland Baddeley, Larry F Abbott, Michael CA Booth, Frank Sengpiel, Tobe Freeman, Edward A Wakeman, and Edmund T Rolls. Responses of neurons in primary and inferior temporal visual cortices to natural scenes. Proceedings of the Royal Society of London B: Biological
Sciences, 264(1389):1775–1783, 1997. 2, 13

14

[BC95]

György Buzsáki and James J Chrobak. Temporal structure in spatially organized neuronal
ensembles: a role for interneuronal networks. Current opinion in neurobiology, 5(4):504–510,
1995. 2

[BIM98]

Michael J Berry II and Markus Meister. Refractoriness and neural precision. In Advances in
Neural Information Processing Systems, pages 110–116, 1998. 2

[BMG+ 17]

Katie C Bittner, Aaron D Milstein, Christine Grienberger, Sandro Romani, and Jeffrey C
Magee. Behavioral time scale synaptic plasticity underlies ca1 place fields. Science,
357(6355):1033–1036, 2017. 14

[Bor10]

J Gerard G Borst. The low synaptic release probability in vivo. Trends in neurosciences,
33(6):259–266, 2010. 14

[BS09]

Tiago Branco and Kevin Staras. The probability of neurotransmitter release: variability and
feedback control at single synapses. Nature Reviews Neuroscience, 10(5):373, 2009. 14

[CK11]

Marlene R Cohen and Adam Kohn. Measuring and interpreting neuronal correlations. Nature
neuroscience, 14(7):811, 2011. 14

[CMA+ 03]

Luke Clark, Facundo Manes, Nagui Antoun, Barbara J Sahakian, and Trevor W Robbins. The
contributions of lesion laterality and lesion volume to decision-making impairment following
frontal lobe damage. Neuropsychologia, 41(11):1474–1483, 2003. 13

[DA01]

Peter Dayan and Laurence F Abbott. Theoretical neuroscience: computational and mathematical modeling of neural systems. 2001. 13

[EB02]

Marc O Ernst and Martin S Banks. Humans integrate visual and haptic information in a
statistically optimal fashion. Nature, 415(6870):429, 2002. 2

[FDMM18]

Ulisse Ferrari, Stephane Deny, Olivier Marre, and Thierry Mora. A simple model for low
variability in neural spike trains. arXiv preprint arXiv:1801.01362, 2018. 2, 13

[FSW08]

A Aldo Faisal, Luc PJ Selen, and Daniel M Wolpert. Noise in the nervous system. Nature
reviews neuroscience, 9(4):292, 2008. 2, 14

[GD08]

Diego A Gutnisky and Valentin Dragoi. Adaptive coding of visual information in neural populations. Nature, 452(7184):220, 2008. 14

[GKvHW96] Wulfram Gerstner, Richard Kempter, J Leo van Hemmen, and Hermann Wagner. A neuronal
learning rule for sub-millisecond temporal coding. Nature, 383(6595):76, 1996. 2
[HDS06]

Timothy D Hanks, Jochen Ditterich, and Michael N Shadlen. Microstimulation of macaque
area lip affects decision-making in a motion discrimination task. Nature neuroscience, 9(5):682,
2006. 13

[HDZ08]

Tomáš Hromádka, Michael R DeWeese, and Anthony M Zador. Sparse representation of sounds
in the unanesthetized auditory cortex. PLoS biology, 6(1):e16, 2008. 2

[HSM06]

Thomas TG Hahn, Bert Sakmann, and Mayank R Mehta. Phase-locking of hippocampal interneurons’ membrane potential to neocortical up-down states. Nature neuroscience,
9(11):1359, 2006. 2

[HW59]

David H Hubel and Torsten N Wiesel. Receptive fields of single neurones in the cat’s striate
cortex. The Journal of physiology, 148(3):574–591, 1959. 2

[HW98]

Christopher M Harris and Daniel M Wolpert. Signal-dependent noise determines motor planning. Nature, 394(6695):780, 1998. 2

15

[IKN98]

Laurent Itti, Christof Koch, and Ernst Niebur. A model of saliency-based visual attention
for rapid scene analysis. IEEE Transactions on pattern analysis and machine intelligence,
20(11):1254–1259, 1998. 2

[JB67]

I Jacobs and E Berlekamp. A lower bound to the distribution of computation for sequential
decoding. IEEE Transactions on Information Theory, 13(2):167–174, 1967. 21

[JM06]

Mehrdad Jazayeri and J Anthony Movshon. Optimal representation of sensory information by
neural populations. Nature neuroscience, 9(5):690, 2006. 13

[KCF17]

Birgit Kriener, Rishidev Chaudhuri, and Ila Fiete. How fast is neural winner-take-all when
deciding between many options? bioRxiv, page 231753, 2017. 2, 9, 13

[KF08]

Mattias P Karlsson and Loren M Frank. Network dynamics underlying the formation of sparse,
informative representations in the hippocampus. Journal of Neuroscience, 28(52):14271–14281,
2008. 2

[KK01]

Masaharu Kinoshita and Hidehiko Komatsu. Neural representation of the luminance and brightness of a uniform surface in the macaque primary visual cortex. Journal of neurophysiology,
86(5):2559–2570, 2001. 2

[KP04]

David C Knill and Alexandre Pouget. The bayesian brain: the role of uncertainty in neural
coding and computation. TRENDS in Neurosciences, 27(12):712–719, 2004. 2

[KPS10]

Andreas Knoblauch, Günther Palm, and Friedrich T Sommer. Memory capacities for synaptic
and structural plasticity. Neural Computation, 22(2):289–341, 2010. 14

[KRR00]

Prakash Kara, Pamela Reinagel, and R Clay Reid. Low response variability in simultaneously
recorded retinal, thalamic, and cortical neurons. Neuron, 27(3):635–646, 2000. 2, 13

[KTA+ 03]

Zoe Kourtzi, Andreas S Tolias, Christian F Altmann, Mark Augath, and Nikos K Logothetis.
Integration of local features into global shapes: monkey and human fmri studies. Neuron,
37(2):333–346, 2003. 2

[KW04]

Konrad P Körding and Daniel M Wolpert. Bayesian integration in sensorimotor learning.
Nature, 427(6971):244, 2004. 2

[KYPH16]

Leor N Katz, Jacob L Yates, Jonathan W Pillow, and Alexander C Huk. Dissociated functional
significance of decision-related activity in the primate dorsal stream. Nature, 535(7611):285,
2016. 13

[LCG+ 15]

Nuo Li, Tsai-Wen Chen, Zengcai V Guo, Charles R Gerfen, and Karel Svoboda. A motor
cortex circuit for motor planning and movement. Nature, 519(7541):51, 2015. 2

[LIKB99]

Dale K Lee, Laurent Itti, Christof Koch, and Jochen Braun. Attention activates winner-take-all
competition among visual filters. Nature neuroscience, 2(4):375, 1999. 2, 13

[LLW13]

Shuai Li, Yangming Li, and Zheng Wang. A class of finite-time dual neural networks for solving quadratic programming problems and its k-winners-take-all application. Neural Networks,
39:27–39, 2013. 2, 13

[LMP16]

Nancy Lynch, Cameron Musco, and Merav Parter. Computational tradeoffs in biological neural
networks: Self-stabilizing winner-take-all networks. arXiv preprint arXiv:1610.02084, 2016. 5

[MA09]

Gaby Maimon and John A Assad. Beyond poisson: increased spike-time regularity across
primate parietal cortex. Neuron, 62(3):426–440, 2009. 2, 13

[Maa97]

Wolfgang Maass. Networks of spiking neurons: the third generation of neural network models.
Neural networks, 10(9):1659–1671, 1997. 5, 14

16

[Maa00]

Wolfgang Maass. On the computational power of winner-take-all.
12(11):2519–2535, 2000. 2

Neural computation,

[MCM07]

Najib J Majaj, Matteo Carandini, and J Anthony Movshon. Motion integration by neurons in
macaque mt is local, not global. Journal of Neuroscience, 27(2):366–370, 2007. 2

[MM07]

Zhi-Hong Mao and Steve G Massaquoi. Dynamics of winner-take-all competition in recurrent
neural networks with lateral inhibition. IEEE transactions on neural networks, 18(1):55–69,
2007. 9

[Nel04]

Israel Nelken. Processing of complex stimuli and natural scenes in the auditory cortex. Current
opinion in neurobiology, 14(4):474–480, 2004. 2

[OF04]

Bruno A Olshausen and David J Field. Sparse coding of sensory inputs. Current opinion in
neurobiology, 14(4):481–487, 2004. 2

[PG99]

Michael L Platt and Paul W Glimcher. Neural correlates of decision variables in parietal cortex.
Nature, 400(6741):233, 1999. 2

[POMT+ 02] Javier Perez-Orive, Ofer Mazor, Glenn C Turner, Stijn Cassenaer, Rachel I Wilson, and Gilles
Laurent. Oscillations and sparsening of odor representations in the mushroom body. Science,
297(5580):359–365, 2002. 2
[PW14]

Yury Polyanskiy and Yihong Wu. Lecture notes on information theory. Lecture Notes for
ECE563 (UIUC) and, 6:2012–2016, 2014. 7, 18, 20

[QKKF08]

R Quian Quiroga, Gabriel Kreiman, Christof Koch, and Itzhak Fried. Sparse but not
?grandmother-cell?coding in the medial temporal lobe. Trends in cognitive sciences, 12(3):87–
91, 2008. 2

[RP99]

Maximilian Riesenhuber and Tomaso Poggio. Hierarchical models of object recognition in
cortex. Nature neuroscience, 2(11):1019, 1999. 2

[RPG99]

Peter Redgrave, Tony J Prescott, and Kevin Gurney. The basal ganglia: a vertebrate solution
to the selection problem? Neuroscience, 89(4):1009–1023, 1999. 2

[RV06]

Nicolas P Rougier and Julien Vitay. Emergence of attention within a neural population. Neural
Networks, 19(5):573–581, 2006. 2, 13

[SK08]

Matthew A Smith and Adam Kohn. Spatial and temporal scales of neuronal correlation in
primary visual cortex. Journal of Neuroscience, 28(48):12591–12603, 2008. 14

[SLW05]

Athanassios G Siapas, Evgueniy V Lubenov, and Matthew A Wilson. Prefrontal phase locking
to hippocampal theta oscillations. Neuron, 46(1):141–151, 2005. 2

[SN96]

Michael N Shadlen and William T Newsome. Motion perception: seeing and deciding. Proceedings of the national academy of sciences, 93(2):628–633, 1996. 13

[SN01]

Michael N Shadlen and William T Newsome. Neural basis of a perceptual decision in the
parietal cortex (area lip) of the rhesus monkey. Journal of neurophysiology, 86(4):1916–1936,
2001. 2, 13

[SS06]

Alan A Stocker and Eero P Simoncelli. Noise characteristics and prior expectations in human
visual speed perception. Nature neuroscience, 9(4):578, 2006. 2

[SSB+ 15]

Marieke L Schölvinck, Aman B Saleem, Andrea Benucci, Kenneth D Harris, and Matteo Carandini. Cortical state determines global variability and correlations in visual cortex. Journal of
Neuroscience, 35(1):170–178, 2015. 14

17

[VRP+ 18]

Stephen J Verzi, Fredrick Rothganger, Ojas D Parekh, Tu-Thach Quach, Nadine E Miner,
Craig M Vineyard, Conrad D James, and James B Aimone. Computing with spikes: The
advantage of fine-grained timing. Neural computation, 30(10):2660–2690, 2018. 5

[wik]

Activation function. https://en.wikipedia.org/wiki/Activation function. Accessed: 2018-08-08.
9

[Wu17]

Yihong Wu. Lecture notes on information-theoretic methods for high-dimensional statistics.
Lecture Notes for ECE598YW (UIUC), 2017. 5

[YG98]

AL Yuille and D Geiger. The handbook of brain theory and neural networks, 1998. 2

[YLS13]

Eric A Yttri, Yuqing Liu, and Lawrence H Snyder. Lesions of cortical area lip affect reach onset
only when the reach is accompanied by a saccade, revealing an active eye–hand coordination
circuit. Proceedings of the National Academy of Sciences, 110(6):2371–2376, 2013. 13

Appendices
A

Preliminaries

In this section, we present some preliminaries on information measures and Fano’s inequality. Interested
readers are referred to [PW14] for comprehensive background.

A.1

Information Measures

Let X and Y be two random variables. The mutual information between X and Y , denoted by I(X; Y ),
measures the dependence between X and Y , or, the information about X (resp. T ) provided by Y (resp.
X).
Definition 14 (Mutual information). Let X and Y be two random variables.
I(X; Y ) := D(PXY k PX PY ), D(P k Q) :=

X

P (a) log

a∈A

P (a)
,
Q(a)

where PXY denotes the joint distribution of X and Y , and PX PY denotes the product of the marginal
distributions of X and Y .
In the following, we use the notation X → Y to denote that Y is a (possibly random) function of X.
c means that X is a (possibly random) function of W ; Y is a (possibly random)
Thus, W → X → Y → W
c is a (possibly random) function of Y . Fano’s inequality:
function of X; and W
Theorem 15. [PW14, Corollary 5.1] Let T : Θ → [M ], and let θ → X → Y → Tb(θ) be an arbitrary Markov
chain. Suppose both θ and T (θ) are uniformly distributed over a set of size M . Then
n
o
I(X; Y ) + 1
Pe := P T (θ) 6= Tb(θ) ≥ 1 −
.
log M
Theorem
Pn 16 (Chernoff Bound). Let X1 , · · · , Xn be i.i.d. with Xi ∈ {0, 1} and P {X1 = 1} = p. Set
X = i=1 Xi . Then
• for any t ∈ [0, 1 − p], we have P {X ≥ (p + t) n} ≤ exp (−nd(p + t k p)).
• for any t ∈ [0, p], we have P {X ≤ (p − t) n} ≤ exp (−nd(p − t k p)).

18

B

Proof of Lemma 2

Proof of Lemma 2. Lemma 2 follows easily from the independence between input spike trains and the assumption that the spikes in each input spike train are i.i.d.. For completeness, we present the proof as
follows.
Recall that
h
i
T
T
S := {St (u1 )}t=1 , · · · , {St (un )}t=1 .
Let s = [s1 , · · · , sn ] such that each component si is a binary sequence of length T , i.e.,


T
si = bi1 , · · · , biT ∈ {0, 1} .
T

T

T

For each i = 1, · · · , n, let PS ({St (ui )}t=1 ) and QS ({St (ui )}t=1 ) be the marginal distributions of {St (ui )}t=1
under joint distributions PS and QS respectively. Similarly, PS (St (ui )) and QS (St (ui )) are the corresponding
two marginal distributions of St (ui ). Thus, we have


T
T
D PS ({St (ui )}t=1 ) k QS ({St (ui )}t=1 )


T
X
 i

PS ({St (ui )}t=1 = bi1 , · · · , biT )
(a)
T
i
=
PS ({St (ui )}t=1 = b1 , · · · , bT ) log


T
QS ({St (ui )}t=1 = bi1 , · · · , biT )
[bi1 ,··· ,biT ]
!
QT
TY
−1
X
PS (St (ui ) = bit )
(b)
i
=
PS (St0 (ui ) = bt0 ) log QTt=1
i
t=1 QS (St (ui ) = bt )
[bi1 ,··· ,biT ] t0 =0
! T
TY
−1
X
X
PS (St (ui ) = bit )
=
PS (St0 (ui ) = bit0 )
log
QS (St (ui ) = bit )
t=1
[bi1 ,··· ,biT ] t0 =0
!
T
TY
−1
X
X
PS (St (ui ) = bit )
i
=
PS (St0 (ui ) = bt0 ) log
QS (St (ui ) = bit )
t=1 [bi ,··· ,bi ] t0 =0
1
T


T
TY
−1
X
X
PS (St (ui ) = bit )

=
PS (St0 (ui ) = bit0 ) PS (St (ui ) = bt ) log
QS (St (ui ) = bit )
t=1 [bi ,··· ,bi ] t0 =0&t0 6=t
1
T
(c)

=

T X
X
t=1 bit

=

T 
X
t=1

=

T
X

PS (St (ui ) = bit ) log

PS (St (ui ) = bit )
QS (St (ui ) = bit )

pi
1 − pi
pi log + (1 − pi ) log
qi
1 − qi



d(pi k qi ) = T · d(pi k qi ).

t=1

P
[bi1 ,··· ,biT ] is the summation over all binary sequences of length T . In the last displayed equation,
equality (a) follows from the definition of KL divergence; equality (b) is true because of independence of
spikes; equality (c) follows from the fact that for any fixed bit ,


T
X
Y

PS (St0 (ui ) = bit0 ) = 1,
[bi1 ,··· ,biT ]\{t} t0 =1&t0 6=t
P
where we use [bi ,··· ,bi ]\{t} to denote the summation over all binary sequences of length T with the t–th
1
T
entry fixed.
where

19

Similarly, we get
X

D(PS k QS ) =

PS (S = s) log

s=[s1 ,··· ,sn ]

=

n
X

PS (S = s)
QS (S = s)



T
T
D PS ({St (ui )}t=1 ) k QS ({St (ui )}t=1 )

i=1

=

n
X

T d(pi k qi ) = T

i=1

n
X

d(pi k qi ),

i=1

proving the lemma.

C

Proof of Lemma 3

Proof of Lemma 3. Since mutual information can be viewed as distance to product distributions, by [PW14,
Theorem 3.4], we have

I(Xp ; S) = min D PXp ,S k QXp QS .
QXp QS

where PXp ,S is the joint distribution of Xp and S, and QXp and QS are any distributions of Xp and S,
respectively.
For any fixed QS , it holds that


min D PXp ,S k QXp QS = min D PS|Xp PXp k QXp QS
QXp
QXp

≤ D PS|Xp PXp k PXp QS ,
where the equality follows from conditioning, and the inequality is true because the best choice over all QXp
cannot be worse than any specific choice of QXp . Here S | Xp denotes the n input spike trains conditioning
on the choice of rate assignment.
For any fixed QS , we have


X

PS|Xp =p0 (S = s)PXp (Xp = p0 )
0
D PS|Xp PXp k PXp QS = PXp (Xp = p )
PS|Xp =p0 (S = s) log
QS (S = s)PXp (Xp = p0 )
s
"
#
k
n
X
X
X
PS|Xp =pij (S = s)PXp (Xp = pij )
ij
+
PXp (Xp = p )
PS|Xp =pij (S = s) log
QS (S = s)PXp (Xp = pij )
s
i=1 j=k+1


X
PS|Xp =p0 (S = s)
1
PS|Xp =p0 (S = s) log
=
k(n − k) + 1 s
QS (S = s)


k
n
X
X
X
PS|Xp =pij (S = s)
1
+
PS|Xp =pij (S = s) log
k(n − k) + 1 i=1
QS (S = s)
s
j=k+1

=

k
n
X
X


1
1
D PS|Xp =p0 k QS +
D PS|Xp =pij k QS ,
k(n − k) + 1
k(n − k) + 1 i=1
j=k+1

P
where s is summation over all possible n binary sequences of length T . Here PS|Xp =p0 is the distribution
of S with the rate assignment p0 , and PS|Xp =pij is the distribution of S with the rate assignment pij .
Choosing QS to be the distribution of S with rate assignment p0 defined in (8), then for any i = 1, · · · , k
and j = k + 1, · · · , n, we have


D PS|Xpij k QS = T (d(r2 k r1 ) + d(r1 k r2 )).
20

Therefore,
I (Xp k S) ≤

k
n
X
X
1
T (d(r2 k r1 ) + d(r1 k r2 ))
k(n − k) + 1 i=1
j=k+1

≤ T (d(r2 k r1 ) + d(r1 k r2 )).

D

Proof of Lemma 13

By the activation rules in Algorithm 1, we know that

(
Pm 
1, if (b − 1)1{St +m−1 (vi )=1} + r=1 1{Vt +m−r >0} − m1{Vt +m−r ≤−1} > b;
0
0
0
St0 +m =
0, otherwise.
As all input neurons are quiescent at time t0 and remain to be quiescent for all t ≥ t0 , it follows that
(b − 1)1{St

0

+
+m−1 (vi )=1}

m 
X

1{Vt

0

− m1{Vt
+m−r >0}


0 +m−r

≤−1}

r=1

= (b − 1)1{St

0

−m
+m−1 (vi )=1}

m
X

1{Vt

}

0 +m−r ≤−1

r=1

≤ b − 1 < b.
Thus, St0 +m (vi ) = 0 for all i = 1, · · · , n. So we have Vt0 +m+1 (vi ) = 0 for all i = 1, · · · , n, which again
implies that St0 +m+1 (vi ) = 0 for all i = 1, · · · , n. Therefore, we conclude that St (vi ) = 0 and Vt (vi ) = 0 for
all t > t0 + m.

E

Proof of Theorem 4

Proof of Theorem 4. We prove this via a genie-aided argument [JB67] by assuming that there is a genie that
can access the firing sequences of all the n input neurons. By assuming the existence of a genie, we are
essentially considering the centralized setting. Clearly, if the error probability is high even in the centralized
setting, then no SNNs (which are distributed algorithms) can achieve lower error probability.
Suppose that T ≤ ((1 − δ) log(k(n − k) + 1) − 1) TR . By (7) there exists r1 , r2 such that r1 6= r2 and
T ≤ ((1 − δ) log(k(n − k) + 1) − 1)

1
.
d(r2 k r1 ) + d(r1 k r2 )

Without loss of generality, assume that r1 > r2 .
Consider the k(n − k) + 1 possible rate assignments defined in Lemma 3. Let P be the set of such rate
assignments. By Yao’s minimax principle, we know the minimax probability of error is always lower bounded
by Bayes probability of error with any prior distribution:
n
o
h n
oi
d (S) 6= W(p) ≥ EX ∼U nif (P) P win
d (S) 6= W(Xp ) ,
max P win
p
p∈ARk

where Xp ∼ U nif (P) is uniformly distributed over set P. In addition, by Fano’s inequality, we have
h n
oi
d (S) 6= W(Xp ) ≥ 1 −
EXp ∼U nif (P) P win

21

I(Xp ; S) + 1
.
log(k(n − k) + 1)

(11)

Applying Lemma 3, we get
I(Xp ; S) + 1
log(k(n − k) + 1)
T (d(r2 k r1 ) + d(r1 k r2 )) + 1
≥1−
log(k(n − k) + 1)
≥ δ.

n
o
d (S) 6= W(p) ≥ 1 −
max P win

p∈ARk

The last inequality holds as T ≤ ((1 − δ) log(k(n − k) + 1) − 1) TR .

F

Proof of Theorem 10

The proof of Theorem 10 uses the following technical fact and lemma.
Fact 17. For any given p ∈ (0, 1) and b > 0, let fp,b : R → R, defined as: for all t > 0,



b
fp,b (t) := exp −td
kp
.
t
Function fp,b (·) is increasing when t ∈ (0, pb ) and decreasing when t ≥ pb .
This fact follows immediately from a simple algebra.
Lemma 18. Assume u, v ∈ [c, C] ⊆ (0, 1). Then for any α ∈ (0, 1),
d ((1 − α)u + αv k u) ≥

α2 c(1 − C)
(d (u k v) + d (v k u)) .
2C(1 − c)

Proof. Note that for any fixed q ∈ [c, C], d (x k q) is a function of x, where x ∈ [c, C]. In addition, by simple
algebra, we have
d0 (x k q) = log

1
(1 − q)x
, and d00 (x k q) =
.
q(1 − x)
x(1 − x)

(12)

By Taylor expansion, we have
d ((1 − α)u + αv k u) = d (u k u) + ((1 − α)u + αv − u) d0 (u k u)
2

+

((1 − α)u + αv − u) 00
d (ξ k u) ,
2

where ξ ∈ [min{u, (1 − α)u + αv}, max{u, (1 − α)u + αv}]. By (12),
d ((1 − α)u + αv k u) = 0 + 0 +

1
α2 (u − v)2
α2 (u − v)2
≥
.
ξ(1 − ξ)
2
2C(1 − c)

On the other hand, since d (u k v) + d (u k v) is symmetric in u and v, without loss of generality, assume
that u ≥ v. We have
u(1 − v)
v(1 − u)


u−v
= (u − v) log 1 +
v(1 − u)
u−v
(u − v)2
(u − v)2
≤ (u − v)
=
≤
v(1 − u)
v(1 − u)
c(1 − C)
2C(1 − c)
≤
d ((1 − α)u + αv k u) ,
c(1 − C)α2

d (u k v) + d (u k v) = (u − v) log

proving the lemma.
22

Now we are ready to prove Theorem 10.
Proof of Theorem 10. Without loss of generality, assume that
p1 ≥ · · · ≥ pk > pk+1 ≥ · · · ≥ pn .
For a given rate assignment p ∈ AR, define τ1 , τ2 , · · · , τn as


min{t,m∗ }


X
Sr (ui ) ≥ b , ∀ i = 1, · · · , n.
τi := inf t :
t 

r=0

To show Theorem 10, it is enough to show that with probability 1 − δ,
τi < τj ∀ i = 1, · · · , k, and j = k + 1, · · · , n;
∗

and τi ≤ m

(13)

∀ i = 1, · · · , k..

(14)

Before diving into proving (13) and (14) hold with probability at least 1 − δ, let’s check the sufficiency of
(13) and (14). Let t0 := max1≤i≤k τi . Let E be the event on which (13) and (14) hold. Clearly, conditioning
on event E, we have


max τi | E = t0 | E ≤ m∗ − 1 ≤ m − 1,
1≤i≤k

and




max τi | E

1≤i≤k

= t0 | E < τj | E ∀j = k + 1, · · · , n.

Notably, for any t ≤ t0 ≤ m − 1 and for i = 1, · · · , n,
#
" t
t
t
t
X
X
X
X
Sr (ui ).
1{Vr (vi )≤−1}
1{Vr (vi )>0} ≤
1{Vr (vi )>0} − m
≤
r=1

r=1

+

r=1

r=1

Thus, conditioning on E, at most k −1 output neurons ever spike by time t0 . So we have (1) 1{Vt (vi )≤−1} = 0,
and (2) 1{Vt (vi )>0} = St (ui ), for all i = 1, · · · , n and for all t ≤ t0 . In addition, we have for all t ≤ t0 ,
"
(b − 1)1{St (vi )=1} +

t
X

1{Vr (vi )>0} − m

= (b − 1)1{St (vi )=1} +
= (b − 1)1{St (vi )=1} +

r=1
t
X

#
1{Vr (vi )≤−1}

r=1

r=1
t
X

t
X

+

1{Vr (vi )>0}
Sr (ui ).

r=1

By the activation rules in Algorithm 1, we know, conditioning on E, at time t0 + 1 ≤ m∗ , output neurons
v1 , · · · , vk spike simultaneously, and output neurons vk+1 , · · · , vn do not spike, proving (1) in Theorem 10.
By the choice of t0 , we know that, on E, t0 + 1 is the first time that k output neurons spike simultaneously,
and no other k output neurons ever spike simultaneously, proving (2) in Theorem 10.
By a simple induction argument, it can be shown that conditioning on E, in each of the time slot t such
that t0 + 1 ≤ t ≤ m + 1, output neurons v1 , · · · , vk spike, and no other output neurons (i.e., output neurons
vk+1 , · · · , vn do not spike). Let’s consider the case when t = (m + 1) + 1. As among output neurons, only
v1 , · · · , vk spike, and no other output neurons spike for any t0 ≤ m + 1, it follows that
m

m
X

1{Vt−r (vi )≤−1} = 0, ∀ v1 , · · · , vk .

r=1

23

Thus, for these k output neurons,
"
(b − 1)1{St−1 (vi )=1} +

m
X

1{Vt−r (vi )>0} − m

r=1

= (b − 1) +
= (b − 1) +
≥b−2+
=b−2+

m
X
r=1
m
X

m
X

#
1{Vt−r (vi )≤−1}

r=1

+

1{Vt−r (vi )>0}
1{Vt−1−r (vi )>0} + 1{Vt−1 (vi )>0} − 1{Vt−1−m (vi )>0}

r=1
m
X

1{Vt−1−r (vi )>0}

r=1
m
X

Sr (ui ) ≥ 2b − 2 ≥ b,

r=1

where the last inequality holds as long as b ≥ 2. For output neurons vk+1 , · · · , vn , we have
"m
#
m
X
X
(b − 1)1{St−1 (vi )=1} +
1{Vt−r (vi )>0} − m
1{Vt−r (vi )≤−1}
r=1

≤

m
X

(a)

=

=
≤

r=1

+

1{Vt−r (vi )>0}

r=1
m
X

1{Vt−1−r (vi )>0} + 1{Vt−1 (vi )>0} − 1{Vt−1−m (vi )>0}

r=1
m
X

1{Vt−1−r (vi )>0} − 1{Vt−1−m (vi )>0}

r=1
m
X

1{Vt−1−r (vi )>0} =

m
X

1{Vr (vi )>0} < b.

r=1

r=1

Equality (a) follows because at time t − 1, output neurons v1 , · · · , vk spike, resulting in 1{Vt−1−r (vi )>0} = 0
for i 6= 1, · · · , k. Thus, we know conditioning on event E, at time (m + 1) + 1, the output neurons v1 , · · · , vk
spike, and no other output neuron spike. It can be shown by a simple induction that at each time t such
that t0 + 1 ≤ t ≤ m + b, the output neurons v1 , · · · , vk spike, and no other output neurons spike. This proves
(3) in Theorem 10.
Next we prove (13) and (14). By definition of τj , we know that τj ≤ m∗ for all j = 1, · · · , n. Thus, we
only need to show that with probability 1 − δ,
τi < τj ∀ i = 1, · · · , k, and j = k + 1, · · · , n,
which is the focus of the remainder of our proof.
Note that
P {τi < τj , ∀i ∈ {1, · · · , k}, ∀j ∈ {k + 1, · · · , n}}
= P {τi < τj , & τi < m∗ , ∀i ∈ {1, · · · , k}, ∀j ∈ {k + 1, · · · , n}}
≥1−

n
k
X
X

P {τi ≥ τj , or τi = m∗ } .

(15)

i=1 j=k+1

For each term in the summation of (15), we have
P {τi ≥ τj , or τi = m∗ } = P {τi = m∗ } + P {τi ≥ τj , & τi < m∗ } ,
24

(16)

which follows from the fact that P {A ∪ B} = P {A} + P {B − A} for any sets A and B. Note that m∗ pi ≥ b.
By Chernoff bound, the first term in (16) is bounded as
( m∗
)



X
b
∗
∗
k pi
.
(17)
P {τi = m } = P
Sr (ui ) ≤ b ≤ exp −m · d
m∗
r=0
For the second term in (16), we have
∗

P {τi ≥ τj and τi < m } = P

(τ
i
X

)
∗

Sr (uj ) ≥ b, and τi < m

r=0



∗



≤ exp −t · d
where t∗ ∈



b
k pk+1
t∗





∗

+ exp −t · d



b
k pk
t∗


,


b
,
pk+1 pk . Thus, (16) is upper bounded as
b






b
P {τi ≥ τj , or τi = m } ≤ exp −m · d
k pk+1
m∗






b
b
∗
∗
+ exp −t · d ∗ k pk+1
+ exp −t · d ∗ k pk
t
t






b
b
∗
∗
≤ exp −t · d ∗ k pk+1
+ 2 exp −t · d ∗ k pk
.
t
t
∗

∗

Eq (15) is bounded as
P {τi < τj , ∀i ∈ {1, · · · , k}, ∀j ∈ {k + 1, · · · , n}}
≥1−

k
n
X
X

P {τi ≥ τj , or τi = m∗ }

i=1 j=k+1


n
k
X
X









b
b
∗
exp −t · d ∗ k pk+1
≥1−
+ 2 exp −t · d ∗ k pk
t
t
i=1 j=k+1







b
b
∗
∗
= 1 − k(n − k) exp −t · d ∗ k pk+1
+ 2 exp −t · d ∗ k pk
.
t
t
Let t∗ =

∗

b
(pk +pk+1 )/2 ,

it holds that






pk + pk+1
b
b
∗
·d
k pk+1
= exp −
,
exp −t · d ∗ k pk+1
t
(pk + pk+1 )/2
2






b
b
pk + pk+1
2 exp −t∗ · d ∗ k pk
= 2 exp −
·d
k pk
.
t
(pk + pk+1 )/2
2

By Lemma 18, we know


pk + pk+1
c(1 − C)
d
k pk+1 ≥
(d(pk+1 k pk ) + d(pk k pk+1 )) ,
2
8C(1 − c)
and,

d

pk + pk+1
k pk
2


≥

c(1 − C)
(d(pk+1 k pk ) + d(pk k pk+1 )) .
8C(1 − c)

Thus, we get
P {τi < τj , ∀i ∈ {1, · · · , k}, ∀j ∈ {k + 1, · · · , n}}


2b
c(1 − C)
(d(pk k pk+1 ) + d(pk+1 k pk ))
≥ 1 − 3k(n − k) exp −
pk + pk+1 8C(1 − c)
25

Since b =

8C 2 (1−c)
c(1−C)

log

3
δ


+ log k(n − k) TR , we have



2b
c(1 − C)
3k(n − k) exp −
(d(pk k pk+1 ) + d(pk+1 k pk )) ≤ δ.
pk + pk+1 8C(1 − c)
Thus, P {τi < τj , ∀i ∈ {1, · · · , k}, ∀j ∈ {k + 1, · · · , n}} ≤ 1 − δ.
In addition,
t∗ =

2b
1
≤ b = m∗ ≤ m,
pk + pk+1
c

completing the proof of Theorem 10.

26

