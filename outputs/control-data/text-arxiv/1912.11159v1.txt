Device-independent randomness expansion against quantum side information
Wen-Zhao Liu,1, 2 Ming-Han Li,1, 2 Sammy Ragy,3 Si-Ran Zhao,1, 2 Bing Bai,1, 2 Yang Liu,1, 2 Peter J.
Brown,3 Jun Zhang,1, 2 Roger Colbeck,3 Jingyun Fan,1, 2, 4 Qiang Zhang,1, 2 and Jian-Wei Pan1, 2

arXiv:1912.11159v1 [quant-ph] 24 Dec 2019

1

Shanghai Branch, National Laboratory for Physical Sciences at Microscale and Department of Modern Physics,
University of Science and Technology of China, Shanghai 201315, P. R. China
2
Shanghai Branch, CAS Center for Excellence and Synergetic
Innovation Center in Quantum Information and Quantum Physics,
University of Science and Technology of China, Shanghai 201315, P. R. China
3
Department of Mathematics, University of York,
Heslington, York YO10 5DD, United Kingdom
4
Shenzhen Institute for Quantum Science and Engineering and Department of Physics,
Southern University of Science and Technology, Shenzhen, 518055, P. R. China

The ability to produce random numbers that are unknown to any outside
party is crucial for many applications.
Device-independent randomness generation
(
)[1–4] allows new randomness to be
provably generated, without needing to trust
the devices used for the protocol. This provides strong guarantees about the security of
the output, but comes at the price of requiring the violation of a Bell inequality to implement. A further challenge is to make the
bounds in the security proofs tight enough to
allow expansion with contemporary technology. Thus, while randomness has been generated in recent experiments[5–9], the amount
of randomness consumed in doing so has been
too high to certify expansion based on existing theory. Here we present an experiment
that demonstrates device-independent randomness expansion (
)[1–3, 10–15], i.e.,
where the generated randomness surpasses
that consumed. By developing a loopholefree Bell test[16–20] setup with a single photon detection efficiency of around 81% and exploiting a spot-checking protocol, we achieve
a net gain of 2.63 × 108 certified bits with
soundness error 5.74 × 10−8 . The experiment
ran for 220 hours corresponding to an average rate of randomness generation of 8202
bits/s. By developing the Entropy Accumulation Theorem (EAT)[4, 21, 22], we established
security against quantum adversaries. We anticipate that this work will lead to further
improvements that push device-independence
towards commercial viability.

DIRNG

DIRNE

According to quantum theory, measurement outcomes are in general unpredictable, even to observers
possessing quantum devices. Quantum processes
have hence been extensively studied as a source of
randomness[23, 24]. In a typical quantum random
number generator, the user relies on the device work-

ing in a particular way, for instance, by having single photons pass through a 50:50 beam splitter and
being detected. Deviations in the device-behaviour
affect the randomness of the outputs, while being
difficult to detect. Furthermore, any real device will
be too complicated to model in its entirety, leaving
open the possibility that an adversary can exploit
a feature of the device outside the model, as has
been seen in QKD[25]. To circumvent this, device
independent protocols were introduced, which are
proven secure without any assumptions about the
devices used. This leads to a significantly higher
level of security by removing any problems caused
by unmodelled features.
Recently we have witnessed significant advances in
experimental device-independent randomness generation. Some previous protocols require additional
assumptions[3, 5–7], and even the most advanced
to date[8, 9] consumed more randomness than they
generated. Hence, randomness expansion, which is
a quantum feature without classical counterpart, remained elusive and technically challenging. For example, with our previous experimental setup[8], almost 110,000 experimental hours would be required
to achieve randomness expansion with the protocol
presented below, putting it out of reach in practice.
Here we report the experimental realization of
device-independent randomness expansion with high
statistical confidence, the success of which is based
on substantial improvements at both theoretical and
experimental sides. We theoretically derive a tighter
bound on entropy accumulation in the randomness
generation process and construct a photonic entanglement platform to realize loophole-free violation
of the Clauser-Horne-Shimony-Holt (CHSH)[26] inequality with a record-high violation. We remark
that the significance of this work is twofold in that
it advances both our understanding of randomness
and our experimental quantum optical capabilities.
Such improvements take us a step closer to being
able to realize a number of other critical quantum

2
information tasks such as device-independent quantum key distribution[27].
The entropy accumulation theorem (EAT)[4, 21,
22] provides relatively tight bounds on the amount
of randomness that can be extracted against an adversary limited only by quantum theory. Roughly
speaking, the EAT shows that in an n-round protocol achieving a CHSH game score of ω, the amount
of output randomness is lower bounded by
randout ≥ nh(ω) −

√

nv ,

State distribution
device

(1)

where h(ω) is the worst-case von Neumann entropy
of an individual round of the protocol with expected score ω. The score on round i is 12 (1 +
(−1)Ai ⊕Bi ⊕(Xi ·Yi ) ), where Ai and Bi are measurement outcomes and Xi and Yi are measurement setting choices at the two sites, with Ai , Bi , Xi and
Yi ∈ {0, 1} (see Fig. 1), and v is a correction factor
accounting for the finite statistics. Using ideas from
the improved EAT[22], we derive a tighter lower
bound on the accumulated entropy, (see the Methods). This allows us to use a spot-checking protocol to experimentally realize randomness expansion with a state-of-art experimental quantum optical technique.
Fig. 1 shows a conceptual drawing of our spotchecking device-independent protocol, where the assumptions are outlined. The underlying idea is to
check that devices situated in a secure lab violate a
Bell inequality, hence it is important to ensure that
the devices at both sites (labelled Alice and Bob)
cannot signal to one another or to the outside of the
lab. If a Bell inequality is violated while satisfying
our assumptions, then the devices must be generating randomness, even relative to an adversary who
may share entanglement with the devices. The generated randomness can be extracted by appropriate
post-processing. In this protocol (Box 1), the initial
randomness is required to decide whether a round is
a test round, Ti = 1 (with probability γ), or a generation round, Ti = 0 (with probability 1 − γ). Ti
is then communicated to two separate sites (but not
to the measurement devices). In a test round, an
independent uniform random number generator at
each site generates the input to each device to perform the CHSH game; this event is made spacelike
to the output of the device at the other site so that
Bob’s output, Bi , cannot depend on Alice’s input,
Xi , and likewise Alice’s output, Ai , cannot depend
on Bob’s input, Yi . A test round consumes 2 bits
of randomness. In a generation round, the devices
at the two sites are given the input “0”. Crucially,
each measurement device only learns its own input
and not whether a round was a test or generation
round.

DIRNE

FIG. 1. Conceptual drawing to realize
protocol (cf. Box 1). The protocol takes place in a secure
lab, which is shielded from direct communication to the
outside. The lab contains two black-box devices which
accept inputs and yield outputs from the binary alphabet
{0, 1} and these can be shielded from communicating at
will. In particular, we assume the user can completely
control the flow of classical communication in and out
of these regions (indicated by the dashed lines). In our
experiment, the secure lab contains two sites Alice and
Bob. They share a pair of entangled particles which may
be distributed from a central station. (If we had good
enough quantum storage, then all entanglement could
be pre-shared.) Alice and Bob’s respective inputs are Xi
and Yi and their outputs Ai and Bi . The user also possesses a trusted classical computer (with which to process
the classical data) and sources of initial randomness. In
our experiment the initial randomness is depicted by an
extractor seed R and three RNGs that determine the
inputs to the devices. These output either 0 or 1, where
the number in the box (γ or 1/2) denotes the probability
of 1. The central RNG determines the round-type and
the peripheral ones determine the inputs if a test round
is chosen.

We implement the protocol on a quantum optical platform (see Fig. 2). Pairs of polarizationentangled photons at the wavelength of 1560 nm
are generated via spontaneous parametric downconversion at the central station and are delivered to
two remote sites, where polarization-dependent measurements are conducted. Previously this platform
proved to be robust enough to realize loophole free
violation of a Bell inequality and DIRNG, in which
the CHSH game scores ω violated the classical bound

3
Box 1 : CHSH-based

DIRNE Protocol

Arguments:
n ∈ N – number of rounds played
γ ∈ (0, 1] – expected fraction of test rounds
ωexp – expected CHSH score given a test round
δ ∈ (0, 1) – width of the statistical confidence interval for the CHSH score
R – A random seed for the extractor
Protocol:
1. For every round i ∈ {1, . . . , n} do 2 − 4.
2. Set Ui =⊥. Choose Ti ∈ {0, 1} such that Pr(Ti = 1) = γ.
3. If Ti = 0 use the devices with inputs (Xi , Yi ) = (0, 0), record Ai , replace Bi with 0 and set Ui = 0.
4. If Ti = 1, choose the inputs Xi and Yi uniformly at random from {0, 1} and record Ai and Bi and set
Ui = 12 (1 + (−1)Ai ⊕Bi ⊕(Xi ·Yi ) ).
5. If |{Ui : Ui = 1}| < nγ(ωexp − δ), then abort the protocol.
6. Apply a strong quantum-proof randomness extractor to get output randomness M = Ext(AB, R).
(Because we use a strong extractor M can be concatenated with R to give Z = (M, R).)

ωclass = 0.75 by 0.00027[8]. Under these conditions
and using the same error parameters as elsewhere in
this paper, it would take about 8.62 × 1013 rounds
of the experiment to witness randomness expansion
according to our revised EAT theory (open square
in Fig. 3). To go beyond this, in the present work,
we achieved record-high single-photon detection efficiencies of 80.41 ± 0.34% for Alice and 82.24 ± 0.32%
for Bob, ensuring the detection loophole is closed in
the CHSH game. Following the spot-checking protocol, a biased quantum random number generator
(QRNG) is used to decide whether to test or not.
Its output Ti is transmitted to Alice and Bob to determine whether to use the local unbiased QRNGs
in each round. When Ti = 1, the setting choices Ai
and Bi are randomly determined, while when Ti = 0,
the local unbiased QRNGs are turned off and fixed
measurements are made.
Before the start of the main experiment, a systematic experimental calibration is implemented to predetermine several parameters mentioned in the protocol, which yields a CHSH game score of 0.750809.
We find that for γ = 1.008 × 10−4 , corresponding
to an average input entropy rate of 0.0017 bits per
round, we would expect to witness randomness expansion with a soundness error (see the Methods) of
5.74 × 10−8 after at least 2.91 × 1012 rounds (open
circle in Fig. 3), i.e., the randomness produced in the
experiment surpasses the consumed entropy after
this number of rounds (see the Supplementary Information, Section III.A). The experimental time taken
to get expansion is about 600 times shorter than with
the previous performance of our platform[8].
In the main experiment, we set ωexp = 0.750809,
δ = 2.1 × 10−4 , and conservatively set the number

of rounds to n = 3.168 × 1012 , which is slightly
larger than the 2.98 × 1012 rounds required. This
is computed with our optimization algorithm for
γ = 1.194 × 10−4 (see the Supplementary Information, Section III.A). We complete all the rounds of
the experiment in 220 hours at a repetition rate
of 4 MHz. The resulting CHSH game score is
ωCHSH = 0.750805. The difference between ωCHSH
and ωexp is smaller than δ, which is consistent with
the value we expect (and means that the protocol
does not abort). The raw experimental output has
size 3.168Tb. According to the development of the
EAT presented in the Supplementary Information,
it contains at least 6.496 × 109 quantum-certified
bits of randomness, exceeding the amount of entropy
(6.233 × 109 bits) required for its generation (see the
inset in Fig. 4 and the Methods). We perform a
Toeplitz matrix (6.496Gb × 3.168Tb) multiplication
to extract the quantum-certified random bits from
the raw output. The soundness error of the final output is 5.74 × 10−8 . Crucially, since a quantum-proof
strong extractor is applied, the seed required for the
extraction remains random after its use and hence
is not considered as entropy consumed[28]. (Technically, the seed degrades by a very small, which is
accounted for in the soundness error given above; see
the Supplementary Information, Section I.C). Overall we achieve DIRNE, gaining 2.63 × 108 net bits
with a net rate of 8.32 × 10−5 bits per round against
an eavesdropper limited by quantum theory (shown
by the open circle in Fig. 4).
When playing the CHSH game in the test rounds
we close both the detection and locality loopholes,
although closing the latter is not absolutely necessary given our assumption that we can shield the

4
SNSPD

SNSPD

T = 1K

T = 1K

Biased
QRNG

TDC

TDC

T i =0

T i =0
Triggered

T i =1

T i =1

Triggered

Pump Pulse

Unbiased
QRNG

Unbiased
QRNG

b)

b)

Bob

Alice

a)

Lens

DM

HWP

QWP

RM

Source

Coupler

Polarization
Coupler

PPKTP

Pockels cell

PBS

FIG. 2. Schematic of the experiment. a) Creation of pairs of entangled photons: Light pulses of 10 ns are
injected at a repetition rate of 4 MHz into a periodically poled potassium titanyl phosphate (PPKTP) crystal in a
Sagnac loop to generate polarization-entangled photon pairs[8]. The two photons of an entangled pair at 1560 nm
travel in opposite directions to two remote sites Alice and Bob, where they are subject to polarization projection
measurements. b) Single photon polarization measurement: In the measurement sites, Alice (Bob) uses a Pockels cell
to project the single photon into one of two pre-determined measurement bases, and then detects single photons with
a superconducting nanowire single-photon detector (SNSPD). A time-digital convertor (TDC) is used to time-tag the
events for random number generation and single-photon detection. In each round, a biased QRNG in the lab creates
a random bit Ti with probability distribution (γ, 1 − γ) to determine in advance whether this round will be a test or
generation round. In test rounds Alice and Bob each receive a random bit “0” or “1” from a local quantum random
number generator (QRNG) to set Pockels cell to zero and half-wave voltage accordingly (in generation rounds they
always use zero).

devices (see the Supplementary Information, Section I.B). We also remark that the randomness we
generate is secure according to a composable security definition (see the Methods) and hence can be
used in any application requiring random numbers.
Strictly, because of an issue with the composability
of device independent protocols[29], without further
assumption, ongoing security of the output randomness relies on the devices not being reused.
Going beyond the work here we would like protocols that have an improved rate. Robust protocols
that achieve up to two bits of randomness per entangled qubit pair are known[15]. However, to experimentally use such protocols to gain an advantage requires a significant improvement in the detection efficiency, which is difficult to achieve with
a photonic setup. On the theory side, better rates
could be achieved by developing tighter bounds on
the output randomness. It would also be interesting to put into practice a protocol for randomness
amplification[30], hence reducing the assumption on
the input randomness.

The authors would like to thank C.-L. Li for experimental assistance. This work was supported
by the National Key R&D Program of China
(2017YFA0303900, 2017YFA0304000), the National
Natural Science Foundation of China, the Chinese Academy of Sciences, the Anhui Initiative
in Quantum Information Technologies, the EPSRC’s Quantum Communications Hub (grant number EP/M013472/1) and an EPSRC First Grant
(grant number EP/P016588/1). We are grateful for
computational support from the University of York
High Performance Computing service, Viking, which
was used for the randomness extraction.

I.
A.

METHODS

Security definition

In this work we use a composable security
definition[31–33].

5
where τm represents a completely mixed state
on m qubits, E represents all systems that
could be held by an adversary (Eve), Ω the
event that the protocol does not abort, pΩ the
probability of this occurring. k · k1 is the trace
norm.

Number of rounds, n

theory
previous conditions
current conditions

10 14

2. (Completeness) There exists an honest implementation such that pΩ ≥ 1 − C .

10 13

10 12
0.7502

0.7504

0.7506

0.7508

0.7510

0.7512

CHSH score

Definition
2
(Smooth min-entropy). For
any
classical-quantum
density matrix ρAE =
P
a
a p(a) |aiha| ⊗ ρE acting on the joint Hilbert space
HAE , the h -smooth min-entropy is defined by

10-3

2.5

finite amount of data
asymptotic rate
our result

!

2
1.5
1
0.5

109 )

3

8

Randomness (bits,

Rate of randomness expansion (bits per round)

FIG. 3. Minimum number of experimental rounds
to witness randomness expansion versus CHSH
scores. We estimate the minimum number of experimental runs with our revised EAT theory to witness
randomness expansion as a function of CHSH game score
(smooth curve) with soundness error 5.74 × 10−8 . The
black square and red circle indicate the previous[8] and
current experimental conditions, respectively.

6

h
Hmin
(A|E)ρAE

consumed
generated

ρ̃AE

{Πa }

p̃(a)Tr(Πa ρ̃aE )

a

(3)
where the outer maximisation is over the set
h
B
P (ρAE ) of alla sub-normalized states ρ̃AE =
purified distance[36] h of
a p̃(a) |aiha| ⊗ ρ̃E within P
ρAE . Note that max{Πa } a p̃(a)Tr(Πa ρ̃aE ) can be
interpreted as the maximum probability of guessing
A given access to the system E.

2
0
0

1013

= max − log max

X

4

100

200

Time(h)

0
1012

The soundness error bounds the distance between
the output of the protocol and that of an idealized
protocol where Eve’s marginal is the same as in the
real protocol, but the output is perfectly uniform
and independent of Eve.
In general, the raw output of a protocol can have a
lot of randomness, while being easily distinguishable
from uniform. However, by applying an appropriate
randomness extractor, which is a classical function
taking a random seed and the raw output, an almost uniform output can be recovered. The length
of this output can be taken to be roughly equal to the
smooth min-entropy of the raw string conditioned on
the side information held by Eve[34, 35].

1014

1015

1016

Number of rounds, n

FIG. 4. Randomness expansion versus number of
rounds. We estimate the randomness expansion rate
based on our revised EAT theory as a function of number
of rounds (smooth line) and the asymptotic rate (dashed
line) with soundness error 5.74 × 10−8 . Open circle: experimental result. Inset: the generated randomness surpasses the consumed randomness in the experiment.

Definition 1 (security). A protocol with an output
Z is called (S , C )-secure if it satisfies
1. (Soundness) For an implementation of the protocol that produces m bits of output we have
1
pΩ kρZE|Ω − τm ⊗ ρE|Ω k1 ≤ S ,
2

(2)

The interpretation in terms of guessing probability makes clear that this quantity is a measure of
unpredictability. Bounding the smooth min-entropy
for a device-independent protocol is challenging. We
do this by means of the entropy accumulation theorem and state an informal version that is applicable
to the CHSH game below.

B.

Theoretical details about the protocol

In the protocol, the user has two devices which
are prevented from communicating with one another
and with which the CHSH game can be played. To
do so each device is supplied with a uniformly chosen
inputs denoted by X, Y ∈ {0, 1}, and each produces

,

6
an output, denoted A, B ∈ {0, 1} respectively. The
CHSH game is scored according to the function 21 (1+
(−1)A⊕B⊕(X·Y ) ). In other words, the game is won
(with a score of 1) if A ⊕ B = X · Y and is lost (with
a score of 0) otherwise.
At the end of the protocol the number of rounds
in which the CHSH game was won is counted and
compared to nγ(ωexp − δ). The challenge in a randomness expansion protocol is to go from this to the
amount of extractable randomness. For this we use
the EAT, which we state informally here (note that
the version we use is a development of Ref. 22; for
more details, see the Supplementary Information).
Theorem 1 (Entropy accumulation, informal).
Suppose the protocol of Box 1 is performed and that
devices are such that pΩ is the probability that the
protocol does not abort. Let α ∈ (1, 2), h ∈ (0, 1)
and f (s) be an affine lower bound on the singleround von Neumann entropy for any strategy achieving an expected score of s. If the protocol does not
abort, we can assume
h
Hmin
(AB|E) ≥ nf (ω) − n(α − 1)V (f, γ, ω)

α
log
−
α−1

1
p
pΩ (1 − 1 − 2h )

!

+ n(α − 1)2 Kα (f, γ),

(4)

where ω = ωexp − δ and the explicit forms of the
functions V (f, γ, ω) and Kα (f, γ) can be found in
the Supplementary Information.
By setting α − 1 ∝ √1n , the subtracted terms scale
√
as n whereas the leading rate term scales with n,
leading to the relation in Eqn. (1) when f (ω) is
a good approximation to h(ω), the worst-case von
Neumann entropy for the observed score.
In order to produce the output string M, we apply
a strong quantum-proof randomness extractor. The
reason we use a strong extractor is that the random
seed, R, required for the extractor remains random
even conditioned on the extractor’s output and is

hence not consumed. This means that M can be
concatenated with the extractor seed R to give output Z = (M, R). We discuss the extraction in more
detail in the Supplementary Information. Importantly, the length of the output (excluding the recyh
cled seed), will be roughly randout ≈ Hmin
(AB|E).
We need this to be greater than the randomness consumed.
Remark 1 (Input randomness). The expected input
randomness, randin of the protocol in Box 1 is
randin = n(Hbin (γ) + 2γ) + 2 ,
(5)
where Hbin denotes the binary Shannon entropy.
The contribution Hbin (γ) comes from the selection of
the test rounds and 2γ from the selection of the input
bits for the CHSH game. The interval algorithm[37]
can be used to turn uniform random bits to biased
ones at the claimed rate.
We do not include the randomness necessary for
seeding the extractor in the above because it is not
consumed, although it is needed to run the protocol.
Suppose that a protocol has some fixed expected
score ωexp . To demonstrate randomness expansion,
i.e., randout − randin > 0, at this performance we
have to choose the parameters n and γ appropriately. Increasing n leads to an improvement in the
rate, but takes longer and increases the experimental difficulty. The tradeoff with γ appears in the
randout and randin terms. The input randomness
evidently decreases as γ shrinks, which is favourable
since this term is subtracted. However, the minentropy also decreases because the error term scales
roughly as √1γ [22]. Moreover, the statistical confidence decreases with less frequent testing and as
such the threshold score for successful parameter estimation must be lowered (i.e., δ increased) in order
to obtain a small completeness error. This also has
a negative impact on the randomness produced. We
outline how to calculate the completeness error in
the Supplementary Information.

Appendix A: Theory of Device-Independent Quantum Randomness Expansion
1.

Notation

We summarize the main notation used in the paper and the supplementary information. We use log for
x
the logarithm base 2 and ln for the natural logarithm. The function sign(x) := |x|
for x ∈ R is the sign
function with sign(0) = 0. We generally denote states by lower case Greek letters, such as ρ and σ. These
will often be subscripted by capital Latin letters denoting the Hilbert spaces upon which the state acts, such
as a state ρABE denoting a state on Alice, Bob and Eve’s joint system, although when clear from context the
system subscripts may be omitted. We denote the set of states for a Hilbert space A by S(A). We consider

7
classical-quantum (CQ) states, which take the form
X
(a)
ρAE =
p(a) |aiha| ⊗ ρE .
a∈A

The classical system, or register, A contains the letters, a, of some alphabet, A. The quantum system E
(a)
carries states ρE where the bracketed superscript indicates the value of the classical system upon which the
state depends.
We account for multiple rounds by encoding the result of each round to a different system. We use
a subscript, e.g., Ai to denote Alice’s system for round i. We denote quantum channels by calligraphic
letters, such as Mi , which we also subscript with the round-number to which the channel relates when
appropriate. When a channel is defined on some system A, we extend it to composite systems implicitly,
hence M(ρAR ) = M ⊗ IR (ρAR ), where IR is the identity channel on the R system. When there are n
systems in total, we will sometimes use the bold face [A] = A1 . . . An , and likewise for values on these n
systems. Hence, |[a]ih[a]|[A] = |a1 iha1 |A1 ⊗· · ·⊗|an ihan |An . We also use capital letters to refer to the random
variables on the classical registers of CQ states.
We use slightly different notation from the main body to refer to the inputs and outputs for the EAT.
In the main body, we have chosen notation which is consistent with the usual notation for cryptography,
A and B denote outputs for each device and X and Y inputs. Here, however, we choose for our notation
to be consistent with that of [21, 22] for readability since we adapt their proof. To translate from the
Supplementary Information to the main body, we can make the substitutions A → AB, B → XY and
U → X, i.e., A is now the register containing the joint outputs, B is the register containing the joint inputs
and X is the register containing the test scores.
2.

Protocol Assumptions

We recall the assumptions necessary for randomness expansion (see e.g. [1]):
1. The user has a secure laboratory and can prevent any devices from receiving or sending communication
at will.
2. The user possesses a trusted classical computer.
3. The user has some initial trusted randomness.
4. Quantum theory is correct and complete (see [38, 39] for a connection between the two).
The first assumption is necessary to prevent the devices from communicating directly to an adversary, which
would trivially compromise security. We also use it to ensure that the devices do not learn whether a
particular round is a test round or not (if they could learn this, they could behave honestly only on test
rounds, which could violate the security). Moreover, to genuinely violate a Bell inequality the devices must
not be able to communicate their inputs to each other before producing their outputs. In our experiment,
this last assumption is ensured because we have spacelike separation.
The second assumption is required for correct data processing. In the extreme case, an untrusted computer
could simply substitute the real key with a compromised one. It may seem unreasonable to allow trust in
classical computers but not in quantum devices, but classical computations are repeatable, so trust in them
can be gained by repeating a calculation on different computers.
The third assumption is needed because the inputs to the devices must be random in order to reliably test
that a Bell inequality is violated and randomness is also required to seed the extractor. The final assumption
constrains the devices and the adversary to operate according to quantum mechanics, and is needed for the
theoretical arguments to work. The initial randomness is often thought of as a pre-existing seed. In our
experiment for convenience RNGs were used to produce the inputs to the devices. Although we have used
RNGs in the protocol, the key point is that more randomness is generated than is used. At the same time
we have demonstrated a Bell inequality violation on the test rounds while closing the detection and locality
loopholes.
Because of Assumption 1, it is not strictly necessary to close the locality loophole in our experiment. The
important thing is to ensure that, before giving its output, each device only learns its own input and not

8
that of the other device. We can ensure this by shielding the devices. (This is sufficient because the aim of
the present experiment is not to disprove local realism.) Since we have chosen to implement a spot-checking
protocol, we do not have full space-like separation over all rounds since the selection of a generation round is
jointly communicated to the device locations by way of a central QRNG. The shielding assumption is hence
necessary to ensure that the devices do not alter their behaviour between generation rounds and test rounds.
More fundamentally, thinking of randomness expansion as a process that extends a pre-existing seed requires
that this seed be shielded from the devices, a task which is not connected to their space-like separation.

3.

Extraction

Given a bound on the min-entropy, a seeded extractor is a deterministic function which takes as arguments
the output string and a random seed and produces a string that is almost indistinguishable from uniform.
Definition 3 (Strong extractor [28, 40, 41]). A function Ext : {0, 1}n × {0, 1}d → {0, 1}m is a quantum-proof
(k, EXT )-strong extractor with uniform seed, if for any classical-quantum state ρXE with Hmin (X|E)ρ ≥ k
and for uniform seed Y we have
1
||ρExt(X,Y )Y E − τm ⊗ τd ⊗ ρE || ≤ EXT ,
2
where τd is the maximally mixed state of dimension d.
A quantum-proof (k, EXT )-strong extractor thus provides m bits of randomness (except with probability
EXT ) given a guarantee of k bits of min-entropy in X. Extractors can also use the smooth min-entropy
instead, which often leads to more randomness (the smooth min-entropy can be much larger than the minentropy) in the output with a relatively small penalty in the error term.
Lemma 1 ([34, 41]). If Ext : {0, 1}n × {0, 1}d → {0, 1}m is a quantum-proof (k, EXT )-strong extractor, then
h
for any classical-quantum state ρXE with Hmin
(X|E)ρXE ≥ k
1
||ρExt(X,Y )Y E − τm ⊗ τd ⊗ ρE || ≤ EXT + 2h .
2
The crucial feature in each of these definitions is that they involve the state ρExt(X,Y )Y E as opposed to
ρExt(X,Y )E . This is what makes them strong extractors: we prove that the seed randomness Y remains
random and is uncorrelated with the extractor output and any information held by an adversary (to within
distance EXT + 2h ). This is why the seed is not considered to be consumed in the process.
In this work we use Toeplitz matrices for the extraction, a procedure that was also followed in [8] (see
also [42]). A Toeplitz matrix T is one for which Ti,j = Ti+1,j+1 whenever both elements exist. Thus, to
choose a random Toeplitz matrix we can randomly choose the first row and column, from which all other
entries are fixed. The set of all binary Toeplitz matrices form a set of two-universal hash functions [43, 44],
and hence can be used as quantum-proof (k, EXT )-strong randomness extractors with EXT = 2−(k−m)/2 [34].
Given a raw string of length n with min-entropy k, we can use a randomly chosen m × n binary Toeplitz
matrix T to extract the randomness by multiplication with the raw string modulo 2. Given that EXT drops
exponentially in k − m one can ensure a small error without sacrificing much in the size of the output.
In our case this theoretically simple computation runs into difficulty due to the size of the data considered.
To reduce the computational requirements we perform several simplifications that reduce the problem size
and increase its efficiency.
Firstly, in the protocol we replace Bob’s output, Bi , with 0 in the generation rounds. This means that
none of the entropy accumulated during the protocol is contained within the outputs recorded by Bob during
the generation rounds and so we do not need to include these in our extraction. The extraction from AB
can be performed instead as an extraction from the binary string v = [AB]test , where [B]test is the string
of outputs recorded by Bob during test rounds. By removing the outputs of Bob in the generation rounds
the input to the extractor is roughly half of its original size, making the computation easier.
After this initial simplification we are left with the problem of multiplying an m × n = (6.496 × 109 ) ×
(3.17 × 1012 ) Toeplitz matrix T to the raw data vector v with a length n = 3.17 × 1012 yielding our extracted
randomness M = T v of approximately 6.496 × 109 bits. To reduce the memory requirements we split this

9
matrix-vector multiplication into several smaller matrix-vector multiplications. For some l ≤ m we can split
T into dn/le blocks of size m × l, each comprising l columns, i.e., T = (T1 T2 . . . Tdn/le ) where T1 is the
matrix consisting of the first l columns of T , T2 is the matrix consisting of the second l columns and so
on.[45] Splitting v = (v1 v2 . . . vdn/le ) also into blocks of the same length l we can rewrite the original matrix
vector multiplication as
T v = T1 v1 ⊕ T2 v2 ⊕ · · · ⊕ Tdn/le vdn/le ,

(A1)

where ⊕ denotes elementwise addition modulo 2. In our case we split the problem into 1618 blocks.
Evaluating Ti vi requires an m × l matrix-vector multiplication where m = 6.496 × 109 and l = 1.959 × 109 .
By exploiting the structure of Toeplitz matrices we can use fast Fourier transforms (FFTs) to reduce the
time complexity of this operation from O(m2 ) to O(m log m) [46]. For completeness we now detail the FFT
based algorithm.
An m × n Toeplitz matrix takes the form


a0

a−1

a−2

···
..
.
..
.
..
.

a−(n−2)

a−(n−1)


 a
a0
a−1
a−(n−2)
 1

..
.
..
T =
a1
a0
.
 a2
 .
..
..
..
 .
.
 .
a−(n−1)+(m−2)
.
.
am−1 am−2 am−3 · · · a−n+(m−1) a−(n−1)+(m−1)






,





(A2)

and so is uniquely specified by the vector a = (a−(n−1) , a−(n−2) , . . . , am−1 ). Consider the vector b = (v 0m )
which is the vector v appended with m zeros. Then, the matrix-vector product T v may be computed using
the identity
(cn−1 T v) = F −1 (F(a) } F(b)) ,

(A3)

where cn−1 is some n − 1 dimensional vector, F denotes the discrete Fourier transform, F −1 denotes its
inverse and } denotes the elementwise (Hadamard) product of vectors. Equation (A3) can be derived by
noting that the circular convolution of the two vectors a and b gives a ? b = (cn−1 T v) and furthermore,
the Fourier convolution theorem states that a ? b = F −1 (F(a) } F(b)). Finally, noting that each of the
blocked matrices Ti is itself a Toeplitz matrix we can perform the FFT technique to speed up each of the
Ti vi computations individually.
To implement the extraction procedure we utilized the Viking research cluster and the FFTs were implemented using the Fftw3 package [47]. The total computation time was around 249 hours, split across 32
cores and required around 400GB of memory.[48] In summary, by applying a quantum-proof strong extractor
(Toeplitz hashing) to the output bit-string (3.17 × 1012 bits) we obtained a shorter bit-string (6.496 × 109
bits) which is almost indistinguishable from uniform randomness. Finally, the seed of the extractor a, which
in our implementation has size m + n − 1 bits, is not expended by the protocol (this is a condition for a strong
extractor), and can thus be reused for some other purpose. Alternatively, a public (but trusted) source of
randomness can be used without compromising security (provided it is unknown to the devices before the
protocol is run).
Remark 2. We chose to use Toeplitz hashing for the extraction because it was efficient enough to implement
on our large output data. In principle, other extractors that require shorter seeds would be desirable to use
instead, such as Trevisan’s extractor [41, 49].

4.

Error parameters

Various error parameters feature in the security statements of device-independent randomness expansion.
In this section we reprise the discussion of some of the parameters introduced in the main body of the text,
starting with a calculation of the completeness error. We use the following theorem which gives tight bounds
for the cumulative distribution function (CDF) of the binomial distribution.

10
Theorem 2 ([50, 51]). Let n ∈ N, p ∈ (0, 1) and let X be a random variable distributed according to
X ∼ Binomial(n, p). Then, for every k = 0, . . . , n − 1 we have

s

!
k+1
k+1
p(X ≤ k) ≤ Φ sign
−p
2nG
,p
n
n
≡ C(n, k + 1, p) ,
where G (x, p) = x ln xp + (1 − x) ln 1−x
1−p and Φ(x) =

√1
2π

Rx
−∞

e−

u2
2

du.

We call an implementation of our DIRNE protocol honest if on each round, the state shared between Alice
and Bob and the measurements performed for their respective inputs remain the same. In particular, this
implies that the CHSH score for each test round is distributed in an i.i.d. manner. We can use Theorem 2
to upper-bound the completeness error of an honest implementation of the protocol.
Corollary 1 (Completeness error). Let ωexp be the expected CHSH score achieved by some honest implementation of Protocol DIRNE. Then, the probability that the protocol aborts is no larger than
C(n, dnγ(ωexp − δ)e + 1, γωexp ),

(A4)

where δ > 0 is the selected confidence threshold. In particular, this means the completeness error for the
protocol is C is no larger than (A4).
Proof. For an honest implementation of the protocol the score registers Xi are distributed according to


for x = 1,
γωexp
P[Xi = x] = γ(1 − ωexp ) for x = 0 .

(1 − γ)
for x =⊥
for each i = 1, . . . , n. Recall that the protocol aborts when |{Xi : Xi = 1}| < nγ(ωexp − δ). The quantity
R = |{Xi : Xi = 1}| is a random variable following the binomial distribution Binomial(n, γωexp ). Applying
Theorem 2, we find the probability that the protocol aborts is upper bounded as
P[|{Xi : Xi = 1}| < nγ(ωexp − δ)] ≤ P[|{Xi : Xi = 1}| < dnγ(ωexp − δ)e]
≤ C(n, dnγ(ωexp − δ)e + 1, γωexp ).

The second parameter in the security definitions of randomness expansion is the soundness error S .
Following [15], we may bound the soundness error of our randomness expansion protocol as
S ≤ max{EAT , EXT + 2h }.

(A5)

The first term EAT , which we refer to as the device-independent error, is roughly our tolerance of encountering
‘lucky’ adversaries. In Theorem 3 we see that the error terms depend explicitly on the probability, pΩ , that
the protocol does not abort. Since we work in the device-independent setting we cannot assume to know
the value of pΩ (this can be set by the adversary). Instead, we can replace pΩ with EAT in the error terms
and consider the two possible scenarios. If pΩ ≥ EAT then by making the replacement pΩ 7→ EAT the
error terms only increase and we have genuine lower bound on the accumulated entropy. Otherwise, we have
pΩ ≤ EAT . However, the chances that the protocol passes but the entropy bound is not valid is less than
EAT which can be chosen to be negligibly small. In summary, either the protocol aborts with probability
greater than 1 − EAT or Theorem 3 with pΩ 7→ EAT gives a valid lower bound on the entropy we produce.
The second term comes from the result of applying a strong extractor to the raw output of our experiment
(cf. Lemma 1). It consists of the smoothing parameter h and the extractor error EXT . The extractor
error has far less impact on our results than the smoothing error and for our calculations we choose to set
EXT = 10−5 S . The smoothing parameter, h , plays a more prominent role in both the soundness error and
the lower bound on quantity of certifiable smooth min-entropy (cf. Theorem 3). By reducing the smoothing
parameter we may decrease the soundness error at the expense of smaller bound on the entropy certified
by the entropy accumulation theorem. This relationship is the same for the device-independent error. To
simplify our calculations we set EAT = EXT + 2h .

11
5.

Entropies

In the entropy accumulation theorem, a lower bound on the min-entropy is obtained by way of the αentropy. In this work, we take α ∈ (1, 2], although some definitions and identities hold for wider ranges of
α. We begin with two definitions of the α-entropy.
Definition 4 (Rényi α-entropy [52]). We define the α-entropy by means of the sandwiched Rényi divergence,
Dα (ρ||σ) =

h 1−α 1−α α i
1
,
log Tr σ 2α ρσ 2α
α−1

where ρ and σ are positive semidefinite operators on the same Hilbert space. Then, on a bipartite state ρAB ,
Hα↑ (A|B)ρ = sup −Dα (ρAB ||1A ⊗ σB )
σB

Hα (A|B)ρ = −Dα (ρAB ||1A ⊗ ρB ) .
When it is clear from the context we will omit the subscript ρ.
The smooth min-entropy can be then be lower bounded by [21, 53, 54]
h
Hmin
(A|B)ρ ≥ Hα↑ (A|B)ρ −

1
1
p
log
.
α−1
1 − 1 − 2h

(A6)

Additionally, we need to condition upon observing a pass-event Ω on a classical register. The state can be
written as ρ = pΩ ρΩ + (1 − pΩ )ρΩ⊥ . The entropy of the conditioned state and unconditioned state can be
related by
Hα↑ (A|B)ρΩ ≥ Hα↑ (A|B)ρ −

α
1
log
.
α−1
pΩ

(A7)

This result is proven in Lemma B.5 of [21]. We can combine Equation A6 and Equation A7 to obtain
h
Hmin
(A|B)ρ

≥

Hα↑ (A|B)ρ

α
log
−
α−1

pΩ (1 −

1
p

!
1 − 2h )

,

where we have used that α > 1.

6.

Entropy Accumulation

In this section we outline further improvements to the theory of [21, 22] which produce improved rates
and make randomness expansion experimentally accessible[55]. We consider a set of channels, {Mi }i , for
i ∈ {1, . . . , n} with Mi : S(Ri−1 ) → S(Ai Bi Xi Ri ), sometimes dubbed EAT channels[56].
Definition 5 (EAT channels). Let {Mi }i be a collection of trace preserving completely positive maps with
Mi : S(Ri−1 ) → S(Ai Bi Xi Ri ) for each i = 1, . . . , n. Then the collection {Mi }i is called a set of EAT
channels if for each i = 1, . . . , n the following both hold:
1. The systems Ai , Bi and Xi are all finite dimensional and classical and the state of the register Xi is a
deterministic function of Ai and Bi . The system Ri may be arbitrary.
2. For any state ρR0 E ∈ S(R0 E), the final state ρ[A][B]E = Tr[X]Rn [(Mn ◦ · · · ◦ M1 )ρR0 E ] satisfies the
conditional independence constraints I(Ai−1
: Bi |B1i−1 E) = 0.
1
[I(A : B|C) is the conditional mutual information.]

12
The collection of channels in the above definition represent the sequential interaction with the devices
that occurs during the first four steps of the protocol from the main-text. In particular, as the inputs to our
devices are chosen independently, the second condition trivially holds for any collection of channels we could
use to implement the protocol. Similarly, the nature of the systems imposed by the first condition is also
satisfied by any channel implementing our protocol, Ai are the outputs for round i, Bi are the inputs for
round i and Xi is the recorded score for round i. We may also view EAT channels as quantum instruments,
i.e., for the channel Mi there is a collection of trace non-increasing completely positive maps {Mab
i }ab with
Mab
i : S(Ri−1 ) → S(Ri ) such that for a state ρ ∈ S(Ri−1 ) we have
X
Mi (ρ) =
|aiha|Ai ⊗ |bihb|Bi ⊗ |x(a, b)ihx(a, b)|Xi ⊗ Mab
(A8)
i (ρ),
a,b

where x(a, b) is a deterministic function of the inputs and outputs and Tr[Mab
i (ρ)] = p(a, b).
Definition 6 (Frequency distribution). Let ρ[X]R be a CQ state. Then we define
freq[X] (x) =

|{i ∈ {1, . . . , n} : Xi = x}|
,
n

and use freq[X] to refer to the induced probability distribution.
Let P denote the set of all probability distributions over the possible outputs of the score register X.
Similarly, let Q denote the set of probability distributions over the possible outputs of the score register X
that could arise from the application of an EAT channel to some state. Formally, we define
(
)
X
Q = pX : ∃ M, ρRR0 such that M(ρRR0 )X =
pX (x) |xihx| ,
(A9)
x

where ρRR0 is a joint state of two finite dimensional quantum systems, M is an EAT channel acting on the
system R and M(ρRR0 )X denotes the state after applying M and tracing out all systems apart from the
score system X.
Lemma 2. The set Q is convex.
Proof. Consider two distributions p, q ∈ Q. To prove convexity we must show that for any λ ∈ (0, 1) we have
λp + (1 − λ)q ∈ Q.
Let M : S(R) → S(ABXR0 ) and ρ ∈ S(R) be the EAT-channel and state that achieves the distribution
p ∈ Q. Similarly, let N : S(T ) → S(ABXT 0 ) and τ ∈ S(T ) be the EAT-channel and state that achieves the
distribution q ∈ Q. Let {Mab }ab and {N ab }ab be the collections of trace non-increasing maps that define
the instrument form of M and N respectively (cf. (A8)). Then define the direct sum channel M ⊕ N :
S(R ⊕ T ) → S(ABX(R0 ⊕ T 0 )) by the action
!
!
X
L1 L2
Mab (L1 )
0
(M ⊕ N )
=
|a b x(x, b)iha b x(a, b)|ABX ⊗
,
L†2 L3
0
N ab (L3 )
a,b
where L1 and L3 have the same dimensions as R and T respectively. This is a valid quantum channel if for
each pair (a, b), the map
!
!
Mab (L1 )
0
L1 L2
ab
ab
,
(M ⊕ N )
=
L†2 L3
0
N ab (L3 )
is trace non-increasing and completely positive. The trace non-increasing condition follows from the fact
ab
ab
that the maps are individually trace non-increasing, so Tr[L!
1 ] + Tr[L3 ] ≥ Tr[M (L1 )] + Tr[N (L3 )]. That
L1 L2
the map is completely positive follows because if
is positive then so are L1 and L3 and hence
L†2 L3
Mab (L1 ) and N ab (L3 ). This channel also satisfies the definition of an EAT channel for the same reasons
discussed immediately after Definition 5.

13
Now, applying the direct sum channel to the state λρ ⊕ (1 − λ)τ ∈ S(R ⊕ T ), we have
(M ⊕ N )(λρ ⊕ (1 − λ)τ ) =

X

|a b x(a, b)iha b x(a, b)|ABX ⊗ (λMab (ρ) ⊕ (1 − λ)N ab (τ )).

(A10)

a,b

Now the probability that X = x is given by
X

P[X = x] =

P[A = a, B = b]

(a,b):x(a,b)=x

X

=

Tr[λMab (ρ) ⊕ (1 − λ)N ab (τ )]

(a,b):x(a,b)=x

X

=λ

X

Tr[Mab (ρ)] + (1 − λ)

(a,b):x(a,b)=x

Tr[N ab (τ )]

(a,b):x(a,b)=x

= λp(x) + (1 − λ)q(x).
On the first line we used that X is a deterministic function of A and B, on the second line we used (A10)
to compute the probabilities and the third line follows from the linearity of the trace. As we have defined a
valid state and EAT-channel that achieves a distribution λp + (1 − λ)q we must have λp + (1 − λ)q ∈ Q.
Given a distribution q ∈ Q, we can identify the set of states and channels Γ(q) that can achieve q, i.e., for
every (ω, M) ∈ Γ(q), the expected distribution generated by M(ω) on the X register is q. In other words,
)

(
Γ(q) =

(ωRR0 , M) : M(ωRR0 )X =

X

q(x) |xihx| ,

x

where R is an arbitrary quantum system and M is an EAT-channel acting on states on R, R0 is an arbitrary
quantum system upon which the channel does not act, it may for instance be a purifying system of the
reduced state ωR .
We now define round-by-round lower bounds on the von Neumann entropy, f (q), known as min-tradeoff
functions.
Definition 7 (Min-tradeoff functions). A function rate : Q → R is called a rate function if for all q ∈ Q we
have
rate(q) ≤

inf
(ωRR0 ,M)∈Γ(q)

H(A|BR0 )M(ω) .

We refer to affine rate functions as min-tradeoff functions, and for these we reserve the symbol f .
Remark 3. This definition differs slightly from the definitions of min-tradeoff functions in [21, 22]. In these
works, min-tradeoff functions are defined with respect to a collection of EAT-channels. In device-independent
applications we do not assume to know the collection of channels used during an actual run of the protocol
and so if we define our min-tradeoff functions in the same way as [21, 22] then we must show later that our
bounds hold for any possible collection of channels compatible with the observed statistics. Here, we instead
absorb this infimum over all collections of channels directly into our definition of a min-tradeoff function.
Rate and min-tradeoff functions are lower bounds to the worst-case von Neumann entropy for any individual
round, given in terms of the score. Whilst rate functions are only defined on the set Q (the infimum is trivial
for distributions not in Q), we allow the domain of the min-tradeoff functions (affine rate functions) to be
naturally extended to all probability distributions on X.
The entropy accumulation theorem derives global bounds on the min-entropy in terms of min-tradeoff
functions. In the following lemma we show that any tight rate function is convex function on Q.
Lemma 3 (Convexity of optimal rate functions). Let rateopt (q) := inf (ω,M)∈Γ(q) H(A|BR0 )M(ω) . Then,
rateopt is a convex function on the set Q.

14
Proof. Let p, q ∈ Q and λ ∈ (0, 1). Now if rateopt (p) = inf (ωRR0 ,M)∈Γ(q) H(A|BR0 )M(ω) then for all  > 0
there exists some (ρRR0 , M) ∈ Γ(p) such that H(A|BR0 )M(ρRR0 ) < rateopt (p) + . Similarly, we can find
(τSS 0 , N ) ∈ Γ(q) such that H(A|BS 0 )N (τSS0 ) < rateopt (q) +  for some auxiliary quantum systems R0 and S 0
which need not be the same.
Now consider the state λρ ⊕ (1 − λ)τ ∈ S((RR0 ) ⊕ (SS 0 )) and the channel M ⊕ N : S((RR0 ) ⊕ (SS 0 )) →
S(ABX((R1 R0 ) ⊕ (S1 S 0 ))). We know from the construction in the proof of Lemma 2 that the pair (λρ ⊕
(1 − λ)τ, M ⊕ N ) ∈ Γ(λp + (1 − λ)q), where M and N act trivially on their respective auxiliary systems R0
and S 0 . We may add an additional ‘flag’ system F which indicates which part of the direct sum our state is
in, i.e., we now extend our state to
ω = λ(ρ ⊕ 0) ⊗ |0ih0|F + (1 − λ)(0 ⊕ τ ) ⊗ |1ih1|F .
Note that by tracing out F we recover the original direct product state. Moreover, as the channel M ⊕ N
does not act on F the statistics will not be altered, i.e., (ω, (M ⊕ N ) ⊗ 1F ) ∈ Γ(λp + (1 − λ)q). Now, by
conditioning on the classical information F we may write
H(A|BR0 S 0 F )(M⊕N )(ω) =λH(A|BR0 S 0 F = 0)(M⊕N )(ω) + (1 − λ)H(A|BR0 S 0 F = 1)(M⊕N )(ω)
= λH(A|BR0 )M(ρ) + (1 − λ)H(A|BS 0 )N (τ ) ,
where on the second line we have used the fact that conditioned on value of F the state is trivial on RR0 or
SS 0 .
It follows that for all  > 0 we have
H(A|BR0 S 0 F )(M⊕N )(ω) < λ rateopt (p) + (1 − λ) rateopt (q) +  ,
and so
H(A|BR0 S 0 F )(M⊕N )(ω) ≤ λ rateopt (p) + (1 − λ) rateopt (q).
Then, since H(A|BR0 S 0 F )(M⊕N )(ω) ≥ rateopt (λp + (1 − λ)q), we recover the condition for convexity
rateopt (λp + (1 − λ)q) ≤ λ rateopt (p) + (1 − λ) rateopt (q) .
In order to use our min-tradeoff functions with the entropy accumulation theorem we require knowledge
of several of their properties. Namely, if f is a min-tradeoff function then we define:
• Maximum over all probability distributions:
Max(f ) = max f (p).
p∈P

(A11)

• Minimum over all quantum distributions:
MinQ (f ) = inf f (p).
p∈Q

(A12)

• Variance
Varp (f ) =

X

p(x)(f (δx ) − E[f (δx )])2 .

(A13)

x

In the final definition, δx denotes the probability distribution with p(x) = 1. As f is an affine function,
the final definition is the statistical variance of the function g(x) = f (δx ). In [22] Var(f ) is defined to be
Var(f ) = supp∈Q Varp (f ), which gives a worst-case variance over all quantum distributions.
In order to explain our modification to the entropy accumulation theorem we shall reproduce a preliminary
step in the proof, beginning Proposition V.3 in [22]. Let f be an affine min-tradeoff function for some set of
EAT channels {Mi }i . We apply at each round a channel Di : Xi → Xi Di , which encodes the min-tradeoff
function directly. In particular, we define
Di (|xihx|Xi ) = |xihx|Xi ⊗ τ (x)Di ,

15
where τ (x)Di is defined so that Hα (τ (x)Di ) = Max(f ) − f (δx ) for some fixed α. We then apply the channels
to the state to get ρABXDE = Dn ◦ · · · ◦ D1 (ρABXE ). In a real protocol, the acceptance of a state will be
conditioned upon some success event Ω, determined by the values observed on the X registers (such as a
minimal threshold for the CHSH score). Let ρABXE|Ω be the state conditioned on passing. It can then be
shown that
Hα↑ (A|BE)ρ|Ω ≥ Hα (AD|BE)ρ|Ω − nMax(f ) + nh,
where h is defined to be inf p∈Ω f (p) (see Equation 33 in [22]). Then, using Equation A7, we obtain
Hα↑ (A|BE)ρ|Ω ≥ Hα (AD|BE)ρ −

α
1
log
− nMax(f ) + nh,
α−1
pΩ

which relates the bound for the state conditioned on Ω to the unconditioned state.
We now seek a lower bound to Hα (AD|BE) in terms of the von Neumann entropy. The first step involves
using the chain rules of [21, 22] to obtain
X
Hα (AD|BE)ρ ≥
inf Hα (Ai Di |Bi R)Di ◦Mi (ω) .
i

ωRi−1 R

From this, we apply a continuity bound relating the von Neumann entropy to the α-entropies which yields
X
Hα (AD|BE)ρ ≥
inf (H(Ai |Bi R)Di ◦Mi (ω) + H(Di |Xi )Di ◦Mi (ω) +
i

ωRi−1 R

− (α − 1)V (Ai Di |Bi R)Di ◦Mi (ω) − (α − 1)2 Kα (Ai Di |Bi R)Di ◦Mi (ω) ) ,

(A14)

where for CQ states
V (Ai Di |Bi R)Di ◦Mi (ω) ≤

ln 2
2



log(1 + 2d2A ) +

q

2
2 + Varp (f )

≡ V (f, p),



1
3
(α−1)(log dA +Max(f )−MinQ (f ))
log dA +Max(f )−MinQ (f )
2
2
ln
2
+
e
6(2 − α)3 ln 2
≡ Kα (f ) .

Kα (Ai Di |Bi R)Di ◦Mi (ω) ≤

So far we have not deviated from the argument of [22], in which they then employ the following simplifications
2
p
ln 2 
V (f, q) ≤ V (f ) ≡
log(1 + 2d2A ) + 2 + Var(f ) ,
2
where Var(f ) = supp∈Q Varp (f ), and
H(Ai |Bi R)Di ◦Mi (ω) + H(Di |Xi )Di ◦Mi (ω) = H(Ai |Bi R)Di ◦Mi (ω) + Max(f ) − f (p)
≥ Max(f ) ,
which is seen by noting that H(Ai |Bi R)Di ◦Mi (ω) = H(Ai |Bi R)Mi (ω) ≥ f (p) by the definition of the channel
D and the min-tradeoff function (where p is assumed to be the distribution on the Xi register). These
simplifications render the error term ‘statistics agnostic’, in the sense that Equation A14 becomes
X
Hα (AD|BE)ρ ≥
(Max(f ) − (α − 1)V (f ) − (α − 1)2 Kα (f ))
i

= n(Max(f ) − (α − 1)V (f ) − (α − 1)2 Kα (f )) ,
which is independent of the actual statistics observed and this incurs a significant loss of entropy in the
regimes of interest to us. Instead, by not taking the supremum in V (f, q) and by permitting a tighter bound
to H(Ai |Bi R)Mi (ω) , we find an improvement.
Given a rate function, we can instead use the bounds H(Ai |Bi R)Di ◦Mi (ω) = H(Ai |Bi R)Mi (ω) ≥ rate(p).
Defining ∆(f, p) := rate(p) − f (p), this leads instead to



2
Hα (AD|BE)ρ ≥ n Max(f ) + inf ∆(f, p) − (α − 1)V (f, p) − (α − 1) Kα (f )
.
(A15)
p∈Q

16
The presence of the ∆(f, p) term yields a two-fold advantage. Not only is it a positive contribution to the
final entropy, but it effectively constrains the probability distribution on the error terms to be close to the
actual value of the observed probability distribution. While we still take a worst-case optimisation over
distributions, we do it in a way that depends explicitly on the min-tradeoff function so that our optimisation
is no longer independent of the actual statistics. By taking min-tradeoff functions that are tangent to some
convex rate function, ∆(f, p) will grow to dominate the error terms if q varies too far from the tangent
point. To ensure convergence of the minimisation to a globally optimal point and hence a true lower bound
in (A15), we show that computing the infimum is a convex optimisation problem.
Lemma 4 (Convexity of the objective). Let f be a min-tradeoff function, rate be a convex rate function and
α ∈ (1, 2). Then,

inf ∆(f, p) − (α − 1)V (f, p) − (α − 1)2 Kα (f )
(A16)
p∈Q

is a convex optimisation problem.
Proof. We note that the domain of the optimisation is Q which is a convex set (see Lemma 2). The first
term ∆(f, p) = rate(p) − f (p)
p is convex since rate(p) is convex and f (p) is affine. The second term can be
written as V (f, p) = c(d + 2 + Varp (f ))2 where c and d are positive constants. We note that Varp (f ) is
the variance of the function g(x) = f (δx ). Variance
p is concave in the probability distributionpand the square
root is an increasing concave function, hence 2 + Varp (f ) is concave. Expanding c(d + 2 + Varp (f ))2
we find that it is a non-negatively weighted sum of concave functions, hence also concave. This implies that
−(α − 1)V (f, p) is convex. Lastly, Kα does not depend on p and is hence a constant term. Overall, we find
that the objective function is a non-negatively weighted sum of functions that are convex in p and hence is
itself a convex function. Finally, minimising a convex function over a convex set is a convex optimisation
problem.

7.

Infrequent sampling and the CHSH game

The spot-checking format of the protocol enforces a particular structure in the probabilities distributions
over the score register that can be produced by the protocol. In particular, the expected distributions over
Xi for each round i must take the form
(
γq(x)
for x 6=⊥,
P[Xi = x] =
,
(A17)
(1 − γ) for x =⊥
where q is a distribution over the test-round scores for round i. That is, each p ∈ Q follows this structure
if we perform spot-checking. To capture this structure in the construction of our min-tradeoff functions
we follow [22, Section 5], by first defining a min-tradeoff function that only takes the statistics of a test
round and then extending the domain of the function to include the no-test symbol ⊥. Formally, we define
infrequent sampling channels as follows.
Definition 8 (Infrequent sampling channel). An infrequent sampling channel, Mi : Ri−1 → Ai Bi Xi Ri is a
channel that decomposes according to
Mi (·) = γMtest
(·) + (1 − γ)Mgen
i
i (·) ⊗ |⊥ih⊥|Xi

(A18)

where Mtest
: Ri−1 → Ai Bi Xi Ri with h⊥| Mtest
(ρRi−1 R0 )Xi |⊥i = 0 for any quantum state ρRi−1 R0 and
i
i
gen
Mi : Ri−1 → Ai Bi Ri .
Thus, on round i the channel Mgen
occurs with probability 1 − γ and this event is recorded with ⊥ in the
i
Xi register and otherwise a test channel acts with the score is written to the Xi register. We define the set
of test round distributions Qtest as
(
)
X
test
test
Q
= qX : ∃ M, ρRR0 such that M (ρRR0 )X =
qX (x) |xihx| ,
(A19)
x

17
where M is an infrequent sampling channel. Let g be an affine function satisfying
)
(
X
0
test
H(A|BR )M(ωRR0 ) : M (ωRR0 )X =
q(x) |xihx| ,
g(q) ≤ inf
(ωRR0 ,M)

(A20)

x

for all q ∈ Qtest . Then for c⊥ ∈ R, the function
(
1
g(δx ) + (1 − γ1 )c⊥
f (δx ) = γ
c⊥

if x 6=⊥
if x =⊥

(A21)

is a min-tradeoff function for the spot checking protocol (in [22], the authors set c⊥ = Max(g)). To show
this, we note that because of the structure of infrequent sampling channels (cf. (A17)), for any p ∈ Q there
exists a q ∈ Qtest such that p(x) = γq(x) for x 6=⊥ and p(⊥) = 1 − γ. For p ∈ Q, we then have

 

X
X
1
1
g(δx ) + 1 −
c⊥
p(x)f (δx ) = (1 − γ)c⊥ + γ
q(x)
γ
γ
X
= (1 − γ)c⊥ +
q(x)g(δx ) − (1 − γ)c⊥
= g(q) .
As g(q) is defined as a lower bound on the von Neumann entropy (A20), f (p) must also be and hence is a
min-tradeoff function. We obtain expressions for V (f, p) and Kα (f ) by noting that




1
1
Max(f ) = max
Max(g) + 1 −
c⊥ , c ⊥ ,
γ
γ
MinQ (f ) = MinQ (g),
X q(x)
(c⊥ − g(δx ))2 .
Varp (f ) ≤
γ
x
The first property is by definition Max(f ). The second property MinQ (f ) follows from the fact that for any
p ∈ Q we have that f (p) = g(q) for some q ∈ Qtest . For Varp (f ), we explicitly calculate
X
Varp (f ) =
p(x)f (δx )2 − f (p)2
x

=

X


γq(x)

x


 2
1
1
g(δx ) + 1 −
c⊥ + (1 − γ)c2⊥ − g(q)2 ,
γ
γ

where we have used that f (q) = g(q) and substituted the explicit forms of p(x) and f (δ⊥ ). We can expand
the term in the sum

 2 X



2 !

X
1
1
1
1
1
1
2
g(δx ) + 1 −
c⊥
=
γq(x)
g(δx ) + 2
1−
g(δx )c⊥ + 1 −
c2⊥
γq(x)
2
γ
γ
γ
γ
γ
γ
x
x


X q(x)
1
(γ − 1)2 2
2
=
g(δx ) + 2 1 −
g(q)c⊥ +
c⊥ .
γ
γ
γ
x
Inserting the final line into the formula for Varp (f ) we can rearrange the expression to get
Varp (f ) =

1X
2
q(x) (c⊥ − g(δx )) − (c⊥ − g(q))2 .
γ x

As the final term is strictly negative we arrive at the desired result.
We wish to apply this to a rate function for the CHSH game. In the CHSH game we have a binary score,
i.e., X ∈ {0, 1}√for test rounds.
√
For quantum systems the probability of winning (scoring one) is bounded
by q ∈ 1/2 − 2/4, 1/2 + 2/4 . A rate function in terms of the CHSH score (without spot-checking) was

18
first derived in [57], and has been applied previously in the context of device-independent cryptography [4].
This rate function, which plays the role of g(q) above, is defined as



p
1
1
1
1
1
1

1 − Hbin 2 + 2 16q(q − 1) + 3 , if 0.75 ≤ q ≤ 2 (1 + √2 ) or 2 (1 − √2 ) ≤ q ≤ 0.25
rateCHSH (q) = 0,
if 0.25 ≤ q ≤ 0.75


undefined
otherwise
where Hbin (x) := −x log(x)−(1−x) log(1−x) is the binary Shannon entropy. We note that the rate function
is undefined for winning probabilities that are not quantum-achievable. It also only takes into account the
randomness obtained from one of Alice’s devices and does not consider the full measurement statistics, so
one could hope to gain more entropy if both parties outputs are taken into account. As rateCHSH is a convex
function, we can √
obtain a family
√ of min-tradeoff functions by taking the tangent to this rate function at any
point t ∈ 1/2 − 2/4, 1/2 + 2/4 . Denoting these functions by gt , we have
gt (q) = rateCHSH (t) + (q − t) rate0CHSH (t) ,

(A22)

where the prime indicates the derivative. As these functions are affine we can uniquely extend their domains
to include all q ∈ [0, 1]. Then, we can define our min-tradeoff function as
(
1
gt (δx ) + (1 − γ1 )c⊥ if x ∈ {0, 1}
(A23)
ft (δx ) = γ
c⊥
if x =⊥
with g(δ0 ) = 0. Note that due to the spot checking structure, for a fixed γ ∈ (0, 1), rateCHSH also defines a
rate function on Q via rate(p) = rateCHSH (q). Recall also that we have a freedom to choose both the tangent
point t and the value of c⊥ , we shall later optimize over these values. The family of functions ft can then
be applied to the entropy accumulation theorem. Before stating the main theorem, we revert back to some
of the original notation of the main text. We note that A refers to the outputs of Alice’s devices B refers
to the inputs, and X the register that records scores and round-type. Thus, for consistency with the main
body, in the theorem below we make the substitutions, A → AB, B → XY and X → U.
Theorem 3 (Entropy accumulation for the CHSH game). Let ρ[A][B][XY U ]E be a CQ state (classical
on [A][B][XY U ])√produced by the CHSH protocol from the main text with test probability γ ∈ (0, 1). Let
ωexp ∈ (0.75, 1/2+ 2/4], δ > 0 and n ∈ N. Let Ω refer to the event specified by |{Ui |Ui = 1}| ≥ nγ(ωexp −δ),
pΩ the probability of this event occurring for ρ[A][B][XY U ]E , and ρ[A][B][XY U ]E|Ω the state conditioned on
this occurrence. Let h ∈ (0, 1), α ∈ (1, 2) and let rateCHSH and ft be defined as above. Then for any r such
that ft (freq[u] ) ≥ r for every [u] ∈ Ω we have
h
Hmin
([AB]|[XY

]E)ρ[A][B][XY U ]E|Ω

α
log
> nr−
α−1

pΩ (1 −

1
p

!
1 − 2h )


+ n inf ∆(ft , p) − (α − 1)V (ft , p) − (α − 1)2 Kα (ft ) ,
p∈Q

where
∆(ft , p) = rateCHSH (q) − ft (p)
r

2
ln 2
1
V (ft , p) =
log(9) + 2 + Varp (ft )
2
γ


1
3
(α−1)(1+Max(ft )−MinQ (ft ))
1+Max(ft )−MinQ (ft )
2
Kα (ft ) =
2
ln
2
+
e
.
6(2 − α)3 ln 2
In the above theorem, the argument of rateCHSH (q) is the unique distribution q ∈ Qtest such that p(x) =
γq(x) for x 6=⊥. Note that we can optimize the above bound by taking the supremum over c⊥ , t and α. Once
a lower bound for the smooth min-entropy has been obtained, a randomness extraction procedure ensures
that the security definitions are satisfied.

19
Appendix B: System characterization
1.

Determination of single photon efficiency

We define the single photon heralding efficiency as ηA = C/NB and ηB = C/NA for Alice and Bob, in
which two-photon coincidence events C and single photon detection events for Alice NA and Bob NB are
measured in the experiment. The heralding efficiency is listed in Tab. I, where η sc is the efficiency of coupling
entangled photons into single mode optical fibre, η so the optical efficiency due to limited transmittance of
optical elements in the source, η fibre the transmittance of fibre linking source to measurement station, η m the
efficiency for light passing through the measurement station, and η det the single photon detector efficiency.
The heralding efficiency and the transmittance of individual optical elements are listed in Tab. I, where η so ,
η fibre , η m , η det can be measured with classical light beams and NIST-traceable power meters.
TABLE I. Characterization of optical efficiencies in the experiment.
heralding efficiency (η)
Alice
Bob

80.41%
82.24%

2.

η sc

η so

η fibre

ηm

η det

93.5%
94.8% 95.5%
95.9% 99.0%
93.5%
95.2% 97.3%

Quantum state and measurement bases

To maximally violate the Bell inequality in experiment, we aim to create a non-maximally entangled twophoton state [26] cos(24.3◦ ) |HV i + sin(24.3◦ ) |V Hi and set measurement bases to be A1 = −83.08◦ and
A2 = −118.59◦ for Alice, and B1 = 6.92◦ and B2 = −28.59◦ for Bob, respectively. We also optimize the
mean photon number to be 0.22 to maximize CHSH score.
We measure diagonal/anti-diagonal visibility in the basis set (45◦ , −24.3◦ ), (114.3◦ , 45◦ ) for minimum
coincidence, and in the basis set (45◦ , 65.7◦ ), (24.3◦ , 45◦ ) for maximum coincidence, where the angles represent measurement basis cos(θ) |Hi + sin(θ) |V i for Alice and Bob. By setting the mean photon number
to µ = 0.0023 to suppress the multi-photon effect, we measure the visibility to be 99.4% and 98.5% in
horizontal/vertical basis and diagonal/anti-diagonal basis.
We perform quantum state tomography measurement of the non-maximally entangled state, with result
shown in Fig. 5. The state fidelity is 99.10%. We attribute the imperfection to multi-photon components,
imperfect optical elements, and imperfect spatial/spectral mode matching.
3.

Spacetime configuration of the experiment

To close the locality loophole in test rounds, space-like separation must be satisfied between relevant events
at Alice and Bob’s measurement stations: the state measurement events by Alice and Bob, measurement
event at one station and the setting choice event at the other station (Fig. 6). We then obtain
(
A
A
A
A
(|SA| + |SB|)/c > TE − (LSA − LSB )/c + TQRNG
+ TDelay
+ TPC
+ TM
,
(B1)
B
B
B
B
(|SA| + |SB|)/c > TE + (LSA − LSB )/c + TQRNG + TDelay + TPC + TM ,
where |SA| = 93 m (|SB| = 90 m) is the free space distance between entanglement source and Alice’s
(Bob’s) measurement station, TE = 10 ns is the generation time for entangled photon pairs, which is mainly
contributed by the 10 ns pump pulse duration, LSA = 191 m (LSB = 173.5 m) is the effective optical path
which is mainly contributed by the long fibre (130 m, 118 m) between source and Alice/Bob’s measurement
A
B
A
station, TQRNG
= TQRNG
= 96 ns is the time elapse for QRNG to generate a random bit, TDelay
= 270 ns
B
A
B
(TDelay = 230 ns) is the delay between QRNG and Pockels cells, TPC = 112 ns (TPC = 100 ns) including the
internal delay of the Pockels Cells (62 ns, 50 ns) and the time for Pockels cell to stabilize before performing
single photon polarization state projection after switching which is 50 ns, which implies that the experimental
time is able to be shortened by increasing the repetition rate of the experiment because the low testing

20
State Tomography (Real)

State Tomography (Imaginary)

1

1

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0

0
HH

VV
HV

VH
VH

HV
VV

VV

HH

VH

HV
HV

VH

HH

HH

VV

(a)

(b)

FIG. 5. (color online) Tomography of the produced two-photon state in the experiment, with real and imaginary
components shown in (a) and (b), respectively.

B
A
= 100 ns) is the
= 55 ns (TM
probability reduced the impact of the modulation rate of the Pockels cells, TM
time elapse for SNSPD to output an electronic signal, including the delay due to fibre and cable length.
The measurement independence requirement is satisfied by space-like separation between entangled-pair
creation event and setting choice events, so we can have

(

A
A
|SA|/c > LSA /c − TDelay
− TPC
B
B
|SB|/c > LSB /c − TDelay
− TPC

(B2)

As shown in Fig. 6, Alice’s and Bob’s random bit generation events for input setting choices are outside
the future light cone (green shade) of entanglement creation event at the source.

Appendix C: Parameter determination and Experimental Results
1.

Parameter determination

The implementation of the protocol depends on several parameters which we can choose in advance.
Firstly, we pre-determine the testing probability γ based on a 10 minute-Bell test at a repetition frequency
of 200 KHz. The counts are summarized in Tab. II. With ωexp = 0.750809, the optimal testing probability
γopt is basically independent of soundness error S and completeness error C as shown in Tab. III. The
amount of randomness expansion we achieve depends on the testing probability, γ. In Fig. 7 we show this
behaviour, indicating the value chosen in our experiment (γ = 1.194 × 10−4 ). Although this was chosen
slightly sub-optimally, it is sufficient for our purposes.
With ωexp = 0.750809 and choose the soundness and completeness errors to be S = 5.74 × 10−8 and
C = 1 × 10−6 , randomness expansion is expected to be witnessed within 200 hours. To ensure success
we run the experiment for slightly longer than this (220 hours), corresponding to 3.168 × 1012 rounds. In
Table IV we show how the amount of randomness would vary by adjusting the completeness and soundness
errors.

21

Time(ns)
700
A
TM

B
TM

600

TPAC

TPBC

500
400

A
TDelay

B
TDelay

300
200

A
TQRNG

B
TQRN
G

100
TE

Source

Alice

Bob

Bob
Source

90m

93m

Alice

FIG. 6. Spacetime analysis of the test rounds. TE = 10 ns is the time elapse to generate a pair of entangled photons.
A,B
A,B
TQRNG
is the time elapse to generate random bits to switch the Pockels cell. TDelay
is the delay between QRNG
A,B
and the Pockels cell. TPC is the time elapse for the Pockels cell to be ready to perform state measurements after
A,B
receiving the random bits from the QRNG. TM
is the time elapse for the SNSPD to output an electronic signal.
A
B
A
B
A
B
A
= 55 ns
= 100 ns, TM
= 112 ns and TPC
= 96 ns, TDelay
= 270 ns and TDelay
= 230 ns, TPC
= TQRNG
For TQRNG
B
and TM = 100 ns, we place Alice’s measurement station and Bob’s measurement station on the opposite side of the
source and 93 ± 1 (90 ± 1) meter from the source, and set the effective optical length between Alice’s (Bob’s) station
and the source to be 130 m (118 m). This arrangement ensures spacelike separation between measurement event and
distant base setting event and between base setting event and photon pair emission event.

TABLE II. Counts of training rounds. Recorded number of two-photon detection events for four sets of polarization state measurement bases x = 0 or 1 indicates “0−” or “1/2−” wave voltages for Pockels cell respectively and
a = 1 or 0 indicates that Alice detects a photon or not, the same applies for y and b on Bob’s side. The CHSH score
is 0.750809.
Basis settings ab = 00 ab = 10 ab = 01 ab = 11
xy
xy
xy
xy

= 00
= 01
= 10
= 11

29172431
28732552
28711770
27868246

2.

214574
654944
154239
1043044

181730
134767
637085
1033950

422697
471554
483897
82496

Experimental results

The recorded experimental data are listed in Table V. We assign 1 for a detection event and 0 for no
detection. The CHSH score ωCHSH as given by
ωCHSH =

i yi =kl
X nxX

k,l

i=1

(1 + (−1)ai ⊕bi ⊕(xi ·yi ) )/nxi yi =kl ,

(C1)

22
TABLE III. Parameters for achieving randomness expansion with expected score. With ωexp = 0.750809
and different soundness error S and completeness error C , nmin represents the minimal expected number of rounds
witness expansion, which corresponds to the optimal testing probability, γopt .
S

C

nmin

γopt

1 × 10−3 1 × 10−3 1.254 × 1012 1.010 × 10−4
1 × 10−3 1 × 10−6 1.944 × 1012 1.010 × 10−4
1 × 10−3 1 × 10−9 2.559 × 1012 1.008 × 10−4
1 × 10−6 1 × 10−3 1.831 × 1012 1.010 × 10−4
1 × 10−6 1 × 10−6 2.647 × 1012 1.010 × 10−4
1 × 10−6 1 × 10−9 3.357 × 1012 1.008 × 10−4
1 × 10−9 1 × 10−3 2.355 × 1012 1.010 × 10−4
1 × 10−9 1 × 10−6 3.270 × 1012 1.010 × 10−4

Rate of expansion randomness (bits per round)

1 × 10−9 1 × 10−9 4.053 × 1012 1.008 × 10−4

10 -4

3

expansion rate with n = nmin
expansion rate with n = nact

2

threshold
our result

1

0

-1

-2
0.6

0.9

1.2

1.5

Testing probability,

1.8
10

-4

FIG. 7. Expansion rate versus the value of γ. With a fixed number of rounds and ωexp = 0.750809, the expansion
rate changes slowly around the optimal value of γ (fixing the other parameters to those used in the protocol). The
yellow dashed line is the threshold to witness expansion. The blue and orange smooth lines represent the expansion
rate with expected number of rounds nmin = 2.91×1012 and actual number of rounds nact = 3.168×1012 , respectively.
The black plus stands for the value of γ = 1.194 × 10−4 used in our experiment.

TABLE IV. Values of the net output that our experiment would achieve with varying completeness and soundness
errors. ‘–’ represents that the consumed randomness surpasses the amount generated.
S
C

10−3

10−4

10−5

10−6

10−7

10−8

10−9

10−3 3.15 × 109 2.73 × 109 2.36 × 109 2.01 × 109 1.70 × 109 1.40 × 109 1.12 × 109
10−4 2.64 × 109 2.22 × 109 1.84 × 109 1.50 × 109 1.18 × 109 8.85 × 108 6.06 × 108
10−5 2.19 × 109 1.77 × 109 1.40 × 109 1.05 × 109 7.36 × 108 4.39 × 108 1.60 × 108
10−6 1.79 × 109 1.37 × 109 9.97 × 108 6.54 × 108 3.37 × 108 4.04 × 107

–

10−7 1.43 × 109 1.01 × 109 6.33 × 108

–

–

–

–

10−8 1.09 × 109 6.72 × 108 2.96 × 108

–

–

–

–

–

–

–

–

10

−9

8

8

7.78 × 10 3.57 × 10

–

23
with (k, l) ∈ (0, 1) × (0, 1) is computed to be 0.750805. After applying a 6.496 Gb ×3.17 Tb Toeplitz matrix
hashing, we obtain 6.496×109 genuinely quantum-certified random bits with a uniformity within 5.74×10−8 ,
which is equivalent to 2.63 × 108 net bits after subtracting the randomness consumed. The stream of random
bits pass the NIST statistical test suite (see Tab. VI for details).
We have made the final random output available at https://tinyurl.com/qssxxaq so that it may be
used for testing (the output has been split between several files for convenience of downloading).
TABLE V. Counts of experimental rounds. Recorded number of two-photon detection events for four sets of
polarization state measurement bases x = 0 or 1 indicates “0−” or “1/2−” wave voltages for Pockels cell respectively
and a = 1 or 0 indicates that Alice detects a photon or not, the same applies for y and b on Bob’s side. The CHSH
score is 0.750805.
Basis settings
ab = 00
ab = 10
ab = 01
ab = 11
xy = 00(generation) 3079174741623 22815515154 19498193776 46131693660
xy = 00
91961904
681402
582328
1377758
xy = 01
90500314
2120124
457496
1503804
xy = 10
90460255
502741
2061782
1557955
xy = 11
87602250
3356060
3353628
263743

To check the statistical properties of our output, we run it through the NIST test suite [58]. To do so, we
set the section length to 1 Mbits for our 6.496 × 109 random output bits. As shown in Tab. VI, the random
bits successfully pass the tests.

[1] R. Colbeck, Quantum and Relativistic Protocols For Secure Multi-Party Computation, Ph.D. thesis, University
of Cambridge (2007), also available as arXiv:0911.3814.
[2] R. Colbeck and A. Kent, Journal of Physics A 44, 095305 (2011).
[3] S. Pironio, A. Acin, S. Massar, A. Boyer de la Giroday, D. N. Matsukevich, P. Maunz, S. Olmschenk, D. Hayes,
L. Luo, T. A. Manning, and C. Monroe, Nature 464, 1021 (2010).
[4] R. Arnon-Friedman, F. Dupuis, O. Fawzi, R. Renner, and T. Vidick, Nature communications 9, 459 (2018).
[5] Y. Liu, X. Yuan, M.-H. Li, W. Zhang, Q. Zhao, J. Zhong, Y. Cao, Y.-H. Li, L.-K. Chen, H. Li, T. Peng, Y.-A.
Chen, C.-Z. Peng, S.-C. Shi, Z. Wang, L. You, X. Ma, J. Fan, Q. Zhang, and J.-W. Pan, Phys. Rev. Lett. 120,
010503 (2018).

TABLE VI. Results of the NIST test suite after dividing our output into 1 Mbit sections.
Statistical tests
Frequency
BlockFrequency
CumulativeSums
Runs
LongestRun
Rank
FFT
NonOverlappingTemplate
OverlappingTemplate
Universal
ApproximateEntropy
RandomExcursions
RandomExcursionsVariant
Serial
LinearComplexity

P value Proportion Result
0.836586
0.680822
0.375465
0.085139
0.535389
0.351484
0.170935
0.142187
0.374441
0.996501
0.525783
0.120519
0.282519
0.261111
0.669968

0.990
0.991
0.990
0.992
0.990
0.991
0.989
0.990
0.989
0.988
0.991
0.988
0.991
0.990
0.990

Success
Success
Success
Success
Success
Success
Success
Success
Success
Success
Success
Success
Success
Success
Success

24
[6] L. Shen, J. Lee, L. P. Thinh, J.-D. Bancal, A. Cerè, A. Lamas-Linares, A. Lita, T. Gerrits, S. W. Nam, V. Scarani,
and C. Kurtsiefer, Phys. Rev. Lett. 121, 150402 (2018).
[7] P. Bierhorst, E. Knill, S. Glancy, Y. Zhang, A. Mink, S. Jordan, A. Rommal, Y.-K. Liu, B. Christensen, S. W.
Nam, et al., Nature 556, 223 (2018).
[8] Y. Liu, Q. Zhao, M.-H. Li, J.-Y. Guan, Y. Zhang, B. Bai, W. Zhang, W.-Z. Liu, C. Wu, X. Yuan, et al., Nature
562, 548 (2018).
[9] Y. Zhang, L. K. Shalm, J. C. Bienfang, M. J. Stevens, M. D. Mazurek, S. W. Nam, C. Abellán, W. Amaya,
M. W. Mitchell, H. Fu, et al., “Experimental low-latency device-independent quantum randomness,” e-print
arXiv:1812.07786 (2018).
[10] S. Fehr, R. Gelles, and C. Schaffner, Phys. Rev. A 87, 012335 (2013).
[11] M. Coudron and H. Yuen, in Proceedings of the 46th Annual ACM Symposium on Theory of Computing (ACM,
2014) pp. 427–436.
[12] C. A. Miller and Y. Shi, in Proceedings of the 46th Annual ACM Symposium on Theory of Computing, STOC
’14 (ACM, New York, NY, USA, 2014) pp. 417–426.
[13] C. A. Miller and Y. Shi, SIAM Journal on Computing 46, 1304 (2017).
[14] U. Vazirani and T. Vidick, in Proceedings of the 44th Annual ACM Symposium on Theory of Computing (STOC12) (2012) pp. 61–76.
[15] P. Brown, S. Ragy, and R. Colbeck, “A framework for quantum-secure device-independent randomness expansion,” e-print arXiv:1810.13346 (2018).
[16] B. Hensen, H. Bernien, A. E. Dréau, A. Reiserer, N. Kalb, M. S. Blok, J. Ruitenberg, R. F. Vermeulen, R. N.
Schouten, C. Abellán, et al., Nature 526, 682 (2015).
[17] L. K. Shalm, E. Meyer-Scott, B. G. Christensen, P. Bierhorst, M. A. Wayne, M. J. Stevens, T. Gerrits, S. Glancy,
D. R. Hamel, M. S. Allman, K. J. Coakley, S. D. Dyer, C. Hodge, A. E. Lita, V. B. Verma, C. Lambrocco,
E. Tortorici, A. L. Migdall, Y. Zhang, D. R. Kumor, W. H. Farr, F. Marsili, M. D. Shaw, J. A. Stern, C. Abellán,
W. Amaya, V. Pruneri, T. Jennewein, M. W. Mitchell, P. G. Kwiat, J. C. Bienfang, R. P. Mirin, E. Knill, and
S. W. Nam, Phys. Rev. Lett. 115, 250402 (2015).
[18] M. Giustina, M. A. M. Versteegh, S. Wengerowsky, J. Handsteiner, A. Hochrainer, K. Phelan, F. Steinlechner,
J. Kofler, J.-A. Larsson, C. Abellán, W. Amaya, V. Pruneri, M. W. Mitchell, J. Beyer, T. Gerrits, A. E. Lita,
L. K. Shalm, S. W. Nam, T. Scheidl, R. Ursin, B. Wittmann, and A. Zeilinger, Phys. Rev. Lett. 115, 250401
(2015).
[19] W. Rosenfeld, D. Burchardt, R. Garthoff, K. Redeker, N. Ortegel, M. Rau, and H. Weinfurter, Phys. Rev. Lett.
119, 010402 (2017).
[20] M.-H. Li, C. Wu, Y. Zhang, W.-Z. Liu, B. Bai, Y. Liu, W. Zhang, Q. Zhao, H. Li, Z. Wang, et al., Phys. Rev.
Lett. 121, 080404 (2018).
[21] F. Dupuis, O. Fawzi, and R. Renner, “Entropy accumulation,” e-print arXiv:1607.01796 (2016).
[22] F. Dupuis and O. Fawzi, “Entropy accumulation with improved second-order,” e-print arXiv:1805.11652 (2018).
[23] A. Acı́n and L. Masanes, Nature 540, 213 (2016).
[24] M. Herrero-Collantes and J. C. Garcia-Escartin, Reviews of Modern Physics 89, 015004 (2017).
[25] I. Gerhardt, Q. Liu, A. Lamas-Linares, J. Skaar, C. Kurtsiefer, and V. Makarov, Nature Communications 2,
349 (2011).
[26] J. F. Clauser, M. A. Horne, A. Shimony, and R. A. Holt, Physical Review Letters 23, 880 (1969).
[27] G. Murta, S. B. van Dam, J. Ribeiro, R. Hanson, and S. Wehner, Quantum Science and Technology (2019).
[28] R. Konig and R. Renner, IEEE Transactions on Information Theory 57, 4760 (2011).
[29] J. Barrett, R. Colbeck, and A. Kent, Physical Review Letters 106, 010503 (2013).
[30] R. Colbeck and R. Renner, Nature Physics 8, 450– (2012).
[31] R. Canetti, Journal of Cryptology 13, 143 (2000).
[32] M. Ben-Or and D. Mayers, “General security definition and composability for quantum & classical protocols,”
e-print quant-ph/0409062 (2004).
[33] C. Portmann and R. Renner, “Cryptographic security of quantum key distribution,” e-print arXiv:1409.3525
(2014).
[34] R. Renner, Security of Quantum Key Distribution, Ph.D. thesis, Swiss Federal Institute of Technology, Zurich
(2005), also available as quant-ph/0512258.
[35] R. König, R. Renner, and C. Schaffner, IEEE Transactions on Information Theory 55, 4337 (2009).
[36] M. Tomamichel, R. Colbeck, and R. Renner, IEEE Transactions on information theory 56, 4674 (2010).
[37] T. S. Han and M. Hoshi, IEEE Transactions on Information Theory 43, 599 (1997).
[38] R. Colbeck and R. Renner, Nature Communications 2, 411 (2011).
[39] R. Colbeck and R. Renner, in Quantum Theory: Informational Foundations and Foils, edited by G. Chiribella
and R. W. Spekkens (Springer, 2016) pp. 497–528.
[40] N. Nisan and D. Zuckerman, Journal of Computer and System Sciences 52, 43 (1996).
[41] A. De, C. Portmann, T. Vidick, and R. Renner, SIAM Journal on Computing 41, 915 (2012).
[42] X. Ma, F. Xu, H. Xu, X. Tan, B. Qi, and H.-K. Lo, Phys. Rev. A 87, 062327 (2013).

25
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]
[55]
[56]
[57]
[58]
[59]

Y. Mansour, N. Nisan, and P. Tiwari, Theoretical Computer Science 107, 121 (1993).
H. Krawczyk, in Proceedings of the 14th Annual Cryptology Conference (CRYPTO 94) (1994) pp. 129–139.
The final block will have fewer columns if n/l is not an integer.
I. Gohberg and V. Olshevsky, Linear Algebra and Its Applications 202, 163 (1994).
M. Frigo and S. G. Johnson, in Proceedings of the International Conference on Acoustics, Speech, and Signal
Processing, Vol. 3 (Seattle, Washington, 1998) pp. 1381–1384.
In principle we could have utilized more memory and reduced the number of blocks. However, significant slowdowns occur to the FFT algorithm when the vectors are not stored in a contiguous block of memory.
L. Trevisan, Journal of the ACM 48, 860 (2001).
D. Alfers and H. Dinges, Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete 65, 399 (1984).
A. Serov and A. Zubkov, “A full proof of universal inequalities for the distribution funtion of the binomial law,”
e-print arXiv:1207.3838 (2012).
M. Müller-Lennert, F. Dupuis, O. Szehr, S. Fehr, and M. Tomamichel, Journal of Mathematical Physics 54,
122203 (2013).
M. Tomamichel, R. Colbeck, and R. Renner, IEEE Transactions on information theory 55, 5840 (2009).
M. Tomamichel, Quantum Information Processing with Finite Resources (Springer, 2016).
The quantum probability estimation framework [59] provides an alternative way to prove bounds on the amount
of extractable randomness, but we do not use this in this work.
The definition of EAT channels supplied here is slightly less general than that in [21] but the proof is easily
adapted to the more general definition.
S. Pironio, A. Acin, N. Brunner, N. Gisin, S. Massar, and V. Scarani, New Journal of Physics 11, 045021 (2009).
“NIST statistical test suite,” http://csrc.nist.gov/groups/ST/toolkit/rng/stats_tests.html.
E. Knill, Y. Zhang, and H. Fu, “Quantum probability estimation for randomness with quantum side information,”
e-print arXiv:1806.04553 (2018).

