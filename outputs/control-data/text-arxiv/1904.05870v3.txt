arXiv:1904.05870v3 [quant-ph] 2 Sep 2019

NEEXP ⊆ MIP∗
Anand Natarajan∗

John Wright†

California Institute of Technology

Massachusetts Institute of Technology

September 4, 2019

Abstract
We study multiprover interactive proof systems. The power of classical multiprover interactive proof systems, in which the provers do not share entanglement, was characterized in
a famous work by Babai, Fortnow, and Lund (Computational Complexity 1991), whose main
result was the equality MIP = NEXP. The power of quantum multiprover interactive proof
systems, in which the provers are allowed to share entanglement, has proven to be much more
difficult to characterize. The best known lower-bound on MIP∗ is NEXP ⊆ MIP∗ due to Ito and
Vidick (FOCS 2012). As for upper bounds, MIP∗ could be as large as RE, the class of recursively
enumerable languages.
poly(n)
The main result of this work is the inclusion NEEXP = NTIME[22
] ⊆ MIP∗ . This
is an exponential improvement over the prior lower bound and shows that proof systems with
entangled provers are at least exponentially more powerful than classical provers. In our protocol
the verifier delegates a classical, exponentially large MIP protocol for NEEXP to two entangled
provers: the provers obtain their exponentially large questions by measuring their shared state,
and use a classical PCP to certify the correctness of their exponentially-long answers. For the
soundness of our protocol, it is crucial that each player should not only sample its own question
correctly but also avoid performing measurements that would reveal the other player’s sampled
question. We ensure this by commanding the players to perform a complementary measurement,
relying on the Heisenberg uncertainty principle to prevent the forbidden measurements from
being performed.

∗
†

anandn@caltech.edu
jswright@mit.edu

1

Contents
I

5

Introduction

1 Introduction

5

2 Overview of our proof
2.1 Basic quantum notation and qudits . . . . . . . . . . . . . .
2.2 Our starting point: a classical interactive proof for NEEXP .
2.3 Restricting the strategies: registers and compilers . . . . . .
2.4 Question reduction through introspection . . . . . . . . . .
2.5 Answer reduction through PCP composition . . . . . . . . .
2.6 Organization . . . . . . . . . . . . . . . . . . . . . . . . . .

II

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

Preliminaries

9
9
10
11
12
13
14

15

3 Classical preliminaries
3.1 Finite fields and polynomials . . . . . . .
3.2 Two-player one-round games and MIP . .
3.3 Low-degree code . . . . . . . . . . . . . .
3.4 A canonical low-degree encoding . . . . .
3.5 Low-degree testing . . . . . . . . . . . . .
3.6 Simultaneous low-degree testing . . . . . .
3.7 NEXP, NEEXP, and complete problems for
3.8 The Tseitin transformation . . . . . . . .

. . . .
. . . .
. . . .
. . . .
. . . .
. . . .
them
. . . .

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

4 Quantum preliminaries
4.1 Quantum measurements . . . . . . . . . . . . . . . . . . . .
4.2 Nonlocal games and MIP∗ . . . . . . . . . . . . . . . . . . .
4.3 Pauli matrices and the EPR state . . . . . . . . . . . . . . .
4.4 State dependent distances . . . . . . . . . . . . . . . . . . .
4.5 Miscellaneous properties of the state-dependent distances .
4.5.1 Simple state-dependent distance facts . . . . . . . .
4.5.2 Data processing . . . . . . . . . . . . . . . . . . . . .
4.5.3 Triangle inequalities . . . . . . . . . . . . . . . . . .
4.5.4 Close strategies have close game values . . . . . . . .
4.5.5 Generating new measurements . . . . . . . . . . . .
4.6 Commuting EPR strategies . . . . . . . . . . . . . . . . . .
4.7 Quantum soundness of the classical low-degree test . . . . .
4.8 Quantum soundness of the classical simultaneous low-degree
4.9 Self-testing . . . . . . . . . . . . . . . . . . . . . . . . . . .

III

.
.
.
.
.
.

Implementing the registers

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
test
. . .

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.

15
15
16
17
18
18
19
22
24

.
.
.
.
.
.
.
.
.
.
.
.
.
.

25
25
27
29
30
32
33
35
35
36
38
43
44
46
47

48

5 Register overview
48
5.1 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
2

5.2
5.3
5.4

Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
Registers for uniform games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

6 A self test for the Pauli basis
52
6.1 The quantum low-degree test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
6.2 Proof of Theorem 6.2: the Pauli basis test . . . . . . . . . . . . . . . . . . . . . . . . 54
7 Compiling games with the Pauli basis test

56

8 The data hiding game
59
8.1 Some facts about the Pauli twirl . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
8.2 Hiding a single coordinate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
9 Compiling games with the data hiding test

64

10 Partial data hiding

65

IV

72

NEEXP protocol

11 A review of a classical PCP
11.1 The instance . . . . . . .
11.2 Encoding assignments . .
11.3 Encoding the formula . .
11.4 Zero on subcube . . . . .
11.5 The PCP . . . . . . . . .

theorem
. . . . . .
. . . . . .
. . . . . .
. . . . . .
. . . . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

73
73
73
74
75
76

12 NEEXP preliminaries
77
12.1 Introspection games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
12.2 Subroutines and superregisters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
13 The
13.1
13.2
13.3
13.4
13.5

introspective low-degree test
Introspected partial data-hiding . . . . . .
An introspective surface sampler . . . . .
The introspective cross-check . . . . . . .
The introspective low-degree test . . . . .
The introspective simultaneous low-degree

. . .
. . .
. . .
. . .
test

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

80
80
83
85
86
88

14 The intersecting lines test
89
14.1 The intersecting lines test . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
14.2 The introspective intersecting lines test . . . . . . . . . . . . . . . . . . . . . . . . . 90
15 The
15.1
15.2
15.3

introspective NEEXP protocol
Computing the register parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . .
An introspective formula game . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The complete introspective protocol . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

94
94
95
98

V

Answer reduction

103

16 Testing error-correcting codes
103
16.1 Testing the low-degree code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
16.2 Efficiently decodable codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
17 Answer reduction
17.1 Oracularization . . . . . . . . . . . . . . . . .
17.2 Probabilistically checkable proofs of proximity
17.3 Composing with an error-correcting code . . .
17.4 The answer reduction protocol . . . . . . . .
17.5 Applying the answer reduction protocol . . .

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

.
.
.
.
.

108
. 108
. 109
. 110
. 112
. 118

Part I

Introduction
1

Introduction

This paper is about the complexity class MIP∗ of multiprover interactive proof systems with entangled quantum provers—the quantum version of the classical class MIP. Classically, the study of MIP
has had far-reaching implications in theoretical computer science. In complexity theory, the proof
by Babai, Fortnow, and Lund [BFL91] that MIP = NEXP was the direct antecedent of the PCP theorem [ALM+ 98, AS98], a seminal result which is the foundation of the modern theory of hardness of
approximation. In cryptography, the MIP model was introduced to allow for information-theoretic
zero-knowledge proofs [BOGKW88], and more recently MIP protocols have become essential building blocks in designing delegated computation schemes (see e.g. [KRR14]). These implications alone
would be a sufficient motivation for considering the quantum class MIP∗ , but remarkably, the study
of MIP∗ is also deeply related to long-standing questions in the foundations of quantum mechanics
regarding the nature of quantum entanglement. Indeed, the MIP∗ model itself was anticipated by
the nonlocal games or Bell tests introduced in the work of John Bell [Bel64], who was in turn
inspired by the thought experiment proposed by Einstein, Podolsky, and Rosen [EPR35]. These
nonlocal games have had applications to quantum cryptography [Eke91, MY98, Col06], delegated
quantum computation [RUV13], and more.
Even though the class MIP is now well-understood, it has proven difficult to determine the
computational power of MIP∗ . A priori, it is not even clear that MIP∗ contains MIP, since adding
entanglement could increase or decrease the power of the proof system. This is because the added
resource of entanglement can make it easier for dishonest provers to cheat the verifier. Indeed,
Cleve et al. [CHTW04] showed that for proof systems based on so-called XOR games (where the
verifier’s decision can only depend on the XOR of the provers’ answer bits), the quantum class
⊕MIP∗ ⊆ EXP, whereas classically ⊕MIP = NEXP. In particular, this result implied that the
classical ⊕MIP protocol for NEXP of Håstad [Hås97] could not be sound against entangled provers.
In spite of this, Ito and Vidick [IV12, Vid16] were able to show that NEXP ⊆ MIP∗ , by proving
that a different classical protocol is sound against entanglement. Note that the protocol of [Vid16]
is identical to a protocol shown to be unsound by Cleve et al., except in that it uses 3 provers
rather than 2 (the protocol is played by choosing a random subset of 2 provers from the 3). This
illustrates the subtleties of dealing with entangled provers.
With the lower bound NEXP ⊆ MIP∗ established, a natural follow-up question is whether MIP∗
is strictly more powerful than MIP. Indeed, it was long known that some MIP∗ protocols possess a
uniquely quantum property called self-testing, which has no direct analog in the classical setting.
Roughly speaking, an MIP∗ protocol is a self-test for a particular entangled state |ψi if only provers
using states close to |ψi can achieve close to optimal success in the protocol. In such a protocol,
observing that the provers succeed with nearly optimal probability certifies that they share a state
close to the target state |ψi. The germ of this idea came from the work of Bell [Bel64], who studied
the types of bipartite correlations that could be obtained from measuring an entangled state called
the EPR state, which had been introduced by Einstein, Podolsky, and Rosen [EPR35]. Bell gave a
protocol where provers using the EPR state could succeed with a greater probability than purely
classical provers, and subsequent works of Tsirelson [Tsi80], and Summers and Werner [SW88]
showed that (a variant of) Bell’s protocol certifies the EPR state in the sense of self-testing.
In order to prove stronger lower bonds on MIP∗ , the post-Ito-Vidick phase of MIP∗ research
aimed to use this self-testing property to design protocols for problems in Hamiltonian complexity,
5

the quantum analog of the theory of NP-completeness. In Hamiltonian complexity, the complexity
class QMA plays the role of NP; it is the set of problems for which there exists a quantum witness
state that can be efficiently checked by a polynomial-time quantum verifier. Problems in QMA
seemed like a natural match for the powers of MIP∗ as one could potentially construct a protocol
for QMA by designing a self-test for accepting witness states of some QMA-complete problem.
The connection between MIP∗ and QMA was also well motivated from the point of view of the
“quantum PCP” research program, which strives to find quantum analogues of the classical PCP
theorem. In the classical setting, the PCP theorem can be viewed as a scaled-down version of
MIP∗ = NEXP, showing that there exists an MIP∗ protocol for 3SAT (and thus for all of NP) with
O(log(n))-sized messages. Drawing inspiration from this, Fitzsimons and Vidick [FV15] stated a
“quantum games PCP conjecture”: that there should exist an MIP∗ protocol with log(n)-sized
messages for the local Hamiltonian problem, and thus for the class QMA. This was proved by
Natarajan and Vidick [NV18a] in 2018 with a 7-prover protocol. Along the way to achieving this
goal, [NV18a] developed a highly efficient self-test for high-dimensional entangled states: their
“quantum low-degree test” is a self-test for n EPR pairs with only O(log(n)) communication.
Already, the result of [NV18a] is strong evidence that MIP∗ 6= MIP, since it is believed that
QMA 6= NP. But, at the same time, several other works showed that even larger separations
were possible in the regime of subconstant soundness gaps. Here there are results in two settings.
For MIP∗ with a soundness gap scaling inverse-exponentially (i.e. 1/ exp(n)) in the instance size,
Ji [Ji17] showed a protocol for NEEXP: nondeterministic doubly-exponential time, and a subsequent
work by Fitzsimons, Ji, Vidick, and Yuen [FJVY19] showed protocols for non-deterministic iterated
n
n
exponential time (e.g. NTIME(22 )) with a correspondingly small soundness gap (e.g. 2−C·2 ). In
the “gapless” case, Slofstra [Slo16, Slo19] showed that given a description of an MIP∗ protocol,
determining whether there exists an entangled strategy that succeeds with probability exactly 1 is
undecidable by any Turing machine.
These results hint at the full power of MIP∗ but are not conclusive, as it is not unusual for
quantum complexity classes to increase significantly in power when a numerical precision parameter
is allowed to shrink. For instance, QIP (quantum interactive proofs with a single prover) with an
exponentially small gap is equal to EXP [IKW12], while QIP with a polynomial gap is equal to
IP = PSPACE. Likewise, QMA with exponentially small gap (known as PreciseQMA) is known to be
equal to PSPACE [FL18], while QMA is contained PP, and QMA(k) (QMA with multiple unentangled
Merlins) with exponentially small gap is equal to NEXP [Per12], whereas in the constant-gap regime
the best known lower bound is that QMA(k) ⊇ QMA. Moreover, even the QMA lower bound for
MIP∗log obtained by [NV18b] holds for 7 provers only; with 2 provers, the best known lower bound for
MIP∗log is NP = MIPlog [NV18a]. Could it be that 2-prover MIP∗ is equal to MIP, with entanglement
providing no advantage at all?
This paper conclusively answers this question in the negative. Our main result (Theorem 1.1)
is to show that MIP∗ contains NEEXP, with only two provers and with a constant completenesssoundness gap. This is establishes the first known unconditional separation between MIP∗ and MIP
in the constant-gap regime: previously, such a separation was known only assuming QMA 6= NP,
and only in the scaled-down setting of logarithmic-sized messages.
Theorem 1.1 (Theorem 17.12 in the body). There is a two-prover, one-round MIP∗ protocol for the
NEEXP-complete problem Succinct-Succinct-3Sat with completeness 1, soundness 1/2, and question
and answer length poly(n).
As a corollary of Theorem 1.1, we obtain a lower bound on the hardness of approximation for
the entangled value ω ∗ of a nonlocal game.

6

Corollary 1.2. There exists a constant c < 1 such that given a two-prover nonlocal game G of size
N , the problem of deciding whether ω ∗ (G ) = 1 or ω ∗ (G ) ≤ 1/2, promised one of the two holds, is
NTIME(2N

log −c N

)-hard.

For two-player games, the best prior lower bound was NP [NV18b]. The lower bound achieved
in Corollary 1.2 is stronger as for any c < 1, the function 2N

log −c N

is superpolynomial.

Techniques. Our construction, inspired by [Ji17] and [FJVY19], involves “compression”: we
show how to take an MIP protocol for NEEXP with exponentially-long questions and answers (the
“big” protocol), and simulate it by an MIP∗ protocol with polynomial-sized messages (the “small”
protocol). However, the techniques we use to achieve our compression are quite different. We
eschew the Hamiltonian-complexity ideas that were used in previous works, and in particular the
use of history states. In our protocol, honest provers need only share a quantum resource state of
(exponentially many) EPR pairs, together with a classical assignment to the NEEXP instance being
tested. The use of history states was the main barrier preventing previous works from applying to
the case of two provers.
We divide compression into two steps: question compression and answer compression. We
achieve question compression by a technique which we call introspection, in which we command
the provers to perform measurements on their shared EPR pairs whose outcomes are pairs of
questions from the “big” protocol. To force the provers to sample their questions honestly, we
use a variant of the quantum low-degree test from [NV18a], which certifies Pauli measurements
on exponentially many EPR pairs using messages of only polynomial size. A crucial challenge
is to prevent each prover from learning the other prover’s sampled question, since this would
destroy the soundness of the “big” protocol. To achieve this, we use the “data-hiding” properties of
quantum measurements in incompatible bases: if a set of qubits is measured in the Pauli X-basis,
this “erases” all information about Z-basis measurements. This means that if Alice samples her
question by measuring her half of a block of EPR pairs in the Z-basis, then her question can be
hidden from Bob by forcing him (via self-testing) to measure his half of the EPR pairs in the
X-basis. Interestingly, our data-hiding scheme does not operate in a black-box way on the “big”
protocol, but rather makes essential use of its structure. In particular, we start with a “big” protocol
based on a scaled-up version of a PCP construction using the low-degree test, where the question
distribution consists of pairs of random points in a vector space and affine subspaces containing
them. The linear structure of the vector space is essential for our data-hiding procedure to work.
Our approach to answer compression is more standard, essentially using composition with a
classical PCP of proximity. Here, the verifier asks the provers to compute a PCP proof that
their “big” answers satisfy the success conditions of the protocol, and verifies this PCP proof by
reading an exponentially smaller number of bits. Care is needed to deal with entanglement between
the provers. The first, fundamental challenge we face is that the success condition of the “big”
protocol is a function of both provers’ answers. Thus, to compute a PCP proof that the condition is
satisfied, one of the provers must have access to both provers’ answers. Classically, this is achieved
using the technique of oracularization, in which one prover receives both provers’ questions and
is checked for consistency against the other prover, which only receives a single question. In the
entangled setting, this oracularization procedure is sound, but not necessarily complete. This is
because oracularization requires that each prover, if given the other prover’s question, could predict
its answer with certainty, even though this answer is obtained from a nondeterministic quantum
measurement. In our protocol, we are able to use oracularization because honest provers always
use a maximally entangled state, which they measure with projective measurements that pairwise
commute for every pair of questions asked in the game. While this commutation requirement is
7

restrictive, it still permits non-trivial quantum behavior; indeed, the linear system games used by
Slofstra [Slo19] involve similar commutation conditions.
The second challenge is to ensure that the PCP of proximity we use for composition is itself
sound against entanglement. We achieve this by performing a further step of composition: we ask
the provers to encode their PCP proof in the low-degree code and verify it with the low-degree test,
which is known to be sound even against entangled provers [NV18b]. This technique was introduced
in the QMA protocol of [NV18a] in order to perform energy measurements on the provers’ state.
Implications and future work We believe that our work opens up several exciting directions
for further progress. For the complexity theorist, the most obvious future direction is to obtain
even stronger lower bounds on MIP∗ by iterating our protocol, as in [FJVY19]. At the most
basic level, we could imagine taking our MIP∗ protocol for NEEXP and performing a further layer
of question compression and answer compression on it, thus obtaining an MIP∗ protocol with
logarithmic message size for NEEXP, or, scaling up, an MIP∗ protocol with polynomial message size
2poly(n)

). By further iterating question reduction and answer reduction k times, we
for NTIME(22
·n
could obtain potentially obtain lower bounds of NTIME(|{z}
2· ) on MIP∗ while retaining a constant
k

completeness-soundness gap. The main obstacle to achieving such results is that the question
compression procedure developed in this paper is tailored to a special distribution of questions
(that of the MIPexp protocol for NEEXP), whereas our answer compression procedure produces
protocols whose question distribution is not of this form.
Assuming that this obstacle can be surmounted, we could aspire to a more ambitious goal:
a general “gap-preserving compression procedure” for some subclass of MIP∗ protocols, which we
may label “compressible” protocols. Such a procedure would consist of a Turing machine that takes
as input any compressible MIP∗ protocol G , and generates a new compressible protocol G ′ with
exponentially smaller message size, but approximately the same entangled value. It was shown
by [FJVY19] that the existence of such a compression procedure for the set of all MIP∗ protocols
would imply that MIP∗ contains the set of all computable languages, and moreover that there exists
an undecidable language in MIP∗ . These consequences would continue to hold as long as the set
of compressible protocols contains a family of protocols solving problems in NTIME(f (n)), where
f (n) is a growing function of n.
Showing that MIP∗ contains undecidable languages would be significant not just for complexity
theory but also for the foundations of quantum mechanics, as it would resolve a long-standing open
problem known as Tsirelson’s problem. Tsirelson’s problem asks whether two notions of quantum
nonlocality are equivalent: the tensor-product model, in which two parties Alice and Bob each act
on their respective factor of a tensor-product Hilbert space HAlice ⊗ HBob , and the commutingoperator model, in which both parties act on a common Hilbert space H, but the algebra of Alice’s
measurement operators must commute with Bob’s, and vice versa. It was shown by Slofstra [Slo16]
that in the “zero-error” setting, these two models differ: there are quantum correlations which
can be exactly achieved in the commuting-operator model but not in the tensor product model.
Surprisingly, showing that MIP∗ contains undecidable languages would imply that the two models
are separated even in the bounded-error setting: it would imply that there exist correlations that can
be achieved in the commuting-operator model that cannot even be approximated (up to constant
precision) in the tensor-product model. The reason for this implication is that if the two models
are indistinguishable up to bounded error, then there exists a Turing machine that can decide any
language in MIP∗ and is guaranteed to halt. This observation, which is folklore in the community,
follows from the completeness of the non-commutative sum of squares hierarchy for the commuting-

8

operator model, as documented in [FJVY19]. Showing a separation between the two models would
have significant mathematical consequences as well, as it would yield a negative answer to the
long-standing Connes’ embedding problem.
In addition to these connections to complexity and mathematical physics, we hope that our
results will have applications in other areas such as to delegated computation or quantum cryptography. In particular, our use of introspection is reminiscent of ideas used in quantum randomness
expansion, where randomness generated by measuring EPR pairs is used to generate questions
for a nonlocal game. Could our results improve on the infinite randomness expansion protocol of
Coudron and Yuen [CY14]?
Acknowledgements We thank Henry Yuen for many useful conversations about the idea of
“introspecting” interactive proof protocols, which inspired us to start this project. AN is also
grateful to the Simons Institute for the hospitable environment of the Summer Cluster on Challenges
in Quantum Computation during which these conversations where held. We thank Thomas Vidick
for his guidance and advice. We thank Ryan O’Donnell and Ryan Williams for a succinct review
of the literature on the complexity of succinct (succinct) 3Sat and NE(E)XP. We are also grateful
to Zhengfeng Ji for several useful discussions, especially regarding the consequences of recursively
composing our protocol with itself.
AN was partially supported by NSF grant CCF-1452616. JW was partially supported by ARO
contract W911NF-17-1-0433. Both authors acknowledge funding provided by the Institute for
Quantum Information and Matter, an NSF Physics Frontiers Center (NSF Grant PHY-1733907).

2

Overview of our proof

In this section we give a more detailed overview of the technical parts of the paper.

2.1

Basic quantum notation and qudits

While the main body of the paper contains a more complete set of quantum preliminaries in Section 4,
for the purposes of this introduction we define some basic notation, aimed at the reader who is
familiar with the standard quantum computing formalism over qubits but is less familiar with qudits: quantum systems of dimension not equal to 2. In this paper, we make extensive use of such
qudits: in particular, for a finite field FQ , we will consider qudits of dimension Q, with a basis state
|ii for every element i ∈ FQ . Under tensor product, we obtain a basis for the space of M qudits of
dimension Q where each basis state |xi corresponds to a vector x ∈ FM
Q.
The basic resource state used in our protocols will be the EPR state over 2M qudits of dimension
Q. The qudits are split into two registers of M qudits each, held by the two provers Alice and Bob,
respectively.
X
1
|EPRM
|xiAlice ⊗ |xiBob .
Qi= p M
Q x∈FM
Q

This state is a maximally entangled state between Alice and Bob.
Acting on this state, we will ask the provers to perform measurements from a special class
called Pauli basis measurements. To define these over a general field FQ requires the introduction
of some finite field technology, in particular the finite field trace function. For simplicity, in this
overview we will imagine that Q is prime, allowing the addition in FQ to be identified with the
additive group ZQ , and simplifying the definition of the Paulis; in the main body of the paper, we

9

will work with Q a power of 2. For a single qudit of dimension Q, the Pauli X and Z bases are the
sets {|τuX i}u∈FQ and {|τuZ i}u∈FQ of vectors
1 X xu
ω |xi ,
|τuX i = √
Q x∈F
Q

|τuZ i = |ui ,

where ω = exp(2πi/Q) is the Q-th root of unity. We denote the projectors onto these basis states
by τuX and τuZ , respectively. For a system of M qudits, the Pauli X and Z observables are a set of
generalized observables indexed by elements of FM
Q : a generalized observable is a Hermitian matrix
with eigenvalues that are Q-th roots of unity. They are given by
X
X
X(v) =
Z(v) =
ω u·v τuX1 ⊗ . . . ⊗ τuZM ,
ω u·v τuZ1 ⊗ . . . ⊗ τuZM ,
u∈FM
Q

u∈FM
Q

P
where u1 , . . . , uM are the components of the vector u, and u · v is the dot product M
i=1 ui · vi . Measuring a generalized observable means performing a projective measurement onto the eigenvectors
of the observable, with the outcome a corresponding to the eigenvector with eigenvalue ω a .

2.2

Our starting point: a classical interactive proof for NEEXP

We start with a classical multiprover interactive proof protocol for NEEXP. The equality MIP =
NEXP was originally shown by Babai, Fortnow, and Lund [BFL91] using a protocol based on the
multilinearity test: the idea is that an exponentially-long witness for a problem in NEXP is encoded
in the truth-table of a multivariate polynomial function over a finite field, which is linear in each
of the variables individually. The verifier is able to verify the witness by evaluating the multilinear
polynomial over appropriately chosen points and subspaces. To scale up to NEEXP, we use a much
more efficient version of the same idea, replacing the multilinearity test with the low-degree test,
which works with multivariate polynomials of low total degree. This more efficient construction
comes from the PCP literature. We give a relatively self-contained presentation of the protocol
in Section 11. For the purposes of this overview, it is sufficient to know the following: any problem
in NEEXP can be reduced to satisfiability for a doubly exponentially long 3Sat formula, succinctly
encoded by a polynomial-sized circuit. (We refer to this problem as Succinct-Succinct-3Sat). Given
a 3Sat formula ψ, we would like the provers to prove to us that they have a satisfying assignment a
to this formula. Instead of reading the assignment directly, we will ask the provers to encode their
assignment as a multivariate polynomial ga : FM
Q → FQ , where the number of variables M and the
finite field size Q are appropriately chosen parameters, and return evaluations of this polynomial.
To check that a satisfies ψ, the verifier first uses a technique called arithmetization to convert the
+k
→ FQ . The polynomial gψ is chosen such
formula ψ into a multivariate polynomial gψ : F3M
Q
that the assignment a satisfies ψ if and only if the expression
satψ,a (x, b, w) := gψ (x, b, w) · (ga (x1 ) − b1 )(ga (x2 ) − b2 )(ga (x3 ) − b3 )
+k
. Our classical protocol for NEEXP
is equal to 0 at every point in a particular subset H ⊆ F3M
Q
checks this condition:

Informal Theorem 2.1 (Section 11 in the body). There exists a protocol G0 for Succinct-Succinct3Sat (and hence NEEXP), where the verifier’s questions to the provers are constant-dimension
subspaces of FM
Q , and the provers’ responses are evaluations of degree-D M -variate polynomials on
these subspaces. The parameters M, Q, D are all chosen to be exp(n), and hence the question and
answer lengths as well as the runtime of the verifier in this protocol are exp(n).
10

The distribution over subspaces sent to the provers in G0 is relatively simple, and in fact is independent of the instance of Succinct-Succinct-3Sat being tested. For the purposes of this overview,
the reader can take the distribution over pairs of questions to be the plane-point distribution D. A
pair (s, u) ∼ D consists of a uniformly random affine plane s ⊆ FM
Q , which is sent to Alice, and a
uniformly random point u ∈ s which is sent to Bob. The full distribution over questions in G0 is
more complicated than this but the essential ideas of our protocol will be illustrated by restricting
to this case.

2.3

Restricting the strategies: registers and compilers

One of the main challenges in working with entangled provers is showing soundness against general
entangled strategies. An important technique in this area is to force the provers to use a particular
state and class of measurements by playing a type of game known as a self-test.
Informal Definition 2.2. A game Gtest is a self-test for a state |ψi and measurements M x if any
strategy that succeeds in Gtest with probability 1 − ǫ must use a state |ψ ′ i and measurements (M ′ )x
that are δ(ǫ)-close, in the appropriate metric, to |ψi and M x .
Some of the earliest self-tests include the famous CHSH game, which self-tests the Pauli X
and Z operators on a single EPR pair (of qubits). Self-testing technology has greatly advanced
over the years, and in this paper we design a highly efficient self-test based on the low-degree test
of [NV18a].
Informal Theorem 2.3 (Theorem 6.2 in the body). The Pauli basis test Pauli(n, q) is a self-test
for the state |EPRnq i and the Pauli X and Z basis measurements. This test sends the players
questions of length O(log(n)) and receives answers of length O(poly(n)).
The Pauli X and Z measurements are “complete” measurements, and as a consequence, there
is no nontrivial measurement on a set n qudits that can be measured jointly with both the Pauli X
and Z measurements on those qudits. Using this property, we design a game called the data-hiding
game, which certifies that a prover’s measurements act trivially on a specified set of qudits.
Informal Theorem 2.4 (Theorem 8.3 in the body). The data-hiding game Ghide is a self test for
states |ψi = |EPRnq i ⊗ |auxi and measurements M x of the form M x = I ⊗ (M ′ )xaux . It has questions
of length O(log(n)) and answers of length O(poly(n)).
Together, the Pauli basis test and the data-hiding game allow us to restrict our analysis of our
protocols to a class of strategies we call register strategies: strategies for which the shared state is
a collection of ℓ registers, each in an EPR state, together with some auxiliary register:
|ψi = |EPRnq11 i ⊗ . . . ⊗ |EPRnqℓℓ i ⊗ |auxi ,
and where the provers can be commanded to perform either (1) Pauli basis measurements on
specified subsets of the registers, or (2) measurements that do not act on specified subset of the
EPR registers (but act on the auxiliary register or the remaining EPR registers). We formalize
this by designing a compiler, which takes in a protocol G that is complete and sound for register
strategies, and produces a new protocol G ′ which is complete and sound over all strategies.
Informal Theorem 2.5 (Theorem 7.2 and Theorem 9.2 in the body). Suppose G is a protocol
for a computation problem for which completeness and soundness hold for register strategies, with
O(1) many registers of size n. (That is, for YES instances of the problem, there exists a register
11

strategy achieving value 1, and for NO instances, no register strategy achieves value greater than
1/2). Let the questions in G be of length Q and the answers be of length A. Then there exists a
protocol G ′ which is complete and sound for general strategies, and for which the question length is
Q + log(n) and the answer length is A + poly(n).
The compiled protocol G ′ either runs the original protocol G , or, with some probability, runs
the Pauli basis test, the data-hiding game, or a consistency test.

2.4

Question reduction through introspection

With our compiler in place, we have now given the verifier the power to command the provers to
perform Pauli basis measurements on a set of EPR pairs. We would like to use this to reduce the
question size of the classical protocol G0 for NEEXP described above from exp(n) to poly(n). We
will do so by forcing the provers, rather than the verifier, to sample the protocol’s exp(n)-length
questions, a technique we call “introspection”. That is, we would like to force the provers to sample
pairs (s, u) from the plane-vs-point distribution D, where s is a uniformly random affine plane in
FM
Q , and u a uniformly random point on s.
To design a scheme to sample from this distribution, let us first fix a representation of affine
M
planes. We will represent an affine plane by an intercept u ∈ FM
Q and two slopes v1 , v2 ∈ FQ . The
v
plane given by u, v1 , v2 is the set su = {u + λ1 v1 + λ2 v2 : λ1 , λ2 ∈ FQ }. As a first attempt, we may
try the following scheme:
1. Alice and Bob share three registers, each of which contains an EPR state, so their shared
state is
M
M
|ψ0 i = |EPRM
Q iR ⊗ |EPRQ iR ⊗ |EPRQ iR .
0

1

2

2. Alice first measures her half of registers R1 and R2 in the Pauli Z-basis, to obtain uniformly
random outcomes v 1 , v 2 . The shared state is now
|ψ1 i = |EPRM
Q iR ⊗ (|v 1 iAlice ⊗ |v 1 iBob )R1 ⊗ (|v 2 iAlice ⊗ |v 2 iBob )R2 .
0

3. Now, Alice and Bob both measure register R0 in the Pauli Z-basis, both obtaining the same
outcome u. The shared state is now
|ψ2 i = (|uiAlice ⊗ |uiBob )R0 ⊗ (|v 1 iAlice ⊗ |v 1 iBob )R1 ⊗ (|v 2 iAlice ⊗ |v 2 iBob )R2 .
Alice sets her plane s to be svu and Bob sets his point to be u.
Indeed, the pair (s, u) generated by this procedure is distributed according to D. However, there
is a problem: through her measurement, Alice obtains additional side information, specifically the
value of Bob’s point u. Can we command Alice to erase the side information? In fact, we can,
using the Heisenberg uncertainty principle: if two observables anticommute, then measuring one
completely destroys information about the other. Using this idea, we modify our protocol as follows:
1. As above.
2. As above. At this point, applying the definition of |EPRM
Q i, we can write the shared state as
|ψ1 i ∝

X

u∈FM
Q

(|uiAlice ⊗ |uiBob )R0 ⊗ (|v 1 iAlice ⊗ |v 1 iBob )R1 ⊗ (|v 2 iAlice ⊗ |v 2 iBob )R2 .

12

3. New: Intuitively, we would like Alice to be prevented from measuring the component of the
intercept along the directions v 1 , v 2 . This information would be obtained by measuring the
observables1 Z(v 1 ), Z(v 2 ). To destroy it, we will ask Alice to measure the complementary
Pauli observables X(v 1 ), X(v 2 ) on register R0 , obtaining outcomes α1 , α2 ∈ FQ . The shared
state is now


XX
ω α1 λ+α2 µ |u + λv 1 + µv 2 i
|uiBob  (|v 1 iAlice ⊗ |v 1 iBob )R1
|ψ2′ i ∝
{z
}
|
u

λ,µ

u′

Alice

R0

⊗ (|v 2 iAlice ⊗ |v 2 iBob )R2 .

where, as above, ω = exp(2πi/Q) is a Q-th root of unity. Alice and Bob’s state on R0 is
now a uniform superposition over pairs u, u′ of points lying on the same affine subspace with
slopes v 1 , v 2 .
4. Alice and Bob both measure register R0 in the Z basis, obtaining outcomes u and u′ , respectively. The shared state is now
|ψ3′ i = (|uiAlice ⊗ |u′ iBob )R0 ⊗ (|v 1 iAlice ⊗ |v 1 iBob )R1 ⊗ (|v 2 iAlice ⊗ |v 2 iBob )R2 .
Alice sets her plane to be svu and Bob sets his point to be u′ .
Now, from the calculation performed above, it’s clear that Bob’s point u′ is uncorrelated with Alice’s
intercept u, apart from lying in the plane svu , and hence there is no further information about Bob’s
point that Alice can learn by measuring her portion of the final state |ψ3′ i. But Alice still obtains
some additional information from her measurements along the way, in particular the outcomes
α1 , α2 of the X measurements. And moreover, how can we certify that the X measurements were
performed correctly, since they are not Pauli basis measurements as given to us by the compiler? To
answer these questions, we define a new game called the partial data-hiding game (Theorem 10.4),
which certifies that Alice and Bob perform the steps described above and that no extra information
is leaked. Building on this game, we can now design a protocol for NEEXP with small question size:
Informal Theorem 2.6 (Theorem 15.8 in the body). There is an MIP∗ protocol G1 for NEEXP
with questions of length poly(n), and answers of length exp(n). The verifier can generate the
questions in poly(n) time but needs exp(n) time to verify the answers.

2.5

Answer reduction through PCP composition

We have succeeded in obtaining a game with short questions, but the answers are now exponentially
long. In the last step, we will use composition with a classical probabilistically checkable proof
(PCP) to delegate verification of the answers to the provers.
Schematically, the protocol G1 consists of the following steps:
1. The verifier sends Alice a question x and Bob a question y.
2. Alice returns an (exponentially-long) answer A and Bob an exponetially-long answer B.
3. The verifier computes a verification predicate V (x, y, A, B) in exponential time.
1
Strictly speaking, this is only true when v 1 · v 1 6= 0 and v 2 · v 2 6= 0. A more rigorous treatment of this is given
in Section 10.

13

We would like to delegate the last step to the provers by asking them to compute a PCP proof
that V (x, y, A, B) = 1, which the verifier can check by communicating only polynomially many
bits with the provers. However, we face an obstacle: Alice cannot know y and B, and neither can
Bob know x and A, and distributed PCPs (where neither party knows the entire assignment) are
known to be impossible [ARW17]. To proceed, we will first have to modify G1 by oracularizing it:
1. The verifier sends Alice the questions x, y, and Bob either x or y, chosen uniformly at random.
2. Alice returns exponentially-long answers A, B, and Bob returns an answer C.
3. The verifier computes a verification predicate V (x, y, A, B) on Alice’s questions and answers,
and further checks that A = C, if Bob received x, or that B = C, if Bob received y.
The idea is that the new Alice simulates both Alice and Bob from the original protocol, and the
new Bob certifies that the new Alice does not take advantage of her access to both questions to
cheat. It is well-known that oracularization does not harm the soundness of interactive protocols,
be they classical or quantum. However, in the quantum world, it is not necessarily the case that
the oracularized protocol retains completeness. This is because Alice and Bob may have been asked
to perform non-compatible measurements in the original protocol, rendering it impossible for the
new Alice to simulate both the original Alice and Bob. Fortunately for us, the honest strategy for
protocol G1 is such that completeness under oracularization.
Now that a single prover is in possession of all inputs to the verification predicate V , we can
implement our idea of using a PCP proof. Classically, this idea is known as PCP composition,
and is extensively used in the PCP literature. In the quantum case, the requirement to maintain
soundness against entanglement makes composition technically difficult, and we defer the details
to Part V of the paper. Once the composition is performed, we reach our main result.
Informal Theorem 2.7 (Theorem 17.12 in the body). There is an MIP∗ protocol G2 for SuccinctSuccinct-3Sat (and hence for NEEXP) with question size, answer, and verifier runtime poly(n).

2.6

Organization

The paper is organized into five parts. The first part is the introduction and this overview. The
remaining parts are organized as follows.
• Part II contains two sections of preliminaries, one containing the classical background and
another the quantum background.
• Part III contains the register compiler, i.e. the proof of Informal Theorem 2.5. This involves
designing the Pauli basis test (Section 6) and the data hiding test (Section 8). Section 5
serves as an introduction to this part and contains more details on the organization.
• Part IV contains the “introspection” question reduction step, i.e. the proof of Informal Theorem 2.6.
To begin, we sketch the classical MIP protocol for Succinct-3Sat in Section 11. Then we give
the introspected, i.e. “big”, low-degree test in Section 13, and finish by giving the entire smallquestion NEEXP protocol in Section 15. Section 14 contains a test necessary for the protocol
called the “intersecting lines test”. It allows us carry over the results of the low-degree test
from one register to another.
• Part V contains the answer reduction, i.e. the proof of Informal Theorem 2.7. The construction involves composing PCP protocols with error-correcting codes, and so Section 16 surveys
the properties we need of an error-correcting code. Finally, Section 17 contains the actual
proof of the answer reduction step.
14

Part II

Preliminaries
3
3.1

Classical preliminaries
Finite fields and polynomials

In this section we review some basic facts about finite fields and polynomials over them. These
facts can be found in a standard reference such as [MBG+ 13]. Let p be a prime and q = pt be a
prime power. We denote by Fp and Fq the finite fields with p and q elements, respectively. The
field Fp is called the base field or prime subfield of Fq . The larger field Fq can be viewed as a
t-dimensional vector space Ftp over the smaller field. We define the trace tr : Fq → Fp by
tr[a] =

t−1
X

ℓ

ap .

ℓ=0

The trace is a linear map under linear combinations with coefficients drawn from Fp .
A basis for Fq over Fp consists of k elements {α1 , . . . , αk }, such that any element u ∈ Fq can be
written as a linear combination
k
X
ci αi ,
u=
i=1

where the coefficients ci ∈ Fp . Two bases {αi } and {βi } are dual bases if tr[αi βj ] = δij , where δij
is the Kronecker delta function.

Fields of characteristic 2 : When p = 2 (i.e. q is even), several useful properties hold. Most
importantly for us, the field Fq has a self-dual basis: that is, there exists a basis P
{αi } such that
+
tr[αi αj ] = δij [MBG 13, Theorem 1.9]. This means that given a field element u = i ci αi , we can
recover the coefficient cj by the expression cj = tr[uαj ].
Fourier identities Below, we give two useful identities for simplifying Fourier sums over finite
fields. We set ω = e2πi/p to be a p-th root of unity.
Fact 3.1. Eu∈Fq ω tr[u·a] = 0 if a is nonzero.
Proof. If a 6= 0, then there must exist some nonzero y ∈ Fq such that tr[ay] 6= 0. Let the value of
the expectation we want to compute be denoted by σ. Then we have
σ = E ω tr[au]
u∈Fq

= E ω tr[a(u+y)]
u∈Fq

= ω tr[ay] E ω tr[au]
u∈Fq

=ω

tr[ay]

σ,

and thus σ = 0.
/ V ⊥.
Fact 3.2. Let V be a subspace of Fnq . Then Eu∼V ω tr[hu,ai] = 0 if a ∈
15

Proof. The idea is the same as the proof of the previous fact. Suppose a ∈
/ V ⊥ . Then there exists
some nonzero y ∈ Fnq such that tr[ha, yi] 6= 0. Letting the value of the expectation we wish to
compute be denoted σ, we have
σ = E ω tr[hu,ai]
u∼V

= E ω tr[hu+y,ai]
u∼V
tr[ha,yi]

=ω

σ,

and hence σ must vanish.

3.2

Two-player one-round games and MIP

A two-prover nonlocal game is an interaction between a verifier and two noncommunicating provers,
in which the verifier samples a pair of random questions and sends them to the provers, receives
a pair of answers, and decides whether to accept or reject based on the questions and answers. In
the literature, a game is usually taken to be described by the verifier’s distribution over question
pairs, together with a table describing the verifier’s behavior for all possible choices of questions and
answers. For our purposes, it will be more convenient to work with uniformly generated families
of games, which are specified by Turing machines that sample the questions and decide whether to
accept or reject given the questions and answers.
Definition 3.3 (Two-player one-round uniform game family). A two-prover one-round game uniform game family G is an interaction between a verifier and two provers, Alice and Bob. The
verifier V = (AlgQ , AlgA ) consists of a “question” randomized Turing machine AlgQ and an “answer” deterministic Turing machine AlgA . Given an input string input, the verifier samples two
questions (x0 , x1 ) ∼ AlgQ (input) and distributes x0 to Alice and x1 to Bob. They reply with
answers a0 and a1 , respectively, and the verifier accepts if AlgA (input, x0 , x1 , a0 , a1 ) = 1. A strategy for Alice and Bob is said to be classical if they are allowed shared randomness but no shared
quantum resources. The value of Alice and Bob’s strategy is simply the probability that the verifier
accepts, and the classical value of the game is the maximum value of any classical strategy. We
write Q-length(G ) for the maximum bit length of the questions as a function of the input input,
and similarly A-length(G ) for the maximum bit length of the answers, Q-time(G ) for the maximum
running time of AlgQ , and A-time(G ) for the maximum running time of AlgA . Often we will not
explicitly write the dependence of these quantities on input.
Definition 3.4 (Multiprover interactive proofs). A 2-player 1-round multiprover interactive proof
protocol is a uniform game family G as in Definition 3.3. For parameters 0 < s < c ≤ 1, we say
that the protocol G decides the language L with completeness c and soundness s if the following
three conditions are true.
◦ (Completeness) Suppose input ∈ L. Then there is a classical strategy for G with value at
least c.
◦ (Soundness) Suppose input ∈
/ L. Then every classical strategy for G has value at most s.
◦ All of Q-length(G ), A-length(G ), Q-time(G ), and A-time(G ) are poly(n) where n is the bit
length of input.
The class MIPc,s is the set of all languages that can be decided by multiprover interactive proof
protocols with the parameters c, s.
16

If c − s is a constant, then we will suppress the dependence on them when writing MIP and
just say that L ∈ MIP. Here, “c” is referred to as the completeness and “s” is referred to as the
soundness. We will typically deal with the case when c = 1 and s = 1 − ǫ, where ǫ > 0 is a small
constant.
In this definition of MIP, the parameters Q-length(G ), A-length(G ), Q-time(G ), A-time(G ) are
required to be polynomial in the input length n. However, in this paper, several of the intermediate
results we achieve are protocols where these parameters scale superpolynomially (indeed, even
exponentially or worse) in n. In these cases, we will explicitly indicate the dependence of these
parameters on n.

3.3

Low-degree code

Let q be a prime power and h ≤ q be an integer. Let H be a subset of Fq of size h. For n ≥ 0, let
x ∈ H n . The indicator function of x over H n is the polynomial with inputs y ∈ Fm
q defined as
Qm Q
i=1
b∈H,b6=xi (yi − b)
.
indH,x (y) := Qm Q
i=1
b∈H,b6=xi (xi − b)
There are two properties of this polynomial that we will need:
(i) that it is low-degree, i.e. a degree-m(h − 1) polynomial,

(ii) that for any x, y ∈ H m , indH,x (y) = 1 if and only if x = y, and otherwise indH,x (y) = 0.
Using this, we can define the low-degree code.
Definition 3.5 (Low-degree encoding). Let |S| ≤ hm , and let π : S → H m be an injection. Then
the low-degree encoding (sometimes also called the Reed-Muller encoding) of a string a ∈ FSq is the
polynomial ga : Fm
q → Fq defined as
X
ga (x) :=
ai · indH,π(i) (x).
i∈S

By the properties of the indicator function above, (i) ga is a degree-m(h − 1) polynomial, and
(ii) ga (π(i)) = ai for all i ∈ S. We will typically, though not always, take S = [n]. Given an
error-correcting code, there are two key properties we care about: the rate and the distance. The
rate of the low-degree code is n/q m . As for the distance, we can estimate it with the following
lemma.
Lemma 3.6 (Schwartz-Zippel lemma [Sch80, Zip79]). Let f, g be two unequal m-variate degree-d
polynomials over Fq . Then
Prm [f (x) = g(x)] ≤ d/q.
x∼Fq

As a result, the low-degree encoding has relative distance m(h − 1)/q. In a typical application,
we would like a code with large rate and distance. To achieve this, we will often use the following
“rule of thumb” setting of parameters:


log(n)
,
q = polylog(n).
(1)
h = Θ(log(n)),
m=Θ
log log(n)
This gives a code with rate 1/poly(n) and distance o(1). The polynomials involved are degree
d = Θ(log(n)2 / log log(n)).
17

3.4

A canonical low-degree encoding

The low-degree encoding affords us some flexibility when choosing the parameters and the injection;
however, for our application we will have to choose these with care, because each of our uses of the
low-degree code requires that the injection π be efficiently computable. In this section, we give a
simple, canonical choice for the subset H and the injection π so that this is true.
Definition 3.7. We say that n, h = 2t1 , q = 2t2 , and m are admissible parameters if t1 ≤ t2 and
hm ≥ n.
The following definition gives the canonical encoding.
Definition 3.8 (Canonical low-degree encoding). Let n, h = 2t1 , q = 2t2 , and m be admissible
parameters. Set ℓ = t1 · m. The canonical low-degree code is defined as follows.
(i) Let e1 , . . . , et2 be a self-dual basis for Fq over F2 . Then we set H to be the subset
H := Ht1 ,t2 = {b1 · e1 + · · · + bt1 · et1 | b1 , . . . , bt1 ∈ F2 }.
As desired, |H| = h.
(ii) Let σ := σt1 ,t2 : {0, 1}t1 → Ht1 ,t2 be the bijection σ(b1 , . . . , bt1 ) = b1 · e1 + · · · + bt1 · et1 . From
this, we can construct a bijection σℓ,t1 ,t2 : {0, 1}ℓ → H m by setting
σℓ,t1 ,t2 (b1 , . . . , bℓ ) = (σ(b1 , . . . , bt1 ), σ(bt1 +1 , . . . , b2t ), . . . , σ(bℓ−t1 +1 , . . . , bℓ )).
(iii) Given an index i ∈ [n], write binℓ (i) for its ℓ-digit binary encoding. Then we define the
injection π := πℓ,t1 ,t2 : [n] → H m as π(i) = σℓ,t1 ,t2 (binℓ (i)).
The following proposition gives the time complexity of the canonical low-degree encoding.
Proposition 3.9. The bijection σℓ,t1 ,t2 and the injection π := πℓ,t1 ,t2 are both computable in time
m · polylog(q). As a result, given a string a ∈ Fnq and a point x ∈ Fm
q , the value ga (x) takes time
poly(n, m, q) to compute.

3.5

Low-degree testing

Definition 3.10 (Surface-versus-point test). The surface-versus-point low-degree test with parameters m, d, q (a prime power), and k, denoted GSurface (m, d, q, k), is defined as follows. Let v 1 , . . . , v k
be k uniformly random vectors in Fm
q , and let s be a uniformly random affine subspace parallel to
span{v 1 , . . . , v k } (that is, s is the set {w + λ1 v 1 + · · · + λk v k : λ1 , . . . , λk ∈ Fq } for a uniformly
random w), and let u be a uniformly random point on s. Given these, the test is performed as
follows.
◦ The vectors v 1 , . . . , v k and the surface s are given to Alice, who responds with a degree-d
polynomial f : s → Fq .

◦ The point u is given to Bob, who responds with a number b ∈ Fq .
Alice and Bob pass the test if f (u) = b.

18

Remark 3.11. Let us remark briefly on the encodings used in this test. A surface s with directions
(k+1)n
v1 , . . . , vk is encoded by the string (u, w1 , . . . , wk ) ∈ Fq
. Here, u is the lexicographically
minimum point in s, and w1 , . . . , wk are the rows of the matrix produced by taking the matrix with
rows v1 , . . . , vk and transforming it to reduced row echelon form. We note that given v1 , . . . , vk and
a point u ∈ s, this encoding can be produced in time poly(n, k, log(q)).
A function f : s → Fq is a degree-d polynomial on s if there exists a degree-d k-variate polynomial
f ′ : Fkq → Fq such that f ′ (λ1 , . . . , λk ) = f (u + λ1 w1 + · · · + λk wk ). When s is already known, we can

encode f by specifying f ′ , which involves writing out its d[k] := d+k
coefficients in some arbitrary
k
but fixed order.
We note that this definition of the surface-versus-point test differs slightly from the standard
definition of the surface-versus-point test in two respects. First, we do not require that the vectors
v 1 , . . . , v k be linearly independent or even nonzero, which implies that there is a





q
q k−1
qk
1
1 − m ··· 1 − m
≤ m
1− 1− m
q
q
q
q
chance that s is less than k-dimensional. Second, we send the vectors v 1 , . . . , v k to Alice in
addition to the description of the surface s. It is not hard to see that these two modifications do
not asymptotically harm the soundness guarantee obtained for the standard plane-versus-point test
shown by Raz and Safra [RS97], which we restate here.
Theorem 3.12 ([RS97]). There exist absolute constants c, c′ > 0 such that the following holds.
Suppose Alice and Bob pass GSurface (m, d, q, 2) with probability at least µ. Then there exists a
degree-d polynomial g : Fm
q → Fq such that
′

Pr [g(u) = b] ≥ µ − c · m(d/q)c .

(s,u)

Explicit values for c, c′ have been derived by Moshkovitz and Raz [MR08], albeit for the weaker
guarantee that g be a degree-md polynomial, which is still sufficient for most applications.
Communication cost.

We can compute the communication cost of this test as follows.

3m
◦ Question length: We encode a plane in Fm
q with a string (u, v1 , v2 ) ∈ Fq . This requires
3m log(q) bits to communicate.

◦ Answer length: A degree-d bivariate polynomial on Fq can be described with d+2
≤
2
(d + 1)2 coefficients in Fq . These require (d + 1)2 log(q) bits to communicate.

Recalling Equation (1), a typical setting of parameters gives questions of length Θ(log(n)), and
answers of length Θ(log(n)4 / log log(n)).

3.6

Simultaneous low-degree testing

Definition 3.13 (Simultaneous surface-versus-point test). The simultaneous surface-versus-point
ℓ
(m, d, q, k),
low-degree test with parameters m, d, q (a prime power), k, and ℓ, denoted GSurface
is defined as follows. A draw (s, u) is sampled as in GSurface (m, d, q, k). Given this, the test is
performed as follows.
◦ The surface s is given to Alice, who responds with ℓ degree-d polynomials f 1 , . . . , f ℓ : s → Fq .
19

◦ The point u is given to Bob, who responds with ℓ numbers b1 , . . . , bℓ ∈ Fq .
Alice and Bob pass the test if f 1 (u) = b1 , . . . , f ℓ (u) = bℓ .
Classically, the k = 2 case of this test can be reduced to a slight generalization of Theorem 3.12
using a simple and standard union-bound argument. Quantumly, however, a corresponding entanglementsound analogue of this generalization is not known to hold. Instead, we use a slightly more involved
reduction in which the ℓ outputs of Alice and Bob are “combined” to create a strategy for the
“standard” plane-versus-point test. (This technique is standard and was also used in the proof of
Lemma 4.6 in [NV18a] for the case ℓ = 2.) In this section, we will introduce the notation needed for
this reduction and carry out the proof of the classical soundness of the simultaneous low-degree test
as a warm-up for our proof of quantum soundness later. We begin by showing how to combine ℓ
functions by introducing ℓ “indexing” variables.
Notation 3.14. Let g1 , . . . , gℓ : s → Fq be functions, where s is a subset of Fm
q . Then we define
ℓ
the new function combineg (x, y) : Fq ⊗ s → Fq as follows:
combineg (x, y) = x1 · g1 (y) + · · · + xℓ · gℓ (y).
m
We will typically apply this with s = Fm
q or s a dimension-k subspace of Fq .
ℓ+m .
If the gi ’s are degree-d polynomials on Fm
q , this produces a degree-(d + 1) polynomial on Fq
First, we show that given a surface-versus-point query from this (ℓ + m)-dimensional space, we can
produce a surface-versus-point query from the m-dimensional space.

Proposition 3.15. Given a subset s ⊆ Fqℓ+m , let sproj = {y | (x, y) ∈ Fℓq ⊗ Fm
q }.
◦ If s is a dimension-k subspace of Fqℓ+m , then sproj is a dimension-k′ subspace of Fm
q , for
′
k ≤ k.
Define s′ ∼k sproj to be a uniformly random dimension-k subspace of Fm
q containing sproj .
◦ If s and (x, y) are distributed as DSurface (ℓ + m, q, k), then s′ ∼ sproj and y are distributed as
DSurface (m, q, k).
Proof. The first bullet follows because if {(x1 , y1 ), . . . , (xk , yk )} is a set of k linearly independent
vectors which span s, then {y1 , . . . , yk } is a set of k vectors which span sspan , though they may no
longer be linearly independent. The second bullet follows by symmetry.
Next, we show that answers to the queries on the m-dimensional space can be used to produce
answers to the queries on the (ℓ + m)-dimensional space.
Proposition 3.16. Let s be a dimension-k subspace of Fqℓ+m , and let s′ ⊆ Fm
q be a subspace which
contains sproj . Then Fℓq ⊗ s′ is a subspace, and it contains s. In particular, if f1 , . . . , fℓ are degree-d
functions on s′ , then combinef is a degree-(d + 1) function on Fℓq ⊗ s′ , and it can be restricted to a
degree-(d + 1) function on s.
Proof. Consider a point (x, y) ∈ s. Then y ∈ sproj ⊆ s′ , and so (x, y) ∈ Fℓq ⊗ s. The statement
about combinef follows immediately.
Finally, we need a technical result: that nonlinear low-degree polynomials rarely become linear
after restricting variables.
20

Definition 3.17. Let n ≥ 0. A function f : Fqℓ+n → Fq is exactly linear in x if it can be written as
f (x, y) = x1 · f1 (y) + · + xℓ · fℓ (y).
(We do not allow constant terms.) Note that when n = 0, such a function can be written as
c1 · x1 + · · · + cℓ · xℓ , where each ci ∈ Fq , in which case we simply call it “exactly linear”. Given
a function f (x, y) and a string y ∈ Fm
q , we will also write f |y for the function defined as fy (x) =
f (x, y).
Proposition 3.18. Suppose f (x, y) : Fqℓ+m → Fq is a degree-d polynomial which is not exactly
linear in x. Then the probability that f |y is exactly linear, over a uniformly random y ∼ Fm
q , is at
most d/q.
Proof. Because f is not exactly linear in x, it contains some non-linear x-monomial xi = xi11 · · · xiℓℓ in
which i1 +· · ·+iℓ is either zero or at least two. Thus, f can be written as f (x, y) = xi ·gi (y)+f ′ (x, y),
where gi (y) is degree-d and f ′ contains no xi terms. For f |y to be exactly linear, this term must
vanish, which means gi (y) = 0. But by Schwartz-Zippel (Lemma 3.6), this happens with probability
at most d/q.
We are now ready to prove soundness of the simultaneous low-degree test in the k = 2 case.
Theorem 3.19. There exists absolute constants c, c′ > 0 such that the following holds. Suppose Alℓ
(m, d, q, 2) with probability at least µ. Then there exist degree-d polynomials
ice and Bob pass GSurface
m
g1 , . . . , gℓ : Fq → Fq such that
′

Pr [g1 (u) = b1 , . . . , gℓ (u) = bℓ ] ≥ µ − c · (m + ℓ)(d/q)c .

(s,u)

Proof. Let c, c′ > 0 be as in Theorem 3.12. We pick the constants in this theorem, say ĉ, ĉ′ so that
′

′

µ − c · (m + ℓ)((d + 1)/q)c − 2(d + 1)/q ≥ µ − ĉ · (m + ℓ)(d/q)ĉ .
′

Note that this means that the theorem is trivial when 2(d + 1)/q ≥ µ − c · (m + ℓ)((d + 1)/q)c . As
such, we will assume below that
′

2(d + 1)/q < µ − c · (m + ℓ)((d + 1)/q)c .

(2)

ℓ
(m, d, q, 2) with probability at least µ. We will use them
Suppose Alice and Bob pass GSurface
to simulate two provers, “Combined Alice” and “Combined Bob”, who pass the single-function
low-degree test GSurface (ℓ + m, d + 1, q, 2) with probability at least µ. They are specified as follows:

◦ Combined Alice: Given s ⊆ Fqℓ+m , draw s′ ∼2 sproj . Give it to Alice, who responds with
f 1 , . . . , f ℓ : s′ → Fq . Output the function combinef |s .
◦ Combined Bob: Given (x, y) ∈ Fqℓ+m , compute y ∈ Fm
q . Give it to Bob, who responds with
b1 , . . . , bℓ ∈ Fq . Return combineb (x) ∈ Fq .
ℓ
(m, d, q, 2). Using our
By Proposition 3.15, s′ and y are distributed as the questions in GSurface
assumption on Alice and Bob, this means that f 1 (y) = b1 , . . . , f ℓ (y) = bℓ with probability at least
µ. As a result, (combinef |s )(x, y) = combineb (y) with probability at least µ. By Proposition 3.16,
combinef |s is a degree-(d + 1) function on s, and so it is a valid response to subspace queries. This
means Combined Alice and Bob pass GSurface (ℓ + m, d + 1, q, 2) with probability at least µ.

21

Thus, we can apply Theorem 3.12. It gives a degree-(d + 1) function g : Fqℓ+m → Fq such that
′

Pr[g(x, y) = combineb (x)] ≥ µ − c · (ℓ + m) · ((d + 1)/q)c .
x,y

(3)

We would like to show that g is exactly linear in x. Assume for the sake of contradiction that this
is not the case. Because b depends only on y (and Bob’s internal randomness), we can consider
varying these two variables independently of x. By Proposition 3.18, the probability that gy is not
exactly linear is at least 1 − (d + 1)/q. In this case, because combineb (x) is always exactly linear,
the probability that g|y (x) = combineb (x) is at most (d + 1)/q by Schwartz-Zippel (Lemma 3.6).
As a result, the probability that g(x, y) = combineb (x) is at most (d + 1)/q + (d + 1)/q, which
contradicts Equations (2) and (3). Thus, we P
may conclude that g is exactly linear in x.
This implies that we can write g(x, y) = i xi · gi (y), where each gi is a degree-d polynomial.
Now, for any fixed b and y, if it is not the case that g1 (y) = b1 , . . . , gℓ (y) = bℓ , then the probability
that g(x, y) = combineb (x) over a random x is at most 1/q by Schwartz-Zippel since both are
exactly linear functions. Thus, if η is the probability that g1 (y) = b1 , . . . , gℓ (y) = bℓ , then
the probability that g(x, y) = combineb (x) is at most η + (1 − η)/q ≤ η + 1/q. Combined with
Equation (3), this implies the theorem.

3.7

NEXP, NEEXP, and complete problems for them

Definition 3.20. The class NEEXP (respectively, NEEXP) is the class of all problems that can be
solved in exponential (respectively, doubly-exponential) time by a nondeterministic Turing machine.
Formally,
[
[
c
nc
NEXP =
NTIME(2n ),
NEEXP =
NTIME(22 ).
c∈N

c∈N

A standard way of generating NEXP-complete problems is by considering “succinct” versions
of NP-complete problems, in which an exponential-sized input is encoded by a polynomial-sized
circuit. The canonical complete problem is a succinct version of 3Sat, but there is considerable
freedom in choosing the succinct encoding used. We choose the following encoding.
Definition 3.21. Succinct-3Sat is the following problem.
◦ Input: a circuit C with 3n + 3 input bits and size poly(n). It encodes the 3-Sat instance ψC
with variable set xu for u ∈ {0, 1}n which includes the constraint (xbu11 ∨ xbu22 ∨ xbu33 ) whenever
C(u1 , u2 , u3 , b1 , b2 , b3 ) = 1.
(Here, x1i refers to the literal xi and x0i refers to the negated literal xi .)
◦ Output: accept if ψC is satisfiable and reject otherwise.
A proof that Succinct-3Sat is NEXP complete can be found in [Pap94, Chapter 20], albeit with
a different encoding. Below, we show this implies NEXP-completeness for our encoding as well.
Proposition 3.22. Succinct-3Sat is NEXP-complete.
Proof. Papadimitriou [Pap94] considers circuits CPap which encode 3Sat formulas φ with n variables
and m clauses as follows: CPap takes as input a string (b, u, k), where b, k ∈ {0, 1}2 are interpreted
as integers in {0, 1, 2, 3} and u ∈ {0, 1}log(m) is interpreted either as a vertex 1 ≤ u ≤ n or a clause
1 ≤ u ≤ m. If 1 ≤ u ≤ n and 0 ≤ k ≤ 2, then on input (0, u, k), CPap outputs the index of the clause
22

where xu appears for the k-th time, and on input (1, u, k), it outputs the index of the clause where
xu appears for the k-th time. (In addition, if 1 ≤ u ≤ m and 0 ≤ k ≤ 3, then on input (2, u, k),
CPap outputs the k-th literal of the u-th clause in φ. We state this for completeness, though we will
not need it for the proof.) Such a 3Sat formula ψ has 2n literals, each occurring 3 times, and so
m = 2n. By [Pap94, Chapter 20], this succinct encoding of 3Sat is NEEXP-complete. Using this,
we can generate an instance of the Succinct-3Sat problem C such that φC = φ as follows: given
input (u1 , u2 , u3 , b1 , b2 , b3 ), we simply evaluate CPap on (bi , ui , k), for each 1 ≤ i ≤ 3 and 0 ≤ k ≤ 2,
and output 1 if there is any clause containing all three literals.
The complete problem for NEEXP is, appropriately enough, a succinct version of Succinct-3Sat.
To define it precisely, it helps to fix a notion of a Boolean circuit. Following Section 4.3 of [Pap94],
we consider Boolean circuits in which each gate can be one of six types: input, true, false, ∧, ∨, or
¬. These gates have 0, 0, 0, 2, 2, or 1 inputs, respectively. A succinct representation of a circuit
C1 is a circuit C2 that, given an index i, outputs the type of gate i as well as the indices j1 , j2 of its
inputs (one or both of these indices may be the null index ∅ depending on the type of the gate i).
Definition 3.23. Succinct-Succinct-3Sat is the following problem.
◦ Input: a circuit C with size poly(n), which is a succinct representation of a circuit C ′ , which
is itself an instance of Succinct-3Sat with instance size N = 2poly(n) .
poly(n)

◦ Output: accept if ψC ′ (the 3Sat formula on 2N = 22
C ′ ) is satisfiable and reject otherwise.

variables generated by the circuit

Fact 3.24. Let M be a deterministic Turing machine which takes two inputs x1 , x2 . Then for any
input x1 of size n1 and for any size parameter n2 and time T > n1 + n2 , there exists a circuit
CM,T,x1 of size N = O(T 2 ) which, on an input x2 of size n2 , computes M run for T steps on the
input pair x1 , x2 . Moreover, there exists a Turing machine M ′ that given x1 , n2 , and an index
i ∈ {1, . . . , N } in binary, outputs in polynomial time the type of the ith gate of CM,T,x1 and the
indices j1 , j2′ of the inputs to this gate.
Proof. The construction in the proof of Theorem 8.1 of [Pap94] yields a circuit of the desired size.
This circuit consists of O(T 2 ) copies of a constant-sized circuit CM that depends only on M .
Theorem 3.25 (Cook-Levin). Let L be a language in NTIME(T (n)). Then the following properties
hold:
1. For every string x of length n, there exists a 3Sat formula Φx on n′ = poly(T (n)) variables
z1 , . . . , zn′ , such that x ∈ L iff Φx is satisfiable.
2. There exists a Turing machine R that given an input x of length n, three indices u1 , u2 , u3 ∈
{1, . . . , n′ } in binary, and three bits b1 , b2 , b3 ∈ {0, 1}, runs in poly log(n′ ) = poly log(T (n))
time and outputs 1 iff the clause (zub11 , zub22 , zub33 ) is included in Φx .
Proof. We follow the proof of Theorem 8.2 of [Pap94] to obtain the 3Sat instance Φx .
Theorem 3.26. Succinct-Succinct-3Sat is complete for NEEXP under polynomial time mapping
reductions. That is, for any language L in NEEXP, there exists a Turing machine R which takes as
input a string x ∈ {0, 1}n , and in time poly(n) outputs an instance Cx of Succinct-Succinct-3Sat,
such that Cx is satisfiable iff x ∈ L.

23

Proof. Suppose we start with a language L ∈ NEEXP. This means there is a nondeterministic
nc
Turing machine M which decides L in time T0 = 22 . By Theorem 3.25, there exists a Turing
c
machine R1 which runs in time T1 = poly log(T0 ) = 2O(n ) such that given input x and clause
indices i = (u1 , u2 , u3 , b1 , b2 , b3 ), represented as a binary string of length |i| = log(poly(T0 )) =
nc
c
log(2O(2 ) ) = O(2n ), runs in time polynomial in ℓ and outputs 1 iff the corresponding clause
exists in a 3Sat formula Φx such that x ∈ L iff Φx is satisfiable.
Now, if we apply Fact 3.24 to R1 , with x playing the role of the first input x1 and i the role of
c
the second input, we obtain that for every x there exists a circuit CR1 ,T1 ,x of size O(T12 ) = 2O(n )
which takes as input a tuple of indices i, and runs R1 for time T1 on this time to output whether
clause i is present in the formula Φx . Moreover, there exists a Turing machine R2 that, given x,
c
the size parameter |i| = O(2n ), represented in binary as a string of O(nc ) bits, and an index j,
represented as a string of O(nc ) bits, outputs the jth gate of CR1 ,T1 ,x in time T2 = poly(n). Note
that R2 is a Turing machine which takes in input of size poly(n) and runs in time poly(n).
We are now almost where we need to be. In the final step, we once again apply Fact 3.24 to
R2 , obtaining a third Turing machine R3 that takes as input x and the size parameters, and an
index k, and generates the kth gate of the circuit CR2 ,T2 ,x corresponding to running R2 for T2 steps.
Finally, by fixing the dependence of the size parameters on the size of x, and iterating through all
possible values of the index parameter, we obtain a Turing machine R3′ that takes as input x and
runs in time poly(n), and outputs the complete description of a Succinct-Succinct-3Sat instance Cx
with the desired properties.

3.8

The Tseitin transformation

In this section, we introduce the Tseitin transformation, which is a simple method of converting a
Boolean circuit into a Boolean formula.
Definition 3.27 (Tseitin transformation). Let C be a Boolean circuit with n input variables
x1 , . . . , xn and s gates. Then the Tseitin transformation of C, denoted F := Tseitin(C), is the
Boolean formula defined as follows.
(i) Introduce new variables w1 , . . . , ws corresponding to the output wires of the gates in C. Then
the input variables to F consist of x1 , . . . , xn along with w1 , . . . , ws .
(ii) Each gate in C operates on one or two variables in {x1 , . . . , xn , w1 , . . . , ws }. Write gi (x, w) for
the function computed by the i-th gate. Then F computes the intermediate expression
zi := (gi (x, w) ∧ wi ) ∨ (gi (x, w) ∧ wi ).
The final output of F is z1 ∧ (z2 ∧ (· · · ∧ zs )).
By construction, C(x) = 1 if and only if there exists a w such that F(x, w) = 1 (in particular, w
is taken to be the wire values of C on input x). In addition, F contains exactly 7s + (s − 1) gates,
meaning that it has size O(s).
Next, we show how to convert Boolean formulas into functions over Fq .
Definition 3.28 (Arithmetization). Let F be a Boolean formula of n variables and size s. The
arithmetization of F over Fq , denoted arithq (F), is the formula produced by the following two-step
process.
(i) Transform F by replacing all ∨ gates with appropriate ∧ and ¬ gates.
24

(ii) Transform each Boolean gate into an Fq gate as follows: Replace each ∧ gate in F with a ×
gate. Replace each ¬ gate with a ×−1 gate followed by a +1 gate (enacting the transformation
b ∈ Fq 7→ 1 − b). Call the resulting formula arithq (F).
Set Farith := arithq (F). On inputs x ∈ {0, 1}n , Farith (x) = F(x). On general inputs x ∈ Fnq ,
Farith (x) is computable in time poly(s, q).
The following proposition shows that small Boolean formulas have low-degree arithmetizations.
Proposition 3.29 (Low-degree arithmetization). Let F be a Boolean formula of n variables, size s,
and m gates. Then arithq (F) is a degree-s polynomial over Fq .
Proof. By induction on the number of gates, the base case (m = 0) being trivial. For the induction
hypothesis, assume the proposition holds for Boolean formulas which have fewer than m gates.
Either the gate at the root of F is a ¬ gate or an {∨, ∧}-gate. In the former case, F = ¬F ′
for some Boolean formula with m − 1 gates, and so arithq (F) = 1 − arithq (F ′ ) by construction.
But these have the same degree, and so arithq (F) is degree s by the induction hypothesis. In the
latter case, assume without loss of generality that it is an ∧-gate. Then F = Fleft ∧ Fright for two
formulas of size sleft + sright = s and fewer than m gates. By the induction hypothesis, arithq (Fleft )
has degree-sleft and arithq (Fright ) has degree-sright , and so arithq (F) = arithq (Fleft ) × arithq (Fright )
has degree s.
The arithmetization procedure describe in Definition 3.28 can also be applied to general Boolean
circuits C, not just Boolean formulas. But Proposition 3.29 does not apply to general circuits; in
fact, the arithmetization of a Boolean circuit can have very high degree, even if that circuit is small.
This motivates using the Tseitin transformation: it allows us to convert a small circuit into a small
formula, which has a low-degree arithmetization.

4
4.1

Quantum preliminaries
Quantum measurements

The most general notion of a quantum measurement is a POVM measurement, which consists of
a set of Hermitian operators {Ma }a∈S indexed by outcomes a from a set S. These satisfy the
conditions
X
∀a, Ma  0,
Ma = I.
a

To refer to the measurement as a whole we will use the letter M , without the subscript indicating
the outcome. For a state |ψi, the probability that the measurement M returns outcome a is
Pr[a] = hψ| Ma |ψi .

A POVM is said to be projective if each element Ma is an orthogonal projector, i.e. Ma2 =
Ma . Note that this implies that Ma Mb = 0 for any a 6= b, i.e. that the projectors are pairwise
orthogonal. Naimark’s theorem says that any POVM measurement can be simulated by a projective
measurement on an enlarged space.
Theorem 4.1 (Naimark). Suppose {Ma } is a POVM acting on a Hilbert space H. Then there
exists a projective measurement {Ma′ } acting on the space H ⊗ Haux together with a state |auxi

25

such that for all states |ψi ∈ H and all outcomes a, the post-measurement state after applying M
and M ′ is the same:
p
p
(4)
Ma |ψi hψ| Ma = traux (Ma′ (|ψi hψ| ⊗ |auxi haux|)Ma′ ).

As a consequence, M and N induce the same distribution over outcome probabilities:
hψ| Ma |ψi = (hψ| ⊗ haux|)Na (|ψi ⊗ |auxi).

Moreover, given any upper-bound n on the number of outcomes of Ma , there is a universal choice of
the state |auxi that works for all POVMs Ma with at most n outcomes. The projective measurement
Ma′ and state |auxi together constitute a Naimark dilation of the POVM Ma .
Theorem 4.2 (Partial Naimark). Suppose {Ma1 ,a2 } is a POVM acting on a tensor product Hilbert
space H = H1 ⊗ H2 of the form Ma1 ,a2 = Πa1 ⊗ Aaa12 , where the operators {Πa1 }a1 is a projective
measurement. Then there is a Naimark dilation Ma′ 1 ,a2 and a state |auxi as above, with the property
′a1
1
that Ma′ 1 ,a2 = Πa1 ⊗ A′a
a2 for projectors Aa2 acting on H2 ⊗ Haux .
Proof. The condition that {Πa1 } forms a projective measurement implies that for each a1 , {Aaa12 }
a1
1
is a POVM. By Theorem 4.1, for each a1 there exists a POVM A′a
a2 dilating Aa2 , and all of these
′
1
POVMs act on the same universal auxiliary state |auxi. Now, define Ma1 ,a1 = Πa1 ⊗ A′a
a2 . For
every state |ψi, we have that
′a1
1
traux (Ma′ 1 ,a2 (|ψi hψ|)Ma′ 1 ,a2 ) = traux (A′a
a (Πa1 |ψi hψ| Πa1 ⊗ |auxi haux|)Aa2 )
p a
p a 2
= Aa12 (Πa1 |ψi hψ| Πa1 ) Aa12
p
p
= Ma1 ,a2 |ψi hψ| Ma1 ,a2 ,

where in going from the first to the second line we used Theorem 4.1.

For the purposes of this paper, we will need to specialize the POVM notation introduced above in
several ways. First, we will often work with families of POVM measurements indexed by questions
in an interactive proof protocol. These will be denoted {Maq }, where q indexes the question and a
the outcome. (We note that the reverse convention “{Mqa }”, which we will not use, is also common
in the literature.) In many cases, the outcomes will consist of tuples of elements, some of which
we may wish to discard. We use the convention that if an outcome element is not written, it is
x } is a family of POVMs, we would have
understood to be summed over. Thus, if {Ma,b
X
x
Max :=
Ma,b
.
(5)
b

Notation 4.3. We will also often consider situations where some of the information in a measurement outcome is discarded. In particular, given a POVM {Mf } whose outcomes are functions
f : U → V over some domain U , and given a point x ∈ U , we will denote by {Mf (x)=y }y∈V the
measurement corresponding to applying M to obtain a function f , and returning the value of f at
x. Formally, the POVM elements of this measurement are given by
X
M[f (x)=a] =
Mf .
f :f (x)=a

(We note that Equation (5) can be viewed as a special case in which the “discarding function” f
simply removes the second coordinate. For this case, it is simpler to use the convenient notation
in Equation (5) than the more cumbersome bracket notation given here.)
26

The following lemma contains a useful fact about marginalized projective measurements.
Lemma 4.4. Let Ma,b be a projective measurement on a tensor product Hilbert space H1 ⊗ H2 ,
and suppose that for all a, Ma = Aa ⊗ Ba where Aa is a rank-one matrix on H1 . Then for all a, b,
Ma,b = Aa ⊗ Ca,b with Ca,b projectors.
Proof. By the Schmidt decomposition, we can write Ma,b as
X
Ma,b =
|ψa,b,j i hψa,b,j |
j

=

X
j,k

σjk |ua,b,j,k i hua,b,j,k | ⊗ |va,b,j,k i hva,b,jk | .

Write the rank-one matrix Aa as an outer product |ψa i hψa |. Then we have
X
X
Ma,b =
σjk |ua,b,j,k i hua,b,j,k | ⊗ |va,b,j,k i hva,b,jk | = |ψa i hψa | ⊗ Ba .
b

j,k,b

Taking the partial trace on the B system, we have
X
X
trB (
Ma,b ) =
σjk |ua,b,j,k i hua,b,j,k | = |ψa i hψa | .
b

j,k,b

Suppose we multiply on the left by hv|
Pand on the right by |vi, for |vi orthogonal to |ψa i. Then
the RHS is 0 while the LHS is a sum j,k,b σjk | hv|ua,b,j,k i |2 of nonnegative terms. Hence, each of
these terms must be zero. Thus, the equation can only hold if all the vectors |ua,b,j,k i are multiples
of |ψa i. This implies that
Ma,b = |ψa i hψa | ⊗ Ca,b
for some Ca,b as desired.

4.2

Nonlocal games and MIP∗

Now, we augment Definitions 3.3 and 3.4 to allow for provers to share quantum resources.
Definition 4.5. Given a game G , a quantum strategy is one in which Alice and Bob are allowed
to share entanglement but not to communicate. We can model their behavior with the strategy
S = (ρ, A, B). Here,
◦ Write HA for Alice’s local Hilbert space and HB for Bob’s. Then ρ is a (possibly entangled)
state in L(HA ⊗ HB ).

◦ The set A contains a matrix Axa for each question x and answer a, with the guarantee that
for each question x, Ax := {Axa }a is a POVM. (Likewise for B.)

Alice and Bob perform their strategy as follows: given question x, Alice performs the POVM
{Axa }a and returns her measurement outcome to the verifier. Bob plays similarly. The value of
their strategy, denoted valG (S), is the probability that they pass the test, over the randomness in G
and in their measurement outcomes.
valG (S) =
=

E

Pr [AlgA (x0 , x1 , a0 , a1 ) = 1]

(x0 ,x1 )∼AlgQ a0 ,a1

E

(x0 ,x1 )∼AlgQ

X

a0 ,a1 ,
AlgA (x0 ,x1 ,a0 ,a1 )=1

27

x1
0
tr(Ax
a0 ⊗ Aa1 · ρ),

where in the first line, (a0 , a1 ) is the distribution on answers given questions x0 , x1 . We write
val(G ) for the infimum of valG (S) over all strategies S. We define value analogously for interactive
proofs.
We say that L ∈ MIP∗c,s if there is an quantum interactive proof G that decides it. This means
that the following three conditions are true.
◦ (Completeness) Suppose input ∈ L. Then there is a quantum strategy for G with value at
least c.
◦ (Soundness) Suppose input ∈
/ L. Then every quantum strategy for G has value at most s.
◦ All of Q-length(G ), A-length(G ), Q-time(G ), and A-time(G ) are poly(n).

If c − s is a constant, then we will suppress the dependence on them and just say that L ∈ MIP∗ .
Remark 4.6. A game G is symmetric if its distribution on questions treats Alice and Bob symmetrically. In this case, we may assume without loss of generality that Alice and Bob’s strategies
are also symmetric, i.e. that Axa = Bax for all questions x and answers a. This allows us to represent their measurements by a single set of matrices M (for which Max = Axa = Bax ). As a further
simplification, by applying Naimark’s dilation theorem to Alice and Bob’s strategy we can assume
that their shared state ψ is pure and their measurements are projectors.
Occasionally, it will be useful to speak of the distribution over measurement outcomes induced
by a strategy independently of any particular game. For this, we introduce the notion of a bipartite
correlation
Definition 4.7. Given a strategy S = (ρ, A, B), the bipartite correlation produced by it is the
function P (a, b|x, y) = tr(Axa ⊗ Byx · ρ).
If two strategies produce the same bipartite correlation, they have the same value for any game
they are used for. Naimark’s theorem (Theorem 4.1) implies for any strategy S, there exists a
strategy S ′ using only projective measurements that produces the same correlation:
Corollary 4.8 (Naimark’s theorem for strategies). Suppose {Ma } and {Nb } are two POVMs acting
on the A and B factors of a tensor Hilbert space HA ⊗ HB , respectively. Then for any Naimark
dilation of {Ma } given by projectors Ma′ and an auxiliary state |auxA i ∈ HauxA , and any Naimark
dilation of {Nb } given by projectors N′b and an auxiliary state |auxB i ∈ HauxB , it holds that for
any bipartite state |ψi ∈ HA ⊗ Hb , the post-measurement state after applying M ⊗ N to |ψi and
M ′ ⊗ N ′ to |ψi ⊗ |auxA i ⊗ |auxB i is the same:
p
p
p
p
Ma ⊗ Nb |ψi hψ| Ma ⊗ Nb = traux [(Ma′ ⊗Nb′ )(|ψi hψ|⊗|auxA i hauxA |⊗|auxB i hauxB |)(Ma′ ⊗Nb′ )].
Moreover, such dilations exist by Theorem 4.1. As a consequence, M, N and M ′ , N ′ induce the
same joint distribution over outcome probabilities:
hψ| Ma ⊗ Nb |ψi = (hψ| ⊗ |auxA i ⊗ |auxB i)Ma′ ⊗ Nb′ (|ψi ⊗ |auxA i ⊗ |auxB i).
Proof. The existence of such dilations follows immediately from Theorem 4.1. To deduce the equality of post-measurement states, we apply Equation (4) twice, and use the fact that the partial trace
composes, i.e. that traux [·] = trauxB [trauxA [·]].
traux [(Ma′ ⊗ Nb′ )(|ψi hψ| ⊗ |auxA i hauxA | ⊗ |auxB i hauxB |)(Ma′ ⊗ Nb′ )]
p
p
= trauxB [ Ma ⊗ I((I ⊗ Nb′ ) |ψi |auxA i hauxA | hψ| (I ⊗ Nb′ )) Ma ⊗ I]
p
p
p
p
= I ⊗ Nb Ma ⊗ I |ψi hψ| Ma ⊗ I I ⊗ Nb .
28

4.3

Pauli matrices and the EPR state

Over a finite field Fq with order q = pt for prime p, the single-qudit Pauli matrices are a set of unitary
matrices acting on Cq . Every Pauli matrix can be uniquely written as a product ω a X(x)Z(z), where
ω is the p-th root ω = e2π/p , and X(x) and Z(z) are the matrices
X
X
X(x) =
|j + xi hj| ,
Z(z) =
ω tr[zj] |ji hj| ,
(6)
j∈Fq

j∈Fq

where the arguments x, z are in Fq , tr : Fq → Fp is the finite field trace. The set of all Pauli matrices
form a group, known as the Pauli group or the Weyl-Heisenberg group. For the most part, in this
paper, it will suffice to consider only the group elements of the form ω a X(x) (“X-type” Paulis)
and Z(z) (“Z-type” Paulis). Elements of the form ω a X(x)Z(z) for x, z 6= 0 are sometimes called
“Y -type”.
The eigenvalues of X(x) and Z(z) for all x, z are powers of ω, as can be seen from the facts
X(x)p = Z(z)p = I. Any unitary with this property is known as a (generalized) observable. Every
generalized observable U induces a projective measurement with p outcomes, corresponding to the
p possible eigenvalues of U . As a convenient shorthand, we will refer to performing this projective
measurement as “measuring U .” In the case of of the X and Z operators, the eigenvectors |τuX i and
|τuZ i of X(1) and Z(1) are indexed by elements u of Fq , with eigenvalue tr[u]; thus, each eigenvalue
occurs with multiplicity q/p. Explicitly, they are given by
1 X −tr[uv]
ω
|vi ,
|τuZ i = |ui .
(7)
|τuX i = √
q
v∈Fq

We denote the projectors onto these eigenvectors by τuX and τuZ , respectively. These eigenvectors
are also the eigenvectors of the remaining X(x), Z(z) observables, as shown by the following fact.
Fact 4.9. For W ∈ {X, Z}, the observables W (v) are related to the projectors τuW by
X
W (v) =
ω tr[u·v] τuW

(8)

u

τuW = E ω −tr[u·v] W (v).
v

(9)

Proof. We start with Equation (8). For W = Z, the relation follows immediately from the definitions. For W = X, by calculation we have:
X
1 X tr[u·x] tr[u(v−v′ )] ′
ω
ω
|v i hv|
ω tr[u·x]τuX =
q
u
u,v,v′
X
′
=
E ω tr[u·(x+v−v )] |v ′ i hv|
v,v′

=

X
v

u

|v + xi hv|

= X(x),
where we have applied Fact 3.1 in passing from the second to the third line. Now we show
Equation (9):
X
X
ω tr[(a−u)·v] τaW = τuW ,
ω −tr[u·v] ω tr[v·a] τaW = E
E ω −tr[u·v] W (v) = E
v

v

v

a

a

where we first applied Equation (8) in the first equality, and then used Fact 3.1 to perform the
expectation over v.
29

The Pauli matrices obey the commutation relation
X(x)Z(z) = ω −tr[xz] Z(z)X(x).

(10)

This follows directly from Equation (6). It follows from this that all of the Pauli matrices (including
the Y -type matrices) are generalized observables.
The maximally entangled state, or EPR state, over qudits of dimension q is the state
1 X
|ui ⊗ |ui .
|EPRq i = √
q
u∈Fq

We will write |EPRnq i for |EPRq i⊗n . This state obeys the stabilizer relations
X(x) ⊗ X(x) |EPRq i = Z(z) ⊗ Z(−z) |EPRq i = |EPRq i
X
τuX ⊗ I |EPRq i = I ⊗ τ−u
|EPRq i

τuZ

⊗ I |EPRq i = I ⊗

τuZ

|EPRq i .

(11)
(12)
(13)

Relations (12) and (13) imply that measuring X(x) on both halves of an EPR state will yield two
outcomes a, b satisfying a = −b, and measuring Z(z) on both halves will yield two outcomes a, b
that are equal.
In the important special case of finite fields with characteristic 2 (i.e. Fq for even q), u = −u
for all u ∈ Fq , and thus measuring any of the X and Z operators on both sides of the state will
always yield the same outcome.

4.4

State dependent distances

In this section, we introduce two state-dependent distances. To motivate them, we first define the
consistency game, perhaps the simplest nontrivial two-player game.
Definition 4.10. The consistency game with question x, denoted Gcon (x) is defined as follows.
The question x is given to Alice and Bob, who respond with answers a and a′ , respectively. The
verifier accepts if a = a′ .
We will typically play the consistency game when x, rather than being a fixed question, is
drawn from some distribution. Our first state-dependent distance quantifies the players‘ success
probability in this case.
Definition 4.11. Let {Axa } and {Bax } be sets of matrices in L(HA ) and L(HB ), respectively. Let D
be a distribution on questions x and |ψi be a state in HA ⊗ HB . Consider the game in which the
verifier selects x ∼ D and then plays Gcon (x). We say that
Axa ⊗ IBob ≃δ IAlice ⊗ Bax
on state |ψi and distribution D if Alice and Bob win with probability 1 − O(δ) using the measurements A and B, respectively.
We will sometimes leave the state or distribution unspecified, as they are often clear from
context. This distance has a clear operational interpretation. Our second state-dependent distance,
defined next, is more analytic.

30

Definition 4.12. Let {Qxa } and {Rax } be sets of matrices in L(H). Let D be a distribution on the
variables x and |ψi be a state in H. Then we say that Qxa ≈δ Rax on state |ψi and distribution D if
X
x
2
E
k(Qx
a − Ra ) |ψi k = O(δ).
x∼D

a

As above, we will sometimes leave the state or distribution unspecified when clear from context.
This is sometimes referred to as the state-dependence distance, whereas our first distance measure
is often referred to as the “consistency”. A typical setting of parameters is H = HA ⊗ HB ,
Qxa := Axa ⊗ IBob , and Rax := IAlice ⊗ Bax . In this case, we have the following relationship between
the two state-dependent distances.
Fact 4.13. Let {Axa } and {Bax } be POVM measurements. The following two facts hold.
1. If Axa ⊗ IBob ≃δ IAlice ⊗ Bax then Axa ⊗ IBob ≈δ IAlice ⊗ Bax .

2. If Axa ⊗IBob ≈δ IAlice ⊗Bax and {Axa } and {Bax } are projective measurements, then Axa ⊗IBob ≃δ
IAlice ⊗ Bax .

Proof. Suppose that Axa ⊗ IBob ≃δ IAlice ⊗ Bax . This is equivalent to the statement
X
x
E
hψ| Ax
a ⊗ Ba |ψi ≥ 1 − O(δ).
x

As a result, using the fact that A and B are POVMs,
X
X
x
2
2
x 2
x
x
E
k(Ax
⊗
I
−
I
⊗
B
)
|ψi
k
=
E
hψ| ((Ax
a
a
a ) ⊗ I + I ⊗ (Ba ) − 2Aa ⊗ Ba ) |ψi
x

(14)

a

x

a

a

≤E
x

X
a

x
x
x
hψ| (Ax
a ⊗ I + I ⊗ Ba − 2Aa ⊗ Ba ) |ψi

= 2 − 2E
x

Axa

X
a

(15)

x
hψ| Ax
a ⊗ Ba |ψi .

⊗ IBob ≈δ IAlice ⊗ Bax . The reverse statement holds
By Equation (14), this is O(δ). As a result,
when A and B are projective measurements because Equation (15) is an equality in this case.
The following fact shows that we can derive a weaker converse in the case when only one of A
or B is projective.
Fact 4.14. Suppose {Axa } and {Bax } are two measurements such that Axa ⊗ IBob ≈δ IAlice ⊗ Bax .
Suppose further that either A or B is a projective measurement (and the other is a POVM measurement). Then Axa ⊗ IBob ≃δ1/2 IAlice ⊗ Bax .
Proof. Our goal is to upper bound the expression
X
x
1−E
hψ| Ax
a ⊗ Ba |ψi .
x

(16)

a

We begin
the number 1. Here we use the fact that because A is projective, (Axa )2 = Axa ,
P by rewriting
x
2
and so a (Aa ) = I. This gives us:
X
X
x
2
hψ| Ax
(16) = E
hψ| (Ax
a ⊗ Ba |ψi
a ) ⊗ IBob |ψi − E
x

=E
x

≤E
x

x

a

X
a

X
a

hψ| (Ax
a

⊗ IBob ) ·

(Ax
a

a

⊗ IBob − IAlice ⊗ Bax ) |ψi

x
x
kAx
a ⊗ IBob |ψi k · k(Aa ⊗ IBob − IAlice ⊗ Ba ) |ψi k

31

(17)

Now we apply Cauchy-Schwarz and then Jensen’s inequality:
s X
X
2
x
2
kAx
k(Ax
(17) ≤ E
a ⊗ IBob |ψi k ·
a ⊗ IBob − IAlice ⊗ Ba ) |ψi k
x

a

a

The first of these terms we bound by 1, and the second is O(δ) by assumption.
Remark 4.15. We note that the requirement in Fact 4.14 that one of the two measurements be
projective is necessary. Consider the measurements {Axa } and {Bax } with m separate outcomes a
in which Axa = Bax = I/m for all x and a. Then Axa ⊗ IBob ≈0 IAlice ⊗ Bax , but as m → ∞,
X
x
hψ| Ax
1−E
a ⊗ Ba |ψi → 1.
x

a

Thus, when one of the measurements is projective, the “≈δ ” distance is roughly equivalent to
the “≃δ ” distance, up to a polynomial factor (which we can tolerate losing in our proofs). More
generally, however, the “≈δ ” distance can be viewed as a weakening of the “≃δ ” distance. In spite
of this, we will spend much of the paper dealing with the “≈δ ” distance, as it is easier to manipulate
but still strong enough to reach our desired consequences. (See [Vid11, Section 2.3.1] for a further
defense of this distance.) We note that even when |ψi is a bipartite state, the “≈δ ” distance is
defined for matrices Q and R which are not necessarily tensor products over the bipartition. Such
matrices will often be useful to pass through during intermediate steps of our proofs.
A common use case for these distances is when the verifier (i) samples a pair of questions x =
(x0 , x1 ), (ii) hands x0 to Alice and x1 second to Bob, (iii) receives their answers a0 and a1 and
(iv) accepts if f (x, a0 ) = g(x, a1 ) for some functions f and g. Write {Axa00 }a0 and {Bax11 }a1 for
Alice and Bob’s measurements, respectively. We can view these as measurements which receive
the pair (x0 , x1 ) and simply ignore one coordinate. Suppose the verifier accepts with probability
1 − δ. Using Notation 4.3, we can view this as performing the consistency game between the
x1
measurements Ax[f0(x,a0 )=b] and B[f
(x,a1 )=b] . Hence, we can derive the following two facts:
x1
Ax[f0(x,a0 )=b] ⊗ IBob ≃δ IAlice ⊗ B[f
(x,a1 )=b] ,

and

x1
Ax[f0(x,a0 )=b] ⊗ IBob ≈δ IAlice ⊗ B[f
(x,a1 )=b] .

This generic format will be the most common use of these notations.
Remark 4.15 highlights the importance of projective measurements when dealing with the “≈δ ”
distance. This, and several other key facts about the “≈δ ” distance, are true only for projective
measurements. As a result, we will sometimes apply Naimark’s theorem (Theorem 4.1) during our
proofs to “round” POVM measurements into projective measurements. However, there is a subtlety
in doing so, namely that because Naimark’s theorem preserves measurement outcomes, any “≃δ ”
statements we have derived about our measurement operators will remain true, but Naimark’s
theorem is not guaranteed to preserve “≈δ ” statements. In this work, we will be able to dispense
with this subtlety and assume all “≈δ ” statements are preserved, because all “≈δ ” statements in
our proofs will be derived from “≃δ ” statements, and so they will remain true after performing
Naimark’s theorem, since we could simply rederive them.

4.5

Miscellaneous properties of the state-dependent distances

In this section, we record some facts about the “≈δ ” notation which we will use repeatedly throughout the paper. A good rule of thumb is that everything one expects to be true about the “≈δ ”
notation actually is true, except for those things which are not. As a result, we will be overly
pedantic in this section in order to call attention to these cases.
32

4.5.1

Simple state-dependent distance facts

Fact 4.16. For two vectors |ψ1 i , |ψ2 i, k |ψ1 i + |ψ2 i k2 ≤ 2k |ψ1 i k2 + 2k |ψ2 i k2 .
Fact 4.17. Let {Aa } be a measurement. Then
X
kAa |ψi k2 ≤ k |ψi k2 .
a

Proof. If {Aa } is a measurement, then
X
X
kAa |ψi k2 =
tr(Aa Aa |ψi hψ|) ≤ tr(I · |ψi hψ|) = k |ψi k2 .
a

a

Fact 4.18. Let {Aa }, {Ba } be measurements. Then for any state |ψi,
X
k(Aa − Ba ) |ψi k2 ≤ 4 · k |ψi k2 .
a

Proof. By Fact 4.16,
X
a

k(Aa − Ba ) |ψi k2 ≤ 2

X
a

kAa |ψi k2 + 2

X
a

kBa |ψi k2 .

The fact now follows from Fact 4.17.
Fact 4.19. Let {Axa } and {Bax } be POVM measurements. Then Axa ≈1 Bax .

P
Fact 4.20. Let {Axa } and {Bax } be matrices. Let {Cby } be matrices such that b (Cby )† Cby ≤ I for
all y. (This includes the case when {Cby } form projective or POVM measurements.) Then
Axa ≈δ Bax implies Cby Axa ≈δ Cby Bax .
Proof. Fix questions x, y and answers a. Because of our property on {Cby }b ,
X
X
k(Cby Axa − Cby Bax ) |ψi k2 =
hψ| (Axa − Bax )† (Cby )† (Cby )(Axa − Bax ) |ψi
b

b

≤ hψ| (Axa − Bax )† (Axa − Bax ) |ψi = k(Axa − Bax ) |ψi k2

We can therefore derive our desired conclusion:
X
X
y x
2
x
2
E
k(Cby Ax
k(Ax
a − Cb Ba ) |ψi k ≤ E
a − Ba ) |ψi k = δ.
x,y

x,y

a,b

a

Fact 4.21. Let D, D ′ be two distributions such that dTV (D, D ′ ) ≤ ǫ. Let {Axa } and {Bax } be
measurements, and suppose Axa ≈δ Bax with respect to D. Then Axa ≈δ+ǫ Bax with respect to D ′ .
Proof. By the definition of total variation distance, for any set of numbers {νx } satisfying 0 ≤ νx ≤
c, the expectations under the two distributions are similar:
| E [νx ] − E ′ [νx ]| ≤ c · ǫ.
x∼D

We will take for our numbers νx =
As a result,

P

x∼D

x
a k(Aa

− Bax ) |ψi k2 , which is always less than 4 by Fact 4.18.

E νx ≤ E νx + 4ǫ ≤ δ + 4ǫ.

x∼D ′

x∼D

This is O(δ + ǫ), which proves the fact.
33

Fact 4.22. Suppose Axa ≈δ Bax on state |ψi, and suppose k |ψi − |ψi k2 ≤ ǫ. Then Axa ≈δ+ǫ Bax on
state |ψi.

Proof. Applying Fact 4.16 to (Axa − Bax ) |ψi and (Axa − Bax )(|ψi − |ψi),
X
X
X
x
2
x
x
2
x
2
E
k(Ax
−
B
)
|ψi
k
≤
E
k(A
−
B
)
|ψi
k
+
E
k(Ax
a
a
a
a
a − Ba )(|ψi − |ψi)k .
x∼D

x∼D

a

x∼D

a

a

The first of these is bounded by O(δ) by the assumption, and the second of these is bounded by 4ǫ
by the assumption and Fact 4.18.

Fact 4.23. Suppose Axa1 ≈δ Bax1 with respect to a distribution Dmargin on x1 . Let D be a distribution
on (x1 , x2 ) such that the marginal distribution on x1 is Dmargin . Then Axa1 ≈δ Bax1 with respect
to D.
Proof. This is a simple calculation involving Notation 4.3.
Fact 4.24. Let k be a constant, and consider distributions over questions D1 , . . . , Dk . Let D be
a mixture of these distributions, meaning that there is a probability distribution p = (p1 , . . . , pk )
such that a draw from D can be simulated as follows: draw i ∼ p and output x sampled from Di .
Suppose Axa ≈δ Bax with respect to Di , for all i ∈ [k]. Then Axa ≈δ Bax with respect to D.
Proof. By definition, for each i ∈ [k] there is some constant Ci such that
X
2
x
k(Ax
E
a − Bb ) |ψi k ≤ Ck · δ.
x∼Di

a

Then we can bound the mixture with
X
X
x
2
x
2
k(Ax
E
k(Ax
a − Bb ) |ψi k ≤ E Ci · δ ≤ max{Ci } · δ = O(δ).
a − Bb ) |ψi k = E E
x∼D

i∼p x∼Di

a

i

i∼p

a

Fact 4.25. Suppose {Axa } is a projective
measurement and {Bax } is a set of matrices such that
P
x
x
each Bax is positive semidefinite
a Ba  I. Define Ca such that for each x, there exists an a
P and
′
x
x
x
such that Ca := Ba + (I − a′ Ba′ ) and for all other a 6= a, Cax′ := Bax′ . Thus, C x is a POVM for
each x. If Axa ≈ǫ Bax then Axa ≈ǫ1/2 Cax .
Proof. By Fact 4.16,
X
X
X
x
2
x
2
k(Ax
Bax ) |ψi k2 .
k(Ax
E
a − Ba ) |ψi k + 2 E k(I −
a − Ca ) |ψi k ≤ 2 E
x

x

a

x

a

a

The first of these terms we can bound by O(ǫ). As for the second,
X
X
X
E k(I −
Bax ) |ψi k2 = E hψ| (I −
Bax )2 |ψi ≤ E hψ| (I −
Bax ) |ψi
x

x

a

x

a

=1−E
x

P

a

X
a

hψ| Bax |ψi

≤1−E
x

X
a

hψ| (Bax )2 |ψi .

2
Now, we write 1 = Ex a hψ| (Ax
a ) |ψi, which holds because A is a projective measurement. We
bound the result as follows.
!
X
X
x
x
x
2
x 2
hψ| (Ax
hψ| ((Ax
E
a + Ba )(Aa − Ba ) |ψi
a ) − (Ba ) ) |ψi = ℜ E
x

a

x

a

≤E
x

s
X
a

34

x
2
k(Ax
a + Ba ) |ψi k ·

s

X
a

x
2
k(Ax
a − Ba ) |ψi k .

For each x, we can bound the first square root by O(1) due to Fact 4.16 and Fact 4.17. Having
done so, we can move the expectation into the second square root by Jensen’s inequality. The result
is O(ǫ1/2 ) by assumption. This proves the fact.
4.5.2

Data processing

In this section, we show a simple data processing inequality for the “≃δ ” distance. We also observe
that one does not hold for the “≈δ ” distance.
x
Fact 4.26. Suppose that Axa ⊗ IBob ≃δ IAlice ⊗ Bax . Then Ax[f (a)=b] ⊗ IBob ≃δ IAlice ⊗ B[f
(a)=b] .

Proof. Given question x, if Alice and Bob return a and a′ in which a = a′ , then f (a) = f (a′ ). As
a result, applying f to their answers cannot decrease the probability they agree.
Remark 4.27. We note that the same fact is not true for the “≈δ ” distance. Consider answers
of the form a = (b, i), where b ∈ {0, 1} and i ∈ [m]. Suppose Axb,i = I/(2m) for all a, whereas
x = I/m and B x = 0 for all i. Consider the function f (b, i) = b. It can be checked that in this
B0,i
1,i
x
case, Axa ⊗ IBob ≈1/2m IAlice ⊗ Bax but Ax[f (a)=b] ⊗ IBob ≈1/2 IAlice ⊗ B[f
(a)=b] .
4.5.3

Triangle inequalities

In this section, we give two triangle inequalities. Our first is for the state-dependent distance.
Fact 4.28 (Triangle inequality). Suppose Axa ≈δ Bax and Bax ≈ǫ Cax . Then Axa ≈δ+ǫ Cax .
Proof. Applying Fact 4.16 to (Axa − Bax ) |ψi and (Bax − Cax ) |ψi,
X
X
X
x
2
x
2
E
k(Ax
k(Ax
k(Bax − Cax ) |ψi k2
a − Ca ) |ψi k ≤ 2 E
a − Ba ) |ψi k + 2 E
x∼D

a

x∼D

x∼D

a

a

≤ 2(δ + ǫ).

Note that this does not show that if
Axa ⊗ IBob ≈δ IAlice ⊗ Bax

and Bax ⊗ IBob ≈δ IAlice ⊗ Cax

then Axa ⊗IBob ≈δ IAlice ⊗Cax . This would only follow if, for example, we also knew that Dax ⊗IBob ≈δ
IAlice ⊗Dax , for D equal to one of A, B, or C. We do, however, always have the following triangle-like
inequalities.
Fact 4.29 (Triangle-like inequalities). The following two facts are true.
1. Suppose Axa ⊗ IBob ≃δ IAlice ⊗ Bax , Bax ⊗ IBob ≃δ IAlice ⊗ Cax , and Cax ⊗ IBob ≃δ IAlice ⊗ Dax .
Then Axa ⊗ IBob ≃δ IAlice ⊗ Dax .
2. Suppose Axa ⊗ IBob ≈δ IAlice ⊗ Bax , Bax ⊗ IBob ≈δ IAlice ⊗ Cax , and Cax ⊗ IBob ≈δ IAlice ⊗ Dax .
Then Axa ⊗ IBob ≈δ IAlice ⊗ Dax .
Before proving this, we need the following fact from linear algebra.
Fact 4.30. Suppose 0  A, B, C, D  I. Then
1 − hψ| A ⊗ D |ψi ≤ (1 − hψ| A ⊗ B |ψi) + (1 − hψ| B ⊗ C |ψi) + (1 − hψ| C ⊗ D |ψi).
35

Proof. Rearranging, we want to show that
hψ| A ⊗ B |ψi + hψ| B ⊗ C |ψi + hψ| C ⊗ D |ψi − hψ| A ⊗ D |ψi ≤ 2.
Or, equivalently
tr(|ψi hψ| · (A ⊗ B + B ⊗ C + C ⊗ D − A ⊗ D)) ≤ 2.
The left-hand side is at most the maximum eigenvalue of A ⊗ B + B ⊗ C + C ⊗ D − A ⊗ D. To
bound this maximum eigenvalue, we note that A ⊗ B  A ⊗ I, B ⊗ C  I ⊗ I, and C ⊗ D  I ⊗ D.
As a result,
A ⊗ B + B ⊗ C + C ⊗ D − A ⊗ D  A ⊗ I + I ⊗ I + I ⊗ D − A ⊗ D.
Next, I ⊗ D − A ⊗ D = (I − A) ⊗ D  (I − A) ⊗ I because A  I. Thus,
A ⊗ I + I ⊗ I + I ⊗ D − A ⊗ D  A ⊗ I + I ⊗ I + (I − A) ⊗ I = 2 · I ⊗ I.
But the maximum eigenvalue of this is 2.
Now we prove Fact 4.29.
Proof of Fact 4.29. The second fact follows from several applications of Fact 4.28. As for the first
fact, we can write the consistency as
X
x
E
(1 − hψ| Ax
a ⊗ Da |ψi)
x

a

Applying Fact 4.30, this is at most
X
x
x
x
x
x
E
(1 − hψ| Ax
a ⊗ Ba |ψi) + (1 − hψ| Ba ⊗ Ca |ψi) + (1 − hψ| Ca ⊗ Da |ψi)
x

a

Averaging over questions and summing over answers, each of these terms is at most δ, by assumption.
4.5.4

Close strategies have close game values

In this section, we will show that two strategies which are close in state-dependent distance are also
close in value for any game G . We note crucially that one of the two strategies must be projective
to apply this fact.
Fact 4.31. Let D be a distribution on questions x, and for each x let acc(x) be a set of “accepting”
answers. Given a state ψ and a strategy {Axa } define
X
val(A) = E
hψ| Ax
a |ψi .
x∼D

a∈acc(x)

Suppose {Axa } and {Bax } are two strategies such that Axa ≈δ Bax on state ψ and distribution D.
Suppose further that either A or B is a projective measurement (and the other is a POVM measurement). Then
val(A) − O(δ1/2 ) ≤ val(B) ≤ val(A) + O(δ1/2 ).

36

Proof. Assume without loss of generality that A is a projective measurement and B is a POVM
measurement. We will prove the fact by showing the following stronger statement: for each x,
let S(x) be any set of answers a, and define
X
val(A, S) := E
hψ| Ax
a |ψi .
x

a∈S(x)

Then val(A, S) ≤ val(B, S) + O(δ1/2 ). By taking S(x) := acc(x) this implies the lower bound
val(A) − O(δ1/2 ) ≤ val(B), and by taking S(x) := rej(x), defined to be the set of answers not in
acc(x), then this implies the upper bound val(B) ≤ val(A) + O(δ1/2 ).
If we write |uxa i = Axa |ψi and |wax i = (Bax − Axa ) |ψi, then
kBax |ψi k2 = k |uxa i + |vax i k2 = k |uxa i k2 + k |wax i k2 + huxa | wax i + hwax | uxa i .

By definition,
val(B) = E
x

≥E
x

=E
x

=E
x

X

a∈S(x)

X

a∈S(x)

X

a∈S(x)

X

a∈S(x)

hψ| Bax |ψi
hψ| (Bax )2 |ψi

(because B is a POVM)

kBax |ψi k2
2
x
2
x
x
x
x
k |ux
a i k + k |wa i k + hua | wa i + hwa | ua i .

Averaging over questions and summing over answers, the first term is exactly val(A) because A is
projective. The second term is always nonnegative, so we lower bound it by zero. As for the last
two terms,
huxa | wax i + hwax | uxa i ≥ −2 · | huxa | wax i | ≥ −2 · kuxa k · kwax k.
(18)

Applying Cauchy-Schwarz, Jensen’s inequality, and Fact 4.17,
s X
s X
X
X
x
x k2 ·
x k2 ≤
kwax k2 .
kux
k
·
kw
k
≤
E
E
ku
kw
E
a
a
a
a
x

x

a∈S(x)

a∈S(x)

a∈S(x)

x

(19)

a∈S(x)

But the expectation inside the root is at most O(δ) because Axa ≈δ Bax . Combining Equations (18)
and (19) completes the proof.
We will typically, though not always, apply Fact 4.31 in the following special case.
Fact 4.32. Let G be a game whose questions (x1 , x2 ) ∼ G have marginal distribution x1 ∼ D.
Suppose {Axa } and {Bax } are measurements such that Axa ⊗I ≈δ Bax ⊗I on state ψ and distribution D.
Consider the strategies SA = {ψ, A} and SB = {ψ, B}. If either A or B is a projective measurement
(and the other is a POVM measurement), then
valG (SA ) − O(δ1/2 ) ≤ valG (SB ) ≤ valG (SA ) + O(δ1/2 ).
Proof. First, we observe that
Axa11 ⊗ Axa22 ≈δ Axa11 ⊗ Bax22 ≈δ Bax11 ⊗ Bax22

by Fact 4.20. The result follows by applying Fact 4.32 with “A” set to Axa11 ⊗ Axa22 , “B” set to
Bax11 ⊗ Bax22 , and “D” set to the distribution on (x1 , x2 ). We note that “val(A)” there is equal to
valG (SA ) here and “val(B)” there is equal to valG (SB ) here.
37

4.5.5

Generating new measurements

In this section, we show how to combine multiple measurements into a single measurement by
“sandwiching” them together.
Fact 4.33. Let k ≥ 0 be a constant. Let {Axa1 ,...,ak } be a projective measurement. For each
1 ≤ i ≤ k, let {(Bi )xai } be a projective measurement, and suppose that
(Axai )Alice ⊗ IBob ≃δ IAlice ⊗ ((Bi )xai )Bob .

(20)

Define the POVM measurement {Jgx1 ,...,gk } as
Jax1 ,...,ak := (Bk )xak · · · (B2 )xa2 · (B1 )xa1 · (B2 )xa2 · · · (Bk )xak .
Then
(Axa1 ,...,ak )Alice ⊗ IBob ≃δ1/2 IAlice ⊗ (Jax1 ,...,ak )Bob .
Proof. For each 1 ≤ i ≤ k, Equation (20) implies that
(Axai )Alice ⊗ IBob ≈δ IAlice ⊗ ((Bi )xai )Bob .
Now, we repeatedly apply this using Fact 4.20:
(Axa1 ,...,ak )Alice ⊗ IBob = (Axak · · · Axa2 · Axa1 · Axa2 · · · Axak )Alice ⊗ IBob

≈δ (Axak · · · Axa2 · Axa1 · Axa2 · · · Axak−1 )Alice ⊗ ((Bk )xak )Bob
···

≈δ IAlice ⊗ ((Bk )xak · · · (B2 )xa2
= IAlice ⊗ (Jax1 ,...,ak )Bob .

· (B1 )xa1 · (B2 )xa2 · · · (Bk )xak )Bob

The fact now follows from Fact 4.14 and the fact that A is a projective measurement.
Next, we extend Fact 4.33 to the case of polynomial measurements (see Section 4.7 below).
These are structured measurements in which the prover returns the evaluation of a function sampled
independently from their input. The goal is to retain this structure even after “sandwiching” them
together.
Fact 4.34. Let k ≥ 0 be a constant. Let D be a distribution on questions x ∈ X . For each
1 ≤ i ≤ k, let Gi be a set of functions gi : X → Ri . and let {Gig } be a projective measurement with
outcomes from this set. Suppose that the set Gi has the following distance property: for any two
nonequal gi , gi′ ∈ Gi , the probability that gi (x) = gi′ (x), over a random x ∼ D, is at most ǫ.
Let {Ag1 ,...,gk } be a projective measurement with outcomes gi ∈ Fi . For each 1 ≤ i ≤ k, suppose
that
(A[gi (x)=ai ] )Alice ⊗ IBob ≃δ IAlice ⊗ (Gi[gi (x)=ai ] )Bob .
(21)
Define the POVM measurement {Jg1 ,...,gk } as
Jg1 ,...,gk := Gkgk · · · G2g2 · G1g1 · G2g2 · · · Gkgk .
Then
(A[g1 (x),...,gk (x)=a1 ,...,ak ] )Alice ⊗ IBob ≃(δ+ǫ)1/2 IAlice ⊗ (J[g1 (x),...,gk (x)=a1 ,...,ak ] )Bob .
38

Proof. Let 1 ≤ i ≤ k. By Equation (21), if Alice measures with A, producing g i , and Bob measures
with Gi , producing g ′i , then the probability that g i (x) 6= g ′i (x) is O(δ). Write η for the probability
that g i 6= g′i . Then we have the expression η · (1 − ǫ) ≤ O(δ) or, equivalently, η ≤ O(δ/(1 − ǫ)).
When ǫ < 1/2, this gives the bound η ≤ O(δ), and when ǫ ≥ 1/2, we have the trivial bound
η ≤ O(ǫ). As a result, η = O(δ + ǫ).
In conclusion,
(Agi )Alice ⊗ IBob ≃δ+ǫ IAlice ⊗ (Gigi )Bob .
We can now apply Fact 4.33 to Ag1 ,...,gk and the Gigi measurements. It implies that
(Ag1 ,...,gk )Alice ⊗ IBob ≃(δ+ǫ)1/2 IAlice ⊗ (Jg1 ,...,gk )Bob .
The fact now follows from the data processing inequality Fact 4.26.
In our next fact, we show that Fact 4.34 holds even when we drop the structured assumption
on the A matrix. The tradeoff is that we must now assume that the k different measurements act
on different parts of the input string. In this case, the distance condition becomes slightly more
cumbersome to state.
Fact 4.35. Let k ≥ 0 be a constant. Let D be a distribution on questions (x, y1 , . . . , yk ), where
each yi ∈ Yi . For each 1 ≤ i ≤ k, let Gi be a set of functions gi : Yi → Ri . and let {(Gi )xg }
be a projective measurement with outcomes from this set. (For the i = 1 case, we also allow this
measurement to be a POVM.) Suppose that the set Gi has the following distance property: fix a
question z = (x, y1 , . . . , yi−1 , yi+1 , . . . , yk ), and let Dz be the distribution on yi conditioned on the
other outcomes z. Then for any two nonequal gi , gi′ ∈ Gi , the probability that gi (y i ) = gi′ (y i ), over
a random y i ∼ Dz , is at most ǫ.
1 ,...,yk
Let {Ax,y
a1 ,...,ak } be a projective measurement with outcomes gi ∈ Fi . For each 1 ≤ i ≤ k,
suppose that
1 ,...,yk
(Ax,y
)Alice ⊗ IBob ≃δ IAlice ⊗ ((Gi )x[gi (yi )=ai ] )Bob .
(22)
ai
Suppose also that
x,y1 ,...,yk
1 ,...,yk
(Ax,y
a1 ,...,ak )Alice ⊗ IBob ≃δ IAlice ⊗ (Aa1 ,...,ak )Bob .

(23)

Define the POVM measurement {Jgx1 ,...,gk } as

Jgx1 ,...,gk := (Gk )xgk · · · (G2 )xg2 · (G1 )xg1 · (G2 )xg2 · · · (Gk )xgk .
Then
x
1 ,...,yk
(Ax,y
a1 ,...,ak )Alice ⊗ IBob ≃poly(δ,ǫ) IAlice ⊗ (J[g1 (y1 ),...,gk (yk )=a1 ,...,ak ] )Bob .

Proof. First, we show how to reduce this to the k = 2 case. Then we prove it for that case. Assume
the fact holds when k = 2. Define the POVM measurement {(Ji )xg1 ,...,gi } as
(Ji )xg1 ,...,gi := (Gi )xgi · · · (G2 )xg2 · (G1 )xg1 · (G2 )xg2 · · · (Gi )xgi .
We will show by induction that
x
1 ,...,yk
(Ax,y
a1 ,...,ai )Alice ⊗ IBob ≃poly(δ,ǫ) IAlice ⊗ ((Ji )[g1 (y1 ),...,gi (yi )=a1 ,...,ai ] )Bob ,

(24)

the base case being trivial. Assume this holds for i. We apply the k = 2 case as follows: consider
the question tuple (y1 , . . . , yi ) as a single question and consider functions of the form (y1 , . . . , yi ) 7→
(g1 (y1 ), . . . , gi (yi )). Then the first POVM measurement is Ji , which satisfies Equation (22) due to
39

Equation (24). The second measurement is the projector Gi+1 . Then the k = 2 case immediately
implies the i + 1 case of Equation (24).
Now we prove the k = 2 case. Our goal is to show that
X
x,y ,y
x
x
(25)
hψ| (Aa1 ,g12 (y2 ) )Alice ⊗ ((G2 )x
E
g2 · (G1 )[g1 (y 1 )=a1 ] · (G2 )g2 )Bob |ψi
x,y 1 ,y 2

2

a1 ,g2

is at least 1 − poly(δ, ǫ). We will do this by showing that
((G1 )x[g1 (y1 )=a1 ] · (G2 )xg2 )Alice ⊗ IBob ≈poly(δ,ǫ) ((G2 )xg2 · (G1 )x[g1 (y1 )=a1 ] )Alice ⊗ IBob .

(26)

is at most poly(δ, ǫ). To see that this is sufficient, note that the related expression
X
x,y ,y
x
x
hψ| (Aa1 ,g12 (y2 ) )Alice ⊗ ((G2 )x
E
g2 · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] )Bob |ψi
x,y 1 ,y 2

2

a1 ,g2

is exactly equal to 1 because G2 is a projector. Taking the difference between this and Equation (25),
we get
X
x,y ,y
x
x
x
x
hψ| (Aa1 ,g12 (y2 ) )Alice ⊗ ((G2 )x
E
g2 · ((G1 )[g1 (y 1 )=a1 ] · (G2 )g2 − (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ))Bob |ψi .
x,y 1 ,y 2

2

a1 ,g2

Cauchy-Schwarz allows us to bound this by
≤

E

x,y 1 ,y 2

sX

a1 ,g2

x,y ,y

2
k(Aa1 ,g12 (y2 ) )Alice ⊗ ((G2 )x
g2 )Bob |ψi k
2

·

sX

a1 ,g2

kIAlice ⊗ ((G1 )x
[g1 (y

1 )=a1 ]

x
x
· (G2 )x
g2 − (G2 )g2 · (G1 )[g1 (y

1 )=a1 ]

)Bob |ψi k2 .

The expression inside the first square root is always at most 1. This allows us to bring the expectation into the second square root by Jensen’s inequality, and the resulting expression we can bound
due to Equation (26).
Now we bound Equation (26). Showing this is small is equivalent to showing
X
x
x
x
2
k((G1 )x
E
[g1 (y 1 )=a1 ] · (G2 )g2 − (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] )Alice ⊗ IBob |ψi k
x,y 1 ,y 2

a1 ,g2

is small. Expanding this, we get
X
x
x
x
hψ| (G2 )x
E
g2 · (G1 )[g1 (y 1 )=a1 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )g2 ⊗ IBob
x,y 1 ,y 2

a1 ,g2

x
x
x
+(G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob

x
x
x
−(G2 )x
g2 · (G1 )[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob


x
x
x
−(G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] · (G2 )g2 ⊗ IBob |ψi .

(27)

We do know that G1 and G2 satisfy some form of commutation. Because they satisfy Equation (22)
and A is a projector, we know that
((G1 )x[g1 (y1 )=a1 ] · (G2 )x[g2 (y2 )=a2 ] )Alice ⊗ IBob ≈δ ((G2 )x[g2 (y2 )=a2 ] · (G1 )x[g1 (y1 )=a1 ] )Alice ⊗ IBob .
40

Expanding this as above, we can bound the following expression by δ:
X
x
x
x
hψ| (G2 )x
E
[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] ⊗ IBob
x,y 1 ,y 2

a1 ,a2

x
x
x
+(G1 )x
[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] · (G2 )[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob

x
x
x
−(G2 )x
[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob


x
x
x
−(G1 )x
[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] ⊗ IBob |ψi .

(28)

We can therefore show Equation (27) is small by upper-bounding (Equation (27)−Equation (28)).
There are four terms in this difference; write ∆i for the i-th term in Equation (27) minus the i-th
term in Equation (28). We will bound each ∆i one-by-one.
The first term in the difference, ∆1 , is
E

x,y 1 ,y 2

−

XX
g2

a1

E

x,y 1 ,y 2

x
x
x
hψ| (G2 )x
g2 · (G1 )[g1 (y 1 )=a1 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )g2 ⊗ IBob |ψi

X

a1 ,a2

x
x
x
hψ| (G2 )x
[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] ⊗ IBob |ψi .

The first of these terms is at most 1, and so we just have to show that the second term is close to 1
as well. Note that by repeated applications of Equation (22), we have that
x,y ,y

x
x
x
1 2
(G2 )x
[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] · (G1 )[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] ⊗ IBob ≈δ IAlice ⊗ Aa1 ,a2 .

But then by Fact 4.31, the expression we want to lower-bound is O(δ1/2 )-close to
X
x,y ,y
hψ| IAlice ⊗ Aa1 ,a12 2 |ψi ,
E
x,y 1 ,y 2

a1 ,a2

which is exactly 1. As a result, ∆1 is at most O(δ1/2 ).
The second term in the difference, ∆2 , can be written as
X
X
x
x
x
− E
hψ| ((G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G2 )g ′ · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob ) |ψi .
x,y 1 ,y 2

a1

2

g2 6=g2′ ,
g2 (y 2 )=g2′ (y 2 )

This is zero because G2 is a projector.
The third and fourth terms in Equation (27) are complex conjugates of each other, as are the
third and fourth terms in Equation (28). As a result, it suffices to bound the magnitude of ∆4 , and
this will serve to bound ∆3 as well. We begin by manipulating the fourth term in Equation (27);
specifically, we will show that it is close to
X
x
x
x
hψ| (G1 )x
(29)
− E
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ (G2 )g2 |ψi .
x,y 1 ,y 2

a1 ,g2

To do so, we take their difference:
E

x,y 1 ,y 2

X

a1 ,g2

x
x
hψ| ((G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ IBob )
x
· (IAlice ⊗ (G2 )x
g2 − (G2 )g2 ⊗ IBob ) |ψi .

41

To bound the magnitude, we apply Cauchy-Schwarz:
E

x,y 1 ,y 2

sX

a1 ,g1

k((G1 )x
[g1 (y
·

x
· (G2 )x
g2 · (G1 )[g1 (y

1 )=a1 ]

sX

a1 ,g1

k((G1 )x
[g1 (y

1 )=a1 ]

1 )=a1 ]

⊗ IBob ) |ψi k2

x
2
⊗ IBob ) · (IAlice ⊗ (G2 )x
g2 − (G2 )g2 ⊗ IBob ) |ψi k .

The expression inside the first square root is always at most 1. This allows us to bring the expectation into the second square root by Jensen’s inequality. Because G1 is a POVM, we can bound
the resulting expectation by
X
x
2
k(IAlice ⊗ (G2 )x
(30)
E
g2 − (G2 )g2 ⊗ IBob ) |ψi k .
x,y 1 ,y 2

g1

To bound this, we note that Equations (22) and (23) along with Fact 4.29 imply that
(G2 )x[g2 (y2 )=a2 ] ⊗ IBob ≃δ IBob ⊗ (G2 )x[g2 (y2 )=a2 ] .
Using the distance properties of G2 , this implies that
(G2 )xg2 ⊗ IBob ≃δ+ǫ IBob ⊗ (G2 )xg2 .
Hence, Equation (30) is at most O((δ + ǫ)1/2 ). A similar argument shows that the fourth term in
Equation (28) is O(δ1/2 )-close to
X
x
x
x
hψ| (G1 )x
(31)
− E
[g1 (y 1 )=a1 ] · (G2 )[g2 (y 2 )=a2 ] · (G1 )[g1 (y 1 )=a1 ] ⊗ (G2 )[g2 (y 2 )=a2 ] |ψi .
x,y 1 ,y 2

a1 ,a2

Now, we compute Equation (29) minus Equation (31):
X
X
x
x
x
E
hψ| (G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ (G2 )g ′ |ψi
x,y 1 ,y 2

=

E

x,y 1 ,y 2

a1

2

g2 ,g2′
g2 (y 2 )6=g2′ (y 2 )

XX

a1 g2 ,g2′

x
x
x
′
hψ| (G1 )x
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ (G2 )g ′ |ψi · 1(g2 , g2 , y 2 ),
2

where 1(g2 , g2′ , y 2 ) is the indicator that g2 6= g2′ but g2 (y 2 ) = g2′ (y 2 ). This is the only part of the
expression that depends on y 2 , and by our distance assumption it is at most ǫ in expectation. Since
the rest of the expression is guaranteed to be positive, we can upper-bound this by
XX
x
x
x
hψ| (G1 )x
E
[g1 (y 1 )=a1 ] · (G2 )g2 · (G1 )[g1 (y 1 )=a1 ] ⊗ (G2 )g ′ |ψi · ǫ.
x,y 1

2

a1 g2 ,g2′

But the remaining part of the expression is at most 1, and so in total we can upper-bound it by ǫ.
This completes the proof.

42

4.6

Commuting EPR strategies

In this section, we introduce a class of strategies important for our proof.
Definition 4.36. A strategy S = (ψ, M ) is called an EPR strategy if it satisfies the following two
properties. First, there is an integer k and powers of two q1 , . . . , qk such that
|ψi = |EPRq1 i ⊗ |EPRq2 i ⊗ · · · ⊗ |EPRqk i .
Second, for each question x, M x is a projective measurement. If for all questions x and answers a,
Max is a real-valued matrix, we say that the strategy is real
In addition, given a game G , we say that a real EPR strategy S is a real commuting EPR strategy
(with respect to G ) if for every (x1 , x2 ) in the support of S and every a1 , a2 , Max11 commutes with
Max22 . We denote the set of real commuting EPR strategies by ComEPR(G ).
Real commuting EPR strategies are motivated by the completeness cases that arise in this work.
We give a series of transformations which modify games to make them sound against increasingly
broader sets of strategies. Unfortunately, these transformations are not complete for all strategies,
in the sense that value-1 strategies may be mapped to value-less-than-1 strategies, but we will be
careful to ensure that they are complete for all commuting EPR strategies. For the majority of the
paper, the one property of commuting EPR strategies that we will use, not shared by all value-1
strategies, is the following.
Fact 4.37. Let (ψ, M ) be a real EPR strategy. Then Max ⊗IBob ≃0 IAlice ⊗Max for every distribution
on x.
Proof. From the definition of EPR strategies, we know that |ψi = |EPRq1 i ⊗ . . . ⊗ |EPRqk i ∈
(Cq1 ·q2 ·····qk )⊗2 . We may choose a basis {|ii : 1 ≤ i ≤ q1 · q2 · · · · · qk } for Cq1 ·····qk , so that
X
|ψi =
|iiAlice ⊗ |iiBob .
i

P
Let us denote the components of Max by the notation (Max )ij , so that Max = ij (Max )ij |ii hj|.
Now, for an arbitrary pair x, a, we can compute the post-measurement states from applying Max
on Alice’s and Bob’s systems.
X
Max ⊗ IBob |ψi = (Max ⊗ IBob )
|iiAlice ⊗ |iiBob
i

X
=
(Max )ij |ii ⊗ |ji
ij

X
=
(Max )ji |ii ⊗ |ji
ij

= (IAlice ⊗ Max ) |ψi ,

where in going from the second to the third line, we have used the fact that Max is real and
Hermitian, and thus symmetric.
The following fact is a useful special case.
Fact 4.38. Let n > 0, q = 2t , and W ∈ {X, Z}. Then τuW ⊗ I ≈0 I ⊗ τuW on the state |EPRnq i.
43

Proof. By Equation (7), we can write
1 X −tr[uv]
ω
|vi ,
|τuX i = √
q

|τuZ i = |ui .

v∈Fq

The second of these self-evidently has real-valued coefficients. As for the first, q = 2t implies that
p = 2. This means that ω = −1 and tr[uv] ∈ {0, 1} for all u, v. As a result, it too has real-valued
coefficients. The fact then follows from Fact 4.37.
This property of real commuting strategies is useful for answer reduction because it allows us to
perform oracularization, giving one prover both questions x1 and x2 so that they may simulate the
action of both provers by simultaneously measuring M x1 and M x2 . For more details, see Part V.

4.7

Quantum soundness of the classical low-degree test

An important tool for quantum protocols is a version of the Raz-Safra theorem (Theorem 3.12) in
which the soundness of the low-degree test is extended to hold even in the case when the provers are
allowed to share entanglement. For the plane-versus-point test, this was first developed by Vidick
in [Vid16], but for technical reasons he could only show it for the case of three or more quantum
provers. In [NV18b], this was improved to hold for the two-prover case, and this is the result we
use in this work. We begin by defining the class of polynomial measurements.
Definition 4.39. Define PolyMeas(m, d, q) to be the set of POVM measurements whose outcomes
correspond to degree-d, Fq -valued polynomials. In other words, G ∈ PolyMeas(m, d, q) if G = {Gg }g
with outcomes degree-d polynomials g : Fm
q → Fq . More generally, we let PolyMeas(m, d, q, ℓ) be
the set of measurements G = {Gg1 ,...,gℓ } outputting ℓ degree-d polynomials gi : Fm
q → Fq .
The following theorem establishes the quantum soundness of the classical low-degree test in the
k = 2 case.
Theorem 4.40 (Quantum soundness of the classical low-degree test [NV18b, Theorem 2]). There
exists a constant c > 0 and a function δ(ǫ) = poly(ǫ, dm/q c ) such that the following holds. Suppose
Alice and Bob are entangled provers who pass GSurface (m, d, q, 2) with probability at least 1 − ǫ using
the strategy (ψ, M ), where M consists of projective measurements. Then there exists a POVM
measurement G ∈ PolyMeas(m, d, q) such that
Mbw ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b] ,

Gg ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gg ,

where the first is on the uniform distribution over Fm
q .
Remark 4.41. The statement of Theorem 4.40 is modified from how it appears in [NV18b, Theorem 2] to better suit our needs. In this remark, we show how to derive our version from theirs,
which is stated as follows.
◦ There exists a constant c > 0 and a function δ(ǫ) = poly(ǫ) such that the following holds. Suppose q ≥ (dm/ǫ)c . Then if Alice and Bob pass the surface-versus-point test with probability
1 − ǫ, there is a measurement G ∈ PolyMeas(m, d, q) such that
X
X X
hψ| Mfs ⊗ Gg |ψi ≤ δ(ǫ),
hψ| Gg ⊗ (I − Gg ) |ψi ≤ δ(ǫ).
(32)
E
s

g

g f 6=g|s

44

These are equivalent to the statements
Mfs ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|s =f ] ,

Gg ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gg ,

where the first is on the uniform distribution over surface in Fm
q . The second of these matches the
corresponding statement above. Next, by Fact 4.26 we derive
M[fs (w)=b] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b]

and

G[g(w)=b] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b] .

with respect to the distribution (s, w) from GSurface (m, d, q, 2). On top of that, since the strategy
passes the test with probability 1 − ǫ,
Mbw ⊗ IBob ≃ǫ IAlice ⊗ M[fs (w)=b]
As a result, if we use Fact 4.13 to switch these to “≈δ ” statements, then
Mbw ⊗ IBob ≈ǫ IAlice ⊗ M[fs (w)=b] ≈δ(ǫ) G[g(w)=b] ⊗ IBob ≈δ(ǫ) IAlice ⊗ G[g(w)=b] .
The result now follows from the triangle inequality (Fact 4.28) followed by Fact 4.14 and the fact
that M was assumed to be projective.
Finally, we remove the condition on q using a trick from [NV18a]. If q < (dm/ǫ)c , then we select
′
ǫ > ǫ such that q = (dm/ǫ′ )c . Alice and Bob also pass the plane-versus-point test with probability
1 − ǫ′ because 1 − ǫ′ < 1 − ǫ, and so we can apply the theorem with these parameters, giving
a robustness of δ(ǫ′ ) = δ(dm/q 1/c ). (In the case when ǫ′ > 1, which is not allowed, this bound
trivially still holds because dm/q 1/c > 1.) In general, then, we can remove the condition on q so
long as we replace the robustness of poly(ǫ) with poly(ǫ, dm/q 1/c ), which holds in both cases.
We will use the following proposition about polynomial measurements several times.
Proposition 4.42. Let d > 0 be an integer. Consider a distribution D on pairs (s, u), where s
s
is a subspace in Fm
q and u is a uniformly random point in s. Let {Mf } be a measurement whose
outcomes are degree-d polynomials f : s → Fq , and let G ∈ PolyMeas(m, d, q). Suppose that
M[fs (u)=b] ⊗ IBob ≃δ IAlice ⊗ G[g(u)=b]
with respect to D. Then

Mfs ⊗ IBob ≃δ+d/q IAlice ⊗ G[g|s =f ]

with respect to D.
Proof. Suppose the verifier (i) samples (s, u) ∼ D, (ii) gives Alice s, who measures with M s and
returns her outcome f : s → Fq , (iii) receives g : Fm
q → Fq from Bob, sampled via G, and (iv)
accepts if f (u) = g(u). Then by assumption, the verifier accepts with probability at least 1 − O(δ).
We can use this to bound the probability that f and g disagree on the subspace s. By SchwartzZippel (Lemma 3.6), conditioned on f and g disagreeing, the probability they disagree on a random
point u ∼ s is at least 1 − d/q. This gives us the inequality Pr[f 6= g|s ] · (1 − d/q) ≤ O(δ). Now,
assume first that q ≥ 2d. Then this bound implies, via Fact 4.13, that
Mfs ⊗ IBob ≈δ+d/q IAlice ⊗ G[g|s =f ] .

(33)

On the other hand, when q ≥ 2d, then this bound is also true for trivial reasons. This is because
we can pick δ(·) such that δ(ǫ) ≥ 1 in this case.
45

4.8

Quantum soundness of the classical simultaneous low-degree test

We would now like to use Theorem 4.40 to show quantum soundness for the simultaneous classical
low-degree test. This will be done using the same reduction presented in Section 3.6. The main
result is the following.
Theorem 4.43 (Quantum soundness of the simultaneous classical low-degree test). There exists
a constant c > 0 and a function δ(ǫ) = poly(ǫ, d(m + ℓ)/q c ) such that the following holds. Suppose
ℓ
Alice and Bob are entangled provers who pass GSurface
(m, d, q, 2) with probability at least 1 − ǫ using
the strategy (ψ, M ), where M consists of projective measurements. Then there exists a measurement
G ∈ PolyMeas(m, d, q, ℓ) such that
Mbw1 ,...,bℓ ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g1 (w),...,gℓ (w)=b1 ,...,bℓ ] ,

Gg1 ,...,gℓ ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gg1 ,...,gℓ ,

where the first is on the uniform distribution over Fm
q .
ℓ
(m, d, q, 2) with probability at least 1 − ǫ. We will
Proof. Suppose Alice and Bob pass GSurface
use them to simulate two provers, “Combined Alice” and “Combined Bob”, who pass the singlefunction low-degree test GSurface (ℓ + m, d + 1, q, 2) with probability at least 1 − ǫ. They are specified
as follows:

◦ Combined Alice: Given s ⊆ Fqℓ+m , draw s′ ∼2 sproj . Give it to Alice, who responds with
f 1 , . . . , f ℓ : s′ → Fq . Output the function combinef |s .
◦ Combined Bob: Given (x, y) ∈ Fqℓ+m , compute y ∈ Fm
q . Give it to Bob, who responds with
b1 , . . . , bℓ ∈ Fq . Return combineb (x) ∈ Fq .
ℓ
(m, d, q, 2). Using our
By Proposition 3.15, s′ and y are distributed as the questions in GSurface
assumption on Alice and Bob, this means that f 1 (y) = b1 , . . . , f ℓ (y) = bℓ with probability
at least 1 − ǫ. As a result, (combinef |s )(x, y) = combineb (y) with probability at least 1 − ǫ.
By Proposition 3.16, combinef |s is a degree-(d + 1) function on s, and so it is a valid response
to subspace queries. This means Combined Alice and Bob pass GSurface (ℓ + m, d + 1, q, 2) with
probability at least 1 − ǫ.
Thus, we can apply Theorem 4.40. It gives a measurement G ∈ PolyMeas(ℓ + m, d + 1, q) such
that
y
M[combine
⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(x,y)=ν] ,
Gg ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gg ,
(34)
b (x)=ν]

where δ(ǫ) = poly(ǫ, (d + 1)(ℓ + m)/q c ). This means that if we give Alice y and she returns b, and
Bob simply returns g, then combineb (x) = g(x, y) with probability at least 1 − δ(ǫ).
We would like to show that g is exactly linear in x with high probability, over the randomness
in the measurement G. Let us condition on a g which is not exactly linear. By Proposition 3.18,
the probability that g|y is not exactly linear is at least 1 − (d + 1)/q. On the other hand, because
combineb (x) is always exactly linear by construction, the probability that g|y (x) = combineb (x)
is at most (d + 1)/q by Schwartz-Zippel (Lemma 3.6). As a result, the probability that g(x, y) =
combineb (x) is at most (d + 1)/q + (d + 1)/q. Thus, if we write µlinear for the probability that g is
exactly linear, we have equality at most µlinear + 2(d + 1)/q fraction of the time. Rearranging, g is
exactly linear with probability
µlinear ≥ 1 − 2δ(ǫ) − 2(d + 1)/q.
Define a new measurement {Hg1 ,...,gℓ } ∈ PolyMeas(m, d, q, ℓ) operationally
as follows: first, meaP
sure G and receive g. If it is exactly linear, it can be written as
i xi · g i (y), and so output
46

g 1 , . . . , g ℓ . If g is not exactly linear, output any arbitrary degree-d polynomials instead. When g is
exactly linear, we have combineg1 ,...,gℓ (x, y) = g(x, y). Since this happens with probability at least
1 − δ(ǫ), we can replace G with H in Equation (34), yielding
y
⊗ IBob ≃δ(ǫ) IAlice ⊗ H[combineg (x,y)=ν] ,
M[combine
b (x)=ν]

(35)

On the other hand, because H is just G with data processing applied to its output, we can apply
Fact 4.26 to Equation (34). This produces the equation
Hg1 ,...,gℓ ⊗ IBob ≃δ(ǫ) IAlice ⊗ Hg1 ,...,gℓ .
Consider g 1 , . . . , g ℓ drawn by Bob using H. For any fixed b and y, if it is not the case that g1 (y) =
b1 , . . . , gℓ (y) = bℓ , then the probability that combineg (x, y) = combineb (x) over a random x is at
most 1/q by Schwartz-Zippel, since both are exactly linear functions. Thus, if Alice draws b1 , . . . , bℓ
given y, and we write η for the probability that g 1 (y) = b1 , . . . , g ℓ (y) = bℓ , then the probability
that combineg (x, y) = combineb (x) is at most η + (1 − η) · 1/q. Combined with Equation (35), this
implies that
Pr[g 1 (y) = b1 , . . . , g ℓ (y) = bℓ ] ≥ 1 − δ(ǫ) − 1/q.

Or, equivalently,

4.9

Mby1 ,...,bℓ ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g1 (y),...,gℓ (y)=b1 ,...,bℓ ] .

Self-testing

The games presented in Sections 4.7 and 4.8 might be referred to as “measurement testers”: if a
strategy passes them with high probability, then we can extract some property on its measurements.
In this section, we will introduce a significantly stronger notion of testing called self-testing. A selftester is a game in which if a prover passes with high probability, then not only do we do exactly
which measurements the prover must be performing, we also know which exactly state it must be
performing them on (up to local isometry). (We note that some works use “self-testing” to refer
both to “measurement testing” and what we refer to as “self-testing” [NV18a]. In this work, we
will reserve the term exclusively for the latter.) We begin with a definition.
Definition 4.44. We say that S = (ψ, M ) is a partial strategy for G if M contains the POVM M x
for only a subset of the questions in G . We call this set of questions S’s question set. A strategy
S ′ = (ψ, M ′ ) extends S if (M ′ )x = M x for every x in S’s question set.
Next, we define self-testing.
Definition 4.45 (Self-testing). Let S = (ψ, G) be a partial strategy and D be a distribution over
its question set. A game G is a self-test for S over D with robustness δ(ǫ) if it satisfies the following
two conditions.
◦ Completeness: There exists a (full) strategy Sfull consistent with S which passes G with
probability 1.
◦ Soundness: Let S = (ψ, M ) be a strategy which passes G with probability 1 − ǫ. Then there
exists a local isometry φ = φlocal ⊗ φlocal and a state |auxi such that
kφ |ψi − |ψi |auxi k2 ≤ δ(ǫ).

x

Furthermore, if we define the new matrices Max := φlocal · M a · (φlocal )† , then
Max ⊗ IBob ≈δ(ǫ) (Gxa ⊗ Iaux ) ⊗ IBob ,

on states |ψi |auxi and |ψ ′ i and distribution x ∼ D.
47

(36)

We note that this definition of self-testing differs in several key places from the one given in
[NV18a, Definition 2.5]. We will explain these differences in more detail when we cite the quantum
low-degree test in Section 6.

Part III

Implementing the registers
5

Register overview

In this part, we implement the quantum registers. Our goal is force Alice and Bob to share a state
of the following form:
r1

r2

···

rk−1

rk

⊗

aux

,

in which each register ri contains an EPR state, and aux is a symmetric auxiliary state. In addition,
we want the verifier to be able to (i) force the provers to perform Pauli basis queries on some of these
registers and report back the outcomes and (ii) “hide” the remaining registers from the provers so
that they do not measure them at all.

5.1

Definitions

In this section, we will begin by defining quantum registers for nonuniform games. Defining registers
for uniform games G is a little more complicated because we allow the number and size of registers
for G (input) to depend on input. We detail this below in Section 5.3.
Definition 5.1. Let k ≥ 0 be an integer, and let n = (n1 , . . . , nk ) and q = (q1 , . . . , qk ) be k-tuples
of integers. A (k, n, q)-register game G is defined as follows.
◦ Questions x are formatted into two blocks x = (x1 , x2 ). The first block contains a list of k
Pauli basis queries x1 = (W1 , . . . , Wk ), where each Wi ∈ {X, Z, H, ⊥}.

◦ Answers a are formatted into two blocks a = (a1 , a2 ). The first block contains a list of answers
to the Pauli basis queries a1 = (u1 , . . . , uk ). Here each ui ∈ Fnqii ∪ {∅}.

An (k, n, q)-register strategy S is defined as follows.
◦ Alice and Bob share a state
|ψi = |r1 i ⊗ · · · ⊗ |rk i ⊗ |auxi .
Here, |ri i = |EPRnqii i for each i, and |auxi is an arbitrary symmetric shared state.

◦ Given a question x = (x1 , x2 ) with first block x1 = (W1 , . . . , Wk ), Alice and Bob act as
follows. Let i ∈ [k].
– If Wi ∈ {X, Z}, they measure τ W on the i-th EPR register and set ui to be the outcome.
– If Wi ∈ {H, ⊥}, they set ui = ∅.

Introduce the notation τ∅W = I for W ∈ {H, ⊥}. We can write their measurement as
Max11 ,x2 = τuW1 1 ⊗ · · · ⊗ τuWk k ⊗ Iaux .
48

(37)

To produce the second part of their answer a2 , Alice and Bob can measure any part of their
state except the EPR registers which have been “hidden”. This entails the following: let
S = {i | Wi = H}. Then for any answer a, the corresponding POVM acts as follows:
Max = MS ⊗ IS .

(38)

Here, IS is the identity matrix on the EPR registers in S, whereas MS is a POVM acting on
the EPR registers in S as well as the state |auxi.
We define valk,n,q (G ) to be the maximum over valG (S), where S is any (k, n, q)-register strategy.
The X and Z questions specify the corresponding Pauli basis measurement, and the H question
specifies that the register is to be hidden. The ⊥ question is a “no-op” and does not restrict Alice
and Bob at all, other than making them respond with the “no-op” answer ∅. Thus, unlike with the
data hiding question, they are allowed to measure the register as they see fit. This will be useful
later when we want Alice and Bob to measure both X and Z observables on the same register.
In designing our compiler, it will be convenient to define a set of strategies called “semiregister
strategies”. These will be strategies which are intermediate between (k − 1)-register strategies and
k-register strategies in the sense that they have Pauli basis queries implemented on the final (k-th)
register but not data hiding queries. These are defined as follows.
Definition 5.2. A (k, n, q)-semiregister strategy is defined just as a (k, n, q)-register strategy, with
the following modification: the set S used in Equation (38) is changed to be S = {i 6= k | Wi = H}.
We define valsemi
k,n,q (G ) to be the maximum over valG (S), where S is any (k, n, q)-semiregister strategy.
Thus, querying the k-th register of a semiregister strategy with a H is the same as querying it with
a ⊥.
The following lemma shows that we can restrict to projective register strategies without loss of
generality.
Lemma 5.3. Let S be a (k, n, q)-register strategy. Then there exists a (k, n, q)-register strategy S ′
in which all measurements are projective, and which produces the same bipartite correlation as S.
,x2
Proof. Start with the strategy S, and let the measurements be denoted Max11,a
2 . From the definition
of register strategies, we know that for every set of questions x1 , x2 , the corresponding measurement
can be written as a product
Wx
Max11,a,x22 = (τa1 1 )S ⊗ (Axa21 ,x2 ,a1 )S ,

where S is the set of registers which receive a Pauli basis query in the set X, Z, H, S is its complement, and the operators {Axa21 ,x2 ,a1 } form valid POVMs with outcomes a2 for every choice of
x1 , x2 , a1 . We will apply Naimark’s theorem Theorem 4.1 using the universal auxiliary state |auxi
to the A operator to produce projectors Aa′x21 ,x2 ,a1 . Using these, we define a projective measurement
Wx

1 ,x2 ,a1
Ma′x11,a,x2 2 = (τa1 1 )S ⊗ (A′x
)S .
a2

It is not hard to see that M ′ and |auxi form a valid Naimark dilation of M . Let S ′ be the strategy
S with the shared state |ψi replaced by |ψi ⊗ |auxA i ⊗ |auxB i and the measurements M replaced
by M ′ . By construction, S ′ is a projective strategy. Further, from Corollary 4.8, it follows that the
bipartite correlations produced by the strategies S ′ and S are the same.

49

5.2

Results

The key elements of our compiler are two new nonlocal games called the Pauli basis test and the
data hiding game. The Pauli basis test ensures that the provers share an EPR state and honestly
answer Pauli basis queries to this state. The data hiding game allows us to “hide” this state from
the provers, ensuring that they do not use this register unless we ask them to.
Our compiler operates a register at a time and involves two subroutines, Ck→semi and Csemi→k−1 .
Given a k-register game, Ck→semi produces a k-semiregister game. To do so, it removes the guarantee
that the provers data hide the k-th register and replaces it by playing the data hiding game on this
register. Thus, although the provers are no longer forced to hide the k-th register, they will have
to do so anyway if they want to pass the data hiding game. Similarly, given a k-semiregister game,
Csemi→k−1 produces a (k − 1)-register game. To do so, it removes the guarantee that the provers
have a k-th EPR register and replaces it by playing the Pauli basis test. Thus, by alternating these
two subroutines, we can compile a k-register game into a 0-register game, i.e. a general game.
Before giving the properties of the Pauli basis compiler, we will need two definitions.
Definition 5.4. Given a string x = (x1 , . . . , xk ) and an integer 0 ≤ ℓ ≤ k, write x|ℓ := (x1 , . . . , xℓ ).
We extend this to register parameters τ = (k, n, q) by setting τ |ℓ := (ℓ, n|ℓ , q|ℓ ). Thus, τ |ℓ is the
register parameters for the first ℓ registers of τ .
Definition 5.5. Let n and q be integers and η be a real number. We say they satisfy the Pauli
basis condition if
q = 2t ,

1
1
≤η≤ ,
poly(n)
2

64 log(n)2
≤ q ≤ poly(n).
η2

The following theorem describes the Pauli basis compiler.
Theorem 5.6. Let λ = (k, n, q), and let nk , qk , and η satisfy the Pauli basis condition. Suppose
Gsemi is a λ-semiregister game, and consider the λ|k−1 -register game Gk−1 = Csemi→(k−1) (Gsemi ).
◦ Completeness: Suppose there is a value-1 λ-semiregister strategy for Gsemi which is also a
real commuting EPR strategy. Then there is a value-1 λ|k−1 -register strategy for Gk−1 which
is also a real commuting EPR strategy.
◦ Soundness: If valλ|k−1 (Gk−1 ) ≥ 1 − ǫ then valsemi
(Gsemi ) ≥ 1 − δ(ǫ), where δ(ǫ) = poly(ǫ, η).
λ
Furthermore,
Q-time(Gk−1 ) = Q-time(Gsemi ) + O(log(nk )),
Q-length(Gk−1 ) = Q-length(Gsemi ) + O(log(nk )),
A-time(Gk−1 ) = A-time(Gsemi ) + poly(nk ),
A-length(Gk−1 ) = A-length(Gsemi ) + O(nk · log log(nk )).
The following theorem describes the data hiding compiler.
Theorem 5.7. Suppose Gk is a (k, n, q)-register game, and consider the (k, n, q)-semiregister game
Gsemi = Ck→semi (Gk ).
◦ Completeness: Suppose there is a value-1 (k, n, q)-register strategy for Gk which is also a
real commuting EPR strategy. Then there is a value-1 (k, n, q)-semiregister strategy for Gsemi
which is also a real commuting EPR strategy.
50

◦ Soundness: If valsemi
k,n,q (Gsemi ) ≥ 1 − ǫ then valk,n,q (Gk ) ≥ 1 − δ(ǫ), where δ(ǫ) = poly(ǫ).
Furthermore,
Q-time(Gsemi ) = O(Q-time(Gk )),

A-time(Gsemi ) = O(A-time(Gk )),

Q-length(Gsemi ) = O(Q-length(Gk )),

A-length(Gsemi ) = O(A-length(Gk )).

Combining Theorems 5.6 and 5.7 gives us the main result of Part III, a compiler C which
compiles k-register games into general games.
Theorem 5.8. Let Gk be a (k, n, q)-register game. Let η = (η1 , . . . , ηk ), and suppose ni , qi , and ηi
pass the Pauli basis condition for all i ∈ [k]. Write
G = C(Gk ) := Csemi→0 (C1→semi ( · · · Csemi→k−1 (Ck→semi (Gk )))).
◦ Completeness: Suppose there is a value-1 (k, n, q)-register strategy for Gk which is also
a real commuting EPR strategy. Then there is a real commuting EPR strategy for G with
value 1.
◦ Soundness: If val(G ) ≥ 1 − ǫ then val(k,n,q) (Gk ) ≥ 1 − δ(ǫ), where δ(ǫ) = poly(ǫ, η1 , . . . , ηk ).
Furthermore,
Q-time(G ) = Q-time(Gk ) + O(log(n1 )) + · · · + O(log(nk )),

Q-length(G ) = Q-length(Gk ) + O(log(n1 )) + · · · + O(log(nk )),
A-time(G ) = A-time(Gk ) + poly(n1 ) + · · · + poly(nk ),

A-length(G ) = A-length(Gk ) + O(n1 · log log(n1 )) + · · · O(nk · log log(nk )).

5.3

Registers for uniform games

In this section, we generalize the notion of registers to the case of uniform games, in which a
different set of register parameters might be used for each input. To compile these games, we will
need for the register parameters themselves to be uniformly generated.
Definition 5.9. Let MParams be a Turing machine which, given an input input, outputs λ = (k, n, q).
Let G be a (nonuniform) game. Then we say MParams outputs the register parameters of G if for
every input, G (input) is a MParams (input)-register game.
Given this, our compiler for uniform games is given as follows.
Corollary 5.10. Let G (·) be a (uniform) game, and let MParams be a Turing machine which
outputs its register parameters. Then there exists a (uniform) game GCompile (·) with the following
properties. Given an input input, write G := G (input), GCompile := GCompile (input), and λ =
(k, n, q) := MParams (input).
◦ Completeness: Suppose there is a value-1 (k, n, q)-register strategy for G which is also a
real commuting EPR strategy. Then there is a real commuting EPR strategy for GCompile with
value 1.
◦ Soundness: Let η = (η1 , . . . , ηk ), and suppose ni , qi , and ηi pass the Pauli basis condition
for all i ∈ [k]. If val(GCompile ) ≥ 1−ǫ then valλ (G ) ≥ 1−δ(ǫ), where δ(ǫ) = poly(ǫ, η1 , . . . , ηk ).
51

Furthermore,
Q-time(G ) = Q-time(Gk ) + O(log(n1 )) + · · · + O(log(nk )) + time(MParams (input)),

Q-length(G ) = Q-length(Gk ) + O(log(n1 )) + · · · + O(log(nk )),

A-time(G ) = A-time(Gk ) + poly(n1 ) + · · · + poly(nk ) + time(MParams (input)),

A-length(G ) = A-length(Gk ) + O(n1 · log log(n1 )) + · · · O(nk · log log(nk )).

Proof. We first compute λ = MParams (input) in time time(MParams (input)). Then it can be checked
that the compiled game C(G (input)) from Theorem 5.8 can be efficiently simulated given the register
parameters λ.

5.4

Organization

The remainder of Part III is organized as follows.
• In Section 6, we introduce the Pauli basis self-test and prove its correctness.
• Section 7 implements the Pauli basis compiler.
• In Section 8, we introduce the data hiding game.
• Section 9 implements the data hiding compiler.
• Section 10 contains a generalization of the data hiding game which allows us to hide more
general sets of Pauli observables. This is not needed to implement the quantum registers, but
it will be needed in Part IV when designing the NEEXP protocol.

6

A self test for the Pauli basis

In this section, we give a self test for the Pauli basis measurement. Given W ∈ {X, Z}, this test
compels the prover to measure an EPR register in the W basis and return the outcome to the
verifier.
Definition 6.1. The Pauli basis strategy with parameters n and q (a prime power), denoted
Pauli(n, q), is the partial strategy with the state |EPRnq i and measurement matrices τuW for each
W ∈ {X, Z}, u ∈ Fnq .
The main result of this section is the following self-test for the case when q is a power of 2.
Theorem 6.2. Let W ∼ {X, Z} uniformly at random. Let n, q, η satisfy the Pauli basis condition. Then there is a self-test Gbasis := Gbasis (n, q) for Pauli(n, q) over W with robustness
δ(ǫ) = poly(ǫ, η). Moreover, there is a value-1 real commuting EPR strategy with auxiliary state
|EPR2 i. Finally,
Q-length(Gbasis ) = O (log(n)) ,
Q-time(Gbasis ) = O (log(n)) ,

A-length(Gbasis ) = poly(n),
A-time(Gbasis ) = poly(n).

We prove this by a straightforward reduction to the quantum low-degree test of [NV18a].

52

6.1

The quantum low-degree test

The goal of the quantum low-degree test of [NV18a] is to force the provers to use a “compressed”
version of the Pauli basis strategy. Given W , they should measure their register in the W basis,
receiving u ∈ Fnq . However, u, a length-n string, might be prohibitively expensive to communicate
to the verifier, so they should instead compute the low degree encoding gu and return its evaluation
at a single point w ∈ Fm
q of the verifier’s choosing. (The point of this section is to “uncompress”
their protocol.)
Definition 6.3. Fix parameters for the low-degree encoding params := (q = pt , h, H, m, n, π)
satisfying the “low-degree conditions” h ≤ q, and n ≤ hm . For any string u ∈ Fnq , these parameters
give a low-degree encoding gu : Fm
q → Fq .
The low-degree Pauli strategy with parameters params, denoted LD(params), is the partial strategy with state |EPRnq i and measurement matrices
τaW,w := τ[gWu (w)=a] =

X

τuW

u:gu (w)=a

for each W ∈ {X, Z}, w ∈ Fm
q , a ∈ Fq . Equivalently, this is the strategy where we perform the
Pauli W -basis measurement and output the low-degree encoding of the outcome u evaluated at the
point w, i.e. the value gu (w).
The main result of [NV18a] is the following.
Theorem 6.4 ([NV18a, Theorem 3.2]). Fix low-degree parameters params with p = 2 (so that
q = 2t ) and m ≥ 2, and let D be the uniform distribution over (W, w) with W ∈ {X, Z}, w ∈ Fm
q .
Then there is a self-test GQlowdeg := GQlowdeg (params) for LD(params) over D with robustness
δ(ǫ) = poly(ǫ, md/q c ), with c > 0. Moreover, there is a value-1 real commuting EPR strategy with
auxiliary state |EPR2 i. Finally,
Q-length(GQlowdeg ) = O(m log q),
Q-time(GQlowdeg ) = O(m log q),

A-length(GQlowdeg ) = O(d2 log(q)),
A-time(GQlowdeg ) = poly(m, d, log q).

(We note that this result is stated in [NV18a] for general primes p. However, the p 6= 2 case
relied on a self-testing result for a generalization of the Magic Square game which was recently
discovered to contain a bug. Fortunately, the p = 2 case needs only a self-testing result for the
“traditional” binary Magic Square game, and this follows from [WBMS16].)
Remark 6.5. We note that the quantum low-degree test, as stated in [NV18a], does not have
value-1 real commuting EPR strategies. This is because it uses as a subroutine the standard magic
square game, and the magic square game does not have value-1 real commuting EPR strategies.
Its value-1 strategies are EPR strategies, and they are real (all observables are either X or Z, with
the sole exception of the Y ⊗ Y observable, which can be rewritten as Y ⊗ Y = −(X ⊗ X) · (Z ⊗ Z),
manifestly real). But they are not commuting, because each row and column have at least one pair
of noncommuting observables.
Consider instead the following “oracularized” version of the magic square game: one player is
given a random row or column (and is expected to play as in the normal magic square game), and
the other player is given a random cell in that row or column, and the verifier simply checks that
they agree on that cell. In addition, with some constant probability, both players are given the
same cell and their answers are checked against each other. In this case, all observables measured
53

With probability

1
2

each, perform one of the following two tests.

1. Low-degree: Perform GQlowdeg (params).
2. Cross-check: Draw W ∼ {X, Z}, w ∼ Fm
q . Flip an unbiased coin b ∼ {0, 1}. Distribute
the questions as follows:
◦ Player b: Give W ; receive u ∈ Fnq .
◦ Player b: give (W , w); receive a.
Accept if gu (w) = a.
Figure 1: The game Gbasis (n, q).
are commuting, and so this variant has a value-1 real commuting EPR strategy. In addition, it
certifies the same state and measurements as the normal magic square game, and so we can use it
as a subroutine in the quantum low-degree test instead.
Remark 6.6. We note again that the soundness case in our definition of a self-test is quite different
from the one given in [NV18a, Definition 2.5], and it is not clear that a self-test in their sense implies
a self-test in our sense. However, for the quantum low-degree test, their soundness case does match
ours. By [NV18a, Lemma 4.1], there is a local isometry φ = φ1 ⊗ φ2 such that
kφ |ψi − |ψi |auxi k2 ≤ δ(ǫ).

and
E

(W ,w)

X
a

W ,w

kφ · (M a

⊗ IBob ) |ψi − (τaW ,w ⊗ Iaux ) ⊗ IBob |ψi |auxi k2 ≤ δ(ǫ).

(39)
(40)

The key difference from our self-test definition is that, as stated, their local isometry need not
be symmetric (i.e. φ1 6= φ2 ), but their construction actually does give a symmetric isometry with
φ1 = φ2 . Then, from Equation (40) it is easy to derive Equation (36) using Equation (40) and the
triangle inequality (Fact 4.28).

6.2

Proof of Theorem 6.2: the Pauli basis test

We now state the Pauli basis test.
Definition 6.7. Let n, q, η be as in Theorem 6.2. Fix the remaining low-degree parameters params
as follows:


log(n)
1/2
h = ⌈q ⌉,
m=2·
,
d = m · (h − 1).
log(q)

Then the Pauli basis game Gbasis (n, q) is given by Figure 1.

These parameters are chosen so that they are valid low-degree parameters (guaranteeing the
existence of the low-degree code), which is necessary for the quantum low-degree test. In particular,
these satisfy (i) h ≤ q and (ii) n ≤ hm . The first of these is immediate; as for the second,
hm ≥ (q 1/2 )2·log(n)/ log(q) = q log(n)/ log(q) = n.

In addition, the code has relative distance d/q ≤ mh/q ≤ η.
m · (h − 1)
mh
log(n) q 1/2
8 log(n)
d
≤ η,
=
≤
≤8·
·
≤
q
q
q
log(q)
q
q 1/2
54

where the final step is because n, q, η satisfy the Pauli basis condition. Finally, we note that even if q
is a large polynomial of n, m is always at least 2, which permits us to use the quantum low-degree
test. We now prove Theorem 6.2.
Proof of Theorem 6.2. The question lengths and times of both the quantum low-degree test and
the cross-check are given by


log(n)
· log(q) = O(log(n)).
m log(q) = 2 ·
log(q)
As for the answer lengths and times, these are bounded by poly(n) for both the quantum low-degree
test and the cross-check. We now consider the completeness and soundness cases separately.
Completeness. Let (ψ, M ) be the value-1 commuting EPR strategy for the quantum low-degree
test guaranteed by Theorem 6.4. This has state |ψi = |EPRnq i |EPR2 i and measurement matrices
MaW,w = τaW,w ⊗ Iaux . If we add in the measurement matrices MuW = τuW ⊗ Iaux , then this strategy
passes the cross-check with probability 1. This is because after Player b measures u, the state
collapses to |τuW i |τuW i |EPR2 i, and so Player b will measure a = gu (w). As a result, this is a value1 strategy. Furthermore, it is a commuting EPR strategy because the cross-check measurements
M W and M W,w commute. Finally, this strategy extends the Pauli basis strategy. This proves the
completeness case.
Soundness. Throughout the soundness, we will use δ(ǫ) to denote a function of the form poly(ǫ, η)
which may change from use to use. The δ(ǫ) in Theorem 6.4 is of this form because d/q ≤ η.
Let S = (ψ, M ) be a strategy with valGbasis (S) = 1 − ǫ. Then this strategy must pass GQlowdeg
with probability at least 1 − 2ǫ. By Theorem 6.4 this gives us a local isometry φ = φlocal ⊗ φlocal
and a state |auxi with the following properties: if we define the new strategy S in which |ψi = φ |ψi
x
and Max = φlocal · M a · φ†local , then
k |ψi − |EPRnq i |auxi k2 ≤ δ(ǫ),

MaW,w ⊗ IBob ≈δ(ǫ) (τaW,w ⊗ Iaux ) ⊗ IBob ,

(41)

on state |ψi and distribution D. Because S is just a rotated version of S, it also passes Gbasis with
probability 1−ǫ. As a result, S passes the cross-check in Section 6.2 with probability at least 1−2ǫ.
By Fact 4.13, we conclude that
M[gWu (w)=a] ⊗ IBob ≈ǫ IAlice ⊗ MaW,w ≈δ(ǫ) IAlice ⊗ (τaW,w ⊗ Iaux ) = IAlice ⊗ (τ[gWv (w)=a] ⊗ Iaux )

(42)

on state |ψi. By Fact 4.14 and the fact that the τ measurements are projective, this implies that
M[gWu (w)=a] ⊗ IBob ≃δ(ǫ) IAlice ⊗ (τ[gWv (w)=a] ⊗ Iaux )
Now by Proposition 4.42 (where we let s be the singleton distribution on the “trivial” subspace
s = Fm
q ) and the fact that d/q ≤ η, we can conclude that
MuW ⊗ IBob ≃δ(ǫ) IAlice ⊗ (τuW ⊗ Iaux ).
Applying Fact 4.13 again, this yields
MuW ⊗ IBob ≈δ(ǫ) IAlice ⊗ (τuW ⊗ Iaux ) ≈δ(ǫ) (τuW ⊗ Iaux ) ⊗ IBob

(43)

on state |ψi, where the last step uses Fact 4.22 to combine Fact 4.38 with Equation (41). The
analogous statement for the state |EPRnq i follows from Fact 4.22. This establishes the theorem.
55

Flip an unbiased coin b ∼ {0, 1}. With probability

1
4

each, perform one of the following four tests.

1. Pauli basis: Draw (x, x′ ) ∼ Gbasis (nk , qk , η). Distribute the questions as follows:
◦ Player b: give (H k−1 , x); receive a = (a1 , a2 ).

◦ Player b: give (H k−1 , x′ ); receive a′ = (a′1 , a′2 ).

Accept if a2 and a′2 are accepting answers to the Pauli basis test.
2. Cross-check: Draw (x, x′ ) ∼ Gsemi . Write x = (x1 , x2 ) with x1 = (W 1 , . . . , W k ). Distribute the questions as follows:
◦ Player b: give x; receive a = (a1 , a2 ), where a1 = (u1 , . . . , uk ).

◦ Player b: give (H k−1 , W k ); receive strings a′1 = (u′1 , . . . , u′k ), u′i ∈ Fnq .
If W k ∈ {X, Z}, accept if uk = u′k . Otherwise, accept if uk = ∅.
3. Consistency check: Draw (x, x′ ) ∼ Gsemi . Distribute the questions as follows:
◦ Player b: give x; receive a

◦ Player b: give x; receive a′ .
Accept if a = a′ .
4. Play game: Perform Gsemi .
Figure 2: The game Csemi→(k−1) (Gsemi ).

7

Compiling games with the Pauli basis test

In this section, we show how to use the Pauli basis test to implement the compiler Csemi→(k−1) . Our
construction is given in the following definition.
Definition 7.1. Let Gsemi be a (k, n, q)-semiregister game. Then its compiled version is the game
Csemi→(k−1) (Gsemi ) defined in Figure 2.
In words, the provers might try to “trick” the verifier by using one of their (k − 1) existing EPR
registers to answer queries meant for the new k-th register. To prevent this, the verifier performs
the Pauli basis test with the first k − 1 registers hidden, forcing the provers to introduce a new
EPR register. It then cross-checks the provers’ answers in the Pauli basis test with their answers
in the game Gsemi . The performance of the compiler is given by the following theorem.
Theorem 7.2. Let λ = (k, n, q), and let nk , qk , and η satisfy the Pauli basis condition. Suppose
Gsemi is a λ-semiregister game, and consider the λ|k−1 -register game Gk−1 = Csemi→(k−1) (Gsemi ).
◦ Completeness: Suppose there is a value-1 λ-semiregister strategy for Gsemi which is also a
real commuting EPR strategy. Then there is a value-1 λ|k−1 -register strategy for Gk−1 which
is also a real commuting EPR strategy.
◦ Soundness: If valλ|k−1 (Gk−1 ) ≥ 1 − ǫ then valsemi
(Gsemi ) ≥ 1 − δ(ǫ), where δ(ǫ) = poly(ǫ, η).
λ

56

Furthermore,
Q-length(Gk−1 ) = Q-length(Gsemi ) + O(log(n)),
Q-time(Gk−1 ) = Q-time(Gsemi ) + O(log(n)),
A-length(Gk−1 ) = A-length(Gsemi ) + poly(n),
A-time(Gk−1 ) = A-time(Gsemi ) + poly(n).
Proof. The communication and time complexities are the result of combining the communication
and time complexities from Gsemi with the values for the Pauli basis test from Theorem 6.2.
Completeness. Let (ψ, M ) be a value-1 λ-semiregister strategy for Gsemi which is also a real
commuting EPR strategy. Then |ψi = |r1 i · · · |rk i |auxi, where each |ri i = |EPRnqii i and |auxi is
an EPR state. In addition, let (ψ ′ , M ′ ) be the value-1 real commuting EPR strategy for Gbasis
guaranteed by Theorem 6.2. Then |ψ ′ i = |EPRnqkk i |aux′ i, where |aux′ i is an EPR state.
Consider the following strategy for Gk−1 . For its state, it uses |r1 i · · · |rk i |auxi |aux′ i. For
inputs drawn from Gsemi , it uses the matrices in M applied to all but the |aux′ i register. For inputs
of the form (H k−1 , x), where x is sampled from Gbasis , it outputs ∅k−1 along with the result of
applying M ′ to |rk i and |aux′ i. Finally, for inputs of the form (H k−1 , H) and (H k−1 , ⊥), it outputs
∅k . This forms a valid λ|k−1 -register strategy for Gk−1 . In addition, its “auxiliary register” is
|rk i |auxi |aux′ i, which is an EPR state. Now we show that it has value 1.
By construction, this strategy passes the Pauli basis test and Gsemi with probability 1. As for the
cross-check, when W k ∈ {H, ⊥}, the strategy always succeeds because (ψ, M ) is a λ-semiregister
strategy. On the other hand, when W k ∈ {X, Z}, this implies that uk is the result of applying the
τ W k measurement to |rk i, putting it in state |τuWk k i |τuWk k i. But then because (ψ ′ , M ′ ) implements
the Pauli basis strategy on |rk i, the outcome u′k is also the result of applying the τ W k measurement
to |rk i. As a result, u′k = uk .
Finally, it is clear that this forms an EPR strategy. As a result, by Fact 4.37, the consistency
check passes with probability 1. Thus, the strategy passes the overall test with probability 1. Next,
we show that this gives a commuting EPR strategy. For the questions that arise in the Pauli basis
test, the consistency check, and Gsemi , commutation follows because M and M ′ are commuting.
As for the cross-check, consider the case when W k ∈ {X, Z}. Then the first (i.e. Player b’s)
measurement is given by
,x2
2
(Max11,a
)
⊗ Iaux′ = τuWk k ⊗ (Aux11,x
,...,uk−1 ,a2 )1,...,k−1,aux,aux′ ,
2 1,...,k,aux

where A is some measurement. This follows because M is a λ-semiregister strategy. Similarly, the
second (i.e., Player b’s) measurement is given by
k
(τ∅H ⊗ · · · ⊗ τ∅H )1,...,k−1 ⊗ (Mu′W
)k,aux′ ⊗ Iaux = τuW′ k ⊗ I1,...,k−1,aux,aux′ .
′
k

k

By inspection, these two commute. On the other hand, when W k ∈ {H, ⊥}, then Player b always
outputs ∅k . Their measurement for this outcome is the matrix I1,...,k,aux,aux′ , and is the zero matrix
for every other outcome. These clearly commute with any strategy for Player b.
Finally, because M and M ′ are real strategies, this strategy is also real. As a result, this gives
a value-1 real commuting EPR strategy.
Soundness. Suppose Sreg = (ψreg , Mreg ) is a λ|k−1 -register strategy for Gk−1 with value 1 − ǫ.
By Lemma 5.3, we can assume without loss of generality that M is projective. For 1 ≤ i ≤ k, write
|ri i := |EPRnqii i. By definition, |ψreg i = |r1 i ⊗ · · · ⊗ |rk−1 i ⊗ |auxreg i. Our goal will be to decode
Sreg into a λ-semiregister strategy Ssemi for Gsemi with nearly the same value.
57

Using the Pauli basis test. Passing the overall test with probability 1 − ǫ means that Sreg
must pass the test in Item 1 with probability 1 − 4ǫ. This test only involves measurements of the
form {(Mreg )H,...,H,x
}a1 ,a2 . Because the first k − 1 coordinates are hidden, Equation (38) allows us
a1 ,a2
to write
(Mreg )H,...,H,x
= I1,...,k−1 ⊗ (Axa2 )aux ,
a2
where {Axa }x is some set of measurements. As a result, the state |auxreg i and measurements {Axa }x
form a strategy for the game Gbasis (nk , qk , η) which succeeds with probability 1−4ǫ. By Theorem 6.2
this gives us a local isometry φ = φlocal ⊗ φlocal and a state |auxi such that
kφ |auxreg i − |rk i |auxi k2 ≤ δ(ǫ),

(44)

†
W
(φlocal · AW
u · φlocal )Alice ⊗ IBob ≈δ(ǫ) (τu ⊗ Iaux )Alice ⊗ IBob ,

(45)

on state |rk i |auxi and the uniform distribution on {X, Z}.
Define the new strategy S in which |ψi = |r1 i ⊗ · · · ⊗ |rk−1 i ⊗ (φ |auxreg i) and
Max = (I1,...,k−1 ⊗ (φlocal )aux ) · (Mreg )xa · (I1,...,k−1 ⊗ (φ†local )aux ).
Then Equations (44) and (45) implies that
k |ψi − |r1 i ⊗ · · · ⊗ |rk i |auxi k2 ≤ δ(ǫ),

(46)

(MuH,...,H,W )Alice ⊗ IBob ≈δ(ǫ) (I1,...,k−1 ⊗ τuW ⊗ Iaux )Alice ⊗ IBob ,

(47)

on state |ψi and the uniform distribution on {X, Z}. Because S is just a rotated version of Sreg , it
also passes Gk−1 with probability 1 − ǫ. In addition, it is also a λ|k−1 -register strategy.
Performing the cross-check. To analyze the cross-check, we begin with a definition. Given
W ∈ {X, Z, H, ⊥} and u ∈ Fnqkk ∪ {∅}, define nullW (u) = u if W ∈ {X, Z} and ∅ otherwise. The
cross-check in Item 2 checks equality between uk and nullW k (u′k ). As a result,
H,...,H,Wk
)Bob .
(Muxk )Alice ⊗ IBob ≈ǫ IAlice ⊗ (M[null
′
W (u )=u ]
k

k

k

Next, we note that when Wk ∈ {H, ⊥},
H,...,H,Wk
= I1,...,k−1 ⊗ τuWk k ⊗ Iaux ,
M[null
′
W (u )=u ]
k

k

k

because both sides are the identity when uk = ∅ and zero otherwise. On the other hand, when
Wk ∈ {X, Z}, these two are close due to Equation (47). Applying Fact 4.24 and Fact 4.28, we get
(Muxk )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (I1,...,k−1 ⊗ τuWk k ⊗ Iaux )Bob ,

(48)

where we have also applied Fact 4.13 to switch to the “≃δ(ǫ) ” notation.
Extracting a strategy. Now we use this to define a λ-semiregister strategy Ssemi for Gsemi . This
strategy will have state |ψsemi i = |r1 i · · · |rk i |auxi. In addition, for each input x = (x1 , x2 ) and
output a = (a1 , a2 ), it will have a matrix
x1 ,x2
,x2
Λax11,a
:= (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ) · M(u
· (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ).
2
1 ,...,uk−1 ),a2

58

First, it follows from M being a λ|k−1 -strategy that this is indeed a λ-semiregister strategy. This
is because
,x2
Λxa11 ,x2 = (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ) · Mux11,...,u
· (I1,...,k−1 ⊗ τuWk k ⊗ Iaux )
k−1
W

k−1
= (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ) · (τuW1 1 ⊗ · · · ⊗ τuk−1
⊗ Ik,aux ) · (I1,...,k−1 ⊗ τuWk k ⊗ Iaux )

= τuW1 1 ⊗ · · · ⊗ τuWk k ⊗ Iaux .

In addition, if S = {i 6= k | Wi = H}, then
,x2
Λax11,a
= (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ) · (IS ⊗ AS ) · (I1,...,k−1 ⊗ τuWk k ⊗ Iaux ) = IS ⊗ AS′ ,
2

where A and A′ are matrices acting on the registers not in S and on the auxiliary register.
Next, we show that this has good value. Write D for the marginal distribution of questions
given to player 1 in Gsemi . By the consistency check,
x1 ,x2
x1 ,x2
(M(u
)Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (M(u
)Bob
1 ,...,uk−1 ),a2
1 ,...,uk−1 ),a2

with respect to D. As a result, Equation (48) and Fact 4.33 imply that
(Λxa )Alice ⊗ IBob ≈δ(ǫ) IAlice ⊗ (Max )Bob ≈δ(ǫ) (Max )Alice ⊗ IBob ,
where the last step uses the self-consistency of M . Applying Fact 4.32, Ssemi passes Gsemi with
probability at least valGk−1 (S) − δ(ǫ). Thus, valsemi
(Gsemi ) ≥ 1 − δ(ǫ), and we are done.
λ

8

The data hiding game

In this section, we introduce a new, simple game called the data hiding game. This game assumes
two (k, n, q)-semiregister provers with a shared state |r1 i · · · |rk i |auxi. The goal is to test that a
given measurement {Max }a acts as the identity on the k-th register.
Definition 8.1. Let x = (x1 , x2 ) with x1 = (W1 , . . . , Wk ), and suppose Wk = H. Then the data
hiding game Ghide := Ghide (x) is given by Figure 3. It has the following parameters:
P
Q-time(Ghide ), Q-length(Ghide ) = O(|x|), A-time(Ghide ), A-length(Ghide ) = O( i ni log(qi ) + ℓ).

Here ℓ is the maximum of |a2 |, |a′2 | over all answers a2 and a′2 given by the provers.

Draw W ∼ {X, Z}. Set x′ = (x′1 , x2 ), where x′1 = (W1 , . . . , Wk−1 , W ). Flip an unbiased coin
b ∼ {0, 1}. Distribute the questions as follows:
◦ Player b: give x; receive (a1 , a2 ).
◦ Player b: give x′ ; receive (a′1 , a′2 ).
Accept if a2 = a′2 .
Figure 3: The game Ghide (x), with input x = (x1 , x2 )
For a measurement {Ma }a which operates on multiple subsystems, it will be convenient to
define a version of the measurement in which one of the subsystems is “hidden”.
59

Notation 8.2. Let M be a matrix which operates on H1 ⊗ · · · ⊗ Hk ⊗ Haux , and let i ∈ [k]. Define
the notation
1
· Ii ⊗ tri (M ).
hidei (M ) :=
tr(Ii )
If {Ma }a is a measurement, then so is {hidek (Ma )}a (though it may not be projective, even if
{Ma }a is). Our main result regarding the data hiding game is that passing it with high probability
certifies that {Ma }a is close to {hidek (Ma )}.
Theorem 8.3. Let x be as in Definition 10.3.
◦ Completeness: Let Spartial = (ψ, M x ) be a partial (k, n, q)-register strategy which is also a
real commuting EPR strategy. Then there is a (k, n, q)-register strategy S extending Spartial
which is also a real commuting EPR strategy such that valGhide (S) = 1.
◦ Soundness: Let S = (ψ, M ) be a projective (k, n, q)-semiregister strategy such that valGhide (S) ≥
1 − ǫ. Then
(Max )Alice ⊗ IBob ≈ǫ (hidek (Max ))Alice ⊗ IBob
on the singleton distribution on input x.
This section is organized as follows: in Section 8.1 we introduce the Pauli twirl, and in Section 8.2
we use it to prove Theorem 8.3. Finally, in Section 9, we design our compiler from layer-two to
layer-one. This last step is essentially standard and is included for completeness.

8.1

Some facts about the Pauli twirl

Definition 8.4. The Pauli twirl T : B((Cq )⊗n ) → B((Cq )⊗n ) is the linear operator


′
′
T (A) := E
X(u)Z(u
)
·
A
·
Z(−u
)X(−u)
.
′
n
u,u ∼Fq

Proposition 8.5. Let P be a Pauli matrix on n qudits of dimension q. Then T (P ) = P if P is a
multiple of the identity, and otherwise T (P ) = 0.

Proof. The case when P is a multiple of the identity follows from the definition. Otherwise, we can
write P = ω z X(a)Z(b), where at least one of a and b is nonzero. Then


T (P ) = E ′ X(u)Z(u′ ) · P · Z(−u′ )X(−u)
u,u


= ω z E ′ X(u)Z(u′ ) · X(a)Z(b) · Z(−u′ )X(−u) .
u,u

By the Pauli X and Z commutation relations (Equation (10)), this rearranges to
i
h
i
h




′
′
′
ω z E ′ ω tr[u ·a−u·b] · X(a)Z(b) = E ′ ω tr[u ·a−u·b] · P = E′ ω tr[u ·a] · E ω −tr[u·b] · P = 0.
u,u

u

u,u

u

Here the last step uses Fact 3.1 and the fact that at least one of a or b is nonzero.

In the next couple of sections, we will consider the effects of applying the Pauli twirl to our
measurements. For convenience, we will “group” our state into two parts: |ψ1 i = |rk i is the
subsystem we want to hide, and |ψ2 i = |r1 i · · · |rk−1 i |auxi is the remaining part of this state. In
this way, we can consider our measurements as operating on the bipartite state |ψ1 i |ψ2 i.
60

Proposition 8.6. Let {Ma } be a measurement on the state |ψi = |ψ1 i |ψ2 i. Then
(T1 ⊗ id2 )[Ma ] = hide1 (Ma ),
where id2 is the identity superoperator applied to the second register.
Proof. Let PJ be the elements of the Pauli group on n qudits of dimension q, with P0 = I. Because
these form a basis for the set of matrices, we can write
X
Ma =
PJ ⊗ Ma,J ,
J

where the Ma,J ’s are matrices acting on the auxiliary register. Using Proposition 8.5,
X
(T1 ⊗ id2 )[Ma ] =
T (PJ ) ⊗ Ma,J = P0 ⊗ Ma,0 = I ⊗ Ma,0 .
J

On the other hand, because PJ is traceless unless J = 0 (i.e. PJ is the identity),
hide1 (Ma ) =

X
J

hide1 (PJ ⊗ Ma,J ) =

X 1
· I ⊗ tr1 (PJ ⊗ Ma,J ) = I ⊗ Ma,0 .
qn
J

These two are equal, completing the proof.

8.2

Hiding a single coordinate

In this section, we prove Theorem 8.3. Prior to doing so, we prove a couple of technical lemmas.
The first shows that a measurement which approximately commutes with the Pauli measurements
also approximately commutes with the Pauli observables.
Lemma 8.7. Let W ∈ {X, Z}. Suppose {Ma } is a measurement on the state |ψi = |EPRnq i |ψ2 i
for which
(Ma · (τuW ⊗ I2 ))Alice ⊗ IBob ≈δ ((τuW ⊗ I2 ) · Ma )Alice ⊗ IBob .
Then the statement
(Ma · (W (u) ⊗ I2 ))Alice ⊗ IBob ≈δ ((W (u) ⊗ I2 ) · Ma )Alice ⊗ IBob
holds with respect to the uniform distribution on u ∈ Fnq .
Proof. Our goal is to bound
X
E
k(Ma · (W (u) ⊗ I2 ) − (W (u) ⊗ I2 ) · Ma ) ⊗ I |ψi k2 .
u

(49)

a

by δ. To do so, for a fixed u we introduce the notation
∆ua := Ma · (W (u) ⊗ I2 ) − (W (u) ⊗ I2 ) · Ma
X
ω tr[u·v] (Ma · (τvW ⊗ I2 ) − (τvW ⊗ I2 ) · Ma ).
=
{z
}
|
n
v∈Fq

∆a,v

We record the following identity, which follows from Equation (50):
X
X
′
†
u
E(∆u
ω tr[u·(v −v)] (∆a,v )† ∆a,v′ =
(∆a,v )† ∆a,v .
a ) · ∆a = E
u

u

v∈Fn
q

v,v′ ∈Fn
q

61

(50)

As a result,
(49) = E
u

X
a

2
k(∆u
a ⊗ I) |ψi k = E
u

=

X
a

† u
hψ| (∆u
a ) ∆a ⊗ I |ψi

XX

a v∈Fn
q

=

X
a,v

hψ| (∆a,v )† ∆a,v ⊗ I |ψi

k∆a,v ⊗ I |ψi k2 .

But this is at most O(δ), by assumption. This completes the proof.
The next technical lemma shows that a measurement which approximately commutes with
products of X and Z observables is approximately equal to its own Pauli twirl.
Lemma 8.8. Consider the distribution D on pairs (u, u′ ), where u, u′ ∼ Fnq . Suppose {Ma } is a
measurement on the state |ψi = |EPRnq i |ψ2 i for which
((Z(u′ )X(u) ⊗ I2 ) · Ma ) ⊗ IBob ≈δ (Ma · (Z(u′ )X(u) ⊗ I2 )) ⊗ IBob .
on distribution D. Then

Ma ⊗ IBob ≈δ (T1 ⊗ id2 )[Ma ] ⊗ IBob .

Proof. By definition,
(T1 ⊗ id2 )[Ma ] = E ′ [(X(u)Z(u′ ) ⊗ I2 ) · Ma · (Z(−u′ )X(−u) ⊗ I2 )].
u,u

Similarly,
Ma = E ′ [(X(u)Z(u′ ) ⊗ I2 ) · (Z(−u′ )X(−u) ⊗ I2 ) · Ma ].
u,u

u,u′

As a result, if we set A

= X(u)Z(u′ ) ⊗ I2 , and

′

Bau,u = (Z(−u′ )X(−u) ⊗ I2 ) · Ma − Ma · (Z(−u′ )X(−u) ⊗ I2 ),
then

′

′

∆a := Ma − (T1 ⊗ id2 )[Ma ] = E ′ [Au,u · Bau,u ].
u,u

We can therefore establish the lemma as follows:
X
X
′
′
k(∆a )Alice ⊗ IBob |ψi k2 =
k E ′ [Au,u · Bau,u ] ⊗ IBob |ψi k2
a

a

≤ E′
u,u

= E′
u,u

u,u

X
a

X
a

′

′

k(Au,u · Bau,u ) ⊗ IBob |ψi k2
′

k(Bau,u ) ⊗ IBob |ψi k2

(Jensen’s inequality)

By assumption, this quantity is O(δ). This concludes the proof.
Now we prove Theorem 8.3.
Proof of Theorem 8.3. We consider the completeness and soundness cases separately.

62

′

(Au,u is unitary)

Completeness. Let Spartial = (ψ, M x ) be a partial (k, n, q)-register strategy which is also a real
commuting EPR strategy. To this strategy we will add matrices for the questions x′ = (x′1 , x2 )
with x′1 = (W1 , . . . , Wk−1 , W ).
Let a1 = (u1 , . . . , uk ), where ui = ∅ if Wi ∈ {H, ⊥}. Let S = {i | Wi 6= ⊥}. By definition of a
(k, n, q)-register strategy,
O
1
Max =
τuWi i ⊗ Max,a
,
2
i∈S

1
Max,a
2

where
acts on the auxiliary registers and the registers not in S. Next, set a′ = (a′1 , a2 ) where
′
a1 = (u1 , . . . , uk−1 , u′k ) and u′k ∈ Fnqkk . Then we set
O
x′ ,x
1
(M ′ )a′1,a22 =
.
τuWi i ⊗ τuW′ ⊗ Max,a
2
1

k

i∈S\k

This is a (k, n, q)-register strategy for Ghide by design. To see that it is value 1, suppose on question x
Player b measures a1 . Then by Fact 4.38, Player b will measure a′1 in which u′i = ui for all i < k.
As a result, to measure a2 , Player b will measure M x,a1 and Player b will measure M x,a1 , both on
state |rS i |auxi. As this is an EPR state, by Fact 4.37 the outcomes will always be the same, and
so this strategy has value 1. The fact that this a real strategy follows from the assumption that
the matrices Max are real, and the fact that for W ∈ {X, Z}, τuW is a real matrix. Finally, the fact
′
that this is a commuting strategy follows from the fact that Max and (M ′ )xa′ are commuting.
Soundness. We write x and x′ = (x′1 , x2 ) with x′1 = (W1 , . . . , Wk−1 , W ) as in the test. Because
the test passes with probability 1 − ǫ, Fact 4.13 implies that
′

(Max2 )Alice ⊗ IBob ≈ǫ IAlice ⊗ (Max2 )Bob .

′

Because S is a (k, n, q)-semiregister strategy, Equation (37) implies that Muxk = τuWk ⊗ Ik , where we
write Ik := I1,...,k−1,aux . Our next step is to show that the measurements approximately commute.
This follows the analysis of the commutation test (cf. [CGJV18, Lemma 28]).
′

′

′

Muxk Max2 ⊗ IBob ≈ǫ Muxk ⊗ Max2

′
′
≈0 IAlice ⊗ Max2 Muxk
′
′
= IAlice ⊗ Muxk Max2
′
≈ǫ Max2 ⊗ Muxk
′
≈0 Max2 Muxk ⊗ IBob .

(Fact 4.20)
(Fact 4.38)
(Fact 4.20)
(Fact 4.38)

In summary,
((τuWk ⊗ Ik ) · Max2 )Alice ⊗ IBob ≈ǫ (Max2 · (τuWk ⊗ Ik ))Alice ⊗ IBob .

Recall this is with respect to the distribution W where W ∼ {X, Z} is uniform. Therefore, it also
holds with respect to the distribution where W is fixed to either X or Z. As a result, for a fixed
W ∈ {X, Z}, by Lemma 8.7,
(Max2 · (W (u) ⊗ Ik ))Alice ⊗ IBob ≈ǫ ((W (u) ⊗ Ik ) · Max2 )Alice ⊗ IBob .

on distribution u ∼ Fnq . As a result, by Fact 4.38 and Fact 4.20,

(Max2 · (Z(u′ )X(u) ⊗ Ik ))Alice ⊗ IBob ≈0 (Max2 · (Z(u′ ) ⊗ Ik ))Alice ⊗ (X(−u) ⊗ Ik )Bob
≈ǫ ((Z(u′ ) ⊗ Ik ) · Max2 )Alice ⊗ (X(−u) ⊗ Ik )Bob

≈0 ((Z(u′ ) ⊗ Ik ) · Max2 · (X(u) ⊗ Ik ))Alice ⊗ IBob
≈ǫ ((Z(u′ )X(u) ⊗ Ik ) · Max2 )Alice ⊗ IBob ,
63

With probability

1
2

each, perform one of the following three tests.

1. Data hiding: Draw (x, x′ , C) ∼ Gk , where x = (x1 , x2 ) and x1 = (W 1 , . . . , W k ). If
W k = H, play Ghide with question x.
2. Play game: Perform Gk .
Figure 4: The game Ck→semi (Gk ).
on distribution u, u′ ∼ Fnq . Applying Lemma 8.8 and Proposition 8.6, we can therefore conclude
Max2 ⊗ IBob ≈ǫ (Tk ⊗ idk )[Max2 ] ⊗ IBob = (hidek (Max2 )) ⊗ IBob .

9

Compiling games with the data hiding test

Now we can show how to compile games from the second layer to the first layer. Our construction
is given in the following definition.
Definition 9.1. Let Gk be a (k, n, q)-register game.
Ck→semi (Gk ) defined in Figure 4.

Then its compiled version is the game

Theorem 9.2. Suppose Gk is a (k, n, q)-register game, and consider the (k, n, q)-semiregister game
Gsemi = Ck→semi (Gk ).
◦ Completeness: Suppose there is a value-1 (k, n, q)-register strategy for Gk which is also a
real commuting EPR strategy. Then there is a value-1 (k, n, q)-semiregister strategy for Gsemi
which is also a real commuting EPR strategy.
◦ Soundness: If valsemi
k,n,q (Gsemi ) ≥ 1 − ǫ then valk,n,q (Gk ) ≥ 1 − δ(ǫ), where δ(ǫ) = poly(ǫ).
Furthermore,
Q-length(Gsemi ) = O(Q-length(Gk )),

A-length(Gsemi ) = O(A-length(Gk )),

Q-time(Gsemi ) = O(Q-time(Gk )),

A-time(Gsemi ) = O(A-time(Gk )).

Proof of Theorem 9.2. The communication and time complexities are the result of combining the
communication and time complexities from Gk with the values for the data hiding game from
Definition 10.3.
Completeness. Let (ψ, M ) be a value-1 (k, n, q)-register strategy for Gk which is also a commuting EPR strategy. Then for every x = (x1 , x2 ) where x1 = (W1 , . . . , Wk ) with Wk = H, by
Theorem 8.3 we can extend this strategy to one that passes the data hiding game with question x
with probability 1. Thus, this strategy has value 1 overall. In addition, Theorem 8.3 implies this
strategy is a real commuting EPR strategy as well.
Soundness. Suppose S = (ψ, M ) is a (k, n, q)-semiregister strategy for Gsemi with value 1 − ǫ.
By Lemma 5.3, we can assume without loss of generality that M is projective. Our goal will be to
decode S into a (k, n, q)-register strategy Sk with nearly the same value.
64

Using the data hiding test. For a fixed question x, write νx for the probability that S passes
the test in Item 1. Then on average, the probability that S passes this test is Ex νx , which is
at least 1 − 2ǫ because the overall test passes with probability at least 1 − ǫ. This implies that
νx ≥ 1 − ǫ1/2 with probability at least 1 − 2ǫ1/2 . Given a matrix M and a W ∈ {X, Z, H, ⊥}, let
us write hideW (M ) := hidek (M ) if W = H and hideW (M ) := M otherwise. For a question x, if
Wk 6= H, then hideWk (Max ) = Max trivially. On the other hand, suppose Wk = H. Then either
νx ≥ 1 − ǫ1/2 , in which case Max ⊗ IBob ≈δ(ǫ) hideWk (Max ) ⊗ IBob by Theorem 8.3, or νx < 1 − ǫ1/2 ,
in which case we have the trivial bound Max ⊗ IBob ≈1 hideWk (Max ) ⊗ IBob from Fact 4.19. Since
this latter case happens with probability at most 2ǫ1/2 , averaging over all x gives us
Max ⊗ IBob ≈δ(ǫ) hideWk (Max ) ⊗ IBob ,

(51)

on the distribution D.
Extracting a strategy. Define the strategy Sk = (ψ, Λ), in which Λxa := hideWk (Max ). First, we
show that Sk is a (k, n, q)-register strategy. To do so, fix x = (x1 , x2 ) with x1 = (W1 , . . . , Wk ) and
a = (a1 , a2 ) with a1 = (u1 , . . . , uk ). Then

Λxa1 = hideWk τuW1 1 ⊗ · · · ⊗ τuWk k ⊗ Iaux = τuW1 1 ⊗ · · · ⊗ τuWk k ⊗ Iaux .

The first equality is by definition of Λ and the fact that S is a (k, n, q)-quasiregister strategy. The
second equality is trivial when Wk 6= H and follows from the fact that τ∅Wk = I when Wk = H.
Next, define S = {i 6= k | Wi = H}. If Wk 6= H then Λxa = Max = MS ⊗ IS for some matrix M .
Otherwise, if Wk = H, set h = tr(Ik ). Then
Λxa = hidek (Max ) = hidek (MS ⊗ IS ) =

1
1
· Ik ⊗ trk (MS ⊗ IS ) = · IS∪k ⊗ trk (MS ).
h
h

The matrix trk (MS ) · h−1 only acts on the registers in S ∪ k and the auxiliary register, and as a
result, this strategy satisfies data hiding. Thus, Sk is a (k, n, q)-register strategy.
It remains to show that Sk has good value. This follows by combining Equation (51) with Fact 4.32:
valGk (Sk ) ≥ valGsemi (S) − δ(ǫ), and so valk,n,q (Gk ) ≥ 1 − δ(ǫ).

10

Partial data hiding

The data-hiding game presented above was used to show that the provers’ measurement acts as
identity on a subset of the provers’ qudits, and thus the prover learns no information from those
qudits. In particular, the measurement outcome of any X- or Z-observable measurement on the
qubits in the subset is hidden from the prover. In this subsection, we generalize this idea to show
how to certify that certain partial information about a register is hidden from a prover. This test
is a crucial component in our technique of introspection, wherein two provers measure a shared
EPR state to sample from the joint distribution over questions of a classical game. The partial
data hiding test will prevent one prover from learning the question sampled by the other prover.
Notation 10.1. Given a set v = {v1 , . . . , vk } of k vectors in Fnq , denote their span by V =
span({v1 , . . . , vk }). The orthogonal complement of their span is the subspace V ⊥ = {a : ∀i ∈
{1, . . . , k}, ha, vi i = 0}. We denote by Surfacesv the set of all affine subspaces parallel to V , i.e. sets
of the form:
s = {u + λ1 v1 + · · · + λk vk : λ1 , . . . , λk ∈ Fq }.
65

For a subspace s ∈ Surfacesv , the subspace projector Πvs is the projector
X
Πvs =
|wihw| .
w∈s

Lemma 10.2. Given a set of vectors {v1 , . . . , vk }, let
X
X
τ[∀i,u·v
=
i =ai ]

τuX .

u:∀i,u·vi =ai

X
Then τ[∀i,u·v
commutes with Πvs for all s ∈ Surfacesv .
i =ai ]

Proof. The proof is by calculation.
X
Πvs τ[∀i,u·v
=
i =ai ]

X

w∈s

=

|wihw|

X

X

τuX

u:∀i,u·vi =ai

X

w∈s u:∀i,u·vi =ai

E ω −tr[b·u] |wihw| X(b).
b

We note an important fact: for any two outcomes u, u′ satisfying u · vi = u′ · vi = ai for all i, the
difference u − u′ must lie in V ⊥ . Fixing some appropriate outcome vector u0 , we can then express
the summation variable u as u0 + x where x runs over V ⊥ :
X X
=
E ω −tr[b·(u0 +x)] |wihw| X(b)
w∈s x∈V ⊥

=

X X

w∈s x∈V ⊥

b

E ω −tr[b·(u0 +x)] |wi hw − b| .
b

Now, the summation over x vanishes unless b ∈ (V ⊥ )⊥ = V , by Fact 3.2. This happens with
probability q k−n which cancels out the factor of q n−k from evaluating the sum over x ∈ V ⊥ ,
yielding:
X
=
E ω −tr[b·u0 ] |wi hw − b| .
w∈s

b∈V

Now, since b ∈ V , and the summation variable w runs over an affine subspace parallel to V , we
can shift it from w to w + b, yielding
X
=
E ω −tr[b·u0 ] |w + bi hw| .
w∈s

b∈V

Finally, we can perform the same manipulations in reverse:
= ...
X
= τ[∀i,u·v
Πv .
i =ai ] s

Definition 10.3. The partial data-hiding game is given by Figure 5.
Theorem 10.4. Let S be any set of k-tuples of vectors in Fnq , and let x be an arbitrary query.

66

Given a set S of k-tuples of linearly independent set of vectors v1 , . . . , vk ∈ Fnq and a query string
x. Sample v = {v1 , . . . , vk } uniformly from S. Flip an unbiased coin b ∼ {0, 1}. Perform one of
the following three tests with probability 1/3 each.
1. Distribute the questions as follows:
◦ Player b: Give (⊥, x, v); receive (∅, a2 ).
◦ Player b: give (Z, x, v); receive (a′1 , a′2 ).

Accept if a2 = a′2 .
2. Distribute the questions as follows:
◦ Player b: Give (⊥, x, v); receive (∅, a2 ).

◦ Player b: give (⊥, x, {X, v}); receive (∅, a′2 , {a′1,1 , . . . a′1,k }).

Accept if a2 = a′2 .
3. Distribute the questions as follows:
◦ Player b: Give (X, ·); receive (a1 , ·). (Here, “·” is the empty string.)
◦ Player b: give (⊥, ⊥, {X, v}); receive (∅, ∅, {a′1,1 , . . . a′1,k }).

Accept if a′1,i = vi · a1 for all i ∈ {1, . . . , k}.
4. Distribute the questions as follows:
◦ Player b: Give (⊥, x, {X, v}); receive (∅, a2 , {a1,1 , . . . , a1,k }).

◦ Player b: give (⊥, ⊥, {X, v}); receive (∅, ∅, {a′1,1 , . . . , a′1,k }).
Accept if a1,i = a′1,i for all i ∈ {1, . . . , k}.

Figure 5: The partial data-hiding game Ghide (S, x).

67

◦ Completeness: Let Spartial = (ψ, M ⊥,x,v ) be a partial (1, n, q)-register strategy for Ghide (S, x),
which is also a real commuting EPR strategy, and for which
X
Πvs ⊗ Ax,v,s
Ma⊥,x,v
=
a2 ,
2
s∈Surfacesv

for some measurement Ax,v,s
acting only on the aux register. Then there is a (1, n, q)-register
a2
strategy S extending Spartial for which valGhide (S) = 1.
◦ Soundness: Let S = (ψ, M ) be a projective (1, n, q)-register strategy such that valGhide (S,x) (S) ≥
1 − ǫ. Then there exists an ideal measurement Ma′⊥,x,v with the property that
X
Πvs ⊗ Mas,x,v ,
Ma′⊥,x,v =
s∈Surfacesv

such that the measurement Ma⊥,x,v used by strategy S in response to the query x is close to
Ma′⊥,x,v :
(Ma⊥,x,v )Alice ⊗ IBob ≈ǫ (Ma′⊥,x,v )Alice ⊗ IBob .
To prove this theorem, we will start with some basic facts about the subspace projector measurements. Let us denote the linear subspace spanned by the vectors v1 , . . . , vk by V .
Definition 10.5. For any distribution U over unitary matrices, the twirl by U is the linear operator
TU : B((Cq )⊗n ) → B((Cq )⊗n ) defined by
i
h
TU (A) := E U AU † .
U ∼U

Definition 10.6. Let v = {v1 , . . . , vk } be a set of linearly independent vectors over Fq . Further let
V be the uniform distribution over the set {X(a) : a ∈ V }, Z be the uniform distribution over the
set of all Pauli Z operators {Z(a) : a ∈ Fnq }, and S be the distribution over products M N where
M is drawn from V and N from Z. Then the v-subspace twirl is the twirl over S:
TS = TV ◦ TZ
Proposition 10.7. Let A be a Hermitian matrix and v a set of k vectors over Fq . Then the
v-subspace twirl of A is a linear combination of projectors onto affine subspaces along v:
X
(TS ⊗ idaux )(A) =
Πvs ⊗ (Ms )aux ,
s∈Surfacesv

for some choice of Hermitian matrices Ms indexed by subspaces s.
Proof. Start by decomposing A into a linear combination of Pauli matrices:
X
A=
X(u)Z(u′ ) ⊗ (Au,u′ )aux .
u,u′

After the twirl over Z, the only terms that survive are those with no X part, i.e.
X
A′ = (TZ ⊗ idaux )(A) =
Z(u) ⊗ (A0,u )aux
u

68

Now if we perform the twirl over V, we get
X
(TV ⊗ idaux )(A′ ) =
E X(a)Z(u)X(a)† ⊗ (A0,u )aux
u

=

a∈V

u∈V

⊥

u

=

a∈V

X

E ω tr[ha,ui] Z(u) ⊗ (A0,u )aux

X

=

X X

u∈V ⊥ w

=

X
w

(Fact 3.2)

Z(u) ⊗ (A0,u )aux
ω tr[hw,ui] |wi hw| ⊗ (A0,u )aux

|wi hw| ⊗

X

ω tr[hw,ui] (A0,u )aux .

(52)

u∈V ⊥

Now, consider a surface s ∈ Surfacesv . For some x ∈ Fnq , s is the set of points written w = x + v,
where v ∈ V . Then for any u ∈ V ⊥ , hw, ui = hx + v, ui = hx, ui, a quantity which depends only on
the subspace and not on the point w. Call this quantity cs,u . As a result,
X
X
X X
(52) =
Πvs ⊗ (Âs )aux ,
|wi hw| ⊗
cs,u (A0,u )aux =
s∈Surfacesv w∈s

P

where Âs =

s∈Surfacesv

u∈V ⊥

u∈V ⊥ cs,u A0,u .

Lemma 10.8. Let W ∈ {X, Z}, and let v = {v1 , . . . , vk } be a set of k linearly independent vectors
in Fnq and V be their span. Suppose {Ma2 } is a measurement for which
W
W
(Ma2 · (τ[∀i,v
⊗ Iaux )) ⊗ IBob ≈δ ((τ[∀i,v
⊗ Iaux ) · Ma2 ) ⊗ IBob ,
i ·a1 =a1,i ]
i ·a1 =a1,i ]

where

X

W
τ[∀i,v
=
i ·a1 =a1,i ]

(53)

τaW1 .

a1 :∀i,vi ·a1 =a1,i

Then
(Ma2 · (W (u) ⊗ Iaux )) ⊗ IBob ≈δ ((W (u) ⊗ Iaux ) · Ma2 ) ⊗ IBob ,
for a uniformly random u drawn from V .
Proof. To start, given a set of outcomes a1,1 , . . . , a1,k , suppose u and u′ are outcomes for a full
W -basis measurement consistent with these outcomes, i.e. u and u′ are vectors such that for all i,
u · vi = a1,i . Then it must hold that u − u′ ∈ V ⊥ . Using this, the bound in Equation (53) becomes
X
a2

1 X
|V ⊥ | u

X

w∈V

⊥

W
W
(Ma2 · (τu+w
⊗ Iaux ) − (τu+w
⊗ Iaux ) · Ma2 ) ⊗ IBob |ψi

2

≤ δ,

(54)

where the factor of 1/|V ⊥ | is because each outcome a1,1 , · · · , a1,k corresponds to |V ⊥ | different
choices of u.
Our goal is to bound
X
k(Ma2 · (W (u) ⊗ Iaux ) − (W (u) ⊗ Iaux ) · Ma2 ) ⊗ IBob |ψi k2 .
(55)
E
u∼V

a2

69

by δ. To do so, for a fixed u we introduce the notation
∆ua2 := Ma2 · (W (u) ⊗ Iaux ) − (W (u) ⊗ Iaux ) · Ma2
X
ω tr[u·x](Ma2 · (τxW ⊗ Iaux ) − (τxW ⊗ Iaux ) · Ma2 ).
=
{z
}
|
n
x∈Fq

(56)
(57)

∆a2 ,x

We record the following identity, which follows from Equation (57) and Fact 3.2:
X
X X
†
u
tr[u·(x′ −x)]
†
′ =
(∆a2 ,x )† ∆a2 ,x+w .
E (∆u
)
·
∆
=
E
ω
(∆
)
∆
a
,x
a
,x
a2
a2
2
2
u∼V

u∼V

⊥
x∈Fn
q w∈V

x,x′ ∈Fn
q

As a result,
(55) = E
u

X
a2

2
k(∆u
a2 ⊗ IBob ) |ψi k = E
u

=

X
a2

† u
hψ| (∆u
a2 ) ∆a2 ⊗ IBob |ψi

XX X

⊥
a2 x∈Fn
q w∈V

=

a2
⊥|

1
⊥|
|V
,x

X

hψ| (∆a2 ,x )† ∆a2 ,x+w ⊗ IBob |ψi

X

w∈V

⊥

∆a2 ,x+w ⊗ IBob |ψi

2

,

where the factor of 1/|V is again to deal with overcounting. But this is at most O(δ), by Equation (54).
This completes the proof.
Lemma 10.9. Let {Ma } be a measurement and U be a distribution over unitaries, and suppose
that for U drawn uniformly from U ,
((U † ⊗ Iaux ) · Ma ) ⊗ IBob ≈δ (Ma · (U † ⊗ Iaux )) ⊗ IBob ,

where the distribution inherent in the ≈δ notation is the uniform distribution over U . Then
Ma ⊗ IBob ≈δ (TU ⊗ Iaux )[Ma ] ⊗ IBob .
Proof. By definition,
(T1 ⊗ Iaux )[Ma ] = E [(U ⊗ Iaux ) · Ma · (U † ⊗ Iaux )].
U ∼U

Similarly,
Ma = E [(U ⊗ Iaux ) · (U † ⊗ Iaux ) · Ma ].
U ∼U

As a result, if we set
B(U )a = (U † ⊗ Iaux ) · Ma − Ma · (U † ⊗ Iaux ),

then

∆a := Ma − (T1 ⊗ Iaux )[Ma ] = E [U · B(U )a ].
U ∼U

We can therefore establish the lemma as follows:
X
X
k∆a ⊗ IBob |ψi k2 =
k E [U · B(U )a ] ⊗ IBob |ψi k2
a

U ∼U

a

≤E
U

=E
U

X
a

X
a

k(U · B(U )a ) ⊗ IBob |ψi k2

kB(U )a ⊗ IBob |ψi k2

(Jensen’s inequality)
(U is unitary)

By assumption, this quantity is O(δ). This concludes the proof.
Proof of Theorem 10.4. We consider the completeness and soundness cases separately.
70

Completeness Let Spartial = (ψ, M ⊥,x,v ) be a partial (k, n, q)-register strategy for Ghide (S, x)
which is also a real commuting EPR strategy, and for which the measurement Ma⊥,x,v
has the form
2
X
Ma⊥,x,v
=
Πvs ⊗ As,x,v
a2 .
2
s∈Surfacesv

To this strategy we will add matrices for the remaining questions.
◦ Question (Z, x): the measurement is
Ma(Z,x,v)
=
1 ,a2

X

s∈Surfacesv

Πvs · τaZ1 ⊗ As,x,v
a2 .

This is a well-defined measurement as Πvs is diagonal in the Z basis and thus commutes with
τaZ1 .
◦ Question (⊥, x, {X, v1 , . . . , vk }): the measurement is
X
(⊥,x,{X,v})
X
M{a1,1 ,...,a1,k },a2 =
Πvs · τ[∀i,a
⊗ As,x,v
a2 .
1 ·vi =a1,i ]
s∈Surfacesv

X
by Lemma 10.2.
This is a well-defined measurement as Πvs commutes with τ[∀i,a
1 ·vi =a1,i ]

◦ Question (⊥, ⊥, {X, v1 , . . . , vk }): the measurement is
(⊥,⊥,{X,v})

X
⊗ I.
M{a1,1 ,...,a1,k ,∅ = τ[∀i,a
1 ·vi =a1,i ]

◦ Question (X, ⊥): the measurement is
Ma(X,·)
= τaX1 ⊗ Iaux .
1
This is a (1, n, q)-register strategy for Ghide by design, and it is not hard to see that it achieves
value 1 on the game. Assuming that the partial strategy Spartial is a real commuting EPR strategy,
it is not hard to see that the full strategy above is also real (this is because if M ⊥,x,v is real and of
the given form, then the matrices As,x,v
must also be real). That the strategy is also commuting
a2
follows from the description of Ghide . In particular, note that while MaZ,x,v does not commute with
M ⊥,x{X,v} or with M X,⊥ , the test never requires these measurements to be measured at the same
time.
Soundness

Recall that a strategy S for this game consists of a state |ψi = |EPRnq i ⊗ |auxi
(⊥,x,v)

and measurement operators of three types, corresponding to the four types of queries: M∅,a2
(Z,x,v)
Ma1 ,a2 ,

⊥,x,{X,v},
M{a′ ,...,a′ },a′ ,
2
1,1
1,k

and

,

(X,·)
Ma1 .

We start by analyzing the third and fourth parts of the test. The goal of these parts of the
test is to certify that when given the query ({X, v}, x), the prover returns k answers a′1,1 , . . . , a′1,k
that are consistent with measuring the X(v1 ), . . . , X(vk ) observables on the state. We certify this
in two stages. In part three of the test, we ask the first prover to do a complete measurement
in the X basis, and send the second prover the query {X, v} indicating that it is to perform a
partial X measurement, and check consistency of outcomes. Importantly, in this part of the test,
we cannot send the second prover the query x, since the corresponding Πvs measurement does not
71

commute with the complete X measurement performed by the first prover. Thus, in part four of
the test, we send one prover the query {X, v} and the other (x, {X, v}), and check consistency of
their outcomes.
(X,·)
Since S is a (k, n, q)-register strategy, Equation (37) implies that Ma1 = τaX1 ⊗ IBob . We thus
have from the third part of the test that
⊥,⊥,{X,v}
′
1,1 ,...,a1,k }

M{a′

X
⊗ IBob ≈ǫ τ[∀i,u·v
′
i =a

1,i ]

⊗ IBob .

From the above equation and the fourth part of the test, we have
⊥,x,{X,v}
′
1,1 ,...,a1,k }

M{a′

⊥,⊥,{X,v}
′
1,1 ,...,a1,k }

⊗ IBob ≈ǫ M{a′

X
⊗ IBob ≈ǫ τ[∀i,u·v
′
i =a

1,i ]

⊗ IBob .

Next, we look at the first and second parts of Ghide (S, x). These are essentially two instances
of the commutation test. The first part of Ghide certifies that the second outcome of MaZ,x,v
1 ,a2 is
⊥,x,v
consistent with M∅,a2 , and the hypothesis that the strategy S is a (1, n, q)-register strategy tells
Z
us that the first outcome of MaZ,x,v
1 ,a2 is consistent with τa1 ⊗ IBob . Thus, applying the analysis of the
commutation, it follows that
⊥,x,v
⊥,x,v
(M∅,a
· (τaZ1 ⊗ Iaux )) ⊗ IBob ≈ǫ ((τaZ1 ⊗ IBob ) · M∅,a
) ⊗ IBob .
2
2

A similar analysis for the second part of Ghide (S) certifies that
X
((τ[∀i,a
′
1 ·vi =a

1,i ]

⊥,x,v
⊥,x,v
X
⊗ Iaux ) · M∅,a
) ⊗ IBob ≈ǫ (M∅,a
· (τ[∀i,a
′
2
2
1 ·vi =a

1,i ]

⊗ Iaux )) ⊗ IBob .

As a result, it holds that W ∈ {X, Z}, by Lemma 10.8,
⊥,x,v
⊥,x,v
(M∅,a
· (W (u) ⊗ Iaux )) ⊗ IBob ≈ǫ ((W (u) ⊗ Iaux ) · M∅,a
) ⊗ IBob .
2
2

where if W = X, then u is chosen uniformly over V , and if W = Z, then u is drawn uniformly
from Fnq . As a result, by Fact 4.38 and Fact 4.20,
⊥,x,v
⊥,x,v
(M∅,a
· (Z(u′ )X(u) ⊗ Iaux )) ⊗ IBob ≈0 (M∅,a
· (Z(u′ ) ⊗ Iaux )) ⊗ (X(−u) ⊗ Iaux )
2
2
⊥,x,v
≈ǫ ((Z(u′ ) ⊗ Iaux ) · M∅,a
) ⊗ (X(−u) ⊗ Iaux )
2

⊥,x,v
≈0 ((Z(u′ ) ⊗ Iaux ) · M∅,a
· (X(u) ⊗ Iaux )) ⊗ IBob
2

⊥,x,v
≈ǫ ((Z(u′ )X(u) ⊗ Iaux ) · M∅,a
) ⊗ IBob ,
2

on the distribution where v is chosen from S, and then u ∼ V , u′ ∼ Fnq . Applying Lemma 10.9
and Proposition 10.7, we can therefore conclude that


X
⊥,x,v
x
 ⊗ IBob ,
Πvs ⊗ (Ax,v,s
M∅,a
⊗ IBob ≈ǫ (TS ⊗ Iaux )[M∅,a
] ⊗ IBob = 
a2 )aux
2
2
s∈Surfacesv

for some choice of measurements Ax,v,s
on the aux register.
a2

72

Part IV

NEEXP protocol
11

A review of a classical PCP theorem

We begin Part IV by reviewing the following classical PCP theorem:
Succinct-3Sat ∈ PCP[n, poly(n)].

(58)

This implies, by standard reduction, that Succinct-3Sat ∈ MIP, which is the main result of [BFL91].
Reviewing this serves two purposes: (i) our MIP∗ protocols are inspired by this PCP construction,
and (ii) their correctness is actually shown by reduction to the correctness of this PCP construction
(Lemma 15.6 below). This section closely follows the excellent course notes of Harsha [Har10].

11.1

The instance

The input to the verifier is an instance of the Succinct-3Sat problem, i.e. a circuit C of size s with
3n+3 inputs. We apply the Tseitin transformation to it to produce a formula F with n′ = 3n+3+s
inputs. It encodes the 3Sat formula ψ := ψF on N = 2n variables which contains (xbi 1 ∨ xbj2 ∨ xbk3 )
as a clause if and only if F(i, j, k, b1 , b2 , b3 , w) = 1 for some w ∈ {0, 1}s .

11.2

Encoding assignments

Writing S = {0, 1}n , an assignment to the variables of ψ is a string a ∈ {0, 1}S , or equivalently a
string in {0, 1}N . The first step of the PCP theorem is to take the low-degree encoding of a. We
begin by choosing parameters.
Definition 11.1. Recall that N = 2n , h = 2t1 , q = 2t2 , and m are admissible parameters if t1 ≤ t2
and hm ≥ N . We call them exactly admissible if the stronger condition hm = N = 2n holds.
We select n, h = 2t1 , q = 2t2 , and m to satisfy our “rule of thumb” parameter settings
(Equation (1)):


n
h = Θ(n), m = Θ
, q = Θ((n′ )10 ).
log(n)

Note that q depends on n′ rather than just n.
It remains to choose H and π. Our construction requires that the permutation π be efficiently
computable, and so we pick these according to the canonical low-degree encoding (Definition 3.8).
This entails setting H = Ht1 ,t2 . As for π, we modify the construction slightly. This is because the
canonical low-degree encoding is designed for strings whose coordinates are indexed by an integer
i ∈ [n], which must first be converted to binary when computing π. However, the coordinates of
our strings a ∈ {0, 1}S are indexed by elements of S = {0, 1}n , which are already written in binary,
allowing us to skip the conversion. Hence, within this section, we define π := πn,t1 ,t2 : S → H m by
setting
π(b1 , . . . , bn ) := σn,t1 ,t2 (b1 , . . . , bn ) = (σ(b1 , . . . , bt1 ), σ(bt1 +1 , . . . , b2t ), . . . , σ(bn−t1 +1 , . . . , bn )),
where σ := σt1 ,t2 . Given these parameters, an assignment a is encoded as a degree-O(mh) polynomial ga : Fm
q → Fq .
73

The crucial property of π that we will need later is that it has an efficiently-computable, lowdegree inverse. We will show this here. To do so, we begin by recalling the notation indH,x (y) for
the indicator function of x ∈ H over H:
Q
b6=x (y − b)
,
indH,x (y) = Q
b6=x (x − b)

where b ranges over H. This is a degree-h polynomial which can be computed in time poly(h, q).

Definition 11.2. Let N = 2n , h = 2t1 , q = 2t2 , and m be exactly admissible parameters. Set
H = Ht1 ,t2 , σ = σt1 ,t2 , and π = πn,t1 ,t2 . Consider the function µ := µt1 ,t2 : Fq → Ftq1 whose i-th
component is defined as
X
µi (y) =
indH,x (y).
x∈H:tr[ei ·x]=1

Let y = b1 · e1 + · · · + bt1 · et1 be an element of H. Then µi (y) = bi , and so µ(y) = (b1 , . . . , bt1 ).
This means that µ(σ(b1 , . . . , bt1 )) = (b1 , . . . , bt1 ). As a result, if we define the function ν := νn,t1 ,t2 :
Fm
q → Sn to be
ν(x1 , . . . , xm ) := (µ(x1 ), . . . , µ(xm ))
then ν(π(x)) = x for any x ∈ Sn . Each component of ν is the sum of h2 indicator functions,
and is therefore degree-h and computable in time poly(h, q). As a result, ν is computable in time
poly(n, h, q).

11.3

Encoding the formula

Our next step is to produce a similar “low-degree encoding” for the formula ψ. This will be
′
→ Fq , for m′ = 3m + 3 + s, with the property that for all i, j, k ∈ S,
a function gψ : Fm
q
b1 , b2 , b3 ∈ {0, 1}, and w ∈ {0, 1}s ,
gψ (π(i), π(j), π(k), b1 , b2 , b3 , w) = F(i, j, k, b1 , b2 , b3 , w).
′

′

This can be accomplished by setting S ′ := {0, 1}n , viewing F as computing a string aψ ∈ {0, 1}S ,
and setting gψ to be its low-degree encoding. However, the verifier in our protocol will be required
to evaluate gψ on a particular input, and this seems challenging given that this gψ is computed by
interpolating over an exponential number of points. Instead, we will produce a gψ which we can
efficiently evaluate at any point using the fact that we have a succinct formula F representing ψ.
To begin, we convert F into an algebraic formula which operates over Fq -valued inputs using
′
arithmetization (cf. Definition 3.28). Set Farith := arithq (F). This is a function Farith : Fnq → Fq
′
with the property that for any x ∈ {0, 1}n , Farith (x) = F(x). Furthermore, Farith has degree O(n′ )
and is computable in time poly(n′ , q). We can now define the function gψ as follows.
Definition 11.3. Let N = 2n , h = 2t1 , q = 2t2 , and m be exactly admissible parameters. Set
ν := νn,t1 ,t2 . Let C be a Succinct-3Sat instance whose Tseitin transformation F has n′ = 3n + 3 + s
inputs and encodes the formula ψ := ψF , and let Farith = arithq (F). Write m′ = 3m + 3 + s. Then
′
we define gψ := gψ,n,t1 ,t2 : Fm
q → Fq to be the function
gψ (x1 , x2 , x3 , b1 , b2 , b3 , w) := Farith (ν(x1 ), ν(x2 ), ν(x3 ), b1 , b2 , b3 , w).
This is degree h · O(n′ ) and can be computed in time poly(n′ , h, q).
, where x =
For shorthand, we will often write inputs to gψ as tuples (x, b, w) ∈ F3m+3+s
q
m
(x1 , x2 , x3 ) contains three strings in Fq and b = (b1 , b2 , b3 ) contains three numbers in Fq .
74

11.4

Zero on subcube

Given a function g : Fm
q → Fq , we would like to check that it is the low-degree encoding of an
assignment which satisfies ψ. To do so, we define the following function.
Definition 11.4. Let N = 2n , h = 2t1 , q = 2t2 , and m be exactly admissible parameters. Let C be
a Succinct-3Sat instance whose Tseitin transformation F has n′ = 3n + 3 + s inputs and encodes the
formula ψ := ψF , and let gψ := gψ,n,t1 ,t2 . Set m′ = 3m + 3 + s. Then given a function g : Fm
q → Fq ,
′
m
we define satψ,g := satψ,g,n,t1 ,t2 : Fq → Fq to be the function
satψ,g (x, b, w) := gψ (x, b, w) · (g(x1 ) − b1 )(g(x2 ) − b2 )(g(x3 ) − b3 ).
The crucial property we would like to check is that satψ,g is zero on the subcube Hzero :=
H 3m ⊗ {0, 1}3+s .

Proposition 11.5. The function satψ,g is zero on the subcube Hzero for some g : Fm
q → Fq if and
only if ψ is satisfiable. If it is satisfiable, g may be taken to be degree-O(mh), in which case satψ,g
is degree-O(mh + hn′ ).

Note what Proposition 11.5 does not say. It does not say that if satψ,g is zero on the subcube,
then g is the low degree encoding of a satisfying assignment of ψ. It does not even say that g
must be low-degree. (Indeed, g might have high degree, as satψ,g only checks g on those numbers
in the range of π.) What it does say is that if ψ is satisfiable, then there exists such a g which
is low-degree: the low-degree encoding of a satisfying assignment. Our strategy, then, will be to
verify that that g is low-degree and then use this fact to verify that satψ,g is zero on the subcube.
(We can then “forget” that g is low-degree, as it is no longer required for the analysis.)
To verify this that satψ,g is zero on Hzero , we would like it to be encoded so that this is selfevidently true. This entails expanding satψ,g in a “basis” of simple polynomials which are zero on
the subcube. To begin, given a subset S ⊆ Fq , define
Y
zeroS (x) :=
(x − b).
b∈S

The following proposition shows how to expand into this “zero” basis.

Proposition 11.6. Let f : Fnq → Fq be a degree-d polynomial which is zero on the subcube H =
H1 ⊗ · · · ⊗ Hn . Then there exist degree-(d − h) “coefficient polynomials” c1 , . . . , cn such that
f (x) = zeroH,c (x) :=

n
X
i=1

zeroH (xi ) · ci (x).

For simplicity, we will write zeroH,c instead of zeroHzero ,c . We would like our proof to consist
of the function g and the coefficient polynomials c1 , . . . , cm′ so that we may check the equality
satψ,g ≡ zeroH,c . The following lemma shows so long as these functions are low-degree, we can
verify that they are equal, and therefore show that ψ is satisfiable.
Lemma 11.7. Let N = 2n , h = 2t1 , q = 2t2 , and m be exactly admissible parameters. Let C be
a Succinct-3Sat instance whose Tseitin transformation F has n′ = 3n + 3 + s inputs and encodes
the formula ψ := ψF ,. Set m′ = 3m + 3 + s. Let g : Fm
q → Fq , and set satψ,g := satψ,g,n,t1 ,t2 . Let
′
3m
3+s
m
c1 , . . . , cm′ : Fq → Fq , set Hzero = H ⊗ {0, 1} , and write zeroHc := zeroHzero ,c . Suppose that
g is degree-d1 , and suppose that c1 , . . . , cm′ are degree-d2 . Suppose
Pr ′ [satψ,g (x) = zeroH,c (x)] >

x∼Fm
q

Then ψ is satisfiable.
75

max{O(hn′ ) + 3d1 , h + d2 }
.
q

Proof. By Definition 11.3, satψ,g has degree h · O(n′ ) + 3d1 . In addition, zeroH,c has degree h + d2 .
Define f = satψ,g − zeroH,c . Then f has degree max{O(hn′ ) + 3d1 , h + d2 }. By assumption,
′
f (x) = 0 with probability larger than deg(f )/q over a uniformly random x ∼ Fm
q . By SchwartzZippel (Lemma 3.6), this means that f ≡ 0, which implies that satψ,g ≡ zeroH,c . But zeroH,c is
self-evidently zero on the subcube Hzero , meaning that satψ,g is as well. By Proposition 11.5, ψ is
satisfiable.
Ensuring that satψ,g is low-degree requires ensuring that g is low-degree, and this can be accomplished with the low-degree test. Arguing similarly for zeroH,c requires ensuring that each ci
is low-degree, and this can be done with the simultaneous plane-versus-point low-degree test
(Theorem 3.19).

11.5

The PCP

We can now state the contents of our probabilistically checkable proof for the satisfiability of ψ. It
consists of the following four tables.
1. A claimed low-degree polynomial g : Fm
q → Fq .

′

2. A set of claimed low-degree polynomials c1 , . . . , cm′ : Fm
q → Fq .

3. A “planes table”, containing for each plane s in Fm
q a degree-d bivariate polynomial.
′

′
4. Another planes table, containing for each plane s in Fm
q an m -tuple of degree-d bivariate
polynomials.

The verifier works as follows: first, it performs the low-degree test between g and its planes table.
Second, it performs the simultaneous low-degree test between the ci ’s and their plane table. Both
of these use the degree parameter d = Θ((n′ )2 ), which is chosen to upper-bound both Θ(mh)
′
and Θ(mh + hn′ ). Finally, it picks a uniformly random (x, b, w) ∈ Fm
q and checks the equality
satψ,g (x, b, w) = zeroH,c (x, b, w). It accepts if all the tests accept individually.
When ψ is satisfiable, there is always a proof that makes the verifier accept with probability 1. This entails setting g to be the low-degree encoding of a satisfying assignment, and setting
c1 , . . . , cm′ to be the coefficient polynomials of satψ,g . The following proposition shows that when ψ
1
.
is not satisfiable, the verifier always rejects with probability at least 10
Proposition 11.8. If the verifier accepts with probability at least 9/10, then ψ is satisfiable.
Proof. If the verifier accepts with probability at least 9/10, then each individual test accepts with
probability at least 9/10. Applying Theorems 3.12 and 3.19, we get degree-d functions g : Fnq → Fq
′
and c1 , . . . , cm′ : Fm
q → Fq such that
dist(g, g) ≤

2
10 ,

dist(c, c) ≤

2
10 ,

dist(satψ,g , zeroH,c ) ≤

1
10 .

(Here, we are assuming that q is a sufficiently large function of m and h.) By the union bound,
dist(satψ,g , satψ,g ) ≤ 3dist(g, g). As a result, by the triangle inequality
dist(satψ,g , zeroH,c ) ≤ dist(satψ,g , satψ,g ) + dist(satψ,g , zeroH,c ) + dist(zeroH,c + zeroH,c )
≤ 3dist(g, g) + dist(satψ,g , zeroH,c ) + dist(c, c) ≤ 3 ·

By Lemma 11.7, ψ is therefore satisfiable.

76

2
10

+

2
10

+

1
10

=

9
10 .

Time and communication complexity.
◦ Question length: The verifier performs two low-degree tests and draws a random point in
′
′
′
Fm
q . These are of size Θ(m log(q)), Θ(m log(q)), and Θ(m log(q)), respectively, all of which
are O(n′ ) bits.
◦ Answer length: The verifier performs one normal low-degree test, and then a second lowdegree test with answer complexity m′ times the normal answer complexity. These are of
total length (m′ + 1) · d2 log(q) = O((n′ )9 ). Finally, in the last test, it queries each of g and
c1 , . . . , cm′ for a point in Fq , a total communication cost of (m′ + 1) log(q) = O(n′ ). In total,
the answer length is poly(n′ ).
◦ Runtime: The verifier runs in time poly(n′ ). This includes computing satψ,g (x, b, w), which
requires computing gψ (x, b, w), taking time poly(n′ , h, q) = poly(n′ ).

12
12.1

NEEXP preliminaries
Introspection games

In this section, we introduce introspection games. These are games in which, rather than the verifier
sampling the questions, the provers sample them instead.
Definition 12.1 (Introspection games). An introspection game is played between two provers Alice
and Bob in which Alice returns two strings xA and a and Bob returns two strings xB and a′ (the
verifier does not specify a question). Here, xA and xB are interpreted as Alice and Bob’s “share” of
the jointly sampled “question” x = (xA , xB ), and a and a′ are interpreted as their “answers”. The
verifier then applies its evaluation function V to the answers and accepts if V (xA , xB , a, b) = 1.
The following three facts show that we can convert between strategies for a “normal” game and
strategies for an introspective version of the game. This allows us to prove soundness results for
the “normal” game and “bootstrap” them up to the introspective game as well.
Fact 12.2. This fact concerns two games and two strategies.
1. Let Gintro be the introspective game with evaluation function V . Consider a strategy Sintro
for Alice and Bob with shared state |introi = |questioni ⊗ |answeri in which Alice and Bob’s
measurements are given by
{PxA ⊗ AxaA }xA ,a ,

{QxB ⊗ Bax′B }xB ,a′ ,

respectively. Write D for the distribution on outcomes (xA , xB ) when the measurement {PxA ⊗
QxB }xA ,xB is performed on |questioni.
2. Let G be the “normal” game played as follows: sample x = (xA , xB ) ∼ D. Distribute the
questions as follows:
◦ Alice: give xA ; receive a.

◦ Bob: give xB ; receive b.

Accept if V (xA , xB , a, b) = 1. Write S for the strategy with shared state |answeri in which
Alice’s strategy is {AxaA }a and Bob’s strategy is {Bax′B }a′ .
Then valG (S) = valGintro (Sintro ).
77

Fact 12.3. Let {Axa }x and {Bax }x be measurements such that
Axa ⊗ IBob ≈δ Bax ⊗ IBob

(59)

on state |answeri and distribution D. Next, let {Qx }x be a measurement and |questioni be a bipartite
state such that the distribution of measurement outcomes produced by measuring {Qx ⊗ IBob }x on
|questioni is D. Then
(Qx ⊗ Axa )Alice ⊗ IBob ≈δ (Qx ⊗ Bax )Alice ⊗ IBob

(60)

on state |questioni ⊗ |answeri. Moreover, if Qx is a projective measurement, then the reverse
implication holds: if Equation (62) holds on |questioni ⊗ |answeri, then Equation (61) holds on the
state |answeri.
Proof. First, we show the forward implication. By definition, we want to bound
X
k(Qx ⊗ Axa ⊗ IBob − Qx ⊗ Bax ⊗ IBob ) |questioni ⊗ |answeri k2
x,a

=

X
x,a

=

X
x,a

≤

X
x,a

=E
x

=E
x

k(Qx ⊗ I)question ⊗ (Axa ⊗ I − Bax ⊗ I)answer |questioni ⊗ |answeri k2

hquestion| ⊗ hanswer| (Qx ⊗ I)2question ⊗ (Axa ⊗ I − Bax ⊗ I)2answer |questioni ⊗ |answeri
hquestion| ⊗ hanswer| (Qx ⊗ I)question ⊗ (Axa ⊗ I − Bax ⊗ I)2answer |questioni ⊗ |answeri

X
a

X
a

x
2
hanswer| (Ax
a ⊗ I − Ba ⊗ I) |answeri
2
2
x
k(Ax
a ⊗ I − Ba ⊗ I) |answeri k .

But this is at most δ by assumption. Now, for the reverse implication, note that if Qx is projective,
then the inequality above becomes an equality.
Fact 12.4. Let {Axa }x and {Bax }x be measurements such that
(Axa )Alice ⊗ IBob ≃δ IAlice ⊗ (Bax )Bob

(61)

on state |answeri and distribution D. Next, let {Qx }x be a measurement and |questioni be a bipartite
state such that
(Qx )Alice ⊗ IBob ≃δ IAlice ⊗ (Qx )Bob
on |questioni. Furthermore, suppose that the distribution of measurement outcomes produced by
measuring {(Qx )Alice ⊗ IBob }x on |questioni is D. Then
(Qx ⊗ Axa )Alice ⊗ IBob ≃δ IAlice ⊗ (Qx ⊗ Bax )Bob
on state |questioni ⊗ |answeri.

78

(62)

12.2

Subroutines and superregisters

In the next few sections, we will design a set of protocols to be used as a subroutine for our main
NEEXP protocol. In doing so, we will encounter the following notational difficulty: a subroutine G
might be a λ = (k, n, q)-register game, whereas the overall protocol which calls it might be a
µ = (ℓ, m, q)-register game. When λ is not equal to µ, how can we use G ? We will consider two
answers to this question. In both of them, we will consider the case when all the register field sizes
are the same value “q”, as this is the case relevant to our application.
Notation 12.5. First, the registers in λ might appear as a subset of the registers in µ. In this case,
we will specify an injection κ : [k] → [ℓ] such that ni = mκ(i) . Given a string W = (W1 , . . . , Wk ),
we write κ(W ) for the length-ℓ string with Wκ(i) in coordinate i, for each i, and the “hide” symbol
H in the remaining coordinates. Similarly, given string a = (a1 , . . . , aℓ ), we write κ−1 (a) for the
length-k string with aκ(i) in its i-th coordinate. Then playing G on registers κ(1), . . . , κ(k) means
to do the following.
1. Draw (x, x′ ) from G .
2. Send (κ(x1 ), x2 ) to Alice and (κ(x′1 ), x′2 ) to Bob.
3. Receive a, a′ . Accept if G accepts on the answers (κ−1 (a1 ), a2 ) and (κ−1 (a′1 ), a′2 ).
Notation 12.6. Second, the registers in λ might appear as the concatenation of register in µ. In
this case, we will specify concatenation lengths c(1) + · · · + c(k) = ℓ such that n1 = m1 + · · · + mc(1) ,
n2 = mc(1)+1 + · · · + mc(1)+c(2) . Pictorially, the first register in λ will be created as the following
concatenation:
n
n
|EPRnq 1 i ⊗ |EPRnq 2 i ⊗ · · · ⊗ |EPRq c(1)−1 i ⊗ |EPRq c(1) i .
{z
}
|
n1 +···+nc(1)

|EPRq

i

We refer to these concatenations of registers as superregisters. A Pauli basis query W ∈ {X, Z, H, ⊥}
to a given superregister R can be simulated as follows:

1. Implement each Pauli basis query W by sending W to each register ri1 , . . . , ric in the superregister.
2. If W ∈ {X, Z}, the prover measures τuWi on each register ri in R, and the verifier receives the
mi
m
outcomes ui1 ∈ Fq 1 , . . . , uic ∈ Fq ic , concatenated as u = (ui1 , . . . , uic ).
3. If W = H, the prover performs I ⊗ . . . ⊗ I on the registers in the superregister, and verifier
| {z }
c

receives c consecutive ∅’s, interpreted as a single ∅.

4. If W = ⊥, the prover may perform any measurement it likes on the registers in the superregister. The verifier receives c consecutive ∅’s, interpreted as a single ∅.

The game G will usually be proven sound against λ-register strategies, but in our cases it will
be straightforward to extend this soundness to µ-register strategies in the case when G is applied
as a subroutine as detailed above. For example, suppose we know that a strategy A which passes G
with probability 1 − ǫ must satisfy (Aa )Alice ⊗ IBob ≈δ (Ba )Alice ⊗ IBob . Then it is straightforward to
derive that if G is played as a subroutine on the second register of µ (this is the case when k = 1
and n1 = m2 ), and if A passes the subroutine with probability 1 − ǫ, then
(Aa )Alice ⊗ IBob ≈δ (I1 ⊗ (Ba )2 ⊗ I3,...,ℓ )Alice . ⊗ IBob
79

Likewise, suppose G is played as a subroutine on one superregister consisting of all the registers
of µ (this is the case when k = 1 and n1 = m1 + · · · + mℓ ). If A passes the subroutine with
probability 1 − ǫ, then
(Aa )Alice ⊗ IBob ≈δ ((Ba )1,...,ℓ )Alice ⊗ IBob .
For our applications, it will be straightforward to extend the soundness of our games to the case
when they are played as subroutines, and we will leave this step implicit in our proofs.

13

The introspective low-degree test

In this section, we give the introspective low-degree test. This is an introspection game which
simulates the classic surface-versus-point test, but is able to reduce the question complexity by
making the provers sample the questions themselves. We allow for a fully general k-dimensional
surface, though in our application we will only use k = 1 (lines) and k = 2 (planes).
Given an integer n > 0 and a power of two q, the introspective low-degree test is a (k + 1, n, q)register game. In other words, the provers share a state of the following form:
|ψi = |EPRnq i0 ⊗ |EPRnq i1 ⊗ · · · ⊗ |EPRnq ik ⊗ |auxiaux .
The intended behavior is this: the “points” prover should measure the point u ∈ Fnq from register 0.
The “surface” prover should measure directions v = {v 1 , . . . , v k } from registers 1 through k and
then should receive their surface s from the surface measurement {Πvs }s∈Surfacesv on register 0.
If the provers act honestly, then u will be a uniformly random point in s, generating the same
distribution as the questions in the surface-versus-point low-degree test.
The key difficulty is preventing the surface prover from fully measuring the register 0 and thus
learning the value of the point u. In this section, we design a test to enforce this behavior on
the surface prover, using an introspected version of the partial data-hiding game developed in
Section 10. This game lets us command the surface prover to erase all information about u except
its value modulo linear combinations of the directions v1 , . . . , v k ; we give it in Section 13.1 below.
We use this test in Section 13.4 to design the introspective low-degree test and prove its soundness.

13.1

Introspected partial data-hiding

In this section, we give an introspected version of the partial data-hiding game, which will be used
to implement the surface and intercept-scrambling measurements described above.
Definition 13.1. Let k, n > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q)
be register parameters. Let x be an arbitrary query. Then the introspected partial data-hiding
game GIntroHide (λ, x) is given in Figure 6.
The performance of the introspected partial data-hiding game is given in the following theorem.
Theorem 13.2. Let k, n > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q) be register
parameters. Let x be an arbitrary query. Then GIntroHide := GIntroHide (λ, x) satisfies the following
two properties.
◦ Completeness: Let Spartial = (ψ, M ⊥,Z,...,Z,x) be a partial λ-register strategy for GIntroHide ,
which is also a real commuting EPR strategy, and for which
X
⊥,Z,...,Z,x
Πvs ⊗ τvZ1 ⊗ . . . ⊗ τvZk ⊗ Ax,s,v
M∅,v
=
a2 ,
1 ,...,vk ,a2
s∈Surfacesv

80

Flip an unbiased coin b ∼ {0, 1}, and perform one of the following three tests with probability 1/3
each.
1. Distribute the questions as follows:
◦ Player b: Give (⊥, Z, . . . , Z , x); receive (∅, v 1 , . . . , v k , a2 ).
| {z }
k

◦ Player b: Give (Z, Z, . . . , Z , x); receive (a′1 , v 1 , . . . , v k , a′2 ).
| {z }
k

Accept if a2 = a′2

2. Distribute the questions as follows:
◦ Player b: Give (⊥, Z, . . . , Z , x); receive (∅, v 1 , . . . , v k , a2 ).
| {z }
k

◦ Player b: Give (⊥, Z, . . . , Z , x, {X}); receive (∅, v 1 , . . . , v k , a′2 , {a′1,1 , . . . , a′1,k }).
| {z }
k

Accept if a2 = a′2 .

3. Distribute the questions as follows:
◦ Player b: Give (X, Z, . . . , Z , ∅); receive (a1 , v 1 , . . . , v k , ∅).
| {z }
k

◦ Player b: Give (⊥, Z, . . . , Z , ⊥, {X}); receive (∅, v ′1 , . . . , v ′k , ∅, {a′1,1 , . . . a′1,k }).
| {z }
k

Accept if v i = v ′i and a′1,i = v i · a1 for all i ∈ {1, . . . , k}.
4. Distribute the questions as follows:

◦ Player b: Give (⊥, x, Z, . . . , Z , {X}); receive (∅, v 1 , . . . , v k , a2 , {a1,1 , . . . , a1,k }).
| {z }
k

◦ Player b: give (⊥, ⊥, Z, . . . , Z , {X}); receive (∅, v ′1 , . . . , v ′k ∅, {a′1,1 , . . . , a′1,k }).
| {z }
k

Accept if a1,i =

a′1,i

for all i ∈ {1, . . . , k}.

Figure 6: The introspected partial data-hiding game GIntroHide (λ, x).

81

for some measurement Ax,s,v
acting only on the aux register. Then there is a value-1 λ-register
a2
strategy for GIntroHide extending Spartial which is also a real commuting EPR strategy.
◦ Soundness: Let S = (ψ, M ) be a projective λ-register strategy passing GIntroHide with probability at least 1 − ǫ. Then there exists an ideal measurement Mv′x1 ,...,vk ,a2 with the property
that


X
Πvs ⊗ (Max,s,v
)aux  ,
Mv′x1 ,...,vk ,a2 = τvZ1 ⊗ . . . ⊗ τvZk ⊗ 
2
s∈Surfacesv

such that the measurement

⊥,Z...,Z,x
M∅,v
1 ,...,vk ,a2

used by strategy S in response to the query (⊥, Z, . . . , Z , x)
| {z }
k

is close to Mv′x1 ,...,vk ,a2 :

(Ma⊥,Z,...,Z,x
)Alice ⊗ IBob ≈ǫ (Ma′x2 )Alice ⊗ IBob .
2

Proof. We first show completeness. Very similarly to the non-introspected partial data-hiding game,
we introduce measurements for the remaining questions as follows:
X
(Πvs · τaZ1 ) ⊗ τvZ1 ⊗ . . . ⊗ τvZk ⊗ Ax,s,v
MaZ,Z,...,Z,x
=
a2 ,
,v
,...,v
,a
1 1
k 2
MaX,Z,...,Z
1 ,v1 ,...,vk
⊥,Z,...,Z,x,{X}
M∅,v1 ,...,vk ,a2 ,{a1,1 ,...,a1,k }

=

=

s∈Surfacesv
τaX1 ⊗ τvZ1 ⊗

X

s∈Surfacesv
⊥,Z,...,Z,{X}
M∅,v1 ,...,vk ,∅,{a1,1 ,...,a1,k }

. . . ⊗ τvZk ⊗ Iaux ,

X
(Πvs · τ[∀i,a
) ⊗ τvZ1 ⊗ . . . ⊗ τvZk ⊗ Ax,s,v
a2 ,
1 ·vi =a1,i ]

X
= τ[∀i,a
⊗ τvZ1 ⊗ . . . τvZk .
1 ·vi =a1,i ]

By essentially the same arguments as in the proof of Theorem 10.4, it follows that these measurements define a value-1 real commuting EPR strategy for GIntroHide .
We now show soundness. Suppose that the provers succeed in the game with probability 1 − ǫ
using a λ-register strategy. From the definition of a register strategy, we know that the measurement
operators used by the provers have the following form.
⊥,Z,...,Z,x
1 ,...,vk
M∅,v
= (Ax,v
)1,aux ⊗ τvZ1 ⊗ · · · ⊗ τvZk ,
a2
1 ,...,vk ,a2

⊥,Z,...,Z,x,{X}
′
′
k ,a2 ,{a1,1 ,...,a1,k }

M∅,v1 ,...,v

1 ,...,vk
= (Bax,v
′ ,...,a′
2 ,{a
1,1

1,k }

)1,aux ⊗ τvZ1 ⊗ · · · ⊗ τvZk ,

1 ,v1 ,...,vk
MaZ,Z...,Z,x
= τaZ1 ⊗ τvZ1 ⊗ · · · ⊗ τvZk ⊗ (Cax,a
)aux ,
1 ,v1 ,...,vk ,a2
2

⊥,Z,...,Z,⊥,{X}

Z
Z
1 ,...,vk
M∅,v1 ,...,vk ,∅,{a1,1 ,...,a1,k } = (Dav1,1
,···a1,k )1,aux ⊗ τv1 ⊗ . . . ⊗ τvk .
1 ,...,vk
1 ,...,vk
where the operators {Ax,v
}, {Bax,v
′ ,...,a′
a2
2 ,{a
1,1

1,k }

1 ,v1 ,...,vk
k
}, {Cax,a
}, and {Dav11,1,...,v
,...,a1,k } form valid
2

POVMs for every choice of x, a1 , v1 , . . . , vk . We further know that the shared state of the provers
is of the form
|ψi = |EPRnq i0 ⊗ |EPRnq i1 ⊗ · · · ⊗ |EPRnq ik ⊗ |auxiaux .
From success in the four parts of the test, we may also deduce the following conditions:
) ,
)
⊗ IBob ≃ǫ IAlice ⊗ (MvZ,Z,...,Z,x
(Ma⊥,Z,...,Z,x
1 ,...,vk ,a2 Bob
2 ,v1 ,...,vk Alice

),
)
⊗ IBob ≃ǫ IAlice ⊗ (Ma⊥,Z,...,Z,x,{X}
(Ma⊥,Z,...,Z,x
2 ,v1 ,...,vk
2 ,v1 ,...,vk Alice

⊥,Z,...,Z,⊥,{X}

X
(Mv1 ,...vk ,{a1,1 ,...,a1,k } )Alice ⊗ IBob ≃ǫ IAlice ⊗ (τ[∀i,a
⊗ τvZ1 ⊗ . . . ⊗ τvZk ⊗ Iaux )Bob ,
1 ·vi =a1,i ]
⊥,Z,...,Z,x,{X}

⊥,Z,...,Z,⊥,{X}

(Mv1 ,...,vk ,{a1,1 ,...,a1,k } )Alice ⊗ IBob ≃ǫ IAlice ⊗ (Mv1 ,...,vk ,a2 ,{a1,1 ,...,a1,k } )Bob .
82

We would now like to argue that the operators A, B, C, D form a good strategy for the partial
data-hiding game. By Fact 12.3, it holds that under the uniform distribution over v1 , . . . , vk ,
X

1 ,v1 ,...,vk
1 ,...,vk
τaZ1 ⊗ Cax,a
,
(Ax,v
)
⊗
I
≃
I
⊗
ǫ
Alice
Bob
Alice
a2
2
Bob
1 ,...,vk
(Ax,v
)Alice
a2
x,v1 ,...,vk
(B{a1,1 ,...,a1,k } )Alice

v1 ,...,vk
(D{a
′ ,...,a′
1,1

1,k }

⊗

⊗

a1

1 ,...,vk
IBob ≃ǫ IAlice ⊗ Bax,v
,
2
Bob
v1 ,...,vk
IBob ≃ IAlice ⊗ (D{a1,1 ,...,a1,k } )Bob

X
)Alice ⊗ IBob ≃ǫ IAlice ⊗ (τ[a
′
1 ·v1 =a

′
1,1 ,...,a1 ·vk =a1,k ]

⊗ Iaux )Bob ,

as well as the same conditions with the Alice and Bob registers exchanged.
These are precisely the conditions of winning the partial data-hiding game Ghide (S, x), where
S is the set of all tuples v1 , . . . , vk in Fnq , with probability 1 − O(ǫ). Hence, by Theorem 10.4, it
1 ,...,vk
follows that there exists a measurement A′x,v
such that
a2
X
1 ,...,vk
Πvs ⊗ As,x,v
,
A′x,v
=
a
a2
1 ,...,vk
(Ax,v
)Alice
a2

⊗

s∈Surfacesv
1 ,...,vk
IBob ≈ǫ (Aa′x,v
)Alice
2

⊗ IBob .

The operator M ′ in the conclusion of the theorem can then be taken to be
1 ,...,vk
= (A′x,v
) ⊗ τvZ1 ⊗ . . . ⊗ τvZk .
Ma′⊥,Z,...,Z,x
a2
2 ,v1 ,...,vk

13.2

An introspective surface sampler

In this section, we will use the introspective data hiding game to implement the “surface prover”.
This is a prover who samples a surface s from register 0 using the Πv measurement and then
reports back s to the verifier, along with a degree-d polynomial f : s → Fq . As above, the prover
is expected not to measure register 0 any further, so that f depends only on s and v. We can
enforce this by running the introspective data hiding game and interpreting the provers’ answers
as a2 = {s, f }. However, we must also verify that s corresponds to the actual surface measured by
the prover in the 0-th register and not some other surface. We do this with a slight modification
to the introspective data hiding game we call the “introspective surface sampling game”.
Definition 13.3. Let k, n, d > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q)
be register parameters. Then the introspective surface sampling game GIntroSurfSamp (λ, d) is given
in Figure 7.
◦ Play the game GIntroHide (λ, x) with x = “surface”, and with the answer a2 taking the form
{s, f }, where s is a surface and f is a degree-d function f : s → Fq .
◦ Consider the test in Item 1 of GIntroHide (λ, x). Here, Player b replies with the answer
case where
(∅, v 1 , . . . , v k , {s, f }), and Player b replies with (a′1 , v 1 , . . . , v k , {s′ , f ′ }). In the P
this test is chosen, accept if GIntroHide (λ, x) accepts and also if s is the surface {a′1 + ki=1 λi v i :
λ1 , . . . , λk ∈ Fq }. (We call this additional check the “Correct Surface Check”.) If this query
is not given to the provers, then accept if GIntroHide (λ, x) accepts.
Figure 7: The game GIntroSurfSamp (λ, d).

83

Notation 13.4. In the case when a prover is given the question (⊥, Z, . . . , Z, “surface”), we refer
to it as the surface prover. It has the following intended behavior.
1. Surface prover:
Input: Pauli basis queries (⊥, Z, . . . , Z ) and an auxiliary query “surface”.
| {z }
k

Output: Pauli basis answers ∅ and v1 , . . . , vk ∈ Fnq , a k-dimensional surface s, and the
coefficients of a degree-d polynomial function f : Fkq → Fq , where the domain of f is to
interpreted as s.

Goal: The prover measures Πv on register 0 and sets s to be its outcome. They then set
f = g|s , where g : Fnq → Fq is a global degree-d polynomial selected independently of s
or v.
In the case when k = 1, we may also refer to it as the lines prover, and in the case when k = 2, we
may also refer to it as the planes prover. We will also refer to the surface prover’s measurement,
which refers to the measurement {Av1 ,...,vk ,s,f } given by
⊥,Z,...,Z,“surface”
Av1 ,...,vk ,s,f = M∅,v
.
1 ,...,vk ,s,f

The following theorem shows that the introspective surface sampling game forces the surface
prover to output the correct surface s.
Theorem 13.5. Let k, n, d > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q) be register
parameters. Write {Av1 ,...,vk ,s,f } for the surface prover’s measurement. Then GIntroSurfSamp :=
GIntroSurfSamp (λ, d) has the following two properties.
◦ Completeness: Suppose there is a degree-d polynomial g : Fnq → Fq such that
Av1 ...,vk ,s,f = Πvs ⊗ τvZ1 ⊗ · · · ⊗ τvZk ⊗ Iaux · 1[f = g|s ].
Then there is a value-1 λ-register strategy for GIntroSurfSamp with A as the surface prover’s
measurement.
◦ Soundness: Let S be a projective λ-register strategy which passes GIntroSurfSamp with probability at least 1 − ǫ. Then there exists an ideal measurement A′ of the form
A′v,s,f = Πvs ⊗ τvZ1 ⊗ . . . ⊗ τvZk ⊗ (Mfs,v )aux ,
with Mfs,v an arbitrary measurement on the aux register, such that A′ is close to the surface
provers’ measurement A in S:
(Av,s,f )Alice ⊗ IBob ≈poly(ǫ) (A′v,s,f )Alice ⊗ IBob .
In particular, the surface output by A′ is the same surface measured by A′ in register 0.
Proof. First, the completeness follows immediately from the completeness guarantee of Theorem 13.2.
Next, we show soundness. Passing with probability 1 − ǫ implies passing GIntroHide (λ, “surface”)
with probability 1 − ǫ. By Theorem 13.2, this implies an ideal measurement Mv′x1 ,...,vk ,s,f with the
property that


X
s′ ,v
)aux  ,
Πvs′ ⊗ (Ms,f
Mv′ 1 ,...,vk ,s,f = τvZ1 ⊗ · · · ⊗ τvZk ⊗ 
s′ ∈Surfacesv

84

Flip an unbiased coin b ∼ {0, 1}. Distribute the questions as follows.
◦ Player b: Give (⊥, Z, . . . , Z , “surface”); receive (∅, v 1 , . . . , v k , s, f ).
| {z }
k

◦ Player b: Give (Z, H, . . . , H , “point”); receive (u, ∅, . . . , ∅, ν), where ν ∈ Fq .
| {z }
| {z }
k

k

Accept if f (u) = ν.

Figure 8: The game GIntroCross (λ, d).
(Av1 ,...,vk ,s,f )Alice ⊗ IBob ≈ǫ (Mv′ 1 ,...,vk ,s,f )Alice ⊗ IBob .

(Note that the measured surface s′ in M ′ is allowed to be different than the output surface s.)
Next, set Bv1 ,...,vk ,s := Πvs ⊗ τvZ1 ⊗ · · · ⊗ τvZk ⊗ Iaux . Then passing the Correct Surface Check with
probability 1 − O(ǫ) implies that
(Av,s )Alice ⊗ IBob ≈ǫ IAlice ⊗ (Bv,s )Bob .
′
′
′
, then
· Bv,s = Bv,s · Mv,s,f
and Bv,s commute. Thus, if we define Cv,s,f := Mv,s,f
Note that Mv,s,f
by Fact 4.20,

(Av,s,f )Alice ⊗ IBob = (Av,s,f · Av,s )Alice ⊗ IBob
≈ǫ (Av,s,f )Alice ⊗ (Bv,s )Bob

′
)Alice ⊗ (Bv,s )Bob
≈ǫ (Mv,s,f

′
· Bv,s )Alice ⊗ IBob
≈ǫ (Mv,s,f

= (Cv,s,f )Alice ⊗ IBob ,

s,v
. Then we can write
where the second-to-last step is by Fact 4.38. Now, set Cfs,v := Ms,f

Cv1 ,...,vk ,s,f = Πvs ⊗ τvZ1 ⊗ · · · ⊗ τvZk ⊗ (Cfs,v )aux .
These matrices are almost of the form guaranteed by the theorem, except they do not necessarily
form a measurement because the matrices Cfs,v do not necessarily sum to the identity. However,
this is still sufficient to imply the theorem by Fact 4.25.

13.3

The introspective cross-check

In this section, we introduce the other subroutine in the introspective low-degree test. In this
subroutine, known as the “introspective cross-check”, we introduce a new prover known as the
“points prover”. This is a prover who samples a point u from register 0 and then reports back a
value ν ∈ Fq interpreted as their assignment to the point u. By data hiding, we can assume the
points prover does not read registers 1 through k. Then the introspective cross-check queries the
points prover and the surface prover and checks that their outputs agree on the point u.
Definition 13.6. Let k, n, d > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q) be
register parameters. The introspective cross-check, denoted GIntroCross (λ, d), is defined in Figure 8.
Notation 13.7. In the case when a prover is given the question (Z, H, . . . , H, “point”), we refer
to it as the points prover. It has the following intended behavior.
85

2. Points prover:
Input: Pauli basis queries (Z, H, . . . , H) and auxiliary query “point”.
Output: String u ∈ Fnq and ∅, . . . , ∅. A number ν ∈ Fq .

Goal: The prover sets ν = g(u), where g : Fnq → Fq is a global degree-d polynomial selected
independently of u.

We will also refer to the point prover’s measurement, which refers to the measurement {Bu,ν } given
by
Z,H,...,H,“point”
Bu,ν = Mu,∅,...,∅,ν
.
Our next lemma shows that if the surface prover’s measurement for f depends only on the
surface s and directions v and not on the point u, then we can relate the value of the introspective
cross-check to its non-introspected variant, Gsurface .
Lemma 13.8. Let k, n, d > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q) be register
parameters. Let S be a λ-register strategy for GIntroCross := GIntroCross (λ, d). Let {Av,s,f } be the
surface prover’s measurement and {Bu,ν } be the point prover’s measurement, and write |auxi for
the auxiliary state. Suppose
Av,s,f = Πvs ⊗ τvZ1 ⊗ · · · ⊗ τvZk ⊗ As,v
f ,
Bu,ν = τuZ ⊗ I ⊗ . . . ⊗ I ⊗Bνu ,
| {z }
k

u
where {As,v
f } and {Bν } are POVM measurements on the auxiliary register. Consider the strategy
s,v
Ssurface = (aux, {A , B u }) for the game Gsurface := Gsurface (n, q, k, d). Then

valGsurface (Ssurface ) = valGIntroCross (S).
Proof. By the definition of Πvs and τuZ , it follows that for any choice of k vectors v, if Alice and
Bob each measure their half of register 0 using the measurements Πvs and τuZ , respectively, then
the measurement outcomes obtained will be pairs (s, u) where s is a uniformly random surface in
Surfacesv and u is a uniformly random point in s. Moreover, if Alice measures her half of registers 1
through k, she will obtain a uniformly random k-tuple v = {v 1 , . . . , v k } ⊆ Fnq . Combining these
facts, we see that if Alice measures her half of registers 0 through k with Πvs ⊗ τvZ1 ⊗ . . . ⊗ τvZk , and
Bob measure his half with τuZ ⊗ I ⊗ . . . ⊗ I , they obtain a pair of outcomes (xA = (s, v), xB = u)
| {z }
k

distributed exactly according to the question distribution in Gsurface . Thus, applying Fact 12.2, we
conclude that valGsurface (Ssurface ) = valGIntroCross (S).

13.4

The introspective low-degree test

In this section, we state the completed introspective low-degree test.
Definition 13.9. Let k, n, d > 0 be integers, let q be a power of 2, and let λ = (k+1, n, q) be register
parameters. The introspective surface-versus-point low-degree test, denoted G := GIntroLowDeg (λ, d),
is defined in Figure 9. It has the following properties:
Q-length(G ) = O(1),
Q-time(G ) = O(1),

A-length(G ) = O(kn log(q) + (d + k)k log(q)),
A-time(G ) = poly(kn log(q), (d + k)k log(q)).
86

With probability

1
2

each, perform one of the following three tests.

1. Surface sampler test: Play GIntroSurfSamp (λ, d).
2. Cross-check test: Play GIntroCross (λ, d).
Figure 9: The game GIntroLowDeg (λ, d).
The question complexities are immediate. As for the answer length, the provers return (k + 1)
elements of Fnq and degree-d polynomials on k-surfaces, encoded as Fq -valued strings of length
d[k] ≤ (d + k)k . Finally, all operations made by the verifier, such as polynomial evaluation, are
efficient, so the answer time complexity is polynomial in the answer length.
Naturally, we analyze the introspective low-degree test via introspection. This involves a reduction to the non-introspected version of the game, i.e. the “normal” surface-versus-point low-degree
test. By Theorem 4.40 we know quantum soundness for this test in the k = 2 (i.e. planes) case. As
a result, we get soundness for the introspective low-degree test in this case as well.
Theorem 13.10. Fix k = 2. Let n, d > 0 be integers, let q be a power of 2, and let λ = (k + 1, n, q)
be register parameters. Write G := GIntroLowDeg (λ, d).
◦ Completeness: Suppose there is a degree-d polynomial g : Fnq → Fq such that
Bu,ν = τuZ ⊗ I1 ⊗ I2 ⊗ Iaux · 1[ν = g(u)].
Then there is a value-1 λ-register real commuting EPR strategy for G with B as the point
prover’s measurement.
◦ Soundness: There exists a constant c > 0 and a function δ(ǫ) = poly(ǫ, dm/q c ) such that the
following holds. Suppose S is a projective λ-register strategy with value 1 − ǫ. Write {Bu,ν }
for the point prover’s measurement. Then there exists a POVM {Gg } in PolyMeas(n, d, q)
such that
(Bu,ν )Alice ⊗ IBob ≈δ(ǫ) (τuZ ⊗ I1 ⊗ I2 ⊗ (G[g(u)=ν] )aux )Alice ⊗ IBob .
Proof. Throughout this proof, we will write {Av,s,f } for the surface prover’s measurement. We first
show completeness. Assign the surface prover’s measurement as follows:
Av,s,f := Πvs ⊗ τvZ1 ⊗ τvZ2 ⊗ Iaux · 1[f = g|s ].
This is clearly a λ-register strategy. By the completeness case of Theorem 13.5, this can be extended into a real commuting EPR strategy that passes GIntroSurfSamp (λ, d) with probability 1.
By Lemma 13.8, the strategy using A and B passes the cross check with the same probability as
the honest classical strategy to Gsurface (n, q, k, d) answering according to the low-degree polynomial
g, which is 1. Hence, this strategy passes both parts of G with probability 1.
Now, we show soundness. The strategy S is a λ-register strategy, so we can write the points
prover’s measurement as
Bu,ν = τuZ ⊗ I1 ⊗ I2 ⊗ (Bνu )aux .

Passing GIntroSurfSamp (λ, d) with probability 1 − 2ǫ implies via Theorem 13.5 a measurement A′u,v,f
such that
A′v,s,f = Πvs ⊗ τvZ1 ⊗ τvZ2 ⊗ ((A′ )s,v
f )aux ,
87

(Av,s,f )Alice ⊗ IBob ≈poly(ǫ) (A′v,s,f )Alice ⊗ IBob ,

where {(A′ )s,v
f }f is a measurement on the auxiliary register. By assumption, the measurement
{Av,s,f } is projective, so we can apply Fact 4.31 to deduce that replacing Av,s,f by A′v,s,f changes
the game value by at most poly(ǫ). Moreover, by applying Theorem 4.2, we can, by performing a
dilation of the auxiliary space, simulate the A′v,s,f measurements by a projective measurement of
the form
A′′v,s,f = Πvs ⊗ τvZ1 ⊗ τvZ2 ⊗ ((A′′ )s,v
f )aux ,

where (A′′ )s,v
f is a projective measurement on the (expanded) aux register. (Note that a direct
invocation of Naimark’s theorem Theorem 4.1 would not have sufficed as the dilated measurement
would not necessarily act as desired on the non-aux registers.) Using the dilated A′′ measurements
instead of A′ does not change the value of the game. Thus, we deduce that the projective strategy
using measurements Bu,ν and A′′v,s,f passes GIntroCross (λ, d) with probability 1 − poly(ǫ).
Now we are in a position to reduce to the soundness of the non-introspective game. Define
the strategy SPlane := (aux, {B u , (A′′ )s,v }). Then by Lemma 13.8, SPlane also passes GPlane with
probability 1 − poly(ǫ). Applying Theorem 4.40, we have that there exists a measurement {Gg } in
PolyMeas(n, d, q) such that
Bνu ⊗ I ≈δ(ǫ) G[ν=g(u)] ⊗ I
on state |auxi.
The theorem then follows from Fact 12.3.

13.5

The introspective simultaneous low-degree test

In this section, we extend the introspective low-degree test to handle multiple functions at once.
This is the introspective version of the simultaneous low-degree test from Definition 3.13.
Definition 13.11. Let m ≥ 1. Let k, n, d > 0 be integers, let q be a power of 2, and let λ =
(k + 1, n, q) be register parameters. The introspective simultaneous low-degree test, denoted G :=
GIntroLowDeg (λ, d, m), is defined by the following modifications to the introspective low-degree test.
First, the prover roles are modified as follows.
◦ Surface prover: Rather than returning a function f : s → Fq , it should return m functions
f1 , . . . , fm : s → Fq . The intent is that fi = gi |s for each i, where each gi : Fnq → Fq is a global
degree-d polynomial selected independently of s or v.
◦ Points prover: Rather than returning a single number ν ∈ Fq , it should return m numbers ν1 , . . . , νm ∈ Fq . The intent is that νi = gi (u) for each i, where each gi is selected
independently of u.
Next, the subroutines are modified as follows.
◦ Introspective surface sampling game: The answer a2 has the form s, f 1 , . . . , f m (rather
than s, f for a single function f ).
◦ Introspective cross-check: Receive f 1 , . . . , f m : s → Fq from the surface prover and
ν 1 , . . . , ν m ∈ Fq from the points prover (rather than a single f and ν). Check that f i (u) = ν i
for all i.
It has the following properties:
Q-length(G ) = O(1),
Q-time(G ) = O(1),

A-length(G ) = O(kn log(q) + m(d + k)k log(q)),
A-time(G ) = poly(kn log(q), m(d + k)k log(q)).
88

The following theorem gives the performance of the introspective simultaneous low-degree test
in the case of k = 2 (i.e. planes).
Theorem 13.12. Fix k = 2. Let n, d, m > 0 be integers, let q be a power of 2, and let λ =
(k + 1, n, q) be register parameters. Write G := GIntroLowDeg (λ, d, m).
◦ Completeness: Suppose there are degree-d polynomials g1 , . . . , gm : Fnq → Fq such that
Bu,ν1,...,νm = τuZ ⊗ I1 ⊗ I2 ⊗ Iaux · 1[∀i, νi = gi (u)].
Then there is a value-1 λ-register real commuting EPR strategy for G with B as the point
prover’s measurement.
◦ Soundness: There exists a constant c > 0 and a function δ(ǫ) = poly(ǫ, d(n + m)/q c ) such
that the following holds. Suppose S is a projective λ-register strategy with value 1 − ǫ. Write
{Bu,ν1 ,...,νm } for the point prover’s measurement. Then there exists a POVM {Gg1 ,...,gm }
in PolyMeas(n, d, q, m) such that
(Bu,ν1 ,...,νm )Alice ⊗ IBob ≈δ(ǫ) (τuZ ⊗ I1 ⊗ I2 ⊗ (G[g1 (u),...,gm (u)=ν1 ,...,νm ] )aux )Alice ⊗ IBob .
The proof, which we omit, is analogous to the proof of Theorem 13.10, except rather than
reducing to Theorem 4.40, we reduce to the soundness of the non-introspective simultaneous lowdegree test given by Theorem 4.43.

14

The intersecting lines test

The introspective low-degree test forces a prover to sample a point from a register and return the
evaluation of a global function at that point. In our eventual protocol, we will want the prover to
use the same global function to answer point queries sampled from multiple different registers. In
this section, we design a game which allows us to “transfer” global functions used from one register
to another. We keep in mind the following picture:
|ψi = |EPRnq i1 ⊗ |EPRnq i2 ⊗ |auxiaux .
We view register 1 as the register with the global function and register 2 as the register we would
like to transfer this global function to.
To accomplish this, we introduce a new test called the “intersecting lines test”. This involves
performing two introspective line-versus-point low-degree tests. The first uses register 1 as its
point register and register 2 as its slope register. This gives us a points prover who samples u from
register 1 and returns a label on it and a line prover who samples v from register 2 and returns
a function on the line {u + λv}, and we know that if the points prover labels their point using a
low-degree polynomial g, then the line prover must label their line with the same polynomial g.
The second low-degree test uses register 2 as its point register and register 1 as its slope register.
This gives a second line prover who returns a function on the line {v + λu}. Noting that the point
u + v is contained in both line provers’ lines, we can check consistency between their functions by
comparing them on this point, forcing the second line prover to label their line using g as well.
This then entails that the second line prover from the second low-degree test must also label their
point v using g. Thus, we have successfully “transferred” the function g from the first register to
the second.
In Section 14.1, we first introduce the intersecting lines test and prove soundness. Following
that, in Section 14.2 we introduce an introspective version of this test which will later be used in
our NEEXP protocol.
89

14.1

The intersecting lines test

Definition 14.1 (Intersecting lines test). Let n, d > 0 be integers, and let q be a power of 2.
The intersecting lines test, denoted Gintersect (n, q, d), is defined as follows. Sample u, v uniformly at
random from Fnq , and let ℓ and ℓ′ be the two lines ℓ := {u+λv : λ ∈ Fq } and ℓ′ := {v+λu : λ ∈ Fq }.
The test is performed as follows.
◦ The line ℓ and v are given to Alice, who responds with a degree-d polynomial f : ℓ → Fq .

◦ The line ℓ′ and u are given to Bob, who responds with a degree-d polynomial f ′ : ℓ′ → Fq .

Alice and Bob pass the test if f (u + v) = f ′ (u + v).
We begin by showing that although Bob knows u, since he doesn’t know v, the point u + v
looks like a uniform point in ℓ′ to him.
Fact 14.2. Conditioned on ℓ′ and u, the point u + v is distributed as a uniformly random element
in ℓ′ .
Proof. Let w be a point in Fnq such that ℓ′ = {w + λu : λ ∈ Fq }. Then for any c ∈ Fq , ℓ′ is also
equal to the set {(w + cu) + (λ − c)u : λ ∈ Fq }. Hence, v is equally likely to be any element in the
set {w + cu : c ∈ Fq }, and therefore so is u + v. Since this set is also equal to ℓ′ , this proves the
fact.
We will be interested in the case when Alice responds using a global function g : Fnq → Fq , always
setting f = g|ℓ . In this case, the following lemma shows that to succeed with high probability, Bob
must usually play the same global function as Alice.
Lemma 14.3. Let (ψ, M ) be a POVM strategy for the intersecting lines game with value 1 − ǫ.
Suppose further that there is a measurement {Gg }g in PolyMeas(n, d, q) such that Mfℓ,v = G[g|ℓ =f ] .
Then
′
(Mfℓ ,u )Alice ⊗ IBob ≃ǫ+d/q IAlice ⊗ (G[g|ℓ′ =f ] )Bob .
Proof. Success on the test implies that
′

,u
)Bob .
(G[g(u+v)=ν] )Alice ⊗ IBob ≃ǫ IAlice ⊗ (M[fℓ (u+v)=ν]

But by Fact 14.2, conditioned on ℓ′ and u, u + v is distributed as a uniformly random point in ℓ′ .
As a result, if we let w be a uniformly random point in ℓ′ , then
′

,u
(G[g(w)=ν] )Alice ⊗ IBob ≃ǫ IAlice ⊗ (M[fℓ (w)=ν]
)Bob .

The lemma then follows from Proposition 4.42.

14.2

The introspective intersecting lines test

Now we introduce the introspective intersecting lines test. This will be an introspective version of
the intersecting lines test.
Definition 14.4. Let n, d > 0 be integers, let q be a power of 2, and let λ = (2, n, q) be register
parameters. The introspective intersecting lines test, denoted GIntroIntersect (λ, d), is a λ-register game
involving two registers, named “1” and “2”, and a possible third auxiliary register. It involves two
line-versus point low-degree tests, instantiated as follows.
90

With probability

1
4

each, perform one of the following four tests.

1. Low degree test 1: Play G1 .
2. Low degree test 2: Play G2 .
3. Intersecting lines test: Flip an unbiased coin b ∼ {0, 1}. Assign the first role to Player b
and the second role to Player b.
◦ Lines1 : Receive ℓ, v, f : ℓ → Fq .

◦ Lines2 : Receive ℓ′ , u, f ′ : ℓ′ → Fq .

Accept if ℓ and ℓ′ both contain u + v and f (u + v) = f ′ (u + v).
4. Consistency test: Assign the first role to Player 1 and the second role to Player 2.
◦ Points1 : Receive ν.

◦ Points1 : Receive ν ′ .

Accept if ν = ν ′ .
Figure 10: The game GIntroIntersect (λ, d).
◦ Let G1 be a copy of GIntroLowDeg (λ, d) using register 1 as the point register and register 2 as
the slope register. Write Lines1 for the surface prover in G1 and write Points1 for the points
prover.
◦ Let G2 be a copy of GIntroLowDeg (λ, d) using register 2 as the point register and register 1 as
the slope register. Write Lines2 for the surface prover in G2 and write Points2 for the points
prover.
Then GIntroIntersect (λ, d) is defined in Figure 10.
Remark 14.5. We remark that although the test runs two separate introspective low-degree tests,
we cannot from these alone conclude that either of the points provers answers according to a
global function. This is because we use the lines (k = 1) introspective low-degree test, whereas
from Theorem 13.10 we only know soundness for the planes (k = 2) introspective low-degree test.
Hence, proving soundness for the introspective intersecting lines test will require an additional
assumption, i.e. that one of the two points provers already answers queries according to a global
function.
Our main result about the introspective intersecting lines test is the following theorem.
Theorem 14.6. Let n, d > 0 be integers, let q be a power of 2, and let λ = (2, n, q) be register
parameters. Write G := GIntroIntersect (λ, d). Write A for the point prover’s measurement in G1 , and
write B for the point prover’s measurement in G2 .
◦ Completeness: Suppose there is a degree-d polynomial g : Fnq → Fq such that
Au,ν = τuZ ⊗ I2 ⊗ Iaux · 1[ν = g(u)],

Bv,ν = I1 ⊗ τvZ ⊗ Iaux · 1[ν = g(v)].

Then there is a value-1 λ-register real commuting EPR strategy strategy for G extending A
and B.
91

◦ Soundness: There exists a function δ(ǫ) = poly(ǫ, d/q) such that the following holds. Let
S be a projective λ-register strategy which passes G with probability 1 − ǫ. Further, suppose
that there exists a projective measurement {Gg }g in PolyMeas(n, d, q) acting on the auxiliary
register such that
Au,ν = τuZ ⊗ I2 ⊗ G[g(u)=ν] .
Then
(Bv,ν )Alice ⊗ IBob ≈δ(ǫ) (I1 ⊗ τvZ ⊗ G[g(v)=ν] )Alice ⊗ IBob .
Furthermore,
Q-length(G ) = O(1),
Q-time(G ) = O(1),

A-length(G ) = O(n log(q) + d log(q)),
A-time(G ) = poly(n log(q), d log(q)).

Proof of Theorem 14.6. The runtime and communication complexities follows from the k = 1 case
of the low-degree test. The completeness follows immediately from the completeness of the introspective low-degree test.
Now, we show soundness. Write C for the line prover’s measurement in G1 , and write E for the
line prover’s measurement in G2 . We can write the point provers’ measurements as
Au,ν = τuZ ⊗ I2 ⊗ G[g(u)=ν] ,

Bv,ν = I1 ⊗ τvZ ⊗ Bνv .

The strategy passes the consistency test with probability 1 − δ(ǫ). As a result,
Au,ν ⊗ IBob ≃δ(ǫ) IAlice ⊗ Au,ν .
By Fact 12.2, this implies that
G[g(u)=ν] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(u)=ν]

(63)

on state |auxi and the uniform distribution on Fnq . By Fact 4.26, this implies that
G[g|ℓ =f ] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|ℓ =f ] ,

(64)

where ℓ is distributed as ℓ = {u + λv : λ ∈ Fq } for uniformly random u, v ∈ Fnq .
Next, the strategy passes both introspective low-degree tests G1 and G2 with probability 1−δ(ǫ).
′
By Theorem 13.5, this implies measurements {Cfℓ,v } and {Efℓ ′,u } on the auxiliary register such that


⊗ IBob ,
(65)
(Cℓ,v,f )Alice ⊗ IBob ≈δ(ǫ) Πvℓ ⊗ τvZ ⊗ Cfℓ,v
Alice



ℓ′ ,u

(Eℓ′ ,u,f ′ )Alice ⊗ IBob ≈δ(ǫ) τuZ ⊗ Πuℓ′ ⊗ Ef ′



Alice

⊗ IBob .

(66)

By Fact 4.32, we can assume Equation (65) holds with equality, incurring a loss of only δ(ǫ) in the
game value. (We will do the same for Equation (66) later.)
The strategy is now in a form that allows us to apply Lemma 13.8 to the introspective crosscheck in G1 . This implies that the measurements G[g(u)=ν] and Cfℓ,v give a good strategy for the
line-versus point test. In other words,
ℓ,v
C[f
⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(u)=ν] .
(u)=ν]

on state |auxi. By Proposition 4.42, this implies that
Cfℓ,v ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|ℓ =f ] .
92

Via Equation (64), this implies
Cfℓ,v ⊗ IBob ≈δ(ǫ) IAlice ⊗ G[g|ℓ =f ] ≈δ(ǫ) G[g|ℓ =f ] ⊗ IBob .
As a result, by Fact 12.3,
(Cℓ,v,f )Alice ⊗ IBob ≈δ(ǫ) (Πvℓ ⊗ τvZ ⊗ G[g|ℓ =f ] )Alice ⊗ IBob .
By assumption, the right-hand side is projective. As a result, by Fact 4.32, we can assume this
expression holds with equality, incurring a loss of only δ(ǫ) in the game value. Following this, we
apply Fact 4.32 again to assume Equation (66) holds with equality.
The distribution given by on (ℓ, v) and (ℓ′ , u) when we measure with C and E is exactly the
question distribution of the (non-introspective) intersecting lines test. As a result, Fact 12.2 implies
′
that the measurements G[gℓ =f ] and Efℓ ′,u pass the intersecting lines test with probability 1 − δ(ǫ).
In other words,
ℓ′ ,u
E[f
′ (u+v)=ν] ⊗ IAlice ≃δ(ǫ) IBob ⊗ G[g(u+v)=ν] .
on state |auxi. Then by Lemma 14.3,
′

Efℓ ′,u ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|ℓ′ =f ′ ] .
Via Equation (64), this implies
′

Efℓ ′,u ⊗ IBob ≈δ(ǫ) IAlice ⊗ G[g|ℓ =f ′ ] ≈δ(ǫ) G[g|ℓ =f ′ ] ⊗ IBob .
Thus, Fact 12.3 implies that
(Eℓ′ ,u,f ′ )Alice ⊗ IBob ≈δ(ǫ) τuZ ⊗ Πuℓ ⊗ G[g|ℓ′ =f ′ ]



Alice

⊗ IBob .

By assumption, the right-hand side is projective. As a result, by Fact 4.32, we can assume this
expression holds with equality, incurring a loss of only δ(ǫ) in the game value.
The strategy is now in a form that allows us to apply Lemma 13.8 to the introspective crosscheck in G2 . This implies that the measurements Bνv and G[g|ℓ′ (v)=ν] = G[g(v)=ν] give a good strategy
for the line-versus-point low-degree test. In other words,
Bνv ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(v)=ν] .
on state |auxi. Via Equation (63), this implies
Bνv ⊗ IBob ≈δ(ǫ) IAlice ⊗ G[g(v)=ν] ≈δ(ǫ) G[g(v)=ν] ⊗ IBob .
As a result, by Fact 12.3,
(Bv,ν )Alice ⊗ IBob ≈δ(ǫ) (I1 ⊗ τvZ ⊗ G[g(v)=ν] )Alice ⊗ IBob .
This completes the proof of the theorem.

93

15

The introspective NEEXP protocol

In this question, we give the complete short-question, introspective NEEXP protocol. The goal is a
protocol for Succinct-Succinct-3Sat instances of size sinst with poly(sinst ) question length and running time and poly(2sinst ) answer length and running time. Our construction will be an introspective version of the classical PCP construction from Section 11, in which we replace the low-degree
tests and simultaneous low-degree tests with our introspective low-degree test and introspective
simultaneous low-degree test.
We summarize the protocol here. Given the Succinct-Succinct-3Sat instance Cinst of size sinst ,
let C be the size-s, (3n + 3)-input Succinct-3Sat instance it succinctly represents, where s and n are
roughly exponential in sinst . Following Section 11, we would like the introspective prover to sample
3+s
strings x1 , x2 , x3 ∈ Fm
q and (b, w) ∈ Fq , which they should return to the verifier. In addition,
they should return the evaluations g(x1 ), g(x2 ), g(x3 ) and c1 (x, b, w), . . . , cm′ (x, b, w), where g and
the ci ’s are purported degree-d polynomials. This suggests using the following registers:
m
m
3+s
|EPRm
q i1 ⊗ |EPRq i2 ⊗ |EPRq i3 ⊗ |EPRq i4 .

The difficulty in this protocol is ensuring that the polynomials involved are low-degree. To begin,
we can run the introspective low-degree test on the first register, which guarantees that g(x1 )
corresponds to a low-degree polynomial. Doing the same on registers 2 and 3 would guarantee the
functions evaluated on x2 and x3 are also low-degree polynomials, but it would not guarantee that
the prover is using same low-degree polynomial g on all three. Instead, we run the introspective
intersecting lines test twice, ensuring that prover evaluates x1 , x2 , and x3 using the same function g.
Next, we consider the coefficient polynomials c1 , . . . , cm′ . They are evaluated on the concatenated outputs of the four registers, i.e. the string (x, b, w). As a result, we view the four registers
as a single superregister of length m′ = 3m + 3 + s, and we would like to perform the introspective
simultaneous low-degree test on this superregister. However, this test requires two additional superregisters of length m′ to serve as the direction registers. As a result, the shared state between
the two provers will be of the following form:
m
m
3+s
|ψi = (|EPRm
q i1 ) ⊗ |EPRq i2 ⊗ |EPRq i3 ⊗ |EPRq i4 )SuperReg1
′

′

m
⊗ (|EPRm
q i5 )SuperReg2 ⊗ (|EPRq i6 )SuperReg3 ⊗ |auxiaux .

Having checked that the provers’ functions are low-degree, we conclude with a consistency check
between g and the ci ’s to ensure that they encode a satisfying assignment to our Succinct-3Sat. In
Section 11, this was done by the “formula test”, i.e. the check that satψ,g (x, b, w) = zeroH,c (x, b, w).
Here, this will be accomplished by an introspective version of this test, in which the provers sample x, b, and w themselves. Passing this test with high probability proves that Cinst is a YES
instance of the Succinct-Succinct-3Sat problem.
This section is organized as follows. In Section 15.1, we will discuss the register parameters
algorithm, needed for the register compiler from Section 5. Next, Section 15.2 introduces the introspective formula game. Finally, Section 15.3 completes the construction and gives the introspective
NEEXP game.

15.1

Computing the register parameters

Given the Succinct-Succinct-3Sat instance Cinst of size sinst, let C be the size-s, (3n + 3)-input
Succinct-3Sat instance it succinctly represents. To compile our protocol to one sound against general
provers, we need a register parameters algorithm which runs in time poly(sinst ) (Definition 5.9).
94

As described above, the register parameters will be simple functions of the numbers s and n (for
example m, a simple function of n to be determined later). However, s and n themselves may not
be easy to compute, as the natural way of computing them involves first computing C, a time 2sinst
task. We solve this by “guessing” values for these numbers which are guaranteed to be larger than
the actual values, and then later “fixing” the circuit C so that it actually has the guessed input
length and size. This is detailed in the following definition.
Definition 15.1. Let Cinst be a size-sinst instance of the Succinct-Succinct-3Sat problem.
1. Let C be the size-s Succinct-3Sat instance it succinctly represents. This circuit takes inputs
i, j, k, each of some length n, and bits b1 , b2 , b3 . Then s and n can both be trivially upperbounded by N := 2sinst .
2. Consider a new circuit Cpad with inputs i, j, k ∈ {0, 1}N and b ∈ {0, 1}3 . We write i = (i1 , i2 ),
where i1 is of length N − n and i2 is of length n, and likewise for j and k. Let this circuit
act as follows:
◦ Compute the ∨ of the bits in i1 , j1 , and k1 . Output 0 if this is 1.
◦ Otherwise, output Cdec (i2 , j2 , k2 , b1 , b2 , b3 ).

As defined, this circuit has size s + 3(N − n)+ 2 ≤ 4N =: S, and we will pad it with additional
gates in a trivial manner so that it has exactly S gates. It can be checked that it succinctly
represents the same 3Sat formula as Cdec .
We set PadC(Cinst ) := Cpad , PadN(Cinst ) := N , and PadS(Cinst ) := 4 · N . We note that given Cinst ,
the value of N is efficiently computable.

15.2

An introspective formula game

In this section, we introduce the “introspective formula game”. This game is the introspective
version of the formula check in Section 11, in which we check satψ,g (x, b, w) = zeroH,c (x, b, w) on
′
a randomly chosen point (x, b, w) in Fm
q . Prior to stating the introspective formula game, we will
begin by recalling what this notation means.
Let Cinst be a size-(sinst ) Succinct-Succinct-3Sat instance. Let C = PadC(Cinst ) be a Succinct-3Sat
instance, and let n = PadN(Cinst ) and s = PadS(Cinst ). Then C is a size-s, (3n + 3)-variable circuit
which is a YES instance of the Succinct-3Sat problem if and only if Cinst is a YES instance of the
Succinct-Succinct-3Sat problem. Introduce h = 2t1 , q = 2t2 , and m such that N = 2n , h, q, and m
are exactly admissible parameters (Definition 11.1). Set n′ = n + 3 + s and m′ = m + 3 + s. We
also recall the following pieces of notation.
◦ (Definition 3.8): Write H := Ht1 ,t2 .
◦ (Definition 11.4): Given a function g : Fm
q → Fq , recall the notation satψ,g := satψ,g,n,t1 ,t2 .
′

◦ (Proposition 11.6): Writing Hzero = H 3m ⊗ {0, 1}3+s . Given c1 , . . . , cm′ : Fm
q → Fq , recall
the notation zeroH,c = zeroHzero ,c .
Before stating the introspective formula game, we must first dispense with the following annoying technicality.

95

Flip an unbiased coin b ∼ {0, 1}.
◦ Player b: Give (Z, Z, Z, Z, “formula”); receive u1 , u2 , u3 , (b, w) and ν 1 , ν 2 , ν 3 and
µ1 , . . . , µM ′ .
Compute satψ,ν (u, b, w) and zeroH,µ (u, b, w). Accept if they are equal.
Figure 11: The game GIntroForm (Cinst , h, q, m).
Notation 15.2. In the classical case (Section 11), we have a fixed proof which contains fixed
functions which may or may not be low-degree. In the quantum case, however, we are dealing not
with a fixed proof but an interactive prover, and the formula prover may not respond based on fixed
functions (their responses might be randomized, for example). To account for this, we modify the
definitions of sat and zero as follows. First, we recall the notation gψ := gψ,n,t1 ,t2 (Definition 11.3).
◦ Given ν1 , ν2 , ν3 ∈ Fq , define
satψ,ν (x, b, w) := gψ (x, b, w) · (ν1 − b1 )(ν2 − b2 )(ν3 − b3 ).
◦ Given µ1 , . . . , µm′ ∈ Fq , define
′

zeroH,µ (x) =

m
X
i=1

zero(Hzero )i (xi ) · µi ,

where by definition (Hzero )i = H for i ∈ [3m] and (Hzero )i = {0, 1} otherwise.
We note that if there is a function g such that νi = g(xi ), then satψ,ν = satψ,g . Similarly, if there
are functions c1 , . . . , cm′ such that µi = ci (x), then zeroH,µ = zeroH,c .
Now we state the introspective formula game.
Definition 15.3. Let Cinst be a size-(sinst ) Succinct-Succinct-3Sat instance. Let n = PadN(Cinst )
and s = PadS(Cinst ). Suppose n, h = 2t1 , q = 2t2 , and m are exactly admissible parameters. The
introspective formula game, denoted G := GIntroForm (Cinst , h, q, m), is defined in Figure 11. This is
a λCinst ,q := (4, ℓ, q)-register game, for ℓ = (m, m, m, 3 + s). Furthermore,
Q-length(G ) = O(1),
Q-time(G ) = O(1),

A-length(G ) = O(m′ log(q)),

A-time(G ) = poly(s, n, n′ , h, q, m′ ).

Notation 15.4. In the case when a prover is given the question (Z, Z, Z, Z, “formula”), we refer
to it as the formula prover. It has the following intended behavior.
3. Formula prover:
Input: Pauli basis queries (Z, Z, Z, Z) and auxiliary query “formula”.
′
3+s
Output: Strings u1 , u2 , u3 ∈ Fm
q and (b, w) ∈ Fq . Three numbers ν1 , ν2 , ν3 ∈ Fq and m
numbers µ1 , . . . , µm′ ∈ Fq .

Goal: The prover should act as follows.

◦ The prover sets ν1 = g(u1 ), ν2 = g(u2 ), ν3 = g(u3 ), where g : Fm
q → Fq is a global
degree-d1 polynomial selected independently of u.
96

′

◦ They then set µi = ci (u1 , u2 , u3 , b, w), where for each i, ci : Fm
q → Fq is a global
degree-d2 polynomial selected independently of (u, b, w).
Here, d1 and d2 are polynomial degrees which will be selected later. We will also refer to the
formula prover’s measurement, which refers to the measurement {Fu,b,w,νi ,µj } such that
Z,Z,Z,Z,“formula”
Fu,b,w,ν1,ν2 ,ν3 ,µ1 ,...,µm′ = Mu,b,w,ν
.
1 ,ν2 ,ν3 ,µ1 ,...,µ ′
m

We begin by showing the completeness case of the introspective formula game.
Proposition 15.5 (Introspective formula game completeness). Suppose Cinst is a YES instance of
the Succinct-Succinct-3Sat problem. Let a : {0, 1}n → {0, 1} be a satisfying assignment to the 3Sat
m′
instance it encodes, and let g := ga : Fm
q → Fq be its low-degree encoding. Let c1 , . . . , cm′ : Fq → Fq
be the coefficient polynomials guaranteed to make satψ,g = zeroHzero ,c by Proposition 11.6. Both g
and the ci ’s are degree-O(hn′ ) polynomials. Consider the λCinst ,q -register strategy (ψ, A) with no
auxiliary register in which
Z
· 1[νi = g(ui ), µj = cj (u, b, w)],
Au,b,w,ν,µ = τuZ1 ⊗ τuZ2 ⊗ τuZ3 ⊗ τb,w

where the indices range over i ∈ [3] and j ∈ [m′ ]. Then this strategy passes GIntroForm (Cinst , h, q, m)
with probability 1.
Proof. This game is simply the oracularized version of the formula check in the classical PCP. The
proposition follows from the discussion in Section 11.5.
Our next lemma covers the soundness case of the introspective formula game. It concerns provers
of a particular form, namely those whose measurements correspond to low-degree polynomials. We
show that if there exists such a prover with nonnegligible value, then the formula must be satisfiable.
Lemma 15.6 (Formula game partial soundness). Let Cinst be a Succinct-Succinct-3Sat instance,
and set G := GIntroForm (Cinst , h, q, m). Let S = (ψ, A) be a λCinst ,q -register strategy. Consider a
measurement on the auxiliary register
G = {Gg,c1 ,...,cm′ }
′

m
with outcomes degree-d1 polynomials g : Fm
q → Fq and degree-d2 polynomials c1 , . . . , cm′ : FQ → Fq .
Suppose A has the following form: for each u, b, w, ν, and µ,


Z
Au,b,w,ν,µ = τuZ1 ⊗ τuZ2 ⊗ τuZ3 ⊗ τb,w
⊗ G[g(ui )=νi ,cj (u,b,w)=µj ]
,
(67)
aux

where the subscript of the G measurement ranges over all i ∈ [3] and j ∈ [m′ ]. If the probability S
passes G is at least
max{O(hn′ ) + 3d1 , h + d2 }
,
q
then ψ is satisfiable.
Proof. Consider the following three step strategy:
1. Measure the auxiliary register with {Gg,c1 ,...,cm′ }, receiving functions g, c1 , . . . , cm′ .
2. Measure the EPR registers in the Z basis, receiving u, b, and w.
97

3. Output u, b, w, g(u1 ), g(u2 ), g(u3 ) and c1 (u, b, w) through cM ′ (u, b, w).
This passes the formula game with probability valG (S). Then there exists functions g, c1 , . . . , cm′
such that conditioned on measuring them in step one, this strategy passes with probability at least
valG (S). By the remark at the end of Notation 15.2, this is the probability that
satψ,g (x, b, w) = zeroH,c (x, b, w),
′

where (x, b, w) is drawn from Fm
q uniformly at random. The lemma follows from Lemma 11.7.

15.3

The complete introspective protocol

In this section, we introduce the introspective protocol for NEEXP and prove its correctness.
The introspective NEEXP protocol builds on top of the introspective formula game by using a
series of introspective low-degree tests to ensure that the formula prover satisfies the condition in
Equation (67). Having done this, we can then apply Lemma 15.6, ensuring that if a strategy passes
with high probability, then the instance is satisfiable.
Definition 15.7. Let Cinst be a size-(sinst ) Succinct-Succinct-3Sat instance. Let n = PadN(Cinst )
and s = PadS(Cinst ). The verifier chooses h = 2t1 , q = 2t2 , m, and d such that m, h, q, and m are
exactly admissible parameters satisfying


n
, q = poly(n), d = O(hn′ ) = O(n2 ).
h = Θ(n), m = Θ
log(n)
(We will choose the polynomial for q in Theorem 15.8 below.) The verifier sets λ = (6, ℓ, q), where
ℓ = (m, m, m, 3 + s, m′ , m′ ).
We begin by instantiating the following list of subroutines.
◦ Let λLD = (3, m, q) be register parameters. Let GLD be a copy of GIntroLowDeg (λLD , d), using
register 1 as the point register and registers 2 and 3 as the direction registers. Write Points1
for the points prover.
◦ Let λIL = (2, m, q) be register parameters. Let GIL1 be a copy of GIntroIntersect (λIL , d) on
registers 1 and 2 whose points prover for register 1 is Points1 from GLD . Write Points2 for the
points prover on register 2.
◦ Let GIL2 be a copy of GIntroIntersect (λIL , d) on registers 1 and 3 whose points prover for register 1
is Points1 from GLD . Write Points3 for the points prover on register 3.
◦ Let GF be a copy of GIntroForm (Cinst , h, q, m) on registers 1, 2, 3, and 4. Write Formula for the
formula prover.
◦ Let λLDSUP = (3, m′ , q) be register parameters. Let GLDSUP be a copy of GIntroLowDeg (λLDSUP , d, 3+
m′ ), applied to the following three superregisters: registers 1 through 4 are combined into
the point superregister, register 5 is used as the first direction superregister, and register 6 is
used as the second direction superregister. In addition, use Formula from Gform as its points
prover.
Then the introspective NEEXP game, denoted GIntroNEEXP (Cinst ), is defined in Figure 12.
The main result Part IV is the following theorem.
98

With probability

1
9

each, perform one of the following nine tests.

1. Low degree test: Play GLD .
2. Intersecting lines test 1: Play GIL1 .
3. Intersecting lines test 2: Play GIL2 .
4. Simultaneous low degree test: Play GLDSUP .
5. Formula test: Player GF .
For the remaining tests, flip an unbiased coin b ∼ {0, 1}. Assign the first role to Player b and the
second role to Player b.
6. Consistency test 1:
◦ Points1 : Receive ν.

◦ Formula: Receive ν 1 .

Accept if ν = ν 1 .
7. Consistency test 2:
◦ Points2 : Receive ν.

◦ Formula: Receive ν 2 .

Accept if ν = ν 2 .
8. Consistency test 3:
◦ Points3 : Receive ν.

◦ Formula: Receive ν 3 .

Accept if ν = ν 3 .
9. Consistency test 4:
◦ Formula: Receive ν 1 , ν 2 , ν 3 and µ1 , . . . , µm′ .

◦ Formula: Receive ν ′1 , ν ′2 , ν ′3 and µ′1 , . . . , µ′m′ .

Accept if ν i = ν ′i and µj = µ′j for all i ∈ [3], j ∈ [m′ ].
Figure 12: The game GIntroNEEXP (Cinst ).

99

Theorem 15.8. Let Cinst be a size-(sinst ) Succinct-Succinct-3Sat instance. Let q be a sufficiently
large poly(n) and ǫ > 0 a sufficiently small constant such that Equation (72) is at least 21 and
Equation (73) is less than 12 . Write G := GIntroNEEXP (Cinst ).
◦ Completeness: Suppose Cinst encodes a satisfiable formula. Then there is a value-1 λ-register
strategy for G with no auxiliary register.
◦ Soundness: If there is a λ-register strategy for G with value at least 1 − ǫ, then Cinst encodes
a satisfiable formula.
Furthermore,
Q-length(G ) = O(1),
Q-time(G ) = O(1),

A-length(G ) = poly(2sinst ),
A-time(G ) = poly(2sinst ).

Proof. The question lengths and question runtimes are both O(1) because all involved subtests
have O(1) question complexity. The answer lengths and question runtimes are both poly(2sinst )
because all our parameters are at most polynomial in n = 2sinst , and the question lengths and
question runtimes of all involved subtests are polynomial in these parameters.
We name the measurements used by the provers as follows.
Points1 : A,

Points2 : B,

Points3 : C,

Formula : F.

We will write the identity matrix on registers 5 and 6 as I5,6 := I5 ⊗ I6 .
Completeness. Suppose Cinst encodes a satisfiable formula. By Proposition 15.5, there are
m′
degree-d polynomials g : Fm
q → Fq and c1 , . . . , cm′ : Fq → Fq such that if we define
Z
Fu,b,w,ν,µ = τuZ1 ⊗ τuZ2 ⊗ τuZ3 ⊗ τb,w
⊗ I5,6 · 1[νi = g(ui ), µj = cj (u, b, w)],

then this strategy passes the formula test with probability 1. We extend this strategy to the
remaining measurements as follows.
Au1 ,ν1 = τuZ1 ⊗ I2 ⊗ I3 ⊗ I4 ⊗ I5,6 · 1[ν1 = g(u1 )],
Bu2 ,ν2 = I1 ⊗ τuZ2 ⊗ I3 ⊗ I4 ⊗ I5,6 · 1[ν2 = g(u2 )],
Cu3 ,ν3 = I1 ⊗ I2 ⊗ τuZ3 ⊗ I4 ⊗ I5,6 · 1[ν3 = g(u3 )].
By the completeness of the introspective low-degree and intersecting lines tests, these can be extended to a strategy which passes the whole test with probability 1.
Soundness.

Throughout this proof, we use δ(ǫ) to represent functions of the form
δ(ǫ) = poly(ǫ, m · d/q e ),

where e > 0 is an absolute constant.

100

Low-degree tests. The strategy passes the introspective low-degree test with probability 1−δ(ǫ).
Applying Theorem 13.10, there is a measurement G = {Gg } in PolyMeas(m, d, q) such that

(Au1 ,ν1 )Alice ⊗ IBob ≈δ(ǫ) τuZ1 ⊗ I2 ⊗ I3 ⊗ I4 ⊗ I5,6 ⊗ (G[g(u1 )=ν1 ] )aux Alice ⊗ IBob .

By Fact 4.32, we can assume this holds with equality with a loss of only δ(ǫ) in the game value. In
addition, by Theorem 4.1, we can assume that the G measurements are all projective.
Next, the strategy passes the two introspective intersecting lines tests with probability 1 − δ(ǫ)
each. By Theorem 14.6, this implies that

(Bu2 ,ν2 )Alice ⊗ IBob ≈δ(ǫ) I1 ⊗ τuZ2 ⊗ I3 ⊗ I4 ⊗ I5,6 ⊗ (G[g(u2 )=ν2 ] )aux Alice ⊗ IBob ,
(68)
(Cu3 ,ν3 )Alice ⊗ IBob ≈δ(ǫ) I1 ⊗ I2 ⊗ τuZ3 ⊗ I4 ⊗ I5,6 ⊗ (G[g(u3 )=ν3 ] )aux



Alice

⊗ IBob .

(69)

Similarly, the strategy passes the introspective simultaneous low-degree test with probability 1−
δ(ǫ). Applying Theorem 13.12, there is a measurement J = {Jf1 ,f2 ,f3 ,c1 ,...,cm′ } in PolyMeas(m′ , d, q, 3+
m′ ) such that
(Fu,b,w,ν,µ)Alice ⊗ IBob


Z
⊗ I5,6 ⊗ (J[fi (u,b,w)=νi ,cj (u,b,w)=µj ] )aux
≈δ(ǫ) τuZ1 ⊗ τuZ2 ⊗ τuZ3 ⊗ τb,w

Alice

⊗ IBob , (70)

where the subscript of the J measurement ranges over all i ∈ [3] and j ∈ [m′ ]. By Fact 4.32, we
can assume Equations (68) to (70) holds with equality with a loss of only δ(ǫ) in the game value.
In addition, by Theorem 4.1, we can assume that the J measurements are all projective.
Consistency tests.
implying

The strategy passes the four consistency tests with probability 1 − δ(ǫ) each,
(Fu1 ,ν1 )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (Au1 ,ν1 )Bob ,
(Fu2 ,ν2 )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (Bu2 ,ν2 )Bob ,
(Fu3 ,ν3 )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (Cu3 ,ν3 )Bob ,
(Fu,b,w,ν,µ)Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (Fu,b,w,ν,µ )Bob .

By introspection (Fact 12.4), these imply the following statements:
(J[f1 (u,b,w)=ν1 ] )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (G[g(u1 )=ν1 ] ),
(J[f2 (u,b,w)=ν2 ] )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (G[g(u2 )=ν2 ] ),
(J[f3 (u,b,w)=ν3 ] )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (G[g(u3 )=ν3 ] ),
(J[cj (u,b,w)=µj ] )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (J[cj (u,b,w)=µj ] ),

where the subscript of the J measurement ranges over all i ∈ [3] and j ∈ [m′ ]. Here, these
statements are with respect to the strategy’s auxiliary state and to the uniform distribution on
′
(u, b, w) ∈ Fm
q .
Now we apply Fact 4.34. To do so, let us specify the sets Gi and the distance parameter. The
′
three sets G2 , G3 , and G4 will just contain all degree-d polynomials g : Fm
q → Fq . (Note that
we can view the outputs of Gg as degree-d polynomials which disregard all of their input (u, b, w)
aside from one of the three strings u1 , u2 , or u3 .) By Schwarz-Zippel, these have distance at
least 1 − d/q. The remaining set, G1 , is defined as follows: for each tuple of degree-d polynomials
101

c1 , . . . , cm′ , it contains a function c defined as c(u, b, w) = (c1 (u, b, w), . . . , cm′ (u, b, w)). Any two
nonequal c, c′ ∈ G1 have some coordinate i in which ci 6= c′i , and on this coordinate alone they will
have distance at least 1 − d/q by Schwarz-Zippel. Thus, c and c′ have distance at least 1 − d/q.
Define the measurement {Kg,c1 ,...,cm′ } as
Kg,c1 ,...,cm′ := Gg · Jc1 ,...,cm′ · Gg ,
Then Fact 4.34 implies that
(J[fi (u,b,w)=νi ,cj (u,b,w)=µj ] )Alice ⊗ IBob ≃δ(ǫ) IAlice ⊗ (K[g(ui )=νi ,c′j (u,b,w)=µj ] ),
where the subscripts range over all i ∈ [3] and j ∈ [m′ ]. By introspection (Fact 12.4), this implies
that
(Fu,b,w,ν,µ)Alice ⊗ IBob


Z
⊗ I5,6 ⊗ (K[g(ui )=νi ,cj (u,b,w)=µj ] )aux
≃δ(ǫ) τuZ1 ⊗ τuZ2 ⊗ τuZ3 ⊗ τb,w

Alice

⊗ IBob , (71)

where the subscripts range over all i ∈ [3] and j ∈ [m′ ]. By Fact 4.32, we can assume Equation (71)
holds with equality with a loss of only δ(ǫ) in the game value.
Formula test: At this point, the formula prover’s strategy F satisfies the condition in Equation (67)
with d1 = d2 = d. In addition, it passes the introspective formula test with probability
1 − poly(ǫ, m · d/q),

(72)

which by our setting of parameters is at least 12 . Finally, our setting of parameters also implies that
max{O(hn′ ) + 3d, h + d}
q

(73)

is less than 12 . As a result, we can apply Lemma 15.6 to conclude that ψ is satisfiable.
Theorem 15.8 only proves soundness of the introspective NEEXP protocol against λ-register
strategies. Our last step is to compile this protocol into one which is sound against general strategies, while only slightly increasing the question length.
Corollary 15.9. There is an absolute constant ǫ > 0 such that the following is true. Let Cinst be a
size-(sinst ) Succinct-Succinct-3Sat instance. Then there exists a game G := GIntroNEEXP (Cinst ) with
the following properties.
◦ Completeness: Suppose Cinst encodes a satisfiable formula. Then there is a value-1 real
commuting EPR strategy for G .
◦ Soundness: If there is a strategy for G with value at least 1−ǫ, then Cinst encodes a satisfiable
formula.
Furthermore,
Q-length(G ) = O(sinst ),
Q-time(G ) = O(sinst ),

A-length(G ) = poly(2sInst ),
A-time(G ) = poly(2sinst ).

102

Proof. Let n = PadN(Cinst ) and s = PadS(Cinst ). Set m = Θ(n/ log(n)) and q = poly(n), as
in Definition 15.7. Set λ = (6, ℓ, q), where ℓ = (m, m, m, 3 + s, 3m + 3 + s, 3m + 3 + s). Then
GIntroNEEXP (Cinst ) is a λ-register game. Furthermore, by Definition 15.1, the register parameters are
computable in time poly(sinst ).
Let ǫ > 0 be as in Theorem 15.8, and select a constant ǫ′ > 0 and η1 , . . . , η6 = 1/poly(n)
such that δ(ǫ′ ) ≤ ǫ, where δ(ǫ′ ) = poly(ǫ′ , η1 , . . . , η6 ) is as in Corollary 5.10. Now, if we apply
Corollary 5.10, it gives us a game G with the following properties.
◦ If C is a “Yes” instance, then GIntroNEEXP (Cinst ) has a value-1 strategy with no auxiliary state,
which implies that G has a value-1 commuting EPR strategy.
◦ If C is a “No” instance, then every λ-register strategy for GIntroNEEXP (Cinst ) has value less than
1 − ǫ. By our choice of parameters, this is less than 1 − δ(ǫ′ ), which implies that G has no
strategy with value 1 − ǫ′ .
Furthermore, log(m) = O(log(n)) = O(sinst ) and log(s) = O(log(n)) = O(sinst ), giving us our
desired question complexities, and poly(m) = poly(n) = poly(2sinst ) and poly(s) = poly(n) =
poly(2sinst ), giving us our desired answer complexities.

Part V

Answer reduction
16

Testing error-correcting codes

In Section 17 below, rather than the prover sending the verifier their entire “large” answer a, they
will instead encode it into Enc(a) using an error correcting code and allow the verifier to query
individual bits of the encoding. (The fact that the verifier is allowed to query bits of the encoding
rather than the original string stems from the PCPP technology we use. See Section 17.3 for
more details.) In this section, we develop the tests which verify that provers are performing this
task honestly, so that when we query a subset of the bits I, they respond based on the bits of a
codeword which was sampled independently of I. We will develop such a test for the low-degree
code (Section 16.1).
Our proofs are entirely standard: we start with the known property tester for this code (i.e..
Theorem 4.40), which allows us to query the prover’s codeword at a uniformly random location.
Then we use the local decodability properties of this code to allow us to query arbitrary subsets of
coordinates. We begin by stating a slightly nonstandard definition of error-correcting codes relevant
to our application.
Definition 16.1 (Error-correcting codes). Let m and q be integers, and let η ∈ [0, 1].
(n, m, q, η)-error-correcting code Code = (Enc, Dec, Sub) is defined as follows.

An

◦ Sub is a subset of Fm
q such that for each x 6= y ∈ Sub, x and y have normalized Hamming
agreement at most η (i.e. the probability, over a uniformly random i ∈ [m], that xi = yi is at
most η).
◦ Enc : {0, 1}n → Sub ⊆ Fm
q is the encoding map.
n
n
◦ Dec : Fm
q → {0, 1} ∪ {⊥} is the decoding map. For each x ∈ {0, 1} , Dec(Enc(x)) = x. In
addition, for every w not in the range of Enc, Dec(w) = ⊥.

103

Remark 16.2. The purpose of the subset Sub is this: in this section, we are designing games
which test that a prover responds according to an error-correcting code. This means that the
prover should respond based on the encoding Enc(x) of some string x ∈ {0, 1}n . However, the
games we design may only be able to test if the prover responds based on a string in Sub, which
contains the encodings Enc(x) but may include other strings as well. This definition ensures that
these other strings are still far from each other in Hamming distance.
The next definition defines a subset tester.
Definition 16.3. Let Code = (Enc, Dec, Sub) be an (n, m, q, η)-error-correcting code. Let k be an
integer. Given a game G (·) whose inputs are from the set of subsets of [m] of size k and a probability
distribution D over this set, we write G (D) for the game in which we first sample I ∼ D and then
play G (I). Then G is a k-subset tester with robustness δ(ǫ) for Code if it satisfies the following two
properties.
◦ Completeness: Let (ψ, M ) be an EPR strategy in which {Mw } is a measurement with
outcomes in {0, 1}n . Consider the partial strategy (ψ, G) in which
GIa1 ,...,ak := M[Enc(w)|I =a1 ,...,ak ] .
Then this can be extended to a (full) real commuting EPR strategy which, for each I, passes
G (I) with probability 1.
◦ Soundness: For any distribution D, consider a strategy (ψ, M ) which passes G (D) with
probability 1 − ǫ. Then there exists a measurement {Gw }w with outcomes w in Sub such that
MaI1 ,...,ak ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[w|I =a1 ,...,ak ] .

16.1

Testing the low-degree code

In this section, we show how to test the low-degree code. This is essentially an exercise in generalizing Theorem 4.40 to arbitrary subsets. We begin with some notation.
m for the family F m = {F ⊆ Fm | |F | ≤ k}.
Notation 16.4. We write Fq,k
q,k
q

Now we define the low-degree code tester.
m.
Definition 16.5. Let m, q, and d be integers. Let k be an integer, and let F be an element of Fq,k
Then GLDsubset (m, q, d, F ) is the game defined in Figure 13.

The performance of the low-degree subset game is given by the following theorem.
Theorem 16.6. Consider low-degree parameters params = (n, q, h, H, m, S, π). Set d = m(h − 1).
′
m
n
Set m′ = q m . We will identify strings in Fm
q with functions g : Fq → Fq . Given a ∈ {0, 1} ,
m
define Enc(a) = ga and Dec(ga ) = a. For all other g : Fq → Fq (i.e. those which are not the
low-degree encoding of a string a), define Dec(g) = ⊥. Finally, define Sub to be the set of degree d
′
polynomials g : Fm
q → Fq . Then Code = (Enc, Dec, Sub) is an (n, m , q, d/q)-error-correcting code.
Furthermore, there exists a constant c > 0 and a function δ(ǫ) = poly(ǫ, dm/q c ) such that the
following holds. Let k be an integer. Then GLDsubset := GLDsubset (m, q, d, ·) is a k-subset tester for
LDCode with robustness δ(ǫ).
Finally,
A-time(GLDsubset ) = poly(m, dk , log q),

Q-time(GLDsubset ) = poly(m, k, log q),
Q-length(GLDsubset ) = O(km log q),

A-length(GLDsubset ) = O(dk log(q)).

104

With probability

1
2

each, perform one of the following two tests.

1. Low-degree: Perform GSurface (m, d, q, 2).
2. Cross-check: Flip an unbiased coin b ∼ {0, 1}. Let s be a uniformly random subspace of
dimension k + 1 containing the points in F . With probability 12 each:
(a) Let w be a uniformly random point in s. Distribute the questions as follows:
◦ Player b: give w; receive a value y ∈ Fq .
◦ Player b: give s; receive a degree-d polynomial g : s → Fq .

Accept if g(w) = y.

(b) Distribute the questions as follows:
◦ Player b: give s; receive a degree-d polynomial g : s → Fq .
◦ Player b: give F ; receive a function f : F → Fq .

Accept if g|F = f .

Figure 13: The game GLDsubset (m, q, d, F ).
Before proving this, we need the following proposition.
Proposition 16.7. Let F ⊆ Fm
q be of size at most k. Consider the distribution Dtwostep on
generated
by
the
following
two-step process: (i) let s be a uniformly random subspace
points x ∈ Fm
q
of size k + 1 containing F , and (ii) draw x uniformly at random from s. Let Dunif be the uniform
distribution on Fm
q . Then dTV (Dtwostep , Dunif ) ≤ 1/q.
Proof. Let x1 , . . . , xℓ be a maximal set of linearly independent elements from F . A uniformly random subspace of size k + 1 containing F can be generated as follows: first, pick a uniformly random
nonzero vector y ℓ+1 linearly independent from F , then pick a uniformly random nonzero vector
y ℓ+2 linearly independent from F ∪ {y ℓ+1 }, and so forth. Set s = span{x1 , . . . , xℓ , y ℓ+1 , . . . , y k+1 }.
A uniformly random point in s will be of the form
x = t1 x1 + · · · + tℓ xℓ + tℓ+1 y ℓ+1 + · · · + tk+1 y k+1 ,
where each ti is a uniformly random element in Fq . Because all the y i ’s are linearly independent, the
linear combination tℓ+1 y ℓ+1 + · · · + tk+1 y k+1 is zero only when tℓ+1 = · · · = tk+1 = 0. Otherwise,
this linear combination is distributed as a uniformly random nonzero vector linearly independent
from F . Thus, with probability (q k+1−ℓ )−1 , x is distributed as a uniformly random vector in the
span of F , and otherwise it is distributed as a uniformly random vector outside the span of F .
Given that the span of F has q ℓ points, the total variation distance is




1
1
1
1
1
1 qm − qℓ
1 qℓ
ℓ
− k+1−ℓ +
− 1 − k+1−ℓ = q
− m ≤ .
m
m
k+1
2 q
q
2
q
q
q
q
q
Now we prove Theorem 16.6.
Proof of Theorem 16.6. The fact that Code is an (n, m′ , q, d/q)-error-correcting code follows from
Schwartz-Zippel (Lemma 3.6).

105

Completeness. Let (ψ, M ) be an EPR strategy in which {Mw } is a measurement with outcomes
in {0, 1}n . Consider the strategy (ψ, G) in which for any subset of points F = {y1 , . . . , yℓ },
GIa1 ,...,aℓ := M[gx (y1 ),...,gx (yℓ )=a1 ,...,aℓ ] .

(This covers the case of points (ℓ = 1) and subsets F (ℓ = k).) In addition, for any subspace s,
Gsf := M[gx |s =f ] .
(This covers the case of the 2-dimensional subspaces used in GPoint and the (k + 1)-dimensional
subspaces used for the local decoding.) By construction, (ψ, G) is an EPR strategy, and it is easy
to see that it is a commuting one as well.
We claim that (ψ, G) passes GLDsubset (m, q, d, D) with probability 1. We begin with the lowdegree test. By Fact 4.37, Mw ⊗ IBob ≃0 IAlice ⊗ Mw . Then by Fact 4.26,
M[gx (w)=b] ⊗ IBob ≃0 IAlice ⊗ M[gx (w)=b] .
This implies passing the low-degree test with probability 1, because
Gs[f (w)=b] ⊗ IBob = M[gx (w)=b] ⊗ IBob ≃0 IAlice ⊗ M[gx (w)=b] = IAlice ⊗ Gw
b .
A similar argument shows the other tests pass with probability 1 as well.
Soundness. Let D be a distribution, and let (ψ, M ) be a strategy which passes GLDsubset (m, q, d, D)
with probability 1 − ǫ. The outline of the proof is as follows: first we will use the low degree test in
Item 1 to ensure the test correctly answers low-degree point queries. Item 2a will then bootstrap
this to subspaces, and Item 2b will further bootstrap this to subsets, proving the theorem.
Using the low-degree test. Passing the test with probability 1 − ǫ means passing the lowdegree test with probability at least 1 − 2ǫ. By Theorem 4.40, this means that there exists a
POVM measurement G ∈ PolyMeas(m, d, q) such that
Mbw ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b] ,

where the first is on the uniform distribution over Fm
q .

Gg ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gg ,

(74)

Bootstrapping to subspaces. Define Dtwostep to be the two-step sampling process (F , s, w) as
in Item 2a. By Proposition 16.7, the marginal distribution on w has total variation distance at
most 1/q with Dunif . As a result, we can apply Fact 4.21 to Equation (74), yielding
Mbw ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b]

(75)

on distribution Dtwostep . Similarly, by Fact 4.26,
G[g(w)=b] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b]

(76)

on distribution Dtwostep .
Next, because the strategy passes the test in Item 2a with probability at least 1 − 4ǫ,
s
Myw ⊗ IBob ≃ǫ IAlice ⊗ M[g(w)=y]
.

(77)

on distribution Dtwostep . Combining Equations (75) to (77) with our second triangle inequality
(Fact 4.29),
s
M[g(w)=y]
⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g(w)=b] .
By Proposition 4.42, we conclude that

Mfs ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|s =f ] .
106

(78)

Concluding with subsets.
1 − 4ǫ. As a result,

The strategy passes the test in Item 2b with probability at least
s
MfF ⊗ IBob ≃ǫ IAlice ⊗ M[g|
.
F =f ]

Applying Fact 4.26 to Equation (78),

s
M[g|
⊗ IBob ≃δ(ǫ) IAlice ⊗ G[h|F =h] .
F =f ]

Similarly, applying Fact 4.26 to Equation (74),
G[h|F =f ] ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[h|F =f ]
Applying the triangle inequality (Fact 4.29) to these three equations, we get
MfF ⊗ IBob ≃δ(ǫ) IAlice ⊗ G[g|F =f ]
with respect to distribution Dtwostep , and therefore, by Fact 4.23, with respect to D.

16.2

Efficiently decodable codes

Our application requires error-correcting codes with two further properties. The first property is
that the decoding map Dec(·) be efficiently computable. (The encoding map, on the other hand,
is allowed arbitrary complexity. This is because we will leave the task of computing the encoding
maps to the provers.) The second, more technical property is we require that the code embed the
codeword, in the following sense: the encoding Enc(x) of a string x should actually contain the
string x, and the function for where to find each bit of x in Enc(x) should be efficiently computable.
Definition 16.8 (Efficiently-decodable error-correcting codes). Let m, q : Z+ → Z+ , and let
η : Z+ → [0, 1]. Let tDec , tEmb : Z+ → Z+ . We say that Coden = (Encn , Decn , Subn ) is an
(n, m, q, η, tDec , tEmb )-efficient code family if the following three conditions are true.
◦ For each n, (Encn , Decn , Subn ) is an (n, m(n), q(n), η(n))-error-correcting code.
◦ There exists an algorithm AlgDec which, on input (n, w), outputs Decn (w). Furthermore,
AlgDec runs in time tDec (n).
◦ There exists an embedding µn : [n] → [m(n)] such that for each i ∈ [n], xi = (Encn (x))µn (i) .
Furthermore, there is an algorithm AlgEmb which, on input (n, i), computes µn (i) in time
tEmb (n).
Now, we show that the low-degree code is efficiently-decodable. The decoding algorithm follows
a simple strategy: assuming that the input is a proper encoding of a message, they can directly
read off the message from the input. Then they compute the encoding of the purported message
and check that it equals the input.
Fact 16.9. There is a (n, m′ , q, η, tDec , tEmb )-error-correcting code Code with parameters set as
follows:
1
,
m′ (n) = poly(n), q(n) = polylog(n), η(n) =
polylog(n)
tDec (n) = poly(n),

tEmb (n) = polylog(n).

In addition, Code has a k-subset test G with robustness δ(ǫ) = poly(ǫ, 1/ log(n)) such that
Q-time(G ) = poly(log n, k),
Q-length(G ) = O(k log n),

A-time(G ) = poly(log(n)k ),
A-length(G ) = O(log(n)2k ).

107

Proof. We instantiate the canonical low-degree encoding from Definition 3.8 with the “rule of
thumb” parameters from Equation (1):


log(n)
h(n) = Θ(log(n)),
m(n) = Θ
,
q(n) = polylog(n).
log log(n)
If we set d(n) = m(n) · (h(n) − 1), then this is a code with distance η(n) = 1 − d(n)/q(n) =
1 − 1/polylog(n). In addition, it has length m′ (n) = q(n)m(n) = poly(n). Finally, the canonical
low-degree encoding gives us the embedding µEmb := σm,t1 ,t2 . By Proposition 3.9, it takes time
tEmb (n) = polylog(n) to compute.
Now we design the decoding algorithm AlgDec . On input (n, w), it rejects if w is not length m′ .
Otherwise, it interprets w as a function f : Fm
q → Fq . It queries g on the points π(1), . . . , π(n). Let
a ∈ {0, 1}n be the received answers. If g is a codeword, it equals the low-degree function ga . So
the algorithm simply iterates over all x ∈ Fm
q and checks that f (x) = ga (x). By Proposition 3.9,
computing ga (x) can be done in time poly(n), and so this takes time tDec (n) = poly(n) in total.
Finally, the performance of the subset tester follows from Theorem 16.6 with our setting of
parameters.

17

Answer reduction

In this section, we carry out the answer reduction. Our main result will be to take the poly(n)
question complexity, O(2n ) answer complexity MIP∗ protocol for Succinct-Succinct-3Sat given by
Corollary 15.9 and convert it to one whose answer complexity is also poly(n); this is Theorem 17.12
below.
Our answer reduction will apply to any game with a value-1 real commuting EPR strategy. We
will require two properties of these strategies: first, that they can be extended to strategies that pass
subset tests with probability 1, as in Definition 16.3; and second, that they are “oracularizable”.
We explain this second property in the next section.

17.1

Oracularization

Our technique will not work for all entangled games but only for a subset, for which a single prover
can simulate both prover’s actions if required to. We call such games “oracularizable” games.
Definition 17.1. Given a two-player entangled game G , its oracularization is the game Coracle (G )
given in Figure 14. If G is value-1, then we call it oracularizable, if val(Coracle (G )) = 1 as well. We
also note that for any game G , if val(G ) ≤ 1 − δ, then val(Coracle (G )) ≤ 1 − O(δ).
A real commuting EPR strategy allows “Player b” to sample both questions x0 and x1 simultaneously. As a result, if a game G has a value-1 real commuting EPR strategy, then it is oracularizable.
The value of oracularization is that when the verifier checks V (x0 , x1 , a0 , a1 ) = 1, both a0
and a1 come from the same prover rather than two different provers. This seems like a minor
change, but in fact it makes all the difference. Our goal is to reduce the verifier’s runtime by
having the provers encode their answers using PCP technology. When the answers come from both
provers, the relevant piece of PCP technology is a distributed PCP, but it is known by a simple
argument of Reingold that distributed PCPs do not exist (see the discussion in [ARW17]). The key
difficulty comes from the fact that Alice needs to prepare her PCP proof without knowing Bob’s
question and answer, and vice versa, and this turns out to be impossible in general. On the other
hand, when the answers come from a single prover, we can use traditional PCPs to implement the
108

Given a game G , sample a tuple (x0 , x1 , C) ∼ G , and flip two unbiased coins b, c ∼ {0, 1}. With
probability 12 each, perform one of the following two tests.
1. Verify: Distribute the questions as follows:
◦ Player b: send the pair (x0 , x1 ) and receive answers (a0 , a1 ).
◦ Player b: send xc and receive an answer a2 .

2. Consistency: Play the consistency game with question x0 , x1 .
Accept if a2 = ac and V (x0 , x1 , a0 , a1 ) = 1.
Figure 14: The oracularized game Coracle (G ).
answer reduction, of which we have a variety of constructions. We note that oracularized games
do still have checks between players, but these are equality checks and will be easy to implement
in the answer reduction regime.

17.2

Probabilistically checkable proofs of proximity

In this section, we introduce the main PCP technology we will use for our answer reduction. In the
oracularized game, the provers want to convince us not just that V (·, ·, ·, ·) is satisfiable—which we
already know to be true by construction—but that (x0 , x1 , a0 , a1 ) is a particular assignment which
satisfies it. For this, we need a stronger notion of a PCP called a probabilistically checkable proof of
proximity (PCPP). These allow one to check that an input x is close to a satisfying assignment of a
circuit C (hence the “proximity”) by making a small number of queries to x. These were originally
introduced in the independent works of [BSGH+ 06] and [DR06] (where they were called assignment
testers).
In our case, we will need even stronger PCPPs in which the verifier is not only query-efficient but
time-efficient as well. The history of these time-efficient PCPPs goes back to the original proof of
MIP = NEXP and the various attempts to “scale it down” [O’D05]. The most famous line of research
considered proof systems in which the verifier’s query complexity is restricted, and this eventually
led to the proof of the PCP theorem [AS98, ALM+ 98]. A parallel line of research considered proof
systems in which the verifier’s runtime is restricted (so-called “transparent” proofs) [BFLS91]. The
latter of these was revisited in the work of Ben-Sasson et al. [BSGH+ 05], who showed that both
lines of research could be remerged in the “scaled down” setting by constructing a PCPP in which
the verifier is both query-efficient and time-efficient. Though their main result is actually sufficient
for our purposes, we will cite the work of Mie [Mie09], which improves on their result in the regime
we care about. Finally, we note the work of Meir [Mei14], who reproves the bounds of Ben-Sasson
et al. [BSGH+ 05] using combinatorial methods.
To our knowledge, ours is the first use of a time-efficient PCPP specifically for its time-efficient
properties in the quantum literature. Natarajan and Vidick [NV18a] used the time-efficient PCPP
of [BSGH+ 05] to prove the quantum games PCP conjecture, but the property they needed was
not that it was time-efficient, but that the bits of the proof are linear functions of the bits of the
assignment. We note that we do not need this property here.
In this literature, it is common to consider “pair languages” consisting of strings (x, y) in which x
is small and given to the verifier and y is large and accessible only through query access. This maps
perfectly onto our scenario, in which the verifier supplies the “small” questions x0 , x1 and the
prover supplies the “large” answers a0 , a1 .
109

Definition 17.2. A pair language L is a subset of {0, 1}∗ × {0, 1}∗ . Given x ∈ {0, 1}∗ , we write
Lx = {y ∈ {0, 1}∗ | (x, y) ∈ L}.
The next two definitions state the notion of an efficient PCPP verifier.
Definition 17.3 ([BSGH+ 05, Definition 2.1]). Let r, q : Z+ → Z+ and t : Z+ × Z+ → Z+ . An
(r, q, t)-restricted PCPP verifier is a probabilistic machine that, given a string x (called the explicit
input) and a number K (in binary) as well as oracle access to an implicit input y ∈ {0, 1}K and to
a proof oracle π ∈ {0, 1}∗ , tosses r(|x| + K) coins, queries the oracles (y, π) for a total of q(|x| + K)
symbols, runs in time t(|x|, K), and outputs a Boolean verdict in {accept, reject}.
Definition 17.4 ([BSGH+ 05, Definition 2.2]). For functions r, q : Z+ → Z+ , t : Z+ × Z+ → Z+ ,
and constants s, γ ∈ [0, 1], a pair language L ⊆ {0, 1}∗ × {0, 1}∗ is in PCPPs,γ [r, q, t] if there exists
an (r, q, t)-restricted PCPP verifier V with the following properties:
◦ Completeness: If (x, y) ∈ L then there exists a π such that PrR [V y,π (x, |y|; R) accepts] = 1,
where V y,π (x, |y|; R) denotes the decision V on input (x, |y|), oracle access to (y, π), and coin
tosses R.
◦ Soundness: If (x, y) is such that y is γ-far from Lx ∩ Σ|y| , then for every π it holds that
PrR [V y,π (x, |y|; R) accepts] ≤ s.
Mie’s time-efficient PCPP is states as follows.
Theorem 17.5 ([Mie09, Theorem 1]). Suppose that L is a pair language in NTIME(T ) for some
non-decreasing function T : Z+ → Z+ . Then, for every two constants s, γ > 0, we have L ∈
PCPPs,γ [r, q, t], for
◦ Randomness complexity r(m) = log2 T (m) + O(log log T (m)).
◦ Query complexity q(m) = O(1),
◦ Verification time t(n, K) = poly(n, log K, log T (n + K)).
We note that this is in fact a much stronger than what we will actually need. In particular, we
will only apply this to languages L in deterministic TIME(T ), which are trivially in NTIME(T ).

17.3

Composing with an error-correcting code

The verifier in a PCPP rejects any input which is γ-far from an accepting input, but of course we
want our verifier to reject all non-accepting inputs, no matter their distance. To do this, we will
(i) encode the verifier’s inputs using an error-correcting code and (ii) check that the inputs are
properly encoded (using, for example, the low-degree test). This approach of composing a PCPP
with an error-correcting code is standard and stretches back in spirit to the transparent proofs
of [BFLS91] (see the discussion of this in [BSGH+ 06]).
Now we show how to compose an MIP∗ game with an error-correcting code.
Definition 17.6 (Error-correcting the provers’ answers). Let V = (AlgQ , AlgA ) be an MIP∗ verifier
(the language it verifies is not important). Suppose on inputs of size n it has question length ℓQ (n)
answer length ℓA (n). Write LA for the language decided by AlgA . Let Codek = (Enck , Deck , Subk )
be a (k, m, q, η, tDec , tEmb )-efficient code family with decoding algorithm AlgDec . Then LA ◦ Code is
a new language defined as follows: suppose (input, x0 , x1 , y0 , y1 ) ∈ LA . Let n be the length of input
and ℓ = ℓA (n). Then (input, x0 , x1 , Encℓ (y0 ), Encℓ (y1 )) ∈ LA ◦ Code.
110

Now, we prove a couple of properties about the composed verifier. First, we show that its
runtime is not much slower than the original verifier’s.
Proposition 17.7 (Runtime of the composed verifier). Let V and Codek be as in Definition 17.6.
Suppose AlgA runs in time T (n). Then there is an algorithm, which we denote AlgA ◦ Code,
deciding the language LA ◦ Code. In addition, on inputs (input, x0 , x1 , z0 , z1 ) in which |input| = n,
|x0 | = |x1 | = ℓQ (n), and |z0 | = |z1 | = m(ℓA (n)), the algorithm runs in time T (n) + tDec (ℓA (n)).
Proof. On input (input, x0 , x1 , z0 , z1 ), we define the action of AlgA ◦ Code as follows.
1. Compute n, the length of input. Set ℓ := ℓA (n).
2. Check that z0 and z1 have length m(ℓ). If they don’t, reject.
3. Compute y0 = AlgDec (ℓ, z0 ) and y1 = AlgDec (ℓ, z1 ). If either y0 or y1 is ⊥, reject.
4. Otherwise, we know that y0 , y1 ∈ {0, 1}ℓ . Run AlgA (input, x0 , x1 , y0 , y1 ). Accept if it accepts,
and reject if it rejects.
It is immediate that AlgA ◦ Code computes LA ◦ Code. As for the time complexity, Item 3 runs
in time tDec (ℓA (n)) and Item 4 runs in time T (n). Combined, these two give the bound in the
proposition statement.
Next, we show that this construction solves the “problem” discussed at the beginning of the
section, namely that if we perform answer reduction by replacing AlgA ◦ Code with a PCPP verifier,
rather than just AlgA , then the verifier will reject all inputs which are not in the language, not
just those which are δ-far, provided that those inputs are encoded as per Definition 17.6.
Proposition 17.8. Let V and Codek be as in Definition 17.6. Let s, γ > 0 be constants, and let
VPCPP be the PCPP verifier for the language LA ◦ Code guaranteed by Theorem 17.5 with these
parameters. Suppose that 1 − η(k) ≥ 2γ for all k. Then we have the following soundness condition.
◦ Soundness: Consider (input, x0 , x1 , z0 , z1 ) for input of length n, x0 and x1 of length ℓQ (n),
and z0 , z1 ∈ Subℓ , for ℓ := ℓA (n). Suppose this does not correspond to the encoding of an
accepting assignment in LA . In other words, suppose that there are no y0 , y1 ∈ {0, 1}ℓ such
that (input, x0 , x1 , y0 , y1 ) is in LA and z0 = Encℓ (y0 ), z1 = Encℓ (y1 ). Then VPCPP accepts
(input, x0 , x1 , z0 , z1 ) with probability at most s. In math, for every π it holds that
z0 ,z1 ,π
Pr[VPCPP
(input, x0 , x1 , |z0 | + |z1 |; R) accepts] ≤ s.
R

|z |+|z |

0
1
. By assumption,
Proof. Given (input, x0 , x1 , z0 , z1 ), write A := (LA ◦ Code)input,x0 ,x1 ∩ Fq(ℓ)
(z0 , z1 ) is not in A. Using this, we would like to show that (z0 , z1 ) is in fact γ-far from A, in which
case the PCPP verifier accepts with probability at most s.
To do this, suppose (z0′ , z1′ ) ∈ A. By design, there exists y0′ , y1′ ∈ {0, 1}ℓ such that z0′ = Enc(y0′ )
and z1′ = Enc(y1′ ). This means that z0′ , z1′ ∈ Subℓ . On the other hand, since (z0 , z1 ) is not in A, we
must have either z0′ 6= z0 or z1′ 6= z1 (or both). We will assume the first without loss of generality.
Then by the distance property of the code, since z0 , z0′ ∈ Subℓ , their normalized Hamming distance
is at least 1 − η(ℓ) ≥ 2γ. This immediately means that (z0 , z1 ) and (z0′ , z1′ ). are at least γ-far apart,
and we are done.

111

17.4

The answer reduction protocol

We are almost ready to state the answer reduction protocol. Before doing so, we discuss one final
nuisance, which is that we will also need the prover to encode their proof with an error-correcting
code. The reason is that we would like to query the proof on a view J sampled by the PCPP
verifier. However, the prover might cheat and respond based only on the view J rather than a
global proof π. To prevent this, we force them to commit to a global error-correcting encoding of
their proof π using a tester as in Definition 16.3. Then, we use the fact that the error-correcting
code embeds their string to allow us to extract the view J by asking for the coordinates in µ(J).
We now state the answer reduction protocol.
Definition 17.9. We instantiate the answer-reduced MIP∗ protocol with the following algorithms
and parameters.
◦ Let V = (AlgQ , AlgA ) be an MIP∗ verifier for a language L. Write LA for the language
decided by AlgA . Suppose on inputs of size n, the verifier V has question length ℓV,Q (n),
answer length ℓV,A (n), question time tV,Q (n), and answer time tV,A (n).
◦ Let Codek = (Enck , Deck , Subk ) be a (k, m, q, η, tDec , tEmb )-efficient code family with decoding
algorithm AlgDec and embedding µk .
◦ Let Gk be a game which tests for Codek with robustness χk (ǫ). Suppose it has question
length ℓG ,Q (k), answer length ℓG ,A (k), question time tG ,Q (k), and answer time tG ,A (k).
◦ Let s, δ > 0 be constants, and let VPCPP be the PCPP verifier for the language LA ◦ Code
guaranteed by Theorem 17.5 with these parameters. Suppose on inputs of size n it has proof
length ℓπ (n). By Proposition 17.7, LA ◦ Code is in time tcompose (n) = tV,A (n) + tDec (ℓV,A (n)).
We can therefore write VPCPP ’s verification time as
tPCPP (n) = poly(n + ℓV,Q (n), log(m(ℓV,A (n))), log(tcompose (n))).
Finally, ℓπ (n) = tcompose (n) · polylog(tcompose (n)).
Write ℓ1 := ℓV,A (n) and ℓ2 := ℓπ (n). Then the answer reduction game Ganswer (input; V, Code, G , s, δ)
is given in Figure 15. We write Vanswer for the corresponding verifier.
Theorem 17.10. Suppose V , Code, G , and VPCPP are as in Definition 17.9. Suppose s, γ are chosen to be constants such that η(k) ≥ 2γ for all k. Suppose further that V has the following property:
for any input in L, the provers have a real commuting EPR strategy with value 1. Then Vanswer is
also an MIP∗ verifier for L with the following two conditions:
◦ (Completeness) If input ∈ L, then there is a value-1 strategy.
◦ (Soundness) Given input, suppose there is a strategy with value 1 − ǫ. Then there is a strategy
for V on input input with value 1 − δ(ǫ), where δ(ǫ) is given by
δ(ǫ) := poly(χℓ1 (poly(ǫ)), χℓ2 (poly(ǫ)), η(ℓ1 ), η(ℓ2 )).
Hence, if we choose our parameters so that 1 − δ(ǫ) is greater than the soundness of V , this implies
that Vanswer is an MIP∗ verifier for L with soundness 1 − ǫ.

112

Flip two unbiased coins b, c ∼ {0, 1}. Sample questions (x0 , x1 ) ∼ AlgQ (input). Sample a view
I 0 , I 1 , J ∼ VPCPP (input, x0 , x1 ). Set J ′ = µℓ2 (J ). Select i0 , i1 ∈ [m(ℓ1 )] and j ∈ [m(ℓπ (n))]
uniformly at random. Set T 0 = I 0 ∪ {i0 }, T 1 = I 1 ∪ {i1 }, and U = J ′ ∪ {j}. With probability 18
each, perform one of the following eight tests.
1. Verify: Distribute the question as follows:
◦ Player b: give (x0 , x1 ), T 0 , T 1 , U ; receive a0 , a1 , a2 .
Accept if VPCPP (instance, x0 , x1 ) accepts on a0 |I 0 , a1 |I 1 , a2 |J ′ .
2. Cross checks:
(a) Consistency test: Distribute the questions as follows:
◦ Player b: give (x0 , x1 ), T 0 , T 1 , U ; receive a0 , a1 , a2 .
◦ Player b: give (x0 , x1 ), T 0 , T 1 , U ; receive a′0 , a′1 , a′2 .

Accept if a0 = a′0 , a1 = a′1 , and a2 = a′2 .

(b) Answer cross-check: Distribute the questions as follows:
◦ Player b: give (x0 , x1 ), T 0 , T 1 , U ; receive a0 , a1 , a2 .
◦ Player b: give xc , T ′c ; receive a′c .

Accept if ac = a′c .

(c) Proof cross-check: Distribute the questions as follows:
◦ Player b: give (x0 , x1 ), T 0 , T 1 , U ; receive a0 , a1 , a2 .
◦ Player b: give x0 , x1 , U ; receive a′2 .

Accept if a2 = a′2 .
3. Code checks:

(a) Answer code check: Sample questions (w0 , w1 ) ∼ Gℓ1 (T c ). Distribute the questions
as follows:
◦ Player b: give xc , w 0 ; receive a0 .
◦ Player b: give xc , w 1 ; receive a1 .

Accept if Gℓ1 (T c ) accepts on a0 , a1 .

(b) Proof code check: Sample questions (w0 , w 1 ) ∼ Gℓ2 (U ). Distribute the questions as
follows:
◦ Player b: give x0 , x1 , w0 ; receive a0 .
◦ Player b: give x0 , x1 , w1 ; receive a1 .

Accept if Gℓ2 (U ) accepts on a0 , a1 .

Figure 15: The answer reduction game Ganswer (input; V, Code, G , s, δ).

113

Furthermore, the question and answer lengths and runtimes are dominated by two subroutines:
the “Verify” subroutine S1 and the “Code Check” subroutine S2 (consisting of both the answer code
check and the proof code check). The complexity of the Verify subroutine is
Q-length(S1 ) = O(ℓV,Q (n) + log(m(ℓV,A (n))) + log(m(ℓπ (n)))),
A-length(S1 ) = O(log(q(ℓV,A (n))) + log(q(ℓπ (n)))),
Q-time(S1 ) = O (tV,Q (n) + tPCPP (n) + tEmb (ℓπ (n))) ,
A-time(S1 ) = O(tPCPP (n)).
In addition, the complexity of the Code Check subroutine is
Q-length(S2 ) = O(ℓG ,Q (ℓV,A (n)) + ℓG ,Q (ℓπ (n)) + ℓV,Q (n)),
A-length(S2 ) = O(ℓG ,A (ℓV,A (n)) + ℓG ,A (ℓπ (n))),
Q-time(S2 ) = O(tG ,Q (ℓV,A (n)) + tG ,Q (ℓπ (n)) + tV,Q (n) + tEmb (ℓπ (n))),
A-time(S2 ) = O(tG ,A (ℓV,A (n)) + tG ,A (ℓπ (n))).
Thus, the complexity of the overall protocol is the sum of these two.
Proof. The fact that S1 and S2 dominate the lengths and runtimes of the protocol is because S1
dominates the lengths and runtimes of the two cross-check subroutines, whose questions and answers
are subsets of those in S1 . Now we compute the complexity of S1 .
◦ Question length: The pair (x0 , x1 ) has total length ℓV,Q (n) by definition. The pair I 0 , I 1
are subsets of indices of constant size into each of the implicit inputs of LA ◦ Code, which are
supposed to be encodings of strings of size ℓV,A (n). Hence, the encodings have size m(ℓV,A (n)),
and so each input is specified with the log of this many bits. Finally, J is a constant-sized
set of indices into a proof of size ℓπ (n), and µ(J) converts these into indices into an encoding
of of this proof. As the encoding has length m(ℓπ (n)), each index can be specified with the
log of this many bits.
◦ Answer length: The strings a0 , a1 contains values from an error-correcting code with alphabet q(ℓV,A (n)), and the string a2 contains values from an error-correcting code with alphabet
q(ℓπ (n)).
◦ Question time: The running time of AlgQ is tV,Q (n). The running time of VPCPP is tPCPP (n).
Finally, the running time to compute µ(J ) given J is tEmb (ℓπ (n)).
◦ Answer time: The running time is simply the running time of VPCPP , i.e. tPCPP (n).
As for the complexity of S2 , it just performs the code tester Gk for message lengths k = ℓV,A (n)
and ℓπ (n) and so inherits the lengths and runtimes of the tester for these two values of k, except
on top of that it also has to sample (x0 , x1 ) and compute J ′ . Sampling (x0 , x1 ) takes time tV,Q (n)
and contributes O(ℓV,Q (n)) to the question lengths, and computing J ′ takes time tEmb (ℓπ (n)).
Completeness. Suppose input is in L. Then there is a real commuting EPR strategy (ψ, M )
with value 1 for V on input. We will use this to demonstrate a value-1 strategy for Vanswer . This
will be the strategy (ψ, G) which uses the same EPR state |ψi and has measurement matrices G
defined as follows.
Fix questions x0 , x1 , T0 , T1 , and U . We begin by defining the simplest measurement,
xc
Gaxcc ,Tc := M[Enc
ℓ

114

1

(zc )|Tc =ac ] .

(79)

If Alice and Bob measure with M x0 and M x1 and receive strings z0 , z1 , then because this strategy
is value 1, we will always have V (input, x0 , x1 , z0 , z1 ) = 1. As a result, there always exists some
proof for VPCPP that (input, x0 , x1 , Encℓ1 (z0 ), Encℓ1 (z1 )) is in LA ◦ Code. We denote this proof
π(x0 , x1 , z0 , z1 ); if there are multiple such proofs, we pick one arbitrarily. Then we define the
measurement
Gax20 ,x1 ,U := (M x0 · M x1 )[Encℓ2 (π(x0 ,x1,z0 ,z1 ))|U =a2 .
(80)
Next, we define the measurement
,x1 ,T0 ,T1 ,U
Gax00,a
:= (M x0 · M x1 )[Encℓ1 (z0 )|T0 ,Encℓ1 (z1 )|T1 ,Encℓ2 (π(x0 ,x1 ,z0 ,z1 ))|U =a0 ,a1 ,a2 ] .
1 ,a2

Now, via Equations (79) and (80), the G measurement is exactly of the form required by Definition 16.3.
As a result, it can be extended to a measurement which passes the answer and proof code checks
with probability 1. Performing this extension concludes the design of the strategy.
By construction, this strategy passes the answer and proof code checks with probability 1. As
for the remaining tests, let us begin with the answer cross-check in the case of c = 0, the other
case being symmetric. Because M is a real commuting EPR strategy, by Fact 4.37 we have that
Max ⊗IBob ≃0 IAlice ⊗Max for any distribution on x. If we consider the measurement (M x0 ·M x1 )z0 ,z1 ,
then (M x0 · M x1 )z0 = Mzx00 . As a result,
(M x0 · M x1 )z0 ⊗ IBob ≃0 IAlice ⊗ Mzx00 .
Finally, by data processing (Fact 4.26), this implies that
(M x0 · M x1 )[Encℓ

1

(z0 )|T0 =a0 ]

x0
⊗ IBob ≃0 IAlice ⊗ M[Enc

′
ℓ1 (z0 )|T0 =a0 ]

.

But this is equivalent to saying that Gxa00 ,x1 ,T0 ,T1 ,U ⊗ IBob ≃0 IAlice ⊗ Gxa00 ,T0 , which implies passing
the cross-check test with probability 1. A similar argument holds for the other tests, with the
exception of the verification step.
Consider the measurement Mzx00 · Mzx11 . By construction and the properties of the PCPP verifier,
if this measurement always outputs z0 , z1 such that V (input, x0 , x1 , z0 , z1 ) = 1, then the G strategy
always passes the verify step. But because M is a real commuting EPR strategy, Mzx ⊗ IBob ≃0
IAlice ⊗ Mzx , which implies that
Mzx00 ⊗ Mzx11 ≈0 Mzx00 · Mzx11 ⊗ IBob .
Thus, these two measurements have the same output distribution. But the left-hand side always
outputs z0 , z1 which satisfy the verifier, because this strategy passes the verifier with probability 1.
This concludes the completeness step.
Soundness.
1 − ǫ.

Suppose input is not in L. Let (ψ, M ) be a strategy that passes with probability

Code checks. Passing the overall test with probability 1−ǫ means the strategy passes the answer
code check with probability 1 − 8ǫ. Given values c, xc , write 1 − ǫc,xc for the probability the code
check passes conditioned on these values. Then with probability at least 1 − 8ǫ1/2 , ǫc,xc ≤ ǫ1/2 .
When this occurs, Theorem 16.6 implies that there exists a measurement {Gxwc }w with outcomes
in Subℓ1 such that
c
Maxc ,Tc ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gx[w|
T =a]
c

115

with respect to the distribution of T c conditioned on c and xc . When this does not occur, we still
can assume such a measurement so that
c
Maxc ,Tc ⊗ IBob ≃1 IAlice ⊗ Gx[w|
T

c =a]

trivially, by Fact 4.19. Thus, if we average over c and xc ,
c
Maxc ,Tc ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gx[w|
T

(81)

c =a]

with respect to the distribution on c, xc , T c . A similar argument with respect to the consistency
guarantee of Theorem 16.6 implies that
Gxwc ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gxwc .

(82)

By Fact 4.26, this implies that
c
Gx[w|
T

c =a]

c
⊗ IBob ≃ IAlice ⊗ Gx[w|
T

c =a]

.

As a result, if we apply Fact 4.13 to this and Equation (81) and then use the triangle inequality
(Fact 4.28), we conclude
c
⊗ IBob
(83)
Maxc ,Ic ⊗ IBob ≈δ(ǫ) Gx[w|
I =a]
c

with respect to the distribution on c, xc , I c .
Applying a similar argument yet again, this time to the proof code check, implies that for every
x0 , x1 , there exists a measurement {Hwx0 ,x1 }w with outcomes in Subℓ2 such that
x0 ,x1
Max0 ,x1 ,U ⊗ IBob ≈δ(ǫ) H[w|
⊗ IBob
U =a]

(84)

with respect to the distribution on x0 , x1 , U . Thus, by Fact 4.32, we can assume that Equations (83)
and (84) hold with equality with a loss of only δ(ǫ) in the game value. In addition, by Theorem 4.1,
we can assume that the G and H measurements are all projective, possibly replacing ψ with a
different state.
Cross checks. Our next step is to apply the cross-checks. Passing these with probability 1 − δ(ǫ)
implies the bounds
0
Max00 ,x1 ,T0 ,T1 ,U ⊗ IBob ≃δ(ǫ) IAlice ⊗ Max00 ,T0 = IAlice ⊗ Gx[w|
T

=a0 ] ,

(85)

1
Max10 ,x1 ,T0 ,T1 ,U ⊗ IBob ≃δ(ǫ) IAlice ⊗ Max11 ,T1 = IAlice ⊗ Gx[w|
T

=a1 ] ,

(86)

0

1

x0 ,x1
Max20 ,x1 ,T0 ,T1 ,U ⊗ IBob ≃δ(ǫ) IAlice ⊗ Max20 ,x1 ,U = IAlice ⊗ H[w|
,
U =a2 ]
,x1 ,T0 ,T1 ,U
,x1 ,T0 ,T1 ,U
⊗ IBob ≃δ(ǫ) IAlice ⊗ Max00,a
.
Max00,a
1 ,a2
1 ,a2

(87)

At this point, we would like to apply Fact 4.35. To do so, we have to verify the distance property
of our functions, and this will follow from the fact that we augmented our index sets I 0 , I 1 , and J ′
with an additional uniformly random index. To see this, consider two nonequal w and w′ in Subℓ1 .
Then for them to agree on T 0 , they must agree on i0 , and this happens only η(ℓ1 ) fraction of the
time. The same holds for U , with the bound of η(ℓ2 ). As a result, Fact 4.35 implies the following:
1
consider the POVM measurement {Λxw00,x
,w1 ,π } with outcomes w0 , w1 in Subℓ1 and π in Subℓ2 defined
as
x0 ,x1
Λw
:= Gxw00 · Gxw11 · Hπx0 ,x1 · Gxw11 · Gxw00 .
(88)
0 ,w1 ,π
116

Then

x0 ,x1
Max00,a,x11,a,T20 ,T1 ,U ⊗ IBob ≃δ(ǫ) IAlice ⊗ Λ[w
0 |T

0

,w1 |T1 ,π|U =a0 ,a1 ,a2 ] .

(89)

⊗ IBob .

(90)

From this, Equation (87) implies
,x1 ,T0 ,T1 ,U
Max00,a
⊗ IBob ≈δ(ǫ) Λx[w00,x|T1
1 ,a2

0

,w1 |T1 ,π|U =a0 ,a1 ,a2 ]

Thus, by Fact 4.32, we can assume that Equation (90) holds with equality by replacing M with G,
incurring a loss of only δ(ǫ) in the game value. (Unlike before, here we do not invoke Theorem 4.1
on J x0 ,x1 to make it a projective measurement, as that would likely change the structure in
Equation (88), which we will need later.)
Verification. The strategy passes the verify check with probability 1 − δ(ǫ). By Equation (90)
(which we now assume is equality), this is the same probability as if we (i) sample x0 , x1 , (ii) use Λ
to draw w0 , w 1 , π, (iii) draw I 0 , I 1 , J conditioned on x0 , x1 , (iv) then draw T 0 , T 1 , U conditioned
on I 0 , I 1 , J , (v) compute a0 = w0 |T 0 , a1 = w1 |T 1 , and a2 = w2 |U , and (vi) give a0 |I 0 , a1 |I 1 , a2 |J
to VPCPP and accept if it accepts.
Condition on a fixed choice of x0 , x1 and a draw for w0 , w1 , π. The PCPP verifier receives
answers to its I 0 and I 1 queries based on w0 and w1 , which are in Subℓ1 . In addition, although π is
in Subℓ2 and may not correspond to the encoding of an actual proof string, the verifier only queries it
at points in the image of the embedding µℓ2 . As a result, the answers VPCPP receives to its J queries
are consistent with some fixed proof string. Thus, by Proposition 17.8, since 1 − η(k) ≥ 2γ for
all k, if the probability the verifier accepts is greater than s, then there are strings y0 , y1 ∈ {0, 1}ℓ1
such that w0 = Encℓ1 (y0 ), w1 = Encℓ1 (y1 ) and V (input, x0 , x1 , y0 , y1 ) = 1. Averaging over all x0 , x1
and w0 , w 1 , π, we conclude that
Pr[V (input, x0 , x1 , Decℓ1 (w0 ), Decℓ1 (w 1 )) = 1] ≥

1 − δ(ǫ) − s
= 1 − δ(ǫ).
1−s

(91)

Recall that the decoding map is one-to-one except on those strings not in the range of the encoding
map, which it maps to ⊥ instead. As we can assume that the verifier V always rejects when it
receives ⊥ for an answer, this tells us that Decℓ1 (w0 ), Decℓ1 (w1 ) 6= ⊥ with probability at least
1 − δ(ǫ).
Wrapping it up. Now we give a strategy for causing the verifier V to accept with high probability
on input. It uses state ψ, and given question x it applies the measurement {Axa }a defined as
Axa := Gx[Decℓ

1

(w)=a] .

Consider the verifier V ′ which samples (x0 , x1 ), gives them to Alice and Bob, receives w0 , w1 , and
accepts if V (input, x0 , x1 , Decℓ1 (w 0 ), Decℓ1 (w1 )) = 1. Then V accepts on strategy A with the same
probability that V ′ accepts on strategy G. In other words, if we define S(x0 , x1 ) to be the set of
(w0 , w1 ) such that
V (input, x0 , x1 , Decℓ1 (w0 ), Decℓ1 (w1 )) = 1,
then the probability that V ′ accepts on strategy G is
X
E
hψ| Gxw00 ⊗ Gxw11 |ψi .
(x0 ,x1 )

w0 ,w1 ∈S(x0 ,x1 )

117

(92)

To show this is large, we begin by showing that the G’s commute with each other. To see this,
note that Equations (85) and (86) implies that for a fixed c ∈ {0, 1},
x0 ,x1
Λ[w
c |T

c =ac ]

⊗ IBob ≃δ(ǫ) IAlice ⊗ Gx[wc ′ |T
c

c =ac ]

.

However, by the distance properties of our code and the fact that T c contains a uniformly random
index, this implies that
x0 ,x1
Λw
⊗ IBob ≃δ(ǫ) IAlice ⊗ Gxwcc .
(93)
c
As a result,
Gxw00 · Gxw11 ⊗ IBob ≈δ(ǫ) Gxw00 ⊗ Λxw01,x1

x0 ,x1
≈δ(ǫ) IAlice ⊗ Λw
· Λxw00,x1
1

x0 ,x1
≈δ(ǫ) IAlice ⊗ Λw
· Λxw01,x1
0

≈δ(ǫ) Gxw11 ⊗ Λxw00,x1

≈δ(ǫ) Gxw11 · Gxw00 ⊗ IBob .
A similar argument as the one establishing (93) implies that
Gxwcc ⊗ IBob ≃δ(ǫ) IAlice ⊗ Gxwcc .
Thus,
Gxw00 ⊗ Gxw11 = Gxw00 · Gxw00 ⊗ Gxw11

≈δ(ǫ) Gxw00 · Gxw00 · Gxw11 ⊗ IBob

≈δ(ǫ) Gxw00 · Gxw11 · Gxw00 ⊗ IBob
1
= Λxw00,x
,w1 ⊗ IBob .

As a result, by Fact 4.31, Equation (92) is at least 1 − δ(ǫ) by Equation (91). This concludes the
proof of the theorem.

17.5

Applying the answer reduction protocol

In this section, we instantiate Theorem 17.10 with the low-degree code and then apply it to our
NEEXP protocol.
Theorem 17.11. Let V = (AlgQ , AlgA ) be an MIP∗ verifier for a language L. Write LA for the
language decided by AlgA . Suppose on inputs of size n, the verifier V has question length ℓV,Q (n),
answer length ℓV,A (n), question time tV,Q (n), and answer time tV,A (n). Then there exists another
MIP∗ verifier Vans for L with the following parameters.
Q-length(Vans ) = O(ℓV,Q (n) + log(ℓV,A (n)) + log(tV,A (n))),
A-length(Vans ) = O(polylog(ℓV,A (n)) + polylog(tV,A (n))),
Q-time(Vans ) = O (tV,Q (n)) + poly(n + ℓV,Q (n), log(ℓV,A (n)), log(tV,A (n))) ,
A-time(Vans ) = poly(n + ℓV,Q (n), log(ℓV,A (n)), log(tV,A (n))).
Proof. We instantiate the low-degree code in Fact 16.9. It gives an error correcting code with
parameters (n, poly(n), polylog(n), polylog(n)−1 , poly(n), polylog(n)) and a c-subset test Gk with
robustness χk (ǫ) = poly(ǫ, log(k)−1 ) such that
Q-time(Gk ) = poly(log k, c),

A-time(Gk ) = poly(log(k)c ),

118

A-length(Gk ) = O(log(k)2c ).

Q-length(Gk ) = O(c log k),

1
. At this point, the theorem follows immediately, but
We then apply Theorem 17.10 with s, γ = 10
as deriving it can be cumbersome, we fill in the details.
By construction, tDec (n) = poly(n). As a result,

tcompose (n) = tV,A (n) + tDec (ℓV,A (n)) = tV,A (n) + poly(ℓV,A (n)).
Thus,
ℓπ (n) = tcompose (n) · polylog(tcompose (n)) = poly(tV,A (n), ℓV,A (n)).
Now, m(n) = poly(n). Thus,
tPCPP (n) = poly(n + ℓV,Q (n), log(m(ℓV,A (n))), log(tcompose (n)))
= poly(n + ℓV,Q (n), log(ℓV,A (n)), log(tV,A (n))).
Furthermore, q(n) = polylog(n) and tEmb (n) = polylog(n). As a result,
log(m(ℓπ (n))) = O(log(ℓV,A (n)) + log(tV,A (n))),
log(q(ℓπ (n))) = O(log log(ℓV,A (n)) + log log(tV,A (n))),
tEmb (ℓπ (n)) = poly(log(ℓV,A (n)), log(tV,A (n))).
The theorem now follows from applying these bounds to Theorem 17.10.
Crucially, although polynomial factors of tV,Q (n) and ℓV,Q (n) appear in Theorem 17.11, only
the logarithms of tV,A (n) and ℓV,A (n) appear in this theorem. As a result, if we apply this to
Corollary 15.9, we arrive at our main result.
Theorem 17.12. There is an MIP∗ verifier G for Succinct-Succinct-3Sat with parameters
Q-length(G ) = O(n),

A-length(G ) = poly(n),

Q-time(G ) = poly(n),

A-time(G ) = poly(n).

References
[ALM+ 98]

Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.
Proof verification and the hardness of approximation problems. Journal of the ACM,
45(3):501–555, 1998. 1, 17.2

[ARW17]

Amir Abboud, Aviad Rubinstein, and Ryan Williams. Distributed PCP theorems for
hardness of approximation in P. In Proceedings of the 58th Annual IEEE Symposium
on Foundations of Computer Science, 2017. 2.5, 17.1

[AS98]

Sanjeev Arora and Shmuel Safra. Probabilistic checking of proofs: a new characterization of NP. Journal of the ACM, 45(1):70–122, 1998. 1, 17.2

[Bel64]

John Bell. On the Einstein Podolsky Rosen paradox. Physics, 1(3):195–200, 1964. 1

[BFL91]

László Babai, Lance Fortnow, and Carsten Lund. Non-deterministic exponential time
has two-prover interactive protocols. Computational complexity, 1(1):3–40, 1991. 1,
2.2, 11
119

[BFLS91]

László Babai, Lance Fortnow, Leonid A Levin, and Mario Szegedy. Checking computations in polylogarithmic time. In Proceedings of the 23rd Annual ACM Symposium
on Theory of Computing, pages 21–32, 1991. 17.2, 17.3

[BOGKW88] Michael Ben-Or, Shafi Goldwasser, Joe Kilian, and Avi Wigderson. Multi-prover
interactive proofs: How to remove intractability assumptions. In Proceedings of the
20th Annual ACM Symposium on Theory of Computing, pages 113–131, 1988. 1
[BSGH+ 05]

Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil Vadhan.
Short PCPs verifiable in polylogarithmic time. In Proceedings of the 20th Annual
IEEE Conference on Computational Complexity, pages 120–134, 2005. 17.2, 17.3,
17.4

[BSGH+ 06]

Eli Ben-Sasson, Oded Goldreich, Prahladh Harsha, Madhu Sudan, and Salil Vadhan.
Robust PCPs of proximity, shorter PCPs, and applications to coding. SIAM Journal
on Computing, 36(4):889–974, 2006. 17.2, 17.3

[CGJV18]

Andrea Coladangelo, Alex Grilo, Stacey Jeffery, and Thomas Vidick. Verifier-on-aleash: new schemes for verifiable delegated quantum computation, with quasilinear
resources. In 21st Conference on Quantum Information Processing, 2018. 8.2

[CHTW04]

Richard Cleve, Peter Hoyer, Benjamin Toner, and John Watrous. Consequences and
limits of nonlocal strategies. In Proceedings of the 19th Annual IEEE Conference on
Computational Complexity, pages 236–249, 2004. 1

[Col06]

Roger Colbeck. Quantum and relativistic protocols for secure multi-party computation. PhD thesis, University of Cambridge, 2006. 1

[CY14]

Matthew Coudron and Henry Yuen. Infinite randomness expansion with a constant
number of devices. In Proceedings of the 46th Annual ACM Symposium on Theory
of Computing, pages 427–436, 2014. 1

[DR06]

Irit Dinur and Omer Reingold. Assignment testers: Towards a combinatorial proof
of the PCP theorem. SIAM Journal on Computing, 36(4):975–1024, 2006. 17.2

[Eke91]

Artur Ekert. Quantum cryptography based on Bell’s theorem. Physical review letters,
67(6):661, 1991. 1

[EPR35]

Albert Einstein, Boris Podolsky, and Nathan Rosen. Can quantum-mechanical description of physical reality be considered complete? Physical review, 47(10):777,
1935. 1

[FJVY19]

Joseph Fitzsimons, Zhengfeng Ji, Thomas Vidick, and Henry Yuen. Quantum proof
systems for iterated exponential time, and beyond. In Proceedings of the 51st Annual
ACM Symposium on Theory of Computing, 2019. 1, 1, 1

[FL18]

Bill Fefferman and Cedric Yen-Yu Lin. A complete characterization of unitary quantum space. In Proceedings of the 9th Innovations in Theoretical Computer Science,
pages 4:1–4:21, 2018. 1

[FV15]

Joseph Fitzsimons and Thomas Vidick. A multiprover interactive proof system for
the local Hamiltonian problem. In Proceedings of the 6th Innovations in Theoretical
Computer Science, pages 103–112, 2015. 1
120

[Har10]

Prahladh
Harsha.
Lecture
9
from
Limits
of
Approximation
Algorithms:
PCPs
and
Unique
Games.
Found
at
http://www.tcs.tifr.res.in/~prahladh/teaching/2009-10/limits/lectures/lec09.pdf,
2010. 11

[Hås97]

Johan Håstad. Some optimal inapproximability results. In Proceedings of the 29th
Annual ACM Symposium on Theory of Computing, pages 1–10, 1997. 1

[IKW12]

Tsuyoshi Ito, Hirotada Kobayashi, and John Watrous. Quantum interactive proofs
with weak error bounds. In Proceedings of the 3rd Innovations in Theoretical Computer Science, pages 266–275, 2012. 1

[IV12]

Tsuyoshi Ito and Thomas Vidick. A multi-prover interactive proof for NEXP sound
against entangled provers. In Proceedings of the 53rd Annual IEEE Symposium on
Foundations of Computer Science, pages 243–252, 2012. 1

[Ji17]

Zhengfeng Ji. Compression of quantum multi-prover interactive proofs. In Proceedings
of the 49th Annual ACM Symposium on Theory of Computing, pages 289–302, 2017.
1, 1

[KRR14]

Yael Kalai, Ran Raz, and Ron Rothblum. How to delegate computations: the power
of no-signaling proofs. In Proceedings of the 46th Annual ACM Symposium on Theory
of Computing, pages 485–494, 2014. 1

[MBG+ 13]

Alfred J Menezes, Ian F Blake, XuHong Gao, Ronald C Mullin, Scott A Vanstone,
and Tomik Yaghoobian. Applications of finite fields. Springer Science & Business
Media, 2013. 3.1, 3.1

[Mei14]

Or Meir. Combinatorial PCPs with efficient verifiers. Computational Complexity,
23(3):355–478, 2014. 17.2

[Mie09]

Thilo Mie. Short PCPPs verifiable in polylogarithmic time with o(1) queries. Annals
of Mathematics and Artificial Intelligence, 56(3-4):313–338, 2009. 17.2, 17.5

[MR08]

Dana Moshkovitz and Ran Raz. Sub-constant error low degree test of almost-linear
size. SIAM Journal on Computing, 38(1):140–180, 2008. 3.5

[MY98]

Dominic Mayers and Andrew Yao. Quantum cryptography with imperfect apparatus.
In Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer
Science, pages 503–509, 1998. 1

[NV18a]

Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a
quantum entangled games PCP. In Proceedings of the 59th Annual IEEE Symposium
on Foundations of Computer Science, 2018. 1, 1, 2.3, 3.6, 4.41, 4.9, 4.9, 6, 6.1, 6.1,
6.4, 6.1, 6.5, 6.6, 17.2

[NV18b]

Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard.
In Proceedings of the 33rd Annual IEEE Conference on Computational Complexity,
2018. 1, 1, 1, 4.7, 4.40, 4.41

[O’D05]

Ryan O’Donnell. A history of the PCP theorem, 2005. 17.2

121

[Pap94]

Christos Papadimitriou. Computational complexity. Addison Wesley, 1994. 3.7, 3.7,
3.7, 3.7

[Per12]

Attila Pereszlényi. Multi-prover quantum Merlin-Arthur proof systems with small
gap. Technical report, arXiv:1205.2761, 2012. 1

[RS97]

Ran Raz and Shmuel Safra. A sub-constant error-probability low-degree test, and
a sub-constant error-probability PCP characterization of NP. In Proceedings of the
29th Annual ACM Symposium on Theory of Computing, pages 475–484, 1997. 3.5,
3.12

[RUV13]

Ben Reichardt, Falk Unger, and Umesh Vazirani. A classical leash for a quantum
system: Command of quantum systems via rigidity of CHSH games. Nature, 496:456–
460, 2013. 1

[Sch80]

Jacob Schwartz. Fast probabilistic algorithms for verification of polynomial identities.
Journal of the ACM, 27(4):701–717, 1980. 3.6

[Slo16]

William Slofstra. Tsirelson’s problem and an embedding theorem for groups arising
from non-local games. Technical report, arXiv:1606.03140, 2016. 1, 1

[Slo19]

William Slofstra. The set of quantum correlations is not closed. In Forum of Mathematics, Pi, volume 7, page e1, 2019. 1, 1

[SW88]

Stephen Summers and Reinhard Werner. Maximal violation of Bell’s inequalities
for algebras of observables in tangent spacetime regions. Annales de l’IHP Physique
théorique, 49(2):215–243, 1988. 1

[Tsi80]

Boris Tsirelson. Quantum generalizations of Bell’s inequality. Letters in Mathematical
Physics, 4(2):93–100, 1980. 1

[Vid11]

Thomas Vidick. The complexity of entangled games. PhD thesis, University of California, Berkeley, 2011. 4.4

[Vid16]

Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate.
SIAM Journal on Computing, 45(3):1007–1063, 2016. 1, 4.7

[WBMS16]

Xingyao Wu, Jean-Daniel Bancal, Matthew McKague, and Valerio Scarani. Deviceindependent parallel self-testing of two singlets. Physical Review A, 93(6):062121,
2016. 6.1

[Zip79]

Richard Zippel. Probabilistic algorithms for sparse polynomials. In Proceedings of
the 2nd International Symposium on Symbolic and Algebraic Manipulation, pages
216–226, 1979. 3.6

122

