arXiv:1909.12533v1 [physics.comp-ph] 27 Sep 2019

EFFICIENT COMPUTATION OF THE DENSITY MATRIX WITH
ERROR CONTROL ON DISTRIBUTED COMPUTER SYSTEMS
ANASTASIA KRUCHININA, ELIAS RUDBERG AND EMANUEL H. RUBENSSON
A BSTRACT. The recursive polynomial expansion for construction of a
density matrix approximation with rigorous error control [J. Chem. Phys.
128, 074106 (2008)] is implemented in the quantum chemistry program
E RGO [SoftwareX 7, 107 (2018)] using the Chunks and Tasks matrix
library [Parallel Comput. 57, 87 (2016)]. The expansion is based on
second-order polynomials and accelerated by the scale-and-fold technique [J. Chem. Theory Comput. 7, 1233 (2011)]. We evaluate the performance of the implementation by computing the density matrix from
the Fock matrix in the large-scale self-consistent field calculations. We
demonstrate that the amount of communicated data per worker process
tends to a constant with increasing system size and number of computer
nodes such that the amount of work per worker process is fixed.

1. I NTRODUCTION
The density matrix D is constructed from the Fock/Kohn-Sham matrix
F in each step of self-consistent field (SCF) calculations emerging in the
Hartree–Fock method [14] and Kohn–Sham density functional theory [7, 9].
In orthogonal basis set, the matrix F has eigenvalues λi and corresponding
eigenvectors yi :
Fyi = λi yi .

(1)

Each eigenpair (eigenvalue and eigenvector) corresponds to one molecular
orbital. Let the eigenvalues of the matrix F be arranged in ascending order
(2)

λ1 ≤ λ2 ≤ . . . ≤ λhomo < λlumo ≤ . . . ≤ λN−1 ≤ λN ,

where λhomo is the eigenvalue corresponding to the highest occupied molecular orbital (homo eigenvalue), and λlumo is the eigenvalue corresponding
to the lowest unoccupied molecular orbital (lumo eigenvalue). We assume
that the homo-lumo gap ξ := λlumo − λhomo is non-zero. The number of
occupied orbitals we denote with nocc . The subspace spanned by the eigenvectors of the matrix F, that correspond to the occupied molecular orbitals,
is referred to as the occupied invariant subspace of F. At zero temperature
Date: July 8, 2021.
1

2

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

the density matrix is the matrix for orthogonal projection onto the occupied
invariant subspace of F:
nocc

(3)

D=

∑ yiyTi .

i=1

Computation of the density matrix using (3) requires diagonalization of the
matrix F which scales cubically with the matrix size, limiting the calculations to rather small systems. Alternative density matrix methods see the
density matrix construction as an evaluation of a matrix function
(4)
(5)

D = θ (µI − F),
(
0 if x < 0,
θ (x) =
1 otherwise,

where µ is located in the homo-lumo gap. Recursive polynomial expansions, also known as purification methods, utilize low-order polynomials fi ,
i = 0, 1, 2, . . . to approximate the shifted and scaled step function θ (µ − x):
(6)

D ≈ Xn = fn ( fn−1 (. . . f0 (F) . . .)).

Recursive polynomial expansions are implemented in a number of electronic structure codes including CP2K [25], E RGO [23, 24], H ONPAS [13],
and LATTE [5]. The initial polynomial f0 usually maps the eigenvalues of
F into the interval [0, 1] in reverse order. The choice of low-order polynomials fi , i ≥ 1 depends on the method, but typically one or two matrix multiplications per iteration are required. Niklasson [12] proposed an efficient
recursive expansion algorithm based on the second-order spectral projection polynomials x2 and 2x − x2 . We will refer to this algorithm as the SP2
algorithm. In the original SP2 algorithm, the polynomial in each iteration
is chosen based on the matrix trace, which may result in slow convergence
in some cases. The convergence can be improved by selecting polynomials
based on the homo and lumo eigenvalues [22]. This will also remove the
explicit dependence on the system size. In the scheme proposed in [17],
homo and lumo eigenvalue estimates are obtained at negligible cost using
Frobenius norms and traces of intermediate matrices Xi − Xi2 . The homo
and lumo estimates for the current matrix F are obtained at the end of the
recursive expansion, but they can be propagated to the following SCF cycle
and used there in the recursive expansion. In the first SCF cycles, where the
eigenvalue bounds are not available yet or not accurate enough, we use the
trace-correcting recursive expansion mentioned above [12, 22]. Knowledge
of homo and lumo eigenvalue estimates allows for further improvement of
the SP2 scheme convergence by making use of the scale-and-fold technique
proposed in [15]. The SP2 scheme, accelerated using the scale-and-fold

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

3

technique, we refer to as the SP2ACC recursive expansion. We use the
parameterless stopping criteria for recursive expansions developed in [10],
which automatically stop the iterations when the level of numerical errors is
reached and the final density matrix approximation cannot be substantially
improved.
Matrices, obtained in electronic structure calculations, posses the exponential decay property of matrix element magnitude [3, 16]. After removal
of small matrix elements (truncation), matrices are sparse, and the matrix
sparsity can be preserved throughout the recursive expansion iterations. Another consequence of the exponential decay property is that non-negligible
matrix elements tend to be localized in certain regions. We implement the
truncation scheme proposed in [22], allowing for rigorous control of the error in the occupied invariant subspace, which is a measure of the density matrix approximation error. The error is controlled in the spectral norm. However, we use a computationally cheaper upper bound of the spectral norm
for selecting truncation threshold values in each iteration. For that purpose,
we propose the Frobenius-infinity mixed matrix norm, which provides an
upper bound of the spectral norm for Hermitian matrices, and which has the
same asymptotic behavior as the spectral norm for matrices with localization properties of element magnitudes.
The main computational cost in the recursive expansion comes from
sparse matrix multiplications, which makes it attractive for parallel computations. Parallel algorithms, developed for dense matrix-matrix multiplication, take advantage of a uniform distribution of matrix elements over computational resources. A few efficient algorithms for sparse matrix-matrix
multiplication use similar ideas. A uniform distribution of non-zero matrix
elements can be obtained dynamically during runtime by a random permutation of matrix rows and columns (see e. g. [1, 4, 6, 11]). The permuted
matrices are divided into blocks with a sparse matrix representation of elements at the block level. Then, some algorithm, inspired by the parallel
dense matrix-matrix multiplication, is used for managing the communication between computer nodes. Individual blocks are multiplied locally using a chosen algorithm for sparse matrix-matrix multiplication. The communication cost per node of the
√ 2D algorithm, utilizing a two-dimensional
process grid [1], scales as O( N) with the matrix size N in a weak scaling
regime. The parallel performance can be improved by introducing a third
process grid dimension [1, 6, 11]. Compared to the 2D approach, in a weak
scaling limit the communication cost per node of the 3D algorithm is constant [2]. Methods involving random permutation were originally developed
for the general sparse matrix-matrix multiplication. By randomly permuting matrix rows and columns, any locality information is lost. Furthermore,

4

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

permutations of matrix rows and columns may be needed for some intermediate matrices in the recursive expansion to enforce load balance. An
efficient sparse matrix-matrix multiplication, utilizing the locality of nonzero elements, has been implemented in the Chunks and Tasks matrix library (CHTML) [21]. It has been shown that the dynamic work and data
distribution over computational resources allows for efficient utilization of
data locality and constant communication cost per worker process in a weak
scaling regime [21].
In this work, we expand CHTML with matrix operations required in the
recursive expansion, and implement the whole recursive expansion using
CHTML in the quantum chemistry code Ergo [24]. We evaluate the weak
scaling performance of our implementation using the Frobenius-infinity
mixed norm for the estimation of the spectral norm in the error control
scheme. We request the same accuracy of the density matrix approximation
for all system sizes. The usage of the Frobenius-infinity mixed norm allows
us to keep the number of non-zero elements per row asymptotically constant
with increasing system size. We show numerically that the communication
cost per node is constant in a weak scaling limit.
2. E RROR CONTROL
A common approach to preserve matrix sparsity is to remove blocks of
elements with norms smaller than some predefined threshold value. Often
such threshold values are provided by the user and not explicitly related to
the desired accuracy of the density matrix approximation. In [22], an upper
bound of the forward error kD − Xn k is given by
(7)

kD − Xn k ≤ kD − PXn k + kPXn − Xn k ,

where k·k is any unitary-invariant matrix norm, PXn is the matrix for orthogonal projection onto the occupied subspace Xn of the matrix Xn . The
first norm kD − PXn k measures erroneous rotations of the occupied invariant subspace or errors in eigenvectors. A scheme for keeping the error in the
occupied invariant subspace smaller than a desired accuracy γ is proposed
in [22]. Let Xei = Xi + Ei be the matrix obtained after truncation of Xi , where
the truncation is written as an explicit perturbation of Xi by the error matrix
Ei . Then, it has been shown in [22], that
n

(8)

kEi k
,
˜
i=0 ξi − kEi k2

kD − PXn k ≤ ∑

where ξ˜i is a lower bound of the homo-lumo gap in iteration i of the recursive expansion. Assume that an upper bound nmax of the total number

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

5

of iterations in the recursive expansion is known. Then, if the truncation
threshold values τi are chosen such that:
γ
˜
nmax +1 ξi
(9)
τi :=
,
1 + nmaxγ +1
and the truncation is performed so that
(10)

kEi k ≤ τi ,

then the total error in the occupied subspace is bounded by γ:
(11)

kD − PXn k ≤ γ.

The error in the occupied subspace is increasing with the number of iterations, and any lost accuracy cannot be recovered in later iterations of the
recursive expansion.
As mentioned above, any unitary-invariant norm can be used in the error control scheme. Examples of unitary-invariant norms are the spectral
and Frobenius norms. The spectral k·k2 and Frobenius k·kF norms of a
Hermitian matrix A = (ai j ) of size N are defined as:
(12)
(13)

kAk2 = ρ(A),
v
u N
u
kAkF = t ∑ a2i j ,
i, j=0

where the spectral radius ρ(A) is equal to the largest by absolute value
eigenvalue of A. The spectral norm depends only on the eigenvalue distribution, but it is expensive to compute for large systems. However, the
computationally cheaper Frobenius norm depends on the system size, making its usage inappropriate in large scale calculations. Thus, we use the
spectral norm in the error control scheme. If we can measure some upper bound Ŝi to the spectral norm of Ei , inequality (10) can be satisfied by
making sure that Ŝi ≤ τi .
In the presence of numerical errors the computed density matrix approximation slightly deviates from idempotency. The second norm kPXn − Xn k
in (7) measures errors in the density matrix approximation coming from
errors in eigenvalues. In [10], we proposed a parameterless stopping criteria for the recursive expansions, which do not require any user defined
tolerance. The criteria are satisfied when the numerical errors in the density matrix approximation, coming from the removal of small matrix elements and round-off errors, prevent any further improvement of the result.
The idea is to observe the numerically computed convergence order during the recursive expansion and automatically detect the convergence order

6

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

drop. The convergence order in iteration i is controlled using the idempotency error Xi − Xi2 , which can be considered as a measure of the error
PXi − Xi . Note that the error kPXn − Xn k may be decreased to a required
level of accuracy by reducing truncation in the last recursive expansion iterations. However, due to the increased computational cost, we do not use
this possibility here, and choose truncation values given by (9) throughout
the whole recursive expansion. If the SP2ACC scheme is used, we fall back
to the SP2 scheme in the final iterations when acceleration does not have a
strong effect on the convergence, and use the stopping criterion developed
for the SP2 scheme, as suggested in [10]. In [10], the proposed stopping
criteria use the spectral norm. In addition, it is shown numerically, that the
Frobenius norm can be used instead of the spectral norm. In contrast to
the error control scheme above, the dependence of the Frobenius norm on
the system size is less critical in the stopping criterion, since the Frobenius
norm provides a good estimate to the spectral norm close to convergence.
In the following section we consider matrix norms providing upper
bounds to the spectral norm. Such norms can be used to ensure (10).
3. U PPER BOUNDS FOR THE SPECTRAL NORM
In [19], the Frobenius-spectral mixed norm is proposed. Let a matrix A
be partitioned into submatrices:


A11 A12
(14)
A=
.
A21 A22
Then the Frobenius-spectral mixed norm of the matrix A is defined as:


kA11 kF kA12 kF
kAkm =
(15)
.
kA21 kF kA22 kF 2
The Frobenius-spectral mixed norm gives an upper bound of the spectral
norm [19]:
(16)

kAk2 ≤ kAkm .

Moreover, the Frobenius-spectral mixed norm has the same asymptotic behavior as the spectral norm, and is computationally cheaper than the spectral
norm [19].
In this work, we introduce a Frobenius-infinity mixed norm, which we
refer to as Frob-Inf and denote k·kM , obtained by the combination of the
Frobenius and infinity matrix norms. The infinity norm of a matrix A = (ai j )
of size N is equal to the largest sum of absolute values of elements in each

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

7

matrix row:
N

(17)

kAk∞ = max

∑ |ai j |.

1≤i≤N j=1

If the matrix A is divided into submatrices as in (14), the Frob-Inf norm of
the matrix A is defined as:


kA11 kF kA12 kF
kAkM =
(18)
.
kA21 kF kA22 kF ∞
In practice, with increasing matrix size the submatrix size is kept fixed,
and the number of submatrices in Frobenius-spectral and Frob-Inf norms is
increasing. Thus, the Frobenius-spectral mixed norm requires computation
of the spectral norm of matrices of growing size, which may be expensive
for very large systems. In addition, efficient implementation of the spectral
norm is difficult on distributed systems.
Under the assumption that the matrix A is Hermitian, the infinity norm
gives an upper bound of the spectral norm [8]. Thus, we have
(19)

kAk2 ≤ kAkm ≤ kAkM ,

which proves that the Frob-Inf norm is an upper bound of the spectral norm.
We note that the infinity norm can be used for estimating the spectral norm
in the error control scheme. However, due to the simplicity of the implementation on distributed systems we chose to use the Frob-Inf norm instead.
We perform numerical tests in Matlab and compare values of matrix
norms. In Figure 1a we show results for a symmetric banded matrix with
random elements drawn from the standard uniform distribution on the open
interval ]0, 10−3 [ and bandwidth 2 × 300 + 1. The Frob-Inf norm, computed
with block sizes 100 and 500, is much smaller than the Frobenius norm and
has the same asymptotic behavior as the spectral norm. However, symmetric random permutation of rows and columns delays the moment when the
Frob-Inf norm becomes proportional to the spectral norm compared to the
non-permuted case. Note that in Figure 1b we use much smaller block sizes
than in Figure 1a. It is hard to predict the behavior of the Frob-Inf norm
for general matrices. However, if matrices posses the locality property and
number of non-zeros per row does not grow significantly with matrix size,
we can expect that, for large enough matrix sizes, the Frob-Inf norm will be
proportional to the spectral norm, and our practical experiments support it.
4. D ENSITY MATRIX CONSTRUCTION
In this section we describe the density matrix construction using the
SP2ACC recursive expansion implemented in the quantum chemistry program Ergo [24] and parallelized using CHTML. Assuming that homo and

8

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

(a) Banded matrices

(b) Randomly permuted matrices

F IGURE 1. Comparison of spectral, Frobenius (“Frob”) and
Frob-Inf norms. The number given in parenthesis for the
Frob-Inf norm is the used block size. In the left panel
we present results for banded matrices with bandwidth 2 ×
300 + 1. In the right panel we perform the random permutation of rows and columns of the banded matrices shown in
the left panel.

lumo estimates are available, the density matrix algorithm based on the
SP2ACC expansion may be divided into three steps:
Step 1 Initialize:
• Following Algorithm 4 in [10], estimate the number of recursive expansion iterations nmax , determine the acceleration parameters αi and
the polynomial sequence pi , i = 1, 2, . . . , nmax , where pi = 1 if fi (x) =
((1 − αi ) + αi x)2 and pi = 0 if fi (x) = 2αi x − (αi x)2 . Moreover, select
the iteration nmin when acceleration should be switched off, i. e. αi = 1
for i ≥ nmin .
• Select truncation threshold values τi , i = 0, 1, . . . , nmax defined by (9).
• Rescale the matrix F such that all its eigenvalues lie in the interval
[0, 1] in reverse order, see Algorithm 1. Here λmax ≥ λN and λmin ≤ λ1
are obtained using Gershgorin circles theorem.
Step 2 Recursively apply polynomials pi until the stopping criterion is satisfied, see Algorithm 2. The constant C in line 2 of Algorithm 2 is used
in the stopping criterion for the SP2 recursive expansion, and it is derived
in [10].
Step 3 Compute homo and lumo eigenvalue estimates using Frobenius
norms ei and traces ti following Algorithm 3 in [17]. These estimates are
then propagated to the next SCF cycle.

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

9

Algorithm 1 Initialization
max I−F
X0 = λλmax
−λmin
e0 = X0 + E0 , kE0 k ≤ τ0
2: X
M
2
e
e
3: e0 = X0 − X0
F 

e0 − Xe2
4: t0 = trace X

1:

. Truncation

0

Algorithm 2 The SP2ACC recursive expansion
1: Input: X0 ; αi , pi , τi , i = 1, . . . , nmax ; nmin
2: C = 6.8872
. Needed for the stopping criterion
3: for i = 1, 2, . . . , nmax do
4:
if pi = 1 then
5:
Xi = ((1 − αi )I + αi Xei−1 )2
6:
else
7:
Xi = 2αi Xei−1 − (αi Xei−1 )2
8:
end if
9:
Xei = Xi + Ei , kEi kM ≤ τi
. Truncation
10:
ei = Xei − Xei2
F 

11:
ti = trace Xei − Xe2
i

12:
13:
14:
15:
16:
17:

if i ≥ nmin and pi 6= pi−1 and ei > Ce2i−2 then
n=i
break
end if
end for
Output: Xn ; ei , ti , i = 1, . . . , n

In Algorithms 1 and 2 the truncation is written as an explicit addition
of some error matrix Ei in each iteration. In this work, we use truncation
based on the Frob-Inf and Frobenius norms. The SP2 recursive expansion
can be obtained using the algorithm outlined above with the acceleration
parameters αi set to 1 for all i ≥ 1, and nmin = 1.
5. I MPLEMENTATION DETAILS
Chunks and Tasks [20] is a task-based programming model, where the
runtime system is responsible for scheduling tasks and distributing the data
into the physical resources. The idea is that the user splits the work into
smaller tasks and the data into smaller chunks, and registers both to the
library. As soon as chunks are registered to the library, they are read-only.

10

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

Upon registration, chunks and tasks are assigned a unique identifier, which
is chosen by the library. Since each task has input chunks which has to be
registered to the library, it will never happen that some task requests nonexistent chunks. Moreover, information about the location of the chunk can
be stored in the chunk identifier, allowing efficient and easy data fetching.
The CHT-MPI library [18] implements the Chunks and Tasks programming
model. The task scheduler is based on randomized work stealing. As soon
as one process runs out of work, it attempts to steal work from another
process chosen at random. Tasks are scheduled for execution as soon as all
input chunks are available, and each task can register new tasks and chunks.
Chunk objects may store different kinds of data, in particular they can
store chunk identifiers of other chunks, giving the possibility to create hierarchical structures. The Chunks and Tasks Matrix Library (CHTML) is
a hierarchical matrix library written using the Chunks and Tasks programming model and implemented on top of the CHT-MPI library. In each level
of the hierarchy, the matrix is divided into four blocks forming a quad-tree
structure. The tree nodes on the lowest level of the hierarchy are called
leaf nodes. Each non-leaf node stores chunk identifiers of corresponding
non-zero submatrices. If the submatrix is zero, its chunk identifier is set
to CHUNK_ID_NULL. On the leaf level we use the block-sparse matrix
representation where the leaf matrix is divided into small blocks and only
elements of non-zero blocks are stored. Other representations of the leaf
matrix are possible.
We implemented a set of classes, wrapping the CHTML matrix type and
various matrix operations. As mentioned above, when a chunk is registered
to the library, the user in return receives a chunk identifier which can be used
as an input to tasks. Inside the wrapper class we do not store any matrix elements, but only the identifier of a root chunk of a quad-tree representing
the matrix. The actual data may be distributed on different computational
nodes by some previous calculation of the matrix. We provide alternative
implementations of tasks for general and symmetric matrices. The symmetric matrix wrapper implementation utilizes matrix symmetry and assumes
that only the upper triangle of the matrix is stored in memory.
6. N UMERICAL EXPERIMENTS
In this section, we verify the efficiency of the density matrix construction
implemented using CHTML in Ergo [24]. We run our tests on the Rackham
cluster at the UPPMAX computer center at Uppsala university, comprised
of 486 nodes with two 10-core Intel Xeon V4 CPU’s running at 2.2 GHz/core, each with at least 128 GB of RAM memory. We use the Chunks
and Tasks matrix library linked to CHT-MPI 1.2 [18] compiled with GCC

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

11

8.2.0 and Open MPI 3.1.3. The performance of leaf matrix operations is
improved by linking to the optimized BLAS library OpenBlas 0.2.19 (single threaded). We set maximum leaf matrix size to 4096 and small block
size to 32. In the current implementation, the block size in the Frob-Inf
norm is equal to the maximum leaf matrix size, i.e. 4096. All timing results
represent elapsed wall time.
To obtain the homo-lumo eigenvalue estimates we run the recursive expansion in each test twice, and measure time and communication cost for
the second run. In the first run we do not have any assumption about
the eigenvalues. Thus, we use the trace-correcting recursive expansion
scheme [12] with ad hoc truncation tolerances. At the end of the recursive expansion we obtain homo-lumo eigenvalue estimates and use them in
the second run as described in section 4.
6.1. Weak scaling tests on block-diagonal matrices. In a weak scaling
test the amount of work per worker process is kept fixed. In order to achieve
this, the number of non-zero elements per row in all (Fock, intermediate and
final density) matrices should be kept constant with increasing system size.
Moreover, to get the same number of recursive expansion iterations, the
homo-lumo gap should be kept constant too. We construct block-diagonal
matrices of increasing size with the desired properties mentioned above. In
the created matrices we repeat the same test matrix along the diagonal. The
test matrix is a Fock matrix of size 19204 obtained in the last SCF cycle of
Hartree–Fock calculations using the standard Gaussian basis set 3-21G on a
glutamic acid and alanine (Glu-Ala) helix with 3330 atoms. The estimated
number of SP2ACC recursive expansion iterations is 24 for all cases and the
actual number of iterations is 18 for the smallest matrix size and 20 for all
other matrices. The maximum allowed error in the occupied subspace is set
to 0.001. Truncation is based on the Frob-Inf norm. In Figure 2a we show
that the number of non-zero elements per row is constant for large enough
matrices. In our tests we increase the number of blocks K along the diagonal
proportionally to the number of worker processes N p such that N p = 2K.
Since we are interested in the communication cost per worker process and
not in the actual timings, we put one worker process per core and use only
one worker thread per worker. We do not use the chunk cache, i.e. it is set
to 0 GB. In Figure 2b we demonstrate that the amount of data received per
worker process tends to a constant with increasing number of workers. We
note that these results are in agreement with the results obtained in [21],
where only the sparse matrix-matrix multiplication is analyzed.
We note that this is an illustrative example. The ideal distribution of
work and data over processes leads to separate computation of each diagonal block, without any communication of matrix elements between blocks.

12

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON
2500

200

2000

150

1500

100
1000

50

500
0
10 4

10 6

10 8

(a) Number of non-zeros per row

0
10 0

10 2

10 4

(b) Data received by each worker

F IGURE 2. Performance of the SP2ACC recursive expansion for the block-diagonal matrices, see text for construction details. Truncation is based on the Frob-Inf norm. Left
panel: number of non-zero elements per row in the Fock matrix (F), in the obtained density matrix approximations (Xn ),
and the maximum number of non-zeros per row in all intermediate matrices Xi throughout all recursive expansion iterations (max). Right panel: the solid line presents the average
communication cost per worker process over all workers and
all recursive expansion iterations. Maximum and minimum
values over all workers and all iterations are plotted using
dashed lines.
However, if the random permutation is used to achieve load balance, such
trivial non-zero matrix structure cannot be exploited, resulting in unnecessary communication of matrix elements. In our approach, the load balance is achieved dynamically, and we are able to utilize the non-zero matrix
structure reducing the communication cost.
6.2. Calculations on water clusters. In this section we present results of
density matrix calculations for water clusters. Water cluster geometries
are generated from a large molecular dynamics simulation of bulk water at
standard temperature and pressure by including all water molecules within
spheres of varying radii. We perform calculations using our test implementation of the Hartree–Fock method parallelized for distributed-memory. We
use the Gaussian basis set 3-21G. Initial guess density matrices are obtained
from calculations with a smaller basis set STO-2G. We perform 5 SCF cycles and save Fock matrices in the orthogonal basis in the last cycle. The
recursive expansion is applied on the saved Fock matrices. The chunk cache
size is set to 8 GB per worker. Two workers are placed on each node (using

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

13

–bind-to socket -map-by socket Open MPI flags) and each worker
has 9 worker threads. The maximum allowed error in the occupied subspace is set to 0.001. We note that the homo-lumo gap does not change significantly with increasing problem size. The estimated number of iterations
in SP2 and SP2ACC recursive expansions is 35-37 and 22-23, respectively.
The obtained number of recursive expansion iterations in SP2 and SP2ACC
recursive expansions is 29 and 16-17, respectively.
In our tests the number of nodes is increasing proportionally to the matrix
size. Number of non-zeros per row in the Fock matrices, obtained density
matrices and the maximum number of non-zeros per row between all intermediate matrices Xi are presented in Figure 3 for both SP2 and SP2ACC
recursive expansions.
2.5

10 4

2.5

2

2

1.5

1.5

1

1

0.5

0.5

0

10 4

0
2

4

6

8

10

12

2

4

6

8

10

10 5

(a) SP2

12
10 5

(b) SP2ACC

F IGURE 3. Number of non-zero elements per row in Fock
matrices (F), in the obtained density matrix approximations
(Xn ), and the maximum number of non-zeros per row in all
intermediate matrices Xi throughout all recursive expansion
iterations (plotted using dashed lines). Fock matrices are
obtained from HF/3-21G calculations for water clusters of
increasing size. Lines with marker “×” correspond to calculations with truncation based on the Frobenius norm, and
lines with marker “O” correspond to calculations with truncation based on the Frob-Inf norm.
In Figure 4 we compare the execution time and the communication cost
of calculations where truncation is based on the Frobenius and Frob-Inf
norms. We use the wrapper class representing a general matrix. In [21],
it is shown that the execution time of sparse matrix-matrix multiplication
implemented in CHTML scales as O((log (N p ))2 ) where N p is a number of

14

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON
50
40
30
20
10
0
0

100

200

(a) Execution time

(b) Communication cost

F IGURE 4. Performance comparison of the SP2 (dashed
lines) and SP2ACC (“acc”, solid lines) recursive expansions
with truncation based on the Frobenius (“Frob.”, “◦”) and
Frob-Inf (“×”) norms. Fock matrices are obtained from
HF/3-21G calculations for water clusters of increasing size.
In the left panel dotted black lines show the least square fit
of data for the Frob-Inf norm by a function c0 +c1 log (N p )+
c2 (log (N p ))2 . In the right panel we show the average, maximum and minimum communication cost over all workers
and all iterations. Maximum and minimum values are plotted using dotted lines and the area in between is shaded.
worker processes. In Figure 4a, data indicate that the same result is obtained
for the whole recursive expansion.
We perform recursive expansions using the CHTML wrapper for general
matrices where matrix symmetry is ignored, and the wrapper for symmetric
matrices where only the upper triangle of the matrix is stored and manipulated. Truncation based on the Frobenius norm is used in both cases. The
total execution time and the amount of data received per worker process are
given in Figure 5. The figure shows that CHTML with the block-sparse leaf
matrix is able to utilize matrix symmetry, providing a reduction of the total
execution time and communication cost by almost a factor of two.
7. C ONCLUDING REMARKS
In this work, the density matrix is constructed using the SP2ACC recursive polynomial expansion, which scales linearly with system size for sufficiently sparse matrices. The matrix sparsity is enforced by removal of small
matrix elements. The combination of the error control scheme [22] and parameterless stopping criteria [10] enables us to use only one user-defined

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

15

50
40
30
20
10
0
0

100

200

(a) Execution time

(b) Communication cost

F IGURE 5. Performance comparison of the SP2 (dashed
lines) and SP2ACC (“acc”, solid lines) recursive expansions
implemented using the CHTML wrappers for general (“◦”)
and symmetric (“O”) matrices. Truncation is based on the
Frobenius norm. Fock matrices are obtained from HF/3-21G
calculations for water clusters of increasing size. In the right
panel we show the average, maximum and minimum communication cost over all workers and all iterations. Maximum and minimum values are plotted using dotted lines and
the area in between is shaded.

tolerance for the density matrix computation: the maximum allowed error
in the occupied invariant subspace. Truncation tolerances are chosen dynamically at the beginning of the recursive expansion to ensure the desired
accuracy of the density matrix approximation.
We study the execution time and communication cost of the recursive
polynomial expansion implemented using the Chunks and Tasks matrix library (CHTML) [21, 20]. Matrices are expressed as quad-trees of chunk
objects, where the matrix elements are stored on the lowest level using a
block-sparse matrix format. The parallelism is then expressed using tasks
operating on the matrix hierarchies. The sparse matrix-matrix multiplication is an important building block of the recursive expansion. Here we
use the locality-aware sparse matrix-matrix multiplication implemented in
CHTML [21]. We demonstrate that, if the number of recursive expansion
iterations and the number of non-zero elements per row in all matrices is
bounded with increase of the system size, the communication cost is asymptotically constant. Moreover, we show that the quad-tree matrix representation in CHTML allows for efficient symmetry utilization.

16

A. KRUCHININA, E. RUDBERG AND E. H. RUBENSSON

To the best of our knowledge this is the first implementation of the density matrix construction with rigorous error control of the density matrix
approximation and bounded communication cost in a weak scaling limit.
The current study focuses on the computation of the density matrix from a
given Fock/Kohn-Sham matrix. Future work includes parallelization using
Chunks and Tasks of the SCF procedure implemented in the Ergo code [24].
ACKNOWLEDGMENTS
This work was supported by the Swedish strategic research programme
eSSENCE. Computational resources were provided by the Swedish National Infrastructure for Computing (SNIC) through Uppsala Multidisciplinary Center for Advanced Computational Science (UPPMAX) in Uppsala, Sweden.
R EFERENCES
[1] A. A ZAD , G. BALLARD , A. B ULUÇ , J. D EMMEL , L. G RIGORI , O. S CHWARTZ ,
S. T OLEDO , AND S. W ILLIAMS, Exploiting multiple levels of parallelism in sparse
matrix-matrix multiplication, SIAM J. Sci. Comput., 38 (2016), pp. C624–C651.
[2] G. BALLARD , A. B ULUÇ , J. D EMMEL , L. G RIGORI , B. L IPSHITZ , O. S CHWARTZ ,
AND S. T OLEDO , Communication optimal parallel multiplication of sparse random
matrices, in Proceedings of the twenty-fifth annual ACM symposium on Parallelism
in algorithms and architectures, ACM, 2013, pp. 222–231.
[3] M. B ENZI , P. B OITO , AND N. R AZOUK, Decay properties of spectral projectors
with applications to electronic structure, SIAM Rev., 55 (2013), pp. 3–64.
[4] A. B ULUÇ AND J. R. G ILBERT, Parallel sparse matrix-matrix multiplication and
indexing: Implementation and experiments, SIAM J. Sci. Comput., 34 (2012),
pp. C170–C191.
[5] M. J. C AWKWELL AND A. M. N. N IKLASSON, Energy conserving, linear scaling
Born-Oppenheimer molecular dynamics, J. Chem. Phys., 137 (2012), p. 134105.
[6] W. DAWSON AND T. NAKAJIMA, Massively parallel sparse matrix function calculations with NTPoly, Comput. Phys. Commun., 225 (2018), pp. 154–165.
[7] P. H OHENBERG AND W. KOHN, Inhomogeneous electron gas, Phys. Rev., 136
(1964), pp. B864–B871.
[8] R. A. H ORN AND C. R. J OHNSON, Matrix analysis, Cambridge University Press,
New York, USA, 2012.
[9] W. KOHN AND L. J. S HAM, Self-consistent equations including exchange and correlation effects, Phys. Rev., 140 (1965), p. 1133.
[10] A. K RUCHININA , E. RUDBERG , AND E. H. RUBENSSON, Parameterless stopping criteria for recursive density matrix expansions, J. Chem. Theory Comput., 12
(2016), pp. 5788–5802.
[11] A. L AZZARO , J. VANDE VONDELE , J. H UTTER , AND O. S CHÜTT, Increasing the
efficiency of sparse matrix-matrix multiplication with a 2.5 D algorithm and onesided MPI, in Proceedings of the Platform for Advanced Scientific Computing Conference, ACM, 2017, p. 3.
[12] A. M. N. N IKLASSON, Expansion algorithm for the density matrix, Phys. Rev. B, 66
(2002), p. 155115.

DENSITY MATRIX ON DISTRIBUTED SYSTEMS

17

[13] X. Q IN , H. S HANG , H. X IANG , Z. L I , AND J. YANG, HONPAS: A linear scaling open-source solution for large system simulations, Int. J. Quantum Chem., 115
(2015), pp. 647–655.
[14] C. C. J. ROOTHAAN, New developments in molecular orbital theory, Rev. Mod.
Phys., 23 (1951), pp. 69–89.
[15] E. H. RUBENSSON, Nonmonotonic recursive polynomial expansions for linear scaling calculation of the density matrix, J. Chem. Theory Comput., 7 (2011), pp. 1233–
1236.
[16] E. H. RUBENSSON , A. G. A RTEMOV, A. K RUCHININA , AND E. RUDBERG, Localized inverse factorization, arXiv:1812.04919, (2019).
[17] E. H. RUBENSSON AND A. M. N. N IKLASSON, Interior eigenvalues from density
matrix expansions in quantum mechanical molecular dynamics, SIAM J. Sci. Comput., 36 (2014), pp. B147–B170.
[18] E. H. RUBENSSON AND E. RUDBERG, CHT-MPI, Available at http://chunks-andtasks.org (Accessed September 2019).
, Bringing about matrix sparsity in linear scaling electronic structure calcula[19]
tions, J. Comput. Chem., 32 (2011), pp. 1411–1423.
[20]
, Chunks and Tasks: A programming model for parallelization of dynamic algorithms, Parallel Comput., 40 (2014), pp. 328–343.
[21]
, Locality-aware parallel block-sparse matrix-matrix multiplication using the
Chunks and Tasks programming model, Parallel Comput., 57 (2016), pp. 87–106.
[22] E. H. RUBENSSON , E. RUDBERG , AND P. S AŁEK, Density matrix purification with
rigorous error control, J. Chem. Phys., 128 (2008), p. 074106.
[23] E. RUDBERG , E. H. RUBENSSON , P. S AŁEK , AND A. K RUCHININA, Ergo (Version 3.8). Available at http: // www. ergoscf. org (Accessed September 2019).
[24]
, Ergo: An open-source program for linear-scaling electronic structure calculations, SoftwareX, 7 (2018), pp. 107–111.
[25] J. VANDE VONDELE , U. B ORŠTNIK , AND J. H UTTER, Linear scaling self-consistent
field calculations with millions of atoms in the condensed phase, J. Chem. Theory
Comput., 8 (2012), pp. 3565–3573.

