Boundary Defense against Cyber Threat for Power System
Operation

arXiv:1908.10315v1 [eess.SP] 4 Aug 2019

Ming Jin∗

Javad Lavaei†

Somayeh Sojoudi‡

Ross Baldick §

Abstract
The operation of power grids is becoming increasingly data-centric. While the abundance of data
could improve the efficiency of the system, it poses major reliability challenges. In particular, state estimation aims to learn the behavior of the network from data but an undetected attack on this problem
could lead to a large-scale blackout. Nevertheless, understanding vulnerability of state estimation against
cyber attacks has been hindered by the lack of tools studying the topological and data-analytic aspects
of the network. Algorithmic robustness is of critical need to extract reliable information from abundant
but untrusted grid data. We propose a robust state estimation framework that leverages network sparsity and data abundance. For a large-scale power grid, we quantify, analyze, and visualize the regions
of the network prone to cyber attacks. We also propose an optimization-based graphical boundary defense mechanism to identify the border of the geographical area whose data has been manipulated. The
proposed method does not allow a local attack to have a global effect on the data analysis of the entire
network, which enhances the situational awareness of the grid especially in the face of adversity. The developed mathematical framework reveals key geometric and algebraic factors that can affect algorithmic
robustness and is used to study the vulnerability of the U.S. power grid in this paper.

∗

Department of Industrial Engineering and Operation Research, University of California Berkeley, CA 94720, USA
Department of Industrial Engineering and Operation Research, University of California Berkeley, CA 94720, USA
‡
Department of Electrical Engineering and Computer Sciences, University of California Berkeley, CA 94720, USA
§
Department of Electrical and Computer Engineering, University of Texas at Austin, TX 78712, USA
†

0

While real-world data abound for many complex systems, they are often noisy and corrupted. Acquiring reliable information from abundant but untrusted data is key to enhancing cybersecurity for missioncritical systems, such as transportation and power grid. Since many of these systems are inherently network
structured, data analytics cannot be satisfactorily understood without incorporating their underlying graph
topologies. Consider the power system state estimation (SE) as an example, which constantly monitors the
status of the grid by filtering and fusing a large volume of data every few minutes. It plays a critical role
in the economic and reliable operation of the grid because major operational problems such as securityconstrained optimal power flow, contingency analysis, and transient stability analysis rely on its output. The
current industry practice is based on a set of heuristic iterative algorithms proposed in the 70s, which are
known empirically to work properly under normal situations. However, those algorithms become brittle
under adverse conditions, such as natural hazards, equipment faults, and even cyber attacks. The significance of functioning SE to operators was illustrated by the 2003 large-scale blackout, in which the failure of
SE contributed to the inability of providing real-time diagnostic support.[22] Despite substantial advances
in algorithm design, namely using semidefinite programming, holomorphic embedding load flow methods,
and homotopy continuation methods, a major obstacle still remains: the lack of a framework for the design of a robust and scalable algorithm together with a realistic evaluation of its vulnerability.[1, 11, 18]
Developing such a framework is challenging for three reasons: (a) the model of a power system is highly
nonlinear and nonconvex due to physical laws, (b) computational resources required by the existing algorithms grow rapidly in the size of the system, and (c) the number of scenarios for adverse conditions is
too large to be enumerated (it is higher than the number of atoms in the observable universe for systems
with as low as 500 possible attack points). These challenges have limited the scope of previous studies to
simple approximate models or conservative methods that ignore the topology-dependent characterization
of vulnerabilities.[11, 18] Similar hurdles exist in studying vulnerability of data analytics for other largescale complex graphs, including ecological and social systems,[24, 10] due to the lack of statistical tools for
untrusted data with underlying nonlinear and structured (rather than random) graphical models.
Here we focus on the U.S. grid, which is the largest machine on earth with more than 200,000 miles
of transmission lines (Figure 1). It consists of three large and nearly independent synchronous systems
(Eastern, Western, and Texas) that together span the lower 48 United States, most of Canada, and some parts
of Mexico. Due to confidentiality requirements on critical infrastructure information, we report our findings

Figure 1: The U.S. power transmission network. (A) Map of the Eastern, Western and Texas interconnections. (B) Schematic diagram of a portion of the network. Each blue circle indicates a node (e.g., generator
bus or load bus). Nodes are connected by transmission lines. Power is generated, transported and consumed
in different locations (the amount of power is shown as the width of the orange arrow).

1

on modified grids, which match the size, complexity, and characteristics of actual grids.[6] Basic properties
of the data are listed in Table 1. Central to the vulnerability analysis is that we provide formal statistical
guarantees that rely on the physical and cyber infrastructure, which can be realistically evaluated on any
large-scale system to depict high-granularity characteristics through graph topology, as shown in Figure 2.

Figure 2: Vulnerability map of the modified U.S. power grid. A line is robust (shown in green) if it stops
error propagation from one end to the other during state estimation; otherwise, it is vulnerable (shown in
red). Because the vulnerability map varies according to the set of available measurements, we demonstrate
the map for a single profile with abundant data, which includes voltage magnitude as well as real and reactive
power injections per bus and real in addition to reactive power flows per branch.

Data abundance meets algorithmic robustness
Existing SE software solves nonlinear least squares (NLS) for the set of complex voltage phasors based on
power flow measurements. NLS is a nonconvex problem, so even in the absence of measurement errors,
local search algorithms such as Newton’s method can become “stuck” at local minima, which are spurious
and do not correspond to a useful estimate of the state. When this occurs, the conventional wisdom is to
conclude that the estimations are unduly influenced by bad data, which are subsequently identified, downweighted and even discarded to rectify the outputs.[16, 14, 19, 11] Nevertheless, this is misleading and even
harmful, especially during unusual or emergency situations when accurate estimates are needed, because
erroneously rejecting useful information can further reduce the reliability. Even though advanced convex
relaxation techniques, such as semidefinite programming, can partially address this issue,[18] the primary
disadvantage is their heavy computational and memory requirements.

2

Compared to the classic state estimation where one needs to obtain useful information from limited
data, there is a paradigm shift from a limited-but-trustworthy data regime to an abundant-but-untrusted data
regime due to the significant growth in instrumentation and communication in the electric grid,. Hence, a
natural question arises: Can the additional information from abundant data sources be leveraged to enhance
the robustness of the algorithm?
In this section, we provide a strong positive answer to this challenging question. We propose a new
representation for the common types of measurements, such as the real and reactive power flows and voltage
magnitudes, by fully exploiting the sparsity structure of power networks. This representation framework
comprises physical quantities such as voltage magnitudes squared and phasor products over the lines. A
key advantage is that one can express all power flow measurements as a linear combination of these basic
parameters. From a computational complexity perspective, this enables depicting the boundary between easy
and difficult instances of SE with respect to the number and locations of sensor measurements. Particularly,
it is well-known that the SE problem is usually unidentifiable (i.e., there are multiple solutions that are
consistent with the measurements) in the traditional power flow setting, where each bus has only 2 sensor
measurements. Yet, our analysis shows that the problem becomes solvable as soon as the SE problem is
modestly over-determined (i.e., there exists a method to uniquely recover the true state of the system). In
contrast, this guarantee is almost vacuous using existing theoretical tools.[7]
While the new parameter representation is effective under clean data, it turns out that it can be used
to deal with corrupted and untrusted data as well. To this end, we propose a two-step pipeline. The first
step is to solve a convex optimization, where the objective deals with both dense noise due to measurement
error and sparse noise due to bad data. Because the variables correspond to physical quantities, they can be
mathematically constrained within a set of second-order cones (SOCs) to improve robustness, though the
unconstrained versions based on linear programming (LP) or quadratic programming (QP) are also viable
options. Based on the estimations from Step 1, the next step directly reconstructs the voltage phasors from
the set of linear bases using elementary algebra. As a general remark, the rationale of the design of the
optimization algorithm in Step 1 can be also explained by an interesting connection to the robust statistics
literature. It can be shown that the optimization is equivalent to minimizing the Huber loss, which is wellknown to be robust to outliers (supplementary material). Previous methods have incorporated Huber loss,
but they are either in the setting of the DC approximation or a nonconvex formulation.[17, 4] There is also
a lack of theoretical understanding of the performance in the literature. Furthermore, the incorporation of
conic constraints tightens the relaxation, but the analysis becomes more involved.
Next, we provide a theoretical guarantee for global recovery in the case of sparse bad data. Consider
the following “corrupted sensing model” where the nonlinearity is hidden within a linear model using our
method to be explained later:
y = Ax + w + b.
(1)
Here, y is the set of m sensor measurements for the vector x consisting of latent variables, A is the sensing
matrix, w is the dense random noise due to measurement error, and b is sparse bad data. Let J ⊂ {1, ..., m}
denote a set of measurements that are biased by sparse dense noise b (i.e., bk 6= 0 if and only if k ∈ J ) and
J c be its complement set; let AJ be the submatrix with rows indexed by J in A. Denote the pseudoinverse
>
−1 >
c
of AJ c as A+
J c = (AJ c AJ ) AJ c . Then, under some mild “observability condition,” the proposed twostep pipeline (the unconstrained version) can simultaneously recover the true state and detect the bad data if
the following condition is satisfied:
>
ρGRC (J ) = kA+>
J c AJ k∞ < 1,

3

(GRC)

1E+0

1.0

1E-1

0.8

1E-2
1E-3
0

2

4

6

8

F1 score

B
F1 score

RMSE

A

0.5

1.0
0.8
0.5
0.3
0.0

NLS

0 2 4 6 8 10

QP
SOCP

Bad data (%)

0.3
0.0

10

0

Bad data (%)

2

4

6

8

10

Bad data (%)

Figure 3: Evaluation of algorithmic robustness for different levels of bad data. The bad data are generated by the “scattered attack” strategy, where a subset of lines are chosen whose branch measurements are
all corrupted. For state estimation, we consider Newton’s method to solve nonlinear least squares (NLS) as
the baseline, and compare it with the proposed methods based on quadratic programming (QP) and secondorder cone programming (SOCP). For each percentage of bad points within dataset, we show (A) the root
mean squared error (RMSE) and (B) the F1 score of bad data detection, averaged over 20 independent simulations. For RMSE, a desirable value is any number less than 0.01. The F1 score is the harmonic average
of precision and recall. Because NLS deteriorates significantly with the addition of bad data, we only show
the simulation results up to 2% of bad data, which corresponds to about 380 number of bad data. We tested
on the synthetic Texas Interconnection with full sensor measurement set.
where k · k∞ denotes the matrix infinity norm (i.e., the maximum absolute column sum of the matrix).
Intuitively, ρGRC (J ) measures the alignment of the corrupted data and the clean data. The condition states
that if the bad data are not aligned with the benign data, then it is possible to detect them.
We compare the proposed technique to the conventional approach based on Newton’s method with bad
data detection (BDD) in some empirical evaluations. For Newton’s method, measurements with residual
larger than a threshold are removed and SE is re-solved. As shown in Figure 3, our method significantly
improves on Newton’s method in terms of estimation accuracy and bad data detection rates. Contrary to
the prevailing wisdom, BDD is not effective because it depends on the quality of the initial estimation
from Newton’s method, which can be badly influenced by the bad data. In contrast, the key idea of the
proposed method is to incorporate a BDD term in the optimization so that the best configuration of the state
estimation and bad data vector be detected simultaneously. Since we solve either LP/QP or second-order
cone programming (SOCP), the runtime is manageable for real-time applications. We also see that the SOCP
version is more robust than the unconstrained LP/QP version (see Figure 3S in the supplementary material
for close comparison) .

From global recovery to boundary defense
The above results demonstrate that the proposed two-step pipeline can deal with random sparse bad data.
More importantly, we are concerned about the scenario where the bad data are engineered, or a whole
subregion’s data are compromised. This corresponds to adverse conditions such as cyberattacks or natural
disasters. In this situation, Newton’s method is particularly vulnerable, because by simply solving the

4

nonlinear least squares, the influence of bad data will propagate throughout the system, as shown in Figure
4. What can we say about the robustness in this case?
It turns out that to defend against cyberattacks where the data for a geographical area are attacked, we
need to devise a new defense mechanism. Because the basic “observability” condition is not satisfied, it is
unrealistic to recover the state within the region. A well-defined problem is how to identify the boundary of
the attacked region to be able to limit the spread from and impact of small disruptions to local regions.
To this end, we propose a new notion of defense on networks, called “boundary defense mechanism.”
For a given attack scenario, there is a natural partition of the network into the attacked, inner and outer
boundaries, and safe regions (Figure 5(A)). If boundary defense is successful, then no matter how erroneous
the state estimation is within the attacked region, the estimates at the boundary and in the safe region are
unaffected. This is a fairly general framework, because it incorporates a wide range of adversarial scenarios
that are localized, including line outage, substation down, natural disasters, and cyberattacks. However, a
key challenge arises: due to the large number of possible scenarios, it is clearly unrealistic to evaluate the
efficacy of boundary defense separately for each case. How can one provide a systematic assessment of the
robustness that can be applied to a variety of scenarios?
Our key idea is that instead of treating the power grid as a collection of buses and lines, we analyze
each line individually. Specifically, we associate a “vulnerability index” (VI) to each line in one of the 2
directions. Note that VI is algorithmically dependent. In the case of unconstrained LP or QP, this metric for
line i → j is given by the following minimax optimization:
LP
αi→j
= max

kξk∞ ≤1

min

h∈HLP (ξ)

khk∞

(VI)

n
o
>
where HLP (ξ) = h | A>
h
+
A
ξ
=
0
is the set of admissible h for a given vector ξ
Mi→j ,X i→j
Mi→j ,X i→j
bdX

bd

bd×

bd

i→j
in the unit hypercube, the index sets Mi→j
bdX and Mbd× correspond to the defending and defective measurei→j
ments on the boundary, and Xbd
denotes the set of variables associated with the boundary (supplementary

Figure 4: Evaluation of the boundary defense mechanism. (A) The grid is under “zonal attack,” where the
measurements within a zone are corrupted (shown in red). State estimation based on (B) Newton’s method
for nonlinear least squares, and (C) the proposed method with SOC constraints, where in both cases, buses
with an estimation error greater than 0.002 are marked red. The errors propagate throughout the grid in (B),
but are contained within the zonal boundary in (C).

5

Node definitions
Attacked node

B

Inner boundary
Outer boundary

Vulnerability index evaluation
line (a1àb1)
b1

a1

a1

a2

b2

b2

a2

…

b1

line (a2àb2)

line (a3àb3)

…

A

line (a3àb4)

a3
b3
a3

a3

…

b3

b4
…

b4

…

Figure 5: Illustration of the boundary defense mechanism. (A) Schematic diagram showing the attacked
nodes as well as inner and outer boundary nodes. (B) Vulnerability index evaluation. Only nodes and lines
considered in the evaluation are highlighted for each line evaluation, with each line direction considered
from the attacked node to the inner boundary node.
material). We use the subscript notation AMi→j ,X i→j to indicate the submatrix of A whose rows are inbdX

bd

i→j
dexed by Mi→j
bdX and columns are indexed by Xbd . Figure 5(B) illustrates the nodes and lines relevant to
the evaluation of four lines for a given attack scenario. The case of SOCP is defined similarly:
SOCP
αi→j
(x) = max

min

h∈HSOCP (ξ,x)

kξk∞ ≤1

khk∞

(VI-SOC)

where HSOCP (ξ, x) is the set of admissible h defined in the supplementary material. Firstly, it can be seen
that (VI-SOC) depends on the true state x. However, this is not an issue because it can be shown that for
every x that corresponds to a complex voltage state of the system, we have
SOCP
LP
αi→j
(x) ≤ αi→j

In other words, the incorporation of second-order cone constraints always improves robustness.
Our main result is stated in the following theorem (formal statement can be found in the supplementary):
Theorem 1 (Boundary defense mechanism). Consider a partition of the network into the attacked, boundary, and safe regions, where the bad data are contained within the attacked region. If the vulnerability index
(LP/QP or SOCP) in the direction that points outwards from the attacked region is less than 1 for all lines
on the boundary, then the solution obtained from the two-step pipeline has the following properties: (i) all
the detected data are bad data, so there are no false positives in Step 1; and (ii) after removing the subgraph
of the attacked region from the main graph, direct recovery in Step 2 recovers the underlying state of the
system for the un-attacked region.
6

From an attacker’s point of view, by attacking data in a local region, the adversary hopes that error
would propagate throughout the system due to miscalculation. Indeed, this normally occurs for Newton’s
method. In contrast, the above theorem guarantees that it will never happen using the proposed algorithm
as long as the boundary defense condition is satisfied. This explains the intriguing phenomenon observed in
the beginning—for the case of topological errors (line or substation outage) or cyberattacks, the boundary
defense mechanism is “triggered” to contain the error within the local neighborhood.

Geographic mapping of vulnerabilities
Based on the mathematical tools developed in the previous section, we assess the robustness of the synthetic
U.S. grid. First, we visualize the vulnerability index on the map for both (VI) and (VI-SOC) in Figure 6.
Due to its dependence on the underlying state, (VI-SOC) is shown for a profile described by the dataset,
which represents a snapshot of the operating status. A line is considered “robust” if the VIs in both directions are less than 1; otherwise, it is “vulnerable (V-line).” The plot shows a geographic distribution of
robust/vulnerable lines for the east coast of the U.S. grid. It can be seen that the density of vulnerable lines is
relatively high for populated areas like Boston and New York, where we also observe a high density of robust
lines. On average, 59% lines are robust across the states, which is further split into each of the independent
synchronous regions, as shown in Table 1. In addition, it can be validated in the map that (VI-SOC) always
improves (VI), which implies that the incorporation of SOCP constraints can help rectify state estimation
and BDD.
The vulnerability map can be used in various ways. For instance, it can be used to investigate whether
topological errors for a line or a substation can be contained locally. This corresponds to the case when there

Figure 6: Comparison of vulnerability maps under different optimization strategies. Vulnerability
maps when using the proposed (A) LP/QP and (B) SOCP are shown, where a robust line is marked green
and a vulnerable line is colored red.

7

Figure 7: Comparison of bus critical index maps under different optimization strategies. Since the bus
critical indices are no larger than 3 within the map, we only show the locations with values 2 (yellow) and 3
(red) for the proposed (A) LP/QP and (B) SOCP state estimation strategies.
is a model mismatch for a transmission line or substation, such that the associated measurements are largely
biased. While this is a challenging problem, it could be addressed using the vulnerability map systematically.
Specifically, if the erroneous line/substation is surrounded by robust lines, then it is guaranteed that the error
will be contained locally via the boundary defense mechanism. Otherwise, there is a possibility that error
will “escape” through a vulnerable line to affect the outside region, which is referred to as a “critical line
(C-line)” or a “critical bus (C-bus).” In particular, for topological errors such as line mis-specification, it can
be regarded as a pair of gross injection errors at the two ends of the line; hence, we can identify it as long as
the line is not a C-line. A summary of statistics is shown in Table 1.
Furthermore, we can extend the case study by defining a criticality index (CI) for each substation. CI
gauges how many nodes in its neighborhoods will be affected if this substation is down. The higher the
value, the more crucial the situation if the substation is compromised. This is analogous to the cascading
failures for generators, but the difference is clear—our focus is on the robustness of data analytics rather
than physical dynamics. For each substation, CI can be calculated as the size of the connected component
rooted at the node, where an edge between two nodes is present if and only if the physical line that connects
them is vulnerable. We visualize the distribution of CI on the map as shown in Figure 7. It can be seen that
they are concentrated in populated areas.

Relating vulnerability to network and optimization properties
To investigate factors that affect line vulnerability, we shift our focus to the underlying network and optimization properties. So far, our study has been conducted with respect to a specific measurement profile,
which corresponds to the set of full nodal and branch measurements. An important question is: How do the

8

Basic properties

Properties of LP/QP

Properties of SOCP

Buses

Lines

V-lines

C-lines

C-bus

Bus CI

V-lines

C-lines

C-bus

Bus CI

Texas

2,000

3,206

.3762

.4251

.4775

.20

.2979

.3674

.4225

.06

Western

10,000

12,706

.4715

.5231

.5313

.15

.3979

.4636

.4860

.06

Eastern

70,000

88,207

.4932

.5415

.5327

.14

.4104

.4780

.4810

.05

Table 1: Summary statistics of network properties and vulnerability characteristics. We show the
percentage of V-lines and C-lines among all network lines, and the percentage of C-bus among all network
buses for LP/QP and SOCP. We also show the average bus critical index, which measures the influence of a
single-bus attack on the rest of the network.

B

1E-1
1E-1

1.0

1E-3
1E-3
1E-4
1E-4 2
2

Method 1
Method 2
Method 3

0.6

0.2

3
4
3
4
Redundancy

2

5
5

3

4

Redundancy

Redundancy

5

RMSE

1E-2
1E-2

F1 score

RMSE
RMSE

A

1E-2
1E-4
2

7

Redundancy

Figure 8: Comparison of different measurement profiles and redundancy. We consider three different
methods for sensor augmentation, as detailed in the main text. The redundancy value is calculated as the
number of sensors divided by 2 × nb (number of buses) − 1, which is the degree of freedom in the traditional power flow problem. Each point for (A) RMSE and (B) F1 score is obtained by averaging over 20
independent simulations.
number and locations of measurement sensors affect line vulnerability? In particular, does decreasing the
number of sensors make the network significantly more vulnerable, and what type of sensor measurements
can bolster boundary defense?
For this purpose, we examine three methods for “measurement augmentation.” The first method (Method
1) starts from a spanning tree of the network and incrementally adds a set of lines to the tree to obtain a
subgraph that will be used for taking measurements. In this method, each bus is equipped with only voltage
magnitude measurements, and each line has 3 out of 4 branch flow measurements. The second method
(Method 2) starts with the full network, where each node has voltage magnitude measurements and each
line has one real and one reactive power measurements, and it grows the set of sensors by randomly adding
branch measurements. The third method (Method 3) differs from Method 2 only in that it grows the set
of sensors by randomly adding branch measurements as well as nodal power injections. To evaluate these
three methods, we devise a “scattered attack” strategy, where we randomly select 25 lines of the 2000-bus
Texas Interconnection and corrupt all of its branch measurements, which amounts to 100 bad data. We then
employ our proposed method to first detect bad data, and then rerun SE on the sanitized measurement set.
The observation is that, in general, both the root mean squared error (RMSE) and the F1 score for bad data
detection are enhanced as more sensors are added to the network, as shown in Figure 8. Specifically, an F1
9

III
II
I
0

0.5

V-lines

1

IV
III
II
I
0

0.5

1

C-lines

V
IV
III
II
I
0

LP
1
0.5
0

Rate of V-lines

IV

V

Measurement profiles

V

C

Rate of V-lines

B
Measurement profiles

Measurement profiles

A

0.5

C-buses

SOCP
LP SOCP

1
0.5
I
0

II

III

IV

Measurement
profiles
1
I
II
III

IV

Measurement profiles

Figure 9: Characterization of vulnerability based on measurement profiles. The five measurement
profiles are full nodal measurements and 2/3/4 branch flows per line (I/III/IV); real and reactive power
injections per bus and 3 branch flows per line (II); and voltage magnitude per bus and 3 branch flows per
line (V). For each state estimation method (LP/QP or SOCP), we show the percentage of (A) V-lines, (B)
C-lines and (C) C-buses within the Texas Interconnection.
score close to 1 indicates that the algorithm detects all bad data (high recall rate) and does not falsely blame
the good data (high precision rate).
There is also a major discrepancy among different methods for the same level of measurement redundancy. For instance, Method 1 significantly outperforms the other two methods at a low redundancy rate,
whereas Method 2 steadily outmatches Method 3 with more sensors. To explain this phenomenon, we need
to examine the types of available measurements. Thus, we select five typical measurement profiles as snapshots of Figure 8 and calculate the percentage of V-lines, C-lines, and the average CI in each case (Figure
9). It turns out that the inclusion of voltage magnitude or branch flow measurements can enhance the robustness, whereas the addition of nodal power injections is a major factor that weakens the defense. For
example, with only voltage magnitude and branch flow measurements, the network is almost “everywhere
defendable,” namely the locations of scattered attack can be accurately detected with high probability. On
the contrary, with the inclusion of nodal injections, even with a high rate of branch flow measurements, the
network is still vulnerable. Intuitively, this is because nodal power injections are highly coupled measurements, which depend on state variables at all lines connected to the node. When one or few of the branches
are under attack, this can lead to miscalculations at all incident lines. In contrast, voltage magnitude and
branch flows are more localized measurements, whose corruptions have less effects on adjacent buses/lines.
In addition to the measurement set, network vulnerability also depends on topological properties. In
particular, our findings show that the connectivity degree for each node is positively correlated with line
vulnerability (Figure 10(A)). For a boundary defense node, it is increasingly likely to defend against attacks
as the degree grows. However, this trend is less obvious when the node is under attack. The reason is that
high-degree nodes have more unattacked measurements to leverage in order to rectify the corrupted lines.
On the other hand, it is more likely for a line to be critical if it is connected to a high-degree bus, as is
shown in Figure 10(B). This is because by the definition of critical line, as long as one of the remaining lines
incident to that bus is vulnerable, then the error will propagate out through the vulnerable line. Similarly, a
high-degree node is more likely to be a critical bus. In addition to the degree of connections, which is a local
10

V
V

B
Boundary

Attacked

C-lines

V-lines

0.6
0.4
0.2
0

C
1
0.8
0.6
0.4
0.2
0

C-buses

A

1 2 3 4 5 6 7 8

1 2 3 4 5 6 7 8

Degree nodes

Degree nodes

1
0.8
0.6
0.4
0.2
0
1 2 3 4 5 6 7 8

Degree nodes

Figure 10: Characterization of vulnerability through nodal degrees. (A) Percentage of V-lines when the
nodes are at the boundary or in the attacked region. In this case, we distinguish the two directions of a line.
Percentage of (B) C-lines and (C) C-buses averaged over nodes with the same degree. Since the distribution
of nodal degrees is light tailed, we group nodes with degree 8 or higher to the same bin.
property, we have observed an interesting relation to the tree decomposition of the network, which provides
a generalization of the discussed method. However, due to the technicality, we leave it to the supplementary
materials.
As for the optimization property, our theoretical analysis indicates that the incorporation of SOCs always
improves line robustness (Proposition 2S). This can be visually verified in Figure 6. This can be also
observed in Figure 9 for different measurement profiles.

Conclusion
Our vulnerability analysis of power system state estimation is distinguished from previous works by its
scalability but also by (i) robust two-step convex formulation of the nonconvex nonlinear problem; (ii) strong
formal guarantees of boundary defense against cyber attacks; and (iii) localized vulnerability assessment
that accounts for network and optimization properties. This study provides a set of notions and tools—
the definition of vulnerability index, the boundary defense mechanism, and the analysis of topological and
optimization relations to vulnerability—that are applicable to graph-structured data.
Our analysis is based on the assumption that the amount of data is not too low—an assumption far from
being restrictive, as we show that with the right set of measurements, one can identify the true state of the
system with only one more sensor per bus on average compared to the classical setting of power flow that
is known to have multiple spurious local minima. More importantly, the emerging scenario of “abundant
but untrusted data” considered in this study is more practically realistic and algorithmically challenging
than the traditional scenario of “redundant and reliable data.” We proposed a robust two-step algorithm to
simultaneously perform bad data detection and state estimation. We showed how the number and locations
of sensors affect the robustness of state estimation to bad data. A well-chosen set of measurements is able
to significantly improve bad data robustness and estimation accuracy without increasing the sensing budget.
We also proposed a boundary defense mechanism to defend against cyber attacks. When a subregion
of the network is under attack, it becomes unrealistic to reliably recover the state within the region. By
attacking locally, the adversary hopes that due to miscalculation, the error will propagate throughout the
grid. However, under some mild conditions, our result shows that this will never occur using the proposed
mathematical technique—we can detect the boundary of the attack region and remove the compromised data.
11

Furthermore, this formal condition can be quantified and visualized on the map, leading to a system-wide
vulnerability map to facilitate security assessment.
Based on the proposed mathematical framework, our analysis revealed several key factors that can affect
the robustness of the network. A highly connected node is able to defend against attacks if it happens to lie
on the boundary, but it is also more prone to attacks with higher collateral damage. For a given topological
structure, the inclusion of nodal power injection data can weaken the defense; by contrast, the inclusion of
voltage magnitude or branch power flow measurements can enhance the robustness against bad data, which
gives rise to a higher bad data detection accuracy. From an algorithmic perspective, the incorporation of
second-order cone constraints is theoretically shown to be beneficial for network robustness, which is also
validated through extensive experiments. Our analysis offers a scientific foundation for vulnerability-based
resource allocation, which in the case of a power grid would be based on prioritizing upgrades of sensing
infrastructure for critical locations.

Method summary
The power grid is modeled as a network of buses connected by transmission lines, where each bus is associated with a complex voltage phasor as the state. Given the topology and measurement profile, some
linear basis variables can be constructed for each bus and branch adaptively—if there are no branch measurements and nodal power injections on the connected buses, then the corresponding branch variables can
be ignored. This ensures sparsity of the basis. From the measurements, we first estimate the linear basis
using a quadratic programming or second-order cone programming. Bad data detection is performed by
thresholding the estimated bad data vector. Then, we rerun the estimation on the sanitized dataset, whose
results are fed into the second step in the pipeline to produce a state estimation.
We considered two types of attacks. The first attack is “scattered attack” (Figures 3 and 8), where a
random subset of lines are chosen whose measurements are all corrupted. In this case, the bad data are
scattered throughout the network, and the goal is to correctly recover the overall system state. The second
attack is “zonal attack” (Figure 4), where all measurements within a zone—usually governed by a single
utility—are corrupted. In this case, the goal is to identify the boundary of the attack and correctly recover
the state outside the attacked zone. For stealthy attack, there is a problem of symmetry, namely, without
additional information, it is impossible to decide which zone is under attack, since the only inconsistency is
observed at the boundary. To avoid this case, we arbitrarily break the symmetry by introducing some sensors
within the attacked zone that are more secure than others, such that their values cannot be modified. We can
also perform posterior inference based on our prior knowledge of which zones are more likely to be secured
than others.
The vulnerability analysis is based on the partition of measurements and variables into attacked and
boundary categories (Figure 5). The vulnerability index is defined by a min-max problem, which is NP-hard
in general. For small-scale problems, we developed an efficient enumeration strategy that scales exponentially by the number of bad measurements. For large-scale instance, we proposed two reformulations of the
problem, namely linear complimentarity problem and mixed-integer programming, which can be employed
to solve the problem efficiently. The critical index for buses (Figure 7) is obtained by counting the size of
the subgraph rooted at the substation and linked by a directional edge that is vulnerable. A critical line is
identified when any one of the adjacent lines pointing outwards is vulnerable.
The formal result of boundary defense mechanism is established through a series of propositions and
lemmas. The key steps include (1) a “glueable property,” which shows that local property of vulnerability
implies global property (Lemma 2S and 5S), (2) a result that establishes that boundary defense can stop
12

error from propagation (Lemma 1S and 3S), and (3) a statistical analysis of the first step algorithm based
on concentration bounds and a primal-dual witness argument. Further details on the linear representation,
two-step pipeline algorithm, theoretical analysis, and experimental setup are given in the supplementary
materials.

Author contributions statement
M.J. and J.L. developed the idea. M.J. developed the theoretical formalism. M.J., J.L., R.B. and S.S.
designed the experiments and interpreted the results. M.J. performed the experiments, analyzed the data and
prepared the manuscript. S.S., J.L. and R.B. revised the manuscript.

References
[1] A. Abur and A. G. Exposito. Power system state estimation: theory and implementation. CRC press,
2004.
[2] F. Alizadeh and D. Goldfarb. Second-order cone programming. Mathematical Programming, 95(1):3–
51, 2003.
[3] A. Bagchi, K. Clements, P. Davis, and F. Maurais. A comparison of algorithms for least absolute value
state estimation electric power networks. In Proceedings of IEEE International Symposium on Circuits
and Systems, volume 6, pages 53–56. IEEE, 1994.
[4] R. Baldick, K. Clements, Z. Pinjo-Dzigal, and P. Davis. Implementing nonquadratic objective functions
for state estimation and bad data rejection. IEEE Transactions on Power Systems, 12(1):376–382, 1997.
[5] D. Bienstock. Electrical transmission system cascades and vulnerability: an operations research
viewpoint, volume 22. SIAM, 2015.
[6] A. Birchfield, T. Xu, K. Gegner, K. Shetye, and T. Overbye. Grid structural characteristics as validation
criteria for synthetic networks. IEEE Transactions on Power Systems, 32(4):3258–3265, 2017.
[7] Y. Chi, Y. M. Lu, and Y. Chen. Nonconvex optimization meets low-rank matrix factorization: An
overview. arXiv preprint arXiv:1809.09573, 2018.
[8] M. C. Ferris and T. S. Munson. Complementarity problems in GAMS and the PATH solver. Journal
of Economic Dynamics and Control, 24(2):165–188, 2000.
[9] J.-J. Fuchs. Recovery of exact sparse representations in the presence of bounded noise. IEEE Transactions on Information Theory, 51(10):3601–3608, 2005.
[10] A. A. Ganin, E. Massaro, A. Gutfraind, N. Steen, J. M. Keisler, A. Kott, R. Mangoubi, and I. Linkov.
Operational resilience: concepts, design and analysis. Scientific reports, 6:19540, 2016.
[11] Y.-F. Huang, S. Werner, J. Huang, N. Kashyap, and V. Gupta. State estimation in electric power grids:
Meeting new challenges presented by the requirements of the future grid. IEEE Signal Processing
Magazine, 29(5):33–43, 2012.
[12] P. J. Huber. Robust statistics. Springer, 2011.
13

[13] M. Jin, J. Lavaei, and K. H. Johansson. Power grid AC-based state estimation: Vulnerability analysis
against cyber attacks. IEEE Transactions on Automatic Control, 64(5):1784–1799, 2019.
[14] W. W. Kotiuga and M. Vidyasagar. Bad data rejection properties of weighted least absolute value
techniques applied to static state estimation. IEEE Power Engineering Review, PER-2(4):32–32, 1982.
[15] J. Lofberg. YALMIP: a toolbox for modeling and optimization in MATLAB. In IEEE International
Conference on Robotics and Automation, pages 284–289, 2004.
[16] H. M. Merrill and F. C. Schweppe. Bad data suppression in power system static state estimation. IEEE
Transactions on Power Apparatus and Systems, PAS-90(6):2718–2725, 1971.
[17] L. Mili, M. Cheniae, N. Vichare, and P. J. Rousseeuw. Robust state estimation based on projection
statistics [of power systems]. IEEE Transactions on Power Systems, 11(2):1118–1127, 1996.
[18] D. K. Molzahn, I. A. Hiskens, et al. A survey of relaxations and approximations of the power flow
equations. Foundations and Trends R in Electric Energy Systems, 4(1-2):1–221, 2019.
[19] A. Monticelli. Electric power system state estimation. Proceedings of the IEEE, 88(2):262–282, 2000.
[20] J. F. Sturm. Using sedumi 1.02, a matlab toolbox for optimization over symmetric cones. Optimization
methods and software, 11(1-4):625–653, 1999.
[21] J. A. Tropp. Just relax: Convex programming methods for identifying sparse signals in noise. IEEE
Transactions on Information Theory, 52(3):1030–1051, 2006.
[22] U.S.-Canada Power System Outage Task Force. Final report on the August 14, 2003 blackout in the
United States and Canada: Causes and recommendations. 2004.
[23] L. Vandenberghe, M. S. Andersen, et al. Chordal graphs and semidefinite optimization. Foundations
and Trends R in Optimization, 1(4):241–433, 2015.
[24] A. Vespignani. Complex networks: The fragility of interdependency. Nature, 464(7291):984, 2010.
[25] M. J. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using `1 constrained quadratic programming (Lasso). IEEE Transactions on Information Theory, 55(5):2183–
2202, 2009.
[26] A. J. Wood, B. F. Wollenberg, and G. B. Sheblé. Power generation, operation, and control. John Wiley
& Sons, 2013.
[27] J. Zhao, L. Mili, and R. C. Pires. Statistical and numerical robust state estimator for heavily loaded
power systems. IEEE Transactions on Power Systems, 33(6):6904–6914, 2018.
[28] P. Zhao and B. Yu. On model selection consistency of Lasso. Journal of Machine Learning Research,
7(Nov):2541–2563, 2006.
[29] R. D. Zimmerman, C. E. Murillo-Sánchez, and R. J. Thomas. Matpower: Steady-state operations,
planning, and analysis tools for power systems research and education. IEEE Transactions on Power
Systems, 26(1):12–19, 2010.
[30] F. Zohrizadehb, C. Josza, M. Jina, R. Madanib, J. Lavaeia, and S. Sojoudia. Conic relaxations of power
system optimization: Theory and algorithms.

14

Supplementary Material
This supplementary material includes formal theory and additional experimental details for the paper “Boundary Defense against Cyber Threat for Power System Operation.” The manuscript is organized as follows. We
first discuss the preliminaries in Section A, including notations, power system modeling, the proposed linear basis of representation, and the measurement model considered in the study. We introduce the two-step
pipeline of state estimation in Section B, where we discuss the algorithms with and without the secondorder cone constraints and their connection to robust statistics. Section C introduces the boundary defense
mechanism, including the main results for boundary defense (Lemmas 7 and 14), implications of local property for global property (Lemmas 11 and 17), and performance guarantees for estimation accuracy and bad
data detection (Theorems 12, 13, 19 and 20). The proofs of the main theorems are delegated to Section E.
Experimental details and additional figures are shown in Section D.

A
A.1

Preliminaries
Notations

Vectors are shown by bold letters, and matrices are shown by bold and capital letters. Let xi denote the i-th
element of vector x. We use R and C as the sets of real and complex numbers, and Sn and Hn to represent
the spaces of n × n real symmetric matrices and n × n complex Hermitian matrices, respectively. A set of
indices {1, 2, ..., m} is denoted by [m]. The cardinality |J | of a set J is the number of elements in a set.
The support supp(x) of a vector x is the set of indices of the nonzero entries of x. For a set J ⊂ [m],
we use J c = [m] \ J to denote its complement. The symbols (·)> and (·)∗ represent the transpose and
conjugate transpose operators. We use <(·), =(·) and Tr (·) to denote the real part, imaginary part and trace
of a scalar/matrix. The imaginary unit is denoted as i. The notations ∠x and |x| indicate the angle and
magnitude of a complex scalar. For a convex function g(x), we use ∇g(x) and ∂g(x) to denote its gradient
and subgradient at x, respectively. We use λmin (A) to denote the smallest eigenvalue of A, and A  0 to
indicate that A is a positive semidefinite matrix. Let I (n) denote the identity matrix of dimension n, but
sometimes for simplicity, we omit the superscript whenever the dimension is clear from the context. The
notations kxk0 , kxk1 , kxk2 and kxk∞ show the cardinality, 1-norm, 2-form and ∞-norm of x. We use
k · k∞ to denote the matrix infinity norm (i.e., the maximum absolute column sum of the matrix). Note that
the notations p and q are used for active power and reactive power, respectively.

A.2

Power system modeling

We model the electric grid as a graph G := {N , L}, where N := [nb ] and L := [nl ] represent its sets
of buses and branches. Each branch ` ∈ L that connects bus f and bus t is characterized by the branch
sh
sh
admittance y` = g` + ib` and the shunt admittance y`sh = g`sh + ibsh
` , where g` (resp., g` ) and b` (resp., b` )
denote the (shunt) conductance and susceptance, respectively. Typically, g`sh  bsh
` , so it is set to zero in
the subsequent description. In addition, to avoid duplicate definition, each line ` = (i, j) is defined with a
direction from bus i (i.e., from end, given by f (`) = i) to bus j (i.e., to end, given by t(`) = j). We also use
{i, j}` or simply {i, j} to denote a line ` that connects nodes i and j.

>
The power system state is described by the complex voltage at each bus v = v1 , ..., vnb
∈ Cnb ,
where vk ∈ C is the complex voltage at bus k ∈ N with magnitude |vk | and phase θk := ∠vk . Given the

15

complex voltages, by Ohm’s law, the complex current injected into line {k, j}` at bus k is given by:
i
vk .
ikj = y` (vk − vj ) + bsh
2 `
By defining θkj := θk − θj , one can write the power flow from bus k to bus j as
(`)

pkj = |vk |2 g` − |vk ||vj |(g` cos θkj − b` sin θkj ),
(`)

qkj = −|vk |2 (b` + 12 bsh
` ) + |vk ||vj |(b` cos θkj − g` sin θkj ),
and active (reactive) power injections at bust f as
X (`)
pkj ,
pk =

qk =

X

(`)

qkj .

(2)

{k,j}`

{k,j}`

The above formulas are based on polar coordinates of complex voltages, where measurements are nonlinear functions of voltage magnitudes and phases. Another popular representation is based on rectangular
coordinates of complex numbers, where measurements are expressed as quadratic functions of the real and
imaginary parts of voltages (see [5, Chap. 1] for more details). We use “PV bus” and “PQ bus” to denote
buses with real power injection and voltage magnitudes, and buses with real and reactive power injection
measurements, respectively.

A.3

Linear basis of representation

We introduce a new basis of representation, where measurements can be expressed as linear combinations
of the quantities derived form bus voltages. Specifically, for a given system G, we introduce two groups of
variables:
mg
1. voltage magnitude square, xk := |vk |2 , for each bus k ∈ N , and
∗
im
∗
2. real and imaginary parts of complex products, denoted as xre
` := <(vi vj ) and x` := =(vi vj ), reim
re
spectively, for each line ` = (i, j). Note that there is only one set of variables {x` , x` } for each
line.

Using this representation, we can derive various types of power and voltage measurements as follows:
mg

• Voltage magnitude square. The voltage square magnitude square at bus k ∈ N is simply xk by
definition;
• Branch power flows. For each line ` = (i, j), the real and reactive power flows from bus i to bus j
and in the reverse direction are given by:
(`)

mg

im
pij = g` xi − g` xre
` − b` x`
(`)

mg

re
im
qij = −(b` + 12 bsh
` )xi + b` x` − g` x`
(`)

mg

im
pji = g` xj − g` xre
` + b` x`
(`)

mg

re
im
qji = −(b` + 21 bsh
` )xj + b` x` + g` x`

16

• Nodal power injection. The power injection at bus node k consists of real and reactive powers, i.e.
pk + iqk , where:
X
X
X
X
mg
b` )xim
b
−
−
(
pk =
g` xk −
g` xre
`
`
`
k∈`

k∈`

f (`)=k

t(`)=k

X
X
X
X
mg
re
qk = −(
b` + 21 bsh
g` )xim
g
−
−
(
)x
+
b
x
`
` `
` ,
`
k
k∈`

k∈`

t(`)=k

f (`)=k

P

P

where k∈` is the sum over all lines
P ` ∈ L that are connected to k, f (`)=k is the sum over all lines
` where f (`) = k, and similarly, t(`)=k is the sum over all lines ` where t(`) = k. Equivalently, we
can use (2) to combine the branch power flows defined above.
Thus, each customary measurement in power systems that belongs to one of the above measurement types
can be represented by a linear function1 :
mi (x) = a>
(3)
i x\ ,
mg

im
where ai ∈ Rnx is the vector for the i-th noiseless measurement and x\ = ({xk }k∈N , {xim
` , x` }`∈L ) is
n
m
the regression vector. By collecting all the sensor measurements in a vector m ∈ R , we have

m = Ax\ ,

(4)

where A ∈ Rnm ×nx is the sensing matrix with rows a>
i for i ∈ [nm ].

A.4

Measurement model

To perform SE, the supervisory control and data acquisition (SCADA) system collects measurements about
power flows and complex voltages at key locations instrumented with sensors. This process is subject to
both ubiquitous sensor noise and randomly occurring sensor faults. We consider the measurement model as
follows:
y = Ax\ + w\ + b\ ,
(5)
where A ∈ Rnm ×nx and x\ ∈ Rnx are the sensing matrix and the true regression vector in (4), w\ ∈ Rnm
denotes random noise, and b\ ∈ Rm is the bad data error that accounts for sensor failures or adversarial
noise [13]. Note that x serves as an intermediate parameter and the end goal is to find v.
Because the sensor data are of different types and their corresponding measurements could be of different
scales, we introduce the following condition.
Definition 2 (Measurement normalization convention). Each row of A corresponding to a voltage magnitude measurement is normalized by the degree of connection of the node k, kai k22 = deg(k), and 1 otherwise
kai k22 = 1, where ai is the i-th row of A. The only exception is when the line vulnerability (c.f., Def. 9) is
calculated, when all the measurements are normalized by 1.
This condition is straightforward to implement in practice, since the sensing matrix A is fixed for a given
set of measurements. This is also known as preconditioning, which assists with the statistical performance
of regression.
1

re
It is straightforward to include linear PMU measurements in our analysis as well using the relation tan θij = xim
` /x` for each
line ` = (i, j). Thus, as long as we have two adjacent PMU measurements, we can use the phase difference to construct a linear
re
measurement equation xim
` − tan θij x` = 0.

17

B

Two-step pipeline of state estimation

This section describes the proposed two-step state estimation method. For the first step, we develop algorithms in two categories, which differ by whether or not the second-order cone constraints are incorporated.
Within each category, we also propose two slight variations, which differ by whether the term of squared
loss is included. For the second step, we propose two approaches based on quadratic programming.

B.1

Step 1: Estimation of x\

In the first step, the goal is to estimate x\ from a set of noisy and corrupted measurements y. We consider
two cases separately. In the first case, the dense noise is negligible, i.e., w\ = 0, and we only need to
consider the sparse measurement corruption b.

Case 1: Sparse corruption but no dense noise (i.e., w = 0)
In this case, the measurements are given by y = Ax\ + b\ . To estimate x\ , we solve the following program:
min

b∈Rnm ,x∈Rnx

kbk1 ,

(S(1) : `1 )

subject to Ax + b = y.

Briefly, under some mild conditions on observability and robusteness to be specified in Section C, we can
faithfully recover b\ from the above program. As a consequence, x\ can be obtained by performing regression using the remaining good data.
For this case, we can also incorporate second-order cone (SOC) constraints:
min

b∈Rnm ,x∈Rnx

where

kbk1 ,


K=

x∈R

nx

subject to Ax + b = y,


mg
im
xi
xre
` + jx`
 0,
mg
im
xj
xre
` − jx`



(S(1) : `1 -K)

x ∈ K,


∀` := (i, j) ∈ L .

(6)
mg

mg

im
Let σ(x) denote the index of the variable x (e.g., xi , xre
` , x` ) in the vector x. For instance, σ(xi ) denotes
mg
the index of xi in x. The SOC constraint can be equivalently written as:
 
D`
>
x ∈ C5 ,
(7)
c` x ≥ kD ` xk2 ⇔
c>
`
mg

mg

where c` ∈ Rnx has its σ(xi ) and σ(xj ) entries to be
mg
(1, σ(xi ))

mg
(2, σ(xj ))

√1
2

and 0 elsewhere, and D ` ∈ R4×nx has

im
its
and
entries to be √12 and its (3, σ(xre
` )) and (4, σ(x` )) entries to be 1, and 0
elsewhere, and C5 denotes the second-order cone of dimension 5.
The problem (S(1) : `1 -K) can be reformulated as:
 
D
min
kbk1 , subject to Ax + b = y, >` x ∈ C5 , ∀` ∈ L
(8)
c`
b∈Rnm ,x∈Rnx

using standard SOCP notations. The Lagrangian is given by:
L (x, b, {ν` , µ` }`∈L , h) = kbk1 + h> (y − Ax − b) −

X
`∈L

18

ν` c>
` x + µ` D ` x



The Karush-Kuhn-Tucker (KKT) conditions are given by:
c>
` x ≥ kD ` xk2 ,

(primal feasibility)

Ax + b = y,

(dual feasibility)
(stationarity)

ν` ≥ kµ` k2 , ∀` ∈ L
X
>
−
(ν` c` + D >
` µ` ) = A h,

(complementary slackness)

`∈L
ν` c>
` x+

µ>
` D ` x = 0,

∀` ∈ L

(9)
(10)

h ∈ ∂kbk1

(11)

∀` ∈ L.

(12)

Therefore, the dual program of (S(1) : `1 -K) is given by:
h> y
X
>
(ν` c` + D >
−
` µ` ) = A h

max

h∈Rnm ,{ν` ,µ` }`∈L

subject to

(13a)
(13b)

`∈L

khk∞ ≤ 1
ν` ≥ kµ` k2 ,

(13c)
∀` ∈ L

(13d)

Case 2: Sparse corruption and dense noise
In this case, the dense noise cannot be ignored, and the measurements are given by (3). We perform the
estimation by solving the following mixed-objective optimization:
1
ky
min
b∈Rnm ,x∈Rnx 2nm

− Ax − bk22 + λkbk1 ,

(S(1) : `2 `1 )

where λ > 0 is the regularization coefficient. Due to the existence of dense noise, it is no longer possible to
exactly recover the true x\ ; however, if the magnitude of each dense noise is small, then we can still have
strong statistical bounds on the estimation error.
We can also incorporate second-order cone constraints:
1
min
ky
b∈Rnm ,x∈Rnx 2nm

− Ax − bk22 + λkbk1 ,

subject to x ∈ K,

(S(1) : `2 `1 -K)

where K is defined in (6). The Lagrangian of (S(1) : `2 `1 -K) is given by:
L (x, b, {µ` }`∈L , {ν` }`∈L , h) =

1
2nm ky

− Ax − bk22 + λkbk1 −

X

ν` c>
` x + µ` D ` x



`∈L

The KKT conditions are given by:
(primal feasibility)

c>
` x ≥ kD ` xk2 ,

(dual feasibility)

ν` ≥ kµ` k2 , ∀` ∈ L
X
1 >
A (y − Ax − b) +
(ν` c` + D >
` µ` ) = 0
nm

(stationarity)

∀` ∈ L

(14)
(15)
(16)

`∈L

(complementary slackness)

1
(y − Ax − b) = λh, h ∈ ∂kbk1
nm
>
ν` c>
∀` ∈ L.
` x + µ` D ` x = 0,

The KKT conditions are important for the analysis in Section C.
19

(17)
(18)

B.2

Connection with robust statistics for bad data detection

The so-called bad data rejection and state estimation form an important part of power systems supervisory
control and data acquisition. There are traditional statistical approaches to bad data rejection that involve
iteratively eliminating the measurements with the largest residual that are obtained from a least squares
estimation (see [26, Section 9.6]). Such a smooth quadratic objective can, however, mask bad data by
“spreading” the error around the system. An alternative approach developed in [3] is to use an `1 objective,
which can identify multiple bad data directly. However, the resulting estimate does not average out the effect
of dense, independent measurement errors.
The so-called Huber loss that is quadratic for small measurement residuals but constant or linear for
large measurement residuals has been explored in [17, 4, 27]. The quadratic-linear loss function is convex,
continuous and differentiable at the transition between the quadratic and linear part, and is given by [12]:
(
1 2
r
|r| ≤ ψ
fHuber (r; ψ) = 2
,
(19)
1
ψ(|r| − 2 ψ) |r| > ψ
where ψ is the hyper-parameter controlling the transition point between the `2 and `1 loss functions.
There is an interesting connection between (S(1) : `2 `1 ) and the Huber loss. To see this, we can view
the optimization over b and x in (S(1) : `2 `1 ) as an inner optimization with b for a given x, and an outer
optimization with x. The inner optimization is composed of a series of smaller optimization problems
2
min 2n1m (yi − a>
i x − bi ) + ψ|bi |,
bi

(20)

for i ∈ [nm ], which has the optimal solution


>
b∗i = sign(yi − a>
i x) max 0, yi − ai x − ψ ,

(21)

where sign(y) is the sign of y. Now, by defining ri := yi − a>
i x, we substitute the solution into the outer
optimization to obtain
X
2
1
1
(22)
nm
2 (ri − sign(ri ) max (0, |ri | − ψ)) + ψ| max (0, |ri | − ψ) |.
i∈[nm ]

Hence, it can be seen that the above expression is equal to the Huber loss:
1 X
fHuber (yi − a>
i x; ψ).
nm

(23)

i∈[nm ]

Despite the wide usage of Huber loss in power system estimation, the existing studies in the literature are
mostly empirical. The approach proposed here allows for strong mathematical results that go well beyond
the promising empirical results.

B.3

Step 2: Recovery of v

The goal of the second step is to recover the underlying system voltage v from the estimation x̂ obtained in
Step 1. First, we transform x̂ into estimations of voltage magnitudes and phase differences:
q
mg
• The voltage magnitude at each bus k ∈ N can be obtained by |v̂k | = x̂k ;
20

re
• The phase difference along each line ` = (i, j) is given by θ̂ij = arctan x̂im
` /x̂` .

To obtain the estimations of phases at each bus, we propose two methds. The first method is to solve the
least-squares problem
X
(θi − θj − θ̂ij )2 ,
(S(2) : `2 )
θ̂ = arg minn
θ∈R

b

`=(i,j)

which has a closed-form solution: let θ ∆ be a collection of θ̂ij , and L ∈ Rnl ×nb be a sparse matrix with
L(`, i) := 1 and L(`, j) := −1 for each line ` = (i, j) and zero elsewhere. Then, the solution for (S(2) : `2 )
is given by:
θ̂ = (L> L)−1 L> θ ∆ .
(24)
The second approach is to solve a mixed-objective problem, similar to the first step:
X
X
|θi − θj − θ̂ij |.
(θi − θj − θ̂ij )2 + λ2
θ̂ = arg minn n1l
θ∈R

b

(S(2) : `2 `1 )

`=(i,j)

`=(i,j)

In this case, there is no longer a closed-form solution available, but the advantage is that it is robust to large
errors in the phase difference estimation, in case the first step method does not fully detect the bad data in
the measurements.
Finally, we can reconstruct v̂ via the formula:
v̂k = |v̂k |eiθ̂k ,

k ∈ N.

(25)

If the regression vector from Step 1 is exact, i.e., x̂ = x\ , then we can use (S(2) : `2 ) to accurately recover the
system state v̂ = v. Even if the x̂ is not exact, the second stage estimator (S(2) : `2 `1 ) has nice properties to
control the estimation error, and therefore any potential error in θ̂ij does not propagate along the branches.

C

Boundary defense mechanism

In this section, we give a detailed discussion of the new notion of defense on networks, called “boundary
defense mechanism.” For a given attack scenario, we define a natural partition of the network into the
attacked, inner and outer boundaries, and safe regions. We describe a fairly general framework, which
incorporates a wide range of adversarial scenarios that are localized, including line outage, substation down,
and zonal attacks. For the rest of the analysis, we denote x] and b] as the ground truth for state x and bad
data b, as defined in (5).
Definition 3 (Attacked, boundary, and safe regions). Let Nat be the set of nodes under attack and the
“attacked region” Bat := {Nat , Lat } be the induced subgraph. Let the “inner boundary” be the set of
nodes adjacent to the attacked region Nbi := {i ∈ N \ Nat | ∃j ∈ Nat , s.t. {i, j} ∈ L} and the induced
graph be denoted as Bbi , and the “outer boundary” be the set of nodes adjacent to the inner boundary
region Nbo := {i ∈ N \ (NB ∪ Nbi ) | ∃j ∈ Nbi , s.t. {i, j} ∈ L} and the induced graph be denoted as
Bbo . Let Nbd := Nbi ∪ Nbo be nodes in the “boundary region” and Bbd := {Nbd , Lbd } be the induced
subgraph. We also denote the set of lines that bridge nodes between Bat and Bbi as Lat∩bi , and the set of
lines that brige nodes between Bbi and Bbo as Lbi∩bo . Lastly, let NBsf := N \ (Nat ∪ Nbd ) be the rest of
the nodes and the “safe region” Bsf := {Nsf , Lsf } be the induced subgraph.

21

When there is an attack on a local region, a subset of the local measurements are compromised. We use
B = Bat ∪ Bbi to delineate the smallest subgraph to cover this region. For the simplicity of the analysis,
we assume that there are no lines connecting two inner boundary nodes in Bbi , and that no two nodes in
Bat are connected to the same node in Bbi (one can always enlarge the region B to satisfy these conditions).
Furthermore, we make the assumption that no measurements on the nodes (e.g., voltage magnitudes and
nodal injections) or on the lines (e.g., power branch flows) within the boundary region Bbd are attacked.
The partition set notations in Def. 3 are illustrated in Fig. 11. With the set partition notions ready, we
introduce a partition of the measurements and variables.

…

…
Attacked inner
region ℬ"#

Attacked inner
boundary ℬ$%

Unaffected outer
boundary ℬ$/

Affected region
ℬ = ℬ"# ∪ ℬ$%

Attacked boundary
ℬ$- = ℬ$% ∪ ℬ$/

Unaffected region
ℬ&' = 𝒢 ∖ (ℬ"# ∪ ℬ$- )

Figure 11: The illustrations of the partition set concepts introduced for the case of zonal attacks. Lines or
buses whose measurements are under attack are shown in red.
Definition 4 (Attacked, boundary and safe variables and measurements). The set of “attacked variables”
Xat includes variables on nodes in Bat and lines in Lat ∪ Lat∩bi . The set of “boundary variables” Xbd
includes variables on nodes in Bbd and lines in Lbd . The set of “safe variables” Xsf includes all other
variables. The set of “attacked measurements” Mat includes measurements on nodes in Bat and lines
in Lat . The set of “inner boundary measurements” Mbi includes nodal power injections in Bbi and line
measurements in Lat∩bi , and the set of “outer boundary measurements” Mbo includes voltage magnitude
and line measurements in Bbd . Together, they form the “boundary measurements” Mbd := Mbi ∪ Mbo .
The rest of the measurements Msf are “safe measurements.”

22

By definition, the sets Msf , Mbo , Mbi , Mat form a partition of [nm ], and the sets Xsf , Xbd , and Xat
form a partition of [nx ]. Thus, we can rearrange and partition the matrix A as follows:

 

0
AMsf ,Xsf AMsf ,Xbd
AMsf ,Xsf AMsf ,Xbd AMsf ,Xat


AM ,X
0
0
AMbo ,Xbd
AMbo ,Xbd AMbo ,Xat 
bo sf
.
=
(26)
A=


 AM ,X
0
AMbi ,Xbd AMbi ,Xat 
AMbi ,Xbd AMbi ,Xat
bi sf
0
0
AMat ,Xat
AMat ,Xsf AMat ,Xbd AMat ,Xat
There is no loss of generality in arranging A as above, which is simply for the purpose of presentation. Let
(n )
(n )
(n )
(n )
I Mmat , I Mmbi , I Mmbo , and I Mmsf be matrices that consist of the Mat , Mbi , Mbo , and Msf rows from the
(n )

(n )

(n )

x
and I Xsfx be the matrices that consist of the Xat ,
identity matrix of size nm , respectively, and I Xatx , I Xbd
Xbd and Xsf rows from the identity matrix of size nx . Then, we can obtain each subblock that accounts for
(n )>
(n )
a set of measurements (e.g. Msf ) and variables (e.g. Xsf ) using the equation AMsf ,Xsf = I Mmsf AI Xsfx
without having to specify a particular order sequence of measurements y or variables x,
We introduce the following properties to characterize the sensing matrix A.
h
i
(|M |)
bd |)>
Definition 5 (Lower eigenvalue). Let QMbd ,Xbd := AMbd ,Xbd I (|M
, where I Mbibd consists of
Mbi
Mbi rows of the size–|Mbd | identity matrix. Then, the lower eigenvalue Cmin is the lower bound:




o
n

>
>
>
≥ Cmin .
min λmin QMbd ,Xbd QMbd ,Xbd , λmin AMbo ,Xbd AMbo ,Xbd , λmin AMsf ,Xsf AMsf ,Xsf
(27)

The value Cmin characterizes the influence of bad data on the identifiability of x\ outside the attacked
region. If Cmin is strictly positive and one can accurately detect the support of bad data on the boundary,
then it is possible to obtain a satisfactory estimation of x\ outside the attacked region.
The next property turns out to be critical for bad data support recovery.
Definition 6 (Global mutual incoherence). Let J denote the support of bad data, and let the pseudoinverse
>
−1 >
c
of AJ c be A+
J c = (AJ c AJ ) AJ c . Then, the mutual incoherence parameter ρ(kb ) is given by:
>
ρ(J ) = kA>+
J c A J k∞ .

(28)

The name “mutual incoherence” originates from the compressed sensing literature [9, 21, 28, 25]. The
proposed mutual incoherence definition is not the same as any of the existing mutual incoherence conditions.
Intuitively, it measures the alignment of the sensing directions of the corrupted measurements (i.e., AJ )
with those of the clean data (i.e., AJ c ). If these directions are misaligned (a.k.a., incoherent), then the value
ρ(J ) is low, and it is likely to uncover the support of bad data. In general, the less bad data exist, the
more likely that ρ(J ) will be small. However, the main drawback of this metric is that it depends on each
instance of the bad data support J , and therefore it cannot be used as a robustness metric in a general sense.
Moreover, it turns out that this metric is more conservative than the vulnerability index to be discussed next
(see Proposition 10).

C.1

Vulnerability index and boundary defense for linear/quadratic programming

Our goal is to find the attacked region by detecting a sufficiently large number of measurements within
Mat while avoiding making false positive detection for measurements belonging to the unaffected region.
23

In other words, if Jˆ := supp(b̂) denotes the support of the estimated bad data, then it is desirable to have
Jˆ ⊆ Mat ∪Mbi (here, we relax the condition that Jˆ ⊆ J and allow both false positives and false negatives
within the attacked region). The following lemma establishes a key result for the estimation without SOCs.
Lemma 7 (Boundary defense stops error propagation). Suppose tthat here is no dense measurement noise
(i.e., w = 0), and the bad data are confined within Mat , i.e., supp(b\ ) ⊆ Mat . Also, suppose that
AMsf ∪Mbd ,Xsf ∪Xbd has full column rank. If for an arbitrary b?Mbd with support limited to the inner boundary, i.e., supp(b?Mbd ) ⊆ Mbi , the solution x̂bd ∈ Xbd to the program
min kz Mbd − AMbd ,Xbd xbd k1

(29)

xbd

is unique and satisfies the properties x̂bd = x\bd , where z Mbd = AMbd ,Xbd x\bd +b?Mbd , then the solution
x̂ to (S(1) : `1 ) satisfies the properties x̂bd = x\bd and x̂sf = x\sf .
To sketch the proof, since by assumption the unique optimal solution for the measurement-sensing matrix pair (y Msf , AMsf ,Xsf ∪Xbd ) given x\bd recovers the ground truth x\sf , we aim at showing that the unique
optimal solution of (y Mbd ∪Mat , AMbd ∪Mat ,Xbd ∪Xat ) corresponding to the boundary state coincides with
x\bd , which completes the proof because this set of measurements is independent of the states xsf . This
achieves a de facto coupling of the “weakly coupled” system due to the overlapping regions corresponding
to measurements y Mbd .
Proof. There are two ways to prove the statement. The first one relies on logical reasoning that is intuitive,
while the second approach is based on KKT conditions that can be easily generalized to measurements with
dense noise. We start with the first approach, which partitions the loss function in (S(1) : `1 ) into the sum of
three terms:
f1 (xsf , xbd ) = ky Msf − AMsf ,Xsf xsf − AMsf ,Xbd xbd k1 ;
f2 (xbd , xat ) = ky Mbd − AMbd ,Xbd xbd − AMbd ,Xat xat k1 ;
f3 (xat ) = ky Mat − AMat ,Xat xat k1 .
Let z Mbd = y Mbd − AMbd ,Xat xat = AMbd ,Xbd x\bd − AMbd ,Xat (x\at − xat ), and by the structure of
AMbd ,Xat shown in (26), we have supp (AMbd ,Xat (xat − x\at )) ⊆ Mat . Hence, we have that the unique
optimal of f2 (xbd , xat ) satisfies x̂bd = x\bd for any given xat . Since there are no bad data for y Msf
and y Mbd and moreover AMsf ∪Mbd ,Xsf ∪Xbd has full column rank, the unique minimum of f1 (xsf , xbd ) is
(x̂sf , x̂bd ) = (x\sf , x\bd ). Therefore, for any given xat , the unique optimal of f1 (xsf , xbd ) + f2 (xbd , xat )
is (x̂sf , x̂bd ) = (x\sf , x\bd ). Since f3 (xat ) does not depend on (xsf , xbd ), the unique optimal solution of
(S(1) : `1 ) recovers the true solution.
The second approach is as follows. We can write the dual program of (S(1) : `1 ) as:
max h> y,

h∈Rnm





x>
\sf

x>
\bd

subject to A> h = 0,
>

h

, b̂ = 0>

we simply need to find a dual certificate h? = h>
Msf
To show that x̂ =

x̂at

>
b̂Mbd

h>
Mbd

khk∞ ≤ 1.
i>
>
b̂Mat
h>
Mat



(S(1) : `1 -dual)

is the optimal solution of (S(1) : `1 ),

>

that satisfies the KKT conditions:

(dual feasibility)

A> h? = 0,

(30)

(stationarity)

h? ∈ ∂kb̂k1 .

(31)

24



> >
Since by the reasoning above, x>
is the unique optimal of the objective f1 (xsf , xbd )+f2 (xbd , xat ),
\sf x\bd
>
 >
>
it corresponds to a dual certificate hMsf hMbd such that
>
A>
Msf ,Xsf ∪Xbd hMsf + AMbd ,Xsf ∪Xbd hMbd = 0,

(32)

khMsf k∞ ≤ 1, khMbd k∞ ≤ 1.

(33)

Similarly, by the optimality of x̂at for f3 (xat ), we can find a dual certificate such that:
A>
Mat ,Xat hMat = 0,

hMat ∈ ∂kb̂Mat k1 .


Thus, by the structure of A, the construction h? = h>
Msf

h>
Mbd

h>
Mat

>

(34)
yields a dual certificate.

A key condition in Lemma 7 is the recovery of the boundary variables in the presence of arbitrary bad
data that occur in the attacked region. This condition needs to be checked for every possible attack scenario,
which is not useful to understand the system vulnerability in the general case. Instead, we propose a linebased vulnerability index notion in the main text, which provides a sufficient condition in this context. The
technical definition is as follows.
Definition 8 (Local boundary variables and measurements). For each line ` that connects nodes i and j, let
us distinguish the directions i → j and j → i. For the direction i → j, let i denote the node under attack
i→j
and j be the node within the inner defense boundary. Accordingly, let Bbo
denote the set of buses (other
i→j
than i) that are directly connected to j as the outer boundary, Bbi = {j} be the one-bus inner boundary,
i→j
and Bat
= {i} be the one-bus attack set. Let Li→j
bd represent the union of line ` and the set of lines that
i→j
i→j
i→j
as the collection of voltage magnitudes
. Define the “boundary variables” Xbd
and Bbo
bridge Bbi
mg
re
im
{xk }k∈Bi→j ∪Bi→j and variables {xη , xη } for the set of lines η ∈ L that connect the inner boundary j
bi

bo

i→j
i→j
i→j
to nodes in the outer boundary Bbo
. Define the “boundary measurements” Mi→j
bd = MbdX ∪ Mbd×
i→j
, denoted by Mi→j
as the collection of measurements that depend only on the boundary variables Xbd
bdX ,
i→j
re
im
and measurements that depend on both Xbd and variables {x` , x` } of the attacked line `, denoted by
Mi→j
bd× . The above terms can be similarly defined for the direction j → i by replacing i → j to j → i in the
notations. Thus, for each line, we will have two sets of boundary variables and measurements.

With the above notations, we can formally describe the line vulnerability index.
Definition 9 (Line vulnerability index). For each line {i, j}` ∈ L, define the line vulnerability metric αi→j
along the direction i → j as the optimal objective value of the following minimax program:
αi→j =

max

i→j
n×

ξ∈{−1,+1}

subject to

α

min
n

α∈R,h∈R

(35a)

i→j
X

A>
h + A>
ξ=0
Mi→j ,X i→j
Mi→j ,X i→j

(35b)

khk∞ ≤ α,

(35c)

bdX

bd

bd×

bd

i→j
i→j
i→j
where ni→j
= |Mi→j
= |Mi→j
X
bdX | and n×
bd× | are the number of measurements in MbdX and Mbd× ,
i→j
i→j
respectively, and Xbd
, Mi→j
bdX and Mbd× are the boundary variables and measurement indices introduced
in Def. 8. Similarly, we can define the backward line vulnerability metric αj→i by replacing i → j to j → i
in (35). We adopt the measurement normalization convention in Def. 2.

25

Note that for the simple case where there are no lines between any two nodes in NBbi , we can extend the
above definition to treat each node in NBbi separately. Due to the localized nature, this condition is much
weaker than the global mutual incoherence condition in Def. 6. This is intuitive, because if the network is
attacked and the data for a subset of the network are manipulated, then this can be modeled by a cut that
removes a subgraph. Then, even if data analytics cannot reason about the lines inside the subgraph, we can
still identify the boundary of the subgraph and correctly recover the state for the rest of the network. In fact,
we can show the following relationship with the mutual incoherence metric.
Proposition 10 (Mutual incoherence is more conservative than vulnerability index). For each line ` and the
i→j
i→j
corresponding partitions of measurements Mi→j
bdX , Mbd× and variables Xbd , let
>+
ρ(Mi→j
bd× ), = kA i→j

i→j
MbdX ,Xbd

k
A>
Mi→j ,X i→j ∞
bd×

bd

be the mutual incoherence metric defined in Def. 6. Then, it holds that ρ(Mi→j
bd× ) ≥ αi→j .
Proof. Notice that the line vulnerability index can be written as
αi→j =

max

khk∞

min

i→j
n×

n

α∈R,h∈R

ξ∈{−1,+1}

(36a)

i→j
X

A>
h + A>
ξ = 0.
Mi→j ,X i→j
Mi→j ,X i→j

subject to

bdX

Since for any ξ, the vector ĥ(ξ) = −A>+i→j

i→j
MbdX ,Xbd

bd

bd×

(36b)

bd

A>
ξ is a feasible point for the inner optimizaMi→j ,X i→j
bd×

bd

tion, and
max

i→j
n×

kĥ(ξ)k∞ = ρ(Mi→j
bd× ),

(37)

ξ∈{−1,+1}

the proof is immediately concluded.
A key step in establishing the validity of the boundary defense mechanism is to ensure that local defense
is sufficient to guard against attacks when solving the problem globally.
Lemma 11 (Local property implies global property). Given
 Bat , Bbi , Bbo , and Bsf and the associated set
AMsf ,Xsf AMsf ,Xbd
0
AMbo ,Xbd , and let Lat∩bi := {{i, j} ∈ L | i ∈ Bat , j ∈ Bbi }
partitioning (c.f., Def. 4), let A◦ = 
0
AMbi ,Xbd
be the set of lines that bridge between Bat and Bbi . If αi→j ≤ 1 − γ and γ > 0 for all {i, j} ∈ Lat∩bi such
that i ∈ Bat and j ∈ Bbi , then for any ĥMbi ∈ [−1, 1]|Mbi | , there exists an ĥMsf ∪Mbo with the properties
kĥMsf ∪Mbo k∞ ≤ 1 − γ and
◦>
A◦>
Msf ∪Mbo ĥMsf ∪Mbo + AMbi ĥMbi = 0.

h
>
Proof. First, we show that a sufficient condition for the existence of ĥMsf ∪Mbo = ĥM
sf

(38)
>

ĥMbo

i>

such

that kĥMsf ∪Mbo k∞ ≤ 1 − γ and (38) is satisfied is that for any ĥMbi , there exists an ĥMbo such that
kĥMbo k∞ ≤ 1 − γ and
>
A>
(39)
Mbo ,Xbd ĥMbo + AMbi ,Xbd ĥMbi = 0.

26

h
i>
>
This is immediate by simply choosing ĥMsf ∪Mbo = 0> ĥM
. In what follows, we prove (39) by
bo
induction. The induction rule is as follows: we start by arbitrarily choosing one line {i, j} ∈ Lat∩bi , where
(1)
(1)
i→j
i ∈ Bat and j ∈ Bbi , and initialize the measurement set Mbo := Mi→j
bdX , Mbi := Mbd× and the variable
(1)
i→j
set Xbd := Xbd
. For each step k, we add a new line {f, t} ∈ Lat∩bi and the associated measurements
(k)
(k)
(k)
and variables to Mbo , Mbi and Xbd , respectively. After the inclusion of all the lines in Lat∩bi , we should
obtain the set Mbo , Mbi and Xbd . In each step, we check whether there exists a vector ĥM(k) such that
bo

kĥM(k) k∞ ≤ 1 − γ and
bo

A>

(k)

(k)

Mbo ,Xbd

ĥM(k) + A>
bo

(k)

(k)

Mbi ,Xbd

ĥM(k) = 0.

(40)

bi

The base case for k = 1 follows directly from the condition that αi→j ≤ 1 − γ. For any k ≥ 1, let
{f, t} ∈ Lat∩bi denote the line to be added, where f ∈ Mat and t ∈ Mbi . There are two possible cases:
1) the new line does not share any nodes with the lines that have been already added; or 2) the new line
shares the attack node f with one (or more) of the lines already added (note that by definition, the new line
cannot share the inner boundary node t with one (or more) of the lines already added). For each case, there
i→j
are connected to one or more
are also three events that may occur: a) one or more of the nodes in Bbo
of the nodes in the inner boundaries of lines that have already been added; and/or b) one or more of the
nodes in the outer boundary of the lines that have already been added are connected to t; or c) none of the
above (note that by definition, there are no lines within the inner boundary region). We need to consider
all the combinations between the three cases and the three events to show that (40) holds in all scenarios.
Fortunately, all the combinations can be reduced to two typical scenarios, where the proofs can be directly
applied. We consider these scenarios now.
(k+1)
(k)
(k+1)
(k)
→t
The first scenario applies to Cases 1c and 2c, where Mbo
= Mbo ∪ MfbdX
, Mbi
= Mbi ∪
(k)
(k)
(k)
(k+1)
(k)
f →t
→t
→t
f →t
→t
= ∅. Therefore,
= ∅, and Xbd ∩Xbd
= ∅, Mbi ∩Mfbd×
, Mbo ∩MfbdX
, Xbd
= Xbd ∪Xbd
Mfbd×
h
i>
h
i
>
>
>
> >
for any given ĥM(k+1) = ĥM(k) ξ̂
with kξ̂k∞ ≤ 1, we can always find ĥM(k+1) = ĥM(k) ĥ
,
bi

bi

bo

bo

where ĥM(k) is given by (40) and ĥM(k) is given by (35), and kĥM(k+1) k∞ ≤ 1 − γ by definition.
bo

bo

bo

The second scenario applies to Cases 1a, 1b, 2a and 2b. Let Ñbo be the set of nodes in the outer boundary
(k+1)
f →t
shared by the new line Bbo
and those of the lines that have been added. Then, we have Mbo
=
(k)
(k+1)
(k)
(k+1)
(k)
(k)
f →t
f →t
f →t
f →t
= Xbd ∪ Xbd , where Mbo ∩ MbdX is the set of
= Mbi ∪ Mbd× , Xbd
Mbo ∪ MbdX , Mbi
f →t
→t
= ∅, and Xbd ∩ Xbd
is the set of
voltage magnitude measurements of nodes in Ñbo , Mbi ∩ Mfbd×
(k)

(k)

>

voltage magnitude variables of nodes in Ñbo . For any given ĥM(k) and ξ̂ , we can always find ĥM(k) and
bi

>

bo

ĥ , where ĥM(k) is given by (40) and ĥM(k) is given by (35). Let ĥM(k) be further divided into the parts
bo
bo
bo
h
i
corresponding to the voltage magnitude measurements (if available) of nodes in Ñbo (i.e. ĥM(k)
) and
h
i
h i
h i bo Ñbo
and the rest ĥ c . Then, by
the rest (i.e. ĥM(k)
); similarly, let ĥ be further divided into ĥ
Ñbo
Ñbo
bo Ñ c
" bo
#
h
i
h i > h i> >
h
i>
1
setting ĥM(k+1) = ĥ (k)
, where deg(Ñbo )
◦ ĥ (k)
+ ĥ
ĥ
bo

Mbo

Mbo

deg(Ñbo )

c
Ñbo

Ñbo

Ñbo

c
Ñbo

is the connectivity degree for each node in Ñbo , and ◦ indicates the Hadamard (element-wise) product, we
h
i
>
> >
can satisfy (40) for any given ĥM(k+1) = ĥM(k) ξ̂
(note that the voltage magnitude measurement in
bi

bi

27

the calculation of line vulnerability metric is normalized by 1, but it is weighted by the degree of each node
in the actual estimation algorithm, c.f., Def. 2). Moreover, by construction, we have kĥM(k+1) k∞ ≤ 1 − γ
bo

for all k. This completes the induction proof.

Lemma 11 implies that as long as all the line vulnerability indices are bounded away from 1, we have
a desirable property in terms of defending against bad data on the boundary. This is formalized in the
following theorem.
Theorem 12. Consider the measurements y = Ax\ + b\ , where supp(b\ ) ⊆ Mat . Suppose that for the
given partitioning of the network as Bat , Bbi , Bbo , and Bsf , the following conditions hold:
• (Full column rank for the safe and boundary region) AMsf ∪Mbd ,Xsf ∪Xbd and
i
h
bd |)>
QMbd ,Xbd = AMbd ,Xbd I (|M
Mbi
have full column rank.
• (Localized mutual incoherence) for all lines {i, j} ∈ Lat∩bi that bridge the attacked region and the
inner boundary, where i ∈ Bat , j ∈ Bbi , we have αi→j ≤ 1 − γ for some γ > 0.
Then, the solution to (S(1) : `1 ), denoted as (x̂, b̂), uniquely recovers the true state outside the attacked region
(i.e., x̂sf = x\sf and x̂bd = x\bd ). Furthermore, the state estimation by (S(2) : `2 ) recovers the true state for
the unaffected region (i.e., v̂k = vk for k ∈ Bsf ∪ Bbd ).
Proof. To prove the claim, we simply need to show that for an arbitrary b? with its support limited to the
inner boundary supp(b? ) ⊆ Mbi , the solution x̂bd ∈ Xbd to the program
min kz Mbd − AMbd ,Xbd xbd k1
xbd

(41)

is unique and satisfies x̂bd = x\bd , where z Mbd = AMbd ,Xbd x\bd + b? . To show this, we obtain the dual
program:
max h>
subject to A>
(42)
Mbd z Mbd ,
Mbd ,Xbd hMbd = 0, khMbd k∞ ≤ 1.
hMbd

Our goal is to find a dual certificate h?Mbd that satisfies the KKT conditions:
(dual feasibility)

A>
Mbd ,Xbd h?Mbd = 0,

(43)

(stationarity)

h?Mbd ∈ ∂kb? k1 .

(44)

By the limited support assumption, we need to find a vector h? such that h?Mbi = sign(b?Mbi ) and
kh?Mbo k∞ ≤ 1. By the mutual incoherence condition and Lemma 11, we can always find h?Mbo that
satisfies (43) for any given h?Mbi and kh?Mbo k ≤ 1 − γ < 1. Thus, this certifies the optimality of
(x\bd , b? ) for (42).
To show that (x\bd , b? ) is the unique optimal solution, let (x̃, b̃) be an arbitrary feasible point of
(41) that is different from (x\bd , b? ). Due to the lower eigenvalue condition, the matrix QMbd ,Xbd :=
h
i
(|Mbd |)>
has full column rank. By letting J˜ = supp(b̃), the set J˜ can not be equal to or
AM ,X
I
bd

bd

Mbi

28


 

x̃
x\bd
= z Mbd , we must have
be a subset of Mbi , because otherwise, from QMbd ,Xbd
= QMbd ,Xbd
b?
b̃

  
x̃
x\bd
=
, which is contradictory to the assumption. Let J˜c = J˜ \ Mbi ; then,
b?
b̃
kb? k1 = h>
?Mbd z Mbd
=

(45)

h>
?Mbd (AMbd ,Xbd x̃

+

I>
b̃
J˜c J˜c

+

I>
Mbi b̃Mbi )

(46)

= h>
b̃ + h>
?Mbi b̃Mbi
?J˜ J˜c

(47)

≤ kh?J˜c k∞ kb̃J˜c k1 + kh?Mbi k∞ kb̃Mbi k1

(48)

< kb̃J˜c k1 + kb̃Mbi k1

(49)

= kb̃k1 ,

(50)

c

where (45) is due to the strong duality between (41) and (42), (46) is due to the primal feasibility of (x̃, b̃),
(47) is due to the dual feasibility condition (43), (48) is due to the Hölder inequality, and (49) is due to the
strict feasibility of h? . Thus, we have shown the uniqueness of the optimal solution (x\bd , b? ). Together
with Lemma 11, we have proved the theorem.
This result can be used to certify robustness under different attack scenarios. For example, if there is
a topological error caused by line mis-specification, say ` = (i, j), we can treat the two ends of the line
as the attacked nodes, i.e., Nat = {i, j}, treat the adjacent nodes to them as inner boundary Nbi , and treat
the adjacent nodes to inner boundary as outer boundary Nbo . As long as the line vulnerability index for the
lines surrounding the attacked nodes are less than 1, one can identify this gross injection error and thus the
topological mistake. We can extend the analysis to the case where the measurements have both sparse bad
data and dense noise. In this case, we need to solve a program that combines quadratic loss with absolute
value loss. The guarantees now depend on the distribution of the dense noise.
Theorem 13 (Robust SE with (S(1) : `2 `1 )). Consider the measurements y = Ax\ + w\ + b\ , where w\ has
independent entries with zero mean and subgaussian parameter σ and supp(b\ ) ⊆ Mat . Suppose that the
rows of A are normalized (c.f., Def. 2), and the regularization parameter λ is chosen such that
λ>

2 p 2
2σ log nm .
nm γ

(51)

In addition, suppose that for the given partitioning of the network, i.e. Bat , Bbi , Bbo , and Bsf , the following
conditions hold:
• (Full column rank for the safe and boundary region) AMsf ∪Mbd ,Xsf ∪Xbd and
i
h
bd |)>
QMbd ,Xbd = AMbd ,Xbd I (|M
Mbi
have full column rank.
• (Localized mutual incoherence) for all lines {i, j} ∈ Lat∩bi that bridge the attacked region and the
inner boundary, where i ∈ Bat , j ∈ Bbi , we have αi→j ≤ 1 − γ for some γ > 0.
Then, the following properties hold for the solution to (S(1) : `2 `1 ), denoted as (x̂, b̂):
29

1. (No false inclusion) The solution (x̂, b̂) has no false bad data inclusion (i.e., supp(b̂) ⊂ supp(b\ ))
0
, for some constant c0 > 0.
with probability greater than 1 − ncm


AMsf ,Xsf AMsf ,Xbd


0
AMbo ,Xbd  and Q◦Mbi = A◦ I ◦>
2. (Large bad data detection) Let A◦ := 
Mbi , and
0
AMbi ,Xbd

g(λ) = nm λ

1
◦
−1 >
+ kI b (Q◦>
Mbi QMbi ) I b k∞
2 Cmin



√

be a threshold value, and let b̃Mbi = AMbi ,Xat (x\at − x̂at ) be the error at the boundary. Then, all
bad data with magnitude greater than g(λ) will be detected (i.e., if |b̃i | > g(λ), then |b̂i | > 0) with
probability greater than 1 − cm2 .
3. (Bounded error) The estimator error is bounded by
p
|Xsf | + |Xbd | + |Mbi |
◦
−1 >
kx\Xsf ∪Xbd − x̂Xsf ∪Xbd k2 ≤ t
+ nm λkI x (Q◦>
Mbi QMbi ) I b k∞,2
Cmin


2
with probability greater than 1 − exp − cσ1 t4 .
Despite the difference in measurement assumptions (i.e., existence of dense noise w) and estimation algorithms (i.e., (S(1) : `1 ) or (S(1) : `2 `1 )), it is remarkable that the boundary defense conditions in Theorems
12 and 13 are coincident. In the case of negligible dense noise, a deterministic boundary defense is achieved.
With the presence of dense noise, it is no longer possible to have deterministic guarantees; however, Theorem 13 indicates that with a proper selection of the penalty coefficient λ, one can avoid false detection
of bad data in the unaffected region (part 1), detect bad data with magnitudes greater than a threshold in
the attacked region (part 2), and achieve estimation within bounded error margin for states within the unaffected region. Furthermore, both the bad data threshold and the error bound decrease with stronger mutual
incoherence condition and lower-eigenvalue condition. The proof of the theorem is provided in Section E.1.

C.2

Vulnerability index and boundary defense for second-order cone programming

In this section, we extend the analysis of boundary defense to the case where we perform state estimation
with the additional second-order cone constraints.
Lemma 14 (Boundary defense stops error propagation with SOCP). Suppose that there is no dense measurement noise (i.e., w = 0), and the bad data are confined within Mat , i.e., supp(b\ ) ⊆ Mat . Let Kbd
and Kat be the subsets of SOC constraints K restricted to variables xbd and xat , respectively, and let
(


xmg
xre
+ jxim
i
`
`
K̃at (x̂bd ) = xat
 0,
im
xre
xmg
j
` − jx`
)
mg
∀` := (i, j) ∈ Lat ∪ Lat∩bi , where xmg
i = x̂i

30

∀i ∈ Bbi ,

be the confined feasible set for xat , which fixes the boundary variables x̂bd in the SOCP constraints. Assume
that for an arbitrary b?Mbd with its support limited to the inner boundary, i.e. supp(b?Mbd ) ⊆ Mbi , the
solution x̂bd ∈ Xbd to the program
min kz Mbd − AMbd ,Xbd xbd k1 ,

(52)

xbd ∈Kbd

is unique and satisfies x̂bd = x\bd , where z Mbd = AMbd ,Xbd x\bd + b?Mbd . Assume that the optimal
solution x̂at to
min ky Mat − AMat ,Xat xat k1 ,
(53)
xat ∈Kat

also satisfies that x̂at ∈ K̃at (x\bd ). Then, the solution x̂ to (S(1) : `1 -K) satisfies x̂bd = x\bd and x̂sf =
x\sf .

h
i>
h
i> 
>
>
>
>
>
>
Proof. To show that x̂ = x\sf x\bd x̂at , b̂ = 0
is the optimal solution of
b̂Mbd b̂Mat


>

>
>
,
{ν
,
u
}
that
(S(1) : `1 -K), we simply need to find a dual certificate h? = h>
h
h
`
`
`∈L
Mat
Mbd
Msf
satisfies the KKT conditions:
h? ∈ ∂kb̂k1 ,

(stationarity)
A > h? +

(dual feasibility)

X



ν` c` + D >
` u` = 0;

(54)

ν` ≥ ku` k2 ,

∀` ∈ L,

(55)

>
ν` c>
` x̂ + u` D ` x̂ = 0,

∀` ∈ L,

(56)

`∈L

(complementary slackness)
For a given xbd = x\bd , let x̂sf be the optimal solution to

min ky Msf − AMsf ,Xsf xsf − AMsf ,Xbd x\bd k1 ,

xsf ∈Ksf

where Ksf is set of all SOCP constraints that involve at least one variable in Xsf . By the lower eigenvalue
condition, x̂sf = x\sf is the unique optimal solution. Since for a given x̂at ∈ K̃at (x\bd ), x̂bd = x\bd is the


> >
is the unique optimal of
unique optimal of (52), we can conclude that x>
\sf x\bd
min

xsf ∈Ksf ,xbd ∈Kbd

ky Msf − AMsf ,Xsf xsf − AMsf ,Xbd xbd k1 + kz Mbd − AMbd ,Xbd xbd k1 ,

which corresponds to a dual certificate


h>
Msf

h>
Mbd

>

>
A>
Msf ,Xsf ∪Xbd hMsf + AMbd ,Xsf ∪Xbd hMbd


, {ν` , u` }`∈Lsf ∪Lbd such that

X 
u
+
ν` c` + D >
` ` = 0,

(57a)

`∈Lsf ∪Lbd

ν` ≥ ku` k2 ,
ν` c>
` x̂

+

∀` ∈ Lsf ∪ Lbd ,

u>
` D ` x̂

= 0,

(57b)

∀` ∈ Lsf ∪ Lbd ,

khMsf k∞ ≤ 1, khMbd k∞ ≤ 1.

(57c)
(57d)

Similarly, by the optimality of x̂at for (53), we can find a dual certificate such that:

X 
>
A>
h
+
ν
c
+
D
u
hMat ∈ ∂kb̂Mat k1 .
M
` `
at
Mat ,Xat
` ` = 0,
`∈Lat




Thus, by setting {ν` = 0, u` = 0}`∈Lat∩bi , and note that L = Lsf ∪ Lbd ∪ Lat∩bi ∪ Lat , the construction
>


>
>
yield a dual certificate.
{ν` , u` }`∈L and h? = h>
Msf hMbd hMat
31

Now, we formally define the vulnerability index.
Definition 15 (Line vulnerability for SOCP). For each line {i, j}` ∈ L and a given x ∈ K that satisfies
SOCP along the direction i → j as the optimal value
primal feasibility, define the line vulnerability metric αi→j
of the following minimax program:
SOCP
αi→j
(x) =

max

i→j
n×

ξ∈{−1,+1}

subject to

αmin
n

α∈R,ω∈R

(58a)

i→j
i→j
n
L
,h∈R X

X

A>
h + A>
ξ+
Mi→j ,X i→j
Mi→j ,X i→j
bdX

bd

bd×

bd

ω` T ` x = 0

∀` ∈ Li→j
bd

ω` ≥ 0,

(58b)

`∈Li→j
bd

(58c)

khk∞ ≤ α,

(58d)

i→j
i→j
i→j
where ni→j
= |Mi→j
= |Mi→j
= |Li→j
X
bdX |, n×
bd× |, nL
bd | are the number of measurements/lines in MbdX ,
i→j
i→j
i→j
i→j
i→j
Mi→j
bd× and Lbd , respectively, and Xbd , MbdX , Mbd× and Lbd are defined in Def. 8. Also, we define
>
T ` = c` c>
` −D ` D ` , where c` and D ` are given in (7). Similarly, we define the backward line vulnerability
metric αj→i by replacing i → j to j → i in (58). We adopt the measurement normalization convention in
Def. 2.
SOCP (x) for a given x ∈ K that satisfies the primal feasibility
Lemma 16. The line vulnerability metric αi→j
coincides with the optimal objective value of the following minimax program:
SOCP
α̃i→j
(x) =

max

ξ̃∈[−1,+1]

i→j
n×

subject to

α̃

min
α̃∈R,ν∈R

i→j
i→j
n
n
L
,h̃∈R X

A>
h̃ + A>
ξ̃ +
Mi→j ,X i→j
Mi→j ,X i→j
bdX

bd

bd×

bd

(59a)
X

ν` c` + D >
` u` = 0

(59b)

`∈Li→j
bd

ν` ≥ ku` k2 ,

∀` ∈ Li→j
bd

(59c)

>
ν` c>
` x + u` D ` x = 0,

∀` ∈ Li→j
bd

(59d)

kh̃k∞ ≤ α̃,

(59e)

with the same notations as in Def. 9, where c` and D ` are define in (7).
i→j

i→j

Proof. The equivalence between optimizing over [−1, +1]n× and {−1, +1}n× for the outer minimization can be reasoned as in (21) due to the convexity of the feasibility region given x ∈ K and ξ̃. Since x
satisfies the primal feasibility, which can be expressed as in (7), a standard result (c.f., [2, Lemma 15]) in
analogy to linear programming indicates that (59d) is equivalent to:
ν` D ` x + c>
` xu` = 0,

∀` ∈ Li→j
bd ,

i→j
which indicates that ν` = ω` c>
` x and u` = −ω` D ` x for ω` ≥ 0 and ` ∈ Lbd . It can be verified that this
>
also satisfies the SOCP constraints (59c). By the definition of T ` = c` c>
` − D ` D ` , the equivalence to (58)
is established.

32

Lemma 17 (Local property implies global property 
for SOCP). Given Bat ,
Bbi , Bbo , and Bsf and the asAMsf ,Xsf AMsf ,Xbd
0
AMbo ,Xbd , and c◦` and D ◦` to be the
sociated set partitioning (c.f., Def. 4), let A◦ = 
0
AMbi ,Xbd
SOCP ≤ 1 − γ and γ > 0 for all
subvector and submatrix of c` and D ` indexed by Xsf ∪ Xbd . If αi→j
{i, j} ∈ Lat∩bi such that i ∈ Bat and j ∈ Bbi , then for any ĥMbi ∈ [−1, 1]|Mbi | , there exist ĥMsf ∪Mbo and
{ν̂` , û` }`∈Lat∩bi ∪Lbd ∪Lsf with the properties that kĥMsf ∪Mbo k∞ ≤ 1 − γ and
X
◦>
ν̂` c◦` + D ◦>
(60)
A◦>
Msf ∪Mbo ĥMsf ∪Mbo + AMbi ĥMbi +
` û` = 0.
`∈Lat∩bi ∪Lbd ∪Lsf

Proof. The proof is similar to the one for Lemma 11. First, we show that a sufficient condition for Lemma
17 is that for any ĥMbi , there exists ĥMbo and {ν̂` , û` }`∈Lat∩bi ∪Lbd such that kĥMbo k∞ ≤ 1 − γ and
h
i
X
>
>
û
= 0.
(61)
ν̂
c
+
D
+
+
A
ĥ
A>
ĥ
` `
Mbi ,Xbd Mbi
Mbo ,Xbd Mbo
` `
Xbd

`∈Lat∩bi ∪Lbd

h
i>
>
and ν̂` = 0 and û` = 0 for ` ∈ Lsf .
This is immediate by simply choosing ĥMsf ∪Mbo = 0> ĥM
bo
In what follows, we prove (61) by induction. The induction rule is as follows: we start by arbitrarily
(1)
choosing one line {i, j} ∈ Lat∩bi , where i ∈ Bat and j ∈ Bbi , and initialize the line set Lbd = Li→j
bd , the
(1)
(1)
(1)
i→j
i→j
i→j
measurement set Mbo := MbdX , Mbi := Mbd× and the variable set Xbd := Xbd . For each step k,
we add a new line {f, t} ∈ Lat∩bi such that Lbd = Lbd ∪ Lfbd→t , and the associated measurements and
(k)
(k)
(k)
variables to Mbo , Mbi and Xbd , respectively. After the inclusion of all the lines in Lat∩bi , we should
obtain the set Mbo , Mbi and Xbd . In each step, we check whether there exist {ν̂` , û` }`∈L(k) and ĥM(k)
(k)

(k−1)

bd

bo

such that kĥM(k) k∞ ≤ 1 − γ and
bo

A>

(k)

>
(k) + A
(k) ĥ
M

Mbo ,Xbd

bo

(k)

(k) +
(k) ĥ
M

Mbi ,Xbd

bi

X h

ν̂` c` + D >
` û`

i

(k)
`∈Lbd

(k)

Xbd

= 0.

(62)

SOCP ≤ 1 − γ. For any k ≥ 1, let
The base case for k = 1 follows directly from the condition that αi→j
{f, t} ∈ Lat∩bi denote the line to be added, where f ∈ Mat and t ∈ Mbi . There are two possible cases:
1) the new line does not share any nodes with lines that have been already added; or 2) the new line shares
the attack node f with one (or more) of the lines already added (note that by definition, the new line cannot
share the inner boundary node t with one (or more) of the lines already added). For each case, there are
f →t
also three events that might occur: a) one or more of the nodes in Bbo
are connected to one or more
of the nodes in the inner boundaries of lines that have already been added; and/or b) one or more of the
nodes in outer boundary of the lines that have already been added are connected to t; or c) none of the
above (note that by definition, there are no lines within the inner boundary region). We need to consider
all the combinations between the three cases and the three events to show that (40) holds in all scenarios.
Fortunately, all the combinations can be reduced to two typical scenarios, where the proofs can be directly
applied. We consider these scenarios now.
(k+1)
(k)
(k+1)
(k)
→t
The first scenario applies to Cases 1c and 2c, where Mbo
= Mbo ∪ MfbdX
, Mbi
= Mbi ∪
(k+1)
(k)
(k)
(k)
(k)
→t
f →t
→t
→t
f →t
Mfbd×
, Xbd
= Xbd ∪ Xbd
, Mbo ∩ MfbdX
= ∅, Mbi ∩ Mfbd×
= ∅, and Xbd ∩ Xbd
= ∅.
h
i>
h
i>
>
>
>
>
Therefore, for any given ĥM(k+1) = ĥM(k) ξ̂
, we can always find ĥM(k+1) = ĥM(k) ĥ
and
bi

bi

bo

33

bo

{ν̂` , û` }`∈L(k+1) = {ν̂` , û` }L(k) ∪Lf →t , where ĥM(k) and {ν̂` , û` }L(k) are given by (62), ĥ and {ν̂` , û` }Lf →t
bd

bd

bd

bo

bd

bd

are given by (58), and kĥM(k+1) k∞ ≤ 1 − γ by definition.
bo

The second scenario applies to Cases 1a, 1b, 2a and 2b. Let Ñbo be the set of nodes in the outer
f →t
boundary shared by the new line Bbo
and those of the lines that have been added. Then, we have
(k+1)
(k)
(k+1)
(k)
(k+1)
(k)
(k)
f →t
→t
f →t
→t
Mbo
= Mbo ∪ MbdX , Mbi
= Mbi ∪ Mfbd×
, Xbd
= Xbd ∪ Xbd
, where Mbo ∩ MfbdX
→t
f →t
is the set of voltage magnitude measurements of nodes in Ñbo , Mbi ∩ Mfbd×
= ∅, and Xbd ∩ Xbd
(k)

(k)

>

is the set of voltage magnitude variables of nodes in Ñbo . For any given ĥM(k) and ξ̂ with kξ̂k∞ ≤ 1,
bi

>

we can always find ĥM(k) , ĥ , {ν̂` , û` }L(k) and {ν̂` , û` }Lf →t , where ĥM(k) and {ν̂` , û` }L(k) are given by
bo

bd

bd

bo

bd

(62), and ĥM(k) and {ν̂` , û` }Lf →t are given by (58). Let ĥM(k) be further divided into the parts correbd
bo
bo
h
i
sponding to the voltage magnitude measurements (if available) of nodes in Ñbo , namely ĥM(k)
and
bo Ñbo
h
h i
i
h i
the rest, namely ĥM(k)
and the rest, namely ĥ c .
; similarly, ĥ be further divided into ĥ
Ñbo
Ñbo
bo Ñ c
bo
#>
"


> h i>
i
h i
h
h
i>
1
. Similarly,
Then, we set ĥM(k+1) =
+ ĥ
ĥ
◦ ĥ (k)
ĥ (k)
bo

Mbo

c
Ñbo

Mbo

deg(Ñbo )

Ñbo

c
Ñbo

Ñbo

we can perform the transformation for {ν̂` , û` }L(k+1) . Hence, we can satisfy (62) for any given ĥM(k+1) =
bd
bi
h
i
>
> >
with kξ̂k∞ ≤ 1 (note that the voltage magnitude measurement in the calculation of line
ĥM(k) ξ̂
bi
vulnerability metric is normalized by 1, but it is weighted by the degree of connections of each node the
actual estimation algorithm, c.f., Def. 2). Moreover, by construction, we have kĥM(k+1) k∞ ≤ 1 − γ for all
bo

k. This completes the induction proof.

Proposition 18 (SOC constraint can improve line vulnerability). For any x ∈ K, it holds that
SOCP
αi→j
(x) ≤ αi→j

Proof. For any given ξ, let ĥ be the optimal solution of the inner minimizer in (35) with kĥk∞ ≤ αi→j .
SOCP = α
Then, the tuple (αi→j
i→j , ω = 0, h = ĥ) is a feasible solution for (58), which proves that we always
SOCP
have αi→j (x) ≤ αi→j .
The above proposition implies a key advantage of incorporating SOCP constraints—to improve robustness. This has also been empirically validated in our study as shown in the main text.
Theorem 19. Consider the measurements y = Ax\ + b\ , where supp(b\ ) ⊆ Mat , and also a partitioning
of the network as Bat , Bbi , Bbo , and Bsf . Let Kbd and Kat be the subsets of SOCP constraints K restricted
to variables xbd and xat , respectively, and let
(


xmg
xre
+ jxim
i
`
`
K̃at (x̂bd ) = xat
 0,
im
xre
xmg
j
` − jx`
)
mg
∀` := (i, j) ∈ Lat ∪ Lat∩bi , where xmg
i = x̂i

∀i ∈ Bbi ,

be the confined feasible set for xat , which fixes the boundary variables x̂bd in the SOCP constraints. Suppose that the following conditions hold:
34

• (Full column rank for the safe and boundary region) AMsf ∪Mbd ,Xsf ∪Xbd and
i
h
(|Mbd |)>
QMbd ,Xbd = AMbd ,Xbd I M
bi
have full column rank.
• (Localized mutual incoherence) for all lines {i, j} ∈ Lat∩bi that bridge the attacked region and the
SOCP ≤ 1 − γ for some γ > 0.
inner boundary, where i ∈ Bat , j ∈ Bbi , we have αi→j
• (Nonbinding SOCP constraints in the boundary) the solution for the attacked states satisfies x̂at ∈
K̃at (x\bd ).
Then, the solution to (S(1) : `1 -K), denoted as (x̂, b̂), uniquely recovers the true state outside the attacked
region (i.e., x̂sf = x\sf and x̂bd = x\bd ). Furthermore, the state estimation by (S(2) : `2 ) recovers the true
state for the unaffected region (i.e., v̂k = vk for k ∈ Bsf ∪ Bbd ).
Proof. To prove the claim, we simply need to show that for an arbitrary b? with its support limited to the
inner boundary supp(b? ) ⊆ Mbi , the solution x̂bd ∈ Xbd to the program
min

xbd ∈Kbd ,b

kbk1 ,

subject to AMbd ,Xbd xbd + b = z Mbd

(63)

is unique and satisfies x̂bd = x\bd , where z Mbd = AMbd ,Xbd x\bd + b? . To show this, we obtain the dual
program:
min

hMbd ,{ν` ,µ` }`∈Lbd

subject to

h>
Mbd z Mbd

(64a)
X

A>
Mbd ,Xbd hMbd +

(ν` c` + D >
` µ` ) = 0

(64b)

`∈Lat∩bi ∪Lbd

khMbd k∞ ≤ 1

(64c)

ν` ≥ kµ` k2 , ∀` ∈ Lbd ,

(64d)

Our goal is to find a dual certificate h?Mbd and {λ?` , µ?` }Lbd that satisfies the KKT conditions:
(dual feasibility)
(stationarity)

λ?` ≥ kµ?` k2 ,

∀` ∈ Lbd
X
A>
Mbd ,Xbd h?Mbd +

(65)
(λ?` c` + D >
` µ?` ) = 0,

(66)

`∈Lat∩bi ∪Lbd

h?Mbd ∈ ∂kb? k1
(complementary slackness)

λ?` c>
` x?

+

µ>
?` D ` x?

(67)
= 0,

∀` ∈ Lbd .

(68)

h
i>
>
>
x
x̂
. By the limited support assumption, we need to find a vector h? such
where x? = x>
at
\sf
\bd
that h?Mbi = sign(b?Mbi ) and kh?Mbo k∞ ≤ 1. By the vulnerability index condition and Lemma 17,
we can always find h?Mbo and {λ?` , µ?` }Lbd that satisfy the KKT conditions for a given h?Mbi , such
that kh?Mbo k ≤ 1 − γ < 1. Thus, this certifies the optimality of (x\bd , b? ) for (42). Clearly, under the
nonbinding SOCP constraints assumption, (x\bd , b? ) is feasible. Following the uniqueness argument of
Theorem 12, we conclude the proof.

35

We can extend the analysis to the case where the measurements have both sparse bad data and dense
noise. In this case, we need to solve a second-order cone program that combines quadratic loss with absolute
value loss, in addition to the SOCP constraints.
Theorem 20 (Robust SE with (S(1) : `2 `1 -K)). Given the measurements y = Ax\ + w\ + b\ , where w\
has independent entries with zero mean and subgaussian parameter σ and supp(b\ ) ⊆ Mat , consider a
partitioning of the network as Bat , Bbi , Bbo , and Bsf . Let Kbd and Kat be the subsets of SOCP constraints
K restricted to the variables xbd and xat , respectively, and let
(


xmg
xre
+ jxim
i
`
`
K̃at (x̂bd ) = xat
 0,
im
xre
xmg
j
` − jx`
)
mg
∀` := (i, j) ∈ Lat ∪ Lat∩bi , where xmg
i = x̂i

∀i ∈ Bbi ,

be the confined feasible set for xat , which fixes the boundary variables x̂bd in the SOCP constraints. Suppose that the rows of A are normalized (c.f., Def. 2), and the regularization parameter λ is chosen such
that
2 p 2
λ>
2σ log nm .
(69)
nm γ
In addition, suppose the following conditions hold:
• (Full column rank for the safe and boundary region) both AMsf ∪Mbd ,Xsf ∪Xbd and
h
i
(|Mbd |)>
QMbd ,Xbd = AMbd ,Xbd I M
bi
have full column rank.
• (Localized mutual incoherence) for all lines {i, j} ∈ Lat∩bi that bridge the attacked region and the
SOCP ≤ 1 − γ for some γ > 0.
inner boundary, where i ∈ Bat , j ∈ Bbi , we have αi→j
• (Nonbinding SOCP constraints in the boundary) the solution for the attacked states satisfies x̂at ∈
K̃at (x\bd ).
Then, the following properties hold for the solution to (S(1) : `2 `1 ), denoted as (x̂, b̂):
1. (No false inclusion) The solution (x̂, b̂) has no false bad data inclusion (i.e., supp(b̂) ⊂ supp(b\ ))
0
with probability greater than 1 − ncm
, for some constant c0 > 0.


AMsf ,Xsf AMsf ,Xbd


0
AMbo ,Xbd  and Q◦Mbi = A◦ I ◦>
2. (Large bad data detection) Let A◦ := 
Mbi , and
0
AMbi ,Xbd


1
◦>
◦
−1 ◦>
√
g(λ) = nm λ
+ kI b (QMbi QMbi ) QMbi k∞
2 Cmin
be a threshold value, and let b̃Mbi = AMbi ,Xat (x\at − x̂at ) be the error at the boundary. Then, all
bad data with magnitude greater than g(λ) will be detected (i.e., if |b̃i | > g(λ), then |b̂i | > 0) with
probability greater than 1 − cm2 .
36

3. (Bounded error) The estimator error is bounded by
p
|Xsf | + |Xbd | + |Mbi |
◦
−1 ◦>
+ nm λkI x (Q◦>
kx\Xsf ∪Xbd − x̂Xsf ∪Xbd k2 ≤ t
Mbi QMbi ) QMbi k∞,2
Cmin


2
with probability greater than 1 − exp − cσ1 t4 .

C.3

Scalable methods to calculate the vulnerability index

The minimax program (35) consists of a linear programming in the inner minimization and a discrete optimization in the outer maximization. For small-scale systems, the number of feasible points in the outer
maximization is not too large. This is the case when we consider the vulnerability on a line-by-line basis.
But for large-scale problems when we consider a group of attacked lines, it is essential to develop more
scalable numerical algorithms. We first show the following result.
Lemma 21. The line vulnerability index αi→j coincides with the optimal value of the following minimax
program:
α̃i→j =

max

ξ̃∈[−1,+1]

i→j
n×

subject to

α̃

min
n

α̃∈R,h̃∈R

(70a)

i→j
X

A>
h̃ + A>
ξ̃ = 0
Mi→j ,X i→j
Mi→j ,X i→j

(70b)

kh̃k∞ ≤ α̃,

(70c)

bdX

bd

bd×

bd

with the same notations as in Def. 9. Note that the difference in (70) is that the minimizer is over the
i→j
i→j
hypercube [−1, +1]n× rather than the simplex {−1, +1}n× .
Proof. Since the feasible region of the outside maximizer in (70) is a superset of that in (35), we always
i→j
have α̃i→j ≥ αi→j . To show the other direction, we simply need to show that for any ξ̃ ∈ [−1, +1]n× ,
we can always find a feasible solution for the minimizer h̃ such that kh̃k∞ ≤ αi→j . Since ξ̃ belongs to
a hypercube, which is convex, there always exists a set of non-negative coefficients βk such that βk ≥ 0,
P
P
ni→j
×
k βk = 1 and ξ̃ =
k βk ξ k , where ξ k ∈ {−1, +1} P . Since for each ξ k , there exists hk such that it is
feasible in (35) and khk k∞ ≤ αi→j , by choosing h̃ = k βk hk , we have:
X
X
kh̃k∞ ≤
βk khk k∞ ≤
βk αi→j = αi→j ,
k

k

which completes the proof.
We can thereby reformulate the problem as a linear complimentarity problem as follows. The KKT
conditions for the inner minimization of (70) are:
• (Primal feasibility) A>
h+A>
ξ = 0, q + = α1−h, q − = α1+h, q + ≥ 0, q − ≥
Mi→j ,X i→j
Mi→j ,X i→j
bdX

bd

bd×

bd

0;
• (Dual feasibility) µ+ ≥ 0, µ− ≥ 0;

37

• (Stationarity) The Lagrangian function
>
L(α, h, µ+ , µ− , λ) = α + λ> (A>
h + A>
ξ) + µ>
+ (h − α1) + µ− (−h − α1)
Mi→j ,X i→j
Mi→j ,X i→j
bdX

bd

bd×

bd

and stationarity conditions:
∂L
>
= 1 − µ>
+ 1 − µ− 1 = 0
∂α
∂L
= AMi→j ,X i→j λ + µ+ − µ− = 0
bdX bd
∂h
• (complementary slackness) µ+ ◦ q + = 0, µ− ◦ q − = 0
Thus, we can write (70) as a linear complementarity problem:
α̃i→j =

α

(71a)

−1≤ξ ≤1

(71b)

max

i→j
n×

ξ∈R

,α∈R,h∈R

subject to

i→j
n
X

ξ=0
h + A>
A>
Mi→j ,X i→j
Mi→j ,X i→j

(71c)

q + = α1 − h

(71d)

q − = α1 + h

(71e)

>
1 − µ>
+ 1 − µ− 1 = 0

(71f)

AMi→j ,X i→j λ + µ+ − µ− = 0

(71g)

µ+ ◦ q + = µ− ◦ q − = 0

(71h)

q + , q − , µ+ , µ− ≥ 0

(71i)

bdX

bdX

,

bd

bd×

bd

bd

This problem can be solved readily using off-the-shelf solvers such as PATH Solver [8] or YALMIP
[15]. We can also use the big-M method to replace the complimentarity condition using a mixed-integer
formulation, and solve the problem using standard packages such as Gurobi. In our experiments, we only
focus on each line, so the improvement of computation is not significant. The advantage becomes more
obvious when we scale the computation to multiple lines.

C.4

Extension to tree decomposition

So far, we have been focusing on evaluating line vulnerabilities. In this section, we introduce a powerful
extension of the vulnerability index to tree decomposition of a graph. This allows us to study the effect of
sparsity on network robustness. We use N (G) to represent the vertices of graph G, and L(i; G) = {j ∈ N |
{i, j} ∈ L} to represent the set of nodes in G that are connected to node i. First, we introduce the standard
definition of tree decomposition and treewidth.
Definition 22 (Tree decomposition and treewidth). A tree decomposition of a graph G := {N , L} is (T , W),
where T is a tree and W := {Wt | t ∈ N (T )} is the set of “bags” Wt which satisfies the following
properties
1. (Node coverage) ∪t∈N (T ) Wt = N (G), i.e., the union of the vertices of T , referred to as “bags,” is
the set of nodes of G;
38

2. (Edge coverage) For any (i, j) ∈ L, there exists t ∈ N (T ) such that i, j ∈ Wt , i.e., each edge of G is
in at least one of the “bags” of T ;
3. (Running intersection property) The subtree of T consisting of all “bags” containing u ∈ N is
connected.
Furthermore, the width of a tree decomposition is max(|Wt | − 1 : t ∈ N (T )). The treewidth of G is the
minimum width of a tree decomposition of G.
Clearly, a graph may have several different tree decompositions. The analysis below does not require
any particular tree decompositions. However, the easiest tree decomposition is to lump all vertices into one
bag, which does not reveal any robustness properties of the graph. In general, the smaller the width of the
decomposition, the easier it is to certify robustness.
Definition 23 (Infected bags, link bags, safe bags). For a given set of attacked nodes Nat and a tree decomposition (T , W), any bag that contains attacked nodes is referred to as an infected bag Wtif ∈ W if =
{Wt | Wt ∩ Nat 6= ∅}. Furthermore, the set of lines induced by the union of infected bags is denoted
as Lif . The bags that are immediately connected to an infected bag are called link bags Wtlk ∈ W lk =
{Wt | Wt ∩ Nat = ∅, ∃ Wtif0 , Wt ∈ L(Wtif0 ; T )}, and the set of lines induced by the union of link bags
is shown as Llk . The rest of the bags are safe bags Wtsf , and the set of lines induced by the union of safe
bags is represented by Lsf . Nodes shared between a link bag Wtlk and an infected bag Wtif are called adhesion nodes Nad (Wtlk , Wtif ) = Wtlk ∩ Wtif ⊆ Nad , and the rest of the nodes in Wtlk are outer link nodes
Nol (Wtlk , Wtif ) = Wtlk \ Wtif ⊆ Nol . We denote the edges that connect adhesion nodes in Wtlk with infected
nodes by Lad (Wtlk ) ⊆ Lad .
Definition 24 (Attacked, boundary and safe variables and measurements for tree decomposition). The set
of “infected variables” Xif includes all variables on lines induced by W if and on nodes in W if except for
adhesion nodes Nad . The set of “link variables” Xlk includes variables on nodes in W lk and the induced
lines. The set of “safe variables” Xsf includes all other variables. The set of “infected measurements” Mif
includes measurements on lines induced by nodes in W if and on nodes in W if except for voltage magnitude
measurements on Nad . The set of “adhesion measurements” Mad includes nodal power injections on nodes
in Nad and line measurements on Lad , and the set of “outer link measurements” Mol includes voltage magnitude on nodes in W lk and line measurements induced by nodes in W lk . Together, they form the “boundary
measurements” Mbd := Mad ∪ Mol . The rest of the measurements Msf are “safe measurements.”
Next, we introduce some useful properties associated with the above definitions. If T 0 is a subtree of
T , we use GT 0 to denote the subgraph of G induced by the nodes in all the bags associated with T 0 , namely
∪t∈T 0 Wt .
Lemma 25. The following properties are satisfied:
(i) There are no shared nodes between the safe bags and the infected bags.
(ii) There are no shared nodes between the set of outer link nodes and the infected bags.
(iii) Suppose that the infected bags form a subtree of T . Then, there are no shared outer link nodes between
any link bags.

39

(iv) Suppose that the infected bags form a subtree of T . Consider any link bag Wtlk that is adjacent to
only one infected bag Wtif0 connected by an edge L(Wtlk , Wtif0 ). If we delete the edge, the tree falls
apart into two connected components, T1 and T2 . Deleting the adhesion nodes Wtlk ∩ Wtif0 from N
disconnects G into the two subgraphs GT1 − (Wtlk ∩ Wtif0 ) and GT2 − (Wtlk ∩ Wtif0 ). Furthermore,
all the infected nodes are contained in only one of the subgraph, and there is no edge across the two
subgraphs.
Proof. (i): For any safe bag Wtsf and affected bag Wtif , if there exists a node i that is shared between them,
it contradicts the definition of a safe bag.
(ii): For any link bag Wtlk and affected bag Wtif , if there exists a node i that is shared between Wtif and
the outer link nodes in Wtlk , then by the running intersection property, it must also appear in the infected
bag connected to Wtlk . This is contradictory, because it makes i an adhesion node.
(iii): For any two link bags Wtlk and Wtlk0 , suppose that they share an outer link node i. By the running
intersection property, there must exist a path of bags between Wtlk and Wtlk0 . Since this path cannot go
through the infected bags, it must be outside the infected region. Since the infected bags form a subtree, this
would create a loop within T , which is impossible. Therefore, there cannot be any shared outer link nodes
between any two link bags.
(iv) Assume that there is a node i that belongs to both GT1 − (Wtlk ∩ Wtif0 ) and GT2 − (Wtlk ∩ Wtif0 ).
Therefore, by the node coverage property, there must exist Wx with x ∈ T1 and Wy with y ∈ T2 such that
i ∈ Wx and i ∈ Wy . Since Wtlk and Wtif0 lie on a x − y path in T , by the running intersection property,
i ∈ Wtlk ∩ Wtif0 . Hence, i belongs to neither GT1 − (Wtlk ∩ Wtif0 ) nor GT2 − (Wtlk ∩ Wtif0 ).
Now, assume that there is an edge (i, j) in G such that i ∈ GT1 −(Wtlk ∩Wtif0 ) and j ∈ GT2 −(Wtlk ∩Wtif0 ).
Then, by the edge coverage property, there must be a bag Wx containing both i and j. However, x cannot
be in both T1 and T2 , otherwise, i and j will belong to Wtlk ∩ Wtif0 . Assume that x 6∈ T2 . Since j is in
GT2 − (Wtlk ∩ Wtif0 ), it must be in a bag y ∈ T2 different than x. Since j belongs to both Wx and Wy ,
it lies on a x − y path in T . By the running intersection property, we have j ∈ Wtlk ∩ Wtif0 , which is a
contradiction.
If the infected bags form a subtree and we can find a link bag that is adjacent to only one infected bag,
then by property (iv) in Lemma 25, if we remove the adhesion nodes, we can separate the infected region
with the rest of the safe region.
Now, we can define a generalized version of vulnerability index using tree decomposition.
Definition 26 (Bag vulnerability index). For each adhesion link L(Wtlk , Wtif ), define the measurement and
variable partitions according to Def. 24. The bag vulnerability index αW if →W lk is given by the optimal
t
t
value of the following minimax program:
αW if →W lk =
t

t

max

ξ∈{−1,+1}|Mad |

min

α

α∈R,h∈R|Mol |

subject to

>
A>
Mol ,Xlk h + AMad ,Xlk ξ = 0

(72b)

khk∞ ≤ α,

(72c)

where Mol , Mad and Xlk are the boundary measurement and variable indices introduced in Def. 24.
Similarly, we can extend the definition to incorporate SOCs.

40

(72a)

Definition 27 (Bag vulnerability index for SOCP). For each adhesion link L(Wtlk , Wtif ), define the meaSOCP
surement and variable partitions according to Def. 24. The bag vulnerability index αW
if
lk for a given
t →Wt
x ∈ K that satisfies primal feasibility is given by the optimal value of the following minimax program:
SOCP
αW
if →W lk =
t

t

min
α

max

ξ∈{−1,+1}|Mad |

(73a)

α∈R,h∈R|Mol |

X

>
subject to A>
Mol ,Xlk h + AMad ,Xlk ξ +

ω` T ` x = 0

(73b)

`∈L(Wtlk )

∀` ∈ L(Wtlk )

ω` ≥ 0,
khk∞ ≤ α,

(73c)
(73d)

where Mol , Mad and Xlk are the boundary measurement and variable indices introduced in Def. 24,
>
L(Wtlk ) is the set of lines induced by nodes in Wtlk . Also, we define T ` = c` c>
` − D ` D ` , where c` and D `
are defined in (7).
With the above definition of bag vulnerability index, we can show the following key results for SE
robustness.
Lemma 28 (Local property implies global property in tree decomposition). Consider a tree decomposition
T and the associated set partitioning (c.f., Def. 24). Suppose that the infected bags form a subtree of T , and
that there exists a link bag Wtlk that is adjacent to only one infected bag Wtif . For simplicity of presentation,

AMsf ,Xsf AMsf ,Xlk
0
AMol ,Xlk  be a
we also treat the rest of the bags in the subtree as infected. Let A◦ = 
0
AMad ,Xlk
submatrix of the sensing matrix. If αW if →W lk ≤ 1 − γ for some γ > 0, then for any ĥMad ∈ [−1, 1]|Mad | ,
t

t

there exists an ĥMsf ∪Mol such that kĥMsf ∪Mol k∞ ≤ 1 − γ and
◦>
A◦>
Msf ∪Mol ĥMsf ∪Mol + AMad ĥMad = 0.

(74)

Proof. The proof is similar to Lemma 11. First, we show that a sufficient condition for the existence of
h
i>
>
>
ĥMsf ∪Mol = ĥM
ĥMol such that kĥMsf ∪Mol k∞ ≤ 1 − γ and (74) is satisfied is that for any ĥMad ,
sf
there exists a vector ĥMol such that kĥMol k∞ ≤ 1 − γ and
>
A>
Mol ,Xlk ĥMol + AMad ,Xlk ĥMad = 0.

(75)

h
i>
>
This is immediate by simply choosing ĥMsf ∪Mol = 0> ĥM
. Since it is guaranteed that there exists
ol
a vector ĥMol to satisfy (75) under the condition that αW if →W lk ≤ 1 − γ, the claim is proved.
t

t

Lemma 29 (Local property implies global property for SOCP with tree decomposition). Consider a tree decomposition T and the associated set partitioning (c.f., Def. 24). Suppose that the infected bags form a subif
tree of T , and that there exists a link bag Wtlk that is adjacent to only one infected bag
 Wt . For simplicity of

AMsf ,Xsf AMsf ,Xlk
0
AMol ,Xlk 
presentation, we also treat the rest of the bags in the subtree as infected. Let A◦ = 
0
AMad ,Xlk
be a submatrix of the sensing matrix, and c◦` and D ◦` be the subvector and submatrix of c` and D ` indexed
41

SOCP
|Mad | , there exist ĥ
by Xsf ∪Xlk . If αW
Msf ∪Mol
if →W lk ≤ 1−γ for some γ > 0, then for any ĥMad ∈ [−1, 1]
t

t

and {ν̂` , û` }`∈Lad (W lk )∪L(W lk )∪Lsf such that kĥMsf ∪Mol k∞ ≤ 1 − γ and
t
t
X
◦>
ν̂` c◦` + D ◦>
+
+
A
ĥ
A◦>
ĥ
M
M
∪M
Mad
Msf ∪Mol
` û` = 0.
ad
sf
ol

(76)

`∈Lad (Wtlk )∪L(Wtlk )∪Lsf

Proof. The proof is similar to the one for Lemma 17. First, we show that a sufficient condition for Lemma
29 is that for any ĥMad , there exists a vector ĥMol and {ν̂` , û` }`∈L(W lk ) such that kĥMol k∞ ≤ 1 − γ and
t
h
i
X
>
>
û
= 0.
(77)
+
ν̂
c
+
D
+
A
ĥ
A>
ĥ
M
M
`
`
`
Mad ,Xlk
Mol ,Xlk
`
ad
ol
`∈Lad (Wtlk )∪L(Wtlk )

Xlk

h
i>
>
and ν̂` = 0 and û` = 0 for ` ∈ Lsf .
This is immediate by simply choosing ĥMsf ∪Mol = 0> ĥM
ol
Since it is guaranteed that there exist ĥMol and {ν̂` , û` }`∈L(W lk ) to satisfy (77) under the condition that
t
SOCP
αW
if →W lk ≤ 1 − γ, the claim is proved.
t

t

Theorem 30 (Robust SE with (S(1) : `2 `1 ) for tree decomposition). Consider a tree decomposition T and
the associated set partitioning (c.f., Def. 24). Suppose that the infected bags form a subtree of T , and
that there exists a link bag Wtlk that is adjacent to only one infected bag Wtif . Given the measurements
y = Ax\ + w\ + b\ , where w\ has independent entries with zero mean and subgaussian parameter σ and
supp(b\ ) ⊆ Mif , suppose that the rows of A are normalized (c.f., Def. 2) and the regularization parameter
λ is chosen such that
2 p 2
λ>
2σ log nm .
(78)
nm γ
In addition, assume that the following conditions hold:
• (Full column rank for the safe and boundary region) AMsf ∪Mlk ,Xsf ∪Xlk and
h
i
(|Mlk |)>
QMlk ,Xlk = AMlk ,Xlk I M
ad
have full column rank.
• (Localized mutual incoherence for bags) for the link bag Wtlk that is adjacent to only one infected bag
Wtif , we have αW if →W lk ≤ 1 − γ for some γ > 0.
t

t

Then, the following properties hold for the solution to (S(1) : `2 `1 ), denoted as (x̂, b̂):
1. (No false inclusion) The solution (x̂, b̂) has no false bad data inclusion (i.e., supp(b̂) ⊂ supp(b\ ))
0
with probability greater than 1 − ncm
, for some constant c0 > 0.


AMsf ,Xsf AMsf ,Xlk


0
AMol ,Xlk  and Q◦Mad = A◦ I ◦>
2. (Large bad data detection) Let A◦ := 
Mad , and
0
AMad ,Xlk


1
◦>
◦
−1 >
√
g(λ) = nm λ
+ kI b (QMad QMad ) I b k∞
2 Cmin
be a threshold value, and let b̃Mad = AMad ,Xif (x\if − x̂if ) be the error at the boundary. Then, all
bad data with magnitude greater than g(λ) will be detected (i.e., if |b̃i | > g(λ), then |b̂i | > 0) with
probability greater than 1 − cm2 .
42

3. (Bounded error) The estimator error is bounded by
p
|Xsf | + |Xlk | + |Mad |
◦
−1 >
+ nm λkI x (Q◦>
kx\Xsf ∪Xlk − x̂Xsf ∪Xlk k2 ≤ t
Mad QMad ) I b k∞,2
Cmin


2
with probability greater than 1 − exp − cσ1 t4 .
Theorem 31 (SE robustness with (S(1) : `2 `1 -K) for tree decomposition). Given a tree decomposition T
and the associated set partitioning (c.f., Def. 24), suppose that the infected bags form a subtree of T and
that there exists a link bag Wtlk that is adjacent to only one infected bag Wtif . Consider the measurements
y = Ax\ + w\ + b\ , where w\ has independent entries with zero mean and subgaussian parameter σ and
supp(b\ ) ⊆ Mif . Let Klk and Kif be the subsets of SOCP constraints K restricted to the variables xlk and
xif , respectively, and let
(


xmg
xre
+ jxim
i
`
`
K̃if (x̂lk ) = xif
 0,
im
xre
xmg
j
` − jx`
)
mg
∀` = (i, j) ∈ Lif ∪ Lad (Wtlk ), where xmg
i = x̂i

∀i ∈ Nad (Wtlk , Wtif ) ,

be the confined feasible set for xif , which fixes the boundary variables x̂lk in the SOCP constraints. Suppose
that rows of A are normalized (c.f., Def. 2), and the regularization parameter λ is chosen such that
2 p 2
λ>
2σ log nm .
(79)
nm γ
In addition, suppose that the following conditions hold:
• (Full column rank for the safe and boundary region) AMsf ∪Mlk ,Xsf ∪Xlk and
h
i
(|Mlk |)>
QMlk ,Xlk = AMlk ,Xlk I M
ad
have full column rank.
• (Localized mutual incoherence for bags) for the link bag Wtlk that is adjacent to only one infected bag
SOCP
Wtif , we have αW
if →W lk ≤ 1 − γ for some γ > 0.
t

t

• (Nonbinding SOCP constraints in the boundary) the solution for the attacked states satisfies x̂if ∈
K̃if (x\lk ).
Then, the following properties hold for the solution to (S(1) : `2 `1 ), denoted as (x̂, b̂):
1. (No false inclusion) The solution (x̂, b̂) has no false bad data inclusion (i.e., supp(b̂) ⊂ supp(b\ ))
0
with probability greater than 1 − ncm
, for some constant c0 > 0.


AMsf ,Xsf AMsf ,Xlk


0
AMol ,Xlk  and Q◦Mad = A◦ I ◦>
2. (Large bad data detection) Let A◦ := 
Mad , and
0
AMad ,Xlk


1
◦>
◦
−1 ◦>
√
g(λ) = nm λ
+ kI b (QMad QMad ) QMad k∞
2 Cmin
43

be a threshold value, and let b̃Mad = AMad ,Xif (x\if − x̂if ) be the error at the boundary. Then, all
bad data with magnitude greater than g(λ) will be detected (i.e., if |b̃i | > g(λ), then |b̂i | > 0) with
probability greater than 1 − cm2 .
3. (Bounded error) The estimator error is bounded by
p
|Xsf | + |Xlk | + |Mad |
◦
−1 ◦>
+ nm λkI x (Q◦>
kx\Xsf ∪Xlk − x̂Xsf ∪Xlk k2 ≤ t
Mad QMad ) QMad k∞,2
Cmin


2
with probability greater than 1 − exp − cσ1 t4 .
The proofs of Theorems 30 and 31 are similar to those of Theorems 13 and 20 in Section E and are
omitted for brevity. As shown in our analysis, tree decomposition provides an efficient way to define the
boundary between infected and safe nodes. Tree decomposition has been employed in semidefinite programming (SDP) to efficiently deal with network with chordal sparsity [23]. The smaller the treewidth, the
faster it is to solve SDP [30]. Our analysis shows that with smaller treewidth, it is generally easier to certify
robustness for SE. This is mainly due to the fact that the adhesion set is bounded by the treewidth, which
limits the number of nodes that an infected bag can influence.

D

Experimental details

Noisy measurements: For each simulation, we randomly generate dense noise w and sparse bad data b, and
add them to the clean data according to (5). The dense noise for each measurement is zero-mean Gaussian
variable, with standard deviation of 1e-5 (per unit) for voltage magnitude measurements and 0.005 (per unit)
for all the other measurements. The difference in standard deviation is due to the fact that voltage magnitude
sensors have higher standards of accuracy compared to power meters. For the sparse bad data, its support
is randomly selected among the line measurements. We randomly select a set of lines, whose branch flow
measurements are all compromised accordingly. The values for the sparse noise can be arbitrarily large, and
we assume these parameters are uniformly chosen from the set [−4.25, −3.75] ∪ [3.75, 4.25] (per unit).
Performance metrics: We
the root-mean-square error (RMSE) as the metric for estimation acq use
1 P
2
curacy, which is defined as
i∈N |vi − v̂i | , where vi and v̂i are the true and estimated complex
nb
voltage at bus i ∈ N . To evaluate the bad data detection accuracy, we use the F1 score, which is defined as
#True positives |J ∩Jˆ|
#True positives |J ∩Jˆ|
2∗precision×recall
precision+recall , where precision is given by #Conditional positives |Jˆ| , and recall is given by #Conditional positives |J | ,
and J and Jˆ denote the true and estimated supports of bad data (# indicates the number of elements). The
F1 score is the harmonic average of the precision and recall, which reaches its best value at 1 (perfect
precision and recall) and worst at 0.
Experimental setup: We evaluate the proposed method (step-1 estimators include (S(1) : `1 ), (S(1) : `2 `1 ),
(1)
(S : `1 -K) or (S(1) : `2 `1 -K)) combined with step-2 recovery method (S(2) : `2 ) or (S(2) : `2 `1 )), and compare it with the current practice of nonlinear least square (NLS) method based on Newton’s algorithm. We
use SeDuMi [20] as the optimization solver and the MATPOWER implementation of NLS. Throughout the
experiment, we choose λ in (S(1) : `2 `1 ) to be 3 × 10−4 /nm , λ2 in (S(1) : `2 `1 -K) to be 0.1, and a bad data
detection threshold of 0.01 for stage-1 estimators. After the removal of bad data (i.e., cleaning step), we
perform the estimation with the remaining data. All the experiments are performed on a standard laptop
with 3.3GHz Intel Core i7 and 16GB memory.
44

Convergence issue of Newton’s method: We performed a simple experiment, where there is no noise
in the measurements, and we use both Newton’s method and our proposed method to estimate the state for
the IEEE 300-bus system [29]. Since Newton’s method depends on the initial point, we randomly generate
an initial point, where we add a complex vector on top of the ground truth. The magnitude of each entry is
uniformly chosen from [1 − τ, 1 + τ ], and angle (in degrees) uniformly chosen from [−100 × τ, 100 × τ ].
We increase τ to enlarge the initialization distance. As shown in Figure 12, as we increase τ , Newton’s
method becomes less and less reliable. This can be due to several factors, for example, if the initial point is
0.2
far from the ground truth, the algorithm can become stuck at a local optimal. On the contrary, our proposed
method based on (S(1) : `2 `1 ) does not depend on the
initial point and can recover the ground truth for all the
0.18
experiments.
0.16

0.2

RMSE

data1
Newton’s method
data2
data3
Proposed method

0.14

0.15
0.1

0.12

0.05
0.1

0
0

0.05

0.1

Initialization distance
0.08

0.15

0.06

Figure 12: Plots of RMSE against initilization distance τ for Newton’s method. The RMSE is averaged
0.04
over 20 simulations. For the Newton’s method, we
show both the mean performance (circled line) and the
min/max range (black shades).
0.02
Simulations on measurement redundancy: In0 the main paper, we demonstrated the performance of
0
0.05
(S(1) : `2 `1 -K) for different sensor measurement profiles.
We have tested three different
methods to add additional sensors: the first method (Method 1) starts from a spanning tree of the network and incrementally
adds a set of lines to the tree. In this method, each bus is equipped with only voltage magnitude measurements, and each line has 3 out of 4 branch flow measurements. The second method (Method 2) starts with
the full network, where each node has voltage magnitude measurements and each line has one real and one
reactive power measurements, and it grows the set of sensors by randomly adding branch measurements.
The third method (Method 3) differs from Method 2 only in that it grows the set of sensors by randomly
adding branch measurements as well as nodal power injections. In Figure 13, we compared the performance
of (S(1) : `2 `1 ) with (S(1) : `2 `1 -K) in terms of both estimation accuracy and bad data detection rates. It can
be seen that (S(1) : `2 `1 -K) consistently outperforms (S(1) : `2 `1 ) at different redundancy rates. We can also
observe that Method 1 is more efficient in terms of improvement of performance with additional sensors.
Visualization of vulnerability maps for different measurement profiles: In Figure 9 from the main
text, we show statistics regarding vulnerability index and critical index for different measurement profiles.
Figures 14 and 15 show the geographical distributions of VI and CI, respectively. It can be seen that
(S(1) : `2 `1 -K) is consistently more robust in terms of VI and CI than (S(1) : `2 `1 ). This is also theoretically proven in Proposition 18. We also see that the more vulnerable lines exist, the higher the bus critical
index tends to be. By comparing Figure (B, G) with Figure (C, H), we see that the inclusion of nodal power
injections is likely to cause vulnerable lines. By including more branch flow measurements, as shown in
Figure (A, C, D) and Figure (F, H, I), or more voltage magnitude measurements, as shown in Figure (B, C,
E) or Figure (G, H, J), it is more likely to robustify the network.

45

0.1

1E-1

B
1.00

F1 score

1E-1

RMSE

RMSE

A
1E-2
1E-3

2

QP

1E-4

1.00

2

7
Redundancy

2.5

2

3

2.5

3

Redundancy

Redundancy

C

D
1.00

F1 score

1E-1

RMSE

SOCP

1E-3

0.99

1E-4

1E-2
1E-3

0.60

0.20

1E-4
2

3

4

2

5

3

4

5

Redundancy

Redundancy

E

F
1.00

F1 score

1E-1

RMSE

1E-2

1E-2
1E-3

0.60

0.20

1E-4
2

3

2

4

3

4

Redundancy

Redundancy

Figure 13: Performance of proposed algorithms with different rates of measurement redundancy. Plots for
different methods to add measurements: (A, B) Method 1, (C, D) Method 2, (E, F) Method 3. Results for
(S(1) : `2 `1 -K) (red) and (S(1) : `2 `1 ) (green) are shown, which are averaged over 20 independent simulations.

E
E.1

Proofs
Proof of Theorem 13

For an arbitrary set of attacked measurements Mat , their boundary Mbd := Mbi ∪ Mbo and unaffected
measurements Msf , as well as the associated variables xat , xbd and xsf , respectively, we design the primaldual witness (PDW) process as follows:
(1) Set b̂Msf = 0 and b̂Mbo = 0;

46

Figure 14: Vulnerability maps for different measurement profiles and optimization techniques. (A–E) and
(F–J) are series of maps without and with the SOCs, respectively. (A, F), (C, H) and (D, I) correspond
to PV or PQ nodal measurements together with 2, 3, and 4 branch power flows, respectively. (B, G) and
(E, J) correspond to only PQ or only voltage magnitude nodal measurements with 3 branch power flows,
respectively.

47

Figure 15: Bus critical index maps for different measurement profiles and optimization techniques. (A–E)
and (F–J) are series of maps without and with the SOCs, respectively. (A, F), (C, H) and (D, I) correspond
to PV or PQ nodal measurements together with 2, 3, and 4 branch power flows, respectively. (B, G) and
(E, J) correspond to only PQ or only voltage magnitude nodal measurements with 3 branch power flows,
respectively. Color indicates low (yellowish) to high (reddish) critical index. If the critical index is 0, which
occurs when attacking the bus does not affect any of its neighbors, the grey color is shown.

48



> >
>
(2) Determine x̂ = x̂>
sf x̂bd x̂at
program:
 

AMsf ,Xsf
y Msf



1 y Mbo  
0
min
−
0
b∈Rnm ,x∈Rnx 2nm  y Mbi  
0
y Mat
and ĥMbi ∈ ∂kb̂Mbi k1 and ĥMat

h
>
and b̂ = 0> 0> b̂M
bi

i>
>
b̂Mat

by solving the following

 2
0


 xsf  0 
 xbd −
 + λ bMbi
,
bM 
AMbi ,Xat 
bMat 1
bi
xat
AMat ,Xat
bMat 2
(80)
∈ ∂kb̂Mat k1 satisfying the optimality conditions
AMsf ,Xbd
AMbo ,Xbd
AMbi ,Xbd
0

0
0









1
(y
− AMat ,Xat x̂at − b̂Mat ) + λĥMat = 0,
nm Mat

− AMbi ,Xbd x̂bd − AMbi ,Xat x̂at − b̂Mbi + λĥMbi = 0.
−

−

1 
y Mbi
nm

(81a)
(81b)

(3) Solve (ĥMsf , ĥMbo ) via the zero-subgradient equation:

1 
−
y − Ax̂ − b̂ + λĥ = 0,
(82)
nm
h
i>


>
>
> >
> 0> b̂>
are solutions obtained in (80),
where x̂ = x̂>
and
b̂
=
x̂
x̂
0
b̂
Bsf
Bbd
Bat
Mbi
Mat
h
i>
>
>
>
>
and ĥ = ĥM
where (ĥMbi , ĥMat ) are given in (81). Check whether strict
ĥM
ĥM
ĥMat
sf

bo

bi

feasibility conditions kĥMsf k∞ < 1 and kĥMbo k∞ < 1 hold.
Lemma 32. If the PDW procedure succeeds, then (x̂, b̂) that is optimal for (80) is also optimal for (S(1) : `2 `1 ).
Furthermore, for any optimal solution (x̃, b̃), if x̂at = x̃at , we must have x̂sf = x̃sf and x̂bd = x̃bd (i.e.,
uniqueness property in the weak sense).
Proof. The KKT conditions of (S(1) : `2 `1 ) for a given primal-dual pair (x̂, b̂) and ĥ are given by:
A> (y − Ax̂ − b̂) = 0,

1 
y − Ax̂ − b̂ + λĥ = 0,
−
nm
kĥk∞ ≤ 1

(83a)
(83b)
(83c)

If PDW succeeds, then the optimality conditions (83) are satisfied,
D which
E certify the optimality of (x̂, b̂).
The subgradient ĥ satisfies kĥMsf k∞ < 1, kĥMbo k∞ < 1 and ĥ, b̂ = kb̂k1 . Now, let (x̃, b̃) be any
other optimal, and let F (x, b) =

1
2nm ky

− Ax − bk22 , then we have
D
E
F (x̂, b̂) + λ ĥ, b̂ = F (x̃, b̃) + λkb̃k1 ,

and hence,
E
D
E

D
F (x̂, b̂) + λ ĥ, b̂ − b̃ = F (x̃, b̃) + λ kb̃k1 − ĥ, b̃ .
By the optimality conditions in (83), we have λĥ = −∇b F (x̂, b̂) = n1m (y − Ax̂ − b̂), which implies that
D
E

D
E
F (x̂, b̂) − ∇b F (x̂, b̂), b̂ − b̃ − F (x̃, b̃) = λ kb̃k1 − ĥ, b̃ ≤ 0
49

E
D
E
ĥ, b̃ . Since by Holder’s inequality, we also have ĥ, b̃ ≤
D
E
≤ 1, it holds that kb̃k1 = ĥ, b̃ . Since by the success of PDW, kĥMsf k∞ < 1

due to convexity. Therefore, kb̃k1 ≤
kĥk∞ kb̃k1 , and kĥk∞

D

and kĥMbo k∞ < 1, we have b̃j = 0 for all j ∈ Msf ∪ Mbo . To show the weak uniqueness, let (x̃, b̃) be
another optimal solution, and assume that x̂at = x̃at . Then, by fixing xat in the optimization (80) as x̂at
and by the lower eigenvalue condition, the the function is strictly convex in xsf , xbd and bMbi .

Proof of Theorem 13
Proof. Part 1): By the construction of PDW, we have b̂Msf = b\Msf = 0 and b̂Mbo = b\Mbo = 0. In the
following, we allow the optimal solution x̂at and b̂Mat of (80) to take any value. Thus, for any given x̂at
and b̂Mat , we can fix xat and bMat in (80) and solve the following smaller program:

 



2

y Msf
AMsf ,Xsf AMsf ,Xbd 
0
1 
xsf





0
AMbo ,Xbd
y Mbo −
0
min
(84)
−
+ λ kbMbi k1 ,
xbd
bMbi ,xsf ,xbd 2nm
0
AMbi ,Xbd | {z
z Mbi
b
2
Mbi
}
| {z } |
{z
} x◦
z◦

A◦

where z Mbi = y Mbi −AMbi ,Xat x̂at = AMbi ,Xbd x\bd + b̃Mbi and b̃Mbi = AMbi ,Xat (x\at − x̂at ). Let I ◦ be
an identity matrix of size nm −|Mat |, and x◦ and w◦ be the subvectors of x and w indexed by Msf ∪Mbo ∪
Mbi , respectively. Thus, we have z ◦ = A◦ x◦\ + w◦\ + I ◦>
Mbi b̃Mbi . The solution (xsf , xbd , bMbi ) of (84)
is unique and coincides with that of (80) due to the lower eigenvalue condition. Thus, the zero-subgradient
condition (81) is satisfied, which together with (82) can be written as:









0
ĥMsf
A
AMsf ,Xbd 
w\Msf
1  Msf ,Xsf
1
x\sf − x̂sf
 −
w\M  +λ ĥM  = 0.
0
0
AMbo ,Xbd 
−
+
bo
bo
x\bd − x̂bd
nm
nm
w\Mbi
0
AMbi ,Xbd
b̃Mbi − b̂Mbi
ĥMbi
(85)
We can partition the above relation into equations indexed by Mbi , which can be rearranged as:



x◦\ − x̂◦
1  ◦
1 ◦
◦
◦
◦>
I
w◦ ,
(86)
ĥMbi =
+
I Mbi A I Mbi I Mbi
nm λ
nm λ Mbi \
b̃Mbi − b̂Mbi
h
>
as well as those indexed by Msf ∪ Mbo , which can be solved for ĥMsf ∪Mbo = ĥM
sf
ĥMsf ∪Mbo =

1
nm λ


I ◦Msf ∪Mbo A◦ (x◦\ − x̂◦ ) + w◦\ .

Since x̂◦ is the optimal solution of (84), it satisfies the optimality condition:


A◦> A◦ (x◦\ − x̂◦ ) + w◦\ + I ◦>
(
b̃
−
b̂
)
=0
Mbi
Mbi Mbi

i>
>
ĥMbo :
(87)

(88)

Combining (86), (87) and (88) and after some elementary operations, we have
◦>
A◦>
Msf ∪Mbo ĥMsf ∪Mbo + AMbi ĥMbi = 0.

(89)

By Lemma 11, for any ĥMbi ∈ ∂kb̂Mbi k1 , there always exists ĥMsf ∪Mbo such that kĥMsf ∪Mbo k∞ < 1.
Thus, the strict feasibility condition is satisfied deterministically.
50



Part 2): By the lower eigenvalue condition the and definition of Q◦Mbi = A◦ I ◦>
Mbi , we can solve
(86) and (88):




x◦\ − x̂◦
0
◦
−1 ◦>
◦
◦>
◦
−1
(90)
= −(Q◦>
Q
)
Q
w
+
n
λ(Q
Q
)
∆ :=
m
Mbi Mbi
Mbi \
Mbi Mbi
ĥMbi
b̃Mbi − b̂Mbi
Let I x and I b denote the matrices that consist of the first |Xsf | + |Xbd | rows and the last |Mbi | rows of the
identity matrix of size |Xsf | + |Xbd | + |Mbi |, respectively. Then, we can bound the estimation error ∆ in
(90). First, we bound the infinity norm of b̃Mbi − b̂Mbi = I b ∆. By triangle inequality,
◦
−1 ◦>
◦
◦>
◦
−1 >
kI b ∆k∞ ≤ kI b (Q◦>
Mbi QMbi ) QMbi w \ k∞ + nm λkI b (QMbi QMbi ) I b k∞ .

(91)

Since the second term is deterministic, we will now bound the first term. By the normalized measurement
condition (2) (we assume all measurement vectors are normalized by 1 without loss of generality) and
◦
◦
−1 ◦>
the lower eigenvalue condition, each entry of (Q◦>
Mbi QMbi ) QMbi w \ is zero-mean sub-Gaussian with
parameter at most
σ2
◦
−1
σ 2 k(Q◦>
.
(92)
Mbi QMbi ) k2 ≤
Cmin
Thus, by the union bound, we have

P
Then, set t =

◦
−1 ◦>
◦
kI b (Q◦>
Mbi QMbi ) QMbi w \ k∞

nm λ
√
,
2 Cmin




Cmin t2
> t ≤ 2 exp −
+ log |Mbi | .
2σ 2

and note that by our choice of λ, we have


kb̃Mbi − b̂Mbi k∞ ≤ nm λ

Cmin t2
2σ 2

(93)

> log |Mbi |. Thus, we conclude that

1
◦
−1 >
√
+ kI b (Q◦>
Mbi QMbi ) I b k∞
2 Cmin


(94)

with probability greater than 1 − 2 exp(−c2 n2m λ2 ). This indicates that all bad data entries greater than


1
◦>
◦
−1 >
√
g(λ) = nm λ
(95)
+ kI b (QMbi QMbi ) I b k∞
2 Cmin
will be detected by b̂Mbi .
Part 3): Now, we bound the `2 norm of the signal error x◦\ − x̂◦ = I x ∆,
◦
−1 ◦>
◦
◦>
◦
−1 >
kI x ∆k2 ≤ kI x (Q◦>
Mbi QMbi ) QMbi w \ k2 + nm λkI x (QMbi QMbi ) I b k∞,2 .

(96)

For the first term, by the application of standard sub-gaussian concentration,


◦
−1 ◦>
◦
◦>
◦
−1 ◦>
◦>
◦
−1 ◦>
P kI x (Q◦>
Mbi QMbi ) QMbi w \ k2 > kI x (QMbi QMbi ) QMbi kF + tkI x (QMbi QMbi ) QMbi k2


2
is upper bounded by exp − cσ1 t4 . Since
◦
−1 ◦>
kI x (Q◦>
Mbi QMbi ) QMbi kF

≤

◦
−1
◦>
kI x k2 k(Q◦>
Mbi QMbi ) k2 kQMbi kF

51

p
|Xsf | + |Xbd | + |Mbi |
≤
Cmin

due to the lower eigenvalue condition and the normalized measurement condition, and similarly it holds that
p
|Xsf | + |Xbd | + |Mbi |
◦>
◦
−1 ◦>
◦>
◦
−1
◦>
kI x (QMbi QMbi ) QMbi k2 ≤ kI x k2 k(QMbi QMbi ) k2 kQMbi kF ≤
.
Cmin
Moreover,
P

◦
−1 ◦>
◦
kI x (Q◦>
Mbi QMbi ) QMbi w \ k2

p
>t

|Xsf | + |Xbd | + |Mbi |
Cmin

!



c1 t2
≤ exp − 4 .
σ

Together, we conclude that
p
|Xsf | + |Xbd | + |Mbi |
◦
−1 >
kx\ − x̂k2 ≤ t
+ nm λkI x (Q◦>
Mbi QMbi ) I b k∞,2
Cmin


2
with probability greater than 1 − exp − cσ1 t4 .

(97)

 ◦

◦
◦
Lemma 33. Suppose that Q◦>
I ◦>
Mbi QMbi is invertible, where QMbi = A
Mbi . Then, it holds that
>+
◦
−1 >
>
I Msf ∪Mbo A◦ I x (Q◦>
Mbi QMbi ) I b = −AMsf ∪Mbo AMbi .

(98)

Proof. By the definition of Q◦Mbi and block matrix inversion formula, we have
◦
−1 >
I x (Q◦>
Mbi QMbi ) I b
◦> ◦ −1 >
−1
= −(A◦> A◦ )−1 A>
Mbi (I − AMbi (A A ) AMbi )
>
−1 >
= −(A◦> A◦ )−1 A>
Mbi (I + AMbi (AMsf ∪Mbo AMsf ∪Mbo ) AMbi )
>
−1
>
= −(A◦> A◦ )−1 (I + A>
Mbi AMbi (AMsf ∪Mbo AMsf ∪Mbo ) )AMbi
−1 >
= −(A>
Msf ∪Mbo AMsf ∪Mbo ) AMbi ,

where the first equation follows from the Sherman-Morrison-Woodbury formula and the rest are elementary
operations.
◦
Lemma 34. Suppose that Q◦>
Mbi QMbi is invertible. Then, it holds that
◦
−1 >
>
−1 >
I b (Q◦>
Mbi QMbi ) I b = I + AMbi (AMsf ∪Mbo AMsf ∪Mbo ) AMbi

Proof. By the definition of Q◦Mbi and block matrix inversion formula, we have
◦
−1 >
◦> ◦ −1 >
−1
I b (Q◦>
Mbi QMbi ) I b = (I − AMbi (A A ) AMbi )
−1 >
= I + AMbi (A>
Msf ∪Mbo AMsf ∪Mbo ) AMbi ,

where the second equation follows from the Sherman-Morrison-Woodbury formula.

52

(99)

E.2

Proof of Theorem 20

For an arbitrary set of attacked measurements Mat , their boundary Mbd := Mbi ∪ Mbo and unaffected
measurements Msf , as well as the associated variables xat , xbd and xsf , respectively, we design the primaldual witness process as follows:
1) Set b̂Msf = 0 and b̂Mbo = 0;
h
i>


>
>
>
> >
>
>
by solving the following
2) Determine x̂ = x̂>
and
b̂
=
x̂
x̂
0
0
b̂Mbi b̂Mat
at
sf
bd
program:

min

b∈Rnm ,x∈Rnx

1
2nm

 
y Msf
AMsf ,Xsf
y M  
0
bo  

 y M −
0
bi
0
y Mat

subject to c>
` x ≥ kD ` xk2 ,

AMsf ,Xbd
AMbo ,Xbd
AMbi ,Xbd
0

 2
0


 xsf  0 
 xbd −
 +λ bMbi
,
 bM 
bMat 1
AMbi ,Xat 
bi
xat
AMat ,Xat
bMat 2
(100a)
0
0









∀` ∈ L,

(100b)

and ĥMbi ∈ ∂kb̂Mbi k1 and ĥMat ∈ ∂kb̂Mat k1 satisfying the optimality conditions
1
(y
− AMat ,Xat x̂at − b̂Mat ) + λĥMat = 0,
nm Mat

− AMbi ,Xbd x̂bd − AMbi ,Xat x̂at − b̂Mbi + λĥMbi = 0.
−

−

1 
y Mbi
nm

(101a)
(101b)

3) Solve (ĥMsf , ĥMbo ) via the zero-subgradient equation:

1 
y − Ax̂ − b̂ + λĥ = 0,
−
(102)
nm
h
i>


>
>
> >
> 0> b̂>
where x̂ = x̂>
and
b̂
=
are solutions obtained in (80),
x̂
x̂
0
b̂
Bsf
Bbd
Bat
Mbi
Mat
h
i>
>
>
>
>
and ĥ = ĥM
where (ĥMbi , ĥMat ) are given in (81). Check whether strict
ĥM
ĥM
ĥMat
sf

bo

bi

feasibility conditions kĥMsf k∞ < 1 and kĥMbo k∞ < 1 hold.
Lemma 35. If the PDW procedure succeeds, then (x̂, b̂) that is optimal for (100) is also optimal for
(S(1) : `2 `1 -K). Furthermore, for any optimal solution (x̃, b̃), if x̂at = x̃at , it holds that x̂sf = x̃sf and
x̂bd = x̃bd (i.e., uniqueness property in the weak sense).
Proof. The KKT conditions of (S(1) : `2 `1 -K) for a given primal-dual pair (x̂, b̂) and ĥ are given by:
X
1 >
A (y − Ax̂ − b̂) + λ
(ν` c` + D >
` µ` ) = 0,
nm
`∈L

1 
−
y − Ax̂ − b̂ + λĥ = 0,
nm
ĥ ∈ ∂kb̂k1 , kĥk∞ ≤ 1

(103a)
(103b)
(103c)

If PDW succeeds, then the optimality conditions (103) are satisfied,
D which
E certify the optimality of (x̂, b̂).
The subgradient ĥ satisfies kĥMsf k∞ < 1, kĥMbo k∞ < 1 and ĥ, b̂ = kb̂k1 . Now, let (x̃, b̃) be any
53

other optimal, and let F (x, b) =

1
2nm ky

− Ax − bk22 ; then,
D
E
F (x̂, b̂) + λ ĥ, b̂ = F (x̃, b̃) + λkb̃k1 ,

and hence,
D
E

D
E
F (x̂, b̂) + λ ĥ, b̂ − b̃ = F (x̃, b̃) + λ kb̃k1 − ĥ, b̃ .
By the optimality conditions in (103), we have λĥ = −∇b F (x̂, b̂) = n1m (y − Ax̂ − b̂), which implies that
D
E

D
E
F (x̂, b̂) − ∇b F (x̂, b̂), b̂ − b̃ − F (x̃, b̃) = λ kb̃k1 − ĥ, b̃ ≤ 0
E
D
E
ĥ, b̃ . Since by Holder’s inequality, we also have ĥ, b̃ ≤
D
E
≤ 1, it holds that kb̃k1 = ĥ, b̃ . Since by the success of PDW, kĥMsf k∞ < 1,

due to convexity. We thus have kb̃k1 ≤
kĥk∞ kb̃k1 , and kĥk∞

D

kĥMbo k∞ < 1, we have b̃j = 0 for j ∈ Msf ∪ Mbo . To show the weak uniqueness, let (x̃, b̃) be another
optimal solution, and assume that x̂at = x̃at . Then, by fixing xat in the optimization (100) at x̂at and by
the lower eigenvalue condition, the the function is strictly convex in xsf , xbd and bMbi .

Proof of Theorem 20
Proof. Part 1): By the construction of PDW, we have b̂Msf = b\Msf = 0 and b̂Mbo = b\Mbo = 0. In the
following, we allow the optimal solution x̂at and b̂Mat of (100) to take any value as long as the nonbinding
SOC constraints assumption is satisfied. Thus, for any given x̂at and b̂Mat , we can fix xat and bMat in
(100) and solve the following smaller program:



 

AMsf ,Xsf AMsf ,Xbd 
0
y Msf
x
y M  − 
0
AMbo ,Xbd  sf −  0 
bo
xbd
0
AMbi ,Xbd | {z }
bMbi
z Mbi
{z
} x◦
| {z } |

bMbi ,xsf ,xbd

1
2nm

subject to

c>
` x

min

z◦

≥ kD ` xk2 ,

2

+ λ kbMbi k1 ,

(104a)

2

A◦

∀` ∈ L \ Lat ,

(104b)

where z Mbi = y Mbi − AMbi ,Xat x̂at = AMbi ,Xbd x\bd + b̃Mbi and b̃Mbi = AMbi ,Xat (x\at − x̂at ). Let I ◦
be an identity matrix of size nm −|Mat |, and x◦ , c◦` and D ◦` be the subvector and submatrix of x, c` and D `
indexed by Xsf and Xbd , respectively, and w◦ be the subvector of w indexed by Msf ∪ Mbo ∪ Mbi . Thus,
we have z ◦ = A◦ x◦\ +w◦\ +I ◦>
Mbi b̃Mbi . The solution (xsf , xbd , bMbi ) of (104) is unique and coincides with
that of (100) due to the lower eigenvalue condition. Thus, the zero-subgradient condition (101) is satisfied,
which together with (102) can be written as:









0
ĥMsf
AMsf ,Xsf AMsf ,Xbd 
w\Msf
1 
x\sf − x̂sf
 − 1 w\M  +λ ĥM  = 0.
0
0
AMbo ,Xbd 
+
−
bo
bo
x
−
x̂
nm
nm
\bd
bd
0
AMbi ,Xbd
w\Mbi
b̃Mbi − b̂Mbi
ĥMbi
(105)
We can partition the above relation into equations indexed by Mbi , which can be rearranged as:



x◦\ − x̂◦
1  ◦
1 ◦
ĥMbi =
I
w◦ ,
(106)
+
I Mbi A◦ I ◦Mbi I ◦>
Mbi
nm λ
nm λ Mbi \
b̃Mbi − b̂Mbi
54

h
>
as well as those indexed by Msf ∪ Mbo , which can be solved for ĥMsf ∪Mbo = ĥM
sf
ĥMsf ∪Mbo =

1
nm λ

i>
>
ĥMbo :


I ◦Msf ∪Mbo A◦ (x◦\ − x̂◦ ) + w◦\ .

(107)

Since x̂◦ is the optimal solution of (104), it satisfies the optimality condition:

1 ◦>  ◦ ◦
)
+
−
b̂
A (x\ − x̂◦ ) + w◦\ + I ◦>
(
b̃
A
Mbi
Mbi Mbi
nm

X

ν̂` c◦` + D ◦>
` û` = 0

(108)

`∈Lat∩bi ∪Lbd ∪Lsf

Combining (106), (107) and (108) and after some elementary operations, it yields that
X
◦>
ν̂` c◦` + D ◦>
λA◦>
Msf ∪Mbo ĥMsf ∪Mbo + λAMbi ĥMbi +
` û` = 0.

(109)

`∈Lat∩bi ∪Lbd ∪Lsf

By Lemma 17, for any ĥMbi ∈ ∂kb̂Mbi k1 , there always exist ĥMsf ∪Mbo and {ν̂` , û` }Lat∩bi ∪Lbd ∪Lsf such
that kĥMsf ∪Mbo k∞ < 1. Thus, the strict feasibility condition is satisfied deterministically.


Part 2): Thus, by the lower eigenvalue condition and definition of Q◦Mbi = A◦ I ◦>
Mbi and ĥ =
h
i>
>
>
, we can solve (106), (108) and (109):
ĥM ∪M
ĥM
sf

bo

bi

x◦\ − x̂◦
∆ :=
b̃Mbi − b̂Mbi



"

=

◦
−1 ◦>
◦
−(Q◦>
Mbi QMbi ) QMbi w \

+

◦
−1
nm λ(Q◦>
Mbi QMbi )

◦>
A◦>
Msf ∪Mbo ĥMsf ∪Mbo + AMbi ĥMbi
ĥMbi

◦>
◦
−1 ◦>
◦
−1 ◦>
◦
= −(Q◦>
Mbi QMbi ) QMbi w \ + nm λ(QMbi QMbi ) QMbi ĥ,

#

(110)

Let I x and I b denote the matrices that consist of the first |Xsf | + |Xbd | rows and the last |Mbi | rows of the
identity matrix of size |Xsf | + |Xbd | + |Mbi |, respectively. Then, we can bound the estimation error ∆ in
(90). First, we bound the infinity norm of b̃Mbi − b̂Mbi = I b ∆. By triangle inequality,
◦>
◦
−1 ◦>
◦
−1 ◦>
◦
kI b ∆k∞ ≤ kI b (Q◦>
Mbi QMbi ) QMbi w \ k∞ + nm λkI b (QMbi QMbi ) QMbi k∞ .

(111)

Since the second term is deterministic, we will bound the first term similar to Theorem 12. This concludes
the proof
Part 3): Now, we bound the `2 norm of the signal error x◦\ − x̂◦ = I x ∆,
◦
−1 ◦>
◦
◦>
◦
−1 ◦>
kI x ∆k2 ≤ kI x (Q◦>
Mbi QMbi ) QMbi w \ k2 + nm λkI x (QMbi QMbi ) QMbi k∞,2 .

(112)

For the first term, we can apply standard sub-gaussian concentration. The second term is deterministic.
Combining them together yields the results.

55

