Beyond the EM Algorithm: Constrained Optimization
Methods for Latent Class Model

arXiv:1901.02928v4 [stat.ML] 19 May 2020

Hao Chen1
Research & Development, Precima, Chicago, IL USA 60631

Lanshan Han
Research & Development, Precima, Chicago, IL USA 60631

Alvin Lim
Research & Development, Precima, Chicago, IL USA 60631

Abstract
Latent class model (LCM), which is a finite mixture of different categorical
distributions, is one of the most widely used models in statistics and machine
learning fields. Because of its non-continuous nature and flexibility in shape,
researchers in areas such as marketing and social sciences also frequently
use LCM to gain insights from their data. One likelihood-based method, the
Expectation-Maximization (EM) algorithm, is often used to obtain the model
estimators. However, the EM algorithm is well-known for its notoriously slow
convergence. In this research, we explore alternative likelihood-based methods that can potential remedy the slow convergence of the EM algorithm.
More specifically, we regard likelihood-based approach as a constrained nonlinear optimization problem, and apply quasi-Newton type methods to solve
them. We examine two different constrained optimization methods to maximize the log-likelihood function. We present simulation study results to show
that the proposed methods not only converge in less iterations than the EM
algorithm but also produce more accurate model estimators.
(NOTE: the paper has been published online at here)
Email addresses: hao.chen@stat.ubc.ca (Hao Chen), lhan2@precima.com
(Lanshan Han), alim@precima.com (Alvin Lim)
1
Corresponding Author. We thank the editor and the anonymous reviewer for suggestions that improved the manuscript.
Preprint submitted to CSSC. Accepted on Apr 28, 2020.

May 20, 2020

Keywords: Constrained Optimization, Quasi-Newton’s Method, Quadratic
Programming, EM Algorithm, Latent Class Model, Finite Mixture Model.
1. Introduction
Latent class model (LCM) (McCutcheon (1987)) is a model to study latent (unobserved) categorical variables by examining a group of observed
categorical variables which are regarded as the indictors of the underlying
latent variables. It can be regarded as a special case of the finite mixture
model (FMM) with component distributions being categorical distributions.
It is widely used to analyze ordered survey data collected from real world
applications. In many applications in econometrics, social sciences, biometrics, and business analytics (see Hagenaars and McCutcheon (2002); Oser
et al. (2013) for example), finite mixture of categorical distributions arises
naturally when we sample from a population with heterogeneous subgroups.
LCM is a powerful tool to conduct statistical inference from the collected
data in such situations.
We provide a motivating example from White et al. (2014) where an LCM
is applied to analyze a dataset of patient symptoms recorded in the Mercer
Institute of St. James’ Hospital in Dublin, Ireland (Moran et al. (2004)). The
data is a recording of the presence of six symptoms displayed by 240 patients
diagnosed with early onset Alzheimer’s disease. The six symptoms are as
follows: hallucination, activity, aggression, agitation, diurnal and affective,
and each symptom has two states: either present or absent. White et al.
(2014) proposed to divide patients into K = 3 groups such that patients are
homogeneous within each group and heterogeneous between groups. Each
group’s characteristics are summarized by the LCM parameters that help
doctors prepare more specialized treatments. In this sense, LCM is a typical
unsupervised statistical learning method that could “learn” the group labels
based on the estimated parameters.
Due to its theoretical importance and practical relevance, many different approaches have been proposed to estimate the unknown parameters in
LCMs from the observed data. In general, there are mainly two different
paradigms. The first one is the frequentist’s approach of maximum likelihood estimation (MLE), i.e., one maximizes the log-likelihood as a function
2

of the unknown parameters. In contrast, a second paradigm – the Bayesian
approach – where the unknown parameters obey a distribution and assumes
prior distributions on them, then one either analytically or numerically obtains the posterior distributions and statistical inference is carried out based
on the posterior distributions.
In recent years, significant progress has been made on Bayesian inference in LCM. White et al. (2014), by assuming the Dirichlet distribution
on each unknown parameter, used Gibbs sampling to iteratively draw samples from the posterior distribution and then conduct inference on the LCM
using the samples drawn. The authors also provided an implementation of
the approach in R. Li et al. (2018) described a similar Bayesian approach to
estimate the parameters and they also utilized the Dirichlet distribution as
the prior distribution. Asparouhov and Muthén (2011) introduced a similar
implementation package of Bayesian LCM in Mplus. However, compared to
the fast development of the Bayesian inference via Markov chain Monte Carlo
(MCMC), the frequentist’s MLE approach for LCM has largely lagged. As
far as we know, researchers still heavily rely on the expectation-maximization
(EM) algorithm (Dempster et al. (1977)), even with its notoriously slow convergence (see for instance Meilijson (1989)), to maximize the log-likelihood
function. It is known that some authors (Jamshidian and Jennrich (1997))
use Quasi-Newton methods as alternatives for the EM algorithm in Gaussian mixture models. However, the extension to LCM is not straightforward
since LCM includes a lot more intrinsic constraints on the parameters than
the general Gaussian mixture model when considered as an optimization
problem. More sophisticated optimization methods need to be applied when
maximizing the log-likelihood function.
This paper primarily focuses on the MLE paradigm. We propose the
use of two widely-used constrained optimization methods to maximize the
likelihood function, namely, the Projected Quasi-Newton method and the
sequential quadratic programming method. Our contributions include not
only exploring alternatives beyond the EM algorithm, but also demonstrating that better results could be obtained by using these alternatives. The rest
of this paper is organized as follows: in Section 2, we present the preliminaries including the log-likelihood function and the classical EM algorithm. In
Section 3, we introduce and discuss the two constrained optimization methods in detail. Some simulation studies and a real world data analysis are
3

presented in Section 4 to compare the performance of the proposed methods
with the EM algorithm. We make concluding remarks in Section 6.
2. Latent Class Models and the EM Algorithm
In many applications, a finite mixture distribution arises naturally when
we sample from a population with heterogeneous subgroups, indexed by k
taking values in {1, · · · , K}. Consider a population composed of K subgroups, mixed at random in proportion to the relative group sizes η1 , · · · , ηK .
There is a random feature y, heterogeneous across and homogeneous within
the subgroups. The feature y obeys a different probability distribution, often
from the same parametric family p(y|θ) with θ differing, for each subgroup.
Now we sample from this population, if it is impossible to record the subgroup
label, denoted by s, then the density p(y) is:
p(y) =

K
X

ηk p(y|θk ),

k=1

which is a finite mixture distribution. In this situation, we often need to
estimate the θk ’s as well as ηk based on the random samples of y, when the
subgroup label s is known or unknown. Throughout this paper, we assume
that K is known.
The LCM is a special case of the FMM. In LCM, the component densities are multivariate categorical distributions. That is, y = (y 1 , · · · , y d ) with
each y j being a categorical random variable, taking values from cj categories
{1, · · · , cj }. It is assumed that y j ’s are independent within each subgroup
with an indictor s (the latent variable), which is a categorical random variable taking values in {1, · · · , K}, i.e., within each subgroup, the probability
density function (PDF) is written as:
cj
d Y
Y

I(y =l)

πk,j,lj

,

j=1 l=1

where πk,j,l = Pr(y j = l|s = k) and I(·) is the Iverson bracket function, i.e.

1 if P is true;
I(P) =
0 if P is false.

4

Overall, the mixture density of latent class models is:
!
cj
K
d Y
X
Y
I(y j =l)
p(y|θ) =
ηk
πk,j,l
,
j=1 l=1

k=1

where, the parameters θ include both the weight distribution η and the πk,j,l ’s
that define the categorical distributions.
Suppose we have collected N samples drawn from the LCM distribution,

T
denoted by {y 1 , · · · , y N }. We write Y = y 1 , · · · , y N ∈ RN ×d as the data
matrix. The log-likelihood function is given by
!
N
Y
i
L(θ|Y ) = log
p(y |θ)
i=1

=

N
X

log

i=1

K
X
k=1

ηk

cd
d Y
Y

I(y i =l)
πk,j,lj

!
.

(1)

j=1 l=1

The maximum likelihood principle is to find a θ ∗ that maximizes the loglikelihood function (1) as the estimation of θ. Clearly, we can regard the
problem of finding such a θ ∗ as an optimization problem. At the same time,
we notice that the LCM implies several constraints that need to be satisfied
when maximizing the log-likelihood function (1). In particular, the ηk ’s are all
nonnegative and sum up to 1. Also, for each k = 1, · · · , K and j = 1, · · · , d,
the πk,j,l ’s are all nonnegative and sum up to 1. Let η = (ηk )K
k=1 be the vector
of ηk ’s and π = (πk,j,l )k=1,··· ,K;j=1,··· ,d;l=1,··· ,cj be the vector of πk,j,l ’s. From
an optimization point of view, the MLE in the LCM case is the following
optimization problem.
!
cd
N
K
d Y
X
X
Y
I(yji =l)
max
log
ηk
πk,j,l
η,π

s.t.

i=1
K
X

k=1

j=1 l=1

ηk = 1,
(2)

k=1
cj

X

πk,j,l = 1, ∀ k = 1, · · · , K, j = 1, · · · , d,

l=1

ηk ≥ 0, ∀ k = 1, · · · , K,
πk,j,l ≥ 0, ∀ k = 1, · · · , K, j = 1, · · · , d, l = 1, · · · , cj .
5

As we can see, the optimization problem (2) possesses K × d + 1 equality
constraints together with nonnegativity constraints on all the individual decision variables. While there are considerable number of constraints, the
feasible region in (2) is indeed the Cartesian product of K × d + 1 probability
simplexes. We recall that a probability simplex in n-dimensional space Rn is
defined as
(
)
n
X
P n = x ∈ Rn+
xi = 1 ,
i=1
c

j
is the nonnegative orthant of Rn . Let πk,j = (πk,j,l )l=1
where
for all
k = 1, · · · , K and j = 1, · · · , d. The constraints in (2) can be written as
η ∈ P K and πk,j ∈ P cj , ∀ k = 1, · · · , K; j = 1, · · · , d.

Rn+

To maximize the log-likelihood function in (1), the EM algorithm is a
classical approach. In statistics, the EM algorithm is a generic framework
that is commonly used in obtaining maximum likelihood estimators. The
reason why the EM algorithm enjoys its popularity in finite mixture model
is the fact that we can view finite mixture model as an estimation problem
with missing data. More specifically, if we know the true label of each observation, we could obtain the MLE in a fairly straightforward fashion. On
the other hand, if we know the true model parameters, it is also trivial to
compute the probability each observation belonging to each class. Therefore,
a natural idea is that we begin the process with an initial random guess of the
parameters, and compute the probability each observation belonging to each
class E(xpectation)-step. With those probabilities we compute the MLE,
which is the M(aximization)-step. We iterate between the two steps until a
convergence condition is reached. Particularly for the LCM, when the EM
algorithm is applied to it, the constraints are implicitly satisfied for all the
iterations thanks to the way the EM algorithm updates the values of the parameters. This nice property does not necessarily hold naturally when other
non-linear optimization algorithms are applied to the optimization problem
(2).
In the context of LCM, the details of the EM algorithm is given in Algorithm 1. We make two comments on Algorithm 1. First, Algorithm 1 does
not produce standard errors of MLE as a by-product. In order to conduct
statistical inference, one has to compute the observed Fisher information
matrix and it could be algebraically tedious or might only apply to special
6

cases. This is one of the criticisms often laid out against the EM algorithm
as compared to Bayesian analysis using Gibbs samplers for example, where
independent posterior samples are collected and statistical inference is easy
under such circumstance. Second, the convergence of Algorithm 1 is typically slow. Wu (1983) studied the convergence issue of the EM algorithm
and concluded that the convergence of the EM algorithm is sublinear when
the Jacobian matrix of the unknown parameters is singular. Jamshidian and
Jennrich (1997) also reported that the EM algorithm could well be accelerated by the Quasi-Newton method. In Section 4, we shall also empirically
observe the two constrained optimization methods converge in less iterations
than the EM algorithm.
3. Constrained Optimization Methods
Motivated by the significant progress in constrained non-linear optimization, as well as the constrained nature of the LCM estimation problem, we
propose to apply two non-linear optimization approaches to solve the optimization problem (2). We notice that the EM algorithm is closely related to
a gradient decent method Wu (1983), whose convergence rate is at most linear. On the other hand, it is known in optimization theory that if the second
order information is utilized in the algorithm, quadratic convergence may be
achieved, e.g., the classical Newton’s method. However, in many applications, it is often computationally very expensive to obtain the second order
information, i.e., the Hessian matrix. One remedy is to use computationally
cheap approximation of the Hessian matrix. This idea leads to the family
of Quasi-Newton methods in the unconstrained case. While the convergence
rate is typically only superlinear, the per iteration cost (both the execution
time and the memory usage) is significantly reduced. In the constrained
case, sophisticated methods have been developed to allow us to deal with the
constraints. Given that it is relative easy to solve a constrained optimization
problem when the objective function is quadratic and the constraints are all
linear, one idea in constrained non-linear optimization is to approximate the
objective function (or the Lagrangian function) by a quadratic function (via
second-order Taylor expansion at the current solution) and approximate the
constraints by linear constraints (via first-order Taylor expansion at the current solution). A new solution is obtained by solving the approximation and
hence a new approximation can be constructed at the new solution. Analogous to the idea of quasi-Newton methods in the unconstrained case, in the
7

Algorithm 1 EM Algorithm for Latent Class Model
1: Supply an initial guess of the parameters
(0)

(0)

θ (0) = (ηk , πj,k,l )k=1,··· ,K;j=1,··· ,d;l=1,··· ,cj
and a convergence tolerance .
2: Initialize with t = 1, and ∆ > .
3: While ∆ > :
4:
(E-step) For each i = 1, · · · , N and k = 1, · · · , K, compute:
I(yji =l)
(t−1)
π
k,j,l
l=1
j=1
.
=
PK (t−1) Qd Qcj  (t−1) I(yji =l)
l=1 πk,j,l
j=1
k=1 ηk
(t−1)

(t)

Dik

5:

ηk

Q cj 

Qd

(M-step for weights) Compute:
(t)

η̂k =

N
1 X (t)
D .
N i=1 ik

6:

(M-step for categorical parameters) Compute:
i
h
Pcj
Pn
(t) Pd
i
D
I(y
=
l)
j
l=1
ik
j=1
i=1
(t)
hP P
io .
πk,j,l = Pc nP
cj
(t)
n
m
j
i
I(y
D
=
l)
j
ik
l=1
l=1
i=1
j=1

7:

Compute ∆ = θ (h+1) − θ (h)
t = t + 1.

8:

.
1

8

constrained case, we can also consider an approximated Taylor expansion
without having to compute the Hessian matrix exactly. Once an approximated quadratic program is obtained, one may use different approaches to
solve it. For example, one can use an active set method or an interior point
method to solve the quadratic program when it does not possess any specific
structure. When the feasible region of the quadratic program is easily computable (typically in strongly polynomial time), a gradient projection method
can be applied to solve the quadratic program approximation. As we have
seen, the feasible region of optimization problem (2) is the Cartesian product
of probability simplexes. It is known that projection on a probability simplex is computable in strongly polynomial time. Therefore, it is reasonable
to apply a projection method to solve the quadratic program approximation.
In the following subsections, the two approaches we propose are discussed in
details. In both approaches, we need to evaluate the gradient of the LCM
log-likelihood function. We provide the analytical expression below. For the
η part, we have:


n
i
X
∂L
 P f (y |θk )
  , k = 1, · · · , K.
(3)
=
K
∂ηk
i
η
f
(y
|θ
)
i=1
k=1

k

k

For the π part, we have for all i = 1, · · · , n; k = 1, · · · , K; j = 1, · · · , m; l =
1, · · · , cj :
cj
YY
∂f (y i |πk )
I(y i =`)
i
πk,,` ,
= I(yj = l)
∂πk,j,l
6=j `=1
where πk = (πk,j,l )j=1,··· ,d;l=1,··· ,cj . And therefore, for all k = 1, · · · , K,


n
i
X
∂L
ηk
∂f (y |πk ) 


=
.
P
K
∂πk
∂π
i |π )
k
η
f
(y
i=1
k
k=1 k

(4)

3.1. Limited Memory Projected Quasi-Newton Method
We first present the Projected Quasi-Newton method which is proposed
by Schmidt et al. (2009). We augment it with the algorithm proposed by
Wang and Carreira-Perpinán (2013) to project parameters onto a probability
simplex in strongly polynomial time. In general, we address the problem of

9

minimizing a differentiable function f (x) over a convex set C subject to m
equality constraints:
minx f (x)
s.t. hj (x) = 0, ∀ j = 1, · · · , m,
x ∈ C.

(5)

In an iterative algorithm, we update the next iteration as follows:
x(t+1) = x(t) + αt d(t) ,

(6)

where x(t) is the solution at the t-th iteration, αt is the step length and d(t)
is the moving direction at iteration t. Different algorithms differ in how d(t)
and αt are determined. In the Projected Quasi-Newton method, a quadratic
approximation of the objective function around the current iterate x(t) is
constructed as follows.
1
qt (x) = f (x(t) ) + (x − x(t) )T g (t) + (x − x(t) )T B (t) (x − x(t) ),
2
where g (t) = ∇f (x(t) ) and B (t) denotes a positive-definite approximation of
the Hessian ∇2 f (x(t) ). The projected quasi-Newton method then compute a
feasible descent direction by minimizing this quadratic approximation subject
to the original constraints:
z (t) = argminx qt (x),
s.t. hj (x) = 0, ∀ j = 1, · · · , m,
x ∈ C.

(7)

Then the moving direction is d(t) = z (t) − x(t) .
To determine the step length αt , we ensure that a sufficient decrease
condition, such as the Armijo condition is met:
f (x(t) + αdt ) ≤ f (x(t) ) + να(g (t) )T d(t) ,

(8)

where ν ∈ (0, 1).
Although there are many appealing theoretical properties of projected
Newton method just summarized, many obstacles prevent its efficient implementation in its original form. A major shortcoming is that minimizing (7)
10

could be as difficult as optimizing (5). In Schmidt et al. (2009), the projected Newton method was modified into a more practical version which uses
the limited memory BFGS update to obtain B (t) ’s and a Spectral Projected
Gradient (SPG) Algorithm ((Birgin et al., 2000)) to solve the quadratic approximation (7).
To apply this Projected Quasi-Newton method to (2), we let f (θ) :=
−L(θ|Y ). As we discussed in the previous section, we rewrite (2) as follows:
min f (θ)
s.t θ ∈ F,

(9)

N Nd
cj
is the feasible region given in the format
where F = P K ⊗ K
j=1 P
k=1
of the Cartesian product of K × d + 1 probability simplexes. This rewriting
is to facilitate the projection operation. We denote ΠS (x) as the projection
of a vector x ∈ Rn on a closed convex set S ⊆ Rn , i.e. Πs (x) is the unique
solution of the following quadratic program:
min ky − xk22
s.t. y ∈ S.

(10)

As we can see, in general, a quadratic program needs to be solved to compute the projection onto a closed convex set, and hence is not computationally cheap. Fortunately, the feasible region in (9) allows for a projection
computable in strongly polynomial time according to Wang and CarreiraPerpinán (2013). This algorithm is presented in Algorithm 4. This algorithm is the building block for the SPG algorithm to solve the quadratic
approximation in each iteration. More specifically, in the t-th iteration, let
1
qt (θ) = f (θ (t) ) + (θ − θ (t) )T g (t) + (θ − θ (t) )T B (t) (θ − θ (t) ),
2
where g (t) = ∇f (θ (t) ) and B (t) denotes a positive-definite approximation of
the Hessian ∇2 f (θ (t) ). The quadratic approximation is now given by
ϑ(t) = argminθ qt (θ),
s.t. θ ∈ F.

(11)

The gradient of qt (θ) is given by
∇qt (θ) = ∇f (θ (t) ) + (B (t) )T (θ − θ (t) ).
11

(12)

In our implementation, ∇f (θ (t) ) is numerically approximated by the method
of symmetric difference quotient with length chosen as 0.05. We can also
compute ∇f (θ(t) ) using the analytical expressions (3) and (4).
We update B (t) using the limited memory version of BFGS. The nonlimited memory BFGS update of B is given by
B (t+1) = B (t) −

B (t) s(t) (s(t) )T B (t) y (t) (y (t) )T
+ (t) T (t) ,
(s(t) )T B (t) s(t)
(y ) s

(13)

where s(t) = θ (t+1) − θ (t) and y (t) = ∇f (θ (t+1) ) − ∇f (θ (t) ). This will consume
significant memory in storing B (t) ’s when the number of features increases
dramatically. Therefore, in the proposed Projected Quasi-Newton algorithm
we only keep the most recent m = 5 Y and S arrays (the definitions of Y
and S are in Algorithm 2) and update B (t) using its compact representation
described by Byrd et al. (1994):
B (t) = σt I − N (t) (M (t) )−1 (N (t) )T ,

(14)

where N (t) and M (t) are explicitly given in equation (3.5) of Byrd et al. (1994).
In addition, running Algorithm 2 until convergence, the B matrix is outputted as a by-product. The −B matrix is an approximation of the observed
Fisher information of the unknown parameters, which will enable us to construct asymptotic confidence intervals using the following classical results:
θ̂ → N (θ, −Bθ−1 ).

(15)

This is way easier than the EM algorithm to conduct statistical inference.
According to Gower and Richtárik (2017), when f is convex quadratic function with positive definite Hessian matrix, it is expected that −B (t) from the
Quasi-Newton method to converge to the true Hessian matrix. However, the
log-likelihood function is obviously not a convex function and as far as we
know there is no formal theory that guarantees the convergence. Nonetheless, in Section 6 of Jamshidian and Jennrich (1997), the authors empirically
compared the estimates for standard errors to the true values and the results
are satisfactory.
In our implementation of Algorithm 2, we use m = 5,  = 10−4 and the
default parameters are αmin = 10−10 , αmax = 1010 , h = 1 and ν = 10−4 in
Algorithm 3.

12

Algorithm 2 Limited Memory Projected Quasi-Newton Method
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:

Given θ (0) , m and . Set t = 0.
While not converge:
f (t) = f (θ t ) and g (t) = ∇f (θ (t) )
Call Algorithm 3 for ϑ(t)
d(t) = ϑ(t) − θ (t)
If ΠF (θ (t) − g (t) ) − θ (t) ≤ , where ΠF (·) calls Algorithm 4:
1
Converged; Break.
α=1
θ (t+1) = θ (t) + αd(t)
While f (θ (t+1) ) > f (t) + να(g (t) )T d(t):
Select α randomly from Uniform distribution U (0, α)
θ (t+1) = θ (t) + αd(t)
s(t) = θ (t+1) − θ (t)
y (t) = g (t+1) − g (t)
If t = 0:
S = [s(t) ], Y = [y (t) ]
Else:
If t ≥ m:
Remove first column of S and Y
S = [S, s(t) ]
Y = [Y, y (t) ]
(y (t) )T s(t)
σ (t) = (y
(t) )T y (t)
Form N and M for BFGS update
t=t+1

13

Algorithm 3 Spectral Projected Gradient Algorithm
1: Given x0 , step bounds 0 < αmin < αmax
2: Initial step length αbb ∈ [αmin , αmax ], and history length h
3: While not converge:
4:
ᾱk = min{αmax , max{αmin , αbb }}
5:
dk = Pc (xk − ᾱk ∇qk (xk )) − xk , where Pc (.) calls Algorithm 4.
6:
Set bound fb = max{f (xk ), · · · , f (xk−h )}
7:
α=1
8:
While qk (xk + αdk ) > fb + να∇qk (xk )T dk :
9:
Select α randomly from Uniform distribution U (0, α).
10:
xk+1 = xk + αdk
11:
sk = xk+1 − xk
12:
yk = ∇qk (xk+1 ) − ∇qk (xk )
13:
αbb = ykT yk /sTk sk
14:
k =k+1

Algorithm 4 Euclidean Projection of a Vector onto the Probability Simplex.
Supply x ∈ RD .
Sort x into u such that u1 ≥ u2 ≥ · · · ≥
Puj D
1
Find ρ = max{1 ≤ j ≤ D : uj + j (1 − i=1 ui ) > 0}
Pρ
4: Define λ = ρ1 (1 −
i=1 ui )
0
5: Output x such that x0i = max{xi + λ, 0}, i = 1, · · · , D.
1:
2:
3:

14

3.2. Sequential Quadratic Programming
Sequential quadratic programming (SQP) is a generic method for nonlinear optimization with constraints. It is known as one of the most efficient
computational method to solve the general nonlinear programming problem
in (5) subject to both equality and inequality constraints. There are many
variants of this algorithm, we use the version considered in Kraft (1988). We
give a brief review of this method and then we will specifically talk about
how this method could be applied to optimization problem (2).
Consider the following minimization problem
min f (x)
x

s.t. cj (x) = 0, j = 1, 2, · · · , me ,
cj (x) ≥ 0, j = me + 1, me + 2, · · · , m,
xl ≤ x ≤ xu ,

(16)

where the problem functions f : Rn → R. SQP is also an iterative method
and each iteration a quadratic approximation of the original problem is also
constructed and solved to obtain the moving direction. Compared to the
Projected Quasi-Newton method, in SQP, the quadratic approximations are
typically solved by an active set method or an interior point method rather
than a projection type method. This significantly complicates the algorithm,
but also allows the algorithm to handle more general non-linear optimization
problems, especially when the feasible region is too complex to admit an
efficient projection computation. In particular, starting with a given vector
of parameters x(0) , the moving direction d(t) at iteration t is determined
by a quadratic programming problem, which is formulated by a quadratic
approximation of the Lagrangian function and a linear approximation of the
constraints. Note that, in contrast to the Projected Quasi-Newton method we
presented in the previous subsection, the SQP algorithm here approximates
the Lagrangian function instead of the objective function itself. An advantage
is that the dual information can be incorporated in the algorithm to ensure
better convergence property. Let
L(x; λ) = f (x) −

m
X

λj cj (x),

(17)

j=1

be the Lagrangian function associated with this optimization problem. This
15

approximation is of the following standard form of quadratic programming:
1
(x − x(t) )T B (t) (x − x(t) ) + ∇f (x(t) )(x − x(t) )
x
2
s.t. (∇cj (x(t) ))T (x − x(t) ) + cj (x(t) ) = 0, j = 1, 2, · · · , me ,
(∇cj (x(t) ))T (x − x(t) ) + cj (x(t) ) ≥ 0, j = me + 1, me + 2, · · · , m,
(18)
with
B (t) = ∇2xx L(x(t) , λ(t) ),
(19)
min

as proposed in Wilson (1963). The multiplier λ(t) is updated using the multipliers of the constraints in ( 18).
In terms of the step length α, Han (1977) proved that a one-dimensional
minimization of the non-differential exact penalty function
φ(x; %) = f (x) +

me
X

%j |cj (x)| +

j=1

m
X

%j |cj (x)|−

j=me +1

with |cj (x)|− = | min (0; cj (x)) |, as a merit function ϕ : R → R
ϕ(α) = φ(x(t) + αd(t) ),
with x(t) and d(t) fixed, leads to a step length α guaranteeing global convergence for values of the penalty parameters %j greater than some lower
bounds. Then, Powell (1978) proposed to update the penalty parameters
according to
1
+ |µj |), |µj |), j = 1, · · · , m,
%j = max( (%−
2 j
where µj denotes the Lagrange multiplier of the j-th constraint in the quadratic
problem and %−
j is the j-th penalty parameter of the previous iteration, starting with some %0j = 0.
It is important in practical applications to not evaluate B (t) in (19) in
every iteration, but to use only first order information to approximate the
Hessian matrix of the Lagrange function in (17). Powell (1978) proposed the
following modification:
B (t+1) = B (t) +

q (t) (q (t) )T
B (t) s(t) (s(t) )T B (t)
−
,
(q (t) )T s(t)
(s(t) )T B (t) s(t)
16

with
s(t) = x(t+1) − x(t)
q (t) = γt η (t) + (1 − γt )B (t) s(t)
where
η (t) = ∇x L(x(t+1) , λ(t) ) − ∇x L(x(t) , λ(t) )
and γt is chosen as
(
1
γt =
0.8(s(t) )T B (t) s(t)
(s(t) )T B (t) s(t) −(s(t) )T η (t)

if (s(t) )T η (t) ≥ 0.2(s(t) )T B (t) s(t) ,
otherwise,

which ensures that B (t+1) remains positive definite within the linear manifold
defined by the tangent planes to active constraints at x(t+1) .
In LCM, the problem turns out to be simpler: the quadratic programming
problem in (18) is only subject to me equality constraints. In addition, unless
we use Projected Quasi-Newton method, for which we have to build our own
solver, there is a popular implementation of SQP in Python’s SciPy package.
The package uses a variant of SQP: Sequential Least SQuares Programming
(SLSQP): It replaces the quadratic programming problem in (18) by a linear
least squares problem using a stable LDLT factorization of the matrix B (t) .
4. Simulation Studies and Real Data Analysis
In this section, we provide four example bundles and one real data analysis to demonstrate the performance of the proposed methods. The model
specifications of the four example bundles as follows:
• Example Bundle 1, N = 500: (A) d = 1, K = 2; (B) d = 1, K = 3; (C)
d = 2, K = 2; (D) d = 4, K = 2
• Example Bundle 2, N = 1000: (A) d = 2, K = 2; (B) d = 2, K = 3;
(C) d = 3, K = 2; (D) d = 3, K = 3
• Example Bundle 3, N = 2000: (A) d = 3, K = 3; (B) d = 3, K = 4;
(C) d = 4, K = 4; (D) d = 5, K = 3
• Example Bundle 4, N = 5000: (A) d = 4, K = 4; (B) d = 4, K = 5;
(C) d = 5, K = 4; (D) d = 5, K = 5
17

One dataset is simulated from latent class model for each combination. In
total, we consider 16 datasets with different combinations of sample size,
dimensionality and number of groups providing a comprehensive picture of
the model performance.
4.1. Example Bundle 1
In this example bundle, we use the following three methods to maximize the log-likelihood function: (1) EM, (2) SQP, and (3) Projected QuasiNewton (QN). Each method is repeated 10 times with different initial values
across the 10 runs. At each run, the three methods begin with identical initial
values. The true weights and categorical parameters are reported in Tables 8,
9, 10, 11 in the appendix. Side by side boxplots are drawn and reported in
Figure 1 and Figure 2 showing number of iterations and log-likelihood values
of the 10 runs, respectively. For each method, the best result based on the
log-likelihood values across the 10 runs are given in Table 1. Results from
the true parameters are also included in Table 1 as a comparison.

EM

Projected_QN

SQP

EM

Projected_QN

SQP

80
60
40
20
0

0

0

20

10

40

20

60

30

80

100

120

N=500_D=2_K=4

100

50
40

40
30
20
10
0

Number of Iterations

N=500_D=2_K=2
120

N=500_D=1_K=3

50

N=500_D=1_K=2

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 1: Example Bundle 1, N = 500; number of iterations for (A) d = 1, K = 2; (B)
d = 1, K = 3; (C) d = 2, K = 2; (D) d = 4, K = 2.

From Table 1, Figure 1 and Figure 2, we observe that the proposed two
optimization methods have good performance compared to the traditional
EM algorithm: the log-likelihood values are very close to that of EM for
all four datasets in this example bundle. Note that the vertical axis scales
are different in Figure 1. The numbers of iterations of the two proposed
optimization methods are obviously lower than that of EM, for example the
number of iterations of SQP and Projected QN are both 12 compared to 88
of the EM algorithm. This suggests that the two optimization methods are
18

Projected_QN

SQP

Projected_QN

SQP

−1323
−1324
−1325
−1326

−661.0
EM

N=500_D=2_K=4

−1322

−659.0
−660.0
−660.5

−345.0
−346.0
EM

N=500_D=2_K=2

−659.5

−343.0

N=500_D=1_K=3

−344.0

−334.5
−335.0
−335.5
−336.0

Log Likelihood

−334.0

N=500_D=1_K=2

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 2: Example Bundle 1, N = 500; log-likelihood values for (A) d = 1, K = 2; (B)
d = 1, K = 3; (C) d = 2, K = 2; (D) d = 4, K = 2.

Table 1: Example Bundle 1, N = 500; the best result based on the log-likelihood among
the 10 runs for each method.

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

(A) d = 1, K = 2
True Parameters
EM
−335.29
−335.25
N.A.
8
(B) d = 1, K = 3
True Parameters
EM
−344.49
−344.45
N.A.
9
(C) d = 2, K = 2
True Parameters
EM
−661.30
−659.75
N.A.
43
(D) d = 4, K = 2
True Parameters
EM
−1323.29
−1323.91
N.A.
88

19

SQP
−335.25
4

Projected QN
−335.25
4

SQP
−344.45
5

Projected QN
−344.45
4

SQP
−659.75
13

Projected QN
−659.75
12

SQP
−1323.80
31

Projected QN
−1324.46
30

less likely to get stuck in local maxima.
In addition, there are no substantial differences between the final best
solutions across the 10 runs. Actually, the final best results are quite close
to the results obtained from the other 9 runs. Using scenario (A) with d =
1, K = 2 in this bundle as an example, we divide the 10 log-likelihood values
into two groups, where the first group contains the largest log-likelihood
value only while the second group contains the rest of the nine log-likelihood
values, and then fit a non-parametric two-group Wilcoxon signed-rank test
Bauer (1972). The p-value is 0.20, which is clearly larger than the usual
0.05 threshold. The parametric t-test might not work well here because the
group sizes are too small. Moreover, the estimated weights and categorical
parameters from the 10 runs are also close to each other. We repeat the
test for the log-likelihood values on the estimates for each of the weight and
categorical parameters and none of the p-values are larger than 0.05.
4.2. Example Bundle 2
The true weights and categorical parameters are reported in Tables 12, 13,
14, 15 in the appendix. As in Example Bundle 1, each method is repeated
10 times with different initial values across the 10 runs. At each run, the
three methods begin with identical initial values. The simulation results for
this bundle are summarized in Figure 3 and 4 for number of iterations and
log-likelihood, respectively. Similarly, for each method, the best result based
on the log-likelihood values among the 10 runs are given in Table 2. Results
from the true parameters are also included in Table 2 for comparison.
From Table 2, Figure 3 and Figure 4, we observed a similar pattern as in
Example Bundle 1, i.e., the log-likelihood values are close to each other, however the number of iterations of the two optimization methods are smaller
than that of EM, further showing the promise of using the proposed optimization methods as alternatives in practice.

4.3. Example Bundle 3
With exactly the same settings, we report results for Example Bundle 3
in this section. The resulting number of iteration and log-likelihood values
are reported in Figure 5 and 6, respectively. For each method, the best result
based on the log-likelihood values among the 10 runs are given in Table 3.
Results from the true parameters are also included in Table 3 for comparison.
20

200

N=1000_D=3_K=3

150

150

80

80

200

N=1000_D=3_K=2

100

N=1000_D=2_K=3

EM

Projected_QN

SQP

100
50

0
EM

Projected_QN

SQP

0

50

40
20
0

20

40

100

60

60

●

0

Number of Iterations

100

N=1000_D=2_K=2

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 3: Example Bundle 2, N = 1000; number of iterations for (A) d = 2, K = 2; (B)
d = 2, K = 3; (C) d = 3, K = 2; (D) d = 3, K = 3.

EM

Projected_QN

SQP

EM

Projected_QN

SQP

−2274.0 −2273.5 −2273.0 −2272.5 −2272.0 −2271.5 −2271.0

N=1000_D=3_K=3

−2155.0 −2154.5 −2154.0 −2153.5 −2153.0 −2152.5 −2152.0

N=1000_D=3_K=2

−1679.0 −1678.5 −1678.0 −1677.5 −1677.0 −1676.5 −1676.0

Log Likelihood

N=1000_D=2_K=3

−1656.0 −1655.5 −1655.0 −1654.5 −1654.0 −1653.5 −1653.0

N=1000_D=2_K=2

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 4: Example Bundle 2, N = 1000; log-likelihood values for (A) d = 2, K = 2; (B)
d = 2, K = 3; (C) d = 3, K = 2; (D) d = 3, K = 3.

21

Table 2: Example Bundle 2, N = 1000; the best result based on the log-likelihood values
among the 10 runs for each method.

(A) d = 2, K = 2
True Parameters
EM
−1656.59
−1654.86
N.A.
65
(B) d = 2, K = 3
True Parameters
EM
−1679.85
−1677.68
N.A.
75
(C) d = 3, K = 2
True Parameters
EM
−2156.11
−2153.60
N.A.
165
(D) d = 3, K = 3
True Parameters
EM
−2274.72
−2272.53
N.A.
169

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

SQP
−1654.86
17

Projected QN
−1655.06
21

SQP
−1677.68
21

Projected QN
−1677.85
22

SQP
−2153.73
29

Projected QN
−2153.74
32

SQP
−2272.53
34

Projected QN
−2272.70
35

The true weights and categorical parameters are reported in Tables 16, 17,
18, 19 in the appendix.

400

400
200

600

800

N=2000_D=5_K=3

200

600

500
400
200
100

300

200
100

300

400

500

800

N=2000_D=4_K=4

600

N=2000_D=3_K=4

EM

Projected_QN

SQP

EM

Projected_QN

SQP

0

0

0

●

0

Number of Iterations

600

N=2000_D=3_K=3

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 5: Example Bundle 3, N = 2000; number of iterations for (A) d = 3, K = 3; (B)
d = 3, K = 4; (C) d = 4, K = 4; (D) d = 5, K = 3.

From Table 3, Figure 5 and Figure 6, we observed a similar pattern as
in the previous examples: the number of iterations of the two optimization
22

EM

Projected_QN

SQP

EM

Projected_QN

SQP

−6433.0 −6432.5 −6432.0 −6431.5 −6431.0 −6430.5 −6430.0

N=2000_D=5_K=3

−5239.0 −5238.5 −5238.0 −5237.5 −5237.0 −5236.5 −5236.0

N=2000_D=4_K=4

−3907.0 −3906.5 −3906.0 −3905.5 −3905.0 −3904.5 −3904.0

Log Likelihood

N=2000_D=3_K=4

−3889.0 −3888.5 −3888.0 −3887.5 −3887.0 −3886.5 −3886.0

N=2000_D=3_K=3

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 6: Example Bundle 3, N = 2000; log-likelihood values for (A) d = 3, K = 3; (B)
d = 3, K = 4; (C) d = 4, K = 4; (D) d = 5, K = 3.

Table 3: Example Bundle 3, N = 2000; the best result based on the log-likelihood values
among the 10 runs for each method.

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

(A) d = 3, K = 3
True Parameters
EM
−3888.77
−3887.30
N.A.
355
(B) d = 3, K = 4
True Parameters
EM
−3906.01
−3905.22
N.A.
464
(C) d = 4, K = 3
True Parameters
EM
−5241.99
−5237.39
N.A.
526
(D) d = 5, K = 3
True Parameters
EM
−6437.05
−6431.05
N.A.
533

23

SQP
−3887.30
23

Projected QN
−3887.30
28

SQP
−3905.22
26

Projected QN
−3905.38
34

SQP
−5237.37
51

Projected QN
−5237.41
46

SQP
−6431.07
53

Projected QN
−6431.07
48

methods are much smaller than that of EM, while the log-likelihood values
are quite close to each other for the three methods.
4.4. Example Bundle 4
The resulting number of iterations and log-likelihood values of Example
Bundle 4 are reported in Figure 7 and 8, respectively. For each method, the
best result based on the log-likelihood values among the ten runs are given
in Table 4. Results from the true parameters are also included in Table 4
for comparison. The true weights and categorical parameters are repeated
in Tables 20, 21, 22, 23 in the appendix.

Projected_QN

SQP

EM

Projected_QN

SQP

1000 1200
600
200
0

0

200

400

600
400

400
200
0
EM

N=5000_D=5_K=5

800

1000 1200
800

800
600

800
600
400
200
0

Number of Iterations

N=5000_D=5_K=4

1000

N=5000_D=4_K=5

1000

N=5000_D=4_K=4

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 7: Example Bundle 4, number of iterations.

These results in Example Bundle 4 further confirm what we have observed: with the same settings, the two optimization methods converge in
less iterations than EM, while they still yield comparable log-likelihood values
as EM. This strengthens the promise of using the two proposed optimization
methods as alternatives to EM when estimating a latent class model.
4.5. An Application
We now go back to the motivating example discussed in Section 1. The
data set is available in the R package BayesLCA. White et al. (2014) used a
K = 3 latent class model to fit the data using Gibbs sampler. It is clear that
this is an n = 240, d = 6 binary data set. We follow the recommendation of
Moran et al. (2004) and fit a K = 3 latent class model with (1) EM, (2) SQP,
and (3) Projected Quasi-Newton methods and 10 different initial points, and
the best result of each method is recorded based on the log-likelihood value.
The results are summarized in Table 5. The result from BayesLCA package
24

Projected_QN

SQP

EM

Projected_QN

SQP

−16660
−16690

−16685

−16680

−16675

−16670

−16665

−16320
−16325
−16340
−16350

−13315
−13310

−16345

−13320

−16335

−13330
−13325

−13120
−13140
−13180

EM

N=5000_D=5_K=5

−16330

−13335

−13100

●

−13160

Log Likelihood

N=5000_D=5_K=4

−13340

N=5000_D=4_K=5

−13080

N=5000_D=4_K=4

EM

Projected_QN

SQP

EM

Projected_QN

SQP

Figure 8: Example Bundle 4, log-likelihood.

Table 4: Example Bundle 4, the best result based on the log-likelihood values among the
10 runs for each method.

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

Log-Likelihood
Number of Iterations

(A) d = 4, K = 4
True Parameters
EM
−13105.82
−13093.78
N.A.
837
(B) d = 4, K = 5
True Parameters
EM
−13335.47
−13328.15
N.A.
852
(C) d = 5, K = 4
True Parameters
EM
−16336.15
−16325.38
N.A.
1028
(D) d = 5, K = 5
True Parameters
EM
−16684.59
−16670.12
N.A.
1038

25

SQP
−13093.98
43

Projected QN
−13093.92
42

SQP
−13327.94
48

Projected QN
−13328.02
40

SQP
−16325.18
76

Projected QN
−16326.06
73

SQP
−16669.97
82

Projected QN
−16670.17
80

(White et al., 2014) is also included. The side-by-side boxplots for number
of iterations and log-likelihood values of the 10 runs are reported in Figure 9.
Table 5: Performance of the three methods based on 10 runs for the application example.

−740

Projected QN
−746.8557
50

●

−755

−750

−745

SQP
−744.9672
44

−760

100

200

Log Likelihood

400
300

EM
−745.7291
302

0

Number of Iterations

Log-Likelihood
Number of Iterations

BayesLCA
−781.8063
N.A.

EM

Projected_QN

SQP

EM

(a) Number of Iterations

Projected_QN

SQP

(b) Log-Likelihood

Figure 9: Boxplots for the application example.

From Table 5, SQP has the best performance in terms both the loglikelihood value and the number of iterations. The results from EM and
Projected Quasi-Newton are very similar although EM needs way more iterations to converge. This agrees with the previous observations. We also note
that all the three methods considered have larger log-likelihood values than
that of BayesLCA. The method proposed by White et al. (2014) actually has
the smallest log-likelihood value.
In addition, since we do not know the true values, we computed pairwise
root mean squared error (RMSE) based on the estimates, i.e, we compute
RMSE of estimates for every two methods. Since we have considered four
26

different methods, we will have six RMSEs, one number for each pair of
methods. The results are reported in Table 6
Table 6: Pairwise root mean squared error (RMSE) of the four methods considered for
the application example.

BayesLCA
EM
SQP
Projected QN

BayesLCA
0
0.237
0.241
0.233

EM
0.237
0
0.029
0.046

SQP
0.241
0.029
0
0.045

Projected QN
0.233
0.046
0.045
0

The results in Table 6 are consistent with the observations we have made:
Since the log-likelihood values are closer for EM, SQP and Projected QN,
the pairwise RMSE of these three methods are way lower than those when
paired with BayesLCA, for example the RMSE of SQP and EM is 0.029,
while the RMSE for SQP and BayesLCA is 0.241, which is over eight times
larger.
5. Discussion
In the previous section, we have shown the number of iterations of the
proposed methods is smaller than that of the EM algorithm. In this section, we report the comparison of CPU times. Taking the application as an
example, the runtime are reported in Table 7.
Table 7: Comparison of CPU time (in seconds).

CPU Time per Iteration
Number of Iterations
Overall Runtime

EM
0.08
302
24.2

SQP
0.31
44
13.6

Projected QN
0.39
50
19.5

From Table 7, we can see that the EM algorithm indeed has the lowest
CPU time per iteration. However, when taking the number of iterations
27

into account, the story is different: using SQP as example, the number of
iterations of EM and SQP are 302 and 44, respectively. The number of
iterations for the SQP algorithm is around 1/8 of the EM algorithm, although
the CPU time per iteration is merely about four times longer. Therefore, the
total computational time of the SQP algorithm is significantly less than that
of the EM algorithm. In the application example, the computational times
of the SQP and Projected QN methods are respectively 43% and 19% better
compared to the EM algorithm.
6. Concluding Remarks
The primary research objective of the paper is to provide alternative
methods to learn the unknown parameters of the latent class model. Given
the log-likelihood as a function of the parameters, we aim to find estimators
that can maximize the log-likelihood function. The traditional way is to use
the EM algorithm. However, it is observed that the EM algorithm converges
slowly. Therefore, in this paper, we propose the use of two constrained
optimization methods, namely the Sequential Quadratic Programming and
the Projected Quasi-Newton methods as alternatives. Simulation studies
and the real example in Section 4 reveal that the two proposed methods
perform well. The obvious advantages we observed are as follows: (1) the two
optimization methods produced slightly larger log-likelihood values compared
to the EM algorithm; (2) they converge in significantly less iterations than
the EM algorithm. That being said, we want to make it clear that the
aim is not to completely replace the EM algorithm, rather we would like to
provide alternative ways of achieving the same goal using some optimization
methods. Inter-disciplinary collaboration between researchers in statistics
and mathematical optimization has never been as important as in the big
data era.
References
Asparouhov, T., Muthén, B., 2011. Using bayesian priors for more flexible
latent class analysis, American Statistical Association.
Bauer, D., 1972. Constructing confidence sets using rank statistics. Journal
of the American Statistical Association 67, 687–690.

28

Birgin, E.G., Martı́nez, J.M., Raydan, M., 2000. Nonmonotone spectral
projected gradient methods on convex sets. SIAM Journal on Optimization
10, 1196–1211.
Byrd, R.H., Nocedal, J., Schnabel, R.B., 1994. Representations of quasinewton matrices and their use in limited memory methods. Mathematical
Programming 63, 129–156.
Dempster, A.P., Laird, N.M., Rubin, D.B., 1977. Maximum likelihood from
incomplete data via the EM algorithm. Journal of the royal statistical
society. Series B (methodological) , 1–38.
Gower, R.M., Richtárik, P., 2017. Randomized quasi-newton updates are
linearly convergent matrix inversion algorithms. SIAM Journal on Matrix
Analysis and Applications 38, 1380–1409.
Hagenaars, J.A., McCutcheon, A.L., 2002. Applied latent class analysis. 64,
Cambridge University Press.
Han, S.P., 1977. A globally convergent method for nonlinear programming.
Journal of optimization theory and applications 22, 297–309.
Jamshidian, M., Jennrich, R.I., 1997. Acceleration of the EM algorithm
by using quasi-newton methods. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) 59, 569–587.
Kraft, D., 1988. A software package for sequential quadratic programming.
Forschungsbericht- Deutsche Forschungs- und Versuchsanstalt fur Luftund Raumfahrt .
Li, Y., Lord-Bessen, J., Shiyko, M., Loeb, R., 2018. Bayesian latent class
analysis tutorial. Multivariate behavioral research 53, 430–451.
McCutcheon, A.L., 1987. Latent class analysis. 64, Sage.
Meilijson, I., 1989. A fast improvement to the EM algorithm on its own
terms. Journal of the Royal Statistical Society. Series B (Methodological)
, 127–138.
Moran, M., Walsh, C., Lynch, A., Coen, R., Coakley, D., Lawlor, B., 2004.
Syndromes of behavioural and psychological symptoms in mild alzheimer’s
disease. International journal of geriatric psychiatry 19, 359–364.
29

Oser, J., Hooghe, M., Marien, S., 2013. Is online participation distinct from
offline participation? a latent class analysis of participation types and their
stratification. Political Research Quarterly 66, 91–101.
Powell, M.J., 1978. A fast algorithm for nonlinearly constrained optimization
calculations, in: Numerical analysis. Springer, pp. 144–157.
Schmidt, M., Berg, E., Friedlander, M., Murphy, K., 2009. Optimizing costly
functions with simple constraints: A limited-memory projected quasinewton algorithm, in: Artificial Intelligence and Statistics, pp. 456–463.
Wang, W., Carreira-Perpinán, M.A., 2013. Projection onto the probability
simplex: An efficient algorithm with a simple proof, and an application.
arXiv preprint arXiv:1309.1541 .
White, A., Murphy, T.B., et al., 2014. Bayeslca: An r package for bayesian
latent class analysis. Journal of Statistical Software 61.
Wilson, R.B., 1963. A simplicial algorithm for concave programming. Ph.
D. Dissertation, Graduate School of Bussiness Administration .
Wu, C.J., 1983. On the convergence properties of the EM algorithm. The
Annals of statistics , 95–103.

About the Authors
Hao Chen received his Ph.D. in Statistics from the University of British
Columbia and is currently a Senior Data Scientist at Precima. Lanshan
Han holds a Ph.D. in Decision Sciences and Engineering Systems from the
Rensselaer Polytechnic Institute and is currently a Director of Research and
Development at Precima. Alvin Lim received his Ph.D. in Mathematical
Sciences from the Johns Hopkins University and is currently Precimas Chief
Scientist and Vice President for Research and Development.

30

Appendix
The Python source codes for EM and Projected Quasi-Newton for LCM
are available upon request. The implementation of SQP is available in Python
SciPy package.
The true weights and parameters used in Section 4 are given below.
Example Bundle 1
Table 8: True Weights and Categorical Parameters for Example Bundle 1, d = 1, K = 2.

weights
K=1
K=2

0.5
0.5

d=1
0
1
0.4 0.6
0.8 0.2

Table 9: True Weights and Categorical Parameters for Example Bundle 1, d = 1, K = 3.

weights
K=1
K=2
K=3

0.5
0.3
0.2

d=1
0
1
0.4 0.6
0.8 0.2
0.1 0.9

Table 10: True Weights and Categorical Parameters for Example Bundle 1, d = 2, K = 2.

weights
K=1
K=2

0.5
0.5

d=1
0
1
0.4 0.6
0.8 0.2

31

d=2
0
1
0.1 0.9
0.6 0.4

Table 11: True Weights and Categorical Parameters for Example Bundle 1, d = 4, K = 2.

weights
K=1
K=2

0.5
0.5

d=1
0
1
0.4 0.6
0.8 0.2

d=2
0
1
0.1 0.9
0.6 0.4

d=2
0
1
0.5 0.5
0.4 0.6

d=2
0
1
0.6 0.4
0.7 0.3

Example Bundle 2
Table 12: True Weights and Categorical Parameters for Example Bundle 2, d = 2, K = 2.

weights
K=1
K=2

0.4
0.6

d=1
0
1
0.1 0.9
0.8 0.2

d=2
0
1
2
0.8 0.1 0.1
0.3 0.4 0.3

Table 13: True Weights and Categorical Parameters for Example Bundle 2, d = 2, K = 3.

weights
K=1
K=2
K=3

0.4
0.4
0.2

d=1
0
1
0.1 0.9
0.8 0.2
0.6 0.4

0
0.8
0.3
0.5

d=2
1
0.1
0.4
0.3

2
0.1
0.3
0.2

Table 14: True Weights and Categorical Parameters for Example Bundle 2, d = 3, K = 2.

weights
K=1
K=2

0.4
0.6

d=1
0
1
0.1 0.9
0.8 0.2

32

d=2
0
1
2
0.8 0.1 0.1
0.3 0.4 0.3

d=3
0
1
0.6 0.4
0.9 0.1

Table 15: True Weights and Categorical Parameters for Example Bundle 2, d = 3, K = 3.

weights
K=1
K=2
K=3

0.4
0.4
0.2

d=1
0
1
0.1 0.9
0.8 0.2
0.6 0.4

0
0.8
0.3
0.6

d=2
1
0.1
0.4
0.3

2
0.1
0.3
0.1

d=3
0
1
0.6 0.4
0.9 0.1
0.2 0.8

Example Bundle 3
Table 16: True Weights and Categorical Parameters for Example Bundle 3, d = 3, K = 3.

weights
K=1
K=2
K=3

0.3
0.4
0.3

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7

Table 17: True Weights and Categorical Parameters for Example Bundle 3, d = 3, K = 4.

weights
K
K
K
K

=1
=2
=3
=4

0.3
0.2
0.3
0.2

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5

33

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8

Table 18: True Weights and Categorical Parameters for Example Bundle 3, d = 4, K = 4.

weights
K
K
K
K

=1
=2
=3
=4

0.3
0.2
0.3
0.2

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8

d=4
0
1
0.6 0.4
0.5 0.5
0.7 0.3
0.5 0.5

Table 19: True Weights and Categorical Parameters for Example Bundle 3, d = 5, K = 3.

weights
K=1
K=2
K=3

0.3
0.4
0.3

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7

d=4
0
1
0.6 0.4
0.5 0.5
0.9 0.1

d=5
0
1
0.7 0.3
0.3 0.7
0.2 0.8

Example Bundle 4
Table 20: True Weights and Categorical Parameters for Example Bundle 4, d = 4, K = 4.

weights
K
K
K
K

=1
=2
=3
=4

0.3
0.2
0.3
0.2

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1

34

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8

d=4
0
1
0.6 0.4
0.5 0.5
0.7 0.3
0.5 0.5

Table 21: True Weights and Categorical Parameters for Example Bundle 4, d = 4, K = 5.

weights
K
K
K
K
K

=1
=2
=3
=4
=5

0.3
0.2
0.3
0.1
0.1

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5
0.8 0.2

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1
0.1 0.9

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8
0.9 0.1

d=4
0
1
0.6 0.4
0.5 0.5
0.7 0.3
0.5 0.5
0.7 0.3

Table 22: True Weights and Categorical Parameters for Example Bundle 4, d = 5, K = 4.

weights
K
K
K
K

=1
=2
=3
=4

0.3
0.2
0.3
0.2

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8

d=4
0
1
0.6 0.4
0.5 0.5
0.7 0.3
0.5 0.5

d=5
0
1
0.2 0.8
0.8 0.2
0.3 0.7
0.9 0.1

Table 23: True Weights and Categorical Parameters for Example Bundle 4, d = 5, K = 5.

weights
K
K
K
K
K

=1
=2
=3
=4
=5

0.3
0.2
0.3
0.1
0.1

d=1
0
1
0.9 0.1
0.2 0.8
0.1 0.9
0.5 0.5
0.8 0.2

d=2
0
1
0.3 0.7
0.5 0.5
0.4 0.6
0.9 0.1
0.1 0.9

35

d=3
0
1
0.1 0.9
0.55 0.45
0.3 0.7
0.2 0.8
0.9 0.1

d=4
0
1
0.6 0.4
0.5 0.5
0.7 0.3
0.5 0.5
0.7 0.3

d=5
0
1
0.4 0.6
0.7 0.3
0.4 0.6
0.8 0.2
0.9 0.1

