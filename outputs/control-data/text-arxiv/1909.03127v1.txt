arXiv:1909.03127v1 [math.NA] 5 Sep 2019

A Harten’s Multiresolution Framework
for Subdivision Schemes
Sergio López-Ureña
January 2019
Abstract
Harten’s Multiresolution framework has been applied in different contexts, such as in the numerical simulation of PDE with conservation laws
or in image compression, showing its flexibility to describe and manipulate the data in a multilevel fashion. Two basic operators form the basis
of this theory: the decimation and the prediction. The decimation is chosen first and determines the type of data that is being manipulated. For
instance, the data could be the point evaluations or the cell-averages of a
function, which are the two classical environments. Next, the prediction
is chosen, and it must be compatible with the decimation.
Subdivision schemes can be used as prediction operators, but sometimes they not fit into one of the two typical environments. In this paper
we show how to invert this order so we can choose a prediction first and
then define a compatible decimation from that prediction. Moreover, we
also prove that any possible decimation can be obtained in this way.

1

Introduction

Subdivision schemes are a valuable technique for the refinement of data, very
common in Computer Aided Geometric Design (CAGD) [11], that allows to
generate curves (or surfaces or even manifolds) from an initial discrete data set,
namely v 0 . A subdivision scheme recursively generates more and more data sets
v k , k ∈ Z+ , and produces a function from these data sets that it is used as the
parametrization of a geometrical object, if the scheme is convergent.
Despite that the subdivision was conceived with a geometrical purpose in
CAGD [12], other applications have been adopted it because of its easy implementation and flexibility to reach special properties. We are interested in
the presence of subdivision in multiresolution algorithms, with applications in
image processing [2, 6], optimization [10, 14] and uncertainty quantification [8],
among others.
Originally, Harten’s Mulitiresolution Framework (HMR-F) [13] provided a
set of tools that allows to define a consistent multi-scale structure for numerical
methods for conservation laws. Nevertheless, this theory is prepared for very

1

general multi-scale scenarios and over the years it were found applications in
other mathematical fields, for instance in the above mentioned applications
[2, 6, 10, 8, 14], where it was combined with subdivision schemes.
In HMR-F, two basic operations are present: decimation and prediction. In
[13] a very detailed study is found where the decimation is a linear operator
which is defined before the prediction. Then, a (possibly nonlinear) prediction
operator is picked, which must be consistent with the decimation previously
chosen. This order (first decimation, then prediction) is crucial in conservation
laws, because the decimation establishes if a cell-average or a point-value framework has been chosen, which indicates how the prediction should be designed.
In other applications, however, the prediction operators are subdivision
schemes and they seem to be more relevant than the decimation operators.
In fact, in [8, 10, 14], the decimation does not appear in the implementation
of the methods, despite being needed to describe the multiresolution structure.
The aim of this paper is to give theoretical support to this procedure. We will
not only prove that decimation operators can be defined consistently from linear
prediction operators (subdivision schemes), but also that every decimation operator chosen for a prediction operator can be derived from such prediction. Thus,
a well-defined multiresolution setting is always guaranteed in those applications
where the prediction is based on linear subdivision schemes.
The nonlinear subdivision schemes that have been applied in practical situations until now (see for example [1, 2, 3, 4, 5, 9, 10]) are usually compatible
with either the point-value framework or the cell-average framework. Since our
interest for the present work lays outside of these frameworks, we will focus only
on the linear case. This case is still of relevance since there are linear subdivision
schemes that do not fit in any of both common frameworks, such as the (exponential) B-Splines family of subdivision schemes [7, 11]. Our results provide
compatible decimation and discretization operations for these situations.
The paper is organized as follows: In Section 2, we introduce the main concepts of the HMR-F which are necessary to understand the situation we would
like to study. In Section 3 the construction of decimation and discretization
operators from linear prediction and reconstruction operators is performed, and
consequently, by Theorem 12 a complete multiresolution setting is obtained.
Morevoer, in Theorem 13 we prove that every linear multiresolution framework
can be built from the prediction and reconstruction operators. We apply our
results to a classical family of subdivision schemes in Section 4.

2

Harten’s Multiresolution Framework

In signal processing, data is often a discrete representation of a function. For
example, consider a digital photo of a landscape, which is actually a set of pixels.
Once the picture is taken, we can apply some treatments to it, such as denoising,
improving the resolution, object classification, etc. All these operations belong
to the signal processing field, and in particular, to image processing.
When a signal is processed, the discrete data is manipulated taking into

2

account the underlying continuous nature that it is approximating. In the previous example, to denoise (that is, to remove noise present in a picture) we may
assume that the color throughout the picture comes from a piecewise smooth
function, so isolated sudden changes in the color may be identify as noise.
Harten’s Multiresolution Framework (HMR-F) can be used to handle properly this kind of signals in a multi-scale fashion. A complete description of the
HMR-F can be found in [13]. This section is dedicated to recall some concepts
introduced there.
We assume that the function f that we want to manage belongs to a vector
space F and that, by performing certain method, we will obtain some discrete
data, which we will denote by v, belonging to some denumerable vector space
V . This process will be performed by what is called the discretization operator
D : F −→ V . In the example above, V represents the set of images (with a fixed
number and distribution of pixels) that can be taken with a digital camera.
Definition 1. Let F and V be vector spaces and D : F −→ V a linear operator
such that V = D(F ). If V has a denumerable basis, say {ηi }, then we say that
D is a discretization operator and we refer to v := Df as the discretization of
f.
The vector space V is usually a space of bounded sequences ℓ∞ (B) or of
square-summable sequences ℓ2 (B), where the indexes are on a discrete domain,
for instance B = Zs . An appropiate norm may be considered on the vector
space ℓ∞ (B) so that it has a denumerable Schauder basis, while ℓ2 (B) is a
Hilbert space. Classical examples of discretization operators are the point-value
operator and the cell-average operator. Let F be the set of bounded continuous
functions defined on R. Given X = (xi )i∈Z , a grid over R, the associated
point-value operator is defined as
D : F −→ ℓ∞ (Z),

D(f ) = (f (xi ))i∈Z ,

and for a given sequence of bounded intervals C = (ci )i∈Z , the associated cellaverage operator is defined as
Z
1
D : F −→ ℓ∞ (Z),
D(f ) =
f,
|ci | ci
R
where |ci | = ci 1 is the length of the interval.
The word multiresolution in HMR-F comes from the definition of several resolutions or scales, which can be thought of successive grids in the discretization
process. In order to achieve this structure, we need a sequence of discretization
operators fulfilling the nested condition (1).
Definition 2. Let {Dk }∞
k=0 be a sequence of discretization operators
Dk : F −→ V k ,

V k = Dk (F ) = span{ηik }.
i

We say that

{Dk }∞
k=0

is nested if for all f ∈ F and all k ≥ 0
Dk+1 f = 0

=⇒
3

Dk f = 0.

(1)

To get a nested sequence of point-value discretizations it is enough to take a
sequence of grids (X k )k≥0 satisfying X k ⊂ X k+1 , for instance X k = (i2−k )i∈Z .
Analogously, the cell-average case demands that each interval of C k is the union
of intervals in C k+1 , such as cki = [(i − 1/2)2−k , (i + 1/2)2−k ], C k = (cki )i∈Z ,
k
that satisfies ck+1
∪ ck+1
2i
2i+1 = ci .
It is said that the resolution level k + 1 is finer than k and, equivalently, the
space V k is coarser than V k+1 . Because of (1), these concepts are coherent and
allow us to define the decimation operators.
Definition 3. Let {Dk }∞
k=0 be a sequence of nested discretization operators.
k
We define the sequence of decimation operators {Dk+1
}∞
k=0 as
k
Dk+1
: V k −→ V k−1 ,

v k+1 = Dk+1 f 7→ v k = Dk f.

A decimation operator projects the data contained at a finer level to a coarser
one, without knowledge of the function f . In real applications this is essential,
since the only available data is discrete.
The multiresolution setting is defined as the set of all the spaces V k and the
k
decimation operators: ({V k }, {Dk+1
})∞
k=0 . In this framework there are other
relevant operators, the reconstruction operators, which takes discrete data and
tries to approximate the original function. Observe that interpolation techniques
can be used as reconstruction operators.
Definition 4. We say that R : V −→ F , V = D(F ), is a reconstruction
operator (compatible with D) if it is a right-inverse of D, i.e.
DR = I,

(2)

where I is the identity operator in V .
The condition (2) is known as consistency, and guarantees that Rk is injective:
Rk v k = Rk wk −→ v k = Dk Rk v k = Dk Rk wk = wk .
The reconstruction operator is crucial in practical applications to manage
the data among different V k (without knowing the true function f ). On the
k
sends vk+1 := Dk+1 f to v k := Dk f and, on the other hand, we
one hand, Dk+1
may consider the prediction operators, that from v k try to approximate v k+1 .
Definition 5. We say that {Pkk+1 }∞
k=0 are prediction operators for the mulk
tiresolution setting, if each one is a right inverse of Dk+1
in V k ,i.e.,
Pkk+1 : V k −→ V k+1 ,

k
Dk+1
Pkk+1 = Ik ,

k ≥ 0.

Observe that the prediction and the decimation are consistent (2). As proved
in [13, Theorem 3.2], there is a useful property that links the prediction and the
decimation with the reconstruction and the discretization:
Pkk+1 = Dk+1 Rk .

k
Dk+1
= Dk Rk+1 ,

(3)

The reconstruction and prediction operators may be nonlinear, which is interk
esting for some applications [1, 2, 3, 4, 5, 9, 10]. However, Dk+1
is always linear,
despite its relation with Rk according to (3).
4

3

Construction of multiresolution settings from
prediction operators

In the last section we showed that a multiresolution setting is defined through
the decimation operators, which in turn could be defined from nested discretization operators. From that, prediction operators are taken in a consistent way.
Here we prove that starting from a linear prediction and a reconstruction operators, which fulfill a certain property, we can always find an associated decimation
operator. This is done in one of the main results of this section, Theorem 12,
which can always be applied to linear convergent subdivision schemes. In particular, throughout this section the theory is applied to the (so-called) univariate,
uniform, local and binary subdivision schemes, a rather simple class of schemes.
Definition 6. A subdivision scheme is a sequence of operators {Pkk+1 : V k −→
V k+1 } such that
X
aki−2j vi ,
(Pkk+1 v)i =
j

for some sequences ak = {aki }i∈Z of compact support1 . It is convergent if
∀k ≥ 0

∀v k ∈ V k

L−1
L
PL−2
· · · Pkk+1 v k ,
∃ lim RL PL−1
L→∞

where the operator Rk : V k → F is defined as
X
Rk v k (t) :=
vik ψ(2k t − i),
ψ(t) := max{1 − |t|, 0}.
i∈Z

In Definition 6, Rk is the linear operator that, given v k , constructs the unique
piece-wise linear function with nodes at 2−k Z fulfilling Rk (v k )(i2−k ) = vik .
Hence, a subdivision scheme is convergent if, and only if, the sequence of piecewise linear functions converges to a function. A classical result in subdivision
theory is that ψ can be replaced by other continuous compactly supported function (see for example [11, Lemma 2.2]), although working with piece-wise linear
functions is usually preferable as they are easier to visualize.
Subdivision schemes are usually defined on V k = ℓ∞ (Z) and they converge in
F = C(R)∩L∞ (R), but, in practice, the data set is always finite, i.e. V k = Rnk .
Some of the following require V k and F to be Hilbert spaces, so henceforward
we suppose that
X
V k = ℓ2 (Z) := {v k :
|vik |2 < +∞},
i∈Z

F = L2 (R) := {f :

Z

|f (t)|2 < +∞}.

R

1 A function φ : A ⊂ R −→ R is of compact support if {t ∈ A : φ(t) 6= 0} is a compact
subset. A sequence a is of compact support if {i ∈ Z : ai 6= 0} is finite.

5

This choice of spaces trivially includes the finite case, since we can suppose
that the sequence is identically zero outside the range. Recall that their inner
products are
Z
X
huk , v k i 7→
uki vik ,
hf, gi 7→
f (t)g(t).
R

i∈Z

We can extend Definition 6 to HMR-F. The subdivision operators are clearly
prediction operators, while the piece-wise linear function is a reconstruction
operator.
Definition 7. Let {Pkk+1 }∞
k=0 be a sequence of injective operators such that
Pkk+1 : V k −→ V k+1 ,

V k = span{ηik }.

We say that {Pkk+1 }∞
k=0 is a convergent sequence of prediction operators in F
k
if there exists a sequence of injective operators {Rk }∞
k=0 , Rk : V −→ F , such
k
k+1
that Rk (V ) ⊂ Rk+1 (V
) and
L−1
L
∃ lim RL PL−1
PL−2
· · · Pkk+1 v k .

∀v k ∈ V k

∀k ≥ 0

L→∞

We remark that the operator in Definition 6 fulfills the condition Rk (V k ) ⊂
Rk+1 (V k+1 ) because ψ(t/2) = 12 ψ(t − 1) + ψ(t) + 12 ψ(t + 1). In addition,
P Rk can
be defined using other compactly supported ψ satisfying ψ(t/2) = bi ψ(t − i),
for some compactly supported sequence b = (bi ), which is a classic result in
subdivision theory. Indeed,
X
X
Rk v k (t) =
vik ψ(2k t − i) =
vik ψ((2k+1 t − 2i)/2)
i∈Z

=

X
i∈Z

=

i∈Z

vik

X

t − 2i − j)

j∈Z

X X

j∈Z

bj ψ(2

k+1

i∈Z

vik bj−2i

!

(4)

ψ(2k+1 t − j) = Rk+1 ṽ k (t),

where ṽjk := i∈Z vik bj−2i .
Now that we have chosen prediction and reconstruction operators from the
framework of subdivision schemes, we set to define discretization operators Dk
that are consistent with them. In the definitions above, applying the reconstruction operator to our data gives us a function, Rk v k , that should approximate f .
This motivates us to define Dk so that Rk v k is the best possible approximation
of f that Rk can reach. The next result, which is a direct application of the
Hilbert projection theorem to our setting, formalizes this idea.
P

Theorem 8. Let F be a Hilbert space and let Rk : V k −→ F be an injective
linear operator. Then the operator defined by
Dk f := argmin kf − Rk vk2
v∈V k

is well defined, linear and it is a left inverse of Rk , that is, Dk Rk = IVk .
6

Proof. Note that Vk := Rk (V k ) ⊂ F is a subspace of F because Rk is linear.
Given f ∈ F , using the orthogonal projection there exist two unique vectors f1 ∈
Vk , f2 ∈ Vk⊥ such that f = f1 + f2 , where f1 = PVk (f ) = argming∈Vk kf − gk2 ,
PVk being the orthogonal projection onto the set Vk . Since Rk is injective, there
exists one and only one v1 ∈ V k such that f1 = Rk (v1 ), so consequently v1 =
−1
argminv∈V k kf −Rk vk2 . Then Dk is defined as the composition Rk |Vk
◦PVk
and therefore the linearity follows directly form the linearity of both Rk and PVk .
−1
−1
Finally, since obviously PVk ◦Rk = Rk , Rk |Vk
◦PVk ◦Rk = Rk |Vk
◦Rk =
IVk .
From the last proof we deduce the following useful equality
f = Rk Dk f + f2 ∈ Vk ⊕ Vk⊥ .
Now that we got a sequence of discretization operators from {Rk }k≥0 , we
prove that it is nested.
Corolary 9. Let F be a Hilbert space, Rk : V k −→ F injective linear operators
satisfying Rk (V k ) ⊂ Rk+1 (V k+1 ), and Dk : F −→ V k defined as Dk f :=
argminv∈V k kf − Rk vk2 . Then {Dk } is a nested sequence of discretizations.
Proof. We have to prove that Dk+1 f = 0 ⇒ Dk f = 0. From Dk+1 f = 0 we
⊥
⊥
deduce that f = 0 + f2 ∈ Vk+1 ⊕ Vk+1
, thus f ∈ Vk+1
. But by hypothesis
⊥
⊥
Vk ⊂ Vk+1 , which implies Vk+1 ⊂ Vk . As a consequence f = 0 + f2 ∈ Vk ⊕ Vk⊥ ,
then Dk f = 0.
From now on we will assume that Pkk+1 is linear, so the following results
can only be applied to linear subdivision schemes. Nevertheless, the nonlinear
schemes developed in the literature [1, 2, 3, 4, 5, 9, 10] are usually designed in
the point-value or in the cell-average framework, so they do not need the theory
presented here.
Now, in order to get a similar definition for the decimation operators, we
apply Theorem 8 considering F = V k+1 and prediction operators instead of
reconstruction operators.
Corolary 10. Let V k , V k+1 be Hilbert spaces and let Pkk+1 : V k −→ V k+1 be
an injective linear operator. Then the operator defined by
k
v k+1 := argmin kv k+1 − Pkk+1 v k k2
Dk+1
v k ∈V k

k
is well defined, linear and it is a left inverse of Pkk+1 : Dk+1
Pkk+1 = IVk .

Note that both in Theorem 8 and in Corllary 10 different discretization and
decimation operators are obtained if the inner product is changed. To prove
Theorem 12, which deals with the consistency of these new operators, the next
inner product may be considered.

7

Lemma 11. Let F be a Hilbert space with inner product h·, ·i and let Vk be
another Hilbert space. Let Rk : Vk → F be a linear injective operator, and
denote for any v, w ∈ V k
hv, wik := hRk v, Rk wi.
Then h·, ·ik is an inner product of V k .
The
and we do not include it. We define kvkk :=
p proof is straightforward
hv, vik = kRk vk, ∀v ∈ V k .
Section 4.D. of [13], and in particular the Theorem 4.5, states that for any
convergent sequence of prediction operators {Pkk+1 } there exists a sequence of
reconstruction operators {RH
k } which are still consistent with {Dk }, fulfilling
Pkk+1 = Dk+1 RH
k = Dk+1 Rk and
k+1
= RH
RH
k+1 Pk
k .

(5)

This is an analogous result to the following well-known fact in subdivision theory
(see [11, Theorem 2.4]): For any convergent subdivision scheme, there exists a
compactly supported function φ such that
X
ai φ(2t − i).
(6)
φ(t) =
i

RH
k

Indeed,
hence (5).

is obtained if ψ = φ, since (4) with b = a implies ṽ k = Pkk+1 v k ,

Theorem 12. Let {Pkk+1 } be a convergent sequence of prediction operators. Let
k
H
us denote kv k kk,H := kRH
k v k, the derived norm of Lemma 11 applied to Rk .
Then
2
Dk f := argmin kf − RH
k vk ,
v∈V

k
w = argmin kw − Pkk+1 vk2k+1,H
Dk+1
v∈V k

k

k+1
are consistent discretization and decimation operators of RH
, respeck and Pk
tively. Furthermore the discretization operators are nested and

Pkk+1 = Dk+1 RH
k .

k
Dk+1
= Dk RH
k+1 ,

Proof. By hypothesis
H
H
2
Dk+1 RH
k w = argmin kRk w − Rk+1 vk .
v∈V k+1

Choosing v = Pkk+1 w and using (5),
k+1
H
H
H
H
RH
w = RH
k w − Rk+1 v = Rk w − Rk+1 Pk
k w − Rk w = 0.
k+1
As a consequence, Dk+1 RH
. On the other hand, using (5) and Lemma
k = Pk
H
11 for Rk+1 :
k+1
k+1
H
H
Dk RH
vk2 = argmin kRH
v)k2
k+1 w = argmin kRk+1 w − Rk+1 Pk
k+1 (w − Pk
v∈V k

= argmin kw −
v∈V k

v∈V k

Pkk+1 vk2k+1,H

8

=

k
Dk+1
w.

If we start by choosing the discretization operators when constructing a multiresolution framework, a consistent reconstruction must be selected afterwards,
and this choice is not unique. For instance, in the point-value framework, the
reconstruction can be any interpolation technique. The next result shows how
this fact is translated into our point of view, since we prove that, when starting
from the reconstruction technique, any consistent discretization operator can be
obtained as in Theorem 12 by choosing a suitable inner product for F .
Theorem 13. Let Dk , Rk be a consistent pair of discretization and reconstruction linear operators. Then, there exists a scalar product hh·, ·ii of F such that
Dk f = argmin |||f − Rk v|||2 ,
v∈V k

where |||f |||2 := hhf, f ii.
Proof. Let us consider Wk f = f −Rk Dk f , so the next decomposition is obtained
f = Wk f + Rk Dk f,
and an associated inner product
hhf, gii := hWk f, Wk gi + hRk Dk f, Rk Dk gi.
Indeed, it is an inner product because of the linearity of the involved operators
and the properties of the inner product h·, ·i. This is easy to check, so we will
only prove one of the properties as an example:
hhf, f ii = 0 → hWk f, Wk f i = 0
→ Wk f = 0

∧

∧

hRk Dk f, Rk Dk f i = 0

Rk Dk f = 0 → f = Wk f + Rk Dk f = 0.

For the new inner product, Wk (F ) and Rk Dk (F ) are orthogonal, as we prove
in what follows. First, note that
Wk Rk = Rk −Rk Dk Rk = Rk −Rk = 0,

Dk Wk = Dk −Dk Rk Dk = Dk −Dk = 0.

Then
hhWk f, Rk Dk gii = hWk Wk f, Wk Rk Dk gi + hRk Dk Wk f, Rk Dk Rk Dk gi
= hWk Wk f, 0i + h0, Rk Dk Rk Dk gi = 0.
p
Hence for |||f ||| := hhf, f ii, we have that
|||f − Rk v|||2 = |||Wk f + Rk Dk f − Rk v|||2

= |||Wk f + Rk (Dk f − v)|||2 = |||Wk f |||2 + |||Rk (Dk f − v)|||2 ,
and as a consequence
Dk f = argmin |||f − Rk v|||2 .
v∈V k

9

4

Computation of the decimation and discretization operators in a practical situation

In this section we apply the Theorem 12 to a subdivision
scheme of the form
P
specified in Definition 6 . That is (Pkk+1 v)i = j∈Z ai−2j vj , being a ∈ ℓ2 (Z)
compactly supported.
Let us consider V k = ℓ2 (Z). If the scheme converges, then exists
P a compactly
k
supported function φ satisfying (6). This implies that RH
v
:=
k
i∈Z vi φ(2 t−i),
because
X
X X

RH
vj φ(2k t − j) =
vj
ai φ(2k+1 t − 2j − i)
k v (t) =
j∈Z

=

X

j∈Z

=

X
i∈Z

j∈Z

vj

X

ai−2j φ(2

k+1

i∈Z

t − i) =

i∈Z

X

φ(2k+1 t − i)

i∈Z

X

ai−2j vj

j∈Z


k+1
(Pkk+1 v)i φ(2k+1 t − i) = RH
v (t).
k+1 Pk

Note that all the sums that appear in the calculations above are actually
finite sums given the compact support of both a and φ, so no arguments about
convergence are needed. Now, let us compute the expression of the discretization
operator given in Theorem 12, which is consistent with RH
k :
2
Dk f := argmin kf − RH
k vk ,

f ∈ L2 (R).

v∈V k

By Theorem 8, we know that Dk f = u with
H
H
⊥
f = RH
k u + f2 ∈ Rk (ℓ2 (Z)) ⊕ Rk (ℓ2 (Z)) .

Then, we have to find u ∈ ℓ2 (Z) such that
H
hf − RH
k u, Rk vi = 0 ∀v ∈ ℓ2 (Z).
R
P
Since i φ(t − i) = 1, we deduce that R φ = 1, which is a classic result on
subdivision theory. Then
Z
X
X
H
H
hf − Rk u, Rk vi = (f (t) −
ui φ(2k t − i))(
vj φ(2k t − j))dt
R

=

X

vj

X

vj

j∈Z

φ(2k t − j)f (t)dt −

Z

φ(2k t − j)f (t)dt −

R

j∈Z

=

i∈Z

Z

R

j∈Z

Z

X

ui vj

X

ui vj 2−k ηj−i

i,j∈Z

φ(2k t − i)φ(2k t − j)dt

R

i,j∈Z

R

where ηi := R φ(t)φ(t − i)dt. Again, φ being compactly supported makes all
the sums that appear above finite sums, and moreover ηj−i = 0 for |j − i| > M ,

10

M ∈ Z+ large enough. Therefore
hf −

H
RH
k u, Rk vi

=

X

vj

j∈Z

Z

k

φ(2 t − j)f (t)dt − 2

−k

R

A
X

uj−i ηi

i=−A

!

The right-hand side of this equality is 0 for all v ∈ ℓ2 (Z) if and only if there
exists u ∈ ℓ2 (Z) such that
A
X

ηi uj−i = 2k

Z

φ(2k t − j)f (t)dt,

R

i=−A

which is an infinite system of linear equations, whose matrix E = (ηi−j )i,j∈Z is
Toeplitz. Theorem 8 assures that the system has a unique solution because it
guarantees the existence of Dk , but to find an explicit expression is not always
possible, so numerical algorithms specialized in Toeplitz systems may be needed.
To illustrate this process with an easy example, let us consider the subdivision scheme (Pkk+1 v)2i = (Pkk+1 v)2i+1 = vi , which can also be written as
P
(Pkk+1 v)i = j ai−2j vi with a1 = a0 = 1 and ai = 0 for all i 6∈ {0, 1}, where
φ is just the box function φ(t) = χ[0,1) (t). We will call this scheme the Step
Scheme, which is closely related with the Haar wavelet. Now η0 = 1 and ηi = 0
for i 6= 0, and the system of equations becomes diagonal:
uj = 2

k

Z

k

φ(2 t − j)f (t)dt = 2

k

Z

2−k (j+1)

f (t)dt.

2−k j

R

R 2−k (i+1)
Observe that, in this particular case, (Dk f )i = 2k 2−k i
f (t)dt, which is the
cell-average discretization.
Now, to get the decimation operators which are consistent with our choice
of a subdivision scheme, we compute the inner product of Theorem 12:
X
X
H
hv, wik,H = hRH
vi φ(2k t − i),
wj φ(2k t − j)i
k v, Rk wi = h
i∈Z

=

X

j∈Z

vi wj hφ(2k t − i), φ(2k t − j)i = 2−k

i,j∈Z

X
i∈Z

= 2−k v T Ew,

vi

A
X

wi−j ηj

j=−A

T
where, in the last line, v and w are considered column
P vectors, denoting by v
−k
its transpose. For the Step Scheme, hv, wik,H = 2
i∈Z vi wi , and we will see
that the associated decimation operator is just the one corresponding to the cellaverage framework. Recall from Theorem 12 the definition of the decimation
operator:
k
Dk+1
w = argmin kw − Pkk+1 vk2k+1,H .
v∈V k

11

k
As above, we know by Theorem 8 that Dk+1
w = u with w−Pkk+1 u ∈ Pkk+1 (ℓ2 (Z))⊥ ,
but now the orthogonality is with respect to the product h·, ·ik+1,H , so now our
equation is
hw − Pkk+1 u, Pkk+1 vik+1,H = 0,
∀v ∈ ℓ2 (Z).

This expression can be straightforwardly developed: for all v ∈ ℓ2 (Z),
0 = hw − Pkk+1 u, Pkk+1 vik+1,H = 2−k−1 (Pkk+1 v)T E(w − Pkk+1 u)
= 2−k−1 v T (Pkk+1 )T E(w − Pkk+1 u)
if, and only if, (Pkk+1 )T EPkk+1 u = (Pkk+1 )T Ew. This is again a Toeplitz system,
as we prove in the following by checking that


(Pkk+1 )T EPkk+1 m,n = (Pkk+1 )T EPkk+1 m−n,0 ,
∀m, n ∈ Z.
(7)

Denoting by δ n the Kronecker delta,

(Pkk+1 )T EPkk+1 m,n = (δ m )T (Pkk+1 )T EPkk+1 δ n = (Pkk+1 δ m )T E(Pkk+1 δ n ),
P
but (Pkk+1 δ n )i = j∈Z ai−2j δjn = ai−2n , so
X

ai−2m ηi−j aj−2n .
(Pkk+1 )T EPkk+1 m,n = ((ai−2m )i∈Z )T E(ai−2n )i∈Z =
i,j∈Z

Taking the correct values of i, j, for the right side of (7) we obtain
X

(Pkk+1 )T EPkk+1 m−n,0 =
ai−2m+2n ηi−j aj .
i,j∈Z

With a simple change of summation variables, now we can see that (7) holds
true.
For the Step Scheme, this Toeplitz matrix is a diagonal matrix with constant
diagonal 2:
X

((Pkk+1 )T EPkk+1 m,n =
ai−2m+2n ηi−j aj
i,j∈Z

=

X

ai−2m+2n ai = a2(n−m) + a1+2(n−m) ,

i∈Z

which is 2 if n = m and 0 if n 6= m. Hence 2u = (Pkk+1 )T Ew. The right part
can be calculated analogously:
X
2un = (Pkk+1 δ n )T Ew = (ai−2n )i∈Z )T Ew =
ai−2n ηi−j wj
i,j∈Z

=

X

η2n−j wj + η2n+1−j wj = w2n + w2n+1 .

j∈Z

Finally we have arrived at our desired conclusion since we have obtained that
1
(w2i + w2i+1 ),
2
which is the usual decimation in the cell-average framework.
(Dkk−1 w)i = ui =

12

References
[1] Sergio Amat, Karine Dadourian, and Jacques Liandrat. Analysis of a class
of nonlinear subdivision schemes and associated multiresolution transforms.
Advances in computational Mathematics, 34(3):253–277, 2011.
[2] Sergio Amat, Rosa Donat, Jacques Liandrat, and J Carlos Trillo. Analysis
of a new nonlinear subdivision scheme. applications in image processing.
Foundations of Computational Mathematics, 6(2):193–225, 2006.
[3] Sergio Amat and Jacques Liandrat. On the stability of the pph nonlinear
multiresolution. Applied and computational harmonic analysis, 18(2):198–
206, 2005.
[4] Francesc Aràndiga, Rosa Donat, and Maria Santágueda. The pchip subdivision scheme. Applied Mathematics and Computation, 272:28–40, 2016.
[5] Muhammad Aslam. A family of 5-point nonlinear ternary interpolating
subdivision schemes with c2 smoothness. Mathematical and Computational
Applications, 23(2):18, 2018.
[6] Albert Cohen and Basarab Matei. Nonlinear subdivision schemes: applications to image processing. In Tutorials on Multiresolution in Geometric
Modelling, pages 93–97. Springer, 2002.
[7] Costanza Conti and Lucia Romani. Algebraic conditions on non-stationary
subdivision symbols for exponential polynomial reproduction. Journal of
Computational and Applied Mathematics, 236(4):543–556, 2011.
[8] Rosa Donat and Sergio López-Ureña. High-accuracy approximation of
piecewise smooth functions using the truncation and encode approach. Applied Mathematics and Nonlinear Sciences, 2(2):367–384, 2017.
[9] Rosa Donat and Sergio López-Ureña. Nonlinear stationary subdivision schemes that reproduce trigonometric functions. arXiv preprint
arXiv:1809.03731, 2018.
[10] Rosa Donat, Sergio López-Ureña, and Marc Menec. A novel multi-scale
strategy for multi-parametric optimization. In European Consortium for
Mathematics in Industry, pages 593–600. Springer, 2016.
[11] Nira Dyn. Subdivision schemes in cagd. Advances in numerical analysis,
2:36–104, 1992.
[12] Nira Dyn, David Levine, and John A Gregory. A butterfly subdivision
scheme for surface interpolation with tension control. ACM transactions
on Graphics (TOG), 9(2):160–169, 1990.
[13] Ami Harten. Multiresolution representation of data: A general framework.
SIAM Journal on Numerical Analysis, 33(3):1205–1256, 1996.
13

[14] S López-Ureña, JR Torres-Lapasió, R Donat, and MC Garcı́a-AlvarezCoque. Gradient design for liquid chromatography using multi-scale optimization. Journal of Chromatography A, 1534:32–42, 2018.

14

