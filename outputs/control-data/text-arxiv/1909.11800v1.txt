Deep Learning for RF Signal Classification in
Unknown and Dynamic Spectrum Environments
Yi Shi∗ , Kemal Davaslioglu∗ , Yalin E. Sagduyu∗ , William C. Headley† , Michael Fowler† , and Gilbert Green‡
∗ Intelligent

Automation, Inc., Rockville, MD, USA
Tech, Blacksburg, VA, USA
‡ US Army, APG, MD, USA
Email: {yshi, kdavaslioglu, ysagduyu}@i-a-i.com, {cheadley, mifowler}@vt.edu, gilbert.s.greeen2.civ@mail.mil

arXiv:1909.11800v1 [cs.NI] 25 Sep 2019

† Virginia

Abstract—Dynamic spectrum access (DSA) benefits from detection and classification of interference sources including innetwork users, out-network users, and jammers that may all
coexist in a wireless network. We present a deep learning based
signal (modulation) classification solution in a realistic wireless
network setting, where 1) signal types may change over time;
2) some signal types may be unknown for which there is no
training data; 3) signals may be spoofed such as the smart
jammers replaying other signal types; and 4) different signal
types may be superimposed due to the interference from concurrent transmissions. For case 1, we apply continual learning and
train a Convolutional Neural Network (CNN) using an Elastic
Weight Consolidation (EWC) based loss. For case 2, we detect
unknown signals via outlier detection applied to the outputs
of convolutional layers using Minimum Covariance Determinant
(MCD) and k-means clustering methods. For case 3, we extend
the CNN structure to capture phase shifts due to radio hardware
effects to identify the spoofing signal sources. For case 4, we apply
blind source separation using Independent Component Analysis
(ICA) to separate interfering signals. We utilize the signal classification results in a distributed scheduling protocol, where innetwork (secondary) users employ signal classification scores to
make channel access decisions and share the spectrum with each
other while avoiding interference with out-network (primary)
users and jammers. Compared with benchmark TDMA-based
schemes, we show that distributed scheduling constructed upon
signal classification results provides major improvements to innetwork user throughput and out-network user success ratio.
Index Terms—Signal classification, deep learning, continual
learning, outlier detection, jammer detection, source separation,
distributed scheduling.

I. I NTRODUCTION
Wireless networks are characterized by various forms of
impairments in communications due to in-network interference
(from other in-network users), out-network interference (from
other communication systems), jammers, channel effects (such
as path loss, fading, multipath and Doppler effects), and traffic
congestion. To support dynamic spectrum access (DSA), innetwork users need to sense the spectrum and characterize
interference sources hidden in spectrum dynamics.
Machine learning provides automated means to classify
received signals. Supported by recent computational and alDISTRIBUTION A. Approved for public release: distribution unlimited.
c
2019 IEEE. Personal use of this material is permitted. Permission from
IEEE must be obtained for all other uses, in any current or future media,
including reprinting/republishing this material for advertising or promotional
purposes, creating new collective works, for resale or redistribution to servers
or lists, or reuse of any copyrighted component of this work in other works.

gorithmic advances, deep learning is promising to extract and
operate on latent representations of spectrum data that conventional machine learning algorithms have failed to achieve. In
particular, deep learning can effectively classify signals based
on their modulation types [1]–[7]. Manifested in available
datasets (e.g., [1], [7]) for training wireless signal classifiers,
a common practice in previous studies is to assume that signal
types are known, remain unchanged, and appear without any
interference and spoofing effects. However, those assumptions
are typically invalid in a realistic wireless network, where
1) signal types change over time;
2) some signal types are not known a priori and therefore
there is no training data available for those signals;
3) signals are potentially spoofed, e.g., a smart jammer may
replay received signals from other users thereby hiding
its identity; and
4) signals are superimposed due to the interference effects
from concurrent transmissions of different signal types.
It is essential to incorporate these four realistic cases (illustrated in Fig. 1) in building the RF signal classifier so
that its outcomes can be practically used in a DSA protocol.
We consider a wireless signal classifier that classifies signals
based on modulation types into idle, in-network users (such as
secondary users), out-network users (such as primary users),
and jammers. Using the signal classification results, in-network
users allocate time slots for collision-free scheduling in a
distributed setting and share the spectrum with each other
while protecting out-network user transmissions and avoiding
interference from jammers.
Assuming that different signal types use different modulations, we present a convolutional neural network (CNN) that
classifies the received I/Q samples as idle, in-network signal,
jammer signal, or out-network signal. We start with the simple
baseline scenario that all signal types (i.e., modulations) are
fixed and known (such that training data are available) and
there are no superimposed signals (i.e., signals are already
separated). The average accuracy over all signal-to-noise-ratios
(SNRs) is 0.934. We then extend the signal classifier to operate
in a realistic wireless network as follows.
1) New modulations appear in the network over time (see
case 1 in Fig. 1) and should be classified as specified
signal types. Instead of retraining the signal classifier,

Baseline

Case 2: Unknown Signals

Case 1: New Signals

Transmitter
Signal types: S1, S2, …

Receiver

Transmitter
Receiver
Existing signal types: S1, S2, …
New (known) signal types: N1, N2, …

Case 4: Superimposed Signals

Case 3: Replay Attack
Replay the Signal:

Steal the Signal:

Receiver

Transmitter
Signal types: S1, S2, …

Jammer

Transmitter
Receiver
Known signal types: S1, S2, …
Unknown signal types: U1, U2, …

Transmitter
Signal types: S1, S2, …

Receiver

Jammer
Replayed Signal types: S1, S2, …

Transmitter
Signal types: S1, S2, …

Receiver

Jammer
Signal types: J1, J2, …

Fig. 1. RF signal classification cases, including new signals, unknown signals, replay attacks from jammers, and superimposed signals.

we design a continual learning algorithm [8] to update
the classifier with much lower cost, namely by using
an Elastic Weight Consolidation (EWC). This approach
achieves over time the level of performance similar to
the ideal case when there are no new modulations.
2) Some signal types such as modulations used in jammer
signals are unknown (see case 2 in Fig. 1) such that there
is no available training data for supervised learning. We
present an outlier detection solution to achieve high accuracy in classifying signals with unknown jamming signals. For that purpose, we apply Minimum Covariance
Determinant (MCD) and k-means clustering methods at
the outputs of the signal classifier’s convolutional layers.
This approach successfully classifies all inliers and most
of outliers, achieving 0.88 average accuracy.
3) Smart jammers launch replay attacks by recording signals from other users and transmitting them as jamming
signals (see case 3 in Fig. 1). We extend the CNN
structure to capture phase shift due to radio hardware
effects to identify the spoofing signals and relabel them
as jammers. This approach achieves 0.972 accuracy in
classifying superimposed signals.
4) Wireless signals are received as superimposed (see case
4 in Fig. 1) if transmitted at the same time (on the same
frequency). We apply blind source separation using Independent Component Analysis (ICA) [9] to obtain each
single signal that is further classified by deep learning.
This approach achieves 0.837 average accuracy.
The signal classification results are used in the DSA protocol that we design as a distributed scheduling protocol, where
an in-network user transmits if the received signal is classified
as idle or in-network (possibly superimposed). If the received
signal is classified as in-network, the in-network user needs
to share the spectrum with other in-network user(s) based on

the confidence of its classification. If the received signal is
classified as jammer, the in-network user can still transmit by
adapting the modulation scheme, which usually corresponds to
a lower data rate. We assume that a transmission is successful
if the signal-to-interference-and-noise-ratio (SINR) at the receiver is greater than or equal to some threshold required by
a modulation scheme. If out-network signals are detected, the
in-network user should not transmit to avoid any interference,
i.e., out-network users are treated as primary users. Results
show that this approach achieves higher throughput for innetwork users and higher success ratio for our-network users
compared with benchmark (centralized) TDMA schemes.
The rest of the paper is organized as follows. Section II
discusses related work. Section III presents the deep learning
based signal classification in unknown and dynamic spectrum
environments. Section IV introduces the distributed scheduling
protocol as an application of deep learning based spectrum
analysis. Section V concludes the paper.
II. R ELATED W ORK
Signal classification is an important functionality for cognitive radio applications to improve situational awareness (such
as identifying interference sources) and support DSA. The traditional approaches for signal classification include likelihood
based methods or feature based analysis on the received I/Q
samples [10]–[12]. However, these two approaches require
expert design or knowledge of the signal. They also add
complexity to a receiver since the raw I/Q data must be
manipulated before classification.
By learning from spectrum data, machine learning has found
rich applications in wireless communications [13], [14]. In
particular, deep learning has been applied to learn complex
spectrum environments, including spectrum sensing by a CNN
[15], spectrum data augmentation by generative adversarial

network (GAN) [16], [17], channel estimation by a feedforward neural network (FNN) [18], and jamming/anti-jamming
with FNN in training and test times [19]–[21]. Modulation
classification has been extensively studied with deep neural
networks [1]–[6], where the goal is to classify a given isolated
signal to a known modulation type. In [7], the performance
of modulation classification was evaluated with over-the-air
measurements. [22] shows that in performance real-world
systems depends on whether the training dataset fully captures
the variety of interference and hardware types in the real radio
environment. Those approaches cannot be readily applied in
a wireless network setting, as they do not capture dynamic
and unknown signal types, smart jammers that may spoof
signal types (e.g., signals may be generated through the GAN
[23]) and superposition of signals types due to concurrent
transmissions. In this paper, we address these issues to make
signal classification applicable for use in a DSA protocol.
III. D EEP L EARNING BASED S PECTRUM A NALYSIS
We consider different modulation schemes used by different
types of users transmitting on a single channel. We start
with the baseline case where modulations used by different
user types are known and there is no signal superposition
(i.e., interfering sources are already separated). We categorize
modulations into four signal types:
1) idle: no signal
2) in-network user signals: QPSK, 8PSK, CPFSK
3) jamming signals: QAM16, QAM64, PAM4, WBFM
4) out-network user signals: AM-SSB, AM-DSB, GFSK
There are in-network users (trying to access the channel
opportunistically), out-network users (with priority in channel
access) and jammers that all coexist. Out-network users are
treated as primary users and their communications should be
protected. Without prior domain knowledge other than training
data, an in-network user classifies received signals to idle, innetwork, jammer, or out-network. The classifier computes a
score vector (p0 , pin , pjam , pout ) for each instance, where p0 ,
pin , pjam , and pout are the likelihood scores for classifying
signals as idle, in-network, jammer, and out-network, respectively. If one score is larger than the other three, the instance
is classified as the corresponding case.
A. The Classifier Structure and Performance
We use the dataset in [1]. Each sample in the dataset consists
of 128 complex valued data points, i.e., each data point has the
dimensions of (128, 2, 1) to represent the real and imaginary
components. We use 10 modulations (QPSK, 8PSK, QAM16,
QAM64, CPFSK, GFSK, PAM4, WBFM, AM-SSB, and AMDSB) collected over a wide range of SNRs from -20 dB to
18 dB in 2 dB increments. These modulations are categorized
into signal types as discussed before. At each SNR, there are
1000 samples from each modulation type. Instead of using
a conventional feature extraction or off-the-shelf deep neural
network architectures such as ResNet, we build a custom deep
neural network that takes I/Q data as input.

Input
data

Output

Convolutional

MaxPooling

Dense

Dropout

Fig. 2. CNN classifier structure for RF signal classification.

We train a CNN classifier that consists of several convolutional layers and fully connected layers in the last three stages.
However, when the filter size in the convolutional layers is not
divisible by the strides, it can create checkerboard effects (see
[24] for more details). In the CNN classifier structure, shown
in Fig. 2, we paid attention to avoid the checkerboard effects
and used the following layers:
• Input shape: (128, 2)
• 2D ZeroPadding with size (1, 1)
• Convolutional layer with 128 filters with size of (3, 3)
• 2D MaxPolling layer with size (2, 1) and stride (2, 1)
• Five cascades of the following:
– 2D Zeropadding with size (1, 1)
– Convolutional layer with 256 filters with size of
(3, 3)
– 2D MaxPolling layer with pool size (2, 2) and stride
(2, 1)
• Fully connected layer with 256 neurons and Scaled Exponential Linear Unit (SELU) activation function, which
is x if x > 0 and aex − a if x ≤ 0 for some constant a
• Dropout with probability 0.5
• Fully connected layer with 64 neurons and SELU activation function
• Dropout with probability 0.5
• Fully connected layer with 4 neurons and SELU activation function
The classifier is trained in TensorFlow [25]. The ADAM
optimizer [26] is used with a step size of 5 × 10−5 and the
categorical cross-entropy loss function is used for training.
Cross-entropy function is given by
X
L(θ) = −
βi log(yi ),
(1)
i

where θ is the set of the neural network parameters and
{βi }m
i=1 is a binary indicator of ground truth such that βi = 1
only if i is the correct label among m classes (labels). The
neural network output y ∈ Rm is an m-dimensional vector,
where each element in yi ∈ y corresponds to the likelihood of
that class being correct.
We split the data into 80% for training and 20% for testing.
The loss function and accuracy are shown in Fig. 3 as a
function of training epochs. The testing accuracy is 0.934.
Fig. 4 shows the average confusion matrix of the classifier
over all SNR levels. Table I shows the average accuracy vs.

B. Continual Learning

0.00

0.00

0.00

In-network

0.00

0.27

0.00

0.00

Jammer

0.00

0.00

0.34

0.00

Out-network

0.00

0.00

0.04

0.23

r
e
m

O

u
tn
e

Ja
m

In
-n
e

tw
o
rk

0.09

tw
o
rk

Idle

Id
le

True label

Fig. 3. CNN classifier performance.

Predicted label

Fig. 4. Confusion matrix (averaged over all SNRs).

SNR over all types of signals. The SNR levels are from 0 to
18dB in 2dB increments. Fig. 5 shows confusion matrices at
0dB, 10dB, and 18dB SNR levels.

TABLE I
CNN CLASSIFIER ACCURACY ( AVERAGED OVER ALL SIGNAL TYPES ).

SNR (dB)
0
2
4
6
8

Accuracy
0.906
0.930
0.928
0.933
0.934

SNR (dB)
10
12
14
16
18

Accuracy
0.942
0.950
0.951
0.933
0.934

So far, we assumed that all modulation types are available
in training data. We now consider the case that initially five
modulations are taught to the classifier. Over time, three new
modulations are introduced. Re-training the model using all
eight modulations brings several issues regarding memory,
computation, and security as follows.
• Memory: Previous data needs to be stored.
• Computation: Retraining using the complete dataset will
take longer.
• Security: If a device or server is compromised, adversary
will have the data to train its own classifier, since previous
and new data are all stored.
On the other hand, if a model is re-trained using the new three
modulations with Stochastic Gradient Descent (SGD), performance on the previous five modulations drops significantly
(see Fig. 6). This is called catastrophic forgetting [27], [28]. In
Fig. 6, Task A is the classification of first five modulations and
Task B is the classification of the next three new modulations.
SGD suffers from catastrophic forgetting and its accuracy on
Task A drops to 0.37 when retrained with Task B.
We apply EWC to address this problem. EWC slows down
learning on selected neural network weights to remember
previously learned tasks (modulations) [28]. EWC augments
loss function using Fisher Information Matrix that captures the
similarity of new tasks and uses the augmented loss function
L(θ) given by
Xλ
∗
Fi (θi − θA,i
)2 ,
(2)
L(θ) = LB (θ) +
2
i
where θA denotes the weights used to classify the first five
modulations (Task A), LB (θ) is the loss function for Task
B, Fi is the fisher information matrix that determines the
importance of old and new tasks, and i denotes the parameters
of a neural network. Higher values on the Fisher diagonal
elements Fi indicate more certain knowledge, and thus they are
less flexible. This approach helps identify and protect weights.
In Fig. 6, we can see that EWC mitigates catastrophic learning
to improve the accuracy on Task B such that the accuracy
increases over time to the level of Task A.
C. Classifier for Unknown Type of Signals
So far, we assumed that all signals including those from
jammers are known (inlier) and thus they can be included in
the training data to build a classifier. This assumption is reasonable for in-network and out-network user signals. However,
jamming signals are possibly of an unknown type (outlier).
Then a classifier built on known signals cannot accurately
detect a jamming signal. An outlier detection is needed as
a robust way of detecting if the (jamming) signal is known or
unknown. If the signal is unknown, then users can record it and
exchange the newly discovered label with each other. If the
signal is known, then the signal passes through the classifier
to be labeled. For the outlier detection, as the waveform
dimensions are large, we reuse the convolutional layers of the

0.00

Idle

0.10

0.00

0.00

0.00

In-network

0.00

0.27

0.00

0.00

In-network

0.00

0.27

0.00

0.00

In-network

0.00

0.26

0.00

0.00

Jammer

0.00

0.00

0.32

0.02

Jammer

0.00

0.00

0.35

0.02

Jammer

0.00

0.00

0.34

0.00

Out-network

0.00

0.00

0.06

0.22

Out-network

0.00

0.00

0.04

0.24

Out-network

0.00

0.00

0.04

0.24

Predicted label

(a) 0 dB.

(b) 10 dB.

r
e
m

O

u
tn
e

Ja
m

u
tn
e

In
-n
e

r
e
m
Ja
m

O

O

In
-n
e

u
tn
e

Id
le

tw
o
rk

r
e
m
Ja
m

In
-n
e

Predicted label

tw
o
rk

0.00

tw
o
rk

0.00

Id
le

0.09

True label

Idle

tw
o
rk

0.00

tw
o
rk

0.00

True label

0.00

tw
o
rk

0.09

Id
le

True label

Idle

Predicted label

(c) 18 dB.

Fig. 5. Confusion matrices at different SNR values.

Fig. 7. MCD-based classifier accuracy on inliers and outliers.

Fig. 6. Classifier performance over time.

classifier to extract the features of the received signal. Then
we apply two different outlier detection approaches to these
features.
1) MCD-based Classifier: The first method for the outlier
detection is based on the Minimum Covariance Determinant
(MCD) method [29], [30]. MCD fits an elliptic envelope to
the test data such that any data point outside the ellipse is
considered as an outlier. MCD uses the Mahalanobis distance
to identify outliers:
q
M D(x) = (x − µx )T (Sx )−1 (x − µx ) ,
(3)
where µx and Sx are the mean and covariance of data x,
respectively. We tried two approaches: i) directly apply outlier
detection using MCD and ii) extract features and apply MCD
outlier detection to these features.
The evaluation settings are as the following:
• Inlier signals: QPSK, 8PSK, CPFSK, AM-SSB, AMDSB, GFSK
• Outlier signals: QAM16, QAM64, PAM4, WBFM

The second approach of feature extraction followed by outlier
detection yields the best performance. In the feature extraction
step, we freeze the model in the classifier and reuse the
convolutional layers. The output of convolutional layers in the
frozen model are then input to the MCD algorithm. MCD
algorithm has a variable called contamination that needs to be
tuned. Contamination accounts for the estimated proportion of
outliers in the dataset. In the training step of MCD classifier,
we only present the training set of known signals (in-network
and out-network user signals), while in the validation step, we
test the inlier detection accuracy with the test set of inliers
and test the outlier detection accuracy with the outlier set
(jamming signals). When some of the jammer characteristics
are known, the performance of the MCD algorithm can be
further improved. Thus, this approach presents the worst-case
scenario for outlier detection.
The classification accuracy for inliers and outliers as a
function of contamination factor in MCD is shown in Fig. 7.
The best contamination factor is 0.15, which maximizes the
minimum accuracy for inliers and outliers.
Table II shows the accuracy as a function of SNR and Fig. 8
shows confusion matrices at 0dB, 10dB, and 18dB SNR levels.

0.06

0.00

Idle

0.03

0.00

0.06

0.09

In-network

0.00

0.27

0.01

0.00

In-network

0.00

0.27

0.00

0.00

In-network

0.00

0.27

0.00

0.00

Jammer

0.00

0.07

0.29

0.00

Jammer

0.00

0.07

0.30

0.00

Jammer

0.00

0.07

0.29

0.00

Out-network

0.00

0.00

0.03

0.24

Out-network

0.00

0.00

0.03

0.25

Out-network

0.00

0.00

0.03

0.25

(b) 10 dB.

r
e
m

u
tn
e
O

Predicted label

(a) 0 dB.

Ja
m

u
tn
e

In
-n
e

tw
o
rk

r
e
m
Ja
m

O

O

In
-n
e

u
tn
e

Id
le

tw
o
rk

r
e
m
Ja
m

In
-n
e

Predicted label

tw
o
rk

0.00

tw
o
rk

0.03

Id
le

Idle

True label

0.00

tw
o
rk

0.07

True label

0.00

tw
o
rk

0.03

Id
le

True label

Idle

Predicted label

(c) 18 dB.

Fig. 8. MCD-based outlier detection confusion matrices at different SNR values.

TABLE II
MCD- BASED OUTLIER DETECTION ACCURACY OVER ALL SNR VALUES .

SNR (dB)
0
2
4
6
8

Accuracy
0.822
0.814
0.824
0.832
0.845

SNR (dB)
10
12
14
16
18

Accuracy
0.843
0.844
0.847
0.844
0.839

Fig. 9. Confusion matrix for k-means clustering based outlier detection.

2) k-means Clustering based Classifier: The second
method for the outlier detection is the k-means clustering
method. This method divides the samples into k = 2 clusters
by iteratively finding k cluster centers. We again have innetwork and out-network user signals as inlier and jamming
signals as outlier. We first use CNN to extract features and then
use k-means clustering to divide samples into two clusters, one
for inlier and the other for outlier. The confusion matrix is
shown in Fig. 9. The accuracy of correctly identifying inliers
has improved with k-means compared to the MCD method.
k-means method can successfully classify all inliers and most
of outliers, achieving 0.88 average accuracy.
D. Detection of a Smart Jammer
Next, we consider a smart jammer that records an innetwork user signal, and then amplifies and forwards it as a
replay attack (instead of transmitting a distinct jamming signal,
as assumed before). Radio hardware imperfections such as I/Q

imbalance, time/frequency drift, and power amplifier effects
can be used as a “radio fingerprint” in order to identify the
specific radio that transmits a given signal under observation.
In particular, we aim to design a classifier using I/Q data with
hardware impairments to identify the type of a transmitter (innetwork user or jammer).
Suppose the jammer receives the in-network user signal,
which is QAM64 at 18 dB SNR, and collects 1000 samples.
Then the jammer amplifies and forwards it for jamming. We
model the hardware impairment as a rotation on the phase
of original signal. This offset will be used in the classifier to
detect a jamming signal in a replay attack.
The jammer rotates 1000 samples with different angles θ =
kπ
16 for k = 0, 1, · · · , 16. The jammer uses these signals for
jamming. Each of these signals has its ejθ rotation.
We design a classifier to detect the difference between these
signals. Using 1000 samples for each of 17 rotation angles,
we have 17K samples. We split the data into 80% for training
and 20% for testing. We use patience of 8 epochs (i.e., if loss
at epoch t did not improve for 8 epochs, we stop and take
the best (t − 8) result) and train for 200 iterations. A CNN
structure similar to the one in Section III-A is used. The only
difference is that the last fully connected layer has 17 output
neurons for 17 cases corresponding to different rotation angles
(instead of 4 output neurons). This classifier achieves 0.972
accuracy (see Fig. 10-(a) for validation loss and Fig. 10-(b)
for validation accuracy). The confusion matrix is shown in
Fig. 11.
E. Classifier for Superimposed Signals
We now consider the signal classification for the case that
the received signal is potentially a superposition of two signal
types. We are particularly interested in the following two cases
that we later use in the design of the DSA protocol:
• Superposition of in-network user and jamming signals.
• Superposition of jamming and out-network user signals.
We first apply blind source separation using ICA. The signal
is separated as two signals and then these separated signals are
fed into the CNN classifier for classification into in-network

(a) Loss value.

Fig. 11. The confusion matrix for 17 types of signals.

A. Superframe structure
We consider the superframe structure (shown in Fig. 13)
that consists of four periods:

(b) Accuracy.
Fig. 10. Classifier performance to detect 17 types of signals.
TABLE III
ACCURACY FOR SUPERIMPOSED SIGNALS ( AVERAGED OVER ALL SIGNAL
TYPES ).

SNR (dB)
0
2
4
6
8

Accuracy
0.851
0.820
0.857
0.843
0.827

SNR (dB)
10
12
14
16
18

Accuracy
0.824
0.834
0.843
0.830
0.841

user signals, jamming signals, or out-network user signals.
We obtained the accuracy as shown Table III and confusion
matrices at 0dB, 10dB and 18dB SNR levels, as shown in
Fig. 12, respectively.
F. Classifier for Superimposed Signals
IV. D ESIGN D ISTRIBUTED S CHEDULING P ROTOCOL
The outcome of the deep learning based signal classifier
is used by the DSA protocol of in-network users. In this
section, we present a distributed scheduling protocol that
makes channel access decisions to adapt to dynamics of
interference sources along with channel and traffic effects.

1) Spectrum sensing collects I&Q data on a channel over
a sensing period.
2) Deep learning based signal classifier determines channel
status based on sensing results. The status may be idle,
in-network, jammer, or out-network.
3) Distributed scheduling exchanges control packages and
assigns time slots to transmitters in a distributed fashion.
4) Data transmission period is divided into time slots and
each transmitter sends data in its assigned time slots.
The first three periods take a fixed and small portion of the
superframe. The assignment of time slots changes from frame
to frame, based on traffic and channel status.
B. Distributed Scheduling Rules
Scheduling decisions are made using deep learning classification results. Deep learning provides a score on the
confidence of classification to four types of signals: idle, innetwork, jammer, and out-network. We use the scheduling protocol outlined in Algorithm 1 to schedule time for transmission
of packets including sensing, control, and user data. If the innetwork user classifies the received signals as out-network, it
does not access the channel. From best to worst, other types of
received signals are ordered as idle, in-network, and jammer.
In-network users that classify received signals to better signal
types gain access to channel. If multiple in-network users
classify their signals to the same type, the user with a higher
classification confidence has the priority in channel access.

0.00

Idle

0.01

0.00

0.03

0.00

In-network

0.00

0.13

0.00

0.00

In-network

0.00

0.13

0.00

0.00

In-network

0.00

0.13

0.00

0.00

Jammer

0.00

0.04

0.38

0.01

Jammer

0.00

0.03

0.36

0.04

Jammer

0.00

0.04

0.37

0.02

Out-network

0.00

0.00

0.06

0.32

Out-network

0.00

0.00

0.07

0.32

Out-network

0.00

0.00

0.07

0.32

(a) 0 dB.

r
e
m

u
tn
e
O

In
-n
e

u
tn
e
O

Ja
m

tw
o
rk

r
e
m
Ja
m

In
-n
e

O

u
tn
e

Id
le

r
e
m
Ja
m

In
-n
e

Predicted label

tw
o
rk

0.03

tw
o
rk

0.00

Id
le

0.02

True label

Idle

tw
o
rk

0.00

True label

0.03

tw
o
rk

0.00

tw
o
rk

0.01

Id
le

True label

Idle

Predicted label

Predicted label

(b) 10 dB.

(c) 18 dB.

Fig. 12. Confusion matrices for superimposed signals at different SNR values.

Spectrum
Signal Classification Distributed Scheduling
Data Transmission
Sensing
Predict channel
Exchange control
Time slots 1,2, …, T
Collect I/Q data
status
packets

Fig. 13. The superframe structure.

Algorithm 1 Scheduling based on classification results.
1: Each receiver sends the channel status (type, score) to its
transmitter if the type is not out-network. If the channel
status is out-network, there should be no transmission to
protect out-network user transmissions.
2: If a transmitter receives channel status from its receiver
and does not detect an out-network user, it broadcasts a
request (type, priorities). Priorities are T numbers generated based on the received score and are used to compete
with other transmitters for T time slots.
3: A receiver generates and broadcasts a response as:
4: if the request type from its transmitter is smaller than the
request type from all other transmitters then
5:
its transmitter will transmit in all T time slots.
6: end if
7: if the request type from its transmitter is the same as the
request type from some other transmitters then
8:
its transmitter will transmit in a time slot t if its priority
in this time slot is the largest among these transmitters’
priorities.
9: end if
10: A transmitter will transmit in time slot t if the response
from its receiver approves it to be active in time slot t
and responses from other receivers do not specify another
transmitter in this time slot.

This protocol is distributed and only requires in-network users
to exchange information with their neighbors.
C. Traffic Profile in Signal Classification
Traffic profiles can be used to improve signal classification
as received signals may be correlated over time. We present
next how to learn the traffic profile of out-network users and

use it for signal classification. We define out-network user
traffic profile (idle vs. busy) as a two-state Markov model.
That is, if there is no out-network user transmission, it is in
state 0, otherwise it is in state 1. The transition probability
from state i to j is pij . Each in-network user builds its own
estimation on this Markov model by online learning as follows.
1) Initialize the number of state changes as
n00 = 1, n01 = 1, n10 = 1, n11 = 1.

(4)

2) Update these numbers based on past state i and current
predicted state j, i.e., nij = nij + 1.
3) State transition probability is calculated as pij =
nij /(ni0 + ni1 ).
After learning the traffic profile of out-network users, signal
classification results based on deep learning are updated as
follows. Suppose the last status is st−1 , where st−1 is either 0
or 1. Then based on pij , we can classify the current status
as sTt with confidence cTt . For example, if st−1 = 0 and
p00 > p01 , then sTt = 0 and cTt = p00 . Suppose the
current classification by deep learning is sD
t with confidence
D
D
cD
t , where st is either 0 or 1 and ct is in [0.5, 1]. The
classification of idle, in-network, and jammer corresponds to
state 0 in this study. We have the following three cases.
T
D
• st = st . There is no need to change classification.
T
D
• st = 0 and st = 1. Then based on traffic profile, the
confidence of sTt = 0 is cTt while based on deep learning,
D
the confidence of sD
t = 1 is 1 − ct . We use a weight
parameter w ∈ [0, 1] to combine these two confidences
as wcTt + (1 − w)(1 − cD
t ). If this combined confidence
is smaller than 0.5, we claim that the current state is 1,
otherwise the current state is 0.
T
D
• st = 1 and st = 0. Then based on traffic profile, the
confidence of sTt = 0 is 1 − cTt while based on deep
D
learning, the confidence of sD
t = 0 is ct . We combine
T
these two confidences as w(1 − ct ) + (1 − w)cD
t . If this
combined confidence is smaller than 0.5, we claim that
the current state is 1, otherwise the current state is 0.
Note that state 0 needs to be classified as idle, in-network,
or jammer based on deep learning. This approach uses both

prediction from traffic profile and signal classification from
deep learning, and would provide a better classification on
channel status.

TABLE IV
S YSTEM PERFORMANCE WITH DIFFERENT CLASSIFIERS .

Classifier

D. Simulation Results
In Section III, the test signals are taken one by one from
a given SNR. Now, we simulate a wireless network, where
the SNR changes depending on channel gain, signals may be
received as superposed, signal types may change over time,
remain unknown, or may be spoofed by smart jammers.
We consider the following simulation setting.
• 100 in-network users are randomly distributed in a 50m
×50m region.
• 2 out-network users and 2 jammers are randomly distributed in the same region.
• Transmission/interference range is 10m.
• 1000 superframes are generated. There are 10 random
links to be activated for each superframe. A superframe
has 10 time slots for data transmission.
• Gaussian channel model is assumed.
• If a transmission is successful, the achieved throughput
in a given time slot is 1 (packet/slot).
The performance measures are in-network user throughput
(packet/slot) and out-network user success ratio (%). The goal
is to improve both measures.
1) Benchmark Schemes: For comparison purposes, we
consider two centralized benchmark schemes by splitting a
superframe into sufficient number of time slots and assigning
them to transmitters to avoid collision.
• Benchmark scheme 1. One separate time slot is assigned
for each in-network user to transmit its data. This scheme
needs 100 time slots since there are 100 in-network users.
• Benchmark scheme 2. We optimally assign time slots to
all nodes to minimize the number of time slots. We can
build an interference graph, where each node represents
a link and each edge between two nodes represents
interference between two links if they are activated at
the same time. If the maximum degree of this interference
graph is D, the minimum number of time slots to avoid
all interference is D + 1.
2) System Performance: We first consider the basic setting
that there are no outliers (unknown signal types) and no
superimposed signals, and traffic profile is not considered. The
benchmark performances are given as follows.
• Benchmark scheme 1: In-network throughput is 760. Outnetwork user success rate is 47.57%.
• Benchmark scheme 2: In-network throughput is 3619.
Out-network user success rate is 47.57%.
The performance of distributed scheduling with different
classifiers is shown in Table IV, where random classifier
randomly classifies the channel with probability 25%.
We considered the effect of no jamming and obtained
benchmark performance:
• Benchmark scheme 1: In-network throughput is 881. Outnetwork user success is 47.57%.

Ideal classifier (no error)
Random classifier
One classifier for all SNRs
One classifier for each SNR

In-net user
throughput
40,578
14,563
38,477
39,153

Out-net user
success ratio
100%
80.48%
100%
99.80%

TABLE V
S YSTEM PERFORMANCE WITH DIFFERENT CLASSIFIERS AND NO
JAMMING .

Classifier
Ideal classifier (no error)
Random classifier
One classifier for all SNRs
One classifier for each SNR

In-net user
throughput
43,316
17,552
41,780
42,614

Out-net user
success ratio
100%
80.70%
100%
99.92%

Benchmark scheme 2: In-network throughput is 4196.
Out-network user success is 47.57%.
The performance of distributed scheduling with different
classifiers is shown in Table V.
3) Traffic profile integrated with signal classification: We
compare results with and without consideration of traffic
profile, and benchmarks. We generate another instance with
p00 = p11 = 0.8 and p01 = p10 = 0.2. The weight (w) to
combine deep learning results and traffic profile results is set
as 0.2. We have the following benchmark performance.
• Benchmark scheme 1: In-network user throughput is 829.
Out-network user success is 16%.
• Benchmark scheme 2: In-network user throughput is
4145. Out-network user success is 16%.
The performance with and without traffic profile incorporated in signal classification is shown in Table VI.
4) Classification with Outliers and Superimposed Signals:
We compare benchmark results with the consideration of
outliers and signal superposition. Benchmark performance is
the same as before, since it does not depend on classification:
• Benchmark scheme 1: In-network user throughput is 829.
Out-network user success is 16%.
• Benchmark scheme 2: In-network user throughput is
4145. Out-network user success is 16%.
The performance with outliers and signal superposition
included is shown in Table VII.
In all the cases considered, the integration of deep learning
based classifier with distributed scheduling performs always
much better than benchmarks.
•

V. C ONCLUSION
We studied deep learning based signal classification for
wireless networks in presence of out-network users and jammers. In addition to fixed and known modulations for each
signal type, we also addressed the practical cases where
1) modulations change over time; 2) some modulations are
unknown for which there is no training data; 3) signals are

TABLE VI
S YSTEM PERFORMANCE WITH AND WITHOUT USING TRAFFIC PROFILE
AND NO JAMMING .

Classifier
Without traffic profile
With traffic profile

In-net user
throughput
40,714
40,616

Out-net user
success ratio
69%
70%

TABLE VII
S YSTEM PERFORMANCE WITH SIGNAL SUPERPOSITION AND NO JAMMING .

Classifier
Without outlier
With outlier
With superimposed signals

In-net user
throughput
40,616
34,236
34,503

Out-net user
success ratio
70%
69%
68%

spoofed by smart jammers replaying other signal types; and
4) signals are superimposed with other interfering signals. In
case 1, we applied continual learning to mitigate catastrophic
forgetting. In case 2, we applied outlier detection to the outputs
of convolutional layers by using MCD and k-means clustering
methods. In case 3, we identified the spoofing signals by
extending the CNN structure to capture phase shift due to
radio hardware effects. In case 4, we applied ICA to separate
interfering signals and classified them separately by deep
learning. Results demonstrate the feasibility of using deep
learning to classify RF signals with high accuracy in unknown
and dynamic spectrum environments. By utilizing the signal
classification results, we constructed a distributed scheduling
protocol, where in-network (secondary) users share the spectrum with each other while avoiding interference imposed
to out-network (primary) users and received from jammers.
Compared with benchmark TDMA schemes, we showed that
distributed scheduling constructed upon signal classification
results provides major improvements to throughput of innetwork users and success ratio of out-network users.
R EFERENCES
[1] T. O’Shea, J. Corgan, and C. Clancy, “Convolutional radio modulation
recognition networks,” in Proc. International Conference on Engineering
Applications of Neural Networks, 2016.
[2] B. Kim, J. K. amd H. Chae abd D. Yoon, and J. W. Choi, “Deep neural
network-based automatic modulation classification technique,” in Proc.
IEEE International Conference on Information and Communication
Technology Convergence (ICTC), 2016.
[3] G. J. Mendis, J. Wei, and A. Madanayake, “Deep learning-based
automated modulation classification for cognitive radio,” in Proc. IEEE
International Conference on Communication Systems (ICCS), 2016.
[4] S. Peng, H. Jiang, H. Wang, H. Alwageed, and Y. D. Yao, “Modulation
classification using convolutional neural network based deep learning
model,” in Proc. IEEE Wireless and Optical Communication Conference
(WOCC), 2017.
[5] A. Ali and Y. Fan, “Unsupervised feature learning and automatic
modulation classification using deep learning model,” Physical Communication, vol. 25, pp. 75–84, 2017.
[6] Y. Tu, Y. Lin, J. Wang, and J. U. Kim, “Semi-supervised learning with
generative adversarial networks on digital signal modulation classification,” Comput. Mater. Continua, no. 2, pp. 243–254, 2018.
[7] T. O’Shea, T. Roy, and T. C. Clancy, “Over-the-air deep learning based
radio signal classification,” IEEE Journal of Selected Topics in Signal
Processing, vol. 12, no. 1, pp. 168–179, 2018.

[8] M. Ring, “Continual learning in reinforcement environments,” Ph.D.
dissertation, University of Texas at Austin, 1994.
[9] S. i. Amari, A. Cichocki, and H. H. Yang, “A new learning algorithm for
blind signal separation,” in Advances in neural information processing
systems, 1996, pp. 757–763.
[10] O. A. Dobre, A. Abdi, Y. Bar-Ness, and W. Su, “Survey of automatic modulation classification techniques: classical approaches and new
trends,” IET Communications, vol. 1, no. 2, pp. 137–156, 2007.
[11] ——, “Blind modulation classification: a concept whose time has
come,” in IEEE/Sarnoff Symposium on Advances in Wired and Wireless
Communication, 2005.
[12] W. C. Headley and C. R. da Silva, “Asynchronous classification of
digital amplitude-phase modulated signals in flat-fading channels,” IEEE
Transactions on Communications, vol. 59, no. 1, pp. 7–12, 2011.
[13] M. Alsheikh, S. Lin, D. Niyato, and H. Tan, “Machine learning in
wireless sensor networks: Algorithms, strategies, and applications,”
IEEE Communications Surveys & Tutorials, vol. 16, no. 4, pp. 1996–
2018, 2014.
[14] M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, “Machine
learning for wireless networks with artificial intelligence: A tutorial on
neural networks,” arXiv preprint arXiv:1710.02913, 2017.
[15] W. Lee, M. Kim, D. Cho, and R. Schober, “Deep sensing: Cooperative spectrum sensing based on convolutional neural networks,” arXiv
preprint arXiv:1705.08164, 2017.
[16] K. Davaslioglu and Y. E. Sagduyu, “Generative adversarial learning
for spectrum sensing,” in Proc. IEEE International Conference on
Communications (ICC), 2018.
[17] T. Erpek, Y. E. Sagduyu, and Y. Shi, “Deep learning for launching and
mitigating wireless jamming attacks,” IEEE Transactions on Cognitive
Communications and Networking, vol. 5, no. 1, pp. 2–14, Mar. 2019.
[18] H. Ye, G. Y. Li, and B. H. Juang, “Power of deep learning for
channel estimation and signal detection in ofdm systems,” IEEE Wireless
Communications Letters, vol. 7, no. 1, pp. 114–117, 2018.
[19] Y. Shi, T. Erpek, Y. E. Sagduyu, and J. Li, “Spectrum data poisoning
with adversarial deep learning,” in Proc. IEEE Military Communications
Conference (MILCOM), 2018.
[20] Y. Shi, Y. E. Sagduyu, T. Erpek, K. Davaslioglu, Z. Lu, and J. Li,
“Adversarial deep learning for cognitive radio security: Jamming attack
and defense strategies,” in Proc. IEEE ICC Workshop on Promises and
Challenges of Machine Learning in Communication Networks, 2018.
[21] Y. E. Sagduyu, Y. Shi, and T. Erpek, “IoT network security from
the perspective of adversarial deep learning,” in Proc. IEEE SECON
Workshop on Machine Learning for Communication and Networking in
IoT, 2019.
[22] C. de Vrieze, L. Simic, and P. Mahonen, “The importance of being
earnest: Performance of modulation classification for real RF signals,”
in Proc. IEEE International Symposium on Dynamic Spectrum Access
Networks (DySPAN), 2018.
[23] Y. Shi, K. Davaslioglu, and Y. E. Sagduyu, “Generative adversarial
network for wireless signal spoofing,” in Proc. ACM Workshop on
Wireless Security and Machine Learning, 2019.
[24] A. Odena, V. Dumoulin, and C. Olah, “Deconvolution
and checkerboard artifacts,” 2016. [Online]. Available: http:
//distill.pub/2016/deconv-checkerboard/
[25] M. Abadi, P. Barham, J. C. abnd Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, and M. Kudlur, “Tensorflow:
A system for large-scale machine learning,” in Proc. 12th USENIX
Symposium on Operating Systems Design and Implementation (OSDI
16), 2016. [Online]. Available: tensorflow.org
[26] D. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
CoRR, abs/1412.6980, 2014.
[27] I. J. Goodfellow, M. Mirza, D. Xiao, A. Courville, and Y. Bengio,
“An empirical investigation of catastrophic forgetting in gradient-based
neural networks,” in arXiv:1312.6211, 2015.
[28] J. Kirkpatrick, R. Pascanu, N. Rabinowitz, J. Veness, G. Desjardins,
A. A. Rusu, K. Milan, J. Quan, T. Ramalho, T. Grabska-Barwinska, and
D. Hassabis, “Overcoming catastrophic forgetting in neural networks,”
Proceedings of the National Academy of Sciences, pp. 3521–3526, 2017.
[29] M. Hubert and M. Debruyne, “Minimum covariance determinant,”
Advanced Review, pp. 36–43, 2010.
[30] P. J. Rousseeuw and K. V. Driessen, “A fast algorithm for the minimum
covariance determinant estimator,” Technometrics, vol. 41, 1999.

