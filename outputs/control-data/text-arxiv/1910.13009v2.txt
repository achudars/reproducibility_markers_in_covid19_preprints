1

Shifting Opinions in a Social Network Through
Leader Selection

arXiv:1910.13009v2 [cs.SI] 16 May 2020

Yuhao Yi, Timothy Castiglia, Stacy Patterson

Abstract—We study the French-DeGroot opinion dynamics in
a social network with two polarizing parties. We consider a
network in which the leaders of one party are given, and we pose
the problem of selecting the leader set of the opposing party so as
to shift the average opinion to a desired value. When each party
has only one leader, we express the average opinion in terms of the
transition matrix and the stationary distribution of random walks
in the network. The analysis shows balance of influence between
the two leader nodes. We show that the problem of selecting
at most k absolute leaders to shift the average opinion is NPhard. Then, we reduce the problem to a problem of submodular
maximization with a submodular knapsack constraint and an
additional cardinality constraint and propose a greedy algorithm
with upper bound search to approximate the optimum solution.
We also conduct experiments in random networks and real-world
networks to show the effectiveness of the algorithm.
Index Terms—Social Network, French-DeGroot model, Balance of Opinions, Optimization, Approximation Algorithm.

I. I NTRODUCTION
Social networks have become increasingly influential in
shaping public opinions. Within this field, the problem of
designing mechanisms to effectively shift opinions in a social
network has received great interest in last two decades [1], [2],
[3], [4], [5], [6], [7], [8]. Much of the existing work studies the
problem of choosing individuals in the network to be opinion
leaders so as to maximize the influence of a particular opinion,
for example, to shift the average opinion of the network to an
extreme opinion. However, fine-grained optimization of the
average opinion has not been well studied.
In this paper, we study the problem of shifting the average
opinion of a network to a given value, which generalizes
the intensely studied influence maximization problem. We
consider a continuous-time French-DeGroot opinion model
with two polarizing parties. The French-DeGroot model [9],
[10] is one of the most popular models for opinion dynamics.
In the model, the social network is represented by a graph,
with nodes corresponding to individuals. Each node has a
real scalar-valued state that represents the individual’s opinion.
Each node updates its state continuously by comparing its state
and the states of its neighbors. We consider a variation on this
model where the nodes consists of leaders nodes, defined as
the nodes with external reference values, and follower nodes,
defined as those without external information.
We assume that there are two opposing sources of opinion,
1 and 0. These could represent, for example, support for
Y. Yi, T. Castiglia, and S. Patterson are with the Department of Computer
Science, Rensselaer Polytechnic Institute, Troy, NY, 12180, USA (email:
yiy3@rpi.edu, castit@rpi.edu, sep@cs.rpi.edu).

Party A (1) or Party B (0), or these sources could represent
support and opposition to an event or outcome. In the model
we adopt, all members of the social network take opinion
values in the interval [0, 1]. A firm supporter of party A
(or pro-event individual) has an opinion close to 1, and a
unquestioned supporter of Party B (or anti-event individual)
holds an opinion close to 0. Individuals with opinion 12 are
considered as completely neutral.
Each party controls a set of nodes as their opinion leaders.
The leader nodes can be fully or partially controlled by each
party. If a leader node is fully controlled, its opinion is set to
the constant opinion value of that party and never changes
over time. We call these leaders absolute leaders and call
such a system an absolute leader system. If a leader node
is partially controlled, it receives a constant input from the
corresponding party as a reference value, and it adjusts its state
according to the reference value and the states of its neighbors.
One can think of these leaders as being influenced through a
relationship with an individual that is a direct source of the
opinion but is not part of the network, i.e., an external party
leader. We define such partially controlled nodes as influenced
leaders, and we call this kind of system an influenced leader
systems.
We consider two leader selection problems, one for each
type of system. In both cases, we assume that the network
already has a leader set for party 0, and our goal is to identify
the leader set for party 1 so as to shift the average opinion
of the social network towards a target value. In the absolute
leader system, this translates to selecting individuals in the
network to act as absolute leaders, for example, by hiring
them into the party. In the influenced leader system, this
leader selection translates to forming relationships between
the identified set of influenced leaders within the network and
the external party leader with opinion 1.
Our problem formulation is related to the well studied
problem of influence maximization [2], [3], [4], [7], i.e., maximizing the average opinion of the network by choosing leaders
for party 1, while the leaders for party 0 are fixed. However,
there are cases where maximizing the average opinion is not
beneficial. It is well known that a large group of people tends
to have polarizing opinions, and the problem of depolarizing
the opinions in a group of interacting individuals has received
interest in social psychology [11]. In this case, one may seek
to balance the network opinion around a target value of 21 .
Moreover, the opinion of an individual relates to his or her
behaviors [12], [13]. In particular, it can be viewed as the
probability that a user adopts a behavior. From this perspective,
party 1 can achieve a desired level of participation in a

2

voluntary activity in a large network by shifting the average
opinion to a certain target value.
We begin by analyzing the two proposed models, and we
propose the concept of domination score to characterize the
balance of influence between leaders of two parties. This
analysis relates the models to properties of random walks
in a network. We also identify the optimal solution to the
leader selection problem for each model when a single leader
is chosen for each party. Next, we study the general problem of
choosing a leader set for party 1 with a given cardinality, when
the leader set for party 0 is already identified. For absolute
leader systems, we prove the NP-hardness of the problem
by a reduction from the vertex cover problem on 3-regular
graphs. We also show the monotonicity and submodularity of
the average steady-state opinion as a function of the leader set
of party 1, for both absolute and influenced leader systems.
Then, we propose an algorithm for the leader selection problems with provable approximation guarantees. Our algorithm
finds an appropriate upper bound for a greedy routine that
approximately solves a submodular cost submodular knapsack
(SCSK) problem with an additional cardinality constraint. we
are not aware of any previous work on SCSK problems with
cardinality constraints.
Related work: In the last two decades, many works considered the French-DeGroot model with leaders accessing
the same reference value [14], [15], [16], [17], [18]. In
such systems, leader selection problems have been formulated
for different objectives such as minimizing the convergence
error [18] or minimizing the total deviation from the reference
value of the system in the presence of additional noise on
followers [15], [16], [17]. These combinatorial optimization
problems are often intractable. For example, the leader selection problem proposed in [15] has been proven to be NPhard [19]. Various approaches have been proposed to address
these problems, including convex relaxation heuristics [16]
and greedy algorithms [18], [20] with constant approximation
ratios.
Another line of works consider leaders with different reference values, in particular two group of leaders with polarizing opinions. In this case, the steady-state opinions of
all nodes fall into the interval of leader states [21], [22].
In such systems, different leader selection problems have
also been studied. [3] investigated the problem of single
leader placement to maximize its influence. The work [7]
studied a problem of choosing leaders to maximize influence
of the leader set in a French-DeGroot model where leaders
have specified stubbornness, and [4] investigated a similar
maximization problem. Both works proved the monotonicity
and submodularity of the average opinion in a French-DeGroot
opinion network with influenced leader dynamics. [2] studied
the influence maximization problem in the Friedkin-Johnsen
model, which is related to a French-DeGroot opinion network
with absolute leaders in special cases but not equivalent, in
general. This work proved the submodularity of the average
opinion in their model as a function of leader nodes and the
NP-hardness of the average opinion maximization problem.
Typical greedy algorithms were applied to these problems due
to submodularity of the objective functions. In contrast, our

work studies the problem of shifting the average opinion of the
network to any specified value. Our problem thus includes the
influence maximization problem as a special case. In addition,
we show that our problem cannot be directly treated as submodular maximization problem with a cardinality constraint.
Thus, a more sophisticated optimization algorithm is needed.
Paper outline: The reminder of the paper is organized
as follows. In Section II, we introduce basic notations and
concepts. In Section III, we present the system model and
the problem formulation. In Section IV, we give an explicit
form of the steady-state opinion vector using the Laplacian
of an augmented graph, and we show how this relates to the
balance of the leader nodes’ influence in a network. We also
prove the hardness of the investigated problem in influenced
leader systems. In Section V, we propose a greedy algorithm
with an upper bound search and provide provable bounds on
the approximation ratio of the algorithm. Section VI presents
experimental results. Finally, we conclude in Section VII.
II. P RELIMINARIES
In this section, we introduce the notation of a graph and its
matrix representations. Further, we review the concepts of hitting time, commute time, resistance distance, and information
centrality, which are used as analytical tools in this paper.
Vectors and Matrices: We use e u to denote the u-th
canonical basis vector of Rn . The vector b u,v is defined as
def
b u,v = e u − e v . 1n represents the all-one vector with length
n, and 0n (0p×q ) represents the all-zero vector (or matrix) with
legnth n (or size p × q). We also use these notations without
specifying the sizes if they are implied in context. Apart from
these exceptions (e u , b u,v , 1n and 0n ), a vector or matrix
with subscripts denotes the vector or submatrix with indices
specified by the subscripts. For example, given a vector x , x i
is its i-th entry, and x I is a vector consisting of entries x i for
all i ∈ I. For a matrix X , X i,j is the (i, j)-th entry of X and
X I,J is the submatrix of X consisting of the entries of X
whose rows are in I and columns are in J . In addition, we
use I to denote the identity matrix, and we use X † to denote
the Moore Penrose pseudoinverse of the matrix X .
Graphs and their Matrix Representations: We denote a
directed graph as G = (V, E, w), where V and E are the node
set and edge set of the graph, respectively, with |V| = n
and |E| = m. An undirected graph can be viewed as a
symmetrically coupled bidirectional graph in this context. We
let e = (u, v) ∈ E represent an edge from nodes u to node v,
and w : E → R+ is the edge weight function. We denote Nv↓
as the set of in-neighbors of v (u ∈ Nv↓ iff (u, v) ∈ E), and
Nv↑ as the set of out-neighbors of v (u ∈ Nv↑ iff (v, u) ∈ E).
In addition, for a graph G = (V, E, w), and a subset of
nodes V ⊆ V, we denote the subgraph supported on V as
G[V ] = (V, E, ω), where E = {e = (u, v) ∈ E : u, v ∈ V }
and ω(e) = w(e) for all e ∈ E. Further, we define the plus operation on graphs as follows. For two graphs G1 = (V1 , E1 , w1 )
and G2 = (V2 , E2 , w2 ), let H = (U, M, ω) = G1 + G2
be a new graph with U = V1 ∪ V2 , M = E1 ∪ E2 , and
ω : M → R+ the new edge weight function defined as
ω(e) = w1 (e) if e ∈ (E1 \E2 ), ω(e) = w2 (e) if e ∈ (E2 \E1 ),
and ω(e) = w1 (e) + w2 (e) if e ∈ (E2 ∩ E1 ).

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

def

The weighted Laplacian matrix of a graph is defined as L =
D − A, where A is the adjacency matrix with Au,v = w(e)
for e = (u, v) ∈ E and Au,v = 0 for (u, v) ∈
/ E,Pand D
is the out-degree diagonal matrix, where D u,u =
v Au,v
and D
=
0
if
u
=
6
v.
From
the
definition,
it
is
clear
that
u,v
P
L = (u,v)∈E w(u, v)b u,v e ⊤
u.
For a matrix (vector, scalar) associated with a graph, we
sometimes use a superscript to explicitly show that it corresponds to the graph. For example, LG is the Laplacian matrix
of graph G.
def

3

Definition II.4 (Information Centrality [26]). In a connected
undirected graph G = (V, E, w), the information centrality of
a vertex u is defined by
n
.
θG (u) = P
G
v∈V Ru,v
From Lemma II.3 we obtain
 
X
G
Ru,v
= n · L†

v,v

u∈V

 
+ Tr L† .

III. P ROBLEM F ORMULATION

Random walks on graphs: We define W = A⊤ D −1
as the random walk transition matrix of graph G. A random
A
walker has a probability W i,j = D j,i
to transition from vertex
j,j
j to vertex i. When the graph is strongly connected there exists
a positive vector (unique up to scaling)
P such that π = W π.
When the vector is scaled such that v π v = 1, π is called
the stationary distribution of the random walk defined by W .
def
We define Π as a diagonal matrix in which Πv,v = π v for
all vertex v ∈ V. We note that L = D(I − W ⊤ ) and L1 = 0.
In a connected graph G, the hitting time from vertex u to v
is the expected number of steps that a random walker, starting
from vertex v, takes until it hits u for the first time. We denote
by Hu,v the hitting time from u to v.

We consider a directed strongly connected graph
G = (V, E, w). Nodes represent individuals in the social
network, and an edge (u, v) ∈ E models a social link from
node u to node v, indicating that node u follows node v, or
node v exerts influence on node u. Edge weights represent the
strengths of the social links. Each node v has a scalar-valued
state x v ∈ R, which represents its opinion. The node set can
be divided into a leader set S and a follower set F . The set
S can be further divided into two disjoint sets S0 and S1 ,
which are sets of nodes controlled by two parties, namely
party 0 and party 1. All nodes in S0 have access to reference
value 0, and all nodes in S1 have access to reference value 1.
Nodes in F update their states according to a diffusion law.

Lemma II.1 (Hitting time [23], [24]). In a strongly connected
graph G,

A. System Dynamics

G
⊤ † −1
Hu,v
= b⊤
(π − e v ) .
u,v (I − (W ) ) Π
†
G
If G is an undirected graph, Hu,v
= 2m · b ⊤
u,v L (π − e v ).
def

The commute time Cu,v is defined as Cu,v = Hu,v + Hv,u .
Lemma II.2 (Commute time [23], [24]). In a strongly connected graph G,
G
⊤ † −1
Cu,v
= b⊤
b u,v .
u,v (I − (W ) ) Π
†
G
If G is an undirected graph, Cu,v
= 2m · b ⊤
u,v L b u,v .

Effective Resistance and Information Centrality: Given
an undirected graph G, we define an electrical network G. In
G, every edge e of G is replaced by a resistor of resistance
1/w(e), and the resistors are connected if the edges are
incident. Then, the effective resistance between node u and
v in graph G (or electrical graph G) is defined as the voltage
difference between vertices u and v in G when unit current is
injected from u and extracted from v. We recall the following
lemma relating to effective resistance.
Lemma II.3 (Effective Resistance [25]). In a connected
undirected electrical network defined by G = (V, E, w), the
effective resistance between nodes u and v is
G
Ru,v
= (L† )v,v − 2(L† )v,u + (L† )u,u .

We further recall the related definition of information centrality.

We consider the French-DeGroot opinion model with absolute leaders and a variation of this model with influenced
leaders that are connected to external absolute sources of
information. The two models differ in how the leaders use
their reference values.
In the absolute leader system, leaders initialize their states
with 0 (for v ∈ S0 ) or 1 (for v ∈ S1 ), and their states remain
unchanged over time. The dynamics of a leader node v is
characterized by ẋ v (t) = 0. A follower node v begins with
an arbitrary initial state x v (0) = x 0v , and it updates its state
by the dynamics
X
ẋ v (t) = −
w(v, u) (x v (t) − x u (t)) .
u∈Nv↑

We partition the state vector x as

⊤ ⊤
x = x⊤
S xF

where x S is associated with the leaders and x F is associated
with the followers. Similarly, we partition the Laplacian matrix
LG and adjacency matrix A into blocks as


LS,S LS,F
LG =
.
LF,S LF,F

Then, the dynamics of the leaders and the followers can be
written as
ẋ S (t) = 0
ẋ F (t) = −LF,F x F − LF,S x S .

(1)
(2)

In the system described by (1) and (2), the steady-state
values of the leader nodes are
x̂ S = x 0S

(3)

4

for v ∈ S. Since −LF,F is Hurwitz for a non-empty leader
set S [27], the system converges to a single stable steadystate [28]. Letting ẋ F (t) = 0, we obtain the steady-state of
the followers
x̂ F = −(LF,F )−1 LF,S x̂ S .

(4)

We note that LF,S x̂ S can be viewed as the sum of columns
of LF,S that correspond to 1-leaders (columns of 0-leaders are
weighted by 0).
In the influenced leader system, disjoint subsets of nodes
S0 and S1 are influenced by two external party leaders with
opinions 0 and 1, respectively. These external nodes are not
part of the graph G, and further, they do not change their
opinions. Each of the influenced leaders in S0 ∪ S1 updates its
state according to its current state, the states of its neighbors,
and the reference value from its external leader, 0 for nodes
in S0 and 1 for nodes in S1 .
The system can start from any initial state and the dynamics
is given by
X
ẋ v = −
w(v, u)(x v (t) − x u (t)) + κv (0 − x v (t)), v ∈ S0 ,
u∈Nv↑

ẋ v = −

X

w(v, u)(x v (t) − x u (t)) + κv (1 − x v (t)), v ∈ S1 ,

u∈Nv↑

ẋ v = −

X

w(v, u)(x v (t) − x u (t)),

v∈F.

u∈Nv↑

where the value κv is the weight that the influenced leader puts
on its reference value. We also refer to it as the stubbornness
of the node. The dynamics can be expressed more compactly
as


ẋ = − LG + E S K x + E S1 K 1 ,
(5)

where E S is the diagonal matrix with E Sv,v = 1 for v ∈ S and
E Sv,u = 0 otherwise; E S1 is defined similarly with non-zero
entries for v ∈ S1 . The matrix K is diagonal with K v,v = κv ,
the stubbornness of vertex v if chosen as an influenced node.
For system (5), −(LG + E S K ) is Hurwitz for a non-empty
leader set S, so the system converges to a single steady-state.
We let ẋ (t) = 0 and obtain the steady-state values of all nodes

−1
x̂ = LG + E S K
E S1 K 1 .
(6)
In this paper, we study the average opinion of all nodes in the
network.

Definition III.1. In both the absolute and influenced leader
systems, given the leader set S0 , the average opinion µ of a
network as a function of leader set S1 is defined as
X
def 1
x̂ v .
(7)
µ(S1 ) =
n
v∈V

Besides the above definition, µ(S1 ) has an interesting interpretation in an opinion-behavior model based on the FrenchDeGroot model. We can model the opinion-behavior linkage
in the system by treating x̂ v as the success probability of
a Bernoulli random variable Xv of taking the value 1. In
the social network, Xv = 1 indicates the event that node

(individual) v takes an action, and Xv = 0 indicates the
event that v does not take an action. We recall that n = |V|
for both the absolute and influenced leader systems. We then
assume X1 , X2 , . . . , Xv , . . . , Xn to be n mutually independent Bernoulli random variables associated with corresponding
nodes in the network. In particular Xv is defined by
Pr (Xv = 1) = x̂ v ,
Pr (Xv = 0) = 1 − x̂ v ,
for all v ∈ V, and therefore E[Xv ] = x̂ v .
We are interested in the fraction of nodes
P that take an action.
We define the random variable X := n1 v Xv . Since Xv are
independent bounded random variables, X concentrates at
1X
x̂ v .
(8)
µ(S1 ) =
n v
According to the Hoeffding’s inequality,
!
r
ln n
2
Pr |X − µ(S1 )| ≥
≤ 2,
n
n

(9)

which indicates that µ(S1 ) determines the fraction of the
population that take an action in a large network, with a
diminishing error bound and a diminishing probability that this
bound is violated. Therefore, a party can control the fraction
of population that take part in an activity or event by shifting
the average opinion of the network to a certain value.
B. Leader Selection Problems
In a system where the set S0 is given, we define the problem
of choosing at most k leaders for the set S1 , such that the
average opinion of all nodes (including leaders and followers)
µ(S1 ) is closest to a given value α. Specifically, we are
interested in minimizing the following objective function,
def

f (P, α) = |µ(P ) − α| .

(10)

We first formally define the problem for the absolute leader
system.
Problem 1 (Absolute Leader Selection). In an absolute
leader system, given a strongly connected directed graph
G = (V, E, w), an opinion 0 absolute leader set S0 6= ∅, a
specified value α ∈ [0, 1], a candidate set Q ⊆ V\S0 , |Q| = q,
and an integer 1 ≤ k ≤ q, find the node set S1 ⊆ Q, |S1 | ≤ k
such that
S1 ∈ arg min f (P, α) .

(11)

P ⊆Q,|P |≤k

We define a similar problem for the influenced leader
system.
Problem 2 (Influenced Leader Selection). In an influenced
leader system, given a strongly connected directed graph
G = (V, E, w), an opinion 0 leader set S0 6= ∅, a stubbornness
function of 0 leader nodes κ0 : S0 → R+ , a specified value
α ∈ [0, 1], a candidate set Q ⊆ V\S0 , |Q| = q, another
stubbornness function κ1 : Q → R+ , and a integer 1 ≤ k ≤ q,
find the node set S1 ⊆ Q, |S1 | ≤ k such that
S1 ∈ arg min f (P, α) .
P ⊆Q,|P |≤k

(12)

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

We note that for both Problems 1 and 2, influence maximization corresponds to the degenerate case of α = 1.

5

u

i

κu = 1
S0
κv = 2

IV. A NALYSIS
In this section, we give analytical solutions for Problems 1
and 2 for the case where k = 1. We also present hardness
results for the case where k > 1.
Our analysis utilizes a leader-equivalent graph to give
analytical expressions for the average opinion of the network.
Furthermore, for a network with a single leader for each party,
we express the average opinion using the transition matrix and
the stationary distribution of random walks in the network.
A. Opinions in Leader-Equivalent Systems
We note that the dynamics of both the absolute leader system and the influenced leader system can be fully characterized
by a system defined in a leader-equivalent graph. For these
two different kinds of systems, we construct the corresponding
leader-equivalent graphs in different ways.
u

i

S0

S1

v

⇒

s′0

s′1
2

j

G

G′

Fig. 1: An example of constructing a leader-equivalent graph
for an absolute leader system. Nodes u and v in G become the
leader s′0 in G ′ , and nodes i and j in G become the leader s′1
in G ′ . Edges without labels are weighted 1; otherwise, edges
are labeled with their weights.
The system described by (1) and (2) is equivalent to a
system in which all nodes in S0 are identified as a single
absolute leader s′0 , and all nodes in S1 are identified as a
single absolute leader node s′1 . We denote the contracted
graph by G ′ = (V ′ , E ′ , w′ ), where V ′ = F ∪ {s′0 } ∪ {s′1 },
E ′ = {(u, v) : u, v ∈ F } ∪ {(u, s′0 ) : (Nu ∩ S0 ) 6=
∅} ∪ {(u, s′1 ) : (Nu ∩ P
S1 ) 6= ∅}, and w′ (u, v) = w(u, v) if
′
′
u, v ∈ F , w (u, s0 ) = v∈(S0 ∩Nu ) w(u, v), and w′ (u, s′1 ) =
P
′
′
′
v∈(S1 ∩Nu ) w(u, v). In addition, we define S = {s0 , s1 } and
′
′
′
′
F = V \S . Note that F = F in this case. Figure 1 shows
an example of constructing a leader-equivalent graph for an
absolute leader system.
′
We denote the Laplacian matrix of G ′ as LG . Then the
dynamics of F ′ in the system defined on the leader-equivalent
graph is expressed by
′

′

ẋ F ′ (t) = −LGF ′ ,F ′ x F ′ − LGF ′ ,{s′ } .
1

(13)

The influenced leader system described by (5) is equivalent
to a system in which two virtual absolute leaders s′0 and s′1
are added to the graph, and all nodes in the original network
G are treated as followers. We define the augmented graph
as G ′ = (V ′ , E ′ , w′ ), where V ′ = V ∪ {s′0 } ∪ {s′1 }, and
E ′ = E ∪ {(u, s′0 ) : u ∈ S0 } ∪ {(u, s′1 ) : u ∈ S1 } ∪ {(s′0 , u) :
u ∈ S0 } ∪ {(s′1 , u) : u ∈ S1 }, w′ (u, v) = w(u, v) if
(u, v) ∈ E, w′ (u, s′0 ) = w′ (s′0 , u) = κu if u ∈ S0 , and

u

i

S0

S1

κi = 2

⇒

S1

s′0

κj = 1

v

2

2

s′1

2

2

v

j

j

G

G′

Fig. 2: An example of constructing a leader-equivalent graph
from an influenced leader system.
w′ (u, s′1 ) = w′ (s′1 , u) = κu if u ∈ S1 . We again define
S ′ = {s′0 , s′1 } and F ′ = V ′ \S ′ ; in this case F ′ = V. Figure 2
shows an example of constructing a leader-equivalent graph
for an influenced leader system. With this augmented graph,
the dynamics of the influenced leader system is also described
by (13).
By constructing the corresponding leader-equivalent graphs,
we can study both absolute and influenced leader systems
using a unified framework. We remark that this does not
mean the systems are equivalent. Choosing leaders in different
system models leads to different leader-equivalent graphs and
hence different steady-states, although system (5) approaches
system (2) as K v,v → +∞ for all v ∈ (S0 ∪ S1 ).
For both the absolute and influenced leader systems, the
nodes s′1 and s′0 are the only nodes that directly use reference
values as their states in the leader-equivalent graph. Their
steady states are x s′0 = 0 and x s′1 = 1. The steady states
of all remaining nodes satisfy
′

′

LGF ′ ,F ′ x̂ F ′ + LGF ′ ,{s′ } = 0 .

(14)

1

We note that the edges from s′0 or s′1 to other nodes are not
used according to the dynamics. We deliberately add these
edges to make the graph strongly connected, which facilitates
our analysis.
′
′
Let (AG )⊤ (D G )−1 be the random walk matrix of a leaderequivalent graph G ′ . Then, we define the following matrices
for G ′ :
′

def

′

LG = Π(I − (W G )⊤ ) ,
G def

R

′

(15)

′

= (I − (W G )⊤ )† Π−1 .

′

(16)

′

In general (LG )† 6= RG , but for any p ⊥ 1, q ⊥ 1,
′
′
p ⊤ (LG )† q = p ⊤ RG q . For more details we refer the readers
to ′the full version
[24] of [23]. For an undirected graph,
′
1
LG = 2m
LG .
Proposition IV.1. For either an absolute leader system or
an influenced leader system, we consider its leader-equivalent
graph G ′ . For any node v ∈ V ′ , the steady state value x̂ v is
given by
′

x̂ v =

G
b⊤
v,s′0 R b s′1 ,s′0
G
b⊤
s′1 ,s′0 R b s′1 ,s′0
′

′

=

G †
b⊤
v,s′0 (L ) b s′1 ,s′0
G †
b⊤
s′1 ,s′0 (L ) b s′1 ,s′0
′

.

(17)

When G is an undirected graph, the expression degenerates to
′

x̂ v =

G †
b⊤
v,s′0 (L ) b s′1 ,s′0
G †
b⊤
s′1 ,s′0 (L ) b s′1 ,s′0
′

.

(18)

6

The correctness of the result in Proposition IV.1 can be
verified by plugging (17) into′ (14), and the uniqueness is
guaranteed by the fact that LGF ′ ,F ′ is full rank and E S1 K ′ 1
is non-zero. We leave the details to Appendix B.
The value of x̂ v is, in fact, the escape probability of node
v, which is defined as the probability that a random walker
starting from vertex v, reaches node s′1 before it reaches node
s′0 1 , We note that the expression (18) was given in [22] in
a different context. [22] studied an opinion dynamics model
where the sum of differences between the states of a node and
its neighbors is divided by the out-degree of the node before it
is applied as a negative feedback to the state of the node. If the
leaders take the same values, the system studied in [22] has a
different convergence rate than the absolute leader system but
shares the same steady-state values.

The proof of Theorem IV.3 follows directly from (19)
and Definition IV.2. The numerator is the absolute value of a
weighted average of DsG1 ,s0 and −DsG0 ,s1 . Therefore, Theorem
IV.3 shows a weighted balance between the domination score
of s0 over s1 and the domination score of s1 over s0 , which
decides the deviation of the average opinion from α. Theorem
IV.3 indicates that for Problem 1, if |S0 | = |S1 | = 1,
given the leader s0 , it suffices to find a node s1 such that
(1 − α)DsG1 ,s0 = αDsG0 ,s1 to shift the average opinion to α.
For influenced leader systems, the vector x̂ is given by (6).
We do not apply the leader-equivalent graph analysis in this
case because G ′ 6= G. We instead interpret x̂ using properties
of G. Fortunately, when we choose one leader for each party,
E S1 is a rank-1 matrix, and E S = E S0 + E S1 is a rank-2
matrix. Applying the rank-1 update of matrices twice leads to
the following theorem.

B. Single Leader for Each Party
For absolute leader systems, if |S1 | = |S0 | = 1, the leaderequivalent graph G ′ is the same as the original graph G. We let
the leaders in G be denoted s0 and s1 for parties with opinion
0 and 1, respectively. Then, by Proposition IV.1,

Theorem IV.4. For influenced leader systems, if |S0 | = |S1 | =
1, we obtain

(L† )s0 ,s0 − (L† )s0 ,s1
. (19)
µ(S1 ) = †
(L )s0 ,s0 −(L† )s0 ,s1 +(L† )s1 ,s1 −(L† )s1 ,s0
Intuitively, we can view this expression as the influence
of node s1 to node s0 , normalized by the sum of their
mutual influence. We quantify this influence with the following
definition.
Definition IV.2. In a strongly connected directed graph G, the
domination score of node u over v is defined as
G
Du,v
= (L† )v,v − (L† )v,u .

(20)
G
Du,v

We provide two physical interpretations for
in special
cases. The first interpretation is that in a balanced regular
G
G
(directed or undirected) graph, Du,v
is the hitting time Hu,v
.
G
A larger Hu,v indicates that a random walker, starting from
node u, spends more time in the network before it reaches
v, therefore, exerting greater influence in the network. The
second interpretation is that in an undirected graph G and its
1
G
induced electrical network G, 2m
is the average voltage
Du,v
value of all nodes in the electrical network when unit current
is injected at u and extracted from v, and v is grounded (s0
has voltage 0).
From the definition of domination score and the expression
of commute time in Lemma II.2, we immediately obtain
µ(S1 ) =

DsG1 ,s0
CsG0 ,s1

=

DsG1 ,s0
DsG0 ,s1 + DsG1 ,s0

.

(1 − α)DsG1 ,s0−αDsG0 ,s1
.
DsG0 ,s1 + DsG1 ,s0

(22)

1 The references [23], [24] discussed the escape probability of a node in a
directed graph, although these papers did not include a correct expression.

1

d

d

( κ0 πs0s + DsG1 ,s0 ) + ( κ1 πs1s + DsG0 ,s1 )
0

,

1

where the entries of the vector d are defined as d v = D v,v ,
∀v ∈ V.
We defer the proof of Theorem IV.4 to Appendix C.
As observed in Theorem IV.3 for absolute leader systems,
for influenced leader systems, Theorem IV.4 also shows the
balancing behavior of domination scores in the social network,
which decides the deviation of the average opinion from α. In
addition, Theorem IV.4 indicates that for Problem 2, if |S0 | =
|S1 | = 1, given the leader s0 , it suffices to find a node s1 such
d
d
that (1 − α)( κs sπ0s + DsG1 ,s0 ) = α( κs sπ1s + DsG0 ,s1 ) to shift
0
1
0
1
the average opinion to α. Assuming κ1 = κ2 , and they both
approach infinity, then the condition is the same as what we
have derived in the absolute leader system.
The balancing behaviors shown in Theorem IV.3 and IV.4
exhibit interesting results when G is undirected and α = 1/2.
In particular, Theorems IV.3 and IV.4 imply the following
corollaries.
Corollary IV.5. For absolute leader systems, when G is
undirected, α = 1/2, and |S0 | = |S1 | = 1,
f (S1 , 1/2) =

θG (s0 )−1 − θG (s1 )−1
.
2RsG0 ,s1

(23)

Corollary IV.6. For influenced leader systems, when G is
undirected, α = 1/2, and |S0 | = |S1 | = 1,
f (S1 , 1/2) =

Theorem IV.3. For absolute leader systems, if |S0 | = |S1 | =
1,
f (S1 , α) =

f (S1 , α) =

0

(21)

As for the deviation of the average opinion from the given
value α, we give its expression the following theorem.

d

d

(1 − α)( κ0 πs0s + DsG1 ,s0 ) − α( κ1 πs1s + DsG0 ,s1 )

θG (s0 )−1 + 1/κ0 − θG (s1 )−1 − 1/κ1
. (24)
2(RsG0 ,s1 + 1/κ0 + 1/κ1 )

These corollaries show the role of information centrality of
leader nodes in an undirected network when the objective is
to balance the opinions in the network. If s1 has the same
information centrality as s0 (assuming κ1 = κ0 for influenced
leader systems), then µ(S1 ) = 21 , and so the opinion network
is balanced. If there is no such an s1 , then it is beneficial
to find a node s1 such that |θG (s1 ) − θG (s0 )| is small while
RsG0 ,s1 is relatively large.

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

C. Hardness of Choosing Optimal k Leaders
Next we show that Problem 1 is NP-hard. The hardness of
Problem 2 remains an open question.

such that a greedy algorithm for maximizing µ(S1 ) with upper
bound b leads to an approximation algorithm for optimum
solution S ∗ , where
S ∗ ∈ arg min |µ(P ) − α|

Theorem IV.7. The Absolute Leader Selection problem for
shifting social opinion, described in Problem 1, is NP-hard.
The proof of Theorem IV.7 is given in Appendix D.
We note that in both Problems 1 and 2, µ(S1 ), as a function
of S1 , is monotone and submodular.
Theorem IV.8. For both absolute and influenced leader systems, the set function µ(S1 ) is monotone and submodular.
The monotonicity and submodularity of µ(S1 ) for influenced leader systems follows in a straightforward manner from
results in [4], [7]. We are unaware of prior analogous results
for absolute leader systems. We give simple proofs for both
cases in Appendix G. Our proofs are based on analyzing the
escape probabilities of random walks in the network.

7

P ⊆Q,|P |≤k

is an optimal solution for Problem 1 or 2, respectively.
We apply a greedy algorithm to problem (25). For an upper
bound b, the algorithm Greedy returns a solution Sb . We
can compare different upper bounds by the solutions Greedy
returns. The bound b1 is a better upper bound than b2 if
|µ(Sb1 ) − α| < |µ(Sb2 ) − α|. We further define the best upper
bound input for algorithm Greedy as b∗ , or formally,
b∗ ∈ arg min |µ(Sb ) − α| .

(26)

b∈[α,1]

We use a modified binary search to converge to the best
upper bound b∗ for Greedy. In the next subsection, we
describe both the bound search algorithm and the routine
Greedy.

V. A LGORITHM
In this section, we present an algorithm for selecting a set
of nodes to be leaders in S1 , given set of leaders S0 , to shift
the average opinion as close as possible to a given value α.
A. Algorithm Intuition
It is well known that greedy algorithms give a (1 − 1/e) approximation for monotone submodular maximization problems
with cardinality constraints [31]. According to Theorem IV.8,
for either Problem 1 or 2, a greedy algorithm provides a
(1 − 1/e) approximation for the problem when α = 1.
However, for other values of α, the problems are not trivial to
solve. We observe that if µ(S1 ) ≤ α always holds, we have a
submodular maximization problem with cardinality constraint;
if µ(S1 ) ≥ α always holds, the problem is a submodular
minimization problem with the same cardinality constraint.
However, we do not know the value of µ(S1 ) beforehand.
Therefore, we need to design a more sophisticated algorithm
to approximately solve Problem 1 and 2.
The intuition behind our algorithm is to consider these
problems as submodular cost submodular knapsack (SCSK)
constraint maximization problems [33], [34]. An SCSK constrained maximization problem is defined as

B. Bounded Search Approximation Algorithm
We first define the algorithm in terms of Problem 1. We
describe the changes of the algorithm in order to solve
Problem 2 in the end of the subsection.
Algorithm 1: P = BoundSearch(G, Q, α, k, δ)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

maximize f (X) subject to g(X) ≤ b.

16

for submodular functions f and g, and upper bound b ∈ R.
Problems 1 and 2 can be interpreted as special cases of SCSK
with additional cardinality constraints:

18

maximize µ(S1 )
subject to: S1 ⊆ Q, µ(S1 ) ≤ b, |S1 | ≤ k.

17

19
20

(25)

21
22

Our algorithm is motivated by an approach in [34] for
the general SCSK problem. We approximate the optimum
µ(S1 ) for Problem 1 or 2 by imposing an upper bound for
the submodular function µ and then applying a submodular
maximization algorithm to the bounded problem. Specifically,
we find an appropriate upper bound constraint µ(S1 ) ≤ b,

23

P ←∅
bmin ← α; bmax ← 1
b̂ ← 1
// current upper bound
b̌ ← b̂
// current best upper bound
dmin ← α
// minimal |µ − α| so far
t←0
do
t←t+1
(S, µ) = Greedy(G, Q, b̂, k)
dˆ ← |µ − α|
if dˆ < dmin then
ˆ b̌ ← b̂
P ← S; dmin ← d;
if µ > α then
while µ ≤ (bmin + bmax )/2 do
bmax ← (bmin + bmax )/2
else
bmin ← b̂
ˆ < bmax then
if (α + d)
ˆ
bmax ← (α + d)
b̂ ← bmax ; continue
b̂ ← (bmin + bmax )/2
while bbmax
> exp(δ)
min
return P

Our algorithm, BoundSearch, is given in Algorithm 1. The
algorithm takes as input a graph G, a candidate vertex set
Q, an objective opinion α, a cardinality constraint k, and a

8

precision parameter δ for binary search. It returns a set of
nodes P , which is a subset of Q satisfying |P | ≤ k.
The bound b̂ is initialized with value 1, and the algorithm
searches for b∗ in the interval [bmin , bmax ] that might include a
better upper bound than b̌, the current best bound found by the
algorithm that leads to the smallest |µ(Sb )−α|. We update bmin
and bmax until bmin ≈δ bmax , and b∗ , b̌, b̂ ∈ [bmin , bmax ]. We
obtain b̌ ≈δ b∗ . Since b̌ is the current best upper bound found
by the algorithm, for any b ∈
/ [bmin , bmax ], |Sb̌ −α| ≤ |Sb −α|.
Before analyzing Algorithm 1, we recall the concept of ǫapproximation [32]:
Definition V.1. Given two numbers a, b ∈ R, a, b ≥ 0, if
exp(−ǫ)a ≤ b ≤ exp(ǫ)a ,

α

Optimum

DS

ER

Random

0.25
0.50
0.75
1.00

0.249830
0.499699
0.750014
0.999645

0.250214
0.500495
0.750014
0.999645

0.000083
0.000083
0.000083
0.000083

0.248751
0.122848
0.002391
0.576522

TABLE I: Average opinion in an absolute leader system. The
graph is the Twitter Retweet Network rt-higgs with a fixed s0
and a node s1 chosen via various methods.
α

Optimum

DS&K

ER

Random

0.25
0.50
0.75
1.00

0.250010
0.500010
0.750111
0.997124

0.250010
0.500010
0.750111
0.997124

0.000028
0.000028
0.000028
0.000028

0.327045
0.345662
0.305945
0.000000

TABLE II: Average opinion in an influenced leader system.
The graph is the Twitter Retweet Network rt-higgs with a
fixed s0 and a node s1 chosen via various methods.

then a is an ǫ-approximation of b, denoted by a ≈ǫ b.
Note that a ≈ǫ b if and only if b ≈ǫ a.
In Algorithm 2, we present the greedy routine P =
Greedy(G, Q, b̂, k) for the constrained submodular maximization described in (25). The algorithm takes as input a graph
G, a candidate set Q, an SCSK upper bound b̂, and an integer
k for the cardinality constraint. It returns a set of nodes P ,
which is a subset of Q satisfying |P | ≤ k and µ(P ) ≤ b̂.
The algorithm chooses the node that most increases µ(P )
without violating the upper bound from the candidate set in
each iteration, deletes it from the candidate set, and adds it to
the current leader set.

2
3
4
5
6
7
8

(1 − ζ) e−δ µ(S ∗ ) ≤ µ(P ) ≤ (1 − ζ)

−1 δ

e µ(S ∗ ) .

The BoundSearch algorithm can be applied to Problem 2
with the same approximation guarantee with the only difference that the stubbornness function κ is an input of the algorithm. The stubbornness function is also passed into Greedy
to calculate the average opinion. Theorem V.3 holds for the
corresponding algorithm P = BoundSearch(G, Q, α, k, κ, δ),
which calls Greedy(G, Q, b̂, k, κ).
C. Complexity Analysis

Algorithm 2: (P, µ) = Greedy(G, Q, b̂, k)
1

We defer the proof of Theorem V.3 to Appendix E.
The guarantee given in Theorem V.3 can also be written as:

A naive implementation of the proposed algorithm runs
in O(kqn3 log 1δ ) time, which is expensive for large graphs.
Using blockwise inversion and rank-1 update of matrices we
can improve the running time of BoundSearch to O(n3 log 1δ ).

P ←∅
while |Q| > 0 and |P | < k do
s ← arg maxu∈Q µ(P ∪ {u})
if µ(P ∪ {s}) ≤ b̂ then
P ← (P ∪ {s})

Theorem V.4. There exists an implementation of Algorithm 1
for a graph with n nodes that has running time O(n3 log δ1 ).

Q ← (Q\{s})
γ ← µ(P )
return (P, γ)

The proof of Theorem V.4 is given in Appendix F.
VI. E XPERIMENTS

To analyze Algorithm 2, we introduce the concept of the
minimum cover number.
Definition V.2. The minimum cover number kµ,b for set
function µ(S), S ⊆ Q, and b ∈ R is defined as
def

kµ,b = min{|S| : µ(S) ≥ b} ,
def

if there exists S satisfying µ(S) ≥ b, otherwise kµ,b = +∞.
Then, we obtain the approximation ratio of BoundSearch.
Theorem V.3. Consider a graph G, a candidate set Q,
an objective α, a cardinality constraint |P | ≤ k, and a
precision parameter δ > 0. Let S ∗ be an optimal solution
for Problem 1 for these parameters. The algorithm P =
BoundSearch(G, Q, α, k, δ) returns a node set P such that
µ(P ) ≈σ µ(S ∗ ) , in which σ = − ln(1 − ζ) + δ, and
def
ζ = max(1/e, 1/kµ,α).

In this section, we present experiments to highlight the
analytical results and to show the effectiveness of the proposed
algorithm.
We first study the properties of µ(S1 ) when |S0 | =
|S1 | = 1 in absolute and influenced leader systems for
α = 0.25, 0.5, 0.75, and 1. The leader s0 is chosen uniformly
at random. We run experiments on a directed and weighted
social network. We utilize the largest strongly connected
component of the Twitter Retweet Network with the keyword
“higgs”, which we refer to as rt-higgs [35]. The edges are
weighted by the number of retweets to a user. The network
has 13, 086 nodes and 63, 537 edges.
For the absolute leader system, we find the average opinion
of the network for the optimal solution to Problem 1, i.e.,
the optimal s1 as given by Theorem IV.3. We also show the
average opinion when s1 is chosen using heuristics motivated
by the theorem. The first heuristic, DS, is based on the domination score; we find the s1 such that the resulting µ({s1 })

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

α

BoundSearch

PDS&K

Random

0.25
0.50
0.75
1.00

0.250732
0.500976
0.750976
0.975863

0.252612
0.499114
0.748867
0.973205

0.640516
0.418073
0.455767
0.533567

TABLE IV: Average opinion in an external leader system on
the rt-higgs network with |S0 | = 100 and k = 100.

select set. To calculate the Proposition Domination Score, for
each leader in S0 , we choose a leader for S1 according to
Theorem IV.3 for absolute leaders and IV.4 for influenced
leaders. For all influenced leaders, κ = 1. Tables III and IV
shows that our algorithm converges to the desired value and
outperforms the heuristic in all tested cases.
0.7

0.7

α=0.2
α=0.35
α=0.5

0.6

μ(S)

0.5

0.4
0.3

1.0

α=0.25 BoundSearch

0.9
0.8

α=0.5 BoundSearch

0.8

α=0.75 BoundSearch

0.7

α=0.5 Optimal

0.7

α=0.5 BoundSearch

α=0.5 Optimal

0.5

0.4

0.4

0.3

α=0.75 Optimal

2

3
k

4

5

(a) Absolute leader system.

0.2

1

2

3
k

4

Fig. 3: Average opinion of Optimum vs. average opinion
of BoundSearch in an ErdősRényi graph with 30 nodes and
connecting probability 0.1. S0 leader sets are chosen randomly,
and S1 leader sets are chosen by brute-force search and
BoundSearch with different k and α values.
Next, to show the effectiveness of our leader selection
algorithm, we compare the result returned by our algorithm
BoundSearch with the optimal value returned by brute-force
search. We use an unweighted undirected ErdősRényi graph
with 30 nodes and connecting probability 0.1. We choose an
S0 leader set of size 3 at random. We run the BoundSearch
algorithm for both absolute leader system and influenced
leader systems with α ∈ {0.25, 0.50, 0.75}. Influenced leaders
use uniform stubbornness κ = 1. The results are shown in
Figure 3. In all cases, BoundSearch returns nearly optimal
results.
α

BoundSearch

PDS

Random

0.250730
0.500975
0.750976
1.000000

0.237610
0.565233
0.843537
1.000000

0.428106
0.206765
0.495980
0.466443

δ

10−2

10−1

0.1

10−4

10−3

δ

10−2

10−1

(b) External Leader System

5

(b) Influenced leader system.

0.25
0.50
0.75
1.00

10−3

Fig. 4: Effect of varying δ on BoundSearch at
α ∈ {0.20, 0.35, 0.50}. Experiment uses the Haggle graph.

0.3
1

0.2
10−4

(a) Internal Leader System

α=0.75 BoundSearch

0.6

0.5

0.2

α=0.25 Optimal

μ(S)

μ(S)

α=0.75 Optimal

0.6

α=0.25 BoundSearch

0.9

α=0.25 Optimal

0.1

0.4
0.3

0.2

1.0

α=0.2
α=0.35
α=0.5

0.6

0.5
μ(S)

minimizes the numerator of (22). We also use a heuristic
based on effective resistance (ER); here, s1 is chosen so as
to maximize the denominator of (22). Finally, we compute
the average opinion for a randomly chosen s1 . The results of
this experiment are shown in Table I,
We also conduct an experiment for an influenced leader
system using the rt-higgs network. Influenced leaders have
uniform stubbornness κ = 1, and the other parameters are the
same as the experiment for the absolute leader system. We find
the optimal s1 as well as the s1 chosen by heuristics motivated
by the numerator (DS&K) and denominator (ER) of the result
given in Theorem IV.4. We note that the s1 that minimizes
denominator of the result in Theorem IV.3 also minimizes
denominator of the result in Theorem IV.4. The results are
shown in Table II.
Table I and II show that when |S0 | = |S1 | = 1, the
domination score well captures the behavior of µ({s1 }). We
have observed similar results in various ErdősRényi graphs
with different choices of a single leader s0 .

9

TABLE III: Average opinion in an internal leader system on
the rt-higgs network with |S0 | = 100 and k = 100.
We next run our leader selection algorithm on rt-higgs
with |S0 | = 100 and k = 100. We compare the result
produced by our algorithm BoundSearch with a heuristic we
call the Propositional Domination Score and with a randomly

Finally, we explore the effect of varying the δ parameter
in BoundSearch. We run BoundSearch on the Haggle [36]
social contact graph. The Haggle graph is a multigraph, which
we turn it into an undirected simple graph by deleting all
duplicate edges. We use the largest connected component of
the graph which has 274 nodes and 2124 edges. All edges have
unit edge weight. We set k = 15 and α ∈ {0.2, 0.35, 0.5}. We
vary δ from 0.0001 to 0.25. For the absolute leader system,
we have |S0 | = 80, and for the influenced leader system,
leaders we have |S0 | = 15. Influenced leaders use uniform
stubbornness κ = 1. The results are shown in Figure 4. We
observe that as δ decreases, the results from BoundSearch
converge to a value close to α.
VII. C ONCLUSION
We have studied two French-DeGroot opinion dynamics
models where leaders have polarizing opinions. For both
models, we showed expressions for the steady-state opinion
using the Laplacian matrix of a leader-equivalent graph. For
the single leader case, we gave an explicit expression for the
steady-state opinion vector and analyzed the average opinion
based on the expression. Then, we studied the problem of
shifting the average steady-state opinion to a given value by
selecting an opposing leader set with a cardinality constraint.
We gave both a hardness result for this problem and an algorithm with provable approximation ratio. We also presented
experiments showing that our algorithm returns results close to
optimal in practice. Future work will focus on algorithms with
better approximation ratios and running time and the hardness
of the influenced leader selection problem.

10

R EFERENCES
[1] M. E. Yildiz, A. E. Ozdaglar, D. Acemoglu, A. Saberi, and
A. Scaglione, “Binary opinion dynamics with stubborn agents,” ACM
Trans. Economics and Comput., vol. 1, no. 4, pp. 19:1–19:30, 2013.
[2] A. Gionis, E. Terzi, and P. Tsaparas, “Opinion maximization in social
networks,” in Proc. 13th SIAM International Conference on Data
Mining, 2013, pp. 387–395.
[3] L. Vassio, F. Fagnani, P. Frasca, and A. E. Ozdaglar, “Message passing
optimization of harmonic influence centrality,” IEEE Trans. Control of
Network Systems, vol. 1, no. 1, pp. 109–120, 2014.
[4] D Scott Hunter and Tauhid Zaman.
Optimizing opinions with
stubborn agents under time-varying dynamics.
arXiv preprint
arXiv:1806.11253v3, 2019.
[5] R. Abebe, J. Kleinberg, D. Parkes, and C. E. Tsourakakis, “Opinion
dynamics with varying susceptibility to persuasion,” in Proc. 24th ACM
SIGKDD International Conference on Knowledge Discovery & Data
Mining, 2018, pp. 1089–1098.
[6] C. Musco, C. Musco, and C. E. Tsourakakis, “Minimizing polarization
and disagreement in social networks,” in Proc. 2018 World Wide Web
Conference on World Wide Web, 2018, pp. 369–378.
[7] V. S. Mai and E. H. Abed, “Optimizing leader influence in networks
through selection of direct followers,” IEEE Trans. Automat. Contr.,
vol. 64, no. 3, pp. 1280–1287, 2019.
[8] E. Mackin and S. Patterson, “Maximizing diversity of opinion in social
networks,” in Proc. 2019 American Control Conference, 2019, pp. 2728–
2734.
[9] J. R. French Jr, “A formal theory of social power.” Psychological review,
vol. 63, no. 3, p. 181, 1956.
[10] M. H. DeGroot, “Reaching a consensus,” Journal of the American
Statistical Association, vol. 69, no. 345, pp. 118–121, 1974.
[11] C. R. Sunstein, “The law of group polarization,” University of Chicago
Law School, John M. Olin Law & Economics Working Paper, no. 91,
1999.
[12] N. E. Friedkin, “The attitude-behavior linkage in behavioral cascades,”
Social Psychology Quarterly, vol. 73, no. 2, pp. 196–213, 2010.
[13] ——, “The problem of social control and coordination of complex
systems in sociology: A look at the community cleavage problem,” IEEE
Control Systems Magazine, vol. 35, no. 3, pp. 40–51, 2015.
[14] P. Barooah and J. P. Hespanha, “Graph effective resistance and distributed control: Spectral properties and applications,” in Proc. 45th
IEEE Conference on Decision and Control, 2006, pp. 3479–3485.
[15] S. Patterson and B. Bamieh, “Leader selection for optimal network
coherence,” in Proc. 49th IEEE Conference on Decision and Control,
2010, pp. 2692–2697.
[16] F. Lin, M. Fardad, and M. R. Jovanovic, “Algorithms for leader
selection in stochastically forced consensus networks,” IEEE Trans.
Automat. Contr., vol. 59, no. 7, pp. 1789–1802, 2014.
[17] A. Clark, L. Bushnell, and R. Poovendran, “A supermodular
optimization framework for leader selection under link noise in linear
multi-agent systems,” IEEE Trans. Automat. Contr., vol. 59, no. 2, pp.
283–296, 2014.
[18] A. Clark, B. Alomair, L. Bushnell, and R. Poovendran, “Minimizing
convergence error in multi-agent systems via leader selection: A
supermodular optimization approach,” IEEE Trans. Automat. Contr.,
vol. 59, no. 6, pp. 1480–1494, 2014.
[19] H. Li, R. Peng, L. Shan, Y. Yi, and Z. Zhang, “Current flow group
closeness centrality for complex networks?” in Proc. 2019 World Wide
Web Conference, 2019, pp. 961–971.
[20] E. Mackin and S. Patterson, “Submodular optimization for consensus
networks with noise-corrupted leaders,” IEEE Transactions on Automatic
Control, 2018.
[21] D. Acemoğlu, G. Como, F. Fagnani, and A. Ozdaglar, “Opinion fluctuations and disagreement in social networks,” Mathematics of Operations
Research, vol. 38, no. 1, pp. 1–27, 2013.
[22] G. Como and F. Fagnani, “From local averaging to emergent global
behaviors: The fundamental role of network interconnections,” Systems
& Control Letters, vol. 95, pp. 70–76, 2016.
[23] M. B. Cohen, J. Kelner, J. Peebles, R. Peng, A. Sidford, and A. Vladu,
“Faster algorithms for computing the stationary distribution, simulating
random walks, and more,” in Proc 57th IEEE Annual Symposium on
Foundations of Computer Science. 2016, pp. 583–592.
[24] ——, “Faster algorithms for computing the stationary distribution,
simulating random walks, and more,” arXiv preprint arXiv:1608.03270,
2016.
[25] D. J. Klein and M. Randić, “Resistance distance,” Journal of mathematical chemistry, vol. 12, no. 1, pp. 81–95, 1993.

[26] K. Stephenson and M. Zelen, “Rethinking centrality: Methods and
examples,” Social networks, vol. 11, no. 1, pp. 1–37, 1989.
[27] Y. Cao, W. Ren, and M. Egerstedt, “Distributed containment control with
multiple stationary or dynamic leaders in fixed and switching directed
networks,” Automatica, vol. 48, no. 8, pp. 1586–1597, 2012.
[28] M. Mesbahi and M. Egerstedt, Graph theoretic methods in multiagent
networks. Princeton University Press, 2010, vol. 33.
[29] G. Fricke, S. T. Hedetniemi, and D. P. Jacobs, “Independence and
irredundance in k-regular graphs,” Ars Combinatoria, vol. 49, pp. 271–
279, 1998.
[30] Y. Yi, T. Castiglia, and S. Patterson, “Shifting opinions in a social
network through leader selection,” arXiv preprint arXiv:1910.13009,
2019.
[31] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher, “An analysis of approximations for maximizing submodular set functionsi,” Mathematical
programming, vol. 14, no. 1, pp. 265–294, 1978.
[32] R. Peng and D. A. Spielman, “An efficient parallel solver for SDD
linear systems,” in Proc. 46th Symposium on Theory of Computing,
2014, pp. 333–342.
[33] A. Atamtürk and V. Narayanan, “The submodular knapsack polytope,”
Discrete Optimization, vol. 6, no. 4, pp. 333–344, 2009.
[34] R. K. Iyer and J. A. Bilmes, “Submodular optimization with submodular
cover and submodular knapsack constraints,” in Advances in Neural
Information Processing Systems, 2013, pp. 2436–2444.
[35] R. A. Rossi and N. K. Ahmed, “The network data repository with interactive graph analytics and visualization,” in Proc. 29th AAAI Conference
on Artificial Intelligence, 2015, pp 4292-4293.
[36] A. Chaintreau, P. Hui, J. Crowcroft, C. Diot, R. Gass, and J. Scott,
“Impact of human mobility on opportunistic forwarding algorithms,”
IEEE Transactions on Mobile Computing, no. 6, pp. 606–620, 2007.
[37] C. D. Meyer, Jr, “Generalized inversion of modified matrices,” SIAM
Journal on Applied Mathematics, vol. 24, no. 3, pp. 315–323, 1973.
[38] P. G. Doyle and J. L. Snell, “Random walks and electric networks,”
arXiv preprint math/0001057, 2000.

A PPENDIX
A. Some Useful Matrix Identities
We introduce some matrix identities.
Lemma A.1. For any p ⊥ 1, r ⊥ 1,
p ⊤ L† r = p ⊤ Rr .
The proof was given in [24, Appendix C.2].
Lemma A.2.
I − LL† =

1
−1

kD πk2
1
I − L† L = 11⊤ .
n

D −1 ππ ⊤ D −1 ,

Proof:
I − LL† = I − I Im(L) = I ker(L⊤ ) ,
I − L† L = I − I Im(L⊤ ) = I ker(L) ,
which completes the proof.
Lemma A.3. For any p ⊥ 1, r ⊥ 1,
p ⊤ L† D Π−1 r = p ⊤ L† r .
Proof: From Lemma A.1 we know that p ⊤ L† r =
p R† r = p ⊤ (I − W ⊤ )† Π−1 r . Therefore it suffices to
prove
⊤

p ⊤((D (I − W ⊤ ))† DΠ−1 − (I − W ⊤ )† Π−1 )r = 0 . (27)

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

Since



(D (I − W ⊤ ))† D − (I − W ⊤ )† (I − W ⊤ )
p

=p ⊤ I Im(I −W )D − I Im(I −W )
⊤

and p ⊥ 1, 1 ∈ ker(I − W ⊤ ), 1 ∈ ker(D(I − W ⊤ )), then
we attain p ∈ Im(I − W ) and p ∈ Im((I − W )D ), which
leads to


p ⊤ (D(I − W ⊤ ))† D − (I − W ⊤ )† (I − W ⊤ ) = 0 .
Therefore


(D (I − W ))† D − (I − W )† p ∈ ker(I − W )

Then we know that


p ⊤ (D(I − W ⊤ ))† D − (I − W ⊤ )† Π−1 r
=v ⊤ Π−1 r = r ⊤ Π−1 v ,

where v ∈ ker(I − W ). Therefore r ⊤ Πv = r ⊤ Π−1 π · β,
β is a scaling factor. Since r ⊤ Π−1 π = r ⊤ 1 = 0, we attain
(27), which proves the lemma.
Lemma A.4. For any y ⊥ 1,



1
Π(I − W ⊤ ) (I − W ⊤ )† Π−1 y = (I − 11⊤ )y .
n
Proof: It suffices to prove that



Π(I − W ⊤ ) (I − W ⊤ )† Π−1 y = y .

Since Π−1 y ⊥ π and (I − W )π = 0, therefore Π−1 y ∈
Im(I − W ⊤ ). Then Π(I − W ⊤ )(I − W ⊤ )† (Π−1 y ) =
ΠI Im(I −W ⊤ ) (Π−1 y ) = ΠΠ−1 y = y .
B. Proof of Proposition IV.1
Proof: We can express (1) and (2) in the following form





x S (t)
ẋ S (t)
0
0
.
=−
x F (t)
ẋ F (t)
LF,S LF,F
When the equilibrium is reached,



x̂ S (t)
0
0
= 0,
x̂ F (t)
LF,S LF,F

(30)

is a solution of (29). This can be verified by plugging it into
(29):
(I − W ⊤ )(I − W ⊤ )† Π−1 b s′1 ,s′0



=Π−1 Π(I − W ⊤ ) (I − W ⊤ )† Π−1 b s′1 ,s′0

1 ⊤
11 )b s′1 ,s′0 = Π−1 b s′1 ,s′0
n
The second equality follows from Lemma A.4. Then, we
further set z ′ = z − z s′0 1 to make z ′s′ = 0. Now we have
0
found z ′ which satisfies (28) except for the second equation.
We note that by multiplying a factor β to z ′ , the other n − 1
equations are still satisfied. So we let y ′ = (z u − z v )−1 z ′ .
Then x̂ = y ′ is the solution of (28).
=Π−1 (I −

C. Proof of Theorem IV.4
Proof: According to the Sherman-Morrison formula,
x̂ v = e ⊤
v
−

(L + E s0 κ0 )

−1

κ1 (L + E s0 κ0 )−1 E s1 (L + E s0 κ0 )−1
s0
1 + κ1 e ⊤
s1 (L + E κ0 )

−1

e s1

!

e s1 κ1 . (31)

−1

Let us then consider (L + E s0 κ0 ) . Since L is a singular
matrix, the Sherman-Morrison formula cannot be applied in
this case. Instead we apply the rank-1 update given in [37].
By further applying some matrix identities discussed in Appendix A, we obtain
(L + E s0 κ0 )

−1

1
†
· (L† e s0 )q ⊤ − 1(e ⊤
s0 L )
q s0
1
†
+ (1/κ0 + e ⊤
· 1q ⊤ , (32)
s0 L e s0 ) ·
q s0

=L† −

1
κ0 q s0
1
κ0 q s0

+

⊤
−1
+ b⊤
b s1 ,s0
v,s0 L DΠ

1
κ1 q s1

⊤
−1
+ b⊤
b s1 ,s0
s1 ,s0 L DΠ

.

(33)

We further note that for any p ⊥ 1, r ⊥ 1, p ⊤ L† D Π−1 r =
p ⊤ L† r (see Appendix A for details). Then we obtain


  
1
0
0
0
0
 1 = 1  . (28)

0
1
0
[I−W ⊤]F,s′0 [I−W ⊤]F,s′1 [I−W ⊤]F,F x̂ F (t)
0


By solving
1

z = (I − W ⊤ )† Π−1 b s′1 ,s′0

x̂ v =

When S0 = {s′0 } and S1 = {s′1 }, x S (t) = (1 0)⊤ ; it suffices
to solve

0

(29), y = z + γ1 also satisfies (29), where γ can be any real
number. We observe that

where q = D −1 π. Plugging (32) into (31), we arrive at

Since L = D(I − W ⊤ ), this is equivalent to solving



0
0
x̂ S (t)
= 0,
x̂ F (t)
[I − W ⊤ ]F,S [I − W ⊤ ]F,F

−1
−1 ⊤ ⊤
⊤ ⊤
(I − W ⊤ )(z ⊤
S z F ) = (−π s′ π s′ 0 )

11

µ(S1 ) =

1
κ0 q s0
1
κ0 q s0

+

†
+ e⊤
s0 L b s0 ,s1

1
κ1 q s1

†
+ b⊤
s1 ,s0 L b s1 ,s0

,

which directly leads to the desired result.
D. Proof of Theorem IV.7

(29)

we obtain a z F that satisfies the latter n − 2 equations in (28).
−1 ⊤ ⊤
We note that (29) has solutions because (−π−1
s′0 π s′1 0 ) ∈
ker(I − W ⊤ ). Since the rank of (I − W ⊤ ) is n − 1 and
(I − W ⊤ )1 = 0, for any z satisfying the system of equations

Problem 3 (Vertex Cover on 3 Regular Graphs). Given an
undirected connected 3-regular graph G = (V, E) and an
integer k, decide whether there is a vertex set S1 ⊆ V , such
that |S1 | ≤ k and |S1 | is a vertex cover of graph G.
We give a decision version of Problem 1 as follows.

12

Problem 4 (Absolute Leader Selection Decision Problem). In
an absolute leader system, given a strongly connected directed
graph G = (V, E, w), an opinion 0 leader set S0 6= ∅, two real
numbers α, β ∈ [0, 1], a candidate set Q ⊆ V\S0 , |Q| = q,
and an integer 1 ≤ k ≤ q, decide whether there is a leader
set S1 ⊆ Q with opinion 1 with at most k nodes, such that the
average opinion
P of all nodes (including leaders and followers)
µ(S1 ) = n1 v x̂ v satisfies f (S1 , α) = |µ(S1 ) − α| ≤ β.

Lemma A.5. Given an instance of problem 4, it is NP-hard to
decide if there is a set S1 , |S1 | ≤ k, such that |µ(S1 )−α| ≤ β

Proof: In this proof, we consider undirected graphs. Let
F = (V, E, w) be a graph consisting of a star graph Sn plus
a 3-regular subgraph F [V ] = (V, E, ω) supported on n − 1
leaves of Sn . Edges in Sn are weighted 3 and edges in F [V ]
are weighted 1. Then, we can construct an instance of Problem
1 by letting S0 = {s0 } be the central node of Sn , and the
candidate set Q be the node set V = V\{s0 }. and k be any
integer that satisfies 1 ≤ k ≤ q.
Completeness: If |S1 | = k and S1 is a vertex cover
of the 3-regular graph G = F [V ], then we consider the
steady-state of the followers x̂ F given by (4). In this case,
−1
x̂ F = diag ([6, . . . , 6]) [3, . . . , 3]⊤ = [ 21 , . . . , 12 ]⊤ . There
are n − 1 − k follower
thus, we have µ(S1 ) =
 nodes;
1 1
n−1+k
·
(n
−
1
−
k)
+
k
=
.
n 2
2n
Soundness: If S1 is not a vertex cover of graph G, then the
follower node set is not an independent set. So, the matrix
LF,F is a block diagonal matrix with each block associated
with a connected component of graph G[V \S]. Let T ⊆ V \S,
|V | ≥ 1 be the node set of a connected component. Following
the analysis given in the proof of [2, Theorem 4.1], we obtain
x̂ u < 21 for any u ∈ T . Then
n−1+k
.
2n
Next, we give a polynomial reduction form VC3 to ALSD:
p : {G = (V, E), k} → {G = (V, E, w), Q, k, α, β}. For any
given 3-regular graph G with n − 1 nodes, we construct a
weighted graph G = G + Sn , with all edges in the original
graph weighted 1 and all edges in the star Sn weighted 3. Let
Q = V , k be the same integer, α be any constant t greater or
equal to c = n−1+k
2n , and β = t − c. Then p(G = (V, E), k) =
(G + Sn , V, k, t, t − c) is a reduction from VC3 to ALSD.
Lemma A.5 immediately implies Theorem IV.7.
µ(S1 ) <

E. Proof of Theorem V.3
Proof: We let b̌ be the best bound found by the algorithm
with the smallest |µ(Sb̌ )−α|. And, Greedy with the best upper
bound b∗ returns the result µ(Sb∗ ). b∗ is given by (26).
If µ(P ∪ {s}) ≤ α is always satisfied during the execution,
then µ(P ∪{s}) ≤ b̂ is also always satisfied. Then the returned
Sb̌ is the same as what we get from a greedy algorithm which
adds the element with largest marginal gain to the current set
in each iteration until the cardinality constraint is violated. We
further define
Se ∈ arg max µ(T ) ,
T ⊆Q, |T |≤k

therefore by the result in [31] we obtain


1
e
e
µ(S).
µ(S) ≥ µ(Sb̌ ) ≥ 1 −
e

e then µ(S)
e = µ(S ∗ ), we attain the guarantee
If α ≥ µ(S),
e where e−γ = (1 − 1/e). If µ(S ) ≤
µ(Sb̌ ) ≈γ µ(S),
b̌
e
e then µ(S ∗ ) ∈ [µ(S ), µ(S)],
which implies
α ≤ µ(S),
b̌
µ(Sb̌ ) ≈γ µ(S ∗ ), where e−γ = (1 − 1/e).
If µ(P ∪ {s}) ≤ α is first violated when we add the
(t + 1)th node, we define Pt as the set of chosen nodes
of size t in Greedy, therefore |Pt | = t. We further define
ρ(st+1 ) = µ(Pt ∪ {st+1 }) − µ(Pt ). From the submodularity
1
of µ(S) we know ρ(st+1 ) ≤ t+1
µ(Pt ∪ {st+1 }) holds for the
greedy algorithm. Then µ(Pt ) = µ(Pt ∪ {st+1 }) − ρ(st+1 ) ≥
kµ,α −1
t
t+1 µ(Pt ∪ {st+1 }) ≥
kµ,α µ(Pt ∪ {st+1 }). By letting
b̄ = µ(Pt ∪ {st+1 }) (then by definition b̄ = µ(Sb̄ ) =
1
)µ(Sb̄ ). We
µ(Pt ∪ {st+1 })), we obtain µ(Sα ) ≥ (1 − kµ,α
∗
further attain µ(S ), µ(Sb∗ ) ∈ [µ(Sα ), µ(Sb̄ )], and b∗ ∈ [α, b̄].
Since b̌, b∗ ∈ [bmin , bmax ] and bmin ≈δ bmax , b̌ ≈δ b∗ we
obtain b̌ ∈ [α, eδ b̄] and therefore µ(Sb̌ ) ∈ [µ(Sα ), eδ µ(Sb̄ )],
so µ(Sb̌ ) ≈γ µ(S ∗ ), where e−γ = (1 − 1/kµ,α )e−δ .
F. Proof of Theorem V.4
Proof: We take the algorithm for the Absolute Leader
Selection problem as an example. In each execution of Line
3 of Algorithm 2 , we need to calculate the sum of steady
states of followers given by −1⊤ (LF,F )−1 LF,S x S , for all
P ∪ {u}, u ∈ Q. P and Q are the current leader set of opinion
1 and the current candidate set. Calculating (LF,F )−1 when
S1 = ∅ takes O(n3 ) running time. LF F can be updated at
iteration t + 1 by deleting the row and column associated with
candidate node u. From block matrix inversion, we obtain that
its inverse can be updated by
L(F (t)\{u}),(F (t)\{u})
−

LF (t),F (t)
e⊤
u

−1

−1

=

LF (t),F (t)

e ue ⊤
u LF (t),F (t)
−1
LF (t),F (t)
eu

−1

−1 !

.
(F (t)\{u}),(F (t)\{u})

To calculate µ(Pt ), we do not need to find
−1
L(F (t)\{u}),(F (t)\{u})
explicitly. It suffices to compare
−1
−1⊤ L(F (t)\{u}),(F (t)\{u})
L(F (t)\{u}),(S(t)∪{u}) x S∪{u} ,
for all u in the current candidate set. We note
−1 that
e u (e ⊤
)
takes
a
column
(row)
of
L
, and
F (t),F (t)
u
L(F (t)\{u}),(S(t)∪{u}) x S∪{u} is a column vector. By the
associative law, we compute the vector inner product first and
find the updated µ(S1 ) for at most n candidates in O(n2 )
total running time. The operations of taking the submatrices
do not change the complexity because for any candidate u,
these operations only take O(|Nu↑ | + |Nu↓ |) running time. So,
in each execution of Line 3 of Algorithm 2, these operations
can be done in O(m) total running time, where m is the
number of edges in the graph. After we find the best choice
st+1 in step t + 1, we update (LF,F )−1 explicitly, which
takes additional O(n2 ) time. Therefore, execution of Line
3 of Algorithm 2 takes O(n2 ) time. By using this simple

YI et al.: SHIFTING THE OPINIONS IN A SOCIAL NETWORK THROUGH LEADER SELECTION

acceleration, the complexity of Algorithm 2 is improved to
O(n3 + kn2 ) = O(n3 ). Algorithm 1 calls Greedy O(log 1δ )
times until bmax ≈δ bmin . Since bmax − bmin decreases
geometrically in Algorithm 1, the total running time of
BoundSearch is O(n3 log 1δ ).
For the Influenced Leader Selection Problem, the the rank-1
update is obtained using the Sherman-Morrison formula. And,
the running time of the Greedy routine is also O(n3 ) by a
similar implementation. We omit the details of the analysis.

To prove that µ(S1 ) is monotone and submodular, it suffices
to show that pGv (S1 , −S0 ) is monotone and submodular for all
v ∈ V.
Lemma A.6. For any S1 ⊆ T1 ⊆ V, S0 ⊆ V, and T1 ∩S0 = ∅,
for any v ∈ V
pGv (T1 , −S0 ) ≥ pGv (S1 , −S0 )
(0)

(1)

We present simple proofs for the submodularity based on
the escape probability interpretation of x̂ .
1) Steady-State Opinion Interpreted as Escape Probability:
The entries of x̂ F can be interpreted as the escape probability
of a random walker [38] in a Markov chain with absorbing
states define on graph G. Consider an absorbing Markov chain
P with S0 ∪ S1 the set of absorbing states and F the set of
non-absorbing states. Then the transition matrix has the form


I 0
P⊤ =
.
(34)
R Q

where R = (D F,F )−1 AF,S and Q = (D F,F )−1 AF,F .
Define a harmonic function y with boundary y B = x̂ S .
The interior y D is determined by (see [38], for a similar
formulation for undirected graphs)
−1

Ry B .

(1)

Proof: We first consider S1 = S1 and S1 = S1 ∪ {u},
where u ∈ (T1 \S1 ). For a random walker in graph G starting
from node v, we observe that

G. Monotonicity and Submodularity of µ(S1 )

y D = (I − Q)

13

(35)

pGv (S1 , −S0 ) = pGv ((S1 ∪ {u}), −S0)
= pGv (S1 , −(S0 ∪ {u})) + pGv ({u}, −(S0 ∪ S1 ))
and
(0)

pGv (S1 , −S0 ) = pGv ((S1 , −S0 )
= pGv (S1 , −(S0 ∪ {u}))
+ pGv ({u}, −(S0 ∪ S1 )) · pGu (S1 , −S0 ) ,

(0)

(1)

pGv (S1 , −S0 ) − pGv (S1 , −S0 )


= pGv ({u}, −(S0 ∪ S1 )) · 1 − pGu (S1 , −S0 )
= pGv ({u}, −(S0 ∪ S1 )) · pGu (S0 , −S1 ) ≥ 0 .
(i)

(i)

LF,S x S .

Combining with the boundary condition y B = x̂ S , we obtain
y = x̂ . y defines the concept of escape probability explained
below.
Let S0 and S1 be two sets of absorbing states in a Markov
chain (34). We let τvG (S1 , −S0 ) represent the event that in
a Markov chain defined by graph G, a random walker starts
from node v, hits any state u ∈ S1 before it reaches any
state u ∈ S0 . Then x̂ v is the probability that τvG (S1 , −S0 )
def
G
happens. We denote
 the escape probability as pv (S1 , −S0 ) =
G
Pr τv (S1 , −S0 ) . This escape probability is given by the
harmonic function y defined above (for example, see [38]).
We have shown that y = x̂ , so x̂ v = pGv (S1 , −S0 ). Similarly,
we define τvG (S0 , −S1 ) as the event that in the Markov chain
defined by graph G, a random walker starts from node v,
hits any state u ∈ S0 before it reaches any state u ∈ S1 ,

def
and we also denote by pGv (S0 , −S1 ) = Pr τvG (S0 , −S1 )
the probability that event τvG (S0 , −S1 ) happens. Since a
random walker is either absorbed by u ∈ S0 or u ∈ S1 ,
pGv (S1 , −S0 ) + pGv (S0 , −S1 ) = 1.
2) Internal Leader System: In the considered leaderfollower system with absolute leaders, given fixed S0 , µ(S1 )
is defined as
X
def 1
pGv (S1 , −S0 ) .
(36)
µ(S1 ) =
n
v∈V

(39)

Similarly, by defining a sequence of S1 , i = 1, . . . , t such
(t)
that t = |T1 \S1 | and S1 = T1 , we attain
(i−1)

pGv (S1 , −S0 ) ≥ pGv (S1

x̂ F = y D = − (LF,F )

(38)

by the Markov property. Therefore

Then we obtain
−1

(37)

, −S0 )

(40)

holds for all i ∈ [t]. And this leads to the result in lemma A.6.
Since pGv (S1 , −S0 ) = 1 − pGv (S0 , −S1 ), we attain the
following corollary
Corollary A.7. For any S0 ⊆ V, S1 ⊆ T1 ⊆ V, and T1 ∩S0 =
∅
pGv (S0 , −T1 ) ≤ pGv (S0 , −S1 ) .
Lemma A.8. For any S1 ⊆ T1 ⊆ V, S0 ⊆ V, T1 ∩ S0 = ∅,
and u ∈ V\(T1 ∪ S0 ),
pGv (T1 ∪ {u}, −S0 ) − pGv (T1 , −S0 )
≤ pGv (S1 ∪ {u}, −S0 ) − pGv (S1 , −S0 )

(41)

Proof: For any v ∈ V,
pGv (T1 ∪ {u}, −S0) − pGv (T1 , −S0 )
= pGv ({u}, −(T1 ∪ S0 )) · pGu (S0 , −T1 )

(42)

and
pGv (S1 ∪ {u}, −S0) − pGv (S1 , −S0 )
= pGv ({u}, −(S1 ∪ S0 )) · pGu (S0 , −S1 )

(43)

Using corollary A.7 we get the inequality in the lemma by
comparing (42) and (43).

14

3) External Leader System: In the considered leaderfollower system with influenced leaders, given fixed S0 , µ(S1 )
is defined as
X ′
def 1
µ(S1 ) =
pGv ({s′1 }, −{s′0 }) ,
(44)
n
v∈V

′
pGv ({s′1 }, −{s′0})

in which
represents the probability that a
random walker in augmented graph G ′ starting from v reaches
s′1 before it reaches s0 . To prove that µ(S1 ) is monotone
′
and submodular, it suffices to show that pGv ({s1 }, −{s0 }) is
monotone and submodular for all v ∈ V.
Lemma A.9. For any S1 ⊆ T1 ⊆ V, S0 ⊆ V, and T1 ∩S0 = ∅,
we consider the augmented graph G ′ defined by G, S0 , and S1 ;
and the augmented graph H′ defined by G, S0 and T1 . Then
H′ has the same node set as G ′ , the edge set of H′ consists of
all edges in the edge set of G ′ , and all (u, s′1 ), u ∈ (T1 \S1 ).
For any v ∈ V

Corollary A.10. For any S0 ⊆ V, S1 ⊆ T1 ⊆ V, and T1 ∩
S0 = ∅, G ′ and H′ have the same definitions as they are
defined in Lemma A.9. then
′

Lemma A.11. For any S1 ⊆ T1 ⊆ V, S0 ⊆ V, T1 ∩ S0 = ∅,
and u ∈
/ (S0 ∪ T1 ), we consider the augmented graph G ′
defined by G, S0 , and S1 ; and the augmented graph H′ defined
by G, S0 and T1 . Then H′ has the same node set as G ′ , the
edge set of H′ consists of all edges in the edge set of G ′ , and
all (l, s′1 ), l ∈ (T1 \S1 ). For any v ∈ V and u ∈
/ (S0 ∪ T1 ),
H′ +(u,s′1 )

pv

pGv

(1)



({s′1 }, −{s′0 })

  (1)

(1)
(1)
=Pr τvG ({s′1 }, −{s′0 }) ξvG (u, s′1 ) Pr ξvG (u, s′1 )
  (1)


G (1)
G
′
′
G (1)
′
′
+ Pr τv ({s1 }, −{s0 }) ξ v (u, s1 ) Pr ξ v (u, s1 )


 (1)

G (1)
G
′
G (1)
′
′
′
=Pr ξv (u, s1 ) + Pr τv ({s1 }, −{s0 }) ξ v (u, s1 )

 (1)

· 1 − Pr ξvG (u, s′1 )
.

We note that



(1)
G (1)
Pr τvG ({s′1 }, −{s′0 }) ξ v (u, s′1 )
 (0)

= Pr τvG ({s′1 }, −{s′0 }) ,

therefore
pGv

(1)

H′ +(u,s′1 )

(i)

(i−1)

′

({s′ }, −{s′0 }) − pH
({s′1 }, −{s′0})
 ′ 1 ′
 v′
H +(u,s1 )
′
′
= Pr ξv
(u, s′1 ) · pH
v ({s0 }, −{s1 })

pv

G ′ +(u,s′1 )

(47)

′

({s′ }, −{s′0 }) − pGv ({s′1 }, −{s′0 })
 ′ 1 ′

′
G +(u,s1 )
= Pr ξv
(u, s′1 ) · pGv ({s′0 }, −{s′1 })

pv

(48)

′

Then we extend the definition of ξvG (u, s′1 ) and denote
′
ξvG (U, s′1 ) as the event that a random walker in G ′ starting
from v passes through any edge (u, s′1 ), u ∈ U before it
G′
reaches any absorbing state. Similarly we define ξ v (U, s′1 ) as
the event that the random walker reaches an absorbing state
without passing through any (u, s′1 ), u ∈ U .
 ′

H +(u,s′1 )
Pr ξv
(u, s′1 )
 ′

H′ +(u,s′1 )
H +(u,s′1 )
= Pr ξv
(u, s′1 ) ξ v
((T1 \S1 ), s′1 )
 H′ +(u,s′ )

1
· Pr ξ v
((T1 \S1 ), s′1 )
 ′

H +(u,s′1 )
H′ +(u,s′1 )
+ Pr ξv
(u, s′1 ) ξv
((T1 \S1 ), s′1 )
 ′

H +(u,s′1 )
· Pr ξv
((T1 \S1 ), s′1 )
(49)

and

(45)

Similarly, by defining a sequence of G (i) , i = 1, . . . , t such
that t = |T1 \S1 |, we attain G (t) = H′ and
pvG ({s′1 }, −{s′0}) ≥ pGv

(46)

In addition,
 ′

H +(u,s′1 )
H′ +(u,s′1 )
Pr ξv
(u, s′1 ) ξv
((T1 \S1 ), s′1 ) = 0

(0)

({s′1 }, −{s′0 }) − pGv ({s′1 }, −{s′0})
 (1)
 

(0)
= Pr ξvG (u, s′1 ) · 1 − pGv ({s′1 }, −{s′0 })
 (1)

(0)
= Pr ξvG (u, s′1 ) · pGv ({s′0 }, −{s′1 }) ≥ 0 .

′

({s′1 }, −{s′0 }) − pGv ({s′1 }, −{s′0}) .

Proof: Following similar analysis as the proof of
Lemma A.9, we obtain

′
′
G
′
′
pH
v ({s1 }, −{s0 }) ≥ pv ({s1 }, −{s0 }) .

Proof: Let G + (u, v) be the graph attained by adding an
edge (u, v) to the graph G. We start by considering G (0) = G ′
′
and G (1) = G ′ + (u, s′1 ), u ∈ (T1 \S1 ). Let ξvG (u, s′1 ) be the
event that a random walker in G ′ starting from node v passes
through edge (u, s′1 ) before it reaches any absorbing state,
G′
and ξ v (u, s′1 ) be the event that a random walker does not
pass through (u, s′1 ) before reaching an absorbing state.

′

′
′
({s′1 }, −{s′0 }) − pH
v ({s1 }, −{s0 })

G ′ +(u,s′1 )

≤ pv

′

′

′

′
′
G
′
′
pH
v ({s0 }, −{s1 }) ≤ pv ({s0 }, −{s1 }) .

({s1 }, −{s0})

holds for all i ∈ [t]. This leads to the result in lemma A.9.
′
′
Since PvG ({s′1 }, −{s′0 }) = 1 − PvG ({s′0 }, −{s′1 }), we
obtain the following corollary


 ′
H′ +(u,s′1 )
H +(u,s′1 )
((T1 \S1 ), s′1 )
Pr ξv
(u, s′1 ) ξ v
 ′

G +(u,s′1 )
= Pr ξv
(u, s′1 ) ,

then we obtain
 ′

 ′

H +(u,s′1 )
G +(u,s′1 )
Pr ξv
(u, s′1 ) ≤ Pr ξv
(u, s′1 )

(50)

(51)

Applying Corollary A.10 and (51) to (47) and (48) leads to
the result stated in Lemma A.11.

