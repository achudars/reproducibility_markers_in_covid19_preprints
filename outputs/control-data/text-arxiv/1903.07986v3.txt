A BSDE Approach to Stochastic Differential Games Involving
Impulse Controls and HJBI Equation

arXiv:1903.07986v3 [math.OC] 7 Apr 2021

Liangquan Zhang1∗
1. School of Science
Beijing University of Posts and Telecommunications
Beijing 100876, China

April 8, 2021

Abstract
This paper focuses on zero-sum stochastic differential games in the framework of forwardbackward stochastic differential equations on a finite time horizon with both players adopting
impulse controls. By means of BSDE methods, in particular that of the notion from Peng’s
stochastic backward semigroups, we prove a dynamic programming principle for both the
upper and the lower value functions of the game. The upper and the lower value functions
are then shown to be the unique viscosity solutions of the Hamilton-Jacobi-Bellman-Isaacs
equations with a double-obstacle. As a consequence, the uniqueness implies that the upper
and lower value functions coincide and the game admits a value.

AMS subject classifications: 93E20, 60H15, 60H30.
Key words: Dynamic programming principle (DPP for short), Forward-backward stochastic
differential equations (FBSDEs for short), Hamilton–Jacobi–Bellman–Isaacs (HJBI for short),
Impulse control, Stochastic differential games, Value function, Viscosity solution.

1

Introduction

Fleming and Souganidis [28] first investigated two-player zero-sum stochastic differential games
as a pioneering work in a rigorous manner and proved that the lower and the upper value
functions of such games fulfill the dynamic programming principle shown to be the unique
viscosity solutions of the associated HJBI equations and coincide under the Isaacs condition.
This work developed the former results on differential games by Isaacs [34], Elliott and Kalton
[22], Friedman [25], Evans and Souganidis [23] from the purely deterministic into the stochastic
framework and has made a huge progress in the field of stochastic differential games. There
are many works which extend the Fleming and Souganidis approach into new contexts. For
instance, Buckdahn, Cardaliaguet and Rainer [9] prove the existence of Nash equilibrium points
for stochastic nonzero-sum differential games and characterize them. Meanwhile, the theory of
backward stochastic differential equations (BSDE) has been used to study stochastic differential
games. In this direction, the reader can see Hamadène and Lepeltier [30] and Hamadène,
Lepeltier, and Peng [31]. In particular, Buckdahn and Li [12] developed the findings obtained
in [30, 31] and generalized the framework in [28] to BSDE. Another direction for generalization
can be seen in Bayraktar and Poor [10] and Browne [11]. Concerning optimal stopping, the
L. Zhang acknowledges the financial support partly by the National Nature Science Foundation of China(Grant
No. 11701040, 11871010 &61871058) and the Fundamental Research Funds for the Central Universities (No.
2019XD-A11). E-mail: xiaoquan51011@163.com.
∗

1

interested reader is referred to the work of Ekström and Peskir [24], of Karatzas and Sudderth
[36], and of Karatzas and Zamfirescu [40].
Different from continuous control, impulse control is also an interesting topic in stochastic
control theory. There are three approaches to exploit it. For functional analysis methods, see
Bensoussan and Lions [6]. For direct probabilistic methods, see Robin [50] and Stettner [52].
For viscosity solution approaches concerning the study of impulse control, see Lenhart [42],
Tang and Yong [55], and Kharroubi et al. [38]. Impulse control has been found as a useful
tool for realistic models in mathematical finance, for instance, transaction costs and liquidity
risk. For more information on this direction refer, in particular, Korn [39], Ly Vath, Mnif and
Pham [43] and Bruder and Pham [13], Tang and Hou [54]. For nonzero sum impulse control
games, see [1]. Some recent advances in numerical impulse control can be seen in [2, 3, 4, 63].
Besides, the celebrated Pontryagin’s maximum principle for stochastic differential games within
the framework of BSDE can be found in Wang and Yu [58] and Wang, Xiao and Xiong [59].
The related topic in this fields see Chen and Wu [19] and Xu [57].
Cosso [17] and El Asri and Mazid [26] studied a two-player zero-sum stochastic differential
game, with both players adopting impulse controls on a finite time horizon of the following type:
The state process is governed by a n-dimensional SDE of the following type:
Z s
Z s
X


t,x;u,v
t,x;u,v
Xs
= x+
b s, Xs
ds +
σ s, Xst,x;u,v dWs +
ηl 1[ρl ,T ] (s)
t

+

X

t

ξm 1[τm ,T ] (s)

m≥1

Y

l≥1

1{τm 6=ρl } ,

(1)

l≥1

for all s ∈ [t, T ] , P -a.s., with Xt− = x, on some filtered probability space (Ω, F, P ), where
b : [0, T ] × Rn → Rn , σ (·, ·) : [0, T ] × Rn → Rn×d are given deterministic functions,
(Ws )s≥0 is
P
an d-dimensional
Brownian
motion,
(x,
t)
are
initial
time
and
state.
u
=
ξ
1
m
[τm ,T ] and
m≥1
P
v = l≥1 ηl 1[ρl ,T ] are the impulse controls of player I and player II, respectively. The infinite
product Πl≥1 1{τm 6=ρl } has the following meaning: whenever the two players act together on the
system at the same time, we take into account only the action of player II.
The gain functional for player I (resp., cost functional for player II) of the stochastic differential game is given by
"Z
T
X
Y

f s, Xst,x;u,v ds −
J (t, x; u, v) = E
c (τm , ξm ) 1{τm ≤T } (s)
1{τm 6=ρl }
t

+

X
l≥1

m≥1

l≥1

#



χ (ρl , ηl ) 1{ρl ≤T } + g XTt,x;u,v ,

(2)

where f : [0, T ] × Rn → R and g : Rn → R are two given deterministic functions, f denoting the
running function and g the payoff. The function c is the cost function for player I and the gain
function for player II, representing that when player I performs an action he/she has to pay a
cost, resulting in a gain for player II. Analogously, χ is the cost function for player II and the
gain function for player I. Cosso [17] and El Asri and Mazid [26] (under weak assumptions) have
shown that the upper and lower value functions coincide and the game admits a value.
The theory of BSDE can be traced back to Bismut [5] who studied linear BSDE motivated
by stochastic control problems. Pardoux and Peng [45] proved the well-posedness for nonlinear
BSDE. Subsequently, Duffie and Epstein [20] introduced the notion of recursive utilities in
continuous time, which is actually a type of BSDE where the generator f is independent of z.
Then, El Karoui et al. [41] extended the recursive utility to the case where f contains z. The
term z can be interpreted as an ambiguity aversion term in the market (see Chen and Epstein
2002 [18]). Particularly, the celebrated Black-Scholes formula indeed provided an effective way
2

of representing the option price (which is the solution to a kind of linear BSDE) through the
solution of the Black-Scholes equation. Since then, BSDE have been extensively studied and
used in the areas of applied probability and optimal stochastic controls, particularly in financial
engineering (cf. [41]).
In our present work, employing BSDE methods, in particular, the notion of stochastic backward semigroups (Peng [48]), allows us to prove the dynamic programming principle for the
upper and lower value functions of the game, with both players adopting impulse controls on a
finite time horizon, and to derive from it with the help of Peng’s method (similar to [48, 47])
the associated HJBI equations with a double-obstacle. To the best of our knowledge, this is the
first work studying impulse control games via BSDE.
Consider
Z T
 Z T


t,x;u,v
t,x;u,v
t,x;u,v
t,x;u,v
t,x;u,v
, Yr
, Zr
Zrt,x;u,v dWr
f r, Xr
+
dr −
Ys
= Φ XT
s
s
Y
X
X
−
c (τm , ξm ) 1{τm ≤T }
1{τm 6=ρl } +
χ (ρl , ηl ) 1{ρl ≤T } ,
(3)
m≥1

l≥1

l≥1

where X·t,x;u,v is defined in (1). The existence and uniqueness of BSDE (3) under certain
conditions can be guaranteed in the next section. We are interested in studying two-player
zero-sum stochastic differential game, with both players adopting impulse controls on a finite
time horizon driven by FBSDEs (1)-(3). Compared with above literature, our paper has several
new features. The novelty of the formulation and the contribution in this paper can be stated
as follows:
• First, in the framework of BSDE, the terminal condition will turn out to be a traditional
Φ(XTt,x;u,v ) plus gains functions with impulses controls. This new trait makes the backward
semigroup valid and avoids the Itô’s formula with jumps.
• Second, in Cosso [17] and El Asri and Mazid [26], the cost functional is defined by (2)
via linear expectation. Our paper considers a more general running cost functional, which
implies that the cost functionals will be supported by a BSDE, which in fact defines a
nonlinear expectation.
• At last, as a response to one of Cosso’s closing comments (Cosso [17], 2013): “we could
apply backward stochastic differential equations methods to provide a probabilistic representation, known as the nonlinear Feynman–Kac formula, for the value function of the
game”, our paper aims to further perfect this theory in the framework of BSDE, with
more rigorous proofs and new techniques introduced.
The rest of this paper is organized as follows: after some preliminaries and notations in the
second section, we devote the third section to studying the regularity properties of the upper and
lower value functions. Moreover, we prove the dynamic programming principle for the stochastic
differential game with some corollaries and generalizations, which are useful in proving that the
two value functions are viscosity solutions to the HJBI equation in Section 4. Furthermore,
under certain assumptions, we establish the comparison theorem for the HJBI equation, from
which one may deduce that the game admits a value. Finally, in Section 5, we conclude and
schedule possible generalizations in future. Some proofs can be found in Appendix A.

2

Preliminaries and Notations

Throughout this paper, we denote by Rn the space of n-dimensional Euclidean space, by Rn×d
the space the matrices with order n × d. The probability space is the classical Wiener space
3

(Ω, F, P ), and the Brownian motion W will be the coordinate process on Ω. Precisely:
Ω is

the set of continuous functions from [0, T ] to Rd starting from 0 (Ω = C0 [0, T ] ; Rd ), F is the
Borel σ-algebra over Ω, completed with respect to the Wiener measure P on this space, and
W denotes the coordinate process: Ws (ω) = ωs , s ∈ [0, T ], ω ∈ Ω. By F = {Fs , 0 ≤ s ≤ T },
we denote the natural filtration generated by {Ws }0≤s≤T and augmented by all P-null sets, i.e.,
Fs = σ {Wr , r ≤ s} ∨ NP , s ∈ [t, T ] , where NP is the set of all P -null subsets and T > 0 a
fixed real time horizon. For each t > 0, we denote by Fst , t ≤ s ≤ T the natural filtration of
the Brownian motion {Ws − Wt , t ≤ s ≤ T }, augmented by NP . ⊤ appearing in this paper as
superscript denotes the transpose of a matrix. U and V are two convex cones of Rn with U ⊂ V .
In what follows, C represents a generic constant, which can be different from line to line.
Now, we give the following definition.
P
P
Definition 2.1 An impulse control u = m≥1 ξm 1[τm ,T ] for player I (resp. v = l≥1 ηl 1[ρl ,T ]
for player II) on [t, T ] is such that
(1) (τm )m (resp., (ρl )l ), the action time, is a nondecreasing sequence of F-stopping time,
valued in [t, T ] ∪ {+∞} .
(2) (ξm )m (resp., (ηl )l ), the actions, is a sequence of U -valued (resp., V -valued) random
variable, where each ξm (resp., ηl ) is Fτm -measurable (resp., Fρl -measurable).
Remark 2.1 Let D ([0, T ] ; Rm ) be the space of all functions ξ : [0, T ] → RmPthat are right limit
with left continuous. Then, the pure jump part of ξ is defined by ξ j (t) = 0≤s≤t ∆ξ (s) , and
the continuous part is ξ c (t) = ξ (t) − ξ j (t) . By Lebesgue decomposition Theorem that we have
ξ c (t) = ξ ac (t) + ξ sc (t), t ∈ [0, T ], where ξ ac (t) is called the absolutely continuous part of ξ, and
ξ sc the singularly continuous part of ξ. Thus, we obtain that
ξ (t) = ξ ac (t) + ξ sc (t) + ξ j (t) , t ∈ [0, T ] , unique!
If we assume that ξ ac (t) + ξ sc (t) ≡ 0, t ∈ [0, T ] , then the singular control performs a special
form of a pure jump process, so-called impulse control (see [60] for details).
We now introduce the following spaces of processes:
(
2

n

S (0, T ; R) , R -valued Ft -adapted process φ(t); E

"

2

sup |φt |

0≤t≤T


Z
n
M (0, T ; R) , R -valued Ft -adapted process ϕ(t); E

T

2

2

#

)

<∞ ,





|ϕt | dt < ∞ ,
0

and denote N 2 [0, T ] = S 2 (0, T ; Rn ) × S 2 (0, T ; R) × M2 (0, T ; Rn ). Clearly, N 2 [0, T ] forms a
Banach space.
We assume that the following conditions hold.
(A1) The coefficients b : [0, T ]×Rn → Rn and σ : [0, T ]×Rn → Rn are continuous on [0, T ]×Rn ,
Lipschitz continuous in the state variable x, uniformly with respect to time, and bound
on [0, T ] × Rn .
(A2) The coefficients f : [0, T ] × Rn × R × Rd and Φ : Rn → R are continuous on [0, T ] × Rn ×
R × Rd , Lipschitz continuous in the state variable (x, y, z) , uniformly with respect to time,
and bounded on [0, T ] × Rn .
To get a well-defined gain functional, we add the following assumption and introduce the
concept of admissible impulse controls. Meanwhile, to ensure that multiple impulses occurring
at the same time are suboptimal, we put (like in Cosso [17]) the following:
4

(A3) Let cost functions c : [0, T ] × U → R and χ : [0, T ] × V → R be measurable and 1/2
Hölder continuous in time, uniformly with respect to the other variable. Furthermore,
inf

[0,T ]×U

c (t, ξ) > 0,

inf

[0,T ]×V

χ (t, η) > 0,

(4)

and there exists a function h : [0, T ] → (0, +∞) such that for all t ∈ [0, T ],
c (t, y1 + z + y2 ) ≤ c (t, y1 ) − χ (t, z) + c (t, y2 ) − h (t)

(5)

χ (t, z1 + z2 ) ≤ χ (t, z1 ) + χ (t, z2 ) − h (t)

(6)

and
for y1 , z, y2 ∈ U and z1 , z2 ∈ V. Moreover,


c (t, y) ≥ c ť, y and χ (t, y) ≥ χ ť, y

(7)

for all t, ť ∈ [0, T ] satisfying t ≤ ť, y ∈ U and z ∈ V.
P
Definition 2.2 Let u = m≥1 ξm 1[τm ,T ] be an impulse control on [t, T ], and let σ, τ be two
[t, T ]-valued F-stopping times. Then we define the restriction u[τ,σ] of the impulse control u by
X
o (s) , τ ≤ s ≤ σ,
u[τ,σ] (s) =
ξµt,τ (u)+m 1nτ
(8)
m≥1

µt,τ (u)+m≤s≤σ

where µt,τ (u) is called the number of impulses up to time τ, namely, µt,τ (u) :=
We now introduce the following subspaces of admissible controls.

P

m≥1 1{τm ≤τ } .

Definition 2.3 An admissible impulse control u for player I (resp., v for player II) on [t, T ]
is an impulse control for player I (resp., II) on [t, T ] with a finite average number of impulses,
i.e., E [µt,T (u)] < ∞, resp., E [µt,T (v)] < ∞, in which µt,T (u) is given by (8). The set of all
admissible impulse controls for player
by Ut,T (resp., Vt,T ). We
P
P I (resp., II) on [t, T ] is denoted
ξ
1
and
ũ
=
ξ̃
identify two impulse controls u =
m≥1 m 1[τ̃m ,T ] in Ut,T , and we
m≥1 m [τm ,T ]
write u ≡ ũ on [t, T ] if P ({u = ũ, a.e. on [t, T ]}) = 1. Similarly, we interpret u ≡ ũ on [t, T ]
in Vt,T .
Finally, we have still to define the admissible strategies for the game.
Definition 2.4 A nonanticipative strategy for player I on [t, T ] is a mapping α : Vt,T → Ut,T
such that for any stopping time τ : Ω → [t, T ] and any v1 , v2 ∈ Vt,T with v1 ≡ v2 on [[t, τ ]], it
holds that α (v1 ) ≡ α (v2 ) on [[t, τ ]]. Nonanticipative strategies for player II on [t, T ], denoted
by β : Ut,T → Vt,T , are defined similarly. The set of all nonanticipative strategies α (resp.,
β) for player I (resp., II) on [t, T ] is denoted by At,T (resp., Bt,T ). (Recall that [[s, τ ]] =
{(r, ω) ∈ [0, T ] × Ω, s ≤ r ≤ τ (ω)}).
Assume that (A1)-(A3) are in force, for any u (·) × v (·) ∈ Ut,T × Vt,T , it is easy to check that
FBSDEs (1)-(3) admit a unique Ft -adapted strong solution denoted by the triple
(X t,x;u,v , Y t,x;u,v , Z t,x;u,v ) ∈ N 2 [0, T ]
(See Pardoux and Peng [45]).
As in Peng in [48], given any impulse controls u (·) × v (·) ∈ Ut,T × Vt,T , we introduce the
following cost functional:
J(t, x; u (·) , v (·)) = Yst,x;u,v

s=t

5

,

(t, x) ∈ [0, T ] × Rn .

(9)

Under assumptions (A1)-(A3), the gain functional J(t, x; u (·) , v (·)), defined by (9) is well defined for every (t, x) ∈ [t, T ] × Rn , u ∈ Ut,T , and v (·) ∈ Vt,T . We are interested in two value
functions of the stochastic differential games of the following type:
V − (t, x) = inf

sup J(t, x; u, β (u)), (t, x) ∈ [0, T ] × Rn

(10)

V + (t, x) = sup

inf J(t, x; α (v) , v), (t, x) ∈ [0, T ] × Rn

(11)

β∈Bt,T u∈Ut,T

and
α∈At,T v∈Vt,T

for every (t, x) ∈ [0, T ] × Rn . When V − = V + , we say that the game admits a value and
V := V − = V + is called the value function of the game. Since the value function (10) and (11)
are defined by the solution of controlled BSDE (3), V − (V + ) is well-defined. Moreover, they are
both bounded Ft -measurable random variables. Nonetheless, we shall prove that V − (V + ) are
even deterministic.
Note that inf and sup in this paper should be interpreted via the essential infimum and
the essential supremum with respect to indexed families of random variables (see Karatzas and
Shreve [37]). For reader’s convenience, we recall the notion of essinf of processes. Given a
family of real-valued random variables ηα , α ∈ I, a random variable η is said to be essinfα∈I ηα ,
if (i) η ≤ ηα , P -a.s., for any α ∈ I; (ii) if there is another random variable ξ such that ξ ≤ ηα , P a.s., for any α ∈ I, then ξ ≤ η, P -a.s. The random variable esssupα∈I ηα can be introduced now
by the relation esssupα∈I ηα = −essinfα∈I (−ηα ). Finally, recall that essinfα∈I ηα = inf n≥1 ηαn
for some countable family (αn ) ⊂ I; esssupα∈I ηα has the same property.
We need the following estimations for BSDE, whose proof can be seen in Proposition 3.2 of
Briand et al. [7].

Lemma 2.1 Let y i , z i , i = 1, 2, be the solution to the following
i

i

y (t) = ξ +

Z

T

f

i

t

i

i


s, y (s) , z (s) ds −

Z

T

z i (s) dWs ,

(12)

t

i
h

β
< ∞, f i s, y i , z i satisfies the conditions (A2), and
where ξ i ∈ L2 (Ω, FT , P ) with E ξ i
E

"Z

T

f
t

i

i

i


s, y (s) , z (s) ds

β #

< ∞.

Then, for some β ≥ 2, there exists a positive constant Cβ such that


 β2
Z T
2
β
z 1 (s) − z 2 (s) ds 
E  sup y 1 (t) − y 2 (t) +
0≤t≤T

≤ Cβ E

"

ξ1 − ξ

0

2 β

+

Z

t

T

f1



s, y 1 (s) , z 1 (s) − f 2 s, y 2 (s) , z 2 (s) ds

Particularly, whenever putting ξ 2 = 0, f 2 = 0, one has


"
 β2
Z T
2
β
z 1 (s) ds  ≤ Cβ E ξ 1
E  sup y 1 (t) +
0≤t≤T

0

β

+

Z

t

T

β #
.

β #
.
f 1 (s, 0, 0) ds

We recall the following well-known comparison theorem (see Barles, Buckdahn, and Pardoux
[8], Proposition 2.6) for BSDE.
6


Lemma 2.2 (Comparison theorem) Let y i , z i , i = 1, 2, be the solution to the following
i

i

y (t) = ξ +

Z

T

t

f

i

s, ysi , zsi



ds −

Z

t

T

zsi dWs ,

(13)

h
i

2
where E ξ i
< ∞, f i s, y i , z i satisfies the conditions (A2), i = 1, 2. Under assumption (A2),

BSDE (13) admits a unique adapted solution y i , z i , respectively, for i = 1, 2. Furthermore, if
(i) ξ 1 ≥ ξ 2 , a.s.; (ii) f 1 (t, y, z) ≥ f 2 (t, y, z) , a.e., for any (t, y, z) ∈ [0, T ] × R × Rd . Then we
have y 1 (t) ≥ y 2 (t) , a.s.

3

Dynamic Programming Principle

In this section, we present the DPP for our stochastic differential games in the framework of
BSDE. The following lemma announces that the values functions are deterministic, which is
important to investigate the other properties of value functions.
Lemma 3.1 Let (t, x) ∈ [0, T ] × Rn . Under assumptions (A1)-(A3), V − (t, x) = E [V − (t, x)],
P -a.s. Since V − (t, x) coincides with its deterministic version E [V − (t, x)] , we can consider
V − : [0, T ] × Rn → R as a deterministic function. An analogous statement holds for the value
function V + .
The proof is displayed in Appendix A.
We shall consider the value functions obtained by no impulse controls, which is useful to
prove the Hölder continuity of value functions in the sequel.
Lemma 3.2 Assume that (A1)-(A3) are in force, then the lower and upper value functions are
given by
(14)
V − (t, x) = inf sup J(t, x; u, β (u)), (t, x) ∈ [0, T ] × Rn
β∈B̄t,T u∈Ūt,T

and
V + (t, x) = sup
α∈Āt,T

inf J(t, x; α (v) , v), (t, x) ∈ [0, T ] × Rn ,

v∈V̄t,T

(15)

where Ūt,T and V̄t,T contain all the impulse controls in Ut,T and Vt,T , respectively, which have no
impulses at time t. Similarly, Āt,T and B̄t,T are subsets of At,T and Bt,T , respectively. In particular, they contain all the nonanticipative strategies with values in Ūt,T and V̄t,T , respectively.
Proof We borrow the idea from Cosso’s work [17]. Fix ǫ > 0. Let u ∈ Ut,T \Ūt,T and β ∈
Bt,T \B̄t,T . Then, let v := β (u) ∈ Vt,T and β̄ (ǔ) = v̄ ∈ V̄t,T for any ǔ ∈ Ut,T for some β̄ ∈ B̄t,T .
Hence, we have to prove that there exist ū ∈ Ūt,T and v̄ ∈ V̄t,T such that
|J (t, x; u, v) − J (t, x; ū, v̄)|2 ≤ ǫ.
We may suppose v := Vt,T \V̄t,T ; in the other case can be proved similarly.
At the beginning, let u and v have only a single impulse at time t. Therefore, there exist
two [t, T ]-valued F-stopping times τ and ρ, with
= t) > 0, such that
P P (τ = t) > 0 and P (ρ P
u = ξ1[τ,T ] + û and v = η1[ρ,T ] + v̂, where û = m≥1 ξm 1[τm ,T ] ∈ Ūt,T , v̂ = l≥1 ηl 1[ρl ,T ] ∈ V̄t,T ,
ξ is an Fτ -measurable U -valued random variable and η is an Fρ -measurable V -valued random
variable. Let us introduce the following stopping times:




1
1
1{τ =t} + τ 1{τ >t} and ρn = ρ +
1{ρ=t} + ρ1{ρ>t}
τn = τ +
n
n
7

Clearly, τn → τ and ρn → ρ, as n approaches to infinity, P -a.s. Now we define the admissible
impulse controls as follows:
un = ξ1[τn ,T ] + û ∈ Ūt,T and vn = η1[ρn ,T ] + v̂ ∈ V̄t,T .
By Proposition 3.2 in [7] and Lemma 3.1, we have the following estimate:
|J (t, x; u, v) − J (t, x; ū, v̄)|2
2

Ytt,x;u,v − Ytt,x;un ,vn
"




≤ CE Φ XTt,x;u,v − Φ XTt,x;un ,vn
=

+

X

χ (ρl , ηl ) 1{ρl ≤T } −

X

χ (ρl , ηl ) 1{ρl ≤T } −

+

X

c (τm , ξm ) 1{τm ≤T }

T

t

Y

1{τm 6=ρl }

Y

1{τm 6=ρl }

l≥1

m≥1

l≥1

Z

c (τm , ξm ) 1{τm ≤T }

m≥1

l≥1

−

X

2

l≥1


t,x;u,v

f s, Xst,x;u,v , Yst,x;u,v , Zs


t,x;un ,vn

− f s, Xst,x;un ,vn , Yst,x;un ,vn , Zs

ds

2 #

.

Note that, for every s ∈ [t, T ] by by Burkholder-Davis-Gundy (B-D-G for short, see [51]) inequality, Xst,x;un ,vn → Xst,x;u,v as n → ∞, P -a.s. Therefore, from Grönwall’s inequality and the dominated convergence theorem, there is an integer N ≥ 1 such that |J (t, x; u, v) − J (t, x; un , vn )|2 ≤
ǫ. As for multiple impulses at time t, one can show the same result by using the assumptions
(A3), which actually leads to the case of the previous one with only a single impulse at time t.
We thus complete the proof.

Now we prove the two values functions are bounded.
Proposition 3.1 Assume that assumptions (A1)-(A3) are in force, Then, the lower and upper
value functions are bounded.
Proof We only consider the lower value function; the other case is analogous. Let ε > 0; then,
by the definition
value function (10), we have, for any (t, x) ∈ [0, T ] × Rn , there exists
Pof lower
some βε (u0 ) = l≥1 ηlε (u0 ) 1[ρε ,T ] ∈ Vt,T , where u0 ∈ Ut,T denotes the control with no impulses,
l

V − (t, x) =
=

inf

β∈Bt,T u∈Ut,T

−

T

s

+

X

"

 Z

t,x;u,β(u)
+
sup E Φ XT

β∈Bt,T u∈Ut,T

Z

t,x;u,β(u)

sup Yt

sup J(t, x; u, β (u)) = inf

inf

β∈Bt,T u∈Ut,T

Zrt,x;u,β(u) dWr −

X

T
s



f r, Xrt,x;u,β(u) , Yrt,x;u,β(u) , Zrt,x;u,β(u) dr

c (τm , ξm ) 1{τm ≤T }

m≥1

Y
l≥1

χ (ρl (u) , ηl (u)) 1{ρl (u)≤T }

l≥1

8

#

1{τm 6=ρl (u)}

t,x;u0 ,βε (u0 )

−ε
 Z

t,x;u0 ,βε (u0 )
+
= E Φ XT
≥ Yt
"
−

Z

s

T

s

Zrt,x;u0 ,βε (u0 ) dWr

+

T



f r, Xrt,x;u0 ,βε (u0 ) , Yrt,x;u0 ,βε (u0 ) , Zrt,x;u0 ,βε (u0 ) dr

X

#

χ (ρl (u) , ηl (u)) 1{ρl (u)≤T } − ε

l≥1

"



t,x;u ,β (u )
≥ E Φ XT 0 ε 0
+

Z

T

s

#


t,x;u0 ,βε (u0 )
t,x;u0 ,βε (u0 )
t,x;u0 ,βε (u0 )
dr − ε.
, Yr
, Zr
f r, Xr

The last inequality above is based on the condition (4) and the comparison theorem (see
Proposition 2.6 in [8]). Due to f and Φ are bounded, we deduce that V − is bounded from
below. In a similar way, we can prove that V − is also bounded from above.

After getting the first result on value functions, we now focus on (the generalized) DPP in
the framework our stochastic differential game (3), (10) and (11). To this end, we should first
define the family of (backward) semigroups associated with FBSDEs (3). As a matter of fact,
this concept of stochastic backward semigroups was first introduced by Peng [48] which was
employed to investigate the DPP for stochastic control problems.
For every the initial data (t, x) ∈ [0, T ] × Rn , a positive number δ ≤ T − t, two admissible impulse control processes u ∈ Ut,T and v ∈ Vt,T , and a real-valued random variable
η ∈ L2 (Ω, Ft+δ , P ; R)), we define

u,v 
t,x;u,v
,
η
+
Θ
Gt,x;u,v
t+δ := Ys
s,t+δ
for s ∈ [t, t + δ] where

Θu,v
s :=

X

χ (ρl , ηl ) 1{ρl ≤s} −

the couple Yst,x;u,v , Zst,x;u,v
t + η:

Yst,x;u,v = η + Θu,v
t+δ +

c (τm , ξm ) 1{τm ≤s}

m≥1

l≥1



X



t≤s≤t+δ

Z

t+δ
s

Y

1{τm 6=ρl }

l≥1

is the solution of the following BSDE with the time horizon


f r, Xrt,x;u,v , Yrt,x;u,v , Zrt,x;u,v dr −

Z

t+δ
s

Zrt,x;u,v dWr ,

(16)

for s ∈ [t, t + δ] and X t,x;u,v is the solution to SDE (1). Then, obviously, for the solution
Y t,x;u,v , Z t,x;u,v to BSDE (3), we have
i
h
i

h 
t,x;u,v
u,v
t,x;u,v
u,v
t,x;u,v
Y
+
Θ
=
G
+
Θ
Φ
X
Gt,x;u,v
T
T
t,T
t+δ
t+δ .
t,t+δ
Indeed,

i

h 
u,v
t,x;u,v
+
Θ
Φ
X
J (t, x; u, v) = Ytt,x;u,v = Gt,x;u,v
T
T
t,T
i
h
t,x;u,v
Yt+δ
+ Θu,v
= Gt,x;u,v
t+δ
t,t+δ
h 
i
t,x;u,v
t,x;u,v
= Gt,t+δ J t + δ, Xt+δ ; u, v .

Now we are ready to derive the the dynamic programming principle (DPP for short), by virtue
of backward semigroups introduced above, in which the impulse control can be regarded as
a terminal condition. This principle is important tool to character the viscosity solution of
corresponding H-J-B equation (see Section 4).
9

Theorem 3.1 Suppose that assumptions (A1)-(A3) hold. Then, the value function V − admits
the following DPP: For any 0 ≤ t < t + δ ≤ T, x ∈ Rn ,


i
h
t,x;u,β(u)
u,β(u)
t,x;u,β(u)
+ Θt+δ
, P -a.e.
V − t + δ, Xt+δ
V − (t, x) = inf sup Gt,t+δ
β∈Bt,T u∈Ut,T

An analogous statement holds for the value function V + .
Proof We prove only the dynamic programming principle only for V − ; the other case is
analogous.
Put


i
h
t,x;u,β(u)
u,β(u)
t,x;u,β(u)
sup Gt,t+δ
+ Θt+δ
.
Vδ− (t, x) = inf
V − t + δ, Xt+δ
β∈Bt,t+δ u∈Ut,t+δ

We proceed the proof that Vδ− (t, x) coincides with V − (t, x) into the following steps.
In the first step, we shall prove Vδ− (t, x) ≥ V − (t, x) . To this end, we have
i


h
u,β(u)
t,x;u,β(u)
t,x;u,β(u)
+ Θt+δ
V − t + δ, Xt+δ
sup Gt,t+δ
inf
Vδ− (t, x) =
β∈Bt,t+δ u∈Ut,t+δ

=

inf

β∈Bt,t+δ

Iδ (t, x, β) ,

where the notation Iδ (t, x, β) = supu∈Ut,t+δ Iδ (t, x, u, β (u)) with
i


h
u,v
t,x;u,v
−
+
Θ
t
+
δ,
X
V
Iδ (t, x, u, v) = Gt,x;u,v
t+δ , P -a.s.
t+δ
t,t+δ


and for some sequences {βi }i≥1 ⊂ Bt,t+δ such that Vδ− (t, x) = inf i≥1 Iδ t, x, βi1 , P -a.s. Let



i−1
.
Υ
:=
Ῡ
\
∪
Ῡ
ε > 0 and set Ῡi := Iδ t, x, βi1 − ε ≤ Vδ− (t, x) ∈ Ft , i ≥ 1. Construct
i
i
k
k=1
P
1 ∈ B
β
Certainly, {Υi }i≥1 forms an (Ω, F)-partition, moreover, β ε,1 :=
1
.
AcΥ
t,t+δ
i i
i≥1

1 , β ε,1 u1
t,
x,
u
=
cording
the
existence
and
uniquenss
of
FBSDEs
(3),
it
follows
that
I
δ

P
1 (u) , P -a.s., for each u1 ∈ U
1 ∈U
t,
x,
u,
β
.
Next,
for
∀u
1
I
Υ
t,t+δ
t,t+δ
δ
i
i
i≥1
X

1Υi Iδ t, x, βi1 − ε
Vδ− (t, x) ≥
i≥1

≥

X
i≥1


1Υi Iδ t, x, u1 , βi1 − ε


= Iδ t, x, u1 , β ε,1 − ε




t,x;u1 ,β ε,1 (u1 )
t,x;u1 ,β ε,1 (u1 )
u1 ,β ε,1 (u1 )
−
= Gt,t+δ
V
t + δ, Xt+δ
+ Θt+δ
− ε, P -a.s.. (17)
We now focus on the time interval [t + δ, T ] . From the definition of Vδ− (t, x), we also deduce
that, with help of previous idea and Lemma 3.2, for any y ∈ Rn , there exists βyε ∈ B̄t+δ,T for
each u2 ∈ Ut+δ,T such that

V − (t + δ, y) ≥ sup J t + δ, y, u2 , βyε u2 − ε, P -a.s.
(18)
u2 ∈Ut+δ,T

Now consider a decomposition of Rn , namely,
i ≥ 1. Take any yi ∈ Oi fixed, i ≥ 1 and
t,x;u1 ,β ε,1

Clearly, we always have Xt+δ

( )
u1

n
i≥1 Oi = R such
t,x;u1 ,β ε,1 (u1 )
=
define Xt+δ

P

t,x;u1 ,β ε,1 (u1 )

− Xt+δ

that diam(Oi ) ≤ ε, for each
P

.
t,x;u1 ,β ε,1 (u1 )
i≥1 yi 1
∈Oi

≤ ε, almost on Ω, for each u1 ∈ Ut,t+δ .

For every yi ∈ Oi , one can seek βyεi ∈ B̄t+δ,T such that (18) holds true.
10

Xt+δ

We introduce the strategy βu2,ε
1 ∈ B̄t+δ,T as follows:
βu2,ε
1 :=

X
i≥1

1

t,x;u1 ,β ε,1 (u1 )

Xt+δ

∈Oi

βε
yi

∈ B̄t+δ,T .

 P

Set βyεi u2 = l≥1 ηli u2 1[ρi (u2 ),T ] , for u2 ∈ Ut+δ,T ; then

(19)

l

X 2,ε


u2 :=
ηl,u1 u2 1hρ2,ε
βu2,ε
1

l,u1

l≥1

where

X

2,ε
2
ηl,u
:=
1
1 u
i≥1

and

X

u2 :=
1
ρ2,ε
l,u1
i≥1

(u2 ),T

t,x;u1 ,β ε,1 (u1 )
Xt+δ
∈Oi

t,x;u1 ,β ε,1 (u1 )
Xt+δ
∈Oi

 ηi
l

 ρi
l

i,

u2



(20)


u2 .

(21)



It is possible to define a new strategy β ε (u) from β ε,1 u1 ∈ Bt,t+δ and βu2,ε
u2 ∈ B̄t+δ,T where
1
u1 = u[t,t+δ] , u2 = u(t+δ,T ] (see Definition 2.2), in the following way:
Let
 X 1,ε 1 
 X 2,ε

β ε,1 u1 =
u2 =
ηl u 1[ρ1,ε (u1 ),T ] , βuε,2
(22)
ηl,u1 u2 1hρ2,ε (u2 ),T i,
1
l
l,u1
l≥1

then β ε (u) =

and

P

l≥1

ε
l≥1 ηl (u) 1[ρεl (u),T ] ,

where



2,ε
2
1{l>µt,t+δ (β ε,1 (u1 ))}
ηlε (u) = ηl1,ε u1 1{l≤µt,t+δ (β ε,1 (u1 ))} + ηl−µ
ε,1 (u)),u1 u
t,t+δ (β


u2 1{l>µt,t+δ (β ε,1 (u))} ,
u1 1{l≤µt,t+δ (β ε,1 (u1 ))} + ρ2,ε
ρεl (u) = ρ1,ε
l
l−µt,t+δ (β ε,1 (u)),u1

(23)

(24)

where µt,t+δ is defined in (8).
Next we shall show that β ε (u) is nonanticipating: Indeed, let κ : Ω → [t, T ] be an F-stopping
time and u, u′ ∈ Ut,T be such that u ≡ u′ on [t, κ]. Decomposing u, u′ into u1 , u′1 ∈ Bt,t+δ , u2 ,
u′2 ∈ B̄t+δ,T such that u = u1 ⊕ u2 , u′ = u′1 ⊕ u′2 where u1 ⊕ u2 (the same for u′1 ⊕ u′2 ) is defined
as follows:
Let
X
X
u1 =
ηl1 1[ρ1 ,T ] , u2 =
(25)
ηl2 1[ρ2 ,T ] .
l≥1

then u1 ⊕ u2 =

P

⊕
,
l≥1 ηl 1[ρ⊕
l ,T ]

l

l≥1

l

where

2
ηl⊕ = ηl1 1{l≤µt,t+δ (u1 )} + ηl−µ
1
t,t+δ (u1 ) {l>µt,t+δ (u1 )}

(26)

and
2
1
(27)
ρ⊕
l = ρl 1{l≤µt,t+δ (u1 )} + ρl−µt,t+δ (u1 ) 1{l>µt,t+δ (u1 )} .


u2 for u1 = u[t,t+δ] , u2 = u(t,T ] . We immediately have β ε,1 (u1 ) =
Thus β ε (u) = β ε,1 u1 ⊕ βu2,ε
1
β ε,1 (u′1 ) since u1 = u′1 on [t, κ ∧ t + δ]. On the other hand, u2 = u′2 on (t + δ, κ ∨ t + δ] and on
t,x;u′ ,β ε,1 (u′1 )
t,x;u ,β ε,1 (u1 )
= Xt+δ 1
{κ > t + δ}, we have Xt+δ 1
. This yields our desired result.

11

Fix u ∈ Ut,T arbitrarily and decompose into u1 = u[t,t+δ] , u2 = u(t+δ,T ] . Then, from (17) and
Proposition 2.6 in [8], we obtain
Vδ− (t, x)
≥

t,x;u1 ,β ε,1 (u1 )
Gt,t+δ



V

−





t+

t,x;u1 ,β ε,1 (u1 )
δ, Xt+δ



+

u1 ,β ε,1 (u1 )
Θt+δ



−ε




u1 ,β ε,1 (u1 )
t,x;u1 ,β ε,1 (u1 )
V − t + δ, Xt+δ
− Cε
+ Θt+δ


X
1
1
ε,1
1
1
ε,1
t,x;u ,β (u )
u ,β (u )

 − Cε, P -a.s.(28)
= Gt,t+δ
1 t,x;u1,β ε,1 (u1 )  V − (t + δ, yi ) + Θt+δ
t,x;u1 ,β ε,1 (u1 )

≥ Gt,t+δ

∈Oi

Xt+δ

i≥1

From (28) and Proposition 2.6 in [8], it follows
Vδ− (t, x)
t,x;u1 ,β ε,1

≥ Gt,t+δ



( ) X 
1
u1

i≥1

t,x;u1 ,β ε,1 (u1 )

Xt+δ

∈Oi

J

t + δ, yi , u2 , βyεi u


2

u1 ,β ε,1

+ Θt+δ



( )
− Cε
u1



 

u1 ,β ε,1 (u1 )
( )
t,x;u1 ,β ε,1 (u1 ) 2
ε
2
, u , βyi u
+ Θt+δ
− Cε
= Gt,t+δ
J t + δ, Xt+δ





t,x;u1 ,β ε,1 (u1 )
t,x;u1 ,β ε,1 (u1 ) 2
u1 ,β ε,1 (u1 )
≥ Gt,t+δ
J t + δ, Xt+δ
, u , βyεi u2 + Θt+δ
− Cε
h
i
t,x;u,β ε (u)
t,x;u,β ε (u)
= Gt,t+δ
Yt+δ
− Cε
t,x;u1 ,β ε,1

u1

t,x;u,β ε (u)

= Yt

− Cε, P -a.s., for every u ∈ Ut,T .

Therefore, we obtain
Vδ− (t, x) ≥

sup J (t, x; u; β ε (u)) − Cε
u∈Ut,T

≥

sup J (t, x; u; β ε (u)) − Cε

inf

β∈Bt,T u∈Ut,T

= V − (t, x) − Cε, P -a.s.
We now deal with the other case: Vδ− (t, x) ≤ V − (t, x) .
Let β ∈ Bt,T be arbitrarily chosen and u2 ∈ Ūt+δ,T . Define the restriction of β to Ut,t+δ as
β 1 (u1 ) := β (u1 ⊕ u2 )[t,t+δ] , u1 ∈ Ut,t+δ . The nonanticipativity property of β indicates that β 1
is independent of the special choice of u2 ∈ Ūt+δ,T . From the definition of Vδ− (t, x) ,
i

h
t,x;u ,β 1 (u1 )
t,x;u ,β 1 (u1 )
, P -a.s.
V − t + δ, Xt+δ 1
Vδ− (t, x) ≤ sup Gt,t+δ1
u1 ∈Ut,t+δ



Consider Iδ t, x, β = supu1 ∈Ut,t+δ Iδ t, x, u1 , β 1 u1 ; then there exists a sequence u1i i≥1 ⊂


1
1
1
Ūt,t+δ such that Iδ t, x, β 1 = sup
 i≥1 Iδ t,1 x, ui , β ui 1 , P1 -a.s.
With the same technique as
before, for any ε > 0, set Λ̄i := Iδ t, x, βi ≤ Iδ t, x, ui , β u1i + ε ∈ Ft , i ≥ 1. Construct

P
1
ε
Λi := Λ̄i \ ∪i−1
i≥1 1Λi ui ∈
k=1 Λ̄k . Certainly, {Λi }i≥1 forms an (Ω, F)-partition, moreover, u1 :=
1
ε
ε
Ut,t+δ . From the existence
 and uniqueness of FBSDEs (3), we deduce that Iδ t, x, u1 , β (u1 ) =
P
1
1
1
ui , P -a.s. Then,
i≥1 Iδ t, x, ui , β
 X

1Λi Iδ t, x, u1i , β 1 u1i + ε
Vδ− (t, x) ≤ Iδ t, x, β 1 ≤

1

=

i≥1

ε
1
Iδ t, x, u1 , β (uε1 ) +
t,x;uε1 ,β 1

= Gt,t+δ

( )
uε1



V

−



ε

t+

t,x;uε ,β 1 (uε1 )
δ, Xt+δ 1

12



+

uε1 ,β 1 (uε1 )
Θt+δ



+ ε, P -a.s.

Noting that β 1 (·) := β (· ⊕ u2 ) ∈ Bt,t+δ does not depend on u2 ∈ Ūt+δ,T , we can construct
β 2 (u2 ) := β (uε1 ⊕ u2 )[t+δ,T ] , for each u2 ∈ Ūt+δ,T such that β 2 : Ūt+δ,T → V̄t+δ,T belongs to
B̄t+δ,T , due to β ∈ Bt,T . Therefore, from the definition of V − (t + δ, y) and Lemma 3.2, we have,
for any y ∈ Rn ,




t,x;uε1 ,β 1 (uε1 )
t,x;uε1 ,β 1 (uε1 )
−
2
V
t + δ, Xt+δ
≤ sup J t + δ, Xt+δ
; u2 , β (u2 ) .
u2 ∈Ut+δ,T


There exists a sequence ui2

⊂ Ut+δ,T such that


t,x;uε ,β 1 (uε1 )
sup J t + δ, Xt+δ 1
; u2 , β 2 (u2 )

i≥1

u2 ∈Ut+δ,T



t,x;uε ,β 1 (uε1 ) i
; u2 , β 2
δ, Xt+δ 1

= sup J t +
i≥1

ui2





.

Then with the same technique as before, for any ε > 0, set


n
t,x;uε1 ,β 1 (uε1 )
2
; u2 , β (u2 )
Π̄i : =
sup J t + δ, Xt+δ
u2 ∈Ut+δ,T



≤ J t+

t,x;uε ,β 1 (uε1 ) i
δ, Xt+δ 1
; u2 , β 2

ui2





o
+ ε ∈ Ft+δ , i ≥ 1.


. Certainly, {Πi }i≥1 also forms an (Ω, F)-partition, moreover,
Construct Πi := Π̄i \ ∪i−1
Π̄
k
k=1
P
P
uε2 := i≥1 1Πi ui2 ∈ Ut+δ,T . Then, β 2 (uε2 ) = j≥1 1Πi . We construct a new strategy β (uε1 ⊕ uε2 ) =
β 1 (uε1 ) ⊕ β 2 (uε2 ) . From the existence and uniqueness of FBSDEs (3), we have


1 ε
t,x;uε
1 ,β (u1 ) ;uε ,β 2 uε
t+δ,X
t,x;uε1 ,β 1 (uε1 ) ε
( 2)
2
2
ε
J t + δ, Xt+δ
; u2 , β (u2 )
= Yt+δ t+δ
1 ε
t,x;uε
1 ,β (u1 )

=

X

t+δ,X
1Πi Yt+δ t+δ

=

X

1Πi J

;uj2 ,β 2 (uj2 )

j≥1

j≥1



t

t,x;uε ,β 1 (uε1 ) j
; u2 , β 2
+ δ, Xt+δ 1

 
uj2
. (29)

Therefore,
V

−



t+

t,x;uε ,β 1 (uε1 )
δ, Xt+δ 1



≤

sup

J t+

u2 ∈Ut+δ,T

≤

X





t,x;uε ,β 1 (uε1 )
δ, Xt+δ 1
; u2 , β 2 (u2 )

t,x;uε1 ⊕uj2 ,β (uε1 ⊕uj2 )

1Πi Yt+δ

+ε

j≥1

t,x;uε1 ⊕uε2 ,β (uε1 ⊕uε2 )

= Yt+δ

t,x;uε ,β(uε )

= Yt+δ

+ε

+ ε,

(30)

where uε = uε1 ⊕ uε2 ∈ Ut,T . Repeating the method before, from (29) and (30) and Proposition
2.6 in [8], we have
i
h
t,x;uε ,β 1 (uε1 )
uε ,β(uε )
t,x;uε ,β(uε )
+ Cε
+ Θt+δ
Yt+δ
Vδ− (t, x) ≤ Gt,t+δ1
i
h
ε
ε
ε
ε
ε
1
ε
u ,β(u )
t,x;u ,β(u )
t,x;u ,β (u )
+ Cε
+ Θt+δ
Yt+δ
= Gt,t+δ
t,x;uε ,β(uε )

= Yt

≤

sup
u∈Ut,T

+ Cε

t,x;u,β(u)
Yt

13

+ Cε, P -a.s.,

which holds for all β ∈ Bt,T .
Vδ− (t, x) ≤ inf

t,x;u,β(u)

sup Yt

β∈Bt,T u∈Ut,T

+ Cε = V − (t, x) + Cε

Now letting ε → 0, we get the desired result, Vδ− (t, x) ≤ V − (t, x). The proof is completed. 
Next, we will show that the continuity of value functions with respect to x and t. Due to
the influence of Brownian motion, the value function will proved to be Lipschitz continuity on
x, but 1/2 hölder on t.
Proposition 3.2 Assume that assumptions (A1)-(A3) are in force. Then the lower value function V − (t, x) is 12 -Hölder continuous in t: There exists a constant C > 0 such that, for every
(t, x) ∈ [0, T ) × Rn

(31)
≤ C x − x′ ,
V − (t, x) − V − t, x′
1

≤ C t − t′ 2 .
V − (t, x) − V − t′ , x
(32)
Proof The first property of the lower value function V − (t, x) which we present is an immediate
consequence of Proposition 3.2 in [7].
Let (t, x) ∈ [0, T ) × Rn and δ > 0 be arbitrarily given such that 0 < δ < T − t. Then for
every ε > 0, thanks to Lemma 3.2, there exist uε ∈ Ut,T and βε ∈ B̄t,T (This ensures no impulse
on initial state) such that
V − (t, x) − V − (t + δ, x)

 

 
t,x;û ,β (û )
t,x;û ,β (û )
t,x;u ,β̂ (u )
t,x;u ,β̂ (u )
+ε
− Gt+δ,Tε ε ε Φ XT ε ε ε
≤ Gt,T ε ε ε Φ XT ε ε ε

(33)

where ûε ∈ Ut+δ,T and β̂ε ∈ Bt,T will be determined soon. Indeed, from (14) and (15), there
exist uε ∈ Ut,T and βε ∈ B̄t,T such that

 
ε
t,x;u ,β̂ (u )
t,x;u ,β̂ (u )
≥ V − (t, x) −
(34)
Gt,T ε ε ε Φ XT ε ε ε
2
and

 
ε
t,x;û ,β (û )
t,x;û ,β (û )
(35)
≤ V − (t + δ, x) + .
Gt+δ,Tε ε ε Φ XT ε ε ε
2
From (34) and (35), one can P
obtain (33) easily.
P
ε 1 ε
ε
We
postulate
that
u
=
ξ
∈
U
;
now
define
û
as
û
=
ε
t,T
ε
ε
[τ
,T
]
m
m≥1
τm ≤t+δ ξm 1t+δ +
m
P
ε
ε ,T ] . Observe that ûε is an impulse control constructing from uε via gathering all
τm >t+δ ξm 1[τm
the impulses in the interval [t, t + δ] . To eliminate the impulses on time t + δ of player II, we
define vε = β̂ε (u) = βε (ûε ) ∈ V̄t+δ,T for any u ∈ Ut,T . After this work, (33) can be written as
V − (t, x) − V − (t + δ, x)

 

 
t,x;ûε ,vε
t,x;uε ,vε
+ ε.
Φ XTt,x;ûε ,vε
− Gt+δ,T
Φ XTt,x;uε ,vε
≤ Gt,T

14

(36)

We deal with

 

 
t,x;ûε ,vε
t,x;uε ,vε
Φ XTt,x;ûε ,vε
− Gt+δ,T
Φ XTt,x;uε ,vε
Gt,T
Z T
Z T




t,x;ûε ,vε
t,x;uε ,vε
t,x;ûε ,vε
Zrt,x;uε ,vε dWr
dWr −
Zr
dr +
− Φ XT
= Φ T, XT
s
s
 


X
X
Y
ε 
ε
ε
+ c t + δ,
ξm
1t+δ +
c (τm
, ξm
) 1[τm
ε ,T ]  1{τ ε ≤T }
1{τ ε 6=ρε }
m
m

τm ≤t+δ

−

X

τm >t+δ

ε
ε
c (τm
, ξm
) 1{τm
ε ≤T }

m≥1

+

Z

T

s

−

Z

T

s

Y
l≥1

l≥1

l

1{τ ε 6=ρε }
m
l

f r, Xrt,x;uε ,vε , Yrt,x;uε ,vε , Zrt,x;uε ,vε





f r, Xrt,x;ûε ,vε , Yrt,x;ûε ,vε , Zrt,x;ûε ,vε dr,

(37)

but from conditions (5) and (7), we have


X
X
ε 
ε
ε
ξm
c t + δ,
≤
c (τm
, ξm
) 1t+δ .
τm ≤t+δ

τm ≤t+δ

Hence, (37) yields


 

 
t,x;ûε ,vε
t,x;uε ,vε
Φ XTt,x;ûε ,vε
− Gt+δ,T
Φ XTt,x;uε ,vε
Gt,T
Z T
Z T




t,x;ûε ,vε
t,x;uε ,vε
t,x;ûε ,vε
Zrt,x;uε ,vε dWr
dWr −
Zr
dr +
− Φ XT
≤ Φ T, XT
s
s
Z T

f r, Xrt,x;uε ,vε , Yrt,x;uε ,vε , Zrt,x;uε ,vε
+
s
Z T 

f r, Xrt,x;ûε ,vε , Yrt,x;ûε ,vε , Zrt,x;ûε ,vε dr.
−

(38)

s

Taking the expectation on both sides of (38) and noting Lemma 3.1, we have

 

 
t,x;ûε ,vε
t,x;uε ,vε
Φ XTt,x;ûε ,vε
− Gt+δ,T
Φ XTt,x;uε ,vε
Gt,T
"




≤ E Φ XTt,x;uε ,vε − Φ XTt,x;ûε ,vε dr
+

Z

−

Z

T

s

f r, Xrt,x;uε ,vε , Yrt,x;uε ,vε , Zrt,x;uε ,vε

T

f

s





r, Xrt,x;ûε ,vε , Yrt,x;ûε ,vε , Zrt,x;ûε ,vε



#

dr .

(39)

ε ,vε
ε ,vε
Set Ξ̂r = Ξt,x;u
− Ξt,x;û
, r ∈ [t + δ, T ] for Ξ = X, Y, Z. By B-D-G inequality and classical
r
r
method, we have
#
"
Z

E

sup

t+δ≤r≤T

X̂r

2

+

sup

Ŷr

2

t+δ≤r≤T

T

+

Ẑr

s

15

2

dr ≤ C t − t′

1
2

.

Therefore,
V − (t, x) − V − (t + δ, x)

 

 
t,x;ûε ,vε
t,x;uε ,vε
Φ XTt,x;ûε ,vε
− Gt+δ,T
Φ XTt,x;uε ,vε
≤ Gt,T

≤ C t − t′

1
2

+ ε.

Letting ε → 0, we get the desired result. We thus complete the proof.

Now we are concerned on a special case of DPP, that is s = t, thanks to conditions (A3), the
multiple impulses can be neglected. It will be useful in proving that the two value functions are
viscosity solutions to the associated HJBI equation and deriving the so called lower and upper
obstacles. Whilst, it announces that our games problems can interpreted via optimal stopping
times.
Lemma 3.3 Assume assumptions (A1)-(A3) are in force. Given any (t, x) ∈ [0, T ] × Rn , we
have
h
t,x;u,β(u)
sup
V − (t, x) =
inf
− c (t, ξ) 1{τ =t} 1{ρ=+∞}
Gt,t
ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

i

t,x;ξ1[τ,T ] ,η1[ρ,T ]
,
+χ (t, η) 1{ρ=t} + V − t, Xt

(40)

where Tt,+∞ is the set of F-stopping times with values in {t, +∞}, τ ∈ Tt,+∞ , ξ ∈ Fτ , u = ξ1[τ,T ]
and ρ ∈ Tt,+∞ , η ∈ Fρ , β (u) = η1[ρ,T ] . An analogous statement holds for the upper value function
V + (t, x).
In Theorem 3.1, consider V − with δ = 0:
"

Proof

V − (t, x) =

inf

t,x;u,β(u)

sup Gt,t

β∈Bt,T u∈Ut,T

−

X

 X

t,x;u,β(u)
χ (ρl , ηl ) 1{ρl =t}
+
V − t, Xt

c (τm , ξm ) 1{τm =t}

m≥1

Y

l≥1

#

1{τm 6=ρl } .

l≥1

P
Given any u ∈ Ut,T , consider the strategy β (u) = η1[ρ,T ] . Let u =
m≥1 ξm 1[τm ,T ] , then
constrcut a new control ū = ξ1[τ,T ] , where


Y
Y
X
1{τm >t}  + ∞
τ = t 1 −
1{τm >t} , ξ =
ξm 1{τm =t} .
m≥1

m≥1

m≥1

t,x;u,β(u)

t,x;ξ1

,η1

[τ,T ]
[ρ,T ]
= Xt
,
Apparently, τ ∈ Tt,+∞ and ξ ∈ Fτ . Meanwhile, we deduce that Xt
P -a.s. By means of (A3), it follows that
i

h X
t,x;u,β(u)
t,x;u,β(u)
−
c (t, ξm ) 1{τm =t} 1{ρ=+∞} + χ (t, η) 1{ρ=t} + V − t, Xt
Gt,t

m≥1

≤

t,x;u,β(u)
Gt,t

h

As a result, we have

i

t,x;ξ1[τ,T ] ,η1[ρ,T ]
.
− c (t, ξ) 1{τ =t} 1{ρ=+∞} + χ (t, η) 1{ρ=t} + V − t, Xt

V − (t, x) ≤

inf

sup

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

h
E − c (t, ξ) 1{τ =t} 1{ρ=+∞}

i

t,x;ξ1[τ,T ] ,η1[ρ,T ]
.
+χ (t, η) 1{ρ=t} + V − t, Xt
16

The reverse inequality can be proved in the analogous way. We end the proof.

In order to prove the the two value functions satisfy, in the viscosity sense, the terminal
condition to the HJBI equation. We need a useful technical lemma.
Lemma 3.4 Assume assumption (A1)-(A3) are in force. Given any (t, x) ∈ [0, T ] × Rn , we
have
V − (t, x)
=

sup

inf

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

t,x;u,β(u)

Gt,t

h

− c (t, ξ) 1{τ =t} 1{ρ=+∞}




t,x;ξ1[τ,T ] ,η1[ρ,T ]
+χ (t, η) 1{ρ=t} + V − t, Xt
1 − 1{τ =+∞,ρ=+∞}
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Φ XT
1{τ =+∞,ρ=+∞} , (41)
t

where u0 , v0 are the controls with no impulses. An analogous statement holds for the upper value
function V + .
Proof

For any ε > 0, from the definition of inf, there exist ρε,1 ∈ Tt,+∞ , η ε,1 ∈ Fρε,1 such that

the right side of(41)
h
t,x;u,β(u)
≥ Gt,t
− c (t, ξ) 1{τ =t} 1{ρε,1 =+∞}


t,x;ξ1[τ,T ] ,ηε,1 1[ρε,1 ,T ] 


+χ t, η ε,1 1{ρε,1 =t} + V − t, Xt
1 − 1{τ =+∞,ρε,1=+∞}
Z T


i

t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Φ XT
1{τ =+∞,ρε,1 =+∞}
t

−ε.

To deal with V

(42)

−



t,x;ξ1[τ,T ] ,ηε,1 1[ρε,1 ,T ]

t, Xt



, let ǔ ∈ Ūt,T . From Theorem 3.1, there exsits a

strategy β ε,2 ∈ B̄t,T such that


 

t,x;ξ1[τ,T ] ,ηε,1 1[ρε,1 ,T ]
t,x;ξ1[τ,T ] ,ηε,1 1[ρε,1 ,T ]
V − t, Xt
≥ E J t, Xt
, ǔ, β ε,2 (ǔ) − ε.
Define




uε =
ξ1{τ =t} + v0 1{τ =+∞} 1t + ǔ 1 − 1{τ =+∞,ρε,1=+∞} + u0 1{τ =+∞,ρε,1 =+∞} ,
 ε,1



βε =
η 1{ρε,1 =t} + u0 1{τ =+∞} 1t + β ε,2 1 − 1{τ =+∞,ρε,1 =+∞} + v0 1{τ =+∞,ρε,1 =+∞} .

It is easy to check that uε ∈ Ut,T and β ε ∈ Bt,T . Hence, from (41), (42) and Theorem 3.1, we

17

have
t,x;u,β(u)

sup

inf

Gt,t

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

h

− c (t, ξ) 1{τ =t} 1{ρ=+∞}




t,x;ξ1[τ,T ] ,η1[ρ,T ]
1 − 1{τ =+∞,ρ=+∞}
+χ (t, η) 1{ρ=t} + V − t, Xt
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Φ XT
1{τ =+∞,ρ=+∞}
t
h
t,x;u,β(u)
− c (t, ξ) 1{τ =t} 1{ρε,1 =+∞}
≥ Gt,t


t,x;ξ1[τ,T ] ,ηε,1 1[ρε,1 ,T ]


ε,1
ε,2
1 − 1{τ =+∞,ρε,1=+∞}
+χ t, η
1{ρε,1 =t} + J t, Xt
, ǔ, β (ǔ)
Z T


i

f s, Xst,x;u0 ,v0 , Yst,x;u0 ,v0 , Zst,x;u0 ,v0 ds + Φ XTt,x;u0 ,v0
+
1{τ =+∞,ρε,1 =+∞} − 2ε
t

= J (t, x; uε , β ε (uε )) − 2ε.
Leting ε → 0, we get
V − (t, x) ≤

inf

sup

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

t,x;u,β(u)

Gt,t

h

− c (t, ξ) 1{τ =t} 1{ρ=+∞}




t,x;ξ1[τ,T ] ,η1[ρ,T ]
1 − 1{τ =+∞,ρ=+∞}
+χ (t, η) 1{ρ=t} + V − t, Xt
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Φ XT
1{τ =+∞,ρ=+∞} .
t

The reverse part can be obtained in the same way. We complete the proof.

4



HJBI equation: Viscosity approach

In the stochastic optimal control theory, the value function is a solution to the corresponding
Hamilton-Jacobi-Bellman equation (H-J-B in short) whenever it has sufficient regularity (Fleming and Soner [27], Krylov [35]). In other word, it requires that the HJB equation admit classical
solutions, meaning that the solutions be smooth enough (to the order of derivatives involved in
the equation). Unfortunately, this is not necessarily the case even for some very simple situations. In the stochastic environment where the diffusion is possibly degenerate, the HJB equation
may in general have no classical solutions either. To overcome this difficulty, Crandall and Lions
introduced the so-called viscosity solutions in the early 1980s (see also [16]). This new notion
is a kind of nonsmooth solutions (the value function is continuous, then, the value function is a
solution to the H-J-B equation in the viscosity sense) to partial differential equations, whose key
feature is to replace the conventional derivatives by the (set-valued) super-/subdifferentials while
maintaining the uniqueness of solutions under very mild conditions. These make the theory a
powerful tool in tackling optimal control problems.
In this section, we consider the following HJBI equation associated to our stochastic differential games, in which lead to be the same expression for the two value functions since the two
players can not operate at the same time in the systems, is described by



 ∂
χ
c V
= 0,
V (t, x) − H t, x, V, DV, D 2 V , V − Hinf
max V − Hsup
V, min − ∂t
(43)
n
V (T, x) = Φ (x) , (t, x) ∈ [0, T ) × R ,
where associated with the Hamiltonians:



1 
H (t, x, y, p, Q) = hb (t, x) , pi + tr σσ ⊤ (t, x) Q + f t, x, y, p⊤ σ (t, x)
2
18

(44)

χ
c V are defined by
and the nonlocal operators Hsup
V and Hinf
χ
Hsup
V (t, x) = sup [V (t, x + y) − c (t, y)] ,
y∈U

c
V
Hinf

(t, x) =

inf [V (t, x + z) + χ (t, z)] ,

z∈V

for any (t, x) ∈ [0, T ) × Rn , y ∈ R, p ∈ Rn , Q ∈ Sn where Sn denotes the set of n × n symmetric
matrices. The coefficients b, σ, f , Φ, χ and c are supposed to satisfy (A1)-(A3).
We next prove that the lower value function V (t, x) introduced by (43) is the viscosity
solution of (43). We extend Cosso’s work [17] for stochastic differential games involving impulse
controls into Peng’s BSDE’s framework. The difficulties related with this extension come from
the fact that now, contrarily to the framework of stochastic control theory studied by Peng, we
have to do with stochastic differential games in which strategies are played versus controls. In
order to overcome these difficulties in the proof that V − is a viscosity supersolution, we have, in
particular, to enrich Peng’s BSDE method. On the other hand, the proof that V − is a viscosity
subsolution is not covered by Peng’s BSDE method and requires a quite new approach. The
uniqueness of the viscosity solution will be shown in the next section for the class of bounded
continuous functions. We first recall the definition of a viscosity solution of (43). The interested
reader is referred to Crandall, Ishii, and Lions [16].
Definition 4.1 Let u (t, x) ∈ C ([0, T ] × Rn ) and (t, x) ∈ [0, T ]×Rn . For every ϕ ∈ C 1,2 ([0, T ] × Rn )
(1) for each local maximum point (t0 , x0 ) of u − ϕ in the interior of [0, T ] × Rn , we have




∂
χ
c
V
≤0
(45)
max V − Hinf
V, min − ϕ − H t, x, ϕ, Dϕ, D 2 ϕ , V − Hsup
∂t
and for each x ∈ Rn , we have

χ
c
max V (T, x) − Hinf
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf
V (T, x)] ≤ 0

i.e., u is a subsolution to HJBI equation (43).
(2) for each local minimum point (t0 , x0 ) of u − ϕ in the interior of [0, T ] × Rn , we have




∂
χ
2
c
≥0
max V − Hinf V, min − ϕ − H t, x, ϕ, Dϕ, D ϕ , V − Hsup V
∂t

and for each x ∈ Rn , we have

χ
c
max V (T, x) − Hinf
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf
V (T, x)] ≥ 0

(46)

(47)

(48)

i.e., u is a supersolution to HJBI equation (43).
(3) u (t, x) ∈ C ([0, T ] × Rn ) is said to be a viscosity solution of (43) if it is both a viscosity sub
and supersolution.
We have the other definition which will be useful to verify the viscosity solutions.
Definition 4.2 Let u (t, x) ∈ C ([0, T ] × Rn ) and (t, x) ∈ [0, T ]×Rn . We denote by P 2,+ u (t, x),
the “parabolic superjet” of u at (t, x) the set of triples (p, q, X) ∈ R × Rn × Sn which are such
that
u (s, y) ≤ u (t, x) + p (s − t) + hq, x − yi


1
+ hX (y − x) , y − xi + o |s − t| + |y − x|2 .
2
19

Similarly, we denote by P 2,− u (t, x) , the ”parabolic subjet” of u at (t, x) the set of triples
(p, q, X) ∈ R × Rn × Sn which are such that
u (s, y) ≥ u (t, x) + p (s − t) + hq, x − yi


1
+ hX (y − x) , y − xi + o |s − t| + |y − x|2 .
2

Definition 4.3 (i) It can be said V (t, x) ∈ C ([0, T ] × Rn ) is a viscosity subsolution of (43) if
at any point (t, x) ∈ [0, T ] × Rn , for any (p, q, X) ∈ P 2,+ V (t, x),



χ
c
max V − Hinf
V, min −p − H (t, x, V (t, x) , q, X) , V − Hsup
V ≤0
(49)
and for each x ∈ Rn , it holds

χ
c
V (T, x)] ≤ 0.
max V (T, x) − Hinf
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf

(50)

and for each x ∈ Rn , we have

χ
c
V (T, x)] ≥ 0.
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf
max V (T, x) − Hinf

(52)

(ii) It can be said V (t, x) ∈ C ([0, T ] × Rn ) is a viscosity supersolution of (43) if at any point
(t, x) ∈ [0, T ] × Rn , for any (p, q, X) ∈ P 2,+ V (t, x),



χ
c
max V − Hinf
V, min −p − H (t, x, V (t, x) , q, X) , V − Hsup
V ≥0
(51)

(iii) It can be said u (t, x) ∈ C ([0, T ] × Rn ) is a viscosity solution of (43) if it is both a viscosity
sub and super solution.
Remark 4.1 Definition 4.1 and 4.3 are equivalent to each other. For more details, see Fleming
and Soner [28], Lemma 4.1 (page 211).
We now introduce the lower and upper obstacles with the help of the following lemms.
Lemma 4.1 Assume (A1)-(A3) are in force. Given any (t, x) ∈ (0, T ] × Rn , the lower and
upper value functions satisfy the following equation:



χ
c
max min 0, V (t, x) − Hsup
V (t, x) , V (t, x) − Hinf
V (t, x) = 0.
Proof

From Lemma 3.1, (40) can be expressed as
V − (t, x) =

inf

sup

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

h
E − c (t, ξ) 1{τ =t} 1{ρ=+∞}

i

t,x;ξ1[τ,T ] ,η1[ρ,T ]
.
+χ (t, η) 1{ρ=t} + V − t, Xt

The remainder of the proof is the same as Lemma 5.3 from [17]. We omit it.



χ
Remark 4.2 We have V − (t, x) ≤ Hinf
V (t, x) on (0, T ] × Rn from Lemma 4.1. Besides, whenχ
c V (t, x) ≤ V − (t, x) and Hc V (t, x) ≤ Hχ V (t, x). So
ever V (t, x) ≤ Hinf V (t, x), then Hsup
sup
inf
c V (t, x) as a lower obstacle and Hχ V (t, x) as an upper obstacle. Both of
we may regard Hsup
inf
them are implicit forms, since they depend on V − . The same remark applies to V + likewise.

We shall prove that the two value functions satisfy, in the viscosity sense, the terminal
condition.
Lemma 4.2 Assume assumptions (A1)-(A3) are in force. The lower value function V − (T, x)
is a viscosity solution of (43).
20

Proof

We shall prove

χ
c
max V (T, x) − Hinf
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf
V (T, x)] ≥ 0.

From Lemma 3.4, we have
V − (t, x) =

sup

inf

E

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

h

− c (t, ξ) 1{τ =t} 1{ρ=+∞}




t,x;ξ1[τ,T ] ,η1[ρ,T ]
1 − 1{τ =+∞,ρ=+∞}
+χ (t, η) 1{ρ=t} + V − t, Xt
Z T


i

t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
ds + Φ XT
+
1{τ =+∞,ρ=+∞} .
t

Thanks to (A1)-(A2), it follows that
Z T


f s, Xst,x;u0 ,v0 , Yst,x;u0 ,v0 , Zst,x;u0 ,v0 ds
E
t

1
2

≤ (T − t) E

Z

t

1

T

f

s, Xst,x;u0 ,v0 , Yst,x;u0,v0 , Zst,x;u0 ,v0

≤ C (T − t) 2 ,



2

ds

 21

and
1

i


2 2
t,x;u0 ,v0
t,x;u0 ,v0
−x
≤ CE XT
E Φ XT
− Φ (x)
h

1

≤ C (T − t) 2 , uniformly in u0 , v0 .

Therefore,
V − (t, x) ≥ −

inf

sup

E

ρ∈Tt,+∞ η∈Fρ τ ∈Tt,+∞ ,ξ∈Fτ

h

− c (t, ξ) 1{τ =t} 1{ρ=+∞}




t,x;ξ1[τ,T ] ,η1[ρ,T ]
1 − 1{τ =+∞,ρ=+∞}
+χ (t, η) 1{ρ=t} + V − t, Xt
i
1
+Φ (x) 1{τ =+∞,ρ=+∞} − C (T − t) 2 .

Repeating the method in Lemma 4.1, we have



χ
c
max min V − (t, x) − Φ (x) , V − (t, x) − Hsup
V − (t, x) , V − (t, x) − Hinf
V − (t, x)
1

≥ −C (T − t) 2 .

According to (A3), namely the 1/2-Hölder continuity in time for c, χ and V − , we deduce that

χ
c
max V (T, x) − Hinf
V (T, x) , min [V (T, x) − Φ (x) , V (T, x) − Hinf
V (T, x)]
1

+C (T − t) 2



χ
c
≥ max min V − (t, x) − Φ (x) , V − (t, x) − Hsup
V − (t, x) , V − (t, x) − Hinf
V − (t, x)
1

≥ −C1 (T − t) 2 .

for some C1 > 0. Then, letting t = T in (53) ends the proof.
We first prove that the lower value function V − (t, x) is a viscosity solution of (43).

(53)


Theorem 4.1 Assume assumptions (A1)-(A3) are in force, the lower value function V − (t, x)
is a viscosity solution of (43).
21

Proof We first show that the lower value function V − is a viscosity solution to (43); the other
case is analogous.
In Lemma 4.2, we have proved that V − satisfies, in the viscosity sense, the terminal condition,
namely (50) and (50). Therefore, we have only to address (49). From Proposition 3.2, V − is
continuous on [0, T ) × Rn . Thus we begin by proving that V − is a viscosity supersolution. By
c V (t̄, x̄) ≤
virtue of Lemma 4.1, we have to show that, given (t̄, x̄) ∈ [0, T ) × Rn such that Hsup
χ
−
−
1,2
n
V (t̄, x̄) and V (t̄, x̄) ≤ Hinf V (t̄, x̄) , then for every ϕ ∈ C ([0, T ) × R ), such that (t̄, x̄) is a
local minimum of V − − ϕ, we have

∂
ϕ (t̄, x̄) + H t, x, ϕ (t̄, x̄) , Dϕ (t̄, x̄) , D 2 ϕ (t̄, x̄) ≤ 0,
∂t

where H is defiend in (44).
Without loss of generality, postulate V − (t̄, x̄) = ϕ (t̄, x̄) . Let


χ
λ + V − (t̄, x̄) = Hinf
V (t̄, x̄) = inf V − (t̄, x̄ + y) + χ (t̄, y) .
y∈V

(54)

(55)

We proceed as in [17] to derive the following result: For every random variable η, Fs -measurable
and values in V, there exists C > 0,

i
h 
i
h 
1
EFs V s, Xst̄,x̄ ≤ EFs V s, Xst̄,x̄ + η + χ (s, η) + C |s − t̄| 2 − λ

with Xst̄,x̄ = Xst̄,x̄,u0 ,v0 for all s ∈ [t̄, T ], P -a.s., where u0 and v0 denote the controls with no
impulses.
Next recall
i


h
u,β(u)
t̄,x̄;u,β(u)
t̄,x̄;u,β(u)
,
+ Θt̄+δ
V − t̄ + δ, Xt̄+δ
V − (t̄, x̄) = inf sup Gt̄,t̄+δ
β∈Bt̄,T u∈Ut̄,T

where

:=
Θu,v
t̄+δ

X

χ (ρl , ηl ) 1{ρl ≤t̄+δ} −

X

c (τm , ξm ) 1{τm ≤t̄+δ}

m≥1

l≥1

Y

1{τm 6=ρl } .

l≥1

From the definition of V − (t̄, x̄) , we have
V − (t̄, x̄) =

t̄,x̄;u,β(u)

sup Gt̄,t̄+δ

inf

β∈Bt̄,T u∈Ut̄,T



i


h
u,β(u)
t̄,x̄;u,β(u)
+ Θt̄+δ
V − t̄ + δ, Xt̄+δ




X
t̄,x̄;u ,β ε (u0 )  −
t̄,x̄;u ,β ε (u0 )
≥ Gt̄,t̄+δ0
+
t̄ + δ, Xt̄+δ 0
V
χ (ρl , ηl ) 1{ρl ≤t̄+δ}  − ε
l≥1

for some β ε ∈ Bt̄,T , with v ε := β ε (u0 ) =
X

P

ε
l≥1 ηl 1[ρεl ,T ]

∈ Vt̄,T . Note that

µ[t̄,t̄+δ]

χ (ρl , ηl ) 1{ρl ≤t̄+δ} =

l≥1

X

χ (ρl , ηl ) .

l≥1

By (A1)-(A2), we have the following estimate



µ[t̄,t̄+δ]


X
ε
t̄,x̄;u0 ,v
EFt̄+δ  V − t̄ + δ, Xt̄+δ
χ (ρl , ηl ) 
− V − t̄ + δ, Xst̄,x̄ +
l≥1

1
2

h

i

≤ Cδ EFt̄+δ 1{µ[t̄,t̄+δ] ≥1} .

22

As a consequence, using (A3) and (54), we deduce




µ[t̄,t̄+δ]
µ[t̄,t̄+δ]
X
X
t̄,x̄
χ (ρl , ηl )
χ (ρl , ηl ) +
EFt̄+δ V − t̄ + δ, Xt̄+δ
+
l≥1

l≥1

≥ EFt̄+δ

h

 


i
1
t̄,x̄
+ λ − Cδ 2 1{µ[t̄,t̄+δ] ≥1} .
V − t̄ + δ, Xt̄+δ

Therefore, applying comparison theorem (Proposition 2.6 in [8]), we find




X
ε
t̄,x̄;u0 ,vε
0 ,v  −
Gt̄,x̄;u
+
χ (ρl , ηl ) 1{ρl ≤t̄+δ} 
V
t̄ + δ, Xt̄+δ
t̄,t̄+δ
l≥1

0
≥ Gt̄,x̄;u
t̄,t̄+δ

Thus

,vε

h

0 ,v
V − (t̄, x̄) ≥ Gt̄,x̄;u
t̄,t̄+δ

 


1
t̄,x̄
+ λ − Cδ 2 1{µ t̄,
V − t̄ + δ, Xt̄+δ

ε

} .

[ t̄+δ] ≥1

h

i


 

1
t̄,x̄
+ λ − Cδ 2 1{µ
V − t̄ + δ, Xt̄+δ

i

} − ε.

[t̄,t̄+δ] ≥1

From the boundedness of f we deduce


ε
f s, Xst̄,x̄;u0 ,v , y, z






ε
= f s, Xst̄,x̄;u0 ,v , y, z − f s, Xst̄,x̄ , y, z + f s, Xst̄,x̄ , y, z


≥ f s, Xst̄,x̄ , y, z − C, for (y, z) ∈ R × Rd .

Applying comparison theorem (Proposition 2.6 in [8]) again, we have V − (t̄, x̄) ≥ Yt̄ , where Yt̄
is the solution to the following BSDE:
 


1
t̄,x̄
+ λ − Cδ 2 − Cδ 1{µ
Yt̄ = V − t̄ + δ, Xt̄+δ
[t̄,t̄+δ] ≥1}
Z t̄+δ
Z t̄+δ 

Zs dWs .
f s, Xst̄,x̄ , Ys , Zs ds −
+
t̄

t̄


We shall take δ sufficiently small. Indeed, there exists δ̄ > 0 such that for ζ ∈ 0, δ̄ , we have
1
λ − Cδ 2 − Cδ ≥ 0. Immediately, by Proposition 2.6 in [8], it follows
i

h
t̄,x̄
−
− ε.
(56)
V
t̄
+
ζ,
X
V − (t̄, x̄) ≥ Gt̄,x̄
t̄+ζ
t̄,t̄+ζ

To abbreviate notations we set, for some arbitrarily chosen but fixed ϕ ∈ C 1,2 ([0, T ) × Rn ) ,

1 
∂
ϕ (s, x) + Tr σσ ⊤ (s, x) D 2 ϕ + hDϕ, b (s, x)i
F (s, x, y, z) =
∂s
2
+f (s, x, y + ϕ (s, x) , z + Dϕ (s, x) · σ (s, x)) ,
for (s, x, y, z) ∈ [0, T ] × Rn ×R × Rd .
Let us consider the following BSDE:


(
−dYs1 = F s, Xst̄,x̄ , Ys1 , Zs1 ds − Zs1 dWs ,

(57)
1
Yt̄+ζ
= 0.


It is not hard to check that F s, Xst̄,x̄ , y, z satisfies (A1) and (A2). Thus, BSDE (57) admits

a unique adapted strong solution. We can characterize the solution process Ys1 as follows.

h 
i

t̄,x̄
t̄,x̄
.
(58)
ϕ
−
ϕ
s,
X
Ys1 = Gt̄,x̄
t̄
+
ζ,
X
s
s,t̄+ζ
t̄+ζ
23

i
h 
t̄,x̄
is defined by the solution of the following BSDE:
ϕ
Indeed, Gt̄,x̄
t̄
+
ζ,
X
t̄+ζ
s,t̄+ζ



 −dȲs = f s, Xst̄,x̄ , Ȳs , Z̄s ds − Z̄s dWs ,


 Ȳt̄+ζ = ϕ t̄ + ζ, X t̄,x̄ .
t̄+ζ

(59)





Therefore, one just need to prove Ȳs − ϕ s, Xst̄,x̄ = Ys1 . Applying Itô’s formula to ϕ s, Xst̄,x̄ ,


i
h

t̄,x̄
1 =
= Yt̄+ζ
we obtain d Ȳs − ϕ s, Xst̄,x̄ = dYs1 , and at the terminal time Ȳt̄+ζ − ϕ t̄ + ζ, Xt̄+ζ
0, as a result, they are equal in the interval [t̄, t̄ + ζ].
Now let us introduce a more simpler BSDE than (57), i.e., Xst̄,x̄ of the equation (57) is taken
place by x:


−dYs2 = F s, x̄, Ys2 , Zs2 ds − Zs2 dWs ,
(60)
2
= 0.
Yt̄+ζ

Notice that F is a deterministic function of (s, x, y, z) therefore Ys2 , Zs2 = (Y0 (s) , 0) where
Y0 (s) is the solution of the ODE:

−Ẏ0 (s) = F (s, x̄, Y0 (s) , 0) ds, s ∈ [t̄, t̄ + ζ] ,
(61)
Y0 (t̄ + ζ) = 0.
The following result indicates that the difference of the solutions of (57) and (60) can be neglected whenever ζ is sufficiently small enough. From the classical estimate on SDE,
 we have

h
pi
2
t̄,x̄
t̄,x̄
p
E sups∈[t̄,t̄+ζ] Xs
≤ C (1 + |x̄| ) . Moreover, applying B-D-G inequality, we get E sups∈[t̄,t̄+ζ] Xs − x̄
≤

Cζ. Hence, when ζ → 0, the following random variable κζ := sups∈[t̄,t̄+ζ] Xst̄,x̄ − x̄ converges
monotone to 0. On the one hand, employing Proposition 3.2 in [7] to BSDEs (57) and(60), we
have
#
"Z
#
"Z
2
 2

t̄+ζ
t̄+ζ
t̄,x̄
1
2 2
1 2
ds ≤ CζE̟ κζ .
E
Ys − Ys + Zs
ds ≤ CE
̟ Xs − x
t̄

t̄

On the other hand, from Lemma 3.1, we have
Yt̄1 − Yt̄2

=
=

E Yt̄1
#
"Z
i

t̄+ζ h 

F s, Xst̄,x̄ , Ys1 , Zs1 − F s, x̄, Ys2 ds
E
t̄

≤ CE

"Z

t̄

t̄+ζ



 
̟ Xst̄,x̄ − x + Ys1 − Ys2 + Zs1 ds

 2
1
≤ CζE̟ κζ + Cζ 2

( "Z
E

t̄

  
 
2
ζ
≤ CζE ̟ κ
+ ̟ κζ ,

t̄+ζ



Ys1

−

2
Ys2

+

#

2
Zs1



#) 1

2

ds

(62)


with ̟ (ǫ) → 0 as ǫ → 0. Note that, for each ζ > 0, ̟ κζ is square integrable, we set
  
 
2
ζ
+ ̟ κζ .
̟0 (ζ) = E ̟ κ

Hence,

Yt̄1 − Yt̄2 ≤ Cζ̟0 (ζ)
24

(63)

From the monotonicity of G [·] ,

i
h
t̄,x̄
−
− ε.
V
t̄
+
ζ,
X
ϕ (t̄, x̄) = V − (t̄, x̄) ≥ Gt̄,x̄
t̄+ζ
t̄,t̄+ζ
i
h 
t̄,x̄
− ε.
≥ Gt̄,x̄
t̄,t̄+ζ ϕ t̄ + ζ, Xt̄+ζ

From (58) and letting ε → 0,

i
h 
t̄,x̄
− ϕ (t̄, x̄) = Yt̄1 .
ϕ
t̄
+
ζ,
X
0 ≥ Gt̄,x̄
t̄+ζ
t̄,t̄+ζ

By (63) we further have Y0 (t̄) = Yt̄2 ≤ Cζ̟0 (ζ) . Therefore, it follows easily that F (t̄, x̄, 0, 0) ≤ 0
and from the definition of F we see that V − is a viscosity supersolution of (43). The proof is
similar for the viscosity sub-solution.

Next, we shall prove that the HJBI equation (43) has a unique viscosity solution. Consequently, the lower and upper value functions coincide, since they are both viscosity solutions to
(43). Thus, the stochastic differential game admits a value.
Before introducing the comparison principle, we need the following two technical lemmas,
mainly taken from [17].
Lemma 4.3 Assume that (A3) is in force. Let U , V : [0, T ] × Rn → R a viscosity
supersolution

and a viscosity subsolution to the HJBI equation (43), respectively. Let t̂, x0 ∈ [0, T ] × Rn be
such that




χ
c
U t̂, x0 ,
V t̂, x0 , U t̂, x0 ≤ Hinf
V t̂, x0 ≤ Hsup

or



χ
U t̂, x0 .
U t̂, x0 ≥ Hinf

Then for every ε > 0, there exists x̂ ∈ Rn such that




V t̂, x0 − U t̂, x0 ≤ V t̂, x̂ − U t̂, x̂ + ε
and





χ
c
U t̂, x̂ .
V t̂, x̂ , U t̂, x̂ < Hinf
V t̂, x̂ > Hsup

Lemma 4.4 Assume that (A3) is in force. Let U , V : [0, T ] × Rn → R a viscosity
supersolution

and a viscosity subsolution to the HJBI equation (43), respectively. Let t̂, x̂ ∈ [0, T ] × Rn be
such that




χ
c
U t̂, x̂ ,
V t̂, x̂ , U t̂, x̂ < Hinf
V t̂, x̂ > Hsup
then there exists ǫ > 0 for which

χ
c
V (t, x) > Hsup
V (t, x) , U (t, x) < Hinf
U (t, x) ,

where (t, x) ∈






t̂ − δ ∨ 0, t̂ + δ ∧ T × B̄δ (x̂) .

In order to get the uniqueness, we add the following assumption:
(A4) Assume that f is strictly monotone in y, that is, f (t, x, y1 , z) < f (t, x, y2 , z) , for ∀y1 ,
y2 ∈ R with y1 < y2 , ∀ (t, x, z) ∈ [0, T ] × Rn × Rd .
Theorem 4.2 Let U , V : [0, T ] × Rn → R a viscosity supersolution and a viscosity subsolution
to the HJBI equation (43), respectively. Assume that (A1)-(A4) are in force and that U , V are
uniformly continuous on [0, T ) × Rn . Then, we have U ≥ V on [0, T ] × Rn .
25

Proof

We prove our result by contradiction. Suppose that
sup (V − U ) > 0.
[0,T ]×Rn

Fix θ > Cf > 0 where Cf denotes the Lipschitz constant of f.
Define
Ū (t, x) = eθt U (t, x) , V̄ (t, x) = eθt V (t, x) , (t, x) ∈ [0, T ] × Rn .
It is fairly easy to check that Ū (t, x) (V̄ (t, x)) is a viscosity supersolusion (subsolution) to the
following HJBI equation:



χ
c
¯
max W − H̄sup
W, min θW − ∂W
= 0,
∂t − LW − f , W − H̄inf W
(64)
n
W (T, x) = Φ̄ (x) , (t, x) ∈ [0, T ) × R ,
where
i
1 h
LW (t, x) = hb (t, x) , DW (t, x)i + tr σσ ⊤ (t, x) D 2 W (t, x) ,
2


θt
−θt
−θt
¯
f (t, x, W, DW · σ (t, x)) = e f t, x, e W, e DW · σ (t, x) ,

(65)

Φ̄ (x) = eθT Φ (x) ,
h
i
χ
H̄sup
W (t, x) = sup W (t, x + z) + eθt χ (t, z) ,
z∈V
h
i
c
H̄inf W (t, x) = inf W (t, x + y) − eθt c (t, z) .
y∈U


Assume that there exists x0 ∈ Rn such
that Ū − V̄ (T, x0 ) < 0. Then, from Lemma 4.3,

There exists x̃ ∈ Rn such that Ū − V̄ (T, x̃) < 0. On the other hand, from the subsolution
property of V̄ , we know V̄ (T, x̃) ≤ Φ̄ (x̃). Similarly, uitilizing the supersolution property of
Ū , we have Ū (T, x̃) ≥ Φ̄ (x̃). Therefore, Ū (T, x̃) ≥ V̄ (T, x̃) which leads a contradition to
Ū − V̄ (T, x̃) < 0.

Now postulate that there exists (t̄, x̄) ∈ [0, T ] × Rn such that Ū − V̄ (t̄, x̄) < 0. Then, from
Lemma 4.4, there exist t̂, x̂ ∈ [0, T ] × Rn and δ > 0 such that

sup V̄ − Ū (t, x) > 0
I×B̄δ (x̂)

and

χ
c
Ū (t, x) , (t, x) ∈ I × B̄δ (x̂)
V̄ (t, x) > H̄sup
V (t, x) , Ū (t, x) < H̄inf




with I := t̂ − δ ∨ 0, t̂ + δ ∧ T .
We define
M
16 |x − x̂|4 M
,
1{|x−x̂|> δ } +
Ṽ (t, x) = V̄ (t, x) −
2
15δ4
15

where M := supI×B̄δ (x̂) V̄ − Ū (t, x) . It is easy to check that


16 |x − x̂|4 m
m
1{|x−x̂|> δ } −
V̄ − Ū (t, x) −
4
2
15δ
15
≤ M.



Ṽ − Ū (t, x) =

So withoutloss of generality, we may assume that


Ṽ − Ū (t, x) ≤ 0, (t, x) ∈ I × ∂ B̄δ (x̂) .
26

Note that P 2,+ V̄ (t, x) = P 2,+ Ṽ (t, x) for all (t, x) ∈ [0, T ] × Rn , Ṽ can be replaced with V̄ .
Now choose (t′ , x′ ) ∈ I × B̄δ (x̂) such that



sup V̄ − Ū (t, x) = V̄ − Ū t′ , x′ > 0.
(66)
I×B̄δ (x̂)

Define the following text function:
φn (t, x, y) = V̄ (t, x) − Ū (t, y) − ψn (t, x, y) , n ∈ N
with

n
2
2
|x − y|2 + x − x′ + t − t′
2
for every (t, x, y) ∈ [0, T ] × Rn × Rn . Clearly, given any n ≥ 1, there exists (tn , xn , yn ) ∈
I × B̄δ (x̂) × B̄δ (x̂) attaining the maximum of φn on I × B̄δ (x̂) × B̄δ (x̂). Up to a subsequence,
(tn , xn , yn ) ∈ I × B̄δ (x̂) × B̄δ (x̂) → (t0 , x0 , y0 ) ∈ I × B̄δ (x̂) × B̄δ (x̂) as n → ∞. Nonetheless, for
every n ≥ 1, we have



V̄ − Ū t′ , x′ = φn t′ , x′ , x′ ≥ φn (tn , xn , yn ) .
ψn (t, x, y) =

It yields that

V̄ − Ū



t ′ , x′



≤ sup limφn (tn , xn , yn )
n→∞

≤ V̄ (t0 , x0 ) − Ū (t0 , y0 ) − inf limn |xn − yn |2
n→∞

− x0 − x

′ 2

− t0 − t

′ 2

,

(67)

from which, up to a subsequence, inf limn |xn − yn |2 < ∞. Then it follows that x0 = y0 . From
n→∞

(67), we derive that

 1) (tn , xn , yn ) → (t′ , x′ , x′ ) ,
2) n |xn − yn |2 → 0

3) V̄ (tn , xn ) − Ū (tn , yn ) → V̄ (t′ , x′ ) − Ū (t′ , x′ ) ,

(68)

as n → ∞. By virtue of Ishii’s lemma (Theorem 8.3 in [16]), up to a subsequence, we may find
sequence p1n , qn1 , Q1n ∈ P 2,+ V̄ (tn , xn ) and p2n , qn2 , Q2n ∈ P 2,− Ū (tn , yn ) such that

p1n − p2n = 2 tn − t′ ,
qn1 = Dx ψn (tn , xn , yn ) = n (xn − yn ) ,

qn2 = −Dy ψn (tn , xn , yn ) = n (xn − yn )

and



Q1n
O
O −Q2n



≤ An +

where
An = Dxy ψn (tn , xn , yn ) = n
Then,


O
Q1n
O −Q2n



≤ 2n

27





1 2
A
2n n
I −I
−I I

I −I
−I I



.



.

(69)

From Ū (t, x) (V̄ (t, x)) is a viscosity supersolusion (subsolution) to the following HJBI equation
(64), we have


≥ 0,
(70)
θ Ū (tn , yn ) − p2n − LŪ (tn , yn ) − f¯ tn , yn , e−θtn Ū , e−θtn D Ū · σ (tn , yn )


θ V̄ (tn , xn ) − p1n − LV̄ (tn , xn ) − f¯ tn , xn , e−θtn V̄ , e−θtn D V̄ · σ (t, xn )
≤ 0,
(71)
where L is defined in (65). From (70) and (71), we immediately get

θ V̄ (tn , xn ) − θ Ū (tn , xn ) + p2n − p1n + LŪ (tn , xn ) − LV̄ (tn , yn )


+f¯ tn , yn , e−θtn Ū (tn , yn ) , e−θtn qn2 · σ (tn , yn )


−f¯ tn , xn , e−θtn V̄ (tn , xn ) , e−θtn qn1 · σ (tn , xn )

≤ 0.

(72)

Clearly,
p1n − p2n → 0, as n → ∞.

(73)

hb (tn , yn ) , n (xn − yn )i − hb (tn , xn ) , n (xn − yn )i → 0,

(74)

and
since (1)-(2) in (68).
For simplicity, set σ1 = σ (tn , yn ) , σ2 = σ (tn , xn ) . We deal with

=
≤
≤
=

 1

1
Tr σσ ∗ (tn , yn ) Q1n − Tr σσ ∗ (tn , xn ) Q2n
2 
 2 1

1
σ1 σ1⊤ σ1 σ2⊤
0
Qn
Tr
σ2 σ1⊤ σ2 σ2⊤
0 −Q2n
2




σ1 σ1⊤ σ1 σ2⊤
I −I
nTr
σ2 σ1⊤ σ2 σ2⊤
−I I
i
h
nTr σ1 σ1⊤ − σ1 σ2⊤ − σ2 σ1⊤ + σ2 σ2⊤
i
h
nTr (σ1 − σ2 ) (σ1 − σ2 )⊤

≤ nC |σ1 − σ2 |2

≤ nC |xn − yn |2 → 0, as n → ∞,

(75)

where we have used the the assumption that Lipschitz condition on σ, (69)
(2) in (68). 
 and
′
Thanks to (3) in (68), the left-hand side of inequality (72) goes to θ V̄ (t , x′ ) − Ū (t′ , x′ ) ,
as n → ∞, moreover, by (A4), we have





 
 
′
′
θ V̄ t′ , x′ − Ū t′ , x′
≤ f¯ t′ , x′ , e−θt Ū t′ , x′ , 0 − f¯ t′ , x′ , e−θt V̄ t′ , x′ , 0
< 0

which leads to a contradiction to (66). Our proof is thus completed.



Remark 4.3 To get a uniqueness result for viscosity solution of (43), we adapt some techniques
from [17]. We have to mention that there is another approach developed by Barles, Buckdahn
and Pardoux [8]. The value function can be considered in given class of continuous functions
satisfying
o
n
lim |u (t, x)| exp −A [log (|x|)]2 = 0,
|x|→∞

28

uniformly for t ∈ [0, T ] , for some A > 0. The space of continuous functions endowed with a
growth condition is slightly weaker than the assumption of polynomial growth but more restrictive
than that of exponential growth. This growth condition was first introduced by Barles, Buckdahn,
and Pardoux [8] to prove the uniqueness of the viscosity solution of an integro-partial differential
equation associated with a decoupled FBSDEs with jumps. It has been shown in [8] that this kind
of growth condition is optimal for the uniqueness and can, in general, not be weakened. These
techniques have been applied in [5, 56] for the uniqueness for viscosity solutions of recursive
control of the obstacle constraint problem and Hamilton-Jacobi-Bellman-Isaacs equations related
to stochastic differential games, respectively. However, as you may have observed, in our HJBI
equation, there appears two obstacles, which are implicit obstacles, in the sense that they depend
on V − . It is worth to pointing out that the smooth supersolution built in [8], namely



χ (t, x) = exp Č (T − t) + A ψ (x) ,
whilst

2
 
1
2
2
ψ (x) = log |x| + 1 + 1 ,

where Č and A are positive constants. One can show

min {L (t, x, v) χ (t, x) + C |χ| + C |∇χσ (t, x, v)|} ≤ 0,
v∈U

where C is the Lipschitz constant of f. Following the idea in [8], whenever considering the
difference of u1 − u2 where u1 (u2 ) is a subsolution (supersolution) of (43). It is hard to check
the obstacles of viscosity solution (45)-(48). This is the reason we borrow the idea from Fleming,
Soner [28] and Cosso [17] to handle the uniqueness.
Remark 4.4 As observed in our paper, we put somewhat strong assumptions on coefficients,
namely, boundedness. On the one hand, it simplifies our proof of existence. Recently, El Asri
and Mazid [26] also investigate the solution to the zero-sum stochastic differential games, but
under rather weak assumptions on the cost functions (c and χ are not decreasing in time). In
the future, we shall adopt the idea developed by El Asri and Mazid [26] to exploit the recursive
utilities.

5

Concluding remarks

In this paper, we study on zero-sum stochastic differential games in the framework of backward
stochastic differential equations on a finite time horizon with both players adopting impulse
controls. By means of stochastic backward semigroups and comparison theorem of BSDE, we
prove a dynamic programming principle for both the upper and the lower value functions of
the game. The upper and the lower value functions are then shown to be the unique viscosity
solutions of the Hamilton-Jacobi-Bellman-Isaacs equations with a double-obstacle. As a result,
the uniqueness implies that the upper and lower value functions coincide and the game admits a
value. In future work, we plan to relax our assumptions and to try to find a smooth solution for
the HJBI (43) in order to obtain uniqueness as Remark 4.3. Besides, as in Zhang [62], we will
consider problems in which one player adopts impulse controls and the other adopts continuous
controls, finite/infinite horizons, etc. These possible extensions promise to be interesting research
directions. We shall response these challenging topics in our future work.

29

A

The Proof of Lemma 3.1

Proof. We adopt the idea from [12]. Let H denote the Cameron–Martin space of all absolutely
continuous elements h ∈ Ω whose derivative ḣ belongs to L2 [0, T ] , Rd . For any h ∈ H, we
define the mapping τh ω := ω + h, ω ∈ Ω. Clearly, τh : Ω → Ω is a bijection, and its law is given
by

Z T
Z
2
1 T
−1
ḣs ds P.
ḣs dWs −
P ◦ (τh ) = exp
2 0
0

Let (t, x) ∈ [0, T ] × Rn be arbitrarily fixed, and put Ht = {h ∈ H|h (·) = h (· ∧ t)}. Let u ∈ Ut,T ,
v ∈ Vt,T , and h ∈ Ht , we first show that J (t, x; u, v) (τh ) = J (t, x; u (τh ) , v (τh )), P -a.s. Indeed,
substitute the transformed control processes u (τh ) and v (τh ) for u and v into FBSDEs (1)-(3)
and take the Girsanov transformation to (1)-(3), finally compare the obtained equation with the
previous ones. Then from the uniqueness of the solution of (1)-(3), we conclude with
Xst,x;u,v (τh ) = Xst,x;u(τh ),v(τh ) ,
Yst,x;u,v (τh ) = Yst,x;u(τh ),v(τh ) ,
Zst,x;u,v (τh ) = Zst,x;u(τh ),v(τh )

for any s ∈ [t, T ], P -a.s., which indicates that J (t, x; u, v) (τh ) = J (t, x; u (τh ) , v (τh )) , P -a.s.
For β ∈ Bt,T , h ∈ Ht , let β h (u) := β (u (τ−h )) (τh ), u ∈ Ut,T . Then β h ∈ Bt,T , which makes Ut,T
into Vt,T . Moreover, it is easy to check that this mapping is nonanticipating and verify
)
(
sup J (t, x; u, β (u)) (τh ) = sup {J (t, x; u, β (u)) (τh )} , P -a.s.
u∈Ut,T

u∈Ut,T

Now let h ∈ Ht ,
V − (t, x) (τh ) =
=
=
=

inf

sup {J (t, x; u, β (u)) (τh )}

inf

sup

inf

sup

inf

sup {J (t, x; u, β (u))}

β∈Bt,T u∈Ut,T

β∈Bt,T u∈Ut,T
β∈Bt,T u∈Ut,T

n 
o
J t, x; u (τh ) , β h (u (τh ))
n 
o
J t, x; u, β h (u)

β∈Bt,T u∈Ut,T

= V − (t, x) , P -a.s.,
which holds even for all h ∈ H. Recall the definition of the filtration, the Ft -measurable random
variable V − (t, x) (ω), ω ∈ Ω, depends only on the restriction of ω to the time interval [0, t]. We
complete our proof with help of Lemma 3.4 in [12].

Acknowledgements. The author wishes to thank the AE and referees for their careful reading
and helpful comments that improved the first version of the paper. The author also thanks the
department of applied mathematics, The Hong Kong Polytechnic University, for its hospitality
during his visit in Jan. 2019.

References
[1] Aı̈d R, Basei M, Callegaro G, Campi L and Vargiolu T, Nonzero-Sum Stochastic Differential
Games with Impulse Controls: A Verification Theorem with Applications, Mathematics of
Operations Research, 2019, Vol. 45, No. 1: 1-29.
30

[2] Altarovici A, Reppen M and Soner H M, Optimal Consumption and Investment with Fixed
and Proportional Transaction Costs, SIAM J. Control Optim., 2017,55(3): 1673–1710.
[3] Azimzadeh P and Forsyth P A, Weakly Chained Matrices, Policy Iteration, and Impulse
Control, SIAM J. Numer. Anal., 2016, 54(3): 1341–1364.
[4] Azimzadeh P, Bayraktar E and Labahn G, Convergence of Implicit Schemes for HamiltonJacobi-Bellman Quasi-Variational Inequalities, SIAM J. Control Optim., 2018, 56(6): 3994–
4016.
[5] Bismut J M, “Théorie Probabiliste du Contrôle des Diffusions”, Memoirs of the American
Mathematical Society, 176, Providence, Rhode Island, 1973.
[6] Bensoussan A, Lions J L, Applications des Inéquations Variationnelles en Contrôle Stochastique, Dunod, Paris, 1978.
[7] Briand P, Delyon B and Hu Y, Pardoux E, Stoica L, Lp solutions of backward stochastic
differential equations. Stochastic Process. Appl., 2003, 108: 109–129.
[8] Barles G, Buckdahn R and Pardoux E, Backward stochastic differential equations and
integral-partial differential equations, Stochastics Stochastics Rep., 1997, Volume 60, Issue
1-2: 57-83.
[9] Buckdahn R, Cardaliaguet P and Rainer C, Nash equilibrium payoffs for nonzero-sum
stochastic differential games, SIAM J. Control Optim., 2004 43: 624–642.
[10] E. Bayraktar and H. V. Poor, Stochastic differential games in a non-Markovian setting,
SIAM J. Control Optim., 2005, 43: 1737–1756.
[11] Browne S, Stochastic differential portfolio games, J. Appl. Probab., 2000, 37: 126–147.
[12] Buckdahn R and Li J, Stochastic differential games and viscosity solutions of HamiltonJacobi-Bellman-Isaacs equations, SIAM J. Control Optim., 2008, 47: 444-475.
[13] Bruder B and Pham H, Impulse control problem on finite horizon with execution delay,
Stochastic Process. Appl., 2009, 119: 1436–1469.
[14] Cvitanić J and Karatzas I, Backward stochastic differential equations with reflection and
Dynkin games, Ann. Probab., 1996, 24: 2024–2056.
[15] Carmona R and Ludkovski M, Swing options, Encyclopedia of quantitative finance, R. Cont,
ed., Wiley, New York, 2009.
[16] Crandall M G, Ishii H and Lions P-L, User’s guide to viscosity solutions of second order
partial differential equations, Bull. Amer. Math. Soc., 1992 (N.S.) 27: 1–67.
[17] Cosso A, Stochastic differential games involving impulse controls and double-obstacle quasivariational inequalities, SIAM J. Control Optim., 2013, Vol. 51, No. 3: 2102–2131.
[18] Chen Z and Epstein L, Ambiguity, risk, and asset returns in continuous time. Econometrica,
2002 70: 1403–1443.
[19] Chen, L., Wu, Z, Stochastic Optimal Control Problem in Advertising Model with Delay. J
Syst Sci Complex 33, 968–987 (2020). https://doi.org/10.1007/s11424-020-8185-1
[20] Duffie D, Epstein L, Stochastic differential utility, Econometrica, 1992, 60: 353–394.

31

[21] Y. Dolinsky, Y. Iron, and Y. Kifer, Perfect and partial hedging for swing game options in
discrete time, Math. Finance, 2011, 21: 447–474.
[22] Elliott R J and Kalton N J, The existence of value in differential games, Memoirs of the
American Mathematical Society, No. 126, American Mathematical Society, Providence, RI,
1972.
[23] Evans L C and Souganidis P E, Differential games and representation formulas for solutions
of Hamilton-Jacobi-Isaacs equations, Indiana Univ. Math. J., 1984, 33: 773–797.
[24] Ekström E and Peskir G, Optimal stopping games for Markov processes, SIAM J. Control
Optim., 2008, 47(2): 684–702.
[25] Friedman A, Differential Games, Wiley, New York, 1971.
[26] El Asri B, Mazid S, Zero-Sum Stochastic Differential Game in Finite Horizon Involving
Impulse Controls, Appl Math Optim., 2020, 81: 1055-1087.
[27] W. Fleming and H. Soner, Controlled Markov Processes and Viscosity Solutions, SpringerVerlag, New York, 1993.
[28] Fleming W H and Souganidis P E, On the existence of value functions of two-player, zerosum stochastic differential games, Indiana Univ. Math. J., 1989, 38: 293–314.
[29] Hamadène S and Hassani M, BSDEs with two reflecting barriers: The general result, Probab.
Theory Related Fields, 2005, 132: 237–264.
[30] Hamadène S and Lepeltier J-P, Zero-sum stochastic differential games and backward equations, Systems Control Lett., 24 (1995): 259–263.
[31] Hamadène S, Lepeltier J-P, and Peng S G, BSDEs with continuous coefficients and stochastic differential games. in Backward Stochastic Differential Equations, N. El Karoui and L.
Mazliak eds., Pitman Res. Notes Math. Ser., 364, Longman, Harlow 1997, 115–128.
[32] Hamadéne S, Lepeltier J P, Reflected backward stochastic differential equations and mixed
game problem, Stochastic Process. Appl., 2000, 85: 177–188.
[33] Iron Y and Kifer Y, Hedging of swing game options in continuous time, Stochastics, 83
(2011): 365–404.
[34] Isaacs R, Differential Games. A Mathematical Theory with Applications to Warfare and
Pursuit, Control and Optimization, John Wiley & Sons, Inc., New York-London-Sydney,
1965.
[35] Krylov N, Controlled Diffusion Processes, Springer-Verlag, New York, 1980.
[36] Karatzas I and Sudderth W, The controller-and-stopper game for a linear diffusion, Ann.
Probab., 2001, 29: 1111–1127.
[37] Karatzas I and Shreve S E, Methods of Mathematical Finance, Springer-Verlag, New York,
1998.
[38] Kharroubi I, Ma J, Pham H and Zhang J, Backward SDEs with constrained jumps and
quasi-variational inequalities, Ann. Probab., 2010, 38:794–840.
[39] Korn R, Some applications of impulse control in mathematical finance, Math. Methods
Oper. Res., 1999 50: 493–518.
32

[40] Karatzas I and Zamfirescu M, Martingale approach to stochastic control with discretionary
stopping, Appl. Math. Optim., 2006, 53: 163–184.
[41] El Karoui N, Peng S and Quenez M C, Backward stochastic differential equations in finance,
Math. Finance, 1997, 7: 1–71.
[42] Lenhart S M, Viscosity solutions associated with impulse control problems for piecewisedeterministic processes, Internat. J. Math. Math. Sci., 1989, 12: 145–157.
[43] Ly Vath V, Mnif M and Pham H, A model of optimal portfolio selection under liquidity
risk and price impact, Finance and Stochastics, 2007, 11: 51–90.
[44] Peng S, Backward stochastic differential equations and applications to optimal control.
Appl. Math. Optim., 1993, 27: 125–144.
[45] Pardoux E, Peng S, Adapted solution of a backward stochastic differential equation, Systems
Control Lett., 1990, 14: 55–61.
[46] Peng S, Probabilistic interpretation for systems of quasilinear parabolic partial differential
equations, Stochastics Stochastics Rep., 1991, 37: 61–74.
[47] Peng S, A generalized dynamic programming principle and HJB equation, Stochastics
Stochastics Rep., 1992, 38: 119–134.
[48] Peng S, BSDE and stochastic optimizations, in: J. Yan, S. Peng, S. Fang, L. Wu, Topics
in Stochastic Analysis, Science Press, Beijing, 1997 (Chapter 2) (in Chinese).
[49] Palczewski J and Stettner L, Finite horizon optimal stopping of time-discontinuous functionals with applications to impulse control with delay, SIAM J. Control Optim., 2010, 48:
4874–4909.
[50] Robin M, Controle impulsionnel des processus de Markov, Thesis, INRIA, Paris, France,
1978. Available online at http://tel.archives-ouvertes.fr/tel-00735779.
[51] Revuz D, Yor M, Continuous Martingales and Brownian Motion, Third Edition With 8
Figures, Springer, 1999.
[52] Stettner L, Zero-sum Markov games with stopping and impulsive strategies, Appl. Math.
Optim., 1982, 9: 1–24.
[53] L. Stettner, Penalty method for finite horizon stopping problems, SIAM J. Control Optim.,
2011, 49: 1078–1099.
[54] Tang S and Hou S-H, Switching games of stochastic differential systems, SIAM J. Control
Optim., 2007, 46: 900–929.
[55] Tang S and Yong J M, Finite horizon stochastic optimal switching and impulse controls
with a viscosity solution approach, Stochastics Stochastics Rep., 1993, 45: 145–176.
[56] Z. Wu, Z. Yu, Dynamic programming principle for one kind of stocastic recursive optimal
control problem and Hamilton-Jacobi-Bellman equation, SIAM J. Control Optim., 2008
Vol. 47, No. 5: 2616–2641.
[57] Xu, X, Fully Coupled Forward-Backward Stochastic Functional Differential Equations and
Applications to Quadratic Optimal Control. J Syst Sci Complex 33, 1886–1902 (2020).
https://doi.org/10.1007/s11424-020-9027-x.
33

[58] Wang G, Yu Z, A partial information non-zero sum differential game of backward stochastic
differential equations with applications. Automatica, 2012, 48(2),342-352.
[59] Wang G, Xiao H and Xiong J, A kind of LQ non-zero sum differential game of backward
stochastic differential equation with asymmetric information, Automatica, 2018, 97, 346352.
[60] Yong J M, Zhou X Y, Stochastic Controls. Hamiltonian Systems and HJB Equations,
Springer-Verlag, New York, 1999.
[61] Yong J M, Zero-sum differential games involving impulse controls, Appl. Math. Optim.,
1994. 29 : 243–261.
[62] Zhang F, Stochastic differential games involving impulse controls, ESAIM Control Optim.
Calc. Var., 2011, 17: 749–760.
[63] Zabaljauregui D, A fixed-point policy-iteration-type algorithm for symmetric nonzero-sum
stochastic impulse games, Appl Math Optim: 2020.

34

