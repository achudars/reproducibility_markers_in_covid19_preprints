Top-down induction of decision trees:
rigorous guarantees and inherent limitations

arXiv:1911.07375v1 [cs.DS] 18 Nov 2019

Guy Blanc

Jane Lange

Li-Yang Tan

Stanford University
November 19, 2019

Abstract
Consider the following heuristic for building a decision tree for a function f : {0, 1}n → {±1}.
Place the most influential variable xi of f at the root, and recurse on the subfunctions fxi =0 and
fxi =1 on the left and right subtrees respectively; terminate once the tree is an ε-approximation
of f . We analyze the quality of this heuristic, obtaining near-matching upper and lower bounds:
◦ Upper bound: For every f with decision tree size s and every ε ∈ (0, 21 ), this heuristic builds
a decision tree of size at most sO(log(s/ε) log(1/ε)) .
√

◦ Lower bound: For every ε ∈ (0, 12 ) and s ≤ 2Õ( n) , there is an f with decision tree size s
such that this heuristic builds a decision tree of size sΩ̃(log s) .
√

√
4

We also obtain upper and lower bounds for monotone functions: sO( log s/ε) and sΩ̃( log s)
respectively. The lower bound disproves conjectures of Fiat and Pechyony (2004) and Lee (2009).
Our upper bounds yield new algorithms for properly learning decision trees under the uniform
distribution. We show that these algorithms—which are motivated by widely employed and
empirically successful top-down decision tree learning heuristics such as ID3, C4.5, and CART—
achieve provable guarantees that compare favorably with those of the current fastest algorithm
(Ehrenfeucht and Haussler, 1989), and even have certain qualitative advantages. Our lower
bounds shed new light on the limitations of these heuristics.
Finally, we revisit the classic work of Ehrenfeucht and Haussler. We extend it to give the first
uniform-distribution proper learning algorithm that achieves polynomial sample and memory
complexity, while matching its state-of-the-art quasipolynomial runtime.

1

Introduction

Consider the problem of constructing a decision tree representation of a function f : {0, 1}n → {±1},
where the goal is to build a decision tree for f that is as small as possible, ideally of size close to
the optimal decision tree size of f . Perhaps the simplest and most natural approach is to proceed
in a top-down, greedy fashion:
1. Choose a “good” variable xi to query as the root of the decision tree;
2. Build the left and right subtrees by recursing on the subfunctions fxi =0 and fxi =1 respectively.
This reduces the task of building a decision tree to that of choosing the root variable—i.e. determining the splitting criterion of this top-down heuristic. Intuitively, a good root variable should
be one that is very “relevant” and “important” in terms of determining the value of f ; it is reasonable to expect that querying such a variable first would reduce the number of subsequent queries
necessary. Our focus in this paper will be on a specific splitting criterion: influence.
Definition 1 (Influence). The influence of the variable xi on a function f : {0, 1}n → {±1} is
defined to be
Inf i (f ) := Pr [f (x) 6= f (x⊕i )],
x∼{0,1}n

where x is drawn uniformly at random, and x⊕i denotes x with its i-th coordinate flipped.
Influence is a fundamental and well-studied notion in the analysis of boolean functions [O’D14].
It is the key quantity of interest in many landmark results (e.g. the KKL inequality [KKL88],
Friedgut’s junta theorem [Fri98], the Invariance Principle [MOO10]) and open problems (e.g. the
Gotsman–Linial conjecture [GL89], the Aaronson–Ambainis conjecture [AA14], the Fourier EntropyInfluence conjecture [FK96]) of the field. Beyond the analysis of boolean functions, this notion has
been widely employed across both algorithms and complexity theory, where it has indeed proven
to be a useful quantitative measure of the relevance and importance of a variable. Most relevant to
the algorithmic applications in this paper, influence has been a key enabling ingredient in a large
number of results in learning theory [BT96, BBL98, LMN93, Ser04, OS07, OW13, GS10, DHK+ 10,
Kan14a, Kan14b, BCO+ 15].

1.1

Influence as a splitting criterion

We now give a formal description of the heuristic for constructing decision trees that we study. We
define a bare tree to be a decision tree with unlabeled leaves, and write T ◦ to denote such trees.
We refer to any decision tree T obtained from T ◦ by a labelling of its leaves as a completion of T ◦ .
Given a bare tree T ◦ and a function f , there is a canonical completion of T ◦ that minimizes the
approximation error with respect to f :
Definition 2 (f -completion of a bare tree). Let T ◦ be a bare tree and f : {0, 1}n → {±1}.
Consider the following completion of T ◦ : for every leaf ` in T ◦ , label it sign(E[f` (x)]), where f` is
the restriction of f by the path leading to ` and x ∼ {0, 1}n is uniform random. This completion
minimizes the approximation error Pr[T (x) 6= f (x)], and we refer to it as the f -completion of T ◦ .

1

In addition to the function f , our heuristic will also take in an error parameter ε, allowing us
to construct both exact (ε = 0) and approximate (ε ∈ (0, 12 )) decision tree representations of f .
BuildTopDownDT(f, ε):
Initialize T ◦ to be the empty tree.
while (f -completion of T ◦ is not an ε-approximation of f ) {

1. (Score) For every leaf ` in T ◦ , let xi(`) denote the most influential variable of the
subfunction f` :
Inf i(`) (f` ) ≥ Inf j (f` ) for all j ∈ [n].
Assign ` the score:
score(`) :=

Pr

x∼{0,1}n

[ x reaches ` ] · Inf i(`) (f` ) = 2−|`| · Inf i(`) (f` ),

where |`| denotes the depth of ` in T ◦ .
2. (Split) Let `? be the leaf with the highest score. Grow T ◦ by replacing `? with a query
to xi(`? ) .
}
Figure 1: Top-down heuristic for building an ε-approximate decision tree representation
of f , with influence as the splitting criterion.
In words, BuildTopDownDT builds a bare tree T ◦ in a top-down fashion, starting from the
empty tree. In each iteration, we first check if the f -completion of T ◦ is an ε-approximation of
f , and if so, we output the completion. Otherwise, we split the leaf `? with the highest score by
querying the most influential variable of f`? , where the score of a leaf ` is the influence of the most
influential variable of f` normalized by the depth of ` within T ◦ .1

1.2

This work

By design, the decision tree returned by BuildTopDownDT(f, ε) is an ε-approximation of f . We
write TopDownDTSize(f, ε) to denote the size of this tree, and when ε = 0, we simply write
TopDownDTSize(f ). The question that motivates our work is:
What guarantees can we make on TopDownDTSize(f, ε) as a function of
the optimal decision tree size of f and ε?
That is, we would like to understand the quality of BuildTopDownDT as a heuristic for
constructing exact and approximate decision tree representations. In addition to being a natural
1
There are two possibilities for ties in BuildTopDownDT: two variables may have the same influence within a
subfunction f` , and two leaves may have the same score. Our upper bounds hold regardless of how ties are broken,
and our lower bounds hold even if ties are broken in the most favorable way.

2

structural question concerning decision trees, this question also has implications in learning theory.
Indeed, BuildTopDownDT is motivated by top-down decision tree learning heuristics such as ID3,
C4.5, and CART that are widely employed and empirically successful in machine learning practice.
We discuss the learning-theoretic context and applications of our structural results in Section 2.1,
and the connection to practical machine learning heuristics in Section 3.1.
To our knowledge, the question above has not been studied in such generality. The most directly
relevant prior work is that of Fiat and Pechyony [FP04], who considered the case when f is either a
linear threshold function or a read-once DNF formula, and the setting of exact representation (ε =
0). For such functions, they proved that the heuristic builds an exact decision tree representation
of optimal size. We give an overview of other related work in Section 3.2.

2

Our results

As our first contribution, we give near-matching upper and lower bounds that provide a fairly
complete answer to the question above. Our upper bound is as follows:
Theorem 3 (Upper bound for approximate representation). For every ε ∈ (0, 12 ) and every size-s
decision tree f , we have TopDownDTSize(f, ε) ≤ sO(log(s/ε) log(1/ε)) .
We complement Theorem 3 with lower bounds showing that (a) for exact representation (ε = 0),
no non-trivial upper bound can be obtained; and (b) for approximate representation (ε ∈ (0, 12 )),
the dependence on s in Theorem 3 is essentially optimal:
Theorem 4 (Lower bounds for exact and approximate representations).
(a) Exact representation: There is an f : {0, 1}n → {±1} with decision tree size s = Θ(n) such
that TopDownDTSize(f ) ≥ 2Ω(s) .
√

(b) Approximate representation: For every ε ∈ (0, 21 ) and function s(n) ≤ 2Õ( n) , there is an
f : {0, 1}n → {±1} with decision tree size s such that TopDownDTSize(f, ε) ≥ sΩ̃(log s) .
Prior to our work, it was not known whether an upper bound of TopDownDTSize(f, ε) ≤
poly(s, 1/ε) holds for all size-s decision trees f and ε ∈ (0, 21 ); Theorem 4(b) provides a strong
negative answer. Indeed, such an upper bound had been conjectured to hold for the class of
monotone functions [Lee09]. We now discuss our results on monotone functions, which disprove
this conjecture, along with a stronger variant of it for exact representation [FP04].
Monotone functions. A monotone boolean function f : {0, 1}n → {±1} is one that satisfies
f (x) ≤ f (y) for all x  y (where x  y iff xi ≤ yi for all i ∈ [n]). An elementary and useful fact
about monotone functions is that the influence of a variable on a monotone function f is equivalent
to its correlation with f :
Fact 2.1 (Influence ≡ correlation for monotone functions). For all monotone functions f : {0, 1}n →
{±1} and i ∈ [n], we have Inf i [f ] = 2 E[f (x)xi ] − E[f (x)].2
2

The equivalence between influence and correlation for monotone functions is more transparent if one works with
{±1}n instead of {0, 1}n as the domain: for monotone functions f : {±1}n → {±1}, we have Inf i [f ] = E[f (x)xi ].

3

Therefore, for monotone functions, splitting on the most influential variable of a subfunction is
equivalent to splitting on the variable that has the highest correlation with the subfunction.3
Our proof of Theorem 3 extends in a straightforward manner to give a different upper bound
under the assumption of monotonicity, where the dependence on s is significantly better. We refer
to a size-s decision tree computing a monotone function as a size-s monotone decision tree.
Theorem 5 (Upper bound for approximate representation of monotone functions.). For every
ε∈
√
(0, 12 ) and every size-s monotone decision tree f , we have TopDownDTSize(f, ε) ≤ sO( log s/ε) .
In analogy with Theorem 4, we also obtain lower bounds for exact and approximate representations of monotone functions:
Theorem 6 (Lower bounds for exact and approximate representations of monotone functions).
(a) Exact representation: There is a monotone f : {0, 1}n → {±1} with decision tree size s =
Θ(n) such that TopDownDTSize(f ) ≥ 2Ω(s) .
4/5

(b) Approximate representation: For every ε ∈ (0, 12 ) and function s(n) ≤ 2Õ(n ) , there is an
√
4
f : {0, 1}n → {±1} with decision tree size s such that TopDownDTSize(f, ε) ≥ sΩ̃( log s) .
Although we have stated Theorem 6 in terms of the specific heuristic BuildTopDownDT
that we study, the actual lower bounds that we establish are significantly stronger: they apply
to all “impurity-based top-down heuristics”. This is a broad class that captures a wide variety of
decision tree learning heuristics used in machine learning practice, including ID3, C4.5, and CART;
see Section 3.1 for details.
4/5

Theorem 7 (Stengthening of Theorem 6(b)). For every ε ∈ (0, 12 ) and function s(n) ≤ 2Õ(n ) ,
there is a size-s monotone decision tree
f such that the ε-approximator built by any impurity-based
√
4
top-down heuristic must have size sΩ̃( log s) .
Disproving conjectures of Fiat–Pechyony and Lee. Motivated by applications in learning
theory (discussed next in Section 2.1), Fiat and Pechyony [FP04] and Lee [Lee09] also considered
the quality of BuildTopDownDT as a heuristic for building decision trees for monotone functions.
[FP04] conjectured that for all monotone functions f , even in the case of exact representation
(ε = 0), BuildTopDownDT returns a tree of minimal depth and size “not far from minimal.”
Theorem 6(a) provides a counterexample to the conjectured bound on size, and the function in Theorem 6(b) disproves the conjecture about depth; see Remark 22.4
Stated in the notation of our paper, [Lee09] raised the possibility that TopDownDTSize(f, ε) ≤
poly(s, 1/ε) for all size-s monotone decision trees f and ε ∈ (0, 21 ). The author further remarked
that “showing TopDownDTSize(f, ε) ≤ poly(s), even only for constant accuracy ε,5 would be a
huge advance”. Theorem 6(b) rules this out.
3

We observe that for general non-monotone functions, correlation can in general be a very poor splitting criterion,
in the sense of building a decision tree that is much larger than the optimal decision tree. Consider f : {0, 1}n → {±1}
where f (x) = xj ⊕ xk , the parity of two variables. The optimal decision tree size of f is 4, but since E[f (x)xi ] = 0
for all i ∈ [n], the top-down heuristic using correlation as its splitting criterion may build a tree of size Ω(2n ) before
achieving any non-trivial accuracy ε < 12 . (On the other hand, the top-down heuristic using influence as its splitting
criterion would build the optimal tree of size 4.) We revisit this observation in Section 3.1.
4
For clarity of exposition, throughout this overview we discuss our results with decision tree size as the complexity
measure. There are analogues of all of our results, both upper and lower bounds, for decision tree depth as the
complexity measure.
5
That is, a bound of the form TopDownDTSize(f, ε) ≤ sOε (1) .

4

2.1

Algorithmic applications: Properly learning decision trees

Learning decision trees has been a touchstone problem in uniform-distribution PAC learning for
more than thirty years. It sits right at the boundary of our understanding of efficient learnability, and continues to be the subject of intensive research. The seminal work of Ehrenfeucht and
Haussler [EH89] gave a poly(nlog s , 1/ε)-time algorithm for learning decision trees using random
examples (see also [Blu92] for an alternative proof based on Rivest’s algorithm for learning decision lists [Riv87]);6 subsequently, Linial, Mansour, and Nisan [LMN93] gave an algorithm that
also runs in quasipolynomial time, but achieves polynomial sample complexity; Kusilevitz and
Mansour [KM93], leveraging a novel connection to cryptography [GL89], gave a polynomial-time
algorithm using membership queries; Gopalan, Kalai, and Klivans [GKK08] obtained an agnostic
analogue of [KM93]’s algorithm, extending it to tolerate adversarial noise; O’Donnell and Servedio [OS07] gave a polynomial-time algorithm for learning monotone decision trees from random
examples; recent work of Hazan, Klivans, and Yuan [HKY18] gives an algorithm agnostically
learning decision trees with polynomial sample complexity; even more recent work of Chen and
Moitra [CM19] gives an algorithm for learning stochastic decision trees.
Properly learning decision trees. When learning decision trees, it is natural to seek a hypothesis
that is itself a decision tree. Indeed, it may be natural to seek a decision tree hypothesis even
when learning other concept classes. The simple structure of decision trees makes them desirable
both in terms of interpretability and explanatory power, which is why they are ubiquitous in
empirical machine learning. A further advantage of decision tree hypotheses is that they are very
fast to evaluate: evaluating a depth-d decision tree on a given input takes time O(d),7 whereas
evaluating say a degree-d polynomial—another canonical and ubiquitous representation class in
learning theory—can take time Θ(nd ), the number of monomials in the polynomial.
In learning theory, algorithms that return a hypothesis belonging to the concept class are known
as proper. Understanding the complexity of proper learning (vis-à-vis improper learning) is an
important research direction in learning theory [Fel16]; proper learning also has deep connections
to proof complexity [ABF+ 09] and property testing [GGR98].
2.1.1

New proper learning algorithms

Among the decision tree learning algorithms discussed at the beginning of this subsection, the
only one that is proper is the one of Ehrenfeucht and Haussler [EH89]. Our upper bounds on
TopDownDTSize yield new algorithms for properly learning decision trees under the uniform
distribution:
Theorem 8 (Algorithmic consequence of Theorem 3). Size-s decision trees can be properly learned
under the uniform distribution in time poly(n, slog(s/ε) log(1/ε) ) using membership queries.8
6
In fact, the algorithm of [EH89] learns decision trees in the more challenging setting of distribution-free PAC
learning. All other results in this discussed in this section, including ours, are specific to uniform-distribution learning,
and we focus our exposition on this setting.
7
Every size-s decision tree is well-approximated by a decision tree of depth O(log s).
8
We remark that our algorithm only requires fairly “mild” use of membership queries. Our algorithm only
requires random edge samples (Definition 24), and hence falls within both the random walk model of Bshouty et
al. [BMOS05] and the local membership queries model of Awasthi et al. [AFK13]. These (incomparable) models are
natural relaxations of the standard model of learning from random examples, and do not allow the learning algorithm
unrestricted membership query access to the target function.

5

Analogously, Theorem 5 yields a new algorithm for learning monotone decision trees using only
random examples. The learnability of monotone functions with respect to various complexity measures has been the subject of intensive study in uniform-distribution learning [HM91, KV94, KLV94,
Bsh95, BT96, BBL98, Ver98, SM00, Ser04, OS07, Sel08, DSLM+ 09, Lee09, JLSW11, OW13].
Theorem 9 (Algorithmic consequence of Theorems 3 and 5). Size-s monotone decision trees
√ can be
properly learned under the uniform distribution in time poly(n, min(sO(log(s/ε) log(1/ε)) , sO( log s/ε) ))
using only random examples.
We now compare our results with the prior state of the art for properly learning decision trees.
◦ Polynomial-time algorithms for superlogarithmic size. Theorems 8 and 9 give the first
polynomial-time algorithms for properly learning decision trees of size ω(log n) to constant accuracy. To see this, we first note that [EH89]’s runtime of poly(nlog s , 1/ε) is superpolynomial
time for any s = ω(1). Alternatively, functions depending on k  n variables (“k-juntas”)
can be properly learned in time poly(n, 2k ), using random examples for monotone juntas, and
membership queries otherwise [BL97, MOS04]. Since every size-s decision tree certainly depends
on at most k ≤ s variables, this runtime is polynomial for decision trees of size s = O(log n),
but becomes superpolynomial once s = ω(log n). In
contrast, the runtimes of our algorithms
√
2/3
in Theorems 8 and 9 remain polynomial for s = 2Ω( log n) and s = 2Ω((log n) ) respectively.
◦ Dimension-independent hypothesis size. Related to the above, the sizes
√ of the hypotheses
returned by the algorithms of Theorems 8 and 9 are sO(log(s/ε) log(1/ε)) and sO( log s/ε) respectively,
independent of n, whereas the size of the hypotheses returned by [EH89]’s algorithm can be as
large as nΩ(log s) . This is gap can be exponential or even larger for small values of s.
◦ Average depth as the complexity measure. Our algorithms and analyses extend easily
to accommodate average depth as the complexity measure. The average depth of a decision
tree, 4(T ), is the number of queries T makes on a uniform random input. Average depth is a
stronger complexity measure than size since 4(T ) ≤ log(size(T )).9
Theorem 10 (Learning trees with small average depth). Decision trees of average depth 4
2
can be properly learned under the uniform distribution in time poly(n, 24 /ε ) using membership queries, and monotone decision trees of average depth 4 can be properly learned in time
3/2
poly(n, 24 /ε ) using random examples.
To our knowledge, these represent the first polynomial-time algorithms for properly learning
decision trees of superconstant average depth, 4 = ω(1). Prior to our work, the fastest algorithm
ran in time poly(n4/ε ); this algorithm, which uses random examples, follows implicitly from the
results of Mehta and Raghavan [MR02].

2.2

Proper learning with polynomial sample and memory complexity

For our final contribution, we revisit the classic algorithm of Ehrenfeucht and Haussler [EH89]. As
discussed above, this remains the fastest algorithm for properly learning decision trees. We extend
9

Furthermore, it is easy to construct examples of decision trees T with the largest possible gap between these
measures: 4(T ) = O(1) and log(size(T )) = Ω(n).

6

it to give the first uniform-distribution proper algorithm that achieves polynomial sample and
memory complexity, while matching its state-of-the-art quasipolynomial runtime (Theorem 29).
Reference

Running time

Sample complexity

Memory complexity

Proper?

[EH89]

poly(nlog s , 1/ε)

poly(nlog s , 1/ε)

poly(nlog s , 1/ε)

X

[LMN93]

poly(nlog(s/ε) )

poly(s, 1/ε) · log n

poly(n, s, 1/ε)

×

[MR02]

poly(nlog(s/ε) )

poly(s, 1/ε) · log n

poly(nlog(s/ε) )

X

This work

poly(nlog s , 1/ε)

poly(s, 1/ε) · log n

poly(n, s, 1/ε)

X

Table 1: Algorithms for learning size-s decision trees from random examples under the
uniform distribution
Ehrenfeucht and Haussler had posed (as the first open problem of their paper) the question of
achieving polynomial sample complexity. Such algorithms were subsequently obtained by Linial,
Mansour, and Nisan [LMN93] and Mehta and Raghavan [MR02]. Interestingly, these two algorithms
are very different from each other and from [EH89]: the algorithm of [LMN93], being Fourier-based,
is non-proper, whereas the algorithm of [MR02], which uses dynamic programming, has a large
memory footprint. Furthermore, both algorithms have a quasipolynomial dependence on 1/ε in
their runtimes, rather than [EH89]’s polynomial dependence.
This state of affairs raises the question of whether there is a single algorithm that achieves “the
best of [EH89], [LMN93], and [MR02]” in each of the four metrics discussed above; see Table 1.
We give such an algorithm in this work (Theorem 29). Our algorithm is a surprisingly simple
modification of [EH89]’s algorithm, but our analysis is more involved. At a high level, the idea
is to terminate [EH89]’s algorithm early to achieve our improved sample and memory complexity. However, incorporating this plan with the inherently bottom-up nature of [EH89]’s algorithm
necessitates a delicate error analysis. (In particular, [EH89]’s algorithm is an Occam algorithm,
whereas ours is not.)1011
We remark that there is an ongoing flurry of research activity on the memory complexity of
learning basic concept classes under the uniform distribution, with a specific focus on tradeoffs
between memory and sample complexity [Sha14, SVW16, Raz17, KRT17, MM17, Raz18, MM18,
BOGY18, GRT18, GRT19].
10
Although our algorithm, like the others in Table 1, only uses random examples, to our knowledge there are no
known membership query algorithms that achieves our guarantees.
11
We note that it is possible to combine the ideas in [EH89] and [MR02] to give an algorithm that runs in
poly(nlog(s/ε) ) time and has sample and memory complexity poly(s, 1/ε) · log n and poly(n, s, 1/ε) respectively. We
do not provide the details in this paper since our main result (Theorem 29) achieves strictly better guarantees.

7

3

Discussion and related work

3.1

Relationship to practical machine learning heuristics

Our work is motivated in part by the tremendous popularity and empirical success of top-down
decision tree learning heuristics in machine learning practice, such as ID3 [Qui86], its successor
C4.5 [Qui93], and CART [Bre17]. The data mining textbook [WFHP16] describes C4.5 as “a
landmark decision tree program that is probably the machine learning workhorse most widely used
in practice to date”. In a similar vein, quoting Kearns and Mansour [KM99], “In experimental and
applied machine learning work, it is hard to exaggerate the influence of top-down heuristics for
building a decision tree from labeled sample data [...] Dozens of papers describing experiments and
applications involving top-down decision tree learning algorithms appear in the machine learning
literature each year”.
We give a high-level description of how these heuristics work, using the framework of uniformdistribution learning. As we will soon see, they serve as motivation for the heuristic that we study,
BuildTopDownDT (Figure 1). These heuristics grow a bare tree T ◦ for a function f : {0, 1}n →
{0, 1} as follows. Consider the progress measure
X
H(T ◦ ) :=
Pr [ x reaches ` ] · G (E[f` ]),
`∈leaves(T ◦ )

x∼{0,1}n

where G : [0, 1] → [0, 1] is known as the impurity function, and encapsulates the splitting criterion
of the heuristic. This carefully chosen function is restricted to be concave, symmetric around 12 ,
and to satisfy G (0) = G (1) = 0 and G ( 12 ) = 1. For example, G is the binary entropy function
in ID3 and C4.5;pCART uses G (p) = 4p(1 − p), known as the Gini criterion; [KM99] studies the
◦ to denote T ◦ with its leaf ` replaced with a query to the
variant G (p) = 2 p(1 − p).12 Writing T`,i
variable xi , these heuristics, in a single iteration, grow T ◦ to T`◦? ,i? , where
(`? , i? ) is the leaf-variable pair that maximizes H(T ◦ ) − H(T`◦? ,i? ).

(1)

We refer to any such top-down heuristic as an impurity-based heuristic, and the progress measure
H(T ◦ ) − H(T`◦? ,i? ) as the purity gain.
Inherent limitations of impurity-based heuristics. It is easy to see (and has been well
known [Kea96]) that impurity-based heuristics can, in general, fare very badly, in the sense of
building a decision tree that is much larger than the optimal decision tree. For example, consider
f (x) = xj ⊕ xk for j, k ∈ [n], the parity of two variables. For such a target function, regardless
of the choice of the impurity function G , splitting on any of the n variables results in zero purity
gain. This is because E[f ] = E[fxi =b ] for all i ∈ [n] and b ∈ {0, 1}. Therefore, any impurity-based
heuristic may build a tree of size Ω(2n ) before achieving any non-trivial error ε < 21 , whereas the
size of the optimal tree of f is only 4.
One could exclude such “parity-like” examples by considering only monotone functions. Monotonicity is a ubiquitous condition in machine learning since many data sets are naturally monotone
in their attributes. In the case of monotone functions, it can be shown that for any impurity function G , the variable split that results in the most progress in the sense of (1), i.e. the variable xi
12

The work of Dietterich, Kearns, and Mansour [DKM96] gives a detailed experimental comparison of various
impurity functions.

8

that maximizes the purity gain
G (E[f ]) − 12 (G (E[fxi =0 ]) + G (E[fxi =1 ])),
is precisely the most influential variable of f (we prove this in Section 7; see Proposition 7.7).
In other words, in the case of monotone functions, BuildTopDownDT closely models impuritybased heuristics. The works of Fiat and Pechyony [FP04] and Lee [Lee09] (recall our discussion
following Theorem 7) were explicitly motivated by this observation, as are our results on monotone
functions (Theorems 5 to 7 and 9).
As we will show, our monotone lower bounds for BuildTopDownDT actually apply to all
impurity-based heuristics (Theorem 7), regardless of the choice of the impurity function G (hence
including ID3, C4.5, and CART).13 Since one could argue that real-world data sets are unlikely to
be “parity-like”, we view our monotone lower bounds as providing more robust (albeit still only
theoretical) evidence of the limitations and potential shortcomings of the impurity-based top-down
heuristics used in practice.
Top-down versus bottom-up: from practice to theory? We find it especially intriguing
that the algorithm of Ehrenfeucht and Haussler [EH89]—which as discussed, remains the fastest
algorithm for properly learning decision trees with provable runtime guarantees—builds its hypothesis tree bottom up, in exactly the opposite order from the top-down heuristics used in practice.
It is natural to ask if top-down heuristics can serve as inspiration for the design and analyses of
fundamentally different algorithms for properly learning decision trees.
Our algorithmic upper bounds for BuildTopDownDT (Theorems 8 and 9) provide affirmative
answers, and as discussed above, these new algorithms even have certain qualitative advantages
over [EH89]. Our lower bounds (Theorems 4 and 6), on the other hand, establish their inherent
limitations. They imply that BuildTopDownDT is provably not a polynomial-time algorithm
for properly learning decision trees using membership queries, or a polynomial-time algorithm for
properly learning monotone decision trees using random examples. Either of these results would
constitute a major advance in learning theory, and BuildTopDownDT—and other impuritybased variants of it—had been a natural candidate for obtaining them. Indeed, the results of [Lee09]
were explicitly motivated by the goal of showing that BuildTopDownDT is a polynomial-time
algorithm for properly learning monotone decision trees. This is now ruled out by Theorems 6
and 7.14

3.2

Related work

Fiat and Pechyony [FP04] considered linear threshold functions and read-once DNF formulas, and
showed that BuildTopDownDT, when run on such functions, returns a decision tree of optimal
size computing them exactly. (Stated in the notation of Theorem 3, TopDownDTSize(f ) = s for
such functions.)
Kearns and Mansour [KM99] (see also [Kea96, DKM96]) showed that impurity-based heuristics
are boosting algorithms, where one views the functions labeling internal nodes of the tree (single
variables in our case) as weak learners. At a high level, the proofs of our upper bounds (Theorems 3
Different impurity functions G lead to different orderings of leaves to split, and hence result in different trees.
Blum et al. [BFJ+ 94] gave an information-theoretic lower bound showing that no “statistical query” algorithm
can learn decision trees in polynomial time. However, this lower bound does not apply when membership queries are
allowed or when the function is assumed to be monotone.
13

14

9

and 5) are similar in spirit to their analysis, in the sense that they are all incremental in nature,
showing that each split contributes to the accuracy of the decision tree hypothesis. However, our
results and analyses are incomparable—for example, [KM99] does not relate the size of the resulting
hypothesis to the size of the optimal decision tree; [KM99]’s analysis assumes the existence of weak
learners for all filtered-and-rebalanced versions of the target distribution, whereas we carry out the
entirety of our analyses with respect to the uniform distribution.15
Recent work of Brutzkus, Daniely, and Malach [BDM19b] studies a variant of ID3 proposed
by [KM99], focusing on learning conjunctions and read-once DNF formulas under product distributions. They provide theoretical and empirical evidence showing that for such functions, the
size-t tree grown by [KM99]’s variant of ID3 achieves optimal or near-optimal error among all
trees of size t. Concurrent work by the same authors [BDM19a] shows that ID3 efficiently learns
(log n)-juntas in the setting of smoothed analysis.

4

Preliminaries

Throughout this paper, we use bold font (e.g. x and S) to denote random variables; all probabilities
and expectations are with respect to the uniform distribution unless otherwise stated.
For any decision tree T , we say the size of T is the number of leaves in T , and the depth of T is
length of the longest path between the root and a leaf. If a tree has size 1, then it contains a single
leaf, computes either the constant +1 or constant −1 function, and has depth 0. For a function
f : {0, 1}n → {±1}, the optimal decision tree size of f is the smallest s for which there exists a
decision tree of size s that exactly computes f , and we write size(f ) to denote this quantity. If T
is a decision tree that computes f , then we will often use T interchangeably with f .
Choose any f, g : {0, 1}n → {±1}. Then, the error is defined as
error(f, g) =

Pr

x∼{0,1}n

[f (x) 6= g(x)].

We say that f is an ε-approximation of g if error(f, g) ≤ ε. If T ◦ is a bare tree, then error(T ◦ , f ) is
shorthand for error(T, f ) where T is the f -completion of T ◦ . We also use the following shorthand.
error(f, ±1) = min(error(f, −1), error(f, 1)).

The variance of f : {0, 1}n → {±1}, denoted Var(f ), is

Var(f ) = 4 · Pr[f (x) = −1] · Pr[f (x) = 1].

The total influence of f , denoted Inf(f ), is
Inf(f ) =

n
X

Infi (f ).

i=1

It is easy to see that for any decision tree T : {0, 1}n → {±1},
error(T, ±1) ≤ Inf(T )

and

Var(T )
≤ error(T, ±1) ≤ Var(T )
2

always hold.
15

Indeed, [KM99]’s results concern impurity-based heuristics, and as discussed above, statements like Theorem 3
that apply to all functions cannot hold for such heuristics because of parity-like functions.

10

5

Upper bounds on TopDownDTSize: Proofs of Theorems 3 and 5

Recall that BuildTopDownDT(f, ε) continually grows a bare tree, T ◦ , until the f -completion of
T ◦ is an ε-approximation of f . At a high level, the proofs of our upper bounds on TopDownDTSize proceed as follows.
Section 5.1 We define a progress metric, the “cost” of T ◦ , which upper bounds the error of the
f -completion of T ◦ with respect to f . Hence, when the “cost” drops below ε, BuildTopDownDT can terminate. We show that whenever BuildTopDownDT grows T ◦ , the “cost”
of T ◦ decreases by exactly the score of the leaf selected.
Section 5.2 We lower bound the score of the leaf that BuildTopDownDT selects.
Section 5.3 We put the above together to prove upper bounds on TopDownDTSize. At each
step, the “cost” of T ◦ must decrease by at least the lower bounds in Section 5.2, which allows
us to upper bound the number of steps until the “cost” falls below ε. This is sufficient since
the size of the tree that BuildTopDownDT produces is exactly one more than the number
of steps it takes.

5.1

Definition and properties of “Cost”

Definition 11 (Cost of a bare tree). Let f : {0, 1}n → {±1} be a function and T ◦ be a bare tree.
Then the cost of T ◦ relative to f is defined as
X
costf (T ◦ ) =
2−|`| · Inf(f` ).
leaf `∈T ◦

This cost function is useful to track because it naturally decreases during BuildTopDownDT
and upper bounds the error of the completion.
Lemma 5.1 (Properties of cost of a bare tree). For any f : {0, 1}n → {±1} and bare tree T ◦ , the
following hold:
1. error(T ◦ , f ) ≤ costf (T ◦ ).

2. Choose any leaf ` of T ◦ and variable xi . Let (T ◦ )0 be the bare tree that results from replacing
` in T ◦ with a query to xi . Then,
costf ((T ◦ )0 ) = costf (T ◦ ) − 2−|`| · Inf i (f` ).
At each step, BuildTopDownDT splits the leaf with the largest score, resulting in the cost
decreasing by exactly the score selected. Once the cost decreases to below ε, we know the completion
of T ◦ is an ε-approximation of f , meaning BuildTopDownDT can terminate.
Proof. The proof of (1) is a simple application of the fact that error(g, ±1) ≤ Inf(g) for any boolean
function g:
error(T ◦ , f ) =
=

Pr
X

x∼{0,1}n

leaf `∈T ◦

≤

X
leaf `∈T ◦

[(Completion of T ◦ )(x) 6= f (x)]
Pr

x∼{0,1}n

[x reaches `] · error(f` , , ±1)

2−|`| · Infi (f` ) = costf (T ◦ ).
11

The proof of (2) follows from the fact that if T is a tree with xi at the root, T0 as its 0-subtree,
and T1 as its 1-subtree, then Inf(T ) − Infi (T ) = 12 (Inf(T0 ) + Inf(T1 )). This fact is true because
Inf(T ) − Infi (T ) =

X

Infj (T )

j6=i

1
Infj (T0 ) + Infj (T1 )
2
2
j6=i


n
n
X
X
1
= 
Infj (T0 ) +
Inf j (T1 )
2

=

X1

j=1

j=1

1
= (Inf(T0 ) + Inf(T1 )).
2

5.2

Lower bounds on the score of the leaf BuildTopDownDT selects

We give two different lower bounds. These lower bounds are incomparable, so when proving Theorems 3 and 5, we use whichever is better. Both of these lower bounds rely on a powerful inequality
from the analysis of boolean functions due to O’Donnell, Saks, Schramm, and Servedio [OSSS05],
which we restate in the form most convenient for us.
Theorem 12 (Corollary of Theorem 1.1 from [OSSS05]). Let f be a size-s decision tree. Then,
 Var(f )
max Inf i (f ) ≥
.
i
log s
We prove our first lower bound on the score of the leaf selected.
Lemma 5.2. Let f be a size s decision tree. At step j, BuildTopDownDT(f, ε) selects a leaf,
`∗ with score at least
score(`∗ ) ≥

ε
.
(j + 1) log(s)

Proof. If BuildTopDownDT has not terminated at step j, then, the completion of T ◦ is not an
ε-approximation of f . Equivalently,
X
2−|`| · error(f` , ±1) > ε
leaf `∈T ◦

At step j, there are exactly j + 1 leaves in T ◦ , so there must be at least one leaf, `, where
2−|`| · error(f` , ±1) >

ε
.
j+1

Since Var(f` ) ≥ error(f` , ±1), we also know
2−|`| · Var(f` ) >

12

ε
.
j+1

By Theorem 12, we know that there is some variable xi such that Inf i (f` ) ≥ Var(f` )/ log(size(f` )).
The optimal size of any restriction of f is certainly at most the optimal size of f itself, so
2−|`| · Inf i (f` ) >

ε
.
(j + 1) log(s)

Since BuildTopDownDT picks a leaf with maximum score, and ` has a score at least ε/(j + 1) log(s),
it must pick a leaf with at least that score.
A standard fact from the analysis of boolean functions gives a log s upper bound on the total
influence of a size-s decision tree (see e.g. [OS07]). In order to prove a second lower bound on the
score of the leaf that BuildTopDownDT selects, we will need a refinement of this bound that
takes into account the variance of the function. The following lemma is a slight variant of a related
(though incomparable) result in [BT15], which upper bounds the total influence of an s-term DNF
formula by 2µ log(s/µ), where µ := Pr[f (x) = 1].
Lemma 5.3 (Total influence of size-s DTs). Let f : {0, 1}n → {±1} be computed by a size-s
decision tree T . Then
Inf(f ) ≤ Var(f ) log(4s/ Var(f )).
Proof. We may assume without loss of generality that µ := Pr[f (x) = 1] ≤
Inf(¬f ) and if f is a size-s decision tree then so is its negation ¬f . Since
Inf(f ) =

E

x∼{0,1}n



= 2 · E sensf (x)1[f (x) = 1]
X
≤2
2−|`| · |`|

(sensf (x) ≤ |`| for every x that reaches `)

1-leaves ` ∈ T

≤ Var(f ) log(4s/ Var(f )),

since Inf(f ) =

(where sensf (x) := |{i ∈ [n] : f (x) 6= f (x⊕i )}|)

[sensf (x)]

≤ 2µ log(s/µ)

1
2,

(Concavity of t 7→ t log(1/t), and size(T ) ≤ s)

(Var(f ) = 4µ(1 − µ), and our assumption that µ ≤ 12 )

the lemma follows.
We now provide a second lower bound on the score of the leaf BuildTopDownDT selects.
The lower bound provided below in Lemma 5.4 is better than the bound provided by Lemma 5.2
when costf (T ◦ ) is large.
Lemma 5.4. Let f be a size s decision tree. Suppose, at step j, that BuildTopDownDT(f, ε)
has already constructed the bare tree T ◦ and that costf (T ◦ ) ≥ ε log(4s/ε) Then, the next leaf, `∗ ,
that BuildTopDownDT picks has score at least
score(`∗ ) ≥

costf (T ◦ )
.
(j + 1) log(4s/ε) log(s)

Proof. We will show that when costf (T ◦ ) is large, there is some leaf with high total influence, which
means it must have high variance, and finally a variable with high influence.
We define:
 
4s
hs : [0, 1] → R where hs (t) = t log
and hs (0) = 0.
t
13

h−1
1 (t)

h1 (t)
1.5

h−1
3 (t)
Lower bound for t ≥ 0.5

1
0.8

1

0.6
0.4

0.5

0.2
0

0
0

0.2

0.4

0.6

0.8

0

1

t

0.2 0.4 0.6 0.8
t

1

1.2 1.4

Figure 2: Graphs of the function h1 (t) = t · log( 4t ) on the left, and of its inverse, h−1
1 (t)
on the right. Since the inverse is convex, we can use a linear lower bound as the dotted
line in the right plot shows.
Then, for any tree T of size at most s, we have that
Inf(T ) ≤ hs (Var(T )).
As long as s ≥ 1, hs is an increasing concave function. This means it has a convex inverse, h−1
s ,
and that for any tree T of size at most s, the following lower bounds the variance.
Var(T ) ≥ h−1
s (Inf(T )).

(2)

−1
Since h−1
s is convex and hs (0) = 0, we can lower bound it as follows. Choose arbitrary a ∈ R.

Then, for t ≥ a we have that h−1
s (t) ≥ t ·

h−1
s (a)
a .

Choosing a = ε log(4s/ε), we have that,
 
t
4s
−1
hs (t) ≥
for all t ≥ ε log
.
log(4s/ε)
ε

Consider the bare tree, T ◦ , at step j. By definition, it has cost
X
2−|`| · Inf(f` ) = costf (T ◦ ).
leaf `∈T ◦

We next apply Jensen’s inequality.
X
leaf `∈T ◦

−1
◦
2−|`| · h−1
s (Inf(f` )) ≥ hs (costf (T )).

Since, at step j, there are j + 1 leaves in T ◦ , for at least one of the leaves, `,
2−|`| · h−1
s (Inf(f` )) ≥

◦
h−1
costf (T ◦ )
s (costf (T ))
≥
.
j+1
(j + 1) log( 4s
ε )

14

By Equation (2), we can lower bound the variance of f` :
∗

2−|` | · Var(f` ) ≥ 2−|`| · h−1
s (Inf(f` )) ≥

costf (T ◦ )
.
(j + 1) log( 4s
ε )

Then, using Theorem 12 and the fact that if f is exactly computed by a size s tree, then f` is
exactly computed by a tree of size at most s.

2−|`| · max Inf i [f` ] ≥
i

costf (T ◦ )
.
(j + 1) log( 4s
ε ) log(s)

Recall that BuildTopDownDT picks the leaf with largest score, so it will pick a leaf with score
costf (T ◦ )
at least (j+1) log(4s/ε)
log(s) .

5.3

Proofs of Theorems 3 and 5

Armed with the above Lemmas, we are now ready to prove our upper bounds on the size of the
tree that BuildTopDownDT produces.
Theorem 3 (Upper bound for approximate representation). For every ε ∈ (0, 12 ) and every size-s
decision tree f , we have TopDownDTSize(f, ε) ≤ sO(log(s/ε) log(1/ε)) .
Proof. We use Cj to refer to costf (T ◦ ) after j steps of BuildTopDownDT. The size of the tree
returned is one more than the number of steps BuildTopDownDT takes. Furthermore, if Cj ≤ ε,
then T ◦ has error at most ε at step j, so BuildTopDownDT will return a tree of size at most
j + 1.
Our analysis proceeds in two phases:
Phase 1: We will show that the larger Cj is, the faster it must decrease at each step. This
multiplicative reduction of Cj will allow us to conclude that after at most k = slog(4s/ε) log(1/ε)
steps, that Ck ≤ ε log( 4s
ε ).
Phase 2: We will argue that Cj makes additive progress towards 0 once it is less than ε log( 4s
ε ),
2
log(4s/ε)
log(1/ε)
showing that after m = s
steps, that Cm ≤ ε.
Once Cm ≤ ε, the algorithm must terminate.
Phase 1: Based on Lemma 5.4, we know that during phase 1, BuildTopDownDT will select a
costf (T ◦ )
leaf with influence at least (j+1) log(4s/ε)
log s at each step j. From Lemma 5.1, we know that:
Cj
Cj ≤ Cj−1 −
j log(4s/ε) log s


1
= Cj−1 · 1 −
.
j log(4s/ε) log s

15

We can use this to bound Ck , the cost after some (k) number of steps, in terms of C0 .
k 
Y
1−
Ck ≤ C0
j=1

1
j log(4s/ε) log s

k
X

= C0 exp

j=1


log 1 −



1
j log(4s/ε) log s

!
.

Using the fact that log(1 + t) < t,


k
X

1
Ck ≤ C0 exp −
j log(4s/ε) log s
j=1


log k
≤ C0 exp −
.
log(4s/ε) log s



We know that C0 ≤ log s because a size-s decision tree has total influence at most log s (see
e.g. [OS07]). Choosing

k = exp log(4s/ε) log(s) log(1/ε) = slog(4s/ε) log(1/ε)
it must be true that Ck ≤ ε log(4s/ε).
Phase 2. This phase combines Lemmas 5.1 and 5.2, which together imply that
Cj+1 ≤ Cj −

ε
.
(j + 1) log s

This means that, for m > k,
Ck − Cm ≥

m
X
j=k+1

ε
ε
≥
(log m − log k).
(j + 1) log s
log s

We are guaranteed to terminate at the first j such that Cj ≤ ε, or earlier. Choosing
log m =

log s
Ck + log k
ε

ensures that Cm ≤ 0, which means BuildTopDownDT must terminate before step m. Plugging
in Ck ≤ ε log(4s/ε) and k = slog(4s/ε) log(1/ε) gives that
m ≤ s2 log(4s/ε) log(1/ε) .
Since BuildTopDownDT terminates after at most m steps, it returns a tree of size at most
m + 1.
The proof of Theorem 5 is mostly the same as Phase 2 from the proof of Theorem 3, except we
have a better guarantee on the starting cost. We will use the following upper bound on the total
influence of monotone decision trees, due to O’Donnell and Servedio [OS07]:
16

Theorem 13 ([OS07]). Let f be a size-s monotone decision tree. Then Inf(f ) ≤

√

log s.

Theorem 5 (Upper bound for approximate representation of monotone functions.). For every
ε∈
√
(0, 12 ) and every size-s monotone decision tree f , we have TopDownDTSize(f, ε) ≤ sO( log s/ε) .
Proof. We use Cj to refer to costf (T ◦ ) after j steps of BuildTopDownDT. By combining Lemma 5.2
and Lemma 5.1, we know that
Cj+1 ≤ Cj −

ε
.
(j + 1) log s

At any step k,
C0 − Ck ≥

k−1
X
j=0

ε · log k
ε
≥
.
(j + 1) log s
log s

Since f is a monotone √
decision tree of size s, it has total influence at most
This means that C0 ≤ log s. We choose
√

k = exp(log(s)1.5 /ε) = s

√

log s (Theorem 13).

log s/ε

at which point, Ck ≤ 0 ≤ ε, so BuildTopDownDTreturns a tree of size k + 1.

6
6.1

Lower bounds on TopDownDTSize for general functions: Proof
of Theorem 4
Size separation for exact representation: Proof of Theorem 4(a)

We begin with a simple family of functions {fh }h∈N whose BuildTopDownDT tree has exponential size compared to the optimal tree. Each fh is a function over 3h + 1 boolean variables
(1) (1)
(h) (h)
x1 , x2 , . . . , x1 , x2 , y (1) , . . . , y (h) , z, and is defined inductively as follows:
f0 (z) = z,
and for h ≥ 1,

(
(h)
(h)
y (h)
if x1 ∨ x2
fh (x, y, z) =
fh−1 (x, y, z) otherwise.
(h)

(h)

(h)

(h)

The structure of BuildTopDownDT(fh ). We see that y (h) has influence 43 , both x1 and x2
have influence 41 , and each variable in fh−1 has influence < 14 . BuildTopDownDT(fh ) therefore
queries yk at the root. In the restrictions of fh obtained by setting y (h) to a constant, x1 and x2
h)
(h)
have equal influence of 41 and each variable in fh−1 has influence < 41 . By setting either x1 or x2
to a constant, we get a subfunction where the other x(h) -variable has influence 21 and each node in
fh−1 has influence < 12 . Thus, BuildTopDownDT(fh ) builds the tree Th depicted in Figure 3.
We see that each Th contains two copies of Th−1 . It follows that the optimal size of fh is O(h),
whereas the size of Th is 2Ω(h) : a size separation of TopDownDTSize(fh ) = 2Ω(s) where s denotes
the optimal size of fh .
17

fh =





















































(h)
x1

1

0

(h)

y (h)
0
−1

x2

1

0

1

y (h)

1

0
−1

Th =




























y (h)
0
(h)

1
1

(h)

x1

x1

1

0



























fh−1

1

(h)

−1

−1

(h)

−1

x2
0

1

0

x2

1
Th−1

0
1

1
Th−1

Figure 3: Diagrams exhibiting a function with exponential difference between the optimal decision tree size and TopDownDTSize. The left diagram shows how to compute
fh with a decision tree of size O(h). The right diagram shows Th , the tree BuildTopDownDT builds, which has size 2Ω(h) .

6.2

Size separation for approximate representation: Proof of Theorem 4(b)

Warmup/intuition: An s versus sΩ(log(1/ε)) separation. Before proving Theorem 4(b), we
first give a brief, informal description of how a simple modification to the family of functions
{fh }h∈N in Theorem 4(a) above yields a separation of TopDownDTSize(f, ε) = sΩ(log(1/ε)) for
approximate representation. Theorem 4(b)—which improves this to a superpolynomial separation
even for constant ε—builds on these ideas, but the family of functions and the proof of the lower
bound are significantly more involved.
Consider replacing each y (h) variable in the definition of fh with the parity of k variables
(h)
(h)
y1 ⊕ · · · ⊕ yk , i.e. consider the following variant f˜h of fh :
(
(h)
(h)
(h)
(h)
y1 ⊕ · · · ⊕ yk
if x1 ∨ x2
˜
fh (x, y, z) =
f˜h−1 (x, y, z)
otherwise.
(h)

Just like the single y (h) variable in fh , we see that the k many yi variables are the most influential
(h)
in f˜h (each having influence 43 ). Furthermore, each yi variable remains the most influential
(h)

even under any restriction to any number of the other yj variables. Therefore the tree T̃h that
BuildTopDownDT builds for f˜h first queries all k many y (h) variables. At each of the 2k resulting
(h)
(h)
leaves, x1 and x2 are then queried, followed by a copy of T̃h−1 , the tree that BuildTopDownDT
(h)
(h)
recursively constructs for f˜h , in the branch corresponding to x1 = x2 = 1. The fact that there
are 2k copies of T̃h−1 within T̃h should be contrasted with the fact that the tree Th in Theorem 4(a)
contains just two copies of Th−1 ; recall Figure 3.
18

It is straightforward to see that there is a tree of size O(h · 2k ) that computes f˜h . This tree
is built by first querying the x(h) variables before the y (h) variables, and recursing on just one of
the Ω(2k ) many resulting leaves. On the other hand, by first querying the y (h) variables followed
by the x(h) variables, BuildTopDownDT recurses on Ω(2k ) many branches while only correctly
classifying a 43 fraction of inputs. Choosing h = Θ(log(1/ε)), we get a separation of O(h · 2k ) versus
2Ω(kh) , or equivalently, s versus sΩ(log(1/ε)) .
6.2.1

Proof of Theorem 4(b)

Before defining the family of functions witnessing the separation, we define a couple of basic boolean
functions and state a few of their properties that will be useful for our analyses:
Definition 14 (Tribes). For any input length r, let w be the largest integer such that (1 −
2−w )r/w ≤ 12 . The Tribesr : {0, 1}r → {±1} function is defined to be the function computed by
the read-once DNF with b wr c terms (over disjoint sets of variables) of width exactly w:
Tribesr (z) = (z1,1 ∧ · · · ∧ z1,w ) ∨ · · · ∨ (zt,1 ∧ · · · ∧ zt,w )

where t := b wr c,

and where we adopt the convention that −1 represents logical False and 1 represents logical True.
The following facts about the Tribes function are standard (see Chapter §4.2 of [O’D14]) and
can be easily verified:
Fact 6.1 (Properties of Tribesr ).
◦ Pr[Tribesr (z) = 1] =

1
2

−O

log r 
.
r

◦ Inf(Tribesr ) = (1 ± o(1)) · ln r and consequently, Inf i (Tribesr ) = (1 ± o(1)) ·
i ∈ [n].

ln r
r

for all

◦ w = log r − log ln r ± O(1).
◦ size(Tribesr ) ≤ wO(r/w) = 2O(r log log r/ log r) .
Definition 15 (Threshold). For any input length ` and t ∈ {0, 1, . . . , `}, the Threshold`,t :
{0, 1}` → {±1} function is defined to be
Threshold`,t (x) = 1 ⇐⇒

`
X
i=1

xi ≤ t.

Defining the family of functions witnessing the separation. Consider the following family
of functions {fh }h∈N . Each fh is a function over h(` + k) + r boolean variables x(1) , x(2) , . . . , x(h) ∈
{0, 1}` ,y (1) , . . . , y (h) ∈ {0, 1}k , and z ∈ {0, 1}r , and is defined inductively as follows:
f0 (z) = Tribesr (z),
and for h ≥ 1,

(
Parityk (y (h) ) if Threshold`,1 (x(h) ) = 1
fh (x, y, z) =
fh−1 (x, y, z)
otherwise.
19

Claim 6.2 (Optimal decision tree size of fh ).
size(fh ) ≤ `O(h) · (size(Parityk ) + size(Tribesr ))
≤ `O(h) · (2k + 2O(r log log r/ log r) ).

Thr`,1 (x(h) )

O(`) paths
O(`2 ) paths

Park (y (h) )

O(2k ) paths
−1

fh−1

O(2k ) paths
1

Figure 4: A small decision tree for fh .
Proof. Please refer to figure Figure 4. We first build a tree of size O(`2 ) that evaluates Threshold`,1 (x(h) ).
Of these leaves, ` + 1 descend into a tree computing Parityk (y (h) ), which has size 2k . The others
descend into a tree computing fh−1 . This yields the recurrence
size(fh ) ≤ O(`) · size(Parityk ) + O(`2 ) · size(fh−1 )
≤ O(` · 2k ) + O(`2 ) · size(fh−1 )

size(f0 ) = size(Tribesr ) ≤ 2O(r log log r/ log r) ,

(Recall Fact 6.1)

and the claim follows.
The remainder of this section will be devoted to proving a lower bound on TopDownDTSize(f, ε).
Figure 5 should be contrasted with Figure 4.
20

Park (y (1) )

O(2k ) paths

O(2k ) paths

Thr`,1 (x(1) )

O(`) paths

Thr`,1 (x(1) )

O(`2 ) paths

−1

O(`) paths

T0

O(`2 ) paths

1

T0

Figure 5: The tree T1 that BuildTopDownDT builds for f1 . Since y (1) has all the most
influential variables, BuildTopDownDT puts them all at the root. As a result, it ends
up building a significantly larger tree than optimal (cf. Figure 4). Notice that the size of
T1 is Ω(2k ) times as large as T0 . This leads to exponential growth of the tree size as a
function of h.
The structure of BuildTopDownDT(fh ) The following helper lemma will be useful in determining the structure of the tree BuildTopDownDT produces.
Lemma 6.3 (Preservation of influence order). Let f : {0, 1}S × {0, 1}S → {±1} and f˜ : {0, 1}S →
{±1} be two functions satisfying the following: there is a function g : {0, 1}S × {±1} → {±1} such
that:
f (a, b) = g(a, f˜(b)) for all a ∈ {0, 1}S , b ∈ {0, 1}S .
Then for all variables v1 , v2 ∈ S,
Inf v1 (f˜) ≥ Inf v2 (f˜)

if and only if

21

Inf v1 (f ) ≥ Inf v2 (f ).

Proof. This holds by noting that for v ∈ {v1 , v2 },

Inf v (f ) = Pr[f (a, b) 6= f (a, b⊕v )]
a,b

= Pr[g(a, f˜(b)) 6= g(a, f˜(b⊕v ))]
a,b

= Pr[f˜(b) 6= f˜(b⊕v )] · Pr[g(a, −1) 6= g(a, 1)]
a

b

= Inf v (f˜) · Pr[g(a, −1) 6= g(a, 1)].
a

The lemma follows since Pr[g(a, −1) 6= g(a, 1)] does not depend on v (and hence is the same
a

regardless of whether v = v1 or v = v2 ).

Lemma 6.3 is especially well-suited for our inductively-defined family of functions {fh }h∈N . For
each i ∈ {0, 1, . . . , h}, we let Si denote the relevant variables of fi . Therefore
S0 = {z1 , . . . , zr }
(i)

(i)

(i)

(i)

Si+1 = Si t {x1 , . . . , x` , y1 , . . . , yk }
Observation 16. For all i ∈ {0, 1, . . . , h}, there exists gi such that
fh (a, b) = gi (a, hi (b))

for all a ∈ {0, 1}Sh \Si and b ∈ {0, 1}Si .

(3)

Consequently, we may apply Lemma 6.3 to get that for all v1 , v2 ∈ Si , we have that
Inf v1 (fi ) ≥ Inf v2 (fi )

if and only if

Inf v1 (fh ) ≥ Inf v2 (fh ).

We note the following corollary, which is a straightforward consequence of the observation that
the property (3) is preserved under restrictions:
Corollary 6.4 (Preservation of influence order under restrictions). Let π be any restriction. For
all i ∈ {0, 1, . . . , h}, we have that
Inf v1 ((fi )π ) ≥ Inf v2 ((fi )π )

if and only if

Inf v1 ((fh )π ) ≥ Inf v2 ((fh )π ).

Lower bounding the size of BuildTopDownDT(f, ε). Let Texact denote the tree returned
by BuildTopDownDT(fh ), and Tapprox denote the tree returned by BuildTopDownDT(fh , ε).
(So Texact computes fh , and Tapprox is an ε-approximation of fh .) Our goal is to lower bound the
size of Tapprox . We will in fact establish something stronger: our lower bound holds forany pruning
of Texact that is an ε-approximation of Texact , where a pruning of a tree T is any tree obtained
by iteratively removing leaves from T in a bottom-up fashion. Since BuildTopDownDT(f, ε)
is simply BuildTopDownDT(fh ) terminated early, we have that Tapprox is indeed a pruning of
Texact .
Let Vexact be defined as follows:
Vexact := {v : v is the first node in a path of Texact that queries a z-variable}.
We define Vapprox ⊆ Vexact analogously. At a very high level, our proof of Theorem 4(b) will proceed
by showing that Vexact has large size, and Vapprox has to contain many nodes in Vexact . For the
remainder of this proof, we will need that r and ` are chosen to satisfy:
2 ln r
< 2−` .
r
22

(4)

Lemma 6.5 (All nodes in Vexact occur deep within Texact ). Fix v ∈ Vexact and let π denote the path
in Texact that leads to v. Then |π| ≥ kh.
(i)

Proof. Suppose without loss of generality that v is a query to z1 . We claim that yj ∈ π for all
i ∈ [h] and j ∈ [k], from which the lemma follows. Fix i ∈ [h]. We will prove there are at least k
(i)
queries to variables in Si within π, and that the first k of these queries have to be yj for j ∈ [k].
We prove both these claims simultaneously by induction on k.
◦ (Base case.) Seeking a contradiction, suppose π does not contain any queries to variables in
Si , in which case (fi )π ≡ fi . Since z1 is the variable queried at the root of (fh )π , it is the
most influential variable within (fh )π . By Corollary 6.4, it follows that z is the most influential
variable within (fi )π ≡ fi . This contradicts Equation (4) since
Inf y(i) (fi ) =
1

`+1
2`

and

Inf z1 (fi ) < Inf z1 (Tribesr ) = (1 ± o(1)) ·

ln r
.
r

Therefore π has to contain at least one variable in Si . Let u ∈ π be the first query to a variable
(i)
in Si , which we claim must be yj for some j. Let πu ⊂ π be the path in Texact that leads
to u. Again, we have that u must be the most influential variable within (fh )πu , and hence,
by Corollary 6.4, it is the most influential within (fi )πu . Since πu does not contain any queries
(i)
to variables in Si , we have that (fi )πu ≡ fi , and hence u must be yj for some j since these are
the most influential variables within fi .
◦ (Inductive step.) Fix k 0 < k, and suppose we have established that there are at least k 0 queries
to variables in Si within π, the first k 0 of which are to y (i) -variables. We first claim that there
is at least one more query to variable in Si within π. Suppose not. It follows that z1 must be
the most influential variable within (fh )π , and hence, by Corollary 6.4, it is the most influential
variable within (fi )π . This is a contradiction, since z1 is less influential than any of the k − k 0
(i)
many yj variables that are not queried by π.
Therefore π has to contain at least one more query to a variable in Si . Let u ∈ π be the (k + 1)st
(i)
query to a variable in Si , which we claim must be yj for some j. Let πu ⊂ π be the path in
Texact that leads to u. Again, we have that u must be the most influential variable within (fh )πu ,
and hence, by Corollary 6.4, it is the most influential within (fi )πu . Since πu contains exactly
(i)
k 0 queries to variables Si , and all these queries are to y (i) variables, we have that u must be yj
for one of the remaining k − k 0 many y (i) -variables since these are the most influential variables
within (fi )πu .
This completes the inductive proof of Lemma 6.5.
Lemma 6.6. Fix v ∈ Vexact and let π denote that path in Texact that leads to v. Then (fh )π ≡
Tribesr .
Proof. Suppose (fh )π 6≡ Tribesr . Our proof of Lemma 6.5 shows that π contains every y-variable,
so it must be the case that some x-variable remains relevant (i.e. has nonzero influence) in (fh )π .
Let i∗ ≥ 1 be the highest value of i for which there is a relevant x(i) -variable in (fh )π . Assume
(i)
without loss of generality that x1 remains relevant, and that z1 is that z-variable that is queried
at v.
23

Since z1 is queried at the root of (fh )π , we have that it must be maximally influential in (fh )π ,
and in particular,
Inf z1 ((fh )π ) ≥ Inf x(i∗ ) ((fh )π ).
1

Applying Corollary 6.4, we infer that
Inf z1 ((fi∗ )π ) ≥ Inf x(i∗ ) ((fi∗ )π ).

(5)

1

Let us say that an input (x, y, z) to fi∗ is z-dependent if
Threshold`,1 (x(i) ) = 0

for all 1 ≤ i ≤ i∗ .

Note that the output of fi∗ on any z-dependent input is Tribesr (z). Since π contains every
∗
y-variable, it fixes Parityk (y (i ) ) to either −1 or 1; we assume without loss of generality that
∗
Parityk (y (i ) )π ≡ 1. We have that
Inf x(i∗ ) ((fi∗ )π ) ≥ Pr [(x, y, z) is z-dependent] · Pr[Tribesr (z) 6= 1]
1

z

(x,y,z)

× Inf x(i∗ ) Threshold`,1 (x

(i∗ )

)π



1
2

· 2−(`−1)

1

≥ Pr [(x, y, z) is z-dependent] ·
(x,y,z)

= Pr [(x, y, z) is z-dependent] · 2−` .
(x,y,z)

∗

The second inequality uses the fact that Inf x(i∗ ) (Threshold`,1 (x(i ) )π ) ≥ 2−(`−1) , which holds with
1

∗

equality when exactly one other x(i ) -variable is in π and that variable is set to 1.16
On the other hand, we have that
Inf z1 ((fi∗ )π ) ≤ Pr [(x, y, z) is z-dependent] · Inf z1 [Tribesr (z)]
(x,y,z)

< Pr [(x, y, z) is z-dependent] ·
(x,y,z)

2 ln r
.
r

(Fact 6.1)

r
These bounds on influences, along with Equation (5), imply that 2−` < 2 ln
r . This contradicts our
assumption on the relationship between ` and r (Equation (4)), and the proof is complete.

We are now ready to lower bound the size of Tapprox .
Claim 6.7 (Lower bound on the size of Tapprox ). Fix ε ∈ (0, 12 ) and let c = ( 12 − ε)/2. If


`+1
1− `
2

h
≥ (2 + c)ε,

then |Vapprox | ≥ Ω(ε · 2kh ). Consequently, the size of Tapprox is also at least Ω(ε · 2kh ).
16

(6)

In this derivation, we have assumed that Tribesr is perfectly balanced, i.e. that Pr[Tribesr (z) = 1] = 21 , when
in fact Pr[Tribesr (z) = 1] = 12 ± o(1) (recall Fact 6.1). The same proof goes through if one carries around the
additive o(1) factor.

24

Proof. An input to fh reaches some node in Vexact if and only if Threshold`,1 (x(i) ) = 0 for all
1 ≤ i ≤ h. The fraction of inputs that satisfies this is exactly (1 − `+1
)h , which is at least (2 + c)ε
2`
by our choice of parameters given by Equation (6).
Fix v ∈ Vexact . If v ∈
/ Vapprox , then Tapprox assigns all inputs reaching v the same −1 or +1 value,
whereas fh labels half of them −1 and half of them +1 (Lemma 6.6). Therefore, Tapprox errors on
half of the inputs that each v. On the other hand, if v ∈ Vapprox , we have by Lemma 6.5 that at
most a 2−kh fraction of inputs reach this specific v. Combining all of the above observations, it
follows that

error(Texact , Tapprox ) ≥ 21 (2 + c)ε − |Vapprox | · 2−kh .
Since error(Texact , Tapprox ) ≤ ε, it follows that
ε≥

1
2


(2 + c)ε − |Vapprox | · 2−kh ,

and the claim follows by rearranging.
Theorem 4(b) now follows from Claim 6.2 and Claim 6.7 by setting parameters appropriately:
Proof of Theorem 4(b). Choosing

 `
2
· log(1/ε)
h=Θ
`

(to satisfy Equation (6))

r = Θ(`2` )

(to satisfy Equation (4))

k = Θ(h log `),
we may apply Claim 6.2 and Claim 6.7 to get that
size(fh ) ≤ 2O(k log k)

whereas

TopDownDTSize(f, ε) ≥ 2Ωε (k

2 / log log k)

.

This is a separation of s versus sΩ̃(log s) .
√

Remark 17. For our choice of parameters above, we have that s(n) = size(fh ) = 2Θ̃( n) , where
n = h(` + k) + r is the number of variables of fh . A standard
padding argument yields the same s
√
Ω̃(log
s)
Õ(
n)
versus s
separation for any function s(n) ≤ 2
.

7
7.1

Lower bounds on TopDownDTSize for monotone functions: Proof
of Theorem 6
Size separation for exact representation: Proof of Theorem 6(a)

We will give a family of monotone functions, {fh }h∈N whose BuildTopDownDT tree has exponential size compared to the optimal tree. First, we define a few terms which will be useful for our
monotone constructions.
Definition 18 (Comparing vectors and upper/lower shadows). For any x, y ∈ {0, 1}n , we use x  y
to represent
x  y ⇐⇒ xi ≤ yi for all i ∈ [n]

and  is defined similarly. For any vector x, the upper shadow of x is the set of all vectors y such
that x  y. Similarly, the lower shadow of x is the set of all vectors y such that x  y.
25

y (h)
0

−1

1

x(h)

x(h)

12 paths 1 path 3 paths

3 paths 1 path 12 paths

Th−1

−1

1

Th−1

1

Figure 6: The tree that BuildTopDownDT builds for fh . It will first query y (h) , followed
by the variables of x(h) . For most choices of y (h) and x(h) , the function is determined,
and BuildTopDownDT will place a constant leaf equal to ±1. However, the paths with
y = 0, x(h) = x∗ and y = 1, x(h) = x∗ each include a copy of the tree for Th−1 .
Defining the family of functions witnessing the separation. Each fh in {fh }h∈N is a function
over 5h + 1 boolean variables x(1) , x(2) , . . . , x(h) ∈ {0, 1}4 , y (1) , . . . , y (h) ∈ {0, 1}, and z ∈ {0, 1}, and
is defined inductively as follows:
f0 (z) = z,
and for h ≥ 1, we fix x∗ := (0, 0, 1, 1) and define


fh−1 (x, y, z) if x(h) = x∗



+1
if x(h)  x∗ and x(h) =
6 x∗
fh (x, y, z) =

−1
if x(h)  x∗ and x(h) =
6 x∗



y
otherwise.
It is straightforward to verify that fh is indeed monotone. We will show that fh can be computed
by a tree of size O(h), but that BuildTopDownDT produces a tree of size 2Ω(h) . For the first
claim, we construct a decision tree for fh directly from its definition. We start with a complete
tree on the x(h) variables—this complete tree has size 24 , a constant. At one of the branches, we
recursively build a tree for fh−1 ; at all the other branches, we build a tree of size 1 or 2 computing
one of −1, 1, or y (h) . The result is a tree of size O(h).
On the other hand, we claim that BuildTopDownDT will build a tree of size 2Ω(h) , as depicted
9
in Figure 6. In fh , y (h) has influence 16
and all the other variables have influence at most 12 . Hence,
y (h) will be placed at root. Then, BuildTopDownDT will query enough of x(h) to determine
whether the output should be −1, +1, or fh−1 . If the output should be fh−1 , which will occur once
for each choice of y, then the entire tree Th−1 will be placed. Hence, the size of Th is more than
double the size of Th−1 , and BuildTopDownDT builds a tree of size 2Ω(h) .

26

7.2

Size separation for approximate representation: Theorem 6(b)

For any ε, we will prove there exists a function
f with optimal tree size s but for which the tree
√
4
Ω̃(
log
s) . The following function, a biased version of
BuildTopDownDT(f, ε) builds has size s
the Tribes function defined in Definition 14, will be used as a building block in our monotone
construction.
Definition 19 (Biased Tribes). Fix any input length ` and δ ∈ (0, 1). We define Tribes`,δ :
{0, 1}` → {±1} to be the read-once DNF with b w` c terms of width exactly w over disjoint sets of
variables (with some variables possibly left unused), where w = w(`, δ) ≈ log(`) ± log log(1/δ) is
chosen such that Pr[Tribes`,δ (x) = 1] is as close to δ as possible.17
Fact 7.1 (Variable influences in biased Tribes). All variables in Tribes`,δ and Tribes`,1−δ have
influence at most
log `
(2 + o(1)) · δ log(1/δ) ·
.
`
Proof. We prove the lemma for the case of Tribes`,1−δ . (The calculations for Tribes`,δ are very
similar, and both claims are special cases of more general facts about variable influences in DNF
formulas [ST13].) Suppose
Tribes`,1−δ (x) = T1 (x) ∨ · · · T ` (x),
w

where the Ti ’s are disjoint terms of width exactly w. We first observe that since
δ=

Pr

x∼{0,1}n

[Tribes`,1−δ (x) = 1] = Pr[ all Ti (x) are falsified by x ]
w

= (1 − 2−w )`/w ≈ e−`/w2 ,
we have that w = (1 ± o(1))(log ` − log log ` − log log(1/δ)). The influence of any variable i ∈ [n] on
Tribes`,1−δ is the probability, over a uniform x that each other variable j in i’s term has xj = 1
and all other clauses evaluate to 0 under x:
Inf i (Tribes`,1−δ ) = 2−(w−1) · (1 − 2−w )(`/w)−1
≤ 2δ · 2−w

= (1 ± o(1)) · 2δ log(1/δ) ·

log `
.
`

Defining the family of functions witnessing the separation. Each fh in the family {fh }h∈N is
a function over h(2`+k)+r boolean variables x(1,1) , x(1,2) , . . . , x(h,1) , x(h,2) ∈ {0, 1}` , y (1) , . . . , y (h) ∈
{0, 1}k , and z ∈ {0, 1}r , and is defined inductively as follows:
f0 (z) = Tribesr (z),
17

Although the acceptance probability of Tribes`,δ cannot be made exactly δ due to granularity issues, it will
be the case that Tribes`,δ = δ ± o(1). For clarity, we will assume for the rest of this paper that the acceptance
probability of Tribesδ is exactly δ, noting that all of our proofs still go through if one carries around the o(1) factor.

27

Tribes` (x(h,1) )
Tribes` (x(h,2) )

O(2` ) paths
O(2` ) paths

−1

O(2` ) paths

O(2` ) paths

Majk (y (h) )

fh−1

O(2k ) paths
−1

1

O(2k ) paths
1

Figure 7: A small decision tree that computes fh
and for h ≥ 1,


−1
if Tribes`,δ (x(h,1) ) = Tribes`,1−δ (x(h,2) ) = 0



f (x, y, z) if Tribes (x(h,1) ) = 0 and Tribes
(h,2) ) = 1
h−1
`,δ
`,1−δ (x
fh (x, y, z) =

Majk (y (h) ) if Tribes`,δ (x(h,1) ) = 1 and Tribes`,1−δ (x(h,2) ) = 0



+1
otherwise.
Clearly fh is monotone in x(h,1) and x(h,2) . Furthermore, since each of the functions −1, +1, and
Majk (y (h) ), are monotone, if fh−1 is monotone then so is fh .
Claim 7.2 (Optimal size of fh ). Choose any integers `, h, r, k > 0 and let Then, fh,`,k,r has optimal
decision tree size
size(fh ) ≤ (size(Tribes`,δ ) · size(Tribes`,1−δ ))O(h) · (size(Majk ) + size(Tribesr ))
≤ 2O(h·` log log `/ log `) · (2k + 2O(r log log r/ log r) ).
28

(Fact 6.1)

Proof. As in the proofs of the previous separations, this upper bound is witnessed by the natural decision tree that one builds by following the definition of fh . This tree first evaluates Tribes`,δ (x(h,1) )
followed by Tribes`,1−δ (x(h,2) ), resulting in a tree of size (size(Tribes`,δ ) · size(Tribes`,1−δ )). At
the end of each branch, we either recursively build a tree for fh−1 , or a tree for Majk (y (h) ), or
place constants {±1} as leaves. Please refer to Figure 7.
The remainder of this section is devoted to lower bounding TopDownDTSize(fh , ε), the size
of the tree Tapprox that BuildTopDownDT constructs to ε-approximate fh .
7.2.1

“Mostly precedes”

By choosing parameters appropriately, we will ensure that when Tapprox begins by querying the variables of Majk (y (h) ). The first technical challenge that arises is the following: unlike Parityk (y (h) )
in our proof of Theorem 4(b), the influence of variables in Majk (y (h) ) changes as variables are
queried. For example, the influence of the remaining variables of Majk (y (h) ) after k2 variables have
been queried is 0 if all of the queried variables are 1 and is Θ( √1k ) if half of the variables queries
are 0 and half are 1. Hence, in Tapprox , the number of nodes from y (h) queried before some nony (h) -variable is queried will vary by path. (In other words, the analogue of Lemma 6.5 in the proof
of Theorem 4(b) is somewhat trickier to establish.)
To handle this, we define the following notion, which will allow us to show that most y (h) variables are before other variables in most paths of the tree (Corollary 7.5).
Definition 20 (Mostly precedes). Let S be a subset of the relevant variables of fh . We say that
y (i) -variables mostly precede S in Tapprox if for every path π in Tapprox leading to a first query to a
variable in S, and every j ∈ [k],

Inf j Majk (y (i) )π ≤

1
√ .
100 k

(For some intuition behind Definition 20, we note that pre-restriction, the influences of variables
in Majk are given by:
  p
2/π
1
k
Inf j (Majk ) = · k ∼ √
for all j ∈ [k],
k
k
2
which is significantly larger than the 1001√k of Definition 20.) With Definition 20 in hand, we now
begin to formalize the structure of Tapprox as depicted in Figure 8. For each i ∈ [h], we define
Ri = {x(i,1) , x(i,2) , and z variables}.
Lemma 7.3. There is a universal constant c such that the following holds. Suppose


c
1
δ log(1/δ) log ` log r
√ ≥ 2 · max
,
.
δ
`
r
k
Then for all i ∈ [h], we have that y (i) -variables mostly precede Ri in Tapprox .

29

(7)

Majk (y (h) )

2Ω(k/ log(k)) paths

Tribes` (x(h,1) )
Tribes` (x(h,2) )

O(2` ) paths
−1

O(2` ) paths
Th−1

O(2` ) paths
1

Figure 8: With appropriately chosen parameters, the y (h) -variables are the most influential in fh , so the tree built by BuildTopDownDT will query them first. Our analysis
shows that this leads to a tree of size 2Ω(kh/ log k) (cf. Figure 7).
Proof. Fix i ∈ [h]. Let π be a path in Tapprox that leads to a first query to a variable in v ∈ Ri . Since
v is maximally influential in (fh )π , we may apply Corollary 6.4 to infer that v is also maximally
influential in (fi )π (and in particular, v is more influential than any y (i) variable). We have that

Inf v ((fi )π ) ≤ max Inf j (Tribes`,δ (x(i,1) )), Inf j (Tribes`,1−δ (x(i,2) )), Inf j (Tribesr (z))


log `
ln r
≤ max (2 + o(1)) · δ log(1/δ) ·
, (1 + o(1)) ·
.
(Fact 6.1 and Fact 7.1)
`
r
On the other hand, for any j ∈ [k],



Inf y(i) ((fi )π ) = Pr Tribes`,δ (x(h,1) ) = 1 and Tribes`,1−δ (x(h,2) ) = 0 · Inf j Majk (y (i) )π
j

= δ 2 · Inf j Majk (y (i) )π .
30

Since Inf y(i) ((fi )π ) ≤ Inf v ((fi )π ), the bounds above imply that
j

(i)

Inf j Majk (y )π





log `
1
ln r
.
≤ 2 · max (2 + o(1)) · δ log(1/δ) ·
, (1 + o(1)) ·
δ
`
r

The lemma follows: by choosing c to be a sufficiently small constant in Equation (7), we can ensure
that Inf j Majk (y (i) )π ≤ 1001√k .
Lemma 7.4. There is a universal constant c such that the following holds. Fix i ∈ [h] and
consider a uniform random y (i) ∈ {0, 1}k . The probability there is an input u to fh consistent with
y (i) such that Tapprox , on input u, queries an Ri -variable before a querying at least ck/ log k many
y (i) -variables is O(k −2 ).
Proof. Fix an outcome y (i) of y (i) . Suppose that there is an input u consistent with y (i) such that
Tapprox , on input u, queries an Ri -variable after querying only < ck/ log k many y (i) -variables. Call
such a y (i) outcome bad, and let π denote the corresponding path in Tapprox that leads to the first
query to an Ri -variable. Since y (i) -variables mostly precede Ri in Tapprox , we have that

Inf j Majk (y (i) )π ≤

1
√
100 k

for all j ∈ [k].

For this to hold, it must be the case that among the t < ck/√log k many y (i) -variables that occur in
π, the discrepancy between the number of 0’s and 1’s is Ω( k). We can therefore bound
ck/ log k

Pr

y (i) ∈{0,1}k

[y

(i)

is bad] ≤

X

Pr



b∼Bin(t, 21 )

t=1

√ 
|b − 2t | ≥ Ω( k)

ck/ log k

≤

X

e−Θ(k/t)

(Hoeffding’s inequality)

t=1

1
ck
· e−Θ((log k)/c)  2 ,
≤
log k
k
where the final inequality holds by choosing c to be a sufficiently small constant.
By a union bound over i ∈ [h], we have the following corollary of Lemma 7.4 (which can be
thought of as being roughly analogous to Lemma 6.5 in the proof of Theorem 4(b)):
Corollary 7.5 (Most queries to z-variables are deep within Tapprox ). Let y = (y (1) , . . . , y (k) ) be
uniform random. The probability that there is an input u to fh consistent with y such that Tapprox ,
on input u, queries a z-variable before querying at least (ck/ log k) · h many y-variables is O(h/k 2 ).
We are finally ready to lower bound the size of Tapprox :
Claim 7.6 (Lower bound on the size of Tapprox ). Fix ε ∈ (0, 21 ) and let c = ( 12 − ε)/2. If
(1 − δ)2h ≥ (2 + c)ε
h ≤ k,

then the size of Tapprox is at least 2Ω(hk/ log k) .
31

(8)
(9)

Proof. We will call an input to fh z-dependent if it satisfies:
Tribes`,δ (x(i,1) ) = 0 and Tribes`,1−δ (x(i,2) ) = 1 for all i ∈ [h].
Note that the output of fh on any z-dependent input is Tribesr (z). Let us define ζ(y (1) , . . . , y (h) )
to be the {0, 1}-valued indicator of whether there is an input u consistent with y (1) , . . . , y (h) such
that Tapprox on input u queries a z-variable. For any fixed y = (y (1) , . . . , y (h) ),
◦ If ζ(y) = 0, then Tapprox must assign the same −1 or +1 value to all z-dependent inputs
consistent with y;
◦ The fraction of z-dependent inputs that are consistent with y is


Pr Tribes`,δ (x(i,1) ) = 0 and Tribes`,1−δ (x(i,2) ) = 1 for all i ∈ [h] = (1 − δ)2h ,
which is at least (2+c)ε by Equation (8). Furthermore, since output of fh on any z-dependent
input is Tribesr (z), among the z-dependent inputs that are consistent with y, we have that
fh labels half of them −1 and half of them +1.
Therefore,
error(Tapprox , fh ) ≥

1
2

· (2 + c)ε · Pr[ζ(y) = 0].

Since error(Tapprox , fh ) ≤ ε, it follows that Pr[ζ(y) = 1] ≥ Ω(1). Next, applying Corollary 7.5 along
with our assumption that h ≤ k (Equation (9)), we further have that
h
i
ck
· h many y-variables ≥ Ω(1).
Pr ∃ y-consistent u s.t. Tapprox (u) queries z-variable after ≥
y
log k
On the other hand, for any fixed path π in Tapprox that queries ≥ Ω(kh/ log k) many y-variables,
at most a 2−Ω(kh/ log k) fraction of y’s can be consistent with this specific π. We conclude that the
size of Tapprox must be at least 2Ω(kh/ log k) , and the proof is complete.
Theorem 6(b) now follows from Claim 7.2 and Claim 7.6 by setting parameters appropriately:
Proof of Theorem 6(b). By choosing

p
3
(log `)4 log(1/ε)/`
p

k = Θ 3 `4 log(1/ε)2 /(log `)4
δ=Θ

r = Θ(k)


1
h=Θ
· log(1/ε) ,
δ
we satisfy Equations (7) to (9). We may therefore apply Claim 7.2 to get that the optimal size of
fh is upper bounded by:

 p
size(fh ) ≤ exp O( 3 `4 log(1/ε)2 /(log `)4 ) .
On the other hand, by Claim 7.6, we have that
 p

TopDownDTSize(fh , ε) ≥ 2Ω(kh/ log k) = exp Ω( 3 `5 log(1/ε)4 /(log `)11 ) .
√
4
This is a separation of s versus sΩ̃( log(s)) .
32

4/5

Remark 21. For our choice of parameters above, we have that s(n) = size(fh ) = 2Θ̃(n ) , where
n = h(2` + k)
+ r is the number of variables of fh . A standard padding argument yields the same
√
4
4/5
s versus sΩ̃( log s) separation for any function s(n) ≤ 2Õ(n ) .
Remark 22 (Depth separation). The same proof witnesses a separation of d versus Ω̃ε (d5/4 ) for
the optimal depth of fh versus the depth of the tree that BuildTopDownDT(fh , ε) builds. This
disproves the conjecture of Fiat and Pechyony [FP04] discussed in Section 2, which states that
BuildTopDownDT builds a tree of optimal depth for all monotone functions, even in the case of
exact representation (ε = 0).

7.3

Lower bounds for all impurity-based heuristics

Proposition 7.7 (Splitting on the most influential variable of a monotone function maximizes
purity gain). Let f : {±1}n → {±1} be a monotone boolean function.18 Let G : [−1, 1] → [0, 1]
be a concave function that is symmetric around 0, and satisfies G (−1) = G (1) = 0 and G (0) = 1.
Suppose i ∈ [n] maximizes:
G (E[f ]) − 12 (G (E[fxi =−1 ]) + G (E[fxi =1 ])),

(10)

Then E[f (x)xi ] ≥ E[f (x)xj ] for all j ∈ [n].
Proof. For all functions f , not necessarily monotone, E[f ] is precisely the average of E[fxi =0 ] and
E[fxi =1 ]. Because G is concave everywhere on its domain, Jensen’s inequality ensures that G (E[f ])
is greater than 12 (G (E[fxi =0 ]) + G (E[fxi =1 ]). Furthermore, again by concavity, we have that this
difference increases with the difference between E[fxi =1 ] and E[fxi =−1 ]. Therefore the variable
i ∈ [n] that maximizes purity gain (10) also maximizes | E[fxi =1 ] − E[fxi =−1 ]|.
For a monotone function f : {±1}n → {±1}, we have the following identity for all variables
j ∈ [n]:
Inf j (f ) = Pr[f (x) 6= f (x⊕j )]
= E[f (x)xj ]

= E[fxj =1 ] − E[fxj =−1 ].
Thus, the variable that maximizes purity gain (10) is also the most influential variable of f .
Recall that in Theorem 7, we claimed that our lower bound on TopDownDTSize(fh , ε) holds
not just for the specific algorithm BuildTopDownDT, but in fact any impurity-based top-down
heuristic. To see this, note that in our proof of Theorem 6(b) described in Section 7.2, we never used
any information about which leaf BuildTopDownDT chooses to split on at each stage, only that
when a leaf is split, it is replaced by the most influential variable of the corresponding subfunction.
In other words, just like our proof of Theorem 4(b), our proof of Theorem 6(b) applies not just
to the specific tree build by BuildTopDownDT(fh , ε); it in fact lower bounds the size of any
pruning Tapprox of Texact = BuildTopDownDT(f, ε = 0) that is an ε-approximator to fh .
By Proposition 7.7, any tree build by a impurity-based top-down heuristic is a pruning of Texact ,
and hence our proof of Theorem 6(b) extends to establish Theorem 7.
18

For this proof, for notational reasons it will be slightly more convenient for us to work with {±1}n instead of
{0, 1}n as the domain of f .

33

8

New proper learning algorithms: Proofs of Theorem 8 and Theorem 9

Recall that BuildTopDownDT builds an approximation to f iteratively. It starts with an empty
bare tree T ◦ and repeatedly replaces the leaf with the highest score with a query to that leaf’s
most influential variable. In section Section 5.2, we proved lower bounds on the score of the leaf
that BuildTopDownDT selects. Using those lower bounds, in section Section 5.3, we are able
to prove upper bounds on the size of the tree BuildTopDownDT needs to produce to guarantee
at most ε error. If, instead, we only guaranteed that we would pick a leaf with score a fourth of
that guaranteed by the lower bounds in Section 5.2, all of our upper bounds would still hold, up
to constant factors in the exponent. In this section, we will show that it is possible to accurately
enough estimate influences to guarantee we pick a leaf with score at least a fourth the maximum
score. First, we provide a definition of score that takes into account both the leaf and the variable
selected.
Definition 23 (score). Given any function f , we define the score of a leaf ` and variable i as
follows.
score(`, i) :=

Pr

x∼{0,1}n

[ x reaches ` ] · Inf i (f` ) = 2−|`| · Inf i (f` ).

We first show that it is possible to estimate scores sufficiently accurately for monotone functions
just from random samples of a function, which proves Theorem 9. Let S be a random sample from
a monotone function f , and recall Fact 2.1. We can estimate the score of a particular leaf and
variable as follows.


score(`, i, S) = E 1[x reaches `] · f (x)(2xi − 1) .
x,y∈S

Note that ES [score(`, i, S))] = score(`, i). Let t be any score threshold and m be the number of
examples in S. By Chernoff bounds, for any particular leaf ` and variable xi ,


1
Pr score(`, i, S) ≤ 2t ≤ e− 8 t·m if score(`, i) ≥ t
S


1
Pr score(`, i, S) ≥ 2t ≤ e− 12 t·m if score(`, i) ≤ t/4.
S

At step j in BuildTopDownDT, there are j +1 leaves in T ◦ . If t is the maximum score possible at
1
that step, with probability at least 1−(j +1)e− 12 t·m , the leaf and variable with maximum empirical
score will have true score at least 4t . By Lemma 5.2, BuildTopDownDT(f, ε), at step j, there
will always be a leaf with score at least (j+1)εlog(s) , where s is the decision tree size of f . Hence,
the maximum empirical score will have true score at least 14 the optimal value with probability at
−

ε·m

least 1 − (j + 1)e 12(j+1) log(s) .
The probability that selecting the maximum empirical score is always within
− 12kε·m
log(s)

value for every step from j = 0 to j = k − 1 is at least 1 − k 2 e
to


k log s
m=O
(log k + log(1/δ))
ε

34

1
4

of the optimal

. By setting the sample size
(11)

with probability at least 1−δ, we choose a sufficiently good leaf for k steps of BuildTopDownDT.
Recall that, for monotone functions, BuildTopDownDT builds a decision tree of size at most
√

k = min(sO(log(s/ε) log(1/ε)) , sO(

log s/ε)

).
√

Hence, with probability at least 1 − δ, taking min(sO(log(s/ε) log(1/ε)) , sO( log s/ε) ) log(1/δ) is enough
to learn to accuracy ε. This proves Theorem 9.
If f is not monotone, we cannot accurately estimate influences from just random samples.
However, we can estimate influences if given access to random edges from f .
Definition 24 (Random edges). For any function f : {0, 1}n → {±1}, a random edge is two points
of the form ((x, f (x)), (x⊕i , f (x⊕i ))), where x ∈ {0, 1}n and i ∈ [n] are both picked uniformly at
random. A random edge sample E is a collection of random edges. Given random edge sample E,
we will use Ei to refer to all those edges in E in which the ith bit of x is flipped.
Given a random edge sample E of a function f , we will be able to accurately estimate influences
of the variables in f , and learn f using BuildTopDownDT. We use the following estimate of
score:


score(`, i, E) =
E
1[x1 and x2 reach `] · 1[y1 6= y2 ]
((x1 ,y1 ),(x2 ,y2 ))∈Ei

If we desire there to be m samples in each Ei with probability at least 1 − δ, then having E by
size O(n · (m + log( 1δ )) is sufficient, where m is as defined in Equation (11). Since one can certainly
general a random edge sample E if given membership query access to f , this proves Theorem 8.
Learning trees with small average depth: Theorem 10. Let f be a monotone function
computed by a decision tree T of average depth 4.
1. We first observe that the total influence of f is at most 4. To see this, first recall that
Inf(f ) = E[sensf (x)], where sensf (x) = |{i ∈ [n] : f (x) 6= f (x⊕i )}|, i.e. that total influence is
equivalent to average sensitivity. For any x, the sensitivity of f at x is at most the depth of
the path that x follows in T , and hence the average sensitivity of f is at most the average
depth 4 of T .
2. Recall Theorem 13,
√ which says that monotone functions with decision tree size s have total
influence at most log s. In fact,
√ [OS07] proves a stronger statement: if f is monotone, then
it has total influence at most 4. (This is indeed a stronger statement because 4 ≤ log s.)
3. Similarly, [OSSS05] also establishes a stronger version of Theorem 12, showing that f has a
variable of influence at least Var(f )/4 (rather than just Var(f )/ log s). Hence an equivalent
statement to Lemma 5.2 holds, where BuildTopDownDT selects a leaf with score at least
ε
(j+1)4 .
Combining these observations, with the same proof as for Theorem 5, we get that BuildTopDownDT
2
3/2
produces a tree of size 2O(4 /ε) , and if T is monotone, size only 2O(4 /ε) . Then, for the same
reasons as Theorems 8 and 9 hold, Theorem 10 holds.

35

9

Proper learning with polynomial sample and memory complexity

In this section we give a quasipolynomial-time algorithm for properly learning decision trees under
the uniform distribution, where sample and memory of our algorithm are both polynomial. To our
knowledge, this is the first algorithm for properly learning decision trees that achieves polynomial
memory complexity. (Recall Table 1.)
Background: Ehrehfeucht–Haussler and Mehta–Raghavan. At the core of most learning
algorithms is an algorithm that achieves low error on a set of samples. We will use the following
notation in this section:
Notation: A sample, S, is a set of examples of the form (x, y) where x ∈ {0, 1}n and y ∈ {−1, 1}.
The error of a decision tree, T , with respect to the samples is
errorS (T ) = Pr [T (x) 6= y].
x,y∈S

We say that a set of samples is exactly fit by a tree of size s if there exists a zero-error tree with
size at most s. Furthermore, we use S0v and S1v to refer to all the points in the sample S where the
variable corresponding to v is 0 and 1 respectively. Lastly, all learning statements in this section
are with respect to the uniform distribution.
Ehrenfeucht and Haussler’s algorithm makes the following guarantee:
Theorem 25 (Algorithmic core of [EH89]). There is an algorithm that takes in a set of samples,
S, over n variables that can be exactly fit by a decision tree of size s and returns a tree of size at
most nlog(s) that exactly fits S. Furthermore, that algorithm runs in time |S| · nO(log s) .
One downside of their algorithm is that it leads to a large hypothesis class—the class of all decision
trees of size nlog s —so in order to generalize with high probability, they require poly(nlog s , 1ε )
samples.
Mehta and Raghavan observe that if a function is computable by a tree of size s, then it is
also ε-approximated by a tree of depth at most log( sε ). They combine this observation with a new
algorithm that makes the following guarantee:
Theorem 26 (Algorithmic core of [MR02]). There is an algorithm that takes a sample, S, over n
variables as well as budgets for size s and depth d and returns the decision tree of size at most s and
depth at most d with minimal error on S.19 Furthermore, the algorithm runs in time nO(d) ·(s2 +|S|).
Importantly, there are only 2 · (4n)s decision trees of size at most s, a much smaller hypothesis
class than for Ehrenfeucht and Haussler’s algorithm. As a result, they only need poly(s, 1ε ) · log n
samples to generalize with high probability. A downside of their work, relative to Ehrenfeucht and
Haussler’s, is that they need to set d = O(log( sε )), so their algorithm has a runtime of approximately
nO(log(s/ε)) instead of nO(log s) .
Neither [EH89] nor [MR02] are able to learn decision trees with only poly(n, s, 1ε ) memory.
[EH89] uses a sample of size approximately nO(log s) to guarantee generalization, and their algorithm
19

They also guarantee that if their are multiple trees with minimal error, they return a tree with minimal size
among those with minimal error.

36

must store all of the samples, so it needs at least that much memory. [MR02] use a dynamic
programming algorithm that stores
for
 computation
 each restriction of the n variables of size at
n
most d = O(log( sε )). There are nd · 2d = Θ log(s/ε)
such restrictions, resulting in superpolynomial
memory complexity.
Our algorithm: proper learning with polynomial sample and memory complexity. We
introduce a new algorithm that makes more assumptions about its input than either [EH89]’s or
[MR02]’s algorithms. It requires the samples it receives to be well-distributed, a property we will
later define (Definition 28). In exchange, it only uses polynomial memory. The following should be
contrasted with Theorems 25 and 26:
Theorem 27 (Core of our algorithm). There is an algorithm (Figure 9) that when given a depth
budget d and a well-distributed sample S that can be exactly fit by a tree of size s returns a tree
with depth at most d and error at most ( 34 + o(1))d · s on the samples. Furthermore, the algorithm
runs in time |S| · nO(log s) and uses poly(2d , log n, |S|) memory.
Note that if the goal is to learn the sample to accuracy ε, we can set d = O(log( sε )). The result
is an algorithm that runs in time |S| · nO(log s) and uses memory poly(n, s, 1/ε, |S|). Furthermore,
the well-distributed requirement turns out to be true for nearly all uniformly random samples that
are sufficiently large. The result is, to the best of our knowledge, the first polynomial memory
proper learning algorithm for decision trees.
Our algorithm (Figure 9) is a surprisingly simple modification of [EH89]’s algorithm, but our
analysis is quite a bit more involved. A key difference is that [EH89]’s algorithm is an Occam
algorithm, whereas ours is not. The original [EH89] algorithm breaks down when in cannot fully
fit the sample; the analysis showing that our algorithm is able to handle a sample it cannot fully
fit is subtle.
Lemma 9.1 (Correctness of Find). If S can be exactly fit by a tree of size s, then Find(S, s, d)
will not return “None.”
Proof. By induction. If s = 1 and S can be fit by a tree of size s, then all samples in S will have
the same label. Hence, Find will return a tree on line 1, and not return “None”.
For s ≥ 2, there are only two spots where Find could return “None”:
Line 4.c.ii Find returns “None” on line 4.c.ii only if a call of the form Find(Sav , s − 1, d − 1)
returns “None” where a = ±1 and v is relevant. Let TS be a minimal size tree that fits S,
which by assumption, has size at most s. Since v is relevant, a node labeled with it must
appear somewhere in that tree. This means that there is a size s − 1 tree that will exactly fit
Sav . By induction, this means that Find(Sav , s − 1, d − 1) will not return “None.”
Line 5. Find returns “None” on line 5 only if there was not a single relevant variable v for
which either of the calls Find(S0v , 2s , d − 1) or Find(S1v , 2s , d − 1) on line 4.a succeeded (i.e. did
not return “None”). Once again, let TS be a minimal size tree that fits S. Then, every node
in TS must be relevant for S. Furthermore, TS has some root variable v ∗ and subtrees (TS )0
and (TS )1 . At least one of (TS )0 or (TS )1 must have size at most 2s . If (TS )0 has size at most
s
v s
2 , then by the inductive hypothesis, Find(S0 , 2 , d − 1) does not return “None.” Otherwise
s
v
Find(S1 , 2 , d − 1) does not return “None.” Hence, Find won’t return “None” on line 5.
37

Find(S, s, d):
Input: A sample S that can be exactly fit by a tree of size s and depth budget d.
Output: A decision tree T with depth at most d that approximately fits S. If S cannot be
fit by a tree of size s, may return “None.”
1. If all samples in S have the same label, return the single-node tree computing that
label.
2. If s ≤ 1 return “None.”
3. If d = 0 return the single-node tree computing the majority label of S.
4. For each relevanta variable v:
(a) Let T0v = Find(S0v , 2s , d − 1) and T1v = Find(S1v , 2s , d − 1).

(b) If both T0v and T1v are not “None”, return the tree with root labeled v, 0-subtree
T0v and 1-subtree T1v .
(c) If one of T0v and T1v is “None” and the other is not:
i. Reexecute the recursive call for the side that was “None” with size s−1 instead
of size 2s . For example, if T1v was “None”, set T1v = Find(S1v , s − 1, d − 1)
ii. If the reexecuted call still returns “None”, return “None.”
iii. Return the tree with root labeled v, 0-subtree T0v and 1-subtree T1v .
5. Return “None”.
a

“relevant” means that neither S0v nor S1v is empty

Figure 9: Our variant of Ehrenfeucht and Haussler’s Find algorithm.
We hope to prove that Find will produce low error trees, but it turns out to be difficult to
guarantee this for arbitrary samples. One particular sample we can guarantee this for is the sample
containing all possible points. If S contains all 2n possible points, then Find will return a tree
with error at most 14 · ( 43 )d , which we will prove in Lemma 9.2. The following property allows us to
quantify how close S is to the full sample.
Definition 28 (Well-distributed samples). We say that a sample of points S is c-well-distributed
to depth d if, for any restriction α where |α| ≤ d,
||(Sα )| − µ| ≤ cµ

where µ = 2−|α| · |S| is the expected size of Sα if S is chosen uniformly at random.

For example, if S contains all possible 2n points, then S is 0-well-distributed to any depth.

Lemma 9.2 (Error of Find on well-distributed samples). Let S be c-well-distributed to depth d. If
Find(S, s, d) does not return “None,” it returns a tree with error at most 14 ( 34 + 4c )d · s with respect
to S.
38

Proof. By induction on the d; If d = 0 and s ≥ 2, then this lemma requires the error to be less
than 12 , which Find satisfies since it places the majority node. If s = 1 and Find doesn’t return
“None,” it must have returned a zero-error tree on Line 1, satisfying the desired error bound.
Next, consider d ≥ 1. If all samples have the same label, Find returns a 0 error tree. Otherwise,
it returns a tree, T , with 0-subtree T0v and 1-subtree T1v for some variable v. Let `0 and `1 be the
number of points in S0v and S1v respectively. Then, we can relate the errors of the trees as follows:
error(T ) =

`1
`0
· error(T0v ) +
· error(T1v )
`0 + `1
`0 + `1

At least one of T0v and T1v was generated using a recursive call to Find with size parameter 2s .
Without loss of generality, let that tree be T0v . The other tree, T1v was generated by a recursive
call with size at most s. By the inductive hypothesis,
`0
1
error(T ) ≤
·
`0 + `1 4



3 c
+
4 4

d

1
s
`1
·
· +
2 `0 + `1 4



3 c
+
4 4

d
·s

(12)

Since S is c-well-distributed to depth d, (1 − c)µ ≤ `0 , `1 ≤ (1 + c)µ, where µ = |S|
2 . Choosing
`0 = (1 − c)µ and `1 = (1 + c)µ maximizes equation Equation (12) and so results in a valid upper
bound.




µ(1 − c) 1 3 c d−1 s µ(1 + c) 1 3 c d−1
error(T ) ≤
·
+
· +
·
+
·s
2µ
4 4 4
2
2µ
4 4 4




1
3 c d−1
3 c
= ·
+
·
+
·s
4
4 4
4 4


1 3 c d
=
+
·s
4 4 4
The above Lemma shows that if a sample is sufficiently well-distributed, Find will return a
tree with low error. We next show that, with high probability, sufficiently large samples will be
well-distributed.
Lemma 9.3 (Well-distributed samples are common). Choose any 0 < c < 1.0, δ > 0. Then for
 d

2
m=O
·
(d
log(n)
+
log(1/δ))
,
c2
a sample of size m chosen uniformly at random from {0, 1}n is c-well-distributed to depth d with
probability at least 1 − δ
Proof. Consider an arbitrary restriction α of length h ≤ d. By Chernoff bounds,
2 /3

Pr[||Sα | − µ| ≥ cµ] ≤ 2e−µc

where µ = E[|Sα |] = m · 2−h . Since h ≤ d, we can upper bound the probability as follows.
−d c2 /3

Pr[||Sα | − µ| ≥ cµ] ≤ 2e−m·2
39

S
if ||Sα | − µ| ≤ cµ for all possible restrictions α of size at most d. There are

Pdis c-well-distributed
n i
O(d)
such restrictions. Thus, by a union bound:
i=0 i 2 = n
−d c2 /3

Pr[S is c-well-distributed] ≥ 1 − nO(d) · e−m·2

.

We set the right-hand side of the above equation to be at least 1 − δ and solve for m, which proves
this Lemma.
Our analysis of the time complexity of Find is very similar to Ehrenfeucht and Haussler’s:
Lemma 9.4 (Time complexity of Find). Find(S, s, d) takes time |S| · (n + 1)2 log(s) .
Proof. Fix a total number of variables n and sample size m. Let T (i, s) be the maximum time
needed by Find(S, s, d) where S has size at most m, i is the number of relevant variables in S, and
d is arbitrary.
If i = 0 or s = 1, then Find must return on Line 1 or 2, using only O(m) time. Otherwise, the
Find makes at most 2i recursive calls on line 4.(a) each of which takes time at most T (i − 1, 2s ) It
also makes zero or one recursive call on line 4.(c).i which takes time up to T (i−1, s−1) ≤ T (i−1, s).
In addition to these recursive calls, all of the auxiliary computations can be done in O(mn) time.
Hence, we have the following recurrence relation:

T (i, s) ≤ 2i · T i − 1, 2s + T (i − 1, s) + O(mn).
If we substitute r = log(s), then equivalently, we have the relation:
T̃ (i, r) ≤ 2i · T̃ (i − 1, r − 1) + T̃ (i − 1, r) + O(mn).
The above relation is shown to be upper bounded by T̃ (i, r) = O(m · (n + 1)2r ) in [EH89]. Substituting back r = log(s) gives that T (i, s) ≤ O(m · (n + 1)2 log(s) ).
Lemma 9.5 (Memory complexity of Find). Find(S, s, d) takes memory O(2d (|S| + log n)).
Proof. Each call to Find with depth d will only ever need simultaneously need to run up to 2
calls to Find, each with depth d − 1. Hence, there are at most 2d copies of Find that need to be
stored in memory at any one time. At worst, each copy stores the sample as well as pointers to
it and the n different variables. This means each copy uses O(|S| + log n) memory, for a total of
O(2d (|S| + log n)) memory.
The last step in this analysis is a standard generalization argument relying on Chernoff bounds.
Lemma 9.6 (Generalization). Choose any δ, ε ≥ 0. Suppose that S is a uniformly random sample
from a function, f , that can be computed by a decision tree of size at most s and depth at most d.
If the number of samples in S is at least
!
2d log(n) + log( 1δ )
m=O
ε
and Find(S, s, d) returns a decision tree that fits S with error at most 4ε . Then, with probability at
least 1 − δ, the decision tree returned by Find has error at most ε on f .
40

Proof. We will upper bound the number of different decision trees Find could return when given
depth limit d. There up to 2d spots where a decision tree of depth ≤ d could have a node. In each
of these spots, the decision tree could either have one of n variables, a leaf that is either +1 or −1,
d
or nothing. Thus, the number of decision trees of depth at most d is at most (n + 3)2 .
We call a decision tree, T , “bad”, if T has error at least ε on f . For any particular bad tree T ,
the probability it will have error less than 4ε on S can be upper bounded using a Chernoff Bound:


9
Pr errorS (T ) ≤ 4ε ≤ exp(− 32
εm).
S

2d

Since there are most (n + 3) bad trees, the probability that any bad tree has error at most 4ε is
d
9
at most (n + 3)2 · exp(− 32
εm). Setting this equal to δ and solving for m completes the proof of
this lemma.
Finally, we are able to put all these pieces together to prove our main theorem of this section,
and show how Find is used to learn decision trees:
Theorem 29 (Proper learning with polynomial sample and memory complexity). Let f be any
function over n variables computable by a size s decision tree. Choose any ε, δ > 0. There is an
algorithm that
◦ runs in time poly(nlog s , 1ε , log( 1δ ))
◦ requires memory poly(s, log n, 1ε , log( 1δ ))
◦ uses poly(s, log n, 1ε , log( 1δ )) random samples from f
and with probability at least 1 − δ returns a decision tree that is an ε-approximation of f .

Proof. Choose any constant 0 < c < 1 and set d = log( sε )/(− log( 3+c
4 )). Then, by taking a uniformly
random sample, S, of size
 d

2
m=O
· (d log(n) + log(1/δ))
εc2
we have the following holds:
1. S is c-well-distributed with probability at least 1 − 2δ .
d
2. If S is c-well-distributed, then Find(S, s, d) returns a tree, T , with error at most 14 ( 3+c
4 ) ·s =
ε
4 on S.

3. If T has error less than 4ε , then with probability at least 1 − 2δ , T is a ε-approximation for f .
Furthermore, this procedure meets the time constraints by Lemma 9.4 and memory constraints by
Lemma 9.5.

Acknowledgments
We thank Clément Canonne, Adam Klivans, Charlotte Peale, Toniann Pitassi, Omer Reingold, and
Rocco Servedio for helpful conversations and suggestions. We also thank the anonymous reviewers
of ITCS 2020 for their valuable feedback.
The third author is supported by NSF grant CCF-1921795.
41

References
[AA14]

Scott Aaronson and Andris Ambainis. The need for structure in quantum speedups.
Theory of Computing, 10(6):133–166, 2014.

[ABF+ 09]

Misha Alekhnovich, Mark Braverman, Vitaly Feldman, Adam Klivans, and Toniann
Pitassi. The complexity of properly learning simple concept classes. Journal of Computer & System Sciences, 74(1):16–34, 2009.

[AFK13]

Pranjal Awasthi, Vitaly Feldman, and Varun Kanade. Learning using local membership queries. In Proceedings of the 26th Annual Conference on Learning Theory
(COLT), pages 398–431, 2013.

[BBL98]

Avrim Blum, Carl Burch, and John Langford. On learning monotone boolean functions. In Proceedings of the 39th Annual Symposium on Foundations of Computer
Science (FOCS), pages 408–415, 1998.

[BCO+ 15]

Eric Blais, Clément Canonne, Igor Oliveira, Rocco Servedio, and Li-Yang Tan. Learning circuits with few negations. In Proceedings of the 18th International Workshop on
Randomization and Computation (RANDOM), pages 512–527, 2015.

[BDM19a]

Alon Brutzkus, Amit Daniely, and Eran Malach. ID3 Learns Juntas for Smoothed
Product Distributions. ArXiv, abs/1906.08654, 2019.

[BDM19b]

Alon Brutzkus, Amit Daniely, and Eran Malach. On the Optimality of Trees Generated
by ID3. ArXiv, abs/1907.05444, 2019.

[BFJ+ 94]

Avirm Blum, Merrick Furst, Jeffrey Jackson, Michael Kearns, Yishay Mansour, and
Steven Rudich. Weakly learning DNF and characterizing statistical query learning
using Fourier analysis. In Proceedings of the 26th Annual ACM Symposium on Theory
of Computing (STOC), pages 253–262, 1994.

[BL97]

Avrim Blum and Pat Langley. Selection of relevant features and examples in machine
learning. Artificial Intelligence, 97(1-2):245–271, 1997.

[Blu92]

Avrim Blum. Rank-r decision trees are a subclass of r-decision lists. Inform. Process.
Lett., 42(4):183–185, 1992.

[BMOS05]

Nader H. Bshouty, Elchanan Mossel, Ryan O’Donnell, and Rocco A. Servedio. Learning DNF from random walks. J. Comput. System Sci., 71(3):250–265, 2005.

[BOGY18] Paul Beame, Shayan Oveis Gharan, and Xin Yang. Time-space tradeoffs for learning finite functions from random evaluations, with applications to polynomials. In
Proceedings of the 31st Conference On Learning Theory (COLT), volume 75, pages
843–856, 2018.
[Bre17]

Leo Breiman. Classification and regression trees. Routledge, 2017.

[Bsh95]

Nader Bshouty. Exact learning via the monotone theory. Information and Computation, 123(1):146–153, 1995.
42

[BT96]

Nader Bshouty and Christino Tamon. On the Fourier spectrum of monotone functions.
Journal of the ACM, 43(4):747–770, 1996.

[BT15]

Eric Blais and Li-Yang Tan. Approximating Boolean functions with depth-2 circuits.
SIAM J. Comput., 44(6):1583–1600, 2015.

[CM19]

Sitan Chen and Ankur Moitra. Beyond the low-degree algorithm: mixtures of subcubes
and their applications. In Proceedings of the 51st Annual ACM Symposium on Theory
of Computing (STOC), pages 869–880, 2019.

[DHK+ 10]

Ilias Diakonikolas, Prahladh Harsha, Adam Klivans, Raghu Meka, Prasad Raghavendra, Rocco Servedio, and Li-Yang Tan. Bounding the average sensitivity and noise
sensitivity of polynomial threshold functions. In Proceedings of the 42nd Annual Symposium on Theory of Computing (STOC), pages 533–542, 2010.

[DKM96]

Tom Dietterich, Michael Kearns, and Yishay Mansour. Applying the weak learning
framework to understand and improve C4.5. In Proceedings of the 13th International
Conference on Machine Learning (ICML), pages 96–104, 1996.

[DSLM+ 09] Dana Dachman-Soled, Homin K. Lee, Tal Malkin, Rocco A. Servedio, Andrew Wan,
and Hoeteck Wee. Optimal cryptographic hardness of learning monotone functions.
Theory of Computing, 5(13):257–282, 2009.
[EH89]

Andrzej Ehrenfeucht and David Haussler. Learning decision trees from random examples. Information and Computation, 82(3):231–246, 1989.

[Fel16]

Vitaly Feldman. Hardness of proper learning. In Encyclopedia of Algorithms, 2016.

[FK96]

Ehud Friedgut and Gil Kalai. Every monotone graph property has a sharp threshold.
Proceedings of the American Mathematical Society, 124:2993–3002, 1996.

[FP04]

Amos Fiat and Dmitry Pechyony. Decision trees: More theoretical justification for
practical algorithms. In Proceedings of the 15th International Conference on Algorithmic Learning Theory (ALT), pages 156–170, 2004.

[Fri98]

Ehud Friedgut. Boolean functions with low average sensitivity depend on few coordinates. Combinatorica, 18(1):474–483, 1998.

[GGR98]

Oded Goldreich, Shafi Goldwasser, and Dana Ron. Property testing and its connection
to learning and approximation. Journal of the ACM, 45:653–750, 1998.

[GKK08]

Parikshit Gopalan, Adam Kalai, and Adam Klivans. Agnostically learning decision
trees. In Proceedings of the 40th ACM Symposium on Theory of Computing (STOC),
pages 527–536, 2008.

[GL89]

Oded Goldreich and Leonid Levin. A hard-core predicate for all one-way functions. In
Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC),
pages 25–32, 1989.

43

[GRT18]

Sumegha Garg, Ran Raz, and Avishay Tal. Extractor-based time-space lower bounds
for learning. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory
of Computing (STOC), pages 990–1002, 2018.

[GRT19]

Sumegha Garg, Ran Raz, and Avishay Tal. Time-space lower bounds for two-pass
learning. In Proceedings of the 34th Computational Complexity Conference (CCC),
pages 22:1–22:39, 2019.

[GS10]

Parikshit Gopalan and Rocco Servedio. Learning and lower bounds for AC0 with
threshold gates. In Proceedings of the 14th International Workshop on Randomization
and Computation (RANDOM), pages 588–601, 2010.

[HKY18]

Elad Hazan, Adam Klivans, and Yang Yuan. Hyperparameter optimization: A spectral
approach. Proceedings of the 6th International Conference on Learning Representations
(ICLR), 2018.

[HM91]

Thomas Hancock and Yishay Mansour. Learning monotone k-µ DNF formulas on
product distributions. In Proceedings of the 4th Annual Conference on Computational
Learning Theory (COLT), pages 179–193, 1991.

[JLSW11]

Jeffrey Jackson, Homin Lee, Rocco Servedio, and Andrew Wan. Learning Random
Monotone DNF. Discrete Applied Mathematics, 159(5):259–271, 2011.

[Kan14a]

Daniel Kane. The average sensitivity of an intersection of halfspaces. In Proceedings
of the 42nd ACM Symposium on Theory of Computing (STOC), pages 437–440, 2014.

[Kan14b]

Daniel Kane. The correct exponent for the Gotsman–Linial conjecture. Computational
Complexity, 23(2):151–175, 2014.

[Kea96]

Michael Kearns. Boosting theory towards practice: recent developments in decision
tree induction and the weak learning framework (invited talk). In Proceedings of the
13th National Conference on Artificial intelligence (AAAI), pages 1337–1339, 1996.

[KKL88]

Jeff Kahn, Gil Kalai, and Nathan Linial. The influence of variables on boolean functions. In Proceedings of the 29th Annual Symposium on Foundations of Computer
Science (FOCS), pages 68–80, 1988.

[KLV94]

Michael Kearns, Ming Li, and Leslie Valiant. Learning Boolean formulas. Journal of
the ACM, 41(6):1298–1328, 1994.

[KM93]

Eyal Kushilevitz and Yishay Mansour. Learning decision trees using the fourier spectrum. SIAM Journal on Computing, 22(6):1331–1348, December 1993.

[KM99]

Michael Kearns and Yishay Mansour. On the boosting ability of top-down decision
tree learning algorithms. Journal of Computer and System Sciences, 58(1):109–128,
1999.

[KRT17]

Gillat Kol, Ran Raz, and Avishay Tal. Time-space hardness of learning sparse parities.
In Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing
(STOC), pages 1067–1080, 2017.
44

[KV94]

Michael Kearns and Leslie Valiant. Cryptographic limitations on learning Boolean
formulae and finite automata. Journal of the ACM, 41(1):67–95, 1994.

[Lee09]

Homin Lee. On the learnability of monotone functions. PhD thesis, Columbia University, 2009.

[LMN93]

Nathan Linial, Yishay Mansour, and Noam Nisan. Constant depth circuits, Fourier
transform and learnability. Journal of the ACM, 40(3):607–620, 1993.

[MM17]

Dana Moshkovitz and Michal Moshkovitz. Mixing implies lower bounds for space
bounded learning. In Proceedings of the 30th Conference on Learning Theory (COLT),
pages 1516–1566, 2017.

[MM18]

Dana Moshkovitz and Michal Moshkovitz. Entropy samplers and strong generic lower
bounds for space bounded learning. In Proceedings of the 9th Innovations in Theoretical
Computer Science Conference (ITCS), pages 28:1–28:20, 2018.

[MOO10]

Elchannan Mossel, Ryan O’Donnell, and Krzysztof Oleszkiewicz. Noise stability of
functions with low influences: Invariance and optimality. Annals of Mathematics,
171:295–341, 2010.

[MOS04]

Elchanan Mossel, Ryan O’Donnell, and Rocco A. Servedio. Learning functions of k
relevant variables. Journal of Computer and System Sciences, 69(3):421–434, 2004.

[MR02]

Dinesh Mehta and Vijay Raghavan. Decision tree approximations of boolean functions.
Theoretical Computer Science, 270(1-2):609–623, 2002.

[O’D14]

Ryan O’Donnell. Analysis of Boolean Functions. Cambridge University Press, 2014.
Available at http://analysisofbooleanfunctions.net/.

[OS07]

Ryan O’Donnell and Rocco Servedio. Learning monotone decision trees in polynomial
time. SIAM Journal on Computing, 37(3):827–844, 2007.

[OSSS05]

Ryan O’Donnell, Michael Saks, Oded Schramm, and Rocco Servedio. Every decision
tree has an influential variable. In Proceedings of the 46th Annual IEEE Symposium
on Foundations of Computer Science (FOCS), pages 31–39, 2005.

[OW13]

Ryan O’Donnell and Karl Wimmer. KKL, Kruskal–Katona, and Monotone Nets.
SIAM Journal on Computing, 42(6):2375–2399, 2013.

[Qui86]

Ross Quinlan. Induction of decision trees. Machine learning, 1(1):81–106, 1986.

[Qui93]

Ross Quinlan. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA, 1993.

[Raz17]

Ran Raz. A time-space lower bound for a large class of learning problems. In Proceedings of the 58th IEEE Annual Symposium on Foundations of Computer Science
(FOCS), pages 732–742, 2017.

[Raz18]

Ran Raz. Fast learning requires good memory: A time-space lower bound for parity
learning. Journal of the ACM, 66(1):3:1–3:18, December 2018.
45

[Riv87]

Ronald Rivest. Learning decision lists. Machine learning, 2(3):229–246, 1987.

[Sel08]

Linda Sellie. Learning random monotone DNF under the uniform distribution. In
Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 181–
192, 2008.

[Ser04]

Rocco Servedio. On learning monotone DNF under product distributions. Information
and Computation, 193(1):57–74, 2004.

[Sha14]

Ohad Shamir. Fundamental limits of online and distributed algorithms for statistical
learning and estimation. In Proceedings of the 28th Conference on Neural Information
Processing Systems, pages 163–171, 2014.

[SM00]

Yoshifumi Sakai and Akira Maruoka. Learning monotone log-term DNF formulas
under the uniform distribution. Theory of Computing Systems, 33:17–33, 2000.

[ST13]

Dominik Scheder and Li-Yang Tan. On the average sensitivity and density of k-CNF
formulas. In Proceedings of the 17th International Workshop on Randomization and
Computation (RANDOM), pages 683–698, 2013.

[SVW16]

Jacob Steinhardt, Gregory Valiant, and Stefan Wager. Memory, communication, and
statistical queries. In Proceedings of the 29th Annual Conference on Learning Theory
(COLT), pages 1490–1516, 2016.

[Ver98]

Karsten Verbeurgt. Learning sub-classes of monotone DNF on the uniform distribution. In Proceedings of the 9th Conference on Algorithmic Learning Theory (ALT),
pages 385–399, 1998.

[WFHP16] Ian Witten, Eibe Frank, Mark Hall, and Christopher Pal. Data Mining: Practical
machine learning tools and techniques. Morgan Kaufmann, 2016.

46

