medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Electrophysiological Studies of Reception of Facial Communication
in Autism Spectrum Disorder and Schizophrenia

Emily J. Levya, Jennifer Foss-Feigb,c, Emily L. Isensteind, Vinod Sriharie, Alan Anticevice,f,g,
Adam J. Naplesh, & James C. McPartlandf,h*
aBiology Department, Duke University; bDepartment of Psychiatry, Icahn School of Medicine at
Mount Sinai; cSeaver Autism Center, Icahn School of Medicine at Mount Sinai; dMedical Center,
University of Rochester; eDepartment of Psychiatry, Yale University School of Medicine;
fDepartment of Psychology, Yale University, gDivision of Neurogenetics, Neurocomputation,
and Neuroimaging, Yale University School of Medicine, hYale Child Study Center, Yale
University School of Medicine
aEmily.J.Levy@duke.edu;

Duke University, 130 Science Drive, Durham, NC 27708, USA.
ORCID: 0000-0002-8182-9456
b,cJennifer.Foss-Feig@mssm.edu; Seaver Center, One Gustave L. Levy Place, Box 1230, New
York, NY 10029, USA. ORCID: 0000-0002-1491-8248
dEmily_Isenstein@urmc.rochester.edu; University of Rochester Medical Center, 601 Elmwood
Avenue, Rochester NY14642, USA
eVinod.Srihari@yale.edu; Yale School of Medicine; 34 Park Street, New Haven, CT 06519,
USA. ORCID: 0000-0003-1556-2332
e,f,gAlan.Anticevic@yale.edu; Yale School of Medicine; 34 Park Street, New Haven, CT 06519,
USA. ORCID: 0000-0002-4324-0536
hAdam.Naples@yale.edu; Yale Child Study Center, 230 South Frontage Road, New Haven, CT
02520, USA
f,hJames.McPartland@yale.edu; Yale Child Study Center, 230 South Frontage Road, New Haven,
CT 02520, USA. ORCID: 0000-0002-2570-0746. Phone: 203.785.7179

*corresponding author

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

1

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

ABSTRACT & KEYWORDS

Autism spectrum disorder (ASD) and schizophrenia spectrum disorders (SZ) are both
characterized by difficulty with social cognition. Likewise, social brain activity is atypical in
both disorders and indicates atypical reception of facial communication – a key area in the
Research Domain Criteria framework for identifying common biological underpinnings of
psychiatric disorders. To identify areas of overlap and dissociation between ASD and SZ, this
paper reviews studies of electrophysiological (EEG) response to facial stimuli across ASD and
SZ populations. We focus on findings regarding amplitude and latency of four brain responses
implicated in social perception: P100, N170, N250, and P300. There were many inconsistent
findings in both the ASD and SZ literatures; however, replication across studies was strongest
for delayed N170 latency in ASD and attenuated N170 amplitude in SZ. EEG responses
corresponded with clinical symptoms in multiple samples. These results highlight the challenges
associated with replicating research findings in heterogeneous clinical populations, as well as the
need for transdiagnostic research and for designing studies to examine relationships among
continuous quantifications of behavior and neural activity across neurodevelopmental disorders.

Keywords: autism spectrum disorder, schizophrenia, electrophysiology, face, emotion, Research
Domain Criteria

2

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

INTRODUCTION
Autism spectrum disorder (ASD) and schizophrenia spectrum disorders (SZ) are highly
prevalent neurodevelopmental disorders (ND) with considerable public health impact, costing
the United States a combined $423 billion per year (Cloutier et al. 2016). Though these disorders
are classified in two separate diagnostic taxonomies, social deficits are diagnostic hallmarks of
both, and diagnostic confusion is common. Social dysfunction is a core symptom of both ASD
and SZ, evident in decreased social motivation, reduced social reward, impaired mentalizing, and
decreased likelihood of social engagement (Dawson et al. 2005; Dowd and Barch 2010; Schultz
2005). Moreover, parallel lines of research indicate commonalities in affected genetic pathways
and neural processes, suggesting shared neuropathology (Cristino et al. 2014; Mitchell 2011).
These findings are consistent with the hypothesis that common mechanisms contribute to social
communication deficits across behaviorally defined categories of ND. Despite these
commonalities, few studies have directly compared distinct diagnostic groups or conceptualized
these diagnostic classes as heterogeneous manifestations of shared dysfunction in overlapping
neural substrates. For this reason, little is known about whether atypical social perception across
NDs reflects common or distinct neural underpinnings. In this review, we focus on literature
related to face and emotion processing across ASD and SZ, highlighting what is known, where
the disorders converge and diverge, and what work remains to be done to understand social
processes related to reception of facial communication across disorders.
Decreased attention to human faces is evident throughout the lifespan in ASD (Maestro et
al. 2002; Osterling and Dawson 1994; Dawson et al. 2005). Though SZ is not usually diagnosed
until adolescence or early adulthood, infants later diagnosed with psychosis also show decreased
attention to faces (Massie 1978). Eye-tracking studies of perception of facial stimuli demonstrate

3

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

atypical face scanning in individuals with ASD (Pelphrey et al. 2002; A. Klin et al. 2002; Joseph
and Tanaka 2003) and SZ (Phillips and David 1997; Gordon et al. 1992), with both clinical groups
spending less time fixating on the eyes and more time fixating on other parts of the face.
Individuals with ASD (Ami Klin et al. 1999; Hobson 1986; Baron-Cohen et al. 2001; Law Smith
et al. 2010) and SZ (Bellack et al. 1996; Mueser et al. 1996; Morrison et al. 1988) also show
deficits in accurately identifying emotions, sorting emotional faces, and matching faces based on
emotion. Atypical sensitivity to emotional expressions is a stable feature of multiple NDs
(Addington and Addington 1998; Gaebel and Wolwer 1992) and has been shown to associate with
chronicity (Kington et al. 2000), severity, and type of active symptomatology (Davis and Gibson
2000; Lewis and Garver 1995). Difficulties in emotion recognition and discrimination in SZ and
ASD are associated with specific disruption in social process systems, such as increased social
withdrawal and impaired social cognition.
Face and emotion processing rely upon a network of specialized brain regions.
Neuroimaging research has clarified the role of specific brain areas, including the fusiform
gyrus, superior temporal sulcus, and amygdala, in face perception (Kesler-West et al. 2001;
Kanwisher 2001). EEG studies reveal a specific time course for related but distinct stages of face
processing in this network (T. Wong et al. 2009; Luo et al. 2009). This sequence of event-related
potentials (ERPs) is distinguished by scalp topography and chronology and shows sensitivity
across perceptual processes, from detecting faces (S. Bentin et al. 1996) to interpreting
differences in facial identity, direction of gaze, and displays of emotion (Conty et al. 2007;
Gosling and Eimer 2011; M. Eimer and Holmes 2002). These ERPs provide temporally precise
indices of function across the regions involved in face perception, or, as conceptualized in the
NIMH’s Research Domain Criteria (RDoC) framework, the subdomain reception of facial

4

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

communication within the broader category of social process systems (Kozak and Cuthbert
2016). Prior research has demonstrated the relevance of a subset of these components across
neurological and psychiatric disorders (Feuerriegel et al. 2015), and here we focus on their
manifestation in ASD and SZ, reviewing the broad, temporally sequential set of ERP
components associated with face processing (P100, N170, N250, and P300).
Measured over the occipital cortex as a positive deflection approximately 100ms after the
onset of a visual stimulus, the P100 reflects low-level processing in the visual cortex (Mangun
1995; V1; A. P. F. Key et al. 2005) that is modulated by age and may be affected by the social
nature of stimuli. In typical development (TD), faces elicit a larger (Herrmann et al. 2005;
Roxane J Itier and Taylor 2004c) and faster (Kuefner et al. 2009; Taylor et al. 2001) P100 than
objects, and in a number of studies, inverted faces elicit a larger (Roxane J Itier and Taylor
2004c, 2004a) but slower (Roxane J Itier and Taylor 2004c; Taylor et al. 2001) P100 than
upright faces. P100 amplitude can be modulated by emotion (Magali Batty and Taylor 2003).
The N170 is a negative-going component, recorded over occipito-temporal scalp
approximately 170ms after viewing a face, that indexes the earliest stages of face processing
(i.e., structural encoding). Neural generators of the N170 have been localized to occipitotemporal sites, including the fusiform gyrus (B. Rossion et al. 2003; Sadeh et al. 2010; R. J. Itier
and Taylor 2002), superior temporal sulcus (Roxane J Itier and Taylor 2004d; Yovel et al. 2008),
lingual gyrus (Shibata et al. 2002), posterior inferotemporal gyrus (Shibata et al. 2002;
Schweinberger et al. 2002), and inferior occipital gyrus (Jacques et al. 2018). Like the P100, in
TD the N170 exhibits enhanced amplitude (more negative) and decreased latency to faces
relative to objects (Roxane J Itier and Taylor 2004c; S. Bentin et al. 1996) and larger amplitude
but slower latency to inverted than to upright faces (Martin Eimer 2000; Roxane J Itier and

5

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Taylor 2004b, 2004d, 2004c; Bruno Rossion et al. 2000). For the N170, this “face inversion
effect” is not found for upright vs. inverted objects, consistent with the interpretation that the
N170 indexes face-selective processing (Martin Eimer 2000; Roxane J Itier and Taylor 2004c).
N170 latency tends to be faster (Blau et al. 2007) with greater amplitude (Roxane J Itier and
Taylor 2004b, 2004c; B. Rossion et al. 2003) over the right hemisphere than the left. Finally,
N170 also may reflect an early indicator of emotion processing. Happy faces elicit faster N170
latencies than faces displaying negative affect (Magali Batty and Taylor 2003), and fearful faces
elicit more negative N170 amplitude than neutral (Magali Batty and Taylor 2003; Blau et al.
2007) and happy (C. A. Brenner et al. 2014) faces.
The N250 is a negative-going component occurring approximately 250ms post-stimulus
(Schweinberger et al. 2002). Though less well characterized than the P100 and N170
components and rarely studied in typically developing populations, the N250 demonstrates
increased amplitude in response to emotional expressiveness relative to neutral faces (Balconi
and Pozzoli 2008; L. Carretié et al. 2001; Labuschagne et al. 2010; Sato et al. 2001; Streit et al.
2001). As such, the N250 is considered a marker of higher-order face processing, such as affect
decoding and emotion processing, and is presumed to reflect the modulatory influence of
subcortical structures, including the amygdala (Streit et al. 1999). Research on face learning and
repetition suggests the N250 is modulated by the identity of a face; familiar or repeated faces
evoke a more negative N250 than unfamiliar or novel faces (Gosling and Eimer 2011; Kaufmann
et al. 2009; Tanaka et al. 2006). N250 latency delays to inverted faces have been observed in a
face repetition task (Roxane J Itier and Taylor 2004b), and, as with the N170, N250 has been
shown to be right lateralized (Kaufmann et al. 2009).

6

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

The P300 is a large-amplitude positive component measured at central locations
approximately 300ms after stimulus onset. It is associated with detecting novel and significant
events (T. Picton 1995; Polich et al. 1995; T. W. Picton 1992; Ferrari et al. 2010), as well as with
context updating (Donchin 2008; Donchin and Coles 1998, 1988). In the context of face
perception, the P300 reflects processing of self-relevant stimuli, such as one’s own face
(Onitsuka et al. 2001; Ninomiya et al. 1998). Emotional stimuli elicit a greater P300 amplitude
than neutral stimuli (V. S. Johnston et al. 1986), and salient or attended stimuli elicit a greater
P300 response than passively viewed stimuli (L Carretié et al. 1997). P300 amplitude is larger to
upright than to inverted faces and may be modified by emotional valence (Kestenbaum and
Nelson 1992), though the evidence is mixed (Conroy and Polich 2007).
In this review, we highlight findings related to the amplitude and latency of these four
ERP components, as elicited in response to face and emotion stimuli in individuals with ASD
and SZ. This work expands on prior reviews focused solely on the N170 in ASD (Kang et al.
2018) and other disorders (Feuerriegel et al. 2015) by reviewing points of convergence and
divergence for additional neural components associated with face processing transdiagnotically.

METHODS
Search Criteria
Scopus, Google Scholar, and PubMed were queried using the following search criteria:
(ASD OR autis* OR “pervasive developmental disorder” OR PDD-NOS OR Asperger* OR SZ
OR schizo*) AND (ERP OR EEG OR electrophys* OR event-related potential OR P100 OR
N170 OR N250 OR P300) AND (face OR facial OR emotion*). Reference lists, review articles,

7

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

and meta-analyses were scanned to identify additional peer-review articles. Searches reflect
updated content through October 23, 2017.

Inclusion Criteria: Methods and Components
These searches yielded 69 eligible studies (36 ASD, 33 SZ); all included articles were
peer-reviewed. Eligible studies were required to investigate at least one of the four key ERP
components most commonly investigated in neuroscientific studies of face processing in typical
and atypical development: P100, N170, N250, and/or P300. Studies that did not include at least
one of these components were excluded (e.g., McMahon and Henderson 2015). Included studies
were required to use images of faces as stimuli. Studies in which more than one face or object
was simultaneously presented were excluded (e.g., Maher et al. 2016), as were studies in which
all visual stimuli were combined with auditory stimuli (Müller et al. 2012). Any study that
included faces stimuli was designated as a ‘face’ study, and any study that included face stimuli
and contrasted response to two or more emotions was designated as an ‘emotion’ study. All
‘emotion’ studies that examined main effects of group collapsed across different emotions were
also included as ‘face’ studies.

Inclusion Criteria: Subjects
Details about population demographics, subject characterization, study methodology, and
stimuli are presented in Table 1. Studies were required to examine individuals diagnosed with
either ASD or SZ, and those studying only high-risk individuals or relatives were excluded
(Wolwer et al. 2012). No studies included both diagnostic groups. Studies were required to
report their method for confirming patients’ diagnostic status. In half of the studies of ASD (18

8

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

of 36), diagnosis was confirmed with a gold-standard clinical assessment, the Autism Diagnostic
Observation Schedule (ADOS; Lord et al. 2012). For the remaining ASD studies, participants
entered the study with a prior diagnosis according to DSM-IV or DSM-5 criteria. In 32 of 33 SZ
studies, clinicians confirmed diagnosis based on DSM-IV criteria. The single study that did not
specify the use of DSM criteria for schizophrenia completed a Schedule for Schizophrenia and
Affective Disorders (Spitzer and Endicott 1979). Study samples targeting individuals under three
years of age were excluded, given the developmental emergence of some of the ERP components
at this point (Roxane J Itier and Taylor 2004b). Studies were otherwise included regardless of
target age group; however, all SZ studies targeted adults or late adolescents, whereas two-thirds
of ASD studies exclusively included children. Studies that included both a child and an adult
group analyzed separately were treated as two separate studies. Studies without a typically
developing (TD) comparison group were excluded. Studies examining additional clinical groups
not targeted by this review (Tye et al. 2014; Tye et al. 2013) were included, but we focused only
on results regarding ASD and SZ.

RESULTS
Details on all study results described below can be found in Table 2. A graphical
overview of findings can be found in Figure 1.
P100 Amplitude
P100 Amplitude in ASD: Face
The majority of ERP literature reported no significant differences in P100 amplitude to
faces between individuals with ASD and TD. Twenty-three studies of face and emotion
processing in ASD reported on P100, 16 of which reported comparable P100 amplitudes in ASD

9

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

and TD. In these 16 studies, no significant group differences in P100 amplitude to faces were
identified across a range of task demands (attending to non-social target images to actively
attending to facial stimuli) and in both child and adult samples (Akechi et al. 2010; Webb et al.
2010; Tye et al. 2013; Senju et al. 2005; Wagner et al. 2013; J. C. McPartland et al. 2011;
Apicella et al. 2013; O'Connor et al. 2005 [child and adult]; 2007; T. K. Wong et al. 2008;
Neuhaus et al. 2016; Shen et al. 2016; Yamasaki et al. 2017; Luyster et al. 2017[child and
adult]).
Studies reporting group differences (7 of 23) in P100 amplitude to faces revealed
inconsistent directionality of effects. One study of adults found increased P100 amplitude to
faces in ASD versus TD (Cygan et al. 2014). One child study and one adult study reported
inversion effects (greater P100 amplitude to inverted versus upright faces) in the TD group, but
not in the ASD group (Hileman et al. 2011; Webb et al. 2012). Poorer face memory in Webb and
colleagues’ study (2012) was correlated with greater P100 response to inverted versus upright
faces in adults with ASD; however, there were no significant differences between groups in
processing upright faces or objects. One study of children reported attenuated P100 amplitude to
faces in ASD compared to TD, but lacked control stimuli (M. Batty et al. 2011), and a second
study replicated this effect in young adults when using photographs of emotional faces, but
reported a slightly larger P100 amplitude in ASD when using realistic drawings of emotional
faces (Tseng et al. 2015). Tseng’s study reported no differential effect of each emotion on the
P100 response within or across groups; thus, this is a face-related, rather than emotionspecific, result. An additional study of children reported reduced P100 amplitude in ASD for
repeated versus novel faces and objects whereas no difference was found in TD (A. P. Key and
Corbett 2014). A final study found reduced P100 lateralization in the ASD group as compared to

10

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

controls (Luckhardt et al. 2017). Of these seven studies, three found effects across face and
objects, and four did not include non-face stimuli. As such, no studies found a face-stimulus
specific effect.

P100 Amplitude in ASD: Emotion
There were 13 studies of emotion processing in ASD that reported on P100 amplitude,
distributed across childhood, adolescence, and adulthood. Across all studies, P100 was
modulated similarly between diagnostic groups in response to emotional faces (Apicella et al.
2013; Akechi et al. 2010; M. Batty et al. 2011; Hileman et al. 2011; Luyster et al. 2017 [child
and adult]; O'Connor et al. 2005 [child and adult]; 2007; Wagner et al. 2013; T. K. Wong et al.
2008; Luckhardt et al. 2017; Yamasaki et al. 2017).

P100 Amplitude in SZ: Face
Similar to findings in ASD, most studies of face processing (14 of 18) reported
comparable P100 amplitudes to face stimuli between SZ and TD groups across a variety of
methodologies and sample compositions (Bediou et al. 2007; Kim et al. 2015; Colleen A Brenner
et al. 2015; Fukuta et al. 2014; Herrmann et al. 2004; Jetha et al. 2013; P. J. Johnston et al. 2005;
Jung et al. 2012; S.-H. Lee et al. 2010; Obayashi et al. 2009; Thoma et al. 2013; Turetsky et al.
2007; Wynn et al. 2008; Liu et al. 2016). Among studies reporting P100 amplitude differences,
three found attenuated P100 to faces in SZ groups (Caharel et al. 2007; Campanella et al. 2006;
Zhang et al. 2016), though Campanella (2006) found that this effect was specific to a group
displaying high SZ symptomatology (compared to TD and low-symptom SZ groups). One study
found the opposite effect, observing larger P100 amplitude to faces in the SZ group (Yang et al.

11

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

2017). In all four of the studies that found significant differences, participants were actively
attending to facial stimuli; twelve of the fourteen studies that found null results also included
active attention to stimuli. Importantly, only 2 of 18 studies included control (i.e., non-face)
stimuli, and neither of these studies reported differences between SZ and TD groups (Obayashi
et al. 2009; Wynn et al. 2008).

P100 Amplitude in SZ: Emotion
Out of 16 emotion-processing studies reporting P100 amplitude in SZ, 14 studies
reported no significant group differences in P100 amplitude as a function of the emotional
content of presented faces (P. J. Johnston et al. 2005; Fukuta et al. 2014; Colleen A Brenner et al.
2015; Caharel et al. 2007; Kim et al. 2015; Campanella et al. 2006; Jung et al. 2012; S.-H. Lee et
al. 2010; Obayashi et al. 2009; Thoma et al. 2013; Turetsky et al. 2007; Wynn et al. 2008; Zhang
et al. 2016; Yang et al. 2017). One study reported amplitude modulation by emotion in the TD
group but not in the SZ group (Bediou et al. 2007), and a second reported reduced P100
amplitude in SZ compared to controls for disgust, but not fear or happy faces (Yang et al 2017).
Jetha and colleagues (2013) reported that moderate shyness in SZ was associated with less
emotional reactivity as indicated by P100 amplitude. This finding suggests that differences in
P100 amplitude may mark alterations in emotion processing associated with specific symptom
dimensions. Taken together, these results suggest that, as in the ASD literature, P100 amplitude
does not specifically index alterations in face or emotion processing.

P100 Latency
P100 Latency in ASD: Face

12

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Almost two-thirds of studies (13 of 21) did not find significant differences between ASD
and TD groups regarding P100 latency to faces (J. C. McPartland et al. 2011; O'Connor et al.
2005 [child]; Apicella et al. 2013; Cygan et al. 2014; Hileman et al. 2011; O'Connor et al. 2007;
Wagner et al. 2013; T. K. Wong et al. 2008; Senju et al. 2005; Webb et al. 2010; Webb et al.
2012; Luckhardt et al. 2017; Luyster et al. 2017 [child]). Eight studies reported group differences
in response to facial stimuli. Two child and two adult studies reported increased latency to faces
in ASD groups compared to the TD group (M. Batty et al. 2011; O'Connor et al. 2005 [adult];
Neuhaus et al. 2016; Luyster et al. 2017 [adult]). Of note, both Luyster (2017) and O’Connor et
al.’s (2005) child sample did not show differences between groups despite using the same
methods as in their adult samples, where P100 latency delays were identified.. A single study
found shorter P100 latencies to faces in adults with ASD versus TD (Yamasaki et al. 2017). Two
other child studies reported group differences in lateralization, wherein P100 latency was faster
in the right versus left hemisphere in TD, but this effect was absent in ASD (Akechi et al. 2010;
Tye et al. 2013). A final study showed shorter left hemisphere P100 latencies present only in the
ASD group (Shen et al. 2016).

P100 Latency in ASD: Emotion
Twelve of thirteen studies of emotion processing in ASD did not report significant group
differences between TD and ASD groups in P100 latency sensitivity to emotion (Akechi et al.
2010; Apicella et al. 2013; Hileman et al. 2011; Luckhardt et al. 2017; Luyster et al. 2017 [child
and adult]; O'Connor et al. 2005 [child and adult]; 2007; Wagner et al. 2013; T. K. Wong et al.
2008; Yamasaki et al. 2017). However, Batty et al. (2011) reported that P100 was modulated by
emotion in TD children, but not in ASD.

13

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

P100 Latency in SZ: Face
Seven of 11 studies reporting P100 latency to face stimuli reported no significant
differences between SZ and TD groups (Herrmann et al. 2004; Campanella et al. 2006; Fukuta et
al. 2014; Kim et al. 2015; P. J. Johnston et al. 2005; Thoma et al. 2013; Liu et al. 2016). The
remaining studies reported longer P100 latency in SZ groups compared to TD groups (Caharel et
al. 2007; Obayashi et al. 2009; S.-H. Lee et al. 2010; Wynn et al. 2008). None of these results are
clearly face-specific, however; two studies did not include control stimuli (Caharel et al. 2007;
S.-H. Lee et al. 2010), and two found P100 latency delays in SZ across both face and control
stimuli (Obayashi et al. 2009; Wynn et al. 2008).

P100 Latency in SZ: Emotion
Out of nine studies, eight reported no difference between P100 latency in SZ and TD
groups in response to emotional faces (Caharel et al. 2007; Campanella et al. 2006; Fukuta et al.
2014; P. J. Johnston et al. 2005; Kim et al. 2015; Obayashi et al. 2009; Thoma et al. 2013; Wynn
et al. 2008). One study reported sex-specific diagnostic differences in emotion processing: in
females, P100 in the left hemisphere was delayed in SZ compared to TD when attending to
happy faces (S.-H. Lee et al. 2010). Moreover, longer latency to happy faces correlated with
more negative symptomatology in SZ females. In SZ males, there was no overall delay in P100
compared to the TD group, and longer latency correlated with better performance on a
behavioral detection task for happy versus fear faces.

N170 Amplitude

14

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

N170 Amplitude in ASD: Face
Since the initial report of N170 as a marker of atypical social perception in ASD (J.
McPartland et al. 2004), 28 studies have examined N170 amplitude to faces in individuals with
ASD, with 12 reporting differences in face processing by diagnosis. Of those 12, six studies (two
in children and four in adults) reported attenuated amplitude in ASD compared to TD (Cygan et
al. 2014; O. Churches et al. 2012b; O'Connor et al. 2005 [adult]; Tye et al. 2014; Webb et al.
2012; Groom et al. 2017). Six other studies reported differences in N170 response to faces
between ASD and TD groups, but these differences were not always evident in direct statistical
comparisons between groups (e.g., absence of lateralization in one group without demonstration
of a group by lateralization interaction). One such study of children reported a typical face
inversion effect in TD but the opposite effect in ASD (J. C. McPartland et al. 2011). Three
studies reported right hemisphere lateralization in TD but lack of lateralization in ASD (J. C.
McPartland et al. 2011; Tye et al. 2013; Webb et al. 2006). Three studies reported findings of
N170 amplitude differentiation between: face stimulus types in TD but not ASD (Akechi et al.
2010), active versus passive tasks in TD but not ASD (Owen Churches et al. 2010), and repeated
versus novel faces and objects in ASD but not TD (A. P. Key and Corbett 2014).
Most studies reporting correlative analyses demonstrated associations between N170
amplitude and autistic symptomatology or social behavior. More negative N170 amplitude to
inverted faces correlated with better face recognition in children with ASD (J. C. McPartland et
al. 2011) and better social skills in adults with ASD (Webb et al. 2012). Stronger overall N170
amplitude to faces was associated with more typical social behavior in TD children (though not
in the ASD group; (Hileman et al. 2011), and increased right lateralization was associated with
better social communication across both TD and ASD children (Tye et al. 2013).

15

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Sixteen of the 28 studies of N170 amplitude to faces in ASD (1 of children, 5 distributed
across childhood into adolescence, 2 of adolescents, 2 spanning adolescence into early
adulthood, and 6 of adults) did not find differences between diagnostic groups (Khorrami et al.
2013; O. Churches et al. 2012a; Grice et al. 2005; Wagner et al. 2013; J. McPartland et al. 2004;
Apicella et al. 2013; T. K. Wong et al. 2008; M. Batty et al. 2011; Senju et al. 2005; O'Connor et
al. 2007; Magnée et al. 2011; O'Connor et al. 2005 [child]; Hileman et al. 2011; Webb et al.
2010; Faja et al. 2016; Luckhardt et al. 2017). Approximately half of these studies did, however,
find differences in N170 latency, reported below. Of note, most of these studies did not instruct
participants to attend to the faces specifically but included non-face targets to monitor attention.
Only four of 16 studies with null results required participants to attend to faces. In contrast, all
but one study (Webb et al. 2010) that reported differences between ASD and TD groups required
participants to actively attend to stimuli. Given evidence that N170 amplitude is enhanced by
attention (Owen Churches et al. 2010; Mohamed et al. 2009), this finding suggests that
differentiation of N170 amplitude emerges when the task demands are most face-specific.

N170 Amplitude in ASD: Emotion
Eleven of 15 studies reported no significant difference in N170 amplitude between ASD
and TD groups during emotional face processing (Apicella et al. 2013; M. Batty et al. 2011;
Hileman et al. 2011; Magnée et al. 2011; O'Connor et al. 2005 [child and adult]; 2007; T. K.
Wong et al. 2008; Luckhardt et al. 2017; Luyster et al. 2017[child and adult]). The remaining
four studies reported group differences. In two of these studies, N170 amplitude was modulated
by emotion in TD groups but not in ASD groups (Akechi et al. 2010; Wagner et al. 2013). One
study found the opposite effect, showing N170 amplitude modulation by emotion only in the

16

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

ASD group (Faja et al. 2016). This last finding is consistent with one other finding in which
ASD groups with and without comorbid ADHD showed increased N170 amplitude to neutral
relative to fearful faces, whereas amplitude in the TD group was not modulated by emotional
valence (Tye et al. 2014). More negative N170 amplitude overall, as well as more negative
amplitude to fearful compared to neutral faces, correlated with better social communication skills
across both TD and ASD children (Tye et al. 2014). Contrary to patterns detected among face
processing findings, only one of these four studies yielding group differences required
participants to attend to the emotional valence of the stimuli; the other two required participants
to attend to non-social target stimuli. Likewise, four studies with null results tasked participants
with identifying the emotional valence of stimuli (O'Connor et al. 2005 [child and adult]; 2007;
T. K. Wong et al. 2008). Thus, the degree to which explicit demands for attention to emotion
may contribute to N170 amplitude alteration in ASD for emotion processing is less clear than for
face stimuli.

N170 Amplitude in SZ: Face
Twenty out of 28 studies investigating N170 amplitude to faces in adults with SZ
reported significant differences in face processing between diagnostic groups. In four of these
studies, amplitude to faces was smaller in SZ relative to TD, whereas amplitude to objects was
not significantly different between groups (Herrmann et al. 2004; Obayashi et al. 2009; Onitsuka
et al. 2006; Tsunoda et al. 2012). One study observed N170 attenuation in SZ across inverted
face and non-face images (Zheng et al. 2016). Another study showed right lateralization of N170
to low-spatial frequency compared to high spatial frequency of fearful faces in SZ but no
differentiation in TD groups (Kim et al. 2015). Fourteen additional studies report attenuated

17

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

N170 amplitude to faces in SZ relative to TD; however, across all these studies, findings were
not necessarily face-specific, as several lacked non-face control stimuli (Bediou et al. 2007;
Caharel et al. 2007; Campanella et al. 2006; Jetha et al. 2013; Jung et al. 2012; Kirihara et al.
2012; S.-H. Lee et al. 2010; Onitsuka et al. 2009; Turetsky et al. 2007; Zhang et al. 2016) and the
remainder showed main effects of group where N170 amplitude attenuation spanned both face
and non-face stimuli (Ibanez et al. 2012; Lynn and Salisbury 2008; Wynn et al. 2013; Liu et al.
2016).
A handful of studies reported correlations between greater N170 amplitude to faces and
higher global functioning (Obayashi et al. 2009), less positive SZ symptomatology (Campanella
et al. 2006), decreased shyness (Jetha et al. 2013), higher social competency (Tsunoda et al.
2012), and increased extraversion (Kirihara et al. 2012). Together, these studies provide strong
evidence for an association between more robust N170 response to faces and better social and
psychiatric functioning across both TD and SZ populations. Eight studies reported no significant
differences in N170 amplitude to faces between diagnostic groups (Akbarfahimi et al. 2013;
Colleen A Brenner et al. 2015; Komlosi et al. 2013; S. Lee et al. 2007; Ramos-Loyo et al. 2009;
Tso et al. 2015; Thoma et al. 2013; Wynn et al. 2008). However, one found emotion-specific
results that are detailed in the following section (Thoma et al. 2013), and the second found
decreased N170 differentiation to facial angle as compared to TD controls (Tso et al.
2015).These eight studies have comparable methodologies and group demographics to those
studies that do detect group differences.

N170 Amplitude in SZ: Emotion

18

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

A number of studies (10 of 22 suggest altered N170 amplitude during emotion
discrimination in SZ compared to TD (Tso et al. 2015; Thoma et al. 2013; Caharel et al. 2007;
Campanella et al. 2006; Lynn and Salisbury 2008; Jung et al. 2012; Turetsky et al. 2007; Zhang
et al. 2016; Kirihara et al. 2012; Ibanez et al. 2012). Four of these studies reported that TD
groups showed modulation of N170 amplitude based on emotional valence, whereas SZ groups
did not (Campanella et al. 2006; Ibanez et al. 2012; Kirihara et al. 2012; Lynn and Salisbury
2008). Three studies reported attenuated N170 amplitude in SZ compared to TD to specific
emotions, such as disgust, sadness, and happiness (Caharel et al. 2007; Jung et al. 2012; Turetsky
et al. 2007). One found that N170 amplitude was differentially modulated by emotion in SZ
relative to TD: whereas in TD it was larger for happy and fearful faces than for neutral faces, in
SZ it was larger for happy faces than for neutral or fearful (Zhang et al., 2016). Additionally,
reduced left hemisphere N170 amplitude to fearful faces in particular was correlated with
severity of blunted affect in patients. Two additional studies found group differences as a
function of more nuanced influences on emotion perception, including larger left lateralized
N170 amplitude in fearful vs. neutral averted-gaze faces in SZ (Tso et al. 2015), and enhanced
N170 amplitude in TD, but not SZ, when the emotion displayed in a stimulus differed from the
stimulus emotion proceeding it (Thoma et al. 2013).
Twelve studies investigating N170 amplitude reported no significant differences between
SZ and TD in this ERP component during emotion processing (Jetha et al. 2013; Bediou et al.
2007; Colleen A Brenner et al. 2015; S.-H. Lee et al. 2010; Obayashi et al. 2009; Kim et al.
2015; Wynn et al. 2013; Akbarfahimi et al. 2013; Komlosi et al. 2013; S. Lee et al. 2007;
Ramos-Loyo et al. 2009; Wynn et al. 2008). These studies have comparable population
demographics and methodologies to the studies above where differences were detected.

19

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

N170 Latency
There were 31 studies of ASD that reported N170 latency. Eighteen of these studies were
performed in children, and 13 were in adults. Findings below are separated by age.

N170 Latency in ASD: Face
Of the 18 studies investigating N170 latency during face processing in children with
ASD, eight reported atypical temporal processing in the ASD group. One study reported facespecific delays in the ASD group compared to the TD group (J. C. McPartland et al. 2011),
another reported delayed latency to faces compared to objects in the ASD group, contrasted with
faster latency to faces than objects in the TD group (Webb et al. 2006), and four studies found
slower N170 latency in ASD compared to TD groups across both face and non-face stimuli
(Khorrami et al. 2013; M. Batty et al. 2011; Hileman et al. 2011; Luyster et al. 2017 [child]). A
study by Gunji et al (2009) found these results when comparing a child ASD group to adult
controls but not to child controls. One study observed shorter N170 latencies in the left
hemisphere only in the ASD group across both social and nonsocial stimuli, (Shen et al. 2016);
this finding is in the opposite direction than others, indicating faster N170 latency in ASD. Ten
studies in children did not find significant between-group differences in N170 latency to faces
(Akechi et al. 2010; Tye et al. 2014; Apicella et al. 2013; O'Connor et al. 2005 [child]; Senju et
al. 2005; Grice et al. 2005; Tye et al. 2013; Wagner et al. 2013; T. K. Wong et al. 2008;
Luckhardt et al. 2017). There were no observable differences in methodology or group
characteristics to account for variations in study findings.

20

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

In adults, seven of 13 studies indicated atypical N170 latency in ASD groups. Across two
studies, faces elicited a slower N170 latency in ASD compared to TD, while between-group
differences in N170 latency to object images were not significant (J. McPartland et al. 2004;
O'Connor et al. 2007); an additional three studies also found N170 delays to faces, but there were
no non-social control stimuli in these experiments (O'Connor et al. 2005 [adult]; Yamasaki et al.
2017; Luyster et al. 2017 [adult]). Two studies suggest a relation between N170 latency and
clinical symptoms. McPartland et al (2004) found that, in ASD but not controls, slower N170
latency to both upright and inverted faces associated with better face memory, suggesting that
longer processing times may confer improved behavioral performance. Though Webb et al
(2012) did not find deficits in in N170 latency to upright faces relative to either houses or
inverted faces or replicate McPartland et al’s (2004) association between N170 latency with face
memory, faster N170 to upright versus inverted faces was related to both better social skills and
better face memory. Two studies reported that topographic differences in N170 latency between
ASD and TD. N170 latency to faces was faster medially than laterally in TD (Webb et al. 2012),
but trending towards faster laterally than medially in ASD (Webb et al. 2010). Finally, six
studies of adults with ASD found no significant between-group differences or differences in
lateralization in N170 latency to face stimuli (O. Churches et al. 2012a; O. Churches et al.
2012b; Magnée et al. 2011; Owen Churches et al. 2010; Cygan et al. 2014; Tseng et al. 2015). A
recent meta-analysis of face processing studies in ASD indicated that, on average, N170 latency
was delayed in ASD relative to TD (Kang et al. 2018).

N170 Latency in ASD: Emotion

21

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Fifteen of sixteen studies of children and adults converge in reporting no emotiondependent differences in N170 latency between individuals with ASD and TD (Akechi et al.
2010; Magnée et al. 2011; Apicella et al. 2013; M. Batty et al. 2011; Hileman et al. 2011;
O'Connor et al. 2005 [child and adult]; 2007; Wagner et al. 2013; T. K. Wong et al. 2008;
Luckhardt et al. 2017; Tseng et al. 2015; Yamasaki et al. 2017; Luyster et al. 2017 [child and
adult]). Seven of these studies were of children only, two studies included both child and adult
groups, and four studies only included adults. Just one study reported significant differences in
emotion perception: when taking ADHD diagnosis into account, Tye and colleagues (2014)
found a group by emotion interaction in which children with ASD showed a longer N170 latency
to angry faces than to neutral faces and a shorter latency to happy faces than to fearful faces,
whereas children with ASD and comorbid ADHD showed the opposite pattern and TD children
did not show any differences in N170 latency across emotions. This finding suggests that a crossdiagnostic approach to identifying neural indices of emotion processing may be more
informative than studies restricted to one clinical group.

N170 Latency in SZ: Face
Twelve of 17 studies reported no difference in N170 latency between diagnostic groups
in response to face stimuli (Campanella et al. 2006; Tso et al. 2015; Herrmann et al. 2004;
Tsunoda et al. 2012; S. Lee et al. 2007; P. J. Johnston et al. 2005; Kim et al. 2015; Lynn and
Salisbury 2008; Obayashi et al. 2009; Thoma et al. 2013; Wynn et al. 2008; Yang et al. 2017).
The remaining five studies found adults with SZ showed delayed N170 latency to faces
compared to TD controls. One of these studies found these results for both upright and inverted
faces (Zheng et al 2016) and showed that N170 latency correlated with both negative and general

22

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

psychiatric symptoms in ASZ patients. However, because the other four studies either had no
control stimuli (Caharel et al. 2007; Wynn et al. 2013; S.-H. Lee et al. 2010) or saw main effects
across both face and non-face stimuli (Akbarfahimi et al. 2013; S.-H. Lee et al. 2010; Caharel et
al. 2007), N170 delays in SZ are not necessarily face-specific.

N170 Latency in SZ: Emotion
Twelve of 14 studies of emotion processing reported no significant differences between
SZ and TD in N170 latency modulation to emotional faces (Campanella et al. 2006; Caharel et
al. 2007; S. Lee et al. 2007; P. J. Johnston et al. 2005; Kim et al. 2015; Tso et al. 2015; Lynn and
Salisbury 2008; Obayashi et al. 2009; Thoma et al. 2013; Wynn et al. 2008; Wynn et al. 2013;
Yang et al. 2017). Two studies reported a differential effect of emotional faces on N170 latency
in SZ versus TD. In a passive viewing study, adults with SZ showed a delayed N170 to fearful
faces relative to other emotional faces, whereas controls displayed the shortest latencies to
fearful faces (Akbarfahimi et al. 2013). Investigating gender differences, Lee et al. (2010)
reported emotion-specific differences between females, but not males, with SZ and TD: in the
right hemisphere, happy and fearful faces elicited a delayed N170 in females with SZ compared
to those with TD. Slower N170 latency to happy faces in females with SZ was also correlated
with increased expression of negative SZ symptomatology. An earlier study from the same group
reported faster N170 latency to happy and neutral faces was associated with increased positive
and negative SZ symptomatology, but found no significant differences between groups (S. Lee et
al. 2007); thus, examining gender-specific effects may clarify the nature of processing deficits
and relations with clinical symptoms.

23

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

N250 Amplitude
N250 Amplitude in ASD: Face
Two studies in adults with ASD reported on N250 amplitude, and both found significant,
yet conflicting, group differences. When viewing a series of neutral faces and instructed to attend
to a target face, relative to TD adults, adults with ASD showed reduced N250 amplitude to
targets (O. Churches et al. 2012a). Groups did not differ in their N250 response to non-target
faces. In contrast, Webb et al. (2010) reported enhanced N250 amplitude to both familiar and
unfamiliar face stimuli in the ASD group relative to TD adults. In the same study, N250
amplitude difference between familiar versus unfamiliar faces was right lateralized in ASD,
while it was uniform across hemispheres in the TD group. Differing methodologies across these
two studies may have elicited different main effects. The first used unfamiliar target faces in an
active viewing task demanding attention and facial memory; the second used familiar faces in a
passive viewing task. Of note, (Webb et al. 2010) also reported that increased right lateralization
of N250 to familiar versus unfamiliar faces in the ASD group correlated with lower ADOS
scores in communication and social domains.

N250 Amplitude in ASD: Emotion
There were no studies of emotion processing in ASD that reported N250 amplitude.

N250 Amplitude in SZ: Face
Three of seven studies of SZ measuring N250 amplitude to faces reported group
differences. Two of these studies reported attenuated N250 in SZ groups relative to TD groups to
both face and non-face stimuli (Wynn et al. 2013; Wynn et al. 2008). These studies used the

24

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

same methodology and the authors noted that while their TD groups were different across the
two studies, their SZ groups were highly overlapping. A third investigated sex differences and
reported larger N250 amplitudes in males versus females with SZ when attending to faces; this
sex difference was absent in TD (Jung et al. 2012). Overall, however, no between group (SZ
versus TD) differences were significant. The remaining four studies did not find significant
differences in N250 amplitude between groups (S.-H. Lee et al. 2010; Kim et al. 2015; Colleen A
Brenner et al. 2015; Turetsky et al. 2007).

N250 Amplitude in SZ: Emotion
Of the seven studies reported above, all used emotional stimuli, but none found group
differences in N250 amplitude as a function of the emotional valence of faces.

N250 Latency
N250 Latency in ASD
There were no studies of face or emotion processing in individuals with ASD that
reported N250 latency.

N250 Latency in SZ
There were five studies of face and emotion processing in SZ that reported N250 latency;
however, none found significant group differences, either to faces overall or to emotional faces
specifically (S.-H. Lee et al. 2010; Kim et al. 2015; Wynn et al. 2013; Wynn et al. 2008; Yang et
al. 2017).

25

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

P300 Amplitude
P300 Amplitude in ASD: Face
Three of four studies of ASD reporting on P300 amplitude detected differences between
diagnostic groups, albeit in conflicting directions. In two studies, familiar faces elicited greater
P300 than unfamiliar faces in TD children, whereas this effect was absent in children with ASD
(Gunji et al. 2009; Gunji et al. 2013). In contrast, (A. P. Key and Corbett 2014) found enhanced
P300 amplitude to repeated faces in children with ASD relative to the TD group. P300 amplitude
was also greater to repeated faces than to neutral stimuli in ASD but not TD. However, in this
study, the same pattern was seen for repeated objects, suggesting the enhanced P300 effect
during stimulus repetition was not necessarily face-specific. When measuring neural response to
averted and direct eye gaze, there were no significant differences in P300 amplitude between
children with ASD and TD to either stimulus type (Senju et al. 2005).

P300 Amplitude in ASD: Emotion
There were no studies of emotion processing in ASD that reported P300 amplitude.

P300 Amplitude in SZ: Face
Five of nine studies of SZ reporting on P300 amplitude detected diagnostic differences
during reception of facial stimuli. In three of these studies, P300 amplitude was attenuated in SZ
relative to TD, although these results were not face-specific (Ramos-Loyo et al. 2009; Turetsky
et al. 2007; Ueno et al. 2004). However, greater P300 amplitude was correlated with lower
negative SZ symptomatology (Ueno et al. 2004) and better emotion identification (Turetsky et al.
2007), suggesting its relevance for social symptomatology specifically. In a study of sex

26

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

differences, while P300 amplitude was equivalent in TD males and females, females with SZ
showed a larger P300 amplitude to faces than males with SZ; overall, there were no between
group differences with regards to P300 amplitude (S.-H. Lee et al. 2010). Finally, a study
investigating effects of anti-psychotic medication reported that, relative to TD controls, the SZ
group showed attenuated P300 amplitude to faces, but only after exposure to 12 months of
medication (Mori et al. 2012). Four studies reported no group differences in P300 amplitude to
faces (Bediou et al. 2007; Kim et al. 2015; P. J. Johnston et al. 2005; Jung et al. 2012). There
were no clear patterns among results to indicate methodological or sample differences
accounting for this variability.

P300 Amplitude in SZ: Emotion
Two of nine studies of emotion processing reported significant group differences in P300
amplitude to emotional faces in SZ. When observing images of infant faces and objects, TD
adults showed the largest P300 amplitude to a crying infant face and the smallest amplitude to a
happy face (Ueno et al. 2004), suggesting that an infant’s distress is most salient to TD adults. In
the SZ group as a whole, P300 amplitude was not modulated by the emotional valence of the
infant face; however, when the SZ group was divided by subtype, adults with paranoid SZ
showed the same pattern as the TD group, while those with non-paranoid SZ showed an inverted
effect, with larger P300 amplitude to happy than to crying faces. In a second study, fearful adult
faces elicited greater P300 amplitude than neutral faces in TD adults tasked with attending to
emotional valence. There was no modulation of the P300 response by emotion in the SZ group
(Bediou et al. 2007). The remaining seven studies found no significant group differences in
emotion processing as measured by P300 amplitude (P. J. Johnston et al. 2005; Kim et al. 2015;

27

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Mori et al. 2012; Ramos-Loyo et al. 2009; S.-H. Lee et al. 2010; Turetsky et al. 2007; Jung et al.
2012).

P300 Latency
P300 Latency in ASD
Two face processing studies in ASD reported on P300 latency; neither found group
differences (Gunji et al. 2013; Senju et al. 2005). No emotion processing studies in ASD reported
on P300 latency.

P300 Latency in SZ
Three of five studies of face and emotion processing that reported on P300 latency in SZ
found group differences. Two studies found delayed P300 in SZ compared to TD in response to
all stimuli, regardless of whether stimuli were faces or objects, or of the emotional valence of
face stimuli (S.-H. Lee et al. 2010; Ueno et al. 2004). Latency differences were, however,
modulated by paranoia. Specifically, adults with non-paranoid SZ showed longer P300 latency to
faces than TD adults, whereas individuals with paranoid SZ did not differ from the TD group
(Ueno et al. 2004). This pattern parallels the P300 amplitude finding from the same study. In a
third study, adults with SZ who had been medicated for 12 months showed delayed P300 latency
to happy—but not neutral or sad—faces relative to TD adults (Mori et al. 2012). In the same
study, a slowing effect of medication on P300 latency in SZ was apparent: adults with SZ
showed slower P300 latency after 12 months of medication compared to their responses while
medication-naïve and medicated for a shorter, 3-month interval. Two studies did not report group
differences in P300 latency (P. J. Johnston et al. 2005; Kim et al. 2015).

28

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

DISCUSSION
Here we have reviewed the results of studies reporting on P100, N170, N250, and P300
ERP components in response to neutral and emotional face stimuli in individuals with autism
spectrum disorders and schizophrenia. Our review sheds light on patterns of replicability in the
literature and highlights multiple areas marked by inconsistent findings and in need of further
research.
For the P100, which reflects early stages of visual processing, there is little evidence of
amplitude or latency alterations in ASD across face or emotion processing. Scattered findings
suggest that P100 amplitude may index neural processes relevant to ASD, but primary P100
deficits are unlikely. As with face processing, P100 latency does not seem to be a reliable
indicator of emotion processing differences between ASD and TD groups. While P100 latency
may index variability in speed of low-level visual processing across groups, it does not capture
behavioral differences in face or emotion processing between ASD and TD groups. In
schizophrenia, there is similarly little evidence for P100 amplitude or latency alterations being
effective indices of face or emotion processing deficits.
The N170, a well-studied index of face processing, was the component most consistently
demonstrating atypical neural response across the two neurodevelopmental disorders. In ASD
studies, approximately 40% of all findings reported diminished amplitude and delayed latency to
faces in ASD compared to TD; however, several of these studies did not include non-face control
stimuli or found effects that were not specific to faces. Two-thirds of the studies that found
significant differences required active attention to stimuli, whereas three-quarters of the studies
that found no significant differences were passive viewing tasks. This distinction suggests that

29

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

N170 deficits in ASD are particularly prominent when attentional demands are involved. There
was little evidence of N170 amplitude or latency reliably indexing deficits in in emotion
processing in ASD. In studies of SZ, evidence for N170 latency delays to faces and differential
N170 latency by emotion was mixed. However, there was strong evidence of diminished N170
amplitude to both face and non-face stimuli, indicating differences by diagnosis in early visual –
but not necessarily face-specific – processing. There was also strong evidence of diminished
N170 amplitude in SZ from studies of emotion processing. In general, N170 amplitude was
differentially responsive to neutral versus emotionally-valenced faces in TD groups, whereas SZ
groups did not tend to show this specialization. This pattern may suggest that processing the
emotional content of faces, rather than just faces themselves, may be most specifically atypical in
SZ. In contrast, early structural processing of faces in general, more so than differentiation of
particular emotions, may be more consistently impacted in ASD.
Across the N250 and P300 components, there are too few studies in ASD to draw
conclusions despite promising group differences. Further research comparing N250 and P300
amplitude in ASD and TD, along with re-analysis of previously published studies that did not
include these components in their original analysis, may help elucidate the neural underpinnings
of atypical face and emotion perception. Many studies that measured N250 and P300 amplitude
found group differences in face perception, indicating that both components may be understudied
but promising leads for indexing social cognition deficits.
In SZ, there is a slightly larger literature, but evidence for diminished N250 and P300
amplitude to face stimuli is mixed. N250 amplitude was attenuated to face, but not emotion,
stimuli in approximately 40% of SZ studies, but N250 latency appears to be unaffected. P300
amplitude to face stimuli appear to be more reliably affected, and P300 amplitude may both mark

30

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

symptom levels and be affected by medication treatments. Though findings from a small sample
of studies suggest P300 latency may reliably index cognitive processing deficits for both face
and emotion stimuli in SZ, the relative paucity of literature measuring P300 latency makes it
difficult to identify this component as a sensitive neural marker of social cognition differences.
To expand both ASD and SZ literatures, given that ongoing, continuous EEG is recorded
before segmentation for ERP analyses, it is likely that pre-existing data from studies reporting on
earlier components (e.g., P100 and/or N170) could provide an opportunity to analyze N250 and
P300 components to test for group differences during face and emotion processing. Such reanalysis of existing data may provide a quick and efficient mechanism to address outstanding
questions of whether later, attentional neural responses are impacted in the context of reception
of facial communication, particularly in ASD where existing data is more limited.

Accounting for Variability Across Studies
Variation in methodologies – such as stimulus design and subject factors – may account
for some of the inconsistencies among studies. Differences in low-level visual characteristics,
such as luminance, contrast, and color, can produce significantly different waveforms (Bruno
Rossion and Caharel 2011; Rousselet and Pernet 2011), yet most studies did not provide specific
details on the low-level visual aspects of their stimulus set. Likewise, there were many different
types of stimuli across studies. For example, while all studies included face stimuli, the nature of
these faces varied (i.e., upright vs. inverted, familiar vs. unfamiliar, neutral vs. emotional, child
vs. adult). Moreover, faces were sometimes the sole stimuli within a study paradigm, whereas
other studies included non-face conditions. Study design, such as the use of blocking by stimulus
type (e.g., face vs. non-face; neutral vs. emotional faces) vs. randomly interspersing all stimuli,

31

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

can affect ERPs due to repetition and habituation effects (Shlomo Bentin and Peled 1990;
Ravden and Polich 1999), which few studies examined. Importantly, many studies claiming
group differences in face processing did not include non-face control stimuli, preventing
conclusions regarding the specificity of reported findings to faces.
Participant tasks varied widely across studies, from passive viewing, to providing buttonpress responses to occasional attentional control trials not included in later analyses, to providing
task-relevant verbal responses to each trial. Variability in task design yields inconsistencies in
the nature and burden of the cognitive load placed on the participant and may manipulate how
intensely and/or consistently the participant is attending to the stimuli. Unfortunately, there were
very few instances in which clear patterns of replicable vs. less consistent findings were revealed
as a function of particular aspects of stimulus type, task design, or demands for participant
attention and task engagement. Finally, no studies in this review monitored participant gaze with
eye-tracking; thus, while participants were ostensibly looking toward the screen (based on
experimenter observations or attention monitoring tasks), gaze was not directly measured.
Subject factors also may have contributed to variability across studies. For example, not
all studies matched clinical and control groups by IQ, making it difficult to ascertain which
observed differences were due to diagnosis versus may have been driven by differences in
cognitive functioning. Moreover, most studies did not account for sex when matching controls,
and this variable may drive certain effects or correlations in ASD and SZ groups, as highlighted
by several studies (Jung et al. 2012; S.-H. Lee et al. 2010). ERP components indexing face
perception change in amplitude and latency over the lifespan (Roxane J Itier and Taylor 2004b;
M. Batty et al. 2011), yet, when comparing studies of ASD and SZ, we are limited by the fact
that most studies of ASD are in children, while all studies of SZ are in adults. Participants in

32

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

clinical groups, especially SZ, were often medicated with psychoactive agents. In their
longitudinal investigation of the effects of antipsychotic use on ERP waveforms, Mori and
colleagues (Mori et al. 2012) reported changes in patients’ P300 amplitude and latency between
drug-naïve and medicated time-points, and another study reported a positive correlation between
medication dosage and P300 amplitude to emotional compared to neutral faces (Komlosi et al.
2013). Many studies did not report on the medication status of patients, and still others reported
medication status but did not discuss testing for correlations between ERP waveforms and
medication dose or controlling for medication status. Thus, effects of medication differences
among participants and between clinical and control groups could also contribute to variability in
findings across studies.
Variability in clinical profiles within participant samples could also have affected results.
With respect to subject characterization, many studies did not report confirming ASD or SZ
diagnoses in the context of the study with an ADOS (for ASD; Lord et al. 2012) or SCID (SCID,
for SZ; First 1995). Lack of rigorous characterization of participants may mean that some
clinical groups were not composed entirely of participants with gold-standard ASD or SZ
diagnoses and/or may have included individuals falling short of diagnostic threshold. Many
studies did not report level or severity or particular profiles of symptomatology within patient
samples, despite the fact that ASD and SZ samples tend to be phenotypically heterogeneous.
With disorders that are behaviorally-defined (and which likely lump individuals with multiple
different etiological origins based on their symptoms; Happé et al. 2006; Insel 2010), regrouping participants by subtypes or symptom profile can be a helpful way of finding patterns.
Conducting correlations and regressions accounting for symptom levels on well-validated
measures like the ADOS (for ASD; Lord et al. 2012) and Positive and Negative Syndrome Scale

33

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

(PANSS, for SZ; Kay et al. 1987), as well as broader measures of symptoms that cut across
diagnoses, may help further clarify the association between clinical profiles and neural
processing abnormalities. For example, when dividing their SZ group into paranoid and nonparanoid subgroups, Ueno et al. (2004) found that the paranoid subgroup showed similar P300
amplitude and latency to the TD group, whereas the non-paranoid subgroup differed in P300
amplitude to emotional faces an in latency to all stimuli. When looking at the SZ group as a
whole, however, these differences were obscured.
Related to the need to carefully characterize and account for variation in symptom
profiles among participants is the need to recruit large study samples in order to capture
heterogeneity and enable statistical analyses that are adequately powered to detect effects using
covariates and regressions. Among the studies highlighted in this review, 50% of studies in ASD
(18 of 36) and approximately 25% of those in schizophrenia (8 of 33) had fewer than 15
participants per group. Moreover, whereas nearly 25% of SZ studies (8 of 33) included 30 or
more participants per group, only 5% of ASD studies (2 of 36) had sample sizes this large. Small
samples are particularly vulnerable to spurious or non-generalizable findings (Button et al.
2013). Thus, it may be the case that some of the inconsistencies across studies relate to the
relatively small sample sizes, particularly in the ASD literature. Moving forward, recruiting large
samples to enable examination of more homogenous subsets of participants and to allow for
evaluation of the association between ERP components and clinical traits measured in a
continuous fashion might help to explain differences among studies where samples can be quite
variable.

Considerations for future research

34

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

This review of electrophysiological studies of face perception in ASD and SZ indicates
that the N170, and possibly N250 and P300, hold promise as biomarkers indexing the integrity of
social perceptual systems across neurodevelopmental disorders and for providing clues about
underlying neural dysfunction within and across disorders. Several caveats for future research
emerge from these findings.
First, this review makes clear that alterations in the highlighted ERP indices are not
diagnostically specific. Similar patterns of atypical processing at identical components were
observed in both ASD and SZ. This suggests that, consistent with the RDoC framework, it may
be most useful to evaluate the underlying neural bases of neurodevelopmental disorders in terms
of specific, dimensionally-measured processes related to function and dysfunction
transdiagnostically, rather than designing studies around a particular diagnostic category.
Although the reviewed evidence does not make a reliable case that any one particular ERP
component may be a consistent diagnostic biomarker, correlations with symptomatology and key
associated features (e.g., emotion recognition) indicate promise with respect to other areas of
biomarker development. These include classifying individuals into subgroups relevant to
treatment selection (stratification biomarkers), demonstrating the influence of an intervention on
a targeted neural system (target engagement biomarkers), or offering short-term indication of
intervention effects on symptoms or underlying neural systems (early efficacy biomarkers; James
C McPartland 2016). Our review focused specifically on ASD and schizophrenia; however,
social cognition and these ERP components are germane to multiple other psychiatric diagnoses
(Feuerriegel et al. 2015). Increased focus on transdiagnostic samples can provide greater clarity
regarding the information these ERP indices provide about the neural processes underlying
neurodevelopmental and psychiatric disorders.

35

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

As the variability in findings across existing studies makes clear, it is necessary to
carefully consider individual differences in participant characteristics, such as age, both within
and across diagnostic groups. Differences in findings reported within ASD between child and
adult samples and cross-diagnostically between studies of ASD and SZ may reflect differences in
age-related characteristics of particular samples. For example, some alterations in neural
responses may be more prominent in adults, reflecting later onset difficulties or premature
developmental plateaus, whereas some may be most notable in young children and resolve over
time. Future research on markers of social perception must either constrain age ranges to reduce
variability, conduct studies with sufficient statistical power to co-analyze age effects, or examine
participant samples longitudinally to study the divergence of particular neural responses as they
relate to emergence or amelioration of symptoms over time. Though age effects are less germane
to schizophrenia, a disorder most commonly occurring in adulthood, whether alterations in ERP
response to face stimuli are present in prodromal phases is an important question. Moreover, as
other factors such as cognitive ability are also demonstrated to influence ERP indices, these
characteristics must be considered and controlled, either statistically or through reduction of
sample heterogeneity. Finally, prioritization of exploring hypotheses in large participant samples,
either within individual studies or by harnessing “big data” sources, such as the National Institute
of Mental Health’s RDoC or NDAR data repositories (data-archive.nimh.nih.gov), will
maximize the probability of detecting robust, clinically meaningful, and replicable findings.
Studies will benefit from increased consistency and methodological rigor in both
experimental design and equipment. Based on existing data, it cannot be determined to what
degree differences in EEG data recording and processing methods (e.g., high versus low
impedance EEG systems, electrode density, choice of scalp topography for component

36

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

extraction) contributed to the diversity of results. Similarly, research on social perception must
include appropriate control stimuli. In the research reviewed here, in some cases inference was
limited by omission of non-face stimuli, stimuli matched for low-level visual features, and, in
studies of emotion, both neutral/natural and emotional faces. Because many studies focused
exclusively on social stimuli, it was often impossible to determine whether reported anomalies
reflected specific difficulties in social brain circuitry or more general problems with object
perception.
Many of these principles have been recognized by researchers and funding agencies, and
within-disorder studies incorporating these features are in progress. Though not in the context of
electrophysiological markers, the schizophrenia field recognized more than a decade ago with
the MATRICS initiative the importance of identifying reliable markers and developing
standardized batteries of cognitive tests for use in diagnosis and assessing treatment outcomes
(Marder and Fenton 2004). The autism field has more recently begun promoting a similar
agenda, with increased focus on the potential utility of electrophysiological biomarkers for
capturing heterogeneity and predicting treatment. To this end, the Autism Biomarkers
Consortium for Clinical Trials (www.asdbiomarkers.org) is evaluating a battery of EEG and eyetracking social-communicative biomarkers in a large, rigorously characterized sample of children
with ASD, with careful attention to participant characteristics, meticulous control of stimulus,
task, and EEG recording parameters across sites, and a longitudinal component to provide
information about developmental effects. Likewise, the European Autism Interventions — A
Multicentre Study for Developing New Medications (EU-AIMS; Murphy and Spooren 2012), is
investigating similar markers, as well as those from additional biomarker domains, such as
functional magnetic resonance imaging (fMRI). Although these initiatives are focused on single

37

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

disorders, their scope and thoroughness are likely to advance understanding of the practical
utility of ERP indices of face perception for developing novel interventions and guiding clinical
trials.
Finally, the scarcity of studies including multiple diagnostic categories within the same
project highlights the urgent need for transdiagnostic work if we are to better understand the
specificity versus universality of particular alterations in brain responses to individuals with
neurodevelopmental disorders. Thus, moving forward, it is imperative to include both individuals
with ASD and SZ – and potentially those with other neurodevelopmental or psychiatric disorders
or subthreshold traits – within a single study sample and to measure dimensional traits associated
with both disorders across all participants. Studying children or adults at biological risk of ASD
or SZ (i.e., siblings, parents, children of affected individuals) to see whether those at risk show
altered neural response and/or behavior would also provide important information about
intermediate phenotypes and risk states as they relate to brain functioning and clinical profiles. In
addition, studies with a longitudinal design and an intervention (targeting either face or emotion
processing circuits) may help better parse out causally relevant effects across diagnostic
categories.
In summary, both the inconsistencies in findings within ASD and SZ samples and the
overlap between findings across ASD and SZ samples make a clear case for the need to consider
symptomatology in a dimensional fashion when designing studies and analyzing results in search
of biologically meaningful and behaviorally relevant markers of face and emotion processing.
Taking a cross-diagnostic, RDoC approach allows for both direct comparison across diagnoses
and more detailed sub-grouping or correlations featuring diagnostically cross-cutting,
categorically-agnostic phenotypic traits. In addition, this type of study would also allow for

38

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

clinical characterization to be made along a continuum, rather than imposing an artificial
dichotomy (i.e., clinical vs. TD). By taking this approach, future research can address whether
and how each categorical disorder (or subset of individuals within a disorder) shows a unique
neural signature of altered reception of facial communication, versus whether some alterations in
ERP markers of face and emotion processing are reflective of broad clinical impairment in social
functioning versus diagnosis or trait-specific pathology. In so doing, research will begin to make
more effective headway toward understanding the complexity of distinct versus overlapping
etiologies of associated neurodevelopmental disorders, which will in turn position the field to
accumulate the precision and replicability of findings needed to develop more targeted treatment
approaches.

39

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

ACKNOWLEDGEMENTS
Funding: Authors’ work was supported by the National institutes of Health (R01MH107426, R01-MH100173, R01-MH103831, RC1-MH088971, 1DP5-OD012109, the Brain
and Behavior Research Foundation (NARSAD Young Investigator Award), and the Autism
Science Foundation (Accelerator Grant).

CONFLICT-OF-INTEREST STATEMENT
The authors declare that they have no conflict of interest.

40

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

REFERENCES

Addington, J., & Addington, D. (1998). Facial affect recognition and information processing in
schizophrenia and bipolar disorder. Schizophr Res, 32(3), 171-181.
Akbarfahimi, M., Tehrani-Doost, M., & Ghassemi, F. (2013). Emotional Face Perception in
Patients with Schizophrenia: an Event-Related Potential Study. Neurophysiology, 45(3),
249-257, doi:10.1007/s11062-013-9363-8.
Akechi, H., Senju, A., Kikuchi, Y., Tojo, Y., Osanai, H., & Hasegawa, T. (2010). The effect of
gaze direction on the processing of facial expressions in children with autism spectrum
disorder: an ERP study. [Research Support, Non-U.S. Gov't]. Neuropsychologia, 48(10),
2841-2851, doi:10.1016/j.neuropsychologia.2010.05.026.
Apicella, F., Sicca, F., Federico, R. R., Campatelli, G., & Muratori, F. (2013). Fusiform gyrus
responses to neutral and emotional faces in children with autism spectrum disorders: a
high density ERP study. Behav Brain Res, 251, 155-162, doi:10.1016/j.bbr.2012.10.040.
Association, A. P. (2013). Diagnostic and statistical manual of mental disorders (5th ed.).
Arlington, VA: American Pyschiatric Publishing.
Balconi, M., & Pozzoli, U. (2008). Event-related oscillations (ERO) and event-related potentials
(ERP) in emotional face recognition. Int J Neurosci, 118(10), 1412-1424, doi:902420168
[pii]
Baron-Cohen, S., Wheelwright, S., Hill, J., Raste, Y., & Plumb, I. (2001). The "Reading the
Mind in the Eyes" Test revised version: a study with normal adults, and adults with
Asperger syndrome or high-functioning autism. J Child Psychol Psychiatry, 42(2), 241251.

41

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Batty, M., Meaux, E., Wittemeyer, K., Roge, B., & Taylor, M. J. (2011). Early processing of
emotional faces in children with autism: An event-related potential study. J Exp Child
Psychol, 109(4), 430-444, doi:10.1016/j.jecp.2011.02.001.
Batty, M., & Taylor, M. J. (2003). Early processing of the six basic facial emotional expressions.
Cognitive Brain Research, 17(3), 613-620.
Bediou, B., Henaff, M. A., Bertrand, O., Brunelin, J., d'Amato, T., Saoud, M., et al. (2007).
Impaired fronto-temporal processing of emotion in schizophrenia. Neurophysiol Clin,
37(2), 77-87, doi:10.1016/j.neucli.2007.04.001.
Bellack, A. S., Blanchard, J. J., & Mueser, K. T. (1996). Cue availability and affect perception in
schizophrenia. Schizophr Bull, 22(3), 535-544.
Bentin, S., Allison, T., Puce, A., Perez, E., & McCarthy, G. (1996). Electrophysiological studies
of face perception in humans. Journal of Cognitive Neuroscience, 8(6), 551-565.
Bentin, S., & Peled, B.-S. (1990). The contributionof task-related factors to ERP repetition
effects at short and long lags. [journal article]. Memory & Cognition, 18(4), 359-366,
doi:10.3758/bf03197125.
Blau, V. C., Maurer, U., Tottenham, N., & McCandliss, B. D. (2007). The face-specific N170
component is modulated by emotional facial expression. Behavioral and Brain
Functions, 3(7), 1-13.
Brenner, C. A., Rumak, S. P., & Burns, A. M. (2015). Facial emotion memory in schizophrenia:
From encoding to maintenance-related EEG. Clinical Neurophysiology.
Brenner, C. A., Rumak, S. P., Burns, A. M., & Kieffaber, P. D. (2014). The role of encoding and
attention in facial emotion memory: an EEG investigation. Int J Psychophysiol, 93(3),
398-410, doi:10.1016/j.ijpsycho.2014.06.006.

42

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Button, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., et al. (2013).
Power failure: why small sample size undermines the reliability of neuroscience. Nature
Reviews Neuroscience, 14(5), 365-376.
Caharel, S., Bernard, C., Thibaut, F., Haouzir, S., Di Maggio-Clozel, C., Allio, G., et al. (2007).
The effects of familiarity and emotional expression on face processing examined by
ERPs in patients with schizophrenia. Schizophr Res, 95(1–3), 186-196,
doi:http://dx.doi.org/10.1016/j.schres.2007.06.015.
Campanella, S., Montedoro, C., Streel, E., Verbanck, P., & Rosier, V. (2006). Early visual
components (P100, N170) are disrupted in chronic schizophrenic patients: an eventrelated potentials study. Neurophysiol Clin, 36(2), 71-78,
doi:10.1016/j.neucli.2006.04.005.
Carretié, L., Iglesias, J., Garcia, T., & Ballesteros, M. (1997). N300, P300 and the emotional
processing of visual stimuli. Electroencephalography and clinical Neurophysiology,
103(2), 298-303.
Carretié, L., Martin-Loeches, M., Hinojosa, J. A., & Mercado, F. (2001). Emotion and attention
interaction studied through event-related potentials. J Cogn Neurosci, 13(8), 1109-1128,
doi:10.1162/089892901753294400.
Churches, O., Baron-Cohen, S., & Ring, H. (2012a). The psychophysiology of narrower face
processing in autism spectrum conditions. Neuroreport, 23(6), 395-399,
doi:10.1097/WNR.0b013e3283525bc8.
Churches, O., Damiano, C., Baron-Cohen, S., & Ring, H. (2012b). Getting to know you: the
acquisition of new face representations in autism spectrum conditions. Neuroreport,
23(11), 668-672, doi:10.1097/WNR.0b013e3283556658.

43

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Churches, O., Wheelwright, S., Baron-Cohen, S., & Ring, H. (2010). The N170 is not modulated
by attention in autism spectrum conditions. Neuroreport, 21(6), 399-403.
Cloutier, M., Sanon, A. M., Guerin, A., Nitulescu, R., Ramanakumar, A. V., Kamat, S. A., et al.
(2016). The economic burden of schizophrenia in the United States in 2013. The Journal
of clinical psychiatry.
Conroy, M. A., & Polich, J. (2007). Affective valence and P300 when stimulus arousal level is
controlled. Cognition and emotion, 21(4), 891-901.
Conty, L., N'Diaye, K., Tijus, C., & George, N. (2007). When eye creates the contact! ERP
evidence for early dissociation between direct and averted gaze motion processing.
[Research Support, Non-U.S. Gov't]. Neuropsychologia, 45(13), 3024-3037,
doi:10.1016/j.neuropsychologia.2007.05.017.
Cristino, A., Williams, S., Hawi, Z., An, J., Bellgrove, M., Schwartz, C., et al. (2014).
Neurodevelopmental and neuropsychiatric disorders represent an interconnected
molecular system. Molecular psychiatry, 19(3), 294-301.
Cygan, H. B., Tacikowski, P., Ostaszewski, P., Chojnicka, I., & Nowicka, A. (2014). Neural
correlates of own name and own face detection in autism spectrum disorder. PLoS One,
9(1), e86020, doi:10.1371/journal.pone.0086020.
Davis, P. J., & Gibson, M. G. (2000). Recognition of posed and genuine facial expressions of
emotion in paranoid and nonparanoid schizophrenia. J Abnorm Psychol, 109(3), 445-450.
Dawson, G., Webb, S. J., & McPartland, J. (2005). Understanding the nature of face processing
impairment in autism: insights from behavioral and electrophysiological studies. Dev
Neuropsychol, 27(3), 403-424, doi:10.1207/s15326942dn2703_6.

44

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Donchin, E. (2008). The context for updating the "context updating" model of the P300.
Psychophysiology, 45, S12-S12.
Donchin, E., & Coles, M. G. H. (1988). Is the P300 Component a Manifestation of Context
Updating. Behavioral and Brain Sciences, 11(3), 357-374.
Donchin, E., & Coles, M. G. H. (1998). Context updating and the P300. Behavioral and Brain
Sciences, 21(1), 152-+.
Dowd, E. C., & Barch, D. M. (2010). Anhedonia and emotional experience in schizophrenia:
neural and behavioral indicators. Biol Psychiatry, 67(10), 902-911,
doi:10.1016/j.biopsych.2009.10.020.
Eimer, M. (2000). Effects of face inversion on the structural encoding and recognition of faces:
Evidence from event-related brain potentials. Cognitive Brain Research, 10(1), 145-158.
Eimer, M., & Holmes, A. (2002). An ERP study on the time course of emotional face processing.
Neuroreport, 13(4), 427-431.
Faja, S., Dawson, G., Aylward, E., Wijsman, E. M., & Webb, S. J. (2016). Early event-related
potentials to emotional faces differ for adults with autism spectrum disorder and by
serotonin transporter genotype. Clin Neurophysiol, 127(6), 2436-2447,
doi:10.1016/j.clinph.2016.02.022.
Ferrari, V., Bradley, M. M., Codispoti, M., & Lang, P. J. (2010). Detecting Novelty and
Significance. Journal of Cognitive Neuroscience, 22(2), 404-411.
Feuerriegel, D., Churches, O., Hofmann, J., & Keage, H. A. (2015). The N170 and face
perception in psychiatric and neurological disorders: A systematic review. Clin
Neurophysiol, 126(6), 1141-1158, doi:10.1016/j.clinph.2014.09.015.
First, M. B. (1995). Structured clinical interview for the DSM (SCID): Wiley Online Library.

45

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Fukuta, M., Kirino, E., Inoue, R., & Arai, H. (2014). Response of schizophrenic patients to
dynamic facial expressions: An event-related potentials study. Neuropsychobiology,
70(1), 10-22.
Gaebel, W., & Wolwer, W. (1992). Facial expression and emotional face recognition in
schizophrenia and depression. Eur Arch Psychiatry Clin Neurosci, 242(1), 46-52.
Gordon, E., Coyle, S., Anderson, J., Healey, P., Cordaro, J., Latimer, C., et al. (1992). Eye
movement response to a facial stimulus in schizophrenia. Biol Psychiatry, 31(6), 626629.
Gosling, A., & Eimer, M. (2011). An event-related brain potential study of explicit face
recognition. [Research Support, Non-U.S. Gov't]. Neuropsychologia, 49(9), 2736-2745,
doi:10.1016/j.neuropsychologia.2011.05.025.
Grice, S. J., Halit, H., Farroni, T., Baron-Cohen, S., Bolton, P., & Johnson, M. H. (2005). Neural
correlates of eye-gaze detection in young children with autism. Cortex, 41(3), 342-353.
Groom, M. J., Kochhar, P., Hamilton, A., Liddle, E. B., Simeou, M., & Hollis, C. (2017).
Atypical Processing of Gaze Cues and Faces Explains Comorbidity between Autism
Spectrum Disorder (ASD) and Attention Deficit/Hyperactivity Disorder (ADHD). J
Autism Dev Disord, 47(5), 1496-1509, doi:10.1007/s10803-017-3078-4.
Gunji, A., Goto, T., Kita, Y., Sakuma, R., Kokubo, N., Koike, T., et al. (2013). Facial identity
recognition in children with autism spectrum disorders revealed by P300 analysis: a
preliminary study. Brain Dev, 35(4), 293-298, doi:10.1016/j.braindev.2012.12.008.
Gunji, A., Inagaki, M., Inoue, Y., Takeshima, Y., & Kaga, M. (2009). Event-related potentials of
self-face recognition in children with pervasive developmental disorders. Brain Dev,
31(2), 139-147, doi:10.1016/j.braindev.2008.04.011.

46

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Happé, F., Ronald, A., & Plomin, R. (2006). Time to give up on a single explanation for autism.
Nature Neuroscience, 9(10), 1218-1220.
Herrmann, M. J., Ehlis, A. C., Ellgring, H., & Fallgatter, A. J. (2005). Early stages (P100) of face
perception in humans as measured with event-related potentials (ERPs). J Neural
Transm, 112(8), 1073-1081, doi:10.1007/s00702-004-0250-8.
Herrmann, M. J., Ellgring, H., & Fallgatter, A. J. (2004). Early-stage face processing dysfunction
in patients with schizophrenia. Am J Psychiatry, 161(5), 915-917.
Hileman, C. M., Henderson, H., Mundy, P., Newell, L., & Jaime, M. (2011). Developmental and
individual differences on the P1 and N170 ERP components in children with and without
autism. Dev Neuropsychol, 36(2), 214-236, doi:10.1080/87565641.2010.549870.
Hobson, R. P. (1986). The autistic child's appraisal of expressions of emotion. J Child Psychol
Psychiatry, 27(3), 321-342.
Ibanez, A., Riveros, R., Hurtado, E., Gleichgerrcht, E., Urquina, H., Herrera, E., et al. (2012).
The face and its emotion: right N170 deficits in structural processing and early emotional
discrimination in schizophrenic patients and relatives. Psychiatry Res, 195(1-2), 18-26,
doi:10.1016/j.psychres.2011.07.027.
Insel, T. R. (2010). Rethinking schizophrenia. Nature, 468(7321), 187-193.
Itier, R. J., & Taylor, M. J. (2002). Inversion and contrast polarity reversal affect both encoding
and recognition processes of unfamiliar faces: a repetition study using ERPs.
Neuroimage, 15(2), 353-372.
Itier, R. J., & Taylor, M. J. (2004a). Effects of repetition and configural changes on the
development of face recognition processes. Developmental Science, 7(4), 469-487.

47

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Itier, R. J., & Taylor, M. J. (2004b). Effects of repetition learning on upright, inverted and
contrast-reversed face processing using ERPs. Neuroimage, 21(4), 1518-1532.
Itier, R. J., & Taylor, M. J. (2004c). N170 or N1? Spatiotemporal differences between object and
face processing using ERPs. Cerebral cortex, 14(2), 132-142.
Itier, R. J., & Taylor, M. J. (2004d). Source analysis of the N170 to faces and objects.
Neuroreport, 15(8), 1261-1265.
Jacques, C., Jonas, J., Maillard, L., Colnat‐Coulbois, S., Koessler, L., & Rossion, B. (2018). The
inferior occipital gyrus is a major cortical source of the face‐evoked N170: Evidence
from simultaneous scalp and intracerebral human recordings. Human brain mapping.
Jetha, M. K., Zheng, X., Goldberg, J. O., Segalowitz, S. J., & Schmidt, L. A. (2013). Shyness
and emotional face processing in schizophrenia: an ERP study. Biol Psychol, 94(3), 562574, doi:10.1016/j.biopsycho.2013.10.001.
Johnston, P. J., Stojanov, W., Devir, H., & Schall, U. (2005). Functional MRI of facial emotion
recognition deficits in schizophrenia and their electrophysiological correlates. Eur J
Neurosci, 22(5), 1221-1232, doi:10.1111/j.1460-9568.2005.04294.x.
Johnston, V. S., Miller, D. R., & Burleson, M. H. (1986). Multiple P3s to emotional stimuli and
their theoretical significance. Psychophysiology, 23(6), 684-694.
Joseph, R. M., & Tanaka, J. (2003). Holistic and part-based face recognition in children with
autism. J Child Psychol Psychiatry, 44(4), 529-542.
Jung, H. T., Kim, D. W., Kim, S., Im, C. H., & Lee, S. H. (2012). Reduced source activity of
event-related potentials for affective facial pictures in schizophrenia patients. Schizophr
Res, 136(1-3), 150-159, doi:10.1016/j.schres.2011.10.023.

48

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Kang, E., Keifer, C. M., Levy, E. J., Foss-Feig, J. H., McPartland, J. C., & Lerner, M. D. (2018).
Atypicality of the N170 event-related potential in autism spectrum disorder: a metaanalysis. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, 3(8), 657666.
Kanwisher, N. (2001). Faces and places: of central (and peripheral) interest. Nature
Neuroscience, 4(5), 455-456.
Kaufmann, J. M., Schweinberger, S. R., & MikeBurton, A. (2009). N250 ERP correlates of the
acquisition of face representations across different images. Journal of Cognitive
Neuroscience, 21(4), 625-641.
Kay, S. R., Flszbein, A., & Opfer, L. A. (1987). The positive and negative syndrome scale
(PANSS) for schizophrenia. Schizophr Bull, 13(2), 261.
Kesler-West, M. L., Andersen, A. H., Smith, C. D., Avison, M. J., Davis, C. E., Kryscio, R. J., et
al. (2001). Neural substrates of facial emotion processing using fMRI. Cognitive Brain
Research, 11(2), 213-226, doi:http://dx.doi.org/10.1016/S0926-6410(00)00073-2.
Kestenbaum, R., & Nelson, C. A. (1992). Neural and behavioral correlates of emotion
recognition in children and adults. Journal of experimental child psychology, 54(1), 1-18.
Key, A. P., & Corbett, B. A. (2014). ERP responses to face repetition during passive viewing: a
nonverbal measure of social motivation in children with autism and typical development.
Dev Neuropsychol, 39(6), 474-495.
Key, A. P. F., Dove, G. O., & Maguire, M. J. (2005). Linking brainwaves to the brain: an ERP
primer. Dev Neuropsychol, 27(2), 183-215.

49

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khorrami, A., Tehrani-Doost, M., & Esteky, H. (2013). Comparison between Face and Object
Processing in Youths with Autism Spectrum Disorder: An event related potentials study.
2013, 8(4), 179-187.
Kim, D.-W., Shim, M., Song, M. J., Im, C.-H., & Lee, S.-H. (2015). Early visual processing
deficits in patients with schizophrenia during spatial frequency-dependent facial affect
processing. Schizophr Res, 161(2), 314-321.
Kington, J. M., Jones, L. A., Watt, A. A., Hopkin, E. J., & Williams, J. (2000). Impaired eye
expression recognition in schizophrenia. J Psychiatr Res, 34(4-5), 341-347.
Kirihara, K., Kasai, K., Tada, M., Nagai, T., Kawakubo, Y., Yamasaki, S., et al. (2012).
Neurophysiological impairment in emotional face processing is associated with low
extraversion in schizophrenia. Prog Neuropsychopharmacol Biol Psychiatry, 37(2), 270275, doi:10.1016/j.pnpbp.2012.02.012.
Klin, A., Jones, W., Schultz, R., Volkmar, F., & Cohen, D. (2002). Visual fixation patterns
during viewing of naturalistic social situations as predictors of social competence in
individuals with autism. Arch Gen Psychiatry, 59(9), 809-816.
Klin, A., Sparrow, S. S., de Bildt, A., Cicchetti, D. V., Cohen, D. J., & Volkmar, F. R. (1999). A
normed study of face recognition in autism and related disorders. Journal of Autism &
Developmental Disorders, 29(6), 499-508.
Komlosi, S., Csukly, G., Stefanics, G., Czigler, I., Bitter, I., & Czobor, P. (2013). Fearful face
recognition in schizophrenia: an electrophysiological study. Schizophr Res, 149(1-3),
135-140, doi:10.1016/j.schres.2013.06.044.
Kozak, M. J., & Cuthbert, B. N. (2016). The NIMH research domain criteria initiative:
Background, issues, and pragmatics. Psychophysiology, 53(3), 286-297.

50

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Kuefner, D., De Heering, A., Jacques, C., Palmero-Soler, E., & Rossion, B. (2009). Early
visually evoked electrophysiological responses over the human brain (P1, N170) show
stable patterns of face-sensitivity from 4 years to adulthood. Front Hum Neurosci, 3.
Labuschagne, I., Croft, R., Phan, K., & Nathan, P. (2010). Augmenting serotonin
neurotransmission with citalopram modulates emotional expression decoding but not
structural encoding of moderate intensity sad facial emotional stimuli: an event-related
potential (ERP) investigation. Journal of Psychopharmacology, 24(8), 1153-1164.
Law Smith, M. J., Montagne, B., Perrett, D. I., Gill, M., & Gallagher, L. (2010). Detecting subtle
facial emotion recognition deficits in high-functioning Autism using dynamic stimuli of
varying intensities. [Research Support, Non-U.S. Gov't]. Neuropsychologia, 48(9), 27772781, doi:10.1016/j.neuropsychologia.2010.03.008.
Lee, S., Kim, E., Kim, S., Im, W., Seo, H., Han, S., et al. (2007). Facial affect perception and
event-related potential N170 in schizophrenia: a preliminary study. CLINICAL
PSYCHOPHARMACOLOGY AND NEUROSCIENCE, 5(2), 76.
Lee, S.-H., Kim, E.-Y., Kim, S., & Bae, S.-M. (2010). Event-related potential patterns and
gender effects underlying facial affect processing in schizophrenia patients. Neuroscience
Research, 67(2), 172-180, doi:http://dx.doi.org/10.1016/j.neures.2010.03.001.
Lewis, S. F., & Garver, D. L. (1995). Treatment and diagnostic subtype in facial affect
recognition in schizophrenia. J Psychiatr Res, 29(1), 5-11.
Liu, T., Pinheiro, A. P., Zhao, Z., Nestor, P. G., McCarley, R. W., & Niznikiewicz, M. (2016).
Simultaneous face and voice processing in schizophrenia. Behav Brain Res, 305, 76-86,
doi:10.1016/j.bbr.2016.01.039.

51

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Lord, C., DiLavore, P. C., & Gotham, K. (2012). Autism diagnostic observation schedule:
Western Psychological Services Torrance, CA.
Luckhardt, C., Kroger, A., Cholemkery, H., Bender, S., & Freitag, C. M. (2017). Neural
Correlates of Explicit Versus Implicit Facial Emotion Processing in ASD. J Autism Dev
Disord, 47(7), 1944-1955, doi:10.1007/s10803-017-3141-1.
Luo, W., Feng, W., He, W., Wang, N., & Luo, Y. (2009). Three stages of facial expression
processing: ERP study with rapid serial visual presentation. Neuroimage, doi:S10538119(09)00997-5 [pii]
10.1016/j.neuroimage.2009.09.018.
Luyster, R. J., Bick, J., Westerlund, A., & Nelson, C. A., 3rd (2017). Testing the effects of
expression, intensity and age on emotional face processing in ASD. Neuropsychologia,
doi:10.1016/j.neuropsychologia.2017.06.023.
Lynn, S. K., & Salisbury, D. F. (2008). Attenuated modulation of the N170 ERP by facial
expressions in schizophrenia. Clin EEG Neurosci, 39(2), 108-111.
Maestro, S., Muratori, F., Cavallaro, M. C., Pei, F., Stern, D., Golse, B., et al. (2002). Attentional
skills during the first 6 months of age in autism spectrum disorder. J Am Acad Child
Adolesc Psychiatry, 41(10), 1239-1245.
Magnée, M. J., de Gelder, B., van Engeland, H., & Kemner, C. (2011). Multisensory integration
and attention in autism spectrum disorder: evidence from event-related potentials. PLoS
One, 6(8), e24196, doi:10.1371/journal.pone.0024196.
Maher, S., Mashhoon, Y., Ekstrom, T., Lukas, S., & Chen, Y. (2016). Deficient cortical facesensitive N170 responses and basic visual processing in schizophrenia. Schizophr Res,
170(1), 87-94.

52

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Mangun, G. R. (1995). Neural mechanisms of visual selective attention. Psychophysiology,
32(1), 4-18.
Marder, S. R., & Fenton, W. (2004). Measurement and treatment research to improve cognition
in schizophrenia: NIMH MATRICS initiative to support the development of agents for
improving cognition in schizophrenia. Schizophr Res, 72(1), 5-9.
Massie, H. N. (1978). Blind ratings of mother-infant interaction in home movies of prepsychotic
and normal infants. Am J Psychiatry, 135(11), 1371-1374.
McMahon, C. M., & Henderson, H. A. (2015). Error‐monitoring in response to social stimuli in
individuals with higher‐functioning Autism Spectrum Disorder. Dev Sci, 18(3), 389-403.
McPartland, J., Dawson, G., Webb, S. J., Panagiotides, H., & Carver, L. J. (2004). Event-related
brain potentials reveal anomalies in temporal processing of faces in autism spectrum
disorder. J Child Psychol Psychiatry, 45(7), 1235-1245, doi:10.1111/j.14697610.2004.00318.x.
McPartland, J. C. (2016). Considerations in biomarker development for neurodevelopmental
disorders. Current opinion in neurology, 29(2), 118-122.
McPartland, J. C., Wu, J., Bailey, C. A., Mayes, L. C., Schultz, R. T., & Klin, A. (2011).
Atypical neural specialization for social percepts in autism spectrum disorder. Soc
Neurosci, 6(5-6), 436-451, doi:10.1080/17470919.2011.586880.
Mitchell, K. J. (2011). The genetics of neurodevelopmental disease. Current Opinion in
Neurobiology, 21(1), 197-203, doi:http://dx.doi.org/10.1016/j.conb.2010.08.009.
Mohamed, T. N., Neumann, M. F., & Schweinberger, S. R. (2009). Perceptual load manipulation
reveals sensitivity of the face-selective N170 to attention. Neuroreport, 20(8), 782-787.

53

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Mori, K., Morita, K., Shoji, Y., Matsuoka, T., Fujiki, R., & Uchimura, N. (2012). State and trait
markers of emotionally charged visual event‐related potentials (P300) in drug‐naïve
schizophrenia. Psychiatry and Clinical Neurosciences, 66(4), 261-269.
Morrison, R. L., Bellack, A. S., & Mueser, K. T. (1988). Deficits in facial-affect recognition and
schizophrenia. Schizophr Bull, 14(1), 67-83.
Mueser, K. T., Doonan, R., Penn, D. L., Blanchard, J. J., Bellack, A. S., Nishith, P., et al. (1996).
Emotion recognition and social competence in chronic schizophrenia. J Abnorm Psychol,
105(2), 271-275.
Müller, V. I., Kellermann, T. S., Seligman, S. C., Turetsky, B. I., & Eickhoff, S. B. (2012).
Modulation of affective face processing deficits in schizophrenia by congruent emotional
sounds. Social cognitive and affective neuroscience, nss107.
Murphy, D., & Spooren, W. (2012). EU-AIMS: a boost to autism research. Nature Reviews Drug
Discovery, 11(11), 815.
Neuhaus, E., Jones, E. J., Barnes, K., Sterling, L., Estes, A., Munson, J., et al. (2016). The
Relationship Between Early Neural Responses to Emotional Faces at Age 3 and Later
Autism and Anxiety Symptoms in Adolescents with Autism. J Autism Dev Disord, 46(7),
2450-2463, doi:10.1007/s10803-016-2780-y.
Ninomiya, H., Onitsuka, T., Chen, C. H., Sato, E., & Tashiro, N. (1998). P300 in response to the
subject's own face. Psychiatry and Clinical Neurosciences, 52(5), 519-522.
O'Connor, K., Hamm, J. P., & Kirk, I. J. (2005). The neurophysiological correlates of face
processing in adults and children with Asperger's syndrome. Brain Cogn, 59(1), 82-95,
doi:10.1016/j.bandc.2005.05.004.

54

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

O'Connor, K., Hamm, J. P., & Kirk, I. J. (2007). Neurophysiological responses to face, facial
regions and objects in adults with Asperger's syndrome: an ERP investigation. Int J
Psychophysiol, 63(3), 283-293, doi:10.1016/j.ijpsycho.2006.12.001.
Obayashi, C., Nakashima, T., Onitsuka, T., Maekawa, T., Hirano, Y., Hirano, S., et al. (2009).
Decreased spatial frequency sensitivities for processing faces in male patients with
chronic schizophrenia. Clin Neurophysiol, 120(8), 1525-1533,
doi:10.1016/j.clinph.2009.06.016.
Onitsuka, T., Ninomiya, H., & Sato, E. (2001). The effect of subject's own face on visual P300 in
schizophrenia. Biol Psychiatry, 49(8), 133S-133S.
Onitsuka, T., Niznikiewicz, M. A., Spencer, K. M., Frumin, M., Kuroki, N., Lucia, L. C., et al.
(2006). Functional and structural deficits in brain regions subserving face perception in
schizophrenia. Am J Psychiatry, 163(3), 455-462, doi:10.1176/appi.ajp.163.3.455.
Onitsuka, T., Spencer, K. M., Lucia, L. C., Shenton, M. E., McCarley, R. W., & Niznikiewicz,
M. A. (2009). Abnormal asymmetry of the face n170 repetition effect in male patients
with chronic schizophrenia. Brain Imaging Behav, 3(3), 240-245, doi:10.1007/s11682009-9066-3.
Osterling, J. A., & Dawson, G. (1994). Early recognition of children with autism: A study of first
birthday home videotapes. Journal of Autism & Developmental Disorders, 24(3), 247257.
Pelphrey, K. A., Sasson, N. J., Reznick, J. S., Paul, G., Goldman, B. D., & Piven, J. (2002).
Visual scanning of faces in autism. J Autism Dev Disord, 32(4), 249-261.
Phillips, M. L., & David, A. S. (1997). Visual scan paths are abnormal in deluded
schizophrenics. Neuropsychologia, 35(1), 99-105.

55

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Picton, T. (1995). P300 - Review and Reconciliation. Psychophysiology, 32, S8-S8.
Picton, T. W. (1992). The P300 Wave of the Human Event-Related Potential. Journal of Clinical
Neurophysiology, 9(4), 456-479.
Polich, J., Friedman, D., Donchin, E., Johnson, R., Polich, J., & Picton, T. (1995). 30 Years of
P300. Psychophysiology, 32, S7-S7.
Ramos-Loyo, J., Gonzalez-Garrido, A. A., Sanchez-Loyo, L. M., Medina, V., & Basar-Eroglu,
C. (2009). Event-related potentials and event-related oscillations during identity and
facial emotional processing in schizophrenia. Int J Psychophysiol, 71(1), 84-90,
doi:10.1016/j.ijpsycho.2008.07.008.
Ravden, D., & Polich, J. (1999). On P300 measurement stability: habituation, intra-trial block
variation, and ultradian rhythms. Biol Psychol, 51(1), 59-76,
doi:http://dx.doi.org/10.1016/S0301-0511(99)00015-0.
Rossion, B., & Caharel, S. (2011). ERP evidence for the speed of face categorization in the
human brain: Disentangling the contribution of low-level visual cues from face
perception. Vision research, 51(12), 1297-1311.
Rossion, B., Gauthier, I., Tarr, M. J., Despland, P., Bruyer, R., Linotte, S., et al. (2000). The
N170 occipito‐temporal component is delayed and enhanced to inverted faces but not to
inverted objects: an electrophysiological account of face‐specific processes in the human
brain. Neuroreport, 11(1), 69-72.
Rossion, B., Joyce, C. A., Cottrell, G. W., & Tarr, M. J. (2003). Early lateralization and
orientation tuning for face, word, and object processing in the visual cortex. Neuroimage,
20(3), 1609-1624.

56

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Rousselet, G. A., & Pernet, C. R. (2011). Quantifying the time course of visual object processing
using ERPs: it's time to up the game. Frontiers in psychology, 2, 107.
Sadeh, B., Podlipsky, I., Zhdanov, A., & Yovel, G. (2010). Event‐related potential and functional
MRI measures of face‐selectivity are highly correlated: A simultaneous ERP‐fMRI
investigation. Human brain mapping, 31(10), 1490-1501.
Sato, W., Kochiyama, T., Yoshikawa, S., & Matsumura, M. (2001). Emotional expression boosts
early visual processing of the face: ERP recording and its decomposition by independent
component analysis. Neuroreport, 12(4), 709-714.
Schultz, R. T. (2005). Developmental deficits in social perception in autism: the role of the
amygdala and fusiform face area. Int J Dev Neurosci, 23(2-3), 125-141,
doi:10.1016/j.ijdevneu.2004.12.012.
Schweinberger, S. R., Pickering, E. C., Jentzsch, I., Burton, A. M., & Kaufmann, J. M. (2002).
Event-related brain potential evidence for a response of inferior temporal cortex to
familiar face repetitions. Cognitive Brain Research, 14(3), 398-409.
Senju, A., Tojo, Y., Yaguchi, K., & Hasegawa, T. (2005). Deviant gaze processing in children
with autism: an ERP study. Neuropsychologia, 43(9), 1297-1306,
doi:10.1016/j.neuropsychologia.2004.12.002.
Shen, I. H., Lin, S. C., Wu, Y. Y., & Chen, C. L. (2016). An Event-Related Potential Study on
the Perception and the Recognition of Face, Facial Features, and Objects in Children
With Autism Spectrum Disorders. Percept Mot Skills, doi:10.1177/0031512516681694.
Shibata, T., Nishijo, H., Tamura, R., Miyamoto, K., Eifuku, S., Endo, S., et al. (2002).
Generators of visual evoked potentials for faces and eyes in the human brain as
determined by dipole localization. Brain Topogr, 15(1), 51-63.

57

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Spitzer, R. L., & Endicott, J. (1979). Schedule for affective disorders and schizophrenia, SADS:
New York State Psychiatric Institute, Department of Research Assessment and Training.
Streit, M., Ioannides, A. A., Liu, L., Wolwer, W., Dammers, J., Gross, J., et al. (1999).
Neurophysiological correlates of the recognition of facial expressions of emotion as
revealed by magnetoencephalography. Brain Res Cogn Brain Res, 7(4), 481-491,
doi:S0926641098000482 [pii].
Streit, M., Wolwer, W., Brinkmeyer, J., Ihl, R., & Gaebel, W. (2001). EEG-correlates of facial
affect recognition and categorisation of blurred faces in schizophrenic patients and
healthy volunteers. Schizophr Res, 49(1-2), 145-155.
Tanaka, J. W., Curran, T., Porterfield, A. L., & Collins, D. (2006). Activation of preexisting and
acquired face representations: the N250 event-related potential as an index of face
familiarity. Journal of Cognitive Neuroscience, 18(9), 1488-1497.
Taylor, M. J., Edmonds, G. E., McCarthy, G., & Allison, T. (2001). Eyes first! Eye processing
develops before face processing in children. Neuroreport, 12(8), 1671-1676.
Thoma, P., Soria Bauser, D., Norra, C., Brune, M., Juckel, G., & Suchan, B. (2013). Do you see
what I feel? - Electrophysiological correlates of emotional face and body perception in
schizophrenia. Clin Neurophysiol, doi:10.1016/j.clinph.2013.10.046.
Tseng, Y.-L., Yang, H. H., Savostyanov, A. N., Chien, V. S. C., & Liou, M. (2015). Voluntary
attention in Asperger's syndrome: Brain electrical oscillation and phase-synchronization
during facial emotion recognition. Research in Autism Spectrum Disorders, 13–14, 3251, doi:https://doi.org/10.1016/j.rasd.2015.01.003.
Tso, I. F., Calwas, A. M., Chun, J., Mueller, S. A., Taylor, S. F., & Deldin, P. J. (2015). Altered
attentional and perceptual processes as indexed by N170 during gaze perception in

58

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

schizophrenia: Relationship with perceived threat and paranoid delusions. J Abnorm
Psychol, 124(3), 519.
Tsunoda, T., Kanba, S., Ueno, T., Hirano, Y., Hirano, S., Maekawa, T., et al. (2012). Altered
face inversion effect and association between face N170 reduction and social dysfunction
in patients with schizophrenia. Clin Neurophysiol, 123(9), 1762-1768,
doi:10.1016/j.clinph.2012.01.024.
Turetsky, B. I., Kohler, C. G., Indersmitten, T., Bhati, M. T., Charbonnier, D., & Gur, R. C.
(2007). Facial emotion recognition in schizophrenia: when and why does it go awry?
Schizophr Res, 94(1-3), 253-263, doi:10.1016/j.schres.2007.05.001.
Tye, C., Battaglia, M., Bertoletti, E., Ashwood, K. L., Azadi, B., Asherson, P., et al. (2014).
Altered neurophysiological responses to emotional faces discriminate children with ASD,
ADHD and ASD+ADHD. Biol Psychol, doi:10.1016/j.biopsycho.2014.08.013.
Tye, C., Mercure, E., Ashwood, K. L., Azadi, B., Asherson, P., Johnson, M. H., et al. (2013).
Neurophysiological responses to faces and gaze direction differentiate children with
ASD, ADHD and ASD+ADHD. Dev Cogn Neurosci, 5, 71-85,
doi:10.1016/j.dcn.2013.01.001.
Ueno, T., Morita, K., Shoji, Y., Yamamoto, M., Yamamoto, H., & Maeda, H. (2004).
Recognition of facial expression and visual P300 in schizophrenic patients: differences
between paranoid type patients and non-paranoid patients. Psychiatry Clin Neurosci,
58(6), 585-592, doi:10.1111/j.1440-1819.2004.01307.x.
Wagner, J. B., Hirsch, S. B., Vogel-Farley, V. K., Redcay, E., & Nelson, C. A. (2013). Eyetracking, autonomic, and electrophysiological correlates of emotional face processing in

59

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

adolescents with autism spectrum disorder. J Autism Dev Disord, 43(1), 188-199,
doi:10.1007/s10803-012-1565-1.
Webb, S. J., Dawson, G., Bernier, R., & Panagiotides, H. (2006). ERP evidence of atypical face
processing in young children with autism. J Autism Dev Disord, 36(7), 881-890,
doi:10.1007/s10803-006-0126-x.
Webb, S. J., Jones, E. J., Merkle, K., Murias, M., Greenson, J., Richards, T., et al. (2010).
Response to familiar faces, newly familiar faces, and novel faces as assessed by ERPs is
intact in adults with autism spectrum disorders. Int J Psychophysiol, 77(2), 106-117,
doi:10.1016/j.ijpsycho.2010.04.011.
Webb, S. J., Merkle, K., Murias, M., Richards, T., Aylward, E., & Dawson, G. (2012). ERP
responses differentiate inverted but not upright face processing in adults with ASD. Soc
Cogn Affect Neurosci, 7(5), 578-587, doi:10.1093/scan/nsp002.
Wolwer, W., Brinkmeyer, J., Stroth, S., Streit, M., Bechdolf, A., Ruhrmann, S., et al. (2012).
Neurophysiological correlates of impaired facial affect recognition in individuals at risk
for schizophrenia. Schizophr Bull, 38(5), 1021-1029, doi:10.1093/schbul/sbr013.
Wong, T., Fung, P., McAlonan, G., & Chua, S. (2009). Spatiotemporal dipole source localization
of face processing ERPs in adolescents: a preliminary study. Behavioral and Brain
Functions, 5(1), 16, doi:10.1186/1744-9081-5-16.
Wong, T. K., Fung, P. C., Chua, S. E., & McAlonan, G. M. (2008). Abnormal spatiotemporal
processing of emotional facial expressions in childhood autism: dipole source analysis of
event-related potentials. Eur J Neurosci, 28(2), 407-416, doi:10.1111/j.14609568.2008.06328.x.

60

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Wynn, J. K., Jahshan, C., Altshuler, L. L., Glahn, D. C., & Green, M. F. (2013). Event-related
potential examination of facial affect processing in bipolar disorder and schizophrenia.
Psychol Med, 43(1), 109-117, doi:10.1017/s0033291712001006.
Wynn, J. K., Lee, J., Horan, W. P., & Green, M. F. (2008). Using event related potentials to
explore stages of facial affect recognition deficits in schizophrenia. Schizophr Bull, 34(4),
679-687, doi:10.1093/schbul/sbn047.
Yamasaki, T., Maekawa, T., Miyanaga, Y., Takahashi, K., Takamiya, N., Ogata, K., et al.
(2017). Enhanced Fine-Form Perception Does Not Contribute to Gestalt Face Perception
in Autism Spectrum Disorder. PLoS One, 12(2), e0170239,
doi:10.1371/journal.pone.0170239.
Yang, C., Zhang, T., Li, Z., Heeramun-Aubeeluck, A., Liu, N., Huang, N., et al. (2017). Changes
in event-related potentials in patients with first-episode schizophrenia and their siblings.
BMC Psychiatry, 17(1), 20, doi:10.1186/s12888-016-1189-7.
Yovel, G., Sadeh, B., Podlipsky, I., Hendler, T., & Zhdanov, A. (2008). The face-selective ERP
component (N170) is correlated with the face-selective areas in the fusiform gyrus (FFA)
and the superior temporal sulcus (fSTS) but not the occipital face area (OFA): a
simultaneous fMRI-EEG study. Journal of Vision, 8(6), 401-401, doi:10.1167/8.6.401.
Zhang, D., Zhao, Y., Liu, Y., & Tan, S. (2016). Perception of the duration of emotional faces in
schizophrenic patients. Scientific Reports, 6.
Zheng, Y., Li, H., Ning, Y., Ren, J., Wu, Z., Huang, R., et al. (2016). Sluggishness of early-stage
face processing (N170) is correlated with negative and general psychiatric symptoms in
schizophrenia. Frontiers in human neuroscience, 10, 615.

61

medRxiv preprint doi: https://doi.org/10.1101/19013003; this version posted November 27, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

FIGURE CAPTIONS
Table 1. Participant characterization and ERP methods for all studies reviewed. Angry (A),
Attention Deficit-Hyperactivity Disorder group (ADHD), amplitude (amp), Autism Spectrum
Disorder group (ASD), disgusted (D), emotion (emo), fear (F), face-only effect (fo; study does
not include non-face stimuli), happy (H), latency (lat), ashamed (M), neutral (N), negative (neg),
not face-specific effect (nfs; effect across face and non-face stimuli), object (obj), positive (pos),
surprised (R), sad (S), schizophrenia group (SZ), typically developing group (TD). Note:
“Targets” were not included in analyses unless repeated in cell.

Table 2. ERP results from all reviewed studies. Angry (A), Attention Deficit-Hyperactivity
Disorder group (ADHD), amplitude (amp), Autism Spectrum Disorder group (ASD), disgusted
(D), emotion (emo), fear (F), face-only effect (fo; study does not include non-face stimuli),
happy (H), latency (lat), ashamed (M), neutral (N), negative (neg), not face-specific effect (nfs;
effect across face and non-face stimuli), object (obj), positive (pos), surprised (R), sad (S),
schizophrenia group (SZ), typically developing group (TD), positive correlation (+; larger
magnitude or faster latency correlated with greater performance or fewer symptoms), negative
correlation (-; larger magnitude or faster latency correlated with poorer performance or more
symptoms. Note: for negative-going components, smaller amplitude indicates greater magnitude.

Fig 1 Number of studies reporting significant versus null findings across all studies, with all face
processing effects summarized in Figure 1a and all emotion-related effects summarized in Figure
1b. Latency (lat), amplitude (amp), significant differences between groups (sig), comparable
values between groups (null)

62

Task
Author, year
ASD: Face
Processing
Churches et al,
2012a
Churches et al.,
2010

Active: find target
Active: find target

Churches et al.,
2012b

Active: find target

Cygan et al., 2014

Active: respond to
all stimuli

Grice et al., 2005

Passive

ASD/SZ group:
mean age
(years), range,
SD, n

Characterization and
behavioral measures

N faces
Target: face identity
N faces; chairs
Target: repeated stimuli
N faces; objects; face-like
objects
Target: flowers
Own/close
other's/celebrity/unfamilia
r faces
Own/close
other's/celebrity/unfamilia
r names

31.8; SD=6.9;
n=11
31.4; SD=6.7;
n=13

Clinician diagnosis, IQ
test
Clinician diagnosis,
WAIS-III

30.6; SD=6.2;
n=10

N faces with direct or
averted gaze

Stimuli

Face w/ left or right gaze
shift (center gazing image
followed by left or right
gazing image)
Familiar, unfamiliar, self,
scrambled, object
Own/mother's/unfamiliar
faces; objects
Block 1 Target: own face
Block 2 Target: mother's
face
Block 3 Target:
unfamiliar face
Block 4 Target: object
Test 1: N faces (1
repeating, 50 novel);
houses (1 repeating, 50
novel)
Target: cartoon face
Re-test: 3 weeks later

Control group
matched by

Medications

Age, IQ

--

Age, IQ

--

Clinician diagnosis, IQ
test

Age, IQ

--

20.4; r=17-27;
SD=2.8; n=23

ADOS, ADI-R, WAISR

Age, IQ,
handedness

--

5.08; r=42-87;
SD=1.0; n=10

Clinician diagnosis,
CARS; ADOS & ADIR if needed

Age, sex

--

12.52; SD=2.36;
r=8-15; n=10

DAWBA, DSM-IV,
ADOS, SCQ, WASI,

Age, IQ, sex,

No nonstimulant
medication

10.8; SD=2.9;
n=8

DSM-IV, WISC

Age, sex,
handedness,

--

8.0; SD=1.2; n=9

Clinician diagnosis,
WISC-III

Age, sex,
handedness, IQ

--

10.76; SD=1.5;
n=13

ADOS, WASI, SCQ

Age

None

Age, sex

No
antipsychotic
meds

Age, sex, IQ,
handedness

--

Groom et al. 2017

Passive

Gunji et al. 2009

passive

Gunji et al., 2013

Active: find target

Key & Corbett,
2014

Active: find target

Khorrami et al.,
2013

Passive

Upright/inverted faces;
upright/inverted cars

14.8; r=9-17;
SD=3.1; n=14

McPartland et al.,
2011

Active: find target

Upright/inverted faces;
upright/inverted houses;

11.2; SD=3.4;
n=32

Clinician diagnosis,
CARS, ASDS, Raven
Progressive Matrices
ADOS, ADI-R, WASI,
Benton

63

letters/pseudoletters
Target: repeated stimuli
McPartland et al.,
2004

Neuhaus et al. 2016

Active: find target

Upright/inverted faces;
upright/inverted furniture
Target: butterflies

21.2; r=15-42;
SD=8.3; n=9

Clinician diagnosis,
ADI-R, IQ test, Faces
subtest of Wechsler
Memory Scale

Age, sex, IQ,
handedness,
ethnicity

--

Active: find target

upright and inverted faces
and houses

11.3; SD=4.4;
n=28 for P1;
n=25 for N170

ADOS, ADI-R, WASI
(DAS if <6)

Age, All
twins/triplets

No medications
known to affect
EEG

12.1; r=9.9-14.1;
n=13

Clinician diagnosis,
NVIQ

Age

--

6.93; SD=1.11;
n=12

DSM-IV, BRSA

Age, sex, IQ

--

N faces with
direct/down/laterally
averted gaze
Block 1 Target: direct
gaze
Block 2 Target: averted
gaze
Block 1: N faces, Cars;
Block 2: Mother's face,
only eyes of N and
mother, only mouth of N
and mother, favorite toy,
unfamiliar toy, target
butterfly

Senju et al., 2005

Active: find target

Shen et al., 2017

Active: identify
target

Tseng et al., 2015

Active: rate
emotionality of face

A/N/H photo and drawn
face

19.6; SD=1.96;
n=10

Gillberg, DSM-IV,
ICD-10, WAIS-III,
WASI

Age, Sex, IQ

2 ASD on
therapy
medication

Tye et al., 2013

Active: count target

Upright/inverted faces
with direct/indirect gaze
Target: flags in fixation
simuli

ASD: 11.7; r=813;SD=1.7; n=19
ASD+ADHD:
10.5; r=8-13;
SD=1.7; n=29

ADOS, ADI-R, SCQ,
WASI

Age, sex

None

Webb et al., 2006

Passive

3.8; r=2.8-4.5;
SD=0.3; n=27

ADOS, ADI-R, Mullen

Age

--

Webb et al., 2010

Active: find target

Age

No anticonvulsants,
barbiturates

Webb et al., 2012

Active: find target

Age, IQ

No anticonvulsants,
barbiturates

Mother's/unfamiliar faces;
familiar/unfamiliar
objects
Familiar/repeatingunfamiliar/novelunfamiliar faces
Target: houses

Upright/inverted faces;
upright/inverted houses
Target: scrambled faces

22.4; r=18-44;
SD=6.1; n=29

23.1; r=18-44;
SD=6.9; n=32

ADOS, ADI-R,
Wechsler IQ test,
Wechsler Memory
Scale, Faces subtest
ADOS, ADI-R,
Wechsler IQ test,
Benton, AQ, SADS,
SCQ, Wechsler
Memory Scale: Faces
subtest, Woodcock
Johnson: object
recognition, House
memory test

64

ASD: Emotion
Processing
Akechi et al., 2010

Active: identify
emotion and find
target

Apicella et al.,
2013

Active: find target

Batty et al., 2011

Active: find target

Faja et al. 2016

Active: find target

H/F/N faces

23.3; SD=7.7;
r=18-44; n=27

Hileman et al.,
2011

Active: find targets

H/F/A/N upright/inverted
faces; upright/inverted
cars
Target: female faces; cars
facing left

13.3; r=9.4-17.4;
SD=2.8;n=27

Luckhardt et al.
2017

Active: identify
blonde hair
(implicit) or angry
face (explicit)

D/S/A faces

12.5; SD=2.2;
n=21

N/H/F/A faces

Luyster et al. 2017
[child and adult]

Active, sort by
emotion

Magnee et al., 2011

Active: find target

O'Connor et al.,
2007

Active: find target

O'Connor et al.,
2005 [child and
adult]

Active: identify
emotion

F/A faces with averted or
direct gaze
Target: asterisk
H/F/N faces; trees
Target: cartoons
H/F/A/S/D/R/N faces
Target:
cars/butterflies/planes

Block 1: H/F faces
Target: white dot
Block 2: H/F autidory
stimuli
Target: tone
Block 3: H/F faces with
H/F auditory stimuli
Target: white dot/tone
Block 1: S/N eyes/mouths
Target: N faces
Block 2: S/N faces;
objects
Target: N faces

H/F/A/S/N faces

13.7; r=10.2-17.8;
SD=2.3; n=14

WISC-III, clinical
diagnosis, ASD

Age, sex, IQ

--

10.2; r=6-13;
n=10

ADOS-G & ADI-R

--

--

10.5; r=5.25-16.5;
SD=3.31; n=15

Clinician diagnosis,
CARS, VIQ, NVIQ,

Age, VIQ

--

Age, IQ, Sex

No anticonvulsants,
barbiturates

Age, sex, IQ

--

ICD-10 (KinderDIPS), ADI-R, ADOS

Age, sex,
handedness, IQ

no psychotropic
meds

Adult: 21.1,
SD=1.24, n=12
18-22 y/o
Child:12.44,
SD=.25,n=17 12
y/o;

ADOS, IQ

Age, IQ, sex,

--

22.7; SD=3.8;
n=23

ADOS, ADI-R, WAISIII

Age, IQ

--

23.5; r=18-41;
SD=5.2; n=15

Clinician diagnosis

Age

3 ASD on SRIs

Adult: 24.6; r=1845; SD=8.8; n=15
Child: 11.6; r=
11-15; SD=1.9;
n=15

Clinician diagnosis

Age, sex

4 ASD adults, 7
ASD children on
SRIs

ADOS, DSM-IV, ADIR, WAIS-III,
Woodcock Johnson
ADOS, WISC-IV,
SCQ,
RMET(children's),
Strange
Stories(mentalizing)

65

Active: find target

H/F/A/D/N faces
Target: blue circle around
stimulus, delayed onset

11.7; r=8-13;
SD=1.7; n=19

Wagner et al., 2013

Active: find target

F/A/N faces; houses
Target: repeated stimuli

17.0; r=13.6-21.1;
SD=2.2; n=18

Wong et al., 2008

Active: identify
gender, emotion

H/F/A/S/N faces

8.5; r=6-10;
SD=1.5; n=10

Passive

N/H/A faces

29.9; SD=7.1;
n=14

N faces; buildings

Tye et al., 2014

Yamasaki et
al.2017
SZ: Face
Processing
Herrmann et al.,
2004
Liu et al., 2016

Active: identify
stimulus type
Active: press button
when monkey face
appears

N human and monkey
faces, some presente
concurrently with sound
N faces; hands; cars
Target: butterflies

ADI-R, ADOS,
Connor's, SCQ, PACS,
WASI
Clinician diagnosis,
ADOS, SCQ, IQ test
(Kaufman brief IQ
test)
ADOS, ADI-R,
Raven's Progressive
Matrices

Age, IQ,
handedness

Age

No meds,
stimulants
interrupted 48
hours prior
11 ASD on
stimulants,
SRIs,
antipsychotics

Age, NVIQ

--

DSM-IV, clinial Dx

Age, Sex, IQ

--

32.3; r=18-57;
SD=10; n=24

PANSS, DSM-IV
diagnosis

17 SZ on
antipsychotics

44.6; SD=7.94,
r=18-55; n=18

DSM-IV, SCID,
PANSS, Verbal IQ

42.7; r=20-55;
SD=10; n=20

DSM-IV diagnosis,
PANSS, VIQ

Age, handedness,
education
Age, handedness,
parental SES,
normal hearing
Age, sex,
handedness
Age, sex,
handedness, parent
SES

--

Onitsuka et al.,
2006

Active: find target

All SZ on
antipsychotics

Onitsuka et al.,
2009

Active: find target

N faces
Target: N female face

42.4; r=20-55;
SD=10.8; n=17

DSM-IV diagnosis,
PANSS, WAIS-R

Tsunoda et al.,
2012

Active: find target

Upright/inverted faces;
upright/inverted cars
Target: butterflies

30.4; r=25-35;
SD=3.2; n=15

DSM-IV diagnosis,
SAPS, SANS, SFS

Age, sex,
handedness, SES,
parent SES

1 typical, 14
atypical
psychotics (all
SZ)

Zheng et al.,

Mental count of
flowers and ignore
other stims

Uprigth faces, upright
tables, inverted faces,
interverted tabels, flowers
(targets)

32.3, SD=11.2
n=24,

DSM-IV, PNSS,
Personal and Social
Performance w/
psychiatrist or
pshychologist

Age

--

Akbarfahimi et al.,
2013

Active: find target

H/F/A/S/N faces
Target: houses

33.3; r=20-45;
SD=5.7; n=28

PANSS, SADS with
psychiatrist and case
files

Age, handedness,
education

--

Bediou et al., 2007

Active: count R
faces, gender

H/F/D/R/N faces

27.8; SD=8.4;
n=10

DSM-IV diagnosis,
MINI, PANSS

Age

Brenner et al., 2015

Active: match
emotion

H/VH/F/A/S/N faces

31; SD=8.65;
n=38

SCID, PANSS

Age, sex

All SZ on
antipsychotics

SZ: Emotion
Processing

Chloropromazin
e equivalent
346mg
Chloropromazin
e equivalent
327mg

66

Caharel et al., 2007

Active: identify
familiarity

Campanella et al.,
2006

Active: find target

Fukuta et al., 2014

Passive

H/D/N faces of
self/familiar/unfamiliar
faces
Block 1: N faces same
identity
Target: N face deviant
identity
Block 2: H/F/S/N faces
Target: H/F/S faces
N, pos, neg, low emo
(dynamic faces NR here)

37.7; r=25-56;
SD=8.3; n=18

DSM-IV diagnosis

Age, handedness

All SZ on
antipsychotics

47.7; SD=11.9;
n=14

DSM-IV diagnosis,
PANSS

Age, handedness,
Beck Depression
Scale

Haloperidol
equivalent 9mg

33.3; SD=6.2;
n=13

DSM-IV diagnosis,
PANSS

Age, sex,
handedness

Risperidone
equivalent
7.8mg

DSM-IV Diagnosis,
PANSS, SCAN,
Raven's Test, Trail
Making Test - Part A

Age, sex,
education,
intellectual
capabilities/process
ing speed

All SZ on
antipsychotics

Age, sex

39/40 SZ on
antipsychotics

--

All SZ on
antipsychotics

Ibanez et al., 2012

Active: identify
emotion

H/A faces;
positive/negative words

38.6; SD=12.0;
n=13

Jetha et al., 2013

Passive

H/F/A/N faces

42.2; SD=6.4;
n=40

Johnston et al.,
2005

Active: find target

H/F/A/S/D/R/N faces
Target: R faces,
male/female

33.4; r=19-44;
SD=8.3; n=11

Jung et al., 2012

Active: find target

H/F/N faces
Target: H/F faces

32.2; SD=10.1;
n=23

PANSS, DSM-IV
diagnosis

Age, sex,
handedness,
education

All SZ on
atypical
antipsychotics

Active: find target

Block 1: F/N faces, broad
spatial freq (BSF)
Block 2: F/N faces, low
spatial freq (LSF)
Block 3: F/N faces, high
spatial freq (HSF)
Target: chairs

37.6; SD=11.4;
n=21

SCID, PANSS

Age, sex, education

All SZ on
atypical
antipsychotics

Age, handedness

All SZ on
antipsychotics

Age, sex, education

All SZ on
antipsychotics

Age, sex,
handedness,
education

All SZ on
atypical
antipsychotics

Kim et al., 2015

Kirihara et al.,
2012

Active: find target

H/F/A/S/D/R/N faces;
cars
Target: butterflies

34.5; SD=6.8;
n=15

Komlosi et al.,
2013

Active: identify
emotion

F/N faces; scrambled
faces

34.2; SD=10.3;
n=24

Lee et al., 2007

Active: find target

H/F/N faces
Target: H/F faces

30.2; SD=10.3;
n=11

PANSS, DSM-IV
diagnosis, Cheek and
Buss Shyness Scale
ICD-10 diagnosis,
Emotion recognition
behavioral task.

DSM-IV diagnosis
(SCID), PANSS,
National Adult
Reading Test, NEOFive Factor Inventory,
Global Assessment of
Functioning (GFA)
DSM-IV diagnosis,
PANSS, Symptom
Checklist-90
DSM-IV diagnosis,
PANSS

67

Lee et al., 2010

Active: find target

H/F/N faces
Target: H/F faces
Block 1: N faces; cars
Target: butterflies
Block 2: H/F/A/S/D/N
faces
Target: N faces
Block 1: H/N infant faces
Block 2: S/N infant faces
Target: H/S infant faces
Session 1 (S1): med
naïve; S2: 3mo post-med;
S3: 12mo post-med
H/F/N faces; blurred
faces; houses
Target: shoe
H/F/A/S/D/R/N faces
Block 1 Target: H faces
Block 2 Target: F Faces
Block 3 Target: Face
identity

30.2; SD=10.3;
n=38

DSM-IV diagnosis,
PANSS

Age, sex,
handedness,
education

All SZ on
atypical
antipsychotics

35.5; SD=9.4;
n=24

No info on diagnosis;
WAIS-II, SAPS,
SANS

Age, sex, IQ,
handedness,
education, parent
SES

Chlorpromazine
equivalent 409

27.1; SD=8.9;
n=30

ICD-10 diagnosis

Age, sex

None at S1

32.9; r=18-47;
SD=10.0; n=16

DSM-IV diagnosis,
SAPS, SANS, GAF

Age, handedness,
parent SES

All SZ on
antipsychotics

30.2; r=18-45;
SD=7.3; n=9

DSM-IV diagnosis,
PANSS

Age, sex,
handedness,
education

All SZ on
typical
antipsychotics

Age, education

All SZ on
antipsychotics

Age, sex,
handedness, parent
education

Most medicated

Age, sex,
handedness

10/16 SZ on
atypical
antipsychotics; 6
unmedicated.

Age

All SZ on
antipsychotics

Lynn et al., 2008

Active: find target

Mori et al., 2012

Active: identify and
count emotion

Obayashi et al.,
2009

Active: find target

Ramos-Loyo et al.,
2009

Active: find target

Thoma, 2013

Active: find target

H/F/S/N face/body pairs
Target: same emotion in
both stimuli

34.1; r=21-59;
SD=11.2; n=14

Tso et al., 2015

Active: identify
gaze direction

F/N faces with
direct/rotated orientation
and direct/averted gaze

41.4; r=18-60;
SD=13.3; n=28

Turetsky et al.,
2007

Active: identify
emotion

H/S/N faces

30.5; r=22-38;
SD=6.0; n=16

Active: find target

Block 1: H infant faces;
flowers
Target: H faces
lock 2: S infant faces;
flowers
Target: S faces
Block 3: N infant faces;
flowers
Target: N faces

26.5; r=16-34,
SD=4.7; n=32

Ueno et al., 2004

ICD-10 diagnosis,
Beck Depression
Inventory, vocabulary
test
DSM-IV diagnosis,
SAPS, SANS, reading
ability (subtest of
WRAT3-R), cognition
(BACS)
DSM-IV diagnosis,
DIGS, BPRS, SAPS,
SANS, Hamilton
Depression Rating
Scale

DSM-IV diagnosis,
PANSS

68

Wynn et al., 2008

Active: identify
gender, emotion,
object

Wynn et al., 2013

Active: identify
gender, emotion,
object

H/F/A/S/R/M faces;
buildings
Block 1 Target: identify
gender
Block 2 Target: identify
emotion
Block 3 Target: count
stories of building
H/F/A/S/R/M faces;
buildings
Block 1 Target: identify
gender
Block 2 Target: identify
emotion
Block 3 Target: count
stories of building

43.9; SD=10.2;
n=26

DSM-IV diagnosis,
SANS, BPRS

Age, sex, education

All SZ on
antipsychotics

45.3; SD=9.4;
n=32

DSM-IV diagnosis,
PBRS

Age, sex, parent
education

30/32 SZ on
antipsychotics

Yang et al. 2017

Active: identify
emotion

H/F/D faces, different
intensities

22.3, SD=3.2,
r=16-28, n=30

DSM-IV, SCID,
PANSS

Age, gender,
education

8 SZ on
aripiprazole, 10
on olanzapine,
12 on
risperidoneduration of use
of each did not
exceed 2 weeks

Zhang et al., 2016

Active: identify
duration

H/F/N faces
Target: H/F/N faces with
altered duration

31.3; r=18-42;
n=47

SCID, PANSS

Age, sex,
handedness, IQ,
education

All SZ on
antipsychotics

69

Table 2.

Author,
year
ASD: Face
Processing
Churches et
al, 2012a

Correlations

--

P100
Amplitude

--

Latency

--

Churches et
al., 2010

--

--

--

Churches et
al., 2012b

--

--

--

Cygan et al.,
2014

--

Faces:
ASD>TD
Names: ns

ns

--

--

--

Grice et al.,
2005
Groom et al.
2017

Faces: ns;
Objects:
ASD>TD
TD:
active<passive,
fo
ASD: ns
Face, face-like
obj: ns
Obj: ASD>TD
All stim: LH,
TD<ASD, nfs
TD: names,
LH<RH; faces,
ns
Fam vs.
Unfam: ns
ns

Lat

P300
Amplitude

Latency

ns

Target face:
ASD>TD, fo
Nontarget face:
ns

--

--

--

ns

--

--

--

--

ns

--

--

--

--

ns

--

--

--

--

ns

--

--

--

--

Latency

N250
Amplitude

ASD>TD;

Gunji et al.
2009

--

Gunji et al.,
2013

--

--

N170 amp w/
parietal P3
amp (+)

All stim:
TD: LH retest,
repeated>no
vel, nfs
ASD: LH retest,
repeated<no
vel, nfs

Key &
Corbett,
2014

N170
Amplitude

ASD:
face<non-face

Adult TD< PDD
and Child TD

--

--

--

--

All stim:
ASD: LH retest,
repeated<novel
, nfs
TD: ns

--

--

--

--

--

TD:
self>familiar;
ASD: ns
TD:
fam>unfam, fo
ASD: ns
All stim:
Repeated:
ASD>TD, nfs
Novel: ns
ASD:
repeated>novel
, nfs
TD: ns

--

ns

--

70

Khorrami et
al., 2013

McPartland
et al., 2011

ns

N170 lat &
ASD amp w/
face
recognition
(+)

--

ns

--

ns

All stim:
ASD>TD, nfs
Face vs. Obj: ns
Up vs. Inv:
TD: up obj<inv
obj

ns

All stim:
TD: RH<LH,
nfs
ASD: ns
Face vs. Obj:
Obj: ASD>TD
Faces: ns
Up vs. Inv:
TD: inv<up, fo
ASD: up<inv,
fo

Face vs. Obj:
Face, RH:
ASD>TD
House: ns
Up vs. Inv: ns

--

--

--

--

--

--

--

--

--

--

--

--

--

--

ns

Face vs. Obj:
Face: ASD>TD
Obj: ns
Up vs. Inv:
ASD>TD, fo
TD: inv>up
ASD: ns

Neuhaus et
al. 2016

TD and ASD
latencies and
peak
amplitudes:
older
particiapnts<y
ounger; MZ
twins highly
correlated
(positive) on
latencies and
amplitudes for
both P1 and
N170, also sig
for DZ except
N170 amp

houses>face
s

TD<ASD;
TD
upright<inve
rted faces
and houses;
ASD:upright
<inverted
faces,
inverted<upr
ight houses;
TD and
ASD: older
particiapnts<
younger

--

--

--

--

--

--

Senju et al.,
2005

--

ns

ns

ns

ns

--

--

ns

ns

Objects>face
s

N
faces<object
s; N faces
vs. objects

Faces&eyes<m
outhes&objects

ASD: left
hemi<right

--

--

--

--

McPartland
et al., 2004

ASD N170 lat
w/ face
memory (-)

Shen et al.,
2017

71

ASD: left
hemi<right

Tseng et al.,
2015

Tye et al.,
2013

ASD slower
RT to evaluate
A/H faces,
shorter for N
faces (photo
and drawing)

N170 amp
laterlization
w/ social
communicatio
n (+)

Photo:
ASD<TD;
Drawing:
TD<ASD

ns

Webb et al.,
2006

--

Webb et al.,
2010

N250 amp w/
VIQ, social
behavior &
social
communicatio
n (+)

ns

Webb et al.,
2012

ASD N170
amp, N170 lat,
ASD P1 amp
& lat w/ social
anxiety, social
behavior &
face memory

Face vs.
Object: ns
Up vs. Inv:
TD: inv>up,
nfs
ASD: ns

--

--

ns

--

--

--

--

All stim:
TD:
RH>LH, fo
ASD/ASD+
ADHD:
LH>RH, fo
ASD: ns
Up vs. Inv:
ns
Gaze:
TD,ADHD:
direct>avert
ASD:
avert>direct

All stim:
TD: LH>RH,
fo
ASD+ADHD:
LH<RH, fo
ASD: ns
Up vs. Inv: ns
Gaze: ns

ns

--

--

--

--

--

All stim:
TD: RH<LH,
nfs
ASD: ns
Face vs. Obj:
TD: ns
ASD: face<obj
Fam vs.
Unfam: ns

Face vs. Obj:
TD: face<obj
ASD: face>obj
Fam vs. Unfam:
ns

--

--

--

--

ns

ns

All stim:
TD: ns
ASD: lat<med,
fo
Fam vs. Unfam:
ns

All stim:
ASD<TD, fo
Fam vs. Unfam:
ASD, famunfam: RH<LH,
fo
TD, fam-unfam:
ns

--

--

--

ns

Face vs. Obj:
ns
Up vs. Inv:
Up: RH med,
TD<ASD, fo
Inv: RH lat,
TD<ASD, fo

All stim:
TD: lat>med,
nfs
ASD: ns
Face vs. Obj: ns
Up vs. Inv: ns

--

--

--

--

72

ASD:
Emotion
Processing
Emo/Gaze:
TD:
congruent>inco
ngruent, fo
ASD: ns
Emo: ns

ns

--

--

--

--

Akechi et
al., 2010

--

ns

TD:
RH<LH, fo
ASD: ns
Emo: ns

Apicella et
al., 2013

--

ns

ns

ns

ns

--

--

--

--

All stim:
ASD<TD, fo
Emo: ns

All stim:
ASD>TD, fo
Emo:
TD:
D>H,S,R
ASD: ns

ns

All stim:
ASD>TD, fo
Emo: ns

--

--

--

--

--

--

--

--

Batty et al.,
2011

Faja et al.,
2016

Hileman et
al., 2011

Luckhardt et
al. 2017

--

TD N170
influenced by
emotion
TD P1 &
N170 amp w/
social
behavior &
cognition (- &
+,
respectively)

--

ASD:F<N
Face vs.
Obj: ns
Up vs. Inv:
TD: inv>up,
fo
ASD: ns
Emo: ns
TD:Explicit
condition>i
mplicit;
ASD: ns;
TD: stronger
laterilzation

Luyster et
al. 2017

--

12 y/o>1822 y/o

Magnee et
al., 2011

--

--

ns

ns

All stim:
ASD>TD, nfs
Face vs. Obj: ns
Up vs. Inv: ns
Emo: ns

ns

explicit<implic
it

ns

--

--

--

--

12 y/o>1822 y/o; in
18-22 group,
TD<ASD

12 y/o<18-22
y/o

TD<ASD

--

--

--

--

--

ns

ns

--

--

--

--

--

--

--

--

--

--

--

--

O'Connor et
al., 2007

--

ns

ns

ns

O'Connor et
al., 2005

ns

ns

Adult:
All stim:
ASD>TD, fo

Adult:
All stim:
ASD>TD, fo

Face vs. Obj:
Face: ASD>TD
Obj: ns
Emo: ns
Adult:
All stim:
ASD>TD, fo

73

Emo: ns
Child: ns

Tye et al.,
2014

Wagner et
al., 2013

Wong et al.,
2008
Yamasaki et
al., 2017
SZ: Face
Processing

N170 amp
emo diff w/
social
communicatio
n (+)

--

TD P1 lat w/
pupil diameter
(-); N170 lat
w/ eye gaze
(+)

All stim:
TD: ns
ASD:
mid>RH, nfs
Face vs.
Obj:
Faces: ns
Obj:
ASD>TD
Emo: ns

---

Emo: ns
Child: ns
All stim:
ASD/ASD+AD
HD>TD, nfs
Emo:
ASD/ASD+AD
HD: N<F
TD: ns

Emo: ns
Child: ns
TD: ns
ASD: A>N;
F>H
ASD+ADHD:
A<N; F<H

--

--

--

--

ns

Face vs. Obj:
ns
Emo:
TD: F>A
ASD: ns

ns

--

--

--

--

ns

ns

ns

ns

--

--

--

--

ns

ASD<TD

--

TD<ASD

--

--

--

--

ns

--

--

--

--

--

Herrmann et
al., 2004

ns

ns

ns

Face vs. Obj:
Face: SZ>TD
Obj: ns
Face-obj diff:
SZ<TD

Liu et al.,
2016

--

ns

ns

TD<SZ

Onitsuka et
al., 2006

SZ N170 amp
w/ L & R
posterior
fusiform (+)

--

--

Face vs. Obj:
Face: SZ>TD
Obj: ns
TD:
face<hand,obj
SZ: ns

--

--

--

--

--

Onitsuka et
al., 2009

ns

--

--

SZ>TD, fo

--

--

--

--

--

--

Face vs. Obj:
TD: face<obj
SZ: ns
Face: SZ>TD
Obj:
Up vs. Inv:
TD: face,

ns

--

--

--

--

Tsunoda et
al., 2012

SZ N170 amp
w/ social
behavior (+)

--

sound+face>fac
e

74

inv<up; obj, ns
SZ: ns
Zheng et al.,
2016

--

--

SZ>TD for
inverted faces

SZ>TD for
upright and
inverted faces

--

--

--

--

--

ns

All stim, LH:
SZ>TD, fo
Emo:
F face: SZ>TD

--

--

--

--

--

--

--

TD, emo task:
F>N
TD, gender
task: ns
SZ: ns

--

--

ns

--

--

--

All stim:
SZ>TD, fo
Fam vs. Unfam:
ns
Emo: ns

--

--

--

--

ns

--

--

--

--

--

SZ:
Emotion
Processing
Akbarfahimi
et al., 2013

ns

--

Bediou et
al., 2007

--

TD: emo
modulated
ASD: ns

--

Emo task:
SZ>TD, fo
Gender task: ns
Emo: ns

Brenner et
al., 2015

ns

ns

--

ns

Caharel et
al., 2007

P1 lat w/
N170 lat (+)

All stim:
SZ<TD, fo
Fam vs.
Unfam: ns
Emo: ns

Campanella
et al., 2006

SZ N170 amp
w/ pos SZ
symptom (-)

All stim: HiSZ<LowSZ,TD, fo
Emo: ns

ns

Fukuta et
al., 2014

ns

ns

ns

--

--

--

--

--

--

--

Emo:
H face: SZ>TD
TD: pos
face<neg face
SZ: ns
Face vs. Word:
TD: face<word
SZ: ns

--

--

--

--

--

Ibanez et al.,
2012

--

--

All stim:
SZ>TD, fo
Fam vs.
Unfam: ns
Emo: ns

Fam vs.
Unfam:
TD:
own<fam,unfa
m, fo
SZ:
unfam<own,fa
m, fo
Emo:
TD: D<H,N
SZ, LH:
D>H,N
D: TD<SZ
Hi-SZ>TD, fo
Emo:
TD: F<H,S
SZ: ns

75

Jetha et al.,
2013

Johnston et
al., 2005

Jung et al.,
2012

P1 & TD
N170 amp w/
shyness (+ & )
P3 amp w/ R
fusiform & L
superior
temporal
gyrus (+)

ns

--

All stim:
SZ>TD, fo
Emo: ns

--

--

--

--

--

ns

ns

--

ns

--

--

ns

ns

--

All stim:
TD: ns
SZ:
male<female, fo
Emo: ns

--

ns

--

ns

ns

ns

ns

ns

--

--

--

--

--

All stim:
SZ>TD, fo
Emo:
H,F: SZ>TD
N: ns
TD, LH:
BSF<HSF,LSF
, fo
TD, RH:
BSF<HSF, fo
SZ, LH:
BSF<HSF,LSF
, fo
SZ, RH:
LSF<HSF, fo
Emo: ns
Face vs. Obj:
Face, RH:
SZ>TD
Obj: NR
Emo:
TD: emo<N
SZ: ns

ns

ns

--

Kim et al.,
2015

--

TD, F:
LSF>HSF,
fo
TD, N: ns
SZ, F:
BSF>HSF,
LSF, fo
SZ, N:
BSF>HSF;
LSF>HSF,
fo

ns

Kirihara et
al., 2012

SZ N170 amp
w/
extraversion
(+)

--

--

--

--

ns

--

--

--

--

--

--

--

ns

ns

--

--

--

--

ns

Emo:
Female LH:
SZ>TD to H
TD RH:
female<male
to H

SZ>TD, fo
Emo: ns

All stim:
SZ>TD, fo
Female, RH:
H/F face,
SZ>TD

ns

All stim:
TD: ns
SZ:
female>male,
fo
Emo: ns

All stim:
SZ>TD, fo
Emo: ns

Komlosi et
al., 2013

Lee et al.,
2007

Lee et al.,
2010

SZ P3 amp
emo diff w/
pos (+) & neg
(-) SZ
symptom &
med dose (+)
SZ N170 lat
w/ SZ
symptom (+)
P1 & N170 lat
w/ neg SZ
symptom (-)

ns

76

Lynn et al.,
2008

SZ N170 amp
to emo w/
N170 amp to
face/object (+)

Mori et al.,
2012

--

Obayashi et
al., 2009

N170 amp w/
global
functioning
(+)

RamosLoyo et al.,
2009

--

--

--

All stim:
SZ>TD, nfs
Face vs. Obj:
ns
Emo:
TD:
S<H/F/A/D
SZ: ns

ns

--

--

--

H: SZ@S3<TD
SZ, S:
S1<S2,S3, fo
TD,
SZ@S2&S3:
S>H
SZ@S1: ns

--

H: SZ@S3>TD
SZ: S3>S1,S2,
fo
SZ@S3: S<H

--

--

--

--

--

--

ns

All stim:
SZ>TD, nfs
Emo: ns

Face vs. Obj:
Face: SZ>TD
Obj: ns
Emo: ns

ns

--

--

--

--

--

--

--

Thoma,
2013

--

ns

ns

Tso et al.,
2015

N170 amp
emo diff w/
delusions (+)

--

--

Turetsky et
al., 2007

SZ N170 w/
pos SZ
symptom (-);
N170 amp w/
P3 amp; P3

ns

--

ns

Emo:
TD:
incongruent>co
ngruent
Face & Body:
TD:
incongruous<c
ongruous, nfs
SZ: ns
F-N face,
averted gaze,
LH: SZ>TD
TD: forward
face>rotated
face
SZ: ns
All stim:
SZ>TD, fo
Emo:
S face: SZ>TD

--

--

--

All stim:
ID face task,
LH: SZ<TD, fo
H face target:
SZ<TD, fo
Emo: ns

ns

--

--

--

--

ns

--

--

--

--

--

ns

--

All stim:
SZ<TD, fo
Emo: ns

--

77

amp w/
depression (-)
& task (+)

Ueno et al.,
2004

Wynn et al.,
2008

Wynn et al.,
2013

SZ P3 amp w/
neg SZ
symptom (-)

--

--

Yang et al.
2017
Zhang et al.,
2016

--

--

ns

All stim:
SZ>TD, nfs
Emo: ns

--

--

--

--

--

All stim:
SZ<TD, nfs
Emo:
TD, paranoid
SZ: H<N<S
Non-paranoid
SZ: S<N<H
SZ: ns

ns

ns

All stim:
SZ>TD, nfs
Face vs. Obj: ns
Emo: ns

ns

--

--

All stim:
SZ>TD, nfs
Face vs. Obj:
ns
Emo: ns

All stim:
SZ>TD, nfs
Face vs. Obj: ns
Emo: ns

All stim:
SZ>TD, nfs
Face vs. Obj: ns
Emo: ns

ns

--

--

--

--

--

SZ>TD
SZ N170 amp
w/ neg SZ
symptom (-)

All stim:
SZ<TD, fo
Emo: ns

ns

--

All stim:
SZ>TD, fo
Emo:
TD: H,F<N
SZ: H<F,N

--

All stim:
SZ>TD, nfs
non-paranoid
SZ>TD,parano
id SZ, nfs
Emo: ns

ns

--

--

78

Figure 1

Aa

25

Null
Significant

20
15
10
0

ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ

5

ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ

Number of Papers

25

P100 N170 N250 P300

P100 N170 N250 P300

Amplitude

Latency

Bb
Null

20

Significant

15
10
5
0

ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ
ASD
SZ

30

Number of Papers

35

P100 N170 N250 P300 P100 N170 N250 P300
Amplitude

Latency

Face

79

