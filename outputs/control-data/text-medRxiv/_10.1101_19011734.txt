medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Evaluation of the Hospital Readmissions Reduction Program
Rohan Khera, MD1; Yongfei Wang, MS2,3; Susannah M. Bernheim, MD, MHS;2,4
Zhenqiu Lin, PhD 2,3; Sharon-Lise T. Normand, PhD,5,6 Harlan M. Krumholz, MD, SM2,3,7

1Division
2Center

of Cardiology, University of Texas Southwestern Medical Center, Dallas, TX

for Outcomes Research and Evaluation, Yale-New Haven Hospital, New

Haven, CT
3Section

of Cardiovascular Medicine, Department of Internal Medicine, Yale School of

Medicine, New Haven, CT
4Section

of General Medicine, Department of Internal Medicine, Yale School of

Medicine, New Haven, CT
5Department

of Biostatistics, T.H. Chan School of Public Health, Harvard University,

Boston, MA
6Department

of Health Care Policy, Harvard Medical School, Boston, MA

7Department

of Health Policy and Management, Yale School of Public Health, New

Haven, CT

Corresponding Author
Dr. Harlan M. Krumholz; 1 Church St., Suite 200, New Haven, CT 06510
203-764-5885; harlan.krumholz@yale.edu
Word Count: 2849

Page 1 of 28
NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

ABSTRACT
Background: There is conflicting evidence about whether the Hospital Readmission
Reduction Program (HRRP) is associated with an increase in mortality.
Methods: In a cohort of Medicare beneficiaries hospitalized with heart failure (HF), we
compared two published approaches to evaluating the association of HRRP and riskadjusted 30-day mortality, including changes in average mortality across periods and
changes in slope of monthly mortality rates across discrete periods. We also tested
various methods with simulated data that was designed with an inflection in mortality.
Results: We identified 4,313,523 hospitalizations for HF, 1,788,219 for AMI, and
3,758,111 for pneumonia. Monthly slope-change models identified an increase in
mortality for HF and pneumonia in the pre-HRRP period (P<.001 for slope-change). The
changes in average mortality across the four time periods model found an increase in
mortality for HF and pneumonia in the HRRP anticipation period (post-announcement,
pre-implementation) as well as following HRRP implementation. However, under those
conditions, our simulations reveal that method errs in identifying the timing of a change.
Varying the data sources and risk-adjustment strategies had no significant effect on the
results.
Conclusion: A national policy incentivizing efforts to reduce readmission did not
increase the risk of mortality.

Page 2 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

BACKGROUND
Recent studies evaluating the Hospital Readmission Reduction Program (HRRP), a
federal policy that incentivizes reducing hospital readmissions, have reported conflicting
results about its association with patient mortality after discharge for patients with heart
failure and pneumonia.1-11 Studies are consistent in reporting that HRRP is not
associated with an increase in mortality for patients with acute myocardial infarction.
Amid the uncertainty, some experts are calling for the HRRP to be revoked.
Others, including Medicare Payment Advisory Committee (MedPAC) – a bipartisan
committee that advises the government on Medicare – concluded that the policy has
averted many readmissions, saved billions, and has not caused harm. 1,12 There is a
need to investigate the source of conflicting results and to determine if there are
methodological issues that explain the differences. A few studies have evaluated the
association of HRRP and mortality,2,4,5,8,9 but only two prominent published studies have
used the entire complement of discharges from the Centers for Medicare and Medicaid
Services (CMS) and sought to pinpoint changes in temporal trends in mortality in
relation to the HRRP announcement and implementation. One study evaluated monthly
changes in the slope of mortality rates over time,3 and another compared differences in
average mortality rates between periods before the announcement of HRRP, during the
announcement, and then implementation.5
There are several methodological differences between studies that may explain
the different conclusions. One influential study, which inferred that there was an
increase in mortality associated with HRRP,5 compared differences in average mortality
rates between periods before the announcement of HRRP, during the announcement,

Page 3 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

and then implementation.5 In contrast, another study, which failed to find such an effect,
evaluated monthly changes in the slope of mortality rates over time.3 A central
assumption of the latter method is that if there are no temporal changes within those
periods that could lead to an inability to identify accurately the time of the change.13
Accordingly, we conducted a series of data experiments to test the effect of the
analytic choices on the temporal trends in patient risk and mortality in the period
spanning the announcement and implementation of the HRRP. We additionally tested
the assumption that there was no temporal trend within the periods, which is essential to
the period-wide assessment method. We developed simulated data in which we created
an inflection in mortality and tested the ability of the two methods to correctly identify the
inflection and its timing. We also investigated whether results were sensitive to the
choice of source data and strategies to handle changes in risk factors as claim reporting
standards changed concurrently with HRRP’s announcement.14,15

METHODS
Data Source and Study Population
We used the Medicare Standard Analytic Files including data from April 2005 through
March 2015 to capture periods included in recent studies evaluating the HRRP. We
included hospitalizations among fee-for-service Medicare beneficiaries, ≥65 years of
age, with a principal discharge diagnosis of HF, AMI, or pneumonia – 3 conditions
included in the HRRP. The study population was consistent with the population under
the purview of the program.3,16

Page 4 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Study Periods
We divided the 120-month period between April 2005 and March 2015 into four 30month periods based on the discharge date of the inpatient admissions: (a) baseline
(April 2005-September 2007); (b) pre-HRRP (October 2007-March 2010), a 30-month
period before HRRP announcement; (c) HRRP anticipation (April 2010-September
2012), a 30-month period between HRRP’s announcement and implementation; and (d)
HRRP penalty (October 2012-March 2015), when the Medicare penalized hospitals for
higher than expected readmissions rates. These consistent periods of observation
allowed us to evaluate for changes in outcomes before the introduction of HRRP, and
after its announcement and subsequent implementation.5

Overview of Data Experiments
We hypothesized that differences in results may derive from differences in study design,
data source, or the approach to inpatient codes for risk adjustment. We constructed
data experiments to test these 3 potential mechanisms (Figure 1). To permit head-tohead assessments, we harmonized the data, keeping the study population and period of
observation consistent across experiments. We examined the same outcome – allcause post-discharge 30-day mortality – across all experiments. Finally, the
experiments were conducted in parallel, such that we isolated the effect tested in one
experiment to the other two.

Experiment 1: Mortality patterns in period-averaged vs monthly assessments

Page 5 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

To test whether differences in study design produced different results, we adopted a
pre-post design that evaluated whether average risk-adjusted mortality differed among
the 4 study periods ignoring within-period temporal trends as previously reported.5
Using the same 4 periods, we evaluated whether risk-adjusted monthly mortality
differed within the study periods, thus explicitly modeling within-period time trends while
evaluating changes across periods in an interrupted time series framework (Figure 1).
We determined whether the two approaches produced different results using the same
data, the same study periods, and the same approach of risk-adjusting data, thereby
isolating the effects of the modeling strategy. We also tested whether the assumption
about absence of within-period trends, which is necessary for studying the effects of
HRRP on average mortality, were satisfied.

Experiment 2: Risk-adjustment with Inpatient vs Inpatient and Outpatient Claims
We identified comorbidities used in the CMS risk-adjustment models from 3 sources: (1)
secondary diagnoses in the index hospitalization, (2) all diagnoses and procedures
during hospitalizations over the preceding 12 months, and (3) diagnosis and procedure
codes across all outpatient and professional claims over these 12 months. One study
that found an increase in mortality with HRRP, only used inpatient data (sources 1 and
2 above) to assess patient risk, compared with another that used all inpatient and
outpatient data (all 3 sources) and did not find an increase in mortality with HRRP. We
assessed whether the differences in the association with mortality arose due to different
data sources for risk-adjustment.

Page 6 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Experiment 3: Changes in Number of Codes on Inpatient Claims
We tested the effect of how studies handled changes in CMS data transaction
standards around HRRP announcement, when the number of secondary diagnosis
codes and procedure codes on inpatient claims increased from 9 to 24, and 6 to 25,
respectively. This experiment was an extension of Experiment 2, wherein the
comparisons between inpatient-only vs inpatient and outpatient strategies to identify risk
factors were stratified into two subgroups each, based on the use of 1) the first 9
secondary diagnosis codes and first 6 procedure codes to derive risk factors even when
a larger number of codes were available; and 2) using all the inpatient codes that were
available.

Statistical Analysis
We described the mean monthly number of risk factors and mean mortality risk across
the 4 periods. The risk scores were based on regression coefficients derived from two
logistic regression models with post-discharge 30-day mortality as outcome –
constructed in parallel using covariates from inpatient data vs inpatient and outpatient
data. The monthly risk score represented the sum of risk factors weighted by their
contribution to mortality averaged across hospitalizations for each month.
For the period-wise analyses that ignored within-period monthly trend approach
in Experiment 1, we calculated the average difference in mortality across all months
between the baseline (period 1) and pre-HRRP (period 2), pre-HRRP and HRRP
anticipation (period 3), and HRRP anticipation and penalty (period 4) periods. The
change between periods 1 and 2 was assumed to represent the secular trend for

Page 7 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

mortality, and the excess mortality changes between periods 2 and 3 and periods 3 and
4 were assumed to be temporal changes in mortality with HRRP announcement and
HRRP penalties. The differences in changes were assessed as marginal effects in
regression models that modeled period as the covariate of interest, and mortality as the
outcome (Supplementary Appendix).
In the second approach, we used a slope-change interrupted time series
framework to evaluate changes in unadjusted and risk-adjusted mortality across
transitions between the 4 periods defined in the first approach.17 We constructed a
linear spline using the monthly post-discharge mortality rates within each of 4 periods
outlined above, with knots at the transitions between these periods. We evaluated for
changes in slope of mortality at the knots between these periods, including between the
baseline and the pre-HRRP periods, the pre-HRRP and the HRRP anticipation periods,
and the HRRP anticipation and HRRP penalty periods (Supplementary Appendix).

Simulation analyses
We tested the hypothesis that comparing average mortality rates would not be able to
correctly identify the timing of a change in mortality. Our hypothesis was based on an
algebraic proof indicating that if within-period temporal trends exist, ignoring such
temporal trends may falsely identify between-period differences associated with the
intervention (Supplementary Appendix). We created data simulations for mortality,
wherein we created a data set in which mortality increased linearly by 1% over the study
period, consistent with the overall increase in HF mortality over this period (increase by
0.008% per month starting at 7% in the first month). We explicitly accounted for random

Page 8 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

variation in monthly rates.18 In a positive control, we introduced an increase in mortality
such that slope was 50% higher rate after HRRP announcement in April 2010 compared
with the slope before the announcement, i.e. slope increased to 0.012% per month
(Figure S1). We created two negative controls wherein the mortality slope changed 12
months and 24 months before HRRP announcement, in April 2009 and April 2008,
respectively (Figures S2 and S3). We assessed whether the strategies accurately
identified the association between HRRP announcement and mortality trends in the 3
scenarios above.
The analyses were performed using SAS, version 9.4 (Cary, NC), and Stata 16
(College Station, TX). The level of significance was set at 0.05. The codes for the
simulation analyses are posted on GitHub.18 The study was approved by the Yale
University Institutional Review Board.

RESULTS
We identified 4, 313,523 hospitalizations for HF, 1,788,219 for AMI during the study
period, and 3,758,111 for pneumonia. In April 2005, there were 49,043 for HF, 18,705
for AMI, and 50,622 for pneumonia, with a decrease in the number of hospitalizations
for all 3 conditions through March 2015.

Experiment 1: Mortality patterns in period-averaged vs monthly assessments
Across the 4 study periods, unadjusted post-discharge 30-day mortality for both HF and
pneumonia increased, whereas unadjusted mortality for AMI decreased in the HRRP
anticipation and penalty periods. In unadjusted analyses, after ascribing changes in

Page 9 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

mortality rates between the baseline and pre-HRRP periods to secular mortality trends,
there was no significant excess change between the pre-HRRP and HRRP anticipation
periods or the HRRP anticipation and HRRP penalty periods for HF or pneumonia,
whereas mortality for AMI decreased (Figure 2, Tables S1-S3). In the second strategy,
monthly rates examined in interrupted time series models for changes across periods
did not find any inflections in unadjusted mortality rates during the HRRP anticipation
and penalty periods (Figure 3, Tables S4-S6). However, for risk-adjusted rates, periodwise analysis and monthly results produced different results. The period-wise analysis
found a significant increase in mortality between the pre-HRRP and HRRP anticipation
periods for both HF and pneumonia, without significant changes in mortality for AMI. In
contrast, the monthly modeled slope-change interrupted time series models revealed no
inflection in mortality slopes for either HF or pneumonia at HRRP announcement. These
contrasting conclusions between period-wise and monthly assessments in mortality
rates persisted for each of covariate selection strategies for risk-adjustment, compared
head-to-head (Table 1). We also identified a within period trend in mortality.

Experiment 2: Risk-adjustment with Inpatient vs Inpatient and Outpatient Claims
The use of outpatient claims identified ~1.5-fold higher number of risk factors in the
baseline period compared with inpatient claims alone for all HRRP conditions (Figures
S4-S6). There were a mean 9.2, 6.0 and 8.6 risk factors based on inpatient and
outpatient claims in HF, AMI and pneumonia, compared with 5.8, 3.8 and 4.8 using
inpatient claims alone in the respective groups. For period-wise or monthly strategies

Page 10 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

there were no differences in the association of HRRP with mortality, regardless of the
use of inpatient or inpatient and outpatient data (Table 1).

Experiment 3: Changes in Number of Codes on Inpatient Claims
The number of risk factors remained consistent after code slots increased if only 9
inpatient codes were used, regardless of whether outpatient codes were used. The use
of all available inpatient codes, when code slots increased, was associated with an
increase in the number of risk factors captured from claims between the pre-HRRP and
the HRRP anticipation periods (when the slots increased) but was smaller when
outpatient claims were also used (Figure S4-S6). The covariate selection strategies,
however, did not cause a change in the average mortality risk score across periods or a
change in monthly mortality risk score across these periods. There was a steady
increase in risk over time in all covariate selection strategies for all conditions, without
inflections between pre-HRRP and HRRP anticipation periods, when the number of
captured codes increased (Figure S4-S6). All covariate selection strategies to identify
risk factors for risk-adjustment models produced qualitatively similar results, regardless
of whether a fixed number of inpatient claims or a combination of inpatient and
outpatient claims were used to adjust for risk over time (Figure 4, Tables S1-S3).

Simulation analyses
In analyses where we simulated an increase in mortality at HRRP announcement,
period-wise and monthly modeled interrupted time series accurately identified that a
change occurred at HRRP announcement in April 2010 (Figure 5). However, in

Page 11 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

negative controls with simulated increases preceding HRRP by 12 or 24 months, a
period-wise analysis, ascribed the increase in mortality to HRRP announcement (Figure
5). In contrast, monthly trends accurately identified that an increase in mortality
occurred between the baseline and pre-HRRP periods, without any inflections in
mortality at HRRP announcement (Figure 5, Table S7).

DISCUSSION
In our study, we show that in studies evaluating the HRRP with CMS the use of
period-specific temporal trends found no association of the HRRP with mortality.
However, studying the effect of HRRP as changes in average risk-adjusted mortality
rates suggested an association with increased mortality. Furthermore, we identified a
problem in the latter method, explaining the discordance in results. The violation of a
central assumption led to a misspecification of the timing of the change in mortality,
which we found algebraically, and in our analysis using simulations. Different data
sources and different strategies to identify covariates for risk adjustment did not further
substantially change the finding, particularly for heart failure and AMI.
Our findings validate concerns about the taking average results in four large time
periods to make an inference about when changes in rates occurred. In the absence of
a control group, such a pre-post health policy intervention evaluation must account for
temporal trends in the outcome within the pre and post periods. Evaluating changes in
averages if there is no within-period trend is satisfactory. However, ignoring such trends
can misattribute the timing of the change. The proof of why this approach can be
misleading is best illustrated by algebra (outlined in Online Supplement). The error term

Page 12 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

in these assessments is directly proportional to the magnitude of trend within periods
relative to the trend across periods. In the case of HRRP, mortality was rising in the
period before the HRRP was announced, which was also noted previously.3,19 Thus, the
within-period trend does not satisfy the assumptions of the approach and should
preclude its use. This issue has been raised in studies of methodology for more than 30
years.13
This issue has contemporary relevance because the study based on averages
within the four large time periods has sparked calls for rescinding the policy.20 In an oped, the authors suggested that the HRRP resulted in the deaths of 10 thousand
patients,21 and in another for limiting the expansion of the program,22 when it is set to
target more conditions.23,24 The White House has called for an investigation of quality
measures, in part as a result of the study. Meanwhile, the Medicare Payment Advisory
Commission (MedPAC) concluded that HRRP saved over $2 billion and reduced
readmissions without an increase in mortality.1,6
Other peer-reviewed studies have evaluated HRRP, but they focused on registry
data,8 or on trends in specific patient groups,4,9 and may not be generalizable to the
entire Medicare population.19,25 Assessments of hospitals that reduced readmissions
have not demonstrated any inflections in mortality.5,10,16 An evaluation by MedPAC was
consistent with the changes in slopes analysis and found no increase in mortality
associated with HRRP.1,6 They recently reaffirmed their initial analysis with a report in
September 2019.12
Our study has several limitations. First, we do not replicate the exact approach
used by the study that focused on period-wise assessments because we could not

Page 13 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

access the code for their analyses, and observations, such as HRRP-associated
increase in unadjusted HF mortality, could not be replicated. Similarly, while we were
able to replicate the association of HRRP announcement and mortality changes in
pneumonia, we could not replicate the association with HRRP implementation.
Moreover, for pneumonia, even the association with HRRP announcement varied
between unadjusted and risk-adjusted assessments, and various covariate selection
strategies. We are unable to explain these differences, especially as we replicate the
association of HRRP and mortality for both heart failure and AMI accurately. Second,
we do not focus on alternative ways to risk-adjust, such as the inverse probability
weighting that were used in the study that suggested HRRP’s association with mortality.
We did this intentionally as the study using this approach reported consistent results
with logistic regression.5 Moreover, the inverse probability weighting model used in the
study is itself prone to errors, especially as currently described in the study. 5
Specifically, the authors describe multiple different logistic regression models for
comparison between different periods, rather than a common model that included all 4
periods. The former approach would, by design, generate different coefficients for
different across-period comparisons, thereby compromising risk-adjustment. Finally, we
could not elucidate whether temporal changes in coding practices underlie the observed
changes in coded severity of illness. However, risk-adjusted analyses were largely
consistent regardless of the number of codes used and did not affect the interpretation
of temporal trends, especially for heart failure and AMI. In a separate assessment, we
have found that the additional codes from inpatient claims after code slot expansion

Page 14 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

were largely limited to covariates with relatively limited contribution to measured severity
of illness.26
In conclusion, policy evaluation that evaluated the HRRP by changes in average
rates over periods ignored within-period temporal trends and likely found a spurious
association. The concern about this approach, when there are intra-period trends, has
been documented in the literature and can be shown with algebraic equations and are
evident in the Medicare data and simulations. Thus, more appropriate analyses of the
changes in slope fail to reveal an increase in mortality associated with the
announcement or implementation of the HRRP.

Page 15 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

ACKNOWLEDGMENT
Funding: Dr. Khera is supported by the National Center for Advancing Translational
Sciences (UL1TR001105) of the National Institutes of Health. The funder had no role in
the design and conduct of the study; collection, management, analysis, and
interpretation of the data; preparation, review, or approval of the manuscript; and
decision to submit the manuscript for publication.

Disclosures: Drs. Krumholz, Normand, Bernheim, Lin, and Mr. Wang work under
contract with the Centers for Medicare & Medicaid Services to develop publicly reported
quality measures. Dr. Krumholz was a recipient of a research grant, through Yale, from
Medtronic and the U.S. Food and Drug Administration to develop methods for postmarket surveillance of medical devices; is a recipient of a research grant with Medtronic
and Johnson & Johnson, through Yale, to develop methods of clinical trial data sharing;
was a recipient of a research agreement, through Yale, from the Shenzhen Center for
Health Information for work to advance intelligent disease prevention and health
promotion; collaborates with the National Center for Cardiovascular Diseases in Beijing;
received payment from the Arnold & Porter Law Firm for work related to the Sanofi
clopidogrel litigation and from the Ben C. Martin Law Firm for work related to the Cook
IVC filter litigation; receives payment from the Siegfried & Jensen Law Firm for work
related to Vioxx litigation; chairs a Cardiac Scientific Advisory Board for UnitedHealth; is
a participant/participant representative of the IBM Watson Health Life Sciences Board;
is a member of the Advisory Board for Element Science, the Advisory Board for
Facebook, and the Physician Advisory Board for Aetna; and is the founder of

Page 16 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

HugoHealth, a personal health information platform and a co-founder of Refactor
Health, an enterprise healthcare AI-augmented data management company. Dr. Khera
reports no potential conflicts of interest.
The study was conceived and conducted by the authors, and the Centers for
Medicare & Medicaid Services played no role in its design and conduct; collection,
management, analysis, and interpretation of the data; and preparation, review, or
approval of the manuscript.

Page 17 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

References
1.

Khera R, Krumholz HM. Effects of the Hospital Readmissions Reduction

Program. Circ Cardiovasc Qual Outcomes 2018;11:e005083.
2.

Dharmarajan K, Wang Y, Lin Z, et al. Association of changing hospital

readmission rates with mortality rates after hospital discharge. JAMA 2017;318:270-8.
3.

Khera R, Dharmarajan K, Wang Y, et al. Association of the Hospital

Readmissions Reduction Program With Mortality During and After Hospitalization for
Acute Myocardial Infarction, Heart Failure, and Pneumonia. JAMA Netw Open
2018;1:e182777.
4.

Huckfeldt P, Escarce J, Sood N, Yang Z, Popescu I, Nuckols T. Thirty-day

postdischarge mortality among black and white patients 65 years and older in the
Medicare Hospital Readmissions Reduction Program. JAMA Netw Open
2019;2:e190634.
5.

Wadhera RK, Joynt Maddox KE, Wasfy JH, Haneuse S, Shen C, Yeh RW.

Association of the Hospital Readmissions Reduction Program With Mortality Among
Medicare Beneficiaries Hospitalized for Heart Failure, Acute Myocardial Infarction, and
Pneumonia. JAMA 2018;320:2542-52.
6.

Medicare Payment Advisory Commission. Mandated report: The effects of the

Hospital Readmissions Reduction Program. 2018. Available at:
http://www.medpac.gov/docs/defaultsource/reports/jun18_ch1_medpacreport_sec.pdf?sfvrsn=0. Accessed August 22, 2018.

Page 18 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

7.

Desai NR, Ross JS, Kwon JY, et al. Association between hospital penalty status

under the hospital readmission reduction program and readmission rates for target and
nontarget conditions. JAMA 2016;316:2647-56.
8.

Gupta A, Allen LA, Bhatt DL, et al. Association of the Hospital Readmissions

Reduction Program implementation with readmission and mortality outcomes in heart
failure. JAMA Cardiol 2018;3:44-53.
9.

Huckfeldt P, Escarce J, Wilcock A, et al. HF Mortality Trends Under Medicare

Readmissions Reduction Program at Penalized and Nonpenalized Hospitals. J Am Coll
Cardiol 2018;72:2539-40.
10.

Sandhu AT, Heidenreich PA. Comparison of the change in heart failure

readmission and mortality rates between hospitals subject to hospital readmission
reduction program penalties and critical access hospitals. Am Heart J 2019;209:63-7.
11.

Khera R, Wang Y, Nasir K, Lin Z, Krumholz HM. Evaluation of 30-Day Hospital

Readmission and Mortality Rates Using Regression-Discontinuity Framework. J Am Coll
Cardiol 2019;74:219-34.
12.

Medicare Payment Advisory Commission. MedPAC evaluation of Medicare’s

Hospital Readmission Reduction Program: Update. Available at:
http://www.medpac.gov/docs/default-source/default-document-library/readmissionsweb-cover-sheet.pdf?sfvrsn=0. Accessed September 22, 2019.
13.

Francis DJ, Fletcher JM, Stuebing KK, Davidson KC, Thompson NM. Analysis of

change: modeling individual growth. J Consult Clin Psychol 1991;59:27-37.

Page 19 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

14.

Ody C, Msall L, Dafny LS, Grabowski DC, Cutler DM. Decreases In

Readmissions Credited To Medicare's Program To Reduce Hospital Readmissions
Have Been Overstated. Health Aff (Millwood) 2019;38:36-43.
15.

Tsugawa Y, Figueroa JF, Papanicolas I, Orav EJ, Jha AK. Assessment of

Strategies for Managing Expansion of Diagnosis Coding Using Risk-Adjustment
Methods for Medicare Data. JAMA Intern Med 2019:doi:
10.1001/jamainternmed.2019.1005.
16.

Centers for Medicare and Medicaid Services. Outcome Measures. Baltimore,

MD. 2017. Available at https://www.cms.gov/Medicare/Quality-Initiatives-PatientAssessment-Instruments/HospitalQualityInits/OutcomeMeasures.html. Accessed
February 5, 2018.
17.

Lopez Bernal J, Cummins S, Gasparrini A. Interrupted time series regression for

the evaluation of public health interventions: a tutorial. Int J Epidemiol 2016;pii: dyw098.
18.

Khera R, Wang Y, Bernheim SM, Lin Z, Normand S-LT, Krumholz HM. Code for

HRRP evaluation based on covariate selection methodology. 2019. Availabile at:
https://github.com/rohankhera/rkhrrpeval. Accessed June 15, 2019.
19.

Khera R, Dharmarajan K, Krumholz HM. Rising Mortality in Patients With Heart

Failure in the United States: Facts Versus Fiction. JACC Heart Fail 2018;6:610-2.
20.

Fonarow GC. Unintended harm associated with the Hospital Readmissions

Reduction Program. JAMA 2018;320:2539-41.
21.

Wadhera RK, Joynt Maddox KE, Yeh RW. Did This Health Care Policy Do

Harm? The New York Times. 2018. Available at:

Page 20 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

https://www.nytimes.com/2018/12/21/opinion/did-this-health-care-policy-do-harm.html.
Accessed July 23, 2019.
22.

Wadhera RK, Yeh RW, Joynt Maddox KE. The Hospital Readmissions Reduction

Program - Time for a Reboot. N Engl J Med 2019;380:2289-91.
23.

Horwitz LI, Partovian C, Lin Z, et al. Development and use of an administrative

claims measure for profiling hospital-wide performance on 30-day unplanned
readmission. Ann Intern Med 2014;161:S66-75.
24.

Khera R, Horwitz LI, Lin Z, Krumholz HM. Publicly reported readmission

measures and the Hospital Readmissions Reduction Program: A false equivalence?
Ann Intern Med 2018;168:670-1.
25.

Krumholz HM, Dharmarajan K, Normand ST. Evaluating Readmission-Need for

More Clarity on Methods. JAMA Cardiol 2018;3:265.
26.

Khera R, Altaf F, Wang Y, et al. Isolating Effects of Medicare Code Slot

Expansion on Longitudinal Risk Assessment. medRxiv 2019:19010074.

Page 21 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

FIGURE LEGENDS
Figure 1: Overview of Data Experiments.

Figure 2: Trends in post-discharge mortality across the 4 study periods, ignoring
within-period temporal trends.

Figure 3: Changes in monthly mortality rates in an interrupted time series
framework that accounts for within-period temporal trends.
Vertical lines demarcate four 30-month periods: baseline (April 2005-September 2007),
pre-HRRP (October 2007-March 2010), HRRP anticipation (April 2010-September
2012), and HRRP penalties (October 2012-March 2015).

Figure 4: Simulated inflections in mortality rates.
Period-wise mortality assessments (A-C). Changes in mortality between the pre-HRRP
and the HRRP anticipation periods in excess of the secular changes in mortality
between baseline and pre-HRRP periods. Simulated increases in mortality at (A) HRRP
announcement in April 2010, (B) 12 months before HRRP announcement in April 2009,
and (C) 24 months before HRRP announcement in April 2008. Monthly rates in
interrupted time series models (D-F). Changes in slopes of monthly mortality trends
between baseline, pre-HRRP, HRRP anticipation and HRRP penalty periods. Simulated
increases in mortality at (D) HRRP announcement in April 2010, (E) 12 months before
HRRP announcement in April 2009, and (F) 24 months before HRRP announcement in
April 2008. *indicates significant changes in slope (P<0.05).

Page 22 of 28

Figure 1: Overview of Data Experiments.

Page 23 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Figure 2: Trends in post-discharge mortality across the 4 study periods, ignoring within-period
temporal trends

Page 24 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Figure 3: Changes in monthly mortality rates in an interrupted time series framework that
accounts for within-period temporal trends

Vertical lines demarcate four 30-month periods: baseline (April 2005-September 2007), pre-HRRP
(October 2007-March 2010), HRRP anticipation (April 2010-September 2012), and HRRP penalties
(October 2012-March 2015)

Page 25 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Figure 4: Simulated inflections in mortality rates.
Period-wise mortality assessments (A-C). Changes in mortality between the pre-HRRP and the HRRP
anticipation periods in excess of the secular changes in mortality between baseline and pre-HRRP
periods. Simulated increases in mortality at (A) HRRP announcement in April 2010, (B) 12 months before
HRRP announcement in April 2009, and (C) 24 months before HRRP announcement in April 2008.
Monthly rates in interrupted time series models (D-F). Changes in slopes of monthly mortality trends
between baseline, pre-HRRP, HRRP anticipation and HRRP penalty periods. Simulated increases in
mortality at (D) HRRP announcement in April 2010, (E) 12 months before HRRP announcement in April
2009, and (F) 24 months before HRRP announcement in April 2008. *indicates significant changes in
slope (P<0.05).

Page 26 of 28

medRxiv preprint doi: https://doi.org/10.1101/19011734; this version posted November 12, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Figure 4 – continued (panels D-F)

Page 27 of 28

Table 1: Summary of results of data experiments
Results indicate changes in mortality at the announcement of the Hospital Readmissions Reduction Program. Values under “4 periods”
below represent excess changes in consecutive 30-month periods surrounding HRRP announcement. The “monthly” rates represent a
change in the slope of the monthly mortality rates at the announcement of HRRP, relative to the slope of mortality in the 30-month preceding
HRRP announcement. Note that the confidence intervals are not adjusted for multiple testing. (Colors: Orange: significant increase in
mortality, yellow: no significant change, and green: significantly decreased mortality).

Experiment 1
Heart failure
4 Periods

Experiments 2 and 3

Unadjusted

AMI

Pneumonia

Monthly

4 Periods

Monthly

4 Periods

Monthly

0.006
(-0.013, 0.024)

-0.63
(-0.96, -0.31)

-0.009
(-0.030, 0.012)

-0.15
(-0.43, 0.12)

-0.016
(-0.033, 0.002)

0.009
(-0.002, 0.020)

-0.08
(-0.27, 0.11)

-0.003
(-0.015, 0.01)

0.18
(0.02, 0.34)

-0.010
(-0.020, 0.000)

0.10
(-0.04, 0.24)

-0.005
(-0.016, 0.006)

-0.21
(-0.40, -0.02)

-0.011
(-0.023, 0.002)

0.01
(-0.15, 0.18)

-0.021
(-0.032, -0.011)

0.34
(0.20, 0.49)

0.008
(-0.003, 0.019)

-0.04
(-0.23, 0.15)

-0.002
(-0.015, 0.01)

0.20
(0.04, 0.37)

-0.011
(-0.021, -0.001)

0.000
(-0.011, 0.011)

-0.04
(-0.23, 0.15)

-0.004
(-0.016, 0.009)

0.11
(-0.05, 0.28)

-0.018
(-0.028, -0.008)

-0.09
(-0.35, 0.17)

Data Source for Risk-Adjusted Rates
Inpatient Only
9 codes
9 codes then 25 codes

0.31
(0.17, 0.45)

Inpatient and Outpatient
Inpatient, 9 codes +
outpatient
Inpatient, 9 codes then
25 codes + outpatient

0.24
(0.10, 0.38)

Page 28 of 28

