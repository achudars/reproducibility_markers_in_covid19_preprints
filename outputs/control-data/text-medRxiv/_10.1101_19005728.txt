medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Checklists to Detect Potential Predatory Biomedical Journals:
A Systematic Review
Samantha Cukier, PhD, MBAa
Lucas Helal, MSca,b
Danielle B Rice, MSca,c
Justina Pupkaite, MSca,d,e
Nadera Ahmadzai, MD, MPH, MSca
Mitchell Wilsona
Becky Skidmore, MLSa
Manoj Lalu, MD, PhDa,d,f,g
David Moher, PhDa,h

Author affiliations:
a

Centre for Journalology, Clinical Epidemiology Program, Ottawa Hospital Research Institute,
Ottawa, ON, Canada
b
Graduate Program in Cardiology and Cardiovascular Sciences, School of Medicine,
Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, Brazil
c
Department of Psychology, McGill University
d
Department of Cellular and Molecular Medicine, University of Ottawa
e
Division of Cell Biology, Department of Clinical and Experimental Medicine, Linköping
University
f
Department of Anesthesiology and Pain Medicine, University of Ottawa, The Ottawa Hospital
g
Regenerative Medicine Program, Ottawa Hospital Research Institute
h
School of Epidemiology and Public Health, University of Ottawa

Corresponding author:
David Moher, PhD
Centre for Journalology
Clinical Epidemiology Program
Ottawa Hospital Research Institute
Ottawa, ON K1H 8L6
613-737-8899 (x79424)
dmoher@ohri.ca

Acknowledgements: The authors would like to thank Raymond Daniel, Library Technician, at
the Ottawa Hospital Research Institute, for document retrieval, information support and setup in
Distiller.

Conflict of Interest: All authors declare no conflict of interest.
1
NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Author Contributions (CReDiT: https://www.casrai.org/credit.html):
Conceptualization: SC and DM;
Methodology: BS
Project administration: SC
Investigation (data collection): SC, LH, DBR, JP, NA, MW
Writing – Original Draft: SC
Writing – Review & Editing: All authors
Supervision: DM, ML

2

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

ABSTRACT
Background: We believe there is a large number of checklists to help authors detect predatory
journals. It is uncertain whether these checklists contain similar content.

Purpose: Perform a systematic review to identify checklists to detect potential predatory
journals and to examine their content and measurement properties.

Data Sources: MEDLINE, Embase, PsycINFO, ERIC, Web of Science and Library, Information
Science & Technology Abstracts (January 2012 to November 2018), university library websites
(January 2019), YouTube (January 2019).

Study Selection: Original checklists used to detect potential predatory journals published in
English, French or Portuguese, with instructions in point form, bullet form, tabular format or
listed items, not including lists or guidance on recognizing “legitimate” or “trustworthy”
journals.

Data Extraction: Pairs of reviewers independently extracted study data and assessed checklist
quality and a third reviewer resolved conflicts.

Data Synthesis: Of 1528 records screened, 93 met our inclusion criteria. The majority of
included checklists were in English (n = 90, 97%), could be completed in fewer than five
minutes (n = 68, 73%), had an average of 11 items, which were not weighted (n = 91, 98%), did
not include qualitative guidance (n = 78, 84%) or quantitative guidance (n = 91, 98%), were not

3

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

evidence-based (n = 90, 97%) and covered a mean of four (of six) thematic categories. Only
three met our criteria for being evidence-based.

Limitations: Limited languages and years of publication, searching other media.

Conclusions: There is a plethora of published checklists that may overwhelm authors looking to
efficiently guard against publishing in predatory journals. The similarity in checklists could lead
to the creation of evidence-based tools serving authors from all disciplines.

Funding Source: This project received no specific funding. David Moher is supported by a
University Research Chair (University of Ottawa). Danielle Rice is supported by a Canadian
Institutes of Health Research Health Systems Impact Fellowship; Lucas Helal is supported by
Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance
Code 001, PDSE - 88881.189100/2018 - 01. Manoj Lalu is supported by The Ottawa Hospital
Anesthesia Alternate Funds Association.

4

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

INTRODUCTION
The influx of predatory publishing along with the substantial increase in the number of predatory
journals, pose a risk to scholarly communication (1,2). Predatory journals often lack an
appropriate peer-review process and frequently are not indexed (3), yet authors are required to
pay an article processing charge. The lack of quality control, the inability to effectively
disseminate research and the lack of transparency compromise the trustworthiness of articles
published in these journals. Currently, no definition of predatory journals exists, however,
characteristics have been studied (3) and a consensus definition is currently being developed (4).
Lists of suspected predatory journals and publishers are available, although different criteria for
inclusion are used (5).

To help prospective authors avoid predatory journals, various groups have developed checklists.
Armed with this knowledge, it is hoped that there will be a substantial decrease in submissions to
these journals. Anecdotally, we have recently noticed a steep rise in the number of checklists
developed for this purpose, although this has not previously been quantified. Large numbers of
checklists with varying content may confuse authors, and possibly make it more difficult for
them to choose any one checklist, if any at all, as suggested by the choice overload hypothesis
(6). The net effect of the abundance of conflicting information could be that users will not
consult any checklist and these efforts will be lost, or discrepancies between checklists could
impact the credibility of each one. We performed a systematic review of the content and
measurement properties of checklists used to detect probable predatory journals.

METHODS

5

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

We followed standard procedures for systematic reviews and reported results according to
Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines (7).
The project protocol was publicly posted prior to data extraction on the Open Science
Framework (http://osf.io/g57tf).

Data Sources and Searches
An experienced medical information specialist (BS) developed and tested the search strategy
using an iterative process in consultation with the review team. The strategy was peer reviewed
by another senior information specialist prior to execution using the PRESS Checklist (8) (see
Appendix 1).

We searched multiple databases with no language restrictions. Using the OVID platform, we
searched Ovid MEDLINE® ALL (including in-process and epub-ahead-of-print records),
Embase Classic + Embase, PsycINFO and ERIC. We also searched Web of Science and the
Library, Information Science and Technology Abstracts (LISTA) database (Ebsco platform). The
LISTA search was performed on November 16, 2018 and the Ovid and Web of Science searches
were performed on November 19, 2018. Retrieval was limited to the publication dates 2012 to
the present. We used 2012 as a cut-off since data about predatory journals were first collected in
2010 (9), and became part of public discourse in 2012 (10). The search strategy for the Ovid
databases is included in Appendix 2.

We searched two relevant sources of unpublished grey literature for checklists that help identify
predatory journals and/or publishers: 1) University library websites of the top 10 universities in

6

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

each of the four world regions (Americas, Europe, Asia / Oceania, Africa), as identified by the
Shanghai Academic Ranking of World Universities (http://www.shanghairanking.com/ARWUStatistics-2018.html) and the library websites of Canada's most research-intensive universities
(U15) (search date January 18, 2019); and 2) YouTube videos that contained checklists (search
date January 6, 2019). We limited our YouTube search to the top 50 results filtered by
“relevance” and used a private browser window. Detailed methods of these searches are
available on the Open Science Framework (http://osf.io/g57tf.).

Eligibility criteria
Inclusion criteria
We included studies and/or original checklists developed or published in English, French or
Portuguese (languages spoken by the authors). We defined checklist as a tool whose purpose is
to detect a potential predatory journal where the instructions are in point form / bullet form /
tabular format / listed items. To be an original checklist, items had to have been identified and/or
developed by the study authors or include a novel combination of items from multiple sources, or
an adaptation of another checklist plus items added by the study authors. We first included
studies that discussed the use of an already existing checklist; we used these studies to search out
the paper that discussed the original checklist development and then included only the study that
discussed the original checklist development.

Exclusion criteria
Checklists were not considered original if items were hand-picked from other sources; for
example, if authors identified the five most salient points from an already existing checklist.

7

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

We did not include lists or guidance on recognizing a “legitimate” or “trustworthy” journal.

Study selection
Following de-duplication of the identified titles, we screened records using the online systematic
review software program Distiller Systematic Review (DSR) (Evidence Partners Inc., Ottawa,
Canada). For each stage of screening, data extraction and risk of bias assessment, we pilot tested
a 10% sample of records among five to six reviewers. Screening was performed in two stages.
First (stage 1), based on title and abstract and second (stage 2), based on full-text screening, was
administered by two reviewers independently and in duplicate. At both stages, discrepancies
were resolved through discussion between the reviewers and consultation with a third reviewer,
where necessary.

Data Extraction and Risk of Bias Assessment
For each eligible study, two reviewers independently extracted relevant data into DSR and a
third reviewer resolved any conflicts. The extracted data items were as follows: Checklist name,
number of items in the checklist, whether or not the items were weighted, the number of thematic
categories covered by the checklist (six-item list developed by Cobey et al. (3)), publication
details (name of publication, author and date of publication), approximate time to complete
checklist (reviewers used a timer to emulate the process that a user would go through to use the
checklist and recorded the time as 0-5 minutes, 6-10 minutes, or more than 10 minutes),
language of the checklist, whether or not the checklist was translated and into what language(s),
methods used to develop the checklist (details on data collection, if any), whether or not there
was qualitative guidance (instructions on how to use the checklist and what to do with the

8

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

results) and/or quantitative guidance (instructions on summing the results or quantitatively
assessing the results to inform a decision). The list of extracted data items can be found on the
Open Science Framework (https://osf.io/na756/).

In assessing checklists identified via YouTube, we extracted data items that were presented
visually so that any item or explanation that was delivered by audio only was not included in our
assessment. For example, if presenters only talked about a checklist item but did not have it on a
slide in the video or in a format that could be seen by those watching the video, we did not
extract this data.

To assess risk of bias, we created an a priori list of five questions developed by the research team
for the purpose of this review, adapted from A Checklist for Checklists tool (11) and principles
of internal and external validity (12). The creation of a novel tool to assess risk of bias was
necessary since no formal assessment tool exists for the type of review we conducted. We used
the results of this assessment to determine whether or not the checklist was evidence-based. We
assigned each of the five criterion (listed below) a judgement of “yes” (i.e. low risk of bias), “no”
(i.e. high risk of bias) or “can‟t tell” (i.e. unclear risk of bias) (see coding manual with
instructions for assessment to determine risk of bias ratings: https://osf.io/sp4vx/). If the checklist
scored three or more “yes” answers on the questions below, we considered it evidence-based.
Two reviewers independently assessed data quality in DSR where discrepancies were resolved
through discussion. A third reviewer was called to resolve conflicts where necessary.

The five criteria used to assess risk of bias in this review were as follows:

9

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

1. Did the developers of the checklist represent more than one stakeholder group (e.g.
researchers, academic librarians, publishers)?
2. Do the developers report gathering any data for the creation of the checklist (i.e. conduct a
study on potential predatory journals, carry out a systematic review, collect anecdotal data)?
3. Does the checklist meet at least one of the following criteria: (1) Has title that reflects its
objectives; (2) Fits on one page; (3) Each item on the checklist is one sentence?
4. Was the checklist pilot-tested or trialed with front-line users (e.g. researchers, students,
academic librarians)?
5. Do the authors report how many criteria in the checklist a journal must meet in order to be
considered predatory?

In assessing websites, we used a “two-click rule” to locate information. Once on the checklist
website, if we did not find the information within two mouse clicks, we determined no
information was available.

Data Synthesis and Analysis
We examined the checklists qualitatively and conducted qualitative comparisons of the items
between the included checklists to gauge their agreement on content by item and overall. We
summarized checklists in table format to facilitate inspection and discussion of findings.
Frequencies and percentages were used to present characteristics of the checklists. We used the
checklist developed by Shamseer et al. (13) as the reference checklist and compared our results
to the reference list. We chose this as the reference list because of the rigorous empirical data
provided by authors to ascertain characteristics of potential predatory journals.
10

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Role of the funding source
This project received no specific funding.

RESULTS
Deviations from our protocol
We refined our definition of an original checklist to exclude checklists that were comprised of
items taken solely from another checklist. Checklists made up of items taken from more than one
source were considered original even when the developers did not create the checklist
themselves. For reasons of feasibility, we did not search the reference lists of included studies to
identify further potentially relevant studies.
We had anticipated using the liberal accelerated method to screen titles and abstracts. Instead, we
had two reviewers screen records independently and in duplicate. We changed methods because
it became feasible to use the traditional screening approach, which also reduced the required
number of full-text articles to be ordered.
After completing data collection, we recognized that checklists were being published in
discipline-specific journals. We wanted to determine what disciplines were represented and in
what proportion. We conducted a scan of the journals and used an evolving list of disciplines to
assign to the list of journals.
Study selection

11

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Following the screening of 1433 records, we identified 93 original checklists to be included in
our study, made up of 53 records from an electronic database search, 30 from university library
websites and 10 from YouTube (see full details in Figure 1: PRISMA flow diagram).
[Insert Figure 1 about here]
Study characteristics
We identified 53 checklists identified through our search of electronic databases. The numbers of
checklists identified increased over time: one each in 2012 (10), 2013 (14) and then increases in
the most recent years (16 in 2017 (13,15–29) and 12 in 2018 (30–41)). We identified 30 original
checklists (1,42–70) from university library websites. More checklists were published in more
recent years (2017 = 4 (44–47); 2018 = 7 (48–54); 2019 = 11 (55–65); five checklists listed no
publication date). We identified 10 more checklists from YouTube (71–80) that included one
uploaded in 2015 (71), six in 2017 (72–77) and three in 2018 (78–80). See Table 1 for full study
characteristics.
[Insert Table 1 about here]
Language and translation
Almost all checklists were published in English (n = 90, 97%), and the remaining checklists in
French (n = 3, 10%) (48,51,60). Two additional English checklists identified through university
library websites were translated into French (54,66) and one was translated into Hebrew (68).
Approximate time for user to complete checklist, number of items per checklist, and weighting
Most checklists could be completed within five minutes (n= 68, 73%); 17 checklists (18%) could
be completed in six to 10 minutes (15,16,18,20,31,33,38–41,52–54,61,71,100,101) and eight
12

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

checklists (9%) took more than 10 minutes to complete (10,19,45,48,65,75,102,103). Checklists
contained a mean of 11 items each, and a range of between three and 64 items. Items were
weighted in two checklists (54,103).
Qualitative and quantitative guidance
Qualitative guidance on how to use the results of checklists was provided on 15 checklists (16%)
(20,30,37,46,49,50,54,58,64,66,67,96,97,100,103), and quantitative guidance was provided on
two checklists (54,103), i.e. prescribing a set number of criteria that would identify the journal or
publisher as predatory.
Methods used to develop checklists
In order to develop the checklists, authors noted using analysis by specialists (45), information
from already existing checklists (88,90,102), using existing literature on predatory journals to
pick the most salient features to create a new checklist (30,41,96), developing checklists after
empirical study (13,26,38,103) or after personal experiences (14).

Risk of bias assessment
Among all 93 checklists, there were three (3%) assessed as evidence-based (26,96,103) (see
Table 2 for risk of bias assessment detailed results including whether or not a checklist was
determined to be evidence-based, i.e. rated as low risk of bias for at least three of the criteria).
[Insert Table 2 about here]
Results for risk of bias criteria

13

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Criterion #1: Representation of more than one stakeholder group in checklist development
For the majority of checklists (n = 88, 94%), it was unclear whether there was representation of
more than one stakeholder group in the checklist development process. The remaining five
checklists were developed with representation from more than one stakeholder group (low risk of
bias) (21,45,54,58,96).
Criterion #2: Authors reported gathering data to inform checklist development
In most studies (n = 55, 59%) there was no mention of data gathering for checklist development
(low risk of bias); in 26 cases (28%), one or two citations were noted next to checklist items,
with no other explanation of item development or relevance (high risk of bias) (17,18,21–
23,29,31,32,34,35,39–41,44,52,81,82,84–86,89,91,93,95,99,102). Twelve records (13%)
included a description of authors gathering data to develop a checklist for this criterion (low risk
of bias) (13,14,25,30,36–38,42,49,92,96,103).
Criterion #3: At least one of the following: Title that reflected checklist objective; Checklist fits
on one page; Items were one sentence long
Most checklists were assessed as low risk of bias on this criterion, with 83 of the checklists
(90%) meeting at least one of the noted criteria (relevant title, fits on one page, items one
sentence long).
Criterion #4: Authors reported pilot testing the checklist
In the majority of studies (n = 91, 98%), authors did not report pilot testing during the checklist
development stages.

14

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Criterion #5: Checklist instructions included a threshold number of criteria to be met in order to
be considered predatory
The majority of studies (n = 90, 97%), did not include a threshold number of criteria to be met in
order for the journal or publisher to be considered predatory (high risk of bias).

Assessment of the thematic content of the included checklists
We found checklists covered the six thematic categories, as identified by Cobey et al. (3), as
follows (see Table 3 for thematic categories and descriptions of categories):
[Insert Table 3 about here]
Journal operations: 85 checklists (91%) assessed information on the journal‟s operations.
Assessment of previously published articles: 40 checklists (43%) included questions on the
quality of articles published in the journal in question.
Editorial and peer review process: 77 checklists (83%) included questions on the editorial and
peer review process.
Communication: 71 checklists (76%) included an assessment of the manners in which
communication is set up between the journal / publisher and the author.
Article processing charges: 61 checklists (66%) included an assessment of information on article
processing charges.

15

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Dissemination, indexing and archiving: 62 checklists (67%) included suggested ways in which
submitting authors should check for information on dissemination, indexing and archiving
procedures of the journal and publisher.
Across all 93 checklists, a mean of four out of the six thematic categories was covered,
demonstrating similar themes covered by all checklists. Twenty percent of checklists (n = 19),
including the reference checklist, covered all six categories
(10,13,15,18,19,25,31,33,39,41,45,52,54,61,65,66,75,101,102). Assessment of previously
published articles was the category least often included in a checklist (n = 40, 43%), and a
mention of the journal operations was the category most often included in a checklist (n = 85,
91%).
Discipline-specific journals
We observed that there were different checklists published in journals of distinct disciplines, i.e.
of the checklists published in academic journals, 10 were published in nursing journals (22%),
eight were published in journals related to general medicine (18%), four in emergency medicine
journals (9%), four in information science journals (9%), four in psychiatry and behavioural
science journals (9%) and the remaining checklists were published in a variety of other
discipline-specific journals, with three or fewer checklists per discipline (specialty medicine,
paediatric medicine, general medicine and surgery, medical education, dentistry, ecology, and
geography).

DISCUSSION

16

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

The number of checklists developed to help identify predatory journals and/or publishers has
increased since 2012. Since 2015, the numbers have increased more dramatically (n = 81, 87%).
Comparing the 93 checklists we identified to the reference checklist, we observed that on
average, the contents of the checklists are similar in terms of items that should be screened, time
to complete the checklist, categories or domains covered by the checklist, number of items in the
checklist (this number does vary considerably, however the average number of items is more
consistent with the reference list) and lack of qualitative and quantitative guidance on completing
the checklists. Furthermore, only 3% of checklists were deemed evidence-based, few checklists
weighted any items (2%) and few checklists were developed through empirical study (4%).
Summary of evidence
In total, we identified 93 checklists to help identify predatory journals and/or publishers. A
search of electronic databases resulted in 53 original checklists, a search of library websites of
top universities resulted in 30 original checklists and a filtered and limited search of YouTube
returned 10 original checklists. Overall, checklists could be completed quickly, covered similar
categories of topics and were lacking in guidance that would help a user determine if the journal
or publisher was indeed predatory.
Strengths and Limitations
We used a rigorous systematic review process to conduct the study. We also searched multiple
data sources including published literature, university library websites, globally, and YouTube.
We were limited by the languages of checklists (English, French and Portuguese), however, it
has been determined, that the majority of academic literature is published in English (104) and so
we are confident we captured the majority of checklists or at least a representative sample. For
17

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

reasons of feasibility, we were not able to capture all checklists available. Our reference checklist
did not qualify as evidence-based when using our predetermined criteria to assess risk of bias; a
possible reason could be because the list of characteristics in the reference list was not initially
intended as a checklist per se. Creating a useable checklist requires attention to other details, like
those we identify in our risk of bias criteria, that perhaps were not attended to by Shamseer et al.
because of the difference in its intended purpose.
We noted that the “Think. Check. Submit” checklist (105) was referenced in many publications
and we believe it is used often as guidance for authors in order to identify presumed legitimate
journals. However, we did not include this checklist in our study because we excluded checklists
that help to identify presumed legitimate publications as opposed to potential predatory ones.
Conclusions
In our search for checklists to help authors identify potential predatory journals, we found great
similarity across checklist media and across journal disciplines in which the checklists were
published.
Although many of the checklists were published in field-specific journals and / or addressed a
specific audience, the content of the lists did not differ much, only a small proportion reported on
empirical methods used to design the checklists, and only a few checklists were deemed
evidence-based according to our criteria. Importantly, very few offered concrete guidance on
using the checklists or offered any threshold that would guide authors to identify definitively if
the journal was predatory. The lack of checklists providing threshold values could be due to the
fact that a definition of predatory journals does not currently exist (3). The provision of detailed
requirements that would qualify a journal as predatory therefore would be a challenge.
18

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

With this large number of checklists in circulation, and the lack of explicit and exacting
guidelines to identify predatory publications, are authors at continued risk of publishing in
journals that do not follow best publication practices? We see some value in discipline-specific
lists for the purpose of more effective dissemination. However, this needs to be balanced against
the risk of confusing researchers and overloading them with choice (4). If most of the domains in
the identified checklists are similar across disciplines, would a single list, relevant in all
disciplines, result in less confusion and maximize dissemination and enhance implementation?
In our study, we found no checklist to be optimal. Currently, we would caution against any
further development of checklists and instead provide the following as guidance to authors:
Look for a checklist that:
1- Provides a threshold value for criteria to assess potential predatory journals, e.g. if the
journal contains these three checklist items then we recommend avoiding submission;
2- Has been developed using rigorous evidence, i.e. empirical evidence that is described or
referenced in the publication.
Using an evidence-based tool with a clear threshold for identifying potential predatory journals
will help reduce the burden of research waste occurring as a result of the proliferation of
predatory publications.

19

Author‟s version before peer review 08 29 19

Table 1. Characteristics of checklists (oldest to most recently published)
Study

Checklist name

Number
of items

Items
weighted
Y/N

Time to
complete
min

Methods used to
develop checklist
(NR = Not reported)

Qualitative
guidance
Y/N

Quantitative
guidance
Y/N

Checklists from electronic journal databases n = 53
Index checklist
Shamseer, 2017 (13)

Beall, 2012 (10)
Beall, 2013 (14)
Crawford, 2014 (100)
Knoll, 2014 (81)
Lukic, 2014 (82)

Beall, 2015 (102)

Bhad, 2015 (83)
Bradley-Springer, 2015 (84)
Hemmat Esfe, 2015 (85)
INANE Predatory Publishing
Practices Collaborative, 2015
(87)
Pamukcu Gunaydin, 2015
(86)
Proehl, 2015 (88)

1
2

Salient characteristics of
potential predatory
journals
Criteria for Determining
Predatory Open-Access
Publishers
Some warning signs of
questionable publishers
No title
Avoiding Predatory OA
Journals
No title

Criteria for Determining
Predatory Open-Access
Publishers
How should one suspect
a journal could be a
predatory journal?
No title
Features of the Fake
Journals
Guidelines for evaluating
the integrity of a journal /
Red flags
No title
Guidelines for evaluating
the integrity of a journal -

13

N

0-5

5

No

10+ min

7

No

0-5 min

11

No

6-10 min

17
13

No
No

0-5 min
0-5 min

5

No

9
6

Cross-sectional analysis
93 predatory journals, 99
OA, 100 subscription
based journals assessed
1
Criteria based on AOSPA
Code of Conduct, two
2
COPE publications
Observational research on
own emails received
Assessed all criteria in
Beall's criteria

No

No

No

No

No

No

Yes

No

No
No

No
No

10+ min

Works cited
Multiple references
Criteria based on COPE
documents: Code of
Conduct and Principles of
Transparency and Best
Practices in Scholarly
Publication

No

No

No
No

0-5 min
0-5 min

NR
Multiple references

No
No

No
No

9

No

0-5 min

NR

No

No

7

No

0-5 min

No

No

10

No

0-5 min

No

No

7

No

0-5 min

Limited literature review
Authors' top 10 based on
other references
References to other
checklists: COPE etc.

No

No

OASPA = Open Access Scholarly Publishers Association
COPE = Committee on Publication Ethics

20

Author‟s version before peer review 08 29 19

Stone, 2015 (89)
Yucha, 2015 (90)
Cariappa, 2016 (91)
Carroll, 2016 (92)

Dadkhah, 2016 (103)

Fraser, 2016 (93)

Glick, 2016 (94)
Glick, 2016a (95)
Hansoti, 2016 (96)
Morley, 2016 (97)
Nolan, 2016 (98)
Ward, 2016 (101)
Abadi, 2017 (15)
Balehegn, 2017 (29)
Berger, 2017 (16)
Das, 2017 (17)
Erfanmanesh 2017 (18)
Eriksson, 2017 (19)
Janodia, 2017 (20)
Khan, 2017 (21)

3

Red flags
Guidelines for evaluating
the integrity of a journal
Guidelines for Evaluating
the Integrity of a Journal
- Red flags
Telltale signs Something is wrong!
Common Practices of
Predatory Open Access
Publications
Criteria to rank predatory
journals
Red Flags for
Recognizing Predatory
Journals
What you can expect
from a predatory
publisher
Clues suggesting a
"predatory" journal
Overall Approach to
Choosing the Journal
10 steps to spot a
predatory publisher
None section title exists
but not title
No title
No title
No title
Detailed Characteristics
of Predatory Journals
How to identify
predators?
No title
Characteristics of a
predatory journal
No title
Attributes,
characteristics and

6

No

0-5 min

Other credible resources:
3
COPE, INANE , other

No

No

10

No

0-5 min

Multiple references to
other checklists

No

No

7

No

0-5

Some literature cited

No

No

4

No

0-5 min

No

No

14

Yes

10+ min

Limited literature review
Observational study of
150 journals 80 predatory,
70 non

Yes

Yes

6

No

0-5 min

Two citations

No

No

7

No

0-5 min

Multiple citations

No

No

11

No

0-5 min

Multiple references

No

No

11

No

0-5 min

Extensive literature review

Yes

No

10

No

0-5 min

A few citations

Yes

No

5
8
26
5

No
No
No
No

0-5 min
6-10 min
6-10 min
0-5 min

None noted
None listed
NR
References

No
No
No
No

No
No
No
No

15

No

6-10 min

NR

No

No

15
18

No
No

0-5 min
6-10 min

Two citations
Multiple references

No
No

No
No

25
9

No
No

10+
6-10 min

Limited literature review
NR

No
Yes

No
No

9

No

0-5 min

Citations

No

No

INANE = International Academy of Nursing Editors

21

Author‟s version before peer review 08 29 19

Klyce, 2017 (22)
Manca, 2017 (23)
Miller, 2017 (24)

Misra, 2017 (25)

Mouton, 2017 (26)

Oren, 2017 (27)

Shamseer, 2017 (13)

Stratton, 2017 (28)

Ajuwon, 2018 (32)
Bowman, 2018 (33)
Gerberi, 2018 (34)

practices of potential
predatory journals
Common characteristics
of predatory journals
No title
Signs of a Predatory
Publisher
Red flags based on
which one may suspect
the legitimacy of a
journal
Comparing the
characteristics of good
practice in scholarly
publishing with those of
predatory publishing
Obvious signs of
predatory journals
Salient characteristics of
potential predatory
journals
Characteristics of Health
and Medical Journal
Publishing Formats Open Access Predatory
Characteristics of
Predatory Publishers
and Journals
Identifying Predatory
Journals and Publishers
Quick List of Predatory
Publisher Warning Signs

13
6

No
No

0-5 min
0-5 min

Limited literature review
Limited literature review

No
No

No
No

8

No

0-5 min

NR

No

No

17

No

0-5 min

Literature review and
authors' experiences

No

No

In-depth assessment of
journals identified by
Beall's list where South
African authors published

No

No

No

No

No

No

7

No

0-5 min

7

No

0-5 min

13

No

0-5 min

NR
Observational study 93
predatory journals, 99
4
OA , 100 subscriptionbased journals assessed

4

No

0-5 min

Cited references

No

No

12

No

0-5 min

Citations from other
sources

No

No

29

No

6-10 min

NR

No

No

7

No

0-5 min

No

No

4

No

0-5

Limited literature review
Analysis of papers 20132017 predatory Beall's vs
non

No

No

8

No

0-5

NR

Yes

No

25

No

0-5 min

Brief literature review

Yes

No

Kokol, 2018 (36)

Lewinski, 2018 (37)
McCann, 2018 (30)

4

No title
Eight tips to identify a
predatory journal or
publisher
Guidelines for authors to
avoid predatory

OA = Open Access

22

Author‟s version before peer review 08 29 19
publishers

Memon, 2018 (38)

Nnaji, 2018 (39)
O’Donnell, 2018 (31)
Pamukcu Gunaydin, 2018
(35)
Power, 2018 (40)

Richtig, 2018 (41)

Wikipedia, 2019 (99)

No title
No title

14
11

No
No

6-10 min
6-10 min

Identifying a predator
How to avoid sending
your work to a predatory
journal

17

No

6-10 min

5

No

0-5

No title
Criteria identified or
suggested in the
literature that can
potentially be used to
identify predatory
journals
No title

11

No

13
10
Number
of items

Study
Checklist name

Collecting emails and web
pages of each journal
/publisher. Used Beall’s
5
list, PubMed, DOAJ ,
Thomson and Reuters
now Clarivate Analytics
Two references
Other evidence-based
checklist

No
No

No
No

No

No

No

No

6-10 min

Limited literature review
References COPE,
INANE

No

No

No
No

6-10
0-5 min

Literature review
Multiple citations

No
No

No
No

Items
weighted
Y/N

Time to
complete
min

Methods used to
develop checklist

Qualitative
guidance
Y/N

Quantitative
guidance
Y/N

No

No

No
No

No
No

No
No

No
No

No

No

Checklists from university library websites n = 30
[REFERENCE CHECKLIST]
Shamseer, 2017

Salient characteristics of
potential predatory
journals

13

N

0-5

None
None
Some warning signs to
look out for
None

11
5

No
No

0-5 min
0-5 min

4
7

No
No

0-5 min
0-5 min

None

64

No

10+ min

Carlson, 2014 (42)
Clark, 2015 (1)
University of Edinburgh,
2015 (43)
Africa Check, 2017 (44)
Cabell's – Clarivate, 2017
(45)

5

Cross sectional analysis
93 predatory journals, 99
OA, 100 subscriptionbased journals assessed
Based on personal
experiences looking into
questionable OA journals
NR
NR
NR
Analysis by specialists
see:
https://www2.cabells.com/

DOAJ = Directory of Open Access Journals

23

Author‟s version before peer review 08 29 19
about-blacklist
Duke University Medical
Center, 2017 (46)
University of Calgary, 2017
(47)
Coopérer en information
scientifique et technique,
2018 (48)
Eaton, University of Calgary
2018 (49)
Lapinksi, Harvard, 2018 (50)
Sorbonne Université, 2018
(51)
University of Alberta, 2018
(53)
University of British
Columbia, 2018 (52)
University of Toronto
Libraries, 2018 (54)
Dalhousie University, 2019
(55)
McGill University, 2019 (56)
McMaster University, 2019
(57)
Prater, American Journal
Experts, 2019 (58)
Ryerson University Library,
2019 (59)
Université Laval, 2019 (60)
University of Cambridge,
2019 (61)
University of Pretoria, 2019
(62)
University of Queensland
Library, 2019 (64)
University of Queensland
Library, 2019a (63)
University of Witwatersrand,
2019 (65)
Canadian Association of
Research Libraries, ND (66)
Columbia University

Be iNFORMEd Checklist

6

No

0-5 min

NR

Yes

No

No title

6

No

0-5 min

NR

No

No

No title

35

No

10+ min

NR

No

No

No title
No title
Comment repérer un
éditeur prédateur

12
3

No
No

0-5 min
0-5 min

Other sources cited
NR

Yes
Yes

No
No

12

No

0-5 min

NR

No

No

No title

19

No

6-10 min

NR

No

No

No title
Identifying Deceptive
Publishers: A Checklist
How to recognize
predatory journals
No title

16

No

6-10 min

NR

No

No

22

Yes

6-10 min

NR

Yes

Yes

6
4

No
No

0-5 min
0-5 min

NR
NR

No
No

No
No

No title

6

No

0-5 min

NR

No

No

No title

8

No

0-5 min

NR

Yes

No

No title
No title

5
8

No
No

0-5 min
0-5 min

NR
NR

No
No

No
No

No title

9

No

6-10 min

NR

No

No

No title

19

No

0-5 min

NR

No

No

No title
Red Flags for Open
Access Journals
Predatory Publisher
Checklist
How to assess a journal
A.K.A. How not to
publish in an undesirable
journal
No title

6

No

0-5 min

NR

No

No

9

No

0-5 min

NR

Yes

No

26

No

10+ min

NR

No

No

12
5

No
No

0-5 min
0-5 min

NR
NR

Yes
Yes

No
No

24

Author‟s version before peer review 08 29 19
Libraries, ND (67)
Technion Library, ND (68)
UC Berkley, ND (69)
University of Ottawa
Scholarly Communication,
ND (70)

No title
No title

10
3

No
No

0-5 min
0-5 min

NR
Cited 1 paper

No
No

No
No

No title

12

No

0-5 min

NR

No

No

Number
of items

Items
weighted
Y/N

Time to
complete
min

Methods used to
develop checklist

Qualitative
guidance
Y/N

Quantitative
guidance
Y/N

No

No

Study
Checklist name
Checklists from YouTube n = 10
[REFERENCE CHECKLIST]
Shamseer, 2017
Robbins, Western Sydney
University, 2015 (71)
Attia, 2017 (72)
Kysh, USC Keck School of
Medicine, 2017 (73)
McKenna, Rhodes
University, 2017 (74)
Nicholson, University of
Witwatersrand, 2017 (75)
Raszewski, 2017 (76)
Seal-Roberts, Springer
Healthcare, 2017 (77)
Menon, SCMS Group of
Educational Institutions,
India and Berryman,
Cabell’s, 2018 (78)
Office of Scholarly
Communication, Cambridge
University, 2018 (79)
Weigand, UNC Libraries,
2018 (80)

13

N

0-5

Cross sectional analysis
93 predatory journals, 99
OA, 100 subscriptionbased journals assessed

Red Flags
Spot Predatory
Publishers
Characteristics of
Predatory Publishers
Predatory Publications:
Shark Spotting

9

No

6-10 min

NR

No

No

4

No

0-5 min

NR

No

No

9

No

0-5 min

NR

No

No

7

No

0-5 min

NR

No

No

Cautionary Checklist
What to watch out for
So how do we recognize
a predatory publisher?

36
4

No
No

10+ min
0-5 min

NR
NR

No
No

No
No

10

No

0-5 min

NR

No

No

Characteristics of
Predatory Journals

7

No

0-5 min

NR

No

No

None

12

No

0-5 min

NR

No

No

No title

5

No

0-5 min

NR

No

No

Salient characteristics of
potential predatory
journals

25

Author‟s version before peer review 08 29 19

Table 2. Risk of bias assessment. Three „Yes‟ assessments results in an overall assessment of evidence based.

Study

Represent 1+
stakeholder
groups
(Y/N/U)*

Gather data for
checklist
development
(Y/N/Only
citations/ U)

Checklists from electronic journal databases (n = 53)
Reference checklist
Shamseer, 2017 (13)
U
Y
Beall, 2012 (10)
U
U
Beall, 2013 (14)
U
Y
Crawford, 2014 (100)
U
U
Knoll, 2014 (81)
U
Only citations
Lukic, 2014 (82)
U
Only citations
Beall, 2015 (102)
U
Only citations
Bhad, 2015 (83)
U
U
Bradley-Springer, 2015
(84)
U
Only citations
Hemmat Esfe, 2015 (85) U
Only citations
INANE Predatory
Publishing Practices
Collaborative, 2015 (87) U
U
Pamukcu Gunaydin,
2015 (86)
U
Only citations
Proehl, 2015 (88)
U
U
Stone, 2015 (89)
U
Only citations
Yucha, 2015 (90)
U
U
Cariappa, 2016 (91)
U
Only citations
Carroll, 2016 (92)
U
Y
Dadkhah, 2016 (103)
U
Y
Fraser, 2015 (93)
U
Only citations
Glick, 2016 (94)
U
U
Glick, 2016a (95)
U
Only citations

Does the checklist meet at least one of
these criteria?
(count only the last column in total)
Meets at
Fits on
Each item
least
Title
one
one
one of
(Y/N)
page
sentence
these
(Y/N)
(Y/N)
(Y/N)

Pilot
test
(Y/N/U)

Y
N
Y
N
Y
N
N
Y

Y
N
Y
Y
Y
Y
N
Y

Y
N
Y
Y
N
N
N
Y

Y
Y
Y
Y
Y
Y
N
Y

U
U
U
U
U
U
U
U

N
N
N
N
N
N
N
N

N
N
N
N
N
N
N
N

N
N

Y
Y

N
Y

Y
Y

U
U

N
N

N
N

Y

Y

Y

Y

U

N

N

N
N
N
Y
Y
Y
Y
Y
Y
Y

Y
Y
Y
Y
Y
Y
Y
Y
Y
Y

N
Y
Y
Y
Y
Y
Y
Y
Y
Y

Y
Y
Y
Y
Y
Y
Y
Y
Y
Y

U
U
U
U
U
U
Y
U
U
U

N
N
N
N
N
N
Y
N
N
N

N
N
N
N
N
N
Y
N
N
N

Includes
number of
criteria to be
considered
predatory (Y/N)

Overall
assessment (is
it evidencebased?) (Y/N)

26

Author‟s version before peer review 08 29 19
Hansoti, 2016 (96)
Morley, 2016 (97)
Nolan, 2016 (98)
Ward, 2016 (101)
Abadi, 2017 (15)
Balehegn, 2017 (29)
Berger, 2017 (16)
Das, 2017 (17)
Erfanmanesh, 2017 (18)
Eriksson, 2017 (19)
Janodia, 2017 (20)
Khan, 2017 (21)
Klyce, 2017 (22)
Manca, 2017 (23)
Miller, 2017 (24)
Misra, 2017 (25)
Mouton, 2017 (26)
Oren, 2017 (27)
Shamseer, 2017 (13)
Stratton, 2017 (28)
Ajuwon, 2018 (32)
Bowman, 2018 (33)
Gerberi, 2018 (34)
Pamukcu Gunaydin,
2018 (35)
Kokol, 2018 (36)
Lewinski, 2018 (37)
McCann, 2018 (30)
Memon, 2018 (38)
Nnaji, 2018 (39)
O’Donnell, 2018 (31)
Power, 2018 (40)
Richtig, 2018 (41)
Wikipedia, 2019 (99)

Y
U
U
U
U
U
U
U
U
U
U
Y
U
U
U
U
U
U
U
U
U
U
U

Y
U
U
U
U
Only citations
U
Only citations
Only citations
U
U
Only citations
Only citations
Only citations
U
Y
U
U
Y
U
Only citations
U
Only citations

N
N
N
N
N
N
N
Y
Y
Y
Y
Y
Y
N
Y
Y
Y
Y
Y
Y
Y
Y
Y

Y
N
Y
N
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y

N
N
N
N
Y
Y
N
Y
Y
Y
N
N
Y
N
Y
Y
N
Y
Y
Y
Y
N
N

Y
N
Y
N
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y
Y

U
U
U
U
U
U
U
U
U
U
U
U
U
U
U
U
Y
U
U
U
U
U
U

N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
Y
N
N
N
N
N
N

Y
N
N
N
N
N
N
N
N
N
N
N
N
N
N
N
Y
N
N
N
N
N
N

U
U
U
U
U
U
U
U
U
U

Only citations
Y
Y
Y
Y
Only citations
Only citations
Only citations
Only citations
Only citations

Y
N
Y
Y
Y
Y
N
N
Y
N

Y
Y
Y
Y
Y
N
N
N
Y
Y

N
Y
N
Y
Y
N
N
N
N
Y

Y
Y
Y
Y
Y
Y
N
N
Y
Y

U
U
U
U
U
U
U
U
U
U

N
N
N
N
N
N
N
N
N
N

N
N
N
N
N
N
N
N
N
N

27

Author‟s version before peer review 08 29 19

Study

Gather data for
checklist
development
(Y/N/Only
citations/ U)

Represent 1+
stakeholder
groups
*
(Y/N/U)

Checklists from university library websites (n = 30)
Reference checklist
Shamseer, 2017 (13)
U
Y
Carlson, 2014 (42)
U
Y
Clark, 2015 (1)
U
U
University of Edinburgh,
2015 (43)
U
U
Africa Check, 2017 (44)
U
Only citations
Cabell's - Clarivate,
2017 (45)
Y
U
Duke University Medical
Center, 2017 (46)
U
U
University of Calgary,
2017 (47)
U
U
Coopérer en information
scientifique et
technique, 2018 (48)
Eaton, University of
Calgary, 2018 (49)
Lapinski, Harvard
University, 2018 (50)
Sorbonne Université,
2018 (51)
University of Alberta,
2018 (53)
University of British
Columbia, 2018 (52)
University of Toronto
Libraries, 2018 (54)

Does the checklist meet at least one of
these criteria?
(count only the last column in total)
Meets at
Fits on
Each item
least
Title
one
one
one of
(Y/N)
page
sentence
these
(Y/N)
(Y/N)
(Y/N)

Pilot
test
(Y/N/U)

Y
N
N

Y
N
Y

Y
N
N

Y
N
Y

U
U
U

N
N
N

N
N
N

Y
N

Y
Y

Y
N

Y
Y

U
U

N
N

N
N

N

N

Y

Y

U

N

N

N

N

N

N

U

N

N

N

Y

N

Y

U

N

N

Includes
number of
criteria to be
considered
predatory (Y/N)

Overall
assessment (is
it evidencebased?) (Y/N)

U

U

N

N

Y

Y

U

N

N

U

Y

N

Y

Y

Y

U

N

N

U

U

N

N

N

N

U

N

N

U

U

Y

Y

Y

Y

U

N

N

U

U

N

N

N

N

U

N

N

U

Only citations

Y

N

N

Y

U

N

N

Y

U

N

N

N

Y

U

Y

N

28

Author‟s version before peer review 08 29 19
Dalhousie University,
2019 (55)
McGill University, 2019
(56)
McMaster University,
2019 (57)
Prater - American
Journal Experts, 2019
(58)
Ryerson University
Library, 2019 (59)
Université Laval, 2019
(60)
University of
Cambridge, 2019 (61)
University of Pretoria,
2019 (62)
University of
Queensland Library,
2019 (64)
University of
Queensland Library,
2019a (63)
University of
Witwatersrand, 2019
(65)
Canadian Association of
Research Libraries, ND
(66)
Columbia University
Libraries, ND (67)
Technion Library, ND
(68)
UC Berkeley, ND (69)
University of Ottawa
Scholarly
Communication, ND
(70)

U

U

Y

Y

N

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

N

Y

Y

Y

U

N

N

Y

U

N

N

N

N

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

N

Y

Y

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U

U

Y

N

Y

Y

U

N

N

U

U

N

Y

Y

Y

U

N

N

U

U

N

Y

N

Y

U

N

N

U
U

U
U

N
N

Y
Y

N
N

Y
Y

U
U

N
N

N
N

U

U

N

Y

N

Y

U

N

N

29

Author‟s version before peer review 08 29 19

Study

Represent 1+
stakeholder
groups
*
(Y/N/U)

Gather data for
checklist
development
(Y/N/Only
citations/ U)

Does the checklist meet at least one of
these criteria?
(count only the last column in total)
Meets at
Fits on
Each item
least
Title
one
one
one of
(Y/N)
page
sentence
these
(Y/N)
(Y/N)
(Y/N)

Checklists from YouTube (n = 10) [website URLs available in appendix]
Reference checklist
Y (cross-sectional
Shamseer, 2017 (13)
U
study on journals)
Y
Robbins S, Western
Sydney University, 2015
(71)
U
U
Y
Attia, 2017 (72)
U
U
Y
Kysh, USC Keck School
of Medicine, 2017 (73)
U
U
Y
McKenna, Rhodes
University, 2017 (74)
U
U
Y
Nicholson, University of
Witwatersrand, 2017
(75)
U
U
Y
Raszewski, 2017 (76)
U
U
Y
Seal-Roberts, Springer
Healthcare, 2017 (77)
U
U
Y
Menon, SCMS Group of
Educational Institutions,
India and Berryman,
Cabells, 2018 (78)
U
U
Y
Office of Scholarly
Communication,
Cambridge University,
2018 (79)
U
U
N
Weigand, UNC
Libraries, 2018 (80)
U
U
N

Pilot
test
(Y/N/U)

Includes
number of
criteria to be
considered
predatory (Y/N)

Overall
assessment (is
it evidencebased?) (Y/N)

Y

Y

Y

U

N

N

Y
N

Y
N

Y
Y

U
U

N
N

N
N

Y

Y

Y

U

N

N

Y

Y

Y

U

N

N

N
Y

N
N

Y
Y

U
U

N
N

N
N

Y

Y

Y

U

N

N

Y

Y

Y

U

N

N

N

Y

Y

U

N

N

Y

Y

Y

U

N

N

*Y = Yes, N = No, U = Unclear

30

Author‟s version before peer review 08 29 19

Table 3. Thematic categories covered by the checklists (oldest to most recently published)
Categories covered by checklist*
Study
Journal
Operations
Checklists from electronic journal databases n = 53
[REFERENCE CHECKLIST] Shamseer, 2017
Beall, 2012 (10)
Beall, 2013 (14)

X
X
X

Crawford, 2014 (100)
Knoll, 2014 (81)
Lukic, 2014 (82)
Beall, 2015 (102)
Bhad, 2015 (83)
Bradley-Springer, 2015 (84)
Hemmat Esfe, 2015 (85)
INANE Predatory Publishing Practices
Collaborative, 2015 (87)
Pamukcu Gunaydin, 2015 (86)
Proehl, 2015 (88)
Stone, 2015 (89)
Yucha, 2015 (90)
Cariappa, 2016 (91)
Carroll, 2016 (92)
Dadkhah, 2016 (103)
Fraser, 2016 (93)
Glick, 2016 (94)

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

Glick, 2016a (95)
Hansoti, 2016 (96)
Morley, 2016 (97)
Nolan, 2016 (98)
Ward, 2016 (101)

X
X
X
X

Article

X
X
X
X

X

Editorial and Peer
Review

X
X
X
X
X
X
X

X
X
X

X

X
X

X
X
X
X
X
X
X
X
X
X

Communications

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X

X
X

X

Dissemination,
indexing +
archiving

Article Processing
Charge

X
X
X
X
X
X

X
X

X
X
X
X

X
X

X
X
X
X
X
X
X

X

X
X
X
X
31

Author‟s version before peer review 08 29 19

Abadi, 2017 (15)

X

X

X

X

X

X
X
X
X

X

X
X

X
X

X
X
X
X
X
X

Balehegn, 2017 (29)
Berger, 2017 (16)
Das, 2017 (17)
Erfanmanesh, 2017 (18)
Eriksson, 2017 (19)
Janodia, 2017 (20)
Khan, 2017 (21)
Klyce, 2017 (22)
Manca, 2017 (23)
Miller, 2017 (24)
Misra, 2017 (25)
Mouton, 2017 (26)
Oren, 2017 (27)
Shamseer, 2017 (13)

X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X

Stratton, 2017 (28)
Ajuwon, 2018 (32)
Bowman, 2018 (33)
Gerberi, 2018 (34)

X
X
X

Kokol, 2018 (36)
Lewinski, 2018 (37)
McCann, 2018 (30)
Memon, 2018 (38)
Nnaji, 2018 (39)
O’Donnell, 2018 (31)
Pamukcu Gunyadin, 2018 (35)
Power, 2018 (40)
Richtig, 2018 (41)
Wikipedia 2019 (99)
TOTALS /53 checklists from electronic journal
databases (n, %)

X
X
X
X
X
X
X
X
47, 89

X
X
X
X

X
X

X
24, 45

X
X

X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X

X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
X

45, 85

42, 79

X

X
X
X
X

X
X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X
X

X
X
X

X
X
X
X
X
X

34, 64

34, 64

32

Author‟s version before peer review 08 29 19

Categories covered by checklists*
Study
Journal
Operations
Checklists from university library websites n = 30
[REFERENCE CHECKLIST] Shamseer, 2017 (13) X
Carlson, 2014 (42)
Clark, 2015 (1)
University of Edinburgh, 2015 (43)
Africa Check, 2017 (44)
Cabell's – Clarivate, 2017 (45)
Duke University Medical Center, 2017 (46)
University of Calgary, 2017 (47)
Coopérer en information scientifique et technique,
2018 (48)
Eaton, University of Calgary, 2018 (49)

X
X
X
X
X
X
X

Editorial and
Peer Review

Article

X

X

Article
Processing
Charge

Communications

X
X

X

X

X

X

X

X
X
X
X

X
X
X
X

X

X
X
X

X
X

X
X

X
X

X

X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X

X

X
X
X
X
X
X
X

X
X
X
X
X

Lapinksi, Harvard, 2018 (50)
Sorbonne Université, 2018 (51)
University of Alberta, 2018 (53)
University of British Columbia, 2018 (52)
University of Toronto Libraries, 2018 (54)
Dalhousie University, 2019 (55)
McGill University, 2019 (56)
McMaster University, 2019 (57)
Prater, 2019 (58)
Ryerson University Library, 2019 (59)
Université Laval, 2019 (60)
University of Cambridge, 2019 (61)
University of Pretoria, 2019 (62)
University of Queensland Library, 2019 (64)
University of Queensland Library, 2019a (63)
University of Witwatersrand, 2019 (65)
Canadian Association of Research Libraries, ND

Dissemination,
indexing +
archiving

X
X

X
X
X

X
X
X

X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X

X
X
X
X
X
X
X

X
X

X
X

X
X
X
X
X
X
X
X
X
X
X
X
X

X
X
X
X
X
X
X
33

Author‟s version before peer review 08 29 19
(66)
Columbia University Libraries, ND (67)
Technion Library, ND (68)
UC Berkley, ND (69)
University of Ottawa Scholarly Communication,
ND (70)
Totals /30 checklists from university library
websites (n, %)

X
X
X

X
X
X

X
29, 97

12, 40

X

X

23, 77

21, 70

X
X

X

X
20, 67

24, 80

Categories covered by checklists*
Study
Journal
Operations

Editorial and
Peer Review

Article

Article
Processing
Charge

Communications

Dissemination,
indexing +
archiving

Checklists from YouTube n = 10
[REFERENCE CHECKLIST] Shamseer, 2017 (13)

X

Robbins S. Western Sydney University, 2015 (71)
Attia, 2017 (72)
Kysh, USC Keck School of Medicine, 2017 (73)
McKenna, Rhodes University, 2017 (74)
Nicholson, University of Witwatersrand, 2017 (75)
Raszewski 2017 (76)
Seal-Roberts, Springer Healthcare, 2017 (77)
Menon, SCMS Group of Educational Institutions,
India and Berryman, Cabells, 2018 (78)
Office of Scholarly Communication, Cambridge
University, 2018 (79)
Weigand, 2018 UNC Libraries (80)
Totals /10 checklists from YouTube (n, %)

9, 90

X

X

X

X

X

X

X

X

X
X
X
X

X
X

X

X

X

X

X
X
X

X

X

X
X
X

X
X
X
X

X

X

X

X

X

X

X

7, 70

4, 40

X

X
X

X

X
3, 30

X
X

X

9, 90

8, 80

TOTAL (n, %)
85, 91
39, 42
77, 83
71, 93
61, 66
*Categories as described by Cobey et al. 2018 (3), reprinted with permission:
Journal operations: Features related to how the journal conducts its business operations
Article: Features related to articles appearing in the journal
Editorial and peer review: Any aspect of the internal or external review of submitted articles and decisions on what to publish
Communications: How the journal interacts with potential authors, editors, and readers
Article processing charge: Fees taken in by journal as part of their business model
Dissemination, indexing and archiving: Information on how the journal disseminates articles and use of indexing and archiving tools

62, 67

34

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

References
1.

Clark J, Smith R. Firm action needed on predatory journals. BMJ. 2015 Jan 17;350:h210.

2.

Benjamin HH, Weinstein DF. Predatory Publishing: An Emerging Threat to the Medical
Literature. Academic Medicine. 2017 Feb;92(2):150.

3.

Cobey KD, Lalu MM, Skidmore B, Ahmadzai N, Grudniewicz A, Moher D. What is a
predatory journal? A scoping review. F1000Res. 2018;7:1001.

4.

Grudniewicz A, Cobey KD, Lalu MM, Bryson GL, Cukier S, Moher D. Defining
predatory journals and predatory publishers: An International Consensus Statement.
Nature. Under Review;

5.

Strinzel M, Severin A, Milzow K, Egger M. Blacklists and Whitelists To Tackle Predatory
Publishing: a Cross-Sectional Comparison and Thematic Analysis. mBio. 2019 Jun
25;10(3):e00411-19.

6.

Iyengar SS, Lepper MR. When choice is demotivating: Can one desire too much of a good
thing? Journal of Personality and Social Psychology. 2000;79(6):995–1006.

7.

Moher D, Liberati A, Tetzlaff J, Altman DG, Group TP. Preferred Reporting Items for
Systematic Reviews and Meta-Analyses: The PRISMA Statement. PLOS Medicine. 2009
Jul 21;6(7):e1000097.

8.

McGowan J, Sampson M, Salzwedel DM, Cogo E, Foerster V, Lefebvre C. PRESS Peer
Review of Electronic Search Strategies: 2015 Guideline Statement. J Clin Epidemiol.
2016;75:40–6.

9.

Shen C, Björk B-C. „Predatory‟ open access: a longitudinal study of article volumes and
market characteristics. BMC Medicine. 2015 Oct 1;13(1):230.

10.

Beall J. Predatory publishers are corrupting open access. Nature News. 2012 Sep
13;489(7415):179.

11.

Checklist for Checklists [Internet]. Project Check. [cited 2019 Jul 12]. Available from:
http://www.projectcheck.org/checklist-for-checklists.html

12.

Shadish WR, Cook TD, Campbell DT. Experimental and quasi-experimental designs for
generalized causal inference. Boston, MA: Houghton Mifflin; 2002.

13.

Shamseer L, Moher D, Maduekwe O, Turner L, Barbour V, Burch R, et al. Potential
predatory and legitimate biomedical journals: can you tell the difference? A crosssectional comparison. BMC Medicine. 2017;15(1):28.

14.

Beall J. Medical publishing triage - chronicling predatory open access publishers. Annals
of Medicine and Surgery (2012). 2013;2(2):47–9.

35

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

15.

Abadi ATB. Roadmap to stop the predatory journals: Author‟s perspective. Research in
Molecular Medicine. 2017;5(1):1–5.

16.

Berger M. Everything You Ever Wanted to Know About Predatory Publishing but Were
Afraid to Ask. In Baltimore, MD; 2017 [cited 2019 Jun 11]. Available from:
http://www.ala.org/acrl/sites/ala.org.acrl/files/content/conferences/confsandpreconfs/2017/
EverythingYouEverWantedtoKnowAboutPredatoryPublishing.pdf

17.

Das S, Chatterjee SS. Say no to evil: Predatory journals, what we should know. Asian
Journal of Psychiatry. 2017;28:161–2.

18.

Erfanmanesh M, Pourhossein R. Publishing in Predatory Open Access Journals: A Case of
Iran. Publishing Research Quarterly. 2017;33(4):433–44.

19.

Eriksson S, Helgesson G. The false academy: predatory publishing in science and
bioethics. Medicine, Health Care, and Philosophy. 2017;20(2):163–70.

20.

Janodia MD. Identifying predatory journals - a few simple steps. Current Science.
2017;112(12):2361–2.

21.

Khan F, Moher D. Predatory Journals : Do Not Enter. UOJM Epub [Internet]. 2017 Jan 23
[cited 2019 Jun 11]; Available from:
https://uottawa.scholarsportal.info/ottawa/index.php/uojm-jmuo/article/view/1755

22.

Klyce W, Feller E. Junk science for sale Sham journals proliferating online. Rhode Island
Medical Journal (2013). 2017;100(7):27–9.

23.

Manca A, Martinez G, Cugusi L, Dragone D, Dvir Z, Deriu F. The surge of predatory
open-access in neurosciences and neurology. Neuroscience. 2017;353:166–73.

24.

Miller E, DeBerg J. The perils of predatory publishing: Views and advice from an editor
and a health sciences librarian. Pain Management Nursing. 2017;18(6):351–2.

25.

Misra DP, Ravindran V, Wakhlu A, Sharma A, Agarwal V, Negi VS. Publishing in black
and white: the relevance of listing of scientific journals. Rheumatology International.
2017;37(11):1773–8.

26.

Mouton J, Valentine A. The extent of South African authored articles in predatory
journals. South African Journal of Science [Internet]. 2017;113(7–8). Available from:
WOS:000406867700015

27.

Oren GA. Predatory publishing: Top 10 things you need to know [Internet]. 2017 [cited
2019 Jun 11]. Available from: https://wkauthorservices.editage.com/resources/authorresource-review/2017/dec-2017.html

28.

Stratton SJ. Another “Dear Esteemed Colleague” Journal Email Invitation? Prehosp
Disaster Med. 2017 Feb;32(1):1–2.

36

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

29.

Balehegn M. Increased Publication in Predatory Journals by Developing Countries‟
Institutions: What It Entails? And What Can Be Done? International Information &
Library Review [Internet]. 2017;49(2). Available from:
https://search.ebscohost.com/login.aspx?direct=true&db=lxh&AN=123828621&site=ehos
t-live

30.

McCann TV, Polacsek M. False gold: Safely navigating open access publishing to avoid
predatory publishers and journals. Journal of Advanced Nursing. 2018;74(4):809–17.

31.

O‟Donnell M. Library guides: Understanding predatory publishers: Identifying a predator
[Internet]. 2018 [cited 2019 Jun 11]. Available from:
//instr.iastate.libguides.com/predatory/id

32.

Ajuwon GA, Ajuwon AJ. Predatory publishing and the dilemma of the Nigerian academic.
African Journal of Biomedical Research [Internet]. 2018;21(1). Available from:
https://www.ajol.info/index.php/ajbr/article/download/165957/155394

33.

Bowman MA, Saultz JW, Phillips WR. Beware of predatory journals: A caution from
editors of three family medicine journals. Journal of the American Board of Family
Medicine. 2018;31(5):671–6.

34.

Gerberi DJ. Predatory Journals: Alerting Nurses to Potentially Unreliable Content. The
American Journal of Nursing. 2018;118(1):62–5.

35.

Pamukcu Gunaydin G, Dogan NO. How can emergency physicians protect their work in
the era of pseudo publishing? Turkish Journal of Emergency Medicine. 2018;18(1):11–4.

36.

Kokol P, Zavrsnik J, Zlahtic B, Blazun Vosner H. Bibliometric characteristics of predatory
journals in pediatrics. Pediatric Research. 2018;83(6):1093–4.

37.

Lewinski AA, Oermann MH. Characteristics of E-Mail Solicitations From Predatory
Nursing Journals and Publishers. Journal of Continuing Education in Nursing.
2018;49(4):171–7.

38.

Memon AR. Predatory Journals Spamming for Publications: What Should Researchers
Do? Science and Engineering Ethics. 2018;24(5):1617–39.

39.

Nnaji JC. Illegitimate Academic Publishing: A Need for Sustainable Global Action.
Publishing Research Quarterly. 2018;34(4):515–28.

40.

Power H. Predatory Publishing: How to Safely Navigate the Waters of Open Access. Can
J Nurs Res. 2018 Mar 1;50(1):3–8.

41.

Richtig G, Berger M, Lange-Asschenfeldt B, Aberer W, Richtig E. Problems and
challenges of predatory journals. Journal of the European Academy of Dermatology and
Venereology : JEADV. 2018;32(9):1441–9.

37

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

42.

Carlson E. The top ten ways to tell that a journal is fake [Internet]. 2014 [cited 2019 Jun
11]. Available from: https://blogs.plos.org/yoursay/2017/03/22/the-top-ten-ways-to-tellthat-a-journal-is-fake/

43.

University of Edinburgh. Some warning signs to look out for [Internet]. 2015 [cited 2019
Jan 16]. Available from: https://www.ed.ac.uk/information-services/researchsupport/publish-research/scholarly-communications/predatory-or-bogus-journals

44.

Africa Check. Guide: how to spot predatory journals n teh wild [Internet]. 2017 [cited
2019 Jan 16]. Available from: https://africacheck.org/factsheets/guide-how-to-spotpredatory-academic-journals-in-the-wild/

45.

Cabell‟s Clarivate. Cabell‟s blacklist violations [Internet]. 2017 [cited 2019 Jan 16].
Available from: https://www2.cabells.com/blacklist-criteria

46.

Duke University Medical Centre. Be iNFORMEd Checklist [Internet]. 2017 [cited 2019
Jan 16]. Available from: https://guides.mclibrary.duke.edu/beinformed

47.

University of Calgary. Tools for evaluating the reputability of publishers [Internet]. 2017
[cited 2019 Jan 16]. Available from:
https://library.ucalgary.ca/guides/scholarlycommunication/predatory

48.

Coopérer en information scientifique et technique. Eviter les éditeurs prédateurs
(predatory publishers) [Internet]. 2018 [cited 2019 Jan 16]. Available from: https://coopist.cirad.fr/aide-a-la-publication/publier-et-diffuser/eviter-les-editeurs-predateurs/3indices-de-revues-et-d-editeurs-douteux

49.

Eaton SE (University of C. Avoiding Predatory Journals and Questionable Conferences: A
Resource Guide [Internet]. 2018 [cited 2019 Jan 16]. Available from:
https://prism.ucalgary.ca/bitstream/handle/1880/106227/Eaton%20%20Avoiding%20Predatory%20Journals%20and%20Questionable%20Conferences%20%20A%20Resource%20Guide.pdf?sequence=1

50.

Lapinski S (Harvard University). How can I tell whether or not a certain journal might be
a predatory scam operation? [Internet]. 2018 [cited 2019 Jan 16]. Available from:
https://asklib.hms.harvard.edu/faq/222404

51.

Sorbonne Université. Comment repérer un éditeur prédateur [Internet]. 2018 [cited 2019
Jan 16]. Available from: https://paris-sorbonne.libguides.com/bibliodoctorat/home

52.

University of British Columbia. Publishing a journal article [Internet]. 2018 [cited 2019
Jan 16]. Available from: http://guides.library.ubc.ca/publishjournalarticle/predatory#s-lgbox-9343242

53.

University of Alberta. Identifying appropriate journals for publication [Internet]. 2018
[cited 2019 Jan 16]. Available from:
https://guides.library.ualberta.ca/c.php?g=565326&p=3896130

38

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

54.

University of Toronto Libraries. Identifying Deceptive Publishers: A Checklist [Internet].
2018 [cited 2019 Jan 16]. Available from:
https://onesearch.library.utoronto.ca/deceptivepublishing

55.

Dalhousie University. How to recognize predatory journals [Internet]. 2019 [cited 2019
Jan 16]. Available from: http://dal.ca.libguides.com/c.php?g=257122&p=2830098

56.

McGill University. Avoiding illegitimate OA journals [Internet]. 2019 [cited 2019 Jan 16].
Available from: https://www.mcgill.ca/library/services/open-access/illegitimate-journals

57.

McMaster University. Graduate guide to research [Internet]. 2019. Available from:
https://libguides.mcmaster.ca/gradresearchguide/open-access

58.

Prater C. 8 Ways to identify a questionable open access journal [Internet]. American
Journal Experts. 2019 [cited 2019 Jan 16]. Available from: https://www.aje.com/en/arc/8ways-identify-questionable-open-access-journal/

59.

Ryerson University Libraries. Evaluating journals [Internet]. 2019 [cited 2019 Jan 16].
Available from: http://learn.library.ryerson.ca/scholcomm/journaleval

60.

Université Laval. Editeurs prédateurs [Internet]. 2019 [cited 2019 Jan 16]. Available from:
https://www.bda.ulaval.ca/conservation-des-droits/editeurs-predateurs/

61.

University of Cambridge. Predatory publishers [Internet]. 2019 [cited 2019 Jan 16].
Available from: https://osc.cam.ac.uk/about-scholarly-communication/authortools/considerations-when-choosing-journal/predatory-publishers

62.

University of Pretoria. Predatory publications: Predatory journals home [Internet]. 2018
[cited 2019 Jan 16]. Available from: http://up-za.libguides.com/c.php?g=834649

63.

University of Queensland Library. Identifying reputable Open Access journals [Internet].
2019 [cited 2019 Jan 16]. Available from:
https://guides.library.uq.edu.au/ld.php?content_id=46950215

64.

University of Queensland Library. Red Flags for Open Access Journals [Internet]. 2019
[cited 2019 Jan 16]. Available from: https://guides.library.uq.edu.au/for-researchers/getpublished/unethical-publishing

65.

University of Witwatersrand. Predatory Publisher Checklist [Internet]. 2019 [cited 2019
Jan 16]. Available from:
https://libguides.wits.ac.za/openaccess_a2k_scholarly_communication/Predatory_Publishe
rs

66.

Canadian Association of Research Libraries. How to assess a journal [Internet]. [cited
2019 Jan 16]. Available from: http://www.carl-abrc.ca/how-to-assess-a-journal/

67.

Columbia University Libraries. Evaluating publishers [Internet]. [cited 2019 Jan 16].
Available from: https://scholcomm.columbia.edu/publishing.html
39

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

68.

Technion Library. Author guide on how to publish an Open Access article [Internet].
[cited 2019 Jan 16]. Available from: https://library.technion.ac.il/en/research/open-access

69.

UC Berkeley. Evaluating publishers [Internet]. [cited 2019 Jan 16]. Available from:
http://www.lib.berkeley.edu/scholarly-communication/publishing/lifecycle/evaluatingpublishers

70.

University of Ottawa Scholarly Communication. Predatory publishers [Internet]. [cited
2019 Jan 16]. Available from:
https://scholarlycommunication.uottawa.ca/publishing/predatory-publishers

71.

Robbins S (Western Sydney University). Red flags [Internet]. 2015. Available from:
https://www.youtube.com/watch?v=7WSDJKaw6rk

72.

Attia S. Spot Predatory Journals [Internet]. 2017. Available from:
https://www.youtube.com/watch?v=vU2M3U7knrk

73.

Kysh L, Johnson RE, (Keck School of Medicine of USC). Characteristics of Predatory
Journals [Internet]. 2017. Available from:
https://www.youtube.com/watch?v=rpVzJWxvClg

74.

McKenna S (Rhodes University). Predatory Publications: Shark Spotting [Internet]. 2017.
Available from: https://www.youtube.com/watch?v=LfOKgS4wBvE

75.

Nicholson DR (University of Witwatersrand). Cautionary Checklist [Internet]. 2017.
Available from:
http://webinarliasa.org.za/playback/presentation/0.9.0/playback.html?meetingId=a967fc2e
c0fdbb5a6d4bfaad2a02dc51a48febab-1508483812099&t=0s

76.

Raszewski R. What to watch out for [Internet]. 2017. Available from:
https://www.youtube.com/watch?v=wF1EEq6qsZQ

77.

Seal-Roberts J (Healthcare Springer). So how do we recognize a predatory journal?
[Internet]. 2017. Available from: https://www.youtube.com/watch?v=g_l4CXnnDHY

78.

Menon V, Berryman K. Characteristics of Predatory Journals [Internet]. 2018. Available
from: https://www.youtube.com/watch?v=aPc_C6ynF8Q

79.

Office of Scholarly Communication Cambridge University. Predatory publishers in 3
minutes [Internet]. 2018 [cited 2019 Jan 5]. Available from:
https://www.youtube.com/watch?v=UwUB3oquuRQ Link

80.

Weigand S, UNC Libraries. Prepare to publish part II: Journal selection & predatory
journals [Internet]. 2018 [cited 2019 Jan 5]. Available from:
https://www.youtube.com/watch?v=KPyDQcC_drg

81.

Knoll JL. Open access journals and forensic publishing. The Journal of the American
Academy of Psychiatry and the Law. 2014;42(3):315–21.
40

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

82.

Lukic T, Blesic I, Basarin B, Ivanovic B, Milosevic D, Sakulski D. Predatory and fake
scientific journals/publishers: A global outbreak with rising trend: A review. Geographica
Pannonica. 2014;18(3):69–81.

83.

Bhad R, Hazari N. Predatory journals in psychiatry: A note of caution. Asian Journal of
Psychiatry. 2015;16:67–8.

84.

Bradley-Springer L. Predatory publishing and you. Journal of the Association of Nurses in
Aids Care. 2015;26(3):219–21.

85.

Hemmat Esfe M, Wongwises S, Asadi A, Akbari M. Fake Journals: Their Features and
Some Viable Ways to Distinguishing Them. Science and Engineering Ethics.
2015;21(4):821–4.

86.

Pamukcu Gunaydin GP, Dogan NO. A Growing Threat for Academicians: Fake and
Predatory Journals. Eurasian Journal of Emergency Medicine. 2015;14(2):94–6.

87.

Inane Predatory Publishing Practices Collaborative. Predatory publishing: What editors
need to know. Canadian Association of Nephrology Nurses and Technicians.
2015;25(1):8–10.

88.

Proehl JA, Hoyt KS, editors. Predatory Publishing: What Editors Need to Know.
Advanced Emergency Nursing Journal. 2015 Mar;37(1):1–4.

89.

Stone TE, Rossiter RC. Predatory publishing: Take care that you are not caught in the
Open Access net. Nursing & Health Sciences. 2015;17(3):277–9.

90.

Yucha C. Predatory Publishing: What Authors, Reviewers, and Editors Need to Know.
Biological Research for Nursing. 2015;17(1):5–7.

91.

Cariappa MP, Dalal SS, Chatterjee K. To publish and perish: A Faustian bargain or a
Hobson‟s choice. Medical journal, Armed Forces India. 2016;72(2):168–71.

92.

Carroll CW. Spotting the Wolf in Sheep‟s Clothing: Predatory Open Access Publications.
Journal of graduate medical education. 2016;8(5):662–4.

93.

Fraser D. Predatory Journals and Questionable Conferences. Neonatal Network. 2016 Jan
1;35(6):349–50.

94.

Glick M. Publish and perish (Clues suggesting a “predatory” journal - ID 3005). The
Journal of the American Dental Association. 2016 Jun 1;147(6):385–7.

95.

Glick M. Publish and perish (What you can expect from a predatory publisher - ID 3017).
The Journal of the American Dental Association. 2016 Jun 1;147(6):385–7.

96.

Hansoti B, Langdorf MI, Murphy LS. Discriminating Between Legitimate and Predatory
Open Access Journals: Report from the International Federation for Emergency Medicine
Research Committee. The Western Journal of Emergency Medicine. 2016;17(5):497–507.
41

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

97.

Morley C. “Dear Esteemed Author:” Spotting a predatory publisher in 10 easy steps
[Internet]. STFM Blog. 2016 [cited 2019 Jun 11]. Available from:
https://blog.stfm.org/2016/05/23/predatory-publisher/

98.

Nolan T. Don‟t fall prey to “predatory” journals [Internet]. International Science Editing.
2016 [cited 2019 Jun 11]. Available from:
https://www.internationalscienceediting.com/avoid-predatory-journals/

99.

Wikipedia. Predatory publishing. In: Wikipedia [Internet]. 2019 [cited 2019 Jun 11].
Available from:
https://en.wikipedia.org/w/index.php?title=Predatory_publishing&oldid=900101199

100. Crawford W. Journals, “Journals” and wannabes: Investigating the list. Cites & Insights.
2014;14(7):24.
101. Ward SM. The Rise of Predatory Publishing: How To Avoid Being Scammed. Weed
Science. 2016;64(4):772–8.
102. Beall J. Criteria for determining predatory open-access publishers, 3rd edition [Internet].
2015 [cited 2019 Jun 9]. Available from:
https://beallslist.weebly.com/uploads/3/0/9/5/30958339/criteria-2015.pdf
103. Dadkhah M, Bianciardi G. Ranking Predatory Journals: Solve the Problem Instead of
Removing It! Advanced Pharmaceutical Bulletin. 2016;6(1):1–4.
104. Amano T, González-Varo JP, Sutherland WJ. Languages are still a major barrier to global
science. PLOS Biology. 2016 Dec 29;14(12):e2000933.
105. Think, Check, Submit [Internet]. 2019 [cited 2019 Jul 13]. Available from:
https://thinkchecksubmit.org/

42

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Appendix 1

PRESS Guideline 2015— Search Submission & Peer Review Assessment
Reference: McGowan J, Sampson M, Salzwedel DM, Cogo E, Foerster V, Lefebvre C. PRESS Peer Review
of Electronic Search Strategies: 2015 guideline statement. J Clin Epidemiol 2016;75:40-6. Available:
http://www.jclinepi.com/article/S0895-4356(16)00058-5/pdf.

Search submission: This section to be filled in by the searcher
Searcher: Becky Skidmore

Email: bskidmore@rogers.com

Date submitted: 7 Nov 2018

Date requested by: 10 Nov 2018 AM

1. Systematic Review Title
Systematic Review of Checklists to Detect Potential Predatory Biomedical Journals and Publishers
2. This search strategy is …

X

My PRIMARY (core) database strategy — First time submitting a strategy for search question and database
My PRIMARY (core) strategy — Follow-up review NOT the first time submitting a strategy for search question and
database. If this is a response to peer review, itemize the changes made to the review suggestions
SECONDARY search strategy— First time submitting a strategy for search question and database

SECONDARY search strategy — NOT the first time submitting a strategy for search question and database. If
this is a response to peer review, itemize the changes made to the review suggestions

3. Database (e.g., MEDLINE, CINAHL)

[mandatory]

MEDLINE

4. Interface (e.g., Ovid, EbscoHost…)

[mandatory]

Ovid
5. Research Question (Describe the purpose of the search)

[mandatory]

43

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

6. PICO Format Outline the PICOs for your question — i.e., Patient, Intervention, Comparison, Outcome, and Study
Design — as applicable

P
I/
Exposure

Predatory Journals
Checklists to detect a potentially predatory journal or publisher

C
O
S

7. Inclusion Criteria (List criteria such as age groups, study designs, etc., to be included) [optional]
Publication years 2012-current
8.

9. Exclusion Criteria (List criteria such as study designs, date limits, etc., to be excluded) [optional]
Opinion
pieces
and editorials
This search
strategy
is …
10. Was a search filter applied? No
If YES, which one(s) (e.g., Cochrane RCT filter, PubMed Clinical Queries filter)? Provide the
source if this is a published filter . [mandatory if YES to previous question — textbox]

11. Notes or comments you feel would be useful for the peer reviewer
[optional]
It is possible info will not be restricted to biomedical field so terminology and choice of databases have
been adjusted for this possible broader scope (e.g., also including library science databases, Web of
Science)
Have shown Ovid multifile search instead of just MEDLINE
“Series” was suggested as a possible synonym for checklists but was tested and discarded
Much of the vocabulary pertaining to predatory journals has been previously PRESSed (dark and rogue
have been added)
There will be an extensive follow-up grey literature search of library web sites, YouTube, etc.

44

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
Volume in published literature is very small – one option is to only search on the population (predatory
journals) for the electronic database searches (684 records after removing duplicates in Ovid).
Thoughts?

12. Please copy and paste your search strategy here, exactly as run, including the number of hits per line.
[mandatory]
Database: Embase Classic+Embase <1947 to 2018 November 06>, Ovid MEDLINE(R) ALL <1946 to
November 06, 2018>, PsycINFO <1806 to October Week 5 2018>, ERIC <1965 to August 2018>
Search Strategy:
-------------------------------------------------------------------------------1 (predator* adj3 edit*).tw,kw,kf. (29)
2 (predator* adj3 journal*).tw,kw,kf. (393)
3 (predator* adj3 periodical?).tw,kw,kf. (6)
4 (predator* adj3 publication?).tw,kw,kf. (48)
5 (predator* adj3 publish*).tw,kw,kf. (373)
6 (bogus adj3 edit*).tw,kw,kf. (2)
7 (bogus adj3 journal*).tw,kw,kf. (7)
8 (bogus adj3 periodical?).tw,kw,kf. (0)
9 (bogus adj3 publication?).tw,kw,kf. (0)
10 (bogus adj3 publish*).tw,kw,kf. (1)
11 (dark adj3 edit*).tw,kw,kf. (32)
12 (dark adj3 journal*).tw,kw,kf. (9)
13 (dark adj3 periodical?).tw,kw,kf. (4)
14 (dark adj3 publication?).tw,kw,kf. (2)
15 (dark adj3 publish*).tw,kw,kf. (19)
16 (decepti* adj3 edit*).tw,kw,kf. (21)
17 (decepti* adj3 journal*).tw,kw,kf. (15)
18 (decepti* adj3 periodical?).tw,kw,kf. (0)
19 (decepti* adj3 publication?).tw,kw,kf. (3)
20 (decepti* adj3 publish*).tw,kw,kf. (20)
21 (disreput* adj3 edit*).tw,kw,kf. (0)
22 (disreput* adj3 journal*).tw,kw,kf. (3)
23 (disreput* adj3 periodical?).tw,kw,kf. (0)
24 (disreput* adj3 publication?).tw,kw,kf. (3)
25 (disreput* adj3 publish*).tw,kw,kf. (0)
26 (distrust* adj3 edit*).tw,kw,kf. (1)
27 (distrust* adj3 journal*).tw,kw,kf. (2)
28 (distrust* adj3 periodical?).tw,kw,kf. (0)
29 (distrust* adj3 publication?).tw,kw,kf. (0)
30 (distrust* adj3 publish*).tw,kw,kf. (5)
31 (exploit* adj3 edit*).tw,kw,kf. (107)
32 (exploit* adj3 journal*).tw,kw,kf. (29)
33 (exploit* adj3 periodical?).tw,kw,kf. (1)
34 (exploit* adj3 publication?).tw,kw,kf. (37)
35 (exploit* adj3 publish*).tw,kw,kf. (93)
36 (fake? adj3 edit*).tw,kw,kf. (11)
45

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84

(fake? adj3 journal*).tw,kw,kf. (36)
(fake? adj3 periodical?).tw,kw,kf. (0)
(fake? adj3 publication?).tw,kw,kf. (4)
(fake? adj3 publish*).tw,kw,kf. (20)
(hoax$2 adj3 edit*).tw,kw,kf. (1)
(hoax$2 adj3 journal*).tw,kw,kf. (5)
(hoax$2 adj3 periodical?).tw,kw,kf. (0)
(hoax$2 adj3 publication?).tw,kw,kf. (2)
(hoax$2 adj3 publish*).tw,kw,kf. (4)
(illegitim* adj3 edit*).tw,kw,kf. (3)
(illegitim* adj3 journal*).tw,kw,kf. (19)
(illegitim* adj3 periodical?).tw,kw,kf. (0)
(illegitim* adj3 publication?).tw,kw,kf. (6)
(illegitim* adj3 publish*).tw,kw,kf. (12)
(mislead* adj3 edit*).tw,kw,kf. (42)
(mislead* adj3 journal*).tw,kw,kf. (36)
(mislead* adj periodical?).tw,kw,kf. (0)
(mislead* adj3 publication?).tw,kw,kf. (57)
(mislead* adj publish*).tw,kw,kf. (5)
(non-legitim* adj3 edit*).tw,kw,kf. (0)
(non-legitim* adj3 journal*).tw,kw,kf. (0)
(non-legitim* adj3 periodical?).tw,kw,kf. (0)
(non-legitim* adj3 publication?).tw,kw,kf. (0)
(non-legitim* adj3 publish*).tw,kw,kf. (0)
(questionabl* adj3 edit*).tw,kw,kf. (24)
(questionabl* adj3 journal*).tw,kw,kf. (38)
(quesionabl* adj3 periodical?).tw,kw,kf. (0)
(questionabl* adj3 publication?).tw,kw,kf. (44)
(questionabl* adj3 publish*).tw,kw,kf. (48)
(racket? adj3 edit*).tw,kw,kf. (0)
(racket? adj3 journal*).tw,kw,kf. (1)
(racket? adj3 periodical?).tw,kw,kf. (0)
(racket? adj3 publication?).tw,kw,kf. (0)
(racket? adj3 publish*).tw,kw,kf. (0)
(rogue adj3 edit*).tw,kw,kf. (4)
(rogue adj3 journal*).tw,kw,kf. (2)
(rogue adj3 periodical?).tw,kw,kf. (0)
(rogue adj3 publication?).tw,kw,kf. (0)
(rogue adj3 publish*).tw,kw,kf. (4)
(scam* adj3 edit*).tw,kw,kf. (3)
(scam* adj3 journal*).tw,kw,kf. (9)
(scam* adj3 periodical?).tw,kw,kf. (0)
(scam* adj3 publication?).tw,kw,kf. (0)
(scam* adj3 publish*).tw,kw,kf. (5)
(sham adj3 edit*).tw,kw,kf. (1)
(sham adj3 journal*).tw,kw,kf. (9)
(sham adj3 periodical?).tw,kw,kf. (0)
(sham adj3 publication?).tw,kw,kf. (1)
46

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132

(sham adj3 publish*).tw,kw,kf. (50)
(spam* adj3 edit*).tw,kw,kf. (1)
(spam* adj3 journal*).tw,kw,kf. (4)
(spam* adj3 periodical?).tw,kw,kf. (0)
(spam* adj3 publication?).tw,kw,kf. (2)
(spam* adj3 publish*).tw,kw,kf. (5)
(unethic* adj3 edit*).tw,kw,kf. (21)
(unethic* adj3 journal*).tw,kw,kf. (22)
(unethic* adj3 periodical?).tw,kw,kf. (0)
(unethic* adj3 publication?).tw,kw,kf. (52)
(unethic* adj3 publish*).tw,kw,kf. (51)
(unprofessional* adj3 edit*).tw,kw,kf. (1)
(unprofessional* adj3 journal*).tw,kw,kf. (4)
(unprofessional* adj3 periodical*).tw,kw,kf. (0)
(unprofessional* adj3 publication?).tw,kw,kf. (3)
(unprofessional* adj3 publish*).tw,kw,kf. (1)
(untrust* adj3 edit*).tw,kw,kf. (0)
(untrust* adj3 journal*).tw,kw,kf. (0)
(untrust* adj3 periodical?).tw,kw,kf. (0)
(untrust* adj3 publication?).tw,kw,kf. (1)
(untrust* adj3 publish*).tw,kw,kf. (2)
pseudo-journal*.tw,kw,kf. (13)
pseudo-periodical*.tw,kw,kf. (5)
pseudo-publish*.tw,kw,kf. (2)
Beall* list.tw,kw,kf. (44)
or/1-109 (1553)
limit 110 to yr="2012-current" (1101)
Checklist/ use emczd,medall (24630)
Check Lists/ use eric (6639)
Editorial Policies/ use medall (7197)
guideline.pt. (16004)
Guidelines/ use eric (23366)
Guides/ use eric (8271)
exp Journalism/st use medall (998)
Open Access Publishing/st use medall (36)
exp Peer Review/st use medall (2244)
Publishing/st use medall (5272)
checklist*.tw,kw,kf. (117991)
check list*.tw,kw,kf. (19096)
guide*.tw,kw,kf. (1713265)
guidance*.tw,kw,kf. (319738)
criteria.tw,kw,kf. (1516630)
criterion.tw,kw,kf. (228194)
(tool or tools).tw,kw,kf. (1634450)
(instrument or instruments).tw,kw,kf. (564019)
algorithm?.tw,kw,kf. (504760)
instruction?.tw,kf,kw. (545248)
(inventory or inventories).tw,kf,kw. (308435)
47

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
133
134
135
136
137
138
139

(list or lists or listing or listings).tw,kf,kw. (461420)
primer?.tw,kw,kf. (204194)
or/112-134 [CHECKLISTS] (6958828)
111 and 135 [PREDATORY JNL CHECKLISTS] (341)
(comment or editorial or news or newspaper article).pt. (1850264)
136 not 137 [OPINION PIECES REMOVED] (286)
remove duplicates from 138 (206)

***************************

Peer review assessment: this section to be filled in by the reviewer
Reviewer: Kaitryn Campbell

Email: kcamlolo668@gmail.com

Date completed: 10 Nov 2018

Do you wish to be acknowledged? (If yes, the review team will be advised to add an acknowledgement
to any publications related to this work). No – unless your organization requires it
The suggested acknowledgement is “ We thank Xxxxx Yyyyyy, MLIS, AHIP (xxxxx Health Sciences Library,
University of xxxxxx) for peer review of the MEDLINE search strategy.” [please edit to indicate your
name, postnomials and institutional affiliation as you would like them presented].

1. TRANSLATION
A -­­No revisions

X

B -­­ Revision(s) suggested
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

AND PROXIMITY
A -­­No revisions

X

B -­­ Revision(s) suggested
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

3. SUBJECT HEADINGS
A -­­No revisions

X

B -­­ Revision(s) suggested

48

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

4. TEXT WORD SEARCHING
A -­­No revisions

X

B -­­ Revision(s)suggested
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

5. SPELLING, SYNTAX, AND LINE NUMBERS
A -­­No revisions

X

B -­­ Revision(s)suggested
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

LIMITS AND
A -­­No revisions

X

B -­­ Revision(s) suggested
C -­­ Revision(s) required

If “B” or “C,” please provide an explanation or example:

A -­­No revisions

X

B -­­ Revision(s) suggested
C -­­ Revision(s) required

Additional comments:

49

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19
Solidly done. No errors or omissions found. Re: including just the “predatory journals” concept alone
as the strategy for the bibliographic database searching, this seems like a strong option for 2
reasons: 1) limited retrieval numbers; 2) I have some experience doing “checklist” searches and
found the description of these types of items can be extremely variable. My personal preference
would be to leave the checklist concept out.

50

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

Appendix 2
Ovid Multifile
Database: Embase Classic+Embase <1947 to 2018 November 19>, Ovid MEDLINE(R) ALL
<1946 to November 19, 2018>, PsycINFO <1806 to November Week 2 2018>, ERIC <1965 to
October 2018>
Search Strategy:
-------------------------------------------------------------------------------1 (predator* adj3 edit*).tw,kw,kf. (29)
2 (predator* adj3 journal*).tw,kw,kf. (397)
3 (predator* adj3 periodical?).tw,kw,kf. (6)
4 (predator* adj3 publication?).tw,kw,kf. (49)
5 (predator* adj3 publish*).tw,kw,kf. (379)
6 (bogus adj3 edit*).tw,kw,kf. (2)
7 (bogus adj3 journal*).tw,kw,kf. (7)
8 (bogus adj3 periodical?).tw,kw,kf. (0)
9 (bogus adj3 publication?).tw,kw,kf. (0)
10 (bogus adj3 publish*).tw,kw,kf. (1)
11 (dark adj3 edit*).tw,kw,kf. (32)
12 (dark adj3 journal*).tw,kw,kf. (9)
13 (dark adj3 periodical?).tw,kw,kf. (4)
14 (dark adj3 publication?).tw,kw,kf. (2)
15 (dark adj3 publish*).tw,kw,kf. (19)
16 (decepti* adj3 edit*).tw,kw,kf. (21)
17 (decepti* adj3 journal*).tw,kw,kf. (15)
18 (decepti* adj3 periodical?).tw,kw,kf. (0)
19 (decepti* adj3 publication?).tw,kw,kf. (3)
20 (decepti* adj3 publish*).tw,kw,kf. (20)
21 (disreput* adj3 edit*).tw,kw,kf. (0)
22 (disreput* adj3 journal*).tw,kw,kf. (3)
23 (disreput* adj3 periodical?).tw,kw,kf. (0)
24 (disreput* adj3 publication?).tw,kw,kf. (3)
25 (disreput* adj3 publish*).tw,kw,kf. (0)
26 (distrust* adj3 edit*).tw,kw,kf. (1)
27 (distrust* adj3 journal*).tw,kw,kf. (2)
28 (distrust* adj3 periodical?).tw,kw,kf. (0)
29 (distrust* adj3 publication?).tw,kw,kf. (0)
30 (distrust* adj3 publish*).tw,kw,kf. (5)
31 (exploit* adj3 edit*).tw,kw,kf. (107)
32 (exploit* adj3 journal*).tw,kw,kf. (29)
33 (exploit* adj3 periodical?).tw,kw,kf. (1)
34 (exploit* adj3 publication?).tw,kw,kf. (37)
35 (exploit* adj3 publish*).tw,kw,kf. (96)
36 (fake? adj3 edit*).tw,kw,kf. (11)
37 (fake? adj3 journal*).tw,kw,kf. (37)
51

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83

(fake? adj3 periodical?).tw,kw,kf. (0)
(fake? adj3 publication?).tw,kw,kf. (4)
(fake? adj3 publish*).tw,kw,kf. (20)
(hoax$2 adj3 edit*).tw,kw,kf. (1)
(hoax$2 adj3 journal*).tw,kw,kf. (5)
(hoax$2 adj3 periodical?).tw,kw,kf. (0)
(hoax$2 adj3 publication?).tw,kw,kf. (2)
(hoax$2 adj3 publish*).tw,kw,kf. (4)
(illegitim* adj3 edit*).tw,kw,kf. (3)
(illegitim* adj3 journal*).tw,kw,kf. (19)
(illegitim* adj3 periodical?).tw,kw,kf. (0)
(illegitim* adj3 publication?).tw,kw,kf. (6)
(illegitim* adj3 publish*).tw,kw,kf. (12)
(mislead* adj3 edit*).tw,kw,kf. (42)
(mislead* adj3 journal*).tw,kw,kf. (36)
(mislead* adj periodical?).tw,kw,kf. (0)
(mislead* adj3 publication?).tw,kw,kf. (57)
(mislead* adj publish*).tw,kw,kf. (5)
(non-legitim* adj3 edit*).tw,kw,kf. (0)
(non-legitim* adj3 journal*).tw,kw,kf. (0)
(non-legitim* adj3 periodical?).tw,kw,kf. (0)
(non-legitim* adj3 publication?).tw,kw,kf. (0)
(non-legitim* adj3 publish*).tw,kw,kf. (0)
(questionabl* adj3 edit*).tw,kw,kf. (24)
(questionabl* adj3 journal*).tw,kw,kf. (38)
(quesionabl* adj3 periodical?).tw,kw,kf. (0)
(questionabl* adj3 publication?).tw,kw,kf. (44)
(questionabl* adj3 publish*).tw,kw,kf. (48)
(racket? adj3 edit*).tw,kw,kf. (0)
(racket? adj3 journal*).tw,kw,kf. (1)
(racket? adj3 periodical?).tw,kw,kf. (0)
(racket? adj3 publication?).tw,kw,kf. (0)
(racket? adj3 publish*).tw,kw,kf. (0)
(rogue adj3 edit*).tw,kw,kf. (4)
(rogue adj3 journal*).tw,kw,kf. (2)
(rogue adj3 periodical?).tw,kw,kf. (0)
(rogue adj3 publication?).tw,kw,kf. (0)
(rogue adj3 publish*).tw,kw,kf. (4)
(scam* adj3 edit*).tw,kw,kf. (3)
(scam* adj3 journal*).tw,kw,kf. (9)
(scam* adj3 periodical?).tw,kw,kf. (0)
(scam* adj3 publication?).tw,kw,kf. (0)
(scam* adj3 publish*).tw,kw,kf. (6)
(sham adj3 edit*).tw,kw,kf. (1)
(sham adj3 journal*).tw,kw,kf. (9)
(sham adj3 periodical?).tw,kw,kf. (0)
52

medRxiv preprint doi: https://doi.org/10.1101/19005728; this version posted September 16, 2019. The copyright holder for this preprint (which
was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-ND 4.0 International license .

Author‟s version before peer review 08 29 19

84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118

(sham adj3 publication?).tw,kw,kf. (1)
(sham adj3 publish*).tw,kw,kf. (50)
(spam* adj3 edit*).tw,kw,kf. (1)
(spam* adj3 journal*).tw,kw,kf. (4)
(spam* adj3 periodical?).tw,kw,kf. (0)
(spam* adj3 publication?).tw,kw,kf. (2)
(spam* adj3 publish*).tw,kw,kf. (5)
(unethic* adj3 edit*).tw,kw,kf. (21)
(unethic* adj3 journal*).tw,kw,kf. (22)
(unethic* adj3 periodical?).tw,kw,kf. (0)
(unethic* adj3 publication?).tw,kw,kf. (52)
(unethic* adj3 publish*).tw,kw,kf. (51)
(unprofessional* adj3 edit*).tw,kw,kf. (1)
(unprofessional* adj3 journal*).tw,kw,kf. (4)
(unprofessional* adj3 periodical*).tw,kw,kf. (0)
(unprofessional* adj3 publication?).tw,kw,kf. (3)
(unprofessional* adj3 publish*).tw,kw,kf. (1)
(untrust* adj3 edit*).tw,kw,kf. (0)
(untrust* adj3 journal*).tw,kw,kf. (0)
(untrust* adj3 periodical?).tw,kw,kf. (0)
(untrust* adj3 publication?).tw,kw,kf. (1)
(untrust* adj3 publish*).tw,kw,kf. (2)
pseudo-journal*.tw,kw,kf. (13)
pseudo-periodical*.tw,kw,kf. (5)
pseudo-publish*.tw,kw,kf. (2)
Beall* list.tw,kw,kf. (46)
or/1-109 (1564)
limit 110 to yr="2012-current" (1112)
(comment or editorial or news or newspaper article).pt. (1853727)
111 not 112 [OPINION PIECES REMOVED] (869)
remove duplicates from 113 (586)
114 use medall (333)
114 use emczd (156)
114 use eric (16)
114 not (115 or 116 or 117) (81)

53

