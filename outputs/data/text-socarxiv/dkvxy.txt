CoronaNet COVID-19 Government Response Event

1

Dataset

2

3

Cindy Cheng1,*

4

Joan Barceló2

5

Allison Spencer Hartnett3

6

Robert Kubinec2

7

Luca Messerschmidt1

8

May 16th, 2020

9

10

11

12

13

1

Hochschule für Politik at the Technical University of Munich (TUM) and the TUM School of Governance,

Munich, Germany
2

Social Science Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates

3

Department of Political Science, Yale University, New Haven, United States

*

Correspondence: Cindy Cheng <cindy.cheng@hfp.tum.de>

1

14

Abstract

15

Governments worldwide have implemented countless policies in response to the COVID-19 pandemic. We

16

present an initial public release of a large hand-coded dataset of over 12,000 such policy announcements across

17

more than 190 countries. The dataset is updated daily, with a 5-day lag for validity checking. We document

18

policies across numerous dimensions, including the type of policy; national vs. sub-national enforcement;

19

the specific human group and geographic region targeted by the policy; and the time frame within which

20

each policy is implemented. We further analyze the dataset using a Bayesian measurement model which

21

shows the quick acceleration of the adoption of costly policies across countries beginning in mid-March and

22

continuing to the present. We believe that the data will be instrumental for helping policy makers and

23

researchers assess, among other objectives, how effective different policies are in addressing the spread and

24

health outcomes of COVID-19.

25

Introduction

26

Governments all around the world have implemented an astonishing number and variety of policies in reaction

27

to the COVID-19 pandemic in a very short time frame. However, policy makers and researchers have to date

28

lacked access to the quality, up-to-date data they need for conducting rigorous analyses of whether, how, and

29

to what degree these fast changing policies have worked in brunting the health, political and economic effects

30

of the pandemic. To address this concern, in this paper, we present the CoronaNet COVID-19 Government

31

Response Event Dataset, which provides fine-grained, monadic and dyadic data on policy actions taken

32

by governments across the world since the Chinese government first reported the COVID-19 outbreak on

33

December 31, 2019. At the time of writing, the dataset covers the policy actions of 196 countries up until

34

2020-05-08, for a total of 12601 events.

35

With the help of a team of over 260 research assistants in 18 time zones, we are releasing the data on

36

a daily basis. We are implementing a five-day lag between data collection and release to evaluate and

37

validate ongoing coding efforts for random samples of the data to ensure the best possible quality given the

38

considerable time constraints. More specifically, the CoronaNet dataset collects daily data on government

39

policy actions taken in response to COVID-19 across the following dimensions:

40

• The type of government policy implemented (e.g. quarantine, closure of schools [16 total])

41

• The level of government initiating the action (e.g. national, provincial)

42

• The geographical target of the policy action, if applicable (e.g. national, provincial, municipal)

43

• The human or material target of the policy action, if applicable (e.g. travelers, masks)

2

44

• The directionality of the policy action, if applicable (e.g. inbound, outbound, both)

45

• The mechanism of travel that the policy action targets, if applicable (e.g. flights, trains)

46

• The enforcement with the policy action (e.g. mandatory, voluntary)

47

• The enforcer of the policy action (e.g. national government, military)

48

• The timing of the policy action (e.g. date announced, date implemented)

49

Though government responses to the COVID-19 pandemic have inaugurated unprecedented changes in how

50

billions of people live their lives, they draw on the lessons learned from the endless series of pandemics

51

and epidemics that came before. Indeed, the earliest written sources document how ancient Mesopotamians

52

responded to the constant threat of epidemic by, on the one hand drawing on spiritual practices and on the

53

other hand, isolating people showing the first symptoms of a disease from others.1,2 As time has marched

54

forward, pandemics and epidemics have consistently and dramatically changed the course of human history3–7

55

and governments have continued to implement a variety of policies in response.1,8,9 Throughout it all, the

56

collection of reliable data has helped advance collective understanding of which policies are effective in

57

curbing the effects of a given disease outbreak.10,11 This is no trivial task given that a policy that is effective

58

in one context may be ineffective in another due to a whole host of potentially conditioning factors, including

59

the pathogenesis of the particular disease12,13 , the characteristics of the underlying population14–17 , and the

60

available medical18,19 and communication20–23 technology at the time.

61

We believe that the data presented in this paper can similarly help policy makers and researchers assess how

62

effective different policies are in addressing the spread and health outcomes of COVID-1924 . While available

63

research is necessarily preliminary, it suggests that which policies governments have implemented in response

64

to COVID-1925–27 , when they decided to implement them29,30 , who they were targeted toward31,32 and what

65

state capacity they possessed to do so33,34 have all significantly influenced how the virus has affected health

66

outcomes both within and across different country contexts35,36 , all of which is readily captured by this

67

dataset. Equally important is understanding why countries adopt different policies, with early analyses

68

suggesting that institutional and political factors, e.g. the authoritarian or democratic nature of a country’s

69

institutions37 or its level of political partisanship38 , play an important role. These findings will not only help

70

improve the global response to the current crisis, but can also build an influential foundation of knowledge

71

for responding to future outbreaks39,40 .

72

Meanwhile, given the exogenous timing of the initial outbreak in Wuhan, China, government policies made

73

in reaction to the COVID-19 pandemic constitute the single largest natural experiment in recent memory,

74

allowing researchers to improve causal inference in any number of fields. Indeed, government reactions to

75

the COVID-19 pandemic may forward our understanding of a wide-range of social phenomena, from the

76

evolution of political institutions41–45 to the progression of economic development46–50 and the stability of

3

77

financial markets51,52 to say nothing of what we might learn about environmental economics53,54 , mental

78

health55,56 , disaster response57,58 and disaster preparedness59–61 . Some initial analyses suggest that the

79

COVID-19 pandemic has already led to authoritarian backsliding in some countries62 , unprecedented shocks

80

to economies around the world63–66 , and serious negative mental health effects for millions of people67,68 .

81

While scholars have always sought to understand how large-scale historical events have shaped contemporary

82

phenomena, modern technological tools allow us to document such events more quickly and more precisely

83

than ever before.

84

Detailed documentation of such policies is all the more important given that policy choices made by one

85

government often depend on the policy choices of other governments. The structure of the data we present

86

in this paper allows researchers and policy-makers not only to examine monadic policy information—i.e.,

87

policies targeted to the same political unit that enacted it—but also directed, dyadic policy information—

88

i.e., policies targeted to a political unit that is different from the unit that enacted it. The dyadic data is not

89

limited to only capturing foreign policy dynamics, such as when country A implements a policy that affects

90

citizens of country B, but can also document dynamics within countries, such as when central governments

91

enact policies targeted to sub-national political entities. Given its dyadic structure, the dataset further

92

enables critical analyses of the links and interdependencies between and within countries, including patterns

93

of policy learning and diffusion across governments, as well as of cooperative and conflictual relationships in

94

global crisis governance.

95

In what follows, we provide a description of the data, as well as an application of the data in which we model

96

policy activity of countries over time. Using a Bayesian dynamic item-response theory model, we produce a

97

statistically valid index that categorizes countries in terms of their responses to the pandemic, and further

98

shows how quickly policy responses have changed over time. We document clear evidence of rapid policy

99

diffusion of harsh measures in response to the virus, indicating some of the most extensive evidence of this

100

type of diffusion ever documented. In the methodology section, we provide a thorough discussion of the

101

methodology used to create this index, to collate the dataset and to manage the more than 260 research

102

assistants coding this data around the world in real time.

103

Results

104

In this section, we first present some descriptive statistics that illustrate how government policy toward

105

COVID-19 has varied across key variables. We then present our new index for tracking how active govern-

106

ments have been with regard to announcing policies targeting COVID-19 across countries and over time.

4

107

Descriptive Statistics

108

Here we present some descriptive statistics for key variables available in the dataset. In Table 1, for each

109

policy type we present cumulative totals for the number of policies and the number of countries which have

110

implemented that policy, an average value for the number of countries a policy targets, and percentages in

111

terms how stringently a policy is enforced. While, we highlight the number of targeted countries in this

112

table, we note that our data also captures other potential geographic targets not shown in the table. For

113

instance, it is possible for a national policy to be targeted toward one or more sub-national provinces or a

114

provincial policy to be targeted toward one or more sub-provincial regions.

115

Table 1 shows that the policy most governments have implemented in reaction to COVID-19 is external

116

border restrictions, i.e. policies that seek to limit entry or exit across different sovereign jurisdictions. We

117

find that 186 countries have made 1064 policy announcements about such restrictions since December 31,

118

2019. The second policy that most countries, by our count 169, have implemented is ‘Closure of Schools’, of

119

which we document 1583 such policies.

120

Meanwhile, the policy that has been implemented the most number of times, at0, has been health resources,

121

that is policies which seek to secure the availability of health-related materials (e.g. masks), infrastructure

122

(e.g. hospitals) or personnel (e.g. doctors) to address the pandemic. The next most common policy in terms

123

of the number of times it has been implemented, at 0, are policies which impose restrictions on non-essential

124

businesses.

125

However, we note that a strict comparison of policy types by this metric is not perfect, given that, for

126

example, there may be a need for more individualized policies regarding external border restrictions (given

127

the number of countries which a government can restrict travel access to) as opposed to closing schools.

128

We also note that we have more possible sub types for documenting health resources in the survey (21 sub

129

types) than restrictions of non-essential businesses (7 sub types). In the next subsection, we provide a more

130

rigorous method of comparing policies while taking their depth into account.

131

Additionally, our dataset also shows that the majority of countries in the world are a target of an external

132

border restriction, quarantine measure, or health monitoring measure from another country. Moreover, a

133

high percentage of policies documented in our dataset have mandatory enforcement.

134

In addition, we can look at the cumulative incidence of different types of policies in our data over time,

135

as we show in Figure 1. The figure shows that arguably relatively easy to implement policies like external

136

border restrictions, the forming of task forces, public awareness campaigns, and efforts to increase health

137

resources came relatively early in the course of the pandemic. Relatively more difficult policies to implement

138

like curfews, closures of schools, restrictions of non-essential businesses and restrictions of mass gatherings

5

Closure of Schools

Curfew

Declaration of
Emergency

External
Border
Restrictions

Health Monitoring

Health Resources

Health Testing

Internal
Border Restrictions

New Task
Force, Bureau or
Administrative
Configuration‘

Other

Public
Awareness Measures

Quarantine

Restriction of
Non−Essential
Businesses

Restriction of
Non−Essential
Government Services

Restrictions of
Mass Gatherings

Social Distancing

2000
1500
1000
500
0

Policies

2000
1500
1000
500
0

2000
1500
1000
500
0

2000
1500
1000
500
0
Jan Feb Mar Apr May Jan Feb Mar Apr May Jan Feb Mar Apr May Jan Feb Mar Apr May

Figure 1: Cumulative Incidence of Policy Event Types Over Time

139

arrived later.

140

We can also explore the extent to which other countries are affected by policies that can have a geographic

141

target outside the policy initiator (e.g. ‘external border restrictions’, ‘quarantine’) across time. For example,

142

in Figure 2, we map a network of bans on inbound flights to European countries initiated by European

143

countries as of March 15, 2020. In the plot, each horizontal line represents a particular country (what in

144

network terminology is called a node). The vertical lines denote whether there was such a flight ban between

145

two countries (what in network terminology is called an edge or a link), and the arrow of the vertical line

146

indicates the direction in which the ban is applied (what in network terminology allows us to capture directed

147

dyads). For instance, in the zoomed in panel inlay in Figure 2, the bottom horizontal line represents Taiwan,

148

and the vertical line connected to it shows that there was a flight ban between Taiwan and Italy. The arrow

149

pointing downwards to Taiwan shows that it was Italy which directed the flight ban against Taiwan. See

150

Longabaugh for more information on how to interpret this plot (2012)69 .

151

Overall, the Figure shows that by March 15, 2020, the governments of Poland and San Marino had banned all

152

flights into Poland and San Marino respectively while the government of Italy banned incoming flights from

153

China, Hong Kong, Macau and Taiwan. Additionally, the governments of Greece and Romania both banned

6

Figure 2: Network Map of Bans on Inbound Flights by European Countries as of March 15, 2020

154

flights from Italy while the government of Albania banned incoming flights from Greece. According to our

155

data, up until this point in time, no other European governments at the national level had banned inbound

156

flights from other countries. The availability of such dyadic data in this dataset may improve inference for

157

any number of analyses which seek to investigate how actions undertaken by different governmental units

158

are linked, including for example on how policies in one country affect health outcomes in another country.

159

Government Policy Activity Index

160

In this section, we briefly present our new index for tracking the relative government activity with regards

161

to policies targeting COVID-19 across countries and over time. The model is a version of item-response

162

theory known as ideal point modeling which incorporates over-time trends70–75 , permitting inference on how

163

a latent construct, in this case total policy activity, responds to changes in the pandemic. To fit the model,

164

the different policy types shown in Table 1, as well as sub-policies within them, were coded in terms of ordinal

165

values, with lower values for sub-national targets of policies and higher values for policies applying to the

7

166

entire country, or in the case of external border restrictions, to one or more external countries. For instance,

167

internal country policies can take on three possible values: no policy, sub-national policy, or policy covering

168

the whole country. Meanwhile external border restrictions can take on four possible values: no policy, policy

169

targeting one other country, policy targeting multiple countries, and policy targeting all countries in the

170

world (i.e., border closure).

171

We employed ideal point modeling because it can be given a latent utility interpretation71 . We assume

172

that each country has an unobserved “ideal point” on a uni-dimensional space representing its willingness

173

to impose policies, while each policy likewise has a position on the same space. The relative cost of different

174

policies can be thought of as the distance between a country’s ideal point and the ideal point of the policy

175

relative to other policies. While the meaning of this implied cost will vary from country to country, it is

176

likely a combination of the social, political and economic costs of implementing the policy at a given time

177

point.

178

As countries become more willing to pay the implied cost (i.e. the latent distance between country and policy

179

decreases), the country’s ideal points/policy activity score will rise and they will implement more policies.

180

This interpretation is similar to the traditional item-response theory approach for analyzing test questions

181

in which students who correctly answer more questions on a test are considered to have higher “ability”76,77 .

182

Following this logic, we are able to estimate latent country scores that represent the readiness of a country

183

to impose a set number of policies. The implied cost of policies is estimated via discrimination parameters,

184

which indicate how strongly policies discriminate between countries.

185

The country-level policy activity score is further allowed to vary over time in a random-walk process with

186

a country-specific variance parameter to incorporate heteroskedasticity73 . Incorporating over-time trends

187

explicitly is very important for capturing the nuances of policy implementation over time. For example,

188

countries that impose more restrictive policies at an earlier date will be rewarded with higher policy activity

189

scores compared to those who impose such policies at a later date. Imposing a given policy when most

190

countries have already imposed them will result in little if any change in the policy activity score.

191

The advantage of employing a statistical model, rather than simply summing across policies, is that the index

192

ends up as a weighted average, where the weights are derived from the probability that a certain policy is

193

implemented. In other words, while many countries set up task forces, relatively few imposed curfews at an

194

early stage. As a result, the model adjusts for these distinctions, producing a score that aggregates across

195

the patterns in the data.

196

Furthermore, because the model is stochastic, it is robust to some of the coding errors of the kind that often

197

occur in these types of datasets. As we discuss in our validation section, while we are continuing to validate

198

the data on a daily basis, the massive speed and scope of data collection means that we cannot identify all
8

199

issues with the data in real time. However, the measurement model employed only requires us to assume

200

that on average the policy codings are correct, not that they are correct for each instance. Coding error,

201

such as incorrectly selecting a policy type, will propagate through the model as higher uncertainty intervals,

202

but will not affect average posterior estimates. As our data quality improves, and we are able to collect more

203

data over time, the model will produce more variegated estimates with smaller uncertainty intervals.

204

Figure 3 shows the estimated index scores for the 196 countries in our dataset at present, and suggests strong

205

evidence of policy diffusion effects. While information about COVID-19 existed at least as early as January,

206

we do not see large-scale changes occurring in activity scores until March. Furthermore, the trajectories are

207

highly non-linear, with a large number of countries quickly transitioning from relatively low to relatively

208

high scores. This non-linear movement could be due to a variety of factors, including the rapid spread of

209

the virus and policy learning as states observe other states’ policy actions. We note that the country that

210

appeared to take the quickest action in the shortest amount of time is New Zealand, as can be seen in Figure

211

5 where we show over-time variance parameters for each country. For an interactive version of this figure,

212

please see our website.

213

Of course, a caveat with the index is that we may be missing some possible policy measures that have occurred

214

due to the difficulty in finding them in published sources. However, there is still clear differentiation within

215

the index in terms of when policies were imposed, with some countries starting to impose policies much

216

earlier than others. Furthermore, there is a clear break around March 1st when countries began to impose

217

more stringent policies across the world.

218

Table 2 shows the discrimination parameters from the underlying Bayesian model for each policy type. These

219

parameters suggest which policies governments find relatively difficult or costly to implement, and for that

220

reason tend to separate more active from less active states in terms of response to COVID-19. Two of these

221

policies (Closure of Restaurants and Quarantine at Home) were given fixed values in order to identify the

222

direction and rotation of the latent scale, and so their discrimination parameters are not informative. These

223

policies were chosen as a priori we can identify them as being relatively high cost. However, the rest of

224

the parameters were allowed to float, which provides inference as to which policies appear to be the most

225

difficult/costly to implement.

226

We note that these are average values for the sample. Imposing these policies may be less costly for certain

227

countries or for countries that share certain characteristics, such as having smaller numbers of enrolled

228

students or relatively healthy economies. However, it is important to note that we can see these patterns on

229

a world-wide scale.

230

At the top of the index we see various business closure policies as the most difficult to implement, while

231

school closures are the next most difficult. Closure of pre-schools, though, as opposed to other school types,
9

A

B
Jan
Spain

100

Russia

United Kingdom

75

United States of America

50

Italy

Russia

San Marino Italy
Germany

Singapore
South Korea

75

Comoros

Fe
b

0
Ja 6
n
1
Ja 3
n
2
Ja 0
n
27

0

0
Fe 3
b
1
Fe 0
b
1
Fe 7
b
24

25

Ja
n

Policy Activity Index Scale (0 to 100)

100

Feb

50
Mar
100

Gambia Samoa

MontenegroTurkey
Nauru

Somalia

75

25

Apr

50

Yemen

Ap

r1
Ap 3
r2
Ap 0
r2
7

6
r0
Ap

30

23

ar
M

16

ar

ar

M

M

May

ar

Apr

ar

Mar

M

Feb

02

0
Jan

M

0

09

25

Figure 3: CoronaNet Time-Varying Index of National Policy Activity of Measures Opposing COVID-19
Pandemic. Estimates are derived from Stan, a Markov Chain Monte Carlo sampler. Median posterior
estimates are shown. Plot A shows the full distribution of countries, while plot B shows each month separately
with the top 3 countries for that month in terms of increases in activity scores from start of the month to
the end of the month.

10

232

appears to be relatively less costly for states to undertake, perhaps because pre-schools do not operate on a

233

full-time basis. Internal border restrictions are considered more difficult to implement than external border

234

restrictions, while relatively straightforward policies like public awareness campaigns, health monitoring

235

and opening new task forces or bureaus are near the bottom of the index. Quarantines placing people in

236

external facilities, such as hotels or government quarantine centers, are also estimated as being less costly

237

than quarantine at home (stay-at-home orders).

238

Given this distribution of discrimination parameters, we believe the index is a valid representation of the

239

underlying process by which governments progressively impose more difficult policies. As states relax policies,

240

we will further gain information about which policies appear to be more costly as we will be able to factor in

241

the duration for which these policies were implemented. Consistent with our findings, we observe that the

242

announced relaxation policies happening at the time of writing in European countries primarily center on

243

businesses and school openings, suggesting that these policies are uniquely costly to keep in place compared

244

to travel restrictions78 .

245

Methods

246

In this section, we first provide more detail on the methodology we employed to estimate our government

247

policy action index. We then describe the variables that our dataset provides as well as how they are

248

organized. We then provide detail on the methodology we employed to collect the data.

249

Time-Varying Item Response Model

250

Our time-varying item response model follows the specification in 79. We review that notation here to show

251

how it relates to classical item-response theory as well as the ideal point modeling literature.

252

The likelihood function for the model is as follows for a set of countries i ∈ I, items j ∈ J, time points t ∈ T

253

and ordinal categories k ∈ K:




1 − ζ(γj αit − βj − c1 )
I
J
T

∏∏∏
L(Yijtk |αit , γj , βj ) =
ζ(γj αi − βj − ck−1 ) − ζ(γj αit − βj − ck )
i=1 j=1 t=1 



ζ(γ α − β − c
j it
j
k−1 ) − 0

if K = 0
if 0 < k < K, and

(1)

if k = K

254

In this equation, the time-varying country parameters αit , also called person abilities or ideal points, are

255

our estimate of policy activity scores. They are estimated jointly with the item (policy type) discrimination
11

256

parameters γj and item difficulty (intercept) parameters βj . To address the ordinal nature of the outcome

257

Yijtk , ordinal cutpoints ck are used to model the varying levels of enforcement and geographical targets in

258

the data. The logit function, represented by ζ(·), maps the latent scale to probability that a given ordinal

259

outcome is chosen. Because we have two separate type of ordered measures (domestic versus international

260

policies) with either three or four ordered categories, we estimate the model jointly as two ordered logit

261

specifications.

262

The likelihood in (1) is not fully identified due to possible scaling issues with the latent variable αit (i.e., it

263

has no natural units) and due to potential sign reflection (also called multi-modality) where L(Yijtk ) could

264

be unchanged even if αit is multiplied by -1. These identification issues are well-known in the literature72 ,

265

and we resolve them with standard practices. First, we assign a reasonably informative prior distribution

266

on the t = 1 ideal points:

αit=1 ∼ N (0, 1)

(2)

267

We also fix the discrimination parameters γj for two items, quarantines and restriction of restaurants and

268

bars, to opposite ends of the latent scale (+1 and -1). Because both of these variables load on the same side

269

of the scale (i.e. both indicate more policy activity), we reverse the order of the categories for restriction of

270

restaurants and bars. We note that these types of restrictions are not commonly used in traditional IRT,

271

where instead a sign restriction is imposed on all discrimination parameters. We employ the more flexible

272

ideal point specification, which also allows us to test the assumption that all the discrimination parameters

273

load on the same sign (as Table 2 shows, this is true for all of the parameters). The rest of the parameters are

274

given weakly informative prior distributions (note a prior is put over the difference of cutpoints, rather than

275

the cutpoints themselves, to reflect the fact that only the differences between cutpoints have any natural

276

scale):

γj ∼ N (0, 5)

(3)

βj ∼ N (0, 2)

(4)

ck − ck−1 ∼ N (0, 5)

(5)

277

Finally, to model the policy scores αit as a random walk, we assign a prior that is equal to the prior period

278

policy score plus normally-distributed noise:

12

αit ∼ N (αit−1 , σi )
σi ∼ E(1)

(6)
(7)

279

The over-time dimension induces a new source of identifiability issues, which we resolve by fixing the variance

280

σi of one of the countries (the United States) to 0.1 so that the over-time variance is relative to this constant.

281

This constraint has a similar identification effect to the informative prior on the first period policy activity

282

scores in (2).

283

Model Convergence

284

For estimation, we sample from four Markov Chain Monte Carlo (MCMC) chains with over-dispersed starting

285

values using Stan, a Hamiltonian Markov Chain Monte Carlo (HMC) sampler80 . We run the sampler for

286

800 iterations, 400 of which are discarded as warm-up. While this number of iterations is far less than other

287

MCMC samplers, HMC is far more efficient at exploring the posterior density and we are able to achieve

288

convergence using this number of iterations.

289

We assess convergence using split-R̂ by fitting four independent chains with over-dispersed starting values.

290

R̂ values for all parameters (which totaled more than 40,000) were 1.01 or less (see plot A in Extended Data

291

Figure 1). Plot B in Figure in Extended Data Figure 1 shows the distribution of effective number of samples

292

for the parameters, which is a way of comparing the auto-correlation in MCMC draws to independent draws

293

without auto-correlation, such as we might obtain from a Monte Carlo simulation. Again, the number of

294

effective samples is quite high, often exceeding the total number of empirical draws. This occurred because

295

Hamiltonian Monte Carlo can produce more informative samples than even a Monte Carlo simulation because

296

it can generate negatively correlated draws that explore the posterior space much more quickly. We also

297

assess convergence using trace plots, one of which is shown below for the time-varying country policy activity

298

scores for the United States. Strong mixing between chains can be observed in the plot. Finally, we report

299

no divergent transitions or iterations where the sampler reached its maximum tree depth, which are both

300

signs of poor mixing in the chains. For these reasons, we are confident than the sampler reached a stationary

301

distribution and was able to adequately explore the high-density regions of the joint posterior.

302

Model Validity

303

While employing a measurement model ensures robustness to arbitrary data coding errors, it is still necessary

304

to validate the model’s over-time process, which imposes some assumptions on how policy activity scores
13

Figure 4: Convergence Diagnostics for Random-Walk HMC Fit. Plot A shows the distribution of split-Rhat
values for all 40,000 parameters in the model, revealing most parameters are close to 1, which indicates strong
convergence. The effective number of samples for parameters in plot B is also very high, often exceeding
the total number of posterior draws. Plots C and D show strong mixing across chains for the intercept and
over-time parameter for the United States for January 30th.

14

United States of America

France

Germany

Mexico

Russia

South Korea

100

Policy Activity Index Scale (0 to 100)

75
50
25
0
Cross Sections
Random Walk

100
75
50
25
0
Jan

Feb Mar

Apr MayJan

Feb Mar

Apr MayJan

Feb Mar

Apr May

Figure 5: Comparison of Cross-sectional Estimates of Policy Activity Scores to the Random-Walk Time
Series Estimates
305

change over time. The use of a random walk implies that policy differences will be relatively stable from

306

one day to the next, which could limit the ability of scores to encompass quick, discontinuous changes81 .

307

While we employ this particular specification because it has been applied previously to a variety of empirical

308

phenomena and because of its relative parsimony, we can partially test for whether it captures changes by

309

estimating a static IRT model for each day in the sample. The corresponding estimates represent cross-

310

sections without any time process imposed.

311

Due to the complexity of comparing the estimates, we plot the results for six countries separately in Figure

312

4. This figure shows that indeed the cross-sectional estimates can show much more discontinuous jumps,

313

though we note at the same time that there appears to be substantial noise in the estimates as they only

314

incorporate information available at a single day. Nonetheless, while the random-walk estimates certainly

315

exhibit less discontinuous change, they do still allow for very quick divergence in policy activity scores, with

316

France and Russia moving from the bottom to the top of the index in the space of only a few weeks.

317

We note as well that the model is parameterized so that each country has its own variance parameter.

318

This permits the rate of change to vary by country, reducing the concern that the model may be overly

15

319

restricting change. These variance parameters are shown in Figure 5, sorted in order of increasing over-time

320

variance. These estimates are themselves substantively interesting, as the United States, which was used as

321

the reference category, has actually one of the lowest rates of over-time change, while some countries like

322

New Zealand, Spain and San Marino witnessed the highest variance in policy activity scores. Because, at

323

this time, the index only captures increasing numbers of policies, the variance parameters can be given the

324

interpretation of which countries responded in the shortest period of time across a broad array of policy

325

indicators.

326

Data Schema

327

Each unique record documents at the minimum, the following information: the policy type; the name of the

328

country from which a policy originates (if the policy originates from a province or state, that information

329

is also documented. Future versions of the dataset will also include information on whether a policy was

330

initiated from a city or municipality or another level of government); the degree to which a policy must be

331

complied with; the entity enforcing the policy; the date a policy is announced, implemented and ends. Note

332

that sometimes policies are announced without a pre-determined end date. In those cases, this field is left

333

blank.

334

For all policies, the database further documents information about the geographic target of the policy and

335

the human or material target of a policy. Note however, for some policies, the geographic target may be

336

the same as the policy initiator and in those cases can be considered monadic. Where applicable, we also

337

document the directional flow of the policy, and the mechanism of travel.

338

All of the information mentioned above is also provided qualitatively via a textual event description. Ad-

339

ditional meta-data that is available for all policies include when the record entered into the database and

340

a link for the information source for the policy. See Appendix A in the supplementary materials for a list

341

of currently available fields in the data, along with a list of external data variables such as country-level

342

covariates that are added to daily releases, including COVID-19 tests and cases.

343

There is a unique record ID for each unique policy announcement per initiating country, which we code at

344

the policy sub type. That is, some policy types are further categorized into sub types. For example, ‘Quar-

345

antine’ can be further classified into one or more of the following sub types: ‘Self-Quarantine’, ‘Government

346

Quarantine’, ‘Quarantine outside the home or government facility’, ‘Quarantine only applies to people of

347

certain ages’ and ‘Other’. Of the 12601 such events in the dataset, we have identified 10798 unique events.

348

That is, some events in the database are updates or changes to existing policies. We link such events over

349

time using a unique ID, which we term the policy ID as opposed to the record ID. An event counts as an

16

San Marino
Djibouti
Jordan

Spain Samoa New Zealand

Luxembourg Republic of Serbia
Guinea
Madagascar Latvia

Grenada
Saint Kitts and Nevis Gabon
Slovakia Belize
Qatar
Laos
United Kingdom
Tonga
Uruguay
Malawi
Netherlands
Peru
Ecuador
The Bahamas

Somalia

Suriname
Hungary Botswana Slovenia
Finland Greece Georgia Gambia
MaltaCentral
African RepublicEl Salvador
Denmark

Eritrea
Montenegro
United Republic of Tanzania
Saudi Arabia
Liechtenstein

Togo
East Timor
Solomon Islands
Mozambique

Mauritania

Philippines
Ukraine
Democratic Republic of the Congo

Sri Lanka
Chile
Zambia
Niger
South Africa Cameroon
Antigua and Barbuda
Italy
Cambodia Afghanistan
Switzerland
Brunei
Portugal

Monaco Swaziland Lesotho
Costa RicaSierra Leone Kenya

Poland Dominica
Algeria
Federated States of Micronesia
Trinidad and Tobago Albania Russia
Romania
Maldives
Angola
Australia
Moldova
Uganda
Guinea
Bissau
Equatorial
Guinea
Burundi
Tunisia
Comoros
Ethiopia
Croatia Panama
Mali
Lithuania
Republic of Congo
Vanuatu
Macedonia
Kiribati
Israel
South Sudan Nauru
Argentina
Sudan
Burkina Faso Bhutan
Guatemala
Kuwait
Yemen
Ireland
Cuba
European Union
Fiji Mexico
Paraguay
Zimbabwe
Iraq
Bosnia and Herzegovina
United Arab Emirates
Belgium
Palestine
Papua New Guinea
Oman
Azerbaijan
Sao Tome and Principe
France Estonia
Saint Lucia Germany Bahrain
Malaysia
Bolivia
Ghana
Thailand
Morocco
Barbados Syria
South Korea Pakistan
Benin
Uzbekistan Namibia
North Korea
Sweden
Nigeria Turkey Colombia
Libya
Kazakhstan Senegal
Czech Republic
Belarus
Austria
Cyprus
Andorra
SingaporeCape Verde
Saint Vincent and the Grenadines Brazil
Armenia
Iran
Egypt Bulgaria
Mauritius
Rwanda
VietnamIvory Coast
Guyana Venezuela
Jamaica Bangladesh
China Lebanon
Indonesia
Nicaragua Seychelles
Tuvalu
Turkmenistan Chad Canada Nepal
Iceland

KyrgyzstanHonduras Tajikistan
Dominican Republic
India

Taiwan Mongolia Liberia

Japan Norway Marshall Islands Myanmar
United States of America
0.0

0.5

1.0

1.5

2.0

Over−Time Variance of Latent Scale

Figure 6: Country-level Variance (Over-time Change)
17 Parameters from Policy Activity Index Estimation

350

update if it deals with a change in either the:

351

1. The time duration (e.g. A country lengthens its quarantine to 28 days from 14 days.)

352

2. The quantitative ‘amount’ of the policy (e.g. A restriction of mass gatherings was previously set at 100

353

people and now it is set at 50 people).

354

3. A set of other policy dimensions:

355

a. Who the policy applies towards (e.g. The quarantine used to apply to people of all ages and now it

356

357

358

359

360

only applies to the elderly).
b. The directionality of the policy (e.g. a travel ban previously banned inbound flights from country X
and now bans both inbound and outbound flights to and from country X).
c. The travel mechanism (e.g. a travel ban was previously applied towards all types of travel but now
only applies towards flights).

361

d. The compliance rules for the policy (e.g. The quarantine used to be voluntary but is now mandatory).

362

e. The enforcer of a policy (e.g. the policy was previously under the purview of the ministry of health

363

but was changed to the ministry of the interior).

364

A policy counts as a new entry and not an update if it deals with a change in any other dimension, e.g. the

365

qualitative policy type (e.g. a quarantine used to mandate a stay in a government facility but now quarantine

366

at home is allowed) or the targeted country (e.g. quarantine upon arrival was mandated for people traveling

367

from China but now these rules also apply to people traveling from Italy). In those cases, or when a policy

368

is completely cancelled or annulled, the policy is coded as having ended.

369

Data Collection Methodology

370

As researchers learn more about the various health, economic, and social effects of the COVID-19 pandemic,

371

it is crucial that to the greatest extent possible, they have access to data that is reliable, valid, and timely.

372

We have adopted a data collection methodology that we believe optimizes over all three of these constraints.

373

To collect the data, we recruited more than 260 research assistants (RAs) from colleges and universities

374

around the world, representing 18 out of the 24 time zones. Large social scientific datasets typically rely on

375

experts, coders, or crowd-sourcing to input data. The literature has shown that common coding tasks can be

376

completed via crowd-sourcing82,83 , but that there are also limitations to the wisdom of crowds when specific

377

contextual or subject knowledge is required84,85 . To address these trade offs, we decided to train current RAs

378

to code our entries, leveraging the benefits of wide-spread recruitment and a diverse pool of country-specific

379

knowledge from across the globe. Data collection started on March 28, 2020 and has proceeded rapidly,

380

reaching 12601 records as of the date of this article. Each RA is responsible for tracking government policy

18

381

actions for at least one country. RAs were allocated depending on their background, language skills and

382

expressed interest in certain countries86 . Note depending on the level of policy coordination at the national

383

level, certain countries were assigned multiple RAs, e.g. the United States, Germany, or France.

384

We have also partnered with the machine learning company Jataware to automate the collection of more than

385

200,000 news articles from around the world related to COVID-19. Jataware employs a natural language

386

processing (NLP) classifier using Bidirectional Encoder Representations from Transformers (BERT) to detect

387

whether a given article is indicative of a governmental policy intervention related to COVID-19. They then

388

apply a secondary NLP classifier to categorize the type of policy intervention based on the definitions in our

389

codebook (e.g. “declaration of emergency”, “quarantine”, etc.). Next, Jataware extracts the geospatial and

390

temporal extent of the policy intervention (e.g. “Washington DC” and “March 15, 2020”) whenever possible.

391

The resulting list of news sources is then provided to our RAs as an additional source for manual coding and

392

further data validation.

393

In what follows, we describe in greater detail how RAs document the policies that they identify using our

394

data collection software instrument, and our post data-collection validation procedure. Please refer to the

395

Appendix B in the supplementary materials for more information on our procedure for on-boarding and

396

training RAs and our system for communicating with and organizing RAs.

397

Data Collection Software Instrument

398

We designed a Qualtrics survey with survey questions to systematize and streamline the documentation of

399

a given government policy over a wide range of dimensions. With this tool, RAs can easily and efficiently

400

document information about different policy actions by answering the relevant questions posed in the survey

401

(Büthe, Minhas and Lieu, unpublished manuscript). For example, instead of entering the country that

402

initiated a policy action into a spreadsheet, RAs answer the following question in the survey: “From what

403

country does this policy originate?” and choose from the available options given in the survey.

404

By using a survey instrument to collect data, we are able to systematize the collection of very fine-grained

405

data while minimizing coding errors common to tools like shared spreadsheets. The value of this approach

406

of course, depends on the comprehensiveness of the questions posed in the survey, especially in terms of the

407

universe of policy actions that countries have implemented against COVID-19. For example, if the survey

408

only allowed RAs to select ‘quarantines’ as a government policy, it would not capture any data on ‘external

409

border restrictions’, which would seriously reduce the value of the resulting data.

410

As such, to ensure the comprehensiveness of the data, before designing the survey, we collected in depth,

411

over-time data on policy actions taken by one country since the beginning of the outbreak, Taiwan, as well

19

412

as cross-national data on travel bans implemented by most countries for a total of 245 events. The specific

413

data source we cross referenced for this effort was the March 20, 2020 version of a New York Times article

414

on travel restrictions across the globe87 .

415

We chose to focus on Taiwan on because of its relative success, as of March 28, 2020, in limiting the

416

negative health consequences of COVID-19 within its borders88 . As such, it seemed likely at the time that

417

other countries would choose to emulate some of the policy measures that Taiwan had implemented, which

418

increases the comprehensiveness of the questions we ask in our survey. Indeed at the time of writing, it

419

would appear that some countries have indeed sought to emulate Taiwan’s response89 .

420

Meanwhile, by also investigating variation in how different countries around the world have implemented

421

travel restrictions, we have also helped ensure that our survey is able to comprehensively document variation

422

in how an important and commonly used policy tool is applied, e.g., restrictions on different methods of travel

423

(e.g. flights, cruises), restrictions across borders and within borders, restrictions targeted toward people of

424

different statuses (e.g. citizens, travelers).

425

There are many additional benefits of using a survey instrument for data collection, especially in terms of

426

ensuring the reliability and validity of the resulting data:

427

1. Preventing unforced measurement error: RAs are prevented from entering data into incorrect fields

428

or unknowingly overwriting existing data—as would be possible with manual data entry into a

429

spreadsheet—because RAs can only document one policy action at a time in a given iteration of a

430

survey and do not have access to the full spreadsheet when they are entering in the data.

431

2. Standardizing responses: We are able to ensure that RAs can only choose among standardized responses

432

to the survey questions, which increases the reliability of the data and also reduces the likelihood of

433

measurement error. For example, when RAs choose different dates that we would like them to document

434

(e.g., the date a policy was announced) they are forced to choose from a calendar embedded into the

435

survey which systematizes the day, month and year format that the date is recorded in.

436

3. Minimizing measurement error: A survey instrument allows coding different conditional logics for when

437

certain survey questions are posed. This technique obviates the occurrence of logical fallacies in our

438

data. For example, we are able to avoid situations where an RA might accidentally code the United

439

States as having closed all schools in another country.

440

4. Reduction of missing data: We are able to reduce the amount of missing data in the dataset by using

441

the forced response option in Qualtrics. Where there is truly missing data, there is a text entry at the

442

end of the survey where RAs can describe what difficulties they encountered in collecting information

443

for a particular policy event.

20

444

5. Reliability of the responses: We increase the reliability of the documentation for each policy by embed-

445

ding descriptions of different possible responses within the survey. For example, in the survey question

446

where RAs are asked to identify the policy type (type variable, see Appendix A in the supplementary

447

materials), the survey question includes pop-up buttons which allow RAs to easily access descriptions

448

and examples of each possible policy type. Such pop-up buttons were also made available for the

449

survey questions which code for the people or materials a policy was targeted at (target_who_what)

450

and whether the policy was inbound, outbound or both (target_direction). Embedding such infor-

451

mation in the dataset both clarifies the distinction between different answer choices and increases the

452

efficiency of the policy documentation process (as RAs are not obliged to refer back and forth from

453

the survey to the codebook).

454

6. Linking observations. The use of a survey instrument facilitates the linking of policy events together

455

over time should there be updates to existing policies. Once coded, each policy is given a unique

456

Record ID, which RAs can easily look up, reference and link to if they need to update a particular

457

policy.

458

Post-Data Collection Validation Checks

459

We further implement the following processes to validate the quality of the dataset:

460

1. Cleaning: Before validation, we use a team of RAs to check the raw data for logical inconsistencies

461

and typographical errors. The data will also become part of a larger effort commissioned by the World

462

Health Organization to collate different datasets on government actions taken in response to COVID-19.

463

To that end, future versions of the data will be further cleaned with resources from this collaborative

464

effort90 .

465

2. Multiple Coding for Validation: Others have shown that the random allocation of tasks and the

466

validation of labels by more than one coder are among the best ways to improve the quality of a

467

dataset91,92 . We randomly sample 10% of the dataset using the source of the data (e.g. newspaper

468

article, government press release) as our unit of randomization. We use the source as our unit of

469

randomization because one source may detail many different policy types. We then provide this source

470

to a fully independent RA and ask her to code for the government policy contained in the sampled

471

source in a separate, but identical, survey instrument. If the source is in a language the RA cannot

472

read, then a new source is drawn. The RA then codes all policies in the given source. This practice is

473

repeated a third time by a third independent coder. Given the fact that each source in the sample is

474

coded three times, we can assess the reliability of our measures and report the reliability score of each

475

coder.
21

476

3. Evaluation and Reconciliation: We then check for discrepancies between the originally coded data and

477

the second and third coding of the data through two primary methods. First, we use majority-voting

478

to establish a consensus for policy labels. Using the majority label as an estimate of the “hidden true

479

label” is a common method to address classification problems93 . One issue with this approach is that

480

it assumes that all coders are equally competent94 . This criticism is generally levied at data creation

481

with crowd-sourced laborers. We mitigate this problem by training our RAs in the data collection

482

process and prioritizing RA country-knowledge and language skills, therefore ensuring a more equal

483

baseline for RA quality. In addition, we will provide RA identification codes that will allow users to

484

evaluate coder accuracy.

485

If the majority achieves consensus, then we consider the entry valid. If a discrepancy exists, a fourth RA or

486

PI makes an assessment of the three entries to determine whether one, some, a combination of all three is

487

most accurate. Reconciled policies are then entered into the dataset as a correction for full transparency. If

488

an RA was found to have made a coding mistake, then we sample six of their previous entries: 3 entries which

489

correspond to the type of mistake made (e.g. if the RA incorrectly codes an ‘External Border Restriction’

490

as a ‘Quarantine’, we sample 3 entries where the RA has coded a policy as being about a ‘Quarantine’) and

491

randomly sample 3 more entries to ascertain whether the mistake was systematic or not. If systematic errors

492

are found, entries coded by that individual will be entirely recoded by a new RA.

493

At the time of writing, we are in the process of completing our second coding of the validation sample. Thus

494

far, 297 policies have been double coded—276 double-coded policies after excluding the category ‘Other

495

policies’ from the analysis—out of the original 500 randomly-selected policies included in our validation set.

496

This is equivalent to 10% of the first 5,000 policies in the dataset. We will be gradually expanding the

497

validation set until we cover all observations.

498

We provide several measures in Table 3 to evaluate the inter-coder reliability at this early stage of validation.

499

We find remarkable heterogeneity in the inter-coder reliability across types of policies. Our coders show

500

a substantial level of agreement on policies such as ‘Restrictions of Mass Gatherings’ (n = 21, k = 0.95),

501

‘Closure of Schools’ (n = 14, k = 0.92), ‘Restrictions of Non-Essential’ (n = 19, k = 0.89), ‘External Border

502

Restrictions’ (n = 52, k = 0.83), ‘Curfew’ (n = 6, k = 0.82), and Internal Border Restrictions (n = 11,

503

k = 0.80). However, we also observe poor inter-rater agreement scores in other policies such as ‘Social

504

Distancing’ (n = 14, k = 0.38), ‘Public Awareness Measures’ (n = 15, k = 0.49), and ‘New Task Force,

505

Bureau or Administrative Configuration’ (n = 9, k = 0.52). Overall, these statistics indicate substantial

506

levels of overall agreement between coders with inter-coder reliability scores between 0.71 and 0.74 (n =

507

276).

508

Our initial assessment of miscodings suggests that our coders have difficulties in distinguishing ‘Social Dis-

22

509

tancing’ policies from ‘Quarantine/Lockdowns’ and ‘Public Awareness Campaigns’. We have taken some steps

510

to ameliorate these issues. First, we have recently separated Quarantine from Lockdowns in our codebook

511

and survey. Second, we have added branching logic into the Qualtrics survey that also clarifies the specific

512

sub-policies that fall under ‘Quarantine’, ‘Lockdowns’, and ‘Social Distancing’. Additionally, we have added

513

several sub-types of ‘Public Awareness Campaigns’ in the survey that should provide conceptual clarity to

514

this policy category. Further, the creation of a ‘New Task Force, Bureau or Administrative Configuration’

515

often goes together with a number of additional policies. In these cases, some of our coders seem to focus

516

on these additional policies rather than on the creation of administrative units, which lowers the reliability

517

of the coding system for this policy. We have provided RAs with better guidance on this category and have

518

also added several sub-types for this question to help improve conceptual clarity for this policy category. Fi-

519

nally, we have detected extremely poor reliability for the health-related policies of ‘Health Monitoring’ and

520

‘Health Testing’. We have clarified the distinction across the three health-related policies—namely, ‘Health

521

Resources’, ‘Health Monitoring’ and ‘Health Testing’—in the codebook and we combine them under the

522

category of ‘Health Measures’ in this on-going validation.

523

In the following weeks, we expect inter-coder reliability scores to improve as a consequence of three processes:

524

(a) our coders are becoming more experience with the codebook and the coding tasks in general; (b) we are

525

cleaning the dataset of obvious errors and logical inconsistencies; and, (c) we are working on clarifying and

526

improving the codebook and the coding system. Notwithstanding these processes, we acknowledge that

527

some ambiguities will unavoidably remain providing evidence for the utility of our planned “majority voting”

528

validation strategy.

529

Conclusion

530

As policymakers, researchers and the broader public debate and compare how to succeed against the novel

531

threats posed by COVID-19, they need real-time, traceable data of government policies in order to understand

532

which of these policies are effective, and under what conditions. This requires specific knowledge of the

533

variation of such policies and how widely implemented they are across countries and time. The goal of the

534

dataset and policy action index presented here is to provide this information.

535

We have tried to match our data collection efforts to keep up with the exponential speed with which COVID-

536

19 has already upended global public health and the international economy while also maintaining high levels

537

of quality. However, we will inevitably be refining, revising and updating our data to reflect new knowledge

538

and trends as the pandemic unfolds. The data that we present here represents an initial release; we will

539

continue to validate and release data so long as governments continue to develop policies in response to

23

540

COVID-19.

541

In future work, we intend to analyze the policy combinations that are best able to stymie the epidemic so as

542

to contribute to the research community and provide urgently needed knowledge for policymakers and the

543

wider global public.

24

544

Data Availability

545

For the most current, up to date version of the dataset, please visit http://coronanet-project.org or our

546

Github page at https://github.com/saudiwin/corona_tscs. For more information on the exact variables

547

collected, please see our publicly available codebook here and visit our website.

548

Code Availability

549

Interested readers may also find our code for collecting the data and maintaining the database at our Github

550

page: https://github.com/saudiwin/corona_tscs.

25

551

References

552

1. Porter, D. Health, civilization and the state: A history of public health from ancient to modern times.

553

(Routledge, 2005).

554

2. Scott, J. C. Against the grain: A deep history of the earliest states. (Yale University Press, 2017).

555

3. Behbehani, A. M. The smallpox story: Life and death of an old disease. Microbiological reviews 47, 455

556

(1983).

557

4. Duncan-Jones, R. P. The impact of the antonine plague. Journal of Roman Archaeology 9, 108–136

558

(1996).

559

5. Crosby, A. W. The columbian exchange: Biological and cultural consequences of 1492. vol. 2 (Greenwood

560

Publishing Group, 2003).

561

6. Ziegler, P. The black death. (Faber & Faber, 2013).

562

7. Jannetta, A. B. Epidemics and mortality in early modern japan. (Princeton University Press, 2014).

563

8. Hatchett, R. J., Mecher, C. E. & Lipsitch, M. Public health interventions and epidemic intensity during

564

the 1918 influenza pandemic. Proceedings of the National Academy of Sciences 104, 7582–7587 (2007).

565

9. Shah, S. Pandemic: Tracking contagions, from cholera to ebola and beyond. (Macmillan, 2016).

566

10. Snow, J. The cholera near golden-square, and at deptford. Medical Times and Gazette 9, 321–322 (1854).

567

11. Paneth, N. Assessing the contributions of john snow to epidemiology: 150 years after removal of the

568

broad street pump handle. Epidemiology 15, 514–516 (2004).

569

12. Taubenberger, J. K. & Morens, D. M. 1918 influenza: The mother of all pandemics. Revista Biomedica

570

17, 69–79 (2006).

571

13. Kilbourne, E. D. Influenza pandemics of the 20th century. Emerging infectious diseases 12, 9 (2006).

572

14. Farmer, P. Social inequalities and emerging infectious diseases. Emerging infectious diseases 2, 259

573

(1996).

574

15. Van Bavel, J. J. et al. Using social and behavioural science to support covid-19 pandemic response.

575

Nature Human Behaviour 1–12 (2020).

576

16. Bootsma, M. C. & Ferguson, N. M. The effect of public health measures on the 1918 influenza pandemic

577

in us cities. Proceedings of the National Academy of Sciences 104, 7588–7593 (2007).

578

17. Hunter, M. The changing political economy of sex in south africa: The significance of unemployment

579

and inequalities to the scale of the aids pandemic. Social science & medicine 64, 689–700 (2007).

26

580

18. Bandayrel, K., Lapinsky, S. & Christian, M. Information technology systems for critical care triage and

581

medical response during an influenza pandemic: A review of current systems. Disaster medicine and public

582

health preparedness 7, 287–291 (2013).

583

19. Abelin, A., Colegate, T., Gardner, S., Hehme, N. & Palache, A. Lessons from pandemic influenza a

584

(h1n1): The research-based vaccine industry’s perspective. Vaccine 29, 1135–1138 (2011).

585

20. Chew, C. & Eysenbach, G. Pandemics in the age of twitter: Content analysis of tweets during the 2009

586

h1n1 outbreak. PloS one 5, (2010).

587

21. Jarynowski, A., Wójta-Kempa, M., Płatek, D. & Czopek, K. Attempt to understand public health

588

relevant social dimensions of covid-19 outbreak in poland. Available at SSRN 3570609 (2020).

589

22. Boyd, T., Savel, T., Kesarinath, G., Lee, B. & Stinn, J. The use of public health grid technology in

590

the united states centers for disease control and prevention h1n1 pandemic response. in 2010 ieee 24th

591

international conference on advanced information networking and applications workshops 974–978 (IEEE,

592

2010).

593

23. Galaz, V. Pandemic 2.0: Can information technology help save the planet? Environment: Science and

594

Policy for Sustainable Development 51, 20–28 (2009).

595

24. Flaxman, S. et al. Estimating the number of infections and the impact of non-pharmaceutical interven-

596

tions on COVID-19 in 11 european countries. preprint:10.25561/77731 (2020).

597

25. Ferguson, N. et al. Impact of non-pharmaceutical interventions (NPIs) to reduce COVID19 mortality

598

and healthcare demand. preprint:10.25561/77482 (2020).

599

26. Goumenou, M. et al. COVID-19 in northern italy: An integrative overview of factors possibly influencing

600

the sharp increase of the outbreak. Molecular Medicine Reports (2020).

601

27. Singh, R. & Adhikari, R. Age-structured impact of social distancing on the covid-19 epidemic in india.

602

Preprint arXiv:2003.12055 (2020).

603

28. Prem, K. et al. The effect of control strategies to reduce social mixing on outcomes of the covid-19

604

epidemic in wuhan, china: A modelling study. The Lancet Public Health (2020).

605

29. Chen, S., Yang, J., Yang, W., Wang, C. & Bärnighausen, T. COVID-19 control in china during mass

606

population movements at new year. The Lancet 395, 764–766 (2020).

607

30. Koo, J. R. et al. Interventions to mitigate early spread of sars-cov-2 in singapore: A modelling study.

608

609

The Lancet Infectious Diseases (2020).
31. Arriola, L. & Grossman, A. Ethnic marginalization and (non)Compliance in public health emergencies.

27

610

forthcoming in the Journal of Politics (2020).

611

32. Yancy, C. W. COVID-19 and african americans. Jama (2020).

612

33. Anwar, S., Nasrullah, M. & Hosen, M. COVID-19 and bangladesh: Challenges and how to address them.

613

Front. Public Health 8, 154 (2020).

614

34. Corburn, J. et al. Slum health: Arresting covid-19 and improving well-being in urban informal settle-

615

ments. Journal of Urban Health 1–10 (2020).

616

35. Anderson, R. M., Heesterbeek, H., Klinkenberg, D. & Hollingsworth, T. D. How will country-based

617

mitigation measures influence the course of the covid-19 epidemic? The Lancet 395, 931–934 (2020).

618

36. Dorn, A. van, Cooney, R. E. & Sabin, M. L. COVID-19 exacerbating inequalities in the us. The Lancet

619

395, 1243–1244 (2020).

620

37. Cronert, A. Democracy, state capacity, and covid-19 related school closures. Preprint at APSA Preprint:

621

10.33774/apsa-2020-jf671-v4 (2020).

622

38. Allcott, H. et al. Polarization and public health: Partisan differences in social distancing during the

623

coronavirus pandemic. Preprint at NBER Working Paper: 10.3386/w26946 (2020).

624

39. Barrett, R., Kuzawa, C. W., McDade, T. & Armelagos, G. J. Emerging and re-emerging infectious

625

diseases: The third epidemiologic transition. Annual review of anthropology 27, 247–271 (1998).

626

40. Miller, M. A., Viboud, C., Balinska, M. & Simonsen, L. The signature features of influenza pandemics—

627

implications for policy. New England Journal of Medicine 360, 2595–2598 (2009).

628

41. Pierson, P. Increasing returns, path dependence, and the study of politics. American political science

629

review 94, 251–267 (2000).

630

42. Przeworski, A., Stokes, S. C. S., Stokes, S. C. & Manin, B. Democracy, accountability, and representation.

631

vol. 2 (Cambridge University Press, 1999).

632

43. Svolik, M. W. The politics of authoritarian rule. (Cambridge University Press, 2012).

633

44. Kitschelt, H., Wilkinson, S. I. & others. Patrons, clients and policies: Patterns of democratic account-

634

ability and political competition. (Cambridge University Press, 2007).

635

45. Gailmard, S. & Patty, J. W. Preventing prevention. American Journal of Political Science 63, 342–352

636

(2019).

637

46. Meltzer, M. I., Cox, N. J. & Fukuda, K. The economic impact of pandemic influenza in the united states:

638

Priorities for intervention. Emerging infectious diseases 5, 659 (1999).

639

47. Nunn, N. The importance of history for economic development. Annu. Rev. Econ. 1, 65–92 (2009).
28

640

48. Kilian, L. Not all oil price shocks are alike: Disentangling demand and supply shocks in the crude oil

641

market. American Economic Review 99, 1053–69 (2009).

642

49. Noy, I. The macroeconomic consequences of disasters. Journal of Development economics 88, 221–231

643

(2009).

644

50. Correia, S., Luck, S. & Verner, E. Pandemics depress the economy, public health interventions do not:

645

Evidence from the 1918 flu. Preprint at SSRN: http://dx.doi.org/10.2139/ssrn.3561560 (2020).

646

51. Kindleberger, C. P. & Aliber, R. Z. Manias, panics and crashes: A history of financial crises. (Palgrave

647

Macmillan, 2011).

648

52. Peckham, R. Economies of contagion: Financial crisis and pandemic. Economy and Society 42, 226–248

649

(2013).

650

53. Dasgupta, S., Laplante, B., Wang, H. & Wheeler, D. Confronting the environmental kuznets curve.

651

Journal of economic perspectives 16, 147–168 (2002).

652

54. Folke, C. Resilience: The emergence of a perspective for social–ecological systems analyses. Global

653

environmental change 16, 253–267 (2006).

654

55. Galea, S. et al. Trends of probable post-traumatic stress disorder in new york city after the september

655

11 terrorist attacks. American Journal of Epidemiology 158, 514–524 (2003).

656

56. Gifford, R. Environmental psychology matters. Annual review of psychology 65, 541–579 (2014).

657

57. Baekkeskov, E. & Rubin, O. Why pandemic response is unique: Powerful experts and hands-off political

658

leaders. Disaster Prevention and Management 23, 81–93 (2014).

659

58. Boin, A., Stern, E., Hart, P. ’. & Sundelius, B. The politics of crisis management: Public leadership

660

under pressure. (Cambridge University Press, 2016).

661

59. Tierney, K. J. From the margins to the mainstream? Disaster research at the crossroads. Annu. Rev.

662

Sociol. 33, 503–525 (2007).

663

60. Blaikie, P., Cannon, T., Davis, I. & Wisner, B. At risk: Natural hazards, people’s vulnerability and

664

disasters. (Routledge, 2014).

665

61. Burby, R. J. Hurricane katrina and the paradoxes of government disaster policy: Bringing about wise

666

governmental decisions for hazardous areas. The annals of the American academy of political and social

667

science 604, 171–191 (2006).

668

62. Lührmann, A., Edgell, A. B. & Maerz, S. F. Pandemic backsliding: Does covid-19 put democracy at

669

risk? Varieties of Democracy Policy Brief 1–4 (2020).

29

670

63. Coibion, O., Gorodnichenko, Y. & Weber, M. Labor markets during the covid-19 crisis: A preliminary

671

view. Preprint at NBER: 10.3386/w27017 (2020).

672

64. Atkeson, A. What will be the economic impact of covid-19 in the us? Rough estimates of disease scenarios.

673

Preprint at NBER: 10.3386/w26867 (2020).

674

65. McKibbin, W. J. & Fernando, R. The global macroeconomic impacts of covid-19: Seven scenarios.

675

CAMA Working Paper No. 19/2020: https://dx.doi.org/10.2139/ssrn.3547729 (2020).

676

66. Fernandes, N. Economic effects of coronavirus outbreak (covid-19) on the world economy. Preprint at

677

SSRN: 3557504 (2020).

678

67. Zandifar, A. & Badrfam, R. Iranian mental health during the covid-19 epidemic. Asian journal of

679

psychiatry 51, 101990 (2020).

680

68. Qiu, J. et al. A nationwide survey of psychological distress among chinese people in the covid-19 epidemic:

681

Implications and policy recommendations. General psychiatry 33, (2020).

682

69. Longabaugh, W. J. Combing the hairball with biofabric: A new approach for visualization of large

683

networks. BMC bioinformatics 13, 275 (2012).

684

70. Kubinec, R. Generalized ideal point models for time-varying and missing-data inference. Preprint at

685

Open Science Foundation Preprints: 10.31219/osf.io/8j2bt (2019).

686

71. Clinton, J., Jackman, S. & Rivers, D. The statistical analysis of rollcall data. American Political Science

687

Review 98, 355–370 (2004).

688

72. Bafumi, J., Gelman, A., Park, D. K. & Kaplan, N. Practical issues in implementing and understanding

689

bayesian ideal point estimation. Political Analysis 13, 171–187 (2005).

690

73. Martin, A. D. & Quinn, K. M. Dynamic ideal point estimation via markov chain monte carlo for the u.s.

691

Supreme court, 1953-1999. Political Analysis 10, 134–153 (2002).

692

74. Barberá, P. Birds of the same feather tweet together: Bayesian ideal point estimation using twitter data.

693

Political Analysis 23, 76–91 (2015).

694

75. Bonica, A. Mapping the ideological marketplace. American Journal of Political Science 58, 367–386

695

(2014).

696

76. Takane, Y. & Leeuw, J. de. On the relationship between item response theory and factor analysis of

697

discretized variables. Psychometrika 52, 393–408 (1986).

698

77. Reckase, M. D. Multidimensional item response theory. (Springer, 2009).

30

699

78. Doherty, B. The exit strategy: How countries around the world are preparing for life after covid-19. The

700

Guardian (2020).

701

79. Kubinec, R. Politically-connected firms and the military-clientelist complex in north africa. Preprint at

702

SocArxiv: https://osf.io/preprints/socarxiv/mrfcu/ (2019).

703

80. Carpenter, B. et al. Stan: A probabilistic programming language. Journal of Statistical Software 76,

704

(2017).

705

81. Reunig, K., Kenwick, M. R. & Fariss, C. J. Exploring the dynamics of latent variable models. Political

706

Analysis 503–517 (2019).

707

82. Benoit, K., Conway, D., Lauderdale, B. E., Laver, M. & Mikhaylov, S. Crowd-sourced text analysis:

708

Reproduceable and agile production of political data. American Political Science Review 110, 278–295

709

(2016).

710

83. Sumner, J. L., Farris, E. M. & Holman, M. R. Crowdsourcing reliable local data. Political Analysis 28,

711

244–262 (2019).

712

84. Marquardt, K. L. et al. Experts, coders, and crowds: An analysis of substitutability. Preprint at V-Dem

713

Working Paper 2017:53: http://dx.doi.org/10.2139/ssrn.3046462 (2017).

714

85. Urlacher, B. R. Opportunities and obstacles in distributed or crowdsourced coding. Qualitative &

715

Multi-Method Research 15, 15–21 (2017).

716

86. Horn, A. Can the online crowd match real expert judgments? How task complexity and coder location

717

affect the validity of crowd-coded data. European Journal of Political Research 58, 236–247 (2019).

718

87. Salcedo, A., Yar, S. & Cherelus, G. Coronavirus travel restrictions and bans globally. The New York

719

720

721

Times (2020).
88. Beech, H. Tracking the coronavirus: How crowded asian cities tackled an epidemic. The New York
Times (2020).

722

89. Aspinwall, N. Taiwan is exporting its coronavirus successes to the world. Foreign Policy (2020).

723

90. Gibney, E. Whose coronavirus strategy worked best? Scientists hunt most effective policies. Nature 581,

724

15–16 (2020).

725

91. Sheng, V. S., Provost, F. & Ipeirotis, P. G. Get another label? Improving data quality and data mining

726

using multiple, noisy labelers. 614–622 (2008).

727

92.

728

amazonaws.com/docs/MTURK_BP.pdf (2011).

Amazon.com, I. Amazon mechanical turk requester best practices guide.

31

https://mturkpublic.s3.

729

93. Raykar, V. C. et al. Supervised learning from multiple experts: Whom to trust when everyone

730

lies a bit. ICML ’09: Proceedings of the 26th Annual International Conference on Machine Learning:

731

https://doi.org/10.1145/1553374.1553488 889–896 (2009).

732

94. Raykar, V. C. et al. Learning from crowds. Journal of Machine Learning Research 11, 1297–1322 (2010).

32

733

Acknowledgements

734

We deeply thank the very large number of research assistants who coded this data. Their affiliations and

735

vita are listed in Appendix C in the supplementary materials. Our research assistants include:

736

Abdelaziz Ibn Abdelouahab, Abhyudaya Tyagi, Adriana Poppe, Advait Arya, Alette Mengerink, Alexander

737

Pachanov, Alexandra Michaelsen, Alisa Udodik, Amadeus Albrecht, Amanda Panella, Ana Acero, Anabella

738

McElroy, Anastasia Steinbrunner, Andreas Duncan, Andres Lopez Schrader, Anelia Petrova, Angad Jo-

739

har, Angela Herz, Angeline Kanyangi, Anke Horn, Anna Sophia Körner, Annika Kaiser, Anoushka Thakre,

740

Antonia Pérez, Ariana Barrenechea, Arianna Schouten, Avery Edelman, Aysina Maria, Babrik Kushwaha,

741

Barbora Bromová, Beatrice Di Giulio, Beatrice von Braunschweig, Bianca Grizhar, Borja Arrue-Astrain,

742

Brahim Ouerghi, Brian Chesney Quartey, Bruno Ciccarini, Calvin Kaleel, Cara Kim, Caress Schenk, Carl

743

Philip Dybwad, Carlos Velez, Carly Kimmett, Carmen Alija, Caroline Beale, Charlotte Vorbauer, Cheng-Hao

744

Shen, Chloë Fraser, Cornelia Marie Dybwad, Cory Martin, Csilla Horvath, Dan Downes, Dan Wu, Daniel

745

Boey, Daniel Martínek, Dariga Abilova, Davit Jintcharadzé, Deborah Agboola, Dick Paul Ouko, Diego

746

Calvo, Dominik Juling, Donia Kamel, Dorian Quelle, Dotrus Wilstic, Dovile Jankunaite, Dr Michelle King-

747

Okoye, Dylan Ollivier, Eduardo Landaeta, Elaine Lin, Elfriede Derrer-Merk, Elisa Seith, Elizabeth (Lizzie)

748

Jones, Ella Pettersen, Elliot Weir, Emma Hutchinson, Esther Ollivier, Eugene Kwizera, Fabienne Lind, Fabio

749

Kadner, Fadhilah Fitri Primandari, Farah Sadek, Feifei Wang, Felix Willuweit, Fernanda Werneck, Francis

750

Yoon, Frank Yuxuan Sun, Franziska Nguyen, Frederic Denker, Gloria Mutheu, Godfrey Katiambo, Griffyne

751

Makaoko, Ha-Neul Yu, Hafsa Ahmed, Hajar Chams Eddine, Helene Paul, Helwan Felappi, Heman Asibuo,

752

Henry Okwatch, Ilona Koch, Imogen Rickert, Ines Böhret, Ingeborg Sæle Helland, Ingrid Ravnanger, Isabela

753

Russo, Isabelle Smith, Ismail Jamai Ait Hmitti, Jack Kubinec, Jakob Berg, Jane Murutu, Janet Li, Janice

754

Klaiber, Janne Luise Piper, Jasmina Sowa, Jean von Agris, Jennifer Noguera Barrera, Jessica Johansson,

755

Jiho Yoo, Joana Lencastre Morais, Joel Gräff, Josef Montag, Jule Scholten, Julia Dröge, Julia Nassl, Julia

756

Smakman, Julia Wießmann, Kadriye Nisa Başkan, Karina Lisboa Båsund, Karlotta Schultz, Katharina Klau-

757

nig, Kayla Schwoerer, Khoa Tran, Klea Vogli, Kojo Vandyck, Konstanze Schönfeld, Laura Cadena, Laura

758

Williamson, Laureen Hannig, Laurent Frick, Lea Clara Frömchen-Zwick, Lea Wiedmann, Lena Kolb, Leon

759

Kohrt, Leonie Imberger, Li Cheng, Lilli Tabea Albrecht, Lily Zandstra, Lincoln Dow, Linlin Chen, Luise

760

Modrakowski, Lya Cuéllar, Magdalena Strebling, Maheen Zahra, Maira Sheikh, Maisa Nasirova, Maite Spel,

761

Malina Winking, Mamle Akosua Kwao, Mara Förster, Marianne Sievers, Marius Deierl, Marlies Hofmann,

762

Mary Nussbaumer, Maryam AlHammadi, Mascha Hotopp, Mats Jensen, Matthew Cottrell, Matthew Har-

763

greaves, Matthew Tan, Maximilian Dirks, Maya Rollberg, Maya Sugden, Mehdi Bhouri, Michaela Balluff,

764

Milan Chen, Milos Moskovljevic, Miranda Tessore Janowski, Miriam Witte, Mirjam Muller, Mona Horn,

765

Muhammad Masood, Muhannad Alramlawi, Museera Moghis, Mustafa Nasery, Nadja Grossenbacher, Na-

33

766

talia Filkina-Spreizer, Nathan Ruhde, Nicolas Göller, Nicole Oubre, Nida Hasan, Niklas Illenseer, Nikolina

767

Klatt, Nivedita Darshini Bholah, Noah Fröhlich, Noelle Kubinec, Noor Altunaiji, Océane Mauffrey, Oketch

768

Juliet Anyango, Oliver Pollex, Oliver Weber, Olzhas Gibatov, Omer Syed, Ongun Durhan, Oscar Courtier,

769

Pablo Robles, Paula Germana, Philipp Weber, Pia Bansagi, Racha Hanine, Rachel Dada, Rahman Demirkol,

770

Raquel Karl, Rebecca Beigel, Ricardo Buitrago, Richmond Silvanus Baye, Robin Fischer, Rosana Fayazzadh,

771

Saif Khan, Salma Soliman, Samantha Law, Samantha Reinard, Sana Moghis, Sarah Edmonds, Sarah Sleigh,

772

Sau Kan Chan, Saw Eh Doh Soe, Sean-Michael Pigeon, Seung-A Paik, Shalini Corea, Shruti Shukla, Simon

773

Hüttemann, Sonja Müller, Sophia Tomany, Stefanie Mallow, Stella Dold, Su Ülkenli, Surendra Belbase, Sym-

774

run Razaque, Tanja Matheis, Tara Goodsir, Tasia Wagner, Temur Davronov, Tess de Rooij, Tess Martin,

775

Tilda Nilsson Gige, Tom Seiler, Tristan Brömsen, Ugochukwu Okoye, Ursela Barteczko, Vellah Kedogo Kig-

776

wiru, Veronica Velasquez Mesa, Veronika Bartáková, Victor Abuor, Victoria Atanasov, Vida Han, Vinayak

777

Rajesekhar, Winrose Njuguna, Xian Jin, Yifei Zhu, Yoes C. Kenawas, Zhandos Ybrayev.

778

779

We also thank Brandon Rose and Jataware for making the news database available to this project. We thank

780

Tim Büthe, the Chair for International Relations, the Hochschule für Politik at the Technical University of

781

Munich (TUM), as well as the TUM School of Governance, and the TUM School of Management for the many

782

ways they have supported this project, including with funding. We further thank New York University Abu

783

Dhabi for funding in support of this endeavor. Moreover, we appreciate the support by Slack Technologies

784

and RStudio Inc. who provided access to their technical infrastructure.

785

Competing interests

786

The authors declare no competing interests.

787

Figure Legends

788

• Figure 1: Cumulative Incidence of Policy Event Types Over Time.

789

• Figure 2: Network Map of Bans on Inbound Flights by European Countries as of March 15, 2020.

790

• Figure 3: CoronaNet Time-Varying Index of National Policy Activity of Measures Opposing COVID-19

791

Pandemic. Estimates are derived from Stan, a Markov Chain Monte Carlo sampler. Median posterior

792

estimates are shown. Plot A shows the full distribution of countries, while plot B shows each month

793

separately with the top 3 countries for that month in terms of increases in activity scores from start

794

of the month to the end of the month.

34

795

796

797

798

• Figure 4: Comparison of Cross-sectional Estimates of Policy Activity Scores to the Random-Walk Time
Series Estimates.
• Figure 5: Country-level Variance (Over-time Change) Parameters from Policy Activity Index Estimation.

799

• Extended Data Figure 1: Convergence Diagnostics for Random-Walk HMC Fit. Plot A shows the

800

distribution of split-Rhat values for all 40,000 parameters in the model, revealing most parameters are

801

close to 1, which indicates strong convergence. The effective number of samples for parameters in plot

802

B is also very high, often exceeding the total number of posterior draws. Plots C and D show strong

803

mixing across chains for the intercept and over-time parameter for the United States for January 30th.

35

804

Tables
Table 1: Descriptive Information about the CoronaNet Government Response Dataset
Type

Total Number

Number of

Average

% With

of Policies

Countries

Number of

Mandatory

Targeted

Enforcement

Countries
Health Resources

2342

148

67

54

Restriction of

1855

135

1

92

Closure of Schools

1583

169

1

90

Quarantine/Lockdown

1102

161

103

87

External Border

1064

186

163

83

Other

819

132

26

60

Public Awareness

609

137

1

23

575

159

1

87

Social Distancing

518

127

1

71

Restriction of

373

99

1

80

345

104

1

100

Declaration of Emergency

330

114

1

100

Health Monitoring

318

110

83

71

Internal Border

313

111

1

89

Health Testing

283

98

61

67

Curfew

172

91

1

95

Non-Essential Businesses

Restrictions

Measures
Restrictions of Mass
Gatherings

Non-Essential
Government Services
New Task Force, Bureau
or Administrative
Configuration

Restrictions

36

Table 2: Discrimination of Item Parameters (Policies) in Policy Activity
Index

Policy

5% Low Estimate

Median Estimate

95% High
Estimate

Closure of Shopping Malls

1.5

1.7

2.0

Restriction Commercial

1.5

1.7

1.9

Closure of Retail Stores

1.3

1.5

1.8

Closure of Personal

1.2

1.4

1.6

Primary School Closure

1.1

1.3

1.4

High School Closure

1.1

1.2

1.4

Higher Ed Closure

1.0

1.1

1.2

Restriction Other Business

0.9

1.1

1.2

Sanitizer Policies

0.9

1.0

1.2

Closure of Restaurants

1.0

1.0

1.0

Quarantine At Home

1.0

1.0

1.0

Pre-school Closure

0.9

1.0

1.1

Mobilization of Volunteers

0.8

0.9

1.1

Other Health Staff

0.8

0.9

1.0

Restriction of Mass

0.8

0.9

1.0

Test Production

0.7

0.8

1.0

Mobilization of Doctors

0.7

0.8

1.0

Mobilization of Nurses

0.7

0.8

1.0

Internal Border Restrictions

0.7

0.8

0.9

Limited Quarantine

0.6

0.8

1.0

Other Health Resources

0.7

0.8

0.9

Social Distancing

0.7

0.8

0.9

Other Health Facilities

0.6

0.8

0.9

Other Health Resources

0.6

0.8

0.9

Mobilization of Ventilators

0.6

0.8

0.9

Masks Policies

0.6

0.7

0.9

Business

Grooming

Gatherings

37

Restriction Government

0.6

0.7

0.8

Other Health Facilities

0.5

0.7

0.8

PPE Mobilization

0.5

0.6

0.8

External Border Closure

0.6

0.6

0.7

Supporting Hospitals

0.5

0.6

0.7

Other Quarantine

0.5

0.6

0.7

Quarantine in Hotel

0.5

0.6

0.7

Curfew

0.5

0.5

0.6

Biomedical Research

0.4

0.5

0.7

Declaration of Emergency

0.4

0.5

0.6

Temporary Medical Units

0.3

0.5

0.6

Quarantine/Lockdown

0.3

0.4

0.6

Building Quarantine

0.3

0.4

0.5

Public Testing Mobilization

0.3

0.4

0.5

Quarantine in Govt.

0.3

0.4

0.5

Border Health Certificates

0.3

0.4

0.5

Monitoring Population

0.3

0.4

0.4

Public Awareness Measures

0.3

0.3

0.4

Suspend Visa Issuance

0.3

0.3

0.4

Mobilization of Testing

0.3

0.3

0.4

Task Force

0.2

0.3

0.4

Other Border Restriction

0.0

0.2

0.5

Border Health Screenings

0.2

0.2

0.3

Travel History Required

0.1

0.1

0.2

Services

Facilities

Facility

Health

38

Table 3: Inter-Coder Reliability Measures for On-Going Validation
Policy

(n)

Percentage Agreement

Cohen’s Kappa (k)

Restrictions of Mass Gatherings

21

95.2

0.95

Closure of Schools

14

92.9

0.92

Restriction of Non-Essential Businesses

19

89.5

0.89

External Border Restrictions

52

84.6

0.83

Curfew

6

83.4

0.82

Internal Border Restrictions

11

81.8

0.80

Declaration of National Emergency

19

73.7

0.71

Quarantine/Lockdown

28

67.9

0.65

Health Measures

52

65.4

0.63

Restriction of Non-Essential Government Services

16

62.5

0.59

New Task Force, Bureau or Administrative Configuration

9

55.6

0.52

Public Awareness Measures

15

53.3

0.49

Social Distancing

14

42.9

0.38

Summary Inter-coder Reliability Scores
Percentage Agreement

0.74

Cohen’s Kappa

0.72

Krippendorff’s alpha

0.71

Scott’s PI – Estimate (SE)

0.71 (0.03)

39

