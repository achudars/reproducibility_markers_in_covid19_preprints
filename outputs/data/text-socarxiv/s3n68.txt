Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021

Pp.37-54

DOI: https://dx.doi.org/10.24093/awej/covid.3
E-Assessment at Jordan’s Universities in the Time of the COVID-19 Lockdown: Challenges and
Solutions
Rami A. Sa'di
Department of English, Community College of Al-Kharj
Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia
Corresponding Author: slmss2002@yahoo.co.uk
Ahmad Abdelraziq
Department of English, Princess Sumaya University for Technology,
Amman, Jordan
Talha A. Sharadgah
Department of English, Community College of Al-Kharj
Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia

Received: 12/24/2020

Accepted: 3/28/2021

Published:4/26/2021

Abstract
This study aims to delineate the observations of instructors at Princess Sumaya University for Technology
(PSUT) in Jordan with regards to online assessment of their students in the time of the Coronavirus
lockdown. Specifically, the study attempts to find out whether universities are prepared for online
assessment during the lockdown and to probe feasible solutions to the challenges that hinder proper
assessment in a virtual learning environment (VLE). As the challenges are determined, the study suggests
a number of practical solutions. Data on faculty’s observations were obtained by means of an online
survey. Eighty-three faculty members participated in this study. The findings showed that universities
swiftly shifted to e-classes during the lockdown but that they were not adequately primed for an
appropriate assessment in an online environment. The findings further showed that instructors were
skeptical about the efficiency of remote assessment of their students. In addition, faculty members
believed there was still a long way to go with regards to (1) the unavailability of reliable software to
preclude academic dishonesty; (2) some faculty being unable to assess their students in VLE as it was
their first experience; and (3) formative assessment not having been given enough attention. It is
concluded that universities should have an exigency strategy for any sudden future lockdowns. This
strategy includes, among other things, intensive e-teaching and e-testing training for faculty, high-tech
invigilation and plagiarism software, reliable e-learning platforms with sufficient Internet bandwidth,
setting up an e-assessment council at the university level.
Keywords: e-assessment, remote assessment, e-test, COVID-19, Jordan, Princess Sumaya University for
Technology, challenges and solutions
Cite as: Sa'di,R.A., Abdelraziq, A., & Talha A. Sharadgah, T. A. (2021). E-Assessment at Jordan’s
Universities in the Time of the COVID-19 Lockdown: Challenges and Solutions. Arab World English
Journal (AWEJ) Special Issue on Covid 19 Challenges (1) 37-54.
DOI: https://dx.doi.org/10.24093/awej/covid.3

37

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Introduction
It goes without saying that the Coronavirus disease 2019 (COVID-19) pandemic has
taken the world by surprise and has brought life in some parts of the world to a complete fullstop. Ever since the first confirmed Coronavirus case in China in December 2019, the virus has
been steadily spreading globally, disrupting life in many ways and causing consternation and
confusion. According to the World Health Organization, the virus has so far claimed more than a
million lives, and it is unlikely to see this virus go anytime in the near future.
In Jordan, like anywhere else in the world, the government tried to respond as swiftly and
sagaciously as possible, and so a number of precautionary measures were put in place. The most
obvious countermeasure to stifle or at least to limit the spread of the virus, which was adopted
almost everywhere in the world, was lockdown. This lockdown was often partial, but sometimes
a complete lockdown had to be enforced in some cases in some parts of Jordan. Most
government institutions and businesses in the country were forced to close temporarily.
Educational institutions too had to close, and learning had to be resumed online, whereby
teachers and students worked from home; they met online via whatever technological amenities
the institutions or the individuals could afford. This way, Jordan made sure that education was
not going to be interrupted due to the sudden lockdown. A number of online educational portals
were activated by the Ministry of Education. All educational institutions nation-wide, schools
and universities, were urged to take advantage of any e-platforms they had access to. Among the
various platforms that were launched and started to become familiar names amongst students and
teachers were Blackboard, ZOOM, Classera, Moodle, and eFront. Javaid et al. (2020) are
proponents of digital platforms for online learning, and they posit that these platforms are going
to be enormously beneficial in supporting virtual learning environments (VLEs) and assuaging
the negative impact of the pandemic on the educational process.
Because of the lockdown, the Ministry of Higher Education in Jordan set out guidelines
for universities with regards to the preparations for testing and assessment. Universities have
adopted a number of assessment policies, and with an eye on the nature of the courses and topics,
they used online assessment as a replacement for face-to-face (FTF) assessments. In order to
make sure that faculty members, as well as students, were prepared for a smooth and trouble-free
transition to e-learning, universities nation-wide held online workshops for faculty and
workshops for the students geared towards acquainting them with the fundamentals of virtual
teaching/learning. Such workshops were deemed indispensable as it was rightly assumed that the
vast majority of faculty and students had never had a virtual learning experience before.
Owing to the abrupt and unprecedented shift to virtual learning, the Ministry of Higher
Education strove to recommend a number of assessment methods that were propitious to the
new-fangled nature of learning/teaching that was taking place in the country. Among those
recommendations were the following: (a) formative assessment throughout the whole duration of
the e-learning; (b) final online testing; (c) periodic quizzes; (d) open-book exams; (e) viva voces
via the various platforms of e-learning; (f) presentations; (g) student active involvement in the
discussions in their online sessions; (h) homework; and (i) various projects. In compliance with
directives from the Ministry of Health and the Ministry of Higher Education, PSUT – from
which the present study elicited responses from 83 participants – made it mandatory that all
Arab World English Journal
ISSN: 2229-9327

www.awej.org

38

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

formative and summative evaluation be carried out remotely to avert physical contact and so to
protect the lives of faculty and students.
On various occasions, the Ministry of Higher Education issued resolutions aimed at
tackling the challenges of e-learning; among those challenges was the procedure for the final
exams. Among those mechanisms was to allow students to drop out of a course or any number of
courses. This unique legislation meant students were not coerced into e-tests against their will.
No academic penalty was entailed upon withdrawal. This way, students had enough time to
reflect on their academic situation so as to make the proper decision in due course. A second
recommendation was to allocate more grades to the formative assessment and fewer grades to the
final exams. This way, the most evaluation would be based on coursework such as assignments
and active student involvement in class. Another recommendation was to analyze students’
grades for previous semesters electronically and to create a matrix that would calculate the
students’ GPAs and produce automated grades for this ‘extraordinary’ period, at least in the
second semester of the academic year 2019/2020, when FTF tuition was first interrupted and
replaced by e-learning. Yet another policy was to alter the grading systems from the ‘percent
system’ to the ‘pass/fail’ policy in order that the results of the ‘lockdown’ courses would have no
influence on the students’ GPAs.
The present study is significantly important because it focuses on the challenges that
universities are facing as they strive to prepare and implement the two types of assessment:
formative and summative. Moreover, the study suggests down-to-earth solutions to sort out the
challenges and to make sure that e-assessments are implemented effectively. To achieve this, the
current study delineates the perceptions of faculty members at PSUT regarding whether
universities are prepared for e-assessment in the time of the Coronavirus pandemic. Additionally,
the study investigates signs of tangible challenges that deter proper employment of formative and
summative assessment, and also provides tentative but realistic solutions that may help make the
VLE learning experience a more agreeable one. With such goals, the current study attempted to
address two research questions:
RQ1: According to faculty member perceptions, to what extent are IHE prepared for eassessment?
RQ2: According to faculty members, what are the most feasible solutions to challenges to eassessment?
Literature Review
Princess Sumaya University for Technology (PSUT) exerted every effort to ensure that
classes would go on unimpeded during the lockdown, and the administrators and faculty worked
indefatigably to cope with this exceptional period. However, they were faced with a tough
challenge that at times seemed insurmountable: how to properly assess students online. Kearns
(2012) posited that “an area of focus that deserves special attention is the assessment of student
learning” (p. 198). Vlachou (2018) stated that “classroom assessment is a process in which
teachers and students gather evidence of student learning through several assessment practices”
(p. 2). Hopfenbeck (2018) pointed out that certain validity and reliability procedures must be
implemented in the classroom to ensure that student assessment is properly achieved but that in
Arab World English Journal
ISSN: 2229-9327

www.awej.org

39

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

VLEs assessment poses genuine concerns. These concerns are innumerable. For example, in the
absence of direct invigilation, students may be tempted to cheat in a way or another.
Ayachi‐Ghanouchi, Cheniti‐Belcadhi, and Lewis (2013) described two main types of
assessment: “formative assessment and summative” assessment (p. 4). Formative assessment
aims to measure students’ ongoing performance throughout an entire course of study (Wuttke,
Hamann, & Henke, 2015). Formative assessment helps provide nonstop feedback throughout the
course (Lozano & Segura, 2016) since it reflects the ups and downs of a student’s performance,
which enables the instructor to fine-tune his/her teaching and meet the student’s specific needs
(Ertle, Rosenfeld, Presser, & Goldstein, 2016). Formative assessment can be conducted in any of
a multiplicity of forms at any point after any chapter or portion of the course has been taught. It
can be a quiz, an oral test, or drills. In fact, formative assessment is intended to (1) monitor goals
in the short-run (Dolin, Black, Harlen, & Tiberghien, 2018); (2) check what has been learned and
what has not (Heritage, 2007); (3) assist learners in ameliorating their overall learning experience
(Alshenqeeti, 2020); (4) help educators diagnose their teaching style (Hasim & Barnard, 2018);
(5) motivate learners to revise and learn (Leenknecht et al., 2020).
According to Faulconer, Griffith, & Frank (2019), summative assessment “occurs at the
end of the learning process” (p. 1). It results “in a ranking, a mark, a grade or a degree” (Jones,
1996, p. 134). Exams provide teachers with feedback on the learner’s progress, and this
“feedback is an essential component to the development of the recipient” (Sarkany & Deitte,
2017, p. 1). The role of summative assessment is to (1) give feedback in the long term
(Chapman, Bynog, & Yocom, 2013); (2) assign grades to students that reflect to what extent they
have achieved the intended objectives (Sangwin, 2017); (3) enable instructors to decide and
enact penalties (Rolfe & McPherson, 1995); (4) allow educational institutions to make decisions
regarding student academic status (Das et al., 2017).
Nowadays, because of the lockdown imposed in many parts of the world, institutions of
higher education (IHE) have resorted to online learning as a temporary replacement of traditional
FTF learning, which means assessment too will have to be conducted online. This will present
unprecedented assessment challenges (Burgess & Sievertsen, 2020). Owing to the lockdown,
Burke and Dempsey (2020) posit that “distance learning is a poor substitute for real interaction,”
and formative assessment is best carried out via direct observation in the classroom (p. 37).
Unsurprisingly, most of the challenges facing e-assessment are due to the absence of direct FTF
contact (Kearns, 2012). Following are some of the e-assessment issues cited in the literature: (1)
educators being unable to thwart cheating or any other act of academic dishonesty (Xiong &
Suen, 2018); (2) verification of the identity of the learner (Baró, Bernaus, Baneres, & GuerreroRoldán, 2020); (3) reliability and validity of assessment in VLE (Akimov & Malin, 2020); (4)
limitations on question types in VLE, since questions are mostly T/F, multiple-choice, match the
items, and fill in the gaps (Marriott, 2009); (5) academic integrity issues (Kearns, 2012); (6)
invigilation of online test sessions (Khan & Jawaid, 2020); (7) instructors’ e-teaching skills and
time management (Hettiarachchi, Balasooriya, Mor, & Huertas, 2016).
The shift “towards institution-wide adoption of online assessment is attracting
considerable attention among higher education institutions” (Mayhew, 2018, p. 1). However,
Crisp et al. (2011) pointed out that although online tools and applications galore are available
Arab World English Journal
ISSN: 2229-9327

www.awej.org

40

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

these days, the efficacy of online assessment replacing direct classroom assessment is debatable.
Xiong and Suen (2018) stated that it may be a tenable idea to shift to VLE teaching but to keep
the traditional assessment as it is because “the need for a high-quality, trustworthy and effective
assessment approach remains a major gap in the burgeoning open online learning world” (p.
257). Khan and Jawaid (2020) also indicated that the pandemic has compelled IHE to transform
their teaching from traditional FTF classes to VLE, and that this change “will bring long-lasting
effects on teaching and learning, assessment procedures and methods” (p. 3). According to
Sabzwari (2020), FTF assessment ought to be maintained “to ensure integrity and security of
assessment;” therefore, IHE need to “consider creating larger venues that allow physical
distancing or plan a greater number of venues to achieve the same goal” (p. 3). Naturally then,
faculty members have been confronting unprecedented challenges that reflect their preparedness
or lack of it for this abrupt shift (Kebritchi, Lipschuetz, & Santiague, 2017; Phillip & Cain,
2015).
The studies so far on the influence of the COVID-19 pandemic and the ensuing eteaching and e-learning have been innumerable. However, little research has been carried out to
ascertain to what extent IHE are prepared for e-assessment, or to ascertain how faculty members
are coping with e-assessment. A rigorous study is badly needed to find out what may best be
done to ensure that e-assessment is as reliable as the traditional FTF assessment. Hussein,
Daoud, Alrabaiah, and Badawi (2020) firmly maintained that online learning was a great
nonpharmaceutical way to curb the spread of the COVID-19 disease, but that “it has also put all
those involved in the educational process under substantial pressure. This is particularly true
because many instructors and learners who had never had adequate (if any) experience with
online learning found themselves obliged to do so with minimal support” (p. 2).
Methods
Before setting about this piece of research, the researchers procured ethics approval from
the research ethics panel in PSUT. The researchers then made an extensive review of relevant
literature on the topic of e-learning and challenges to e-assessment. Enlightened by this review,
they created a survey, using Google Forms, that aimed at eliciting faculty members’ perceptions
of e-assessment. To make sure that no items on the e-survey would be skipped, whether
intentionally or inadvertently, the researchers assigned the electronic feature ‘*Required’ to all
items. This tactic eliminated all room for ‘missing data’ in the participants’ responses. The
participants were reassured that their responses were going to be used for academic purposes
only and that their data would remain confidential and anonymous. The elicited data came from
83 participants, who represented a simple random sample.
The data were then coded and analyzed using the “IBM SPSS Statistics 26”. A statistical
summary of the results was reported using descriptive statistics, namely means (M) and
percentages. Responses are presented in the form of a continuum of variables because the esurvey took the form of a Likert-type scale of five options that ranged from strongly agree (5) to
strongly disagree (1), which had equal-appearing intervals. Analysis of the data gave the
researchers insight into the most likely challenges that loomed over e-assessment at PSUT during
the COVID-19 lockdown and shed light on a number of feasible solutions to those challenges.

Arab World English Journal
ISSN: 2229-9327

www.awej.org

41

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Participants
Instructors from PSUT, Jordan, participated in this study. They represented a simple
random sample because every member of the PSUT faculty population had an equal chance of
providing data for the study. An e-survey was created, and its link was shared with the faculty
members. 83 faculty responded. Data were collected from 2 to 30 Nov 2020. No demographic
data about the participants was collected in this research inasmuch as the respondents were more
or less comparable in that they all worked at the same university and also due to the fact that the
main objective of this study was solely the collection of data about challenges facing eassessment at universities in the time of the lockdown. PSUT gave the researchers the
opportunity to contact its faculty for use as a sample, based on factors such as the willingness of
faculty to take part in the study, the University having chosen to do e-assessment in exams, and
because one of the researchers was already affiliated with PSUT, which gave him easy access to
contact faculty there.
Instruments
The survey was key to this study, and to create it in such a way that it would serve its
purpose, the researchers made an extensive review of relevant literature, and they also benefited
from their own experience as an indispensable source of information. Taking advantage of
Google Forms, the researchers created the e-survey. The e-survey was intended for the collection
of data on the challenges facing e-assessment, both formative and summative, at IHE from the
faculty’s perspectives. The e-survey was divided into two parts. The first part had twenty closedresponse questions with a focus on these categories: (1) to what extent universities were prepared
for e-assessment, (2) to what extent instructors were prepared for e-assessment, (3) challenges
facing the validity and reliability of e-assessment, and (4) technology-related issues that
presented challenges to e-assessment. The second part provided an unrestrictive question meant
to elicit from faculty whatever further ideas on challenges not mentioned in the first part. The
participants were required to carefully read the questions and then to click the option that
accurately conveyed their views, on a five-level Likert-scale, with options ranging from strongly
disagree (1) to strongly agree (5).
Validity and Reliability
A panel of English language experts reviewed the items of the survey for the purpose of
assessing its validity. The panel gave their expert feedback, which helped improve the survey.
Working independently of each other, the experts assessed the survey for clarity, correctness and
relevance to the study. The researchers also carried out a pilot test on a number of instructors (n
= 12). Those instructors did not participate in the e-survey. The pilot study was done for the
purpose of achieving maximum face validity and to guarantee reliability. The aim was to
ascertain if the survey was suitable in order to find out if any additional alterations were needed
before sharing the survey with the faculty members. In light of findings from the pilot study, the
final version of the survey was thus made. Making use of Cronbach’s alpha, the researchers were
able to prove the internal reliability of the survey questions (.871). This value was proof of quite
a high degree of reliability.
Findings
The researchers opted to group the findings into four groups: (a) to what extent
universities were prepared for e-assessment, (b) to what extent instructors were prepared for eArab World English Journal
ISSN: 2229-9327

www.awej.org

42

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

assessment, (c) challenges that are likely to mar the validity and reliability of e-assessment, and
(d) technology-related issues that presented challenges to e-assessment. The first two categories
answer RQ1, and the third and fourth categories answer RQ2. Despite a likely overlap amongst
the categories sometimes, these categories are propitious for a convenient classification of the
findings.
This study aimed first and foremost to find out the perceptions of faculty members with
regards to how prepared or otherwise IHE were for e-assessment during the COVID-19
lockdown. Table one lists all the survey questions and shows Means, Standard Deviations, and
percentages of faculty members’ perceptions elicited via the survey. Analysis of the survey
responses shows that, for example, 64.7% of instructors believed that IHE were not prepared for
e-assessment because the transition to e-learning was sudden and unexpected (M = 3.76). It was
also found out that 78% of faculty believed that universities hesitated time and again in their
endeavor to arrive at a decision with regards to shifting to e-learning (M = 4.0). Moreover, the
majority of faculty (90.1%) agreed that PSUT ran a good number of training workshops aimed at
acquainting faculty with e-learning (M = 4.4).
Table 1.
Means, Standard Deviation, and percentages of faculty members’ perceptions.
Mean

Std.
Deviation

%

IHE were not prepared for e-assessment because the transition to e-learning was
sudden and unexpected.

3.76

1.313

64.7

Universities hesitated time and again in their endeavor to arrive at a decision with
regards to shifting to e-learning.

4.0

1.160

78

3.92

1.135

68.8

4.54

.960

89.1

4.24

1.196

78

3.96

1.123

80.1

3.71

1.172

70.5

4.4

.820

90.1

3.61

1.313

60.7

3.91

1.051

74.4

3.26

1.275

52.1

Items

It was impossible to prevent students from cheating.
The scores obtained by students in online tests were significantly higher than those
they would have obtained in FTF tests on campus.
Online tests were propitious for cheating.
It was a good idea to assign less marks to the final / summative assessment because it
was believed that e-assessment, at least for the time being, was not highly reliable or
accurate.
Instructors were not sufficiently acquainted with e-assessment and its various
features.
PSUT ran a good number of training workshops aimed at acquainting faculty with elearning.
Online testing took a very long time to create.
Neither the instructors nor the academic programs were capable of assessing the
students truthfully and justly.
Moodle is a deficient platform that does not welcome all types of test questions.

Arab World English Journal
ISSN: 2229-9327

www.awej.org

43

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Some technical issues with the Moodle software hamper the e-assessment experience
because of some features of Moodle like the limitations on testing options.

The Moodle interface does not provide comfortable experience for students taking
exams, and in general it is not user-friendly.
There was a substantial amount of online traffic on PSUT’s server while final exams
were being conducted, which slowed down student’s work on their exams and thus
put a damper on the overall online assessment experience.
There was a more pressing need for strict regulations and procedure in summative
assessment than in formative assessment.

The students’ achievement in e-testing was the same as their achievements in FTF
testing.

3.77

1.005

63

2.94

.876

20.1

3.54

1.120

74.2

4.01

.735

83.7

1.82

1.082

14.2

3.81

1.236

66.8

3.72

1.142

65

3.1

1.095

35.1

3.93

1.136

83.9

The e-assessment was grossly unfair to the students because some of them had
powerful, reliable internet connection while others did not.

At the outset of each electronic test, a great deal of time was wasted in pre-test
procedures such as communicating with students, making sure they were ready,
giving them instructions, repeating the instructions again and again in a way that
confused the testing process.
Sometimes Moodle behaved so erratically that I was muddled and unsure what to do.
For example, in some tests it scored some students’ answers and overlooked others
for no explicit reasons, or it sometimes left the test open for some students but closed
for others even when test time was up.
Most of the questions in the final exams were of the objective type like multiplechoice, gap-filling, T/F, and item matching.

Discussion
Institutions of Higher Education and E-assessment
Results of this study show that IHE were not quite prepared to carry out reliable eassessment during this exceptional period. IHE did not have any straightforward, unequivocal
mechanisms for e-assessment, and that is why universities hesitated and set forth various
decisions, some of which were even conflicting, during the lockdown period. One of the
participants mentioned in the open-ended question that the most irksome experience s/he had
with e-learning was the incessant resolutions made by the university, which took faculty
members ‘out of their depth.’ Those challenges were in line with the concerns posited by
Hopfenbeck (2018), as mentioned earlier in the literature review. Oncu and Cakir (2011) state
that any university that has delivered education exclusively in the traditional classrooms is
Arab World English Journal
ISSN: 2229-9327

www.awej.org

44

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

unlikely to have a clear vision for VLE learning, and this definitely casts doubt on the reliability,
validity and security of its e-assessment.
Faculty Members and E-assessment
The majority of faculty members agreed that their university ran a good number of
orientation workshops aimed at preparing them for teaching in a VLE. However, most of them
acknowledged that those workshops aimed to prepare them to conduct online classes and to carry
out summative assessment only, using Moodle, but did not focus on connecting the summative
assessment with the intended course outcomes. This finding confirms the position of Burke and
Dempsey (2020), cited earlier in the literature, who did not believe VLE assessment could
replace physical classroom FTF interaction. Thuy (2019) states that, as the e-learning semester
draws to a close, it is incumbent upon universities to assess students’ academic performance and
to scrutinize their learning outcomes. In fact, it is insufficient for IHE to refer to the numbers of
learners who completed their courses and to consider those statistics as evidence that eassessment has been a successful experience. Xiong and Suen (2018) posit that e-assessment is
posing new-fangled challenges to educators with regards to how this type of assessment is going
to meet the different needs of the learners.
As already mentioned, training workshops focused exclusively on summative assessment,
and formative assessment was largely relegated by the universities. Relegation of the importance
of formative assessment in VLEs does not sit well with the literature on the inalienable
importance of both types of assessment (e.g., Ayachi‐Ghanouchi et al., 2013); Wuttke et al.,
2015; Ertle et al., 2016). Heinrich (2006) indicates that in e-assessment faculty are excessively
concerned with summative assessment only. Ullah, Xiao, Lilley, and Barker (2012) state that
formative assessment is not used to calculate the ultimate grades for students. In stark contrast
with Heinrich (2006) and Ullah et al. (2012), Thuy (2019) points out that the technology used at
Hanoi Open University is auspicious for developing formative evaluation only inasmuch as the
online system used there is not conducive to summative tests. Interestingly, Thuy (2019) affirms
that Hanoi Open University is just beginning to take advantage of assisted technologies for eassessment and that it is going to take some time before faculty are capable of using this
technology to carry out summative e-assessment successfully.
Many of the participants pointed out that not all professors had enough experience in
creating tests for e-assessment notwithstanding the sheer bulk of training during the lockdown. A
respondent explained that the IT department at the University was sloppy in spreading knowhow about using Moodle for e-assessment. However, another participant believed that the
amount of training s/he had received on e-assessment was more than enough.
Assessment Methods and Challenges Confronting Validity and Reliability
Although the University made it clear to faculty that the final exam was not going to be
the ‘be-all-and-end-all’ of assessment during the lockdown, most faculty members believed that
they were unable to ‘e-assess’ the students correctly and equitably. A number of shortcomings
made them so believe. For instance, most faculty believed that the vast majority of students were
able to cheat in the final exams in defiance of all the e-invigilation measures, and that many
students acquired scores that they did not deserve. Tereseviciene, Trepule, Dauksiene,
Tamoliune, and Costa (2020) assert that IHE should implement various techniques, such as
Arab World English Journal
ISSN: 2229-9327

www.awej.org

45

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

software to verify student identity, to guarantee the validity and reliability of e-assessment. For
the time being, cheating was believed to be rife and unstoppable. At present, if there develops a
rift between students’ GPAs and their actual abilities, the credibility of IHE graduates in the
marketplace is going to be adversely impacted. As mentioned by Heritage (2007), proper
assessment is an indispensable tool to measure what has been learned and what has not.
The researchers analyzed the students’ grades in their courses they had taken in the
second semester of the academic year 2019-2020, which was the first semester during which
lockdown started, and e-learning was launched and compared them with their grades in previous
semesters prior to the lockdown. It was evident from this analysis that the grades of the latest
‘lockdown’ semester were blatantly incongruent with the students’ grades in all previous
semesters. The later scores were significantly higher. Although this comparison is not necessarily
flawless, it can be used as an indication that e-assessment may not be reliable. Moreover, in
some e-tests where students were given the opportunity to attempt question tests two times, the
second attempt yielded very different results from the first. This could mean students may have
cheated in a way or another.
To prevent academic dishonesty like cheating and the need to verify student identity are
genuine concerns that started to appear in VLE during the pandemic. The literature shows that
amongst the most compelling challenges facing e-assessment is that there is ample room for
plagiarism and other dishonest behavior from some students during the testing (Mellar,
Peytcheva-Forsyth, Kocdar, Karadeniz, & Yovkova, 2018). Because of the sudden and quick
shift to virtual learning during the lockdown, most IHE made use of only uncomplicated security
procedures instead of using intricate high-security software (Hernández, Ortiz, Andaverde, &
Burlak, 2008). A number of studies indicate that for summative assessment, stricter measures are
needed than for formative assessment for obvious reasons (Andreatta & Gruppen, 2009).
Typically, formative assessment is carried out without it being invigilated, since it basically
helps in supplementing education (Xiong & Suen, 2018). However, to ensure the validity of eassessment, there must be a reliable form of invigilation (Xiong & Suen, 2018). As for
plagiarism, at PSUT teachers did not use any plagiarism detection software in the case of
assignments as most deemed it unnecessary to do so, and probably also because such software,
such as iThenticate, is considered by many to be costly to use.
Most assessment tests (84.4% agreed) took up the form of objective questions like MCQ,
gap filling, T/F, and matching items. Such kinds of questions are “generally easier to grade both
by automatic and human means” (Hettiarach-chi et al., 2016, p. 50). Professors can benefit from
the automatic grading feature, and so they can do away with test questions that need to be
marked manually. But it is worth mentioning that this kind of question is usually appropriate for
assessing knowledge at the lower-order level of Bloom’s taxonomy rather than at the higherorder level (Hettiarachchi et al., 2016; Khan & Jawaid, 2020). Much of the literature posits that it
is not possible to cater for cognitive skills at the higher-order level (such as analysis, problemsolving, creative thinking, etc.) by relying on MCQs (Bloor, Sampson, & Gekara, 2014) or
“questions which only need a simple yes or no” (Bearn, Chadwick, Jack, & Sackville, 2002, p.
163).
Technology-Related Challenges
Arab World English Journal
ISSN: 2229-9327

www.awej.org

46

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

As for technological challenges, many studies point out that the use of technology in
education cannot be problem-free (Burgess & Sievertsen, Op. Cit; Burke and Dempsey, Op. Cit;
Brown & Dinecola, 2020; Al Meajel & Sharadgah, 2018). This study describes a number of
challenges in the discussion. In the survey, some respondents agreed but others disagreed about
whether these challenges really are an issue. For instance, some participants agreed that
conducting e-assessment tests is a painstaking process. Dean (2003) posits that this type of
“assessment development involves a multi-step exacting and often frustrating procedure” (p.
896). By contrast, Yao (2020) argues that technology-based assessment, in contrast with
traditional assessment, “is less time-consuming, easier and quicker to be administered and
scored” (p. 124). Some participants remarked on these technical restrictions stating that giving
exams online is a headache because students keep complaining about everything. For example,
some students’ internet connection isn’t powerful enough. Some students use their phones to do
the test, but it seems Moodle works better on computers than on phones. We cannot force all
students to buy laptops, for example.
One serious issue in Moodle is that its automatic grading feature is not always identical to
grading by a person. For one thing, such platforms as Moodle lack human flexibility, which can
sometimes be indispensable in giving students marks for unexpected answers, whereas Moodle
would rule them out right away as wrong answers. On various occasions, professors noted that a
student might provide the correct answer in an open-ended question, but Moodle crosses it out
completely because of a couple of misspellings. In a case like this, human intervention is of
paramount importance for the assessment accurately reflect the students’ performance.
Besides all these challenges mentioned so far, e-assessment did not give equal
opportunity to all students with regards to internet connection, internet reliability and other
technological considerations. In the present study, the majority of participants agreed that the
students’ achievement in e-tests was very different from what they were likely to have done in
pre-lockdown classroom assessment. Azzahra (2020) discovered that this abrupt halt to FTF
education and the shift to e-learning posed intractable problems for students who lived in rural
areas or in impoverished slums. Azzahra also stated that the pandemic triggered in universities
assessment challenges caused by the disparity amongst students in their access to technological
amenities. Because the shift to e-learning was unanticipated, some students were ‘out of their
depth’ as they struggled to cope with the inexorable technical demands of the new-fangled
learning experience (Longhurst et al., 2020). One of the participants pointed out that Zoom
sessions and Moodle assessments posed like an insurmountable citadel at the outset of the elearning experience. The researchers assume that this initial conundrum was a genuine concern at
first owing to the busy online traffic as a number of classes were taking place at the same time.
Solutions
This article has brought to the forefront a good number of e-assessment challenges
brought about by the lockdown and the shift to e-learning. The issues presented here will clearly
become even more of a challenge in the coming semester unless the lockdown is continued, but
since it is next to impossible for now to tell how long more the lockdown will linger on, it should
be assumed that the challenges to e-assessment presented in this paper are likely to continue to
pose a case of uncertainty. Because of this, it is imperative at the moment to take action in order
Arab World English Journal
ISSN: 2229-9327

www.awej.org

47

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

to make sure that universities are capable of conducting an appropriate online assessment (see
Table two).
Table 2.
The challenges faced by instructors and recommended solutions.
Challenge
University readiness

Readiness of educators
(This challenge is
interconnected with all the
others because educators are
at the receiving end of all
challenges)
Cheating

Plagiarism

Summative assessment needs
stricter practices than
formative assessment.

Technical issues with the auto
grading system
IHE server stretched to its
limits due to too much
simultaneous online activity

Arab World English Journal
ISSN: 2229-9327

Solution(s)
• Universities should have an exigency strategy for any sudden future
lockdowns, in order that unambiguous measures are ready in place for eassessment.
• It is essential for universities to devise whatever means are needed to make
sure that the students’ achievement in online testing is the same as their
achievement in FTF tests.
• It is extremely necessary for IHE to provide adequate constant training on
making online tests for the two types of assessments: formative and
summative.
• It is essential to give instructors access to e-test invigilation software.
• In order to prevent cheating, universities should use online invigilation
software (such as Respondus Lockdown Browser) that locks down the testing
environment within a learning management system during the exam (Khan &
Jawaid, 2020).
• IHE could utilize biometrics like face/voice recognition software
(Tereseviciene et al., 2020).
• IHE may make it mandatory to create one test for each one learner (Palloff &
Pratt, 2008).
• IHE may run the exams at real physical locations with invigilators but still
maintain rules of social distancing set by WHO.
• To foil plagiarism, the iThenticate software should be made more accessible to
faculty. Currently, using it can be costly.
• It may also be a good idea to give students free access to iThenticate. This way
the software is not intended to be a “plagiarism detection tool” for punishing
dishonest academic behavior but as a “learning tool used to support learners”
(Mahabeer & Pirtheepal, 2019, p. 3).
• Measures must be taken to ensure similarly accurate reliability and validity for
the two types of assessment, formative and summative, since they are essential
to meet educational goals and objectives.
• All aforementioned solutions that the researchers have put forward for the
purpose of foiling academic dishonesty have to be implemented for both kinds
of assessment.
• The auto grading system is not immaculate. Final grades should be reviewed by
a human examiner prior to final approval.
• There should be a dedicated server for e-tests so that online activity has enough
bandwidth.
• E-tests may be distributed over numerous time slots to avoid running too many
tests simultaneously.

www.awej.org

48

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19
Most final exams made use of
objective questions.

Sa'di, Abdelraziq, & Sharadgah

• IHE ought to conduct workshops on objective and subjective assessment. This
may ensure a comprehensive assessment of both lower and higher-order
cognitive skills.
• Universities ought to form an experienced e-assessment team in every
academic program to monitor e-assessments and to aid faculty members.

Limitations and Future Research
Two limitations have been identified by the researchers, which can be directions for
future research. One of these limitations is that this study merely investigates the observations of
faculty members. Student perceptions are as yet to be investigated in future studies, and the
findings can be scrutinized against the findings of the current study. Second, the sample was
taken only from PSUT. However, because e-assessment was made obligatory in all universities
in Jordan, it is still possible to generalize the findings of the present research. Moreover, because
the COVID-19 lockdown limited the researchers’ movement, it was difficult to generalize the
findings to a larger population. To augment the generalizability of the findings, future research
may be applied to a greater extent that involves instructors from various IHE. Moreover, there
may still be plenty of room for further recommendations and suggestions with regards to the
procedures and methods of e-assessment. More solutions are needed for the challenges that were
pinpointed in the current study.
Conclusion
There is no shadow of a doubt that the academic year 2019-2020 has witnessed unique
challenges to education because of the sudden shift from traditional classroom teaching to online
teaching. This research was mainly concerned with investigating and assessing challenges that
emerged as the assessment of student performance shifted from the traditional classroom to
VLEs. The degree of incertitude involved in e-learning, both for learners and educators, has been
alarming. It is perfectly clear that students did not all have equal opportunities in Internet
connection and several related technological issues. This may have adversely impacted the
validity and reliability of e-assessments. Universities were not prepared for this unforeseen
change and thus were in many ways incapable of carrying out the assessment process
appropriately. One of the prominent challenges was that, although faculty were able to make eassessment tasks, there was no way they could completely bank on the performance of the
students, since learners did not interact with their e-classes at all times as their professors were
expecting from them. As a result, it is now of paramount importance to get the students to accept
and be ready for a new-fangled realm of assessment in a VLE, and to produce a new generation
of students who are capable of identifying what their learning needs are and what commitments
they are liable to.
The Coronavirus has interrupted the commonly practiced ways of education, resulting in
a critical need for applying alternative approaches to assessment. Because of this, universities
need to learn from mistakes committed so far during the lockdown semesters; they should revisit
their existing assessment methods and tailor them to the current, exceptional learning scenario. It
is incumbent upon IHE to examine the merits and demerits of their initial experience in online
assessment and to try to use this knowledge as a launching pad for improvement. E-assessment
Arab World English Journal
ISSN: 2229-9327

www.awej.org

49

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

requires IHE to develop a system that hinges on scrupulous planning to make sure that
assessment in a VLE is truthful, valid and reliable.
In summation, the current e-assessment systems do not prepare universities or faculty
members for valid and reliable assessment of the students. In order for e-assessment to be
trustworthy and reliable, the challenges discussed in the present study should be tackled.
Acknowledgments
This work was funded by the Deanship of Scientific Research at Prince Sattam bin Abdulaziz
University.
About the Authors:
Dr. Rami Sa’di is specialized in linguistics, with a special interest in phonetics and phonology.
He also has vested interest in TEFL and educational technology.
https://orcid.org/0000-0002-6205-6144
Dr. Ahmad Abdelraziq is specialized in linguistics, with a special interest in TEFL and
translation. He is currently conducting research in educational technology at Princess Sumaya
University for Technology in conjunction with colleagues from the Computer and the
Engineering Departments. https://orcid.org/0000-0002-9667-1786
Dr. Talha Shardgah is specialized in curricula and teaching methods. Currently, he is an
assistant professor in the English Department at Prince Sattam bin Abdulaziz University in Saudi
Arabia. His areas of research interest are focused on educational assessment and technology
integration in education. https://orcid.org/0000-0001-6338-9605
References
Akimov, A., & Malin, M. (2020). When old becomes new: a case study of oral examination as
an online assessment tool. Assessment & Evaluation in Higher Education, 45(8), 12051221. https://doi.org/10.1080/02602938.2020.1730301
Al Meajel, T. M., & Sharadgah, T. A. (2018). Barriers to using the blackboard system in
teaching and learning: Faculty perceptions. Technology, Knowledge and Learning, 23(2),
351-366. https://doi.org/10.1007/s10758-017-9323-2
Alshenqeeti, H. (2020). Assessment in higher education: A critical review of a masters-level
module’s assessment procedures. Asian Journal of Language, Literature and Culture
Studies, 3(1),
11-18.
Retrieved
from
http://www.journalajl2c.com/index.php/AJL2C/article/view/30113
Andreatta, P. B., & Gruppen, L. D. (2009). Conceptualizing and classifying validity evidence for
simulation. Medical education, 43(11), 1028-1035. https://doi.org/10.1111/j.13652923.2009.03454.x
Ayachi‐Ghanouchi, S., Cheniti‐Belcadhi, L., & Lewis, R. (2013). Analysis and modeling of tutor
functions. Computer Applications in Engineering Education, 21(4), 657-670.
https://doi.org/10.1002/cae.20511
Azzahra, N. F. (2020). Addressing distance learning barriers in Indonesia amid the Covid-19
pandemic. Policy Brief, 2, 1-8.
Arab World English Journal
ISSN: 2229-9327

www.awej.org

50

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Baró, X., Bernaus, R. M., Baneres, D., & Guerrero-Roldán, A. E. (2020). Biometric tools for
learner identity in e-assessment. In D. Baneres, E. M. Rodriguez, & A. E. Guerrero,
(eds.), Engineering Data-Driven Adaptive Trust-based e-Assessment Systems (pp. 41-65).
Springer, Cham. https://doi.org/10.1007/978-3-030-29326-0_3
Bearn, D. R., Chadwick, S. M., Jack, A. C., & Sackville, A. (2002). Orthodontic undergraduate
education: Assessment in a modern curriculum. European Journal of Dental
Education, 6(4), 162-168. https://doi.org/10.1034/j.1600-0579.2002.00255.x
Bloor, M., Sampson, H., & Gekara, V. (2014). Global governance of training standards in an
outsourced labor force: The training double bind in seafarer license and certification
assessments. Regulation
&
Governance, 8(4),
455-471.
https://doi.org/10.1111/rego.12042
Brown, M. E., & Dinecola, C. (2020). Technology and community-engaged research. Journal of
Technology
in
Human
Services, 38(1),
3-21.
https://doi.org/10.1080/15228835.2019.1577790
Burgess, S., & Sievertsen, H. H. (2020). Schools, skills, and learning: The impact of COVID-19
on education. VoxEu.org, 1. Available at https://voxeu.org/article/impact-covid-19education
Burke, J., & Dempsey, M. (2020). Covid-19 practice in primary schools in Ireland report.
County
Kildare,
Ireland:
Maynooth
University.
https://doi.org/10.13140/RG.2.2.14091.03369
Chapman, D. L., Bynog, M., & Yocom, H. (2013). Assessment, evaluation, and revision of a
technology plan. In Wang S., Hartsell T. (eds) Technology Integration and Foundations
for Effective Leadership (pp. 124-150). IGI Global. https://doi.org/10.4018/978-1-46662656-0.ch008
Crisp, G., et al. (2011). Teacher's handbook on e-assessment: A handbook to support teachers in
Using e-assessment to improve and evidence student learning and outcomes. Canberra
ACT: Australian Learning & Teaching Council.
Dean, D. (2003). The first three years of Blackboard at Eastern Washington University: Valuable
lessons from a highly successful project. In C. Crawford, N. Davis, J. Price, R. Weber &
D. Willis (Eds.), Proceedings of SITE 2003--Society for Information Technology &
Teacher Education International Conference (pp. 895-901). Albuquerque, New Mexico,
USA: Association for the Advancement of Computing in Education (AACE). Retrieved
July 28, 2020 from https://www.learntechlib.org/p/18051
Das, S., Alsalhanie, K. M., Nauhria, S., Joshi, V. R., Khan, S., & Surender, V. (2017). Impact of
formative assessment on the outcome of summative assessment–a feedback based cross
sectional study conducted among basic science medical students enrolled in MD
program. Asian
Journal
of
Medical
Sciences, 8(4),
38-43.
https://doi.org/10.3126/ajms.v8i4.17161
Dolin J., Black P., Harlen W., Tiberghien A. (2018) Exploring Relations Between Formative
and Summative Assessment. In: Dolin J., Evans R. (eds) Transforming Assessment.
Contributions from Science Education Research, vol 4. Springer, Cham.
https://doi.org/10.1007/978-3-319-63248-3_3
Ertle, B., Rosenfeld, D., Presser, A. L., & Goldstein, M. (2016). Preparing preschool teachers to
use and benefit from formative assessment: The birthday party assessment professional
development system. ZDM, 48(7), 977-989. https://doi.org/10.1007/s11858-016-0785-9
Arab World English Journal
ISSN: 2229-9327

www.awej.org

51

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Faulconer, E., Griffith, J. C., & Frank, H. (2019). If at first you do not succeed: student behavior
when provided feedforward with multiple trials for online summative assessments.
Teaching in Higher Education, 1-16. https://doi.org/10.1080/13562517.2019.1664454
Heinrich, E. (2006). Addressing efficiency and quality of marking in essay assessment with elearning support. Journal of Open, Flexible, and Distance Learning, 10(1), 15-25.
Hasim, Z., Di, S., & Barnard, R. (2018). Eliciting teachers’ understanding and their reported
practices on school-based formative assessment: Methodological challenges. Indonesian
Journal of Applied Linguistics, 8(1), 158-166. https://doi.org/10.17509/ijal.v8i1.11476
Heritage, M. (2007). Formative assessment: What do teachers need to know and do? Phi Delta
Kappan, 89(2), 140-145. https://doi.org/10.1177/003172170708900210
Hernández, J. A., Ortiz, A. O., Andaverde, J., & Burlak, G. (2008). Biometrics in online
assessments: A study case in high school students. In 18th International Conference on
Electronics, Communications and Computers (conielecomp 2008) (pp. 111-116). IEEE.
10.1109/CONIELECOMP.2008.36
Hettiarachchi, E., Balasooriya, I., Mor, E., & Huertas, M. A. (2016). E-assessment for skill
acquisition in online engineering education: challenges and opportunities. In Caballé S.,
Clarisó R. (eds) Formative Assessment, Learning Data Analytics and Gamification (pp.
49-64). Academic Press. https://doi.org/10.1016/B978-0-12-803637-2.00003-8
Hopfenbeck, T. N. (2018). The global and the local in educational assessment. Assessment in
Education:
Principles,
Policy
&
Practice,
25(2),
137-140.
https://doi.org/10.1080/0969594X.2018.1442992
Hussein, E., Daoud, S., Alrabaiah, H., & Badawi, R. (2020). Exploring undergraduate students’
attitudes towards emergency online learning during COVID-19: A case from the
UAE. Children
and
Youth
Services
Review, 119,
1-7.
https://doi.org/10.1016/j.childyouth.2020.105699
Javaid, M., Haleem, A., Vaishya, R., Bahl, S., Suman, R., & Vaish, A. (2020). Industry 4.0
technologies and their applications in fighting COVID-19 pandemic. Diabetes &
Metabolic
Syndrome:
Clinical
Research
&
Reviews,
14(4)
419-422.
https://doi.org/10.1016/j.dsx.2020.04.032
Jones, S. H. (1996). Crits—an examination. Journal of Art & Design Education, 15(2), 133-141.
https://doi.org/10.1111/j.1476-8070.1996.tb00660.x
Kearns, L. R. (2012). Student assessment in online learning: Challenges and effective
practices. Journal
of
Online
Learning
and
Teaching, 8(3),
198.
https://jolt.merlot.org/vol8no3/kearns_0912.pdf
Kebritchi, M., Lipschuetz, A., & Santiague, L. (2017). Issues and challenges for teaching
successful online courses in higher education: A literature review. Journal of Educational
Technology Systems, 46(1), 4-29. https://doi.org/10.1177/0047239516661713
Khan, R., & Jawaid, M. (2020). Technology enhanced assessment (TEA) in COVID 19
pandemic. Pakistan
Journal
of
Medical
Sciences, 36(COVID19-S4).
https://doi.org/10.12669/pjms.36.COVID19-S4.2795
Leenknecht, M., Wijnia, L., Köhlen, M., Fryer, L., Rikers, R., & Loyens, S. (2020). Formative
assessment as practice: the role of students’ motivation. Assessment & Evaluation in
Higher Education, 46(2), 1-20. https://doi.org/10.1080/02602938.2020.1765228
Longhurst, G. J., Stone, D. M., Dulohery, K., Scully, D., Campbell, T., & Smith, C. F. (2020).
Strength, weakness, opportunity, threat (SWOT) analysis of the adaptations to anatomical
Arab World English Journal
ISSN: 2229-9327

www.awej.org

52

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

education in the United Kingdom and Republic of Ireland in response to the COIVD‐19
pandemic. Anatomical Sciences Education, 13(3), 301-311.
https://doi.org/10.1002/ase.1967
Lozano, S. M., & Segura, F. T. (2016). Enhancing historical reasoning: A strategy including
formative assessment with systematic continuous feedback. International Journal of
Educational Psychology, 5(2), 187-219. http://dx.doi.org/10.17583/ijep.2016.1639
Mahabeer, P., & Pirtheepal, T. (2019). Assessment, plagiarism and its effect on academic
integrity: Experiences of academics at a university in South Africa. South African
Journal of Science, 115(11/12), 1-8. https://doi.org/10.17159/sajs.2019/6323
Marriott, P. (2009). Students' evaluation of the use of online summative assessment on an
undergraduate financial accounting module. British Journal of Educational
Technology, 40(2), 237-254. https://doi.org/10.1111/j.1467-8535.2008.00924.x
Mayhew, E. (2018). Implementing electronic management of assessment: four key barriers faced
by higher education providers moving to online submission and feedback. Research in
Learning Technology, 26, 1-13. https://doi.org/10.25304/rlt.v26.2083
Mellar, H., Peytcheva-Forsyth, R., Kocdar, S., Karadeniz, A., & Yovkova, B. (2018). Addressing
cheating in e-assessment using student authentication and authorship checking systems:
teachers' perspectives. International Journal for Educational Integrity, 14(1), 1-21.
https://doi.org/10.1007/s40979-018-0025-x
Oncu, S., & Cakir, H. (2011). Research in online learning environments: Priorities and
methodologies. Computers
&
Education, 57(1),
1098-1108.
https://doi.org/10.1016/j.compedu.2010.12.009
Palloff, R. M., & Pratt, K. (2008). Assessing the online learner: Resources and strategies for
faculty. San Francisco, CA: John Wiley & Sons, Inc.
Phillip, S., & Cain, M. (2015). Instructors' perspectives of their initial transition from face-toface to online teaching. International Journal for E-learning Security, 5(1), 441- 448.
10.20533/ijels.2046.4568.2015.0056
Rolfe, I., & McPherson, J. (1995). Formative assessment: How am I doing? The Lancet,
345(8953), 837-839. https://doi.org/10.1016/S0140-6736(95)92968-1
Sabzwari, S. (2020). Rethinking assessment in medical education in the time of COVID19. MedEdPublish, 9(1). https://www.mededpublish.org/manuscripts/3044
Sangwin, C. J. (2017). Practice and practise in university: What defines success and how does
online assessment support achieving this? In Wood L., Breyer Y. (eds) Success in Higher
Education (pp. 111-130). Springer, Singapore. https://doi.org/10.1007/978-981-10-27918_7
Sarkany, D., & Deitte, L. (2017). Providing feedback: practical skills and strategies. Academic
Radiology, 24(6), 740-746. https://doi.org/10.1016/j.acra.2016.11.023
Tereseviciene, M., Trepule, E., Dauksiene, E., Tamoliune, G., & Costa, N. (2020). Are
universities ready to recognize open online learning? International Education
Studies, 13(2), 21-32. https://doi.org/10.5539/ies.v13n2p21
Thuy, H. N. (2019). Towards 21st century assessment in open and distance education: A case
study at Hanoi Open University. In International Conference on Education 2019
conference proceedings (pp. 238-243).
Ullah, A., Xiao, H., Lilley, M., & Barker, T. (2012). Using challenge questions for student
authentication in online examination. International Journal for Infonomics, 5(3/4), 631639. https://doi.org/10.20533/iji.1742.4712.2012.0072
Arab World English Journal
ISSN: 2229-9327

www.awej.org

53

Arab World English Journal (AWEJ) Special Issue on Covid 19 Challenges April 2021
E-Assessment at Jordan’s Universities in the Time of the COVID-19

Sa'di, Abdelraziq, & Sharadgah

Vlachou, M. A. (2018). Classroom assessment practices in middle school science lessons: A
study
among
Greek
science
teachers. Cogent
Education, 5(1),
1-20.
https://doi.org/10.1080/2331186X.2018.1455633
Wuttke, H. D., Hamann, M., & Henke, K. (2015, February). Integration of remote and virtual
laboratories in the educational process. In Proceedings of 2015 12th International
Conference on Remote Engineering and Virtual Instrumentation (pp. 157-162). IEEE.
https://doi.org/10.1109/REV.2015.7087283
Xiong, Y., & Suen, H. K. (2018). Assessment approaches in massive open online courses:
Possibilities, challenges and future directions. International Review of Education, 64(2),
241-263. https://doi.org/10.1007/s11159-018-9710-5
Yao, D. (2020). A comparative study of test takers' performance on computer-based test and
paper-based test across different CEFR levels. English Language Teaching, 13(1), 124133. https://doi.org/10.5539/elt.v13n1p124

Arab World English Journal
ISSN: 2229-9327

www.awej.org

54

