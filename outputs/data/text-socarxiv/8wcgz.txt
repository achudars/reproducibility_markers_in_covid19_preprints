Explaining Support for COVID-19 Cell Phone Contact
Tracing†
Ludovic Rheault

Andreea Musulan

Department of Political Science

Department of Political Science

University of Toronto

University of Toronto

Abstract
Contact tracing applications have been deployed at a fast pace around the world to stop the spread
of COVID-19, and they may be a key policy instrument to contain future pandemics. This study aims
to explain public opinion toward cell phone contact tracing using a survey experiment conducted
with a representative sample of Canadian respondents. We build upon a theory in evolutionary
psychology—disease avoidance—to predict how media coverage of the pandemic affects public support
for containment measures. We report three key findings. First, exposure to a news item that shows
people ignoring social distancing rules causes an increase in support for cell phone contact tracing.
Second, pre-treatment covariates such as anxiety and a belief that other people are not following the
rules rank among the strongest predictors of support for COVID-19 apps. And third, while a majority
of respondents approve the reliance on cell phone contact tracing, many of them hold ambivalent
thoughts about the technology. Our analysis of answers to an open-ended question on the topic
suggests that concerns for rights and freedoms remain a salient preoccupation.

Accepted for publication in the Canadian Journal of Political Science. Please cite as:
Rheault, Ludovic and Andreea Musulan. 2020. “Explaining Support for COVID-19 Cell Phone Contact
Tracing.” Canadian Journal of Political Science, Forthcoming.

†

The authors thank the Social Sciences and Humanities Research Council of Canada for research support.

1

Introduction
Containing a pandemic like the coronavirus has brought the state back into the daily life of citizens, to
an extent arguably not seen in decades. The government response entails a trade-off that is fundamental
to political science: the extent to which people are willing to relinquish their civil liberties for the benefit
of society.1 Cell phone contact tracing apps—applications designed to facilitate the process of contact
tracing—encapsulate such a trade-off. These apps have the potential to protect the public while avoiding
the need for large-scale restrictions on economic activities during a pandemic (Ferretti et al., 2020; Peak
et al., 2020; WHO, 2020). However, they also involve design choices that may encroach on the right for
privacy, if only by increasing the capacity of the state to collect information about individual health
conditions (Bengio et al., 2020). Some countries have gone further by legally enforcing the usage of a
COVID-19 app (see e.g. O’Neill, Ryan-Mosley, and Johnson, 2020). The COVID Alert app launched by the
Canadian federal government in July of 2020 is voluntary and designed with privacy protection features.
However, it only attracted fewer than 5 million users in 3 months, or roughly 12.5% of the population
(Canada, 2020). Since the effectiveness of these apps depends on the rate of adoption (Braithwaite et al.,
2020), understanding public opinion on this question is key for a successful implementation.
This paper’s objective is to examine the effect of mass communication on public support for cell
phone contact tracing. We draw from evolutionary psychology to explain attitudes toward policy
responses in times of pandemic. We argue that media coverage emphasizing the risk-prone behaviour
of people ignoring social distancing, a common occurrence during the COVID-19 pandemic, should
increase support for a more stringent policy response. Conversely, we expect news items suggesting
that a majority of the population will be infected to reduce support for containment measures that may
encroach on privacy, by forcing the public to consider themselves as potential carriers. We test both
hypotheses using a survey experiment conducted on a representative sample of Canadian respondents (n
= 1,200), in which we randomly exposed participants to real-life news items. We also measured various
attitudes using traditional survey questions, and asked respondents to elaborate on their opinion about
cell phone contact tracing specifically, using an open-ended question. Our results show that perceptions
of other people flouting social distancing rules—both stimulated by the treatment and self-reported—are
a key determinant of support for cell phone contact tracing.
COVID apps can facilitate the industrious process of contact tracing, one of the primary methods
used by governments to contain the spread of viruses during an epidemic. On date of May 7, 2020,
the MIT Technology Review had identified 25 countries with active COVID-19 app campaigns, five of
which making the contact tracing app mandatory (O’Neill, Ryan-Mosley, and Johnson, 2020).2 Using
either GPS geolocation or Bluetooth technology, these apps have the common characteristic of keeping
1

For an overview of the pandemic’s implications for rights and freedoms in Canada, see Macfarlane (2020).
Many more apps were actually deployed or in development as of May 2020. See e.g. https://benlevyx.github.io/covidtracking/ for an overview.
2

2

a record of interactions between users who come in proximity to each other, for various periods of
time. When a new case of COVID-19 is identified, users who have been in contact with the infected
person are notified. Scholars and human rights advocates have emphasized various concerns about
the implementation of cell phone contact tracing (Cho, Ippolito, and Yu, 2020; Stanley and Granick,
2020; Kahn et al., 2020; Parker et al., 2020). Aside from security risks associated with the technology,
COVID-19 apps may increase the effectiveness of authorities in gaining information about the health
risks of specific individuals. A common design choice is to have the app inform health agencies of the
identity of users who have been in contact with an infected individual, similar to manual contact tracing
(see Cohen, Gostin, and Weitzner, 2020).3 The app used in Alberta during the COVID-19 pandemic
(ABTraceTogether) is based on this approach: it shares the name and phone number of users exposed to
the virus with provincial health authorities (Alberta, 2020). On the other hand, the nationwide COVID
Alert application launched in Canada sends the alerts to users only.
The Canadian case is particularly interesting given the remarkable resilience of the population in
dealing with the early stages of the COVID-19 pandemic. Previous research has shown that Canadians
were overwhelmingly supportive of social distanciation measures during the spring 2020 lockdown
(Sevi et al., 2020; Merkley et al., 2020; Pickup, Stecula, and van der Linden, 2020), despite the presence
of a rather extensive set of restrictive policies in urban areas (Armstrong and Lucas, 2020). However,
we still have limited information on the public’s perceptions of containment measures such as cell
phone contact tracing. A survey commissioned by Senators has shown Canadian respondents to be
supportive of COVID-19 apps. The study found that 80% of respondents “support the use of mobile device
data by public health officials to notify those who have been close to someone who has tested positive
for COVID-19” (Moodie et al., 2020, 20) and a majority of respondents (65%) supported the idea of a
mandatory COVID-19 app. In contrast, a Mainstreet Research/iPolitics poll conducted shortly after using
an interactive voice response (IRV) system found that a majority of respondents (57%) would consider it
unacceptable if the government asked them to download a contact tracing app (Mainstreet Research,
2020). The present study helps to assess public opinion on this sensitive question, and highlights factors
that make people more or less likely to support cell phone contact tracing.

Theory
Our objective is to explain how people cope with the trade-off between civil liberties and emergency
measures to contain pandemics. Our argument stems from a well established theory in evolutionary
3

This particular point can easily be a source of confusion. The Apple-Google exposure notification system used as a basis
for many COVID apps was designed to notify health authorities when someone was in proximity to an infected individual,
although specific implementations may diverge from that principle. As of June 18, 2020, the Apple-Google documentation
stated that “no data will be shared by the system with public health authority apps unless one of the following two scenarios
takes place”, with the second scenario being “[i]f a user is notified through their app that they have come into contact with
an individual who is positive for COVID-19” (Apple and Google, 2020, 5-6).

3

psychology, disease avoidance, which posits that humans have developed a natural response mechanism
to avoid the threat posed by pathogens (Schaller, 2006). While political science research has relied on this
theory to study attitudes toward outgroups such as immigrants and the homeless (see e.g. Aarøe, Petersen,
and Arceneaux, 2017; Clifford and Piston, 2017), this response mechanism—also called the behavioural
immune system—has an even more immediate relevance to understanding the formation of attitudes
during a pandemic like COVID-19. Due to evolutionary processes that have allowed human beings to
survive through pandemics, we are predisposed to detect, and avoid, signs of infectious diseases (Schaller
and Park, 2011). This explains, for instance, why many people feel disgust when seeing individuals
with ostensible signs of infection (Aarøe, Osmundsen, and Petersen, 2016). Faced with the spread of
coronavirus, people will naturally seek for clues that help them to identify the source of the threat, and
minimize the risks. As Lockyer and Hatemi (2014) pointed out, however, the presence of an evolutionary
mechanism does not preclude individual variations in behaviours. The degree to which each person
interprets the COVID-19 threat and the appropriate policy response may vary depending on the type of
information they are exposed to, and other individual characteristics.
We argue that media coverage of the COVID-19 pandemic introduces frames that elicit predictable
responses among the public. Framing, and more specifically emphasis framing, is a central theory in
political communication, suggesting that the choice to emphasize a specific element of an issue may influence how people form opinions on that issue (Chong and Druckman, 2007, 2011; Cacciatore, Scheufele,
and Iyengar, 2016). For instance, the association between the virus and China in mass communications—
one salient example was Donald Trump’s discourse, who initially relied on the expression “Chinese
virus”—may have pernicious effects, by presenting Chinese people as a potential vector of contagion.4
Individuals who incorporate such a frame may seek to avoid contact with Chinese-Americans, display
hostility toward the group, and demand a closing of the border for Chinese travelers. In fact, all of those
behaviours have been observed in North America (see e.g. Tavernise and Oppel Jr, 2020).5
In this study, we consider how emphasis frames used in media communication may affect public
opinion toward containment measures, specifically. We start from the general premise that COVID-19
has two distinctive features. First, there is a sense that the threat is real and important, reflected by the
intensity of news coverage and by provinces declaring a state of emergency. Second, the low prevalence
rate of confirmed cases makes the origin of threat particularly elusive.6 This context opens the door to
multiple interpretations regarding who actually poses a contagion risk, and what steps must be taken to
avoid that threat.
4

See also Motta, Stecula, and Farhart (2020) about the impact of media coverage of the pandemic and its effect on beliefs
in conspiracy theories.
5
Previous research on political communication in Canada has also documented media framing on topics such as immigration and ethnicity (e.g. Lawlor, 2015; Tolley, 2016).
6
As of June 2020, confirmed cases in Canada represented less than 0.3% of the population, using data from the Johns
Hopkins Coronavirus Resource Center (Dong, Du, and Gardner, 2020).

4

We advance two hypotheses to explain how framing can influence public perceptions about the risk
of contagion. First, news media frames emphasizing people who disregard social distancing guidelines
should increase support for containment measures. A common emphasis frame during the pandemic
was the coverage of people ignoring physical distancing rules.7 We expect this type of coverage to
stress the idea that a specific group of the population—non-compliers—are a source of disease risk.
The choice to emphasize non-compliance also suggests a causal interpretation that links a problematic
behaviour with the spread of coronavirus. Consequently, we posit that people exposed to this frame are
more likely to support tougher state interventions designed to contain the risk. A mandatory contact
tracing application represents an intrusive type of state response to pandemics, but one that may seem
justified with the belief that negligent behaviour from other members of the public poses an increased
risk of contagion. In summary, we expect that news media coverage emphasizing non-compliers increases
unconditional support for cell phone contact tracing (Hypothesis 1).
Second, we expect another type of news coverage—emphasizing the idea that a virus is inevitable—to
generate the opposite effect. We argue that exposing the public to the notion that COVID-19 will infect
a majority of the population should reduce support for containment measures, especially mandatory
cell phone contact tracing. News items of that nature were also common during the pandemic. For
instance, an article circulated early on with projections that 30 to 70% of Canadians would be infected
with the virus (Dunham, 2020). This emphasis frame challenges the “optimism bias,” that is, the tendency
that people have to believe they are unlikely to become infected themselves (see Van Bavel et al., 2020;
Wise et al., 2020). Instead of depicting an external group of population as a source of risk, this kind of
information shifts the locus of the threat, by forcing the public to consider a scenario where they are
potential carriers of the virus. As a result, we expect the consequences of government interventions
to become salient and personal, in particular if a measure deals with health information. While the
nationwide COVID alert application launched by the federal government in Canada ultimately came
with some guarantees of anonymity, we expect that news coverage predicting a high rate of infection
leads the public to become more cautious before embracing the idea of cell phone contact tracing. Thus,
we expect that news media coverage emphasizing that a majority of the population will become infected
reduces unconditional support for cell phone contact tracing (Hypothesis 2).
In short, the two frames suggest contrasting ideas to the audience: that the threat may originate
from groups of reckless individuals, or that it may come from just about everyone. In the first case, the
consequences of state interventions appear directed at external agents posing a risk of contagion. The
second frame breaks the dissociation between the audience and the threat, with the consequence that
state interventions appear directed at the audience itself.
7

For example, our experimental treatment in this study uses a real news item covering a large gathering in downtown
Toronto (Aguilar, 2020).

5

Data and Research Design
Our data come from an online survey of 1,200 Canadians recruited using the Cint platform, a market
exchange for survey respondents. Coppock and McClellan (2019) provide a detailed examination of
the validity of this type of survey platform for social science research. We fielded the survey in both
official languages between May 28 and May 29, 2020. The survey used quota sampling based on
census distributions for age, gender and region. We examined the quality of our sample by comparing
proportions for additional demographic variables—income groups, education and ethnicity—against
census proportions. Overall, the sample closely matches population distributions even for variables not
utilized to establish the quotas. We report details of this analysis in the Online Appendix.
The survey questionnaire contained five blocks of items presented on separate pages: 1) questions
designed to measure pre-treatment covariates, 2) the randomized media treatment, 3) two questions measuring opinion on COVID-19 contact tracing applications, 4) questions on other government measures,
and 5) demographic questions.
We start by discussing the two questions designed to measure support for COVID-19 apps, the
outcome variable of interest. All respondents were asked to answer a close-ended query inviting them
to indicate whether they support the government’s participation in a COVID app. Next, all respondents
were invited to elaborate on their opinion using an open-ended question. Our analysis focuses on
both data types. Informed by previous surveys mentioned in the introduction, which led to divergent
results, we paid particular attention to the drafting of the close-ended question about COVID apps.
We self-imposed the following criteria when designing that question: the nature of cell phone contact
tracing must be described accurately using a simple language; the question should remain as neutral as
possible (avoiding statements emphasizing the benefits of cell phone contact tracing over the risks, or
vice-versa); and the question should make clear that cell phone contact tracing involves the participation
of governments. The baseline wording reads:
Many COVID-19 apps are being used around the world to notify people who were in contact
with someone infected (contact tracing apps). These apps record the interactions between
users by detecting when two cell phones are close to each other.
These apps require the participation of health agencies to confirm who tested positive for
COVID-19.
Do you support the government’s participation in a COVID-19 contact tracing app?
We offered three response categories: “Yes,” “Yes, but only if using the app is voluntary,” and “No.” This
allows respondents to explicitly state whether their approval is conditional on the voluntary use of a
contact tracing app.
To further validate measurement accuracy, we took two additional steps. First, we randomly assigned
a total of three variations of the same question, to assess the sensitivity of the results to question wording.
6

One alternative included the sentence “In most cases, COVID-19 apps are designed to notify health
agencies when someone was in contact with an infected individual,” which captures an important design
choice. For instance, the app used in Alberta was designed to share contact information from persons
who were near someone infected with provincial health authorities, as is the case with manual contact
tracing. The other alternative mentioned both sides of the public debate regarding the use of contact
tracing apps, with the sentence “Some people claim that COVID-19 apps may pose a risk to fundamental
rights, such as the right to privacy. Others claim these apps are needed to help reopen the economy
while protecting public health.” These variations in question wording, however, have no statistically
significant impact on the distribution of responses. We report a model that includes a direct test of the
effect of question wording in the empirical section below.
Next, we asked all respondents to elaborate on their opinion using an open-ended question. The
response rate was high: 90.7% of respondents, or 1088 out of 1200, wrote a substantive answer. This
number excludes gibberish text. The answers ranged from 1 to 139 words in length. These written
comments provide an opportunity to conduct a more detailed analysis of public opinion. Responses
were manually classified into a priori categories by three independent coders.8 The binary categories
are not mutually exclusive and correspond to common arguments for and against cell phone contact
tracing. Two of these arguments are in line with the theoretical mechanisms laid out in the previous
section—whether people evoke the risk posed by other individuals to justify their position in support
of COVID apps (Hypothesis 1), and whether people evoke the importance of restricting the scope of
these apps (Hypothesis 2). We discuss the classification in detail and provide information on inter-rater
reliability in the empirical section, whereas the full coding scheme appears in the appendix.
The experimental treatment in our survey consists of exposing respondents to a news item using one
of the two frames discussed in the previous section. We randomly assigned respondents to three groups
with equal probability. The first group was asked to read a news item describing people who neglect to
abide by physical distancing rules in Toronto. The second group was exposed to a news article about
the Canadian health minister indicating that 30% to 70% of the population might become infected with
COVID-19. The survey invited respondents to read an excerpt of either news article, which included
title, author, original image, and the article lead (the vignettes appear in the online appendix). Both news
stories were published during the pandemic, and we selected them because a semantically equivalent
French version also appeared in national media. The third group of respondents was not exposed to any
news items, and serves as a control.
A recent stream of literature has emphasized the role of attentiveness in survey experiments (Alvarez
8

Two of the coders are authors, and the third was a student hired for this task. All English language responses were
classified by three coders, whereas the French language responses were classified by two coders. We use the majority choice
as our final response in the former case, and the few coder disagreements about French language comments were manually
resolved by the authors.

7

et al., 2019). While we acknowledge the importance of this question and considered the possibility of
including an attention check in this study, we ultimately decided against it for a number of reasons. First,
the reaction of respondents to attention checks is debated, and may introduce undesirable behaviours
such as increased drop out (see e.g. Berinsky, Margolis, and Sances, 2016; Anduiza and Galais, 2017;
Vannette and Krosnick, 2014). Second, our survey design is relatively simple and does not entail the kind
of cognitive involvement required in more elaborate experiments, for instance conjoint designs. Our
reliance on large fonts and images in the media treatments is backed up by a literature showing that
illustrations facilitate the processing of text (Glenberg and Langston, 1992), which simplifies the cognitive
load for respondents. Finally, the open-ended question on COVID apps provides a way to monitor
attention directly. We read each response individually, and we were able to verify that respondents who
wrote valid comments understood the query. Furthermore, we replicated the results in the next section
with and without respondents who did not answer the open-ended survey question. Omitting these
respondents does not affect the main conclusions.
Figure 1 shows percentages of responses to the closed-ended survey question on COVID-19 cell
phone contact tracing, our outcome variable of interest. For simplicity, we pool responses across the
three variations of the question. A plurality of respondents endorsed the use of a COVID-19 app, but
their support was conditional on participation being voluntary (47%). When combining with respondents
who expressed unconditional support for COVID apps, the proportion favourable reaches 85%. This is
consistent with the high levels of support found in the Senate study (Moodie et al., 2020). Bengio et al.
(2020) suggest that 56% of the population must adopt a contact tracing app for it to be successful at abating
the spread of coronavirus. Thus, based on the data observed in this survey, the successful deployment of
a COVID app will largely depend on convincing those whose support was only conditional.
For the analysis that follows, we focus on explaining unconditional support for COVID apps—those
respondents who answered with a plain “Yes”, endorsing even the idea of a mandated COVID-19 contact
tracing app. From a theoretical standpoint, this response category is the most interesting because it
captures citizens willing to accept restrictions on liberties in response to the pandemic. We combine
the categories “Only if voluntary” and “No” to create a binary dependent variable that equals one if
the respondents answered “Yes”, and zero otherwise. To further assess the plausibility of this decision,
we fitted multinomial models with the three response categories, and tested whether the “Only if
voluntary” and “No” categories can be combined using A Wald test of the null that coefficients are equal
across equations (Long, 1997, 162–163). We cannot reject the null at conventional levels of statistical
significance, which supports the choice to combine these two response categories. Moreover, we note
that the substantive conclusions we report below hold by considering a model that compares respondents
answering “Yes” versus “Only if voluntary”, the two most frequent answers.

8

Figure 1: Distribution of Answers to COVID-19 Survey Question

Sample percentage

50

47.3%

40

37.6%

30
20

15.1%

10
0
No

Only if voluntary

Yes

Notes: The figure shows sample percentages across the three categories of the outcome variable, which are answers to a
question asking “Do you support the government’s participation in a COVID-19 contact tracing app?” Percentages are
tabulated using the full sample, comprising all treatment groups (n = 1,200).

Results
We begin by reporting the breakdown of our outcome variable across treatment groups. Figure 2 shows
the proportion of respondents fully supporting cell phone contact tracing for each condition. We label
“Non-Compliers” the first media treatment, which featured people not complying with social distancing
guidelines. The second media treatment is labelled “Large Infection Rate”. The differences observed in
Figure 2 are consistent with expectations from theory. Respondents presented with the Non-Compliers
media frame are more likely to express an unconditional support for mandatory cell phone contact
tracing. Conversely, those exposed to the idea that most of the Canadian population will be infected are
less likely to do so. The first result is the most robust, as we detail below.
For a more accurate assessment, we report sample average treatment effects computed with confidence
intervals in Figure 3. These estimates represent differences in predicted probabilities from logistic
regression models that also include covariates and demographic variables (see Online Appendix for the
full tables and covariate definitions). The table shows results with and without raking weights, and
the third model includes the wording used for the outcome variable as a predictor. Overall, we find
that the Non-Compliers media frame increases support for mandatory cell phone contact tracing by
about 9 percentage points (everything else equal), a result that is statistically significant at the 95%
confidence level. This effect size is non-trivial. Combined with the support from theory, the reliance
on randomization means that we can more safely interpret this effect in terms of causality. In contrast,
the treatment effect for the second media frame under consideration is not robust. Our research design
aimed to maximize external validity by relying on real-life news media articles. It is possible that the
9

Figure 2: Support for Mandatory COVID-19 Apps, by Treatment Group

Support for Mandatory COVID−19 App

0.5

0.4

0.3

0.2

0.1

0.0
Control

Non−Compliers
Treatment

Large Infection Rate

Notes: The figure shows the percentage answering an unconditional “Yes” to the close-ended question on cell phone contact
tracing across the three treatment groups, for the full sample (n = 1,200).

statement featured in the second treatment was not forceful enough to induce a change in attitudes,
which could be explored in future research.
We can further validate the plausibility of our first hypothesis using traditional survey questions
(pre-treatment covariates). A pre-existing belief that others are not taking physical distancing seriously
is positively associated with support for COVID-19 apps (the “Not Serious Enough” variable in Figure
3). This relationship is consistent with the idea that people are more likely to seek remedial measures
from the government when they perceive a group that poses a health risk. Controlling for this belief
also accounts for a potential prior exposure to news items similar to the first media treatment. Next, we
find that the level of anxiety regarding the virus matters. Respondents who declare being “very worried”
about their family members being infected by the virus are much more likely to support COVID-19 apps.
This last result is particularly robust across the specifications considered.
Finally, we turn our attention to respondents’ written comments on COVID-19 apps. These comments
are useful for understanding the considerations people have in mind when thinking about this technology.
Immediately after asking respondents about COVID-19 apps, our survey invited them to elaborate on
their opinion. The open-ended question read “We would like to understand public opinion about COVID19 apps. Could you please give us the main reason for your previous answer, in one or two sentences [...]”
As mentioned above, three coders independently classified the arguments invoked by respondents using
a manual coding scheme. Table 1 reports the proportion of all respondents mentioning each argument
type. The categories are non-exclusive, binary indicators equalling one if the respondent mentions a
given type of argument, and zero otherwise.
We designed the coding scheme based on our theory and prior knowledge of public debates surround-

10

Treatment

Figure 3: Support for Mandatory COVID-19 Apps (Average Treatment Effects)
●
●
●

Non−Compliers
●
●
●

Large Infection Rate

●
●
●

Not Serious Enough

●
●
●

Pre−Treatment Covariates

Worried

●
●
●

Trudeau Approval
●
●
●

Lost Job

●
●
●

Above 56 Years Old
●
●
●

Female
Question Wording

Model

Health Agency

●

Unweighted

●

Weighted

●

Wording Control

●

Dilemma

●

−0.2

0.0

0.2

0.4

Notes: The figure reports differences in predicted probabilities for a change from 0 to 1 in each predictor, along with 95%
confidence intervals, computed from logistic regression models. The raw output appears in the Online Appendix. The
dependent variable equals one if the respondent supports COVID-19 apps unconditionally, zero otherwise. The “Unweighted”
model does not include sampling weights. The “Weighted” model includes raking weights. The “Wording Control” model is
computed with raking weights and includes dummy variables for variants of the COVID-19 apps question wording.

11

Table 1: Most Frequent Arguments about COVID-19 Apps
Arguments

Top Unigrams

κ

Category

%

Civil Liberties

Impact on privacy; Importance of rights and privacy, government, inva32.3% freedoms; Being tested is an individual respon- sive, governments, intru- 0.89
sibility, not the state’s.
sive

With Conditions

Usage must be voluntary; App must be used
forced, mandatory, volun21.1% for this purpose alone; Only infected should be
0.80
tary, choice, choose
required to use.

Not Going To Work 8.9%

Not everyone has a phone; People can leave
phone, cell, smartphone,
their phones at home; Other methods are more
0.80
cells, rely
effective.

Threat Is Not Real

1.4%

Threat is exaggerated
ment/media.

Societal Concerns

Public health above other considerations; Need
safety, worth, safe, safer,
18.2% to protect the vulnerable; Need to take action;
0.67
important
Need to reopen the economy.

Others as a Threat

Need to locate the infected; Need to avoid coninfected, avoid, rules, dis13.4% tact with the infected; People not respecting the
0.75
tancing, contacted
rules pose a risk.

App Is Effective

App would make contact tracing easier; Suchelpful, easier, useful, con0.56
14.8% cessful in other countries; App would provide
tact, great
useful data.

by

the

govern-

—

0.85

Notes: The table reports a classification of argument types for the written answers to the open-ended question on COVID-19
apps. The response rate was 90.7% (1,088 out of 1,200). A residual category, not shown here, contains all other arguments
that did not fit the coding scheme (3.8% of respondents, or 45). The second column is the percentage of written answers
containing each argument type, out of 1,200 respondents. Percentages do not sum to 100 since the categories are not
exclusive. The last column shows Cohen’s Kappa coefficients averaged across pairs of coders.

12

ing cell phone contact tracing, which are discussed in the literature cited in our introduction. We started
by identifying four types of arguments against COVID apps. Concerns about infringements of rights and
freedoms, including the risks for privacy, constitute the first of these categories (we call it Civil Liberties
for short). The second argument type focuses on the need to restrict the scope of COVID apps (With
Conditions). The third argument against COVID-19 apps concerns their limited effectiveness (Not Going
to Work). A last category targets beliefs that the virus threat may be exaggerated by governments or the
media (Threat Is Not Real). Next, we constructed three categories of arguments in support of COVID
apps, based on which consideration is salient: society, the source of the threat, or the app itself. The
first positive category is meant to capture one side of the trade-off involved by containment measures,
that is, whether respondents are explicitly mentioning the benefits for society as their justification for
supporting COVID apps (Societal Concerns).9 The second category includes arguments in line with our
theoretical model based on disease avoidance: whether the respondent explicitly mentions the risk posed
by the infected or by people not respecting the rules (Others as a Threat). The last category includes
arguments focusing on the technology (App is Effective).
Table 1 reports additional information about each category of the coding scheme. The penultimate
column displays the top five unigrams (single words) most strongly associated with each category,
calculated using the in-sample coefficients from a support vector classifier. These top words give an
overview of the substantive content of written answers invoking each argument type, and they help to
support the construct validity of the coding scheme. The last column of Table 1 reports the Cohen’s
Kappa (κ) inter-rater reliability coefficients by category, averaged over each pair of coders. Overall,
the level of agreement between coders is very strong for negative arguments about COVID apps, with
values equal to or above 0.80.10 Coders were not as consensual for positive arguments, but given the
interpretative nature of the task, a value of 0.75 for the “Others as a Threat” category, for instance, is more
than satisfactory. Classes with a lower reliability score (for instance, arguments about the effectiveness
of contact tracing apps) are not used for inference in what follows.
By far, the most frequent argument invoked by respondents concerned civil liberties, in particular
the impact of COVID apps on privacy (mentioned by 32.3% of the 1,200 respondents). The importance
of keeping contact tracing apps voluntary was also a recurring concern; those arguments are included
in the second category (With Conditions). While we expected conspiracy theories about the virus to
be prevalent, very few respondents made explicit statements suggesting that the threat is exaggerated
(1.4% of respondents only). Among the positive arguments, comments focusing on the benefits to society
were the most frequent (18.2%). Many respondents explicitly justified their support to COVID apps by
9

We initially devised a separate category for economic arguments—that is, the idea that cell phone contact tracing could
avoid economic restrictions. However, this type of argument was seldom invoked by respondents. For simplicity, we combined
this argument with the Societal Concerns category.
10
The average Cohen’s Kappa score for all seven categories combined is 0.78.

13

the need to track people who pose a risk of infection (13.4%), which we expect to be primed by the the
Non-Complier news media coverage. In fact, several respondents interpreted that contact tracing apps
would allow them to locate and avoid the infected ahead of time, even though the COVID Alert app
deployed in Canada does not provide that kind of information. Some respondents evoked combinations
of arguments for and against COVID-19 apps (e.g. a respondent supportive of COVID-19 apps explicitly
acknowledging the risks for privacy). Nonetheless, each argument type is a very strong predictor of the
discrete response categories discussed earlier.
This fine-grained categorization affords us with the opportunity to trace the causal mechanisms
involved in the media treatment effects. Figure 4 reports results from logistic regression models similar
to those used previously, but using the type of argument mentioned by the respondent as outcome
variables. For simplicity, we focus on the two noteworthy relationships. We find that exposure to the
Non-Compliers news story is positively associated with arguments mentioning the risk posed by other
individuals (“Others as a Threat” in Table 1). In turn, these considerations are positively related to
unconditional support for COVID-19 apps (p < 0.001; test of difference in proportions). The self-reported
belief that people are not serious enough is also a significant predictor of arguments invoking the risk
posed by others. This gives credence to explanations drawn from disease avoidance theory. In contrast,
exposure to the Large Infection Rate treatment is positively associated with arguments emphasizing the
need to restrict the scope of the app (the “With Conditions” category). This time, the treatment effect is
statistically significant at the 95% confidence level. While the overall effect of the second media treatment
did not seem robust, we can conjecture about the theoretical mechanism at work. People exposed to
the idea that they could become infected themselves are more likely to consider the implications of a
mandatory program, and request the inclusion of safeguards. Future research would help to further
assess the plausibility of such a mechanism.

Conclusions
Our research design allowed us to examine the determinants of public support for containment measures
during a pandemic, a topic for which there is still a paucity of research at the present time. We find
that exposure to news items featuring people not respecting social distancing rules—a recurring type of
emphasis frame during the COVID-19 pandemic—increases the level of support for contact tracing apps.
The treatment is positively associated with explicit concerns about the risk posed by other individuals,
and with support for mandatory cell phone contact tracing. This finding is consistent with expectations
from disease avoidance theory, which posits that people confronted with an epidemic will naturally
seek to identify the source of threat and look for solutions to abate the risk. We also expected that news
coverage predicting a large infection rate would offset the tendency of people to dissociate themselves
from the threat. We find weaker evidence of this type of effect. Nonetheless, respondents assigned to
14

Figure 4: Determinants of Arguments on COVID-19 Apps (Average Treatment Effects)

Treatment

Non−Compliers

Large Infection Rate

Not Serious Enough

Worried

Covariates

Trudeau Approval

Lost Job

Above 56 Years Old

Dependent Variable

With Conditions

Female

Others as a Threat

−0.2

0.0

0.2

0.4

Notes: The figure reports differences in predicted probabilities for a change from 0 to 1 in each predictor, along with 95%
confidence intervals, computed from logistic regression models. The full models appear in the Online Appendix. The
dependent variables equal 1 if the respondent invoked the argument type described in the legend, and 0 otherwise. The
estimates are computed with raking weights.

15

that treatment were more likely to mention the importance of restricting the scope of contact tracing
apps.
Understanding the psychology of public opinion is key to predicting compliance with health safety
measures during a pandemic. In particular, our results contribute to a literature focusing on the role of
communication in the formation of attitudes toward health policy (see e.g. Lunz Trujillo et al., 2020).
The reliance on fear appeals when communicating health risks to the public, for instance, is a well
documented strategy used to induce changes in behaviour (Witte and Allen, 2000; Van Bavel et al., 2020).
Yet the way public officials and the media should communicate the threat during a pandemic remains
an open question. Recent research has shown that news coverage during epidemics may also cause
undesirable consequences such as hoarding and the burdening of medical facilities (McDonnell, Nelson,
and Schunk, 2012; Gollust, Nagler, and Fowler, 2020; Garfin, Silver, and Holman, 2020). Our findings
suggest that media coverage of non-compliers during the COVID-19 pandemic led some respondents to
endorse contact tracing apps, even if usage is mandated by the government. On the other hand, a danger
with that communication practice is that it may encourage stigmatization, by spreading the belief that
those infected with the virus are responsible for their fate. Respondents exposed to that treatment in our
study were more likely to justify their support for COVID apps by emphasizing the need to locate the
infected, as opposed to social benefits. Future research on the topic could greatly benefit the efficiency of
communication strategies during health crises, by revealing what types of attitudes the messages elicit.
The COVID-19 pandemic has had devastating economic consequences for Canadians, and the effect
of the lockdown—one of the most extreme form of limitations to civil liberties—may be felt for a long
time. Containment measures that may help to avoid the need for a full scale lockdown, like cell phone
contact tracing, will likely be on the agenda in the response to COVID-19 and future pandemics. In a
democratic country, however, the success of automated contact tracing ultimately depends on public
perceptions toward the technology. Our survey results illustrate the trade-off involved, with most
respondents being ambivalent about COVID-19 apps. Some acknowledge the need to protect public
health, but even more are concerned about implementation, privacy, and freedom of choice. Addressing
the contentious aspects of cell phone contact tracing effectively may be key for encouraging adoption
during the fight against pandemics.

16

References
Aarøe, Lene, Mathias Osmundsen, and Michael Bang Petersen. 2016. “Distrust as a Disease Avoidance
Strategy: Individual Differences in Disgust Sensitivity Regulate Generalized Social Trust.” Frontiers in
Psychology 7: 1038.
Aarøe, Lene, Michael Bang Petersen, and Kevin Arceneaux. 2017. “The Behavioral Immune System
Shapes Political Intuitions: Why and How Individual Differences in Disgust Sensitivity Underlie
Opposition to Immigration.” American Political Science Review 111(2): 277–294.
Aguilar, Bryann. 2020. “’It’s Selfish’: Officials Disappointed to See Large Crowds at Downtown Toronto
Park Amid Pandemic. CP24 News, May 23.
Alberta. 2020. ABTraceTogether. Government of Alberta. https://www.alberta.ca/ab-trace-together.aspx.
Page consulted on May 28, 2020.
Alvarez, R Michael, Lonna Rae Atkeson, Ines Levin, and Yimeng Li. 2019. “Paying Attention to Inattentive
Survey Respondents.” Political Analysis 27(2): 145–162.
Anduiza, Eva, and Carol Galais. 2017. “Answering Without Reading: IMCs and Strong Satisficing in
Online Surveys.” International Journal of Public Opinion Research 29(3): 497–519.
Apple and Google. 2020.
“Privacy-Preserving Contact Tracing.” Apple and Google.
https://www.apple.com/covid19/contacttracing. Page consulted on May 28, 2020.
Armstrong, David A., and Jack Lucas. 2020. “Measuring and Comparing Municipal Policy Responses to
COVID-19.” Canadian Journal of Political Science, p. 1–12.
Bengio, Yoshua, Richard Janda, Yun William Yu, Daphne Ippolito, Max Jarvie, Dan Pilat, Brooke Struck,
Sekoul Krastev, and Abhinav Sharma. 2020. “The Need for Privacy With Public Digital Contact Tracing
During the COVID-19 Pandemic.” The Lancet Digital Health 2: e342–e344.
Berinsky, Adam J, Michele F Margolis, and Michael W Sances. 2016. “Can We Turn Shirkers Into
Workers?” Journal of Experimental Social Psychology 66: 20–28.
Braithwaite, Isobel, Thomas Callender, Miriam Bullock and Robert W Aldridge. 2020. “Automated and
Partly Automated Contact Tracing: A Systematic Review to Inform the Control of COVID-19” The
Lancet Digital Health 2: e607–e621.
Cacciatore, Michael A, Dietram A Scheufele, and Shanto Iyengar. 2016. “The End of Framing as We
Know It... and the Future of Media Effects.” Mass Communication and Society 19(1): 7–23.
17

Canada. 2020. Download COVID Alert today.
https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covidalert.html. Ottawa: Government of Canada. Page consulted on October 22, 2020.
Cho, Hyunghoon, Daphne Ippolito, and Yun William Yu. 2020. “Contact Tracing Mobile Apps for
COVID-19: Privacy Considerations and Related Trade-Offs.” arXiv Preprints: arXiv:2003.11511.
Chong, Dennis, and James N Druckman. 2007. “Framing Theory.” Annu. Rev. Polit. Sci. 10: 103–126.
Chong, Dennis, and James N. Druckman. 2011. “Identifying Frames in Political News.” In The Sourcebook
for Political Communication Research: Methods, Measures, and Analytical Techniques, ed. Erik P. Bucy,
and R. Lance Holbert. New York: Routledge pp. 238–267.
Clifford, Scott, and Spencer Piston. 2017. “Explaining Public Support for Counterproductive Homelessness
Policy: The Role of Disgust.” Political Behavior 39(2): 503–525.
Cohen, I Glenn, Lawrence O Gostin, and Daniel J Weitzner. 2020. “Digital Smartphone Tracking for
COVID-19: Public Health and Civil Liberties in Tension.” JAMA 323(3): 2371–2372.
Coppock, Alexander, and Oliver A McClellan. 2019. “Validating the Demographic, Political, Psychological,
and Experimental Results Obtained from a New Source of Online Survey Respondents.” Research &
Politics 6(1): 1–14.
Dong, Ensheng, Hongru Du, and Lauren Gardner. 2020. “An Interactive Web-Based Dashboard to Track
COVID-19 in Real Time.” The Lancet infectious diseases 20(5): 533–534.
Dunham, Jackie. 2020. “COVID-19 Could Infect 30 to 70 per Cent of Canadians: Health Minister. CTV
News, March 12.
Ferretti, Luca, Chris Wymant, Michelle Kendall, Lele Zhao, Anel Nurtay, Lucie Abeler-Dörner, Michael
Parker, David Bonsall, and Christophe Fraser. 2020. “Quantifying SARS-CoV-2 Transmission Suggests
Epidemic Control With Digital Contact Tracing.” Science 368(6491): 1–7.
Garfin, Dana Rose, Roxane Cohen Silver, and E Alison Holman. 2020. “The Novel Coronavirus (COVID2019) Outbreak: Amplification of Public Health Consequences by Media Exposure.” Health Psychology
39(5): 355–357.
Glenberg, Arthur M, and William E Langston. 1992. “Comprehension of Illustrated Text: Pictures Help
to Build Mental Models.” Journal of Memory and Language 31(2): 129–151.
Gollust, Sarah E, Rebekah H Nagler, and Erika Franklin Fowler. 2020. “The Emergence of COVID-19 in
the US: A Public Health and Political Communication Crisis.” Journal of Health Politics, Policy and Law.
18

Kahn, Jeffrey et al. 2020. Digital Contact Tracing for Pandemic Response: Ethics and Governance Guidance.
Baltimore: Johns Hopkins University Press.
Lawlor, Andrea. 2015. “Framing Immigration in the Canadian and British News Media.” Canadian Journal
of Political Science 48(2): 329–355.
Lockyer, Adam, and Peter K Hatemi. 2014. “Resolving the Difference Between Evolutionary Antecedents
of Political Attitudes and Sources of Human Variation.” Canadian Journal of Political Science 47(3):
549–568.
Long, John Scott. 1997. Regression models for categorical and limited dependent variables. Thousand Oaks:
Sage Publications.
Lunz Trujillo, Kristin, Matthew Motta, Timothy Callaghan, and Steven Sylvester. 2020. “Correcting
Misperceptions about the MMR Vaccine: Using Psychological Risk Factors to Inform Targeted Communication Strategies.” Political Research Quarterly DOI: 1065912920907695.
Macfarlane, Emmett. 2020. “Public Policy and Constitutional Rights in Times of Crisis.” Canadian Journal
of Political Science, 1–5.
Mainstreet Research. “Survey of Canada.” Canada iPolitics, May 11, 2020. https://ipolitics.ca/wpcontent/uploads/2020/05/Canada-iPolitics-11May2020.pdf.
McDonnell, William M, Douglas S Nelson, and Jeff E Schunk. 2012. “Should We Fear “Flu Fear” Itself?
Effects of H1N1 Influenza Fear on ED Use.” The American Journal of Emergency Medicine 30(2): 275–282.
Merkley, Eric, Aengus Bridgman, Peter John Loewen, Taylor Owen, Derek Ruths, and Oleg Zhilin. 2020.
“A Rare Moment of Cross-Partisan Consensus: Elite and Public Response to the COVID-19 Pandemic
in Canada.” Canadian Journal of Political Science, 1–8.
Moodie, Rosemary, Donna Dasko, Colin Deacon, Peter Loewen, and David TS. Fraser. 2020. “Canadian
Public Support For The Use Of Mobile Phone Data To Fight The Covid-19 Pandemic.” Ottawa: Senate
of Canada. May 7, 2020.
Motta, Matt, Dominik Stecula, and Christina Farhart. 2020. “How Right-Leaning Media Coverage of
COVID-19 Facilitated the Spread of Misinformation in the Early Stages of the Pandemic in the US.”
Canadian Journal of Political Science, 1–8.
O’Neill, Patrick Howell, Tate Ryan-Mosley, and Bobbie Johnson. 2020. “A Flood of Coronavirus Apps
Are Tracking Us. Now It’s Time to Keep Track of Them.” MIT Technology Review May 7, 2020.
https://www.technologyreview.com/2020/05/07/1000961/launching-mittr-covid-tracing-tracker/.
19

Parker, Michael J, Christophe Fraser, Lucie Abeler-Dörner, and David Bonsall. 2020. “Ethics of Instantaneous Contact Tracing Using Mobile Phone Apps in the Control of the COVID-19 Pandemic.” Journal
of Medical Ethics, 1–5.
Peak, Corey M, Rebecca Kahn, Yonatan H Grad, Lauren M Childs, Ruoran Li, Marc Lipsitch, and Caroline O
Buckee. 2020. “Individual Quarantine Versus Active Monitoring of Contacts for the Mitigation of
COVID-19: A Modelling Study.” The Lancet Infectious Diseases, doi.org/10.1016/S1473-3099(20)30361-3.
Pickup, Mark, Dominik Stecula, and Clifton van der Linden. 2020. “Novel Coronavirus, Old Partisanship:
COVID-19 Attitudes and Behaviors in the United States and Canada.” Canadian Journal of Political
Science, 1–10.
Schaller, Mark. 2006. “Parasites, Behavioral Defenses, and the Social Psychological Mechanisms Through
Which Cultures Are Evoked.” Psychological Inquiry 17(2): 96–101.
Schaller, Mark, and Justin H Park. 2011. “The Behavioral Immune System (And Why It Matters).” Current
Directions in Psychological Sscience 20(2): 99–103.
Sevi, Semra, Marco Mendoza Aviña, Gabrielle Péloquin-Skulski, Emmanuel Heisbourg, Paola Vegas,
Maxime Coulombe, Vincent Arel-Bundock, Peter John Loewen, and André Blais. 2020. “Logarithmic
Versus Linear Visualizations of COVID-19 Cases Do Not Affect Citizens’ Support for Confinement.”
Canadian Journal of Political Science, 1–6.
Stanley, Jay, and Jennifer Stisa Granick. 2020. “The limits of location tracking in an epidemic.” American
Civil Liberties Union .
Tavernise, Sabrina, and Richard A Oppel Jr. 2020. “Spit On, Yelled At, Attacked: Chinese-Americans Fear
for Their Safety.” The New York Times, March 23.
Tolley, Erin. 2016. Framed: Media and the Coverage of Race in Canadian Politics. Vancouver: UBC Press.
Van Bavel, Jay J, Katherine Baicker, Paulo S Boggio, Valerio Capraro, Aleksandra Cichocka, Mina Cikara,
Molly J Crockett, Alia J Crum, Karen M Douglas, James N Druckman et al. 2020. “Using Social and
Behavioural Science to Support COVID-19 Pandemic Response.” Nature Human Behaviour pp. 1–12.
Vannette, David L, and Jon A Krosnick. 2014. “Answering Questions: A Comparison of Survey Satisficing
and Mindlessness.” In The Wiley Blackwell Handbook of Mindfulness, ed. Amanda Ie, Christelle T
Ngnoumen, and Ellen J Langer. Chichester: Wiley Blackwell pp. 312–27.
Wise, Toby, Tomislav D Zbozinek, Giorgia Michelini, Cindy C Hagan, and Dean Mobbs. 2020. “Changes
in risk perception and self-reported protective behaviour during the first week of the COVID-19
pandemic in the United States.” Royal Society Open Science 7(9): 200742.
20

Witte, Kim, and Mike Allen. 2000. “A Meta-Analysis of Fear Appeals: Implications for Effective Public
Health Campaigns.” Health Education & Behavior 27(5): 591–615.
WHO. 2020. “Ethical Considerations to Guide the Use of Digital Proximity Tracking Technologies for
COVID-19 Contact Tracing: Interim Guidance.” Technical report. World Health Organization. May 28,
2020.

21

Online Appendix
“Explaining Support for COVID-19 Cell Phone Contact
Tracing”
Ludovic Rheault

Andreea Musulan

Department of Political Science

Department of Political Science

University of Toronto

University of Toronto

Recruitment of Survey Respondents
Our internet survey responses were collected between May 28 and May 29, 2020 using the Cint platform.
Recruitment relied on quota sampling—that is, we used target numbers matching the expected census
distributions for age, gender, and region. Respondents from the territories were not included. The
experimental protocol, including a statement of the theory and hypotheses, was reviewed and approved
by the University of Toronto Research Ethics Board prior to launching the survey (RIS Human Protocol
Number #39375). The questionnaire was made available to respondents in both official languages, and
the French version was written by a native speaker.
Opt-in, online surveys have become increasingly common for academic research with the decline of
previous gold standards in public opinion research, e.g. random digit dialing. This mode of administration
is even considered for major projects such as the Canadian Election Study (Breton et al., 2017). Previous
research suggests that average treatment effects estimated from non-random surveys—the average impact
of a randomized treatment, calculated on the sample—are reliable quantities of interest (Miratrix et al.,
2018; Coppock and McClellan, 2019). Readers should remain wary of inferences involving population
quantities, such as the percentage of the population supporting a given option.
To further assess data quality, we show in Table A1 that the sample provided by Cint is representative
of the Canadian population on demographic variables other than the ones used for the quotas. We
retrieved population proportions from the 2016 Census Profile data. While these data points were
calculated four years ago, they provide a reasonably reliable benchmark to evaluate the sample. The
1

representation of ethnic groups in the sample closely matches that in the population, with the exception
of Indigenous peoples. For most of the demographic groups listed in Table A1, the sample proportions
could have been observed using probability sampling. All told, the quality of the sample is impressive,
and provides a rather accurate representation of the Canadian population.
Table A1: Representativeness of Cint Sample
Demographic variable

Cint sample

2016 census p-values

Ethnicity
Asian

0.177

0.164

0.323

Black

0.024

0.035

0.108

Hispanic or Latino

0.019

0.013

0.148

White

0.770

0.777

0.638

Indigenous

0.010

(0.024)

0.010∗

0.316

0.125

Education
University degree

0.338
Household Income

$0–$14,999

0.074

0.059

0.055

$15,000–$24,999

0.095

0.090

0.593

$25,000–$49,999

0.225

0.247

0.111

$50,000–$79,999

0.242

0.249

0.613

$80,000–$99,999

0.154

0.118

<0.001∗

$100,000–$149,999

0.145

0.155

0.421

$150,000 or more

0.065

0.082

0.052

Notes: All census proportions come from the 2016 Canadian Census Profile tables. Proportions by ethnic group are from the
item “Visible minority for the population in private households,” with the exception of the “Registered and Treaty Indian”
proportion used for the indigenous group, and marked in parentheses. The proportion with a university degree is for the
Canadian population aged 25 and older. The household after-tax income is used for census income groups. The p-values are
for Pearson chi-square tests of difference in proportions with Yates continuity correction. Significant differences indicate that
the proportion is unlikely to be observed with random sampling.
∗
: p < 0.005.

2

Questionnaire and Treatment Vignettes
The survey questionnaire presented to respondents contains five blocks. The first block included pretreatment covariates (the variables labelled “Not Serious Enough” and “Worried” in the main text). The
second block randomly assigned respondents to one of three groups and presented the media framing
vignettes to the two treated subgroups. The third block queried respondents about their opinion toward
cell phone contact tracing; the outcome variable of interest. The fourth block asked additional questions
regarding containment measures. The fifth and final block contained demographic questions.
Figures A1 and A2 display the vignettes used for the two framing treatments administered during
the survey. Each version invited respondents to read the excerpt from a news headline that included the
title, author, picture and lead. The two news articles were selected specifically because they captured the
theoretical concept of interest, and since they had an equivalent version published in French media.
Figure A1: Media Frame Treatment I (Non-Compliers, English)

3

Figure A2: Media Frame Treatment II (Large Infection Rate, English)

4

As explained in the manuscript, we devoted considerable attention to ensure that the question used
to ask respondents about COVID-19 apps remained as neutral as possible. One reason for this was the
existence of conflicting results in previous polls. In the introduction to the main text, we mentioned
the Senate study and the Mainstreet Research poll, two sources of data for public opinion on cell phone
contact tracing that featured in Canadian news media. The phrasing of survey questions differed in
these two studies, which raises the issue of how sensitive public opinion is to question wording. The
Senate study’s query contained a preamble explaining the purpose and benefits of contact tracing apps.
While it provided respondents with background information about the technology, this choice may have
painted the issue in a more positive light. The preamble and question read:
Today’s smart phones have location and proximity tracking capabilities. Used together with
rapid testing capabilities, this technology could help public health professionals to more
rapidly, accurately and completely trace the possible spread of COVID-19. This would allow
them to protect public health and help to better manage the easing of social and economic
restrictions.
If the tracking capabilities of smart phones provided public health officials with the ability to
anonymously and automatically notify all those who have been close to someone who tested
positive for COVID-19, how supportive would you be of using this capability in Canada?
(Moodie et al., 2020, 34).
The Mainstreet Research question, on the other hand, relied on a different language. It contained the
verb “track”, which may have primed the privacy implications of contact tracing apps. The question was:
[...] Please tell us if you think it is acceptable or not: The government asking you to download
an app on your smart-phone to track who you might come into contact with, otherwise
known as contact tracing (?, 13).
It is not clear whether “the government asking you” means making the use of a COVID-19 app mandatory—
a practice currently used in other countries—but some respondents could interpret the query as such.
As discussed in the main text, our study relied on a question that described the app using plain
language, and we avoided to prime the merits versus the risks. To assess the sensitivity of our results
to question wording, we randomly assigned respondents to one of three variants of the same question.
The text appears in the next section. These variations in question wording, however, had no significant
impact on the response.
In the next section we also report the question wording for the variables used in the main text. For the
“Not Serious Enough” and “Worried” variables, we relied on the phrasing used in COVID-19 surveys from
5

the Washington Post and the Center for Democracy and Civic Engagement at the University of Maryland,
to allow comparisons with existing datasets. For the purpose of our analysis, these variables were recoded
to equal 1 for respondents who answered “Not seriously enough” and “Very worried”, respectively, and
0 otherwise. Using the multinomial version of these variables did not affect the substantive conclusions
reported in the text. The “Trudeau Approval” variable is coded 1 for respondents who believe the federal
government did an excellent job handling the pandemic, 0 otherwise. The “Lost Job” variable equals 1
for respondents who reported having lost their job during the pandemic, and 0 otherwise.

Survey Questionnaire
[Not Serious] “During the COVID-19 lockdown, do you think most people have taken social distancing
measures too seriously, not seriously enough, or are most people striking the right balance?”
• “Not taking seriously enough”
• “Striking the right balance”
• “Taking too seriously”
[Worried] “How worried, if at all, are you about close family members or friends becoming infected
and seriously ill from the coronavirus?”
• “Very worried”
• “Somewhat worried”
• “Not worried”
[COVID Apps (Base Wording)] “Many COVID-19 apps are being used around the world to notify people
who were in contact with someone infected (contact tracing apps). These apps record the interactions
between users by detecting when two cell phones are close to each other.
These apps require the participation of health agencies to confirm who tested positive for COVID-19.
Do you support the government’s participation in a COVID-19 contact tracing app?”
• “Yes”
• “Yes, but only if using the app is voluntary”
• “No”
[COVID Apps (Health Agency Wording)] “Many COVID-19 apps are being used around the world to
notify people who were in contact with someone infected (contact tracing apps). These apps record the
interactions between users by detecting when two cell phones are close to each other.
These apps require the participation of health agencies to confirm who tested positive for COVID-19. In
6

most cases, COVID-19 apps are designed to notify health agencies when someone was in contact with
an infected individual.
Do you support the government’s participation in a COVID-19 contact tracing app?”
• “Yes”
• “Yes, but only if using the app is voluntary”
• “No”
[COVID Apps (Dilemma Wording)] “Many COVID-19 apps are being used around the world to notify
people who were in contact with someone infected (contact tracing apps). These apps record the
interactions between users by detecting when two cell phones are close to each other.
These apps require the participation of health agencies to confirm who tested positive for COVID-19.
Some people claim that COVID-19 apps may pose a risk to fundamental rights, such as the right to
privacy. Others claim these apps are needed to help reopen the economy while protecting public health.
Do you support the government’s participation in a COVID-19 contact tracing app?”
• “Yes”
• “Yes, but only if using the app is voluntary”
• “No”
[Open-Ended] “We would like to understand public opinion about COVID-19 apps. Could you please
give us the main reason for your previous answer, in one or two sentences, using the box below.”
[Trudeau Approval] “How would you rate the Canadian government’s overall response to the coronavirus outbreak?”
• “Excellent”
• “Good”
• “Not so good”
• “Poor”
[Lost Job.] “Have you lost your job due to the COVID-19 lockdown?”
• “Yes”
• “No, but my hours were reduced”
• “No”
• “Not applicable/I did not work/I am retired”

7

Extended Results
Table A2 reports the full results for the logistic regression models used to calculate the differences in
predicted probabilities reported in Figure 3 of the main text. The differences in predicted probabilities
are averaged across all respondents after leaving all other covariates at their observed values. While the
trend in experimental research is to model average treatment effects with linear regression, we should
point out that the conclusions are the same using linear probability models.
Table A3 shows the full models used to create Figure 4 in the main text, where the outcome variables
are two types of argument mentioned in the answers to the open-ended question on COVID-19 cell
phone contact tracing apps. Once again, we used logistic regression models and the figure in the main
text reports differences in predicted probabilities for a change from 0 to 1 in each independent variable,
leaving other variables in the sample at their observed values. The effect sizes are virtually the same as
coefficients from linear regression models. Note that the treatment effects on the other argument types
are not statistically significant.
Finally, we report alternative specifications of the main models used to measure treatment effects in
Figure 3. Table A4 shows the output from regression models without covariates, as well as a specification
including an indicator of general support for “tougher” policies, which is an additive composite of four
other survey questions asking respondents whether they support 1) mandatory facial masks in public
transit, 2) the use of infrared cameras in public spaces, 3) mandatory COVID-19 testing in the workplace,
and 4) stronger fines for people violating quarantine rules. In all cases, the dependent variable is the
binary indicator of unconditional support for COVID-19 apps. These alternative specifications produce
results that are consistent with those reported in the main text, although the effect of the “Not Serious
Enough” covariate is not statistically significant.

8

Table A2: Explaining Support for COVID-19 Cell Phone Contact Tracing (Full Results)
COVID-19 Contact Tracing Apps = Yes
Unweighted

Weighted

Wording Control

(1)

(2)

(3)

Non-Compliers

0.388
(0.156)

0.425
(0.159)

0.429∗∗
(0.160)

Large Infection Rate

−0.022
(0.154)

0.027
(0.158)

0.027
(0.158)

∗

∗∗

Dilemma Wording

0.066
(0.155)

Health Agency Wording

−0.113
(0.158)

Not Serious Enough

0.385∗∗
(0.129)

0.383∗∗
(0.132)

0.379∗∗
(0.132)

Worried

0.859∗∗∗
(0.131)

0.903∗∗∗
(0.134)

0.902∗∗∗
(0.134)

Trudeau Approval

0.860∗∗∗
(0.169)

0.824∗∗∗
(0.171)

0.819∗∗∗
(0.171)

Lost Job

0.126
(0.169)

0.057
(0.176)

0.049
(0.177)

Above 56 Years Old

0.197
(0.135)

0.204
(0.138)

0.205
(0.138)

Female

−0.179
(0.126)

−0.207
(0.129)

−0.211
(0.129)

Atlantic (Base = Ontario)

−0.528∗
(0.264)

−0.556∗
(0.271)

−0.551∗
(0.272)

British Columbia (Base = Ontario)

−0.169
(0.202)

−0.115
(0.208)

−0.111
(0.209)

Prairies (Base = Ontario)

−0.050
(0.177)

−0.054
(0.181)

−0.046
(0.181)

Québec (Base = Ontario)

0.178
(0.166)

0.223
(0.167)

0.224
(0.167)

−1.237∗∗∗
(0.181)

−1.264∗∗∗
(0.185)

−1.247∗∗∗
(0.204)

1,200

1,200

1,200

Constant

Observations

Notes: The table shows the full output of logistic regressions used to compute the differences in predicted probabilities
reported in Figure 3 of the main text. The dependent variable equals 1 if the respondent supports COVID apps
unconditionally, and 0 otherwise. The first model is unweighted. The last two models are computed using raking weights for
interlocking quotas by age, gender and region. ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001

9

Table A3: Determinants of Arguments on COVID-19 Apps (Full Results)
Others as a Threat

With Conditions

(1)

(2)

Non-Compliers

0.512
(0.221)

0.101
(0.191)

Large Infection Rate

−0.137
(0.235)

0.364∗
(0.180)

Not Serious Enough

1.088∗∗∗
(0.192)

−0.138
(0.157)

Worried

0.712∗∗∗
(0.186)

−0.784∗∗∗
(0.176)

Trudeau Approval

0.138
(0.236)

−0.286
(0.218)

Lost Job

−0.225
(0.264)

0.227
(0.199)

Above 56 Years Old

−0.084
(0.198)

0.114
(0.158)

Female

0.727∗∗∗
(0.189)

0.375∗
(0.150)

Atlantic (Base = Ontario)

−0.708
(0.369)

0.464
(0.269)

British Columbia (Base = Ontario)

−0.818∗
(0.323)

0.039
(0.231)

Prairies (Base = Ontario)

−0.604∗
(0.266)

0.161
(0.212)

Québec (Base = Ontario)

−0.432
(0.246)

−0.260
(0.205)

−2.940∗∗∗
(0.271)

−1.437∗∗∗
(0.216)

1,200

1,200

∗

Constant

Observations

Notes: The table shows the full output of logistic regressions used to compute the differences in predicted probabilities
reported in Figure 4 of the main text. The dependent variable equals 1 if the respondent invoked the argument indicated in
the column header, and 0 otherwise. The models are computed using raking weights for interlocking quotas by age, gender
and region. ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001

10

Table A4: Alternative Specifications (Treatment Effects)

Non-Compliers
Large Infection Rate

Linear

Linear

Logistic

Logistic

(1)

(2)

(3)

(4)

0.076
(0.036)

∗∗

0.098
(0.033)

0.317
(0.151)

0.467∗∗
(0.167)

−0.0004
(0.035)

0.016
(0.032)

−0.002
(0.151)

0.057
(0.165)

∗

∗

Dilemma Wording

0.011
(0.032)

0.049
(0.162)

Health Agency

−0.021
(0.032)

−0.126
(0.166)

Tougher Policy Support

0.109∗∗∗
(0.010)

0.637∗∗∗
(0.078)

Not Serious Enough

0.030
(0.029)

0.161
(0.139)

Worried

0.161∗∗∗
(0.031)

0.742∗∗∗
(0.141)

Trudeau Approval

0.151∗∗∗
(0.038)

0.706∗∗∗
(0.177)

Lost Job

−0.012
(0.037)

−0.073
(0.188)

Above 56 Years Old

−0.009
(0.029)

−0.051
(0.140)

Female

−0.048
(0.026)

−0.247
(0.135)

Atlantic (Base = Ontario)

−0.106∗
(0.050)

−0.509
(0.280)

British Columbia (Base = Ontario)

−0.015
(0.043)

−0.058
(0.224)

Prairies (Base = Ontario)

0.030
(0.038)

0.147
(0.193)

Québec (Base = Ontario)

0.058
(0.035)

0.288
(0.174)

Constant

Observations

0.355∗∗∗
(0.025)

−0.063
(0.045)

−0.598∗∗∗
(0.109)

−3.063∗∗∗
(0.315)

1,200

1,200

1,200

1,200

Notes: Alternative specifications using the unconditional support for COVID-19 apps as the binary outcome variable. All
models are computed using raking weights. ∗ p<0.05; ∗∗ p<0.01; ∗∗∗ p<0.001

11

Content Analysis
In this section, we report the coding scheme used to annotate the written answers to the open-ended
question on COVID-19 contact tracing applications. The comments were annotated independently by
three coders.
The coding scheme was created a priori (i.e. before commencing the manual annotation of comments)
and is based on theory. The arguments against COVID-19 apps (concerns for privacy, the need to impose
conditions, doubts about the effectiveness, and dismissal of the threat) were all part of the public debate
and prominent in the literature cited in the main text. The arguments in favour of COVID-19 apps were
selected according to our theory. The three categories are meant to measure whether the respondent’s
considerations are oriented toward society (“Societal Concerns”), the threat posed by others (“Others as a
Threat”) or the application itself (“App is Effective”). In particular, the second category is the mechanism
expected in the disease avoidance hypothesis, whereby individuals come to support the app because of
the threat posed by other groups, either the infected themselves or people whose behaviour pose a risk
of contagion.
Our coding scheme originally included a separate category for supportive arguments evoking
economic concerns—the need for a contact tracing app to help reopen the economy. However, that
argument was seldom evoked by respondents, and we ultimately merged it with the “Societal Concerns”
category for simplicity of presentation. The third coder used the coding scheme with seven substantive
categories from the start.
The coding scheme below corresponds to the document used as instructions for the classification of
comments. Each category is binary. The classification is not mutually exclusive: for each comment, we
indicate if an argument is present or not. As a result, some comments may include more than one of the
arguments from the coding scheme. Some respondents also expressed their ambivalence and explicitly
mentioned arguments for and against the use of COVID apps.
Coding Scheme
What are the considerations/arguments emphasized by the respondent to explain their position regarding
cell phone contact tracing apps? For each comment, check all categories that apply.
1. Risk for privacy; impact on civil liberties
e.g. the app infringes on privacy; app violates civil liberties; government may use the data to track
people
(“Civil Liberties” in Table 1)
2. The app must be restricted in scope; conditions must be in place
e.g. the app must be voluntary; only a part of the population should be required to use it;
12

government must guarantee the app won’t be used after the pandemic
(“With Conditions” in Table 1)
3. The app will not work
e.g. not everyone has a phone; people may just stop carrying their phone; other methods are more
useful
(“Not Going to Work” in Table 1)
4. The threat isn’t real
e.g. the media/government exaggerated the threat of the virus; COVID is a conspiracy
(“Threat Is Not Real” in Table 1)
5. Social benefits (societal considerations)
e.g. we must protect the vulnerable; we need to stop the virus; we need to reopen the economy;
public health is more important than anything else
(“Societal Concerns” in Table 1)
6. Other people are a source of risk (focusing on others as a threat)
e.g. people not following the rules pose a threat; app is needed because people won’t quarantine;
we need to know where infected people are; we need to avoid hot spots
(“Others as a Threat” in Table 1)
7. The app is useful (considerations focusing on the app itself)
e.g. it’s an effective technology, the app will give useful information, the app worked well in other
countries
(“App is Effective” in Table 1)
8. Not applicable (other arguments)
When the text makes another type of argument that does not fit any of the categories.
9. No response
Non-response (blank text box) or gibberish comment.
The three human coders annotated all English language comments (978) and the average Cohen’s
Kappa coefficients (Cohen, 1960) are calculated on that common sample. The final categories used for
analysis are based on the majority choice for English language comments. Two out of the three coders
annotated the French language comments; the few cases of disagreement were resolved manually by
discussion among the two coders. To further assess the robustness of our results, we replicated the
analysis reported in the main text using a unanimity rule for English language comments (i.e. an argument
13

is considered to be present in the written answer only if all three coders agree). The findings remain
consistent to those reported in the main text when using the unanimity rule (in fact, the confidence in
our inferences improves slightly when using unanimity).

References
Breton, Charles, Fred Cutler, Sarah Lachance, and Alex Mierke-Zatwarnicki. 2017. “Telephone versus
Online Survey Modes for Election Studies: Comparing Canadian Public Opinion and Vote Choice in
the 2015 Federal Election.” Canadian Journal of Political Science 50(4): 1005–1036.
Cohen, Jacob. 1960. “A Coefficient of Agreement for Nominal Scales.” Educational and Psychological
Measurement 20(1): 37–46.
Coppock, Alexander, and Oliver A McClellan. 2019. “Validating the demographic, political, psychological,
and experimental results obtained from a new source of online survey respondents.” Research & Politics
6(1): 1–14.
Mainstreet Research. “Survey of Canada.” Canada iPolitics, May 11, 2020. https://ipolitics.ca/wpcontent/uploads/2020/05/Canada-iPolitics-11May2020.pdf.
Miratrix, Luke W, Jasjeet S Sekhon, Alexander G Theodoridis, and Luis F Campos. 2018. “Worth
weighting? How to think about and use weights in survey experiments.” Political Analysis 26(3):
275–291.
Moodie, Rosemary, Donna Dasko, Colin Deacon, Peter Loewen, and David TS. Fraser. 2020. “Canadian
Public Support For The Use Of Mobile Phone Data To Fight The Covid-19 Pandemic.” Ottawa: Senate
of Canada. May 7, 2020.

14

