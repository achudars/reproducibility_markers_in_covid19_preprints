Locked Down or Locked In? Institutionalized Public Preferences and
Pandemic Policy Feedback in 32 Countries

Hung H.V. Nguyen*,

0000-0001-9496-6217, hunghvnguyen@gmail.com

Nate Breznau*

0000-0003-4983-3137

Lisa Heukamp*

0000-0002-6381-7099

*University of Bremen
Forthcoming in Social Policy Review, Volume 33

Abstract
The Novel Coronavirus Pandemic provides a unique opportunity to test theories of policy
feedback in times of national emergency. An important question in this field is whether the
discrepancy between public attitudes and emergency rules makes ordinary citizens less likely
to comply, which in turn can undermine the goals of that national emergency policies such as
the recent lockdown. In this study, we first compare 2016 institutionalized non-Covid related
public preferences for government intervention to government actions taken at the outbreak of
this pandemic in early March 2020 across 32 middle to high income countries, using aggregated
data from the International Social Survey Program and country-level Blavatnik Coronavirus
Government Response Tracker data. Then, we use the relative discrepancy between them to
predict public behaviors shortly after the initial outbreak in late-March into early April using
the Measuring Worldwide COVID-19 Attitudes and Beliefs survey. We find no association
between public preferences and government response at the outbreak; however, we find some
tentative evidence that the discrepancy between them shows a relationship with public
behaviors in the subsequent stage, after adjusting for the local severity of the outbreak and the
current level of government intervention. Where the government took much stronger
interventions in the outbreak stage relative to public preferences for non-Covid government
interventions, the public were more likely to engage in risky social behaviors, such as going
out when asked not to, attending social gatherings, or not keeping a safe distance from others.
In contrast, where the government took weaker measures, the public were instead more likely
to avoid risky social behaviors. Although we cannot conclude whether this means that the
enforced measures were more or less effective, our results may suggest that governments took
stronger measures in countries where they expected more risky behaviors and that there may
be a tradeoff between institutionalized public preferences and the ability to curtail social
behaviours.

Keywords: COVID-19, public preferences, public policy, policy feedback, public behaviors,
government intervention, public opinion.

Introduction
The Novel Coronavirus Pandemic is the most severe worldwide public health crisis
since the ‘Hong Kong Flu’ in the late 1970s1. According to the John Hopkins Coronavirus
Resource Center, the number of confirmed deaths worldwide from COVID-19 by December
2020 surpassed 1.5 million. Already at its outbreak, this rapidly spreading virus tested the limits
of governance. On the one hand, in a pandemic the strength and speed of government responses
prevents infection and saves lives (Wilder-Smith, Chiew and Lee, 2020). On the other, the
public will only tolerate so much government ‘lockdown’ and engage in behaviors that cause
political turmoil and increase infections in response. Most theories of governance suggest that
government actors respond to public opinion when making public policy. Therefore, we
explore if variation in response to this pandemic met public preferences, and if not, whether it
led to risky public behaviors.
Governments around the world varied in the timing and severity of measures such as national
lockdowns, imposing curfews, and contact tracing. Surprisingly, strict lockdowns early in this
pandemic often led the public to become more supportive of the incumbent government and
democratic institutions (Baekgaard et al., 2020; Bol et al., 2020; Reeskens et al., 2020),
something known as the “rally around the flag” effect. However, after some time, more and
more members of the public began acting against government regulations by refusing to wear
masks, holding social gatherings, or even engaging in mass protests. We question how much
of these anti-lockdown behaviors can be explained as a result of policy feedback from
governments’ initial responses to the pandemic.
In a basic policy responsiveness model, governments act as representatives of the public and
thus should formulate policies that follow public expectations (Page and Shapiro, 1983;
Stimson, Mackuen and Erikson, 1995; Wlezien, 1995; for example: Manza and Cook, 2002).
From an institutional theory perspective, path dependency suggests that governments are
unlikely to engage in policymaking that is far removed from what the public expect (Pierson,
2004; Rasmussen, Reher and Toshkov, 2019), as the cost is simply too high from an electoral
maximization and practical standpoint (Huber and Powell, 1994; Adams et al., 2004, 2006;
Adams, 2012). At the same time, policy shapes public opinion leading some to propose that
opinion and policy operate in equilibrium with one another, which creates feedback keeping
things on a stable trajectory (Jones and Baumgartner, 2012; Breznau, 2017).
The conventional link between public preferences and what policymakers do, however, might
be interrupted in a pandemic due to imminent threats to human lives. This would explain the
rallying of the public in support of the government at first, even though government policies
severely limited their freedoms and rights. Given the preceding discussion of how opinion and
policy are theoretically related, we expect that after the initial outbreak the public will begin to
express their dissatisfaction as a function of what they normally see as acceptable government

1

https://www.cdc.gov/flu/pandemic-resources/1968-pandemic.html

intervention policies. Therefore, if public preferences are deeply institutionalized in opposition
to government intervention into people’s freedoms, but the government takes severe and longlasting lockdown measures, the public will react negatively – either by simply refusing to
follow the measures or engaging in political actions such as protests. This is a prediction of
institutional theories of public preferences about what happens when governments encroach
upon them by taking away longstanding rights such as social security (Pierson, 1994). If true,
this could explain why many democratic countries still struggle to convince or enforce some
member of the public to follow guidelines such as wearing masks, even when such guidelines
are supported by scientific evidence (Prather, Wang and Schooley, 2020).
To test the link between embedded public preferences and government response we investigate
two stages of this pandemic. In the Outbreak Stage in the first half of March2, we expect
governments to have reacted fiercely, implementing freedom-restricting measures that would
go against most public preferences. This might have led to a temporary disconnection between
long standing public preferences and public policy. After the initial shock of the outbreak, a
Public Reaction Stage followed where people experienced fatigue from what they perceived as
harsh restrictions or gradually lost trust in the effectiveness of government restrictions, as
observed in both Germany and the UK (Colfer, 2020; Naumann et al., 2020). We expect such
negative affect among the public to be a function of the discrepancy between government
responses and what the public normally deem appropriate. Therefore, we discuss this
discrepancy as leading to two potentially opposing outcomes in public reaction that should
follow in this phase. On the one hand, the public may react in opposition to the discrepancy
creating negative feedback and potentially undermining the government’s response. When
governments restrict freedom less than the public normally prefer, people would fill in the
missing role of the government and protect themselves by taking additional precautions. In
contrast, in societies where government measures are stricter than the public normally prefer,
people become dismayed and disobedient, resulting in less cautious activities. This is a form
of self-undermining feedback (Jacobs and Weaver, 2015).
On the other hand, the public may react in concordance to the gap creating positive feedback.
Following a policy feedback perspective (Pierson, 1993; Soroka and Wlezien, 2010), if
governments take weaker measures than the public are institutionally conditioned to prefer,
people might develop a false sense of security and take weaker measures themselves. This may
explain why death tolls early on in some northern European countries were so high, while the
public rebellion and concerns were so low (Breznau, Heukamp and Nguyen, 2020). In a similar
fashion, people seeing their governments taking actions more critically than expected might
also become more prudent, virus-conscious, and less likely to engage in risky behaviors. From
this perspective, stronger government intervention would be self-reinforcing.
Our policy feedback logic suggest that public responses could support or undermine pandemic
policies. Therefore, we leave these aforementioned competing hypotheses open for empirical

2

Death cases started to grow exponentially from March (see Breznau, 2020).

investigation. What is crucial here is that these public reactions should occur net of the actual
severity of the outbreak and whether early interventions worked well, which varied widely
across countries (Colfer, 2020). Figure 1 visualizes our theoretical model.
Figure 1. Theoretical Framework. Source: drawn by the authors.
Outbreak Stage

Government
Intervention

Public
Preferences

Discrepancy
Public Reaction Stage
Negative
Feedback

Undermining
behaviors

Positive
Feedback

Reinforcing
behaviors

Note: In the Outbreak Stage, government intervention is a function of public preferences. In the Public
Reaction Stage, the gap between government intervention and public preferences, measured as the residual
error, should explain one of two outcomes: self-reinforcing (positive) feedback or self-undermining (negative)
feedback on public behaviors.

Data and Methods
All code, data and replication materials available in our Project Repository3.
Data selection
The beginning of March is when the Pandemic emerged as a global emergency and
governments everywhere took measures in response (Breznau, 2020). We accordingly
conceive of the Outbreak Stage from March 1 to March 15 and the Public Reaction Stage that
follows from March 20 to April 7. We assume by the latter stage the public have adjusted to
the initial shock and begun evaluating the adequacy of their government’s initial response. Our
selection of time periods is also somewhat determined by the data. First, our measure of public
behaviors is only globally available after mid-March; secondly, it comes from survey questions
asking about respondents’ behaviors in “the past week”, necessitating a lag between the two
stages.
Public preferences
We are aware of only one possibility to measure public preferences for government
intervention into personal liberties that has a broad sample of countries. That is the
International Social Survey Programme (ISSP) which asked three new questions in 2016 about
the government’s right to encroach on personal freedoms and privacy “in the name of national
security” or “for the sake of public security”.
They are (in verbatim English):
- Do you think that the [COUNTRY] government should or should not have the right to do the
following: Keep people under video surveillance in public areas?
- Do you think that the [COUNTRY] government should or should not have the right to do the
following: Monitor e-mails and any other information exchanged on the Internet?
- Some people think that governments should have the right to take certain measures in the
name of national security. Others disagree. Do you think that the [COUNTRY] government
should or should not have the right to do the following: ...collect information about anyone
living in [COUNTRY] without their knowledge?
Although there were no questions on a pandemic specifically, these three offer insights into
abstract and normative principles analogous to policies governments implemented at the early
stages of this pandemic that infringed on personal liberties for a greater public good, namely
regional, and national lockdowns, contact tracing, or prohibition of public gatherings. With

3

https://github.com/hungnguyen167/SPR33-COVID

these data, there are 32 mostly middle to high income countries for comparison (exact countries
shown in Figure 2 and Figure 3).
Apart from the abovementioned, there are other questions on public/national security but they
either involve collecting information of people living outside of the country or suspected
terrorist acts. These questions fall outside the national context or are too specific for our
research. The same can be said for batteries of questions regarding government spending or
government responsibilities; although social insurance and basic welfare provisions are
interventions into individual lives, they do not inhibit personal freedoms as with a pandemic
‘lockdown’.
We do not take a strong stance on measurement here, as in whether individuals in a public do
or do not have a single latent opinion regarding the rights of the government to intervene in
their freedoms and private lives. We are certain that these are highly salient issues to the public
given some of the violent acts and protests we witnessed worldwide in response to lockdown
measures, or even reactions to simple facemask regulations in stores or on public transportation
(Pavlik, 2020). An extensive search using Google Scholar revealed that although the Design
Group of the 2016 ISSP had good reasons to include these new questions (Edlund and Lindh,
2019), no scholars have yet taken the time to investigate their scaling properties. We thus
conduct our own confirmatory factor analysis (CFA), finding reasonable metric invariance
across the 32 countries (see Table A1 in the Appendix). Crucially, they have ostensible face
validity as reflective indicators of government intervening in personal freedoms. The resulting
fit measures point toward invariance that we deem appropriate for our purposes (CFI = 0.968,
TLI = 0.950, RMSEA = 0.086); again, the substantiation of a single latent reflective
psychometric indicator was not our goal4. We used this model to create a new variable called
“Public Preferences” which contains the predicted factor scores from the three indicators. This
provides us the independent variable measuring embedded public preferences in the Outbreak
Stage (see Figure 1). For this index, higher values indicate more support of government
intervention.
Deaths per million
We assume one of the core predictors in both stages is the local severity of the pandemic. In
the Outbreak Stage, governments should have responded directly to the seriousness of the
situation, which should also have shaped public behaviors in the Public Reaction Stage.
Accordingly, we measure this local severity using the country-level number of confirmed
Deaths per million due to COVID-19 in each period, respectively. We opt to use it here because
it causes subjective severity perceptions amongst publics and governments: it was a key piece
of information available to both apart from mixed predictions from scientists at the time.

4

Modification indices suggested that one country (Chile) had residual covariances that were extreme outliers for
unknown reasons. We freed these and the RMSEA decreased by 0.006.

Moreover, it is a measure that is more directly comparable across countries, unlike COVID-19
confirmed cases or infection rate measures.
Government intervention
We measure government response to the pandemic, which we label “Government
Intervention”, using the COVID Stringency Index (also known as the Oxford COVID-19
Government Response Tracker), created and maintained by a team of researchers from the
Blavatnik School of Government at the University of Oxford (Hale et al., 2020). Data are
publicly available on the project’s GitHub page as well as on the Our World in Data website.
This project collects 17 different indicators of government responses to the pandemic, ranging
from economic to containment and health measures. As the predictor in this case revolves
solely around containment issues (lockdowns, contract tracing, etc.), we take the Containment
and Health Index in lieu of the general Stringency Index because they are a subset of variables
that link directly to personal freedoms. We create two versions of the index as the respective
averages from each period standardized. The former is our dependent variable in the Outbreak
Stage. The latter is a crucial control variable in the Public Reaction Stage because public
behaviors are limited by current laws and because we observe a large increase in stringency
between the stages (see Figure A1 in the Appendix). To assess the validity of our hypothesized
lag, we also take a mean index for the period from March 1 to March 19 as a sensitivity analysis.
Discrepancy score
To capture the gap between Public Preferences and Government Intervention we create a
“Discrepancy Score” as the standardized difference between the two. This is our main test
variable. Like most research on public preferences, we cannot know exactly how much
intervention a public want from their government. Therefore, we can only identify relative
public preferences based on the average across countries, and then compare deviations from
this average to deviations from the average government intervention. As a result, a larger value
in either direction indicates that Government Intervention was further away from the crosscountry average of Public Preferences. We also explore the idea of a categorical difference
between negative and positive relative discrepancies by dichotomizing this score. In our very
first theoretical test model, we calculated this score while adjusting for Deaths per million, but
subsequent tests revealed that this introduced an endogeneity problem, so we abandoned this
model in favor of the simple subtraction method.
Public behaviors
For public behaviors in the Public Reaction Stage, we employ the Global Behaviors and
Perceptions in the COVID-19 Pandemic data set, published by a team of researchers from
various institutions (Fetzer et al., 2020). This is a large-scale internet survey which received
answers from 175 countries from March 20 to April 7, 2020. The original study attempted to
offer weights, but it seems they are not available for all cases or in all countries, so we opt not
to use them. The sample over-represents younger, more educated, higher income and more
frequent internet users; the limitations of which we discuss in the conclusion. In this survey,
we identify three questions that ask about preventative social behaviors of respondents in the

past week, including staying at home, not attending social gatherings, and keeping a safe
distance of two meters with others. We leave out other available questions because they ask
about private activities such as washing hands and reporting symptoms. Respondents use a
slider to reflect how frequent they practiced each of the said actions on a scale from 0 – 100.
The exact wordings of the questions (in verbatim English) are:
To what extent do the following statements describe your behavior for the past week?
- I stayed at home.
- I did not attend social gatherings.
- I kept a distance of at least two meters to other people.
Following a similar procedure as with the ISSP data we find reasonable standardized factor
loadings for the baseline CFA model (Table A2) and goodness-of-fit indices for the metric
invariance model with the three questions (CFI = 0.972, TLI = 0.957, RMSEA = 0.078)5. We
created a new variable called “Public Behaviors” using predicted factor scores. This variable
was subsequently aggregated to the country-level.
Control variables
Besides the main variables, we also control for other country-level factors. They are economic
development, measured as GDP per capita in thousands of US Dollars, disposable income
inequality (Gini), and social spending as a percentage of GDP.
Table 1 gives basic descriptive statistics of all key variables discussed above, as well as other
control variables in our subsequent regression models. Scatterplots with correlation
coefficients for the main variables are shown right below (Figure 2). The left plot shows the
bivariate relationship of Public Preferences and Government Intervention in the Outbreak
Stage. The right scatterplot visualizes the relationship of this Discrepancy Score and Public
Behaviors in the Public Reaction Stage; to remind the reader, this is where we did not expect
to find a relationship but were asked by a reviewer to provide these visuals.

5

We once again ran several checks on error covariances and found that if we allowed residual variances of stay
and gather in Sweden to covary, RMSEA would be significantly improved (down to 0.061). As measurement is
not our substantive interest, we avoid further freeing of parameters to try to meet some arbitrary cutoff preferred
by reviewers as this would basically amount to p-hacking and provide no scientific utility.

Table 1. Descriptive statistics of key variables.
Variable

N

Mean

SD

Min

Max

Public Preferences

32

3.07

0.44

2.32

4.08

Deaths per million
- Outbreak Stage

32

0.14

0.26

0

0.93

Deaths per million
- Public Reaction Stage

32

13.34

28.83 0.03

131.74

Government Intervention
- Outbreak Stage

32

0.06

0.95

-2.22

3.05

Government Intervention
- Public Reaction Stage

32

0.02

1.01

-2.34

1.99

Discrepancy Score

32

0

0.95

-2.29

2.91

Discrepancy Score
(dichotomized)

32

0.44

0.5

0

1

Public Behaviors

32

-0.03

1.02

-2.57

1.1

GDP (k$) per capita

32

33.45

22.39 2.1

81.99

Disposable Income Inequality
(Gini)

32

33.17

7.75

23.3

57.5

Social Spending (% of GDP)

32

18.07

7.86

2.2

31.68

Figure 2. Scatterplots with correlation coefficients of selected variables.

Research Design
Outbreak Stage: Alignment between institutionalized public preferences and government
intervention?
We start our analysis by predicting Government Intervention with Public Preferences using
OLS regression in the Outbreak Stage (M11). In the next models, M12 to M15, we gradually
include our control variables as potential confounders, starting with Deaths per million.
Public Reaction Stage: Does the discrepancy between expectation and reality predict public
behaviors?
In the second phase of the analysis, Discrepancy Score is the main predictor of Public
Behaviors (M21). Again, this Discrepancy Score is the difference between predicted
Government Intervention and observed values of Government Intervention in the Outbreak
Stage. We then add in Government Intervention and Deaths per million in the Public Reaction
Stage as the other main test variables (M22 and M23). The point of including both Government
Intervention and Discrepancy Score is to see how the gap between public preferences and
actual stringency of government measures influences public behaviors net of current level of
intervention and the severity of the pandemic. M24 – M26 then contain the other control
variables in the same order as in the first stage.
Next, we check whether positive and negative discrepancies are qualitatively different
phenomena by recoding the Discrepancy Score to be binary (one for positive scores and zero
otherwise) for another round of regression models (Table A3 in the Appendix). Although we
believe it takes time for the public to react, we also test a scenario without a time lag between
stages. For this, we recode the Outbreak Stage from March 1 to March 19 and keep the Public
Reaction Stage from March 20 to April 7 for sensitivity models M41 – M46 in Table A4

(Appendix). Finally, we remove an influential data point detected using the Cook’s distance6
on M24, namely Croatia, from the data set and re-run the main models (M21 – M26) to learn
whether results are potentially distorted by it. These models are found in Table A5.
Results
Outbreak Stage
Regression results suggest the government did not react to institutionalized public preferences
in the Outbreak Stage, as we expected. In other words, the coefficient for Public Preferences
is near zero (see Table 2) and has a wide confidence interval (p-value = 0.75). Deaths per
million is the major predictor of Government Intervention with a statistical effect significantly
different from zero with at least a 95% confidence interval. The effect is moderate-to-large.
For every one additional death per million, government measures are more stringent by 1.49
standard deviations (standardised beta = 0.41). We could explain around 25% (R2 equals 0.250
in M15) of the variance in Government Intervention. The implicit assumption in this approach
is that the remaining 75% unexplained variance is ‘random’ in the sense that it is not causally
associated with the variables on the ‘right-hand’ side of our regression equation. Our main
focus and finding is then the non-existent statistical association between public preferences and
government intervention.

Although none of the data point has a Cook’s distance statistic larger than 1, Croatia stands out from the rest and
has a value larger than the 4/n threshold, as suggested in the literature (Heiberger and Holland, 2015).
6

Table 2. OLS Regressions Predicting Government Intervention using Public Preferences,
Outbreak Stage, March 1 - March 15, 2020, 32 Countries
M11
Predictors

Estimates

M12
Estimates

M13
Estimates

M14
Estimates

M15
Estimates

Intercept

0.43

0.24

0.85

2.15

2.20

Public Preferences

-0.12

-0.12

-0.06

0.02

0.07

1.38 **

1.25 *

1.44 **

1.49 **

-0.02

-0.05 *

-0.05 *

-0.04

-0.03

Deaths per Million
Disposable
Income
Inequality (Gini)
Social Spending
GDP (k$, per capita)

-0.01

Observations

32

R2 / R2 adjusted

0.003 / - 0.151
0.030
0.093

* p<0.1 ** p<0.05 *** p<0.01

32

32

32

32

/ 0.186
0.099

/ 0.242
0.130

/ 0.250
0.106

/

Public Reaction Stage
Results of main models in Table 3 suggest that the public are more likely to engage in risky
behaviors as the relative discrepancy between what they prefer and what their government did
in response to the outbreak gets larger. In particular, the coefficient for the Discrepancy Score
is negative and significantly different from zero at 95% confidence. The effect is moderately
sized at -0.38 reflecting a beta coefficient of -0.35 in the most parsimonious model (M24; AIC
equals 84.099). There are two caveats for readers at this point. First, such an effect is put in the
context of a strong, positive effect of current Government Intervention on Public Behaviors,
meaning people generally practice safety measures more frequently in societies with stricter
measures, even after having controlled for the severity of the outbreak and other comparative
socio-economic measures. Second, in the vanilla model where there is only one predictor –
Discrepancy Score (M21; also see Figure 2, third scatterplot), the effect is both weak and nonsignificant, and the R-squared statistic is significantly lower (0.012). We only start to witness
a robust effect of Discrepancy Score after introducing Deaths per million into the models (M23
– M26). Theoretically speaking, the relative Discrepancy Score as an abstract concept,
resulting from a latent construct (Public Preferences), should not be a predictor of Deaths per
million. Similarly, Deaths per million in the Public Reaction Stage cannot cause Discrepancy
Score due to timing (the former took place later). Statistically, the correlation between the two
is not significant and close to 0 (0.09), rejecting the possibility of Deaths per million being a
collider/confounder7. Therefore, the best way to explain this phenomenon is that the datagenerating process would not be complete without controlling for both current Government
Intervention and Deaths per million as they are the more obvious predictors of Public
Behaviors.

7

Likewise, the correlation coefficient between Government Intervention in the Public Reaction Stage and
Discrepancy Score is not significantly different from zero.

Table 3. OLS Regressions Predicting Public Behaviors in the Public Reaction Stage (March
20 - April 7) with Discrepancy Score from the Outbreak Stage (March 1 - March 15), 32
Countries.
M21
Predictors

M22

M23

M24

M25

M26

Estimates Estimates Estimates Estimates Estimates Estimates

Intercept

-0.03

-0.04

-0.19

0.81

-0.07

-0.44

Discrepancy Score - -0.12
Outbreak Stage

-0.27

-0.30 *

-0.38 **

-0.36 **

-0.38 **

Government
Intervention - Public
Reaction Stage

0.58 ***

0.58 ***

0.65 ***

0.66 ***

0.72 ***

0.01 **

0.01 *

0.01

0.01

-0.03

-0.02

-0.01

0.02

0.01

Deaths per Million
Disposable
Inequality

Income

Social Spending
GDP (k$, per capita)

0.01

Observations

32

32

R2 / R2 adjusted

0.012 / - 0.315
0.021
0.268

AIC

96.983

87.268

32

32

32

32

/ 0.412
0.349

/ 0.452
0.371

/ 0.467
0.364

/ 0.511
0.394

84.376

84.099

85.266

/

84.472

* p<0.1 ** p<0.05 *** p<0.01
When dichotomizing our Discrepancy Score, we no longer find a reliable regression coefficient (Table A3). This
suggests that the impact of the score is linear rather than categorical. This linear relationship is easy to see when
plotted. In Figure 3 below, we visualize the relationship between Public Behaviors and the Discrepancy Score
after adjusting for current level of Government Intervention.

Figure 3. Aggregate Public Social Behaviors and the Relative Discrepancy between Public
Preferences and Government Pandemic Response, after adjusting for current Government
Intervention. Plotted by the authors.

Note: Chile and Russia trimmed slightly for visualization purposes.

Figure 3 reveals that in countries such as Sweden, Chile, Spain and South Africa, the
government fell completely short of institutionalized public preferences, whereas in Korea,
Japan, the Philippines, and France the government engaged in a ‘lockdown’ that can be seen
as relatively restrictive given pre-COVID-19 public perceptions of appropriate government
intervention. Other countries fall somewhere in between on the continuum. The shaded grey
area is a fitted correlation between the two measures. There is variation in the distribution of
countries around this line suggesting that many factors were likely at play in this pandemic,
and our models are a simplification of this complex causal reality. Nonetheless, if the
assumption that any other factors are exogenous to the model holds, then we have evidence of
negative policy feedback.
Table A4 in the Appendix provide that our findings do not hold true when we remove the lag
between the Outbreak and Public Reaction Stages. Current Government Intervention is still
robust with a 99% confidence interval but the effect of Discrepancy Score loses its significance

(0.1 < p < 0.2) despite pointing toward the same direction and effect size. Looking at the
Pearson correlation coefficient between the new Discrepancy Score and Government
Intervention, the two are statistically correlated at 0.38 (p < 0.05), causing multicollinearity.
Because Discrepancy Score is constructed from Government Intervention, this suggests some
form of autocorrelation in the data, meaning the decision to keep a time lag between the two
stages is supported. When removing the outlier – Croatia – from the data set and re-run the
models (Table A5), the effect of Discrepancy Score is still significant at 95% confidence with
slightly larger effect size and R-squared, as well as a better fit (AIC equals 75.284 in M54,
compared to 84.099 in M24). This further substantiates our findings.
Conclusion
In the Novel Coronavirus Pandemic, the fit of the initial government response to the outbreak
with what the public normally prefers appears to impact public behaviors. Our main regression
results (in Table 3) suggest negative policy feedback. A Discrepancy Score closer to zero,
means that Public Behaviors are mostly predicted by current Government Intervention.
Meanwhile, if the Score has a large positive value, it cancels out the effect of current
Government Intervention. In the reverse case, a large negative Score statistically complements
Government Intervention. This is evidence of negative policy feedback because public
behaviors undermine the government’s policies. In theory, this means that government
interventions towards risky behaviour become less successful if they take away much more
individual freedom than to what the public are institutionally accustomed to or accepting of.
This would be evidence of a ‘lock in’ effect of public preferences supporting a range of
institutional theories about public preferences and government response. Here, the publics’
engagement in risky behaviors threatens to undermine government pandemic responses.
Interestingly, if government response is too weak, it leads to relatively less risky public
behaviors, suggesting the public compensate for their government’s failures. This is different
from self-undermining negative feedback because we assume governments did not have the
intention to cause more deaths in their policies, although it is still ‘negative’ in the sense that
the public act in a different direction than the policies of their governments. Because of the
limitation of our data, the large effect of Government Intervention could also mean that in
countries where risky behaviours are more prevalent, governments are more likely to enforce
stricter rules. Future research should investigate this important relationship further.
There are limitations to this study. The online sample over-represents certain groups.
Specifically, our Public Behaviors data over-represents young to middle-aged people, high
education, and higher income; however, male and female respondents are balanced. Such
information is not surprising given internet usage is more common among these groups.
However, this pandemic, at least at the beginning, removed the possibility to conduct more
representative sampling due to risks and restrictions. That the survey organizers were able to
get the pandemic-specific survey in the field in so many countries already in mid-March makes
the data quite unique. Nevertheless, although we do not observe dramatic cross-country
variation in observed sampling bias, there may be substantial unobserved sampling bias, and
this may vary across different countries and this may undermine our results.

Regarding the elderly being under-represented, we would expect that they are the most risk
averse in the pandemic. Thus, if the government does not meet their expectations, they may be
the least likely to act out in response. This would mean that they are a special case, and it is not
too problematic that our data focus more on younger persons. If higher income and higher
educated are over-represented we see this as creating a more conservative test case and
strengthening our results, because these are the people who are either less in need of rebelling
against the government because of financial security (higher income) or better equipped to
understand the risks (higher educated). Moreover, in addition to the small-N problem of only
32 countries, there are time-series methods better equipped to answer questions of changes over
time. Unfortunately, data limitations prevent this, and instead our unit of analysis is roughly
one week, so we do our best to compare what happened at time ‘zero’ during the outbreak and
then how the public responded in time ‘one’ in the following two weeks or so. Finally, we
argue that our measure of discrepancy is a proxy for the discrepancy between Covid restrictions
and attitudes towards these. We therefore had to assume that attitudes towards government
intervention before the pandemic are correlated with attitudes towards Covid-restrictions. This
cannot be verified given the unprecedented nature of the pandemic and the lack of relevant
data.
We conclude that more research needs to be carried out on the enforcement of strict government
measures, especially where the public prefers a high level of individual freedom. Bearing in
mind the limitations outlined above, our best recommendation for (future) policymakers to
reduce damaging negative feedback effects from their immediate pandemic policies is to
complement them with comprehensive public communication strategies that address
institutionalized public concerns regarding government intervention. We believe a highfrequency, transparent flow of information which places the public in the role of a partner rather
than a recipient of orders may lead to more sustained public acceptance of pandemic policies.
For overcoming an exceptional situation such as the Novel Coronavirus Pandemic, where the
health and livelihoods of all are acutely threatened, a trusting and close relationship between
the government and the governed is needed more than ever as one side cannot succeed without
the other.

References
Adams, J. et al. (2004) ‘Understanding Change and Stability in Party Ideologies: Do Parties
Respond to Public Opinion or to Past Election Results?’, British Journal of Political Science,
34(4), pp. 589–610. doi: 10.1017/S0007123404000201.
Adams, J. et al. (2006) ‘Are Niche Parties Fundamentally Different from Mainstream Parties?
The Causes and the Electoral Consequences of Western European Parties’ Policy Shifts, 19761998’, American Journal of Political Science, 50(3), pp. 513–529.
Adams, J. (2012) ‘Causes and Electoral Consequences of Party Policy Shifts in Multiparty
Elections: Theoretical Results and Empirical Evidence’, Annual Review of Political Science,
15(1), pp. 401–419. doi: 10.1146/annurev-polisci-031710-101450.
Baekgaard, M. et al. (2020) ‘Rallying around the flag in times of COVID-19: Societal
lockdown and trust in democratic institutions’, Journal of Behavioral Public Administration,
3(2). doi: 10.30636/jbpa.32.172.
Bol, D. et al. (2020) ‘The effect of COVID‐19 lockdowns on political support: Some good
news for democracy?’, European Journal of Political Research, pp. 1475-6765.12401. doi:
10.1111/1475-6765.12401.
Breznau, N. (2017) ‘Positive Returns and Equilibrium: Simultaneous Feedback Between
Public Opinion and Social Policy’, Policy Studies Journal, 45(4), pp. 583–612. doi:
10.1111/psj.12171.
Breznau, N. (2020) ‘The Welfare State and Risk Perceptions: The Novel Coronavirus
Pandemic and Public Concern in 70 Countries’, European Societies, 0(0), pp. 1–14. doi:
10.1080/14616696.2020.1793215.
Breznau, N., Heukamp, L. and Nguyen, H. (2020) The Swedish paradox explained?
Investigating the role of economic inequality and risk perceptions in the Novel Coronavirus
Pandemic. SocArXiv. doi: 10.31235/osf.io/re7sn.
Colfer, B. (2020) ‘Herd‐immunity across intangible borders: Public policy responses to
COVID‐19 in Ireland and the UK’, European Policy Analysis, p. epa2.1096. doi:
10.1002/epa2.1096.
Edlund, J. and Lindh, A. (2019) ‘The ISSP 2016 Role of Government Module: Content,
Coverage, and History’, International Journal of Sociology, 49(2), pp. 99–109. doi:
10.1080/00207659.2019.1582963.
Fetzer, T. et al. (2020) Perceptions of an Insufficient Government Response at the Onset of the
COVID-19 Pandemic are Associated with Lower Mental Well-Being. PsyArXiv. doi:
10.31234/osf.io/3kfmh.

Hale, T. et al. (2020) ‘Oxford COVID-19 Government Response Tracker’. Blavatnik School
of Government.
Heiberger, R. M. and Holland, B. (2015) Statistical Analysis and Data Display. New York,
NY: Springer New York (Springer Texts in Statistics). doi: 10.1007/978-1-4939-2122-5.
Huber, J. D. and Powell, G. B. (1994) ‘Congruence between Citizens and Policymakers in Two
Visions of Liberal Democracy’, World Politics, 46(3), pp. 291–326. doi: 10.2307/2950684.
Jacobs, A. M. and Weaver, R. K. (2015) ‘When Policies Undo Themselves: Self-Undermining
Feedback as a Source of Policy Change’, Governance, 28(4), pp. 441–457. doi:
10.1111/gove.12101.
Jones, B. D. and Baumgartner, F. R. (2012) ‘From There to Here: Punctuated Equilibrium to
the General Punctuation Thesis to a Theory of Government Information Processing’, Policy
Studies Journal, 40(1), pp. 1–20. doi: 10.1111/j.1541-0072.2011.00431.x.
Manza, J. and Cook, F. L. (2002) ‘A Democratic Polity?: Three Views of Policy
Responsiveness to Public Opinion in the United States’, American Politics Research, 30(6),
pp. 630–667. doi: 10.1177/153267302237231.
Naumann, E. et al. (2020) ‘COVID‐19 policies in Germany and their social, political, and
psychological consequences’, European Policy Analysis, p. epa2.1091. doi:
10.1002/epa2.1091.
Page, B. I. and Shapiro, R. Y. (1983) ‘Effects of Public Opinion on Policy’, American Political
Science Review, 77(1), pp. 175–190. doi: 10.2307/1956018.
Pavlik, M. (2020) ‘A great and sudden change: The global political violence landscape before
and
after
the
COVID-19
pandemic.’,
ACLED.
Available
at:
https://acleddata.com/2020/08/04/a-great-and-sudden-change-the-global-political-violencelandscape-before-and-after-the-covid-19-pandemic/.
Pierson, P. (1993) ‘When Effect Becomes Cause: Policy Feedback and Political Change’,
World Politics, 45(4), pp. 595–628. doi: 10.2307/2950710.
Pierson, P. (1994) Dismantling the Welfare State? Reagan, Thatcher and the Politics of
Retrenchment. Cambridge: Cambridge Univ Press.
Pierson, P. (2004) ‘Positive Feedback and Path Dependence’, in Politics in Time: History,
Institutions and Social Analysis. Princeton, NJ: Princeton University Press, pp. 17–53.
Prather, K. A., Wang, C. C. and Schooley, R. T. (2020) ‘Reducing transmission of SARS-CoV2’, Science, 368(6498), pp. 1422–1424. doi: 10.1126/science.abc6197.

Rasmussen, A., Reher, S. and Toshkov, D. (2019) ‘The opinion‐policy nexus in Europe and
the role of political institutions’, European Journal of Political Research, 58(2), pp. 412–434.
doi: 10.1111/1475-6765.12286.
Reeskens, T. et al. (2020) ‘Stability or change of public opinion and values during the
coronavirus crisis? Exploring Dutch longitudinal panel data’, European Societies, 0(0), pp. 1–
19. doi: 10.1080/14616696.2020.1821075.
Soroka, S. N. and Wlezien, C. (2010) Degrees of Democracy: Politics, Public Opinion and
Policy. Cambridge: Cambridge University Press.
Stimson, J. A., Mackuen, M. B. and Erikson, R. S. (1995) ‘Dynamic Representation’, American
Political Science Review, 89(3), pp. 543–565. doi: 10.2307/2082973.
Wilder-Smith, A., Chiew, C. J. and Lee, V. J. (2020) ‘Can we contain the COVID-19 outbreak
with the same measures as for SARS?’, The Lancet Infectious Diseases, 20(5), pp. e102–e107.
doi: 10.1016/S1473-3099(20)30129-8.
Wlezien, C. (1995) ‘The Public as Thermostat: Dynamics of Preferences for Spending’,
American Journal of Political Science, 39(4), pp. 981–1000. doi: 10.2307/2111666.

Appendix
Table A1. Metrics from measurement invariance models, Public Preferences
FIT INDEX

BASELINE

CONFIGURAL

METRIC

METRIC X

1

Chi-square

0

0

578.27

516.282

2

df

0

0

64

64

3

RMSEA

0

0

0.086

0.08

4

CFI

1

1

0.968

0.972

5

TLI

1

1

0.95

0.956

6

AIC

374065

360400

360850

360788

7

LL

-187026

-179903

-180192

-180161

Table A2. Metrics from measurement invariance models, Public Behaviors
FIT INDEX

BASELINE

CONFIGURAL

METRIC

METRIC X

1

Chi-square

0

0

827.548

627.841

2

df

0

0

66

66

3

RMSEA

0

0

0.078

0.067

4

CFI

1

1

0.972

0.98

5

TLI

1

1

0.957

0.969

6

AIC

499949

468193

468889

468689

7

LL

-249969

-233791

-234204

-234105

Table A3. OLS Regressions Predicting Public Behaviors in the Public Reaction Stage (March
20 - April 7) with Discrepancy Score, dichotomized, from the Outbreak Stage (March 1 - March
15), 32 Countries.
M31
Predictors

M32

M33

M34

M35

M36

Estimates Estimates Estimates Estimates Estimates Estimates

Intercept

-0.05

-0.03

-0.13

0.39

-0.81

-1.12

Positive Discrepancy 0.06
from Outbreak Stage

-0.03

-0.10

-0.13

-0.07

-0.13

Current
Intervention

0.51 ***

0.51 ***

0.54 ***

0.56 ***

0.61 ***

0.01 *

0.01 *

0.01

0.01

-0.02

0.00

0.01

0.03

0.02

Gov.

Deaths per Million
Disposable
Inequality

Income

Social Spending
GDP (k$, per capita)

0.01

Observations

32

R2 / R2 adjusted

0.001 / - 0.255
0.033
0.203

* p<0.1 ** p<0.05 *** p<0.01

32

32

32

32

32

/ 0.341
0.270

/ 0.352
0.256

/ 0.378
0.259

/ 0.418
0.278

/

Table A4. OLS Regressions Predicting Public Behaviors in the Public Reaction Stage (March
20 - April 7) with Discrepancy Score from the Outbreak Stage (March 1 - March 19), 32
Countries.
M41
Predictors
Intercept

M42

M43

M44

M45

M46

Estimates Estimates Estimates Estimates Estimates Estimates
-0.03

-0.04

-0.19

0.68

-0.28

-0.63

Discrepancy Score - 0.06
Outbreak Stage

-0.17

-0.21

-0.28

-0.25

-0.27

Government
Intervention - Public
Reaction Stage

0.57 ***

0.58 ***

0.66 ***

0.66 ***

0.72 ***

0.01 **

0.01 *

0.01

0.01

-0.03

-0.01

-0.00

0.03

0.01

Deaths per Million
Disposable
Income
Inequality (Gini)
Social Spending
GDP (k$, per capita)

0.01

Observations

32

R2 / R2 adjusted

0.003 / - 0.276
0.030
0.226

* p<0.1 ** p<0.05 *** p<0.01

32

32

32

32

32

/ 0.370
0.303

/ 0.401
0.312

/ 0.417
0.305

/ 0.459
0.329

/

Table A5. OLS Regressions Predicting Public Behaviors in the Public Reaction Stage (March
20 - April 7) with Discrepancy Score from the Outbreak Stage (March 1 - March 15), 31
Countries, Croatia excluded.
M51
Predictors

M52

M53

M54

M55

M56

Estimates Estimates Estimates Estimates Estimates Estimates
0.02

-0.12

1.25 *

0.10

-0.15

Discrepancy Score - -0.12
Outbreak Stage

-0.30 *

-0.33 **

-0.44 ***

-0.41 **

-0.42 **

Government
Intervention - Public
Reaction Stage

0.67 ***

0.66 ***

0.78 ***

0.80 ***

0.83 ***

0.01 **

0.01 *

0.01

0.01

-0.04 **

-0.02

-0.02

0.03

0.02

Intercept

0.00

Deaths per Million
Disposable
Income
Inequality (Gini)
Social Spending
GDP (k$, per capita)

0.01

Observations

31

R2 / R2 adjusted

0.013 / - 0.400
0.021
0.357

AIC

94.312

* p<0.1 ** p<0.05 *** p<0.01

31

80.873

31

31

31

31

/ 0.486
0.428

/ 0.560
0.492

/ 0.585
0.502

/ 0.603
0.504

78.112

75.284

75.428

76.056

/

Figure A1. Density plots of Government Intervention over two stages.

