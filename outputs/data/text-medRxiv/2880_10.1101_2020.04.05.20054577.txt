medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

A Bayesian Logistic Growth Model for the Spread of COVID-19 in New York

Svetoslav Bliznashki
Sofia University, Sofia, Bulgaria
valsotevs@gmail.com

Abstract: We use Bayesian Estimation for the logistic growth model in order to
estimate the spread of the coronavirus epidemic in the state of New York. Models weighting
all data points equally as well as models with normal error structure prove inadequate to
model the process accurately. On the other hand, a model with larger weights for more recent
data points and with t-distributed errors seems reasonably capable of making at least short
term predictions.
1. Introduction. The logistic growth model is frequently used in order to model the
spread of viral diseases and of covid-19 in particular (e.g. Batista, 2020; Wu et al., 2020). The
differential equation is given in (1):

(

)

(1)

where C is the cumulative number of infected individuals, r is the infection rate, and K is the
upper asymptote (i.e. the upper limit of individuals infected during the epidemic). Unlike
other models, like SIR, Eq. 1 has an explicit analytical solution:

( )

(2)

where A=(K-C0)/C0 and C0 is the initial number of infectees.
The parameters of Eq. 2 can easily be estimated via Least Squares (LS) but in this note
we use a Bayesian approach which allows us to make use of explicit posterior distributions in
order to make probabilistic predictions.

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

We apply the above model to the state of New York which represents a relatively
geographically homogenous population with sufficient data points in order build a reliable
model which is not affected by different trends present in different regions.
2. Simulation 1. We begin with a simple model which estimates the parameters of Eq.
2 based on the assumption of normally distributed homoscedastic errors. We use the data for
28 consecutive days of the epidemic beginning with the 4th of March (11 infectees) and
ending with the 31st of March (75832 infectees)1.
Prior to estimation we standardized our data by dividing all data points by 70000 in
order to avoid numerical problems; after the posteriors were obtained we back-transformed
the results in their original scale.
We assumed that the errors are normally distributed with mean equal to 0 and standard
deviation (σ) estimated by the model.
We used the blockwise Random Walk Metropolis algorithm2 in order to sample from
the joint posterior distribution of the four parameters of the model (K, A, r, and σ). The
proposal distribution was multivariate normal with scaled variance-covariance matrix
estimated on the basis of pilot runs. Uninformative improper uniform priors ranging from 0 to
+ ∞ were employed for all parameters in the model. A pilot chain showed an acceptance rate
within the optimal range of 23% (e.g. Chib & Greenberg, 1995). The final simulation used 20
million iterations and heavy thinning (each 200th sample was retained). The traceplots and
autocorrelation functions indicated excellent convergence. A histogram and a traceplot for the
K parameter are shown in Fig. 1.
Table 1. Shows the mean (Expected Aposteriori - EAP) and median estimates for the 4
parameters as well as their standard deviations and 95% Highest Density Intervals (HDI).

K
A
r
σ

1

mean
median
SD
2.50%
97.50%
92114.87 91903.83 3904.86 84636.23 99978.49
2674.25 2564.55 707.51 1473.55 4069.47
0.34
0.34
0.01
0.31
0.37
0.02
0.02
0.003
0.01
0.02

The data is publicly available via the github repository: https://github.com/nytimes/covid-19data/blob/master/us-states.csv
2
The posterior chains showed high correlations between the parameters (ranging from -0.87 to +0.96) which
renders algorithms like the Gibbs Sampler and/or componentwise Metropolis highly inefficient for the task at
hand.

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Table 1. Means, medians, standard deviations (SD), and 95% HDIs for the parameters
of Eq. 2 obtained from the posterior of our first model.

16000

12000

8000

4000

0
76,112

83,377

90,642

97,907

105,172

112,437

120000
115000
110000
105000
100000
95000
90000
85000
80000
75000

Figure 1. A histogram (top) and a traceplot (bottom) for the posterior for the K
parameter from Eq. 2 for our first model.

Note that in Table 1 and in subsequent tables of this type the σ parameter and its
posterior SD are given in the standardized scale (the original data was divided by 70000 as

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

explained above) in order to avoid clutter. The same is true for the scale parameter described
in Section 4 (Table 5). The K parameter is always given in its original (unstandardized) form
since it is of primary interest.
For comparison, the estimates obtained from LS estimation (via the Matlab’s cftool)
are the following: K=92470 (95% CI=[85120; 99890]), A=2424 (95% CI=[1247; 3601]), and
r=0.34 (95% CI=[0.31; 0.37]). We see that the estimates are very similar to the posterior
EAPs reported above which is to be expected given the uninformative nature of our priors.
Still, the Bayesian analysis gives slightly wider intervals for the estimates which as we’ll see
below is a positive.
Fig. 2 below shows the observed and the fitted estimates for the cumulative number of
infectees in New York.
80000
70000
60000
50000
actual

40000

predicted

30000
20000
10000
0
0

3

6

9

12

15

18

21

24

27

Figure 2. Observed cases (circles) and fitted values (continuous grey line) based on the
EAP estimates for the parameters reported in Table 1. The values on the x-axis represents
number of days since the initial data point used in our model (March the 4th).
Both Fig. 1 (top) and Fig. 2 show that the model’s estimates (e.g. K) are very
conservative. This is a commonly observed situation for phenomenological (i.e. purely datadriven) models of this type.
At the time of writing this note, there is information for the number of infectees three
days after the 28 days used in order to fit the model. We used the posterior estimates in order
to predict the number of future infectees. More precisely, we used the posterior estimates

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

(including σ) in order to simulate data for future values of t thereby constructing what is
known as posterior predictive distributions. For example, for a given future day (e.g. for the
28th day) we sampled all posterior values for Eq. 2 parameters and for each sample we
plugged in the t=28 value in order to obtain a mean prediction value; then we added a random
number generated from N(0, σ) where the value for σ is sampled from the posterior alongside
the other parameters available for the given step. The resulting predictive distribution has an
observed mean, variance, etc. and can be used in order to make point and/or interval
predictions (HDIs) as usual. Some results are shown in Table 2.
t
HDI2.5%
HDI97.5%
Range
HDI0.5%
HDI99.5%
Range
True

28
74289
81709
7420
72982
83071
10089
83889

29
77225
86016
8791
75552
87457
11905
92770

30
79240
89392
10152
77644
91387
13743
102870

31
80764
92143
11379
79032
94458
15426

32
81840
94256
12416
79792
96663
16871

33
82597
95883
13286
80452
98520
18068

34
83133
97099
13967
80896
99921
19025

200
84323
100504
16181
81759
103831
22072

Table 2. 95% and 99% HDIs for the predictive distributions for 7 days after the final
data point used to fit the model. Ranges for the HDIs are given below the upper values for a
given interval. The true values available by now are shown on the last row. The last column
(day 200) gives the posterior prediction for the final number of infectees.
We see that the predictive distributions fail to capture even the immediate true value
which once again suggests that indeed the model is inadequate and fails to capture the true
trends in the data. Note, however, that the ranges of the prediction intervals increase for later
data points which is a desirable quality of a model and is intrinsic to the Bayesian approach
employed here. As Fig. 2 (upper right portion) suggests, the model converges too quickly to
its upper asymptote and hence its predictions are too low and probably too narrow. This
observation is not surprising given that it is well-known that the simple logistic model is
applicable only during specific stages of an outbreak and/or when enough data is available
(see Wu et al, 2020 for a review). Possible solutions include: improving the model (e.g.
Richards, 1959) by adding more parameters which can account better for the deviation of the
observed data points from the symmetric S-shaped curve suggested by the logistic growth
model; adjusting the prior distributions so as to reflect our expectations of a much higher

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

upper asymptote (K); switching to a different, preferably more mechanistic approach
altogether.
Instead, we attempted to construct a more accurate model within the same logistic
growth paradigm in a different way: we introduced weights to our data points with later data
points receiving higher weights than older ones in the hope that this will alleviate some of the
problems observed above. Specifically, we weighted the points according to a Rectified
Linear-like function (e.g. Glorot et al., 2011) whereby the first 20 observations received
constant (0.008) low weights and the last 8 observations received linearly increasing higher
weights (last 8 weights=[0.77 1.55 2.32 3.09 3.87 4.64 5.41 6.19]). The idea behind this
scheme was to try to force the model to account better for the observations following the
approximately linear trend observed in the upper half of Fig. 2. Note also that the weights sum
to the number of original observations (28). The weights pattern is shown in Fig. 3.
7
6

5
4
3
2
1
0
0

3

6

9

12

15

18

21

24

27

Figure 3. The Rectified Linear pattern of weights used to weigh the likelihood
function in our second and third simulations. The x-axis denotes the consecutive number of
each observation and the y-axis shows its weight. See the text for the actual values employed.
In the subsequent simulations we used the proposed weights in order to weigh the
likelihood function of the model. Following Simeckova (2005), assuming we have
observations Y1, …Yn and Yi has density fi(Yi|θ) where θ is the vector of parameters (see Eq.
2), we apply the weights vector w=[w1,…wn]. If we let li(θ)=log(fi(Yi|θ)), the weighted loglikelihood function of our model becomes:

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

l(θ)=Σwi.li(θ)

(3)

3. Simulation 2. We used the above weighing scheme and repeated the previous
simulation. In that sense we altered the likelihood function while leaving the prior
distributions intact. Everything else (including the simulation details such as number of
posterior draws, thinning, etc.) was the same as reported in Section 2. Again, we observed
good convergence for all parameters (see Fig. 4 depicting a traceplot and a histogram for the
K parameter).

16000
14000
12000
10000
8000
6000
4000
2000

0
109,334

200000

180000

160000

140000

120000

100000

125,563

141,793

158,023

174,252

190,482

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Figure 4. A histogram (top) and a traceplot (bottom) for the posterior for the K
parameter from Eq. 2 for our second model.
Table 3 gives a summary for the posterior estimates3. We see that our weighting
scheme appears to give more reasonable results and that the estimates for the upper asymptote
(K) are substantially higher than before. The same observations can be made when we inspect
the fitted equation against the observed data (Fig. 5). It is clear that the fitted curve is much
more affected by the later points and consequently the upper asymptote is higher than before
(compare also Tables 3 and 1).

K
A
r
σ

mean
median
SD
2.50%
97.50%
136869.67 135614.03 10422.80 117921 157535.3
410.97
401.77
73.45
279.37
557.52
0.23
0.23
0.01
0.21
0.25
0.01
0.01
0.002
0.01
0.01

Table 3. Means, medians, standard deviations (SD), and 95% HDIs for the parameters
of Eq. 2 obtained from the posterior of our second (weighted) model.
80000
70000
60000
50000
actual

40000

predicted

30000
20000
10000
0
0

5

10

15

20

25

30

Figure 5. Observed cases (circles) and fitted values (continuous grey line) based on the
EAP estimates for the parameters reported in Table 3.

3

For comparison the LS estimates obtained with the same weighing scheme are K=135870 (95% CI=[117600;
151140]), A=398.5 (95% CI=[267; 530.1]), and r=0.23 (95% CI=0.21; 0.25]).

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Table 4 gives the posterior predictive distribution for 7 days ahead as well as for the
estimate for the final number of infectees.
t
HDI2.5%
HDI97.5%
Range
HDI0.5%
HDI99.5%
Range
True

28
81208
84970
3761
80551
85653
5102
83889

29
30
87755 93408
92915 100644
5160
7236
86843 92130
93872 102046
7028
9916
92770 102870

31
98316
108090
9774
96700
110128
13428

32
102300
114896
12596
100366
117752
17386

33
105708
121216
15508
103302
124759
21457

34
108498
126905
18407
105775
131281
25506

200
117813
157554
39741
114050
171023
56972

Table 4. 95% and 99% HDIs for the predictive distributions for 7 days after the final
data point used to fit the second model. Ranges for the HDIs are given below the upper values
for a given interval. The true values available by now are given at the last row (the values in
bold are accurately predicted by the model). The last column (day 200) gives the posterior
prediction for the final number of infectees.
We see that this time the model accurately predicts two consequent data points and
fails to predict the third. This is still not a satisfactory performance, however, and hints
towards the possibility that the actual process exhibits steeper rise than the one suggested by
the model. In the same way, it appears that the HDIs are not wide enough in order to
accommodate the actual uncertainty.
4. Simulation 3. Looking at figures 2 and 5 we see that the errors, in all likelihood,
both lack homoscedasticity and possess an auto-correlated structure. In order to (partially)
alleviate these problems we removed the normality assumption present above and replaced it
with the assumption that the errors follow a t-distribution with location parameter equal to 0
and scale (similar to the standard deviation used above) and degrees of freedom (df)
parameters estimated from the data (see Kruschke, 2012 for the same approach in the context
of a linear model).
We used the same weighing scheme as above and introduced the two new parameters
(scale and df) describing the t-distribution governing the model’s errors. We again proposed
the first four parameters of the model (i.e. K, A, r, scale) by a multivariate normal distribution
centered on the previous values of the chain with scaled variance-covariance matrix estimated
from pilot chains; the df parameter was proposed separately based on a lognormal

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

distribution4 which was transformed back to the original scale after the end of the simulation.
30 million samples from the posterior were obtained with every 300th step retained (i.e. we
had a thinning parameter of 300). We used improper uniform priors for all parameters except
for the df parameter for which a shifted exponential with mean equal to 30 was specified as
suggested by Kruschke (2012).
The results indicated good convergence (a traceplot for the K parameter is shown in
Fig. 6 below; histograms from the posterior for all parameters are shown in Appendix A).
Table 5 gives the point and interval estimates for the posteriors for the five parameters
in question. We see that the estimates differ substantially from the ones reported above and
that a steeper curve is indicated.
275000

250000
225000
200000
175000
150000
125000
100000

Figure 6. Traceplot for the posterior for the K parameter from Eq. 2 for our final
model.

K
A
r
scale
df

4

mean
median
SD
2.50%
97.50%
169235.12 170739.00 19085.84 128757.85 202630.50
293.33
276.99
51.09
232.13
403.94
0.20
0.20
0.01
0.18
0.23
0.01
0.01
0.002
0.002
0.01
5.79
2.38
10.32
1.03
23.30

The lognormal distribution is not symmetric and hence we use the actual Metropolis-Hastings acceptance
probability (e.g. Chib & Greenberg, 1995) during the step sampling from the df posterior.

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Table 5. Means, medians, standard deviations (SD), and 95% HDIs for the parameters
of Eq. 2 obtained from the posterior of our last model.
Consistently with our expectations the 95% HDI for the df parameter suggests a
noticeable deviation from normality.
Fig. 7 shows the predicted trend based on the EAP estimates shown in Table 5.
Finally, Table 6 specifies the predictive distributions for the next 7 days and for the
estimate for the final cumulative number of infectees. We see that this model accurately
predicts at least three future data points. In the next several days we should be able to observe
how the model deals with data points further away in time.
80000
70000
60000

50000
actual

40000

predicted

30000
20000
10000
0
0

5

10

15

20

25

30

Figure 7. Observed cases (circles) and fitted values (continuous grey line) based on the
EAP estimates for the parameters reported in Table 5.
t
HDI2.5%
HDI97.5%
Range
HDI0.5%
HDI99.5%
Range
True

28
82041
85694
3653
80770
87387
6617
83889

29
89429
94827
5399
87838
96109
8271
92770

30
96073
104246
8173
94098
105515
11417
102870

31
101971
113682
11711
99462
115211
15750

32
107125
123002
15877
103842
124839
20996

33
111375
131784
20408
107458
134255
26797

34
115128
140337
25209
110558
143455
32897

200
129412
203450
74038
119862
216170
96307

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Table 6. 95% and 99% HDIs for the predictive distributions for 7 days after the final
data point used to fit our last model. Ranges for the HDIs are given below the upper values for
a given interval. The true values available by now are given at the last row (the values in bold
are accurately predicted by the model). The last column (day 200) gives the posterior
prediction for the final number of infectees.
As can be seen in Appendix A the posteriors for the different parameters no longer
resemble parametric distributions (for the previous two models the posteriors for the K, A,
and r definitely resemble normal/t-distributions while the σ parameter is pronouncedly
positively skewed and thus resembles a gamma distribution). Nevertheless this model appears
to be best suited for the modeled phenomenon.
5. Discussion. It appears that a logistic growth model with a weighted likelihood
function and a t-distribution imposed on the error structure is able to make accurate short term
predictions of the spread of a disease. The Bayesian estimation gives more accurate estimates
than traditional Least Squares and Maximum Likelihood approaches with more accurate
interval estimates. Moreover, the Bayesian posteriors (including the predictive distributions)
have a straightforward probabilistic interpretation which cannot be said about traditional
frequentist Confidence Intervals.
As a rule, the posterior distributions show high correlations between the parameters
which makes algorithms like blockwise Metropolis-Hastings more effective in general than
algorithms which explore a single posterior distribution at a time such as the Gibbs Sampler
and the componentwise Metropolis-Hastings. The fact that some posteriors lack closed-form
solutions is another impediment when it comes to the Gibbs Sampler but not necessarily for
the use of the componentwise Metropolis-Hastings with respect to certain parameters as
demonstrated in Section 3.
The weighing scheme employed here proves beneficial over modeling the raw data by
forcing the model to pay more attention to more recent observations. Other weighing schemes
are certainly possible and investigating the properties of different approaches seems a
potentially fruitful future enterprise.
As a whole it appears that the combination of Bayesian Estimation, differentially
weighing the observations, and employing a more robust approach towards modeling the

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

errors (i.e. assuming a t-distribution with scale and df parameters estimated from the data)
results in more reliable HDIs and prediction intervals than more traditional approaches.
Far from being perfect, the proposed model appears to be somewhat useful. Of course,
such a model can be continuously augmented by including new data points and applying the
same or similar weighing procedure. Presumably, continuously adjusting the model by adding
new observations as they become available would improve its accuracy.
That being said, our simulations suggest that we should be somewhat skeptical
towards logistic growth models applied to the raw data describing an outbreak, especially
when the number of available data points is relatively small and the upper asymptote appears
not to have been approached yet.

References:
Batista, M. (2020). Estimation of the Final Size of Coronavirus Epidemic by the
Logistic Model. medRxiv, 2020.
Chib, D., Greenberg, E. (1995). Understanding the Metropolis-Hastings Algorithm.
The American Statistician, 49, 327 – 335.
Glorot, X., Bordes, A., Bengio, Y. (2011). Deep Sparse Rectifier Neural Networks.
Proceedings of the 14th International Conference on Artificial Intelligence and Statistics, FL,
USA, Vol. 15.
Kruschke, J. (2012). Bayesian Estimation Supersedes the t test. Journal of
Experimental Psychology: General, 142 (2), 573 – 603.
Richards, F. (1959). A Flexible Growth Function for Empirical Use. Journal of
Experimental Botany, 10 (29), 290 – 301.
Simeckova, M. (2005). Maximum Weighted Likelihood Estimation in Logistic
Regression. WDS’05 Proceedings of Contributed Papers, 1, 144 – 148.
Wu, K., Darcet, D., Wang, W., Sornette, D. (2020). Generalized Logistic Growth
Modeling of the COVID-19 Outbreak in 29 Provinces in China and in the rest of the World.
arXiv, 2020.

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

APPENDIX A
Histograms of the posterior distributions for the five parameters for our last model.
For simplicity the scale parameter values are presented in their standardized form (i.e. they
are not back-transformed).
14000

K

12000
10000

8000
6000
4000
2000
0
116,062 142,348 168,634 194,919 221,205 247,491

30000

A

25000
20000

15000
10000
5000
0
217

301

384

467

550

634

16000

r

14000
12000

10000
8000
6000
4000
2000

0
0.17

0.18

0.20

0.22

0.23

0.25

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

14000

scale

12000
10000
8000
6000
4000
2000
0
0.001

0.004

0.007

0.010

0.013

0.016

90000

df

80000
70000
60000
50000
40000
30000
20000
10000
0
6

52

99

146

193

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

APPENDIX B
Matlab code for the third simulation.
%t, y, and covmat should be imported before running the code; t is time in days (the first day
%for which there are 11 infectees is labeled 0 – March 4th); all consecutive days up to 27 are
%simply given their corresponding numbers (i.e. 0, 1, 2, 3…27); y is the cumulative number
%of infectees for each consecutive day up to the 31st of March; available at github;
%the y values are standardized before the code is run by dividing them by 70000;
%The columns of PAR correspond to the posteriors for K, A, r, scale, and df respectively;
nit=30000000; %# iterations;
PAR=zeros(nit/300, 4); cur=[2.38 299 0.2046 0.0061]; %starting values;
DF=zeros(nit/300, 1); curdf=0.1; %starting value for df;
wei=[0.1*ones(1, 20) [10 20 30 40 50 60 70 80]]; wei=wei/sum(wei)*28; wei=wei';
PrevPred=cur(1)./(1+cur(2)*exp(-cur(3)*t)); cnt=0;
Lp=gentdst(y, PrevPred, cur(4), exp(curdf));
Lp=sum(wei.*log(Lp)); Lp=Lp+log((1/29)*exp(-(1/29)*(exp(curdf)-1))); %posterior;
for i=1:nit
prop=mvnrnd(cur, covmat*0.09, 1); %proposal;
if prop(1)<=0 || prop(2)<=0 || prop(3)<=0 || prop(4)<=0 %prior;
alp=0;
else
Pred=prop(1)./(1+prop(2)*exp(-prop(3)*t));
Ln=gentdst(y, Pred, prop(4), exp(curdf)); %Likelihood;
Ln=sum(wei.*log(Ln)); Ln=Ln+log((1/29)*exp(-(1/29)*(exp(curdf)-1)));
alp=exp(Ln-Lp); %acceptance probability;
end
if rand<alp
cur=prop;
Lp=Ln;
end
propdf=curdf+randn(1, 1)*0.93; %proposal for df;
if propdf<0 %prior (df should be>=1);
alp=-99999;
else
Pred=cur(1)./(1+cur(2)*exp(-cur(3)*t));
Ln=gentdst(y, Pred, cur(4), exp(propdf));
Ln=sum(wei.*log(Ln)); Ln=Ln+log((1/29)*exp(-(1/29)*(exp(propdf)-1)));
alp=(Ln-Lp)+(log(propdf)-log(curdf)); %accounting for the log-normal proposal;
end
if log(rand)<alp;
curdf=propdf;
Lp=Ln;
end
if mod(i, 300)==0
cnt=cnt+1;
PAR(cnt, :)=cur;
DF(cnt)=curdf;
end
end

medRxiv preprint doi: https://doi.org/10.1101/2020.04.05.20054577; this version posted April 14, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

%%%%%%%%%%%%%%%Proposal Covariance Matrix%%%%%%%%%%%%%%%%
%should be imported as covmat to Matlab before running the above program;
K
K
A
r
scl

A

0.07903
-12.97633
-12.97633 2869.77687
-0.00380
0.71946
-0.00047
0.08648

r
scl
-0.00380
-0.00047
0.71946
0.08648
0.00020
0.00002
0.00002
0.00001

%%%%%Function calculating the density for the Generalized t-distribution%%%%%%%%
%the function is used to calculate the likelihood;
function y = gentdst(x, m, s, v)
%x – data point, m – location, s – scale, v 0 degrees of freedom;
c=(1/sqrt(v))*(1/(beta(v/2, 0.5)));
y=(c/s)*(1+((x-m).^2)/(v*(s^2))).^(-0.5*(v+1));

