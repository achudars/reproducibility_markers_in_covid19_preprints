medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

1
2
3
4

Who dies from COVID-19? Post-hoc explanations of mortality prediction models

5

using coalitional game theory, surrogate trees, and partial dependence plots

6
7

Russell Yang¹

8
9
10
11

¹*The Harker School, San Jose, CA, USA

12
13
14
15

* Corresponding author

16

E-mail: russell.a.yang@gmail.com (RY)

17
18
19
20
21
22

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

1

Abstract

2

As of early June, 2020, approximately 7 million COVID-19 cases and 400,000 deaths have been

3

reported. This paper examines four demographic and clinical factors (age, time to hospital,

4

presence of chronic disease, and sex) and utilizes Shapley values from coalitional game theory

5

and machine learning to evaluate their relative importance in predicting COVID-19 mortality.

6

The analyses suggest that out of the 4 factors studied, age is the most important in predicting

7

COVID-19 mortality, followed by time to hospital. Sex and presence of chronic disease were

8

both found to be relatively unimportant, and the two global interpretation techniques differed in

9

ranking them. Additionally, this paper creates partial dependence plots to determine and

10

visualize the marginal effect of each factor on COVID-19 mortality and demonstrates how local

11

interpretation of COVID-19 mortality prediction can be applicable in a clinical setting. Lastly,

12

this paper derives clinically applicable decision rules about mortality probabilities through a

13

parsimonious 3-split surrogate tree, demonstrating that high-accuracy COVID-19 mortality

14

prediction can be achieved with simple, interpretable models.

15
16

Introduction

17

Interpretable machine learning is critically important in healthcare, and clinicians seek

18

explanations that justify and rationalize model predictions [1]. Medical professionals also prefer

19

parsimonious machine learning methods because of their explainability and because they are

20

more likely to conform to operational guidelines, which often include fixed attribute scores [2].

21

Thus, feature extraction is often eschewed in medical research because it reduces interpretability

22

[2].

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

23
24

The incubation period of COVID-19 is about 5.2 days [3], and there is a median length of 14

25

days between onset of symptoms and death [4]. COVID-19 symptoms include pneumonia, fever,

26

fatigue, and dry cough [5], and risk factors include pre-existing health conditions (asthma,

27

chronic lung/kidney disease, diabetes, hemoglobin disorders, being immunocompromised,

28

liver/heart disease), old age, and obesity [6]. COVID-19 mortality also varies among different

29

ethnicities, potentially due to discrimination, economic disadvantages, unequal access to health

30

care, and other factors [7].

31
32

ICU resources are scarce and ethical dilemmas arise in deciding how to allocate limited hospital

33

resources [8]. The demand for ICUs and beds in hospitals is increasing as the number of cases

34

rise, and ICUs already had high occupancy before the pandemic. Previous estimates of mean

35

hourly occupancy of ICUs put the number at about 68.2% [9].

36
37

Much of the current COVID-19 informatics literature focuses on macro-level disease forecasting

38

using machine learning and statistical techniques, with few studies focusing on individual-level

39

predictions. For example, [10] utilizes a SEIR (Susceptible-Exposed-Infectious-Removed)

40

differential equation-based model to predict the sizes and peaks of the COVID-19 pandemic, and

41

[11] utilizes a logistic model to understand the COVID-19 case trend. One study published in

42

Nature Machine Intelligence used various biomarkers (lactic dehydrogenase, lymphocyte and

43

high-sensitivity C-reactive protein) to achieve advanced individual-level COVID-19 mortality

44

predictions with 90% accuracy [12]. We hypothesize that demographic and temporal risk factors

1

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

45

can explain COVID-19 mortality as well, avoiding the time and cost associated with biomarker

46

measurement.

47
48

Recently, epidemiological datasets with demographic, geographic, and temporal data have

49

become available and have opened up new dimensions for COVID-19 modeling. One such

50

dataset is [13]. This study focuses on ranking the relative importance of age, time to hospital

51

after symptom onset, sex, and presence of chronic disease in COVID-19 mortality prediction and

52

developing a framework for local interpretation of COVID-19 mortality predictions in clinical

53

settings.

54
55

Methods

56

Sourcing and Preprocessing

57

This analysis utilized publicly available individual-level epidemiological data as of June 4th,

58

2020 [13]. The dataset includes various temporal, demographic, geographic, and environmental

59

attributes, including age, sex, city, province, country, sourced from Wuhan or elsewhere,

60

latitude, longitude, etc. It was aggregated from various sources and is extremely sparse. Several

61

preprocessing steps were employed to filter and clean the data.

62
63

4 suspected risk factors were studied as explanatory variables: age, time from onset of symptoms

64

to hospital admission, sex, and presence of chronic disease. The outcome variable was binary:

65

either recovery or mortality. The dataset was subsetted to include only relevant columns. The sex

66

binary categorical variable was encoded to numeric values. Samples were removed from the

67

analysis if they had missing values for any of the relevant variables. There was heterogeneity in

2

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

68

clinical variable annotation, so various values of outcome ('discharge', 'discharged', 'Discharged',

69

'recovered') were coded to 0 (recovery) and other values ('died', 'death') were coded to 1

70

(mortality). Patients with other outcome values ('severe', 'stable,' ‘Symptoms only improved with

71

cough. Currently hospitalized for follow-up.’) were removed from the analysis. For samples

72

where an age range was given instead of a single number, the lower and upper limits of the range

73

were averaged to produce a single number. One sample was assumed to have a coding error in

74

the date_onset_symptoms column and was removed. A new derived column to represent time

75

from onset of symptoms to hospital admission was created (time_to_hospital =

76

date_admission_hospital - date_onset_symptoms). One sample had a negative value for

77

time_to_hospital, which was assumed to be the result of a coding error and was removed.

78
79

After filtering and cleaning the dataset, 184 viable patients remained. These 184 patients may not

80

necessarily be representative of the global population (in terms of geographic location,

81

healthcare quality, etc.) because many samples had to be discarded in the preprocessing steps;

82

nonetheless, we hope that the relative importance of age, sex, time to hospital, and presence of

83

chronic disease will be relatively consistent between this sample and the global population.

84

Furthermore, some individuals may have experienced mortality after being discharged from the

85

hospital, but that information was not included in the dataset. Here, we provide visualizations

86

and descriptive statistics to understand the 184-patient dataset. Fig 1 provides histograms of the

87

continuous covariates and Table 1 provides summary statistics for the dataset. As shown in Table

88

1, the mean age of patients was about 48.02 (SD 18.62). 63.59% of patients were male. Chronic

89

disease was present in 20.11% of individuals, and the average time to hospital was 5.17 (SD

90

4.28). Approximately 25.54% of individuals in the dataset experienced mortality.

3

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Fig 1: Histograms for the two continuous covariates (age and time_to_hospital)

91

92

Table 1. Descriptive statistics for variables in the 184-patient dataset.

93

age (yrs)

time_to_hospital (days)

sex

chronic_disease_binary

outcome

mean

48.019022

5.168478

0.635870

0.201087

0.255435

std

18.615785

4.279687

min

1

0

Q1

33

2
Not applicable for binary data

median

46

5

Q3

61

7

max

89

26

94
95

An XGBoost model was trained for binary classification of patient mortality/recovery. XGBoost

96

utilizes a gradient tree boosting algorithm and provides state-of-the-art classification

97

performance in many scenarios [14]. The algorithm is highly scalable and utilizes minimal

4

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

98

machine resources [14]. The model was trained with default parameters using the Python

99

xgboost package. Table 2 shows various classification metrics of the XGBoost model when it

100

was trained on 70% of the data and tested on the remaining 30%. The model achieves an testing

101

accuracy of 0.91.
Table 2: Classification report for XGBoost model predictions on test set

102

Precision

Recall

F1 Score

Support

0 (Recovery)

0.95

0.93

0.94

44

1 (Mortality)

0.77

0.83

0.80

12

0.91

56

Accuracy
Macro Avg

0.86

0.88

0.87

56

Weighted Avg

0.91

0.91

0.91

56

103
104

Shapley Additive Explanations (SHAP)

105

SHAP is a method for model interpretation that relies on the Shapley value, a solution concept in

106

coalitional game theory. In coalitional game theory, the Shapley value represents a distribution

107

of a collective payoff/prediction among multiple participants/features. In feature interpretation

108

using Shapley values, predictions are compared between models with and without each feature

109

so that importance values can be assigned to each feature. Shapley values are given by the

110

following formula, where F is the feature set, the summation is over all the possible feature

111

subsets, the expression in brackets is the difference in predictions between a model trained on the

112

feature subset and a model trained on the same feature subset but also with feature i, and the

113

fraction is a factor for averaging [15]:

5

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

�

114

𝑆𝑆⊆𝐹𝐹{𝑖𝑖}

|𝑆𝑆|! (|𝐹𝐹| − |𝑆𝑆| − 1)!
�𝑓𝑓𝑆𝑆∪{𝑖𝑖} �𝑥𝑥𝑆𝑆∪{𝑖𝑖} � − 𝑓𝑓𝑆𝑆 (𝑥𝑥𝑆𝑆 )�
|𝐹𝐹|!

115

Intuitively the Shapley value can be interpreted as the expected value of the marginal

116

contribution to the coalition, and it is computed by adding each feature to a model and

117

understanding how it impacts the prediction. Shapley feature attribution methods possess several

118

desirable properties, including local accuracy, missingness, and consistency [15]. The method

119

used in this paper is Tree SHAP, which is a variant of SHAP for decision tree models. Tree

120

SHAP improves the time complexity of SHAP from exponential to polynomial [16].

121
122

Skater

123

The Skater package was also employed for model interpretation. The package was used to create

124

model-agnostic partial dependence plots and perform local interpretation using LIME (Local

125

Interpretable Model-Agnostic Explanations). Additionally, parsimonious tree surrogates were

126

created. Partial dependence plots specify the marginal effect of features on the response variable

127

in a model. According to [17], the partial dependence is given by the following formula, where S

128

is a subset of predictor indices and C is the complement of S:
𝑓𝑓𝑆𝑆 = 𝐸𝐸𝑥𝑥𝐶𝐶 [𝑓𝑓(𝑥𝑥𝑆𝑆 , 𝑥𝑥𝐶𝐶 )] = � 𝑓𝑓(𝑥𝑥𝑆𝑆 , 𝑥𝑥𝐶𝐶 )𝑑𝑑𝑑𝑑(𝑥𝑥𝐶𝐶 )

129
130

In practice, partial dependence is estimated using the following formula, where N is the number

131

of samples in the training set and 𝑥𝑥𝐶𝐶1 through 𝑥𝑥𝐶𝐶𝐶𝐶 are observed values of 𝑥𝑥𝐶𝐶 from the training set

132

[17]:

𝑁𝑁

1
𝑓𝑓�𝑠𝑠 = � 𝑓𝑓̂( 𝑥𝑥𝑆𝑆 , 𝑥𝑥𝐶𝐶𝐶𝐶 )
𝑁𝑁

133

𝑖𝑖=1

6

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

134

LIME is a technique that uses local approximations to a machine learning model to provide

135

interpretations of the prediction of any sample [18]. Roughly speaking, LIME perturbs the model

136

many times to determine the influence of each explanatory variable on the outcome variable.

137

LIME allows for rapid and clinically useful local interpretation of the model's predictions.

138

Furthermore, LIME explanations are locally faithful [18]. Surrogate trees are approximations of

139

complex models (such as those produced by the XGBoost algorithm). They are model-agnostic

140

since they can be trained by observing inputs and outputs of the underlying model [19].

141

Unfortunately (but unsurprisingly), a tradeoff exists between fidelity (how well the surrogate can

142

approximate the original model) and model complexity [19].

143
144

Results

145

Shapley Additive Explanations

146

A TreeExplainer from the shap package in Python was used to calculate Shapley values. The

147

TreeExplainer object can be used for global interpretations of the model as well as local

148

interpretations of the prediction for any individual. In Fig 2, the relative importance of

149

explanatory variables is plotted. According to the Shapley values, age is the most important of

150

the 4 features, followed by time_to_hospital, chronic_disease_binary, then sex.

7

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

151

Fig 2: Barplot of relative feature importance of explanatory variables as assessed by mean

152

absolute value of Shapley value

153
154

Fig 3 shows example local interpretations for two patients. In the figure, values of certain

155

features 'push' the prediction from an initial base value (bias) to a final model output value. In the

156

first patient, the low age (38) was the major factor that pushed the patient towards a smaller

157

model output value, whereas in the second patient, the high age (82) pushed the patient towards a

158

higher value. Also, being male pushed the model output up in the first patient and being female

159

pushed the model output down in the second patient. In the first individual, absence of chronic

160

disease pushes the model output down, while presence of chronic disease pushes the output up in

161

the second individual. Interestingly, a time to hospital value of 7 pushes one individual down and

162

the other up.

8

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Fig 3: Sample local explanations for a negative and positive individual

163

164
165

Fig 4, created using the shap package, shows local interpretations for all patients on one graph.

166

The magnitude of the SHAP value quantifies the importance of the feature in the model, and

167

each dot signifies a Shapley value for an individual’s feature.
Fig 4: SHAP Interpretation for all patients

168

169
170

Partial dependence plots were created for each of the four explanatory variables (Fig 5). Higher

171

values of age are associated with higher SHAP values. Values of 1 for sex (male) are associated

172

with higher SHAP values than 0 for sex (female). Likewise, values of 1 for

173

chronic_disease_binary (chronic disease present) are associated with higher SHAP values than 0

174

for chronic_disease_binary (chronic disease absent). The partial dependence plot for

175

time_to_hospital exhibits heteroskedasticity and cannot be easily interpreted.

9

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Fig 5: Partial dependence plots for each of the 4 explanatory variables

176

177
178

Fig 6 shows the partial dependence plot for age, and points are colored by time_to_hospital to

179

elucidate potential interactions between age and time_to_hospital.
Fig 6: Partial dependence plot for age with interaction index set to time_to_hospital

180

181

10

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

182

Skater Interpretations

183

The skater package in Python was also used to perform interpretation analyses. Skater, like shap,

184

has global and local interpretation abilities. As shown in Fig 7, the skater packages provides a

185

similar ordering of feature importance as the shap package. Age is the most important feature by

186

far, followed by time_to_hospital. However, skater ranks sex as more important than

187

chronic_disease_binary, while shap ranks chronic_disease_binary as more important than sex.

188

Fig 7: Barplot of relative feature importance of explanatory variables as assessed by skater

189

package

190
191

A LimeTabularExplainer object was then created using the skater package. LIME (Local

192

Interpretable Model-Agnostic Explanations) was used to perform local interpretations. Fig 8 lists

193

the factors contributing to recovery/death and summarizes them in a table, where orange colored

194

factors are those that contribute to mortality and blue colored factors are those that contribute to

195

recovery. For example, in the bottom patient (predicted to experience mortality), the high age,

196

presence of chronic disease, and time to hospital all contribute to the high probability of death.

11

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

197

Fig 8: LIME local interpretations for a patient who experienced recovery and was

198

predicted to recover (top) and for a patient who experienced mortality and was predicted

199

to die (bottom).

200
201

Skater also provides functionality for creation of partial dependence plots. Fig 9 shows one-way

202

partial dependence plots created by the skater package. These appear to be similar to the plots

203

created using the shap package.
Fig 9: Partial dependence plots with error bars as created by the skater package

204

205
12

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

206

Surrogate Trees

207

Although tree-based models are generally considered to be interpretable [20], XGBoost (like

208

other gradient boosting algorithms) combines many trees (100 by default) as weak predictors.

209

More parsimonious trees are required to find simple decision rules (heuristics) for use in a

210

clinical setting. Therefore, we create a parsimonious surrogate tree using the skater package (Fig

211

10).

212

Fig 10: A parsimonious 3-split surrogate decision tree. X0, X1, X2 and X3 are age, sex,

213

chronic_disease_binary, and time_to_hospital respectively.

214
215

Rules of thumb can easily be extracted from this parsimonious tree. In this tree, four simple

216

decision rules can be extracted:
1. If the person’s age is 57.5 or less and they do not have chronic disease, the probability of

217

mortality is 3.5%.

218

2. If the person’s age is 57.5 or less and they have chronic disease, the probability of

219

mortality is 66.7%.

220

3. If the person’s age is greater than 57.5 and they get to the hospital in 2 days or less (after

221

symptom onset), the probability of mortality is 42.9%.

222

13

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

4. If the person’s age is greater than 57.5 and they get to the hospital after more than 2 days,

223

the probability of mortality is 93.3%.

224
225

Note that in this tree, the sex variable was not used, but different trees using different

226

combinations of explanatory variables can be created by tweaking the random seed of the

227

surrogate explainer. Various classification metrics were calculated to assess the prediction

228

performance of the parsimonious model on the test data (Table 3). Interestingly, the more

229

parsimonious model still achieves a classification accuracy of 84% despite only having 3 splits.
Table 3: Classification report for 3-split surrogate tree predictions on test set

230

Precision

Recall

F1 Score

Support

0 (Recovery)

0.95

0.84

0.89

44

1 (Mortality)

0.59

0.83

0.69

12

0.84

56

Accuracy
Macro Avg

0.77

0.84

0.79

56

Weighted Avg

0.87

0.84

0.85

56

231
232

Discussion

233

This paper developed an XGBoost model for prediction of individual-level COVID-19 mortality

234

and performed global and local model interpretations using Shapley values from coalitional

235

game theory. Global and local intepretations were also performed using the skater package. Both

236

methods resulted in the similar ranking of the relative importance of the four explanatory

237

variables studied, placing age as the most important feature and time to hospital after symptom

238

onset as the second most important. The interpretation techniques differed in that one ranked sex

239

as more important than chronic disease presence while the other ranked chronic disease presence

14

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

240

as more important than sex. Lastly, a surrogate tree model was developed by perturbing the

241

XGBoost model’s inputs and observing the outputs. The surrogate tree achieved a high degree of

242

parsimony while retaining a relatively high predictive accuracy of 84%. Because of its

243

parsimony, the surrogate tree model retains interpretability and can potentially be used in a

244

clinical setting. Furthermore, rules-of-thumb about COVID-19 mortality probabilities can easily

245

be derived by tracing different root-to-leaf paths on the tree.

246
247

Hospital systems are not generally well-equipped to handle pandemics, and many hospitals are

248

facing resource shortages. Some estimates suggest that at the peak of the COVID-19 outbreak in

249

the US, the number of ICU beds required would be 3.8 times the number in existence [21].

250

COVID-19 mortality prediction models can potentially be used to help allocate resources to

251

those with the highest risk of dying in hospitals with limited resources and high load. In addition

252

to developing as a potential tool for clinical resource allocation, this study determines the relative

253

importance of four suspected risk factors and demonstrates the viability of local model

254

interpretations for data-driven clinical decision-making.

255
256

To the best of our knowledge, no other published studies have predicted COVID-19 mortality

257

solely off of demographic and temporal variables. This paper demonstrates that COVID-19

258

mortality prediction can be accomplished with 91% accuracy (or 84% in the parsimonious

259

model) without the use of cellular, molecular, and chemical biomarkers.

260

15

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

261

Future analysis is required to determine the joint effect of multiple features on outcome and

262

explore other demographic, spatial, temporal, and environmental factors as data on them

263

becomes readily available.

264

Acknowledgements

265

None

266

References
1.

267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298

2.
3.

4.

5.

6.
7.
8.
9.

10.

11.

12.

16

Tonekaboni S, Joshi S, McCradden MD, Goldenberg A. What Clinicians Want:
Contextualizing Explainable Machine Learning for Clinical End Use. In: Finale D-V,
Jim F, Ken J, David K, Rajesh R, Byron W, et al., editors. Proceedings of the 4th
Machine Learning for Healthcare Conference; Proceedings of Machine Learning
Research: PMLR; 2019. p. 359--80.
Vellido A, Martín-Guerrero JD, Lisboa PJG, editors. Making machine learning
models interpretable. ESANN; 2012.
Li Q, Guan X, Wu P, Wang X, Zhou L, Tong Y, et al. Early Transmission Dynamics
in Wuhan, China, of Novel Coronavirus–Infected Pneumonia. New England Journal
of Medicine. 2020;382(13):1199-207.
Wang W, Tang J, Wei F. Updated understanding of the outbreak of 2019 novel
coronavirus (2019-nCoV) in Wuhan, China. Journal of Medical Virology.
2020;92(4):441-7.
Lei S, Jiang F, Su W, Chen C, Chen J, Mei W, et al. Clinical characteristics and
outcomes of patients undergoing surgeries during the incubation period of COVID-19
infection. EClinicalMedicine. 2020;21:100331.
Centers for Disease Control and Prevention. Groups at Higher Risk for Severe Illness
2020.
Webb Hooper M, Nápoles AM, Pérez-Stable EJ. COVID-19 and Racial/Ethnic
Disparities. JAMA. 2020.
White DB, Lo B. A Framework for Rationing Ventilators and Critical Care Beds
During the COVID-19 Pandemic. JAMA. 2020;323(18):1773-4.
Wunsch H, Wagner J, Herlim M, Chong DH, Kramer AA, Halpern SD. ICU
occupancy and mechanical ventilator use in the United States. Critical care medicine.
2013;41 12:2712-9.
Yang Z, Zeng Z, Wang K, Wong S-S, Liang W, Zanin M, et al. Modified SEIR and
AI prediction of the epidemics trend of COVID-19 in China under public health
interventions. Journal of thoracic disease. 2020;12(3):165-74.
Rui H, Miao L, Yongmei D. Spatial-temporal distribution of COVID-19 in China and
its prediction: A data-driven modeling analysis. The Journal of Infection in
Developing Countries. 2020;14(03).
Yan L, Zhang H-T, Goncalves J, Xiao Y, Wang M, Guo Y, et al. An interpretable

medRxiv preprint doi: https://doi.org/10.1101/2020.06.07.20124933; this version posted June 9, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325

13.

14.

15.
16.
17.

18.

19.
20.

21.

17

mortality prediction model for COVID-19 patients. Nature Machine Intelligence.
2020;2(5):283-8.
Xu B, Gutierrez B, Mekaru S, Sewalk K, Goodwin L, Loskill A, et al.
Epidemiological data from the COVID-19 outbreak, real-time case information.
Scientific Data. 2020;7(1):106.
Chen T, Guestrin C. XGBoost: A Scalable Tree Boosting System. Proceedings of the
22nd ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining. 2016.
Lundberg S, Lee S-I. A Unified Approach to Interpreting Model Predictions. ArXiv.
2017;abs/1705.07874.
Lundberg SM, Erion GG, Lee S-I. Consistent Individualized Feature Attribution for
Tree Ensembles. ArXiv. 2018;abs/1802.03888.
Goldstein A, Kapelner A, Bleich J, Pitkin E. Peeking Inside the Black Box:
Visualizing Statistical Learning With Plots of Individual Conditional Expectation.
Journal of Computational and Graphical Statistics. 2015;24(1):44-65.
Ribeiro MT, Singh S, Guestrin C. “Why Should I Trust You?”: Explaining the
Predictions of Any Classifier. Proceedings of the 22nd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining; San Francisco, California,
USA: Association for Computing Machinery; 2016. p. 1135–44.
Castro FD, Bertini E, editors. Surrogate Decision Tree Visualization. IUI Workshops;
2019.
Elshawi R, Al-Mallah MH, Sakr S. On the interpretability of machine learning-based
model for predicting hypertension. BMC Medical Informatics and Decision Making.
2019;19(1):146.
Moghadas SM, Shoukat A, Fitzpatrick MC, Wells CR, Sah P, Pandey A, et al.
Projecting hospital utilization during the COVID-19 outbreaks in the United States.
Proceedings of the National Academy of Sciences. 2020;117(16):9122-6.

