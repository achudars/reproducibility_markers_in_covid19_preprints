Evaluating the Impact of COVID-19 on Cyberbullying through
Bayesian Trend Analysis
Sayar Karmakar

Sanchari Das

arXiv:2009.02126v1 [cs.SI] 8 Aug 2020

University of Florida
sayarkarmakar@ufl.edu

Indiana University & University of Denver
sancdas@iu.edu

ABSTRACT

1

COVID-19’s impact has surpassed from personal and global health
to our social life. In terms of digital presence, it is speculated that
during pandemic, there has been a significant rise in cyberbullying.
In this paper, we have examined the hypothesis of whether cyberbullying and reporting of such incidents have increased in recent
times. To evaluate the speculations, we collected cyberbullying related public tweets (N = 454, 046) posted between January 1st , 2020
– June 7t h , 2020. A simple visual frequentist analysis ignores serial
correlation and does not depict changepoints as such. To address
correlation and a relatively small number of time points, Bayesian
estimation of the trends is proposed for the collected data via an
autoregressive Poisson model. We show that this new Bayesian
method detailed in this paper can clearly show the upward trend on
cyberbullying-related tweets since mid-March 2020. However, this
evidence itself does not signify a rise in cyberbullying but shows
a correlation of the crisis with the discussion of such incidents by
individuals. Our work emphasizes a critical issue of cyberbullying
and how a global crisis impacts social media abuse and provides
a trend analysis model that can be utilized for social media data
analysis in general.

Bullying is characterized as the “repeated oppression, psychological
or physical, of a less powerful person by a more powerful one” [18].
With the ascent of online communication, the dynamics of bullying
have transcended beyond physical boundaries to the digital realm,
referred to as “cyberbullying” . Cyberbullying has gotten increasingly pervasive, as focused exploitation has moved from face to
face to advanced stages, targeting users despite geographic constraints [44, 52]. Victims of cyberbullying can be targeted through
various sources, including mobile phones, video cameras, emails,
and web pages [53]. Cyberbullying can negatively impact mental
health, with 32% of victims reporting symptoms of stress and 38%
of victims experiencing emotional distress, even after the online
abuse stops [19, 54].
Earlier investigations have indicated that web-based social networking has expanded the impact of cyberbullying [54]. On social
networking sites and applications, cyberbullying is particularly
common, with 66% of all cyberbullying episodes occurring on these
platforms 1 . Twitter permits individuals to now and again interact
with outsiders (counting celebrities) [11]; however, this also leads
others to mirror and forge identities online and trick users [47].
Verification of profiles only works for celebrities or those who are
well-known in their field, making it difficult to verify an individual’s identity [31]. It is even more challenging to identify abusers
when they are imitating someone else. Due to the correlation of cyberbullying with social media usage, individuals often have shown
negative user experience in these social media platforms [36].
Besides, with the current COVID-19 pandemic, individuals have
increased their social media use to remain associated with others
while social distancing [50]. In any case, there have likewise been
reports of incivility through such platforms [23]. An abrupt ascent
in internet-based life use - joined by children and adolescents continually utilizing such stages - could make a concerning spike in
cyberbullying 2 . Along these lines, our goal was to explore explicitly: How has a crisis, such as a pandemic (COVID-19), impacted
reporting and discussions of cyberbullying incidents on Twitter?
To understand users’ perspectives, we collected 454, 046 of publicly available tweets about cyberbullying to understand user discussions online. We first tried a simple visual analysis to detect a
significant rise in the incidence count of these keywords anytime
around March. However, as one can see from Figure 1 or 2 such
a changepoint is not very prominent. This allowed us to address
the shortcomings of such a simplistic model, which ignores the
possibility of a smooth change, the inherent dependence in the time
series of counts. The initial analysis motivated our research to build
a suitable autoregressive bayesian model, as described in Section 5.

CCS CONCEPTS
• Security and privacy → Human and societal aspects of security and privacy; Social aspects of security and privacy; Privacy protections.

KEYWORDS
Social Media, Cyberbullying, Twitter, Time Series, Change-point,
Bayesian, COVID-19, Pandemic
ACM Reference Format:
Sayar Karmakar and Sanchari Das. 2020. Evaluating the Impact of COVID19 on Cyberbullying through Bayesian Trend Analysis. In EICC ’20: ACM
Symposium on European Interdisciplinary Cybersecurity Conference, November 18–19, 2020, Rennes, France. ACM, New York, NY, USA, 6 pages.
https://doi.org/10.1145/1122445.1122456

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
EICC ’20, November 18–19, 2020, Rennes, France
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00
https://doi.org/10.1145/1122445.1122456

INTRODUCTION

1 https://www.pewresearch.org/internet/2014/10/22/part-2-the-online-environment/

2 https://www.digitaltrends.com/news/coronavirus-cyberbullying-separationlearning/

EICC ’20, November 18–19, 2020, Rennes, France
We choose a time-varying Bayesian method previously detailed
by Karmakar et al. [40]. As hypothesized, we noticed an increase
in cyberbullying incident discussions during the pandemic, which
shows an impact of the crisis on cyberbullying trends. Our method
allowed us to construct posterior samples of the parameter function
of time with the collected data. To the best of our knowledge, this
work is the first quantitative trend analysis on a large sample data.
Our results also reveal a clear telling effect of COVID-19 on worsening cyberbullying incidents as reported and discussed through
tweets. Based on our quantitative work, we can explore in-depth
qualitative analysis as a future extension of this work to further see
the details of the discussed tweets.

2

RELATED WORK

Cyberbullying has expanded significantly with the advent of social media and billions of users being online everyday [44]. User
experience of cyberbullying has been reported in several social networking platforms, chat rooms, and mobile messaging applications;
such abuse transcends beyond geographical proximity [45, 48]. Furthermore, in light of the fact of crisis, it is being speculated that the
crisis has increased cyberbullying incidents [13]. To address the
issue of cyberbullying, prior research has investigated online maltreatment and created effective technical and policy-focused [9, 10]
mitigation strategies. However, though some of these strategies are
being implemented through social media policy management, there
are several privacy concerns of the social media users [4, 14]. Thus,
the speculation about the rise of cyberbullying due to a pandemic
is a natural progression, which requires detailed analysis to verify
such hypothesis. To understand further, we start by analyzing the
cyberbullying discussion trends over twitter.

2.1

Emergence and Effects of Cyberbullying

Mason defined cyberbullying as “an individual or a group willfully
using information and communication involving electronic technologies to facilitate deliberate and repeated harassment or threat
to another individual or group by sending or posting cruel text
and/or graphics using technological means” [28]. To investigate
further, Nocentini et al. studied the behaviour of the attackers for
different types of cyberbullying, including imbalance of power, intention, repetition, anonymity, and publicity [35]. Previous works
have explored the effects of cyberbullying on targets, especially
on teenagers; sometimes such abuses can impact both the cyberaggressors and cybervictims [5, 29, 43, 51]. Dredge et al. noted the
detrimental effects of cyberbullying on the social and emotional
lives of targets, with the severity of the impact of the harassment
depending on different factors, including the anonymity of the
perpetrators and the presence of bystanders [17]. All of the abovementioned studies and several other researchers [24, 38] indicate
the severity of cyberbullying on individuals and for the society,
thus it is critical to develop strong defense against cyberbullying.

2.2

Defence Against Cyberbullying

2.2.1 Technical Mitigation Techniques. Several technical mitigation
techniques have been proposed, with the goal of automatically detecting and intervening in cyberbullying incidents online [2, 3]. For
instance, Dinakar et al. proposed an online dashboard, which would

Karmakar and Das
allow moderators to track potential bullying incidents on a forum
through natural language processing [16]. Mondal et al. analyzed
hate speech on Twitter and Whisper to improve automated detection of bullying [34], while Cortis and Handschuh analyzed bullying
tweets in the context of major world events [7]. Such technical mitigation strategies are helpful, yet it is also critical to understand an
individual’s perspective and any policy implementation strategies
adapted by the social media organizations.
2.2.2 Organizational Policies. As a mitigating measure, some prior
work has focused on improving social media policies to prevent
perpetrators from abusing their victims [8]. Pater et al. compared
the social media policies of 15 different platforms and found that
these policies vary from mild censoring to the involvement of law
enforcement [39]. Given the legal implications, there can be severe
consequences for such incidents for these social media organizations [33]. Milosevic examined the responsibilities of social media
companies in addressing cyberbullying among children [32].
2.2.3 User Perspective. In order to improve anti-harassment measures, previous research has examined the motivations of cyberbullies [15, 25, 30, 42]. Lee and Kim interviewed 110 subjects to
investigate why social media users leave benevolent or malicious
comments [26]. Whittaker and Kowalski found that cyber aggression was more present in online comment sections and forum replies
than on Facebook, again suggesting the importance of anonymity [49].
Overall, these defensive mechanisms are helpful and aid in making internet and online experience better for individuals. But, even
with such strong defensive tactics, it is speculated that cyberbullying has increased, especially during the COVID-19. Thus, for our
work we try to understand the problem better through detailed
quantitative analysis.

2.3

Cyberbullying Trend Analysis

Studies that analyze trends in cyberbullying are helpful in understanding how events can impact digital users. Schneider et al. conducted four surveys across 17 high schools and found that the
overall rate of cyberbullying increased from 2006 to 2012 [22]. Snell
and Englander through survey-based analysis found that females
are more likely to be involved in cyberbullying as both victims and
as perpetrators, indicating the importance of gender as a factor
in mitigating online bullying [46]. Mangaonkar et al. used a distributed design for analyzing tweets and detecting cyberbullying
in real-time [27].
Twitter allows users to express themselves in 280 character
‘tweets;’ prior studies have analyzed these messages for cyberbullying [1, 37]. Cortis and Handschuh analyzed bullying tweets in the
context of two trending events (the Ebola outbreak and shooting
of Michael Brown in Ferguson, Missouri) and identified commonly
used hashtags and named entitites in bullying tweets [7]. They tried
to identify cyberbullies through these discussions, but whether or
not such crisis situations increased bullying tweets was not studied.
Due to an increase in individuals’ online digital presence, assumptions have been made that the pandemic situation from COVID-19
can increase cyberbullying attacks. Thus, our goal was to find concrete evidence to support or contradict this hypothesis, also rather

Bayesian Trend Analysis of Cyberbullying
than surveys, we chose to collect data from Twitter itself to get the
real-time trend of such critical incidents.

3

3 keywords 96, 147, tweets). The daily count distribution for these
sub-classes are shown in Figure 2.

METHOD: DATA COLLECTION

With over 300 million active daily users, Twitter 3 is an ideal data
source 4 . Thus, to assess the impact of COVID-19 on cyberbullying,
we collected 454, 046 public tweets on Twitter, all of which mentioned cyberbullying. We scraped Twitter for user-posted, publicly
available tweets related to the topics of cyberbullying, social media
bullying, online harassment, etc. The data was collected using Get
Old Tweets API 5 , which allowed us to access tweets older than one
week. This API was used in the web crawler written in Python, and
the data was stored with MongoDB. The data collection spanned
from January 1st 2020–June 7th 2020. This timeline was particularly selected to note the impact of COVID-19 on online users and
determine whether the crisis situation led to an increase in online abuse. We used the following key terms when conducting our
search: Internet bullying, Internet bully, Internet bullies, online abuse,
online harassment, online shaming, online stalking, cyberbullying,
social media bullying, stop cyberbullying, cyberbully, cyberbullies, FB
bullying, FB cyberbullying, FB harassment, FB victim, Facebook bullying, Facebook cyberbullying, Facebook victim, Facebook harassment,
Twitter bullying, Twitter cyberbullying, Twitter harassment, Twitter
victim, Insta bullying, Insta cyberbullying, Insta harassment, Insta
victim. We only collected direct tweets and removed any retweets
or duplicate tweets.

4

EICC ’20, November 18–19, 2020, Rennes, France

CHANGE-POINT ANALYSIS

After completing the data collection, we performed trend analysis
to evaluate the impact of the crisis situation, such as COVID-19
pandemic on cyberbullying. Using the timestamp of the post, we
obtained the daily count of the tweets which including at least one
of these keywords. Figure 1 shows the daily count for the 159 days
from 01st January, 2020 to 07t h June, 2020.

Figure 1: Daily count of total tweets related to bullying
Some of the types of keywords had fewer tweets with negligible impact on the analysis. Thus, we broadly divide them in 3 sub-classes:
keywords containing “cyber” (CY, 7 keywords, 235, 542 tweets),
“online/internet”(ON, 6 keywords, 96, 629 tweets) and “twitter”(TW,
3 https://twitter.com/login

4 https://www.statista.com/statistics/282087/number-of-monthly-active-twitter-users/
5 https://github.com/Jefferson-Henrique/GetOldTweets-python

Figure 2: Daily count of total tweets for the three sub-class

4.1

Traditional Change-Point Analysis

In a traditional change-point analysis, one looks for an abrupt
change; i.e. after observing X 1 , . . . , XT if we suspect there is at most
one change point then we are looking for the unknown location
1 ≤ τ ≤ T , such that
E(X i ) = µ if i ≤ τ , and E(X i ) = µ + δ if i > τ where δ , 0

(1)

The analysis shows a clear pattern that is prevalent to all the
counts and the sub-classes that we present here. Overall, except
for the sub-class ‘ON’ , there does not seem to be a huge change
in mean except it went slightly upwards since mid-March and in
all categories including the total. We notice a huge spike in the
cyberbullying related tweets in the second half of May. The sudden
rise in the frequency of tweets in the second half May, can be due
to the untimely demise of the Japanese TV star 6 which occurred
due to cyberbullying. Moreover for the class ‘ON’ , one can see
a significant spike in the second half of February and the overall
mean also had an upward trend. This may or may not be due to
the pandemic. Note that except for the spike in later half of May,
there is no abrupt break due to COVID-19. The authors explored
([12]) such a simple change-point model as an work in progress.
However we believed that a simple model like (1) can often fail to
adequately capture some other sophistication that are particular to
the data we collected here.

4.2

Short-coming of the simpler model

Abrupt change vs Smooth change: Note that the change-point model
in 1 address for abrupt change. However, due to the heterogeneous
nature of Twitter, one can expect the change might not be abrupt
and this can explain why just from the daily count summaries of
the total tweets or the sub-classes do not reveal any abrupt change
6 https://www.japantimes.co.jp/news/2020/05/30/national/media-national/

online-harrassment/

EICC ’20, November 18–19, 2020, Rennes, France
in either mean or variance in general. A more meaningful model
could be where the parameters change smoothly over time and we
can estimate these parameters as function of time and see whether
the trend is increasing due to COVID-19 or not.
Dependence: Note that, the daily time count of number of occurrences is a time-series. Any visual analysis of change-point
would heavily disregard the inherent dependence assumption that
is present in a time-series. These counts depend heavily on current
trend and are expected to show strong correlation with recent pasts.
We decide to furnish this through the following Figure 3. Under
such heavy dependence for the total count and the three sub-series,
one needs to take the dependence into account. Otherwise any analysis, be it abrupt change point or smooth time-varying parameter
model will not be justified.

Karmakar and Das
expectation of X t in the above model (2) is E(X t |Ft −1 ) = µ(t/T ) +
Íp
i=1 ai (t/T )X t −i , which is positive-valued. Additionally, we impose the following constraints on parameter space for the timevarying parameters,
Õ
P1 = {µ, ai : µ(x) > 0, 0 ≤ ai (x) ≤ 1, sup
ak (x) < 1}. (3)
x

k

When p = 0, our proposed model reduces to routinely used nonparametric independent Poisson regression model as in [41]. The
µ(·) function correspond to the general mean trend at time t and
ap (·), the p-th order autoregressive (AR hereafter) coefficient function denotes how the observation at time t is affected by a past
observation at lag p. The strong correlation pattern in Figure 3
shows we should opt for a p > 0.

5.2

Posterior Computation

To proceed with Bayesian computation, we put priors on the unknown functions µ(·) and ai (·)’s such that they are supported in P1 .
The prior distributions on these functions are induced through basis
expansions in B-splines with suitable constraints on the coefficients
to impose the shape constraints as in P. Detailed description of the
priors are given below,
µ(x) =

5

SMOOTH CHANGE: A BAYESIAN MODEL

In order to address the inadequacy of a visual detection of changepoint, we propose the following time-varying Bayesian autoregressive count (TVBARC) model from [40]. Note that this model
addresses the short-comings mentioned above.

5.1

Model

Due to the possibly non-stationary (over time) nature of the data, we
propose a time-varying version of the linear Poisson autoregressive
model [6, 55]. The conditional distribution for count-valued timeseries X t given Ft −1 = {X i : i ≤ (t − 1)} is,
X t |Ft −1 ∼Poisson(λt ) where λt = µ(t/T ) +

p
Õ

ai (t/T )X t −i . (2)

i=1

Due to the Poisson link in (2), both conditional mean and conditional variance depend on the past observations. The conditional

exp(β j )B j (x), ai (x) =

j=1

Figure 3: Daily count of total tweets for the three sub-class
Poisson count time series: Also note that the daily number of occurrences is a count series but unfortunately the traditional changepoint analysis often assume normality (Normal distribution). Another advantage of using Poisson random variable is it can model
the mean and variance through a single parameter.
Small sample size: A wide range of frequentist time-varying
model were discussed in [21] and [20] that relied on kernel-based
methods. However, one needs a large sample (Sample time point
size of at least 500) to estimate any time-trend with precision. This
is a sheer shortcoming of the kernel based methods that are essential for a frequentist model. But here we collected tweets of first 5
months of 2020 resulting in a sample of 159 time points.

K1
Õ

Mi = Íp

θ i j Mi B j (x),

0 ≤ θ i j ≤ 1,

j=1

exp(δi )

k =0

K2
Õ

exp(δk )

,

i = 1, . . . , p,

δl ∼N (0, c 1 ), for 0 ≤ l ≤ p, β j ∼ N (0, c 2 ) for 1 ≤ j ≤ K 1 ,
θ i j ∼U (0, 1) for 1 ≤ i ≤ p, 1 ≤ j ≤ K 2 .
Here B j ’s are the B-spline basis functions and δ j ’s are unbounded.
The prior induced by above construction are P-supported. The
verification is straightforward and can be found in [40]. We develop efficient MCMC algorithm to sample the parameter β, θ and
δ from the above likelihood. Interested readers can see [40] for the
computation of the likelihood and partial derivatives.

6

ANALYSIS OF DAILY COUNT DATA

We first analyze the total count trends through two different choices
of lag p: an AR(1) and an AR(10) model. Often there could be weekly
patterns which could mean high correlation at lag 7 and also lag
8 if lag 1 was significant. To see if there is really a weekly pattern
we decided to take a lag that is slightly higher than 7. The trend
functions with their corresponding credible intervals (we omit the
credible intervals for 10 AR coefficients for clarity) are shown in
Figure 4, 5 and 6. The trend and the credible intervals are mean and
quantiles of 20000 posterior MCMC samples after 10000 burn-in.
When we increase the number of lags to 10, we no longer report
the credible intervals. From the above figures we summarize the
findings as follows:
• Mean trend increased from March 9th or so. If we contrast
this with Figure 1, it is easy to appreciate the significant role
of dependence for such time-series data.
• For the AR(1) model, it increased upto March and then slowly
decreased, it was again reaching a peak around end of May.

Bayesian Trend Analysis of Cyberbullying

EICC ’20, November 18–19, 2020, Rennes, France

Figure 4: Total count: Mean trend of AR(1) model

Figure 5: Total count: AR(1) trend of AR(1) model

Figure 7: Sub-classes: Mean and AR(1) trends of model

Figure 6: Total count: AR trends of AR(10) model
• The AR(1) and AR(10) models are comparable and usually
only the first lag accounts for most of the correlation. The
mean trend µ(t) came out to be very similar to Figure 4.
• The 95% credible intervals provided are very narrow and
thus gives us a significant confidence about the true trends
being of similar nature.
Next we analyze the three sub-classes under the AR(1) model and
put them together in Figure 7. These sub-classes are very similar to
the original total count. In all three of them there is a rise around
first week of March and the rise continues for a while (except class
TW). Nothing significant can be said about the AR coefficients
except that the are also non-stationary. Note that with smaller
number of data points for the classes ON and TW one can see the
credible intervals are wider which is understandable.

7

CONCLUSION

Cyberbullying is a primary concern, and there have been several
speculations on the increase in cyberbullying incidents during
COVID-19. To start with this investigation, we perform a comprehensive Bayesian analysis of the daily count of cyberbullying
occurrences and its dominant classes on cyberbullying-related public tweets (N = 454, 046) posted between January 1st , 2020 – June
7th , 2020. We developed a Bayesian model that exhibited a sharp

increase in the general mean trend for most of these twitter keywords related to cyberbullying. The significant AR correlation was
at lag 1, and it evolved around 0.4-0.6 but not in a monotonic way.
This analysis showed the increase in the cyberbullying discussion
trend by Twitter users during COVID-19, which may or may not be
due to the pandemic’s direct impact. However, to further analyze
the content discussed in these tweets, we plan to perform in-depth
qualitative analysis. Our work is novel due to its first quantitative
trend analysis on understanding the users based on their discussions regarding cyberbullying, especially during a pandemic crisis.
Since COVID-19 has spread in multiple phases, it will be of utmost
importance to detect such a high rise in social media trends.

ACKNOWLEDGMENTS
We would like to thank Umang Mehta for his help with the data
collection. We would also like to acknowledge the support of Secure and Privacy Research in New-Age Technology (SPRINT) Lab,
University of Denver; and Human and Technical Security (HATS)
Lab, Indiana University, and University of Florida. Any opinions,
findings, and conclusions or recommendations expressed in this
material are solely those of the author(s).

REFERENCES
[1] Sophia Alim. 2015. Analysis of tweets related to cyberbullying: exploring information diffusion and advice available for cyberbullying victims. International
Journal of Cyber Behavior, Psychology and Learning (IJCBPL) 5, 4 (2015), 31–52.
[2] Zahra Ashktorab. 2016. A Study of Cyberbullying Detection and Mitigation on
Instagram. In Proceedings of the 19th ACM Conference on Computer Supported
Cooperative Work and Social Computing Companion. 126–130.

EICC ’20, November 18–19, 2020, Rennes, France
[3] Zahra Ashktorab and Jessica Vitak. 2016. Designing cyberbullying mitigation and
prevention solutions through participatory design with teenagers. In Proceedings
of the 2016 CHI Conference on Human Factors in Computing Systems. 3895–3905.
[4] Emmanuel W Ayaburi and Daniel N Treku. 2020. Effect of penitence on social
media trust and privacy concerns: The case of Facebook. International Journal of
Information Management 50 (2020), 171–181.
[5] Rina A Bonanno and Shelley Hymel. 2013. Cyber Bullying and Internalizing
Difficulties: Above and Beyond the Impact of Traditional Forms of Bullying.
Journal of Youth and Adolescence 42, 5 (2013), 685–697.
[6] Patrick T Brandt and John T Williams. 2001. A linear Poisson autoregressive
model: The Poisson AR (p) model. Political Analysis 9, 2 (2001), 164–184.
[7] Keith Cortis and Siegfried Handschuh. 2015. Analysis of Cyberbullying Tweets
in Trending World Events. In Proceedings of the 15th International Conference on
Knowledge Technologies and Data-driven Business. 1–8.
[8] Kate Crawford and Tarleton Gillespie. 2016. What is a Flag for? Social Media
Reporting Tools and the Vocabulary of Complaint. New Media & Society 18, 3
(2016), 410–428.
[9] Sanchari Das, Jayati Dev, and L Jean Camp. 2019. Privacy Preserving Policy
Model Framework. Available at SSRN 3427634 (2019).
[10] Sanchari Das, Jayati Dev, and Kaushik Srinivasan. 2018. Modularity is the Key A
New Approach to Social Media Privacy Policies. In Proceedings of the 7th Mexican
Conference on Human-Computer Interaction. 1–4.
[11] Sanchari Das, Javon Goard, and Dakota Murray. 2017. How Celebrities Feed
Tweeples with Personal and Promotional Tweets: Celebrity Twitter Use and
Audience Engagement. In Proceedings of the 8th International Conference on Social
Media & Society. 1–5.
[12] Sancahri Das, Andrew Kim, and Sayar Karmakar. 2020. Change-Point Analysis
of Cyberbullying-Related Twitter Discussions During COVID-19. 16th Annual
Social Informatics Research Symposium (ASIS&T) (2020).
[13] Anneliese Depoux, Sam Martin, Emilie Karafillakis, Raman Preet, Annelies
Wilder-Smith, and Heidi Larson. 2020. The Pandemic of Social Media Panic
Travels Faster than the COVID-19 Outbreak.
[14] Jayati Dev, Sanchari Das, and Linda Jean Camp. 2018. Privacy Practices, Preferences, and Compunctions: WhatsApp Users in India.. In HAISA. 135–146.
[15] Dominic DiFranzo, Samuel Hardman Taylor, Franccesca Kazerooni, Olivia D
Wherry, and Natalya N Bazarova. 2018. Upstanding by design: Bystander intervention in cyberbullying. In Proceedings of the 2018 CHI conference on human
factors in computing systems. 1–12.
[16] Karthik Dinakar, Birago Jones, Catherine Havasi, Henry Lieberman, and Rosalind
Picard. 2012. Common Sense Reasoning for Detection, Prevention, and Mitigation
of Cyberbullying. ACM Transactions on Interactive Intelligent Systems (TiiS) 2, 3
(2012), 1–30.
[17] Rebecca Dredge, John Gleeson, and Xochitl De la Piedad Garcia. 2014. Cyberbullying in Social Networking Sites: An Adolescent VictimâĂŹs Perspective.
Computers in Human Behavior 36 (2014), 13–20.
[18] David P Farrington. 1993. Understanding and Preventing Bullying. Crime and
Justice 17 (1993), 381–458.
[19] David Finkelhor, Kimberly J Mitchell, and Janis Wolak. 2000. Online Victimization:
A Report on the Nation’s Youth. (2000).
[20] Sayar Karmakar. 2018. Asymptotic Theory for Simultaneous Inference Under
Dependence. Technical Report. University of Chicago.
[21] Sayar Karmakar, Stefan Richter, and Wei Biao Wu. 2020+. Simultaneous inference
for time-varying models. In revision, https:// sayarkarmakar.github.io/ publications/
sayar1.pdf (2020+).
[22] Shari Kessel Schneider, Lydia O’Donnell, and Erin Smith. 2015. Trends in cyberbullying and school bullying victimization in a regional census of high school
students, 2006-2012. Journal of School Health 85, 9 (2015), 611–620.
[23] Bumsoo Kim. 2020. Effects of Social Grooming on Incivility in COVID-19. Cyberpsychology, Behavior, and Social Networking (2020).
[24] Robin M Kowalski, Susan P Limber, and Patricia W Agatston. 2012. Cyberbullying:
Bullying in the digital age. John Wiley & Sons.
[25] Cheng-Yu Lai and Chia-Hua Tsai. 2016. Cyberbullying in the Social Networking Sites: An Online Disinhibition Effect Perspective. In Proceedings of the 3rd
Multidisciplinary International Social Networks Conference. 1–6.
[26] So-Hyun Lee and Hee-Woong Kim. 2015. Why People Post Benevolent and
Malicious Comments Online. Commun. ACM 58, 11 (2015), 74–79.
[27] Amrita Mangaonkar, Allenoush Hayrapetian, and Rajeev Raje. 2015. Collaborative
detection of cyberbullying behavior in Twitter data. In 2015 IEEE International
Conference on Electro/Information Technology (EIT). IEEE, 611–616.
[28] Kimberly L Mason. 2008. Cyberbullying: A preliminary assessment for school
personnel. Psychology in the Schools 45, 4 (2008), 323–348.
[29] Bridget Christine McHugh, Pamela J Wisniewski, Mary Beth Rosson, Heng Xu,
and John M Carroll. 2017. Most Teens Bounce Back: Using Diary Methods
to Examine How Quickly Teens Recover from Episodic Online Risk Exposure.
Proceedings of the ACM on Human-Computer Interaction 1 (2017), 1–19.
[30] Brenna McNally, Priya Kumar, Chelsea Hordatt, Matthew Louis Mauriello, Shalmali Naik, Leyla Norooz, Alazandra Shorter, Evan Golub, and Allison Druin. 2018.

Karmakar and Das

[31]

[32]
[33]
[34]
[35]

[36]

[37]

[38]
[39]

[40]
[41]
[42]

[43]
[44]
[45]

[46]
[47]
[48]
[49]
[50]
[51]

[52]
[53]
[54]

[55]

Co-Designing Mobile Online Safety Applications with Children. In Proceedings
of the 2018 CHI Conference on Human Factors in Computing Systems. 1–9.
Ali M Meligy, Hani M Ibrahim, and Mohamed F Torky. 2017. Identity Verification
Mechanism for Detecting Fake Profiles in Online Social Networks. International
Journal of Communication Networks and Information Security (IJCNIS) 9, 1 (2017),
31–39.
Tijana Milosevic. 2016. Social Media Companies’ Cyberbullying Policies. International Journal of Communication 10 (2016), 22.
Tijana Milosevic. 2018. Protecting Children Online? Cyberbullying Policies of Social
Media Companies. The MIT Press.
Mainack Mondal, Leandro Araújo Silva, and Fabrício Benevenuto. 2017. A Measurement Study of Hate Speech in Social Media. In Proceedings of the 28th ACM
Conference on Hypertext and Social Media. 85–94.
Annalaura Nocentini, Juan Calmaestra, Anja Schultze-Krumbholz, Herbert Scheithauer, Rosario Ortega, and Ersilia Menesini. 2010. Cyberbullying: Labels, behaviours and definition in three European countries. Journal of Psychologists and
Counsellors in Schools 20, 2 (2010), 129–142.
Abu Saleh Md Noman, Sanchari Das, and Sameer Patil. 2019. Techies Against
Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content. In Proceedings of the 2019 CHI Conference on Human Factors in
Computing Systems. 1–15.
Hani Nurrahmi and Dade Nurjanah. 2018. Indonesian Twitter Cyberbullying
Detection using Text Classification and User Credibility. In 2018 International
Conference on Information and Communications Technology (ICOIACT). IEEE,
543–548.
Justin W Patchin and Sameer Hinduja. 2010. Cyberbullying and self-esteem.
Journal of school health 80, 12 (2010), 614–621.
Jessica A Pater, Moon K Kim, Elizabeth D Mynatt, and Casey Fiesler. 2016. Characterizations of Online Harassment: Comparing Policies Across Social Media
Platforms. In Proceedings of the 19th International Conference on Supporting Group
Work. 369–374.
Arkaprava Roy and Sayar Karmakar. 2020. Bayesian semiparametric time varying
model for count data to study the spread of the COVID-19 cases. arXiv preprint
arXiv:2004.02281 (2020).
Weining Shen and Subhashis Ghosal. 2015. Adaptive Bayesian procedures using
random series priors. Scandinavian Journal of Statistics 42, 4 (2015), 1194–1213.
Vivek K Singh, Marie L Radford, Qianjia Huang, and Susan Furrer. 2017. "They
basically like destroyed the school one day" On Newer App Features and Cyberbullying in Schools. In Proceedings of the 2017 ACM Conference on Computer
Supported Cooperative Work and Social Computing. 1210–1216.
Veronika Šléglová and Alena Cerna. 2011. Cyberbullying in Adolescent Victims:
Perception and Coping. Cyberpsychology: Journal of Psychosocial Research on
Cyberspace 5, 2 (2011).
Robert Slonje and Peter K Smith. 2008. Cyberbullying: Another Main Type of
Bullying? Scandinavian Journal of Psychology 49, 2 (2008), 147–154.
Peter K Smith, Jess Mahdavi, Manuel Carvalho, and Neil Tippett. 2006. An
Investigation into Cyberbullying, its Forms, Awareness and Impact, and the
Relationship Between Age and Gender in Cyberbullying. Research Brief No.
RBX03-06. London: DfES (2006).
Patricia A Snell and Elizabeth Englander. 2010. Cyberbullying victimization and
behaviors among girls: Applying research findings in the field. Journal of Social
Sciences (2010).
Alexander Tsoutsanis. 2012. Tackling Twitter and Facebook Fakes: ID Theft in
Social Media. World Data Protection Report 12, 4 (2012), 1–3.
Erin A Vogel, Jason P Rose, Lindsay R Roberts, and Katheryn Eckles. 2014. Social
Comparison, Social Media, and Self-Esteem. Psychology of Popular Media Culture
3, 4 (2014), 206.
Elizabeth Whittaker and Robin M Kowalski. 2015. Cyberbullying via Social Media.
Journal of School Violence 14, 1 (2015), 11–29.
Brenda K Wiederhold. 2020. Social Media Use During Social Distancing.
Pamela Wisniewski, Heng Xu, Mary Beth Rosson, Daniel F Perkins, and John M
Carroll. 2016. Dear Diary: Teens Reflect on Their Weekly Online Risk Experiences.
In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems.
3919–3930.
Michele L Ybarra, Marie Diener-West, and Philip J Leaf. 2007. Examining the
Overlap in Internet Harassment and School Bullying: Implications for School
Intervention. Journal of Adolescent Health 41, 6 (2007), S42–S50.
Michele L Ybarra and Kimberly J Mitchell. 2004. Online aggressor/targets, aggressors, and targets: A comparison of associated youth characteristics. Journal
of child Psychology and Psychiatry 45, 7 (2004), 1308–1316.
Michele L Ybarra, Kimberly J Mitchell, Janis Wolak, and David Finkelhor. 2006.
Examining Characteristics and Associated Distress Related to Internet Harassment: Findings from the Second Youth Internet Safety Survey. Pediatrics 118, 4
(2006), e1169–e1177.
Scott L Zeger. 1988. A regression model for time series of counts. Biometrika 75,
4 (1988), 621–629.

