CxSE: Chest X-ray Slow Encoding CNN for
COVID-19 Diagnosis

arXiv:2106.12157v1 [eess.IV] 23 Jun 2021

Thangarajah Akilan

Abstract—The coronavirus continues to disrupt our everyday
lives as it spreads at an exponential rate. It needs to be
detected quickly in order to quarantine positive patients so as
to avoid further spread. This work proposes new convolutional
neural network (CNN) architecture called ’slow Encoding CNN.
The proposed model’s best performance wrt Sensitivity, Positive
Predictive Value (PPV) found to be SP=0.67, PP=0.98, SN=0.96,
and PN=0.52 on AI AGAINST COVID19 - Screening X-ray
images for COVID-19 Infections competition’s test data samples.
SP and PP stand for the Sensitivity and PPV of the COVID-19
positive class, while PN and SN stand for the Sensitivity and PPV
of the COVID-19 negative class.
Index Terms—COVID-19, x-ray classification, medical diagnosis

I. I NTRODUCTION
Coronavirus, also known as COVID-19 was discovered in
Wuhan, China, in December of 2019 [1]. COVID-19 has many
strains and can infect animals and humans. COVID-19 is hard
to detect because it has common symptoms such as cold and
flu. The symptoms also range in seriousness depending on
the person’s immune system. Symptoms can take up to 14
days to appear after exposure. Because of this, the public
disregards them as everyday common flu or cold. COVID19 is spread through respiratory droplets when you cough,
sneeze, and touch [2]. COVID-19 spread has become so severe
it is shutting down our economies. There are over 127 million
worldwide cases and over 2.7 million deaths as of March 29,
2021 and rising daily [3]. Chest X-rays and CT scans can be
conducted quickly and efficiently for detecting COVID-19 [4].
It will allow the radiologist, pathologist, and physicians to
properly learn the condition of the COVID-19 affected patients
for additional care and drive specific clinical solutions to safe
lives. The quicker the detection, the quicker the patient will
receive treatment and can be put in quarantine to avoid further
spread.
This work introduces a new CNN-based solution with slow
feature learning strategy to predict if the person is affected
with COVID-19 using the patient’s chest x-ray. The model is
solely trained and tested on COVIDx CXR-2 dataset provided
by the AI against COVID-19: Screening X-ray Images for
COVID-19 Infections competition, which is available at data
set. It comprises of over 16000 (480 × 480) chest X-ray scans
taken from 15000 patients from across the world (minimum
of 51 participating countries). We follow the exact training
and test sets splits containing positive and negative classes
Thangarajah Akilan is with the Department of Software Engineering, Lakehead University, Thunder Bay, ON, Canada. (e-mail:
{takilan}@lakeheadu.ca).

to indicate COVID or non-COVID cases, and evaluate the
proposed model on the hold out set that do not provide
the ground truths. For performance computation we submit
our model’s binary label predictions to the evaluating site
leaderboard and receive the results.
II. L ITERATURE R EVIEW
To tackle the surge of COVID-19, the AI community
has been actively developing efficient solutions for automatic
detection of COVID-19 patients from various sources as
an alternative/supportive to the conventional time consuming
diagnosis procedures. Among them the vision-based (e.g., the
medical images, like X-rays, CT scans) classification models
show promising results.
As data scarcity is a longstanding issue in the medical
machine learning, most of the researchers go by transfer
learning (TL) approach. In this direction, Gozes et al. [5] focus
using the well-known UNet [6] and ResNet50-2D [7] architectures for CT scan-based COVID-19 patient classification,
quantification and tracking for the patients. Similarly, Wang
et al. [8] use ResNet18 architecture, and Ali et al. [9] employ
ResNet50, InceptionV3 and Inception-ResNetV2 [10] models.
The main aim of these TL techniques is to extract features
from the small number of medical images leveraging an
exhaustively trained CNN on large-scale data, then a shallow
classifiers, like decision tree and SVM on the extracted feature
sets. Relatively, such approaches work well. That being said,
they are over dependant on the pretrained backbone models.
In response to that, there are few attempts where researchers
carefully [4], [11] architect new deep learning models specifically for the detection COVID-19. In this line, this work CNN
model is trained from scratch on Chest X-rays to classify
COVID-19 cases.
III. P ROPOSED S LOW E NCODING CNN
Earlier in [12]–[14], we introduced a novel encoder-decoder
(EnDec) foreground segmentation architecture that perform
feature learning twice at every stage of down-sampling processing. It has two subnets (cf. Fig. 1): encoder (spatial
subsampling) and decoder subnet (up-sample the lower dimensional bottle neck output feature map of the encoder
back to the original dimension of the image). In the encoder
subnet, a spatial input (layeri ) is transformed through a spatial
sub-sampling convolutional (Conv) operations ((layeri+1 )),
followed by an up-sampling operation using a transpose convolution ((layeri+2 )) that generates exactly matching spatial
feature maps to the previous layer’s input feature dimension.

site using Adamax optimizer with learning rate of 0.001. The
training history is show in Fig. 2.

Fig. 2: The training history of CxSE.
2) Testing Results: The proposed model is tested on the
given test set on the competition site. The probability scores
produces (cf. Fig. 3) by the model is converted into class labels
using a threshold of 0.5 and it is compared against the ground
truths. The model’s performance is shown by a confusion
matrix in Fig. 4. Similarly, the model’s probability scores on
the competition set (cf. Fig. 5) is also converted using the same
threshold and uploaded to the competition’s evaluation site to
get the model’s overall performance as tabulated in Table I.

Fig. 1: The proposed slow encoding Convent classifier for
COVID-19 detection using chest X-rays. All Conv2D layers
use ReLU activation.

Now, the up-sampled feature maps are aggregated depth wise
with the original input features (layeri ). Then, the aggregated
new feature maps are encoded using a spatial subsampling
Conv layer. In this way, an input feature map in sub-sampling
stage is learnt twice before completely moving to the nextlevel of lower spatial dimension. Following that, this work
upcycle the model by removing decoder subnet and refurbish
it by adding dense layers on the top with a Sigmoid classifier
targeting the COVID-19 patient classification using Chest Xray images. Figure 1 depicts the proposed slow encoding
Convnet model. In total the model has 9,692,865 trainable
parameters.
IV. DATA - SET
V. E XPERIMENTAL A NALYSIS
A. Training Time Analysis
1) Training History: The proposed CxSE model was
trained for 30 epochs on the given train set on the competition

Fig. 3: CxSE’s sigmoid probability scores on test set.

Metrics
SP
PP
SN
PN
Overall points

Score
0.67
0.98
0.96
0.52
12.80

TABLE I: CxSE’s COIVD-19 classification performance on
competition set (cf. leaderboard - Participant team: MVLC)

Fig. 4: Proposed CxSE’s performance on test set.

Fig. 5: CxSE’s sigmoid probability scores on competition set.

VI. C ONCLUSION
This work has introduced a new feature learning DCNN
aiming for COVID-19 diagnosis using chest x-rays. This fist
stage of our development shows promising outcome. The
future work is dedicated to improving the model’s learning
ability through class-agnostic semi-supervised training approach.
ACKNOWLEDGEMENTS
This work acknowledges IEEE SIGHT MTL, VIP lab, and
DarwinAI the organizers of “AI Against COVID19 - Screening
X-ray images for COVID-19 Infections”.
R EFERENCES
[1] WHO.
(2019)
Coronavirus
disease
(covid-19)
pandemic. [Online]. Available: https://www.who.int/emergencies/diseases/
novel-coronavirus-2019/
[2] Gov.Canada. (2020) Know the facts about covid-19. [Online].
Available: https://www.canada.ca/en/public-health/services/publications/
diseases-conditions/know-facts-about-coronavirus-disease-covid-19.
html
[3] ASEAN, “Risk assessment for international dissemination of covid-19
to the asean region,” ASEAN Biodiaspora Virtual Center (ABVC), Tech.
Rep., 2021.
[4] L. Wang, Z. Q. Lin, and A. Wong, “Covid-net: a tailored deep
convolutional neural network design for detection of covid-19 cases from
chest x-ray images,” Scientific Reports, vol. 10, no. 1, p. 19549, Nov
2020. [Online]. Available: https://doi.org/10.1038/s41598-020-76550-z

[5] O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning, H. Zhang,
W. Ji, A. Bernheim, and E. Siegel, “Rapid ai development cycle for the
coronavirus (covid-19) pandemic: Initial results for automated detection
& patient monitoring using deep learning ct image analysis,” arXiv
preprint arXiv:2003.05037, 2020.
[6] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in International Conference on
Medical image computing and computer-assisted intervention. Springer,
2015, pp. 234–241.
[7] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[8] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang,
Y. Li, X. Meng et al., “A deep learning algorithm using ct images to
screen for corona virus disease (covid-19),” European radiology, pp.
1–9, 2021.
[9] A. Narin, C. Kaya, and Z. Pamuk, “Automatic detection of coronavirus
disease (covid-19) using x-ray images and deep convolutional neural
networks,” Pattern Analysis and Applications, pp. 1–14, 2021.
[10] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. Alemi, “Inception-v4,
inception-resnet and the impact of residual connections on learning,” in
Proceedings of the AAAI Conference on Artificial Intelligence, vol. 31,
no. 1, 2017.
[11] H. Aboutalebi, M. Pavlova, M. J. Shafiee, A. Sabri, A. Alaref, and
A. Wong, “Covid-net cxr-s: Deep convolutional neural network for
severity assessment of covid-19 cases from chest x-ray images,” arXiv
preprint arXiv:2105.00256, 2021.
[12] T. Akilan and Q. M. J. Wu, “sendec: An improved image to image
cnn for foreground localization,” IEEE Transactions on Intelligent
Transportation Systems, vol. 21, no. 10, pp. 4435–4443, 2020.
[13] T. Akilan, Q. M. J. Wu, and W. Zhang, “Video foreground extraction
using multi-view receptive field and encoder–decoder dcnn for traffic and
surveillance applications,” IEEE Transactions on Vehicular Technology,
vol. 68, no. 10, pp. 9478–9493, 2019.
[14] T. Akilan and J. Wu, “Double encoding - slow decoding image to image
cnn for foreground identification with application towards intelligent
transportation,” in 2018 IEEE International Conference on Internet of
Things (iThings) and IEEE Green Computing and Communications
(GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData), 2018, pp. 395–403.

