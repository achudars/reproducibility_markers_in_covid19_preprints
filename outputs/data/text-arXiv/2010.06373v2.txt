Generalized Rescaled PoÃÅlya urn and its statistical applications
Giacomo Aletti

‚àó

and

Irene Crimaldi

‚Ä†

December 18, 2020

Abstract

arXiv:2010.06373v2 [math.ST] 17 Dec 2020

We introduce the Generalized Rescaled PoÃÅlya (GRP) urn, that provides three different generative models for a chi-squared test of goodness of fit for the long-term probabilities of clusterized
data, with independence between clusters and correlation, due to a reinforcement mechanism, inside each cluster. We apply the proposed test to a ‚Äúbig‚Äù dataset of Twitter posts about COVID-19
pandemic: in a few words, for a classical œá2 test the data result strongly significant for the rejection
of the null hypothesis (the daily sentiment rate remains constant), but, taking into account the
correlation among data, the introduced test leads to a different conclusion. Beside the statistical
application, we point out that the GRP urn is a simple variant of the standard Eggenberger-PoÃÅlya
urn, that, with suitable choices of the parameters, shows ‚Äúlocal‚Äù reinforcement, almost sure convergence of the empirical mean to a deterministic limit and different asymptotic behaviours of the
predictive mean.
Keywords: central limit theorem, chi-squared test, PoÃÅlya urn, preferential attachment, reinforcement learning, reinforced stochastic process, stochastic approximation, urn model.
MSC2010 Classification: 62L20, 60F05, 62F05, 62F03.

Contents
1 Introduction

2

2 The Generalized Rescaled PoÃÅlya (GRP) urn

4

3 Main theorem: goodness of fit result

6

4 Asymptotic results for the empirical means

7

5 Simulations
5.1 Simulations of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Simulations of Theorem 4.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8
8
9

6 Statistical applications
11
6.1 Estimation of the parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
7 COVID-19 epidemic Twitter analysis
‚àó
‚Ä†

19

ADAMSS Center, UniversitaÃÄ degli Studi di Milano, Milan, Italy, giacomo.aletti@unimi.it
IMT School for Advanced Studies, Lucca, Italy, irene.crimaldi@imtlucca.it

1

8 Proof of Theorem 4.2

21

Supplemental Materials

S1

S1 Proofs and intermediate results
S1
S1.1 Proof of Theorem 3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 1
S1.2 A preliminary central limit theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . S 2
S1.3 Proof of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 3
P
S2 Case n n < +‚àû
S3
S3 Computations regarding local reinforcement
S7
S3.1 Case Œ± = Œ≤ ‚àà (0, 1) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 8
S3.2 Case Œ± = Œ≤ = 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 8
S3.3 Case 0 < Œ± < Œ≤ < (1 + Œ±)/2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 9
S4 Technical results

S 10

S5 Some stochastic approximation results

S 12

S6 Stable convergence

S 14

1

Introduction

The standard Eggenberger-PoÃÅlya urn (see [23, 34]) has been widely studied and generalized (some
recent variants can be found in [3, 7, 8, 9, 11, 13, 16, 18, 19, 25, 26, 32, 33]). In its simplest form,
this model with k-colors works as follows. An urn contains N0 i balls of color i, for i = 1, . . . , k,
and, at each discrete time, a ball is extracted from the urn and then it is returned inside the urn
together with Œ± > 0 additional balls of the same color. Therefore, if we denote by Nn i the number
of balls of color i in the urn at time n, we have
Nn i = Nn‚àí1 i + Œ±Œæn i

for n ‚â• 1,

where Œæn i = 1 if the extracted ball at time n is of color i, and Œæn i = 0 otherwise. The parameter
Œ±
Pnregulates the reinforcement mechanism: the greater Œ±, the greater the dependence of Nn i on
h=1 Œæh i .
The ‚ÄúRescaled‚Äù PoÃÅlya (RP) urn model, presented in [3], is characterized by the introduction
of the parameter Œ≤, together with the initial parameters (b0 i )i=1,...,k and (B0 i )i=1,...,k , next to the
parameter Œ± of the original model, so that
Nn i = b0 i + B n i

with

Bn i = Œ≤Bn‚àí1 i + Œ±Œæn i

n ‚â• 1.

Therefore, the urn initially contains b0 i +B0 i balls of color i and the parameter Œ≤ ‚â• 0, together with
Œ± > 0, regulates the reinforcement mechanism. More precisely, the term Œ≤Bn‚àí1 i links Nn i to the
‚Äúconfiguration‚Äù at time n‚àí1 through the ‚Äúscaling‚Äù parameter Œ≤, and the term Œ±Œæn i links Nn i to the
outcome of the extraction at time n through the parameter Œ±. Note that the case Œ≤ = 1 corresponds
to the standard Eggenberger-PoÃÅlya urn with an initial number N0 i = b0 i + B0 i of balls of color
i. When Œ≤ ‚àà [0, 1), this variant of the Eggenberger-PoÃÅlya urn shows the following features: (i) a
‚Äúlocal‚Äù reinforcement, i.e. a reinforcement mechanism mainly based on the last observations, (ii)
PN
a long-term almost sure convergence of the empirical mean n=1 Œæn i /N to the deterministic limit

2

Pn
p0 i = b0 i / i=1 b0 i , and (iii) a chi-squared goodness of fit result for the long-term probabilities
{p0 1 , . . . , p0 k }. In particular, regarding the point (iii), we have that the chi-squared statistics
œá2 = N

k
X
(b
p i ‚àí p 0 i )2
i=1

p0 i

=

k
X
(Oi ‚àí N p0 i )2
i=1

N p0 i

,

(1)

where N is the size of the sample, pbi = Oi /N , with Oi the number of observations equal to i in
1
the sample, is asymptotically distributed as œá2 (k ‚àí 1)Œª = Œì( k‚àí1
2 , 2Œª ), with Œª > 1. This constant
Œª, due to the presence of correlation among units, mitigate the effect of the sample size N in
(1), that multiplies the chi-squared distance between the observed frequencies and the expected
probabilities. Indeed, the observed value of the chi-squared distance has to be compared with the
‚Äúcritical‚Äù value œá21‚àíŒ∏ (k ‚àí 1)Œª/N , where œá21‚àíŒ∏ (k ‚àí 1) denotes the quantile of order 1 ‚àí Œ∏ of the
chi-squared distribution œá2 (k ‚àí 1). This aspect is important for the statistical applications in the
context of a ‚Äúbig sample‚Äù, when a small value of the chi-squared distance might be significant, and
hence a correction related to the correlation between observations is desirable (see, for instance,
[10, 12, 15, 24, 27, 30, 36, 40, 41, 43]).
In this work, we replace the two parameters Œ± and Œ≤ by two sequences (Œ±n )n and (Œ≤n )n , in
order to give more flexibility to the model and capture different asymptotic behaviours. We call
this new variant of the Eggenberger-PoÃÅlya urn Generalized Rescaled PoÃÅlya (GRP) urn. Besides
the Eggenberger-PoÃÅlya urn and the RP urn, the GRP urn model also includes as special cases the
models illustrated in [28] and [38].
Referring to the above issues (ii)-(iii), we show that, with a suitable choice of the model parameters, we still have the almost sure convergence of pbi = Oi /N to the probability p0 i , together with a
chi-squared goodness of fit result, where the effect of the sample size N is weakened by the presence
of correlation. More precisely, we present a case where, as before, the chi-squared statistics (1) is
asymptotically distributed as œá2 (k ‚àí 1)Œª, with Œª > 1, and another case where it is asymptotically
distributed as œá2 (k ‚àí 1)N 1‚àí2e Œª, where Œª > 0 may be smaller than 1, but e is always strictly smaller
than 1/2. In particular, in the second case, the critical value for the chi-squared distance becomes
œá21‚àíŒ∏ (k ‚àí 1)Œª/N 2e , where, although the constant Œª may be smaller than 1, the effect of the sample
size N is mitigated by the exponent 2e < 1. Summing up, the GRP urn provides three models
(the RP urn introduced and studied in [3] and the other two analyzed in the present work), each
of them presenting different limit features and all of them suitable as theoretical frameworks for
a chi-squared test of goodness of fit for the long-term probabilities of correlated data, generated
according to a reinforcement mechanism. It is worthwhile to underline that the results proven in
this work do not cover (and are not covered by) those obtained for the RP urn in [3]. Moreover, as
explained in the following Section 2, the techniques required here and in [3] are completely different.
Regarding issue (i), we show that the provided examples exhibit a broader sense local reinforcement, in the sense that the ‚Äúweight‚Äù of the observations is eventually increasing with time.
Finally, we underline that the almost sure convergence of the predictive mean œàn i = E[Œæn+1 i =
1| ‚Äúpast‚Äù] is typically proven for urn models, in order to apply ‚Äústochastic approximation central
limit theorems‚Äù, where it is assumed as an hypothesis. In the GRP this kind of convergence is
not always guaranteed (see, for instance, the RP urn model, where we have a random persistent
fluctuation of the predictive mean) or it is not easy to check if it holds or not (see Section 8 for
more details). Therefore, in these cases, different proof arguments are necessary.
The sequel of the paper is so structured. In Section 2 we set up our notation, we define the
Generalized Rescaled PoÃÅlya (GRP) urn and we discuss its relationships with previous models. In
Section 3 we provide the main result of this work, that is the almost sure convergence of the
empirical means to the deterministic limits p0 i and the goodness of fit result for the long-term
probabilities p0 i , together with comments and examples. In Section 4 we state two convergence
results for the empirical means, which are the basis for the proof of the main theorem, and Section
5 collects some related simulations. In Section 6 we describe a possible statistical application of
the GRP urn and the related results in the context of a big sample, inspired by [3, 12, 35]. More

3

precisely, it is a chi-squared test of goodness of fit for the long-term probabilities of clusterized data,
with independence between clusters and correlation, due to a reinforcement mechanism, inside each
cluster. We apply the proposed test to a dataset of Twitter posts about COVID-19 pandemic [2].
Given the null hypothesis that the daily sentiment rate of the posts is the same for all the considered days (suitably spaced days in the period February 20th - April 20th 2020), performing a
classical œá2 test, the data result strongly significant for the rejection of the null hypothesis, while,
taking into account the correlation among posts sent in the same day, the proposed test leads to
a different conclusion. All the shown theoretical results are analytically proven. The proofs are
left to Section S1 in the Supplementary Material [1], except for the proof of Theorem 4.2, which
is methodologically new and emphasizes new techniques of martingale limit theory and so it is
illustrated in Section 8. Finally, in the Supplementary Material we also provide some complements,
some technical lemmas and some recalls about stochastic approximation theory and about stable
convergence. When necessary, the references to the Supplementary Material are preceded by an
‚ÄúS‚Äù, so that (S1.2) will refer to the equation (S1.2) in [1].

2

The Generalized Rescaled PoÃÅlya (GRP) urn

In all the sequel, we suppose given two sequences of parameters (Œ±n )n‚â•1 , with Œ±n > 0 and
Pk
(Œ≤n )n‚â•0 with Œ≤n ‚â• 0. Given a vector x = (x1 , . . . , xk )> ‚àà Rk , we set |x| =
i=1 |xi | and
P
k
kxk2 = x> x = i=1 |xi |2 . Moreover we denote by 1 and 0 the vectors with all the components
equal to 1 and equal to 0, respectively.
The urn initially contains b0 i + B0 i > 0 distinct balls of color i, with i = 1, . . . , k. We set
b0 = (b0 1 , . . . , b0 k )> and B0 = (B0 1 , . . . , B0 k )> . We assume |b0 | > 0 and we set p0 = |bb00 | . At
each discrete time (n + 1) ‚â• 1, a ball is drawn at random from the urn, obtaining the random
vector Œæn+1 = (Œæn+1 1 , . . . , Œæn+1 k )> defined as
(
1 when the extracted ball at time n + 1 is of color i
Œæn+1 i =
0 otherwise,
and the number of balls in the urn is so updated:
Nn+1 = b0 + Bn+1

with

Bn+1 = Œ≤n Bn + Œ±n+1 Œæn+1 ,

(2)

which gives (since |Œæn+1 | = 1)
|Bn+1 | = Œ≤n |Bn | + Œ±n+1 .
Therefore, setting

rn‚àó

= |Nn | = |b0 | + |Bn |, we get
‚àó
rn+1
= rn‚àó + (Œ≤n ‚àí 1)|Bn | + Œ±n+1 ,

(3)

‚àó
rn+1
‚àí rn‚àó = |b0 |(1 ‚àí Œ≤n ) ‚àí rn‚àó (1 ‚àí Œ≤n ) + Œ±n+1 .

(4)

that is
Moreover, setting F0 equal to the trivial œÉ-field and Fn = œÉ(Œæ1 , . . . , Œæn ) for n ‚â• 1, the conditional
probabilities œàn = (œàn 1 , . . . , œàn k )> of the extraction process, also called predictive means, are
œàn = E[Œæn+1 |Fn ] =

b0 + Bn
Nn
=
|Nn |
rn‚àó

n ‚â• 0.

(5)

It is obvious that we have |œàn | = 1. Moreover, when Œ≤n > 0 for all n, the probability œàn i results
increasing with the number of times we observed the value i, that is the random variables Œæn i are
generated according to a reinforcement mechanism: the probability that the extraction of color i

4

occurs has an increasing dependence on the number of extractions of color i occurred in the past
(see, e.g. [39]). More precisely, we have
Qn‚àí1
Pn  Qn‚àí1 
b0 + B0 j=0 Œ≤j + h=1 Œ±h j=h Œ≤j Œæh
œàn =
(6)
Pn  Qn‚àí1  .
Qn‚àí1
|b0 | + |B0 | j=0 Œ≤j + h=1 Œ±h j=h Œ≤j
Qn‚àí1
The dependence of œàn on Œæh depends on the factor f (h, n) = Œ±h j=h Œ≤j , with 1 ‚â§ h ‚â§ n, n ‚â• 0.
In the case of the standard Eggenberger-PoÃÅlya urn, that corresponds to Œ±n = Œ± > 0 and Œ≤n = 1
for all n, each observation Œæh has the same ‚Äúweight‚Äù f (h, n) = Œ±. Instead, if the factor f (h, n)
increases with h, then the main contribution is given by the most recent extractions. We refer to
this phenomenon as ‚Äúlocal‚Äù reinforcement. For instance, this is the case when (Œ±n ) is increasing
and Œ≤n = 1 for all n. Another case is when Œ±n = Œ± > 0 and Œ≤n < 1 for all n. The case Œ≤n = 0
for all n is an extreme case, for which œàn depends only on the last extraction Œæn (recall that
Qn‚àí1
conventionally j=n = 1). For the next examples, we will show that they exhibit a broader sense
local reinforcement, in the sense that the ‚Äúweight‚Äù of the observations is eventually increasing with
time.
By means of (5), together with (2) and (3), we have
œàn+1 ‚àí œàn = ‚àí

 Œ±n+1

(1 ‚àí Œ≤n )
|b0 | œàn ‚àí p0 + ‚àó
Œæn+1 ‚àí œàn .
‚àó
rn+1
rn+1

(7)

The particular case when Œ≤n = Œ≤ = 0 for all n corresponds to a version of the so-called ‚Äúmemory-1
senile reinforced random walk‚Äù on a star-shaped graph introduced in [28]. The case Œ±n = Œ± > 0 and
Œ≤n = Œ≤ = 1 for all n corresponds to the standard Eggenberger-PoÃÅlya urn with an initial number
N0 i = b0 i + B0 i of balls of color i. When (Œ±n ) is a not-constant sequence, while Œ≤n = Œ≤ = 1
for all n, the GRP urn coincides with the variant of the Eggenberger-PoÃÅlya urn introduced in [38]
(see also [39, Sec. 3.2]). Instead, when Œ≤ 6= 1, the GRP urn does not fall in any variants of the
Eggenberger-PoÃÅlya urn discussed in [39, Sec. 3.2]. The case when Œ±n = Œ± > 0 and Œ≤n = Œ≤ ‚â• 0 for
all n corresponds to the Rescaled PoÃÅlya (RP) urn introduced and studied in [3]. When (Œ≤n ) is not
identically equal to 1, since the first term in the right hand of the above relation, the GRP urn does
not belong to the class of Reinforced Stochastic Processes (RSPs) studied in [4, 6, 5, 20, 21, 22].
Indeed, the RSPs are characterized by a ‚Äústrict‚Äù reinforcement mechanism such that Œæn i = 1 implies
œàn i > œàn‚àí1 i and so, as a consequence, œàn i has an increasing dependence on the number of times
we have Œæh i = 1 for h = 1, . . . , n. When (Œ≤n ) is not identically equal to 1, the GRP urn does
not satisfy the ‚Äústrict‚Äù reinforcement mechanism, because the first term is positive or negative
according to the sign of (1 ‚àí Œ≤n ) and of (œàn ‚àí p0 ). Furthermore, we observe that equation (7)
recalls the dynamics of a RSP with a ‚Äúforcing input‚Äù (see [4, 20, 42]), but the main difference relies
on the fact that the GRP urn model also allows for the two cases:
P 1‚àíŒ≤n
P  1‚àíŒ≤n 2
‚Ä¢
=
+‚àû
and
= +‚àû,
‚àó
‚àó
n rn+1
n
rn+1


2
P
P 1‚àíŒ≤n
n
< +‚àû and n 1‚àíŒ≤
< +‚àû.
‚Ä¢
n r‚àó
r‚àó
n+1

n+1

n)
Setting Œ∏n = œàn ‚àí p0 and ‚àÜMn+1 = Œæn+1 ‚àí œàn = Œæn+1 ‚àí p0 ‚àí Œ∏n and letting n = |b0 | (1‚àíŒ≤
r‚àó
n+1

‚àó
and Œ¥n = Œ±n+1 /rn+1
, from (7) we obtain

œàn+1 ‚àí œàn = ‚àín (œàn ‚àí p0 ) + Œ¥n ‚àÜMn+1

(8)

Œ∏n+1 ‚àí Œ∏n = ‚àín Œ∏n + Œ¥n ‚àÜMn+1 .

(9)

and so
Therefore, the asymptotic behaviour of (Œ∏n ) depends on the two sequences (n )n and (Œ¥n )n .
PN
Finally, we observe that, setting Œæ N = n=1 Œæn /N and ¬µn = Œæ n ‚àí p0 , we have the equality
1
1
¬µn+1 ‚àí ¬µn = ‚àí (¬µn ‚àí Œ∏n ) + ‚àÜMn+1 ,
n
n

5

(10)

that links the asymptotic behaviour of (¬µn ) and the one of (Œ∏n ).
Different kinds of sequences (n )n and (Œ¥n )n provide different kinds of asymptotic behaviour of
Œ∏n , i.e. of the empirical mean Œæ N . In Section 3, we provide two cases in which we have a long-term
PN
almost sure convergence of the empirical mean Oi /N = n=1 Œæn i /N toward the constant p0i =
b0 i /|b0 |, together with a chi-squared goodness of fit result. In particular, the quantities p0 1 , . . . , p0 k
can be seen as a long-run probability distribution on the possible values (colors) {1, . . . , k}.
It is worthwhile to point out that the two cases studied in the present work do not include
(and are not included in) the case Œ±n = Œ± > 0 and Œ≤n = Œ≤ ‚àà [0, 1), studied in [3]. Moreover, the
techniques employed here and in [3] are completely different: when Œ≤n = Œ≤ ‚àà [0, 1) as in [3], the
jumps ‚àÜœàn do not vanish and the process œà = (œàn )n converges to a stationary Markov chain and
so the appropriate Markov ergodic theory is employed; in this work, we have |‚àÜœàn | = o(1), so that
the martingale limit theory is here exploited to achieve the asymptotic results. Obviously, the two
techniques are not exchangeable or adaptable from one contest to the other one.

3

Main theorem: goodness of fit result

Given a sample (Œæ1 , . . . , ŒæN ) generated by a GRP urn, the statistics
N
X

Oi = #{n = 1, . . . , N : Œæn i = 1} =

Œæn i ,

i = 1, . . . , k,

n=1

counts the number of times we observed the value i. The theorem below states,
PN under suitable
assumptions, the almost sure convergence of the empirical mean pbi = Oi /N = n=1 Œæn i /N toward
the probability p0 i , together with a chi-squared goodness of fit test for the long-term probabilities
p0 1 , . . . , p0 k . More precisely, we prove the following result:
Theorem 3.1. Assume p0 i > 0 for all i = 1, . . . , k and suppose to be in one of the following cases:
a) n = (n + 1)‚àí and Œ¥n = cn , with  ‚àà (0, 1] and c > 0, or
b) n = (n + 1)‚àí , Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with  ‚àà (0, 1), Œ¥ ‚àà (/2, ) and c > 0.
Define the constants e and Œª as
(
e=
and

1/2
1/2 ‚àí ( ‚àí Œ¥) < 1/2

Ô£±
2
Ô£¥
Ô£≤(c + 1)
Œª = (c + 1)2 + c2 = [2c(c + 1) + 1]
Ô£¥
Ô£≥ c2
1+2(‚àíŒ¥)

in case a)
in case b)
in case a) with  ‚àà (0, 1) ,
in case a) with  = 1 ,
in case b) .

(11)

a.s.

Then pbi = Oi /N ‚àí‚Üí p0 i and
1
N 1‚àí2e

k
X
(Oi ‚àí N p0 i )2
i=1
2

N p0 i

where W0 has distribution œá (k‚àí1) = Œì

= N 2e

k
X
(b
pi ‚àí p0 i )2
i=1

k‚àí1 1
2 , 2)

p0 i

d

‚àí‚Üí W‚àó = ŒªW0

N ‚Üí‚àû

and, consequently, W‚àó has distribution Œì

k‚àí1 1
2 , 2Œª



.

We note that Œª is a constant greater than 1 in case a); while, in case b), it is a strictly positive
quantity. Moreover, in case b), we have 0 < ( ‚àí Œ¥) < /2 < 1/2 and so (1 ‚àí 2e) = 2( ‚àí Œ¥) ‚àà (0, 1).
As a consequence, we have N 1‚àí2e Œª > 1 for N large enough.
In the next two examples we show that it is possible to construct suitable sequences (Œ±n )n and
(Œ≤n )n such that the corresponding sequences (n )n and (Œ¥n ) converge to zero with the same rate or
with different rates and satisfy the assumptions a) or b) of the above theorem, respectively.

6

Example 3.2. (Case n = (n + 1)‚àí and Œ¥n = cn , with  > 0 and c > 0 )
n)
Take Œ±n+1 = c|b0 |(1 ‚àí Œ≤n ), with Œ≤n ‚àà [0, 1) and c > 0, that implies Œ¥n = Œ±r‚àón+1 = c |b0 |(1‚àíŒ≤
= cn .
r‚àó
n+1

Set rn‚àó = (1 + c)|b0 |(1 ‚àí tn ) so that from (4) we obtain tn+1 = Œ≤n tn . Hence, we have
tn+1 = t0

n
Y
k=0

and so

Œ≤k =

n+1

n
c|b0 | ‚àí |B0 | Y
Œ≤k
(1 + c)|b0 |
k=0

n
Y
‚àó
rn+1
= (1 + c)|b0 | + |B0 | ‚àí c|b0 |
Œ≤k .
k=0

Q‚àû

‚àí‚Üí r = (1+c)|b0 |+(|B0 |‚àíc|b0 |)Œ≤ ‚àó > 0. If we
Therefore, setting Œ≤ = k=0 Œ≤k ‚àà [0, 1), we get
‚àó
‚àó
choose |B0 | = c|b0 |, then rn = r = (1 + c)|b0 | for each n and so, setting Œ≤n = 1 ‚àí (1 + c)(1 + n)‚àí
with  > 0, we obtain n = (1 + n)‚àí and Œ¥n = cn . Taking  ‚àà (0, 1], we have that n and Œ¥n satisfy
assumption a) of Theorem 3.1. Moreover, we have Œ±n = c|b0 |(1+c)n‚àí and 1‚àíŒ≤n = (1+c)(1+n)‚àí
Qn‚àí1
and so, for the behaviour of the factor f (h, n) = Œ±h j=h Œ≤j in (6), we refer to Section S3.
‚àó

rn‚àó

‚àó

Example 3.3. (Case n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with 0 < Œ¥ <  < 1 and c > 0)
Take 0 < Œ¥ <  < 1 and set Œ≥ =  ‚àí Œ¥ > 0, rn‚àó = nŒ≥ and (1 ‚àí Œ≤n ) = |b0 |‚àí1 (1 + n)‚àíŒ¥ . We immediately
have
(1 ‚àí Œ≤n )
= (1 + n)‚àíŒ¥‚àíŒ≥ = (n + 1)‚àí
n = |b0 | ‚àó
rn+1
and (4) yields Œ±n+1 = (n + 1)Œ≥ ‚àí nŒ≥ [1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ] ‚àí (1 + n)‚àíŒ¥ , so that


Œ±n+1
1 Œ≥ 
Œ±n+1
Œ¥n = ‚àó
=
1
‚àí
1
‚àí
=
1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ‚àí (1 + n)‚àíŒ¥‚àíŒ≥
rn+1
(n + 1)Œ≥
n+1



= 1 ‚àí 1 ‚àí Œ≥(n + 1)‚àí1 + O(n‚àí2 ) 1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ‚àí (1 + n)‚àí


= |b0 |‚àí1 (1 + n)‚àíŒ¥ 1 + Œ≥|b0 |(n + 1)‚àí1+Œ¥ ‚àí |b0 |(1 + n)‚àí+Œ¥ ‚àí Œ≥(n + 1)‚àí1 + O(n‚àí2+Œ¥ ) .
Setting c = |b0 |‚àí1 > 0, we obtain n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ . Taking Œ¥ ‚àà (/2, ), we
have that n and Œ¥n satisfy assumption b) of Theorem 3.1. Moreover, we have Œ±n = cn‚àí(2Œ¥‚àí) (1 +
Œ≥c‚àí1 n‚àí1+Œ¥ ‚àí c‚àí1 n‚àí+Œ¥ ‚àí Œ≥n‚àí1 + O(n‚àí2+Œ¥ )) and (1 ‚àí Œ≤n ) = c(1 + n)‚àíŒ¥ , with 0 < 2Œ¥ ‚àí  < Œ¥ <
Qn‚àí1
(1 + 2Œ¥ ‚àí )/2, and so, for the behaviour of the factor f (h, n) = Œ±h j=h Œ≤j in (6), we refer to
Section S3.

4

Asymptotic results for the empirical means

Theorem 3.1 is a consequence of suitable convergence results for the empirical means Œæ N in the
s
considered cases a) and b). In the sequel, we will use the symbol ‚àí‚Üí in order to denote the stable
convergence (for a brief review on stable convergence, see Section S6).
The case when Œ¥n = cn in (8) is essentially
Approximation (SA)
P 2
P 2 covered by the Stochastic
theory. The most known case is when

<
+‚àû.
The
case

=
+‚àû is less usual in
n n
n n
literature, but it is well characterized in [31]. More precisely, leveraging the results collected in
Section S5, we prove in Section S1.3 the following result:
Theorem 4.1. Take n = (n + 1)‚àí and Œ¥n = cn , with  ‚àà (0, 1] and c > 0, and set Œì =
a.s.
diag(p0 ) ‚àí p0 p0 > . Then Œæ N ‚àí‚Üí p0 and
‚àö
 s
N Œæ N ‚àí p0 ‚àí‚Üí N (0, ŒªŒì) ,
with Œª = (c + 1)2 when 0 <  < 1 and Œª = (c + 1)2 + c2 = 2c(c + 1) + 1 when  = 1.

7

The case when (n )n and (Œ¥n )n in (8) go to zero with different rates is typically neglected in
SA literature. To our best knowledge, it is taken into consideration only in [37], where the weak
convergence rate of the sequence (œàn ) toward a certain point œà ‚àó is established under suitable
assumptions, given the event {œàn ‚Üí œà ‚àó }. No result is given for the empirical mean Œæ N , which
instead is the focus of the present paper, as shown in the following theorem (proven in Section 8):
Theorem 4.2. Take n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with  ‚àà (0, 1), Œ¥ ‚àà (/2, ) and c > 0.
a.s.
Then Œæ N ‚àí‚Üí p0 and


 s
c2
1/2‚àí(‚àíŒ¥)
N
Œæ N ‚àí p0 ‚àí‚Üí N 0,
Œì ,
1 + 2( ‚àí Œ¥)
with Œì = diag(p0 ) ‚àí p0 p0 > .

5

Simulations

In this section, we provide some simulations related to Theorem 4.1 and Theorem 4.2 stated above.
More precisely, we have simulated the model in the two different cases following Example 3.2 and
Example 3.3. In both cases, we have k = 3, b0 = p0 = (0.167, 0.333, 0.5) (in order to show possible
asymmetries in the convergence) and N in {100, 316, 1 000, 3 162, 10 000, 31 623, 100 000} (unformly
spaced in log-scale). Each sinulation is made with 1 000 independent replicas.
Firstly, we show for both the theorems the convergence of the empirical mean Œæ N to p0 , by
PN
plotting the mean value of the empirical mean Œæ N = n=1 Œæn i /N , for i = 1, 2, 3 and the different
values of N , together with its standard deviation.
Then, we consider the CLT. To this regard, we point out that, as shown in the analytical proofs,
we have

N 1/2‚àí(‚àíŒ¥) Œæ N ‚àí p0 = DOM + REM ,
where DOM is a ‚Äúdominant factor‚Äù converging to the Gaussian distribution with the appropriate
variance, while REM is a remainder part which is eventually negligible.

Finally, we show that in any set of data the CLT is experimentally found for N 1/2‚àí(‚àíŒ¥) Œæ N ‚àí p0
with a Gaussian distribution of the form N (0, ŒªÃÇŒì), where ŒªÃÇ = ŒªÃÇ(, Œ¥) is the standard deviation computed with the simulated data.

5.1

Simulations of Theorem 4.1

The results of Theorem 4.1 are here shown simulating the model by means of Example 3.2 with
n = Œ¥n = (1 + n) , where  ‚àà {0.30, 0.40, 0.50, 0.85, 1.00} and c = 1.
Fig. 1 shows the convergence of the empirical means to p0 .
For what concerns the CLT, we observe that
‚àö
‚àö

 ‚àö
N Œæ N ‚àí p0 = (c + 1) N Œæ N ‚àí œà N ‚àí1 ‚àí N DN ,
(12)
‚àö
where the first term tends to N (0, (c + 1)2 Œì) and the remainder term N DN tends to 0 only when
 < 1. Indeed, when  = 1, we have a different value for the constant Œª in Theorem 4.1. These
facts are summarized in Fig. 2 and Fig 3.
‚àö

Finally, Fig. 4 shows the convergence in distribution of N Œæ N ‚àí p0 to a Gaussian distribution of the form N (0, ŒªÃÇŒì), where ŒªÃÇ = ŒªÃÇ(, Œ¥) is the standard deviation computed with the simulated
data.

8

Figure 1: Convergence of the empirical mean to p0 : 1 000 independent simulations of the model
by means of Example 3.2 P
with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values of  = Œ¥ and
plot of the mean value of N
n=1 Œæn i /N , together with its standard deviation, for different values of N .

5.2

Simulations of Theorem 4.2

We have simulated the model following Example 3.3 with k = 3, b0 = p0 = (0.167, 0.333, 0.5)
(so that c = 1) and different values for the parameters  and Œ¥. The total number of performed
(independent) replications is again 1 000.
PN
In Fig. 5 we provide the mean value of the empirical mean Œæ N = n=1 Œæn i /N , for i = 1, 2, 3
and different values of N , together with its standard deviation. This plot shows the convergence of
the empirical means to p0 .
For what concerns the CLT, the proof given in Section 8 points out that
N


2
X
Œ¥n‚àí1
d
N 1/2‚àí(‚àíŒ¥) Œ∏ N ‚àí1 ‚âà N 0, N ‚àí1‚àí2(‚àíŒ¥)
Œì
‚Üí N (0, ŒªŒì) ,
2
n=1 n‚àí1

where Œª = 1/[1 + 2( ‚àí Œ¥)] (see the proof after (21)). Fig. 2 shows this convergence, while the
reminder term

N 1/2‚àí(‚àíŒ¥) Œæ N ‚àí p0 ‚àí N 1/2‚àí(‚àíŒ¥) Œ∏ N ‚àí1 ,
(13)
is shown to converge towards 0 in Fig. 3, with different speed.

Finally, Fig. 8 shows the convergence in distribution of N 1/2‚àí(‚àíŒ¥) Œæ N ‚àí p0 to a Gaussian
distribution of the form N (0, ŒªÃÇŒì), where ŒªÃÇ = ŒªÃÇ(, Œ¥) is the standard deviation computed with
simulated data. For some values of  and Œ¥, the constant ŒªÃÇ is not equal to the theoretical value
1/[1 + 2( ‚àí Œ¥)], because the term (13) goes to 0 slowly. However, it is worth to note that this
issue does not matter for the statistical application of the result, since, as described in Section 6,
we estimate the pair (Œ∑ = 2( ‚àí Œ¥), Œª) from the data.

9

‚àö

Figure 2: Convergence in distribution of (c + 1) N Œæ N i ‚àí œà N ‚àí1 i : 1 000 independent simulations of the model by means of Example 3.2 with ‚àö
k = 3, b0 = p0 =(0.167, 0.333, 0.5) and different
values of  = Œ¥ and plot of the distribution of (c+1) N Œæ N i ‚àí œà N ‚àí1 i for i = 1, 2, 3. In red: Standard
Gaussian distribution.
10

‚àö
Figure 3: Convergence to zero of the remaining term N DN in (12): 1 000 independent
simulations of the model by means of Example 3.3 with k = 3, b0 = p0 =‚àö(0.167, 0.333, 0.5) and
different values of  = Œ¥ and plot of the distribution of the three components N DN i .

6

Statistical applications

In a big sample the units typically can not be assumed independent and identically distributed,
but they exhibit a structure in clusters, with independence between clusters and with correlation
inside each cluster [12, 17, 29, 35, 44, 45]. The model and the related results presented in [3] and
in the present paper may be useful in the situation when inside each cluster the probability that
a certain unit chooses the value i is affected by the number of units in the same cluster that have
already chosen the value i, hence according to a reinforcement rule. Formally, given a ‚Äúbig‚Äù sample
{Œæ n : n = 1, . . . , N }, we suppose that the N units are ordered so that we have the following L
clusters of units:
( `‚àí1
)
`
X
X
C` =
Nl + 1, . . . ,
Nl ,
` = 1, . . . , L.
l=1

l=1

Therefore, the cardinality of each cluster C` is N` . We assume that the units in different clusters
are independent, that is
[Œæ1 , . . . , ŒæN1 ], . . . , [ŒæP`‚àí1 Nl +1 , . . . , ŒæP`l=1 Nl ], . . . , [ŒæPL‚àí1 Nl +1 , . . . , ŒæN ]
l=1

l=1

are L independent multidimensional random variables. Moreover, we assume that the observations
inside each cluster can be modeled as a GRP satisfying case a) or case b) of Theorem 3.1. Given
certain (strictly positive) intrinsic probabilities p‚àó0 1 (`), . . . , p‚àó0 k (`) for each cluster C` , we firstly
want to estimate the model parameters and then perform a test with null hypothesis
H0 :

p0 i (`) = p‚àó0 i (`) ‚àÄi = 1, . . . , k

based on the the statistics
Q` =

1
2(‚àíŒ¥)

N`

k
X
Oi (`) ‚àí N` p‚àó0 i (`)
N` p‚àó0 i (`)
i=1

2
,

11

with Oi (`) = #{n ‚àà C` : Œæn i = 1},

(14)

‚àö

Figure 4: Convergence in distribution of N Œæ N i ‚àí p0 i : 1 000 independent simulations of the
model by means of Example 3.3 with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values of  = Œ¥
‚àö
and plot of the distribution of N ‚àö ŒæN i ‚àíp0 i for i = 1, 2, 3. In red: Standard Gaussian distribution.
ŒªÃÇp0 i (1‚àíp0 i )

12

Figure 5: Convergence of the empirical mean to p0 : 1 000 independent simulations of the model
by means of Example 3.3 P
with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values of  and Œ¥ and
plot of the mean value of N
n=1 Œæn i /N , together with its standard deviation, for different values of N .

1
and its corresponding asymptotic distribution Œì k‚àí1
2 , 2Œª , where Œª is given in (11). Note that we
can perform the above test for a certain cluster `, or we can consider all the clusters together using
PL
1
the aggregate statistics `=1 Q` and its corresponding distribution Œì( L(k‚àí1)
, 2Œª
).
2
‚àó
Regarding the probabilities p0 i (`), some possibilities are:
‚Ä¢ we can take p‚àó0 i (`) = 1/k for all i = 1, . . . , k if we want to test possible differences in the
probabilities for the k different values;
(1)
‚Ä¢ we can suppose to have two different periods of times, and so two samples, say {Œæn
: n=
P
(1)
(2)
‚àó
1, . . . , N } and {Œæn : n = 1, . . . , N }, take p0 i (`) = n‚ààC` Œæn i /N` for all i = 1, . . . , k, and
perform the test on the second sample in order to check possible changes in the intrinsic
long-run probabilities;
P
‚Ä¢ we can take one of the clusters as benchmark, say `‚àó , set p‚àó0 i (`) = n‚ààC`‚àó Œæn i /N`‚àó for all
i = 1, . . . , k and ` 6= `‚àó , and perform the test for the other L ‚àí 1 clusters in order to check
differences with the benchmark cluster `‚àó .

Finally, if we want to test possible differences in the clusters, then we can take p‚àó0 i (`) = p‚àó0 i =
PN
PL
n=1 Œæn i /N for all ` = 1, . . . , L and perform the test using the aggregate statistics
`=1 Q` with
1
,
).
asymptotic distribution Œì( (L‚àí1)(k‚àí1)
2
2Œª

6.1

Estimation of the parameters

The model parameters are , Œ¥ and c. However, as we have seen, the fundamental quantities are
Œ∑ = 2( ‚àí Œ¥) and Œª given in (11). Moreover, recall that in case a), we have Œ∑ = 0 and Œª > 1 and, in
case b), we have Œ∑ ‚àà (0, 1) and Œª > 0. Therefore, according the considered model, the pair (Œ∑, Œª)

13

Figure 6: Convergence in distribution of N 1/2‚àí(‚àíŒ¥) Œ∏N ‚àí1 i : 1 000 independent simulations of the
model by means of Example 3.3 with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values of 
Œ∏
and Œ¥ and plot of the distribution of N 1/2‚àí(‚àíŒ¥) ‚àö N ‚àí1 i
for i = 1, 2, 3. In red: Standard Gaussian
Œªp0 i (1‚àíp0 i )

distribution.
14

Figure 7: Convergence to zero of the difference (13): 1 000 independent simulations of the model
by means of Example 3.3 with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values of  and Œ¥ and
plot of the distribution of the three components of (13).
belongs to S = {0} √ó (1, +‚àû) ‚à™ (0, 1) √ó (0, +‚àû). In order to estimate the pair (Œ∑, Œª) ‚àà S, we define
T` = N`Œ∑ Q` =

k
X
Oi (`) ‚àí N` p‚àó0 i (`)
N` p‚àó0 i (`)
i=1

2
.

Given the observed values t1 , . . . , tL , the log-likelihood function of Q` reads
L

ln(L(Œ∑, Œª)) = ln L(Œ∑, Œª; t1 , . . . , tL ) = ‚àí

k‚àí1 X
k‚àí1
L ln(Œª) ‚àí
Œ∑
ln(N` ) ‚àí
2
2
`=1

1
2Œª

L
X

t`
N`Œ∑

+ R1 ,

`=1

where R1 is a remainder term that does not depend on (Œ∑, Œª). Now, we look for the maximum
likelihood estimator of the two parameters (Œ∑, Œª).
We immediately observe that, when all the clusters have the same cardinality, that is all the
N` are equal to a certain N0 , then we cannot hope to estimate Œ∑ and Œª, separately. Indeed, the
log-likelihood function becomes
ln(L(Œ∑, Œª)) = ln L(Œ∑, Œª; t1 , . . . , tL ) = ‚àí

i
k‚àí1 h
L ln(Œª) + Œ∑ ln(N0 ) ‚àí
2

1
2ŒªN0Œ∑

L
X

t` + R1 = f (ŒªN0Œ∑ ) .

`=1

dŒ∑ = PL t /(k ‚àí1)L.
This fact implies that it possible to estimate only the parameter (ŒªN0Œ∑ ) as ŒªN
0
`=1 `
From now on, we assume that at least two clusters have different cardinality, that is at least a
pair of cardinalities N` are different. We have to find (if they exist!) the maximum points of the
function (Œ∑, Œª) 7‚Üí ln(L(Œ∑, Œª)) on the set S, which is not closed nor limited. First of all, we note that
ln(L(Œ∑, Œª)) ‚Üí ‚àí‚àû for Œª ‚Üí +‚àû and Œª ‚Üí 0. Thus, the log-likelihood function has maximum value
on the closure S of S and its maximum points are stationary points belonging to (0, 1) √ó (0, +‚àû) or

15


Figure 8: Convergence in distribution of N 1/2‚àí(‚àíŒ¥) Œæ N i ‚àí p0 i : 1 000 independent simulations
of the model by means of Example 3.3 with k = 3, b0 = p0 = (0.167, 0.333, 0.5) and different values
of  and Œ¥ and plot of the distribution of N 1/2‚àí(‚àíŒ¥) ‚àö ŒæN i ‚àíp0 i
for i = 1, 2, 3. In red: Standard
ŒªÃÇp0 i (1‚àíp0 i )

Gaussian distribution.
16

they belong to {0, 1} √ó (0, +‚àû). For detecting the points of the first type, we compute the gradient
of the log-likelihood function, obtaining
PL
PL t` ln(N` ) !
1
‚àí k‚àí1
Œ∑
`=1 ln(N` ) + 2Œª
`=1
2
PL t` N`
‚àá(Œ∑, Œª) ln L =
.
1
k‚àí1
‚àí 2Œª L + 2Œª2 `=1 N Œ∑
`

Hence, the stationary points (Œ∑, Œª) of the log-likelihood function are solutions of the system
Ô£± PL t
PL
`
Ô£¥
Œ∑ ln(N` )
Ô£¥
ln(N` )
Ô£¥ `=1 N`
Ô£¥
= `=1
P L t`
Ô£¥
Ô£≤
L
Œ∑
`=1 N`

PL t`
Ô£¥
Ô£¥
Ô£¥
`=1 N`Œ∑
Ô£¥
Ô£¥
Ô£≥Œª =
.
L(k ‚àí 1)
In particular, we get that the stationary points are of the form (Œ∑, Œª(Œ∑)), with
PL t`
Œª(Œ∑) =

`=1 N`Œ∑

L(k ‚àí 1)

.

(15)

In order to find the maximum points on the border, that is belonging to {0, 1} √ó (0, +‚àû), we
observe that, fixed any Œ∑, the function
Œª 7‚Üí ‚àí

k‚àí1
L ln(Œª) ‚àí
2

1
2Œª

L
X

t`
N`Œ∑

+ R2 ,

`=1

where R2 is a remainder term not depending on Œª, takes its maximum value at the point Œª(Œ∑)
defined in (15).
Summing up, the problem of detecting the maximum points of the log-likelihood function on S
reduces to the study of the maximum points on [0, 1] of the function
Œ∑ 7‚Üí ln(L(Œ∑, Œª(Œ∑))) = ‚àí

L

L

`=1

`=1

X t  k ‚àí 1 X
k‚àí1
`
L ln
‚àí
Œ∑
ln(N` ) + R3 ,
2
N`Œ∑
2

(16)

where R3 is a remainder term not depending on Œ∑. To this purpose, we note that we have
Ô£ÆP
Ô£π
L
PL
t`
ln(N
)
ln(L(Œ∑, Œª(Œ∑))
k ‚àí 1 Ô£∞ `=1 N`Œ∑ ln(N` )
`
Ô£ª = (k ‚àí 1)L g(Œ∑) ,
d
=
L
‚àí `=1
PL t`
dŒ∑
2
L
2
`=1 Œ∑
N`

where

PL
g(x) =

t`
`=1 N`x ln(N` )
PL t`
`=1 N`x

PL
‚àí

ln(N` )
.
L

`=1

Setting
t`
N`x
P L tl
l=1 Nlx

p(x, `) =

and denoting by Ex [¬∑] and by Eu [¬∑] the mean value with respect to the discrete probability distribution {p(x, `) : ` = 1, . . . , L} on {N1 , . . . , NL } and with respect to the uniform discrete distribution
on {N1 , . . . , NL } respectively, the above function g can be written as
g(x) =

L
X
`=1

PL
p(x, `) ln(N` ) ‚àí

ln(N` )
= Ex [ln(N )] ‚àí Eu [ln(N )] .
L

`=1

17

Moreover, we have

g 0 (x) =

‚àí

PL

t`
`=1 N`x

 P
L
ln2 (N` )
`=1
P

t`
N`x

L
t`
`=1 N`x

=‚àí

L
X

p(x, `) ln2 (N` ) +

L
X

`=1



+

P

L
t`
`=1 N`x

2
ln(N` )

2

p(x, `) ln(N` )

2

= ‚àí V arx [ln(N )] ,

`=1

where V arx [¬∑] denotes the variance with respect to the discrete probability distribution {p(x, `) :
` = 1, . . . , L} on {N1 , . . . , NL }. Since, we are assuming that at least two N` are different, we have
V arx [ln(N )] > 0 and so the function g is strictly decreasing. Finally, we observe that we have
PL

`=1 t`

Covu (ln(N ), T ) =
and

ln(N` )

L

PL

PL
‚àí

`=1 t`

PL

L

PL

`=1 t`

L

PL t`
ln(N` )
`=1 N`
Covu (ln(N ),
=
‚àí
= g(1)
,
L
L
L
L
where Covu (¬∑, ¬∑) denotes the covariance with respect to the discrete joint distribution concentrated
on the diagonal and such that P {N = N` , T = t` } = 1/L with ` = 1, . . . , L. Hence, we distinguish
the following cases.
T
N)

t`
`=1 N`

ln(N` )

PL

ln(N` )
= g(0)
L

`=1

t`
`=1 N`

PL

`=1

First case: Covu (ln(N ), T ) ‚â§ 0
We are in the case when g(0) ‚â§ 0 and so the function (16) is strictly decreasing for Œ∑P> 0. Thus, its
L
b = Œª(0) = `=1 t` . Recall
maximum value on [0, 1] is assumed at Œ∑b = 0. Consequently, we have Œª
L(k‚àí1)

b ‚àà S and so Œª
b > 1. If the model fits well the data, this is a consequence. Indeed,
that we need (0, Œª)
d
b
b
b = Œª > 1. A value Œª
b ‚â§ 1 means
Œª is an unbiased estimator: Œª ‚àº Œì(L(k ‚àí 1)/2, 1/(2Œª)) and so E[Œª]
a bad fit of the consider model to the data (the smaller the value of Œª, the worse the fitting). Note
b = 1), the corresponding test statistics (14) and its distribution
that in the threshold case (b
Œ∑ = 0, Œª
coincide with the classical ones used for independent observations.
T
Second case: Covu (ln(N ), T ) > 0 and Covu (ln(N ), N
)<0

We are in the case when g(0) > 0 and g(1) < 0. Hence, the function (16) has a unique stationary
t`
N`Œ∑b
L(k‚àí1)

PL

b = Œª(b
point Œ∑b ‚àà (0, 1), which is the maximum point. Consequently, we have Œª
Œ∑) =
b belongs to S.
The point (b
Œ∑ , Œª)

`=1

> 0.

T
Third case: Covu (ln(N ), N
)‚â•0

We are in the case when g(1) ‚â• 0 and so the function (16) is strictly increasing on [0, 1]. Hence,
PL

t`

b = Œª(1) = `=1 N` . However, the point
its maximum point is at Œ∑b = 1, and, accordingly, we have Œª
L(k‚àí1)
b does not belong to S and so, in this case, we conclude that we have a bad fit of the model to the
(1, Œª)
d

data. Note that, if the considered model fits well the data, then we have T /N ‚àº Œªe(Œ∑‚àí1) ln(N ) œá2 (k ‚àí
T
1) with Œ∑ < 1 and, consequently, we expect Covu (ln(N ), N
) < 0. Moreover, a value Œ∑ ‚â• 1 in the
d

statistics (14) means a central limit theorem of the type N (1‚àíŒ∑)/2 (Œæ N ‚àí p0 ) ‚àº N (0, CŒì) with
(1 ‚àí Œ∑)/2 ‚â§ 0. This is impossible since (Œæ N ‚àí p0 ) is bounded.

18

Figure 9: Plot of the function (16). Its maximum point gives the estimated value of the model
parameter Œ∑.

7

COVID-19 epidemic Twitter analysis

We illustrate the application of the above statistical methodology to a dataset containing posts
on the on-line social network Twitter about the COVID-19 epidemic. More precisely, the dataset
covers the period from February 20th (h. 11pm) to April to 20th (h. 10pm) 2020, including tweets
in Italian language. More details on the keywords used for the query can be found in [14]. For every
message, the relative sentiment has been calculated using the polyglot python module developed
in [46]. This module provides a numerical value v for the sentiment and we have fixed a threshold
T = 0.35 so that we have classified as a tweet with positive sentiment those with v > T and
as a tweet with negative sentiment those with v < ‚àíT . We have discarded tweets with a value
v ‚àà [‚àíT, T ].
We are in the case k = 2 and the random variables Œæn = Œæn 1 take the value 1 when the sentiment
of the post n is positive. We have partitioned the data so that each set Pd collect the messages of the
single day d, for d = 1(February 20st), . . . , 61(April 20th) and then, in order to obtain independent
clusters, we have set C` = P1+3(`‚àí1) , for ` = 1, . . . , 21 = L. Therefore N` is the total number of
PL
tweets posted during the day 1 + 3(` ‚àí 1) and N = `=1 N` = 699 450 is the sample size. Inside
each cluster, the ‚Äúsentiment‚Äù associated to each message is driven by a reinforcement mechanism,
that can be modeled by means of a GRP: the probability to have a tweet with positive sentiment is
increasing with the number of past tweets with positive sentiment and the reinforcement is mostly
driven by the most recent tweets (see [2]).
Our purpose is to test the null hypothesis H0 : p0 (`) = p0 for any `. Therefore, taking
PN
p‚àó0 1 (`) = p‚àó0 = n=1 Œæn /N for each `, we have firstly estimated the model parameters and then
PL
we have performed the chi-squared test based on the aggregate statistics `=1 Q` and its corre1
, 2Œª
). The estimated values are Œ∑b = 0.4363572 and
sponding asymptotic distribution Œì( (L‚àí1)(k‚àí1)
2
b
Œª = 2.728098 (in Fig. 9 we plot the function (16)).
The contingency table and the associated statistics for testing H0 is given in Table 1. The
obtained œá2 -statistics for a usual œá2 -test is 5507.803, which is significant at any level of
Pconfidence.
L
Under the proposed GRP model and the null hypothesis, the aggregate statistics
`=1 Q` has
L‚àí1 1
(asymptotic) distribution Œì( 2 , b ) and the corresponding p-value associated to the data is equal
2Œª
to 0.4579297. The null hypothesis that the daily sentiment rate of the posts is the same for all the
considered days is therefore strongly rejected with a classical œá2 test, while the same hypothesis is
accepted if we take into account the reinforcement mechanism of correlation given in GRP model.
Finally, in Fig. 10 there are the values of the single statistics Q` . We have tested the inde-

19

Date
2020-02-20
2020-02-23
2020-02-26
2020-02-29
2020-03-03
2020-03-06
2020-03-09
2020-03-12
2020-03-15
2020-03-18
2020-03-21
2020-03-24
2020-03-27
2020-03-30
2020-04-02
2020-04-05
2020-04-08
2020-04-11
2020-04-14
2020-04-17
2020-04-20

Obs+
25
53564
29831
18220
16801
27906
41650
255
14193
12064
11571
13339
14798
12689
12714
13373
14889
12153
13406
13977
13753

Obs‚àí
43
60476
37175
22184
14834
27030
34769
156
13562
10089
10026
9172
10039
10651
9300
10815
11987
10777
11430
11371
12393

Exp+
35.11
58886.18
34599.51
20863.18
16335.18
28366.99
39460.04
212.23
14331.69
11439.02
11151.92
11623.88
12824.94
12051.94
11367.24
12489.82
13877.81
11840.23
12824.42
13088.80
13500.86

Exp‚àí
32.89
55153.82
32406.49
19540.82
15299.82
26569.01
36958.96
198.77
13423.31
10713.98
10445.08
10887.12
12012.06
11288.06
10646.76
11698.18
12998.19
11089.77
12011.58
12259.20
12645.14

œá2+
2.91
481.02
657.20
334.87
13.28
7.49
121.54
8.62
1.34
34.15
15.75
253.07
303.55
33.67
159.56
62.45
73.68
8.26
26.37
60.27
4.71

œá2‚àí
3.11
513.58
701.67
357.53
14.18
8.00
129.76
9.20
1.43
36.46
16.81
270.20
324.09
35.95
170.36
66.68
78.67
8.82
28.16
64.35
5.03

(c)

œá2+
0.46
2.99
5.15
3.27
0.14
0.06
0.90
0.62
0.02
0.43
0.20
3.19
3.67
0.42
2.03
0.76
0.86
0.10
0.32
0.72
0.06

(c)

œá2‚àí
0.49
3.19
5.50
3.49
0.15
0.07
0.96
0.67
0.02
0.46
0.22
3.41
3.92
0.45
2.17
0.82
0.92
0.11
0.34
0.77
0.06

Table 1: Contingency table associated to COVID-Twitter data: Obs+ (Obs‚àí ) are the number of posts
with positive (negative) sentiment posted in the day ` reported in the first column (DataTime); Exp+
(Exp‚àí ) corresponds to N` p‚àó0 (resp. N` (1 ‚àí p‚àó0 )), where N` = Obs+ + Obs‚àí ; œá2+ (œá2‚àí ) is the quantity
(Obs+ ‚àí Exp+ )2 /Exp+ (resp. (Obs‚àí ‚àí Exp‚àí )2 /Exp‚àí ); œá2+
œá2‚àí /N`Œ∑b). The statistics Q` corresponds to œá2+

(c)

+ œá2‚àí

(c)

(c)

(œá2‚àí

(c)

) is the quantity œá2+ /N`Œ∑b (resp.

.

Figure 10: Plot of the Q` -series. The black line corresponds to the value of 95th-quantile of the
distribution Œì( 12 , 1b ), that is 10.48.
2Œª

20

Df
œá2
p‚àívalue

1
3.454
0.063

2
3.624
0.163

3
4.209
0.240

4
4.640
0.326

5
5.065
0.408

6
7.103
0.311

7
8.660
0.278

8
8.812
0.358

9
10.360
0.322

10
12.852
0.232

Table 2: Summary of Ljung‚ÄìBox test for autocorrelation of Q` statistics with different numbers
of autocorrelation lags being tested. Df: number of lags under investigation; œá2 : Ljung‚ÄìBox test
statistics, which is distributed as a œá2 distribution with Df degrees of freedom under the null hypothesis
of independence; p‚àívalue: p‚àívalue of the Ljung‚ÄìBox test
pendence of the timed sequence {Q` } with a Ljung‚ÄìBox test and we give the results in Table 2.
The strong emotional involvement of those days had a ‚Äúmixing effects‚Äù that cancelled possible
significant autocorrelation during different 3-delayed days.

8

Proof of Theorem 4.2

PN
PN
For all the sequel, we set œà N ‚àí1 = n=1 œàn‚àí1 /N and Œ∏ N ‚àí1 = n=1 Œ∏n‚àí1 /N . To the proof of
Theorem 4.2, we premise some intermediate results.
Lemma 8.1. Under the same assumptions of Theorem 4.2, we have E[kŒ∏n k2 ] = O(n‚àí2Œ¥ ) ‚Üí 0.
Proof. We observe that, starting from (8), we get
kŒ∏n+1 k2 = Œ∏n+1 > Œ∏n+1 = (1 ‚àí n )2 kŒ∏n k2 + Œ¥n2 k‚àÜMn+1 k2 + 2(1 ‚àí n )Œ¥n Œ∏n > ‚àÜMn+1
and so
E[kŒ∏n+1 k2 |Fn ] = (1 ‚àí n )2 kŒ∏n k2 + Œ¥n2 E[k‚àÜMn+1 k2 |Fn ] .

(17)

2

Hence, setting xn = E[kŒ∏n k ], we get
xn+1 = (1 ‚àí 2n )xn + 2n xn + Œ¥n2 E[k‚àÜMn+1 k2 ]


Œ¥2
= (1 ‚àí 2n )xn + n n xn + n E[k‚àÜMn+1 k2 ]
n
= (1 ‚àí 2n )xn + 2n Œ∂n ,
with 0 ‚â§ Œ∂n =



n x n +

2
Œ¥n
2
n E[k‚àÜMn+1 k ]



/2. Applying Lemma S4.4 (with Œ≥n = 2n ), we find

that lim supn xn ‚â§ lim supn Œ∂n . On the other hand, since (‚àÜMn+1 )n is uniformly bounded and
2
2
2n /Œ¥n2 ‚àº c‚àí2 n‚àí2(‚àíŒ¥) ‚Üí 0, we have Œ∂n = O(n + Œ¥n2 ‚àí1
n ) = O(Œ¥n /n ) and so xn = O(Œ¥n /n ). We can
2 ‚àí2Œ¥
2
.
conclude recalling that Œ¥n /n ‚àº c n
Lemma 8.2. Under the same assumptions of Theorem 4.2, we have
Œ∏ N ‚àí1 =

N
N ‚àí1
1 X
1 X Œ¥n
Œ∏n‚àí1 =
‚àÜMn+1 + RN ,
N n=1
N n=0 n



a.s.
where RN ‚àí‚Üí 0 and N e E |RN | ‚àí‚Üí 0 with e = 1/2 ‚àí ( ‚àí Œ¥) ‚àà (0, 1/2).
Proof. By (9), we have
Œ∏n = ‚àí

1
Œ¥n
(Œ∏n+1 ‚àí Œ∏n ) + ‚àÜMn+1 .
n
n

21

(18)

Therefore, we can write
N
‚àí1
X

N
‚àí1
X

N ‚àí1

X Œ¥n
1
Œ∏n = ‚àí
(Œ∏n+1 ‚àí Œ∏n ) +
‚àÜMn+1


n=0
n=0 n
n=0 n

 NX

‚àí1 
N
‚àí1
X
Œ∏N
Œ∏0
1
1
Œ¥n
=‚àí
‚àí
‚àí
‚àí
Œ∏n +
‚àÜMn+1 ,
N ‚àí1
0



n‚àí1
n
n=1
n=0 n

where the second equality is due to the Abel transformation for a series. It follows the decomposition
(18) with



N ‚àí1 
1
Œ∏N
Œ∏0
1 X
1
1
RN = ‚àí
‚àí
‚àí
‚àí
Œ∏n .
(19)
N N ‚àí1
0
N n=1 n‚àí1
n
Since |Œ∏n | = O(1), we have
|RN | =

O(N ‚àí1 ‚àí1
N ‚àí1 )

+O N

‚àí1

N
‚àí1
X

!
|‚àí1
n‚àí1

‚àí

‚àí1
n |

n=1

PN ‚àí1
‚àí1
‚àí1
‚àí1
Note that n=1 |‚àí1
n‚àí1 ‚àín | = 0 ‚àíN ‚àí1 when (n ) is decreasing and so the last term in the above
‚àí(1‚àí)
expression is O(N ‚àí1 ‚àí1
)‚Üí
N ‚àí1 ). Therefore, since  < 1 by assumption, we have |RN | = O(N
0.
Regarding the
 last statement of the lemma, we observe that, from what we have proven before,
we obtain N e E |RN | = O(N e‚àí(1‚àí) ) = O(N Œ¥‚àí1/2 ) ‚Üí 0 when Œ¥ < 1/2. However, in the considered
cases 1) and 2), we might have Œ¥ ‚â• 1/2. Therefore, we need other arguments in order to prove the
last statement. To this purpose, we observe that, by Lemma 8.1, we have E[ |Œ∏n | ] = O(n/2‚àíŒ¥ )
and so, by (19), we have
!
N ‚àí1


1 X ‚àí1
‚àí1 /2‚àíŒ¥
e
‚àí(1‚àíe) 3/2‚àíŒ¥
|
‚àí n |n
N E |RN | = O(N
N
)+O
N 1‚àíe n=1 n‚àí1
!
N ‚àí1
1 X ‚àí1
‚àí1 /2‚àíŒ¥
‚àí(1‚àí)/2
|
‚àí n |n
.
= O(N
)+O
N 1‚àíe n=1 n‚àí1
Moreover, we have
N
‚àí1
X
n=1

‚àí1 /2‚àíŒ¥
|‚àí1
=
n‚àí1 ‚àí n |n

N
‚àí1
X

[(n ‚àí 1) ‚àí n ] n/2‚àíŒ¥ =

N
‚àí1
X

n‚àí1+/2‚àíŒ¥ ‚àº N 3/2‚àíŒ¥ = o(N 1‚àíe ) ,

n=1

n=1

because e = 1/2 ‚àí ( ‚àí Œ¥) and  < 1. Summing up, we have N e E[|RN |] = O(N ‚àí(1‚àí)/2 ) + o(1) ‚Üí
0.
a.s.

a.s.

Lemma 8.3. Under the same assumptions of Theorem 4.2, we have Œ∏ N ‚àí1 ‚àí‚Üí 0, that is œà N ‚àí1 ‚àí‚Üí
a.s.
a.s.
p0 . In particular, when  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ), we have Œ∏N ‚àí‚Üí 0, that is œàN ‚àí‚Üí p0 .
Note that, when  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ), we have the typical asymptotic behaviour of
the predictive mean of an urn process, that is its almost sure convergence. In the complementary
case, it seems to us not so easy to check if this type of convergence holds true. Therefore, for
the proof of Theorem 4.2 in this last case, we will employ a different technique, which is based on
the L2 -estimate of Lemma 8.1 for the predictive mean œàN and the almost sure convergence of the
corresponding empirical mean œà N ‚àí1 .
Proof. Let us distinguish the following two cases:

22

1)  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ) or
2)  ‚àà (0, 1) and Œ¥ ‚àà (/2, min{, 1/2}] \ {}.
For the case 1), we observe that, by (17), we have
E[kŒ∏n+1 k2 |Fn ] ‚â§ (1 + 2n )E[kŒ∏n k2 |Fn ] + Œ¥n2 E[k‚àÜMn+1 k2 |Fn ].
P 2
Therefore,
since (‚àÜMn+1 )n is uniformly bounded and, in case 1), we have
n n < +‚àû and
P 2
2
Œ¥
<
+‚àû,
the
sequence
(kŒ∏
k
)
is
a
bounded
non-negative
almost
supermartingale.
As a
n
n
n n
consequence, it converges almost surely to a certain random variable. This limit random variable
is necessarily equal to 0 because, by Lemma 8.1, we have E[kŒ∏n k2 ] = O(n‚àí2Œ¥ ) ‚Üí 0. Hence, we
have the almost sure convergence of Œ∏N to 0 and, consequently, the almost sure convergence of
Œ∏ N ‚àí1 to 0 follows by Lemma S4.2 and Remark S4.3 (with cn = n and vN,n = n/N ), because
E[Œ∏n‚àí1 |Fn‚àí2 ] = (1 ‚àí n‚àí2 )Œ∏n‚àí2 ‚Üí 0 almost surely.
a.s.
For the case 2), we use Lemma 8.2, that gives the decomposition (18), with RN ‚àí‚Üí 0. Indeed,
PN ‚àí1 Œ¥n
by this decomposition, it is enough to prove that the term n=0 n ‚àÜMn+1 /N converges almost
surely to 0. To this purpose, we observe that, if we set
Ln =

n
X
1 Œ¥j‚àí1
j=1

j j‚àí1

‚àÜMj ,

then (Ln ) is a square integrable martingale. Indeed, we have
+‚àû
2
X
1 Œ¥n‚àí1
E[k‚àÜMn k2 ] = O
2 2
n
n‚àí1
n=1

+‚àû
X
n=1

Therefore, (Ln ) converges almost surely, that is we have
Applying Lemma S4.1 (with vN,n = n/N ), we find

!

1
n1+2e

< +‚àû .

1 Œ¥n‚àí1
n n n‚àí1 ‚àÜMn

P

< +‚àû almost surely.

N ‚àí1
N
X
1 X Œ¥n
1 Œ¥n‚àí1
a.s.
‚àÜMn+1 =
vN,n
‚àÜMn ‚àí‚Üí 0
N n=0 n
n

n‚àí1
n=1
a.s.

and so Œ∏ N ‚àí1 ‚àí‚Üí 0.
Proof of Theorem 4.2. Set e = 1/2 ‚àí ( ‚àí Œ¥) ‚àà (0, 1/2) and Œª = c2 /[2(1 ‚àí e)] = c2 /[1 + 2( ‚àí Œ¥)].
Moreover, let us distinguish the following two cases:
1)  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ) or
2)  ‚àà (0, 1) and Œ¥ ‚àà (/2, min{, 1/2}] \ {}.
Almost sure convergence: In case 1), by Lemma 8.3, œàN converges almost surely to p0 . Therefore,
the almost sure convergence of Œæ N to p0 follows by Lemma S4.2 and P
Remark S4.3 (with cP
n = n and
vN,n = n/N ), because E[Œæn+1 |Fn ] = œàn ‚Üí p0 almost surely and n E[kŒæn k2 ]n‚àí2 ‚â§ n n‚àí2 <
+‚àû.
In case 2), we use a different argument. Take Œ≥ ‚àà [0, e) and set
Ln =

n
X
j=1

1 Œ¥j‚àí1
‚àÜMj .
j 1‚àíŒ≥ j‚àí1

Then (Ln ) is a square integrable martingale, because we have
+‚àû
X
n=1

1
n2‚àí2Œ≥

2
Œ¥n‚àí1
E[k‚àÜMn k2 ] = O
2
n‚àí1

23

+‚àû
X
n=1

1
n1+2e‚àí2Œ≥

!
< +‚àû .

P
1 Œ¥n‚àí1
Therefore, (Ln ) converges almost surely, that is we have n n1‚àíŒ≥
n‚àí1 ‚àÜMn < +‚àû almost surely.
1‚àíŒ≥
1‚àíŒ≥‚àí+Œ¥
1‚àíŒ≥
By Lemma S4.1 (with vN,n = (n/N )
n‚àí1 /Œ¥n‚àí1 ‚àº n
/N
), we get
N
‚àí1
X

1
N 1‚àíŒ≥

N
X

‚àÜMn+1 =

n=0

vN,n

n=1

1
n1‚àíŒ≥

Œ¥n‚àí1
a.s.
‚àÜMn ‚àí‚Üí 0.
n‚àí1

Therefore, we have

N Œ≥ Œæ N ‚àí œà N ‚àí1 =

1
N 1‚àíŒ≥

N
‚àí1
X

a.s.

‚àÜMn+1 ‚àí‚Üí 0,

n=0

‚àíŒ≥



that is Œæ N ‚àí œà N ‚àí1 = o(N ) for each Œ≥ ‚àà [0, e). Recalling Lemma 8.3, we obtain in particular
that Œæ N converges almost surely to p0 .
Second order asymptotic behaviour: We have
‚àö


N e Œæ N ‚àí p0 = N e ¬µN = N e‚àí1/2 N ¬µN ‚àí Œ∏ N ‚àí1 + N e Œ∏ N ‚àí1 .
(20)
Moreover, by Lemma 8.1, we have
N ‚àí1
N
X
1 X
E[|Œ∏n |] = O(N ‚àí1
n/2‚àíŒ¥ ) = O(N ‚àí1‚àíŒ¥+/2+1 ) = O(N /2‚àíŒ¥ ) ‚Üí 0 ,
N n=0
n=1
N ‚àí1
N
X
1 X
2
‚àí1
E[kŒ∏n k ] = O(N
n‚àí2Œ¥ ) = O(N ‚àí1‚àí2Œ¥++1 ) = O(N ‚àí2Œ¥ ) ‚Üí 0 ,
N n=0
n=1

and so Theorem S1.1 holds true with V = Œì (see Remark S1.2). Therefore, the first term in the
right side of (20) converges in probability to 0 because e < 1/2. Hence, if we prove that
s

N e Œ∏ N ‚àí1 ‚àí‚Üí N (0, ŒªŒì) ,

(21)

then the proof is concluded.
In order to prove (21), we observe that, by decomposition (18) in Lemma 8.2, we have
N e Œ∏ N ‚àí1 =

N
X

YN,n + N e RN ,

n=1
1 Œ¥n‚àí1
N 1‚àíe n‚àí1 ‚àÜMn


and N e RN converges in probability to 0 (because N e E |RN |] ‚Üí
PN
0). Therefore, it is enough to prove that the term n=1 YN,n stably converges to the Gaussian
kernel N (0, ŒªŒì), with Œª = c2 /[2(1 ‚àí e)] = c2 /[1 + 2( ‚àí Œ¥)]. To this purpose, we observe that
PN
E[YN,n |Fn‚àí1 ] = 0 and so n=1 YN,n converges stably to N (0, ŒªŒì) if the conditions (c1) and (c2) of
Theorem S6.1, with V = ŒªŒì, hold true. Regarding (c1), we note that Œ¥n‚àí1 /n‚àí1 ‚àº cn‚àíŒ¥ = cn1/2‚àíe
and so we have
where YN,n =

max |YN,n | ‚â§ N ‚àí(1‚àíe) max

1‚â§n‚â§N

1‚â§n‚â§N

Œ¥n‚àí1
Œ¥n‚àí1
|Œæn ‚àí œàn‚àí1 | ‚â§ N ‚àí(1‚àíe) max
= O(N ‚àí1/2 ) ‚Üí 0 .
1‚â§n‚â§N n‚àí1
n‚àí1

Condition (c2) means
1
N 2(1‚àíe)
We note that N ‚àí2(1‚àíe)

PN

N
2
X
Œ¥n‚àí1
P
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí ŒªŒì.
2

n=1 n‚àí1

2
2
n=1 Œ¥n‚àí1 /n‚àí1

2
‚Üí Œª, because Œ¥n‚àí1
/2n‚àí1 ‚àº c2 n1‚àí2e , and

E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > .

24

(22)

Therefore, in case 1), condition (22) immediately follows by the almost sure convergence of œàn to p0 .
2
It is enough to apply Lemma S4.2 and Remark S4.3 with cn = n and vN,n = nŒ¥n‚àí1
/(N 2(1‚àíe) 2n‚àí1 ) ‚àº
2 1+2(‚àíŒ¥)
2‚àí2e
2
2(1‚àíe)
c n
/N
= c (n/N )
. In case 2), we apply again Lemma S4.2 with the above cn
and vN,n , but we note that œàn = Œ∏n + p0 and so condition (S4.6) in Lemma S4.2, with V = ŒªŒì,
is equivalent to
1
N 2‚àí2e

N
‚àí1
X
n=0

Œ¥n2
P
Œ∏n ‚àí‚Üí 0
2n

1

and

N 2‚àí2e

N
‚àí1
X
n=0

Œ¥n2
P
Œ∏n Œ∏n > ‚àí‚Üí 0k√ók .
2n

These two convergences hold true because, by Lemma 8.1, we have
N
‚àí1
X

1
N 2‚àí2e
1
N 2‚àí2e

n=0

N
‚àí1
X
n=0

N
X
Œ¥n2
‚àí2+2e
E[|Œ∏n |] = O(N
n‚àí2Œ¥+2‚àíŒ¥+/2 ) = O(N ‚àí2+2e‚àí3Œ¥+5/2+1 ) = O(N ‚àíŒ¥+/2 ) ‚Üí 0 ,
2n
n=1

N
X
Œ¥n2
2
‚àí2+2e
E[kŒ∏
k
]
=
O(N
n‚àí2Œ¥+2‚àí2Œ¥+ ) = O(N ‚àí2+2e‚àí4Œ¥+3+1 ) = O(N ‚àí2Œ¥+ ) ‚Üí 0 .
n
2n
n=1

Therefore, in both cases 1) and 2), conditions c1) and c2) of Theorem S6.1 are satisfied and so
PN
n=1 YN,n stably converges to the Gaussian kernel N (0, ŒªŒì).
Declaration
Both authors equally contributed to this work.
Acknowledgments
Giacomo Aletti is a member of the Italian Group ‚ÄúGruppo Nazionale per il Calcolo Scientifico‚Äù of
the Italian Institute ‚ÄúIstituto Nazionale di Alta Matematica‚Äù and Irene Crimaldi is a member of the
Italian Group ‚ÄúGruppo Nazionale per l‚ÄôAnalisi Matematica, la ProbabilitaÃÄ e le loro Applicazioni‚Äù
of the Italian Institute ‚ÄúIstituto Nazionale di Alta Matematica‚Äù.
Funding Sources
Irene Crimaldi is partially supported by the Italian ‚ÄúProgramma di AttivitaÃÄ Integrata‚Äù (PAI),
project ‚ÄúTOol for Fighting FakEs‚Äù (TOFFE) funded by IMT School for Advanced Studies Lucca.

References
[1] Generalized rescaled PoÃÅlya urn and its statistical applications. Supplementary Material of this
article (2020)
[2] Aletti Giacomo, C.I., Saracco, F.: A model for the twitter sentiment curve. arXiv:2011.05933
(2020)
[3] Aletti, G., Crimaldi, I.: The rescaled PoÃÅlya urn: local reinforcement and chi-squared goodness
of fit test. arXiv:1906.10951 (2019)
[4] Aletti, G., Crimaldi, I., Ghiglietti, A.: Synchronization of reinforced stochastic processes with
a network-based interaction. Ann. Appl. Probab. 27(6), 3787‚Äì3844 (2017). DOI 10.1214/
17-AAP1296. URL https://doi.org/10.1214/17-AAP1296
[5] Aletti, G., Crimaldi, I., Ghiglietti, A.: Networks of reinforced stochastic processes: asymptotics
for the empirical means. Bernoulli 25(4B), 3339‚Äì3378 (2019)
[6] Aletti, G., Crimaldi, I., Ghiglietti, A.: Interacting reinforced stochastic processes: Statistical
inference based on the weighted empirical means. Bernoulli 26(2), 1098‚Äì1138 (2020)

25

[7] Aletti, G., Ghiglietti, A., Paganoni, A.M.: Randomly reinforced urn designs with prespecified
allocations. J. Appl. Probab. 50(2), 486‚Äì498 (2013). DOI 10.1239/jap/1371648956. URL
https://doi.org/10.1239/jap/1371648956
[8] Aletti, G., Ghiglietti, A., Rosenberger, W.F.: Nonparametric covariate-adjusted responseadaptive design based on a functional urn model. Ann. Statist. 46(6B), 3838‚Äì3866 (2018).
DOI 10.1214/17-AOS1677. URL https://doi.org/10.1214/17-AOS1677
[9] Aletti, G., Ghiglietti, A., Vidyashankar, A.N.: Dynamics of an adaptive randomly reinforced
urn. Bernoulli 24(3), 2204‚Äì2255 (2018). DOI 10.3150/17-BEJ926. URL https://doi.org/
10.3150/17-BEJ926
[10] Bergh, D.: Sample size and chi-squared test of fit‚Äî a comparison between a random sample approach and a chi-square value adjustment method using swedish adolescent data. In:
Q. Zhang, H. Yang (eds.) Pacific Rim Objective Measurement Symposium (PROMS) 2014
Conference Proceedings, pp. 197‚Äì211. Springer Berlin Heidelberg, Berlin, Heidelberg (2015)
[11] Berti, P., Crimaldi, I., Pratelli, L., Rigo, P.: Asymptotics for randomly reinforced urns with
random barriers. J. Appl. Probab. 53(4), 1206‚Äì1220 (2016). DOI 10.1017/jpr.2016.75. URL
https://doi.org/10.1017/jpr.2016.75
[12] Bertoni, D., Aletti, G., Ferrandi, G., Micheletti, A., Cavicchioli, D., Pretolani, R.: Farmland
use transitions after the cap greening: a preliminary analysis using markov chains approach.
Land Use Policy 79, 789 ‚Äì 800 (2018). DOI https://doi.org/10.1016/j.landusepol.2018.09.012.
URL http://www.sciencedirect.com/science/article/pii/S0264837718308676
[13] Caldarelli, G., Chessa, A., Crimaldi, I., Pammolli, F.: Weighted networks as randomly reinforced urn processes. Phys. Rev. E 87, 020106 (2013)
[14] Caldarelli G. de Nicola R., P.M.P.M., F., S.: Analysis of online misinformation during the
peak of the covid-19 pandemics in italy. arXiv: 2010.01913 (2020)
[15] Chanda, K.C.: Chi-squared tests of goodness-of-fit for dependent observations. In: Asymptotics, Non-Parametrics and Time Series, Statist. Textbooks Monogr., vol. 158, pp. 743‚Äì756.
Dekker (1999)
[16] Chen, M.R., Kuba, M.: On generalized poÃÅlya urn models. J. Appl. Probab. 50(4), 1169‚Äì1186
(2013). DOI 10.1239/jap/1389370106. URL https://doi.org/10.1239/jap/1389370106
[17] Chessa, A., Crimaldi, I., Riccaboni, M., Trapin, L.: Cluster analysis of weighted bipartite
networks: A new copula-based approach. PLOS ONE 9(10), 1‚Äì12 (2014). DOI 10.1371/
journal.pone.0109507. URL https://doi.org/10.1371/journal.pone.0109507
[18] Collevecchio, A., Cotar, C., LiCalzi, M.: On a preferential attachment and generalized poÃÅlya‚Äôs
urn model. Ann. Appl. Probab. 23(3), 1219‚Äì1253 (2013). DOI 10.1214/12-AAP869. URL
https://doi.org/10.1214/12-AAP869
[19] Crimaldi, I.: Central limit theorems for a hypergeometric randomly reinforced urn. J. Appl.
Probab. 53(3), 899‚Äì913 (2016). DOI 10.1017/jpr.2016.48. URL https://doi.org/10.1017/
jpr.2016.48
[20] Crimaldi, I., Dai Pra, P., Louis, P.Y., Minelli, I.G.: Synchronization and functional central
limit theorems for interacting reinforced random walks. Stochastic Processes and their Applications 129(1), 70‚Äì101 (2019)
[21] Crimaldi, I., Dai Pra, P., Minelli, I.G.: Fluctuation theorems for synchronization of interacting
PoÃÅlya‚Äôs urns. Stochastic Process. Appl. 126(3), 930‚Äì947 (2016). DOI 10.1016/j.spa.2015.10.
005. URL https://doi.org/10.1016/j.spa.2015.10.005
[22] Dai Pra, P., Louis, P.Y., Minelli, I.G.: Synchronization via interacting reinforcement. J. Appl.
Probab. 51(2), 556‚Äì568 (2014). DOI 10.1239/jap/1402578643. URL http://dx.doi.org/10.
1239/jap/1402578643

26

[23] Eggenberger, F., PoÃÅlya, G.: UÃàber die statistik verketteter vorgaÃànge. ZAMM - Journal of Applied Mathematics and Mechanics / Zeitschrift fuÃàr Angewandte Mathematik und Mechanik
3(4), 279‚Äì289 (1923). DOI 10.1002/zamm.19230030407. URL https://onlinelibrary.
wiley.com/doi/abs/10.1002/zamm.19230030407
[24] Gasser, T.: Goodness-of-fit tests for correlated data. Biometrika 62(3), 563‚Äì570 (1975). DOI
10.1093/biomet/62.3.563
[25] Ghiglietti, A., Paganoni, A.M.: Statistical properties of two-color randomly reinforced urn
design targeting fixed allocations. Electron. J. Statist. 8(1), 708‚Äì737 (2014). DOI 10.1214/
14-EJS899. URL https://doi.org/10.1214/14-EJS899
[26] Ghiglietti, A., Vidyashankar, A.N., Rosenberger, W.F.: Central limit theorem for an adaptive
randomly reinforced urn model. Ann. Appl. Probab. 27(5), 2956‚Äì3003 (2017). DOI 10.1214/
16-AAP1274. URL https://doi.org/10.1214/16-AAP1274
[27] Gleser, L.J., Moore, D.S.: The effect of dependence on chi-squared and empiric distribution
tests of fit. The Annals of Statistics 11(4), 1100‚Äì1108 (1983). URL http://www.jstor.org/
stable/2241300
[28] Holmes, M., Sakai, A.: Senile reinforced random walks. Stochastic Processes and their Applications 117(10), 1519‚Äì1539 (2007)
[29] Ieva, F., Paganoni, A.M., Pigoli, D., Vitelli, V.: Multivariate functional clustering for the
morphological analysis of electrocardiograph curves. Journal of the Royal Statistical Society.
Series C (Applied Statistics) 62(3), 401‚Äì418 (2013). URL http://www.jstor.org/stable/
24771812
[30] Knoke, D., Bohrnstedt, G.W., Potter Mee, A.: Statistics for Social Data Analysis. F.E.Peacock
Publishers (2002)
[31] Kushner, H.J., Yin, G.G.: Stochastic approximation and recursive algorithms and applications,
Applications of Mathematics (New York), vol. 35, second edn. Springer-Verlag, New York
(2003). Stochastic Modelling and Applied Probability
[32] Laruelle, S., PageÃÅs, G.: Randomized urn models revisited using stochastic approximation.
Ann. Appl. Proba. 23(4), 1409‚Äì1436 (2013)
[33] Lasmar, N., Mailler, C., Selmi, O.: Multiple drawing multi-colour urns by stochastic approximation. J. Appl. Probab. 55(1), 254‚Äì281 (2018)
[34] Mahmoud, H.M.: PoÃÅlya urn models. Texts in Statistical Science Series. CRC Press, Boca
Raton, FL (2009)
[35] Micheletti, A., Aletti, G., Ferrandi, G., Bertoni, D., Cavicchioli, D., Pretolani, R.: A weighted
œá2 test to detect the presence of a major change point in non-stationary Markov chains (2019).
Submitted for publication
[36] Pan, W.: Goodness-of-fit tests for GEE with correlated binary data. Scand. J. Statist. 29(1),
101‚Äì110 (2002). DOI 10.1111/1467-9469.00091
[37] Pelletier, M.: Weak convergence rates for stochastic approximation with application to multiple
targets an simulated annealing. Ann. Appl. Probab. 8(1), 10‚Äì44 (1998)
[38] Pemantle, R.: A time-dependent version of poÃÅlya‚Äôs urn. J. Theor. Probab. 3, 627‚Äì637 (1990)
[39] Pemantle, R.: A survey of random processes with reinforcement. Probab. Surveys 4, 1‚Äì79
(2007). DOI 10.1214/07-PS094. URL https://doi.org/10.1214/07-PS094
[40] Radlow, R., Alf Jr., E.F.: An alternate multinomial assessment of the accuracy of the œá2 test
of goodness of fit. Journal of the American Statistical Association 70(352), 811‚Äì813 (1975).
DOI 10.1080/01621459.1975.10480306

27

[41] Rao, J.N.K., Scott, A.J.: The analysis of categorical data from complex sample surveys: chisquared tests for goodness of fit and independence in two-way tables. J. Amer. Statist. Assoc.
76(374), 221‚Äì230 (1981)
[42] Sahasrabudhe, N.: Synchronization and fluctuation theorems for interacting Friedman urns.
J. Appl. Probab. 53(4), 1221‚Äì1239 (2016). DOI 10.1017/jpr.2016.76. URL http://dx.doi.
org/10.1017/jpr.2016.76
[43] Tang, M.L., Pei, Y.B., Wong, W.K., Li, J.L.: Goodness-of-fit tests for correlated paired binary
data. Stat. Methods Med. Res. 21(4), 331‚Äì345 (2012). DOI 10.1177/0962280210381176
[44] Tharwat, A.: Independent component analysis: An introduction. Applied Computing
and Informatics (2018). DOI https://doi.org/10.1016/j.aci.2018.08.006. URL http://www.
sciencedirect.com/science/article/pii/S2210832718301819
[45] Xu, D., Tian, Y.: A comprehensive survey of clustering algorithms. Annals of Data Science
2(2), 165‚Äì193 (2015)
[46] Y., C., S., S.: Building sentiment lexicons for all major languages. In: Proceedings of the 52nd
Annual Meeting of the Association for Computational Linguistics (Short Papers), pp. 383‚Äì389
(2014)

28

Supplemental Materials
In this document we collect some proofs, complements, technical results and recalls, useful for [S01].
Therefore, the notation and the assumptions used here are the same as those used in that paper.

S1

Proofs and intermediate results

We here collect some proofs omitted in the main text of the paper [S01].

S1.1

Proof of Theorem 3.1

The proof is based on Theorem 4.1 (for case a)) and Theorem 4.2 (for case b)). The almost
sure convergence of Oi /N immediately follows since Oi /N = Œæ N i . In order to prove the stated
convergence in distribution, we mimic the classical proof for the Pearson chi-squared test based on
the Sherman Morison formula (see [S18]), but see also [S16, Corollary 2].
We start recalling the Sherman Morison formula: if A is an invertible square matrix and we
have 1 ‚àí v > A‚àí1 u 6= 0, then
(A ‚àí uv > )‚àí1 = A‚àí1 +

A‚àí1 uv > A‚àí1
.
1 ‚àí v > A‚àí1 u

‚àó
Given the observation Œæn = (Œæn 1 , . . . , Œæn k )> , we define the ‚Äútruncated‚Äù vector Œæn
= (Œæn‚àó 1 , . . . , Œæn‚àó k‚àí1 )> ,
given by the first k ‚àí 1 components of Œæn . Theorem 4.1 (for case a)) and Theorem 4.2 (for case b))
give the second order asymptotic behaviour of (Œæn ), that immediately implies

N

e



‚àó
ŒæN

‚àó

‚àíp



PN
=

‚àó
n=1 (Œæn ‚àí
N 1‚àíe

p‚àó )

d

‚àí‚Üí N (0, Œì‚àó ),

(S1.1)

where p‚àó is given by the first k ‚àí 1 components of p0 and Œì‚àó = Œª(diag(p‚àó ) ‚àí p‚àó p‚àó T ). By assumption p0 i > 0 for all i = 1, . . . , k and so diag(p‚àó ) is invertible with inverse diag(p‚àó )‚àí1 =
1
) and, since (diag(p‚àó )‚àí1 )p‚àó = 1 ‚àà Rk‚àí1 , we have
diag( p01 1 , . . . , p0 k‚àí1
1 ‚àí p‚àó T diag(p‚àó )‚àí1 p‚àó = 1 ‚àí

k‚àí1
X

p0 i =

i=1

k
X

p0 i ‚àí

i=1

k‚àí1
X

p0 i = p0 k > 0.

i=1

Therefore we can use the Sherman Morison formula with A = diag(p‚àó ) and u = v = p‚àó , and we
obtain

1
1
1
1
(Œì‚àó )‚àí1 = (diag(p‚àó ) ‚àí p‚àó p‚àó T )‚àí1 =
diag( p01 1 , . . . , p0 k‚àí1
)+
11> .
(S1.2)
Œª
Œª
p0 k
Pk
Pk‚àí1
Now, since i=1 (Œæ N i ‚àí p0 i ) = 0, then Œæ N k ‚àí p0 k = i=1 (Œæ N i ‚àí p0 i ) and so we get
k
X
(Oi ‚àí N p0 i )2
i=1

N p0 i

k
X
(Œæ

k‚àí1

h X (Œæ ‚àí p )2
‚àí p0 i )2
(Œæ
‚àí p0 k )2 i
0i
Ni
=N
+ Nk
p0 i
p0 i
p0 k
i=1
i=1
P
k‚àí1
h k‚àí1
X (Œæ ‚àí p0 i )2
( i=1 (Œæ N i ‚àí p0 i ))2 i
Ni
=N
+
p0 i
p0 k
i=1
=N

=N

Ni

k‚àí1
X
i1 ,i2


1
1 
(Œæ N i1 ‚àí p0 i1 )(Œæ N i2 ‚àí p0 i2 ) Ii1 ,i2
+
,
p0 i1
p0 k
=1

S1

where Ii1 i2 is equal to 1 if i1 = i2 and equal to zero otherwise. Finally, from the above equalities,
recalling (S1.1) and (S1.2), we obtain
k
X
(Oi ‚àí N p0 i )2

1
N 1‚àí2e

i=1

N p0 i

‚àó

‚àó

d

= ŒªN 2e (Œæ N ‚àí p‚àó )> (Œì‚àó )‚àí1 (Œæ N ‚àí p‚àó ) ‚àí‚Üí ŒªW0 = W‚àó ,

where 1 ‚àí 2e ‚â• 0 and W0 is a random variable with distribution œá2 (k ‚àí 1) = Œì((k ‚àí 1)/2, 1/2),
where Œì(a, b) denotes the Gamma distribution with density function
f (w) =

ba a‚àí1 ‚àíbw
w
e
.
Œì(a)

As a consequence, W‚àó has distribution Œì((k ‚àí 1)/2, 1/(2Œª)).

S1.2

A preliminary central limit theorem

The following preliminary central limit theorem is useful for the proofs of the other central limit
theorems stated in [S01] and in Section S2.
Theorem S1.1. If
N
1 X
P
diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚àí‚Üí V ,
N n=1

(S1.3)

where V is a random variable with values in the space of positive semidefinite k √ó k-matrices, then
‚àö
 s
 ‚àö
N ¬µN ‚àí Œ∏ N ‚àí1 = N Œæ N ‚àí œà N ‚àí1 ‚àí‚Üí N (0, V ) .
Proof. We can write
‚àö

N


1
1 X
N Œæ N ‚àí œà N ‚àí1 = ‚àö N Œæ N ‚àí œà N ‚àí1 = ‚àö
(Œæn ‚àí œàn‚àí1 )
N
N n=1
N
N
X
1 X
YN,n ,
‚àÜMn =
=‚àö
N n=1
n=1

PN
with YN,n = N ‚àí1/2 ‚àÜMn . For the convergence of n=1 YN,n , we observe that E[YN,k |Fk‚àí1 ] = 0
and so, by Theorem S6.1, it converges stably to N (0, V ) if the conditions (c1) and (c2)‚àö
hold true.
Regarding (c1), we note that max1‚â§n‚â§N |YN,n | ‚â§ ‚àö1N max1‚â§n‚â§N |Œæn ‚àí œàn‚àí1 | = O(1/ N ) ‚Üí 0.
Condition (c2) means
N
X
n=1

YN,n Y >
N,n =

N
1 X
P
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí V.
N n=1

The above convergence holds P
true by Assumption (S1.3) and
P Lemma S4.2 (with cn = n and
vN,n = n/N ). Indeed, we have n‚â•1 E[kŒæn ‚àí œàn‚àí1 k2 ]/n2 ‚â§ n‚â•1 n‚àí2 < +‚àû and
E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > .

Remark S1.2. Recalling that œàn = Œ∏n +p0 , the convergence (S1.3) with V = Œì = diag(p0 )‚àíp0 p0 > ,
means
N
N
1 X
1 X
P
P
Œ∏ N ‚àí1 =
Œ∏n‚àí1 ‚àí‚Üí 0
and
Œ∏n‚àí1 Œ∏n‚àí1 > ‚àí‚Üí 0k√ók ,
N n=1
N n=1
where 0k√ók is the null matrix with dimension k √ó k.

S2

S1.3

Proof of Theorem 4.1

By Lemma S4.2 (with cn = n and vN,n = n/N ), Remark S4.3 and Theorem S5.1, we immediately
get Œæ N ‚Üí p0 almost
surely. Indeed, we have E[Œæn+1 |Fn ] = œàn ‚Üí p0 almost surely and
P
P
2 ‚àí2
‚àí2
E[kŒæ
k
]n
‚â§
< +‚àû.
n
n‚â•1
n‚â•1 n
Regarding the central limit theorem for Œæ N , we have to distinguish the two cases 1/2 <  ‚â§ 1 or
0 <  ‚â§ 1/2. In the first case, the result follows from Theorem S5.3, because (10) and the fact that
E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚Üí Œì almost surely; while for the second
case the result follows from Theorem S1.1. Indeed, we have
‚àö
 ‚àö
 ‚àö

N Œæ N ‚àí p0 = N Œæ N ‚àí œà N ‚àí1 + N œà N ‚àí1 ‚àí p0
‚àö
 ‚àö
= (c + 1) N Œæ N ‚àí œà N ‚àí1 ‚àí N DN ,
‚àö



where D N = c Œæ N ‚àí œà N ‚àí1 ‚àí œà N ‚àí1 ‚àí p0 . By Theorem S1.1, the term (c+1) N Œæ N ‚àí œà N ‚àí1
stably converges to N (0, (c + 1)2 Œì) (note that assumption (S1.3) is satisfied with V = Œì, ‚àö
because
œàn ‚Üí p0 almost surely). Therefore, in order to conclude, it is enough to show that N DN
converges in probability to 0. To this purpose, we observe that, by (8) with Œ¥n = cn , we have
œàn ‚àí œàn‚àí1 = n‚àí1 [c(Œæn ‚àí œàn‚àí1 ) ‚àí (œàn‚àí1 ‚àí p0 )]
and so
DN =

N
1 X œàn ‚àí œàn‚àí1
.
N n=1
n‚àí1

P+‚àû
Moreover, we note that n=1 (œàn ‚àí œàn‚àí1 ) = limN œàN ‚àí œà0 = p0 ‚àí œà0 < +‚àû and, by Lemma
S4.1 (with vN,n = N ‚àí1 /n‚àí1 ), we get
N ‚àí1

N
X
œàn ‚àí œàn‚àí1 a.s.
‚àí‚Üí 0.
n‚àí1
n=1

For  ‚â§ 1/2, this fact implies
‚àö

N DN = ‚àö

N
‚àí1
X
1
œàn ‚àí œàn‚àí1 a.s.
N ‚àí1
‚àí‚Üí 0 .
n‚àí1
N N ‚àí1
n=1

The proof is thus concluded.

S2

Case

P

n n

< +‚àû

P
In this section we provide some results regarding the case n n < +‚àû, even if, as we will see, this
case is not interesting for the chi-squared test of goodness of fit. Indeed, as shown in the following
result, the empirical mean almost surely converges to a random variable, which does not coincide
almost surely with a deterministic vector.
P+‚àû
a.s.
Theorem S2.1. If n=0 n < +‚àû, then Œæ N ‚àí‚Üí œà‚àû , where œà‚àû is a random variable, which is
not almost surely equal to a deterministic vector, that is P (œà‚àû 6= q0 ) > 0 for all q0 ‚àà Rk .
P+‚àû
Proof. When n=0 n < +‚àû, the sequence (œàn ) is a (bounded) non-negative almost supermartingale (see [S17]) because, by (8), we have
E[œàn+1 |Fn ] = œàn (1 ‚àí n ) + n p0 ‚â§ œàn + n p0 .

S3

As a consequence, it converges almost surely (and in Lp with p ‚â• 1) to a certain random variable
œà
fact follows from quasi-martingale theory [S12]: indeed, since
P‚àû . An alternative proof of this P
E[
|E[œà
|F
]
‚àí
œà
|
]
=
O(
n+1
n
n
n
n n ) < +‚àû, the stochastic process (œàn ) is a non-negative
quasi-martingale and so it converges almost surely (and in Lp with p ‚â• 1) to a certain random
variable œà‚àû .
The almost sure convergence of Œæ n to œà‚àû follows by Lemma S4.2 and Remark
P S4.3 (with cn = n
and vN,n = n/N ), because E[Œæn+1 |Fn ] = œàn ‚Üí œà‚àû almost surely and n‚â•1 E[kŒæn k2 ]n‚àí2 ‚â§
P
‚àí2
< +‚àû.
n‚â•1 n
In order to show that œà‚àû is not almost surely equal to a deterministic vector, we set
yn = E[kœàn ‚àí p0 k2 ] ‚àí kE[œàn ‚àí p0 ]k2 =

k
X

V ar[œàn i ‚àí p0 i ]

i=1

and observe that, starting from (8), we get
œàn+1 ‚àí p0 = (1 ‚àí n )(œàn ‚àí p0 ) + Œ¥n ‚àÜMn+1
and so
kE[œàn ‚àí p0 ]k2 = E[œàn ‚àí p0 ]> E[œàn ‚àí p0 ] = (1 ‚àí n )2 kE[œàn ‚àí p0 ]k2
and
E[kœàn+1 ‚àí p0 k2 ] = E[(œàn+1 ‚àí p0 )> (œàn+1 ‚àí p0 )]
= (1 ‚àí n )2 E[kœàn ‚àí p0 k2 ] + Œ¥n2 E[k‚àÜMn+1 k2 ] .
Hence, we obtain
yn+1 = (1 ‚àí n )2 yn + Œ¥n2 E[k‚àÜMn+1 k2 ] = (1 ‚àí 2n )yn + Œ∂en

(S2.4)

with Œ∂en = 2n yn + Œ¥n2 E[k‚àÜMn+1 k2 ] ‚â• 0. It follows that, given nÃÉ such that n < 1/2 for n ‚â• nÃÉ, we
QN ‚àí1
have yN ‚â• ynÃÉ n=nÃÉ (1 ‚àí 2n ) for each N ‚â• nÃÉ and so
!
+‚àû
+‚àû
Y
X
E[kœà‚àû ‚àíp0 k2 ]‚àíkE[œà‚àû ‚àíp0 ]k2 = y‚àû = lim yN ‚â• ynÃÉ
(1‚àí2n ) = ynÃÉ exp
ln(1 ‚àí 2n ) .
N ‚Üí+‚àû

n=nÃÉ

n=nÃÉ

P+‚àû

P+‚àû
The above exponential is strictly greater than 0 because n=nÃÉ ln(1 ‚àí 2n ) ‚àº ‚àí2 n=nÃÉ n > ‚àí‚àû.
Therefore, if ynÃÉ > 0, then we have y‚àû > 0. This means that œà‚àû ‚àí p0 , and consequently œà‚àû ,
is not almost surely equal to a deterministic vector, that is P (œà‚àû 6= q0 ) > 0 for all q0 ‚àà Rk . If
e then, by (S2.4), we get
ynÃÉ = 0, that is if œànÃÉ is almost surely equal to a deterministic vector œà,
e 2] > 0 ,
ynÃÉ+1 = Œ¥n2 E[k‚àÜMn+1 k2 ] = Œ¥nÃÉ2 E[kŒænÃÉ+1 ‚àí œàk
e is different from a vector of the canonical base of Rk by means of
because Œ¥n > 0 for each n and œà
the assumption b0 i + B0 i > 0 and equality (5). It follows that we can repeat the above argument
replacing nÃÉ by nÃÉ + 1 and conclude that œà‚àû is not almost surely equal to a deterministic vector.
As a consequence of the above theorem, if we aim atP
having the almost sure convergence of
+‚àû
Œæ N to a deterministic vector, we have to avoid the case n=0 n < +‚àû. However, for the sake
of completeness, we provide a second-order convergence result also in this case. First, we note
that Theorem S1.1 still holds true with V = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > . Indeed, assumption (S1.3) is
satisfied by Lemma S4.2 and Remark S4.3 (with cn = n and vN,n = n/N ), because of the almost
sure convergence of œàn to œà‚àû . Moreover, we have the following theorem:
Theorem S2.2. Suppose to be in one of the following two cases:

S4

a)

PN

n=1

‚àö
‚àö
PN
nn‚àí1 = o( N ) and n=1 nŒ¥n‚àí1 = o( N );

b) n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0, Œ¥ ‚àà (1/2, 1) and  > Œ¥ + 1/2 ( = +‚àû
included, that means n = 0 for all n).
Set e = 1/2 and Œª = 1 in case a) and e = Œ¥ ‚àí 1/2 ‚àà (0, 1/2) and Œª = c2 /[2(1 ‚àí e)] = c2 /(3 ‚àí 2Œ¥) in
case b). Then, we have
 s
N e Œæ N ‚àí œàN ‚àí‚Üí N (0, ŒªŒì) ,
where Œì = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > .
When (œàN ‚àí œà‚àû ) = oP (N ‚àíe ), we also have
 s
N e Œæ N ‚àí œà‚àû ‚àí‚Üí N (0, ŒªŒì) .
Note that case a) covers the case n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and min{, Œ¥} >
3/2.
The case n = 0 (that is Œ≤n = 1) for all n corresponds to the case considered in [S15], but in
that paper the author studies only the limit œà‚àû and he does not provide second-order convergence
results.
Proof. We have

N e Œæ N ‚àí œàN =

1
N 1‚àíe

1
N 1‚àíe
=


N Œæ N ‚àí N œàN =

N
X

(Œæn ‚àí œàn‚àí1 ) +

n=1

1
N 1/2‚àíe

N
X

YN,n +

n=1

N 1‚àíe

N 1‚àíe

[Œæn ‚àí œàn‚àí1 + n(œàn‚àí1 ‚àí œàn )]

n=1

N
X

1

N
X

N
X

1

nn‚àí1 (œàn‚àí1 ‚àí p0 ) ‚àí

n=1

N
X

1
N 1‚àíe

nŒ¥n‚àí1 ‚àÜMn

n=1

ZN,n + QN ,

n=1

where
YN,n =

‚àÜMn
Œæn ‚àí œàn‚àí1
‚àö
= ‚àö ,
N
N

ZN,n = ‚àí

and
QN =

1
N 1‚àíe

N
X

nŒ¥n‚àí1 (Œæn ‚àí œàn‚àí1 )
nŒ¥n‚àí1 ‚àÜMn
=
N 1‚àíe
N 1‚àíe

nn‚àí1 (œàn‚àí1 ‚àí p0 ).

n=1

PN
In both cases a) and b), we have n=1 nn‚àí1 = o(N 1‚àíe ) and so QN converges almost surely to 0.
PN
Moreover, by Theorem S1.1, n=1 YN,n stable converges to N (0, V ) with V = Œì = diag(œà‚àû ) ‚àí
PN
œà‚àû œà‚àû > . Therefore it is enough to study the convergence of n=1 ZN,n . To this purpose, we
PN
observe that, if we are in case a), then n=1 ZN,n converges almost surely to 0 and so
‚àö
 s
N Œæ N ‚àí œàN ‚àí‚Üí N (0, Œì).
PN
Otherwise, if we are in case b), we observe that E[ZN,n |Fn‚àí1 ] = 0 and so n=1 ZN,n converges
stably to N (0, ŒªŒì) if the conditions (c1) and (c2) of Theorem S6.1, with V = ŒªŒì, hold true.‚àö Re1
garding (c1), we observe that max1‚â§n‚â§N |ZN,n | ‚â§ N 1‚àíe
max1‚â§n‚â§N nŒ¥n‚àí1 |Œæn ‚àíœàn‚àí1 | = O(1/ N ).
Regarding condition (c2), that is
N
X
n=1

ZN,n ZN,n > =

1
N 2(1‚àíe)

N
X

P

2
n2 Œ¥n‚àí1
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí

n=1

S5

c2
Œì,
2(1 ‚àí e)

we observe that it holds true even almost surely, because
c2 /(3 ‚àí 2Œ¥) and

1
N 2(1‚àíe)

PN

n=1

2
n2 Œ¥n‚àí1
‚Üí c2 /[2(1 ‚àí e)] =

a.s.

E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚àí‚Üí Œì
2
(see Lemma S4.2 and Remark S4.3 with cn = n and vN,n = n3 Œ¥n‚àí1
/N 2(1‚àíe) ‚àº c2 (n/N )3‚àí2Œ¥ ).
Therefore, we have
 s

N e Œæ N ‚àí œàN ‚àí‚Üí N 0, c2 (3 ‚àí 2Œ¥)‚àí1 Œì .

Finally, we observe that


N e Œæ N ‚àí œà‚àû = N e Œæ N ‚àí œàN + N e (œàN ‚àí œà‚àû ) .
Therefore, when (œàN ‚àí œà‚àû ) = oP (N ‚àíe ), we have
 s
N e Œæ N ‚àí œà‚àû ‚àí‚Üí N (0, ŒªŒì) .

An example of the case a) of Theorem S2.2 with (œàN ‚àí œà‚àû ) = oP (N ‚àíe ) is the RP urn with
Œ±n = Œ± > 0 and Œ≤n = Œ≤ > 1 (see [S02]). Indeed, in this case, we have n ‚àº c Œ≤ ‚àín and Œ¥n ‚àº cŒ¥ Œ≤ ‚àín ,
where c > 0 and cŒ¥ > 0 are suitable constants, and (œàN ‚àí œà‚àû ) = O(Œ≤ ‚àíN ). We conclude this
section with other two examples regarding the case n = 0 (that is Œ≤n = 1) for all n.
Example S2.3. (Case n = 0 and Œ¥n ‚àº c(n + 1)‚àíŒ¥Pwith c > 0 and Œ¥ > 3/2)
n
If n = 0 for all n, then we have rn‚àó = |b0 | + |B0 | + h=1 Œ±h . Therefore, if we take Œ±n = n‚àíŒ¥ , with
P+‚àû
‚àó
Œ¥ > 3/2, then rn‚àó converges to the constant r‚àó = |b0 | + |B0 | + h=1 h‚àíŒ¥ and Œ¥n = Œ±n+1 /rn+1
‚àº
‚àíŒ¥
‚àó
cŒ±n+1 = c(n + 1) , with c = P
1/r . Moreover, since Œ¥ > 3/2, assumption a) of Theorem S2.2 is
satisfied. We also observe that n Œ¥n2 < +‚àû and so œà‚àû i is not concentrated on {0, 1} and has no
atoms in (0, 1) (see [S15, Th. 2 and Th. 3]). More precisely, we have
œà‚àû =

b0 + B0 +
|b0 | +

P+‚àû

n=1 Œ±n Œæn
P+‚àû
|B0 | + n=1 Œ±n

and so
œàN ‚àí œà‚àû =
PN
P
PN
P
(b0 + B0 + n=1 Œ±n Œæn ) n‚â•N +1 Œ±n ‚àí (|b0 | + |B0 | + n=1 Œ±n ) n‚â•N +1 Œ±n Œæn
=
PN
P+‚àû
(|b0 | + |B0 | + n=1 Œ±n )(|b0 | + |B0 | + n=1 Œ±n )
Ô£´
Ô£∂
X

OÔ£≠
Œ±n Ô£∏ = O N 1‚àíŒ¥ .
n‚â•N +1

Since Œ¥ > 3/2, we get (œàN ‚àí œà‚àû ) = o(N ‚àí1/2 ). This fact can also be obtained as a consequence
of Theorem S2.5 below. Indeed, this theorem states that the rate of convergence of œàN to œà‚àû is
N ‚àí(Œ¥‚àí1/2) .
Note that, since Œ≤n = 1 for all n, the factor f (h, n) in (6) coincides with Œ±h and so, in this case,
it is decreasing.
Example S2.4. (Case n = 0 and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and Œ¥ ‚àà (1/2, 1)) P
n
As in the P
previous example, since n = 0 for all n, we have rn‚àó = |b0 | + |B0 | + h=1 Œ±h . Let us
n
Œ±
‚àó
set An = h=1 Œ±h = exp(bn ) with b > 0 and Œ± ‚àà (0, 1/2), which brings to rn ‚àº An ‚Üë +‚àû and

S6

Œ±n = exp(bnŒ± ) ‚àí exp(b(n ‚àí 1)Œ± ) and
Pn‚àí1
Œ±h
Œ±n
Œ¥n‚àí1 =
‚àº 1 ‚àí Ph=1
n
|b0 | + |B0 | + An
h=1 Œ±h
= 1 ‚àí exp [b ((n ‚àí 1)Œ± ‚àí nŒ± )]



= bnŒ± 1 ‚àí (1 ‚àí n‚àí1 )Œ± + O n2Œ± (1 ‚àí (1 ‚àí n‚àí1 )Œ± )2 = bnŒ± Œ±n‚àí1 + O(n‚àí2 ) + O(n‚àí(2‚àí2Œ±) )
= bŒ±n‚àí(1‚àíŒ±) + O(n‚àí(2‚àíŒ±) ) + O(n‚àí(2‚àí2Œ±) ) = bŒ±n‚àí(1‚àíŒ±) + O(n‚àí2(1‚àíŒ±) ),
so that Œ¥ = (1 ‚àí Œ±) ‚àà (1/2, 1) and c = bŒ± > 0. Hence,
have Œ¥n ‚àº c(n + 1)‚àíŒ¥ and assumption b)
P we
2
of Theorem S2.2 is satisfied. We also observe that n Œ¥n < +‚àû and so œà‚àû i is not concentrated on
{0, 1} and has no atoms in (0, 1) (see [S15, Th. 2 and Th. 3]). Moreover, by Theorem S2.5 below,
we get that N e (œà N ‚àí œà‚àû ) ‚àí‚ÜíN 0, c2 (2e)‚àí1 Œì , where e = Œ¥ ‚àí 1/2. Hence, applying Theorem
S6.3, we obtain
 s

N e Œæ N ‚àí œà‚àû ‚àí‚Üí N 0, c2 [2e(1 ‚àí e)]‚àí1 Œì .
Finally, note that, as before, since Œ≤n = 1 for all n, the factor f (h, n) in (6) coincides with Œ±h and
so, in this case, `(h) = ln(f (h, n)) = ln(Œ±h ) ‚àº ln(Œ¥h‚àí1 ) + bhŒ± ‚àº bhŒ± ‚àí bŒ±(1 ‚àí Œ±) ln(h). Hence,
there exists h‚àó such that h 7‚Üí `(h) is increasing for h ‚â• h‚àó . Since maxh‚â§h‚àó `(h) ‚â§ C, for a suitable
constant C, the contributions of the observations until h‚àó are eventually smaller than those with
h ‚â• h‚àó , that are increasing with h.
Theorem S2.5. For n = 0 for all n and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and 1/2 < Œ¥ ‚â§ 1, we have

1
stably in the strong sense w.r.t. F,
N Œ¥‚àí 2 (œà N ‚àí œà‚àû ) ‚àí‚ÜíN 0, c2 (2Œ¥ ‚àí 1)‚àí1 Œì
where Œì = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > .
Proof. We want to apply Theorem S6.2. To this purpose, we recall that, when n = 0 for all n, the
process (œàn ) is a martingale with respect to F. Moreover, it converges almost surely and in mean
to œà‚àû . Therefore, in order to conclude, it is enough to check conditions (c1) and (c2) of Theorem
S6.2. Regarding the first condition, we note that
N Œ¥‚àí1/2 sup |œàn ‚àí œàn+1 | = N Œ¥‚àí1/2 sup Œ¥n |‚àÜMn+1 | = O(N Œ¥‚àí1/2‚àíŒ¥ ) = O(N ‚àí1/2 ) ‚àí‚Üí 0.
n‚â•N

n‚â•N

Finally, regarding the second condition, we observe that
X
X
N 2Œ¥‚àí1
(œàn ‚àí œàn+1 )(œàn ‚àí œàn+1 )> ‚àº N 2Œ¥‚àí1 c2
(n + 1)‚àí2Œ¥ (‚àÜMn+1 )(‚àÜMn+1 )>
n‚â•N

n‚â•N
a.s.

‚àí‚Üí

2

c
Œì,
(2Œ¥ ‚àí 1)

where the almost sure convergence follows from [S06, Lemma 4.1] and the fact that
a.s.

E[(‚àÜMn+1 )(‚àÜMn+1 )> |Fn ] = E[(Œæn+1 ‚àí œàn )(Œæn+1 ‚àí œàn )> |Fn ] ‚àí‚Üí Œì.

S3

Computations regarding local reinforcement

Suppose Œ±n ‚àº an‚àíŒ± for n ‚â• 1 and (1 ‚àí Œ≤n ) ‚àº b(n + 1)‚àíŒ≤ for n ‚â• 0. In the following subsections
Qn‚àí1
we study the behaviour of the factor f (h, n) = Œ±h j=h Œ≤j in some particular cases that cover the
cases of the two examples in Section 3. Specifically, for all the considered cases, we set `(h, n) =
Qn‚àí1
Pn‚àí1
ln(Œ±h j=h Œ≤j ) = ln(Œ±h ) + j=h ln(Œ≤j ) for n ‚â• h and we prove that there exists h‚àó such that
maxh‚â§h‚àó `(h, n) ‚â§ `(h‚àó , n) and h 7‚Üí `(h, n) is increasing for h ‚â• h‚àó . This means that the weights
f (h, n) of the observations until h‚àó are smaller than those with h ‚â• h‚àó and the contribution of the
observation for h ‚â• h‚àó is increasing with h.

S7

S3.1

Case Œ± = Œ≤ ‚àà (0, 1)

Suppose Œ±n = an‚àíŒ± and 1 ‚àí Œ≤n = b(n + 1)‚àíŒ± , with a, b > 0 and Œ± ‚àà (0, 1). For n ‚â• h, we have
`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àíŒ± ) ‚àí ln(ah‚àíŒ± ) ‚àí ln(1 ‚àí b(h + 1)‚àíŒ± )



1
b
Œ±
b
= ‚àíŒ± ln 1 +
‚àí ln 1 ‚àí
=‚àí +
.
h
(h + 1)Œ±
h (h + 1)Œ±
Since Œ± < 1, there exists h0 such that the function h 7‚Üí `(h, n) is monotonically increasing for
‚àíŒ±
h ‚â• h0 . Now, fix Œ∑ > 0 and let j0 such that j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj
1+Œ∑ . Then take h‚àó ‚â•
max(h0 , j0 ) + 1 and h ‚â§ h0 ‚àí 1. For h‚àó large enough, we get
`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

‚àíŒ±
ln(Œ≤j ) = ln(ah‚àíŒ±
)‚àí
‚àó ) ‚àí ln(ah

j=h

hX
‚àó ‚àí1

ln(Œ≤j )

j=h

hX
‚àó ‚àí1

bj ‚àíŒ±
1+Œ∑
j=max(h0 ,j0 )
Z h‚àó ‚àí1
b
x‚àíŒ± dx
‚â• ‚àíŒ± ln(h‚àó ) + C1 +
1 + Œ∑ max(h0 ,j0 )


b
= ‚àíŒ± ln(h‚àó ) + C1 +
(h‚àó ‚àí 1)1‚àíŒ± ‚àí max(h0 , j0 )1‚àíŒ±
(1 + Œ∑)(1 ‚àí Œ±)
b
= C2 ‚àí Œ± ln(h‚àó ) +
(h‚àó ‚àí 1)1‚àíŒ± ‚â• 0 .
(1 + Œ∑)(1 ‚àí Œ±)
‚â• ln(h‚àíŒ±
‚àó )+

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n)‚à®maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S3.2

Case Œ± = Œ≤ = 1

Suppose Œ±n = an‚àí1 and 1 ‚àí Œ≤n = b(n + 1)‚àí1 , with a > 0 and b > 1. For n ‚â• h, we have
`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àí1 ) ‚àí ln(ah‚àí1 ) ‚àí ln(1 ‚àí b(h + 1)‚àí1 )


b 
b‚àí1
1
‚àí ln 1 ‚àí
=
+ o(h‚àí1 ).
= ‚àí ln 1 +
h
(h + 1)
h+1
Since b > 1, we can argue as in the previous subsection. Therefore, there exists h0 such that the
function h 7‚Üí `(h, n) is monotonically increasing for h ‚â• h0 . Now, fix Œ∑ = (b ‚àí 1)/(b + 1) > 0 and
‚àí1
let j0 such that j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj
1+Œ∑ . Then take h‚àó ‚â• max(h0 , j0 ) + 1 and h ‚â§ h0 ‚àí 1.

S8

For h‚àó large enough, we get
`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

ln(Œ≤j ) =

ln(ah‚àí1
‚àó )

‚àí ln(ah

‚àí1

)‚àí

j=h

hX
‚àó ‚àí1

ln(Œ≤j )

j=h

hX
‚àó ‚àí1

bj ‚àí1
1+Œ∑
j=max(h0 ,j0 )
Z h‚àó ‚àí1
b
x‚àí1 dx
‚â• ‚àí ln(h‚àó ) + C1 +
1 + Œ∑ max(h0 ,j0 )

b 
= ‚àí ln(h‚àó ) + C1 +
ln(h‚àó ‚àí 1) ‚àí ln(max(h0 , j0 ))
(1 + Œ∑)
b‚àí1‚àíŒ∑
= C2 +
ln(h‚àó ) ‚àí O(1/h‚àó )
(1 + Œ∑)
b(b ‚àí 1)
= C2 +
ln(h‚àó ) ‚àí O(1/h‚àó ) ‚â• 0 .
2b
‚â• ln(h‚àí1
‚àó )+

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n)‚à®maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S3.3

Case 0 < Œ± < Œ≤ < (1 + Œ±)/2

Suppose



c2
c3
c1
+ O(1/n2‚àíŒ≤ )
Œ±n = an‚àíŒ± 1 + 1‚àíŒ≤ + Œ≤‚àíŒ± +
n
n
n

and 1 ‚àí Œ≤n = b(n + 1)‚àíŒ≤ , with a, b > 0, 0 < Œ± < Œ≤ < (1 + Œ±)/2 and c1 , c2 , c3 ‚àà R. Set
Œ≥ = Œ≤ ‚àí Œ± ‚àà (0, 1/2). For n ‚â• h, we have
`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àíŒ± ) ‚àí ln(ah‚àíŒ± ) ‚àí ln(1 ‚àí b(h + 1)‚àíŒ≤ )

+ ln 1 + c1 /(h + 1)1‚àíŒ≤ + c2 /(h + 1)Œ≥ + c3 /(h + 1) + O(1/h2‚àíŒ≤ ) (S3.5)

‚àí ln 1 + c1 /h1‚àíŒ≤ + c2 /hŒ≥ + c3 /h + O(1/h2‚àíŒ≤ ) .
Now, we aim at obtaining a series expansion with a reminder term of the type o(1/hŒ≤ ). Since
Œ≤ < 1, the first three terms of the right-hand side of the above equation give
 1


b
b
ln(a(h+1)‚àíŒ± )‚àíln(ah‚àíŒ± )‚àíln(1‚àíb(h+1)‚àíŒ≤ ) = ‚àíŒ± ln 1+ ‚àíln 1‚àí
=
+o(h‚àíŒ≤ ).
h
(h + 1)Œ≤
(h + 1)Œ≤
We deal now with the last two terms of (S3.5). We recall that
ln(1 + x) = x ‚àí

x2
x3
xj
+
+ ¬∑ ¬∑ ¬∑ + (‚àí1)j‚àí1
+ o(xj ) ,
2
3
j

and therefore, since 2 ‚àí Œ≤ = 1 + 1 ‚àí Œ≤ > 1 > Œ≤ and j(1 ‚àí Œ≤) > Œ≤ and jŒ≥ = j(Œ≤ ‚àí Œ±) > Œ≤ for j large
enough, there are only a finite number J0 of terms with an order œÑj ‚â§ Œ≤. In other words, we can
write

ln 1 + c1 /(h + 1)1‚àíŒ≤ + c2 /(h + 1)Œ≥ + c3 /(h + 1) + O(1/n2‚àíŒ≤ )

‚àí ln 1 + c1 /h1‚àíŒ≤ + c2 /hŒ≥ + c3 /h + O(1/n2‚àíŒ≤ )
=

J0
X
j=1

Cj (h + 1)‚àíœÑj ‚àí

J0
X

Cj h‚àíœÑj + o(1/hŒ≤ )

j=1

S9

=

=

J0
X

J0
X




Cj (h + 1)‚àíœÑj ‚àí h‚àíœÑj + o(1/hŒ≤ ) =
Cj h‚àíœÑj (1 + h‚àí1 )‚àíœÑj ‚àí 1 + o(1/hŒ≤ )

j=1

j=1

J0
X


Cj h‚àíœÑj (œÑj h‚àí1 + o(1/h) + o(1/hŒ≤ ) = o(1/hŒ≤ ) .

j=1

Summing up, we have
`(h + 1, n) ‚àí `(h, n) =

b
+ o(h‚àíŒ≤ ).
(h + 1)Œ≤

Then there exists h0 such that the function h 7‚Üí `(h, n) is monotonically increasing for h ‚â• h0 .
‚àíŒ≤
Now, fix Œ∑ > 0 and let j0 such that j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj
1+Œ∑ . Then take h‚àó ‚â• max(h0 , j0 ) + 1
and h ‚â§ h0 ‚àí 1. Since Œ≤ < (1 + Œ±)/2, we have Œ±n = an‚àíŒ± (1 + O(1/nŒ≥ )) and so, for h‚àó large enough,
we get
`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

ln(Œ≤j )

j=h
‚àíŒ±
= ln(ah‚àíŒ±
) + ln(1 + O(h‚àíŒ≥
‚àó ) ‚àí ln(ah
‚àó )) + C1 ‚àí

hX
‚àó ‚àí1

ln(Œ≤j )

j=h
hX
‚àó ‚àí1

‚àíŒ≥
‚â• ln(h‚àíŒ±
‚àó ) + ln(1 + O(h‚àó )) + C1 +

j=max(h0 ,j0 )

‚â• ‚àíŒ± ln(h‚àó ) +

O(h‚àíŒ≥
‚àó )

b
+ C2 +
1+Œ∑

Z

h‚àó ‚àí1

bj ‚àíŒ≤
1+Œ∑

x‚àíŒ≤ dx

max(h0 ,j0 )



b
(h‚àó ‚àí 1)1‚àíŒ≤ ‚àí max(h0 , j0 )1‚àíŒ≤
(1 + Œ∑)(1 ‚àí Œ≤)
b
= C3 + O(h‚àíŒ≥
(h‚àó ‚àí 1)1‚àíŒ≤ ‚â• 0 .
‚àó ) ‚àí Œ± ln(h‚àó ) +
(1 + Œ∑)(1 ‚àí Œ≤)

= ‚àíŒ± ln(h‚àó ) + O(h‚àíŒ≥
‚àó ) + C2 +

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n)‚à®maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S4

Technical results

We recall the generalized Kronecker lemma [S03, Corollary A.1]:
Lemma S4.1. (Generalized Kronecker Lemma)
Let {vN,n : 1 ‚â§ n ‚â§ N } and (zn )n be respectively a triangular array and a sequence of complex
numbers such that vN,n 6= 0 and
lim vN,n = 0,
N

and

P

n zn

lim vn,n exists finite,
n

is convergent. Then limN

N
X

|vN,n ‚àí vN,n‚àí1 | = O(1)

n=1

PN

n=1

vN,n zn = 0.

The above corollary is useful to get the following result for complex random variables, which
slightly extends the version provided in [S03, Lemma A.2]:

S 10

Lemma S4.2. Let H = (Hn )n be a filtration and (Yn )n a H-adapted sequence of complex
random

P
variables. Moreover, let (cn )n be a sequence of strictly positive real numbers such that n E |Yn |2 /c2n <
+‚àû and let {vN,n , 1 ‚â§ n ‚â§ N } be a triangular array of complex numbers such that vN,n 6= 0 and
lim vN,n = 0,
N

lim vn,n exists finite,
n

N
X

|vN,n ‚àí vN,n‚àí1 | = O(1) .

n=1

Suppose that
N
X

vN,n

n=1

E[Yn |Hn‚àí1 ] P
‚àí‚Üí V,
cn

where V is a suitable random variable. Then

PN

n=1

(S4.6)
P

vN,n Yn /cn ‚àí‚Üí V .

If the convergence in (S4.6) is almost sure, then also the convergence of
V is almost sure.

PN

n=1

vN,n Yn /cn toward

Proof. Consider the martingale (Mn )n defined by
Mn =
It is bounded in L2 since
that means

P

n

E[|Yn |2 ]
c2n

n
X
Yj ‚àí E[Yj |Hj‚àí1 ]
.
cj
j=1

< +‚àû by assumption and so it is almost surely convergent,

X Yn (œâ) ‚àí E[Yn |Hn‚àí1 ](œâ)
cn

n

< +‚àû

for œâ ‚àà B with P (B) = 1. Therefore, fixing œâ ‚àà B and setting zn = Yn (œâ)‚àíE[Ycnn |Hn‚àí1 ](œâ) , by Lemma
S4.1, we get
N
X
Yn (œâ) ‚àí E[Yn |Hn‚àí1 ](œâ)
vN,n
lim
= 0,
N
cn
n=1
that is

N
X
n=1

vN,n

Yn ‚àí E[Yn |Hn‚àí1 ] a.s.
‚àí‚Üí 0.
cn

In order to conclude, it is enough to observe that
N
X
n=1

vN,n

N
N
X
Yn
Yn ‚àí E[Yn |Hn‚àí1 ] X
E[Yn |Hn‚àí1 ]
=
vN,n
+
vN,n
cn
cn
cn
n=1
n=1

and use assumption (S4.6).
PN |v |
PN v
a.s.
Remark S4.3. If we have n=1 N,n
= O(1), limN n=1 N,n
cn
cn = Œª ‚àà C and E[Yn |Hn‚àí1 ] ‚àí‚Üí Y ,
then (S4.6) is satisfied with almost sure convergence and V = ŒªY . Indeed, if we denote by A an
event such that P (A) = 1 and limn E[Yn |Hn‚àí1 ](œâ) = Y (œâ) for each œâ ‚àà A, then we can fix œâ ‚àà A,
set wn = E[Yn |Hn‚àí1 ](œâ) and w = Y (œâ), and apply the generalized Toeplitz lemma [S03, Lemma
A.1] (with zN,n = vN,n /(cn Œª) and s = 1 when Œª 6= 0 and with zN,n = vN,n /cn and s = 0 when
PN
Œª = 0) in order to get n=1 vN,n wcnn ‚Üí ŒªY almost surely.
The proof of the following lemma can be found in [S08]. We here rewrite the proof only for the
reader‚Äôs convenience.

S 11

Lemma S4.4. ([S08], Lemma 18)
Let xn , Œ∂n , Œ≥n be non-negative sequences such that Œ≥n ‚Üí 0,

P

n

Œ≥n = +‚àû and

xn ‚â§ (1 ‚àí Œ≥n )xn‚àí1 + Œ≥n Œ∂n .
Then lim supn xn ‚â§ lim supn Œ∂n .
Proof. Take L > lim supn Œ∂n and n‚àó large enough so that Œ∂n < L and Œ≥n ‚â§ 1 when n ‚â• n‚àó . Then,
using that (x + y)+ ‚â§ x+ + y + , we have for n ‚â• n‚àó
+

(xn ‚àí L)+ ‚â§ ((1 ‚àí Œ≥n )(xn‚àí1 ‚àí L) + Œ≥n (Œ∂n ‚àí L))

‚â§ (1 ‚àí Œ≥n )(xn‚àí1 ‚àí L)+ + Œ≥n (Œ∂n ‚àí L)+
‚â§ (1 ‚àí Œ≥n )(xn‚àí1 ‚àí L)+ .
P
+
Since
= 0. This is enough to
n Œ≥n = +‚àû, the above inequality implies that limn (xn ‚àí L)
conclude, because we can choose L arbitrarily close to lim supn Œ∂n .

S5

Some stochastic approximation results

Consider a stochastic process (Œ∏n ) taking values in Œò = [‚àí1, 1]k , adapted to a filtration F = (Fn )n
and following the dynamics
Œ∏n+1 = (1 ‚àí n )Œ∏n + cn ‚àÜMn+1 ,

(S5.7)

where c > 0, (‚àÜMn+1 )n is a uniformly bounded martingale difference sequence with respect to F
P
fn+1 = c‚àÜMn+1 ,
and n = (n + 1)‚àí with  ‚àà (0, 1] so that n ‚Üí 0 and n n = +‚àû. Setting ‚àÜM
equation (S5.7) becomes
fn+1 .
Œ∏n+1 = (1 ‚àí n )Œ∏n + n ‚àÜM
Then:
a.s.

Theorem S5.1. In the above setting, we have Œ∏N ‚àí‚Üí 0 .
Proof. We have the following two cases:
P
‚Ä¢  ‚àà (1/2, 1] so that n 2n < +‚àû or
P
‚Ä¢  ‚àà (0, 1/2] so that n 2n = +‚àû.
For the first case, we refer to [S11, Cap. 5, Th. 2.1]. For the second case, we refer to [S11, Cap. 5,
fn ) are uniformly bounded, the key assumption to be
Th. 3.1]). In this case, since (Œ∏n ) and (‚àÜM
verified in order to apply [S11, Cap. 5, Th. 3.1] is the ‚Äúrate of change‚Äù condition (see [S11, p. 137]),
that is
lim sup sup |M 0 (N + t) ‚àí M 0 (N )| = 0,
a.s.
N

t‚àà[0,1]

Pm(t)‚àí1

fj+1 and m(t) = inf{n : t < tn+1 = Pn j } (see [S11, p. 122]).
where M 0 (t) = j=0 j ‚àÜM
j=0
fn ) is uniformly bounded, the above condition is satisfied when the following simpler
Since (‚àÜM
conditions are satisfied (see [S11, pp. 139-141]):
P
(i) For each u > 0 n e‚àíu/n < +‚àû;
(ii) For some T < +‚àû, there exists a constant c(T ) < +‚àû such that supn‚â§j‚â§m(tn +T )

j
n

‚â§ c(T ).
‚àí

When n = (1 + n)‚àí , condition (i) is obviously verified, because we have limn n2 /eu(1+n) = 0.
Finally, condition (ii) is always satisfied when n is decreasing, as it is in the case n = (1 + n)‚àí .
Indeed, we simply have supn‚â§j‚â§m(tn +T ) j /n = n /n = 1.

S 12

a.s.

Theorem S5.2. In the above setting, if we have E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì with Œì a symmetric positive definite matrix, then we have
1
d
‚àö Œ∏N ‚àí‚Üí N (0, Œ£),
N
where Œ£ = c2 Œì/2 when  ‚àà (0, 1) and Œ£ = c2 Œì when  = 1.
a.s.

Proof. We have Œ∏N ‚àí‚Üí 0 and 0 belongs to the interior part of Œò. Moreover, we have
>

a.s. 2
fn+1 ‚àÜM
fn+1 |Fn ] ‚àí‚Üí
E[‚àÜM
c Œì.

For the case  ‚àà (1/2, 1], we refer to [S09, Th. 2.1] (with h = Id, U‚àó = c2 Œì and Œ≥‚àó = 1) and [S14,
Th. 1] (with H = ‚àíId, Œ≥n = œÉn = n and so Œ≥0 = 1 and Œ≤ = ). For the case  ‚àà (0, 1/2], we
refer to [S11, cap.10, Th. 2.1] (with A = ‚àíId). The key assumption for applying this theorem is
‚àö
Œ∏n / n tight. On the other hand, in the considered setting, this last condition is satisfied because
of [S11, Th. 4.1]. Note that the limit distribution corresponds to the stationary distribution of the
diffusion
dUt = (‚àíId + c()) Ut dt + cŒì1/2 dWt ,
where W = (Wt )t is a standard Wiener process and
(
0 for  < 1
c() =
1/2 for  = 1.
Therefore the limit covariance matrix is determined by solving the associated Lyapunov‚Äôs equation
[S14], that, in the considered case, simply is
2 (‚àíId + c()Id) Œ£ = ‚àíc2 Œì.

Theorem S5.3. In the above setting, let (¬µn ) be another stochastic process taking values in Œò =
[‚àí1, 1]k , adapted to a filtration F and following the dynamics
1
1
¬µn+1 ‚àí ¬µn = ‚àí (¬µn ‚àí Œ∏n ) + ‚àÜMn+1 .
n
n
a.s.

Suppose that E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì. If  ‚àà (1/2, 1), then we have
!
‚àö
 

(c + 1)2 Œì
0
N ¬µN
d
2
‚àí‚Üí
N
0,
.
‚àí1/2
c
0
N Œ∏ N
2 Œì
If  = 1, then we have
‚àö

N ¬µN
‚àí1/2
N Œ∏ N

!
d

‚àí‚Üí N




0,

[(c + 1)2 + c2 ]Œì
c(c + 1)Œì

c(c + 1)Œì
c2 Œì


.

Proof. The dynamics for the pair (¬µn , Œ∏n )n is
(
¬µn+1 ‚àí ¬µn = ‚àí n1 (¬µn ‚àí Œ∏n ) + n1 ‚àÜMn+1
fn+1 .
Œ∏n+1 ‚àí Œ∏n = ‚àín Œ∏n + cn ‚àÜMn+1 = ‚àín Œ∏n + n ‚àÜM
a.s.

with E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì. Therefore, when 1/2 <  < 1, the statement follows from
[S13] (with Q11 = Q22 = ‚àíId, Q12 = Id, Q21 = 0, b = Œ≤0 = 1, a = , Œì11 = Œì, Œì22 = c2 Œì and

S 13

Œì12 = Œì21 = cŒì). In particular, the two blocks of the limit covariance matrix, say Œ£¬µ and Œ£Œ∏ , are
determined solving the equations
1
1
(H + Id)Œ£¬µ + Œ£¬µ (H > + Id) = ‚àíŒì¬µ ,
2
2
‚àí1
‚àí1 > >
‚àí1 > >
where H = Q11 ‚àí Q12 Q‚àí1
22 Q21 = ‚àíId + 0 and Œì¬µ = Œì11 + Q12 Q22 Œì22 (Q22 ) Q12 ‚àí Œì12 (Q22 ) Q12 ‚àí
‚àí1
2
2
Q12 Q22 Œì21 = Œì + c Œì + cŒì + cŒì = (c + 1) Œì, and

Q22 Œ£Œ∏ + Œ£Œ∏ Q>
22 = ‚àíŒì22 .
When  = 1, we can conclude by [S14] or [S19] taking Xn = (¬µn , Œ∏n )> . Indeed, in this case
the covariance matrix is given by
1
1
e
(H + Id)Œ£ + Œ£(H > + Id) = ‚àíŒì,
2
2
where


H=

‚àíId
0

Id
‚àíId




e=
and Œì

Œì
cŒì


cŒì
.
c2 Œì

Therefore, if we split Œ£ in blocks, say Œ£¬µ , Œ£Œ∏ and Œ£¬µŒ∏ , we find the system
‚àíŒ£¬µ + 2Œ£¬µŒ∏ = ‚àíŒì
‚àíŒ£¬µŒ∏ + Œ£Œ∏ = ‚àícŒì
‚àíŒ£Œ∏ = ‚àíc2 Œì
and so the proof is concluded by solving this system.

S6

Stable convergence

This brief section contains some basic definitions and results concerning stable convergence. For
more details, we refer the reader to [S05, S07, S10] and the references therein.
Let (‚Ñ¶, A, P ) be a probability space, and let S be a Polish space, endowed with its Borel œÉ-field.
A kernel on S, or a random probability measure on S, is a collection K = {K(œâ) : œâ ‚àà ‚Ñ¶} of
probability measures on the Borel œÉ-field of S such that, for each bounded Borel real function f
on S, the map
Z
œâ 7‚Üí Kf (œâ) =

f (x) K(œâ)(dx)

is A-measurable. Given a sub-œÉ-field H of A, a kernel K is said H-measurable if all the above
random variables Kf are H-measurable. A probability measure ŒΩ can be identified with a constant
kernel K(œâ) = ŒΩ for each œâ.
On (‚Ñ¶, A, P ), let (Yn )n be a sequence of S-valued random variables, let H be a sub-œÉ-field of
A, and let K be a H-measurable kernel on S. Then, we say that Yn converges H-stably to K, and
we write Yn ‚àí‚Üí K H-stably, if
weakly

P (Yn ‚àà ¬∑ | H) ‚àí‚Üí E [K(¬∑) | H]

for all H ‚àà H with P (H) > 0,

where K(¬∑) denotes the random variable defined, for each Borel set B of S, as œâ 7‚Üí KIB (œâ) =
K(œâ)(B). In the case when H = A, we simply say that Yn converges stably to K and we write
Yn ‚àí‚Üí K stably. Clearly, if Yn ‚àí‚Üí K H-stably, then Yn converges in distribution to the probability

S 14

distribution E[K(¬∑)]. The H-stable convergence of Yn to K can be stated in terms of the following
convergence of conditional expectations:
E[f (Yn ) | H]

œÉ(L1 , L‚àû )

‚àí‚Üí

Kf

(S6.8)

for each bounded continuous real function f on S. In [S07] the notion of H-stable convergence
is firstly generalized in a natural way replacing in (S6.8) the single sub-œÉ-field H by a collection
G = (Gn ) (called conditioning system) of sub-œÉ-fields of A and then it is strengthened by substituting
the convergence in œÉ(L1 , L‚àû ) by the one in probability (i.e. in L1 , since f is bounded). Hence,
according to [S07], we say that Yn converges to K stably in the strong sense, with respect to
G = (Gn ), if
P
E [f (Yn ) | Gn ] ‚àí‚Üí Kf
for each bounded continuous real function f on S.
We now conclude this section recalling some convergence results that we apply in our proofs.
From [S10, Th. 3.2] (see also [S07, Th. 5 and Cor. 7] or [S05, Th. 5.5.1 and Cor. 5.5.2]), we get:
Theorem S6.1. Given a filtration F = (Fn )n , let (YN,n )N,n be a triangular array of random
variables with values in Rk such that YN,n is Fn -measurable and E[YN,n |Fn‚àí1 ] = 0. Suppose that
the following two conditions are satisfied:
(c1) E [ max1‚â§n‚â§N |YN,n | ] ‚Üí 0 and
PN
> P
(c2)
n=1 YN,n YN,n ‚àí‚Üí V , where V is a random variable with values in the space of positive
semidefinite k √ó k-matrices.
PN
Then n=1 YN,n converges stably to the Gaussian kernel N (0, V ).
From [S07, Th. 5, Cor. 7, Rem. 4] or [S05, Th. 5.5.1, Cor. 5.5.2, Rem. 5.5.2]), we obtain:
Theorem S6.2. Let (Ln ) be a Rk -valued martingale with respect to the filtration F = (Fn ).
a.s., L1

Suppose that Ln ‚àí‚Üí L for some Rk -valued random variable L and
(c1) ne E[supj‚â•n |Lj‚àí1 ‚àí Lj | ] ‚àí‚Üí 0 and
P
P
(c2) n2e j‚â•n (Lj‚àí1 ‚àí Lj )(Lj‚àí1 ‚àí Lj )> ‚àí‚Üí V , where V is a random variable with values in the
space of positive semidefinite k √ó k-matrices.
Then

ne Ln ‚àí L ‚àí‚Üí N (0, V )

stably in strong sense w.r.t. F.

Indeed,P
following [S07, Example 6], it is enough to observe that Ln ‚àí L can be written as
Ln ‚àí L = j‚â•n (Lj ‚àí Lj+1 ).
Finally, the following result combines together a stable convergence and a stable convergence in
the strong sense [S04, Lemma 1].
Theorem S6.3. Suppose that Cn and Dn are S-valued random variables, that M and N are kernels
on S, and that G = (Gn )n is an (increasing) filtration satisfying for all n
S
œÉ(Cn )‚äÇGn and œÉ(Dn )‚äÇœÉ ( n Gn ) .
If Cn stably converges to M and Dn converges to N stably in the strong sense, with respect to G,
then
[Cn , Dn ] ‚àí‚Üí M ‚äó N
stably.
(Here, M ‚äó N is the kernel on S √ó S such that (M ‚äó N )(œâ) = M (œâ) ‚äó N (œâ) for all œâ.)

S 15

This last result contains as a special case the fact that stable convergence and convergence in
probability combine well: that is, if Cn stably converges to M and Dn converges in probability to a
random variable D, then (Cn , Dn ) stably converges to M ‚äó Œ¥D , where Œ¥D denotes the Dirac kernel
concentrated in D.

References
[S01] Generalized rescaled PoÃÅlya urn and its statistical applications. Main Article of this supplementary material (2020)
[S02] Aletti, G., Crimaldi, I.: The rescaled PoÃÅlya urn: local reinforcement and chi-squared goodness
of fit test. arXiv:1906.10951 (2019)
[S03] Aletti, G., Crimaldi, I., Ghiglietti, A.: Networks of reinforced stochastic processes: asymptotics for the empirical means. Bernoulli 25(4B), 3339‚Äì3378 (2019)
[S04] Berti, P., Crimaldi, I., Pratelli, L., Rigo, P.: A central limit theorem and its applications to
multicolor randomly reinforced urns. J. Appl. Probab. 48(2), 527‚Äì546 (2011). DOI 10.1239/
jap/1308662642. URL https://doi.org/10.1239/jap/1308662642
[S05] Crimaldi, I.: Introduzione alla nozione di convergenza stabile e sue varianti (Introduction
to the notion of stable convergence and its variants), vol. 57. Unione Matematica Italiana,
Monograf s.r.l., Bologna, Italy. (2016). Book written in Italian
[S06] Crimaldi, I., Dai Pra, P., Minelli, I.G.: Fluctuation theorems for synchronization of interacting PoÃÅlya‚Äôs urns. Stochastic Process. Appl. 126(3), 930‚Äì947 (2016). DOI 10.1016/j.spa.2015.
10.005. URL https://doi.org/10.1016/j.spa.2015.10.005
[S07] Crimaldi, I., Letta, G., Pratelli, L.: A Strong Form of Stable Convergence, vol. 1899, pp.
203‚Äì225. Springer (2007)
[S08] Delyon, B.: Stochastic approximation with decreasing gain: Convergence and asymptotic
theory. Technical report (2000)
[S09] Fort, G.: Central limit theorems for stochastic approximation with controlled markov chain
dynamics. ESAIM: PS 19, 60‚Äì80 (2015). DOI 10.1051/ps/2014013. URL https://doi.org/
10.1051/ps/2014013
[S10] Hall, P., Heyde, C.C.: Martingale limit theory and its application. Academic Press Inc.
[Harcourt Brace Jovanovich Publishers], New York (1980). Probability and Mathematical
Statistics
[S11] Kushner, H.J., Yin, G.G.: Stochastic approximation and recursive algorithms and applications, Applications of Mathematics (New York), vol. 35, second edn. Springer-Verlag, New
York (2003). Stochastic Modelling and Applied Probability
[S12] MeÃÅtivier, M.: Semimartingales. Walter de Gruyter and Co., Berlin (1982)
[S13] Mokkadem, A., Pelletier, M.: Convergence rate and averaging of nonlinear two-time-scale
stochastic approximation algorithms. Ann. Appl. Probab. 16(3), 1671‚Äì1702 (2006). DOI
10.1214/105051606000000448. URL https://doi.org/10.1214/105051606000000448
[S14] Pelletier, M.: Weak convergence rates for stochastic approximation with application to multiple targets an simulated annealing. Ann. Appl. Probab. 8(1), 10‚Äì44 (1998)
[S15] Pemantle, R.: A time-dependent version of poÃÅlya‚Äôs urn. J. Theor. Probab. 3, 627‚Äì637 (1990)
[S16] Rao, J.N.K., Scott, A.J.: The analysis of categorical data from complex sample surveys:
chi-squared tests for goodness of fit and independence in two-way tables. J. Amer. Statist.
Assoc. 76(374), 221‚Äì230 (1981)

S 16

[S17] Robbins, H., Siegmund, D.: A convergence theorem for non negative almost supermartingales
and some applications. In: Optimizing Methods in Statistics, pp. 233‚Äì257. Academic Press
(1971)
[S18] Sherman, J., Morrison, W.J.: Adjustment of an inverse matrix corresponding to a change
in one element of a given matrix. Ann. Math. Statist. 21(1), 124‚Äì127 (1950). DOI 10.1214/
aoms/1177729893. URL https://doi.org/10.1214/aoms/1177729893
[S19] Zhang, L.X.: Central limit theorems of a recursive stochastic algorithm with applications to
adaptive designs. Ann. Appl. Probab. 26(6), 3630‚Äì3658 (2016)

S 17

