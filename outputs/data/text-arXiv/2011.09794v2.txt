Positively Correlated Samples Save Pooled Testing
Costs

arXiv:2011.09794v2 [stat.ME] 17 Apr 2021

Yi-Jheng Lin, Che-Hao Yu, Tzu-Hsuan Liu, Cheng-Shang Chang, Fellow, IEEE,
and Wen-Tsuen Chen, Life Fellow, IEEE
Abstract—The group testing approach that achieves significant
cost reduction over the individual testing approach has received
a lot of interest lately for massive testing of COVID-19. Many
studies simply assume samples mixed in a group are independent.
However, this assumption may not be reasonable for a contagious
disease like COVID-19. Specifically, people within a family tend
to infect each other and thus are likely to be positively correlated.
By exploiting positive correlation, we make the following two
main contributions. One is to provide a rigorous proof that
further cost reduction can be achieved by using the Dorfman
two-stage method when samples within a group are positively
correlated. The other is to propose a hierarchical agglomerative
algorithm for pooled testing with a social graph, where an edge
in the social graph connects frequent social contacts between
two persons. Such an algorithm leads to notable cost reduction
(roughly 20%-35%) compared to random pooling when the
Dorfman two-stage algorithm is applied.

Keywords: COVID-19, group testing, regenerative processes, Markov modulated processes, social networks.
I. I NTRODUCTION
Massive testing is one of the most effective measures to
detect and isolate asymptomatic COVID-19 infections so as
to reduce the transmission rate of COVID-19 [1]. However,
massive testing for a large population is very costly if it is
done one at a time. The recent article posted on the US FDA
website [2] indicates that the group testing approach (or pool
testing, pooled testing, batch testing) has received a lot of
interest lately. Such an approach (testing a group of mixed
samples) can greatly save testing resources for a population
with a low prevalence rate [3]–[6]. Moreover, the following
testing procedure is suggested in the US CDC’s guidance for
the use of pooling procedures in SARS-CoV-2 [7]:
“If a pooled test result is negative, then all specimens can
be presumed negative with the single test. If the test result is
positive or indeterminate, then all the specimens in the pool
need to be retested individually.”
A simple testing procedure that implements the above
guidance is known as Dorfman’s two-stage group testing
method [8]. The method first partitions the population into
groups of M samples. If the test of a group of M samples is
negative, then all the M samples in that group are declared to
be negative. Otherwise, each sample in that group is retested
individually. Such a method has been implemented by many
countries for massive testing of COVID-19 [9].
The authors are with the Institute of Communications Engineering, National Tsing Hua University, Hsinchu 30013, Taiwan R.O.C.
Email: s107064901@m107.nthu.edu.tw; chehaoyu@gapp.nthu.edu.tw; carina000314@gmail.com; cschang@ee.nthu.edu.tw; wtchen@cs.nthu.edu.tw.

To measure the amount of saving of a group testing method,
Dorfman used the expected relative cost (that is defined as
the ratio of the expected number of tests required by the
group testing method to the number of tests required by the
individual testing). The expected relative cost for independent
and identically distributed (i.i.d.) samples was derived in
[8]. Suppose that the prevalence rate (the probability that a
randomly selected sample is positive) is r1 . Note that if the
test result of a group is positive, all the samples in that group
need to be retested individually. For a group of M samples,
the group is tested positive with the probability 1 − (r0 )M ,
where r0 = 1 − r1 . So the expected number of tests for the
group is 1 + M · (1 − (r0 )M ) = (M + 1) − M (r0 )M . Thus,
the expected relative cost for i.i.d. samples with group size
M is
M +1
− (r0 )M .
(1)
M
One can then use (1) to optimize the group size M according
to the prevalence rate [8].
There are more sophisticated group testing methods for
implementing the CDC’s guidance for testing COVID-19 (see
e.g., [10]–[15]). These methods require diluting a sample and
then pooling the diluted samples into multiple groups (pooled
samples). Such methods are specified by two components:
(i) a pooling matrix that directs each diluted sample to be
pooled into a specific group, and (ii) a decoding algorithm
that uses the test results of pooled samples to reconstruct
the status (i.e., a positive or negative result) of each sample.
As shown in the recent comparative study [15], the expected
relative costs of such methods depend heavily on the pooling
matrix, and one has to select an appropriate pooling matrix
according to the prevalence rate. For i.i.d. samples, using
such sophisticated methods result in significant gains over the
simple Dorfman two-stage group testing method, in particular
when the prevalence rate is low (below 5%).
In practice, samples are not i.i.d. For a contagious disease
like COVID-19, people in the same family (or social bubble)
are likely to infect each other. Lendle et al. [16] studied the
efficiency (i.e., the expected relative costs) for group testing
methods when samples within a group are positively correlated exchangeable random variables. They derived closedform expressions of efficiency for hierarchical- and matrixbased group testing methods under certain assumptions, and
examined three models of exchangeable binary random variables. They concluded that positive correlations between
samples within a group could improve efficiency. Moreover,

expected number of tests is
1+(1−P(X(t+1) = 0, X(t+2) = 0, . . . , X(t+M ) = 0))M.
Fig. 1: An illustration of an arrival process in a testing site,
where Ti is the group size of the ith arriving groups, Z(t)
is the group type of the tth sample, and M samples of
contiguous positions are pooled together for Dorfman’s twostage group testing.

in the recent WHO research article [17], it was shown by
computer simulations that pooled samples from homogeneous
groups of similar people could lead to cost reduction for the
Dorfman two-stage method. The main objective of this paper
is to provide insight and proof for that observation through a
mathematical model.
Let us consider a testing site where people form a line (or
queue) to be tested. It is reasonable to assume that people
arriving in groups of various sizes are in contiguous positions
of the line. Since the disease prevalence rate in two arriving
groups may differ, we say that two groups are of the same type
if they have the same prevalence rate. People in M contiguous
positions are pooled together and tested by using Dorfman’s
two-stage group testing method. For our analysis, we make
the following three mathematical assumptions:
(A1) i.i.d. group sizes: The sizes of arriving groups of
people are i.i.d. with a finite mean.
(A2) i.i.d. group types: There are K types of arriving
groups. The types of arriving groups of people are
i.i.d. With probability πk , a group of arriving people
is of type k, k = 1, 2, . . . , K.
(A3) Homogeneous samples within the same group: Samples obtained from people within the same group
are i.i.d. Bernoulli random variables with the same
prevalence rate. With probability r0,k (resp. r1,k =
1 − r0,k ), a sample in a type k group is negative
(resp. positive).
An illustration of an arrival process in a testing site is
provided in Figure 1. In this figure, the number of people
in the first group T1 is 4, the number of people in the second
group T2 is 7, the number of people in the third group T3
is 6, and the number of people in the forth group T4 is 5.
Eight samples of contiguous positions are pooled together for
Dorfman’s two-stage group testing, i.e., M = 8.
Denote by X(t) the indicator random variable of the tth
sample in the line of the testing site. We say the tth sample
is negative (resp. positive) if X(t) = 0 (resp. X(t) = 1).
Consider using the Dorfman two-stage method for testing the
M consecutive samples X(t + 1), X(t + 2), . . . , X(t + M )
for some fixed t ≥ 0. With probability
1 − P(X(t + 1) = 0, X(t + 2) = 0, . . . , X(t + M ) = 0),
the test result for the group of M consecutive samples is
positive and they need to be tested individually. Thus, the

As such, the expected relative cost for these M samples by
the Dorfman two-stage method is
M +1
− P(X(t + 1) = 0, X(t + 2) = 0, . . . , X(t + M ) = 0).
M
(2)
We state the first main result of this paper in the following
theorem.
Theorem 1: Suppose that the arriving process {X(t), t ≥ 1}
satisfying (A1)-(A3). The expected relative cost for pooling
any M consecutive samples into a group is not higher than that
for pooling M samples at random, i.e., the expected relative
cost in (2) is not higher than (1) with
r0 =

K
X

πk r0,k .

(3)

k=1

Our second main result is the monotonicity of the expected
relative cost under a stronger assumption than (A1).
(A1+ ) The group sizes are independent and geometrically
distributed with parameter 1−ω for some 0 ≤ ω ≤ 1.
Theorem 2: Suppose that the arriving process {X(t), t ≥ 1}
satisfying (A1+ ), (A2), and (A3). Then the expected relative
cost in (2) is decreasing in ω.
Note that when ω = 0, {X(t), t ≥ 1} is reduced to the
sequence of i.i.d. samples with the prevalence rate r1 . As such,
the monotonicity result in Theorem 2 is a stronger result than
that in Theorem 1.
Our third main result is a closed-form expression for the
expected relative cost under (A1+ ), (A2), and (A3).
Theorem 3: Under (A1+ ), (A2), and (A3), the expected
relative cost is
M +1
− πR(PR)M −1 1,
(4)
M
where P = (pi,j ) is the K × K matrix with

ω + (1 − ω)πi if j = i
pi,j =
,
(5)
(1 − ω)πj
if j 6= i
R is the diagonal matrix with the k th diagonal element being
r0,k , 1 is the K × 1 (column) vector with all its elements
being 1, and π is the 1 × K (row) vector with its k th element
being πk .
We can further derive the lower bound of the expected
relative cost in (4).
Theorem 4: Under (A1+ ), (A2), and (A3), the expected
relative cost is lower bounded by
M +1
− r0 (ω + (1 − ω)r0 )M −1 .
(6)
M
Using the closed-form expression in Theorem 3, we compare the expected relative cost of the simple Dorfman twostage method with the lowest expected relative cost of the
(d1 , d2 )-regular pooling matrix [15]. With a moderate positive correlation, our numerical results demonstrate that the

gain by such a simple method outperforms those by using
sophisticated strategies with (d1 , d2 )-regular pooling matrices
when the prevalence rate is higher than 5%.
The results for samples in a line of a testing site only
exploits the positive correlations between two contiguous
samples in a line graph. One important extension is to consider
pooled testing with a social graph, where frequent social
contacts between two persons are connected by an edge in
the social graph. Contagious diseases such as COVID-19 can
propagate the disease from an infected person to another
person through the social contacts between two persons,
two persons connected by an edge are likely to infect each
other, and they are likely to be positively correlated. To
exploit the positive correlation in a social graph, we adopt
the probabilistic framework of sampled graphs for structural
analysis in [18]–[20]. In particular, we propose a hierarchical
agglomerative algorithm for pooled testing with a social graph
(see Algorithm 1). Our numerical results show that such an
algorithm leads to significant cost reduction (roughly 20%35%) compared to random pooling when the Dorfman twostage algorithm is used.
The paper is organized as follows: in Section II-A, we prove
Theorem 1 and Theorem 2 by using the renewal property
of regenerative processes. We then prove Theorem 3 and
Theorem 4 in Section II-B by using the Markov property of
Markov modulated processes. In Section III, we extend the
dependency of samples from a line graph to a general graph.
There we propose a hierarchical agglomerative algorithm to
exploit the positive correlation of samples. The numerical
results are shown in Section IV. The paper is concluded in
Section V, where we discuss possible extensions for future
works.
II. M ATHEMATICAL A NALYSES AND P ROOFS
A. Regenerative processes
In this section, we prove the main result in Theorem 1
and Theorem 2 by using the renewal property of regenerative
processes (see, e.g., Section 6.3 of the book [21]).
Let {Ti ,P
i ≥ 1} be the number of samples in the ith group,
i
and τi = `=1 T` be the cumulative number of samples in
the first i groups. Since we assume that {Ti , i ≥ 1} are i.i.d.
in (A1), {τi + 1, i ≥ 1} is a renewal process. From (A2)
and (A3), {X(t), t ≥ 1} is a regenerative process with the
regenerative points {τi + 1, i ≥ 1}, i.e., {X(τi + t), t ≥ 1}
has the same joint distribution as {X(t), t ≥ 1}.
In the following lemma, we derive the prevalence rate.
Lemma 5: The prevalence rate of a randomly selected
sample for the arrival process satisfying (A1)-(A3) is
r1 =

K
X

πk (1 − r0,k ).

(7)

k=1

PK
Thus, r0 = 1 − r1 = k=1 πk r0,k .
Proof. Let Z(t) be the group type of the tth sample. In view
of (A2), we have
P(Z(t) = k) = πk ,

(8)

Also, from (A3),
P(X(t) = 1|Z(t) = k) = (1 − r0,k ).

(9)

From the law of total probability, it follows that

P(X(t) = 1)

=

=

K
X
k=1
K
X

P(X(t) = 1|Z(t) = k)P(Z(t) = k)
πk (1 − r0,k ).

(10)

k=1

As (10) holds for any arbitrary t, the prevalence rate of a
randomly selected sample is the same as (10).

Now we prove Theorem 1.
Proof. (Theorem 1) In view of (2), it suffices to show that
for any t ≥ 0,
P(X(t + 1) = 0, X(t + 2) = 0, . . . , X(t + M ) = 0) ≥ (r0 )M .
(11)
For this, we first show that (11) holds for t = 0 by induction
on M . Since P(X(1) = 0) = r0 from Lemma 5, the inequality
in (11) holds trivially for M = 1. Assume that the inequality
in (11) holds for t = 0 and all m ≤ M − 1 as the induction
hypothesis. From the law of total probability, we have

=

=
+

P(X(1) = 0, . . . , X(M ) = 0)
∞
X
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s)
s=1
M
−1
X
s=1
∞
X

P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s)
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s).

s=M

(12)
Conditioning on the event {T1 = s} for s ≥ M , the number
of samples in the first group is not smaller than M . Thus, for
s ≥ M , we have from (A2) and (A3) that
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)
K
X
=
πk (r0,k )M
k=1
K
X

≥(

πk r0,k )M = r0M ,

(13)

k=1

where the last inequality follows from Jensen’s inequality for
the convex function xM . For T1 = s ≤ M − 1, we know that

the second group starts from s + 1. It then follows from the
renewal property in (A1) that
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)
= P(X(1) = 0, . . . , X(s) = 0|T1 = s)
P(X(s + 1) = 0, . . . , X(M ) = 0|T1 = s)
K
X

=
πk (r0,k )s P(X(1) = 0, . . . , X(M − s) = 0)
k=1

≥
≥

K
X

πk r0,k

s

k=1
(r0 )s (r0 )M −s

P(X(1) = 0, . . . , X(M − s) = 0)
M

= (r0 )

(14)

where the second last inequality follows from Jensen’s inequality for the convex function xs , and the last inequality
follows from the induction hypothesis. Using (13) and (14) in
(12) completes the induction for t = 0 in (11).
Now we show that (11) hold for any arbitrary t. For a fixed
t, let T̃1 (t) be the residual life from t to the next regenerative
point, i.e., the number of remaining samples in the same group
of the tth sample. The argument for any arbitrary t then
follows from the same inductive proof for t = 0 by replacing
T1 with T̃1 (t).

P(X(t + 1) = 0, X(t + 2) = 0, . . . , X(t + M ) = 0)
(15)

By replacing r0,k by 1 − r0,k in the proof of Theorem 1, one
can also show that
P(X(t + 1) = 1, X(t + 2) = 1, . . . , X(t + M ) = 1)
≥ (r1 )M = (P(X(1) = 1))M .

(16)

Letting M = 2 in (16) yields the following corollary.
Corollary 6: Suppose that the arriving process {X(t), t ≥
1} satisfying (A1)-(A3). Then X(t + 1) and X(t + 2) are
positively correlated, i.e.,
E[X(t + 1)X(t + 2)] − E[X(t + 1)]E[X(t + 2)] ≥ 0, (17)
where E[X] denotes the expectation operator of the random
variable X.
There are two key properties used in the proof of Theorem
1: the regenerative property and Jensen’s inequality (for convex functions). To prove Theorem 2, we need the following
generalization of Jensen’s inequality.
Lemma 7: For any positive integers t1 , t2 , . . . , tL ,
L X
K
Y
`=1

k=1

K
 X
PL
πk (r0,k )t` ≤
πk (r0,k ) `=1 t` .

r0,k ≥ 0 for all k, Y is nonnegative.
Then the right-hand-side
PL
t`
of (18) can be written as E[Y `=1
].
QL Similarly, the left-handside of (18) can be written as `=1 E[Y t` ]. Thus, it suffices
to show that
L 
Y


PL
E[Y t` ] ≤ E[Y `=1 t` ].

(19)

`=1

We show (19) by induction on L. For L = 2, we consider two
independent random variables Y1 and Y2 that have the same
distribution as Y . Since Y1 and Y2 are nonnegative, for any
two positive integers t1 and t2 ,
(Y1t1 − Y2t1 )(Y1t2 − Y2t2 ) ≥ 0.

(20)

To see this, note that if Y1 ≥ Y2 , then Y1t1 ≥ Y2t1 and Y1t2 ≥
Y2t2 . Taking expectations on both side of (20) yields

In the proof of Theorem 1, we show that
≥ (r0 )M = (P(X(1) = 0))M .

Fig. 2: An illustration of coupling two sequences of group
(1)
(2)
sizes {Ti , i ≥ 1} and {Ti , i ≥ 1}.

(18)

k=1

Note that for t1 = t2 = · · · = tL = 1, the inequality in
(18) reduces to Jensen’s inequality for the convex function xL
used in the proof of Theorem 1.
Proof. Consider a random variable Y with the probability
mass function P(Y = r0,k ) = πk , k = 1, 2, . . . , K. Since

E[(Y1t1 − Y2t1 )(Y1t2 − Y2t2 )]
= E[Y1t1 +t2 ] − E[Y2t1 Y1t2 ] − E[Y2t2 Y1t1 ] + E[Y2t1 +t2 ]
≥0

(21)

Since Y1 and Y2 are independent and have the same distribution as Y , we have from (21) that
E[Y t1 ]E[Y t2 ] ≤ E[Y t1 +t2 ].

(22)

Now assume that (19) hold for L − 1 as the induction
hypothesis. From (22) and the induction hypothesis, it follows
that
E[Y

PL

`=1 t`

]

PL−1

≥ E[Y `=1 t` ]E[Y tL ]
L 

Y
≥
E[Y t` ] .

(23)

`=1

Now we prove Theorem 2.
Proof. (Theorem 2) To show that the expected relative cost
in (2) is decreasing in ω, it is equivalent to showing that
P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0) is increasing
in ω. Consider two arrival processes {X (1) (t), t ≥ 1} and
{X (2) (t), t ≥ 1} that are generated by using the parameters
ω1 and ω2 in (A1+ ), respectively. Assume that ω2 ≥ ω1 . Let
(1)
(2)
Ti (resp. Ti ) be the group size of the ith group in the

first (resp. second) arrival process. Note from (A1+ ) that for
all i ≥ 1 and n ≥ 1,
(1)
P (Ti
(2)
P (Ti

= n)

=

= n)

=

ω1n−1 (1
ω2n−1 (1

− ω1 ),
− ω2 ).

The trick of the proof is to couple the two sequences of
(1)
(2)
group sizes {Ti , i ≥ 1} and {Ti , i ≥ 1} so that the
(2)
regenerative points of {X (t), t ≥ 1} is a subset of the
regenerative points of {X (1) (t), t ≥ 1}. Such a coupling is
feasible because the random splitting of a renewal process
with geometrically distributed interarrival times is also a
renewal process with geometrically distributed interarrival
times. In particular, the size of the first group for the second
(2)
arrival process, i.e., T1 , is a sum of the sizes of several
groups for the first arrival process, i.e.,
(2)

T1

=

L
X

(1)

T` ,

`=1

P(X (2) (1) = 0, . . . , X (2) (M ) = 0)
∞
X
(2)
P(X (2) (1) = 0, . . . , X (2) (M ) = 0|T1 = s)
=
s=1
(2)

In this section, we prove Theorem 3 and Theorem 4 by
using the Markov property of Markov modulated processes
(see, e.g., Chapter 8 and Chapter 9 of the book [21]).
Recall that Z(t) is the group type of the tth sample. In view
of the memoryless property of the geometrical distribution, we
know that with probability ω, the (t + 1)th sample is still in
the same group of the tth sample. With probability 1 − ω, it
is in another group. Under (A1+ ) and (A2), the sequence of
group types {Z(t), t = 1, 2, . . .} is a Markov chain with K
states. Denote by pi,j the transition probability from state i
to state j for the (hidden) Markov chain. For such a Markov
chain, we then have
pi,j

(24)

for some L ≥ 1. An illustration of coupling two sequences
(1)
(2)
of group sizes {Ti , i ≥ 1} and {Ti , i ≥ 1} is shown in
Figure 2.
Following the regenerative analysis in the proof of Theorem
(2)
1, we condition on the event {T1 = s} and use the law of
the total probability to derive that

P(T1

B. Markov modulated processes

= s).

(25)
(2)

P(X (2) (1) = 0, . . . , X (2) (M ) = 0|T1
K
X
=
πk (r0,k )M .

It is easy to see that the correlation coefficient of Z(t + 1)
and Z(t) is simply ω, i.e.,
ω=

E[Z(t + 1)Z(t)] − E[Z(t + 1)]E[Z(t)]
.
Var(Z(t + 1))Var(Z(t))

(31)

From (A3), we also know that {X(t), t ≥ 1} is a Markov
modulated process that is modualted by the (hidden) Markov
chain {Z(t), t ≥ 1}. The conditional probability that X(t) is
negative given the (hidden) Markov chain is in the state k is
r0,k , i.e.,
r0,k = P(X(t) = 0|Z(t) = k).
(32)

= s)
(26)

P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0)
K
X
=
P(X(1) = 0, . . . , X(M ) = 0|Z(1) = k)
k=1

k=1

P(Z(1) = k).

From the coupling of these two arrival processes,
(2)

P(X (1) (1) = 0, . . . , X (1) (M ) = 0|T1

= P(X (1) (1) = 0, . . . , X (1) (M ) = 0|

(1)

T`

L X
K
hY

(1)

πk (r0,k )T`


.

= s)

(2)

Using (34) in (33) yields

= s)
(2)

≥ P(X (1) (1) = 0, . . . , X (1) (M ) = 0|T1

= s).(28)

The case for s < M is similar, and we have from (25) that
P(X (2) (1) = 0, . . . , X (2) (M ) = 0)
≥ P(X

(1) = 0, . . . , X

(1)

(M ) = 0).

P(X(1) = 0|Z(1) = k)
= P(X(2) = 0, . . . , X(M ) = 0|Z(1) = k)r0,k . (34)

As a direct consequence of Lemma 7, we then have

(1)

P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0|Z(1) = k)
= P(X(2) = 0, . . . , X(M ) = 0|Z(1) = k)

(27)

k=1

P(X (2) (1) = 0, . . . , X (2) (M ) = 0|T1

(33)

From the (conditional) independence of Bernoulli samples in
(A3), it follows that

= s)

L
X
`=1

`=1

(30)

As such, we have from the law of total probability that

For s ≥ M , we have from (A3) that

=E

= P(Z(t + 1) = j|Z(t) = i)

ω + (1 − ω)πi if j = i
=
.
(1 − ω)πj
if j 6= i

P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0)
K
X
=
P(X(2) = 0, . . . , X(M ) = 0|Z(1) = k)r0,k πk .
k=1

(35)

(29)
Now let
sk,M −1 = P(X(2) = 0, . . . , X(M ) = 0|Z(1) = k).

(36)

Similar to the argument for (35), we can further condition on
the event {Z(2) = j} and use the law of total probability to
show that
sk,M −1 =

K
X

sj,M −2 r0,j pk,j ,

M − 1 as the induction hypothesis. From the law of total
probability, we have

(37)

j=1

=

for k = 1, 2, . . . , K. Let sM −1 be the K × 1 (column) vector
with its k th element being sk,M −1 , P = (pi,j ) be the K × K
transition probability matrix, and R be the diagonal matrix
with the k th diagonal element being r0,k . Then (37) can be
rewritten in the following matrix form:

=
+

P(X(1) = 0, . . . , X(M ) = 0)
∞
X
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s)
s=1
M
−1
X
s=1
∞
X

P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s)
P(X(1) = 0, . . . , X(M ) = 0|T1 = s)P(T1 = s).

s=M

sM −1 = PRsM −2 .
Since sk,0 = 1 for all k, we have from (38) that
sM −1 = (PR)M −1 1,

(43)

(38)

(39)

Conditioning on the event {T1 = s} for s ≥ M , the number
of samples in the first group is not smaller than M . Thus, for
s ≥ M , we have from (A2) and (A3) that

where 1 is the K × 1 vector with all its elements being 1.
Let π be the 1 × K (row) vector with its k th element being
πk . Then we have from (35) and (39) that

P(X(1) = 0, . . . , X(M ) = 0|T1 = s)
K
X
=
πk (r0,k )M

P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0)
= πR(PR)M −1 1.

≤

(40)

k=1
K
X

πk r0,k = r0 ,

(44)

k=1

Thus, the expected relative cost is
M +1
− πR(PR)M −1 1,
M

(41)

as in Theorem 3.
For ω = 1, we note that the Markov chain {Z(t), t =
1, 2, . . .} stays at the same state from time 1 onward, and the
M random variables {X(1), X(2), . . . X(M )} are i.i.d. when
conditioning on Z(1). As such, they
PMare exchangeable random
variables, and the distribution of t=1 X(t) can be expressed
as a mixture of Binomial distributions. For the special case
ω = 1, our model of Markov modulated processes recovers
the model of exchangeable binary random variables in [16]
(see Assumptions 2 and 3 in [16]).
Now we prove Theorem 4.
Proof. (Theorem 4) Analogous to the proof of Theorem 1,
it suffices to show that for any M ≥ 1,
P(X(1) = 0, X(2) = 0, . . . , X(M ) = 0)

(42)

≤ r0 (ω + (1 − ω)r0 )M −1 .
For this, we show that (42) holds by induction on M . Since
P(X(1) = 0) = r0 , the inequality in (42) holds trivially for
M = 1. Assume that the inequality in (42) holds for all s ≤

where the last inequality follows from the fact that the convex
function xM ≤ x for 0 ≤ x ≤ 1. For T1 = s ≤ M − 1, we
know that the second group starts from s + 1. It then follows
from the renewal property in (A1) that

P(X(1) = 0, . . . , X(M ) = 0|T1 = s)
= P(X(1) = 0, . . . , X(s) = 0|T1 = s)
P(X(s + 1) = 0, . . . , X(M ) = 0|T1 = s)
K
X

=
πk (r0,k )s P(X(1) = 0, . . . , X(M − s) = 0)
k=1

≤

K
X


πk r0,k P(X(1) = 0, . . . , X(M − s) = 0)

k=1



≤ (r0 ) r0 (ω + (1 − ω)r0 )M −s−1 ,

(45)

where the second last inequality follows from the fact that
the convex function xM ≤ x for 0 ≤ x ≤ 1, and the last
inequality follows from the induction hypothesis. Since T1 is
geometrically distributed from (A1+ ), we have

P(T1 = s) = (1 − ω)ω s−1 .

(46)

Using (44), (45) and (46) in (43) yeilds

≤
+
=

P(X(1) = 0, . . . , X(M ) = 0)
M
−1
X
(r0 )(r0 (ω + (1 − ω)r0 )M −s−1 )(1 − ω)ω s−1
s=1
∞
X

r0 (1 − ω)ω s−1

s=M
r02 (1 −
M
−1 
X

ω)(ω + (1 − ω)r0 )M −2
s−1
ω

ω + (1 − ω)r0

+

s=1
r0 ω M −1

=

r0 (ω + (1 − ω)r0 )M −1

(47)

This then completes the induction in (42).

III. P OOLED T ESTING WITH A S OCIAL G RAPH
In the previous section, we consider samples in a line of
a testing site, where the correlations between two contiguous
samples are characterized by a line graph. In this section,
we extend the dependency between two samples to a general
graph. Suppose that there is a social network modeled by a
graph G = (V, E), where V is the set of nodes, and E is the
set of edges. A node in G represents a person in the social
graph, and an edge between two persons represents frequent
social contacts between these two persons. As a contagious
disease can propagate the disease from an infected person
to another person through the social contacts between these
two persons, two persons connected by an edge are likely
to infect each other. Thus, two samples obtained from two
persons connected by an edge are also likely to be positively
correlated.
The question for pooled testing with a social graph G =
(V, E) is how to exploit positive correlation from the edge
connections in a social graph to save pooled testing costs.
Intuitively, a set of nodes that are densely connected to each
other are likely to be positively correlated. In social network
analysis (see, e.g., [22]), such a set of nodes is called a
community. In view of this, our idea for addressing the pooled
testing problem with a social graph is to detect communities
in a graph and then pool samples in the same community
together for pooled testing.
Like pooled testing for people in a line, we define a
pooling strategy for a graph G = (V, E) with n nodes,
i.e., |V | = n, as a permutation σ of {1, 2, . . . , n} that
puts the n nodes into a line. As such, when we use the
Dorfman two-stage algorithm with a given group size M ,
we can pool nodes σ(1), . . . , σ(M ) in the first group, nodes
σ(M + 1), . . . , σ(2M ) in the second group, etc. A random
pooling strategy for a graph G = (V, E) is the strategy
where the permutation σ is selected at random among the n!
permutations. The main objective of this section is to propose
a pooling strategy from a community detection algorithm in

[18]–[20] that can achieve a lower expected relative cost than
the random pooling strategy.
A. The probabilistic framework of sampled graphs
In this section, we briefly review the probabilistic framework of sampled graphs for structural analysis in [18]–[20].
For a graph G(V, E) with n nodes, we index the n nodes
from 1, 2, . . . , n. Also, let A = (ai,j ) be the n × n adjacency
matrix of the graph, i.e.,

1, if there is an edge from node i to node j,
ai,j =
0, otherwise.
Let Ru,w be the set of paths from u to w and R =
∪u,w∈V Ru,w be the set of paths in the graph G(V, E).
According to a probability mass function p(·), called the path
sampling distribution, a path r ∈ R is selected at random
with probability p(r). Let U (resp. W ) be the starting (resp.
ending) node of a randomly selected path by using the path
sampling distribution p(·). Then the bivariate distribution
X
pU,W (u, w) = P(U = u, W = w) =
p(r)
(48)
r∈Ru,w

is the probability that the ordered pair of two nodes (u, w) is
selected. Intuitively, one might interpret the bivariate distribution pU,W (u, w) in (48) as the probability that both nodes u
and w are infected (through one of the paths r in Ru,w ). Thus,
the bivariate distribution pU,W (u, w) can also be viewed as a
similarity measure from node u to node w and this leads to
the definition of a sampled graph in [18]–[20].
Definition 8: (Sampled graph [18]–[20]) A graph G(V, E)
that is sampled by randomly selecting an ordered pair of two
nodes (U, W ) according to a specific bivariate distribution
pU,W (·, ·) in (48) is called a sampled graph and it is denoted
by the two-tuple (G(V, E), pU,W (·, ·)).
Definition 9: (Covariance and Community [19], [20]))
For a sampled graph (G(V, E), pU,W (·, ·)), the covariance
between two nodes u and w is defined as follows:
q(u, w) = pU,W (u, w) − pU (u)pW (w).

(49)

Moreover, the covariance between two sets S1 and S2 is
defined as follows:
X X
q(S1 , S2 ) =
q(u, w).
(50)
u∈S1 w∈S2

Two sets S1 and S2 are said to be positively correlated if
q(S1 , S2 ) ≥ 0. In particular, if a subset of nodes S ⊂ V
is positively correlated to itself, i.e., q(S, S) ≥ 0, then it is
called a community.
There are many methods to obtain a sampled graph [19].
In this paper, we will use the following bivariate distribution
pU,W (u, w) = c · (A + 0.5 ∗ A2 )(u, w),

(51)

where A = (ai,j ) is the adjacency matrix of a graph
G = (V, E), and c is the normalization constant so that
the sum of pU,W (u, w) over u and w equals to 1. As such
bivariate distribution is obtained from sampling paths with

ALGORITHM 1: The Hierarchical Agglomerative
Algorithm for Pooled Testing with a Social Graph
Input: A sampled graph (G(V, E), pU,W (·, ·)).
Output: A pooling strategy σ.
(H1) Initially, the number of sets C is set to be n, and
node i is assigned to the ith set, i.e., Si = {i},
i = 1, 2, . . . , n.
(H2) Compute the covariance q(Si , Sj ) = q({i}, {j})
from (49) for all i, j = 1, 2, . . . , n.
while C > 1 do
(H3) Find the pairs of two sets i and j that have
the largest covariance q(Si , Sj ).
(H4) Merge Si and Sj into a new set Sk by
appending Sj to Si .
(H5) Update the covariances as follows:

Fig. 3: The Zachary karate club friendship network.

q(Sk , Sk ) = q(Si , Si ) + 2q(Si , Sj ) + q(Sj , Sj ).
(52)
for each ` 6= k do
q(Sk , S` ) = q(S` , Sk ) = q(Si , S` ) + q(Sj , S` ).
(53)
end
C = C − 1.
end
(H6) There is only one remaining set. Output σ by
letting σ(i) be the ith element in the remaining set.

lengths 1 and 2, it seems to be a good sampling distribution
for modelling the disease propagation within the second
neighbors of an infected person.
B. The hierarchical agglomerative algorithm for pooled testing in a graph
We propose a pooling strategy that uses the hierarchical
agglomerative algorithm for community detection in sampled
graphs [20]. The detailed steps are outlined in Algorithm 1.
Initially, every node in the input graph is assigned to a set
(community) that contains the node itself. Then the algorithm
recursively merges two sets that have the largest covariance
into a new set. This is done by appending one set to the end
of the other set so that the order of the elements in each set
can be preserved. Each merge of two sets reduces the number
of sets by 1. Eventually, there is only one remaining set, and
the order of the elements in the remaining set is the pooling
strategy from the algorithm. It was shown in [20] that all the
sets are indeed communities if Algorithm 1 stops at the point
when there does not exist a pair of two positively correlated
sets. However, as our objective is to output a permutation for
a pooling strategy, we continue the merge of two sets until
there is only one remaining set.
As an illustrating example of our algorithm, we use the
Zachary karate club friendship network [23]. Such a friendship
network is obtained by Wayne Zachary over the course of
two years in the early 1970s at an American university

(a) The dendrogram from Algorithm 1.

(b) Convert the dendrogram to a queue.

Fig. 4: (a) The dendrogram from Algorithm 1 for the Zachary
karate club friendship network by using the similarity measure
in (51). (b) An illustration of the 34 members of the Zachary
karate club forming a line to be tested in a testing site.

(see Figure 3). During the course of the study, the club
split into two clusters (marked with two different colors in
Figure 3) because of a dispute between its administrator (node
34) and its instructor (node 1). In Figure 4a, we show the
dendrogram obtained from Algorithm 1 for the Zachary karate
club friendship network by using the similarity measure in
(51). A dendrogram for a hierarchical agglomerative algorithm
is a tree-like graph with the height indicating the order of the
merges of two sets. The pooling strategy is the list of the 34
nodes in the bottom of this figure. In Figure 4b, we illustrate
the members of the Zachary karate club forming a line to be
tested in a testing site.
IV. N UMERICAL R ESULTS
A. Pooled testing on a line of a testing site
In this section, we compare the expected relative cost of
Dorfman’s two-stage method with that of a sophisticated
group testing method in [15] by considering the special case
with K = 2, r0,1 = 0 and r0,2 = 1. In this case, there are two
types of arriving groups, and such a group is of type 1 (resp.
type 2) with probability π1 = r1 (resp. π2 = r0 ). The sizes
of these arriving groups are i.i.d. geometric random variables
with parameter 1 − ω. Moreover, with probability 1, samples

in the type 1 group are positive and those in the type 2 group
are negative. Consequently, we have X(t) = 2 − Z(t) for all
t and it reduces to the serial correlated model in [24]. The
expected relative cost in this case is
M +1
− r0 (ω + (1 − ω)r0 )M −1 ,
M

(54)

where r0 = π2 . Notice that from Theorem 4, (54) achieves
the lower bound of the expected relative costs under (A1+ ),
(A2), and (A3).
The optimal group size of M that induces the lowest
expected relative cost in (54) can be determined by the
prevalence rate r1 and the parameter ω in the hidden Markov
model. In general, the parameter ω is unknown and difficult
to estimate; thus, in Section IV-A1, we choose the group size
M according to that in Table I of [8], which only depends
on the prevalence rate r1 . However, if one can estimate the
parameter ω reliably, the optimal group size of M can be
selected accordingly to further reduce the expected relative
cost. We optimize M depending on both r1 and ω in Section
IV-A2.
1) Group size M determined by r1 : In this section, we
choose the group size M from Table I of [8] that only depends
on the prevalence rate r1 (since the parameter ω in the hidden
Markov model is generally unknown).
We numerically evaluate the expected relative cost in (54)
for each value of r1 ranging from 1% to 10% with increment
of 1%, and each value of ω ranging from 0 to 0.9 with
increment of 0.1. The results are shown in Table I. To compare
the expected relative costs of Dorfman’s two-stage algorithm
(with positively correlated samples) with those of the (d1 , d2 )regular pooling matrices [15], we also list the lowest expected
relative costs of the (d1 , d2 )-regular pooling matrices (Table
I of [15]) in Table I. In this table, we can easily verify that
the expected relative cost decreases in ω. The numbers given
in boldface are the expected relative costs of Dorfman’s twostage algorithm of the smallest values of ω that outperform
those of the (d1 , d2 )-regular pooling matrices under the same
prevalence rate r1 . We can observe that when the prevalence
rate r1 is low (e.g., r1 < 5%), the gain by Dorfman twostage method is not as good as that of (d1 , d2 )-regular pooling
matrix, except for some large ω. The reason is that under a
low prevalence rate, there are very few positive samples in
a group, and such positive samples can be detected easily
by using the sophisticated group testing method, thus saving
more testing costs. However, Dorfman’s 2-stage algorithm can
only check if the group contains at least one positive sample
at the first stage. When a group of M samples includes any
positive ones (even if there is only one positive sample in
the group), all the M samples should be retested individually
at the second stage. Thus, the performance of Dorfman’s
method is not as good as those of sophisticated group testing
methods, on the premise that the prevalence rate is low and
correlations between samples in a group are small. But when
the prevalence rate r1 is high (e.g., r1 ≥ 5%), the simple

Dorfman’s method can achieve better performance with some
moderate positive correlation ω.
To show the advantage of using positively correlated samples in Dorfman’s two-stage method, we calculate the ratio of
the expected relative cost with the positive correlation ω to
that of the i.i.d. Bernoulli samples (ω = 0) in Table II. For
example, under the prevalence rate r1 = 1%, the expected
relative cost with ω = 0.1 is 0.1865 from Table I, and thus
the ratio is 0.1865/0.1956 = 95.4%.
2) Group size M determined by r1 and ω: In this section,
the optimal group size M that induces the lowest expected
relative cost is determined by both the prevalence rate r1 and
the correlation coefficient ω. For each value of r1 ranging
from 1% to 10% with increment of 1%, and each value of
ω ranging from 0 to 0.9 with increment of 0.1, we show
its optimal group size M in Table III and its corresponding
expected relative cost in Table IV. Intuitively, with correlated
samples, the group size for pooled testing can be larger. This
can be verified in Table III, which shows the size M increases
in ω for a fixed value of r1 . To make a comparison of
the expected relative costs of Dorfman’s two-stage algorithm
(with positively correlated samples) and those of the (d1 , d2 )regular pooling matrices [15], we also list the lowest expected
relative costs of the (d1 , d2 )-regular pooling matrices (Table
I of [15]) in Table IV. To show the advantage of using
positively correlated samples in Dorfman’s two-stage method,
we calculate the ratio of the expected relative cost with the
positive correlation ω to that of the i.i.d. Bernoulli samples
(ω = 0) in Table V.
B. Pooled testing with a social graph
In this section, we report our simulation results for pooled
testing with a social graph. For our experiments, we use a
synthetic dataset and three real-world datasets. The synthetic
dataset is constructed by the small-world model in [25] as
follows. First, we generate a ring with 1, 000 nodes, and each
node has a degree of 30 connected to its nearest neighbors.
Then, for each edge, with probability 0.5, we remove that
edge and add a new one to two randomly selected nodes. By
doing so, we obtain the synthetic dataset. The three real-world
datasets are: the email-Eu-core in [26] [27], the political blogs
in [28] and the ego-Facebook in [29]. There are 986 nodes and
16,064 edges for the email-Eu-core network after removing
multiple edges, self-loops, and nodes with degree 0. For the
political blogs, there are 1,224 nodes and 16,715 edges. For
the ego-Facebook dataset, we remove multiple edges, selfloops, and nodes that are not in the largest component of the
network as in [30]. By doing so, there are 2, 851 nodes and
62, 318 edges left in the network. The basic information of
datasets is given in Table VI.
We also need a model for modelling disease propagation in
a network. A widely used model is the independent cascade
(IC) model (see, e.g., Kempe, Kleinberg, and Tardos in [31]).
In the IC model, an infected node can transmit the disease to a
neighboring susceptible node (through an edge) with a certain
propagation probability φ. An infected neighboring node can

TABLE I: The expected relative cost of the Dorfman two-stage algorithm with group size M and the lowest expected relative
cost of (d1 , d2 )-regular in [15]. The numbers given in boldface are the expected relative costs of Dorfman’s two-stage algorithm
of the smallest values of ω that outperform those of the (d1 , d2 )-regular pooling matrices under the same prevalence rate r1 .
r1
1%
2%
3%
4%
5%
6%
7%
8%
9%
10%

M
11
8
6
6
5
5
5
4
4
4

ω=0
0.1956
0.2742
0.3337
0.3839
0.4262
0.4661
0.5043
0.5336
0.5643
0.5939

ω = 0.1
0.1865
0.2620
0.3207
0.3675
0.4098
0.4472
0.4831
0.5148
0.5437
0.5718

The Dorfman Two-stage Algorithm
ω = 0.3
ω = 0.4
ω = 0.5
ω = 0.6
0.1681
0.1587
0.1493
0.1398
0.2371
0.2244
0.2116
0.1986
0.2943
0.2809
0.2673
0.2535
0.3337
0.3165
0.2989
0.2810
0.3762
0.3590
0.3415
0.3238
0.4082
0.3882
0.3678
0.3470
0.4393
0.4167
0.3935
0.3699
0.4761
0.4562
0.4360
0.4155
0.5014
0.4796
0.4574
0.4348
0.5261
0.5025
0.4784
0.4537

ω = 0.2
0.1773
0.2496
0.3076
0.3507
0.3931
0.4279
0.4615
0.4956
0.5227
0.5492

TABLE II: The ratio of the expected relative cost with positive
correlation ω to that of the i.i.d. Bernoulli samples (ω = 0)
under different prevalence rate r1 . (unit: %)
r1 \ω
1%
2%
3%
4%
5%
6%
7%
8%
9%
10%

0.1
95.4
95.5
96.1
95.7
96.1
95.9
95.8
96.5
96.4
96.3

0.2
90.7
91.0
92.2
91.4
92.2
91.8
91.5
92.9
92.6
92.5

0.3
85.9
86.5
88.2
86.9
88.3
87.6
87.1
89.2
88.9
88.6

0.4
81.2
81.8
84.2
82.4
84.2
83.3
82.6
85.5
85.0
84.6

0.5
76.3
77.2
80.1
77.9
80.1
78.9
78.0
81.7
81.1
80.5

0.6
71.5
72.4
76.0
73.2
76.0
74.5
73.3
77.9
77.1
76.4

0.7
66.6
67.6
71.8
68.5
71.7
69.9
68.5
74.0
73.0
72.2

0.8
61.6
62.8
67.6
63.7
67.4
65.3
63.7
70.0
68.8
67.8

0.9
56.6
57.8
63.3
58.8
63.1
60.6
58.6
65.9
64.6
63.4

TABLE III: The optimal group size of the Dorfman two-stage
algorithm with different values of the prevalence rate r1 and
the correlation coefficient ω.
r1 \ω
1%
2%
3%
4%
5%
6%
7%
8%
9%
10%

0
11
8
6
6
5
5
5
4
4
4

0.1
11
8
7
6
5
5
5
4
4
4

0.2
12
8
7
6
6
5
5
5
4
4

0.3
12
9
7
7
6
6
5
5
5
4

0.4
13
10
8
7
6
6
6
5
5
5

0.5
15
11
9
8
7
6
6
6
5
5

0.6
16
12
10
9
8
7
7
6
6
6

0.7
19
14
11
10
9
8
8
7
7
7

0.8
23
16
14
12
11
10
9
9
8
8

0.9
32
23
19
17
15
14
13
12
12
11

continue the propagation of the disease to its neighbors.
For our experiments, a set of seeded nodes S are randomly
selected in the IC model. Each neighbor of a seeded node is
infected with probability φ. These infected nodes are called
the first-generation cascade of a seeded node and they can
continue infecting their neighbors. The D-generation cascade
from a seeded node is generated by collecting the set of
infected nodes within the distance D of the seeded node,
and the D-generation cascade from the set S is generated by
taking the union of the D-generation cascades of the seeded
nodes in S. In our experiments, we set φ = 0.1 and D = 2.
The pooling strategy for each dataset is obtained in the same
way as that for the Zachary karate club friendship network in
Section III-B. Specifically, we first generate a sampled graph
by using the bivariate distribution in (51). Then we use the
hierarchical agglomerative algorithm for pooled testing with a

ω = 0.7
0.1302
0.1854
0.2395
0.2629
0.3057
0.3259
0.3457
0.3947
0.4117
0.4286

ω = 0.8
0.1205
0.1721
0.2254
0.2445
0.2874
0.3043
0.3210
0.3735
0.3883
0.4029

ω = 0.9
0.1108
0.1586
0.2111
0.2257
0.2689
0.2824
0.2958
0.3519
0.3643
0.3767

(d1 , d2 )-regular
Lowest Cost
0.1218
0.1881
0.2545
0.3147
0.3678
0.4166
0.4627
0.5035
0.5416
0.5760

social graph in Algorithm 1 to generate the pooling strategy.
In Figure 5 (resp. Figure 6, Figure 7, Figure 8), we show the
expected relative cost of Dorfman’s two-stage algorithm with
the group size M = 10, as a function of the number of seeded
nodes |S| for the small-world dataset (resp. the email-Eu-core
dataset, the political blogs dataset, the ego-Facebook dataset).
In our experiments, the number of seeded nodes |S| is from
1 to 5. Each data point is obtained from averaging 10,000
independent runs. Specifically, for the ith run, we measure
(i)
the prevalence rate r1 and the total number of tests I (i) . The
expected relative cost is calculated by
P10,000 (i)
I
i=1
,
n ∗ 10, 000
where n is the number of nodes in the graph. The average
prevalence rate is calculated by
P10,000 (i)
r1
i=1
.
10, 000
As shown in Figure 5, the pooling strategy from Algorithm
1 results in much lower expected relative costs than those
from the random pooling strategy. We note that the two
curves, Random(simulation) and Random(Theory) from (1),
are almost identical in this figure. We confirm the same
finding for the email-Eu-core, the political blogs and the egoFacebook datasets in Figure 6, Figure 7 and Figure 8. To
understand the effect of the number of seeded nodes in a
dataset, we show the average prevalence rates in Table VII.
As shown in this table, the prevalence rates are in the range of
1% to 12% that are basically in line with the prevalence rates
of COVID-19 in various countries. Moreover, we can observe
that the email-Eu-core network has the highest prevalence
rates among the four datasets. Intuitively, the higher density
and the higher averaging clustering coefficient, the higher
the prevalence rate. However, under the IC model, the total
number of people infected in a network highly depends on
the network’s structure. To conclude, under the IC model,
the expected relative costs for the small-world dataset and
the three real-world datasets can be significantly reduced by
roughly 10%-13% and 20%-35%, respectively, by exploiting
positive correlation within a social graph.

TABLE IV: The expected relative cost of the Dorfman two-stage algorithm with its optimal group size in Table III, and the
lowest expected relative cost of (d1 , d2 )-regular in [15]. The numbers given in boldface are the expected relative costs of
Dorfman’s two-stage algorithm of the smallest values of ω that outperform those of the (d1 , d2 )-regular pooling matrices under
the same prevalence rate r1 .
r1
1%
2%
3%
4%
5%
6%
7%
8%
9%
10%

ω=0
0.1956
0.2742
0.3337
0.3839
0.4262
0.4661
0.5043
0.5336
0.5643
0.5939

ω = 0.1
0.1865
0.2620
0.3198
0.3675
0.4098
0.4472
0.4831
0.5148
0.5437
0.5718

The Dorfman Two-stage Algorithm
ω = 0.2
ω = 0.3
ω = 0.4
0.1771
0.1670
0.1559
0.2496
0.2356
0.2209
0.3044
0.2888
0.2708
0.3507
0.3333
0.3131
0.3921
0.3717
0.3509
0.4279
0.4082
0.3841
0.4615
0.4393
0.4162
0.4939
0.4694
0.4443
0.5227
0.4985
0.4712
0.5492
0.5261
0.4973

with Positively Correlated Samples
ω = 0.5
ω = 0.6
ω = 0.7
ω = 0.8
0.1438
0.1303
0.1147
0.0961
0.2046
0.1862
0.1652
0.1397
0.2516
0.2299
0.2048
0.1744
0.2916
0.2673
0.2388
0.2045
0.3267
0.3003
0.2693
0.2317
0.3595
0.3304
0.2972
0.2568
0.3884
0.3586
0.3234
0.2803
0.4165
0.3847
0.3476
0.3025
0.4431
0.4091
0.3707
0.3237
0.4669
0.4328
0.3932
0.3437

The expected relative cost

The expected relative cost

small-world
0.6
Algorithm 1
Random(simulation)
Random(theory)

0.5

0.4

0.3

0.2
1

2

3

4

Algorithm 1
Random(simulation)
Random(theory)

0.6
0.5
0.4
0.3
0.2

5

1

2

The expected relative cost

The expected relative cost

Algorithm 1
Random(simulation)
Random(theory)

0.6
0.5
0.4
0.3
0.2
3

4

5

Fig. 7: The expected relative cost of Dorfman’s two-stage
algorithm with M = 10 as a function of the number of seeded
nodes |S| from 1 to 5 for the political blogs dataset.

email-Eu-core
0.8

2

3

Number of seeds

Fig. 5: The expected relative cost of Dorfman’s two-stage
algorithm with M = 10 as a function of the number of seeded
nodes |S| from 1 to 5 for the small-world dataset.

1

(d1 , d2 )-regular
Lowest Cost
0.1218
0.1881
0.2545
0.3147
0.3678
0.4166
0.4627
0.5035
0.5416
0.5760

political blogs

0.7

Number of seeds

0.7

ω = 0.9
0.0715
0.1057
0.1337
0.1585
0.1810
0.2022
0.2221
0.2411
0.2595
0.277

4

5

Number of seeds

Fig. 6: The expected relative cost of Dorfman’s two-stage
algorithm with M = 10 as a function of the number of seeded
nodes |S| from 1 to 5 for the email-Eu-core dataset.

ego-Facebook

0.6

Algorithm 1
Random(simulation)
Random(theory)

0.5
0.4
0.3
0.2
0.1
1

2

3

4

5

Number of seeds

Fig. 8: The expected relative cost of Dorfman’s two-stage
algorithm with M = 10 as a function of the number of seeded
nodes |S| from 1 to 5 for the ego-Facebook dataset.

TABLE V: With optimal group sizes in Table III, the ratio of
the expected relative cost with positive correlation ω to that of
the i.i.d. Bernoulli samples (ω = 0) under different prevalence
rate r1 . (unit: %)
r1 \ω
1%
2%
3%
4%
5%
6%
7%
8%
9%
10%

0.1
95.4
95.5
95.8
95.7
96.1
95.9
95.8
96.5
96.4
96.3

0.2
90.5
91.0
91.2
91.4
92.0
91.8
91.5
92.6
92.6
92.5

0.3
85.4
85.9
86.6
86.8
87.2
87.6
87.1
88.0
88.4
88.6

0.4
79.7
80.6
81.2
81.5
82.3
82.4
82.5
83.3
83.5
83.7

0.5
73.5
74.6
75.4
76.0
76.7
77.1
77.0
78.1
78.5
78.6

0.6
66.6
67.9
68.9
69.6
70.5
70.9
71.1
72.1
72.5
72.9

0.7
58.7
60.2
61.4
62.2
63.2
63.8
64.1
65.1
65.7
66.2

0.8
49.2
50.9
52.3
53.3
54.4
55.1
55.6
56.7
57.4
57.9

0.9
36.6
38.5
40.1
41.3
42.5
43.4
44.0
45.2
46.0
46.6

TABLE VI: Basic information of four datasets. Note that
the political blogs dataset is not connected; the average path
length and the diameter of the largest connected component
in political blogs are reported.
Dataset
Number of nodes
Number of edges
Average degree
Average excess degree
Average clustering
coefficient
Average path length
Diameter
Density

small-world
1,000
15,000
30
29.3581

email-Eu-core
986
16,064
32.5842
73.6564

political blogs
1,224
16,715
27.3121
80.2587

ego-Facebook
2,851
62,318
43.7166
98.0664

0.1133

0.4071

0.3197

0.5914

2.4414
3
3.0030e-2

2.5843
7
3.3080e-2

2.7467
8
2.2332e-2

4.1353
14
1.5339e-2

V. C ONCLUSION
By modelling the arrival process of a COVID-19 testing
site by a regenerative process, we showed that the expected
relative cost for positively correlated samples is not higher
than that of i.i.d. samples with the same prevalence rate.
A more detailed model by a Markov modulated process
allows us to derive a closed-form expression for the expected
relative cost. Using the closed-form expression in Theorem
3, we showed that for a specific Markov modulated process
with a moderate positive correlation, the gain by Dorfman’s
two-stage method outperforms those by using sophisticated
strategies with (d1 , d2 )-regular pooling matrices when the
prevalence rate is higher than 5%.
One important extension of our results is to consider the
pooled testing problem with a social graph. The frequent
social contacts between two persons are connected by an edge
in the social graph. To exploit positive correlation in a social
graph, we adopted the probabilistic framework of sampled
graphs for structural analysis in [18]–[20] and proposed a
hierarchical agglomerative algorithm for pooled testing with
a social graph in Algorithm 1. Our numerical results show
that the pooled testing strategy obtained from Algorithm 1
can have significant cost reduction (roughly 20%-35%) in
TABLE VII: Average prevalence rates (unit: %).
Dataset \ Number of seeds
small-world
email-Eu-core
political blogs
ego-Facebook

1
1.26
2.63
1.91
1.26

2
2.51
5.15
3.77
2.44

3
3.75
7.42
5.56
3.59

4
4.95
9.62
7.21
4.72

5
6.13
11.68
8.78
5.79

comparison with random pooling when the Dorfman two-stage
algorithm is used.
There are several possible extensions for our work:
(i)

(ii)

Association of random samples: in this paper, we
model in the arrival process by three explicit assumptions. It is possible to further generalize our
results by using the notion of association of random
variables [32]. In particular, it was shown in Theorem 4.1 of [32] that (15) and (16) hold for associated
binary random variables.
Sensitivity/specificity analysis: in this paper, we did
not consider the effect of noise. Noise (see, e.g.,
the monograph [33] for various noise models) can
affect sensitivity (true positive rate) and specificity
(true negative rate) of a testing method. It would be
of interest to see how the expected relative cost is
affected by a certain type of noise, e.g., the dilution
noise.
R EFERENCES

[1] Y.-C. Chen, P.-E. Lu, C.-S. Chang, and T.-H. Liu, “A Timedependent SIR model for COVID-19 with undetectable infected persons,” IEEE Transactions on Network Science and Engineering, DOI:
10.1109/TNSE.2020.3024723, 2020.
[2] “Pooled
Sample
Testing
and
Screening
Testing
for
COVID-19,”
Aug
2020.
[Online].
Available: https://www.fda.gov/medical-devices/coronavirus-covid-19-andmedical-devices/pooled-sample-testing-and-screening-testing-covid-19
[3] S. Lohse, T. Pfuhl, B. Berkó-Göttel, J. Rissland, T. Geißler, B. Gärtner,
S. L. Becker, S. Schneitler, and S. Smola, “Pooling of samples for
testing for SARS-CoV-2 in asymptomatic people,” The Lancet Infectious
Diseases, 2020.
[4] B. Abdalhamid, C. R. Bilder, E. L. McCutchen, S. H. Hinrichs, S. A.
Koepsell, and P. C. Iwen, “Assessment of specimen pooling to conserve
SARS CoV-2 testing resources,” American journal of clinical pathology,
vol. 153, no. 6, pp. 715–718, 2020.
[5] I. Yelin, N. Aharony, E. Shaer-Tamar, A. Argoetti, E. Messer, D. Berenbaum, E. Shafran, A. Kuzli, N. Gandali, T. Hashimshony et al., “Evaluation of COVID-19 RT-qPCR test in multi-sample pools,” MedRxiv,
2020.
[6] C. Gollier and O. Gossner, “Group testing against COVID-19,” Covid
Economics, vol. 2, 2020.
[7] “Interim Guidance for Use of Pooling Procedures in SARS-CoV2 Diagnostic, Screening, and Surveillance Testing,” June 2020.
[Online]. Available: https://www.cdc.gov/coronavirus/2019-ncov/lab/
pooling-procedures.html
[8] R. Dorfman, “The detection of defective members of large populations,”
The Annals of Mathematical Statistics, vol. 14, no. 4, pp. 436–440,
1943.
[9] “List of countries implementing pool testing strategy against COVID19,” 2020. [Online]. Available: https://en.wikipedia.org/wiki/List of
countries implementing pool testing strategy against COVID-19
[10] N. Sinnott-Armstrong, D. Klein, and B. Hickey, “Evaluation of group
testing for SARS-CoV-2 RNA,” medRxiv, 2020.
[11] N. Shental, S. Levy, V. Wuvshet, S. Skorniakov, B. Shalem, A. Ottolenghi, Y. Greenshpan, R. Steinberg, A. Edri, R. Gillis et al., “Efficient
high-throughput SARS-CoV-2 testing to detect asymptomatic carriers,”
Science Advances, p. eabc5961, 2020.
[12] S. Ghosh, A. Rajwade, S. Krishna, N. Gopalkrishnan, T. E. Schaus,
A. Chakravarthy, S. Varahan, V. Appu, R. Ramakrishnan, S. Ch et al.,
“Tapestry: A Single-Round Smart Pooling Technique for COVID-19
Testing,” medRxiv, 2020.
[13] S. Ghosh, R. Agarwal, M. A. Rehan, S. Pathak, P. Agrawal, Y. Gupta,
S. Consul, N. Gupta, R. Goyal, A. Rajwade et al., “A Compressed
Sensing Approach to Group-testing for COVID-19 Detection,” arXiv
preprint arXiv:2005.07895, 2020.

[14] L. Mutesa, P. Ndishimye, Y. Butera, J. Souopgui, A. Uwineza, R. Rutayisire, E. L. Ndoricimpaye, E. Musoni, N. Rujeni, T. Nyatanyi et al., “A
pooled testing strategy for identifying SARS-CoV-2 at low prevalence,”
Nature, pp. 1–8, 2020.
[15] Y.-J. Lin, C.-H. Yu, T.-H. Liu, C.-S. Chang, and W.-T. Chen, “Comparisons of Pooling Matrices for Pooled Testing of COVID-19,” arXiv
preprint arXiv:2010.00060, 2020.
[16] S. D. Lendle, M. G. Hudgens, and B. F. Qaqish, “Group Testing for
Case Identification with Correlated Responses,” Biometrics, vol. 68, pp.
532–540, 2012.
[17] A. Deckert, T. Bärnighausen, and N. N. Kyei, “Simulation of pooledsample analysis strategies for COVID-19 mass testing,” Bulletin of the
World Health Organization, vol. 98, no. 9, p. 590, 2020.
[18] C.-S. Chang, C.-Y. Hsu, J. Cheng, and D.-S. Lee, “A general probabilistic framework for detecting community structure in networks,” in
2011 Proceedings IEEE INFOCOM. IEEE, 2011, pp. 730–738.
[19] C.-S. Chang, C.-J. Chang, W.-T. Hsieh, D.-S. Lee, L.-H. Liou, and
W. Liao, “Relative centrality and local community detection,” Network
Science, vol. 3, no. 4, pp. 445–479, 2015.
[20] C.-S. Chang, D.-S. Lee, L.-H. Liou, S.-M. Lu, and M.-H. Wu, “A
probabilistic framework for structural analysis and community detection
in directed networks,” IEEE/ACM Transactions on Networking, vol. 26,
no. 1, pp. 31–46, 2017.
[21] R. Nelson, Probability, stochastic processes, and queueing theory: the
mathematics of computer performance modeling. Springer Science &
Business Media, 2013.
[22] M. Newman, Networks: An Introduction. Oxford University Press,
2010.
[23] W. W. Zachary, “An information flow model for conflict and fission in
small groups,” Journal of anthropological research, vol. 33, no. 4, pp.
452–473, 1977.
[24] M. Hung and W. H. Swallow, “Robustness of group testing in the
estimation of proportions,” Biometrics, vol. 55, no. 1, pp. 231–237,
1999.
[25] D. J. Watts and S. H. Strogatz, “Collective dynamics of ‘small-world’
networks,” Nature, vol. 393, pp. 440–442, 1998.
[26] H. Yin, A. R. Benson, J. Leskovec, and D. F. Gleich, “Local higherorder graph clustering,” in Proceedings of the 23rd ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining.
ACM, 2017, pp. 555–564.
[27] J. Leskovec, J. Kleinberg, and C. Faloutsos, “Graph evolution: Densification and shrinking diameters,” ACM Transactions on Knowledge
Discovery from Data (TKDD), vol. 1, no. 1, p. 2, 2007.
[28] L. A. Adamic and N. Glance, “The political blogosphere and the 2004
US election: divided they blog,” in Proceedings of the 3rd international
workshop on Link discovery, 2005, pp. 36–43.
[29] J. Leskovec and J. J. Mcauley, “Learning to discover social circles in
ego networks,” in Advances in neural information processing systems,
2012, pp. 539–547.
[30] P.-E. Lu and C.-S. Chang, “Explainable, Stable, and Scalable Graph
Convolutional Networks for Learning Graph Representation,” arXiv
preprint arXiv:2009.10367, 2020.
[31] D. Kempe, J. Kleinberg, and É. Tardos, “Maximizing the spread of
influence through a social network,” in Proceedings of the ninth ACM
SIGKDD international conference on Knowledge discovery and data
mining. ACM, 2003, pp. 137–146.
[32] J. D. Esary, F. Proschan, and D. W. Walkup, “Association of random
variables, with applications,” The Annals of Mathematical Statistics, pp.
1466–1474, 1967.
[33] M. Aldridge, O. Johnson, and J. Scarlett, “Group testing: an information
theory perspective,” arXiv preprint arXiv:1902.06002, 2019.

Yi-Jheng Lin received his B.S. degree in electrical
engineering from National Tsing Hua University,
Hsinchu, Taiwan, in 2018. He is currently pursuing
the Ph.D. degree in the Institute of Communications Engineering, National Tsing Hua University,
Hsinchu, Taiwan. His research interests include
wireless communication and cognitive radio networks.

Che-Hao Yu received his B.S. degree in mathematics from National Tsing-Hua University, Hsinchu,
Taiwan (R.O.C.), in 2018, and the M.S. degree in
communications engineering from National Tsing
Hua University, Hsinchu, Taiwan (R.O.C.), in 2020.
His research interest is in 5G wireless communication.

Tzu-Hsuan Liu received the B.S. degree in communication engineering from National Central University, Taoyuan, Taiwan (R.O.C.), in 2018. She is
currently pursuing the M.S. degree in the Institute of
Communications Engineering, National Tsing Hua
University, Hsinchu, Taiwan (R.O.C.). Her research
interest is in 5G wireless communication.

Cheng-Shang Chang (S’85-M’86-M’89-SM’93F’04) received the B.S. degree from National Taiwan University, Taipei, Taiwan, in 1983, and the
M.S. and Ph.D. degrees from Columbia University,
New York, NY, USA, in 1986 and 1989, respectively, all in electrical engineering.
From 1989 to 1993, he was employed as a
Research Staff Member with the IBM Thomas J.
Watson Research Center, Yorktown Heights, NY,
USA. Since 1993, he has been with the Department
of Electrical Engineering, National Tsing Hua University, Taiwan, where he is a Tsing Hua Distinguished Chair Professor. He is
the author of the book Performance Guarantees in Communication Networks
(Springer, 2000) and the coauthor of the book Principles, Architectures and
Mathematical Theory of High Performance Packet Switches (Ministry of
Education, R.O.C., 2006). His current research interests are concerned with
network science, big data analytics, mathematical modeling of the Internet,
and high-speed switching.
Dr. Chang served as an Editor for Operations Research from 1992 to
1999, an Editor for the IEEE/ACM TRANSACTIONS ON NETWORKING
from 2007 to 2009, and an Editor for the IEEE TRANSACTIONS ON
NETWORK SCIENCE AND ENGINEERING from 2014 to 2017. He is
currently serving as an Editor-at-Large for the IEEE/ACM TRANSACTIONS
ON NETWORKING. He is a member of IFIP Working Group 7.3. He received
an IBM Outstanding Innovation Award in 1992, an IBM Faculty Partnership
Award in 2001, and Outstanding Research Awards from the National Science
Council, Taiwan, in 1998, 2000, and 2002, respectively. He also received
Outstanding Teaching Awards from both the College of EECS and the
university itself in 2003. He was appointed as the first Y. Z. Hsu Scientific
Chair Professor in 2002. He received the Merit NSC Research Fellow Award
from the National Science Council, R.O.C. in 2011. He also received the
Academic Award in 2011 and the National Chair Professorship in 2017 from
the Ministry of Education, R.O.C. He is the recipient of the 2017 IEEE
INFOCOM Achievement Award.

Wen-Tsuen Chen (M’87-SM’90-F’94) received his
B.S. degree in nuclear engineering from National
Tsing Hua University, Taiwan, and M.S. and Ph.D.
degrees in electrical engineering and computer sciences both from University of California, Berkeley, in 1970, 1973, and 1976, respectively. He has
been with the Department of Computer Science
of National Tsing Hua University since 1976 and
served as Chairman of the Department, Dean of
College of Electrical Engineering and Computer
Science, and the President of National Tsing Hua
University. In March 2012, he joined the Academia Sinica, Taiwan as a
Distinguished Research Fellow of the Institute of Information Science until
June 2018. Currently he is Sun Yun-suan Chair Professor of National Tsing
Hua University. His research interests include computer networks, wireless
sensor networks, mobile computing, and parallel computing. Dr. Chen received numerous awards for his academic accomplishments in computer
networking and parallel processing, including Outstanding Research Award
of the National Science Council, Academic Award in Engineering from
the Ministry of Education, Technical Achievement Award and Taylor L.
Booth Education Award of the IEEE Computer Society, and is currently a
lifelong National Chair of the Ministry of Education, Taiwan. Dr. Chen is the
Founding General Chair of the IEEE International Conference on Parallel
and Distributed Systems and the General Chair of the IEEE International
Conference on Distributed Computing Systems. He is an IEEE Fellow and a
Fellow of the Chinese Technology Management Association.

