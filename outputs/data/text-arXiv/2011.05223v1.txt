1

arXiv:2011.05223v1 [q-bio.QM] 10 Nov 2020

AC-DC: Amplification Curve Diagnostics for
Covid-19 Group Testing
Ryan Gabrys:,1 , Srilakshmi Pattabiraman:,1 , Vishal Rana:,1 , João Ribeiro:,2 , Mahdi Cheraghchi;,3 ,
Venkatesan Guruswami;,4 and Olgica Milenkovic;,1
1 University of Illinois, Urbana-Champaign; 2 Imperial College London; 3 University of Michigan, Ann
Arbor; 4 Carnegie Mellon University, Pittsburgh.
ryan.gabrys@gmail.com, sp16@illinois.edu, vishalr@illinois.edu, j.lourenco-ribeiro17@imperial.ac.uk,
mahdich@umich.edu, venkatg@cs.cmu.edu, milenkov@illinois.edu

Abstract
The first part of the paper presents a review of the gold-standard testing protocol for Covid-19, real-time,
reverse transcriptase PCR, and its properties and associated measurement data such as amplification curves that
can guide the development of appropriate and accurate adaptive group testing protocols. The second part of the paper
is concerned with examining various off-the-shelf group testing methods for Covid-19 and identifying their strengths
and weaknesses for the application at hand. The third part of the paper contains a collection of new analytical results
for adaptive semiquantitative group testing with probabilistic and combinatorial priors, including performance bounds,
algorithmic solutions, and noisy testing protocols. The probabilistic setting is of special importance as it is designed
to be simple to implement by nonexperts and handle heavy hitters. The worst-case paradigm extends and improves
upon prior work on semiquantitative group testing with and without specialized PCR noise models.

I. I NTRODUCTION
In less than ten months since the first case reported in the Hubei province of China, Covid-19 has rapidly spread
across all continents except Antarctica [1]. The disease has caused more deaths than Ebola, SARS, and the seasonal
Flu combined (reaching 1, 000, 000 mortalities in September 2020), disrupted the global economy to an extent not
seen since the Great Depression and altered the lives of hundreds of millions of people across the globe [2].
Many analyses associated with the Covid-19 pandemic have established that widespread population testing is key
to effectively containing outbreaks of this and other infectious diseases. In May 2020, the United States was able to
test around 150, 000 people per day (According to the Covid Tracking Project, this number has since increased to
750, 000 in August), while countries that have managed to keep the outbreak under control, such as Germany and
South Korea, have performed millions of tests during the same stage of the spread of the disease. Although there is
no general consensus on the exact number of individuals that need to be tested, most experts agree that the reported
numbers are highly inadequate and should be at least an order of magnitude higher before the economy can be
safely reopened to the pre-pandemic extent [3]. Some universities, such as Yale University, and the University of
Illinois, currently have a biweekly test schedule in place for all individuals accessing school property [4]. This is
believed to be a sufficiently large-scale testing protocol that allows the institution to safely operate.
To address the need for sustainable high-frequency population testing, a number of countries and states proposed
and implemented group testing schemes in which genetic samples from different individuals are pooled together
in a manner that incorporates thresholded real time reverse transcriptase polymerase chain reaction (RT-PCR)
fluorescence signals into the testing scheme1 .
Group testing (GT) is a combinatorial screening method introduced by Dorfman [6] for identifying small groups
of soldiers infected by Syphilis. His scheme, known as single-pooling, consists of mixing blood samples from five
soldiers at a time, and running one test for each pool. For positive test outcomes, the soldiers involved in the
All junior authors: are listed in alphabetical order, and all senior authors; are listed in alphabetical order. M. Cheraghchi is supported in part
by an NSF grant CCF-2006455.
1 A recent ordinance issued by the governor of Nebraska [5] recommends using group testing for widespread screening for Covid-19, while
group testing methods are employed in part in Israel.

2

test are examined individually in a second round to determine who has the disease. For negative outcomes, all
subjects involved are declared healthy and removed from future testing schedules. Given a relatively small number
of infected individuals in a population, this scheme provides a significant reduction in the number of tests required
when compared to individual testing [7]. The scheme proved ineffective for its original task as blood sample pooling
dilutes the resulting sample to a point below the sensitivity of the tests used.
A number of recent reports suggest using Dorfman’s or other mostly off-the-shelf GT schemes for Covid-19
testing [8]–[17]. Most of the proposed schemes do not incorporate relevant biological priors or exploit the highly
specific measurement and noise properties of the RT-PCR method in their testing schemes. We argue this is a
significant detriment, as in order to properly execute the effort and avoid dangerous failures, testing schemes should
to be guided both by mathematical considerations as well as social, clinical, and genomic side information2 . This
suggests designing Covid-19 group testing schemes that carefully address the following issues:
1) Selection of adequate primers. As stated in the CDC SARS-CoV-2 testing guidelines [20], only two primers
are recommended for use in the USA for RT-PCR reactions, selected from the N open reading frame (ORF)
of the SARS-CoV-2 genome. It is often hard to predict which regions will have small mutations and it is
currently not known how fast the N regions and other primer regions chosen by various countries mutate
and how these mutations affect the PCR protocol. To determine the influence of mutations one first needs
to determine which regions will remain mostly unaffected by mutations, determine the melting temperatures
of the primers [21] and their binding affinity to the mutated reference regions. For this purpose, the recent
work [22] may be used to guide the primer selection process, while actually recorded mutated N primer
regions may be used to estimate the failure rates of the individual PCR tests or model the errors in group
PCR protocols due to mutations. These issues will be examined in Sections II and V.
2) Selection of (near-)optimal sample mixing strategies with priors. If not properly designed, GT schemes
may lead to errors that are even more detrimental to the population than no tests at all. Since some individuals,
such as health workers, may harbor multiple strains of the virus, and since clinical priors are often readily
available (e.g., symptom charts, chest X-ray images) the sampling and mixing approaches should be carefully
designed to include the right number and combinations of subjects in order to minimize test errors. This is
a complicated issue that will be examined elsewhere.
3) Use of quantitative test outcomes. RT-PCR experiments provide significantly more information about the
viral load or number of infected individuals within the group rather than just a simple binary answer, “no
infected samples” or “at least one infected sample”. Except for a handful of works proposing to use quantitative
RT-PCR through Compressed Sensing (CS) [23]–[25], most reported Covid-19 GT schemes assume binary
test outcomes (among them the scheme used in Israel and described in [26]). Furthermore, practically tested
schemes operate in a nonadaptive setting, which is suboptimal and not justified for large-scale testing strategies
which use a limited number of PCR machines. Another important issue is that heavy hitters (individuals
with very high viral loads) can “mask” individuals with smaller loads which makes the use of quantitative
information difficult [27], [28]. This masking phenomena, as well as saturation effects present in RT-PCR
outputs, can make CS approaches highly susceptible to errors. The focus of this work is to develop schemes
that can address these issues in a simple, yet efficient manner. Consequently, our main results pertain to
scalable, adaptive and semiquantitative testing methods that can efficiently handle heavy hitters and errors
that are specific to RT-PCR systems.
4) Incorporation of social/contact network information. Due to the highly heterogeneous response of
individuals to the infection, diverse infection rates across different geographic and communal regions, the
best testing practices have to be guided by infection risk assessments and scores. Such “network-guided”
schemes are not known in the GT and CS literature, except for a recent work that partitions individuals into
unconnected communities and aims to identify all infected members of all communities simultaneously [29].
One can argue that in the early stages of the outbreak it is more relevant to identify the highly infected
communities and their neighboring communities rather than all individuals in each infected community. In
this context, assuming that there exist only “infected” and “uninfected” communities as postulated in [29]
2 As the disease affects people from different age groups, ethnicities and regions in a highly disparate manner [18]; it has also been reported
that mortality rates across different populations can deviate by as much as two orders of magnitude [19]; furthermore, recent studies also suggest
that women exhibit significantly milder symptoms than men as they have more responsive immune systems. The World Health Organization
(WHO) has also repeatedly issued testing guidelines that suggest “suspect influenza should be tested with consideration for geographical, gender
and age representativeness” in order to contain the spread of the disease in real-time.

3

appears unrealistic. “Heavily infected” community detection as well as heavy hitter problems arising in Covid19 are discussed in Section IV.
We argue that the availability of (semi)quantitative test outcomes and the use of adaptive strategies can greatly
increase the efficiency and scalability of Covid-19 testing schemes. In that direction, we generalize the Semiquantitative Group Testing (SQGT) strategy [30]–[32] to an adaptive setting and devise simple probabilistic adaptive
GT methods3 and worst-case adaptive GT schemes that take the specific measurement data noise and quantization
properties into account. The SQGT scheme assumes that one cannot tell the exact viral load or number of infected
individuals in a pool but only an interval in which the load or number of defectives lies. The setting is a generalization
of GT that includes more than two outcomes, or a quantized version of the adder channel/CS approach [35], [36]. It
also represents a generalization of the setting [37] in which only saturation effects are taken into account within the
adder model. It is worth pointing out that this is also the first approach that uses actual RT-PCR features and also
postulates rigorous models that allow for relating viral loads to actual fluorescence values and analyze the testing
schemes rigorously. Other methods that will be reviewed in later sections either completely ignore the RT-PCR
measurements or do not properly justify or analyze their proposed models.
For an illustration of the differences between various testing schemes (group testing, additive tests, additive tests
with saturation, and general SGQT), the reader is referred to Figure 1.

Figure 1: Figure (a) illustrates the classical GT framework. Here, 0 corresponds to a test outcome that is indicative of no infected individual
being present, while 1 corresponds to an outcome indicative of at least one infected individual. Figure (b) represents an additive test output
model, in which the underlying assumption is that one can tell the exact number of infected individuals in a test. An instance of the general
SQGT is illustrated in Figure (c). In this case, the test outcome r`{τs “ i for i ą 2 indicates that pi ´ 2qτ ď ` ď pi ´ 1qτ defectives are
present. When the number of defectives detected is ą pm ´ 1qτ, the test reports m. When τ “ 1, (c) represents an adder model with saturation.

For the worst case setting, in which we assume a known number of d defectives, but make no assumptions about
how they are distributed, and where one can tell if zero defectives were present, or the number of defectives is
nonzero and lies in one out of m consecutive intervals of length τ, the number of tests per defective roughly equals
log pn{dq ` log logpm ` 1q
.
logpm ` 1q
The savings in the number of tests as compared to the classical GT setting provided by the increased resolution of
the levels is logpm ` 1q-fold, which even for 7 levels amounts to three-fold savings. Clearly, one has to be able to
properly calibrate the RT-PCR readouts and determine adequate thresholds in order to take full advantage of the
scheme. This issue will be addressed in Section II.
For the probabilistic setting, where each item is assumed to be independently defective with some probability, our
main results include simple-to-implement algorithms for adaptive testing that involve two thresholds and two test
stages, and are also capable of handling heavy hitters (i.e., individuals with high viral loads that may mask other
individual’s presence, provided these individuals are not too common.)
3 The quantifier “probabilistic” may refer to either the individuals being ill according to some probability distribution (usually iid Bernoullippq,
or generalized binomial [33] or Poisson [34], where the number of infected individuals has a right-truncated Poisson distribution with parameter
λpnq “ opnq; Dorfman’s scheme falls into the first category.) or, the test matrices having entries dictated by a probability distribution (again,
usually iid Bernoullipqq). Some papers refer to the former setting as “group testing with probabilistic priors” and the latter setting as “group
testing with probabilistic tests.” Which paradigm we refer to will be clear from the context.

4

The remainder of the paper is organized as follows. Section II provides an overview of the PCR, RT-PCR and the Real
Time (Quantitative) PCR techniques. The section also addresses key issues that impede the amplification efficiency
of the methods currently used for Covid-19 testing and introduces several practical noise models. Section III
describes various GT approaches and assesses their utility for Covid-19 testing. Sections IV and V describe the
main original results. Section IV describes a probabilistic version of a SQGT model, simplified to account for two
rounds of testing and two test thresholds only. This section also introduces test schemes that aim to identify highly
virulent individuals, termed heavy hitters. Section V introduces a new worst-case adaptive SQGT technique that
is near-optimal and describes a noise model termed the birth-death chain model. Section VI provides preliminary
directions towards designing efficient community-aware testing strategies. Section VII reports the results obtained
using the GISAID database [38] that explain the influence of mutations in the primer regions on the efficiency of
the tests and therefore suggests that noise models previously considered in the literature that only account for errors
in the PCR test are inadequate. Section VIII concludes the paper and discusses future work.
II. BACKGROUND
We start our exposition by describing the real-time reverse transcriptase (RT-PCR) testing mechanism. DNA has a
double helix structure and both strands in the helix are composed of periodic sugar and phosphate groups to which
one of four different bases is attached, namely A, T, C, and G. A sugar, phosphate, and base are jointly referred
to as a nucleotide. As the sugar is asymmetric in terms of the placement of its carbon atoms with respect to the
position of binding to the phosphates, the two strands of the DNA have two different directions: One runs from the
3’ to 5’ carbon end, while the other runs from the 5’ to 3’ carbon end. The two strands are held together through
the stacking of bases and the hydrogen bonds that exist between them. The pairing rule is dictated by Watson-Crick
(WC) complementarity asserting that only (or with overwhelming probability) the bases A and T and G and C bind
to each other, respectively.
A. Reverse Transcriptase PCR
The Reverse-Transcriptase PCR (RT-PCR) technique is used to identify/amplify RNA strands. Since RNA is singlestranded and hence an unstable molecule, RT-PCR first converts the target RNA into its complementary doublestranded DNA (cDNA, as illustrated in Figure 2) and then performs amplification using the standard PCR technique.
Note that RNA has three of the same building blocks as DNA, namely A, C, and G, but instead of T (encountered
in DNA), RNA contains U (Uracil).
Conversion of RNA into cDNA is accomplished through the use of the reverse transcriptase (RT) enzyme that
stitches together “free” nucleotides A, T, C, and G together, in the presence of primers that are complementary to a
specific part of the target RNA sample (see Figure4 2 ). Since RNA is inherently single-stranded, the primers have
an affinity to attach to the complementary RNA regions, recruit the RT enzyme and thereby initiate synthesis. The
process proceeds through two steps: In the first step, the first-strand cDNA is created using the single-stranded RNA
as a template. In the second step, the second-strand cDNA is formed by using the first-strand cDNA as template.
Consequently, the product cDNA represents an accurate replica of the original RNA content, converted to the DNA
alphabet.
The test results are usually compared to a control as a means to assess the quality of the experiment. RT-PCR is used
to detect RNA viruses, i.e., viruses whose genomic content is stored in RNA rather than DNA. SARS-Cov-2, the
virus causing Covid-19, is an RNA virus, as is for example the HIV virus that causes AIDS. For viral detection, the
first step of testing involves isolating genomic RNA by breaking the viral membrane, but this and other processes
that lead to actual sample isolation will not be discussed in this short review.
The Covid-19 detection and amplification process relies on standard RT-PCR methods and RT-PCR and its
quantitative version described next.
B. The Polymerase Chain Reaction (PCR)
The Polymerase Chain Reaction (PCR) is used to amplify specific segments of the DNA strands in order to enable
a downstream analysis of the segments or to detect the presence of specific DNA content. The operating principles
4 Reverse

Transcriptase image is from Wikipedia.

5

Figure 2: Reverse transcription for converting viral RNA into cDNA.

of the PCR process are illustrated in Figures 3 and 4. A Thermal Cycler uses the target DNA, specific primers
(short DNA segments that initiate the replication process by allowing the polymerase to bind to the DNA), the
taq polymerase (which actually performs DNA replication after the primers get attached), and free A (Adenine),T
(Thymine), C (Cytosine) and G (Guanine) nucleotides needed to amplify the segment of interest through repeated
cycles that involve the following steps: DNA denaturation, annealing, and extension.
1) DNA Denaturation: The DNA sample to be amplified or detected is first heated to 960 C. At this temperature,
hydrogen bonds between the bases across the two strands break, producing two complementary single-stranded
DNA fragments.
2) Annealing (Hybridization): The sample is subsequently cooled to 550 C. This allows the primers to bind to
their WC complementary segments on the two single-stranded DNA targets. The primer that binds to the
forward strand is referred to as the forward primer while the one that binds to the reverse strand is referred
to as reverse primer.
3) Extension: The sample is heated to 720 C to enable the taq polymerase to extend the primers to form two
complete copies of the original double-stranded DNA molecule.
Under ideal conditions, at the end of the Extension step of a cycle, the amount of target DNA doubles. This
setting is illustrated in Figure 3. However, due to several factors [21] including the efficiency of denaturation,
primer annealing affinity, polymerase binding strength, and others, the DNA content may not double during each
cycle. For example, denaturation requires heating the sample to a higher temperature which by itself may cause

Figure 3: Polymerase Chain Reaction: In any given cycle, the DNA strands in the sample are first denatured into single-strands. The two
single-strands are then extended to form complete DNA double-helixes. The primers (short DNA fragments) are attached to the single-stranded
DNA such that extension is facilitated in the 3’-5’ direction. At the end of each ideally executed cycle, the number of DNA strands in the
sample doubles.

oxidative and other damages to the DNA being amplified. The efficiency of denaturation is measured in terms of
the concentration of viable single-stranded DNA present after heating.

6

During the primer annealing stage, single-stranded DNA strings previously denatured can anneal back, therefore
prohibiting access to the primer segments. The primer annealing efficiency is captured by the proportion of singlestranded DNA with bound primers.
When the polymerase binds to the DNA-primer complex it forms a potentially unstable tertiary complex in which the
polymerase can disassociate in a stochastic manner. The polymerase binding efficiency is captured by the fraction
of tertiary products in the assay. The tertiary complexes formed during the early stage of a cycle are more likely
to result in complete double-stranded DNA compared to those formed in a later stage of the cycle, due to cycle
timing issues. This effect is captured through what is known as the extension efficiency of PCR.
These effects jointly contribute towards the reduction of the average efficiency of DNA amplification, which goes
down from the expected doubling factor to some value ă 2, usually written as p1 ` ηq, where η is referred to as
the cycle efficiency. The doubling of the target material at every cycle corresponds to η “ 1. At the end of i cycles,
a sample with concentration x DNA strands is amplified to a sample with concentration xp1 ` ηqi . More precisely,
the cycle efficiency depends on the cycle number. Consequently, a more accurate amplification model should use
the factor η j for cycle j, so that the amplified concentration after the ith cycle reads as x ¨ Πij“1 p1 ` η j q. It is also
known that η j decreases with j, which may be attributed to the fact that the primers used for amplification are more
and more integrated into the DNA products and that the efficiency of the polymerase decreases. At the same time,
for a small number of cycles (usually i ď 10) the DNA products are hard to detect. As a result, it is a common
practice to run 30 ´ 40 cycles of PCR, depending on the expected original concentration of the double-stranded
DNA to be amplified.
Note that the polymerase can also be active at temperatures below 720 C, thereby initiating the extension process.
However, the polymerase is non-specific at lower temperatures and leads to amplification of non-specific DNA
strands. The high concentration of the stronger and more stable GC bonds in the DNA strands hinders effective
denaturation at 960 C. Regions with high GC bond concentration also form secondary products that prevent primer
bonding [39]. These phenomena all jointly contribute to “noise” in the amplification PCR process which is not
associated with the cycle efficiency. Additional sources of noise such as CCD thermal noise and shot noise can
lead to a further decrease in the reliability of data points at low signal levels [40].
Also, primers may fail to attach to the DNA if the corresponding DNA primer regions contain mutations (indels
or point mutations). Since the error is caused by the actual DNA sample strand, and not the PCR process, this
phenomenon should not be considered as part of the PCR noise model. The results of a simulation that studies the
effect of mutations along the primer region on PCR amplification are described in Section VII, using a collection
of real genomic datasets retrieved from the GISAID database [41].

Figure 4: Under ideal conditions, every cycle of the PCR process should double the DNA content. Due to various factors, described in the main
text, not every cycle may result in twice as many strands and an averaged efficiency factor η ă 1 is used to describe the growth rate of the
PCR product.

7

C. Quantitative (real-time) RT-PCR
Quantitative Real Time PCR (qPCR) is a technique used for precise analysis of viral and bacterial samples. As
implied by its name, qPCR allows for the amplification process to be monitored in real-time. This is achieved by
introducing fluorescent labels into the DNA products and recording the change in fluorescence with an increasing
number of cycles (which also allows for estimating the number of cycles needed to detect an appropriate product).
The result of a qPCR experiment is usually given in terms of an amplification curve (an example of such a graph is
shown in Figure 7, where real measurements are approximated by piecewise polynomial fragments of degree ď 10).
The amplification curve plots the normalized (relative) fluorescence ∆Rn against the cycle number. The fluorescence
increases with the increase in the target genetic material with every cycle until the fluorescence saturates. The cycle
number for which the fluorescence crosses the detection threshold (which can be defined in several ways) is referred
to as the cycle threshold, and denoted by Ct . Note that Ct is inversely proportional to the concentration of the target
material in the sample: A low Ct value indicates a higher concentration of the sample we wish to detect, while a
high Ct value indicates a low concentration of the same or spurious amplification results. The slopes of the curves
most often show very small variations with the concentration of the subject but may potentially be used as further
indicators of the sample load.
Real-time or qPCR is usually performed using one of the following two approaches:
Dye-based qPCR. The dye-based method uses dyes that only fluoresce when bound to double-stranded DNA.
Thus, at the end of each extension stage, the fluorescence increases (see Figure 5). The chemistry of the
dyes used helps in distinguishing desired and undesired products. However, the dye-based method is often
nonspecific, thereby inaccurately quantifying genetic material that is not of interest. As a result, this approach
requires highly selective primers and other additional controls to provide accurate amplification curve results.
‚ Probe-based qPCR. In this technique, primers specific to the target DNA include two molecules, a fluorescent
reporter dye and a quencher on its two ends. When the quencher is in close proximity to the fluorescent
dye, the former molecule inhibits (quenches) the fluorescence of the latter. This is usually the case when the
primer is not bound to the target (see Figure 6). However, when the primer is hybridized to the target and the
polymerase extends the primer segment, the quencher and reporter separate out and the dye is cleaved and
displaced. In its free form, it fluoresces which leads to detectable signals.
‚

Figure 5: Dye-based qPCR: The dye attaches to the double-stranded DNA formed at the end of the extension stage and fluoresces. Thus, the
fluorescence measured increases with the number of cycles.

D. Amplification Curves and the Viral Load
From Figures 7 and 8, and as already discussed in the previous section, it is clear that one can estimate upper/lower
bounds on the viral load of an individual by observing the Ct value and the slope and saturation point of the
amplification curve. It is important to point out that the viral load of individuals may vary up to five orders of
magnitude, as shown in the recent study [42]. Viral loads in infected individuals tend to follow a “typical” invertedV dynamics shown in Figure 9. There, it can be seen that an individual tested 3 ´ 5 days after the infection may

8

Figure 6: Probe-based qPCR: When DNA is denatured, a primer specific to the target DNA is attached to a single strand. The primers are then
attached and extended by the polymerase. During the extension, the probes are cleaved and the reporter dye is no longer in the proximity of
the quencher molecule, which enables it to fluoresce.

Figure 7: A typical amplification graph, plotting the relative fluorescence versus the number of PCR cycles for various input concentrations
of the DNA sample. The dots represent actual fluorescent levels, while the curves represent a degree-10 polynomial approximation of the
measurements. Since the solid curves are approximations, the fluorescence level for a small number of cycles can be negative, which is clearly
not physically possible. Simple, yet less precise piecewise linear and quadratic curves will be described when discussing error models for realtime PCR. Also, note that the fluorescence saturates after roughly 35 ´ 40 cycles which shows that models that use the final cycle fluorescence
cannot distinguish viral loads. Another observation is that due to the stochastic nature or RT-PCR it usually takes around 5 ´ 10 cycles to obtain
visible fluorescence, independent of the viral load. Both of these features demonstrate the highly nonlinear relationship between the viral load
and the fluorescence.

have a viral load that is large enough to mask any other individual tested by the same test under the GT framework.
This is a sensitive issue for SQGT schemes as the Ct curves may have multiple interpretations: As an example,
the same Ct value may correspond to 10 ´ 100 individuals tested 5 ´ 6 days after infection or one individual
tested 3 days after infection. There are multiple possible ways to mitigate this problem: First, given that high viral

9

Figure 8: Amplification curves and quantization regions for the Ct values. Given a number of amplification curves used for calibration in
a specific lab, the quantization regions in this example are chosen based on the intersection of the fluorescence detection level 500 and the
calibration amplification curves. A Ct value for a particular experiment is placed in the quantization region bounded by the two “closest”
amplification curves used for calibration and their underlying Ct values, or into the corresponding quantization bin. In this particular example,
except for the quantization regions corresponding to the early and late cycles, the quantization regions are of nearly-uniform length. Note that
the larger the Ct value, the lower is the viral load. Also, if one were to only use the fluorescence levels observed at the final RT-PCR cycle
(i.e., cycle number „40), the results would be noninformative with respect to the viral load as a strong saturation effect comes into existence.

loads very often positively correlate with observable disease symptoms [43],5 asking individuals about symptoms
before scheduling the tests (as is, for example, done at UIUC [44]) allows one to determine if the individual should
be group-tested or not. Another approach is to perform adaptive testing where samples with large viral loads are
subjected to additional screenings, as is done in one of our proposed methods. Specialized testing strategies for
pooled measurements with high viral loads can also be devised using heavy-hitter detection methods [45].
As an abstraction, and only for our worst-case analysis we assume that each individual is represented by a viral
load equal to the expected value over the tested population. In this case, the test outcome can be translated into an
interval in which the number of infected individuals lies. Hence, the assumption in this case is that one can convert
Ct values into a rough estimate of the number of infected people in the test. For probabilistic testing, we do not
have to rely on such assumptions as the testing scheme itself can be easily adapted to handle heavy hitters.
III. BASICS OF GT
In what follows, we provide concise overviews of all relevant GT schemes used or proposed for potential use
for Covid-19 testing: (1) Classical nonadaptive and adaptive GT; (2) Nonadaptive SQGT; (3) Threshold GT; (4)
Compressive sensing (CS); (5) Graph-Constrained GT. For all these methods, we describe their potential advantages
and drawbacks and then proceed to introduce a new method, which we refer to as adaptive SQGT. Adaptive SQGT
with a “curve fitting”-based noise model appears to provide the theoretical state of the art GT results for qPCR test
models and is the focus of our subsequent discussions.
A. Nonadaptive and Adaptive GT
The assumptions are as follows: In a group of n individuals, there are d infected people. When a subset of people are
tested, the result is positive (e.g., equal to 1) if at least one person in the tested group is infected, else the test result
is negative (e.g., equal to 0). Such a testing scheme is referred to as binary, as the outcomes take one of two values
(see Figure 1 (a)). GT aims to find the set of all infected people with the fewest number of binary tests possible and
may use nonadaptive and adaptive tests. In the former case, all tests are performed simultaneously and the outcome
5 According to this study, among the set of infected patients, those who exhibited “severe" symptoms had significantly lower C “ C psampleq ´
t
t
Ct preferenceq values than those who exhibited “mild” symptoms.

10

Figure 9: A typical viral load dynamics in an infected individual versus the time since infection. The viral load sharply spikes within the first
three days of infection and then more gradually decreases. The nonlinear part of the viral load curve can be approximated by a linear component
symmetric with respect to the linear component. This linear approximation will be used to determine the probability of heavy hitters, i.e.,
individuals who have an absolute viral load above 106 .

of one test cannot be used to inform the selection of the individuals for other tests. In the adaptive setting, one can
use multiple stages of testing and different combinations of individuals to best inform the sequentially made test
choices.
When d ! n, it is well-known that Ωpd ¨ logpn{dqq number of tests are required to find all infected individuals.
Furthermore, it was shown in [46] that for NAGT, at least Ωpd2 ¨ logpnq{ logpdqq tests are required. For the same
parameter regime, there exist explicit nonadaptive schemes that require O pd2 ¨ logpn{dqq tests to find the infected
group [47]. A four-stage adaptive scheme that uses an optimal number of tests that meets the lower bound was
recently described in [48]. Of special interest is the classical binary search result of [49] which established an
elegant adaptive scheme that differs from the information-theoretic limit only by an additive O pdq term.
Despite the many proposed applications of this model to Covid-19 testing, it is obvious from the previous discussion
that the GT measurement outcomes do not fully use the actually available qPCR results. One could argue that the
fluorescence exceeding the detection threshold may correspond to the test outcome 1, but clearly, significantly more
information is available as the detection threshold depends on the concentration of the viral cDNA and hence the
number of infected individuals. This motivates using a more quantitative GT approach, already introduced under
the name of SQGT.
B. Nonadaptive SQGT
In SQGT, one is given a collection of thresholds 0 “ τ1 ă τ2 ă ¨ ¨ ¨ ă τr , and the outcome of each test is an
interval pτi , τi`1 s, where 0 ď i ď r ´ 1. The outcome of an experiment cannot specify the actual number of infected
individuals but rather provides a lower and upper bound on that number, τi´1 and τi , respectively. If τi “ τi´1 ` 1
for all values of i and r “ d, the scheme is referred to as additive GT, or the adder model [35], [36]. The two
models are depicted in Figure 1 (b) and (c). The additive test model described in [36] requires 2 ¨ pn{ log nq tests
to determine all possible infected individuals, for 0 ď d ď n.
Another special SGT case of interest assumes that the test results are additive up to some threshold τ and after
that, they saturate [37] (see Figure 1). This model is of special interest for Covid-19 testing as it takes the
warm-up/saturation information into account and, in addition, under a proper noise model, captures the fact that
amplification graphs have different Ct values determined by the concentration of the viral load (an hence the
approximate number of infected individuals). Furthermore, one can argue that the RT-PCR fluorescence intensity

11

information is inherently semiquantitative [30] as the fluorescence levels and Ct values can be placed into bounded
bins determined by the number of cycles. This observation is explained in more detail in the next section, along
with new theoretical results pertaining to adaptive SQGT schemes with appropriate noise models.

Figure 10: The birth-death noise model. Here, the assumption is that the Ct value can be corrupted by noise only in so far that they can be
mislabeled as belonging to intervals adjacent to the correct interval (except for the values falling into the first and last quantization region or
bin).

C. Threshold GT
An extension of the GT problem was introduced by Damaschke in [50]: In this setting, if the number of defectives
in any pool is at most the lower threshold ` ą 0, then the test outcome is negative. If the number of defectives
in the pool is at least the upper threshold u ą `, then the test outcome is positive. However, if the number of
defectives in the pool is between u and `, the test outcome is arbitrary (i.e., either 0 or 1). Thus, the algorithms
for Threshold GT are designed to handle worst-case adversarial model errors. Note that when ` “ 0, and u “ 1,
Threshold GT reduces to GT. It is known that for nonadaptive threshold GT, O pd ¨ g ` 2 ¨ plog dq logpn{dqq tests
(where g “ u ´ ` ´ 1) suffice to identify the d infected individuals [51].
The Threshold GT model is partly suitable for modeling the qPCR process, as the lower threshold can obviously
assume the role of the fluorescence-based detection threshold, ` “ Ct ; unfortunately, due to the saturation
phenomena, a specialized choice for the upper threshold u does not allow one to accurately assess the number
of infected individuals in the pool. The “in-between” threshold results also make the simplistic assumption that
despite the observed fluorescence value being closer to the upper threshold, one can still call the outcome negative
(and similarly for the small fluorescence levels and the lower threshold).
D. Compressive Sensing
In compressive sensing, the defectives are represented by nonnegative real-valued entries. Thus, quantitative GT
represents a special instance of compressive sensing. Compressive sensing assumes that one is given an unknown
vector x P Rn , in which only d ! n entries are nonzero. The vector x is observed through linear measurements
formed using a measurement matrix M P Rmˆn , leading to an observed vector y “ Mx ` n, where n is the
measurement noise (usually taken to be Gaussian N p0, σ2 q). For noiseless support recovery, m “ O pd ¨ log nd q
measurements are sufficient. For exact support recovery in the noisy setting, a signal-to-noise-ratio S of Ωplog nq
is required for the same number of measurements as needed in the noiseless setting [52]. Compressive sensing
reconstruction is possible through linear programming methods or low-complexity greedy approaches [53]–[55].
The recently proposed Tapestry method [56] combines group testing with compressive sensing and uses combinatorial designs (i.e., Kirkman systems) to construct the measurement matrix. However, there are several factors that
do not seem to be accounted for in this approach. First, Tapestry assumes a CS framework, which is additive and
applies to viral loads. But the PCR measurements report fluorescence levels, and these are nonlinear functions of
the viral load. Furthermore, it does not account for the stochasticity of the PCR measurements and that different
lab protocols may lead to different Ct values when presented with the same sample mixture. Tapestry also does not
take into account the fact that the number of RT-PCR machines/staff members is limited6 , and that this inherently
suggests using adaptive testing strategies.7 Finally, the CS methods [56] rely on Gaussian assumptions regarding
measurement errors due to cycle inefficiency that are often hard to verify (and do not take into account that the
6 PCR

tests are performed on samples typically organized in 96 wells, each of which can be used for one (group) test.
a related question in the context of group testing microarrays and quantized compressive sensing, the interested reader is referred
to [57]–[59]).
7 For

12

efficiency decays with the number of cycles and with the number of potential mutations in the primer regions; see
Section II). As many other quantitative methods, it appears vulnerable to heavy hitters, which are not accounted
for in the Tapestry scheme.
Nevertheless, there seem to be multiple advantages of CS methods for Covid-19 testing: One should be able,
in principle, to recover not only the infected individuals but their viral loads as well. In particular, integer
and nonnegative CS testing, along with quantized CS approaches can impose model restrictions on such testing
schemes [58], [60] to render them more suitable for the problem at hand.
The only other work that explores quantitative testing for Covid-19 is reported in [61]. There, the same problem
setup as in [56] is used to postulate an additive viral load model which does not refer further to the Ct values.
The new contribution is a proposal for a two-stage testing scheme that bears a small resemblance to our methods
in so far that we also propose two-stage adaptive pooling schemes. However, the techniques used are different
since [61] employs a combination of maximum likelihood and maximum-a-posteriori estimators to determine the
infected individuals in the second stage, while we employ zero-error GT and SQGT techniques to find all infected
individuals. Additionally, while [61] reports the number of tests and conditional false positive and conditional
false negative rates for the simulation experiments, we supplement our new schemes with theoretical analysis and
performance guarantees.
E. Graph-Constrained GT
Let G “ tV, Eu be a graph with vertex set V, |V| “ n, and edge set E, representing a connected network of n
people out of whom d are infected. In graph-constrained GT, vertices participating in the same test are restricted
to form a path in the graph [62]. This model is relevant as it can be adapted to require that only individuals that
did not have contacts with each other are tested together (one only has to apply the problem to the dual of the
contact graph used in Covid-19 testing). This allows us to identify individuals that fell ill in an “independent”
fashion rather than through contact with each other. If Tpnq denotes the mixing time of the random walk on the
graph, and c “ ∆∆max is used to denote the ratio between the maximum degree and the minimum degree of the
min
graph, then no more than O pc4 ¨ d2 ¨ T 2 pnq logpn{dqq tests are required to find the set of infected vertices. For
example, a complete graph (Tpnq “ 1, c “ 1) requires no more than O pd2 ¨ logpn{dqq tests since it corresponds to
the classical GT regime. Unfortunately, graph-constrained GT requires a significantly higher number of tests than
classical GT methods as the tests are inherently restricted. As a result, despite the fact that this scheme is a natural
choice for problems such as network tomography where these constraints need to be satisfied, it is not a proper
choice for Covid-19 testing. Another “community-constrained” (although without an underlying interaction graph)
was recently proposed in [29] and is discussed in the next subsection.
F. Community-Aware GT
In order to incorporate the underlying community network information, the authors of [29] introduced a communitybased testing paradigm. The goal of the scheme is to devise methods that use community structure to guide the
schedule of group tests.
More precisely, a community of n members is assumed to have d ! n infected individuals. The population is
partitioned into F families. In the combinatorial infection model, it is assumed that d f families have at least one
infected individual and that all the members of the remaining
ř families are infection-free. An infected family indexed
by j is assumed to have dp jq infected members so that d “ iF“1 dp jq . The testing scheme can be succinctly described
as follows: A representative individual from each family is selected uniformly at random. The representative
community members are tested using either an adaptive or a nonadaptive GT algorithm. Family members whose
representatives tested positive are tested individually. Members from the remaining families are tested together
using either an adaptive or a nonadaptive GT scheme. As proposed, the scheme has several drawbacks. First, in
practice, it is advisable to quickly identify heavily infected (heavy hitter) families and then quarantine members
of such communities [63]. Also, testing each person in a community that may have only one infected individual
seems overly cautious and prohibitively expensive. We address this issue in terms of what we call the heavyhitting community detection model described in Section VII. Second, [29] ignores interactions between members of
different communities, which are crucial for spreading the disease. Third, the PCR noise is modeled as a Z-channel,
in which a positive sample can test negative but a negative sample cannot test positive. As we will see in Section V,

13

nonspecific hybridization due to either poor primer selection or mutations can actually render negative tests positive.
On the other hand, qPCR is very sensitive - even 10 viral fragments are enough to detect fluorescence. Hence, false
negative errors overwhelmingly arise from inadequate sample collection or bad sample collection timings (when
the individual is just infected or almost recovered from the disease, see Figure 4). This fact is clearly supported by
the study in [64], which established that roughly 93% ´ 98% of individual samples have viral loads at least three
times higher than the detection threshold so that false-negatives due to PCR are highly unlikely.
Before proceeding with the original contributions, we remark that all the above GT techniques and scheduling models
have probabilistic counterparts in which each individual is assumed to be infected with the same probability p [6] or
members of different communities are infected with different probabilities, pi , i “ 1, . . . , F [33]. The latter setting
is especially important when prior information about the individuals is known (for example, their risk groups,
potential symptoms etc). For an excellent in-depth review of these and some other GT schemes, the interested
reader is referred to [7].
IV. AC-DC: N EW A MPLIFICATION C URVE BASED A DAPTIVE S CHEMES - T HE P ROBABILISTIC S ETTING
Next, we introduce two adaptive SQGT schemes, one which is suitable for probabilistic testing and another one
that is worst-case and nearly-optimal from the information-theoretic perspective. In the former case, considered
in this section, a simple two-stage testing scheme is designed and analyzed with the goal of enabling practical
implementations of adaptive SQGT. The results are described for two thresholds only, but a generalization is
straightforward. This scheme also allows for incorporating heavy hitters into the testing scheme, which is of great
practical relevance. In the worst-case, which is considered in the section to follow, the schemes extend the ideas
behind Hwang’s generalized splitting [49] in two directions that lead to algorithms using what we call parallel
and deep search, respectively. In both settings, the outcomes of the first round of testing inform the choice of the
composition of the test in the rounds to follow. The methods are collectively referred to as the AC-DC schemes, in
reference to the use of the information provided by the amplification curve (AC) during the process of diagnostics of
Covid-19 (DC). A relevant observation is that the worst-case adaptive schemes allow for using nonuniform amounts
of genetic material from different individuals, which may be interpreted as using nonbinary test matrices.
A. Practical Adaptive AC-DC Schemes
We describe next a simple probabilistic two-stage AC-DC scheme that significantly improves upon the original
single-pooling scheme of Dorfman and builds upon the SQGT framework. The underlying idea is to follow the
same overall strategy as in the single-pooling scheme, but exploit the SQ information obtained in the first stage
to perform better-informed testing in the second stage (i.e., dispense with individual testing of all individuals that
feature in infected pools as part of the second stage).
Consider a scenario where we have access to semiquantitative tests that return one of three values: If no individual
featured in the test is positive, the test returns 0. If between 1 and τ individuals are positive, for some threshold
τ ě 1, the test returns 1. Finally, if more than τ individuals test positive, the test returns 2. This scheme can be
interpreted as follows: Suppose that Ct is the observed cycle thresholds (defined in Section II-C for a particular
test). If Ct ą c1 for some large threshold c1 , we say that the outcome is 0 as the potential viral or viral-like
contamination load is too small to claim the presence of an infected individual. If c2 ď Ct ď c1 , we say that
the output is 1 and based on the average viral load, convert this into the maximum possible number of infected
individuals τ. If Ct ă c2 , we say that the output is 2 and that more than τ individuals in the pool are affected.
For the new single-pooling AC-DC scheme, we assume that the population contains n individuals, each of which
is independently positive with some probability p (Which can be easily determined based on regional infection rate
reports: For example, at UIUC in September/October 2020 [44], p » 0.05), and proceed as follows:
1) Stage 1: Divide the n individuals into n{s disjoint pools S1 , . . . , Sn{s , each of size s;
2) Stage 2:
If a pool Si tests 0, then immediately set the status of all individuals P Si as “negative”.
If a pool Si tests 1, then apply a nearly-optimal zero-error nonadaptive group testing scheme to detect
the t infected individuals in Si . (Such a testing scheme is simple to design: It suffices to sample a random
binary matrix where all entries are i.i.d. according to some Bernoullipqq distribution, 0 ă q ă 1. This is so

14

since the resulting matrix will be a zero-error NAGT scheme with high probability provided the number of
rows is large enough.)
If a pool Si tests 2, then test all individuals P Si separately.
Given the description above we can compute the expected number of tests per individual of the testing scheme, T{n,
as a function of the probability of infection p, the first-stage pool size s, and the threshold τ. Using the fact that
the zero-error nonadaptive GT schemes we use in the second stage can be designed with mps, τq “ c ¨ τ 2 logps{τq
tests, we conclude that
c ¨ τ 2 logps{τq
1
` p2 ,
(1)
ErT{ns “ ` p1 ¨
s
s
where p1 “ Prr1 ď Bps, pq ď τs and p2 “ PrrBps, pq ą τ ` 1s denote the probability that a given pool tests 1
and 2, respectively. Here, Bps, pq stands for a binomial random variable with s trials and success probability p.
A particular case of interest pertains to setting τ “ 1 in (1). For a small probability of infection p, the optimal
threshold τ is close to 1 which justifies this choice. In this case, we have p1 “ s ¨ pp1 ´ pqs´1 and p2 “ 1 ´ p1 ´
pqs ´ s ¨ pp1 ´ pqs´1 . Moreover, it is well-known that, for any s, there exists a simple (and optimal) zero-error
nonadaptive scheme for finding 1 defective among s items using mps, 1q “ rlog ss tests (namely, set the i-th column
of the test matrix to be the binary representation of i, i.e., use a Hamming code parity-check matrix for testing).
Combining these observations together with (1), we conclude that the expected number of tests per individual when
τ “ 1 equals
1
` pp1 ´ pqs´1 rlog ss ` 1 ´ p1 ´ pqs ´ s ¨ pp1 ´ pqs´1 .
(2)
s
On the other hand, the expected number of tests per individual for the basic single-pooling scheme [6] is
1
` 1 ´ p1 ´ pqs ,
s
and the expected number of tests per individual for the double-pooling scheme [9] is

(3)

2
` p ` p1 ´ pqp1 ´ p1 ´ pqs´1 q2 .
(4)
s
We compare the optimal expected number of tests per individual (as a function of p) achieved by our semiquantitative
single-pooling scheme with τ “ 1 (given in (2)) and the single- and double-pooling schemes (given in (3) and (4),
respectively) in Figure 11. Semiquantitative single-pooling outperforms the other methods considered here as shown
in the figure. This is in particular true for p ď 0.05, which we already pointed out corresponds to a practical
parameter value.
expected tests per individual
0.35
0.30

single-pooling

0.25
0.20

double-pooling

0.15

semiquant single-pooling (t=1)

0.10
0.05
0.01

0.02

0.03

0.04

probability of infection

Figure 11: Comparison between the expected number of tests per individual required by Dorfman’s single-pooling scheme [6], the Broder-Kumar
double-pooling scheme [9], and our semiquantitative single-pooling scheme.

There are two directions to further improve our scheme:
‚

We can easily extend the simple ideas presented above to obtain a semiquantitative version of double-pooling,
and, more generally, multi-pooling schemes. The algorithm for this setting is summarized below:
1) Stage 1: Repeat Stage 1 of the previous semiquantitative scheme twice in parallel. We say an individual
tests pa, bq if its first pool tests a and its second pool tests b.

15

2) Stage 2:
If an individual tests p0, bq or pa, 0q, immediately mark it as negative;
If an individual tests p1, 1q or p1, 2q, then apply a zero-error nonadaptive GT scheme for τ defectives
to its first pool.
If an individual tests p2, 1q or p2, 2q, test them individually.
‚ We may also improve the performance of our semiquantitative scheme by introducing more (sufficiently small)
thresholds τ1 ă τ2 ă ¨ ¨ ¨ ă τ` and extending the original idea in a natural way: If a pool has between τi´1
and τi infected individuals, then apply a nearly-optimal zero-error NAGT scheme that detects τi infected to
the pool in question.
B. Probabilistic SQGT with Variable Viral Load
It is also simple to analyze how the SQGT scheme from the previous section performs when infected individuals
may have either low or high viral loads, i.e., it is straightforward to account for heavy hitters. To this end, we
consider a simplified model where each individual is independently infected and presents a low viral load at the time
of testing with probability pi1 , or is infected and presents a high viral load at the time of testing with probability
pi2 . In particular, each individual is infected (regardless of her/his viral load) with total infection probability p “
pi1 ` pi2 ă 1.
As already explained, individuals with high viral load are problematic because, based on the SQ output of RT-PCR,
pools featuring one such individual may be mistaken for pools with several infected individuals with low-to-average
viral load.8 This phenomenon naturally leads us to consider the following modified version of the testing method
studied in Section IV-A: A test applied to a pool of individuals has outcome 0 if there are no infected individuals
in the pool, outcome 1 if there exists exactly one infected individual with low viral load, and 2 if either there
exists more than one infected individual with low viral load, or at least one infected individual with high viral load.
Therefore, as expected, individuals with high viral load obfuscate the test outcomes.
We consider now the SQGT scheme described in Section IV-A with τ “ 1 and under the heavy-hitter model. The
probability that a pool of size s contains exactly one infected individual with low viral load and zero individuals
with high viral load (leading to test outcome 1) is
s ¨ pi1 ¨ p1 ´ pi1 ´ pi2 qs´1 “ s ¨ pi1 ¨ p1 ´ pqs´1 ,
while the probability that the pool contains either more than one infected individual with low viral load or at least
one individual with high viral load is
1 ´ s ¨ pi1 ¨ p1 ´ pi1 ´ pi2 qs´1 ´ p1 ´ pi1 ´ pi2 qs “ 1 ´ s ¨ pi1 ¨ p1 ´ pqs´1 ´ p1 ´ pqs .
Combining these observations with the reasoning from Section IV-A, we conclude that the expected number of
tests per individual as a function of pi1 and pi2 is given by
1
` s ¨ pi1 ¨ p1 ´ pqs´1 ¨ rlog ss ` 1 ´ s ¨ pi1 ¨ p1 ´ pqs´1 ´ p1 ´ pqs ,
s

(5)

where p “ pi1 ` pi2 .
For fixed pi1 and pi2 , it is easy to numerically minimize the expression above as a function of s to find the
optimal pool size for the scheme under consideration. Figures 12 and 13 compare the expected number of tests
per individual required by different schemes for different values of the total infection probability p and the specific
infection probabilities pi1 and pi2 . The most practically relevant pair of parameters can be obtained from Figure 12,
under the assumption that heavy hitters are individuals who have viral loads above 106 . Thus, by approximating
the nonlinear portion of the viral load curve by a linear function, one can easily show that the probability that
an infected individual is a heavy hitter is proportional to the area of the highlighted triangle, and approximately
equal to 0.16 (which is used in Figure 12). Note that the reduction in the number of tests increases with p, and for
p „ 0.05, which is a realistic infection rate, the savings compared to nonquantitative testing are larger than 5%.
8 This is not problematic for binary group testing, where the test outcomes do not distinguish between one or several infected individuals in
the pool.

16

Although we considered only an SQ single-pooling scheme in this section, these ideas can be easily extended to
upgrade multi-pooling schemes with binary testing (such as the one from [9]) to exploit SQ test information under
a variable viral load. This would allow one to further improve on the expected number of tests required by [9].
expected tests per individual
0.40
0.35
0.30

single-pooling

0.25

double-pooling

0.20

semiquant single-pooling w/ variable viral load

0.15
0.10
0.05
0.01

0.02

0.03

0.04

probability of infection

Figure 12: Comparison between the expected number of tests per individual required by Dorfman’s single-pooling scheme [6], the Broder-Kumar
double-pooling scheme [9], and our semiquantitative semi-pooling scheme as a function of total infection probability p with pi1 “ 0.84p, pi2 “
0.16p.

expected tests per individual
0.40
0.35
0.30

single-pooling

0.25

double-pooling

0.20

semiquant single-pooling w/ variable viral load

0.15
0.10
0.05
0.01

0.02

0.03

0.04

probability of infection

Figure 13: Comparison between the expected number of tests per individual required by Dorfman’s single-pooling scheme [6], the Broder-Kumar
double-pooling scheme [9], and our semiquantitative semi-pooling scheme as a function of total infection probability p with pi1 “ 2p{3 and
pi2 “ p{3.

C. Adaptive SQGT with Priors
The above described probabilistic setting can be generalized to account for different priors for different individuals
by invoking the generalized binomial group testing scheme. Recall that Dorfman’s scheme assumes that each
individual has a probability p of being infected, independent of everyone else. The set of individuals is partitioned
into groups of size s, and each group is tested once. The group size s is selected to minimize the number of expected
tests.
Hwang extended this setting in [33] to account for the varying prior probabilities of infection. In this setting
every individual i P t1, 2, . . . , nu is assumed to have probability pi of being infected, and thereby a probability
of qi “ 1 ´ pi of not being infected. Clearly, in this generalized setting, a (possibly random) partitioning of the
individuals into groups of equal sizes is no longer the optimal strategy to for the first round of testing.
To find the optimal partition of the individuals in the generalized binomial setting, without loss of generality, one
may assume that the individuals are reindexed so that 0 ă q1 ď q2 ď . . . ď qn ă 1.
Given a subset of individuals to be tested, G Ď t1, 2, . . . , nu, let TpG q denote the expected number of tests required
to find the set of infected individuals in G by first jointly testing all the individuals in the group G and then testing
every member of G individually if the first test is positive. This number equals:
#
1,
if |G | “ 1,
TpG q “
(6)
1 ` p1 ´ Π jPG q j q|G |, otherwise.
Now, let DpU q “ tG1 , G2 , . . . , Gk u denote the optimal partition of the population U to be tested, where |U | “ n.
Let CpU q denote the total expected number of tests required to run the two-stage testing procedure on the optimal
ř
partition. Clearly, CpU q “ ik“1 TpGi q. Furthermore, let Um denote the set of m individuals with the highest

17

probability of being infected, i.e., individuals indexed by t1, 2, . . . , mu. The optimal partition and the corresponding
expected number of tests can be found by solving the following optimization problems:
CpUm q “

min

tTpUm ´ Ui q ` CpUi qu, 2 ď m ď n,

(7)

m´ L´1ďiăm´rp L`1q{2s

where L denotes the size of the largest group/part in DpUm´1 q. At step m of the optimization procedure, the
probabilities tp j u jďm and the previously computed CpU j q are used to determine DpUm q and the expected number
of tests CpUm q of the population Um . As a consequence of the structure of the program, one has the following
property for the optimal partition: If individuals i and j, j ą i, are in the same group, then all individuals k such
that i ă k ă j are in the same group as well (a simple induction argument can be used to prove this claim).
Next, assume that the population has only two types of individuals: m individuals that have a high p1 probability
of infection, and the remaining n ´ m individuals that have a low p2 ! p1 probability of infection. Exploiting the
structure of the optimization program and the fact that only two types of individuals are present in the test pool,
the optimal number of tests needed to find the set of infected individuals using the two-stage procedure equals:

„
˘ n´m´y `
˘
m´x `
s1
s2
x y
1 ` p1 ´ q1 qs1 `
1 ` p1 ´ q2 qs2 ` 1 xyą0 ` p1 ´ q1 q2 qpx ` yq ,
min
s1
s2
s1 , s2 , x, y PNYt0u
where x and y represent the number of individuals that have high and low probabilities of infection, respectively,
and are tested together, while s1 , s2 are the sizes of the groups used for testing individuals with high and low
probabilities of infection, respectively. The optimization allows for at most one heterogeneous group of size x ` y.
The average number of tests required to find all the infected individuals in this heterogeneous group is given by
y
1 xyą0 ` p1 ´ q1x q2 qpx ` yq. The remaining m ´ x individuals who have p1 probability of infection are divided
s
equally into groups of size s1 , where each group requires, on average, 1 ` p1 ´ q11 qs1 tests to determine the set of
all infected individuals. Similarly, the n ´ m ´ y remaining individuals who have p2 probability of infection are
divided equally into groups of size s2 , where each group requires, on average, 1 ` p1 ´ q2s2 qs2 tests to determine
the set of all infected individuals.
D. Lower Bounds for Nonadaptive Probabilistic SQGT
We conclude our exposition in this section by presenting a theoretical result that establishes lower bounds for
nonadaptive probabilistic GT that may be used to assess the quality of our adaptive schemes. For this purpose, we
adapt an argument by Aldridge [65] for arbitrarily small error probability under a constant probability of infection.
More precisely, we consider a setting where each test has m ` 1 outcomes for some m ě 1: The outcome of a test
is either i if there are exactly i infected individuals for i ă m, and ě m otherwise. This corresponds to the setting
introduced in [37] which provides the most informative type of measurements one can expect from the SQGT
framework using the amplification curve information. This model accounts for the saturation limit for each test,
dictated by m, which is a phenomenon observable from the amplification curve. Moreover, as before we assume
that each individual in the population of size n is infected independently with some constant probability p ą 0.
We show the following.
Theorem 1 For every m and constant p ą 0 there exists a constant epm, pq ą 0 such that, under the setting described
above, nonadaptive testing requires at least n{m tests to achieve error probability less than epm, pq in a population of
size n.
In contrast, for m “ 2, our two-stage scheme uses significantly fewer than n{2 tests provided p is not very large.
Proving Theorem 1 follows by a simple adaptation of an approach by Aldridge [65], who showed that individual
testing is required in order to achieve arbitrarily small error in regular nonadaptive probabilistic group testing (which
corresponds to m “ 1). First, given any nonadaptive testing scheme, we may without loss of generality remove all
tests with m or fewer elements, along with all individuals who participate in those tests. This does not affect the
lower bound. Then, we show that there are no nonadaptive testing schemes with an arbitrarily small error where
every test includes at least m ` 1 individuals. Combining these two observations immediately yields Theorem 1.
For an individual i, let xi denote its infection status. Call an individual i (regardless of its infection status) disguised
if every test t in which it participates contains at least m other individuals which are infected. If i is disguised, then
changing xi from 0 to 1, or vice-versa, does not change the outcome of the testing scheme. As a result, we can do

18

no better than guess xi , and we will be wrong with probability at least minpp, 1 ´ pq. To finalize the argument, it
suffices to show there is a disguised individual with constant probability.
Let Di denote the event that individual i is disguised, and let Dt,i denote the event that individual i is disguised in
test t. Since the Dt,i are increasing events9 , the Fortuin-Kasteleyn-Ginibre (FKG) inequality [66] implies that
PrrDi s ě

ź

PrrDt,i s,

(8)

t:xt,i “1

where xt,i indicates whether individual i participates in test t. Moreover, we have
PrrDt,i s “ PrrBpwt ´ 1, pq ě rs,
where wt “

řn

i “1

(9)

xt,i is the weight of test t.

Let
˛

¨
Li “ log ˝

ź

PrrDt,i s‚ “

ÿ

log PrrDt,i s “

t:xt,i “1

t:xt,i “1

T
ÿ

xt,i log PrrDt,i s,

t“1

where T denotes the total number of tests, which we assume satisfies T{n ă 1. Then, it suffices to show that there
exists some i‹ with Li‹ ą c for some constant c independent of n. Let I be uniformly distributed over t1, 2, . . . , nu,
and let L “ ErL I s. We have
L“

“

n T
1 ÿÿ
xt,i log PrrDt,i s
n

1
n

i “1 t “1
T
ÿ

wt log PrrDt,i s

t “1

ě min wt log PrrBpwt ´ 1, pq ě ms
t“1,...,T

ě min w log PrrBpw ´ 1, pq ě rs “: L‹ ,
w ě r `1

where the second equality follows from the fact that PrrDt,i s is the same for every i such that xt,i “ 1, and in
the first inequality we use the assumption that T{n ă 1. It is immediate that there exists some i‹ with Li‹ ě L,
‹
which implies that PrrDi‹ s ě 2 L . Therefore, the error probability of the testing scheme is at least epm, pq “
‹
minpp, 1 ´ pq ¨ 2 L . Noting that L‹ does not depend on n and is bounded from below for any m and p (since
limwÑ8 w log PrrBpw ´ 1, pq ě ms “ 0) concludes the proof.

V. AC-DC S CHEMES : W ORST-C ASE M ODEL A NALYSIS
As before, we assume that we are given a set of n samples with at most d infected individuals. Our goal is to
minimize the number of tests needed to identify all infected individuals and we do not impose any restrictions on
the “simplicity” of our scheme. As a result, we consider a generalization of the model described in the previous
section which allows for more than three test outcomes.
For simplicity, as well as for practical reasons10 , we focus on equidistant thresholds but allow for warm-up/saturation
effects.
Let τ, m P Z` represent the distance between the thresholds and the number of thresholds, respectively.
9 If

Dt,i holds and the set of infected individuals is expanded, then Dt,i continues to hold under this expanded set
we quantize the Ct values or the phase transition thresholds according to equally spaced cycle numbers

10 As

19

Denote the outcomes of the test by a nonnegative integer t ď m. Then,
$
’
0,
if every sample in the test is negative,
’
’
’
’
1,
if the number of infected individuals is between 1 and τ,
’
’
’
’
&2,
if the number of infected individuals is between τ ` 1 and 2τ,
t“ .
.
.
.
’
’
.
.
’
’
’
’
’
’m ´ 1, if the number of infected individuals is between pm ´ 2qτ ` 1 and pm ´ 1qτ, or
’
%
m,
if the number of infected individuals is at least pm ´ 1qτ ` 1.

(10)

We seek to identify d infected individuals from a population of size n given that each test returns a value in (10).
We refer to this problem as the pn, dq adaptive SQGT problem or the pn, dq-ASQGT problem for short.
Another way of looking at (10) is that if the collection of samples tested contains d1 infected individuals, then the
1
output of the test is r dτ s when d1 ď mτ and m otherwise. Note that for every test there are m ` 1 possible outcomes
and the output of a test tells us roughly (within at most τ) how many total infected samples are part of the tested
pool of samples.
Remark 2. Note that this model differs from the model introduced in Section IV since as m increases the widths of our
threshold remain the same whereas in Section IV the widths changes as the number of thresholds increases. Despite
this difference, and as will be discussed in Example 18, the ideas discussed here are applicable to the case where the
widths of the thresholds are nonuniform.
Let 2β “ m ` 1. Motivated by practical applications, we will be interested in the case where β “ O p1q. Our main
results are two algorithms, which we refer to as parallel search and deep search. Parallel search is applicable for
the setting d ą β. In Lemmas 6 and 7, we show that using parallel search it is possible to efficiently identify
from a set of pools (each of size s “ 2α and large enough to contain at least β infected individuals) a set of β
defectives using at most α tests. Note that as a first-step simplification, one may think of n being approximately
equal to d ¨ 2α ; the notation involving α is chosen to enable a comparison between our SQGT search scheme and
the well-known splitting approach by Hwang [67]. Deep search, discussed in Lemma 10 and applicable for the
d¨α
tests. Our
setting d ă β, shows that it is possible to identify all d infected individuals using roughly β´log
p βq
main result is Algorithm 1, which for d “ Ωpnq shows that one can identify d infected individuals using at most
d
β ¨ pα ` 3 ` log βq tests. These results show that adaptive SQGT roughly provides β-fold savings in the number of
tests when compared to classical adaptive GT. Furthermore, they differ from the information-theoretic lower bound
(as it applies to ASQGT) of Lemma 4 by O p βd q tests. It remains an open problem to identify whether it is possible
to solve the pn, dq-ASQGT problem using fewer tests.
We start with the following obvious claim, which allows us to restrict our attention to the case where τ “ 1 and
simplifies the problem at hand.
Claim 3. Let G be the set of test subjects and suppose that there are at most d infected individuals within this group.
Let P p1q be a pool formed by taking one sample from each individual in G and let P pwq be a pool formed by taking w
samples from each individual in G . Let tp1q be the output of testing P p1q under the setup pm, τq “ pm, 1q and let tpwq
be the output of testing P pwq under the setup pm, τq “ pm, wq, according to ( 10). Then, tp1q “ tpwq .
Next, we present a lower bound (i.e., information-theoretic or counting lower bound) on the number of tests necessary
to solve the pn, dq-ASQGT problem. The result follows from a simple counting argument and is consistent with
the result from Claim 3, as it does not depend on the width τ of the threshold.
Lemma 4. Let n “ p2α ` 1q ¨ d ` 2α ¨ δ ` ∆, where α, δ, ∆ are integers, δ ă d, and ∆ ă 2α . Then, the number of tests
Lpn, d, mq needed to identify the infected individuals is bounded as:
Lpn, d, mq ě

d
¨ pα ` 1q.
β

20

ř ` ˘
Proof: The number of ways to select at most d infectives in a group of n individuals is id“0 ni . Thus, we have
˜ ˆ ˙¸
ˆ
˙
d
ÿ
n´d`d
n
Lpn, d, mq ě logm`1
ě logm`1
d
i
i “0
ˆ
˙
n´d`d d
ě logm`1
d
´ `
δ
∆
1 ˘¯
ěd ¨ logm`1 2α 1 ` ` α ` α
d 2 d 2
´
d¨α d
2α ¨ δ ` ∆ ` d ¯
ě
` ¨ log2 1 `
β
β
2α d
d
ě ¨ pα ` 1q .
β

The next example illustrates a simple approach for addressing the ASQGT problem, and motivates the analysis that
follows.
From here on, we write rrxss “ t0, 1, . . . , x ´ 1u and rxs “ t1, . . . , xu.
Example 5. Suppose that we are given a collection of n individuals with exactly d infected subjects. We start by
randomly partitioning the set of n individuals into d groups each of size s “ nd “ 2α , where we assumed for simplicity
that d|n. The expected number of infected individuals in each group is 1.
Denote the d groups or pools by G0 , G1 , . . . , Gd´1 ; all groups have the same size and from this point on, for simplicity,
assume that each group contains exactly one infected subject. For i P rrdss we proceed as follows. We partition Gi into
p0q p1q
p 2 β ´1 q
2β groups of equal size and denote the subgroups as Gi , Gi , . . . , Gi
. Under this setup, there exists exactly one
p j‹ q

index j‹ such that the number of infected individuals in Gi
is free of infected individuals.

p jq

equals to one, and every other group Gi , j P rr2β sszj‹
pk q

Next, we form a new set of pools, which we denote by Pi , i P rrdss, comprising k replicas of the samples in Gi , for
all k “ 0, . . . , 2β ´ 1. Let ti denote the output of the semi-quantitative test described in ( 10) after the pool Pi is tested.
Then, it is straightforward to observe that the outcome ti is j‹ , and hence we can identify the group which contains
the one single infected individual using only one nonbinary outcome test. We repeat this procedure for each group Gi ,
i P rrdss, partitioned into subgroups. It can be hence seen that it is possible to identify d infected individuals using
l
only d αβ tests assuming each of the d groups of size 2α each contain exactly one infected subject.
To make this argument rigorous, we need to account for the fact that not every group will have exactly one infected
individual. In this case, upon creating the subpools we have to recursively test them until we identify a prescribed
number of infected individuals. In fact, the approach from the previous example is a special case of what we refer
to as deep search, described in Lemma 10. The resulting algorithm is summarized in Algorithm 1, and it requires
roughly an additional factor of O p βd q tests compared to the information-theoretic lower bound.
A. Parallel search
We start by introducing some useful notation. Suppose that G 1 is a subgroup of individuals to be tested and that
the outcome of a test governed by (10) is t. In this case, we say that G 1 is a t-infected group. When referring to an
ordered collection of groups pG0 , G1 , . . . , G g´1 q, we say that the collection is a pt0 , t1 , . . . , t g´1 q-infected group if
t0 ě t1 ě ¨ ¨ ¨ ě t g´1 and Gi is a ti -infected group, for i P rrgss. We also say that pG0 , . . . , G g´1 q is a β-minimal
ř g ´2
řg´1
group if j“0 t j ă β, but j“0 t j ě β.
The following lemma constitutes the key component of one of our approaches to solving the pn, dq-ASQGT problem.
We refer to the procedure described in the proofs of the next two results as parallel search.
In the first lemma below, we make the simplifying assumption that a group is β-minimal and g “ β. Afterward, in
Lemma 7 we consider the case when g ă β.

21

Lemma 6. Let α and β be positive integers. Suppose that pG0 , G1 , . . . , G β´1 q is a β-minimal group, where g “ β, and
that each group has size at most 2α . Then, we can identify β infected individuals in the group using at most α tests.
Proof: We prove the result by induction on α, where 2α as before is the size of each subgroup. Recall that under
this setup t0 “ t1 “ ¨ ¨ ¨ “ t g´1 “ 1 and g “ β.
First, consider the case α “ 1, for which we have β 1-infected groups of individuals and each group has size 2.
For shorthand, denote the β infected groups as G0 , G1 , . . . , G β´1 . From these β groups, we form a “super-pool”
of samples which contains a total of 20 ` 21 ` 22 ` ¨ ¨ ¨ ` 2β´1 “ 2β ´ 1 samples. More precisely, for i P rrβss,
the super-pool contains 2i samples from one individual P Gi . Since t0 “ t1 “ ¨ ¨ ¨ “ t β´1 “ 1 and τ “ 1,
according to (10) the output returned after testing this super-pool of samples is a number t between 0 and 2β ´ 1.
Let b0 , b1 , . . . , bβ´1 be the binary representation of the number t. It is straightforward to verify that bi “ 1 then the
individual selected from Gi is infected. Otherwise, if bi “ 0, then the above described individual is not infected,
which implies the other individual (the one not tested) in group Gi is infected. Thus, we conclude the statement in
the lemma holds when α “ 1.
1

For the inductive step, assume that the statement holds when the group size is at most 2α and consider the setup
1
where the group size is 2α “ 2α `1 . We follow the same approach as described for α “ 1 for creating super-pools.
1
Under this setup, we have β 1-infected groups G0 , G1 , . . . , G β´1 , each of size 2α `1 . For i P rrβss, let Qi Ď Gi be
1
a subset of Gi of size 2α . Next we construct a super-pool that contains 2i samples from each individual in Qi ,
i P rrβ ´ 1ss. Let t denote the output of testing this super-pool according to (10), where b0 , b1 , . . . , bβ´1 is the
binary representation of t. As before, if bi “ 1, then Qi has a single infected individual. Otherwise, if bi “ 0, then
1
there is an infected individual in the set Gi zQi which also has size 2α . For i P rrβss, let Gi1 “ Qi if bi “ 1 and
otherwise, if bi “ 0, set Gi1 “ Gi zQi . Then, pG01 , G11 , . . . , G β1 ´1 q is a p1, 1, . . . , 1q-infected group and we can apply
the inductive hypothesis to pG01 , G11 , . . . , G β1 ´1 q.
For the case g ă β, we use a similar partitioning idea to identify at most β subgroups which satisfy the conditions
in the lemma. The difference between the approaches is that for g ă β the number of samples added into the pool
is dictated by a mixed-radix representation (in which the numerical base varies from position to position) rather
than a binary representation. For simplicity, we assume from now on that β is an even integer although the results
hold for odd integers as well.
Lemma 7. Let α, β, g be positive integers such that g ă β. Suppose that pG0 , G1 , . . . , G g´1 q is a β-minimal group and
that each group has size at most 2α . Then, we can identify β infected individuals using at most α tests.
Proof: We begin with the following claim which we find useful in our subsequent discussion.
Claim 8. Suppose we are given a sequence pt0 , . . . , t g´1 q P rrβ ` 1ssg , where g ă β, and the values t0 ě t1 ě ¨ ¨ ¨ ě
ř g ´1
ř g ´2
t g´1 are such that j“0 t j ě β, but j“0 t j ă β. Furthermore, let pn0 , . . . , n g´1 q P rrt0 ` 1ss ˆ rrt1 ` 1ss ˆ ¨ ¨ ¨ ˆ
rrt g´1 ` 1ss. Then, the number of different choices for pn0 , . . . , n g´1 q is at most 2β .
β
2

ř g ´2

β

t j ă β, it follows that t g´2 ď g´1 and, from the
β
assumptions stated in the claim, t g´1 ď t g´2 ď g´1 . The total number of possibilities for pn0 , . . . , n g´1 q restricted
to the first g ´ 1 components is maximized when t0 “ t1 “ ¨ ¨ ¨ “ t g´2 , which implies that the total number of
β
possible choices for the i-th component of the sequence when i P rrg ´ 1ss equals g´1 ` 1. Therefore, the total
number of possibilities for the constrained sequences is
ˆ
˙g
β
` 1 ď 3β{2`1 ,
g´1
´
¯g
β
β
which follows since g´1 ` 1 is increasing with g and g ď 2 ` 1. Since 3β{2`1 ď 2β whenever β ě 8, we
conclude that the result holds for β ě 8. For the case where β ă 8, the result can be verified through exhaustive
checking.
Proof of Claim 8: First, consider the case g ď

β

` 1. Since

j“0

Next, we consider the case g ě 2 ` 1. Note that under this setup, since t0 ě t1 ě ¨ ¨ ¨ ě t g´1 , it follows that
ř g ´2
t g´1 “ 1. Otherwise, if t g´1 “ 2, we would have j“0 t j ě β.

22

β

For this case, we prove the result by induction on g. The base case, corresponding to g “ 2 ` 1, follows from
β
the previous paragraph. Therefore, assume that the result holds for all g ă γ and consider g “ γ ą 2 ` 1. Since
ř γ ´3
ř γ ´3
β
γ ą 2 ` 1, we have tγ´2 “ tγ´1 “ 1 which implies that j“0 ă β ´ 1, since otherwise, if j“0 “ β ´ 1, then
ř γ ´2
β´1
j“0 t j “ β and we arrive at a contradiction. Thus, we have γ ´ 1 ě 2 ` 1 and so we can apply the inductive
hypothesis to the first γ ´ 1 components of the sequence pn0 , . . . , n g´1 q and conclude that there are at most 2β´1
possible choices for the sequence pn0 , n1 , . . . , nγ´1 q. Since tγ´1 “ 1, it follows that the total number of different
options for the sequence pn0 , n1 , . . . , nγ´1 q is at most 2 ¨ 2β´1 . This completes the proof.
Recall the main idea behind the proof of Lemma 6, where we tacitly assumed that g “ β. There, we used the
binary representation of the integer t, where t denotes the test outcome of the super-pool, to determine which of
the tested subgroups involved infected individuals. In order to make this argument work, we formed the super-pool
|G |
by adding 2i samples from group Qi Ď Gi for i P rrβss, where |Qi | “ 2i . Next, the idea is to add Ni samples
from each group, where Ni is chosen by considering a mixed-radix representation of the number t.
We say that pb0 , b1 , . . . , bg´1 q is the pt0 , t1 , . . . , t g´1 q-mixed radix representation for t if the following is true.
Let N0 “ 1. For i P rg ´ 1s, let Ni “ pti´1 ` 1q ¨ Ni´1 . Note that when t0 “ t1 “ t2 “ ¨ ¨ ¨ “ t g´1 “ 1,
řg´1
Ni “ 2i . The mixed radix representation of t is of the form t “ i“0 bi ¨ Ni , where bi ď ti . Note that under this
setup since bi ď ti , the sequence pb0 , b1 , . . . , bg´1 q P rrt0 ` 1ss ˆ rrt1 ` 1ss ˆ ¨ ¨ ¨ ˆ rrt g´1 ` 1ss provides a unique
representation and is invertible provided that pt0 , t1 , . . . , t g´1 q is given. In other words, given the number t we can
uniquely determine the i-th digit in the pt0 , t1 , . . . , t g´1 q mixed radix representation for t, which is bi . Furthermore,
as a result of Claim 8, we know that t ď 2β ´ 1 “ m.
We are now ready to proceed with the proof. Suppose that pG0 , G1 , . . . , G g´1 q is a β-minimal group. We will prove
the result by induction and we will show the inductive step (since the base case follows from similar ideas).
1

For the inductive step, assume the statement holds when the group size is at most 2α and consider the setup where
1
the group size is 2α “ 2α `1 . Note that we have pt0 , t1 , . . . , t g´1 q-infected groups G0 , G1 , . . . , G g´1 each of size
1
2α `1 . We form our super-pool as follows. As before, for each i P rrgss, we select a subset Qi Ă Gi of size
1
|Qi | “ 2α . For each individual in Qi we add Ni samples into the superpool, where Ni is as defined in the previous
paragraphs.
Let t be the output of testing the resulting super-pool according to (10) and let bi denote the i-th symbol of the
pt0 , t1 , . . . , t g´1 q-mixed radix representation of t.
Note that based on t, we can determine the number of infected individuals in each of the subgroups
Q0 , G0 zQ0 , . . . , Q g´1 , G g´1 zQ g´1 . In particular, since we know ti , and given the output bi which can be recovered
after testing the super-pool, we know that for all i P rrgss, the number of infected subjects in Qi is bi and the
number of infected subjects in Gi zQi is ti ´ bi . Given this information, we can generate G01 , G11 , . . . , G g1 1 ´1 , where
for i P rrgss, Gi1 Ď Qi or Gi1 Ď Gi zQi , such that the collection is a β-minimal group. Thus, we can apply the
inductive hypothesis to G. This establishes that we can identify β infected individuals using at most α tests and
completes the proof.
B. Deep search
d
Next, we consider the case d ă β, and show that there exists an ASQGT scheme which requires roughly β´log
¨
p βq
pα ` logpβqq ` d tests. Recall that the main idea behind the parallel search procedure was to simultaneously run a
binary search on g subpools each of size 2α . In this manner, using α tests we can identify β infected. For d ă β,
there are not sufficiently many infected individuals to use this method, and so for this setup, rather than perform a
binary search in parallel, we test roughly 2β´logpβq (significantly smaller) subpools at the same time. We refer to
this procedure as deep search.

Before proving a relevant lemma, we begin by describing a variant of well-known Newton identities. For
completeness, we include a proof.
Claim 9. Let S “ tj1 , . . . , jd u P Z be a multiset of nonnegative integers each of which has value at most p ´ 1, where
řd
`
th
p is an odd prime.
` Define p` pS q “ k“1 ˘jk mod p, the ` power sum of S over the finite field F p . Then, one can
recover S given p0 pS q, p1 pS q, . . . , pd pS q .

23

Figure 14: Illustration of the parallel search ASQGT procedure. In this example, m “ 7 and exactly one individual is infectious in each of the
three groups. The weights of samples in each test round are set to 4, 2, 1 as seen in Frame 1. A binary search procedure is implemented to
find the infected individual in each group. In Frame 1, the test outcome for the first round is 2, implying that there is one infected individual
in the second group. Thus, the subgroups from groups 1 and 3 that were probed in Frame 1 are discarded as illustrated in Frame 2. Similarly,
the second subgroup of group 2 that was not tested is discarded as well. The subgroups that contain an infected individual are further probed
as seen in Frames 2, 3 and 4.

Proof: We represent S using S p`q , containing the positive elements in S and z P Z, which denotes the number of
zeros in S . Given S p`q and z, the set S is uniquely determined.
(
First, note that Newton’s identities can be used to recover the set S p`q “ i1 , i2 , . . . , id1 . To see this, let
ś1
ř1
σpi1 , i2 , . . . , id1 q “ dk“1 p1 ´ ik xq “ dk“0 σk x k P F p rxs and assume that the operations are over the polynomial
ring F p rxs, where the elements in S are assumed to lie in F p . Then, we have
d
ÿ

p` pS q ¨ x ` pmod x d`1 q “

`“1

d
ÿ

1

p` pS p`q q ¨ x ` pmod x d`1 q “

` “1
˜
d1
ÿ

“
k “1

d ÿ
d
ÿ

1

ik` ¨ x ` pmod x d`1 q “

` “1 k “1

1 ´ ikd`1

¨ x d `1

1 ´ ik ¨ x

¸
´1

pmod x d`1 q “

d ÿ
d
ÿ

ik` ¨ x ` pmod x d`1 q

k “1 ` “1
d1
ÿ
k “1

ik ¨ x
pmod x d`1 q,
1 ´ ik ¨ x

which implies
d
ÿ

p` ¨ pS p`q q ¨ x ` ¨ σpi1 , . . . , id1 q pmod x d`1 q “ ´x ¨ σ1 pi1 , . . . , id1 q.

` “1

ř 1
The above equality in turn implies `k´
“0 σk ¨ p`´k pS q “ ´` ¨ σ` . Thus, given p` pS q, ` P rds, one can recover
p`q
p`q
σpS q as well as the multiset S . The multiset S can be subsequently recovered by noting that the number of
zeros in S equals p0 pS q ´ |S p`q |.
Lemma 10. Let p be an odd prime such that p ě 2 L ´ 1 and pp ´ 1q ¨ d ă 2β . Suppose that G is a d-infected set of
size 2α , and d ď p ´ 1. Then we can identify the d infected individuals using at most d ¨ αL tests.
Proof: For simplicity we assume that L|α, and, similar to Lemmas 6 and 7, use induction in α. For the case α “ L,
we run d tests, and for each test we design a different test group. For ` P rds, test group ` contains j` P F p samples

24

from each individual indexed by j P rr2 L ss. Suppose that D is a multi-set of elements from rr2 L ss and that D is
such that if group j has k infected individuals, then the elements from group j appear k times in D . Then according
to the above setup the output of performing the SQGT on pool ` results in the following `-th power sum:
p` pj1 , j2 , . . . , jd q “

d
ÿ

jk` .

k “1

Note that jk` ă p (since by design j` P F p ) and so pi pj1 , j2 , . . . , jd q ď pp ´ 1qd ă 2β . Thus, for ` P rrd ` 1ss, we can
recover p` pj1 , j2 , . . . , jd q “ p` pj1 , j2 , . . . , jd q mod p, since p0 pj1 , j2 , . . . , jd q mod p “ d follows from the fact that
G is a d-infected set. From the set of d ` 1 power sums over the field F p , we can recover the multi-set tj1 , . . . , jd u
from Claim 9, which completes the proof of the base case.
1

1

For the inductive step, assume the statement holds for group sizes at most 2α and consider a group size 2α “ 2α ` L .
As in the proofs of Lemmas 6 and 7, we work with subgroups. The subgroups are formed by partitioning the set
1
1
of 2α ` L individuals into 2 L subgroups P1 , P2 , . . . , P2L each of size 2α . Applying the same ideas as before, we
form d test groups where test group ` P rds contains j` P F p samples from each individual in subgroup j P rr2 L ss.
Let D “ tj11 , j21 , . . . , jd1 u be a multiset of integers such that ju1 appears t times in the multiset if and only if
group ju1 has t infected individuals. Using the same approach as for the base case, we first recover the power sums
pi pj11 , j21 , . . . , jd1 q. Then from Claim 9, we recover the set D in the same manner as before and we apply the inductive
hypothesis to the subgroups in D . This completes the inductive step and the proof.
Remark 11. For the case d “ 1, the deep search procedure coincides with the approach described in Example 5. Deep
search may be of limited practical value due to the large amounts of sample material required for testing, but is of
theoretical relevance due to the fact that it generalizes Hwang’s generalized splitting method to the SQGT setting for
a small number of infected individuals.
C. pn, dq-ASQGT schemes
As discussed in the text following Example 5, our general approach to adaptive SQGT is to first partition the
set of n individuals into βd subpools and test each subpool separately using either parallel search or deep search,
depending on the number of infected in each subpool. Parallel search produces the best results in the worst case,
provided that the number of infected individuals across all the subpools is ď β, while parallel search gives the best
results for the case of a large number of infected individuals.
Let TP pn, dq denote the number of tests required by our ASQGT scheme, summarized in Algorithm 1, and let
n ´ d “ 2α ¨ d ` 2α ¨ δ ` ∆, where α, δ, ∆ are integers such that δ ă d and ∆ ă 2α . In order to simplify the notation
by avoiding floor and ceiling functions, we assume that β|d and β|δ.
Theorem 12. TP pn, dq ď

d
β

¨ pα ` 3 ` log βq ` βδ .

Proof: Since the first step involves testing
2α`1 β.

d
β

`

δ
β

groups, the first step requires

d
β

`

δ
β

tests. For the next steps, note
α`1`logp βq

that each group has size ď
Hence, we can uncover β infected individuals using at most
tests
β
according to Lemmas 6 and 7. In step 3), we use one additional test for every β infected individuals. Since there
are d infected the total number of tests required by Algorithm 1 equals
ˆ
˙
d
δ
d
d
d
δ
TP pn, dq ď
`
` ¨ pα ` 1 ` logpβqq ` “ ¨ pα ` 3 ` logpβqq ` .
β β
β
β
β
β
As discussed earlier, the parallel search ASQGT scheme requires O p βd q more tests than the information-theoretic
lower bound. When β “ 1, our scheme requires O pdq additional tests which agrees with the traditional adaptive
binary setting studied in [49].
Next, we consider the second approach to the ASQGT problem based on deep search, for the case where d ă β.
Let TD pn, dq denote the number of tests required by our algorithm and, with a slight abuse of parameter definitions,
assume that n ´ d “ 2α ¨ d. Furthermore, assume as before that d|2β and d|n. The corresponding approach is
described in Algorithm 2.

25

Algorithm 1 Parallel search ASQGT scheme
δ
1) Initialize: Partition the set of n individuals into d`
β groups, denoted by G0 , G1 , . . . , G d`δ ´1 , each of size
β

ď β ¨ 2α`1 .
δ
Test each subgroup individually. For i P rr d`
β ss, suppose that Gi is a ti -infected group and let D denote the
total number of infected subjects across all groups.
2) Parallel Search: Identify a β-minimal group pGi0 , . . . , Gi g´1 q, and apply parallel search on the group to
uncover β infected individuals. Remove the β infected individuals from their respective groups.
3) Update: Use one additional test to determine the number of infected subjects in pGi0 , . . . , Gi g´1 q after Step
2). Update ti0 , . . . , ti g´1 and D. If D ą 0, go to Step 2).
Algorithm 2 Deep search ASQGT scheme
1) Initialize: Partition the set of n individuals into d groups, denoted by G0 , G1 , . . . , Gd´1 , each of size 2α . Test
each subgroup individually and let D denote the total number of infected subjects across all groups.
2) Deep Search: Identify a ti -infected group Gi , and apply deep search to uncover ti infected subjects, for some
i P rrdss.
3) Update: Let D “ D ´ ti . If D ą 0, go to Step 2).

Theorem 13. The number of tests for deep search ASQGT satisfies
α
TD pn, dq ď d ¨
` β.
β ´ log β ´ 1
Proof: The first step in Algorithm 2 requires d ă β tests. According to Lemma 10, Step 2) requires at most
ti ¨ β´logαpβq´1 tests. Hence, the total number of tests is upper bounded as
TD pn, dq ď β `

dÿ
´1
i “0

ti ¨

α
α
“ β`d¨
.
β ´ log β ´ 1
β ´ log β ´ 1

D. Error-resilient pn, dq-ASQGT schemes
We consider next the question of designing ASQGT models that can tolerate a bounded number of birth-death (BD)
chain errors. Recall from (10) that in the event that there are no errors, the output of testing a pool of individuals,
of which d are infected, is an integer t, such that t “ d for d ď m and t “ m, whenever d ą m. Suppose instead
that the erroneous output of testing a pool is t1 , where t1 P tt ´ 1, t ` 1u with the appropriate boundary conditions.
We refer to such an error as a single BD error.
d
Our main result is described in Theorem 17. We prove that there exists a scheme that requires β´
2 ¨ pα ` 3 ` log βq `
δ
can correct an arbitrary number of test errors. For the case where the number of test errors is a small
β tests that
´
¯
d
integer e, β ` e ¨ pα ` 3 ` log βq ` 2 ¨ βd ` βδ ` e tests suffice, which implies that only e pα ` 3 ` log βq ` 2 βd ` e
additional tests are required to correct e errors in Algorithm 1.

The next claim highlights one of the main ideas behind our approach: Take multiple copies of samples from each
of the individuals being tested in such a way to get error-free readouts even when errors occur. Here, as before,
we assume that 2β “ m ` 1.
Claim 14. Let P be a pool of individuals and suppose that P pˆ3q is a pool which contains three samples from each
individual in P . Let t be the output of the test performed on the pool P pˆ3q given that no errors occur, and suppose t1
is a possibly erroneous output of the test performed on the pool P pˆ3q . Given t1 , one can determine t.
Proof: Since we have taken 3 samples from each of the individuals in the pool P , it follows that t pmod3q “ 0.
Thus, if an error occurs, the output of the test under the BD model equals t1 P tt ` 1, t ´ 1u which implies that

26

t1 pmod3q “ ˘1. If t1 mod 3 “ 1, then t1 “ t ` 1 and so we can recover t by simply decrementing t1 by one.
Similarly, if t1 mod 3 “ ´1, then t1 “ t ´ 1 and we can recover t by incrementing t1 by one.
Using the idea from the previous claim, we can determine exactly how many infected individuals are present in
each of the tested pools despite the fact that testing errors can occur. We describe the underlying method through
an example, for which we need the following terminology.
pˆ3q

We say that Pi is a ti -infected group if the output of testing Pi
is in the set t3ti ´ 1, 3ti , 3ti ` 1u. We also say
ř g ´2
ř g ´1
that pPi0 , . . . , Pi g´1 q is a β-minimal group if t0 ě ti1 ě ¨ ¨ ¨ ě ti g´1 , j“0 t j ă β, but j“0 t j ě β.
Example 15. For simplicity, assume that we have m “ 3 p2γ ´ 1q thresholds, and suppose that pP0 , P1 , . . . , P g´1q is
a γ-minimal group, where we again make a simplifying assumption, namely γ “ g. We proceed in the same manner
as described in Lemma 6 and we first form a super-pool, denoted P which consists of 2i copies of each sample in Pi .
Afterward, we generate a larger pool of samples, P pˆ3q which contains 3 copies of each sample in P .
Notice that given the output of the test P p3q , we can uniquely determine the number of infected that are in each
of the groups P0 , P1 , . . . , P g´1 . Suppose that t1 is the output of testing P p3q and suppose t is the output of testing

P p3q assuming no errors occur during testing. From Claim 14, we can recover t and from Lemma 6 it is possible to
determine how many infected are in P0 , how many infected are in P1 , etc.
Another simple way to see how the above scheme overcomes BD noise is to see that it suffices that test outcomes
differ from one another by at least three. This can be easily accomplished by fixing the coefficients of 21 and 20 in the
binary representation of the test outcomes to zero.
More precisely, we can artificially introduce two subgroups, so that when m “ 2γ ´ 1, we collect samples from
subgroups labeled by 1 ă i ă γ, 2i with the amounts dictated by their labels. If the observed test outcome is
ř γ ´1
t1 “ i“0 ēi ¨ 2i , then the true test outcome is decoded as:
#
ē
ēγ´2 . . . ē2 00,
if ē1 ē0 “ 00 or ē1 ē0 “ 01,
e γ ´1 e γ ´2 . . . e 2 e 1 e 0 “ γ ´1
(11)
ēγ´1 ēγ´2 . . . ē2 ē1 ē0 ` 1 (binary addition), if ē1 ē0 “ 11.
l
The following claim is straightforward.
Claim 16. Let α, β ě 2, g be positive integers where 2β “ m ` 1, g ď β ´ 2. Suppose that pG0 , G1 , . . . , G g´1 q is a
pβ ´ 2q-minimal group and that each group has size at most 2α . Then we can identify β ´ 2 infected individuals using
at most α tests.
Proof: The proof follows immediately by applying the procedure described in Example 15 and noting that 3 ¨ 2β´2 ă
2β ´ 1 when β ě 2.
Next, we turn our attention to a scheme designed for a small number of testing errors e. To this end, let TN pn, d, eq
denote the number of tests required for a noisy ASQGT scheme that tolerates up to e BD testing errors (see
Algorithm 3). As before, let n ´ d “ 2α d ` 2α δ ` ∆, where α, δ and ∆ are integers such that δ ă d and ∆ ă 2α .
Once again we assume that β|d and β|δ.
We prove the correctness of our algorithm in the following theorem.
Theorem 17. Let β ě 2. We have
ˆˆ
˙
˙
d
δ
d
δ
d
TN pn, d, eq ď min
` e ¨ pα ` 3 ` log βq ` 2 ¨ ` ` e,
¨ pα ` 3 ` log βq `
.
β
β β
β´2
β
Proof: The second term under the minimum follows immediately from the parallel search ASQGT scheme given
the use of a robust parallel search. Therefore, in the remainder of the proof, we focus our attention on the first
term.

27

Algorithm 3 Noisy search ASQGT scheme
δ
1) Initialize: Partition the set of samples from the n individuals into d`
β groups, denoted by P0 , P1 , . . . , P d`δ ´1 ,
β

and each of size at most β2α`1 .
pˆ3q
δ
Test each subgroup Pi
individually. For i P rr d`
β ss, suppose that Pi is a ti -infected group and let D
denote the total number of infected subjects in all subgroups.
2) Parallel Search: Identify a β-minimal group pPi0 , . . . , Pi g´1 q, and apply parallel search to uncover β potential
β

β

infected subjects. Divide the set of β potentially infected individuals into two groups of sizes t 2 u and r 2 s,
pˆ3q
pˆ3q
denoted by D1 , D2 .
pˆ3q
pˆ3q
3) Verify: Test D1 , D2
to determine the total number of infected recovered. Update ti0 , . . . , ti g´1 and D.
pˆ3q

4) Update Large Group Counts: If only one group is present, |Pi0 | ě β, and t0 ě 1, then test Pi
0
determine the number of infected in Pi0 . Go back to Step 2).

to

δ
The first step of our algorithm requires d`
β tests and each time we execute Step 2), we perform α ` 1 ` log β

tests. Since Step 2) is executed at most
two steps of our procedure is at most

d
β

` e times this implies that the total number of tests required by the first

d`δ
`
β

ˆ

˙
d
` e ¨ pα ` 1 ` log βq .
β

!
)
β
pˆ3q
pˆ3q
β
For Step 3), note that since max |D1 |, |D2 | ď r 2 s we have t1 ď 3p2r 2 s ´ 1q ă 2β ´ 1 “ m when β ě 2,
pˆ3q

pˆ3q

and so we can determine exactly how many infected subjects are in each of the sets D1 , D2
in Step 3). Each
time Step 3) is executed, we require 2 tests. Since Step 2) is executed at most βd ` e times, this step requires at
most
2¨d
`2¨e
β
tests. Finally, since Step 4) is executed at most βd ` e times, it follows that the total number of tests is at most
´
¯
d
d`δ
`
`
e
¨ pα ` 1 ` log βq ` 2β¨d ` 2 ¨ e ` βd ` e, which proves the claimed result.
β
β
E. Extensions to non-uniform threshold widths
The next two examples illustrate how the ideas from the previous sections can be extended to the case where the
threshold widths increase exponentially. For this case, we only consider small values of m (i.e., m “ 3, 4).
Example 18. In the following, we consider a model that mirrors the results from Section IV. Suppose that the test
outcomes equal
$
0, if there are no infected subjects in the test,
’
’
’
&1, if the number of infected samples is 1,
t“
(12)
’
2, if the number of infected samples is in r2, 3s,
’
’
%
3 if the number of infected samples is in r4, 7s.
We consider the following extension of the approach discussed in Example 5. Suppose we have a pool of size 2α that
contains at least one infected subject. We start by testing this pool to determine the total number of infected individuals.
There are two cases to consider: (a) The output of the test is 2 or 3, which indicates that there is more than a single
infected in the pool or (b) The output of the test is 1.
Suppose that the outcome is (b). In this case, we run a variant of deep search. In particular, we divide the pool into 4
subpools and form a superpool from these 4 subpools which contains 0 samples from the first pool, 1 sample from the
second pool, 2 samples from the third pool, and 4 samples from the fourth pool. It is straightforward to verify that in
this case we can determine which of the 4 subpools contain the single infected sample by testing the superpool, and
we then repeat this procedure using the subpool which contains the single infected.

28

If the outcome is (a), then we proceed to divide the pool of size 2α into two disjoint subpools, each of size 2α´1 . We
further select one of the two subpools for testing. If the subpool tested contains a single infected, then we continue
by applying the procedure discussed in the previous paragraph on the subpool of size 2α´1 that contains one infected
sample. Otherwise, we repeat the procedure from this paragraph on one of the subpools of size 2α´1 that contains
more than a single infected subject.
Using the procedure described above, it is straightforward to verify that recovering 2 infected individuals requires at
most α tests provided we know the number of infected samples in the pool of size 2α . Now suppose n “ d 2α . Then we
can recover d infected subjects using at most 2 ¨ d ` d2¨α tests as follows. First, we partition the set of n individuals into
d groups each of size 2α and we initially test each of these d groups. Afterward, we search for the infected individuals
using the process outlined in this example.
l
We note that despite the fact that we have focused on the case where m is a power of two, the next example shows
that in some cases our ideas extend to settings where m is not `necessarily a ˘power of two. In the next example, we
show an adaptive scheme that requires at most roughly d ` d ¨ log3 p nd q ` 1 . The ideas are similar to the previous
example except that here we only allow 3 thresholds.
Example 19. For this example, we assume that n “ d ¨ 3α . The output of the test is t, where:
$
’
&0, if no infected samples are present in the pool,
t “ 1, if the number of infected samples equals 1,
’
%
2, if the number of infected samples is ą 1.

(13)

The core idea behind the testing strategy is a simple extension of the previous example. Suppose we have a pool of
size 3α that contains at least one infected individual. First, we test this pool of size 3α to determine the total number of
infected individuals. There are two cases to consider: (a) The output of the test equals 2, which indicates that there is
more than one infected sample in the pool or (b) The output of the test equals 1.
Suppose (b) occurred. We perform the same procedure as before except that instead of dividing the pool into 4
subpools, we divide the pool into 3 subpools of equal size. Next, we form a superpool from these 3 sub pools which
contains 0 samples from the first pool, 1 sample from the second pool, and 2 samples from the third pool. Similarly
as before, we can determine which of the three subpools contains the single infected sample, and we then repeat this
procedure using the subpool which contains the single infected sample.
If (a) occurs, then we perform the same procedure as in the previous example. In particular, we divide the pool of
α
size 3α into two disjoint subpools each of size at most r 32 s and perform a single test. If two infected individuals
α
are contained in a single pool, then we repeat the procedure from this paragraph on the pool of size at most r 32 s
that contains at least two infected samples. Otherwise, we perform the procedure from the previous paragraph on the
α
subpool of size at most r 32 s that contains a single infected sample.
Using this approach, it is straightforward to verify that recovering an infected requires at most α ` 1 tests. Thus we can
recover d infected individuals using at most d ` d ¨ pα ` 1q tests as follows. First, we partition the set of n infected into
d groups each of size 3α . Afterward, we search for the infected individuals using the process outlined in this example.
l
Since the model proposed in the previous example is identical to the one used for probabilistic priors and described
in Section IV, we now directly compare the two in terms of the number of tests required per individual. Recall that
the model in section IV required on average
1
` p ¨ p1 ´ pqs´1 ¨ rlog ss ` 1 ´ p1 ´ pqs ´ s ¨ p ¨ p1 ´ pqs´1
(14)
s
tests per individual where s represents the size of each subpool used in the first step of the corresponding algorithm.
For n large enough, our setup requires approximately
ˆ ˙
1
p ` p ¨ log3
(15)
p
tests where p “ nd . Figure 15 compares the number of tests required in (14) and (15). Notice that the ASQGT scheme
from the previous example requires only roughly half the tests per individual of the approach from Section IV.

29

However, the latter method is simpler to implement in practice since it only requires two stages of testing. We also
note that since the schemes are not exclusive, it is possible to use a combination of both approaches if needed.

Figure 15: Comparison of the average number of test per individual for the 3-threshold schemes (14) and (15). The choice of s is optimized
for each value of p for the probabilistic priors setting.

VI. A S HORT N OTE ON C OMMUNITY-AWARE T ESTING
As mentioned previously, in order to formulate effective and optimal testing schemes, the underlying community
network structure must be incorporated. Towards that end, we assume that the community labels are known as
well as their sizes (not the entire network, but entities like families or clusters of families in close proximity; this
assumption is realistic, as most testing sites require subjects to submit their addresses). The aim is to find efficient
strategies that will identify communities with high infection rates, rather than infected individuals, as this would
guide effective quarantine strategies.
More precisely, consider a partition of a population of N individuals into communities A1 , A2 , . . . , A f of size
N1 , N2 , ..., N f , respectively, where N “ N1 ` ... ` N f and f ě 2. Each group has some (unknown) number of
řf
infected individuals equal to di , i “ 1, . . . , s, and d “ i“1 di . The following question is of interest: Devise adaptive
and nonadaptive GT and SQGT schemes that identify heavy hitter communities, i.e., communities with at least d{k
infected individuals, where k is an input parameter.
The naive non-adaptive scheme for this problem corresponds to running within each of the f communities an optimal
testing scheme for determining the number of infected individuals. Each such scheme requires Θplog Ni q tests [68],
řf
leading to a total of Θp i“1 log Ni q tests. Note that Θplog Nq tests are both necessary and sufficient to estimate
the number of defectives in general, but it is conceivable that a better result is possible when we already know an
upper bound on this number, which is the case here. This approach is suboptimal, and we describe an alternative
nonadaptive binary testing scheme for the heavy hitters problem that requires significantly fewer tests when the
total number of infected individuals, d, is much smaller than the population size n. We leave as an important open
problem to construct semiquantitative testing schemes for the heavy hitters problem with few adaptivity stages and
requiring significantly fewer tests than the scheme we propose below.
First, we
řnote that the heavy hitters problem can be solved with t “ Opk log f q queries that on input a set T Ď r f s
output iPT di [45], which corresponds to the quantitive GT model. Indeed, this corresponds to the setting of
compressed sensing with 0/1 linear tests. We show below how to emulate such a query with error probability e
using r “ Op22d ¨ logp1{eqq randomized disjunctive queries. Combining the two observations above immediately
yields a nonadaptive group testing scheme using r ¨ t “ Opk ¨ log f ¨ 22d ¨ logp1{eqq tests that solves the heavy hitters
1
problem with error probability at most t ¨ e via a union bound. For example, if d ă log log log N and e ď t log
n
then the required number of tests may be significantly smaller than that required by the naive scheme from the
previous paragraph.
ř
It remains to show how to emulate the query iPT di with error
Ťprobability e using r tests. Consider a randomized
test obtained by independently including each individual
j
P
i in the test with probability 1{2, and let Y
iPT Ař
ś
´di “ 2´ iPT di , since the test outputs 0 if and only if
denote the test output. Then, we have PrrY “ 0s
“
2
iP T
ř
no
infected
individual
is
included.
Noting
that
d
ď d, a Chernoff bound guarantees that we can determine
i
i
P
T
ř
2d
iPT di with error probability at most e by independently sampling r “ Op2 logp1{eqq such tests Y1 , Y2 , . . . , Yr

30

¯]
Q
´ ř
and setting our estimate to be ´ log 1r ra“1 Ya , where rxu denotes the closest integer to x. This yields the
desired result.
We conclude the discussion with the following remarks:
1) The above scheme provides a reduction from community-aware testing of heavy hitters to the standard heavy
hitters problem in compressed sensing. While this provides a proof of concept, it remains to be seen whether
a direct approach can provide more effective test designs for the identification of heavy hitter communities
via disjunctive queries.
2) An important direction is to construct an analogous approach for the detection of heavy hitter communities
using SQGT schemes. Recall that quantitative group testing (equivalently, the compressed sensing model via
binary matrices) is an extremal special case of SQGT, whereas standard group testing is another extreme. It
is therefore natural to expect that SQGT provides the identification of heavy hitter communities at varying
efficiency depending on the granularity of the quantization levels.
3) Furthermore, we ask whether adaptivity can help to identify heavy hitter communities more efficiently than
non-adaptive schemes can offer.
VII. M UTATIONS AND RT-PCR N OISE
A number of works have focused on RT-PCR asymmetric error models that assume that positive samples can
actually test negative while the opposite scenario is highly unlikely [29]. As already pointed out, these assumptions
are not practically justified since even as few as 10 viral cDNA fragments can lead to detectable fluorescence levels
after roughly 40 cycles of amplification. Hence, the cause of false negative measurements does not lie in inadequate
PCR testing but erroneous sample collection instead, in addition to possible mutations in the genomic regions used
as primers. In both cases, no matter how many times an RT-PCR test is repeated, an infected sample may not be
identified (i.e., the sample is masked). As an example, the CDC originally identified three pairs of primers from
the N open reading frame (gene) of the SARS-CoV-2 virus for testing, but since one pair was removed due to the
presence of mutations in a larger-than-acceptable population. There are further efforts to reduce the problem of
false negatives due to mutations such as using primers from at least two genes [69].
The problem of mutations in primer regions of individuals tested via RT-PCR is of relevance to GT both from the
perspective of measurement modeling (as mutations add an additional level of nonlinearity to the measurements
that are not captured by current approaches) as well as error analysis. It is important to observe that mutations or
undesired hybridization to nontarget regions may lead to variable test outcomes for the same sample in different
tests. As a result, trying to exactly estimate the viral load of the individuals as proposed in [25] is not possible and
estimates like the ones used in the SQGT framework may be more appropriate. Furthermore, quantization noise is
signal-dependent, which is another desirable feature of the SQGT framework.
To examine the influence of mutations on RT-PCR we examined the GISAID [41] database of Cov-SARS-2 genomes
and identified 7 individuals with mutations in the N1 and N2 primer regions. Using the FastPCR online simulation
software [70], we examined the influence of the mutation on primer binding and PCR amplification. The results
are summarized in Table I. Furthermore, the complete primer and DNA sequences are given in Appendix A. There,
the symbols ‘f’ and ‘r’ refer to the DNA strands’ forward and reverse directions, respectively. In the forward
direction, the genome and primer have to be an exact match, while in the reverse direction the two strings have to
be Watson-Crick complementary. As one can observe, mutations along the forward (reverse) direction of the N1
or N2 regions that do not contain the exact match (or Watson-Crick complement) can severely affect the efficiency
of primer/target bonding. For a more precise characterization, the corresponding melting temperatures are given in
the Table I along with an estimate of the primer binding efficiency for the N1 and N2 regions.
As seen in the results of the simulation, not all samples that have mutations along the primer region are amplified.
VIII. C ONCLUSION
We provided a brief overview of existing testing protocols for Covid-19 along with descriptions of state-of-the-art
pooling algorithms proposed in the literature. In addition, we presented a collection of new algorithms and testing
schemes specifically tailored for RT-PCR testing protocols that improve upon prior models and other GT schemes.
Many open problems remain, including:

31

TABLE I: Simulation results
Patient
EPI ISL 413609

EPI ISL 415600

EPI ISL 416650

EPI ISL 417938

EPI ISL 422983

EPI ISL 424955

EPI ISL 425148

Primer Region
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r
N1f
N1r
N2f
N2r

Amplification Predicted?
Y
Y
Y
Y
Y
N
Y
Y
N
Y
Y
Y
Y
Y
Y
Y
Y
N
Y
Y
Y
Y
N
Y
Y
N
Y
Y

Melting Temperature (in
51.6
56.3
52.9
52.2
51.6
51.7
52.9
54.7
42.6
56.3
52.9
54.7
51.6
56.3
47.3
54.7
44.6
52.1
52.9
54.7
51.6
56.3
43.1
54.7
51.6
51.7
52.9
54.7

0

C)

Amplification %
100
100
100
97
100
97
100
100
97
100
100
100
100
100
95
100
95
95
100
100
100
100
97
100
100
97
100
100

Probabilistic testing schemes for more than 3 thresholds: In Section IV, we considered the setup where each
test generated the output 0, 1, or 2 depending upon the number of defectives in each group. How much can
one reduce the number of tests of our schemes if we incorporate additional semi-quantitative information, in
the presence of errors?
‚ Worst-case testing schemes with a constant number of rounds: The schemes described in Section V have the
potential drawback that almost every test depends upon the results of prior tests. It has been shown that in the
binary group testing setting, the information-theoretic lower bound can be achieved using only two rounds of
non-adaptive testing when the number of infected individuals is at most nc for any constant c ă 1 [71]. Can
a similar result be shown in the setting where there is more than one threshold?
‚ Practical SQGT schemes resilient to errors: Our practical two-stage SQGT schemes from Section IV-A can
be enhanced with noise-resilience properties in a straightforward by repeating each test a prescribed number
of times, while keeping the number of testing stages the same. Nevertheless, it would be interesting to find
more efficient, and still practical, ways of adding good noise-resilience properties to these schemes.
‚ Community-Aware Testing: Section VI presented a simple, first effort towards the problem of attempting to
identify heavy hitter communities. Can such schemes be improved?

‚

ACKNOWLEDGEMENT
The authors are grateful to Sergei Maslov and Nigel Goldenfeld from the University of Illinois for several insightful
discussions.

32

R EFERENCES
[1] “Coronavirus Live Updates,” https://www.healthline.com/health-news/how-deadly-is-the-coronavirus-compared-to-past-outbreaks, 2020,
[Online; accessed 20-April-2020].
[2] “Here’s
how
COVID-19
compares
to
past
outbreaks,”
https://www.healthline.com/health-news/
how-deadly-is-the-coronavirus-compared-to-past-outbreaks, 2020, [Online; accessed 20-April-2020].
[3] “Testing the key to reopening economy, returning life to normal, officials say,” https://www.deseret.com/utah/2020/4/21/21229734/
coronavirus-covid-19-testing-key-economy-reopening-returning-life-normal, 2020, [Online; accessed 20-April-2020].
[4] S. M. Robert F. Service, “New drool-based tests are replacing the dreaded coronavirus
https://www.sciencemag.org/news/2020/08/new-drool-based-tests-are-replacing-dreaded-coronavirus-nasal-swab#, 2020.

nasal

swab,”

[5] A. Stone, “Nebraska public health lab begins pool testing COVID-19 samples,” KETV Omaha, 2020.
[6] R. Dorfman, “The detection of defective members of large populations,” The Annals of Mathematical Statistics, vol. 14, no. 4, pp. 436–440,
1943.
[7] M. Aldridge, O. Johnson, and J. Scarlett, “Group testing: An information theory perspective,” Foundations and Trends in Communications
and Information Theory, vol. 15, no. 3-4, pp. 196–392, 2019.
[8] B. Abdalhamid, C. R. Bilder, E. L. McCutchen, S. H. Hinrichs, S. A. Koepsell, and P. C. Iwen, “Assessment of specimen
pooling to conserve SARS CoV-2 testing resources,” American Journal of Clinical Pathology, 04 2020, aqaa064. [Online]. Available:
https://doi.org/10.1093/ajcp/aqaa064
[9] A. Z. Broder and R. Kumar, “A note on double pooling tests,” arXiv e-prints, Apr. 2020.
[10] C. Gollier, “Optimal group testing to exit the Covid confinement,” Toulouse School of Economics, Tech. Rep., Mar. 2020. [Online].
Available: https://www.tse-fr.eu/optimal-group-testing-exit-covid-confinement
[11] O. Gossner, “Group testing against COVID-19,” Center for Research in Economics and Statistics, Working Papers 2020-04, Mar. 2020.
[Online]. Available: https://ideas.repec.org/p/crs/wpaper/2020-04.html
[12] R. Hanel and S. Thurner, “Boosting test-efficiency by pooled testing strategies for SARS-CoV-2,” arXiv e-prints, Mar. 2020.
[13] K. R. Narayanan, A. Heidarzadeh, and R. Laxminarayan, “On accelerated testing for COVID-19 using group testing,” arXiv e-prints, Apr.
2020.
[14] M. Täufer, “Rapid, large-scale, and effective detection of COVID-19 via non-adaptive testing,” bioRxiv, 2020. [Online]. Available:
https://www.biorxiv.org/content/early/2020/04/13/2020.04.06.028431
[15] N. Shental, S. Levy, S. Skorniakov, V. Wuvshet, Y. Shemer-Avni, A. Porgador, and T. Hertz, “Efficient high throughput SARS-CoV-2
testing to detect asymptomatic carriers,” medRxiv, 2020. [Online]. Available: https://www.medrxiv.org/content/early/2020/04/20/2020.04.
14.20064618
[16] I. Yelin, N. Aharony, E. Shaer-Tamar, A. Argoetti, E. Messer, D. Berenbaum, E. Shafran, A. Kuzli, N. Gandali, T. Hashimshony,
Y. Mandel-Gutfreund, M. Halberthal, Y. Geffen, M. Szwarcwort-Cohen, and R. Kishony, “Evaluation of COVID-19 RT-qPCR test in
multi-sample pools,” medRxiv, 2020. [Online]. Available: https://www.medrxiv.org/content/early/2020/03/27/2020.03.26.20039438
[17] J. Zhu, K. Rivera, and D. Baron, “Noisy pooled PCR for virus testing,” arXiv e-prints, Apr. 2020.
[18] “Does Covid-19 Hit Women and Men Differently? U.S. Isn’t Keeping
coronavirus-male-female-data-bias.html, 2020, [Online; accessed 20-April-2020].

Track,”

https://www.nytimes.com/2020/04/03/us/

[19] “Covid-19’s devastating toll on black and Latino Americans, in one chart,” https://www.deseret.com/utah/2020/4/21/21229734/
coronavirus-covid-19-testing-key-economy-reopening-returning-life-normal, 2020, [Online; accessed 20-April-2020].
[20] Center for Disease Control, “CDC 2019-novel coronavirus (2019-nCoV) real-time RT-PCR diagnostic panel,” 2020.
[21] C. S. Booth, E. Pienaar, J. R. Termaat, S. E. Whitney, T. M. Louw, and H. J. Viljoen, “Efficiency of the polymerase chain reaction,”
Chemical engineering science, vol. 65, no. 17, pp. 4996–5006, 2010.
[22] V. Rana, E. Chien, J. Peng, and O. Milenkovic, “How fast does the SARS-Cov-2 virus really mutate in heterogeneous populations?”
medRxiv, 2020.
[23] J. Yi, R. Mudumbai, and W. Xu, “Low-cost and high-throughput testing of COVID-19 viruses and antibodies via compressed sensing:
System concepts and computational experiments,” arXiv e-prints, Apr. 2020.
[24] H. Bernd Petersen, B. Bah, and P. Jung, “Efficient noise-blind `1 -regression of nonnegative compressible signals,” arXiv e-prints, Mar.
2020.
[25] S. Ghosh, A. Rajwade, S. Krishna, N. Gopalkrishnan, T. E. Schaus, A. Chakravarthy, S. Varahan, V. Appu, R. Ramakrishnan, S. Ch,
M. Jindal, V. Bhupathi, A. Gupta, A. Jain, R. Agarwal, S. Pathak, M. A. Rehan, S. Consul, Y. Gupta, N. Gupta, P. Agarwal, R. Goyal,
V. Sagar, U. Ramakrishnan, S. Krishna, P. Yin, D. Palakodeti, and M. Gopalkrishnan, “Tapestry: A single-round smart pooling technique
for COVID-19 testing,” medRxiv, 2020. [Online]. Available: https://www.medrxiv.org/content/early/2020/04/29/2020.04.23.20077727

33

[26] N. Shental, S. Levy, V. Wuvshet, S. Skorniakov, B. Shalem, A. Ottolenghi, Y. Greenshpan, R. Steinberg, A. Edri, R. Gillis,
M. Goldhirsh, K. Moscovici, S. Sachren, L. M. Friedman, L. Nesher, Y. Shemer-Avni, A. Porgador, and T. Hertz,
“Efficient high-throughput SARS-CoV-2 testing to detect asymptomatic carriers,” Science Advances, 2020. [Online]. Available:
https://advances.sciencemag.org/content/early/2020/08/20/sciadv.abc5961
[27] M. J. Mina, R. Parker, and D. B. Larremore, “Rethinking covid-19 test sensitivity – a strategy for containment,” New England Journal of
Medicine, vol. 0, no. 0, p. null, 0. [Online]. Available: https://doi.org/10.1056/NEJMp2025631
[28] R. Arnaout, R. A. Lee, G. R. Lee, C. Callahan, C. F. Yen, K. P. Smith, R. Arora, and J. E. Kirby, “SARS-CoV2 Testing: The limit of
detection matters,” bioRxiv, 2020. [Online]. Available: https://www.biorxiv.org/content/early/2020/06/04/2020.06.02.131144
[29] P. Nikolopoulos, T. Guo, C. Fragouli, and S. Diggavi, “Community aware group testing,” 2020.
[30] A. Emad and O. Milenkovic, “Semiquantitative group testing,” IEEE Transactions on Information Theory, vol. 60, no. 8, pp. 4614–4636,
2014.
[31] ——, “Group testing for non-uniformly quantized adder channels,” in 2014 IEEE International Symposium on Information Theory, 2014,
pp. 2351–2355.
[32] ——, “Code construction and decoding algorithms for semi-quantitative group testing with nonuniform thresholds,” IEEE Transactions on
Information Theory, vol. 62, no. 4, pp. 1674–1687, 2016.
[33] F. Hwang, “A generalized binomial group testing problem,” Journal of the American Statistical Association, vol. 70, no. 352, pp. 923–926,
1975.
[34] A. Emad and O. Milenkovic, “Poisson group testing: A probabilistic model for nonadaptive streaming boolean compressed sensing,” in
2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2014, pp. 3335–3339.
[35] J. Wolf, “Born again group testing: Multiaccess communications,” IEEE Transactions on Information Theory, vol. 31, no. 2, pp. 185–191,
1985.
[36] B. Lindstrom, “Determining subsets by unramified experiments,” A Survey of Statistical Design and Linear Models, 1975.
[37] A. Dyachkov and V. Rykov, “Generalized superimposed codes and their application to random multiple access,” in Proc. 6th Int. Symp.
Inf. Theory, vol. 1, 1984, pp. 62–64.
[38] Y. Shu and J. McCauley, “GISAID: Global initiative on sharing all influenza data–from vision to reality,” Eurosurveillance, vol. 22, no. 13,
2017.
[39] S. Neidler, “What are the differences between PCR, RT-PCR, qPCR, and RT-qPCR?” https://www.enzolifesciences.com/science-center/
technotes/2017/march/what-are-the-differences-between-pcr-rt-pcr-qpcr-and-rt-qpcr?/, 2020.
[40] A. E. Platts, G. D. Johnson, A. K. Linnemann, and S. A. Krawetz, “Real-time PCR quantification using a variable reaction efficiency
model,” Analytical Biochemistry, vol. 380, no. 2, pp. 315–322, 2008.
[41] “GISAID,” https://www.gisaid.org.
[42] A. Goyal, E. F. Cardozo-Ojeda, and J. T. Schiffer, “Potency and timing of antiviral therapy as determinants of duration of SARS CoV-2
shedding and intensity of inflammatory response,” medRxiv, 2020.
[43] Y. Liu, L.-M. Yan, L. Wan, T.-X. Xiang, A. Le, J.-M. Liu, M. Peiris, L. L. M. Poon, and W. Zhang, “Viral dynamics in
mild and severe cases of COVID-19,” The Lancet Infectious Diseases, vol. 20, no. 6, pp. 656 – 657, 2020. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S1473309920302322
[44] “On-campus COVID-19 testing,” https://covid19.illinois.edu/health-and-support/on-campus-covid-19-testing/, 2020.
[45] P. Indyk, “Sketching via hashing: from heavy hitters to compressed sensing to sparse Fourier transform,” in Proceedings of the 32nd ACM
SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems, 2013, pp. 87–90.
[46] A. G. D’yachkov and V. V. Rykov, “Bounds on the length of disjunctive codes,” Problemy Peredachi Informatsii, vol. 18, no. 3, pp. 7–13,
1982.
[47] E. Porat and A. Rothschild, “Explicit non-adaptive combinatorial group testing schemes,” in Automata, Languages and Programming,
L. Aceto, I. Damgård, L. A. Goldberg, M. M. Halldórsson, A. Ingólfsdóttir, and I. Walukiewicz, Eds. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2008, pp. 748–759.
[48] J. Scarlett, “An efficient algorithm for capacity-approaching noisy adaptive group testing,” in 2019 IEEE International Symposium on
Information Theory (ISIT). IEEE, 2019, pp. 2679–2683.
[49] F. K. Hwang, “A method for detecting all defective members in a population by group testing,” Journal of the American Statistical
Association, vol. 67, no. 339, pp. 605–608, 1972.
[50] P. Damaschke, “Threshold group testing,” in General theory of information transfer and combinatorics.

Springer, 2006, pp. 707–718.

[51] M. Cheraghchi, “Improved constructions for non-adaptive threshold group testing,” Algorithmica, vol. 67, no. 3, pp. 384–417, 2013.
[52] S. Aeron, V. Saligrama, and M. Zhao, “Information theoretic bounds for compressed sensing,” IEEE Transactions on Information Theory,
vol. 56, no. 10, pp. 5111–5130, 2010.
[53] R. G. Baraniuk, “Compressive sensing [lecture notes],” IEEE signal processing magazine, vol. 24, no. 4, pp. 118–121, 2007.

34

[54] J. A. Tropp, “Greed is good: Algorithmic results for sparse approximation,” IEEE Transactions on Information theory, vol. 50, no. 10, pp.
2231–2242, 2004.
[55] W. Dai and O. Milenkovic, “Subspace pursuit for compressive sensing signal reconstruction,” IEEE transactions on Information Theory,
vol. 55, no. 5, pp. 2230–2249, 2009.
[56] S. Ghosh, R. Agarwal, M. A. Rehan, S. Pathak, P. Agrawal, Y. Gupta, S. Consul, N. Gupta, R. Goyal, A. Rajwade et al., “A compressed
sensing approach to group-testing for COVID-19 detection,” arXiv preprint arXiv:2005.07895, 2020.
[57] W. Dai, M. A. Sheikh, O. Milenkovic, and R. G. Baraniuk, “Compressive sensing DNA microarrays,” EURASIP journal on bioinformatics
and systems biology, vol. 2009, no. 1, p. 162824, 2008.
[58] W. Dai, H. V. Pham, and O. Milenkovic, “A comparative study of quantized compressive sensing schemes,” in 2009 IEEE International
Symposium on Information Theory. IEEE, 2009, pp. 11–15.
[59] W. Dai and O. Milenkovic, “Information theoretical and algorithmic approaches to quantized compressive sensing,” IEEE transactions on
communications, vol. 59, no. 7, pp. 1857–1866, 2011.
[60] W. Dai and O. Milenkovic, “Weighted superimposed codes and constrained integer compressed sensing,” IEEE Transactions on Information
Theory, vol. 55, no. 5, pp. 2215–2229, 2009.
[61] A. Heidarzadeh and K. R. Narayanan, “Two-stage adaptive pooling with RT-qPCR for COVID-19 screening,” arXiv preprint
arXiv:2007.02695, 2020.
[62] M. Cheraghchi, A. Karbasi, S. Mohajer, and V. Saligrama, “Graph-constrained group testing,” IEEE Transactions on Information Theory,
vol. 58, no. 1, pp. 248–262, 2012.
[63] W. E. Parmet and M. S. Sinha, “Covid-19 – the law and limits of quarantine,” New England Journal of Medicine, vol. 382, no. 15, p. e28,
2020.
[64] B. W. Buchan, J. S. Hoff, C. G. Gmehlin, A. Perez, M. L. Faron, L. S. Munoz-Price, and N. A. Ledeboer, “Distribution of SARS-CoV-2
PCR cycle threshold values provide practical insight into overall and target-specific sensitivity among symptomatic patients,” American
Journal of Clinical Pathology, vol. 154, no. 4, pp. 479–485, 07 2020. [Online]. Available: https://doi.org/10.1093/ajcp/aqaa133
[65] M. Aldridge, “Individual testing is optimal for nonadaptive group testing in the linear regime,” IEEE Transactions on Information Theory,
vol. 65, no. 4, pp. 2058–2061, 2019.
[66] C. M. Fortuin, P. W. Kasteleyn, and J. Ginibre, “Correlation inequalities on some partially ordered sets,” Communications in Mathematical
Physics, vol. 22, no. 2, pp. 89–103, 1971.
[67] D. Du, F. K. Hwang, and F. Hwang, Combinatorial group testing and its applications.

World Scientific, 2000, vol. 12.

[68] P. Damaschke and A. S. Muhammad, “Bounds for nonadaptive group tests to estimate the amount of defectives,” in Combinatorial
Optimization and Applications, W. Wu and O. Daescu, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp. 117–130.
[69] M. Park, J. Won, B. Y. Choi, and C. J. Lee, “Optimization of primer sets and detection protocols for SARS-CoV-2 of coronavirus disease
2019 (COVID-19) using PCR and real-time PCR,” Experimental & molecular medicine, vol. 52, no. 6, pp. 963–977, 2020.
[70] PrimerDigital, “Primerdigital,” http://primerdigital.com/tools/, 2020.
[71] M. Hahn-Klimroth and P. Loick, “Optimal adaptive group testing,” arXiv e-prints, Nov. 2019.

35

A PPENDIX
A. Simulation Results: PCR on DNA strands with mutations along primer regions
We present below the results of the PCR simulation run on DNA sequences that contain mutations along the N1
and N2 regions of the genome. The notation EPI ISL xxxxxx corresponds to the sample ID. As already indicated,
the symbols ‘f’ and ’r’ at the end of the primer regions indicate the DNA strand directions, forward and reverse
respectively. The symbol ‘Y’ indicates a successful PCR amplification, while the symbol ‘N’ indicates that PCR
amplification cannot be initiated. We also list the percentage of the primer string that is matched by genomic
DNA, and the melting temperature Tm .
EPI ISL 413609
N1f
5-gaccccaaaa t cagcgaaa t

Y 100% Tm =51.6˝ C

| | | | | | | | | | | | | | | | | | | |
t ggaccccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

Y 100% Tm =56.3˝ C

| | | | | | | | | | | | | | | | | | | | | | | |
c t caga t t caac t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 100% Tm =52.9˝ C

| | | | | | | | | | | | | | | | | | | |
ga t t acaaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5

Y 97% Tm =52.2˝ C

| | | | | | | | | | | | | | | | | :
cg t t c t t cggaa t g t cgcg t a t t g
EPI ISL 415600
N1f
5-gaccccaaaa t cagcgaaa t

Y 100% Tm =51.6˝ C

| | | | | | | | | | | | | | | | | | | |
t ggaccccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

N 97% Tm =51.7˝ C

| | | | | | | | | : | | | | | | | | | | | | | |
c t caga t t caa t t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 100% Tm =52.9˝ C

| | | | | | | | | | | | | | | | | | | |
ga t t acaaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5

Y 100% Tm =54.7˝ C

36

| | | | | | | | | | | | | | | | | |
cg t t c t t cggaa t g t cgcgca t t g

EPI ISL 416650
N1f
5-gaccccaaaa t cagcgaaa t

N 97% Tm =42.6˝ C

| | | | | | | | | | | | | : | | | | | |
t ggaccccaaaa t ca t cgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

Y 100% Tm =56.3˝ C

| | | | | | | | | | | | | | | | | | | | | | | |
c t caga t t caac t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 100% Tm =52.9˝ C

| | | | | | | | | | | | | | | | | | | |
ga t t acaaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5

Y 100% Tm =54.7˝ C

| | | | | | | | | | | | | | | | | |
cg t t c t t cggaa t g t cgcgca t t g

EPI ISL 417938
N1f
5-gaccccaaaa t cagcgaaa t

Y 100% Tm =51.6˝ C

| | | | | | | | | | | | | | | | | | | |
t ggaccccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

Y 100% Tm =56.3˝ C

| | | | | | | | | | | | | | | | | | | | | | | |
c t caga t t caac t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 95% Tm =47.3˝ C

| | | : | | | | | | | | | | | | | | | |
ga t t a t aaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5
| | | | | | | | | | | | | | | | | |

Y 100% Tm =54.7˝ C

37

cg t t c t t cggaa t g t cgcgca t t g

EPI ISL 422983
N1f
5-gaccccaaaa t cagcgaaa t

Y 95% Tm =44.6˝ C

| | : | | | | | | | | | | | | | | | | |
t ggaacccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

N 95% Tm =52.1˝ C

| | | | | : | | | | | | | | | | | | | | | | | |
c t caga t acaac t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 100% Tm =52.9˝ C

| | | | | | | | | | | | | | | | | | | |
ga t t acaaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5

Y 100% Tm =54.7˝ C

| | | | | | | | | | | | | | | | | |
cg t t c t t cggaa t g t cgcgca t t g

EPI ISL 424955
N1f
5-gaccccaaaa t cagcgaaa t

Y 100% Tm =51.6˝ C

| | | | | | | | | | | | | | | | | | | |
t ggaccccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

Y 100% Tm =56.3˝ C

| | | | | | | | | | | | | | | | | | | | | | | |
c t caga t t caac t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

N 97% Tm =43.1˝ C

| | | | | | | | | | | | | | | : | | | |
ga t t acaaaca t t ggcc t caaa t t gc
N2r
aagaagcc t t acagcgcg-5
| | | | | | | | | | | | | | | | | |
cg t t c t t cggaa t g t cgcgca t t g

Y 100% Tm =54.7˝ C

38

EPI ISL425148
n1f
5-gaccccaaaa t cagcgaaa t

Y 100% Tm =51.6˝ C

| | | | | | | | | | | | | | | | | | | |
t ggaccccaaaa t cagcgaaa t gcac
N1r
g t c t aag t t gaccg t ca t t gg t c t - 5

N 97% Tm =51.7˝ C

| | | | | | | | | : | | | | | | | | | | | | | |
c t caga t t caa t t ggcag t aaccagaa t gg
N2f
5 - t t acaaaca t t ggccgcaaa

Y 100% Tm =52.9˝ C

| | | | | | | | | | | | | | | | | | | |
ga t t acaaaca t t ggccgcaaa t t gc
N2r
aagaagcc t t acagcgcg-5
| | | | | | | | | | | | | | | | | |
cg t t c t t cggaa t g t cgcgca t t g

Y 100% Tm =54.7˝ C

