arXiv:2102.01551v1 [cs.RO] 2 Feb 2021

An Open-Source Modular Robotic System for
Telepresence and Remote Disinfection
Andre Potenza

Andrey Kiselev

Center for Applied Autonomous Sensor Systems (AASS)
Örebro University
Örebro, Sweden
andre.potenza@oru.se

Center for Applied Autonomous Sensor Systems (AASS)
Örebro University
Örebro, Sweden
andrey.kiselev@oru.se

Alessandro Saffiotti

Amy Loutfi

Center for Applied Autonomous Sensor Systems (AASS)
Örebro University
Örebro, Sweden
asaffio@aass.oru.se

Center for Applied Autonomous Sensor Systems (AASS)
Örebro University
Örebro, Sweden
amy.loutfi@oru.se

Abstract—In a pandemic contact between humans needs to be
avoided wherever possible. Robots can take over an increasing
number of tasks to protect people from being exposed to others.
One such task is the disinfection of environments in which infection spread is particularly likely or bears increased risks. It has
been shown that UVC light is effective in neutralizing a variety
of pathogens, among others the virus causing COVID-19, SARSCoV-2. Another function which can reduce the need for physical
proximity between humans is interaction via telepresence, i.e.,
the remote embodiment of a person controlling the robot.
This work presents a modular mobile robot for telepresence
and disinfection with UVC lamps. Both operation modes are supported by adaptable autonomy navigation features for facilitating
efficient task execution. The platform’s primary contributions
are its hardware and software design, which combine consumergrade components and 3D-printed mountings with open-source
software frameworks.
Index Terms—Robotic Telepresence, UVC Disinfection, Adaptable Autonomy, Teleoperation, Open-Source Robotics, COVID-19

I. I NTRODUCTION
The global COVID-19 pandemic has disrupted public life
and entire industries. Exposing a severe lack of preparedness in
the healthcare sector, among others, administrations scrambled
to adjust to the new reality and prevent contagion in critical
environments such as hospitals and retirement homes. While
protective personal equipment was made available within
weeks and cleaning protocols ramped up, more actions can
be taken to avoid a spread of the virus and other pathogens.
Mobile robots are now entering a stage in which they have the
potential to make a difference in fighting the current and future
pandemics [1]. Two types of measures can help protect both
healthcare workers and patients, as well as older adults as the
primary risk group. Telepresence (or telemedicine) can reduce
the physical contact between healthcare workers and caregivers
on the one side and patients on the other [2]. Second, better
hygiene in hospitals further reduces the risk of transmission,
especially between patients.

Disinfection is an essential concern in hospital care. Even
before the first appearance of COVID-19, recent years have seen
a growing interest in alternative and supplementary methods for
disinfecting surfaces in high-risk environments. Besides cost
pressure, this development was precipitated by the increased
occurrence of Hospital-Acquired Infections (HAI), which are
associated with a rise in morbidity and deaths across a large
number of countries [3]. HAIs are most frequently attributed
to several types of bacteria, some of which over the years
have developed resistances to a wide range of antibiotics [4].
Standard cleaning procedures frequently fail to remove a
substantial share of potentially harmful microbes on hightouch surfaces. As a result, HAIs have become a common
cause of complications and deaths in patients that are immunocompromised or recently underwent surgery.
For decades, no-touch disinfection with Ultraviolet-C (UVC)
light has been applied in water purification [5], as it decontaminates without the need for chemical disinfectants. As such, it
represents a more environment-friendly and safer alternative.
Only in recent years it has been identified as a viable option for
decreasing the microbial burden on surfaces in hospitals, e.g.,
in patient and operating rooms [6]. As an adjunct procedure
to standard cleaning protocols using chemical cleaning agents
it has been shown to further reduce the density of microbes
on surfaces. Although the majority of HAIs are caused by
bacteria, UVC is similarly effective against viruses [7] and
fungi. Furthermore, unlike many chemical sanitizers, it leaves
no residues that might pose long-term health risks.
This work presents the design and implementation of an opensource modular disinfection and mobile robotic telepresence
system for prototyping and research. The system provides
functionality for environment mapping and semi-autonomous
navigation. The two operation modes, telepresence and UVC
disinfection, rely on the same architecture and interface and
only differ with regards to the hardware equipment on the
robot (i.e., the lamps which take the place of the screen).

While there are a variety of telepresence and a few disinfecVarious platforms with different sets of features are available
tion robots available on the market, the main motivation behind as consumer products on the market. In recent years it has
the presented work is to offer an approach and methodology become increasingly common to provide assisted driving
for building and deploying such robots on demand and within and other convenient capabilities beyond basic teleoperation
a narrow time frame. This implicates specific requirements, and telecommunication (e.g., Double 31 and Ava2 ). However,
especially with respect to the hardware. The approach taken such commercial products are generally not designed to be
in the present work relies on off-the-shelf components, simple customizable, as they do not provide access to components
assembly, and affordable manufacturing methods. The software and utilize proprietary software.
part of the project is designed for rapid deployment and
B. Disinfection with UVC Light
engineered in a way that permits easy modification.
The remaining part of the paper is organized as follows. In
With a wavelength spectrum ranging from approximately
Section II we discuss relevant work and developments related 100 to 280 nm, UVC light from the Sun is absorbed entirely
to both robotic telepresence and the use of Ultraviolet (UV) by the ozone layer. As a consequence, the only sources on
lamps for disinfection in hospitals, as well as the few efforts the Earth’s surface are artificial. UVC light causes inactivation
combining mobile robotics and UVC disinfection. Section III of microorganisms by damaging the RNA and DNA, thereby
provides a detailed description of hardware and software design inhibiting their reproduction [17]. Due to its strong germicidal
of our platform. Subsection III-C is concerned with the design properties it is well suited for disinfection in a wide range of
and behavior of the robot’s (semi-)autonomous functionality, scenarios.
followed by the conclusion in Section IV.
The time required for disinfecting a surface depends on
several factors. The maximal dose of light absorbed by a
II. R ELATED W ORK
surface is a function of the distance from the UVC source and
the output of the source, and is cumulative over time. The dose
A. Robotic Telepresence
is measured in J/m2 (in practice often in µWs/cm2 ) [6]. The
In a minimal configuration, a telepresence robot possesses surface material and presence of organic matter can play a role
a mobile base, which can be controlled remotely to navigate in the effectiveness of the procedure. The required dose for
through its environment, and a device for telecommunication, inactivation further depends on the initially present microbial
e.g., a tablet, smartphone or standard computer, along with a load and can vary between types of microorganisms. In clinical
wireless internet connection. In order to facilitate ’face-to-face’ tests, the effectiveness of a disinfection process is commonly
interaction, the screen and camera are typically mounted in expressed in log reductions of a known initial quantity of
an elevated position on top of the base [8]. In a telepresence pathogens on a test surface as a result of exposure from a
interaction the person controlling the robot is often referred to reference distance and over a fixed amount of time [18].
as the remote user or operator, whereas the local user(s) are
Today, the most widely used devices are fluorescent lamps
located in the same physical environment as the robot. Unlike based on low-pressure mercury vapor and emit UVC light at
standard communication devices, robotic telepresence affords a peak wavelength of 253.7 nm. Aside from the ultraviolet
the user a certain degree of freedom to explore and interact radiation, they give off visible light of a blueish-white hue.
with the local environment independently.
Other types include pulsed xenon lamps [19], [20] and in
In addition, with the introduction of advanced features such recent years UV Light-Emitting Diode (LED) lamps have been
as adaptable autonomy, users can be supported in controlling the shown to produce similar results in inactivating bacteria and
robot efficiently while focusing on relevant tasks [9]. Common viruses [21], [22]. LED lamps are especially promising for
application domains for telepresence robots include elderly deployment on robots, as they are significantly more energycare [10], [11], healthcare (as a form of telemedicine) [12], as efficient than fluorescent lamps and easier to install. However,
well as telecommuting in office or industrial environments [13]. at the time of writing they are not yet available in adequate
The range of action of current telepresence platforms is and certified devices.
still fairly limited. Besides the common limitations related to
Early studies concerned with evaluating the efficacy of
wheel-based locomotion and a lack of (effective) manipulators, UVC light for disinfection mainly sought to compare it with
their performance often suffers from a reduced sense of conventional methods, i.e., chemical disinfection [23]. The
remote presence and awareness within the robot’s environment. lamps used in these studies were deployed manually and
Important contributing factors to this impairment are the often moved between cycles. In some more recent efforts targeting
insufficient sensor resolution and Field-of-View (FoV) of practical use, arrays of lamps were mounted on a passive
common webcams [14], [15]. One of the goals in designing a wheeled platform to be moved manually from one position to
telepresence robot is to enhance the user experience and control another [18]. By placing several petri dishes with test cultures
performance by providing visual and auditory information that in different locations in a hospital room it is possible to obtain
matches as closely as possible people’s natural perception of evidence of efficacy under realistic conditions.
the world, either by using a camera with a wide angle or
1 https://www.doublerobotics.com
mounting it on an articulated element, so as to simulate head
2 www.avarobotics.com
movements [16].

Despite the documented conducive effect of disinfection
with UVC light, it has thus far only found sparse adoption in
the healthcare sector. This is attributable to a variety of factors,
not least a still unfavorable cost-benefit equation. Moreover,
deployment often remains impractical and associated with
added labor rather than an easing of the burden on healthcare
and custodial staff.
One drawback of UVC light is that it is harmful to the
skin and eyes of higher organisms, including humans, which
is why exposure must be strictly avoided. Therefore, robots
lend themselves as an obvious alternative for operating UVC
emitting devices and reducing human involvement to the extent
possible. Nevertheless, staff operating the lamps need to be
trained in handling them safely to avoid inadvertent exposure.
1) Practical Limitations: In practice, the efficacy of UVC
light as a disinfectant is limited by natural constraints, such
as the need for direct surface exposure. That is, any occluded
surfaces receive a significantly smaller dose, which is too low
for complete disinfection. Proximity of the light source to the
target surface is crucial, as intensity decreases in proportion
to the inverse square of its distance from that surface. In
addition, since UVC is absorbed by most materials, its effect
is diminished in the presence of organic residues such as blood
or urine [6].
Although extensible robotic arms could potentially reach
surfaces that are otherwise shadowed and UV-reflective wall
coating has been shown to reduce the duration of disinfection
cycles [24], neither method can guarantee that all sites receive
a sufficient dose. As a consequence, UVC disinfection is
inadequate as a standalone cleaning procedure. Rather, it can
complement environmental and spot cleaning as an additional
layer towards further decreasing the risk of nosocomial infections.

Fig. 1: High-level view of the system architecture in telepresence mode.

Robot), its control interface (Client), and the supporting server
for signaling and Network Address Translation (NAT) traversal
(Server Infrastructure) 3 . The latter two parts are not required
if the final system does not foresee telepresence or remote
control features.
A. Robot Hardware Design

The hardware design is based on an open-frame approach
which leaves structural components of the robot exposed. It
uses slotted aluminum extrusions to simplify assembly and
allow flexibility in mounting components. For the most part,
the hardware design makes use of standard consumer-grade offthe-shelf components to allow rapid customization, assembly,
and deployment in different geographical locations.
As is common for telepresence robots, the platform consists
of a wheel base and a screen mounted on a pole on top of the
base to provide the various functionalities. It is further equipped
with a 2D LIDAR for Simultaneous Localization and Mapping
(SLAM) and navigation, as well as a wide angle camera for
operation with an extended FoV. The wheels and mounts for
sensors and electronics as well as casings are printed from
III. S YSTEM A RCHITECTURE AND I MPLEMENTATION
PLA material. The robot was designed as a hybrid to be used
A major impediment in the early stages of the pandemic were for telepresence and UVC disinfection, with the screen and UV
intellectual property regulations preventing rapid large-scale lamps being swapped out between the two modes of operation
production of critical equipment. Examples of such products (as seen in Fig. 3).
range from simple adapters to complete ventilator designs.
Below, we describe the various components and infrastrucVital products had to be redesigned and released under various ture in more detail.
open-source licences to allow manufacturing on demand. Our
1) Chassis and Wheels: The frame consists of T-Slot 40
main purpose in developing the presented system was to make
aluminum extrusions which render the hardware platform highly
it available as an open-source project that can be implemented
modular and reconfigurable. The robot’s kinematics consist
by anyone. Therefore, the focus was placed on simplicity, ease
in a symmetrical differential drive, which allows rotating in
of manufacturing, as well as software and hardware licensing.
place. The two motor-driven wheels on the sides are supported
Another central factor shaping the overall architectural design by a caster wheel in the front and rear each, resulting in
of the robotic system is its adaptability to a wide variety of user an overall footprint of 49x62cm (WxL). The vertical pole
requirements. Being primarily intended as a research platform is attached centrally on top of the base. This simple design
for experimentation in robotic telepresence, modularity and provides high stability, capable of supporting relatively large
adaptability are vital both with respect to hardware and software. payloads such as a 22” touchscreen display at a high mounting
At the same time, the development was also motivated by the point. Additionally, universal mounting adapters can be attached
intention to make the system available to a wider community, as and rearranged freely on the T-Slots. Electronic components
a platform for implementing robotic solutions for telepresence are mounted onto the frame with cabling hidden inside the
and remote disinfection.
An overview of the system’s three major components is
3 The source code of all components and blueprints are available at
shown in Fig. 1. They include the robotic platform (Sp00tn1k https://bitbucket.org/sp00tn1k

Fig. 2: Overall system architecture in telepresence mode

extrusion where possible (see Fig. 3). While this design yields a high quality audio input and output, while a Huddly IQ
high degree of flexibility, it also exposes electrical connections, camera delivers the video stream from the local environment.
which can be undesirable in a number of cases. With the camera A 360◦ 2D laser range finder (RPLIDAR S1) detects obstacles
sitting on top of the pole, the robot measures 1.65 m in height. on a plane around the robot. This information is used for
It weighs 17.5 kg in the telepresence configuration and 13.6 kg several processes, including mapping, localization, autonomous
with the disinfection lamps mounted.
navigation and assisted teleoperation.
The base does not have any built-in suspension. Instead,
the flexible wheels enable the robot to traverse small bumps,
3) Disinfection Lamps: In the current setup the platform is
such as carpets and thresholds. This design is prone to higher equipped with 4 fluorescent UVC lamps (Philips T8, 16.7 W)
instabilities in comparison with traditional suspension with with a length of 590 mm. The lamps are attached on the pole at
dampers and stabilizer bars, but usually performs better than a height of approximately 1.2 m and arranged in a semicircle
inflated wheels. The wheels are 3D-printed in two parts, using in the front. The UVC output per lamp is equal to 4.5 W,
PLA material for the rims and TPU 95A for the tires. The which corresponds to a maximum intensity of 35.8 µW/cm2
robot is powered by two parallel 12V lithium-iron-phosphate at 1m distance. For efficient use in real-world scenarios a
(LiFEPo4) batteries with a capacity of 60 Wh each. Under higher wattage as well as possibly additional lamps are highly
normal load the average runtime is roughly 3 hours. The motors suggested. The lamps are controlled through the client and set
are Actobotics 12 V 313RPM DC planetary gear motors with to be deactivated when the connection with the client is lost.
a 27:1 gear ratio. The low-level controller runs on an Arduino
Mega 2560 board and uses a Cytron 10A 7-30V dual channel
4) Modularity: Since the screen and lamps occupy the same
motor driver.
space on the robot, they need to be replaced when switching
2) Components and Sensors: The robot’s computer is an between the operation modes. The components listed above
Intel® NUC 10 (NUC10i7FNK) with 32GB RAM and a solid are an example configuration. In most cases there are less
state drive. The screen for the telepresence mode is a 22” expensive equivalents that serve the purpose sufficiently well.
iiyama ProLite TF2215MC-B2 which is rotated in portrait Individual components can be omitted altogether, depending
mode. In addition, a Jabra SPEAK 410 speakerphone provides on the application.

Fig. 3: Sp00tn1k robot. Left: CAD assembly view with mounted UVC lamps. Center: Assembled robot. Right: Robot with
display instead of lamps.

B. Robot Software Design

1) ROS Infrastructure: The platform itself runs on the opensource ROS framework (noetic distribution on Ubuntu 20.04),
making use of readily available and established packages such
as the ROS navigation stack, rosserial and cartographer for
SLAM. In addition, several packages were developed to provide
the back end functionality of the client UI, as well as the
assisted teleoperation mode. The ROS package rosbridge server
allows transmission of ROS messages to and from the client
through WebRTC’s data channel.

The two major components of the software infrastructure
are Robot Operating System (ROS) and Web Real-Time
Communication (WebRTC). Being fully open-source, they
offer the necessary interfaces both on a process level on the
robot and for web-based communication with and through the
client. WebRTC was selected as a means of communication
between the robot and its control interface. The main motivation
for using WebRTC is its wide support by most modern web
browsers, as well as its ability to fully handle communication
2) Client and Robot UI: The client interface can be
between peers via media and data channels. It further supports controlled via mouse and touch input (see Fig. 4). Located in
open-source codecs for media streams, such as VP8 and OPUS, the center of the screen is the video stream from the robot’s
and implements security on the communication channel level. camera showing the local environment. Two sidebars to the
As a result, the system can be controlled using any device left and right host the client’s own video stream, a map of the
capable of running modern browsers with WebRTC support.
environment (if available) and further inputs for the robot’s
Developers are only required to implement signalling be- controls, e.g., for activating and deactivating the UVC lamps.
tween peers and handle media and data streams on the robot The video stream is embedded in a 3D-rendered environment.
and control interface. On sp00tn1k the PeerJS library [25] is This allows displaying other relevant information, as well as
responsible for these tasks.
switching to a Virtual Reality (VR) mode. New features can

Fig. 4: The client interface. Left: The remote user’s own video stream, autonomy level slider and disinfection lamp control.
Center: The robot’s video stream. Right: A map of the environment.

be introduced via a plugin system without interfering with the from the client at the rosbridge server are passed on to the
rest of the infrastructure.
driver controller by means of rosserial communication.
The interface on the robot’s side is minimal, comprising
primarily the incoming video stream from the client’s side. Like C. Adaptable Autonomy
the client, it can be extended to host additional information
In order to facilitate multi-purpose deployment and satisfy
and functionality, such as a local control mode.
3) Communication: The robot connects to a peering server different user requirements and preferences, the platform can
on startup and waits for incoming connections. The client navigate at various degrees of autonomy. By clicking on a
software is loaded from the web server, and also connects to position on the map, be it static (prerecorded) or dynamic
a peering server when loaded. Subsequently, the client can (SLAM), the robot leverages the ROS navigation stack to
attempt to connect and log on to the robot with a known ID. plot and follow a route to the appropriate position in the
The Session Traversal Utilities for NAT (STUN) and Traversal environment. The robot is teleoperated manually by clicking
Using Relays around NAT (TURN) servers are required to on the central video image. A disk-shaped element projected
on the floor indicates the approximate location to where the
establish a direct connection between the robot and a client.
Two channels mediate communication between the client robot will move. Teleoperation can be used either without any
and the robot. The RTCMediaStream transmits full-duplex support or with assistance. This entails collision avoidance by
audio and video, and the RTCDataChannel is responsible for decelerating in close proximity to nearby objects. Moreover, in
control commands and telemetry data. Both are contained in a second assistance mode, the robot steers away from obstacles
an RTCPeerConnection object (see Fig. 2). Because the robot to either side. The interface further affords seamless switching
uses ROS as its control framework, the client software is also between the different navigation modes, thus allowing users to
”ROS-aware”, i.e., it communicates with the robot through quickly adapt to new situations.
Two of the navigation modes (assisted teleoperation and
ROS messages.
On the robot side, the audio stream is routed directly to autonomous) were evaluated in a previous user study [26].
its audio devices. The incoming video stream is displayed Following the study results, the client’s responsiveness and
in the UI and the outgoing stream is supplied by a virtual feedback were augmented to offer enhanced transparency when
loopback webcam device. This way the camera image can be operating in the assisted or autonomous mode. A central
aspect in the design of autonomous functions is to ensure that
preprocessed before being streamed to the client.
Control messages are transparently passed by the robot’s users maintain a high degree of situation awareness while not
communication part (ws gateway on the diagram) to ROS via incurring excess mental workload [27]. To prevent confusion
the local WebSocket connector. Navigation messages arriving and frustration, a GUI element located in the sidebar of the

interface displays which mode is active at any moment (see
Fig. 4).
IV. C ONCLUSION
The platform described in this paper is a research-oriented
work in progress and as such not ready to be deployed for
disinfection. However, we hope that it can serve as a basis for
the development of fully operational devices.
It is believed that pandemics like the current one are going
to become more frequent and we understand now that we
need to be better prepared for the next one. It is likely that
both mobile robotics and disinfection with UVC light will
play a vital role in combating future outbreaks and preventing
widespread infection with contagious diseases in public spaces.
Even though the utility of most available mobile robots is still
fairly limited, telepresence robots may, in the not too distant
future, become true embodiments of people in the world.
A. Limitations and Future Work
In its present form the robot cannot mechanically manipulate
its surroundings. As a consequence, autonomous disinfection
relies on appropriate infrastructure or provisions in the environment where it is deployed. Doors and stairs represent barriers
that need to be accounted for. As previously noted, the UVC
output of the current configuration is relatively low. A higher
wattage increases the dose delivered to a nearby surface in a
given time and thus reduces the time the robot needs to stop
at each visited location accordingly. In turn, a higher battery
capacity can compensate for the increased energy intake to
yield a reasonable runtime between charge cycles.
An integrated task planner will allow users to plan and
schedule disinfection in a larger area (e.g., an entire hospital
wing) from within the client. At a subsequent stage the robot
might be taught to select appropriate poses for disinfecting a
provided selection of prioritized surfaces and sites based on
respective distances and angles. This way the need for human
intervention could be further reduced.
The assisted teleoperation currently relies on rule-based
methods to avoid or soften collisions with the environment. In
a next step machine learning may further enhance the capacity
to provide assistance by leveraging feedback from the user and
learning their preferences.
With the robot conceivably being deployed in a variety of
different environments and scenarios, local users should be
enabled to control it as well as the remote user. For this purpose,
different interfaces may qualify, such as game controllers, the
touch screen or even speech and gestures. Yet another useful
feature both for remote and local control is autonomous people
following [28].
A key aspect for the safe use and acceptance of telepresence
robots is privacy. As usage scenarios vary with respect to the
scenario and overall purpose, so do usage and access rights –
both of remote and local users. In a public environment such
as a hospital, there may be telepresence platforms for anyone
to log in to. In private homes, however, it would be up to
the local user to accept a requested login, analogous to any

conventional telecommunication device. Yet other arrangements
are conceivable if a caregiver is to check in regularly on
a patient or relative. Accordingly, any commercial platform
should be able to handle these different scenarios.
F UNDING
This work has received funding from the European Union’s
Horizon 2020 research and innovation program under the
Marie Skłodowska-Curie grant agreement No 721619 for the
SOCRATES project and the testbed for Autonomous Intelligent
Machines for Enterprise and Exploration (AI.MEE) at Örebro
University.
ACKNOWLEDGMENTS
The authors express gratitude to Samer Dia for his work on
the design and manufacturing of the flexible wheels.
R EFERENCES
[1] G.-Z. Yang, B. J. Nelson, R. R. Murphy, H. Choset, H. Christensen,
S. H. Collins, P. Dario, K. Goldberg, K. Ikuta, N. Jacobstein, et al.,
“Combating covid-19—the role of robotics in managing public health
and infectious diseases,” 2020.
[2] G. Yang, H. Lv, Z. Zhang, L. Yang, J. Deng, S. You, J. Du, and H. Yang,
“Keep healthcare workers safe: Application of teleoperated robot in
isolation ward for covid-19 prevention and control,” Chinese Journal of
Mechanical Engineering, vol. 33, no. 1, pp. 1–4, 2020.
[3] J. I. Barrasa-Villar, C. Aibar-Remón, P. Prieto-Andrés, R. Mareca-Doñate,
and J. Moliner-Lahoz, “Impact on morbidity, mortality, and length of stay
of hospital-acquired infections by resistant microorganisms,” Clinical
Infectious Diseases, vol. 65, no. 4, pp. 644–652, 2017.
[4] H. A. Khan, A. Ahmad, and R. Mehboob, “Nosocomial infections and
their control strategies,” Asian pacific journal of tropical biomedicine,
vol. 5, no. 7, pp. 509–514, 2015.
[5] K. Song, M. Mohseni, and F. Taghipour, “Application of ultraviolet
light-emitting diodes (uv-leds) for water disinfection: A review,” Water
research, vol. 94, pp. 341–349, 2016.
[6] B. Andersen, H. Bånrud, E. Bøe, O. Bjordal, and F. Drangsholt,
“Comparison of uv c light and chemicals for disinfection of surfaces
in hospital isolation units,” Infection Control & Hospital Epidemiology,
vol. 27, no. 7, pp. 729–734, 2006.
[7] C. P. Sabino, F. P. Sellera, D. F. Sales-Medina, R. R. G. Machado, E. L.
Durigon, L. H. Freitas-Junior, and M. S. Ribeiro, “Uv-c (254 nm) lethal
doses for sars-cov-2,” Photodiagnosis and Photodynamic Therapy, 2020.
[8] A. Kristoffersson, S. Coradeschi, and A. Loutfi, “A Review of Mobile Robotic Telepresence,” Advances in Human-Computer Interaction,
vol. 2013, pp. 1–17, 2013.
[9] A. Potenza, A. Kiselev, A. Loutfi, and A. Saffiotti, “Towards sliding
autonomy in mobile robotic telepresence: a position paper,” in ECCE
2017-European Conference on Cognitive Ergonomics, 20-22 September
2017, Umeå University, Sweden, 2017.
[10] A. Orlandini, A. Kristoffersson, L. Almquist, P. Björkman, A. Cesta,
G. Cortellessa, C. Galindo, J. Gonzalez-Jimenez, K. Gustafsson, A. Kiselev, et al., “Excite project: A review of forty-two months of robotic
telepresence technology evolution,” Presence: Teleoperators and Virtual
Environments, vol. 25, no. 3, pp. 204–221, 2016.
[11] J. M. Beer and L. Takayama, “Mobile Remote Presence Systems for
Older Adults : Acceptance , Benefits , and Concerns,” in Proceedings of
the 6th International Conference on Human-Robot Interaction HRI 11,
HRI ’11, pp. 19–26, ACM, 2011.
[12] A. Garingo, P. Friedlich, T. Chavez, L. Tesoriero, S. Patil, P. Jackson,
and I. Seri, ““tele-rounding” with a remotely controlled mobile robot in
the neonatal intensive care unit,” Journal of Telemedicine and Telecare,
vol. 22, no. 2, pp. 132–138, 2016.
[13] K. M. Tsui, M. Desai, H. A. Yanco, and C. Uhlik, “Exploring use
cases for telepresence robots,” in Proceedings of the 6th international
conference on Human-robot interaction - HRI ’11, no. August, (New
York, New York, USA), p. 11, ACM Press, 2011.

[14] S. Johnson, I. Rae, B. Mutlu, and L. Takayama, “Can you see me
now? how field of view affects collaboration in robotic telepresence,” in
Proceedings of the 33rd Annual ACM Conference on Human Factors in
Computing Systems, pp. 2397–2406, 2015.
[15] A. Kiselev, A. Kristoffersson, and A. Loutfi, “The Effect of Field of
View on Social Interaction in Mobile Robotic Telepresence Systems,”
in HRI2014, (New York, New York, USA), pp. 214–215, ACM Press,
2014.
[16] M. Karimi, T. Aykut, and E. Steinbach, “Mavi: A research platform for
telepresence and teleoperation,” arXiv preprint arXiv:1805.09447, 2018.
[17] T. D. Cutler and J. J. Zimmerman, “Ultraviolet irradiation and the
mechanisms underlying its inactivation of infectious agents,” Animal
Health Research Reviews, vol. 12, no. 1, p. 15, 2011.
[18] J.-H. Yang, U.-I. Wu, H.-M. Tai, and W.-H. Sheng, “Effectiveness of an
ultraviolet-c disinfection system for reduction of healthcare-associated
pathogens,” Journal of Microbiology, Immunology and Infection, vol. 52,
no. 3, pp. 487–493, 2019.
[19] S. E. Simmons, R. Carrion, K. J. Alfson, H. M. Staples, C. Jinadatha,
W. R. Jarvis, P. Sampathkumar, R. F. Chemaly, F. Khawaja, M. Povroznik,
et al., “Deactivation of sars-cov-2 with pulsed-xenon ultraviolet light:
Implications for environmental covid-19 control,” Infection Control &
Hospital Epidemiology, pp. 1–4, 2020.
[20] M. M. Nerandzic, P. Thota, T. Sankar, A. Jencson, J. L. Cadnum, A. J.
Ray, R. A. Salata, R. R. Watkins, and C. J. Donskey, “Evaluation of a
pulsed xenon ultraviolet disinfection system for reduction of healthcareassociated pathogens in hospital rooms,” infection control & hospital
epidemiology, vol. 36, no. 2, pp. 192–197, 2015.

[21] S. E. Beck, H. Ryu, L. A. Boczek, J. L. Cashdollar, K. M. Jeanis,
J. S. Rosenblum, O. R. Lawal, and K. G. Linden, “Evaluating uv-c
led disinfection performance and investigating potential dual-wavelength
synergy,” Water research, vol. 109, pp. 207–216, 2017.
[22] P. O. Nyangaresi, Y. Qin, G. Chen, B. Zhang, Y. Lu, and L. Shen,
“Comparison of the performance of pulsed and continuous uvc-led
irradiation in the inactivation of bacteria,” Water research, vol. 157,
pp. 218–227, 2019.
[23] N. L. Havill, B. A. Moore, and J. M. Boyce, “Comparison of the
microbiological efficacy of hydrogen peroxide vapor and ultraviolet
light processes for room decontamination,” Infection Control & Hospital
Epidemiology, vol. 33, no. 5, pp. 507–512, 2012.
[24] W. A. Rutala, M. F. Gergen, B. M. Tande, D. J. Weber, et al.,
“Rapid hospital room decontamination using ultraviolet (uv) light with a
nanostructured uv-reflective wall coating,” Infect Control Hosp Epidemiol,
vol. 34, no. 5, pp. 527–529, 2013.
[25] M. Bu and E. Zhang, “Simple peer-to-peer with webrtc,” 2020.
[26] S. Olatunji, A. Potenza, A. Kiselev, T. Oron-Gilad, A. Loutfi, and Y. Edan,
“Levels of automation for a mobile robot teleoperated by a caregiver.”
under review, 2020.
[27] J. Beer, A. D. Fisk, and W. A. Rogers, “Toward a framework for levels
of robot autonomy in human-robot interaction,” Journal of Human-Robot
Interaction, vol. 3, no. 2, p. 74, 2014.
[28] S. Olatunji, T. Oron-Gilad, V. Sarne-Fleischmann, and Y. Edan, “Usercentered feedback design in person-following robots for older adults,”
Paladyn, Journal of Behavioral Robotics, vol. 11, no. 1, pp. 86–103,
2020.

