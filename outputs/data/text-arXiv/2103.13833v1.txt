Deep Learning with robustness to missing data:
A novel approach to the detection of COVID-19

arXiv:2103.13833v1 [eess.IV] 25 Mar 2021

Erdi Çallı1 *, Keelin Murphy1 , Steef Kurstjens2 , Tijs Samson2 , Robert Herpers3 , Henk
Smits3 , Matthieu Rutten1,2 , Bram van Ginneken1
1 Diagnostic Image Analysis Group, Radboudumc, Nijmegen, the Netherlands
2 Laboratory for Clinical Chemistry and Hematology, Jeroen Bosch Hospital,
’s-Hertogenbosch, the Netherlands
3 Laboratory for Clinical Chemistry and Hematology, Bernhoven Hospital, Uden, the
Netherlands
* erdi.calli@radboudumc.nl

Abstract
In the context of the current global pandemic and the limitations of the RT-PCR test,
we propose a novel deep learning architecture, DFCN, (Denoising Fully Connected
Network) for the detection of COVID-19 using laboratory tests and chest x-rays. Since
medical facilities around the world differ enormously in what laboratory tests or chest
imaging may be available, DFCN is designed to be robust to missing input data. An
ablation study extensively evaluates the performance benefits of the DFCN architecture
as well as its robustness to missing inputs.
Data from 1088 patients with confirmed RT-PCR results are obtained from two
independent medical facilities. The data collected includes results from 27 laboratory
tests and a chest x-ray scored by a deep learning network. Training and test datasets
are defined based on the source medical facility. Data is made publicly available.
The performance of DFCN in predicting the RT-PCR result is compared with 3
related architectures as well as a Random Forest baseline. All models are trained with
varying levels of masked input data to encourage robustness to missing inputs. Missing
data is simulated at test time by masking inputs randomly.
Using area under the receiver operating curve (AUC) as a metric, DFCN
outperforms all other models with statistical significance using random subsets of input
data with 2-27 available inputs.
When all 28 inputs are available DFCN obtains an AUC of 0.924, higher than
achieved by any other model. Furthermore, with clinically meaningful subsets of
parameters consisting of just 6 and 7 inputs respectively, DFCN also achieves higher
AUCs than any other model, with values of 0.909 and 0.919.

Introduction
COVID-19 (the novel coronavirus disease) has disrupted the world since December 2019.
Since then, the Reverse Transcription Polymerase Chain Reaction (RT-PCR) test has
been the primary testing method to confirm positive cases.
Despite its general acceptance, the RT-PCR test has limited sensitivity, as well as
being relatively expensive, and difficult to implement [1]. The RT-PCR requires

March 26, 2021

1/22

specialized and expensive equipment as well as trained personnel. Issues such as swab
contamination make it difficult to apply in non-optimal circumstances. Even with
modern laboratory facilities, it takes at least 2-3 hours to obtain the result of this test.
Such constraints are difficult to overcome in the developing world, during localized
infection peaks or for mass testing.
As an alternative to the RT-PCR test, meta-analyses [2–4] have shown that routine
laboratory test results can distinguish the RT-PCR test outcome, as well as the disease
severity and patient mortality risk. Further, some studies [5–10] propose using a chest
x-ray to predict the RT-PCR test outcome. In [11] a protocol is defined that combines
the chest x-ray interpretation with important laboratory parameters to predict the
RT-PCR test outcome. In contrast to the RT-PCR test, the chest X-ray (CXR) and
routine laboratory tests are readily available and cheaper to obtain in most scenarios.
Various machine learning methods have been proposed to make predictions of
clinical information from laboratory parameters. For example, [12] trains an ensemble of
deep neural networks using 41 blood chemistry and cell count results to predict
chronological age and sex. They report a mean absolute error of 5.55 years in a test
dataset of 6252 patients. In [13], the use of 13 laboratory parameters to predict patient
cardiovascular risk is evaluated. The study reports the use of various machine learning
algorithms, such as tree-based, regression-based, neural network, or nearest neighbour.
Researchers in [14] use various machine learning models to determine the baseline
hemoglobin and creatinine levels of ICU patients. They use vital signs (such as
temperature and heart rate) as well as 28 routine laboratory parameters. This approach
was shown to improve acute kidney injury classification. In [15], 33 laboratory
measurements are used as well as age and gender to predict inpatient mortality using
various models (such as random forests, boosted trees, or neural networks). This
method is compared to the traditional approach of using logistic regression models.
Denoising autoencoders [16] and their variants are used commonly on clinical data.
In [17], denoising autoencoders are used on a sleep breathing dataset to improve the
cardiovascular disease prediction of a classifier with missing input values. In another
study, [18] Defines autoencoders to detect coronary heart disease risk prediction using
health and nutritional data, [19] uses compares stacked denoising autoencoders to FCN,
LSTM and SVM models to detect 97 health conditions from 81 clinical features and
patient metadata. The same authors later combine two denoising autoencoders, one for
high and one for low levels of glycated haemoglobin, to improve the early detection of
Type-2 Diabetes Mellitus from 78 features [20].
In this study, we propose a novel architecture, the denoising fully connected network
(DFCN), to predict the RT-PCR test result with high accuracy while remaining robust
to missing input data. Missing data is an issue in the medical domain, as in many
others [21]. There is no global protocol to determine which laboratory or imaging data
is collected from a patient. The availability of medical instruments differs per medical
facility or may be limited by cost/availability considerations. In the developing world,
for example, the range of blood tests or imaging techniques available is typically
extremely limited. In any setting data may also be lost or inaccessible due to instrument
malfunction or other reasons. Such issues are very common and they pose a problem for
machine learning models trained with a specific set of inputs. To overcome this issue,
DFCN is designed to function well in the context of missing data, to ensure the utility
of the model in most settings globally, including those where laboratory testing and
imaging facilities are limited. Unlike the denoising autoencoders used to address missing
data in previous works, the DFCN architecture does not include a bottleneck (efficiency
constraint) which we demonstrate improves the performance of the model.
During training, we make use of 27 routine laboratory tests combined with the chest
x-ray interpretation of a deep learning model. An ablation study is performed to

March 26, 2021

2/22

compare the model with related architectures as well as a baseline Random Forest
classifier. Performance in the context of missing data is demonstrated using random
subsets of inputs and with two specific subsets, (A and B), selected based on clinical
utility and cost efficiency.
DFCN performs significantly better (p ≤ 0.05) than all other methods in
experiments on extensive random subsets of data with 2-27 inputs. In experiments with
1 or 28 available inputs only one other model performs similarly. It obtains 0.924 AUC
on the test dataset with all available inputs, which falls to 0.909 or 0.919 respectively if
only subset A or B of the parameters is available. We demonstrate that there is no
advantage to training these models with the subset of inputs expected at test time. In
experiments using test data with subsets A and B of inputs, DFCN trained on all inputs
achieves a higher AUC than models retrained with only subset A or B of inputs
respectively. To our knowledge, this is the first time the DFCN architecture has been
proposed and evaluated. Its novel benefits in terms of classification performance and
robustness to missing data are demonstrated in this work. It is additionally applied to a
globally important problem - diagnosis of COVID-19 - where issues of missing input
data may be expected.

Data and Methods
In this section, we present the data and proposed methods to combine laboratory
parameters with chest x-ray interpretation for prediction of the RT-PCR result using
DFCN and other compared methods.

Data
This study was approved by the Institutional Review Boards of Jeroen Bosch Hospital
(‘s-Hertogenbosch, The Netherlands), Bernhoven Hospital (Uden, The Netherlands) and
Radboud University Medical Center (Nijmegen, The Netherlands). Informed written
consent was waived, and data collection and storage were carried out in accordance with
local guidelines.
Data was collected from patients attending the emergency department of either
hospital with respiratory complaints between 5 March 2020 and 26 April 2020. From
those patients, up to 27 laboratory parameters, a frontal chest x-ray, and an RT-PCR
test result for COVID-19 were collected. All laboratory parameters were not always
available; in Table 1 we present the number of available laboratory parameters per
hospital. The distribution of the laboratory parameter values per institute and RT-PCR
test results are provided in Supporting Information S1 Fig.
The data includes 640 subjects (382 COVID-19 positive) from Bernhoven Hospital
(BHH) and 488 subjects (291 COVID-19 positive) from Jeroen Bosch Hospital (JBH),
all with confirmed RT-PCR test results. In all experiments, we use the BHH dataset as
the training dataset (since it has a larger number of samples) and the JBH dataset as
the test dataset. The data is publicly available1 .
Experiments using random subsets of input parameters are used to demonstrate
robustness to missing data in general. We additionally define two specific subsets (A
and B) which represent more realistic input combinations in practise. Subset A includes
the (6) laboratory/imaging parameters indicated as important in [11] and likely to be
available in medical facilities in most industrialized countries. Subset B includes (7)
laboratory/imaging inputs which are relatively inexpensive to obtain and could be
acquired by point-of-care machines in a low-resource setting. These parameters were
1 The

March 26, 2021

data is publicly available at https://doi.org/10.5281/zenodo.4461478

3/22

Table 1. Data used in this study from Jeroen Bosch Hospital (JBH) and Bernhoven
Hospital (BHH), divided by RT-PCR result. Laboratory and Imaging data parameters
collected are indicated in the rows. Letters (A, B) are used to indicate which inputs
belong to subsets A and B described in Section Data. Numbers of subjects are provided,
values in parentheses indicate the numbers of subjects for whom the value was missing
or not collected.
Institute
RT-PCR

BHH

JBH

Negative

Positive

Negative

Positive

258 (0)
258 (0)
258 (0)
32 (226)
258 (0)
258 (0)
258 (0)
253 (5)
253 (5)
253 (5)
253 (5)
253 (5)
51 (207)
258 (0)
258 (0)
258 (0)
258 (0)
255 (3)
258 (0)
249 (9)
258 (0)
258 (0)
184 (74)
258 (0)
222 (36)
258 (0)
258 (0)

382 (0)
382 (0)
382 (0)
23 (359)
382 (0)
382 (0)
382 (0)
378 (4)
378 (4)
378 (4)
378 (4)
378 (4)
12 (370)
382 (0)
382 (0)
382 (0)
382 (0)
375 (7)
382 (0)
374 (8)
382 (0)
382 (0)
224 (158)
382 (0)
170 (212)
382 (0)
382 (0)

193 (4)
193 (4)
165 (32)
194 (3)
194 (3)
185 (12)
197 (0)
188 (9)
188 (9)
188 (9)
188 (9)
188 (9)
91 (106)
95 (102)
195 (2)
196 (1)
196 (1)
190 (7)
196 (1)
166 (31)
196 (1)
196 (1)
191 (6)
196 (1)
118 (79)
196 (1)
196 (1)

283 (8)
282 (9)
239 (52)
289 (2)
290 (1)
271 (20)
291 (0)
286 (5)
286 (5)
286 (5)
286 (5)
286 (5)
213 (78)
219 (72)
291 (0)
289 (2)
289 (2)
284 (7)
291 (0)
239 (52)
289 (2)
289 (2)
278 (13)
291 (0)
266 (25)
289 (2)
290 (1)

258 (0)

382 (0)

197 (0)

291 (0)

Laboratory Parameter (Subsets)
Alkaline Phosphatase
Alanine Aminotransferase
Aspartate Aminotransferase
Bilirubin Direct
Bilirubin Total
Creatine Kinase
C-Reactive Protein (A, B)
Absolute Basophil Count (B)
Absolute Eosinophil Count (B)
Absolute Lymphocyte Count (A, B)
Absolute Monocyte Count (B)
Absolute Neutrophil Count (A, B)
D-Dimer
Ferritin (A)
Gamma-Glutamyl Transferase
Hemoglobin
Hematocrit
Potassium
Creatinine
Lactate Dehydrogenase (A)
Absolute Leukocyte Count
Mean Corpuscular Volume
Magnesium
Sodium
Procalcitonin
Thrombocyte Count
Urea
Chest X-Ray (A, B)

planned for use in a funded research project in Africa [22], based on pilot test results, at
the time of writing. The inputs in each of these subsets are indicated in Table 1.
Validation dataset
From the training (BHH) dataset, we derive a validation dataset of 102 patients, 86 of
these patients have PA (upright) chest x-rays (43 RT-PCR positive, 43 RT-PCR
negative) and 16 have AP (bedside) chest x-rays (8 RT-PCR positive, 8 RT-PCR
negative). These represent approximately 20% of the training dataset population and
are chosen at random.

March 26, 2021

4/22

Extracting RT-PCR likelihood score from CXRs
SARS-CoV-2 may infect the lungs and manifest as viral pneumonia, which is usually
visible on a chest x-ray as opacities in the lungs. To incorporate information from the
chest x-ray in our system we first train a classifier to predict RT-PCR results based on
the chest x-ray image. This classifier is used to produce a likelihood score representing
the chest x-ray information. To create a good starting point for this classifier, we use
the RSNA-Pneumonia dataset [23] for pre-training.
The RSNA-Pneumonia dataset consists of 26684 chest x-rays acquired in the
pre-COVID-19 era. These chest x-rays were annotated by 17 radiologists using 3 labels
(Normal, No Lung Opacity / Not Normal, and Lung Opacity). For this study, we split
the labeled data into training, validation, and test datasets consisting of 22184, 1500,
and 3000 chest x-rays respectively. The training dataset contains 7351 Normal, 10321
No Lung Opacity / Not Normal, and 4512 Lung Opacity cases. The validation and test
datasets have equally distributed classes.
We pre-train our convolutional neural network (Resnet 18) on the RSNA-Pneumonia
dataset and retrain the last layer of the resulting model on the BHH dataset, to predict
a probability for the RT-PCR test outcome.

Denoising Fully Connected Network
In this study, we propose a novel architecture which we refer to as the Denoising Fully
Connected Network (DFCN). The term denoising has been used to refer to the
objective of reconstructing inputs in the field of Autoencoders [16]. The DFCN
architecture is designed such that the primary objective is a classification task
(prediction of the RT-PCR result in this case) while the objective of reconstructing
masked inputs is applied as a regularizer during training. The model is trained with
randomly masked inputs which, combined with this unique regularization method,
instills a robustness to missing input data.
The details of the fundamental elements of DFCN are described in the sub-sections
below.
Randomly Masked Inputs
The findings of [24, 25] indicate that randomly masking model inputs improves model
generalization to unseen data. In the context of internal features of neural networks, [26]
has shown that dropout (randomly masking the inputs of layers) helps models develop
better, more generalized, internal representations. Based on these findings, we identified
random input masking as a key feature in developing a model robust to missing inputs.
In our training experiments, scalar inputs to the model are randomly set to zero with a
specified probability (input masking probability, IMP). Different IMP values are
evaluated as described in Section Model Selection: Validation dataset experiments.
Reconstruction Regularization
In Denoising Autoencoders [16], the objective of input reconstruction is used to
pre-train an Autoencoder and hence develop an optimal encoder of the input data. This
trained encoder can then be used as the early layers in subsequent tasks such as
classification, for example. In DFCN, however, this process is modified to train the
decoder and classifier at the same time. The decoding objective is used as a regularizer
for the classification task. In this study, we define the reconstruction regularizer based
on the L2 sum of the reconstruction errors of the masked and known inputs. This
process is illustrated in Fig 1.

March 26, 2021

5/22

Fig 1. An illustration of how the reconstruction regularization term is calculated, in
combination with input masking. The top two rows identify data that is missing in our
dataset. The subsequent two rows indicate data that is randomly masked at training
time. Dashed lines demonstrate that only values which are both known and masked are
used in calculating the reconstruction regularization term.
No Efficiency Constraint
Denoising Autoencoders are bound to creating so-called efficient encodings of the
masked inputs. We refer to this property as the efficiency constraint and it is achieved
by the use of a ”bottleneck” architecture which limits the number of features that
represent the input data. In autoencoders [27], it is argued that this bottleneck is
necessary to prevent learning a one-to-one mirroring of inputs. When defining DFCN,
we bypass this necessity because the reconstruction loss is only applied to the known
and masked input values. Hence, the model can not learn such a one-to-one mirroring.

Ablation Study
In this section we describe the ablation study that compares the DFCN to 3 related
model architectures to try to identify its important properties. We additionally present
results using a Random Forest classifier as a baseline.
Fig 2 illustrates the general high-level architecture that is common among the
models which are described in more detail below. The principal idea is to encode the
network input and then use this encoding to make a classification as positive or negative.
The variants on this architecture used in the ablation study are described in the
sub-sections below. All models are trained with various levels of random input masking.
Denoising Fully Connected Network
The DFCN uses reconstruction regularization during the training procedure of a fully
connected network, as described in detail in section Denoising Fully Connected Network.
This model architecture is illustrated in Fig 3.
Fully Connected Network
This model, (FCN), removes the reconstruction regularization that is used during the
training of DFCN. It is illustrated alongside DFCN in Fig 3.

March 26, 2021

6/22

Fig 2. High level illustration of the architecture underlying the neural networks
in the ablation study. The RT-PCR classifier score from the chest x-ray is extracted
using a CNN (top-right). This score is concatenated with the laboratory parameters.
During training, inputs are masked by removing a certain percentage of the inputs
randomly. The models incorporate an encoder, a classifier (for RT-PCR result
prediction), and a decoder to reconstruct the masked inputs.

Fig 3. Architectures of DFCN and FCN. DFCN is trained using randomly
masked inputs and uses the reconstruction of the inputs as a regularizer during the
training process. FCN ignores the reconstruction objective. Numbers of neurons are
indicated alongside the fully connected layers (large right arrows).
Denoising Autoencoder
As per [16] the Denoising Autoencoder (DAE) uses a two-step training procedure,
training firstly the encoder-decoder pair to reconstruct the unmasked inputs, and fixing
the weights of the encoder. Next, we use this encoder to extract features from inputs
and train a classifier using these features. Compared to DFCN, this model does not
make use of the reconstruction objective as a regularizer, but as a pre-training step.
Also, this model is bound by the efficiency constraint as it is constructed with the
typical autoencoder bottleneck architecture. The DAE is illustrated in Fig 4.

March 26, 2021

7/22

Fig 4. Architectures of DAE and SDAE. DAE trains the encoder and decoder
first with the objective being to reconstruct masked inputs. The classifier is trained in a
subsequent step using the features extracted from the encoder. In SDAE the decoder
and classifier are trained together and the reconstruction loss is used as a regularizer for
the classification. The numbers of neurons are indicated alongside the fully connected
layers (large right arrows). Both models incorporate the efficiency constraint by the use
of a bottleneck architecture.
Simplified Denoising Autoencoder
This model, (SDAE), uses the same architecture as DAE, but simplifies the DAE
training procedure by removing the initial encoder-decoder training step and using the
reconstruction objective as a regularizer while training the classifier. The training
process is therefore the same as DFCN, but the model is bound by the efficiency
constraint imposed by the bottleneck architecture. This model is illustrated in Fig 4.
Random Forest
Random forest (RF) is a machine-learning classifier introduced by [28] as an ensemble of
decision trees. Random forest is known to be robust to noise and is considered a very
strong classifier. It is included here as a baseline method which does not incorporate
deep learning. The decoder and associated reconstruction objective that is shown in
Fig 2 do not apply to this classifier.
No Input Masking
All models used in this ablation study are trained using various probabilities of random
input masking. This includes the random masking probability of 0, or in other words,
No Input Masking (NIM). Training without input masking alters the behaviour of some
of the models, since it effectively disables the reconstruction regularizer. Models trained
without any input masking will be referred to with NIM as a prefix to the model name.

Evaluation Metrics
We use the area under the receiver operating characteristic curve (AUC) to represent
the performance of an individual model. The Scikit-learn [29] implementation of the
AUC metric is employed. To determine whether an AUC improvement is statistically
significant, we use DeLong’s test [30]. A threshold of 0.05 (p ≤ 0.05) is used to indicate
statistical significance.

March 26, 2021

8/22

Experiments
This section describes the experiments designed to evaluate the performance of DFCN
and compare it to the other methods in our ablation study. Detailed training settings
(such as preprocessing, hyperparameters, optimization algorithms) are provided in
Supporting Information S1 Text.

RT-PCR test prediction from CXRs
A Resnet-18 [31] network, pre-trained on the ImageNet dataset [32] is trained first on
the RSNA-Pneumonia dataset [23]. We re-initialize and fine-tune only the last layer of
this model on the training dataset from BHH to predict the RT-PCR test results and
apply softmax activations to obtain likelihood of positive and negative outcomes.

Model Selection: Validation dataset experiments
In this section we describe the process used to select optimal models based on
performance on the validation dataset. We use the 27 laboratory parameters as well as
the chest x-ray score from the model described in Section RT-PCR test prediction from
CXRs to train all models, DFCN, FCN, DAE, SDAE and RF using the training dataset
from BHH. The models are trained with input masking probabilities (IMP) of 0.0 (no
input masking (NIM)), 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8 and 0.9, which results in a
total of 50 trained models.
Next, we compare the performance of all trained models in the context of robustness
to missing data. For this purpose a heavily masked version of the validation dataset is
constructed. To compose this dataset, we first construct a set of combinations of input
parameters masking 0-27 of the 28 input parameters. All 28 combinations with length 1
are included, as well as the single combination with length 28. For each of the
combination lengths 2-27, 15 random combinations are chosen. This results in 419
(28 + 1 + (15 ∗ 26)) unique input parameter combinations. Applying these combinations
to the validation dataset (and ignoring the samples that end up having no values), we
obtain a heavily masked dataset of 13,596 samples (5,668 positive). We evaluate the
AUC of each model using this heavily masked version of the validation dataset to
determine performance and robustness to missing data.
For each of the five methods (DFCN, FCN, DAE, SDAE, RF) the model with the
highest AUC is selected and the model trained with that IMP value is used in further
experiments. The NIM (no input masking) version of each method is also selected,
resulting in a total of 10 models for further experimentation.

Ablation study on independent test dataset
The 10 models selected based on performance on the heavily masked version of the
validation dataset are next applied to the test dataset from a different institute. To
evaluate their robustness to missing data we construct a heavily masked version of the
test dataset, in a similar way as described for the validation dataset. For a more
thorough evaluation, however, when constructing random input combinations of length
1-28, we now select 1,000 random combinations of inputs (or the maximum possible
number where 1,000 is not feasible) for each specified combination length. This results
in 23,813 different combinations of inputs.
For each model, we calculate the AUC on all test dataset samples with n available
inputs for n from 1 to 28. These values are used to indicate performance robustness as
the number of available inputs changes. The mean AUC over all 28 values is also

March 26, 2021

9/22

calculated as an overall performance indicator. We use DeLong’s test to evaluate the
significance of the AUC differences between models for each number of available inputs.

Clinically relevant subsets A and B
In this section we experiment with reduction of the input parameters to specific subsets
(A and B) which are chosen for clinical/cost reasons. The inputs used for these subsets
are indicated in Table 1. For these experiments, we limit the test dataset to only those
patients with all of the inputs available. The models trained without input masking
(NIM) are excluded based on their observed poor performance, particularly with
reduced numbers of inputs. The AUCs of the 5 remaining models are calculated on the
test dataset limited to the inputs in A and B respectively.
Furthermore, since a typical machine-learning approach involves training with a
fixed set of data inputs which are expected to be available at test-time, we retrain the 5
optimal models using only subsets A and B of inputs respectively. We train these
models using various input masking probabilities and select the best performing models
using the performance on the validation dataset. The AUCs obtained by these retrained
models, on the test datasets with input parameters from A and B, is compared to the
performance of our models on the same data. This determines whether training and
testing with identical sets of inputs can improve on our more generalizable models
which are designed to adapt to the available inputs.

Results
RT-PCR test prediction from CXRs
The Resnet-18 achieves 0.855 AUC in the RSNA-Pneumonia dataset for detection of
pneumonia in chest x-ray. This model trained further to predict the RT-PCR test result
from the chest x-rays of the training dataset achieves 0.808 AUC in the test dataset
from a different institution. This result is comparable with the performance (0.810
AUC) reported by [5].

Model Selection: Validation dataset experiments
Table 2 shows the results of Experiment Model Selection: Validation dataset
experiments in which we select models based on the AUCs achieved on the heavily
masked validation dataset (13,596 samples, 5,668 positive). In this table the AUC
values are presented for the most optimal IMP settings per architecture and for the
models trained with no input masking (NIM). An extended version of this table with
results for all IMP values is provided in Supporting Information S2 Table.
All of the models with optimal IMP setting perform better than their counterparts
trained with no input masking. The DFCN trained with 0.6 IMP outperforms all other
models at their optimal IMP setting, achieving 0.843 AUC on the heavily masked
validation dataset. The 10 models identified in Table 2 are selected for further
experimentation on the test dataset.

Ablation study on independent test dataset
The results of applying the 10 models presented earlier in Table 2 to the test dataset
from a different institute are presented in this section. The test data is configured into
28 sets with combinations of 1-28 available input parameters (as described in
experiment Ablation study on independent test dataset). The AUCs achieved by the
selected models on each of these sets are plotted in Fig 5. DFCN clearly outperforms

March 26, 2021

10/22

Table 2. Results on validation set data. Five models are trained using various input
masking probabilities (IMP). Each resulting model is validated using the heavily
masked validation dataset of 13596 samples (5668 positive) to evaluate their
performance in the context of missing input data. AUC values for the optimal training
IMP are shown, along with those achieved with no input masking (NIM). Bold font
indicates the highest AUC in the table. Results for other IMP values are provided in
the Supporting Information.
DAE

SDAE

FCN

DFCN

RF

Most Robust Models

IMP
AUC

0.2
0.815

0.4
0.834

0.6
0.838

0.6
0.843

0.7
0.831

No Input Masking (NIM)

IMP
AUC

0.0
0.811

0.0
0.746

0.0
0.799

0.0
0.763

0.0
0.796

other methods with a higher AUC at all points and a mean AUC of 0.857 across all
numbers of inputs, demonstrating robust performance in the context of missing data.

Fig 5. Comparison of the 10 selected models on test datasets with an
increasing number of available inputs. Each test dataset is composed of 1000
random combinations of n inputs (n from 1-28) as described in experiment Ablation
study on independent test dataset. Models are trained without input masking (NIM), or
with the optimal input masking as per Table 2. Mean AUC across all numbers of
available inputs (1-28) is provided in the legend.
The statistical significance of the differences in these AUC values is calculated and
summarised in Fig 6. Here it is illustrated that for 2 to 26 inputs, DFCN performs
significantly better than every other model. With other numbers of inputs (1 or 27) its
performance is matched (but not improved upon) by other models (FCN (1 input),
SDAE (27 inputs)). For 28 inputs, its performance is not significantly different to
SDAE, FCN, and NIM RF, however there are relatively few data points (250) with all
28 inputs, making significance difficult to achieve. Conversely, NIM DFCN is one of the
worst models, performing significantly worse than all of the other models from 8 inputs
upwards, and only better than NIM SDAE with smaller numbers of inputs. In general,
the models trained with no input masking (NIM) perform significantly worse than those

March 26, 2021

11/22

trained with input masking, with the exception of NIM RF which outperforms RF,
DAE and FCN at various points with >20 available inputs.

Fig 6. Statistical significance of differences in the AUC values presented in
Figure 5. Significance is determined by DeLong’s test with (p < 0.05). The y-axis
value indicates how many of the other models were statistically worse in terms of AUC.
(Models with the same y value are statistically equal in performance.)

Clinically relevant subsets A and B
Table 3 shows the results of experiments using datasets with inputs reduced to subsets
A and subset B. In the top section of the table, as a benchmark, the performance of
each model, trained with optimal input masking and on all of the available inputs
during training and testing is shown.
The central part of the table shows the results for experiments with subset A as the
test data input. The highest AUC (0.909) is obtained by the DFCN trained with all
inputs. It is shown to be statistically better than four other models in these
experiments, and is considered equivalent to the remainder, including the DFCN trained
with the input parameters of subset A (AUC=0.901).
In the last part of the table the results of the same experiments using inputs from
subset B are shown. Again, the highest AUC is achieved by DFCN trained with all
inputs (0.919). This is statistically better than 7 of the 9 remaining results in this
section, including DFCN trained with subset B inputs (AUC=0.912). It is notable that
statistical significance is more difficult to achieve in all experiments shown in Table 3
since the number of data points is small compared to those in the experiments of Fig 5
(with x in the range [2, 27]).
The p values for all model comparisons in these experiments are presented in
Supporting Information S3 Table.

March 26, 2021

12/22

Table 3. Comparison of models on the test dataset from a different institution
using specific input subsets (subsets A and B) selected for clinical/cost reasons. The top
section indicates the benchmark performance when both training and test-sets include
all inputs. In the central section performance on test-data with only subset A of inputs
is shown. Models are trained with all inputs and with only subset A of inputs. The
lower section of the table repeats these experiments for subset B. Bold font indicates the
highest AUC value in the table section. ∗ indicates AUCs that are significantly lower
than the highest in that section (p < 0.05).
Available Inputs
Training
Test

# Samples
(# Positives)

DAE
∗

SDAE

AUC
FCN

DFCN

RF

0.917

0.909

∗

0.924

0.870∗

All

All

488 (291)

0.902

All
Subset A

Subset A

258 (179)

0.879∗
0.886

0.891∗
0.904

0.901
0.908

0.909
0.901

0.875∗
0.887∗

All
Subset B

Subset B

474 (286)

0.897∗
0.897∗

0.893∗
0.912

0.906∗
0.910∗

0.919
0.912∗

0.883∗
0.894∗

Discussion
In this work we have proposed a novel deep learning architecture, DFCN, designed to
achieve a robust performance in the context of missing input data, a common issue in
the medical domain. The model has been evaluated against other architectures in an
ablation study, studying performance and robustness for diagnosis of COVID-19 from
laboratory and imaging input parameters. In extensive experiments with randomized
subsets of available inputs, DFCN has been demonstrated to achieve a significantly
superior performance compared to all other tested models.
The ablation study in this work investigates a number of properties of the DFCN,
including the reconstruction regularization term, the use of a ”bottleneck” structure
associated with autoencoders, and the two-step training process typically associated
with autoencoder based classification. It further thoroughly investigates the role of
input masking during training of all models and the performance of a baseline Random
Forest classifier.
By comparing the SDAE and DAE models, we show that using the reconstruction
objective as a regularizer rather than a pre-training step improves the model
performance when most of the inputs are available. Both of these models are restricted
by the efficiency constraint, to encode data in a limited number of features. In the DAE
model these features contain information relevant to reconstruction, while in SDAE the
features are related to both reconstruction and classification. We theorize that
reconstruction information is more important when few inputs are available, but
becomes less important as more inputs are added. This explains why DAE performs
better with few inputs, but is surpassed by SDAE when > 18 inputs are present.
Further, our comparison between DFCN and FCN demonstrates that the inclusion of
the reconstruction regularizer is important and significantly improves the model
performance for all numbers of inputs >1.
The comparison between DFCN and SDAE shows that the ”bottleneck” architecture,
or efficiency constraint, does not confer any advantage in this task. Its removal
improves the model performance significantly for experiments at all levels of missing
inputs, and particularly where the numbers of available inputs are smaller. Removing
the efficiency constraint likely provides more capacity for the DFCN to learn specific
representations for different combinations of inputs.
Input masking has been demonstrated to contribute substantially to the model

March 26, 2021

13/22

performance and robustness to missing data, through the comparison of each model
with its NIM (no input masking) version. The optimum level of input masking
probabilities varied between models from 0.2 to 0.7 suggesting that this value is
dependent on characteristics of the model design and architecture. The Random Forest
classifier was the only model where the NIM version outperformed the version with
input masking, achieving a better performance when >20 input parameters were
available. In contrast to the performance of DFCN, the results achieved by NIM DFCN
were the worst in most experiments. This demonstrates the importance of applying
input masking when the reconstruction objective is in place.
Two subsets of the 28 available inputs (A and B, with 6 and 7 inputs respectively)
were selected based on their clinical utility and their practicality in terms of cost and
ease of use. We have demonstrated that in a setting where only subset A or B of input
data is available at test time, the DFCN, trained on all data, achieves the highest AUC
among all models, including the DFCN trained with only the specified subset of inputs.
This is the case for both subsets A and B, tested in separate experiments. Although
statistical significance was not achieved in all comparisons, we believe that this may be
related to the relatively small numbers of samples involved, compared to the
experiments illustrated in Fig 5. Even assuming that there is no statistical difference
between training on all inputs and training on the specified subset, these experiments
demonstrate that there is no advantage to the latter training scheme, which, in practise,
would require training new models for each additional setting where the model would be
deployed with different input data. The DFCN is sufficiently robust and versatile for
deployment in a new setting without any requirement for re-training.
In the context of the current pandemic and the limitations of the RT-PCR test, this
study introduces a model that is accurate and applicable for use in many diverse
settings around the world. The AUCs achieved by our proposed DFCN on subsets A
and B (0.909, 0.919) indicate the expected AUC on small subsets of clinically important
parameters. These AUC values are in line with that reported in [11] (0.910) and
represent a clinically relevant performance and a means to rapidly and accurately
identify COVID-19 subjects.
Our study has some limitations. Since we had a limited number of training samples
(382 positives, 258 negatives), it was only practical to train the last layer of a
pre-trained convolutional neural network for chest x-ray interpretation. If sufficient data
was available it would be preferable to train all layers. The limitation on data also
limited the ways we could combine the chest x-ray model with the laboratory
parameters model. Similarly, our test dataset had a relatively small number of samples
(283 positives, 193 negatives). Another limitation of this study is the accuracy of the
RT-PCR test which we use as our reference standard. This test has been shown to
suffer from limited sensitivity in particular [33].
Future work on this topic should investigate improvements using additional data and
alternative ways to combine the chest x-ray interpretation model with the diagnostic
network. For full clinical validation, testing on a large diverse dataset is also essential,
however in this work we have focused on novel contributions in the machine-learning
field, to deal with missing data in particular.
This study has described the development and validation of a novel architecture,
DFCN, robust to missing data, and validated through extensive experimentation for the
task of detecting COVID-19 subjects based on laboratory and imaging parameters. This
deep learning technique is ideally suited to tasks in any domain where not all input
parameters are reliably available, or differ between installation settings.

March 26, 2021

14/22

Acknowledgment
Funding for this study was partially provided by the Botnar Research Centre for Child
Health.

References
1. Lippi G, Simundic AM, Plebani M. Potential preanalytical and analytical
vulnerabilities in the laboratory diagnosis of coronavirus disease 2019
(COVID-19). Clinical Chemistry and Laboratory Medicine. 2020;58(7):1070–1076.
doi:10.1515/cclm-2020-0285.
2. Lippi G, Plebani M. Laboratory abnormalities in patients with COVID-2019
infection. Clinical Chemistry and Laboratory Medicine (CCLM).
2020;58(7):1131–1134. doi:10.1515/cclm-2020-0198.
3. Terpos E, Ntanasis-Stathopoulos I, Elalamy I, Kastritis E, Sergentanis TN,
Politou M, et al. Hematological findings and complications of COVID-19.
American Journal of Hematology. 2020;95(7):834–847. doi:10.1002/ajh.25829.
4. Henry BM, Oliveira MHSd, Benoit S, Plebani M, Lippi G. Hematologic,
biochemical and immune biomarker abnormalities associated with severe illness
and mortality in coronavirus disease 2019 (COVID-19): a meta-analysis. Clinical
Chemistry and Laboratory Medicine (CCLM). 2020;58(7):1021–1028.
doi:10.1515/cclm-2020-0369.
5. Murphy K, Smits H, Knoops AJG, Korst MBJM, Samson T, Scholten ET, et al.
COVID-19 on the Chest Radiograph: A Multi-Reader Evaluation of an AI
System. Radiology. 2020; p. 201874. doi:10.1148/radiol.2020201874.
6. Jacobi A, Chung M, Bernheim A, Eber C. Portable chest X-ray in coronavirus
disease-19 (COVID-19): A pictorial review. Clinical Imaging. 2020;64:35–42.
doi:10.1016/j.clinimag.2020.04.001.
7. Wong HYF, Lam HYS, Fong AHT, Leung ST, Chin TWY, Lo CSY, et al.
Frequency and Distribution of Chest Radiographic Findings in Patients Positive
for COVID-19. Radiology. 2020;296(2):E72–E78. doi:10.1148/radiol.2020201160.
8. Schiaffino S, Tritella S, Cozzi A, Carriero S, Blandi L, Ferraris L, et al.
Diagnostic Performance of Chest X-Ray for COVID-19 Pneumonia During the
SARS-CoV-2 Pandemic in Lombardy, Italy. Journal of Thoracic Imaging.
2020;35(4):W105. doi:10.1097/RTI.0000000000000533.
9. Bandirali M, Sconfienza LM, Serra R, Brembilla R, Albano D, Pregliasco FE,
et al. Chest Radiograph Findings in Asymptomatic and Minimally Symptomatic
Quarantined Patients in Codogno, Italy during COVID-19 Pandemic. Radiology.
2020;295(3):E7–E7. doi:10.1148/radiol.2020201102.
10. Borghesi A, Maroldi R. COVID-19 outbreak in Italy: experimental chest X-ray
scoring system for quantifying and monitoring disease progression. La Radiologia
Medica. 2020;125(5):509–513. doi:10.1007/s11547-020-01200-3.
11. Kurstjens S, Horst Avd, Herpers R, Geerits MWL, Hingh YCMKd, Göttgens EL,
et al. Rapid identification of SARS-CoV-2-infected patients at the emergency
department using routine testing. Clinical Chemistry and Laboratory Medicine
(CCLM). 2020;58(9):1587–1593. doi:10.1515/cclm-2020-0593.

March 26, 2021

15/22

12. Putin E, Mamoshina P, Aliper A, Korzinkin M, Moskalev A, Kolosov A, et al.
Deep biomarkers of human aging: Application of deep neural networks to
biomarker development. Aging (Albany NY). 2016;8(5):1021–1030.
doi:10.18632/aging.100968.
13. Goldstein BA, Navar AM, Carter RE. Moving beyond regression techniques in
cardiovascular risk prediction: applying machine learning to address analytic
challenges. European Heart Journal. 2017;38(23):1805–1814.
doi:10.1093/eurheartj/ehw302.
14. Dauvin A, Donado C, Bachtiger P, Huang KC, Sauer CM, Ramazzotti D, et al.
Machine learning can accurately predict pre-admission baseline hemoglobin and
creatinine in intensive care patients. npj Digital Medicine. 2019;2(1):1–10.
doi:10.1038/s41746-019-0192-z.
15. Schütz N, Leichtle AB, Riesen K. A comparative study of pattern recognition
algorithms for predicting the inpatient mortality risk using routine laboratory
measurements. Artificial Intelligence Review. 2019;52(4):2559–2573.
doi:10.1007/s10462-018-9625-3.
16. Vincent P, Larochelle H, Lajoie I, Bengio Y, Manzagol PA. Stacked Denoising
Autoencoders: Learning Useful Representations in a Deep Network with a Local
Denoising Criterion. The Journal of Machine Learning Research.
2010;11:3371–3408.
17. Dong X, Zhang J, Wang G, Xia Y. DAEimp: Denoising Autoencoder-Based
Imputation of Sleep Heart Health Study for Identification of Cardiovascular
Diseases. In: Lin Z, Wang L, Yang J, Shi G, Tan T, Zheng N, et al., editors.
Pattern Recognition and Computer Vision. Lecture Notes in Computer Science.
Cham: Springer International Publishing; 2019. p. 517–527.
18. Amarbayasgalan T, Lee JY, Kim KR, Ryu KH. Deep Autoencoder Based Neural
Networks for Coronary Heart Disease Risk Prediction. In: Gadepally V, Mattson
T, Stonebraker M, Wang F, Luo G, Laing Y, et al., editors. Heterogeneous Data
Management, Polystores, and Analytics for Healthcare. Lecture Notes in
Computer Science. Cham: Springer International Publishing; 2019. p. 237–248.
19. Alhassan Z, Budgen D, Alshammari R, Daghstani T, McGough AS, Moubayed
NA. Stacked Denoising Autoencoders for Mortality Risk Prediction Using
Imbalanced Clinical Data. In: 2018 17th IEEE International Conference on
Machine Learning and Applications (ICMLA); 2018. p. 541–546.
20. Alhassan Z, Budgen D, Alessa A, Alshammari R, Daghstani T, Al Moubayed N.
Collaborative denoising autoencoder for high glycated haemoglobin prediction. In:
Tetko IV, Kůrková V, Karpov P, Theis F, editors. Artificial neural networks and
machine learning – ICANN 2019; 28th International Conference on Artificial
Neural Networks, Munich, Germany, September 17–19, 2019 ; proceedings. Cham:
Springer; 2019. p. 338–350. Available from:
https://doi.org/10.1007/978-3-030-30493-5_34.
21. Ibrahim JG, Chu H, Chen MH. Missing Data in Clinical Studies: Issues and
Methods. Journal of Clinical Oncology. 2012;30(26):3297–3303.
doi:10.1200/JCO.2011.38.7589.
22. http://www cs2 ch CAS. Mitigation strategies for communities with COVID-19
transmission in Lesotho using artificial intelligence on chest x-rays and novel

March 26, 2021

16/22

rapid diagnostic tests; 2020. Available from:
https://www.swisstph.ch/en/projects/project-detail/project/
mitigation-strategies-for-communities-with-covid-19-transmission-in-lesoth
23. RSNA. RSNA Pneumonia Detection Challenge; 2018. Available from:
https://kaggle.com/c/rsna-pneumonia-detection-challenge.
24. Matsuoka K. Noise injection into inputs in back-propagation learning. IEEE
Transactions on Systems, Man, and Cybernetics. 1992;22(3):436–440.
doi:10.1109/21.155944.
25. Zur RM, Jiang Y, Pesce LL, Drukker K. Noise injection for training artificial
neural networks: A comparison with weight decay and early stopping. Medical
Physics. 2009;36(10):4810–4818. doi:10.1118/1.3213517.
26. Srivastava N, Hinton G, Krizhevsky A, Sutskever I, Salakhutdinov R. Dropout: a
simple way to prevent neural networks from overfitting. The Journal of Machine
Learning Research. 2014;15(1):1929–1958.
27. Kramer MA. Nonlinear principal component analysis using autoassociative neural
networks. AIChE Journal. 1991;37(2):233–243. doi:10.1002/aic.690370209.
28. Breiman L. Random Forests. Machine Learning. 2001;45(1):5–32.
doi:10.1023/A:1010933404324.
29. Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al.
Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research.
2011;12(85):2825–2830.
30. DeLong ER, DeLong DM, Clarke-Pearson DL. Comparing the areas under two or
more correlated receiver operating characteristic curves: a nonparametric
approach. Biometrics. 1988;44(3):837–845.
31. He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition.
arXiv:151203385 [cs]. 2015;.
32. Deng J, Dong W, Socher R, Li LJ, Li K, Fei-Fei L. ImageNet: A large-scale
hierarchical image database. In: 2009 IEEE Conference on Computer Vision and
Pattern Recognition; 2009. p. 248–255.
33. Wang W, Xu Y, Gao R, Lu R, Han K, Wu G, et al. Detection of SARS-CoV-2 in
Different Types of Clinical Specimens. JAMA. 2020;doi:10.1001/jama.2020.3786.
34. Smith LN. Cyclical Learning Rates for Training Neural Networks.
arXiv:150601186 [cs]. 2017;.
35. Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the Inception
Architecture for Computer Vision. arXiv:151200567 [cs]. 2015;.

March 26, 2021

17/22

Supporting information
S1 Protocol. Data Cleanup In a small number of cases laboratory parameters are
not specified with absolute numeric values, but rather by denoting that the value fell
above or below a specific threshold (based on guidelines from each institution). To
obtain numeric values we converted these using the protocol shown in Supporting
Information S1 Table. Any values of Potassium, Lactate Dehydrogenase, and
Magnesium that were considered as an outlier by the institutions were removed.
S1 Table.

Data Cleanup Data cleanup protocol thresholds and replacement values.

Table 4. Data cleanup protocol thresholds and replacement values.
Parameter

Specified as

Converted to

C-reactive protein
D-Dimer
D-Dimer
Gamma-Glutamyl Transferase
Procalcitonin
Procalcitonin

<
>
<
<
<
>

2 mg/L
4.01 mg/L
0.16 mg/L
5 U/L
0.01 ng/ml
76 ng/ml

3 mg/L
4 mg/L
0.17 mg/L
5 U/L
0.03 ng/ml
75 ng/ml

S1 Fig. Data Distribution The input data distribution per hospital and per
RT-PCR test outcome is provided.
S1 Text.

Training Settings

RT-PCR test prediction from CXRs
Training settings
We train Resnet-18 using a cyclic learning rate [34] between 0.001 and 0.01 and 2.5
epoch step size. We use stochastic gradient descent with Nesterov momentum of 0.95.
We minimize the cross-entropy loss between the softmax activations and binary labels.
We perform all experiments with a batch size of 16.
When fine-tuning the last layer on RT-PCR test results, we use a heavy label
smoothing regularization [35] of 0.2. We apply a weight of 0.625 to the positive samples,
to account for the class imbalance. This number is calculated by dividing the number of
negative cases in the training dataset by the number of positive cases. After training,
we restore the model weights that have achieved the best validation cross-entropy loss.
Image preprocessing
We convert the DICOM files to 8-bit PNG files by clipping the values above the 99th
percentile and scaling the resulting values between 0 and 255. We resize the resulting
images to 512 by 512. Before we feed those images to the convolutional neural network,
we augment them by cropping a width and height in the range of (409, 512] randomly.
We resize the resulting image to 448 by 448. We randomly scale (by [0.75, 1.25]) and
shift (±64) the pixel values and clip the values above 255. We randomly flip the image
from left to right. We standardize the resulting pixel values using the ImageNet dataset
means and variances.

March 26, 2021

18/22

Fig 7. Value ranges of the 27 laboratory test results and chest x-ray scores, separated
by institute and by positive/negative RT-PCR test results. JBH stands for Jeroen
Bosch hospital and this data is used as the test dataset, BHH stands for Bernhoven
Hospital and the data from this institution is used as the training dataset in our study.
Positive cases are indicated by 1.0 and Negative by 0.0. It should be noted that the
chest x-xray scoring model was trained using data from BHH leading to a difference in
the scores produced between instiututes.

Model Selection: Validation dataset experiments
Training settings
Similar to the previous experiment, we train DAE, SDAE, FCN, and DFCN using a
cyclic learning rate [34] between 0.001 and 0.01 and 2.5 epoch step size. We use
stochastic gradient descent with Nesterov momentum of 0.95. We minimize the
cross-entropy loss between the softmax activations and binary labels. For all models we
use ReLU activations for intermediate layers. We train our models until there is no
improvement in the validation loss for 10 epochs. We perform all experiments with a
batch size of 16. When reconstruction regularization is used, the loss is calculated using
the sum of squared errors of the prediction differences, applied with a coefficient of 0.03.
We normalize each of the 27 laboratory parameters to unit mean and variance with
respect to the training dataset statistics. After normalization, we set the masked and
missing values to zero. We calculate the reconstruction loss only using the known values
that are not missing in the training dataset. We apply a weight of 0.625 to the positive
samples to account for the class imbalance as described in Supporting
information Training settings.
Random Forest Settings
We use the Random Forest implementation of Scikit-learn (v0.22.1) [29]. This
implementation does not allow partial training or mini batching. Hence, we apply input

March 26, 2021

19/22

masking by repeating the dataset 100 times and applying the input masking on this set.
For comparability with the other methods, we impute the missing values using the
mean. We use the default model parameters because they have performed the best in
our preliminary experiments.
S2 Table. Robustness validation experiments expanded results The results
of Table 2 is truncated for simplicity. Here in Table 5, we provide the full robustness
validation experiment results.
Table 5. All robustness evaluation AUC results of experiment Model Selection:
Validation dataset experiments.
IMP
NIM → 0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9

AUCs on heavily masked validation data
DAE SDAE FCN DFCN
RF
0.811
0.798
0.815
0.810
0.783
0.795
0.800
0.789
0.783
0.681

0.746
0.806
0.810
0.818
0.834
0.834
0.828
0.827
0.730
0.497

0.799
0.810
0.817
0.822
0.834
0.838
0.838
0.834
0.833
0.822

0.763
0.812
0.822
0.823
0.832
0.836
0.843
0.827
0.808
0.809

0.796
0.816
0.785
0.792
0.799
0.812
0.830
0.831
0.816
0.797

S3 Table. All p values for significance tests in results Clinically relevant
subsets A and B The statistical significances mentioned in results Clinically relevant
subsets A and B are provided in Tables 6, 7, and 8.
Table 6. p values from comparing AUC results (DeLong’s test) of experiment
Clinically relevant subsets A and B on All test data. Models with statistical significance
and significant p-values are presented in bold.

March 26, 2021

Model 1

Model 1 Training

Model 2

Model 2 Training

Test Dataset

DAE
DAE
DAE
DAE
DFCN
DFCN
DFCN
DFCN
FCN
FCN
FCN
FCN
RF
RF
RF
RF
SDAE
SDAE
SDAE
SDAE

All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All

DFCN
FCN
RF
SDAE
DAE
FCN
RF
SDAE
DAE
DFCN
RF
SDAE
DAE
DFCN
FCN
SDAE
DAE
DFCN
FCN
RF

All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All

All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All
All

p-value
0.00681
0.58261
0.02875
0.16335
0.00681
0.03849
< 0.00000
0.23376
0.58261
0.03849
0.00134
0.40531
0.02875
< 0.00000
0.00134
0.00024
0.16335
0.23376
0.40531
0.00024

20/22

Table 7. p values from comparing AUC results (DeLong’s test) of experiment
Clinically relevant subsets A and B on Subset A labels of the test data. Models with
statistical significance and significant p-values are presented in bold.

March 26, 2021

Model 1

Model 1 Training

Model 2

Model 2 Training

Test Dataset

p-value

DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE

All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset

DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE

Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All

Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset

0.58384
0.02982
0.04600
0.13971
0.02978
0.56853
0.90902
0.35907
0.02188
0.58384
0.10716
0.23022
0.32074
0.11969
0.35180
0.79816
0.71616
0.17905
0.02982
0.10716
0.58065
0.25026
0.97176
0.00318
0.01887
0.02356
0.59272
0.04600
0.23022
0.58065
0.99266
0.54821
0.08873
0.27054
0.50519
0.78887
0.13971
0.32074
0.25026
0.99266
0.33117
0.02002
0.09254
0.11815
0.78720
0.02978
0.11969
0.97176
0.54821
0.33117
0.00339
0.01502
0.07703
0.39365
0.56853
0.35180
0.00318
0.08873
0.02002
0.00339
0.05234
0.14601
0.01799
0.90902
0.79816
0.01887
0.27054
0.09254
0.01502
0.05234
0.47878
0.07467
0.35907
0.71616
0.02356
0.50519
0.11815
0.07703
0.14601
0.47878
0.24057
0.02188
0.17905
0.59272
0.78887
0.78720
0.39365
0.01799
0.07467
0.24057

A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

21/22

Table 8. p values from comparing AUC results (DeLong’s test) of experiment
Clinically relevant subsets A and B on Subset B labels of the test data. Models with
statistical significance and significant p-values are presented in bold.

March 26, 2021

Model 1

Model 1 Training

Model 2

Model 2 Training

Test Dataset

p-value

DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DAE
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
DFCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
FCN
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
RF
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE
SDAE

All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
All
All
All
All
All
All
All
All
All
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset

DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
FCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
RF
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
SDAE
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE
DAE
DAE
DFCN
DFCN
FCN
FCN
RF
RF
SDAE

Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All
All
Subset
All
Subset
All
Subset
All
Subset
All
Subset
Subset
All
Subset
All
Subset
All
Subset
All
Subset
All

Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset
Subset

0.98772
0.00876
0.11224
0.39230
0.15350
0.22107
0.83053
0.80068
0.12611
0.98772
0.00521
0.04597
0.21183
0.04032
0.13714
0.77915
0.65732
0.01101
0.00876
0.00521
0.00501
0.00108
0.00801
< 0.000
0.00114
0.00358
0.12674
0.11224
0.04597
0.00501
0.17454
0.56112
0.00019
0.03065
0.04803
0.90291
0.39230
0.21183
0.00108
0.17454
0.19996
0.00109
0.11613
0.09070
0.05721
0.15350
0.04032
0.00801
0.56112
0.19996
0.00032
0.04280
0.04172
0.62502
0.22107
0.13714
< 0.000
0.00019
0.00109
0.00032
0.01913
0.27330
0.00021
0.83053
0.77915
0.00114
0.03065
0.11613
0.04280
0.01913
0.95579
0.02479
0.80068
0.65732
0.00358
0.04803
0.09070
0.04172
0.27330
0.95579
0.00596
0.12611
0.01101
0.12674
0.90291
0.05721
0.62502
0.00021
0.02479
0.00596

B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B

B
B
B
B
B

B
B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B
B

B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B
B

22/22

