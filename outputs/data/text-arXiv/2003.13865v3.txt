1–14

COVID-CT-Dataset: A CT Image Dataset about COVID-19
Xingyi Yang

x3yang@eng.ucsd.edu

UC San Diego

Xuehai He

x5he@eng.ucsd.edu

UC San Diego

arXiv:2003.13865v3 [cs.LG] 17 Jun 2020

Jinyu Zhao

jiz077@eng.ucsd.edu

UC San Diego

Yichen Zhang

yiz037@eng.ucsd.edu

UC San Diego

Shanghang Zhang

shz@eecs.berkeley.edu

UC Berkeley

Pengtao Xie

pengtaoxie2008@gmail.com

UC San Diego

Abstract
During the outbreak time of COVID-19, computed tomography (CT) is a useful manner
for diagnosing COVID-19 patients. Due to privacy issues, publicly available COVID-19
CT datasets are highly difficult to obtain, which hinders the research and development of
AI-powered diagnosis methods of COVID-19 based on CTs. To address this issue, we build
an open-sourced dataset COVID-CT, which contains 349 COVID-19 CT images from 216
patients and 463 non-COVID-19 CTs. The utility of this dataset is confirmed by a senior
radiologist who has been diagnosing and treating COVID-19 patients since the outbreak
of this pandemic. We also perform experimental studies which further demonstrate that
this dataset is useful for developing AI-based diagnosis models of COVID-19. Using this
dataset, we develop diagnosis methods based on multi-task learning and self-supervised
learning, that achieve an F1 of 0.90, an AUC of 0.98, and an accuracy of 0.89. According
to the senior radiologist, models with such performance are good enough for clinical usage.
The data and code are available at https://github.com/UCSD-AI4H/COVID-CT

1. Introduction
Coronavirus disease 2019 (COVID-19) is an infectious disease that has caused about 386,000
deaths all over the world, among 6.5 million infected cases, as of June 3rd, 2020. One major
hurdle in controlling the spreading of this disease is the shortage of tests. The current tests
are mostly based on reverse transcription polymerase chain reaction (RT-PCR). During the
peak time of COVID-19 outbreak, RT-PCR test kits were in great shortage. As a result,
many suspected cases cannot be tested in time and they continue to spread the disease to
others unconsciously. To mitigate the shortage of RT-PCR test kits, hospitals have been
utilizing alternative diagnosis methods. Among them, computed tomography (CT) scans
have been used for screening and diagnosing COVID-19. For example, in the Diagnosis

c

X. Yang, X. He, J. Zhao, Y. Zhang, S. Zhang & P. Xie.

COVID-CT-Dataset: A CT Image Dataset about COVID-19

and Treatment Protocol for Novel Coronavirus Pneumonia (Trial Version 5)1 made by the
National Health Commission and State Administration of Traditional Chinese Medicine in
China, CT and other chest imaging techniques have been named as an important way for
diagnosing COVID-19. Following this guideline, many hospitals in China used CT scans
for COVID-19 diagnosis, which has been demonstrated to be effective.
To further understand the role of CTs in diagnosing COVID-19, we consulted a senior radiologist in Tongji Hospital, Wuhan, China, who has been diagnosing and treating
COVID-19 patients since the outbreak of this disease in China. According to this radiologist, during the outbreak time, CT is useful for diagnosing COVID-19; out of the outbreak
time, CT is not as useful. The reasons are as follows. CTs can be used to judge whether a
patient is infected by viral pneumonia (COVID-19 is a type of viral pneumonia caused by
the SARS-CoV-2 virus). However, CTs do not have the ability to determine which virus
is causing the viral pneumonia: SARS-CoV-2 or others. Strictly speaking, CTs cannot be
used to confirm whether a patient is infected by COVID-19. However, during the outbreak
time, most viral pneumonia is caused by SARS-CoV-2. That is to say, if a patient is confirmed to have viral pneumonia according to CT results, this viral pneumonia is very likely
to be COVID-19. Due to this fact, CTs are considered useful for diagnosing COVID-19
during its outbreak.
During the outbreak of COVID-19, radiologists are highly occupied, who may not have
the bandwidth to read a number of CT scans timely. Besides, for radiologists in underdeveloped areas, such as rural regions, they may not be well-trained to recognize COVID19 from CT scans, since this disease is relatively new. To address these problems, several
works (Huang et al., 2020; Li et al., 2020) have developed deep learning methods to screen
COVID-19 from CTs. Due to privacy concerns, the CT scans used in these works are not
shared with the public. This greatly hinders the research and development of more advanced
AI methods for more accurate screening of COVID-19 based on CTs.
To address this issue, we built a COVID-CT dataset which contains 349 CT images
positive for COVID-19 belonging to 216 patients and 397 CT images that are negative
for COVID-19. The dataset is open-sourced to the public, to foster the R&D of CTbased testing of COVID-19. From 760 medRxiv and bioRxiv preprints about COVID-19,
we extract reported CT images and manually select those containing clinical findings of
COVID-19 by reading the captions of these images. After releasing this dataset, we received
several feedback expressing concerns about the usability of this dataset. The major concerns
are summarized as follows. First, when the original CT images are put into papers, the
quality of these images is degraded, which may render the diagnosis decisions less accurate.
The quality degradation includes: the Hounsfield unit (HU) values are lost; the number
of bits per pixel is reduced; the resolution of images is reduced. Second, the original CT
scan contains a sequence of CT slices, but when put into papers, only a few key slices are
selected, which may have a negative impact on diagnosis as well.
We consulted the aforementioned radiologist at Tongji Hospital regarding these two
concerns. According to the radiologist, the issues raised in these concerns do not significantly
affect the accuracy of diagnosis decision-making. First, experienced radiologists are able to
make accurate diagnosis from low quality CT images. For example, given a photo taken
1. http://www.kankyokansen.org/uploads/uploads/files/jsipc/protocol_V5.pdf

2

COVID-CT-Dataset: A CT Image Dataset about COVID-19

by smartphone of the original CT, experienced radiologists can make accurate diagnosis
by just looking at the photo, though the CT image in the photo has much lower quality
than the original CT. Likewise, the quality gap between CT images in papers and original
CTs will not largely hurt the accuracy of diagnosis. Second, while it is preferable to read a
sequence of CT slices, oftentimes a single-slice of CT contains enough clinical information
for accurate decision-making.
To further address these concerns, we use the CT images extracted from papers only
for model training, not for evaluation. For testing, we use original CT images donated by
hospitals. Validation is also conducted on original CTs. We compare models trained on our
paper-extracted CTs and models trained on original CTs, and the former outperforms the
latter. This demonstrates that COVID-19 CTs extracted from papers are useful for training
diagnosis models of COVID-19. In the end, we leverage our COVID-CT dataset, original
CT images collected elsewhere, lesion masks labeled by radiologists to train a diagnosis
model of COVID-19, based on multi-task learning and self-supervised learning. This model
achieves an F1 of 0.90, an AUC of 0.98, and an accuracy of 0.89. According to the senior
radiologist, models with such performance are good enough for clinical usage.
The major contributions of this paper are as follows: (1) We collect a COVID-19 CT
dataset, which contains 349 positive COVID-19 CT images from 216 patients; (2) We verify
the usefulness of this dataset for developing COVID-19 diagnosis models via experiment
studies; (3) We develop methods based on multi-task learning and contrastive self-supervised
learning to improve the diagnosis accuracy to a clinically useful level.
The rest of the paper is organized as follows. In Section 2, we introduce the COVIDCT dataset. In Section 3, we perform a study to verify whether COVID-CT is useful for
training COVID-19 diagnosis models. In Section 4, we develop methods based on multitask learning and self-supervised learning to improve the diagnosis accuracy of COVID-19.
Section 5 reviews related works and Section 6 concludes the paper.

2. The COVID-CT Dataset
In this section, we describe how the COVID-CT dataset is built. We first collected 760
preprints about COVID-19 from medRxiv2 and bioRxiv3 , posted from Jan 19th to Mar
25th. Many of these preprints report patient cases of COVID-19 and some of them show
CT images in the reports. CT images are associated with captions describing the clinical
findings in the CTs. We used PyMuPDF4 to extract the low-level structure information
of the PDF files of preprints and located all the embedded figures. The quality (including
resolution, size, etc.) of figures were well-preserved. From the structure information, we also
identified the captions associated with figures. Given these extracted figures and captions,
we first manually selected all CT images. Then for each CT image, we read the associated
caption to judge whether it is positive for COVID-19. If not able to judge from the caption,
we located the text analyzing this figure in the preprint to make a decision. For each CT
image, we also collected the meta information extracted from the paper, such as patient age,
gender, location, medical history, scan time, severity of COVID-19, and radiology report.
2. https://www.medrxiv.org/
3. https://www.biorxiv.org/
4. https://github.com/pymupdf/PyMuPDF

3

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Table 1: Comparison of COVID-CT with other datasets.
Dataset

# COVID images

# patients

Open-source

Metadata

349

216

Y

Y

84
100
68626
379

45
60
400
20

Y
Y
N
Y

Y
Y
N
N

COVID-CT
COVID-19 Image Data Collection
(Cohen et al., 2020a)
SIRM COVID-19 Database 5
COVID-CS (Wu et al., 2020)
COVID-19 CT Segmentation
Dataset (Jun et al.)

For any figure that contains multiple CT images as sub-figures, we manually split it into
individual CTs, as shown in Figure 1(left).
Chest Computed tomography (CT) images of patients
infected with 2019-nCoV on admission to hospital. A,
Chest CT scan obtained on February 2, 2020, from a
39-year-old man, showing bilateral ground glass
opacities. B, Chest CT scan obtained on February 6,
2020, from a 45-year-old man, showing bilateral
ground glass opacities. C, Chest CT scan taken on
January 27, 2020, from a 48-year-old man (discharged
after treatment on day 9), showing patchy shadows. D,
Chest CT scan taken on January 23, 2020, from a 34year-old man (discharged after treatment on day 11),
showing patchy shadows.

COVID-19

COVID-19

COVID-19

COVID-19

Figure 1: (Left) For any figure that contains multiple CT images as sub-figures, we manually
split it into individual CTs. (Right) Examples of CT images that are positive for
COVID-19.

In the end, we obtain 349 CT images labeled as being positive for COVID-19. These
CT images have different sizes. The minimum, average, and maximum height are 153, 491,
and 1853. The minimum, average, and maximum width are 124, 383, and 1485. These
images are from 216 patient cases. Figure 1(right) shows some examples of the COVID19 CT images. For patients labeled with positive, 169 of them have age information and
137 of them have gender information. Figure 2(left) shows the age distribution of patients
with COVID-19. Figure 2(right) shows the gender ratio of patients with COVID-19. Male
patients are more than female patients, with a number of 86 and 51 respectively. Table 1
compares the COVID-CT dataset with others. Our dataset has more COVID19-positive
images and patients than COVID-19 Image Data Collection and SIRM COVID-19 Database.
COVID-CS is not open-sourced. COVID-19 CT Segmentation Dataset has more COVID19positive images, but less patients. Note that CT images of the same patient are highly
similar visually. Therefore, the diversity of images in our dataset is larger than that in the
COVID-19 CT Segmentation Dataset.
Collection of non-COVID-19 CT images as negative training set To develop
binary classification models for diagnosing COVID-19, in addition to the 349 COVID-19
4

COVID-CT-Dataset: A CT Image Dataset about COVID-19

CT images, we also collect a set of non-COVID-19 CT images as negative training examples.
The sources of these images include:
• The MedPix6 database, which is an open-access online database of medical images, teaching cases, and clinical topics. It contains more than 9000 topics, 59000 images from 12000
patient cases.
• The LUNA7 dataset, which contains 888 lung cancer CT scans from 888 patients.
• The Radiopaedia website8 , which contains radiology images from 36559 patient cases.
• PubMed Central (PMC)9 , which is a free full-text archive of biomedical and life sciences
journal literature. Some papers contain CT images.
Gender Ratio

Age Distribution
60
50
40

Female, 51

30
Male, 86

20
10
0

Male

[1, 11] (11, 21] (21, 31] (31, 41] (41, 51] (51, 61] (61, 71] (71, 81]

Female

Figure 2: (Left) Age distribution of COVID-19 patients. (Right) The gender ratio of
COVID-19 patients. The ratio of male:female is 86:51.

Table 2: Statistics of the negative training set
# patients
# images

Class

LUNA

MedPix

PMC

Radiopaedia

Total

Non-COVID
Non-COVID

17
36

55
195

55
202

2
30

55
463

Table 3 shows the composition of the negative training set which contains 463 images
from 55 patients: 36 images from LUNA, 195 from MedPix, 202 from PMC, and 30 from
Radiopaedia.
6.
7.
8.
9.

https://medpix.nlm.nih.gov/home
https://luna16.grand-challenge.org/
https://radiopaedia.org/articles/covid-19-3
https://www.ncbi.nlm.nih.gov/pmc/

5

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Table 3: Statistics of the test set
Class
LUNA COVID-Seg Radiopaedia

Total

# patients

COVID
Non-COVID

0
19

4
0

0
1

4
20

# images

COVID
Non-COVID

0
164

173
0

0
4

173
168

Table 4: Statistics of the validation set
Class
LUNA COVID-Seg Radiopaedia

Total

# patients

COVID
Non-COVID

0
38

4
0

0
1

4
39

# images

COVID
Non-COVID

0
48

88
0

0
16

88
64

Collection of test and validation images To evaluate the trained models, we collect
a validation set and a test set. In these two sets, all images are original CTs donated by
hospitals. None of them is extracted from papers. These original COVID-19 CTs come
from the COVID-19 CT Segmentation dataset (COVID-Seg)10 , which contains 20 axial
volumetric COVID-19 CT scans. The sources of original non-COVID-19 CTs include LUNA
and Radiopaedia. Table 3 shows the composition of the test set. It has 173 COVID-19 CT
images, from 4 patients in the COVID-Seg dataset. It contains 168 non-COVID-19 CT
images: 164 of them are from 19 patients in the LUNA dataset and the rest 4 are from 1
patient in Radiopaedia.
Table 4 shows the composition of the validation set. It has 88 COVID-19 CT images,
from 4 patients in the COVID-Seg dataset. It contains 64 non-COVID-19 CT images: 48
of them are from 38 patients in the LUNA dataset and the rest 16 are from 1 patient in
Radiopaedia. The images from LUNA are either about lung cancer or normal. The images
from Radiopaedia are normal. We automatically crop the chest position in images through
threshold segmentation and convex hull detection, which gets rid of white space at the edge
of images.

3. Study I: Is COVID-CT useful for training CT-based diagnosis models
of COVID-19?
As mentioned before, we received several feedback expressing concerns that the COVID-CT
dataset may not be useful for training CT-based diagnosis models for COVID-19 since (1)
images in COVID-CT are extracted from papers in PDF format, which are likely to have
lower quality compared with original CT scans and (2) images in COVID-CT are single-slice
CTs rather than multiple-slice CTs as in original CT scans. In this section, we perform an
10. http://medicalsegmentation.com/covid19/

6

COVID-CT-Dataset: A CT Image Dataset about COVID-19

experimental study to investigate whether the images in COVID-CT are useful for training
CT-based diagnosis models.
Study Design
datasets.

We compare experimental settings with three different positive training

• COVID-Seg: We use 118 positive CTs in COVID-Seg as positive training examples. These
images are original CT images obtained from the image archiving systems in hospitals.
• COVID-CT-349: We use the full set of 349 COVID-19 CTs in COVID-CT as positive
training examples. These images are extracted from papers.
• COVID-CT-118: We randomly sample 118 images from COVID-CT as positive training
examples. These images are extracted from papers.
The negative training images, test images, and validation images are the same for the
above-mentioned three settings, as given in Table 2, 3, and 4 respectively. The images used
for validation and testing are original CT images obtained from the image archiving systems
in hospitals. We use the DenseNet-169 (Huang et al., 2017) and ResNet-50 (He et al., 2016)
models for classifying a CT image as COVID-19 or non-COVID-19. They are pretrained
on the ImageNet (Deng et al., 2009) dataset. The trained models are evaluated using three
metrics: accuracy, F1, and area under ROC curve (AUC). For all metrics, the higher the
better. Hyperparameters are tuned on the validation set.
Experimental Settings Input images are resized to 480-by-480. We perform data augmentation on the training set. Each training image is augmented with random cropping
with a scale of 0.5, horizontal flip, random contrast, and random brightness with a factor
of 0.2. The weight parameters in the networks are optimized using Adam (Kingma and Ba,
2014) with an initial learning rate of 0.0001 and a mini-batch size of 16. Cosine scheduling
with a period of 10 is used to adjust the learning rate across the training process. We
implement the network using PyTorch and train it on one GTX 1080Ti GPU.
Results Table 5 shows the results on the test set, under three settings of positive training
images. From this table, we observe the following. First, the model trained on COVID-CT349 is largely better than that trained on COVID-Seg. COVID-CT-349 contains images
extracted from papers. COVID-Seg contains original CT images. This demonstrates that
COVID-CT is useful for training CT-based diagnosis models for COVID-19, despite the
concerns that images extracted from papers have low quality and are single slices. Second,
the model trained on COVID-CT-349 is much better than that trained on COVID-CT118. Adding more COVID-CT images into the training set substantially improves performance, which further demonstrates that the CTs in COVID-CT have high utility in training
COVID-19 diagnosis models. Third, COVID-Seg outperforms COVID-CT-118. These two
sets have the same number of images. This indicates that on average, an original CT is
more useful for model training than a CT extracted from papers. However, paper-extracted
CTs are much easier to obtain than original CTs. In sum, these results demonstrate the
usefulness of our COVID-CT dataset in training diagnosis models of COVID-19.

7

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Table 5: Performance of DenseNet-169 and ResNet-50 on the test set under different settings of positive training images.
Model

Positive training data

Accuracy (%)

F1-score (%)

AUC (%)

DenseNet-169

COVID-Seg
COVID-CT-349
COVID-CT-118

69.8
79.5
57.8

61.1
76.0
36.3

86.9
90.1
75.2

ResNet-50

COVID-Seg
COVID-CT-349
COVID-CT-118

66.3
77.4
60.4

58.1
74.6
42.6

80.6
86.4
74.1

4. Study II: Improve the performance to a clinically more useful level
In the previous study, we have shown that paper-extracted COVID-CT is useful for training
diagnosis models for COVID-19 and yields much better performance than purely using
original COVID-19 CTs. But the accuracy is still low. In this section, we develop methods
that improve the diagnosis accuracy to a clinically more useful level.
4.1. Method
The total number of positive training images in COVID-CT and COVID-Seg is 467. Training deep learning models on such a small number of images is prone to overfitting. To
address this issue, we study two ways: one is to incorporate additional information including segmentation masks of lung regions and segmentation masks of lesion regions; the other
way is to learn better visual representations. Lung masks inform models to pay more attention to lung regions which contain clinical manifestation of COVID-19, instead of paying
attention to background regions that are irrelevant to COVID-19. While lung masks narrow
down the search space of COVID-19, they are still coarse-grained. Within the lung regions,
areas exactly containing COVID-19 occupy a small proportion. Lesion masks can pinpoint
such areas and provide fine-grained guidance to the model regarding which specific areas to
pay attention to. While lesion masks are more accurate, they are more difficult to obtain.
Only experienced radiologists can provide such labels while lung masks can be labeled by
non-medical people. The positive and negative training images in COVID-CT and COVIDSeg are all labeled with lung masks. Only the positive training images in COVID-Seg are
labeled with lesion masks. Figure 3 shows some examples. In light of these facts, we use
different strategies to utilize lung masks and lesion masks. Lung masks are incorporated
at the input side of the diagnosis model. Using the labeled lung masks in COVID-CT and
COVID-Seg, we develop a lung segmentation model based on residual U-Net (Zhang et al.,
2018). Given a CT image (either during training or testing), we use the segmentation model
to detect the lung mask, then concatenate it with the CT image and feed them into the diagnosis model (as shown in Figure 4(A)). The details of the lung segmentation experiments
are deferred to the supplements. Lesion masks are incorporated at the output side of the

8

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Figure 3: CT images from COVID-Seg dataset (first column), lung masks (second column),
and lesion masks (third column).

Segmentation
branch

Positive
Negative
concat

Feature extractor

(A)

Positive

Feature extractor ASPP

concat

Classification Negative
branch

(B)

Segmentation
branch

\
Positive

concat

Feature extractor

ASPP

concat

Classification Negative
branch

(C)

Figure 4: Architecture for our proposed models. (A) Architecture for incorporating lung
masks as inputs. (B) Architecture for incorporating lesion masks as outputs. (C)
Architecture for incorporating both lung masks and lesion masks.

diagnosis model during training (as shown in Figure 4(B)). They supervise the model to
pay better attention to regions containing lesions.
Figure 4(C) shows the architecture for incorporating lung masks and lesion masks simultaneously. During training, given a CT image, the network predicts the class label (whether
this image is positive for COVID-19 or negative) and the lesion mask, by minimizing the
sum of a classification loss and a lesion segmentation loss. Given a CT image, we first use
the lung segmentation model to obtain the lung mask. Then the original CT image together
with the lung mask image are concatenated and fed into the feature extraction network.
Then the visual features are fed into an atrous spatial pyramid pooling (ASPP) (Chen
et al., 2017) layer to extract denser and higher-resolution feature maps. These features
maps are fed into two branches: a lesion segmentation branch for predicting lesion segmentation mask and a classification branch for prediction class label. The predicted lesion
segmentation mask is fed into the classification branch as additional information. A lesion
9

COVID-CT-Dataset: A CT Image Dataset about COVID-19

segmentation loss function is defined between the groundtruth mask and predicted mask.
A classification loss is defined between the groundtruth label and predicted label. The sum
of these two losses are minimized for learning the weight parameters in the network. Note
that the lesion masks are only required during training. During testing, the prediction is
made solely based on test images and their lung segmentation masks. No lesion mask is
required.
The other approach for improving performance is to learn better visual representations.
The weights in DenseNet-169 and ResNet-50 are pretrained on ImageNet using transfer
learning. The class labels in ImageNet are leveraged during the pretraining. Since ImageNet
classes are mostly non-medical, models pretrained by ImageNet may be biased to these
general-domain classes and generalize less well on COVID-19 classification. To mitigate
this bias, we use contrastive self-supervised learning (CSSL) (He et al., 2019) to finetune
the ImageNet-pretrained models on the training CT images in our COVID-19 diagnosis task.
CSSL is an unsupervised approach. It learns representations by solving an auxiliary task.
CSSL creates augmented examples of CTs, then learns the visual representation network by
solving the prediction task that whether two augments originate from the same CT. During
CSSL training, only the input CT images are used and no labels are utilized. After CSSL
training, the network is further finetuned using both the input CTs and output labels.
4.2. Experiments
Experimental settings In the multi-task learning framework, the weights associated
with the segmentation loss and the classification loss are both set to 1. The rest of hyperparameter settings are the same as those in Section 3. In contrastive self-supervised
learning, we follow the same hyperparameter setting as in MoCo (He et al., 2019). Each
input image is augmented with random horizontal flip, random cropping with a size of 0.2 in
area, random color jittering such as random brightness with a ratio of 0.4, random contrast
of 0.4, random saturation of 0.4, random hue of 0.1, Gaussian blur, and random gray-scale
conversion. The size of the dynamic dictionary was set to 512. Stochastic gradient descent
(SGD) was used as the optimizer with a minibatch size of 128, a weight decay of 0.0001, a
momentum of 0.9, and an initial learning rate of 0.015.
Results Table 6 shows the performance of DenseNet-169 on test data. “Combination”
denotes the combined training dataset of COVID-CT-349 and COVID-Seg. DenseNet-169
is pretrained on ImageNet via transfer learning, without finetuning using CSSL. From this
table, we make the following observations. First, incorporating lung masks can greatly
improve performance. This is evident from the comparison of (1) “COVID-CT-349 with
lung mask only” and “COVID-CT-349”, (2) “COVID-CT-118 with lung mask only” and
“COVID-CT-118”, and (3) “Combination with lung mask only” and “Combination”. On
COVID-Seg, incorporating lung masks substantially improves F1, though the accuracy and
AUC are sacrificed a bit. Second, incorporating lesion masks can greatly improve performance. This is evident from the comparison of (1) “COVID-Seg with lesion mask only” and
“COVID-Seg” and (2) “Combination with lesion mask only” and “Combination”. Third, on
the combined dataset, using both lung masks and lesion masks achieve better performance
than using lung masks only or using lesion masks only. Overall, these results demonstrate
the usefulness of lung masks and lesions masks in improving diagnosis performance.
10

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Train data

Table 6: Performance of DenseNet-169 on the test set.
Accuracy(%) F1-score(%)

AUC(%)

COVID-CT-349
COVID-CT-349 with lung mask only

79.5
85.0

76.0
85.9

90.1
92.8

COVID-Seg
COVID-Seg with lung mask only
COVID-Seg with lesion mask only

69.8
68.0
72.4

61.1
74.8
77.5

86.9
85.8
95.0

COVID-CT-118
COVID-CT-118 with lung mask only

57.8
73.3

36.3
66.4

75.2
86.2

Combination
Combination with lung mask only
Combination with lesion mask only
Combination with lung and lesion masks

74.5
86.2
83.3
87.1

70.1
87.2
84.6
88.1

89.8
97.6
94.8
95.2

Table 7: Comparison of different pretraining methods.
Initialization
Random initialization
Transfer learning (TL)
TL+CSSL

Accuracy(%)

F1-score(%)

AUC(%)

83.0
87.1
89.1

83.2
88.1
89.6

94.1
95.2
98.1

Table 7 shows the testing performance of DenseNet-169 trained on the combined dataset,
under different pretraining methods. From this table, we make the following observations.
First, CSSL+TL achieves better performance than transfer learning (TL). This demonstrates the effectiveness of CSSL in improving the learned representations. Second, TL
performs better than random initialization. By incorporating lung masks and lesion mask
via multi-task learning and leveraging CSSL pretraining, our method achieves an F1 of 0.90,
an AUC of 0.98, and an accuracy of 0.89. The senior radiologist has confirmed that models
with such performance are clinically useful.

5. Related works
5.1. Deep learning based diagnosis of COVID-19
Since the outbreak of COVID-19, there have been increasing efforts on developing deep
learning methods to perform screening of COVID-19 based on medical images such as CT
scans and chest X-rays. Wu et al. established an early-screening model based on multiple
CNN models to classify CT scans of patients with COVID-19 (Xu et al., 2020). Wang et
al. proposed a 3D deep CNN to detect COVID-19 (Zheng et al., 2020) using chest CT
slices. Chowdhury et al. employed CNN to identify COVID-19 patients based on chest
X-ray images (Chowdhury et al., 2020). Several works have also applied 3D deep learning
models to screen COVID-19 based on chest CT images (Gozes et al., 2020; Li et al., 2020).

11

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Yang et al. developed a deep learning based CT diagnosis system (DeepPneumonia) to assist
clinicians to identify patients with COVID-19 (Song et al., 2020). Xu et al. developed a deep
learning algorithm by modifying the inception transfer-learning model to provide clinical
diagnosis ahead of the pathogenic test (Wang et al., 2020). Shi et al. employed the “VB-Net
neural network to segment COVID-19 infection regions in CT scans (Shan+ et al., 2020).
Yu et al. constructed a system based on UNet++ for identification of COVID-19 from CT
images (Chen et al., 2020). Shen et al. proposed an infection-size-aware Random Forest
(iSARF) method which can automatically categorize subjects into groups with different
ranges of infected lesion sizes (Shi et al., 2020). In most of these studies, the datasets are
not publicly available.
5.2. Datasets about COVID-19
At present, few large-sized datasets with medical images on COVID-19 are publicly available
due to privacy concerns and information blockade (Cohen et al., 2020b). Existing datasets
on COVID19 are mainly X-ray images (Cohen et al., 2020b; Chowdhury et al., 2020; COV,
c). The Italian Society of Medical and Interventional Radiology (SIRM) provides chest
X-rays and CT images of 68 Italian COVID-19 cases (COV, a). Moore et al. released a
dataset of axial and coronal CTs from 59 COVID-19 cases at Radiopaedia (COV, b). Other
data sources provide medical images of no more than 10 patients (Eur; Cor). To deal with
the lack of large-sized and open-source datasets containing CT images of COVID-19 cases,
we built the COVID19-CT dataset.

6. Conclusions
We build a publicly available CT image dataset about COVID-19, to foster the development
of AI methods for using CT to screen and test COVID-19 patients. The dataset contains
349 COVID-19 CT images from 216 patients and 463 non-COVID-19 CT images (used as
negative training examples). The utility of this dataset is confirmed by a senior radiologist
who has intensively practiced diagnosis and treatment of COVID-19 patients. We also
perform experimental studies to further verify the utility of this dataset. Using this dataset,
we develop an approach based on multi-task learning and contrastive self-supervised learning
that achieves an F1 of 0.90, an AUC of 0.98, and an accuracy of 0.89, on a test set of original
CT images donated by hospitals. The senior radiologist has confirmed that models with
such performance are clinically useful.

References
Covid-19 database, a. https://www.sirm.org/ Accessed April 9, 2020.
Covid-19, b. https://radiopaedia.org/ Accessed April 9, 2020.
Covid-19 chest x-ray database, c.
https://www.kaggle.com/tawsifurrahman/
covid19-radiography-database/ Accessed April 9, 2020.
Coronacases. https://coronacases.org/ Accessed April 9, 2020.

12

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Eurorad. https://www.eurorad.org/ Accessed April 9, 2020.
Jun Chen, Lianlian Wu, Jun Zhang, Liang Zhang, Dexin Gong, Yilin Zhao, Shan Hu, Yonggui Wang, Xiao Hu, Biqing Zheng, et al. Deep learning-based model for detecting 2019
novel coronavirus pneumonia on high-resolution computed tomography: a prospective
study. medRxiv, 2020.
Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking
atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587,
2017.
Muhammad EH Chowdhury, Tawsifur Rahman, Amith Khandakar, Rashid Mazhar,
Muhammad Abdul Kadir, Zaid Bin Mahbub, Khandakar R Islam, Muhammad Salman
Khan, Atif Iqbal, Nasser Al-Emadi, et al. Can ai help in screening viral and covid-19
pneumonia? arXiv preprint arXiv:2003.13145, 2020.
Joseph Paul Cohen, Paul Morrison, and Lan Dao. Covid-19 image data collection. arXiv
preprint arXiv:2003.11597, 2020a.
Joseph Paul Cohen, Paul Morrison, and Lan Dao. Covid-19 image data collection. arXiv
preprint arXiv:2003.11597, 2020b.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A largescale hierarchical image database. In CVPR, 2009.
Ophir Gozes, Maayan Frid-Adar, Hayit Greenspan, Patrick D Browning, Huangqi Zhang,
Wenbin Ji, Adam Bernheim, and Eliot Siegel. Rapid ai development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient monitoring
using deep learning ct image analysis. arXiv preprint arXiv:2003.05037, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for
image recognition. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 770–778, 2016.
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast
for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722, 2019.
Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely
connected convolutional networks. In The IEEE Conference on Computer Vision and
Pattern Recognition (CVPR), July 2017.
Lu Huang, Rui Han, Tao Ai, Pengxin Yu, Han Kang, Qian Tao, and Liming Xia. Serial
quantitative chest ct assessment of covid-19: deep-learning approach. Radiology: Cardiothoracic Imaging, 2(2):e200075, 2020.
M Jun, G Cheng, W Yixin, et al. Covid-19 ct lung and infection segmentation dataset.
2020.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv
preprint arXiv:1412.6980, 2014.
13

COVID-CT-Dataset: A CT Image Dataset about COVID-19

Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin Wang, Bin Kong, Junjie Bai, Yi Lu, Zhenghan Fang, Qi Song, et al. Artificial intelligence distinguishes covid-19 from community
acquired pneumonia on chest ct. Radiology, page 200905, 2020.
Fei Shan+, Yaozong Gao+, Jun Wang, Weiya Shi, Nannan Shi, Miaofei Han, Zhong Xue,
Dinggang Shen, and Yuxin Shi. Lung infection quantification of covid-19 in ct images
with deep learning. arXiv preprint arXiv:2003.04655, 2020.
Feng Shi, Liming Xia, Fei Shan, Dijia Wu, Ying Wei, Huan Yuan, Huiting Jiang, Yaozong Gao, He Sui, and Dinggang Shen. Large-scale screening of covid-19 from community acquired pneumonia using infection size-aware classification. arXiv preprint
arXiv:2003.09860, 2020.
Ying Song, Shuangjia Zheng, Liang Li, Xiang Zhang, Xiaodong Zhang, Ziwang Huang,
Jianwen Chen, Huiying Zhao, Yusheng Jie, Ruixuan Wang, et al. Deep learning enables
accurate diagnosis of novel coronavirus (covid-19) with ct images. medRxiv, 2020.
Shuai Wang, Bo Kang, Jinlu Ma, Xianjun Zeng, Mingming Xiao, Jia Guo, Mengjiao Cai,
Jingyi Yang, Yaodong Li, Xiangfei Meng, et al. A deep learning algorithm using ct images
to screen for corona virus disease (covid-19). medRxiv, 2020.
Yu-Huan Wu, Shang-Hua Gao, Jie Mei, Jun Xu, Deng-Ping Fan, Chao-Wei Zhao, and
Ming-Ming Cheng. Jcs: An explainable covid-19 diagnosis system by joint classification
and segmentation. arXiv preprint arXiv:2004.07054, 2020.
Xiaowei Xu, Xiangao Jiang, Chunlian Ma, Peng Du, Xukun Li, Shuangzhi Lv, Liang Yu,
Yanfei Chen, Junwei Su, Guanjing Lang, et al. Deep learning system to screen coronavirus
disease 2019 pneumonia. arXiv preprint arXiv:2002.09334, 2020.
Zhengxin Zhang, Qingjie Liu, and Yunhong Wang. Road extraction by deep residual u-net.
IEEE Geoscience and Remote Sensing Letters, 15(5):749–753, 2018.
Chuansheng Zheng, Xianbo Deng, Qing Fu, Qiang Zhou, Jiapei Feng, Hui Ma, Wenyu Liu,
and Xinggang Wang. Deep learning-based detection for covid-19 from chest ct using weak
label. medRxiv, 2020.

14

