Noname manuscript No.
(will be inserted by the editor)

The Development and Deployment of a Model for
Hospital-level COVID-19 Associated Patient Demand
Intervals from Consistent Estimators (DICE)

arXiv:2011.09377v2 [stat.AP] 19 Nov 2020

Linying Yang · Teng Zhang · Peter Glynn · David Scheinker

the date of receipt and acceptance should be inserted later

Abstract Hospitals commonly project demand for
their services by combining their historical share of
regional demand with forecasts of total regional demand. Hospital-specific forecasts of demand that provide prediction intervals, rather than point estimates,
may facilitate better managerial decisions, especially
when demand overage and underage are associated
with high, asymmetric costs. Regional forecasts of
patient demand are commonly available as a Poisson random variable, e.g., for the number of people
requiring hospitalization due to an epidemic such as
COVID-19. However, even in this common setting,
no probabilistic, consistent, computationally tractable
forecast is available for the fraction of patients in a
region that a particular institution should expect.
We introduce such a forecast, DICE (Demand Intervals from Consistent Estimators). We describe its
development and deployment at an academic medical center in California during the ‘second wave’ of
COVID-19 in the Unite States. We show that DICE
is consistent under mild assumptions and suitable
for use with perfect, biased, unbiased regional forecasts. We evaluate its performance on empirical data
from a large academic medical center as well as on
synthetic data.
Keywords COVID-19 · Hospital-level forecast ·
Prediction interval · Parametric bootstrap · Moment
method · Prediction bias
Linying Yang
Institute for Computational and Mathematical Engineering,
Stanford University, Stanford, CA 94305, USA
Teng Zhang · Peter Glynn · David Scheinker
Department of Management Science and Engineering, Stanford University, Stanford, CA 94305, USA

1 Introduction
The COVID-19 pandemic has disrupted hospital operations the world over. Large influxes of patients
requiring intensive care and mechanical ventilation
have overwhelmed capacity, forced hospitals to triage,
and have been associated with significantly elevated
case fatality rates. Shortages of personal protective
equipment (PPE) have exposed healthcare workers
to additional risk and many have contracted COVID19 and died.
Hospitals managers have a variety of options to
increase total and available capacity when planning
for an influx of COVID-19 patients [1]. Managers
may be able to increase total capacity by calling in
additional nurses and doctors, opening previously
closed beds, and acquiring additional PPE. Managers may be able to increase available capacity by
expediting patient discharge or canceling or delaying non-discretionary, non-urgent patient admissions
[2]. The potential detriments to the quality of care
and higher costs associated with these actions may
be partially or fully mitigated if the decision to act
is made with sufficient lead time. In the worst-case
scenario when a hospital has insufficient intensive
care unit (ICU) or ventilator capacity, patients with
COVID-19 may experience significantly higher case
mortality rates [3]. In less dire scenarios, nurses called
in to work on short notice may require overtime pay
while those scheduled a week in advance may not;
PPE is less expensive when its purchase is not expedited; and patients whose non-urgent procedures
are scheduled for later will experience less disruption than patients whose procedures are cancelled
on short notice. In the United States, where health-

2

care is paid for through a combination of private
and public insurance, the pandemic has created the
additional challenge of significant financial stress as
COVID-19 patients are associated with lower rates
of reimbursement than patients who receive nonurgent, non-discretionary procedures such as tumor
removal surgery or chemotherapy [4].
The complementary challenges of ensuring sufficient capacity to meet the demand associated with
COVID-19 while avoiding unnecessarily long delays
to non-COVID-19 care, require hospital managers
to generate forecasts of the volume of COVID-19
patients requiring care at their institution. Managerial decisions based on forecasts of COVID-19 may
benefit from the availability of the forecast with as
much lead time as possible. To allow managers to account for the asymmetric risk associated with having
insufficient capacity to meet urgent COVID-19 demand or non-urgent procedural demand, such forecasts should provide probabilistic, rather than point,
estimates.
Our methodology reflects the random fluctuations that arise at the hospital level that are averaged
out at the regional level. For example, if a hospital
receives, on average, 5% of a county’s hospitalization and the forecast county hospitalization level is
100, the random fluctuation about the mean hospital load of 5 patients can be significant (in a relative
error sense). In particular our methodology provides
a prediction interval on the number of COVID-19
positive patients at a given hospital rather than a
“point forecast”. In addition, our methodology takes
into account the additional uncertainty induced by
estimation error associated with estimating the underlying statistical parameters from observed data.
This paper is concerned with developing statistical methods to support hospital decision making
with regard to COVID-19 capacity planning issues.
In particular, hospital leadership can benefit from
statistical tools to help them assess the amount of
capacity that will need to be assigned to coronavirus
patients in the weeks to come. A serious complication is that epidemiological forecasts typically focus
on aggregate COVID-19 predictions that are provided at the regional level. For example, in California, the available COVID-19 forecasts are provided at the county level. Our goal in this paper
is to provide a statistically principled methodology
for obtaining hospital-level coronavirus hospitalization forecasts from such regional forecasts. A simple
example is illustrative.

Linying Yang et al.

Consider a hospital preparing for a forecast influx of COVID-19 patients. Suppose the hospital can
accommodate up to 20 COVID-19 patients with its
current capacity, 21-30 COVID-19 patients by calling in additional staff, and over 30 patients by cancelling scheduled procedures. A forecast that the hospital will have to accommodate 25 .
Given a regional forecast for the daily number
of hospitalizations as well as historical data on the
share of regional hospitalizations accommodated by
a specific hospital, all assumed to be Poisson random
variables, we develop a forecast model DICE (Demand Intervals from Consistent Estimators). The
primary contributions of this paper are as follows.
– We show that DICE is consistent under mild assumptions and suitable for use with biased and
unbiased regional forecasts.
– We show that DICE performed well on empirical data from a large academic medical center in
California as well as on synthetic data.
– We describe the COVID-19 related capacity management decisions facilitated by the use of DICE.

2 Literature
Numerous COVID forecasting models have been developed since the start of the pandemic. Among them,
many forecast regional-level COVID-19 cases, hospitalizations, and deaths [5], [6], [7], [8] and [9]. Most
such models use publicly available data and epidemic
models to forecast hospitalizations down to the level
of a single county or several adjacent counties. However, few tools are available for hospitals to make a
probabilistic forecast of their expected share of the
forecast regional volume. The data available to make
such a forecast include: the outputs of the aforementioned models; detailed historical data on countylevel hospitalizations, available from the national authorities such as [10]; real-time data on hospitalizations in a particular county or region available
from local authorities such as and [11]; and hospitalspecific hospitalization data to the managers of the
institution generating the forecast.

3 Setting
This model was developed in response to a request
from the COVID-19 planning leadership of a large
academic medical center (AMC) in a large county in

Title Suppressed Due to Excessive Length

California during the summer of 2020. After the initial wave of COVID-19 cases was brought under control with non-pharmaceutical interventions such as
social distancing, the hospital restarted non-urgent
admissions for procedures such as surgery. As national news of a ‘second wave’ of COVID-19 hospitalizations spread, the AMC leadership wanted to prepare. They requested a forecast that would inform
them, with as much notice as possible, of an influx
of COVID-19 patients sufficiently large that elective
admissions should be halted in order to make capacity available for the expected COVID-19 patients.
We were provided with the hospital’s historical data
on the number of admissions and the length of stay
of each patient in the ACU and ICU, historical and
forecast data for the total number of hospitalizations
in the county, and automated daily updates on the
number of new COVID-19 admissions to the ICU
and ACU as well as patients currently in those units.
We worked with hospital leadership to estimate the
capacity of COVID-19 patients that the institution
could accommodate without having to increase available capacity by canceling scheduled procedures as.
We also worked with the leadership to determine an
order for cancelling scheduled, non-urgent surgical
procedures if necessary. The order was based primarily on the clinical acuity of those requiring the
procedure, the average ICU and ACU post-operative
length of stay associated with the procedure, and additional constraints on hospital operations. Those efforts are described in another work in progress. The
goal of the present work was to generate a forecast
that used recent data on the share of all COVID19 patients in the county to provide two weeks notice for when the demand associated with COVID19 patients was likely to require the cancellation of
the scheduled procedures. Since hospital occupancy
fluctuates naturally, rather than determine a hard
cut-off for cancelling procedures, hospital leadership
requested that we notify them if the upper bound
of the prediction interval exceeded a pre-specified
lower bound at which point they would evaluate the
prospect of cancelling cases.

3

care unit (ICU) hospitalization at the end of day
r, with r ≥ 0. For the purpose of predicting these
hospital-level prediction intervals, we have available
historical data ((Aj , Bj , Nj ) : −n ≤ j ≤ −1), where
Nj is the total number of regional hospitalizations
at the end of day j, Aj is the number of ACUte care
hospitalizations at the given hospital at the conclusion of day j, and Bj is the number of ICU hospitalizations at the given hospital at the end of day
j. Furthermore, we assume that we have available a
point forecast Fr for the mean number of regional
hospitalizations at the end of day r.
Throughout the paper, we take the view that the
Aj ’s,Bj ’s and Nj ’s can be reasonably modeled as
Poisson distributed random variables (rv’s).We will
use the notation P(λ) to denote a Poisson rv with
mean λ. There is an extensive mathematical theory
supporting the use of Poisson rv’s in the setting of
such count statistics; see, for example, [12].
A simple model relates Aj and Bj to Nj by assuming that EAj = p0 ENj and EBj = q0 ENj for
p0 , q0 ≥ 0. Because the Nj ’s are subject to episodic
epidemic growth spurts, we do not assume that ENj
is constant. Instead, we permit λj ≡ ENj to fluctuate in a potentially complex fashion.
In this section, we assume that point forecast Fr
is perfect, in the sense that
Fr = λr .

It follows that if we select l(λ) (the lower endpoint)
as the largest integer such that P (P(λ) < l(λ)) ≤ 2δ
and u(λ) (the upper endpoint) as the smallest integer
such that P (P(λ) > u(λ)) ≤ 2δ , then [l(Fr ), u(Fr )] is
a 100(1 − δ)% prediction interval for Nr having the
property that P (Nr ∈ [l(Fr ), u(Fr )]) ≥ 1 − δ.
To obtain similar prediction intervals for Ar and
Br , we need to estimate p0 and q0 from the data.
The obvious estimators for p0 and q0 are given by
p̂ =

q̂ =

−1
X

We start by describing the problem setting from a
mathematical perspective. We assume that we are
currently in day 0 and have been tasked with producing prediction intervals for the future number of
hospital-level ACUte care unit (ACU) and intensive

Aj /

−1
X

j=−n

j=−n

−1
X

−1
X

j=−n

4 Prediction Intervals with Perfect Forecasts

(2.1)

Bj /

Nj ,
(2.2)
Nj .

j=−n

In fact, p̂ and q̂ are the maximum likelihood estimators (MLE’s) for p0 and q0 when Aj (and Bj )
are, conditional on N−n , . . . , N−1 , independent in j
and binomially distributed with parameters Nj and
p0 (and q0 ).
This leads to the prediction intervals [l(p̂Fr ),
u(p̂Fr )] for Ar and [l(q̂Fr ), u(q̂Fr )] for Br . We refer

4

Linying Yang et al.

to these prediction intervals as the plug-in prediction
intervals based on perfect forecasts.
5 Prediction Intervals with Perfect
Forecasts: Incorporating Estimation
Uncertainty
Our frequentist approach starts by setting θ = (p, q)
and letting Pθ (·) be the probability model under
which the (Ai , Bi , Ni − Ai − Bi )’s are conditionally
independent given the Nj ’s., with (Ai , Bi , Ni − Ai −
Bi ) following a multinomial distribution with parameters (Ni , p0 , q0 , 1 − p0 − q0 ). Our ideal prediction interval for Ar would, of course, be the interval
[`(p0 Fr ), u(p0 Fr )]. Since p0 is unknown, the plug-in
interval [`(p̂Fr ), u(p̂Fr )] of section 2 is an obvious alternative. However, because p̂ is random, we can not
guarantee that
Pθ0 (Ar < `(p̂Fr )) ≤ δ/2,

(3.1)

where θ0 = (p0 , q0 ).
Instead, we seek a probabilistic guarantee, namely
that (3.1) holds, with probability (or confidence level)
1 − α.
We can accomplish this by choosing the integer
z` so that
Pθ0 (`(p̂Fr ) − `(p0 Fr ) ≤ z` ) ≥ 1 − α.

(3.2)

On the event {`(p0 Fr ) ≥ `(p̂Fr ) − z` },
Pθ0 (Ar < `(p̂Fr ) − z` ) ≤ Pθ0 (Ar < `(p0 Fr )) ≤ δ/2.

where θ̂ = (p̂, q̂) and p̂∗ is the estimator for p̂ obtained from a bootstrap sample of the data set; the
details can be found in the algorithm as described
below. This leads to the prediction interval [`(p̂Fr )−
z`∗ , u(p̂Fr ) − zr∗ ]; we refer to this as the bootstrap prediction interval for Ar based on perfect forecasts.
We can similarly compute the bootstrap prediction
interval for Br based on perfect predictions.
Specifically, our bootstrap prediction intervals are
produced by the following algorithm.
Algorithm 1.
1. Simulate independent Poisson random variables
(Ni∗ : −n ≤ i ≤ −1) with mean (Fi : −n ≤ i ≤
−1).
2. Conditional on Ni∗ , simulate a multinomial rv
(A∗i , Bi∗ , Ni∗ − A∗i − Bi∗ ) with parameters (n, p̂, q̂,
1 − p̂ − q̂).
3. Compute
P−1
∗
j=−n Aj
∗
p̂ = P−1
∗
j=−n Nj
P−1
∗
j=−n Bj
q̂ ∗ = P−1
∗
j=−n Nj
4. Compute (`(p̂∗ Fr ), u(p̂∗ Fr ), `(q̂ ∗ Fr ), u(q̂ ∗ Fr )).
5. Repeat steps 1 to 4 b times, thereby yielding b
4-tuples (`(p̂∗i Fr ), u(p̂∗i Fr ), `(q̂i∗ Fr ), u(q̂i∗ Fr )).
∗
∗
6. Compute the smallest integers zA,`
and zB,`
for
which
b

Hence, with confidence at least 1 − α, `(p̂Fr ) − z` is
an appropriately chosen value for the left endpoint
of Ar ’s prediction interval.
Similarly, if we choose the integer zr so that
Pθ0 (u(p̂Fr ) − u(p0 Fr ) ≥ zr ) ≥ 1 − α,

(3.3)

u(p̂Fr ) − zr is a right endpoint for which
Pθ0 (Ar > u(p̂Fr ) − zr ) ≤ δ/2 holds, at a confidence
level of at least 1 − α. Hence, we adopt the interval
[`(p̂Fr ) − z` , u(p̂Fr ) − zr ] as our prediction interval
for Ar that takes into account the estimation uncertainty that is present in p̂.
To compute z` and zr from (3.2) and (3.3), we
use the parametric bootstrap (see, for example, [13]),
thereby computing the values z`∗ and zr∗ such that
Pθ̂ (`(p̂∗ Fr ) − `(p̂Fr ) ≤ z`∗ ) ≥ 1 − α
and
Pθ̂ (u(p̂∗ Fr ) − u(p̂Fr ) ≥ zr∗ ) ≥ 1 − α,


1X
∗
I `(p̂∗i Fr ) − `(p̂Fr ) ≤ zA,`
≥1−α
b i=1
and
b


1X
∗
I `(q̂i∗ Fr ) − `(q̂Fr ) ≤ zB,`
≥ 1 − α,
b i=1
∗
∗
and the largest integers zA,r
and zB,r
for which
b


1X
∗
I u(p̂∗i Fr ) − u(p̂Fr ) ≥ zA,r
≥1−α
b i=1
and
b


1X
∗
I u(q̂i∗ Fr ) − u(q̂Fr ) ≥ zB,r
≥ 1 − α.
b i=1
∗ +
∗
Then, the intervals [[`(p̂Fr )−zA,`
] , u(p̂Fr )−zA,r
]
∗
+
∗
and [[`(q̂Fr ) − zB,` ] , u(q̂Fr ) − zB,r ] are the bootstrap prediction intervals for Ar and Br respec∆
tively, where [x]+ = max(x, 0) for x ∈ R.

Title Suppressed Due to Excessive Length

5

6 Unbiased Forecasts with Lognormal Errors
The model described in Section 2 and 3 assumes no
forecast error. As a consequence, the distribution for
Ni is Poisson distributed with mean Fi . However, the
forecast Fi itself is imperfect, and there typically is
additional uncertainty in the prediction of Ni (beyond the stochastic variability of a Poisson rv) that
should be reflected in the prediction interval. In this
section, we model the forecast error by assuming that
Fi = λi Γi−1 ,

(4.1)

where Ni is (again) Poisson with mean λi , and the
relative forecast error Γi−1 is assumed to be lognormally distributed. Furthermore, we assume that
the Ni ’s are independent of the Γi−1 ’s, and that the
forecasts are relatively unbiased, in the sense that
 
Ni
E
=1
(4.2)
Fi
for all i, thereby implying that E[Γi ] = 1.
Of course, one expects that if the forecast underpredicts Ni at time i, Fi+1 is also likely to underpredict Ni+1 . This suggests that the Γi ’s should be
modeled as a correlated sequence. In particular, we
will assume that if Yi = log Γi , the Yi ’s form a stationary sequence that evolves according to the recursion
Yi+1 = ρ0 Yi + Zi+1 ,
where the Zi ’s are independent and identically distributed (iid) normally distributed rv’s with mean
µ0 and variance σ02 . Note that the stationarity of
the Yi ’s implies that ρ ∈ (−1, 1), with Yi having a
normal distribution having mean µ0 (1 − ρ0 )−1 and
variance σ02 (1 − ρ20 )−1 ; see [14].
For this model, we need to estimate the parameters µ0 , σ02 and ρ0 associated with the log-normally
distributed forecast error sequence. As in Section 2
and 3, we assume that we have observed the time
series ((Ai , Bi , Ai , Fi ) : −n ≤ i ≤ −1), and we adopt
the view that we wish to impose as few assumptions
as possible on the λi ’s (given the episodic nature of
the coronavirus epidemic). For this reason, we will
use the method of moments to estimate µ0 , σ02 and
ρ0 .
Given (4.2), we require that


µ0
1 σ02
E[exp(Yi )] = exp
+
1 − ρ0
2 1 − ρ20
∆

= m1 (µ0 , σ02 , ρ0 ) = 1.

To obtain a second equation, note that

 2
Ni − Ni
2
= E[Ni2 − Ni ] · λ−2
E
i E[Γi ]
Fi2
2
= ((λi + λ2i ) − λi ) · λ−2
i E[Γi ]

= E[exp(2Yi )]


σ02
2µ0
+2
= exp
1 − ρ0
1 − ρ20
∆

= m2 (µ0 , σ02 , ρ0 ).
For the third equation, we observe that


Ni Ni+1
E
= ENi · ENi+1 · (λi λi+1 )−1 EΓi Γi+1
Fi Fi+1
= E[exp(Yi + Yi+1 )]
= E[exp((1 + ρ0 )Yi + Zi+1 )]


σ02
2µ0
+
= exp
1 − ρ0
1 − ρ0
∆

= m3 (µ0 , σ02 , ρ0 )
This suggests that we estimate µ0 , σ02 and ρ0 by minimizing the objective

2 
2
M̂2 − m2 (µ, σ 2 , ρ) + M̂3 − m3 (µ, σ 2 , ρ)
subject to
m1 (µ, σ 2 , ρ) = 1,
−1 ≤ ρ ≤ 1,
σ 2 ≥ 0,
where

−1 
1 X Ni2 − Ni
,
,
n i=−n
Fi2


−1
X
Ni Ni−1
1
,
M̂3 =
n − 1 i=−n+1 Fi Fi−1
M̂2 =

followed by utilizing the minimizer (µ̂, σ̂ 2 , ρ̂) as our
estimator of (µ0 , σ02 , ρ0 ), and then estimate p̂ and
q̂ as in (2.2). When n is large (and the statistical
model describes the data well), we expect that the
objective function will vanish at (µ̂, σ̂ 2 , ρ̂), in which
case
mi (µ̂, σ̂ 2 , ρ̂) = M̂i
will be satisfied as equations for i = 2, 3. In the Appendix, we prove that our estimators for µ0 , σ02 , and
ρ0 are consistent, under very moderate assumptions
on the λi ’s.

6

Linying Yang et al.

We note that in this model, the prediction interval for Nr must reflect the additional randomness stemming from the fact that the mean of the
Poisson random variable is itself random, namely it
is given by Fr Γr . In particular, let P(µ, σ 2 , ρ, f ) be
a rv that is conditionally Poisson distributed, with
(random) mean f exp(N (µ/(1 − ρ), σ 2 /(1 − ρ2 ))),
where N (µ/(1 − ρ), σ 2 /(1 − ρ2 )) is a normal rv with
mean µ/(1 − ρ) and variance σ 2 /(1 − ρ2 ). The plugin prediction interval for Ar based on this model is
the interval [`(µ̂, σ̂ 2 , ρ̂, p̂Fr ), u(µ̂, σ̂ 2 , ρ̂, p̂Fr ))], where
`(µ, σ 2 , ρ, f ) is the largest integer j such that
P (P(µ, σ 2 , ρ, f ) < j) ≤ δ/2 and u(µ, σ 2 , ρ, f ) is the
smallest integer k such that P (P(µ, σ 2 , ρ, f ) > k) ≤
δ/2. Similarly, [`(µ̂, σ̂ 2 , ρ̂, q̂Fr ), u(µ̂, σ̂ 2 , ρ̂, q̂Fr ))] is the
plug-in prediction interval for Br .
The computation of `(µ, σ 2 , ρ, f ) and u(µ, σ 2 , ρ, f )
can be implemented via Monte Carlo, using the following algorithm.

2. For −n < i ≤ −1, simulate Yi∗ via the recursion
∗
Yi∗ = ρ̂Yi−1
+ Zi∗ ,

where the Zi∗ ’s are independently simulated as
normal rv’s with mean µ̂ and variance σ̂ 2 .
3. Given (Yi∗ : −n ≤ i ≤ −1), simulate the Ni∗ ’s as
independent Poisson rv’s with means (Fi exp(Yi∗ ) :
−n ≤ i ≤ −1).
4. Compute

−1 
1 X Ni∗2 − Ni∗
,
n i=−n
Fi2
 ∗ ∗ 
−1
X
Ni Ni−1
1
M̂3∗ =
.
n − 1 i=−n+1 Fi Fi−1

M̂2∗ =

5. Compute the minimizer (µ̂∗ , σ̂ 2∗ , ρ̂∗ ) of


Algorithm 2
1. Simulate Yr as a normal rv with mean µ/(1 − ρ)
and variance σ 2 /(1 − ρ2 ).
2. Generate Nr as a Poisson rv with mean f exp(Yr ).
3. Repeat Steps 1 and 2, independently, m times,
thereby yielding Nr,1 , . . . , Nr,m .
ˆ σ 2 , ρ, f ) for `(µ, σ 2 , ρ, f )
4. Define the estimator `(µ,
as the largest integer j such that
m

1 X
I(Nr,i < j) ≤ δ/2
m i=1
and define the estimator û(µ, σ 2 , ρ, f ) for
u(µ, σ 2 , ρ, f ) as the smallest integer k for which

2 
2
M̂2∗ − m2 (µ, σ 2 , ρ) + M̂3∗ − m3 (µ, σ 2 , ρ)

subject to
m1 (µ, σ 2 , ρ) = 1,
−1 ≤ ρ ≤ 1,
σ 2 ≥ 0.
6. Generate (A∗i , Bi∗ , Ni∗ − A∗i − Bi∗ ) as multinomial
rv’s with parameters (Ni∗ , p̂, q̂, 1 − p̂ − q̂), −n ≤
i ≤ −1.
7. Compute
P−1
∗

We now turn to the construction of prediction intervals for Ar and Br that reflect the additional uncertainty due to the need to estimate µ0 , σ02 , ρ0 fro
the observed data ((Ai , Bi , Ni , Fi ) : −n ≤ i ≤ −1).
Again, we use the bootstrap to compute the correc∗
∗
∗
∗
tions zA,`
, zB,`
, zA,r
, zB,r
that appear in this setting
(that are direct analogs to those appearing in Algorithm 1 for perfect forecasts.)
Algorithm 3
∗
1. Generate Y−n
as a normal rv with mean µ̂/(1− ρ̂)
and variance σ̂ 2 /(1 − ρ̂2 ).

A∗j

j=−n

Nj∗

P−1

m

1 X
I(Nr,i > k) ≤ δ/2.
m i=1

j=−n

p̂ = P−1

j=−n

Bj∗

j=−n

Nj∗

q̂ ∗ = P−1

8. Use Algorithm 2 to compute `(µ̂∗ , σ̂ 2∗ , ρ̂∗ , p̂∗ Fr ),
u(µ̂∗ , σ̂ 2∗ , ρ̂∗ , p̂∗ Fr ), `(µ̂∗ , σ̂ 2∗ , ρ̂∗ , q̂ ∗ Fr ),
u(µ̂∗ , σ̂ 2∗ , ρ̂∗ , q̂ ∗ Fr ).
9. Repeat Steps 1 to 8 b times, thereby yielding b
4-tuples (`(µ̂∗i , σ̂i2∗ , ρ̂∗i , p̂∗i Fr ), u(µ̂∗i , σ̂i2∗ , ρ̂∗i , p̂∗i Fr ),
`(µ̂∗i , σ̂i2∗ , ρ̂∗i , q̂i∗ Fr ), u(µ̂∗i , σ̂i2∗ , ρ̂∗i , q̂i∗ Fr )).
∗
∗
10. Compute the smallest integers zA,`
and zB,`
for
which
b

1X
I(`(µ̂∗i , σ̂i2∗ , ρ̂∗i , p̂∗i Fr )−
b i=1
∗
`(µ̂, σ̂ 2 , ρ̂, p̂Fr ) ≤ zA,`
)≥1−α

Title Suppressed Due to Excessive Length

7

As in Section 4, we estimate p0 and q0 via p̂ and q̂
as in (2.2). As in Section 4, [`(µ̂, σ̂ 2 , ρ̂, p̂Fr ), u(µ̂, σ̂ 2 ,
ρ̂, p̂Fr )] and [`(µ̂, σ̂ 2 , ρ̂, q̂Fr ), u(µ̂, σ̂ 2 , ρ̂, q̂Fr )] are then
our plug-in prediction intervals for Nr based on the
biased log-normal forecast error model.
Similarly, incorporating the estimation error related to estimating (µ0 , σ02 , ρ0 , p0 , q0 ) via (µ̂, σ̂ 2 , ρ̂,
p̂, q̂) requires only small modifications to the methodology of Section 4. The modified version of Algorithm 3 reflecting use of biased forecasts is provided
next.

and
b

1X
I(`(µ̂∗i , σ̂i2∗ , ρ̂∗i , q̂i Fr )−
b i=1
∗
`(µ̂, σ̂ 2 , ρ̂, q̂Fr ) ≤ zB,`
)≥1−α
∗
∗
and the largest integers zA,r
, zB,r
for which
b

1X
I(`(µ̂∗i , σ̂i2∗ , ρ̂∗i , p̂∗i Fr )−
b i=1
∗
`(µ̂, σ̂ 2 , ρ̂, p̂Fr ) ≥ zA,r
)≥1−α

Algorithm 4

and

Algorithm 4 is identical to Algorithm 3, excepting
that (µ̂, σ̂ 2 , ρ̂) is now the minimizer of (5.1), and
Steps 4 and 5 are modified as follows:

b

1X
I(`(µ̂∗i , σ̂i2∗ , ρ̂∗i , q̂i∗ Fr )−
b i=1
∗
`(µ̂, σ̂ 2 , ρ̂, q̂Fr ) ≥ zB,r
)≥1−α

40 . Compute

∗ +
] , u(µ̂, σ̂ 2 , ρ̂, p̂Fr ) −
Then, [[`(µ̂, σ̂ 2 , ρ̂, p̂Fr ) − zA,`
2
∗
and [[`(µ̂, σ̂ , ρ̂, q̂Fr ) − zB,` ]+ , u(µ̂, σ̂ 2 , ρ̂, q̂Fr ) −
are our bootstrap prediction intervals for Ar
and Br , respectively, based on unbiased log-normal
forecasts.

∗
]
zA,r
∗
zB,r
]

7 Biased Forecasts with Log-normal Errors
We now modify the model of Section 4 to permit
biased forecasts. The only change we make here is
that we drop the requirement (4.2). In this case, we
need to add an additional moment identity in order
to uniquely identify the coefficients (µ0 , σ02 , ρ0 ) underlying the forecast errors given by the Γi−1 ’s. Note
that
 
Ni
2
E
= ENi (λ−1
i EΓi ) = EΓi = m1 (µ0 , σ0 , ρ0 ).
Fi
This suggests that we should estimate (µ0 , σ02 , ρ0 )
via the minimizer (µ̂, σ̂ 2 , ρ̂) of the objective function
3 
X

2
M̂i − mi (µ, σ 2 , ρ)


−1 
1 X Ni∗
,
n i=−n Fi

−1 
1 X Ni∗2 − Ni∗
,
M̂2∗ =
n i=−n
Fi2
 ∗ ∗ 
−1
X
Ni Ni−1
1
M̂3∗ =
.
n − 1 i=−n+1 Fi Fi−1

M̂1∗ =

50 . Compute the minimizer (µ̂∗ , σ̂ 2∗ , ρ̂∗ ) of
3 
X

2
M̂i − mi (µ, σ 2 , ρ)

i=1

subject to
−1 ≤ ρ ≤ 1,
σ 2 ≥ 0.
Algorithm 4 yields our desired bootstrap prediction intervals for Ar and Br , just as Algorithm 3
yields such intervals for the unbiased model of Section 4.

(5.1)

i=1

8 Empirical Results and Results on
Synthetic Data

subject to
−1 ≤ ρ ≤ 1,

8.1 Model Deployment and Evaluation: Empirical
Data

σ 2 ≥ 0,
where M̂2 and M̂3 are defined as in Section 4 and
M̂1 =

−1
X
i=−n



Ni
Ft


.

We use historical county-level COVID-19 hospitalization forecasts and ACU, ICU COVID-19 hospitalizations from the AMC studied. Given the small
number of patients, we protect patient privacy by

8

Linying Yang et al.

Fig. 1: Empirical Data
replacing the actual date with the number of days
from a reference date during the summer of 2020.
The values are shown in Figure 1.
We compare the prediction intervals under the
three settings we discuss above (perfect, unbiased,
biased), with plug-in prediction intervals and bootstrap prediction intervals under each setting. We choose
δ = 0.05 (corresponding to 95% prediction intervals)
for both plug-in and bootstrap, and α = 0.05 (corresponding to confidence level of 95%) for bootstrap.
To compare the prediction performance of each
proposed model with real data, we choose r = 7
(on each Monday we make ACU, ICU predictions
for the next Monday), comparing with the actual
value. Also we set n increased by 1 for each additional observed day in each model. We set algorithm
parameters b0 = 1000, m = 300, δ = 0.05, α = 0.05.
With these parameters, the perfect model, unbiased
model and biased model proposed converged in 1.25,
4.08 and 4.25 seconds, respectively, when run on a
laptop.
Projections for ACU and ICU made by different
models are shown in Figure 2 and 3. In each plot,
dash lines indicate 95% bootstrap prediction intervals, solid lines indicate 95% plug-in prediction intervals and black dots indicate actual values. The

unbiased models tend to provide wider prediction intervals. As we get larger n, the bootstrap prediction
intervals are getting closer to the plugin prediction
intervals.
As shown in Table 1, with r = 7, the fractions of
weeks for which each 95% plug-in prediction intervals covered the observed bed count in the ACU is
70% for all three models. The 95% bootstrap prediction intervals covered 90% of the observed bed count
in the ACU for all models. All of the prediction intervals covered 100% of the observed bed count in the
ICU. Bootstrap intervals are generally wider, thus
the coverage rates are higher. The results with 90%
prediction intervals (Figure 8, Figure 9, Table 3) and
80% prediction intervals (Figure 10, Figure 11, Table 4) on AMC data can be found in the Appendix.
The demand intervals forecast using the perfect
model were communicated to the hospital manager
in charge of COVID-19 response capacity planning.
The upper bound of the prediction intervals remained
below the threshold hospital leadership felt comfortable could be accommodated without the cancellation of elective admissions.

Title Suppressed Due to Excessive Length

9

Fig. 2: AMC ACU projections, r = 7, 95% prediction intervals, with black dots representing actual values

Fig. 3: AMC ICU projections, r = 7, 95% prediction intervals, with black dots representing actual values

10

Linying Yang et al.
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

70%
70%
70%

90%
90%
90%

100%
100%
100%

100%
100%
100%

Table 1: Coverage rate of 95% plug-in prediction intervals and 95% bootstrap prediction intervals at a
confidence level of 95%, AMC
8.2 Performance Evaluation: Synthetic Data
In this section, we generate synthetic data for 100
days. The λ’s are generated using SIR model (see,
for example, [15] and [16]), and the forecasts are
generated following different model assumptions. We
generate Ni from the Poisson distribution with mean
λi . Ai ’s and Bi ’s are generated from the multinomial
distribution with parameters (Ni , p, q, 1−p−q). They
are all generated once and used in all following sections.
To evaluate the performances, we apply the above
prediction methods on the last 60 observations.
The synthetic data are shown in Figure 4.
8.2.1 Synthetic Data under Perfect Forecasts Model
Here we generate
Fi = λi , i = 1, ..., 100
satisfying the “perfect forecast” assumption. The 95%
prediction intervals for ACU({Ai }), ICU({Bi }) are
shown in Figure 5. The fractions of observations for
which 95% plug-in prediction intervals covered the
observed bed count are 97%, 90% for ACU, ICU respectively; the ones for 95% bootstrap prediction intervals are 98%, 93%.
8.2.2 Synthetic Data under Unbiased Forecasts
Model
Under this setting, we set ρ = 0.5, σ 2 = 0.01, µ =
σ2
− 2(1+ρ)
and generate
2

µ
σ
,
)
1 − ρ 1 − ρ2
Yi = ρYi−1 + Zi , Zi ∼ N (µ, σ 2 ), i = 2, ..., 100
λi
Γi = exp(Yi ), Fi = , i = 1, ..., 100,
Γi

Y1 ∼ N (

where ∼ represents “distributed according to”, so
that E(Γi ) = 1 which satisfies the assumptions in
the “unbiased forecasts model”. The 95% prediction

intervals for ACU({Ai }), ICU({Bi }) are shown in
Figure 6. The fractions of observations for which 95%
plug-in prediction intervals covered the observed bed
count are 100%, 98% for ACU, ICU respectively;
the ones for 95% bootstrap prediction intervals are
100%, 100%. Since unbiased model tend to generate wider prediction intervals, the coverage rates are
higher.
8.2.3 Synthetic Data under Biased Forecasts Model
Under this setting, we set ρ = 0.5, σ 2 = 0.01, µ = 0.
The generation method is the same as that in unbiased model setting. The 95% prediction intervals
for ACU({Ai }), ICU({Bi }) are shown in Figure 7.
The fractions of observations for which plug-in prediction intervals covered the observed bed count are
97%, 97% for ACU, ICU respectively; the ones for
bootstrap prediction intervals are 100%, 98%.
All the plots show that with n increasing, the
bootstrap prediction intervals are getting closer to
the plugin intervals. Unbiased and biased models
larger variances, resulting in wider prediction intervals. The coverage rates of prediction intervals are
shown in Table 2. The results with 90% prediction
intervals (Figure 12, Figure 13, Figure 14, Table 5)
and 80% prediction intervals (Figure 15, Figure 16,
Figure 17, Table 6) on synthetic data can be found
in the Appendix.

9 Conclusions
In this work we introduce, DICE (Demand Intervals from Consistent Estimators), a model to forecast prediction intervals for the fraction of regional
patient demand arriving to an institution based on
the historical fraction of demand served by the institution and, potentially biased, forecasts of demand
as a Poisson random variable. We show that our
model is consistent, computationally tractable, and
well-calibrated on empirical data as well as synthetic
data. Unlike Hidden Markov models that may fail to

Title Suppressed Due to Excessive Length

11

Fig. 4: Synthetic Data
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

97%
100%
97%

98%
100%
100%

92%
98%
97%

95%
100%
98%

Table 2: Coverage rate of 95% prediction intervals, synthetic data
converge or be prohibitively computationally expensive due to the curse of dimensionality, all of the
models tested converged in seconds. To illustrate
its potential usefulness, we discuss the managerial
COVID-19 decisions that prompted the development
of the models as well as how they were used to inform
these decisions at an academic medical center. The
demand interval forecasts suggested that the ‘second
wave’ influx of COVID-19 patients would be unlikely
to exceed available hospital capacity. The information provided by the model contributed to, the ultimately correct, decision that COVID-19 patients

could be accommodated without the cancellation of
elective admissions.
As hospitals the world over prepare for a third
wave of COVID-19, this model may find similar applications at institutions planning their response to
an influx of patients. Beyond COVID-19, patient demand for a variety of medical conditions is forecast
as a Poisson random variable. The model developed
may be of use to the numerous decision to make
which hospital managers project demand for their
services by combining their historical share of regional demand with forecasts of total regional demand.

12

Linying Yang et al.

Fig. 5: Projections on synthetic data, 95% prediction intervals, perfect model, with black dots representing
actual values
References
1. Weissman GE, Crane-Droesch A, Chivers C, Luong T, Hanish A, Levy MZ, Lubken J, Becker M,
Draugelis ME, Anesi GL, et al. (2020) Locally
informed simulation to predict hospital capacity
needs during the covid-19 pandemic. Annals of
internal medicine
2. Negopdiev D, Collaborative C, Hoste E (2020)
Elective surgery cancellations due to the covid19 pandemic: global predictive modelling to inform surgical recovery plans. British Journal of
Surgery 107(11):1440–1449
3. Livingston E, Bucher K (2020) Coronavirus disease 2019 (covid-19) in italy. Jama
323(14):1335–1335
4. Khullar D, Bond AM, Schpero WL (2020)
Covid-19 and the financial health of us hospitals. Jama 323(21):2127–2128

5. CovidActNow (2020) Covid ActNow. URL
https://covidactnow.org/?s=1279305
6. GLEAM (2020) GLEAM Project. URL https:
//covid19.gleamproject.org/#about
7. Lemaitre JC, Grantz KH, Kaminsky J, Meredith
HR, Truelove SA, Lauer SA, Keegan LT, Shah
S, Wills J, Kaminsky K, et al. (2020) A scenario
modeling pipeline for covid-19 emergency planning. medRxiv
8. Altieri N, Barter RL, Duncan J, Dwivedi R,
Kumbier K, Li X, Netzorg R, Park B, Singh
C, Tan YS, et al. (2020) Curating a covid19 data repository and forecasting county-level
death counts in the united states. arXiv preprint
arXiv:200507882
9. Ferstad JO, Gu AJ, Lee RY, Thapa I, Shin AY,
Salomon JA, Glynn P, Shah NH, Milstein A,
Schulman K, et al. (2020) A model to forecast
regional demand for covid-19 related hospital

Title Suppressed Due to Excessive Length

13

Fig. 6: Projections on synthetic data, 95% prediction intervals, unbiased model, with black dots representing
actual values

10.

11.
12.

13.
14.
15.

beds. medRxiv
CDC (2020) COVID-19 Forecasts: Hospitalizations.
URL
https://www.cdc.gov/
coronavirus/2019-ncov/cases-updates/
hospitalizations-forecasts.html
CalCAT (2020) CalCAT Project. URL https:
//calcat.covid19.ca.gov/cacovidmodels/
Daley DJ, Vere-Jones D (2003) An introduction
to the theory of point processes, volume 1: Elementary theory and methods. Verlag New York
Berlin Heidelberg: Springer
Efron B, Tibshirani RJ (1994) An introduction
to the bootstrap. CRC Press
Anderson T (1971) The statistical analysis of
time series. Wiley Online Library
Bartlett MS (1956) Deterministic and stochastic
models for recurrent epidemics. In: Proceedings
of the third Berkeley symposium on mathematical statistics and probability, vol 4, p 109

16. Allen LJ (1994) Some discrete-time SI, SIR, and
SIS epidemic models. Mathematical Biosciences
124(1):83–105
17. Hamilton JD (1994) Time series analysis.
Princeton University Press

14

Linying Yang et al.

Fig. 7: Projections on synthetic data, 95% prediction intervals, biased model, with black dots representing
actual values
as n → ∞. But

Appendix
We establish here that the “method of moments”
estimators of Sections 4 and 5 will be consistent in
great generality. This will follow if we can prove that

p

M̂i −
→ mi (µ0 , σ02 , ρ0 )

(A.1)

p

as n → ∞, for 1 ≤ i ≤ 3, where −
→ denotes “converge
in probability”.
Note that EM̂i = mi (µ0 , σ02 , ρ0 ) for 1 ≤ i ≤ 3.
Hence, (A.1) follows from Chebyshev’s inequality if
we can show that

VarM̂i → 0

!
−1
X
Ni
F
i=−n i
 
−1
X
Ni
Var
+
Fi
i=−n


−1
−n
X
X
Ni Nj
Cov
,
Fi Fj
i=−n j=i+1

1
VarM̂1 = 2 Var
n
=

1
n2
2
n2

Title Suppressed Due to Excessive Length

15

Of course,
 2    2
 
Ni
Ni
Ni
− E
=E
Var
2
Fi
Fi
Fi
ENi2
= 2 · EΓi2 − m1 (µ0 , σ02 , ρ0 )2
λi
λi + λ2i
2
· EΓ−1
=
λ2i
1
2
= VarΓ−1 + EΓ−1
.
λi
Also, for i < j




   
Ni Nj
Ni Nj
Ni
Nj
Cov
,
=E
−E
E
Fi Fj
Fi Fj
Fi
Fj
ENi ENj
=
EΓi Γj − m1 (µ0 , σ02 , ρ0 )2
λi λj

= Cov Γ−1−(j−i) , Γ−1
2

= E exp(Y−1−(j−i) + Y−1 ) − (EΓ−1 )
= E exp((1 + ρ−j−i )Y−1−(j−i) +
j−i−1
X

2

ρj Z−1−j ) − (EΓ−1 )

j=0

= O(ρj−i ),
where O(ai ) denotes a quantity that is bounded by
a multiple of |ai |. Similar calculation can be found
in, for example, [17]. Consequently,

−1 
1
1 X
2
VarΓ−1 + EΓ−1 +
VarM̂1 = 2
n i=−n
λi
−n
−1
2 X X
O(ρj−i )
n2 i=−n j=i+1
 
1
=O
→0
n

as n → ∞ if we assume that the infimum of the λi ’s
is bounded away from zero. Similarly, VarM̂i → 0 for
i = 2 and i = 3 under this very moderate hypothesis
on the λi ’s, thereby establishing the consistency.
Acknowledgements We thank Kristan Lea Staudenmayer
and jonathan Lu for help understanding the problem from
the point of view of the hospital, accessing hospital data,
and providing feedback about how the projections should
be made useful.

16

Linying Yang et al.
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

60%
60%
70%

60%
60%
90%

100%
100%
100%

100%
100%
100%

Table 3: Coverage rate of 90% prediction intervals, AMC

Fig. 8: AMC ACU projections, r = 7, 90% prediction intervals, with black dots representing actual values
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

60%
60%
60%

60%
70%
70%

90%
100%
90%

90%
100%
90%

Table 4: Coverage rate of 80% prediction intervals, AMC
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

95%
98%
95%

97%
98%
97%

90%
92%
93%

93%
97%
95%

Table 5: Coverage rate of 90% prediction intervals, synthetic data

Title Suppressed Due to Excessive Length

17

Fig. 9: AMC ICU projections, r = 7, 90% prediction intervals, with black dots representing actual values

Fig. 10: AMC ACU projections, r = 7, 80% prediction intervals, with black dots representing actual values

18

Linying Yang et al.

Fig. 11: AMC ICU projections, r = 7, 80% prediction intervals, with black dots representing actual values

Fig. 12: Projections on synthetic data, 90% prediction intervals, perfect model, with black dots representing
actual values

Title Suppressed Due to Excessive Length

19

Fig. 13: Projections on synthetic data, 90% prediction intervals, biased model, with black dots representing
actual values

Fig. 14: Projections on synthetic data, 90% prediction intervals, biased model, with black dots representing
actual values

20

Linying Yang et al.

Fig. 15: Projections on synthetic data, 80% prediction intervals, perfect model, with black dots representing
actual values
Model

Plug-in, ACU

Bootstrap, ACU

Plug-in, ICU

Bootstrap, ICU

Perfect Model
Unbiased Model
Biased Model

87%
97%
92%

88%
97%
93%

85%
88%
82%

87%
90%
85%

Table 6: Coverage rate of 80% prediction intervals, synthetic data

Title Suppressed Due to Excessive Length

21

Fig. 16: Projections on synthetic data, 80% prediction intervals, unbiased model, with black dots representing
actual values

22

Linying Yang et al.

Fig. 17: Projections on synthetic data, 80% prediction intervals, biased model, with black dots representing
actual values

