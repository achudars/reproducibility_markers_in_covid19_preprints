COVIDx-US - An Open-Access Benchmark Dataset of Ultrasound
Imaging Data for AI-Driven COVID-19 Analytics
Authors
Ashkan Ebadi1,*, Pengcheng Xi2, Alexander MacLean3, Stéphane Tremblay2, Sonny Kohli5, &
Alexander Wong3,4
Affiliations
1. National Research Council Canada, Montreal, QC H3T 1J4, Canada
2. National Research Council Canada, Ottawa, ON K1K 2E1, Canada
3. University of Waterloo, Department of Systems Design Engineering, Waterloo, ON N2L 3G1,
Canada
4. Waterloo Artificial Intelligence Institute, Waterloo, ON N2L 3G1, Canada
5. Oakville Trafalgar Memorial Hospital, McMaster University, ON, Canada
*
Corresponding author: Ashkan Ebadi (ashkan.ebadi@nrc-cnrc.gc.ca)

Abstract
The COVID-19 pandemic continues to have a devastating effect on the health and well-being
of the global population. Apart from the global health crises, the pandemic has also caused
significant economic and financial difficulties and socio-physiological implications. Effective
screening, triage, treatment planning, and prognostication of outcome plays a key role in
controlling the pandemic. Recent studies have highlighted the role of point-of-care ultrasound
imaging for COVID-19 screening and prognosis, particularly given that it is non-invasive,
globally available, and easy-to-sanitize. Motivated by these attributes and the promise of
artificial intelligence tools to aid clinicians, we introduce COVIDx-US, an open-access
benchmark dataset of COVID-19 related ultrasound imaging data. The COVIDx-US dataset was
curated from multiple sources and its current version, i.e., v1.2., consists of 150 lung
ultrasound videos and 12,943 processed images of patients infected with COVID-19 infection,
non-COVID-19 infection, other lung diseases/conditions, as well as normal control cases. The
COVIDx-US is the largest open-access fully-curated dataset of its kind that has been
systematically curated, processed, and validated specifically for the purpose of building and
evaluating artificial intelligence algorithms and models.

Background & Summary
The novel Coronavirus Disease 2019 (COVID-19), which appeared first in December 2019 and
was caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), led to a
pandemic of severe and deadly respiratory illness, affecting human lives and well-being. The
SARS-CoV-2 virus, now observed in different variants, can emerge in various forms and levels
of severity, ranging from asymptomatic infection to an acute illness with organ failure risk and
death1. Ebadi and colleagues2 investigated the temporal evolution of COVID-19 related
research themes and confirmed dynamic changes in the response of the scientific community
to the disease evolution. The rapid growth of confirmed cases over several waves of a
pandemic highlights the importance of effective screening and risk stratification of infected
patients as a means to minimize spread and identify those that need a higher level of care3.
The reliable and effective identification of infected patients with a low rate of false negatives
contributes to controlling the disease transmission rate and mitigating the spread of the virus.
A low false-positive rate is also desirable to not quarantine and treat people unnecessarily,
removing burdens from the healthcare system as well as the society4.
The reverse transcription-polymerase chain reaction (RT-PCR) test, performed on biological
samples taken from the patient, is the main screening method used for COVID-19 detection5.
1

Although RT-PCR is used in many countries, it requires a long complicated manual processing3,4
that is a huge disadvantage for an effective fight against the pandemic. Moreover, there is no
consensus about the sensitivity of RT-PCR testing, with highly variable rates reported in the
literature6–8. These obstacles are compounded by a lack of necessary equipment and expertise
to perform this test in many countries, an issue that also leads to improper management of
infected patients9. Finally, RT-PCR tests do not provide additional information that supports
clinical decision-making with respect to the triage of infected patients, treatment options, and
predictions of patient outcomes that may assist in resource allocation. Therefore, finding
complementary solutions for COVID-19 screening and alternative solutions for risk
stratification and treatment planning has attracted the attention of the scientific community.
Radiography is an alternative imaging method utilized for COVID-19 screening and risk
stratification. This modality entails an acute care physician and a radiologist visually inspecting
radiographic images, e.g., chest X-ray (CXR) or computed tomography (CT) scans, to find
indicators that are associated with SARS-CoV-2 viral infection, and that may assess the severity
of infection. Biomedical imaging can accelerate diagnostic and prognostic decision-making
processes by facilitating rapid assessment of patient condition and severity, as well as guiding
the ordering of subsequent tests, if necessary10. It was reported in recent studies that patients
infected with COVID-19 present abnormalities in their chest radiography images11,12.
Additionally, some studies observed a higher sensitivity of CT scans for COVID-19 detection in
their examined cohort compared to RT-PCR7,13.
Although radiography examination is confirmed as a potential complementary method for
conventional diagnostic techniques such as RT-PCR10, some studies even suggest that it could
be used as a primary COVID-19 screening tool in epidemic areas13. To this end, CT imaging is
known to provide greater image detail and is considered as the gold standard for pneumonia
detection14. It has also been shown to be effective for screening7,13,15. However, CXR imaging
remains the first-line examination10, especially in resource-limited and heavily-infected areas,
mainly due to its lower cost, high availability, accessibility, and potential for rapid triaging of
patients suspected of the infection3. Furthermore, CXR imaging has been demonstrated to be
effective for both screening3 and risk stratification16.
As an established method for monitoring and detecting pneumonia17, lung point-of-care
ultrasound (POCUS) is an emerging imaging modality that is receiving growing attention from
the scientific community in recent years18. Due to its many desirable properties, i.e., high
portability, non-ionizing radiation nature, and being used as the preferred lung infection
diagnosis and prognosis method in resource-limited settings/environments, e.g., in
emergency rooms or developing countries19, POCUS is showing considerable promise as an
alternative imaging solution to CXR as the first-line screening approach20,21, and tool that aids
in prognostication22.
Unfortunately, the literature on the applicability of POCUS for COVID-19 screening and
prognosis assessment remains scarce. However, it is suggested that lung ultrasound (LUS) can
play a key role in the context of the COVID-19 epidemic10,23. Changes in lung structure, such as
pleural and interstitial thickening, are identifiable on LUS and help to detect viral pulmonary
infection in the early stages24. For COVID-19 screening, recent studies reported identifiable
lesions in the bilateral lower lobes and abnormalities in bilateral B-lines on LUS as the main
attributes of the disease25,26. The LUS findings in other diseases, e.g., flu virus pneumonia,
together with current clinical evidence, suggest that the LUS patterns of COVID-19 patients
are quite characteristic, and LUS has a high potential for evaluating early lung-infected patients
in various settings, including at home, patient triage, the intensive care unit, and for

2

monitoring treatment effects23. Furthermore, studies have also found POCUS to be applicable
for predicting mortality and whether a patient is in need of intensive care admission22.
Artificial-intelligence (AI) powered decision support systems, mostly based on deep neural
network architectures, have shown exemplary performance in many computer vision
problems in healthcare27,28. By extracting complex hidden patterns in healthcare images, deep
learning (DL) techniques may find relationships/patterns that are not instantly available to
human analysis29. Compared to CXR and CT, lung ultrasound deep learning studies are
comparably limited due to the lack of well-established, organized, carefully labelled LUS data
sets30. Motivated by recent open-source efforts of the research community in the fight against
COVID-19 and to support alternative screening, risk stratification, and treatment planning
solutions powered by AI and advanced analytics, we introduce COVIDx-US, an open-access
benchmark dataset of ultrasound imaging data that was carefully curated from multiple
sources and integrated systematically specifically for facilitating the building and evaluation of
AI-driven analytics algorithms and models. Another publicly available LUS dataset comprising
of 200+ videos and ~60 images (as of April 2021 on their GitHub repository) built for COVID19 detection is the work of Born and his colleagues10. As one of the main contributions of our
work, in COVIDx-US we offer a systematic framework for data curation, data processing, and
data validation to dataset creation for creating a unified, standardized POCUS dataset. We also
tried our best to design our systematic framework to be very easy-to-use and easy-to-scale,
even for users without deep computer science/programming knowledge. The current version
of the COVIDx-US dataset comprises 150 videos and 12,943 processed ultrasound images of
patients diagnosed with COVID-19 infection, non-COVID-19 infection, other lung
diseases/conditions, as well as normal control patients. The COVIDx-US dataset was released
as part of a large open-source initiative, the COVID-Net initiative15,16,31, and will be
continuously growing, as more data sources become available. To the best of the authors’
knowledge, COVIDx-US is the first and largest open-access fully-curated benchmark LUS
imaging dataset that is reproducible, easy-to-use, and easy-to-scale thanks to the modular
well-documented design.

Methods
The COVIDx-US dataset continues to grow as new POCUS imaging data is continuously curated
and added as part of the broader initiative. All versions of the dataset will be made publicly
available. Although this study represents the current snapshot of the dataset in terms of
coverage, all the steps, including the data collection and processing pipeline that are
introduced in this section in detail, will remain similar in the upcoming versions. Fig. 1 shows
the flow of processes and the steps taken to generate the COVIDx-US dataset.

3

Fig. 1 The conceptual flow of COVIDx-US data set integration. The current version of COVIDxUS contains 150 ultrasound videos and 12,943 processed ultrasound images from the
following four data sources: 1) Butterfly Network, 2) GrepMed, 2) The POCUS Atlas, and 4)
LITFL. Original ultrasound videos are extracted from these data sources and are curated and
integrated systematically in a unified and organized structure.

Data Sources
The COVIDx-US dataset is heterogeneous in nature, containing ultrasound imaging data of
various characteristics, e.g., convex and linear US probes, from multiple sources. The current
version, i.e. COVIDx-US v1.2., curates ultrasound video data of four categories, i.e., COVID-19
infection, non-COVID-19 infection (e.g., bacterial infection, non-SARS-CoV-2 viral infection,
etc.), other lung diseases/conditions, and normal control, from four different sources: 1) The
POCUS Atlas (TPA), 2) GrepMed (GM), 3) Butterfly Network (BN), and 4) Life in the Fast Lane
(LITFL). The POCUS Atlas is a collaborative education platform for sharing ultrasound
education. GrepMed is an open-access medical image and video repository. Butterfly Network
is a health-tech company that developed a technology to miniaturize ultrasounds and
launched a portable ultrasound device. LITFL is a repository of emergency and critical care
education materials. Users are also provided with metadata to define their analytics problems
as binary (COVID vs non-COVID), 3-class (COVID, non-COVID, normal), and 4-class classification
problems. Table 1 shows the distribution of the LUS video files per data source in the current
version of the dataset, i.e. COVIDx-US v1.2. The COVID-19 US video files account for 39% of
the data, although the pandemic is recent.
Table 1 Distribution of the collected ultrasound video files per source and class in COVIDx-US
v1.2.
Data
source

Website

TPA
GM
BN
LITFL

www.thepocusatlas.com
www.grepmed.com
www.butterflynetwork.com
www.litfl.com
Total

COVID-19
18
8
33
0
59

Categories
NonNormal
COVID-19
9
5
9
3
0
2
19
3
37
13

Total
Other
0
0
0
41
41

32
20
35
63
150

4

Fig. 2 shows sample ultrasound frames captured from the ultrasound video recordings in the
COVIDx-US dataset. The examples are processed by the COVIDx-US scripts. These few
examples illustrate the diversity of ultrasound imaging data in the dataset. The choice of the
four different data sources and the heterogeneity in the structure and format of their hosted
videos resulted in a highly diverse set of videos and images in the COVIDx-US dataset that is
key to the generalizability of the AI-driven solutions that are built on the COVIDx-US dataset.
We will continuously grow the dataset by adding more data points and/or data sources.
a)

b)

c)

d)

e)

f)

Fig. 2 Sample ultrasound frames captured from the curated ultrasound video recordings in the
COVIDx-US dataset which comprises 150 ultrasound videos, collected and curated
systematically from four different data sources, and ~13,000 carefully curated ultrasound
images in the current version.

Data Curation
The data were curated from four data sources, each with a different structure. To support
reproducibility and ease of use, we developed data curation engines, personalized for each of
the target data sources, to automatically curate lung POCUS video recordings as well as
associated metadata from the target data sources and to integrate them locally in a unified,
organized structure. No original data is hosted in the COVIDx-US repository and the data is
rather curated and integrated locally via our publicly released COVIDx-US scripts and the
parameters set by the user. The metadata provides information on the video files, e.g.,
dimension and framerate, along with their category, i.e., COVID-19, non-COVID-19, other lung
diseases/conditions, or normal control. The scripts are designed to be highly extensible such
that more data sources can be added to the pipeline, supporting the scalability of the dataset.
The scripts are made available to the general public as part of each release of the dataset.

Data Cropping
The curated data contains video recordings captured with linear and convex US probes (N=38
and 112, respectively) that are the most common probes used in medical settings. This
provides users with higher flexibility to filter in the video files based on the probe types, if
required. It also enables higher generalizability of the models that are trained on the COVIDx5

US dataset by covering data of different types. Fig. 3 shows examples of linear and convex US
images, i.e. single snapshots of the respective video recordings. The linear probe has a flat
array and appearance and provides images of higher resolution but with less tissue
penetration. Convex probes, also called curved linear probes, provide a deeper and a wider
view and are mostly used for abdominal scans32. The original data, collected from multiple
sources, contains artifacts, such as measure bars, symbols, or text (Fig. 3-a). We initially
processed the collected videos and cropped them to remove these peripheral artifacts.
b)

a)

Fig. 3 Sample frame of an ultrasound video captured with a) a convex, and b) a linear probe.
To do data cropping, we treated convex and linear US video files separately. For the convex
and linear US video files, we used square and rectangular windows to crop the frames,
respectively. We used rectangular windows for linear US video files to include a larger portion
of the original file in the processed video file. Publicly available processing scripts that we
release as part of COVIDx-US to automatically perform data cropping on the benchmark
dataset. The parameters of the square and rectangular windows can be modified by the enduser, if desired. However, using the default parameters for the defined windows will remove
artifacts such as bars and texts visible on the side or top of the collected US video files. The
output of this step is a video file containing frames that were processed using the abovementioned cropping process, along with a metadata file that includes information about the
video file properties such as dimension and framerate, as well as the type of artifacts observed,
e.g., static symbols or moving pointers. The cropped files are stored locally by the provided
processing scripts.

Ultrasound Image Extraction
As mentioned in the previous sections, the videos were curated from multiple data sources,
hence, their properties differ. To ensure maximum flexibility of the COVIDx-US dataset and as
part of each release, we provide end users with highly flexible data processing scripts, allowing
them to extract frames from the initially processed video files based on their research
objectives and requirements, using a set of parameters as follows:





The maximum number of frames to extract from each video.
Extract frames from either all classes or a subset of classes from the set of [‘COVID19’, ‘Non-COVID-19’, ‘Other’, ‘Normal’].
Extract frames from either all data sources, i.e. [‘BN, ‘GM, ‘LITFL’, ‘TPA’] or a subset of
them.
Extract frames from all videos or those captured with a specific probe, i.e. convex or
linear.

We set the default parameters to extract all frames from all videos. Using the defined
parameters, the frames are extracted from the videos and are stored locally.

6

Data Processing
After extracting frames from the videos and using the metadata file from the data cropping
stage, the frames are further processed as follows:
1. Videos with moving pointers are identified.
2. If the video contains a moving pointer:
a. Delete frames with a moving pointer on the lung region.
b. For the remaining frames, generate and store a frame-specific mask.
3. If the video does not contain a moving pointer:
a. Make a generic mask (suitable for all the extracted frames) and store it.
4. Use the generated masks to process the frames, removing the remaining artifacts.
The generated masks are provided as part of the COVIDx-US release. Using the generated
masks, we leveraged the inpainting technique introduced by Bertalmio and colleagues33 to
remove the remaining peripheral artifacts from the frames by replacing bad marks, i.e. pixels
in the masked regions, with their neighboring pixels. The clean frames as well as the clean
video file, generated by appending the clean frames, are stored locally on the user’s device.
Fig. 4 shows an example of a US frame, the mask generated for this specific frame, and the
final clean frame obtained by applying the mask to the original frame.
a)

b)

c)

Fig. 4 a) A sample frame with a blue symbol on the top-left of the image, b) the mask generated
for the frame, and c) the clean frame resulted from applying the generated mask to the original
frame.

Data Records
The COVIDx-US benchmark dataset is available to the general public at
https://github.com/nrc-cnrc/COVID-US. The repository also includes the generated masks and
metadata. The current version of the data set contains 150 processed and clean ultrasound
videos, divided into 59 videos of COVID-19 infected patients, 37 videos of non-COVID-19
infected patients, 41 videos of patients with other lung diseases/conditions, and 13 videos of
normal patients, along with 12,943 ultrasound images extracted from the clean video files,
divided into 7,170 images of COVID-19, 3,159 images of non-COVID-19, 1,636 images of
patients with other diseases/conditions, and 978 images of normal patients, using default
parameters. As mentioned in the ultrasound image extraction section, users can extract
frames from the US videos according to their projects’ objectives and requirements, using the
codes provided and by setting their own parameters. This makes the COVIDx-US data set highly
flexible for various research objectives. Meanwhile, the modular design of the scripts allows
adding/removing data sources, if required.
Running the scripts provided in COVIDx-US will extract original videos from BN, GM, TPA, and
LITFL and will store them locally on the user’s device in the ‘/data/video/original’ folder. The
cropped videos are stored locally in the ‘/data/video/cropped’ folder, the clean videos in the
7

‘/data/video/clean’ folder, and the clean images in the ‘/data/image/clean’ folder. Table 2 lists
video files included in COVIDx-US v1.2., and presents their properties and the number of
frames extracted using the default parameters. Complementary information about the file
properties can be found in the metadata files located in the ‘/utils’ folder in the COVIDx-US
GitHub repository. Users may refer to the data dictionary file located in the ‘/utils’ folder for
detailed information/description of all the metadata files. The original video files extracted
from the four above-mentioned data sources are named such that the filename contains
information on the source and class of the video file. This naming convention was respected
for all the other generated data such as clean videos and images.
Table 2 Ultrasound video files included in the COVIDx-US v1.2. data set.
No

Original filename

File
type

Src

Prb

Class

Original
dimension

Final
dimension

#Fr

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46

1_butterfly_covid
2_butterfly_covid
3_butterfly_covid
4_butterfly_covid
5_butterfly_covid
6_butterfly_covid
7_butterfly_covid
8_butterfly_covid
9_butterfly_covid
10_butterfly_covid
11_butterfly_covid
12_butterfly_covid
13_butterfly_covid
14_butterfly_covid
15_butterfly_covid
16_butterfly_covid
17_butterfly_covid
18_butterfly_covid
19_butterfly_covid
20_butterfly_normal
21_butterfly_normal
23_grepmed_pneumonia
24_grepmed_covid
25_grepmed_pneumonia
26_grepmed_covid
27_grepmed_pneumonia
28_grepmed_normal
29_grepmed_covid
30_grepmed_covid
31_grepmed_covid
32_grepmed_pneumonia
33_grepmed_covid
34_grepmed_pneumonia
35_grepmed_covid
36_grepmed_normal
37_grepmed_pneumonia
38_grepmed_pneumonia
39_grepmed_normal
40_grepmed_pneumonia
41_grepmed_pneumonia
42_grepmed_covid
43_litfl_pneumonia
44_litfl_pneumonia
45_litfl_pneumonia
46_litfl_pneumonia
47_litfl_pneumonia

Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4

BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
GM
LITFL
LITFL
LITFL
LITFL
LITFL

Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Lin
Con
Con
Con
Con
Lin
Lin
Con
Con
Lin
Lin
Con
Con
Con
Con
Con
Lin
Con
Con
Con
Con
Con
Con
Con
Lin

COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
Normal
Normal
Non-COVID-19
COVID-19
Non-COVID-19
COVID-19
Non-COVID-19
Normal
COVID-19
COVID-19
COVID-19
Non-COVID-19
COVID-19
Non-COVID-19
COVID-19
Normal
Non-COVID-19
Non-COVID-19
Normal
Non-COVID-19
Non-COVID-19
COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19

880 * 1080
720 * 1236
1928 * 1080
880 * 1080
860 * 1080
720 * 1236
880 * 1080
880 * 1080
1928 * 1080
736 * 1080
624 * 1080
880 * 1080
880 * 1080
880 * 1080
1928 * 1080
720 * 1236
1928 * 1080
880 * 1080
880 * 1080
720 * 1236
880 * 1080
816 * 540
960 * 720
1280 * 720
720 * 720
480 * 360
302 * 336
600 * 436
800 * 652
720 * 1076
816 * 540
960 * 720
800 * 600
720 * 720
720 * 540
962 * 720
800 * 600
1280 * 720
500 * 354
600 * 406
640 * 480
720 * 540
720 * 540
720 * 540
720 * 540
720 * 540

820 * 820
624 * 624
1055 * 1055
820 * 820
810 * 810
642 * 642
820 * 820
820 * 820
1055 * 1055
640 * 640
544 * 544
820 * 820
820 * 820
820 * 820
1055 * 1055
634 * 634
1055 * 1055
820 * 820
820 * 820
594 * 594
820 * 820
408 * 408
500 * 500
665 * 665
382 * 382
345 * 345
302 * 302
315 * 410
625 * 465
608 * 608
300 * 410
435 * 500
550 * 550
595 * 595
540 * 540
653 * 653
540 * 540
600 * 685
354 * 354
386 * 386
435 * 435
540 * 540
540 * 540
540 * 540
540 * 540
465 * 540

64
158
90
108
249
169
125
109
80
147
114
111
91
103
87
202
76
101
81
142
99
252
225
300
70
91
39
75
69
365
302
116
458
361
85
187
300
157
114
151
159
115
18
21
16
18

8

47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107

48_litfl_pneumonia
49_pocusatlas_covid
50_pocusatlas_covid
51_pocusatlas_covid
52_pocusatlas_covid
53_pocusatlas_covid
54_pocusatlas_covid
55_pocusatlas_covid
56_pocusatlas_covid
57_pocusatlas_covid
58_pocusatlas_covid
59_pocusatlas_covid
60_pocusatlas_covid
61_pocusatlas_covid
62_pocusatlas_normal
63_pocusatlas_covid
64_pocusatlas_pneumonia
65_pocusatlas_pneumonia
66_pocusatlas_covid
67_pocusatlas_covid
68_pocusatlas_pneumonia
69_pocusatlas_pneumonia
70_pocusatlas_pneumonia
71_pocusatlas_normal
72_pocusatlas_pneumonia
73_pocusatlas_covid
74_pocusatlas_covid
75_pocusatlas_pneumonia
76_pocusatlas_normal
77_pocusatlas_normal
78_pocusatlas_normal
79_pocusatlas_pneumonia
80_pocusatlas_pneumonia
81_butterfly_covid
82_butterfly_covid
83_butterfly_covid
84_butterfly_covid
85_butterfly_covid
86_butterfly_covid
87_butterfly_covid
88_butterfly_covid
89_butterfly_covid
90_butterfly_covid
91_butterfly_covid
92_butterfly_covid
93_butterfly_covid
94_butterfly_covid
95_litfl_other
96_litfl_other
97_litfl_other
98_litfl_other
99_litfl_other
100_litfl_other
101_litfl_other
102_litfl_other
103_litfl_other
104_litfl_other
105_litfl_other
106_litfl_other
107_litfl_other
108_litfl_other

Mp4
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Gif
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4

LITFL
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
TPA
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
BN
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL

Con
Con
Con
Con
Con
Con
Con
Lin
Con
Lin
Con
Lin
Con
Con
Con
Lin
Con
Lin
Con
Lin
Con
Con
Con
Con
Con
Con
Con
Lin
Con
Con
Lin
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Lin
Lin
Con
Con
Lin
Con
Con
Con
Lin
Lin
Con
Lin
Con
Con

Non-COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
Normal
COVID-19
Non-COVID-19
Non-COVID-19
COVID-19
COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Normal
Non-COVID-19
COVID-19
COVID-19
Non-COVID-19
Normal
Normal
Normal
Non-COVID-19
Non-COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
COVID-19
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other

720 * 540
600 * 600
600 * 600
600 * 1025
600 * 1025
598 * 430
590 * 423
600 * 436
600 * 410
493 * 368
600 * 450
240 * 320
600 * 384
600 * 492
492 * 376
440 * 312
394 * 394
600 * 410
309 * 299
299 * 303
282 * 290
600 * 450
324 * 249
600 * 450
632 * 414
439 * 595
463 * 480
600 *409
600 * 338
237 * 293
480 * 480
442 * 309
198 * 197
760 * 1080
760 * 1080
632 * 1080
624 * 1080
736 * 1080
760 * 1080
736 * 1080
760 * 1080
736 * 1080
760 * 1080
736 * 1080
736 * 1080
736 * 1080
760 * 1080
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360

540 * 540
282 * 282
282 * 282
528 * 528
528 * 528
400 * 320
420 * 415
315 * 410
410 * 410
265 * 300
450 * 450
140 * 290
384 * 384
472 * 472
376 * 376
318 * 310
348 * 348
245 * 370
299 * 299
299 * 299
282 * 282
440 * 382
249 * 249
450 * 450
414 * 414
407 * 407
463 * 463
285 * 350
338 * 338
237 * 237
260 * 460
309 * 309
197 * 197
656 * 656
656 * 656
558 * 558
544 * 544
622 * 622
656 * 656
640 * 640
658 * 658
640 * 640
656 * 656
640 * 640
642 * 642
642 * 642
658 * 658
360 * 310
360 * 360
360 * 360
360 * 360
335 * 472
360 * 360
360 * 360
360 * 360
335 * 462
340 * 463
360 * 360
360 * 380
360 * 360
360 * 360

14
76
83
40
40
41
39
75
30
32
30
30
30
21
60
137
59
60
41
183
30
40
30
59
36
46
46
61
60
60
109
31
30
243
52
76
114
155
287
177
107
179
145
402
113
109
300
45
42
29
149
46
46
28
28
46
46
43
39
43
43

9

108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150

109_litfl_other
110_litfl_other
111_litfl_other
112_litfl_other
113_litfl_other
114_litfl_other
115_litfl_other
116_litfl_other
117_litfl_other
118_litfl_other
119_litfl_other
120_litfl_other
121_litfl_pneumonia
122_litfl_pneumonia
123_litfl_pneumonia
124_litfl_pneumonia
125_litfl_pneumonia
126_litfl_pneumonia
127_litfl_pneumonia
128_litfl_pneumonia
129_litfl_pneumonia
130_litfl_pneumonia
131_litfl_pneumonia
132_litfl_pneumonia
133_litfl_other
134_litfl_other
135_litfl_normal
136_litfl_other
137_litfl_other
138_litfl_normal
139_litfl_normal
140_litfl_other
141_litfl_other
142_litfl_other
143_litfl_other
144_litfl_other
145_litfl_other
146_litfl_other
147_litfl_other
148_litfl_other
149_litfl_other
150_litfl_other
151_litfl_pneumonia

Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4
Mp4

LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL
LITFL

Lin
Lin
Con
Lin
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Con
Lin
Lin
Lin
Con
Con
Con
Con
Con
Con
Lin
Lin
Lin
Lin
Lin
Lin
Lin
Lin
Con
Lin
Lin
Lin
Con
Con
Con
Con
Con
Con
Con

Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Non-COVID-19
Other
Other
Normal
Other
Other
Normal
Normal
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Other
Non-COVID-19

480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 384
480 * 384
480 * 384
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360
480 * 360

360 * 480
31
350 * 468
29
360 * 360
33
355 * 470
37
360 * 360
45
360 * 360
46
360 * 360
28
360 * 360
28
360 * 360
39
360 * 360
28
360 * 360
28
360 * 360
28
360 * 360
27
360 * 360
42
360 * 360
36
355 * 420
36
360 * 460
36
360 * 460
31
360 * 360
24
360 * 360
32
360 * 360
25
360 * 360
41
360 * 360
26
360 * 360
27
360 * 410
46
355 * 400
46
360 * 410
36
360 * 410
36
330 * 470
46
360 * 460
46
384 * 430
26
365 * 428
27
384 * 384
46
340 * 430
34
360 * 405
38
360 * 405
46
360 * 360
45
360 * 360
45
360 * 360
36
360 * 360
26
360 * 360
18
360 * 360
28
360 * 360
42
Total 12943

Note: Src: Data source, Prb: probe type, #Fr: Number of frames.

Technical Validation
The COVIDx-US is curated from four data sources and contains data of different types and
characteristics. The scripts provided will perform the processes necessary to clean the
collected POCUS videos, extract frames, and store them locally on the user’s device. But, they
do not validate the analyses performed and published by the research community using
COVIDx-US data. As COVIDx-US will be continuously growing, feedbacks provided by
researchers will provide information that may be used in the next versions of COVIDx-US to
perform additional processes/reviews. Such feedbacks may be addressed to
ashkan.ebadi@nrc-cnrc.gc.ca.
In order to validate the quality of images in the COVIDx-US dataset and ensure the existence
of markers in the processed ultrasound images, our contributing clinician (S.K.) reviewed a
10

randomly selected set of images and reported his findings and observations. Our contributing
clinician is a practicing Internal Medicine and ICU (Intensive Care specialist), certified in both
specialties by the Royal College of Physicians of Canada. Fig. 5 shows three select images of
COVID-19 positive cases, as examples, that were reviewed. The summary of our expert
clinician’s report is as follows.
a)

b)

c)

Fig. 5 Sample processed ultrasound images of COVID-19 positive cases, reviewed and reported
on by our contributing clinician.
Case 1 (Fig. 5-a). Our contributing clinician observed multiple pleural irregularities, including
pleural thickening and the presence of sub-pleural consolidations which have been previously
described as markers of COVID-19 disease severity34. These findings, together with the
observed C-line profile, are indicative of a moderate to severe pulmonary disease.
Case 2 (Fig. 5-b). This is an image of lung pleura in short depth. Our clinical expert observed
abnormalities and irregularities in the pleura as it is thickened and “shredded” with
hypoechoic signals suggesting consolidations and air bronchograms. Although a deeper view
to assess for B-lines would be more optimal, these findings together suggest moderate
airspace disease, most commonly on the basis pneumonia.
Case 3 (Fig. 5-c). This appears to be an image of lung pleura at depth of ~5±2cm. According to
our contributing clinician, the pleura and underlying lung are abnormal. There is the presence
of a “waterfall sign”, i.e., subpleural consolidation with a B-line. The pleura is thickened and
irregular. Despite the observed abnormalities, more imaging data is needed to inform on
differential diagnosis. In addition, it is not possible to comment on lung sliding as this is a static
image.
Our expert clinician findings and observations confirmed the existence of identifiers and
indicators of disease in the COVIDx-US dataset. AI-powered analytics solutions can exploit such
indicators and patterns to detect COVID-19. Based on our contributing clinician’s evolving
experience, LUS has significant utility in the management of COVID-19 patients with
respiratory symptoms. As a safe, rapid, reproducible, low-cost, and highly informative tool for
assessing the severity of lung involvement, early studies suggest that it can be used to inform
triage and treatment decisions35. To this end, several published LUS-based protocols are now
undergoing validation in prospective clinical trials36,37. Furthermore, several groups are now
evaluating the potential utility of LUS in other settings, including the Intensive Care Unit (ICU)
where it could be used to track disease progression, and to evaluate patient candidacy and
clinical response to various interventions including ventilator weaning, prone positioning and
lung recruitment maneuvers in patients with acute respiratory distress syndrome (ARDS)38.

11

Known limitations of this modality include the observation that LUS findings are not
necessarily specific to COVID-19. Moreover, they have yet to be proven as reliable markers of
clinical outcome in appropriately sized clinical studies. The deployment of LUS in COVID-19
also requires strict infection control measures. Lastly, LUS requires significant operator
training and experience before it can be used in the management of potentially unstable
patients, or in those with suspected infectious syndromes.’ AI-driven solutions can aid
clinicians with the screening process of COVID-19 patients, reducing the pressure on
healthcare systems and healthcare providers.

Usage Notes
We are constantly searching for more data, therefore, the COVIDx-US will be growing over
time as more data sources become available. We recommend that users check the COVIDx-US
repository at https://github.com/nrc-cnrc/COVID-US, for the latest version of data and scripts.
The data collection and processing pipeline is coded in Python (version 3.6.12). Users are
provided with a Python notebook including all the steps required to collect, process, and
integrate data, as described in the manuscript. The provided scripts are well-documented
allowing users to modify parameters for frame extraction from ultrasound videos, based on
their research objectives and requirements, if required.

Code Availability
All the codes and materials, e.g. metadata and masks, necessary to reproduce the COVIDx-US
data set, as described and explained in this manuscript, are available to the general public at
https://github.com/nrc-cnrc/COVID-US, accessible with no restrictions. The scripts were in
Python programming language (version 3.6.12), using pandas 1.1.3, selenium 3.141.0, and
requests 2.24.0 libraries.

Acknowledgements
The authors would like to offer their special thanks to Mr. Patrick Paul for his help and support
during this project.

References
1. Jamshidi, M. et al. Artificial Intelligence and COVID-19: Deep Learning Approaches for
Diagnosis and Treatment. IEEE Access 8, 109581–109595 (2020).
2. Ebadi, A. et al. Understanding the temporal evolution of COVID-19 research through
machine learning and natural language processing. Scientometrics 126, 725–739 (2021).
3. Wang, L., Lin, Z. Q. & Wong, A. COVID-Net: a tailored deep convolutional neural network
design for detection of COVID-19 cases from chest X-ray images. Scientific Reports 10,
19549 (2020).
4. Brunese, L., Mercaldo, F., Reginelli, A. & Santone, A. Explainable Deep Learning for
Pulmonary Disease and Coronavirus COVID-19 Detection from X-rays. Computer Methods
and Programs in Biomedicine 196, 105608 (2020).
5. Wang, W. et al. Detection of SARS-CoV-2 in Different Types of Clinical Specimens. JAMA
323, 1843–1844 (2020).
6. West, C. P., Montori, V. M. & Sampathkumar, P. COVID-19 Testing: The Threat of FalseNegative Results. Mayo Clin Proc 95, 1127–1129 (2020).
7. Fang, Y. et al. Sensitivity of Chest CT for COVID-19: Comparison to RT-PCR. Radiology 296,
E115–E117 (2020).
8. Wikramaratna, P. S., Paton, R. S., Ghafari, M. & Lourenço, J. Estimating the false-negative
test probability of SARS-CoV-2 by RT-PCR. medRxiv 2020.04.05.20053355 (2020)
doi:10.1101/2020.04.05.20053355.
9. Li, Z. et al. Development and clinical application of a rapid IgM-IgG combined antibody
test for SARS-CoV-2 infection diagnosis. Journal of Medical Virology 92, 1518–1524 (2020).
12

10. Born, J. et al. POCOVID-Net: Automatic Detection of COVID-19 From a New Lung
Ultrasound Imaging Dataset (POCUS). arXiv:2004.12084 [cs, eess] (2020).
11. Ng, M.-Y. et al. Imaging Profile of the COVID-19 Infection: Radiologic Findings and
Literature Review. Radiology: Cardiothoracic Imaging 2, e200034 (2020).
12. Guan, W. et al. Clinical Characteristics of Coronavirus Disease 2019 in China. New England
Journal of Medicine 382, 1708–1720 (2020).
13. Ai, T. et al. Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease
2019 (COVID-19) in China: A Report of 1014 Cases. Radiology 296, E32–E40 (2020).
14. Bourcier, J.-E. et al. Performance comparison of lung ultrasound and chest x-ray for the
diagnosis of pneumonia in the ED. The American Journal of Emergency Medicine 32, 115–
118 (2014).
15. Gunraj, H., Wang, L. & Wong, A. COVIDNet-CT: A Tailored Deep Convolutional Neural
Network Design for Detection of COVID-19 Cases From Chest CT Images. Front Med
(Lausanne) 7, (2020).
16. Wong, A. et al. COVIDNet-S: Towards computer-aided severity assessment via training and
validation of deep neural networks for geographic extent and opacity extent scoring of
chest X-rays for SARS-CoV-2 lung disease severity. arXiv:2005.12855 [cs, eess] (2020).
17. Pagano, A. et al. Lung ultrasound for diagnosis of pneumonia in emergency department.
Intern Emerg Med 10, 851–854 (2015).
18. Gehmacher, O., Mathis, G., Kopf, A. & Scheier, M. Ultrasound imaging of pneumonia.
Ultrasound in Medicine & Biology 21, 1119–1122 (1995).
19. Amatya, Y. et al. Diagnostic use of lung ultrasound compared to chest radiograph for
suspected pneumonia in a resource-limited setting. International Journal of Emergency
Medicine 11, 8 (2018).
20. Gazon, M. et al. Agreement between lung ultrasonography and chest radiography in the
intensive care unit. Ann Fr Anesth Reanim 30, 6–12 (2011).
21. Bourcier, J.-E., Braga, S. & Garnier, D. Lung Ultrasound Will Soon Replace Chest
Radiography in the Diagnosis of Acute Community-Acquired Pneumonia. Curr Infect Dis
Rep 18, 43 (2016).
22. Bonadia, N. et al. Lung Ultrasound Findings Are Associated with Mortality and Need for
Intensive Care Admission in COVID-19 Patients Evaluated in the Emergency Department.
Ultrasound in Medicine & Biology 46, 2927–2937 (2020).
23. Soldati, G. et al. Is There a Role for Lung Ultrasound During the COVID‐19 Pandemic? J
Ultrasound Med (2020) doi:10.1002/jum.15284.
24. Buonsenso, D., Pata, D. & Chiaretti, A. COVID-19 outbreak: less stethoscope, more
ultrasound. The Lancet Respiratory Medicine 8, e27 (2020).
25. Peng, Q.-Y., Wang, X.-T. & Zhang, L.-N. Findings of lung ultrasonography of novel corona
virus pneumonia during the 2019–2020 epidemic. Intensive Care Med 1–2 (2020)
doi:10.1007/s00134-020-05996-6.
26. Huang, Y. et al. A Preliminary Study on the Ultrasonic Manifestations of Peripulmonary
Lesions
of
Non-Critical
Novel
Coronavirus
Pneumonia
(COVID-19).
https://papers.ssrn.com/abstract=3544750 (2020) doi:10.2139/ssrn.3544750.
27. Brinker, T. J. et al. Deep learning outperformed 136 of 157 dermatologists in a head-tohead dermoscopic melanoma image classification task. European Journal of Cancer 113,
47–54 (2019).
28. Chilamkurthy, S. et al. Deep learning algorithms for detection of critical findings in head
CT scans: a retrospective study. The Lancet 392, 2388–2396 (2018).
29. Poplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs
via deep learning. Nature Biomedical Engineering 2, 158–164 (2018).
30. Arntfield, R. et al. Development of a deep learning classifier to accurately distinguish
COVID-19 from look-a-like pathology on lung ultrasound. medRxiv 2020.10.13.20212258
(2020) doi:10.1101/2020.10.13.20212258.
13

31. COVID-Net. COVID-Net open-source initiative. http://www.covid-net.ml/ (2020).
32. ProboMedical. What Probe Do I Need for My Ultrasound System?
https://www.probomedical.com/blog/what-probe-do-i-need-for-my-ultrasound-system/
(2019).
33. Bertalmio, M., Bertozzi, A. L. & Sapiro, G. Navier-stokes, fluid dynamics, and image and
video inpainting. in Proceedings of the 2001 IEEE Computer Society Conference on
Computer Vision and Pattern Recognition. CVPR 2001 vol. 1 I–I (2001).
34. Buda, N., Segura-Grau, E., Cylwik, J. & Wełnicki, M. Lung ultrasound in the diagnosis of
COVID-19 infection - A case series and review of the literature. Advances in Medical
Sciences 65, 378–385 (2020).
35. Brahier, T. et al. Lung ultrasonography for risk stratification in patients with COVID-19: a
prospective observational cohort study. Clinical Infectious Diseases (2020)
doi:10.1093/cid/ciaa1408.
36. Karagöz, A., Saglam, C., Demirbas, H. B., Korkut, S. & Ünlüer, E. E. Accuracy of Bedside
Lung Ultrasound as a Rapid Triage Tool for Suspected Covid-19 Cases. Ultrasound
Quarterly 36, 339–344 (2020).
37. Manivel, V., Lesnewski, A., Shamim, S., Carbonatto, G. & Govindan, T. CLUE: COVID-19
lung ultrasound in emergency department. Emerg Med Australas 32, 694–696 (2020).
38. Dargent, A. et al. Lung ultrasound score to monitor COVID-19 pneumonia progression in
patients with ARDS. PLoS One 15, (2020).

14

