arXiv:2010.12679v1 [stat.AP] 23 Oct 2020

N OWCASTING COVID-19 INCIDENCE INDICATORS DURING THE
I TALIAN FIRST OUTBREAK

Pierfrancesco Alaimo Di Loro

Fabio Divino

Alessio Farcomeni

Dpt. of Statistical Sciences

Dpt. of Bio-Sciences

Dpt. of Economics and Finance

University of Rome "La Sapienza"

University of Molise

University of Rome "Tor Vergata"

pierfrancesco.alaimodiloro@uniroma1.it

fabio.divino@unimol.it

alessio.farcomeni@uniroma2.it

Giovanna Jona Lasinio

Gianfranco Lovison

Dpt. of Statistical Sciences

Dpt. of Economics, Management and Statistical Sciences

Antonello Maruotti
Dpt. GEPLI

University of Rome "La Sapienza"

University of Palermo

Libera Università Maria Ss Assunta

giovanna.jonalasinio@uniroma1.it

Dpt. of Epidemiology and Public Health

Dpt. of Mathematics

Swiss TPH Basel

University of Bergen

gianfranco.lovison@unipa.it

a.maruotti@lumsa.it

Marco Mingione
Dpt. of Statistical Sciences
University of Rome "La Sapienza"
marco.mingione@uniroma1.it

October 27, 2020

A BSTRACT
A novel parametric regression model is proposed to fit incidence data typically collected during
epidemics. The proposal is motivated by real time monitoring and short-term forecasting of the
main epidemiological indicators within the first outbreak of COVID-19 in Italy. Accurate short-term
predictions, including the potential effect of exogenous or external variables are provided; this
ensures to accurately predict important characteristics of the epidemic (e.g., peak time and height),
allowing for a better allocation of health resources over time. Parameters estimation is carried out
in a maximum likelihood framework. All computational details required to reproduce the approach
and replicate the results are provided. COVID-19, Growth curves, Richards’ equation, SARS-CoV-2,
GLM

1

Introduction

Italy has been the first European country to be severely hit by the first epidemic wave due to the spread of the SARSCoV-2 virus. COVID-19 syndrome emerged in northern Italy in February 2020, with a basic reproduction number
R0 between 2.5 and 4 [1]. In its most severe form, COVID-19 has two challenging characteristics [2]: it is highly
infectious and, despite having a benign course in the vast majority of patients, it requires hospital admission and even
intensive care for about 10% of infected. During the outbreak, it was crucial to set up appropriate data collection and
modeling systems quickly. Both were necessary for monitoring infections evolution, evaluation of policy interventions,
and prediction.
Generally speaking, the nature of epidemics’ spread has nearly always followed the same scenario: first, the growth in
the number of infected people is (close to) exponential; in a second moment, this growth gradually but consistently slows
down. So far, in order to explain the spread of epidemics and predict their consequences, a number of mathematical
and statistical models of different complexity levels are used. The starting point is often the Verhulst logistic equation
[3], which can easily capture both the exponential increase in the number of infected people at the initial stage of the

A PREPRINT - O CTOBER 27, 2020

epidemic development and the tendency towards a constant value by its ending. In more complex models, people are
divided into different groups: (S) the susceptible class, namely those individuals who are capable of contracting the
disease and becoming infected; (I) the infected class, namely those individuals who are capable of transmitting the
disease to others; (R) the removed class, namely infected individuals who are deceased or have recovered, who are
either permanently immune or isolated. This group of mathematical models are called SIR (or compartmental) models
(e.g., [4]). References include [5; 6; 7; 8], and several more. However, whilst being potentially very appropriate to
model the true dynamics underlying any epidemic, the SIR-based models rely on accurate initial estimates of several
quantities governing its spreading mechanism (which are mostly unknown). As discussed in [9], poor data input on key
features of the pandemic can heavily bias these estimates, jeopardizing the reliability of any theory-based forecasting
effort. Indeed, such specifics lead the choice of coefficients in the equations defining the SIR model and define its
initial conditions. It is well known that even a slight change in those can lead to large differences in the final results.
For instance, at the beginning of the epidemic, early data providing estimates for case fatality rate, infection fatality
rate, basic reproductive number, and other key numbers that are essential for the modeling, are often inflated and may
cause potentially large over-estimation of the epidemic severity. Similar critiques to using compartmental modeling for
nowcasting can also be found in [10], and references therein.
We have thus preferred to follow an alternative approach, which involved direct modeling of the observed counts
(e.g., [11]). We propose a parametric regression model for the modeling of incidence indicators (defined in Sec. 2.1)
based on the use of the Richard’s curve (a generalized logistic function) as response function in place of the widely
used exponential or polynomial trend. Furthermore, we replace the generally entrenched Gaussian assumption for the
distribution of log-counts [12; 13] by the more appropriate Poisson or Negative Binomial distributions for counts. In
this way, we avoid the implausible assumptions stemming from the more common alternatives: the former allows the
underlying counts to potentially grow indefinitely; the latter neglects the proper specification of dependence between
mean and variance under the log-normal distribution. We further propose different ways of including exogenous
information as a linear effect on the response function of counts in a very general generalized linear model framework.
These models have been implemented during the outbreak with the aim of modeling the medium to long term evolution
of the epidemic wave.
The use of logistic-based curves is also widely discussed in the literature [14; 15; 16]. Logistic growth curves can be
seen as a flexible formulation for approximating a large variety of growth phenomena, especially in biology and in
epidemiology [17; 18; 19; 20; 21]. In particular, highly flexible parametric models such as Gompertz curves and the
unified-Richards family [22] have been proposed in the study of organisms’ growth, for a review see [23].
The paper is organized as follows: Section 2 gives a detailed description of the Italian situation and provides a brief
account of the Italian public data made available daily, with some remarks on limitations and flaws in the data collection
process; Section 3 contains a description of our approach to modeling incidence indicators, including remarks on how
to obtain standard errors for parameters and predictions; Section 4 illustrates results of our approach applied to the
incidence indicators recorded during first wave of the Italian outbreak of COVID-19. In particular, Sections 4.3 and 4.4
include the evaluation of the (out-of-sample) now-casting accuracy both in terms of future counts predictions and the
anticipated forecast of the day of the peak. Finally, results are discussed and commented along with some concluding
remarks in Section 5.
The methods discussed in this paper have also been implemented in a Shiny app, publicly available at https:
//statgroup19.shinyapps.io/StatGroup19-Eng/.

2

Available data and their limitations

The Italian Dipartimento della Protezione Civile (DPC, civil protection department), starting from February 24th, 2020,
has been gathering data at the regional level every day and making these public in a gitHub repository. During most of
the Italian epidemic, data were commented by the department head in an official press release at about 6 p.m. . The
daily updated data are currently stored at https://github.com/pcm-dpc/COVID-19.
For public health service purposes, Italy is divided into 21 regions. There are 19 administrative regions, plus two
autonomous provinces (Trento and Bolzano) that form the administrative region of Trentino-Alto-Adige. We chose to
merge (by summing) data about Trento and Bolzano and use the 20 administrative regions as a territorial reference in
our analyses.
2.1

Incidence and prevalence indicators: different mathematical features

The epidemiological data provided by Protezione Civile can be distinguished into two basic types:
2

A PREPRINT - O CTOBER 27, 2020

(a)

●

●
● ● ●
●
●
●

4K

●●
●
●●
●
●
●
●●
●
●

●●●
●

●
●

●●
●

2K

●
●
●
●
●●
●●●
●
● ●●●
●●

0K

●

●
●●

●

●
●●

●

●
● ● ●
● ●●
● ●●
●●
●●●
●
● ●●● ●
●
● ● ●
●●●●● ●
● ●●●● ●●
● ●● ●●● ● ●●
●●●●
●●
●
●
● ●●●●●●● ● ●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●

daily deceased

daily positives

(b) 1000

●

6K

750

daily recovered/discharged

●

500

●
●

●
● ●●●
●
● ●
●
●●
● ● ●●●

●
●●

250

●
●●
● ●
●
●
●
●●●●
●●●●●●●●

0

01−Mar 01−Apr 01−May 01−Jun 01−Jul
(c)

●
●
●●
● ●●
●
●
● ●
●
●
●●●
●
●

●
●

●

●●
●
● ●

● ●
●● ●
● ● ●
● ●●● ●●
●● ●
●● ●
● ● ●● ●●
●● ● ● ●●●● ● ●
●● ● ●●● ●●
●
●
●● ●●●●●●●●●●● ●●●● ●●●●●●
●● ●● ●● ●
●

01−Mar 01−Apr 01−May 01−Jun 01−Jul

8K

●

6K
●

●

4K

●
●

●

●
●●●
●
● ●
● ●
● ●
●
●
● ●
●
●●● ●
●
●●●●● ●
●●●● ●●●
●
● ●
●
●● ●
●●
●
●
●
● ● ● ●●
●
●●
●
● ●
●
●
● ●●
●
●
●
●● ●
● ● ●●
●
●
●●●●●
●
●
●●● ●●
●
●
●
● ●● ●
●
●● ● ● ●●
●●●
●
●● ●● ●●●●●●●●●
●●●●●
●●
●
●
●●●●●●●●●●●●●●●

2K
0K

01−Mar 01−Apr 01−May 01−Jun 01−Jul

Figure 1: Time series of the Italian daily incident indicators: daily positives (a), daily deceased (b) and daily
recovered/discharged (c).

1. incidence indicators (flows)
2. prevalence indicators (stocks)
2.1.1

Incidence indicators

Incidence indicators measure the number of individuals with a particular condition, related with the epidemic, recorded
during a given period. They can be referred to different time periods; in particular, in the Protezione Civile dataset,
daily incidence counts are available for the following indicators:
• positives, which are sub-classified into two sub-conditions:
– hospitalised (either in regular wards or in ICU)
– isolated-at-home
• deceased
• recovered/discharged
These indicators can be considered, by analogy with the terminology used in econometrics, as flow data, quantifying
the daily input (positives) and output (deceased and recovered/discharged) of the system. Fig. 1 shows the time series
of daily incidence indicators.
One important feature of these indicators, from the viewpoint of the following modeling effort, is that they can be
referred to longer time intervals, simply aggregating them over time. The most interesting cumulative incidence
indicators are those referring to the whole history of the pandemic, computed from a conventional date of "beginning
of the pandemic" (typically, the day the systematic recording of daily positives began) to the current day:
• cumulative positives
• cumulative deceased
• cumulative recovered/discharged
By their nature of cumulative counts, these data series are necessarily monotonically non-decreasing. Fig. 2 shows the
time series of cumulative incidence indicators.
3

A PREPRINT - O CTOBER 27, 2020

200K
150K
100K
50K
0K

(b)

●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●
●●●●●●●●●●
●●●●●●●
●●●●●
●●●●●
●●●●
●●●
●
●●
●●
●●
●●
●●
●●
●●
●
●●
●
●●
●●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

cumulative deceased

cumulative positives

(a) 250K

●
●
●
●●
●●
●●
●
●●
●●●
●●●●●●●●●●●

30K
20K
10K
0K

(c)

cumulative recovered/discharged

01−Mar 01−Apr 01−May 01−Jun 01−Jul
200K
150K
100K
50K
0K

●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●
●●●●●●●●
●●●●●●
●●●●●
●●●
●●●●
●●●
●
●
●●
●●●
●●
●●
●●
●●
●●
●
●
●●
●
●
●●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●●
●●●
●●●●●●●●●●●●●●●

01−Mar 01−Apr 01−May 01−Jun 01−Jul

●●●●●●
●●●●●●●●●●
●●●●●●●
●●●●
●●●●●
●●●●
●●
●●●
●
●
●
●
●●●
●●●
●●
●●
●●●
●●
●
●
●●
●●
●●
●●
●●
●
●
●
●
●●●
●●
●●
●●
●
●●
●●
●●
●●
●●
●●●
●●
●
●
●●●
●●●
●●●
●●●
●●●●
●●●●●
●●●●●●●●●●●●●●●●●●●●●●●

01−Mar 01−Apr 01−May 01−Jun 01−Jul

Figure 2: Time series of the Italian cumulative incident indicators: cumulative positives (a), cumulative deceased (b)
and cumulative recovered/discharged (c).

2.1.2

Prevalence indicators

Prevalence indicators measure the number of individuals with a particular condition, related with the epidemic, at a
given instant in time (or at a given short interval of time, e.g. a day). They are typically obtained from simple algebra
from other indicators; in particular, in the Protezione Civile dataset, the following indicators are available daily:
• current positives (CP )
• current ICU occupancy (ICU )
Again, these indicators can be considered, by analogy with the terminology used in econometrics, as stock data,
resulting from the balance between total inputs (cumulative positives, etc.) and outputs (cumulative deceased and
recovered/discharged, etc.) of the system.
Two important features of these indicators are that:
1. given their stock nature, they cannot be aggregated (e.g.: it does not make sense to compute "cumulative
current positives");
2. by their own nature, these indicators are not monotone, since they can increase or decrease as a result of
different trends of the component series. Typically, we expect the series of current positives and ICU occupancy
to increase in the rising phase of an epidemic, reach a peak and then decrease to a lower asymptote (see Fig.
3), although more complex patterns due to resurgence of the epidemic are also plausible.
Prevalence indicators are characterized by a strong and tangled dependence structure which is cumbersome to simplify
into a manageable and useful statistical model on the short run.
For this reason, the focus of this work concerns only incidence indicators. Our model proposal, from a strictly
mathematical point of view, could potentially applied also on prevalence indicators. However, from the statistical point
of view, the modeling assumptions which are assumed to hold (with good approximation) considering the incidence
indicators, are likely to be strongly violated by prevalence indicators and the resulting outcome cannot be considered
reliable. In Sec. 5 we shall briefly discuss some possible approaches for the analysis of prevalence indicators.
4

A PREPRINT - O CTOBER 27, 2020

(a)

(b)

60K

30K

0K

●
●●●
● ●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●
●●
●

4K

●
●

3K

ICU occupancy

current positives

90K

●●●●●
●● ●●●●●
●
●●
●●
●
●●●
●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●
●
●
●●
●
●
●
●●
●
●
●
●●
●
●●
●
●
●●●●
●
●●
●●
●
●●●
●●●●●●●
●
●●●●●●
●●●●●●●
●
●
●●
●
●
●
●
●
●●●
●●●●●●

2K

●

1K

0K

01−Mar 01−Apr 01−May 01−Jun 01−Jul

●
●
●
●
●
●
●
●
●
●
●●
●●●●●

●
●●●
●
●●
●●
●●
●●
●
●●
●●●
●●●
●●●
●
●●●
●●●●
●●●●●
●●●
●●●●●
●●●●●●●●●●●
●●●●●●●●●●●●●●●●

01−Mar 01−Apr 01−May 01−Jun 01−Jul

Figure 3: Time series of Italian daily prevalence indicators: current positive (a) and ICU occupancy (b).

2.2

Data issues

COVID-19 public Italian data present several issues that severely affect their quality. The information has been gathered
and reported at a regional level, and each regional healthcare organization has a different transmission and data collection
system1 .
Measurement errors, and errors in data entry, are expected to be often present. Delays in reporting has been, sometimes,
substantial. Some patients were transferred (e.g., from Lombardia to Puglia, and even to Germany) without notification,
and they were counted as hospital patients of the receiving region (or not at all when sent abroad) and positive cases of
the region of residence. Most importantly, counts were updated on the notification day rather than aligned to a more
appropriate date. For example, death is counted on the day of the reporting, not on the day of the outcome, which could
be even weeks before. Positive status is also counted on the day that test results are received, with swabs being done
from one day to weeks after symptoms’ onset. No distinction between actively symptomatic and asymptomatic patients
was made.
Swabs and positive cases are not time-aligned. For example, in countries like Singapore (https://www.moh.gov.sg/
covid-19), daily data include information on total swabs tested, total unique persons swabbed as well as total swabs
per 1,000,000 total population and total unique persons swabbed per 1,000,000 total population. In Italy, up to the 19-th
of April 2020, only the total number of daily swabs is available, and no linkage between swabs and tested individuals
was kept in the data repository. Hence, it is impossible to make statistically sound use of swabs’ count to model the
whole first pandemic wave.
Finally, it is crucial to recall that people diagnosed with COVID-19 disease are only a small fraction of the people
infected by the virus. Moreover, since the tracking was highly symptoms’ driven, especially in the first phase of the
outbreak, the detected number of positives cases can provide only a partial estimate of the true incidence of COVID-19
in the Italian population. Eventually, we expect this detected fraction to vary wildly over space and time.
In our opinion, the most reliable indicator is the count of ICU occupancy. The reason is that the Italian Society
for Emergency Care issued national guidelines (that did not change substantially during the epidemic) for testing
patients with a suspected infection by SARS-CoV-2, who also had top priority for swab access and reporting; and
ICU admissions can be expected to depend on the proportion of infected population susceptible to severe infection,
rather than to the regional strategy for testing and contact tracing. However, while probably reliable, this indicator does
present some drawbacks. First of all, it provides only a partial snapshot of the epidemic’s current stage, which concerns
the most severe cases of the disease. The latter is a critical issue, especially in the COVID-19 case, which is known
to present severe symptoms only in a small percentage of the currently affected individuals. Second, this snapshot
is affected by a constant delay (i.e., the time between catching the disease and manifesting severe symptoms). As
mentioned in Sec. 2.1.2, its daily variation is obtained as a combination of new incoming patients (+) and the deceased
or recovered ones (-), whose effects blend and are hard to disentangle. As a consequence, incidence indicators, such as
daily positives and daily deceased, while being measured with some error and even more delay in the case of deaths,
still represent the critical indicators for timely and appropriate monitoring of the pandemic.
1

see https://www.epiprev.it/materiali/2020/EP2-3/112_edit1.pdf for further details.

5

A PREPRINT - O CTOBER 27, 2020

(a)

(b)
●●●●●●●●●●●●●●●●●
●●●●●●
●●●
●●
●●
●
●
●
●
●
●
●
●

0.9

●
●●
●

0.06

●
●

●
●
●

●

●

●
●

●

●

●

0.04

●

●

●

●

~
λt

~
λt

●

0.6

●

●
●

●

●
●

●

0.02

●

0.3

●

●
●

●

●

●

●

●

●

●
●
●
●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●

0.0

0

1

●
●
●
●
●
●
●
●●
●●
●●●
●●●●●
●●●●●●●●●●●●

●

●

●
●
●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●

0.00

2

3

4

5

0

1

t

2

3

4

5

t

Figure 4: Example of Richard’s curve (a) and derivative of the Richard’s curve (b).

3

Model specification
T

The time series of any of the observed indicators, denoted by z = {zt }t=t0 , is modeled separately and considered as
T
the realization of the stochastic process Z = {Zt }t=t0 . The idea behind this paper is to model any of the mentioned
indicators through a Generalized Linear Model with a response function E[Zt ] = µ(t) = g −1 (t; γ), where g(·) is
a known link function and γ is a parameter vector, that is appropriate for the specific mathematical features of the
epidemic process. This must be coupled with a response distribution f (Zt ; θ) coherent with the domain of such
indicators, which are counts and therefore Natural numbers.
3.1

Response function for incidence indicators
T

Let us denote by {ytc }t=0 the time-series of cumulative incidence indicators since the start of the epidemic (t0 = 0, first
day of systematic data recording). Visual inspection of these indicators in Fig. 2 suggests that their expected values
follow a logistic-type growth curve. For these indicators, we consider a Generalized Logistic Function, also known as
Richards’ Curve (see Fig. 4 as an example), as response function for the mean of the process [24]. Richards’ response
function depends on 5 parameters γ T = [b, r, h, p, s] and can be expressed as:
E[Ytc ] = g −1 (t; γ) = λγ (t) = b +

r
(1 + 10h(p−t) )s

(1)

where b ∈ R+ represents a lower asymptote and r > 0 is the distance between the upper and the lower asymptote.
The parameter h is the hill (growth rate), p ∈ (0, T ) is a peak position parameter: it tells when the curve growth
speed slows down, and s ∈ R is an asymmetry parameter. In our context, since cumulative incidences are always
monotone increasing indicators, it is reasonable to assume h, s > 02 . An extensive review of Gompertz models and
proper interpretation of the parameters is given in [22].
An extended GLM with (1) as response function seems to be a natural choice for modeling time series of cumulative
counts, whose monotonically non-decreasing average behaves as the Richard’s curve. Unfortunately, there is a
significant drawback to this choice. As it will be better clarified in the Sec 3.2, a very useful working assumption
would be that all these counts were stochastically independent, given their mean function λγ (t). However, we cannot
consider this assumption as realistic in the case of cumulative counts, since the constraint on the domain of definition
on subsequent counts (i.e., ytc ≥ yτc , ∀τ < t) is not guaranteed to be satisfied. On the other hand, the stochastic
T
independence assumption sounds more reasonable, albeit not necessarily true, for the daily incidence counts {yt }t=1 ,
i.e., the addenda of the cumulative counts excluding the starting point y0 , which can be defined as:
ytc =

t
X

yτ

⇒

c
yt = ytc − yt−1
,

τ =0
2

Conversely, we may assume h, s < 0

6

t = 1, . . . , T

A PREPRINT - O CTOBER 27, 2020

where y0 = 0 by definition.
Using Equation 1, and exploiting the additive properties of the expected value, we have:
c
µ̃(t) = E[Yt ] = E[Ytc ] − E[Yt−1
] = λγ (t) − λγ (t − 1) =
i
h
h(p−t) −s
= r · (1 + 10
) − (1 + 10h[p−(t−1)] )−s = λ̃γ (t)

which, in particular, does not depend on the baseline b. Therefore, we shall adopt an extended GLM with response
n
oT
function given by the first differences of the Richards Curve λ̃γ = λ̃γ (t)
to model the daily expected values
T

t=1

T

µ = {µ(t)}t=1 of the observed incidence counts y = {yt }t=1 (see example in Fig. 4).
In addition, we may also consider adding a kink effect/baseline α to the first differences λ̃γ (·), which is to say assuming
the following functional form for the mean of the daily counts:
µ̃θ (t) = α + λ̃γ (t),

α ≥ 0,

(2)

where θ = (α, γ). This would correspond to the following mean function for the cumulative counts:
µθ (t) = α · (t − 1) + λγ (t).
In practice, the parameter α includes the possibility of having a strictly positive baseline rate, which can be interpreted
as the endemic steady state incidence rate. On the other hand, the first differences of the Richard’s Curve λ̃γ (t) are (by
construction) forced to decrease asymptotically to the value of 0. However, this asymptotic result is not necessarily
observed in real data. In particular, Fig. 1 highlights that both time-series do not attain the 0 value, but settle to a
low, constant level. This situation may, potentially, continue indefinitely: new cases will be found as long as people
will be tested. Consequently, the model without a baseline lacks the ability to catch this tail and, because of the curve
parametric form, this may indirectly affect the fit on the whole series.
In the first instance, one solution would be to fit the model, including the kink effect α. Afterward, if it is estimated to
be sensibly different from 0, the model without α can be fitted again to stabilize the estimation procedure and decrease
the uncertainty on the other parameters.
3.2

Response distribution for incidence indicators

Before introducing the distributions for the daily incidence counts, we must make some assumptions about the time
dependence structure. In particular, we assume that given the mean function λ̃γ (·), the daily incidence counts Yt are:
c
• stochastically independent from the previous state Yt−1
given the mean function λγ (·):

Yt ⊥ Yτc ∀ τ < t
• stochastically independent among them:
Yt ⊥ Yτ ∀t, τ
This implies a 1-st order Markov property for the cumulative counts:
c
c
Ytc |Yt−1
⊥ Y1:t−2
∀t

and we can write:
c
c
c (y , . . . , y |y0 ; θ) =
fY1:T
1
T

T
Y

c
fYtc (ytc |y0:t−1
; θ) =

t=1

=

T
Y

T
Y

c
fYtc (ytc |yt−1
; θ) =

t=1
c
fYt (yt |yt−1
; θ) =

t=1

T
Y

fYt (yt |θ)

t=1

where we recall that the last equivalence is justified by the assumption that, given the parameters, the daily incidence
counts are independent w.r.t. to the previous observed cumulative count.
We remark that although the first-order Markov property for the cumulative counts is an approximation in the present
case, this kind of approach has been valid for all incidence indicators provided by the Italian Protezione Civile.
For communication purposes, it can be of interest to report the results of analyses and predictions in terms of cumulative,
rather than daily, incidence indicators. Clearly, it is possible to model and predict the daily incidence indicators and,
from these estimates and predictions, obtain the relevant cumulative incidence indicators.
7

A PREPRINT - O CTOBER 27, 2020

3.2.1

Poisson distribution

Let us assume that the vector of daily incident counts, y = {y1 , . . . , yt }, is composed of independent Poisson
realizations with expected value µ̃θ (t):
Yt |θ ∼ P ois(µ̃θ (t)),

t = 1, . . . , T

Hence, the likelihood can be written as:
L(θ|y) =

T
Y

P ois(yt |µ̃θ (t)) ∝

t=1

∝ µ̃θ (t)

PT

t=1

yt −

e

PT

t=1

µ̃θ (t)

and the log-likelihood is given by:
log L(θ|y) ∝

T
X

yt log (µ̃θ (t)) −

t=1

T
X

µ̃θ (t)

t=1

Remark that, under the assumption of Poisson distribution and the baseline α = 0 (i.e. µ̃(α,γ) = λ̃γ (·)), we can exploit
the well-known Poisson’s additive property3 to conclude that each cumulative count Ytc is still marginally distributed
according to a Poisson, parametrized by the original Richard’s Curve function λγ (·):
!
t
X
c
Yt |γ ∼ P ois
λ̃γ (τ ) = P ois(λγ (t))
τ =1

3.2.2

Negative Binomial distribution

When counts are over-dispersed the Poisson distribution is not a suitable choice. We can model the observed daily
incidence counts y = {y1 , . . . , yt } as independent realizations from a Negative Binomial with mean λ̃γ (t) and
dispersion parameter ν ∈ R+ :
Yt |θ ∼ N B(µ̃θ (t), ν), t = 1, . . . , T
Hence, the likelihood can be written as:
L(θ, ν|d) =

T
Y

N B(yt |µ̃θ (t), ν) ∝

t=1

∝


T 
Y
Γ(ν + yt )
t=1

Γ(ν)

ν
ν + µ̃θ (t)

ν 

µ̃θ (t)
ν + µ̃θ (t)

yt 

and the log-likelihood is:
T
X




T
X
Γ(ν + yt )
ν
+ν
log
log L(θ, ν|y) ∝
log
Γ(ν)
ν + µ̃θ (t)
t=1
t=1


T
X
µ̃θ (t)
+
yt log
µ̃θ (t) + ν
t=1


The Negative Binomial does not satisfy the same additive property as the Poisson, hence we cannot draw the same
conclusion reached in the Poisson case about the marginal distribution of the cumulative count Ytc when α = 0. In
general, the cumulative count in the NB case will follow the distribution stemming from the sum of independent
n
oT
Negative Binomial r.v. with common dispersion parameter ν but different means µ̃ = λ̃γ (t)
.
t=1

3

the sum of independent Poissons is still a Poisson with parameter the sum of the parameters

8

A PREPRINT - O CTOBER 27, 2020

3.3

Response function depending on covariates

The trend of any of the considered indicators may also depend on additional exogenous information, which we may
assume to be known a priori either because it is immutable (i.e., the day of the week), or because policy makers fixed
it (daily number of tested cases/swabs set by the government). For instance: one might want to correct for possible
weekly seasonality, which is known to affect the daily positives series since many laboratories are closed during the
weekend and can not evaluate swabs. The latter can be used to disentangle the underlying trend of the epidemic from
the obvious positive correlation between tested cases and daily positives.
In general, we may want to include the effect of any set of k time-varying covariates

X

T ×(k+1)

T

= [x(t)]t=1 in the

Richards’ GLM framework through the usual linear predictor:
η(X) = Xβ
where β is a k + 1-dimensional vector of real valued parameters (including intercept). Let us denote the mean function
of the considered indicator as µ̃θ (t) = E [Yt ], where θ = (α, γ, β). In order to respect the positivity of the mean
parameter (which is necessary both in the Poisson and in the Negative Binomial case), we consider the link function
g(·) = log(·), so that the effect on the mean is expressed as:
η̂(X) = exp {η(X)} = exp {Xβ} .
Considering a single time point t, we would get the following functional form:
η̂(x(t)) = exp {x(t)β} .
Now, the transformed predictor can unload its effect on the mean function either in an additive or a multiplicative
fashion.
3.3.1

Additive inclusion of covariates

The inclusion of an additive effect of covariates implies that the effect of every covariate is constant through-out the
pandemic, notwithstanding the current contagion level: for instance, one may think that an increase of daily tested
cases will always produce the same increase of daily daily positives. If that is the case, we may just express the baseline
parameter α at each time-point t as the linked linear combination of covariates η̂(x(t)), which would produce the
following mean function:
µ̃θ (t) = exp {x(t)β} + λ̃γ (t)
On the whole vector of observations, this can be expressed as:
µ̃θ = exp {Xβ} + λ̃γ .
3.3.2

Multiplicative inclusion of covariates

The inclusion of a multiplicative effect of covariates would imply that the more serious the pandemic situation, the
more severe the impact of any covariate on the indicators’ daily rate.
First, let us recall that in Sec. 2.1.1 we computed the first differences of the Richard’s curve function as:
h
i
λ̃γ (t) = r · (1 + 10h(p−t) )−s − (1 + 10h[p−(t−1)] )−s = r · λ̃γ,−r (t)


where λ̃γ,−r (t) = (1 + 10h(p−t) )−s − (1 + 10h[p−(t−1)] )−s . On the log-scale, it would return the more familiar:


log(λ̃γ (t)) = log(r) + log λ̃γ,−r (t)
From Equation 3.3.2, it comes natural the idea of expressing log(r) at each time-point t as the linear combination of
covariates η(x(t)) as in the classic GLM Poisson model with log link function. This indeed provides a multiplicative
effect of the covariates, where the parameter r is:
rβ (t) = exp {x(t)β} = exp {β0 + β1 x1 (t) + · · · + βk xk (t)} .

(3)

Note that the constant r is still present and included in Equation 3 through the intercept β0 . Therefore, the mean at time
t is expressed:
µ̃θ (t) = α + exp {x(t)β} · λ̃γ,−r (t)
Considering the whole vector of observations, we would have the following vector of means:
µ̃θ = α + exp {Xβ} · λ̃γ,−r ,
where α = α · 1T .
9

A PREPRINT - O CTOBER 27, 2020

3.4

Model estimation

Parameters can be estimated by maximizing the log-likelihood l(θ|y), where θ in this case includes all the parameters
the likelihood depends on (e.g. includes ν in the Negative Binomial case). This optimization problem does not have
an analytical solution, and numerical maximization must be used. To improve computation, we derived analytical
expressions for the gradient and Hessian of the two possible log-likelihoods (i.e. Poisson or Negative Binomial counts),
making Fisher-scoring iteration very fast. The expressions are reported in the Appendix. Given the non-smooth shape
of the objective function, we are at risk of being trapped by local maxima of the log-likelihood, depending on the
initial conditions. Therefore, in order to robustify the optimization procedure, a multistart procedure based on genetic
algorithms has been used [25].
Once an approximate point of maximum θ̂ has been obtained, the inverse of the negative log-likelihood Hessian in
θ̂ (which corresponds to the Observed Fisher Information) is used to approximate its standard errors and variancecovariance matrix according to the usual asymptotic properties:

−1
V̂θ = −H l(θ̂|y)
,
where H denotes the Hessian matrix and the interval estimates for the parameters are directly derived through the
asymptotic distribution θ̂ ∼ N (θ, V̂θ ). A similar theoretical result for predictions is not straightforward. Therefore,
these are derived through a parametric double bootstrap procedure ([26], [27], [28]), which accounts for both the
B
uncertainty from estimation and the randomness of the observations. In practice, re-sampled trajectories {Yi }i=1
are obtained by simulating B sets of parameters from their asymptotic distribution and computing B mean functions
B
trajectories {µθi (t)}i=1 . An artificial time series of counts is then simulated for each of the B trajectories and 95%
confidence intervals are obtained by computing the point-wise 2.5% and 97.5% quantiles. Diagnostic check on the
model has been performed through the Pearson residuals, which can be computed as:
ρˆt =

yt − yˆt
,
c [Yt ]
Var

t = 1, . . . , T.

c Poi [Yt ] = ŷt , while under the Negative Binomial assumption Var
c NB [Yt ] =
Recall that, under the Poisson assumption Var
ŷt + ŷt2 /ν̂. Under the null hypothesis (the GLM assumption holds), Pearson residuals are expected to be Normally
distributed and independent.

4

Nowcasting the Italian outbreak of COVID-19

For the sake of brevity, here we present results referred to the proposed Richards’ growth model only for daily positives
and daily deceased, aggregated at the national level. We use the Negative Binomial distributional assumption. Indeed,
this choice is justified by the substantial over-dispersion present at the national level for these indicators.
We first show the fitted curve for each indicator, and compare its shape with the observed time series. We also calculate
the residuals and check if model assumptions under the GLM framework hold.
Later on, we show the performance for two fundamental issues: (i) predicting the epidemic trend in advance and (ii)
predicting the peak of the epidemic.
4.1

Model on daily positives

To decide whether or not to include the kink effect, we fitted the model with and without the baseline α and compared
the two fits in terms of log-likelihood, AIC, BIC and Corrected AIC (AICc). The values are presented in Table 1 and
provide clear evidence in favor of the model with baseline (i.e. with mean µt (·) as in Eq. 2). Parameters’ estimate of
such model θ̂ and the respective 95% confidence intervals are shown in Table 2, where the baseline α is estimated to be
α̂ = 175.04, with interval (158.15, 193.73), which confirms that the baseline is estimated to be significantly different
from 0, and it should be included in the model.
The uncertainty characterizing the parameters p and s is not alarming. Indeed, according to the Hessian value in the
maximum point, these two parameters are highly correlated (see Fig. 5a). Bootstrapping trajectories, by simulating
M = 5000 set of parameters from the Normal distribution with variance corresponding to the Hessian underlying the
correlation matrix in Fig. 5a, we get the set of curves in Fig. 5b.
10

A PREPRINT - O CTOBER 27, 2020

Table 1: Log-likelihood, AIC, BIC and AICc for the model without baseline and the model with baseline, on daily
positives
Index
Model without baseline Model with baseline
−1081.4
2152.7
2162.3
2137.8

log-likelihood
AIC
BIC
AICc

−982.8
1953.6
1965
1935.7

Table 2: Parameters’ points estimates and 95% confidence intervals for the model with baseline, on daily Positives
Parameter Point estimate
Interval
α
r
h
p
s
ν

175.04
221.94 × 103
0.029
−32.29
77.74
18.76

a

0.57

0.15

−0.07

−0.08

r

0.31

0.07

−0.02

1

(158.15, 193.73)
(209.03 × 103 , 235.65 × 103 )
(0.028, 0.03)
(−51.34, −13.23)
(0, 170.88)
(14.78, 23.81)

6K

1

4K

µt

1.0
0.5

s

−0.26

−0.99

1

0.0
−0.5
−1.0

p

0.4

h

1

2K

1

0K
01−Apr

01−May

01−Jun

01−Jul

01−Aug

a

r

s

p

h

01−Mar

(a) Correlation matrix

(b) Trajectories

Figure 5: Correlation matrix and bootstrapped trajectories corresponding to the Hessian in the point of maximum for
the model with baseline on daily positives.
T

We can also directly obtain point predictions {ŷt }t=1 as:
ŷt = µθ̂ (t),


t = 1, . . . , T,

T

(4)

and prediction intervals (b
ytl ; ybtu ) t=1 through the same set of bootstrapped trajectories, whose statistical validity relies
on the asymptotic properties introduced in Sec. 3.4. Fig. 6 shows the model fit on the whole available time series
of counts: the former on the daily series, the latter on the cumulative one. We can see how the estimated curve does
catch the observed general behavior, providing a smooth approximation only marginally influenced by extreme values.
Fitting performances are further evaluated through numerical metrics such as the pseudo-R2 and coverage of the 95%
prediction intervals:
PT
(yt − ŷt )2
MSE
R2 = 1 − 2 = 1 − Pt=1
,
T
2
σy
t=1 (yt − ȳ)
Cov95%

T
1 X
= ·
I l u (yt ),
T t=1 (ybt ;byt )

11

A PREPRINT - O CTOBER 27, 2020

(a)

(b)

8K

daily positives

cumulative positives

●

6K

●
●●

●
●
●

●● ●
●

●●
●
●

4K

●●
●
●●

●

●

●

●

●
●
●
●
●
●●

●
●

●
●

●
●
●

2K

●
●
●
●

0K

●●
●●
●
●
●●●
●●

●

●

●

●

●
●
●

●●

200K

100K

●●
●
●●

●

● ●●● ●
●
● ●
●
●●
●● ● ●
● ●●●●
● ●●●
●
●
● ●
●
● ●●● ●●● ●●●●●●● ●●
●
●
● ● ● ●● ● ●●●● ●●●●●●●●●●●●●●●●●●●●●

01−Mar 01−Apr 01−May 01−Jun

01−Jul

0K

01−Aug

●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●●●
●●●●●
●●●●
●
●
●
●●●
●●●
●●
●●
●●
●●
●●
●●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●●
●●●●●●●●

01−Mar 01−Apr 01−May 01−Jun 01−Jul 01−Aug

Figure 6: Observed (black dots) and fitted values (grey solid lines) with 95% confidence intervals (grey dashed lines)
for the model with baseline on daily positives.

Table 3: Log-likelihood, AIC, BIC and AICc for the models with baseline including additive or multiplicative week-day
effect on daily positives
Index
Additive effect Multiplicative effect
log-likelihood
AIC
AICc
BIC

−971.8
1929.6
1942.8
1908.7

−974.1
1934.3
1947.5
1913.4

PT
where MSE is the Mean Squared Error, ȳ = T1 t=1 yt and IY (·) denotes the indicator function over the set Y. Our
model produces an R2 = 0.941 and coverage Cov95% = 0.945, meaning that the percentage of observed daily counts
falling inside the estimated bounds is perfectly coherent with the specified confidence level. Looking at Fig. 6, we notice
how daily counts boundaries get smaller as time passes, due to the implicit relationship between mean and variance that
characterizes count distributions. At the same time, the opposite happens to the bounds on the cumulative counts. The
latter is not surprising: indeed, they are built marginally on all the epidemic’s possible scenarios. Therefore, they give
us a clear sight of what we could have currently observed, keeping into account and accumulating the uncertainty at
each stage of the epidemic.
We also perform a diagnostic check on the Pearson residuals. In Fig. 7, we can observe different plots referred to the
residuals: histogram (a), including the p-value from the Shapiro test; Normal qq-plot (b); autocorrelation plot (c); plot
of the residuals vs. fitted values (d). The first two check the (approximated) Normality assumption on the residuals,
while the second two control for the correlation of the residuals (among them and with the observed values).
4.1.1

Weekly seasonality

The diagnostic check on the residuals (see Fig. 7) shows that the Normality assumption is not rejected, but the correlation
plot manifests undesirable patterns. In particular, the autocorrelation between errors is larger at lag 7 (and multiples
of this). We can interpret this outcome as the presence of an intense weekly seasonality (especially during/after the
weekend). This may be adjusted by simply adding a weekday effect in our model as a covariate, using the approach in
Sec. 3.3. Such effect may be included either in an additive or a multiplicative fashion. At first we considered effects
for each day of the week, taking Monday as a corner point. Preliminary results showed that not all week-days present
a significant deviation from the common mean. On the other hand, the distribution of the Pearson residuals ρ̂t of
the standard model aggregated by week-day (see Fig. 8) shows that an evident overestimation pattern (i.e., negative
deviations) is taking place on Monday and Tuesday.
12

A PREPRINT - O CTOBER 27, 2020

(a)

1.00

(b)

p−value Norm. Test = 0.901

sample

Density

0.75
0.50

●

●
●

2

●

1
0
−1

0.25

●●

−2
0.00

●
●●●
●●●
●●●
●●●
●●
●●●●●●
●●●●●
●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●●
●●●●●
●●●
●●●●●
●
●●●●●
●●
●
●●●●

●● ●

●

● ●
●
●

●
●

−1.0

−0.5

0.0

0.5

−3

1.0

−2

−1

0

Pearson residuals

1

2

theoretical

(c)

1.0

(d)

●●

Pearson residuals

●

acf

0.8

0.4

0.0

●
●
●●
●●

0.5

●
●
●
●
●
●●

5

10

15

●

●

● ●

−0.5

●

●
●

●

●
●

●

●

●
●

●
●
●

●

●●

●

●

●

●

●
●
●
●

●

●

●

●

●

●

●

●

●

●

●
●

●
●

●
●

●

●

●

●

●
●

●
● ●●

●

●

●
●●
●
● ●
●
●
●

20

●
● ●

●● ●
●
●

●

●

●●

●

●

●
●
● ●

●
●●
●
● ●
●
● ●
●
●
●
●●
●●
● ●
●
● ●●
●● ● ●
● ●
●
●● ● ●

0.0

−1.0
0

●
●

●

●●

●

●
●

●

●

0

2000

lag

4000

Fitted values

Figure 7: Pearson’s residuals for the model with baseline on daily positives.

1.0

●
●

^
ρ

0.5

0.0

−0.5
●
●

●

−1.0

ay
nd
Su

rd
ay
tu

id
ay
Fr

Sa

Th

ur

sd
ay

sd
ay
ne
W
ed

Tu
es
da
y

M

on
da
y

●

Figure 8: Pearson’s residuals distribution aggregated by day of the week for daily positives.

Therefore, in the sequel, we will present only results obtained with the dichotomous variable that is equal to 1 whenever
the week-day is Monday or Tuesday (0 vice versa). Note that lower tests effort during the weekend shows in the data on
Monday and Tuesday, since daily reports involve mostly results received the day before, with swabs therefore dating
back 48 hours on the day of publication. The additive option is chosen over its alternative because of its lower/improved
AIC, BIC and AICc score (see Table 3).
The resulting fit of the model with week seasonality on the observed data is shown in Fig. 9, where, on the left, we show
the fitted curve and the 95% confidence intervals; on the right, we can show the first differences of the corresponding
Richard’s curve, not including the multiplicative effect of the week-days coefficients (the latter can be interpreted as the
underlying trend of the epidemic, disentangled from the heterogeneity due to the week-days correlation). Estimated
parameters are shown in Table 4.
13

A PREPRINT - O CTOBER 27, 2020

Table 4: Intercept β0 and week-day effect βwd point estimates and 95% confidence intervals for the additive model with
baseline on daily positives
Parameter Point estimate
Interval
β0
βwd

5.26
−0.46

(5.16, 5.36)
(−0.63, −0.28)

(a)

(b)
●

8K

●

6K

●

●●

●
●

●

6K

●●

●
●●

●

●

●

● ●
●
●

●

●
●

●● ●
●

4K

●●
●
●●

●
●
●
●
●
●●
●

●
●

●

●

●

●

●

●

●

●

●

●
●●
●●

2K

●●

●
●

●

●
●

●
●
●

●
●●

●

●●
●
●●
●

●

●●

●
●

●

●

●

2K

●
●
●

●
● ●

●

●

●
●

●

●●

●

●

●

●

4K

●●
●
●

^
λt

daily positives

●
●

●

●

● ●●● ●
●
● ●
●
●●
●● ● ●
● ●●●●
● ●●●
●
●
● ●
●
● ●●● ●●● ●●●●●●● ●●
●
●
● ● ● ●● ● ●●●● ●●●●●●●●●●●●●●●●●●●●●

●
●●
●●
●
●
●●●
●●

0K

●●
●

●
●

●
●

01−Mar 01−Apr 01−May 01−Jun

01−Jul

●

●
●

●

●
●
●

●●
● ●
●
●
●●●

●
● ●
● ●
● ●●●●
●

●

0K

01−Aug

●●
●
●
●
● ●●
● ●●
● ●● ● ●
●●
● ●●
● ●● ●
●
●
● ●● ●●● ●● ●● ● ● ●●● ●
● ● ● ●● ●
●
●●
●
●

●
●

●●

01−Mar 01−Apr 01−May 01−Jun 01−Jul 01−Aug

Figure 9: Fitted curve and 95% prediction intervals (on the left) and estimated underlying trend of the epidemic (on the
right), for the model with baseline and week-day additive effect, estimated on the daily positives.

(a)

p−value Norm. Test = 0.939

(b)

●

sample

0.6

●

●

● ●

2

0.9

Density

3
●
●●
●●
●●●●●●
●●●●
●●●●
●●
●●●
●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●
●●●●
●●
●●●●●●●
●●●
●●●
●●●●

1
0
−1

0.3
−2

●

●

●

●

●●

●

●●

●

−3

0.0
−1.0

−0.5

0.0

0.5

●

1.0

−2

−1

0

Pearson residuals
(d)

1.00

Pearson residuals

(c)

0.75

acf

1

2

theoretical

0.50
0.25
0.00

●

1.0
●

●

●●
●

●
●
●
●
●●●●●
●
●
●
●
●
●
●
●
●
●
●●
●
●●● ●
●●
●
●●
●
●
●
●
●
●
●
●●
● ●
●●
● ●
● ●
●
● ●
●
●
●
●
●
●
● ●
●
●
●● ●
●
● ● ●●
●
●
● ●
●
●● ●
●
●
● ●
●
● ●
●
●
●
●●

0.5
0.0
−0.5

●
●

●

●

●
●
●
●

●
●
●
●

●
●●

●

●
●

●

●

●
●

●

●

●

●

●
●

●

●

●

●

●

●

●
●

●

●

●

● ●●

●●

●

●

−1.0
●

0

5

10

15

20

0

lag

2000

4000

Fitted values

Figure 10: Pearson’s residuals for the model with baseline and week-day additive effect estimated on daily positives.

The inclusion of this effect improves sensibly the R2 (0.956), while the average coverage Cov95% is constant (0.950).
Furthermore, the diagnostic check of the Pearsons’s residuals (see Fig. 10) shows that the correlation pattern at lag 7
has diminished.
14

A PREPRINT - O CTOBER 27, 2020

Table 5: Log-likelihood, AIC, BIC and AICc for the model without baseline and the model with baseline on daily
deceased
Index
Model without baseline Model with baseline
−735.8
1461.6
1471.2
1446.7

log-likelihood
AIC
AICc
BIC

−732.1
1452.11
1463.5
1434.2

Table 6: Parameters’ points estimates and 95% confidence intervals for the model with baseline on daily deceased
Parameter Point estimate
Interval
α
r
h
p
s
ν

4.2

3.74
35.42 × 103
0.025
−50.4
170.6
11.9

(1.74, 8.05)
(33.13 × 103 , 37.87 × 103 )
(0.023, 0.026)
(−63.7, −37.04)
(50, 291.2)
(8.82, 16.18)

Model on daily deceased

The procedure described in Sec. 4.1 has been applied to decide for the inclusion of the baseline in the modeling effort
of the daily deceased, too. Comparisons in terms of goodness of fit measures are reported for both models in Table
5. The best model in terms of all the goodness of fit scores (AIC, AICc and BIC) is the model with baseline. The
resulting estimated parameters θ̂ and the respective intervals are shown in Table 6, where the baseline α is estimated to
be α̂ = 3.74 (sensibly larger than 0).
 l u T
T
We can then obtain point predictions {ŷt }t=1 through Eq. 4 and prediction intervals (b
yt ; ybt ) t=1 through the
parametric bootstrap procedure described in Sec. 3.4.
Fig. 11 shows the fit on the whole available time series of counts: the former on the daily series, the latter on the
cumulative one. Also in the case of the deceased the estimated curve does catch the observed general behavior. The same
metrics are used to evaluate the fitting performances, which correspond to an R2 = 0.90 and a coverage Cov95% = 0.95.
Pearson residuals are shown in Fig. 12.
Table 7: Log-likelihood, AIC, BIC and AICc for the models with baseline including additive or multiplicative week-day
effect on daily deceased
Index
Additive effect Multiplicative effect
log-likelihood
AIC
AICc
BIC

−725.71
1437.43
1450.62
1416.55

−725.30
1436.61
1449.81
1415.73

Table 8: Intercept β0 and week-day effect βwd point estimates and 95% confidence intervals for the additive model with
baseline on daily deceased
Parameter Point estimate
Interval
β0
βwd

10.54
−0.22

15

(10.46, 10.61)
(−0.33, −0.1)

A PREPRINT - O CTOBER 27, 2020

(a)

(b)

1250

40K

1000

cumulative deceased

●

daily deceased

●
●
●

●

750

●

● ●●
●

●
●

●
●
●

●
●

●
●● ●
● ●●●

●

500

●

● ●

●
●

●

250

●
●●
●●
●●

●

●

●
●●

●

●●
●
● ●

●
●●
● ●

●
●●

●
●●●
●●●
●●●●●●

30K

20K

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●●
●●●●●●●●●●●●

10K

●
●

● ● ●
●
●
●●

●

0

●●●●●●●
●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●
●●●●●
●●●●●
●●●●●
●●●●
●●●●
●●●
●
●
●●
●●
●●
●●
●●
●●
●●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

●●●●●
●
● ●●
●
● ● ●●
●● ● ● ● ●● ●
●● ●● ●● ●
●
●●●●● ●
● ●●● ●●●●●● ●
● ●●● ●●●●●●
●
● ●● ●● ●●

0K

01−Mar 01−Apr 01−May 01−Jun 01−Jul 01−Aug

01−Mar 01−Apr 01−May 01−Jun 01−Jul

01−Aug

Figure 11: Observed (black dots) and fitted values (grey solid lines) with 95% confidence intervals (grey dashed lines)
for model with baseline on daily deceased.
(a)

p−value Norm. Test = 0.038

(b)

●
●

●
●

2

sample

Density

0.75
0.50

●

0

0.25
● ● ●●

−2
0.00

●

●

●

0

1

2

−2

−1

Pearson residuals

0

1

2

theoretical
(d)

Pearson residuals

1.00
0.75

acf

●

●

−1
(c)

●

●
●●
●●●
●●●
●●
●●●●●●
●●●●●●
●●●●
●●●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●●
●●●●●●●
●
●
●●●
●●
●●●●●
●●
●●●

0.50
0.25
0.00

●
●

●

●

1

●

0

−1

●
●

●
●

●

●

●

●

●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
● ●
●
●●
●
●
●
●●●
●
●●
● ●
●
●
●
●
●
●
●
● ●
●
●● ●
●
●
●
●
●
●
● ●
●
●●
●
●●
●
●
●
●
●●
●
●
● ●
●● ● ●
● ●
● ●
●
●●
●●
●
●
●
●
●
●
●
●
●
● ●
●
●●
●

●

●

●

● ●

●

●

●

●

●

●
●

●

●
●

●

●

●

● ●
●

●

●

●

●

●●

●
● ●●
●
●

●

●

0

5

10

15

20

0

lag

200

400

600

Fitted values

Figure 12: Pearson’s residuals for the model with baseline on daily deceased.

4.2.1

Week seasonality

As in the case of daily positives, the diagnostic check on the Pearson’s residuals for the daily deceased highlights a
slight week seasonality pattern for the autocorrelations. In addition, also the residual Normality hypothesis is rejected.
Potentially, the inclusion of a week-day effect may solve both problems. In order to decide what set of week-days
to group together, we visualize the residuals’ distribution aggregated by week (see Fig. 13). The pattern is not as
evident as in the case of daily positives, but we can still detect some undesirable overestimation on Mondays and
Sundays. Therefore, on the line of the previous application, we decide to include a dichotomous week-day fixed effect
on the pair Monday-Sunday. As before, this effect may be included either in an additive or a multiplicative fashion
and, again, we may pick the version that achieves the best AIC, AICc and BIC scores. However, as shown in Table 7,
differences in this scores are almost negligible and choice based on such a small improvement would not be robust.
Therefore, we checked the Pearson residuals for both alternatives and we selected the additive model because of the
improved residuals behavior (Normality is accepted, autocorrelation at lag 7 is reduced). Estimated parameters are
shown in Table 8, where the Monday-Sunday effect is estimated to have a reducing effect on the daily baseline rate
16

A PREPRINT - O CTOBER 27, 2020

●

●
●

^
ρ

1

0

−1

●

ay

ay

nd

Sa

Su

tu

Fr

id

rd

ay

da
y
rs
Th
u

sd
ne
W
ed

M

Tu
e

on

sd

da
y

ay

ay

●

Figure 13: Pearson’s residuals distribution aggregated by day of the week for daily deceased.
of ≈ −357, i.e. exp {−357} ≈ 0, which shrinks to 0 the kink effect on Mondays and Sundays. The resulting fit is
shown in Fig. 14 where: on the left, we can observe the fitted curve and the 95% confidence intervals; on the right, we
can observe the first differences of the corresponding Richard’s curve, not including the multiplicative effect of the
week-days coefficients (i.e. underlying trend of the epidemic). The inclusion of the Sunday-Monday effect allows for
an increase of the R2 to 0.91, whilst keeping the coverage Cov95% steady at 0.95. The diagnostic check shown in Fig.
15 shows how Residual Normality is now accepted and the previously evident correlation pattern is slightly reduced.
(a)

(b)

1250

1000
●

●

●
●

1000

●

●

●
● ●

750

●
●

●

●

●
●

●
●
●

●
●●

250

●
●●
● ●
●
●
●●●
●●●
●●●●●●

●
●

●
● ● ●
●

●

●

●

●
●● ●
● ●●●
●

500

●

●

●
●

●

●
●

● ●

●
●

●●

●

●

500

●

●
●

●

● ●●
●
●

750

0

●

^
λt

daily deceased

●

●
●

●
●●
●●
●●

●

●

● ●
●●
●

●

●

●

●
●●

●
●

●

●●
●
● ●

250
●
●●

●

●
●
●
●

●●●●●
●
● ●●
●
● ● ●●
●● ● ● ● ●● ●
●● ●● ●● ●
●
●●●●● ●
● ●●● ●●●●●● ●
● ●●● ●●●●●●
●
● ●● ●● ●●

●

0

01−Mar 01−Apr 01−May 01−Jun 01−Jul 01−Aug

●
●

●
●

●
●

● ● ●
●
●
●●

●

●

●
●●
●●
●
●●●●●●

●
●

●

●

●

● ●
●
●
●

●

●●
● ●
●
●
● ●
●
●
● ●
●●
● ●
● ●
● ●●●
●
●
●●
● ●●
●
● ● ●●
●
●
●
●●● ● ● ●●● ● ●
● ●●● ●●●●●●●
●
●● ●
●
● ●

01−Mar 01−Apr 01−May 01−Jun 01−Jul 01−Aug

Figure 14: Fitted curve and 95% prediction intervals (on the left) and estimated underlying trend of the epidemic (on
the right), for the model with baseline and week-day additive effect, estimated on the daily deceased.

17

A PREPRINT - O CTOBER 27, 2020

(a)

1.00

3

(b)

p−value Norm. Test = 0.253

sample

Density

0.75
0.50
0.25

●●

1
0
−1
−2

0.00
0

●
● ●●

●

●

●

1

−2

−1

0

1

2

theoretical
(d)

1.00

●

●

●

Pearson residuals

●

0.75

acf

●

● ●

●●
●●●
●●
●●●●
●●●●●●
●●●●●●
●●●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●●●●
●●●●
●●●●●●
●●●
●●●
●●●
●●
●●●
●

Pearson residuals
(c)

●

●

−3
−1

●

●
●

2

0.50
0.25
0.00

1

●

●

●

● ●
●
● ●

●

●
●
●
●
● ●●
●
●
●
●
●
●
●●
●●● ● ●
●
●
●
●
●●
●
●
●
●●
●
●
●
●
●
● ●
●
●●
●
●
●
●● ●
●
●
●
●●
●
●
●
●
●●
● ●
●
●
●
●●
●
●
●
●
●
● ●
● ●●
●
●
●● ●
●
●
●
●
●●
●
●
●●
●
●
●●
●
●● ●

0

−1

●

●

●

●

●

●

●

●
●

●●
●

●
●

●

●
●

●

●

●

● ●
●

●

●

●

●

●
● ●
●
●

●

●

●

0

5

10

15

20

0

200

lag

400

600

Fitted values

Figure 15: Pearson’s residuals for the model with baseline and week-day additive effect on daily deceased.
1 step−ahead

5 step−ahead

●

1500

1500

●
●
●

RMSPE

RMSPE

●
●

●

●

1000

●
●

●

●
●

●

●

500

●

●
●

1000

●
●
●

●
●●
●

●

●

● ●
●●
●
●

500

●
●

●●
●

●
●

● ●●
●●

●
●
● ●
●●
● ●● ● ●
●

●

●
●
●●

0

●

01−Apr

●●

●
●●●●●
●●
●● ●●
●●
● ●●●

●
●

●
● ●
●●●
●
●
●●● ●●● ●●
●
● ●
●
● ●●
● ●
●● ● ●
● ●● ●● ●●●● ● ●●
● ●● ●●●●●
●
●●
● ● ● ●● ● ●
●● ● ●

01−May

01−Jun

● ●●
●●●●●● ●●●●●
●
● ● ● ●●●●●● ●●●●
●
●●●
●●● ●●●●
●●
● ●
●●●
●●
●●●●●●●● ●● ●●●●●●

0

01−Jul

01−Apr

10 step−ahead
1500

●
●

01−May

01−Jun

01−Jul

15 step−ahead
1500

●●
●● ● ●
●

●
●
●
●
● ●
●
●
●

●

RMSPE

RMSPE

●
●
●
●

1000

●

●

●
● ●
●
●●●●

500

●
●

●

1000

●
●
●●
●
●
●●
●●

500

●
●
●
●●● ●●●
●●●●●●
●●●●●

●●●●●
●● ●●●●●●●●●●
●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●
●●●●
●●●●●●●●●●●●●●●●●●●●●

0
01−Apr

01−May

01−Jun

●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●
●●●
●●●●●●●●●●●●●●●●●●

0

01−Jul

01−Apr

01−May

01−Jun

01−Jul

Figure 16: RMSPE for daily positives at different steps-ahead.

4.3

Step-ahead predictions

In this section, we test our model’s ability to predict the evolution of the epidemic (at least its first wave) from the short
to the medium term. Indeed, while the choice of a rigid parametric form for the mean function is penalizing in terms of
flexibility and fitting ability, it allows for extrapolation outside the observed domain and is supposed to provide robust
forecasts (at least in the short/medium term). Therefore, using the best model for the two indicators (i.e. baseline +
week-day additive effect), we calculated the out-of-sample Root Mean Squared Prediction Error (RMSPE) for:
• different fitting windows t = 1, . . . , t̃, where t̃ goes from the 1st of April up to the 19th of July
• different forecast horizons, say K ∈ {1, 5, 10, 15}
18

A PREPRINT - O CTOBER 27, 2020

1 step−ahead

5 step−ahead
●

200

200

●

150

●

RMSPE

RMSPE

●
●

●
●
●
●

100

●

●
●

●
●

●
● ●

50

●

●

●●
●

●

●

●

●

●
●● ●

●

●

●●

●●

●●●
●

●●

01−Apr

●

●

01−May

01−Jun

●
●●
●

●
●

100

●

01−Apr

●

●
●
●

●
● ● ●●●
●
●● ●
● ●
●●

●
●

●● ●
●●●●
●●
●

●
●●

●●●●
●●
●
●●● ●●●●●●●●● ●●●●●●
●●●
●
●●●●●●
●●●●●● ●●
●● ●●●●●●●●
●●●

0
01−May

●

150

●●●●
●
●
● ●
● ●
● ● ● ● ● ●●●● ●●● ●●
●●●●●●●
● ●●
●●●●●●●
●●●●●●●●●●●●
●●●
●●●● ●

01−Jun

01−Jul

●

●
●

100

●●
●

●

●

●
●
●
● ●●
●●
●●
●●
●●●● ●
●
●
●●●
●
●●●●●●
●

50

●

01−Apr

●

01−May

●

●

●

50

●

15 step−ahead

RMSPE

RMSPE

100

●●●
●

●●
●
●
●
●

0

01−Jul

●●
●

● ●
●
●

●●●●

●

●

200

●

●
●●
●

●●

●

●

●●
●

●

200
150

●●

●

●●

10 step−ahead

●

●

●

●

50

●

●
●
●● ●
●
●
●
●●
●
●●
●
●
●
●
●●● ●
●
●
●
●
●●
● ● ● ●● ●●
●
● ●●
●● ● ●●
●●
●
● ● ●●● ● ● ●●●
●

●
●

●

0

●

●

●
●●

150

01−Jun

●
●●●●
●●
●●●●●●●●●●●●●●●●●●●
●●●●
●●●●●
●●●●●●●
●●●●●●●●●●

0

01−Jul

01−Apr

01−May

01−Jun

01−Jul

Figure 17: RMSPE for daily deceased at different steps-ahead.

We recall that, given the fitting window set 1, . . . , t̃:
RMSPEt̃,K

v
u
K
u1 X
(y
− ŷt̃+j )
=t
K j=1 t̃+j

The RMSPEs for each steps-ahead are presented in Fig. 16 and 17. Results match the expectations as: (i) the error
decreases with the length of the fitting window; (ii) the error trend is more stable on larger testing windows (10-15
steps ahead vs 1-5 steps ahead); (iii) larger errors are made around the day of the peak. It can be seen nevertheless that
predictions are always reasonable at these time horizons.
4.4

Prediction of the peak day

Finally, we evaluate the model’s ability to predict the date of the peak. To do so, we estimate the model without
covariates, using all available data until K ∈ {15, 10, 5, 3, 2, 1} days before the observed peak. For the sake of
conciseness, we only report results for K ∈ {10, 5, 2, 1} as shown in Fig. 18 and 19.
When s = 1, the peak t̂ is directly expressed by the parameter p. When s 6= 1, after some algebra it can be seen that the
peak can still be computed analytically as:
log10 (ŝ)
t̂γ = p̂ +
.
ĥ
Confidence intervals are obtained through the same bootstrap procedure introduced in Sec. 3.4. The dashed grey vertical
lines represent the bounds of the confidence interval and the predicted date of the peak (confidence area is shaded with
the same grey). The solid vertical black line represents the "true" date of the peak (i.e. obtained via smoothing of the
observed counts through non-parametric polynomial approximations). The observed time-series is represented through
point and lines, where the black section is referred to the training window while the grey section is referred to the
testing (out-of-sample) window.
As expected, as we approach the real date of the peak, we predict it more accurately. Point predictions are very accurate
for both indicators since 5 days before the actual peak. At the same time, interval bounds get tighter and tighter as the
fitting interval approached the day of the peak and, in general, the day of the peak is always included in such bounds
(see Table 9 for exact numerical evaluation).
19

A PREPRINT - O CTOBER 27, 2020

Table 9: Delay (days) in point estimation of the peak
10
5
2
1
Delay Width Delay Width Delay Width Delay Width

Days before

-1
20

daily deceased
daily positives
(a)

37
106

-3
17

25
69
(b)

10 days before the peak

-4
1

6K
● ●
●
●

●

●

●

●

●●

●

●

●
●

●

●
● ●

●●

●

●
●

●

●

●
●

●

●
●
●

●
●
●●

●

●●
●
●●

●

●

●

● ●●● ●
●
● ●
●
●
●● ●● ●
● ●●●●
● ●●●
●
●
● ●● ●●
●
●
●
● ●● ●●● ●● ● ●●
● ● ● ● ● ● ● ●●●● ●●●●●●●●●●●●● ●●●●●●●●●

●
●

(c)

●●
● ●
●
●
●●●
●●

01−Mar

01−Apr

01−May

01−Jun

daily positives

daily positives

●
●● ●

●

0K

●

●

●
●

●

●●

●

●
●

●

2K

●

●

●
●

●

●
●
●

●
●●

●

●●
●
●●

●

●

●

● ●●● ●
●
● ●
●
●
●● ●● ●
● ●●●●
● ●●●
●
●
● ●● ●●
●
●
●
● ●● ●●● ●● ● ●●
● ● ● ● ● ● ● ●●●● ●●●●●●●●●●●●● ●●●●●●●●●

●

(d)

●●
● ●
●
●
●●●
●●

01−Mar

01−Apr

01−May

01−Jun

01−Jul

1 days before the peak
●

6K
● ●
●
●

●

●

●

●

●

●●

●

●

●
●

●

●
● ●

●●

●

●
●

●

●

●

●

●
●
●

●
●

●
●●

●

●●
●
●●

●

●

●

● ●●● ●
●
● ●
●
●
●● ●● ●
● ●●●●
● ●●●
●
●
● ●● ●●
●
●
●
● ●● ●●● ●● ● ●●
● ● ● ● ● ● ● ●●●● ●●●●●●●●●●●●● ●●●●●●●●●

●
●
●●
● ●
●
●
●●●
●●

01−Mar

●
●●

●
●

●● ●

01−Apr

01−May

01−Jun

daily positives

daily positives

●
●

●
● ●

0K

01−Jul

●
●●

●

0K

●

●
●●

●

2K

● ●
●
●

●

●

4K

●

●

4K

●● ●

●

2 days before the peak

6K

●
●●

●

●
●

2K

21
37

●
●
●●

●

4K

-3
2

5 days before the peak

●

6K

22
37

●

●● ●
● ●
●
●

●

●

●

●

4K

●

●●

●

●

●
●

●

●
● ●

●●

●

●
●

●

2K

●

●

●

●
●
●

●
●

●
●●

●

●●
●
●●

●

●

●

● ●●● ●
●
● ●
●
●
●● ●● ●
● ●●●●
● ●●●
●
●
● ●● ●●
●
●
●
● ●● ●●● ●● ● ●●
● ● ● ● ● ● ● ●●●● ●●●●●●●●●●●●● ●●●●●●●●●

●
●

0K

01−Jul

●●
● ●
●
●
●●●
●●

01−Mar

01−Apr

01−May

01−Jun

01−Jul

Figure 18: Estimation of the date of the peak for daily positives at different steps-before.

(a)

(b)

10 days before the peak

1000

5 days before the peak

1000

●

●

●

750

● ●●
●

●

●

●
●
●

●
● ●

●
●
●
●● ●
● ●●●
●
● ●

●

●

500

●

●
●

●

●

●
●●

250

●

● ●
● ●●
●

●

●●
●
●

●

●
●●
● ●
●
●

0

●
●

01−Apr

●
●

● ●
●
● ● ● ●●●
●
●● ●
●
●
● ●
● ● ● ●●●● ●●● ● ●
●● ● ●●
●
● ●● ●● ●
●
●●● ● ● ●●●●● ●●●● ●●●●●●
●●
●● ●●
●
●

●●●
●●●
●●●●●●

01−Mar

(c)

●
● ●

01−May

01−Jun

daily deceased

daily deceased

●

●
● ●

●
●

●

250

●

●

●
● ●
●

●●
● ●
●
●

●
●
●
●● ●
● ●●●
●
● ●
●
●

●

●

● ●
● ●●
●
●

●
●●

●

●●
●

●
●●
● ●

●
●

●
● ●
●
●

●●●
●●●
●●●●●●

01−Mar

01−Apr

●
●

● ●
●
●●

●
●

0

●
● ●
●
●

●●●
●●●
●●●●●●

01−Apr

●
●

● ●
●
● ● ● ●●●
●
●● ●
●
●
● ●
● ● ● ●●●● ●●● ● ●
●● ● ●●
●
● ●● ●● ●
●
●●● ● ● ●●●●● ●●●● ●●●●●●
●●
●● ●●
●
●

01−May

01−Jun

01−Jul

1 days before the peak
●
●

● ●●
●

●

250

●
●

●

●

1000

●

500

●

●●

01−Mar

01−May

●● ●●●
●● ●
●
●
● ●
● ● ● ●●●● ●●● ● ●
●● ● ●●
●
● ●● ●● ●
●
●●● ● ● ●●●●● ●●●● ●●●●●●
●●
●● ●●
●
●

01−Jun

daily deceased

daily deceased

750

●

● ●
● ●●
●

●
●●

(d)

●
●
●

●
●
●● ●
● ●●●
●
● ●

●

●

●

●

●

●

500

01−Jul

●

● ●●
●

●

●

0

2 days before the peak

1000

●
●

●

750

750

●

●

●
● ●
●

● ●●
●
●
●
●
●● ●
● ●●●
●
● ●

●

500

●

●
●

●

250

●

● ●
● ●●
●
●

●
●●

●

●●
●

●
●●
● ●

●
●

●
● ●
●
●

●●●
●●●
●●●●●●

01−Mar

01−Apr

●
●

● ●
●
●●

●
●

0

01−Jul

●
●

●

01−May

●● ●●●
●● ●
●
●
● ●
● ● ● ●●●● ●●● ● ●
●● ● ●●
●
● ●● ●● ●
●
●●● ● ● ●●●●● ●●●● ●●●●●●
●●
●● ●●
●
●

01−Jun

01−Jul

Figure 19: Estimation of the date of the peak for daily deceased at different steps-before.
20

A PREPRINT - O CTOBER 27, 2020

5

Discussion and further work

We presented an approach to modeling and prediction of epidemic indicators that has proven useful during the first
outbreak of COVID-19 in Italy. The model has been validated on publicly available data, and has proved flexible
enough to adapt to different indicators.
Summarizing the results, we would like to emphasize that the proposed Richard’s curve model describes properly the
growth in the number of COVID-19 daily positives and daily deceased, despite its simplicity. Indeed, it is able to
reflect properly the trend of the considered daily incidence indicators and also allows for the straightforward inclusion
of exogenous information. Basic covariates such as the week-day effect proved to sensibly enhance model fitting
and prediction accuracy. While we have illustrated results at the national level, the model can clearly be used also at
regional/local level (including specific local effects).
The maximum likelihood approach so far considered is rather stable, as long as reasonable starting values are passed to
initialize the algorithm. Of course, different approaches could be investigated. In further work, a Bayesian approach
will be experimented in order to overcome possible issues with the asymptotic properties of the maximum likelihood
estimator. Notably, implementation of the No-U-Turn Sampler (NUTS) algorithm for the estimation of non-linear
models might be a valid working solution. Additionally, a Bayesian approach may also be used to include spatial
dependence into the modeling framework and also to relax the first-order Markov assumption for taking into account
more complex temporal dependence. In particular, the latter may be key in order to adapt the introduced Richard’s curve
model for the nowcasting of prevalence indicators, e.g. current positives and current intensive care units occupancy.
Indeed, any modeling effort shall account for the strong temporal dependence between subsequent counts stemming
from the fact that daily counts at time t potentially include units which are in stock since times τ < t. Furthermore, as
specified in Section 2.1.2, prevalence indicators are non-monotonic and their value is the result of the combination of
the incidence components building up each of those. These two last issues may be addressed by adapting the Richard’s
response function to accommodate non-monotonicity and/or by hierarchically specifying a model for the prevalence
indicators through the combination of models for their incidence components. A successful attempt in accurately
nowcasting the intensive care units occupancy is given in [29].

6

Software

Software in the form of R code, together with a sample input data set and complete documentation is available on
request from the corresponding author.

References
[1] S. Flaxman, S. Mishra, A. Gandy, H. J. T. Unwin, H. Coupland, T. A. Mellan, H. Zhu, T. Berah, J. W. Eaton, P. N. P.
Guzman, N. Schmit, and L. Callizo. Estimating the number of infections and the impact of non-pharmaceutical
interventions on COVID-19 in European countries: technical description update. arXiv:2004.11342, 2020.
[2] N. C. Peeri, N. Shrestha, S. Rahman, R. Zaki, Z. Tan, S. Bibi, M. Baghbanzadeh, N. Aghamohammadi, W Zhang,
and U. Haque. The SARS, MERS and novel coronavirus (COVID-19) epidemics, the newest and biggest global
health threats: what lessons have we learned? International Journal of Epidemiology, 2020.
[3] Kaihao Liang. Mathematical model of infection kinetics and its analysis for COVID-19, SARS and MERS.
Infection, Genetics and Evolution, 82:104306, 2020.
[4] O. Diekmann, H. Heesterbeek, and T. Britton. Mathematical Tools for Understanding Infectious Disease Dynamics.
Princeton University Press, Princeton, 2013.
[5] Y. C. Chen, P. E. Lu, and C. S. Chang. A time-dependent SIR model for COVID-19. arXiv:2003.00122, 2020.
[6] G. Giordano, F. Blanchini, R. Bruno, P. Colaneri, A. Di Filippo, A. Di Matteo, and M. Colaneri. Modelling the
COVID-19 epidemic and implementation of population-wide interventions in Italy. Nature Medicine, page to
appear, 2020.
[7] Marino Gatto, Enrico Bertuzzo, Lorenzo Mari, Stefano Miccoli, Luca Carraro, Renato Casagrandi, and Andrea
Rinaldo. Spread and dynamics of the COVID-19 epidemic in Italy: Effects of emergency containment measures.
Proceedings of the National Academy of Sciences, 117(19):10484–10491, 2020.
[8] Jonas Dehning, Johannes Zierenberg, F. Paul Spitzner, Michael Wibral, Joao Pinheiro Neto, Michael Wilczek, and
Viola Priesemann. Inferring change points in the spread of COVID-19 reveals the effectiveness of interventions.
Science, 2020.
21

A PREPRINT - O CTOBER 27, 2020

[9] John P.A. Ioannidis, Sally Cripps, and Martin A. Tanner. Forecasting for COVID-19 has failed. International
Journal of Forecasting, 2020.
[10] J. Baek, V. F. Farias, A. Georgescu, R. Levi, T. Peng, D. Sinha, J. Wilde, and A. Zheng. The limits to learning an
SIR process: granular forecasting for COVID-19. arXiv.2006.06373, 2020.
[11] Henrik Salje, Cécile Tran Kiem, Noémie Lefrancq, Noémie Courtejoie, Paolo Bosetti, Juliette Paireau, Alessio
Andronico, Nathanaël Hozé, Jehanne Richet, Claire-Lise Dubost, Yann Le Strat, Justin Lessler, Daniel LevyBruhl, Arnaud Fontanet, Lulla Opatowski, Pierre-Yves Boelle, and Simon Cauchemez. Estimating the burden of
SARS-CoV-2 in France. Science, 2020.
[12] G. Grasselli, A. Pesenti, and M. Cecconi. Critical care utilization for the COVID-19 outbreak in Lombardy, Italy:
Early experience and forecast during an emergency response. Journal of the American Medical Association,
323:1545–1546, 2020.
[13] G. Sebastiani, M. Massa, and E. Riboli. COVID-19 epidemic in Italy: evolution, projections and impact of
government measures. European Journal of Epidemiology, 35:341–345, 2020.
[14] S. Cabras. A Bayesian deep learning model for estimating COVID-19 evolution in Spain. arXiv.2005.10335,
2020.
[15] P. Girardi, L. Greco, V. Mameli, M. Musio, W. Racugno, E. Ruli, and L. Ventura. Robust inference from robust
Tsallis score: application to COVID-19 contagion in Italy. STAT, 2020.
[16] C. Ritz, F. Baty, J.C. Streibig, and D. Gerhard. Dose-response analysis using R. PLoS ONE, 10:e0146021, 2015.
[17] FH Hsu, CJ Nelson, and WS Chow. A mathematical model to utilize the logistic function in germination and
seedling growth. Journal of Experimental Botany, 35(11):1629–1640, 1984.
[18] M Grossman and BB Bohren. Logistic growth curve of chickens: heritability of parameters. Journal of Heredity,
76(6):459–462, 1985.
[19] Anne Krislov Morris and Wendy Kuhn Silk. Use of a flexible logistic function to describe axial growth of plants.
Bulletin of Mathematical Biology, 54(6):1069–1081, 1992.
[20] Joseph Berkson. Application of the logistic function to bio-assay. Journal of the American Statistical Association,
39(227):357–365, 1944.
[21] Daniel E Wachenheim, John A Patterson, and Michael R Ladisch. Analysis of the logistic function model:
derivation and applications specific to batch cultured microorganisms. Bioresource Technology, 86(2):157–164,
2003.
[22] Even Tjørve and Kathleen M.C. Tjørve. A unified approach to the richards-model family for use in growth
analyses: Why we need only two model forms. Journal of Theoretical Biology, 267(3):417 – 425, 2010.
[23] KMC Tjørve and E Tjørve. The use of Gompertz models in growth analyses, and new Gompertz-model approach:
An addition to the unified-richards family. PLoS ONE, 12(6):e0178691, 2017.
[24] FJ Richards. A flexible growth function for empirical use. Journal of experimental Botany, 10(2):290–301, 1959.
[25] L. Scrucca. GA: A package for genetic algorithms in R. Journal of Statistical Software, 53:1–37, 2013.
[26] Bradley Efron. The estimation of prediction error: covariance penalties and cross-validation. Journal of the
American Statistical Association, 99(467):619–632, 2004.
[27] Peter Hall and Tapabrata Maiti. On parametric bootstrap methods for small area prediction. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 68(2):221–238, 2006.
[28] Bradley Efron. Bayesian inference and the parametric bootstrap. The Annals of Applied Statistics, 6(4):1971,
2012.
[29] Alessio Farcomeni, Antonello Maruotti, Fabio Divino, Giovanna Jona Lasinio, and Gianfranco Lovison. An
ensemble approach to short-term forecast of covid-19 intensive care occupancy in italian regions. arXiv preprint
arXiv:2005.11975, 2020.

22

A PREPRINT - O CTOBER 27, 2020

Appendix
Gradients
In order to make the optimization procedure robust, gradients and Hessians used for the estimation (optimization routine
on the log-likelihood) have been computed analytically. This section provides insights about their derivation for the
log-likelihoods at hand. For the sake of clarity, in the sequel, we will invert the previous notation and denote the
functions of interest as functions of the parameters, given the observed time points: e.g. µ̃θ (t) becomes µ̃t (θ). We first
provide the computations for the gradient of the log-likelihood for both Poisson and Negative Binomial distributions
by considering their mean function µ̃t (θ) as a whole. Afterwards, we show the gradients and introduce the Hessians
specific to λ̃t (γ), as it is the most cumbersome component of the mean to derive with respect to its parameters.
Poisson Gradient
Let q denote any of the elements of θ, vector of parameters characterizing the mean function µ̃t (θ). The generic
derivative with respect to the component q of θ for the Poisson log-likelihood Poi(µ̃t (θ)) is:
T
T
X
X
∂
∂
∂
lP oi (γ|y) = −
µ̃t (θ) +
yt
log(µ̃t (θ)) =
∂q
∂q
∂q
t=1
t=1
T
T
X
X
∂
1 ∂
yt
=−
µ̃t (θ) +
µ̃t (θ).
∂q
µ̃
t (θ) ∂q
t=1
t=1

(5)

Negative Binomial Gradient
The Negative Binomial NB (ν, µt (θ)) presents the additional parameter ν, which does not affect the mean function but
controls for the dispersion. In the following, we provide the first derivative with respect to ν and with respect to the
generic element q of θ, respectively.
The first derivative with respect to ν of the log-likelihood is:
∂
lN B (ν, θ|y) = T (log(ν) − ψ(ν))+
∂ν

T 
X
µt (θ) − yt
+
ψ(ν + yt ) − log (µt (θ) + ν) +
µt (θ) + ν
t=1

(6)

where ψ(·) denotes the digamma function.
The generic derivative with respect to q of the log-likelihood is:
T
X
yt + ν ∂
∂
lN B (ν, γ|y) = −
µ̃t (θ)+
∂q
µ̃
(θ) + ν ∂q
t
t=1

+

T
X
t=1

(7)

yt ∂
µ̃t (θ).
µ̃t (θ) ∂q

Richards’ Gradient
Derivation of the gradient µ̃t (θ) can be obtained by deriving separately (but appropriately) each of the pieces composing
it. Computations are straightforward for all components, but for the Richard’s first differences parameters, which can in
turn be divided as:
∂
∂
∂
λ̃t (γ) =
λt (γ) −
λt−1 (γ)
∂γi
∂γi
∂γi
23

A PREPRINT - O CTOBER 27, 2020

The Richards’ function gradient is composed of the following four terms:
∂

∂r λt (γ)


∂

 λt (γ)
 ∂h


∇λt (γ) = 
∂

 λt (γ)
 ∂p



∂
∂s λt (γ)
which can be computed as follows.
r
(1 + 10h(p−t) )s



r
b+
(1 + 10h(p−t) )s



∂
∂
λt (r) =
∂r
∂r


b+

∂
∂
λt (h) =
∂h
∂h



=

1
,
(1 + 10h(p−t) )s

=

= −r · s · (1 + 10h(p−t) )−s−1 10h(p−t) (p − t) log(10),
∂
∂
λt (p) =
∂p
∂p


b+

r
(1 + 10h(p−t) )s


=

= −r · s · (1 + 10h(p−t) )−s−1 10h(p−t) h log(10),

r
=
(1 + 10h(p−t) )s

−s


= −r · 1 + 10h(p−t)
log 1 + 10h(p−t)

∂
∂
λt (s) =
∂s
∂s



b+

Log-scale
In the R implementation, the log-likelihood has been parametrized on the log-scale for all the parameters defined on
R+ in order to ease the optimization process under he positivity constraint. This means that given q ∈ {b, r, p, s}, the
log-likelihood uses log(q) = v, where q = ev . This implies that, when we do the derivative, we have to take into
account the jacobian as a result of the transformation:
∂
∂
∂ev
∂
∂
λt (γ) = v λt (γ)
= v λt (γ) · ev =
λt (γ) · q.
∂v
∂e
∂v
∂e
∂q

(8)

Therefore, each derivative must be multiplied by ev = q.

Hessians
Hessians used for the estimation procedure of the model (optimization routine on the log-likelihood) have been
computed analytically. In the sequel, we first provide the hessian for the log-likelihod of Poisson and Negative Binomial
by considering λt (γ) as a whole.
Poisson Hessian
Let q and f denote any pair of the parameters characterizing the mean function µ̃t (θ).
The mixed second derivative with respect to the components q and f of θ for the Poisson log-likelihood is:
T
T
X
X
∂2
yt − µ̃t (θ) ∂ 2
yt ∂
∂
lP oi (θ|y) =
µ̃t (θ) −
µ̃ (θ) µ̃t (θ).
2 ∂q t
∂xf
µ̃
(θ)
∂qf
µ̃
(θ)
∂f
t
t=1
t=1 t

24

A PREPRINT - O CTOBER 27, 2020

The second derivative with respect to the components q for the Poisson log-likelihood is:

2
T
T
X
X
∂2
∂
yt − µ̃t (θ) ∂ 2
yt
lP oi (θ|y) =
µ̃t (θ) −
µ̃t (θ) .
∂q 2
µ̃t (θ) ∂q 2
µ̃ (θ)2 ∂q
t=1
t=1 t
Negative Binomial Hessian
Let q and f denote any pair of the parameters characterizing the mean function µt (θ).
The mixed second derivative with respect to q and f of the Negative Binomial log-likelihood is:
T

X
∂2
lN B (θ|y) =
∂xf
t=1


yt
∂
∂
yt + ν
−
µ̃t (θ) µ̃t (θ)
(µt (θ) + ν)2
µt (θ)2 ∂q
∂f
 2
T 
X
yt
yt + ν
∂
+
−
µ̃t (θ).
µ̃t (θ) µ̃t (θ) + ν ∂qf
t=1


+

The second derivative with respect to q of the Negative Binomial log-likelihood is:
T

2

yt
yt + ν
∂
−
µ̃
(θ)
t
(µ̃t (θ) + ν)2
µ̃t (θ)2
∂q
 2
T 
X
yt
yt + ν
∂
+
−
µ̃t (θ).
µ̃t (θ) µ̃t (θ) + ν ∂q 2
t=1

X
∂2
lN B (θ|y) =
2
∂q
t=1



+

In the Negative Binomial case, we must recall the presence of the additional parameter ν. The second derivative with
respect to ν of the Negative Binomial log-likelihood is:


0
∂2
1
lN B (θ|y) = T
− ψ (ν) +
∂ν 2
ν

T 
X
1
µ̃t (θ) − yt
0
ψ (ν + yt ) −
+
−
µ̃t (θ) + ν
(µ̃t (θ) + ν)2
t=1
where ψ(·) and ψ 0 (·) denote the digamma and the trigamma function, respectively.
The mixed derivative with respect to ν and the generic element q of γ is:
T

X yt − µ̃t (θ) ∂
∂2
lN B (γ|y) =
µ̃t (θ)
∂νq
(µ̃t (θ) + ν)2 ∂q
t=1
Richards’ Hessian
As for the gradient, the same holds for the Hessian of the first differences of the Richards function, which would be
only one interesting computation to show. Also here:
∂2
∂2
∂2
λ̃t (γ) =
λt (γ) −
λt−1 (γ)
∂γi γj
∂γi γj
∂γi γj
In particular, the resulting Hessian is a 4 × 4 matrix such that:
[H (λt (γ))]ij =

∂2
λt (γ),
∂γ i γ j

i, j ∈ {1, . . . , 4} .

Computations are straightforward for most of the terms, but the final result counts 10 terms (the Hessian matrix is
symmetric) and some of those terms are cumbersome to report. Therefore, we won’t include these in the appendix. The
reader is invited to contact the authors if he is interested in their detailed computation.
25

A PREPRINT - O CTOBER 27, 2020

Log-scale
In the R implementation, the log-likelihood has been parametrized on the log-scale for all the parameters defined on R+
in order to ease the optimization process under the positivity constraint. This means that given two generic elements,
say q and f , of the parameters’ vector γ, the log-likelihood uses log(q) = v and log(f ) = u, where q = ev and f = eu .
The Jacobian inclusion has two implications on the Hessian.
When computing the mixed derivative, we need to account for the transformation of both terms (if both are on the log
scale):




∂2
∂eu
∂
∂
∂
∂
λ
(γ)
λt (γ) =
λt (γ) =
=
t
∂v∂u
∂v ∂u
∂v ∂eu
∂u



 v
∂
∂
∂
∂
∂e
u
u
(9)
λ
(γ)
·
e
λ
(γ)
·
e
=
=
=
t
t
u
v
u
∂v ∂e
∂e
∂e
∂v


∂
∂ ∂
∂
λt (γ) · eu · ev =
= v
λt (γ) · q · f.
u
∂e
∂e
∂q ∂s
Therefore, each mixed derivative

∂2
∂xs λt (γ)

must be multiplied by both ev = q and eu = f .

When computing the second derivative for v, we need to recall that the first derivative contains the jacobian, so:




∂
∂
∂2
∂
∂
v
λt (γ) =
λt (γ) = v
λ
(γ)
·
e
· ev =
t
∂v
∂v ∂v
∂e
∂ev


∂ ∂
∂
∂ v
v
=
λ
(γ)
·
e
+
λ
(γ)
·
e
· ev =
t
t
∂ev ∂ev
∂ev
∂ev
(10)


∂
∂
∂ ∂
λt (γ) · q +
λt (γ) ·
q ·q =
=
∂q ∂q
∂q
∂q
2
∂
∂
= 2 λt (γ) · q 2 +
λt (γ) · q.
∂q
∂q

26

