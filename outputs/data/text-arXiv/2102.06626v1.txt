Do-calculus enables causal reasoning with latent variable models
Preprint, compiled February 15, 2021
Sara Mohammad-Taheri1 , Robert Ness2 , Jeremy Zucker3 , and Olga Vitek1
1

∗

Khoury college of computer sciences, Northeastern University, Boston, MA, USA
2
Altdeep, Boston, MA, USA
3
Pacific Northwest National Laboratory, Richland, WA

Latent variable models (LVMs) are probabilistic models where some of the variables are hidden during training.
A broad class of LVMshave a directed acyclic graphical structure. The directed structure suggests an intuitive
causal explanation of the data generating process. For example, a latent topic model suggests that topics cause the
occurrence of a token. Despite this intuitive causal interpretation, a directed acyclic latent variable model trained
on data is generally insufficient for causal reasoning, as the required model parameters may not be uniquely
identified. In this manuscript we demonstrate that an LVM can answer any causal query posed post-training,
provided that the query can be identified from the observed variables according to the do-calculus rules. We
show that causal reasoning can enhance a broad class of LVM long established in the probabilistic modeling
community, and demonstrate its effectiveness on several case studies. These include a machine learning model
with multiple causes where there exists a set of latent confounders and a mediator between the causes and
the outcome variable, a study where the identifiable causal query cannot be estimated using the front-door or
back-door criterion, a case study that captures unobserved crosstalk between two biological signaling pathways,
and a COVID-19 expert system that identifies multiple causal queries.

1

Introduction

intuition into the ability to answer causal queries would greatly
extend the power of LVMs. An LVM that could answer ad hoc
Latent variable models (LVMs) are probabilistic models of a causal queries would be advantageous as compared to alternative
joint distribution on a set of variables, where some of the vari- methods of causal inference, e.g. the ”plug-in“ estimator [6],
ables are unobserved (i.e., hidden, latent) during training. These that require building a new statistical model every time a new
models have had a major impact on applications ranging from causal query arises. Unfortunately, due to the non-uniqueness
natural language processing, social science, computer vision, to of parameters during training, LVM-based estimates of causal
computational biology. A broad class of LVMs have a directed queries are in general incorrect.
acyclic graphical structure. Canonical examples of directed This manuscript proposes an approach for alleviating the chalacyclic graphical LVMs include topic models, hidden Markov lenge above. Using Bayesian perspective, we demonstrate that
models, Gaussian mixture models [1], and deep generative latent training an LVM, and applying probabilistic inference algovariable models such as variational autoencoders [2].
rithms to the trained model yields an accurate estimator of a
LVMs contain parameters that must be learned from data. Once causal estimand, provided that the estimand is identifiable from
the model is trained, it can answer numerous marginal and con- the training variables and the graph structure according to a set
ditional queries with respect to its variables using computational of rules called the do-calculus.
inference algorithms, including graphical modeling inference al- We illustrate the generality and the practical utility of causal reagorithms such as belief propagation [3], gradient-based sampling soning with LVMs in four case studies. The first is an LVM with
techniques such as Hamiltonian Monte Carlo [4] or stochastic multiple causes, similar to the Box Office revenue model in [7],
variational inference [5]. The ability to answer multiple queries modified to include a mediator [8, 9]. Such structure underlies
after a single training is particularly valuable for probabilistic many high-dimensional problems in generative machine learnreasoning systems, e.g. in natural language processing or medi- ing. The second case study is a deceptively simple causal LVM,
cal diagnosis, where large-scale models are expensive to train known as the new Napkin problem [10]. It shows the applicabiland maintain. When variables are latent during training, some ity of the proposed approach to a graph topology where causal
model parameters and the associated model-based queries may reasoning is challenging. The third case study is an LVM that
not be uniquely identified.
captures unobserved crosstalk between two signaling pathways.
The directed graph structure of latent variable models often The fourth case study uses a molecular biology expert system
suggests intuitive causal interpretations. Indeed, for many LVMs to model host response to viral infection of SARS-CoV-2 the
the causal semantics is built into the model definition. For novel coronavirus responsible for the COVID-19 pandemic. In
example in natural language processing, the directed structure of this case, multiple causal queries were identified by introducing
a latent topic model suggests that topics drive the occurrence of latent variables that isolate each causal effect from the rest of
token. In molecular biology, the directed structure may suggest the system.
a process by which an interaction between a virus and a host
protein dysregulates the immune response, even in the absence
of measurements of that interaction. Formalizing that causal
*correspondence: ovitek@northeastern.edu

Preprint doi

Publication doi

arXiv:2102.06626v1 [cs.LG] 12 Feb 2021

Abstract

Preprint – Do-calculus enables causal reasoning with latent variable models

2
2.1

Background
Notation

Let bold face upper case letters such as X = {X1 , ..., X J } be a
set of random variables and an upper case letter such as Xi be
a single variable. Note that Xi can be multivariate. Let x be an
instance of X and xi be an instance of Xi . Let P(x1 , ..., x j ) be the
joint probability distribution of the event X = x = {x1 , ..., x j }.
P(Xi = xi |X j = x j ) is a conditional probability distribution for
the event Xi = xi given X j = x j . In this manuscript, we simplify
the joint distribution as P(x), and conditional distribution as
P(xi |x j ). Let G be a directed acyclic graph (DAG) with nodes
X, where Pa(Xi ) are the parents of a node Xi in G. The causal
Markov condition assumes
that P(x) factorizes along the strucQ
ture of G, i.e. P(x) = xi ∈X P(xi |Pa(xi )).
2.2

Latent variable models

Latent variable models (LVM) are probabilistic models of P(x),
where some variables are not observed during training. LVMs
are generative, in the sense that they allow us to generate samples
from P(x). A particularly attractive class are LVM with directed
acyclic graph structures. Beyond representing conditional independence on P(x), the structures typically have an intuitive
causal interpretation. In this manuscript we refer to latent variable models with DAG structures and causal interpretation as
causal LVM.

2

The average causal effect of X on Y is a special case of causal
query defined as E[Y|do(x)] − E[Y].
A causal query on a joint interventional distribution is identifiable if it can be transformed into an equivalent probabilistic
expression on the joint observational distribution. This can be
determined by the following criteria.
The back-door criterion holds as long as there are no unobserved confounders of cause and effect. If the back-door
criterion
holds, P(Y|do(x0 )) is identifiable and is given by
R
0
P(y|x , z)P(z)dz where Z is a set of variables that satisfies
z
the back-door criterion relative to X and an effect Y in a DAG
G.
The front-door criterion holds even when there is an unobserved confounder, but there exists a mediator (M) between
cause and effect that is shielded from confounding. If the front0
door
)) is identifiable and is given by,

R R criterion holds, P(Y|do(x
0
P
(Y|m,
x)P
(x)dx
P
(m|x
)dm [8, 9]. Front-door criteG
G
G
m x
rion is particularly useful when the back-door criterion does
not hold. For example, the back-door criterion does not hold in
Fig. 1 (a) and (b) but the front-door criterion does hold in Fig. 1
(b).

The back-door and front-door criteria are sufficient but not necessary for causal identifiability. The do-calculus, comprised of
three graph-mutilation-based rules [14], helps determine other
identifiable causal queries. A causal query containing a do()
A latent mediator is a latent variable with incoming and outgo- operator is identifiable if the do-calculus transforms it into an
ing edges. A node Xk is a collider if it is part of a Xi ← Xk → X j equivalent do-free estimand. The do-calculus estimands are
structure with no edges connecting Xi and X j . A latent con- non-parametric in the sense that they do not impose constraints
founder is a latent node affecting both the cause and the effect. on P(x).
After the training, a causal LVM is a probabilistic expert system Depending on the causal query, the graph, and the set of lathat can answer many causal and non-causal queries about vari- tent variables, a number of sound and complete algorithms and
ables in X by applying probabilistic inference algorithms such implementations help determine whether the query is identias MCMC and stochastic variational inference (SVI).
fiable [15, 16], and, if the query is identifiable, generate an
estimand [17, 15, 18, 19].
2.3 Causal inference
An intervention on a target variable X fixes the variable to
a constant x (denoted do(x) [8]), rendering it independent of
its causes [11, 12]. The causal effect of X on Y is denoted
P(y|do(x)).
Graph mutilation in a causal graphical model is a method for
simulating the effect of an intervention. Graph mutilation severs the incoming edges to the target node, and fixes it to the
intervention value [13] rendering it independent of its causes.
In the following we denote G X̄ the graph produced by mutilating G to remove all incoming edges to X, and PG X̄ (x) denotes
the new distribution created by the mutilation. Sampling from
P(y|do(x)) is achieved by applying algorithmic inference to G X̄
and sampling from PG X̄ (y|x).
A causal query is any probabilistic query that conditions on an
intervention, such as P(x j |do(xi ), xk ) or E[x j |do(xi )]. It is answered either by applying inference algorithms to the mutilated
graph representing the joint interventional distribution, or by
estimating the equivalent probabilistic expression on the joint
observational distribution. In other work, the term causal query
includes counterfactual queries [8]. While many counterfactual
queries reduce to conditioning on interventions, we consider
general counterfactual queries beyond the scope of this work.

2.4

Expressing model misspecification

Model misspecification is a common challenge in modeling joint
probability distributions, particularly when some variables are
latent. Acyclic directed mixed graph (ADMG) [16] structures
help account for potential model misspecification. ADMG ignore latent mediators and colliders, and only consider the effect
of latent confounding. The presence of latent confounders in an
ADMG is indicated with bidirected (↔) edges.
An ADMG has several properties. First, it is associated with a
model that has the same equality constraints (such as conditional
independence relationships) on the observed joint probability
distribution as those obtained by marginalizing out the latent
variables from the original LVM [20]. At the same time, the
model associated with the ADMG does not contain inequality constraints (such as nonparametric bounds on instrumental
variables) that may exist in the original LVM [21, 22]. Second, an infinite set of causal LVMs can project onto the same
ADMG. Third, any causal query in an ADMG identifiable by
the do-calculus rules is also identifiable in every causal LVM
that projects onto that ADMG [16]

Preprint – Do-calculus enables causal reasoning with latent variable models

3

ZZ
165
165
=
(
=
PPGGX̄ (Y
0✓ 0
X̄
✓U
✓U✓U
UU
UU
U
l l
l l
166
166
mm
Z
Z
Developing estimators of causal effects of a set of variables X
LL
LL
167
on a variable Y has been subject of much research. E.g., the 167
(
== PPGGX̄ (Y
X̄
168
168
mm
plug-in estimator [6] is a straightforward approach, that assumes
X
Z
XX
X
Z
Y
M
Y
j
j
Y
M
Y
j
j
169
169
a parametric model for the conditional distributions appearing
(Y
== PPGG(Y
170
170
in a do-calculus-based estimand. If the formula for calculatmm
✓Z
✓Z
ZZ
171
171
0✓ 0
0✓ 0
✓X
✓X✓X
✓M
✓Y
✓M
✓Y✓Y
X
Y
ing the estimand is complicated and includes many conditional 172
172
==
P
J
J
J
J
distributions, one has to make parametric assumptions for each 173
mm x x
173
(a)
(b)
(a)
(b)
distribution. Other authors [23, 7, 24] have developed genera- 174
(a)
(b)
174
tive machine learning modeling techniques by relying on the 175
Eq.(1)
(1)holds
holdsbeb
Eq.
175
presence of multiple causes or the proxy variables.
Figure
1.Plate
Plate
representationofof
ofLVM.
LVM.
Circular
white/gray
nodes
Figure
representation
Circular
white/gray
nodes
(m|x0 )0
Figure
1: 1.Plate
representation
LVM.
Circular
white/gray
nodes
GGX̄X̄. .PPGGX̄ (m|x
176
176
X̄
areobserved/latent
observed/latent
variables.Square
Squaregray
graynodes
nodes
areare
theassociated
associated
are
variables.
Square
are
the
are
observed/latent
variables.
gray
nodes
the
associated
ates
G
.
ates
G
.
Hence
177
X̄X̄ Henc
Many algorithms efficiently estimate the causal effect when the 177
parameters.
Each
parametersuch
suchas
as✓U
✓U
has
prior
distribution,
e.g. e.g.
parameters.
Each
parameter
such
a aprior
distribution,
e.g.
Uhas
parameters.
Each
parameter
as
θ
has
a
prior
distribution,
from
the
backd
from
the
backdo
178
back-door criterion holds [25, 26, 27]. Famous examples include 178 ✓U✓U⇠⇠PP(q(q✓ ✓ ),),where
where
hyperparameter.
Each
variable
isisa ahyperparameter.
Each
variable
θU ∼ P(qθU ), where
qθU isq✓qaU✓Uhyperparameter.
Each
variable
isisis
condiUU
sion
on
the
rig
sion
on
the
righ
179
179
the g-formula [28], the inverse probability weighting (IPW) tionally
conditionally
independent
non-descendents
given
parents.
conditionally
independent
ofofitsitsnon-descendents
given
itsitsparents.
independent
of its non-descendents
given its
parents.
(a) Multidooradjustmen
adjustme
door
180 (a)
[29], and Targeted Maximum Likelihood Estimators (TMLE), 180
Multi-cause
model
without
mediator.PP
|do(x))
notnonnonMulti-cause
model
without
mediator.
(Y(Y
|do(x))
isisnot
cause (a)
model
without
mediator.
P(Y|do(x))
is
not
non-parametrically
thatisisderived
derivedf
that
181
parametrically
identified.
(b)Multi-cause
Multi-cause
modelwith
with
mediator.
a family of doubly-robust estimators combining the g-formula 181
parametrically
identified.
(b)
model
a amediator.
identified.
(b) Multi-cause
model
with a mediator.
P(Y|do(x))
is non182
182
P
(Y
|do(x))
is
non-parametrically
identified.
P (Y |do(x))
is non-parametrically identified.
and IPW. Augmented IPW [30, 31] is a doubly robust semi- parametrically
identified.
Thelemma
lemmaillu
illu
The
183
parametric approach that goes beyond back-door criterion in 183
identifiedby
bythth
identified
184
specific settings. For models with a single cause and a single 184
duringtraining,
training
during
185
outcome, [32] propose doubly robust semiparametric estimators 185
a causal
query on the mutilated LVM is an estimand identified
Methods
3.3.Methods
is
a
valid
do-c
is
a
valid
do-ca
186
186
primal IPW (PIPW) and dual IPW (DIPW) that do not require by the do-calculus.
biningthis
thisproc
pro
187 InInthis
187
thissection
sectionwe
weshow
showthat
thattraining
trainingaacausal
causalLVM
LVMthen
then bining
the back-door criterion to hold.
estimator
for
estimator
for
tht
188 applying
188
applyinggraphical
graphicalinference
inferenceon
onthe
thetrained
trained mutilatedmodel
model
Proof. According
to the do-calculus,
a causalmutilated
query involving an
[33] proposed weighted empirical risk minimization (WERM- 189
theoremusing
usingc
189 isisequivalent
equivalenttotoestimating
estimatingaado-calculus
do-calculusidentifiable
identifiableestiesti- theorem
intervention on X transforms a probability distribution encoded
ID), a general probabilistic inference technique for any do- 190
alsoprovide
provideanan
190 mand.
mand.Taking
TakingaaBayesian
Bayesianview,
view,we
wefirst
firstdemonstrate
demonstratethis
thisinin also
by PG (.), to a distribution encoded by PGX̄ (.). Then, given inference
ainferenceininthe
calculus-identified estimand. Unfortunately at the time of writ- 191
th
191 the
thespecial
specialcase
caseofofFig.
Fig.1(b),
1(b),where
wherethe
thecausal
causaleffect
effectofofXXon
on
ground truth parameterization of PG (.), exact inference on PGX̄ (.)
ing its implementation was not publicly available for evaluation. 192
192 YYisisidentifiable
identifiableaccording
accordingtotothe
thefront-door
front-doorcriterion.
criterion.Then
Then Theorem
TheoremAssum
Assu
samples from the query distribution.
193 we
weshow
showthat
thatthis
thisisistrue
truefor
forany
anyidentifiable
identifiablecausal
causalquery
queryinin tifiable
For problems with a network structure, data, and an identifiable 193
tifiablevia
viado-c
do194
arbitrary
causal
LVM.
ananarbitrary
Assume
a causalcausal
DAGLVM.
G
as in Fig. 1(b), where X, M, and Y are
causal query, the ananke library [34, 35] suggests appropriate 194
during
training
during
training.
195
observed
variables,
and
U
is latent, and
the
query
PGground
(Y|do(x0 )).
estimators (including IPW, AIPW, g-formula, PIPW and DIPW) 195
exactsampling-b
sampling
exact
LemmaAssume
Assumethe
theparameters
parametersofofan
anLVM
LVMare
arethe
theground
Lemma
196
196
Modeling
ideal
interventions
with
graph
mutilation
implies
that
and the corresponding estimate. The Causal Fusion platform
an
estimator
an
estimator
ofof
truthparameters.
parameters.
Then
exact
graph-based
probabilistic
truth
Then
exact
graph-based
probabilistic
0
197
PG (Y|do(x
)) =
P acausal
(Y|x0 ). query
Hence,
valueasasthe
thenum
nu
[19] is another tool that takes as input a DAG and a causal query, 197
X̄causalquery
inference
onthe
themutilated
mutilatedLVM
LVMisisan
an value
inference
ofofaG
on
198
0
0
and investigates the identifiability of the query. If the query is 198
estimand
identified
by
the
do-calculus.
estimand
identified
by
the
do-calculus.
P
(Y|do(x
))
=
P
(Y|x
)
G
G X̄
199
Z
identifiable, it provides a full derivation of the do-calculus-based 199
Proof. Assume
Assum
Proof.
200
200
0
formula.
observed
durin
observed
during
=
P
(Y,
u,
m|x
)dmdu
GX̄
201
201
u,m
butionencoded
encoded
bution
The methods above start with a pre-specified causal query, derive 202
!
202
Z Z
Proof. According
Accordingtotothe
thedo-calculus,
causalquery
queryinvolvinvolvProof.
0do-calculus,a a0causal
0
Boththe
themodel
mode
an estimand for that query based on theoretical premises such 203
203 =
PGX̄ (Y|u, m,
xX)P
PGX̄ (m|x
)dm Both
GX̄ (u|m, xa )du
ingm
intervention
on
transforms
probability
distribuananintervention
on
X
transforms
a
probability
distribusubjectsofofinfe
inf
204 ing
as do-calculus, and derive an estimator for that query. The 204
subjects
u
Z encoded
tion
encodedby
byPPGG(.),
(.),totoaadistribution
distributionencoded
encodedby
byPPGGX̄ (.).
(.). vector
vectorrepresen
represe
205 tion
X̄
process repeats every time the new queries arise. In contrast, 205
0
Then,P
given
ground
truth
parameterization
(.),exact
exact and
Then,
given
aaground
truth
parameterization
ofofPPGG(.),
x0 )PG
(m|x
)dm
GX̄ (Y|m,
andofofthe
thelaten
late
206 =
this manuscript targets a workflow that trains a causal causal 206
X̄
m
inference
on
P
(.)
samples
from
the
query
distribution.
inference
on
P
(.)
samples
from
the
query
distribution.
G
G
dependson
on⇥.
⇥.L
Z
207
depends
X̄ X̄
latent variable model once, and answers multiple causal queries 207
0
its
expectation
208 =
its
expectation
v
by applying graph mutilation and algorithmic inference to the 208
Assume
acausal
causalGDAG
DAGG
GasasininFig.
Fig.1(b),
1(b),where
whereX,
X,M
M, , (1)
PGX̄a(Y|m)P
(m|x
)dm
Assume
209 and
m
trained model. We propose an approach that does not rely on 209
and
areobserved
observedvariables,
variables,and
andUUisislatent,
latent,and
andthe
thequery
query
Z YYare
0
210 PPGG(Y
the back-door or the front-door criteria, is applicable to multiple 210
E(Q
E(Q
(Y|do(x
|do(x0 )).
)).Modeling
Modelingideal
ideal
interventionswith
withgraph
graphmumu0 interventions
=
P
(Y|do(m))P
(m|x
)dm
G
G
0 0 )) = P
0 0 ). Hence,
211 tilation
causes and outcomes, and restricts parametric assumptions to 211
tilation
implies
that
P
(Y
|do(x
(Y
|x
implies
that
P
(Y
|do(x
))
=
P
(Y
|x
).
Hence,
G
G
G
G
m
X̄ X̄
!
Z Z
212
212
the data-generating process.
Whenthe
themodel
mode
When
0
213 =
213
PG (Y|m,
x)PG (x)dx
(2)
(i.e.,
inference
00
0 0 PG (m|x )dm
(i.e.,
inference
(Y|do(x
|do(x))))==PPGGX̄X̄(Y
(Y|x|x) )
PPG
(Y
G
214
214
ZZm x
thedata
datagoe
go
ofofthe
3 Methods
215
215
00
⇥
=
{
,
},
w
⇥
=
{
,
},
wh
=
PGGX̄ (Y,
(Y,
u,
m|x
)dmdu
=
P
u,
m|x
)dmdu
X̄
Eq. (1) holds
because
Y is independent from x given m in GX̄and
.
216
216
u,m
u,m
are
unid
and
are
unid
In this section we show that training a causal latent variable 217
0
◆ that creates G .
ZZ) ✓Z
PGX̄ (m|x
is✓Zunaffected by the mutilation of◆G
217
X̄
do-calculus,the
th
do-calculus,
0 00
00
00
model (LVM) then applying graphical inference on the trained 218
(Y
|u,
m,
x
)P
(u|m,
x
)du
(m|x
)dm
== PGX̄ (m|x
PPG0G
|u,
m,
x
)P
(u|m,
x
)du
PPGfrom
(m|x
)dm
Hence,
)X̄ (Y
=
P
(m|x
).
Eq.
(2)
follows
the
back218
G
G
G
G
X̄
X̄ X̄
X̄ X̄
function
only
o
function
only
of
mutilated model is equivalent to estimating a do-calculus identi- 219
mmbetween
uu
door path
Y and M in G. The expression on the right44
219

2.5

Existing methods for inferring causal effects

l l

l l

j j

j j

fiable estimand. Taking a Bayesian view, we first demonstrate hand side of Eq. (2) is exactly the front-door adjustment forthis in the special case of Fig. 1(b), where the causal effect of X mula, an estimand for P (Y|do(x0 )) that is derived from the
G
on Y is identifiable according to the front-door criterion. Then do-calculus.
we show that this is true for any identifiable causal query in an
arbitrary causal LVM.
The lemma illustrates that if a causal query on an LVM is idenLemma Assume the parameters of an LVM are the ground truth tified by the do-calculus given the variables observed during
parameters. Then exact graph-based probabilistic inference of training, then exact inference on the mutilated LVM is a valid

Preprint – Do-calculus enables causal reasoning with latent variable models

4

do-calculus estimand. Next we show that combining this pro- sampling procedure targeting the following integral:
Z
cedure with the training step constitutes an estimator for that
estimand. While we chose to prove this theorem using concepts
E(Q(Θ)) =
PG (y|do(x0 ), Θ)PG (Θ|xo )dΘ
common to Bayesian statistics, we also provide an equivalent
Θ
Z
proof using concepts from causal inference in the supplementary
=
PG X̄ (y|x0 , λ, φ)PG (λ, φ|xo )dλ, dφ
materials.
λ,φ
Theorem Assume that a causal query of the LVM is identifiable
via do-calculus given the set of variables observed during training. Then the training procedure combined with exact samplingbased inference on the mutilated model yield an estimator of
that query that converges to the unique true value as the number
of samples goes to infinity.

If Q(Θ) is identified, we know that λ does not impact the result,
despite the fact that it is sampled in the inference procedure.
When Q(Θ) is unidentified, then Q(φ, λ) , Q(φ). The posterior
is be spread around partial identification bounds if the identified
part φ constrains λ in any way.

Proof. Assume a causal DAG G(X), where Xo ⊆ X are observed Complexity of the algorithm Traditional approaches to causal
during training. Let PG (.) be a probability distribution encoded inference construct the estimator after the query is specified.
by G.
The proposed approach amortizes most of the computational
work
into a single training step inferring PG (θ|xo ), performed
Both the model parameters and the latent variables are the subonly
once
for all the parameters θ in the model to answer an
jects of inference during training. Let Θ be a random vector
arbitrary
number
of (identifiable) causal queries.
representing the union of the model parameters θ and of the
latent variables. Inference on a causal query depends on Θ. Let
Q(Θ) denote the causal query. We infer its expectation via the
posterior inference over Θ:
Z
E(Q(Θ)) =
Q(Θ)PG (Θ|xo )dΘ

The training step (whether it is inferring P(θ|xo ) or a point estimator of θ|xo ) depends on the inference algorithm. To evaluate
its computational complexity, we assume the practical case of
stochastic variational inference (SVI) where the proposal distribution is specified such that inference is exact. Inference with
SVI takes advantage of state-of-the-art training methods, though
Θ
in general it is not an exact technique. However, the trade-offs
When the model is trained, some elements in Θ are identified between exact and approximate inference are well known.
(i.e., inference converges to a unique solution as the size of
the data goes to infinity), and some are not. Partition Θ = An exact alternative to SVI is the Hamiltonian Monte Carlo
{φ, λ}, where φ contains the identified components and λ are (HMC). The complexity of exact probabilistic inference on
unidentified. If the query is identified by the do-calculus, then the graph depends on the parameterization of each factor
by definition any estimand of Q(Θ) is a function only of xo , i.e. P(X|pa(X), θ) in the joint distribution.
any valid estimator for an estimand for Q(Θ) can only rely on Causal LVMs with misspecified latent structure If a causal
parameters uniquely identified by xo . Therefore, Q(Θ) = Q(φ), LVM has a misspecified latent structure with respect to the true
i.e. inference of Q(Θ) only depends on the parameters in φ.
LVM, but both latent projections result in the same ADMG, they
Z
will both produce the same estimand for an identifiable causal
query. Choosing from the right set of LVM is a less restrictive
E(Q(Θ)) =
Q(φ)PG (Θ|xo )dΘ
constraint than choosing exactly the right LVM.
Θ
Z
=
Q(φ)PG (λ, φ|xo )dφ, dλ
φ,λ
Z
4 Case studies
=
Q(φ)PG (λ|φ, xo )PG (φ|xo )dφ, dλ
4.1 Overall inference and evaluation strategy
φ,λ
!
Z
Z
For each case study, we used Causal Fusion to investigate the
=
Q(φ)
PG (λ|φ, xo )dλ PG (φ|xo )dφ
identifiability of the causal queries and derive do-calculus-based
φ
λ
Z
estimands. See supplementary material for do-calculus-based
=
Q(φ)PG (φ|xo )dφ
(3) estimands for each case study. Inference was performed with
φ
HMC, and implemented in Stan [36] 2 .

Eq. (3) does not contain λ. Hence, correct estimation of Q(Θ) Let µ = E[effect|do(cause)] − E[effect] and µ̂ =
Ê[effect|do(cause)] − E[effect] be the true and the estimated
does not depend on these elements.
average causal effects. For each case study, we specify the true
If one had the query prior to the analysis, it would be possible to values of model parameters and simulate observational data.
determine the partition of Θ into λ and φ, and derive an inference Next, we simulate interventional data by fixing the value of the
procedure that targets the integral in Eq. (3). In contrast, the cause to its intervened value. µ is then calculated as the mean
proposed procedure assumes that the queries are posed after effect in the interventional data, and µ̂ is estimated by forward
the training. Therefore we first learn Θ via PG (Θ|xo ), and then sampling on the mutilated graph. We evaluate the performance
sample Θ ( both of its λ and φ components) during sampling- of the estimation in terms of the distribution of absolute error
based inference on the mutilated graph. For example, suppose
2
Q(Θ) = PG (y|do(x0 ), Θ). Then inference may take the form of a
https://github.com/srtaheri/LVMwithDoCalculus

Preprint – Do-calculus enables causal reasoning with latent variable models
AE = |µ̂−µ| over 10 observational and 10 interventional datasets,
and compare the box plots of them to those obtained with alternative estimators applicable to the specific causal query. To
evaluate the robustness of the estimation to model misspecification, we also compare the performance of the proposed approach
on a causal LVM trained with the true DAG structure (the true
LVM) to a misspecified LVM, i.e. causal LVM trained with a
misspecified latent structure but same ADMG.
4.2

Case study 1: The Multi-cause model

The system [7, 37] proposed a causal LVM in Fig. 1(a). Their
work highlights the attractiveness of applying causal LVMs to
multidimensional problems common in machine learning. E.g.,
variational autoencoder could capture the relationship between
observed X and latent U, where P(x|u) is learned by the decoder,
and P(u|x) by the encoder. Their work also illustrates the challenge of causal identifiability in LVMs. The authors argued that
it is possible to identify P(y|do(x)) by relying on the multidimensionality of the latent variable U. However, [38] showed that
this is not true in general, except for cases with strong parametric assumptions. Case study 1 is similar to an example in [38].
It demonstrates that by extending the causal LVM in Fig. 1(a)
with a mediator M as in Fig. 1(b), the causal effect of X on Y
becomes non-parametrically identified by the do-calculus-based
front-door criterion. As the result, it can be estimated correctly
by an exact graph-based probabilistic inference on the mutilated
graph.

5
EGF

U
L

IGF

V

W
K

SOS

R

Ras

PI3K

Raf

Akt

Mek
X

(a)

Y

Erk

(b)

Figure 2: Node representations are as in Fig. 1. (a) The Napkin model.
X is the target of the intervention. Y is the effect. (b) The Signaling
model. Nodes are proteins. Pointed/flat-headed edges are relationships
of type increase/decrease. SOS is the target of intervention. Erk is the
effect.
Data for the root nodes are simulated as Normal. W is simulated
from a Gamma distribution. R and Y are simulated from a
Normal distribution. X is simulated from a Bernoulli distribution
with logit parametrization.
True and misspecified LVM The true LVM is modeled with
the DAG in Fig. 2(b). The misspecified LVM has two latent
causes of W and Y instead of one. Non-informative N(0, 10)
priors are used for all the parameters.

Accuracy of estimation of the causal effect is summarized in
Fig. 3(b). Even though this case study has one cause and one
effect, the ananke library is unable to estimate the causal query
Causal query of interest is E[Y|do(X = 0)].
with any of its estimators. Hence, we only compare the causal
Data are generated with three latent variables and five causes, LVM to the plug-in estimator. The relative performance is as in
where U follows Normal distribution and the remaining variables case study 1.
follow Bernoulli distribution with logit parameterization.
True and misspecified LVM The true LVM is as in Fig. 1(b) 4.4 Case study 3: The Signaling model
with 3 latent variables and 5 causes. The misspecified LVM only
The system The insulin-like growth factor (IGF) signaling syshas one latent variable U. Non-informative N(0, 10) priors are
tem in Fig. 2(b) regulates growth and energy metabolism of a
used for all the parameters.
cell. It is activated by external stimuli IGF and EGF. Nodes
Accuracy of estimation of the causal effect is summarized in in the system represent kinase proteins, and edges represent the
Fig. 3(a). Since the model has multiple causes, the proposed ap- effect that the upstream kinase has on the downstream kinase’s
proach can only be compared to the plug-in estimator. Estimates activity. IGF, EGF, and PI3K are latent. This case study does
based on the true LVM and the misspecified LVM outperform not satisfy the back-door or the front-door criteria, and has a
the plug-in estimator. Estimates based on the true LVM preforms non-trivial data generation process defined by prior biological
best. Estimates based on the misspecified LVM converge to that knowledge [41].
of the true LVM as the number of data points increases.
Causal query of interest is an ideal intervention fixing SOS to
70. We are interested in E[Erk|do(S OS = 70)].
4.3 Case study 2 : The new Napkin problem
Data mimics the process of collecting observational and interThe system Fig. 2(b) describes an observational study of pa- ventional data. Since dynamics of this system are well charactertients with HIV, where treatment R affects CD4 cell counts X, ized in form of stochastic differential equations (SDE) [42], we
and W is a known disease history, that affects the treatment. U generate observational data by simulating from an SDE. We set
and V are sets of latent confounders, such as underlying comor- the initial amount of each protein molecule to 100, and generate
bidities, and Y is the disease outcome. This model requires a subsequent observations via the Gillespie algorithm [43] in the
non-trivial application of the do-calculus, as we cannot block smfsb [44] R package. Replicates are generated by randomly
the back-door path, and the front-door criterion does not hold initializing EGF and IGF. Interventional data are generated
[39, 40, 10, 33].
similarly, while fixing S OS = 70.
Casual query of interest is the average outcome of disease after
an intervention on CD4 cell counts, i.e. E[Y|do(X = 0)]. By
intervening on X, the mutilated graph removes all the incoming
edges to X. Hence the causal effect on Y only depends on X and
V.

True and misspecified LVM Since the latent PI3K kinase has
parents, we can avoid learning its parameters by transforming the network, removing PI3K, and re-directing all its incoming edges into Akt [45]. The true LVM is modeled with
this transformed DAG. Probability distributions at each root

Preprint – Do-calculus enables causal reasoning with latent variable models
Case 1

Case 2

4
Napkin model

Multi cause model

Case 3

0.2

0.6

3

AE

AE

AE

True LVM
Misspecified LVM

2

0.4

Plug−in

2

2

0.1

0.1
1

0.0

Case 4−2

0.2

3

0.1

Case 4−1

3

4

0.2

6

Augmented IPW

1

1

0.2

g−formula
Dual IPW

0

0.0
15

0
60 0
100
0.0
0.0
number
of data points
15 60100
15 60100 30 60100
60100200
60100200

15
60
100
number of data points

(a)

number of data points

(b)

Primal IPW

(c)

Figure 3: Absolute error of average causal effect estimation (AE). (a) The Multi-cause model. (b) The Napkin model. (c) The Signaling model.
Triangles refer to plug-in estimates, for which AE exceeds 3 for all numbers of data points. In the case of the misspecified LVM with 100 data
points, one dataset has AE=9, outside of the y axis limit.

ACE2

Gefi

Angiotensin II

AGTR1

Covid model, query
E[cytokine | do(sIL6Ra)= 20)]

ADAM
17

Covid model, query
E[cytokine | do(EGFR= 20)]

EGF

0.6
0.2

PRR
TNF⍺

sIL6R⍺

AE

EGFR

NF-𝜅β

Toci

AE

SARS-COV2

0.4

0.1
0.2

IL-6-STAT3

IL-6
AMP

0.0
60
100
200
number of data points

Cytokine Storm

(a)

0.0

60
100
200
number of data points

(b)

(c)

Figure 4: The Covid model. Boxplot colors are as in Fig. 3. (a) The causal LVM. Nodes are proteins, pointed/flat-headed edges are relationships

of type increase/decrease, dotted edges indicate presence of latent variables. sIL6Rα and EGFR are targets of intervention. Cytokine Storm is
the effect. (b) AE for E[Cytokine|do(sIL6Rα = 20)]. (c) AE for E[Cytokine|do(EGFR = 20)].

node are N(µr , σr ). Probability distributions at each non-root
node N( 1+exp(θ100
0 Pa(X)+θ ) , σ X ) are motivated by common biologi0
cal practice, where simple biomolecular reactions are modeled
with Hill function [46] and approximated with a sigmoid. For a
node X with q parents, Pa(X) is a q × 1 vector of measurements
on the parent nodes, θ0 is a 1 × q vector of unknown parameters,
and θ0 is an unknown scalar bias parameter. Non-informative
N(0, 10) priors are used for all the parameters, with the constraint that the parameter weight θ in the sigmoid is positive for
the relationships of type increase and negative for relationships
of type decrease. The misspecified LVM has a similar structure, while only including EGF and PI3K as latent and omitting
IGF.

primal IPW, true LVM and misspecified LVM converge as the
number of data points increases.
4.5

Case study 4: The Covid model

The system This small-scale expert system showcases the ability of a causal LVM to answer multiple causal queries after a
single instance of training. It models activation of Cytokine
Release Syndrome (cytokine storm or CytokineStorm), known
to cause tissue damage in severely ill SARS-CoV-2 patients
[47], Fig. 4(a). The simultaneous activation of the nuclear
factor kappa-light-chain-enhancer of activated B cell (NF-κB
or NF-κB) and Interleukin 6 STAT3 Complex (IL6-STAT3 or
Accuracy of the estimator is summarized in Fig. 3(c). The do- IL6-STAT3) initiates a positive feedback loop known as Intercalculus-based formula for the plug-in estimator, obtained using leukin 6 Amplifier (IL6-AMP or IL6-AMP), which in turn actiCausal Fusion platform, includes many conditional distributions. vates a cytokine storm [48].
The estimator make parametric assumptions for each distribution
and performs poorly. The ananke library suggests the Dual IPW The network was extracted from COVID-19 Open Research
and the Primal IPW as the best alternatives. While the Dual IPW Dataset (CORD-19) [49] document corpus using the Integrated
performs poorly, the primal IPW performs best, slightly better Dynamical Reasoner and Assembler (INDRA) [50] workflow
than the true LVM and the misspecified LVM. The estimates by [41], and by quering and expressing the corresponding causal
statements in the Biological Expression Language (BEL) [51].

Preprint – Do-calculus enables causal reasoning with latent variable models
Presence of latent variables was determined by querying pairs
of entities in the network for common causes in the corpus.
Causal queries examine the ability of two different drugs to
prevent the cytokine storm. Tocilizumab (Toci or Toci) is an
immunosuppressive drug that targets sIL6Rα and blocks the IL6
signal transduction pathway [52]. Gefitinib (Gefi or Gefi) is an
Epidermal Growth Factor Receptor (EGFR or EGFR) inhibitor,
which blocks EGFR. The first causal query examines the effect
of Toci by setting its target sIL6Rα = 20 (low value), and
considering E[Cytokine|do(sIL6Rα) = 20)]. This causal query
is identifiable using the backdoor criterion. The second causal
query examines the effect of Gefi by setting its target EGFR =
20, and considering E[Cytokine|do(EGFR = 20)]. This causal
query is not identifiable via either the backdoor or the front-door
criterion, but can be identified via the do-calculus.
Data for the root nodes were simulated from a Normal distribution. Simulation of the non-root nodes was motivated by the
same biological practice as in case study 3, and simulated by
the same procedure. Cytokine storm has a Bernoulli distribution
with logit parameterization.

7

to new variables in the model. The four case studies showed
that the proposed approach is applicable to more situations than
many alternative estimators, with satisfactory performance.
From Bayesian perspective, the estimator of the causal query
can be thought of as a posterior predictive statistic. In practice,
we need not be strictly Bayesian in training the parameters θ.
The same approach can be implemented with alternative point
estimate of model parameters, depending on bias, variance, and
computational cost trade-offs.
The proposed approach has limitations. The distribution obtained by marginalizing out the latent variables may be intractable or contain singularities [53]. An LVM with misspecified latent structures may also entail different constraints on the
joint marginal probability of the variables that were observed
during training [21, 22]. As a result, models with different latent structure may differ in terms of fit to the training data or
precision of their causal inference. These difficulties may be
navigated with traditional model evaluation techniques, such
as posterior predictive checks and model selection statistics.
Exploring these issues is subject of our future work.

True and misspecified LVM The true LVM contains two latent variables between S ARS − CoV − 2 and AngiotensinII,
ADAM17 and sIL6Rα, and PRR and NF−κB, and one latent
variable for each remaining dotted edge in Fig. 4(a). The misspecified LVM only has one latent variable for each dotted edge.

Acknowledgements We thank Carlos Cinelli and Alexander
D’Amour for their useful comments and suggestions. Support for Jeremy Zucker was provided by the PNNL Laboratorydirected R&D Data-Model Convergence Initiative and the Mathematics for Artificial Reasoning Systems Initiative. PNNL is
operated for the DOE by Battelle Memorial Institute under ConAccuracy of the estimators for the two queries is summarized
tract DE-AC05-76RLO1830.
in Fig. 4 (b)-(c). In addition to the plug-in estimator, the ananke
library suggests the g-formula and the Augmented IPW as the
best alternative estimators for each query. For the first query the References
misspecified LVM performs best. This may be due to the fact
that it is less complex, and easier to train by HMC. Performance
[1] David M Blei. Build, compute, critique, repeat: Data
of the true LVM approaches that of the misspecified model as the
analysis with latent variable models. Annual Review of
number of observations increases. The plug-in, the g-formula
Statistics and Its Application, 1:203, 2014.
and the Augmented IPW estimators perform slightly worse.
[2] Diederik P Kingma and Max Welling. Stochastic gradient
To estimate the second query, the models corresponding to the
VB and the variational auto-encoder. In Second Interalternative estimators were retrained from scratch. In contrast,
national Conference on Learning Representations, ICLR,
we do not retrain the LVM, but simply sample from a different
volume 19, 2014.
mutilated version of the trained model. At the same time, the
[3] Judea Pearl. Reverend Bayes on inference engines: A
second query produces a different mutilated model and the assodistributed hierarchical approach. Cognitive Systems Labciated estimand, and therefore evaluation on this query produces
oratory, School of Engineering and Applied Science . . . ,
overall higher absolute errors and different relative performance.
1982.
Unlike for the first query, the true LVM performs best. The
g-formula and the augmented IPW perform the same or better [4] Mark Girolami and Ben Calderhead. Riemann manifold
langevin and hamiltonian monte carlo methods. Journal of
than the plug-in estimator and the misspecified LVM.
the Royal Statistical Society B, 73:123, 2011.

5

Discussion

This manuscript demonstrates the value of using a Bayesian
approach on a trained causal LVM, to answer causal queries
that are identifiable via the do-calculus rules. This is particularly useful in settings where multiple ad hoc queries arise after
model training. The existing approaches for causal query estimation typically require rebuilding the underlying model from
scratch. If the model incorporates deep learning architectures,
this process must cope with nonlinear relationships between
high-dimensional variables, and starting from scratch is computationally expensive. In contrast, the LVM, once trained, can
answer an arbitrary number of queries, and is easily extendable

[5] Matthew D Hoffman, David M Blei, Chong Wang, and
John Paisley. Stochastic variational inference. Journal of
Machine Learning Research, 14:1303, 2013.
[6] G Casella and RL Berger. Statistical inference, Duxbury,
2002.
[7] Yixin Wang and David M Blei. The blessings of multiple
causes. Journal of the American Statistical Association.
[8] Judea Pearl. Causal diagrams for empirical research.
Biometrika, 82:669, 1995.
[9] Judea Pearl. Bayesian analysis in expert systems: comment: graphical models, causality and intervention. Statistical Science, 8:266, 1993.

Preprint – Do-calculus enables causal reasoning with latent variable models

8

[10] Judea Pearl and Dana Mackenzie. The Book of Why: The [29] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf.
New Science of Cause and Effect. Basic Books, 2018.
Elements of causal inference: foundations and learning
algorithms. MIT press, 2017.
[11] Peter Spirtes, Clark N Glymour, Richard Scheines, and
David Heckerman. Causation, Prediction, and Search. [30] James M Robins. Robust estimation in sequentially ignorable missing data and causal inference models. In ProceedMIT press, 2000.
ings of the American Statistical Association, volume 1999,
[12] Frederick Eberhardt and Richard Scheines. Interventions
pages 6–10. Indianapolis, IN, 2000.
and causal inference. Philosophy of Science, 74:981, 2007.
[31] Heejung Bang and James M Robins. Doubly robust esti[13] Daphne Koller and Nir Friedman. Probabilistic graphical
mation in missing data and causal inference models. Biomodels: principles and techniques. MIT press, 2009.
metrics, 61(4):962–973, 2005.
[14] Judea Pearl. Causality. Cambridge University Press, 2009. [32] Rohit Bhattacharya, Razieh Nabi, and Ilya Shpitser. Semiparametric inference for causal effects in graphical models
[15] Ilya Shpitser and Judea Pearl. Identification of joint interwith hidden variables. arXiv:2003.12659, 2020.
ventional distributions in recursive semi-markovian causal
models. In Proceedings of the National Conference on [33] Yonghan Jung, Jin Tian, and Elias Bareinboim. Learning
Artificial Intelligence, volume 21, page 1219, 2006.
causal effects via weighted empirical risk minimization.
Advances in Neural Information Processing Systems, 33,
[16] Thomas S. Richardson, Robin J. Evans, James M. Robins,
2020.
and Ilya Shpitser. Nested markov properties for acyclic
directed mixed graphs. arXiv, jan 2017.
[34] Jaron JR Lee and Ilya Shpitser. Identification methods with arbitrary interventional distributions as inputs.
[17] Yimin Huang and Marco Valtorta. Pearl’s calculus of
arXiv:2004.01157, 2020.
intervention is complete. In Proceedings of Uncertainty in
Artificial Intelligence, UAI’06, 2006.
[35] Razieh Nabi, Rohit Bhattacharya, and Ilya Shpitser. Full
law identification in graphical models of missing data:
[18] Santtu Tikka and Juha Karvanen. Identifying causal effects
Completeness results. arXiv:2004.04872, 2020.
with the R package causaleffect. arXiv:1806.07161, 2018.
[19] Elias Bareinboim and Judea Pearl. Causal inference and [36] Stan Development Team et al. RStan: the R Interface to
Stan. R package version 2.17. 3, 2018.
the data-fusion problem. Proceedings of the National
Academy of Sciences, 113:7345, 2016.

[37] Rajesh Ranganath and Adler Perotte. Multiple causal inference with latent confounding. arXiv:1805.08273, 2018.

[20] Robin J. Evans. Margins of discrete bayesian networks.
[38] Alexander D’Amour. On multi-cause causal inference with
The Annals of Statistics, 46(6A):2623–2656, 2018.
unobserved confounding: Counterexamples, impossibility,
[21] Judea Pearl. On the testability of causal models with latent
and alternatives. arXiv:1902.10286, 2019.
and instrumental variables. arXiv, feb 2013.
[39] Jouni Helske, Santtu Tikka, and Juha Karvanen. Estimation
[22] Robin J. Evans. Graphical methods for inequality conof causal effects with small data under implicit functional
straints in marginalized DAGs. In International Workshop
constraints. arXiv:2003.03187, 2020.
on Machine Learning for Signal Processing, pages 1–6.
[40]
Michael D Hughes, Michael J Daniels, Margaret A Fischl,
IEEE, sep 2012.
Soyeon Kim, and Robert T Schooley. Cd4 cell count as a
[23] Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag,
surrogate endpoint in hiv clinical trials: A meta-analysis
Richard Zemel, and Max Welling. Causal effect inference
of studies of the aids clinical trials group. Aids, 12:1823,
with deep latent-variable models. In Advances in Neural
1998.
Information Processing Systems, page 6446, 2017.
[41] J. Zucker, K. Paneri, S. Mohammad-Taheri, S. Bhargava,
[24] Yixin Wang, Dawen Liang, Laurent Charlin, and David M
P. Kolambkar, C. Bakker, J. Teuton, C. T. Hoyt, K. Oxford,
Blei. The deconfounded recommender: A causal inference
R. Ness, and O. Vitek. Leveraging structured biological
approach to recommendation. arXiv:1808.06581, 2018.
knowledge for counterfactual inference: A case study of
viral
pathogenesis. IEEE Transactions on Big Data, pages
[25] Paul R Rosenbaum and Donald B Rubin. The central role
1–1, 2021.
of the propensity score in observational studies for causal
effects. Biometrika, 70:41, 1983.
[42] F. Bianconi, E. Baldelli, V. Ludovini, L. Crino, A. Flacco,
and P. Valigi. Computational model of EGFR and IGF1R
[26] Judea Pearl, F Bacchus, P Spirtes, C Glymour, and
pathways in lung cancer: a systems biology approach for
R Scheines. Probabilistic reasoning in intelligent systems:
translational oncology. Biotechnology Advances, 30:142,
Networks of plausible inference. 1995.
2012.
[27] Mark J Van Der Laan and Daniel Rubin. Targeted max[43]
D. T. Gillespie. Exact stochastic simulation of coupled
imum likelihood learning. International Journal of Biochemical reactions. Journal of Physical Chemistry, 81:
statistics, 2, 2006.
2340, 1977.
[28] James Robins.
A new approach to causal inference in mortality studies with a sustained exposure pe- [44] D. Wilkinson. Package smfsb. 2018.
riod—application to control of the healthy worker survivor [45] Robin J Evans. Graphs for margins of Bayesian networks.
effect. Mathematical Modelling, 7:1393, 1986.
Scandinavian Journal of Statistics, 43:625, 2016.

Preprint – Do-calculus enables causal reasoning with latent variable models
[46] Uri Alon. An Introduction to Systems Biology: Design
Principles of Biological Circuits. CRC Press, 2019.
[47] Z. S. Ulhaq and G. V. Soraya. Interleukin-6 as a potential biomarker of COVID-19 progression. Medecine et
Maladies Infectieuses, 50:382, 2020.
[48] T. Hirano and M. Murakami. COVID-19: A new virus,
but a familiar receptor and cytokine release syndrome.
Immunity, 52:731, 2020.
[49] L. Lu Wang, K. Lo, Y. Chandrasekhar, R. Reas, J. Yang,
D. Eide, K. Funk, R. Kinney, Z. Liu, W. Merrill, P. Mooney,
D. Murdick, D. Rishi, J. Sheehan, Z. Shen, B. Stilson, A. D.
Wade, K. Wang, C. Wilhelm, B. Xie, D. Raymond, D. S.
Weld, O. Etzioni, and S. Kohlmeier. CORD-19: The Covid19 Open Research Dataset. arXiv, 2020.
[50] B. M. Gyori, J. A. Bachman, K. Subramanian, J. L. Muhlich, L. Galescu, and P. K Sorger. From word models to
executable models of signaling networks using automated
assembly. Molecular Systems Biology, 13, 2017.
[51] T. Slater. Recent advances in modeling languages for
pathway maps and computable biological networks. Drug
Discovery Today, 19:193, 2014.
[52] C. Zhang, Z. Wu, J.-W. Li, H. Zhao, and G.-Q. Wang. Cytokine release syndrome in severe COVID-19: Interleukin6 receptor antagonist Tocilizumab may be the key to reduce
mortality. International Journal of Antimicrobial Agents,
55:105954, 2020.
[53] Ilya Shpitser, Robin J. Evans, Thomas S. Richardson, and
James M. Robins. Introduction to nested markov models.
Behaviormetrika, 41(1):3–39, Jan 2014.

9

