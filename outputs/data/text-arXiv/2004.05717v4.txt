Towards an Effective and Efficient Deep Learning Model
for COVID-19 Patterns Detection in X-ray Images
Eduardo Luza , Pedro Silvab , Rodrigo Silvaa , Ludmila Silvac , Gladston
Moreiraa,∗, David Menottid

arXiv:2004.05717v4 [eess.IV] 9 Jul 2020

a Computing

Department, Federal University of Ouro Preto, Campus Morro do Cruzeiro,
Ouro Preto-MG, Brazil
b Graduate Program in Computer Science, Federal University of Ouro Preto (UFOP), MG,
Brazil
c Hospital e Maternidade Otaviano Neves, Belo Horizonte-MG, Brazil
d Department of Informatics, Federal University of Paraná, Centro Politécnico, Jardim das
Américas, Curitiba-PR, Brazil

Abstract
Purpose: Confronting the pandemic of COVID-19, is nowadays one of the
most prominent challenges of the human species. A key factor in slowing down
the virus propagation is the rapid diagnosis and isolation of infected patients.
The standard method for COVID-19 identification, the Reverse transcription
polymerase chain reaction method, is time-consuming and in short supply due
to the pandemic. Thus, researchers have been looking for alternative screening
methods and deep learning applied to chest X-rays of patients has been showing
promising results. Despite their success, the computational cost of these methods remains high, which imposes difficulties to their accessibility and availability.
Thus, the main goal of this work is to propose an accurate yet efficient method
in terms of memory and processing time for the problem of COVID-19 screening
in chest X-rays.
Methods: To achieve the defined objective we exploit and extend the EfficientNet family of deep artificial neural networks which are known for their
high accuracy and low footprints in other applications. We also exploit the
underlying taxonomy of the problem with a hierarchical classifier. A dataset
∗ Corresponding

author
Email address: gladston@ufop.edu.br (Gladston Moreira )
URL: http://www.decom.ufop.br/csilab/ (Gladston Moreira )

Preprint submitted to arXiv

July 10, 2020

of 13,569 X-ray images divided into healthy, non-COVID-19 pneumonia, and
COVID-19 patients is used to train the proposed approaches and other 5 competing architectures. Finally, 231 images of the three classes were used to assess
the quality of the methods.
Results: The results show that the proposed approach was able to produce
a high-quality model, with an overall accuracy of 93.9%, COVID-19, sensitivity of 96.8% and positive prediction of 100%, while having from 5 to 30 times
fewer parameters than other than the other tested architectures. Larger and
more heterogeneous databases are still needed for validation before claiming
that deep learning can assist physicians in the task of detecting COVID-19 in
X-ray images.
Conclusions: We believe the reported figures represent state-of-the-art results, both in terms of efficiency and effectiveness, for the COVIDx database,
a database comprised of 13,800 X-ray images, 183 of which are from patients
affected by COVID-19. The current proposal is a promising candidate for embedding in medical equipment or even physicians’ mobile phones.
Keywords: COVID-19, Deep Learning, EfficientNet, Pneumonia, Chest
(X-ray) Radiography.

1. Introduction
The COVID-19 is an infection caused by the SARS-CoV-2 virus and may
manifest itself as a flu-like illness potentially progressing to an acute respiratory
distress syndrome. The disease severity resulted in a global public health efforts
to contain person-to-person viral spread by early detection [1].
The Reverse-Transcriptase Polymerase Chain Reaction (RT-PCR) is currently the gold standard for a definitive diagnosis of COVID-19. However, false
negatives have been reported (due to insufficient cellular content in the sample
or inadequate detection and extraction techniques) in the presence of positive
radiological findings [2]. Therefore, effective exclusion of the COVID-19 infection requires multiple negative tests, possibly exacerbating test kit shortage [3].
2

As COVID-19 spreads in the world, there is growing interest in the role and
suitability of chest X-Rays (CXR) for screening, diagnosis, and management of
patients with suspected or known COVID-19 infection [4, 5, 6]. Besides, there
have been a growing number of publications describing the CXR appearance in
patients with COVID-19 [3].
The accuracy of CXR diagnosis of COVID-19 infection strongly relies on
radiological expertise due to the complex morphological patterns of lung involvement which can change in extent and appearance over time. The limited
number of sub-specialty trained thoracic radiologists hampers reliable interpretation of complex chest examinations, specially in developing countries, where
general radiologists and occasionally clinicians interpret chest imaging [1].
Deep Learning is a subset of machine learning in artificial intelligence (AI)
concerned with algorithms inspired by the structure and function of the brain
called artificial neural networks. Since deep learning techniques, in particular
convolutional neural networks (CNNs), have been beating humans in various
computer vision tasks [7, 8, 9], it becomes a natural candidate for the analysis
of chest radiography images.
Deep learning has already been explored for the detection and classification
of pneumonia and other diseases on radiography [9, 10, 11]. In this context,
this work aims to investigate deep learning models that are capable of finding
patterns X-ray images of the chest, even if the patterns are imperceptible to the
human eye, and to advance on a fundamental issue: computational cost.
Finding a model of low computational cost is important because it allows
the exploitation of input images of much higher resolutions without making the
processing time prohibitive. Besides, it becomes easier and cheaper to embed
these models in equipment with more restrictive settings such as smartphones.
We believe that a mobile application, that integrates deep learning models for
the task of recognizing patterns in x-rays must be easily accessible and readily
available to the medical staff. For such aim, the models must have a low footprint
and low latency, that is, the models must require little memory and perform
inference quickly to allow use on embedded devices and large scale, enabling
3

integration with smartphones and medical equipment.
To find such cost-efficient models, in this work, the family of EfficientNets,
recently proposed in [12], is investigated. These models have shown high performance in the classic ImageNet dataset [13] while presenting only a small fraction
of the cost of other popular architectures such as the ResNets and VGGs. We
also exploit the natural taxonomy of the problem and investigate the use of
hierarchical classification. In this case, low computational cost is even more
critical since multiple models have to be built.
The results show that it is indeed possible to build much smaller models
without compromising accuracy. Thus, embedding the proposed neural network
model in a mobile device to make fast inferences becomes more feasible. Despite
its low computational cost, the proposed model achieves high accuracy (93.9%)
and detect infection caused by COVID-19 on chest X-rays with a Sensitivity of
96.8% and Positivity Prediction of 100% (without false positives). Regarding
the hierarchical model, in addition to consuming more computational resources
than the flat classification, it showed to be less effective for minority classes,
which is the case for the COVID-19 class in this work. However, we believe that
the hierarchical method is the most suitable for the application. It may suffer
less from bias in the evaluation protocols [14], since images from different sources
(datasets) are mixed to build the superclasses according to the taxonomy of the
problem [15].
The development of this work may allow the future construction of an application for use by the medical team, through a camera on a regular cell
phone. The source code as the pre-trained models are available in https:
//github.com/ufopcsilab/EfficientNet-C19.
The remainder of this work consists of six sections. Section 2 presents a
review of related works. Section 3 defines the problem tackled in this paper.
The methodology and the dataset are described in Section 4. In Section 5, the
results of a comprehensive set of computational experiments are presented. In
Section 6, propositions for future research in the area are addressed. Finally,
conclusions are pointed out in Section 7.
4

2. Related Works
Addressing the COVID-19, in [16], a comparison among seven different wellknown deep learning neural networks architectures was presented. In the experiments, they use a small dataset with only 50 images in which 25 samples are from
healthy patients and 25 from COVID-19 positive patients. The models were pretrained with the ImageNet dataset [13], which is a generic image dataset with
over 14 million images of all sorts, and only the classifier is trained with the
radiography. In their experiments, the VGG19 [17] and the DenseNET201 [18]
were the best performing architectures.
In [19], a new architecture of CNN, called COVID-net, is created to classify CXR images into normal, pneumonia, and COVID-19. Differently from
the previous work, they use a much larger dataset consisting of 13, 800 CXR
images across 13, 645 patient cases from which 182 images belong to COVID-19
pacients. The authors report an accuracy of 92.4% overall and sensitivity of
80% for COVID-19.
In [20], the ResNet50 [21] is fine-tuned for the problem of classifying CXRs
into normal, COVID-19, bacterial-pneumonia and viral pneumonia. The authors report better results when compared with the COVID-net, 96.23% accuracy overall, and 100% sensitivity for COVID-19. Nevertheless, it is important
to highlight that the problem in [20] has an extra class and that its dataset is a
subset of the dataset used in [19]. In [20] the dataset consists of 68 COVID-19
radiographs from 45 COVID-19 patients, 1,203 healthy patients, 931 patients
with a bacterial pneumonia and 660 patients with nonCOVID-19 viral pneumonia.
In [22], the authors also performed a hierarchical analysis for the task of
detecting COVID-19 patterns on CXR images. A dataset was built, from other
public datasets, containing 1,144 X-ray images, of which only 90 were related
to COVID-19 and the remaining belonging to six other classes: five types of
pneumonia and one normal (healthy) type. Several techniques were used to
extract features from the images, including one based on deep convolutional

5

networks (Inception-V3 [23]). For classification, the authors explored classifiers
such as SVM, Random Forest, KNNs, MLPs, and Decision Trees. A F1-Score
of 0.89 for the COVID-19 class is reported. In spite of having a strong relation
to the present work, we emphasize that a direct comparison is not possible, due
to the different nature of the datasets employed on both works.
In [24], the authors propose a Convolutional Neural Network-based model
to automate the detection of COVID-19 infection from chest X-ray images,
named CoroNet. The proposed model uses the Xception CNN architecture
[25], pre-trained on ImageNet dataset [13]. CoroNet was trained and tested on
the prepared dataset from two different publically available image databases
(available at https://github.com/ieee8023/covid-chestxray-dataset and
https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia).
The CoroNet model achieved an accuracy of 89.6%, with precision and recall rate
for COVID-19 cases of 93% and 98.2% for 4-class cases (COVID vs Pneumonia
bacterial vs Pneumonia viral vs Normal) with a 4-fold cross-validation scheme.
Also, the authors evaluate their model on a second dataset, tough this second
dataset apparently contains the same COVID-19 images used during training.

3. Problem Setting
The problem addressed by the proposed approach can be defined as follows:
Given a chest X-ray, determine if it belongs to a healthy patient, a patient with
COVID-19, or a patient with other forms of pneumonia. FIGURE 1 shows
typical chest X-ray samples in COVIDx dataset [19]. As can be seen, the model
should not make assumptions regarding the view in which the X-ray was taken.
Thus, given an image similar to these ones, a model must output one of the
following three possible labels:
• normal - for healthy patients.
• COVID-19 - for patients with COVID-19.
• pneumonia - for patients with non-COVID-19 pneumonia.
6

Following the rationale in [19], choosing these three possible predictions can
help clinicians in deciding who should be prioritized for PCR testing for COVID19 case conïňĄrmation. Moreover, it might also help in treatment selection since
COVID-19, and non-COVID-19 infections require different treatment plans.
We analyze the problem from two perspectives: 1) the traditional flat classification, in which we disregard the relationship between the classes; and 2)
the hierarchical classification approach, in which we assume the classes to be
predicted are naturally organized into a taxonomy.

4. Methodology
In this section, we present the methodology for COVID-19 detection by
means of a chest X-ray image. We detail the main datasets and briefly describe
the COVID-Net [19], our baseline method. Also, we describe the employed deep
learning techniques as well as the learning methodology and evaluation.
4.1. Datasets
4.1.1. RSNA Pneumonia Detection Challenge dataset
The RSNA Pneumonia Detection Challenge [26] is a competition that aims
to locate lung opacities on chest radiographs. Pneumonia is associated with
opacity in the lung, and some conditions such as pulmonary edema, bleeding,
volume loss, lung cancer can also lead to opacity in lung radiography. Finding
patterns associated with pneumonia is a hard task. In that sense, the Radiological Society of North America (RSNA) has promoted the challenge, providing a
rich dataset. Although The RSNA challenge is a segmentation challenge, here
we are using the dataset for a classification problem. The dataset offers images
for two classes: Normal and Pneumonia (non-normal). We are using a total of
16, 680 images of this dataset, of which 8, 066 are from Normal class and 8, 614
from the Pneumonia class.

7

(a)

(b)

Figure 1: Radiograph example of images from COVID-19 image data collection [27]. (a) X-ray
of a 54-year-old male, infected with COVID-19 [27]. (b) X-ray a 70-year-old female, infected
with COVID-19 [27].

4.1.2. COVID-19 image data collection
The “COVID-19 Image Data Collection” [27] is a collection of anonymized
COVID-19 images, acquired from websites of medical and scientific associations [28, 29] and research papers. The dataset was created by researchers from
the University of Montreal with the help of the international research community
to assure that it will be continuously updated. Nowadays, the dataset includes
more than 183 X-ray images of patients who were affected by COVID-19 and
other diseases, such as MERS, SARS, and ARDS. The dataset is public and also
includes CT scans images. According to the authors, the dataset can be used
to assess the advancement of COVID-19 in infected individuals, and also allow
the identification of patterns related to COVID-19 helping in differentiating it
from other types of pneumonia. Besides, CXR images can be used as an initial
screening for the COVID-19 diagnostic processes. So far, most of the images
are from male individuals (approx. 60/40% of males and females, respectively),
and the age group that concentrates most cases is from 50 to 80 years old.

8

4.1.3. COVIDx dataset
In [19], a new dataset is proposed by merging two other public datasets:
“RSNA Pneumonia Detection Challenge dataset” and “COVID-19 Image Data
Collection”. The new dataset, called COVIDx, is designed for a classification
problem and contemplates three classes: Normal, Pneumonia, and COVID-19.
Most instances of the Normal and Pneumonia classes come from the “RSNA
Pneumonia Detection Challenge dataset”, and all instances of the COVID-19
class come from the “COVID-19 Image Data Collection”. The dataset has a total
of 13, 800 images from 13, 645 individuals and is split into two partitions, one
for training purposes and one for testing (model evaluation). The distribution
of images between the partitions is shown in TABLE 1, and the source code to
reproduce the dataset is publicly available1 .
Table 1: COVIDx Images distribution among classes and partitions. The dataset is proposed
in [19].

Type

Normal

Pneumonia

COVID-19

Total

Train

7966

5421

152

13569

Test

100

100

31

231

4.2. EfficientNet
The EfficientNet [12] is in fact a family of models defined on the baseline
network described in TABLE 2. Its main component is known as the Mobile
Inverted Bottleneck Conv (MBconv) Block introduced in [30] and depicted in
FIGURE 2.
The rationale behind the EfficientNet family is to start from high quality yet
compact baseline model and uniformly scale each of its dimensions systematically with a fixed set of scaling coefficients. Formally, an EfficientNet is defined
1 https://github.com/lindawangg/COVID-Net

9

Table 2: EfficientNet baseline network : B0 architecture.

Stage

Operator

Resolution

#channels

#layers

1

Conv3x3

224x224

32

1

2

MBConv1,k3x3

112x112

16

1

3

MBConv6,k3x3

112x112

24

2

4

MBConv6,k5x5

56x56

40

2

5

MBConv6,k3x3

28x28

80

3

6

MBConv6,k5x5

14x14

112

3

7

MBConv6,k5x5

14x14

192

4

8

MBConv6,k3x3

7x7

320

1

9

Conv1x1/Pooling/FC

7x7

1, 280

1

by three dimensions: (i) depth; (ii) width; and (iii) resolutions as illustrated in
FIGURE 3.
Starting from the baseline model in TABLE 2 each dimension is scaled by
the parameter φ according to
depth = αφ
width = β φ
resolution = γ φ

,

(1)

s.t. α · β 2 · γ 2 ≈ 2
α ≥ 1, β ≥ 1, γ ≥ 1
where α, β, γ are constants obtained by a grid search experiment. As stated in
[12], Eq. 1 provides a nice balance between performance and computational cost.
The coefficient φ controls the available resources. Eq. 1 determines the increase
or decrease of model FLOPS when depth, width or resolution are modified.
Notably, in [12], a model from EfficientNet family was able to beat the
10

HxWxF

(Conv1x1, BN, ReLu)
HxWx6F

(DWConv3x3, BN, ReLu)
HxWx6F

(Conv1x1, BN)
HxWxF
+
Figure 2: MBConv Block [30]. DWConv stands for depthwise conv, k3x3/k5x5 defines the
kernel size, BN is batch norm, HxW xF means tensor shape (height, width, depth), and
ÃŮ1/2/3/4 is the multiplier for number of repeated layers. (Figure created by the authors)

width

deepth

resolution
Figure 3: Efficient net compound scaling on three parameters. (Adapted from [12])

powerful GPipe Network [18] on the ImageNet dataset [31] running with 8.4x
fewer parameters and being 6.1x faster.
4.3. Hierarchical Classification
In classification problems, it is common to have some sort of relationship
among classes. Very often, on real problems, the classes (the category of an
instance) are organized hierarchically, like a tree structure. According to Silla
Jr. and Freitas [15], one can have three types of classification: flat classification,

11

which ignores the hierarchy of the tree; local classification, in which there is a
set of classifiers for each level of the tree (one classifier per node or level); and
finally, global classification, in which one single classifier is built with the ability
to classify any node in the tree, besides the leaves.
The most popular type of classification in the literature is the flat one. However, here we propose the use of local classification, which we call hierarchical
classification. Thus, the target classes are located in the leaves of the tree, and
in the intermediate nodes, we have classifiers. In this work, we need two classifiers, one at the root node, dedicated to discriminate between the Normal and
Pneumonia classes, and another one in the next level dedicated to discriminate
between pneumonia types. The problem addressed here can be mapped as the
topology depicted in FIGURE 4 in which there are two levels of classification.
To make the class inference for a new instance, first, the instance is presented to
the first classifier (in the root node). If it is predicted as “Normal”, the inference
ends there. If the instance is considered “Pneumonia”, it is then presented to
the second classifier, which will discern whether it is a Pneumonia caused by
“COVID-19” or “Not”.
4.4. Training
Deep learning models are complex, and therefore require a large number of
instances to avoid overfitting, i.e., when the learned network performs well on the
training set but underperform on the test set. Unfortunately, for most problems
in real-world situations, data is not abundant. In fact, there are few scenarios in
which there is an abundance of training data, such as the ImageNet [31], in which
there are more than 14 million images of 21, 841 classes/categories. To overcome
this issue, researchers rely on two techniques: data augmentation and transfer
learning. We also detail here the proposed models, based on EfficientNet.
4.4.1. Image Pre-processing and Data Augmentation
Several pre-processing techniques may be used for image cleaning, noise removal, outlier removal, etc. The only pre-processing applied in this work is a

12

Root node

Pneumonia

Normal

NonCOVID-19

COVID-19

Figure 4: Natural topology of the classes: Normal, Pneumonia, COVID-19. It illustrates
the Local-Per-Node hierarchical approach, in which there is a classifier on each parent node.
(Figure created by the authors)

simple intensity normalization of the image pixels to the range [0, 1]. In this
manner, we rely on the filters of the convolutional network itself to perform possible data cleaning. Also, all images are resized according to the architecture
resolution parameter (See table 2).
Data augmentation consists of expanding the training set with transformations of the images in the dataset [32] provided that the semantic information is
not lost. In this work, we applied three transformations to the images: rotation,
horizontal flip, and scaling, as such transformations would not hinder, for example, a physician to interpret the radiography. Figure 5 presents an example
of the applied data augmentation.
4.4.2. Proposed models
The EfficientNet family has models of high performance and low computational cost. Since this research aims to find efficient models capable of being embedded in conventional smartphones, the EfficietNet family is a natural choice.
We explore the EfficientNets by adding more operator blocks atop of it. More

13

Figure 5: Data augmentation applied using the Augmentor python package. The transformations applied to the images are: rotation (0 to 15 degrees clockwise or anticlockwise), 20%
Zoom or horizontal flipping . All or none changes may be applied/combined according to a
probability. (Figure created by the authors)

specifically, we add four new blocks, as detailed in TABLE 3.
Since the original EfficientNets were built to work on a different classification
problem we add new fully connected layers (FC) responsible for the last steps
of the classification process. We also use batch normalization (BN), dropout,
and swish activation functions for the following reasons.
The batch normalization constrains the output of the last layer in a range,
forcing zero mean and standard deviation one. That acts as regularization,
increasing the stability of the neural network, and accelerating the training [33].
The Dropout [34] is perhaps the most powerful method of regularization.
The practical effect of dropout operation is to emulate a bagged ensemble of
multiple neural networks by inhibiting a few neurons, at random, for each minibatch during training. The number of inhibited neuronal units is defined by the
dropout parameter, which ranges between 0 to 100 percent.
The most popular activation function is the Rectified Linear Unit (ReLU),
which can be formally defined as f (x) = max(0, x). However, in the added

14

block we have opted for the swich activation function [35] defined as:
(2)

f (x) = x · (1 + exp−x )−1 .

Differently from the ReLU the swish activation produces a smooth curve during
the minimization loss process when a gradient descent algorithm is used. Another advantage of the swish activation regarding the ReLU, it does not zero
out small negative values which may still be relevant for capturing patterns
underlying the data [35].
Table 3: Proposed architectures, considering the EfficientNet B0 as base model. (NC =
Number of Classes).

Stage

Operator

Resolution

#channels

#layers

1-9

EfficientNet B0

224x224

32

1

10

BN/Dropout

7x7

1280

1

11

FC/BN/Swich/Dropout

1

512

1

12

FC/BN/Swich

1

128

1

13

FC/Softmax

1

NC

1

4.4.3. Transfer learning
Instead of training a model from scratch, one can take advantage of using
the weights from a pre-trained network and accelerate or enhance the learning
process. As discussed in [36], the initial layers of a model can be seen as feature
descriptors for image representation, and the latter ones are related to instance
categories. Thus, in many applications, several layers can be re-used. The
task of transfer learning is then to define how and what layers of a pre-trained
model should be used. This technique has proved to be effective in several
computer vision tasks, even when transferring weights from completely different
domains [32, 37].
The steps for transfer of learning are:
15

1. Copying the weights from a pre-trained model to a new model;
2. Modifying the architecture of the new model to adapt it to the new problem, possibly including new layers;
3. Initialize the new layers;
4. Define which layers will pass through a new the learning process; and
5. training (updating the weights according to the loss function) with a suitable optimization algorithm.
We apply transfer learning to EfficientNets pre-trained on the ImageNet
dataset [31]. It is clear that the ImageNet domain is much broader than the chest
X-rays that will be presented to the models in this work. Thus, the imported
network weights are taken just as an initial solution and are all fine-tuned (i.e.,
the weights from all layers) by the optimizer over the new training phase. The
rationale is that the imported models already have a lot of knowledge about
all sorts of objects. By permitting all the weights to get fine-tuned we allow
the model to specialize to the problem in hands. In the training phase, the
weights are updated with the Adam Optimizer and a schedule rule decreasing
the learning rate by a factor of 10 in the event of stagnation (’patience=2’).
The learning rate started with 10−4 , and the number of epochs fixed at 10.
4.5. Model evaluation and metrics
The final evaluation is carried out with the COVIDx dataset, and since the
COVIDx comprises a combination of two other public datasets, we follow the
script2 provided in [19] to load the training and test sets. The data is then
distributed according to the TABLE 1.
In this work, three metrics are used to evaluate models: accuracy (Acc),
2 https://github.com/lindawangg/COVID-Net

16

COVID-19 sensitivity (SeC ), and COVID-19 positive prediction (+PC ), i.e.,
Acc =

T PN + T PP + T PC
#samples

SeC =

T PC
T PC + F NC

+PC =

T PC
T PC + F PC

(3)

wherein T PN , T PP , T PC , F NC , and F PC stand for the normal samples correctly classified, non-COVID-19 samples correctly classified, the COVID-19 samples correctly classified, the COVID-19 samples classified as normal or nonCOVID-19, the non-COVID-19 and normal samples classified as COVID-19.
The number of multiply-accumulate (MAC) operations are used to measure the
computational cost.

5. Experiments and Discussion
In this section, we present the experimental setup and results for both flat
and hierarchical approaches. The execution environment of the computational
experiments was conducted on an Intel(R) Core(TM) i7-5820K CPU @ 3.30GHz,
64Gb Ram, two Titan X with 12Gb, and the TensorFlow/Keras framework for
Python.
5.1. Dataset setup
Three different training set configurations were analyzed with the COVIDx
dataset: i) (Raw Dataset) - the raw dataset without any pre-processing; ii) (Raw
Dataset + Data Augmentation) - the raw dataset with a data augmentation of
1,000 new images on COVID-19 samples and a limitation of 4,000 images for
the two remaining classes; and iii) (Balanced Dataset) - the dataset with a
1,000 images per class achieved by data augmentation on COVID-19 samples
and undersampling the other two classes to 1, 000 samples each one. Learning
17

with an unbalanced dataset could bias the prediction model towards the classes
with more samples, leading to inferior classification models.
In this work, we evaluate two scenarios: flat and hierarchical. Regardless of
the scenarios, the three training sets remain the same (Raw, Raw + Data Augmentation, and Balanced). However, for the hierarchical case, there is an extra
process to split the sets into two parts: the first part, the instances of Pneumonia and COVID-19 classes are joined and receive the same label (Pneumonia).
In the second part, the instances related to the Normal class are removed, leaving in the set only instances related to Pneumonia and COVID-19. Thus, two
classifiers are built for the hierarchical case, and each one works with a different
set of data (see Section 4.3 for more details).
5.2. Experimental settings and results
Table 4: Base models footprint details. (Mb = Megabytes)

Model

Input shape

#Params

Memory usage (Mb)

EfficientNet B0

224, 224, 3

5,330,564

21

EfficientNet B1

240, 240, 3

7,856,232

31

EfficientNet B2

260, 260, 3

9,177,562

36

EfficientNet B3

300, 300, 3

12,320,528

48

EfficientNet B4

380, 380, 3

19,466,816

76

EfficientNet B5

456, 456, 3

30,562,520

118

MobileNet

224, 224, 3

4,253,864

17

MobileNet V2

224, 224, 3

3,538,984

14

ResNet 50

224, 224, 3

25,636,712

99

VGG-16

224, 224, 3

138,357,544

528

VGG-19

224, 224, 3

143,667,240

549

18

We evaluate four families of convolutional neural networks: EfficientNet,
MobileNet, VGG and ResNet. Their features are summarized in TABLE 4.
Among the presented models, we highlight the low footprint of MobileNet and
EfficientNet.
Regarding the base models (B0-B5 models of EfficientNet family), the simplest one is the EfficientNet-B0. Thus, we assess the impact of the different
training sets and the two forms of classification (flat and hierarchical) from this
one. The results are shown in TABLE 5.
Table 5: EfficientNet B0 results over the three proposed training sets. (Acc. = Accuracy; SeC
= COVID-19 Sensitivity; +PC = COVID-19 Positive Prediction.)

Approach

Training dataset

Acc.

SeC

+PC

Raw Dataset

92.2%

67.7%

100.0%

93.0%

83.8%

100.0%

90.0%

93.5%

100.0%

54.1%

83.8%

100.0%

90.4%

70.9%

91.6%

85.7%

93.5%

82.8%

Raw Dataset +
Flat

Data
Augmentation
Balanced
Dataset
Raw Dataset
Raw Dataset +

Hierarchical

Data
Augmentation
Balanced Dataset

Since there are more pneumonia, and normal x-ray samples than COVID19, the neural network learning process tends to improve the classification of
the majoritarian classes, since they have more weight for the loss calculation.
This may justify the results obtained by balancing the data. As described in
Section 4.3, the hierarchical approach is also evaluated here. First, classes of
COVID-19 and common Pneumonia are combined and presented to the first
level of classification (Normal vs Pneumonia). At the second level, another
19

model classifies between pneumonia caused by COVID-19 and other causes.

Figure 6: Loss during training-time, EfficientNet-B0 and balanced data. Epochs vs Loss.

It is possible to see on TABLE 5 that better results are achieved with the
flat approach on balanced data. This scenario is used to evaluate the remaining
network as base architectures. The training loss for this scenario is presented
in FIGURE 6.
The results of all evaluated architectures are summarized in TABLE 6. We
stress that we adapted all architectures by placing the same four blocks on top.
It can be seen that all the networks have comparable performances in terms of
accuracy. However, the more complex the model is, the worse is the performance
for the minority class, the COVID-19 class.
The cost of a model is related to the number of parameters. The higher the
number of parameters, the higher the amount of data the model needs to adjust
them. Thus, we hypothesized that the lack of a bigger dataset may explain the
difficulties faced by the more complex models.

20

Table 6: Results on different network architectures as base model. Best scenario for COVID19: all experiments with a balanced training set and flat classification. (Acc. = Accuracy;
SeC = COVID-19 Sensitivity; +PC = COVID-19 Positive Prediction.)

Base Model

Acc.

SeC

+PC

EfficientNet B0

90.0%

93.5%

100.0%

EfficientNet B1

91.8%

87.1%

100.0%

EfficientNet B2

90.0%

77.4%

100.0%

EfficientNet B3

93.9%

96.8%

100.0%

EfficientNet B4

93.0%

90.3%

93.3%

EfficientNet B5

92.2%

93.5%

90.6%

MobileNet

90.4%

83.8%

100.0%

MobileNet V2

90.0%

87.1%

96.4%

ResNet-50

83.5%

70.9%

81.4%

VGG-16

77.0%

67.7%

63.64%

VGG-19

75.3%

77.4%

50.0%

TABLE 7 presents a comparison of the proposed approach and the one proposed by Wang et al. [19] (COVID-net) under the same evaluation protocol.
Even though the accuracy is comparable, the proposed approach presents an
improvement on positive prediction without losing sensitivity. Besides, a significant reduction both in terms of memory (our model is >15 times smaller) and
latency is observed. It is worth highlighting that Wang et al. [19] apply data
augmentation to the dataset but it is not clear in their manuscript how many
new images are created.
The COVID-Net [19] is a very complex network, which demands a memory
of 2.1GB (for the smaller model) and performs over 3.5 billion MAC operations
implying three main drawbacks: computation-cost, time-consumption, and in21

Table 7: Comparison of the proposed approach against SOTA. (Acc. = Accuracy; SeC =
COVID-19 Sensitivity; +PC = COVID-19 Positive Prediction.)

Method
Approach Flat

Acc.

#Params

MACs

Memory

(millions)

(millions)

required

100.0%

11.6

11.5

134Mb

80.6%

100.0%

23.2

23

268Mb

96.8%

90.9%

126.6

3500

2.1Gb

SeC

+PC

93.9%

96.8%

93.5%

94.3%

EfficientNet B3
Approach
Hierarchical
EfficientNet B3
COVID-net [19]

frastructure costs. A 3.59 billion MAC operations model takes much more time
and computations than a 11.5 million MAC model - in the order of almost 300
times -, and the same GPU necessary to run one COVID-Net model can run
more than 15 models of the proposed approach (based on the EfficienteNet B3
flat approach) keeping a comparable (or even better) figures. The improvements, in terms of efficiency, are even greater using the EfficientNet B0 - with
a small trade-off in terms of the sensitivity metric. The complexity can hinder
the use of the model in the future, for instance, on mobile phones or common
desktop computers (without GPU).
5.3. Discussion
In FIGURE 7, we present two X-ray images of COVID-19 infected individuals. Those images are from the test set and therefore, were not seen by the
model during training. According to studies [6], the presence of the COVID-19
infection can be observed through some opacity (white spots) on chest radiography imaging. In the first row of FIGURE 7, one can see the corrected classified
image and its respective activation maps generated by our model. The activation map corresponds to opaque points in the image, which may correspond
to the presence of the disease. For the second row images, it is observed that
the model failed to find opaque points in the image and the activation map
highlights non-opaque regions.
22

Figure 7: Original images and their activation maps according to the proposed approach.
First row presents a patient with COVID-19 (a corrected classified image and its respective
activation maps generated by our model), the second, from a healthy chest x-ray sample (the
model failed to find opaque points in the image and the activation map highlights non-opaque
regions).

23

In FIGURE 8, the confusion matrices of flat and hierarchical approaches
are presented. It is possible to observe that the hierarchical model classifies the
normal class better, though it also shown a noticeable reduction in terms of sensitivity and positive prediction for the COVID-19 class. One hypothesis is that
both Pneumonia and COVID-19 classes are similar (both kinds of pneumonia)
and share key features. Thus, the lack of normal images on second classification
level reduces the diversity of the training set, interfering with model training.
Besides, the computational cost is twice as higher than flat classification since
two models are required. However, we believe that the hierarchical approach has
a key aspect: it suffers less from bias in the dataset/protocol. In [14], a critical
evaluation of the test protocols and databases for methods aiming at classifying
COVID-19 in X-ray images is presented. According to Maguolo and Nanni [14],
the considered datasets are mostly composed of images from different distributions, different databases, and this may favor the deep learning models to learn
patterns related to the image acquisition process, instead of focusing only on
disease patterns.

Figure 8: Confusion matrix of flat (left) and hierarchical (right) approaches respectively with
balanced training set. Class zero is the normal images, 1, pneumonia non-COVID-19, and, 2,
COVID-19.

In the first stage of the hierarchical classification, images related to COVID19 and non-covid pneumonia are given the same classification label. Thus images

24

from different datasets are combined which forces the method to disregard patterns related to the acquisition process or sensors at the first classification stage.
An example of the hierarchical model application can be seen in Figure 9. It
can be seen from the confusion matrix of the first stage (Figure 9 (a)), that
the model is able to classify most instances correctly and for that, we believe it
has focused on the patterns that may help discriminate among different types
of pneumonia.

Figure 9: Confusion matrix hierarchical approach respectively with balanced training set. On
first hierarchical stage (a), class zero is for the normal images and class 1 all Pneumonias (noncovid and COVID-19 pneumonias). On second stage (b) class 0 non-COVID-19 pneumonia,
and, 2, COVID-19.

6. Findings and Future Direction
We summarize our findings as follows.
• An efficient and low computational approach was proposed to detect
COVID-19 patients from chest X-ray images. Even with only a few images
of the COVID-19 class, insightful results with a sensitivity of 90% and a
positive prediction of 100% were obtained, with the evaluation protocol
proposed in [19].
• Regarding the hierarchical analysis, we conclude that there are significant
gains that justify the use of the present task. We believe that it suffers
25

less from the bias present in the evaluation protocols, already discussed
in [14].
• The proposed network blocks, put on top of the base models, showed to be
very effective for the CRX detection problem, in particular, CRX related
to COVID-19.
• The evaluation protocol proposed in [19] is based on the public dataset
“COVID-19 Image Data Collection” [27], which is being expanded by the
scientific community. With more images from the COVID-19 class, it will
be possible to improve the training. However, the test partition tends to
become more challenging. For sake of reproducibility and future comparisons of results, our code is available at https://github.com/ufopcsila
b/EfficientNet-C19.
• The Internet of Medical Things (IOMT) [38] is now a hot topic on industry.
However, the internet can be a major limitation for medical equipment,
especially in poor countries. Our proposal is to move towards a model that
can be fully embedded in conventional smartphones (edge computing),
eliminating the use of the internet or cloud services. In that sense, the
model achieved in this work requires only 55Mb of memory and has a
viable inference time for a conventional cell phone processor.

7. Conclusion
In this paper, we exploit an efficient convolutional network architecture for
detecting any abnormality caused by COVID-19 through chest radiography images. Experiments were conducted to evaluate the neural network performance
on the COVIDx dataset, using two approaches: flat classification and hierarchical classification. Although the datasets are still incipient and, therefore,
limited in the number of COVID-19 related images, effective training off the
deep neural networks has been made possible with the application of transfer
learning and data augmentation techniques.
26

Concerning evaluation, the proposed approach brought improvements compared to baseline work, with an accuracy of 93.9%, COVID-19 Sensitivity of
96.8% and Positivity Prediction of 100% with a computational efficiency more
than 30 times higher.
We believe that the current proposal is a promising candidate for embedding
in medical equipment or even physicians’ mobile phones. However, larger and
more heterogeneous databases are still needed to validate the methods before
claiming that deep learning can assist physicians in the task of detecting COVID19 in X-ray images.

Conflict of interest statement
The authors declare that they have no known competing financial interests or
personal relationships that could have appeared to influence the work reported
in this paper.

References
[1] A. H. AU Davarpanah, A. Mahdavi, A. Sabri, T. F. Langroudi, S. Kahkouee, S. Haseli, M. A. Kazemi, P. Mehrian, A. Mahdavi, F. Falahati, A. M.
Tuchayi, M. Bakhshayeshkaram, M. S. Taheri, Novel screening and triage
strategy in iran during deadly coronavirus disease 2019 (covid-19) epidemic:
Value of humanitarian teleconsultation service, Journal of the American
College of Radiology (2020) 1doi:10.1016/j.jacr.2020.03.015.
[2] J. d. A. B. Araujo-Filho, M. V. Y. Sawamura, A. N. Costa, G. G. Cerri,
C. H. Nomura, COVID-19 pneumonia: what is the role of imaging in diagnosis?, Jornal Brasileiro de Pneumologia 46.
[3] A. C. of Radiology, Acr recommendations for the use of chest radiography and computed tomography (ct) for suspected covid-19 infection, ACR
website.

27

[4] P. Huang, T. Liu, L. Huang, H. Liu, M. Lei, W. Xu, X. Hu, J. Chen, B. Liu,
Use of chest ct in combination with negative rt-pcr assay for the 2019 novel
coronavirus but high clinical suspicion, Radiology 295 (1) (2020) 22–23.
[5] T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao, Z. Sun, L. Xia,
Correlation of chest ct and rt-pcr testing in coronavirus disease 2019 (covid19) in china: a report of 1014 cases, Radiology (2020) 200642.
[6] M.-Y. Ng, E. Y. Lee, J. Yang, F. Yang, X. Li, H. Wang, M. M.-s. Lui,
C. S.-Y. Lo, B. Leung, P.-L. Khong, et al., Imaging profile of the covid-19
infection: radiologic findings and literature review, Radiology: Cardiothoracic Imaging 2 (1) (2020) e200034.
[7] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, nature 521 (7553) (2015)
436–444.
[8] H. Touvron, A. Vedaldi, M. Douze, H. Jégou, Fixing the train-test resolution discrepancy: Fixefficientnet, arXiv preprint arXiv:2003.08237.
[9] P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding,
A. Bagul, C. Langlotz, K. Shpanskaya, et al., Chexnet: Radiologist-level
pneumonia detection on chest x-rays with deep learning, arXiv preprint
arXiv:1711.05225.
[10] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, R. M. Summers, Chestx-ray8:
Hospital-scale chest x-ray database and benchmarks on weakly-supervised
classification and localization of common thorax diseases, in: 2017 IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), 2017,
pp. 3462–3471.
[11] A. K. Jaiswal, P. Tiwari, S. Kumar, D. Gupta, A. Khanna, J. J. Rodrigues,
Identifying pneumonia in chest x-rays: A deep learning approach, Measurement 145 (2019) 511–518.
[12] M. Tan, Q. V. Le, Efficientnet: Rethinking model scaling for convolutional
neural networks, arXiv preprint arXiv:1905.11946.
28

[13] J. Deng, W. Dong, R. Socher, L. Li, Kai Li, Li Fei-Fei, Imagenet: A largescale hierarchical image database, in: 2009 IEEE Conference on Computer
Vision and Pattern Recognition, 2009, pp. 248–255.
[14] G. Maguolo, L. Nanni, A critic evaluation of methods for covid-19 automatic detection from x-ray images, arXiv preprint arXiv:2004.12823.
[15] C. N. Silla, A. A. Freitas, A survey of hierarchical classification across
different application domains, Data Mining and Knowledge Discovery 22 (12) (2011) 31–72.
[16] E. E.-D. Hemdan, M. A. Shouman, M. E. Karar, Covidx-net: A framework of deep learning classifiers to diagnose covid-19 in x-ray images, arXiv
preprint arXiv:2003.11055.
[17] K. Simonyan, A. Zisserman, Very deep convolutional networks for largescale image recognition, arXiv preprint arXiv:1409.1556.
[18] Y. Huang, Y. Cheng, A. Bapna, O. Firat, D. Chen, M. Chen, H. Lee,
J. Ngiam, Q. V. Le, Y. Wu, et al., Gpipe: Efficient training of giant neural
networks using pipeline parallelism, in: Advances in Neural Information
Processing Systems, 2019, pp. 103–112.
[19] L. Wang, A. Wong, Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest radiography images,
arXiv preprint arXiv:2003.09871.
[20] M. Farooq, A. Hafeez, Covid-resnet: A deep learning framework for screening of covid19 from radiographs, arXiv preprint arXiv:2003.14395.
[21] C. Szegedy, S. Ioffe, V. Vanhoucke, A. A. Alemi, Inception-v4, inceptionresnet and the impact of residual connections on learning, in:

Pro-

ceedings of the Thirty-First AAAI Conference on Artificial Intelligence,
AAAIâĂŹ17, AAAI Press, 2017, p. 4278âĂŞ4284.

29

[22] R. M. Pereira, D. Bertolini, L. O. Teixeira, C. N. Silla Jr, Y. M. Costa,
Covid-19 identification in chest x-ray images on flat and hierarchical classification scenarios, Computer Methods and Programs in Biomedicine (2020)
105532.
[23] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, Rethinking the
inception architecture for computer vision, in: Proceedings of the IEEE
conference on computer vision and pattern recognition, 2016, pp. 2818–
2826.
[24] A. I. Khan, J. L. Shah, M. M. Bhat, Coronet: A deep neural network
for detection and diagnosis of covid-19 from chest x-ray images, Computer
Methods and Programs in Biomedicine 196 (2020) 105581.
[25] F. Chollet, Xception: Deep learning with depthwise separable convolutions,
in: 2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), 2017, pp. 1800–1807.
[26] Radiological Society of North America. RSNA pneumonia detection challenge., https://www.kaggle.com/c/rsna-pneumonia-detection-chal
lenge/data, accessed: 2020-04-01.
[27] J. P. Cohen, P. Morrison, L. Dao, Covid-19 image data collection, arXiv
preprint arXiv:2003.11597.
[28] A. Giovagnoni, Facing the covid-19 emergency: we can and we do, La
Radiologia Medica (2020) 1.
[29] I. S. of Medical, I. Radiology, COVID-19. database, https://www.sirm.o
rg/en/category/articles/covid-19-database/, accessed: 2020-04-12.
[30] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L.-C. Chen, Mobilenetv2:
Inverted residuals and linear bottlenecks, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 4510–4520.

30

[31] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang,
A. Karpathy, A. Khosla, M. Bernstein, et al., Imagenet large scale visual recognition challenge, International journal of computer vision 115 (3)
(2015) 211–252.
[32] I. Goodfellow, Y. Bengio, A. Courville, Deep learning, MIT press, 2016.
[33] S. Ioffe, C. Szegedy, Batch normalization: Accelerating deep network training by reducing internal covariate shift, arXiv preprint arXiv:1502.03167.
[34] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov,
Dropout: a simple way to prevent neural networks from overfitting, The
journal of machine learning research 15 (1) (2014) 1929–1958.
[35] P. Ramachandran, B. Zoph, Q. V. Le, Searching for activation functions,
arXiv preprint arXiv:1710.05941.
[36] M. Oquab, L. Bottou, I. Laptev, J. Sivic, Learning and transferring midlevel image representations using convolutional neural networks, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 1717–1724.
[37] E. Luz, G. Moreira, L. A. Z. Junior, D. Menotti, Deep periocular representation aiming video surveillance, Pattern Recognition Letters 114 (2018)
2–12.
[38] G. J. Joyia, R. M. Liaqat, A. Farooq, S. Rehman, Internet of medical things
(iomt): applications, benefits and future challenges in healthcare domain,
Journal of Communications 12 (4) (2017) 240–7.

31

