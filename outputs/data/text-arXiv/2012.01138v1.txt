arXiv:2012.01138v1 [cs.CY] 28 Nov 2020

Clinical prediction system of complications among
COVID-19 patients: a development and validation
retrospective multicentre study
Ghadeer O. Ghosheh1 , Bana Alamad1 , Kai-Wen Yang1 , Faisil Syed2 , Nasir Hayat1 , Imran
Iqbal2 , Fatima Al Kindi2 , Sara Al Junaibi2 , Maha Al Safi2 , Raghib Ali1 , Walid Zaher3 ,
Mariam Al Harbi2* , and Farah E. Shamout1*†
1

Engineering Division, NYU Abu Dhabi
2
Abu Dhabi Health Services
3
G42 Healthcare
*
Joint supervision
†
fs999@nyu.edu

Abstract
Background
Existing prognostic tools mainly focus on predicting the risk of mortality among patients with coronavirus
disease 2019 (COVID-19). However, clinical evidence suggests that COVID-19 can result in non-mortal
complications that affect patient prognosis. To support patient risk stratification, we aimed to develop a
prognostic system that predicts complications common to COVID-19.
Methods
In this retrospective study, we used data collected from 3,352 COVID-19 patient encounters admitted to
18 facilities between April 1 and April 30, 2020, in Abu Dhabi (AD), United Arab Emirates. The hospitals
were split based on geographical proximity to assess for our proposed system’s learning generalizability, AD
Middle region and AD Western & Eastern regions, A and B, respectively. Using clinical data collected
during the first 24 hours of admission, the machine learning-based prognostic system predicts the risk
of developing any of seven complications during the hospital stay. The complications include secondary
bacterial infection, Acute Kidney Injury (AKI), Acute Respiratory Distress Syndrome (ARDS), and elevated
biomarkers linked to increased patient severity, including d-dimer, interleukin-6, aminotransferases, and
troponin. During training, the system applies an exclusion criteria, hyperparameter tuning, and model
selection for each complication-specific model. We assessed its performance using the area under the receiver
operating characteristic curve (AUROC) and the area under the precision recall curve.
Findings
The system achieves good accuracy across all complications and both regions. In test set A (587 patient
encounters), the system achieves 0.91 AUROC for AKI and > 0.80 AUROC for most of the other complications.
In test set B (225 patient encounters), the respective system achieves ≥ 0.90 AUROC for AKI, elevated
troponin, and elevated interleukin-6, and > 0.80 AUROC for most of the other complications. The best
performing models, as selected by our system, were mainly gradient boosting models and logistic regression.

1

Interpretation
Our results show that a data-driven approach using machine learning can predict the risk of such complications
with high accuracy. Such an early risk prediction system could have real-life impact in supporting clinical
decision-making for COVID-19 patients.
Funding
New York University Abu Dhabi.

Research In Context
Evidence before this study.
We conducted an extensive literature review between May 30, 2020, and July 10, 2020, to assess
published work until end of July, 2020, using the key terms “coronavirus”, “COVID-19”, “prognosis”,
“prediction model”, and “machine learning”. Peer reviewed papers obtained from PubMed and
EMBASE in addition to preprints obtained from MedRxiv and BioRxiv were included in our review.
We excluded studies that did not incorporate any machine learning, studies that focused on diagnosis
rather than prognosis, and studies that relied on imaging data. The majority of published work for
COVID-19 patients propose to predict admission to the intensive care unit, mortality, prolonged
hospital stay or the need for mechanical ventilation. There was a clear gap in the machine learning
literature for the simultaneous prediction of non-mortal complications among COVID-19 patients,
despite the vast clinical evidence showing that COVID-19 can result in such complications.
Added value of this study.
We analyzed data extracted from electronic health records for a large cohort of COVID-19 patients
(3,352 COVID-19 patient encounters) admitted to hospitals in Abu Dhabi, United Arab Emirates, to
develop a risk prediction system for seven common complications among COVID-19 patients. We
focus on the accurate prediction of seven complications since they are precursors to widely studied
adverse events, including mortality. This is the first study to study such complications and to present
the patient cohort in the UAE, as most previous studies have focused on European or Chinese patient
cohorts. Our approach achieves good accuracy across all complications and can be easily adapted to
external patient cohorts.
Implications of all available evidence.
We present data-driven system that uses machine learning to predict seven complications indicative of
COVID-19 patient severity. The results highlight the promise of machine learning to support clinical
decision-making and hospital resource management.

2

1

Introduction

The Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) has led to a global health emergency
since the emergence of the coronavirus disease 2019 (COVID-19). Despite containment efforts, more than 55
million confirmed cases have been reported globally, of which 157,785 cases are in the United Arab Emirates
(UAE) as of November 21, 2020 [1]. Due to unexpected burdens on healthcare systems, identifying high risk
groups using prognostic models has become vital to support patient triage.
Most of the recently published prognostic models focus on predicting mortality, the need for intubation, or
admission into the intensive care unit [2]. While the prediction of such adverse events is important for patient
triage, clinical evidence suggests that COVID-19 may result in a variety of complications in organ systems
that may eventually lead to mortality [3]. For example, Acute Respiratory Distress Syndrome (ARDS) related
pneumonia has been reported as a major complication of COVID-19 [4]. Other studies reported alarming
percentages among hospitalized COVID-19 patients that have developed hematological complications [5],
organ dysfunction [6], or secondary bacterial infection [4]. Table 1 summarizes key studies that reported
diagnosed complications or biomarkers which may lead to severe complications across different COVID-19
patient populations. Those findings suggest a pressing need for the development and validation of a prognostic
system that predicts such complications in COVID-19 patients to support patient management.
Here, we address this need by proposing an automated prognostic system that learns to predict a
variety of non-mortal complications among COVID-19 patients admitted to the Abu Dhabi Health Services
(SEHA) facilities, UAE. The system uses multi-variable data collected during the first 24 hours of the
patient admission, including vital-sign measurements, laboratory-test results, and baseline information.
We particularly focus on seven complications based on the clinical evidence presented in Table 1, which
are either based on clinical diagnosis or biomarkers that are indicative of patient severity. To allow for
reproducibility and external validation, we made our code and a test set publicly available at: https:
//github.com/nyuad-cai/COVID19Complications.
Table 1: Summary of clinical studies reporting various non-mortal complications in patients with confirmed COVID-19
diagnosis. The alarming incidence rates suggest a pressing need for developing a clinical decision support system that
predicts such complications.
Complication

Cohort Size

Incidence rate

Location

Elevated Troponin

614
1527

45.3%
8.0%

Italy
China

[7]
[8]

Elevated D-Dimer

248
2377

74.6%
76.0%

China
United States

[9]
[5]

Elevated Aminotransferases

105
5700

21.0%
39.0% & 58.5%∗

China
United States

[10]
[11]

Elevated Interleukin-6

728

16.5%

China

[12]

Secondary Bacterial Infection

191
338

15.0%
5.6%†

China
United States

[4]
[13]

Acute Kidney Injury

5449
98

36.6%
9.2%

United States
South Korea

[6]
[14]

Acute Respiratory Distress
Syndrome

191
98
1099

31.0%
18.4%
3.4%

China
South Korea
China

[4]
[14]
[15]

∗

References

This study reported a 39.0% incidence rate for alanine aminotransferase and & 58.5% for aspartate aminostransferase.
† This was specifically reported for bacteremia.

3

In-patients
n=3,493
p=3,464

Excluded

Pregnant women
n=14

Excluded

Patients under <18 years
old
n=127

In-patients
n=3,352
p=3,323

Key
Abu Dhabi Middle region
Abu Dhabi Western region
Abu Dhabi Eastern region

Abu Dhabi Western and
Eastern Regions

Abu Dhabi Middle
Region

Training Set A
April 1st to April 25th 2020
n=1,829
p=1,824

Test set A
April 26th to April 30th 2020
n=587
p=587

(a)

Training Set B
April 1st to April 25th 2020
n=711
p=703

Test Set B
April 26th to April 30th 2020
n=225
p=225

(b)

Figure 1: (a) The UAE map showcasing the location of the healthcare facilities included in this study. (b) Flowchart
for the overall dataset showing how the inclusion and exclusion criteria were applied to obtain the final training and
test sets, where n represents the number of patient encounters, and p represents the number of unique patients.

2

Methods

We reported this study following the TRIPOD guidance [16].

2.1

Data source

This study is a retrospective multi-centre study that includes anonymized data recorded within 3,493 COVID19 hospital encounters at 18 Abu Dhabi Health Services (SEHA) healthcare facilities in Abu Dhabi, United
Arab Emirates. The study received approval by the Institutional Review Board (IRB) from the Department of
Health (Ref: DOH/CVDC/2020/1125) and New York University (Ref: HRPP-2020-70). There were 9 facilities
in the Middle region, which includes the capital city, and 9 facilities in the Eastern and Western regions.
Those regions are highlighted in Figure 1(a). Figure 1(b) shows the flowchart as we applied the exclusion
criteria to obtain the final data splits. We excluded 127 non-adult encounters and 14 pregnant encounters
and split the dataset into training and test sets. Training set A consisted of 1,829 encounters recorded in the
Middle region between April 1, 2020 and April 25, 2020. To evaluate for temporal generalizability, test set A
included 587 encounters recorded in the Middle region between April 26, 2020 and April 30, 2020. Training
set B included 711 encounters admitted to the Eastern and Western regions between April 1, 2020 and April
25, 2020 and test set B included 225 encounters admitted to the same hospitals between April 26, 2020, and
April 30, 2020.

2.2

Defining and labeling of complications

Based on clinical evidence and in collaboration with clinical experts, we focused on predicting seven
complications, including three clinically diagnosed events such as secondary bacterial infection (SBI), Acute
Kindey Injury (AKI) [17] and ARDS [18] and four biomarkers that may be indicative of patient severity. In
particular, among COVID-19 patients, elevated troponin reflects myocardial injury and has been reported to
be associated with a higher risk of mortality [7], elevated d-dimer is associated with thrombotic events [9],
elevated interleukin-6 is a proinflammatory cytokine that has been shown to be associated with disease severity

4

Table 2: Criteria used to define the occurrence of the complications that our system aims to predict.
Complication

Definition

Elevated Troponin

Troponin T ≥ 14 ng/L

[19]

Elevated D-Dimer

D-Dimer ≥ 500 ng/mL

[20]

Elevated Aminotransferases

AST ≥ 40 U/l AND ALT ≥ 40 U/l

*

Elevated Interleukin-6

Interleukin-6 ≥ 8.43 pg/mL

*

SBI

Positive blood, urine, throat or sputum cultures within 24 hours of sample
collection

*

AKI

Based on the Kidney Disease Improving Global Guidelines (KDIGO) classification, increase in Serum Creatinine by ≥ 0.3mg/dl within 48 hours
OR
increase in Serum Creatinine by ≥ to 1.5 times
OR
Urine volume < 0.5ml/kg/hr for 6 hours

[17]

Based on the Berlin definition, presence of bilateral opacity in radiology reports
AND
Oxygenation: PaO2 /FiO2 ≤300 mm Hg
AND
Timing: ≤ one week
AND
Origin: pulmonary

[18]

ARDS

Reference

* Based on SEHA’s clinical standards.

and in-hospital mortality [12], and elevated aminotransferases have been reported to be associated with liver
Injury [11]. For each patient encounter in the training and test sets, we identified the first occurrence (i.e.,
date and time), if any, of each complication based on the criteria shown in Table 2. The biomarkers-based
complications are defined based on elevated laboratory-test results, SBI is defined based on positive cultures,
AKI is defined based on the KDIGO classification criteria [17], and ARDS is defined based on the Berlin
definition [18], which required the processing of free-text chest radiology reports. Further details on the
processing of those reports is described in Supplementary Section A.

2.3

Input features

We considered data recorded within the first 24 hours of admission as input features to our predictive
models. This data included continuous and categorical features related to the patient baseline information
and demographics, vital signs, and laboratory-test results. Within the patient’s baseline and demographic
information, age and body mass index (BMI) were treated as continuous features, while sex, pre-existing
medical conditions (i.e., hypertension, diabetes, chronic kidney disease, and cancer), and symptoms recorded
at admission (i.e., cough, fever, shortness of breath, sore throat, and rash) were treated as binary features.
As for the vital-sign measurements and laboratory-test results, we excluded any variable that was used
to define the presence of any complication in order to avoid label leakage. In particular, we considered
seven continuous vital-sign features, including systolic blood pressure, diastolic blood pressure, respiratory
rate, peripheral pulse rate, oxygen saturation, auxiliary temperature, and the Glasgow Coma Score, and 19
laboratory-test results, including albumin, activated partial thromboplastin time (APTT), bilirubin, calcium,
chloride, c-reactive protein, ferritin, hematocrit, hemoglobin, international normalized ratio (INR), lactate
dehydrogenase (LDH), lymphocytes count, prothrombin time, procalcitonin, sodium, red blood cell count
(RBC), urea, uric acid, and neutrophils count. All vital-sign measurements and laboratory-test results were
processed into minimum, maximum, and mean statistics. We also defined seven binary input features to
represent whether a complication had occurred within the first 24 hours of admission, to allow the models to
learn from any dependencies between the complications.

5

2.4

Predictive modeling

The proposed system predicts the risk of developing each of the complications during the patient’s stay after
24 hours of admission. This is represented by a vector y consisting of 7 risk scores, where each risk score is
computed by a complication-specific model, such that


y = y El. troponin , y El. d-dimer , y El. aminotransferases , y El. interleukin-6 , y SBI , y AKI , y ARDS ,
where y complication ∈ [0, 1].
The overall workflow of the model development is depicted in Figure 2. For each complication-specific
model, we excluded from its training and test sets patients who developed that complication prior to the time
of prediction. For AKI, we also excluded patients with chronic kidney disease. Then for each complication,
our system trains five model ensembles based on five types of base learners: logistic regression (LR), k-nearest
neighbors (KNN), support vector machine (SVM), multi-layer perceptron (MLP) and a light gradient boosting
model (LGBM). Missing data was imputed using median imputation for all models except for LGBM, which
can natively learn from missing data, and the data was further scaled using min-max scaling for LR and
MLP and standard scaling for SVM and KNN.
For each type of base learner, the system performs a stratified k-folds cross-validation using the complication’s respective training set with k = 3. We performed random hyperparameter search for each base
learner’s hyperparameters [21] over 20 iterations, resulting with 3 trained models per hyperparameter set.
The hyperparameter search ranges are described in Supplementary Section B. We selected the top two
sets of hyperparameters that achieved the highest average area under the receiving operator characteristic
curve (AUROC) on the validation sets, resulting with 6 trained models per ensemble. Then, we selected the
ensemble that achieves the highest average AUROC on the validation set. Each model within the selected
ensemble was further calibrated using isotonic regression on its respective validation set to ensure non-harmful
decision making [22], except for the LR models. The final prediction of each complication consisted of an
average of the predictions of all calibrated base learners per ensemble.
To understand what input features were most predictive of each complication, we performed post-hoc
feature importance analysis using the tree SHapley Additive exPlanations (SHAP) [23]. All analysis was
performed using Python (version 3.7.3), LR, KNN, SVM, and MLP models were trained using the Python
scikit-learn package and the LGBM models were trained using the LightGBM package [24].

2.5

Statistical Analysis

We evaluated each complication ensemble using the AUROC and the area under the precision recall curve
(AUPRC) on the test set. Confidence intervals for all of the evaluation metrics were computed using
bootstrapping with 1,000 iterations [25]. We also assessed the calibration of the ensemble, after post-hoc
calibration of its trained models, using reliability plots and reported calibration intercepts and slopes [22].

2.6

Role of Funding Source

The funding source had no role in the study design or data analysis. The study was performed by all
co-authors who had access to the anonymized dataset.

6

Model Development
Complication labeling

Data source

Data
pre-processing

Elevated troponin
Elevated d-dimer
Elevated aminotransferases
Elevated interleukin-6
Secondary bacterial infection
Acute kidney injury
Acute respiratory distress
syndrome

Complications
training subsets

Hyperparameter
search and model
selection

Evaluation on test
sets

Application
Patient Admission
Data collection & pre-processing

24 hours

Patient Discharge

Predictions of 7 complications
Elevated troponin

Patient baseline
Demographic Information
Vital signs
Laboratory test results

…
Acute respiratory distress syndrome

Figure 2: Overview of our proposed model development approach and expected application in practice. In the first
row, we developed our complication-specific models by first preprocessing the data, identifying the occurrences of
the complications based on the criteria shown in Table 2, training and selecting the best-performing models on the
validation set, and then evaluating the performance on the test set, retrospectively. As for deployment, we expect our
system to predict the risk of developing any of the seven complications for any patient after 24 hours of admission.

3

Results

A total of 3,352 encounters were included in the study and the characteristics of the characteristics of the final
data splits are presented in Table 3. Across all the data splits, the mean age ranges between 39.3 and 45.5
years and the proportion of males ranges between 84.8% to 88.9%. The mortality rate was also less than 4%
across all data splits, ranging between 1.3% and 3.7%. The most prevalent complication across all datasets
was elevated d-dimer, although most patients mainly exhibited elevated d-dimer during the first 24 hours of
admission. Elevated interleukin-6 was the most prevalent complication developed after 24 hours of admission
across all datasets. The incidence of the complications developed after 24 hours were higher in the test sets
than in their respective training sets, except for elevated troponin and d-dimer which were higher in training
set A (3.0% and 6.6%, respectively) than in test set A (2.4% and 4.8%, respectively). The distributions of the
vital signs and laboratory-test results, in terms of of the mean and interquartile ranges, are shown in Table 4.
The performance of the models selected by our system across the two test sets in terms of the AUROC and
AUPRC are shown in Table 5. The ROC, PRC, and reliability plots are also visualized in Figure 3. Across
both test sets, our data-driven approach achieved good accuracy (>0.80 AUROC) for most complications.
In test set A, AKI was the best discriminated endpoint at 24 hours from admission, with 0.905 AUROC
(95% CI 0.861, 0.946). This is followed by ARDS (0.864 AUROC), SBI (0.862 AUROC), elevated troponin
(0.843 AUROC), elevated interleukin-6 (0.820 AUROC), and elevated aminotransferases (0.801 AUROC).
The complication with the worst discrimination was elevated d-dimer (0.717 AUROC). In test set B, AKI
was also the best discriminated endpoint with 0.958 AUROC (95% CI 0.913, 0.994), followed by elevated
troponin (0.913 AUROC), and elevated interleukin-6 (0.899 AUROC). Similar to test set A, elevated d-dimer
was the worst discriminated endpoint (0.714 AUROC). We also observe that LGBM was selected as the
best performing model on the validation sets for most complications, as shown in Supplementary Section
C. LR was selected for AKI in both datasets, for elevated d-dimer in dataset A, and for SBI in dataset B,
highlighting its predictive power despite its simplicity compared to the other machine learning models.
The top four important features for each complication are shown in Figure 4 across the two test sets. In
test set A, age was among the top predictive features for all the complications except for elevated interleukin-6
and AKI. In test set B, C-reactive protein was among the top predictive features for predicting elevated
7

Table 3: Summary of the baseline characteristics of the patient cohort in the training sets and test sets and the
prevalence of the predicted complications. Note that n represents the total number of patients while % is the proportion
of patients within the respective dataset.
Training set A

Test set A

Training set B

Test set B

1829
41.7 (17.0)
1582 (86.5)
295 (16.1)
1534 (83.9)
332 (18.2)
36 (2.0)

587
45.5 (18.0)
522 (88.9)
89 (15.2)
498 (84.8)
83 (14.1)
22 (3.7)

711
39.3 (17.0)
622 (87.5)
120 (16.9)
591 (83.1)
63 (8.8)
9 (1.3)

225
42.7 (20.0)
191 (84.8)
43 (19.1)
182 (80.9)
26 (11.6)
3 (1.3)

Elevated troponin, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

101 (5.5)
47 (2.6)
54 (3.0)

50 (8.5)
36 (6.1)
14 (2.4)

33 (4.6)
20 (2.8)
13 (1.8)

19 (8.4)
5 (2.2)
14 (6.2)

Elevated d-dimer, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

643 (35.2)
523 (28.6)
120 (6.6)

296 (50.4)
268 (45.7)
28 (4.8)

173 (24.3)
130 (18.3)
43 (6.0)

78 (34.7)
60 (26.7)
18 (8.0)

Elevated aminotransferases, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

397 (21.7)
287 (15.7)
110 (6.0)

117 (30.2)
133 (22.7)
44 (7.5)

119 (16.7)
72 (10.1)
47 (6.6)

56 (24.9)
35 (15.6)
21 (9.3)

Elevated interleukin-6, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

245 (13.5)
57 (3.1)
188 (10.3)

126 (21.5)
49 (8.3)
77 (13.1)

65 (9.1)
7 (1.0)
58 (8.2)

28 (12.4)
1 (0.4)
27 (12.0)

SBI, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

92 (5.0)
1 (0.1)
91 (5.0)

45 (7.7)
3 (0.5)
42 (7.2)

23 (3.2)
1 (0.1)
22 (3.1)

17 (7.6)
1 (0.4)
16 (7.1)

AKI, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

126 (6.9)
28 (1.5)
98 (5.4)

52 (8.9)
9 (1.5)
43 (7.3)

32 (4.5)
14 (2.0)
18 (2.5)

16 (7.1)
3 (1.3)
13 (5.8)

ARDS, n (%)
Developed within 24 hours from admission, n (%)
Developed after 24 hours from admission, n (%)

117 (6.4)
61 (3.3)
56 (3.1)

57 (9.7)
26 (4.4)
31 (5.3)

45 (6.3)
23 (3.2)
22 (3.1)

24 (10.7)
13 (5.8)
11 (4.9)

Patient Cohort
Encounters, n
Age, mean (IQR)
Male, n (%)
Arab, n (%)
Non-Arab, n (%)
Critical Care, n (%)
Mortality, n (%)
Complications

aminotransferases, elevated d-dimer, elevated interleukin-6, and ARDS. Other features such as ferritin and
LDH, and BMI, were among the top predictive features for several complications across both sets, specifically
for AKI and ARDS, respectively.
We also visualize the timeline of for two patients in Figure 5, along with the predictions of our system. In
Figure 5(a), the patient shown developed all seven complications during their hospital stay of 43 days. This
highlights the importance of predicting all complications simultaneously, especially for patients who may
develop more than one complication. In Figure 5(b), the patient did not develop any complications during
their hospital stay of two days. To compare both patients, the system’s predictions for patient (a) were
relatively higher than those for patient (b). For example, the AKI predictions were 0.54 and 0.03, respectively,
despite the fact that patient (a) developed AKI at around 20 days from admission. This demonstrates the
value of our system in predicting the risk of developing complications early during the patient’s stay.

8

Table 4: Characteristics of the variables that were used as input features to our models. The mean and interquartile
ranges are shown for the demographic features, vital-sign measurements, and laboratory-test results. For the
commorbidities and symptoms admission, n denotes the number of patients and % denotes the percentage of patients
per the respective dataset.
Variable, unit

Training set A

Test set A

Training set B

Test set B

41.7 (17.0)
26.9 (5.2)

45.5 (18.0)
26.7 å(5.7)

39.3 (17.0)
26.5 (5.7)

42.7 (20.0)
27.9 (6.2)

550 (30.1)
427 (23.3)
68 (3.7)
30 (1.6)

213 (36.3)
221 (37.6)
30 (5.1)
7 (1.2)

168 (23.6)
121 (17.0)
20 (2.8)
12 (1.7)

71 (31.6)
73 (32.4)
7 (3.1)
8 (3.6)

851 (46.5)
28 (1.5)
190 (10.4)
238 (13.0)
29 (1.6)

338 (57.6)
20 (3.4)
99 (16.9)
89 (15.2)
10 (1.7)

259 (36.4)
3 (0.4)
71 (10.0)
118 (16.6)
15 (2.1)

99 (44.0)
3 (1.3)
34 (15.1)
28 (12.4)
5 (2.2)

38.4 (11.1)
38.8 (5.6)
9.9 (5.5)
2.3 (0.2)
100.9 (4.2)
30.1 (23.4)
579.1 (382.2)
0.4 (0.1)
141.9 (21.0)
1.1 (0.1)
260.2 (106.0)
1.9 (1.1)
13.9 (1.2)
0.4 (0.1)
138.8 (3.9)
5.1 (0.8)
4.4 (1.70)
288.4 (121.0)
4.1 (2.3)

35.1 (11.9)
38.1 (6.1)
9.3 (6.1)
2.2 (0.2)
99.7 (4.4)
55.7 (74.6)
672.6 (652.4)
0.4 (0.1)
136.4 (28.0)
1.7 (0.1)
316.5 (153.0)
1.5 (0.9)
13.9 (1.2)
0.8 (0.2)
137.4 (5.5)
5.0 (1.0)
5.3 (2.1)
273.6 (100.0)
4.8 (3.0)

39.9 (6.0)
30.4 (8.3)
9.7 (5.5)
2.3 (0.2)
101.3 (3.3)
22.2 (7.6)
470.9 (288.4)
0.4 (0.1)
143.4 (22.0)
1.0 (0.1)
235.3 (68.6)
2.0 (1.2)
11.0 (1.6)
0.5 (0.1)
139.4 (3.0)
5.1 (0.78)
4.2 (1.5)
295.5 (108.0)
4.2 (2.5)

38.6 (7.7)
29.5 (5.7)
9.4 (5.0)
2.3 (0.2)
100.7 (4.4)
29.6 (20.8)
624.6 (628.0)
0.4 (0.1)
141.6 (18.0)
1.0 (0.1)
263.0 (103.1)
1.7 (1.0)
10.8 (1.1)
0.2 (0.1)
138.6 (4.4)
5.1 (0.1)
4.7 (1.9)
288.3 (115.5)
4.5 (2.4)

126.3 (15.0)
77.5 (9.8)
18.9 (1.0)
82.6 (11.5)
98.4 (1.6)
36.9 (0.4)
14.8 (0.0)

126.8 (16.0)
76.9 (9.9)
20.2 (2.5)
85.4 (11.6)
97.5 (2.1)
37.0 (0.7)
15.0 (0.0)

128.8 (15.5)
77.9 (10.3)
18.1 (0.7)
81.7 (13.4)
98.5 (1.0)
36.9 (0.4)
14.8 (0.0)

128.2 (15.7)
77.5 (10.7)
18.7 (0.8)
82.5 (12.5)
98.2 (1.4)
37.1 (0.6)
14.8 (0.0)

Demographics, mean (IQR)
Age
BMI
Comorbidties, n (%)
Hypertension
Diabetes
Chronic kidney disease
Cancer
Symptoms at admission, n (%)
Cough
Fever
Shortness of breath
Sore throat
Rash
Laboratory-test results, mean (IQR)
Albumin, g/L
APTT, seconds
Bilirubin, micromol/L
Calcium, mmol/L
Chloride, mmol/L
C-reactive protein, mg/L
Ferritin, mcg/L
Hematocrit, L/L
Hemoglobin, g/L
INR, ratio
LDH, IU/L
Lymphocytes, 109 /L
Prothrombin time, seconds
Procalcitonin, ng/mL
Sodium, mmol/L
RBC, million/mm3
Urea, mmol/L
Uric Acid, mmol/L
Neutrophil, 109 /L
Vital-sign measurements, mean (IQR)
Systolic Blood Pressure, mmHg
Diastolic Blood Pressure, mmHg
Respiratory Rate, breaths per minute
Peripheral Pulse Rate, beats per minute
Oxygen Saturation, %
Temperature Auxiliary, ◦ C
Glasgow Coma Score

9

Table 5: Performance evaluation of the best performing models on test sets A & B, which were selected based on the
average AUROC performance on the validation sets, as shown in Supplementary Section C. Model type indicates the
type of the base learners within the final selected ensemble. All the metrics were computed using bootstrapping with
1,000 iterations [25].
Complication

Elevated troponin

Elevated d-dimer

Elevated aminotransferases

Elevated interleukin-6

SBI

AKI

ARDS

Result

Test Set A

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

Test Set B

0.843
0.226
0.661
-0.032

LGBM
(0.720, 0.945)
(0.106, 0.499)
(0.134, 1.264)
(-0.101, 0.029)

LGBM
0.913 (0.788, 0.994)
0.674 (0.405, 0.898)
1.029 (0.142, 2.536)
0.060 (-0.027, 0.257)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

0.717
0.315
1.592
-0.187

LR
(0.618, 0.816)
(0.167, 0.494)
(0.460, 1.841)
(-0.241, 0.023)

LGBM
0.714 (0.612, 0.810)
0.235 (0.118, 0.397)
0.338 (-0.33, 1.481)
0.071 (-0.102, 0.206)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

0.801
0.261
-0.145
0.205

LGBM
(0.741, 0.858)
(0.176, 0.391)
(-0.193, 0.159)
(0.110, 0.254)

LGBM
0.808 (0.699, 0.894)
0.396 (0.229, 0.604)
0.628 (0.172, 1.135)
0.042 (-0.110, 0.186)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

LGBM
0.820 (0.760, 0.872)
0.514 (0.403, 0.635)
0.777 (0.540, 0.980)
0.018 (-0.046, 0.094)

0.899
0.776
1.120
-0.094

LGBM
(0.810, 0.971)
(0.623, 0.900)
(0.879, 1.299)
(-0.193, 0.034)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

0.862
0.486
0.977
-0.021

LGBM
(0.802, 0.920)
(0.339, 0.645)
(0.566, 1.298)
(-0.126, 0.095)

0.843
0.612
1.583
-0.075

LR
(0.721, 0.960)
(0.384, 0.847)
(0.846, 1.865)
(-0.155, 0.051)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

0.905
0.377
0.683
-0.030

LR
(0.861, 0.946)
(0.238, 0.574)
(0.313, 1.032)
(-0.129, 0.079)

LR
0.958 (0.913, 0.994)
0.637 (0.344, 0.901)
1.127 (-0.022, 1.808)
0.076 (-0.106, 0.216)

Model type
AUROC
AUPRC
Calibration Slope
Calibration Intercept

LGBM
0.864 (0.809, 0.910)
0.340 (0.202, 0.496)
1.346 (1.082, 1.419)
-0.171 (-0.222, -0.071)

LGBM
0.808 (0.621, 0.972)
0.570 (0.273, 0.842)
2.023 (0.486, 2.18)
-0.063 (-0.136, 0.032)

10

1.0

0.8

0.8

0.8

0.6

0.6

0.4
0.2

0.4
0.2

0.2

0.4
0.6
0.8
False positive rate

0.0
0.0

1.0

0.2

0.4
0.6
Recall

0.8

0.6
0.4

0.0
0.0

1.0

1.0

0.8

0.8

0.8

0.6

0.6

0.2
0.0
0.0

True Proability in each bin

1.0

0.4

0.4
0.2

0.2

0.4
0.6
0.8
False positive rate

0.0
0.0

1.0

0.2

(a)

0.4
0.6
Recall

0.8

1.0

Elevated troponin
Elevated d-dimer
Elevated amino.
Elevated IL6
SBI
AKI
ARDS

0.2

1.0

Precision

True positive rate

0.0
0.0

True Proability in each bin

1.0

Precision

True positive rate

1.0

0.2

0.4
0.6
0.8
Predicted Probablity

1.0

0.2

0.4
0.6
0.8
Predicted Probablity

1.0

0.6
0.4
0.2
0.0
0.0

(b)

(c)

Figure 3: The (a) ROC curves, (b) PRC curves, and (c) calibration curves are shown for all model ensembles evaluated
on test set A (top) and test set B (bottom). The color legend for all figures is shown on the right. The numerical
values for the AUROC, AUPRC, calibration slopes and intercepts can be found in Table 5.

Elevated troponin
Age

Min SpO_2
Max Procalcitonin
Max Respiratory Rate

Max Ferritin
Min Ferritin
Age
Min Systolic Blood Pressure

Elevated d-dimer

Max Respiratory Rate
Shortness of Breath
Max C Reactive Protein
Mean SpO_2

Elevated interleukin-6

Max Respiratory Rate
Min SpO_2
Max Albumin
Max C Reactive Protein

Elevated interleukin-6

Max LDH
Min LDH
Max Ferritin
Min Ferritin

AKI

Max C Reactive Protein
Min SpO_2
Max LDH
Max Sodium

Elevated
aminotransferases

Max Respiratory Rate
Age
BMI
Max Systolic Blood Pressure

SBI

Min SpO_2
Mean Respiratory Rate
Mean Calcium
Min C Reactive Protein

Elevated d-dimer

Max Peripheral Pulse Rate
Age
Min SpO_2
Mean SpO_2

Elevated
aminotransferases

Mean Diastolic Blood Pressure
Hypertension
Max RBC
Max Ferritin

Elevated troponin

SBI

Max Ferritin
Min Ferritin
Mean Ferritin
Min LDH

AKI

Min Ferritin
Max Ferritin
Min LDH
Max LDH
BMI
Mean C Reactive Protein
Min SpO_2
Min Systolic Blood Pressure

Max Respiratory Rate
BMI
Age
Mean SpO_2

ARDS

0

0.1 0.2 0.3 0.4
mean SHAP values

ARDS

0

0.5

(a)

0.2
0.4
0.6
mean SHAP values

0.8

(b)

Figure 4: The four most important features are shown for each complication in (a) test set A and (b) test set B.
Feature importance was computed using the average SHAP values of the six models per ensemble.

11

Admission Elevated D-Dimer

0

ARDS

5

Elevated Interleukin-6

10

Secondary Bacterial Infection Elevated Troponin

15

20

Elevated Aminotransferases

25

30

AKI

Dicharge

35

40

45

(a)
Admission

0.0

Dicharge

0.2

0.4

0.6

0.8

1.0

1.2

1.4

1.6

1.8

2.0

(b)
Figure 5: Timeline showing the development of complications with respect to number of days from admission (x-axis)
for two sample patients. (a) For [y El. troponin , y El. d-dimer , y El. aminotransferases , y El. interleukin-6 , y SBI , y AKI , y ARDS ], our
system predictions (multiplied by a 100 to obtain percentages) were [71%, NA, 60%, 87%, 77%, 54%, 44%], where NA
denotes that the complication had already occurred during the first 24 hours, hence it was not predicted. (b) This
patient did not develop and complications and our model predictions were [2%, 7%, 1%, 16%, 1%, 3%, 2%].

4

Discussion

In this study, we developed a predictive system of commonly occurring complications among COVID-19
patients to support patient triage. During validation, the system was assessed for performance and calibration.
To the best of our knowledge, this is one of the few machine learning studies that predict non-mortal
complications secondary to COVID-19 and the first to demonstrate a system that predicts the risk of such
complications simultaneously. The system achieves a good performance across all complications, for example,
reaching above 0.9 AUROC for AKI across two independent datasets. This study has several strengths and
limitations.
One of the main strengths is that we used multicentre data collected from 18 facilities across several
regions in Abu Dhabi, UAE. COVID-19 treatment is free for all patients, hence there were no obvious gaps
in terms of access to healthcare services in our dataset. Our dataset is diverse since Abu Dhabi is residence
for more than 200 nationalities, of which only 19.0% of the population only is Emirati. Those characteristics
of the dataset make our findings relevant to a global audience. This is also the first data-driven study to
present the population in the UAE and one of few studies with large sample sizes (3,352 COVID-19 patient
encounters) among COVID-19 related studies, while most previous studies have focused on European or
Chinese patient cohorts. Despite the diversity of the dataset, one limitation is that we did not perform
validation on a patient cohort external to the UAE. Compared to other international patient cohorts, our
patient cohort is relatively younger, with a lower overall mortality rate, suggesting that our system needs to
be further validated on populations with different demographic distributions [4, 7, 13, 14]. Our data-driven
approach and open-access code can be easily adapted for such purposes.
Several studies reported worse prognosis among COVID-19 infected patients who had multi-organ failure,
severe inflammatory response, and other hematological complications [5, 6, 7, 10]. Most existing studies
focus on predicting the mortality endpoint [2]. The low mortality rate in our dataset strongly discouraged
the development of a mortality risk prediction score, as small sample sizes may lead to biased models [2].
Our work was motivated by predicting the precursors of such severe adverse events, as identified by the
World Health Organization [3]. We identified and predicted seven complications indicative of patient severity
in order to avoid worse patient outcomes. The prevalence of the predicted complications ranged between
2%-10% and 2%-13% in our training and test sets, respectively. This high class imbalance is reflected in
the AUPRC results. Since most of those tasks have not been investigated thoroughly before, our results
introduce new benchmarks to evaluate other competing models. Future work should also investigate the use
of multi-label deep learning classifiers, while accounting for the exclusion criteria during training.

12

An important aspect of this study is that the labeling criteria relies on renowned clinical standards and
hospital-acquired data to identify the exact time of the occurrence of such complications. In collaboration with
the clinical experts, this approach was considered more reliable than relying on International Classification
of Disease (ICD) codes, since ICD codes are generally used for billing purposes and their derivation may
vary across facilities, especially during a pandemic. One limitation of the labeling procedure is that it could
miss patients for whom the data used in identifying a particular complication was not collected. However,
this issue is more closely related to data collection practices at institutions and clinical data is often not
missing at random. We also avoided label leakage by ensuring that there is no overlap between the set of
input features and the features used to identify complications.
The feature importance analysis revealed that age, oxygen saturation, and respiratory rate are highly
predictive of several complications. Since COVID-19 is predominantly a pulmonary illness, it was not
surprising that oxygen saturation and respiratory rate ranked among the highest predictive features. Such
features are routinely collected at hospitals and do not incur any additional data collection costs. We also
identified C-reactive protein, ferritin, LDH, procalcitonin, systolic blood pressure, and diastolic blood pressure
as markers for severity among COVID-19 patients, which is aligned with clinical literature [20, 26]. This
analysis demonstrates that our system’s learning is clinically meaningful and relevant.
We assessed our models’ calibration by reporting the calibration slopes and intercepts with confidence
intervals and visualizing the calibration curves. Sufficiently large datasets are usually needed to produce
stable calibration curves at model validation stage. Despite the size of our dataset, we found that reporting
the calibration slopes and intercepts would provide a concise summary of potential problems with our system’s
risk calibration, to avoid harmful decision-making [22]. Overall, our results show that our ensemble models
were adequately calibrated across all complications, as shown in Table 5 and Figure 3(c). This is also reflected
in the sample patient timelines shown in Figure 5, where the predicted risks for the patient who experienced
the complications were relatively higher than those predicted for the patient who did not experience any
complications. Limiting factors to perfect calibration are the small dataset size and the fact that the ensemble
prediction consists of an average of the predictions of the individually calibrated models. Further work should
investigate how to improve the calibration of ensemble models.
Our data-driven approach and results highlight the promise of machine learning in predicting the risk
of complications among COVID-19 patients. The proposed approach performs well when applied to two
independent multicentre training and test sets in the UAE. The system can be easily implemented in practice
due to several factors. First, the input features that our system uses are routinely collected by hospitals
that accommodate COVID-19 patients as recommended by WHO. Second, training the machine learning
models within our system does not require high computational resources. Finally, through feature importance
analysis, our system can offer interpretability, and is also fully automated as it does not require any manual
interventions. To conclude, we propose a clinically applicable prognostic system that predicts non-mortal
complications among COVID-19 patients. Our system can serve as a guide to anticipate the course of
COVID-19 patients and to help initiate more targeted and complication-specific decision-making on treatment
and triage.

5

Contributors

GOG, BA, and KWY managed and analyzed the data. FS and IQ extracted, anonymized, and provided the
dataset for analysis. GOG, KWY, and NH developed and maintained the experimental codebase. FAK, SAJ,
MAS, RA, and MAH provided clinical expertise. WZ, FS, MAH and FES designed the study. MAH and
FES supervised the work. GOG, BA, KWY, and FES wrote the manuscript. All authors interpreted the
results and revised and approved the final manuscript.

13

6

Data sharing

We are unable to share the full dataset used in this study due to restrictions by the data provider. However,
to allow for reproducibility and benchmarking on our dataset, we are sharing test set B (n=225), the trained
models, and the source code online at https://github.com/nyuad-cai/COVID19Complications.

7

Acknowledgments

We would like to thank NYU Abu Dhabi for the generous funding. We would also like to thank Waqqas
Zia and Benoit Marchand from the Dalma team at New York University Abu Dhabi for supporting data
management and access to computational resources. This study was supported through the data resources
and staff expertise provided by Abu Dhabi Health Services.

References
[1] Ensheng Dong, Hongru Du, and Lauren Gardner. An interactive web-based dashboard to track covid-19
in real time. The Lancet infectious diseases, 20(5):533–534, 2020.
[2] Laure Wynants, Ben Van Calster, Gary S Collins, Richard D Riley, Georg Heinze, Ewoud Schuit,
Marc MJ Bonten, Darren L Dahly, Johanna AA Damen, Thomas PA Debray, et al. Prediction models
for diagnosis and prognosis of covid-19: systematic review and critical appraisal. bmj, 369, 2020.
[3] John C Marshall, Srinivas Murthy, Janet Diaz, Neil Adhikari, Derek C Angus, Yaseen M Arabi, Kenneth
Baillie, Michael Bauer, Scott Berry, Bronagh Blackwood, et al. A minimal common outcome measure
set for covid-19 clinical research. The Lancet Infectious Diseases, 2020.
[4] Fei Zhou, Ting Yu, Ronghui Du, Guohui Fan, Ying Liu, Zhibo Liu, Jie Xiang, Yeming Wang, Bin Song,
Xiaoying Gu, Lulu Guan, Yuan Wei, Hui Li, Xudong Wu, Jiuyang Xu, Shengjin Tu, Yi Zhang, Hua
Chen, and Bin Cao. Clinical course and risk factors for mortality of adult inpatients with covid-19 in
wuhan, china: a retrospective cohort study. The Lancet, 395(10229):1054 – 1062, 2020.
[5] Jeffrey S Berger, Dennis Kunichoff, Samrachana Adhikari, Tania Ahuja, Nancy Amoroso, Yindalon
Aphinyanaphongs, Meng Cao, Ronald Goldenberg, Alexander Hindenburg, James Horowitz, et al.
Prevalence and outcomes of d-dimer elevation in hospitalized patients with covid-19. Arteriosclerosis,
thrombosis, and vascular biology, 40(10):2539–2547, 2020.
[6] Jamie S. Hirsch, Jia H. Ng, Daniel W. Ross, Purva Sharma, Hitesh H. Shah, Richard L. Barnett,
Azzour D. Hazzan, Steven Fishbane, Kenar D. Jhaveri, Mersema Abate, and et al. Acute kidney injury
in patients hospitalized with covid-19. Kidney International, 98(1):209–218, 2020.
[7] Carlo Mario Lombardi, Valentina Carubelli, Annamaria Iorio, Riccardo M Inciardi, Antonio Bellasi,
Claudia Canale, Rita Camporotondo, Francesco Catagnano, Laura A Dalla Vecchia, Stefano Giovinazzo,
et al. Association of troponin levels with mortality in italian patients hospitalized with coronavirus
disease 2019: results of a multicenter study. JAMA cardiology, 2020.
[8] Bo Li, Jing Yang, Faming Zhao, Lili Zhi, Xiqian Wang, Lin Liu, Zhaohui Bi, and Yunhe Zhao. Prevalence
and impact of cardiovascular metabolic diseases on covid-19 in china. Clinical Research in Cardiology,
109(5):531–538, 2020.
[9] Yumeng Yao, Jiatian Cao, Qingqing Wang, Qingfeng Shi, Kai Liu, Zhe Luo, Xiang Chen, Sisi Chen,
Kaihuan Yu, Zheyong Huang, et al. D-dimer as a biomarker for disease severity and mortality in covid-19
patients: a case control study. Journal of intensive care, 8(1):1–11, 2020.

14

[10] Qi Wang, Hong Zhao, Li-Gai Liu, Yan-Bin Wang, Ting Zhang, Ming-Hui Li, Yan-Li Xu, Gui-Ju Gao,
Hao-Feng Xiong, Ying Fan, et al. Pattern of liver injury in adult patients with covid-19: a retrospective
analysis of 105 patients. Military Medical Research, 7(1):1–8, 2020.
[11] Safiya Richardson, Jamie S. Hirsch, Mangala Narasimhan, James M. Crawford, Thomas McGinn,
Karina W. Davidson, , and the Northwell COVID-19 Research Consortium. Presenting Characteristics,
Comorbidities, and Outcomes Among 5700 Patients Hospitalized With COVID-19 in the New York City
Area. JAMA, 323(20):2052–2059, 05 2020.
[12] Zeming Liu, Jinpeng Li, Danyang Chen, Rongfen Gao, Wen Zeng, Sichao Chen, Yihui Huang, Jianglong
Huang, Wei Long, Man Li, Liang Guo, Xinghuan Wang, and Xiaohui Wu. Dynamic interleukin-6 level
changes as a prognostic indicator in patients with covid-19. Frontiers in Pharmacology, 11:1093, 2020.
[13] Parag Goyal, Justin J. Choi, Laura C. Pinheiro, Edward J. Schenck, Ruijun Chen, Assem Jabri, Michael J.
Satlin, Thomas R. Campion, Musarrat Nahid, Joanna B. Ringel, Katherine L. Hoffman, Mark N. Alshak,
Han A. Li, Graham T. Wehmeyer, Mangala Rajan, Evgeniya Reshetnyak, Nathaniel Hupert, Evelyn M.
Horn, Fernando J. Martinez, Roy M. Gulick, and Monika M. Safford. Clinical characteristics of covid-19
in new york city. New England Journal of Medicine, 382(24):2372–2374, 2020.
[14] Kyung Soo Hong, Kwan Ho Lee, Jin Hong Chung, Kyeong-Cheol Shin, Eun Young Choi, Hyun Jung
Jin, Jong Geol Jang, Wonhwa Lee, and June Hong Ahn. Clinical features and outcomes of 98 patients
hospitalized with sars-cov-2 infection in daegu, south korea: a brief descriptive study. Yonsei Medical
Journal, 61(5):431, 2020.
[15] Wei-jie Guan, Zheng-yi Ni, Yu Hu, Wen-hua Liang, Chun-quan Ou, Jian-xing He, Lei Liu, Hong Shan,
Chun-liang Lei, David SC Hui, et al. Clinical characteristics of coronavirus disease 2019 in china. New
England journal of medicine, 382(18):1708–1720, 2020.
[16] Gary S Collins, Johannes B Reitsma, Douglas G Altman, and Karel GM Moons. Transparent reporting
of a multivariable prediction model for individual prognosis or diagnosis (tripod) the tripod statement.
Circulation, 131(2):211–219, 2015.
[17] Arif Khwaja. Kdigo clinical practice guidelines for acute kidney injury. Nephron Clinical Practice,
120(4):c179–c184, 2012.
[18] The ARDS Definition Task Force. Acute Respiratory Distress Syndrome: The Berlin Definition. JAMA,
307(23):2526–2533, 06 2012.
[19] Zhivko Zhelev, Christopher Hyde, Emily Youngman, Morwenna Rogers, Simon Fleming, Toby Slade,
Helen Coelho, Tracey Jones-Hughes, and Vasilis Nikolaou. Diagnostic accuracy of single baseline
measurement of elecsys troponin t high-sensitive assay for diagnosis of acute myocardial infarction in
emergency department: systematic review and meta-analysis. Bmj, 350:h15, 2015.
[20] Ian Huang, Raymond Pranata, Michael Anthonius Lim, Amaylia Oehadian, and Bachti Alisjahbana.
C-reactive protein, procalcitonin, d-dimer, and ferritin in severe coronavirus disease-2019: a meta-analysis.
Therapeutic advances in respiratory disease, 14:1753466620937175, 2020.
[21] James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. The Journal of
Machine Learning Research, 13(1):281–305, 2012.
[22] Ben Van Calster, Daan Nieboer, Yvonne Vergouwe, Bavo De Cock, Michael J Pencina, and Ewout W
Steyerberg. A calibration hierarchy for risk models was defined: from utopia to empirical data. Journal
of clinical epidemiology, 74:167–176, 2016.
[23] Scott M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M Prutkin, Bala Nair, Ronit Katz,
Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. From local explanations to global understanding
with explainable ai for trees. Nature machine intelligence, 2(1):2522–5839, 2020.
15

[24] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan
Liu. Lightgbm: A highly efficient gradient boosting decision tree. In I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information
Processing Systems 30, pages 3146–3154. Curran Associates, Inc., 2017.
[25] Thomas J DiCiccio and Bradley Efron. Bootstrap confidence intervals. Statistical science, pages 189–212,
1996.
[26] Jinjun Ran, Ying Song, Zian Zhuang, Lefei Han, Shi Zhao, Peihua Cao, Yan Geng, Lin Xu, Jing Qin,
Daihai He, et al. Blood pressure control and adverse outcomes of covid-19 infection in patients with
concomitant hypertension in wuhan, china. Hypertension Research, pages 1–10, 2020.
[27] Vitaly Herasevich, Murat Yilmaz, Hasrat Khan, Rolf D Hubmayr, and Ognjen Gajic. Validation of an
electronic surveillance system for acute lung injury. Intensive care medicine, 35(6):1018–1023, 2009.
[28] Helen C. Azzam, Satjeet S. Khalsa, Richard Urbani, Chirag V. Shah, Jason D. Christie, Paul N. Lanken,
and Barry D. Fuchs. Validation Study of an Automated Electronic Acute Lung Injury Screening Tool.
Journal of the American Medical Informatics Association, 16(4):503–508, 07 2009.

16

Supplementary Information
A

Details of data pre-processing for labeling the complications

KDIGO classification was used to classify AKI encounters [17]. The definition has three criteria, and if any
of them were satisfied, the patient was assigned a diagnosis of AKI. The three criteria were either an increase
in serum creatinine of 0.3 mg/dl within 48 hours, an increase of 1.5 times the baseline serum creatinine
measurement, or urine output of less than 0.5 ml/kg/hr for 6 hours [17]. We only assessed the first two
definitions, since urine output was not available in our dataset. The patient’s first record of serum creatinine
was treated as the baseline for that patient. Patients with reported chronic kidney disease were excluded
from the training and testing AKI subsets.
The Berlin definition was employed to identify the timing and incidence of ARDS [18]. The full ARDS
labeling process is illustrated by the flow diagram in Figure 1. Textual chest X-ray reports and CT scan
reports were processed using natural language processing (NLP) techniques to identify three categorized
key terms: opacity, bilaterality, and ARDS. The lexicon developed was in reference to the Herasevich [27]
and ASSIST [28] sniffers, which was further refined and validated based on clinical expertise. To minimize
the influence of uncertainty profiles, the negation expression “no” was searched 40 characters prior to the
identification of opacity. The ARDS diagnosis was confirmed if either one of the two criteria is satisfied:
(1) the ARDS term is present or (2) both terms of bilaterality and opacity are present in the report. We
identified the first radiology observation of bilateral opacity, as subsequent reports usually refer to the ones
previously conducted for the identical patient instead of repeating the full interpretation and findings. Manual
inspection of portions of the reports was done to validate the efficacy of the algorithm.
For the oxygenation criteria, 13,862 arterial partial pressure of oxygen (P aO2 ) measurements acquired
through arterial blood gas tests (ABG) were recorded for 358 unique patients. We have confirmed with SEHA
clinicians that such test is only conducted for patients suspected of ARDS or with severe symptoms, and
therefore, patients without one can be ruled out of ARDS directly. Each P aO2 measurement was matched
with the closet prior record of F iO2 (the fraction of inspired oxygen) for the given patient to obtain the P/F
ratio. For patients with missing F iO2 measurements, we assumed that they were not on oxygen therapy and
were assigned a value of 0.2095 (20.95% of oxygen in air). The patients were then labeled as potentially
having ARDS if their P/F ratio ≤ 300 mm Hg.
The earliest recorded time —either arrival time, admission time, or the first time the patient tested
positive for COVID-19 —was utilized in lieu of the precise point of clinical insult of respiratory symptoms
for the timing criteria of the Berlin definition. To rule out pulmonary edema of other origin, patients with
cardiac edema prior to the onset of ARDS were identified from the vitals and excluded. With the criteria and
steps delineated herein, 243 patients were identified as having ARDS across both training sets as well as test
sets.

17

All patients (n=3493)

Imaging

Have imaging report
Yes

Terms for Identiﬁcation

Opacity

bilateral
biapical
bibasilar
bibasal
widespread
diffuse
perihilar
parahilar
multifocal
extensive
symmetrical
both lung
"left" and "right"

opacity
opacities
opaciﬁcation
shadowing
inﬁltrate
inﬁltration
consolidate
consolidation
pneumonia
aspiration
groundglass
ground glass
reticular
cyst

(n=3315)

(Bilaterality AND Opacity)
OR (ARDS)

Yes

Bilaterality

No

(n=178)
No

(n=1567)

(n=1748)
No

Oxygenation

Have PaO2 record
Yes

(n=347)

PaO2 ≤ 300mmHg
Yes

Timing

Yes

No

ARDS
acute respiratory distress syndrome

No

(n=22)

(n=244)

Cardiac edema

ARDS

No

(n=81)

(n=266)

Timing ≤1 week

Origin

(n=1401)

Yes

(n=1)

(n=243)

ARDS (n=243)

Not ARDS (n=3250)

< 24 hrs (n=123)
≥ 24 hrs (n=120)

Figure 1: The ARDS labeling process in our dataset, in accordance with the four criteria of the Berlin definition [18]:
imaging, oxygenation, timing, and origin. The lexicon developed for identifying bilateral opacity in radiology reports
is also shown within the table on the left.

B

Hyperparameter search

Our system performs random search for the hyperparameters of the machine learning models and then
evaluates their performance on the validation sets. The searched hyperarameters for each of the models are
shown in Table B.
Table B: Hyperparameter values considered during the random hyperparameter search. Ranges are indicated
with a ‘-’.
Model

Hyperparameters

Values

Logistic Regression

Regularization parameter C
Max iterations

[0.01, 0.10, 0.1, 10, 25, 50, 100]
[50, 100, 200]

Leaf size
Power parameter
N neighbors

[1-50]
[1,2]
[1 - 30]

Regularization parameter C
Gamma

[0.01, 0.10, 0.1, 10, 25, 50, 100]
[1e-2, 1e-3, 1e-4, 1e-5]

L2 penalty parameter alpha
Activation function
Learning rate
Weight optimization solver
Hidden layer sizes

[0.005,0.002, 0.01,0.2, 0.03, 0.05]
[Tanh, Relu]
[Constant, Adaptive]
[Sgd, Adam]
[(50,50,50), (50,100,50), (100,)]

Number of leaves
Learning rate
Max depth
N estimators

[10-40]
[0.005, 0.002, 0.01,0.2, 0.03, 0.1]
[1-10]
[200-500]

K-Nearest Neighbors

Support Vector Machine

Multi-layer Perceptron

Light Gradient Boosting Model

18

C

Model comparison

After preprocessing the data, we compared the performance of 5 ensembles based on 5 types of base learners
on the validation sets: Logistic Regression (LR), K-Nearest Neighbors (KNN), Support Vector Machine (SVM)
Multi-layer Perceptron (MLP), and Light Gradient Boosting Model (LGBM). The models were compared
using the AUROC and AUPRC and the results are shown in Table C. We selected the ensemble that achieved
the highest AUROC on the validation set.
Table C: Performance comparison for the different ensembles on the validation sets. Best performance is shown in
bold.

Validation Set A
Complication

Elevated troponin

Elevated d-dimer

Elevated aminotransferases

Elevated interleukin-6

SBI

AKI

ARDS

Validation Set B

Models

AUROC

AUPRC

AUROC

AUPRC

LR
KNN
SVM
MLP
LGBM

0.908
0.839
0.829
0.816
0.919

0.409
0.298
0.175
0.201
0.430

0.977
0.882
0.956
0.937
0.990

0.557
0.327
0.243
0.291
0.686

LR
KNN
SVM
MLP
LGBM

0.742
0.704
0.658
0.700
0.741

0.291
0.220
0.198
0.239
0.247

0.724
0.652
0.691
0.669
0.753

0.329
0.163
0.217
0.184
0.327

LR
KNN
SVM
MLP
LGBM

0.841
0.792
0.756
0.754
0.849

0.361
0.236
0.237
0.208
0.375

0.850
0.802
0.831
0.842
0.884

0 0.597
0.483
0.268
0.525
0.5786

LR
KNN
SVM
MLP
LGBM

0.874
0.846
0.823
0.853
0.907

0.550
0.445
0.380
0.467
0.649

0.905
0.869
0.905
0.881
0.9464

0.602
0.574
0.575
0.587
0.690

LR
KNN
SVM
MLP
LGBM

0.873
0.783
.825
0.802
0.904

0.360
0.291
0.226
0.274
0.501

0.945
0.918
0.911
0.935
0.931

0.625
0.464
0.490
0.462
0.417

LR
KNN
SVM
MLP
LGBM

0.907
0.809
0.818
0.775
0.889

0.459
0.240
0.235
0.218
0.449

0.829
0.740
0.807
0.809
0.828

0.225
0.319
0.262
0.283
0.225

LR
KNN
SVM
MLP
LGBM

0.891
0.835
0.825
0.770
0.911

0.310
0.178
0.220
0.143
0.360

0.950
0.901
0.922
0.931
0.960

0.488
0.364
0.326
0.415
0.654

19

