Diagnosis/Prognosis of COVID-19 Images:
Challenges, Opportunities, and Applications
Arash Mohammadi† , Senior Member, IEEE, Yingxu Wang∗∗ , Fellow, IEEE, Nastaran Enshaei† , Graduate Student
Member, IEEE, Parnian Afshar† , Graduate Student Member, IEEE, Farnoosh Naderkhani† , Member, IEEE,
Anastasia Oikonomou (MD)†† , Moezedin Javad Rafiee (MD)∗ , Helder C. R. Oliveira∗∗ , Member, IEEE, Svetlana
Yanushkevich∗∗ , Senior Member, IEEE, and Konstantinos N. Plataniotis‡‡ , Fellow, IEEE

arXiv:2012.14106v1 [eess.IV] 28 Dec 2020

† Concordia
†† Department

Institute for Information Systems Engineering (CIISE), Concordia University, Montreal, Canada
of Medical Imaging, Sunnybrook Health Sciences Centre, University of Toronto, Toronto, Canada

∗ Department
‡‡
∗∗

of Medicine and Diagnostic Radiology, McGill University Health Center-Research Institute

Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada

Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada

Abstract—The novel Coronavirus disease, COVID-19, has
rapidly and abruptly changed the world as we knew in 2020. It
becomes the most unprecedent challenge to analytic epidemiology
in general and signal processing theories in specific. Given its
high contingency nature and adverse effects across the world,
it is important to develop efficient processing/learning models
to overcome this pandemic and be prepared for potential future
ones. In this regard, medical imaging plays an important role for
the management of COVID-19. Human-centered interpretation
of medical images is, however, tedious and can be subjective. This
has resulted in a surge of interest to develop Radiomics models for
analysis and interpretation of medical images. Signal Processing
(SP) and Deep Learning (DL) models can assist in development
of robust Radiomics solutions for diagnosis/prognosis, severity
assessment, treatment response, and monitoring of COVID-19
patients. In this article, we aim to present an overview of
the current state, challenges, and opportunities of developing
SP/DL-empowered models for diagnosis (screening/monitoring)
and prognosis (outcome prediction and severity assessment)
of COVID-19 infection. More specifically, the article starts by
elaborating the latest development on the theoretical framework
of analytic epidemiology and hypersignal processing for COVID19. Afterwards, imaging modalities and Radiological characteristics of COVID-19 are discussed. SL/DL-based Radiomic models
specific to the analysis of COVID-19 infection are then described
covering the following four domains: Segmentation of COVID19 lesions; Predictive models for outcome prediction; Severity
assessment, and; Diagnosis/classification models. Finally, open
problems and opportunities are presented in detail.

Index Terms: COVID-19, Deep Learning, Hypersignal
Processing, Image Radiomics, Medical Imaging.
I. I NTRODUCTION
We are facing, first hand, an abrupt and sudden change
of the world as we knew because of the novel Coronavirus
outbreak. Known as COVID-19, it first appeared in late
December 2019 in Wuhan, China, and few months later, on
This Project was partially supported by the Department of National Defence’s Innovation for Defence Excellence and Security (IDEaS)
program, Canada. Corresponding Author is Arash Mohammadi, email:
arash.mohammadi@concordia.ca

the 11th of March 2020, was characterized as a pandemic
by World Health Organization (WHO). Given its high contingency nature, relatively unknown behaviour, systemic complications, and adverse effects ranging from human fatalities
to economic recessions across the world, it is of importance to
develop efficient processing/learning models to help overcome
this pandemic and be prepared for potential future ones.
The Reverse-Transcription Polymerase Chain Reaction (RTPCR) is the standard testing approach for early diagnosis
of suspected cases of COVID-19. Unavailability of enough
RT-PCR testing kits particularly in areas severely affected
by the pandemic and its relatively high and variable falsenegative rate (i.e., highest during the first five days (up to
67%), and lowest on day 8 (21%) [2]), resulted in focusing
on medical image Radiomics [3] as a complementary source
for diagnosis/prognosis.
Recent studies [4]–[6] show that chest Computed Tomography (CT) scans and Chest Radiographs (CXR) reveal informative features of COVID-19 that can assist in the monitoring,
severity assessment, and treatment of COVID-19 [13]. According to the guideline provided by WHO, use of chest imaging as
a complementary source of data is recommended in different
scenarios and stages of COVID-19 to assist radiologists and
physicians to detect and evaluate the disease more accurately.
CT and CXR can decrease the false negative rate both at
the admission and discharge times. It is worth mentioning
that chest CT has a key role for diagnosis of COVID-19 in
the very early stages of the infection and also to set up a
prognosis. Comparisons between CT and RT-PCR at early
stages of COVID-19 infection show that CT abnormalities
may appear before PCR positivity. In other words, CT has
greater sensitivity during the early stages of the infection.
In addition, false negatives in RT-PCR results occur both
at the admission and discharge. Finally, CT plays its role
over the course of the disease for evaluating changes in
severity and for treatment adjustments. The key power of chest
imaging is in its prognostic value to identify severity of the

2

Fig. 1. The trend in COVID-19-related research.

disease, likelihood of needing hospitalization and/or admission
to Intensive Care Unit (ICU). However, interpretation of chest
images for confirming the suspected cases of COVID-19, and
severity assessment of the disease based on imaging findings
are time-consuming and may be challenging.
Interpretation of CT and CXR images should be performed
by expert thoracic radiologists, who may not be easily accessible especially during the outbreak when the number of
suspected cases of COVID-19 is growing up exponentially.
To address these issues, there has been a surge of interest in
developing Signal Processing (SP) and Deep Learning (DL)
techniques to extract informative features from chest images
and help in fast detection and risk assessment of the COVID19 infection. We would like to mention that although research
works on COVID-19-related topics have started very recently,
the extensive number of research works that have been disseminated during this short period of time makes the topic mature.
More specifically, extensive research works on application of
Signal/Image Processing and Artificial Intelligence (AI) for
COVID-19 have lead to almost 1, 200 publications by the
end of November 2020. Fig. 1 presents COVID-19 research
trend in year 2020, obtained from PubMed with the keyword
“COVID-19” and either of the following keywords: “Signal
Processing”, “Machine Learning”, “AI”, or “Deep Learning”.
These publications cover several aspects and applications of
SP/DL for COVID-19 including diagnosis, classification, detection, segmentation, severity assessment, and survival analysis.
In summary, in this feature article, we aim to present an
overview of the current state, challenges, and opportunities of
developing SP/DL-empowered models for diagnosis and prognosis of the COVID-19 infection based on medical images.
The article will mainly focus on the problems, applications and
on how SP/DL models can be used to address the identified
problems/applications. In brief, we will cover the following
main topics:
(i) We focus on SP techniques specific to COVID-19 images and target specialized SP aspects of COVID-19
diagnoses, including Analytic Epidemiology and Hypersignal Processing (HP) theory as advanced processing
solutions of COVID-19.
(ii) Introduction of potential applications of SP/DL-based
models for the diagnosis and predictive prognosis of
COVID-19 infections using medical images as the main
source of data.

(iii) Investigation of the required medical background related
to COVID-19 for development of advanced SP/DL models. An overview of different characteristics of COVID19 that can be observed on chest images is presented.
Furthermore, we describe how these imaging findings
are related to the severity of the disease, and how they
can be utilized in the development of SP/DL models.
(iv) Presentation of DL Radiomic directions specific to the
analysis of COVID-19 infection. We focus on DLbased solutions from the following four different aspects: Segmentation of COVID-19 Lesions; Predictive
models for outcome prediction in COVID-19 patients;
DL/SP models for severity assessment, and; Diagnosis
and classification of COVID-19 cases.
(v) Introducing challenges, open problems, and opportunities of developing intelligent and autonomous models
for diagnosis/prognosis of COVID-19.
Distinction with Existing Articles: As a final note, we
would like to briefly elaborate on the differences between
this article and a recent feature article [3] on Radiomics and
other survays/tutorials [4]–[6] on COVID-19. In particular,
Reference [3] is focused on hand-crafted and deep learningbased techniques for extracting features from cancer-related
images. Cancer diagnosis is essentially a completely different
task than that of COVID-19 analysis, which requires its
own specific techniques and solutions. For instance, while
nodules have solid shapes and defined locations, COVID-19
infection areas could be multifocal, ill defined and diverse in
pattern or (morphology). Therefore, the traditional Radiomics
filters are not applicable to the latter. Furthermore, images
from patients with pulmonary malignancies contain far less
motion artifacts compared to COVID-19 ones, where patients
suffer from dyspnea, calling for more advanced artifact reduction techniques. Deep learning models developed for Cancer
Radiomics are also not transferable to COVID-19 without
modifications. This is mainly due to the fact that in a patient
with COVID-19 a large number of slices may be affected, for
which 3D analysis and more powerful resources are required.
With regards to differences with recent survay/tutorial articles
on COVID-19 research, Reference [4] is limited to deep
learning techniques. In this article, however, we also focus
on SP modeling, applications, required medical background,
and challenges/open-problems. Reference [5] is more focused
on the medical background and imaging modalities and AI
models are not discussed in a separate section compared to this
article, where different models and applications are separated
and discussed. Reference [6] reviews a subset of deep learning
models, without referring to SP methods, and challenges.
The reminder of the manuscript is organized as follows:
Section II is devoted to analytic epidemiology and hypersignal processing for COVID-19. Applications and imaging
modalities for diagnosis/prognosis of COVID-19 images are
then presented in Section III. SL/DL-based Radiomic models
specific to the analysis of COVID-19 infection are then described in Section IV covering the following four application
domains: Segmentation of COVID-19 lesions; Predictive models for outcome prediction; Severity assessment, and; Diagno-

3

sis/classification models. Finally, challenges, open problems,
and opportunities are discussed in Section V.
II. A NALYTIC E PIDEMIOLOGY AND H YPER S IGNAL
P ROCESSING FOR COVID-19
In this section, we focus on SP techniques specific to
COVID-19 images (in Section IV, we focus on DL models). Here, we target specialized SP aspects of COVID-19
diagnoses, including analytic epidemiology and Hypersignal
Processing (HP) theory as advanced processing solutions of
COVID-19. The worldwide outbreaks of COVID-19 and other
contemporary contagious diseases have triggered a wide scope
of transdisciplinary studies on epidemiology for their systematical treatments, control, prediction, prevention, management,
and decision optimization [9]–[11]. The transdisciplinary investigations into the COVID-19 pandemic have led to the
emergence of analytic epidemiology underpinned not only
by epidemiology, biology, and medical sciences, but also by
computer, big data, information, signal and sensor, AI, system
science as well as mathematics, sociology, and economics.
A. Analytic Epidemiology Models of COVID-19
Analytic epidemiology [12], [13] is a transdisciplinary study
on the cognitive, theoretical, and mathematical models of
COVID-19 and other contagious diseases. It is recognized
that analytic epidemiology may be better studied by signal
explorations at the macro level rather than merely biological
analyses at the micro level in order to not lose the forest for
the trees [13].
The decision model of COVID-19 diagnoses may be formally described by a Cartesian product of the sets of symptoms [13] and test results. Let the set of symptoms of COVID19 be
n
S = S1 (F ever), S2 (Cough), S3 (BreathDif f iculty), S4 (Chills),
S5 (ChillShaking), S6 (M uscleP ain), S7 (HeadAche),
o
S8 (SoreT hroat), S9 (LossOf T aste/Smell) ,

and the set of lab tests be
L=

n

o
L1 (N ucleicAcid), L2 (SoreSample), L3 (LungImage) .

The diagnosis outcomes E of COVID-19 infections are detected by the Cartesian product between the sets of logical
values of detection symptoms ES and lab confirmations EL
as follows [13]:
∧

=

9

3

E = ES × EL = R Si |L × R Lj |L
i=1
j=1

9
3


[( ∧ Si |L) = T |L] ∧ [( ∧ Lj |L) = T |L] // Positive


i=1
j=1


 9
3


 [( ∨ Si |L) = T |L] ∧ [( ∨ Lj |L) = T |L] // Suscetibly positive
i=1

∧

Ninf (t0 + k) = R̄0 k Ninf (t0 ), R̄0 > 1.0, k ≥ 0, Ninf (t0 ) 6= 0.

(2)

Therefore, the average reproductive rate of a pandemic transmission is reduced to the kth root of the average ratio between
the number of infectives Ninf (t0 + k) cumulatively infected
at t0 + k by each initial infective Ninf (t0 ):
s
Ninf (t0 + k)
∧ k
, k ≥ 0, Ninf (t0 ) 6= 0
(3)
R̄0 =
Ninf (t0 )
For instance, WHO has empirically estimated R̄0 of COVID19 in the range of 2.24 to 4.00 [9], which was considerably
higher than those obtained in rigorous analyses with real-world
signals according to Eqs. (2) and (3) as rigorously treated a
long series of pandemic signals.
The reproductive rate R̄0 in analytic epidemiology has been
adopted as the key indicator θ for the congruous severity
classified in two categories by the threshold R̄0 = 1.0, i.e.:

congruous,
R0 (t) > 1.0
θ=
(4)
incongruous, 1.0 ≥ R0 (t) ≥ 0
However, when investigating into the nature of pandemic
dynamics to rigorously predict the pandemic trends, we found
that in order to model more general and complex pandemic
dynamics, the reproductive rate must be treated as a series of
variables R0 (t) over time. This finding has led to the formal
model of the series of dynamic reproductive rates of COVID19, which is recursively determined by a long-chain of causal
probabilities over time:
n

R
t=2

∧

R0 (t − 1) =

n

R
t=2

Ninf (t − 1)
, R0 (0) = 1, Ninf (t) 6= 0.
Ninf (t − 2)

(5)

Simulations performed based on real-world signals have provided highly accurate predications based on the mathematical
model of the analytic epidemiology theory and its dynamic
predictability for the pandemic signal series [13].
B. Hypersignal Processing (HP) for COVID-19 Image Diagnoses

j=1

9
3


[( ∨ Si |L) = T |L] ∧ [( ∧ Lj |L) = F |L] // Suscetibly negative


i=1
j=1



9
3


 [( ∧ Si |L) = F |L] ∧ [( ∧ Lj |L) = F |L] // Negative
i=1

[14], [15] is a generic calculus that denotes an iterative or
recursive series of recurrent structures or embedded functions.
Eq. (1) reveals that many important symptoms and diagnosis
of COVID-19 are in the domain of advanced signal processing
as a foundation for COVID-19 diagnosis. In analytic epidemiology, the reproductive ratio R0 of a contagious disease is
modeled as an exponential transmission series Ninf (t) on
the t0 + kth day, which is estimated by a product of initial
infectives Ninf (t) and the average reproductive rate raised to
the kth power:

j=1

(1)
where T |L and F |L denotes a Boolean logical variable for
True or False, respectively. The diagnosing results are classified in the categories of symptomatic positive, susceptibly
positive, negative, and susceptibly negative. The big-R notation

Hypersignals are a general structure of abstract or realworld signals beyond 1D or its parallel compositions [10],
[11]. Hypersignal Processing (HP) theory provides a unified
mathematical model for advancing 1D signal (voice and time
series) processing to 2D (images) and nD (generic hypersignals) processing [14]–[18]. The hypersignals may be embodied
by sequences of images (videos), language expressions and
semantics, knowledge structures, neural networks, and AI

4

systems. Therefore, HP demands novel theories, mathematical
means, and algorithms [16]–[18].
For instances, the HP theory models hypersignals as follows:

∧

T ext|TX : TX = S


∧


V oice|V : V = B × T



∧
Image|I : I = B × B
∧


V
ideo|M : M = B × B × T


nj

nk
ni

∧

 HyperSig|H : H =
R R . . . R Θ(i, j, . . . , k)
i=0 j=0

k=0

(6)
where B stands for a byte, T for time, S for a string, and Θ
for an instance of an abstract hypersignal.
More generically, the hyper Structure Model (SM) is introduced to model complex hyper signals and entities. For
example, the SM model of the color scheme of an image signal
is formally modeled as:

|X| |Y |



Image|FG
=
R R P ixel(i, j)|PG


i=1 j=1



|X| |Y |



Image|FB
=
R R P ixel(i, j)|PB


i=1 j=1



|X| |Y |
∧
∗
Image|SM =
Image|FR
=
R R P ixel(i, j)|PR∗

i=1 j=1



|X| |Y |




Image|FG∗ = R R P ixel(i, j)|PG∗


i=1 j=1



|X| |Y |


 Image|FB∗ = R R P ixel(i, j)|PB∗
i=1 j=1

Fig. 2. Formal diagnoses of COVID-19 affected lung images and other
applications by image differentiations.

according to the generic image differential algorithm (Eqs. (8)
and (9)), respectively, as shown in Fig. 2.

(7)
where the 2D frame is represented in six forms including FC
(color), FG (gray), FB (black/white), FR* (red), FG* (green),
FB* (blue), and the composition FC = (FR*, FG*, FB*).
A paradigm of HP towards COVID-19 is represented by
Image Frame Algebra (IFA) [15], [18], which processes and
diagnoses suspectedly infected lung images by efficient and
accurate hypersignal handling according to a set of IFA
operators. In IFA, a generic image model is an SM based
on Eq. (7). According to IFA, the differential algorithm for
COVID-19 images manipulations is implemented as follows:
∧

δ(I1 , I2 ) = 1 − σ(I1 , I2 ), p1,2 (i, j)|PG ∈ [0, 255]
P|X| P|Y |
j=1 |p1 (i, j)|PG − p2 (i, j)|PG|
i=1
=
255|X| • |Y |
(8)
The operations of image differentiation in IFA may be expressed according to Eq. (8) as follows:
(
∧
Space Differentiation: Diffs = δs (IL , IR )
(9)
∧
Time Differentiation: Difft = δt (It1 , It1 )
where the first model expresses a differentiation between the
left and right images of a symmetric structure such as lungs,
breasts, and the brain. The second model denotes a sequential
differentiation of image series with respect to time.
For instances, the results of COVID-19 affected lung images, brain tumors, and breast tumors may be diagnosed

III. A PPLICATIONS AND I MAGING M ODALITIES FOR
D IAGNOSIS /P ROGNOSIS OF COVID-19 I MAGES
As stated previously, chest imaging provides an important
source of data for diagnosis/prognosis of COVID-19 infection,
assessment of treatment response, and monitoring of COVID19 patients. In brief, several recent studies have been conducted to investigate specific characteristics of Coronavirus
disease on chest images that can be used for design of
processing/learning models. Different types of chest imaging
patterns and distribution of lung involvement are related to
the severity/stage of the COVID-19 infection and can help
construct predictive SP/DL models to make decisions on
hospital admission versus home isolation, non-ICU hospital
admission versus ICU admission, on monitoring the treatment
process and on the time of home discharge.
In this section, we first present an overview of potential
applications of SP/DL models for the diagnosis and predictive
prognosis of COVID-19 infections. Then, we present the
required medical background related to COVID-19 for development of SP/DL models and will review different imaging
modalities. Advantages and limitations of each modality is
discussed together with its application in different stages
of COVID-19 management. Generally speaking, applications
of SP/DL models for COVID-19 diagnosis/prognosis can be
classified into the following four categories:
• Diagnosis of COVID-19 Pneumonia from other Community Acquired Pneumonia (CAP): The most common

5

COVID-19 symptoms (cough, shortness of breath, and fever)
overlap with CAP symptoms. CAP is mainly caused by a
bacterial infection but can also be caused by viruses. In
most cases, microbiological tests for CAP such as cultures of
sputum and blood, are time consuming with poor sensitivity
and specificity, and are not enough to identify the main
pathogen [19]. Thus, the Polymerase Chain Reaction (PCR)
test via nasopharyngeal or oropharyngeal swab has been used
for correct identification of the source of the viral cause of
CAP (like influenza) [20]. For COVID-19, a variation of PCR
test, the RT-PCR, has been used as a gold standard [21].
Due to the test inaccuracy, the decision on treatment may be
incorrect, i.e., antibacterial drug therapy can be administrated
to all CAP patients who may not be confirmed COVID-19
positive, while for patients tested positive for COVID-19 this
treatment is not required [19]. Cases of negative RT-PCR
with persistent COVID-19 symptoms are submitted to chest
imaging evaluation. This application domain will be further
discussed in Sub-section IV-D, where different SP/DL models
developed for COVID-19 diagnosis are presented.
• Localizing COVID-19 Lesions and Identifying their Types:
The pattern and extent of chest imaging findings is related to
the stage and severity of COVID-19 and affects the treatment
decision making. In Sub-section IV-A, we will further describe
applications of SP/DL models in localizing involved areas and
demonstrating imaging features on CT scans.
• Outcome Prediction (COVID-19 Prognosis): To efficiently
manage the limited medical resources during the pandemic,
it is vital to accurately predict the risk of poor outcomes in
COVID-19 patients. Some essential outcomes in COVID-19
patients are as follows:
• Mortality risk;
• Progression to severe/critical stage;
• Need for ICU admission/mechanical ventilation, and;
• Length of hospital stay.
Predictive models are required to compute the probability
of poor outcomes to help health-care professionals deliver
appropriate services to high-risk patients. This application
domain will be presented in detail in Sub-section IV-B.
• Severity Assessment of COVID-19: Chest imaging can be
used to assess the lung infection severity in COVID-19 patients [19]. Calculation of percentage of parenchymal involvement and CT severity score can be achieved by segmenting
the infected regions and lung areas in chest images. This is
required to evaluate and quantify severity, then prediction of
prognosis of the COVID-19 infection. In Sub-section IV-C, we
will present different SP/DL models developed for computing
lung infection rate and CT severity score metrics as two
commonly used criteria for severity assessment of COVID-19
infection.
A. Imaging Modalities and Radiological Characteristics of
COVID-19
The Fleischner Society and the American College of Radiology, among others, recommend CT scan and CXR for COVID19 patients with moderate to severe cases [23]. Among

the chest imaging modalities, the CXR is less sensitive,
and less specific compared to CT. The advantages of CXR
over CT include its fast availability, ease of execution, and
minimization of in-hospital transmissions. In addition, the
CXR findings correlate well with CT findings [22]. In some
situations where a fast assessment is necessary, the Point-ofCare lung Ultrasound (POCUS) offers a radiation-free imaging
modality with higher accuracy in patients without any previous
cardiopulmonary disease [24]. In what follows, application
of the above-mentioned imaging modalities for COVID-19
diagnosis/prognosis will be discussed in detail.
1) Computerized Tomography (CT) Scan: There has been
considerable attention on CT imaging as the most useful
imaging modality for representing COVID-19 infections. A
study [25] on 51 patients with positive nucleic acid testing
reported that only 3.9% of patients were misdiagnosed based
on their chest CT images. Fig. 3 shows common CT patterns
in COVID-19 patients, where the most prevalent are “Ground
Glass Opacities (GGOs)” and “Consolidations”. GGO is a
hazy transparent opacity that does not conceal lung vessels
and bronchial areas [26]. In a consolidation pattern, the air in
the alveoli and peripheral bronchioles is replaced by fluid such
as pus, water, blood, or an inflammatory material, obscuring
the underlying distal airways and vascular margins [26]. In
a research study on 645 confirmed COVID-19 patients, 88%
of patients showed either pure GGOs or consolidation or
both [27]. The appearance of pure GGO is more common
in the early stage of the disease, while the appearance of
GGOs with consolidations is more frequently seen in the
progressive stage [28]. Another common CT pattern associated
with COVID-19 is the so-called “Crazy Paving” referring
to thickened interlobular septa and intralobular interstitium
superimposed on GGOs [26]. The crazy paving pattern is more
commonly seen in the progressive stage of the disease [28].
The appearance of the crazy paving/consolidation patterns as
a sign of disease progression/severity can help radiologists
evaluate the disease stage. Interlobular septal thickening, air
bronchogram, and vascular enlargement are other CT findings
in COVID-19 patients [28].
Distribution of Lung Involvement in COVID-19: CT findings of COVID-19 infections demonstrate that most of the
COVID-19 patients have had “Bilateral” and “multifocal” lung
involvements. Bilateral involvement means that the lesions are
distributed in both the right and left lungs, and multifocal
involvement implies that more than one lobe (from five lobes)
of the lung is affected by the disease. A systematic review of
COVID-19 imaging findings [28] declared that in 17 out of
36 studies (78.2%), the number of patients with bilateral lung
involvement had been higher than the patients with unilateral
involvement.
Researches also showed that COVID-19 lesions in most
of the cases are distributed in lower lobes and have a “Peripheral” instead of central distribution [28], [30]. Similarities
between CT features of COVID-19 with other viral pneumonia
pose limitations in using CT images to diagnose COVID19. However, in a study of 58 patients [31], six of seven
radiologists could distinguish COVID-19 from other types of

6

TABLE II
S CORING SYSTEM FOR MEASURING CT SEVERITY SCORE [34].

Fig. 3. The most common CT patterns in COVID-19 patients. (a) Axial CT
image of a 38 year-old man with bi-lateral GGOs distributed in posterior
lung regions [29]. (b) Axial CT image of a 60-year-old woman, scattered
consolidation patterns with mainly peripheral distribution [29]. (c) Axial CT
image of a 51-year-old man, the appearance of GGOs (white arrow) and
consolidations (red arrows) [29]. (d) Crazy-paving pattern in axial CT image
of a 43-year-old woman [30]. All CT images have been obtained without
contrast enhancement.
TABLE I
C ORRELATION BETWEEN P ERCENTAGE OF O PACITY (PO) MEASURE AND
COVID-19 STAG [32].

COVID-19 stage

Percentage of Opacity (PO)

Moderate

2.2 (0.4, 7.1) (median and interquartile range).

Sever

28.9 ± 19.2 (mean ± std).

Critical

49.6 ± 14.8 (mean ± std).

viral infections with an accuracy of 67−93% and a specificity
of 93−100%. Peripheral distribution and GGOs were the most
critical characteristics for distinguishing COVID-19 from nonCOVID-19 pneumonia [31].
Correlation between CT Findings and Severity/Stage of
the Disease: Since CT images provide high sensitivity for
detecting COVID-19 patients, they are reliable for developing SP/DL-based diagnosis models. Detecting the pattern of
pulmonary involvement in COVID-19 including consolidation
and/or crazy-paving patterns in chest CT images by SP/DLpowered networks, can help evaluate the disease severity.
Quantifying the extent of lung involvement in COVID-19
patients is a deterministic criterion for assessing the disease’s
stage/severity. Different CT severity measures have been introduced in the literature that can be mapped to disease severity.
The manual calculation of these measures by radiologists is
tedious and time-consuming. Severity measures that can be
automatically quantified by SP/DL models are as follows:
•

Percentage of Opacity (PO): The PO measures the
volume of COVID-19 abnormalities related to the whole
lung volume. It was reported in Reference [32] that
the POs for COVID-19 patients are divided into three
different categories as shown in Table I.

Lobe involvement rate

Score

No involvement

0

Involvement of less than 5%.

1

Involvement from 5% to 25%.

2

Involvement from 26% to 50%.

3

Involvement from 51% to 75%.

4

Involvement is higher than 75%.

5

Percentage of High Opacity (PHO) and Lung High
Opacity Score (LHOS): The PHO and LHOS introduced
in [33] quantify the volume of consolidation regions in
the whole lung and across the lobes, respectively.
• CT Severity Score: Authors in [34] used a severity
measure for COVID-19 patients, referred to as the CT
score, that measures the extent of involvement based on
a semi-quantitative scoring for each of the five lobes. The
score ranges from 0 to 5, which is computed as shown in
Table II. The overall CT score would be between 0 and
25, which is the sum of the lobar scores (some studies
use a different scoring scale, which ends up to a CT score
between 0 and 20 [30]). Francone, et al. [34] conducted
research on 130 COVID-19 patients and evaluated the
correlation between CT score and disease severity. They
showed that the CT score is strongly correlated with
the COVID-19 clinical stage and severity. For patients
in severe or critical categories, CT score is significantly
higher than patients in the mild category [34]. CT score
greater than 18 (out of 25) can be used as a predictor of
mortality in COVID-19 patients [34]. CT score is highly
correlated with patients’ age. In [34], authors revealed
that CT score in patients with age range > 50 was
significantly higher than those in the age range of 26-50.
For patients in late-stages of the disease, the CT score is
higher than those in early-stages. CT score, together with
patients’ age, can be used to predict COVID-19 patients’
death.
2) Chest Radiography (CXR): Some studies report that
CXR images often show no lung infection in COVID-19
patients at early stages resulting in a low sensitivity of 69%
for diagnosis of COVID-19 [35]. However, CXR is helpful for
prediction of clinical outcome and for detection of COVID-19
in areas with limited access to reliable RT-PCR testing kits.
The most commonly observed patterns in CXR of COVID-19
patients are GGOs and consolidations with bilateral peripheral
distribution [35]. Pre-existence of medical conditions such
as heart or other lung diseases will make the interpretation
of CXR images challenging. Therefore, the interpretation
•

7

of CXRs in younger patients would be more reliable and
predictive. In Reference [36], the authors developed a scoring
approach for severity assessment and outcome prediction of
COVID-19 patients between the ages of 21 to 50 years based
on their CXR images. In their scoring system, each lung is
divided into three zones. A binary score is then given to
each zone based on the appearance/absence of COVID-19
abnormalities, and the total score would be in the range of
0-6. Their study on 338 patients demonstrates that there is a
significant correlation between CXR score greater than two
and hospital admission. They also reported that a CXR score
greater than three could predict the need for intubation. Using
lung Edema severity measure, referred to as RALE score,
the authors in [37] quantify the extent of lung involvement
and compute correlations with the risk of ICU admission for
COVID-19 patients. Recent research works have demonstrated
potentials of developing SP/DL-based models for grading the
disease stage and performing outcome-prediction using CXR
images.
3) Ultrasound: Beside the advantages of using CT or
CXR combined with RT-PCR test for a correct and precise
diagnosis of COVID-19, these imaging modalities have limitations, including diagnostic accuracy, logistic challenges, timeconsuming assessment and the use of ionizing radiation [24].
Despite low sensitivity of Ultrasound for diagnosis of COVID19 patients in mild and moderate categories, lung ultrasound
has shown high-sensitivity results in critical cases [38]. Due to
its low cost, portability, ease of use, and being radiation-free,
lung ultrasound can play a crucial role in the follow up and
monitoring patients in the ICU. Furthermore, Ultrasound has
been widely used for the diagnosis and monitoring of COVID19 in pregnant women. In Italy, health professionals used lung
ultrasound as a screening tool and developed a lung ultrasound
score for evaluating the severity of the disease in COVID-19
patients [39].
In another study with 93 patients, where 27 (29%) of
them were tested positive for COVID-19 by RT-PCR or
CT, the Ultrasound imaging achieved a sensitivity of 89%
and specificity of 59% [24]. Considering a subgroup of 37
patients without any cardiopulmonary disease, the assessment
based on Ultrasound revealed and sensitivity of 100% and
specificity of 76% [24]. Thus, Ultrasound represents a valuable
imaging modality for the detection or assessing COVID-19
severity mainly in patients without any medical history of
cardiopulmonary disease.
COVID-19 CT Scans & CXR Datasets: To assure model
generalization for clinical use, it is beneficial to train SP/DL
models based on a diverse set of dataset acquired from
different scanners, different health centers covering a wide
range of patients. Table III provides an overview of the
available CT imaging datasets along with their COVID-19
related information. CT images represent different resolutions and contrasts depending on the type of scanner, image
acquisition approach, and the thickness of the slices. It is,
therefore, necessary to make CT images consistent before
feeding them into the processing and learning models. For a
list of available CT imaging datasets along with their COVID-

19 related information please refer to Reference [29]. Given
the heterogeneity of the data source, available data collections
comprehend a wide sort of equipment, images characteristics
and diagnosed disease.
Table IV presents datasets of the two biggest data collection
initiatives. Several other datasets are under development once
when new data become available it is promptly aggregated by
those initiatives. Given the heterogeneity of the data source,
these data collection comprehends a wide sort of equipment,
images characteristics and diagnosed disease.
IV. D EEP L EARNING R ADIOMICS S PECIFIC TO COVID-19
In this section, we present different DL-based Radiomic
models specific to the analysis of COVID-19 infection. In
particular, we focus on the following four different application
domains of discovery Radiomics: Segmentation of COVID19 lesions (presented in Sub-section IV-A); Predictive models
for outcome prediction in COVID-19 patients (described in
Sub-section IV-B); DL/SP models for severity assessment (presented in Sub-section IV-C), and; Diagnosis and classification
of COVID-19 cases, which are detailed in Sub-section IV-D.
A. Segmentation of COVID-19 Lesions
In this sub-section, we provide an overview of segmentation
networks developed in the context of COVID-19 from different
aspects as presented in Fig. 4. Segmentation networks are
image-to-image DL models that are trained to produce a
mask indicating the region of interest. Segmentation allows
physicians to identify the type and location of lesions; Evaluate
the extent of lung involvement, and; Quantify the lung severity
measures. Depending on the objective, they one segment the
COVID-19 lesions, lungs, and lobe regions. Segmentationbased infection quantification models can be used to evaluate
effectiveness of different treatment solutions.
Imaging Modality used for Segmentation of COVID-19
Lesions: Since CT images provide the most accurate COVID19 manifestations for grading and evaluation of infections,
they have been widely used in the context of COVID-19
segmentation. The goal in this context is localization of
COVID-19 infections and/or grading the disease stage. In the
literature, the focus was mainly on development of 2D models
for segmentation of lung infections in each CT slice [49]–
[51]. There have also been some 3D segmentation models
that take the 3D CT volumes as input and segment the lung
abnormalities on a patient-level basis [52], [53]. Since the
use of portable CXRs is more feasible for patients in ICU,
it is essential to develop segmentation models for severity
assessment of COVID-19 patients based on CXR images.
A study on 2, 951 COVID-19 CXRs, performed the lung
infections segmentation as the first step of their COVID-19
diagnosis pipeline [54]. Using a human-machine collaboration,
they provided the first COVID-19 CXR dataset with the
ground-truth infection masks. Segmenting the lung infections
using a U-Net model with DenseNet-121 yielded a higher
performance in their classification framework [54].
Region of Interest (RoI): The region of interest would be
different in COVID-19 segmentation models based on the

8

TABLE III
AVAILABLE COVID-19 CT SCAN DATASETS .
Number of cases
Dataset

COVID

Reference [40]

49

Reference [41]

20

Reference [42]

CAP

Label type

Single

Available

Not available

Label Level

Multiple

NA

3

3

3

3

NA

NA

3

3

3

3

20

NA

NA

3

3

3

3

Reference [43]

856

NA

254

3

3

3

Reference [44]

216

NA

55

3

3

3

3

Reference [45]

60

NA

60

3

3

3

3

Reference [46]

95

NA

282

3

3

3

3

3

Reference [29]

171

60

76

3

3

3

3

3

1

Classification

CT volume

Segmentation

NA

Normal

Data Source

Patient-level

Slice-level

Lobe-level

3

3

TABLE IV
AVAILABLE COVID-19 CXR DATASETS .

Number of cases

Label type

Data Source
Status

Dataset

COVID

CAP

Normal

Classification

Segmentation

Multiple

Reference [47]

802

605

284

3

3

3

Under development

Reference [48]

468

NA

NA

3

3

3

Under development

research objective and can be classified into the following three
main categories:
(i) Localizing the Infection Regions without Considering
their Types: These studies perform a two-way segmentation approach, assigning each pixel of the CT images
either to an infection or to a background class.
(ii) Segmenting Different Types of COVID-19 Lesions: As
mentioned previously, different types of COVID-19 infections can be correlated to the stage/severity of the disease.
In this regard, some studies have segmented different
types of COVID-19 lesions under different classes to
further evaluate severity of the disease [49], [52].For
instance, a 3D DeepLabv3 segmentation model was proposed in [52] using CT images of 4, 154 patients. The
constructed model segments lung regions and different
types of COVID-19 infections, including consolidations,
GGO, pulmonary fibrosis, interstitial thickening, and
pleural effusion.
(iii) Segmentation of COVID-19 Lesions, Lungs, and Lobs:
Researchers who aim to quantify the extent of lung
involvement and determine the COVID-19 severity measures consider segmenting lung/lobe regions besides the
COVID-19 lesions. Advanced segmentation models can
be trained to quantify different severity measures such as
PO, PHO, CT score, and LHOS, based on CT images.
This will be further discussed in Sub-section IV-C.
Next, we investigate different DL architectures proposed for
the segmentation of COVID-19 abnormalities.
1) DL Architectures for Segmentation of COVID-19 Lesions: Segmentation is considered an essential step in the

Single

severity/stage assessment of COVID-19 patients. However,
comparing to classification models, limited number of research
works have focused on segmentation models for COVID-19.
Generally speaking, segmentation models (mostly developed
based on CNNs) contain a contracting path (encoder) for
extracting informative features from input images and an
expanding path (decoder) for reconstructing the mask representing the regions of interest. Unlike classification models,
typically, there are no fully connected layers in segmentation
models. U-Net network [57] and its various extensions are
the most commonly used architecture for segmentation of
COVID-19 lesions. There are few works developed based
on other successful segmentation networks. Some researchers
have proposed innovative encoder-decoder networks for segmentation of COVID-19 lesions. Below, we present COVID-19
segmentation architectures classified into the aforementioned
three main categories:
(ii) U-Net-based Segmentation Models: The majority of
researches for segmentation of COVID-19 abnormalities
have been developed upon the U-Net model. In UNet [57], skip connections transfer the extracted features
from the contracting path to the corresponding layer in the
expanding path. This helps the model to better understand
visual details of images making it an ideal architecture
for segmentation in the medical domain. Adoption of
pre-existing CNNs like DensNet and ResNet blocks in
the encoder path of the U-Net will result in extracting
higher resolution features from CT images [33], [58].
Multi-scale feature fusion, i.e., integration of dilated
convolutions with different dilation rates, can be added

9

Fig. 4. Taxonomy of the COVID-19 segmentation techniques using deep learning.

into U-Net-based segmentation models to help capture
COVID-19 abnormalities in different scales [59]. The
current focus is on increasing performance in segmenting
the COVID-19 lesions. In this regard, References [49],
[55], [66] considered incorporation of spatial and channel attention mechanisms within the U-Net architecture.
The authors in Reference [49] proposed a new attention
mechanism that enables the basic U-Net model to better
understand the contextual information from CT slices
and perform the segmentation of COVID-19 abnormalities more accurately. Commercial U-Net-based soft-wares
have also been used in some researches for quantification
of COVID-19 abnormalities and determining the severity
of the disease [32], [60].
(ii) Non U-Net Segmentation Models: Some COVID-19
segmentation researchers developed models based on
architectures other than the U-Net model. Fully Convolutional Networks (FCNs), U-Net++, and V-Net are some
examples of successful segmentation networks that have
been used as a base model for developing COVID-19
segmentation networks.
(iii) Innovative COVID-19 Specific Encoder-Decoders:
Some studies have developed innovative models for the
segmentation of COVID-19 opacifications from scratch.
Qiu, et al. [51] proposed a compact (light-weight) segmentation network based on 100 annotated CT slices
from > 40 COVID-19 patients. In contrary to most of the
segmentation models, which are large DL networks with
millions of trainable parameters, their proposed model
contains only 472 thousand parameters and achieved
comparable results to its large-scale counterparts. Reference [50] developed a parallel partial decoder with edge
and reverse attention modules to segment the COVID-19
lesions more precisely. Joint classification and segmentation networks, belonging to multi-task learning models,
can enhance the performance of both segmentation and
classification tasks by sharing the extracted features [61],

[62]. Finally, segmentation models without use of labeled
data can be developed [120] for distinguishing COVID19 areas of infections. More specifically, random shape,
noise generation, and image filtering operations can be
used to synthesize COVID-19 lesions for inclusion into
healthy chest CT scans and form training pairs.
Table V provides classifications of different COVID-19 lesion
Segmentation models.
2) Hand-Crafted Radiomics: Hand-crafted radiomics refers
to the process of extracting several quantitative and semiquantitative features from the ROI with the ultimate goal
of diagnosis/prediction. Compared to DL techniques, Handcrafted radiomics is less common in the problem of COVID19 analysis, as it requires fine delineation of the infected
regions and a prior knowledge of the types of the features
to extract. Nevertheless, it benefits from more interpretability,
as the features are engineered. As shown in Fig. 5, Handcrafted radiomics, utilized in a few COVID-19 studies, follows
a multi-step process, in the first of which infected regions
are annotated. Consequently, several features are extracted
from the segmented regions and fed to a conventional model,
such as Support Vector Machine (SVM), logistic regression,
and decision tree, for making the final decision. Hand-crafted
features cover a wide range of categories, including firstorder (basic intensity and shape-based features), second-order
(texture features extracted from various matrices), and more
advanced features such as those calculated from Fourier and
Wavelet transforms. Intensity features [71], shape-based [72],
and/or texture-based features, as well as other COVID-19
related features such as CT quantification metrics can be
leveraged [58], [69]. Radiomics in COVID-19 studies are
mostly used in adverse outcome prediction models, explained
in the next section. It is also possible to develop hybrid
frameworks, where both hand-crafted and DL-based features
are combined. Such methodology is adopted in Reference [70]
by combining GAN generated features with pre-defined handcrafted ones.

CT scans

CT scans

CT scans, clinical/laboratory information

CT scans

CT scans

CT
scans,CT
quantitative
feature,clinical
data

CT scans

CT scans

Ref. [58]

Ref. [60]

Ref. [68]

Ref. [55]

Ref. [52]

Ref. [61]

Ref. [56]

CT scans

Ref. [50]

Ref. [67]

CT scans

Ref. [32]

CT scans

CT scans

Ref. [62]

CT scans

CT scans

Ref. [51]

Ref. [66]

CT scans

Ref. [65]

Ref. [59]

CT scans

CT scans

Ref. [63]

CT scans

CT scans

Ref. [49]

Ref. [120]

CT scans

Ref. [33]

Ref. [64]

Input data

Ref.

Dataset diversity

Model

multi-center

100 annotated CT slices from > 40 patients

549 COVID-19 patients

750 CT volumes (400 COVID-19 & 350 uninfected
cases). 3,855 annotated CT slices

617,775 CT images from 4,154 patients, 4695 annotated slices

2506 slices with COVID-19 infected lesions and
2274 non-infected slices from 18 COVID-19 patients and 18 non-COVID people

880 COVID-19 CT volumes, 80 annotated cases

60 COVID-19 patients

531 thick-section CT scans from 204 COVID-19
patients

1117 annotated CT images from 19 COVID-19
patients, for external validation: 8 lung CT scans
from two COVID-19 patients

single-center

multi-center

multi-center

single-center

multi-center

single-center

single-center

single-center

multi-center

multi-center

100 annotated CT slices from > 40 patients, 1600
CT slices from 20 patients

558 COVID-19 patients including 76250 slices

U-Net-based

Single-center

The commercial deep-learning software used for
segmentation has been trained based on 842
COVID-19 CT volumes from one hospital. For
follow up CTs: 126 COVID-19 patients classified
into four clinical stages: 6 mild, 94 moderate, 20
severe, and 6 critical cases

VB-Net-based

Innovative model

DeepLabv3-based

U-Net-based

nnU-Net-based

U-Net-based

U-Net-based

U-Net++-based

U-Net-based

U-Net-based

Innovative model

Innovative model (multitask learning)

Innovative model (lightweight architecture)

U-Net-based + GAN

U-Net-based

FCN-based

U-Net-based

U-Net-based

U-Net-based

Three datasets for classification,
one dataset for segmentation

single-center

100 annotated CT slices form > 40 patients

1396 CT slices for classification, 100 slices from
> 40 patients for segmentation

four public datasets for training
and three public datasets for testing

Three datasets for COVID-19 lesion segmentation, Three datasets
for lung segmentation

multi-center

multi-center

multi-center

multi-center

2563 COVID-19 CT volumes, 254 healthy CT
volumes

For COVID-19 lesion segmentation: (453 healthy
CT volumes, 18 COVID-19 CT volumes) For lung
segmentation: 515 lung CT volumes

29 COVID-19 CT volumes

20 COVID-19 CT volumes from 2 datsets (10
patients from each)

471 slices (100 slice from 40 patients, 371 slices
from 9 patients)

9749 CT volumes

Dataset size

Segmentation, quantification

binary-classification,
Segmentation

Three-way classification, Segmentation, quantification

Segmentation

Segmentation

abnormalities quantification, correlation with disease severity

Segmentation;
Severity
assessment using PO and the
average infection HU (iHU)

Segmentation

Segmentation

Segmentation

Segmentation

Quantification of lung involvement, monitoring changes in follow up CTs

Segmentation + Classification
+Image reconstruction

Segmentation

Segmentation

Segmentation

Segmentation

Segmentation

Segmentation

Quantification

Task

TABLE V: COVID-19 lesion Segmentation models
ROI

lesions
class

lesions
class

Covid-19 lesions, Lungs,
Lobes

COVID-19 lesions

Lung regions, COVID-19
lesions including consolidation, GGO, pulmonary fibrosis, interstitial thickening, and pleural effusion

COVID-19 lesions (including GGOs, interstitial in
ltrates, and consolidation)

COVID-19 lesions

COVID-19 lesions/ Lungs/
Lobes

COVID-19 lesions

COVID-19 lesions

COVID-19 lesions

COVID-19 lesions

COVID-19
(Bianry/multiple
segmentation)

COVID-19 lesions, Lungs,
Lobes

COVID-19 lesions

COVID-19 lesions

COVID-19 lesions

COVID-19 lesions, Lungs

COVID-19 lesions

COVID-19 lesions, Lungs

COVID-19
(binary/multiple
segmentation)

lesions, Lungs, lobes

Validation

Train/test split

Train/test split

5-fold cross validation, External validation

5-fold cross validation

5-fold cross validation

NA

Train/test split

5-fold cross-validation

Train/test split

Train/test split

External validation

Train/test split

Train/test split

Train/test split

External validation

Eternal validation

Train/test split

4-fold cross validation

3-fold cross validation

Train/test split

Results

DSC: 0.916% ± 10, PO error (the difference between GT and
predicted PO): 0.3%

Classification: sensitivity: 0.95, specificity: 0.93; segmentation: DSC:
0.783

three-way classification: accuracy: 0.9249, AUROC: 0.9813 (95%
CI: 0.9691–0.9902); The classification performance on five external
datasets: accuracy: above 0.8411, sensitivity above 0.8667, and
specificity above 0.8226; The AI-based lesion quantification could
evaluate the effectiveness of different treatment solutions”

for three infection categories: DSC: 0.7422,0.7384,0.8769.SEN and
SPC: (0.8593, 0.9742), (0.8268,0.9869) and (0.8645,0.9889) respectively

DSC: 0.7225 ± 0.1989, HD: 23.46 ± 32.12

Patients with need for mechanical ventilation had a significantly
higher PO (median 44%, IQR: 23–58% versus 13%, IQR: 10–24%;
p = 0.001) and PHO (median: 11 %, IQR: 6–21% versus 3%, IQR:
2–7 %, p = 0.002) compared to those without.

For segmentation: DSC: 0.74, For severity assessment: two imaging
bio-markers (PO and iHU) can distinguish between the severe and
non-severe stages with an AUC of 0.9680 (p-value< 0 : 001).

Results on test set: DSC: 0.8948, SEN: 0.8874, PPV: 0.9064; Results
on external set: only qualitative results have been presented

DSC: 0.8029 ± 11.14, HD:18.72 ± 27.26

DSC: 0.83.1 , SEN: 0.867, SPC: 0.993

Results on test set: DSC: 0.73, SEN: 0.725, SPC: 0.96, Results on
external validation: DSC: 0.597, SEN: 0.865, SPC: 0.977

DSC: median: 0.8481, range: 0.6526 - 0.9094; PO for different
categories: mild: 0, moderate: 2.2% (0.4, 7.1), severer: 28.9% ±
19.2, critical: 49.6% ± 14.8

For segmentation DSC: 0.88; For classification Acc: 0.9467, SEN:
0.96, SPC: 0.92

DSC: 0.7728, SEN: 0.8362, SPC: 0.9747

Results on different test sets: DSC: 0.589-0.767, SPC: 0.992-0.998,
SEN: 0.584-0.846

Results on test set 1: DSC: 0.687 ± 15.8, SPC: 0.851 ± 6.97,
SEN: 0.621 ± 22.8 ; Results of test set 2: DSC: 0.594 ± 17.4,
SPC: 0.604 ± 19.7, SEN: 0.618 ± 18.4

Reducing annotating time

DSC: on left lung: 0.8581, DSC on right lung: 0.8799, DSC on
lesions: 0.6732

DSC: 0.791, SEN: 0.862, SPC: 0.987

Pearson correlation for PO: 0.92, PHO: 0.97, LSS: 0.91, LHOS: 0.9

10

11

(ii) Hybrid Models: Hybrid models (such as multiple-models,
mixture of experts, and ensemble models) are of high importance in the field of medical imaging, typically, improving
the initial results. While hybrid models can be developed in
a variety of forms, they are mostly adopted in COVID-19
analysis in two main ways, i.e., combinations of Hand-Crafted
and Clinical/Laboratory features or combination of DL-driven
and clinical/Laboratory features, as described below:
Fig. 5. Hand-crafted Radiomics workflow.

•

B. Predictive Models for Adverse Outcome Prediction in
COVID-19 Patients
As stated previously, for efficient utilization of limited medical resources during the COVID-19 pandemic, it is critically
important to accurately predict mortality risk, progression
to severe/critical stage, need for ICU admission/ventilation,
and the length of hospital stay. In this regard, development
of predictive models is essential to compute the probability
of poor outcomes and help health-care professionals deliver
appropriate services to high-risk patients.
Although image-driven features have shown high correlation
with COVID-19 outcomes, they are not the only influential
factors. In other words, radiologists use image-driven features
together with other clinical and risk factors to make the final
decision. Some of the clinical/laboratory information used for
COVID-19 outcome prediction are patients’ symptoms, laboratory test results, oxygen saturation, and comorbid diseases.
Chronic lung disease, obesity, hypertension, cardiovascular
diseases, and diabetes are examples of comorbidities that
will increase the risk of adverse outcomes in COVID-19
pneumonia. In this section, we focus on predictive models that
image-driven features to estimate the risk of adverse outcomes
in COVID-19 patients. As shown in Fig. 6, in what follows,
predictive models are categorized and described in terms of
their: (i) Model structure, and; (ii) Target outcome.
1) Model Structure of COVID-19 Outcome Prediction Models: Most COVID-19 outcome prediction studies exploit both
chest CT images and clinical/laboratory data in their models.
To effectively benefit from heterogenous data resources, conventional ML methods or hybrid models can be utilized, as
explained below.
(i) Conventional ML Models: In some COVID-19 predictive
studies, CT Radiomics and quantification features are extracted
in a pre-processing step. Extracted features are then used with
clinical/laboratory data to train a shallow classifier such as logistic regression or random forest. For instant, Chao et al. [79]
used CT features including lobe-wise quantification features
and whole lung Radiomics together with patients’ clinical
information including age, sex, vital signs, and laboratory
findings to predict the need for ICU admission in COVID19 patients. They used a DL-based segmentation model to
measure CT quantification features. Integrated input data from
various types and resources are then fed into a random forest
classifier for outcome prediction. Following this study, one can
conclude that adding clinical information to CT features can
improve the overall outcome prediction performance.

•

Combinations of Hand-Crafted Features and Clinical/Laboratory Information: Although hand-crafted Radiomics, typically, rely on fine annotations and prior
knowledge of the features to be extracted, they benefit
from domain knowledge. Combining the CT Radiomics
and clinical/laboratory information in a hybrid model,
therefore, benefits from more interpretability. After integration of hand-crafted Radiomics and clinical/laboratory
information, DL features can be extracted for achieving
improved overall results. For instance, DL models can be
developed to predict the probability that mild COVID-19
patients deteriorate into the severe/critical stage. In this
regard, Reference [74] developed a DL model to predict
the probability that mild COVID-19 patients deteriorate
into the severe/critical stage. In their model, first, clinical/laboratory data are fed into a Multi-Layer Perceptron
(MLP). The output is then integrated with extracted handcrafted features from serial CT scans, which are then
fed into an LSTM network followed by fully connected
layers. The LSTM network could detect the temporal
dependencies between the vector of features and achieved
an AUC of 0.92 in distinguishing mild patients who are
more likely to deteriorate into the severe/critical stage.
Combination of DL-driven and Clinical/Laboratory Features: The superiority of a mixture model that takes
advantage of both image-driven and clinical factors is
investigated in [78], [115]. In this study, gender, age,
severity grade, and chronic disease history are combined
with the chest CT scans through a joint CNN-MLP network to distinguish between high and low-risk COVID-19
patients. In another study [78], blood and urine test results
of 1, 170 patients are used as the clinical information.
The developed model consists of two successive CNN
networks for analysis of CT images, i.e., a DNN network
for analysis of clinical features, and a penalized logistic
regression to integrate image-driven DL features and the
DL features extracted from clinical data. Improvements
are reported when image-driven and clinical features are
jointly used.

2) Target Outcomes in COVID-19 Patients: Generally
speaking, in the context of COVID-19 prognosis, the target
outcomes of interest include progression to severe/critical
stage, mortality risk, need for ICU admission/ventilation,
and the length of hospital stay. Below, we present different
COVID-19 outcome prediction models based on these target
outcomes:
•

Risk of Progression to Severer Stages: Li et al. [58]
aimed at measuring the progression of the disease by
monitoring the Portion of Infection (POI) and the av-

12

TABLE VI
P REDICTIVE MODELS FOR OUTCOME PREDICTION IN COVID-19 PATIENTS .

Reference

Dataset Size

Dataset Diversity

Input Data

Model

Target Outcome

Ref. [73]

31 patients

Multi-center

extracted CT features

Logistic regression/ Random forest

short- and long-term
hospital stay

Ref. [74]

133 patients in
mild stage

single-center

Temporal information of CT scans and
clinical/laboratory data

A joint multi-layer perceptron and
LSTM network

Progression from mild
stage to sever/critical
stage

Ref. [75]

338 patients

Single-center

Extracted features from CT images/
clinical variables

Multivariate survival analyses

Progression Risk

Ref. [76]

236 patients

Single-center

clinical parameters and CT metrics

Logistic regression

ICU admission or death
vs no ICU admission or
death

Ref. [69]

693 patients

multi-center

Radiomic CT features, clinical/ biological attributes

Ensemble consensus-driven learning

Severe vs non-severe/
short vs long-term
prognosis

Ref. [77]

1003 patients

multi-center

Clinical, biological, and CT scan images and reports

DL pipeline for segmentation/ DL
pipeline for predicting severity evolution

Progression Risk

Fig. 6. Taxonomy of the COVID-19 predictive models.

•

erage infection HU (iHU). Changes in POI and iHU are
calculated over each two consecutive CT examinations
and compared with the radiologists’ reports, leading to
a high agreement in determining the infection increase
or decrease. To understand the temporal evolution of
COVID-19, Reference [32] calculates the Lung Opacity
Percentage (LOP) for the whole lung and its 5 lobes over
follow-up CT examinations. Progression assessment has
also been followed in Reference [80] by calculating the
pneumonia ratio.
Mortality Risk: Chassagnon et al. [69] proposed an ensemble consensus-driven learning approach with a combination of multiple ML classifiers. They used CT Ra-

•

diomic features (including first-order, higher-order statistics, texture, and shape information) and patients’ data
(including age and gender) as the model’s input. Their
model aimed to predict a short term negative outcome
(death in less than four days) or a long-term negative
outcome (patients who did not recover after 31 days may
die after four days or still intubated). They trained their
model based on a multi-center dataset containing 693
COVID-19 patients and obtained promising results on
multiple external validation sets.
Need of ICU Admission: Reference [76] implemented
a logistic regression model to predict the risk of ICU
admission/death based on clinical parameters and CT

13

Fig. 7. Taxonomy of the COVID-19 severity assessment techniques using deep learning.

•

quantification metrics of 236 COVID-19 patients from
one health center. CT quantification metrics, i.e., the
extent of lung involvement by COVID-19 infections, can
also be used to predict ICU admission or death. PO
and PHO are calculated in Reference [60] for potential
correlation with clinical and laboratory factors. Obtained
results show that patients with high PO and PHO have
higher needs for mechanical ventilation. Length of ICU
stay, the duration of oxygen inhalation, and hospitalization are the main follow up objectives in Reference [85].
Homayounieh et al. [122] used a logistic regression
model to predict the risk of ICU admission or death based
on CT radiomics and clinical information. They indicated
that CT radiomics could be superior to radiologists’ visual
assessment in predicting COVID-19 patients’ outcomes.
Length of Hospital Stay: Need for short or long-term
hospital stay of COVID-19 patients can be estimated
using regression or random forest models. In such scenarios, hand-crafted features such as first-order, secondorder, and/or shape features are extracted to predict the
length of hospital stay of COVID-19 patients. Yue et
al. [73] estimated the length of hospital stay in COVID19 patients using logistic regression and random forest
techniques.

C. DL/SP Models for COVID-19 Severity Assessment
Severity essentially refers to how much the lungs are
affected and involved in the disease. COVID-19 severity
assessment is of high importance due to its unique role in
risk management and resource allocation. In this sub-section,
as shown in Fig. 7, we present existing severity assessment
methodologies. Table VII summarizes how different studies
are categorized based on these perspectives.
Imaging Modality used for Severity Assessment of COVID19: Severity of the COVID-19 can be assessed using both CXR
and CT scans, where the latter, due to its 3D nature, is capable
of providing more accurate estimate of the lung involvement.
Below, we provide few examples of recent works using CXR
or CT for severity assessment of COVID-19 infection:
• CXR for Severity Assessment: For utilization of CXR for
severity assessment, irrelevant, low quality and negative

•

COVID-19 images need to be excluded prior to the
analysis [82]. CXR are also used in Reference [80] for
severity assessment.
CT for Severity Assessment: RT-PCR-confirmed CT scans
are utilized in Reference [60] for severity assessment,
accompanied by clinical and laboratory data, as well
as the need for oxygen supply and mechanical ventilation. CT scans are also utilized by Li et al. [58] and
divided into severe and non-severe groups. The nonsevere cases may progress into the severe class during
the treatment. Since severe and non-severe patients have
different treatment regimens, the same grouping is performed in Reference [87]. CT scans from multiple centers
are utilized by Ghosh et al. [88] for a generalizable
severity assessment. As stated previously, segmentation
models are, typically, used to quantify different severity
measures such as PO, PHO, CT score, and LHOS, based
on CT images. More specifically, to quantify (PO, CT
score) and (PHO, LHOS), the model learns to segment
COVID-19 infections and COVID-19 high-opacity infections, respectively. The whole lung region and lobe
regions are segmented to measure (PO, PHO) and (CT
score, LHOS). For instance, Reference [32], segmented
the lungs regions and COVID-19 lesions using a U-Netbased commercial software and determined the PO in
COVID-19 patients. Based on the clinical data, they could
map the PO measure to the severity of the disease. It was
concluded in this study that the median PO for patients
in the moderate category is 2.2 (0.4, 7.1), for patients in
the severe group is 28.9 ± 19.2, and for patients in the
critical category is 49.6 ± 14.8. Along the similar path,
Reference [56] developed a VB-Net-based segmentation
model using 249 CT volumes of COVID-19 patients to
segment the lung regions, lobes, and lung infections.
Their model could quantify the PO measure with an error
of 0.3% over a testset of 300 CT volumes collected at a
single hospital. Commercial U-Net-based soft-wares have
also been used in some researches for quantification of
COVID-19 abnormalities and determining the severity of
the disease [32], [60].

Input
data

CT

CT

CT

CT

CT

X-ray

CT

X-ray

CT

CT

CT

X-ray

Ref.

Ref. [88]

Ref. [81]

Ref. [32]

Ref. [58]

Ref. [60]

Ref. [82]

Ref. [87]

Ref. [80]

Ref. [83]

Ref. [84]

Ref. [85]

Ref. [86]

468 COVID-19 patients

99 COVID-19 patients

346 COVID-19 patients

1110 COVID-19 patients

15756 COVID-19 images

176 patients

131 portable CXR from 84
COVID-19 patients

60 COVID-19 patients

531 thick-section CT scans from
204 COVID-19 patients

842 COVID-19 CT volumes for
segmentation; 126 COVID-19
patients classified into four clinical stages: 6 mild, 94 moderate,
20 severe, and 6 critical cases

51 patients

509 CT images from 101
COVID-19 patients

Dataset size

public

One hospital

Two institutions

Two hospitals

One public dataset

Several
datasets

7 hospitals with different scanners

One public dataset

One hospital

One hospital

One hospital

One hospital

Multi-center

Dataset diversity

Progression
assessment

Correlation with
clinical factors

Progression
assessment

Diagnosis

Progression
assessment

Diagnosis

Diagnosis

Correlation with
clinical factors

Progression
assessment

Progression
assessment

Diagnosis

Diagnosis

Objective

TABLE VII: COVID-19 severity assessment models.

Not required

Deep learning

Deep learning

Traditional

Deep learning

Deep learning

Not required

Deep learning

Deep learning

Deep learning

Automatic followed
by
manual
adjustment

Deep learning; Traditional; Manual

Segmentation
method

Siamese neural networks

Hand-crafted radiomics

Deep learning

Hand-crafted radiomics

Volume calculation

Volume calculation

Deep learning

Volume calculation

Volume calculation

Volume calculation

Volume calculation

Hand-crafted radiomics

Type of assessment

14

15

in Reference [84] for COVID-19 severity classification.
In the first stage, CT scans are individually fed to a
U-Net model, whose extracted features are stored for
the second stage. Through the second stage, the feature
vectors are fed to a bi-directional LSTM model, for the
final classification.

Fig. 8. Taxonomy of DL-based COVID-19 classification techniques.

1) Severity Assessment Types: Generally speaking, two
types of severity assessment can be defined within the COVID19 literature. The first one is to consider a classification
approach, where different discrete labels are defined to assess
the severity. The second type, however, aims at calculating the
degree/portion of lung involvement as a measure of severity.
Although, the second type, referred to as “quantification”, is
often followed by a classification paradigm, degree of lung
involvement is essentially embedded in the feature vector.
Below, we further elaborate on these two severity assessment
types:
(i) COVID-19 Severity Classification: Similar to most of the
classification problems, COVID-19 severity classification can
be solved using either hand-crafted or DL methods.
• Hand-crafted Radiomics: While different engineered features have the potential to distinguish between severe and
non-severe cases, Ghosh et al. [88] proposed a handcrafted feature, referred to as the Lnorm . This feature
is defined using the maximum bone reference (B), minimum air reference (A), and the mean gray scale intensity
of the lesion (L), as follows
Lnorm = 100 ×

•

L−A
,
B−A

0 ≤ Lnorm ≤ 100.

(10)

The optimum cut-off value to distinguish between severe
and non-severe cases using the Lnorm is then obtained
based on a Receiver Operating Characteristic (ROC)
curve analysis. Other traditional hand-crafted features,
such as first-order histogram features and/or texture-based
ones can be incorporated followed by a regression model
to distinguish between severe and non-severe patients.
First-order histogram features are also used in Reference [85] for severity classification.
Deep Learning: To identify discrete severity scores of the
COVID-19 patients, CNN-based models can alternatively
developed [82]. A two stage DL framework is proposed

(ii) Severity Assessment via Quantification: Although quantification is performed by calculating the lung and infection
volume in most of the studies, it is also possible to adopt a
different approach such as using a Siamese neural network.
Below, we discuss recent works performed along these two
directions:
• Quantification via Volume Calculation: To quantify the
COVID-19 severity, Reference [60] calculated PO and
PHO. POI and the average infection HU are calculated
in Reference [58], to quantify the severity, followed
by dividing the patients into two groups of severe and
non-severe. Infection and GGO ratio are calculated in
Reference [87]. These two measures, along with several
other quantitative features, are further fed to a Random
Forest (RF) classifier, to classify patients as severe and
non-severe.
• Quantification via Siamese Neural Networks: This approach consists of two identical models, in terms of
weights and parameters, with the goal of finding the
similarity between the two inputs. Beside having several
applications, Siamese models, in particular convolutional
Siamese neural networks, can be adopted for COVID-19
severity assessment [86] In such scenarios, the Euclidean
distance between the two final layers is calculated as a
measure of difference between the inputs. Therefore, the
distance between a COVID-19 and normal scan can show
the degree of abnormality. Utilizing a pool of normal
images, the median distance can represent the severity.
D. COVID-19 Classification Models
Development of DL-based COVID-19 classification models
can be approached from four main perspectives, as shown in
Fig. 8. The first aspect is the annotation dependency of the
developed frameworks. The second one is whether the proposed methods consider a binary or multi-class classification,
followed by the third perspective focusing on the imaging
modality used for the classification, as based on the modality
different solutions are admissible. The DL model architecture
is another important aspect of the developed frameworks. Next,
we discuss these four categories in detail.
Table VIII summarizes how different studies approach the
aforementioned categories.
1) Annotation Dependency: Annotation dependency refers
to whether the developed COVID-19 classification models rely
on annotated images as inputs. Annotation can be related
to either segmenting the whole lung region or the infected
areas from the chest image. In this regard, we categorized
studies into three groups of (i) no annotation required, (ii)
lung segmentation required, and (iii) infection segmentation
required. These three groups are discussed in the following:

[t!]

CT

CT

CT

CT

X-ray

X-ray; CT

CT

CT

CT

CT

CT

CT

Ref. [118]

Ref. [108]

Ref. [105]

Ref. [111]

Ref. [106]

Ref. [110]

Ref. [112]

Ref. [113]

Ref. [114]

Ref. [115]

Ref. [116]

Ref. [117]

X-ray

Ref. [103]

X-ray

X-ray

Ref. [102]

Ref. [107]

X-ray

Ref. [101]

X-ray

X-ray

Ref. [100]

X-ray

CT

Ref. [99]

Ref. [104]

X-ray

Ref. [98]

Ref. [109]

CT

Ref. [97]

CT

X-ray

Ref. [96]

CT

X-ray

Ref. [95]

Ref. [119]

X-ray

Ref. [94]

Ref. [62]

X-ray

X-ray
CT

Ref. [46]
Ref. [91]

CT

CT

Ref. [90]

Ref. [92]

CT

Ref. [89]

Ref. [93]

Input data

Ref.

171 COVID-19; 60 Non-COVID; 76 Normal

171 COVID-19; 60 Non-COVID; 76 Normal

366 COVID-19

146 COVID-19; 149 Normal

20 COVID-19; 282 Non-COVID

110 COVID-19; 224 None-COVID, 175 Normal

288 COVID-19; 288 Normal

180 COVID-19; 131 Non-COVID; 191 Normal

540 COVID-19; 229 Normal

88 COVID-19; 101 Non-COVID; 86 Normal

150 COVID-19; 150 Non-COVID; 150 Normal

159 COVID-19; 90 Non-COVID

599 COVID-19; 24622 Non-COVID; 18881 Normal

25 COVID-19; 25 Non-COVID

1525 COVID-19; 1525 Non-COVID; 1525 Normal

127 COVID-19; 500 Non-COVID; 500 Normal

449 COVID-19; 495 Non-COVID; 425 Normal

266 COVID-19; 5538 Non-COVID; 8066 Normal

127 COVID-19; 500 Non-COVID; 500 Normal

50 COVID-19; 50 Normal

45 COVID-19; 1591 Non-COVID; 1023 Normal

106 COVID-19; 100 Normal

266 COVID-19; 5538 Non-COVID; 8066 Normal

44 COVID-19; 55 Non-COVID

266 COVID-19; 5538 Non-COVID; 8066 Normal

403 COVID-19; 721 Normal

105 COVID-19; 11 Non-COVID; 80 Normal

4356 chest CT exams from 3322 patients

250 COVID-19; 250 Non-COVID

118 COVID-19; 6054 Non-COVID; 8851 Normal
521 COVID-19; 665 Non-COVID

108 COVID-19; 86 Non-COVID

419 COVID-19; 486 Non-COVID

Dataset size

One center

One center

4 centers

One hospital

One public dataset

3 hospitals

NA

Several public datasets

One hospital

hospitals of two provinces in
China

Two hospitals

Multi-center

Multi-class

Two public datasets

Several public datasets

Two public datasets

3 hospitals

Three public datasets

Two public datasets

One public dataset

Multi-center

Multi-center

Multi-center

3 hospitals

Multi-center

Multi-center

Multi-center

6 hospitals

Two public datasets
COVID from 10 hospitals; NonCOVID from 3 hospitals
2 hospitals

One hospital

18 centers

Dataset diversity

Binary

Binary

Binary

Binary

Multi-class

Multi-class

Binary

Multi-class

Binary

Multi-class

Multi-class

Binary

One-class anomaly detection

Binary

Multi-class

Multi-class

Multi-class

Multi-class

Multi-class; Binary

Binary

Multi-class

Binary

Multi-class

Binary

Binary

Binary

Multi-class

Multi-class

Binary

Multi-class
Binary

Binary

Binary

Number of classes

Capsule network

Capsule network

3D CNN with integrated clinical
data

CNN

Bi-directional LSTM; CNN

CNN

LSTM

ResNet CNN

CNN

CNN

Multi-scale CNN

ResNet CNN

EfficientNet CNN

CNN

LSTM

Xception CNN

Encoder-decoder CNN

Ensemble CNN

DarkNet (YOLO base model)

ResNet CNN

ResNet CNN

ResNet CNN

CNN

Inception CNN; Ensemble of classifiers

Capsule network

VGG CNN

CNN

ResNet50 CNN

ResNet CNN

Xception and ResNet
EfficientNet CNN

ResNet CNN

Inception and ResNet CNN

Architecture

TABLE VIII: COVID-19 classification models.
Bias and over-fitting prevention

Loss modification

Loss modification

Loss modification; Data augmentation

data augmentation

Changing sampling probability; Data augmentation

Changing sampling probability

Gan-based data augmentation

Transfer learning

Data augmentation

NA

Loss modification; Data augmentation

Data augmentation; Transfer learning

Data augmentation; Transfer learning

NA

NA

Transfer learning

Multi-task learning

Data augmentation

NA

Transfer learning

Data augmentation; Transfer learning

Data augmentation; Transfer learning

Data augmentation; Transfer learning

Transfer learning

Loss modification; Transfer learning

Gan-based data augmentation; Transfer learning

Data augmentation; Transfer learning

Data augmentation

Data augmentation; Transfer learning

Data Augmentation; Transfer Learning
Data augmentation; Transfer learning

Transfer learning

Data Augmentation; Transfer Learning

Annotation dependency

Lung segmentation

Lung segmentation

Lung segmentation

Lung segmentation

Lung segmentation

Infection segmentation

Not required

Lung segmentation

Lung segmentation

Lung segmentation

Lung segmentation

Lung segmentation

Not required

Not required

Not required

Not required

Not required

Not required

Not required

Not required

Not required

Lung segmentation

Not required

Infection segmentation

Not required

Not required

Not required

Lung segmentation

Not required

Not required
Lung segmentation

Infection segmentation

Lung segmentation

16

17

COVID-19 Classification without Annotation: Studies that
do not include any segmentation as a pre-processing step
essentially feed the developed model with raw images. As
CXR images are single slices and simpler to process compared
to CT scans, they are utilized without annotation in most of
the studies. Reference [102] is an example of such studies,
where raw CXR images are fed to a DL model for binary and
multi-class COVID-19 classification. Narayan Das et al. [119]
and Islam et al. [109] also utilized CXR images without
annotation for a three-way COVID-19 classification. Although
using CT scans, Reference [62] is independent from segmented
inputs. It exploits annotation labels in the output layer to
develop a multi-task training framework. In other words, both
classification and segmentation are aimed at in this work.
Lung Segmentation for COVID-19 Classification: Lung segmentation is the first step in many COVID-19 classifications
studies, as it eliminates unessential information. Gozes et
al. [118], for instance, used a pre-trained U-net model for
this task. Since the segmentation model should be able to
annotate lungs even in the presence of COVID-19 opacities,
the U-net model is fine-tuned on a dataset of interstitial lung
disease cases. More advanced lung segmentation models are
also used in COVID-19 studies. Reference [108], for instance,
has proposed a multi-window U-Net that incorporates several
windows instead of the standard Hounsfield unit (HU) window.
Furthermore, this study uses a sequential information attention
module to integrate all CT slices.
Infection Segmentation for COVID-19 Classification: Beside
lung segmentation, some COVID-19 classification studies rely
on segmenting the pulmonary regions of infection. Xu et
al. [112], for instance, have used a 3D CNN model trained on
pulmonary tuberculosis for infection segmentation. Although
this model is not trained on a COVID-19 dataset, it can
still extract candidate patches. The annotation results are
consequently used to form cubic patches around the regions
of infection, which are then fed to the classification model.
Based on the COVID-19 characteristics, such as GGO, Wang
et al. [97] have manually delineated the CT scans to extract
all the ROIs, from which 2-3 patches are randomly selected
as the input to the CNN model for classification purposes.
2) COVID-19 Classification Types: Binary or multi-class
COVID-19 classification refers to whether the problem is
considered as COVID-19 versus all other possible categories
as one class or all the classes are treated separately. These two
approaches are investigated in the following:
Binary COVID-19 Classification Problems: Reference [102]
is an example of binary classification, where the goal is to
distinguish between COVID-19 and non-COVID cases. NonCOVID cases include both normal and pneumonia patients.
Reference [101] explores three different COVID-19-related
binary classification problems, in each of which COVID-19 is
classified against a different class, including viral pneumonia,
bacterial pneumonia, and normal. Obtained results show that
COVID-19 is best distinguishable from bacterial pneumonia.
Beside positive and negative COVID-19, patients can be classified based on other clinical outcomes. Meng et al. [115], for

instance, consider high and low-risk as the binary classification
labels.
Multi-class COVID-19 Classification Problems: Reference [102], beside considering a binary classification problem,
tries to solve a multi-class classification consisting of three
classes of COVID-19, pneumonia, and normal. The obtained
accuracy, however, is lower than the binary scenario. The
same categorization is followed in [109]. Reference [62]
also followed a three-way classification with the difference
that all diseases other than COVID-19 are considered as
the “others” class to be classified against COVID-19 and
normal subjects. COVID-19, pneumonia, and other diseases
are considered as three separate classes in Reference [119].
Since Reference [112] have used annotated infection patches
as inputs to a CNN model, it also considers a irrelevant-toinfection class to exclude incorrectly segmented areas.
It is worth mentioning that unlike binary and multi-class
approaches, COVID-19 classification is considered as a oneclass anomaly detection in Reference [107], where the model’s
output is the anomaly score of the input, along with a
confidence score that determines the model’s confidence in its
prediction. Consequently, subjects with a high anomaly score
or low confidence score are considered as positive COVID-19.
3) Imaging Modality used for COVID-19 Classification:
CXR and CT are two common imaging modalities considered
in the COVID-19 classification studies. These two modalities,
however, require different processing strategies, as described
below:
(i) COVID-19 Classification via CXR Images: CXR images
are 2D and as such processing techniques to incorporate the
relation between images are not required. CXR images can be
independent inputs to a DL model. References [102], [109],
[119] are examples of using CXR images for classification
tasks. Unlike most of the COVID-19 classification methods
using CXR that incorporate the whole image at once, Oh
et al. [106] extract several random patches from the input
image and feed them individually to the DL model. The final
decision is a majority voting over all the obtained outcomes.
(ii) COVID-19 Classification via CT Scans: Unlike CXR
images, CT scans are 3D in the sense that each patient is
associated with several 2D slices. As a result, analyzing CT
scans require specific strategies, the first of which is a slicelevel classification, where slices are treated independently
with the goal of assigning labels to separate slices. Patientlevel classification, on the other hand, tries to make the final
decision using all the available slices.
• Slice-level Classification: Reference [62], as an example
of a slice-level classification algorithm, uses separate
slices as inputs to a DL model, where slices are gathered from three different data sources and pre-processed
to have consistent size, resolution, and contrast. Reference [108] has assigned patient-level labels to all the
slices and leveraged a 2D CNN model. This strategy,
however, can cause inconsistency when a slice without
any visible manifestation is assigned with COVID-19
or pneumonia label. References [99], [114] are other

18

•

examples of slice-level classification models, where target
slices are manually selected to train the CNN model. At
the test time, however, these studies, average over all
the probabilities to form the patient-level classification.
Therefore, the underlying studies can be considered as
cross-sections of slice-level and patient-level classification, bringing us to the discussion in the next part, i.e.,
patient-level classification.
Patient-level Classification: Patient-level classification using CT scans requires a voting strategy to combine
the slice-level outcomes. The voting mechanism is of
particular importance as the whole CT volume cannot
be typically processed at once. Different voting mechanisms have been developed in the literature including the
following items:
– Volumetric Scoring: In Reference [118] 2D slices
are first processed to form the slice-level outcomes.
Summing over the activation maps of the detected
positive slices, consequently, results in the aforementioned volumetric score. It is worth mentioning that
only activations above a pre-defined threshold are
considered in the summation. The obtained COVID19 score can also be considered as the extent of the
disease in a patient’s lungs.
– Pooling Operations: For patient-level classification,
one approach [105] is to combine different models
(e.g., parallel CNNs) in a parallel architecture. Results from individual slices can then be aggregated
through pooling operations. Similarly, Li et al. [93]
incorporate parallel CNNs, results of which are aggregated through a max pooling operation.
– Whole CT Volume: To leverage the information from
all the CT scans and capture their relations, Wang
et al. [111] feed their developed CNN model with
the whole CT volume, which is concatenated with
the segmented lung mask. The same strategy of
feeding the whole CT volume is also used in Reference [115].
– Bayesian Merging: A Noisy-or Bayesian function is
adopted in Reference [112] to combine outcomes of
several infection patches.
– RNN-based Merging: Using Recurrent Neural Networks (RNNs) is another strategy to combine the
slice-level information and consider the spatial relations. This group of models are discussed in Section IV-D4.
– Multi-stage Frameworks: Designing a multi-stage
framework is also a common patient-level classification approach. Mei et al. [89], for instance, have
designed a two stage workflow, where in the first
stage abnormal slices are detected using a previous
pre-trained pulmonary tuberculosis (PTB) detection
model. Top ten candidate slices are then fed to
another CNN, in stage two, to identify slices with
positive COVID-19. Final outcome is ultimately set
as the average of slice-level prediction of a patient’s
ten most abnormal candidates. The same multi-stage

strategy is followed in Reference [116], with the
difference that the CNNs are replaced with capsule
networks, as described in Section IV-D4.
4) DL Architectures for COVID-19 Classification: Although different DL architectures are applicable to the task of
image classification, in the COVID-19 scenario, discriminative
models including CNNs, RNNs, and capsule networks are the
most commonly used ones. These networks and how they are
incorporated in COVID-19 classification studies are explained
below.
CNN-based COVID-19 Classification Models: CNNs are
stack of convolutional and pooling layers, often followed by
fully connected ones. Since the trainable filters share weight
across the whole image, these networks are computationally
effective, and can extract local features from the input. CNNs
have shown promising results in the field of image processing
including COVID-19 classification. Although it is possible to
design a CNN from scratch, most of the studies have built their
models upon pre-existing successful CNN models as described
below:
• Pre-existing CNN models: Since the start of the outbreak,
the following pre-existing CNN models for COVID-19
classification:
– Darknet-19 Model: DarkCovidNet model proposed
in Reference [102] is a modification of Darknet-19
model, which is the basis of YOLO object detection
system. The proposed DarkCovidNet consists of 17
convolutional layers, which are followed by pooling
layers, and eventually one fully connected layer for
the final classification.
– Inception Model, is another commonly used
CNN model utilized in COVID-19 studies. Reference [119], for instance, utilizes extreme version
of the Inception model, referred to as Xception.
Two other variations of Inception, referred to as
InceptionV3 and Inception-ResNetV2, are exploited
in Reference [101], along with three variations of
the popular ResNet architecture, namely ResNet50,
ResNet101, and ResNet152. Obtained results show
superior performance for ResNet50 model.
– ResNet Models: ResNet50 is the basis of the model
proposed in Reference [100], referred to as the
COVID-ResNet. This model is trained in three
stages, where in each stage the image size is increased gradually. The ResNet50 model of Reference [118] is followed by a GradCam localization
to verify the pathological areas focused through
the training process. The resulting map can provide
insights to the radiologist.
– EfficientNet, utilizing compound coefficients to scale
up CNNs, is another architecture used for COVID-19
classification in Reference [107].
– Ensemble Models: Besides adopting the pre-existing
CNN architectures, it is also possible to develop
ensemble frameworks to leverage the potentials of
different CNN models.
• Self-designed CNN models: Based on the identified re-

19

quirements, some studies have designed their own specific
CNN models for COVID-19 classification. A multi-scale
CNN, for instance, is proposed in Reference [108], where
intermediate CNN representations are aggregated through
a global Max Pooling operation to make the final decision. The self-designed CNN model proposed by Wang
et al. [111] consists of three subsequent blocks, the first
of which is a vanilla 3D CNN, followed by a residual
block. The last part is a progressive classifier, containing
convolutional and fully-connected layers. Beside focusing
on designing layers of a CNN, another strategy is to
feed the model with information other than the raw
image. Such strategy is leveraged in Reference [112],
where the distance between the center of infection and
pleura is concatenated with a fully-connected layer. This
distance can contribute to a more accurate classification,
as COVID-19 infection has a pleural distribution, partly
distinguishing it from other diseases. Meng et al. [115]
utilized patient’s clinical factors, such as gender, age, and
chronic disease history, as the additional information to
be concatenated with the CNN’s fully connected layer.
More heterogeneous factors, including travel and exposure history and symptomatology, are incorporated in the
model designed by Mei et al. [89].
RNN-based COVID-19 Classification Models: RNNs are
especially useful in medical imaging when the goal is to
process the whole volume or analyze follow-up studies. Since
RNNs are subject to the problem of vanishing gradients,
LSTM networks are commonly used as an effective alternative.
The vanilla LSTM is not designed for extracting local features
from images and as such this network is often combined
with a CNN, to make use of its weight sharing advantages.
Such a model is utilized in Reference [109] for COVID19 classification, resulting in a CNN-LSTM design. In the
underlying study, 12 convolutional layers are first incorporated
to extract features from CXR images. The output of the CNN
is then fed to an LSTM, the result of which determines
the probability of COVID-19, pneumonia and normal classes.
While a conventional LSTM considers only forward relations,
bi-directional LSTMs additionally take the backward relations
into account. Such models are incorporated in Reference [113]
for COVID-19 classification.
CapsNet-based COVID-19 Classification Models: CapsNets
are relatively new deep learning architectures, proposed to
solve the incapability of CNNs to recognize spatial information. Each capsule in a CapsNet, consist of several neurons
to represent an object instantiation parameters, as well as its
existence probability. The main feature of the CapsNet is its
routing by agreement process, through which capsules in a
lower layer predict the outcome of capsules in the next layer.
The parent capsules take these predictions into account, based
on the similarity (agreement) between the prediction and actual
outcome. Using the routing by agreement, CapsNet is capable
of recognizing spatial relations between image instances, and
therefore handle much smaller datasets, compared to CNNs.
Reference [96] has recently exploited CapsNets for the problem of COVID-19 classification using CXR, showing improve-

ments over the CNN counterparts. The proposed architecture,
referred to as COVID-CAPS, consists of several convolutional,
pooling, and capsule layers, the output of which determines
the probability of positive COVID-19.
V. C HALLENGES , O PEN P ROBLEMS , AND O PPORTUNITIES
In this section, first, we focus on limitations and challenges of developing COVID-19 diagnosis/prognosis models
as shown in Fig. 9. Then, we discuss open problems and potential opportunities for SP research by highlighting problems
and challenges of developing SP/DL models for COVID-19
management.
A. Challenges in Developing COVID-19 Diagnosis/Prognosis
Models
The ultimate goal of developing COVID-19 diagnosis/prognosis models is to be used in clinical applications
and reduce the healthcare system’s workload during pandemic
conditions. Some models proposed for diagnosis and prognosis
of COVID-19 have shown successful results in real applications and enhanced the performance of junior radiologists to
senior-level [52]. However, some common issues such as the
risk of bias and over-fitting may cause poor generalization of
such models. The leading causes of these issues are: (i) Lack
of sufficient data; (ii) Lack of labeled/annotated data, and;
(iii) Imbalanced dataset. These three categories are described
below together with solutions developed in COVID-19 studies
to overcome them:
1) Lack of Sufficient Data:: There is no doubt that preparing a high-quality dataset is the most critical part of developing
a data-driven model. Collection of sufficient data for training
robust COVID-19 models is challenging because: (i) COVID19 is a new arising disease; (ii) Restrictions imposed to
preserve patients’ privacy, and; (iii) Health centers’ strict data
sharing protocols. On the other hand, despite the robustness
of CNNs in hierarchically extracting high-value features from
images, they cannot recognize the spatial relationships between those features. Due to various shapes and complex
appearances of COVID-19 lesions, a large number of chest
medical images are required to avoid over-flitting and ensure
the model generalization. Data augmentation, transfer learning,
multi-task learning, and the use of Capsules networks are some
solutions to tackle these problems.
Data Augmentation, compensates for the lack of large training dataset, by generating several variations of the original
samples [118]. Random cropping, zooming, and flipping, for
instance, are applied to the samples in Reference [107].
Flipping, random rotation, and lighting are also adopted in
Reference [100] to further enlarge the training set. Random
Gaussian noises is another data augmentation technique that
has been used in Reference [59]. Other than applying different
transformations to the dataset, Generative Adversarial Networks (GANs) can be used to generate new instances [110].
GANs produce fake images and forces the algorithm to
discriminate them from the original ones, which makes the
model robust on unseen images. Such strategy is utilized in
Reference [110], where a convolutional GAN is leveraged for

20

Fig. 9. Challenges and possible solutions in developing COVID-19 diagnosis/prognosis Models.

COVID-19 data augmentation. Similarly, a conditional GAN,
referred to as COVIDGAN, is proposed in Reference [95], for
CXR data augmentation.
Transfer Learning, refers to pre-training a model using an
external dataset with the goal of encouraging the model to
learn meaningful filters. The model is then fine-tuned on the
main dataset, which might be a small one for an independent training. Transfer learning has shown promising results
especially in field of medical imaging, where large datasets
are scarce. While most of the existing studies utilize natural
image datasets for pre-training, it is also possible to leverage
similar medical samples as described below:
• Natural Image Dataset: Reference [119] utilized transfer
learning to fine-tune a pre-trained Xception model using
a COVID-19 dataset. Transfer learning is also explored in
Reference [101] to pre-train five well-known CNN models, namely ResNet50, ResNet101, ResNet152, InceptionV3 and Inception-ResNetV2. ImageNet is the common choice for pre-training the CNN models [100], [107],
[118]. Some COVID-19 segmentation models incorporated an encoder pre-trained on ImageNet in their segmentation models to achieve more accurate results [51].
• Medical Datasets: Although pre-training with natural image datasets is very common in COVID-19 classification,
it is also possible to leverage similar medical datasets,
having the advantage of providing more useful filters
and features. Such strategy is recently adopted by Afshar
et al. [96], where the proposed CapsNet is pre-trained
on a CXR dataset collected for a completely different
task. In the fine-tuning phase, all the convolutional layers
are kept fixed and only the capsule layers are re-trained
on the COVID-19 dataset. Reference [63] trained their
COVID-19 segmentation network on a dataset containing

80% of lung cancer CT images and 20% of COVID19 CT samples. However, the model failed to segment
the COVID-19 regions of infection in test set due to the
significant appearance differences between lung cancer
tumors and COVID-19 lesions.
Multi-task Learning is a popular strategy to leverage the
information available in several related tasks and make use
of small datasets associated with different end goals. Multitask learning is shown to be effective in reducing overfitting and can be further divided into two categories, i.e.,
(i) Hard parameter sharing, and; (ii) Soft parameter sharing.
In the former category, different tasks explicitly share several
layers. In the latter, however, separate models are trained for
separate tasks and the parameters are encouraged to take close
values. With this in mind, Amyar et al. [62] proposed a DL
model to perform COVID-19 classification, segmentation and
reconstruction at the same time, using the hard parameter
sharing strategy. The model begins with an encoder to encode
all CT scan into a latent space for subsequent analysis. For
the segmentation and reconstruction tasks, the latent space is
decoded into the original feature space. In the classification
scenario, however, the latent space goes through a MLP for
the final three-way classification. It is also worth mentioning
that the encoder-decoder architecture follows the well-known
U-Net design. While Mean Squared Error (MSE) is utilized
for the reconstruction part, dice score and cross-entropy losses
are adopted for segmentation and classification, respectively.
The final loss is the sum over all the three losses.
Capsule Networks, which are less data-demanding in comparison to CNNs and can be trained using smaller datasets.
Incorporation of Capsule Networks for COVID-19 diagnosis
models and their superiority when having a limited dataset

21

at hand has been discussed in [96]. Capsule networks can be
adopted instead of CNNs in medical segmentation networks.
Capsule network-based segmentation network can potentially
outperform its CNN-based counterparts. Due to data limitations for COVID-19 lesion segmentation, there is a potential
for further investigation of replacing CNNs with Capsule
Networks in segmentation models.
2) Class-Imbalanced Dataset: This problem occurs in situations where samples associated with one class outnumber those of the other class, which is a common problem
in most real-world problems, including COVID-19 diagnosis/prognosis. In training a model for diagnosis of COVID-19
from normal/CAP cases, we usually have a fewer number of
COVID-19 instances and a larger number of other classes. It is
the same situation in segmentation models, where the pixels
labeled as COVID-19 lesions are in the minority compared
to the background pixels. In such scenarios, the model can
be biased toward the majority class. To tackle this issue, one
can consider: (i) Modified loss functions, or; (ii) Re-sampling
techniques as possible solutions, as discussed below:
Modified Loss Functions, which improve the model performance by assigning more penalty to the mis-classified instances/pixels of the minority class. Weighted binary crossentropy is a commonly used loss function in class-imbalanced
classification/segmentation models [49]. Focal Tversky loss is
a re-weighted loss functions that optimizes the coverage of
predicted and ground-truth masks by assigning more weights
to the target pixels. Some COVID-19 segmentation studies
adopt a combination of modified loss functions to improve the
model performance in both image-level and small ROIs [50].
Reference [108], [115] developed a COVID-19 diagnosis
model under supervision of a focal loss which assigns smaller
weight to easy examples, and thus they contribute less to the
loss function.
Re-sampling Strategies, that handle the class imbalance problem by either over-sampling the minority class instances or
under-sampling from the majority class. Xi et al. [123] adopted
an over-sampling strategy in their COVID-19 diagnosis model
to adjust the samples of different classes in each mini-batch.
Li et al. [121] introduced a new off-line sampling strategies
that ranks the non-COVID-19 samples based on their diversity
and difficulty. The most informative samples are then fed into
the classification model. Their approach could significantly
decrease the training time while achieving comparable results.
3) Lack of Labeled/Annotated Data: One of the most
challenging problems when developing medical segmentation
networks is the lack of pixel-level labeled images. Pixellevel labeling of medical images by experienced radiologists
is time-consuming. When it comes to COVID-19 infections
segmentation, since the regions of infection are blurry with
hardly-distinguishable boundaries from healthy lung tissues,
the experts’ annotation may not be consistent, making it necessary to work with a team of radiologists. Manual annotation
of one COVID-19 CT volume takes 1 to 5 hours [56]. Some
helpful solutions to overcome this problem are as follows:
Human-in-loop Annotation Process, which is a humanmachine collaboration approach to ease and accelerate the

Fig. 10. Acquired CT images with three different dose levels for three
COVID-19 patients. (a) Standard-dose, (b) Low-dose, (c) Ultra Low-dose.

annotation process. Shan et al.. [56] proposed an efficient
human-in-the-loop system by the collaboration of radiologists
and the DL-segmentation model, which could dramatically
reduce the annotation time.
Semi-supervised Learning, where a few annotated samples
together with a large number of non-annotated CT images are
fed to the network to increase the model accuracy. Combining
3D segmentation with GANs in a semi-supervised fashion can
also be used to segment COVID-19 lesions. GASNet proposed
in [65] is a 3D segmentation framework containing a segmentation network with embedded GANs and a discriminator
that uses a semi-supervised approach to segment the COVID19 lesions. The experimental results on three external public
datasets showed that their model’s performance trained on a
few labeled CT volumes was comparable with fully-supervised
segmentation networks trained on a large labeled dataset.
Un-supervised Learning, where the model distinguishes out of
distribution data in a dataset without any pre-existing label. Li
et al. [121] used a new paradigm of un-supervised learning,
refereed to as self-learning, to exploit helpful information from
unlabeled data in their COVID-19 classification model.
B. Open Problems
In this section, we focus on open problems and potential
opportunities for SP research by highlighting problems and
challenges of developing SP/DL models for COVID-19 management.
• COVID-19 patients suffer from dyspnea as such there are
inevitable motion artifacts in the acquired images. This is
in contrast to most of other medical images, where motion
artifact is rarely present. The artifacts in the COVID-19 images
sometimes overlap with the main areas of infection, making
the diagnosis/prognosis challenging even for experienced radiologists. To eliminate the effect of artifacts, most of the studies
simply remove the noisy data from the dataset. This, however,
reduces the generalizability and applicability of the model
in clinical practice. An alternative solution is to approach
advanced artifact reduction techniques, among which adaptive
techniques are of higher capability as they can adjust and track
the signal under noisy conditions.
• COVID-19 involves a large volume of the lung and is
sparsely distributed around the lung volume. This is, in par-

22

Fig. 11. Acquired images for three patients suspected to COVID-19. These patients have pre-existing conditions interfering with the diagnosis of COVID-19:
(a) 47 year old male with fatty embolism and pulmonary edema, (b) 51 year old female with history of right lung cancer and right lower lobectomy, (c) 27
year old male with gunshot injury in the left hemithorax with pulmonary contusion and left hemothorax and pneumothorax.

ticular, in contrast to medical images in which the region
of interest is located in a specific location of the organ.
Analyzing and extracting patterns from the COVID-19 images
require sparse filtering techniques within the signal processing
domain.
• As COVID-19 infection is distributed in the whole lung
volume, the relation between the image slices is of high
diagnostic and prognostic importance, calling for specific 3D
filtering and pattern recognition approaches.
• A key issue with chest CT scan is exposing patients to
harmful radiation. In this regard, using low-dose or ultra
low-dose scanning is of high interest. In a recent study by
Tabatabaei et al. [124], it is shown that obtained low-dose CT
scans have high agreement with standard-dose ones, in terms
of typical findings of COVID-19. More importantly, low-dose
examinations are associated with less cancer risk, especially in
young women. Fig. 10 shows the obtained CT scans for three
different patients at three different dose levels, i.e., standard,
low, and ultra low. According to this figure, although low and
ultra low-dose images have more visible artifacts, they can
still reveal the presence of COVID-19 infection. The artifacts,
however, can hamper the effective training of the model.
Furthermore, collecting a dataset of low-dose scans may not
resolve this issue, as besides dose, other factors such as the
patient’s weight can influence the quality of the image, leading
to a wide variety of possible artifacts. This calls for SP/DL
models that can cope with images at different resolutions while
providing the same level of diagnosis/prognosis performance.
• COVID-19 is relatively new, and as such, large datasets are
not easily accessible. Therefore, the developed SP/DL models
should be capable of handling small datasets and yet capturing
informative features.
• To encourage physicians and health professionals to confidently utilize DL models, it is important to provide explanation
and interpretations on the internal behaviour of the DL models
and the achieved results and therefore eliminate the “blackbox perception”. Regarding the black-box nature of the deep
learning models, communicating explainable outcomes to the

physicians is essential for clinical adoption of implemented
DL models. Several explainability techniques are leveraged
in COVID-19 studies, the simplest of which is to verify the
outcomes with a radiologist. This approach is, however, timeconsuming and burdensome. Techniques, providing heat-maps
of the most important regions of the input image, are also popular within the COVID-19 studies. One of the commonly used
heat-map techniques is Class Activation Mapping (CAM),
utilized in Reference [108] at different feature levels. Gradientweighted Class Activation Mapping (Grad-CAM), visually
depicting the deep model’s decision, is also a CAM approach
with the advantage of not requiring re-training. Grad-CAM
outcome shows how the developed model pays more attention
to the regions of infection of the chest radiographs in [102],
[109]. Saliency map has also shown interpretable outcomes
within the COVID-19 studies [108].
Despite the advances in improving the explainability of the
models, there are still examples for which the model fails to
provide a clear explanation. Furthermore, heat-maps do not
provide enough explanation of the unique features they used
to distinguish between COVID-19 and CAP cases.
• Due to the policy of protecting people’s privacy and also
immediate quarantine of mild cases without further examinations, scans with non-severe symptoms are missing from most
of the public datasets, and models are mostly developed based
on patients with severe lung lesions who are at late/advanced
stages of the disease. The models, therefore, are biased towards
severe cases and cannot be easily generalized.
• Evaluating the developed SP/DL models’ performance in
an unseen domain, results in a decrease in the sensitivity of
COVID-19 diagnosis. Most of the developed models, however,
incorporate data coming from a single hospital, without a
cross-center validation. In other words, the impact of equipment differences are not fully considered yet, and data from
different sources are required to verify the generalizability of
the models.
• One limitation associated with many COVID-19 studies is
that they try to distinguish COVID-19 cases from normal ones

23

or categorize normal and non-COVID pneumonia cases as one
class. Studies who consider a separate CAP class also report
a relatively poor performance in distinguishing the COVID19 and CAP classes. This calls for developing models with
stronger backbone architectures and higher capacities. Furthermore, pneumonia incidence samples are older compared
to the COVID-19 ones and images from pneumonia patients
with COVID-19 symptoms are not included in the datasets.
• Although hybrid models, combining images and other
relevant clinical information, can play an important role in
COVID-19 analysis, few datasets are accompanied with demographic and clinical risk factors.
• One important challenge associated with COVID-19 analysis
is the disease manifestation in patients with complications
other than COVID-19. Several diseases can impact the lung
tissue and interfere or change the appearance of COVID-19.
Interstitial lung diseases, pleural or cardiac diseases may have
imaging manifestations that may mask superadded COVID19, and make it challenging for the interpreting radiologist.
As shown in Fig. 11, it is not clear if the abnormalities are
related to COVID-19. This calls for developing more advanced
SP solutions and unique features to facilitate COVID-19
identification.
VI. C ONCLUSION
Medical imaging plays an important role in the diagnosis
and management of COVID-19 infection. Signal Processing
(SP) methods coupled with Deep Learning (DL) models can
help to develop robust autonomous solutions for diagnosis/prognosis of COVID-19 based on chest images. In this
article, an integrated sketch is presented for designing and
developing intelligent models for the COVID-19 infection diagnosis/prognosis. Advanced SP methodologies and DL models for diagnosis and prognosis of COVID-19 are presented,
taking into consideration major challenges and opportunities.
This article provides the SP community with a comprehensive
introduction to various solutions to COVID-19 Radiomics. In
addition, the article provides the required radiological background, available resources, and challenges/opportunities for
extensive future SP research in this multidisciplinary domain
to serve our diligent role in combating COVID-19 pandemic
and possible future similar ones.
ACKNOWLEDGEMENT
This project was partially supported by the Department of
National Defence’s Innovation for Defence Excellence and
Security (IDEaS) program, Canada.
We would like to thank the consulting committee and EiC
of IEEE SPM for their two-round reviews and encouraging
comments.
R EFERENCES
[1] WHO Publications, “Use of Chest Imaging in COVID-19,” WHO/2019nCoV/Clinical/Radiology imaging/2020.1.
[2] L.M. Kucirka, S.A. Lauer, O. Laeyendecker, D. Boon, and J. Lessler,
“Variation in False-Negative Rate of Reverse Transcriptase Polymerase
Chain Reaction-based SARS-CoV-2 tests by Time since Exposure,” Ann.
Intern. Med., 2020

[3] P. Afshar, A. Mohammadi, K. N. Plataniotis, A. Oikonomou and H.
Benali, “From Handcrafted to Deep-Learning-Based Cancer Radiomics:
Challenges and Opportunities,” IEEE Signal Processing Magazine, vol.
36, no. 4, pp. 132-160, July 2019.
[4] F. Shi, et al., “Review of Artificial Intelligence Techniques in Imaging
Data Acquisition, Segmentation and Diagnosis for COVID-19,” IEEE
Reviews in Biomedical Engineering, 2020.
[5] D. Dong, et al., “The Role of Imaging in the Detection and Management
of COVID-19: A Review,” IEEE Reviews in Biomedical Engineering,
2020.
[6] M. Jamshidi, et al., “Artificial Intelligence and COVID-19: Deep
Learning Approaches for Diagnosis and Treatment,” IEEE Access, pp.
109581-109595, 2020.
[7] H. Swapna, et al., “Role of Intelligent Computing in COVID-19
Prognosis: A State-of-the-Art Review,” Chaos, Solitons & Fractals,
2020.
[8] A. Shoeibi, et al., “Automated Detection and Forecasting of COVID-19
using Deep Learning Techniques: A Review,” arXiv:2007.10785, 2020.
[9] WHO Publications, “COVID-19 Cases by Countries and Territories,
Geneva: World Health Organization,” https://portal.who.int/report/eioscovid19-counts/, 2020.
[10] Government of Canada
“Coronavirus Disease (COVID-19),”
https://www.canada.ca/en/public-health/services/diseases/2019-novelcoronavirus-infection.html, 2020.
[11] CDC,
“Coronavirus (COVID-19), Cases and Data,”
https://www.cdc.gov/coronavirus/2019-ncov/covid-data/
covidview/index.html, 2020.
[12] R.M. Anderson and R.M., May, “Population Biology of Infectious
Diseases I,” Nature, vol. 280, pp. 361- 367, 1979.
[13] Y. Wang, et al., “The Cognitive and Mathematical Foundations of Analytic Epidemiology,” IEEE 19th International Conference on Cognitive
Informatics and Cognitive Computing (ICCI*CC’20), Tsinghua Univ.,
Beijing, China, Sept. 2020, in press.
[14] Y. Wang, O. Zatarain, T. Tsai, and D. Graves, “Sequence Learning for
Image Recognition in Videos with Differential Neural Networks,” IEEE
18th International Conference on Cognitive Informatics and Cognitive
Computing (ICCI*CC’19), Polytechnic Milan, Italy, IEEE CS Press, July
2019, pp. 117-112.
[15] Y. Wang, “On Visual Semantic Algebra (VSA): A Denotational Mathematical Structure for Modelling and Manipulating Visual Objects and
Patterns,” International Journal of Software Science and Computational
Intelligence, vol. 1, no. 4, pp. 1-16, 2009.
[16] Y. Wang, “Keynote: From Neuroinformatics, Bioinformatics to Cognitive Informatics, Brain Informatics and Computational Medical Applications,” IEEE 32nd International Symposium on Computer-Based
Medical Systems (CBMS‘19), Cordoba, Spain, June 5-7, 2019, pp. 2.
[17] Y. Wang, “Keynote: On the Three-Generation Information Theories
and Latest Advances in Cognitive Informatics,” 6th World Congress
of Information Technologies (InfoTech’19), Nanjing, China, May 11-12,
pp. 3, 2019.
[18] Y. Wang, “Keynote: Cognitive Foundations and Formal Theories of
Human and Robot Visions,” 17th IEEE International Conference on
Cognitive Informatics and Cognitive Computing (ICCI*CC’2018), UC
Berkeley, USA, IEEE CS Press, July 2018, pp. 5.
[19] J.P. Metlay, and G.W. Waterer, “Treatment of Community-Acquired
Pneumonia During the Coronavirus Disease 2019 (COVID-19) Pandemic,” American College of Physicians, 2020.
[20] M. Burk, et al., “Viral Infection in CCommunity-acquired Pneumonia: A
Systematic Review and Meta-Analysis,” European Respiratory Review,
vol. 25, no. 140, pp.178-188, 2016.
[21] J.M. Abduljalil, “Laboratory Diagnosis of SARS-CoV-2: Available
Approaches and Limitations,” New microbes and new infections, 100713,
2020.
[22] J.P. Ko, et al., “Pulmonary COVID-19: Multimodality Imaging Examples,” RadioGraphics, vol.40, no.7, pp. 1893-1894, 2020.
[23] G.D. Rubin, et al., “The Role of Chest Imaging in Patient Management
During the COVID-19 Pandemic: A Multinational Consensus Statement
from the Fleischner Society,” Chest, 2020.
[24] S.L. Haak, et al., “Diagnostic Accuracy of Point-of-Care Lung Ultrasound in COVID-19,” Emergency Medicine Journal, 2020.
[25] Y. Li and L. Xia, “Coronavirus Disease 2019 (covid-19): Role of Chest
CT in Diagnosis and Management,” American Journal of Roentgenology,
vol. 214, no. 6, pp. 1280-1286, 2020.
[26] D.M. Hansell, et al., “Fleischner Society: Glossary of Terms for
Thoracic Imaging,” Radiology, vol. 246, no. 3, pp. 697-722, 2008.

24

[27] X. Zhang, et al., “Epidemiological, Clinical Characteristics of Cases of
Sars-Cov-2 Infection with Abnormal Imaging Findings,” International
Journal of Infectious Diseases, 2020.
[28] Z. Sun, N. Zhang, Y. Li, and X. Xu, “A Systematic Review of Chest
Imaging Findings in COVID-19,” Quantitative Imaging in Medicine and
Surgery, vol. 10, no. 5, 1058, 2020.
[29] P. Afshar, et al., “COVID-CT-MD: COVID-19 Computed Tomography
(CT) Scan Dataset Applicable in Machine Learning and Deep Learning,”
Submitted to Nature Scientific Data, September 2020.
[30] A. Bernheim, et al., “Chest CT Findings in Coronavirus Disease-19
(COVID-19): Relationship to Duration of Infection,” Radiology, 200463,
2020.
[31] H.X. Bai, et al., “Performance of Radiologists in Differentiating
COVID-19 from Viral Pneumonia on Chest CT,” Radiology, 200823,
2020.
[32] L. Huang, et al., “Serial Quantitative Chest CT Assessment of COVID19: Deep-Learning Approach,” Radiology: Cardiothoracic Imaging, vol.
2, no. 2, e200075, 2020.
[33] S. Chaganti, et al., “Automated Quantification of CT Patterns Associated
with COVID-19 from Chest CT,” Radiology: Artificial Intelligence, vol.
2, no. 4, e200048, 2020.
[34] M. Francone, et al., “Chest CT Score in COOVID-19 Patients:
Correlation with Disease Severity and Short-term Prognosis,” European
Radiology, vol. 30, no. 12, pp. 6808-6817, 2020.
[35] H. Yuen, et al., “Frequency and Distribution of Chest Radiographic
Findings in COVID-19 Positive Patients,” Radiology, 201160, 2020.
[36] D. Toussie, et al., “Clinical and Chest Radiography Features Determine
Patient Outcomes in Young and Middle Age Adults with COVID-19,”
Radiology, 201754, 2020.
[37] D. Cozzi, et al., “Chest X-ray in New Coronavirus Disease 2019
(COVID-19) Infection: Findings and Correlation with Clinical Outcome,” La Radiologia Medica, 2020.
[38] W. Lu, et al., “A Clinical Study of Noninvasive Assessment of
Lung Lesions in Patients with Ccoronavirus Disease-19 (COVID-19)
by Bedside Ultrasound,” Ultraschall in der Medizin-European Journal
of Ultrasound, vol. 41, no. 03, pp. 300-307, 2020.
[39] L. Vetrugno, et al., “Our Italian Experience using Lung Ultrasound for
Identification, Grading and Serial follow-up of Severity of Lung Involvement for Management of Patients with COVID-19,” Echocardiography,
vol. 37, no. 4, pp. 625-627, 2020.
[40] H. Bjorke,
“COVID-19 Segmentation Dataset,”
MedSeg
http://medicalsegmentation.com/covid19/, 2020
[41] M. Jun, et al., “COVID-19 CT Lung and Infection Segmentation Dataset
(version 1.0), Zenodo, http://doi.org/10.5281/zenodo.3757476, 2020.
[42] J. Cohen, P. Morrison, and L. Dao, “COVID-19 Image Data Collection,”
Preprint at arXiv:2003.11597v1, 2020.
[43] S. Morozov, et al., “Mosmeddata: Chest CT Scans with COVID-19
Related Findings Dataset,” Preprint at arXiv:2005.06465, 2020.
[44] J. Zhao, Y. Zhang, X. He, and P. Xie, “COVID-CT-Dataset: A CT Scan
Dataset about COVID-19,” Preprint at arXiv:2003.13865, 2020.
[45] E. Soares, et al., “Sars-cov-2 CT-Scan Dataset: A Large Dataset of Real
Patients CT Scans for sars-cov-2 Identification,” Preprint at medRxiv,
2020.
[46] M. Rahimzadeh, A. Attar, and S. Sakhaei, “A Fully Automated Deep
Learning-based Network for Detecting COVID-19 from a New and
Large Lung CT Scan Dataset,” Preprint at medRxiv, 2020.
[47] M. de la Iglesia Vayá, et al., “BIMCV COVID-19+: A large Annotated
Dataset of RX and CT Images from COVID-19 Patients.,” arXiv preprint
arXiv:2006.01174, 2020.
[48] P.J. Cohen, et al., “COVID-19 Image Data Collection: Prospective
Predictions are the Future,” arXiv preprint arXiv:2006.11988, 2020.
[49] K.T. Rajamani, H. Siebert, and M. Heinrich, “Dynamic Deformable
Attention (DDANET) for Semantic Segmentation,” medRxiv, 2020.
[50] D. Fan, et al., “INf-NET: Automatic COVID-19 Lung Infection
Segmentation from CT Images,” IEEE Trans. Medical Imaging, 2020.
[51] Y. Qiu, Y. Liu, and J. Xu, “Miniseg: An Extremely Minimum
Network for Efficient COVID-19 Segmentation,”
arXiv preprint
arXiv:2004.09750, 2020.
[52] K. Zhang, et al., “Clinically Applicable AI System for Accurate
Diagnosis, Quantitative Measurements, and Prognosis of COVID-19
Pneumonia using Computed Tomography,” Cell, 2020.
[53] D. Müller, I. Rey, and F. Kramer, “Automated Chest CT Image
Segmentation of COVID-19 Lung Infection based on 3D N-Net,” arXiv
preprint arXiv:2007.04774, 2020.
[54] A. Degerli, et al., “COVID-19 Infection Map Generation and Detection
from Chest X-ray Images,” arXiv preprint arXiv:2009.12698, 2020.

[55] B. Zheng, et al., “MSD-Net: Multi-scale Discriminative Network for
COVID-19 Lung Infection Segmentation on CT,” IEEE Access, vol. 8,
pp. 185786-185795, 2020.
[56] F. Shan, et al., “Lung Infection Quantification of COVID-19 in CT
Images with Deep Learning,” arXiv preprint arXiv:2003.04655, 2020.
[57] O. Ronneberger, P. Fischer, and T. Brox, “U-Net: Convolutional Networks for Biomedical Image Segmentation,” International Conference
on Medical Image Computing and Computer-Assisted Intervention, pp.
234-241, 2015.
[58] Z. Li, et al., “From Community-Acquired Pneumonia to covid-19: A
deep Learning-based Method for Quantitative Analysis of COVID-19 on
Thick-section CT Scans,” European Radiology, vol. 30, pp. 6828-6837,
2020.
[59] G. Wang, et al., “A Noise-Robust Framework for Automatic Segmentation of COVID-19 Pneumonia Lesions from CT Images,” IEEE
Transactions on Medical Imaging, vol. 39, no. 8, pp. 2653-2663, 2020.
[60] V. Mergen, et al., “Deep Learning for Automatic Quantification of Lung
Abnormalities in COVID-19 Patients: First Experience and Correlation
with Clinical Parameters,” European Journal of Radiology Open, vol.
7, 100272, 2020.
[61] Y.H. Wu, et al., Jcs: An explainable covid-19 diagnosis system by joint
classification and segmentation. arXiv preprint arXiv:2004.07054, 2020.
[62] A. Amyar, R. Modzelewski, H. Li, and S. Ruan. “Multi-task Deep
Learning based CT Imaging Analysis for COVID-19 Pneumonia: Classification and Segmentation,” Computers in Biology and Medicine, vol.
126, 104037, 2020.
[63] J. Ma, et al., “Towards Efficient COVID-19 CT Annotation: A
Benchmark for Lung and Infection Segmentation,” arXiv preprint
arXiv:2004.12537, 2020.
[64] I. Laradji, et al., “A Weakly Supervised Region-based Active Learning
Method for COVID-19 Segmentation in CCT Images,” arXiv preprint
arXiv:2007.07012, 2020.
[65] Z. Xu, et al., “GASNET: Weakly-Supervised Framework for COVID-19
Lesion Segmentation,” arXiv preprint arXiv:2010.09456, 2020.
[66] T. Zhou, S. Canu, and S. Ruan, “An Automatic COVID-19 CT
Segmentation based on U-Net with Attention Mechanism,” arXiv
preprint arXiv:2004.06673, 2020.
[67] S. Zhao, et al., “Scoat-Net: A Novel Network for Segmenting COVID19 Lung Opacification from CT Images,” medRxiv, 2020.
[68] J. Ma, et al., “Active Contour Regularized Semi-supervised Learning
for COVID-19 CT Infection Segmentation with Limited Annotations,”
Physics in Medicine & Biology, 2020.
[69] G. Chassagnon, et al., “Ai-Driven Quantification, Staging and Outcome
Prediction of COVID-19 Pneumonia,” Medical Image Analysis, vol. 67,
101860, 2020.
[70] H. Wang, et al., “Decoding COVID-19 Pneumonia: Comparison of Deep
Learning and Radiomics CT Image Signatures,” European Journal of
Nuclear Medicine and Molecular Imaging, 2020.
[71] F. Shi, et al., “Large-scale Screening of COVID-19 from Community
Acquired Pneumonia using Infection Size-aware Classification,” 2020.
[72] M. Fang, et al., “CT Radiomics can help Screen the Coronavirus Disease
2019 (COVID-19): A Preliminary Study,” Science China Information
Sciences, vol. 63, 2020.
[73] H.Yue, et al., “Machine Learning-based CT Radiomics Method for
Predicting Hospital Stay in Patients with Pneumonia Associated with
Sars-Cov-2 Infection: A Multicenter Study,” Annals of translational
medicine, vol. 8, no. 14, 2020.
[74] X. Bai, et al., “Predicting COVID-19 Malignant Progression with AI
Techniques,” medRxiv 2020.03.20.20037325, 2020.
[75] L. Zeng, et al., “Risk Assessment of Progression to Severe Conditions
for Patients with COVID-19 Pneumonia: A Single-center Retrospective
Study,” medRxiv, 2020.
[76] D. Colombi, et al., “Well-aerated Lung on Admitting Chest CT
to Predict Adverse Outcome in COVID-19 Pneumonia,” Radiology,
201433, 2020.
[77] N. Lassau, et al., “AI-based Multi-modal Integration of Clinical
Characteristics, Lab Tests and Chest CTs Improves COVID-19 Outcome
Prediction of Hospitalized Patients,” medRxiv, 2020.
[78] W. Ning, et al., “Open Resource of Clinical Data from Patients
with Pneumonia for the Prediction of COVID-19 Outcomes via Deep
Learning,” Nature Biomedical Engineering, pp. 1-11, 2020.
[79] H. Chao, et al., “Integrative Analysis for COVID-19 Patient Outcome
Prediction,” Medical Image Analysis, vol. 67, pp. 101844, 2020.
[80] R. Amer, M. Frid-Adar, O. Gozes, J. Nassar, and H. Greenspan,
“COVID-19 in CXR: From Detection and Severity Scoring to Patient
Disease Monitoring,” arXiv:2008.02150, 2020.

25

[81] P. Lyu, X. Liu, R. Zhang, L. Shi, and J. Gao. “The Performance of
Chest CT in Evaluating the Clinical Severity of COVID-19 Pneumonia:
Identifying Critical Cases based on CT Characteristics,” Investigative
Radiology, vol. 55, no. 7, pp. 412-421, 2020.
[82] J. Zhu, et al., “Deep Transfer Learning Artificial Intelligence Accurately Stages COVID-19 Lung Disease Severity on Portable Chest
Radiographs,” PLOS ONE, vol. 15, no. 7, pp. 1-11, 2020.
[83] S.S.F. Yip, et al., “Performance and Robustness of Machine Learningbased Radiomic COVID-19 Severity Prediction,” medRxiv, 2020.
[84] Y. Feng, et al., “Severity Assessment and Progression Prediction of
COVID-19 Patients based on the Lesion Encoder Framework and Chest
CT,” medRxiv, 2020.
[85] W. Cai, et al., “CT Quantification and Machine-Learning Models for
Assessment of Disease Severity and Prognosis of COVID-19 Patients,”
Academic Radiology, vol. 27, no. 12, pp. 1665-1678, 2020.
[86] M.D. Li, et al., “Automated Assessment and Tracking of COVID-19
Pulmonary Disease Severity on Chest Radiographs using Convolutional
Siamese Neural Networks,” Radiology: Artificial Intelligence, vol. 2,
no. 4, e200079, 2020.
[87] Z. Tang, et al., “Severity Assessment of COVID-19 using CT Image
Features and Laboratory Indices,” Phys Med Biol, 2020.
[88] B. Ghosh, et al., “A Quantitative Lung Computed Tomography Image
Feature for Multi-center Severity Assessment of COVID-19,” medRxiv,
2020.
[89] X. Mei, et al., “Artificial Intelligence-Enabled Rapid Diagnosis of
Patients with COVID-19,” Nature Medicine, vol. 26, pp. 1224-1228,
2020.
[90] A.A. Ardakani, et al., “Application of Deep Learning Technique to
Manage COVID-19 in Routine Clinical Practice using CT Images:
Results of 10 Convolutional Neural Networks,” Computers in Biology
and Medicine, vol. 121, 103795, 2020.
[91] H.X. Bai, et al., “Artificial Intelligence Augmentation of Radiologist
Performance in Distinguishing COOVID-19 from Pneumonia of other
origin at Chest CT,” Radiology, vol. 296, no. 3, pp. E156-E165, 2020.
[92] I. Castiglioni, et al., “Artificial Intelligence Applied on Chest X-ray can
Aid in the Diagnosis of COVID-19 Infection: A first Experience from
Lombardy, Italy,” medRxiv, 2020.
[93] L. Li, et al., “Using Artificial Intelligence to Detect COVID-19 and
Community-Acquired Pneumonia based on Pulmonary CT: Evaluation
of the Diagnostic Accuracy,” Radiology, vol. 296, no. 2, pp. E65–E71,
2020.
[94] A. Abbas, M. M. Abdelsamea, and M. M. Gaber. “Classification of
COVID-19 in Chest X-ray Images using Detrac Deep Convolutional
Neural Network,” 2020.
[95] A. Waheed, et al., “COVIDGAN: Data Augmentation using Auxiliary
Classifier GAN for Improved COVID-19 Detection,” IEEE Access, vol.
8, pp. 91916-91923, 2020.
[96] P. Afshar, Sh. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis, and A. Mohammadi. “COVID-CAPS: A Capsule Network-based
Framework for Identification of COVID-19 Cases from X-ray Images,”
Pattern Recognition Letters, vol. 138, pp. 638-643, 2020.
[97] Sh. Wang, et al., “A Deep Learning Algorithm using CT Images to
Screen for Corona Virus Disease (COVID-19),” medRxiv, 2020.
[98] L. Wang, Z.Q. Lin, and A. Wong. “COVID-NET: A Tailored Deep
Convolutional Neural Network Design for Detection of COVID-19
Cases from Chest X-ray Images,” Scientific Reports, vol. 10, 19549,
2020.
[99] O. Gozes, et al., “Rapid AI Development Cycle for the Coronavirus
(COVID-19) Pandemic: Initial Results for Automated Detection &
Patient Monitoring using Deep Learning CT Image Analysis,” 2020.
[100] M. Farooq, and A. Hafeez.
“COVID-Resnet: A Deep Learning Framework for Screening of COVID-19 from Radiographs,”
arXiv:2003.14395, 2020.
[101] A. Narin, C. Kaya, and Z. Pamuk, “Automatic Detection of Coronavirus
Disease (COVID-19) using X-ray Images and Deep Convolutional
Neural Networks,” arXiv:2003.10849, 2020.
[105] S. Ying, et al., “Deep Learning Enables Accurate Diagnosis of Novel
Coronavirus (COVID-19) with CT images,” medRxiv, 2020.

[102] T. Ozturk, et al., “Automated Detection of COVID-19 Cases using
Deep Neural Networks with X-ray Images,” Computers in Biology and
Medicine, vol. 121, 103792, 2020.
[103] M. Karim, et al., “Deep COVID Explainer: Explainable COVID19 Predictions based on Chest X-ray Images,
arXiv preprint
arXiv:2004.04582, 2020.
[104] E.E. Hemdan, M.A. Shouman, and M.E. Karar. “Covidx-Net: A
Framework of Deep Learning Classifiers to Diagnose COVID-19 in Xray Images,” 2020.
[106] Y. Oh, S. Park, and J.C. Ye, “Deep Learning COVID-19 Features on
CXR using Limited Training Data Sets,” IEEE Transactions on Medical
Imaging, vol. 39, no. 8, pp. 2688-2700, 2020.
[107] J. Zhang, et al., “Viral Pneumonia Screening on Chest X-ray Images
using Confidence-aware Anomaly Detection,” arXiv:2003.12338, 2020.
[108] S. Hu, et al., “Weakly Supervised Deep Learning for COVID-19
Infection Detection and Classification from CT Images,” IEEE Access,
vol. 8, pp. 118869-118883, 2020.
[109] Z. Islam, M. Islam, and A. Asraf. “A Combined Deep CNN-LSTM
Network for the Detection of Novel Coronavirus (COVID-19) using Xray Images,” Informatics in Medicine Unlocked, vol. 20, 100412, 2020.
[110] A. Sedik, et al., “Deploying Machine and Deep Learning Models for
Efficient Data-augmented Detection of COVID-19 Infections,” Viruses,
vol. 12, no. 769, 2020.
[111] X. Wang, et al., “A Weakly-Supervised Framework for COVID19 Classification and Lesion Localization from Chest CT,” IEEE
Transactions on Medical Imaging, vol. 39, no. 8, pp. 2615-2625, 2020.
[112] X. Xu, et al., “A Deep Learning System to Screen Novel Coronavirus
Disease 2019 Pneumonia,” Engineering, 2020.
[113] A. Mohammed, et al., Weakly-Supervised Network for Detection of
COVID-19 in Chest CT Scans,” IEEE Access, vol. 8, pp. 155987156000, 2020.
[114] Sh. Yang, et al., “Deep Learning for Detecting Corona Virus Disease
2019 (COVID-19) on High-Resolution Computed Tomography: A Pilot
Study,” Annals of Translational Medicine, vol. 8, no. 7, 2020.
[115] L. Meng, et al., “A Deep Learning Prognosis Model Help Alert for
COVID-19 Patients at High-risk of Death: A Multi-Center Study,” IEEE
Journal of Biomedical and Health Informatics, 2020.
[116] Sh. Heidarian, et al., “COVID-FACT: A Fully-Automated Capsule
Network-based Framework for Identification of COVID-19 Cases From
Chest CT Scans,” arXiv:2010.16041, 2020.
[117] Sh. Heidarian, et al., “CT-CAPS: Feature Extraction-based Automated
Framework for COVID-19 Disease Identification from Chest CT scans
using Capsule Networks,” arXiv:2010.16043, 2020.
[118] O. Gozes, et al., “Coronavirus Detection and Analysis on Chest CCT
with Deep Learning,: arXiv:2004.02640, 2020.
[119] N.N. Das, N. Kumar, M. Kaur, V. Kumar, and D. Singh, “Automated
Deep Transfer Learning-based Approach for Detection of COVID-19
Infection in Chest X-rays,” IRBM, 2020.
[120] Q. Yao, L. Xiao, P. Liu, and S.K. Zhou, “Label-free Segmentation
of COVID-19 Lesions in Lung CT,” arXiv preprint arXiv:2009.06456,
2020.
[121] Y. Li, et al., “Efficient and Effective Training of COVID-19 Classification Networks with Self-Supervised Dual-Track Learning to Rank,”
IEEE J. Biomedical & Health Inf., vol. 24, no. 10, pp. 2787-2797, 2020.
[122] F. Homayounieh, et al., “CT Radiomics, Radiologists and Clinical
Information in Predicting Outcome of Patients with COVID-19 Pneumonia,” Radiology: Cardiothoracic Imaging, vol. 2, no. 4, pp. e200322,
2020.
[123] X. Ouyang, et al., “Dual-sampling Attention Network for Diagnosis of
COVID-19 from Cmmunity Acquired Pneumonia,” IEEE Transactions
on Medical Imaging, 2020.
[124] S.M.H. Tabatabaei, et al., “A Low-dose Chest CT Protocol for the
Diagnosis of COVID-19 Pneumonia: A Prospective Study,” Emergency
Radiology, 27, 2020.

