U.S. Broadband Coverage Data Set: A Differentially Private
Data Release
Mayana Pereira1 , Allen Kim1 , Joshua Allen1 , Kevin White1 , Juan Lavista Ferres1 , and Rahul Dodhia1

arXiv:2103.14035v2 [cs.CR] 1 Apr 2021

Microsoft Corp.

Abstract. Broadband connectivity is a key metric in today’s economy. In an era of rapid expansion of the digital economy, it directly impacts GDP. Furthermore, with the COVID-19 guidelines
of social distancing, internet connectivity became necessary to everyday activities such as work,
learning, and staying in touch with family and friends. This paper introduces a publicly available
U.S. Broadband Coverage data set that reports broadband coverage percentages at a zip codelevel. We also explain how we used differential privacy to guarantee that the privacy of individual
households is preserved. Our data set also contains error ranges estimates, providing information
on the expected error introduced by differential privacy per zip code. We describe our error range
calculation method and show that this additional data metric does not induce any privacy losses.

1

Introduction

Reaping the benefits of this digital world – pursuing new educational opportunities through distance
learning, growing a small business by leveraging the cloud, and accessing better healthcare through
telemedicine – is only possible for those with a broadband connection. As more people are staying home
due to the COVID-19 pandemic, it becomes more evident the necessity of broadband connection for daily
activities and better growth opportunities.
Based on the 2019 Broadband Deployment Report from the Federal Communications Commission
(FCC) [5], broadband connection is not available to at least 21 million people in the United States,
16 million of whom live in this country’s rural areas. Getting these numbers right is vitally important.
This data is used by federal, state, and local agencies to decide where to target public funds dedicated
to closing this broadband gap 1 . That means millions of Americans already lacking broadband access
have been made invisible, substantially decreasing the likelihood of additional broadband funding or
much-needed broadband service. At the same time, making this data available in the clear, without any
type of post-processing, may affect the privacy of individual households. In this contribution we solve
this dilemma by presenting a data set that allows researchers and policy makers to develop solutions to
improve broadband access while simultaneously preserving the privacy of individual households.
This paper describes the data privatization process used in the release of the broadband coverage data
set2 . The data sets utilized are derived from anonymized data Microsoft collects as part of our ongoing
work to improve our software and services’ performance and security. We estimate broadband coverage
by combining data from multiple Microsoft services. Every time a device receives an update or connects
to a Microsoft service, we can estimate the throughput speed. We know the package’s size sent to the
computer, and we know the total time of the download. We also determine zip code level location data
via reverse IP. Therefore, we can count the number of devices connected to the internet at broadband
speed per each zip code based on the FCC’s definition of broadband that is 25mbps per download 3 .
Using this method, we estimate that in 2020, ≈ 123 million people in the United States are not using the
internet at broadband speeds.
Contributions: . In this paper, we describe the U.S. Broadband Coverage Data set and the data
privatization process to enable its safe sharing. Our two main contributions are:
1
2
3

https://www.fcc.gov/about-fcc/fcc-initiatives/bridging-digital-divide-all-americans
https://github.com/microsoft/USBroadbandUsagePercentages
https://broadbandnow.com/report/fcc-broadband-definition/

2

Mayana Pereira, Allen Kim, Joshua Allen, Kevin White, Juan Lavista Ferres, and Rahul Dodhia

• We describe the privatization process of the Broadband Coverage Data Set. Our method utilizes
differentially private mechanisms for data privatization. We describe implementation details and
privacy loss specifications.
• We propose a method for error range estimation. Our empirical method estimates the error introduced
by differential privacy for each zip code in our data set. The main advantage of our method is that
it does not result in additional privacy losses.

Fig. 1. Map of the United States by postal codes with indicators of broadband coverage.

2

Preliminaries

Differential privacy is a rigorous privacy notion used to protect an individual’s data in a data set disclosure.
We present in this section notation, definitions, and theorems that we will use to describe our privatization
approach. We refer the reader to [4], [6] and [3] for more detailed explanations of these definitions and
theorem proofs.
Definition 1. Differential Privacy A randomized mechanism M : D → Y with data base domain D and
output set Y is -differentially private if, for any output Y ⊆ Y and neighboring databases D, D0 ∈ D
(i.e., D and D0 differ in at most one entry), we have
P r[M(D) ∈ Y ] ≤ e P r[M(D0 ) ∈ Y ]
The privacy loss of the mechanism is defined by the parameter  ≥ 0.
The definition of neighboring databases used in this paper is user-level privacy. User-level privacy
defines neighboring to be the addition or deletion of a single user in the data and all possible records
of that user. Informally, the definition above states that the addition or removal of a single individual

U.S. Broadband Coverage Data Set: A Differentially Private Data Release

3

in the database does not provoke significant changes in the probability of any differentially private output. Therefore, differential privacy limits the amount of information that the output reveals about any
individual.
A function f (also called query) from a data set D ∈ D to a result set Y ⊆ Y can be made differentially
private by injecting random noise to its output. The amount of noise depends on the sensitivity of the
query.
Definition 2. l1 -sensitivity. The l1 -sensitivty of a function f : D → Rn is:
∆f = maxD,D0 k f (D) − f (D0 ) k1
Where D and D0 are neighboring databases.
We note that, for count queries, ∆f = 1.
The Laplace distribution with 0 mean and scale λ, denoted by Lap(λ), has a probability density
x
1 −λ
e . It can be used to obtain an -differentially private algorithm to answer
function Lap(x|λ) = 2λ
numeric queries [3].
Definition 3. Laplace Mechanism. Let f : D → Rn be a numeric query. The Laplace mechanism is
defined as:
ML (x, f (·), ) = f (x) + (η1 , . . . , ηn )
where ηi are drawn from the Laplace distribution Lap( ∆f
 ).
Theorem 1. The Laplace Mechanism preserves -differential privacy [4].
An important differential privacy property is its immunity to post-processing. The composition of a
data-independent mapping g with a -differentially private algorithm M, is also -differentially private.
Theorem 2. Post-Processing [4] Let M be an -differentially private mechanism and g be an arbitrary
randomized mapping. Then, g ◦ M is -differentially private.

3

Differentially Private Broadband Coverage Estimates per Zip Code

The Broadband Coverage Estimates data set is derived from aggregated and anonymized information
Microsoft collects as part of our ongoing work to improve software and service performance and security.
Our metric for computing broadband coverage across the United States estimates the percentage of
devices with internet connection speed over 25Mbps. We denote the set of zip codes in our data set by
Z. Our analysis uses zip codes as the smallest territorial unit. For every zip code z in Z, the calculation
encompasses the following variables:
From Microsoft Services, we query the following Windows telemetry data:
– Lz : Counts of devices connecting to Microsoft Services with internet speed lower than 25Mbps in
zip code z.
– Hz : Counts of devices connecting to Microsoft Services with internet speed greater or equal than
25Mbps in zip code z.
Additionally, we query Microsoft Services for the following data:
– Mz : Counts of devices utilizing Microsoft Services in zip code z.
– Oz : Counts of devices not utilizing Microsoft Services in zip code z.
Our data set contains 32,653 zip codes, covering most of the United States territory (see Figure 1).
The Broadband Coverage Estimate (BCE), is a metric that estimates the fraction of households of a
zip code with access to internet with connection speeds over 25Mpbs. BCE is computed as follows:
BCE(z) = Hz · (

Mz
1
)−1 ·
Mz + O z
HUDz

(1)

4

Mayana Pereira, Allen Kim, Joshua Allen, Kevin White, Juan Lavista Ferres, and Rahul Dodhia

Where HUDz is the number of households in zip code z, provided by the publicly available HUD data
set [10]. Given the zip code-level data set provides a granular view of broadband coverage, we ensure data
privacy by utilizing differential privacy. For each of the counts queries from Microsoft Services Telemetry
Data, we use the Laplace Mechanism, with an epsilon of 0.1, to obtain differentially private counts.
Our chosen privacy parameter is comparable to other industry differentially private data releases [1] [9].
Because the Laplace mechanism can induce negative counts when the true counts are very small, we
clamp all negative values to zero [11]. According to the post-processing immunity property (theorem 2),
the privacy loss does not change by this step. We denote the differentially private counts of the variables
DP
DP
used in our calculations by LDP
and OzDP .
z , Hz , Mz
The published data set consists of a list of 32,653 zip codes. This list of zip codes was predefined based
on average number of machines is the last years. For each zip code we provide the differentially private
DP
DP
DP
Broadband Coverage Estimate BCEDP . BCEDP takes as input LDP
and is calculated
z , Hz , Mz , Oz
according to equation 1.
Our data set also includes the expected error, per zip code, induced by the privatization process. In
section 4 we describe the details of our error ranges estimation method.
3.1

Privacy Loss

The privacy loss computation is a straightforward application of the parallel and sequential composition
properties of differential privacy mechanisms [6]. The total privacy loss resulted from querying the internet
and HzDP are differentially private count queries applied to
speed telemetry is  = 0.1. Given that LDP
z
disjoint subsets of the data, from parallel composition we know that the privacy guarantee depends only
on the worst of the guarantees of each analysis. The same happens when computing the privacy loss
incurred from the Microsoft Services devices queries. The count queries are applied to disjoint subsets
of data, resulting in an additional privacy loss of  = 0.1. From sequential composition we have that
sequences of queries accumulate privacy costs additively. Finally, based on the post-processing immunity
property described in theorem 2, the total privacy cost of the Broadband Coverage Estimates calculation
is  = 0.2.

4

Error Ranges Estimation

Differential privacy adds noise to protect privacy. A consequence of the additive noise is that differentially
private counts from smaller subsets of data can be proportionally more affected by the noise, resulting in
greater impact on utility.
To ensure transparency into how zip codes with different population magnitudes are affected by
differential privacy, we have included error range data. We propose an empirical methodology, via a
simulation process, to calculate the expected error range caused by differential privacy. Although we
can estimate differential privacy effects in query counts, the resulting error when combining several
differentially private data sources is better estimated through a simulation process.
Our simulation process, illustrated in figure 2, simulates k differentially private broadband coverage
estimate BCE(z) for each zipcode z in Z. For each zipcode we estimate 95th percentile error, mean
absolute error and mean signed deviation.
All simulations occur in a post processing phase. For each zipcode z in Z, and for i ∈ {1, 2, . . . , k},
the error range estimation process occurs as follows:
i

– HzDP ← HzDP + Lap( 1 ).
i

– MzDP ← MzDP + Lap( 1 ).
i

– OzDP ← OzDP + Lap( 1 ).
i

i

i

– BCEi (z) takes as input HzDP , MzDP , OzDP and is computed according to equation 1.
– Finally, we compute dzi = BCEDP (z) − BCEi (z).

U.S. Broadband Coverage Data Set: A Differentially Private Data Release

5

Fig. 2. Process for estimating the error introduced by differential privacy. The error ranges are estimated by
generating several simulated private releases, and reporting the error introduced differential privacy.

Each Lap( 1 ) is an independent sample from the Laplace distribution. For each zipcode, the simulation
process will produce the vector dz = [dz1 , dz2 , . . . , dzk ], which consists of simulated errors caused by utilizing
differentially private counts in the BCE calculation.
Finally, for each zipcode z we estimate from dz the following error metrics: mean absolute error and
th
95 percentile error. The non-private broadband coverage estimate will be, on average, within the mean
absolute error (MAE) error range. Additionally, the 95th percentile error gives a range where, for 95% of
the time, the non-private broadband coverage estimate will be within. We also provide the mean signed
deviation (MSD). The mean signed deviation offers an estimate of bias introduced by the process.
We display on Figure 3 the error metrics for different population ranges (in number of households).
Notice that the expected error decreases as the population size increases. Informally, we can say that
the larger the population is, the less noise is needed to mask the presence or absence of an individual.
Analogously, we can say that the smaller the population is, the more noise is necessary to mask the
presence or absence of an individual.
The error range calculation is a post processing operation on the privatized data, i.e., all calculations
DP
DP
use only the private counts LDP
and OzDP as input. From the post-processing immunity
z , Hz , Mz
property, this process results in zero the privacy loss.
It is worth noting that the broadband coverage estimation has other sources of error, such as sampling
error and bias. The error estimates provided in this data release do not account for such errors.

5

Implementation Details

All differential privacy processing was done with the OpenDP SmartNoise library. The SmartNoise library
includes a comprehensive set of differential privacy mechanisms, algorithms, and validator. The library
is open source, and is maintained and vetted by OpenDP.

6

Conclusion

In this paper, we describe all the steps executed to ensure that the Broadband Coverage Estimates
data set provides high utility data points while preserving privacy of Microsoft Services data. This data
provides estimates of Broadband Coverage across the United States, at a zip code level.
Additionally, we propose a simple method for estimating error via a simulation process. These supplementary data points help explain the impacts of differential privacy in different subgroup sizes. The
main advantage of the proposed method for error generation is it does not cause any additional privacy
losses.

6

Mayana Pereira, Allen Kim, Joshua Allen, Kevin White, Juan Lavista Ferres, and Rahul Dodhia

Fig. 3. Error metrics for several population ranges: Expected mean absolute error (MAE), mean signed error
(MSD) and 95th percentile of the error caused by the privatization mechanism for different population thresholds.

U.S. Broadband Coverage Data Set: A Differentially Private Data Release

7

References
1. Ahmet Aktay, Shailesh Bavadekar, Gwen Cossoul, John Davis, Damien Desfontaines, Alex Fabrikant, Evgeniy
Gabrilovich, Krishna Gadepalli, Bryant Gipson, Miguel Guevara, et al. Google covid-19 community mobility
reports: Anonymization process description (version 1.0). arXiv preprint arXiv:2004.04145, 2020.
2. Census. American fact finder. https://data.census.gov/.
3. Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private
data analysis. In Theory of cryptography conference, pages 265–284. Springer, 2006.
4. Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations and
Trends in Theoretical Computer Science, 9(3-4):211–407, 2014.
5. Federal Communications Commission.
2018 broadband deployment report — federal communications commission. https://www.fcc.gov/reports-research/reports/broadband-progress-reports/
2018-broadband-deployment-report.
6. Frank D McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis.
In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19–30,
2009.
7. OpenDP.
Accuracy: Pitfalls and edge cases.
https://github.com/opendifferentialprivacy/
smartnoise-samples/blob/master/analysis/accuracy_pitfalls.ipynb.
8. OpenDP.
Privacy-preserving statistical release.
https://github.com/opendifferentialprivacy/
smartnoise-samples/blob/master/analysis/tutorial_mental_health_in_tech_survey.ipynb.
9. Ryan Rogers, Subbu Subramaniam, Sean Peng, David Durfee, Seunghyun Lee, Santosh Kumar Kancha,
Shraddha Sahay, and Parvez Ahammad. Linkedin’s audience engagements api: A privacy preserving data
analytics system at scale. arXiv preprint arXiv:2002.05839, 2020.
10. U.S. Department of Housing and Urban Development. Office of policy development research. https://www.
huduser.gov/portal/datasets/usps_crosswalk.html.
11. Min Xu, Antonis Papadimitriou, Ariel Feldman, and Andreas Haeberlen. Using differential privacy to efficiently mitigate side channels in distributed analytics. In Proceedings of the 11th European Workshop on
Systems Security, pages 1–6, 2018.

