Divergent modes of online collective attention to the COVID-19 pandemic are
associated with future caseload variance
David Rushing Dewhurst,1, 2 Thayer Alshaabi,1, ∗ Michael V. Arnold,1, ∗
Joshua R. Minot,1, ∗ Christopher M. Danforth,1, 3 and Peter Sheridan Dodds1, 3
1

arXiv:2004.03516v2 [physics.soc-ph] 20 May 2020

Vermont Complex Systems Center, Computational Story Lab,
The University of Vermont, Burlington, VT 05405
2
MassMutual Data Science, Boston, MA 02110
3
Department of Mathematics and Statistics, The University of Vermont, Burlington, VT 05405
(Dated: May 21, 2020)
Using a random 10% sample of tweets authored from 2019-09-01 through 2020-04-30, we analyze
the dynamic behavior of words (1-grams) used on Twitter to describe the ongoing COVID-19 pandemic. Across 24 languages, we find two distinct dynamic regimes: One characterizing the rise and
subsequent collapse in collective attention to the initial Coronavirus outbreak in late January, and
a second that represents March COVID-19-related discourse. Aggregating countries by dominant
language use, we find that volatility in the first dynamic regime is associated with future volatility in
new cases of COVID-19 roughly three weeks (average 22.49 ± 3.26 days) later. Our results suggest
that surveillance of change in usage of epidemiology-related words on social media may be useful
in forecasting later change in disease case numbers, but we emphasize that our current findings are
not causal or necessarily predictive.

I.

INTRODUCTION

COVID-19 is a potentially lethal viral respiratory disease that is causing a global pandemic [1, 2]. While Coronavirus testing availability is suboptimal [3], social media
data can be part of an effective strategy for infectious disease surveillance [4–9]. Previous work has demonstrated
that online collective attention to COVID-19 as measured
by social media activity has fluctuated from the date of
the first public report of the disease (2019-12-31) to near
the time of writing (2020-04-30) [10–12].
In this work we analyze time series of word (1-gram)
ranks on Twitter computed from a 10% random sample of all messages. We find that the temporal dynamics of this discourse separate into two distinct clusters,
one (C1 ) that contains words contributing to the explosive rise in online discussion of COVID-19 prevention and
treatment during March 2020 and another (C2 ) that contains words contributing to the rise and subsequent fall in
collective attention to COVID-19 during mid-January –
mid-February 2020. Variance of percent changes in word
time series closest to the centroid of C2 is a consistent
leading indicator of variance in percent change in new
cases of COVID-19. We close with a short discussion of
the implications and limitations of these findings, and
suggestions for future research [13].

II.

DATA

We analyzed time series of word usage on a random
10% sample of tweets written between 2019-09-01 and

∗

These authors contributed equally to this work.

Typeset by REVTEX

2020-04-30. For each language under study, we considered only the top 1000 words used in the language as
ranked during the first three weeks of March 2020 [12],
and restrict our analysis to the same 24 languages analyzed in a previous work. Languages are detected and
annotated using a previously-introduced procedure [14].
We obtained data on languages spoken in each country
from the Australian Federal Department of Social Services and data on number of new COVID-19 cases by
country from the European Centers for Disease Control
[15].

III.
A.

RESULTS

Divergent modes of COVID-19 related language

We find k ∗ = 6 clusters of normalized log rank word
usage timeseries using the algorithm detailed in Sec. V A.
We compute these clusters using the entire dataset, i.e.,
aggregating all log rank time series in each of the 24
languages under study. Of these clusters, two are composed primarily of words that do not appear to relate
to COVID-19. The remaining four clusters contain language that relates to COVID-19 both explicitly and
implicitly. We combine these clusters into two aggregate clusters using the methodology defined in Sec. V.
We label these clusters C1 and C2 and their cluster centroids E[C1 ] and E[C2 ] respectively. (The ordering of the
cluster subscripts comes from the respective maxima of
their cluster centroids.) E[C1 ] exhibits very little variation until the first week of March 2020, where it begins a
sustained increase in time. Conversely, E[C2 ] exhibits a
smaller increase at the end of January 2020 followed by a
larger increase in the second week of February 2020. This
second increase in E[C2 ] is followed by another sustained

2

FIG. 1. The rise in collective attention to COVID-19 during late January 2020 to early February 2020 followed by a marked
decline preceding the global pandemic is generated by two distinct clusters of COVID-19 related language. We display the
mean normalized log rank timeseries of the top 20 English words closest to each of E[C1 ] and E[C2 ] in thinner, dashed curves,
and the single English word closest to each of E[C1 ] and E[C2 ] in thin solid curves. Increasing granularity (centroids → top 20
words → single representative word) is associated with exaggeration of the dynamics of E[C1 ] and E[C2 ]. Before normalization
we map log10 r 7→ log10 r1 so that higher values on the vertical axis are lower values of (log) rank. For comparison, the word
“pandemic” rises in popularity from a rank of 133,445 on December 21 to a rank of 188 on March 17, while the word “flatten”
goes from being the 100,913th most popular English word on January 20 to being 2,131st most used word on March 15.

increase until mid March 2020.
This divergent dynamic behavior is amplified when
restricting analysis to sets of individual word time series
that are closest to E[C1 ] or E[C2 ] in Euclidean distance.
The mean normalized log rank timeseries of the top 20
words in each language that were closest to E[C1 ] and
E[C2 ] exhibit the same qualitative behavior for most of
the 24 languages under study, but this behavior is amplified (greater magnitudes of increase and decrease). We
display these dynamics for English in Fig. 1 and for all
24 languages under study in Figs. 2 and 3. We plot
languages in order of frequency of usage on Twitter in
Figs. 2, 3, 4, and 5. For interpretable visualization, we
invert ranks (log10 r 7→ log 10 1r ) before normalization and
before plotting, so that lower ranked words — words that
are more popular and are receiving more attention — are
higher on the vertical axis than words of higher rank corresponding to lower popularity. We display the top 20
words associated with C1 and C2 in Tab. I.
Words assigned to C1 reflect immediate measures taken
to prevent the spread of COVID-19, such as “flatten”,
“distancing”, “tltravail” (telework), “hospitalier” (hospital), “encerrado” (closed), and “evitar” (to avoid).
In contrast, words assigned to C2 include more conceptual words that describe people, agencies, institu-

tions, and concepts surrounding epidemics more generally, such as “pandemic”, “CDC”, “epidemiologist”,
“l’pidmie” (the epidemic), “virus”, “contagiado” (contagious). Words assigned to C2 describe pandemics in general, while words assigned to C1 describe quarantines and
lockdowns in particular, and words particular to this pandemic (e.g., “Hydroxychloroquine”). Though we have
not conducted a formal linguistic analysis to conclude
that there are significant semantic differences between
words assigned to each cluster, these preliminary findings provide evidence that such a semantic difference does
exist.

B.

Death attribution by language

Using the methodology described in Sec. V B, we
aggregate country-wide infection case numbers and bin
them approximately by language, thus enabling analysis of new cases stratified by language. Because the log
word rank time series are nonstationary and the new
case number time series are not scale-independent, we
move to a percent-change based analysis of these data.
We analyze percent-change time series for the mean
log rank timeseries of the top 20 words closest to E[C2 ]
and the new case time series for each language. We esti-

3

FIG. 2. We display the mean normalized log rank timeseries of the top 20 words closest to each of E[C1 ] and E[C2 ] in dashed
curves and the single word closest to each of E[C1 ] and E[C2 ] in thin solid curves for each of the first 12 of 24 languages. The
divergent modes of dynamic behavior are consistent across most languages, with some languages (English, French, German,
and Indonesian) displaying prominently larger peaks in words closest to E[C2 ] during late January through early February
2020. Other languages, such as Korean and Tagalog, do not display this behavior.

4

FIG. 3. For the second 12 of 24 languages, we display the mean normalized log rank timeseries of the top 20 words closest
to each of E[C1 ] and E[C2 ] in dashed curves and the single word closest to each of E[C1 ] and E[C2 ] in thin solid curves. (We
display the first 12 of 24 languages in Fig. 2.)

5

FIG. 4. We display percent-change time series and associated latent log variance (volatility) time series for both mean log
rank timeseries of the top 20 words closest to E[C2 ] (blue curves) and new case number time series (red time series) for each
language. This figure presents the first 12 of 24 languages. There is a positive association between peak volatility in log rank
word usage and future peak volatility in new infection case numbers. For all languages but four (Swedish, Urdu, Finnish,
and Ukrainian), the peak-to-peak difference (P2PD) between case and log rank volatility is non-negative. The observed P2PD
empirical cumulative distribution function (cdf) is not reproduced by a simple difference-of-Poissons (Skellam) model as it
exhibits heavier tails than those generated by this model. However, it is reproduced by a Dirichlet process Poisson mixture
model. We describe this model in Sec. V in more detail.

6

FIG. 5. The second 12 of 24 percent-change and latent volatility time series for log rank (blue time series) and new case load
(red time series); we display the first 12 of 24 and provide an expanded description in Fig. 4.

7
Top 20 closest to E[C1 ] Top 20 closest to E[C2 ]
virtual
Quarantine
villain’s
quarantine
Starmer
Virus
lockdown
Corona
LIBERATE
quarantined
$24,000
pandemics
pallbearers
Fauci
Hydroxychloroquine
cases
PPE
BANG.BANG.CON
essential
corona
Covid-19
Pandemic
FANTASIA
pandemic
CRABS
infected
vol.7
asymptomatic
lockdowns
virus
Lockdown
coronavirus
TABLE I. We display the top 20 English words closest to
the centroids of C1 and C2 . The pattern of words assigned
to C1 being more specific and concerned with social distancing in particular, while words assigned to C2 are focused on
pandemics more generally, is apparent. Because we do not
perform any explicit topic modeling, some words are included in this list that do not correspond to COVID-19-related
topics. They are close to the cluster centroids just because
they display very similar intertemporal collective attention
dynamics. Though individual words may change rank, this
list is qualitatively insensitive to regeneration of clusters as
new data becomes available.

mate a latent volatility statistic for each percent-change
time series. This statistic captures the latent variance of
the time series at each point in time without destroying
information through computation of a rolling variance.
Peaks in the latent volatility statistic indicate days on
which the underlying time series exhibited large percentchanges in its value. We measure the distance between
(a) the peak latent volatility statistic of percent-change
log word rank and (b) the peak latent volatility statistic
of percent-change new cases, termed the peak-to-peak
distance (P2PD), for each language under study. P2PD
is a simple metric of the lag between fluctuations in social
media attention to the initial Coronavirus outbreak and
(usually positive) large fluctuations in new cases. P2PD
is greater than zero for all but four languages (Swedish,
Urdu, Finnish, and Ukrainian) under study.
Observed values of P2PD are partially reproduced by
a simple Poisson data generating process. We model the
days at which peak volatility of each percent-change time
series occurred as being generated by a Poisson distribution with an unknown rate parameter. P2PD is then
modeled as the number of days between the peak day
of new case volatility and the peak day of log word rank
volatility. Under this difference-of-Poissons model, P2PD
is approximately 22.57 days with a estimated SEM of
3.26 days. The observed cumulative distribution function (cdf) of P2PD data is not wholly contained within
the posterior distribution of empirical cdfs generated by
this model; the middle third of the distribution is repro-

FIG. 6. Mean distance between the peak latent volatility
of percent-change in new cases and peak latent volatility of
percent-change of closest C2 word to E[C2 ] is approximately
µ = 22.49 days, with a standard deviation of the mean given by σ ≈ 3.26 days under the difference-of-Poissons model.
This model captures the middle third of the observed P2PD
empirical cdf, but does not capture the tail behavior of this
distribution.

FIG. 7.
The observed empirical cdf of the P2PD data is
reproduced by the posterior predictive distribution of empirical cdfs of the Poisson model described in Sec. V B. The posterior mean µ of the P2PD data is displayed as a vertical
black line. The middle third of the data is reproduced by the
posterior distribution of empirical cdfs, but the tails of the
distribution are not. We display the mean posterior empirical
cdf in the red curve.

duced by this model, but the tails are not. We display
the distribution of estimated mean P2PD in Fig. 6 and
empirical cdfs generated by the posterior predictive distribution of the difference-of-Poissons model in Fig. 7.
A Dirichlet process Poisson mixture model, an alternative model that hypothesizes subpopulation heterogeneity in P2PD data, does accurately reproduce the observed

8
IV.

FIG. 8. Distribution of posterior mean P2PD under the alternative, Dirichlet process Poisson mixture model. This model
imposes regularization toward zero mean P2PD. Nonetheless,
a 2σ uncertainty interval around the posterior mean P2PD
still excludes zero.

FIG. 9. The empirical cdf of the P2PD data has high posterior probability under the Dirichlet process Poisson mixture
model. We display the mean posterior empirical cdf in the
red curve.

empirical cdf of P2PD data, as we demonstrate in Figs.
8 and 9. We discuss the specifics of this model in greater
depth in Sec. V. The estimated distribution of posterior
mean P2PD under this alternative model (18.76 ± 8.43
days) is lower and has higher variance than the estimated distribution of posterior mean (22.49 ± 3.26) under
the difference-of-Poissons model. Even though the alternative model imposes strong regularization toward zero
mean P2PD, a two-standard deviation uncertainty interval for posterior mean P2PD does not contain zero.

DISCUSSION

Analyzing the behavior of words found in a random
10% sample of all tweets between 2019-09-01 and 202003-25, we find a distinct bilateral split in dynamics of
words relating to the COVID-19 pandemic. Though we
have not performed a formal linguistic analysis, evidence
suggests that words used to describe the initial reports of
a Coronavirus outbreak in China differ semantically from
words used later to describe the worldwide fight against
the pandemic. This second cluster reflects discussion of
specific measures, such as quarantine and social distancing, currently being used to mitigate the spread of the
virus and limit casualties.
The initial spike in collective attention to the Coronavirus in mid-January 2020, subsequently followed by
a decay, is explained by the dynamics of the first cluster of words and not the second. The mean number of
days between peak volatility of percent change in firstcluster words and peak volatility of percent change in new
case numbers (P2PD) is approximately 23 days, which is
comparable to estimates of right-censored median time
delay betweeen onset of COVID-19 and death [16, 17]
and median duration of viral shedding [18]. The observed
distribution of P2PD is statistically reproduced by a simple difference-of-Poissons model when aggregating across
all languages under study.
This study is exploratory. We take care to not extrapolate from the current set of results without adequate
caution. First, we use only the top 1000 words in each
language as ranked in April 2020 when compared with
April 2019 [12]. This list of words is dynamic and may
change our results either quantitatively or qualitatively.
Second, all of our results are non-causal because we analyze the entirety of each time series (word time series and
new infection case numbers).
Associations that we find should not be taken as causal,
or even necessarily predictive, for two reasons. It is obvious that change in word usage rank on Twitter does not
cause new cases of COVID-19. Though it may be possible to use change in word usage rank to inform predictions of new case numbers, we have not performed such
forecasting ourselves and it is possible that these results
will not hold in the future. In addition, this time delay
may be applicable only to COVID-19 and not necessarily other infectious diseases. While we have attempted to
control for nonstationarity and explicit time dependence
by analyzing percent changes and their variance — and
not analyzing correlation between the nonstationary time
series of log word rank and new case numbers — this does
not mean that the association is not spurious and more
extensive analysis of this association is warranted.
While it is suggestive that mean P2PD is comparable
to estimates of time delay between COVID-19 onset and
death, we particularly hesitate to draw any conclusions
from this observation, though it should be a target of
further theoretical and empirical study. We do not have

9
subject-matter expertise in epidemiology and so will not
offer speculation on this matter.
There are several ways in which this study could be
extended, for example by continuously updating words
through time in order to test our methods’ generalizability. More importantly, the methodology can be applied to
other infectious disease outbreak data to test our hypothesis that changes in social media attention to epidemicrelated words can provide a useful signal in predicting
future new case volatility. Future studies could also use
more sophisticated clustering, similarity search or latent
volatility estimation methods [19, 20].

V.
A.

METHODS

Cluster number selection

We clustered the log word rank time series log10 r1t
using the minibatch k-means clustering (KMC) algorithm [7]. Before clustering, we normalized the time
series so that clusters would not form purely based on
the average rank of each word. The functional form
log10

1

−µ

rt
of the normalization was log10 r1t 7→
, where
σ
P
P
T
T
1
1
1
1
2
µ = T t=1 log10 rt and σ = T t=1 (log10 rt − µ)2 .
We chose the number of clusters k ∗ using the following
algorithm [21]. For each of N independent trials, we fit a
minibatch KMC model for each of k = 1, ..., 15 clusters.
For each of these clusters in each independent trial, we
recorded the average Euclidean distance of the set of all
time series from the closest cluster centroid. We denote
this error metric by `n,k . We then
. computed a ratio-

of-ratios statistic, an,k =

`n,k+1
`n,k

`n,k
`n,k−1 ,

and selected

the number of clusters as k ∗ = arg min {k − 1 : ak ≤ 1},
PN
where we have put ak = N1 n=1 an,k . We display bootstrapped single standard deviation confidence intervals
around ak in Fig. 10. This algorithm returned the number of clusters k ∗ = 6. We then collapsed the number of
clusters based on dynamic behavior. Panel (b) of Fig. 11
displays each cluster centroid.
We extracted time windows where cluster centroids
displayed increasing rates of increase followed by decreasing rates of decrease using the discrete shocklet transform
[20]. This dynamic behavior corresponds with increased
collective attention to words and topics associated with
that cluster centroid followed by decreased collective
attention. Each time window is composed of one or
more time points. To aggregate this “cusplike” behavior, we placed a Gaussian kernel around each extracted
time point and analyzed the resulting function, which we
display in panel (a) of Fig. 11 and which we denote by
S(t). We considered cluster centroids to be temporallyrelevant to our analysis of COVID-19 language dynamics
if their maxima occurred in time intervals where S(t)
was equal to at least half of its maximum. This condition was satisfied for four of the clusters during one

FIG. 10.
Mean and bootstrapped two-standard deviation
uncertainty intervals for ratio statistic used in choosing number of clusters in minibatch k-means algorithm.

time window, 2020-03-03 to 2020-04-30. The maxima of
these four clusters neatly partition into two groups. One
group has maxima that occur in late March and the other has maxima that occur in mid April. We combine
the four clusters into two aggregated clusters based on
this criterion and label the aggregate clusters C2 and C1
respectively. We display C1 and C2 in panel (c) of Fig.
11.
We used tweets authored both before and during the
COVID-19 pandemic to generate the clusters, so the centroids are relatively flat before the initial coronavirus
reports (late December 2019) and some exhibit periodic
behavior. The magnitude of the horizontal axis is lower
than in Figs. 1, 2, and 3 because here we display only the
cluster centroids, which necessarily have moderated fluctuations compared to the more extreme cluster elements
displayed in other figures.

B.

Case number attribution by language

To associate country-level case number changes with
languages, we performed a one-to-one lossy mapping
of country to dominant language spoken in that country. Using data from the Australian federal government’s
Department of Social Services, we truncated the list of
languages spoken in each country to the most prevalent
language in each country. While this mapping is crude
and eliminates subtleties of intranational language diversity (e.g., Switzerland is mapped solely to German, while
French, Italian, and Romansh are dropped), it allowed
us to reverse the direction of this mapping and assign to
each language the number of new cases equal to the sum
of new cases in each country for which the language is the
primary language. We obtained new case numbers from
the European Center for Disease Control and Prevention.

10

FIG. 11. Using the algorithm detailed in Sec. V A, we find k∗ = 6 clusters of log rank word time series during the time
period 2019-09-01 to 2020-03-25. We do not label the clusters with informative labels because clusters are unique only up to a
permutation of labels.

C.

Volatility characterization

We move to a percent-change approach in our joint
analysis of new case numbers and log rank word time
series because log rank word time series are nonstationary (they are only wide-sense stationary in our analysis because we normalize them to have intertemporal zero mean and unit variance) and new case number time series are not scale-independent. We define
t
the percent-change time series as yt ≡ log xxt−1
, where
xt ∈ {log rank word time series, new case time series}.
Instead of analyzing yt , an unbounded random variable,
we instead analyze the variance of yt , denoted st , by estimating a standard Bayesian stochastic volatility model
[22, 23]. We hypothesize that the latent log-variance st
evolves according to
st ∼ Normal(st−1 , v 2 ), s0 ∼ Normal(0, 1).

(1)

We place a weakly informative prior on the standard deviation of the increments of this process, v ∼
LogNormal(0, 1). The percent change is then modeled as
yt ∼ Normal(µ, exp(st /2)),

(2)

where we include a tight zero-centered prior for the mean
percent change, µ ∼ Normal(0, 0.01). We fit this model using stochastic variational inference with a diagonal
normal guide (variational posterior) [24]. We conduct
optimization using the Adam optimizer with a learning
rate of 0.05 and run the optimizer for a total of 1500 iterations [25]. We conduct our subsequent volatility analysis
using draws from the optimized guide distribution.
In addition to estimating the mean P2PD, we model
P2PD with a null, simple model and an alternative, more
complex model.
In the null model, we suppose that the number of days
to peak in average latent volatility in each of the percent change time series is given by Ns ∼ Poisson(λ),
where we place a weakly informative prior on the rate
parameter, λ ∼ LogNormal(0, 1). We sample from this
Poisson model for each of the percent change time series,
and then model P2PD as the difference in these Poisson rvs (known as a Skellam distribution). We use the
No U-Turn Sampler (NUTS) algorithm to sample from
the posterior [26], sampling from one chain for 500 iterations of warmup followed by 2500 iterations of sampling.
We display draws from the posterior predictive distribution of empirical cdfs in Fig. 7, along with the observed
empirical cdf of the P2PD data. This null model does not
adequately capture the shape of the empirical cumulative

11
distribution function (cdf) of the observed P2PD data.
Though it does capture the distribution of the middle
third of the observations well, the tails of the observed
P2PD are heavier than predicted by this model. In particular, the tails of the observed empirical cdf lie outside
of the distribution of posterior empirical cdfs generated
by this model.
We then move to a Dirichlet process Poisson mixture, a
more expressive alternative model. This model hypothesizes that the data are generated by a possibly-infinite
mixture of Poisson probability distributions. (More
technical definitions can be found in a variety of references Q
[27–30].) The mixture weights are drawn as
wi = βi j<i βj for each i = 1, ..., N . Each βi is drawn
independently as βi ∼ Beta(1, 1) ≡ Uniform(0, 1). Each
component Poisson distribution has rate parameter distributed independently as λi ∼ LogNormal(0, 1). We
model each component of P2PD data (peaks in new case
volatility and peaks in C2 volatility) using this model,
and then again model P2PD as the difference in these
random variables. In practice the Dirichlet process must
be truncated to a finite number of components N . We
truncate to N = 3 as there is not a substantial difference
in the distributions of empirical cdfs for N = 6, 9, 12. (We
present more details in Appendix A.) We again fit this
model using NUTS, this time sampling from one chain
for 1000 iterations of warmup followed by 2500 iterations

[1] Z. Wu and J. M. McGoogan. Characteristics of and
important lessons from the coronavirus disease 2019
(COVID-19) outbreak in China: summary of a report of
72 314 cases from the Chinese Center for Disease Control
and Prevention. Jama, 2020.
[2] Coronavirus disease 2019 (COVID-19): Situation report,
67. 2020.
[3] M. P. Cheng, J. Papenburg, M. Desjardins, S. Kanjilal,
C. Quach, M. Libman, S. Dittrich, and C. P. Yansouni.
Diagnostic testing for severe acute respiratory syndrome–
related coronavirus-2: A narrative review. Annals of
internal medicine, 2020.
[4] T. Bodnar and M. Salathé. Validating models for disease
detection using twitter. In Proceedings of the 22nd International Conference on World Wide Web, pages 699–702,
2013.
[5] L. E. Charles-Smith, T. L. Reynolds, M. A. Cameron,
M. Conway, E. H. Lau, J. M. Olsen, J. A. Pavlin,
M. Shigematsu, L. C. Streichert, K. J. Suda, et al. Using
social media for actionable disease surveillance and outbreak management: A systematic literature review. PloS
one, 10(10), 2015.
[6] M. Santillana, A. T. Nguyen, M. Dredze, M. J. Paul,
E. O. Nsoesie, and J. S. Brownstein.
Combining
search, social media, and traditional data sources to
improve influenza surveillance. PLoS computational biology, 11(10), 2015.
[7] D. Sculley. Web-scale k-means clustering. In Proceedings
of the 19th international conference on World wide web,

of sampling.
This model describes the entire empirical distribution
of observed data well, as the observed empirical cdf lies
entirely within the distribution of posterior empirical cdfs
generated by this model.
We chose the Dirichlet process Poisson mixture model
over a more conventional model of overdispersed count
data, such as a negative binomial model, because we do
not believe that the mechanistic interpretation of a negative binomial model (number of failures observed before
a given fixed number of successes) applies in the context of counting number of days from a reference date
until peak volatility. It is unclear what a “success” or
“failure” would be in this context. On the other hand,
the Poisson mixture model has a clear mechanistic interpretation: there is subpopulation heterogeneity among
languages and countries grouped by language, but within each subpopulation the number of days from reference date until peak volatility occurs with a constant
subpopulation-specific mean rate.

ACKNOWLEDGMENTS

The authors are grateful for the computing resources
provided by the Vermont Advanced Computing Core and
financial support from the Massachusetts Mutual Life
Insurance Company and Google.

pages 1177–1178, 2010.
[8] S. Wojcik, A. Bijral, R. Johnston, J. M. Lavista, G. King,
R. Kennedy, A. Vespignani, and D. Lazer. Survey Data
and Human Computation for Improved Flu Tracking.
arXiv preprint arXiv:2003.13822, 2020.
[9] V. Lampos, S. Moura, E. Yom-Tov, I. J. Cox, R. McKendry, and M. Edelstein. Tracking COVID-19 using
online search. arXiv preprint arXiv:2003.08086, 2020.
[10] E. Dong, H. Du, and L. Gardner. An interactive webbased dashboard to track COVID-19 in real time. The
Lancet infectious diseases, 2020.
[11] L. Li, Q. Zhang, X. Wang, J. Zhang, T. Wang, T.-L.
Gao, W. Duan, K. K.-f. Tsoi, and F.-Y. Wang. Characterizing the propagation of situational information in
social media during COVID-19 epidemic: A case study
on weibo. IEEE Transactions on Computational Social
Systems, 2020.
[12] T. Alshaabi, J. Minot, M. Arnold, J. L. Adams, D. R.
Dewhurst, A. J. Reagan, R. Muhamad, C. M. Danforth,
and P. S. Dodds. How the world’s collective attention
is being paid to a pandemic: COVID-19 related 1-gram
time series for 24 languages on twitter. arXiv preprint
arXiv:2003.12614, 2020.
[13] All relevant data, code, and figures will eventually be
hosted at http://compstorylab.org/covid19ngrams/.
[14] T. Alshaabi, D. R. Dewhurst, J. R. Minot, M. V. Arnold,
J. L. Adams, C. M. Danforth, and P. S. Dodds. The growing echo chamber of social media: Measuring temporal
and social contagion dynamics for over 150 languages on

12

[15]

[16]

[17]
[18]

[19]

[20]

[21]
[22]

[23]

[24]

[25]
[26]

[27]
[28]

[29]

[30]

[31]

Twitter for 2009–2020. arXiv preprint arXiv:2003.03667,
2020.
Language list by country is available at https://www.dss.
gov.au/sites/default/files/files/foi\protect disclosure\
protect log/12-12-13/language-list.pdf and new case
numbers are available at https://www.ecdc.europa.eu/
en/publications-data/.
N. M. Linton, T. Kobayashi, Y. Yang, K. Hayashi, A. R.
Akhmetzhanov, S.-m. Jung, B. Yuan, R. Kinoshita, and
H. Nishiura. Incubation period and other epidemiological
characteristics of 2019 novel coronavirus infections with
right truncation: A statistical analysis of publicly available case data. Journal of clinical medicine, 9(2):538,
2020.
Report of the who-china joint mission on coronavirus disease 2019 (COVID-19). 2020.
F. Zhou, T. Yu, R. Du, G. Fan, Y. Liu, Z. Liu, J. Xiang,
Y. Wang, B. Song, X. Gu, et al. Clinical course and risk
factors for mortality of adult inpatients with COVID19 in wuhan, china: A retrospective cohort study. The
Lancet, 2020.
G. Kastner and S. Frühwirth-Schnatter. Ancillaritysufficiency interweaving strategy (ASIS) for boosting
mcmc estimation of stochastic volatility models. Computational Statistics & Data Analysis, 76:408–423, 2014.
D. R. Dewhurst, T. Alshaabi, D. Kiley, M. V. Arnold,
J. R. Minot, C. M. Danforth, and P. S. Dodds. The shocklet transform: A decomposition method for the identification of local, mechanism-driven dynamics in sociotechnical time series. EPJ Data Science, 9(1):3, 2020.
This algorithm is a modified version of an unpublished
algorithm [31].
E. Jacquier, N. G. Polson, and P. E. Rossi. Bayesian analysis of stochastic volatility models. Journal of Business
& Economic Statistics, 20(1):69–87, 2002.
A. Gelman, J. B. Carlin, H. S. Stern, D. B. Dunson,
A. Vehtari, and D. B. Rubin. Bayesian data analysis.
CRC press, 2013.
M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley.
Stochastic variational inference. The Journal of Machine
Learning Research, 14(1):1303–1347, 2013.
D. P. Kingma and J. Ba. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.
M. D. Hoffman and A. Gelman. The No-U-Turn sampler: Adaptively setting path lengths in Hamiltonian
Monte Carlo. Journal of Machine Learning Research,
15(1):1593–1623, 2014.
J. Sethuraman. A constructive definition of dirichlet priors. Statistica sinica, pages 639–650, 1994.
R. M. Neal. Markov chain sampling methods for dirichlet
process mixture models. Journal of computational and
graphical statistics, 9(2):249–265, 2000.
Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M.
Blei. Sharing clusters among related groups: Hierarchical dirichlet processes. In Advances in neural information
processing systems, pages 1385–1392, 2005.
D. B. Dahl. Model-based clustering for expression data
via a dirichlet process mixture model. Bayesian inference
for gene expression and proteomics, 4:201–218, 2006.
Automatic selection of k in k-means clustering, Jul 2017.

S1
Appendix A: DP Poisson mixture results

The Dirichlet process Poisson mixture model is able to capture heterogeneity in the distribution of P2PD. We
display posterior distributions of empirical cdfs of Dirichlet process Poisson mixtures. We sampled from four different
realizations of this model with number of components truncated to N = 3, 6, 9, 12. We sampled from each model using
the NUTS sampler, 1000 iterations of burnin, and 2500 iterations of sampling. Changing N did not substantially
alter the fit of the models, as we display in Figs. S1 - S4. Because of this, we choose the most parsimonious of these
models and set N = 3 for analysis.

FIG. S1. Posterior distribution of empirical cdfs of the Dirichlet process Poisson model with number of components truncated
to N = 3.

S2

FIG. S2. Posterior distribution of empirical cdfs of the Dirichlet process Poisson model with number of components truncated
to N = 6.

S3

FIG. S3. Posterior distribution of empirical cdfs of the Dirichlet process Poisson model with number of components truncated
to N = 9. The region of increased density between -50 and -100 peak-to-peak time is a sampling artifact.

S4

FIG. S4. Posterior distribution of empirical cdfs of the Dirichlet process Poisson model with number of components truncated
to N = 12.

