arXiv:2004.06680v3 [q-bio.PE] 1 May 2020

Epidemic control
via stochastic optimal control
Andrew Lesniewski
Department of Mathematics
Baruch College
55 Lexington Avenue
New York, NY 10010
Draft of May 4, 2020
First draft: April 14, 2020

Abstract
We study the problem of optimal control of the stochastic SIR model. Models of this
type are used in mathematical epidemiology to capture the time evolution of highly
infectious diseases such as COVID-19. Our approach relies on reformulating the
Hamilton-Jacobi-Bellman equation as a stochastic minimum principle. This results
in a system of forward backward stochastic differential equations, which is amenable
to numerical solution via Monte Carlo simulations. We present a number of numerical
solutions of the system under a variety of scenarios.

2

A. Lesniewski

1

Introduction

The classic SIR model, originally proposed in [15], is the standard tool of mathematical
epidemiology [4] for quantitative analysis of the spread of an epidemic. It describes the
state of the affected population in terms of three state variables, traditionally denoted
by S, I, and R:
(i) 0 ≤ S ≤ 1, the fraction of individuals who are susceptible to the disease.
(ii) 0 ≤ I ≤ 1, the fraction of individuals who are infected with the disease.
(iii) 0 ≤ R ≤ 1, the fraction of individuals who have been removed and are immune
to the disease. Note that, in this simplified model, R includes the individuals
who have left the population through mortality.
The model dynamics is given as the following dynamical system:
Ṡ(t)
= −βI(t),
S(t)
˙
I(t)
= βS(t) − γ,
I(t)

(1)

Ṙ(t)
= γ,
I(t)
where the constant parameters β > 0 and γ > 0 are called the infection rate and
recovery rate, respectively. The evolution above is subject to the initial conditions:
S(0) = S0 ,
I(0) = I0 ,

(2)

R(0) = 1 − S0 − I0 .
Notice that this dynamics obeys the conservation law
S(t) + I(t) + R(t) = 1,

(3)

consistent with the assumption that the variables S, I, and R represent population fractions. This means that the variable R is, in a way, redundant, as its current value does
not affect the dynamics of S and I, and it can be computed in a straightforward manner
from (3). It is thus natural to consider the two dimensional system defined by S, I only.
Eventually every epidemic comes to a natural halt1 , but its impact on the population
may be very serious. The overall objective of epidemic control is to slow down the
spread of infection in a way that it does not overwhelm the healthcare system and
it allows the economy to function. All of this should be done within the limits of
available resources.
1 In the SIR model (1) this is reflected by the fact that the solution (S(t), I(t)) = (0, 0) is globally
asymptotically stable.

Optimal control of an epidemic

3

In this note we study the problem of optimal control of an epidemic modeled by
means of a stochastic extension of the SIR model (see Section 2 for definition). We
assume that the controlling agent (“government”) has the ability to impact the spread
of the disease through one of the policies (or the combination of both):
(i) Vaccination of susceptible individuals, with rate v. This makes the fraction vS
of the susceptible population immune to the disease.
(ii) Isolation of infected individuals, with rate i. This removes the fraction iI of the
infected population and prevents it from spreading the disease.
The controlled dynamics of the SIR model reads [1], [13]:
Ṡ(t)
= −βI(t) − v(t),
S(t)
˙
I(t)
= βS(t) − γ − i(t),
I(t)

(4)

Ṙ(t) = v(t)S(t) + (γ + i(t))I(t).
For efficiency, we will be using the notation X1 = S and X2 = I throughout the
remainder of the paper.
Mathematical models are only as good as (i) their analytic specifications, and (ii)
the data that fuel them. During initial phases of an epidemic the available data tend
to be of limited usefulness: because of the lack of reliable large scale testing, it is
not really known what fractions of the population fall into the different compartments
S, I, and R. This may lead to a panic reaction of the population and a chaotic and
economically devastating public health response to the epidemic. In the absence of
an effective vaccine (which would allow to immunize a portion of the population) the
optimal policy is to isolate at least a significant fraction of the infected individuals so
that the basic reproduction ratio R0 can be brought significantly below one. Since we
lack the knowledge who is infected and who is not, the public health response is to try
to isolate everyone, whether susceptible, infected or immune.
These circumstances impose a serious limitation on practical applicability of the
approach to optimal epidemic control discussed in this paper, as well as other quantitative approaches. Unless the inputs to the model (β, γ, and the current snapshots
of S and I) can reliably be estimated from the available data, the model’s output is
unreliable2 .
The paper is organized as follows. In Section 2 we review the formulation of the
continuous time stochastic SIR model. The optimal control problem for the stochastic SIR model is formulated in Section 3. The optimal control problem is recast as
the stochastic minimum principle problem and formulated in terms of a system of forward backward stochastic differential equations (FBSDE). We present an algorithm for
solving this system in Section 5. This section presents also the results of a number
2 “This is indeed a mystery,” Watson remarked. “What do you imagine that it means?”
“I have no data yet,” Holmes replied. “It is a capital mistake to theorise before one has data. Insensibly one
begins to twist facts to suit theories, instead of theories to suit facts.” [8]

4

A. Lesniewski

of numerical experiments involving the three mitigation policies within various cost
function regimes.
Acknowledgement. I would like to thank Nicholas Lesniewski for numerous discussions.

2

Stochastic SIR model

We consider a continuous time stochastic extension of the deterministic SIR model,
see [3] and references therein. Let Wt denote the standard Brownian motion, and let
Ẇt denote the white noise process. We assume that the infection rate β is subject to
random shocks, rather than being constant, namely
βt = β + σ Ẇt ,

(5)

while the recovery rate γ remains constant. Here σ > 0 is a constant volatility parameter. This leads to the following system of stochastic differential equations (SDE),
driven by Wt
dX1,t
= −βX2,t dt − σX2,t dWt ,
X1,t
dX2,t
= (βX1,t − γ)dt + σX1,t dWt ,
X2,t

(6)

with the initial conditions
X1,0 = S0 ,

(7)

X2,0 = I0 .
The third component of the process, X3 = R, follows the dynamics
dX3,t
= γdt,
X2,t

(8)

which implies that the conservation law
Xt + Yt + Zt = 1

(9)

continues to hold in the stochastic model.
Notice that, under the stochastic SIR model (6), an epidemic eventually comes to
a natural end. More precisely, the solution (X1,t , X2,t ) = (0, 0) to (6) is stable in
probability [16]. In order to see it, we set
Vρ (X1 , X2 ) = β(X1 + X2 ) − γ log(1 + ρX1 ),

(10)

for 0 ≤ Xi ≤ 1, i = 1, 2, and fixed 0 < ρ < β/γ. Then Vρ (0, 0) = 0, and
Vρ (X1 , X2 ) > 0 in a neighborhood of (0.0). Furthermore, denoting by L the generator
of the process(6), we verify that
LVρ (X1 , X2 ) = −βγ
≤ 0.

I
ρX1 + 1

−

γσρ2
X1 X2
2 (1 + ρX1 )2

(11)

Optimal control of an epidemic

5

In other words, Vρ (X1 , X2 ) is a Lyapunov function for (6) and our claim follows from
Theorem 5.3 in [16].
The model (6) is a one factor model, driven by a single source of randomness.
There is a natural two-factor version of the stochastic SIR model [18], in which also
the recovery rate γ is allowed to be subject to white noise shocks. For simplicity, our
analysis will focus on the one-factor model (6).

3

HJB equation

We frame the problem of epidemic control as a stochastic control problem [2]. We
denote by u = (u1 , u2 ) ≡ (v, i) the vaccination and isolation controls, and we denote
the controlled process by Xtu . Generalizing the deterministic specification (4) to the
stochastic case, we assume that the dynamics of Xtu is given by:
u
dX1,t
u
u
= −(βX2,t
+ u1,t )dt − σX2,t
dWt ,
u
X1,t
u
dX2,t
u
u
= (βX1,t
− γ − u2,t )dt + σX1,t
dWt ,
u
X2,t

(12)

subject to initial conditions (7).
Two special cases of the controlled process are of interest. If a vaccine against the
disease is unavailable, we set u1 = 0 in the equation above, which yields the following
controlled process:
u
dX1,t
u
u
= −βX2,t
dt − σX2,t
dWt ,
u
X1,t
u
dX2,t
u
u
= (βX1,t
− γ − u2,t )dt + σX1,t
dWt .
u
X2,t

(13)

We will refer to this policy as an isolation policy.
Similarly, we can consider a vaccination policy, for which u2 = 0. In this case the
controlled dynamics reads
u
dX1,t
u
u
= −(βX2,t
+ u1,t )dt − σX2,t
dWt ,
u
X1,t
u
dX2,t
u
u
= (βX1,t
− γ)dt + σX1,t
dWt .
u
X2,t

(14)

We assume a finite time horizon T < ∞. The controlling agent’s objective is to
minimize a running cost function c(Xt , ut ) and the terminal value function G(XT ). In
other words, we are seeking a policy u∗ such that
∗

u = arg min E
u

Z
0

T


c(Xtu , ut )dt + G(XT ) .

(15)

6

A. Lesniewski

We consider the following cost function:
c(x, u) = c1 (x1 , u1 ) + c2 (x2 , u2 ),

(16)

where


1
Li u2i + Mi ui + Ni xi ,
(17)
2
for i = 1, 2. In other words, the running cost of vaccination is assumed to be proportional to the number of susceptible individuals, while the cost of isolation is assumed to
be proportional to the number of infected individuals. The coefficients Li > 0, Mi , Ni
are determined by the overall cost of following the mitigation policy. In particular, they
should be selected so that the running cost functions are strictly positive.
As the terminal value function we take the transmission rate of the infection [13],
namely
G(x) = βx1 x2 .
(18)
ci (xi , ui ) =

We now invoke stochastic dynamic programming, see eg. [10], [21]. The key
element of this approach is the value function J(t, x, y). It is determined by two requirements:
(B1) It satisfies Bellman’s principle of optimality,

J(t, Xt ) = min Et J(t + dt, Xt+dt ) + c(Xt , ut )dt ,
u

(19)

for all 0 ≤ t < T , where Et denotes conditional expectation with respect to the
information set at time t, and where the minimum is taken over all admissible
controls ut , [10].
(B2) It satisfies the terminal condition,
J(T, XT ) = G(XT ).

(20)

Using Ito’s lemma, we verify that these two conditions lead to the following nonlinear partial differential equation for the value function, namely the stochastic HamiltonJacobi-Bellman equation:
n
J˙ + min − x1 (βx2 + u1 )Jx1 + (βx1 − γ − u2 )x2 Jx2
u
(21)
o

1 2 2 2
+ σ x1 x2 Jx1 x1 + Jx1 x2 − 2Jx1 x2 + c(x, u) = 0,
2
subject to the terminal condition
J(T, x) = G(x).

(22)

As the first step towards solving the HJB equation (21), we let u = u∗ denote the
minimizer of the expression inside the curly parentheses in (21). In other words, u∗
satisfies
−xi Jxi + (Li ui + Mi )xi = 0,

Optimal control of an epidemic

7

which leads to the following first order condition on u∗ :
u∗i =

1
(Jxi − Mi ).
Li

(23)

Substituting u∗ back to the HJB equation yields the equation

1
J˙ − βx1 x2 Jx1 + (βx1 − γ)x2 Jx2 + σ 2 x21 x22 Jx1 x1 + Jx1 x2 − 2Jx1 x2
2
(Jx1 − M1 )2 
(Jx2 − M2 )2 
N1 −
x 1 + N2 −
x1 = 0.
2L1
2L2

(24)

We do not believe that the solution to this equation can be explicitly represented in
terms of standard functions. This is a three dimensional partial differential equation,
and solving it numerically may pose challenges. Rather than following this path, we
shall invoke the stochastic minimum principle and reformulate the problem as a system
of FBSDEs. Among the advantages of this approach is that it might be amenable to a
deep learning approach via the method advocated in [14].

4

Stochastic minimum principle

The stochastic minimum principle, see [21] and references therein, offers an alternative approach to stochastic optimal control. It is a stochastic version of Pontryagin’s
minimum principle introduced in the context of deterministic optimal control [22]. It
also offers an effective numerical methodology to solving the HJB equation (24) via
Monte Carlo simulations. In this approach, the key object is the Hamiltonian function
H = H(x, u, y, z) of four arguments and a system of stochastic differential equations,
both forward and backward, determined by H.
Specifically, for the case of the controlled stochastic SIR model (14), we have
x, u, y, z ∈ R2 , and the Hamiltonian function reads:
H(x, u, y, z) = − x1 (βx2 + u1 )y1 + (βx1 − γ − u2 )x2 y2
+ σx1 x2 (z2 − z1 ) + c(x, u).

(25)

We consider the following system of stochastic Hamilton’s equations:
dXt = ∇y H(Xt , ut , Yt , Zt )dt + σ(Xt )dWt ,
 
S0
X0 =
,
I0

(26)

and
−dYt = ∇x H(Xt , ut , Yt , Zt )dt − Zt dWt ,
YT = ∇x G(XT ),
where


σ(Xt ) = σX1,t X2,t


−1
.
1

(27)

(28)

8

A. Lesniewski

Equation (26) is merely an alternative way of writing the underlying controlled diffusion process (14), while equation (27) reflects the dynamics of the control variables
given the running cost function. Note that while the first of the equations (26) is a
standard (forward) SDE, the second one is a backward stochastic differential equation
(BSDE), see e.g. [9].
Explicitly, these four equations can be stated as
dX1,t = −X1,t (βX2,t + u1,t )dt − σX1,t X2,t dWt ,
dX2,t = (βX1,t − γ − u2,t )X2,t dt + σX1,t X2,t dWt ,
−dY1,t = β(Y2,t − Y1,t ) + σ(Z2,t − Z1,t ))X2,t − u1,t Y1,t

+ cx1 (Xt , ut ) dt − Z1,t dWt ,

−dY2,t = β(Y2,t − Y1,t ) + σ(Z2,t − Z1,t ) X1,t − (γ + u2,t )Y2,t

+ cx2 (Xt , ut ) dt − Z2,t dWt ,

(29)

subject to the boundary conditions in (26).
∗
Let now choose u∗ to be the policy such that Xt∗ ≡ Xtu is a solution to (29) and
H(Xt∗ , u∗t , Yt∗ , Zt∗ ) = min H(Xtu , ut , Ytu , Ztu ),
u

(30)

Then u∗ is an optimal control, i.e. it satisfies the optimality condition (15).
In fact, there is a direct link between the Hamilton function H and the value function J (also known in classical dynamics as the action function). Namely, we set [21],
[23]:
Z t
J(t, Xt ) =
YsT dXs − H(Xs , us , Ys , Zs )ds.
(31)
0
∗

∗

If u is an optimal control and X denotes the corresponding optimal diffusion process,
then the pair
Yt = ∇x J(t, Xt∗ ),
Zt = ∇2x J(t, Xt∗ ) σ(Xt∗ )

(32)

is the solution to the BSDE (27).
Going back to the main line of reasoning, we find that u∗ has to satisfy
u∗i =

yi − Mi
.
Li

(33)

From equations (32) we see that, up to a simple linear transformation, Yt is essentially
the optimal policy. Furthermore, the process Zt can be thought of as the sensitivity
of the optimal policy to the underlying process Xt (multiplied by the instantaneous
volatility of that process).
Substituting this expression into (29), we find that the optimal process has to follow

Optimal control of an epidemic

9

the dynamics:

1
∗
∗
∗
(Y1,t
− M1 ) dt − σX1,t
X2,t
dWt ,
L1
 ∗
1
∗
∗
∗
= βX1,t
−γ−
(Y ∗ − M2 ) X2,t
dt + σX1,t
X2,t
dWt ,
L2 2,t
∗
∗
∗
∗
∗
= β(Y2,t
− Y1,t
) + σ(Z2,t
− Z1,t
))X2,t
dt

1
∗
∗
(Y1,t
− M1 )2 dt − Z1,t
dWt ,
+ N1 −
2L1

∗
∗
∗
∗
∗
= β(Y2,t
− Y1,t
) + σ(Z2,t
− Z1,t
) X1,t
dt

1
∗
∗
∗
+ − γY2,t
+ N2 −
(Y2,t
− M2 )2 dt − Z2,t
dWt ,
2L2

∗
∗
∗
dX1,t
= −X1,t
βX2,t
+
∗
dX2,t
∗
−dY1,t

∗
−dY2,t

(34)

subject to the boundary conditions in (26) and (27). In particular, the isolation only and
vaccination only policies are given by the following systems of FBSDEs:
∗
∗
∗
∗
∗
dX1,t
= −βX1,t
X2,t
dt − σX1,t
X2,t
dWt ,
 ∗
1
∗
∗
∗
∗
∗
(Y2,t
− M2 ) X2,t
dt + σX1,t
X2,t
dWt ,
dX2,t
= βX1,t
−γ−
L2
∗
∗
∗
∗
∗
∗
∗
−dY1,t
= β(Y2,t
− Y1,t
) + σ(Z2,t
− Z1,t
))X2,t
dt − Z1,t
dWt ,

∗
∗
∗
∗
∗
∗
−dY2,t = β(Y2,t − Y1,t ) + σ(Z2,t − Z1,t ) X1,t dt

1
∗
∗
∗
+ − γY2,t
+ N2 −
(Y2,t
− M2 )2 dt − Z2,t
dWt ,
2L2

(35)

and

1
∗
∗
∗
∗
∗
∗
(Y1,t
− M1 ) dt − σX1,t
X2,t
dWt ,
dX1,t
= −X1,t
βX2,t
+
L1
 ∗
∗
∗
∗
∗
dX2,t
= βX1,t
− γ X2,t
dt + σX1,t
X2,t
dWt ,
∗
∗
∗
∗
∗
∗
−dY1,t
= β(Y2,t
− Y1,t
) + σ(Z2,t
− Z1,t
))X2,t
dt

1
∗
∗
+ N1 −
(Y1,t
− M1 )2 dt − Z1,t
dWt ,
2L1

∗
∗
∗
∗
∗
∗
∗
∗
−dY2,t
= β(Y2,t
− Y1,t
) + σ(Z2,t
− Z1,t
) X1,t
dt − γY2,t
dt − Z2,t
dWt ,

(36)

respectively.
Even though derived in the context of a meaningful underlying dynamics, there
is no a priori reason why these equations should have solutions. The drivers of the
backward equations above contain terms quadratic in Y , and so the standard existence
theorems [9] do not apply. We proceed in the following assuming that these systems
do, in fact, have solutions.

5

Numerical solution

In this section we discuss a numerical algorithm for solving the system (34). Applying this methodology in a number of numerical experiments, we present compelling

10

A. Lesniewski

evidence that solutions to (34) exist and are meaningful over a wide range of model
parameters.

5.1

Simulating the optimal FBSDE

We start by describing a method for discretization of the basic FBSDE system (34).
We notice first that the two dimensional system defined by the state variables S, I is in
fact Hamiltonian [17]. Namely, we define new (canonical) variables
q = − log S,
p = − log I,

(37)

and set3
H(p, q) = −βe−p − γq − βe−q .

(38)

It is easy to verify that
d
H = 0,
(39)
dt
under the dynamics (1). The system (1) can be explicitly written in the Hamilton form
∂H
,
∂q
∂H
.
q̇ =
∂p

ṗ = −

(40)

Notice also that the Hamiltonian function is separable, i.e. it is of the form H(p, q) =
T (p) + V (q)4 .
A convenient discretization to (6) can be formulated in terms of the canonical variables (pt , qt ) = (− log X2,t , − log X1,t ) as follows [18]. Choose the number of steps
n, define the time step δ = T /n, set tn = nδ for n = 0, 1, . . . , n, and use simplified
(pn , qn ) ≡ (ptn , qtn ). This yields the following Euler scheme:
1 2 −2pn
σ δe
,
2
(41)
1
pn+1 = pn + γδ − (βδ + σ∆Wn )e−qn + σ 2 δe−2qn ,
2
for n = 0, 1, . . . , n − 1. Here, the Brownian motion increments ∆W = W(n+1)δ −
Wnδ are independent variates drawn from the normal distribution N (0, δ). At each
iteration step also have to to floor qn+1 and pn+1 at 0, qn+1 = max(qn+1 , 0), pn+1 =
max(pn+1 , 0), so that e−qn , e−pn ≤ 1.
Approximating the backward equations of the system (34) leads to the following
backward Euler scheme:
qn+1 = qn + (βδ + σ∆Wn )e−pn +

Y1,n = Y1,n+1 + f1 (Xn , Yn , Zn )δ − Z1,n ∆Wn ,
Y2,n = Y2,n+1 + f2 (Xn , Yn , Zn )δ − Z2,n ∆Wn ,
3 Note

(42)

that the Lyapunov function V of Section 2 is the negative of a regularized version of H.

4 There is a practical dimension to these theoretical observations The fact that the SIR model is a Hamilto-

nian allows us to solve it numerically by means of the extremely efficient Störmer-Verlet method [12], [17].
We will not make use of this method, as it does not seem to directly extend to the stochastic case

Optimal control of an epidemic

11

where
1
(y1 − M1 )2 ,
2L1
1
(y2 − M2 )2
f2 (x, y, z) = β(y2 − y1 ) + σ(z2 − z1 ))x1 − γy2 + N2 −
2L2

f1 (x, y, z) = β(y2 − y1 ) + σ(z2 − z1 ))x2 + N1 −

(43)

denote the generators of the two BSDEs. Starting with the terminal condition
Yn = ∇G(Xn ),

(44)

we will move backward in time with computing Yn and Zn , for n = n − 1, . . . , 0.
Notice that two difficulties arise while doing so: (i) the Yn ’s in (42) are not necessarily adapted, and (ii) they depend on Zn . These two problems can be solved by
taking conditional expectations En ( · ) = E( · | X0 , X1 , . . . , Xn ) on time tn . This leads
to the following condition:
Yi,n = En (Yi,n )
= En (Yi,n+1 ) + fi (Xn , Yn , Zn )δ.
This is an implicit scheme, which may slow down the computations. However, we can
easily replace it with an explicit scheme of the same order:

Yi,n = En Yi,n+1 + fi (Xn , Yi,n+1 , Zn )δ .
In order to determine Zi,n , i = 1, 2, we multiply (42) by an increment ∆Wn and
take conditional expectations. This yields
0 = En (Yi,n ∆Wn )
= En (Yi,n+1 ∆Wn ) − Zi,n δ,
and hence we obtain the following expression for Zi,n :
Zi,n =

1
En (Yi,n+1 ∆Wn ).
δ

In summary, we are led to the following discrete time scheme for solving (42):
Yn = ∇G(Xn ),
1
Zi,n = En (Yi,n+1 ∆Wn ),
δ

Yi,n = En Yi,n+1 + fi (Xn , Yn+1 , Zn )δ ,

(45)

for n = n − 1, . . . , 0. Note that simulating this system requires numerical estimation
of the conditional expected values En ( · ) in the formulas above. We discuss this issue
in the following section.

12

5.2

A. Lesniewski

Computing the conditional expectations

A practical and powerful method of computing the conditional expected values in (45)
is the Longstaff-Schwartz regression method originally developed for modeling American options [20]. We use a variant of this method that involves the Hermite polynomials, and that was used for a similar purpose in [19]. This choice is natural, as
conditional expectations of Hermite polynomials of a Gaussian random variable lead
to simple closed form expressions.
Let Hek (x), k = 0, 1, . . ., denote the k-th normalized Hermite polynomial cor2
responding to the standard Gaussian measure dµ(x) = (2π)−1/2e−x /2 dx. These
functions form an orthonormal basis for the Hilbert space L2 R, dµ .
The key property of Hek (x) is the following addition formula for χ ∈ [0, 1] and
w, x ∈ R:
k  1/2
X
p
k
√
χj/2 (1 − χ)(k−j)/2 Hej (w)Hek−j (x). (46)
Hek ( χw + 1 − χx) =
j
j=0
Consequently, integrating over x with respect to to the measure µ yields the following
conditioning rule:
p

√
E Hek ( χw + 1 − χx) | w = χk/2 Hek (w).
(47)
Here, w, x are independent standard normal random variables. We shall use this relation in order to estimate
√ the conditional expected values in (45).
We set Wti = ti wi , for i = 1, . . . , m, where wi is an n-dimensional standard
normal random variable. We notice that
p
√
wi+1 = χi wi + 1 − χi Xi ,
(48)
where χi = ti /ti+1 , and where Xi is standard normal and independent of wi . In the
following, we shall use this decomposition in conjunction with (47).
Now, we assume the following linear architecture:
Yi+1 =

K
X

gk,i+1 Hek (wi+1 ),

(49)

k=0

where K is the cutoff value of the order of the Hermite polynomials. This is simply
a truncated expansion of the random variable Yi+1 in terms of the orthonormal basis
Hek (wi+1 ). The values of the Fourier coefficients are estimated by means of ordinary
least square regression. Then, as a consequence of the conditioning rule (47),
Ei (Yi+1 ) =

K
X

k/2

gk,i+1 χi

Hek (wi ).

(50)

k=0

In other words, conditioning Yi+1 on wi is equivalent to multiplying its Fourier coeffik/2
cients gk by the factor χi . This allows us to calculate the first term on the right hand
side of the third equation in (45). In order to calculate the second term, we substitute
the explicit formula for Zn into the generators (43) and repeat the calculations in (49)
and (50) with Yn+1 replaced by Yn+1 + f (Xn , Yn , Zn )δ.

Optimal control of an epidemic

5.3

13

Numerical experiments

For numerical experiments within the framework developed above, we assume a time
horizon of 1 year (365 days), and choose the SIR model parameters as follows:
β = 38.0,
γ = 11.5,

(51)

S0 = 0.999,
I0 = 0.001,

These parameters are purely hypothetical, and they do not arise from the calibration
to any actually reported data. The corresponding value of the basic reproduction ratio
R0 = S0 β/γ is 3.30 and it indicates a highly infectious disease such as COVID-19.
We choose the diffusion parameter
σ = 3.1.

(52)

A typical scenario generated by this model is graphed in Figure 1.

0.5

0.8

0.4

0.6

0.3

0.4

0.2

0.2

0.1

Infected

Susceptible

Simulated path of (Susceptible, Infected)
1.0

0.0

0.0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 1: A single Monte Carlo path of the raw process (6).
For solving the FBSDE system (34) we generate 2, 000 scenarios (Monte Carlo
paths) using the low variance spectral decomposition method. Each scenario is based
on daily sampling, i.e. n = 365. For calculating the conditional expectations in the
Longstaff-Schwartz regression we use the cutoff value of K = 4. The expectation
behind this choice is that we obtain the accuracy of four sigma.
We attempt to construct a numerical solution to (34) through the following iterative
(0)
procedure. We start by generating initial Monte Carlo paths Xt using the (discretized
(0)
(0)
version of the) raw process (6). For the initial guess of Yt we take Yt = ∇G(Xt ).

14

A. Lesniewski

Notice that this is not at solution to the backward equations in (34), it merely satisfies
the terminal condition. After this, we iterate
(k+1)

Xt

(k+1)
Yt

(k)

= solution of the discretized forward equation with Yt = Yt
= solution of the discretized backward equation with Xt =

,

(53)

(k+1)
Xt
,

for k = 0, 1, . . ., until the stopping criterion is satisfied or the maximum number of
iterations is reached. For the stopping criterion we choose the condition that the average
L2 -norm change of a Monte Carlo path falls below a tolerance threshold of 10−8 .
We make various choices of the coefficients L, M, N defining the running cost
functions. Depending on the values of these coefficients, the iterative process described
above converges to a meaningful solution or it diverges. At this point, it is unclear
what choices of the coefficients lead to what outcomes, but it appears that there are
well defined basins of convergence in the space of the parameters.
We first consider a high cost policy. Figures 2 - 5 show the graphs of the solutions
assuming the following parameters of the quadratic polynomial in the running cost
function c2 (u2 , x2 ):
L2 = 1.0,
M2 = 0.0,

(54)

N2 = 120.0.
Unlike Figure 1, the curves in all graphs below show the averages of the corresponding
quantities over 2,000 Monte Carlo paths.

(Susceptible, Infected) for the optimal isolation policy
1.0
0.25

0.20

0.6

0.15

0.4

0.10

Infected

Susceptible

0.8

0.05

0.2

0.00
0.0

0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 2: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the isolation
policy assuming high cost running cost function. The read and green lines are the average values
of the raw Susceptible (primary axis) and Infected (secondary axis) fractions, respectively, while
the yellow and blue lines represent the averages of the corresponding optimal values.

Optimal control of an epidemic

15

Y1 and Z1 for the optimal isolation policy
0.5

0.07

0.06
0.4
0.05
0.3

Y

Z

0.04

0.03

0.2

0.02
0.1
0.01

0.0

0.00
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 3: Plot of Y1,t (primary axis) and Z1,t (secondary axis) for equation (35).

Y2 and Z2 for the optimal isolation policy

65

300

250

60

200
55

Y

Z

150

50

100

50
45
0

40

50

0.0

0.2

0.4

Time

0.6

0.8

Figure 4: Plot of Y2,t (primary axis) and Z2,t (secondary axis) for equation (35).

1.0

16

A. Lesniewski

Optimal isolation policy vs Infected

65

0.0010

60
0.0008

55

Optimal u

Infected

0.0006

50
0.0004

45
0.0002

40
0.0000
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 5: Plot of the Infected fraction (primary axis) versus the optimal isolation policy (secondary axis) under high cost running cost function.

Under this running cost function, the optimal policy is to implement a draconian
isolation regime, which leads to a rapid drop in infections, while keeping the susceptible fraction of the population at a very high level.
On the other hand, Figures 6 - 9 show the plots of the solutions assuming a low cost
policy, with the following parameters of the quadratic polynomial in the running cost
function c2 (u2 , x2 ):

L2 = 5.0,
M2 = 0.0,

(55)

N2 = 10.0.

Under this running cost function, the optimal policy is a moderate isolation regime.
Following this policy, the isolation rate is high, as the infections are low, and then it
declines over time while the epidemic develops. Unlike the policy above, this leads to
a gradual decline in both the infected and susceptible fractions of the population.

Optimal control of an epidemic

17

(Susceptible, Infected) for the optimal isolation policy
1.0
0.25

0.20

0.6

0.15

0.4

0.10

Infected

Susceptible

0.8

0.05

0.2

0.00
0.0

0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 6: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the isolation
policy assuming low cost running cost function. The read and green lines are the average values
of the raw Susceptible (primary axis) and Infected (secondary axis) fractions, respectively, while
the yellow and blue lines represent the averages of the corresponding optimal values.

Y1 and Z1 for the optimal isolation policy
1.0
1.0
0.8
0.5

Y

Z

0.6
0.0
0.4
0.5
0.2
1.0
0.0

0.2

0.4

Time

0.6

0.8

Figure 7: Plot of Y1,t (primary axis) and Z1,t (secondary axis) for equation (35).

1.0

18

A. Lesniewski

Y2 and Z2 for the optimal isolation policy
100
20
80

15

Y

Z

60

40

10

20
5
0

0

0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 8: Plot of Y2,t (primary axis) and Z2,t (secondary axis) for equation (35).

Optimal isolation policy vs Infected
0.25
4

0.20

Optimal u

Infected

3
0.15

2

0.10

0.05

1

0.00
0.0

0.2

0.4

Time

0.6

0.8

1.0

0

Figure 9: Plot of the Infected fraction (primary axis) versus the optimal isolation policy (secondary axis) under low cost running cost function.

Consider now the case of an optimal vaccination strategy. Again, we make two
choices of the running cost function: high cost and low cost.
For the high cost case we choose the parameters as follows:
L1 = 10.0,
M1 = 0.0,
N1 = 500.0.

(56)

Optimal control of an epidemic

19

The results of Monte Carlo simulations for this cost function are plotted in Figures 10
- 13. They parallel the results presented above in the case of high cost isolation mitigation. The optimal policy is a massive vaccination campaign that dramatically reduces
the susceptible fraction of the population and leads to significantly lower infections.

(Susceptible, Infected) for the optimal vaccination policy
1.0

0.25

0.20

0.6

0.15

Infected

Susceptible

0.8

0.4

0.10

0.2

0.05

0.00

0.0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 10: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the vaccination policy assuming high cost running cost function. The read and green lines are the average
values of the raw Susceptible (primary axis) and Infected (secondary axis) fractions, respectively,
while the yellow and blue lines represent the averages of the corresponding optimal values.

Y1, Z1 for the optimal vaccination policy

400

100

300
80

200

100

Y

0

40

Z

60

100

200
20
300

400

0
0.0

0.2

0.4

Time

0.6

0.8

Figure 11: Plot of Y1,t (primary axis) and Z1,t (secondary axis) for equation (36).

1.0

20

A. Lesniewski

Y2, Z2 for the optimal vaccination policy
0

0

200
2000

4000

600

Z

Y

400

800

6000

1000
8000
1200

0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 12: Plot of Y2,t (primary axis) and Z2,t (secondary axis) for equation (36).

10

0.8

8

0.6

6

0.4

4

0.2

2

Optimal u

Susceptible

Optimal vaccination policy vs Susceptible
1.0

0

0.0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 13: Plot of the Infected fraction (primary axis) versus the optimal vaccination policy
(secondary axis) under high cost running cost function.

The low cost running cost function is parameterized as follows:
L2 = 0.01,
M2 = 0.0,

(57)

N2 = 0.4.
The results of Monte Carlo simulations for this cost function are plotted in Figures 14
- 17.

Optimal control of an epidemic

21

(Susceptible, Infected) for the optimal vaccination policy
1.0
0.25

0.8

0.6

0.15

Infected

Susceptible

0.20

0.4

0.10

0.2

0.05

0.00

0.0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 14: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the vaccination policy assuming low cost running cost function. The read and green lines are the average
values of the raw Susceptible (primary axis) and Infected (secondary axis) fractions, respectively,
while the yellow and blue lines represent the averages of the corresponding optimal values.

Y1, Z1 for the optimal vaccination policy
0.10

0.08

0.05
0.06

Y

Z

0.00
0.04

0.05
0.02
0.10

0.00
0.0

0.2

0.4

Time

0.6

0.8

Figure 15: Plot of Y1,t (primary axis) and Z1,t (secondary axis) for equation (36).

1.0

22

A. Lesniewski

Y2, Z2 for the optimal vaccination policy
0

0.0

0.2
2
0.4
4

Y

Z

0.6

0.8

6

1.0
8
1.2

10

1.4
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 16: Plot of Y2,t (primary axis) and Z2,t (secondary axis) for equation (36).

Optimal vaccination policy vs Susceptible
1.0
8
0.8

Optimal u

Susceptible

6
0.6

4

0.4

2

0.2

0

0.0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 17: Plot of the Infected fraction (primary axis) versus the optimal vaccination policy
(secondary axis) under low cost running cost function.

Finally, we consider the case of the vaccination / isolation policy. An example of a

Optimal control of an epidemic

23

cost running cost function is given by the following parameter values:

L1 = 1.0,
M1 = 0.0,
N1 = 500.0,

(58)

L2 = 5.0,
M2 = 0.0,
N2 = 555.0.

The results of Monte Carlo simulations are plotted in Figures 18 - 21.

(Susceptible, Infected) for the optimal vaccination / isolation policy
1.0
0.25

0.8

0.6

0.15

Infected

Susceptible

0.20

0.4

0.10

0.2

0.05

0.0

0.00
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 18: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the vaccination / isolation policy assuming high cost running cost function. The read and green lines are
the average values of the raw Susceptible (primary axis) and Infected (secondary axis) fractions,
respectively, while the yellow and blue lines represent the averages of the corresponding optimal
values.

24

A. Lesniewski

Optimal vaccination / isolation policy vs Susceptible
1.0
30

25

20

0.6

Optimal u

Susceptible

0.8

15
0.4

10
0.2
5

0.0

0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 19: Optimal isolation (green line) and vaccination (blue line) policies (secondary axis)
versus the Susceptible (red line) fraction (primary axis) for the high cost running cost function.

Optimal vaccination / isolation policy vs Infected
0.0012

30

25

0.0008

20

0.0006

15

0.0004

10

0.0002

5

Optimal u

Infected

0.0010

0

0.0000
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 20: Optimal isolation (green line) and vaccination (blue line) policies (secondary axis)
versus the Infected (red line) fraction (primary axis) for the high cost running cost function.

Optimal control of an epidemic

25

Optimal vaccination policy vs isolation policy
8

Isolation rate

6

4

2

0
0

5

10

15

Vaccination rate

20

25

30

Figure 21: Plot of the optimal isolation policy versus optimal vaccination policy under high
cost running cost function.

A low cost running cost function is given by the following set of coefficients:

L1 = 0.1,
M1 = 0.0,
N1 = 50.0,
L2 = 3.0,
M2 = 0.0,
N2 = 35.0.

The results of Monte Carlo simulations are plotted in Figures 22 - 25.

(59)

26

A. Lesniewski

(Susceptible, Infected) for the optimal vaccination / isolation policy
1.0
0.25

0.8

0.6

0.15

Infected

Susceptible

0.20

0.4

0.10

0.2

0.05

0.0

0.00
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 22: Raw (Susceptible, Infected) versus optimal (Susceptible, Infected) under the vaccination / isolation policy assuming low cost running cost function. The read and green lines are
the average values of the raw Susceptible (primary axis) and Infected (secondary axis) fractions,
respectively, while the yellow and blue lines represent the averages of the corresponding optimal
values.

Optimal vaccination / isolation policy vs Susceptible
1.0
30

25

20

0.6

Optimal u

Susceptible

0.8

15
0.4

10
0.2
5

0.0

0
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 23: Optimal isolation (green line) and vaccination (blue line) policies (secondary axis)
versus the Susceptible (red line) fraction (primary axis) for the low cost running cost function.

Optimal control of an epidemic

27

Optimal vaccination / isolation policy vs Infected

0.0016

30

0.0014

25

0.0012

20

Optimal u

Infected

0.0010

0.0008

15
0.0006

10
0.0004
5

0.0002

0

0.0000
0.0

0.2

0.4

Time

0.6

0.8

1.0

Figure 24: Optimal isolation (green line) and vaccination (blue line) policies (secondary axis)
versus the Infected (red line) fraction (primary axis) for the low cost running cost function.

Optimal vaccination policy vs isolation policy

1.0

Isolation rate

0.8

0.6

0.4

0.2

0.0
0

5

10

15

Vaccination rate

20

25

30

Figure 25: Plot of the optimal isolation policy versus optimal vaccination policy under low cost
running cost function.

28

A. Lesniewski

References
[1] Anderson, R. M., and May, R. M.: Population biology of infectious diseases: Part
I, Nature, 280, 361 - 366 (1971).
[2] Bellman, R.: Dynamic Programming, Princeton University Press (1957).
[3] Bolzoni, L., Bonacini, E., Soresina, C., and Groppi, M.: Time-optimal control strategies in SIR epidemic models, Mathematical Biosciences, 292, 86 - 96
(2017).
[4] Brauer, F., Castillo-Chavez, C., and Feng, Z.: Mathematical Models in Epidemiology, Springer (2019).
[5] Britton, T.: Stochastic epidemic models: A survey, Mathematical Biosciences,
210, 24 - 35 (2010).
[6] Bartlett, M. S.: Deterministic and stochastic models for recurrent epidemics,
Proc. Third Berkeley Symposium on Math. Statistics and Probability, 4, 81 -109
(1956).
[7] Bouchard B., Touzi N.: Discrete Time Approximation and Monte-Carlo Simulation of Backward Stochastic Differential Equations, Stochastic Processes and
their Applications, Vol 111, 2, 175-206 (2004).
[8] Doyle, A. C.: A Scandal in Bohemia, (1891), included in The Adventures of Sherlock Holmes, (1892).
[9] El Karoui, N., Peng, S. and Quenez, M. C.: Backward stochastic differential
equations in finance, Math. Finance, 7, 1 - 71 (1997).
[10] Flemming, W. H., Soner, H. M.: Controlled Markov processes and viscosity solutions, Springer-Verlag (1992).
[11] Gray, A., Greenhalgh, D., Hu, L., Mao, X., and Pan, J.: A stochastic differential
equation SIS epidemic model, SIAM J. on Appl. Math., 71, 876 - 902 (2011).
[12] Hairer, E., Lubich, C., and Wanner, G.: Geometric numerical integration illustrated by the StörmerVerlet method, Acta Numerica, 399 450 (2003).
[13] Hansen, E., and Day, T.: Optimal control of epidemics with limited resources, J.
Math. Biol., 62, 423 - 451 (2011).
[14] Han, J., Jentzen, A., and E, W.: Solving high-dimensional partial differential
equations using deep learning, Proc. Nat. Acad. Sci., 115, 8505 - 8510 (2018).
[15] Kermack, W. O., and McKendrick, A. G.: A contribution to the mathematical
theory of epidemics, Proc. Roy. Soc. Lond. A115, 700 - 721 (1927).
[16] Khasminskii, R.: Stochastic Stability of Differential Equations, Springer (2012).

Optimal control of an epidemic

29

[17] Leimkuhler, B., and Reich, S.: Simulating Hamiltonian Dynamics, Cambridge
University Press (2004).
[18] Lesniewski, A., and Lesniewski, N.: Options on infectious diseases, https:
//arxiv.org/abs/2003.07992 (2020).
[19] Lesniewski, A., and Richter, A.: Managing counterparty credit risk via backward
stochastic differential equations, https://arxiv.org/abs/1608.03237
(2016).
[20] Longstaff, F. A., and Schwartz, E. S.: Valuing American Options by Simulation:
A Simple Least-Squares Approach, Rev. Fin. Stud., 14, 113 - 147 (2001).
[21] Pham, H.: Continuous-time Stochastic Control and Optimization with Financial
Applications, Springer (2009).
[22] Pontryagin, L. S., Boltyanskii, V. G., Gamkrelidze, R.V., and Mishchenko, E. F.:
The Mathematical Theory of Optimal Processes, Interscience (1962).
[23] Yong, J., and Zhou, X. U.: Stochastic Controls: Hamiltonian Systems and HJB
Equations, Springer (1999).

