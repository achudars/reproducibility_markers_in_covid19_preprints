Automatic Textual Evidence Mining in COVID-19 Literature
Xuan Wang1 , Weili Liu1 , Aabhas Chauhan1 , Yingjun Guan2 , Jiawei Han1
1

Department of Computer Science, University of Illinois at Urbana-Champaign
School of Information Sciences, University of Illinois at Urbana-Champaign
1,2
{xwang174,weilil2,aabhasc2,yingjun2,hanj}@illinois.edu
2

arXiv:2004.12563v3 [cs.IR] 29 Apr 2020

Abstract
We created this E VIDENCE M INER system for
automatic textual evidence mining in COVID19 literature. E VIDENCE M INER is a webbased system that lets users query a natural language statement and automatically retrieves textual evidence from a background
corpora for life sciences. It is constructed in
a completely automated way without any human effort for training data annotation. E VIDENCE M INER is supported by novel datadriven methods for distantly supervised named
entity recognition and open information extraction. The named entities and meta-patterns
are pre-computed and indexed offline to support fast online evidence retrieval. The annotation results are also highlighted in the original document for better visualization. E VI DENCE M INER also includes analytic functionalities such as the most frequent entity and relation summarization.

1

Introduction

Coronavirus disease 2019 (COVID-19) is an infectious disease caused by severe acute respiratory
syndrome coronavirus 2 (SARS-CoV-2). The disease was first identified in 2019 in Wuhan, Central
China, and has since spread globally, resulting in
the 20192020 coronavirus pandemic. On March
16th, 2020, researchers and leaders from the Allen
Institute for AI, Chan Zuckerberg Initiative (CZI),
Georgetown University’s Center for Security and
Emerging Technology (CSET), Microsoft, and the
National Library of Medicine (NLM) at the National Institutes of Health released the COVID-19
Open Research Dataset (CORD-19)1 of scholarly
literature about COVID-19, SARS-CoV-2, and the
coronavirus group.

Corpora

Knowledge Bases

User

Algorithm Pool
Distantly-supervised NER:
AutoNER, AutoBioNER, PeNNER
Meta-pattern Discovery:
MetaPAD, TruePIE, CPIE, WWPIE

User Query

EvidenceMiner
Text Evidence Retrieval

Metadata
Storage

Pattern
Index

Full-text
Index

Annotation Result Visualization
Entity/Relation Summarization

Figure 1: System architecture of E VIDENCE M INER.

Traditional search engines for life sciences (e.g.,
PubMed) are designed for document retrieval and
do not allow direct retrieval of specific statements.
Some of these statements may serve as textual evidence that is key to tasks such as hypothesis generation and new finding validation. We created E VI DENCE M INER (Wang et al., 2020a), a web-based
system for textual evidence discovery for life sciences. We apply the E VIDENCE M INER system to
the CORD-19 corpus to facilitate textual evidence
mining for the COVID-19 studies2 . Given a query
as a natural language statement, E VIDENCE M INER
automatically retrieves sentence-level textual evidence from the CORD-19 corpus. In the following sections, we introduce the details of the E VI DENCE M INER system. We also show some textual
evidence retrieval results with E VIDENCE M INER
on the CORD-19 corpus.

2

E VIDENCE M INER System

E VIDENCE M INER is a web-based system for textual evidence discovery for life sciences (Figure
1). Given a query as a natural language state-

1

https://www.kaggle.com/
allen-institute-for-ai/
CORD-19-research-challenge

2
https://xuanwang91.github.io/
2020-04-15-cord19-evidenceminer/

ment, E VIDENCE M INER automatically retrieves
sentence-level textual evidence from a background
corpora of biomedical literature. E VIDENCE MINER is constructed in a completely automated way
without any human effort for training data annotation. It is supported by novel data-driven methods
for distantly supervised named entity recognition
and open information extraction.
2.1

Pre-processing

E VIDENCE M INER relies on external knowledge
bases to provide distant supervision for named entity recognition (NER) (Shang et al., 2018; Wang
et al., 2018b, 2019). For this COVID-19 study, the
NER results are obtained from the CORD-NER
system (Wang et al., 2020b). Based on the entity
annotation results, it automatically extracts informative meta-patterns (textual patterns containing
entity types, e.g., CHEMICAL inhibit DISEASE)
from sentences in the background corpora. (Jiang
et al., 2017; Wang et al., 2018a; Li et al., 2018a,b).
Sentences with meta-patterns that better match the
query statement is more likely to be textual evidence.
2.2

Corpus Indexing

After we get all entities and meta-patterns extracted,
we use them to guide the textual evidence discovery. We create three offline indexes of the input
corpus based on the words, entities and synonym
meta-pattern groups from the previous steps. Indexing helps boost the online processing of textual
evidence discovery given a user-specified query.
Word indexing. We normalize the words in the
corpus to lowercase and split the corpus into single
sentences for indexing. We take each word in the
vocabulary of the corpus as the key and generate an
identifier list as the value including the sentences
containing the key word.
Entity indexing. Similar to word indexing, we
take each entity recognized by PubTator as the key
and generate an identifier list as the value including
the sentences containing the key entity.
Pattern indexing. After the fine-grained metapattern matching, we take each meta-pattern together with its extracted entity set as two levels of keys and generate the identifier list as the
value including the sentences matched by the metapatterns with their corresponding entity set. We
also maintain two dictionaries, one mapping each
meta-pattern to its synonym meta-pattern group

and the other mapping each synonym meta-pattern
group to its list of meta-patterns.
2.3

Textual Evidence Retrieval.

Taken an user-input query and the indexed corpus,
we retrieve all the candidate evidence sentences
and rank them by a confidence score of it being
textual evidence for the query. The confidence
score is a weighted combination of three scores: a
word score, an entity score and a pattern score. Our
evidence ranking function calculates the following
three ranking scores:
1. Word score: candidate evidence sentences
covering more query-related words will be
ranked higher.
2. Entity score: candidate evidence sentences
covering more query-related entities will be
ranked higher.
3. Pattern score: candidate evidence sentences
covering more query-matched meta-patterns
will be ranked higher.
Word Score. We use the BM25 (Robertson et al.,
2009) score as the word score to measure the relatedness between the query and the candidate evidence sentence. BM25 is a commonly used ranking
score for information retrieval. Given a query Q
containing the words (w1 , w2 , ..., wn ), the BM25
score of a candidate evidence sentence S is
Sw (Q, S)
n
X
=
IDF (wi ) ·
i=1

f (wi , S) · (k + 1)
f (wi , S) + k · (1 − b + b ·

|S|
)
avgsl

,

where f (wi , S) is the term frequency of wi in
the sentence S, |S| is the length of the sentence S,
avgsl is the average length of all the sentences and
k and b are two free parameters chosen by the user.
IDF (wi ) is the inverse document frequency of wi ,
which is computed as
IDF (wi ) = log

N − n(wi ) + 0.5
,
n(wi ) + 0.5

where N is the total number of sentences and
n(wi ) is the number of sentences containing wi . A
candidate evidence sentence that is more related to
the query will have a higher word score.
Entity Score. We also use the BM25 score as
the entity score to measure the relatedness of the

query and the candidate evidence sentence. Given
a query Q containing the entities (e1 , e2 , ..., em ),
the BM25 score of a candidate evidence sentence
S is
SE (Q, S)
m
X
=
IDF (ei ) ·
i=1

f (ei , S) · (k + 1)
f (ei , S) + k · (1 − b + b ·

|S|
)
avgsl

,

where f (ei , S) is the term frequency of ei in
the sentence S, |S| is the length of the sentence S,
avgsl is the average length of all the sentences and
k and b are two free parameters chosen by the user.
IDF (ei ) is the inverse document frequency of ei ,
which is computed as
IDF (ei ) = log

N − n(ei ) + 0.5
,
n(ei ) + 0.5

where N is the total number of sentences and
n(ei ) is the number of sentences containing ei . A
candidate evidence sentence more related to the
query will have a higher entity score.
Pattern Score. We measure how many synonym
patterns to the query pattern can be matched on
each candidate evidence sentence. Given an input
query (e.g., (resveratrol, inhibit, pancreatic cancer)), we first try to convert it into a query metapattern (e.g., “$CHEMICAL inhibit $DISEASE”).
If the query meta-pattern can be found in our pattern index, we directly retrieve all the synonym
meta-patterns to the query meta-pattern. Then we
measure how many meta-patterns among the synonym meta-patterns can be matched for each candidate evidence sentence on the query entities. Given
a query Q containing the entities (e1 , e2 , ..., en ),
the pattern score of a candidate evidence sentence
S is

SP (Q, S) =

k
X

M atch(M Pi (Q), S),

i=1

where k is the number of meta-patterns in
the synonym meta-pattern group of the query
on Q, M Pi (S) is each meta-pattern in the synonym meta-pattern group of the query on Q, and
M atch(M Pi (Q), S) is an indicator function that
measures if the sentence S can be matched with
M Pi (Q) on the query entities. A candidate evidence sentence is more likely to be confident evidence if it can be matched to more synonym metapatterns to the query meta-pattern.

Method / nDCG
BM25
LitSense
E VIDENCE M INER

@1
0.714
0.599
0.855

@5
0.720
0.624
0.861

@10
0.746
0.658
0.889

Table 1: Performance comparison of the textual evidence retrieval systems with nDCG@1,5,10.

Textual Evidence Score. The final score of the
candidate evidence sentence is a weighted average
of the three scores,
S(Q, S) = σ · Sw + θ · SE + η · SP ,

where (σ, θ, η) is the weight vector indicating
the importance of each aspect of the information
(i.e., word, entity and pattern), which can be adjusted by the user. The default weight vector we
use is equal weight for word, entity and pattern in
our experiments.

3

Results on COVID-19

3.1

Textual Evidence Retrieval

To demonstrate the effectiveness of E VIDENCE MINER in textual evidence retrieval, we compare its
performance with the traditional BM25 (Robertson et al., 2009) and a recent sentence-level search
engine, LitSense (Allot et al., 2019). The background corpus is the same PubMed subset for all
the compared methods. We first ask domain experts to generate 50 query statements based on
the relationships between three biomedical entity
types (gene, chemical, and disease) in the Comparative Toxicogenomics Database3 . Then we ask
domain experts to manually label the top-10 retrieved evidence sentences by each method with
three grades indicating the confidence of the evidence. We use the average normalized Discounted
Cumulative Gain (nDCG) score to evaluate the textual evidence retrieval performance. In Table 1, we
observe that E VIDENCE M INER always achieves
the best performance compared with other methods. It demonstrates the effectiveness of using entities and meta-patterns to guide textual evidence
discovery in biomedical literature.
3.2

Case Study

Here are some case studies to demonstrate that E VIDENCE M INER can help scientific discoveries on
COVID-19. In Figure 2, scientists want to find
some evidence for using ultraviolet (UV) to kill
3

http://ctdbase.org

the SARS-COV-2 virus. In the top-retrieved results, we see many supporting sentences such as
the top one Ultraviolet-C (UV-C) radiation represents an alternative to chemical inactivation methods. More interestingly, we found the fifth sentence Whole UV-inactivated SARS-CoV (UV-V),
bearing multiple epitopes and proteins, is a candidate vaccine against this virus indicating that
UV-inactivation also has the potential for vaccine
development against the virus. Scientists are very
interested in this result that inspired them to conduct UV-related COVID-19 vaccine development.
Moreover, E VIDENCE M INER allows more flexible queries, such as the relational patterns, if the
users are not sure which specific entity to search. In
Figure 3, scientists want to find some evidence related to CORONAVIRUS cause DISEASEORSYNDROME. In the top-retrieved results, we see many
highly-related evidence sentences, such as HCoVOC43, HCoV-229E, HCoV-HKU1, and HCoVNL63 cause mild, self-limiting upper respiratory
tract infections. This function is supported by our
meta-pattern discovery methods and has not been
incorporated by any existing systems.
We show some more examples. In Figure 4, doctors want to study if remdesivir is a potential drug
treatment for COVID-19. Remdesivir is currently
a very actively studied drug that has the potential
to be repurposed for COVID-19 treatment. Similarly, in the top-retrieved results shown below, we
can see many sentences regarding the clinical trials
for remdesivir against COVID-19. An additional
example is shown for amodiaquine as a potential
drug for COVID-19 in Figure 5.
Last, we show that E VIDENCE M INER is also
useful for evidence finding for controversial topics. In Figure 6, people are interested to see if
wearing masks can help prevent the COVID-19
spreading. In the top-retrieved results, we see many
related statements, among them are clearly two opposite opinions. For example, some statements
support the use of masks to prevent the virus, such
as COVID-19 is transmitted by saliva droplets, ,
which can be prevented by wearing masks. While
other statements are against the effectiveness of
wearing masks, such as Although surgical masks
are in widespread use , there is no evidence that
wearing these masks can prevent the acquisition
of COVID-19 . An interesting future work is to
classify the opinions by their semantic polarity and
even automatically generate summarizations of the

evidence retrieval results.

4

Conclusion

E VIDENCE M INER on COVID-19 be constantly
updated based on the incremental updates of the
CORD-19 corpus and the improvement of our system. We hope this system can help the text mining
community build downstream applications for the
COVID-19 related tasks. We also hope this system
can bring insights for the COVID-19 studies on
making scientific discoveries.

Acknowledgment
Research was sponsored in part by US DARPA
KAIROS Program No. FA8750-19-2-1004 and
SocialSim Program No. W911NF-17-C-0099,
National Science Foundation IIS 16-18481, IIS
17-04532, and IIS-17-41317, and DTRA HDTRA11810026. Any opinions, findings, and conclusions or recommendations expressed herein are
those of the authors and should not be interpreted
as necessarily representing the views, either expressed or implied, of DARPA or the U.S. Government. The U.S. Government is authorized to
reproduce and distribute reprints for government
purposes notwithstanding any copyright annotation
hereon. The views and conclusions contained in
this paper are those of the authors and should not be
interpreted as representing any funding agencies.

References
Alexis Allot, Qingyu Chen, Sun Kim, Roberto Vera Alvarez, Donald C Comeau, W John Wilbur, and Zhiyong Lu. 2019. Litsense: making sense of biomedical
literature at sentence level. Nucleic acids research.
Meng Jiang, Jingbo Shang, Taylor Cassidy, Xiang Ren,
Lance M Kaplan, Timothy P Hanratty, and Jiawei
Han. 2017. Metapad: Meta pattern discovery from
massive text corpora. In KDD, pages 877–886.
ACM.
Qi Li, Meng Jiang, Xikun Zhang, Meng Qu, Timothy P Hanratty, Jing Gao, and Jiawei Han. 2018a.
Truepie: Discovering reliable patterns in patternbased information extraction. In KDD, pages 1675–
1684. ACM.
Qi Li, Xuan Wang, Yu Zhang, Qi Li, Fei Ling, Cathy
Wu H, and Jiawei Han. 2018b. Pattern discovery for wide-window open information extraction in
biomedical literature. In BIBM. IEEE.
Stephen Robertson, Hugo Zaragoza, et al. 2009. The
probabilistic relevance framework: Bm25 and beyond. FnT Inf. Ret., 3(4):333–389.

Figure 2: Case study: (Ultraviolet, UV, kills, SARS-COV-2)

Jingbo Shang, Liyuan Liu, Xiang Ren, Xiaotao Gu,
Teng Ren, and Jiawei Han. 2018. Learning named
entity tagger using domain-specific dictionary. In
EMNLP. ACL.
Xuan Wang, Yingjun Guan, Weili Liu, Aabhas
Chauhan, Enyi Jiang, Qi Li, David Liem, Dibakar
Sigdel, J. Harry Caufield, Peipei Ping, and Jiawei
Han. 2020a. Evidenceminer: Textual evidence discovery for life sciences. In ACL: System Demonstrations.
Xuan Wang, Xiangchen Song, Yingjun Guan,
Bangzheng Li, and Jiawei Han. 2020b. Comprehensive named entity recognition on cord-19
with distant or weak supervision. arXiv preprint
arXiv:2003.12218.
Xuan Wang, Yu Zhang, Qi Li, Yinyin Chen, and Jiawei
Han. 2018a. Open information extraction with metapattern discovery in biomedical literature. In BCB,
pages 291–300. ACM.
Xuan Wang, Yu Zhang, Qi Li, Xiang Ren, Jingbo
Shang, and Jiawei Han. 2019. Distantly supervised
biomedical named entity recognition with dictionary
expansion. In 2019 IEEE International Conference
on Bioinformatics and Biomedicine (BIBM), pages
496–503. IEEE.
Xuan Wang, Yu Zhang, Qi Li, Cathy H. Wu, and Jiawei
Han. 2018b. PENNER: pattern-enhanced nested

named entity recognition in biomedical literature. In
BIBM, pages 540–547.

Figure 3: Case study: (CORONAVIRUS cause DISEASEORSYNDROME)

Figure 4: Case study: (COVID-19, remdesivir)

Figure 5: Case study: (COVID-19, amodiaquine)

Figure 6: Case study: (COVID-19, masks)

