1

News consumption
and social media regulations policy

arXiv:2106.03924v1 [cs.SI] 7 Jun 2021

Gabriele Etta, Matteo Cinelli, Alessandro Galeazzi, Carlo Michele Valensise, Walter Quattrociocchi, Mauro Conti,
Senior Member, IEEE

Abstract—Users online tend to consume information adhering
to their system of beliefs and to ignore dissenting information.
During the COVID-19 pandemic, users get exposed to a massive
amount of information about a new topic having a high level of
uncertainty. In this paper, we analyze two social media that enforced opposite moderation methods, Twitter and Gab, to assess
the interplay between news consumption and content regulation
concerning COVID-19. We compare the two platforms on about
three million pieces of content analyzing user interaction with
respect to news articles. We first describe users’ consumption
patterns on the two platforms focusing on the political leaning
of news outlets. Finally, we characterize the echo chamber effect
by modeling the dynamics of users’ interaction networks. Our
results show that the presence of moderation pursued by Twitter
produces a significant reduction of questionable content, with a
consequent affiliation towards reliable sources in terms of engagement and comments. Conversely, the lack of clear regulation on
Gab results in the tendency of the user to engage with both types
of content, showing a slight preference for the questionable ones
which may account for a dissing/endorsement behavior. Twitter
users show segregation towards reliable content with a uniform
narrative. Gab, instead, offers a more heterogeneous structure
where users, independently of their leaning, follow people who
are slightly polarized towards questionable news.
Index Terms—COVID-19, Social Media, News Consumption,
Fake news, Echo Chambers.

I. I NTRODUCTION
The COVID-19 outbreak [1], which was declared as a
pandemic by the World Health Organization (WHO) on 11
March 2020 [2], changed several aspects of our everyday
life both in the online and offline sphere. For instance, the
news diet of users was remarkably modified in its structure by
introducing a considerable amount of information referring to
a new topic. This phenomenon was accelerated by social media
platforms, which are known for shaping discussions on a wide
range of issues, including politics, climate change, economics,
migration, and health [3]–[6].
The arising of the pandemic generated an overabundant
flow of information and news, whose trustworthiness may not
always be guaranteed, especially online. This phenomenon,
referred as infodemic [7], [8] reportedly affect people’s behavior [9] in a harmful way. This aspect calls for urgent
investigations of the turbulent dynamics of the online infosphere, complementary to the monitoring of the spreading of
infections [10]–[12]. Indeed, the current infodemic may foster
the tendency of users a) to acquire information adhering to
their system of beliefs [13], b) to ignore dissenting information

[14], c) to form polarized groups around a shared narrative
[15]. Two common factors to such behaviors carried on by
users are opinion polarization [16], one of the dominating
traits of online social dynamics, and echo chambers [17].
Divided into echo chambers, users account for the coherence
with their preferred narrative rather than the actual value of
the information [18]–[20]. Such evidence for polarization and
online echo chambers seems to be related to a feedback loop
between individual choices and algorithm recommendations
towards like-minded contents [17], [21], [22]. However, other
presumably harmless factors like the enforcement of content
regulation may play a role in increasing online polarization.
Indeed, it was recently observed that moderation policies
and removal actions/bans of users produce adverse effects in
terms of online polarization [23]–[25]. Users who got banned
often consider this action as a badge of honor, rejoining the
same social media under new identities or migrating to more
tolerant platforms. The result could be either a reinforcement
of their (extreme) opinion or reduced exposure to opposing
voices. Therefore, raising awareness about the collateral costs
of content policy and other interventions is crucial for making
social media a less toxic environment.
a) Contribution: This work provides a comparative analysis between two social media platforms that differ on how
content moderation is applied. We select Twitter as a representative of content-regulated social media and Gab, a social
network known for its willingness to ensure free speech by
using little to no content moderation [26], like its counterpart.
Despite their differences in how content policy is applied,
both platforms are characterized by a similar platform design.
Users are allowed to post and interact with content, together
with their ability to create connections with other users. We
perform our analysis on a timespan between 1/1/2020 and
30/09/2020, covering the first global wave of COVID-19.
The dataset includes about three million posts and comments
related to the COVID-19 topic expressed from more than one
million users. We investigate consumption patterns from a user
and post perspective on the two social media, assessing differences in terms of engagement. We extend this analysis by taking into account the trustworthiness of the contents published,
classifying news sources accordingly to a categorization based
on Media Bias/Fact Check [27] and NewsGuard [28]. An
akin type of classification was exploited in several papers [5],
[12], [14], [17] bringing essential insights on the circulation of
misinformation online. Therefore, we employ this dichotomy
by classifying posts as Questionable or Reliable depending
on their credibility. The same labeling was used to model the

2

persistence of users repeatedly commenting under a post of
the same outlet category. Finally, we investigate the presence
of homophily, i.e., the tendency of users to aggregate around
common interests, by measuring the relationship between users
and their tendency to post questionable content. We find
that the content moderation imposed by Twitter promotes the
existence of two echo chambers of radically different sizes.
In summary, the bulk of users on Twitter seems to share and
interact with verified content.
Oppositely, users on Gab show a lack of a clear preference
between the two types of outlets. Questionable posts are preferred in terms of commenting persistence. However, reliable
posts are more likely to be commented on as time passes.
Coherently, the existence of echo chambers on Gab is not as
evident as observed in the case of Twitter due to the presence
of users with a relatively heterogeneous leaning. We conclude
that a valid content regulation policy produces tangible results
in contrasting misinformation spreading.
b) Organization: This work is organized as follows.
Section II-A describes the recent developments in the study of
misinformation dynamics and their relationship with the phenomenon of polarization. Section II-B introduces the structure
of Gab, providing an overview of this particular social media.
Section II-C describes the recent advances in the study of
misinformation related to COVID-19 from a social dynamics
and machine learning perspective. Section III introduces the
methodology and the theoretical tools applied for this study.
Section IV describes the results obtained from the experiments. Section V provides the final remarks of this work,
summarizing the results obtained and the future developments.
Finally, Section A provides additional information on the
results presented in the paper.
II. R ELATED W ORKS
A. Misinformation and polarization
The study of misinformation and the spreading of fake news
has received increasing interest in recent years, disentangling
the role of news consumption on mainstream and niche social
media [5], [12], [19], [29], [30]. The presence of psychological
mechanisms that affect the way users choose which news
to consume [9] has been attributed to the effect of online
polarization [16], [19] and, consecutively, to the creation of
the so-called echo chambers [17], [31]–[35].
B. The role of Gab
Gab [36] is an online social platform that aroused much
controversy in recent years. It describes itself as “A social
network that champions free speech, individual liberty and the
free flow of information online. All are welcome” [36]. Such
a claim, together with the political leaning of its founders and
developers, made Gab a safe place for the alt-right movement,
playing a central role in the organizations of actions to harm
the offline world [37]. The lack of content regulation within
Gab helped the proliferation of hate speech and fake news.
The risks associated with this content policy led to a series of
suspensions by its former service provider and the ban of its
application from online stores [26]. Gab attracted the interest

of researchers due to its permissive content regulatory policy
and the political leaning of its users. In Lima et al. [38],
authors analyzed the content shared on Gab and the leaning
of users, finding a homogeneous environment prone to share
right biased content. Zannettou et al. [26] characterized Gab in
terms of user leanings and their contents, suggesting that this
platform better suits for a safe place for right-wing extremists
rather than an environment where free speech is protected.
Moreover, a topological analysis performed by Cinelli et al.
[17] reveals that Gab users form one relevant cluster biased
to the right.
Overall, all these studies suggest that Gab can be considered
as a homogeneous environment where biased content and
misinformation may easily proliferate.
C. Recent advances in COVID-19 misinformation studies
Research against misinformation during the COVID-19 outbreak produced a series of results to limit the spreading of
harmful information.
Cinelli et al. [12] analyzed posts obtained from 5 different
social media platforms (Facebook, Twitter, Instagram, Gab,
and Reddit), finding out that the spreading of information is
mainly driven by the peculiar structure of the social media
in exam that in turn shapes the interaction patterns between
users.
In the field of machine learning, Elhadad et al. [39] introduced a framework that can identify, through a composed
machine leaning approach, misleading health-related information based on a ground-truth dataset. Since their use case
is related to COVID-19, the ground-truth dataset contained
both epidemiological and textual data from organizations like
WHO, UNICEF, UN and a range of fact-checking websites.
Sear et al. [40] provided a result that does not depend on
a classification approach. Instead, they employed LDA-based
algorithm to identify similar topics related to posts obtained
from Facebook Pages belonging to pro-vax and anti-vax communities. Their findings describe how the anti-vax community
develops a less focused debate on COVID-19 compared with
the pro-vax counterpart. However, anti-vax seems to be more
spread on the COVID-19 debate, with the result of being
more positioned to attract new supporters than the pro-vax
community.
In the context of Twitter, Jiang et al. [41] proposed a machinelearning model based on BERT architecture which estimated
user polarity within the U.S. debate by employing features
related to language and network structures. They found that
users belonging to the right-leaning are more active in the
creation and spreading of news affiliated with their echo
chamber if compared with their counterparts from the leftleaning.
III. P RELIMINARIES AND D EFINITIONS
In this section, we present the methodology applied in this
study. We start by introducing the data collection process of
posts from Twitter and Gab together with its categorization.
Then, we describe the theoretical tools behind the analysis of
engagement patterns, homophily and survival lifetime.

3

A. Data Collection
The collection of all posts concerning the COVID-19 was
designed to capture its corresponding debate on social media,
gathering posts and comments from both platforms. Therefore,
as the first step of this process, we analyzed the most searched
terms worldwide related to the aforementioned pandemic on
Google Trends. The analysis period ranges from 1/1/2020
to 30/09/2020. We selected four terms based on their interest and significance over time, namely: coronavirus, corona,
covid, covid19. Those terms served as a proxy, in the form of
hashtags, to retrieve posts on the two social media.
The collection of Twitter posts related to the COVID-19
pandemic relied on the existence of a public dataset [42]
covering this specific topic. It includes a collection of tweet
IDs, starting from 28/01/2020, posted by accounts with a
recognized influence or including representative keywords. To
provide a categorization of the reliability of the tweets, we
refined this dataset by retaining only those posts with a link,
reducing the dimension to 1.1M posts.
The same strategy was applied in the case of Gab. We
queried their API to obtain posts that included at least one of
the search hashtags. Due to some modifications made by the
platform during the study, the API stopped providing results
in chronological order since June 2020. Therefore, we started
collecting all posts from the general stream until the end
of the analysis period, filtering by hashtag as we previously
described. This process produced a dataset of ∼ 130K posts
containing a link.
B. Questionable and Reliable Sources
To evaluate the reliability of information circulating on both
social media, we employed a source-based approach. We built
a dataset of news outlets’ domains from our dataset where each
domain is labeled either as Questionable or Reliable. The classification relied on two fact-checking organizations called MediaBias/FactCheck (MBFC, https://mediabiasfactcheck.com)
and NewsGuard (NG, https://www.newsguardtech.com/). On
MBFC, each news outlet is associated with a label that refers
to its political bias, namely: Right, Right-Center, Least-Biased,
Left-Center, and Left. Similarly, the website also provides a
second label that expresses its reliability, categorizing outlets
as Conspiracy-Pseudoscience, Pro-Science or Questionable.
Noticeably, the Questionable set includes a wide range of
political biases, from Extreme Left to Extreme Right. For
instance, the Right label is associated with Fox News, the
Questionable label to Breitbart (a famous right extremist outlet), and the Pro-Science label to Science. MBFC also provides
a classification based on a ranking bias score that depends on
four categories: Biased Wording/Headlines, Factual/Sourcing,
Story Choices, and Political Affiliation. Each category is rated
on a 0 − 10 scale, with 0 indicating the absence of bias and
10 indicating the presence of maximum bias. The bias outlet
score is computed as the average of the four score categories.
Likewise, NG classifies news outlets into four categories based
on nine journalistic criteria, each of them having a specific
score whose sum ranges between 0 and 100. Outlets with a
score of at least 60 points are considered compliant with the

basic standards of credibility and transparency. Otherwise, they
are recognized as outlets that lack of credibility. A different
characterization is provided for humor and platforms websites,
not accounting for the categorization process.
Given the different ways of classifying information sources
from the two organizations, the following heuristic was applied. On MBFC, all the outlets already classified as Questionable or belonging to the category Conspiracy-Pseudoscience
were labeled as Questionable. The remaining categories were
labeled as Reliable. Coherently, outlets on NG were classified
based on their score, maintaining the dichotomy provided by
the website. We choose a score of 60 as threshold to consider
an outlet as Reliable (score > 60), otherwise it is referred as
Questionable (score ≤ 60).
Considering a total of 2738 news outlets provided by the
two organizations, 2701 belonging to MBFC and 37 to NG, we
end up with 814 outlets classified as Questionable and 1924
outlets classified as Reliable.
C. User Leaning
To measure the extent to which a user is associated with the
consumption of questionable or reliable contents, we introduce
the user leaning q. We define it in the range q ∈ [0, 1], where
0 means that a user posts contents exclusively associated with
reliable sources, and 1 means that a user puts into circulation
only questionable posts.
Formally, the user leaning can be defined as follows: let P
be the set of all posts with a URL matching a domain in our
dataset and U the set containing all the users with at least
a categorized post. At each element pj ∈ P is associated
a binary value lj ∈ {0, 1} based on the domain of the
link contained: if the URL refers to a domain classified as
questionable then lj = 1, otherwise lj = 0. Considering a
user ui in a bipartite network between users and posts, then
the user leaning qi of a user ui can be defined as:
qi =

ki
1 X
lj ,
ki j=1

(1)

where lj is the leaning score of the j-th neighbor of the user
ui , and ki is the number of categorized contents that the user
posted.
D. Comparison of power law distributions
Most quantities related to the activity of users on social
media show a heavy tailed distribution of discrete variables.
Given the discrete nature of such distributions, we could
not rely on Kolmogorov-Smirnov [43] test to assess whether
two distributions present significant differences between each
other. Indeed, such a test assumes that distributions must be
continuous, and the presence of a large number of ties in the
long-tailed distributions that we want to compare may lead to
the computation of biased p-values. To overcome this issue,
we employed a methodology proposed in Zollo et al. [14]
which makes use of a Wald Test [44] to assess significant
differences between the scaling parameters of two long-tailed
distributions.

4

105

5

104

10

103
102
101
100
105
104
102

10

103

3

102

102
101
100
106
105
10

4

10

3

101
100
105
104

Twitter

103

104

Gab

Cumulative N. of Interactions

104

103
102

102

101

101

101

100
100 101 102 103 104

100

100
100 101 102 103 104

N. of Interactions

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

N. of Posts

106

N. of Users

105

Time
Likes

Reblogs

N. of Interactions

Replies

Fig. 1: Representation of the engagement collected on Gab (upper panel) and Twitter (bottom panel). Left column: frequency
distribution of the interactions for posts, defined as Likes, Reblogs (or Retweets) and Replies. A like is generally considered
positive feedback on a news item. A reblog indicates a desire to spread a news item to friends. A reply can have multiple
features and meanings and can generate collective debate. Both social media shows a heavy-tailed distribution that allows room
for large deviations, i.e., some posts go viral. Middle column: evolution of the cumulative number of interactions over time.
The general trend shows a rapid increase during February 2020, in parallel with the spreading of the COVID-19 outbreak.
The absence of replies on Twitter is due to the limitations provided by their API. Right column: frequency distribution of
interactions received by users. Similarly to posts, the distribution is heavy-tailed, describing how users tend to collect similar
values of different interactions as their number increases.

E. Kaplan-Meier Estimator for lifetime analysis
Let T ∈ [0, +∞] be a random variable which represents
the time an event takes place. The probability that a randomly
selected subject lives up to time t is called Survival Function
S(t) = P (T ≤ t). The estimation of this probability is
provided by the Kaplan-Meier estimator [45], defined as

Y
di
,
(2)
Ŝ(t) =
1−
ni
ti ≤t

where di is the number of events that happened at time ti
and ni are the numbers of subjects who survived up to time
ti . In user lifetime analysis, we define as di the number of
users who have been commenting on a post up to ti days
and ni the number of users who stopped commenting after
ti days. Similarly, in post lifetime analysis, we define as di
the number of posts that have been receiving a comment up
to ti days and ni the number of posts that stopped receiving
comments at ti days. In both cases, our N distinct events times
t1 , t2 , . . . , tN ≥ 0 are independent, which is required by the
assumptions of the Kaplan-Meier estimator.
a) Homophily Analysis in User Following Networks:
Results from the computation of the user leaning q were
generalized to measure user homophily based on his news
consumption. This phenomenon was modeled from a network
perspective based on the work originally proposed by Cota
et al. [46]. We considered a new network in which a user is
represented as a node i with a given leaning qi . Each node

can be connected to others through a following relationship:
if user i follows user j on the social media in exam, their
corresponding representation in the adjacency matrix A is
Aij = 1, meaning that there is a directed edge between i
and j. In case of no relationship between the two users, we
have Aij = 0. This representation allows the computation of a
measure called average neighborhood leaning that quantifies
the mean leaning from all those users followed by a given one.
It is defined as
1 X
Aij qj ,
(3)
qiN = →
ki j
P
where ki→ = j Aij is the out-degree of node i, i.e., the
number of users followed by user i.
IV. R ESULT AND D ISCUSSION
This work aims at performing a comparative analysis of
two social media, namely Twitter and Gab, in order to understand how news consumption and social dynamics change in
presence of two radically different types of content regulation
policies (more stringent in the case of Twitter, almost absent
in the case of Gab). The following results will provide insights
to explain this behavior from different perspectives. At first,
we analyze the engagement of users with posts, which we
consider as separated into two categories named questionable
and reliable. Then, we quantify the commenting behavior of
users and posts. Lastly, we provide a network analysis to

5

B

10

100
5

10

104
3

10

103

2

10

101
1006
10
105
104
103
102

1

101

0

100

10

Time
Outlet Leaning

102

10

N. of Reblogs
Questionable

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

104

103

102

N. of Likes

Cumulative N. of Reblogs

104

101
101

10

0

105

102

100

10

1

106

1

104

102

N. of Posts

10

3

101

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

10

4

10

102

103

Twitter

Cumulative N. of Likes

N. of Posts

100
105

2

Gab

10

1

104

103

103

D

105

104

104

103
10

10

103

10

105

102

10

4

106

5

101

10

2

C

6

100

A
5

Time

Reliable

Fig. 2: Column A-B: categorized distribution of the number of posts against the number of likes they received with its cumulative
evolution. The distributions show some evidence about content preference on both platforms. Users on Gab show signs of better
appreciation toward questionable posts, supported by the lack of clear content regulation. Twitter, oppositely, shows strong
evidence towards the appreciation of reliable content, with a remarkable gap between the two categories. From a cumulative
perspective, the regulation imposed by Twitter results in an increasing divergence between questionable and reliable posts,
showing how the latter category is the most preferred one. The same does not apply to Gab, whose divergence seems not
to increase during the analysis period. Column C-D: categorized distribution of the number of posts against the number of
reblogs or retweets they received with its cumulative evolution. The previous considerations also apply to this kind of interaction,
describing the willingness of users to inject the contents they support into the news feed of their followers.

measure the tendency of users to aggregate with like-minded
peers, describing how the presence of content regulation may
be correlated with the polarization towards specific narratives.
A. Consumption Patterns
We investigate how the engagement on the two social
media differs in relationship with the COVID-19 topic. Fig. 1
compares the engagement distribution for posts and users.
Despite the differences in terms of scale that are attributable
to the size of the platforms’ user base, we observe that both
frequency distributions are long-tailed. This feature provides a
first evidence in the consumption of news, showing that interaction patterns are similar regardless of the content moderation
imposed.
Next, we extend the analysis of consumption patterns by
categorizing posts, based on their outlet leaning, into Questionable or Reliable. The resulting distributions from the application of this dichotomy are represented in Fig. 2 and 3. Fig.
2 displays the distribution of the number of likes and shares
(reblogs or retweets) obtained by posts in our dataset, together
with the corresponding cumulative. Similarly, Fig. 3 describes
the frequency distribution of the same kind of interactions from
a user perspective. In general, we observe how Twitter users
show a larger appreciation of reliable posts, establishing a clear
gap from questionable ones that increases during the analysis
period. This difference can be attributed to the commitment of
Twitter to limit the spreading of unverified contents [47]. The

opposite scenario happens on Gab, in which the consumption
patterns do not show a clear sign of polarization towards a
specific kind of narrative. This provides some evidence of
how users belonging to segregated environments like Gab are
not interested in the origin of the content itself. Instead, they
tend to self-segregate within environments in which they can
consume and spread questionable content. Therefore, the lack
of regulation on this platform may allow them to perform
information operations [48], i.e., a category of actions taken by
organized actors (governments or non-state actors) to distort
domestic or foreign political sentiment, against other users
who do not share the mainstream system of beliefs of the
community.
In order to assess the similarity between the distributions
deriving from the consumption patterns of questionable and
reliable posts, we fit power-law distributions to such data and
perform a statistical evaluation of their scaling parameters
using the Wald test. For Gab, all the obtained p-values were
significantly higher than 0.05, describing how questionable
and reliable distributions are comparable in terms of the
engagement produced. The same behavior is found on Twitter,
except for the likes distribution whose p-value is less than
0.001, describing a significant difference in the way users
engage with questionable and reliable content.
We can conclude that the presence of content moderation
is associated with a significant reduction of the flowing of
misinformation. The avoidance of these countermeasures, as

6

105

10−1

10−1

10−3

N. of Total Likes
Outlet Leaning

N. of Total Reblogs
Questionable

Reliable

Fig. 3: Distribution of likes (left column) and reblogs (right
column) received by users posting Questionable or Reliable
contents on Gab (upper panel) and Twitter (bottom panel).
The figure shows how the presence of content regulations,
performed by Twitter, results in a greater appreciation towards
users who post reliable content. Gab, instead, shows a mixed
endorsement pattern in which the appreciation towards users
does not depend on the category of the content they post.

reported on Gab, seems to be associated with more heterogeneous news consumption in terms of outlet category.
This particular shape of the news diet may be exploited to
conduct information operations. Statistical tests indicate how
questionable and reliable contents produce similar engagement
behaviors within the same social media. In the end, such
moderation helps the emergence of segregation, a condition
in which users are affected by the restriction applied in terms
of accessibility to the contents they are affiliated with but not
in their engagement behaviors.
B. Characterizing Commenting Behavior for Questionable
and Reliable posts
To quantify the persistence of comments concerning users
and posts, we employed Kaplan-Meier estimates of two survival functions. The first accounts for the period between
the first and last comment received from posts. The second
instead considers the period between the first and last comment
made by a user. To characterize any significant difference
in the two survival functions, we perform the Peto & Peto
[49] test. The upper panel of Figure 4 shows the KaplanEstimates computed on Gab, grouped by outlet category. The
test performed on its post and user lifetimes produces a pvalue of 0.026 and 0.001, respectively. Therefore, we can
conclude that the commenting persistence on Gab may be
subjected to the outlet category of the post commented. Indeed,
post lifetime on questionable posts reports a lower probability
of being commented as time increases despite its longer
persistence, reaching a maximum 340 days. Results from user
lifetime estimation, instead, describe how users are more likely
to comment on questionable posts for the first 240 days after

10−1

10−1

10−2

10−2
10−3

10

−3

10−4
0
40
80
120
160
200
240
280
320
360
400

100
100 101 102 103 104

100

S(t)

1

Days

100

Twitter

10

100
100 102 104 106 108

Days

Twitter

102
101

10−3
0
40
80
120
160
200
240
280
320
360
400

104
103

102

10−2

0
40
80
120
160
200
240
280
320
360
400

100
105

0
40
80
120
160
200
240
280
320
360
400

N. of Users

N. of Users

103

10−2

101

Gab

100

S(t)

103

S(t)

100

102
101

User Lifetime

100

Gab

102

Post Lifetime

104

S(t)

103

Days
Outlet Leaning

Days
Questionable

Reliable

Fig. 4: Kaplan-Meier estimates for Gab (upper panel) and
Twitter (lower panel), grouped by outlet category.
Left column: estimates obtained through the computation
of post lifetime, i.e., the period between the first and last
comment a post received. Right column: estimates obtained
through the computation of post lifetime, i.e., the period
between the user’s first and last comment.
Gab shows how the lack of content regulation is associated
with a commenting behavior that underlines a preference
towards questionable content. This behavior is characterized
by a discrepancy between the outlet category with the highest
commenting persistence both on user and post lifetimes. By
contrast, the introduction of content policies from Twitter
makes reliable content those with the highest commenting
persistence, which does not depend on the lifetime perspective.

post creation. After that time, the survival probability becomes
higher on reliable posts.
In the end, we can conclude that the commenting behaviors
on Gab reflect the general leaning of its community. Users
are more likely to comment on questionable posts since their
contents adhere to a common system of beliefs oriented to
conspiracy theories. Coherently, the significant commenting
persistence reported on reliable posts may describe the desire
of users to express their dissent against the narratives introduced from such posts.
Next, we examine the commenting persistence on Twitter.
Results from Peto & Peto test on the post and user lifetimes
report a p-value equal to 0.011 and 0.0055 respectively, stating
how the survival functions on both lifetimes differentiate
with respect to the outlet category of the posts commented.
Indeed, such estimations on Twitter describe a uniformity in
the commenting behavior for the reliable category. This fact
also provides further evidence about how content moderation
can discourage users from expressing their views under posts
whose authority is not verified.
In summary, Gab demonstrates how the lack of content

7

policy helps the emergence of the narratives that characterize
this environment, resulting in a discrepancy between the outlet
categories with the most commenting persistence on the two
lifetimes. However, when the content policy is applied, like on
Twitter, such discrepancy dissolves, resulting in a commenting
behavior that favors reliable content.
C. Quantifying Polarization
The presence of content moderation may affect how users
develop homophily, i.e., the tendency to surround themselves
with other peers who share the same narratives or system of
beliefs. To quantify this phenomenon, we build a network
in which the nodes represent the users i with their corresponding leaning xi , while the edges represent the following
relationship with other users that occurs on the social media.
This representation allows us to measure the neighborhood
leaning xN
i , i.e., a measure of the characteristic leaning of
the network surrounding user i. Figure 5 displays the joint
distribution between the individual leaning of a user xi and
its corresponding neighborhood leaning xN
i , on Twitter and
Gab. In addition to this, the marginal probability distributions
P (x) and P N (x), referring to the individual and average
neighborhood leaning, are represented on their corresponding
axis. Lastly, the density of users at point (x, xN ) is represented
as a contour map: the brighter the color in that point, the higher
the user density. Results described in Figure 5a show the
presence of homophily on Twitter, characterized by a strong
correlation of leanings in correspondence of low values. The
existence of a second echo chamber of incomparable size
made of users with high individual leaning, and therefore
not represented in the main figure but only visible in the
marginal distributions, signals strong segregation between two
communities. This finding also indicates how content regulations actively affect the shape of the news diet of users in the
context of the COVID-19 pandemic. Indeed, the concentration
around small values for both leanings provides evidence about
the effectiveness of the moderation imposed by the platform
against posts and users that promote questionable content. On
the other side, Gab shows a more heterogeneous behavior, as
represented in Figure 5b. Indeed, the joint distribution spreads
over different values of the individual leaning domain, with
the highest mode represented in correspondence of the point
(0.6, 0.6). We observe that on average users, regardless of their
leaning, are surrounded by a neighborhood skewed towards
questionable contents. Only very few users have a reliablebased leaning, who are also likely to be those with a weaker
activity since they could be on Gab just for curiosity or dissing.
Furthermore, the outlet category of the news that users post
is not relevant anymore since the user’s peers share a leaning
with a high value. Finally, these findings may suggest that
questionable news is employed to support the narrative of the
environment, whilst reliable ones are only used to perform
information operations by changing the original meaning of
the posts through a comment.
V. C ONCLUSIONS
In this work, we compared two social media, Twitter and
Gab, to investigate the interplay between content regula-

(a) Twitter

(b) Gab

Fig. 5: Joint distribution between individual and average
neighborhood leaning of all users posting classifiable contents
at least three times on Twitter (left) and Gab (right). The
figure shows further evidence about the regulation imposed
by Twitter which results in the creation of a unique echo
chamber of users with strong posting habits towards reliable
content. Oppositely, Gab shows the presence of an echo
chamber in which both individual and neighborhood leanings
are concentrated around high values of the intervals, with a
greater dispersion due to the mixed posting habits of users.
tion policies and news consumption. We provide quantitative
measures of such differences by evaluating the engagement
of users and posts. These measures are then extended by
providing a categorization of news outlets. Next, we measure
the commenting persistence of users and posts to describe
their ability to express themselves under posts belonging to
a specific outlet category. In the end, we characterize the
presence of homophily, investigating how users with a specific
leaning are more likely to surround themselves with users who
share the same narratives.
Our results show how the application of content regulation,
performed by Twitter, limits the diffusion of fake news and
conspiracy theories, shaping the news consumption and the
polarization of users towards reliable content. The avoidance
of these countermeasures, carried on by Gab, provides results
that underline the presence of patterns related to information
operations. Indeed, users tend to engage with questionable
and reliable content comparably. However, their commenting
behavior and the assessment of the homophily in this environment describe a systematic affiliation towards questionable
contents.
We conclude that content policies cover an important role
against the circulation of harmful content, especially in the
context of the COVID-19 pandemic. Our work provides meaningful evidence in this direction, indicating how a lack of
content policy is associated with the emergence of harmful
narratives that promote questionable content and mistrust
everything that goes against them.
Future implementations of this work may focus on the
dissing/endorsement behavior promoted by users in segregated
environments like Gab, analyzing those mechanisms from a
textual perspective. Furthermore, a topological analysis of
users who perform information operations in such environ-

8

ments may be relevant to understand their inner dynamics and
to promote specific countermeasures.
R EFERENCES
[1] W. H. Organization, “Coronavirus disease (covid-19) pandemic.” [Online]. Available: https://www.who.int/emergencies/diseases/
novel-coronavirus-2019?adgroupsurvey={adgroupsurvey}
[2] “Who director-general’s opening remarks at the media briefing on covid19 - 11 march 2020.”
[3] A. Bessi, F. Zollo, M. Del Vicario, A. Scala, G. Caldarelli, and
W. Quattrociocchi, “Trend of narratives in the age of misinformation,”
PloS one, vol. 10, no. 8, 2015.
[4] W.-Y. S. Chou, A. Oh, and W. M. Klein, “Addressing health-related
misinformation on social media,” Jama, vol. 320, no. 23, pp. 2417–
2418, 2018.
[5] A. Bovet and H. A. Makse, “Influence of fake news in twitter during the
2016 us presidential election,” Nature communications, vol. 10, no. 1,
pp. 1–14, 2019.
[6] M. Del Vicario, S. Gaito, W. Quattrociocchi, M. Zignani, and F. Zollo,
“News consumption during the italian referendum: A cross-platform
analysis on facebook and twitter,” in 2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA). IEEE, 2017,
pp. 648–657.
[7] J. Zarocostas, “How to fight an infodemic,” The lancet, vol. 395, no.
10225, p. 676, 2020.
[8] “Organization, w. h. director-general’s remarks at the media
briefing on 2019 novel coronavirus on 8 february 2020.” [Online]. Available: https://www.who.int/docs/default-source/coronaviruse/
situation-reports/20200202-sitrep-13-ncov-v3.pdf?sfvrsn=195f4010 6
[9] T. Sharot and C. R. Sunstein, “How people decide what they want to
know,” Nature Human Behaviour, vol. 4, no. 1, pp. 14–19, Jan 2020.
[Online]. Available: https://doi.org/10.1038/s41562-019-0793-1
[10] L. Kim, S. M. Fast, and N. Markuzon, “Incorporating media
data into a model of infectious disease transmission,” PLOS
ONE, vol. 14, no. 2, pp. 1–13, 02 2019. [Online]. Available:
https://doi.org/10.1371/journal.pone.0197646
[11] C. Viboud and A. Vespignani, “The future of influenza forecasts,”
Proceedings of the National Academy of Sciences, vol. 116, no. 8, pp.
2802–2804, 2019. [Online]. Available: https://www.pnas.org/content/
116/8/2802
[12] M. Cinelli, W. Quattrociocchi, A. Galeazzi, C. M. Valensise,
E. Brugnoli, A. L. Schmidt, P. Zola, F. Zollo, and A. Scala, “The
covid-19 social media infodemic,” Scientific Reports, vol. 10, no. 1, Oct
2020. [Online]. Available: https://doi.org/10.1038/s41598-020-73510-5
[13] A. Bessi, M. Coletto, G. A. Davidescu, A. Scala, G. Caldarelli, and
W. Quattrociocchi, “Science vs conspiracy: Collective narratives in the
age of misinformation,” PloS one, vol. 10, no. 2, p. e0118093, 2015.
[14] F. Zollo, A. Bessi, M. Del Vicario, A. Scala, G. Caldarelli, L. Shekhtman, S. Havlin, and W. Quattrociocchi, “Debunking in a world of tribes,”
PloS one, vol. 12, no. 7, 2017.
[15] M. Del Vicario, G. Vivaldo, A. Bessi, F. Zollo, A. Scala, G. Caldarelli,
and W. Quattrociocchi, “Echo chambers: Emotional contagion and group
polarization on facebook,” Scientific reports, vol. 6, p. 37825, 2016.
[16] M. D. Vicario, W. Quattrociocchi, A. Scala, and F. Zollo, “Polarization
and fake news: Early warning of potential misinformation targets,” ACM
Transactions on the Web (TWEB), vol. 13, no. 2, pp. 1–22, 2019.
[17] M. Cinelli, G. De Francisci Morales, A. Galeazzi, W. Quattrociocchi, and
M. Starnini, “The echo chamber effect on social media,” Proceedings
of the National Academy of Sciences, vol. 118, no. 9, 2021.
[18] M. Cinelli, M. Conti, L. Finos, F. Grisolia, P. K. Novak, A. Peruzzi,
M. Tesconi, F. Zollo, and W. Quattrociocchi, “(mis)information
operations: An integrated perspective,” Journal of Information Warfare,
vol. 18, no. 3, pp. 83–98, 2019. [Online]. Available: https:
//www.jstor.org/stable/26894683
[19] M. Del Vicario, A. Bessi, F. Zollo, F. Petroni, A. Scala, G. Caldarelli,
H. E. Stanley, and W. Quattrociocchi, “The spreading of misinformation
online,” Proceedings of the National Academy of Sciences, vol. 113,
no. 3, pp. 554–559, 2016. [Online]. Available: https://www.pnas.org/
content/113/3/554
[20] M. Conti, D. Lain, R. Lazzeretti, G. Lovisotto, and W. Quattrociocchi,
“It’s always april fools’ day!: On the difficulty of social network
misinformation classification via propagation features,” in 2017 IEEE
Workshop on Information Forensics and Security (WIFS). IEEE, 2017,
pp. 1–6.

[21] E. Bakshy, S. Messing, and L. A. Adamic, “Exposure to ideologically
diverse news and opinion on facebook,” Science, vol. 348, no. 6239, pp.
1130–1132, 2015.
[22] M. Cinelli, E. Brugnoli, A. L. Schmidt, F. Zollo, W. Quattrociocchi, and
A. Scala, “Selective exposure shapes the facebook news diet,” PloS one,
vol. 15, no. 3, p. e0229129, 2020.
[23] J. Berger and H. Perez, “Occasional paper the islamic state’s diminishing
returns on twitter: How suspensions are limiting the social networks
of english-speaking isis supporters,” GW Program on Extremism and
El Akkad, Omar (2012)“Why Twitter’s censorship plan is better than
you think”. The Globe and Mail. Berger, Morgan (2015)“Defining and
describing the population of ISIS supporters on Twitter”. The Brookings
Institution, 2016.
[24] S. Hughes and L. Vidino, “Isis in america: From retweets to raqqa,” Program on Extremism, George Washington University.[online] https://cchs.
gwu. edu/sites/cchs. gwu. edu/files/downloads/ISIS (Rev. 03.03. 2016),
2015.
[25] A. A. Siegel, “Online hate speech,” Social Media and Democracy, p. 56,
2019.
[26] S. Zannettou, B. Bradlyn, E. De Cristofaro, H. Kwak, M. Sirivianos,
G. Stringini, and J. Blackburn, “What is gab,” Companion of the The
Web Conference 2018 on The Web Conference 2018 - WWW ’18, 2018.
[Online]. Available: http://dx.doi.org/10.1145/3184558.3191531
[27] M. B. Check, “Mbfc.” [Online]. Available: https://mediabiasfactcheck.
com/
[28] N. Technologies, “Ng.” [Online]. Available: https://www.newsguardtech.
com/
[29] S. Vosoughi, D. Roy, and S. Aral, “The spread of true and false news
online,” Science, vol. 359, no. 6380, pp. 1146–1151, 2018. [Online].
Available: https://science.sciencemag.org/content/359/6380/1146
[30] D. M. J. Lazer, M. A. Baum, Y. Benkler, A. J. Berinsky, K. M.
Greenhill, F. Menczer, M. J. Metzger, B. Nyhan, G. Pennycook,
D. Rothschild, M. Schudson, S. A. Sloman, C. R. Sunstein, E. A.
Thorson, D. J. Watts, and J. L. Zittrain, “The science of fake news,”
Science, vol. 359, no. 6380, pp. 1094–1096, 2018. [Online]. Available:
https://science.sciencemag.org/content/359/6380/1094
[31] K. H. Jamieson and J. N. Cappella, Echo chamber: Rush Limbaugh and
the conservative media establishment. Oxford University Press, 2008.
[32] R. K. Garrett, “Echo chambers online?: Politically motivated selective
exposure among internet news users,” Journal of computer-mediated
communication, vol. 14, no. 2, pp. 265–285, 2009.
[33] K. Garimella, G. De Francisci Morales, A. Gionis, and M. Mathioudakis,
“Political discourse on social media: Echo chambers, gatekeepers, and
the price of bipartisanship,” in Proceedings of the 2018 World Wide Web
Conference, 2018, pp. 913–922.
[34] ——, “The effect of collective attention on controversial debates on
social media,” in Proceedings of the 2017 ACM on Web Science
Conference, 2017, pp. 43–52.
[35] W. Cota, S. C. Ferreira, R. Pastor-Satorras, and M. Starnini, “Quantifying
echo chamber effects in information spreading over political communication networks,” EPJ Data Science, vol. 8, no. 1, pp. 1–13, 2019.
[36] “Gab.” [Online]. Available: https://gab.com/
[37] CNN, “Gab, the social network used by the pittsburgh suspect, has
been taken offline,” 2018. [Online]. Available: https://edition.cnn.com/
2018/10/29/tech/gab-offline-pittsburgh/index.html
[38] L. Lima, J. C. Reis, P. Melo, F. Murai, L. Araujo, P. Vikatos, and
F. Benevenuto, “Inside the right-leaning echo chambers: Characterizing
gab, an unmoderated social system,” in 2018 IEEE/ACM International
Conference on Advances in Social Networks Analysis and Mining
(ASONAM). IEEE, 2018, pp. 515–522.
[39] M. K. Elhadad, K. F. Li, and F. Gebali, “Detecting misleading information on covid-19,” IEEE Access, vol. 8, pp. 165 201–165 215, 2020.
[40] R. F. Sear, N. Velásquez, R. Leahy, N. J. Restrepo, S. E. Oud, N. Gabriel,
Y. Lupu, and N. F. Johnson, “Quantifying covid-19 content in the online
health opinion war using machine learning,” IEEE Access, vol. 8, pp.
91 886–91 893, 2020.
[41] J. Jiang, X. Ren, and E. Ferrara, “Social media polarization and echo
chambers: A case study of covid-19,” 2021.
[42] E. Chen, K. Lerman, and E. Ferrara, “Tracking social media discourse
about the covid-19 pandemic: Development of a public coronavirus
twitter data set,” JMIR Public Health and Surveillance, vol. 6, no. 2, p.
e19273, 2020.
[43] A. Clauset, C. R. Shalizi, and M. E. J. Newman, “Power-law distributions in empirical data,” SIAM Review, vol. 51, no. 4, pp. 661–703,
2009.

9

[44] A. Wald, “Tests of statistical hypotheses concerning several parameters
when the number of observations is large,” Transactions of the
American Mathematical Society, vol. 54, no. 3, pp. 426–482, 1943.
[Online]. Available: http://www.jstor.org/stable/1990256
[45] E. L. Kaplan and P. Meier, “Nonparametric estimation from incomplete
observations,” Journal of the American Statistical Association, vol. 53,
no. 282, pp. 457–481, 1958.
[46] W. Cota, S. C. Ferreira, R. Pastor-Satorras, and M. Starnini,
“Quantifying echo chamber effects in information spreading over
political communication networks,” EPJ Data Science, vol. 8, no. 1,
p. 35, Dec 2019. [Online]. Available: https://doi.org/10.1140/epjds/
s13688-019-0213-9
[47] Twitter, “Updates to our work on covid-19 vaccine misinformation.”
[Online]. Available: https://blog.twitter.com/en us/topics/company/
2021/updates-to-our-work-on-covid-19-vaccine-misinformation.html
[48] J. Weedon, W. Nuland, and A. Stamos, “Information operations and facebook,” Retrieved from Facebook: https://fbnewsroomus. files. wordpress.
com/2017/04/facebook-and-information-operations-v1. pdf, 2017.
[49] R. Peto and J. Peto, “Asymptotically efficient rank invariant test procedures,” Journal of the Royal Statistical Society. Series A (General), vol.
135, no. 2, pp. 185–207, 1972.
[50] Twitter, “Academic research program.” [Online]. Available: https:
//developer.twitter.com/en/solutions/academic-research

Time

Time
105
104
103
102
101

101
100
103
102

Gab
Twitter

Time

Fig. 6: Upper panel: Time series evolution of new posts (left)
and users posting for the first time (right) on Gab and Twitter.
Lower panel: cumulative evolution of new posts (left) and
users posting of the first time (right) on Gab and Twitter.

100

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

101

Time
Outlet Leaning

105
104
103
102
101
105
104
103
102
101

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

10

100

Cumulative N. of Posts

102

1

N. of Posts

105
104
103
102
101
100

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

Time

10

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

100

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

10

103

2

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

N. of Users

1

Cumulative N. of Users

102

103

Twitter

Cumulative N. of Posts

103

Gab

N. of Posts

10

Time
Questionable

Reliable

Fig. 7: Evolution of posts based on their outlet leaning,
categorized as Questionable or Reliable.
Upper panel: Time series evolution of new posts (left) together
with its cumulative representation (right) on Gab.
Lower panel: Time series evolution of new posts (left) together
with its cumulative representation (right) on Twitter.

A PPENDIX A
S UPPORTING I NFORMATION
C. Results of Comparison between power law distributions
Here we provide further details about the datasets employed
for the study, the cumulative and daily evolution of posts and
new users posting and the numerical results of the statistical
tests performed. The description of the dataset is reported in
Section A-A, the representation of the time series is reported in
Section A-B while the results of the statistical test performed
are described in Section A-C.

A. Data breakdown
Here we report the composition of the dataset for Gab
and Twitter employed for the study, described in Table I and
Table II respectively. Each dataset represents the number of
unique posts, users and comments, as well as their engagement
quantities over the different data collection and processing
steps. Due to Twitter API limitations, posts were initially
gathered without any information about their number of comments. The collection of this quantity was performed after the
categorization of the news outlets through the employment of
specific APIs provided from Twitter as part of its Academic
Research Program [50].

B. Time Series Evolution
Here we report the evolution of posts and new users
collected on Twitter and Gab during the analysis time. Figure
6 shows the overall evolution of such quantities, while Figure
7 shows the previous evolution after performed the categorization of the news outlets. Figure 6 describes a spike on Gab
in the number of posts and users in correspondence of June.
This was due to the change of the collecting method. Indeed,
the lack of chronological order of posts reported on Gab APIs
since June required the gathering of all posts from the general
stream, which was then filtered by the search hashtags in order
to be compliant with the data collection process.

Here we report the information related to the comparison
of the power law fits described in Section IV-A by means of
the Wald test. Tables III - VI report the estimated coefficients
of each power law fit, i.e., α̂ and x̂min , depending on the
engagement and news outlet category. Furthermore, the results
of the Wald test score applied on the previous engagement
categories are reported, together with the corresponding pvalues.

11

Category
Number of
Number of
Number of
Number of
Number of

Posts
users
Likes
Reblogs
Comments

Overall
205 458
11 063
234 255
138 793
42 993

Containing search hashtags
130 864
8 194
117 281
75 250
22 287

Categorized
83 784
5 681
72 435
48 172
14 165

Questionable
49 772
4 660
53 154
34 960
9 489

Reliable
34 012
3 289
19 281
13 212
4 676

TABLE I: Composition of Gab Dataset where each column represents the quantities of collected posts collected during the
preprocessing phase.

Category
Number of
Number of
Number of
Number of
Number of

Posts
users
Likes
Reblogs
Comments

Overall
2 668 286
1 185 541
18 610 555
7 753 971
NA

Containing search hashtags
1 110 030
382 449
5 885 562
2 862 098
NA

Categorized
244 430
118 635
1 422 629
703 765
30 262

Questionable
25 121
13 711
141 273
68 609
8771

Reliable
219 309
108 153
1 281 356
635 156
21 491

TABLE II: Composition of Twitter Dataset where each column represents the quantities of collected posts collected during the
preprocessing phase.

Likes
α̂
Questionable
1.32
Reliable
1.37
Wald test score
p-value

x̂min
1
1
0.22
0.64

Reblogs
α̂
Questionable
1.31
Reliable
1.33
Wald’s test score
p-value

x̂min
1
1
0.034
0.85

TABLE III: Power law fits of Likes and Reblogs for post consumption patterns on Gab, together with the result of Wald test
between the scaling parameters of each outlet category.

Likes
α̂
Questionable
1.52
Reliable
1.55
Wald test score
p-value

x̂min
1
1
0.15
0.70

Reblogs
α̂
Questionable
1.57
Reliable
1.55
Wald’s test score
p-value

x̂min
1
1
0.05
0.83

TABLE IV: Power law fits of Likes and Reblogs for post consumption patterns on Twitter, together with the result of Wald
test between the scaling parameters of each outlet category.

Likes
α̂
Questionable
1.81
Reliable
1.83
Wald test score
p-value

x̂min
1
1
0.015
0.90

Reblogs
α̂
Questionable
1.83
Reliable
1.83
Wald’s test score
p-value

x̂min
1
1
0.0004
0.98

TABLE V: Power law fits of Likes and Reblogs for user consumption patterns on Gab, together with the result of Wald test
between the scaling parameters of each outlet category.

Likes
α̂
Questionable
3.33
Reliable
2.21
Wald test score
p-value

x̂min
1
1
1286.34
< 0.001

Reblogs
α̂
Questionable
1.75
Reliable
1.67
Wald’s test score
p-value

x̂min
1
1
1.06
0.30

TABLE VI: Power law fits of Likes and Reblogs for user consumption patterns on Twitter, together with the result of Wald
test between the scaling parameters of each outlet category.

12

Gabriele Etta Gabriele Etta received his MSc degree in Data Science from the University of Padua,
Italy, in 2020. He is currently a Ph.D. student from
Sapienza University of Rome, Italy, working on Data
Driven Modeling of Social Dynamics. His research
interests include complex networks, information diffusion, and computational social science.

Matteo Cinelli Matteo Cinelli is a post-doc researcher at Ca’ Foscari, University of Venice and
associate researcher at ISC-CNR. His background is
in Management Engineering and he obtained a PhD
in Enterprise Engineering from the University of
Rome “Tor Vergata”. His research interests include
network science, computational social science and
big data.

Mauro Conti Mauro Conti is Full Professor at the
University of Padua, Italy. He is also affiliated with
TU Delft and University of Washington, Seattle.
He obtained his Ph.D. from Sapienza University of
Rome, Italy, in 2009. After his Ph.D., he was a PostDoc Researcher at Vrije Universiteit Amsterdam,
The Netherlands. In 2011 he joined as Assistant
Professor the University of Padua, where he became
Associate Professor in 2015, and Full Professor in
2018. He has been Visiting Researcher at GMU,
UCLA, UCI, TU Darmstadt, UF, and FIU. He has
been awarded with a Marie Curie Fellowship (2012) by the European Commission, and with a Fellowship by the German DAAD (2013). His research is also
funded by companies, including Cisco, Intel, and Huawei. His main research
interest is in the area of Security and Privacy. In this area, he published
more than 400 papers in topmost international peer-reviewed journals and
conferences. He is Area Editor-in-Chief for IEEE Communications Surveys &
Tutorials, and has been Associate Editor for several journals, including IEEE
Communications Surveys & Tutorials, IEEE Transactions on Dependable
and Secure Computing, IEEE Transactions on Information Forensics and
Security, and IEEE Transactions on Network and Service Management. He
was Program Chair for TRUST 2015, ICISS 2016, WiSec 2017, ACNS 2020,
and General Chair for SecureComm 2012, SACMAT 2013, CANS 2021, and
ACNS 2022. He is Senior Member of the IEEE and ACM. He is a member
of the Blockchain Expert Panel of the Italian Government. He is Fellow of
the Young Academy of Europe.

Alessandro Galeazzi Alessandro Galeazzi obtained
the B.Sc. in Information Engineering in 2016 from
the University of Padua. In 2016 he enrolled in the
M.Sc. course of ICT for Internet and Multimedia
at the University of Padova and in 2017 he joined
the double degree program between National Taiwan
University and the University of Padova. In 2018 he
received the M.Sc. in Communication Engineering
from National Taiwan University and the M.Sc. in
ICT for Internet and Multimedia from the University
of Padova. In 2018 he joined the Ph.D. course at
the University of Brescia. His interests include human behavior on online
social media, information and misinformation spreading, and social feedback
algorithm effects on users’ choices.

Walter Quattrociocchi Walter Quattrociocchi is
Associate Professor at Sapienza University of Rome
where he leads the Center of Data Science and
Complexity for Society (CDCS. His research interests include data science, network science, cognitive
science, and data-driven modeling of dynamic processes in complex networks. His activity focuses on
the data-driven modeling of social dynamics such
as (mis)information spreading and the emergence of
collective phenomena. Dr Quattrociocchi has published extensively in peer reviewed conferences and
journals including PNAS. The results of his research in misinformation
spreading have informed the Global Risk Report 2016 and 2017 of the
World Economic Forum and have been covered extensively by international
media including Scientific American, New Scientist, The Economist, The
Guardian, New York Times, Washington Post, Bloomberg, Fortune, Poynter
and The Atlantic). He published two books: “Misinformation. Guida alla
società dell’informazione e della credulità” (Franco Angeli) and “Liberi di
Crederci. Informazione, Internet e Post Verità” with Codice Edizioni for the
dissemination of his results.
In 2017 Dr Quattrociocchi was the coordinator of the round table on
Fake News and the role of Universities and Research to contrast fake
news chaired by the President of Italy’s Chamber of Deputies Mrs Laura
Boldrini. Since 2018 he is Scientific Advisor of the Italian Communication
Authority (AGCOM) and currently Member of the Task Force to contrast Hate
Speech nomianted by the Minister of Innovation. Professor Quattrociocchi is
regularly invited for keynote speeches and guest lectures at major academic
and other organizations, having presented among others at CERN, European
Commission, the University of Cambridge, Network Science Institute, Global
Security Forum etc.

Carlo Michele Valensise Carlo Michele Valensise received in 2017 the M.S. degree in Physics
from Sapienza University of Rome, and the Ph.D.
degree in Physics in 2021, working on ultrafast
spectroscopy, and application of Artificial Intelligence to Optics experiments. Besides that, he was
Research Fellow of Ca’ Foscari University of Venice
in Data Science for Complexity and Computational
Social Science. He is currently post-doc researcher
at Centro Ricerche Enrico Fermi in Rome, working
on Computational Social Science.

