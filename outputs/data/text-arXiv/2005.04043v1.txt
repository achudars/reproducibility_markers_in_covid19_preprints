Hypergraph Learning for Identification of COVID-19 with CT Imaging

arXiv:2005.04043v1 [eess.IV] 7 May 2020

Donglin Dia,1 , Feng Shib,1 , Fuhua Yanc,1, Liming Xiad,1 , Zhanhao Moe,1 , Zhongxiang Dingf,1 , Fei Shang,1 , Shengrui
Lia , Ying Weib , Ying Shaob , Miaofei Hanb , Yaozong Gaob , He Suie , Yue Gaoa,∗, Dinggang Shenb,∗
a BNRist,

THUIBCS, KLISS, School of Software, Tsinghua University, Beijing, China.
of Research and Development, Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China.
c Department of Radiology, Ruijin Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, China.
d Department of Radiology, Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology, Wuhan, Hubei, China.
e Department of Radiology, China-Japan Union Hospital of Jilin University, Changchun, China.
f
Department of Radiology, Hangzhou First Peoples Hospital, Zhejiang University School of Medicine, Zhejiang, China.
g Department of Radiology, Shanghai Public Health Clinical Center, Fudan University, Shanghai, China.
b Department

Abstract
The coronavirus disease, named COVID-19, has become the largest global public health crisis since it started in early
2020. CT imaging has been used as a complementary tool to assist early screening, especially for the rapid identification of COVID-19 cases from community acquired pneumonia (CAP) cases. The main challenge in early screening
is how to model the confusing cases in the COVID-19 and CAP groups, with very similar clinical manifestations and
imaging features. To tackle this challenge, we propose an Uncertainty Vertex-weighted Hypergraph Learning (UVHL)
method to identify COVID-19 from CAP using CT images. In particular, multiple types of features (including regional
features and radiomics features) are first extracted from CT image for each case. Then, the relationship among different cases is formulated by a hypergraph structure, with each case represented as a vertex in the hypergraph. The
uncertainty of each vertex is further computed with an uncertainty score measurement and used as a weight in the hypergraph. Finally, a learning process of the vertex-weighted hypergraph is used to predict whether a new testing case
belongs to COVID-19 or not. Experiments on a large multi-center pneumonia dataset, consisting of 2,148 COVID-19
cases and 1,182 CAP cases from five hospitals, are conducted to evaluate the performance of the proposed method.
Results demonstrate the effectiveness and robustness of our proposed method on the identification of COVID-19 in
comparison to state-of-the-art methods.
Keywords:
COVID-19 pneumonia, Uncertainty Calculation, Vertex-weighted, Hypergraph Learning

1. Introduction

kind of savagely contagious virus, and could lead to acute
respiratory distress and multiple organ failure (Li et al.,
2020a; Chen et al., 2020; Li et al., 2020b; Wang et al.,
The coronavirus disease pandemic, named COVID-19,
2020a; Holshue et al., 2020).
has become the largest global public health crisis since
in started it early of 2020. COVID-19 was caused by a
The latest guideline, published by the Chinese
government
(the
trial
sixth
version)
(of
National
Health
Committee
et
al.),
declares
that
∗ Correspondence authors: Yue Gao (gaoyue@tsinghua.edu.cn), and
the
diagnosis
of
COVID-19
must
be
confirmed
by
the
Dinggang Shen (dinggang.shen@gmail.com)
1 D. Di, F. Shi, F. Yan, L. Xia, Z. Mo, Z. Ding, F. Shan contributed
reverse transcription polymerase chain reaction (RT-PCR)
equally to this work.
or gene sequencing for respiratory or blood specimens.
Preprint

May 11, 2020

Recent studies (Fang et al., 2020; Gozes et al., 2020;
Xie et al., 2020) have investigated the sensitivity of noncontrast chest CT, and demonstrated that, recognizing
either diffusion or focal ground-glass opacities as the
disease characteristics in CT is a reliable and efficient
approach. More specifically, the bilateral and peripheral
ground-class and consolidative pulmonary opacities in
CT are the typical features of COVID-19 symptoms, and
the greater severity of the disease with increasing time
from onset symptoms shows larger lung involvement
and more linear opacities, a.k.a. the “crazy-paving”
pattern and the “reverse halo” sign (Xie et al., 2020;
Bernheim et al., 2020).
To reduce the workload in diagnosing COVID-19,
plenty of machine learning-based studies have been conducted (Gozes et al., 2020; Li et al., 2020a; Narin et al.,
2020; Zhang et al., 2020; Shan+ et al., 2020). However,
there are still two major challenges: 1) Noisy data, due to
the large variations of data collected in an emergent situation, such as using different reconstruction kernels and
CT manufactures, along with possible patient movements;
2) Confusing cases, due to similar radiological appearance of COVID-19 and other pneumonia, especially in the
early stage. Therefore, how to handle these challenges is
the key for successful identification of COVID-19 from
CAP.
Accordingly, in this work, we propose an uncertainty
based learning framework, called Uncertainty Vertexweighted Hypergraph Learning (UVHL), to identify
COVID-19 from CAP with CT images. The most essential task is to exploit the latent relationship among various COVID-19 cases and CAP cases, and then make a
prediction for a new testing case, i.e., whether belonging to COVID-19 or not. The proposed framework employs a vertex-weighted hypergraph structure to formulate data correlation among different cases. The module of “uncertainty score measurement” is used to generate two metrics, i.e., 1) noisy data aleatoric uncertainty
and 2) the models inability epistemic uncertainty. Then,
the proposed UVHL conducts learning on the hypergraph
structure to make a prediction for the new testing case,
by simultaneously a) incorporating the uncertainty values of measured data to relieve the misleading patterns
from noisy low-quality data and b) allocating more attention to the nodes distributing around the classifying
interface in the latent representation space. Another ad-

Figure 1: Illustration of lung CT image, infection, lung lobes, and pulmonary segments on a CAP case (left) and a COVID-19 case (right).

vantage of the proposed framework is its flexibility in utilizing multi-modal data/features when available. We apply our proposed method to a large dataset, with 2,148
COVID-19 cases and 1,182 CAP cases. The experimental
results show that our proposed method can achieve a satisfactory accuracy of 90% for identification of COVID-19
from CAP.
The main contributions of this paper are summarized as
follows:
• We propose to formulate data correlation among all
COVID-19 and CAP cases using hypergraph, for exploring high-order relationship using multi-type CT
features (such as regional features and radiomics features).
• We propose an uncertainty vertex-weighted strategy
to relieve the influence of noisy (CT) data collected
from suspected COVID-19 patients in emergent situation.
• We have demonstrated better performance in the task
of identifying COVID-19 from CAP, and have also
shown how different types of CT features perform in
this task.

2

2. Related Work

infection patches need to be manually labeled. Another issue is the correlation among the COVID-19 cases and the
In this section, we briefly review recent works on di- CAP cases, which is important to identify the category of
agnosing COVID-19 and introduce current studies on hy- a new testing case.
pergraph learning.
2.2. Preliminary on Hypergraph Learning
Hypergraph learning has been widely applied in
many tasks, such as identifying non-random structure
in structural connectivity of the cortical microcircuits
(Dotko et al., 2016), identifying high-order brain connectome biomarkers for disease diagnosis (Zu et al., 2016),
and studying the co-relationships between functional and
structural connectome data (Munsell et al., 2016). Hypergraph learning was first introduced in (Zhou et al., 2007),
in which each node represents one case, each hyperedge
captures the correlation between each pair of nodes, and
the learning process is conducted on a hypergraph as a
propagation process. By this method, the transductive inference on hypergraph aims to minimize the label differences between vertices that are connected by more and
stronger hyperedges. Then, the hypergraph learning is
conducted as a label propagation process on the hypergraph to obtain the label projection matrix (Liu et al.,
2017), or as a spectral clustering (Li and Milenkovic,
2017).
Other applications of hypergraph learning include
video object segmentation (Huang et al., 2009), images
ranking (Huang et al., 2010), and landmark retrieval
(Zhu et al., 2015). Hypergraph learning has the advantage of modeling high-order correlation modeling, but the
reliability of different vertices on the hypergraph, also important to conduct accurate learning, has not been well
investigated.

2.1. AI-based COVID-19 Diagnosis
As introduced in (Zu et al., 2020), COVID-19 patients
could be divided into mild, moderate, severe and critically
ill stages, according to the severity of disease development. In the mild stage, the pneumonia symptom is difficult to be observed from CT images for a suspected patient. With the development of the disease, ground-glass
opacity (GGO), increased crazy-paving pattern, and consolidation can be observed (Li and Xia, 2020). When it
becomes a serious situation, the symptom will deteriorate
and also the gradual resolution of consolidation could be
observed in CT images.
In the very early studies, several statistics-based
methods (Chen et al., 2020; Li et al., 2020b; Wang et al.,
2020a) are proposed to develop automatic detection and
patient monitoring methods for diagnosis of COVID-19.
However, only simple data statistics is employed in these
methods, which limits the capability of diagnosing suspected patients when facing the challenge of noisy data
and confusing cases.
To further improve the performance, a group of AIbased methods (Narin et al., 2020; Shan+ et al., 2020;
Gozes et al., 2020) are proposed in the following. In
Bernheim et al. (2020); Shan+ et al. (2020); Tang et al.
(2020), reliable representations from CT are learned to
represent the symptom of COVID-19. The co-relationship
between chest CT and RT-PCR testing has also been
investigated in COVID-19 (Ai et al., 2020; Fang et al.,
2020; Xie et al., 2020). Gozes et al. (2020) introduce an
AI-based automatic CT image analysis tool for detection,
quantification, and tracking of coronavirus.
Although there have been plenty of works on AIassisted COVID-19 diagnosis tools, the identification of
COVID-19 from CAP has not fully investigated, which
has become an important issue recently. In this task,
Wang et al. (2020b) propose to classify the patches of infected lesions into COVID-19 or typical viral pneumonia
using the modified and fine-tuned Inception migrationlearning model with the pre-trained weights, in which the

3. Materials and Preprocessing
In this section, we first introduce materials used in this
work and image preprocessing steps. Then, multi-type
features, including regional features and radiomics features from CT images are extracted.
3.1. Dataset
In this study, a total of 3,330 CT images were collected,
including 2,148 from COVID-19 patients and the rest
1,182 from CAP patients. These images were provided
3

Figure 2: Illustration of our proposed Uncertainty Vertex-weighted Hypergraph Learning (UVHL) method for COVID-19 identification.

To generate regional features, we calculate a dimension
of R96 features for each patient, including histogram distribution, infected lesion counting numbers, the mean and
variance grey values of lesion area, lesion surface area,
and additional density and mass features, etc. To generate
radiomics features, radiomics computation is performed
on the infected lesions and a dimension of R93 for each patient is extracted, including the first-order intensity statistics and texture features such as gray level co-occurrence
matrix (Shi et al., 2020). With the information on age and
sex also included, the representations for each patient can
be concatenated as x ∈ R191 overall.

by the Ruijin Hospital of Shanghai Jiao Tong University,
Tongji Hospital of Huazhong University of Science and
Technology, China-Japan Union Hospital of Jilin University, Hangzhou First Peoples Hospital of Zhejiang University, and Shanghai Public Health Clinical Center of Fudan
University. All the COVID-19 cases were confirmed as
positive by RT-PCR and acquired from Jan. 9, 2020 to
Feb. 14, 2020. CAP images were obtained from Jul. 30,
2018 to Feb. 22, 2020. The CT scanners used in this
study include uCT 780 from UIH, Optima CT520, Discovery CT750, LightSpeed 16 from GE, Aquilion ONE
from Toshiba, SOMATOMForce from Siemens, and SCENARIA from Hitachi. The CT protocol here includes:
120 kV, reconstructed CT thickness ranging from 0.625
to 2mm, and breath-hold at full inspiration. All images
were de-identified before sending for analysis. This study
was approved by the Institutional Review Board of participating institutes. Written informed consent was waived
due to retrospective nature of the study.

4. The Method
In this section, we introduce our proposed Uncertainty
Vertex-weighted Hypergraph Learning (UVHL) method
for COVID-19 identification. Figure 2 shows in the
framework of our proposed method, which is composed
of three steps, i.e., 1) “Data Uncertainty Measurement”,
2) “Uncertainty-vertex Hypergraph modeling” and 3)
“Uncertainty-vertex Hypergraph Learning”, respectively.

3.2. Preprocessing
In this study, both regional and radiomics features are
extracted from CT image for each patient. More specifically, we first perform segmentation of left / right lung,
5 lung lobes, and 18 pulmonary segments, as well as infected lesions by deep learning based network, i.e., VBNet, in a portal software (Shan+ et al., 2020), for each CT
image.

4.1. Data Uncertainty Measurement
As introduced before, the data quality may suffer from
the unstable, noisy nature caused in the emergent situation. To overcall this limitation, it is important to identify the reliability of different cases during the learning
processing. In this step, a data uncertainty measurement
4

Note that log (2π)/2 and H (PD (x)) are redundant for
process is conducted to generate uncertainty scores for all
cases used in the learning processing. Here, two types of optimization. Therefore, for N samples, we can rewrite
the loss function as Eq. 3:
uncertainty factors are calculated in our method.
!
N
1 X 1
1
a. Aleatoric Uncertainty. The data is abnormal, noisy
L(Θ) =
exp(−αΘ (xi ))CE(yi , fΘ (xi ))+ αΘ (xi )
N i 2
2
or collected by mistake with low quality.
(3)
b. Epistemic Uncertainty. The features of these cases
If
the
Cross-Entropy
between
the
predicted
y
(x
)
and
lie around the decision boundary that makes the disΘ i
true label yi is quite large, the model tends to predict a
tinguishing model under a serious challenge.
higher αΘ (xi ) to make inputs with high uncertainty havWe will introduce how to calculate these uncertainty ing a smaller effect on the loss. This allows the network
to learn to attenuate the effect from erroneous labels, thus
scores in details as below.
becoming more robust to noisy data. In our task, we denote AΘ (xi ) as aleatoric uncertainty to identify low qual4.1.1. Aleatoric Uncertainty
ity data, as defined in Eq. 4:
The aleatoric uncertainty represents the measure of the
quality measure of noisy data, and is based on the comAΘ (xi ) = σ2Θ (xi ) = exp(αΘ (xi ))
(4)
parison of data distributions. The objective is to estimate
Θ that minimizes the Kullback-Leibler (KL) divergence 4.1.2. Epistemic Uncertainty
between true distribution PD (x) and predicted distribution
Epistemic uncertainty refers to the model’s inability for
PΘ (x) over N training samples:
accurate and precise prediction. To compute this measurement, we use the dropout variation inference, which
N
is a widely adopted practical approach for approximate
1 X
Θ̂ = arg min
(1) inference (Gal and Ghahramani, 2016). The Monte Carlo
DKL (PD (x)kPΘ (x))
N i=1
Θ
estimation method is referred as MC dropout. Our apHence, the loss function can be defined as KL- proximate predictive distribution is given by Eq. 5:
Z
Divergence: L(Θ) = LKL (Θ), which is minimized during
∗ ∗
(y
)
q
|x
=
p (y∗ |x∗ , ω) q(ω)dω
(5)
the training process. In detail, the loss for a single case
can be calculated as Eq. 2:

L
where ω = {Wi }i=1
is a set of random variables for a
model with L layers. x∗ and y∗ denote the input and the
corresponding output of any MC dropout model, respectively. The effect of our MC dropout can be attributed to
impose a Gaussian distribution on each layer during the
test stage. In detail, the multi-layer perception neural network (MLP) model can be trained with dropout. But different from the conventional settings, these dropout layers
are kept open during the testing stage. Each case is predicted for K times, and the epistemic uncertainty for this
case can be calculated using the variance of these K values.
Therefore, the predicted result for one case can be obtained by Eq. 6:

L(Θ) = DKL (PD (x)kPΘ (x))
Z
Z
=
PD (x) log PD (x)dx − PD (x) log PΘ (x)dx


2
CE(y, fΘ (x)) log σΘ (x) log(2π)
=
+
−H(PD (x))
+
2
2
2σ2Θ (x)
(2)
where CE denotes the Cross-Entropy function, x ∈ R191
denotes the feature vector of each patient, y ∈ R2 is the
label, and fΘ : R191 7→ R2 represents the network with
softmax function as the last layer that maps features to the
corresponding binary prediction. H(PD (x)) stands for the
entropy of PD (x). σ2Θ denotes the predicted variance. To
avoid the potential division by zero, we replace log σ2Θ (x)
by αΘ (x). Therefore, αΘ : R191 7→ R1 can be used to
predict the uncertainty score for each case.

Eq(y∗ |x∗ ) (y∗ ) ≈

5

K
1 X ∗  ∗ k
b
y x ,ω
K k=1

(6)

number of cases involved. Given the two types of features, i.e., the regional features and radiomics features,
two groups of hyperedges are generated to build the connections among these cases. For the regional features,
each time one vertex (case) is selected as the centroid,
and its k nearest neighbors (cases) are selected to be connected by one hyperedge. This process repeats until all
vertices have been selected once. Then, a group of hyperedges based on the regional feature can be generated.
The same process is performed for the radiomics feature,
which generates another group of hyperedges. These two
groups of hyperedges are concatenated to build the final
hypergraph.
Different from conventional hypergraph, the
uncertainty-vertex hypergraph not only cares about
features F and the label L of each vertex, but also
considers the uncertainty U of each vertex. In this way,
these more reliable vertices could contribute more during
the learning process, and vice versa. Here, V is the vertex
set, E is the hyperedges set, and W is the pre-defined
matrix of hyperedge weights. Besides these, U denotes
the uncertainty matrix for all the vertices. Therefore,
our uncertainty-vertex hypergraph can be written as
G = hV, E, W, Ui. Leveraging vertex weights U, an
incidence matrix H is then generated to represent the
relationship among different vertices.
(
Ui , vi ∈ e p
H(vi , e p ) =
(10)
0, vi < e p

or more specifically by Eq. 7 in our task:
E( fΘb (xi )) ≈

K
1 X
fb k (xi )
K k=1 Θ(ω )

(7)

Combined with aleatoric uncertainty introduced before, the epistemic uncertainty can be approximated
as (Kendall and Gal, 2017) in Eq. 8:

E ( fΘb (xi )) ≈AΘb (xi ) +

K
1 X
fb k (xi )T fΘ(ω
b k ) (xi )
K k=1 Θ(ω )

(8)

T
− E( fΘ(ω
b k ) (xi )) E( fΘ(ω
b k ) (xi ))

where i denotes the ith sample and k denotes the kth test
with dropout.
Note that E ( fΘb (xi )) ≈ AΘb (xi ) (epistemic uncertainty) is
mainly composed of aleatoric uncertainty. Consequently,
when E ( fΘb (xi )) gets higher, it mainly represents lower
data quality instead of the limitation on classification capability.
To normalize the epistemic uncertainty E ( fΘb (xi )), its
mean and standard deviation in the whole dataset can
be calculated as µe , se . Then, sigmoid function σ(·) is
adopted to ensure the uncertainty score ranging from 0
to 1. λ is an adjustable parameter, to make different uncertainty cases more distinctive. If the λ is set to positive,
the cases with the high uncertainty score will be adjusted
higher, the cases with the low uncertainty score will be
lower, and vice versa. Weights of all data are shown in
In the end of this stage, the uncertainty vertex-weighted
Eq. 9:
hypergraph is constructed to represent the correlation
!
E ( fΘb (xi )) − µe
(9) among all cases.
Ui = σ λ
se
In the end of this step, by leveraging the uncertainty, the 4.3. Uncertainty-vertex Hypergraph Learning
quality of data is measured and also the weighted vertices
As shown in Fig. 3, compared with the conventional hyare generated accordingly.
pergraph learning method, the proposed UVHL structure
considers the uncertainty of each vertex individually and
4.2. Uncertainty-vertex Hypergraph Construction
the learning process is conducted on an unequal space.
To identify the COVID-19 cases, it is important to ex- The learning task on the uncertainty-vertex hypergraph
ploit the data correlation. Here, the hypergraph structure can be formulated as:
is employed to model the relationship among the known
n
o
QU (F) = arg min Ω(F) + λRemp (F)
(11)
training COVID-19 cases, the known training CAP cases,
F
and the unknown testing cases.
More specifically, the smoothness regularizer function
In the hypergraph P = hF , L, Ui, each vertex denotes
one case, and there are totally n vertices according to the Ω(·) and the empirical loss term Remp (·) can be, respec6

5. Experiments
5.1. Evaluation Metrics
In our experiments, six criteria are employed to evaluate the COVID-19 identification performance, and the
definition of the confusion matrix is shown in Table 1.
1. Accuracy (ACC): ACC measures the proportion of
samples that are correctly classified. ACC =
T P+T N
T P+T N+FP+FN .
2. Sensitivity (SEN): SEN measures the proportion of
actual positives that are correctly identified as such.
This metric is also called as “recall”, reflecting the
misdiagnose proportion. In actual medical diagnostic application scenarios, this evaluation metric is
TP
more critical. S EN = T P+FN
.
3. Specificity (SPEC): SPEC measures the proportion
of actual negatives that are correctly identified as
such. It stands for the omission diagnose rate.
TN
.
S PEC = T N+FP
4. Balance (BAC): BAC is the mean value of SEN and
PEC
.
SPEC. BAC = S EN+S
2
5. Positive Predictive Value (PPV): PPV measures the
proportion of detected positives that are true positive.
TP
.
PPV = T P+FP
6. Negative Predictive Value (NPV): NPV measures the
proportion of detected negatives that are true negaTN
.
tive. NPV = T N+FN

Figure 3: Besides the hyperedge weights, the uncertainty-vertex hypergraph contains the uncertainty score of each vertex.
Table 1: The definition of the confusion matrix for COVID-19 identification.

COVID-19
CAP

Classify as COVID-19 Classify as CAP
True Positive (TP)
False Negative (FN)
False Positive (FP)
True Negative (TN)

tively, rewritten as follows:
Ω(F, V, U, E, W) = tr(F⊤ (U⊤ − U⊤ ΘU U)F)
Remp (F, U) =

K
X

F(:, k) − Y(:, k)

2

(12)

k=1

where F(:, k) is the kth column of F and ΘU = 5.2. Compared Methods
1
−1
T −2
Dv 2 HWD−1
The uncertainty vertex-weighted
e H Dv .
The following popular classification approaches are
hypergraph loss function Remp (·) can be further rewritten
used
for comparison:
as:
Remp (F, U) =tr(F⊤ U⊤ UF + Y⊤ U⊤ UY
⊤

⊤

− 2F U UY)

• Support Vector Machine (SVM) (Cortes and Vapnik,
1995): It is a non-probabilistic linear classifier, used
to perform supervised learning. It selects a group
of the training data as support vectors to determine
the boundary that divides different categories apart
as unambiguously as possible.

(13)

Therefore, the target label matrix F can be obtained as:
F = λ(U⊤ − U⊤ ΘU U + λU⊤ U)−1 U⊤ UY

(14)

• Multilayer Perceptron (MLP) Neural Network: As
the fundamental feed-forward artificial neural network, MLP can be utilized to perform binary classification with the cross-entropy as the loss function.

With the generated label matrix F ∈ Rn×K (K = 2 in
our task), the new coming testing case can be identified as
COVID-19 or CAP accordingly.
7

Table 2: Performance comparison of different methods on the pneumonia dataset. (“†” denotes the significance testing, p − value < 0.05.)
Methods
SVM (p-value)
MLP (p-value)
iHL
(p-value)
tHL
(p-value)
UVHL
(std)

ACC
0.84084 1.173e-7
0.84685 4.917e-6
0.85135 5.260e-7
0.86486 3.533e-4
0.89790† ±0.0223

SEN
0.85714 1.438e-6
0.86175 1.082e-5
0.86327 3.415e-4
0.89191 2.851e-4
0.93269† ±0.0291

SPEC
0.81034 4.235e-3
0.81897 0.0153
0.83052 0.0332
0.81743 4.559e-3
0.84000† ±0.0274

BAC
0.83374 1.037e-4
0.84036 2.349e-3
0.84790 7.905e-3
0.85467 0.0197
0.88635† ±0.0210

PPV
0.89423 0.0498
0.89904 0.0507
0.90256 0.2367
0.89898 0.2383
0.90654 ±0.0222

NPV
0.75200 3.283e-6
0.76000 8.777e-9
0.76866 2.088e-8
0.80547 7.071e-5
0.88235† ±0.0383

We randomly divide them into 10 subsets and perform
10-fold cross-validation, in which 9 subfolds are used for
training and the rest one is used for testing each time. The
data splitting process repeats 10 times, and the mean and
standard deviation of all 10 runs are reported as the final
result for comparison. All features are normalized into
[0, 1] in the training dataset, and the offset mean and variance are applied to the testing dataset for data normalization, respectively.
For our UVHL model, K nearest neighbors are connected for each vertex when generating hyperedges. We
note that it is important to generate a suitable hypergraph
structure for representation learning. However, how to select the best K value in this procedure is difficult. A large
K will lead to high dissimilarity insider the hyperedge,
while a small K may be not informative enough to the
overall hypergraph structure. To select a suitable K, the
following strategy is adopted to select K. First, a pool
of candidate K values is set as [2, 3, ..., 20] in our experiments. Given a set of training data and corresponding
testing data, we further split the training data into 5 folds.
The 5-fold cross-validation is conducted on the training
data, where different K are used. We then collect the performance of different K on the training data, and the K
with the best performance is used for testing. In this way,
the selection of K can be fully automatic and optimized.

• Inductive Hypergraph Learning (iHL) (Zhang et al.,
2018): In iHL, all available features are combined
into one single feature, and then a projection is
learned on the hypergraph structure, which is used
to conduct classification task on the pneumonia instances. This model learns the high-order representations from the training set and is evaluated in the
testing set.
• Transductive
Hypergraph
Learning
(tHL)
(Zhou et al., 2007): The transductive learning
on hypergraph is conducted to learn the label matrix.
Both the training data and all testing data are
employed in the hypergraph structure, yet leading
to the commonly used semi-supervised learning
approach.

5.4. Results and Discussions
Experimental results are demonstrated in Fig. 4, and
the detailed mean value and the significance of the t-test
between UVHL and other methods are listed in Table 2.
From these results, we have the following observations:

Figure 4: The performance of UVHL and compared methods. The
results show that UVHL outperforms other methods for all metrics.

1. Our proposed method UVHL achieves the most reliable performance among all metrics. Compared with
SVM and MLP, our approach obtains better performance (i.e., 6.79% and 6.03% relative improvement
in terms of ACC, respectively), demonstrating that

5.3. Implementation
In our experiments, the whole dataset consists of 2,148
COVID-19 cases and 1,182 CAP cases.
8

the hypergraph based approach has the effective ability to tackle the pneumonia identification task.
2. Compared with other hypergraph based methods, i.e., inductive hypergraph learning (iHL)
(Zhang et al., 2018) and transductive hypergraph
learning (tHL) (Zhou et al., 2007), our approach
achieves relative gains of 5.47% and 3.82% in terms
of ACC, respectively.
3. Besides the better sensitivity value, our proposed
UVHL method achieves much higher specificity
value compared with all other methods. This indicates that our proposed method can not only have
high recall of COVID-19 patients but also be effective on filtering CAP patients, which is quite useful
in practice.

achieves the best performance, which demonstrates
the effectiveness of our proposed data uncertainty
strategy.
5.6. Analysis On Feature Types
In this study, there are two types of features from CT,
i.e., regional features and radiomics features. Here, we
evaluate the effectiveness of these two features on the task
of COVID-19 identification. We have conducted experiments with our proposed method using each feature individually. Experimental comparison is demonstrated in
Table 4. Our method using regional feature has higher
sensitivity, while the specificity is relatively lower, compared with the cases of using radiomics features. These
results indicate that regional feature is better in finding
the true positive COVID-19 cases, while radiomics features have the advantage of identifying CAP cases. When
using both types of features in our proposed method, the
performance becomes stable, along with both increasing
sensitivity and specificity, as shown in the last row of Table 4. This observation demonstrates that our proposed
method has the ability of jointly utilizing multi-type features and achieve better performance.

Table 3: Experimental comparison on the data uncertainty measurement.
Weighting strategy
ACC
1
Equal Weight
0.85586
Support Vectors
0.86066
2
3 Aleatoric Uncertainty 0.87387
4 Epistemic Uncertainty 0.88589
5 Proposed Uncertainty 0.89790

SEN
0.88426
0.87021
0.918919
0.90741
0.93269

SPEC
0.80342
0.84442
0.78378
0.84615
0.84000

BAC
0.84384
0.85731
0.85135
0.87678
0.88635

PPV
0.89252
0.90983
0.89474
0.91589
0.90654

NPV
0.789912
0.78137
0.82857
0.83193
0.88235

5.5. Data Uncertainty Study
Table 4: Experimental comparison on different feature types and their
To evaluate the effectiveness of our proposed data un- combination.
certainty method, we further conduct ablation experi- Feature Types ACC SEN SPEC BAC PPV NPV
ments to compare variants of the data uncertainty meaRegional
0.85886 0.90323 0.77586 0.83954 0.88288 0.81081
Radiomics 0.85946 0.86982 0.84182 0.85582 0.90889 0.78012
surement procedure. First, we remove the uncertainty
0.89790 0.93269 0.84000 0.88635 0.90654 0.88235
Both
measurement procedure and treat all cases equally. Secondly, the SVM-based uncertainty score is calculated, instead of that of using MLP. Then, the two uncertainty
measurements are used individually for comparison. Ex- 5.7. Analysis on Few Labeled Data
perimental results are reported in Table 3, from which we
As the large-scale labeled data for COVID-19 is excan have the following observations:
pensive and maybe infeasible in emergent situations, how
1. Compared with the method without uncertainty, i.e., these methods perform with very limited labeled data is
with equal weights, all the other methods with un- an important issue. It should be noted that we have not
certainty can achieve better performance.
included MLP, as MLP performs very badly when hav2. The method with uncertainty from SVM performs ing very few training data. To do that, we investigate how
worse than that of using MLP. It indicates that MLP the compared methods work with respect to a small scale
has better identification effectiveness compared with of labeled data from 10 to 100 for COVID-19 and CAP
SVM on uncertainty measurement.
respectively. In these experiments, 100 cases for each cat3. Compared with the case of using aleatoric uncer- egory are selected as the validation data. The training
tainty and epistemic uncertainty individually, the data selection process repeats 10 times and the average
use of both uncertainties, i.e., the proposed method, performance is calculated for comparison. Experimental
9

SVM
tHL
iHL
UVHL

0.75
0.70
10

20

30

40
50
60
70
Training Data Scale

80

90

0.75
0.70

100

10

SVM
tHL
iHL
UVHL

0.75
0.70
0.65

10

20

30

40
50
60
70
Training Data Scale

80

90

100

PPV

BAC

0.85
0.80

SVM
tHL
iHL
UVHL

0.80

20

30

40
50
60
70
Training Data Scale

80

90

0.90
0.88
0.86
0.84
0.82
0.80
0.78
0.76

100

SVM
tHL
iHL
UVHL

10

20

30

40
50
60
70
Training Data Scale

80

90

0.825
0.800
0.775
0.750
0.725
0.700
0.675
0.650

100

SVM
tHL
iHL
UVHL

10

NPV

0.80

SEN

ACC

0.85

SPEC

0.90

0.85

20

30

40
50
60
70
Training Data Scale

80

90

0.85
0.80
0.75
0.70
0.65
0.60
0.55

100

SVM
tHL
iHL
UVHL

10

20

30

40
50
60
70
Training Data Scale

80

90

100

Figure 5: Performance comparison with respect to different scales of training data.

results are shown in Fig. 5. As shown in these results,
we can observe that SVM performs inferior in all settings
when given just very few labeled data, and the hypergraph
based methods perform the best. We can also observe that
our proposed method, i.e., UVHL, can achieve very stable
performance when only a few labeled data are available,
which justifies the effectiveness of our proposed method
in these difficult situations.

method on identification of COVID-19 in comparison to
the existing state-of-the-art methods.
In future work, the effectiveness of each individual feature should be fully investigated. Regarding the limited
data and possible evolution of COVID-19, it is important
to explore small sample learning methods as well as transfer learning techniques on this difficult task of identifying
COVID-19.

6. Conclusion

References

In this paper, we propose an uncertainty vertexweighted hypergraph learning method to identify
COVID-19 from CAP using CT images. Confronting
the challenging issues from noisy data and confusing
cases with similar clinical manifestations and imaging
features, our proposed method employs a hypergraph
structure to formulate the data correlation among the
known COVID-19 cases, the known as CAP cases,
and the testing cases. Through this method, two types
of CT image features (including regional features and
radiomics features) are extracted for patient representation. To overcome the limitations of the noisy data, a
data uncertainty measurement process is conducted to
measure the uncertainty of each training case. Finally,
a vertex-weighted hypergraph learning process is used
to predict whether a new case is COVID-19 or CAP.
We have conducted experiments on a large multi-center
pneumonia dataset, including 2,148 COVID-19 cases and
1,182 CAP cases from 5 hospitals, and the experimental
results demonstrate the effectiveness of our proposed

Ai, T., Yang, Z., Hou, H., Zhan, C., Chen, C., Lv, W., Tao,
Q., Sun, Z., Xia, L., 2020. Correlation of chest ct and
rt-pcr testing in coronavirus disease 2019 (covid-19) in
china: a report of 1014 cases. Radiology , 200642.
Bernheim, A., Mei, X., Huang, M., Yang, Y., Fayad,
Z.A., Zhang, N., Diao, K., Lin, B., Zhu, X., Li, K.,
et al., 2020. Chest ct findings in coronavirus disease-19
(covid-19): relationship to duration of infection. Radiology , 200463.
Chen, N., Zhou, M., Dong, X., Qu, J., Gong, F., Han,
Y., Qiu, Y., Wang, J., Liu, Y., Wei, Y., et al., 2020.
Epidemiological and clinical characteristics of 99 cases
of 2019 novel coronavirus pneumonia in wuhan, china:
a descriptive study. The Lancet 395, 507–513.
Cortes, C., Vapnik, V., 1995. Support-vector networks.
Machine learning 20, 273–297.
Dotko, P., Hess, K., Levi, R., Nolte, M., Reimann, M.,
Scolamiero, M., Turner, K., Muller, E., Markram, H.,

10

2016. Topological analysis of the connectome of digital Li, Q., Guan, X., Wu, P., Wang, X., Zhou, L., Tong, Y.,
Ren, R., Leung, K.S., Lau, E.H., Wong, J.Y., et al.,
reconstructions of neural microcircuits. arXiv preprint
arXiv:1601.01580 .
2020b. Early transmission dynamics in wuhan, china,
of novel coronavirus–infected pneumonia. New EngFang, Y., Zhang, H., Xie, J., Lin, M., Ying, L., Pang, P.,
land Journal of Medicine .
Ji, W., 2020. Sensitivity of chest ct for covid-19: comparison to rt-pcr. Radiology , 200432.
Li, Y., Xia, L., 2020. Coronavirus disease 2019 (covid19): Role of chest ct in diagnosis and management.
Gal, Y., Ghahramani, Z., 2016. Dropout as a bayesian
American Journal of Roentgenology , 1–7.
approximation: Representing model uncertainty in
deep learning, in: international conference on machine Liu, M., Zhang, J., Yap, P.T., Shen, D., 2017. Viewlearning, pp. 1050–1059.
aligned hypergraph learning for alzheimers disease diagnosis with incomplete multi-modality data. Medical
Gozes, O., Frid-Adar, M., Greenspan, H., Browning, P.D.,
image analysis 36, 123–134.
Zhang, H., Ji, W., Bernheim, A., Siegel, E., 2020.
Rapid ai development cycle for the coronavirus (covid- Munsell, B.C., Wu, G., Gao, Y., Desisto, N., Styner,
19) pandemic: Initial results for automated detection &
M., 2016. Identifying relationships in functional and
patient monitoring using deep learning ct image analystructural connectome data using a hypergraph learning
sis. arXiv preprint arXiv:2003.05037 .
method, in: International Conference on Medical Image Computing and Computer-Assisted Intervention,
Holshue, M.L., DeBolt, C., Lindquist, S., Lofy, K.H.,
Springer. pp. 9–17.
Wiesman, J., Bruce, H., Spitters, C., Ericson, K., Wilkerson, S., Tural, A., et al., 2020. First case of 2019 Narin, A., Kaya, C., Pamuk, Z., 2020. Automatic denovel coronavirus in the united states. New England
tection of coronavirus disease (covid-19) using x-ray
Journal of Medicine .
images and deep convolutional neural networks. arXiv
preprint arXiv:2003.10849 .
Huang, Y., Liu, Q., Metaxas, D., 2009. ] video object
segmentation by hypergraph cut, in: 2009 IEEE confer- of National Health Committee, G.O., et al., . Office of
ence on computer vision and pattern recognition, IEEE.
state administration of traditional chinese medicine. nopp. 1738–1745.
tice on the issuance of a programme for the diagnosis and treatment of novel coronavirus (2019-ncov) inHuang, Y., Liu, Q., Zhang, S., Metaxas, D.N., 2010. Imfected pneumonia (trial sixth edition). 2020.
age retrieval via probabilistic hypergraph ranking, in:
2010 IEEE Computer Society Conference on Computer
Shan+, F., Gao+, Y., Wang, J., Shi, W., Shi, N., Han, M.,
Vision and Pattern Recognition, IEEE. pp. 3376–3383.
Xue, Z., Shen, D., Shi, Y., 2020. Lung infection quantification of covid-19 in ct images with deep learning.
Kendall, A., Gal, Y., 2017. What uncertainties do we need
arXiv preprint arXiv:2003.04655 .
in bayesian deep learning for computer vision?, in: Advances in neural information processing systems, pp.
Shi, F., Xia, L., Shan, F., Wu, D., Wei, Y., Yuan, H.,
5574–5584.
Jiang, H., Gao, Y., Sui, H., Shen, D., 2020. Large-scale
screening of covid-19 from community acquired pneuLi, L., Qin, L., Xu, Z., Yin, Y., Wang, X., Kong, B., Bai,
monia using infection size-aware classification. arXiv
J., Lu, Y., Fang, Z., Song, Q., et al., 2020a. Artificial inpreprint arXiv:2003.09860 .
telligence distinguishes covid-19 from community acquired pneumonia on chest ct. Radiology , 200905.
Tang, Z., Zhao, W., Xie, X., Zhong, Z., Shi, F., Liu, J.,
Li, P., Milenkovic, O., 2017. Inhomogeneous hypergraph
Shen, D., 2020. Severity assessment of coronavirus disclustering with applications, in: Advances in Neural Inease 2019 (covid-19) using quantitative features from
formation Processing Systems, pp. 2308–2318.
chest ct images. arXiv preprint arXiv:2003.11988 .
11

Wang, D., Hu, B., Hu, C., Zhu, F., Liu, X., Zhang, J.,
Wang, B., Xiang, H., Cheng, Z., Xiong, Y., et al.,
2020a. Clinical characteristics of 138 hospitalized patients with 2019 novel coronavirus–infected pneumonia in wuhan, china. Jama .
Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J.,
Cai, M., Yang, J., Li, Y., Meng, X., et al., 2020b. A
deep learning algorithm using ct images to screen for
corona virus disease (covid-19). medRxiv .
Xie, X., Zhong, Z., Zhao, W., Zheng, C., Wang, F., Liu, J.,
2020. Chest ct for typical 2019-ncov pneumonia: relationship to negative rt-pcr testing. Radiology , 200343.
Zhang, J., Xie, Y., Li, Y., Shen, C., Xia, Y., 2020.
Covid-19 screening on chest x-ray images using deep
learning based anomaly detection. arXiv preprint
arXiv:2003.12338 .
Zhang, Z., Lin, H., Zhao, X., Ji, R., Gao, Y., 2018. Inductive multi-hypergraph learning and its application
on view-based 3d object classification. IEEE Transactions on Image Processing 27, 5957–5968.
Zhou, D., Huang, J., Schölkopf, B., 2007. Learning
with hypergraphs: Clustering, classification, and embedding, in: Advances in neural information processing systems, pp. 1601–1608.
Zhu, L., Shen, J., Jin, H., Zheng, R., Xie, L., 2015.
Content-based visual landmark search via multimodal
hypergraph learning. IEEE Transactions on Cybernetics 45, 2756–2769.
Zu, C., Gao, Y., Munsell, B., Kim, M., Peng, Z., Zhu, Y.,
Gao, W., Zhang, D., Shen, D., Wu, G., 2016. Identifying high order brain connectome biomarkers via learning on hypergraph, in: International Workshop on Machine Learning in Medical Imaging, Springer. pp. 1–9.
Zu, Z.Y., Jiang, M.D., Xu, P.P., Chen, W., Ni, Q.Q., Lu,
G.M., Zhang, L.J., 2020. Coronavirus disease 2019
(covid-19): a perspective from china. Radiology ,
200490.

12

