An Automatic System to Monitor the Physical Distance and Face Mask Wearing
of Construction Workers in COVID-19 Pandemic
1

Moein Razavi*
Department of Computer Science and Engineering
Texas A&M University
moeinrazavi@tamu.edu
Vahid Janfaza*
Department of Computer Science
and Engineering
Texas A&M University
vahidjanfaza@tamu.edu

Benyamin Sadeghi
Industrial and Manufacturing
Engineering
University of Wisconsin-Milwaukee
bsadeghi@uwm.edu

Abstract1
The COVID-19 pandemic has caused many shutdowns in
different industries around the world. Sectors such as
infrastructure construction and maintenance projects have
not been suspended due to their significant effect on
people's routine life. In such projects, workers work close
together that makes a high risk of infection. The World
Health Organization recommends wearing a face mask and
practicing physical distancing to mitigate the virus's
spread. This paper developed a computer vision system to
automatically detect the violation of face mask wearing and
physical distancing among construction workers to assure
their safety on infrastructure projects during the pandemic.
For the face mask detection, the paper collected and
annotated 1,000 images, including different types of face
mask wearing, and added them to a pre-existing face mask
dataset to develop a dataset of 1,853 images. Then trained
and tested multiple TensorFlow state-of-the-art object
detection models on the face mask dataset and chose the
Faster R-CNN Inception ResNet V2 network that yielded
the accuracy of 99.8%. For physical distance detection, the
paper employed the Faster R-CNN Inception V2 to detect
people. A transformation matrix was used to eliminate the
camera angle's effect on the object distances on the image.
The Euclidian distance used the pixels of the transformed
image to compute the actual distance between people. A
threshold of six feet was considered to capture physical
distance violation. The paper also used transfer learning
for training the model. The final model was applied on
several videos of road maintenance projects in Houston,
TX, that effectively detected the face mask and physical
distance. We recommend that construction owners use the
proposed system to enhance construction workers' safety in
the pandemic situation.

*
1

Hamed Alikhani*
Department of Engineering
Texas A&M University
hamedalikhani@tamu.edu

These authors contributed equally to this paper
Corresponding author

Ehsan Alikhani
Systems Science and Industrial
Engineering
State University of New York at Binghamton
ealikha1@binghamton.edu

1. Introduction2
The spread of COVID-19 has resulted in more than
1,841,000 global deaths and more than 351,000 deaths in
the US by Dec. 31, 2020 [1]. The spread of virus can be
avoided by mitigating the effect of the virus in the
environment [2], [3] or preventing the virus transfer from
person to person by practicing physical distance and
wearing face masks. WHO defined physical distancing as
keeping at least six feet or two meters distance from others
and recommended that keeping the physical distance and
wearing a face mask can significantly reduce transmission
of the COVID-19 virus [4]–[7]. Like other sectors, the
construction industry has been affected, where unnecessary
projects have been suspended or mitigated people's
interaction. However, many infrastructure projects cannot
be suspended due to their crucial role in people's life.
Therefore, bridge maintenance, street widening, highway
rehabilitation, and other essential infrastructure projects
have been activated again to keep the transportation
system's serviceability. Although infrastructure projects are
activated, the safety of construction workers cannot be
overlooked. Due to the high density of workers in
construction projects, there is a high risk of the infection
spread in construction sites [8]. Therefore, systematic
safety monitoring in infrastructure projects that ensure
maintaining the physical distance and wearing face masks
can enhance construction workers' safety.
In some cases, safety officers can be assigned to
infrastructure projects to inspect workers to detect cases
that either social distancing or face mask wearing is not
satisfied. However, once there are so many workers on a
construction site, it is difficult for the officers to determine
hazardous situations. Also, assigning safety officers
increases the number of people on-site, raising the chance
of transmission even more, and putting workers and officers
in a more dangerous situation. Recently, online video
capturing in construction sites has become very common.

Drones are used in construction projects to record online
videos to manage worksites more efficiently [9]–[11]. The
current system of online video capturing can be used for
safety purposes. An automatic system that uses computer
vision techniques to capture real-time safety violations
from online videos can enhance infrastructure project
workers' safety. This study develops a model using Faster
R-CNN to detect workers who either don't wear a face mask
or don't maintain the physical distance in road projects.
Once a safety violation occurs, the model highlights who
violates the safety rules by a red box in the video.
2. Literature Review
Object detection problems aim to locate and classify
objects in an image [12]. The face mask and physical
distance detection are classified as object detection
problems. Object detection algorithms have been
developing in the past two decades. Since 2014, deep
learning usage in object detection has driven remarkable
breakthroughs, improving accuracy and detection speed
[13].
Object detection is divided into two categories. Onestage detection, such as You Only Look Once (YOLO), and
two-stage detection, such as Region-Based Convolutional
Neural Networks (R-CNN). Two-stage detectors have
higher localization and object recognition accuracy, while
the one-stage detectors achieve greater inference speed
[14]. R-CNN or regions with CNN features (R-CNNs),
introduced by Girshick et al. [15], implements four steps;
First, it selects several regions from an image as object
candidate boxes, then rescales them to a fixed size image.
Second, it uses CNN for feature extraction of each region.
Finally, the features of each region are used to predict the
category of boundary boxes using the SVM classifier [15],
[16]. However, feature extraction of each region is
resource-intensive and time-consuming since candidate
boxes have overlap, making the model perform repetitive
computation. Fast R-CNN handles the issue by taking the
entire image as the input to CNN to extract features [17].
Faster R-CNN speeds up the R-CNN network by replacing
selective search with a Region Proposal Network (RPF) to
reduce the number of candidate boxes [18]–[20]. Faster RCNN is a near-real-time detector [18].
Face mask detection identifies whether a person is
wearing a mask or not in a picture [21], [22]. Physical
distance detection first recognizes people in a picture then
identifies the real distance between them [23]. Since the
beginning of COVID-19 pandemic, studies have been
conducted to detect face masks and physical distancing in
the crowd. Jiang et al. [21] employed a one-stage detector,
called RetinaFaceMask, that used a feature pyramid
network to fuse the high-level semantic information. They
added an attention layer to detect the face mask faster in an
image. They achieved a higher accuracy of detection
comparing with previously developed models. Militante &

Dionisio [24] used the VGG-16 CNN model and achieved
96% of accuracy to detect people who wear a face mask or
not. Rezaei & Azarmi [25] developed a model based on
YOLOv4 to detect face mask wearing and physical
distancing. They trained their model on some accessible big
databases and achieved the precision of 99.8% for a realtime detection. Ahmed et al. [23] employed YOLOv3 to
detect people in the crowd then used the Euclidian distance
to detect the physical distance between two people. They
also used a tracking algorithm to track people who violate
the physical distancing in a video. They achieved an initial
accuracy of 92% and then increased the accuracy by
applying transfer learning to 98%.
Drones are used in construction projects to capture realtime video and provide aerial insights that help catch
problems immediately. Research studies have collected
large scale image data from drones and applied deep
learning techniques to detect objects. Asadi & Han [26]
developed a system to improve data acquisition from drones
in construction. Mirsalar Kamari & Ham [10] used drones'
image data in a construction site to quickly detect areas
vulnerable to the wind in the job site. Li et al. [27]applied
deep learning object detection networks on video captured
from drones to track moving objects. The data obtained
from drones can be used to detect workers and identify
whether they are wearing face masks and practice physical
distancing.
3. Methodology
This research obtains a facemask dataset available on the
internet and increases the number of data by adding more
images. Then, the paper trains multiple Faster R-CNN
object detection models to choose the most accurate model
for face mask detection. For the physical distance detection,
the paper uses a Faster R-CNN model to detect people and
then uses the Euclidian distance to obtain the people's
distance in reality based on the pixel numbers in the image.
Transfer learning is used to increase accuracy. The model
was applied on multiple videos of road maintenance
projects in Houston, TX, to show the performance of the
model.
3.1. Dataset
A part of the dataset of face masks was obtained from
MakeML website [28] that contains 853 images that each
image includes one or multiple normal faces with various
illumination and poses. The images are already annotated
with faces with a mask, without mask, and incorrect mask
wearing. To increase the training data 1,000 other images
with their annotations were added to the database. The total
of 1,853 images was used as the facemask dataset. Some
samples of images with their annotations are illustrated in
Figure 1, where three types of face mask wearing are

With mask

With mask

Incorrect+With mask

Without mask

Figure 1. Examples of images in the facemask database
annotated including a correct face mask wearing, incorrect
wearing, and without face mask.

The Faster R-CNN Inception ResNet V2 800*1333 was
selected due to its highest accuracy, i.e., 99.8%.

3.2. Face mask detection

3.3. Physical distance detection

For the face mask detection task, five different object
detection models in the TensorFlow object detection model
Zoo [29] were trained and tested on the face mask dataset
to compare their accuracy and choose the best model for the
face mask detection. Table 1 shows the models and their
accuracies.

The paper used the physical distancing detector model
developed by Roth [31]. The model detects the physical
distancing in three steps; people detection, picture
transformation, and distance measurement. Roth [32]
trained models available on the TensorFlow object
detection model Zoo on the COCO data set that includes
120,000 images. Among all the models, the Faster R-CNN
Inception V2 with coco weights was selected as people
detection through model evaluation due to its highest
detector performance indicator. The picture transformation
was implemented to project the pictures captured by the
camera from an arbitrary angle to the bird's eye view.
Figure 2 shows the original image captured from a
perspective to the vertical view of bird's eye, where the
dimensions in the picture have a linear relationship with
real dimensions [30]. The relationship between pixel of (x,
y) in the bird's eye picture and pixel of (u, v) in the original
picture is defined as:

Table 1. Object detection models and their accuracy on the
Face Mask dataset
# Model
Image
Accuracy
size
1 Faster R-CNN Inception
800*1333 99.8%
ResNet V2
2 Faster R-CNN Inception
640*640
81.8%
ResNet V2
3 Faster R-CNN ResNet 152 640*640
95%
V1
4 SSD ResNet50 V1 FPN
640*640
82%
(RetinaNet50)
5 SSD MobileNet V1 FPN
640*640
93.6%

𝑎!!
𝑥′
! 𝑦′ & = !𝑎"!
𝑎#!
𝑤′

𝑎!"
𝑎""
𝑎#"

𝑎!# 𝑢
𝑎"# & ( 𝑣 +
𝑎## 𝑤

Figure 2. A perspective image transformation to a bird's eye image [30]

Fast R-CNN Network

Object
Classification

ROI
Pooling

Boundry Box
Regression

CNN
Backbone

RPN Proposals
Fully Connected

CNN
Backbone

3×3 conv

Region Proposal Network
(RPN)

Fully Connected

The size of the training dataset for the face mask
detection is limited. Since the face mask detection model is
a complex network, the scarce data would result in an
overfitted model. Transfer learning is a common technique
in machine learning when the dataset is limited and the
training process is computationally expensive. Transfer

Fully Connected

3.5. Transfer learning

For both networks of face mask detection and physical
distance recognition the Google Colaboratory was used.
Google Colaboratory is a cloud service developed by
Google Research that provides python programming
environment for executing machine learning and data
analysis codes and provides free access to different types of
GPUs including Nvidia K80s, T4s, P4s and P100s and
includes leading deep learning libraries [36]. In this
experiment, for the face detection, we used the batch size of
1, the momentum optimizer of value 0.9 with cosine decay
learning rate (learning rate base of 0.008), and the image
size of 800*1333. The maximum number of steps was
200,000 and the training of the model was stopped when the
classification loss reached below 0.07, that happened in
near the 42,000th step (Figure 4). For the physical distance
detection model, we used the batch size of 1, the total
number of steps of 200,000, and the momentum optimizer
of value 0.9 with manual step learning rate. The first step
was from zero to 90,000, where the learning rate was 2e-4,
the second step was from 90,000 to 120,000, where the
learning rate was 2e-5, and the third step was from 120,000
to 200,000, where the learning rate was 2e-6.

1×1 conv

Figure 3 shows a schematic architecture of the Faster RCNN model. The Faster R-CNN includes the Region
Proposal Network (RPN) and the Fast R-CNN as the
detector network. The input image is passed through the
Convolutional Neural Networks (CNN) Backbone to
extract the features. The RPN then suggests bounding boxes
that are used in the Region of Interest (ROI) pooling layer
to perform pooling on the image's features. Then, the
network passes the output of the ROI pooling layer through
two Fully Connected (FC) layers to provide the input of a
pair of FC layers that one of them determines the class of
each object and the other one performs a regression to
improve the proposed boundary boxes [17], [18], [34].

4. Results and discussion

1×1 conv

3.4. Faster R-CNN model

learning uses the weights of a pre-trained model on a big
dataset in a similar network as the starting point in training
[35]. In this research, we used the weights of the
TensorFlow pre-trained object detection models for the
model training.

Fully Connected

Where x=x′/w′ and y=y′/w′. For the transformation matrix,
the OpenCV library in Python was used [33]. Finally, the
distance between each pair of people is measured by
estimating the distance between the bottom-center point of
each boundary box in the bird's eye view. The actual
physical distance, i.e., two feet, was approximated as 120
pixels in the image [31].

Figure 3. A schematic architecture of the Faster R-CNN

Figure 4. The convergence of the classification loss for the
face mask detection model
The two models of face mask detection and physical
distance recognition were combined. Four videos of road
maintenance projects captured in Houston, TX, were given
to the model as the testing input. Figure 5 shows
screenshots of one moment of each case. In case 1, the
model detected a worker without a mask with 99% accuracy
and a worker wearing a mask with 97% accuracy. The
model also highlighted workers who don't practice physical
distancing with a red box indicating a zone with a high risk
of infection and a person far from others with a green box
suggesting a safe zone. In case 2, the model detected an
incorrect mask wearing and a correct mask wearing with
89% and 94% accuracy, respectively. The model indicated
that the workers are keeping the physical distance. The
slight drop in the accuracy of the incorrect mask wearing is
because of the smaller number of training data for the
incorrect face mask wearing case in the dataset. Case 3 and
4 indicate high accuracy of face masks and physical
distancing detection. In case 3, the model detected a face
mask for the worker on the left side of the image with a
relatively lower accuracy due to the lower number of
training data for a rotating head with this type of mask
wearing. However, the output cases indicate a reliable
accuracy of face mask and physical distance detection of
workers in road projects.

Case #2

Case #3

Case #4
Figure 5. The application of the model on four road
construction cases
5. Conclusion

Case #1

This paper developed a model to detect face mask
wearing and physical distancing among construction
workers to assure their safety in the COVID-19 pandemic.
The paper found a facemask dataset including images of
people with mask, without mask, and incorrect mask
wearing. To increase the training dataset, 1,000 images with
different types of mask wearing were collected and added
to the dataset to create a dataset with 1,853 images. A Faster
R-CNN Inception ResNet V2 network was chosen among
different models that yielded the accuracy of 99.8% for face

mask detection. For physical distance detection, the Faster
R-CNN Inception V2 was used to detect people and a
transformation matrix was used to remove the effect of the
camera angle on actual distance. The Euclidian distance
converted the pixels of the transformed image to people’s
real distance. The model set a threshold of six feet to
capture physical distance violation. Transfer learning was
used for training models. Four videos of actual road
maintenance projects in Houston, TX, were used to evaluate
the combined model. The output of the four cases indicated
an average of more than 90% accuracy in detecting
different types of mask wearing in construction workers.
Also, the model accurately detected workers who were too
close and didn't practice the physical distancing. Road
project owners and contractors can use the model results to
monitor workers to avoid infection and enhance workers'
safety. Future studies can employ the model on other
construction projects such as building projects. Also, future
studies can try other detection models and tune the hyperparameters to increase the detection accuracy.

[8]

[9]

[10]

[11]
References
[1]
Johns Hopkins University, “COVID-19 Map Johns Hopkins Coronavirus Resource Center,”
Johns Hopkins Coronavirus Resource Center,
2020.
https://coronavirus.jhu.edu/map.html
(accessed Jul. 30, 2020).
[2]
WHO, “Water, sanitation, hygiene and waste
management for COVID-19: technical brief, 03
March 2020,” World Health Organization, 2020.
[3]
R. Jahromi, V. Mogharab, H. Jahromi, and A.
Avazpour, “Synergistic effects of anionic
surfactants on coronavirus (SARS-CoV-2)
virucidal efficiency of sanitizing fluids to fight
COVID-19,” bioRxiv, p. 2020.05.29.124107, Jun.
2020, doi: 10.1101/2020.05.29.124107.
[4]
R. Ellis, “WHO Changes Stance, Says Public
Should
Wear
Masks,”
2020.
https://www.webmd.com/lung/news/20200608/wh
o-changes-stance-says-public-should-wear-masks
(accessed Jul. 31, 2020).
[5]
S. Feng, C. Shen, N. Xia, W. Song, M. Fan, and B.
J. Cowling, “Rational use of face masks in the
COVID-19 pandemic,” The Lancet Respiratory
Medicine, vol. 8, no. 5. Lancet Publishing Group,
pp. 434–436, May 01, 2020, doi: 10.1016/S22132600(20)30134-X.
[6]
WHO, “Advice on the use of masks in the context
of COVID-19,” 2020. Accessed: Jul. 31, 2020.
[Online].
Available:
https://www.who.int/publications-.
[7]
WHO, “COVID-19 advice - Know the facts | WHO
Western
Pacific,”
2020.
https://www.who.int/westernpacific/emergencies/c

[12]

[13]

[14]

[15]

[16]

[17]
[18]

ovid-19/information/physical-distancing (accessed
Jul. 31, 2020).
M. Afkhamiaghda and E. Elwakil, “Preliminary
modeling of Coronavirus (COVID-19) spread in
construction industry,” J. Emerg. Manag., vol. 18,
no.
7,
pp.
9–17,
Jul.
2020,
doi:
10.5055/JEM.2020.0481.
M. Kamari and Y. Ham, “Automated Filtering Big
Visual Data from Drones for Enhanced Visual
Analytics in Construction,” in Construction
Research Congress 2018, Mar. 2018, vol. 2018April,
pp.
398–409,
doi:
10.1061/9780784481264.039.
M. Kamari and Y. Ham, “Analyzing Potential Risk
of Wind-Induced Damage in Construction Sites and
Neighboring Communities Using Large-Scale
Visual Data from Drones,” in Construction
Research Congress 2020: Computer Applications Selected Papers from the Construction Research
Congress 2020, 2020, pp. 915–923, doi:
10.1061/9780784482865.097.
Y. Ham and M. Kamari, “Automated content-based
filtering for enhanced vision-based documentation
in construction toward exploiting big visual data
from drones,” Autom. Constr., vol. 105, p. 102831,
Sep. 2019, doi: 10.1016/j.autcon.2019.102831.
L. Liu et al., “Deep Learning for Generic Object
Detection: A Survey,” Int. J. Comput. Vis., vol.
128, no. 2, pp. 261–318, Feb. 2020, doi:
10.1007/s11263-019-01247-4.
Z. Q. Zhao, P. Zheng, S. T. Xu, and X. Wu, “Object
Detection with Deep Learning: A Review,” IEEE
Transactions on Neural Networks and Learning
Systems, vol. 30, no. 11. Institute of Electrical and
Electronics Engineers Inc., pp. 3212–3232, Nov.
01, 2019, doi: 10.1109/TNNLS.2018.2876865.
L. Jiao et al., “A survey of deep learning-based
object detection,” IEEE Access, vol. 7, pp. 128837–
128868,
2019,
doi:
10.1109/ACCESS.2019.2939201.
R. Girshick, J. Donahue, T. Darrell, and J. Malik,
“Rich feature hierarchies for accurate object
detection and semantic segmentation,” in
Proceedings of the IEEE Computer Society
Conference on Computer Vision and Pattern
Recognition, Sep. 2014, pp. 580–587, doi:
10.1109/CVPR.2014.81.
Z. Zou, Z. Shi, Y. Guo, and J. Ye, “Object
Detection in 20 Years: A Survey,” 2019, Accessed:
Aug.
02,
2020.
[Online].
Available:
http://arxiv.org/abs/1905.05055.
R. Girshick, “Fast R-CNN,” 2015. Accessed: Aug.
03,
2020.
[Online].
Available:
https://github.com/rbgirshick/.
S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-

[19]

[20]

[21]
[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

CNN: Towards Real-Time Object Detection with
Region Proposal Networks.” pp. 91–99, 2015.
V. Carbune et al., “Fast multi-language LSTMbased online handwriting recognition,” Int. J. Doc.
Anal. Recognit., vol. 23, no. 2, pp. 89–102, 2020,
doi: 10.1007/s10032-020-00350-4.
H. Jiang and E. Learned-Miller, “Face detection
with the faster R-CNN,” in 2017 12th IEEE
International Conference on Automatic Face &
Gesture Recognition (FG 2017), 2017, pp. 650–
657.
M. Jiang, X. Fan, and H. Yan, “RetinaMask: A Face
Mask detector,” 2020, [Online]. Available:
http://arxiv.org/abs/2005.03950.
Z. Wang et al., “Masked Face Recognition Dataset
and Application,” Mar. 2020, Accessed: Aug. 02,
2020.
[Online].
Available:
http://arxiv.org/abs/2003.09093.
I. Ahmed, M. Ahmad, J. J. P. C. Rodrigues, G. Jeon,
and S. Din, “A deep learning-based social distance
monitoring framework for COVID-19,” Sustain.
Cities Soc., p. 102571, Nov. 2020, doi:
10.1016/j.scs.2020.102571.
S. V. Militante and N. V. Dionisio, “Real-Time
Facemask Recognition with Alarm System using
Deep Learning,” in 2020 11th IEEE Control and
System Graduate Research Colloquium, ICSGRC
2020 - Proceedings, Aug. 2020, pp. 106–110, doi:
10.1109/ICSGRC49013.2020.9232610.
M. Rezaei and M. Azarmi, “DeepSOCIAL: Social
Distancing Monitoring and Infection Risk
Assessment in COVID-19 Pandemic,” Appl. Sci.,
vol. 10, no. 21, p. 7514, Oct. 2020, doi:
10.3390/app10217514.
K. Asadi and K. Han, “An Integrated Aerial and
Ground Vehicle (UAV-UGV) System for
Automated
Data
Collection
for
Indoor
Construction Sites,” in Construction Research
Congress 2020: Computer Applications - Selected
Papers from the Construction Research Congress
2020, Nov. 2020, pp. 846–855, doi:
10.1061/9780784482865.090.
C. Li, X. Sun, and J. Cai, “Intelligent Mobile Drone
System Based on Real-Time Object Detection,”
JAI, vol. 1, no. 1, pp. 1–8, 2019, doi:
10.32604/jai.2019.06064.
MakeML, “Mask Dataset | MakeML - Create
Neural
Network
with
ease,”
2020.
https://makeml.app/datasets/mask (accessed Nov.
11, 2020).
V. Rathod, A-googler, S. Joglekar, Pkulzc, and
Khanh, “TensorFlow 2 Detection Model Zoo,”
2020.
https://github.com/tensorflow/models/blob/master/
research/object_detection/g3doc/tf2_detection_zo

[30]

[31]

[32]

[33]

[34]

[35]

[36]

o.md (accessed Dec. 23, 2020).
I. S. Kholopov, “Bird’s Eye View Transformation
Technique in Photogrammetric Problem of Object
Size Measuring at Low-altitude Photography,” vol.
133, no. Aime, pp. 318–324, 2017, doi:
10.2991/aime-17.2017.52.
B. Roth, “A social distancing detector using a
Tensorflow object detection model, Python and
OpenCV,” Towards Data Science, 2020.
https://towardsdatascience.com/a-socialdistancing-detector-using-a-tensorflow-objectdetection-model-python-and-opencv-4450a431238
(accessed Dec. 22, 2020).
B. Roth, “GitHub - basileroth75/covid-socialdistancing-detection: Personal social distancing
detector using Python, a Tensorflow model and
OpenCV,”
2020.
https://github.com/basileroth75/covid-socialdistancing-detection (accessed Dec. 22, 2020).
A. Rosebrock, “4 Point OpenCV getPerspective
Transform Example - PyImageSearch,” 2014.
https://www.pyimagesearch.com/2014/08/25/4point-opencv-getperspective-transform-example/
(accessed Dec. 23, 2020).
S. Ananth, “Faster R-CNN for object detection,
Towards
Data
Science,”
2019.
https://towardsdatascience.com/faster-r-cnn-forobject-detection-a-technical-summary474c5b857b46 (accessed Nov. 11, 2020).
A. R. Zamir, A. Sax, W. Shen, L. Guibas, J. Malik,
and S. Savarese, “Taskonomy: Disentangling Task
Transfer Learning,” 2018. Accessed: Jan. 03, 2021.
[Online]. Available: http://taskonomy.vision/.
Colaboratory, “Frequently Asked Questions,”
2020.
https://research.google.com/colaboratory/faq.html
(accessed Nov. 11, 2020).

