D ISCOVERING ASSOCIATIONS IN COVID-19 RELATED

arXiv:2004.03397v1 [cs.IR] 6 Apr 2020

RESEARCH PAPERS

Iztok Fister Jr.
University of Maribor
Maribor, Slovenia
iztok.fister1@um.si

Karin Fister
Department of Infectious Diseases
General Hospital Murska Sobota
Murska Sobota, Slovenia

Iztok Fister
University of Maribor
Maribor, Slovenia

April 8, 2020

A BSTRACT
A COVID-19 pandemic has already proven itself to be a global challenge. It proves how vulnerable
humanity can be. It has also mobilized researchers from different sciences and different countries in
the search for a way to fight this potentially fatal disease. In line with this, our study analyses the
abstracts of papers related to COVID-19 and coronavirus-related-research using association rule text
mining in order to find the most interestingness words, on the one hand, and relationships between
them on the other. Then, a method, called information cartography, was applied for extracting
structured knowledge from a huge amount of association rules. On the basis of these methods, the
purpose of our study was to show how researchers have responded in similar epidemic/pandemic
situations throughout history.
Keywords COVID-19 · data science · metro maps · optimization

1

Introduction

When we look at the COVID-19 Global Cases web site [5, 2] maintained by the Center for Systems Science and
Engineering at Johns Hopkins University, we can observe with concern the comprehensiveness of the pandemic on
the one hand, and an exponential increase in the number of infected people around the world on the other. While the
conditions have stabilized in China, the circumstances in Europe and the USA have become critical. The number of
infected people in Italy, the pandemic’s epicenter in Europe, have achieved almost 60,000 at the time of this writing (i.e.
on 23.3.2020), while the number of deaths is quickly approaching 7,000.
Consequently, the mentioned circumstances have mobilized scientists from different domains around the world to try to
find a way to throttle the coronavirus. These endeavors are not only the domain of researchers in medical labs, where
they are searching for a new vaccine, but all the other mass of researchers from various scientific disciplines being
indirectly affected. In this, data scientists also play an important role.
The present study associates the Association Rule Text Mining (ARTM) [3] method with information cartography [4].
The former is a data mining method used to search for interestingness terms and their mutual relations in the form of
association rules. This method demands the parsing of text documents and highlights the words that are distinguished
according to the appropriate measures. These words are called terms, while the relationships among them are described
in the form of association rules. The latter is devoted to extracting structured knowledge from the huge amount
of association rules generated in the first step. In line with this, the concept of information cartography has been
applied [11] which is capable of creating structured summaries of information, and visualize them in the form of metro
maps. The role of the metro map in helping users understand their surroundings, also is similar to the effect the metro
map of information has on understanding information landscapes [10]. Visualizations with metro maps can even tell
stories to users and provide them with good directions. In essence, the metro maps consist of a set of metro lines, where
each metro line interprets the same story from a different aspect. Metro stops on these lines introduce salient pieces of
information (i.e. a definite term), while the interrelations among these pieces ensure the plot of the story. Recently,

A PREPRINT - A PRIL 8, 2020

this methodology has been applied to understanding information in many areas [9, 12]. However, the concept of metro
maps serves as a basis for exploring the extracted knowledge in this study.
The proposed method consists of the following steps: text preprocessing, generation of ARTM database, association
rule simplification, word graph generation, metro map construction, and the exploration of extracted knowledge. In the
first step, the interestingness words are extracted from a collection of observed paper abstracts. The association rules
are generated from a set of mined words in the second step. The third step is devoted to simplification rules, where the
rules with more antecedents and more consequent are simplified into a set of simple rules consisting of one antecedent
and one consequent. These simple rules serve as building blocks for creating a word graph with source X and sink
nodes Y connected with a directed arc, when there is an association rule X ⇒ Y (fourth step). In the fifth step, the
metro map is created from the word graph. Finally, the knowledge hidden in the metro maps is explored.
The method was applied to a collection of paper abstracts found in the CORD-19 dataset [8] in order to show how
researchers have responded to similar epidemic/pandemic situations during history. Indeed, the results of the performed
experiments have proven an increasing of terms referred to these situations.
In the remainder of the paper, the structure is as follows. Section 2 introduces material and methods used in our study.
In Section 3, the experiments are described and the obtained results are analyzed. A discussion of the results can be
found in Section 4, while the paper is concluded with Section 5, which also provides an outline for the future work.

2

Materials & methods

2.1

Search Strategy

The proposed method consists of three components:
• ARTM:
– text preprocessing,
– generation of an ARTM database,
• information cartography:
– association rule simplification,
– term graph generation,
– metro map construction,
• exploration of extracted knowledge.
The purpose of ARTM is to generate a database of the more interestingness terms. The information cartography enables
us to extract the structured knowledge from a huge amount of association rules in the form of metro maps. The extracted
knowledge in the form of terms, constituting the particular metro lines, serves as keywords for matching the terms from
paper abstracts found in the huge database.
2.1.1

ARTM

Text preprocessing step. Here, punctuation marks are removed as a first step. As a result, only words delimited by
space remain in the document. Some words, like definite and indefinite articles (e.g. the, a, an), connective words (e.g.
and, also, then), conjunctions (e.g. but, when, because), and verbs (e.g. is, done), represent so-called stop words, and
must be removed next. The result of this removal is a sequence of terms. Then, the terms undergo term frequency
calculation, where occurrences are not only determined, but also weighted. Here, a Term Frequency/Inverse Term
Frequency (TF/ITF) weighting scheme is used that penalizes the rare occurring terms with higher weights.
The TF/ITF weighting scheme is defined as follows: For the given term zj , for j = 1, . . . , M , occurring in document
di , for i = 1, . . . , N , the term frequency is expressed as:
TF i,j =

n(di , wj )
,
|di |

(1)

where n(di , wj ) denotes the number of occurrences of term wj in document di , and |di | is the total number of terms in
document Di . On the other hand, the inverse term frequency is expressed as:
ITF j = log
2

n(d|wj )
,
N

(2)

A PREPRINT - A PRIL 8, 2020

where n(d|wj ) denotes the number of documents d containing the term wj , where N is the total number of documents.
Furthermore, the weighted frequency of the term zj in document di is represented as a vector of weights wi =
{wi,1 , . . . , wi,n }, where each element wi,j is expressed as:
wi,j = TF i,j · ITF j ,

for j = 1, . . . , n.

(3)

Finally, the transaction database is generated from the relevant documents by moving each vector wi , representing
weighted frequencies for all terms in the corresponding document, to a transaction database. In this way, the transaction
database is very similar to the market basket, except that the weighted frequencies are put into transaction database
instead of the value of one.
Generation of ARTM database step. The ARTM problem is defined formally as follows: Let us assume a set
of documents D = {d1 , . . . , dN } and set of terms Z = {z1 , . . . , zM }, where N denotes the maximum number of
documents, and M the maximum number of terms, respectively. Additionally, the matrix of weights W is assigned with
the dimension N × M , where each element wi,j represents a frequency weight of term zj in document di , calculated
according a TF-ITF weighting scheme. Then, the task of generation is to select the binary vector y = (y1 , . . . , yM )T ,
determining the presence or absence of the corresponding term in the solution, such that the scalar product
AWS =

M X
N
X

wi,j · yj

(4)

j=1 i=1

subject to
M
X

yj ≤ K,

(5)

j=1

is maximum. Let us mention that variable K denotes the maximum number of terms in an association rule. Actually,
the selected elements of vector y form the set Y = {yj |yj = 1, for j = 1, . . . , M } that is a subset of Z, in other words
Y ⊂ Z. Let us notice that the values of the vector are initially set to zero.
Obviously, the problem is defined as an optimization and can be solved using any of the well-known stochastic
population-based, nature-inspired algorithms. For our study, the Particle Swarm Optimization (PSO) [7] was selected
for this purpose. Interested readers, who would like to see the detailed implementation of this algorithm, are invited to
consult the paper of Fister et al. [3].
2.1.2

Information cartography

The concept of information cartography is applied in order to explore knowledge from an archive of mined association
rules in text [4, 12], where this knowledge is visualized in the form of metro maps. The metro map is formally defined
as M = (G, Π), where G = (T, E) denotes a term graph of vertices T = {X1 , . . . , XN }, representing attributes, and
edges E = {r1 , . . . , rM }, representing simple rules, together with the incident function ψG that associates an ordered
pair ψG (rk ) = (Xi , Yj ) with direct edge rk , when there exists a simple association rule in the form of Xi ⇒ Yj , and
Π represents a set of paths in G. In the definitions, variables N and M denote the maximum number of vertices and
maximum number of edges, respectively.
Association rule simplification. Thus, the simple association rule consists of only one antecedent and one consequent,
where the former is mapped to the source node Xi ∈ G and the latter to the sink node Yj ∈ G of the corresponding
attribute graph, while the path Xi → Yj leads from the source to the sink node.
In general, the association rules in the archive consist of more antecedents and more consequences, in other words:
X1 ∧ X2 ∧ . . . ∧ Xp ⇒ Y1 ∧ Y2 ∧ . . . ∧ Yq .

(6)

The simple association rules are obtained from the mined rules by pairing each antecedent with each consequent, in
other words:
(X1 ⇒ Y1 ), (X1 ⇒ Y2 ), . . . , (Xp ⇒ Yq ).
(7)
In this process of simplifying rules, the p × q pairs of simple rules are obtained representing direct edges in the
association graph.
3

A PREPRINT - A PRIL 8, 2020

Term graph generation. The simple association rules present building blocks from which a term graph is constructed.
In a term graph, each simple rule Xi ⇒ Yi , for i = 1, . . . , p×q, where p designates the maximum number of antecedents
and q the maximum number of consequents, respectively, denotes a direct arc from source node Xi to sink node Yi .
However, the nodes can appear in this graph as: (1) antecedent only, (2) consequent only, or (3) antecedent in one
and consequent in the other rules. Consequently, these are divided into three subsets, i.e. Ante(T ), Cons(T ), and
Mixed (T ). In the term graph G, the attributes in the antecedent subset X ∈ Ante(A) represent source nodes with
indegree zero, the attributes in consequent subset Y ∈ Cons(A) are sink nodes with outdegree zero, while the attributes
in the mixed subset hX|Y i ∈ Mixed (A) denote the intern nodes with an indegree and outdegree higher than zero.
In summary, the antecedent set consists of nodes suitable for starting metro stops on the metro lines, the consequent
set for the final metro stops, while the mixed set determines the intermediate metro stops and outlines a definite path
towards achieving a certain final destination.
Metro map construction. The task of metro map construction is to find a set of metro lines, where each metro
line starts with the particular starting metro stop Xi ∈ Ante(T ) and finishes with the particular final metro stop
Yi ∈ Cons(T ), while the intermediate metro stops connect the starting metro stop with the final one by selecting proper
simple rules from the term graph such that the sink node of the i-th simple rule is the source node of the (i + 1)-th
simple rule, in other words:
X ⇒ Y ≡ X ⇒ Y ≡, . . . , ≡ Xn−1 ⇒ Yx−1 ≡ Xn .
| 0 {z }0 | 1 {z }1
{z
}
|
simple rule 1

|

simple rule 2

(8)

simple rule n

{z

metro line

}

The terms Yi for i = 0, . . . , (n − 1) in Eq. (8) can be avoided due to equivalence Yi ≡ Xi+1 . As a result, a sequence of
implication rules is given, as follows:
X0 ⇒ X1 ⇒, . . . , ⇒ Xn−1 ⇒ Xn .

(9)

According to standard rules in mathematical logic, Eq. (9) can be transformed, as follows:
X1 ∧ X2 ∧ . . . ∧ Xn−1 ⇒ Xn ,

(10)

asserting that the conjunctions of (n − 1) terms implied by the consequent is equivalent to a sequence of implications
of n term. Obviously, Eq. (10) is more easier to apply in an interpretation of the obtained results.
The algorithm for constructing the metro map for visualizing the association rules needs to fulfill the following four
objectives:
•
•
•
•

minimum line coherence,
maximum map size,
high coverage,
high structure quality.

The minimum line coherence limits the number of intermediate metro stops in some metro line and is expressed by the
following relation:
coherence(M) ≤ τ,
(11)
where the variable τ determines the maximum number of intermediate metro stops. The maximum map size is referred
to the maximum number of metro lines L, in other words:
|M| ≤ L.

(12)

Indeed, we are interested in covering our information domain by using the number of metro lines as close to K as
possible.
The coverage estimates how well the selected metro line exploits the attributes in a transaction database. In line with
this, the lift measure of association rule Lift(X ⇒ Y ) is used that is expressed as:
supp(X ∪ Y )
.
(13)
supp(X) × supp(Y )
Let it be noted that the characteristic of the measure is that the higher the value, the stronger the association. Additionally,
the coverage of the whole metro line π ∈ Π is expressed as:
1 X
coverage(π) =
Lift(r),
(14)
|π| r∈π
Lift(X ⇒ Y ) =

4

A PREPRINT - A PRIL 8, 2020

where r represents the particular simple association rule X ⇒ Y . Finally, the coverage of the metro map is a simple
average of all the proposed metro lines, in other words:
coverage(Π) =

1 X
coverage(π).
|M|

(15)

π∈Π

The metro map structure quality refers to the diversity of the metro lines, where we are interested in those metro lines
that differ in the intermediate points as much as possible. This relation is expressed by the following equation:
sQuality(M) =

1 X |{r ∈ πi ∧ s ∈ πj : r 6= s}|
,
C π ∈Π
|πi | × |πj |

(16)

i
πj ∈Π

i6=j

where the variable C =


|M|
2

counts the number of metro line interactions.

In summary, the quality of the solution considers the constructed metro map according to two objectives: the coverage
(according to Eq. (15)), and the quality (according to Eq. (16)). Both equations are contained within a linear combination
as follows:
f (yi ) = (coverage(yi ) + w · (1 − sQuality(yi ))) · ni ,

(17)

where the weight variable w indicates the influence of the second term on the total fitness value, and ni is the number
of metro lines. However, each solution is subject to minimum line coherence, and maximum map size as previously
explained.
A stochastic population-based, nature-inspired evolutionary algorithm was used for the implementation of the metro
map construction. Interested readers are invited to consult the paper of Fister et al. [4] for more details about the
implementation of the evolutionary algorithm.
2.1.3

Exploration of extracted knowledge

Normally, the created metro map of ARTM information is visualized in the sense of real metro maps, where each
metro line consists of a particular number of metro stops. Some metro lines proceed straightforwardly, while some can
interrelate between the other. Obviously, these relationships affect the plot of the story and highlight special events that
can occur either unexpectedly or as an ordinary consequence of some process operation.
In our study, we are interested in identifying the terms that occur in the best metro map according to the fitness function
evaluation. These terms, then, serve as keywords for searching for knowledge hidden in articles of papers saved into a
huge database. The results of these experiments are then visualized using traditional statistical visualization techniques.
2.2

Parameter setting

The proposed search method introduces two stochastic, nature-inspired, population-based algorithms: The former
searches for the optimal binary vector y, in which the value 0 determines that the corresponding term is absent from
the solution and value 1 that it is present in the solution. The latter is reserved for constructing the metro map. Both
algorithms are controlled by some parameters that ensure their proper operation. The parameter setting used during the
experimental work is illustrated in Table 2.
Table 1: Parameter setting of evolutionary algorithm for metro map creation.
Parameter
Maximum number of terms in association rules
Maximum number of intermediate metro stops
Maximum number of metro lines
Weight variable

Abbreviation
K
τ
L
w

Value
10
10
10
0.5

Let us mention that the problem parameters are only captured in the table. The proper values of these parameters were
found after extensive experimental work. Indeed, the detailed setting of algorithm parameters can be found by interested
readers in the corresponding literature [3, 4].
5

A PREPRINT - A PRIL 8, 2020

2.3

Data Extraction and Outcome Measure

The study was divided into two parts: In the first part, the ARTM was conducted on the CORD-19 dataset [8]1 , where
its non-commercial subset was taken into consideration, while the quality of solutions were evaluated by maximizing
Eq. (4). The second part was applied on the MEDLINE2 database. This database consists of medical scientific papers.
Here, the abstracts of all the papers found in the database were parsed using the tool Pubmed Parser in Python [1]. In
this case, the quality of solutions are estimated using Eq. (17).

3

Results

The purpose of our experimental work was to show how researchers have responded to similar epidemic/pandemic
situations throughout history. In line with this, the ARTM method was applied to the CORD-19 dataset. The results
of the method is presented in the word cloud in Fig. 1, from which it can be seen that terms like ”cell”, ”protein”,

Figure 1: A word cloud.
”infection”, and ”patient” occur most frequently in the observed abstracts of the papers.
The goal of our research was to show how researchers reacted to epidemic/pandemic events in the past. In line with this,
terms in association rules constituting the best metro maps according to the fitness function were extracted (i.e., 44
such terms), from which those terms that do not have any connections with medicine were eliminated (i.e., 18 terms).
Finally, the 26 terms that remained are illustrated in Table 2.
Let us mention that the eliminated terms are denoted as crossed out text in the table. All the other regular terms (i.e. 21
without any repetition of the same words) are entered into the second phase of the experiment, where they were used as
keywords to searching for the abstracts of medicine papers maintained in the MEDLINE database from the year 1955
onward. All abstracts matching at least 30 % of the keywords contribute to the final outcome. The number of hits are
depicted in Fig. 2.
Interestingly, the number of hits increased from the year 1955 until 2019 almost exponentially, although there are some
periods of stall (e.g., the year 2013, or period from years 2014 to 2018). This means that the application of terms
like ”viruses”, ”quarantine”, and ”h7n9” have appeared with greater frequency in line with the appearance of different
viruses denoting epidemic/pandemic events over recent years. Once again, the increasing can be observed in the year
2019.
1
2

https://pages.semanticscholar.org/coronavirus-research
ftp://ftp.ncbi.nlm.nih.gov/pubmed/baseline/

6

A PREPRINT - A PRIL 8, 2020

Table 2: The best metro map found using the evolutionary algorithm.
Num.
1
2
3
4
5
6
7
8
9
10

Metro line description
via⇒mitochondrial
produced⇒propagation
three∧study∧transfection∧human∧severe∧viruses∧pneumonia⇒ventilation
act⇒pseudoknots
consistent∧rna∧virus∧transfection∧viral∧review∧identify∧study∧caused⇒cardiac
introduced⇒diagnostic
quarantine⇒taking
pathogens∧diseases⇒truncated
like∧transfection∧different∧virus∧protein∧cells∧study∧viruses∧human∧may⇒downregulation
pulmonary⇒h7n9

0

1955
1956
1957
1958
1959
1960
1961
1962
1963
1964
1965
1966
1967
1968
1969
1970
1971
1972
1973
1974
1975
1976
1977
1978
1979
1980
1981
1982
1983
1984
1985
1986
1987
1988
1989
1990
1991
1992
1993
1994
1995
1996
1997
1998
1999
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015
2016
2017
2018
2019

Hits in MEDLINE

800

Year

Figure 2: Historical review of mined terms according to Table 2.

4

Discussion

The results of the study showed that epidemic/pandemic events affected the production of new scientific papers a lot
during the course of history. On the other hand, these were inspired by the emergence of new viruses or caused a
mutation of old ones. A historical analysis revealed the biggest increase in the number of papers in the years 2013 and
2014. This increase correlates with the outbreak of the MERS disease. Interestingly, in these times, preprints were
not as popular as today [6]. Therefore, a lot of papers struggled during the long-term review process and appeared
many months after the outbreak. Among the terms found using the proposed method, the papers that referred to any
aspect correlated with coronavirus research were mostly distinguished by the types of the virus (e.g. RNA), its clinical
manifestation (e.g. pneumonia), and consequences (e.g. quarantine), the familiarity (e.g. H7N9), or virus description
(e.g. pathogen). Some terms found in the study were hard to define like mitochondrial and pseudoknots.

5

Conclusion

The COVID-19 pandemic has affected the lives of people all over the world. Social isolation and quarantines stopped
the world for many months. Moreover, the catastrophe has entered its zenith at this time. Although no one in the world
expected such dimensions for the pandemic, the situation has shown how susceptible humanity can be.
7

A PREPRINT - A PRIL 8, 2020

The purpose of the study was to show how researchers responded with subjects of their papers in similar epidemic/pandemic situations during history. This study analyzed the abstract of the papers found in the CORD-19
dataset using the ARTM method and extracted knowledge hidden in a large amount of mined association rules with
metro map methodology. The extracted terms were then used as keywords to search the abstracts of papers collected in
the MEDLINE database.
The results of the study showed that the number of papers that include the terms proposed by the metro map method
increased exponentially during the course of history. In the future work, we will try to relate these findings to the
increased usage of antiviral drugs. We speculate that higher consumption of antiviral drugs may lead to the development
of more pathogenic strains like SARS-CoV-2.

References
[1] Titipat Achakulvisut, Daniel Acuna, and Konrad Kording. Pubmed parser: A python parser for pubmed openaccess xml subset and medline xml dataset xml dataset. Journal of Open Source Software, 5(46):1979, 2020.
[2] Ensheng Dong, Hongru Du, and Lauren Gardner. An interactive web-based dashboard to track covid-19 in real
time. The Lancet infectious diseases, 2020.
[3] Iztok Fister Jr, Suash Deb, and Iztok Fister. Population-based metaheuristics for association rule text mining.
arXiv preprint arXiv:2001.06517, 2020.
[4] Iztok Fister Jr and Iztok Fister. Information cartography in association rule mining. arXiv preprint
arXiv:2003.00348, 2020.
[5] Center for Systems Science and Engineering.
Coronavirus COVID-19 Global Cases,
https://coronavirus.jhu.edu/map.html, 2020.
[6] J Kaiser. Are preprints the future of biology? a survival guide for scientists. Science, 485, 2017.
[7] J Kennedy and R Eberhart. Particle swarm optimization. In Neural Networks, 1995. Proceedings., IEEE
International Conference on, volume 4, pages 1942–1948. IEEE, 1995.
[8] Sebastian Kohlmeier, Kyle Lo, Lucy Lu Wang, and JJ Yang. Covid-19 open research dataset (cord-19), March
2020.
[9] Dafna Shahaf, Carlos Guestrin, and Eric Horvitz. Metro maps of science. In Qiang Yang, Deepak Agarwal, and
Jian Pei, editors, KDD, pages 1122–1130. ACM, 2012.
[10] Dafna Shahaf, Carlos Guestrin, and Eric Horvitz. Trains of thought: Generating information maps. In Proceedings
of the 21st International Conference on World Wide Web, WWW ’12, page 899–908, New York, NY, USA, 2012.
Association for Computing Machinery.
[11] Dafna Shahaf, Carlos Guestrin, Eric Horvitz, and Jure Leskovec. A metro map can tell a story, as well as provide
good directions. Communications of the ACM, 58(11):62–73, November 2015.
[12] Dafna Shahaf, Jaewon Yang, Caroline Suen, Jeff Jacobs, Heidi Wang, and Jure Leskovec. Information cartography:
Creating zoomable, large-scale maps of information. In Proceedings of the 19th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, KDD ’13, page 1097–1105, New York, NY, USA, 2013.
Association for Computing Machinery.

8

