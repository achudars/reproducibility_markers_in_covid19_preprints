1

Exploiting Shared Knowledge from Non-COVID
Lesions for Annotation-Efficient COVID-19 CT
Lung Infection Segmentation

arXiv:2012.15564v1 [eess.IV] 31 Dec 2020

Yichi Zhang, Qingcheng Liao, Lin Yuan, He Zhu, Jiezhen Xing, and Jicong Zhang

Abstract—The novel Coronavirus disease (COVID-19) is a
highly contagious virus and has spread all over the world,
posing an extremely serious threat to all countries. Automatic
lung infection segmentation from computed tomography (CT)
plays an important role in the quantitative analysis of COVID19. However, the major challenge lies in the inadequacy of
annotated COVID-19 datasets. Currently, there are several
public non-COVID lung lesion segmentation datasets, providing
the potential for generalizing useful information to the related
COVID-19 segmentation task. In this paper, we propose a novel
relation-driven collaborative learning model for annotationefficient COVID-19 CT lung infection segmentation. The network
consists of encoders with the same architecture and a shared
decoder. The general encoder is adopted to capture general
lung lesion features based on multiple non-COVID lesions, while
the target encoder is adopted to focus on task-specific features
of COVID-19 infections. Features extracted from the two
parallel encoders are concatenated for the subsequent decoder
part. To thoroughly exploit shared knowledge between COVID
and non-COVID lesions, we develop a collaborative learning
scheme to regularize the relation consistency between extracted
features of given input. Other than existing consistency-based
methods that simply enforce the consistency of individual
predictions, our method enforces the consistency of feature
relation among samples, encouraging the model to explore
semantic information from both COVID-19 and non-COVID
cases. Extensive experiments on one public COVID-19 dataset
and two public non-COVID datasets show that our method
achieves superior segmentation performance compared with
existing methods in the absence of sufficient high-quality
COVID-19 annotations.
Index Terms—COVID-19, Computed Tomography, Lung
Infection Segmentation, Few-shot Learning, Knowledge Transfer.

This work is supported by the National Key Research and Development
Program of China (2016YFF0201002), the University Synergy Innovation
Program of Anhui Province (GXXT-2019-044), and the National Natural
Science Foundation of China (61301005). The first two arthors contributed
equally to this work.
Yichi Zhang, Qingcheng Liao and Jiezhen Xing are with School of
Biological Science and Medical Engineering, Beihang University, Beijing,
China.
Lin Yuan is with College of Biomedical Engineering, Taiyuan University
of Technology, Taiyuan, China.
He Zhu is with School of Computer Science and Engineering, Beihang
University, Beijing, China.
Jicong Zhang (corresponding author) is with School of Biological Science
and Medical Engineering, Beihang University, Beijing, China, and with Hefei
Innovation Research Institute, Beihang University, Hefei, China, and with
Beijing Advanced Innovation Centre for Biomedical Engineering, Beijing,
China, and with Beijing Advanced Innovation Centre for Big Data-Based
Precision Medicine, Beijing, China.

I. I NTRODUCTION
INCE the beginning of 2020, the novel coronavirus disease (COVID-19) has spread worldwide, seriously endangering human health. This severe disease has been declared
as a public health emergency of international concern by
the World Health Organization (WHO). Until the end of
September 2020, COVID-19 has caused more than 1,000,000
deaths, posing an extremely serious threat and challenge to all
countries.
As one of the most commonly used imaging methods,
computed tomography (CT) plays an important role in the
fight against COVID-19 [1], [2], [3]. Researchers have proved
that CT images have strong ability to capture typical features
like ground glass and bilateral patchy shadows of affected
patients [4] and are shown to be more sensitive compared
with standard viral nucleic acid detection using real-time
polymerase chain reaction (RT-PCR) for the early diagnosis
of COIVD-19 infection [5]. Besides, CT images can provide
visual evaluation of the extent of lung abnormalities and assist
the process of prognostic [6].
In clinical practice, the segmentation of lung infections
from CT volumes is an important component to assist in
further assessment and quantification of the diseases [7]. Since
manual contour delineation is time-consuming and laborious,
and suffers from inter and intra-observer variabilities [8],
it is of great significance to develop artificial intelligencebased approaches to assist in the automatic segmentation of
COVID-19 infections. Recently, the unprecedented development in deep learning has showed significant improvements
and achieved state-of-the-art performances in many medical

S

Fig. 1. Examples of COVID-19 CT cases showing the large variations of
shape, size and position of lung infections. The upper row shows the raw
image and the lower row shows corresponding annotation of infection areas.

2

image segmentation tasks [9], [10], [11], and deep neural
networks have been widely applied in the global fight against
COVID-19 [12], [13], [14], [15].
However, the success of deep learning methods mainly
requires large amount of high-quality annotated datasets, while
it is impractical to collect large amount of well annotated
data in real clinical approach, especially when radiologists are
busy fighting the coronavirus disease. Additionally, as shown
in Fig.1, the large variations in shape, size and position of
lung infections and large inter-case variations pose great challenges for the segmentation tasks [16]. Therefore, exploring
annotation-efficient COVID-19 lung infection segmentation
methods with limited labelled data has become an urgent need
especially in the current situation.
Currently, there are several public non-COVID lung lesion
datasets due to other clinical practices, such as MSD Lung
for segmentation of lung tumor and NSCLC Pleural Effusion for segmentation of pleural effusion. These non-COVID
datasets may serve as potential profit for generalizing useful
information to the related COVID-19 infection segmentation
task. Wang et al. [17] have proven that pre-training on nonCOVID datasets can improve the segmentation performance of
COVID-19 infection segmentation. However, the improvement
of transfer learning is not stable when encountering large
domain difference between datasets, and shared knowledge
between COVID-19 and non-COVID lung lesions cannot be
fully exploited.
To address these challenges, we propose a novel relationdriven collaborative learning model for annotation-efficient
COVID-19 CT lung infection segmentation by exploiting
shared knowledge from non-COVID lesions. The network
consists of encoders with the same architecture and a shared
decoder. The general encoder is adopted to capture general
lung lesion features based on multiple non-COVID lesions,
while the target encoder is adopted to focus on task-specific
features of COVID-19 infections. Features extracted from the
two parallel encoders are concatenated for the subsequent
decoder part. Besides, we develop a collaborative learning
scheme to exploit shared knowledge between COVID and
non-COVID lesions by regularizing the relation consistency
between extracted features of given input. Our method can
enforce the consistency of feature relation among different
samples and encourage the model to explore semantic information from both COVID-19 and non-COVID cases. The
contributions of this work are summarized as follows:
• We propose a novel relation-driven collaborative learning
model for annotation-efficient segmentation of COVID19 lung infections from CT volumes by leveraging shared
knowledge from non-COVID lesions to improve the
segmentation performance of COVID-19 infections with
limited training data.
• We present a collaborative learning scheme to explore
general semantic information from both COVID-19 and
non-COVID cases by regularizing the relation consistency
between extracted features of given input, so as to encourage the model to learn more general and discriminative
representation of COVID-19 infections for better segmentation performance.

•

We have conducted extensive experiments on one
COVID-19 dataset and two non-COVID lung lesion
datasets. The results show that our method achieves
superior segmentation performance compared with other
methods in the absence of sufficient high-quality COVID19 data.
II. R ELATED W ORK

In this section, we briefly review the research related to
our work. We first review works on annotation-efficient deep
learning for medical image segmentation. Then we review existing works on COVID-19 segmentation and transfer learning
approaches for COVID-19.
A. Annotation-efficient Deep Learning
Compared with natural images, the annotations of medical
images are much harder and more expensive to acquire due
to following problems: 1) annotating medical images heavily
relies on professional diagnosis knowledge of radiologists; 2)
most modalities of medical images like CT are 3D volumes,
which will take much more time and labor for annotation.
To alleviate annotation scarcity, annotation-efficient methods
have received great attention in medical image analysis community [18], [19]. For example, semi-supervised learning aims
at learning from a limited amount of labeled data and a
large amount of unlabeled data, which is an effective way
to explore knowledge from the unlabeled data [20]. Weakly
supervised learning explores the use of weak annotations like
noisy annotations and sparse annotations [21]. Besides, some
approaches also aim at integrating multiple related datasets
to learn general knowledge [22], [23]. To issue the problem
of limited labeled COVID-19 data, in this work, we aim at
utilizing existing non-COVID lung lesion datasets for generalizing useful information to related COVID-19 task, so as
to achieve better segmentation performance with limited indomain training data.
B. Research on COVID-19 Segmentation
Automatic segmentation of COVID-19 infections from CT
volumes is a crucial step to for quantification of the disease
progression. Recently, several approaches have been proposed
for COVID-19 lung infection segmentation. Shan et al. [24]
propose a deep learning-based system for automatic segmentation and quantification of infection regions. Amyar et al.
[25] propose to improve the segmentation performance with
a multi-task learning approach. Other than fully supervised
learning, Zheng et al. [26] develop a weakly-supervised approach to investigate the potential for automatic detection
of COVID-19 based on patient-level label. Fan et al. [27]
present a lung infection segmentation network for 2D CT
slices with semi-supervised strategy. Wang et al. [28] propose
a noise-robust framework to learn from noisy labels for the
pneumonia lesion segmentation task. Yao et al. [29] use a set
of operations to synthesize lesion-like appearances for labelfree segmentation.

COVID-19 CT

Non-COVID

3

G

D
T

Fig. 2. The overview of our proposed relation-driven collaborative learning model, where green and blue represent the data flow of general encoder and target
encoder for COVID-19 infection segmentation, respectively. Extracted features from these two parallel encoders are concatenated for the input of the shared
decoder. To exploit shared knowledge from non-COVID-cases, an additional data flow in orange is adopted. By regularizing the relation consistency between
extracted features of given input, the model is encouraged to explore semantic information from both COVID-19 and non-COVID cases.

C. Transfer Learning Approaches for COVID-19
Transfer learning aims to leverage knowledge and latent
features from other datasets by pre-training models on large
datasets and fine-tuning trained models on downstream tasks.
Due to the problem of limited COVID-19 data, several transfer
learning methods have been applied. For example, Wang et al.
Chouhan [30] propose an ensemble model to combine outputs
from five pre-trained models based on ImageNet. Majeed
et al. [31] adopt transfer learning procedure and propose a
simple CNN architecture with a small number of parameters
to distinguish COVID-19 from normal X-rays. Misra et al.
[32] propose a multi-channel pre-trained ResNet architecture
to facilitate the diagnosis of COVID-19. For segmentation of
COVID-19 infections, Wang et al. [17] evaluate different transfer learning methods and revealed the benefits of transferring
knowledge from non-COVID lung lesions. However, transfer
learning only takes the advantage of existing models, and
non-COVID cases are not utilized in the training procedure
of downstream COVID-19 segmentation tasks. Different from
these existing methods, our method aims at learning from
COVID-19 and non-COVID lung lesions collaboratively to
exploit shared semantic information.
III. M ETHOD
In this section, we first introduce the overview of our
proposed method. Then we provide details of our relationdriven collaborative learning scheme and the overall training
procedure.
A. Overview
An overview of our proposed framework is shown in Fig2.
Following the design of standard U-Net [33], [34], our network

consists of two encoders with the same architecture and a
shared decoder. Since the encoder serves as a contraction to
extract image contextual features, the upper one named general
encoder (G) is adopted to capture general lung lesion features
based on multiple non-COVID lesions, and the lower one
named target encoder (T) is adopted to focus on task-specific
features of the target COVID-19 infection segmentation task.
After that, extracted features from these two parallel encoders
are concatenated together for the input of the decoder. The
shared decoder (D) serves as a symmetric expanding path
to recover the spatial information of the extracted features.
The skip connections between the target encoder and shared
decoder are employed for the fusion of multi-scale features.
c
Given a set of samples {Xic , Yic }N
i=1 from COVID-19
n
n
datasets Sc and a set of samples {Xi , Yin }N
i=1 from nonCOVID datasets Sn , where X and Y denote the CT volume and corresponding annotation of lung lesions. For the
segmentation workflow, the general encoder is applied to
extract general features, while the target encoder is applied
to extract the task-specific features. These extracted features
are concatenated and then fed into the decoder part to get the
final segmentation results. To issue the problem of limited
COVID-19 training data, instead of transferring pre-trained
models to the downstream learning task of X n , we aim
to involve X c collaboratively in the training procedure of
COVID-19 to exploit shared knowledge from non-COVID
cases, which can be used as a guidance for the learning
of target COVID-19 infection segmentation. Specifically, a
relation-driven collaborative learning scheme is applied to
regularize the relation consistency between extracted features
of given input and encourage the model to explore semantic
information.

4

B. Relation-driven Collaborative Learning
Inspired by recent study on relational-driven semisupervised learning [35], we aim to exploit shared knowledge from non-COVID lesions by regularizing the relation
consistency between extracted features of given input, so as
to facilitate the learning procedure of COVID-19 infections.
Based on the assumption that general encoder is adopted to
capture general features of lung lesion, and the target encoder
is adopted to focus on task-specific COVID-19 infection
features, we propose to utilize the relation of features extracted
from these two encoders as guidance for the collaborative
learning approach.
To estimate the feature relation, we model the feature
relation with channel-wise Gram Matrix [36]. For each input
batch with B samples, we average the features within each
batch to get the mean representation. We denote the extracted
feature maps of encoder F ∈ RC×H×W ×D , where H, W
and D represent the spatial dimension of feature maps, and C
represents the channel number. To obtain channel-wise feature
relation, we reshape the feature maps into A ∈ RC×HW D .
After that, we get the channel-wise Gram Matrix as follows:
G = A · (A)T

GC T
G1
, ...,
]
kG1 k2
kGC k 2

X
{X n ,X c }∈{Sn ,Sc }

λG kRG (X n ) − RG (X c )k2

while for target encoder, the extracted target-specific feature
relation matrices are enforced to be more discriminative using
target relation consistency loss LTrc defined as:
LTrc =

X

− λT kRG (X c ) − RT (X c )k2

(5)

(2)
where RG (X c ) and RT (X c ) denote the feature relation
matrices of COVID-19 cases extracted from general encoder
and target encoder, respectively. λG and λT are ramp-up
weighting coefficients that control the trade-off between the
segmentation loss and consistency loss, so as to mitigate the
disturbance of consistency loss at early training stage.
Since the network is supervised by limited COVID-19 cases,
the training may become unstable and with poor generalization
ability. By minimizing feature relation consistency losses LG
rc
and LTrc during the training procedure, the general encoder
and target encoder can be enhanced to capture more general
and discriminative representation, thereby exploring useful
shared knowledge from adequate non-COVID data for better
segmentation performance.

(3)

Besides, to utilize the feature relation for collaborative
learning, the non-COVID cases are additionally fed into
general encoder to explore the general feature representation
and its corresponding feature relation matrix RG (X n ). The
proposed scheme requires the generated feature relation matrices of general encoder to be stable using general relation
consistency loss LG
rc defined as:
LG
rc =

Update θT ,θD with Lseg
Update θG with LG
rc
Update θT with LTrc
Ramp up the weighting coefficients λG and λT
end while
return Trained network N

{X n ,X c }∈{Sn ,Sc }

After the modeling of feature relation, our method regularizes the network to learn more general and discriminative
representation of COVID-19 infections by regularizing the
feature relation consistency among given input, thereby encouraging the network to explore semantic information from
both COVID-19 and non-COVID cases.
For explicit learning, the network is optimized based on
the supervised segmentation loss Lseg between output Ŷ c and
corresponding ground truth Y c . We use the combination of
dice loss Ldice and cross entropy loss Lce as the supervised
segmentation loss, and deep supervision [37] is applied to
obtain multi-scale supervision at different scales. The segmentation loss can be summarized as
Lseg = Ldice (Ŷ c , Y c ) + Lce (Ŷ c , Y c )

9:
10:
11:
12:
13:
14:

(1)

where Gmn is the inner product between the vectorized
activation map of A(m) and A(n) , representing the similarity
between the mth and nth channel. The final feature relation
matrix R is obtained by conducting the L2 normalization for
each row of G as follows:
R=[

Algorithm 1 Training procedure of our proposed framework.
Input: A batch of (X c ,Y c ) from COVID-19 dataset Dc and
(X n ,Y n ) from non-COVID dataset Dn .
Output: Trained network N with parameters θG ,θT ,θD
1: while not converge do
2:
(X c ,Y c ), (X n ,Y n ) ← sampled from Dc and Dn
3:
Generate features of general encoder FG (X c ) and target
encoder FT (X c )
4:
Generate general feature representation FG (X n )
5:
Calculate feature relation matrices RG (X c ), RT (X c )
and RG (X n ) as Eq. (1) and (2)
6:
Generate segmentation output Ŷ c
7:
Calculate segmentation loss Lseg as Eq. (3)
T
8:
Calculate consistency losses LG
rc , Lrc as Eq. (4) and (5)

(4)

C. Overall Training Procedure
Algorithm1 presents the detailed training procedure of our
framework. For the optimation of the network, we update
the target encoder and decoder based on the supervised segmentation loss Lseg . Besides, relation consistency losses LG
rc
and LTrc are used to update the general encoder and target
encoder, respectively. The collaborative learning scheme allow
the two parallel encoders to benefit from each other’s guidance,
encouraging the model to explore semantic information from
both COVID-19 and non-COVID cases.

5

TABLE I
D ETAILS OF 3D U-N ET ARCHITECTURE USED IN OUR EXPERIMENTS . N OTE THAT THE GENERAL ENCODER AND TARGET ENCODER ARE WITH THE SAME
ARCHITECTURE AS SHOWN IN THE LEFT COLUMN .
feature size

encoder (G / T)

1x56x160x192

input

32x56x160x192

conv1

64x56x80x96

decoder (D)
output

conv(1x1x1)-sigmoid

conv(1x3x3)-IN-LReLU

conv10

conv(1x3x3)-IN-LReLU

down1

strided conv(1,2,2)

up10

transposed conv(1,2,2) - conv1

64x56x80x96

conv2

conv(3x3x3)-IN-LReLU

conv9

conv(3x3x3)-IN-LReLU

128x28x40x48

down2

strided conv(2,2,2)

up9

transposed conv(2,2,2) - conv2

128x28x40x48

conv3

conv(3x3x3)-IN-LReLU

conv8

conv(3x3x3)-IN-LReLU

256x14x20x24

down3

strided conv(2,2,2)

up8

transposed conv(2,2,2) - conv3

256x14x20x24

conv4

conv(3x3x3)-IN-LReLU

conv7

conv(3x3x3)-IN-LReLU

320x7x10x12

down4

strided conv(2,2,2)

up7

transposed conv(2,2,2) - conv4

320x7x10x12

conv5

conv(3x3x3)-IN-LReLU

conv6

conv(3x3x3)-IN-LReLU

320x7x5x6

down5

strided conv(1,2,2)

up6

transposed conv(1,2,2) - conv5

IV. E XPERIMENTS
A. Dataset Introduction
1) COVID-19 Dataset: This dataset is released by Coronacases Initiative and Radiopaedial and contains 20 COVID19 CT volumes, which is publicly available at1 . The annotation
of infections is labeled by two radiologists and verified by an
experienced radiologist by Ma et al. [38].
2) Non-COVID Lung Lesion Datasets: In order to explore
relevant information from non-COVID lung lesions to promote
the annotation-efficient training of COVID-19 cases, we select
out two public non-COVID lung lesion segmentation datasets
for our following experiments. The first dataset is MSD Lung
Tumor Dataset of Medical Segmentation Decathlon (MSD)
Challenge [39] in MICCAI 20182 . This dataset is comprised
of patients with non-small cell lung cancer from Stanford
University (Palo Alto, CA, USA) publicly available through
TCIA. The tumor is annotated by an expert thoracic radiologist
and 63 labeled CT volumes are used. The second dataset is
NSCLC Pleural Effusion Dataset3 . This dataset contains 78 CT
volumes with annotation of pleural effusion. To exploit general
features of lung lesions, we combine MSD and NSCLC
datasets to form a non-COVID multi-lesion dataset in the
following experiments.

select 80% of the data for training and the rest of 20% for
validation.
We use 3D U-Net [34] as the backbone network with nnUNet implementation [41]. Since nnU-Net can automatically
adapt preprocessing strategies and network architectures based
on the analysis of given dataset, to unify the setting for our
collaborative learning approach, we manually adjust the patch
size and network architectures to the design of target COVID19 infection segmentation task. The input patch size is set as
56x160x192 with batch size of 2. Stochastic gradient descent
(SGD) optimizer is used for training with initial learning rate
of 0.01 and momentum of 0.99. The detailed structure of the
network is shown in Table I.
Motivated by the evaluation methods of the medical image
segmentation decathlon [39], we employ two complementary metrics to evaluate the segmentation performance. Dice
Similarity Coefficient (DSC), a region-based measure is used
to measure the region mismatch, and Normalized surface
Dice (NSD), a boundary-based measure is used to evaluate
how close the segmentation and ground truth surfaces are
to each other. Both metrics take the values in [0,1] and
higher scores represent better segmentation performance. Let
G and S denote the ground truth and the segmentation result,
respectively. The two metrics are defined as follows:

B. Experimental Settings and Implementation Details
All the experiments in our work are implemented in Pytorch
[40] and trained on NVIDIA Tesla V100 GPUs. To make a
fair comparison, we follow the task settings of COVID-19
benchmarks in [38]. For the COVID-19 dataset, we make 5fold cross validation based on pre-defined dataset split. Each
fold contains 4 scans (20%) for training and 16 scans (80%)
for testing. For non-COVID lung lesion datasets, we randomly
1 https://zenodo.org/record/3757476#.X4ABeYvivid
2 http://medicaldecathlon.com/
3 https://wiki.cancerimagingarchive.net/display/Public/NSCLC-Radiomics

DSC(G, S) =

2|G ∩ S|
;
|G| + |S|
(τ )

N SD(G, S) =
(τ )

(τ )

(6)

(τ )

|∂G ∩ B∂S | + |∂S ∩ B∂G |
.
|∂G| + |∂S|

(7)

where B∂G , B∂S denote the border regions of ground truth
and segmentation surface at a threshold τ to tolerate the
inter-rater variability of the annotators. We set τ = 3mm
for the evaluation of segmentation results in the following
experiments.

6

TABLE II
Q UANTITATIVE RESULTS OF 5- FOLD CROSS VALIDATION OF ABLATION ANALYSIS IN OUR EXPERIMENTS .
DSC

Method

NSD

Fold 0

Fold 1

Fold 2

Fold 3

Fold 4

Avg

Fold 0

Fold 1

Fold 2

Fold 3

Fold 4

Avg

nnUNet Baseline

0.681

0.713

0.662

0.681

0.627

0.673±0.223

0.709

0.718

0.717

0.708

0.649

0.700±0.224

Ours (backbone)

0.689

0.721

0.712

0.720

0.632

0.695±0.205

0.709

0.747

0.770

0.764

0.649

0.728±0.216

0.701

0.727

0.727

0.710

0.625

0.699±0.210

0.747

0.758

0.790

0.763

0.648

0.740±0.221

0.723

0.728

0.718

0.720

0.625

0.703±0.193

0.756

0.760

0.790

0.771

0.631

0.742±0.203

Ours

)

T
(LG
rc +Lrc )

Ours

Baseline

Ground truth

CT Image

Ours

(LG
rc

(a)

(b)

(c)

(d)

(e)

Fig. 3. Visual comparison of COVID-19 infection segmentation results by different methods. As we can see, our method can generate segmentation results
with more accurate boundaries and less segmentation mistakes in small infection areas, which is closer to the ground truth.

C. Ablation Analysis
To investigate the effectiveness of the key components in
our framework, we conduct ablation studies by removing the
feature relation consistency loss. As shown in Table II, it
is observed that all our methods can achieve better performance on all metrics compared with baseline results, showing
the effectiveness of our method. When removing the target
relation consistency, the average segmentation performance
of five folds are degraded by 0.4% and 0.2% on DSC and
NSD, respectively. The result proves that the usage of target
relation consistency loss LTrc can enforce the target encoder
to be more discriminative, so as to improve the segmentation
performance. However, the improvement is susceptible to the
domain difference. Besides, we also conduct experiments of
our backbone by removing the general relation consistency
loss. In this way, the general encoder is frozen and are not

updated during the training procedure, which means that the
knowledge transfer is not available. The experimental results
demonstrate that the average segmentation performance are
degraded by 0.8% and 1.4% on DSC and NSD, showing the
importance of knowledge transfer in our collaborative learning
scheme.
D. Comparison Experiments with State-of-the-art Methods
To demonstrate the effectiveness of our method, we conduct
extensive comparison experiments with other state-of-the-art
methods. To ensure a fair comparison, all methods are experimented with the same network backbone and experimental
settings. Segmentation models trained from scratch with only
COVID-19 cases serve as our baseline results. Besides, as
a simple and intuitive approach, pre-training segmentation
models on non-COVID cases and fine-tuning on COVID-19

7

TABLE III
Q UANTITATIVE RESULTS OF 5- FOLD CROSS VALIDATION OF COMPARISON EXPERIMENTS WITH STATE - OF - THE - ART METHODS . T HE BEST RESULTS ARE
SHOWN IN RED FONT AND THE SECOND BEST RESULTS IN BLUE FONT.
DSC

Method

NSD

Fold 0

Fold 1

Fold 2

Fold 3

Fold 4

Avg

Fold 0

Fold 1

Fold 2

Fold 3

Fold 4

Avg

nnUNet baseline

0.681

0.713

0.662

0.681

0.627

0.673±0.223

0.709

0.718

0.717

0.708

0.649

0.700±0.224

Pre-train on MSD

0.679

0.706

0.724

0.708

0.623

0.688±0.201

0.706

0.708

0.785

0.724

0.642

0.713±0.225

Pre-train on NSCLC

0.696

0.716

0.673

0.690

0.579

0.671±0.228

0.714

0.720

0.734

0.707

0.590

0.693±0.248

Ours (best)

0.723

0.728

0.718

0.720

0.625

0.703±0.193

0.756

0.760

0.790

0.771

0.631

0.742±0.203

0.702

0.736

0.703

0.725

0.612

0.696±0.213

0.715

0.730

0.755

0.754

0.628

0.717±0.227

0.712

0.732

0.721

0.742

0.608

0.703±0.201

0.735

0.740

0.785

0.772

0.629

0.732±0.218

Pre-train on

Multi-lesion∗

Multi-encoder∗ [17]

Note: ∗ denotes the method use additional non-COVID datasets.

cases are utilized as comparison results for learning from both
COVID-19 and non-COVID cases. The quantitative experimental results are shown in Table III. From the results, we
can observe that transferring pre-trained models to COVID19 infection segmentation tasks can generally improve the
performance of training from scratch with only COVID-19
cases on most experiments, and using multi-lesion is superior
to single-lesion when more general representations can be
utilized to help COVID-19 infection tasks, with 2.3% and
1.7% improvements in DSC and NSD, respectively. However,
these transfer learning methods show instability under different
data distribution in five-fold cross validation experiments. The
rationale is that the transfer ability largely depends on the
domain difference between datasets. When there exists a large
domain distance between non-COVID and limited COVID19 training cases, transfer learning may somehow mislead the
learning procedure.

In [17], the authors propose a multi-encoder architecture to
freeze the non-COVID pre-trained encoder as an additional
feature extractor for the training of COVID-19 cases. Features
from the frozen adapted-encoder and reinitialized self-encoder
are concatenated for the subsequent decoder. However, their
workflow is still based on transfer learning, that training a
network first on non-COVID cases and then on COVID19 cases with foregoing pre-trained parameters. The main
limitation is that the learning procedures of two tasks are
separate. Therefore, the shared knowledge of non-COVID
and COVID-19 cases cannot be exploited. It is observed
that our method takes advantage of collaborative learning
between two encoders and interactively improves the overall
learning procedure. As a consequence, our method achieves
the highest segmentation performance with an averaged DSC
of 70.3% and averaged NSD of 74.2%. Visual comparison
of segmentation results is shown in Fig.3. As shown in the
figure, our method can generate segmentation results with
more accurate boundaries in Fig.3(a)(b), and less segmentation
mistakes in small infection areas in Fig.3(c)(d)(e). These
results demonstrate that the collaborative learning approach
can better exploit shared knowledge from non-COVID cases,
leading to better performance when generalizing on test data.

E. Visual Analysis of Our Method
To better analysis the learning procedure and validate the
effectiveness of our method, we show some visual examples
of feature relation matrices at different epochs during the
network training procedure in Fig.4 and Fig.5. The absolute
differences of these two matrices are shown in the right
column in red to clearly visualize the alignment of matrices.
It can be observed in Fig.4 that as the training goes on, the
network gradually produces more meaningful relation matrices
with higher response at the same channel. Meanwhile, the
absolute differences of feature relation matrices extracted from
general encoder are gradually decreased, indicating that the
general encoder learns more general and robust representations
of lung lesions. Besides, as observed in Fig.5, the absolute
differences of general and target feature relation matrices
gradually increase and tend to be stable, indicating that the
target encoder is gradually enforced to be more discriminative.
V. D ISCUSSION
With the outbreak of COVID-19 all over the world, designing effective automated tools for fighting against COVID19 is highly demanded to improve the efficiency of clinical
approaches and reduce the tedious workload of clinicians and
radiologists. However, accurate segmentation of COVID-19
lung infections is a challenging task due to the large appearance variance of COVID-19 lesions of patients in different
severity level, and existing data-driven segmentation methods
mainly rely on large amount of well annotated data. In order
to mitigate the insufficiency of labeled COVID-19 CT scans,
it is essential and meaningful to develop annotation-efficient
segmentation methods for the COVID-19 lung infection segmentation task.
Considering that there are several public non-COVID lung
lesion segmentation datasets due to other clinical practice,
these datasets may serve as potential profit for generalizing
useful information to assist in the related COVID-19 infection segmentation task. Some previous studies also highlight
the usage of non-COVID lung lesions [17], [38]. However,
these existing approaches merely focus on investigating the
transferability in COVID-19 infection segmentation. Although
their results reveal benefits of pre-training on non-COVID

8

Relation Matrix

Absolute Difference

Absolute Difference

Relation Matrix

Epoch 100
Epoch 500

Epoch 500

Epoch 100

Epoch 0

Relation Matrix

Epoch 0

Relation Matrix

0.0

1.0

0.0

1.0

0.0

1.0

0.0

1.0

Fig. 4. Visualization of the general feature relation matrices of non-COVID
cases (left column) and COVID-19 cases (middle column) and their absolute
difference (right column) during the training procedure.

Fig. 5. Visualization of the general feature relation matrix (left column) and
target feature relation matrix (middle column) of COVID-19 cases and their
absolute difference (right column) during the training procedure.

datasets, the improvement is limited when shared knowledge
between COVID-19 and non-COVID lung lesions cannot
be fully utilized. Our experiment reveal that the proposed
collaborative learning scheme can effectively exploit shared
semantic information by regularizing the consistency between
extracted features so as to promote the training procedure in
the absence of sufficient high-quality COVID-19 data.
Although promising performance has been achieved for
learning from non-COVID lesions, the limitation of our
method still exists. Due to the limitation of data, we only
evaluate our method on two non-COVID datasets and one
relatively small COVID-19 dataset. As a near future work, we
plan to extend our method to more diverse datasets with larger
amount of multi-institutional, multi-national cases like [42]
to further enhance the generalization capability of our model
for COVID-19 lung infection segmentation in the absence of
sufficient annotations. In addition, we also plan to extend our
method to other related medical image segmentation tasks
to explore the usage of existing annotations effectively, thus
enhancing the applicability of deep learning methods in realworld applications.

specific feature of target COVID-19 infection. Besides, we
develop a collaborative learning scheme to exploit shared
knowledge from non-COVID lesions by regularizing the relation consistency between extracted features of given input.
Experimental results on two non-COVID datasets and one
COVID-19 dataset demonstrate the superiority of our method
over existing state-of-the-art methods in the absence of sufficient high-quality annotations, illustrating strong potential for
real-world applications in the global fight against COVID-19.

VI. C ONCLUSION
In this paper, we propose a novel multi-lesion collaboratively learning model to exploit shared knowledge from
non-COVID lesions for annotation-efficient COVID-19 lung
infection segmentation from CT volumes. In specific, the
network consists of encoders with the same architecture and
a shared decoder. The general encoder is adopted to capture
general lung lesion features based on multiple non-COVID
lesions and the target encoder is adopted to focus on task-

R EFERENCES
[1] P. J. Mazzone, M. K. Gould, D. A. Arenberg, A. C. Chen, H. K. Choi,
F. C. Detterbeck, et al., “Management of lung nodules and lung cancer
screening during the covid-19 pandemic: Chest expert panel report,”
Chest, 2020.
[2] M. Oudkerk, H. R. Büller, D. Kuijpers, N. van Es, S. F. Oudkerk, T. C.
McLoud, et al., “Diagnosis, prevention, and treatment of thromboembolic complications in covid-19: report of the national institute for public
health of the netherlands,” Radiology, p. 201629, 2020.
[3] Y. Li and L. Xia, “Coronavirus disease 2019 (covid-19): role of chest
ct in diagnosis and management,” American Journal of Roentgenology,
vol. 214, no. 6, pp. 1280–1286, 2020.
[4] M. Chung, A. Bernheim, X. Mei, N. Zhang, M. Huang, X. Zeng,
et al., “Ct imaging features of 2019 novel coronavirus (2019-ncov),”
Radiology, vol. 295, no. 1, pp. 202–207, 2020.
[5] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, et al., “Sensitivity
of chest ct for covid-19: comparison to rt-pcr,” Radiology, p. 200432,
2020.
[6] K. Li, Y. Fang, W. Li, C. Pan, P. Qin, Y. Zhong, et al., “Ct image visual
quantitative evaluation and clinical classification of coronavirus disease
(covid-19),” European Radiology, pp. 1–10, 2020.
[7] F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, et al., “Review of artificial intelligence techniques in imaging data acquisition, segmentation
and diagnosis for covid-19,” IEEE Reviews in Biomedical Engineering,
2020.
[8] L. Joskowicz, D. Cohen, N. Caplan, and J. Sosna, “Inter-observer
variability of manual contour delineation of structures in ct,” European
Radiology, vol. 29, no. 3, pp. 1391–1399, 2019.

9

[9] P. Bilic, P. F. Christ, E. Vorontsov, G. Chlebus, H. Chen, Q. Dou,
et al., “The liver tumor segmentation benchmark (lits),” arXiv preprint
arXiv:1901.04056, 2019.
[10] N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, et al.,
“The state of the art in kidney and kidney tumor segmentation in
contrast-enhanced ct imaging: Results of the kits19 challenge,” Medical
Image Analysis, vol. 67, p. 101821, 2019.
[11] O. Bernard, A. Lalande, C. Zotti, F. Cervenansky, X. Yang, P.-A. Heng,
et al., “Deep learning techniques for automatic mri cardiac multistructures segmentation and diagnosis: is the problem solved?” IEEE
Transactions on Medical Imaging, vol. 37, no. 11, pp. 2514–2525, 2018.
[12] L. Huang, R. Han, T. Ai, P. Yu, H. Kang, Q. Tao, et al., “Serial
quantitative chest ct assessment of covid-19: Deep-learning approach,”
Radiology: Cardiothoracic Imaging, vol. 2, no. 2, p. e200075, 2020.
[13] L. Sun, Z. Mo, F. Yan, L. Xia, F. Shan, Z. Ding, et al., “Adaptive feature
selection guided deep forest for covid-19 classification with chest ct,”
IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 10,
pp. 2798–2805, 2020.
[14] K. Zhang, X. Liu, J. Shen, Z. Li, Y. Sang, X. Wu, et al., “Clinically
applicable ai system for accurate diagnosis, quantitative measurements,
and prognosis of covid-19 pneumonia using computed tomography,”
Cell, 2020.
[15] Z. Wang, Q. Liu, and Q. Dou, “Contrastive cross-site learning with redesigned net for covid-19 ct classification,” IEEE Journal of Biomedical
and Health Informatics, vol. 24, no. 10, pp. 2806–2813, 2020.
[16] X. Ouyang, J. Huo, L. Xia, F. Shan, J. Liu, Z. Mo, et al., “Dual-sampling
attention network for diagnosis of covid-19 from community acquired
pneumonia,” IEEE Transactions on Medical Imaging, 2020.
[17] Y. Wang, Y. Zhang, Y. Liu, J. Tian, C. Zhong, Z. Shi, et al., “Does
non-covid19 lung lesion help? investigating transferability in covid-19
ct image segmentation,” arXiv preprint arXiv:2006.13877, 2020.
[18] V. Cheplygina, M. de Bruijne, and J. P. Pluim, “Not-so-supervised:
a survey of semi-supervised, multi-instance, and transfer learning in
medical image analysis,” Medical Image Analysis, vol. 54, pp. 280–296,
2019.
[19] N. Tajbakhsh, L. Jeyaseelan, Q. Li, J. N. Chiang, Z. Wu, and X. Ding,
“Embracing imperfect datasets: A review of deep learning solutions for
medical image segmentation,” Medical Image Analysis, p. 101693, 2020.
[20] J. E. Van Engelen and H. H. Hoos, “A survey on semi-supervised
learning,” Machine Learning, vol. 109, no. 2, pp. 373–440, 2020.
[21] Z. Ji, Y. Shen, C. Ma, and M. Gao, “Scribble-based hierarchical weakly
supervised learning for brain tumor segmentation,” in International
Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, 2019, pp. 175–183.
[22] R. Huang, Y. Zheng, Z. Hu, S. Zhang, and H. Li, “Multi-organ
segmentation via co-training weight-averaged models from few-organ
datasets,” in International Conference on Medical Image Computing and
Computer-Assisted Intervention. Springer, 2020, pp. 146–155.
[23] J. Zhang, Y. Xie, Y. Xia, and C. Shen, “Dodnet: Learning to segment
multi-organ and tumors from multiple partially labeled datasets,” arXiv
preprint arXiv:2011.10217, 2020.
[24] F. Shan, Y. Gao, J. Wang, W. Shi, N. Shi, M. Han, et al., “Lung
infection quantification of covid-19 in ct images with deep learning,”
arXiv preprint arXiv:2003.04655, 2020.
[25] A. Amyar, R. Modzelewski, H. Li, and S. Ruan, “Multi-task deep learning based ct imaging analysis for covid-19 pneumonia: Classification and
segmentation,” Computers in Biology and Medicine, p. 104037, 2020.
[26] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, et al., “Deep
learning-based detection for covid-19 from chest ct using weak label,”
medRxiv, 2020.
[27] D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, H. Fu, et al., “Inf-net:
Automatic covid-19 lung infection segmentation from ct images,” IEEE
Transactions on Medical Imaging, 2020.
[28] G. Wang, X. Liu, C. Li, Z. Xu, J. Ruan, H. Zhu, et al., “A noise-robust
framework for automatic segmentation of covid-19 pneumonia lesions
from ct images,” IEEE Transactions on Medical Imaging, vol. 39, no. 8,
pp. 2653–2663, 2020.
[29] Q. Yao, L. Xiao, P. Liu, and S. K. Zhou, “Label-free segmentation of
covid-19 lesions in lung ct,” arXiv preprint arXiv:2009.06456, 2020.
[30] V. Chouhan, S. K. Singh, A. Khamparia, D. Gupta, P. Tiwari, C. Moreira,
et al., “A novel transfer learning based approach for pneumonia detection
in chest x-ray images,” Applied Sciences, vol. 10, no. 2, p. 559, 2020.
[31] T. Majeed, R. Rashid, D. Ali, and A. Asaad, “Covid-19 detection using
cnn transfer learning from x-ray images,” medRxiv, 2020.
[32] S. Misra, S. Jeon, S. Lee, R. Managuli, I.-S. Jang, and C. Kim, “Multichannel transfer learning of chest x-ray images for screening of covid19,” Electronics, vol. 9, no. 9, p. 1388, 2020.

[33] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference
on Medical Image Computing and Computer-Assisted Intervention.
Springer, 2015, pp. 234–241.
[34] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger,
“3d u-net: learning dense volumetric segmentation from sparse annotation,” in International Conference on Medical Image Computing and
Computer-Assisted Intervention. Springer, 2016, pp. 424–432.
[35] Q. Liu, L. Yu, L. Luo, Q. Dou, and P. A. Heng, “Semi-supervised medical image classification with relation-driven self-ensembling model,”
IEEE Transactions on Medical Imaging, 2020.
[36] L. Gatys, A. Ecker, and M. Bethge, “A neural algorithm of artistic style,”
Journal of Vision, vol. 16, no. 12, pp. 326–326, 2016.
[37] Q. Dou, H. Chen, Y. Jin, L. Yu, J. Qin, and P.-A. Heng, “3d deeply supervised network for automatic liver segmentation from ct volumes,” in
International Conference on Medical Image Computing and ComputerAssisted Intervention. Springer, 2016, pp. 149–157.
[38] J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, et al., “Towards
data-efficient learning: A benchmark for covid-19 ct lung and infection
segmentation,” Medical physics, 2020.
[39] A. L. Simpson, M. Antonelli, S. Bakas, M. Bilello, K. Farahani,
B. Van Ginneken, et al., “A large annotated medical image dataset for the
development and evaluation of segmentation algorithms,” arXiv preprint
arXiv:1902.09063, 2019.
[40] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, et al.,
“Pytorch: An imperative style, high-performance deep learning library,”
in Advances in Neural Information Processing Systems, 2019, pp. 8026–
8037.
[41] F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein,
“nnu-net: a self-configuring method for deep learning-based biomedical
image segmentation,” Nature Methods, pp. 1–9, 2020.
[42] P. An, S. Xu, S. A. Harmon, E. B. Turkbey, T. H. Sanford,
A. Amalou, et al. (2020) CT Images in Covid-19 [Data
set]. [Online]. Available: https://wiki.cancerimagingarchive.net/display/
Public/CT+Images+in+COVID-19

