COV-ELM classifier: An Extreme Learning Machine based identification of
COVID-19 using Chest X-Ray Images
Sheetal Rajpala , Ankit Rajpalb,∗, Navin Lakhyanic , Naveen Kumara
a Department of Computer Science, University of Delhi, Delhi, India
of Computer Science, Deen Dayal Upadhyaya College, University of Delhi, Delhi, India
c Department of Radiology, Saral Diagnostics, Pitampura, Delhi -110034, India

arXiv:2007.08637v3 [eess.IV] 15 Aug 2020

b Department

Abstract
Coronaviruses constitute a family of virus that gives rise to respiratory diseases. Coronavirus disease 2019
(COVID-19) is an infectious disease caused by a newly discovered coronavirus also termed as Severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2). Due to its rapid spread, WHO has declared COVID19 outbreak a pandemic on 11th March 2020. Reverse transcription-polymerase chain reaction (RT-PCR)
test is popularly used worldwide for the detection of COVID-19. However, due to the high false-negative
rate of RT-PCR test, chest X-ray (CXR) imaging is emerging as a feasible alternative for the detection of
COVID-19. In this work, we propose a multiclass classification model COV-ELM, based on the extreme
learning machine which classifies the CXR images into one of the three classes, namely COVID-19, normal,
and pneumonia. The choice of ELM in this work has been motivated by its significantly short training time
as compared to conventional gradient-based learning algorithms. After some preprocessing, we extract a pool
of features based on texture and frequency. This pool of features serves as an input to the ELM and a 10-fold
cross-validation method is employed to evaluate the proposed model. For experimentation, we use chest
X-ray (CXR) images from three publicly available sources. The results of applying COV-ELM on test data
are quite promising. The COV-ELM achieved a macro average F1-score of 0.95 and the overall sensitivity of
0.94 ± 0.02 at 95% confidence interval. When compared to state-of-the-art machine learning algorithms, the
COV-ELM is found to outperform in a three-class classification scenario. The main advantage of COV-ELM
is that its training time being quite low, as bigger and diverse datasets become available, it can be quickly
retrained as compared to its gradient-based competitor models.
Keywords: COVID-19, Extreme Learning Machine, chest X-rays, Pneumonia viral, Pneumonia bacterial.

1. Introduction
Coronavirus disease 2019 (COVID-19), known to originate from Wuhan City in Hubei Province, China is a
contagious infection resulting in respiratory illness in most cases. COVID-19 is caused by a novel coronavirus,
widely recognized as severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2; previously known as
∗ Corresponding

author
Email addresses: sheetal.rajpal.09@gmail.com (Sheetal Rajpal), ankit.cs.du@gmail.com (Ankit Rajpal),
navinlakhyani@gmail.com (Navin Lakhyani), nkumar@cs.du.ac.in (Naveen Kumar)

2019-nCoV) [1]. As COVID-19 outbreak has become a global health emergency, on March 11, 2020, the
WHO declared COVID-19 a global pandemic [2].
The Reverse transcription-polymerase chain reaction (RT-PCR) test has been used popularly for detection of
SARS-CoV-2. Although COVID-19 may be asymptotic in several instances, it has been reported that even
many symptomatic cases showing characteristics of COVID-19 were not diagnosed by RT-PCR test [3]. Thus,
due to the high false-negative rate of RT-PCR test which may be up to 67% in early days of contracting the
infection, it has to be supplemented with other means of monitoring the clinical features of a subject. This
limitation associated with RT-PCR test is shifting the research focus on the analysis of Chest X-ray images.
Chest X-ray is the most common method of examining common respiratory and lung infections for fast and
cost-effective diagnosis [4, 5]. Though several research groups are working in this direction [6, 7, 8, 9], they are
struggling with the challenge to distinguish COVID-19 patients against those suffering from other forms of
pneumonia [10]. In this paper, the Extreme Learning Machine (ELM) classifier is preferred over conventional
gradient-based learning algorithms due to its faster convergence with the least number of tunable parameters
involved in the network.
Several research groups have recently applied some well known deep neural networks like AlexNet (also known
as ’ImageNet’) [11], VGGNet [12], GoogLeNet [13], ResNet [14], and the variations of these networks for the
classification of COVID-19 on chest X-ray images [7, 8, 9]. ImageNet has 60 million parameters and 650,000
neurons, trained through the dataset of 1.2 million images, which took almost a week on two NVIDIA GTX
580 3GB GPUs [11]. VGGNet has 144 million parameters and greater depth compared to ImageNet but it
converges in fewer epochs due to regularization, smaller filter sizes, and pre-initialization of certain layers [12].
GoogLeNet [13] utilizes a 22- layer deep network for 1.2 million images in training set, 50,000 in validation
set, and 100,000 images in testing set. ResNet trained 23 million parameters to achieve good generalization
performance on CIFAR-10 dataset [15] using 50 thousand images for training and another 10 thousand for
testing [14].
Khan et al. [7] proposed a deep convolutional neural network (DCNN) model to automate the detection
of COVID-19 based on chest X-ray images. The model is based on Xception architecture [16] pre-trained
on ImageNet [11] and achieved an overall accuracy of 89.6%. Mahmud et al. [8] proposed a DCNN model
using a variation in dilation rate to extract distinguishing features from chest X-ray images and achieved an
accuracy of 90.2% for multi-class classification (COVID-19/Normal/Pneumonia). They also used Gradientweighted Class Activation Mapping (Grad-CAM) to visualize the abnormal regions in CXR scans. Wang et
al. [9] developed a computer-aided screening tool for detection of COVID-19 from CXR images based on an
already-trained network on ImageNet, tuned with the Adam optimizer, and achieved 91% sensitivity for the
COVID-19 class. Basu et al. [17] used domain extension transfer learning (DETL) framework comprising 12
layers. They used an already trained network on National Institutes of Health (NIH) CXR image dataset [4]
(comprising 108,948 frontal view X-ray images of 32,717 unique patients) which was fine-tuned for COVID-19
dataset to obtain an overall accuracy 95.3% ± 0.02 on 5-fold cross-validation. Rajaraman et al. [18] iteratively

2

pruned the task-specific models (VGG-16, VGG-19, and Inception-V3) by pruning 2% of the neurons in each
convolutional layer and retrained the model to obtain a macro averaged F1-score of 0.99.
Khuzani et al. [10] used multilayer neural networks (MLNN) to distinguish the CXR images of COVID-19
patients from other forms of pneumonia. They extracted a set of spatial and frequency domain features
from X-ray images. Based on the evaluation of extracted features, they concluded that the while Fast Fourier
Transform (FFT) features were best suited in detecting the COVID-19, the normal class was best determined
by gray level difference method (GLDM). Principal Component Analysis (PCA) was applied to generate an
optimized set of synthetic features that served as input to an MLNN to distinguish COVID-19 images from
the non-COVID-19 ones with an accuracy of 94% .
It is evident from the above discussion that so far the research groups have mainly focused on the use
of deep neural networks which require millions of parameters and the optimal choice of hyper-parameters.
However, it is well known that the training of a deep neural network is a time-consuming task even on
high-performance computing platforms. Therefore, in order to improve the computational efficiency of the
classification models, in this work we have proposed the use of a single hidden layer feed-forward neural
network (SLFN) known as extreme learning machine (ELM) [19, 20]. The ELM is a batch learning algorithm
proposed by Huang et al. [19] and has been used extensively in different domains like ECG signal classification
[21] and identification of arrhythmia disease [22]. The ELM and its variants have also been applied in
applications such as fingerprint identification [23], lung cancer detection [24], image and video watermarking
[25, 26], and 3D object recognition [27]. The applicability of ELM in various domains is due to its fast
learning, good generalization performance, and ease of implementation. The main contribution of this paper
is to explore successfully the feasibility of applying ELM in the diagnosis of COVID-19 using CXR images.
The rest of the paper is organized as follows: section 2 presents a review of ELM, section 3 gives the dataset
description followed by the detailed methodology, outcomes of the experiments and analysis of the results
have been discussed in section 4, finally, the conclusions and scope of future work are discussed in section 5.
2. Extreme Learning Machine
Extreme Learning Machine (ELM) was proposed by Huang et al. as an efficient alternative to the backpropagation algorithm for single-layer feed-forward networks (SNFN) [19]. It is a fast learning algorithm with
good generalization performance as compared to other traditional feed-forward networks. An ELM works
by initializing a set of weights randomly and computing the output weights analytically by Moore Penrose
Matrix Inverse [28].
Fig. 1 depicts the overall ELM architecture and the details of its functioning are provided in algorithm 1.
Given a training set (xj , tj ), xj ∈ Rn , tj ∈ Rm for j = 1, 2, . . . , N , where the pairs (xj , tj ) denote the training
vectors and the corresponding target values, following [19], the standard ELM having L nodes is modeled as:
L
X

βi gi (ai .xj + bi ) = tj

i=1

3

(1)

Figure 1: ELM Architecture: The ELM network comprises an input layer, a hidden layer, and an output layer

In Equation 1, ai denotes the weight vector that connects the input layer to the ith hidden node and bi
denotes the corresponding bias. Further, βi denotes the weight vector connecting the ith hidden node and
the output neurons. The above N equations may also be represented as:

Gβ = T

(2)

The form of the hidden layer output matrix G, mentioned in Equation 2, is given in Equation 3. The form
of vectors β and T is given in equation 4.



g(a1 .x1 + b1 ) . . .

..

G=
.
...

g(a1 .xN + b1 ) . . .

 
βT
 1
 . 
β =  .. 
 
βLT


g(aL .x1 + bL )

..


.

g(aL .xN + bL )

(3)

N ×L



and


tT1
 
 . 
T =  .. 
 
tTN

(4)

N ×m

L×m

The solution of the above system of linear equations is obtained using Moore-Penrose generalized inverse
(Equation 5).
β = G† T
In Equation 5, G† = (GT G)−1 GT denotes the Moore-Penrose generalized inverse [28] of matrix G.

4

(5)

Algorithm 1 ELM Algorithm
Input:
Training set: (xj , tj ), xj ∈ Rn , tj ∈ Rm for j = 1, 2, . . . , N
Activation function: g : R → R
Number of hidden nodes: L
Output:
Optimized weight matrix: β
1. Randomly assign hidden node parameters (ai , bi ), i = 1, 2, . . . , L;
2. Compute the hidden-layer output matrix G;
3. Compute output weight vector β = G† T

Huang et al. [29] argue that ELM outperforms the conventional learning algorithms in terms of learning
speed, and in most of the cases shows better generalization capability than the conventional gradient-based
learning algorithms such as backpropagation where the weights are adjusted with a non-linear relationship
between the input and the output [28]. They further stated that ELM can compute the desired weights of
the network in a single step in comparison to classical methods.

3. Material and Methods
In this section, we present a list of CXR image datasets used for experimentation in this work, followed by
details of the proposed methodology.
3.1. Dataset Description
In the present work, we have used the following publicly available CXR datasets for COVID-19, Normal, and
Pneumonia.
• COVID-19 Image Data Collection [6]. It comprises 760 samples, COVID-19: 538, ARDS: 14, Other
Diseases: 222.
• COVID-19 Radiography Database (Kaggle) [30]. It comprises 2905 samples, COVID-19: 219, Normal:
1341, Viral Pneumonia: 1345.
• Mendeley Chest X-ray Images [31]. It comprises 5856 samples, Pneumonia (Viral and Bacterial) : 4273,
Normal:1583.

5

In this work, we only consider the CXR images in a frontal view, namely Poster anterior (PA) and Erect
anteroposterior (AP). The first two databases in the above list comprise 520 such images. For the training
purpose, we have used these images alongwith 520 CXR images of normal and pneumonia cases from COVID19 Radiography Database (Kaggle) [30] and Mendeley Chest X-ray Images [31].
3.2. Preprocessing
Due to diversity in the CXR image collection, they are resized and subjected to min-max normalization
[32] to ensure uniformity. Further, to enhance the local contrast in the CXRs, Contrast Limited Adaptive
Histogram Equalization (CLAHE), a variant of adaptive histogram equalization is applied. Fig. 2 depicts
the preprocessing steps for the CXR image dataset, which includes resizing, normalization, and CLAHE [33]
applied in sequence.

Figure 2: Preprocessing: Image Resizing, Normalization, and Contrast Limited Adaptive Histogram Equalization (CLAHE).

3.3. Feature Extraction
Texture plays a significant role in classifying images or identifying the region of interest (ROI) in an image
[34]. In this work, we consider four groups of texture features in a CXR image. The first group of features is
directly generated from the preprocessed image of 512 × 512. These include area, mean, standard deviation,
skewness, kurtosis, energy, entropy, max, min, mean absolute deviation, median, range, root mean square, and
uniformity. Remaining texture features are obtained by applying gray-level co-occurrence matrix (GLCM)
[35, 36], histogram of oriented gradients (HOG) [37, 38, 39], and gray-level difference matrix (GLDM) [40, 10].
Apart from texture features, the use of frequency features also plays an important role in developing efficient
classifiers in medical imaging [41, 42, 43]. In the present work, the frequency features are extracted using Fast
Fourier Transform (FFT) and Discrete Wavelet Transform (DWT). Zargari et al. [44] used the aforementioned
statistical features for predicting chemotherapy response in ovarian cancer patients. Drawing inspiration from
their work, we computed these features for FFT map and three-level (LL3) DWT coefficients to generate a
vector of frequency features. Finally, a vector of features is obtained by concatenating textural feature vector
of length (140) with the frequency vector of length (28) to generate a vector of size 168 for the CXR images.

6

3.4. COV-ELM
In this work, we use extreme learning machine (ELM) discussed in section 2 to develop an ELM classifier
(COV-ELM) for detection of COVID-19 in CXR images. Based on experimentation, we used L2-normalized
radial basis function (rbf-l2) activation function. We also experimented with different number of neurons in
the hidden layer. Using 10-fold cross-validation, we observed that with increase in the number of neurons in
the hidden layer, accuracy increases up to L = 140 neurons, and the highest 10-fold cross-validation accuracy
of 94.10% was reached when the number of hidden neurons was L = 350. Experimenting with different seeds,
we found the peak accuracy was reached for the number of hidden neurons in the range 350 to 380, but
without any further increase in 10-fold cross-validation accuracy. So, for further experiments, we fixed the
number of hidden neurons as L = 350.

Figure 3: Effect of the increase in the number of hidden neurons (L) on 10-fold cross-validation accuracy. Accuracy increases
with increase in L upto L = 140, and witnessed highest 10-fold cross-validation accuracy of 94.10% at L = 350

Boxplot in Figure 4 depicts the variation in sensitivity value. It is evident from the results that the texture
features scores over frequency features. We also examined the influence of a combined set of features (168)
on the classification process. It may be noted that the model yields median sensitivity of 0.945 using the
combined set of features which scores over the median sensitivity values considering the frequency and texture
features separately, exhibiting 0.90 and 0.93 respectively.

7

Figure 4: Boxplot for sensitivity (recall) values using frequency features, texture features, and combined set of frequency and
texture features. The combined set of features depicts the median sensitivity of 0.945 which scores over the median values
considering frequency and texture features separately.

4. Results and Discussion
We have carried out all the experiments using Python 3.6.9 on the NVIDIA Tesla K80 GPU. To evaluate the
performance of the proposed method for the three-class classification problem, we trained the model on the
CXR dataset using 10-fold cross-validation. Following Handy and Till [45], we depict the receiver operating
characteristic (ROC) curves for each of the three classes, namely COVID-19, Normal, and Pneumonia for
one fold (please see in Figure 5). It is apparent from the ROC curves that AUC is near unity for all three
classes which shows a good generalization performance of COV-ELM.
To evaluate the performance of the proposed classifier, we carried out a 10-fold cross-validation. Fig. 6 depicts
the confusion matrix and the heatmap for 10-fold cross-validation. The results of the 10-fold cross-validation
are summarized in a confusion matrix (Figure 6(a)). It shows that out of 380 COVID-19 patients, 364 were
correctly identified, three were misclassified as normal and thirteen were labeled as pneumonia. Similarly,
pneumonia and normal subjects were also labeled by the system quite accurately. Thus, we obtained an
overall accuracy of 94.40% and a high recall rate of 95.78%, 95.53%, and 92.41% for COVID-19, Normal,
and Pneumonia classes respectively. The macro average of f1-score is 0.95 as depicted in the heatmap (Fig.
6(b)). As shown in Table 1, COV-ELM identified COVID-19, Normal, and Pneumonia classes with sensitivity
0.96 ± 0.04, 0.96 ± 0.01, and 0.92 ± 0.03 respectively at 95% confidence interval.
To establish the effectiveness of our approach, the COV-ELM is compared with the state-of-the-art machine

8

(a) ROC Curve (COVID-19 vs other classes)

(b) ROC Curve (Normal vs other classes)

(c) ROC Curve (Pneumonia vs other classes)
Figure 5: AUC is near unity for each of the three classes namely COVID-19, Normal, and Pneumonia in one vs all setting.
Table 1: Sensitivity (Recall) values for COVID-19, Normal, and Pneumonia at 95% confidence interval.

Sensitivity at 95% CI
COVID-19

Normal

Pneumonia

0.96 ± 0.04

0.96 ± 0.01

0.92 ± 0.03

learning algorithms, namely support vector classifier (SVC) using rbf and linear kernels, gradient boosting
classifier (GBC), random forest ensemble (RBE), artificial neural networks (ANN), decision tree classifier
(DTC), and voting classifier (VC) ensemble of (logistic regression (LR), SVC, and GBC) in terms of sensitivity
at 95% confidence interval (CI) (please see Table 2). It is clear that COV-ELM has higher sensitivity as
compared to its competitors. It is evident from the table that the proposed approach achieves sensitivity of
0.94 ± 0.02 and scores over other state-of-the-art classifiers .

9

(a) Confusion matrix summarizing number fo instances (b) Heatmap summarizing performance metrics: precicorrectly classified across diagonal elements.

sion, recall and f1-score

Figure 6: The classification error in classifying COVID-19, Normal, and Pneumonia is 3.68%, 4.46%, and 7.58% respectively
and the macro average of f1-score is 0.95.
Table 2: Comparison of COV-ELM with other state-of-the-art classifiers in terms of sensitivity value at 95% confidence interval.

Classifier

Sensitivity

ELM (L=350, rbf-l2)

0.94 ± 0.02

GBC (learning rate=1.0)

0.91 ± 0.05

SVC (C=1.0, kernel=’rbf’)

0.86 ± 0.06

SVC (C=1.0, kernel=’linear’)

0.90 ± 0.05

RBE (min samples split=2)

0.89 ± 0.05

ANN (23,747 Parameters)

0.85 ± 0.08

DTC (min samples leaf=1)

0.82 ± 0.07

VC (LR, SVC, GBC)

0.89 ± 0.05

5. Conclusions
The current research is focused on the accurate diagnosis of COVID-19 with a high sensitivity. In this
direction, the paper evaluates the applicability of ELM as a classifier. We use a combination of texture
(Spatial, GLDM, HOG, AND GLDM) and frequency features (FFT and DWT) for classification of COVID-19
patients against pneumonia and normal patients. The proposed model has been evaluated using CXR images
from three publicly available sources. Opposed to deep neural network which require millions of parameters
for training, the number of parameters in ELM is considerably less, compared to a conventional neural
network requiring thousands of parameters. We found that the 10-fold cross-validation accuracy increases
with an increase in the number of hidden neurons 140, then it stabilizes more or less, finally reaching the
10

peak accuracy of 94.10% at 350 hidden neurons. The proposed method achieved a macro average f1-score
of 0.95 in a three-class classification scenario and an overall accuracy 94.40%. The COV-ELM outperforms
other competitive machine learning algorithms with a sensitivity of 0.94% ± 0.02 at 95% confidence interval.
The training time of COV-ELM being quite low, compared to its gradient-based competitor models, it can
be quickly trained on bigger and diverse datasets that may become available in future. As part of future
work, we will like to investigate whether segmentation of lung region could help improving the classification
results.

References
[1] M.-Y. Ng, E. Y. Lee, J. Yang, F. Yang, X. Li, H. Wang, M. M.-s. Lui, C. S.-Y. Lo, B. Leung, P.-L.
Khong, et al., Imaging profile of the COVID-19 infection: radiologic findings and literature review,
Radiology: Cardiothoracic Imaging 2 (1) (2020) e200034.
[2] WHO,

Archived:

WHO

Timeline

-

COVID-19,

https://www.who.int/news-room/detail/

27-04-2020-who-timeline---covid-19 (2020).
[3] A. Tahamtan, A. Ardebili, Real-time RT-PCR in COVID-19 detection: issues affecting the results (2020).
[4] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, R. M. Summers, Chestx-ray8: Hospital-scale chest xray database and benchmarks on weakly-supervised classification and localization of common thorax
diseases, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp.
2097–2106.
[5] L. Nanni, A. Lumini, S. Brahnam, Local binary patterns variants as texture descriptors for medical
image analysis, Artificial intelligence in medicine 49 (2) (2010) 117–125.
[6] J. P. Cohen, P. Morrison, L. Dao, K. Roth, T. Q. Duong, M. Ghassemi, COVID-19 Image Data Collection: Prospective Predictions Are the Future, arXiv preprint arXiv:2006.11988 (2020).
[7] A. I. Khan, J. L. Shah, M. M. Bhat, Coronet: A deep neural network for detection and diagnosis of
COVID-19 from chest x-ray images, Computer Methods and Programs in Biomedicine (2020) 105581.
[8] T. Mahmud, M. A. Rahman, S. A. Fattah, CovXNet: A multi-dilation convolutional neural network
for automatic COVID-19 and other pneumonia detection from chest X-ray images with transferable
multi-receptive feature optimization, Computers in Biology and Medicine (2020) 103869.
[9] L. Wang, A. Wong, COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection
of COVID-19 Cases from Chest X-Ray Images, arXiv preprint arXiv:2003.09871 (2020).
[10] A. Z. Khuzani, M. Heidari, S. A. Shariati, COVID-Classifier: An automated machine learning model to
assist in the diagnosis of COVID-19 infection in chest x-ray images, medRxiv (2020).
11

[11] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with deep convolutional neural networks, in: Advances in neural information processing systems, 2012, pp. 1097–1105.
[12] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, arXiv
preprint arXiv:1409.1556 (2014).
[13] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich,
Going deeper with convolutions, in: Proceedings of the IEEE conference on computer vision and pattern
recognition, 2015, pp. 1–9.
[14] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the
IEEE conference on computer vision and pattern recognition, 2016, pp. 770–778.
[15] A. Krizhevsky, G. Hinton, et al., Learning multiple layers of features from tiny images, Tech. rep.,
Toronto (2009).
[16] F. Chollet, Xception: Deep learning with depthwise separable convolutions, in: Proceedings of the IEEE
conference on computer vision and pattern recognition, 2017, pp. 1251–1258.
[17] S. Basu, S. Mitra, Deep Learning for Screening COVID-19 using Chest X-Ray Images, arXiv preprint
arXiv:2004.10507 (2020).
[18] S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio, S. K. Antani, Iteratively Pruned
Deep Learning Ensembles for COVID-19 Detection in Chest X-rays, arXiv preprint arXiv:2004.08379
(2020).
[19] G.-B. Huang, Q.-Y. Zhu, C.-K. Siew, Extreme learning machine: a new learning scheme of feedforward
neural networks, in: 2004 IEEE international joint conference on neural networks (IEEE Cat. No.
04CH37541), Vol. 2, IEEE, 2004, pp. 985–990.
[20] A. Akusok, K.-M. Björk, Y. Miche, A. Lendasse, High-performance extreme learning machines: a complete toolbox for big data applications, IEEE Access 3 (2015) 1011–1025.
[21] S. Karpagachelvi, M. Arthanari, M. Sivakumar, Classification of electrocardiogram signals with support
vector machines and extreme learning machine, Neural Computing and Applications 21 (6) (2012) 1331–
1339.
[22] J. Kim, H. S. Shin, K. Shin, M. Lee, Robust algorithm for arrhythmia classification in ECG using
extreme learning machine, Biomedical engineering online 8 (1) (2009) 31.
[23] J. Yang, S. Xie, S. Yoon, D. Park, Z. Fang, S. Yang, Fingerprint matching based on extreme learning
machine, Neural Computing and Applications 22 (3-4) (2013) 435–445.

12

[24] M. R. Daliri, A hybrid automatic system for the diagnosis of lung cancer based on genetic algorithm
and fuzzy extreme learning machines, Journal of medical systems 36 (2) (2012) 1001–1005.
[25] A. Rajpal, A. Mishra, R. Bala, A Novel fuzzy frame selection based watermarking scheme for MPEG-4
videos using Bi-directional extreme learning machine, Applied Soft Computing 74 (2019) 603–620.
[26] A. Mishra, A. Rajpal, R. Bala, Bi-directional extreme learning machine for semi-blind watermarking of
compressed images, Journal of information security and applications 38 (2018) 71–84.
[27] R. Nian, B. He, A. Lendasse, 3D object recognition based on a geometrical topology model and extreme
learning machine, Neural Computing and Applications 22 (3-4) (2013) 427–433.
[28] J. A. Fill, D. E. Fishkind, The Moore–Penrose Generalized Inverse for Sums of Matrices, SIAM Journal
on Matrix Analysis and Applications 21 (2) (2000) 629–635.
[29] G.-B. Huang, Q.-Y. Zhu, C.-K. Siew, Extreme learning machine: theory and applications, Neurocomputing 70 (1-3) (2006) 489–501.
[30] T. Rahman, M. Chowdhury, A. Khandakar, COVID-19 Radiography Database — Kaggle, https://
www.kaggle.com/tawsifurrahman/covid19-radiography-database (2020).
[31] D. Kermany, K. Zhang, M. Goldbaum, Large dataset of labeled optical coherence tomography (oct) and
chest x-ray images, Mendeley Data, v3 http://dx. doi. org/10.17632/rscbjbr9sj 3 (2018).
[32] A. Jain, K. Nandakumar, A. Ross, Score normalization in multimodal biometric systems, Pattern recognition 38 (12) (2005) 2270–2285.
[33] S. A. Ahmad, M. N. Taib, N. E. A. Khalid, H. Taib, An analysis of image enhancement techniques
for dental X-ray image interpretation, International Journal of Machine Learning and Computing 2 (3)
(2012) 292.
[34] R. M. Haralick, K. Shanmugam, I. H. Dinstein, Textural features for image classification, IEEE Transactions on systems, man, and cybernetics 6 (1973) 610–621.
[35] M. R. Zare, W. C. Seng, A. Mueen, Automatic classification of medical x-ray images, Malaysian Journal
of Computer Science 26 (1) (2013) 9–22.
[36] MathWorks,
(GLCM)

Texture
-

MATLAB

Analysis
&

Using

the

Simulink,

Gray-Level

Co-Occurrence

Matrix

https://www.mathworks.com/help/images/

texture-analysis-using-the-gray-level-co-occurrence-matrix-glcm.html#:~:text=More-,
Texture%20Analysis%20Using%20the%20Gray%2DLevel%20Co%2DOccurrence%20Matrix%20(,gray%
2Dlevel%20spatial%20dependence%20matrix. (2020).

13

[37] N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, in: 2005 IEEE computer
society conference on computer vision and pattern recognition (CVPR’05), Vol. 1, IEEE, 2005, pp.
886–893.
[38] GitHub, Histogram of Oriented Gradients, https://scikit-image.org/docs/dev/auto_examples/
features_detection/plot_hog.html (2020).
[39] Z. Xue, D. You, S. Candemir, S. Jaeger, S. Antani, L. R. Long, G. R. Thoma, Chest x-ray image
view classification, in: 2015 IEEE 28th International Symposium on Computer-Based Medical Systems,
IEEE, 2015, pp. 66–71.
[40] J. K. Kim, H. W. Park, Statistical textural features for detection of microcalcifications in digitized
mammograms, IEEE transactions on medical imaging 18 (3) (1999) 231–238.
[41] N. V. Shree, T. Kumar, Identification and classification of brain tumor MRI images with feature extraction using DWT and probabilistic neural network, Brain informatics 5 (1) (2018) 23–30.
[42] J. M. Leibstein, A. L. Nel, Detecting tuberculosis in chest radiographs using image processing techniques,
University of Johannesburg (2006).
[43] N. Parveen, M. M. Sathik, Detection of pneumonia in chest X-ray images, Journal of X-ray Science and
Technology 19 (4) (2011) 423–428.
[44] A. Zargari, Y. Du, M. Heidari, T. C. Thai, C. C. Gunderson, K. Moore, R. S. Mannel, H. Liu, B. Zheng,
Y. Qiu, Prediction of chemotherapy response in ovarian cancer patients using a new clustered quantitative
image marker, Physics in Medicine & Biology 63 (15) (2018) 155020.
[45] D. J. Hand, R. J. Till, A simple generalisation of the area under the ROC curve for multiple class
classification problems, Machine learning 45 (2) (2001) 171–186.

14

