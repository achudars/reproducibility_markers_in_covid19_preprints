1

Robust Task Scheduling for Heterogeneous Robot
Teams under Capability Uncertainty

arXiv:2106.12111v1 [cs.RO] 23 Jun 2021

Bo Fu, William Smith, Denise Rizzo, Matthew Castanier, Maani Ghaffari, and Kira Barton

Abstract—This paper develops a stochastic programming
framework for multi-agent systems where task decomposition, assignment, and scheduling problems are simultaneously optimized.
Due to their inherent flexibility and robustness, multi-agent
systems are applied in a growing range of real-world problems
that involve heterogeneous tasks and uncertain information. Most
previous works assume a unique way to decompose a task into
roles that can later be assigned to the agents. This assumption
is not valid for a complex task where the roles can vary and
multiple decomposition structures exist. Meanwhile, it is unclear
how uncertainties in task requirements and agent capabilities can
be systematically quantified and optimized under a multi-agent
system setting. A representation for complex tasks is proposed
to avoid the non-convex task decomposition enumeration: agent
capabilities are represented as a vector of random distributions,
and task requirements are verified by a generalizable binary
function. The conditional value at risk (CVaR) is chosen as a
metric in the objective function to generate robust plans. An
efficient algorithm is described to solve the model, and the
whole framework is evaluated in two different practical test
cases: capture-the-flag and robotic service coordination during
a pandemic (e.g., COVID-19). Results demonstrate that the
framework is scalable, generalizable, and provides low-cost plans
that ensure a high probability of success.
Index Terms—Heterogeneous multi-agent systems, Task allocation, Stochastic vehicle routing problem, Scheduling and
coordination, Pandemic robotic services

I. I NTRODUCTION

T

ECHNOLOGICAL advances in sensing and control have
enabled robotic applications in an ever-growing scope.
On the other hand, the growing complexity and requirements
of the applications soon exhaust the capability of a single
robot: limited by design rules and actuator/sensor power, even
the most competent robot is not able to handle all real-world
tasks alone. This trend fosters the recent proliferation of multiagent system applications in agriculture [1], warehouse management [2], construction [3], defense [4], exploration [5]–[9],
and surveillance [10]–[12]. The advantages of replacing a large
omnipotent robot with a team of smaller and less powerful
robots include the robustness to agent failures, resilience of
team configuration, and lower maintenance costs (a large robot
Manuscript received: Month, Day, Year; Revised Month, Day, Year; Accepted Month, Day, Year.
DISTRIBUTION A. Approved for public release; distribution unlimited.
(OPSEC 5240)
Bo Fu, Maani Ghaffari, and Kira Barton are with the University
of Michigan, Ann Arbor, MI 48109, USA (e-mail: bofu@umich.edu;
maanigj@umich.edu; bartonkl@umich.edu)
William Smith, Denise Rizzo, and Matthew Castanier are with the US
Army DEVCOM Ground Vehicle Systems Center, Warren, MI 48397, USA
(e-mail: william.c.smith1019.civ@mail.mil; denise.m.rizzo2.civ@mail.mil;
matthew.p.castanier.civ@mail.mil)

Surveillance

Rescue

1,3,0

0,1,2

1

2

1
2
2
3

0,2,0

1,1,0

Team
capabilities

0,0,1

Capability types
Fly (non-cumulative)
Perception
Transport people

Agent
capabilities

Fig. 1: Graphical model: an example of the heterogeneous teaming problem
(HTP) with two tasks and three agent species. A graphical model links agents
and tasks. There are three types of capabilities: fly, perception, and transport
people. The rescue task requires the ability to transport people, but also
perception to guide the process. While the surveillance task requires both
flying and perception capabilities as the task is performed in a small mountain.
We regard the capability to fly as non-cumulative (the team can fly only when
all agents in the team can fly).

with the same task capabilities is usually harder to design and
costlier due to the system complexity) [13].
The reason that a team of less powerful robots can achieve
the same or more complex tasks with the above advantages is
that the functional heterogeneity within the team, i.e., distinct
sensor and actuator capabilities of the robots, can complement
each other during a task. In contrast to structural heterogeneity
(e.g., maximum velocity or energy capacity), functional heterogeneity usually leads to fundamental differences between
task capabilities (e.g., the ability to fly or remove debris) [14].
The fundamental problems [15] that arise when applying
a functionally heterogeneous multi-agent system to a mission
containing multiple complex sub-tasks include: understanding
how to decompose the tasks into elements that can be assigned
to a single agent (how), determining which agents should be
assigned to a particular task element (who), and deriving a
schedule that enables the heterogeneous team to successfully
complete the task (when). I.e., consider the whole problem as
a task allocation; then, task allocation = task decomposition +
assignment + scheduling.
A task is considered complex if there exist multiple decompositions and it is unknown which decomposition should be
selected without simultaneously considering task assignment
and schedule planning (e.g. the problem is coupled) [15]. One
modeling option is to enumerate all decomposition possibilities, but such an enumeration discretizes the feasible problem
space and adds non-convex constraints to the optimization. As
a result, the solver may need to enumerate the decomposition

2

Cost map,
task distribution

Routing, Scheduling, and Risk Minimization

Local path planner

min Ce
Edge costs

Flow Decomposition

Σ cost + Cq node
Σ time + Ch task
Σ risk(ρtask(team))

edge

Plans of
agent species

Graph model

1.9

Agent capabilities

2.9
1

1
1

Agent
plans
xn

1

Task requirements: ρ(team) = 1 or 0

Fig. 2: System architecture. Input: cost (energy) maps, agent capabilities, and task requirements. Output: agent routes, schedules, and team formations. There
are two major components. A routing, scheduling, and risk minimization model (Sec. III) generates a network flow for each agent species. And then these
networks are further decomposed into individual agent plans through a flow decomposition model (Sec. V).

cases, which could result in an exponentially growing computation cost. Therefore, in the representation of the constraints
between complex tasks and heterogeneous agents, high nonconvexity and discreteness, such as enumerations of decomposition, should be avoided to facilitate the optimization. Namely,
convex task representations/constraints are preferred.
Among the few previous works that deal with functional
heterogeneity in a complex task setting, most optimization
models are designed for use with a specific application.
Therefore, in addition to a convex representation, there is a
need for fundamental methods that provide a more systematic
representation that can generalize within a larger scope of
complex tasks.
An important aspect to consider when dealing with dynamic
systems is the concept of uncertainty. To capture the effects
of uncertainty within the decision making process, we must
consider the design of a robust framework. In this work, we
consider uncertainties within the task requirements and agent
capabilities.
In this paper, we present a Capability-based robust Task
Assignment and Scheduling (CTAS) framework to optimize
task decomposition, assignment, and scheduling simultaneously within a closer to convex stochastic task model , which
can generalize to multiple practical scenarios. Figure 1 shows
a graphical model for a small example problem. Consider a set
of heterogeneous agents (can be robots/vehicles/humans) and
complex tasks; the proposed framework will form agent teams,
schedules, and routes to minimize energy and time costs for
completing the task combined with the risk of non-completion.
We define this class of problems as the heterogeneous teaming
problem (HTP). The system architecture is summarized in Fig.
2 and will be discussed in the following sections.

1) The development of a modeling framework that captures
uncertainties within the task requirements and agent capabilities.
2) The derivation of a cost function that incorporates the
concept of risk within the minimization.
3) Reformulation of the heterogeneous teaming problem
(HTP) to provide a more scalable algorithm that is solved
by using a flow decomposition sub problem.
4) A comprehensive evaluation approach that provides a
demonstration of the relevant contributions as well as
a comparison of the task assignment performance to a
baseline algorithm.
B. Outline
The remainder of this paper is organized as follows: Sec.
II briefly introduces the related work of multi-agent task
allocation and concludes with research gaps that this work
investigates. Sec. III describes the general problem mathematically and presents a risk minimization framework for
the problem. Sec. IV introduces an algorithm to solve the
risk minimization problem and output a general routing plan
described as network flows of agent movements. Sec. V
proposes a network flow decomposition problem to generate
routing plans and schedules for individual agents. The twostep process in sections IV and V improves the scalability of
the framework compared to a solution method that outputs
individual plans directly within one optimization. Sec. VI
describes the experiments and results, followed by discussion.
Finally, Sec. VII concludes the paper and provides ideas for
future work based on current limitations.
II. R ELATED W ORK

A. Contributions
In [16], we dealt with a deterministic variation of such a
problem, where we assumed exact information (instead of a
distribution) of the agent capabilities and task requirements
was known. In this work, we develop a generalizable framework for task assignment and scheduling that systematically
represents heterogeneous and uncertain task requirements and
agent capabilities. This paper provides the following contributions.

According to the taxonomy in [15], [17], the aboveproposed problem is a task allocation problem in the category
CD-[ST-MR-TA]: complex task dependencies (CD), singletask robot (ST), multi-robot tasks (MR), and time-extended
assignment (TA). It is one of the most challenging task
assignment categories and has been considered in few previous
works in literature. The time-extended assignment considers
scheduling, in contrast to the instantaneous assignment (IA),
which only makes matches between tasks and robots.

While there are many previous works about multi-robot
tasks, most of them decompose a multi-robot task into elements that can be handled by a single agent in a fixed
way. If such a decomposition exists, the task decomposition
problem is presolved and decoupled from the assignment
and scheduling problem. Many previous works in coalition
formation [18], vehicle routing [14], [19], job shop scheduling
[20]–[22], and robotic soccer games [23], [24] deal with
such non-complex (or compound) tasks. In [19], the tasks are
decomposed into roles for medical agents and transport agents
while connected with scheduling constraints. In a job shop
scheduling problem [21], a job (task) is decomposed into fixed
operations that can be executed by a single machine (agent).
In [24], a soccer game is also composed of multiple roles
that can be later assigned to a specific agent based on utility
maximization.
Among the systems that deal with complex tasks, [25], [26]
model the constraints between fire extinguishing and debris
removal tasks such that at least one ‘clear’ route to a fire
extinguishing task can be identified. Since the solution set
contains multiple combinations, the whole problem is deemed
complex. [11] models the specific recharging behaviors of
an unmanned aerial/ground vehicle team under a coverage
problem. While these example demonstrate approaches for
dealing with complex tasks, the models used in these examples
are specific to the application and do not generalize to other
examples.
There are some methods for formulating complex tasks
that can generalize and avoid a naive enumeration of role or
action combinations. In [27]–[33], a task is represented as a
graph of states (nodes) and actions (edges) using planning
domain definition language (PDDL) [34] that is domainindependent once the language is defined. Moreover, there
are variants of PDDLs for multi-agent problems [35]. [36],
[37] use a Bayesian network representation consisting of tasks,
observations, constraints, and action nodes. Hierarchical tree
networks (HTN) are used in [38]–[41] to represent tasks
where leaf nodes are roles for assignment. A tree structure
representation utilizes the hierarchical nature of a task and
partially avoids enumerations. However, these representations
are usually applied to systems with less than five agents. The
number of states in such trees/graphs could explode rapidly
with respect to the number of agents and decomposition
choices. Such a scalability issue limits its application to larger
multi-agent systems.
Uncertainty exists widely in the estimation of task requirements and agent capabilities. More recent works capture such
uncertainty explicitly in their models. [42] models the agent
action uncertainty during single-robot tasks in Markov decision processes (MDP). However, instead of modeling the joint
space of multiple tasks as a large MDP through concatenation,
they use linear temporal logic to describe the relationship
between these task MDPs, limiting the dimensionality of the
integrated problem. Each MDP is solved beforehand, and
jointly the probability of completing the tasks is maximized.
In [23], [24], [43], an agent’s capabilities are represented as a
Gaussian random vector where the uncertainty is captured in
the distribution. A task requirement is then specified by the

Probability density

3

Probability β

Expectation E(X)

Cost X
CVaR ηβ(X) Worst case sup(X)

Fig. 3: Graphical illustration of CVaR, defined as expected cost of the worst
β-proportion of the cases. Denoted as ηβ (·), it is a function of the random
distribution with β as a hyper-parameter.
Table I: A comparison between STRATA and CTAS. The meaning of ‘and/or’
in the task requirements is defined in Sec. III. STRATA claims that it can deal
with noncumulative capability types (such as the speed of an agent). However,
it thresholds on a value and then treats the binary value after thresholding in
the same way as a cumulative capability. For noncumulative types, we require
instead that all agents in the team meet the minimum requirement.
Agent capabilities
Capability types
Task requirements
Scheduling
Uncertainty control

STRATA [43]

CTAS (Ours)

continuous/Gaussian
cumulative
and
no
limit variance

continuous/stochastic
cumulative/noncumulative
and/or
yes
minimize CVaR

minimum value needed for each capability type. The work of
[43] then models the problem as an optimal control process
(called STRATA) where they penalize the time, misplaced
capabilities, and the variance of the distribution. However,
probability, expectation, or variance are not well-justified
quantitative metrics in such an optimization problem and can
result in problematic solutions. For instance, if the required
capability of a task is matched precisely, it is reasonable to
limit the variances within a small threshold. However, if the
team’s capability surpasses the task requirement by a lot, larger
variances are acceptable. As another example, optimizing an
expected cost (average performance) can be problematic for
safety-critical applications.
In our proposed model, we represent the agent capabilities
as a vector of random distributions (not necessarily Gaussian)
and the task requirements within a binary function of the
team capabilities (defined in Sec. III). The task requirement is
verified once the ‘sum capabilities’ of the team drive the binary
function to one. Because there can be multiple ways to satisfy
the ‘sum requirements’, the agent combination for a complex
task is not enumerated but encoded implicitly. We then solve
the task decomposition, assignment, and scheduling problem
simultaneously, where we optimize the time, energy, and
‘uncertainty’. For the ‘uncertainty’, we choose to minimize the
conditional value at risk (CVaR), which is a provably sensible
measurement of the uncertainties in practical applications [44].
It is widely accepted by the finance community and appears
with a growing frequency in recent robotic applications [45]–
[49]. A graphical illustration of the definition of CVaR is
shown in Fig. 3.
STRATA [43], [50] shares many similarities with our proposed approach, CTAS, including stochastic agent capability
vectors, task requirements on the team’s sum capabilities, and
graphical representations of the problem. Therefore, we choose
STRATA as our baseline algorithm in one of the experiments
in Sec. VI. However, STRATA falls in the area of CD-[ST-

4

MR-IA], where it assumes a schedule of the tasks is given,
which simplifies one of the core components of such a multiagent system. Meanwhile, our task model, represented using
requirement functions, is more expressive. TABLE I provides
a more detailed comparison between the two models.
III. ROUTING , S CHEDULING , AND R ISK M INIMIZATION
In this section, we formally define the heterogeneous teaming problem with uncertain agent capabilities and task requirements. We describe the task requirement functions and
agent capability vectors used to represent the task structure,
organize them in a graphical model, and then encode the
task allocation problem as a stochastic mixed-integer program
whose objective jointly consists of time, energy, and risk cost.
A. Heterogeneous Teaming Problem Description
We simplify the graphical model in [16] for this work.
Consider a set of agent species V = {v1 , · · · , vnv }, capability
types A = {a1 , · · · , ana }, and tasks M = {m1 , · · · , mnm }.
Each agent specie k ∈ V is associated with a non-negative
capability vector ck = [cka1 , · · · , ckana ]T , where cka is a
random variable with a known distribution, representing the
uncertainty in agents’ task capabilities. Each task i ∈ M
requires an agent team with appropriate capabilities that drives
a task requirement function ρi (·) to 1.
A task requirement function is a binary function of similar
structure as (1). The logical operators ≥, ∧, and ∨ are ‘greater
than’, ‘and’, and ‘or’ that return 1 if their conditions are
satisfied, and 0 otherwise. Note that there can be an arbitrary
number of ∧ and ∨, theoretically. αa is the capability a
of the agent team. Depending on whether the capability is
cumulative, we can compute αa according to (2). An example
of non-cumulative capabilities is the speed limit of a team. It
equals the speed of the slowest moving agent in the team. γa
reflects the task requirement on capability a, and is modeled
as a random variable with a known distribution.
ρm1 (αa1 , αa2 , · · · ) = [(αa1 ≥ γa1 ) ∨ (αa2 ≥ γa2 )]
∧ [αa3 ≥ γa3 ] ∧ [αa4 ≥ γa4 ]
(P
k∈Vm1 cka , a is cumulative
αa =
mink∈Vm1 cka , a is non-cumulative

(1)
∀a ∈ A (2)

The requirement to drive these functions to 1 could be satisfied with appropriate team formation planning. In our model,
this requirement can be encoded as linear constraints [16]. In
this representation, the only part that could introduces nonconvexity is the logic ∨ which takes the union of two feasible
regions. Reducing the number of ∨ is desired as it facilitates
the optimization. Therefore, the representation is closer to
convex than a simple enumeration of role decomposition.
With the stochasticity in task requirements and agent capabilities, the goal is to determine the optimal task schedule for
a selected set of agents, such that the energy, time, and path
constraints are satisfied, and the energy cost and the risk of
task’s non-completion are jointly minimized.

B. Routing Model
As shown in Fig. 4, we first define a directed graph G =
(N, E), with a set of vertices N = S ∪ U ∪ M and edges
E. M = {m1 , · · · , mnm } is the set of the task nodes. S =
{s1 , · · · , snv } and U = {u1 , · · · , unv } are the sets of start and
terminal nodes respectively for each agent specie vi ∈ V . Note
that these nodes can represent the same or different physical
locations in the real world.
s1

v1
v2

s2
s3

ev

ev

s m
1 1 1

m1
ev

u1
u2

m m
1 1 2

m2
v3

m u
1 1 1

u3

Fig. 4: Graphical model with 3 agent species and 2 tasks. The arrow type
differentiates which agent specie an edge belongs to. Three edges are labeled
as examples.

For each agent specie vk ∈ V , there is an edge evk sk i from
the start node to the task node i ∈ M and an edge evk iuk from
the task node i ∈ M to its terminal node. For simplicity, we
also use notation eksi for evk sk i and ekiu for evk iuk , as there
will be no ambiguity for the start and terminal node once vk
is determined. Between each task node pair i, j ∈ M , there
are edges ekij and ekji ∈ E for all agent species k ∈ V .
Under this setting, the agents of specie vk should start at
sk , follow the edges to visit a subset of task nodes (often
together with other agents), and terminate at uk . As a result,
the agent numbers on the edges form a network flow from the
start to the terminal nodes in the given graph G. Based on
the graphical model G and all the above definitions, a mixedinteger program (MIP) can be formulated.
Compared to [16], two major differences in this work are
that the nodes and edges are defined for agent species instead
of individual agents (there are fewer copies of nodes and
edges) and the agent number on an edge is now real instead of
binary. These changes reduce the graph size and the number of
variables and, therefore, decrease the computational cost of the
planner. However, as the model does not specify variables for
individual agents, the MIP outputs agent flow of each specie
instead of path plans for individual agents. We will discuss
algorithms for post-processing the agent flows to get routes
for individual agents in Sec. V.

C. Risk Minimization Model
In this section, we discuss a MIP model that generates a
schedule and agent team for each task, and the corresponding
agent flow by minimizing the energy cost and the risk of task’s
non-completion. Here we provide common notations that will
be used in TABLE II. Note that the variables are xkij , yki ,
rkij , rki , qi , and gki .
1) Variable Bounds: The numbers of agents from specie
k ∈ V on an edge and at a task node are positive and real.
Their helper variables are binary. The time and cumulative

5

within the capacity limit Bk . However, it is possible that the
most costly path is not picked during the flow decomposition
procedure (Sec. V). This is a compromise made by us along
the process of improving the scalability of the model: we
replace the variables for individual agents with variables for an
entire agent specie. With the original variables for individual
agents, necessary and sufficient energy constraints were easily
imposed.
5) Time constraints: (15) is a scheduling constraint: for an
agent, the time duration between two consecutive tasks should
be larger than the service time at the previous task plus the
travel time. Since this duration constraint is effective for all
agents in a team, it gives all the agents in the team enough
time to arrive before the current task starts.

Table II: Definition of the notations.
Meaning
xkij
yki
rkij
rki
qi
gki
bkij
tkij
tki
Cq
Clarge
Bk
hi

The number of agents on edge ekij with specie k ∈ V , where
i ∈ M ∪ S and j ∈ M ∪ U .
The number of agents at task i ∈ M with specie k ∈ V .
= 1, if xkij ≥ 1, otherwise 0. (A helper variable indicating
whether there are agents with specie k on that edge.)
= 1, if yki ≥ 1, otherwise 0. (A helper variable indicating
whether there are agents with specie k at that task.)
The time that task i ∈ M begins.
The maximum cumulative energy that an agent of specie k ∈
V has spent at node i. (A helper variable.)
The deterministic energy cost to travel edge ekij (k ∈
V, i, j ∈ N ).
The deterministic time to travel edge ekij (k ∈ V, i, j ∈ N ).
The deterministic time for agent specie k ∈ V to complete its
part for task i ∈ M .
Time penalty coefficient.
A large constant number for the MIP.
The energy capacity of agent k ∈ V .
The conditional value at risk from task i ∈ M .

qi − qj + tkij + tki ≤ Clarge (1 − rkij ) ∀i, j ∈ N, ∀k ∈ V
(15)

energy are positive.
xkij ≥ 0, yki ≥ 0 ∀i, j ∈ N, ∀k ∈ V

(3)

rkij , rki ∈ {0, 1}

(4)

qi ≥ 0

∀i, j ∈ N, ∀k ∈ V

∀i ∈ M ∪ U,

gki ≥ 0

qi = 0 ∀i ∈ S

∀i ∈ M ∪ U,

gki = 0 ∀i ∈ S

(5)
(6)

2) Helper Variable Constraints: (7) encodes the relationship between agent number variables {xkij , yki } and their
helper variables {rkij , rki }.
xkij ≥ rkij ,
yki ≥ rki ,

xkij ≤ nk · rkij ,
yki ≤ nk · rki ,

∀i, j ∈ N, ∀k ∈ V

∀i ∈ N, ∀k ∈ V

(7)
(8)

3) Network flow constraints: (9)-(11) are flow constraints
that ensure the agent numbers are smaller than the upper
bound, and that the incoming agent number at a node equals
the outgoing number. (12) reflects the relationship that the
number of agents at a node equals the sum of the agent flows
from all incoming edges.
X
X
xkim =
xkmj ∀m ∈ M, ∀k ∈ V
(9)
j∈U ∪M

i∈S∪M

X

xksi ≤ nk

∀k ∈ V

(10)

∀j ∈ M, ∀k ∈ V

(11)

i∈M

ykj ≤

X

xksi

i∈M

ykj =

X

xkij

∀j ∈ M, ∀k ∈ V

(12)

i∈S∪M

4) Energy constraints: (13) ensures that the maximum
cumulative energy at node j is no smaller than the energy at
its previous node i plus the edge cost in between. And because
gki is the maximum cumulative energy of agent specie k at
node i, (14) ensures the energy cost for an agent of specie k
does not exceed its energy capacity Bk .

6) Task requirement constraints: Though the task requirements and the agents’ task capabilities are stochastic, we
can add a deterministic constraint that requires the teams’
expected capabilities to satisfy the task requirement by driving
the requirement function toP
1. Note that for non-cumulative
capabilities, we replace the
in (16) with min.
X
X
1 = ρi (
E{cka1 }yki ,
E{cka2 }yki , · · · ) ∀i ∈ M (16)
k∈V

k∈V

7) Objective function: In the objective function (17), we
want to minimize a weighted combination of the energy cost,
task time, and the conditional value at risk of the task’s noncompletion. Here, the task m1 in (1) is used as an example
to illustrate the math definition of the risk of a task hi . mi
requires the capability of a1 -a4 . Assuming these requirements
on these capabilities are independently placed, the total risk
is the sum of the risk of each requirement. Take a3 in (1)
as an example, where the task requires the team capability
larger than a threshold, αa3 ≥ ra3 . Since both αa3 and γa3 are
stochastic, in order to maximize the probability P (αa3 ≥ γa3 ),
we instead, minimize the CVaR of γa3 − αa3 . Let the function
ηβ (·) be the CVaR of a random variable with probability level
β. The risk hm1 a3 can be computed according to 20 or 19
depending on whether a3 is cumulative or not.
X X
X
X
min Ce
bkij · xkij + Cq
qi + Ch
hi (17)
k∈V i,j∈N

i∈U

hm1 = hm1 a1 + hm1 a2 + hm1 a3 + hm1 a4
hm1 a3 =
hm1 a3

max
ηβ (−cka3 + γa3 )
X
= ηβ (−
cka3 · ykm1 + γa3 )
k∈V s.t. rkm1 =1

i∈M

(18)
(19)
(20)

k∈V

Given the uncertainty in the capabilities, the objective
function (12), together with the deterministic task requirement
constraint (16), tries to maximize the probability of task
success at a low energy and time cost.

gki − gkj + bkij ≤ Blarge (1 − rkij ) ∀i, j ∈ N, ∀k ∈ V (13)
gki ≤ Bki

∀i ∈ N, ∀k =∈ V

(14)

These energy constraints are sufficient conditions as they
assure the most costly path in the flow network of specie k is

D. Sample Average Approximation (SAA)
Solving the optimization specified by (3)-(20) requires
dealing with stochasticity and nonlinearity. In this section, we

6

show how to convert this stochastic mixed-integer nonlinear
program (MINLP) to a deterministic mixed-integer linear
program (MILP).
Notice that the E{cka } in (16) and the ηβ (−cka3 + γa3 ) in
(19) do not involve decision variables, these can be computed
prior to the optimization, given the distribution of the c’s and
γ’s. The stochsticity is eliminated by the expectation and risk
function. The deterministic task requirements (16) can then be
represented with a set of linear constraints according to [16].
(19) can also be represented as a linear constraint as in (21).
hm1 a3 ≥ ηβ (−cka3 + γa3 ) · rkm1

k∈V

(21)

The only non-linearity is in (20) due to the function ηβ (·)
and the decision variable ykm1 . However, we can linearize it
using the sample average approximation algorithm. Suppose
we can represent the random distribution cka3 and γa3 by
(ξ)
(ξ)
samples cka3 and γa3 (ξ = 1, · · · , nξ ), respectively. Then we
can approximate (20) with a linear equation (22) according to
−1/2
[51]. The approximation converges at the rate of O(nξ
)
[52].
hm1 a3 =λm1 a3 + 1/nξ (1 − β)·
#+
nξ "
X
X (ξ)
(ξ)
−
cka3 · ykm1 + γa3 − λm1 a3
ξ=1

(

x,
[x] =
0,
+

(24)

ξ=1

(ξ)
wm
≥−
1 a3

X

(ξ)

cka3 · ykm1 + γa(ξ)
− λm1 a3
3

(25)

k∈V
(ξ)
wm
≥0
1 a3

4
5

6
7
8
9
10

11
12
13
14
15

Input: The unsolved optimization problem (27)-(30)
for m ∈ M and a ∈ A do
Lma = 0
while True do
Solve the first stage problem (27)-(31) and let
[p]
[p]
[p]
[p]
[p]
(yv1 m , · · · , yvnv m , λma , θma , xkij ) be the solution.
flag = True
for m ∈ M and a ∈ A do
// Lma is abbreviated to L in the following lines.
for ξ =1 : nξ do
Solve the second stage problem (32)-(34) and let
(ξ)[p]
πma be the Lagrangian multiplier associated
(ξ)[p]
with the solution wma .
[L]

[L]

Calculate Dma and dma according to (35)-(36).
[L]
[p]
[p]
[p]
[p]
[L]
if Dma [yv1 m , · · · , yvnv m , λma ]T + θma < dma
then
flag = False
L=L+1
Add the cut
[L]
Dma [yv1 m , · · · , yvnv m , λma ]T + θma ≥ d[L]
if flag then
[p]
return the solution xkij // Optimality obtained.

(22)

Finally, the piece-wise linear function in (22) can be represented as linear constraints in (24)-(26).
nξ
X
1
(ξ)
wm
1 a3
nξ (1 − β)

3

17

(23)

hm1 a3 = λm1 a3 +

2

16

k∈V

x>0
x≤0

Algorithm 1: L-shaped algorithm for the model.
1

(26)

IV. T HE L- SHAPED A LGORITHM
In the previous section, we formulate the stochastic heterogeneous teaming problem as an MINLP optimization and
approximate it as a MILP using sample average approximation. However, the number of variables and constraints in
the linear program is a function of the sample number nξ .
When the sample number dominates, the size of the linear
program is roughly O(nξ ), and the computation complexity is
O(n2ξ ). Therefore, when the sample number is large, solving
the teaming problem through MILP can still be expensive.
Due to the specific structure of the large MILP described
in Sec. III, we can explore the sparsity and decouple the
large problem into a two-stage linear program. This method
is called the L-shaped algorithm [53], which returns the same
optimal solution but reduces the computation cost from O(n2ξ )
approximately to O(nξ ) with a larger constant coefficient
empirically.
The general structure of the algorithm is summarized in
Algorithm 1. At the first stage, the algorithm solves a fixedsized mixed-integer linear program (the size is not a function

of nξ ). At the second stage, it solves nξ small linear programs
and then adds cuts to the first stage program according to
the second-stage solutions. The two stage is iterated until
convergence.
The first stage problem in the algorithm is (27)-(31). Note
that equations (27)-(29) are the same as (17), (19), and
(21), but are copied here for clarity. If capability a3 is noncumulative, then hm1 a3 is calculated according to (29). If
a3 is cumulative, the large linear program described in (24)(26) is replaced with (30)-(31). θm1 a3 is a lower bound for
Pnξ
(ξ)
ξ=1 wm1 a3 in (25), and is tightened iteratively with cuts in
(31) obtained from the second stage. Note that (29)-(31) and
the following second stage problem as a whole is only an
example for calculating hm1 a3 . Similar operations are applied
to compute all other hma ’s where m ∈ M and a ∈ A.
min Ce

X X
k∈V i,j∈N

bkij · xkij + Cq

X

qi + Ch

i∈U

X

hi (27)

i∈M

s.t. (3)-(16) and
hm1 = hm1 a1 + hm1 a2 + hm1 a3 + hm1 a4
hm1 a3 ≥ ηβ (−cka3 + γa3 ) · rkm1 k ∈ V
1
hm1 a3 = λm1 a3 +
θm a
nξ (1 − β) 1 3

(28)
(29)
(30)

[`]
Dm
[yv1 m1 , · · · , yvnv m1 , λm1 a3 ]T + θm1 a3 ≥ d[`]
1 a3

∀` = 1, · · · , L

(31)

The second stage problem is described in (32)-(34): once
ykm1 and λm1 a3 are determined in the first stage, the large
linear program in (24)-(26) can be decoupled into nξ small
linear programs with analytic solutions.

7

s1
(ξ)
min wm
1 a3

s.t.

(ξ)
wm
1 a3

(32)
≥−

X

(ξ)
cka3

·

[p]
ykm1

+

γa(ξ)
3

−

λ[p]
m 1 a3

v1
v2

(33)

s2

(34)

s3

0.6

m1

1.4
0.6

1.0

k∈V
(ξ)
wm
≥0
1 a3

An additional optimality cut can be added in (31) according
(ξ)[p]
to the Lagrangian multipliers (simplex multipliers) πm1 a3
associated with the second stage solutions. The parameters
of the cuts are calculated as follows in (35)-(36).
[L]
=
Dm
1 a3

nξ
X



(ξ)[p]
cv1 a3 , · · · , cvnv a3 , 1
πm
1 a3

X

u2
m2

1.0
u3

v3
(a)

s1

v1

xv

s m=
1 1 1

bv

0.6→1= x’v s m
1 1 1
m1

u1

s m
1 1 1

0.6→1

1.4→2

(35)

2.0→3

m2

ξ=1
nξ

d[L]
m1 a3 =

u1
2.0

(ξ)[p]
πm
· γa(ξ)
1 a3
3

(36)
(b)

ξ=1
(ξ)[p]

The Lagrangian multipliers πm1 a3 are obtained by solving
the second stage dual problem (37)-(38), and the solutions are
shown in (39).
!
X (ξ)
[p]
(ξ)
[p]
(ξ)
(37)
max −
cka3 · ykm1 + γa3 − λm1 a3 · πm
1 a3
k∈V
(ξ)
≤ πm
1 a3

s.t. 0
≤1

P (ξ)
[p]
[p]
(ξ)
0, −
cka3 · ykm1 + γa3 − λm1 a3 < 0
(ξ)[p]
k∈V
πm
=
1 a3
1, otherwise

(38)
(39)

V. D ECOMPOSE AGENT F LOWS INTO PATHS
Solving the teaming problem in Sec. III using the algorithm
in Sec. IV provides the optimal solutions to xkij , ∀k ∈
V, ∀i, j ∈ N , i.e. the flows of different agent species. An
example is shown in Fig. 5a, where the flow values are
not necessarily integer. This section discusses an optimal
algorithm to extract a routing plan for each individual agent
from the agent flows.
Formally, A flow network is a graph G(N = S ∪ M ∪
U, E) with a function f (·) : E → R, where S, M , U , and
E denotes the set of start nodes, intermediate nodes, terminal
nodes, and directed edges, respectively. For a node m ∈ M ,
in
suppose the incoming and outgoing edge sets are Em
and
out
Em , respectively. Then, the function f (·) should satisfy (40).
In this section, the flow function f (ekij ) = xkij indicates the
agent number on an edge.
X
X
f (e) =
f (e) ∀m ∈ M
(40)
in
e∈Em

out
e∈Em

A. Problem Description
Because the agent numbers cannot be fractional, we need
to round off these flows to integers and then pick individual
agents and their paths to cover the flow. As an example, the
flow network of v1 is extracted and rounded off in Fig. 5b.
Then, in Fig. 5c, three individual agent paths with flows of
1 on the path edges are selected such that the sum flow of
the three paths equals the rounded integer network flow in
Fig. 5b. Note that in order to maintain the task requirements

s1

v11

1

v12
1
v13
1

m1

u1

m2

(c)
Fig. 5: Decompose a flow into paths. The x’s are the flow on an edge, with
the red numbers an example of the actual value. The b’s are the energy cost
of the edge. (a) Resulted agent flows. (b) The flow of agent specie v1 . (c)
The path cover of agents specie v1 using three individuals.

in equation (1), we have to round up a fractional flow rather
than round it to the nearest integer. This rounding up results
in a suboptimal but still feasible solution.
The rounding up process has to maintain the flow constraints: for all of the nodes, the incoming flow equals the
outgoing flow. A naive rounding up might break the flow
constraint. Take the node m3 in Fig. 6a as an example: naively
rounding up the flows on an edge will result in 2 incoming
agents but 3 outgoing agents.
When the flow constraints are maintained, there can still be
multiple rounding off choices. For instance, the Fig. 6b-c are
both valid ways to round off the flow in Fig. 6a. However,
the energy cost of the flow in Fig. 6c is higher. Therefore, the
optimal rounding up will need to maintain the flow constraint
and introduce the lowest additional energy cost.
After rounding off the flow to integers, there are multiple
choices to assign individual agent paths. We call this ‘cover
a flow with paths’. For example, the flow in Fig. 6b can be
covered with the 3 agent routes either in Fig. 7a or Fig. 7b.
Though the sum energy costs are the equivalent, the energy
cost of the three paths in the two choices are {20, 20, 20} and
{20, 24, 16}, respectively. The choice affects the behavior
of an individual agent. Here, we prefer the former cover,
because the energy costs of individual agents are more evenly
distributed and the maximum energy cost of an individual
agent is smaller. We define the optimal flow cover as the set
of paths that minimizes maximum individual energy cost.

8

agent
flow
v1 1.0
5

s1

0.5
8
energy
cost

m4
m1

5
5
0.5
m5 0.5
5
5
0.6
0.6
3
3
m6

1.0
5

m3

0.5
8

m2

0.4

0.4

u1

(a)

m4
v1

m1

2

s1

2

1

1

m3

1

1

1
m5
1

m2

1

u1

1
m6

cost individual paths. This section discusses a linear program
to round the real-numbered flow with minimum additional
energy cost.
See Fig. 5b as an example, suppose the flow output from
the MIP model in Sec. III for agent specie k ∈ V is xkij
on edge ekij . Let the integer flow after the rounding off
process be x0kij . Then, the linear program in (41)-(44) will
return an integer flow network with minimum energy cost.
The objective function (41) penalizes the energy cost. (42)
ensures the rounding off is happening upward, where dxkij e
denotes the smallest integer larger than xkij . The network flow
constraint (44) should be maintained during the optimization.
S, U , and M are the set of start, terminal, and task nodes
respectively. N = S ∪ M ∪ U .
X
min
bkij · x0kij
(41)
i,j∈N

(b)

s.t. x0kij ≥ dxkij e

m4
v1
s1

m1

1
2

1

m3

2

m5
1

m2

=0
X
xkim =

1

1

1

x0kij

1

u1

1
m6

(c)
Fig. 6: Round up the flow of agent specie v1 . The red number is the agent
flow on an edge. The black number below an edge are the energy cost of the
edge. (a) The original flow with real numbers. (b) Round up choice 1. (c)
Round up choice 2.

m4
v1
s1

m1

7
energy
cost

5

5
5

5

m3

m5

5

u1

5

7

m2

3

3
m6

(a)

i∈S∪M

X

∀xkij > 0

(42)

∀xkij = 0

(43)

∀m ∈ M

(44)

xkmj

j∈U ∪M

Note that there is no explicit integer constraint here to
assure that x0kij is integer. However, if this linear program is
solved using Simplex-based algorithms, the solutions to x0kij
are guaranteed to be integers. Because of this, the minimum
energy rounding off problem could be solved in polynomial
time through a linear program (instead of an integer linear
program).
A brief proof that solutions will be integers: since this
round up problem falls in the category of minimum cost
flow problems, if converted to the form min cT x with Ax ≤
b, x ≥ 0, the A matrix will be totally unimodular [54].
Meanwhile, the entries in b will be integers. Because of the
total unimodularity, all extreme points (possible solutions) of
the polytope defined by the linear constraints, Ax ≤ b and
x ≥ 0, will be integers. And an integer solution is guaranteed
if Simplex-based algorithms are applied as it searches through
the extreme points.

m4
v1
s1

m1

7
energy
cost

m2

m3

5

C. The Minimum Max-Energy Flow Cover

5

5
5

5

m5

u1

5

7
3

3
m6

(b)
Fig. 7: Cover the agent flow in Fig. 6b with 3 paths. The black number below
an edge are the energy cost of the edge. There are two choices with different
individual costs. (a) Choice 1. (b) Choice 2.

B. The Minimum Energy Cost Rounding Up
According to the previous section, optimally decomposing
a real-numbered agent flow into individual agent routes can be
divided into two steps: rounding up to an integer flow with the
lowest additional cost and covering the integer flow with low-

After the rounding off, we get the integer flows x0kij in
Fig. 5b, the next step is to decompose this integer flow into
individual agent paths in Fig. 5c. By summing up the out going
flow at the start node, we are able to get the needed number of
agents from specie k ∈ V , denoted as n0k . Then we compose
n0k graphs as in Fig. 8 for the n0k agent individuals for k ∈ V .
We can formalize an integer linear program (ILP) to find
the routes for all the individual agents, such that the maximum
individual energy cost is minimized and the unit agent flow on
these paths sums up to the original network flow in Fig. 5b. In
the following ILP, the objective (45) penalizes the maximum
energy cost of an individual agent. (46) ensures that the result
agent flows in Fig. 8 sum up to Fig. 5b. (47) is the network
constraint. (48) requires that in each subgraph in Fig. 8, there
is only one agent.

9

X

min max
xlkij

l

bkij · xlkij

(45)

i,j∈N

0

s.t.

nk
X

xlkij = x0kij

∀i, j ∈ N

(46)

l=1

X

xlkim =

i∈N

X

X

xlkmj

∀m ∈ M, ∀l = 1, · · · , n0k (47)

j∈N

xlksi

= 1 ∀l = 1, · · · , n0k

(48)

Table III: The computational cost of the flow decomposition. ‘Task’ is the
number of tasks, which equals to the number of nodes in the flow network.
‘Flow’ is the sum agent flow number from the start to the terminal node and
‘int flow’ is the value after rounding off. The ‘round time’ and ‘cover time’
are the time used to solve the rounding and cover problems, and the units are
both seconds.
Case

Task

Edge

Flow

Int flow

Round time

Cover time

1
2
3
4
5

5
10
10
35
70

15
29
27
101
211

155.56
24.89
212.64
139.40
148.26

161
33
220
173
234

0.001
0.001
0.005
0.002
0.001

0.69
0.15
1.28
10.58
142.58

i∈M

xlkij ∈ 0, 1

s1

∀i, j ∈ N,
1
s m
1 1 1

v1

∀l = 1, · · · , n0k

xv

1
m
1 1

1

xv

s m
1 1 2

m

xv

m1

1

(49)

u1

xv

m u
1 2 1

2

m2

(a)

s1

2

v1

xv

s m
1 1 1
2
m
1 1

2

xv

s m
1 1 2

m

xv

m1

2

u1

xv

m u
1 2 1

2

m2

(b)

s1

3

v1

xv

s m
1 1 1
3
m
1 1

3

xv

s m
1 1 2

m

xv

m1

3
xv m u
1 2 1

u1

2

m2

(c)
Fig. 8: Graphical model for the minimum max-energy flow cover problem
for agent specie v1 . The x’s are the flow on an edge. (a)(b)(c) are the flow
networks for the three agent individuals of specie v1 .

the node number of the network. The optimization models in
Sec. V are then applied to the initialized random flow network
to solve the minimum energy cost rounding up and minimum
max-energy flow cover problems. The computational costs
and the optimality of the solutions are then evaluated under
different sizes of test cases.
2) Result and Discussion: Different sizes of flow decomposition problems are solved, and the computational costs of
the two steps are listed in TABLE III. The size of the rounding
and cover problems are proportional to edge number and edge
number × sum integer flow, respectively. For the cases shown
in TABLE III, the rounding steps can be completed within
several milliseconds. The rounding process scales well because
the linear program can be solved in polynomial time. The
cover step involves solving an integer linear program, which
does not scale well generally with the problem size. The largest
test case shown in the table involves 70 tasks and 234 agents,
much larger than the typical teaming problem sizes that the
risk minimization model will be applied to. Therefore, the flow
decomposition part will not be the bottleneck of the overall
teaming planner.
Though there are no explicit integer constraints in the
rounding up model in Sec. V-B, we provided a proof in Sec.
V-B that showed that the solutions would be integers, and the
results support it. As an example, the rounding up solution of
case 1 is shown in Fig. 9, where we can see that the agent flow
on each edge is rounded up to an integer, while the overall
network flow constraint is maintained. For instance, the 13.41
on edge (S, 1) is rounded to 15 instead of 14 in order to
maintain the flow constraint.
B. Capture the Flag

VI. E XPERIMENTS AND R ESULTS
In this section, we first initialize randomized flow networks
to test the model of decomposing agent flows, and then
use two practical applications to show the robustness and
generalizability of the proposed risk minimization model. All
computations were done on a laptop with Intel i7-7660U CPU
(2.50GHz).
A. Decompose Agent Flows into Paths
1) Setup and Test Cases: An agent flow network with
random connections is initialized, and the flow and unit cost
of each edge are sampled from uniform random distributions.
The hyper-parameters are the maximum flow on an edge and

In this section, we apply the risk minimization model in Sec.
III to a team of agents in a capture the flag game setting and
compare the team performance against the baseline (STRATA
[43]) in a simulation environment (Fig. 10). The goal of this
simulation is to evaluate and demonstrate the performance of
the task assignment component of our framework. The number
of wins is used as the metric for the task performance.
1) Game Setup, Baseline, and Metrics: The blue and green
teams contain 12 heterogeneous agents initialized at random
locations within their own sides. The overall goal is to win
the game by taking the flag of the other side back. The 12
agents are from 4 species (3 individuals for each specie). These
species are with different speed, viewing distance, health, and
ammunition capabilities (TABLE IV). The specific values in

10

number of wins in 500 games, which reveals the relative task
assignment performances. A win is either a team taking back
the other side’s flag or defeating all enemies using bullets.
A draw happens when all agents from both sides decide to
defend and no longer attack, or no team wins the game within
120 seconds.

Fig. 9: Flow round up result (5 task nodes, 15 edges). There are two numbers
on each edge, indicating the agent flows before and after the round up process.
This example corresponds to case 1 in TABLE III.

Both STRATA and our model need task requirements specified as capability distributions. For the three tasks, the agents
are programmed to switch to heal automatically when their
health is lower than a threshold, and the required capabilities
of the attack and defend tasks are listed in TABLE VI. The
specific numbers are manually decided to reflect the following
requirements: the attack task needs agents with higher speed
and health to capture the flag, while the defend task needs
agents with higher viewing distance and ammunition to detect
and defeat the opposing team.
Table IV: Capability distributions of the four agent species. µi and σi2 (i =
1, · · · , 4) are the mean and variance of the capability distributions of speed,
viewing distance, health, and ammunition.
Specie

µ1

µ2

µ3

µ4

σ12

σ22

σ32

σ42

1
2
3
4

1.5
1.5
3
3

2
4
2
4

90
60
80
350

40
40
30
30

0.35
0.35
0.35
0.35

0.1
0.1
0.1
0.1

10
10
10
10

3
3
3
3

Table V: General task descriptions.
Task

Fig. 10: Capture the flag setup. Each small square tile is 1 × 1 unit length.
A line points to the current target of the corresponding agent.

the table are set according to the baseline paper [43]. Among
these capabilities, the first two are noncumulative, while the
last two are cumulative.
Each agent can play a role in one of the 3 tasks in
TABLE V and will disappear when its health reaches zero. The
adversarial elements of the game are not explicitly modeled,
and the focus is to assign tasks such that the requirements are
fulfilled while overall time and energy costs are considered in
the trade-off. Therefore, the agents follow predefined behaviors
once their tasks are determined.
STRATA [43] is chosen as the baseline of this work
because its model makes use of similar concepts like agents,
species, capability vectors, and task requirements specified by
capabilities. While STRATA has no ability to output a schedule
of the tasks, the tasks in this game are all ‘life-long’ tasks, and
in such a setting, there is no scheduling aspect, and CTAS
reduces to an instantaneous task assignment, tackling the
same type of problem as STRATA does. Therefore, this game
simulation will give us a fair comparison between STRATA
and the task assignment component of our work under the
metric of number of wins. Apart from STRATA, we also
compare our model to a random task assignment mechanism
where an agent is randomly assigned a task.
All games are played with two teams using different assignment models. The metric used in this simulation is the

Attack
Defend
Heal

Description
Try to capture the flag of the other side
Apply a defense mode to defeat opposing team members
Use hearts to apply healing powers

Table VI: Task requirements specified as capabilities distributions. The 1131
is 65% of the expected total initial health of the 12 agents, and 231 is 55%
of the expected total ammunition.
Speed
Attack
Defend

View

≥2

Health

Ammunition

≥ 1131 (65%)
≥1

≥ 231 (55%)

2) Results: Based on all the settings described in the above
section, we developed a simulation environment in C++. A
screenshot is shown in Fig. 10. The three task assignment
models, random, baseline, and CTAS, are linked with the
simulation environment. During the simulation, the mean
time for the baseline and CTAS to optimize and output an
assignment are 0.43 and 0.04 seconds, respectively.
The relative performances of the models are shown in Fig.
11. As can be seen from Fig. 11, CTAS results in a higher win
rate as compared to the baseline or random selection methods.
The number of agents assigned to attack, grouped by
species, are shown in Fig. 12. According to the figure, CTAS
is more likely to use specie 4 and does not use species 1 and
2. The baseline methods shows a similar trend of preferring
specie 4 over the other species. This preference is logical
since specie 4 contains attributes of high speed and health,
which are more suitable for the attack task than other species’
attribute distributions (particularly specie 1 and 2). Though the

11

baseline claims to be able to consider noncumulative capability
through thresholding, it lacks an explicit mechanism to prevent
incompetent agents from joining a task. For instance, though
specie 1 and 2 are not competent for the attack task due to
their low speed, they are still allowed to conduct the task
and contribute to other required capabilities such as health.
However, this is not a good choice as there exist other
agents that satisfy both the speed and health requirements
of the attack task. Another possible factor contributing to
CTAS’s improved performance is that the CTAS algorithm
directly minimizes the CVaR metric, which ensures enough
task required capabilities, whereas the baseline focuses on
matching the expected requirements and penalizing variance
of the assigned capability distributions.
In conclusion, through the comparison, our framework
demonstrates superior task assignment performance against the
baseline algorithm, and the task assignment patterns in Fig. 12
support this performance result.
Blue Wins
Random vs. Baseline

194

Random vs. CTAS

22

151

Baseline vs. CTAS

Draws

284

25

203

Green Wins

324
4

293

Number of agents assigned to attack

Fig. 11: Relative performances of random task assignment, baseline, and
CTAS. Each row shows the mean result from ten 500 capture the flag games.

6
Random
Baseline
CTAS

5
4
3
2
1
0
1

2

3

4

All

Agent species
Fig. 12: Agent assigned to attack.

C. Robotic Services during a Pandemic
In this section, we demonstrate how the CTAS framework
can be applied to a real-world example and show the full task
assignment and scheduling components of the framework. A
different application than the capture-the-flag game in Sec.
VI-B also supports the claimed generalizability of CTAS. The
energy cost and probability of success will be used to evaluate
the optimality of the plans generated by the framework. The
optimality gap given limited time for the optimization will be
used to evaluate the scalability of the framework.
The COVID-19 pandemic has strongly affected society,
industry, and daily lives around the world. On the other
hand, it stimulated robotic applications in hospitals, public

health, transportation, and manufacturing to reduce physical
human interaction [55]. Autonomous and teleoperated drones,
vehicles, humanoids, and manufacturing robots are utilized to
handle or assist disinfection and cleansing, patient diagnosis
and treatment, medical triage, quarantine enforcement, delivery, and medical kit manufacturing [55]–[57]. A pandemic response or post-pandemic recovery mission requires all of these
robots to form teams, cooperate, and handle tasks together. In
such a situation, it is important for the task assignment and
scheduling framework to capture the agents’ heterogeneity,
quickly adapt to changes in the task setup, and consider the
uncertainty due to the lack of information. Therefore, this
section uses this pandemic robotic services coordination as
an example and shows how our framework considers the
heterogeneity and uncertainty in a practical problem.
To the best of our knowledge, no existing framework focuses on the same HTP as this work (though there are models
solving some components of this problem in the context of
vehicle routing and task allocation). Therefore, we compare
the current model to the one in our previous work [16].
1) Experiment Setup and Model Description: Consider
pandemic robotic services in a city environment consisting
of multiple delivery, disinfection, test, and treatment subtasks that require one or multiple robots to complete. The
task requirements and agent capabilities are uncertain. We
choose to include 8 types of tasks and 7 agent species in this
illustration based on our investigation. These chosen tasks are
a subset of the tasks we mentioned above at the beginning
of this section. Note that some of the agents need a human
operator.
Applying the CTAS model to describe the problem of the
pandemic robotic services, we first define 9 capability types
according to the chosen tasks and agents in TABLE VII.
The 7 agent species and their capabilities are defined in TABLE VIII, according to real-world references [55]. The agent
capabilities are random variables and are assumed Gaussian
distributed in this example.
The 8 task types and their required capabilities are listed in
TABLE IX. Apart from the ones with self-explanatory names,
we add further explanation to the following tasks. m3 medical
kit delivery: the team should be equipped with freezers; m4
contaminants removal: remove contaminated materials and
then disinfect the location; m5 open area disinfection: perceive
and locate a contaminated area to conduct contaminants removal and disinfection; m6 quarantine enforcement: perceive,
locate, carry materials to, disinfect a contaminated area, and
then place signals and barricades to enforce a quarantine in
the area. These tasks are distributed in a city. An example
of 16 tasks (two tasks from each type) is shown in Fig. 18a.
The agents start from the base, which, in practice, can be a
hospital.
We use the M3500 data set [58] as the city’s road map
in this illustration. Suppose we can receive information about
the safe and contaminated regions. For instance, if a location
in the city map is exposed to viral contamination, we can
then regard the neighborhood as dangerous and set the cost
to travel within that area as high. Based on such an idea,
a cost map indicating the viral exposure in an area can be

12

Table IX: Task requirements. A value in the table is the requirement for that
specific capability. γ is a scaling coefficient. E.g., the γ in (row 1, column
3) means task type m1 requires the team’s capability a3 ≥ γ. When γ
is set larger, more agents get involved in the optimization and the problem
space is larger. We do not scale non-cumulative capabilities. For one task, the
requirements on different capability types are imposed with ‘and’ logic.

Table VII: Definitions of the capability types.
Definition
a1
a2
a3
a4
a5
a6
a7
a8
a9

Fly
Equipped with a freezer
Deliver materials
Conduct perception
Remove and collect harmful materials
Conduct viral test
Physically interact and conduct treatment
Spray disinfectant
Place signals and barricades to conduct quarantine enforcement

Table VIII: Agent capabilities. The values are expectations of the random
distributions, and the standard deviations are 10% of the expectations.
Agent specie

a1

v1 :
v2 :
v3 :
v4 :
v5 :
v6 :
v7 :

1

Quadcopter
Vehicle
Vehicle (freezer)
Vehicle (contaminants)
Guidance robot
Test robot
Treatment robot

a2

a3

a4
1

1

1
1
1

a5

a6

a7

a8

1

Goods delivery
Goods delivery (fly) 1
Medical kits delivery
Contaminants removal
Open area disinfection
Quarantine enforcement
Viral tests
Remote treatment

a3

γ

γ
γ
γ
γ

a4

a5

γ
γ

γ
γ
γ

a6

a7

γ
γ

a8

a9

γ
2γ
γ

10γ

γ

Table X: Three teaming models. ‘Agent var’ stands for ‘agent variables’.
2

Model

Agent var

Objective

Variable number

5

CTAS-O [16]
CTAS-D
CTAS

Binary
Real
Real

Energy + Time
Energy + Time
Energy + Time + Risk

Large
Relatively small
Relatively small

1
1
1

m1 :
m2 :
m3 :
m4 :
m5 :
m6 :
m7 :
m8 :

a2

a9

1

1

a1

Task type

1

modeled as a Gaussian process [59] where we use a set of
known Gaussian distributions to infer a collection of correlated
Gaussian distributions. For the example city map in Fig. 18a,
we randomly choose 6 contaminated and 6 proven-safe regions
as samples and learn a viral exposure map. The blue and
red regions have low and high cost, respectively, while the
white regions have less information, high ambivalence, and
are assigned a medium cost. Based on this, we compute a
viral-exposure-based travel cost between the tasks and regard
it as the energy cost for the edges in the diagram in Fig. 4.
We choose the agents and tasks from their types in TABLEs
VIII and IX and compose 32 mission cases of different sizes
where the agent numbers, task numbers, and the coefficient γ
are chosen from {21, 70, 140}, {16, 24, 32, 40}, and {1, 3,
5, 10}, respectively. As an example, the smallest case consists
of 21 agents and 16 tasks, it means there are 3 agents from
each agent specie v1 to v7 . And the 16 tasks in the examples
are distributed according to rule: m1 and m9 are task type
1 in TABLE IX, m2 and m10 are type 2, ..., m8 and m16
are type 8. Note that mi and mi+8 have the same capability
requirements, but are at different location.
Based on these test cases, we evaluate the mission performance and computational cost of the three models in TABLE
X: the model in [16] which optimizes time and energy, the
risk minimization model in Sec. III, and its deterministic
version, where the capability uncertainties are not considered
and the risk part, hi , is removed from the objective function
(17). Note that the model CTAS-O in [16] solves the same
deterministic problem as the CTAS-D in this paper, but has a
binary constraint for each agent (whether this agent is used or
not). Therefore, CTAS-O does not use the flow decomposition
described in Sec. V, but requires a binary variable for each
individual agent instead of agent species. These additional
binary constraints and variables expand the search space and
reduce the scalability.
2) Computational Cost and Discussion: A 120-second time
limitation is added to the solvers of the models. The optimality

gaps after the rounding process in Sec. V-B are given in Fig.
13a. Note that this gap is defined as (objective value - lower
bound) / lower bound. The blue cells mean the solver cannot
find a feasible solution for the specific case within the time
limit. According to the two figures, CTAS-D and CTAS can
solve much larger teaming problems. The largest problem that
CTAS-D can deal with involves 140 agents and 40 tasks.
The increases of the optimality gaps due to the rounding
process are shown in Fig. 13b. For most of the cases, the
rounding process introduces an increase of the optimality gap
within 1%. The leftmost cases have larger increases because
the agent numbers are small, and rounding has larger overall
influences. Since CTAS-O involves no rounding process, the
increased gap is 0 for all test cases.
In these test cases, we assume the agent capabilities are
Gaussian distributed. Therefore, given the estimation of the
means and variances, we can calculate the probability of
success. As shown in (50), the probability that a task can succeed equals the product of the probability that each capability
requirement is satisfied. The mean probability is calculated
according to (51).
Y
P (task i succeeds) =
P (a satisfied) ∀i ∈ M (50)
capability a

!1/nm
mean P (success) =

Y

P (task i succeeds)

(51)

i∈M

The mean probabilities of success for the three models
are shown in Fig. 14. For all cases, CTAS-O and CTASD models roughly result in a probability of 0.25. This is
because each task requires two capabilities on average. When
the risk is not considered, these two models tend only to match
the expected requirement, and the probability of matching a
single capability is 0.5. Clearly, the risk minimization model
increases the probability of success for the tasks. In Fig. 15,
we compare the result of CTAS to its deterministic version
CTAS-D. With the chosen penalty coefficients on energy cost
and task completion, i.e., Ce and Ch in equation (17), for most

13

of the test cases, a ≈20% increase in energy cost introduce
a ≈35% increase in the mean probability of success. More
importantly, the trade-off between energy cost and robustness
depends on the penalty coefficients in the objective function
and can be tuned smoothly. The trade-off gained by changing
the penalty coefficients is shown in Fig. 17, using the smallest
test case as an example.
m16

CTAS-O

m40

CTAS-D

m24

0.03

0.4m16

0.025

CTAS-D

m32

m24

0.02

0.3m32

m40

0.015

0.2

m16

m16

m24

0.01

m24

CTAS
0.1
m32

m32
m40

0

=1 =1 3 5
v 21
v 70

0.005
0

=1 =1 3 5
v 21
v 70

=1 3 5 10
v 140

(a)

(b)

0.45

m16
m24
m32

0.4

m40
m16
CTAS-D

m24

0.35

m32
m40
m16

CTAS

0.3

m24
m32
m40

0.25

=1 =1 3 5
v 21
v 70

=1 3 5 10
v 140

Fig. 14: The mean probability of success for the tasks using the three models.

m16
CTAS

0.6

m24

0.4
CTAS

m32

0.2

m40
=1 =1 3
5
v 21
v 70

=1 3 5
v 140

(a)

10

10

Fig. 16: The relative approximation gap of the nonlinear CVaR through
sampling and linear programming.
1

0.8

0.6

0.4
Trade-off (Pareto set)
CTAS-D: not penalize risk of task failure

0.7

m16

0.6

m24

0.5

m32

0.4

m40

0.3

=1 =1 3
5
v 21
v 70

=1 3 5
v 140

1.5

2

2.5

3

3.5

Energy cost (relative to the CTAS-D)
Fig. 17: Trade-off between energy cost and risk of task’s non-completion for
the case {16 tasks, 21 agents, and γ = 1}.

Fig. 13: The optimality gap of the three models applied to the 32 test cases.
The colors correspond to the value specified in the color bars on the right.
The blue cells mean the solver cannot find a feasible solution for the specific
case within the time limit. (a) The optimality gap before the flow rounding
process. The two white cells in the CTAS group are outliers whose values are
around 1.0. (b) The increased optimality gap due to the rounding process.

CTAS-O

0

=1 3 5
v 140

0.2

m40

=1 3 5 10
v 140

0.005

=1 =1 3
5
v 21
v 70

0.035

m32

0.5

m40

CTAS

m24
m40

m16

0.01

m32

0.04

m16

m32

m24
m40

Mean probability of success

CTAS-O

CTAS

0.6

m24

0.015

m16

10

(b)

Fig. 15: Comparing the results of CTAS to CTAS-D. The values (colors) in the
girds are (a) increased energy (relative) and (b) increased mean probability
(relative) by adding the risk as an objective. I.e., the values are (CTAS −
CTAS-D) / CTAS-D.

For the sample average approximation of the CVaR, we use
500 samples to approximate the assumed Gaussian distributions. Given the solution, we compare the nonlinear objectives

to their sample approximations, and find that the relative
approximation gaps are smaller than 1% for most of the cases
as shown in Fig. 16. This shows that the approximation quality
is good using 500 samples.
3) Mission Performance and Discussion: In this section,
we take the test case with 16 tasks, 21 agents, and γ = 1 as
an example to compare the solutions generated by the three
models. In TABLE XI, we list the performance metrics and the
probability of 5 tasks whose success rate is increased by the
CTAS model. All three models are solved to optimal within
the time limit. The models presented in this paper end up with
much fewer variables for the same problem. By comparing
CTAS with CTAS-D, we see that the risk minimization model
reduces the CVaR and increases the probability of success
for 5 tasks out of 16, with a small increase (5.3%) in the
overall energy cost. Though CTAS-D and CTAS-O solve the
same practical problem, the CTAS-D model, without explicit
integer constraints on the number of agents, can fulfill the task
requirements with lower cost before the rounding process and
higher cost after.
The teams for the last 8 tasks are shown in TABLE XII.
As expected, the CTAS model puts more agents in the team
to reduce the CVaR. This task assignment is resulted from
simultaneously considering the energy cost. As an example,
CTAS puts more agents in the team of tasks m9 -m12 , but not
tasks m1 -m4 , even if they are of the same types. Because
energy and time costs are jointly considered, and m1 -m4 are
far from the depot, adding more agents to ensure redundancy
and robustness could potentially result in much higher costs.
The risk minimization model also generates the routes and a
consistent schedule. As an example, one v1 , v4 , and v5 visit
task m13 at the same time as a team. The routes of species
v1 , v4 , and v5 are shown in Fig. 18. These routes minimize
overall travel distances and avoid the high-cost red regions to
lower energy costs.

14

100

100

80

80

60

60

40

40

20

20

(a)

(b)

100

100

80

80

60

60

40

40

20

20

(c)

(d)

Fig. 18: (a) Task distribution: the 16 tasks are distributed in a city [58] where the unit travel cost depends on viral exposure. Blue and red stand for low and
high energy costs, respectively. (b)-(d) The planned routes from the CTAS model for species v1 , v4 , and v5 . Different colored lines represent distinct agent
individuals from the same species.

Table XI: A comparison of the results of the three models. The P (mi ), i =
9, · · · , 13 are the calculated probability of success for the specific tasks.

Table XII: Team configurations given by the three models. For task m1 to
m8 , the three models output the same team configurations.

Item

CTAS-O

CTAS-D

CTAS

Task

CTAS-O

CTAS-D

CTAS

Variables
Task CVaR
Energy cost
P (m9 )
P (m10 )
P (m11 )
P (m12 )
P (m13 )

6194
4.99 ×103
2.06 ×105
0.5
0.25
0.25
0.25
0.125

4276
5.41 ×103
2.06 ×105
0.5
0.25
0.25
0.25
0.125

4384
-1.03 ×104
2.17 ×105
1
0.5
1
0.5
0.25

m9
m10
m11
m12
m13
m14
m15
m16

v3
v1
v3
v4
v1 , v4
v2 × 3, v4 , v5
v7
v7

v3
v1
v3
v4
v1 , v 4
v2 × 3, v4 , v5
v7
v7

v1 × 3, v2 × 3, v3 × 3
v1 × 2
v1 × 2, v2 × 3, v3 × 3
v1 × 2, v4
v1 , v4 , v5
v2 × 3, v4 , v5
v7
v7

In summary, according to the teams in TABLE XII and
routes in Fig. 18, the CTAS framework generates a consistent
schedule for coordination, outputs routes that minimize energy
costs, and assign tasks to agents such that redundancy is
preserved at low costs to ensure a higher probability of
task completion. The computational evaluation in Sec. VI-C2
shows that the frameworks CTAS and CTAS-D scale to 140
agents and 40 tasks with low optimality gaps. The scalability
in agent number is better than the task number. Furthermore,
CTAS-D still shows no optimality gap degeneration dealing
with the largest test case we tested.
VII. C ONCLUSIONS AND F UTURE W ORK
This paper addresses a single-task robot multi-robot task
time-extended assignment problem for complex tasks (CD[ST-MR-TA]). We propose a mixed-integer programming

model that simultaneously optimizes the task decomposition,
assignment, and scheduling. The uncertainty within the team’s
capability is considered through risk minimization, and a
robust metric, conditional value at risk (CVaR), is minimized
to ensure robustness. The framework contributes to a domainindependent representation for complex tasks and heterogeneous agent capabilities that can generalize to multi-agent
applications where the major goals are satisfying task-required
capabilities. A two-step solution method is described, and the
whole framework is evaluated in two different practical test
cases. Results show that the framework is scalable to the
number of agents and solves the problems with low optimality
gaps. Given the selected hyper-parameters, the resulted assignments and schedules make a sensible trade-off between energy,
time, and the probability of success. The task assignment

15

performance (apart from the scheduling) is also demonstrated
through the comparison with the STRATA framework in the
capture the flag case.
Future work will consider developing probabilistic learning
methods that automatically estimate the parameters in the
representation of task requirements and agent capabilities
from current and previous task executions. Such learning
methods would enable the possibility of closing the loop of
the task assignment and scheduling, and iteratively improving
the performance.
In future modeling choices, we will consider imposing a
necessary and sufficient energy constraint in the CTAS model
in Sec. III but still preserving the scalability of the current
framework.
ACKNOWLEDGMENTS
DISTRIBUTION A. Approved for public release; distribution unlimited (OPSEC 5240). This research has been
supported by the Automotive Research Center, a US Army
center of excellence for modeling and simulation of ground
vehicles.
R EFERENCES
[1] P. Tokekar, J. Vander Hook, D. Mulla, and V. Isler, “Sensor planning for
a symbiotic uav and ugv system for precision agriculture,” IEEE Trans.
Robot., vol. 32, no. 6, pp. 1498–1511, 2016.
[2] P. R. Wurman, R. D’Andrea, and M. Mountz, “Coordinating hundreds of
cooperative, autonomous vehicles in warehouses,” AI magazine, vol. 29,
no. 1, pp. 9–9, 2008.
[3] J. Werfel, K. Petersen, and R. Nagpal, “Designing collective behavior in
a termite-inspired robot construction team,” Science, vol. 343, no. 6172,
pp. 754–758, 2014.
[4] D. Shishika, J. Paulos, and V. Kumar, “Cooperative team strategies for
multi-player perimeter-defense games,” IEEE Robot. and Autom. Lett.,
vol. 5, no. 2, pp. 2738–2745, 2020.
[5] X. Cai, B. Schlotfeldt, K. Khosoussi, N. Atanasov, G. J. Pappas, and
J. P. How, “Non-monotone energy-aware information gathering for
heterogeneous robot teams,” arXiv preprint arXiv:2101.11093, 2021.
[6] M. Quann, L. Ojeda, W. Smith, D. Rizzo, M. Castanier, and K. Barton, “An energy-efficient method for multi-robot reconnaissance in an
unknown environment,” in Proc. Amer. Control Conf. IEEE, 2017, pp.
2279–2284.
[7] ——, “Ground robot terrain mapping and energy prediction in environments with 3-d topography,” in Proc. Amer. Control Conf. IEEE, 2018,
pp. 3532–3537.
[8] ——, “Chance constrained reachability in environments with spatially
varying energy costs,” Robot. and Auton. Syst., vol. 119, pp. 1–12, 2019.
[9] ——, “Power prediction for heterogeneous ground robots through spatial
mapping and sharing of terrain data,” IEEE Robot. and Autom. Lett.,
vol. 5, no. 2, pp. 1579–1586, 2020.
[10] B. Schlotfeldt, V. Tzoumas, D. Thakur, and G. J. Pappas, “Resilient
active information gathering with mobile robots,” in Proc. IEEE/RSJ
Int. Conf. Intell. Robots and Syst. IEEE, 2018, pp. 4309–4316.
[11] K. Yu, J. M. O’Kane, and P. Tokekar, “Coverage of an environment
using energy-constrained unmanned aerial vehicles,” in Proc. IEEE Int.
Conf. Robot. and Automation. IEEE, 2019, pp. 3259–3265.
[12] Y. Sung, A. K. Budhiraja, R. K. Williams, and P. Tokekar, “Distributed
assignment with limited communication for multi-robot multi-target
tracking,” Auton. Robot., vol. 44, no. 1, pp. 57–73, 2020.
[13] Y. Tan and Z.-y. Zheng, “Research advance in swarm robotics,” Defence
Technology, vol. 9, no. 1, pp. 18–39, 2013.
[14] K. Sundar, S. Venkatachalam, and S. G. Manyam, “Path planning
for multiple heterogeneous unmanned vehicles with uncertain service
times,” in Proc. of the Int. Conf. on Unmanned Aircraft Syst., 2017, pp.
480–487.
[15] G. A. Korsah, A. Stentz, and M. B. Dias, “A comprehensive taxonomy
for multi-robot task allocation,” Int. J. Robot. Res., vol. 32, no. 12, pp.
1495–1512, 2013.

[16] B. Fu, W. Smith, D. Rizzo, M. Castanier, and K. Barton, “Heterogeneous
vehicle routing and teaming with gaussian distributed energy uncertainty,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst. IEEE,
2020, pp. 4315–4322.
[17] B. P. Gerkey and M. J. Matarić, “A formal analysis and taxonomy of
task allocation in multi-robot systems,” Int. J. Robot. Res., vol. 23, no. 9,
pp. 939–954, 2004.
[18] S. D. Ramchurn, M. Polukarov, A. Farinelli, N. Jennings, and C. Trong,
“Coalition formation with spatial and temporal constraints,” Proc. of the
Int. Conf. on Auton. Agents and Multiagent Syst., 2010.
[19] G. A. Korsah, B. Kannan, B. Browning, A. Stentz, and M. B. Dias,
“xbots: An approach to generating and executing optimal multi-robot
plans with cross-schedule dependencies,” in Proc. IEEE Int. Conf. Robot.
and Automation. IEEE, 2012, pp. 115–122.
[20] C. Özgüven, Y. Yavuz, and L. Özbakır, “Mixed integer goal programming models for the flexible job-shop scheduling problems with
separable and non-separable sequence dependent setup times,” Applied
Mathematical Modelling, vol. 36, no. 2, pp. 846–858, 2012.
[21] W.-Y. Ku and J. C. Beck, “Mixed integer programming models for job
shop scheduling: A computational analysis,” Computers & Operations
Research, vol. 73, pp. 165–173, 2016.
[22] J. Moser, J. Hoffman, R. Hildebrand, and E. Komendera, “A flexible
job shop scheduling representation of the autonomous in-space assembly
task assignment problem,” arXiv preprint arXiv:2003.12148, 2020.
[23] S. Liemhetcharat and M. Veloso, “Modeling mutual capabilities in
heterogeneous teams for role assignment,” in Proc. IEEE/RSJ Int. Conf.
Intell. Robots and Syst. IEEE, 2011, pp. 3638–3644.
[24] ——, “Weighted synergy graphs for role assignment in ad hoc heterogeneous robot teams,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots and
Syst. IEEE, 2012, pp. 5247–5254.
[25] E. G. Jones, M. B. Dias, and A. Stentz, “Time-extended multi-robot
coordination for domains with intra-path constraints,” Auton. Robot.,
vol. 30, no. 1, pp. 41–56, 2011.
[26] M. Pujol-Gonzalez, J. Cerquides, P. Meseguer, and J. A. Rodrı́guezAguilar, “Efficient inter-team task allocation in robocup rescue,” Proc.
of the Int. Conf. on Auton. Agents and Multiagent Syst., 2015.
[27] S. D. Klee, G. Gemignani, D. Nardi, and M. Veloso, “Graph-based task
libraries for robots: Generalization and autocompletion,” in Congress of
the Italian Association for Artificial Intelligence. Springer, 2015, pp.
397–409.
[28] M. N. Nicolescu and M. J. Mataric, “Natural methods for robot task
learning: Instructive demonstrations, generalization and practice,” in
Proceedings of the second international joint conference on Autonomous
agents and multiagent systems, 2003, pp. 241–248.
[29] S. Ekvall and D. Kragic, “Robot learning from demonstration: a tasklevel planning approach,” International Journal of Advanced Robotic
Systems, vol. 5, no. 3, p. 33, 2008.
[30] S. Niekum, S. Osentoski, G. Konidaris, and A. G. Barto, “Learning and
generalization of complex tasks from unstructured demonstrations,” in
Proc. IEEE/RSJ Int. Conf. Intell. Robots and Syst. IEEE, 2012, pp.
5239–5246.
[31] D. H. Grollman and O. C. Jenkins, “Incremental learning of subtasks
from unsegmented demonstration,” in Proc. IEEE/RSJ Int. Conf. Intell.
Robots and Syst. IEEE, 2010, pp. 261–266.
[32] B. Hayes and B. Scassellati, “Effective robot teammate behaviors for
supporting sequential manipulation tasks,” in Proc. IEEE/RSJ Int. Conf.
Intell. Robots and Syst. IEEE, 2015, pp. 6374–6380.
[33] C. Galindo, J.-A. Fernández-Madrigal, J. González, and A. Saffiotti,
“Robot task planning using semantic maps,” Robot. and Auton. Syst.,
vol. 56, no. 11, pp. 955–966, 2008.
[34] C. Aeronautiques, A. Howe, C. Knoblock, I. D. McDermott, A. Ram,
M. Veloso, D. Weld, D. W. SRI, A. Barrett, D. Christianson, et al.,
“Pddl— the planning domain definition language,” 1998.
[35] A. Torreño, E. Onaindia, A. Komenda, and M. Štolba, “Cooperative
multi-agent planning: A survey,” ACM Computing Surveys (CSUR),
vol. 50, no. 6, pp. 1–32, 2017.
[36] D. Song, K. Huebner, V. Kyrki, and D. Kragic, “Learning task constraints for robot grasping using graphical models,” in Proc. IEEE/RSJ
Int. Conf. Intell. Robots and Syst. IEEE, 2010, pp. 1579–1585.
[37] C. H. Ek, D. Song, K. Huebner, and D. Kragic, “Task modeling in
imitation learning using latent variable models,” in Proc. of the IEEERAS Int. Conf. Humanoid Robots. IEEE, 2010, pp. 548–553.
[38] R. Zlot and A. Stentz, “Multirobot control using task abstraction in a
market framework,” in Collaborative Technology Alliances Conference,
2003.
[39] ——, “Market-based multirobot coordination using task abstraction,” in
Field and Service Robotics. Springer, 2003, pp. 167–177.

16

[40] ——, “Complex task allocation for multiple robots,” in Proc. IEEE Int.
Conf. Robot. and Automation. IEEE, 2005, pp. 1515–1522.
[41] B. Hayes and B. Scassellati, “Autonomously constructing hierarchical
task networks for planning and human-robot collaboration,” in Proc.
IEEE Int. Conf. Robot. and Automation. IEEE, 2016, pp. 5469–5476.
[42] F. Faruq, D. Parker, B. Laccrda, and N. Hawes, “Simultaneous task
allocation and planning under uncertainty,” in Proc. IEEE/RSJ Int. Conf.
Intell. Robots and Syst. IEEE, 2018, pp. 3559–3564.
[43] H. Ravichandar, K. Shaw, and S. Chernova, “Strata: unified framework for task assignments in large teams of heterogeneous agents,”
Autonomous Agents and Multi-Agent Systems, vol. 34, no. 2, 2020.
[44] A. Majumdar and M. Pavone, “How should a robot assess risk? towards
an axiomatic theory of risk in robotics,” in Robotics Research. Springer,
2020, pp. 75–84.
[45] L. Zhou and P. Tokekar, “An approximation algorithm for risk-averse
submodular optimization,” in International Workshop on the Algorithmic
Foundations of Robotics. Springer, 2018, pp. 144–159.
[46] R. Balasubramanian, L. Zhou, P. Tokekar, and P. Sujit, “Risk-aware
submodular optimization for multi-objective travelling salesperson problem,” arXiv preprint arXiv:2011.01095, 2020.
[47] J. Bernhard, S. Pollok, and A. Knoll, “Addressing inherent uncertainty:
Risk-sensitive behavior generation for automated driving using distributional reinforcement learning,” in Proc. IEEE Intell. Veh. Symp. IEEE,
2019, pp. 2148–2155.
[48] L. Lindemann, G. J. Pappas, and D. V. Dimarogonas, “Control barrier
functions for nonholonomic systems under risk signal temporal logic
specifications,” in Proc. IEEE Conf. Decision Control. IEEE, 2020,
pp. 1422–1428.
[49] A. Hakobyan, G. C. Kim, and I. Yang, “Risk-aware motion planning and

[50]
[51]
[52]
[53]
[54]
[55]

[56]
[57]

[58]
[59]

control using cvar-constrained optimization,” IEEE Robot. and Autom.
Lett., vol. 4, no. 4, pp. 3924–3931, 2019.
A. Prorok, M. A. Hsieh, and V. Kumar, “The impact of diversity on
optimal control policies for heterogeneous robot swarms,” IEEE Trans.
Robot., vol. 33, no. 2, pp. 346–358, 2017.
R. T. Rockafellar, S. Uryasev, et al., “Optimization of conditional valueat-risk,” Journal of risk, vol. 2, pp. 21–42, 2000.
S. Asmussen and P. W. Glynn, Stochastic simulation: algorithms and
analysis. Springer Science & Business Media, 2007, vol. 57.
J. R. Birge and F. Louveaux, Introduction to stochastic programming.
Springer Science & Business Media, 2011.
I. Heller and C. Tompkins, “An extension of a theorem of dantzig’s,”
Linear inequalities and related systems, vol. 38, pp. 247–254, 1956.
T. Barfoot, J. Burgner-Kahrs, E. Diller, A. Garg, A. Goldenberg, J. Kelly,
X. Liu, H. Naguib, G. Nejat, A. Schoellig, et al., “Making sense of the
robotized pandemic response: a comparison of global and canadian robot
deployments and success factors,” arXiv preprint arXiv:2009.08577,
2020.
A. A. Malik, T. Masood, and R. Kousar, “Repurposing factories with
robotics in the face of covid-19,” Science Robotics, vol. 5, no. 43, 2020.
V. Chamola, V. Hassija, V. Gupta, and M. Guizani, “A comprehensive
review of the covid-19 pandemic and the role of iot, drones, ai,
blockchain, and 5g in managing its impact,” IEEE Access, vol. 8, pp.
90 225–90 265, 2020.
E. Olson, J. Leonard, and S. Teller, “Fast iterative alignment of pose
graphs with poor initial estimates,” in Proc. IEEE Int. Conf. Robot. and
Automation. IEEE, 2006, pp. 2262–2269.
C. K. Williams and C. E. Rasmussen, Gaussian processes for machine
learning. MIT press Cambridge, MA, 2006, vol. 2, no. 3.

