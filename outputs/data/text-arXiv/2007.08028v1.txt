Predicting Mechanical Ventilation Requirement and Mortality in COVID-19 using
Radiomics and Deep Learning on Chest Radiographs: A Multi-Institutional Study
Joseph Bae1,2*, Saarthak Kapse3*, Gagandeep Singh4, Tej Phatak4, Jeremy Green4,
Nikhil Madan5, Prateek Prasanna1
(* equal contribution)
1

Department of Biomedical Informatics, Stony Brook University, NY, USA
Renaissance School of Medicine, Stony Brook University, NY, USA
3
Department of Electrical Engineering, Indian Institute of Technology, Bombay, India
4
Department of Radiology, Newark Beth Israel Medical Center, NJ, USA
5
Department of Pulmonary Critical Care, Newark Beth Israel Medical Center, NJ, USA
2

Abstract
Objectives
To predict mechanical ventilation requirement and mortality using computational modeling of
chest radiographs (CXR) for coronavirus disease 2019 (COVID-19) patients. We also investigate
the relative advantages of deep learning (DL), radiomics, and DL of radiomic-embedded feature
maps in predicting these outcomes.
Methods
This two-center, retrospective study analyzed deidentified CXRs taken from 514 patients
suspected of COVID-19 infection on presentation at Stony Brook University Hospital (SBUH)
and Newark Beth Israel Medical Center (NBIMC) between the months of March and June 2020.
A DL segmentation pipeline was developed to generate masks for both lung fields and artifacts for
each CXR. Machine learning classifiers to predict mechanical ventilation requirement and
mortality were trained and evaluated on 353 baseline CXRs taken from COVID-19 positive
patients. A novel radiomic embedding framework is also explored for outcome prediction.
Results
Classification models for mechanical ventilation requirement (test N=154) and mortality (test
N=190) had AUCs of up to 0.905 and 0.926, respectively. We also found that the inclusion of
radiomic-embedded maps improved DL model predictions of clinical outcomes.
Conclusions
We demonstrate the potential for computerized analysis of baseline CXR in predicting disease
outcomes in COVID-19 patients. Our results also suggest that radiomic embedding improves DL
models in medical image analysis, a technique that might be explored further in other pathologies.
The models proposed in this study and the prognostic information they provide, complementary
to other clinical data, might be used to aid physician decision making and resource allocation
during the COVID-19 pandemic.
Key Words: COVID-19, X-Ray, Deep learning, Machine learning, Artificial Intelligence

1

Key Points
 Computational modeling of baseline CXR can predict mechanical ventilation requirement
and mortality with high sensitivity.
 Radiomic-embedded feature maps can improve modeling of outcomes in COVID-19
patients.
Introduction
Coronavirus disease 2019 (COVID-19), an illness caused by novel severe acute respiratory
syndrome coronavirus 2, has spread rapidly across the world with over 9.5 million cases
internationally and over 2.4 million cases in the United States as of June 25, 2020 [1].
While the popularity of chest computed tomography (CT) in the early detection and monitoring of
COVID-19 is growing in many countries such as China, hospitals in the United States employ
chest radiographs (CXRs) as the primary imaging modality for the monitoring of the disease [2–
8]. CXRs are useful due to the speed, portability, and easy disinfection of radiography units. The
American College of Radiology has suggested that CT be reserved for only severe cases of
COVID-19 and strongly recommends the usage of portable radiography units to minimize spread
of infection [8]. However, CXRs have lower resolution than CT images and provide 2Dimensional (2D) rather than 3D representations of the lungs. Additionally, portable radiography
units may result in non-uniform orientations and partial visual fields on images. These features of
CXRs make them more difficult to interpret than CTs. Current reports suggest that radiologist
diagnosis of COVID-19 from CXR has a sensitivity of 69% compared to a sensitivity of up to 97%
on CT [4, 5, 7].
There is a growing need for methods to monitor and predict disease progression in COVID-19. In
severe cases of the infection, patients may progress to hypoxemic respiratory failure and acute
respiratory distress syndrome requiring mechanical ventilation [9]. In the United States, early
projections forecasted a deficit in ventilators during the COVID-19 pandemic, indicating the
importance of efficient resource management [10]. The ability to identify patients that might
progress to critical illness beginning at clinical presentation will be invaluable in potential
ventilator shortages, and a few studies have demonstrated that radiologic imaging may be of use
in this regard [3, 6, 11–13]. Recent studies have qualitatively described the association of groundglass opacities and lung consolidations with disease presence and progression on CXR and CT [2–
4, 6, 7]. Specifically, the presence of opacities in multiple lobes has been shown to predict severe
illness [3]. Studies have also evaluated various clinical biomarkers and comorbidities as predictors
of disease progression, and there is some evidence that imaging data might complement these
models [6, 13–17]. However, uses of CXRs have been largely qualitative, and there has been little
work linking quantifiable CXR findings with patient outcomes in COVID-19. Nevertheless,
portable radiography is an appealing, and often the only modality in high-volume hospital settings.
In this study we utilize computational techniques to further evaluate the role of CXR in predicting
patient outcomes.
Computational radiology is a rapidly advancing field that employs machine learning to interpret
medical images. Two general approaches include deep learning (DL) and radiomic analysis [12,
2

18]. Recent studies have used these techniques in order to study COVID-19, but few have applied
them to multi-institutional CXR cohorts [2, 12, 19, 20]. Furthermore, there has not been extensive
work utilizing computational models to predict COVID-19 outcomes using CXR.
In this study, we use computational techniques to identify clinically actionable information from
CXR. We first predict both mechanical ventilation requirement and mortality from baseline CXR
using a DL model. Our second experiment uses machine learning classifiers to predict these same
outcomes based upon computer-extracted, pre-defined radiomic features. Third, we propose a
combined DL model using both processed CXRs and corresponding radiomic-embedded feature
maps as inputs to predict outcomes. This synergistic approach utilizing radiomic-embedded maps
for DL has not been explored in evaluating CXRs and may offer insights into novel interpretations
of pre-defined radiomic features. Figure 1 displays a general flowchart of experiments.

Figure 1: Study pipeline. Visualized here is the schema for the experiments performed in this study. Experiment 1
uses a CNN deep learning model to predict COVID-19 patient outcomes using segmented CXRs as inputs. In
Experiment 2 we extract pre-defined radiomic features from segmented CXRs and input them into machine learning
models such as Random Forests. In Experiment 3 we use extracted radiomic features to generate radiomic-embedded
maps which are inputted with segmented CXRs into a CNN deep learning model.

Materials and Methods
Patient and Image Dataset
In this two-center, IRB approved study, anonymized coronal CXRs were obtained from patients
suspected of COVID-19 on presentation at Stony Brook University Hospital (SBUH) and Newark
Beth Israel Medical Center (NBIMC) between March and June 2020 (Figure 2). At SBUH, 484
baseline CXRs for 463 patients were analyzed. Among these, 17 CXRs from 16 patients were
3

discarded due to being images of pediatric patients or due to poor image quality. Here, a baseline
CXR refers to any CXR taken on the first day for which CXR data exists for a patient. A total of
72 baseline CXRs obtained from 72 patients prior to ventilation were included from NBIMC. Of
these, 5 CXRs were discarded due to indistinguishable lung fields.
In total, 534 CXRs taken from 514 patients were analyzed in this study. 305 of these images were
from 290 male patients and 229 were from 224 female patients. The mean age of patients studied
was 54 years old (median=55 years, standard deviation=18.055 years, Table 1). COVID-19
positivity was tested for each patient via reverse transcriptase polymerase chain reaction (RTPCR). 353 CXRs were taken from 338 patients who tested positive for COVID-19 (Table 2) and
181 CXRs were from 176 patients who were found to be negative. CXRs taken from COVID-19
positive patients were used in outcome prediction experiments whereas those from both COVID19 positive and negative patients were used to build lung and artifact segmentation models. Of the
353 CXRs from positive patients, 113 baseline CXRs were taken for 109 patients that later required
mechanical ventilation. 89 CXRs were from 84 patients who later died from the disease.
Representative CXR images are displayed in Figure 3. Training of all machine learning models
was performed on CXRs acquired at SBUH and evaluated using a combination of CXRs taken at
both SBUH and NBIMC.

Figure 2. Summary of patient inclusion and exclusion criteria. (a) displays criteria for SBUH and (b) displays
criteria for NBIMC

4

Table 1. Patient demographics table
Stony Brook University
Hospital
patients (N=447)

Newark Beth Israel Medical
Center patients (N=67)

Sex

248 male 199 female

42 male 25 female

Age

53±18.597 (p=0.6041*)

61±12.045 (p=0.5768*)

*p-values for age difference between sexes using a Wilcoxon rank-sum test

Image Preprocessing
To conduct our analysis, we ensured that CXRs were properly segmented to avoid analysis of
features unrelated to lung fields. In order to segment the lungs from CXR images, a Residual UNet DL model was employed [21, 22]. This architecture was augmented using a multiscale image
input
pyramid for better intermediate feature representations with deep supervision
(Supplementary Figure S1) [23]. To train the network, lung fields were first manually segmented
for a dataset of 100 CXRs, excluding heart shadows. Additionally, artifacts such as EKG leads,
pacemakers, and other non-anatomical objects were manually segmented in this training set. These
segmentations were used to train a second multiscale-input Residual U-Net model to generate
artifact masks. A focal Tversky loss function was employed (alpha=0.3, gamma=1.0) to ensure a
higher penalty to false positive results [24]. This was to avoid misidentification of high-intensity
objects as lungs and to mitigate misclassification of lungs as unwanted artifacts. These models
were then used to generate lung and artifact masks for the remaining 434 CXRs. Each of these
masks was manually reviewed and errors in segmentation, if any, were corrected.

Figure 3. Representative CXRs studied. Displayed here are baseline CXRs taken from patients that later (a) required
mechanical ventilation, (b) did not require ventilation, (c) survived the disease, and (d) did not survive. Green contours
represent computationally-generated lung segmentations excluding non-anatomic artifacts such as wires.

5

Table 2. COVID-19 positive patient outcome table
Age

Number of
COVID-19
positive patients

Number requiring
mechanical ventilation

Number
deceased

10-19

Male

1

0

0

(N=1)

Female

0

0

0

20-29

Male

8

0

0

(N=16)

Female

8

1

1

30-39

Male

23

6

2

(N=37)

Female

14

2

2

40-49

Male

34

8

4

(N=54)

Female

20

3

2

50-59

Male

45

15

11

(N=84)

Female

39

10

5

60-69

Male

43

22

17

(N=74)

Female

31

16

10

70-79

Male

24

13

12

(N=41)

Female

17

9

7

80+

Male

18

4

8

(N=31)

Female

13

0

3

Total

Male

196

68

54

(N=338)

Female

142

41

30

6

Experiment 1: Outcome classification using convolutional neural networks
Convolutional neural networks (CNNs) were employed to predict future mechanical ventilation
requirement and patient mortality from the baseline CXRs. Utilizing the earlier-described image
processing pipelines, lung and artifact segmentation was performed. Additional preprocessing
steps included cropping of the full CXR to a tight boundary around the lungs, resizing of input
images to 224 by 224 pixels, and the application of min-max normalization to rescale image
intensity values between 0 and 1.
For each classification experiment, ResNet-18, ResNet-34, and ResNet-50 architectures were
trialed [25]. Pre-trained weights were utilized in model training, and data augmentation techniques
such as flipping, rotation, and translation were used to reduce the potential for overfitting. The
fully-connected (FC) layer of each architecture was replaced by a custom layer with an input size
of 512 by 1 (no clinical variables included) or 514 by 1 (patient age and sex included) and an
output size of 2 by 1 to match our desired binary classification scheme. The FC layer was trained
without the use of pre-trained weights. Dropout layers with a probability of 0.1 were included after
FC layers to improve generalizability of classification. For each model, a binary cross-entropy loss
function and an Adam optimizer with a learning rate of 0.00001 were used for network training
[26]. The learning rate was decreased by a factor of 0.01 after each 10th epoch. The specific ResNet
architecture chosen for each classification problem was determined based upon validation scoring
for each tested architecture.
To classify ventilation requirement, training was performed on a set of 41 CXRs from patients
who eventually required mechanical ventilation (Group V) and 41 CXRs from COVID-19 positive
patients who did not (Group NV). Validation was performed on 10 CXRs from Group V and 86
CXRs from Group NV. Based on the validation results, a ResNet-34 architecture was chosen as
the best performing network. Testing was performed on 62 CXRs from Group V and 92 CXRs
from Group NV.
For mortality classification, training was performed on 27 CXRs from COVID-19 patients who
did not survive (Group NR) and 27 CXRs from patients who recovered (Group R). Validation was
performed on 10 CXRs from (Group NR) and 86 CXRs from (Group R). A ResNet-18 architecture
was determined to produce the best results on validation. Testing was performed on 52 CXRs from
(Group NR) and 138 CXRs from (Group R).
Experiment 2: Outcome classification using radiomic features
143 radiomic features from the Haralick, Gabor, Laws energy, histogram of gradients, and grey
intensity feature families were computed for each baseline CXR [27–30]. Features were extracted
solely from segmented lung fields, excluding any artifacts. For each radiomic feature, various
statistics were calculated including measures of median, skewness, standard deviation, and
kurtosis. The obtained statistics and clinical factors including patient age and sex were used for
classifier construction.
To develop machine learning classifiers to predict future mechanical ventilation requirement and
mortality, baseline CXRs were divided into the same training, validation, and testing sets used in
7

Experiment 1. First, the training set was used to train Random Forest (RF), Linear Discriminant
Analysis, and Quadratic Discriminant Analysis classifiers [31, 32]. For each of 100 iterations in
a 3-fold cross validation setting, feature reduction among radiomic and clinical features was
performed on the training set using a Wilcoxon rank sum test, student’s t-test, or a maximum
relevance minimum redundancy approach [33]. Highly correlated features (identified using a
correlation threshold of 0.9) were removed to reduce redundancy. Validation experiments were
then performed to identify the best classifier. Finally, the chosen classifiers, trained on the training
set were evaluated on the distinct testing set of CXRs.
Based upon the results of validation experiments, RF classifiers were used for both COVID-19
mechanical ventilation requirement and mortality prediction. For ventilation classification, eight
radiomic features were used while six were selected for mortality classification (Table S1).
Experiment 3: Outcome classification using convolutional neural networks and radiomicmap embedding
The radiomic feature statistics from Experiment 2 were used to create radiomic-embedded feature
maps for each CXR. t-Distributed Stochastic Neighbor Embedding (random state=1) was
employed to perform feature reduction and to convert radiomic data to a 2D representation [34].
The normalization procedure is detailed in Supplementary Section I.
To assess the predictive capability of a model trained using both these radiomic-embedded feature
maps and CXR images as inputs, the same general procedure employed in Experiment 1 was used.
A key difference was a change in the first input convolution filter of each ResNet architecture to
receive a 2-channel rather than a 3-channel input. Here our first channel was the CXR and the
second was the corresponding radiomic-embedded feature map. This new input layer did not use
pre-trained weights. All other network configurations are identical to those described in
Experiment 1. A ResNet-50 architecture and ResNet-34 architecture were determined by
validation to perform best for mechanical ventilation requirement and mortality prediction,
respectively. Dataset splits of each of these classifiers were identical to those detailed in
Experiment 1.
Evaluation of all classifiers in Experiments 1 through 3 was performed using a bootstrap
resampling approach on the test set over 100 iterations.
Class Activation Mapping of DL Models
Class Activation Maps (CAMs) were also generated for Experiment 1 using network outputs prior
to the global average pooling layer in each ResNet architecture. These CAMs enable a degree of
visualization of the areas in an image that the model used to make predictions.
Results
Results and 95% confidence intervals for Experiments 1, 2, and 3 are summarized in Table 3 and
Table 4.

8

In Experiment 1, a ResNet-34 model trained to predict future mechanical ventilation requirement
had an AUC of 0.842, a specificity of 73%, and a sensitivity of 83% on the testing dataset. A
ResNet-18 model trained to predict mortality yielded an AUC of 0.639, a specificity of 66%, and
a sensitivity of 50% on the testing dataset. Representative CAMs are shown in Figure 4. An expert
reader (J.G, 15 years of experience) noted diffuse, bilateral patchy infiltrates most notable in the
middle and lower lung zones on both CXR images. These findings align with our CAM findings
of high network activations within lung fields, predominantly in the middle and lower lung zones.
Table 3. Mechanical ventilation requirement classifier results

Classification Type

Clinical

Sensitivity

Specificity

AUC

None

0.828±0.008

0.725±0.007

0.842±0.041

Age and Sex

0.691±0.009

0.648±0.007

0.755±0.005

Random Forest –
Radiomic Features

None

0.964±0.006

0.615±0.013

0.867±0.008

Age and Sex

0.972±0.006

0.632±0.014

0.905±0.005

ResNet-50 – CXR +
Radiomic Embedding
Map

None

0.907±0.005

0.705±0.006

0.897±0.004

Age and Sex

0.907±0.005

0.706±0.006

0.903±0.004

Features
ResNet-34 – CXR

For Experiment 2, an RF classifier, trained to predict need for mechanical ventilation, yielded an
AUC of 0.905, a specificity of 63%, and a sensitivity of 97% on the testing dataset. An RF classifier
was also used to predict mortality in COVID-19 positive patients and had an AUC of 0.926, a
specificity of 69% and a sensitivity of 100% on the testing dataset. The top radiomic features used
for predicting mechanical ventilation requirement and mortality were the Laws S5L5 filter
responses and Haralick correlation, respectively (Figure 5).

Figure 4. Representative class activation maps for deep learning models. The baseline CXRs depicted in (a) and (b)
along with their respective CAMs in (c) and (d) are from two patients that later required mechanical ventilation.
CAMs in (c) and (d) depict high levels of activation in the left middle and lower lung zones, in concordance with an
expert reader’s interpretation of the respective CXRs shown in (a) and (b). Also note that activations are primarily
within lung fields and exclude other areas of the images.

9

Table 4. Mortality prediction classifier results

Classification Type

Clinical

Sensitivity

Specificity

AUC

None

0.503±0.014

0.663±0.007

0.639±0.008

Age and Sex

0.444±0.014

0.548±0.008

0.506±0.010

Random Forest –
Radiomic Features

None

1.000±0.000

0.691±0.010

0.926±0.005

Age and Sex

0.889±0.032

0.804±0.017

0.925±0.007

ResNet-34 – CXR +
Radiomic Embedding
Map

None

0.916±0.007

0.435±0.007

0.732±0.007

Age and Sex

0.700±0.011

0.615±0.007

0.756±0.007

Features
ResNet-18 – CXR

For Experiment 3, a ResNet-50 model trained to predict future mechanical ventilation requirement
had AUC of 0.903, a specificity of 71%, and a sensitivity of 91% on the testing dataset. A ResNet34 model trained to predict mortality yielded an AUC of 0.756, a specificity of 62%, and a
sensitivity of 70% on the testing dataset. For both predictions, these models had higher prediction
confidence than those reported for Experiment 1 (Figure 6).

Figure 5. Radiomic classification features. (a) visualizes the median of the Laws S5L5 filter response for the
ventilation requirement prediction dataset. (b) displays the variance of the Haralick correlation feature for the
mortality prediction dataset. p-values are calculated using a Wilcoxon rank-sum test

Discussion
As the COVID-19 pandemic continues to unfold, there will be a growing need for useful
interpretations of CXRs. In this work we have presented models for baseline CXRs that
demonstrate high sensitivities in predicting future mechanical ventilation requirement (≤97%) and
mortality (≤100%). For these predictions of disease outcomes, radiomic classifiers had higher
10

sensitivities than those yielded by DL. However, we did report higher specificities for prediction
of mechanical ventilation requirement using DL classifiers with radiomic embedding (Table S2).
Several non-imaging models have been proposed with high sensitivities for various clinical
outcomes using biomarkers such as serum lactate dehydrogenase, C-reactive protein, lymphocyte
counts, and coagulation factors [13–17]. These models might be complemented by novel imagingbased approaches. The quantitative modeling of baseline CXRs is relatively unexplored and will
be of particular importance for resource allocation if projected scarcity of ventilators and other
supplies occurs [10].
Previous studies have applied DL to the analysis of COVID-19 CXRs [12, 19, 20, 35]. However,
at least one study has reported potential deficiencies in these approaches, including insufficiencies
in a commonly used public dataset, a neglect to segment lung fields, and a failure to account for
large differences between disparate public datasets [35]. Previous studies have also not explicitly
accounted for foreign objects in the lung fields such as buttons, clips, wires, etc., which can obscure
pathological findings. Here, we have developed a unique pre-processing pipeline to segment lung
fields from CXRs. We have further shown that our classifiers are effective in predicting COVID19 outcomes in patients treated at multiple institutions, reflecting a degree of robustness in their
predictive value.
The high middle and lower lung activations observed in network CAMs are consistent with studies
reporting lower lobe lung findings on both CT and CXR (Figure 4) [4–6]. In the CAMs presented
in Figure 4, high network activations are visualized in areas where a radiologist had independently
identified lung opacities, providing evidence that our DL models are using pathology-relevant
features to predict patient outcomes.

Figure 6. Prediction probabilities for deep learning models. (a) visualizes prediction probabilities generated for
CXRs from patients that later required mechanical ventilation. (b) visualizes prediction probabilities for CXRs from
patients that died.

Using an integrated model that incorporates both baseline imaging and the associated radiomicembedded feature maps, we demonstrated an improvement in outcome prediction results over use
of baseline image-based DL models alone (Figure 6). The generation of a radiomic-embedded
feature map for DL classification is a novel approach in CXR analysis and may be used in future
studies to augment DL approaches. While most learning approaches assume independence
between prediction variables, DL considers the ‘relative arrangement' of primitives such as that of
image pixels. To increase the versatility of CNNs, we first embedded radiomic statistics in a
11

reduced dimensional space, clustered similar features together, and then used the embedding to
obtain a pseudo image. This pseudo image was inputted into our classifiers in addition to the
original CXR scan. This fusion framework can help assess feature importance and may also be
extended to other clinical parameters. Both radiomic and radiomic embedding approaches can give
insight into what features of a patient’s CXR are significant in making predictions, and the use of
either can be more informative to a physician than exclusively DL approaches.
There are certain limitations in our work. First, we used baseline CXRs that are likely to be
nonuniform in the interval between COVID-19 infection and image acquisition. While our data is
representative of the clinical reality of patients receiving baseline CXRs at varying timepoints in
the course of their disease, future studies might build improved time-to-event prediction models
using data with a more uniform temporal distribution. Furthermore, we are limited in the number
of clinical features studied and our models might benefit from including co-morbidities such as a
history of cancer, chronic obstructive pulmonary disease, hypertension, etc. The inclusion of comorbidities and other laboratory variables might further improve our models [13–17]. Finally,
future work will be helpful in demonstrating the robustness of these classification models in the
broader context of COVID-19 treatment in other hospitals and locations.
Conclusion
In summary, we have presented a complete pipeline for computational evaluation of CXR in
COVID-19 patients. Both radiomic and DL classification models enable us to predict mechanical
ventilation requirement and mortality from baseline CXRs. Furthermore, we demonstrate the
improvement that a novel radiomic embedding approach has on DL predictions of COVID-19
outcomes. We posit that the ability to make early predictions of disease outcomes may aid in triage,
clinical decision-making, and efficient hospital resource allocation as the COVID-19 pandemic
progresses.

12

List of Abbreviations
COVID-19: Coronavirus disease 2019
CXR: Chest radiograph (x-ray)
DL: Deep Learning
2D: 2-dimensional
SBUH: Stony Brook University Hospital
NBIMC: Newark Beth Israel Medical Center
RT-PCR: Reverse transcriptase polymerase chain reaction
CNN: Convolutional neural network
FC: Fully-connected
RF: Random forest
LDA: Linear discriminant analysis
QDA: Quadratic discriminant analysis
CAM: Class activation map
AUC: Area under the receiving operator characteristic curve
Acknowledgements
Research reported in this publication was supported by the Office of the Vice President for
Research and Institute for Engineering-Driven Medicine Seed Grants, 2019 at Stony Brook
University. JB supported by NIGMS T32GM008444.
Notes
The authors declare no conflicts of interest. The Institutional Review Board approved this study to
be a non-human subjects research study. All data was de-identified prior to any analysis.
This article has been submitted to European Radiology.
References
1.
Dong E, Du H, Gardner L (2020) An interactive web-based dashboard to track COVID-19
in real time. Lancet Infect Dis 20:533–534. https://doi.org/10.1016/S1473-3099(20)30120-1
2.
Chaganti S, Balachandran A, Chabin G, et al (2020) Quantification of Tomographic
Patterns Associated with COVID-19 from Chest CT. 24
3.
Toussie D, Voutsinas N, Finkelstein M, et al (2020) Clinical and Chest Radiography
Features Determine Patient Outcomes In Young and Middle Age Adults with COVID-19.
Radiology 201754. https://doi.org/10.1148/radiol.2020201754
4.
Wen Z, Chi Y, Zhang L, et al (2020) Coronavirus Disease 2019: Initial Detection on Chest
CT in a Retrospective Multicenter Study of 103 Chinese Subjects. Radiol Cardiothorac Imaging
2:e200092. https://doi.org/10.1148/ryct.2020200092
5.
Wong HYF, Lam HYS, Fong AH-T, et al (2020) Frequency and Distribution of Chest
Radiographic
Findings
in
COVID-19
Positive
Patients.
Radiology
201160.
https://doi.org/10.1148/radiol.2020201160

13

6.
Yang R, Li X, Liu H, et al (2020) Chest CT Severity Score: An Imaging Tool for Assessing
Severe
COVID-19.
Radiol
Cardiothorac
Imaging
2:e200047.
https://doi.org/10.1148/ryct.2020200047
7.
Ai T, Yang Z, Hou H, et al (2020) Correlation of Chest CT and RT-PCR Testing in
Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases. Radiology 200642.
https://doi.org/10.1148/radiol.2020200642
8.
ACR Recommendations for the use of Chest Radiography and Computed Tomography
(CT) for Suspected COVID-19 Infection. https://www.acr.org/Advocacy-and-Economics/ACRPosition-Statements/Recommendations-for-Chest-Radiography-and-CT-for-SuspectedCOVID19-Infection. Accessed 15 Jun 2020
9.
Alhazzani W, Møller MH, Arabi YM, et al (2020) Surviving Sepsis Campaign: guidelines
on the management of critically ill adults with Coronavirus Disease 2019 (COVID-19). Intensive
Care Med 1–34. https://doi.org/10.1007/s00134-020-06022-5
10.
Ranney ML, Griffeth V, Jha AK (2020) Critical Supply Shortages — The Need for
Ventilators and Personal Protective Equipment during the Covid-19 Pandemic. N Engl J Med
382:e41. https://doi.org/10.1056/NEJMp2006141
11.
Vaid A, Somani S, Russak AJ, et al (2020) Machine Learning to Predict Mortality and
Critical Events in COVID-19 Positive New York City Patients. Health Informatics
12.
Shi F, Wang J, Shi J, et al (2020) Review of Artificial Intelligence Techniques in Imaging
Data Acquisition, Segmentation and Diagnosis for COVID-19. ArXiv200402731 Cs Eess Q-Bio
13.
Liang W, Liang H, Ou L, et al (2020) Development and Validation of a Clinical Risk Score
to Predict the Occurrence of Critical Illness in Hospitalized Patients With COVID-19. JAMA
Intern Med. https://doi.org/10.1001/jamainternmed.2020.2033
14.
Yan L, Zhang H-T, Goncalves J, et al (2020) An interpretable mortality prediction model
for COVID-19 patients. Nat Mach Intell 2:283–288. https://doi.org/10.1038/s42256-020-0180-7
15.
Ji D, Zhang D, Chen Z, et al (2020) Clinical Characteristics Predicting Progression of
COVID-19. Social Science Research Network, Rochester, NY
16.
Zhou Y, He Y, Yang H, et al (2020) Development and validation a nomogram for
predicting the risk of severe COVID-19: A multi-center study in Sichuan, China. PLoS ONE 15:.
https://doi.org/10.1371/journal.pone.0233328
17.
Shang W, Dong J, Ren Y, et al The value of clinical parameters in predicting the severity
of COVID-19. J Med Virol n/a: https://doi.org/10.1002/jmv.26031
18.
Parekh VS, Jacobs MA (2019) Deep learning and radiomics in precision medicine. Expert
Rev Precis Med Drug Dev 4:59–72. https://doi.org/10.1080/23808993.2019.1585805
19.
Cohen JP, Morrison P, Dao L (2020) COVID-19 Image Data Collection. ArXiv200311597
Cs Eess Q-Bio
20.
Ozturk T, Talo M, Yildirim EA, et al (2020) Automated detection of COVID-19 cases
using
deep
neural
networks
with
X-ray
images.
Comput
Biol
Med.
https://doi.org/10.1016/j.compbiomed.2020.103792
21.
Ronneberger O, Fischer P, Brox T (2015) U-Net: Convolutional Networks for Biomedical
Image Segmentation. ArXiv150504597 Cs
22.
Zhang Z, Liu Q, Wang Y (2018) Road Extraction by Deep Residual U-Net. IEEE Geosci
Remote Sens Lett 15:749–753. https://doi.org/10.1109/LGRS.2018.2802944
23.
Lee C-Y, Xie S, Gallagher P, et al (2014) Deeply-Supervised Nets. ArXiv14095185 Cs
Stat

14

24.
Abraham N, Khan NM (2018) A Novel Focal Tversky loss function with improved
Attention U-Net for lesion segmentation. ArXiv181007842 Cs
25.
He K, Zhang X, Ren S, Sun J (2015) Deep Residual Learning for Image Recognition.
ArXiv151203385 Cs
26.
Kingma DP, Ba J (2017) Adam: A Method for Stochastic Optimization. ArXiv14126980
Cs
27.
Haralick RM, Shanmugam K, Dinstein I (1973) Textural Features for Image Classification.
IEEE Trans Syst Man Cybern SMC-3:610–621. https://doi.org/10.1109/TSMC.1973.4309314
28.
Jain AK, Farrokhnia F (1991) Unsupervised texture segmentation using Gabor filters.
Pattern Recognit 24:1167–1186. https://doi.org/10.1016/0031-3203(91)90143-S
29.
Laws KI (1980) Textured Image Segmentation. University of Southern California
30.
Dalal N, Triggs B (2005) Histograms of oriented gradients for human detection. In: 2005
IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05). pp
886–893 vol. 1
31.
Tin Kam Ho (1998) The random subspace method for constructing decision forests. IEEE
Trans Pattern Anal Mach Intell 20:832–844. https://doi.org/10.1109/34.709601
32.
Hastie T, Tibshirani R, Friedman JH (2009) The Elements of Statistical Learning: Data
mining, Inference, and Prediction, 2nd ed. New York: Springer
33.
Peng H, Long F, Ding C (2005) Feature selection based on mutual information criteria of
max-dependency, max-relevance, and min-redundancy. IEEE Trans Pattern Anal Mach Intell
27:1226–1238. https://doi.org/10.1109/TPAMI.2005.159
34.
Sharma A, Vans E, Shigemizu D, et al (2019) DeepInsight: A methodology to transform a
non-image data to an image for convolution neural network architecture. Sci Rep 9:1–7.
https://doi.org/10.1038/s41598-019-47765-6
35.
Maguolo G, Nanni L (2020) A Critic Evaluation of Methods for COVID-19 Automatic
Detection from X-Ray Images. ArXiv200412823 Cs Eess
36.
Alkhouli M, Nanjundappa A, Annie F, et al (2020) Sex Differences in COVID-19 Case
Fatality Rate: Insights From a Multinational Registry. Mayo Clin Proc.
https://doi.org/10.1016/j.mayocp.2020.05.014
37.
Wei X, Xiao Y-T, Wang J, et al (2020) Sex Differences in Severity and Mortality Among
Patients With COVID-19: Evidence from Pooled Literature Analysis and Insights from Integrated
Bioinformatic Analysis

15

Supplementary Section
1. t-Distributed Stochastic Neighbor Embedding normalization
The chosen normalization procedure utilized the minimum value for each feature independently
(Minj), and the global maximum (Max) to rescale values logarithmically between 0 and 1. This is
formulated as follows where Xtr is the training dataset and (j,:) refers to all samples of the jth
radiomic feature:
𝑀𝑖𝑛 = min 𝑋 (𝑗, : )
𝑋 (𝑗, : ) ← log (𝑋 (𝑗, : ) + 𝑀𝑖𝑛 + 1
𝑀𝑎𝑥 = max(𝑋 )
𝑋 (𝑗, : )
𝑋 (𝑗, : ) ←
𝑀𝑎𝑥
The validation and test sets were then adjusted using the extrema values from the training set for
normalization. If, after adjusting by the minimum values, any element of the validation or test set
was less than 0, it was clamped at 0. Similarly, if after normalizing by the global maximum value
any feature from the validation and test sets was above 1, it was clamped to 1.
2. False positive rates in mechanical ventilation predictions
In Table S2 we visualize the false positive rates for ventilation requirement prediction in
Experiments 1 and 3. We see that false positive rates in mechanical ventilation requirement
prediction are much higher in males than in females using radiomic-based RF classifiers. This
might reflect the sex-based disparities in disease progression that have been reported in other
studies for COVID-19 [36, 37]. Future studies might further investigate any differences in disease
outcome prediction capabilities for male and female patients.

Figure S1. Network architecture for lung and image artifact segmentation. (a) visualizes our multiscale input
Residual U-Net architecture. (b) displays an example residual block.

16

Table S1. Features used in radiomic classifiers

*Ws: Window size

17

