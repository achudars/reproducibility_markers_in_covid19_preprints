Scalable Optical Learning Operator
Uğur Teğin1,2,*, Mustafa Yıldırım2, İlker Oğuz1,2, Christophe Moser2 and Demetri Psaltis1
1 Optics

Laboratory, École Polytechnique Fédérale de Lausanne, Switzerland

2 Laboratory

of Applied Photonics Devices, École Polytechnique Fédérale de Lausanne, Switzerland

* ugur.tegin@epfl.ch

Abstract
Today's heavy machine learning tasks are fueled by large datasets. Computing is performed with
power hungry processors whose performance is ultimately limited by the data transfer to and from
memory. Optics is one of the powerful means of communicating and processing information and
there is intense current interest in optical information processing for realizing high-speed
computations. Here we present and experimentally demonstrate an optical computing framework
based on spatiotemporal effects in multimode fibers for a range of learning tasks from classifying
COVID-19 X-ray lung images and speech recognition to predicting age from face images. The
presented framework overcomes the energy scaling problem of existing systems without
compromising speed. We leveraged simultaneous, linear, and nonlinear interaction of spatial
modes as a computation engine. We numerically and experimentally showed the ability of the
method to execute several different tasks with accuracy comparable to a digital implementation.
Our results indicate that a powerful supercomputer would be required to duplicate the
performance of the multimode fiber-based computer.

Introduction
Early optical computers were used to calculate linear operations such as the Fourier transform
and correlations. They found applications in pattern recognition and synthetic aperture radar [1,
2]. However, with the advent of modern VLSI technology and efficient algorithms (e.g Fast Fourier
Transform), digital signal processing based on silicon circuits became so fast and parallel that the
analog optical computation that included the input and output electronic overhead became
obsolete. Digital optical computing, that combined nonlinear optical switches [3] with linear optical
interconnections [4] replacing wires, was then intensely pursued in the 1980’s. Optical
interconnections can be advantageous in terms of power consumption [5], however in an alloptical implementation this advantage is counter-balanced by the power inefficiency and large
size of optical switches compared to the electronic ones. Therefore, all-optical digital computers
are not yet competitive. Optics has also been used for the implementation of nonlinear
computations that are not based on Boolean logic, such as the optical implementation of neural

networks [6, 7]. In principle, the dense connectivity of neural networks and their relative
robustness against noise and device imperfections, renders neural networks a promising area for
optical computing.
Interest in optically implemented neural networks has intensified in recent years partially because
the large size of databases that need to be managed stresses the capabilities of existing digital,
electronic computers. Several promising approaches are being investigated and they are
summarized in a recent review article [8]. The key challenge in designing a viable optical
computer (including a neural one) is to combine the linear part of the system from where the
competitive edge of optics derives, with nonlinear elements and input-output interfaces while
maintaining the speed and power efficiency of the optical interconnections. The prospect of an
optical engine for computation is as a computational accelerator working alongside CPUs and
GPUs, which may be placed physically close to the edge of the communication network in order
to minimize data transfer and perform the computation which would otherwise be carried out in a
server farm.
The solution we propose and demonstrate in this paper is the combination of the linear and
nonlinear parts of the optical system in a shared volume confined in a multimode fiber (MMF).
The principal advantage of this approach is the combination of the 3D connectivity of optics with
the long interaction length and lateral confinement afforded by the fiber which makes it possible
to realize optical nonlinearities at relatively low power. At the same time, the large number of
spatial modes that can be densely supported in a MMF maintains the traditional high parallelism
feature of optics, while maintaining a compact form factor. Finally, with the availability of
megapixel spatial light modulators (SLMs) and cameras, the 2D input and output interfaces to the
MMF can sustain a large information processing throughput. We refer to the proposed method as
SOLO (Scalable Optical Learning Operator) in the remainder of this paper.
A schematic diagram of the MMF processing element is shown in Figure 1. The data to be
processed is entered through the 2D spatial light modulator on the left. At sufficiently high
illumination peak power, the light from a pulsed light source is nonlinearly transformed as it
propagates through the fiber and the result of the computation is projected on the 2D camera.
Given the properties of the fiber and the laser source, the input-output operation performed by
the MMF is fixed and highly nonlinear. We implement a reconfigurable processor by combining
the fixed nonlinear MMF mapping in the optical domain with a single layer digital neural network
(decision layer) trained to recognize the output recorded on the camera using a large data set of

input-output pairs. For instance, we used this system to diagnose with high accuracy (93%)
COVID-19 from X-ray images of lungs. We used a large database of X-ray images of lungs with
various diseases including COVID-19 to train the single layer network that classifies the
representation of the lungs that is produced at the output camera. The notion of combining a
complex, fixed mapping with a simpler programmable processor to realize a powerful overall
system, including the optical implementation of such machines, has been used in support vector
machines [9,10] reservoir computing [11-15], random mappings [16-19], and extreme learning
machines [20,21]. The nonlinear mapping performed by the MMF is not the same as in any of the
earlier approaches. As we will show, it proves to be very effective in transforming the input data
space on the SLM to a nearly linearly separable output data space (camera at end of the MM
fiber) at very high speed and power efficiency.

Figure 1 Illustration of the fixed-parameter neural network architectures and the experimental setup
for nonlinear projection with spatiotemporal multimode fiber nonlinearities. The inset depicts neural
network architectures with similar attributes as the MMF processor with black and blue connections
indicating fixed and adaptable weights, respectively.

In the remainder of the paper, we present numerical and experimental results from our optical
computing framework for single variable linear regression, multivariable linear regression, age
prediction from face images, audio speech classification and COVID-19 diagnosis from X-ray
images tasks. We then discuss how the system scales to large data size and estimate the power

consumption per operation. These studies show that the analog optical computer based on the
MMF is power efficient, versatile and obtains accuracy performance comparable to that obtained
with digital computers when solving the tasks we investigated.

Results
Experimental studies
Multimode fibers (MMFs) exhibit waveguide properties while allowing a large number of spatial
degrees of freedom. Graded-index multimode fibers (GRIN MMFs) in particular, have become the
subject of significant interest for telecommunications, imaging and nonlinear optics studies due to
their unique properties such as relatively low modal dispersion and periodic self-imaging. In recent
years, with spatiotemporal pulse propagation in GRIN MMFs, various nonlinear frequency
generation dynamics [22-26], nonlinear beam cleaning [27] and spatiotemporal mode-locking [2830] have been realized. Moreover, learning and controlling nonlinear optical dynamics in GRIN
MMFs was demonstrated by modifying the spatial properties of the intense pump pulse with a
spatial light modulator (SLM) or deformable mirror device (DMD) [31,32].
In machine learning studies, a variety of nonlinear transformations of the input data have been
investigated in order to enable learning of complex relations hidden in the data [33]. In our case,
we make use of the nonlinear mapping that takes place at high light intensities when an input
pattern propagates in a multimode fiber as a physical realization of machine learning. The
experimental setup in Fig.1 is explained in detail in the Methods section. In this setup, information
spatially modulated an intense laser pulse with the input data and the Fourier transform of the
spatially modulated beam was focused on the input facet of the optical fiber through a lens. The
amount of light coupled to each of the modes of the fiber is given by the inner product between
the incident light amplitude and the mode profile. Upon propagation, the initial complex modal
coefficients evolve according to spatiotemporal linear and nonlinear effects. The nonlinear
transformation of information is achieved by nonlinear energy exchange between the fiber modes.
The transformed information at the end of the fiber is imaged onto a camera, and the image was
downscaled such that the spatial sampling period is approximately equal to the resolution limit,
which can be approximated by λ/2(NA), the Abbe diffraction limit. Each pixel of the downscaled
image served as an input feature to a linear regression or equivalently, to a single layer neural
classification algorithm to estimate the identity of the input on the SLM.

Figure 2 Learning a nonlinear function (sinc): dependence on the pulse propagation regimes in a
graded-index multimode fiber caused by increasing the input optical peak power. (a) Experimental
measurements: increasing the input peak power increases the nonlinear coupling between modes which
translates in better learning. Beyond an optimal peak power, the learning performance degrades due to the
Raman beam cleaning effect (see text). (b) Illustration of the propagation difference for linear (low peak
power) and nonlinear (high peak power) cases in a GRIN MMF with 10 self-imaging period length.

Learning a nonlinear function
To test this, we selected a simple regression problem on a dataset generated with a nonlinear
(Sinc function) relation. The input information (x) were randomly generated numbers between -π
to π and the corresponding output labels (y) were generated according to the y = Sin(πx)/(πx)
relation. This simple dataset is often used as a benchmark in machine learning studies since
linear regression of a nonlinear function is impossible without a nonlinear transformation [20,21].
Each input value (x) was uniquely coded as a 2D pattern which was recorded on the SLM (see
Supplementary Discussion 4 for details). By recording the nonlinearly propagated beam profile of
many such input values, a linear regression method was performed on the output data (see Fig.
2 a). To measure the effectiveness of the spatiotemporal nonlinear propagation and assess the
importance of the nonlinearity, we experimented with different pulse peak powers to control the
level of nonlinearity. For low peak power (~1.14 kW), the nonlinearity is relatively weak, and the
transmission through the fiber is very nearly a linear transformation (except for the square-law at

the detector) and as a result, the performance is poor since the mapping is not linearly separable.
Increasing the laser peak power results in nonlinear propagation, and we reached the best
performance at around 3.43 kW laser peak power. For this optimum power level, correct outputs
were estimated from unseen test inputs with a root-mean-squared error (RMSE) of 0.0671.
Further power escalation gradually deteriorated the performance because it drives nonlinear
pulse propagation to the Raman beam clean-up regime [34]. In this regime the projected beam
profiles become virtually unaffected by the input data. In the other experiments reported below,
the optical peak power used was 3.43 kW corresponding to the optimal peak power of the Sinc
and COVID-19 diagnosis experiments.

Figure 3 Experimental (a-d) learning results for regression and classification tasks. (a) Learning of
abalone (multivariable) dataset. (b) Age prediction from face image dataset. (c) Confusion matrix for audio
dataset digit classification. (d) Confusion matrix for audio dataset speaker classification.

Abalone dataset
The Sinc dataset demonstrates the interpolation capability of our optical computing framework;
however, interpolation is not an adequate property for complex inference problems. Therefore,
we moved to multivariable inference problems and we tested our computing method on the
abalone dataset [35]. The abalone dataset consists of various physical features of sea snails in
the dataset that are related to age (e.g., number of rings) that can be used for the prediction of
the age of sea snails from eight different parameters. We recorded these 8 parameters on the
SLM as a 4x2 matrix with proper pixel scaling. Similar to the Sinc function experiments, the
recorded spatial distribution at the distal fiber facet was recorded, flattened (written as a long 1D
vector) and fed to the decision layer to perform linear regression. (see Methods). Fig. 3 presents
the true ages (Label) and the corresponding predictions; the figure indicates that the framework
learns the ages of the abalone from spatially distributed independent variables with remarkable

accuracy (RMSE of 0.126) compared with the output that takes normalized values between 0 and
1.
Digit classiﬁcation

0.2

Training
Test

1.5

0.8

0.6

1
0.5

0.1

0

0

0.4
0

0

5

10

Epoch

15

20

c

1

10

20

30

40

50

Training
Test

0.8
Training
Testing

1.5

Loss

0.3

Tranining
Test

Loss

Digit accuracy

0.4

b
1

Speaker classiﬁcation

Speaker accuracy

Training
Test

a

0.5

Age looss

SOLO Experiments

Age prediction

0.6

1
0.5
0

0.4

0

10

Epoch
0

10

20

30

40

20

30

40

50

Epoch
50

Epoch

0

10

20

30

40

50

Epoch

Figure 4 Training of the experimental (a-c) results. (a) Evolution of loss function for age prediction
dataset. (b) Evolution of accuracy and loss function for digit classification with audio dataset. (c) Evolution
of accuracy and loss function for speaker classification with audio dataset.

Face image dataset
Next, we tackled the problem of estimating the age of a person from an image of the person’s
face. A dataset containing 9780 images of faces of people from different gender and ethnicity with
a long age span (0-116) is used [36]. The age is first normalized from 0 to 1. The number 1
represents the oldest person (116 years old). Here again, a single neuron is employed as the
decision layer using the recorded fiber output intensity profiles. The achieved RMSE for age
prediction is 0.167 normalized years. For the first 1000 samples the true ages (Labels) and
predictions are shown in Fig. 3 b. Some predictions have negative values, which is impossible;
however, this error is due to the final regression layer. This task is promising since image
problems are massive and power-hungry in digital machine learning tools and gave birth to the
convolutional neural network (CNN) architectures.
Audio digit dataset
Classification of isolated audio records is one of the popular implementations of machine learning,
which has a wide range of applications. We employed spoken digit classification to challenge the
SOLO system. The audio digit classification dataset incorporates recordings of English digits by
six distinct people [37]. Audio recordings are inherently time-varying signals. Following the
standard approach, one-dimensional audio signals were converted to two-dimensional
representation by generating so-called Mel spectrograms. These spectrograms of audio

recordings were provided as inputs to the SLM. Similar to the previous dataset, the spectrograms
are encoded on the pulses with high peak power. The output decision layer classifies the recorded
respective fiber output intensity images and 91% accuracy over test data is obtained (see Fig. 3
c) for digit categorization task.

Figure 5 Experimentally tested COVID-19 CT-scan dataset. (a) Confusion matrix for condition
classification. Evolution of accuracy (b) and loss (c) functions for COVID-19 CT-scan dataset. (d) Measured
effect of nonlinear pulse propagation on categorization accuracy.

To demonstrate the versatility of SOLO, we changed the task for the same dataset and aimed to
differentiate the speaker from the audio record. Since the nonlinear transformation is independent
of the task, we only updated the decision layer in SOLO and achieved 85% accuracy on test data
as presented in Fig. 3 d. The evolution of loss and accuracy (if applicable) functions for our digital
decision layer with fiber simulation results are presented in Fig. 4 a-c.
COVID-19 dataset
Encouraged by the performance we obtained with the relatively simple tasks described so far, we
tested SOLO with a difficult challenge of current interest by studying COVID-19 diagnosis with a
dataset consisting of 2482 CT scan samples [38]. Similar to the audio dataset, CT scan samples
are applied to pulses as phase modulation and the corresponding fiber output intensity patterns
were recorded. By performing classification in the decision layer, 93% accuracy over the unseen
test set is achieved (see Fig. 5). In the literature, with nonparametric methods such as Decision
Tree, lower performances (79% accuracy) are reported [38]. To reach similar performance levels

(90-95% accuracy), the results reported in reference [38] employed transfer learning approach by
using the heavily pre-trained neural networks such as ResNet, GoogleNet or VGG-16 which
contain 16-22 layers and 6-130 million parameters to train. Alternative methods such as cascaded
deep neural network schemes are proposed in the literature to initially decompose features of Xray images and additional 1-4% improvements were reported with transfer learning approach [39].
Physical model
The nonlinear mapping performed by the MMF can be investigated by the beam propagation
method involving the fiber mode amplitudes (Eq. 1) [40]. In an ideal fiber without imperfections
and bending, with low power pulse or continuous-wave light, only the phases of the mode
coefficients change at different rates, due to modal and chromatic dispersion, without any
intermodal power exchange. This behavior is captured by the first term in Eq. 1. This results in a
linear transformation of the field as it propagates through the fiber.
Mode-coupling caused by perturbations due to fiber bending or by impurities, shown by matrix C,
also acts as linear mixing (the second term in Eq. 1) [40, 41].

𝜕𝐴𝑝
𝜕𝐴𝑝
𝛽2 𝜕 2 𝐴𝑝
= 𝑖𝛿𝛽0 𝑝 𝐴𝑝 − 𝛿𝛽1 𝑝
−𝑖
+
⏟
𝜕𝑧
𝜕𝑡
2 𝜕𝑡 2
𝑃𝑟𝑜𝑝𝑎𝑔𝑎𝑡𝑖𝑜𝑛 𝑎𝑛𝑑 𝐷𝑖𝑠𝑝𝑒𝑟𝑠𝑖𝑜𝑛

𝑖 ∑ 𝐶𝑝,𝑛 𝐴𝑛
⏟𝑛
𝐿𝑖𝑛𝑒𝑎𝑟 𝑀𝑜𝑑𝑒 𝐶𝑜𝑢𝑝𝑙𝑖𝑛𝑔

+ 𝑖𝛾 ∑ 𝜂𝑝,𝑙,𝑚,𝑛 𝐴𝑙 𝐴𝑚 𝐴𝑛 ∗
⏟ 𝑙,𝑚,𝑛
𝑁𝑜𝑛𝑙𝑖𝑛𝑒𝑎𝑟 𝑀𝑜𝑑𝑒 𝐶𝑜𝑢𝑝𝑙𝑖𝑛𝑔

Equation 1
If the peak power of the pulse is high enough to induce nonlinear behavior in the material,
nonlinear mode coupling takes place, and it results in a nonlinear operation on the information
spatially encoded in the intense pulse throughout the fiber (the third term in Eq. 1). For each
propagation step, the fiber modes couple to each other according to the linear coupling
coefficients and the nonlinear coupling tensor, indicated by 𝜂. This nonlinear operator can be
modeled at each propagation step by multiplying each three-element combination of mode
coefficients with the related entry of the nonlinear mode coupling tensor (for details see
Supplementary Discussion 1)

Figure 6 Illustration of the spatiotemporal nonlinear pulse propagation as deep neural network
architecture in the experimental setup. Each elementary step Δz in the MMF is modeled as a cascade
of linear and nonlinear network-like operators capturing the phase delay (in blue), the linear mode coupling
due to bending and imperfections (in red), and the nonlinear mode coupling (in magenta and yellow).

Numerical studies
Our experiments demonstrated that the proposed optical computing framework can process
information and has potential to learn with adequate performance. To understand the nonlinearity
in the MMF, and analyze its effect on learning, we performed time-dependent beam propagation
method (TBPM) simulations (see Method section and Supplementary Discussion 2). Numerically
studying pulse propagation in the 5m GRIN MMF for a dataset with 3000 samples requires
approximately 2 years with our GPU parallelized simulation as explained in the Methods section.
To reduce the computation time but maintain the required optical nonlinearity, we performed a
rescaling of the propagation length and pulse peak power, also explained in the Methods section.
We numerically studied the learning sinc function (see Supplementary Discussion 4), abalone
dataset, face image dataset and audio dataset (see Supplementary Discussion 5). Note that the
numerical simulation is only partial due to computational limitation. As a result the data is not fully
linearly separable after the numerically simulated operation whereas experimentally the data
becomes linearly separable as evidenced by the flattening of the learning curves in Fig. 4.

Figure 7 Numerically tested COVID-19 CT-scan dataset. (a) Confusion matrix for condition classification.
Evolution of accuracy (b) and loss (c) functions for COVID-19 CT-scan dataset. Simulated effect of pulse
peak power (d) and fiber length (e) on categorization accuracy.

Last but not least, we simulated nonlinear beam propagation in GRIN MMF by encoding the
COVID-19 dataset onto the optical pulses. 2482 CT scan samples are propagated numerically
and by performing classification to the resulting spatial distribution of the pulses, 74% accuracy
is achieved (see Fig. 7 a-c), which is significantly lower than the experimentally obtained
classification accuracy (93%). For categorization tasks, our numerical results offered lower
performances than our experimental studies. These tasks require optically processing 2D
information and the simulations were performed with a shorter fiber lengths and higher peak
power due to the previously mentioned computational complexities. This simplification may not
have captured the complex nonlinear mapping occurring in a longer fiber and lower peak power.
To understand the impact of peak power and fiber length, we simulated the COVID-19 dataset
with lower peak power levels and shorter fiber lengths. The numerically obtained 74% COVID-19
diagnosis accuracy decreased to 69 % and 66 % when the peak power respectively decreased

to half and quarter of the initial power. Similar results were also obtained for shorter propagation
lengths such as by decreasing the fiber length from 10 to 5 self-imaging period, we could achieve
69% diagnosis accuracy. A further decrease of fiber length by 2 self-imaging periods resulted in
66% diagnosis accuracy in our simulations. The numerically achieved confusion matrices for
these studies are shown in Fig. 7. This simulation confirms the role of high intensity light in
learning ability.

Discussion
The present study reveals that the nonlinear interactions in spatiotemporal pulse propagation in
MMFs is a key element for learning. It is also important to understand how the performance of
SOLO scales with the input data size. We first analyze how the power scales with the input size
for SOLO. The number of modes N in a MMF scales proportionally to the fiber core area, hence
the optical power necessary to maintain the same intensity per mode scales linearly with the
number of modes. Since a fiber having N modes can accommodate N-dimensional input (law of
etendue), the optical power scales with the size of the dimensional input N. The GRIN MMF used
in the present study supports 240 modes (counting the polarization degeneracy) and
experimentally, learning reached an optimum for a pulse peak power of 3.4 kW for nonlinear
optical effects which corresponds to 4.4 mW average optical power for 125 kHz repetition rate
and 10 ps pulse duration. Thus, to perform the computation in our experiments, the required
average optical power is 18 µW per fiber mode (4.4 mW/240).
In terms of optical computing operations, we can assume that the number of operations is at least
of the order of N2, since the input of size N is first multiplied with the number of modes (mode
decomposition) and then each of the N modes is operated upon. This can be seen from the
propagation Eq. 1 or its implementation as a network in Fig. 6. The nonlinear coupling tensor 𝜂
has the largest terms for self-phase and cross phase modulation [40]. Even keeping only these
terms, the number of multiplications reduces to N 2. As Fig. 6 suggest, this latter computation is
performed many times in the fiber.
With current SLM technology, the number of inputs N can reach up to 10 7 pixels with a 60 Hz
refresh rate [42]. Increasing the number of fiber modes to 107 can be done by employing large
core MMFs and/or multicore MMFs. The number of Operations per seconds would then be N2 x
SLM refresh rate, or more than 6 PetaOps/s. The digital single layer network N x 1 following the
optical computation would require only 6•107 FLOPs.

At this hypothetical optical computation rate of 6 PetaOps/s, an optimal pulsed laser having 10 ps
long pulses with a 60 Hz repetition rate synchronized to the 60 Hz SLM, would require less than
1 W of average optical power. By comparison, the world’s fastest supercomputer, Fugaku at the
Riken Center in Japan consumes 30 MW, which is 15 gigaFLOPS/W [43]. The SOLO system has
6 orders of magnitude less power consumption per computation.
The digital counterparts of the SOLO can be categorized into three categories. The first approach
can be the simulations with exact experimental parameters such as 5 m GRIN MMF. As we
already saw such an approach will require more than 2 years of GPU computation for a dataset
with 3000 samples when the simulation grid sizes are set to the parameters explained in the
Methods section of this paper. The second approach can be to compare SOLO to a deep neural
network that is trained to learn the spatiotemporal pulse propagation in MMFs. This approach has
been achieved for linear propagation in MMFs with particular datasets [44,45] with networks
having at least >14 layers and >50 million parameters (weights). Nonlinear propagation studies
are yet to be investigated but it is reasonable to expect that more complex networks would be
required to learn nonlinear propagation in MMF. The last approach can be the standard deep
neural networks whose structure is unrelated to SOLO for each specific task. This approach
requires designing specific network architectures for each dataset type. As explained in the
Results section, the transfer learning methods can offer similar performances with the SOLO for
challenging datasets such as COVID-19 [38,39]. For transfer learning purposes, the deep neural
networks used in these studies contain 16-22 layers and 6-130 million parameters to train [46,47].
Even at the lower end of 6 million parameters (weights) the computational speed required to
match SOLO on a digital fully connected neural network would be Nx6X106 divided by the refresh
time of the SLM. For N=107 and a 15 ms refresh rate, this requires a digital machine with at least
1014 OPS. We should point out that the PetaOps nonlinear optical computation speed of the SOLO
system is compatible with today’s electronic IO interface speed: an 8 bit, 10 Megapixels camera
with 60 frames per second generates 15 Gbit/s data speed which can be handled by a 20 Gbit/s
PCI express data bus.
SOLO is a computing framework on which different problems were embedded and were
experimentally implemented. Our study demonstrated calculations that yield performance
comparable to fully connected and convolutional neural. With digital or optical feedback, the
present optical paradigm could act as a reservoir network structure [48]. Our tests targeted

supervised learning examples, yet unsupervised learning is possible with the proposed technique
due to the label-free nonlinear projection behavior of the spatiotemporal pulse propagation. To
increase the performance of SOLO or to adapt it for more challenging tasks, the decision layer
used in the present studies can be modified with additional layers. Thus, SOLO can compute
information as a fast and efficient front-end module.
To evaluate the robustness of the present optical computing method, we repeated the
experiments for the COVID-19 dataset two weeks after the prior measurements presented in Fig.
5. Without requiring a calibration, we obtained the same learning performance level, 91%
accuracy on the test set, for diagnosing COVID-19 from X-ray images (see Supplementary
Discussion 7). This demonstration shows that the proposed SOLO method is remarkably robust,
and reproducible.

Outlook and Conclusion
The presented optical computing framework can be further improved with an active MMF scheme
where the fiber is mechanically perturbed [49] or the pump light is also shaped to control
spatiotemporal nonlinear propagation. Different cases of adaptive pumping in fiber amplifiers are
already demonstrated in the literature [50,51]. Such an implementation may lead to optically
controllable computing with nonlinear fiber optics.
We envision that another implementation of SOLO can be realized with silicon-on-Insulator
technology. This technology enables optical functions on integrated circuits, which already
resulted in many useful applications [52]. Nonlinear silicon photonics already demonstrated
supercontinuum generation through self-phase modulation, light amplification using the Raman
effect and matrix convolution operations [53,54]. By leveraging the existing integrated silicon
photonic manufacturing platform, it is possible to implement the machine learning that we
demonstrated in optical fibers.
In conclusion, we have shown how spatiotemporal nonlinear pulse propagation in MMFs can
optically process information to compute complex machine learning tasks that only sophisticated
deep neural networks can tackle. In our benchmarks, the proposed optical computing platform
performs as powerful as its digital counterparts for different tasks. With better energy efficiency
that previous proposals and a path to PetaOPs scalability, SOLO provides a novel path toward
supercomputer-level optical computation.

Method
Experimental setup
As the light source, an Yb fiber laser (Amplitude Laser-Satsuma) that produces 10ps pulses with
a 125 kHz repetition rate is selected. The pulse is centered around 1033 nm with a width of 10
nm. The linearly polarized Gaussian laser output beam is shaped via a phase-only SLM (Holoeye
Pluto-NIRII), an 8um pixel pitch and 60 Hz speed. The SLM prints the desired input pattern on
top of a grating phase pattern that expels unmodulated light. We used 5m of a commercial GRIN
50/125 multimode fiber with NA of 0.2; this fiber allows 120 modes per polarization for the given
excitation. The phase-modulated light from SLM is imaged onto the MMF with a 15mm lens focal
length. The information beam covers the whole MMF core area. The beam-core overlap is
checked by imaging the back reflection of the proximal fiber side (not shown in fig 1). The distal
fiber side is magnified 12.5 times through a 4f imaging system and recorded by a camera with a
5.2um pixel pitch. We monitored fiber output power after and before the MMF continuously.
Various neutral density filters are embedded to avoid camera saturation. The pulse power and
width are optimized so that the pulse conserves its temporal unity (no temporal splitting) and
maximizes spatial interactions.

Numerical Simulations
We implemented a GPU parallelized time-dependent beam propagation method (TBPM) in
Python to simulate sufficiently fast nonlinear pulse propagation in the fiber. TBPM simulations
often require long computational times due to heavy multidimensional fast Fourier transform
calculations. The launched pulses centered at 1030 nm with one ps duration were numerically
propagated for 10 self-imaging periods distance. In the experiment, the fiber length is 5 m. To
reach a manageable computing time for the datasets with 3000 samples, we performed a
rescaling of the propagation length from 5 m to ~5.5 mm. To generate significantly nonlinear
spatiotemporal evolution in such a short propagation, we increased the pulse peak power to 10
MW. The time window of simulation is 20ps with 9.8 fs resolution and the spatial window is set as
a 64x64 spatial grid. To properly simulate the graded-index MMF's spatial self-imaging, the
numerical integration step is set to sample each self-imaging period 16 times. To create an
absorptive boundary condition around the core we truncated the parabolic fiber index profile with
the super-Gaussian filter. We matched the launched Gaussian beam diameter (1/e 2) to fiber core
size (50 μm). For our studies, we encoded data into the beam as a multiplied phase information.

After propagation, the obtained pulse is time-averaged and converted into normalized intensity
images. There are several ways of converting images into one-dimensional representations. For
simplicity, we used a flattened version of downsampled images as an output vector. Finally,
flattened output vectors are linearly fitted using the standard Linear Regression method.

Data and code availability
The numerical data used in this work and a public version of the codes are available at
https://github.com/ugurtegin/Nonlinear_MMF_Network.

Acknowledgements
The authors thank Niyazi Ulaş Dinç and Prof. Yaser Abu-Mostafa for fruitful discussions.

Author contributions
U.T., M.Y. and I.O. performed simulations and experiments, C.M and D.P. supervised and
directed the project. All the authors participated in the analysis of the data and the writing process
of the manuscript.

References
[1] Cutrona, L., Leith, E. N., Palermo, C., & Porcello, L. Optical data processing and filtering systems. IRE
Transactions on Information Theory, 6 (3), 386-400 (1960).
[2] Cutrona, L. J., Leith, E. N., Porcello, L. J., & Vivian, W. E. On the application of coherent optical
processing techniques to synthetic-aperture radar. Proceedings of the IEEE, 54 (8), 1026-1032 (1966).
[3] Miller, D. A. B., Chemla, D. S., Damen, T. C., Gossard, A. C., Wiegmann, W., Wood, T. H., & Burrus, C.
A. Novel hybrid optically bistable switch: The quantum well self‐electro‐optic effect device. Applied Physics
Letters, 45 (1), 13-15 (1984).
[4] Goodman, J. W., Leonberger, F. J., Kung, S. Y., & Athale, R. A. Optical interconnections for VLSI
systems. Proceedings of the IEEE, 72 (7), 850-866 (1984).
[5] Feldman, M. R., Esener, S. C., Guest, C. C., & Lee, S. H. Comparison between optical and electrical
interconnects based on power and speed considerations. Applied Optics, 27 (9), 1742-1751 (1988).
[6] Farhat, N. H., Psaltis, D., Prata, A., & Paek, E. Optical implementation of the Hopfield model. Applied
Optics, 24 (10), 1469-1475 (1985).
[7] Psaltis, D., Brady, D., Gu, XG. et al. Holography in artificial neural networks. Nature 343, 325–330
(1990).

[8] Wetzstein, G., Ozcan, A., Gigan, S. et al. Inference in artificial intelligence with deep optics and
photonics. Nature 588, 39–47 (2020).
[9] Cortes, C., & Vapnik, V. Support-vector networks. Machine Learning, 20 (3), 273-297 (1995).
[10] Noble, W. S. What is a support vector machine?. Nature Biotechnology, 24 (12), 1565-1567 (2006).
[11] Gallicchio, C., & Micheli, A. Tree echo state networks. Neurocomputing, 101, 319-337 (2013).
[12] Maass, W. Liquid state machines: motivation, theory, and applications. In Computability in context:
computation and logic in the real world, 275-296 (2011).
[13] Larger, L., Soriano, M. C., Brunner, D., Appeltant, L., Gutiérrez, J. M., Pesquera, L., ... & Fischer, I.
Photonic information processing beyond Turing: an optoelectronic implementation of reservoir computing.
Optics Express, 20 (3), 3241-3249 (2012).
[14] Brunner, D., Soriano, M. C., Mirasso, C. R., & Fischer, I. Parallel photonic information processing at
gigabyte per second data rates using transient states. Nature Communications, 4 (1), 1-7 (2013).
[15] Vandoorne, K., Mechet, P., Van Vaerenbergh, T., Fiers, M., Morthier, G., Verstraeten, D., ... &
Bienstman, P. Experimental demonstration of reservoir computing on a silicon photonics chip. Nature
Communications, 5 (1), 1-6 (2014).
[16] Saade, A., Caltagirone, F., Carron, I., Daudet, L., Drémeau, A., Gigan, S., & Krzakala, F. Random
projections through multiple optical scattering: Approximating kernels at the speed of light. IEEE
International Conference on Acoustics, Speech and Signal Processing, 6215-6219 (2016).
[17] Rafayelyan, M., Dong, J., Tan, Y., Krzakala, F., & Gigan, S. Large-Scale Optical Reservoir Computing
for Spatiotemporal Chaotic Systems Prediction. Phys. Rev. X, 10 (4) 041037(2020).
[18] Paudel, U., Luengo-Kovac, M., Pilawa, J., Shaw, T. J., & Valley, G. C. Classification of time-domain
waveforms using a speckle-based optical reservoir computer. Optics Express, 28 (2), 1225-1237(2020).
[19] Sunada, S., Kanno, K., & Uchida, A. Using multidimensional speckle dynamics for high-speed, largescale, parallel photonic computing. Optics Express, 28 (21), 30349-30361 (2020).
[20] Huang, G. B., Zhu, Q. Y., & Siew, C. K. Extreme learning machine: theory and applications.
Neurocomputing, 70 (1-3), 489-501 (2006).
[21] Marcucci, G., Pierangeli, D., & Conti, C. Theory of neuromorphic computing by waves: machine
learning by rogue waves, dispersive shocks, and solitons. Physical Review Letters, 125 (9), 093901 (2020).
[22] Wright, L. G., Christodoulides, D. N., & Wise, F. W. Controllable spatiotemporal nonlinear effects in
multimode fibres. Nature Photonics, 9 (5), 306-310 (2015).
[23] Krupa, K., Tonello, A., Barthélémy, A., Couderc, V., Shalaby, B. M., Bendahmane, A., ... & Wabnitz, S.
Observation of geometric parametric instability induced by the periodic spatial self-imaging of multimode
waves. Physical Review Letters, 116 (18), 183901 (2016).
[24] Teğin, U., & Ortaç, B. Spatiotemporal instability of femtosecond pulses in graded-index multimode
fibers. IEEE Photonics Technology Letters, 29 (24), 2195-2198 (2017).

[25] Lopez-Galmiche, G., Eznaveh, Z. S., Eftekhar, M. A., Lopez, J. A., Wright, L. G., Wise, F., ... & Correa,
R. A. Visible supercontinuum generation in a graded index multimode fiber pumped at 1064 nm. Optics
Letters, 41 (11), 2553-2556 (2016).
[26] Teğin, U., & Ortaç, B. Cascaded Raman scattering based high power octave-spanning supercontinuum
generation in graded-index multimode fibers. Scientific Reports, 8 (1), 1-7 (2018).
[27] Krupa, K., Tonello, A., Shalaby, B. M., Fabert, M., Barthélémy, A., Millot, G., ... & Couderc, V. (2017).
Spatial beam self-cleaning in multimode fibres. Nature Photonics, 11 (4), 237-241.
[28] Wright, L. G., Christodoulides, D. N., & Wise, F. W. Spatiotemporal mode-locking in multimode fiber
lasers. Science, 358 (6359), 94-97 (2017).
[29] Teğin, U., Kakkava, E., Rahmani, B., Psaltis, D., & Moser, C. Spatiotemporal self-similar fiber
laser. Optica, 6 (11), 1412-1415 (2019).
[30] Teğin, U., Rahmani, B., Kakkava, E., Psaltis, D., & Moser, C. Single-mode output by controlling the
spatiotemporal nonlinearities in mode-locked femtosecond multimode fiber lasers. Advanced Photonics, 2
(05), 1–8 (2020).
[31] Tzang, O., Caravaca-Aguirre, A. M., Wagner, K., & Piestun, R. Adaptive wavefront shaping for
controlling nonlinear multimode interactions in optical fibres. Nature Photonics, 12 (6), 368-374 (2018).
[32] Teǧin, U., Rahmani, B., Kakkava, E., Borhani, N., Moser, C., & Psaltis, D. Controlling spatiotemporal
nonlinearities in multimode fibers with deep neural networks. APL Photonics, 5 (3), (2020).
[33] Barbastathis, G., Ozcan, A., & Situ, G. On the use of deep learning for computational imaging. Optica,
6 (8), 921-943 (2019).
[34] Terry, N. B., Alley, T. G., & Russell, T. H. An explanation of SRS beam cleanup in graded-index fibers
and the absence of SRS beam cleanup in step-index fibers. Optics Express, 15 (26), 17509, (2007).
[35] https://archive.ics.uci.edu/ml/datasets/Abalone
[36] Zhang, Z., Song, Y., & Qi, H. Age progression/regression by conditional adversarial autoencoder. In
Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 5810-5818) (2017).
[37] https://github.com/Jakobovski/free-spoken-digit-dataset
[38] Soares, E., Angelov, P., Biaso, S., Froes, M. H., & Abe, D. K. SARS-CoV-2 CT-scan dataset: A large
dataset of real patients CT scans for SARS-CoV-2 identification. medRxiv (2020).
[39] Abbas, A., Abdelsamea, M. M., & Gaber, M. M. Classification of COVID-19 in chest X-ray images using
DeTraC deep convolutional neural network. arXiv preprint arXiv:2003.13815 (2020).
[40] Mafi, A. Pulse propagation in a short nonlinear graded-index multimode optical fiber. Journal of
Lightwave Technology, 30 (17), 2803-2811 (2012).
[41] Snyder, A. W. Coupled-mode theory for optical fibers. JOSA, 62(11), 1267-1277 (1972).
[42] https://holoeye.com/gaea-4k-phase-only-spatial-light-modulator/
[43] https://www.fujitsu.com/global/about/innovation/fugaku/
[44] Borhani, N., Kakkava, E., Moser, C., & Psaltis, D. Learning to see through multimode fibers. Optica, 5
(8), 960-966 (2018).

[45] Rahmani, B., Loterie, D., Konstantinou, G., Psaltis, D., & Moser, C. Multimode optical fiber transmission
with a deep learning network. Light: Science & Applications, 7 (1), 1-11 (2018).
[46] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. Going deeper
with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.
1-9) (2015).
[47] Simonyan, K., & Zisserman, A. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556 (2014).
[48] Ortín, S., Soriano, M., Pesquera, L. et al. A Unified Framework for Reservoir Computing and Extreme
Learning Machines based on a Single Time-delayed Neuron. Sci Rep 5, 14945 (2015).
[49] Resisi, S., Viernik, Y., Popoff, S. M., & Bromberg, Y. Wavefront shaping in multimode fibers by
transmission matrix engineering. APL Photonics, 5 (3), 036103 (2020).
[50] Sperber, T., Billault, V., Dussardier, B., Gigan, S., & Sebbah, P. Gain As Configurable DisorderAdaptive Pumping for Control of Multimode Fiber Amplifiers and Lasers. arXiv preprint arXiv:2008.04085
(2020).
[51] Bachelard, N., Gigan, S., Noblin, X., & Sebbah, P. Adaptive pumping for spectral control of random
lasers. Nature Physics, 10 (6), 426-431 (2014).
[52] Bogaerts, W., Pérez, D., Capmany, J. et al. Programmable photonic circuits. Nature 586, 207–216
(2020).
[53] Leuthold, J., Koos, C. & Freude, W. Nonlinear silicon photonics. Nature Photon 4, 535–544 (2010).
[54] Feldmann, J., Youngblood, N., Karpov, M., Gehring, H., Li, X., Gallo, M. L., ... & Wright, D. Parallel
convolution processing using an integrated photonic tensor core. arXiv preprint arXiv:2002.00281 (2020).

Supplementary Material of
Scalable Optical Learning Operator
Uğur Teğin1,2,*, Mustafa Yıldırım2, İlker Oğuz1,2, Christophe Moser2 and Demetri
Psaltis1
1 Optics

Laboratory, École Polytechnique Fédérale de Lausanne, Switzerland
of Applied Photonics Devices, École Polytechnique Fédérale de Lausanne, Switzerland
* ugur.tegin@epfl.ch
2 Laboratory

Supplementary Discussion 1: Physical Model of the Computation Framework
The optical beam at any position of the optical fiber can be decomposed into spatial modes of
the fiber. In Eq. 1, 𝐸 (𝜌, 𝜑, 𝜔) is the electric field of the light, 𝐴𝑙 is the envelope of the
corresponding mode along the propagation direction 𝑧 and 𝐹𝑙 is the mode shape. Eq.2 shows
the solution of the mode shape 𝐹𝑙 for graded index fibers having relative index difference of
∆ and radius of R, 𝐿𝑝 is the generalized Laguerre polynomial [S1,S2]. The modes propagation
constant 𝛽𝑝,𝑚 are calculated using Eq. 3.

𝐸 (𝜌, 𝜑, 𝜔) = ∑ 𝐹𝑙 (𝜌, 𝜑, 𝜔) ⅇ ⅈ𝛽𝑙(𝜔)𝑧 𝐴̃𝑙 (𝑧, 𝜔)
𝑙

(Supp.Eq. 1)

𝑝!

𝐹𝑝,𝑚 (𝜌, 𝜑, 𝜔) =√𝜋(𝑝+|𝑚|)!

𝜌 |𝑚|
(𝑤0 /√2)|𝑚|+1

2

𝜌2

ⅈ𝑚𝜑
ⅇ −𝜌∕𝑤0 𝐿|𝑚|
𝑝 (2 𝑤 ) ⅇ
0

(Supp.Eq. 2)

𝛽𝑝,𝑚 (𝜔) = 𝑘√1 −

2√∆
(2𝑝 + |𝑚| + 1)
𝑘𝑅
(Supp.Eq. 3)

Propagation of an intense pulse inside an optical fiber can be analyzed following this
representation. Eq. 4 represents the nonlinear spatiotemporal evolution of each mode. Each
mode is coupled to the others through the nonlinearity tensor coefficient 𝜂𝑝,𝑙,𝑚,𝑛which models
nonlinear intermodal and intramodal effects, and through a linear coupling coefficient ( 𝐶𝑝,𝑛 )

which expresses mode coupling due to perturbations to the ideal fiber shape and refractive
index distribution, such as bending and impurities. The linear coupling coefficient (𝐶𝑝,𝑛 )
relates perturbation in permittivity (or refractive index) to intermodal model coupling by
calculating the overlap integral with the corresponding mode shapes [S3]. Similarly, the
nonlinearity tensor coefficient (𝜂𝑝,𝑙,𝑚,𝑛 ) is computed with the normalized overlap integral of
modes. We computed the nonlinear coupling tensor between the modes for our GRIN-50/125
fiber. The tensor has a 1204 size and computing all nonlinear terms took two and a half months
on a server computer with 2x Intel Xeon CPU E5-2670 and 384 GB of RAM. The cross-phase
modulation coefficients (𝜂𝑝,𝑝,𝑞,𝑞 , inter modal nonlinearities) are shown in Fig. 1, where the
diagonal terms correspond to self-phase modulation (𝜂𝑝,𝑝,𝑝,𝑝 , intramodal nonlinearities). This
demonstrates the richness of the nonlinear interaction that SOLO relies upon. Note that fourwave mixing could not be shown on the graph due to its dimensionality.

𝜕𝐴𝑝
𝜕𝐴𝑝
𝛽2 𝜕 2 𝐴𝑝
= 𝑖𝛿𝛽0 𝑝 𝐴𝑝 − 𝛿𝛽1 𝑝
−𝑖
+
⏟
𝜕𝑧
𝜕𝑡
2 𝜕𝑡 2
𝑃𝑟𝑜𝑝𝑎𝑔𝑎𝑡ⅈ𝑜𝑛 𝑎𝑛𝑑 𝐷ⅈ𝑠𝑝𝑒𝑟𝑠ⅈ𝑜𝑛

𝑖 ∑ 𝐶𝑝,𝑛 𝐴𝑛
⏟𝑛
𝐿ⅈ𝑛𝑒𝑎𝑟 𝑀𝑜𝑑𝑒 𝐶𝑜𝑢𝑝𝑙ⅈ𝑛𝑔

+ 𝑖𝛾 ∑ 𝜂𝑝,𝑙,𝑚,𝑛 𝐴𝑙 𝐴𝑚 𝐴𝑛 ∗
⏟ 𝑙,𝑚,𝑛
𝑁𝑜𝑛𝑙ⅈ𝑛𝑒𝑎𝑟 𝑀𝑜𝑑𝑒 𝐶𝑜𝑢𝑝𝑙ⅈ𝑛𝑔

(Supp.Eq. 4)

𝜂𝑝,𝑙,𝑚,𝑛 =

∬ 𝑑𝑥 𝑑𝑦 𝐹𝑝 𝐹𝑙 𝐹𝑚 𝐹𝑛
[∬ 𝑑𝑥 𝑑𝑦 𝐹𝑝 ∬ 𝑑𝑥 𝑑𝑦 𝐹𝑙 ∬ 𝑑𝑥 𝑑𝑦 𝐹𝑚 ∬ 𝑑𝑥 𝑑𝑦 𝐹𝑛 ]2
(Supp.Eq. 5)

𝐶𝑝,𝑛 =

𝜔
2

∬ 𝑑𝑥 𝑑𝑦 (𝜖̃∗ − 𝜖)𝐹𝑝 𝐹∗𝑛
(Supp.Eq. 6)

Supplementary Figure 1: Intra- and Intermodal nonlinear coupling coefficients
(𝜂𝑝,𝑝,𝑞,𝑞 , 𝜂𝑝,𝑝,𝑝,𝑝 )
Supplementary Discussion 2: Time Dependent Beam Propagation
Instead of considering individual mode field propagation, we use. Eq.7 to describe the total
field propagation in a GRIN fiber without perturbations. We numerically implemented Eq.7
using symmetrized split-step Fourier Method. The codes are implemented in Python + Cupy
library which made it possible to utilize powerful GPUs. The time steps are selected at the
Nyquist rate defined by the wavelengths range given in Eq. 8-9. We used the self-imaging
period as one of our control knobs in simulations using the equations in Supp. Eq.10 [S2]. 𝐴
in the Supp. Eq. 8 is the slowly varying envelope at the center frequency.
The datasets are divided with a ratio of 0.2 for training (2400 samples) and validation (600
samples). The regression is implemented using Scikit-learn or Tensorflow on Google Colab
cloud service which provides an Intel Xeon CPU and Nvidia Tesla V100 GPU. We also used
single dense layer without nonlinear activations for linear regression.

𝜕𝐴
𝑖 𝜕2 𝐴 𝜕2 𝐴
𝛽2 𝜕 2 𝐴 𝛽3 𝜕 3 𝐴 𝑖𝑘0 ∆(𝑥 2 + 𝑦 2 )𝐴
=
( 2 + 2) − 𝑖
+
−
+ 𝑖𝛾|𝐴|2 𝐴
𝜕𝑧 2𝑘0 𝜕𝑥
𝜕𝑦
2 𝜕𝑡 2
6 𝜕𝑡 3
𝑅2
(Supp.Eq. 7)
𝜆𝑚ⅈ𝑛 =

1
1
1
2𝑐𝛥𝑡 + 𝜆0
(Supp.Eq. 8)

𝜆𝑚𝑎𝑥 =

1
1
1
− 2𝑐𝛥𝑡 +
𝜆0
(Supp.Eq. 9)

𝑆ⅇ𝑙𝑓 𝑖𝑚𝑎𝑔𝑖𝑛𝑔 𝑝ⅇ𝑟𝑖𝑜𝑑 =

𝜋𝑅
√2∆
(Supp.Eq. 10)

Supplementary Discussion 3: Data encoding to SLM
Images are 2D arrays, therefore the image datasets are directly mapped to SLM pixels. We
illuminated the 600-by-600 pixels central region of the SLM and all images are scaled to that
size to cover the entire beam. A blazed grating is added to the pattern to prevent unmodulated
DC light to enter the fiber. Encoding 2D arrays are relatively easy than a scalar or 1D input.
To handle a scalar input (such as for Sinc experiment), we mapped the scalar value to a 2D
array by multiplying the value through a fixed random 2D matrix. This provides unique 2D
matrixes for every distinct input value. For a 1D input, we simply converted them to 2D and
upscaled to the illumination pixel range.
Supplementary Discussion 4: Single value regression of Sinc function
First, we tested the nonlinear information transformation ability of spatiotemporal propagation
of high peak power pulses numerically by performing time-dependent beam propagation
method (TBPM) simulations (Supplementary Discussion 2). Our first numerical simulation was
learning the Sinc function input-output relation numerically duplicating the experiment we
described above. The Sinc is a simple nonlinear function that cannot be learned with a singlelayer network and it has been used as a standard benchmark to validate learning methods
[18,19]. We used 3000 randomly generated samples, which lie in [-π,π] to cover the Sinc
function's characteristic behavior. We fed the generated samples to TBPM by expanding
scalar values to two-dimensional form using a random mask and calculated the nonlinear
pulse propagation in the GRIN MMF. The projected intensity distribution at the distal end of
the fiber is considered as the nonlinearly transformed information. The linear regression
parameters are retrieved from the training data, and the overall performance is assessed by
the test data. A remarkable learning performance with 0.0039 root-mean-squared error
(RMSE) for the test data is obtained. The achieved performance shows that spatiotemporal
fiber nonlinearity provides a significant contribution to learning ability. The result proves that
our computational device transformed the input space to a higher dimensional space efficiently
such that the proposed framework interpolates a function for the unseen data.

Supplementary Figure 2: Learning the Sinc function from simulated data

Supplementary Figure 3: Learning the Sinc function from experimental data

Supplementary Discussion 5: Results of numerical studies
We simulated the nonlinear pulse propagation with the abalone dataset information to perform
multivariable regression. We encoded the abalone features as the spatial phase distribution
of a pulse in our numerical implementation onto the input beam. Similar to the Sinc function,
a decision layer to perform linear regression is employed and we obtained an age prediction
with remarkable accuracy (RMSE of 0.0831). Supp. Fig. 4 a presents normalized correct ages
and predictions. We continued our numerical studies with the face image dataset. By encoding
different human face images into the simulated pulse, each person's age on the images was
estimated, and an RMSE of 0. 2175 on normalized output values indicated again close
correspondence with the experimental studies (see Supp. Fig. 4 b).

Supplementary Figure 4: Experimental (a-d) learning results for regression and
classification tasks. (a) Learning of abalone (multivariable) dataset. (b) Age prediction from
face image dataset. (c) Confusion matrix for audio dataset digit classification. (d) Confusion
matrix for audio dataset speaker classification.
As indicated in our experimental studies, the audio data can also be converted to a twodimensional format and regarded as an image analysis task by calculating the related
spectrogram. This way, we simulated the nonlinear propagation of pulses for audio digit for
categorization purposes. By taking the fiber output beam shapes as inputs to a single layer
classifyer gave approximately 68% accuracy as shown in Supp. Fig. 4 c. Similar to our
experimental investigations, we updated the decision layer and tried to differentiate the
speaker from the audio record. In our numerical studies, we obtained 61% accuracy over the
unseen test set (see Supp. Fig. 4 e). The evolution of loss and accuracy (if applicable)
functions for our digital decision layer with experimental results are presented in Fig. 5 a-c.

Supplementary Figure 5: Training of the numerical (a-c) results. (a) Evolution of loss
function for age prediction dataset. (b) Evolution of accuracy and loss function for digit
classification with audio dataset. (c) Evolution of accuracy and loss function for speaker
classification with audio dataset.
Supplementary Discussion 6: Power Oscillations during experiment
Learning is related to the amount of nonlinearity (or power). Therefore, stable power is
required during experiments. Supp. Fig. 6 shows power fluctuations recorded at the fiber end.

There is a small variation due to the modulated diffraction efficiency of grating that depends
on the encoded patterns.

Supplementary Figure 6: Output power fluctuations of Face dataset

Supplementary Discussion 7: Peak power vs Beam and Spectrum Analysis
The effect of the nonlinearity on the output beam shape and spectrum are shown in Supp. Fig.
7. In these experiments, a symmetric Gaussian beam with flat phase is injected without any
encoding. The power of the beam at the output of the fiber is concentrated in the center. In fig.
7, we observe that an increase of peak power spreads the spectrum and the spatial distribution
of the output beam initially spread from center (Supp. Fig. 7 a-b). Raman beam cleaning [S4]
then becomes dominant when the power further increase, which creates again a beam with
powe concentrated in the center ( Supp. Fig. 11).

Supplementary Figure 7: Spectrum and output beam evolution at the end of the test fiber
with increasing pulse peak power.

Supplementary Discussion 8: Robustness of experiments
The robustness test results of the experimentally demonstrated optical computing method are
presented in this section. The exact same experiments with the COVID 19 x-ray images were
performed again at a two week interval. As illustrated in Supplementary Fig. 12, above 90%
accuracy over test data is achieved similar to the results obtained in Fig.5 in the main text.
These results validate the robustness of the present optical computing framework.

Supplementary Figure 12: Experimentally tested COVID-19 CT-scan dataset. (a)
Confusion matrix for condition classification. Evolution of accuracy (b) and loss (c) functions
for COVID-19 CT-scan dataset.
Supplementary Discussion 9: Robustness of experiments

An example of input and output relation in SOLO is presented in Supp. Fig. 13. Here
the input images are loaded on the SLM. After propagation through the fiber, the beam
profile is recorded corresponding to each respective input. These beam profiles
contain the nonlinearly processed input information for the decision layer, as explained
in detail in the Methods section.

Supplementary Figure 13: Experimentally used input images and SOLO output beam
profiles for COVID-19 CT-scan dataset.

Supplementary References
[S1] Poletti, F., & Horak, P. (2009). Dynamics of femtosecond supercontinuum generation in
multimode fibers. Optics express, 17(8), 6134-6147.
[S2] Mafi, A. (2012). Pulse propagation in a short nonlinear graded-index multimode optical
fiber. Journal of Lightwave Technology, 30(17), 2803-2811.
[S3] Snyder, A. W. (1972). Coupled-mode theory for optical fibers. JOSA, 62(11), 12671277.
[S4] Terry, N. B., Alley, T. G., & Russell, T. H. An explanation of SRS beam cleanup in
graded-index fibers and the absence of SRS beam cleanup in step-index fibers. Optics
Express, 15 (26), 17509, (2007).

