arXiv:2105.08848v1 [math.OC] 18 May 2021

Optimal Control of the SIR Model with
Constrained Policy, with an Application to
COVID-19
Yujia Ding, Henry Schellhorn
May 20, 2021
Abstract
This article considers the optimal control of the SIR model with both
transmission and treatment uncertainty. It follows the model presented
in Gatto and Schellhorn (2021). We make four significant improvements
on the latter paper. First, we prove the existence of a solution to the
model. Second, our interpretation of the control is more realistic: while
in Gatto and Schellhorn the control α is the proportion of the population
that takes a basic dose of treatment, so that α > 1 occurs only if some patients take more than a basic dose, in our paper, α is constrained between
zero and one, and represents thus the proportion of the population undergoing treatment. Third, we provide a complete solution for the moderate
infection regime (with constant treatment). Finally, we give a thorough
interpretation of the control in the moderate infection regime, while Gatto
and Schellhorn focussed on the interpretation of the low infection regime.
Finally, we compare the efficiency of our control to curb the COVID-19
epidemic to other types of control.

1

Introduction

This article extends the analysis of the model presented in Gatto and Schellhorn
(2021).We make four significant improvements on the latter paper. First, we
prove existence of a solution. Second, In Gatto and Schellhorn (2021) the optimal control α has the interpretation of the proportion of the population that
takes a basic dose of treatment, so that α > 1 occurs only if a proportion of
the population takes more than a basic dose of treatment. In the low infection
regime part of our paper, α is constrained to be between zero and one, and represents thus the proportion of the population undergoing treatment. The latter
interpretation is much more realistic, as it is uncommon to ration treatment.
Third, we provide a complete solution for the moderate infection regime (with
constant treatment). The final improvement is a thorough numerical analysis and sensitivity analysis of the moderate infection regime, while Gatto and
Schellhorn (2021) focused exclusively on the interpretation of the control in the
1

low infection regime. This enables us to discover some errors in the secondorder term of the solution in Gatto and Schellhorn (2021), which we correct
here. Finally, we compare the efficiency of our control to curb the COVID-19
pandemic to other types of control. While our solution is complex, it allows to
satisfy the objective better. Also, our analytical solutions allow for an intuitive
understanding of the optimal control compared to a purely numerical solution.
The structure of the article is as follows. In section 2 we briefly introduce
the model in Gatto and Schellhorn (2021), and provide a proof of existence of
the solution. In section 3, we show our results for the low infection regime. In
section 4, we extend and analyze the solution in the moderate infection regime.
Section 5 shows our experimental results when applying our methodology to the
COVID-19 in the US in 2020. We draw the conclusion in Section 6. We refer the
reader to our earlier paper, Gatto and Schellhorn (2021) for a literature review.

2

A Stochastic SIR Model with Treatment Uncertainty

Let S, I, R be the proportions of susceptible, infected, and out of infection
(recovered, and dead), respectively. Let β be the transmission rate and µ be
the death rate.
In the SIR model, the rate of decrease dS
dt of the proportion of susceptible is
equal to the constant transmission
rate
β
time
SI. As in Gatto and Schellhorn
√
dB1
1
(2021), we add a term σS SI dB
,
where
is
white noise, in order to model
dt
dt
the error in the transmission rate:
√ dB1
dS
= −βSI + σS SI
dt
dt
The optimal policy α is the proportion of the infected population that received treatement, thus α(t) ∈ [0, 1]. The presence of this constraint is an
important addition to the model in Gatto and Schellhorn (2021). Depending
whether the individual is treated or not, there are then four different ways for
an infected individual to exit the pool of infected:
•
•
•
•

not treated and recover
not treated and die
treated and recover
treated and died.

Thus, the ”out of infection rate” will be:
dR(t)
= (1 − α(t))I(t)K0 + (1 − α(t))I(t)µ0 + α(t)I(t)K1 (t)
|
{z
}
|
{z
}
|
{z
}
dt
not treated and recover

+ α(t)I(t)µ1 −
| {z }
treated and die

not treated and die

dB2
α(t)I(t)σ
|
{z dt }

treated and recover

treatment measurement error

2

(1)

For simplicity, we assume that the Brownian motion driving transmission
uncertainty (B1 ) is independent from the Brownian motion driving treatment
uncertainty (B2 ). We suppose that µ0 ≥ µ1 (people die faster without treatment
than with treatment), but the reader will not lose any intuition by supposing
that µ0 = µ1 . Most of the time K1 (t) > K0 (treatment is better than no treatment), but not necessarily. We relax this requirement somewhat by requiring:
P (K0 < K1 (t)) is close to one

(2)

We model the treatment rate as an Ornstein-Uhlenbeck process:
dK1 (t) = λk (k̄1 − K1 (t))dt + σk dB2 (t)
with the mean-reversion rate λk > 0 and the long run value of the treatment
rate k̄1 . It is well-known that K1 is Gaussian, with variance equal to:
Var[K1 (t)] =

σk2
(1 − e−2λk t )
2λk

Thus, if mean-reversion is large compared to volatility σk , constraint (2) is
satisfied. We simplify (1) by:
dR(t)
dt

I(t)

= K0 + µ0 + α(t)(−K0 + K1 (t) − µ0 + µ1 ) − α(t)σ

dB2
dt

Putting everything together, the dynamics of the infected is:
p
dR(t)
dB1
dI(t)
= βS(t)I(t) −
− σS S(t)I(t)
dt
dt
dt
We try to minimize a measure of the infected over our horizon T . To model
risk-aversion to unfavorable treatment decisions, the decision-maker is supposed
to minimize the expected value of a convex and increasing function of I(T ).
Alternately, one can maximize the negative thereof, i.e., maximize the expected
value of a concave and decreasing function of I(T ). Such a function U is called
a utility function in financial economics. The policy obtained in maximizing
the expected value of a concave utility function can be showed, under certain
conditions, to maximize the expected value of the outcome (here −I) under a
constraint on the dispersion of the outcome. Out of the universe of concave
decreasing utility functions, we choose the power utility function:
U (I) = −

I 1−γ
1−γ

The coefficient γ is often called the risk-aversion parameter. When γ = 0
the decision-maker is risk-neutral, meaning that the uncertainty does not have
an influence on her decisions. It is straightforward to check that this power
utility function is concave in I when γ < 0,which we will assume. Taking for
instance γ = −1, we see that the objective is to
 I2 
max E −
2
3

which returns the same policy as:
 I2 
min E
2
The importance of analytic formulations is that other figures of interest in
this model, like the expected number of deaths from treatment can be analytically calculated, and depend on γ. Thus, a decision-maker can calibrate its
risk-aversion parameter γ on other goals. Expected number of deaths is only
one type of goal and economic factors that can be easily added. We define
τ = min{t > 0|I(t) ≤ 0 or I(t) ≥ 1}
Our controlled SIR model is thus:
 I(min(τ, T ))1−γ 
E −
1−γ
0≤α(t)≤1
p
dS(t) = −βS(t)I(t)dt + σS S(t)I(t)dB1 (t)
sup

(3)

dI(t) = (βS(t) − (K0 + µ0 ) + α(t)(K0 − K1 (t) + µ0 − µ1 )) I(t)dt
p
+ α(t)I(t)σdB2 (t) − σS S(t)I(t)dB1 (t)
(4)
dK(t) = λk (K̄ − K(t))dt + σk dB2 (t)

(5)

The relative sign of our volatilities σ and σk is important. We will assume
without loss of generality that σ < 0. The sign of σk is the sign of covariance
between the measured value of today’s treatment rate and the change in value
of the treatment rate between today and a future date. An example may help
illustrate the difference. Suppose that over a week one performs daily measurements of the treatment recovery rate as well as daily forecasts of the evolution
of the treatment recovery rate over the next day. The two quantities measured
each day t are proportional to the same white noise B2 (t+1 day) − B2 (t). One
then calculates weekly estimates σ̂ of σ and σ̂k of σk over these 7 daily observations. Since we arbitrarily choose σ > 0, a positive σ̂k shows a correlation of +1
between the measurement (of today’s treatment rate) and the forecast. Figure
1 is a depiction of our model.
Theorem 1. For any given intial value (S(0), I(0), R(0)) and any X(0) there
exists a unique solution of (3)(4)(5) up to time τ .
The proof of Theorem 1, included in Appendix A, follows the proof of a
theorem of Yamada and Watanabe (1971), as exposed in the book by Karatzas
and Shreve (2014, Prop. 2.13, Sec. 5.2).

3

Results in the Low Infection Regime

We assume S(t) close to one and σS = 0. Thus the term:
r = βS(t) − (K0 + µ0 ) ' β − K0 − µ0
4

Figure 1: A stochastic SIR model
is assumed constant. With this simplification, we give an analytical solution
to the constrained problem, i.e., the case where 0 ≤ α(t) ≤ 1, a significant
improvement over Gatto and Schellhorn, who considered the unconstrained case.
We define the impact of treatment risk X:
X(t) =

K0 + µ0 − µ1 − K1 (t)
σ

as well as the long run impact of the treatment risk X̄:
X̄ =

K0 + µ0 − µ1 − k̄1
σ

We define λx = λk and σx = σk /σ. For simplicity we write µ = K0 + µ0 .
We consider first the case where the treatment rate is constant, and then the
case where it follows an Ornstein Uhlenbeck process.

3.1

Constant Treatment Rate

Let b = β − µ1 − k̄1 . The problem is:

5

 I(T )1−γ 
E −
1−γ
0≤α(t)≤1
sup

(6)

dI(t) = (r + α(t)(b − r))I(t)dt + α(t)σI(t)dB2 (t)
Theorem 2. The optimal control is constant, and satisfies

k̄1 − K0 
α = min 1, max 0,
σ 2 |γ|
The proof is the Appendix B, and follows closely Cvitanić and Karatzas
(1992).

3.2

Treatment Rate as Ornstein-Uhlenbeck Process

The problem is
 I(T )1−γ 
sup E −
1−γ
dI(t) = (r + α(t)σX(t))I(t)dt + α(t)σI(t)dB2 (t)

(7)

dX(t) = λx (X̄ − X(t))dt − σx dB2 (t)
In the low infection regime our solution will depend on a kernel H0 (Xt , τ )
with τ = T − t, while in the moderate infection regime it will also depend on
two other kernels H1 (Xt , τ ) and H2 (Xt , τ ) that are closely related. In order to
unify notation we define the kernels. Define
 

1 A1 (τ, γ)Xt2
H0 (Xt , τ ) = exp
+ A2 (τ, γ)Xt + A3 (τ, γ) + (1 − γ)(µ + r)τ
γ
2
(8)
and, for i > 0
 

i A1 (τ, γ/i)Xt2
Hi (Xt , τ ) = exp
+ A2 (τ, γ/i)Xt + A3 (τ, γ/i)
(9)
γ
2
where
A1 (τ, γ) =

2(1 − exp(−θ(γ)τ ))
1−γ
γ 2θ(γ) − (b2 (γ) + θ(γ))(1 − exp(−θ(γ)τ ))
2

(10)

4λx X̄b1 (γ) (1 − exp (−θ(γ)τ /2))
(11)
θ(γ) (2θ(γ) − (θ(γ) + b2 (γ))(1 − exp(−θ(γ)τ )))

Z τ 2
σx
σ2
A3 (τ, γ) =
+ λx X̄ A22 (s, γ) + x A1 (s, γ) + (γ − 1)µds (12)
2γ
2
0

1−γ
σ2
γ−1
b1 (γ) =
b2 (γ) = 2
σx − λ x
b3 (γ) = x
γ
γ
γ
q
θ(γ) = b22 (γ) − 4b1 (γ)b3 (γ)
A2 (τ, γ) =

6

We provide an explicit formula for A3 (τ, γ) in Appendix C. The solution to
(7) is shown in Gatto and Schellhorn (2021, Prop. 1), but with some typos in
the expression of H0 (Xt , τ ), hence we correct the mistake by providing (8) in
this paper.

4

Results in the Moderate Infection Regime

We first handle the Ornstein-Uhlenbeck treatment rate case, which was presented in Gatto and Schellhorn (2021, Prop. 2). In this work, we aim to correct
the typos and provide more detials for the Proposition 2 in Gatto and Schellhorn
(2021).

4.1

Treatment Rate as Ornstein-Uhlenbeck Process

The problem is defined in Section 2. We rewrite here for convenience,
 I(min(τ, T ))1−γ 
sup E −
1−γ
p
dS(t) = −βS(t)I(t)dt + σS S(t)I(t)dB1 (t)
dI(t) = (βS(t) − µ + α(t)σX(t)) I(t)dt + α(t)I(t)σdB2 (t)
p
− σS S(t)I(t)dB1 (t)

(13)

dX(t) = λx (X̄ − X(t))dt − σx dB2 (t)
To express the solution of (13), we further define
1

2θ(γ)e 2 (b2 (γ/2)−b2 (γ)−θ(γ))(τ −t)

M̃ (t, τ ) =
2θ(γ) − (b2 (γ) + θ(γ)) 1 − e−θ(γ)(τ −t)
Z τ
σ2
mY (τ, x) = xM̃ (t, τ ) +
M̃ (s, τ )(λx X̄ + γx A2 (τ − s, γ))ds

(14)

s=t

A2 (T − τ, γ)
+
A1 (T − τ, γ)
Z τ
VY (τ, x) = σx2
M̃ 2 (s, τ )ds
t

Z

T

H2 (X, τ − t)

g(X, t) =
τ =t

× exp

1 β2
1
p
2
2 σS γ 1 − 2VY (τ, X)A1 (T − τ, γ)/γ

A22 (T − τ, γ)
γ
γA1 (T − τ, γ)
2
mY (τ, X)A1 (T − τ, γ) 
+
dτ
γ − 2VY (τ, X)A1 (T − τ, γ)

2

A3 (T − τ, γ) −

7

(15)

From this, we can calculate:
Z T
∂g
1 β2
1
=
H2 (X, τ − t) 2 p
∂X
2 σS γ 1 − 2VY (τ, X)A1 (T − τ, γ)/γ
τ =t


2
A2 (T − τ, γ)
m2Y (τ, X)A1 (T − τ, γ)
× exp
A3 (T − τ, γ) − 2
+
γ
γA1 (T − τ, γ) γ − 2VY (τ, X)A1 (T − τ, γ)
 A (τ − t, γ/2)X(t) + A (τ − t, γ/2)
1
2
×
γ/2

2mY (τ, X)A1 (T − τ, γ)
+
M̃ (t, τ ) dτ
γ − 2VY (τ, X)A1 (T − τ, γ)
Theorem 3. Let I(0) = ε. Suppose I(t) ≤ 1. If σx < 0 then the problem (13)
has a solution such that
I(t) = εZ 1/γ (t)H1 (X(t), T − t) + ε2 Z 2/γ (t)S(t)g(X(t), t) + O(ε3 )
where Z(t) satisfies:
√
β 2 SI
β SI
dZ
2
= (−µ + X +
)dt −
dB1 + XdB2
Z
σS2
σS
!γ
p
−H1 (X(0), T ) + H12 (X(0), T ) − 4εS(0)g(X(0), 0)(O(ε2 ) − 1)
Z(0) =
2εS(0)g(X(0), 0)
The optimal control α∗ (t) = α0 (t) + εα1 (t) + O(ε2 ) where:
X(t)
σx
−
(A1 (T − t, γ)X(t) + A2 (T − t, γ))
γσ
γσ
Z 1/γ (t)S(t)  g(X(t), t)X(t)
∂g
α1 (t) =
− σx
H1 (X(t), T − t)σ
γ
∂X

g(X(t), t)
+σx
(A1 (T − t, γ)X(t) + A2 (T − t, γ))
γ
α0 (t) =

The proof is in Appendix D. We refer to Gatto and Schellhorn (2021) for a
discussion of α0 . The sign of α1 is determined by the signs of σ and

g(X(t), t) 
∂g
X(t) + σx (A1 (T − t, γ)X(t) + A2 (T − t, γ)) − σx
(16)
γ
∂X
More specifically, α1 is positive if σ and (16) are both positive or negative. α1
is negative if one of them is positive and the other one is negative.
∂g
It is obvious that the magnitude of both g(X(t), t) and ∂X
decrease with time
and are equal to zero when t = T . Therefore, the importance of α1 decreases
as time increases.
To further discuss the sign of (16), we rewrite it by


σx A2 (T − t, γ)
∂g
g(X(t), t)
(1 + |σx A1 (T − t, γ)|) X(t) + X̄
+ |σx |
γ
∂X
X̄
8

∂g
Thus, suppose ∂X
, X(t), and X̄ are all positive, (16) is positive, and vice versa.
In the following cases, we provide two simple cases that we can easily discuss
the sign of α1 :

• if

∂g
∂X σ

> 0, µ − µ1 > max(K1 (t), k̄1 ), then α1 is positive.

• if

∂g
∂X σ

< 0, µ − µ1 < min(K1 (t), k̄1 ), then α1 is negative.

In the following, we discuss the full expansion of the solution in Theorem 3.
Consider equation (57) in Gatto and Schellhorn (2021):
∂

+ L1 + εL2 f = 0
∂t
This time we use full asymptotic expansion:
f = f1 + εf2 + . . . =

∞
X

fi εi−1

i=1

and obtain:
0

∞ 


∂

X
∂
+ L1 f1 +
+ L1 fi+1 + L2 fi εi
∂t
∂t
i=1

=

The terms of our asymptotic expansion are thus determined by:

∂
+ L1 f1 = 0
∂t
∂

+ L1 fi+1 = −L2 fi
i = 1, 2, . . .
∂t

(17)
(18)

We use the Ansatz:
fi (Z(t), X(t), t) = Z(t)2

i−1

/γ

i−1

S(t)2

−1

gi (X(t), t)

i = 1, 2, . . .

We have showed that g1 = H1 and g2 = g in the proof of Theorem 3. By the
same process, we can also calculate the expressions for g3 , g4 , . . . in the sequel.

4.2

Constant Treatment Rate

The problem is:
 I(T )1−γ 
sup E −
1−γ
p
dS(t) = −βS(t)I(t)dt + σS S(t)I(t)dB1 (t)
dI(t) = (r + α(t)(b − r))I(t)dt + α(t)σI(t)dB2 (t) − σS

(19)
p

S(t)I(t)dB1 (t)

Let τ = T − t, the solution kernels hi (τ ) for i = 1, 2, . . . are given by:
hi (τ ) = exp

 2i−1  a

i,1

γ

2
9

 
b − r 2
+ ai,2 τ
σ

(20)

where
ai,1

=

1 − γ/2i−1
γ/2i−1

(21)

ai,2

=

(γ/2i−1 − 1)µ

(22)

Theorem 4. Let I(0) = ε, then the problem (19) has a solution such that
I(t) =

∞
X

i−1

Z(t)2

/γ

i−1

S(t)2

−1

gi (t)εi

i=1

where g1 (t) = h1 (T − t), gi (t), i > 1 can be obtained by (44), and Z(t) satisfies:
√

b − r 2 β 2 SI 
β SI
b−r
dZ
= −µ+
+
dt −
dB2
dB1 +
Z
σ
σS2
σS
σ
∞
X
i−1
i−1
Z(0)2 /γ S(0)2 −1 gi (0)εi−1
1=
i=1

Moreover the optimal proportion undergoing treatment α∗ (t) equal to α0 (t) +
εα1 (t) + O(ε2 ), where α0 (t) and α1 (t) are equal to
α0 =

b−r
γσ 2

α1 =

Z 1/γ (t)S(t) b − r
h1 (T − t)g2 (t) γσ 2

The proof is in Appendix E, where we also provide a formula for g3 . Observe
that
g2 (t) =

β2
2σS2

h2 (T

b−r 2
(a1,1
σ

− t) − h21 (T − t)
− a2,1 ) + 2(a1,2 − a2,2 )

=

β 2 h2 (T − t) − h21 (T − t)
2
2σS2
γµ − b−r
/γ
σ

is always positive because the signs of h2 (T − t) − h21 (T − t) and γµ − b−r
σ
are the same. The signs of α0 and α1 are determined by the sign of r−b
σ2 .

5

2

/γ

Application to COVID-19

We use the same data set and parameters (see Table 1) as in Gatto and Schellhorn (2021), but this time we show the optimal control (result of Theorem 2)
of problem (6). We compare in Figure 2 three types of treatment:
• no treatment
• full control, i.e., α(t) = 1
• optimal control, given in Theorem 2
We can see that, for all risk-aversion parameters γ considered (between −1 and
−5), our control is better.
10

Treatment Parameter
Death rate/no treatment
Death rate
Recovery rate/ no treatment
Recovery rate at time 0
Long run value of recovery rate
Volatility of the measurement of today’s recovery rate
Volatility of changes in the recovery rate
Speed of mean-reversion of the recovery rate
Transmission rate
Proportion of infected at time 0
Time step

Symbol
µ0
µ1
K0
K1 (0)
k̄1
σ
σk
λk
β
ε
∆t

Value
0.0575
0.0575
0.2559
0.2559
0.4612
0.4418
-1.1647
0.7692
0.025
0.01
0.001

Table 1: Parameters

Figure 2: Optimal control of low infection with constant treatment. Weekly US
COVID-19 data from June 7, 2020 to November 1, 2020. Github repository for
generating the plot: https://github.com/yujiading/optimal-control-sir-model.

11

6

Conclusion

We showed that a stochastic optimal control approach enables to fight the
COVID-19 epidemic better. Many interesting problems remain to be solved.
For instance, we could analytic constrained policies in the multiple treatment
case or the Ornstein-Uhlenbeck case. Optimal vaccination is another area where
we believe a similar asymptotic approach can be used. Finally, Bertozzi et al.
(2020) use Hawkes processes to model COVID-19. The control of Hawkes processes remains a largely open problem that deserves attention, in particular for
its application to epidemiology.

Appendix A

Proof of Theorem 1

We follow the proof in Karatzas and Shreve (2014, Prop. 2.13, Sec. 5.2). They
consider the one-dimensional case. Let h : [0, ∞) → [0, ∞) be a strictly increasing function with h(0) and
Z
h−2 (u) = ∞, ∀ε > 0
(23)
(0,ε)

In our case, we take h(x) = x. Because of (23), there exists a strictly
decreasing
Ra
sequence {an } ⊂ (0, 1] with a0 and limn→∞ an = 0 such that ann−1 h−2 (u)du =
n. For every n there exists continuous function ρn on R with support on
(an , an−1 ) so that
2
, x>0
0 ≤ ρn (x) ≤
nh(x)
R an
and an−1
ρn (u)du = 1. Then the function
Z

|x|

Z

Ψn (x) =

y

ρn (u)dudy
0

0

is even and twice continuously differentiable, with |Ψ0n (x)| ≤ 1 and limn→∞
Ψn (x) = |x|. Suppose there are two strong solutions (I (1) , S (1) ) and (I (2) , S (2) ),
d(I (1) − I (2) − E[I (1) − I (2) ]) − ασ(I (1) − I (2) )dB2

p
p
S (1) I (1) − S (2) I (2) dB1
= −σS
= −d(S (1) − S (2) − E[S (1) − S (2) ])
so that
(d(I (1) − I (2) ))2 < σS2 (S (1) I (1) − S (2) I (2) )dt + (ασ)2 (I (1) − I (2) )2 dt
(d(S (1) − S (2) ))2 < σS2 (S (1) I (1) − S (2) I (2) )dt
d((I (1) − I (2) )(S (1) − S (2) )) < −σS2 (S (1) I (1) − S (2) I (2) )dt

12

Thus, since |Ψ0n | < 1,
(1)

E[dΨn (It

(2)

(1)

− It ) + dΨn (St
(1)

(2)

− St )]

(2)

(1)

(2)

= E[Ψ0n (It − It )(d(I (1) − I (2) )) + Ψ0n (St − St )(d(S (1) − S (2) ))]
1
(1)
(2)
+ E[Ψ00n (It − It )(d(I (1) − I (2) ))2 ]
2
1
(1)
(2)
+ E[Ψ00n (St − St )(d(S (1) − S (2) ))2 ]
2
≤ E[2|β||S (1) I (1) − S (2) I (2) |dt + |D||I (1) − I (2) |dt]
1
(1)
(2)
+ E[Ψ00n (It − It )σS2 (S (1) I (1) − S (2) I (2) )dt]
2
1
(1)
(2)
+ E[Ψ00n (St − St )σS2 (S (1) I (1) − S (2) I (2) )dt]
2
1
(1)
(2)
+ E[Ψ00n (It − It )(ασ)2 (I (1) − I (2) )2 ]dt
2
where
D = −(K0 + µ0 ) + α(K0 − K1 + µ0 − µ1 )
Observe that:
S (1) I (1) − S (2) I (2)

= S (1) (I (1) − I (2) ) + I (2) (S (1) − S (2) )
< |I (1) − I (2) | + |S (1) − S (2) |

Since Ψ00n < 2/nh and h is positive,



(1)
(2)
(1)
(2)
Ψ00n (It − It ) + Ψ00n (St − St ) S (1) I (1) − S (2) I (2)


2
1
1
<
+
(|I (1) − I (2) | + |S (1) − S (2) |)
n h(|I (1) − I (2) |) h(|S (1) − S (2) |)


2
|I (1) − I (2) |
|S (1) − S (2) |
<
+
n h(|I (1) − I (2) |) h(|S (1) − S (2) |)
Taking h(x) = x results in
(1)

(2)

(1)

(2)

E[dΨn (It − It ) + dΨn (St − St )]

< E[(2|β| + |D|)|I (1) − I (2) |] + E[2|β||S (1) − S (2) |]

(ασ)2
2σ 2
E[|I (1) − I (2) |] dt
+ S +
n
2
Since limn→∞ Ψn (x) = |x|,
(1)

(2)

(1)

− It | + |St

E[|It

Z
<

(2)

− St |]

t

E[(2|β| + |Ds |)|Is(1) − Is(2) |] + E[2|β||Ss(1) − Ss(2) |]

0

+

(αs σ)2
E[|Is(1) − Is(2) |]ds
2
13

But,
|Ds |)|Is(1)

p

|)2 ]

q
(1)
(2)
E[|Is − Is |2 ]

E[(2|β| + |Ds
q
(1)
(2)
(1)
(1)
(2)
(1)
(2) 2
Since |Is − Is | < 1, E[(Is − Is ) ] < 1 and E[(Is − Is )2 ] < E[|Is −
E[(2|β| +

−

Is(2) |]

<

(2)

Is |] thus
(1)

(2)

(1)

(2)

− It | + |St − St |]

Z t p
(ασ)2
2
E[(2|β| + |Ds |) ] +
E[|Is(1) − Is(2) |]
<
2
0

E[|It

+ 2|β|E[|Ss(1) − Ss(2) |]ds


Z t
p
(ασ)2
2
E[(2|β| + |Ds |) ] +
, 2|β|
<
max
2
0
× E[|Is(1) − Is(2) | + |Ss(1) − Ss(2) |]ds
and local uniqueness follows by Gronwall’s inequality.

Appendix B

Proof of Theorem 2

We refer to the problem treated by Gatto and Schellhorn (2021) as the unconstrained problem. Indeed, in that problem α was not constrained. We refer
to our problem as the constrained problem. We follow the method of proof
in Cvitanić and Karatzas (1992), referred to hereafter as CK. They introduce
auxiliar y problems, which are unconstrained. They show that there exists an
auxiliary problem which solution can be used to construct the solution of the
original constrained problem. We follow the numbering of the sections in CK
in order to ease understanding.
CK Section 2. The Model. To ease the correspondence with the CK paper,
we define b − r = K0 + µ0 − µ1 − k̄1 , θ := (b − r)/σ, and
Z
 Z t
1 t 2 
(0)
H (t) = exp(−rt) exp −
θdB2 (s) −
θ ds
2 0
0
Rt
Observe that E[ 0 θ2 ds] < ∞.
CK Section 3. Portfolio and consumption processes.
Z t
(0)
B2 (t) = B2 (t) +
θds

Define:

0

Denote by I i,α the infected process subject to I(0) = i and control α. It is
admissible if
0 ≤ I i,α (t) ≤ 1 ∀ 0 ≤ t ≤ T
14

The set of admissible α is denoted A0 (i). Note that (See (3.5) in CK)
H (0) (t)I(t) = i +

t

Z

H (0) (s)I(s)(α(s)σ − θ)dB2 (s)

0

CK Section 4. Convex sets and their support functions. The difference
between CK and this paper is that our objective is to minimize. This means
that the key relation between our auxiliary infected and infected is reversed
compared to the first equation in CK. Indeed if αν solves the auxiliary problem
and α the original problem, we must have:
Iνi,αν (t) ≤ I i,α (t)
Define


δ(ν) =

0
ν

ν<0
ν>0

(24)

It is subadditive:
δ(λ + ν) ≤ δ(λ) + δ(ν)

(25)

CK Section 5. Utility functions. The main difference between our utility
functions and the utility functions in financial economics is that our utility
functions are decreasing for positive arguments. Recall indeed that our utility
function is, for γ < 0:
i1−γ
U (i) = −
1−γ
Since
U 0 (i) = −i−γ
We have limi→∞ U 0 (i) = −∞ and limi→0 U 0 (i) = 0, again for γ < 0. This is
unlike CK and Wachter (2002) who consider the case 0 < γ < 1 with utility of
1−γ
wealth U2 (x) = x1−γ . In their case, limx→∞ U20 (x) = 0 and limx→0 U20 (x) = ∞.
We define I2 to be the inverse of U 0 , with I2 (y) on y ≤ 0. By straighforward
calculations:
I2 (y) = (−y)−1/γ
We also define the Legendre-Fenchel dual
Ũ (y) = max[U (x) − xy] = U (I2 (y)) − yI2 (y)
x>0

This function satisfies:
Ũ 0 (y) = −I2 (y) y ≤ 0

15

CK Section 6. The constrained and unconstrained optimization problems. We define:
A0 (i) = {α ∈ A0 (i)|0 ≤ α ≤ 1}
The supremum of the unconstrained problem is denoted by V0 , while the supremum of the constrained problem is denoted by V , namely:
V0 (i)

=

sup E[U (I i,α (T ))|I(0) = i]
α∈A0 (i)

V (i)

=

sup E[U (I i,α (T ))|I(0) = i]

α∈A0 (i)

CK Section 7. Solution of the unconstrained problem.
the expectation
X0 (y) ≡ E[H (0) (T )I2 (yH (0) (T ))]

We note that

is finite for every y ∈ (−∞, 0]. We define its inverse Y0 :
Y0 (X0 (y)) = y
The solution of the unconstrained problem is well-known, and equal to:
α(s) =

r−b
θ
= 2
σγ
σ |γ|

CK Section 8. Auxiliary unconstrained optimization problems. Recall δ(ν) in (24). It is easily seen that:


αν
ν<0
αν − δ(ν) =
≤0
(α − 1)ν ν > 0
We introduce a new process I (ν) by:
dI (ν) (t)
(0)
= (r + α(t)ν(t) − δ(ν(t)))dt + α(t)σdB2 (t)
I (ν) (t)
Likewise we introduce
θ(ν) = θ + ν/σ
Z

t

θ(ν) (s)ds
Z t

  Z t

(ν)
H (t) = exp − rt +
δ(ν(s))ds E −
θ(ν) (s)dB2 (s)
0
0
Z
 Z t

 Z t

1 t (ν)
(ν)
(ν)
E −
θ (s)dB2 (s) ≡ exp −
θ (s)dB2 (s) −
(θ (s))2 ds
2 0
0
0

B

(ν)

(t) = B2 (t) +

0

We denote by A0ν (i) the class of α for which
Iνi,α (t) ≤ 1
16

Since the solution of our dual problem will have α(t)ν(t) − δ(ν(t)) ≤ 0,
clearly A0 (i) ⊂ A0ν (i). We define:
sup E[U (I i,α (T ))]

Vν (i) =

π∈A0ν (i)

Xν (y) ≡ E[H (ν) (T )I2 (yH (ν) (T ))]
We define a class of progressively measurable processes ν in R by:
Z
n
D0 = ν; E

T

Z
δ(ν(t))dt ≤ ∞, E

ν 2 (t)dt < ∞, Xν (y) < ∞, y ∈ (−∞, 0]

o

0

Proposition 8.3. in CK shows that, if for some λ ∈ D0 the corresponding
control αλ is optimal for the auxiliary optimization problem and if
−δ(λ) + αλ (t)λ(t) = 0
then α ∈ A0 (i) and is optimal for the constrained problem.
The solution of the unconstrained problem is:
α(s) =

θ + ν/σ
r−b−ν
θ(ν)
=
=
σγ
σγ
σ 2 |γ|

(26)

CK Section 9. Contingent claims attainable by constrained portfolios.
We sketch the proof of theorem 9.1 in CK, as the signs are different, and the
structure of the control is slightly different.
CK 9.1 Theorem. Let B be a positive FT -measurable random variable and
suppose there is a process λ ∈ D0 such that, for all ν ∈ D0
E[H (ν) (T )B] ≤ E[H (λ) (T )B] := i

(27)

Then there exists a control α ∈ A0 (i) such that I i,α = B.
Sketch of Proof. See CK p.782 for a definition of the stopping time τn . By (27)
and subadditivity of δ (25):
0

≤
=

1
lim sup E[(H (λ)(T ) − H (λ+ε(ν−λ)) (T ))B]
ε↓0
ε


1 h (λ)
lim sup E H (T )B 1 − exp
ε↓0
ε
Z T ∧τn
(δ(λ(t) + ε(ν(t) − λ(t))) − δ(λ(t))) dt
0

Z

T ∧τn

(λ)

(−θ(λ) (t) + θ(λ+ε(ν−λ)) (t))dB2 (t)
0
h
i
≤ lim sup E H (λ) (T )B(LT + NT )
×E

ε↓0

17

i

where
δ̆

(ν)


(λ(t)) =

δ(λ(t))
ν=0
−δ(ν(t) − λ(t)) otherwise

T ∧τn

Z

δ̆ (ν) (λ(t))dt

LT =
0
T ∧τn

Z
NT =
0

ν(t) − λ(t) (λ)
dB2 (t)
σ

By Ito’s lemma.
d[H (λ) (t)I(t)(Lt + Nt )] = I(t)H (λ) (t)d(Lt + Nt )
(λ)

+ (Lt + Nt )H (λ) (t)I(t)α(t)σdB2 (t) + I(t)H (λ) (t)α(t)(ν(t) − λ(t))dt
which implies
H (λ) (T )I(T )(LT + NT )
Z τn

 ν(t) − λ(t)
(λ)
+ (Lt + Nt )σα(t) dB2 (t)
=
I(t)H (λ) (t)
σ
0
Z τn


+
H (λ) (t)I(t) α(t)(ν(t) − λ(t))dt + dLt
0

Therefore,
hZ
0 ≤ E[H (λ) (T )B(LT + NT )] = E

τn


i
H (λ) (t)I(t) α(t)(ν(t) − λ(t))dt + dLt

0

It is easy to see that, for any ρ ∈ D0 , take ν = λ + ρ:
− δ(ρ(t)) + α(t)ρ(t) ≥ 0

(28)

and, taking ν(t) = 0, we obtain:
−δ(λ(t)) + α(t)λ(t) ≤ 0
which together with (28) for ρ = λ yields:
−δ(λ(t)) + α(t)λ(t) = 0

CK Section 10. Equivalent optimality conditions. The most important
implication to prove is (D)⇒(B)⇒(A) in CK. It shows that the solution of the
dual problem solves the auxiliary problem, and that, moreover, it is feasible and
optimal for the original constrained problem. We make it more explicit here.

18

(Part of ) CK 10.1 Theorem. Suppose that for every ν ∈ D0 ,
E[Ũ (Yλ (i)H (λ) (T ))] ≤ E[Ũ (Yλ (i)H (ν) (T ))]

(29)

then there exists a control αλ ∈ [0, 1] that is optimal for the constrained problem
Vλ (i) = E[U (I i,αλ (T ))] and such that
Vλ (i) = V (i)
Proof.
E[Ũ (Yλ (i)H (λ) (T ))] ≤ E[Ũ (Yλ (i)H (λ+ε(ν−λ)) (T ))]
Since Ũ 0 (y) = −I2 (y),
0

≤
=

1
lim sup E[Ũ (Yλ (i)H (λ+ε(ν−λ)) (T )) − Ũ (Yλ (i)H (λ) (T ))]
ε↓0
ε
1
Yλ (i) lim sup E[I2 (Yλ (i)H (λ) (T ))(H (λ) (T ) − H (λ+ε(ν−λ)) (T ))
ε↓0
ε

By theorem 9.1 there exists a control αλ ∈ A0λ (i) such that:
I i,αλ (T ) = I2 (Yλ (i)Hλ (T ))
Clearly αλ is optimal for the constrained problem, and
−δ(λ) + αλ (t)λ(t) = 0
Thus by proposition 8.3, αλ is optimal for the constrained problem.
CK Section 12. A dual problem. Define:
V̂ (y) = inf 0 E[Ũ (yHν (T ))]
ν∈D

In our case,
 x1−γ

Ũ (y) = max −
− xy
x>0
1−γ
Thus
y = U 0 (x) = −x−γ =⇒ I2 (y) = (−y)−1/γ
Let ρ = (1 − γ)/γ. Then:
Ũ (y) = −(−y)−ρ /ρ
Typically, γ = −1, so that:
Ũ (y) = y 2 /2
The main problem in condition (29) is to find the optimal process H (λ)
(across all H (ν) ) but it depends on y which depends on λ. Thus the dual must
be fixed for a fixed but arbitrary real number y. The objective has the form
E[Ũ (yH (ν) (T ))] = E[U (I2 (yH (ν) (T ))) − yH (ν) (T )I2 (yH (ν) (T ))]
19

The right handside of the equation (see Korn (1997, p.134)) is the maximum
of the function h(B, y) := L(B, y) for all non-negative FT measurable B with
E[H (ν) (T )B] ≤ i. Thus a minimization over all positive numbers y of h(B, y)
would yield the optimal utility of the unconstrained problem. We could thus
first minimize E[Ũ (yH (ν) (T ))] in y, and then minimize over ν. However, the
main idea is to first minimize over µ, and then minimize over y, hoping that the
two can be interchanged.
CK 12.1 Proposition. Suppose that for any y there exists λy such that V̂ (y) =
E[Ũ (yH (λy ) (T ))]. Then there exist an α ∈ A0 (i) with i = Xλy (y) which is optimal
for the primal problem, and we have:
V̂ (y) = sup[V (i) − iy]
i

Proof. Write λ for λYλ (i) . Then
E[Ũ (Yλ (i)H (λ) (T ))] ≤ E[Ũ (Yλ (i)H (ν) (T ))]
and we conclude by CK Theorem 10.1.
CK Section 15.
Define:

Deterministic coefficients and feedback formulae.
Q(y, t) = E[Ũ (yH (ν) (T ))|yH (ν) (t) = y]

Recall
dH (ν)
= (−r + δ(ν))dt − (θ + ν/σ)dB2
H (ν)
The HJB equation is:
1
min y 2 (θ + ν/σ)2 Qyy + y(−r + δ(ν))Qy + Qt = 0
ν 2
(−y)−ρ
Q(T, y) = Ũ (y) = −
ρ
Again, with ρ = (1 − γ)/γ < 0. We choose
1
Q(y, t) = − (−y)−ρ v(t)
ρ
Thus
1 2
y (θ + ν/σ)2 Qyy + y(−r + δ(ν))Qy
2
1
= − (ρ + 1)(−y)−ρ v(t)(θ + ν/σ)2 + (−r + δ(ν))(−y)−ρ v(t)
2
Dividing by (−y)−ρ v(t), the problem becomes:
argmin −
ν

1+ρ
(θ + ν/σ)2 + δ(ν)
2
20

(30)

Recall that if ν is positive, then δ(ν) = ν thus we solve (30) and obtain
ν=

σ2
+ r − b = −σ 2 |γ| + r − b
1+ρ

since 1 + ρ = 1/γ and γ is negative. If ν is negative, then δ(ν) = 0, thus
ν = r − b.
From (26), the solution is
α(s) =


 r − b 
r−b−ν
=
min
1,
max
0, 2
σ 2 |γ|
σ |γ|

Suppose µ0 = µ1 and treatment is better than no treatment k̄1 > K0 . Thus
r − b = k̄1 − K0 is positive. Thus

 k̄ − K 
1
0
α(s) = min 1, max 0,
σ 2 |γ|

Appendix C
Z

τ



A3 (τ, γ) =
0


σ2
σx2
+ λx X̄ A22 (s, γ) + x A1 (s, γ) + (γ − 1)µds
2γ
2

2λx X̄b2 (γ)A2 (τ, γ) 2X̄ 2 λ2x
A1 (τ, γ)
+ 3
−
2γ
θ3 (γ)b3 (γ)
θ (γ)
b3 (γ)


2θ(γ)−(θ(γ)+b2 (γ))(1−e−θ(γ)τ )
p
8b21 (γ)τ log
2θ(γ)
b2 (γ)(θ(γ) − 2 b1 (γ)b3 (γ))
p
+
+
θ(γ)b23 (γ)
(b2 (γ) − θ(γ)) b1 (γ)b3 (γ)
p
p
b2 (γ) − 2 b1 (γ)b3 (γ)
2b2 (γ) + 4 b1 (γ)b3 (γ)e−θ(γ)τ /2

× log
θ(γ)
2θ(γ) − (b2 (γ) + θ(γ)) 1 − e−θ(γ)τ
!!

(b2 (γ) + θ(γ))A1 (τ, γ)
4b21 (γ)τ
−
+
2b1 (γ)
(b2 (γ) + θ(γ))2
!
!
1
2θ(γ)e−θ(γ)τ
2b1 (γ)τ
σx2
 −
log
+
2 b3 (γ)
b2 (γ) + θ(γ)
2θ(γ) − (b2 (γ) + θ(γ)) 1 − e−θ(γ)τ


=

σx2

Explicit Formula of A3 (τ, γ) in (12)



+ λx X̄

+(γ − 1)µτ

Appendix D

Proof of Theorem 3

We following the proof of Proposition 2 in Gatto and Schellhorn (2021). Recall
the equations (58) (59) in Gatto and Schellhorn (2021) and following same

21

notations:
∂

+ L1 f1 = 0
∂t
∂

+ L1 f2 = −L2 f1
∂t

(31)
(32)

where L1 , L2 are equations (53) (54) in Gatto and Schellhorn (2021).
Solution of (31) We postulate that:
f1 (Z, X, t) = Z 1/γ H1 (X, T − t)
Substitution in (31) shows that H1 solves:

∂
+ Lγ H1 = 0
∂t
H1 (X, 0) = 1

(33)

where the operator Lγ is defined by:
Lγ H

≡


 ∂H
1 2 ∂ 2 H  γ − 1
σx
+
σ
−
λ
X
+
λ
X̄
x
x
x
2 ∂X 2
γ
∂X
 1 1 1




1
+ X2
−1 +µ 1−
H
2γ γ
γ

Using the Ansatz (9), we can rewrite the LHS of (33) into:
(C1 (t)X 2 + C2 (t)X + C3 (t))H1 /γ = 0
Clearly all terms C1 , C2 , C3 must be identically zero. Thus:

σ2
γ−1
1−γ
dA1 (t, γ)
= x A21 (t, γ) + 2
σx − λx A1 (t, γ) +
dt
γ
γ
γ

dA2 (t, γ)
σx2 A1 (t, γ)
γ−1
=
A2 (t, γ) +
σx − λx A2 (t, γ) + λx X̄A1 (t, γ)
dt
γ
γ
dA3 (t, γ)
σ2
A2 (t, γ) 
= x A1 (t, γ) + 2
+ λx X̄A2 (t, γ) − µ(1 − γ)
dt
2
γ
which admit the solutions (10),(11),(12).
Solution of (32) The second equation can be rewritten
∂

1 β 2 2/γ
+ L1 f2 =
Z SH1 (X, T − t)2
∂t
2 γσS2

(34)

We try the Ansatz:
f2 (Z(t), X(t), t) = Z(t)2/γ S(t)g(X(t), t)
22

(35)

Thus
∂

1 β2
+ Lγ/2 g(X, t) =
H1 (X, T − t)2
∂t
2 σS2 γ
g(X, T ) = 0
We use Lemma to obtain the g(X, t) in (15).
The optimal policy is:


∂F
∂F
1
XZ −
σx = α0 + εα1 + O(ε2 )
α∗ =
σF ∂Z
∂X
where
α0

=
=

α1

=
=

∂f1 XZ
∂f1 σx
−
∂Z σf1
∂X σf1
X(t)
σx
−
(A1 (T − t, γ)X(t) + A2 (T − t, γ))
γσ
γσ



∂f1 f2
∂f1 f2
∂f2
σx ∂f2
−
−
−
∂Z
∂Z f1
σf1 ∂X
∂X f1

1/γ
g(X(t), t)X(t)
∂g
Z (t)S(t)
− σx
H1 (X, T − t)σ
γ
∂X

g(X(t), t)
(A1 (T − t, γ)X(t) + A2 (T − t, γ))
+σx
γ
XZ
σf1



Lemma 5. Let u(x, t) =

2
1 β
2 γ H1 (x, T
2 σS

− t)2 . The solution to

∂g(x, t)
+ Lγ/2 g(x, t) = u(x, t)
∂t
g(x, T ) = 0

(36)

is in (15).
Sketch of Proof. The solution g(x, t) is the price of a variable-coupon bond in
an affine model. The building block is the solution of a zero-coupon bond in the
similar model. Define m(x) and r(x) to be such that:
∂f (x, t)
1 ∂ 2 f (x, t)
+ m(x)
− r(x)f (x, t)
Lγ/2 f (x, t) = σx2
2
∂x2
∂x
 γ/2 − 1

m(x) =
σx − λx x + λx X̄
γ/2
 1 2

2 
r(x) = − x2
−1 +µ 1−
γ γ
γ
Let f (x, t) be the solution of:
∂f (x, t) 1 2 ∂ 2 f (x, t)
∂f (x, t)
+ σx
+ m(x)
= r(x)f (x, t)
∂t
2
∂x2
∂x
23

(37)

Defining:
dX(t) = m(X)dt + σx dW (t)

(38)

we see that:
∂f (x, t) 1 2 ∂ 2 f (x, t)
∂f (x, t)
+ m(x)
+ σx
= E[df (X, t)|X(t) = x]/dt
∂t
2
∂x2
∂x

(39)

Thus (37) can be rewritten:
E[df (X(t), t) − r(X(t))f (X(t), t)dt|X(t)] = 0
Rt
Using the integrating factor exp(− 0 r(X(s)ds), we have:
Z

t

r(X(s))ds)f (X(t), t))|X(t)] = 0

E[d(exp(−
0

Under the boundary condition f (X(T ), T ) = 1 the only possible solution is:
Z T
f (x, t; T ) = E[exp(−
r(X(s))ds)|X(t) = x]
t

Define P (t, T ) = f (X(t), t; T ) = H2 (X(t), T − t) to be the price of a discount
bond with a maturity of T . Clearly:
dP (t, T )
= r(X(t))dt + v(t, T )dW (t)
P (t, T )
where:

∂f

v(t, T ) = σx ∂x
f
By Ito’s lemma, and for the exact same reason as (39):
∂g(x, t) 1 2 ∂ 2 g(x, t)
∂g(x, t)
+ σx
+ m(x)
= E[dg(X, t)|X(t) = x]/dt
2
∂t
2
∂x
∂x
The stochastic equivalent of (36) is:
E[dg(X(t), t) − r(X(t))g(x, t)dt|X(t)] = E[u(X(t), t)dt|X(t)]
The solution is:
Z

T

g(X(t), t) =

Q(t, τ )dτ
τ =t

where:

Z
Q(t, τ ) = E[exp(−

τ

r(X(s))ds)u(X(τ ), τ )|X(t)]
t

Clearly, for some volatility σQ (t, τ )
dQ(t, τ )
= r(X(t))dt + σQ (t, τ )dW (t)
Q(t, τ )
24

We are now ready to define a change of numeraire. Let
dW τ = dW − v(t, τ )dt
By Theorem 9.2.2. in Shreve (2004), Q(t, τ )/P (t, τ ) is a Pτ -martingale, i.e.,
Q(t, τ ) = P (t, τ )Eτt [u(X(τ )]
where
dX(t)

= m(X)dt + σx dW (t)
= m(X)dt + σx (dW τ (t) + v(t, τ )dt)

From (9),
u(X(t), t) =

1 β 2 γ2
e
2 σS 2 γ



A1 (T −t,γ)
X(t)2 +A2 (T −t,γ)X(t)+A3 (T −t,γ)
2



Let us now take:

 2  A (T − t, γ/2)
1
X 2 (t) + A2 (T − t, γ/2)X(t) + A3 (T − t, γ/2)
P (t, T ) = exp γ
2
Thus:
v(t, τ ) =

σx
γ

(A1 (τ − t, γ/2)X(t) + A2 (τ − t, γ/2))

γ
2


−1
σ2
σx − λx + γx A1 (τ − t, γ/2) X(t) + λx X̄
γ/2
i
σ2
+ γx A2 (τ − t, γ/2) dt + σx dW τ (t)

h
dX(t) =

(40)

Thus Eτt [u(X(τ ))] when (40) holds can be calculated exactly the same way
as E[u(X(τ ))] when (38) holds. The structure is also affine, and there will be a
solution of the form:
 

1 β 2 τ γ2 A1 (T2−τ,γ) X 2 (τ )+A2 (T −τ,γ)X(τ )+A3 (T −τ,γ)
Eτt [u(X(τ ), τ )] =
Et e
2 σS 2 γ
To summarize, since P (t, T ) = H2 (X(t), T − t)
Z

T

g(x, t) =

P (t, τ )Eτt [u(X(τ ), τ )]dτ

τ =t
Z T

H2 (X, τ − t)

=
τ =t

1 β2
2 σS 2 γ

  A (T −τ,γ)

2
1
X 2 (τ )+A2 (T −τ,γ)X(τ )+A3 (T −τ,γ)
τ
γ
2
dτ
Et e

25

(41)

Let M̃ (t, τ ) as in (14) and
Y (τ ) = X(τ ) +

A2 (T − τ, γ)
A1 (T − τ, γ)

Clearly:
Z

τ

τ

E [X(τ )|X(t) = x] = xM̃ (t, τ ) +
M̃ (s, τ )(λx X̄ +
s=t
Z τ
M̃ 2 (s, τ )ds
Varτ [X(τ )|X(t) = x] = σx2

σx2
γ

A2 (τ − s, γ))ds

t

Thus we can calculate:
mY (τ, x) = Eτ [Y (τ )|X(t) = x]
A2 (T − τ, γ)
A1 (T − τ, γ)
Z τ
τ
2
M̃ 2 (s, τ )ds
VY (τ, x) = Var [Y (τ )|X(t) = x] = σx
= Eτ [X(τ )|X(t) = x] +

t

We can further develop:
i
h
 2  A (T − τ, γ)
1
Eτt exp
X 2 (τ ) + A2 (T − τ, γ)X(τ ) + A3 (T − τ, γ)
γ
2




A2 (T −τ,γ)
A2 (T −τ,γ) 2
2
1
− γA2 (T −τ,γ)
τ
γ A3 (T −τ,γ)+ γ A1 (T −τ,γ) X(τ )+ A1 (T −τ,γ)
1
= Et e


 
A2 (T −τ,γ)
A1 (T −τ,γ)
A (T −τ,γ) 2
2
X(τ )+ A2 (T −τ,γ)
A (T −τ,γ)− γA2 (T −τ,γ)
γ
1
1
= Eτt e γ 3
e
Z
A2 (T −τ,γ)
(y−m (τ,x))2
A1 (T −τ,γ) 2
2
1
A (T −τ,γ)− γA2 (T −τ,γ)
y − 2VYY(τ,x)
γ
1
p
e
dy
= eγ 3
e
2πVY (τ, x)
2

= eγ

m2
A2 (T −τ,γ)
Y (τ,x)A1 (T −τ,γ)
+ γ−2V
1 (T −τ,γ)
Y (τ,x)A1 (T −τ,γ)

A3 (T −τ,γ)− γA2

1
p
1 − 2VY (τ, x)A1 (T − τ, γ)/γ

providing γ < 2A1 (T − τ, γ)VY (τ, x). Thus equation (15) follows from equation
(41).

Appendix E

Proof of Theorem 4

When X(t) is a constant, equations (53) and (54) in Gatto and Schellhorn (2021)
become
1 2 b − r 2 ∂ 2 F
∂F
Z
− µZ
+ µF
2
2
σ
∂Z
∂Z
1 β2
∂F
L2 F = − 2 ZSF
2 σS
∂Z
L1 F =

26

Use the Ansatz f1 (Z(t), t) = Z 1/γ (t)h1 (T − t) and insert in (17) shows that h1
solves:


∂
+ Lγ h1 = 0
h1 (0) = 1
(42)
∂t
where the operator Lγ is defined by:
Lγ H

 b − r 1 1 1

1 
2
H
−1 +µ 1−
σ
2γ γ
γ

≡

Using the Ansatz (20), we can rewrite (42) into:


C1 (t)


b − r 2
+ C2 (t) h1 /γ = 0
σ

Clearly all terms C1 , C2 must be identically zero. Thus
1−γ
da1,1 t
=
dt
γ

da1,2 t
= µ(γ − 1)
dt

which admit the solutions (21), (22) at i = 1.
i−1
i−1
Now use fi (Z(t), t) = Z 2 /γ (t)S 2 −1 (t)gi (t). We can rewrite (18) by


i
∂
1 β 2 2i−1 2
+ Lγ/2 gi+1 (t) =
g (t)
gi+1 (T ) = 0
(43)
∂t
2 σS2 γ i
Let u(t) =

2 i−1
1β 2
2
2 γ gi (t)
2 σS

ri =

and

2i  1 b − r 2
ai+1,1 + ai+1,2
γ 2 σ

Then

i

Lγ/2 gi+1 (t) = ri gi+1 (t)
and the stochastic equivalent of (43) is:
∂gi+1 (t)
+ ri gi+1 (t) = u(t)
∂t

gi+1 (T ) = 0

which admits
1 β 2 2i−1
1
gi+1 (t) = −
2
2 σS γ hi+1 (t)

Z

T

gi2 (s)hi+1 (s)ds

(44)

t

We have showed that g1 = h1 (T − t). Here we also provide the g2 and g3 in the
following:
g2 (t)

=

β2
2σS2

h2 (T − t) − h21 (T − t)

b−r 2
(a1,1 − a2,1 ) + 2(a1,2 − a2,2 )
σ
27

β6
g3 (t) = −
16σS6

h22 (T )


b−r 2
(a1,1 − a2,1 )
σ
h3 (T )
h3 (t)
− h2 (t)
h22 (T )
2

a3,1 −a2,1 b−r 2
+
a3,2 − a2,2
2
σ

h2 (T )
−2 2
h1 (T )

h3 (T )h21 (T )
h2 (T )
a3,1 −

!2

1

a2,1 −a1,1
2

2

−

b−r 2
σ

+ 2(a1,2 − a2,2 )

1
h3 (t)

h3 (T )
(t)
− hh43 (t)
h41 (T )
4
1
+h1 (T ) a −a

3,1
1,1 b−r 2
+ a3,2
2
σ

h3 (t)h21 (t)
h2 (t)

+ a3,2 −

− a1,2


a2,2 −a1,2
2



Suppose we use the first two expansions, the optimal policy is given by:
α∗ = α0 + εα1 + O(ε2 )
where
b−r
∂f1 b−r
σ Z
= σ
∂Z σf1
γσ


b−r
Z
∂f1 f2
∂f
Z 1/γ (t)S(t) g2 (t) b−r
2
σ
α1 = σ
−
=
σf1
∂Z
∂Z f1
h1 (T − t)σ
γ

α0 =

References
Andrea L Bertozzi, Elisa Franco, George Mohler, Martin B Short, and Daniel
Sledge. The challenges of modeling and forecasting the spread of covid-19.
Proceedings of the National Academy of Sciences, 117(29):16732–16738, 2020.
https://doi.org/10.1073/pnas.2006520117.
Jakša Cvitanić and Ioannis Karatzas. Convex duality in constrained portfolio optimization. The Annals of Applied Probability, 2:767–818, 1992.
https://doi.org/10.1214/aoap/1177005576.
Nicole M Gatto and Henry Schellhorn. Optimal control of the SIR model in
the presence of transmission and treatment uncertainty. Mathematical Biosciences, 333:108539, 2021. https://doi.org/10.1016/j.mbs.2021.108539.
Ioannis Karatzas and Steven Shreve. Brownian Motion and Stochastic Calculus.
Springer, 2014. https://doi.org/10.1007/978-1-4612-0949-2.
Ralf Korn.
Optimal Portfolios: Stochastic Models for Optimal Investment and Risk Management in Continuous Time. World Scientific, 1997.
https://doi.org/10.1142/3548.
Steven E Shreve. Stochastic calculus for finance II: Continuous-time models.
Springer-Verlag New York, 2004.
Jessica A Wachter. Portfolio and consumption decisions under mean-reverting
returns: An exact solution for complete markets. Journal of financial and
quantitative analysis, 37:63–91, 2002. https://doi.org/10.2307/3594995.
28

