Explainable Automated Coding of Clinical Notes using Hierarchical Label-wise Attention
Networks and Label Embedding Initialisation
Hang Donga,d , Vı́ctor Suárez-Paniaguaa,d , William Whiteleyb,d , Honghan Wuc,d
a Centre

for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, Edinburgh, United Kingdom
b Centre for Clinical Brain Sciences, University of Edinburgh
c Institute of Health Informatics, University College London, London, United Kingdom
d Health Data Research UK, London, United Kingdom

arXiv:2010.15728v3 [cs.CL] 25 Feb 2021

Abstract
Background: Diagnostic or procedural coding of clinical notes aims to derive a coded summary of disease-related information
about patients. Such coding is usually done manually in hospitals but could potentially be automated to improve the efficiency
and accuracy of medical coding. Recent studies on deep learning for automated medical coding achieved promising performances.
However, the explainability of these models is usually poor, preventing them to be used confidently in supporting clinical practice.
Another limitation is that these models mostly assume independence among labels, ignoring the complex correlations among
medical codes which can potentially be exploited to improve the performance.
Methods: To address the issues of model explainability and label correlations, we propose a Hierarchical Label-wise Attention
Network (HLAN), which aimed to interpret the model by quantifying importance (as attention weights) of words and sentences
related to each of the labels. Secondly, we propose to enhance the major deep learning models with a label embedding (LE)
initialisation approach, which learns a dense, continuous vector representation and then injects the representation into the final
layers and the label-wise attention layers in the models. We evaluated the methods using three settings on the MIMIC-III discharge
summaries: full codes, top-50 codes, and the UK NHS (National Health Service) COVID-19 (Coronavirus disease 2019) shielding
codes. Experiments were conducted to compare the HLAN model and label embedding initialisation to the state-of-the-art neural
network based methods, including variants of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).
Results: HLAN achieved the best Micro-level AUC and F1 on the top-50 code prediction, 91.9% and 64.1%, respectively; and
comparable results on the NHS COVID-19 shielding code prediction to other models: around 97% Micro-level AUC. More importantly, in the analysis of model explanations, by highlighting the most salient words and sentences for each label, HLAN showed
more meaningful and comprehensive model interpretation compared to the CNN-based models and its downgraded baselines, HAN
and HA-GRU. Label embedding (LE) initialisation significantly boosted the previous state-of-the-art model, CNN with attention
mechanisms, on the full code prediction to 52.5% Micro-level F1 . The analysis of the layers initialised with label embeddings
further explains the effect of this initialisation approach. The source code of the implementation and the results are openly available
at https://github.com/acadTags/Explainable-Automated-Medical-Coding.
Conclusion: We draw the conclusion from the evaluation results and analyses. First, with hierarchical label-wise attention mechanisms, HLAN can provide better or comparable results for automated coding to the state-of-the-art, CNN-based models. Second,
HLAN can provide more comprehensive explanations for each label by highlighting key words and sentences in the discharge
summaries, compared to the n-grams in the CNN-based models and the downgraded baselines, HAN and HA-GRU. Third, the
performance of deep learning based multi-label classification for automated coding can be consistently boosted by initialising label
embeddings that captures the correlations among labels. We further discuss the advantages and drawbacks of the overall method
regarding its potential to be deployed to a hospital and suggest areas for future studies.
Keywords: Automated medical coding, Deep learning, Attention Mechanisms, Explainability, Natural Language Processing,
Multi-label classification, Label correlation

Preprint submitted to Journal of Biomedical Informatics

February 26, 2021

1. Introduction

the document structure.
In this work, we propose to highlight the most essential

Diagnostic or procedural coding of medical free-text docu-

words and sentences in a document for automated medical cod-

ments (e.g. discharge summaries) aims to derive a coded sum-

ing, inspired and adapted from Hierarchical Attention Networks
(HAN) [10] and the recent model, Hierarchical Attention bi-

mary of disease-related information about patients, for clinical care, audit, and research. In hospitals, such coding is usu-

directional Gated Re-current Units (HA-GRU) [1]. With atten-

ally done manually, requiring much cognitive human effort, but

tion mechanisms, HAN can highlight the salient words and sen-

could potentially be automated. An automated program could

tences related to the overall prediction. However, HAN could

efficiently take a clinical note as input and then output medical

not generate a specific interpretation for each label. HA-GRU

codes from existing classification systems, e.g. ICD (Interna-

[1] can provide a sentence-level explanation for each label, but

tional Classification of Diseases). This could facilitate coding

still could not specify the most essential words leading to the

professionals provide more accurate results.

decision of each code. We present a novel model, Hierarchical

This clinical task is technically challenging, due to (i) the

Label-wise Attention Network (HLAN), which has label-wise

explainability required to process long documents, in average

word-level and sentence-level attention mechanisms, so as to

about 2000 tokens in a discharge summary in MIMIC-III [1],

provide a richer explainability of the model.

and thus pose a “needle-in-a-haystack” issue to locate the key

We formally evaluated HLAN along with HAN, HA-GRU,

words and sentences relevant to each code; (ii) the complex

and CNN-based neural network approaches for automated med-

label correlations in the multi-label setting, in average about

ical coding. With better or comparative coding performance in

16 different ICD-9 (the Ninth Revision) codes per discharge
summary in the MIMIC-III dataset [2], which inherently ex-

various data settings, HLAN can further generate more comprehensive explanations through key sentences and words for each

hibit the complex relations among codes; and (iii) a large set

label, as indicated from the analysis on model explainability.

of codes when using all the codes as candidates for prediction,

The analysis of the false positive predictions also shows that

e.g. around 13k unique codes in ICD-9 and many times further

the explanation based on the hierarchical label-wise attention

in ICD-10 [3] and ICD-11 [4].

mechanisms in HLAN can serve as a reference for medical pro-

Automated medical coding has been studied for more than

fessionals and engineers to make reasonable coding decisions
and system iterations even when the model seems to predict er-

a decade. Early studies mostly use systems based on rules,
grammar, and string matching, as reviewed in [5]. Recent stud-

roneously.

ies adapt deep learning based document classification methods,
which commonly formalise the task as a multi-label classifica-

Apart from model interpretability, another issue not thor-

tion problem [6, 7, 1]. Typically, they use variations of Recur-

oughly studied in deep learning based multi-label classification

rent Neural Networks (RNNs) and Convolutional Neural Net-

is label correlation. Medical codes are related and can be pre-

works (CNNs) to derive a continuous representation of clinical

dicted together, for example, the code 486 (ICD 9 for Pneumo-

notes matched to the high-dimensional coding space. However,

nia) commonly appeared for over 1.5k times (out of about 53k

few studies have tackled the above challenges above regarding

documents) with the code 518.81 (Acute respiratory failure) in

explainability and label correlations.

the MIMIC-III dataset. Such co-occurrences are under-lied by
the clinical, biomedical, and biological associations among dif-

Explainability (or interpretability, used interchangeably in

ferent diseases. Deep learning for multi-label classification rep-

this paper) is a key requirement for models applied to the clin-

resents the label space with orthogonal vectors: each label as a

ical domain, particularly regarding the ethical aspect and to

one-hot vector and each label set as a multi-hot representation

build medical professionals’ trust in machine learning models
[8, 9]. Also, to facilitate the work of coding professionals, a
desired automated coding system should be able to highlight

[11, 7]. This, however, assumes independence among labels.

the most essential part of a long clinical note to support the assignment of medical codes. To address this, models based on

proach to tackle the label correlation problem. We encode the
label correlation using pre-trained label embeddings from the

CNNs can be adapted to highlight n-gram information to sup-

label sets in the training data, derived from the coding practice.

port the explanation, as in [7]. Solely the n-grams, however,

Then the label embeddings are used to initialise the weights in

may not be enough to provide accurate interpretation reflecting

the final hidden layer and label-wise attention layers. The idea

We propose an effective label embedding initialisation ap-

2

is that the linear projection can automatically leverage the label

label correlation in Section 2. Then, we present the problem

similarity encoded in the continuous label embedding space.

formulation, followed by the proposed model, HLAN, and the

This approach shows consistent and significant improvement,

idea of LE initialisation in Section 3. The experiments, includ-

while not requiring hyper-parameter tuning or further computa-

ing datasets, experimental settings, main and per-label results,

tional complexity.

analysis and comparison of model explainability, and analysis

We evaluate our approach with three specific datasets based

on the layers initialised with LE, are in Section 4. We finally

on the openly available, MIMIC-III database [2], containing

discuss the advantages and drawbacks of the overall methods in

clinical notes in the critical care sector in the US. The first two
datasets, full code and top-50 code predictions, are the same as

Section 5 and summarise the work in Section 6.

in the work [7] for comparison. The third dataset was created to

2. Related Work

simulate the task of identifying high-risk patients for shielding

We will first present the task of automated medical cod-

during the COVID-19 (Coronavirus disease 2019) pandemic by

ing with the methods used especially in most recent studies,
then introduce in detail the mainstream breakthrough on deep

predicting the ICD-9 codes matched to the codes used in the UK
NHS (National Health Service) patient shielding identification

learning-based multi-label classification for the task, and finally

method1 .

review the label correlation issue, particularly relevant to the

Thus, the contribution of the paper includes:

medical and clinical domain.

• A novel, Hierarchical Label-wise Attention Network
(HLAN) for automated medical coding. The proposed

2.1. Automated Medical Coding with Explainability

HLAN model provides an explanation in the form of at-

Automated medical coding is the task of transforming medi-

tention weights on both the word level and the sentence

cal records, especially the natural language in the clinical notes,

level for the prediction of each medical code.

into a set of structured, medical codes to facilitate clinical care,
audit, and research [5]. The applied alphanumerical codes in

• An effective label embedding (LE) initialisation approach

the clinical domain, such as ICD and SNOMED-CT, represent

to enhance the performance of various deep learning mod-

patients’ diagnosis, procedures and other information with con-

els for multi-label classification. Analysis of the LE ini-

trolled clinical terminology.

tialised layers shows the efficacy to leverage label correla-

One of the earliest reviews back in 2010 [5] surveyed 113

tions for medical coding.

studies on coding or classification of clinical notes. Most of

• A formal comparison of the main deep learning based
methods for automated coding.

the studies applied tools with rule-based, grammar-based, and

Experiments on three

string matching methods, and they in overall suffered the chal-

datasets based on the MIMIC-III discharge summaries,

lenges of reasoning and the lack of method generalisability.

i.e. full code prediction, top-50 code prediction, and the

The field of automated medical coding has in more recent years

NHS COVID-19 shielding-related code prediction, show

been advanced with the open, benchmarking datasets like radi-

the advantage of the proposed method over the state-of-

ology reports in [12] and MIMIC-III [2] discharge summaries.

the-art methods (CNNs, Bi-GRU) and downgraded base-

With the datasets, deep learning based approaches have been

lines (HA-GRU, HAN). Label embedding initialisation

proposed and tested, which have generally demonstrated better

significantly improved the performance of neural network

performance than traditional machine learning methods. The

models in most evaluation settings. An analysis and com-

work in [6] compared the deep learning based method, CNN,

parison of the model interpretability demonstrate the most

with several traditional machine learning methods, support vec-

comprehensive explanations from the HLAN model.

tor machine, random forests, and logistic regression, for ICD9 code prediction (number of ICD-9 codes |Y|=38) from 978
radiology reports in [12]. The result showed comparable or

The rest of the paper is organised as follows. First, we review
the related work on automated medical coding with explainabil-

improved results of the deep learning approach to the tradi-

ity, deep learning methods for multi-label classification, and

tional methods, even without parameter tuning in the CNN
model. The work in [7] adapted CNN with attention mecha-

1 https://digital.nhs.uk/coronavirus/
shielded-patient-list/methodology

nisms and established a state-of-the-art performance in predict3

ing the full set (|Y|=8,921) and the top-50 most frequent ICD-9

while substantially improved many NLP tasks, so far still are

codes (|Y|=50) from MIMIC-III discharge summaries.

under-performing for automated coding with the MIMIC-III
discharge summaries [18, 19].

A key aspect of clinical applications is their requirement of
the explainability of models. Users are entitled to a “right of

The idea of the above mentioned attention mechanism is a

explanation” when their data being used for AI algorithms, as

key, recent advancement in deep learning for NLP, originated

potentially regulated by the General Data Protection Regulation

from machine translation to align (or attend to) words in the

(GDPR) [9]. For clinical applications, e.g. radiology, the Joint

source sentence in one language to predict each of the target

European and North American Multisociety Statement raises
great ethical concern on AI algorithms regarding explainabil-

words in another language [20]. This inspires to jointly learn

ity, i.e. “the ability to explain what happened when the model

fying a document in HAN [10], thus also enables to explain

made a decision, in terms that a person understands” [8, p. 438].

the inner working of deep learning models. HAN was adapted

While deep learning achieves better results in general, the ap-

to a multi-label classification setting to classify socially shared

proach is inherently less transparent than traditional methods

texts in [15] and for automated medical coding [1]. Founded

due to its extremely complex networks of non-linear activation.

on the studies above, our approach provides a richer label-wise
attention mechanism at both the word and the sentence level for

to represent the important words and sentences while classi-

Few studies explored the explainability of deep learning

automated medical coding.

models for automated medical coding. A representative work
is the study [7], which compared the ability of different models

2.3. Label Correlation

to highlight n-grams along with the models’ ICD-9 code pre-

In multi-label classification, labels are potentially correlated
to each other. As the example in Section 1, the medical codes

diction. A manual evaluation showed that the CNN model with
attention mechanisms can generate more meaningful n-grams

of “Pneumonia” and “Acute Respiratory Failure” tend to ap-

relevant to the labels [7]. The study [1] proposed a Hierarchi-

pear together in the MIMIC-III discharge summaries. In auto-

cal Attention bi-directional Gated Recurrent Unit (HA-GRU)

mated medical coding, the number of unique code |Y| is large

to produce a sentence-level explanation for each code, instead

(|Y| = 8921 in the MIMIC-III dataset) and further the possi-

of n-gram-level explanation. In this work, we propose an ap-

ble label relations (e.g. the number of pairwise combinations

proach with enhanced interpretability, from both the label-wise

is near to |Y|2 ). Such correlations among the labels represent

word-level and the sentence-level attention weights, to support

additional knowledge that could be exploited to improve per-

automated coding.

formance [21].

2.2. Deep Learning-based Multi-label Classification with Attention Mechanisms

mains an ongoing challenge [21] in multi-label classification,

This issue of label correlation (or “label dependence”) re-

Automated medical coding is mainly formulated as a multi-

especially with deep learning models. Deep learning for multi-

label classification problem [13, 14, 7, 1], where each object

label classification mostly represents the label space with or-

(e.g. clinical note) is associated with a set of labels (e.g. diag-

thogonal vectors: each label as a one-hot vector and each label

nosis or procedure ICD codes) instead of a single label in binary

set as a multi-hot representation, in general domains [11] and

or multi-class classification.

clinical domains [7, 1]. Combined with the sigmoid activation
and binary cross-entropy loss, this overall approach, effectively,

Deep learning has become the main approach for multi-label

assumes independence among labels.

document classification [11, 15] in recent years. The advantage
of multi-label deep learning models lies in their straightforward

One recent approach to address the problem is through

problem formulation and strong approximation power on large

weight initialisation [22, 23]: initialising higher weights for

datasets, resulting in better performance over traditional ma-

dedicated neurons (each encoding a co-occurrence relation

chine learning approaches, as compared in [16, 15, 6]. For

among labels) in the final hidden layer. The approach showed

automated coding, some of the notable neural network models adapted for multi-label classification are variations of CNNs

performance improvement, however, it is not computationally

[6, 7] and RNNs [1] with attention mechanisms. Pre-trained

resent one of the massive (even the pairwise) patterns of la-

models with multi-head self-attention blocks (e.g. BERT, Bi-

bel relations. An alternative method is through regularisation

directional Encoder Representations from Transformers) [17],

in [15] to enforce the output layer of the neural network to

efficient to assign each neuron in the final hidden layer to rep-

4

satisfy constraints on label relations. This requires to further

the probability of the label (e.g. ICD code) yl being related to

tune the hyper-parameters of the regularisers so that a relatively

the document (e.g. discharge summary) d.

marginal improvement (0.5-1.5% example-based F1 on scien-

pdl = σ(wl h + b), or collectively as pd = σ(Wh + b)

tific paper abstracts and questions in social Q&A platforms)
could be achieved. In this study, we further propose a novel

(1)

The loss function is commonly the binary cross-entropy loss

effective weight initialisation approach to tackle the label cor-

[11] as defined in Equation 2, which measures the sum of nega-

relation problem, by initialising pre-trained dense label embed-

tive log-likelihood of the predictions pdl of the actual labels. A
−→
large deviation between Ydl and pdl will cause a greater value in

dings instead of the sparse co-occurrence representations.

the LCE and thus will be penalised during training.

3. Proposed Method

LCE = −

We formalise automated medical coding from clinical notes
as a multi-label text classification problem [11]. With deep

X X −→
−→
(Ydl log(pdl ) + (1 − Ydl ) log(1 − pdl ))
d

(2)

l

For inference, a calibration threshold Th (default as 0.5) is
set to assign the label to the document when pdl > Th.

learning, multi-label classification mainly contains two, integrated parts, (i) a neural document encoder, representing documents into a continuous representation, and (ii) a prediction

3.2. Hierarchical Label-wise Attention Network

layer, matching the document space to the label space. We
present the problem formalisation and the deep learning based

Following the framework above, the neural document en-

multi-label classification in Section 3.1. Then, regarding the

coder in HLAN (as illustrated in Figure 1) takes into input the

neural document encoder, we propose the hierarchical label-

word sequence xd = {xd1 , xd2 , ..., xdn }, where xdi denotes the
sequence of tokens in the ith of all n sentences, and output

wise attention network in Section 3.2, followed by the idea of
label embedding initialisation in the prediction layer in Section

the document representation. The distinction to HAN [10] is

3.3.

that HLAN represents the same document differently at both
the word-level and the sentence-level regarding different labels.

3.1. Problem Formulation with Deep Learning Models

HLAN extends the contextual vectors in HAN to the label-wise

Formally multi-label classification can be defined as follows.

contextual matrices, Vw and V s . The document representation

Suppose X denoting the collection of textual sequences (e.g.

also becomes a matrix, Cd , where each row (corresponding to

clinical notes), and Y = {y1 , y2 , ..., y|Y| } denotes the full set of

each label) has the same dimensionality as h.

word sequence of a document, where d is the document index.

ding layer, hidden layers (hierarchical label-wise attention lay-

Each xd ∈ X is associated with a label set Yd ⊆ Y. Each label

ers), and a prediction (or projection) layer. First, the embed-

As shown in Figure 1, the model consists of an embed-

labels (i.e. ICD codes) of size |Y|. Each instance xd ∈ X is a

set Yd can be represented as a |Y|-dimensional multi-hot vector,
−
→
Yd = [yd1 , yd2 , ..., yd|Y| ] and ydl ∈ {0, 1}, where a value of 1 indi-

ding layer transforms the one-hot input representation udi of

cates that the lth label yl has been used to annotate (is relevant

dimensional continuous vector, edi = We udi , where we used the

to) the dth instance, and 0 indicates irrelevance. The task is to

neural word embedding algorithm, Word2vec [24], to pre-train

learn a complex function f : X → Y based on a training set
−
→
D = {xd , Yd |d ∈ [1, m]}, where m is the number of instances in

We for its efficiency.

each token in the sequence of the ith sentence xdi into a low-

Second, we applied the Gated Recurrent Unit (GRU) [25],

the training set.

a type of RNN unit, to capture long-term dependencies in the

Neural document encoders in deep learning models (e.g.

clinical narrative. An RNN unit “reads” each token in the se-

CNN, RNN, and BERT, as review in Section 2.2) represent each

quence one by one, every time producing a new hidden state

word sequence x as a continuous vector h, with matrix projection and non-linear activation. The representation h is projected

h(t) , corresponding to the token at time t. Different from the
vanilla RNN unit, GRU additionally considers the previous tokens by using a reset gate r(t) and an update gate z(t) . This allows

to the label space and turned into pdl ∈ (0, 1) with the sigmoid
function (σ(x) =

1
1+e x ),

as defined in Equation 1 below, where

to model the dependencies among tokens in long sequences.
A GRU can be formally defined as in the Equations 3 below,
→
−
where h denotes the hidden states through forward processing,

the weight wl (a row vector in W) and the bias b are parameters
to be learned during the training process. The obtained pdl is
5

Figure 1: Hierarchical Label-wise Attention Network (HLAN)

σ is a non-linear activation function (e.g. sigmoid function),
Whr , Whz , Whh̃ ∈ R

dh ×dh

ing is contained in a well selected part of the lengthy discharge

dh

are weights, and br , bz ∈ R represent

summary. We therefore use an attention mechanism to learn

bias terms. A bi-directional adaptation was applied by concate-

a weighted average of the hidden states to form a final repre-

nating the hidden states at each time after read the sequence

sentation as in [10, 20]. The attention scores are based on an

both forwardly (→) and backwardly (←) to form a more com→
− ←
−
prehensive representation, h(t) = [ h (t) ; h (t) ] ∈ R2dh . This sub-

alignment (or a similarity computation) of each hidden representation in a sequence to a context vector. The context vector

architecture is generally known as Bi-GRU [25].

→
−
r(t) = σ(Wer e(t) + Whr h (t−1) + br )
→
−
z(t) = σ(Wez e(t) + Whz h (t−1) + bz )
→
−
h̃(t) = tanh(Weh̃ e(t) + Whh̃ (r(t) ◦ h (t−1) ))
→
− (t)
→
−
h = (1 − z(t) ) ◦ h (t−1) + z(t) ◦ h̃(t)

is usually shared for all labels as in [10, 15], whereas in medical coding, it is essential to interpret the amount of attention
paid regarding a specific medical code to the clinical note.
h(i) = Bi-GRU(e, Θw )

(3)

v(i) = tanh(Ww h(i) + bw )

hidden states) above. Instead of applying one single Bi-GRU

exp(Vwl • v(i) )
α(i)
wl = P
(o)
o∈[1,n ] exp(Vwl • v )
X t
(i)
C sl =
α(i)
wl h

layer to represent the whole document, we applied a word-level

Thus, the adapted, label-wise word-level attention mechanism

Bi-GRU to represent each sentence and then a sentence-level

is defined in Equations 4 above. The context matrix for the

one to represent the whole document, as illustrated in Figure

word-level attention mechanism is denoted as Vw ∈ R|Y|×dw ,

For simplicity, we use the function h = Bi-GRU(e, Θ) to denote the whole process (with bi-directional concatenation of

(4)

i∈[1,nt ]

where each row Vwl (of attention layer size dw ) is the context

1. This captures the hierarchical structure of the document and
relieves the burden of having a too lengthy sequence for each

vector corresponding to the label yl . The attention score α(i)
wl

GRU [1] (e.g. from the original sequence length 2500 in the

for the label yl is calculated as a softmax function of the dot

MIMIC-III discharge summaries to only 100 on the word level

product similarity between the vector representation v(i) (transformed from the ith hidden state h(i) with a feed-forward layer)

and 25 on the sentence level).

and the context vector Vwl for the same label. nt denotes the

A common way is to represent the whole sequence as the
of the last time t. This repre-

number of tokens in a sentence. The sentence representation

sentation tends to emphasise the ending elements (i.e. words

C sl , as a row vector in C s ∈ R|Y|×2dh , for the label yl , is com-

concatenated hidden state h

(t)

puted as the weighted average of all the hidden state vectors

or sentences) and does not discriminate between the elements

h(i) .

in a sequence. In fact, the key information for medical cod6

In a similar way, we can compute the label-wise sentence-

518.81 (Acute respiratory failure), one would expect that the

level attention mechanism as defined in Equations 5, which
encodes each row C sl in the sentence representations C s to a

prediction of one label has an impact on the other label for some
clinical notes, i.e. pd j is correlated or has a similar value to pdk .

label-wise sentence representation S l(r) , to be non-linearly trans-

To achieve this, according to Equations 1 or 6, we propose to

formed to

initialise their corresponding weights w j and wk (corresponding

Ul(r)

and aligned to the corresponding row V sl in
|Y|×d s

, and outputs the

to the labels y j and yk ) in W with a label representation E which

sentence-level attention scores α sl (for a label yl ) and the doc-

reflects the actual label correlation (e.g. similarity between y j

sentence-level contextual matrix V s ∈ R
ument representation matrix Cd ∈ R

|Y|×4dh

and yk ) in a continuous space.

. To note that the

dimensionality of S lr and thus Cdl are further doubled to 4dh

A straightforward idea is thus to initialise the projection ma-

through the Bi-GRU process.

trix W using E as pre-trained label embeddings, e.g. with a
neural word embedding algorithm, learned from the label sets in
−
→
the training data, {Yd |d ∈ [1, m]}. For initialisation, we pre-train

S l(r) = Bi-GRU(C sl , ΘS )
Ul(r) = tanh(WS S l(r) + bS )
exp(V sl • Ul(r) )

α(r)
sl = P
(q)
q∈[1,n] exp(V sl • U l )
X
(r)
Cdl =
α(r)
sl S l

the label embeddings E with dimensionality the same as W.
We used the Continuous Bag of Words algorithm in word2vec

(5)

[24] for its efficiency and its power to represent the correlations of the labels. Figure 2 shows an intuitive visualisation, for
which we used an unsupervised technique, T-SNE (t-distributed

r∈[1,n]

Stochastic Neighbor Embedding), to reduce the dimensionality

Then, we use a label-wise, dot product projection with logis-

of the learned label embeddings while preserving the local simi-

tic sigmoid activation to model the probability of each label to

larity and structure of the labels [27]. It can be observed that the

each document, as defined in Equation 6, adapted from Equa-

ICD-9 code learned from the MIMIC-III training label sets can

tion 1. The parameters in wl are row vectors in the projection

capture the semantic relations that are distinct from the ICD-9

matrix W.
pdl = σ(wlCdl + bl )

hierarchy. For example, 486 (Pneumonia) and 518.81 (Acute

(6)

respiratory failure) appear closely on the bottom while they are
not under the same parent in the ICD-9 hierarchy.

We finally optimise the binary cross-entropy loss function
in Equation 2 with L2 regularisation using the Adam opti-

Besides, the label embedding initialisation can also be ap-

miser [26].

plied to the context matrices Vw and V s (see Figure 1) in the
label-wise attention mechanisms. Taking the word-level atten-

3.3. Label Embedding Initialisation

tion mechanisms in Equation 4 as an example, we can initialise
Vwl with the pre-trained label embedding El for the label yl .

For automated medical coding, the diagnostic and proce-

This imposes a tendency for context vectors of the correlated

dural codes (or labels) have complex semantic relations, and

labels to align the Bi-GRU encoded token representation vi in

can potentially be leveraged to improve prediction. Clinically,

a geometrically similar way. Similarly, we can also initialise

these code relations represent the correlation among diseases

the label-wise attention layer in CNN+att [7] and in HA-GRU
[1]. While the initialised layers are dynamically updated dur-

and medical procedures from the medical coding practice.
As we reviewed in Section 2.3, previous studies on weight

ing the training, the tendency that imposed by label embeddings

initialisation to address the label correlation issue mostly focus

remains for most neural networks; we will empirically demon-

on a co-occurrence based representation of labels [22, 23]. Both

strate this in the analysis of initialised layers in Section 4.8.

studies dedicate a neuron in the final hidden layer to initialise
one single co-occurrence pattern. There are, however, very lim-

For automated coding, the approach can be extended by ini-

ited neurons to be assigned to initialise the massive number of

tialising label embeddings with the clinical ontologies and de-

label relations, especially for the large label size in automated

scription texts of ICD codes. However, due to the different na-

coding.

ture of the knowledge (i.e. embedded label relations), the ex-

Instead of encoding the sparse co-occurrence patterns of la-

ternal sources may bring contradictory label correlations to the

bels, we learn low-dimensional, dense, label embeddings. For

ones in the dataset, as also discussed in [28]. In this research,

two correlated labels y j and yk , e.g. 486 (Pneumonia) and

we focus on leveraging label relations from the label sets alone
7

Figure 2: The 2-dimensional T-SNE plot of word2vec Continuous Bag of Words label embeddings of the 50 ICD-9 codes in MIMIC-III-50, trained on the whole
−
→
training label sets, {Yd |d ∈ [1, m]}, in MIMIC-III.

4.1. Datasets

as in [22, 23], as it directly reflects the label correlation of the
coding practice that generated the dataset, and leave the integration of external knowledge for a future study.

We used the benchmark dataset, MIMIC-III (“Medical Information Mart for Intensive Care”) [2], which contains clinical data from adult patients admitted to the critical care unit
in the Beth Israel Deaconess Medical Center in Boston, Massachusetts between 2001 and 2012, to validate our approach.

4. Experiments

The ICD-9 codes annotated by professionals in the dataset were
used as labels. We focused on discharge summaries and folWe tested HLAN and several strong baseline models, with

lowed the preprocessing and data split from [7]. The prepro-

label embedding initialisation, on three data sets based on the

cessed full MIMIC-III dataset has 8,922 unique codes as labels

MIMIC-III database. The main results show the comparative

assigned to 52,724 discharge summaries, where 47,724 of them

results of HLAN to other state-of-the-art models on the datasets

(from 36,998 patients) were used for training, 1,632 for valida-

and the consistent improvement with label embedding initialisation. More importantly, through an analysis on model inter-

tion, and 3,372 for testing. We also used the same top-50 setting

pretability, we also show that HLAN can provide a more com-

labels to the top 50 by their frequencies (codes and their fre-

prehensive explanation using the label-wise word and sentence-

quencies are available in Table S1 in the supplementary mate-

level attention mechanisms. Analysis of the layers initialised

(termed as “MIMIC-III-50”) from [7], which narrows down the

with label embeddings further reveals the effect of the ini-

rial). This has 8,067 discharge summaries for training, 1,574
for validation, and 1,730 for testing.

tialisation approach. The source code of our implementation

We further created a subset of discharge summaries anno-

and the results are openly available at https://github.com/

tated using the COVID-19 shielding related ICD codes. This

acadTags/Explainable-Automated-Medical-Coding.

simulates the application of identifying key patients for shield8

ing during the pandemic. We used the ICD-9 codes matched

statistics show a high imbalanced characteristics of the labels

to the ICD-10 codes selected by the NHS to identify patients

in all three data settings. Most label occurrences are from a

with medium or high risks during COVID-19. The considered

few labels and there is a long-tail of labels having very low

patients were related to solid organ transplant recipients, people

frequencies. This is most pronounced in the full label setting

with specific cancers, with severe respiratory conditions, with

(“MIMIC-III”) and also presented in the other two datasets.

rare diseases and inborn errors of metabolism, on immunosuppression therapies, or who were pregnant with significant con-

4.2. Experiment Settings

genital heart disease2 , which is still in active use and under
maintenance at the time of writing this paper. While the actual

We implemented the proposed Hierarchical Label-wise At-

EHR data and the shielded patient list from the NHS are not

tention Network (HLAN) model and the other baselines for

easy to obtain, the ICD-10 codes are openly available for re-

comparison:

3

use . We thus used MIMIC-III to simulate the task of identify-

1. CNN, Convolutional Neural Network, which is essentially

ing patients for shielding during COVID-19. We selected those

based on [29] for text classification, and applied in [6, 30]

appeared at least 50 times in the MIMIC-III dataset, resulting

for automated medical coding.

in 20 ICD-9 codes (out of 79 matched codes), available in Table

2. CNN+att (or CAML), CNN with a label-wise attention

S2 in the supplementary material. After filtering the MIMIC-III

mechanism, proposed in [7].

dataset with the selected ICD-9 codes, there are 4,574 discharge

3. Bi-GRU, Bi-directional Gated Recurrent Unit [25] for

summaries for training, 153 for validation, and 322 for testing.

multi-label classification. The document representation is

We name this dataset as “MIMIC-III-shielding”.

set as the last concatenated hidden state h(t) .

Statistics of the three datasets are in Table 1. Denoted by Ave,
the average number of labels per document (or label cardinality)

4. HAN, Hierarchical Attention Network [10], which can be

in the training set of MIMIC-III, MIMIC-III-50, and MIMIC-

considered as a downgraded model of HLAN when the

III-shielding are 15.88, 5.69, and 1.08, respectively. While all

attention mechanisms are shared for all labels (see Figure

originated from MIMIC-III database, the three datasets repre-

1, when Vw , V s , and C s , Cd become vectors, same for all

sent different case scenarios in automated medical coding with

labels).

various scales of data and vocabulary size (“vocab”), number

5. HA-GRU, Hierarchical Attention bi-directional Gated Re-

of labels to predict, and the average number of labels per doc-

current Unit, proposed in [1], which can be considered as

ument. While the full MIMIC-III dataset has much more train-

a downgraded model of HLAN when the word-level atten-

ing instances, it is more complex as its number of labels |Y| and

tion mechanism is shared for all labels (see Figure 1, when

MIMIC-III-shielding.

and Cd are the same as in HLAN).

vocabularies are significantly greater than MIMIC-III-50 and

Vw and C s become vectors, same for all labels, while V s

We applied the label embedding initialisation approach (de-

Table 1: Statistics of the datasets
Dataset
MIMIC-III-50
MIMIC-III-shielding
MIMIC-III

Vocab
59,168
47,979
140,795

Train
8,067
4,574
47,724

Valid
1,574
153
1,632

Test
1,730
322
3,372

|Y|
50
20
8,921

noted as “+LE”) to all the models above. We pre-trained the

Ave
5.69
1.08
15.88

label embeddings E from the label sets in the training data with
the word2vec (Continuous Bag of Words with negative sampling) algorithm [24]. The label embeddings have the dimension same as the final hidden layer or the label-wise attention

Figures of ICD-9 code distributions by frequency in the three

layer(s) in each neural network model. We applied the Python

datasets are available in Figure S1 in the supplementary mate-

Gensim package [31] to train embeddings, by setting the window size as 5 and minimum frequency threshold (“min count”)

rial, along with the list of the selected codes (and their frequencies) in the MIMIC-III and MIMIC-III-shielding datasets. The

as 0. Label embeddings were normalised to unit length for initialisation. Xavier initialisation [32] was used for labels not

2A

clearer description of the “high risk” category is in https:
//digital.nhs.uk/coronavirus/shielded-patient-list/
methodology/background
3 To see the annexe B in https://digital.nhs.uk/coronavirus/
shielded-patient-list/methodology/annexes

existing in the training data for faster model convergence. We
used the same setting to train and initialise the 100-dimension
word embeddings We from the documents.
9

The implementations of HLAN and HA-GRU were adapted

mal size of a BERT model, i.e. BioBERT-base [35], which

from our previous implementation4 of HAN in [15] using the

had been further pre-trained with PubMed paper abstracts9 and

Python Tensorflow [33] framework, originated from bright-

full texts10 ; we used a sliding window approach to address the

mart’s implementation5 , all under the MIT license. We adapted

token limit issue (512 tokens) in BERT. Our results from the

HA-GRU with the sigmoid activation and binary cross-entropy

BioBERT-base model were similar to the results in [19], signif-

as described in Section 3.1, instead of the softmax activation

icantly worse than HLAN and CNN11 . We believe further adap-

used in the original paper [1], for a controlled comparison with

tations are necessary for BERT models on automated medical

other models. For CNN, CNN+att, and Bi-GRU, we adapted
the implementation6 from [7] using the PyTorch framework

coding and leave the direction for a future study.

[34] with the same parameters for MIMIC-III and MIMIC-50

4.3. Evaluation Metrics

from [7]. For MIMIC-III-shielding, we used the same hyper-

For comparison, we applied the same set of label-based met-

parameters as in MIMIC-50. We did not get the results with

rics as in [7] and according to the evaluation of multi-label

HA-GRU and HLAN for the MIMIC-III dataset, due to the

classification algorithms [14, 13]. The chosen metrics include

memory limit caused by the large label size (|Y| = 8, 921), while

micro- and macro-averaging precision (P), recall (R), F1 score

for MIMIC-III-50 and MIMIC-III-shielding, we obtained the

(F1 ), area under the receiver operating characteristic curve

results of all models.

(AUC), an the precision@k.

The input token length for the models was padded to 2,500

The micro-averaging metrics treat each document-label as a

as in [7]. We optimised the precision@k or micro-F1 metrics

separate prediction, whereas the macro-averaging metrics are

(defined in Section 4.3) during the training7 , according to the

an average of the per-label results. Micro- and macro-averaging

implementation in [7]. The batch size for CNN, CNN+att, Bi-

applies to all the binary evaluation metrics including precision,

GRU were set as 16 as in [7], for HLAN and HA-GRU as 32,

recall, AUC. For example, the micro- and macro-averaged pre-

and HAN as 128. For HLAN, HAN, and HA-GRU, we tried

cision is defined in Equation 7 below. Recall is calculated in a

both a customised rule-based parsing of real sentences with

similar way, but divided by all the true cases (T Pl + FNl ), and

Spacy8 and using text chunks of fix length as “sentences”; for

F1 is then the harmonic mean of the calculated precision and
recall, i.e. F1 = 2×P×R
P+R . The AUC is defined by two metrics,

both ways, we set the sentence length as 25 and padded the
number of sentences to 100. The dimensions of the final docu-

the true positive rate (or recall) on the Y axis and false positive

ment representation were 512, 500, 50, 400 for Bi-GRU, CNN,

rate on the X axis, depicting the tradeoff between the two met-

CNN+att, and HLAN (also HAN and HA-GRU), respectively.

rics when varying the calibration threshold Th [36]. The overall

All models were trained using a single GeForce GTX TITAN

performance of a classifier (with a set of varied Th) can thus be

X server, and the trained HLAN, HA-GRU, and HAN mod-

reflected by AUC.

els were further tested using a CPU server (4-core, Intel(R)
Xeon(R) Platinum 8259CL CPU @ 2.50GHz). The detailed

Micro-P = PL

hyper-parameter settings, containing learning rate, dropout rate,

PL

l=1

and CNN specific parameters (kernel size and filter size), with

l=1

L

TPl

TPl + FPl

Macro-P =

1 X
TPl
|L| l=1 TPl + FPl
(7)

In some clinical application or epidemiological studies, only

the estimated training and testing times, are in Table S3 in the
supplementary material.

one type of code (either the diagnosis or the procedure code) is

We also experimented with BERT as the neural document

favoured. Thus, for the MIMIC-III full label setting, we also

encoder. Due to the GPU memory limit, we tested the nor-

report Micro-F1 results on the diagnosis codes (F1 -diag) and
procedure codes (F1 -proc) separately as in [7].
Furthermore,

4 https://github.com/acadTags/Automated-Social-Annotation/

tree/master/2%20HAN
5 https://github.com/brightmart/text_classification
6 https://github.com/jamesmullenbach/caml-mimic
7 We optimised precision@k for CNN, CNN+att, and Bi-GRU for MIMICIII and MIMIC-III-50, and micro-F1 for all other models and for the MIMICIII-shielding dataset.
8 We parsed sentences using the rule-based pipeline component in Spacy
with adding double newlines as another rule to segment sentences, see https:
//spacy.io/usage/linguistic-features#sbd.

we

report

the

example-based

metric,

precision@k as in [7], averaged over all the documents,
9 https://pubmed.ncbi.nlm.nih.gov/

10 https://www.ncbi.nlm.nih.gov/pmc/

11 We thus do not report the BERT results here but make the implementation details and results available on https://github.com/acadTags/
Explainable-Automated-Medical-Coding.

10

where each precision score is the fraction of the true positive in

For the full label setting (“MIMIC-III”), HAN has better re-

the top-k labels, having highest score pdl , for the document d.

sults of Micro-AUC and precision@8 than the vanilla CNN

The idea is to simulate the real-world scenario that the system

and Bi-GRU, but worse than the CNN+att approach specifi-

recommending k predicted medical codes and to evaluate the

cally tuned for this dataset. With label embedding initialisa-

percentage of them being correct. The number of top-ranked

tion, CNN+att+LE achieved significant best results on MIMIC-

labels k were set as 8 for MIMIC-III, 5 for MIMIC-III-50 to be

III (an Micro-AUC of 98.6%). It is worth to further explore

consistent to the study [7], and 1 for MIMIC-III-shielding, near

to enhance the scalability of HLAN so that it can process

to the average number of labels per document (see Table 1).

datasets with large label sizes. Also to note that results of the
Macro-level metrics (averaging over labels) were dramatically

4.4. Main Results

lower than the Micro-level ones (calculated from document-

We report the mean and the standard deviation (i.e. the

label pairs), showing the strong imbalance of labels in MIMIC-

square root of variance) of the testing results of 10 runs with

III (see Section 4.1).

randomly initialised parameters for each model. The results

Injecting the code relations through label embedding consis-

of the MIMIC-III-50, MIMIC-III-shielding, and MIMIC-III
datasets are shown in Table 2, 3, and 4, respectively.

tently boosted the performance of automated medical coding. It
is clear that most models were improved with label embedding
initialisation (“+LE”). Models were affected to different extend

For the top 50 label dataset (MIMIC-III-50, see Table 2),
HLAN performed the best among all experimental settings,

by label embedding: CNN+att model was mostly improved

achieved significantly better Micro-AUC (91.9%), Micro-F1

with “+LE” (an increase of 6.6% Macro-AUC on MIMIC-III-

(64.1%), and Precision@5 (62.5%) than the second best model,

shielding), the rest models (CNN, Bi-GRU, HA-GRU) being

CNN. This shows the advantage of the hierarchical label-wise

relatively less affected, while there was no significant improve-

attention mechanisms for top-50 code prediction. With the

ment for HLAN or HAN on the datasets. This may due to

same calibration threshold, the precision of HLAN is better than

the fact that the prior layers, e.g. hierarchical layers and the

CNN absolutely by 15% (73.2% vs. 57.7%), while recall is

label-wise attention layers, could already learn some of the la-

lower with a similar absolute value, indicating that tuning the

bel relations. We thus further analyse the LE-initialised layers

threshold to balance precision and recall could further improve

in Section 4.8 to understand the effect of label embedding ini-

the F1 scores.

tialisation. Besides, most metrics with the “+LE” models also

For code related to high-risk patients for shielding during

have higher stability (i.e. reduced variance); and low variance

the COVID-19 pandemic (MIMIC-III-shielding, see Table 3),

is an essential characteristic to deploy a model in the clinical

results (of Micro-AUC) show that HLAN (96.9%) and HAN

setting.

(97.6%) performed comparably to the best performed model,

4.5. Result for each label

CNN (97.9%). HLAN obtained a high value of precision@1,
slightly below CNN by 1% (81.2% vs 82.2%), while the dif-

Apart from the overall performance of the models, it is also

ference was not significant (p > 0.05). The better performance

essential to see how the models perform regarding each med-

of CNN (or HAN) may be because that smaller datasets like

ical code. Figures 3 show the precision and recall of the five

MIMIC-III-shielding, with much fewer documents and labels

diagnosis codes having the highest and the lowest frequencies

(see Table 1), tends to favour models with simpler architectures.

in MIMIC-III-50. For this analysis, we selected the three best

In both MIMIC-III-50 and MIMIC-III-shielding, HA-GRU

performing models, CNN, CNN+att, and HLAN, all with la-

did not perform better than HLAN, this shows that the label-

bel embedding initialisation (“+LE”), in terms of AUC metrics

wise word-level attention mechanisms in HLAN further im-

for MIMIC-III-50 (see Table 2). We provide the full per-label

proved the performance. Also, surprisingly, the HLAN or HAN

results of HLAN+LE with the MIMIC-III-50 and MIMIC-III-

models with the real sentence split did not perform better (up

shielding datasets in Table S1-S2 in the supplementary material.

to 2.8% less Micro-F1 ) than using text chunk “sentences” (of
25 continuous tokens) in all three datasets. This is probably

In Figures 3, we can observe that the overall trend of performance is generally consistent to, while not solely dependent on,

because, with the sentence split setting, some tokens and sen-

the label frequency in the training data. For the five most fre-

tences were lost during the padding procedure, which could sig-

quent labels, the models achieved around 70%-90% precision

nificantly affect the performance.

and recall. For example, in terms of precision, HLAN obtained
11

Table 2: Results on MIMIC-III-50 dataset (50 labels)
Model
CNN
+LE
Bi-GRU
+LE
CNN+att
+LE
HAN
+LE
HA-GRU
+LE
HLAN
+LE
+sent split

AUC
88.1±0.3
88.3±0.3
80.6±1.1
80.9±0.8
88.1±0.0
88.3±0.0∗
87.0±0.4
87.3±0.4
85.3±1.3
86.4±0.7∗
88.4±0.7
88.4±0.5
86.9±0.5

Macro
P
R
51.5±0.9
67.4±1.0
66.7±1.5
53.0±1.0∗
47.2±3.2
36.7±2.6
47.3±2.0
39.2±2.0∗
63.1±0.1
48.4±0.2∗
64.3±0.3∗
46.0±0.1
61.7±2.7
46.3±2.3
61.3±3.2
46.9±2.9
59.3±2.5
43.1±4.0
∗
62.1±1.9
44.3±2.3
65.0±1.2
51.0±2.6
65.5±1.5
50.2±1.1
63.6±1.3
47.8±2.4

F1
58.4±0.5
59.1±0.5∗
41.2±2.3
42.8±1.5
54.8±0.2∗
53.6±0.1
52.8±1.1
53.0±1.1
49.9±3.4
51.7±1.9
57.1±1.6
56.8±0.8
54.5±1.7

AUC
90.9±0.2
91.3±0.1∗
85.5±1.0
85.8±0.7
91.1±0.0
91.3±0.0∗
90.1±0.3
90.3±0.4
89.2±0.9
90.1±0.5∗
91.9±0.4
91.9±0.3
90.4±0.3

Micro
P
R
55.6±1.1
71.2±0.9
57.7±1.4∗
70.4±1.4
58.1±3.2
45.8±2.2
57.5±2.2
48.4±2.1∗
70.9±0.2
53.1±0.2∗
71.6±0.1∗
52.5±0.1
68.2±3.1
52.9±2.4
67.9±4.1
54.2±2.8
69.5±0.6
48.7±4.1
∗
71.1±1.2
50.7±2.3
72.9±0.8
57.3±2.5
73.2±0.6
56.9±1.0
71.5±1.2
53.8±2.1

F1
62.4±0.6
63.4±0.5∗
51.2±1.9
52.5±1.3∗
60.7±0.1
60.6±0.1
59.4±0.7
60.1±0.7
57.2±2.8
59.1±1.4∗
64.1±1.4
64.0±0.7
61.4±1.2

Top-k
P@5
61.8±0.3
62.1±0.3
51.3±1.7
52.1±1.2
60.8±0.1
61.6±0.1∗
59.5±0.7
59.9±0.8
57.9±1.7
59.5±1.0∗
62.5±0.7
62.4±0.6
60.2±0.7

The results of better metric score between the model with label embedding initialisation (“+LE”) and the model not using LE initialisation are underlined, and the asterisk (*) further marks the paired two-tailed t-tests with .95 significant level (p < 0.05) between them. The
best result for each metric (column) is in bold. The AUC, F1 , and P@5 scores in HLAN models with italics indicates their significantly
improved results (p < 0.05) over the second best model category (i.e. HLAN vs. CNN). The model with lower variance is preferred if
the average scores are the same.
Table 3: Results on MIMIC-III-shielding dataset (20 labels)
Model
CNN
+LE
Bi-GRU
+LE
CNN+att
+LE
HAN
+LE
HA-GRU
+LE
HLAN
+LE
+sent split

AUC
96.9±0.2∗
96.7±0.2
91.9±1.4
92.0±1.6
88.9±1.3
95.5±0.0∗
96.0±1.4
96.4±1.3
93.4±2.0
93.9±2.0
93.5±2.5
93.5±1.9
94.5±1.2

Macro
P
R
59.8±1.2
59.6±1.3
60.4±2.8
60.4±2.3
57.4±3.1
43.4±2.2
58.6±1.5
46.8±2.3∗
46.7±4.6
37.6±2.4
62.1±2.2∗
48.4±1.9∗
66.4±2.7
58.2±2.0
65.2±2.1
56.5±2.9
60.9±3.9
51.6±2.8
59.2±4.3
49.7±4.2
59.8±2.9
53.2±2.6
60.5±4.2
52.7±5.0
60.9±2.1
51.7±3.1

F1
59.7±0.9
60.4±2.3
49.4±2.2
52.0±1.4∗
41.7±3.3
54.4±2.0∗
62.0±2.0
60.5±2.3
55.8±3.1
54.0±4.1
56.3±2.4
56.3±4.6
55.8±2.3

AUC
97.9±0.4∗
97.6±0.3
93.6±0.8
95.1±0.7∗
93.5±0.2
96.1±0.0∗
97.4±0.3
97.6±0.3
96.7±0.4
96.8±0.9
96.9±0.7
96.5±0.4
96.3±0.2

Micro
P
R
80.5±1.3
76.2±0.9
78.8±2.5
76.4±1.8
77.9±2.8
58.5±1.9
78.1±2.1
61.8±2.7∗
52.9±2.8
86.9±1.2∗
83.3±0.5
61.4±0.6∗
82.9±1.8
68.7±2.4
83.4±1.2
68.2±2.0
83.0±2.1
65.8±2.2
81.3±4.0
66.3±4.1
81.4±1.8
69.0±2.9∗
81.8±2.8
65.6±4.0
81.4±2.2
64.4±2.5

F1
78.3±1.0∗
77.5±0.7
66.8±1.2
68.9±1.6∗
65.7±2.0
70.7±0.3∗
75.1±1.5
75.0±1.2
73.4±1.6
73.0±3.6
74.6±1.6
72.7±3.1
71.9±1.7

Top-k
P@1
82.2±0.8
81.6±0.9
72.2±1.6
75.1±2.0∗
70.0±2.6
77.7±0.3∗
78.1±1.7
79.2±1.7
80.3±1.5
79.1±4.3
81.2±1.2
79.8±3.0
77.8±2.6

The results of better metric score between the model with label embedding initialisation (“+LE”) and the model not using LE initialisation are underlined, and the asterisk (*) further marks the paired two-tailed t-tests with .95 significant level between them. The best result
for each metric (column) is in bold. The AUC, F1 , and P@1 scores in CNN models with italics indicates their significantly improved
results (p < 0.05) over the second best model category (i.e. CNN vs. HAN or HLAN). The model with lower variance is preferred if the
average scores are the same.

4.6. Model Explanation with Hierarchical Label-wise Atten-

highest to 91.7% for 427.31 (Atrial fibrillation) and lowest to

tion Visualisation

71.4% for 584.9 (Acute kidney failure). For the five least frequent labels, the results were much worse due to the fewer train-

A critical requirement of the clinical use of automated medical coding systems is their explainability or interpretability.

ing data for the labels and the imbalance issue. For precision,
HLAN generally performs better than CNN and CNN+att, es-

We propose to use label-wise word-level and sentence-level at-

pecially there is a significant gap for low frequent labels; while

tention mechanisms in HLAN to enhance the explainability of

for recall, CNN outperforms the other two models. We also

the model. The learned word-level and sentence-level atten-

note that the precision and recall could be tuned in favour of

tion scores for the label yl are αwl ∈ (0, 1) and α sl ∈ (0, 1)

only one of them through changing the calibration threshold Th

(see Equations 4 and 5, respectively). For a more concise visu-

(now set as the default value, 0.5), considering the need and

alisation, we propose a sentence-weighted word-level attention

the preference of the coding work when deploying the model to

score α̃wl to only highlight the words from the salient sentences.

support coding professionals.

This adapted word-level attention score is calculated as α̃wl =
µα s̃l αwl , where α s̃l is the attention score of the sentence where
the word is belong to and µ is a hyperparameter to control the
12

Table 4: Results on MIMIC-III dataset (8,922 labels)
Model
CNN
+LE
Bi-GRU
+LE
CNN+att
+LE
HAN
+LE
+sent split

AUC
81.8±0.7
82.4±0.4∗
83.5±1.6
84.9±0.7∗
88.6±0.2
90.2±0.0∗
88.5±0.1∗
88.2±0.2
87.4±0.7

Macro
P
R
4.5±0.4
3.7±0.5
4.7±0.4
3.6±0.2
4.9±0.2
3.6±0.5
5.0±0.4
3.6±0.5
7.7±0.2
6.4±0.3
9.3±0.1∗
8.0±0.1∗
5.4±0.2∗
2.7±0.2∗
5.1±0.2
2.4±0.1
4.7±0.6
2.3±0.4

F1
4.1±0.4
4.1±0.2
4.1±0.4
4.2±0.5
7.0±0.2
8.6±0.1∗
3.6±0.2∗
3.3±0.2
3.1±0.5

AUC
97.0±0.1
97.1±0.1
97.3±0.3
97.6±0.1∗
98.4±0.0
98.6±0.0∗
98.1±0.1
98.1±0.0
97.9±0.1

P
51.0±2.8
53.0±2.6
52.8±4.6
55.4±4.1
62.8±0.3∗
61.8±0.4
63.2±3.3
63.2±1.0
60.4±2.2

Micro
R
F1
36.9±1.7 42.8±0.9
36.9±1.2 43.4±0.6
34.8±2.2 41.8±1.5
34.8±2.4 42.6±1.5
43.9±0.4 51.7±0.1
45.6±0.1∗ 52.5±0.1∗
30.0±1.1∗ 40.7±0.7∗
27.6±1.1 38.4±1.0
25.3±2.5 35.6±2.6

F1 -diag
41.1±1.0
41.7±0.6
39.3±1.6
40±1.6
50.1±0.2
50.7±0.1∗
37.0±0.7∗
34.8±1.2
31.4±2.6

F1 -proc
50.7±0.9
51.3±0.9
51.7±1.3
52.7±1.1
59.8±0.1
60.7±0.1∗
52.6±0.9∗
50.6±1.0
49.1±2.3

Top-k
P@8
59.6±0.5
60.3±0.4∗
58.9±2.2
60.3±1.8
69.4±0.2
69.7±0.1∗
61.4±1.3∗
59.6±0.6
56.3±2.0

The results of better metric score between the model with label embedding initialisation (“+LE”) and the model not using LE initialisation are
underlined, and the asterisk (*) further marks the paired two-tailed t-tests with .95 significant level between them. The best result for each metric
(column) is in bold. The model with lower variance is preferred if the average scores are the same.

Figure 3: Precision and recall of the five most and the five least frequent ICD-9 diagnosis codes in the MIMIC-III-50 dataset. The bar chart (with the left y-axis)
shows the metric score, while the line chart (with the right y-axis) shows the number of occurrences or the frequency (“Freq”) of the label in the training data.

magnitude of the final weighted attention score. A greater µ

monly used by clinicians in the clinical note, for example “a

will result in highlighting more words in the clinical note and

fib” as a short form of atrial fibrillation and “chf” as the ab-

we empirically set µ as 5. We clip the value of α̃wl to 1 if it is

breviation of Congestive Heart Failure. This shows that the

above 1.

proposed HLAN model can learn to recognise the strongly correlated words (e.g. “a fib”) related to the label (e.g. the code

An example attention visualisation for a random document

427.31) with label-wise attention mechanisms, even given the

(number 24) in MIMIC-III-50 using the model HLAN+LE with

fact that the label description (i.e. the knowledge that 427.31 is

the parsed sentences (“+sent split”) is shown in Figure 4. The

“Atrial Fibrillation”) were not fed into the model during train-

two columns on the left visualise the sentence-level attention

ing. Other relevant words are highlighted, e.g., “ef” (short for

scores α sl for the two codes, 427.31 (Atrial fibrillation) and

Ejective Fraction), “pressor”, and “extremities”, which show a

428.0 (Congestive heart failure, unspecified), respectively. The
highlighted sentences are corresponding to the sections “past

correlation to the code 428.0 while not indicating a causal rela-

medical history” and “discharge diagnosis” in the discharge
summary. This is in line with our intuition that the key diag-

like “age” and “drugs” were too general, which could not be di-

tion to the diagnosis. We also note that the highlighted words
rectly related to the diagnosis from a clinician’s point of view.

nosis information is likely to be contained in the two sections.

This may be related to the peaky distribution of the softmax

The words are highlighted according to the adapted word-level

(normalised exponential) function to form the attention scores

attention score α̃wl . Words related to the code 427.31 is high-

(see Equation 4), paying the most of the attention to only a few

lighted in yellow and for 428.0 in blue. It is clear that the

(one or two) words in a long sentence.

most salient words are highlighted, and the model successfully
recognised the abbreviations and alternative short forms com13

Figure 4: An example of interpretation using attention visualisation from the Hierarchical Label-wise Attention Network (HLAN), the chosen example is a random document (index 24) in the MIMIC-III-50 dataset with two true positive labels, ICD-9 code 427.31 (Atrial fibrillation) and 428.0 (Congestive heart failure,
unspecified). The two red columns show the sentence-level attention scores for the two codes respectively. The tokens highlighted by yellow (for code 427.31)
or blue (for code 428.0) show the importance of them based on the value of sentence-weighted word-level attention scores. The deeper the colour, the higher
the (sentence-weighted) attention scores, and thus the more important the highlight words or sentences contributes to the model prediction. Only the first part (11
tokens) of each sentence was shown for a clearer display.

Especially with the sentence parsing (“HLAN+LE+sent split”,

4.7. Comparison of Model Explanations
Following the previous section, we further qualitatively anal-

see the last row in Figure 5, corresponding to the visualisation

yse and compare the interpretability of the HLAN model and

in Figure 4), we can clearly see which sections of the discharge

other baseline models. Table 5 shows how CNN, CNN+att,

summary, along with words, contribute more to predict the la-

HAN, HA-GRU, and HLAN, all with label embedding initial-

bel.

isation, highlight the “important” part of a random document

It is also interesting to see how the proposed model inter-

(number 24) to predict two different labels (427.31 and 428.0).

pret when it predicted a medical code not previously assigned

The CNN12 and CNN+att chose the most salient n-grams based

by the coding professionals. We selected some representative

on the max-pooling and the attention mechanism, respectively

“false positive” results from the HLAN+LE model with sen-

[7]. HLAN and its downgraded models, HA-GRU and HAN,

tence splitting in Table 6. We presented the prediction results

alternatively, highlighted the important sentences and words.

and the highlighted explanations to an experienced clinician to

The distinction is that HAN has the same highlights of the same

validate and deduce the potential reason for the error. In Table

document for different labels (columns in Table 5), and HA-

6, we observe that the model can explain the predictions with

GRU has the same word-level but different sentence-level high-

key sentences and words, therefore it is easier for us to know

lights across labels, while HLAN can highlight the most salient

where there may have been a problem. For example, for the

words and sentences for different labels. This gives HLAN the

first two rows, “doc-68” and “doc-19” in MIMIC-III-50, the
highlighted words and sentences are quite relevant to the non-

most comprehensive interpretability among the models.
Compared to CNN, we observe that CNN+att generated a

coded, “false positive” ICD-9 code, indicating that there might

more relevant set of n-grams. This is in accordance with the

have been missed coding or the disease was a past disease of

conclusion in [7]. We also found that the attention weights from

the patient.

CNN are unstable, i.e. the suggested n-grams from CNN were

The false positives in “doc-1” and “doc-65” in MIMIC-III-

not the same among different runs. Compared to the interpre-

shielding are errors related to the wrong correlations learned

tation with n-grams, highlighting the key sentences and words
can produce a more comprehensive interpretation, as the lat-

from the data, particularly regarding the high granularity and
subtle difference among sub-type diseases. In “doc-1”, the

ter is based on the whole hierarchical structure of a document.

highlighted words “htn elev lipids” show that the patient has a
certain type of hypertension, but does not necessarily mean the

12 We further normalised the scores of n-grams in CNN based on max-pooling

predicted code 416.0 for “Primary pulmonary hypertension”.

from [7] to probabilities, to be comparable to the attention scores in other models.

In “doc-65”, the strongly highlighted word “metastasis” actu14

Table 5: Comparison of model interpretability across deep learning models of true positive predictions on a random document (index 24) in the MIMIC-III-50
dataset
Model
doc-24 to predict 427.31 (Atrial fibrillation)
doc-24 to predict 428.0 (Congestive heart failure, unspecified)
n-gram-1 (0.105): admission date discharge date service surgery
n-gram-1 (0.096): ...surgical intensive care unit she required maxCNN+LE
allergies patient recorded as having no known...
imum pressor support to maintain sufficient cardiac index...
n-gram-2 (0.083): ...surgical or invasive procedure ex lap r hemin-gram-2 (0.075): ...past medical history pmhx a fib aortic stenosis
colectomy mucous fistula ileostomy gj tube placement history of
chf last ef in osteoporosis reflux...
present illness...
n-gram-3 (0.075): ...presented to location un with perforated visn-gram-3 (0.071):...on ventilation support family meeting at latter
cous hd stable upon transfer to location un...
evening decided to make patient cmo patient...
n-gram-1 (0.017): ...pressor support to maintain sufficient cardiac
n-gram-1 (0.026): ...upon arrival past medical history pmhx a fib
CNN+att+LE
index patient did show signs of distal ischemia to extremities by
aortic stenosis chf last ef in osteoporosis reflux doctor first name
the afternoon urine output post...
hx appendectomy many years ago social history non...
n-gram-2 (0.023): ...diagnosis cardiopulmonary arrest perforated
n-gram-2 (0.011): ...past medical history pmhx a fib aortic stenosis
colon atrial fibrillation ventilatory support discharge condition
chf last ef in osteoporosis reflux doctor first name hx appendecdeath discharge instructions none followup instructions none
tomy many years ago social history non contributory...
sent-1 (0.34): medical history pmhx a fib(0.374) aortic stenosis chf(0.206) last ef in osteoporosis reflux(0.097) doctor first name hx
HAN+LE
appendectomy many(0.28) years ago social history non contributory
sent-2 (0.18): arthritis fosamax q week(0.039) coumadin(0.282) qd discharge medications none discharge disposition expired discharg diagnosis cardiopulmonary(0.019) arrest(0.109) perforated(0.134) colon(0.119) atrial(0.173) fibrillation(0.023) ventilatory(0.047) support discharge condition death
sent-3 (0.11): admission(0.201) date(0.263) discharge(0.05) date(0.055) service(0.075) surgery(0.118) allergies(0.062) patient(0.013) recorded(0.054) as having no known allergies to drugs attending first name3(0.021) lf(0.02) chief complaint perforated
bowel(0.046) major
HA-GRU+LE sent-1 (0.62): arthritis fosamax q week coumadin(0.06) qd disDid not predict 428.0 (i.e. false negative)
charge medications none discharge disposition expired discharge
diagnosis cardiopulmonary arrest perforated colon atrial fibrillation(0.94) ventilatory support discharge condition death
sent-1 (0.54): arthritis fosamax q week coumadin qd discharge
sent-1 (0.71): medical history pmhx a fib aortic stenosis chf(1.0)
HLAN+LE
medications none discharge disposition expired discharge diagnolast ef in osteoporosis reflux doctor first name hx appendectomy
sis cardiopulmonary arrest perforated colon atrial(1.0) fibrillation
many years ago social history non contributory
ventilatory support discharge condition death
sent-2 (0.18): medical history pmhx a fib(1.0) aortic stenosis chf
last ef in osteoporosis reflux doctor first name hx appendectomy
many years ago social history non contributory
sent-1 (0.8): past medical history pmhx a fib aortic stenosis
sent-1 (0.49): discharge diagnosis cardiopulmonary arrest perfo+sent split
rated colon atrial fibrillation(1.0) ventilatory support discharge
chf(0.888) last ef(0.112) in osteoporosis reflux doctor first name
condition death discharge instructions none followup instructions
hx appendectomy many years ago social history non
none
sent-2 (0.41): past medical history pmhx a fib(1.0) aortic stenosis
chf last ef in osteoporosis reflux doctor first name hx appendectomy
many years ago social history non
∗ CNN and CNN+att suggested top n-grams, while HAN, HA-GRU, and HLAN suggested key sentences (“sent-”) and words in the sentences. “+sent split”
denotes the HLAN model using real sentence splits. The numbers in the parentheses are the attention scores (e.g. for HLAN, αw and α s ) in the models.
∗∗ For CNN and CNN+att, some of the suggested top-3 n-grams were combined together if any of them overlapped; up to five tokens before and after the
top n-grams were also displayed.
∗∗∗ For HAN, HA-GRU, and HLAN, the sentences were selected by those with sentence-level attention scores above 0.1 and the words were selected by
those with the word-level attention scores above 0.01. Both HAN and HA-GRU predicted 427.31 but not 428.0. The word- and sentence-level attention
weights of HAN are shared for all labels, therefore the interpretation is the same for both columns.

ally is related to pancreatic cancer, rather than the more com-

may be related to that “hypercalcemia” (appeared in both sent-

mon lung cancer as predicted. This wrong correlation may

1 and sent-2) can be caused by cancer, while neutropenia can

be due to the imbalance of vocabularies in the training data:

be caused by treatments like cancer chemotherapy. The word

there are 94 (about 2% out of 4,593) discharge summaries in

“chemotherapy” was highlighted in another sentence with an

the training data where “pancreatic” and “metasta” appeared

attention weight 0.09 (not presented as below the 0.1 thresh-

together in MIMIC-III-shielding, while there are significant

old) and the word “neutropenia” in the document was not in-

more discharge summaries (661, about 14%) where “lung” and

cluded during the padding process. While it is very likely

“metasta” appeared together.

that the neutropenia was induced by the drug for chemotherapy
(that is, 280.03, Drug induced neutropenia), we did not find di-

The error in the last example was due to the subtle differ-

rect words in the report to point the cause of the disease (thus

ence between two codes (280.00 vs 280.03). We noticed some

280.00, Neutropenia, unspecified, is also appropriate).

unexpected highlights (e.g. the local oncologist’s name code)
In general, we observe that the label-wise attention mecha-

in the last example (“doc-95” in MIMIC-III-shielding). This
15

Table 6: Examples of false positives of HLAN (with label embedding “+LE” and sentence splitting “+sent split”) on MIMIC-III-50 and MIMIC-III-shielding
Document index (dataset)
False positive ICD-9 Explanation with the most relevant sentences and words by atpotential reason
code
tention scores
sent-1 (0.32): discharge diagnosis septic shock due to asdoc-68 (MIMIC-III-50)
427.31 (Atrial fibrillation) cending cholangitis choledocholithiasis atrial fibrillation(1.0)
missed coding
with rapid ventricular response pulmonary emboli deep venous
thrombosis upper gi bleed peptic ulcer
sent-2 (0.31): past medical history recent pe dvt afib(1.0) htn
hypotension hypothyroidism cad mild chf
sent-3 (0.25): she was found to have bilateral pe s and new
afib(1.0) and started on coumadin
doc-19 (MIMIC-III-50)
401.9
(Hypertension sent-1 (0.84): decision made to proceed with primary right topast disease or missed
NOS, or Unspecified tal knee arthroplasty past medical history htn(1.0) asthma alcoding
essential hypertension)
lergies diabetes social history nc family history nc
416.0 (Primary pulmonary sent-1 (0.45): brief hospital course year old female with
subtle difference in
doc-1 (MIMIC-III-shielding)
hypertension)
h o mild alzheimer s disease cea in htn(0.177) elev(0.145) language (regarding the
lipids(0.659) bladder ca who presents as a transfer
type of hypertension)
sent-2 (0.36): past medical history mild alzheimer s disease
l cea in htn(0.284) elev(0.167) lipids(0.518) bladder ca no
known metastasis
197.0 (Secondary
sent-1 (0.31): brief hospital course yo man with history of
subtle difference in
doc-65 (MIMIC-III-shielding)
malignant neoplasm of
metastatic(1.0) pancreatic cancer was admitted with dyspnea
language (regarding the
lung)
new ascites and profound hyponatremia
type of secondary cancer),
sent-2 (0.3): history of present illness yo cantonese and spanimbalance of vocabularies
ish speaking male with metastatic(1.0) pancreatic cancer was
or diseases in the training
admitted from the ed with dyspnea altered mental status and
data
sent-3 (0.1): metastatic(1.0) pancreatic cancer evidence of
progression of ct abdomen pelvis
280.00 (Neutropenia,
sent-1 (0.24): she has since been found to have a rising ldh and
subtle difference between
doc-95 (MIMIC-III-shielding)
unspecified)
hypercalcemia and decided with her local(0.538) oncologist dr
the predicted label 280.00
first name8(0.448) namepattern2 name stitle to
and the ground truth label
sent-2 (0.17): at presentation on she developed hypercalcemic
280.03 (Drug induced
with a calcium(1.0) of an elevated ldh
neutropenia)

nisms in the HLAN model can provide a more comprehensive

weights (e.g. rows such as w j , wk in W in Equation 1 or rows

explanation to support the predictions. For wrong or non-coded

Vwl in Vw in Equations 4), and also the top-10 similar labels

predictions, the explanations through highlighted sentences and

from original label embedding E, and then to see to what ex-

words can help us better understand the problem. This provides

tent the two sets of “top-10 similar labels” overlap. We used

an essential reference to help coding professionals use the sys-

the Jaccard Index to measure the degree of overlap between the

tem and help engineers fix the problems for the next system

two sets for each label, which is the size of the intersection di-

iteration.

vided by the size of the union of the two sets. We averaged the
Jaccard Index over the labels. Thus the final metric reflects how

4.8. Analysis of Label Embedding Initialisation

the layers can retain the semantics, i.e. label similarities, of the

We previously visualised the label embedding from the

label embedding E. We also used the models without the LE

MIMIC-III dataset reduced to two dimensions using T-SNE, in

initialisation as the control group and calculated this averaged

Figure 2. The visualisation intuitively shows how the label em-

Jaccard Index from their layers for comparison.

bedding can capture the correlations among ICD-9 codes derived from the coding practice in the clinical setting.

The results are displayed in Figure 5. We selected several

It is also interesting to know, after the dynamic update during

representative models that either were significantly improved

training, how the weights in the initialised layers (the final projection layer and the attention layer) preserve the semantics of

with LE initialisation approach or did not improve with LE ac-

the label embedding, and why, in a few cases, LE did not result

cording to the results in Tables 2-4. The experiment shows that
weights in the final projection layer (and the label-wise atten-

in a significant improvement. We thus extracted the weights in

tion layer, if applied) with LE initialisation (“+LE”) can capture

the learned layers and measured their similarity to the original

further label similarities from the label embedding. We also ob-

label embedding. Based on the idea of label similarity, we cal-

served a strong correlation between the performance improve-

culated the top-10 similar labels for every label based on the

ment with LE (see Tables 2-4) and the increase of averaged

pairwise cosine similarity of the rows in the initialised layer

Jaccard Index with LE initialisation (i.e. the extent that the ini16

tialised layers captures the semantics of LE after training, as

can better capture the label similarity from the data. This fur-

reflected in Figure 5). The models which are more enhanced by

ther contributes to the explainability of the overall approach.

LE (for example, CNN+att, with 6.6% improvement of Macro-

There are a few exceptions that LE did not improve the perfor-

AUC with “+LE” in Table 3) have a greater averaged Jaccard

mance, this may be due to the fact that the hierarchical layers

Index compared to the models without LE (0.76 vs. 0.42-0.43)

can already model certain label correlations when optimising

in Figure 5. On the contrary, the models which were not im-

the document-label matching.

proved with LE, e.g. HLAN and HAN, for automated coding,

In terms of the performance, for MIMIC-III-50, the HLAN

also, was also not affected by LE in terms of the averaged Jaccard Index. The less effect of LE on HLAN and HAN may

model with LE achieved significant better micro-level AUC

be because the hierarchical attention layers (especially with the

models; for MIMIC-III-shielding, HLAN and HAN performed

label-wise attention mechanisms) could already model certain

comparably to CNN (all around 97-98% micro-level AUC); for

label correlations through the document-level matching pro-

MIMIC-III, the previous state-of-the-art model CNN+att was

cess. In overall, the analysis supports the idea that LE initialisation, capturing the label correlations, is a key factor to en-

significantly boosted by LE initialisation, achieving best AUC
and F1 scores (Micro-level AUC of 98.6% and Micro-level F1

hance automated coding with deep learning based multi-label

of 52.5%).

(91.9%) and F1 score (64.1%) than the previous state-of-the-art

classification. Since LE can be visualised after dimensionality

It is worth nothing that the higher comprehensiveness in ex-

reduction (see Figure 2), this further serves as a mean to help

planation from HLAN is at the cost of further memory require-

explain the overall model.

ments and the training time13 . Thus, in practice, if there are
only limited computational resources (e.g. a single GPU with
12GB memory), we suggest training HLAN with a fewer num-

5. Discussion

ber of codes, e.g. equal or less than 50, in a sub-disease domain or for specific tasks (i.e. shielding-related diseases dur-

We have presented the results on the three datasets and anal-

ing COVID-19) that require higher model explainability for de-

ysed the interpretability of models and the layers initialised

cision making. We also notice that the vanilla CNN can be

with label embeddings.

trained relatively faster with significantly less memory require-

The main advantage of HLAN lies in its model explainabil-

ment; HAN and HA-GRU can also be applied as “downgraded”

ity, based on the label-wise word-level and sentence-level at-

alternatives of HLAN for tasks with larger label sizes. It is also

tention mechanisms. The qualitative comparison of model ex-

worth to explore to optimise the implementation and to distil the

planation suggests that the highlighted key words and sentences

model of HLAN to enable its application to large label sizes.

from HLAN tend to be more comprehensive and more accurate

While training deep learning models can be slow, during the

than, those from HAN or HA-GRU and the n-gram explana-

testing phase, the trained models perform reasonably efficient

tion from the CNN related models. Such explainable highlights

for real-time inference. On average, it requires less than 1/3

can be particularly helpful when medical coding professionals

second (330 milliseconds) to assign ICD codes with explain-

need to locate the essential part of a long clinical note. When

able highlights for a discharge summary with a CPU server us-

the model suggests a code, its accompanying explanation could

ing HLAN trained from MIMIC-III-50; and the CNN related

be served as a reference for professionals to validate whether

models can process even faster (see Table S3 in the Supple-

the code should be included. This has the potential to build the

mentary Material). This allows the efficient use of the models

users’ trust in the deep learning model and help identify missed

in real-time for automated coding.

and erroneous coding.

Also, the calibration threshold (default as 0.5) could be tuned

The label embedding initialisation approach boosted the per-

to adjust the precision and recall of the system when deploying

formance and reduced the variance of most models. The
method is efficient, not requiring further model parameters. It is

it to a coding department. While high precision is obtained
when suggesting a few top-ranked predictions, a system with

independent of the neural encoders, and can thus be applied to

a higher recall can help the coding professionals to prevent

various deep learning models for multi-label classification. Our
analysis on the LE initialised layers show that they can preserve

13 The estimated training and testing time of the models are in Table S3 in the
Supplementary Material.

the semantics in the pre-trained label embeddings and therefore
17

Figure 5: Averaged Jaccard Index between the sets of top-10 similar labels derived from the layers (final projection layer and label-wise attention layers with or
without label embedding initialisation) and from the label embedding (LE). The higher the averaged Jaccard Index, the more similar the overall semantics between
the layer weights and the pre-trained label embedding. Error bars show the standard deviation over the labels. Representative models are selected for all the three
datasets. “+LE” means label embedding initialised for the layer indicated in the closest left bar.

missed coding. A higher recall can be achieved by using a lower

past medical history rather than present diseases, nuances of

calibration threshold, e.g. 0.3-0.4. The results are also highly

language variations, imbalanced vocabularies, and high label

varied across labels, as seen in the per-label results in Figures 3.

granularity. The highlighted sentences and words helped us

A domain for future studies is therefore to investigate few-shot

better determine the cause of the problems. Since missed cod-

or zero-shot learning for the rare labels and we noticed one re-

ing is very common in real-world practice, as also pointed out

cent related work in [37], which is based on ICD-9 hierarchies

recently in [40], it is worth to adapt the current algorithms

and descriptions to better predict rare labels.

to capture missing labels and emerging new labels. Informa-

The results demonstrate the usefulness of label embedding

tion on the report template may further help the model select

to boost coding performance for most models. In this work,

the relevant part of a discharge summary and differentiate a

the label embedding was trained with the label sets in the

present disease from a past disease. Unable to capture the subtle

training data using the Continuous Bag of Words algorithm in

variations or labels is potentially related to wrong correlations

word2vec. Thus, it encodes the similarity of medical codes de-

learned from the imbalance of vocabularies and labels in the

rived from the real-world coding practice in the critical care unit

dataset. This may be addressed by incorporating various exter-

of the US hospital. This knowledge is distinct from the ICD-9

nal knowledge.

hierarchy, as visualised in Figure 2 and there may be contradictions between them. The advantage of the former is that it

6. Conclusion

directly learned the label correlation from the existing hospital
and does not require external knowledge. There are recently
more studies on leveraging the hierarchy for medical coding as

In this paper, we examined the existing deep learning based
automated coding algorithms and introduced a new architec-

in [38, 39]. One future direction is thus to combine the local

ture, Hierarchical Label-wise Attention Network (HLAN) and

knowledge with external knowledge for the task.

a label embedding initialisation approach for automated medi-

The analysis of false positives in the model (see Section 4.6

cal coding. We tested the approaches on the benchmark datasets

and Table 6) suggests further research in the area of automated

extracted from the MIMIC-III database, with the simulated task

medical coding. The errors are likely due to missed coding,

to predict ICD-9 codes related to the high-risk diseases selected
18

References

by the NHS for shielding during the COVID-19 pandemic. The
experiment results showed that HLAN has a more comprehen-

[1] T. Baumel, J. Nassour-Kassis, R. Cohen, M. Elhadad, N. Elhadad, Multilabel classification of patient notes: case study on ICD code assignment,
in: Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence, 2018, pp. 409–416.
[2] A. E. W. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng,
M. Ghassemi, B. Moody, P. Szolovits, L. A. Celi, R. G. Mark, MIMICIII, a freely accessible critical care database, Scientific Data 3 (1) (2016)
1–9. doi:10.1038/sdata.2016.35.
[3] D. J. Cartwright, ICD-9-CM to ICD-10-CM codes: What? why? how?,
Advances in Wound Care 2 (10) (2013) 588–592. doi:10.1089/wound.
2013.0478.
[4] A. Stewart, ICD-11 contains nearly 4x as many codes as ICD-10: Here’s
what WHO has to say, https://www.beckersasc.com/asc-coding-billingand-collections/icd-11-contains-nearly-4x-as-many-codes-as-icd-10here-s-what-who-has-to-say.html, accessed 2 April, 2020 (2018).
[5] M. H. Stanfill, M. Williams, S. H. Fenton, R. A. Jenders, W. R. Hersh, A
systematic literature review of automated clinical coding and classification systems, Journal of the American Medical Informatics Association:
JAMIA 17 (6) (2010) 646–651. doi:10.1136/jamia.2009.001024.
[6] S. Karimi, X. Dai, H. Hassanzadeh, A. Nguyen, Automatic diagnosis
coding of radiology reports: A comparison of deep learning and conventional classification methods, in: BioNLP 2017, Association for Computational Linguistics, Vancouver, Canada,, 2017, pp. 328–332. doi:
10.18653/v1/W17-2342.
[7] J. Mullenbach, S. Wiegreffe, J. Duke, J. Sun, J. Eisenstein, Explainable
prediction of medical codes from clinical text, in: Proceedings of the
2018 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1
(Long Papers), Association for Computational Linguistics, New Orleans,
Louisiana, 2018, pp. 1101–1111. doi:10.18653/v1/N18-1100.
[8] J. R. Geis, A. P. Brady, C. C. Wu, J. Spencer, E. Ranschaert, J. L. Jaremko,
S. G. Langer, A. B. Kitts, J. Birch, W. F. Shields, et al., Ethics of artificial
intelligence in radiology: summary of the joint european and north american multisociety statement, Canadian Association of Radiologists Journal
70 (4) (2019) 329–334.
[9] B. Goodman, S. Flaxman, European union regulations on algorithmic
decision-making and a “right to explanation”, AI magazine 38 (3) (2017)
50–57.
[10] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, E. Hovy, Hierarchical attention networks for document classification, in: Proceedings of the 2016
Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 2016, pp. 1480–
1489.
[11] J. Nam, J. Kim, E. Loza Mencı́a, I. Gurevych, J. Fürnkranz, Largescale multi-label text classification — revisiting neural networks, in:
T. Calders, F. Esposito, E. Hüllermeier, R. Meo (Eds.), Machine Learning and Knowledge Discovery in Databases, Springer Berlin Heidelberg,
Berlin, Heidelberg, 2014, pp. 437–452.
[12] J. P. Pestian, C. Brew, P. Matykiewicz, D. J. Hovermale, N. Johnson, K. B.
Cohen, W. Duch, A shared task involving multi-label classification of
clinical free text, in: Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, BioNLP ’07,
Association for Computational Linguistics, USA, 2007, p. 97–104.
[13] M.-L. Zhang, Z.-H. Zhou, A review on multi-label learning algorithms,
IEEE Transactions on Knowledge and Data Engineering 26 (8) (2014)
1819–1837.

sive explainability and better or comparative results to the previous state-of-the-art, CNN-based approaches and the downgraded models, HAN and HA-GRU. The proposed label embedding initialisation effectively boosted the performance of the
state-of-the-art deep learning models, capturing label correlations from the dataset, which reflects the coding practice.
Analyses on the experiment results of this work suggest that
future studies are required in several areas: incorporating external knowledge, learning to capture missed coding, rare labels, and emerging new labels. In particular, automated medical
coding work requires to be tested in real-world clinical settings
and iteratively improved with inputs from relevant professionals such as coders, nurses and clinicians. Thus an open area
to work on in the future is to adapt automated coding models
with human corrections in real-time, which is mostly related to
human-in-the-loop machine learning and active learning [41].
Inspire by these, we plan to further test and develop the approach to support the coding department in the NHS. We will
consult processionals to identify and address the issues involved
in deploying the system to facilitate coding staff and improve
efficiency, accuracy, and overall satisfaction.

Acknowledgement

The authors would like to thank Dr Johnson Alistair in the
MIMIC-III team to confirm to display the sentences of discharge summaries in this paper. The authors would also like
to thanks comments from Prof Cathierine Sudlow and other
members in the Clinical Natural Language Processing Research
Group in the University of Edinburgh. HD is supported by
Health Data Research UK (HDR UK) National Phenomics Resource Project; Wellcome Institutional Translation Partnership
Award (PIII032). VSP is supported by HDR UK National
Text Analytics Implementation Project; Wellcome Institutional
Translation Partnership Award (PIII029). HW is supported by
HDR UK fellowship MR/S004149/1; Wellcome Institutional
Translation Partnership Award (PIII054); The Advanced Care
Research Centre Programme at the University of Edinburgh;
The Health Foundation (I-qual-PPC). This work has also made
use of the resources provided by the Edinburgh Compute and
Data Facility (ECDF) (http://www.ecdf.ed.ac.uk/).
19

[29] Y. Kim, Convolutional neural networks for sentence classification, in:
Proceedings of the 2014 Conference on Empirical Methods in Natural
Language Processing (EMNLP), Association for Computational Linguistics, Doha, Qatar, 2014, pp. 1746–1751. doi:10.3115/v1/D14-1181.
[30] S. Gehrmann, F. Dernoncourt, Y. Li, E. T. Carlson, J. T. Wu, J. Welt,
J. Foote Jr, E. T. Moseley, D. W. Grant, P. D. Tyler, et al., Comparing deep
learning and concept extraction based methods for patient phenotyping
from clinical narratives, PloS one 13 (2) (2018) e0192360.
[31] R. Řehůřek, P. Sojka, Software Framework for Topic Modelling with
Large Corpora, in: Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, ELRA, Valletta, Malta, 2010, pp. 45–
50, http://is.muni.cz/publication/884893/en.
[32] X. Glorot, Y. Bengio, Understanding the difficulty of training deep feedforward neural networks, in: Proceedings of the thirteenth international
conference on artificial intelligence and statistics, 2010, pp. 249–256.
[33] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, X. Zheng, Tensorflow: A system for large-scale
machine learning, in: Proceedings of the 12th USENIX Conference on
Operating Systems Design and Implementation, OSDI’16, USENIX Association, Berkeley, CA, USA, 2016, pp. 265–283.
[34] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf,
E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, S. Chintala, Pytorch: An imperative style, highPerformance deep learning library, in: H. Wallach, H. Larochelle,
A. Beygelzimer, F. d'Alché-Buc, E. Fox, R. Garnett (Eds.), Advances
in Neural Information Processing Systems 32, Curran Associates, Inc.,
2019, pp. 8024–8035.
[35] J. Lee, W. Yoon, S. Kim, D. Kim, S. Kim, C. H. So, J. Kang, BioBERT:
a pre-trained biomedical language representation model for biomedical
text mining, Bioinformatics 36 (4) (2019) 1234–1240. doi:10.1093/
bioinformatics/btz682.
[36] T. Fawcett, An introduction to roc analysis, Pattern Recognition Letters
27 (8) (2006) 861 – 874, rOC Analysis in Pattern Recognition. doi:
https://doi.org/10.1016/j.patrec.2005.10.010.
[37] A. Rios, R. Kavuluru, Few-shot and zero-shot multi-label learning for
structured label spaces, in: Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Brussels, Belgium, 2018, pp. 3132–3142. doi:
10.18653/v1/D18-1352.
[38] M. Falis, M. Pajak, A. Lisowska, P. Schrempf, L. Deckers, S. Mikhael,
S. Tsaftaris, A. O’Neil, Ontological attention ensembles for capturing
semantic concepts in ICD code prediction from clinical text, in: Proceedings of the Tenth International Workshop on Health Text Mining
and Information Analysis (LOUHI 2019), Association for Computational Linguistics, Hong Kong, 2019, pp. 168–177. doi:10.18653/v1/
D19-6220.
[39] P. Cao, Y. Chen, K. Liu, J. Zhao, S. Liu, W. Chong, HyperCore: Hyperbolic and co-graph representation for automatic ICD coding, in: Proceedings of the 58th Annual Meeting of the Association for Computational
Linguistics, Association for Computational Linguistics, Online, 2020, pp.
3105–3114. doi:10.18653/v1/2020.acl-main.282.
[40] T. Searle, Z. Ibrahim, R. Dobson, Experimental evaluation and development of a silver-standard for the MIMIC-III clinical coding dataset, in:
Proceedings of the 19th SIGBioMed Workshop on Biomedical Language

[14] G. Tsoumakas, I. Katakis, I. Vlahavas, Mining multi-label data, in:
O. Maimon, L. Rokach (Eds.), Data Mining and Knowledge Discovery Handbook, Springer US, Boston, MA, 2010, pp. 667–685. doi:
10.1007/978-0-387-09823-4_34.
[15] H. Dong, W. Wang, K. Huang, F. Coenen, Automated social text annotation with joint multilabel attention networks, IEEE Transactions on Neural Networks and Learning Systems (2020) 1–15.
[16] M.-L. Zhang, Z.-H. Zhou, Multilabel neural networks with applications
to functional genomics and text categorization, IEEE Transactions on
Knowledge and Data Engineering 18 (10) (2006) 1338–1351. doi:
10.1109/TKDE.2006.162.
[17] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training
of deep bidirectional transformers for language understanding, in: Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Association for Computational Linguistics, Minneapolis, Minnesota, 2019, pp. 4171–4186.
doi:10.18653/v1/N19-1423.
[18] I. Chalkidis, M. Fergadiotis, S. Kotitsas, P. Malakasiotis, N. Aletras,
I. Androutsopoulos, An empirical study on large-scale multi-label text
classification including few and zero-shot labels (2020). arXiv:2010.
01653.
[19] Y. Chen, Predicting ICD-9 codes from medical notes – does the magic of
BERT applies here?, https://web.stanford.edu/class/archive/
cs/cs224n/cs224n.1204/reports/custom/report25.pdf, stanford CS224N Custom Project (Option 3) (2020).
[20] D. Bahdanau, K. Cho, Y. Bengio, Neural machine translation by jointly
learning to align and translate, in: 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings, 2015, pp. 1–15.
[21] E. Gibaja, S. Ventura, A tutorial on multilabel learning, ACM Computing
Survey 47 (3) (2015) 52:1–52:38.
[22] G. Kurata, B. Xiang, B. Zhou, Improved neural network-based multi-label
classification with better initialization leveraging label co-occurrence, in:
Proceedings of the 2016 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics, San Diego, California,
2016, pp. 521–526. doi:10.18653/v1/N16-1063.
[23] S. Baker, A. Korhonen, Initializing neural networks for hierarchical multilabel text classification, in: BioNLP 2017, Association for Computational
Linguistics, Vancouver, Canada,, 2017, pp. 307–315. doi:10.18653/
v1/W17-2339.
[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, J. Dean, Distributed
representations of words and phrases and their compositionality, in: Advances in neural information processing systems, 2013, pp. 3111–3119.
[25] K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares,
H. Schwenk, Y. Bengio, Learning phrase representations using RNN
encoder–decoder for statistical machine translation, in: Proceedings of
the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014, pp. 1724–1734.
[26] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv
preprint arXiv:1412.6980 (2014).
[27] L. v. d. Maaten, G. Hinton, Visualizing data using t-SNE, Journal of machine learning research 9 (Nov) (2008) 2579–2605.
[28] L. Song, C. W. Cheong, K. Yin, W. K. Cheung, B. C. Fung, J. Poon,
Medical concept embedding with multiple ontological representations.,
in: IJCAI, 2019, pp. 4613–4619.

20

Processing, Association for Computational Linguistics, Online, 2020, pp.
76–85. doi:10.18653/v1/2020.bionlp-1.8.
[41] R. M. Monarch, Human-in-the-Loop Machine Learning: Active learning and annotation for human-centered AI, Shelter Island, NY: Manning
Publications Company, 2021, version 11, MEAP Edition (Manning Early
Access Program).

21

arXiv:2010.15728v3 [cs.CL] 25 Feb 2021

Table S1: List of ICD-9 codes in MIMIC-III-50 (50 codes, sorted by frequency in the training data) and per-label prediction results using Hierarchical Label-wise
Attention Network with label embedding initialisation (HLAN+LE).

MIMIC-III-50
ICD-9 code

Short Title∗

401.9
38.93
428.0
427.31
414.01
96.04
96.6
584.9
250.00
96.71
99.04
272.4
518.81
39.61
599.0
96.72
530.81
272.0
285.9
88.56
38.91
486
244.9
99.15
285.1
36.15
276.2
496
995.92
V58.61
507.0
038.9
39.95
585.9
88.72
410.71
403.90
305.1
276.1
311
37.22
V45.81
412
287.5
424.0
37.23
511.9
45.13
33.24
V15.82

Hypertension NOS
Venous cath NEC
CHF NOS
Atrial fibrillation
Crnry athrscl natve vssl
Insert endotracheal tube
Entral infus nutrit sub
Acute kidney failure NOS
DMII wo cmp nt st uncntr
Cont inv mec ven <96 hrs
Packed cell transfusion
Hyperlipidemia NEC/NOS
Acute respiratry failure
Extracorporeal circulat
Urin tract infection NOS
Cont inv mec ven 96+ hrs
Esophageal reflux
Pure hypercholesterolem
Anemia NOS
Coronar arteriogr-2 cath
Arterial catheterization
Pneumonia, organism NOS
Hypothyroidism NOS
Parent infus nutrit sub
Ac posthemorrhag anemia
1 int mam-cor art bypass
Acidosis
Chr airway obstruct NEC
Severe sepsis
Long-term use anticoagul
Food/vomit pneumonitis
Septicemia NOS
Hemodialysis
Chronic kidney dis NOS
Dx ultrasound-heart
Subendo infarct, initial
Hy kid NOS w cr kid I-IV
Tobacco use disorder
Hyposmolality
Cutaneous mycobacteria
Left heart cardiac cath
Aortocoronary bypass
Pneumococcus infect NOS
Thrombocytopenia NOS
Mitral valve disorder
Rt/left heart card cath
Pleural effusion NOS
Sm bowel endoscopy NEC
Closed bronchial biopsy
History of tobacco use

Frequency
(train, 8067
documents)
3233
2139
2115
1992
1921
1581
1525
1448
1416
1395
1287
1259
1186
1096
1067
969
953
926
852
801
773
765
761
736
726
719
694
646
613
604
569
567
549
544
530
520
513
504
494
493
482
479
477
471
451
438
421
415
407
397

Frequency
(test,
1574
documents)
195
210
165
172
181
102
100
135
470
95
91
422
148
203
121
91
138
435
266
108
215
157
548
87
340
233
362
155
84
51
155
778
196
127
104
187
187
255
402
251
228
60
181
258
174
226
149
160
247
72

Precision

Recall

F1

78.5
60.6
85.5
91.7
84.4
59.4
67.0
71.4
73.2
64.2
19.6
74.7
65.3
94.6
73.8
66.5
72.2
58.0
30.3
87.4
46.4
63.7
80.8
82.2
69.4
94.9
72.6
65.4
70.6
66.3
59.6
52.5
84.4
56.8
51.8
66.4
77.5
28.3
52.7
40.0
62.4
76.3
60.8
58.3
72.9
47.3
46.5
60.2
75.8
0.0

82.8
47.9
78.6
88.6
72.0
60.2
63.4
56.4
69.5
49.5
22.2
81.5
56.1
96.3
59.2
61.1
67.5
39.6
2.0
71.3
2.8
51.0
84.0
62.3
44.8
92.9
25.4
49.3
49.2
66.9
54.4
28.1
80.4
42.3
22.5
41.4
62.9
4.6
26.6
20.9
44.7
67.3
42.3
23.3
38.3
19.2
16.8
70.7
50.1
0.0

80.5
53.4
81.9
90.1
77.7
59.7
65.1
62.9
71.3
55.7
20.4
77.9
60.2
95.5
65.7
63.4
68.3
47.0
3.6
78.5
5.2
56.1
82.3
70.9
54.3
93.8
37.6
55.9
57.8
66.1
56.7
36.1
82.3
48.4
31.1
50.3
69.2
7.2
34.9
26.9
51.9
71.5
48.8
33.0
49.8
27.0
24.4
64.6
60.0
0.0

* Short titles of the ICD-9 codes are from https://mimic.physionet.org/mimictables/d_icd_diagnoses/
and https://mimic.physionet.org/mimictables/d_icd_procedures/.

Table S2: List of ICD-9 codes in MIMIC-III-shielding (20 codes, sorted by frequency in the training data) and per-label prediction results using Hierarchical
Label-wise Attention Network with label embedding initialisation (HLAN+LE).

MIMIC-IIIshielding ICD-9
code
197.0
745.5
996.81
042
441.2
416.0
746.4
288.00
238.75
996.82
238.71
494.0
288.0
996.85
238.7
770.2
501
288.03
289.59
446.4

Short Title

Frequency
(train, 4574
documents)
Secondary malig neo lung
656
Secundum atrial sept def
592
Compl kidney transplant
480
Shigella boydii
470
Thoracic aortic aneurysm
430
Prim pulm hypertension
375
263
Cong aorta valv insuffic
Neutropenia NOS
196
170
Myelodysplastic synd NOS
Compl liver transplant
169
Essntial thrombocythemia
164
Bronchiectas w/o ac exac
152
Neutropenia
136
Compl marrow transplant
133
Neoplasm of uncertain behav- 116
ior of other lymphatic and
hematopoietic tissues
108
NB interstit emphysema
Alastrim
103
Drug induced neutropenia
96
Spleen disease NEC
95
Wegener’s granulomatosis
49

Frequency
(test,
322
documents)
42
41
14
30
36
10
35
39
21
4
28
27
0
8
0

Precision

Recall

F1

82.1
95.3
94.1
97.7
86.3
54.0
94.5
51.2
87.4
49.5
74.6
87.6
0.0
71.9
0.0

84.8
83.7
97.1
99.3
73.9
60.0
76.3
18.5
50.5
77.5
46.8
71.1
0.0
77.5
0.0

83.3
89.0
95.4
98.5
79.5
56.7
84.0
26.5
63.5
60.1
56.4
76.5
0.0
74.3
0.0

0
5
17
14
1

0.0
44.4
47.0
71.9
20.0

0.0
56.0
16.5
45.0
20.0

0.0
48.8
23.0
55.0
20.0

* Short titles of the ICD-9 codes are from https://mimic.physionet.org/mimictables/d_icd_diagnoses/
and https://mimic.physionet.org/mimictables/d_icd_procedures/.

Figure S1: Distribution of label frequency in the training data for the datasets, MIMIC-III, MIMIC-III-50, and MIMIC-III-shielding.

Table S3: Model parameters, training time, and testing time from the datasets.

CNN* CNN+att* Bi-GRU* HAN
Parameter settings
Calibration threshold Th
0.5
0.5
0.5
0.5
Learning rate
0.003
0.0001
0.003
0.01
Batch size (training and testing)
16
16
16
128
Kernel size (or filter size)
4
10
# of words per document
2500
2500
2500
2500
# of words per sentence nt
25
# of sentences per document n
100
# of filters
500
50
512
Hidden size dh
100
Attention layer size (e.g. dw , d s in HLAN) 500
50
200
Final hidden layer size
500
50
512
400
Dropout rate
0.2
0.2
0
0.5
L2 penalty
0
0
0
0.0001
Training time, estimated in minutes∗∗
From MIMIC-III-50
5
50
40-50
10
From MIMIC-III-shielding
2.5
8
20-40
10
From MIMIC-III
250
1700
100-140
100
Testing time per document, estimated in milliseconds, GPU time / CPU time∗∗∗
From MIMIC-III-50
2
5
50
34 / 40
From MIMIC-III-shielding
3
3
43
32 / 40
From MIMIC-III
2
3
50
42 / 40

HA-GRU

HLAN

0.5
0.01
32
2500
25
100
100
200
400
0.5
0.0001

0.5
0.01
32
2500
25
100
100
200
400
0.5
0.0001

30
10-15
-

80
25-30
-

61 / 160
17 / 30
-

141 / 330
14 / 50
-

“-” denotes that the parameter is inapplicable to the model or the estimated time was not obtained.
* Parameter settings for CNN, CNN+att, and Bi-GRU are the same as in Mullenbach et al., 2018.
** All models were trained and tested using a single GeForce GTX TITAN X server.
*** For HAN, HA-GRU, and HLAN, testing times on a CPU server (4-core, Intel(R) Xeon(R) Platinum 8259CL
CPU @ 2.50GHz) were further reported (displayed after the GPU time).

