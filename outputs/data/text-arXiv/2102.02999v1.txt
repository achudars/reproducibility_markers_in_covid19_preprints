An Interaction Neyman-Scott Point Process
Model for Coronavirus Disease-19

arXiv:2102.02999v1 [stat.AP] 5 Feb 2021

Jaewoo Park1,2 , Won Chang3 , and Boseung Choi4
1

Department of Statistics and Data Science, Yonsei University
2

3

Department of Applied Statistics, Yonsei University

Division of Statistics and Data Science, University of Cincinnati
4

Division of Big Data Science, Korea University
February 8, 2021

Abstract
With rapid transmission, the coronavirus disease 2019 (COVID-19) has led to over 2
million deaths worldwide, posing significant societal challenges. Understanding the spatial
patterns of patient visits and detecting the local spreading events are crucial to controlling
disease outbreaks. We analyze highly detailed COVID-19 contact tracing data collected
from Seoul, which provides a unique opportunity to understand the mechanism of patient
visit occurrence. Analyzing contact tracing data is challenging because patient visits show
strong clustering patterns while clusters of events may have complex interaction behavior.
To account for such behaviors, we develop a novel interaction Neyman-Scott process that
regards the observed patient visit events as offsprings generated from a parent spreading
event. Inference for such models is complicated since the likelihood involves intractable
normalizing functions. To address this issue, we embed an auxiliary variable algorithm
into our Markov chain Monte Carlo. We fit our model to several simulated and real data
examples under different outbreak scenarios and show that our method can describe spatial
patterns of patient visits well. We also provide visualization tools that can inform public

1

health interventions for infectious diseases such as social distancing.

Keywords: infectious disease; doubly-intractable distributions; cluster point process; Bayesian
hierarchical model; Markov chain Monte Carlo

1

Introduction

Caused by the transmission of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2),
the coronavirus disease 2019 (COVID-19) was first reported in December 2019 in Wuhan, Hubei
providence, China (WHO, 2020). By February 2021, there have been 100 million confirmed cases
of COVID-19, with more than 2 million deaths. The disease spreads more quickly than influenza,
mainly through close contact with infected people (CDC, 2020). Human-to-human transmission
is most common for COVID-19, primarily via respiratory droplets or aerosols from an infected
person. Thus contact tracing, which records the travel paths of confirmed patients in detail, is
a highly effective disease control measure. Spatial point process models for contact tracing data
can provide useful insights into the mechanism of patient visits. Here, we propose a new point
process model for studying the probabilistic mechanism of patient visits. Our model can provide
useful epidemiological information such as a warning system for local hotspots.
Here we analyze the locations visited by confirmed patients in Seoul, South Korea. The
data set contains full contact histories of confirmed patients, and is hence a unique source for
point process modeling. Contact tracing data for most other countries contain only partial or
imperfect tracing records. We regard each visit in the contact tracing data as an event in the
point process model. Since such events are spatially clustered, a natural way to model this is
the Neyman-Scott point process (Neyman and Scott, 1952), which considers observed events as
offsprings generated around unobserved parents. In the epidemiological context, we can regard a
parent point as a cluster center of disease (i.e., spreading event), and offsprings are corresponding
clusters (i.e., patient visits).
Several computational methods have been developed for inference for point processes, including a minimum contrast method (Diggle, 2013) and pseudolikelihood approximation (Guan, 2006,
Diggle et al., 2010). However, such approaches are sensitive to the choice of tuning parameters
and may not be accurate in the presence of strong spatial dependence among points. Through
2

simulation studies, Mrkvička et al. (2014) reports that Bayesian estimation is the most precise
for the Neyman-Scott point process. Furthermore, we can easily adjust priors based on epidemiological knowledge. Therefore, the Bayesian framework can be practical for fitting hierarchical
point process models.
A simple Neyman-Scott process has limited applicability here because it assumes an independent parent process. Local spreading events (parents) may have complex interaction behavior,
leading to an intractable likelihood function; this is common in many spatial point process models. Several extensions for Neyman-Scott processes have been developed. Waagepetersen (2007),
Mrkvička et al. (2014), Mrkvička and Soubeyrand (2017) study inference for inhomogeneous
Neyman-Scott point processes. Yau and Loh (2012) considers a special case where the parent
process exhibits repulsion. Albert-Green et al. (2019) generalizes the Neyman–Scott process by
allowing the parents to follow the log-Gaussian Cox process (Møller et al., 1998). However, these
existing models may not be appropriate for our COVID-19 data because of the complex interactions of local spreading events. Unobserved spreading events attract each other at mid-range
distances because other spreading events likely to appear in nearby communities. At the same
time, spreading events repel each other at small distances to avoid merging. Otherwise, one
spreading event would become offsprings to others.
In this manuscript, we propose a novel parametric approach that exhibits interaction between
unobserved spreading events. This new approach can infer model parameters that describe
spatial patterns of spreading events. Our model allows us to detect unobserved spreading events,
thereby providing a practical warning system for coronavirus hotspots. Recently, Goldstein et al.
(2015) proposes an attraction-repulsion point process model by extending the Strauss process
(Strauss, 1975) that only allows repulsion behavior. Russell et al. (2016) uses such a process
to model different types of interactions among animals, including herding behavior and collision
avoidance. In this manuscript, we develop an interaction Neyman-Scott point process to describe
this behavior. We incorporate the attraction-repulsion (Goldstein et al., 2015) process into the
parent process. Our model includes an intractable normalizing function, posing computational
and inferential challenges. To address this, we adopt a novel auxiliary variable Markov chain
Monte Carlo (MCMC) (Møller et al., 2006, Liang, 2010), that can avoid the direct evaluation of
intractable normalizing functions.
3

Note that susceptible-infected-recovered (SIR) models (Kermack and McKendrick, 1927, Dietz, 1967) are also popular for modeling infectious disease dynamics. There is a vast literature on
modeling the COVID-19 data based on SIR type models (Choi and Ki, 2020, Fanelli and Piazza,
2020, Anastassopoulou et al., 2020, Barlow and Weinstein, 2020). These models are typically
based on daily counts of infection, death, and recovery. Rather than modeling confirmed cases,
as in SIR models, we fit our point process model to locations visited by confirmed patients from
our contact tracing data. Our approach can provide epidemiological insights for social distancing
in daily life by using the full information of visiting history.
The remainder of this paper is as follows. In Section 2, we describe the COVID-19 contact
tracing data in Seoul, South Korea. In Section 3, we introduce a new interaction NeymanScott process model and discuss its computational and inferential challenges. We describe our
MCMC algorithm for this model and provide implementation details. In Section 4, we apply our
methods to both simulated and real COVID-19 data sets. We show that our methods can detect
the sources of spreading events and describe the spatial patterns of patient visits. Furthermore,
we provide a disease risk map that can give important epidemiological interpretations. In Section
5, we conclude the paper with a discussion and summary.

2

Data Description and Exploratory Analysis

In this section, we provide the background of our contact tracing data and summarize the results
from exploratory data analysis.

2.1

COVID-19 Contact Tracing Data

We study the COVID-19 contacting tracing data in Seoul. During the early stages of the pandemic in South Korea, Daegu and the North Gyeongsang (NGO) province were the central areas
of the disease outbreak. However, the regional government only provided data on daily new
infections, deaths, and recoveries, rather than disclosing full contact tracing information. On the
other hand, confirmed COVID-19 patients in Seoul were perfectly under control, with their full
contact information recorded. When a patient is confirmed to be infected by a screening clinic, he
or she is immediately quarantined. In addition, the local government tracks the patient’s moving
4

PATID
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX
XXX

Date time
0307
0302
0302
0301
0301
0301
0301
0229
0229
0229
0229
0229
0229

Address
Chunhodaero 145, Seoul
Gyungheedaero 7-1,Seoul
HanChunro 58, Seoul
Hoegiro 19, Seoul
Hoegiro 18, Seoul
Imunro 37, Seoul
HanChunro 58, Seoul
Shinimunro 40, Seoul
Shinimunro 24, Seoul
Hoegiro 21, Seoul
Imunro 37, Seoul
Hwigyeongro 2, Seoul
HanChunro 58, Seoul

Trans
car
other
car
other
route
route
other
route
route
route
car
route
other

Description
Screening Clinic
Café
House
Café
Restaurant
Café
House
Hosipital
Pharmacy
Restaurant
Café
Café
House

Latitude
959371
960469
962047
960541
960500
960812
962047
961735
961718
960558
960812
961181
962047

Longitude
1952879
1954862
1956113
1954855
1954704
1954692
1956113
1956027
1956025
1954887
1954692
1955099
1956113

Table 1: Movement path of a confirmed patient. For confidentiality, we do not report the patient’s
ID (PATID).
paths and posts the routes on local government websites. This information is legally disclosed
for two weeks and then archived. This code follows the “Response Guidelines to Prevent the
Spread of COVID-19 (local government)” (KDCA, 2020). The contact tracing data sets have
been collected directly from these websites.
Table 1 provides examples of contact tracing data for a patient. For each individual, the
information for travel route (transportation, places visited, coordinates) has been recorded. For
example, the patient in Table 1, visited 13 places from February 29 to March 7, 2020. This patient
was confirmed infected at a screening clinic in Seoul and immediately quarantined. Figure 1
illustrates a graphical representation of the travel routes of five patients, including the patient
in Table 1. To study the spatial patterns of patient visits, we regard each visit (coordinate) as
a realization of the point process.
In this paper, at any given time point, we fit a point process model based on contact tracing
data accumulated over the last two weeks. According to the basic data analysis for the early
stages of the COVID-19 spread in South Korea and China, two weeks is the mean period of
recovery from infection (Ki, 2020, Choi and Ki, 2020). Two weeks is also the period for epidemic
investigation conducted by the local health authority for all confirmed cases. Therefore, when we
construct a warning system for COVID-19 at a certain time, modeling patient visits in the last
two weeks would be most useful. As illustration examples, we fit our model for non-overlapping
8 different time periods from February 20th to June 11th in 2020. Our goal here is to examine

5

Figure 1: Travel routes of five confirmed patients in the Dondaemoon-gu area. Each color
represents a patient’s path.
how our model works and provide important epidemiological insights for these different time
periods with various disease spreading patterns. In particular, in the main document we focus
on three consecutive time periods that end at March 19th, April 2nd, and April 15th which can
be considered as severe, moderate, and mild outbreak cases, respectively in terms of overall visit
numbers. The results for other time periods are provided in the supplementary material.

2.2

Exploratory Data Analysis

Spatial point processes provide a natural solution to model spatial patterns for locations visited
by confirmed patients. Here, we provide the motivation for a new interaction point process model
with some exploratory data analysis. Let X = {x1 , · · · , xn } be a realization of point process over
the bounded spatial domain S ∈ R2 . The pair correlation function (PCF) is useful for exploring

6

PCF
7

Locations visited by confirmed
g^R i pl ey (r )

4
1

2

1940000

3

1950000

g (r )

5

6

1960000

g P oi s (r )

940000

950000

960000

970000

1000

2000

3000

4000

5000

6000

Figure 2: The left panel shows the locations visited by patients (March 6 - March 19, 2020). The
right panel shows the estimated PCF from the observation. The red line indicates theoretical
PCF under complete spatial randomness.
point process observations (Stoyan and Stoyan, 1994). The PCF is defined as

J(r) =

1
K 0 (r),
2πr

K(r) =

i
|S| h X
1
E
kxi −xj k≤r ,
n2
i6=j

where |S| is the area of the spatial domain. Here, Ripley’s K(r) is the expected density of points
within distance r. Under complete spatial randomness, K(r) = πr2 , which results in J(r) = 1.
J(r) > 1 indicates that points have a tendency to cluster at distance r (attraction) while J(r) < 1
indicates that points tend to remain apart at distance r (repulsion).
Figure 2 illustrates an example of COVID-19 data and their PCF. We observe that patient
visits are spatially clustered (J(r) > 1). Therefore, a point process model for COVID-19 should
capture such behavior. The Neyman-Scott process (Neyman and Scott, 1952) is widely used to
study spatially aggregated point patterns. Furthermore, the Neyman-Scott process can detect
cluster centers, which can be regarded as spreading events in our application; identifying the
spreading center of the disease is crucial in our problem. Consider the Neyman-Scott process
X = ∪c∈C Xc , where Xc is the offspring (clusters) and C is the parent (cluster centers). Given
parent process C, offspring Xc , c ∈ C follows an independent Poisson process with intensity
αk(u − c, ω). Here, ω controls the spread of offsprings around their parent, and α determines the
7

expected number of offsprings per each cluster. With the Gaussian kernel k(u − c, ω) with mean
c and variance ω 2 , X is called the Thomas process (Thomas, 1949). The basic Neyman-Scott
process models the unobserved parent process C as a simple Poisson process.
The Neyman-Scott process is appropriate for modeling COVID-19 data because the locations
visited by confirmed patients, Xc , are clustered around the unobserved spreading event C. From
this, we can detect the local spreading events (cluster center of patient visits) of COVID-19.
However, local spreading events C may have complex interactions. At mid-range distances r,
spreading events tend to clump together because other spreading events likely to exist in the
nearby region. At small r, spreading events tend to remain apart; otherwise, they would become
offsprings of other spreading events, and hence two clusters can be ‘merged.’ The basic NeymanScott process cannot describe such behavior because the basic model considers an independent
Poisson process for C. In the following section, we add another layer of complexity to the
basic Neyman-Scott process. This new model can provide epidemiological interpretation for
understanding spreading events for COVID-19.

3

An Interaction Neyman-Scott Point Process Model

In this section, we propose a new Neyman-Scott process by incorporating interaction behavior
into C. This new parametric approach can detect unobserved spreading events of COVID-19 and
describe their patterns. Based on this, we can provide a warning system for higher risk regions.

3.1

Model

Consider the realization of Neyman-Scott point process X = {x1 , · · · , xn } in the bounded plane
S ⊂ R2 (Seoul domain). This indicates the observed locations visited by the confirmed patients.
Let C = {c1 , · · · , cm } be their unobserved parent process. In our context, each ci is the location
of a spreading event in a local community. Note that Seoul has a two-level hierarchical administrative structure, Gu-Dong: Gu consists of multiple Dongs and each Dong has average size of
1.427 km2 . We focus on modeling spreading events with a size of Dong because this coincides
with most citizens’ life radius. From this, we can provide a warning system for distancing in
daily life. Spreading events tend to remain apart (repulsion) at small distances to avoid merging;
8

otherwise, they would become offsprings to each other. At mid-range distances, they tend to
clump together (attraction), because other spreading events likely to appear in nearby areas.
Spreading events become independent at sufficiently large distances. To describe such patterns,
we model the parent in the Neyman-Scott process as an attraction-repulsion interaction point
process (Goldstein et al., 2015). The locations of unobserved spreading events (parent process)
is modeled as
κm

Qm

i=1

f (C|κ, θ1 , θ2 ) =

n
P
o
exp min
i6=j log (φ(Di,j )), 2
Z(κ, θ1 , θ2 )

,

(1)

where the interaction function is

φ(D) =


2
√


θ1
θ 1 −
(D
−
θ
)
2
θ2


1 +

1
(0.5(D−D2 ))2

0 < D ≤ D1

(2)

D > D1

Here, D1 , D2 are set to make the interaction function φ(D) continuously differentiable (Goldstein et al., 2015). The interaction function φ(D) is determined by the distance between two
parent points ci , cj . There are three parameters {κ, θ1 , θ2 } in this model: κ controls the overall
intensity of the parent process and {θ1 , θ2 } control the shape of the interaction function φ(D).
θ1 gives the peak value of φ, whereas θ2 gives the location of the peak value. When the distance between spreading events Dij becomes too small, φ is less than 1, which means spreading
events show repulsion behavior. On the other hand, as Dij becomes larger, φ is increased, which
means spreading events show attraction behavior at mid-range distance. Such attractions become weaker as the distance between the spreading events becomes larger. From this, (1) can
describe the attraction-repulsion behavior of local spreading events.
Given the local spreading events, the locations visited by the confirmed patients can be
modeled as


f (X|C, α, ω) = exp |S| −

Z X
m

n X
m
Y
αk(u − ci , ω)du
αk(xj − ci , ω).

S i=1

(3)

j=1 i=1

We use a symmetric Gaussian kernel with a center at each spreading event ci and variance ω 2 .

9

This results in a higher intensity of patient visits around the spreading events. In our context,
α controls the expected number of confirmed patients for each spreading event, and ω controls
the levels of spreading events activity.

3.2

Computational and Inferential Challenges

The proposed model in the previous section has a hierarchical structure. Unobserved local
spreading events (parent process) follow the spatial interaction process defined in (1) and (2).
Observed patient visits (offsprings) are distributed around the unobserved parents with Gaussian
kernels. The Bayesian framework is useful for such hierarchical models in that it can easily
quantify the model parameters’ uncertainty using MCMC. With priors p(Θ), the joint posterior
distribution is

π(Θ, C|X) ∝ f (X|C, α, ω)f (C|κ, θ1 , θ2 )p(Θ),

Θ = {α, ω, κ, θ1 , θ2 }.

(4)

Although (4) is a natural way to construct a joint posterior distribution, there are computational
and inferential challenges to fit such a model due to the intractable normalizing functions. The
model for spreading events in (1) can be written as

f (C|κ, θ1 , θ2 ) =

h(C|κ, θ1 , θ2 )
=
Z(κ, θ1 , θ2 )

κm

n
P
o
exp
min
log
(φ(D
)),
2
i,j
i=1
i6=j

Qm

Z(κ, θ1 , θ2 )

.

(5)

Here, the calculation of normalizing function Z(κ, θ1 , θ2 ) requires integration over the spatial
domain S, which is infeasible. Inference for such models is challenging because an intractable
Z(κ, θ1 , θ2 ) is a function of model parameters. The resulting posterior (4) is referred to as a
doubly-intractable distribution (Murray et al., 2006).
Several computational methods have been proposed to address this issue. By assuming conditional independence of points, Besag (1974) proposed the pseudolikelihood that does not have
intractable normalizing functions. Due to its convenience, pseudolikelihood approximations are
often used in many point process applications (e.g., Diggle et al., 2010, Tamayo-Uria et al.,
2014). However, it is well known that such approximations are unreliable when there is strong
dependence among points (Mrkvička et al., 2014). Geyer and Thompson (1992) propose the-

10

oretically justified Monte Carlo maximum likelihood methods, which maximize a Monte Carlo
approximation to the likelihood. However, this has limited applicability because the algorithm
requires gradients for h(C|κ, θ1 , θ2 ), which is not available for interaction point process models
such as the one defined above. Bayesian approaches can be an alternative for such cases. Several
Bayesian methods have been proposed for doubly-intractable distribution (see Park and Haran
(2018) for a comprehensive review). Among current approaches, Park and Haran (2018) reports
that double Metropolis-Hastings (DMH) is the most practical method for point process models.
DMH can avoid the calculation of Z(κ, θ1 , θ2 ) and alleviate memory issues, which can be serious
for adaptive algorithms (Atchade et al., 2008, Liang et al., 2016). In the following section, we
formulate DMH that can carry out Bayesian inference for an interaction Neyman-Scott point
process model.

3.3

Markov Chain Monte Carlo

Here, we describe an MCMC algorithm for the attraction-repulsion Neyman-Scott point process
(t)

(t)

model. Consider the model parameters Θ(t) = {α(t) , ω (t) , κ(t) , θ1 , θ2 } and latent parent process
C(t) in (4) at the t-th iteration. We update the parameters successively. Offspring parameters
α(t+1) , ω (t+1) can be updated from

α(t+1) , ω (t+1) ∼ f (X|C(t) , α(t) , ω (t) )p(α(t) , ω (t) )

with a joint prior density p(α(t) , ω (t) ). We can update parent parameters from
(t+1)

κ(t+1) , θ1

(t+1)

, θ2

(t)

(t)

(t)

(t)

(t)

∼ f (C(t) |κ(t) , θ1 , θ2 )p(κ(t) , θ1 , θ2 )
(t)

with a joint prior density p(κ(t) , θ1 , θ2 ) (see Section 4.1 for how we choose the priors in our
problem). Compared to updating offspring parameters, updating parent parameters is challenging due to the intractable normalizing function in (5). Intractable Z(κ, θ1 , θ2 ) leads to the

11

intractable acceptance probability in MCMC as

α = min

0





0

0
0
0
0
0
(t) (t)
h(C(t) |κ0 ,θ1 ,θ2 )
p(κ , θ1 , θ2 )q(κ0 , θ1 , θ2 |κ(t) , θ1 , θ2 )
0
0
0
Z(κ1 ,θ1 ,θ2 )

(t) |κ(t) ,θ (t) ,θ (t) )
0
0
(t) (t)
(t) (t)

2
1
 h(C (t)
p(κ(t) , θ1 , θ2 )q(κ(t) , θ1 , θ2 |κ0 , θ1 , θ2 )
(t) (t)

,1

(6)




Z(κ1 ,θ1 ,θ2 )
0





0

for the proposed parameters κ0 , θ1 , and θ2 . To avoid direct evaluation of the intractable normalizing functions in α, we incorporate double Metropolis-Hastings (DMH) (Liang, 2010) into
our MCMC algorithm. Instead of evaluating the intractable normalizing functions in the α,
DMH sampler generates an auxiliary variable A from (1) via a birth-death MCMC (Moller and
Waagepetersen, 2003). We provide details of the birth-death MCMC in the supplementary material. Note that the auxiliary variable A is from the same probability model as C and can be
regarded as synthetic point process data. The acceptance probability of DMH is now given as
(
α = min

0

0

(t)

(t)

0

0

0

0

0

(t)

)

(t)

h(C(t) |κ0 , θ1 , θ2 )h(A|κ(t) , θ1 , θ2 )p(κ , θ1 , θ2 )q(κ0 , θ1 , θ2 |κ(t) , θ1 , θ2 )
(t)

(t)

0

(t)

0

(t)

(t)

(t)

0

0

h(C(t) |κ(t) , θ1 , θ2 )h(A|κ0 , θ1 , θ2 )p(κ(t) , θ1 , θ2 )q(κ(t) , θ1 , θ2 |κ0 , θ1 , θ2 )

, 1 . (7)

This does not include intractable terms because the introduction of A modifies the original densi(t)

(t)

(t)

0

(t)

0

0

0

ties in (6) by multiplying h(A|κ(t) , θ1 , θ2 )/Z(κ(t) , θ1 , θ2 ) into the numerator and h(A|κ0 , θ1 , θ2 )/Z(κ0 , θ1 , θ2 )
into the denominator. If the simulated auxiliary variable A resembles the parent process C, the
0

0

proposed parameters κ0 , θ1 , θ2 are likely to be accepted.
Finally, we obtain C(t+1) from
(t+1)

C(t+1) ∼ f (X|C(t) , α(t+1) , ω (t+1) )f (C(t) |κ(t+1) , θ1

(t+1)

, θ2

)

using a birth-death MCMC. Note that stationary distribution of the birth-death MCMC algorithm for updating C(t+1) is different from that of generating the auxiliary variable A in DMH.
The stationary distribution for generating the auxiliary variable follows (1) (see the supplementary material for details). Our MCMC algorithm is summarized in Algorithm 1.

12

Algorithm 1 MCMC for an attraction-repulsion Neyman-Scott process
(t)

(t)

Given Θ(t) = {α(t) , ω (t) , κ(t) , θ1 , θ2 } and C(t) at t-th iteration.
Part 1: Update offspring parameters: α(t) , ω (t) .
Propose α0 , ω 0 ∼ q(·|α(t) , ω (t) ) and accept it with probability


f (X|C(t) , α0 , ω 0 )p(α0 , ω 0 )q(α(t) , ω (t) |α0 , ω 0 )
α = min
,
1
f (X|C(t) , α(t) , ω (t) )p(α(t) , ω (t) )q(α0 , ω 0 |α(t) , ω (t) )
else reject (set α(t+1) = α(t) , ω (t+1) = ω (t) ).
(t)

(t)

Part 2: Update parent parameters: κ(t) , θ1 , θ2 .
0

0

(t)

(t)

Propose κ0 , θ1 , θ2 ∼ q(·|κ(t) , θ1 , θ2 ).
Generate an auxiliary variable A from the probability model using birth-death MCMC:
0
0
A ∼ f (C(t) |κ0 , θ1 , θ2 ).
Accept it with probability
)
(
0
0
0
0
0
0
(t) (t)
(t) (t)
h(C(t) |κ0 , θ1 , θ2 )h(A|κ(t) , θ1 , θ2 )p(κ0 , θ1 , θ2 )q(κ0 , θ1 , θ2 |κ(t) , θ1 , θ2 )
,1
α = min
0
0
0
0
(t) (t)
(t) (t)
(t) (t)
h(C(t) |κ(t) , θ1 , θ2 )h(A|κ0 , θ1 , θ2 )p(κ(t) , θ1 , θ2 )q(κ(t) , θ1 , θ2 |κ0 , θ1 , θ2 )
(t+1)

else reject (set κ(t+1) = κ(t) , θ1

(t)

(t+1)

= θ1 , θ2

(t)

= θ2 ).

Part 3: Update unobserved parent process: C(t) .
(t+1)

C(t+1) ∼ f (X|C(t) , α(t+1) , ω (t+1) )f (C(t) |κ(t+1) , θ1

13

(t+1)

, θ2

) using birth-death MCMC

4

Application

In this section, we apply our approach to simulated and real data examples. The computer code
for this is implemented in R and C++ using the Rcpp and RcppArmadillo packages (Eddelbuettel
et al., 2011).

4.1

Prior Specification

To complete the posterior specification we now explicitly define the prior distributions. In
Neymann-Scott process, there is a strong dependence between α and ω. The same observed
pattern can be regarded as points generated from a small number of parents, with each of them
has a large number of offsprings (large α, large ω), or they may come from a large number of
parents, with each of them has a small number of offsprings (small α, small ω). To avoid such
identifiability issues, we need to set the upper and lower bounds for them using uniform priors
(Møller and Waagepetersen, 2007, Kopeckỳ and Mrkvička, 2016).
As pointed out in Section 3.1, we focus on modeling spreading events in Dong scale. To this
end we set lower and upper bound for ω based on the average size of a Dong. This encourages
that patient visits from different Dongs come from different spreading events. Therefore, we set
p
p
the range for ω to [ |S|/70, |S|/25]. We assume that each spreading event (parent) generates
at least 3 and at most 30 patient visits (offsprings) in a Dong on average. This choice of priors can
avoid identifiability issues in the Neyman-Scott point process while maintaining interpretability
and modeling flexibility.
The prior range for κ needs to be determined in consideration of the overall intensity and the
offspring intensity α. The overall intensity is around 6 × 10−7 , computed as dividing the average
number of patient visits within two weeks by the area of Seoul |S|. The average number of patient
visits is computed over the 8 time periods. Since κ controls for parent process intensity and α
controls for average number of offsprings per each parent, κ × α should be around the overall
intensity 6 × 10−7 . By specifying the prior of κ to be uniform with range [1 × 10−10 , 1 × 10−6 ],
κ × α belongs to the range [3 × 10−10 , 3 × 10−5 ] so that the resulting range can include the overall
intensity 6 × 10−7 .
Similar to ω, we set a uniform prior for θ2 whose upper and lower bounds are proportional

14

Scenario 1
Truth
Estimates
95%HPD
Scenario 2
Truth
Estimates
95%HPD
Scenario 3
Truth
Estimates
95%HPD

α

ω

κ × 107

θ1

θ2

6
5.70
(4.79, 6.62)

360
370.34
(356.27, 390.39)

1.2
1.13
(0.39, 2.05)

1.5
1.85
(1.25, 2.67)

600
626.81
(500.02, 798.47)

5
5.58
(4.72, 6.52)

400
400.02
(373.65, 427.80)

1.0
1.18
(0.60, 1.79)

1.5
1.40
(1.00, 1.93)

650
684.59
(500.02, 937.61)

4
4.12
(3.20, 5.02)

440
423.73
(387.68, 461.51)

0.5
0.75
(0.34, 1.22)

1.5
1.64
(1.03, 2.36)

700
716.71
(500.03, 941.41)

Table 2: Inference results for simulated data sets. 100,000 MCMC samples are generated, discarding the first 50,000 as burn-in. Posterior mean estimates are reported for each parameter.
The highest posterior density (HPD) is calculated using the coda package.
p
p
to the average size of a Dong. We use a uniform prior with range [ |S|/70, |S|/25] so that θ2
gives the location of the peak value within a Dong. To allow for attraction, we set the prior for
θ1 to be uniform with range [1, 3] as in Goldstein et al. (2015).

4.2

Simulated Data

We now conduct a simulation study to validate our method. We first simulate the parent process
C from (1) with true parent parameters κ, θ1 and θ2 . We then simulate offsprings X from (3)
centered around each parent point with true offspring parameters α and ω. We consider three
different scenarios here: In Scenario 1, we emulate COVID-19 data with a severe outbreak. This
has numerous local spreading events (m = 129) and each of them also generates a large number
of offsprings. This results in n = 798 patient visits in total. In Scenario 2, we consider a moderate
outbreak. This has fewer spreading events (m = 93) and each generates a moderate number of
offsprings; the simulated patient visits consisted of n = 446 points. Finally, in Scenario 3, we
consider a mild outbreak in which we have the smallest number of spreading events (m = 56)
and patient visits (n = 239).
Table 2 indicates that the true parameter values used in all scenarios are estimated with
reasonable accuracy. We also compare the true and recovered parent points in Figure 3. We
obtain the recovered parent points from the last iteration of the MCMC algorithm (i.e., C(t) in

15

March 19th
Estimates
95%HPD
April 2nd
Estimates
95%HPD
April 15th
Estimates
95%HPD

α
5.42
(4.69, 6.11)
α
4.61
(3.88, 5.25)
α
4.08
(3.24, 4.93)

κ × 107
1.33
(0.57, 2.06)
κ × 107
1.00
(0.43, 1.71)
κ × 107
0.56
(0.25, 0.88)

ω
357.40
(356.26, 359.63)
ω
357.44
(356.26, 359.74)
ω
358.55
(356.26, 363.21)

θ1
1.72
(1.31, 2.21)
θ1
1.92
(1.37, 2.58)
θ1
2.08
(1.34, 2.99)

θ2
547.43
(500.00, 638.49)
θ2
553.22
(500.02, 646.51)
θ2
568.40
(500.01, 699.50)

Table 3: Inference results for real data. 100,000 MCMC samples are generated, discarding the
first 50,000 as burn-in.
Algorithm 1). We observe that our method can detect spreading events well as there are good
agreements between true and fitted points in all scenarios. Trace plots for number of parents
also indicate that the MCMC chain from Algorithm 1 converges.

4.3

COVID-19 Contact Tracing Data Analysis

Parameter Interpretation We now apply our method to the real observational data described in Section 2.1. The parameter estimation results for time periods that end at March
19th, April 2nd, and April 15th are summarized in Table 3. These three consecutive periods
can be regarded as severe, moderate, and mild outbreaks, respectively, in terms of the number
of patient visits. Parameter estimation results for other time periods are provided in the supplementary material. The average number of offspring points per each parent (α) and the intensity
for parent (κ) change as the overall number of visits changes; that is, more overall events lead
to higher α and κ values. The width of the Gaussian kernel controlled by ω, on the other hand,
stays similar. For April 15th, when the total number of visits is relatively small (n = 190), α
takes a lower value as well.
The estimated values for the remaining two parameters θ1 and θ2 describe the interaction
between parent points and show how clusters of the events are distributed in Seoul. The distance
for maximum interaction, determined by θ2 , increases as the number of parents reduces, reflecting
a sparser distribution of the parent events. Nevertheless, from the θ1 estimates (which are
significantly greater than 1), parent points in all periods show clear attraction at the location
given by θ2 (around 550m). This implies that different event clusters tend to appear near each

16

other rather than independently.

Visualization for COVID-19 Risk

From the estimated values of α, κ, and ω, we can create

an intensity map for patient visit events. Since local spreading events cause rapid community
transmission, it is essential to avoid the higher risk locations in daily life. Understanding the
probabilistic mechanism occurring patient visits and detecting local spreading events (hotspots)
are key to manage disease outbreaks. Let α̂ and ω̂ be the posterior mean of α and ω respectively.
Given the parent points from the last iteration of the MCMC, denoted as ĉ1 , · · · , ĉm , the spatial
intensity function for offspring points is given by

g(x) =

m
X

αk(x − ĉi , ω̂)

(8)

i=1

for any x ∈ S. This map can be used to identify high-risk areas where the intensity exceeds a
certain threshold set by administrative decision. Figure 5 illustrates the intensity map g(x) and
high-risk areas defined as g(x)/14 > 1.427 km2 , which corresponds to roughly one patient per
1.427 km2 each day. Here we divide g(x) by 14 to convert the intensity computed for two weeks
into the intensity for one day. The area 1.427 km2 is the average size of each Dong in Seoul, the
smallest administrative district.
The hotspots shown in Figure 5 present different types of spreading events. For example,
the hotspots in Guro-gu (bottom left corner of the map) are caused by a group infection from a
call center building around March. The event led to multiple detected confirmed cases. On the
other hand, the hotspots in Jungrang-gu (top right corner in the map) are mostly caused by a
single patient. This patient moved around multiple places in the local area, which resulted in
many close contacts. The former gained considerable media attention, and people became aware
of the potential risk in the community. The latter, on the other hand, did not receive media
coverage considering privacy protection, and the local community was largely unaware of the
risk. Our approach may provide a way to warn local people without revealing information about
the specific contagious individual. From Figure 5, we observe that the overall intensity decreases
as time goes, indicating the outbreaks had been controlled around mid-April. In summary, these
visualizations allow authorities to identify contagion risk hotspots and help them to set up public

17

health interventions while maintaining privacy protection.

Visualization for Risk Boundaries Our approach can also provide a way to generate “risk
boundaries” within a short time period (such as one day), assuming that the event distribution
within that period can be approximated by a model based on the previous two weeks. Such
boundaries are potentially useful for issuing public health advisories. The left column of Figure
6 shows that the patient visits occurred on April 3rd mostly concentrated within the areas with
high intensity g(x), given by the existing parent points (ĉ1 , ..., ĉm ), but there are also points
located slightly away from high intensity areas. However, there are no points that are clearly
far away from the existing high intensity areas either. Therefore, these points can be viewed as
offspring events from new parents that are created near the existing parents.
The right column of Figure 6 shows the risk boundaries that consider both the occurrence
of new parent points and the range of offspring densities created by them. Specifically, risk
boundaries are represented as the orange circles, whose centers are the existing parent points
ĉ1 , . . . , ĉm . The radii are given as θ2 + 1.96ω, the sum of the distance that maximizes the
interaction between the parent points (θ2 ) and one side of the 95% interval for the offspring
density (1.96ω). As Figure 6 shows, these risk boundaries indicate how far new events can
reach given the existing parent points. The other periods also show qualitatively similar results
(Figures 4, 5 in the supplementary material).

5

Discussion

In this manuscript, we proposed a novel interaction Neyman-Scott point process for modeling
COVID-19 data. Our model can be used to study the spatial patterns of patient visits and detect
spreading events in local communities by considering location-based interactions. To address the
intractable normalizing functions involved in the posterior, we embed DMH (Liang, 2010) into
our MCMC algorithm. We apply our approach to COVID-19 data sets pertaining to Seoul, and
draw meaningful epidemiological conclusions based on parameter estimates. Furthermore, we
provide easy-to-interpret disease risk maps from the fitted results. Through simulation studies,
we show that our method can provide reasonably accurate parameter estimates and detect true

18

spreading events.
Here, we focus on developing a new cluster point process model by regarding each patient visit
as a realization from the process. Note that there are other spatial models that can be applied to
contact tracing data. Examples include dynamic models for movement tracks of animals (Russell
et al., 2016) and spatial gradient methods for modeling the spread of invasive species (Goldstein
et al., 2019). Adopting such methods for studying COVID-19 contact tracing data could provide
another interesting epidemiological insight.
Our method can be useful for planning public health interventions such as deciding the social
distancing levels. Social distancing is necessary to prevent the spread of infectious diseases,
especially for people in risk groups for severe coronavirus disease. However, raising the social
distancing level could adversely affect the local economy. Therefore, it is essential to measure
the degree of the COVID-19 risk: how dangerous is the current coronavirus outbreak? Based
on our approach, we can provide some guidelines for deciding the appropriate distancing levels
to minimize economic damage. We can quantify such risks based on model parameters. For
instance, α and ω estimates provide the expected number of patient visits per spreading event
and the levels of spreading events activity (range of spread). From the θ2 estimate, we can expect
the probable location of a new spreading event. Using these parameter estimates, disease control
authorities can decide the threshold for social distancing levels. Note that such interpretation is
not available from existing cluster point process approaches.
Furthermore, our proposed approach has some advantages considering privacy protection.
The disease risk maps allow authorities to alert local communities about disease hotspots without
revealing privacy-sensitive information. This is opposite to the current practice in South Korea,
where local governments or health authorities release each individual’s travel history; although
the names of individuals are not revealed, the released information can be used to infer the
identity of each patient. The method and ideas developed in this manuscript are generally
applicable to other infectious diseases as well.

19

Supplementary Material
The supplementary material available online provides details for birth-death MCMC algorithms
and fitted results for other time periods.

Acknowledgement
Jaewoo Park was supported by the Yonsei University Research Fund of 2020-22-0501 and the
National Research Foundation of Korea (NRF-2020R1C1C1A0100386811). Boseung Choi was
supported by the National Research Foundation of Korea (2020R1F1A1A01066082). The Ohio
Super Computer Center (OSC) provided part of computational resources for this study. The
authors are grateful to Tomáš Mrkvička for providing useful sample codes and the anonymous
reviewers for their careful reading and valuable comments. The authors are also grateful to Korea
Spatial Information & Community Co. Ltd. for their support with data and Sungjae Kim and
Eunjin Eom for data collection and organization.

20

Scenario 1

Trace plot of parents

160
150
140

CCdim[50000:1e+05]

120

1940000

130

1950000

y−coordinates

1960000

170

True
Recovered

950000

960000

970000

0

30000

40000

Scenario 2

Trace plot of parents

50000

95
90
85
75

80

CCdim[50000:1e+05]

1960000
1950000

70

1940000

940000

950000

960000

970000

0

10000

20000

30000

40000

x−coordinates

Index

Scenario 3

Trace plot of parents

70
65
50

1940000

55

1950000

CCdim[50000:1e+05]

75

1960000

80

True
Recovered

50000

60

y−coordinates

20000
Index

True
Recovered

y−coordinates

10000

x−coordinates

100

940000

940000

950000

960000

970000

0

x−coordinates

10000

20000

30000

40000

50000

Index

Figure 3: The left panel compares the true (circle) and recovered (triangle) parent points for
different scenarios. The right panel illustrates the trace plots of parents.

21

March 19th

Trace plot of parents

950000

960000

0

10000

20000

30000

40000

April 2nd

Trace plot of parents

50000

CCdim[50000:1e+05, 3]

1960000
1940000

100

1950000

120

130

Index

Offsprings
Parents

950000

960000

970000

0

10000

20000

30000

40000

x−coordinates

Index

April 15th

Trace plot of parents

55
40

1940000

1950000

CCdim[50000:1e+05, 4]

1960000

60

Offsprings
Parents

50000

50

940000

45

y−coordinates

140

970000

x−coordinates

110

940000

y−coordinates

130

CCdim[50000:1e+05, 2]

120

1950000
1940000

y−coordinates

1960000

150

Offsprings
Parents

940000

950000

960000

970000

0

x−coordinates

10000

20000

30000

40000

50000

Index

Figure 4: The left panel compares the true (circle) and recovered (triangle) parent points for real
data examples. The right panel illustrates the trace plots of parents.

22

Figure 5: (Left Column) Intensity map for patient visit events computed by the offspring intensity
function in (8). (Right Column) High risk area with the intensity greater than 1 patient / 1 day
1.427 km2 , roughly meaning one patient per day within a “Dong”.

23

Figure 6: The same intensity map as the left column in Figure 5 (left column) and the risk
boundaries defined as circles, whose centers are the existing sampled parent points ĉ1 , . . . , ĉm
and the radii are defined as θ2 + 1.96ω (right Column). The black dots in both columns show
events observed on the day following the last date of each time interval.

24

Supplementary Material for An Interaction
Neyman-Scott Point Process Model for
Coronavirus Disease-19
Jaewoo Park, Won Chang, and Boseung Choi
A

Birth-Death MCMC

Birth-death samplers (Moller and Waagepetersen, 2003) are often used to generate point processes given the model parameters. We propose adding a new point (birth), removing an existing
point (death), or moving a point with equal probability. To generate an auxiliary variable in
DMH, we use a birth-death sampler whose stationary distribution is f (C|κ, θ1 , θ2 ). Algorithm 2
summarizes this step. In our full MCMC algorithm (Algorithm 1 in the manuscript), we update C, given all the model parameters. Here, we use a birth-death sampler whose stationary
distribution is f (X|C, α, ω)f (C|κ, θ1 , θ2 ). Algorithm 3 summarizes this step.

25

Algorithm 2 Birth-death MCMC for generating the auxiliary variable in DMH
Given parent parameters κ, θ1 , θ2 and the point pattern C = {c1 , · · · , cm }.
Birth step: add a point with probability 1/3
Propose a new point ξ uniformly over the spatial domain S: C+ = C ∪ {ξ}
Accept it with probability

α = min

f (C+ |κ, θ1 , θ2 )|S|
,1
f (C|κ, θ1 , θ2 )(m + 1)



Death step: remove a point with probability 1/3
Remove an existing point η ∈ {c1 , · · · , cm }: C− = C \ {η}
Accept it with probability

α = min


f (C− |κ, θ1 , θ2 )(m − 1)
,1
f (C|κ, θ1 , θ2 )|S|

Move step: move a point with probability 1/3
0

Propose a new point ξ and remove an existing point η: C = C ∪ {ξ} \ {η}
Accept it with probability
(
α = min

)
0
f (C |κ, θ1 , θ2 )
,1
f (C|κ, θ1 , θ2 )

26

Algorithm 3 Birth-death MCMC for updating C in the full model
Given parent parameters α, ω, κ, θ1 , θ2 and the point pattern C = {c1 , · · · , cm }.
Birth step: add a point with probability 1/3
Propose a new point ξ uniformly over the spatial domain S: C+ = C ∪ {ξ}
Accept it with probability

α = min


f (X|C+ , α, ω)f (C+ |κ, θ1 , θ2 )|S|
,1
f (X|C, α, ω)f (C|κ, θ1 , θ2 )(m + 1)

Death step: remove a point with probability 1/3
Remove an existing point η ∈ {c1 , · · · , cm }: C− = C \ {η}
Accept it with probability

α = min


f (X|C− , α, ω)f (C− |κ, θ1 , θ2 )(m − 1)
,1
f (X|C, α, ω)f (C|κ, θ1 , θ2 )|S|

Move step: move a point with probability 1/3
0

Propose a new point ξ and remove an existing point η: C = C ∪ {ξ} \ {η}
Accept it with probability
(
α = min

)
0
0
f (X|C , α, ω)f (C |κ, θ1 , θ2 )
,1
f (X|C, α, ω)f (C|κ, θ1 , θ2 )

27

B

Analysis Results for Different Timelines
March 5th
Estimates
95%HPD
April 30th
Estimates
95%HPD
May 14th
Estimates
95%HPD
May 28th
Estimates
95%HPD
June 11th
Estimates
95%HPD

α
5.02
(4.40, 5.70)
α
3.19
(3.00, 3.58)
α
3.21
(3.00, 3.56)
α
5.13
(4.53, 5.79)
α
5.25
(4.50, 6.07)

ω
357.98
(356.26, 361.38)
ω
563.40
(402.32, 744.51)
ω
359.62
(356.26, 366.27)
ω
357.17
(356.26, 358.93)
ω
357.39
(356.27, 359.51)

κ × 107
0.89
(0.41, 1.43)
κ × 107
0.17
(0.07, 0.29)
κ × 107
0.63
(0.27, 1.03)
κ × 107
1.34
(0.66, 2.25)
κ × 107
1.07
(0.37, 1.93)

θ1
1.75
(1.25, 2.41)
θ1
1.66
(1.00, 2.65)
θ1
2.11
(1.43, 2.97)
θ1
1.66
(1.28, 2.13)
θ1
1.98
(1.41, 2.66)

θ2
611.67
(500.02, 802.75)
θ2
724.74
(500.14, 966.40)
θ2
585.78
(500.00, 745.21)
θ2
538.49
(500.01, 607.51)
θ2
548.45
(500.02, 644.46)

Table 4: Inference results for real data. 100,000 MCMC samples are generated, discarding the
first 50,000 as burn-in.

28

March 5th

April 30th

y−coordinates

1950000
1940000

1950000
1940000

y−coordinates

1960000

Offsprings
Parents

1960000

Offsprings
Parents

940000

950000

960000

970000

940000

960000

x−coordinates

May 14th

May 28th

970000

y−coordinates

1940000

1950000
1940000

1950000

1960000

Offsprings
Parents

1960000

Offsprings
Parents

y−coordinates

950000

x−coordinates

940000

950000

960000

970000

940000

x−coordinates

950000

960000

970000

x−coordinates

June 11th

y−coordinates

1940000

1950000

1960000

Offsprings
Parents

940000

950000

960000

970000

x−coordinates

Figure 7: Recovered parent points for the real data example. Circles indicate offsprings and
triangles indicate recovered parent points.

29

Figure 8: (Left column) Intensity map of the patient visit events. (Right column) High-risk area
with intensity greater than 1 patient/1 day 1.427 km2 , which roughly translates to one patient
per day within a “Dong”, the smallest administrative unit.

30

Figure 9: (Left column) Intensity map of the patient visit events. (Right column) High-risk area
with intensity greater than 1 patient/1 day 1.427 km2 , which roughly translates to one patient
per day within a “Dong”, the smallest administrative unit.

31

Figure 10: The intensity map (left column) and risk boundaries defined as circles, whose centers
are the existing sampled parent points ĉ1 , . . . , ĉm and the radii are defined as θ2 + 1.96ω (right
column). The black dots in both columns show the observed events during the day following the
last date of each time interval.

32

Figure 11: The intensity map (left column) and risk boundaries defined as circles, whose centers
are the existing sampled parent points ĉ1 , . . . , ĉm , and the radii are defined as θ2 + 1.96ω (right
column). The black dots in both columns show the observed events during the day following the
last date of each time interval.

33

References
Albert-Green, A., W. J. Braun, C. B. Dean, and C. Miller (2019). A hierarchical point process
with application to storm cell modelling. Canadian Journal of Statistics 47 (1), 46–64.
Anastassopoulou, C., L. Russo, A. Tsakris, and C. Siettos (2020). Data-based analysis, modelling
and forecasting of the covid-19 outbreak. PloS one 15 (3), e0230405.
Atchade, Y., N. Lartillot, and C. P. Robert (2008). Bayesian computation for statistical models
with intractable normalizing constants. Brazilian Journal of Probability and Statistics 27,
416–436.
Barlow, N. S. and S. J. Weinstein (2020). Accurate closed-form solution of the sir epidemic
model. Physica D: Nonlinear Phenomena, 132540.
Besag, J. (1974). Spatial interaction and the statistical analysis of lattice systems. Journal of
the Royal Statistical Society. Series B (Methodological) 36, 192–236.
CDC (2020). How COVID-19 spreads. https://www.cdc.gov/coronavirus/2019-ncov/preventgetting-sick/how-covid-spreads.html .
Choi, S. and M. Ki (2020). Estimating the reproductive number and the outbreak size of covid-19
in korea. Epidemiology and health 42.
Dietz, K. (1967). Epidemics and rumours: A survey. Journal of the Royal Statistical Society.
Series A (General), 505–528.
Diggle, P. J. (2013). Statistical analysis of spatial and spatio-temporal point patterns. CRC press.
Diggle, P. J., I. Kaimi, and R. Abellana (2010). Partial-likelihood analysis of spatio-temporal
point-process data. Biometrics 66 (2), 347–354.
Eddelbuettel, D., R. François, J. Allaire, J. Chambers, D. Bates, and K. Ushey (2011). Rcpp:
Seamless R and C++ integration. Journal of Statistical Software 40 (8), 1–18.
Fanelli, D. and F. Piazza (2020). Analysis and forecast of covid-19 spreading in china, italy and
france. Chaos, Solitons & Fractals 134, 109761.
34

Geyer, C. J. and E. A. Thompson (1992). Constrained Monte Carlo maximum likelihood for
dependent data. Journal of the Royal Statistical Society. Series B (Methodological), 657–699.
Goldstein, J., M. Haran, I. Simeonov, J. Fricks, and F. Chiaromonte (2015). An attractionrepulsion point process model for respiratory syncytial virus infections. Biometrics 71 (2),
376–385.
Goldstein, J., J. Park, M. Haran, A. Liebhold, and O. N. Bjørnstad (2019). Quantifying spatiotemporal variation of invasion spread. Proceedings of the Royal Society B 286 (1894), 20182294.
Guan, Y. (2006). A composite likelihood approach in fitting spatial point process models. Journal
of the American Statistical Association 101 (476), 1502–1512.
KDCA (2020).

Responseguidelines to prevent the spread of covid-19 (local government).

http://ncov.mohw.go.kr/en/ .
Kermack, W. O. and A. G. McKendrick (1927). A contribution to the mathematical theory
of epidemics. Proceedings of the royal society of london. Series A, Containing papers of a
mathematical and physical character 115 (772), 700–721.
Ki, M. (2020). Epidemiologic characteristics of early cases with 2019 novel coronavirus (2019ncov) disease in korea. Epidemiology and health 42.
Kopeckỳ, J. and T. Mrkvička (2016). On the Bayesian estimation for the stationary NeymanScott point processes. Applications of Mathematics 61 (4), 503–514.
Liang, F. (2010). A double Metropolis–Hastings sampler for spatial models with intractable
normalizing constants. Journal of Statistical Computation and Simulation 80 (9), 1007–1022.
Liang, F., I. H. Jin, Q. Song, and J. S. Liu (2016). An adaptive exchange algorithm for sampling
from distributions with intractable normalizing constants. Journal of the American Statistical
Association 111, 377–393.
Møller, J., A. N. Pettitt, R. Reeves, and K. K. Berthelsen (2006). An efficient Markov chain Monte
Carlo method for distributions with intractable normalising constants. Biometrika 93 (2), 451–
458.
35

Møller, J., A. R. Syversveen, and R. P. Waagepetersen (1998). Log Gaussian Cox processes.
Scandinavian journal of statistics 25 (3), 451–482.
Moller, J. and R. P. Waagepetersen (2003). Statistical inference and simulation for spatial point
processes. CRC Press.
Møller, J. and R. P. Waagepetersen (2007). Modern statistics for spatial point processes. Scandinavian Journal of Statistics 34 (4), 643–684.
Mrkvička, T., M. Muška, and J. Kubečka (2014). Two step estimation for Neyman-Scott point
process with inhomogeneous cluster centers. Statistics and Computing 24 (1), 91–100.
Mrkvička, T. and S. Soubeyrand (2017). On parameter estimation for doubly inhomogeneous
cluster point processes. Spatial statistics 20, 191–205.
Murray, I., Z. Ghahramani, and D. J. C. MacKay (2006). MCMC for doubly-intractable distributions. In Proceedings of the 22nd Annual Conference on Uncertainty in Artificial Intelligence
(UAI-06), pp. 359–366. AUAI Press.
Neyman, J. and E. Scott (1952). A theory of the spatial distribution of galaxies. The Astrophysical
Journal 116, 144.
Park, J. and M. Haran (2018). Bayesian inference in the presence of intractable normalizing
functions. Journal of the American Statistical Association 113 (523), 1372–1390.
Russell, J. C., E. M. Hanks, and M. Haran (2016). Dynamic models of animal movement
with spatial point process interactions. Journal of Agricultural, Biological, and Environmental
Statistics 21 (1), 22–40.
Stoyan, D. and H. Stoyan (1994). Fractals, random shapes, and point fields: methods of geometrical statistics, Volume 302. John Wiley & Sons Inc.
Strauss, D. J. (1975). A model for clustering. Biometrika 62 (2), 467–475.
Tamayo-Uria, I., J. Mateu, and P. J. Diggle (2014). Modelling of the spatio-temporal distribution
of rat sightings in an urban environment. Spatial Statistics 9, 192–206.

36

Thomas, M. (1949).

A generalization of Poisson’s binomial limit for use in ecology.

Biometrika 36 (1/2), 18–25.
Waagepetersen, R. P. (2007). An estimating function approach to inference for inhomogeneous
Neyman–Scott processes. Biometrics 63 (1), 252–258.
WHO (2020). Novel Coronavirus - China. https://www.who.int/csr/don/12-january-2020-novelcoronavirus-china/en/ .
Yau, C. Y. and J. M. Loh (2012). A generalization of the Neyman-Scott process. Statistica
Sinica, 1717–1736.

37

