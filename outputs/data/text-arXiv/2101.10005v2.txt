arXiv:2101.10005v2 [stat.ME] 2 Feb 2021

Low incidence rate of COVID-19 undermines confidence in
estimation of the vaccine efficacy
Yasin Memari
1

∗1

MRC Cancer Unit, University of Cambridge, Cambridge CB2 0XZ, UK
February 3, 2021

Abstract
Knowing the true effect size of clinical interventions in randomised clinical trials is key to
informing the public health policies. Vaccine efficacy is defined in terms of the relative risk or the
ratio of two disease risks. However, only approximate methods are available for estimating the
variance of the relative risk. In this article, we show using a probabilistic model that uncertainty
in the efficacy rate could be underestimated when the disease risk is low. Factoring in the baseline
rate of the disease, we estimate broader confidence intervals for the efficacy rates of the vaccines
recently developed for COVID-19. We propose new confidence intervals for the relative risk. We
further show that sample sizes required for phase 3 efficacy trials are routinely underestimated and
propose a new method for sample size calculation where the efficacy is of interest. We also discuss
the deleterious effects of classification bias which is particularly relevant at low disease prevalence.

Introduction
Vaccines are seen as the best control measure for the coronavirus pandemic. In this context,
understanding the true efficacy of the vaccines and clinical interventions is crucial. Randomised
clinical trials are conducted to systematically study the safety and the efficacy of an intervention
in a subset of the population before it is widely used in the general population. In
placebo-controlled vaccine trials, participants are randomised into vaccinated and unvaccinated
groups where cases of the disease or infection are allowed to accrue over time. In planning a
clinical trial, advance sample size calculation determines the size of the trial population needed to
detect a minimal clinically relevant difference between the two groups if such a difference exists.
The indicator for effectiveness of a vaccine is usually reduction of the cases in the vaccinated
group relative to the control group. However, it is sometimes naively assumed that the trial
participants who do not experience the event provide no information. Consequently, the event
rate or the incidence rate of the disease receives inadequate attention. For rare diseases, it is often
∗ ym255@cam.ac.uk

1

simply accepted that the accrual of the cases takes longer. Human clinical trials are also an area
where theory and practice are seldom consistent, as experiments in human populations are hardly
fully controlled experiments, not least due to unrealistic assumptions, loss to follow-up,
noncompliance, heterogeneity of treatment effect and the trial population, etc. [1] Therefore, it is
not uncommon that, by the time an interim analysis declares a significant finding, the original
assumptions used to define the statistical power of the study and the sample size are neglected.
In this article our interest is on evaluating the impact of the event rate, insofar as it could
affect the estimation of the efficacy rate. We show that low incidence rate of the disease could
lead to overestimation of confidence in the estimated efficacy rates. We propose a new method for
posterior probability of the vaccine efficacy that has a more subtle relationship with the event
rate. Using our approach, we obtain broader confidence intervals for the efficacy of the vaccines
recently developed for COVID-19. Based on our findings, we propose new confidence intervals for
the relative risk. A new method for sample size calculation in controlled efficacy trials is proposed
which is more robust at low disease prevalence. Also highlighted is the impact of classification
bias which could have large consequences when the disease risk is low.

Methods
Vaccine efficacy is defined as the proportionate reduction in the risk of disease or infection in a
vaccinated group compared to an unvaccinated group. It is defined as (1-RR)×100% in terms of
the relative risk or the risk ratio, RR = πv /πc , where π are the incidence of the disease among
those exposed in the vaccinated and control groups. Throughout this paper we interchangeably
use the terms, incidence rate, disease risk, prevalence and event rate.
It is important to remember that the variables πv and πc are scaled binomials as they
represent sample proportions. Assuming equal person-time exposure in the two groups, the
efficacy is often summarised in terms of the numbers of cases in the vaccinated and unvaccinated
groups, tv and tc respectively:
πv
tv
α=1−
≃1− .
(1)
πc
tc
It appears in the literature that only approximate methods are available for the variance of the
ratio of two binomial parameters [2, 3]. The consensus method that is commonly used to assign
confidence intervals to the risk ratio is credited to Katz et al [3]. The method is based on
asymptotic normality of logarithm of the ratio of two binomial variables. Assuming independence
of the incidence rates, it follows that var(log(πv /πc )) = var(log(πv )) + var(log(πc )). Using a
Taylor series, the variances are approximated as var(log(π)) ≈ var(π)/π 2 where Wald method is
often used to set var(π). Then two-sided 95% confidence intervals on the efficacy (e.g. see [4–7])
can be written as
r


1 − πc
1 − πv
.
(2)
+
95%CL : 1 − exp ln(RR) ± 1.96
tv
tc
Hereafter we refer to equation 2 as pooled Wald approximation. We will show that the method
underestimates the variance espcially when the incidence rate is low.
Equation 2 sets out the large sample asymptotic variance of the risk ratio. However, Wald
method used to define var(π) is known to be unreliable when π is small. One may use alternative
binomial proportion confidence intervals, however, log normality of the ratio might not hold and
the variance of (the logarithm of) the ratio may be irreducible. Hightower et al [5] raised question

2/16

about the credibility of the confidence limits when the efficacy is high and the disease risk is low.
Also, O’Neill [8] noted that, when t ≪ n, the variance of ln(RR) in equation 2 remains fairly
stable and quickly converges to 1/tv + 1/tc .
Ratio distributions are known to have heavy tails and often no finite variance. If one were to
model the likelihood function for the efficacy defined in equation 1 in terms of independent
incidence rates, the choice of the prior probabilities for πv and πc would be critical. One can
readily verify that the variance of the ratio of two binomial distributions increases as binomial
probabilities decrease. Uninformative priors could simply cancel out by the division and the
dependence of the posterior on the prevalence would not become obvious. Analytical solutions
using independent incidence rates may also be hard to obtain.
For an analytical solution, we model the efficacy in terms of conditional probabilities of the
disease risks. Independence of the probabilities of the incidence rates is neither necessary nor ideal
when calculating the efficacy, as equation 1 imposes a constraint on the two variables. Under a
binomial model with overall prevalence of π = t/n in both groups and total population size of n,
overall number of cases t = tc + tv follows t ∼ Bin(n, π), then, from equation 1 assuming
tc ∼ Bin(t, 1/(2 − α)), we expect tc ∼ Bin(n, π/(2 − α)). Were we to use Poisson distributions for
t and tc , tc conditional on t would still follow a binomial distribution. Modeling the efficacy in
terms of conditional probabilities has previously been suggested [4]. This notation enables to
explicitly parametrise the likelihood function in terms of the prevalence, irrespective of the priors
for πv and πc .
For a general solution accounting for classification bias we assume an imperfect diagnostic
procedure with sensitivity Se and specificity Sp. Then fraction of individuals who test positive for
the disease is sum of true positive rate and false positive rate:
T = Se × π + (1 − Sp) × (1 − π)
= c1 + c2 π,

(3)

where c1 =1-Sp is the false positive rate and c2 =Se+Sp-1. The posterior distribution of α given
that tc is binomial follows as
p(tc |α, π, c1 , c2 )p(π)p(α)
g(α)
 
t 
n−tc
1
c1 + c2 π
n
c1 + c2 π c
∝
1−
f (π),
g(α) tc
2−α
2−α

p(α|tc , π, c1 , c2 ) =

(4)

where f (π) is the prior on π and we have assumed uniform prior on the efficacy α ∼ unif{0, 1}.
For a complete solution, the marginal likelihood g(α) can be written in terms of the incomplete
beta function (see e.g. [9]):
 

n
g(α) = f (π)
(c1 + c2 π) B(c1 + c2 π; tc − 1, n − tc + 1)
tc
− B((c1 + c2 π)/2; tc − 1, n − tc + 1) .

As we do not intend to impose a prior on the prevalence, f (π) in equation 4 cancels out and our
analysis, in essence, is likelihood based. One needs to remember that, the posterior in equation 4,
as it was derived from the second equality in equation 1, is valid only when the individuals are
equally divided between the two groups.
3/16

The mode of the posterior of α is obtained by setting the derivative of the log likelihood to
zero i.e. ∂ℓ/∂α = ∂ln(p(α|tc , π))/∂α = 0. This leads to
αmode = 2 −

n(c1 + c2 π)
,
tc

(5)

which corresponds to the maximum likelihood estimator (MLE). Cramér–Rao bound expresses a
lower bound on the variance of any unbiased estimator of α in terms of the inverse of the Fisher
information
1
Var(αmode ) ≥
,
(6)
I(α)
where the Fisher information I(α) is obtained as
2 i
h
h ∂
1 − tc
−1 2 i
ℓ(α|tc , π)
=n×E −
−
I(α) = E
∂α
2−α−π
2−α
n(c1 + c2 π)
=
.
(2 − α)2 (2 − α − (c1 + c2 π))

(7)

Here E denotes ‘expected’ over tc , where we have substituted E[tc ] = E[t2c ] = (c1 + c2 π)/(2 − α).
We will show that the conditional binomial model has a more subtle dependence on π compared
to the pooled Wald method.
Under certain regularity conditions and assuming asymptotic normality near MLE, 95%
confidence intervals on αmode can be estimated as
1.96
.
αmode ± p
I(αmode )

(8)

However, as the posterior distribution is asymmetric, especially when the efficacy is high, and the
intervals could lie outside [0,1], we will estimate the credible intervals computationally.

Results
Effect of incidence rate on vaccine efficacy
The posterior probability of vaccine efficacy given in its simplest form in equation 4 is ready for
inspection. Using binomial notation is particularly useful in enabling us to directly plug in the
numbers n, tc in the estimation of α. In this section we evaluate the impact of the incidence rate
on the efficacy and assign new confidence bounds to the efficacy of COVID-19 vaccines.
Firstly, we assume a diagnostic test with perfect sensitivity and specificity i.e. Se=Sp=1. In
the absence of misclassification, mode of the posterior in equation 5 corresponds to the
expectation α̂ = 1 − tv /tc . The larger n the smaller the variance of the posterior, however, for a
fixed n, the variance depends on π. Figure 1 shows the posterior probability of α plotted over a
range of π, for a fixed n on the left hand, and for a fixed t on the right hand, assuming true
vaccine efficacy of 70% and 90% respectively. Also plotted in vertical lines are the independent
95% confidence intervals from equation 2. As the event rate falls, the posterior distributions and
the confidence intervals become wider, however, for a fixed t (right plot) Wald intervals are stable
over a wide range of π, and more so when the efficacy is high. The proposed conditional binomial
model better represents the variability at low prevalence.
4/16

incidence rate

A
BCD
EFG
HIJK

()*

LMNOP
QRSTU

posterior probability



posterior probability

incidence rate

0.3
0.1
0.05
0.04
0.03
0.02
0.01
0.001



%&'



0 

"#$









1

!

+,-.

vaccine efficacy rate

/234

5678

9:;<

=>?@

vaccine efficacy rate

Figure 1. Posterior distribution of vaccine efficacy. Blue lines represent the normalised
posterior probabilities, while vertical lines show the independent pooled Wald confidence intervals.
Left hand plot assumes a fixed n=50,000 while right hand plot is for a fixed t=2,000. The general
trend holds for different values of the parameters. Wald method overstates the confidence in the
efficacy when t ≪ n.
Three clinical trials of the vaccines designed to prevent COVID-19 recently published their
interim phase 3 analysis results [10–12] with two of them reporting incredibly narrow 95%
confidence bounds on the efficacy. The reported case numbers and the efficacy rates for the
primary end points are provided in Table 1. Firstly, we note that, although the trials used
different models and priors on the efficacy, the reported confidence intervals almost perfectly
correspond with those obtained from equation 2. At large n the posterior is clearly dominated by
the data and the Bayesian and the frequentist are equivalent. Furthermore, especially where the
efficacy is high, pooled Wald confidence intervals hardly vary by the choice of n. If one were to use
different values for n in Table 1, over a large range of the values equation 2 would still give the
same confidence intervals. Therefore, the uncertainty caused by nv and nc is not accounted for.
We re-estimate the confidence intervals using the conditional binomial model presented in the
Methods. Using the case numbers reported, the likelihood of the data in equation 4 is obtained by
setting the prevalence to π = T = t/n. Then maximum a posteriori (MAP) and 95% credible
Table 1. Estimated efficacy of COVID-19 vaccine trials
Trial

AZ-Oxford (combined)
Pfizer-BioNTech
Moderna-NIH

Case numbers and reported efficacy rates

Estimated efficacy rate

case rate in
vaccinated

case rate in
control

reported
efficacy and 95% CI

estimated mode
and 95% credible interval

30/5,807
8/18,198
11/14,134

101/5,829
162/18,325
185/14,073

70·4% [54·8, 80·6]
95.0% [90.3, 97.6]
94.1% [89.3, 96.8]

70.3% [39.1, 90.9]
95.1% [74.9, 99.6]
94.1% [75.4, 99.5]

5/16

Figure 2. Estimated efficacy of COVID-19 vaccines. Posterior probabilities for the
conditional binomial model are plotted in red, with shaded areas representing the 95% credible
intervals. Blue curves are for when n is set to tv + tc and correspond with pooled Wald
approximation.
intervals for the efficacy rates are calculated computationally. The results shown in Table 1 are
contrasted with those reported. Although estimated modes are the same, our credible intervals
are wider. Incorporating the incidence rates has removed the overwhelming confidence originally
assigned to the point estimates. Note that, our approach requires the trial participants to be
equally divided between the vaccinated and unvaccinated groups which is roughly the case here.
Figure 2, in red, shows the posterior probabilities and the credible intervals for COVID-19
vaccines. Of note is that, if we were to hypothetically assume π = t/n = 1, the posterior in
equation 4 would produce the same intervals as those reported by the vaccine trials and Wald
approximation. Moreover, an independent binomial model with uninformative (e.g. uniform)
priors for πv and πc would produce the pooled Wald intervals.

Bias in case classification
So far we have assumed no bias in classification of the cases, however, imperfect diagnostic
procedure could lead to misclassification of the infected and uninfected individuals. In this section
we examine the effect of classification bias on estimation of the efficacy.
It is worth noting that equation 3 requires the observed infection rate T to be greater than the
false positive rate c1 = 1 − Sp. This relates to the ‘false positive paradox’ which implies that the
accuracy of a diagnostic test is compromised if the test is used in a population where the
incidence of the disease is lower than the false positive rate of the test itself. Furthermore, false
negatives could dominate at low incidence rates. When the disease risk is low, as the majority of
the tests are negative, a small false negative rate could lead to a situation where false negatives
outnumber the positive cases. These concepts are further explained in Note 1.
Figure 3 illustrates the effect of classification bias on the posterior probability of the vaccine
efficacy. The left plot shows the impact of a very small reduction in specificity to 0.999 (or
increase in false positive rate), while the right hand plot shows the effect of reduction in
sensitivity to 0.95 (or increase in false negative rate). A small loss of specificity could lead to
serious underestimation of the effect size as noted by [6, 7], but it could further lead to complete
loss of precision when the incidence rate is low. Loss of sensitivity results in overestimation of the

6/16



incidence rate

0.3
0.1
0.05
0.04
0.03
0.02
0.01
0.001



posterior probability

bcde

posterior probability

incidence rate

0.3
0.1
0.05
0.04
0.03
0.02
0.01
0.001

^_`a

Z[\]



~

VWXY

z{|}

fghi

jklm

nopq

vaccine efficacy rate

rstu

vwxy











¡

vaccine efficacy rate

Figure 3. Effect of imperfect diagnostic procedure. Misclassification error biases the vaccine
efficacy rate. Left plot shows the distributions for Se=1 and Sp=0.999, while the right plot is for
Se=0.95 and Sp=1, with n=50,000 in both. True efficacy rate is assumed at 70%. Imperfect
specificity, however small, could have disastrous effects when incidence rate is low, whereas lack of
sensitivity consistently inflates the efficacy rate.
efficacy irrespective of the disease rate. In these plots, we have considered a larger reduction in
sensitivity, not only because reduction in specificity has a more dramatic effect, but also as
diagnostic assays typically have relatively higher specificity than sensitivity, not least due to
specimen collection, insufficient viral load, stage of the disease, etc. [13] However, the effect of loss
of sensitivity is consistently toward shifting the mode in equation 5, or MAP, to higher values of
α, even at low incidence rates where negative predictive value is high.

Discussion
Base rate fallacy happens in situations where base rate information is ignored in favour of
individuating information. In probability terms, it often occurs when P (A|B) is confused or
interchangeably used with P (B|A) ignoring the prior probability P (A), e.g. probability of having
a rare disease given a positive test is wrongly equated to probability of a positive test given the
disease (or diagnostic sensitivity) ignoring the low prior probability of the disease itself. We
showed, in estimation of the vaccine efficacy when the disease rate is low, not only diagnostic
error could have deleterious effects, but also failure to appropriately integrate the information
about the base rate or incidence rate of the disease in the calculation could lead to
underestimation of the uncertainty.
Vaccine efficacy is defined in terms of the risk ratio πv /πc , that is the ratio of two binomial
proportions. Ratio distributions are known to have undefined variances, conversely, pooled Wald
method has been traditionally used to approximate the variance of the risk ratio. In this article,
we used a parametrisation that makes the dependence of the efficacy on the disease prevalence
explicit, without recourse to priors for πv and πc . Particularly, improper priors for πv and πc
7/16

Note 1
²³´µ

positive and negative predictive value

J. Balayla [14] noted that there exists
a prevalence threshold below which the
positive predictive value (PPV) of a
diagnostic test drops precipitously relative
to the prevalence. This means that at
too low a prevalence a positive test result
could more likely be a false positive than
a true positive. More underappreciated is
the impact of the negative predictive value
(NPV). Though, at low incidence rates,
the negative predictive value is nearly
100%, a small loss in sensitivity could
still have a marked effect as the negative
tests vastly outnumber the positive tests.
We could even have a situation where the
false negatives are more than the true and
false positives. To avoid these pitfalls,
the participants are pre-selected for their
symptoms before confirmation with the
assay. Though this raises the pre-test
probability, it could cause collider bias [15].

®¯°±

ª«¬­

¦§¨©

¢£¤¥
¶·¸¹

º»¼½

¾¿ÀÁ

ÂÃÄÅ

ÆÇÈÉ

prevalence

Figure 4. Positive (red) and negative
(blue) predictive values are plotted in terms
of population prevalence. Solid lines are
for to a diagnostic test with Se=Sp=0.99;
dashed lines are for Se=Sp=0.95. Vertical
lines show the prevalence thresholds.

could lead to underestimation of the variance. We conditioned tc on t = tc + tv and treated t as
another random variable. The resulting compound probability tc ∼ Bin(n, π/(2 − α)) is
over-dispersed and better captures the variability of the variance with π, whereas pooled Wald
confidence intervals are largely insensitive to π when π is small.
Wald method is intended as large sample approximation, however, the bulk of the life sciences
deals with small sample sizes. Therefore, it is likely that the confidence intervals reported in the
literature for the risk ratio (and odds ratio) are overly optimistic. By analogy of equations 6 and
8, one could define new confidence intervals for the risk ratio by substituting RR=(nc /nv )(1 − α)
for unequal sized groups in the Fisher information. The results can be written as
s
tv  1 + tv /tc − π
nc
,
(9)
1+
95%CL : RR ± 1.96
nv
tc
tv + tc
where π=(tv + tc )/(nv + nc ). The above intervals on the risk ratio are generally wider than but
converge to the pooled Wald method when the sample size is large. They may be preferred to
those obtained from equation 2 when the sample size is small or the relative risk is low.
Particularly, for a fixed sample size as RR nears zero, the upper bound in equation 9 remains
conservative and the lower bound takes negative values and becomes undetermined. On the
contrary, as RR nears zero, the pooled Wald intervals remain positive and shrink rapidly, giving
the counterintuitive impression of increased precision when the incidence rate is low (similar to
figure 2). However, as with Wald method, the confidence intervals in equation 9 were derived
8/16

using normal approximation which may not hold when RR significantly deviates from 1.
Our findings have implications for pre-planning the sample sizes for phase 3 efficacy trials.
Sample size calculation in case-control design is often stated as “How many samples are needed to
be randomised in order to conclude with 100(1 − β)% power that a treatment difference of size ∆
exists between the two groups at the level of significance of α?”. Therefore calculation of sample
size requires specification of the null hypothesis (expected treatment effect) and the alternative
hypothesis defined in terms of the difference in treatment outcomes. Here, α or type I error is the
probability of rejecting the null hypothesis where we should not, and β or type II error is the
probability of failing to reject the null hypothesis where we should reject it. Under the assumption
of normality of the treatment outcome, a generic formula for per-group sample size is derived in
terms of the two-sample t-test: [1]
n=

2σ 2
(z1−α/2 + z1−β )2 ,
∆2

(10)

where z-scores determine the critical values for the standard normal distribution. Therefore one
needs to specify the variance of the measured variable, the desired rates of error and the
magnitude of the treatment difference. Where the measured variable is binary (infected or
uninfected), the test statistic reduces to the test for the difference between two proportions.
Where the efficacy is of interest, the log normal approximation of the risk ratio from equation 2
may be used to define the test statistic. O’Neill [8] calculated the required sample sizes for a
two-sided test given the pooled Wald variance in equation 2. We re-write the total sample size in
this form:

(z1−α/2 + z1−β )2  (2 − VE)2
−
2
,
(11)
n=2
d2
π(1 − VE)
where

q


2
∆/(2(1 − VE)) + 1 .
d = ln ∆/(2(1 − VE)) +

Here VE is the anticipated efficacy and ∆ is the expected difference in VE in absolute terms. We
showed, however, that at low prevalence rate, equation 2 significantly underestimates the variance.
Using an inadequately small variance could lead to underestimation of the type I and type II
errors, potentially resulting in winner’s curse in underpowered studies [16, 17]. If instead we were
to use the proposed compound binomial model, one could simply substitute the variance in
equation 6. As in [8], under the assumption of normality and assuming ∆ is the difference
between the upper and lower limits of the confidence interval, substituting the margin of error as
∆/2 = zσ in equation 6 gives
n≥4

(z1−α/2 + z1−β )2
(2 − VE)2 (2 − VE − π).
π∆2

(12)

This equation sets out the total required sample size for a perfect diagnostic test, to be equally
divided between the two groups.
The proposed Cramér–Rao bound based formula 12 assumes normality of distributions of the
null and the alternative hypotheses, however, the binomial likelihood function is asymmetric, as is
pooled Wald intervals (see [8]), and becomes more so as the efficacy increases. Notwithstanding
the limitations, we plug in the critical values for α = 0.05 and power of 100(1 − β) = 80 per cent
(z1−α/2 = 1.96 and z1−β = 0.84) in equations 11 and 12. The resulting sample sizes are plotted in
Figure 5 for ∆ = 10% and different prevalence and efficacy rates.
9/16

1010

1010

Efficacy

30%
70%
90%
99%

30%
70%
90%
99%

108

sample size

sample size

108

Efficacy

6

ÐÑ

Ï

6

ØÙ

×

ÍÎ

ÕÖ

Ì

Ô

ÊË

ÒÓ

10−6

10−5

10−4

10−3

10−2

incidence rate

10−1

100

0.00

0.25

0.50

0.75

1.00

incidence rate

Figure 5. Sample size relative to disease prevalence. Total number of samples required
to detect with 80% power and level of significance of α = 0.05 a difference in the efficacy of
size ∆ = 10%. Solid lines represent Cramér–Rao bound and dashed lines represent pooled Wald
approximation. On the left, x-axis is on logarithmic scale. y-axis is logarithmic in both plots.
In Figure 5 the relationship between the sample size and the incidence rate looks linear on
log-log scale as they have a power law relationship. However, while the two methods coincide at
high incidence rates, pooled Wald method significantly underestimates the sample sizes at low
incidence rates especially when the efficacy is high (note that y-axis is on logarithmic scale).
Contrasting Figure 5 with the case rates in Table 1, it is clear that, to achieve the narrow
confidence bounds that Pfizer and Moderna have reported, they would have needed several times
more samples under pooled Wald method, and an order of magnitude more under Cramér–Rao
bound. If the event rate were to differ from that in the general population or if possibility of
misclassification was non negligible, such a discrepancy in incidence rates could cause such large
variations in the variance that the trial population could be unrepresentative of the larger
population. Table 2 provides the total sample sizes from Cramér–Rao bound formula 12 for
different levels of efficacy and effect size. It is clear that the sample size is also very sensitive to
the choice of ∆, therefore an investigator must be wary of misspecification of the anticipated
treatment difference [1].
Throughout the Methods, we incorporated the misclassification error in the calculations in
order to emphasise the importance of accounting for classification bias when the disease is rare.
We showed that, while lack of diagnostic sensitivity consistently inflates the estimated efficacy
rates, imperfect specificity results is serious loss of accuracy and precision at low disease risks.
Case definition for COVID-19 is particularly a major caveat. The three vaccine trials broadly
follow FDA definition of the disease. For primary end points symptomatic cases are identified by
surveillance or are self-reported, and are subsequently confirmed with RT-PCR. Pre-selecting of
the participants for PCR assay could create the possibility for collider bias [15]. Moreover, the
highly non-specific symptoms of COVID-19, which include symptoms as common as cough and
congestion, could create the perfect conditions for misclassification. False negatives due to e.g.

10/16

Table 2. Total sample sizes needed to conclude with 80% power and α=0.05 a significant effect
size
effect size

event rate

VE

∆

0.5

0.1

0.05

0.01

0.005

0.001

0.0005

0%
0%
0%
0%

10%
20%
30%
40%

37,632
9,408
4,181
2,352

238,336
59,584
26,482
14,896

489,216
122,304
54,357
30,576

2,496,256
624,064
277,362
156,016

5,005,056
1,251,264
556,117
312,816

25,075,456
6,268,864
2,786,162
1,567,216

50,163,456
12,540,864
5,573,717
3,135,216

30%
30%
30%
30%

10%
20%
30%
40%

21,751
5,438
2,417
1,359

145,009
36,252
16,112
9,063

299,080
74,770
33,231
18,693

1,531,654
382,913
170,184
95,728

3,072,371
768,093
341,375
192,023

15,398,105
3,849,526
1,710,901
962,382

30,805,273
7,701,318
3,422,808
1,925,330

60%
60%
60%
60%

10%
20%
30%
40%

11,064
2,766
1,229
691

79,905
19,976
8,878
4,994

165,957
41,489
18,440
10,372

854,372
213,593
94,930
53,398

1,714,890
428,723
190,543
107,181

8,599,037
2,149,759
955,449
537,440

17,204,221
4,301,055
1,911,580
1,075,264

90%
90%
90%
90%

10%
20%
30%
40%

4,553
1,138
506
285

37,946
9,486
4,216
2,372

79,686
19,921
8,854
4,980

413,607
103,402
45,956
25,850

831,009
207,752
92,334
51,938

4,170,221
1,042,555
463,358
260,639

8,344,237
2,086,059
927,137
521,515

selective reporting, specimen collection, etc, and PCR false positives due to e.g. remnant viral
RNA, etc could be introduced if the test is not repeated [13, 18]. Much remains unknown about
COVID-19 and its many symptoms and presentations. Therefore, it is recommended to account
for classification bias in the calculation. The code for calculating the posterior probability of the
vaccine efficacy, which can simultaneously marginalise over the diagnostic sensitivity and
specificity is provided.

Code
R code for the posterior probability of the efficacy was modified from code published in [9]. It is
provided in Appendix along with functions to calculate the sample sizes from equations 11 and 12.

Acknowledgments
The author’s position at the University of Cambridge is funded by CRUK grant C60100/A23916.
The author would like to appreciate the helpful comments received from the Cancer Mutagenesis
group at MRC Cancer Unit.

11/16

References
1. J. Wittes. Sample Size Calculations for Randomized Controlled Trials. Epidemiologic
Reviews, 24(1):39–53, 07 2002.
2. J. J. Gart and J. Nam. Approximate interval estimation of the ratio of binomial
parameters: a review and corrections for skewness. Biometrics, 44(2):323–338, Jun 1988.
3. D. Katz et al. Obtaining confidence intervals for the risk ratio in cohort studies.
Biometrics, 34:469–474, 1978.
4. M. Ewell. Comparing methods for calculating confidence intervals for vaccine efficacy. Stat
Med, 15(21-22):2379–2392, 1996.
5. A. W. Hightower et al. Recommendations for the use of Taylor series confidence intervals
for estimates of vaccine efficacy. Bull World Health Organ, 66(1):99–105, 1988.
6. P. A. Lachenbruch. Sensitivity, specificity, and vaccine efficacy. Controlled Clinical Trials,
19(6):569 – 574, 1998.
7. A. Hahn et al. Impact of diagnostic methods on efficacy estimation – a proof-of-principle
based on historical examples. Tropical Medicine & International Health, 25(3):357–363,
2020.
8. R. T. O’Neill. On sample sizes to estimate the protective efficacy of a vaccine. Stat Med,
7(12):1279–1288, Dec 1988.
9. P. J. Diggle. Estimating prevalence using an imperfect test. Epidemiology Research
International, 2011(608719), 2011.
10. M. Voysey et al. Safety and efficacy of the ChAdOx1 nCoV-19 vaccine (AZD1222) against
SARS-CoV-2: an interim analysis of four randomised controlled trials in Brazil, South
Africa, and the UK. Lancet, Dec 2020.
11. F. P. Polack et al. Safety and efficacy of the bnt162b2 mrna covid-19 vaccine. New England
Journal of Medicine, 383(27):2603–2615, 2020. PMID: 33301246.
12. L. R. Baden et al. Efficacy and safety of the mrna-1273 sars-cov-2 vaccine. New England
Journal of Medicine, 0(0):null, 0.
13. I. Arevalo-Rodriguez et al. False-negative results of initial RT-PCR assays for COVID-19:
A systematic review. PLoS One, 15(12):e0242958, 2020.
14. J. Balayla. Prevalence threshold and the geometry of screening curves. PLoS One,
15(10):e0240215, 2020.
15. G. J. Griffith et al. Collider bias undermines our understanding of COVID-19 disease risk
and severity. Nat Commun, 11(1):5749, 11 2020.
16. J. P. Ioannidis. Why most discovered true associations are inflated. Epidemiology,
19(5):640–648, Sep 2008.

12/16

17. K. S. Button et al. Power failure: why small sample size undermines the reliability of
neuroscience. Nat Rev Neurosci, 14(5):365–376, 05 2013.
18. J. Balayla. Bayesian updating and sequential testing: Overcoming inferential limitations of
screening tests, 2020.

Appendix
#
# R f u n c t i o n f o r Ba yesia n e s t i m a t i o n o f t h e e f f i c a c y r a t e u s i n g an
# i m p e r f e c t t e s t , o r i g i n a l l y m o d i f i e d from co de p r o v i d e d by
# P . J . D i g g l e . E s t i m a t i n g p r e v a l e n c e u s i n g an i m p e r f e c t t e s t . \
# E pidemio lo g y Resea r ch I n t e r n a t i o n a l , 2 0 1 1 ( 6 0 8 7 1 9 ) , 2011
#
# Notes
#
# 1 . P r i o r f o r e f f i c a c y r a t e i s assumed unifo r m on ( 0 , 1 )
# 2 . P r i o r s f o r s e n s i t i v i t y and s p e c i f i c i t y a r e i n d e p e n d e n t s c a l e d
# beta d i s t r i b u t i o n s
# 3 . Functio n u s e s a s i m p l e q u a d r a t u r e a l g o r i t h m with number o f
# q u a d r a t u r e p o i n t s a s an o p t i o n a l argument ” n g r i d ” ( s e e below ) ;
# t h e d e f a u l t v a l u e n g r i d =20 has been s u f f i c i e n t f o r a l l exa mples
# t r i e d by t h e author , but i s not g u a r a n t e e d t o g i v e a c c u r a t e
# r e s u l t s f o r a l l p o s s i b l e v a l u e s o f t h e o t h e r arguments .
#
l i b r a r y ( Rmpfr )
.N <− f u n c t i o n ( . ) mpfr ( . , p r e c B i t s = 2 0 0 )
e f f i c a c y . bayes<−f u n c t i o n ( alpha , Tc , n , pi , l o w s e = 0 .5 , h i g h s e = 1 .0 ,
s e a =1 , seb =1 , lo wsp = 0 .5 , h i g h s p = 1 .0 ,
spa =1 , spb =1 , n g r i d =20) {
#
# arguments
# a lpha : v e c t o r o f e f f i c a c y r a t e s f o r which p o s t e r i o r i s r e q u i r e d
# ( w i l l be c o n v e r t e d i n t e r n a l l y t o i n c r e a s i n g s e q u e n c e o f e q u a l l y
# spa ced v a l u e s , s e e ” r e s u l t ” below )
# Tc : number o f p o s i t i v e t e s t r e s u l t s
# n : number o f i n d i v i u d a l s t e s t e d
# lowse : lower l i m i t of p r i o r f o r s e n s i t i v i t y
# h i g h s e : upper l i m i t o f p r i o r f o r s e n s i t i v i t y
# sea , seb : p a r a m e t e r s o f s c a l e d beta p r i o r f o r s e n s i t i v i t y
# lo wsp : l o w e r l i m i t o f p r i o r f o r s p e c i f i c i t y
# h i g h s p : upper l i m i t o f p r i o r f o r s p e c i f i c i t y
# spa , spb : p a r a m e t e r s o f s c a l e d beta p r i o r f o r s p e c i f i c i t y
# n g r i d : number o f g r i d − c e l l s i n ea ch dimensio n f o r q u a d r a t u r e
#
13/16

# r e s u l t i s a l i s t with components
# a lpha : v e c t o r o f e f f i c a c y r a t e f o r which p o s t e r i o r d e n s i t y has
# been c a l c u l a t e d
# post : vector of p o s t e r i o r d e n s i t i e s
# mode : p o s t e r i o r mode
# i n t e r v a l : maximum a p o s t e r i o r i c r e d i b l e i n t e r v a l
#
i b e t a <−f u n c t i o n ( x , a , b ) {
pbeta ( x , a , b ) ∗ beta ( .N( a ) , .N( b ) )
}
nalpha<−l e n g t h ( a lpha )
b i n . width <−(a lpha [ na lpha ]− a lpha [ 1 ] ) / ( nalpha −1)
alpha<−a lpha [ 1 ] + b i n . width ∗ ( 0 : ( nalpha −1) )
i n t e g r a n d <−a r r a y ( 0 , c ( nalpha , n g r i d , n g r i d ) )
h1<−(h i g h s e −l o w s e ) / n g r i d
h2<−(hig hsp−lo wsp ) / n g r i d
fo r ( i in 1: ngrid ) {
se<−l o w s e+h1 ∗ ( i − 0 .5 )
pse <−(1/( h i g h s e −l o w s e ) ) ∗ dbeta ( ( se−l o w s e ) / ( h i g h s e −l o w s e ) , sea , seb )
fo r ( j in 1: ngrid ) {
sp<−lo wsp+h2 ∗ ( j − 0 .5 )
psp <−(1/(hig hsp−lo wsp ) ) ∗ dbeta ( ( sp−lo wsp ) / ( hig hsp−lo wsp ) , spa , spb )
i f ( n g r i d ==1){
s e=h i g h s e ; sp=h i g h s p ; pse =1; psp =1; h1 =1; h2=1
}
c1<−1−sp
c2<−s e+sp−1
g<−(c1+c2 ∗ p i ) ∗ chooseMpfr ( n , Tc ) ∗ ( i b e t a ( c1+c2 ∗ pi , Tc−1 ,n−Tc+1)−i b e t a
( ( c1+c2 ∗ p i ) / 2 , Tc−1 ,n−Tc+1) )
p<−(c1+c2 ∗ p i ) /(2− a lpha )
d e n s i t y <−r ep ( 0 , na lpha )
f o r ( k i n 1 : na lpha ) {
d e n s i t y [ k]<−asNumeric ( dbinom ( Tc , n , . N( p [ k ] ) ) /g )
}
i n t e g r a n d [ , i , j ]<−pse ∗ psp ∗ d e n s i t y
}
}
po st<−r ep ( 0 , na lpha )
f o r ( i i n 1 : na lpha ) {
p o s t [ i ]<−h1∗ h2 ∗sum ( i n t e g r a n d [ i , , ] )
}
ord<−o r d e r ( po st , d e c r e a s i n g=Tc )
mode<−a lpha [ ord [ 1 ] ]
cumpost=cumsum( p o s t /sum ( p o s t ) )

14/16

i n t e r v a l=c ( a lpha [ which . min ( abs ( cumpost − 0 .0 2 5 ) ) ] ,
a lpha [ which . min ( abs ( cumpost − 0 .9 7 5 ) ) ] )
l i s t ( a lpha=alpha , p o s t=po st , mode=mode , i n t e r v a l=i n t e r v a l )
}
#
#
#
#
#

example , t o r e p r o d u c e Table 1 r e s u l t s s e t n g r i d =1 , h i g h s e =1 , h i g h s p=1
o x f o r d 30 o f 5807 vs 101 o f 5829
p f i z e r 8 o f 18198 vs 162 o f 18325
moderna 11 o f 14134 vs 185 o f 14073

N<−14134+14073 # t o t a l number o f p a r t i c i p a n t s
Tc<− 185 # number o f c a s e s i n c o n t r o l
pi <−(185+11)/(14134+14073) # t o t a l number o f c a s e s / N
n g r i d <−1
lo wse <−1
h i g h s e <− 1 #0.95
lowsp<−1
hig hsp <−1 #0.999
sea <−2 #5
seb<−2
spa<−2 #5
spb<−2
alpha <−s e q ( 0 , 1 , by = 0 .0 0 0 5 ) # 0 . 0 0 1 ∗ ( 1 : 4 0 0 )
r e s u l t <−e f f i c a c y . ba yes ( alpha , Tc , N, pi , lo wse , h i g h s e ,
sea , seb , lowsp , hig hsp , spa , spb , n g r i d )
result$mode
result$interval
p l o t ( r e s u l t $ a l p h a , r e s u l t $ p o s t /sum ( r e s u l t $ p o s t ) , type=” l ” , x l a b=”a lpha ” ,
y l a b=”p ( a lpha ) ” )

# Functio n t o r e p r o d u c e per−group sample s i z e s p r e s e n t e d i n O’ N e i l l ,
# 1 9 8 8 . Note t h a t he used r e l a t i v e width (RW) and a t t a c k r a t e i n
# u n v a c c i n a t e d group (ARU)
s a m p l e s i z e 9 5 w a l d p a p e r <− f u n c t i o n (ARU,RW) {
VE=0.4
y<−RW∗VE/(2∗(1 −VE) )
d<−l o g ( y+s q r t ( yˆ2+1) )
r e t u r n ( ( 1 . 9 6 ) ˆ2/dˆ2∗((1+1/(1 −VE) ) /ARU−2) )
}
print ( t ( outer ( c (0 . 0 1 , 0 . 0 0 5 , 0 . 0 0 1 , 0 . 0 0 0 5 ) , rev ( seq ( 0 . 1 , 1 , 0 . 1 ) ) ,
s a m p l e s i z e 9 5 w a l d p a p e r ) ) , quo te = FALSE)
# To ta l sample s i z e s f o r p o o l e d Wald v a r i a n c e ( power 80%

15/16

# and a lpha = 0 .0 5 )
s a m p l e s i z e w a l d <− f u n c t i o n (VE, Pi , d e l t a ) {
RW=d e l t a /VE
ARU=Pi /(2−VE)
y<−RW∗VE/(2∗(1 −VE) )
d<−l o g ( y+s q r t ( yˆ2+1) )
r e t u r n ( 2 ∗ ( 1 . 9 6 + 0 . 8 4 ) ˆ2/dˆ2∗((1+1/(1 −VE) ) /ARU−2) )
}
# To ta l sample s i z e s f o r Cramer−Rao bound ( power 80% and a lpha = 0 .0 5 )
s a m p l e s i z e c r a m e r <− f u n c t i o n (VE, Pi , d e l t a ) {
r e t u r n ( 4 ∗ ( 1 . 9 6 + 0 . 8 4 ) ˆ2∗(2 −VE) ˆ2∗(2 −VE−Pi ) / Pi / d e l t a ˆ 2 )
}

16/16

