Real-Time Neural Network Scheduling of Emergency
Medical Mask Production during COVID-19

arXiv:2007.14055v1 [cs.NE] 28 Jul 2020

Chen-Xin Wua , Min-Hui Liaoa , Mumtaz Karatasb , Sheng-Yong Chenc ,
Yu-Jun Zhenga,∗
a

College of Information Science and Engineering, Hangzhou Normal University,
Hangzhou 311121, China
b
Industrial Engineering Department, Naval Academy, National Defense University, Tuzla
34940, Istanbul, Turkey
c
School of Computer Science and Engineering, Tianjin University of Technology, Tianjin
300384, China.

Abstract
During the outbreak of the novel coronavirus pneumonia (COVID-19), there
is a huge demand for medical masks. A mask manufacturer often receives
a large amount of orders that are beyond its capability. Therefore, it is of
critical importance for the manufacturer to schedule mask production tasks
as efficiently as possible. However, existing scheduling methods typically
require a considerable amount of computational resources and, therefore,
cannot effectively cope with the surge of orders. In this paper, we propose
an end-to-end neural network for scheduling real-time production tasks. The
neural network takes a sequence of production tasks as inputs to predict a
distribution over different schedules, employs reinforcement learning to optimize network parameters using the negative total tardiness as the reward
signal, and finally produces a high-quality solution to the scheduling problem. We applied the proposed approach to schedule emergency production
tasks for a medical mask manufacturer during the peak of COVID-19 in
China. Computational results show that the neural network scheduler can
solve problem instances with hundreds of tasks within seconds. The objective function value (i.e., the total weighted tardiness) produced by the neural
network scheduler is significantly better than those of existing constructive
∗

Corresponding author.
Email address: yujun.zheng@computer.org (Yu-Jun Zheng)

Preprint submitted to Elsevier

July 29, 2020

heuristics, and is very close to those of the state-of-the-art metaheuristics
whose computational time is unaffordable in practice.
Keywords: emergency production, flow shop scheduling, neural network,
reinforcement learning, public health emergencies
1. Introduction
ZHENDE is a medical apparatus manufacturer in Zhejiang Province,
China. It has a mask production line that can produce different types masks,
such as disposable medical masks, surgical masks, medical protective masks,
and respiratory masks. The Daily output is nearly one hundred thousand.
However, on each day during the outbreak of the novel coronavirus pneumonia (COVID-19), the manufacturer often receives tens to hundreds of mask
orders, the total demand of which ranges from hundreds of thousands to a
million masks. Almost all orders have tight delivery deadlines. Therefore, it
is of critical importance for the manufacturer to efficiently schedule the mask
production tasks to satisfy the orders as much as possible. The manufacturer
asked our research team to develop a production scheduler that can schedule
hundreds of tasks within seconds. In fact, many manufacturers of medical
supplies have similar requirements during the pandemic.
Scheduling production tasks on a production line can be formulated as a
machine scheduling problem which is known to be NP-hard [1]. Exact optimization algorithms (e.g., [2, 3, 4, 5]) have very large computation times that
are infeasible on even moderate-size problem instances. As for moderate- and
large-size instances optimal solutions are rarely needed in practice, heuristic approximation algorithms, in particular evolutionary algorithms (e.g.,
[6, 7, 8, 9, 10, 11, 12]), are more feasible to achieve a trade-off between
optimality and computational costs. However, the number of repeated generations and objective function evaluations for solving large-size instances
still takes a relatively long time and, therefore, cannot satisfy the requirement of real-time scheduling.
Using end-to-end neural networks to directly map a problem input to
an optimal or near-optimal solution is another research direction that has
received increasing attention. The earliest work dates back to Hopfield and
Tank [13], who applied a Hopfield-network to solve the traveling salesman
problem (TSP). Simon and Takefuji [14] modified the Hopfield network to
solve the job-shop scheduling problem. However, the Hopfield network is
2

only suitable for very small problem instances. Based on the premise that
optimal solutions to a scheduling problem have common features which can
be implicitly captured by machine learning, Weckman et al. [15] proposed a
neural network for scheduling job-shops by capturing the predictive knowledge regarding the assignment of operation’s position in a sequence. They
used solutions obtained by genetic algorithm (GA) as samples for training
the network. To solve the flow shop scheduling problem, Ramanan et al.
[16] used a neural network trained with optimal solutions of known instances
to produce quality solutions for new instances, which are then given as the
initial solutions to improve other heuristics such as GA. Recently, deep learning has been utilized to optimization algorithm design by learning algorithmic decisions based on the distribution of problem instances. Vinyals et al.
[17] introduced the pointer network as a sequence-to-sequence model, which
consists in an encoder to parse the input nodes, and a decoder to produce
a probability distribution over these nodes based on a pointer (attention)
mechanism over the encoded nodes. They applied the pointer network to
solve TSP instances with up to 100 nodes. However, the pointer network is
trained in a supervised manner, which heavily relies on the expensive optimal
solutions of sample instances. Nazari et al. [18] addressed this difficulty by
introducing reinforcement learning to calculate the rewards of output solutions, and applied the model to solve the vehicle routing problem (VRP).
Kool et al. [19] used a different decoder based on a context vector and
improved the training algorithm based on a greedy rollout baseline. They
applied the model to several combinatorial optimization problems including
TSP and VRP. Peng et al. [20] presented a dynamic attention model with dynamic encoder-decoder architecture to exploit hidden structure information
at different construction steps, so as to construct better solutions.
In this paper, we propose a deep reinforcement approach for scheduling
real-time production tasks. The neural network takes a sequence of production tasks as inputs to predict a distribution over different schedules, employs
reinforcement learning to optimize network parameters using the negative total tardiness as the reward signal, and finally produces a high-quality task
scheduling solution. We applied the proposed neural network scheduler to a
medical mask manufacturer during the peak of COVID-19 in China. Computational results show that the neural network scheduler can solve problem
instances with hundreds of tasks within seconds. The objective function value
(i.e., the total weighted tardiness) produced by the neural network scheduler
is significantly better than those of existing constructive heuristics such as
3

the Nawaz, Enscore and Ham (NEH) heuristic [21] and Suliman heuristic
[22], and is very close to those of the state-of-the-art metaheuristics whose
computational time is obviously unaffordable in practice.
The remainder of this paper is organized as follows. Section 2 describes
the emergency production scheduling problem. Section 3 presents the architecture of the neural network, Section 4 depicts the reinforcement learning
algorithm, and Section 5 presents the experimental results, and finally Section 6 concludes with a discussion.
2. Medical Mask Production Scheduling Problem
In this section, we formulate the scheduling problem as follows (the variables are listed in Table 1). The manufacturer receives K orders, denoted by
O = {O1 , O2 , . . . , OK }. Each order Ok is associated with a set Φk of production tasks (jobs), which is related to the number of mask types in the order.
Each order Ok has an expected delivery time dk and an importance weight
wk according to its value and urgency. In our practice, the manager gives a
score between
1–10 for each order, and then all weights are normalized such
PK
that ( k=1 wk ) = 1.
Let J = {J1 , J2 , . . . , Jn } be the set of all tasks. These tasks need to
be scheduled on a production line with m machines, denoted by M =
{M1 , M2 , . . . , Mm }. Each task Jj has exactly m operations, where the ith operation must be processed on machine Mi with a processing time tij
(1 ≤ i ≤ m; 1 ≤ j ≤ n). Each machine can process at most one task at
a time, and each operation cannot be interrupted. The operations of mask
production typically include cloth cutting, fabric lamination, belt welding,
disinfection, and packaging.
The problem is to decide a processing sequence π = {π1 , π2 , . . . , πn } of the
n tasks. Let C(πi , j) denote the completion time of task πj on machine Mi .
For the first machine M1 , the tasks can be sequentially processed immediately
one by one:
C(π1 , 1) = tπ1 ,1
C(πj , 1) = C(πj−1 , 1) + tπj ,1 ,

j = 2, ..., n

(1)
(2)

The first job π1 can be processed on each subsequent machine Mi immediately after it is completed on the previous machine Mi−1 :
C(π1 , i) = C(π1 , i − 1) + tπ1 ,i ,
4

i = 2, ..., m

(3)

Table 1: Mathematical variables used in the problem formulation.

Symbol
O = {O1 , O2 , . . . , OK }
K
k
dk
wk
Φk
J = {J1 , J2 , . . . , Jn }
n
j
M = {M1 , M2 , . . . , Mm }
m
i
tij
π = {π1 , π2 , . . . , πn }
C(πi , j)
T (Ok )

Description
The set of orders
Number of orders
Index of orders (1 ≤ k ≤ K)
Expected delivery time of order Ok
Importance weight of order Ok
Set of all production tasks in order Ok
Set of all production tasks
Number of tasks
Index of tasks (1 ≤ j ≤ n)
Set of machines
Number of machines
Index of machines (1 ≤ i ≤ m)
Processing time of i-th operation of task Jj (on machine Mi )
A solution (sequence of n tasks) to the problem
Completion time of task πj on machine Mi
Completion time of order Ok

Each subsequent job πj can be processed on machine Mi only when (1)
the job πj has been completed on the previous machine Mi−1 ; (2) the previous
job πj−1 has been completed on machine Mi :

C(πj , i) = max C(πj , i − 1), C(πj−1 , i) + tπj ,i , i = 2, . . . , m; j = 2, . . . , n
(4)
Therefore, the completion time of each order Ok is the completion time
of the last task of the order on machine Mm :
T (Ok ) = max C(π, m)
π∈Φk

(5)

The objective of the problem is to minimize the total weighted tardiness
of the orders:
min f (π) =

K
X

wk max(T (Ok ) − dk , 0)

(6)

k=1

If all tasks are available for processing at time zero, the above formulation can be regarded as a variant of the permutation flow shop scheduling
5

problem which is known to be NP-hard [1]. When there are hundreds of
tasks to be scheduled, the problem instances are computationally intractable
for exact optimization algorithms, and search-based heuristics also typically
take tens of minutes to hours to obtain a satisfying solution. Moreover,
in a public health emergency such as the COVID-19 pandemic, new orders
may continually arrive during the emergency production and, therefore, it
is frequently to reschedule production tasks to incorporate new tasks into
the schedules. The allowable computational time for rescheduling is even
shorter, typical only a few seconds. Hence, it is required to design real-time
or near-real-time rescheduling methods for the problem.
3. A Neural Network Scheduler for Emergence Production Task
Scheduling
We propose a neural network scheduler based on the encoder-decoder architecture [23] to efficiently solve the above production task scheduling problem. Fig. 1 illustrates the architecture of the network. The input to the network is a problem instance represented by a sequence of n tasks, each of which
is described by a (m+2)-dimensional vector xj = {pj,1 , pj,2 , . . . , pj,m , dk , wk }
that consists the processing times on the m machines and the expected delivery time and weight importance of the corresponding order. To facilitate the
processing of the neural network, all inputs are normalized into [0,1], e.g.,
each dk is transformed to (dk −dmin )/(dmax −dmin ), where dmin = min1≤k≤K dk
and dmax = max1≤k≤K dk .
The encoder is a recurrent neural networks (RNN) with long short-term
memory (LSTM) [24] cells. An LSTM takes a task xj as input at a time and
transforms it to a hidden state hj by increasingly computing the embedding
of the inputs (where att denotes the transformation by LSTM):
h1 = att(h1 , x1 ) = encode(x1 )
h2 = att(h1 , x2 ) = encode(x1 , x2 )
..
.
hn = att(hn−1 , x2 ) = encode(x1 , x2 , . . . , xn )

(7)

As a result, the encode produces an aggregated embedding of all inputs
as the mean of n hidden states:
n
1X
hj
(8)
h=
n j=1
6

Decoder

pθ

…
5th layer
……
2nd layer
hc

Encoder

LSTM

1st layer

LSTM

……

LSTM

x1
x2
……
xn

……

Figure 1: Architecture of the neural network scheduler.

The decoder also performs n decoding steps, each making a decision on
which task should to be processed at the next step. At each j-th step, it
constructs a context vector hc by concatenating h and the hidden state hj−1
of the previous LSTM. We use a five-layer deep neural network to implement
the decoder. The first layer takes h as input and transforms it into a n1 dimensional hidden vector u1 (n1 < n):
T

u1 = ReLU(W1 h + b1 )

(9)

where W1 is a n1 ×n weight matrix and b1 is a n1 -dimensional bias vector.
The second layer takes the concatenation of u1 and context vector hc as
input and transforms it into a n2 -dimensional hidden vector u2 :
u2 = ReLU(W2 [u1 ; hc ]T + b2 )

(10)

where [ ; ] denotes the horizontal concatenation of vectors, W2 is a n2×(n1+
2n) weight matrix and b2 is a n2 -dimensional bias vector.
And each of the remaining layer takes the hidden state of the previous
layer, and transforms it into a lower-dimensional hidden vector using ReLU
activation. Finally, the probability that each task xj is selected at the t-th
7

step is calculated based on the state u of the top layer of the DNN:
euj
pθ (πt = xj |x, π 1:t−1 ) = Pn
j 0 =1

euj0

(11)

4. Reinforcement Learning of the Neural Network
A solution to the scheduling problem can be viewed as a sequence of
decisions, and the decision process can be regarded as a Markov decision
process [25]. According to the objective function (6), the training of the
network is to minimize the loss
L(θ|x) = Eπ∼pθ ( |x) f (π|x)

(12)

We employ the policy gradient using REINFORCE algorithm [26] with
Adam optimizer [27] to train the network. The gradients of network parameters θ are defined based on a baseline base(x) as:

(13)
∇θ L(θ|x) = Eπ∼pθ ( |x) (f (π|x)−base(x))∇θ log pθ (π|x)
A good baseline reduces gradient variance and increases learning speed
[19]. Here, we use both the NEH heuristic [21] and Suliman heuristic [22] to
solve each instance x, and use the better one as the base(x).
During the training, we approximate the gradient via Monte-Carlo sampling, where B problem instances are drawn from the same distribution:
B

1 X
(f (π i |xi )−base(xi ))∇θ log pθ (π i |xi )
∇θ L(θ) =
B i=1

(14)

Algorithm 1 presents the pseudocode of the REINFORCE algorithm.
5. Computational Results
In the training phase, according to production tasks of the manufacturer
during the peak of COVID-19 in China, we randomly generate 20,000 instances. The basic features of the instance distribution are as follows: m = 5,
n follows a normal distribution N (124, 33), tij follows a normal distribution N (2.4, 1.6) (in hours), and dk follows a uniform discrete distribution
{24, 36, 48, 60, 72, 96, 120} (in hours). The maximum number of epochs for
training the network is set to 100.
8

Algorithm 1: The REINFORCE algorithm.
1
2
3
4
5
6
7
8
9
10

Randomly initialize the network parameters θ;
for epoch= 1 to epochmax do
for t = 1 to T do
for i = 1 to B do
Sample an instance xi from the problem distribution;
Compute the model output π i ;
Compute the baseline base(xi );

P
g(θ) ← B1 B
(f
(π
)−base(x
))∇
log
p
(π
|x
)
;
i
i
i
i
θ
θ
i=1
θ ← Adam(θ, g(θ));
return θ.

For comparison, we also use three different baselines:
Pthe first is a greedy
heuristic that sorts tasks in decreasing order of wk /( m
i=1 tij ), the second
is the NEH heuristic [21], and the third is the Suliman heuristic [22]. The
neural network is implemented using Python 3.4, while the heuristics are
implemented with Microsoft Visual C# 2018. The experiments are conducted
on a computer with Intel Xeon 3430 CPU and GeForce GTX 1080Ti GPU.
Fig. 2 presents the convergence curves of the four methods during the
training process. In average, our method converges after 55∼65 epochs,
the individual NEH and Suliman heuristics converge after 80∼85 epochs,
while the greedy method converges to local optima that are significantly
worse than the results of the first three methods. The results demonstrate
that our method using hybrid NEH and Suliman heuristics as the baseline
can significantly improve the training performance compare to the existing
heuristic baselines.
Next, we test the performance of the trained neural network scheduler for
solving the mask production task scheduling problem. We select 146 realworld instances of the manufacturer from Feb 8 to Feb 14, 2020, the peak
of COVID-19 in China. For each day, we need to first solve an instance
with about 50∼200 tasks; during the daytime, with the arrival of new orders, we need to reschedule the production for 20∼40 times. To validate
the performance of neural network scheduler, we also run the following five
state-of-the-art metaheuristic algorithms to solve each instance, as use the
best result among the algorithms as the benchmark:
• A shuffled complex evolution algorithm (SCEA) [28];
9

35
30

Greedy

NEH

Suliman

Ours

25

f(x) 20
15
10
5
0

20

40

60

80

100

epochs

Figure 2: The convergence curves of the four methods for training the neural network.

• An algebraic differential evolution (ADE) algorithm [29];
• A teaching-learning based optimization (TLBO) algorithm [30];
• A biogeography-based optimization (BBO) algorithm [31];
• A discrete water wave optimization (WWO) algorithm [12].
Fig. 3 presents the average objective function value obtained by our
scheduler and those of the NEH, Suliman, and benchmark solutions on each
day, and Table 2 presents the average CPU time required to obtain the solutions. The results show that, the results of the neural network scheduler are
significantly better than those of the NEH and Suliman heuristics. The NEH
heuristic and neural network scheduler consume similar computational time,
but the objective function value of NEH is about 2∼3 times of that of the neural network scheduler. The Suliman heuristic consumes more computational
time and obtains even worse objective function value than the neural network
scheduler. The benchmark solutions are obtained by the best metaheuristic
among the five state-of-the-art ones, using significantly longer computational
time (600∼1500 seconds) than that of the neural network scheduler (only 1∼2
seconds). Nevertheless, the objective function values produced by the neural network scheduler are very close to (approximately 6%∼7% larger than)
those of the benchmark solutions. In emergency conditions, the computational time of the state-of-the-art metaheuristics is obviously unaffordable,

10

NEH

Suliman

Ours

Benchmark

30
25
20

f(x) 15
10
5
0
8-Feb

9-Feb

10-Feb

11-Feb

12-Feb

13-Feb

14-Feb

Figure 3: Comparison of the results of the neural network scheduler, constructive heuristics, and state-of-the-art metaheuristics.

while the proposed neural network scheduler can produce high-quality solutions within seconds and, therefore, satisfy the requirements of emergency
medical mask production.
6. Conclusion
In this paper, we propose a deep neural network with reinforcement for
scheduling emergency production tasks within seconds. The neural network
consists of an encoder and a decoder. The encoder employs LSTM-based

Table 2: CPU time (in seconds) consumed by the neural network scheduler, constructive
heuristics, and state-of-the-art metaheuristics.

Day
Feb-8
Feb-9
Feb-10
Feb-11
Feb-12
Feb-13
Feb-14

NEH Suliman Benchmark algorithm
0.63
0.93
522
0.92
2.35
713
1.71
4.59
1064
2.13
5.26
1125
2.30
5.96
1390
0.97
2.64
885
1.45
3.84
971
11

Neural network
0.75
1.03
1.32
1.57
1.72
1.09
1.20

RNN to sequentially parse the input production tasks, and the decoder employs a deep neural network to learn the probability distribution over these
tasks. The network is trained by reinforcement learning using the negative
total tardiness as the reward signal. We applied the proposed neural network
scheduler to a medical mask manufacturer during the peak of COVID-19 in
China. The results show that the proposed approach can achieve high-quality
solutions within very shorter computational time to satisfy the requirements
of emergency production.
The baseline plays a key role in reinforcement learning. The baseline used
in this paper is based on two constructive heuristics, which have much room
to be improved. However, better heuristics and metaheuristics often require
large computational resource and are not efficient in training a large number
of test instances. In our ongoing work, we are incorporating other neural
network schedulers to improve the baseline. Another future work is to use
evolutionary metaheuristics to optimize the parameters of the deep neural
network [32].
Acknowledgment
This work was supported by National Natural Science Foundation of
China under Grant 61872123 and Zhejiang Provincial Natural Science Foundation under Grant LY18F030023 and LR20F030002.
References
[1] M. Pinedo, Scheduling Theory, Algorithms, and Systems, 2nd Edition,
Prentice Hall, 2002.
[2] G. B. McMahon, P. G. Burton, Flow-shop scheduling with the branchand-bound method, Oper. Res. 15 (3) (1967) 473–481. doi:10.1287/
opre.15.3.473.
[3] J. K. Karlof, W. Wang, Bilevel programming applied to the flow shop
scheduling problem, Comput. Oper. Res. 23 (5) (1996) 443–451. doi:
10.1016/0305-0548(95)00034-8.
[4] M. Ziaee, S. Sadjadi, Mixed binary integer programming formulations for
the flow shop scheduling problems. a case study: ISD projects scheduling, Appl. Math. Comput. 185 (1) (2007) 218–228. doi:10.1016/j.
amc.2006.06.092.
12

[5] C. Gicquel, L. Hege, M. Minoux, W. van Canneyt, A discrete time exact
solution approach for a complex hybrid flow-shop scheduling problem
with limited-wait constraints, Comput. Oper. Res. 39 (3) (2012) 629–
636. doi:10.1016/j.cor.2011.02.017.
[6] O. Etiler, B. Toklu, M. Atak, J. Wilson, A genetic algorithm for flow
shop scheduling problems, J. Oper. Res. Society 55 (8) (2004) 830–835.
doi:10.1057/palgrave.jors.2601766.
[7] G. Onwubolu, D. Davendra, Scheduling flow shops using differential
evolution algorithm, Eur. J. Oper. Res. 171 (2) (2006) 674–692. doi:
10.1016/j.ejor.2004.08.043.
[8] C. J. Liao, C. T. Tseng, P. Luarn, A discrete version of particle swarm
optimization for flowshop scheduling problems, Comput. Oper. Res.
34 (10) (2007) 3099–3111. doi:10.1016/j.cor.2005.11.017.
[9] I. H. Kuo, S. J. Horng, T. W. Kao, T. L. Lin, C. L. Lee, T. Terano,
Y. Pan, An efficient flow-shop scheduling algorithm based on a hybrid
particle swarm optimization model, Expert Syst Appl 36 (3) (2009)
7027–7032.
[10] J. Lin, A hybrid discrete biogeography-based optimization for the permutation flow-shop scheduling problem, Int. J. Prod. Res. 54 (16) (2016)
4805–4814. doi:10.1080/00207543.2015.1094584.
[11] F. Zhao, H. Liu, Y. Zhang, W. Ma, C. Zhang, A discrete water wave
optimization algorithm for no-wait flow shop scheduling problem, Expert
Syst. Appl. 91 (2018) 347–363. doi:10.1016/j.eswa.2017.09.028.
[12] Y.-J. Zheng, X.-Q. Lu, Y.-C. Du, Y. Xue, W.-G. Sheng, Water wave
optimization for combinatorial optimization: Design strategies and applications, Appl. Soft Comput. 83 (2019) 105611. doi:10.1016/j.asoc.
2019.105611.
[13] J. J. Hopfield, D. W. Tank, “neural” computation of decisions in optimization problems, Bio. Cybern. 52 (3) (1985) 141–152. doi:10.1007/
BF00339943.

13

[14] F. Y.-P. Simon, Takefuji, Integer linear programming neural networks for
job-shop scheduling, in: International Conference on Neural Networks,
Vol. 2, 1988, pp. 341–348. doi:10.1109/ICNN.1988.23946.
[15] G. R. Weckman, C. V. Ganduri, D. A. Koonce, A neural network jobshop scheduler, J. Intell. Manuf. 19 (2) (2008) 191–201. doi:10.1007/
s10845-008-0073-9.
[16] T. R. Ramanan, R. Sridharan, K. S. Shashikant, A. N. Haq, An artificial
neural network based heuristic for flow shop scheduling problems, J. Intell.Manuf. 22 (2) (2011) 279–288. doi:10.1007/s10845-009-0287-5.
[17] O. Vinyals, M. Fortunato, N. Jaitly, Pointer networks, in: C. Cortes,
N. D. Lawrence, D. D. Lee, M. Sugiyama, R. Garnett (Eds.), Advances
in Neural Information Processing Systems, Vol. 28, Curran Associates,
Inc., 2015, pp. 2692–2700.
[18] M. Nazari, A. Oroojlooy, L. Snyder, M. Takac, Reinforcement learning for solving the vehicle routing problem, in: S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, R. Garnett (Eds.), Advances in Neural Information Processing Systems, Vol. 31, Curran Associates, Inc., 2018, pp. 9839–9849.
[19] W. Kool, H. van Hoof, M. Welling, Attention, learn to solve routing
problems!, in: International Conference on Learning Representations,
2019.
[20] B. Peng, J. Wang, Z. Zhang, A deep reinforcement learning algorithm
using dynamic attention model for vehicle routing problems, Springer
Singapore, Singapore, 2020, pp. 636–650.
[21] M. Nawaz, E. E. Enscore, I. Ham, A heuristic algorithm for the mmachine, n-job flow-shop sequencing problem, Omega 11 (1) (1983) 91–
95. doi:10.1016/0305-0483(83)90088-9.
[22] S. M. A. Suliman, A two-phase heuristic approach to the permutation
flow-shop scheduling problem, Int. J. Prod. Econom. 64 (1) (2000) 143–
152. doi:10.1016/S0925-5273(99)00053-5.
[23] I. Sutskever, O. Vinyals, Q. V. Le, Sequence to sequence learning with
neural networks, in: Z. Ghahramani, M. Welling, C. Cortes, N. D.
14

Lawrence, K. Q. Weinberger (Eds.), Advances in Neural Information
Processing Systems, Vol. 27, Curran Associates, Inc., 2014, pp. 3104–
3112.
URL http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neura
pdf
[24] F. Gers, J. Schmidhuber, F. Cummins, Learning to forget: continual
prediction with LSTM, in: International Conference on Artificial Neural
Networks, Edinburgh, UK, 1999, pp. 850–855.
[25] I. Bello, H. Pham, Q. V. Le, M. Norouzi, S. Bengio, Neural combinatorial optimization with reinforcement learning, arXiv preprint
arXiv:1611.09940 (2016).
[26] R. J. Williams, Simple statistical gradient-following algorithms for connectionist reinforcement learning, in: R. S. Sutton (Ed.), Machine
Learning, Springer US, Boston, MA, 1992, pp. 5–32. doi:10.1007/
978-1-4615-3618-5\_2.
[27] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, in:
ICLR, 2015.
URL http://arxiv.org/abs/1412.6980
[28] F. Zhao, J. Zhang, J. Wang, C. Zhang, A shuffled complex evolution
algorithm with opposition-based learning for a permutation flow shop
scheduling problem, Int. J. Comput. Integ. Manuf. 28 (11) (2015) 1220–
1235. doi:10.1080/0951192X.2014.961965.
[29] V. Santucci, M. Baioletti, A. Milani, Algebraic differential evolution
algorithm for the permutation flowshop scheduling problem with total
flowtime criterion, IEEE Trans. Evol. Comput. 20 (5) (2016) 682–694.
doi:10.1109/TEVC.2015.2507785.
[30] W. Shao, D. Pi, Z. Shao, An extended teaching-learning based optimization algorithm for solving no-wait flow shop scheduling problem, Appl.
Soft Comput. 61 (2017) 193–210. doi:10.1016/j.asoc.2017.08.020.
[31] Y.-C. Du, M.-X. Zhang, C.-Y. Cai, Y.-J. Zheng, Enhanced
biogeography-based optimization for flow-shop scheduling, in: J. Qiao,

15

X. Zhao, L. Pan, X. Zuo, X. Zhang, Q. Zhang, S. Huang (Eds.), Bioinspired Computing: Theories and Applications, Commun Comput Inf
Sci, Springer, Singapore, 2018, pp. 295–306.
[32] X.-H. Zhou, M.-X. Zhang, Z.-G. Xu, C.-Y. Cai, Y.-J. Huang, Y.-J.
Zheng, Shallow and deep neural network training by water wave optimization, Swarm Evol. Comput. 50 (2019) 1–13. doi:10.1016/j.
swevo.2019.100561.

16

