1

arXiv:2101.10667v1 [eess.IV] 26 Jan 2021

Efficient Multi-objective Evolutionary 3D Neural
Architecture Search for COVID-19 Detection with
Chest CT Scans
Xin He∗ , Shihao Wang∗ , Guohao Ying† , Jiyong Zhang‡ and Xiaowen Chu∗§
∗ Department of Computer Science, Hong Kong Baptist University, Hong Kong, China
Email: {csxinhe,shwang,chxw}@comp.hkbu.edu.hk
† Viterbi School of Engineering, University of Southern California, CA, USA
Email: gying@usc.edu
‡ School of Automation, Hangzhou Dianzi University, Hang Zhou, China
jzhang@hdu.edu.cn

Abstract—COVID-19 pandemic has spread globally for
months. Due to its long incubation period and high testing cost,
there is no clue showing its spread speed is slowing down, and
hence a faster testing method is in dire need. This paper proposes
an efficient Evolutionary Multi-objective neural ARchitecture
Search (EMARS) framework, which can automatically search for
3D neural architectures based on a well-designed search space for
COVID-19 chest CT scan classification. Within the framework,
we use weight sharing strategy to significantly improve the search
efficiency and finish the search process in 8 hours. We also
propose a new objective, namely potential, which is of benefit
to improve the search process’s robustness. With the objectives
of accuracy, potential, and model size, we find a lightweight
model (3.39 MB), which outperforms three baseline humandesigned models, i.e., ResNet3D101 (325.21 MB), DenseNet3D121
(43.06 MB), and MC3 18 (43.84 MB). Besides, our well-designed
search space enables the class activation mapping algorithm to be
easily embedded into all searched models, which can provide the
interpretability for medical diagnosis by visualizing the judgment
based on the models to locate the lesion areas.
Index Terms—COVID-19, Evolutionary Algorithm, Neural Architecture Search, Multi-objective optimization

I. I NTRODUCTION

T

EN months after the global pandemic starts, COVID-19 is
still a significant problem for most countries in the world.
Besides the 14-days incubation period making it hard to trace
and guarantee the patients, accurate diagnosis is also hard to
perform. One of the most widely used testing methods is to
use reverse transcription-polymerase chain reaction (RT-PCR)
[1] for viral testing; however, it is relatively slow, expensive,
and requires professionals, reagents, and exceptional devices
to perform. To facilitate rapid COVID-19 diagnosis, many
researchers attempt to accelerate COVID-19 diagnosis by deep
learning (DL) techniques. However, most of the proposed
models are designed manually, which requires the designer’s
abundant experience and high expertise. This situation hinders
the generalization of DL for COVID-19 diagnosis. At the
same time, an excellent neural network needs to perform well
on multiple metrics (e.g., precision and sensitivity) before
§ Corresponding author.

applying it to actual disease diagnosis. However, in practice,
no human expert can guarantee to find the optimal neural
architecture.
This paper proposes an efficient evolutionary multiobjective neural architecture search (EMARS) method, which
can automatically search 3D neural networks for COVID19 detection. Our method can achieve 89.74% sensitivity on
Clean-CC-CCII dataset [2], which is significantly higher than
the average sensitivity of antigen tests (56.2%) [3], similar to
radiologist’s average diagnosis sensitivity by Chest CT (92%)
[4], and only slightly worse than average sensitivity of RTPCR (95.2%) [3].
The neural architecture search (NAS) technique is a feasible
and promising solution to automate and accelerate the process
of model designing, as many studies have experimentally
demonstrated that NAS-designed models outperform handcrafted models. There are mainly four classes of NAS methods: reinforcement learning (RL)-based methods [5]–[8], gradient descent (GD)-based methods [9]–[11], surrogate modelbased optimization (SMBO) methods [12], and evolutionary
algorithm (EA)-based methods [13]–[19]. Many early studies
focus on searching for neural architectures that achieve higher
performance (e.g., classification accuracy), regardless of the
resource consumption and model size. For example, Zoph
et al. [5] were the first to propose RL-based NAS methods
and successfully found models outperforming state-of-the-art
(SOTA) manually designed models, while they took 800 GPUs
and 22,400 GPU days for searching, which is unacceptable
for individuals and small companies. The following GDbased methods, such as DARTS [9], significantly improve the
search efficiency. However, as stated in [10], DARTS tends
to select the simpler operations (e.g., skip-connect) in the
later stage of the search, resulting in a lack of diversity in
the searched models. Although the EA-based methods can
escape local optima and find promising models, it introduces
randomness during the search stage. The EA-based methods
have a huge requirement of computational resources and time,
as the typical EA-based NAS methods generally need to
train each individual for several epochs before obtaining their

2

validation results.
In this paper, we propose an Evolutionary Multi-objective
neural ARchitecture Search (EMARS) framework to resolve
the above inherent issues. Many previous NAS studies search
only one cell and repeat a fixed number of searched cell to
construct the final model. Inspired by [8], [20], our search
space is factorized into multiple searchable cells and blocks
(shown in Fig. 1); therefore, the model diversity in our work
is guaranteed. Besides, we use the mobile inverted bottleneck
convolution (MBConv) as the candidate operations. MBConv
requires less computation than standard convolution modules
and has been demonstrated effective in improving model performance. In EMARS, individuals indicate child architectures
derived in the same SuperNet initialized at the beginning of
the algorithm. In other words, all individuals share the weights
of the SuperNet among each other, which can significantly
improve the efficiency of our evolutionary algorithm. The
search process of 100 epochs can be finished in about 8 hours
using 4 Nvidia Tesla V100 GPUs.
Many multi-objective NAS methods [8], [11], [18], [19]
only considered accuracy and model size as objectives. In this
work, we introduce a new objective, namely potential, into
the NSGA-III algorithm [21]. We experimentally demonstrated
that potential is of great benefit to improve the robustness
of the search process by applying EMARS to three publicly
available COVID-19 CT scan datasets (Clean-CC-CCII [22],
MosMedData [23], and Covid-CTset [24]). According to the
experimental results, EMARS can effectively find a series of
neural architectures with higher accuracy than baseline models
(ResNet3D101 [25], DenseNet3D121 [26], and MC3 18 [25]),
and these searched architectures cover a wide range over
the model size. Furthermore, medical diagnoses generally
require interpretability of the decision, so we apply the class
activation mapping (CAM) [27] algorithm into our EMARS
series models to visualize the judgment of the model, which
can help doctors understand the chest CT scan while verifying
the validity.
The contributions of our work are summarized as follows:
1) We design a 3D search space, which is factorized into
multiple searchable cells and blocks and hence increase
the model diversity. We also use the weight sharing
strategy, which significantly improves search efficiency.
The search process of 100 epochs can be finished in
about 8 hours.
2) We propose an EA-based NAS framework, namely
EMARS, which is capable of scalability, i.e., we can
easily apply multiple objectives into EMARS for optimization. Specifically, we introduce a new objective,
called potential, and experimentally prove it effective
to improve the robustness of the search process.
3) With the proposed search space and EMARS, we find
a series of neural architectures, all of which outperform
three baseline models with a much smaller mode size.
4) In our search space, a global average pooling layer is
inserted before the fully connected layer; therefore, the
class activation mapping (CAM) [27] algorithm can be
easily embedded into our searched models, which can

help doctors locate the discriminative lesion areas on the
CT scan images.
The rest of the paper is organized as follows. Section
II describes the related work. Section III introduces the
search space for building 3D neural architectures. Section
IV illustrates our search algorithm, including the warm-up,
selection, crossover, and mutation processes. We introduce the
experimental implementations in Section V, and present and
analyze the results in Section VI. Section VII concludes the
paper and proposes the future research directions.
II. R ELATED W ORK
A. DL-Based COVID-19 Detection
With the rapid growth of computational power, DL has
become a popular way to assist the diagnosis of X-ray or
CT images [28]. The growing amount of publicly available
datasets in different aspects also facilitates researches to implement deep neural networks on different tasks. For COVID19, there are two kinds of data, which are CT images and
X-ray images. The difference between CT and X-ray is CT is
a 3D format, which contains the textural information of a part
of the human body composed of many slices of body cross
sections images. X-ray is a 2D format contains overlapping
textual information of the human body. There are several
researches using deep learning on X-ray datasets [29]–[31].
Ghoshal et al. [29] achieved 88.39% accuracy on their X-ray
dataset using the DL model. While Narin et al. [31] achieved
98% accuracy on a smaller X-ray dataset. Experiments using
CT datasets are more popular compared with X-rays. There
are two kinds of CT datasets, 2D and 3D, used for deep
learning classification for COVID-19. According to [32], most
of existing studies focus on a single representative slice from a
CT scan volume for COVID-19 detection [33]–[37]. However,
since 3D volumes contains more information, which is CT’s
advantage by design, more experiments choose to use 3D CT
volume to do classification and segmentation tasks [22]–[24],
[38], [39], in which Zheng et al. [38], Li et al. [39], Morozov et
al. [23], Zhang et al. [22] designed 3D convolutional networks
to analyze 3D CT volumes.
B. Neural Architecture Search
Recently, there is a growing interest in the NAS technique,
as it has been applied to many areas and outperformed humandesigned models [40], [41]. Arguably, the studies of [5], [7]
mark the beginning of NAS, as they demonstrated that RLbased NAS methods could effectively discover good architectures. ENAS [6] accelerates the search process by adopting
a parameter-sharing strategy, in which all child architectures
are regarded as sub-graph of a super-net; this enables these
architectures to share parameters, obviating the need to train
each child model from scratch. Besides RL-based methods,
several improved methods are also proposed to further improve
NAS efficiency.
SMBO methods evaluate the searched models with the
surrogate function instead of metrics from trained architectures
and thus shorten the search time. Furthermore, Liu et al. [12]

3

Input

Stem

Calibration

Block
1-1

Block
1-B1

...

GAP

Cell N

...

Cell 1

Calibration

FC

Block
N-1

...

Output

Block
N-BN

Candidate operations

MBConv7_3

MBConv3_3

...

Identity

MBConv5_4

decode
[1 0 0 0 0 0]

...

Individual architecture encoding α
[0 1 0 0 0 0]
...
[0 0 0 0 0 1]

...

[0 0 1 0 0 0]

Fig. 1. Overview of our search space. The order of model construction is from bottom to top. α contains one-hot sequences of all searchable blocks (blue),
and each one-hot sequence will be decoded as a corresponding module (red). Each cell (yellow) comprises a calibration block and a different number of
blocks. The final model is composed of a stem layer, a fixed number of cells, the global average pooling (GAP) layer, and a fully connected (FC) layer. Best
viewed in color.

used learned a surrogate model to guide the search, and their
method is five times more efficient than the RL-based method
[7].
Liu et al. [9] were one of the first to propose the GD-based
method, namely DARTS, which uses the softmax function
to relax the discrete search space and significantly improve
the search efficiency. But according to Liang et al. [10],
the performance of DARTS is often observed to collapse,
as DARTS tends to select the simpler operations (e.g., skipconnect) in the later stage of the search, which may result in
a lack of diversity in the searched models.
Evolutionary algorithm (EA) is inspired by biological evolution. A new model (also known as individual) is evolved from a
previous model with operations including selection, crossover
and mutation. The early EA-based methods are computateintensive, e.g., AmoebaNet [16] took 450 GPUs and 3,150
GPU days for searching. CARS [17] significantly improves
the search efficiency by introducing the weight sharing strategy
into the evolutionary algorithm. MoreNAS [18] combines RL
and EA to obtain promising architecture for multi-objective
optimal. LemonadeNAS [42] encodes network by function,
and each network can be generated from network morphism
operators.
C. Multi-objective Neural Architecture Search
In terms of the multi-objective tasks, the target will be
complex, and hard to weigh different objectives. Some existing
methods try to reduce multi-objective to single-objective. For
example, MONAS [19] maps multi-objective to single by a

linear combination, but it may lead to suboptimal. Since it’s
tricky for one single network to surpass all the optimal target,
architectures satisfied with the Pareto front are preferred. Yant
et al. [17] introduced an improved method based on NSGA-III
[21], namely pNSGA, to achieve optimal architectures with
multi-objective. Besides, most multi-objective NAS methods
[8], [11], [18], [19] only considered accuracy and model size as
objectives. In this paper, we propose a new objective, namely
potential, which is of great benefit to improve the robustness
of the search process.
III. S EARCH S PACE
A well-designed search space is of great benefit to enhance
the final model performance. The traditional cell-based search
space [6], [9] has several problems: 1) the cell structure is
inefficient for reference as it is a non-regularized combination
of candidate operations; 2) the final model is constructed by
repeating the searched cell, thus lacking diversity. To this end,
we adopt the idea that is factorizing each network into cells
and blocks [8], as shown in Fig. 1. The details of our search
space are introduced as follows.
A. Block
Each block is a searchable module, which can be selected
from a predefined number of candidate operations. To find a
lightweight and high-quality 3D model for COVID-19 detection, we add a series of mobile inverted bottleneck convolution
(MBConv) [20] into the candidate operation set. As shown in
Fig. 2, MBConvk e comprises three sub-modules: 1) a 3D

4

+

+

C×D×H×W

C×D×H×W

Conv3D 1×1×1
BN3D, ReLu6

Conv3D 1×1×1
BN3D, ReLu6

6C×D×H×W

3C×D×H×W

DWConv3D 5×5×5
BN3D, ReLu6

DWConv3D 3×3×3
BN3D, ReLu6

6C×D×H×W

3C×D×H×W

Conv3D 1×1×1
BN3D, ReLu6

Conv3D 1×1×1
BN3D, ReLu6

C×D×H×W

C×D×H×W
MBConv3_3

MBConv5_6

Fig. 2. Structure of mobile inverted bottleneck convolution (MBConv).
MBConv has two hyperparameters: kernel size and expand ratio. For example,
MBConv5 6 indicates that the kernel size of the intermediate module is 5×5,
and the expand ratio is 6. DWConv3D indicates 3D depthwise convolution,
BN3D indicates 3D batch normalization, and C × D × H × W indicates
input tensor shape (channel, depth, height, width).

point-wise (1×1×1) convolution, which increases the number
of channels of the output feature e times that of input feature;
2) the intermediate expansion layer uses lightweight a 3D
depthwise convolution with kernel size k × k × k to extract
features and introduce non-linearity; 3) another 3D point-wise
(1×1×1) convolution, which restores the output feature size
to the input feature size. In MBConv, most convolutional
operations are followed by a 3D batch normalization and a
ReLU6 activation function [43], and the last convolution has
no ReLU6.
B. Cell
Each cell is composed of a calibration block and a different
number of searchable blocks. The calibration block is a 3D
1 × 1 × 1 point-wise convolution to solve the problem of
feature dimension mismatch; therefore, all subsequent blocks
have stride 1. As shown in Fig. 1, in our search space, the i-th
cell has Bi searchable blocks, and each block is also different.
Therefore, this design paradigm enables model diversity. In
our experiments, we empirically choose the following set of
candidate operations:

S = [S1 , ..., SN ] for each cell. In this work, we fix F, N, B,
and S during the search stage; thus the network can be
regarded as a SuperNet N constrained to all possible cell
structures. Besides, the stem layer is a fixed convolutional
operation to process the input. The global average pooling
(GAP) [45] is inserted before the fully connected (FC) layer;
therefore, the network can handle variable input size.

D. Weight-sharing
Although EA can effectively solve the multi-objective problem that other optimization algorithms struggle to solve, it usually suffers from huge computational resources consumption
[13], [14], [42]. Therefore, inspired by [6], [9], [17], we adopt
a weight-sharing strategy to improve efficiency.
An individual architecture denoted by N (α) is sampled
from the SuperNet N , where α is a set of one-hot sequences
that encodes the individual architecture. Each one-hot sequence is decoded as a candidate operation. For example,
as shown in Fig. 1, [0, 0, 0, 0, 0, 1] is decoded as the identity
(skip-connect) operation. All individuals share the weights W
of the SuperNet, and the weights of the i-th individual are
denoted by W(α).
With loss of the individual L(α) = H(N (α), X, Y ) where
H is the loss function, X is the input data and Y is the label
data, the individual gradient W(α) can be calculated as
dW(α) =

•
•
•

MBConv3
MBConv3
MBConv3
MBConv5

3
4
6
3

•
•
•
•

MBConv5 4
MBConv7 3
MBConv7 4
Identity

Identity indicates the skip connection operation [44], which
is equivalent to reducing one block.
C. Network
As shown in Fig. 1, the network could be specified with
several factors: cell structures, the number of filters F in the
stem layer, the number of cells N , the number of blocks
B = [B1 , ..., BN ] and the stride of each calibration block

(1)

Since the weights W of the SuperNet is shared among all
individual architectures, the gradient of W can be calculated
as the accumulation of gradients of all individuals.

dW =

P
P
1 X
1 X ∂L(αi )
dW(αi ) =
P i=1
P i=1 ∂W

(2)

where P is the size of population. In [17], the authors used a
mini-batch architectures to obtain an unbiased approximation
to Eq. 2, detailed as Eq. 3

dW ≈
•

∂L(α)
.
∂W

B
1 X
dW(αi )
B i=1

(3)

where B is the number of individuals in a mini-batch and
B < P . In our experiments, we find that B = 1 works just
fine, i.e., we can update W using the gradient from any single
individual sequentially sampled from the population.

IV. S EARCH ALGORITHM
Our evolutionary search algorithm is based on NSGA-III
[21], which is composed of selection, crossover, mutation,
and update steps. Alg. 1 summarizes the detailed steps of our
evolutionary algorithm for searching 3D neural architectures.

5

Algorithm 1: Efficient Multi-objective Evolutionary
Algorithm for Neural Architecture Search
Input: SuperNet N , SuperNet weight W, population
size P , population A, selection size K,
crossover probability pc , mutation probability
pm , multi-objective T = {T1 , ..., TM }, loss
function H, training set Dtrain , validation set
Dval
Output: a population of individual architectures
{N (α1 ), ..., N (αP )}
(0)
(0)
(0)
1 A
= {α1 , ..., αP } ← Warm-up(N , P );
2 for e=1:Eevolve do
3
for Mini-batch data X, label Y in Dtrain do
(e−1)
4
Select i-th individual encoding αi
(i ← e mod P );
(e−1)
5
Get i-th individual architecture N (αi
);
(e−1)
6
Calculate loss L = H(N (αi
), X, Y );
7
Update individual weight W(αi );
8
end
// Start evolution
9
Akeep ← SelectTopK(A(e−1) , K, T , Dval );
10
Anew ← {};
11
while |Anew | < P − K do
12
p ←random probability;
13
if p < 0.5 then
14
i, j (i 6= j) ← GenerateRandomInteger(K);
15
α ← Crossover(Akeep [i], Akeep [j], pc );
16
α ← Mutation(α, pm );
17
else
18
α ← RandomSamplingIndividual();
19
if α not in Anew then
20
Append α to Anew ;
21
end
22
Update population A(e) ← Akeep ∪ Anew ;
23 end

A. Warm-up stage
In our experiment, the SuperNet weights W are randomly
initialized and shared among all individuals; if we evolve
from the beginning, then the first set of sampled architectures
can get more training. In this case, these architectures may
dominate in the later stage and compromise the search’s
effectiveness. Similar to [17], [46], we adopt uniform sampling
to treat all individual architectures equally during the warm-up
stage. In our experiments, all searchable blocks are selected
from eight different operations, and each operation is sampled
with a probability of 18 . After the warm-up stage, many
individuals are sampled and trained, and the top P bestperforming individual architectures are collected as the initial
population for evolution.
B. Selection
As Alg. 1 illustrates, all individuals from the population
A are equally trained for batches before the selection step.
Then, top K best-performing individuals are selected for the

following evolution steps. The selection process allows us to
preserve strong individuals while eliminating weak ones. The
most commonly used selection method is to select individuals
based on the their fitness, such as validation accuracy [14],
[47]. Practically, we are not only concerned with model
accuracy, but also with other metrics such as model size. We
use NSGA-III [21] to select promising individuals along the
Pareto front of multi-objective.
In practice, we denote {N (α1 ), ..., N (αP )} as a population
of individual architectures and T = {T1 , ..., TM } as multiobjective. We want to minimize the number of architectures
by replacing some architecture with ones dominating them. In
{N (α1 ), ..., N (αP )}, N (αi ) dominants N (αj ) when N (αi )
are not worse than N (αj ) in each metrics of multi-objective.
Formally:
Tk (N (αi )) ≥ Tk (N (αj )) ∀k ∈ {1, ..., M }
Tk (N (αi ))>Tk (N (αj )) ∃k ∈ {1, ..., M }

(4)

From the above explanation, we can guarantee N (αi ) must
have at least one metric better than N (αj ) with others metric
at least the same. Thus, we can replace N (αj ) with N (αi ) and
ensure measurement increasing at the process of evolution.
Most existing multi-objective NAS methods [8], [11], [18],
[19] only considered the accuracy and model size, which
may cause Matthew Effect, because models with relatively
more training tend to achieve higher validation accuracy and
thus are more likely to be trained, while other models may
therefore lose the opportunity to compete. Therefore, we
propose a new objective, namely potential (P), which predicts
the individual performance by incorporating the individuals’
history performance. The individual potential is represented
by the slope of the line after applying the linear fitting to
the individual’s history performance. The potential of one
individual is derived as follows

Y
if S = 1
(5)
P=
(X T X)−1 X T Y
if S > 1
P indicates the individual potential, X ∈ RS×1 stores the
epoch index when the individual is sampled, Y ∈ RS×1 indicates the corresponding validation accuracy, and S represents
the number of times the individual is sampled.
In our experiments, we consider three objectives: accuracy,
model size, and potential. Therefore, we can generate three
Pareto stages by applying the non-dominated sorting algorithm
to each objective. Then we merge three Pareto stages to get
the final Pareto stage.
C. Crossover
After selection, K best-performing individuals are selected
for the crossover, which exchanges architecture encodings between two different parent individuals to result in recombinant
individuals. Since we use the one-hot encoding to represent the
categorical candidate operations, crossovers are performed on
the one-hot encodings other than binary encodings. Each pair
of one-hot encodings of two parent individuals are crossovered
with a probability of pc . Fig. 3 (a) presents an example that
only one crossover occurs between two parent individuals,
both of which consist of three one-hot encodings.

6

[1 0 0 0 0 0]

[0 1 0 0 0 0]

[0 0 0 0 0 1]

[0 1 0 0 0 0]

[0 0 0 0 0 1]

[0 0 1 0 0 0]

[0 1 0 0 0 0]

[0 0 0 0 0 1]

[0 0 1 0 0 0]

TABLE I
T HE STATISTICS OF THE THREE CT SCAN DATASETS . NCP INDICATES THE
NOVEL CORONAVIRUS PNEUMONIA . N ON -NCP INCLUDES CP ( COMMON
PNEUMONIA ) AND N ORMAL .
Dataset
[Input size]

[1 0 0 0 0 0]

[0 0 0 0 0 1]

[0 0 0 0 0 1]

[0 1 0 0 0 0]

[0 1 0 0 0 0]

[0 0 1 0 0 0]

(a) Crossover

[0 1 0 0 0 0]

[0 0 0 1 0 0]

[0 0 1 0 0 0]

(b) Mutation

Fig. 3. Examples of crossover and mutation. The basic unit for both crossover
and mutation is the one-hot encoding sequence, which represents a candidate
operation. The length of the one-hot sequence indicates the total number of
candidate operations (here 6).

CleanCC-CCII
[128×128]
MosMedData
[256×256]
COVID-CTset
[512×512]

Classes
NCP
CP
Normal
Total
NCP
Normal
Total
NCP
Normal
Total

#Patients
Train
Test
726
190
778
186
660
158
2164
534
601
255
178
76
779
331
202
42
200
82
402
124

#Scans
Train
Test
1213
302
1210
303
772
193
3195
798
601
255
178
76
779
331
202
42
200
82
402
124

B. Baselines
D. Mutation
Since crossovers are performed between two promising
parent individuals, the child individuals can inherit their
good architecture encodings. In other words, crossovers are
primarily for exploitation, while mutations are usually for
exploration. The basic unit for mutation is also the one-hot
encoding. In Fig. 3 (b), the second one-hot encoding of the
parent individual is mutated.
V. E XPERIMENTAL I MPLEMENTATION
In this section, we first describe three datasets used in our
experiments. Then, we introduce the implementation details of
the baseline experiment and our EMARS algorithm.
A. Datasets
In this paper, we use three publicly available datasets:
Clean-CC-CCII [32], MosMedData [23] and COVID-CTset
[24], all of which provide 3D chest CT scans. The statistics
of three datasets are presented in Table. I. Clean-CC-CCII
consists of three classes: NCP (novel coronavirus pneumonia),
CP (common pneumonia), and Normal, while both MosMedData and COVID-CTset contains NCP and Normal. Besides,
each patient may have several CT scans, and each scan data is
composed of multiple slice grey images. For Clean-CC-CCII
and MosMedData, the image format is PNG (portable network
graphics), while the image format of the Covid-CTset is 16bit TIFF (tagged image file format). Notably, in this work, the
basic classification unit is the scan data instead of the slice
image.
We conducted multiple search experiments on the CleanCC-CCII dataset. Therefore, to shorten the experimental time,
we set each slice’s size to 128×128 and fix each scan data
containing 32 slices. After finishing the search experiments,
we applied the best-performing model to the other two datasets
to verify its transferability. In order to provide a more thorough
evaluation of the EMARS-designed model performance, we
processed the two datasets differently. For the MosMedData
dataset, each scan data consists of 40 slices, and a slice
resolution is 256×256. For the Covid-CTset, we set the slice
size to 512×512, and each scan contains 32 slices.

In our experiments, we use three hand-crafted 3D neural
architectures as the baseline models: DenseNet3D121 [26],
ResNet3D101 [25], and MC3 18 [25]. We apply transformations to scans, including resize, center-crop, and normalization.
For the training set, we randomly perform the horizontal and
vertical flip operation. We use the Adam [48] optimizer with
the weight decay of 5e-4. The learning rate is initialized to
0.001. The cosine annealing scheduler [49] is applied to adjust
the learning rate. Three baseline models are trained for 200
epochs. The loss function H is cross-entropy.
C. Evolutionary Multi-objective Neural Architecture Search
EMARS includes two stages: the search stage and the
retraining stage. The experimental configuration of each stage
is as follows:
1) Search stage: The SuperNet comprises six cells, and
the number of searchable blocks in each cell is [4,4,4,4,4,4,1].
Each block is selected from eight candidate operations (see
Section III-C). The blocks within the same cell keep the same
number of input and output channels, and all blocks have a
stride of 1. In other words, the spatial dimensions of the output
features of each cell are determined by the calibration block.
Here, we empirically set the number of output channels of
each cell to [24,40,80,96,192,320], and the stride of calibration
block in each cell to [2, 2, 2, 1, 2, 1]. The stem block is a
Conv3D-BN3D-ReLU6 sequential module, with the number
of output channels fixed to 32.
Besides using the weight-sharing strategy, we reduce the
resolution of input scan data to 64×64 to improve search
efficiency. The training set is divided into the sub-training set
Dtrain , and the validation set Dval . To avoid the Matthew
effect, we performed the warm-up stage before the evolution
and initialized the population with 20. The SuperNet weights
are optimized using the stochastic gradient descent (SGD)
optimizer with a momentum of 3e-4. The initial learning rate
is 0.001.
Selection. For each epoch in the evolution process, all individual architectures from the population were equally trained
with the training data batches before the selection. Using
the NSGA-III algorithm, we evaluate the impact of different
objectives on search results, including accuracy, potential, and

0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6

0.5

0.5
0.4

0.4
0.3

Accuracy

0.8

Accuracy

Accuracy

7

5.0

7.5 10.0 12.5 15.0 17.5 20.0
Model size (MB)

0.3

0.5
0.4

5.0

7.5

10.0 12.5 15.0 17.5 20.0
Model size (MB)

0.3

5.0

7.5 10.0 12.5
Model size (MB)

15.0

17.5

(a) Objectives: accuracy. There are 26 individ- (b) Objectives: accuracy + large model size. (c) Objectives: accuracy + small model size.
uals with an accuracy rate exceeding 0.7.
There are 42 individuals with an accuracy rate There are 14 individuals with an accuracy rate
exceeding 0.7.
exceeding 0.7.
Fig. 4. Comparison among the evolution results of different experiments with different model size objectives. Each point indicates the results of one individual.
The purple and yellow points indicate the individual results of the first and last 50 epochs, respectively. Individuals in the later stage of evolution (e.g., yellow
points) in Fig. 4(a) cover a wider range over model size dimension, while Fig. 4 (b) and (c) show that individuals gradually evolve into large and small
models, respectively.
TABLE II
P ERFORMANCE COMPARISON AMONG MODELS SEARCHED WITH DIFFERENT MODEL SIZE OBJECTIVE ON C LEAN -CC-CCII DATASET.
Model
EMARS-A
EMARS-B
EMARS-C

Model size
(MB)
5.93
20.61
3.79

Objectives
Accuracy
Accuracy + large model size
Accuracy + small model size

model size. Each experiment is conducted on four Nvidia Tesla
V100 GPUs (the 32GB PCIe version) and can be finished in
about 8 hours. We set selection size K in Alg. 1 to 10, which
indicates that we preserved 10 most promising individuals for
exploitation and generated 10 new individuals for exploration.
Crossover & Mutation. As shown in Alg. 1, after the
selection, we first generated a random probability p ∈ (0, 1). If
p > 0.5, we randomly sampled a new individual; otherwise,
we performed crossover and mutation on the selected individuals to generate a new individual. The basic unit for both
crossover and mutation is the one-hot encoding. The probability of crossover and mutation for each one-hot encoding is
pc = 0.3 and pm = 0.2, respectively.
2) Retraining stage: After the search stage, we export top10 promising individual architecture along Pareto front of the
search stage’s objectives. We train each exported individual for
a few epochs and finally choose the best-performing one for
further retraining. The experimental configuration of retraining
is the same as the baseline experiment.
VI. R ESULTS & A NALYSIS
In this section, we first introduce our evaluation metrics.
Then, we present and analyze the experimental results.
A. Evaluation Metrics
We use several commonly used evaluation metrics to compare the model performance, as follows:
Precision =

TP
TP + FP

Sensitivity (Recall) =

TP
TP + FN

(6)
(7)

Accuracy
(%)
89.67
87.92
89.39

Precision
(%)
91.07
95.8
93.13

Sensitivity
(%)
87.75
83.11
89.74

F1-score
0.8938
0.8901
0.9141

F1-score =

2 × (Precision × Recall)
Precision + Recall

(8)

Accuracy =

TN + TP
TN + TP + FN + FP

(9)

To be noticed, the positive and negative cases are assigned
to the COVID-19 class and the non-COVID-19 class, respectively. Specifically, T P and T N indicate the number of
correctly classified COVID-19 (i.e., NCP) and non-COVID-19
(i.e., CP and Normal) scans, respectively. F P and F N indicate
the number of wrongly classified COVID-19 and non-COVID19 scans, respectively. The accuracy is the micro-averaging
value for all test data to evaluate the overall performance of
the model. Besides, we also use model size as an evaluation
metric to compare the model efficiency.
B. Model Size-aware Search
To verify the ability of multi-objective optimization of the
EMARS algorithm, we set up three experiments with different
model size objectives. The three experiments run for 100
epochs. We visualized the search results of three experiments
in Fig. 4, in which each point indicates the result of one
individual. We split 100 epochs into two parts: the purple
points represent the evolution results of the first 50 epochs,
and the yellow points represent the evolution results of the last
50 epochs. Fig. 4 shows the distribution of evolution with the
objectives of (a) only the validation accuracy, (b) the validation
accuracy and large model size, (c) the validation accuracy and
small model, respectively. We can see that the results of the
three experiments are in line with expectations. The yellow
points in Fig. 4(a) cover a wider range over the model size

8

(a) Objectives: [accuracy]

(b) Objectives: [potential]

(c) Objectives: [accuracy + potential + small model
size]

Fig. 5. Comparison among the evolution results of different experiments with or without the potential objective. Each point indicates the results of one
individual and is divided into first or second half of epochs. Solid line indicates the average accuracy of individuals. Dashed line indicates the 30/70 percentile
of individual distribution. The 30/70 percentile in Fig. 5(a) is relatively higher than that of Fig. 5(b), but the 30/70 percentile of Fig. 5(b) is closer than of Fig.
5(a), which indicates that potential can effectively improve search process’ robustness. Fig. 5(c) combines the advantages of accuracy, potential, and small
model size objectives.
TABLE III
P ERFORMANCE COMPARISON AMONG MODELS SEARCHED WITH OR WITHOUT THE POTENTIAL OBJECTIVE ON C LEAN -CC-CCII DATASET.
Model
EMARS-A
EMARS-D
EMARS-E

Model size
(MB)
5.93
5.63
3.39

Objectives
Accuracy
Potential
Accuracy + potential + small model size

dimension, while the yellow points in Fig. 4(b) and (c) tend to
be distributed to the large and small model size, respectively.
Besides, the number of individuals with an accuracy of more
than 0.7 in Fig. 4 (a) to (c) is 26, 42, and 14, respectively. A
possible explanation for this might be that the larger models
have more parameters and thus overfit the training dataset
during the search stage, which is proved by the retraining
results shown in the Table. II. EMARS-A, EMARS-B, and
EMARS-C are the best-performing models selected from Fig.
4 (a), (b), and (c), respectively. Although the size of EMARSB is much more than EMRAS-A and EMRAS-C, it achieves
the lowest accuracy, sensitivity, and f1-score.

C. Model Potential-aware Search
We experimentally demonstrated that the potential objective
is of great benefit to search stability. Fig. 5 (a) shows that,
with the objective of accuracy, EMARS can gradually find
strong individuals achieving high validation accuracy, but may
also waste time in some weak ones. Fig. 5 (b) shows that,
with the objective of potential, the search process is relatively
robust, as the 30/70 percentile becomes closer than that of
Fig. 5 (a); however, Fig. 5 (b) fails to find enough individuals
with high accuracy. Therefore, we take accuracy, potential, and
small model size as objectives, and Fig. 5 (c) shows that the
search process keeps robust, and many individuals get high
accuracy. We further retrained the best-performing individual
from each experiment, and their performance is presented in
Table. III. One can see that EMARS-E, which is searched with
the objectives of accuracy and potential, has a smaller size and
outperforms EMARS-A and EMARS-D in terms of precision,
sensitivity, and f1-score.

Accuracy
(%)
89.67
88.78
89.61

Precision
(%)
91.07
93.68
98.16

Sensitivity
(%)
87.75
88.41
88.41

F1-score
0.8938
0.9097
0.9303

D. Performance Comparison between Baseline and EMARS
on Clean-CC-CCII dataset
Table. IV summarizes the performance between three 3D
baseline models and EMARS series models on the Clean-CCCCII dataset. Our searched architectures cover an extensive
range of model sizes, ranging from 3.39 MB to 20.61 MB. In
other words, we can easily select a suitable architecture for
different deploy devices. Besides, all EMARS series models
outperform the baseline models with a much smaller model
size. EMARS-A achieves the best accuracy of 89.67% among
all models, and it surpasses ResNet3D101, DenseNet3D121,
and MC3 18 by 4.83%, 3.05%, and 4.07%, respectively.
EMARS-C achieves the best sensitivity compared with other
models. EMARS-E achieves the best precision and f1-score
and has the smallest size (3.39 MB), which is 98.96%, 92.13%,
and 92.27% smaller than ResNet3D101, DenseNet3D121, and
MC3 18.
E. Transferability
Based on the above experimental results, we select two
representative architectures, i.e., EMARS-B and EMARSC, to evaluate the transferability by training them on the
MosMedData and Covid-CTset datasets. The experimental
configuration is the same as the baseline experiment (see
Section V-B). The final results presented in Table. V show
the transferability of our searched architectures.
F. Interpretability
CAM is an algorithm that can visualize the regions that the
model focuses on, and hence provide the interpretability for
our searched models. We apply it to a 3D CT scan volume

9

TABLE IV
P ERFORMANCE COMPARISON BETWEEN MANUALLY DESIGNED MODELS AND EMARS- DESIGNED MODELS ON C LEAN -CC-CCII DATASET. *GPU
DAYS =# GPUS × REAL SEARCH TIME
Model
ResNet3D101
DenseNet3D121
MC3 18
EMARS-A
EMARS-B
EMARS-C
EMARS-D
EMARS-E

Model size
(MB)
325.21
43.06
43.84
5.93
20.61
3.79
5.63
3.39

Search Method
manual
manual
manual
evolution
evolution
evolution
evolution
evolution

Search Cost
(GPU days*)
1.3
1.3
1.3
1.3
1.3

TABLE V
P ERFORMANCE COMPARISON BETWEEN BASELINE MODELS AND
EMARS- DESIGNED MODELS ON M OS M ED DATA AND C OVID -CT SET
DATASETS .
Dataset

MosMedData

Covid-CTset

Model
ResNet3D101
DenseNet3D121
MC3 18
EMARS-B
EMARS-E
ResNet3D101
DenseNet3D121
MC3 18
EMARS-B
EMARS-E

Model size
(MB)
325.21
43.06
43.84
20.61
3.39
325.21
43.06
43.84
20.61
3.39

Accuracy
(%)
81.82
79.55
80.4
81.51
81.25
93.87
91.91
92.57
92.09
92.86

from the Clean-CC-CCII dataset using EMARS-E model. Fig.
6 presents the generated heat maps of some slices. A red
and brighter region means that it have a larger impact on the
model’s decision to classify it as COVID-19.
From the perspective of the scan volume, we can see that
some slices have more impacts on the model’s decision than
the others. In terms of a single slice, the areas that EMARSE focuses on has ground-glass opacity, which is proved a
distinctive feature of CT images of COVID-19 Chest CT
images [50]. CAM enables the interpretability of our searched
models (e.g., EMARS-E), which can help doctors quickly
locate the discriminative lesion areas in a large CT volume.

Fig. 6. The class activation mappings generated by EMARS-E on a chest CT
scan of the Clean-CC-CCII dataset. Regions colored in red and brighter has
more impact on model’s decision to the class of COVID-19 while grey and
darker region has less.

Accuracy
(%)
85.54
87.02
86.16
89.67
87.92
89.39
88.78
89.61

Precision
(%)
89.62
88.97
87.11
91.07
95.80
93.13
93.68
98.16

Sensitivity
(%)
77.15
82.78
82.78
87.75
83.11
89.74
88.41
88.41

F1-score
0.8292
0.8576
0.8489
0.8938
0.8901
0.9141
0.9097
0.9303

VII. C ONCLUSION
In this work, we propose a factorized 3D search space, in
which all child architectures share weights among each other.
We introduce an efficient evolutionary multi-objective neural
architecture search (EMARS) framework to search for 3D
models for COVID-19 CT scan classification. We also propose
a new objective, namely potential, that can effectively improve
the robustness of the search process. The results on three
COVID-19 datasets show that a series of models searched by
EMARS cover a wide range over the model size, and they all
outperform the baseline models on the Clean-CC-CCII dataset.
We also verify the EMARS series models’ transferability by
training two representative models on the MosMedData and
Covid-CTset datasets. Our work demonstrates that NAS is a
powerful and promising solution for assisting in COVID-19
CT scan detection. In the future, we will apply our EMARS
framework to more complex tasks, such as 3D medical image
segmentation.
R EFERENCES
[1] I. Smyrlaki, M. Ekman, A. Lentini, N. R. de Sousa, N. Papanicolaou,
M. Vondracek, J. Aarum, H. Safari, S. Muradrasoli, A. G. Rothfuchs,
J. Albert, B. Högberg, and B. Reinius, “Massive and rapid COVID-19
testing is feasible by extraction-free SARS-CoV-2 RT-PCR,” Nature
Communications, vol. 11, no. 1, Sep. 2020. [Online]. Available:
https://doi.org/10.1038/s41467-020-18611-5
[2] X. He, S. Wang, S. Shi, X. Chu, J. Tang, X. Liu, C. Yan, J. Zhang, and
G. Ding, “Benchmarking deep learning models and automated model
design for covid-19 detection with chest ct scans,” medRxiv, 2020.
[Online]. Available: https://www.medrxiv.org/content/early/2020/06/17/
2020.06.08.20125963
[3] J. Dinnes, J. J. Deeks, A. Adriano, S. Berhane, C. Davenport,
S. Dittrich, D. Emperador, Y. Takwoingi, J. Cunningham, S. Beese,
J. Dretzke, L. F. di Ruffano, I. M. Harris, M. J. Price, S. Taylor-Phillips,
L. Hooft, M. M. Leeflang, R. Spijker, and A. V. den Bruel and, “Rapid,
point-of-care antigen and molecular-based tests for diagnosis of SARSCoV-2 infection,” Cochrane Database of Systematic Reviews, Aug.
2020. [Online]. Available: https://doi.org/10.1002/14651858.cd013705
[4] B. Xu, Y. Xing, J. Peng, Z. Zheng, W. Tang, Y. Sun, C. Xu,
and F. Peng, “Chest CT for detecting COVID-19: a systematic
review and meta-analysis of diagnostic accuracy,” European Radiology,
vol. 30, no. 10, pp. 5720–5727, May 2020. [Online]. Available:
https://doi.org/10.1007/s00330-020-06934-2
[5] B. Zoph and Q. V. Le, “Neural architecture search with reinforcement
learning,” arXiv preprint arXiv:1611.01578, 2016.
[6] H. Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean, “Efficient neural architecture search via parameter sharing,” arXiv preprint
arXiv:1802.03268, 2018.
[7] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, “Learning transferable
architectures for scalable image recognition,” in Proceedings of the IEEE
conference on computer vision and pattern recognition, 2018, pp. 8697–
8710.

10

[8] M. Tan, B. Chen, R. Pang, V. Vasudevan, M. Sandler, A. Howard,
and Q. V. Le, “Mnasnet: Platform-aware neural architecture search for
mobile,” in Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, 2019, pp. 2820–2828.
[9] H. Liu, K. Simonyan, and Y. Yang, “Darts: Differentiable architecture
search,” 2018.
[10] H. Liang, S. Zhang, J. Sun, X. He, W. Huang, K. Zhuang, and
Z. Li, “Darts+: Improved differentiable architecture search with early
stopping,” arXiv preprint arXiv:1909.06035, 2019.
[11] B. Wu, X. Dai, P. Zhang, Y. Wang, F. Sun, Y. Wu, Y. Tian, P. Vajda,
Y. Jia, and K. Keutzer, “Fbnet: Hardware-aware efficient convnet design
via differentiable neural architecture search,” in Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2019, pp.
10 734–10 742.
[12] C. Liu, B. Zoph, M. Neumann, J. Shlens, W. Hua, L.-J. Li, L. Fei-Fei,
A. Yuille, J. Huang, and K. Murphy, “Progressive neural architecture
search,” pp. 19–34, 2018.
[13] E. Real, S. Moore, A. Selle, S. Saxena, Y. L. Suematsu, J. Tan, Q. Le, and
A. Kurakin, “Large-scale evolution of image classifiers,” arXiv preprint
arXiv:1703.01041, 2017.
[14] H. Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu,
“Hierarchical representations for efficient architecture search,” arXiv
preprint arXiv:1711.00436, 2017.
[15] L. Xie and A. Yuille, “Genetic cnn,” in Proceedings of the IEEE
international conference on computer vision, 2017, pp. 1379–1388.
[16] E. Real, A. Aggarwal, Y. Huang, and Q. V. Le, “Regularized evolution
for image classifier architecture search,” in Proceedings of the aaai
conference on artificial intelligence, vol. 33, 2019, pp. 4780–4789.
[17] Z. Yang, Y. Wang, X. Chen, B. Shi, C. Xu, C. Xu, Q. Tian, and C. Xu,
“Cars: Continuous evolution for efficient neural architecture search,”
in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2020, pp. 1829–1838.
[18] X. Chu, B. Zhang, R. Xu, and H. Ma, “Multi-objective reinforced evolution in mobile neural architecture search,” arXiv preprint
arXiv:1901.01074, 2019.
[19] C.-H. Hsu, S.-H. Chang, J.-H. Liang, H.-P. Chou, C.-H. Liu, S.-C.
Chang, J.-Y. Pan, Y.-T. Chen, W. Wei, and D.-C. Juan, “Monas: Multiobjective neural architecture search using reinforcement learning,” arXiv
preprint arXiv:1806.10332, 2018.
[20] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen,
“Mobilenetv2: Inverted residuals and linear bottlenecks,” in Proceedings
of the IEEE conference on computer vision and pattern recognition,
2018, pp. 4510–4520.
[21] K. Deb and H. Jain, “An evolutionary many-objective optimization
algorithm using reference-point-based nondominated sorting approach,
part i: solving problems with box constraints,” IEEE transactions on
evolutionary computation, vol. 18, no. 4, pp. 577–601, 2013.
[22] K. Zhang, X. Liu, J. Shen, Z. Li, Y. Sang, X. Wu, Y. Zha, W. Liang,
C. Wang, K. Wang et al., “Clinically applicable AI system for accurate
diagnosis, quantitative measurements, and prognosis of covid-19 pneumonia using computed tomography,” Cell, 2020.
[23] S. Morozov, A. Andreychenko, N. Pavlov, A. Vladzymyrskyy,
N. Ledikhova, V. Gombolevskiy, I. Blokhin, P. Gelezhe, A. Gonchar,
V. Chernina, and V. Babkin, “Mosmeddata: Chest ct scans with
covid-19 related findings,” medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/05/22/2020.05.20.20100362
[24] M. Rahimzadeh, A. Attar, and S. M. Sakhaei, “A fully automated
deep learning-based network for detecting covid-19 from a new and
large lung ct scan dataset,” medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/06/12/2020.06.08.20121541
[25] D. Tran, H. Wang, L. Torresani, J. Ray, Y. LeCun, and M. Paluri, “A
closer look at spatiotemporal convolutions for action recognition,” 2017.
[26] A. Diba, M. Fayyaz, V. Sharma, A. H. Karami, M. M. Arzani,
R. Yousefzadeh, and L. Van Gool, “Temporal 3d convnets: New architecture and transfer learning for video classification,” arXiv preprint
arXiv:1711.08200, 2017.
[27] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning
deep features for discriminative localization,” in Proceedings of the IEEE
conference on computer vision and pattern recognition, 2016, pp. 2921–
2929.
[28] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi,
M. Ghafoorian, J. A. van der Laak, B. van Ginneken, and C. I. Sánchez,
“A survey on deep learning in medical image analysis,” Medical Image
Analysis, vol. 42, no. 1995, pp. 60–88, 2017.
[29] B. Ghoshal and A. Tucker, “Estimating Uncertainty and Interpretability
in Deep Learning for Coronavirus (COVID-19) Detection,” pp. 1–14,
2020. [Online]. Available: http://arxiv.org/abs/2003.10769

[30] J. Zhang, Y. Xie, Y. Li, C. Shen, and Y. Xia, “COVID-19 Screening on
Chest X-ray Images Using Deep Learning based Anomaly Detection,”
2020. [Online]. Available: http://arxiv.org/abs/2003.12338
[31] A. Narin, C. Kaya, and Z. Pamuk, “Automatic Detection of
Coronavirus Disease (COVID-19) Using X-ray Images and Deep
Convolutional Neural Networks,” 2020. [Online]. Available: http:
//arxiv.org/abs/2003.10849
[32] X. He, S. Wang, S. Shi, X. Chu, J. Tang, X. Liu, C. Yan, J. Zhang, and
G. Ding, “Benchmarking deep learning models and automated model
design for covid-19 detection with chest ct scans,” medRxiv, 2020.
[33] D. Singh, V. Kumar, Vaishali, and M. Kaur, “Classification of COVID19 patients from chest CT images using multi-objective differential
evolution-based convolutional neural networks,” European journal of
clinical microbiology & infectious diseases : official publication of
European Society of Clinical Microbiology, 2020.
[34] A. A. Ardakani, A. R. Kanafi, U. R. Acharya, N. Khadem, and
A. Mohammadi, “Application of deep learning technique to manage
COVID-19 in routine clinical practice using CT images: Results
of 10 convolutional neural networks,” Computers in Biology and
Medicine, vol. 121, no. March, p. 103795, 2020. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0010482520301645
[35] M. Z. Alom, M. M. S. Rahman, M. S. Nasrin, T. M. Taha, and V. K.
Asari, “Covid MTNet: Covid-19 detection with multi-task deep learning
approaches,” 2020.
[36] X. He, X. Yang, S. Zhang, J. Zhao, Y. Zhang, E. Xing, and P. Xie,
“Sample-Efficient Deep Learning for COVID-19 Diagnosis Based on
CT Scans,” medRxiv, vol. XX, no. Xx, p. 2020.04.13.20063941, 2020.
[37] A. Mobiny, P. A. Cicalese, S. Zare, P. Yuan, M. Abavisani, C. C.
Wu, J. Ahuja, P. M. de Groot, and H. Van Nguyen, “Radiologist-Level
COVID-19 Detection Using CT Scans with Detail-Oriented Capsule
Networks,” 2020. [Online]. Available: http://arxiv.org/abs/2004.07407
[38] “Deep Learning-based Detection for COVID-19 from Chest CT using
Weak Label,” medRxiv, p. 2020.03.12.20027185, 2020. [Online]. Available: http://medrxiv.org/content/early/2020/03/17/2020.03.12.20027185
[39] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu,
Z. Fang, Q. Song et al., “Artificial intelligence distinguishes covid-19
from community acquired pneumonia on chest ct,” Radiology, p. 200905,
2020.
[40] X. He, K. Zhao, and X. Chu, “Automl: A survey of the state-of-the-art,”
arXiv preprint arXiv:1908.00709, 2019.
[41] T. Elsken, J. H. Metzen, and F. Hutter, “Neural architecture search: A
survey,” arXiv preprint arXiv:1808.05377, 2018.
[42] ——, “Efficient multi-objective neural architecture search via lamarckian evolution,” arXiv preprint arXiv:1804.09081, 2018.
[43] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. A. Mobilenets, “Efficient convolutional neural networks for mobile vision applications,” arXiv preprint arXiv:1704.04861,
2017.
[44] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[45] M. Lin, Q. Chen, and S. Yan, “Network in network,” arXiv preprint
arXiv:1312.4400, 2013.
[46] Z. Guo, X. Zhang, H. Mu, W. Heng, Z. Liu, Y. Wei, and J. Sun, “Single
path one-shot neural architecture search with uniform sampling,” arXiv
preprint arXiv:1904.00420, 2019.
[47] H. Zhu, Z. An, C. Yang, K. Xu, E. Zhao, and Y. Xu, “Eena: efficient evolution of neural architecture,” in Proceedings of the IEEE International
Conference on Computer Vision Workshops, 2019, pp. 0–0.
[48] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
2014.
[49] I. Loshchilov and F. Hutter, “Sgdr: Stochastic gradient descent with
warm restarts,” 2016.
[50] H. X. Bai, B. Hsieh, Z. Xiong, K. Halsey, J. W. Choi, T. M. L.
Tran, I. Pan, L.-B. Shi, D.-C. Wang, J. Mei, X.-L. Jiang, Q.-H. Zeng,
T. K. Egglin, P.-F. Hu, S. Agarwal, F.-F. Xie, S. Li, T. Healey, M. K.
Atalay, and W.-H. Liao, “Performance of radiologists in differentiating
covid-19 from non-covid-19 viral pneumonia at chest ct,” Radiology,
vol. 296, no. 2, pp. E46–E54, 2020, pMID: 32155105. [Online].
Available: https://doi.org/10.1148/radiol.2020200823

