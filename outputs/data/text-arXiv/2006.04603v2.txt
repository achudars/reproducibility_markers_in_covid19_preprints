End-to-end learning for semiquantitative rating of COVID-19 severity on Chest
X-rays

arXiv:2006.04603v2 [eess.IV] 6 Aug 2020

Alberto Signoronia,1,∗, Mattia Savardia,1 , Sergio Beninia , Nicola Adamia , Riccardo Leonardia , Paolo Gibellinib ,
Filippo Vaccherb , Marco Ravanellib , Andrea Borghesib , Roberto Maroldib , Davide Farinab
b Department

a Department of Information Engineering – University of Brescia, Brescia, Italy
of Medical and Surgical Specialties, Radiological Sciences, and Public Health – University of Brescia, Brescia, Italy

Abstract
In this work we design an end-to-end deep learning architecture for predicting, on Chest X-rays images (CXR), a
multi-regional score conveying the degree of lung compromise in COVID-19 patients. Such semi-quantitative scoring system, namely Brixia score, is applied in serial monitoring of such patients, showing significant prognostic
value, in one of the hospitals that experienced one of the highest pandemic peaks in Italy. To solve such a challenging
visual task, we adopt a weakly supervised learning strategy structured to handle different tasks (segmentation, spatial alignment, and score estimation) trained with a “from part to whole” procedure involving different datasets. In
particular, we exploit a clinical dataset of almost 5,000 CXR annotated images collected in the same hospital. Our
BS-Net demonstrates self-attentive behavior and a high degree of accuracy in all processing stages. Through interrater agreement tests and a gold standard comparison, we show that our solution outperforms single human annotators
in rating accuracy and consistency, thus supporting the possibility of using this tool in contexts of computer-assisted
monitoring. Highly resolved (super-pixel level) explainability maps are also generated, with an original technique, to
visually help the understanding of the network activity on the lung areas. We also consider other scores proposed in
literature and provide a comparison with a recently proposed non-specific approach. We eventually test the performance robustness of our model on a variegated public COVID-19 dataset, for which we also provide Brixia score
annotations, observing good direct generalization and fine-tuning capabilities that highlight the portability of BS-Net
in other clinical settings. The CXR dataset along with the source code and the trained model are publicly released for
research purposes.
Keywords: COVID-19 severity assessment, Chest X-Rays, semi-quantitative rating, End-to-end learning,
Convolutional Neural Networks
1. Introduction
Worldwide, the saturation of healthcare facilities, due
to the high contagiousness of Sars-Cov-2 virus and
the significant rate of respiratory complications (WHO,
∗ Corresponding

author
Email address: alberto.signoroni@unibs.it (Alberto
Signoroni)
1 Shared first authorship

2020), is indeed one among the most critical aspects of
the ongoing COVID-19 pandemic. As we write, in many
countries virulence has not yet peaked, while in others a
second wave is feared. Under these conditions, it is extremely important to adopt all types of measures to improve the accuracy in monitoring the evolution of the disease and the level of coordination and communication between different clinicians for the streamlining of healthcare procedures, from facility- to single patient-level. In
this context, thoracic imaging, specifically chest X-ray

Figure 1. Brixia score: (a) zone definition and (b-d) examples of annotations. Lungs are first divided into six zones on frontal chest radiograph.
Line A is drawn at the level of the inferior wall of the aortic arch. Line B is drawn at the level of the inferior wall of the right inferior pulmonary
vein. A and D upper zones; B and E middle zones; C and F lower zones. A score ranging from 0 (green) to 3 (black) is then assigned to each
sector, based on the observed lung abnormalities.

ing system, namely Brixia score, that was immediately implemented in the clinical routine (Borghesi and
Maroldi, 2020). With this system, the lungs are divided
into six regions, and the referring radiologist assigns to
each region an integer rating from 0 to 3, based on the
local assessed severity of lung compromise (see Figure 1
and Section 3.1 for details). Other scores have been recently proposed as well, which are less resolute either in
terms of intensity scale granularity (Toussie et al., 2020),
or localization capacity (Wong et al., 2020; Cohen et al.,
2020a) (see Section 3.2). Severity scores offer a mean
to introduce the use of representation learning techniques
to automatically assess disease severity using artificial intelligence (AI) approaches starting from CXR analysis.
However, while in general computer-aided interpretation
of radiological images based on Deep Learning (DL) can
be an important asset for a more effective handling of
the pandemic in many directions (Shi et al., 2020), the
early availability of public datasets of CXR images from
COVID-19 subjects catalyzed the research almost exclusively on assisted COVID-19 diagnosis (i.e. dichotomous
or differential diagnosis versus other bacterial/viral forms
of pneumonia). This happened despite the fact that normal CXRs do not exclude the possibility of COVID-19,
and abnormal CXR is not enough specific for a reliable
diagnosis (Rubin et al., 2020). Moreover, much research
applying AI to CXR in the context of COVID-19 diagnosis considered small or private datasets, or lacked rigorous experimental methods, potentially leading to overfitting and performance overestimation (Castiglioni et al.,
2020; Maguolo and Nanni, 2020; Tartaglione et al., 2020).

(CXR) and computed tomography (CT), are playing an
essential role in the management of patients, especially
those evidencing risk factors (from triage phases) or moderate to severe COVID-19 signs of pulmonary disease
(Rubin et al., 2020). In particular, CXR is a widespread,
relatively cheap, fast, and accessible diagnostic modality,
which may be easily brought to the patient’s bed, even in
the emergency departments. Therefore, the use of CXR
may be preferred to CT not only in limited resources environments, but where this becomes fundamental to avoid
handling of more compromised patients, or to prevent
infection spread due to patient movements from and towards radiology facilities (Manna et al., 2020). Moreover
a serious X-ray dose concern arises in this context, where
serial image acquisitions on a daily basis are often advisable due to the frequency of rapid worsening of the disease and the need of a prompt assessment of the therapy
effects. For these reasons, notwithstanding a lower sensitivity compared to CT, CXR has been set up as a first
diagnostic imaging option for COVID-19 severity assessment and disease monitoring in many healthcare facilities.
Due to the projective nature of the CXR image and the
wide range of possible disease manifestations, a precise
visual assessment of the entity and severity of the pulmonary involvement is particularly challenging and semiquantitative scoring systems are usually adopted to map
radiologist judgments to numerical scales. This leads to
a more objective reporting and improved communication
among specialists. In particular, from the beginning of the
pandemic phase in Italy, the Radiology Unit 2 of ASST
Spedali Civili di Brescia introduced a multi-valued scor2

So far, no much work has been done in other directions,
such as COVID-19 severity assessment from CXR, despite this has been highlighted as one of the highest reasonable research efforts to be pursued in the field of AIdriven COVID-19 radiology (Laghi, 2020; Cohen et al.,
2020c).

2017). Far from constituting in itself a “weakness”,
these approaches have demonstrated to be highly valuable methods to leverage available knowledge in medical domains (Xu et al., 2014; Wang et al., 2017; Karimi
et al., 2019; Bontempi et al., 2020; Tajbakhsh et al., 2020).
All this given, and being the adopted scoring system the
richer among others proposed for the same purpose (see
1.1. Aims and contributions
Sec. 3.2), our goal results to be particularly challenging,
Main goal. In this work, we aim at introducing the first especially considering radiologists’ performance as a tarrepresentation-learning solution specifically designed to get to reach, and to possibly overcome.
obtain an effective and reliable assessment of the severity
End-to-end severity assessment architecture. We develof COVID-19 disease by means of an automated CXR in- oped an original multi-network Deep Learning-based arterpretation. This system must be able to produce a multi- chitecture of which we give a high-level representation in
regional scoring estimation by autonomously operating Figure 2. The system is designed as to learn and execute
on data directly coming from different X-ray modalities different tasks such as: data normalization, lung segmen(computed radiography, CR, and digital radiography by tation, geometric alignment, feature extraction, and the
Direct X-ray detection, DX), acquisition directions (an- final multi-valued score estimation. Although the presteroposterior, AP, and posteroanterior, PA) and patient ence of specific task dedicated stages, the overall logic is
conditions (e.g., standing, supine, with or w/o the pres- end-to-end, which is reached through a hierarchical orgaence of life support systems), providing robust data con- nization of the training, according to a from-the-part-toditioning and self-attentive behavior. This corresponds to the-whole strategy. This consists of leveraging multiple
a highly difficult visual task, as further detailed in Sec- datasets of various nature and origins (described in Section 3.
tion 4) for early training stages, then arriving at a global
Large CXR database. For this purpose, we collected (involving all network portions) severity assessment trainand operated on a large dataset of almost 5,000 CXRs, ing, based on the large collected dataset. Our end-to-end
which can be assumed representative of all possible man- network architecture, called BS-Net and described in deifestations and degrees of severity of the COVID-19 tail in Section 5, is thus characterized by the joint work of
pneumonia, since these images come from the whole different sections, represented as a group of four hexagons
flow of hospitalized patients in one of the biggest health in Figure 2, comprising 1) a shared multiresolution feature
facilities in northern-Italy during the pandemic peak. extraction backbone, 2) a state-of-art lung segmentation
Since a highly-expressive multi-zone scoring system branch, 3) an original registration mechanism capable of
(Brixia score) was adopted from the very beginning spatially normalizing the feature computation stream in
of the pandemic period, our CXR dataset is fully anno- the backbone, and 4) a multi-regional classification part
tated with scores directly coming from the patients’ med- for the final six-valued score estimation. Performance roical records, as provided by the reporting radiologist on bustness is also guaranteed by the choice of the loss funcduty among the about 30 specialists forming the radiology tion which comprises a differentiable version of the target
staff. Therefore, we have the possibility to work on a com- discrete metric.
plete and faithful picture of an intense and emergencyExplainability maps. In the perspective of a responsidriven clinical activity.
ble and transparent exploitation of the proposed solution,
Weakly supervised learning framework. Given the dif- there is the need to establish a communication channel
ficulties and pitfalls in the visual interpretation of the dis- between the specialist and the AI system. Given the spaease signs on CXRs (spanning from subtle findings to tial distribution of the severity assessment we need highly
heavy lung impairment), the lack of detailed localization resolved explainability maps. To this end we propose an
information, and the unavoidable inter-rater variability in original technique (described in Section 5.4) able to create
the semi-quantitative scoring, we was compelled to op- highly structured explanation maps at a superpixel level.
erate in a weakly supervised learning framework (Zhou,
Experimental goals. A complete set of Results (Sec3

Figure 2. Overview of the proposed method.

2. Related Work

tion 6) and related Discussion (Section 7) are articulated
in a multi-purpose validation path. 1) In terms of system
performance assessment, we select optimal configurations
and justify architectural choices also considering different
possible alternatives from the literature. 2) To cope with
the inter-rater variability and to demonstrate above radiologists’ performance, we involve a team of specialists to
establish a consensus-based gold-standard as a reference
for both single radiologist and our model ratings. 3) We
consider other scores proposed in the literature and provide a comparison with a recently proposed non-specific
approach for demonstrating both system versatility and
performance boost coming from the adoption of a specifically designed solution to severity assessment. 4) We address the problem of portability of the proposed solution
on CXRs coming from different worldwide contexts by
providing new annotations and assessing our system behavior on a public CXR dataset of reference for COVID19.

Since the very beginning of the pandemic, the attention and resources of researchers in digital technologies
(Ting et al., 2020), AI and data science (Latif et al., 2020)
have been captured by COVID-19. A review of artificial
intelligence techniques in imaging data acquisition, segmentation, and diagnosis for COVID-19 has been made
in Shi et al. (2020), where authors structured previous
work according to different tasks, e.g., contactless imaging workflow, image segmentation, disease detection, radiomic feature extraction, etc.
The use of convolutional neural networks (CNN) to analyze CXRs for presumptive early diagnosis and better
patient handling based on signs of pneumonia, has been
proposed by (Oh et al., 2020) at the very beginning of the
outbreak, when a systematic collection of a large CXR
dataset for deep neural network training was still problematic. As the epidemic was spreading, the increasing
availability of CXR datasets from patients diagnosed with
COVID-19 has polarized almost all the research efforts
on diagnosis-oriented image interpretation studies. As it
is hard to mention them all (we counted more than 80
studies, most of them in a pre-print format), the reader

Data, Code, and Model distribution. The whole dataset
along with the source code and the trained model are
available from http://github.org/BrixIA.
4

can refer to an early reviewing effort Shi et al. (2020),
while here we derive the most relevant emerging issues.
Most methods exploit available public COVID-19 CXR
datasets (Kalkreuth and Kaufmann, 2020). Constantly updated collections of COVID-19 CXR images are curated
by the authors of (Linda Wang and Wong, 2020)2 and
(Cohen et al., 2020b)3 . Prior to COVID-19, large CXR
datasets have been released and also used in the context
of open challenges for the analysis of different types of
pneumonia Wang et al. (2017)4 or pulmonary and cardiac (cardiomegaly) diseases Irvin et al. (2019)5 . These
datasets are usually exploited as well in works related to
COVID-19 diagnosis, as in (Minaee et al., 2020), to pretrain existing networks and fine-tune them on a reduced
set of COVID-19 CXRs, or to complete case categories
when the focus is on differential diagnosis to distinguish
from other types of pneumonia (Linda Wang and Wong,
2020; Oh et al., 2020; Li et al., 2020b). However, beyond
the fact that CXR modality should be more appropriate
for patient monitoring and severity assessment than for
primary COVID-19 detection, other issues severely affect
the previous studies which employed CXR for COVID19 diagnosis purposes (Burlacu et al., 2020). In particular, many of these data-driven works are interesting in
principle, but almost all would require and benefit from
extensions and validation on a higher number of CXRs
from COVID-19 subjects. Working with datasets of a few
hundred images, when analyzed with deep architectures,
often results in severe overfitting and can encounter issues generated by unbalanced classes when larger datasets
are used to represent other kinds of pneumonia (Pereira
et al., 2020). Moreover, most of the studies issued in this
emergency period are often based on sub-optimal experimental designs, and the numerous still unknowns factors
about COVID-19 severely undermine the external validity and generalizability of the performance of diagnostic tests (Sardanelli and Di Leo, 2020). In (Maguolo
and Nanni, 2020) it is pointed out that many CXR based
systems seem to learn to recognize more the character-

istics of the dataset rather than those related to COVID19. This effect can be overcome, or at least mitigated,
by working on more homogeneous and larger datasets, as
in (Castiglioni et al., 2020), or by preprocessing the data
as in (Pereira et al., 2020). In addition, automated lung
segmentation can play an essential role in the design of
a robust respiratory disease interpretation system, either
diagnosis-oriented (Tartaglione et al., 2020) or, as we see
in this work, for pneumonia severity assessment. Lung
segmentation on CXR has been recently witnessing a convergence towards encoder-decoder architectures, such as
in the U-Net framework (Ronneberger et al., 2015), and
in the fully convolutional approach found in Long et al.
(2015). All these approaches share skip connections as
a common key element, originally found in ResNet (He
et al., 2016) and DenseNet architectures (Huang et al.,
2017). The idea behind skip connections is to combine
coarse-to-fine activation maps from the encoder within the
decoding flow. In doing so, these models are capable of
efficiently using the extracted information from different
abstraction layers. In Zhou et al. (2018), a nested U-Net
is presented, bringing the idea of skip connection to its
extreme. This approach is well suited to capture finegrained details from the encoder network, and exploding them in the decoding branch. Last, in critical sectors like healthcare, the lack of understanding of complex
machine-learned models is hugely problematic. Therefore, explainable AI approaches able to reveal to physicians where is directed the model attention (Karim et al.,
2020; Oh et al., 2020; Rajaraman et al., 2020; Reyes et al.,
2020), are always desirable. Despite some evidenced issues, there is still an abundant ongoing effort on AI-driven
approaches for COVID-19 detection based on CXR analysis. However, in the global race to contain and treat
COVID-19 (Kundu et al., 2020), AI-based solutions have
high potentials to expand the role of chest imaging beyond
diagnosis, to facilitate risk stratification, disease progression monitoring, and trial of novel therapeutic targets.
Cautions about a radiologic diagnosis of COVID-19 infection driven by deep learning have been also expressed
by Laghi (2020), who states that a more interesting application of AI in COVID-19 infection is to provide for
a more objective quantification of the disease, in order to
allow the monitoring of the prognostic factors (i.e., lung
compromising severity) for appropriate and timely patient
treatment. For example, the presence of AI-assisted first

2 https://github.com/lindawangg/COVIDNet/blob/master/docs/COVIDx.md
3 https://github.com/ieee8023/covid-chestxray-dataset
4 https://www.kaggle.com/c/rsna-pneumonia-detectionchallenge/data
5 https://stanfordmlgroup.github.io/competitions/chexpert/

5

preliminary readings, or working with AI-generated second opinions, can lead to better procedures in terms of
speed-up and efficiency of decision-making, especially in
critical conditions like the ones characterizing the management of health facilities overload. In particular, we did
not find dedicated AI-driven solutions for disease monitoring and lung severity assessment based on CXR, although this modality, for the aforementioned reasons, is
part of the routine practice in many institutions, like the
one from which this study originates. In (Cohen et al.,
2020a), different kinds of features coming from a neural network pre-trained on non-COVID-19 CXR datasets
are considered in their predictive value on the estimation of COVID-19 severity scores. In (Li et al., 2020a) a
good correlation is reported between a lung based severity score judgement and machine prediction by using a
transfer learning approach from a large non-COVID-19
dataset to a small COVID-19 one. However, authors acknowledge several limitations in the capability to handle
image variability that can arise due to patient condition
and image acquisition settings.
From these early studies, the need for dedicated research toward solutions for the challenging visual task
of COVID-19 severity assessment on CXRs coming from
real clinical settings, and the necessity to operate on large
annotated datasets, clearly emerge.

diology Unit 2 of ASST Spedali Civili di Brescia (Borghesi and Maroldi, 2020), and later validated for risk stratification on a large population in (Borghesi et al., 2020b).
According to it, lungs in antero-posterior (AP) or posteroanterior (PA) views, are subdivided into six zones, three
for each lung, as shown in Figure 1(a). For each zone, a
score 0 (no lung abnormalities), 1 (interstitial infiltrates),
2 (interstitial and alveolar infiltrates, interstitial dominant), or 3 (interstitial and alveolar infiltrates, alveolar
dominant) is assigned, based on the characteristics and
extent of lung abnormalities. The six scores can be aggregated to obtain a Global Score in the range [0, 18]. Examples of scores assigned to different cases are showcased
in Figure 1(b-d). As in daily practice CXR exams are inevitably reported by different radiologists, this combined
codification of the site and type of lung lesions makes the
comparison of CXR exams faster and significantly more
consistent, and this allows a better handling of patients.
3.2. Other severity scores and possible relations among
them
In (Toussie et al., 2020) the presence/absence of pulmonary COVID-19 alterations is mapped on a 1/0 score
associated to each of six pulmonary regions according to
a subdivision scheme substantially reproducing the one
of the Brixia score. We here refer to this score as
T score which globally ranges from 0 to 6. By ignoring slight differences in terms of anatomic landmarks that
guide the radiologist to determine the longitudinal lung
subdivisions, the T score can be directly estimated from
the Brixia score by just mapping the set of values
{1, 2, 3} of the latter to the value 1 of the former.
In (Cohen et al., 2020a) two different COVID-19 severity scores are considered which are derived and simplified versions of a composite scoring system proposed by
(Warren et al., 2018) int the context of lung oedema. Both
scores are composed by couples of values, one for each
lung: 1) a geographic extent score, here GE score, in
the integer range [0, 8] and 2) a lung opacity score, here
LO score in the integer range [0, 6]. The GE score, introduced in (Wong et al., 2020) for COVID-19 severity assessment, assigns for each lung a value depending on the
extent of involvement by consolidation or ground glass
opacity (0 = no involvement; 1 ≤ 25%; 2 = 25 − 50%; 3 =
50 − 75%; 4 ≥ 75% involvement). While this area-based

3. Scoring systems for severity assessment
CXR severity scoring based on the subdivision of lungs
in different regions (Borghesi and Maroldi, 2020; Toussie
et al., 2020; Wong et al., 2020) evidenced significant prognostic value when applied in serial monitoring of COVID19 patients (Borghesi et al., 2020a,b). Since the radiologists are asked to map a global or region-based qualitative
judgment on a quantitative scale, this diagnostic image interpretation task can be defined as semi-quantitative, i.e.
characterized by a certain degree of subjectivity. Following, a detailed description of the three semi-quantitative
scoring systems we found in use and we also consider in
this work.
3.1. Brixia score
The multi-region and multi-valued Brixia score was
designed and implemented in routine reporting by the Ra6

quantification has no clear correspondence to the judgment made with the Brixia score, a possible mapping
can be estimated with the LO score (e.g., by a simple linear regression, as we will see in Sec.6.5), which assigns
for each lung a value depending on degree of opacity (0 =
no opacity; 1 = ground glass opacity; 2 = consolidation;
3 = white-out). A global score derived by a modified version of the ones introduced in (Warren et al., 2018) has
been also used in (Li et al., 2020a).

Eventually, the same visual task related to global or
localized COVID-19 severity assessment is challenging
in itself, since CXR findings may be extremely variable
(from no or subtle signs to extensive changes that modify
anatomical patterns and borders), and the quality of the information conveyed by the images may be impaired from
the presence of medical devices, or from sub-optimal patient positioning.
All these factors, if not handled, can impact in an
unpredictable way on the reliability of an AI-based interpretation. This concomitant presence of quantitative
and qualitative aspects, on a difficult visual analysis task,
makes the six-valued Brixia score estimation on CXR
particularly challenging.

3.3. AI-based prediction of severity scores
At first sight, an automatic assessment of a semiquantitative prognostic score may seem easier than other
tasks, such as differential diagnosis, or purely quantitative severity evaluations. Nevertheless, when dealing with
semi-quantitative scores, major critical aspects arise.
First, the difficulty of establishing a ground truth information, since subjective differences in scoring are expressed by different radiologists while assessing and qualifying the presence of, sometimes subtle, abnormalities.
This differs from more quantitative tasks that can be associated to measurable targets, as in the case of DL-based
quantitative (volumetric) measure of opacities and consolidations on CT scans for lung involvement assessment in
COVID-19 pneumonia (Huang et al., 2020; Gozes et al.,
2020; Lessmann et al., 2020). The application of quantitative methods to AI-driven assessment of COVID-19
severity on CXR, however, is not advisable due to the projective nature of these images, with inherent ambiguities
in relating opacity area measures to corresponding volumes.
A semi-quantitative scoring system can instead leverage the sensitivity of CXR as well as the ability of radiologists to detect COVID-19 pneumonia and communicate in an effective way its severity according to an agreed
severity scale.
Second, the exact localization of the lung zones and
of severity-related findings (even within each of the selected lung zones) remains implicit and related to the visual attention of the specialist in following anatomical
landmarks (without any explicit localization information
indicated with the score, nor any lung segmentation provided). This results in the difficulty to define reference
spatial information usable as ground truth and implies significantly incomplete annotations with respect to the task.

4. Dataset
Training and validation of the proposed multi-network
architecture (Figure 2) require the use of multiple
datasets, which are described in the following.
4.1. Segmentation datasets
For the segmentation module we exploit and merge
three different datasets: Montgomery County (Jaeger
et al., 2014), Shenzhen Hospital (Stirenko et al., 2018),
and JSRT databases (Shiraishi et al., 2000), for a total of
about 1,000 images. When indicated we adopt the original training/test set splitting (as for the JSRT database);
otherwise, we consider the first 50 images as test set, and
the remaining as training set (see Table 1).
Table 1
Segmentation datasets.

Training-set

Test-set

Split

Montgomery County
Shenzhen Hospital
JSRT database

88
516
124

50
50
123

first 50
first 50
original

Total

728

223

4.2. Alignment dataset
CXRs acquired in a real clinical setting lack of standardized levels of magnification and alignment of the
lungs. Moreover, possible patient positions are different
7

(standing, sitting, prone, supine) and, according to subject conditions, it is not always feasible to produce images
with an ideal shooting of the chest. To avoid the inclusion
of anatomical parts not belonging to the lungs in the AI
pipeline, which would increase the task complexity and
introduce unwanted biases, we integrate in the pipeline
an alignment block. This exploits the same images used
for the segmentation stage to create a synthetic dataset
formed by artificially transformed images (see Table 2),
including random rotations, shifts, and zooms, which are
used in first phases of the training, in an on-line augmentation fashion, using the framework provided in (Buslaev
et al., 2020).

All image reports include the Brixia score as a
string of six digits indicating the scores assigned to each
region. The Global Score is simply the sum of the six
numbers. Each image has been annotated with the sixvalued score by the radiologist on shift (here referred to
as R0 ), belonging to a team of about 30 radiologists operating in different radiology units of the hospital with
a very wide range of years of experience and different
specific expertise in imaging of the chest. All images
were collected and anonymized, and their usage for this
study had the approval of the local Ethical Committee
(#NP4121) that also granted an authorization to release
the whole anonymized dataset for research purposes. The
main characteristics of the dataset are summarised in Table 3.

Table 2
Alignment dataset: synthetic transformations. The parameters refer to
the implementation in Albumentation (Buslaev et al., 2020). In the last
column is expressed the probability of application of each
transformation.

Rotation
Scale
Shift
Elastic transformation
Grid distortion
Optical distortion

Parameters (up to)

Probability

25 degree
10%
10%
alpha=60, sigma=12
step=5, limit=0.3
distort=0.2, shift=0.05

0.8
0.8
0.8
0.2
0.2
0.2

Table 3
Brixia COVID-19 dataset details.

4.3. Brixia COVID-19 dataset
We collected a large dataset of CXR images corresponding to the entire amount of images taken for both
triage and patient monitoring in sub-intensive and intensive care units during one month (between March 4th and
April 4th 2020) of pandemic peak at the ASST Spedali
Civili di Brescia, and contains all the variability originating from a real clinical scenario. It includes 4,707 CXR
images of COVID-19 subjects, acquired with both CR and
DX modalities, in AP or PA projection, and retrieved from
the facility RIS-PACS system. All data are directly imported from DICOM files, consisting in 12-bit gray-scale
images, and mapped to float32 between 0 and 1. To mitigate the grayscale variability in the dataset, we normalize the appearance of the CXR by sequentially applying
an adaptive histogram equalization (CLAHE, clip:0.01),
a median filtering to cope with noise (kernel size: 3), and
a clipping outside the 2nd and 98th percentile.

Parameter

Value

Modality

CR (62%) - DX (38%)

View position

AP (87%) - PA (13%)

Manufacturers

Carestream, Siemens

Image size

(1056 ÷ 3050) ×
(1186 ÷ 3376)

No. of images

4,703

Training set

3, 311 images

Validation set

945 images

Test set

447 images

4.3.1. Consensus-based Gold Standard
To assess the level of inter-rater agreement among human annotators, we asked other 4 radiologists to rate a
subset of 150 images belonging to the test set of the Brixia
COVID-19 dataset. While R0 is the original clinical annotation in the patient report, we name R1 , R2 , R3 , and R4 the
four radiologists that provided additional scores. Their
expertise is variegated so as to represent the whole staff
experience: we have one resident at the 2nd year of training, and three staff radiologists with 9, 15 and 22 years
of experience (reported numerical ordering of Ri does
not necessarily correspond to seniority order). A Gold
8

Brixia-score

Input
CXR

Segmentation
probability
mask

1

0

2

2

3

2

θ → Tθ(G)

256
A

D

1,0

B

E

0,8

C

F

0,5

A

D

B

E

C

F

0,3

128

0,0

Aligned
probability
mask

A

D

B

E

C

F

A

D

B

E

C

F

FPN x 6
FPN x 6
FPN x 6

Score extraction

64

32

FPN x 6

Optional hard self-attention

Blocks

Confidence

Alignment

512

Convolutional block

Dense layer

Backbone

Sampler

ROI pooling

Decoder stage

Nested U-Net

Primary feature alignment

Pixelwise multiplication

Global average pooling

Figure 3. Detailed scheme of the proposed architecture. In particular, in the top-middle the CXR to be analyzed is fed to the network. The
produced outputs are: the segmentation mask of the lungs (top-left); the aligned mask (middle-left); the Brixia score (top-right).

Standard score is then built based on a majority criterion, by exploiting the availability of multiple ratings (by
R0 , R1 , R2 , R3 , and R3 ), using seniority in case of equally
voted scores. Building such Gold Standard is useful, on
the one hand, to grasp the inbuilt level of error in the training set, and on the other hand, to gain a reference measure
for human performance and inter-rater variability assessments.

certified staff member R s and a trainee R j , with 22 and
2 years of experience, respectively, produced the related
Brixia score annotations for CXR in this collection,
exploiting labelbox7 , an online solution for labelling.
After discarding problematic cases (e.g., images with a
significant portion missing, too low resolution/quality, the
impossibility of scoring for external reasons, etc.), the obtained dataset is composed of 192 CXRs, completely annotated according to the Brixia score system 8 .

4.4. Public COVID-19 dataset
5. End-to-end multi-network model

To later demonstrate the robustness and the portability
of the proposed solution, we exploit the public repository
by Cohen et al. (2020b), which contains CXR images of
patients which are positive or suspected of COVID-196 .
This dataset is an aggregation of CXR images collected in
several centers worldwide, at various spatial resolutions,
and other unknown image quality parameters, such as
modality and window-level settings. In order to contribute
to such public dataset, two expert radiologists, a board-

5.1. Proposed architecture
To predict the pneumonia severity of a given CXR, we
propose a novel architecture where different networks cooperate, in an end-to-end scheme, to segment, align, and
predict the Brixia score. The global scheme is depicted in Figure 3, while details on single parts follow.
7 https://labelbox.com/

6 We

8 Available
from both https://github.com/BrixIA/Brixia-scoreCOVID-19 and https://github.com/ieee8023/covid-chestxray-dataset

downloaded a copy on May 11th, 2020.

9

Backbone. The input image is initially processed by a
cascade of convolutional blocks, referred to as Backbone
(in yellow in Figure 3). This cascade is used both as the
encoder section of the segmentation network, and as the
feature extractor for the Feature Pyramid Network of the
classification branch. To identify the best solution at this
stage, we tested different backbones among the state-ofthe-art, i.e., ResNet (He et al., 2016), VGG (Simonyan
and Zisserman, 2014), DenseNet (Huang et al., 2017), and
Inception (Szegedy et al., 2017).
Segmentation. Lung segmentation is performed by a
nested version of U-net, also called U-Net++ (Zhou et al.,
2018), a specialized architecture oriented to medical image segmentation (in blue in Figure 3). It is composed of
an encoder-decoder structure, where the encoder branch
(i.e., the Backbone) exploits a nested interconnection to
the decoder.

Figure 4. Example of the alignment through the sampling grid
produced by the transformation matrix, and its application to both the
segmentation mask and the feature maps. On the right, the
hard-attention mechanism and the ROI Pooling operation.

used for spatial normalization and alignment of extracted
features, but not to mask the CXR image.

Alignment. The segmentation probability map in output is then used to estimate the alignment transformation, which is employed to align both the segmentation
mask and the feature pyramid. Alignment is achieved
through a spatial transformer network (Jaderberg et al.,
2015) able to estimate the spatial transform matrix to center and correctly zoom the lungs. This alignment block,
pre-trained on the synthetic alignment dataset, produces
a self-attentive mechanism useful to propagate the correct area of the lungs, through the ROI (Region Of Interest) pooling, towards the final classification stage. In
Figure 4 a high-level representation where the alignment
through resampling is depicted on the left. This resampling scheme can be used for both the features from the
backbone and for the segmentation map.

ROI Pooling. The aligned (and optionally hard masked)
features are finally used to estimate the 3 × 2 matrix containing the Brixia score. To this purpose, ROI Pooling
is performed on a fixed grid with the same dimensions. In
particular, lung regions are vertically overlapped by 25%,
with no horizontal overlap (since the left/right boundary
between lungs is easily identified, while the vertical separation presents a larger variability). This pooling module
introduces a-priori information regarding the location of
the six regions (i.e, A, B, . . . , F), while leaving to the network the role to correctly rearrange the lungs by means of
the alignment block.

Scoring head. The final scoring module exploits the ideas
of Feature Pyramid Networks (FPN) (Lin et al., 2017) for
the generation of multi-scale feature maps. As depicted
Hard vs. Soft self-attention. A hard self-attention mech- in Figure 3, we combine feature maps that come from
anism can also be applied by masking the aligned fea- various levels of the network, therefore with different setures with the hard segmentation mask (obtained as soft- mantic information at various resolutions. The presence
max probability map). This option has the advantage of the alignment block, in conjunction with the optional
of switching off possible misleading regions outside the masking, produces input feature maps that are well folungs, favoring the flow of relevant regions only. There- cused on the specific area of interest. Eventually, the outfore the network can operate in two configurations: ei- put of the FPN layer flows in a series of convolutional
ther with a hard self-attention scheme (HA), in which the blocks to retrieve the output map (3 × 2 × 4, i.e., 3 rows, 2
soft-max segmentation mask (from 0 to 1) is used as a columns, and 4 possible scores [0, . . . , 3]). The classifica(product) weighting mask for the CXR image, or with a tion is performed by a final Global Average Pooling layer
soft version (SA), where the segmentation mask is only and a SoftMax activation.
10

5.2. Loss Function and Model Training

5.3. Implementation details

The network has an input size of 512 × 512. The seThe Loss function we use for training, is a sparse categorical cross entropy (SCCE) with a (differentiable) mean lected backbone is a ResNet-18 He et al. (2016), because
it offers the best trade-off between the expressiveness of
absolute error (MAEd ) contribution:
the extracted features and the memory footprint (as in the
L = α · SCCE + (1 − α) · MAEd
(1) case of the input size). In the network, we use the rectified
linear unit (ReLU) activation functions for the convoluwhere α controls how much weight is given to SCCE and tional layer of the backbone, and the U-Net++, while the
MAEd , which are defined as follows:
Swish activation function by Ramachandran et al. (2017)
is used for the remaining blocks. We extensively make use
1X
yc log(ŷc )
(2) of online augmentation throughout the learning phases. In
SCCE = −
C c
particular, we apply all the geometric transformations described in Section 4.2, plus random brightness and conX eβŷc
1
d
y−
MAE =
c
(3) trast, as well. Moreover, we randomly flip images horP
βŷ j
C
e
izontally (and the score, accordingly) with a probabilj∈C
c∈C
ity of 0.5. We exploit, for training purposes, two mawhere y is the reference Brixia score, ŷ is the prechines equipped with Titan® V GPUs. We train the model
dicted one, and c ∈ [0, 1, . . . 3] is the score class. To make
by jointly optimizing the sparse categorical cross-entropy
the mean absolute error differentiable (MAEd ), β can be
function and MAE, with a selected α = 0.7. Convergence
chosen to be an arbitrary large value.
is achieved after roughly 6hours of training (80 epochs),
The selection of such loss function is coherent with
using Adam (Kingma and Ba, 2014) with an initial learnthe choice to configure the Brixia score problem as a
ing rate of 3 · 10−2 , halving it on flattening. Furthermore,
joint multi-class classification and regression. Tackling
we set the batch size to 8.
our score estimation as a classification problem allows to
associate to each score a confidence value: this can be
useful to either produce a weighted average, or to intro- 5.4. Super-pixel explainability maps
duce a quality parameter that the system, or the radioloTo evaluate whether the network is predicting the severgist, can take into account. Moreover, the MAEd compo- ity score on the basis of correctly identified lung areas, we
nent, while being meaningful for the scoring system, adds need a method capable of generating explainability maps
robustness to outliers and noise.
with a sufficiently high resolution. Unfortunately, with the
Due to the nature and complexity of the proposed ar- chosen network architecture, the popular Grad-CAM apchitecture, the training of network’s weights takes place at proach (Selvaraju et al., 2017) generates poorly localized,
several stages, according to a from-the-part-to-the-whole and spatially blurred, visual explanations of activation restrategy. The different sections of the overall network gions, as it happens for example also in (Oh et al., 2020).
are first pre-trained on specific tasks: U-Net++ is trained For these reasons, we designed a novel method for generusing the lung segmentation masks in the segmentation ating useful explainability maps. Loosely inspired by the
datasets; the alignment block is trained using the syn- LIME (Ribeiro et al., 2016) initial phases, we first genthetic alignment dataset (in a semi-supervised setting); erate a partitioning scheme of the segmented and aligned
the classification portion (Scoring head) is trained using lungs using Quick-shift (Vedaldi and Soatto, 2008). For
Brixia COVID-19 dataset, while blocking the weights of each of the N generated super-pixel, we create an imthe remainder (i.e., Backbone, Segmentation, Alignment). age with the corresponding super-pixel set to zero value
Then a complete fine-tuning on Brixia COVID-19 dataset (super-pixel-masked image), and for such N images we
follows, making all weights (about 20 Million) trainable. predict the six-valued Brixia score (thus excluding the
The network hyper-parameters eventually undergo a se- specific super-pixel from the computation). We then aclection that maximizes the MAE score on the validation cumulate the differences with respect to the predicted valset.
ues considering the whole original images for each score
11

class on the specific super-pixel. Given S the set of superpixels, the output explanation map E is obtained as:

methods (Candemir and Antani, 2019), both DL based
(Zhou et al., 2018; Frid-Adar et al., 2018; Oh et al., 2020),
and hybrid (Candemir et al., 2014). Table 4 reports the re|S |
X
sults for the U-Net++ (and U-Net comparison) in terms
E=
S i · (pi − p0 )
(4)
of Dice coefficient and Intersection over Union (IoU), aka
i
Jaccard index, obtained on the test set of the segmentation
where p0 is the probability map obtained with the original datasets (Sec.4.1). Training curves for the segmentation
input, while pi is the probability associated to the super- task (on both training set, and validation set), tracking the
pixel-masked image. Intuitively, the obtained map high- IoU, are shown in Figure 7-a for BS-Net in HA configulights the region that most accounts for the final score. ration.
Examples can be appreciated in Figure 2 (bottom-right) as
Table 4
well as in Figure 9: the more intense the color, the more
Lung segmentation performance.
important the region contribution to the score decision.
6. Results
Through an articulated experimental validation we first
consider how single components of the architecture operate (Sections 6.1 and 6.2) and we give a complete picture of the severity assessment performance referred to
the whole collected dataset (Section 6.3). Then we deal
with the inter-rater variability issue and demonstrate that
the proposed solution overcomes the radiologists’ performance on a consensus based Gold Standard reference
(Section 6.4). We then widen the scope of our results
in two directions: 1) we consider other proposed severity scores and give measures, observations, and comparisons that clearly support the need of dedicated solutions
to the COVID-19 severity assessment (Section 6.5); 2)
we consider the portability (both direct or mediated by
a fine-tuning) of our model on public data collected in
the most different locations and conditions, verifying a
high degree of robustness and generalization of our solution (Section 6.6). Qualitative evidences of the role that
the new explainability solution can have in a responsible
and transparent use of the technology are then proposed
(Section 6.7). We conclude with an ablation study essentially aiming at showing how the complexity of our multinetwork architecture is neither over- nor under-sized, but
it is adequate to the needs and complexity of the target
visual task (Section 6.8). All results presented in this section are discussed in the following Section 7.
6.1. Lung segmentation
The performance of the segmentation stage shows totally comparable results with respect to state-of-the-art

U-Net++
U-Net

Backbone

Dice coefficient

IoU

ResNet-18
ResNet-18

0.971
0.969

0.945
0.941

6.2. Alignment
After training on the synthetic dataset described in Section 4.2, we report the following alignment results: Dice
coefficient = 0.873, IoU = 0.778. Given the difficulty of
the task and the fact that simulated transforms are usually overemphasised with respect to misalignment found
in real data, this apparently fair performance is fully satisfactory in our context. Moreover, during a visual check
on all 4,707 images in the Brixia Covid-19 dataset, no
impairing misalignment (lung outside the normalized region) was observed. Residual errors are typically in the
form of slight rotations and zooms, which are not critical
and well tolerable in terms of overall self-attentive behavior. Training curves for the alignment task (on both training set, and validation set), tracking the IoU, are shown
in Figure 7-b, always for HA configuration. Convergence
behaviors are clearly visible, with a consolidating residual
distance between training and validation curves.
6.3. Score prediction on Brixia COVID-19 dataset
To evaluate the overall performance of the network,
we analyze the Brixia score predictions with respect
to the score assigned by the radiologist(s) R0 , i.e. the
one(s) who originally annotated the CXR during the clinical practice. Discrepancies found on the 449 test images of Brixia COVID-19 dataset are evaluated in terms

12

Table 5
Brixia score prediction performance parameters for the four considered models on the Brixia COVID-19 dataset (only blind test set results
reported). Parameters are evaluated on each single lung region (A-F), averaged on all the lung regions and on the Global Score (P-value
 0.00001 everywhere).

BS-Net-Ens
BS-Net-SA
BS-Net-HA
ResNet-18
BS-Net-Ens
BS-Net-SA
BS-Net-HA
ResNet-18
BS-Net-Ens
BS-Net-SA
BS-Net-HA
ResNet-18
BS-Net-Ens
BS-Net-SA
BS-Net-HA
ResNet-18

A

B

C

D

E

F

Avg. on
regions

Global
score

MEr

0.169
0.107
0.156
0.356

-0.038
-0.087
-0.147
-0.038

-0.056
-0.171
-0.085
-0.056

0.125
0.082
0.107
0.125

-0.045
-0.129
-0.016
-0.045

-0.192
-0.343
-0.238
-0.192

-0.006
-0.090
-0.037
0.100

-0.036
-0.541
-0.223
0.601

MAE

0.459
0.499
0.481
0.543

0.448
0.501
0.477
0.486

0.412
0.506
0.481
0.506

0.374
0.408
0.370
0.452

0.459
0.499
0.488
0.584

0.494
0.566
0.532
0.530

0.441
0.496
0.471
0.517

1.728
1.846
1.826
1.951

SD

0.604
0.638
0.613
0.657

0.524
0.560
0.575
0.579

0.540
0.579
0.583
0.591

0.541
0.576
0.552
0.632

0.574
0.594
0.594
0.657

0.609
0.634
0.616
0.601

0.565
0.597
0.589
0.619

1.429
1.514
1.505
1.710

CC

0.675
0.635
0.665
0.598

0.779
0.733
0.742
0.739

0.731
0.675
0.679
0.667

0.682
0.633
0.662
0.562

0.737
0.718
0.722
0.655

0.672
0.636
0.645
0.643

0.713
0.672
0.686
0.644

0.862
0.847
0.845
0.842

of Mean Error (MEr), Mean Absolute Error (MAE) with
its standard deviation (SD), and Correlation Coefficient
(CC).
Four networks are considered for comparison, three of
which are different configurations of BS-Net: the hard attention (HA) one, the soft attention (SA) one, and one
ensemble of the two previous configurations (ENS). In
particular ENS configuration exploits both HA and SA
paths to make the final prediction (by averaging their output probabilities): these realizations are the best model
with respect to the validation set, and the obtained model
after the last training iteration. The fourth compared network is ResNet-18 (the backbone of our framework) as an
all-in-one solution (with no dedicated segmentation, nor
alignment stage), since it is one among the most adopted
architectures in studies involving CXR analyses, also until today in the COVID-19 context.
Table 5 lists all performance values referred to each of
the six regions (A to F) of the Brixia score (range [03]), to the average on single regions, and to the Global
Score (range [0-18]). In a consistency assessment perspective, Figures 5 (top) and (bottom) show the confu-

sion matrices for the four networks related to the score
value assignments for single lung regions, and for their
sum (Global Score), respectively. From Table 5 it clearly
emerges that the ensemble decision strategy (ENS) succeeds in combining the strengths of the soft and hard attention policies, with the best average MAE on the six
regions of 0.441. Conversely, the straightforward end-toend approach offered by means of an all-in-one ResNet-18
is always the worst option compared to the three BS-Net
configs.
The error distribution analysis on MAE, depicted in
Figure 6, shows the prevalence of lower error values on
both single lung regions and Global Score estimations.
The joint view gives another evidence that single-region
errors unlikely sum up as constructive interference. Training curves for this prediction task (on both training set,
and validation set), tracking the Mean Absolute Error
(MAE) on the set of lung sectors are shown in Figure 7-c
(HA configuration). Convergence behaviors are clearly
visible, with a consolidating residual distance between
training and validation curves.

13

ResNet18

BS-Net-SA

BS-Net-HA

Avg. on regions

BS-Net-Ens

Global Score

Figure 5. Consistency/confusion matrices based on lung regions score values (top, 0–3), and on Global Score values (bottom, 0–18).

MAE

MAE

120
80
40
0

40

80

120

7

Global Score (MAE)

6
5
4
3
2
1
0
0.00

0.25

0.50

0.75

6.4. Performance assessment on Consensus-based Gold
Standard
Results in Table 5 are computed with respect to the
score assigned by a single radiologist (i.e., R0 ) among the
ones in the whole staff. With the aim of providing a more
reliable reference, we consider the Consensus-based Gold
Standard (CbGS) dataset (Sec.4.3.1). This allows to recompute the BS-Net (ENS) performance on a subset of
150 images, which are annotated with multiple ratings (by
R0 , R1 , R2 , R3 , and R4 ) from which a consensus reference
score is derived. Table 6 (top-center) clearly shows a significant improvement on MAE with respect to the comparison versus R0 only (0.424 vs. 0.452).

1.00

Avg. on regions (MAE)

Figure 6. Single and joint MAE distribution for lung regions and
Global Score predictions obtained by BS-Net (ENS).

Inter-rater agreement: human vs. machine performance.
In Figure 8 we assess the inter-rater agreement by listing
MAE and SD values referred to all possible pairs of raters,
including R0 , and also BS-Net (ENS), as a further “virtual
rater”. Looking at how BS-Net behaves (orange boxes in
Figure 8), we observe the level of agreement reached between the network and any other rater is, almost always,
higher than the inter-rater agreements between any pair of
14

0.96

0.7

0.80

0.65

0.92

0.6

MAE

IOU

IOU

0.88
IOU

IOU

0.70

0.5
Global Score

Avg. on regions

0.60

0.84

0.80

0.55

0.45

0

25

50

75

100

125

150

175

0.50

0

25

50

75

100

125

150

175

0

200

10

20

30

40

Step

Step

Step

(a)

(b)

(c)

50

60

80

70

Figure 7. Training curves related to BS-Net-HA. Segmentation (a); Alignment (b); Brixia score prediction – best single model (c).

Table 6
Results on the Consensus-based Gold Standard dataset (150 images):
(top) performance of BS-Net (ENS) computed on the Consensus-based
Gold Standard; (center) performance of BS-Net (HS) vs original rater
R0 ; (bottom) averaged performance of all Ri vs CbGS

MEr

MAE

SD

Avg. on regions
4

Global Score
BS
-N

et

4

BS

-N
e

t

CC

BS-Net (ENS) vs. CbGS
Avg. on reg.
Global score

-0.133
0.800

0.424
1.787

0.580
1.354

0.743
0.907

BS-Net (ENS) vs. R0
Avg. on reg.
Global score

-0.019
-0.113

0.452
1.847

0.575
1.553

4

0.754
0.834

Figure 8. Pairwise inter-rater results in terms of MAE (and SD). In the
most right column (orange), the inter-rater results with predictions by
BS-Net-Ens.

Average on all pairs of radiologists
Avg. on reg.
Global score

-0.131
-0.784

0.528
2.592

0.614
1.965

0.736
0.835

human raters. For example, by considering R0 as a common reference, we have an equal performance only in the
case of R4 . Table 6 confirms how BS-Net (top) performs
on average significantly better (MAE 0.424) with respect
to the global indicators (bottom) coming from averaging
all pairwise Ri vs R j (i , j) comparisons (MAE 0.528).
The inter-rater agreement values (between human
raters) indicates a fair to moderate level of agreement
(both averaged two-raters Cohen’s kappa value and multirater Fleiss’ kappa value, based on single cell scores, are
around 0.4). One the one hand, this is a confirmation that
the Brixia score, probably succeeds in reaching the
though compromise between maximizing the score expressiveness (spatial and rating granularity) while keeping under control the level of subjectivity (inter-rater vari-

ability). On the other hand, measured inter-rater variability levels constitute a clear limitation that bound the network learning abilities, concurrently allowing to assess
whether the network surpasses single radiologists performance. The opportunity for the network to learn not only
from a single radiologist but virtually from a fairly large
community of specialists (being R0 a varying radiologist)
is, de facto, the margin that we have been able to exploit.
6.5. Performance assessment on other severity scores
In Table 7 we show the performance related to sixvalued T score, akin to the score presented in (Toussie
et al., 2020), derived by thresholding the Brixia score
as described in Section 3.2. We provide results on both the
whole Brixia COVID-19 test set and on the ConsensusBased Gold Standard set. Interestingly, the correlation
increases from 0.73 on the whole test set to 0.81 on the

15

Table 7
T score performance (faithful simulation of the score proposed in
(Toussie et al., 2020)).

from a junior radiologist R j ), we performed a portability
study, with the aim of deriving some useful guidance for
extended use of our model on data generated in other facilities. In particular, we carried out three tests on BS-Net
MEr
MAE SD
CC
(HA configuration) measuring the performance on: 1) the
BS-Net-ENS on the whole test set
whole set of 192 annotated images (full); 2) a reduced test
set with fine-tuning, after random 75/25 splitting (subset,
Avg. on reg. 0,009
0,147 0,349 0,51
fine-tuning); 2) a reduced test set with partial retraining
Global score 0,056
0,742 0,921 0,728
of the network, after random 75/25 splitting, with segBS-Net-ENS on the CbGS set
mentation and alignment blocks trained on their specific
Avg. on reg. -0,074 0,174 0,38
0,563
datasets (subset, from scratch). In reporting results, we
Global score -0,447 0,94
1,07
0,81
considered the senior radiologist R s as the reference in order to have the possibility to assess the second rater R j
performance the same way we assess the network perforCbGS set, while MAE, despite maintaining acceptable mance. Table 9 lists all results from the above described
values, increases as well (probably due to a residual from tests.
a non perfect mapping between the two scores).
Looking at results on the full dataset, we can deIn Table 8 we simulate the computation of the rive that, even by directly applying the model trained on
LO score by Brixia score mapping followed by lin- the Brixia COVID-19 dataset on a completely different
ear regression (see Sec.3.2). Thanks to annotations we dataset (and collected in a highly uncontrolled way), the
provided for CXRs in the dataset by (Cohen et al., 2020c) network confirms the meaningfulness of the learning task
we had the possibility to perform a direct comparison and shows a fair robustness to work in different context
with the non-specific method described in Cohen et al. even in an uncontrolled way. On the other hand, the
(2020a) from which we report only the best results. We skilled human observer confirms higher generalization careport the results produced by BS-Net-ENS on the in- pability, with a MAE of 0.405 on the full dataset. On
tersection between the subset of the Cohen dataset con- the reduced subset, when retrained from scratch, the netsidered in our work (Sec.4.4) and the CXRs we found work is not able anymore to produce even the results obused in Cohen et al. (2020a) (a retrospective cohort tained by the same model trained on the Brixia COVID-19
of 94 PA CXR images). We also produce the results dataset: a clear evidence of the need to work with a large
considering the whole subset for which we produced dataset and of the adequate capacity of our model. This
Brixia score annotations (obtaining virtually equiva- is further confirmed by looking at the fine-tuning results,
lent results). We also report LO score related results where the network reaches the best performance (MAE
starting from Brixia score assigned by our experts. 0.465) by exploiting an already trained baseline.
The performance boost produced by a prediction from a
specifically designed solution is evident, and this is co- 6.7. Explainability maps
herent also to the considerations and limitations acknowlIn Figure 9 we illustrate some explainability maps genedged by the authors of Cohen et al. (2020a).
erated on Brixia COVID-19 data: three are exact predictions (top), while two are chosen among the most diffi6.6. Public COVID-19 datasets: portability tests
cult cases (bottom). Along with maps, we also report the
The aggregate public CXR dataset (Cohen et al., related lung segmentation and alignment images. Such
2020b), described in Section 4.4, has been judged as in- maps, obtained as described in Section 5.4, clearly highherently well representative with respect to the various light the regions that triggered a specific score: they are
manifestations degrees of COVID-19. For this reason, drawn with the colour of the class score (i.e., 1 = orange,
it represents a good test bed to assess model portability. 2 = red, 3 = black) in case they significantly contributed to
Exploiting the two independent Brixia score annota- the decision for that score, while a white coloured region
tions of this dataset (one from a senior R s , and another means that it gave no contribution to such score decision.
16

Table 8
Opacity score linear regression from global Brixia score.

Correlation

R2

MAE

MSE

coef

intercept

0.80±0.05
0.84±0.05
0.85±0.08
0.90±0.06

0.60±0.17
0.54±0.17
0.53±0.24
0.72±0.13

1.14±0.11
0.67±0.10
0.67±0.12
0.55±0.10

2.06±0.34
0.68±0.18
0.67±0.22
0.45±0.15

–
0.31±0.01
0.31±0.01
0.28±0.01

–
0.15±0.08
0.09±0.09
0.55±0.07

from
Best (Cohen et al., 2020a)
BS-Net on Cohen set
BS-Net on our subset
R s on our subset

Table 9
Portability tests on the public dataset (Cohen et al., 2020b). MAE and its SD are listed for both reporting radiologist R j and BS-Net-HA. The
network has been used in three training conditions: 1) as is, originally trained on the Brixia COVID-19 dataset (full), 2) fine-tuned on the public
dataset (subset, fine-tuning), and 3) completely retrained, classification part only, on the public dataset (subset, from scratch).

Test

A

B

C

D

E

F

Avg. on
regions

Global
score

MEr

full
subset
full
subset
subset
subset

0.135
0.149
0.177
0.125
0.208
0.146

0.182
0.234
-0.167
-0.104
0.396
0.167

0.156
0.191
-0.177
-0.188
0.104
-0.042

0.115
0.000
0.167
0.167
0.250
0.229

0.177
0.191
-0.208
-0.063
0.042
0.167

0.021
0.021
-0.651
-0.583
0.063
-0.208

0.131
0.131
-0.143
-0.108
0.177
0.076

0.786
0.787
-0.859
-0.646
1.063
0.458

MAE

full
subset
full
subset
subset
subset

0.396
0.404
0.521
0.458
0.375
0.479

0.401
0.447
0.438
0.479
0.646
0.500

0.438
0.489
0.552
0.521
0.604
0.500

0.333
0.340
0.385
0.375
0.458
0.354

0.396
0.362
0.438
0.479
0.542
0.458

0.469
0.447
0.776
0.625
0.479
0.500

0.405
0.415
0.518
0.490
0.517
0.465

1.974
1.851
2.214
2.396
2.188
2.000

Radiologist R j
BS-Net-HA
* from scratch
* fine-tuning
Radiologist
BS-Net-HA
* from scratch
* fine-tuning

The first row of Figure 9 offers a clear overview of the
agreement level between the network and the radiologist
in shift (R0 ). Conversely, the two cases in the bottom row
of Figure 9 evidences both under- and over-estimations in
single sectors, despite producing a correct Global Score
in the case on the left.

leading to the Brixia score estimation (see Scoring
head in Section 5.1). We then compare the adopted FPNbased solution with three different configurations. The
first, simplified, configuration gets rid of the multi-scale
approach, so that the score estimation exploits the features
extracted by the backbone head. The second, more complex, configuration envisages an articulated multi-scale
6.8. Ablation study
approach based on the EfficientDet (Tan et al., 2019),
Adopting BS-Net in the HA configuration, we con- where BiFPN (Bidirectional FPN) blocks are introduced
ducted an ablation study comprising two sets of experi- for an easy and fast multi-scale feature fusion. The third
ments, which are carried out on the training (3,313 CXRs) configuration adds one resolution level to the FPN to aland on the validation (945 CXRs) sets of the Brixia low the flow of 1, 024 × 1, 024 images. Results on this
COVID-19 database.
benchmark are reported in Table 10. While the first simplified configuration produces an improved MAE on the
Feature Extraction. This set of experiments investigates
training set, we observe a poorer generalization capability
on the type and complexity of the feature map extraction
17

Input CXR

Segmented and
aligned lungs

Input CXR

Predicted

R0
GT

Predicted

Segmented and
aligned lungs

Input CXR

Predicted

R0
GT

Segmented and
aligned lungs

R0
GT

0

0

0

0

0

0

0

0

0

0

0

0

0

2

0

2

0

2

0

2

2

1

2

1

0

1

0

1

1

3

1

3

3

2

3

2

Score 1

Score 2

Score 3

Score 1

Segmented and
aligned lungs

Input CXR

Score 2

1

2

2

3

1

1

0

2

3

2

2

3

1

2

1

3

3

2

3

3

3

2

2

Score 2

Score 3

Score 2

Score 3

R0

Predicted

1

Score 1

Score 1

Segmented and
aligned lungs

Input CXR

R0
GT

Predicted

Score 3

Score 1

Score 2

Score 3

Figure 9. Results and related explainability maps obtained on five examples from the Brixia COVID-19 test set. (top) Three examples of accurate
predictions. (bottom) Two critical cases in which the prediction is poor with respect to the original clinical annotation R0 . For each block, the most
left image is the input CXR, followed by the aligned and masked lungs. In the second row we show the predicted Brixia score with respect to
the original clinical annotation R0 , and the explainability map. In such maps the relevance is colored so that white means that the region does not
contribute to that prediction, while the class colour (i.e., 1 = orange, 2 = red, 3 = black) means that the region had an important role in the
prediction of thaT score class.

Table 10
Performance on the training and validation set for different Feature
Pyramid Networks (or lack of).
(∗) No complete fine-tuning due to memory limitation

on the validation set. The complex configuration, instead,
produces a worsening on both data sets. Therefore FPN
confirms to be a good intermediate solution between the
latter two configurations. Eventually, adding one resolution level produces again a performance worsening (this is
a confident indication despite, for memory limitations, we
did not succeeded in performing a complete fine-tuning).
Data Augmentation. The second investigated matter regards whether the pre-processing and augmentation policies we adopted are effective, or if there are some prevailing or redundant constituents. In Table 11 we present the
results of performed experiments which combines different augmentation policies: it is clearly evident that partial
augmentation policies are not adequate, since they pro-

FPN (adopted)
Backbone head
BiFPN
FPN 1024 (∗)

Train MAE (SD)

Val MAE (SD)

0.455 (0.578)
0.395 (0.542)
0.486 (0.593)
0.498 (0.564)

0.469 (0.583)
0.475 (0.592)
0.504 (0.598)
0.498 (0.589)

duce performance worsening on the validation set, and
tend to create overfitting gaps between training and validation performance. Conversely, their joint use produces
best results and not such a gap. Moreover, we can appre18

ciate the impact of the pre-processing equalization, which
is able to correctly handle the grayscale variability in the
dataset.
Table 11
Performances on the training and validation set for different
augmentation policies.

No augmentation
Bright. & contrast
Geometric transf.
All together
All together

Pre
proc.

Train MAE (SD)

Val MAE (SD)

y
y
y
n
y

0.306 (0.490)
0.341 (0.518)
0.272 (0.460)
0.437 (0.585)
0.455 (0.578)

0.528 (0.610)
0.550 (0.628)
0.541 (0.623)
0.571 (0.645)
0.469 (0.583)

7. Discussion
We have introduced an end-to-end image analysis system for the assessment of a semi-quantitative rating based
on a highly difficult visual task. The estimated lung severity score is, by itself, the result of a compromise: on the
one hand, the need for a clinically expressive granularity
of the different stages of the disease; on the other hand,
the built-in subjectivity in the interpretation of CXR images, stemming from the intrinsic limits of such imaging modality, and from the high variability of COVID-19
manifestations. As an additional complication, the available Brixia score, even if coming from expert personnel, has neither ground truth characteristics (as ratings are
affected by inter-observer variability), nor it is highly accurate in terms of spatial indication (since scores are related to generic rectangular regions).
The best performance in the prediction of the
Brixia score is obtained, in all tests, by using an ensemble decision strategy (ENS). Reported mean absolute
errors on the six regions are: MAE=0.441, when compared against the clinical annotations by radiologist R0 on
the whole test set of 450 CXRs; and MAE=0.424 when
compared against a Consensus-based Gold Standard set
of 150 images annotated by 5 radiologists. Naively speaking, being the scoring scale defined on integers, any MAE
measured on single regions below 0.5 could be interpreted as acceptable. This might appear as a simplified
reasoning, but interviewed radiologists, with hundreds of
19

cases of experience of such semi-quantitative rating system, also indicated, from a clinical perspective, ±0.5 as
an acceptable error on each region of the Brixia score,
and ±2 as an acceptable error on the Global Score from 0
to 18. These indications are also backed up by the prognostic value and associated use of the score as a severity
indicator that comes from the experimental evidence and
clinical observations during the first period of its application (Borghesi et al., 2020a).
The above a-priori interpretation of “acceptable” error
on a single region is clearly not sufficient. It is also for
this reason that we built a CbGS. This is useful to have
a reference measure of the inter-rater agreement between
human annotators, acting as a boundary measure of human performance. This is relevant since, being a source
of error in our weakly supervised approach, such interrater agreement also determines an implicit limit to the
performance we can expect from the network. Tests on
the CbGS confirm that, on average, the level of agreement reached between the network and any other human
rater is slightly above the inter-rater agreements between
any pair of human raters, thus statistically evidencing that
performance of BS-Net overcome those of radiologists
in accomplishing the task. This is a fundamental basis
to think at clinically oriented studies in a perspective of
a responsible deployment of the technology in (humanmachine collaborative or computer-aided diagnosis) clinical settings. A MAE under 0.5 for both the network and
radiologists is also an indirect evidence of the fact that the
Brixia score rating system (on four severity values) is
a good trade-off between the two opposite needs of having
a fine granularity of the rating scale, and a good inter-rater
agreement. Moreover, what comes out from the comparison with other scoring systems is that the Brixia score
can be considered as a good super-set with respect to others. This is provided by either a good spatial granularity
(over six regions), and a good sensibility (over four levels).
The fact that the ensemble decision strategy combines
the strengths of the soft and hard attention policies deserves some further elaboration. In fact, if on one hand,
removing the context is fine to avoid possible bias on the
decision, on the other hand, the context info can help
when the segmentation is too restrictive. For example,
retrocardiac consolidations that could be visible are removed from the lung segmentation and therefore their as-

sessment is not allowed in the hard attention approach.
This residual complementarity between the two options is
exploited by the ensemble decision and this can explain
the significant improvement. This also clearly justifies
the more structured approach we designed, which demonstrates to pay-off right from the soft-attention configuration. Another aspect that emerges looking at MEr is that
our architecture does not over/under-estimate, while the
other compared architecture (ResNet-18) tends to overestimate. A last qualitative evidence in favor of the use of
the composite loss function of Equation 1, comprising an
additional component related to the MAE, is that the performance we obtain are unbiased and stable over several
repetitions of the whole training process.
Portability tests performed on public datasets can be
easily turned into clear guidelines for the use of the
proposed model on data originated at different facilities
and/or on related clinical contexts (e.g., severity assessment of other kind of pneumonia). In fact, from collected evidence, there are all the makings of a highly
portable model: performance are robust to change of settings, while fine tuning is advisable for performance optimization.
For what concerns explainability maps, this information can be used to increase trust in the outcome, and point
in possible confounding situations. We had a valuable
positive general feedback from radiologists that considered these maps as a possible complementary source of
visual attention and of second level reasoning in a possible scenario of computer-assisted diagnosis. Looking for
example at Figure 9, some additional considerations are
possible. The case on the bottom-left part, despite producing a correct Global Score (considered a positive fact by
the radiologists, given the specific case), evidences both
under- and over-estimations in single sectors. Reviewed
by a senior radiologist, this case evidenced some problematic areas even for the radiologists that are often called to
express an average score about what they see in different
areas. For this reason the super-pixel explainability maps
constitute a useful machine-human communication tool.
In particular the sector A interested by the presence of an
assisted ventilation device can determine a common problem for both machine an expert, but the machine proves
to not diverge toward unduly high ranking, while the expert ruled in favor to the machine in the other upper lung
sector (D), while confirms a slight overestimation in sec-

tor E. In general, we can appreciate the fact that external equipment do not harm the prediction, nor produces
unwanted biases as in Figure 9(top-middle, bottom-left,
bottom-right). The last case (bottom right) evidences a
segmentation error on the right lung, since part of the
colon (filled by air, pulling up the diaphragm and compressing the lung) enters in the segmentation mask, determining a wrong evaluation of the corresponding area.
However, the radiologist positively considered the fact
that the system sees a difference of two levels between the
upper lung portions, which the expert considered a more
coherent judgment at a second view. From these qualitative observations and explainability map support, we can
conclude that, despite the automated AI-driven scoring is
not meant to eliminate the evaluation of the radiologist,
it can be used to aid and streamline the reporting workflow, and improving the timeliness of first evaluation, by
proposing a preliminary interpretation of findings. Such
aid might also prove useful in case of shortage of radiologists, condition that might be worsened due to the spread
of contagion among physicians.
The main limitations of this work are related to residual errors. Despite highly aligned with radiologists’ performance and not evidencing statistical biases, a case-bycase deeper comparison of possible causes of error could
guide further improvement of the image analysis architecture. In particular, since the segmentation task is sometimes ambiguous and hard to accomplish, better solutions
should be designed to handle anomalies in the segmentation results.

8. Conclusions and future directions
Our study for the estimation of a semi-quantitative rating of lung severity is justified and driven by the strong
clinical reasons related to the role of CXR images for the
management of COVID-19 patient monitoring, especially
in conditions of overloaded healthcare facilities. Working with a very large dataset of almost 5,000 images allowed to develop a solution which deals with all aspects
of the problem, also thanks to other datasets which are exploited in a hierarchical end-to-end training process. The
prospected solution is designed to work in a weakly supervised context and to be capable of manifesting selfattentive abilities on data directly coming from all CXR

20

modalities/devices and in all clinical and patient care conditions. Having tested architectural variants, and targeted
ablation studies, the network performance ultimately surpasses qualified radiologists in rating accuracy and consistency. We also collected evidences of the robustness
and portability of the model, that favorably highlights its
application to other clinical settings. All annotated CXRs
and the proposed models are made available for research
purposes9 .
Regarding future work, observed results constitute a
strong basis in a perspective of more clinically oriented
validations and in a perspective of trustable and responsible deployment. An interesting clinical scenario to evaluate is the following: whether, in case the BS-Net follows
the same patient, it could exhibits greater self-coherent
behavior if compared to the case where serial CXR acquisitions are reported by different radiologists (according to
availability and working shifts). Another direction to consider is the possibility to exploit CT images from COVID19 patients to derive semi-quantitative ground truth information directly from the quantitative volumetric assessments.

References
Bontempi, D., Benini, S., Signoroni, A., Svanera,
M., Muckli, L., 2020. CEREBRUM: a fast and
fully-volumetric Convolutional Encoder-decodeR for
weakly-supervised sEgmentation of BRain strUctures
from out-of-the-scanner MRI. Medical Image Analysis
62, 101688.
Borghesi, A., Maroldi, R., 2020. COVID-19 outbreak
in italy: experimental chest x-ray scoring system for
quantifying and monitoring disease progression. La radiologia medica .
Borghesi, A., Zigliani, A., Golemi, S., Carapella, N.,
Maculotti, P., Farina, D., Maroldi, R., 2020a. Chest xray severity index as a predictor of in-hospital mortality
in coronavirus disease 2019: A study of 302 patients
from italy. International Journal of Infectious Diseases
96, 291 – 293.
Borghesi, A., Zigliani, A., Masciullo, R., Golemi, S.,
Maculotti, P., Farina, D., Maroldi, R., 2020b. Radiographic severity index in COVID-19 pneumonia: relationship to age and sex in 783 italian patients. La
radiologia medica .

Declaration of Competing Interest
None.

Acknowledgements
The authors would like to thank colleagues of the Information and IT System Operational Units of ASST
Spedali Civili di Brescia, Francesco Scazzoli, Silvio Finardi, Roberto Marini, and Sabrina Vicari for providing
the infrastructure. A very special thanks to Marco Renato
Roberto Merli, and Andrea Carola of Philips S.p.A., and
to Gian Stefano Bosio, and Simone Gaggero of EL.CO.
S.r.l (Cairo Montenotte, Italy) for their outstanding technical support.

Burlacu, A., Crisan-Dabija, R., Popa, I.V., Artene, B.,
Birzu, V., Pricop, M., Plesoianu, C., Generali, D.,
2020. Curbing the AI-induced enthusiasm in diagnosing COVID-19 on chest X-Rays: the present and the
near-future. medRxiv .
Buslaev, A., Iglovikov, V.I., Khvedchenya, E., Parinov,
A., Druzhinin, M., Kalinin, A.A., 2020. Albumentations: Fast and flexible image augmentations. Information 11.
Candemir, S., Antani, S., 2019. A review on lung boundary detection in chest x-rays. International Journal of
Computer Assisted Radiology and Surgery 14, 563–
576.

Candemir, S., Jaeger, S., Palaniappan, K., Musco, J.P.,
Singh, R.K., Xue, Z., Karargyris, A., Antani, S.,
Thoma, G., McDonald, C.J., 2014. Lung Segmentation
in Chest Radiographs Using Anatomical Atlases With
9 Note for reviewers: the dataset is subject of a separate data-only
Nonrigid Registration. IEEE Transactions on Medical
journal submission while models will be released upon acceptance of
this paper.
Imaging 33, 577–590.
21

Castiglioni, I., Ippolito, D., Interlenghi, M., Monti, C.B.,
Salvatore, C., Schiaffino, S., Polidori, A., Gandola,
D., Messa, C., Sardanelli, F., 2020. Artificial intelligence applied on chest X-ray can aid in the diagnosis
of COVID-19 infection: a first experience from lombardy, italy. medRxiv .
Cohen, J.P., Dao, L., Morrison, P., Roth, K., Bengio, Y.,
Shen, B., Abbasi, A., Hoshmand-Kochi, M., Ghassemi,
M., Li, H., Duong, T.Q., 2020a. Predicting COVID-19
pneumonia severity on chest x-ray with deep learning.
arXiv:2005.11856.

COVID-19: Deep-learning approach. Radiology: Cardiothoracic Imaging 2, e200075.
Irvin, J., Rajpurkar, P., Ko, M., Yu, Y., Ciurea-Ilcus, S.,
Chute, C., Marklund, H., Haghgoo, B., Ball, R., Shpanskaya, K., et al., 2019. Chexpert: A large chest
radiograph dataset with uncertainty labels and expert
comparison, in: Proceedings of the AAAI Conference
on Artificial Intelligence, pp. 590–597.
Jaderberg, M., Simonyan, K., Zisserman, A.,
kavukcuoglu, k., 2015. Spatial Transformer Networks, in: Advances in Neural Information Processing
Systems 28. Curran Associates, Inc., pp. 2017–2025.

Cohen, J.P., Morrison, P., Dao, L., 2020b. COVID19 image data collection.
arXiv 2003.11597
Jaeger, S., Candemir, S., Antani, S., Wáng, Y.X.J., Lu,
URL:
https://github.com/ieee8023/
P.X., Thoma, G., 2014. Two public chest x-ray datasets
covid-chestxray-dataset.
for computer-aided screening of pulmonary diseases.
Quantitative imaging in medicine and surgery 4, 475.
Cohen, J.P., Morrison, P., Dao, L., Roth, K., Duong,
T.Q., Ghassemi, M., 2020c. COVID-19 image data
Kalkreuth, R., Kaufmann, P., 2020. COVID-19: A
collection: Prospective predictions are the future.
survey on public medical imaging data resources.
arXiv:2006.11988.
arXiv:2004.04569.
Frid-Adar, M., Ben-Cohen, A., Amer, R., Greenspan, H.,
Karim, M.R., Dhmen, T., Rebholz-Schuhmann, D.,
2018. Improving the segmentation of anatomical strucDecker, S., Cochez, M., Beyan, O., 2020. Deeptures in chest radiographs using u-net with an imagenet
COVIDExplainer: Explainable COVID-19 predictions
pre-trained encoder, in: Image Analysis for Moving Orbased on chest x-ray images. arXiv:2004.04582.
gan, Breast, and Thoracic Images. Springer, pp. 159–
168.
Karimi, D., Dou, H., Warfield, S.K., Gholipour, A.,
2019. Deep learning with noisy labels: exploring
Gozes, O., Frid-Adar, M., Greenspan, H., Browning,
techniques and remedies in medical image analysis.
P.D., Zhang, H., Ji, W., Bernheim, A., Siegel, E.,
arXiv:1912.02911.
2020. Rapid ai development cycle for the coronavirus
(COVID-19) pandemic: Initial results for automated Kingma, D.P., Ba, J., 2014. Adam: A method for stochasdetection and patient monitoring using deep learning
tic optimization. arXiv preprint arXiv:1412.6980 .
CT image analysis. arXiv:2003.05037.
Kundu, S., Elhalawani, H., Gichoya, J.W., Kahn, C.E.,
He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual
2020. How might ai and chest imaging help unravel
learning for image recognition, in: Proceedings of the
COVID-19’mysteries? Radiology: Artificial IntelliIEEE conference on computer vision and pattern recoggence 2, e200053.
nition, pp. 770–778.
Laghi, A., 2020. Cautions about radiologic diagnosis of
Huang, G., Liu, Z., Van Der Maaten, L., Weinberger,
COVID-19 infection driven by artificial intelligence.
K.Q., 2017. Densely connected convolutional netThe Lancet Digital Health 2, e225.
works, in: Proceedings of the IEEE conference on comLatif, S., Usman, M., Manzoor, S., Iqbal, W., Qadir, J.,
puter vision and pattern recognition, pp. 4700–4708.
Tyson, G., Castro, I., Razi, A., Boulos, M.N.K., Weller,
Huang, L., Han, R., Ai, T., Yu, P., Kang, H., Tao, Q.,
A., Crowcroft, J., 2020. Leveraging Data Science To
Xia, L., 2020. Serial quantitative chest ct assessment of
Combat COVID-19: A Comprehensive Review .
22

Lessmann, N., Snchez, C.I., Beenen, L., Boulogne, L.H., Manna, S., Wruble, J., Maron, S., Toussie, D., VoutsiBrink, M., Calli, E., Charbonnier, J.P., Dofferhoff, T.,
nas, N., Finkelstein, M., Cedillo, M.A., Diamond, J.,
van Everdingen, W.M., Gerke, P.K., Geurts, B., GiEber, C., Jacobi, A., Chung, M., Bernheim, A., 2020.
etema, H.A., Groeneveld, M., van Harten, L., HenCOVID-19: A Multimodality Review of Radiologic
drix, N., Hendrix, W., Huisman, H.J., Igum, I., Jacobs,
Techniques, Clinical Utility, and Imaging Features. RaC., Kluge, R., Kok, M., Krdzalic, J., Lassen-Schmidt,
diology: Cardiothoracic Imaging 2, e200210.
B., van Leeuwen, K., Meakin, J., Overkamp, M., van
Rees Vellinga, T., van Rikxoort, E.M., Samperna, R., Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., Jamalipour Soufi, G., 2020. Deep-covid: Predicting
Schaefer-Prokop, C., Schalekamp, S., Scholten, E.T.,
covid-19 from chest x-ray images using deep transfer
Sital, C., Stger, L., Teuwen, J., Vaidhya Venkadesh,
learning. Medical Image Analysis , 101794.
K., de Vente, C., Vermaat, M., Xie, W., de Wilde, B.,
Prokop, M., van Ginneken, B., 2020. Automated as- Oh, Y., Park, S., Ye, J.C., 2020. Deep learning COVID-19
sessment of co-rads and chest ct severity scores in pafeatures on cxr using limited training data sets. IEEE
tients with suspected covid-19 using artificial intelliTransactions on Medical Imaging , 1–1.
gence. Radiology 0, 202439. PMID: 32729810.
Pereira, R.M., Bertolini, D., Teixeira, L.O., Silla, C.N.,
Li, M.D., Arun, N.T., Gidwani, M., Chang, K., Deng,
Costa, Y.M., 2020.
COVID-19 identification in
F., Little, B.P., Mendoza, D.P., Lang, M., Lee, S.I.,
chest X-ray images on flat and hierarchical classificaOShea, A., Parakh, A., Singh, P., Kalpathy-Cramer,
tion scenarios. Computer Methods and Programs in
J., 2020a.
Automated assessment and tracking
Biomedicine , 105532.
of covid-19 pulmonary disease severity on chest
radiographs using convolutional siamese neural net- Rajaraman, S., Siegelman, J., Alderson, P.O., Folio, L.S.,
Folio, L.R., Antani, S.K., 2020. Iteratively pruned deep
works. Radiology: Artificial Intelligence 2, e200079.
arXiv:https://doi.org/10.1148/ryai.2020200079. learning ensembles for COVID-19 detection in chest Xrays. arXiv:2004.08379.
Li, X., Li, C., Zhu, D., 2020b. COVID-MobileXpert: OnRamachandran, P., Zoph, B., Le, Q.V., 2017.
device COVID-19 screening using snapshots of chest
Searching for activation functions. arXiv preprint
x-ray. arXiv:2004.03042.
arXiv:1710.05941 .
Lin, T.Y., Dollar, P., Girshick, R., He, K., Hariharan, B.,
Belongie, S., 2017. Feature Pyramid Networks for Object Detection, in: The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR).
Linda Wang, Z.Q.L., Wong, A., 2020. COVID-Net: A
tailored deep convolutional neural network design for
detection of COVID-19 cases from chest radiography
images. arXiv:2003.09871.
Long, J., Shelhamer, E., Darrell, T., 2015. Fully convolutional networks for semantic segmentation, in: Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 3431–3440.
Maguolo, G., Nanni, L., 2020. A Critic Evaluation of
Methods for COVID-19 Automatic Detection from XRay Images. arXiv:2004.12823.

Reyes, M., Meier, R., Pereira, S., Silva, C.A., Dahlweid,
F.M., Tengg-Kobligk, H.v., Summers, R.M., Wiest, R.,
2020. On the Interpretability of Artificial Intelligence
in Radiology: Challenges and Opportunities. Radiology: Artificial Intelligence 2, e190043.
Ribeiro, M.T., Singh, S., Guestrin, C., 2016. Why Should
I Trust You?: Explaining the Predictions of Any Classifier, in: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, Association for Computing Machinery,
New York, NY, USA. p. 11351144.
Ronneberger, O., Fischer, P., Brox, T., 2015. U-net:
Convolutional networks for biomedical image segmentation, in: International Conference on Medical
image computing and computer-assisted intervention,
Springer. pp. 234–241.
23

Rubin, G.D., Ryerson, C.J., Haramati, L.B., Sverzellati, Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., 2017.
N., Kanne, J.P., Raoof, S., Schluger, N.W., Volpi, A.,
Inception-v4, inception-resnet and the impact of residYim, J.J., Martin, I.B.K., Anderson, D.J., Kong, C.,
ual connections on learning, in: Thirty-first AAAI conAltes, T., Bush, A., Desai, S.R., Goldin, J., Goo, J.M.,
ference on artificial intelligence.
Humbert, M., Inoue, Y., Kauczor, H.U., Luo, F., MazTajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J.N., Wu,
zone, P.J., Prokop, M., Remy-Jardin, M., Richeldi, L.,
Z., Ding, X., 2020. Embracing imperfect datasets: A
Schaefer-Prokop, C.M., Tomiyama, N., Wells, A.U.,
review of deep learning solutions for medical image
Leung, A.N., 2020. The Role of Chest Imaging in
segmentation. Medical Image Analysis 63, 101693.
Patient Management during the COVID-19 Pandemic:
A Multinational Consensus Statement from the Fleis- Tan, M., Pang, R., Le, Q.V., 2019. EfficientDet: Scalable
chner Society. Radiology (simultaneously published in
and Efficient Object Detection. arXiv:1911.09070.
Chest) 0, 201365.
Tartaglione, E., Barbano, C.A., Berzovini, C., Calandri,
M., Grangetto, M., 2020. Unveiling COVID-19 from
Sardanelli, F., Di Leo, G., 2020. Assessing the Value of
chest x-ray with deep learning: a hurdles race with
Diagnostic Tests in the New World of COVID-19 Pansmall data. arXiv:2004.05405.
demic. Radiology X, 201845.
Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R.,
Parikh, D., Batra, D., 2017. Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization, in: The IEEE International Conference on
Computer Vision (ICCV).
Shi, F., Wang, J., Shi, J., Wu, Z., Wang, Q., Tang, Z.,
He, K., Shi, Y., Shen, D., 2020. Review of Artificial
Intelligence Techniques in Imaging Data Acquisition,
Segmentation and Diagnosis for COVID-19. IEEE Reviews in Biomedical Engineering , 1–1.
Shiraishi, J., Katsuragawa, S., Ikezoe, J., Matsumoto, T.,
Kobayashi, T., Komatsu, K.i., Matsui, M., Fujita, H.,
Kodera, Y., Doi, K., 2000. Development of a digital
image database for chest radiographs with and without
a lung nodule: receiver operating characteristic analysis of radiologists’ detection of pulmonary nodules.
American Journal of Roentgenology 174, 71–74.
Simonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition.
arXiv preprint arXiv:1409.1556 .
Stirenko, S., Kochura, Y., Alienin, O., Rokovyi, O., Gordienko, Y., Gang, P., Zeng, W., 2018. Chest x-ray analysis of tuberculosis by deep learning with segmentation
and augmentation, in: 2018 IEEE 38th International
Conference on Electronics and Nanotechnology (ELNANO), IEEE. pp. 422–428.

Ting, D.S.W., Carin, L., Dzau, V., Wong, T.Y., 2020. Digital technology and COVID-19. Nature Medicine 26,
459–461.
Toussie, D., Voutsinas, N., Finkelstein, M., Cedillo, M.A.,
Manna, S., Maron, S.Z., Jacobi, A., Chung, M., Bernheim, A., Eber, C., Concepcion, J., Fayad, Z., Gupta,
Y.S., 2020. Clinical and chest radiography features
determine patient outcomes in young and middle age
adults with COVID-19. Radiology 0, 201754.
Vedaldi, A., Soatto, S., 2008. Quick shift and kernel
methods for mode seeking, in: European conference
on computer vision, Springer. pp. 705–718.
Wang, X., Peng, Y., Lu, L., Lu, Z., Bagheri, M., Summers, R.M., 2017. Chestx-ray8: Hospital-scale chest
x-ray database and benchmarks on weakly-supervised
classification and localization of common thorax diseases, in: 2017 IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 3462–3471.
Warren, M.A., Zhao, Z., Koyama, T., Bastarache, J.A.,
Shaver, C.M., Semler, M.W., Rice, T.W., Matthay,
M.A., Calfee, C.S., Ware, L.B., 2018. Severity scoring
of lung oedema on the chest radiograph is associated
with clinical outcomes in ards. Thorax 73, 840–846.
WHO, 2020.
Coronavirus disease (COVID-19)
outbreak.
World Health Organization.
URL:
https://www.who.int/emergencies/diseases/
novel-coronavirus-2019.
24

Wong, H.Y.F., Lam, H.Y.S., Fong, A.H.T., Leung, S.T.,
Chin, T.W.Y., Lo, C.S.Y., Lui, M.M.S., Lee, J.C.Y.,
Chiu, K.W.H., Chung, T., Lee, E.Y.P., Wan, E.Y.F.,
Hung, F.N.I., Lam, T.P.W., Kuo, M., Ng, M.Y., 2020.
Frequency and distribution of chest radiographic findings in COVID-19 positive patients. Radiology 0,
201160.
Xu, Y., Zhu, J.Y., Chang, E.I.C., Lai, M., Tu, Z., 2014.
Weakly supervised histopathology cancer image segmentation and classification. Medical Image Analysis
18, 591 – 604.
Zhou, Z., Rahman Siddiquee, M.M., Tajbakhsh, N.,
Liang, J., 2018. UNet++: A Nested U-Net Architecture
for Medical Image Segmentation, in: Deep Learning in
Medical Image Analysis and Multimodal Learning for
Clinical Decision Support, Springer International Publishing, Cham. pp. 3–11.
Zhou, Z.H., 2017. A brief introduction to weakly supervised learning. National Science Review 5, 44–53.

25

