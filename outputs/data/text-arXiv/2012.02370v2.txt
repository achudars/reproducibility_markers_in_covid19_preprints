Birdspotter: A Tool for Analyzing and Labeling Twitter Users
Rohit Ram

Quyu Kong

Marian-Andrei Rizoiu

University of Technology Sydney
Sydney, Australia
rohit.ram@uts.edu.au

Australian National University &
UTS & Data61, CSIRO
Canberra, Australia
quyu.kong@anu.edu.au

University of Technology Sydney &
Data61, CSIRO
Sydney, Australia
marian-andrei.rizoiu@uts.edu.au

arXiv:2012.02370v2 [cs.CY] 23 Feb 2021

ABSTRACT
The impact of online social media on societal events and institutions
is profound, and with the rapid increases in user uptake, we are
just starting to understand its ramifications. Social scientists and
practitioners who model online discourse as a proxy for real-world
behavior often curate large social media datasets. A lack of available
tooling aimed at non-data science experts frequently leaves this
data (and the insights it holds) underutilized. Here, we propose
birdspotter – a tool to analyze and label Twitter users –, and
birdspotter.ml – an exploratory visualizer for the computed metrics. birdspotter provides an end-to-end analysis pipeline, from
the processing of pre-collected Twitter data to general-purpose
labeling of users and estimating their social influence, within a
few lines of code. The package features tutorials and detailed documentation. We also illustrate how to train birdspotter into a
fully-fledged bot detector that achieves better than state-of-the-art
performances without making Twitter API calls, and we showcase
its usage in an exploratory analysis of a topical COVID-19 dataset.
ACM Reference Format:
Rohit Ram, Quyu Kong, and Marian-Andrei Rizoiu. 2021. Birdspotter: A Tool
for Analyzing and Labeling Twitter Users. In Proceedings of the Fourteenth
ACM International Conference on Web Search and Data Mining (WSDM ’21),
March 8–12, 2021, Virtual Event, Israel. ACM, New York, NY, USA, 6 pages.
https://doi.org/10.1145/3437963.3441695

1

INTRODUCTION

Barely a decade old, social media in general — and Twitter in particular — are becoming increasingly important in shaping societal
events. They serve as novel fora for a wide array of users to express
themselves, discuss, promote agendas and attempt to influence the
said societal events. As a result, social and political scientists, journalists, and communication scientists increasingly turn to social
media as a proxy to study society. They carefully curate and label
large social media datasets, and here a gap emerges. There is a
limited offer of tools aimed at non-machine learning experts to
analyze users in already existing datasets without making additional web API calls that limits the amount of retrieved data. This
paper fills this gap by proposing birdspotter, a package aimed at
non-computing practitioners with quantitative expertise (basic R
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
WSDM ’21, March 8–12, 2021, Virtual Event, Israel
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8297-7/21/03. . . $15.00
https://doi.org/10.1145/3437963.3441695

Figure 1: The birdspotter.ml visualization system: Twitter
users are plotted based on their user influence and botness
(left panel), and we show a selected user’s profile (top-right)
and cascade history (bottom-right).
or Python), to analyze, describe, and automatically label users in
Twitter datasets.
This work addresses three specific open questions concerning
analyzing Twitter users. The first question relates to the availability of user analysis tools. Existing tools are typically designed for
Twitter branding and management, i.e. to either analyze a user’s
or organization’s account (Twitter Analytics6 , or Brandwatch Consumer Research7 ), or one given user account (Account Analysis
Tool8 ). The question is whether a tool exists to retrospectively
analyze and label all the users in Twitter dumps, aimed at
non-data science experts with computational expertise? We
address this question by proposing birdspotter1 , an integrated
Twitter user analysis tool, that can achieve three types of analysis
in only a couple of lines of code. First, it processes existing Twitter
datasets (e.g. jsonl data dumps collected through the Streaming
API). Second, it describes users using three types of features (relating to the user, content semantics, and hashtag usage). Last, it
allows training a classifier against a labeled user subset, which turns
birdspotter into a general-purpose inferential user analysis tool.

1 birdspotter

source code, tutorial, and feature list: https://github.com/behavioralds/BirdSpotter
2 birdspotter.ml public installation: https://www.birdspotter.ml
3 birdspotter documentation: https://birdspotter.readthedocs.io
4 COVID-19 tutorial: https://github.com/behavioral-ds/user-analysis
5 Supplementary Material: https://arxiv.org/pdf/2012.02370.pdf#page=5
6 Twitter Analytics: https://analytics.twitter.com/
7 Brandwatch Consumer Research: https://www.brandwatch.com
8 Account Analysis Tool: https://accountanalysis.app

The second open question relates to profiling user botness and
influence on previously collected data. The state-of-the-art bot detector, botometer [11], can only be accessed through its web APIs
and cannot produce predictions for users that are no longer accessible, such as suspended accounts. Since bots have a high tendency
of being suspended by Twitter, measuring botness a while after
collecting data risks missing a large proportion of the bots involved
in discussions. Similarly, existing influence estimation tools require
knowledge of the social graph, which often is impossible to capture retrospectively. The question is: can we design a tool that
quantifies users’ botness and influence on existing curated
datasets, without the need of online API calls or supplementary information? We address this question two-fold. First, using
four existing Twitter bot datasets, we train birdspotter to detect bots without requiring additional API calls. We show that
birdspotter achieves a higher performance than the current stateof-the-art botometer [11]; birdspotter ships the bot detector by
default, with the package. Second, we implement a diffusion-based
influence estimation [10], which is as accurate as using the social
graph.
The third open question is can we visualize and explore both
broad and specific views of Twitter users and their activity?
We address this question by proposing birdspotter.ml2 , a tool
that provides both broad views of the user population and detailed
inspections of user activity (see Fig. 1 for the main interface).
The main contributions of this paper are as follows:
• birdspotter1 — a software package designed for inferential
analysis of online users in pre-collected data, and to estimate
online user influence based on the reshare cascades.
• birdspotter.ml2 — an online visualizer designed to perform
exploratory analysis of Twitter users.
• an offline bot detector, built using four public labeled datasets;
we show that it achieves better than state-of-the-art performance and we showcase it on an example analysis of users
discussing COVID-194 .
Related work. Here, we present the prior work most relevant to
birdspotter. For a complete related work discussion, please refer
to the online appendix5 .
Tree-based ensemble methods dominate social bot detection
(over deep learning) due to the heterogeneity of bots and the relative sparsity of training data. The de-facto bot detection tool is
botometer (formerly BotOrNot) [4], which uses more than 1000
user- and recent activity-related features to train a Random Forest
classifier. The main limitations of botometer are 1) usage of online
APIs which are rate-limited by Twitter, 2) lack of reproducibility,
since deactivated, protected, and suspended users can no longer be
retrieved, and 3) botometer scores are likely to vary with user activity and botometer versioning. Birdspotter addresses the above
by predicting bots on pre-collected Twitter dumps.
User influence is typically measured using static user attributes [3],
analyzing the online social graph [8], and modeling information diffusion [14]. Closest to our work is ConTinEst [5], which requires
knowledge of the social graph (often prohibitively expensive to

obtain) on which it performs random walks (very slow on large social graphs). Birdspotter estimates user influence from resharing
dynamics in the absence of knowledge about the social graph.

2

PRELIMINARIES

In this section, we briefly outline prerequisites concerning influence
estimation using point-process models. For a thorough construction
of the influence estimation, please refer to the online appendix5 .
User influence estimation. birdspotter implements the algorithm in [9], estimating online influence as the mean number of
retweets generated, directly and indirectly, by a user’s (re)tweet.
Rizoiu et al. [9] estimate user influence, absent of the retweet branching structure, by assuming that retweets arrive following a Hawkes
point process [10]. They estimate the probability that the tweet
𝜙 (𝑚 ,𝑡 −𝑡 )

𝑣 𝑗 = (𝑚 𝑗 , 𝑡 𝑗 ) is a direct retweet of 𝑣𝑖 as 𝑝𝑖 𝑗 = Í 𝑗 −1 𝑖 𝑗 𝑖
,
𝜙 (𝑚 ,𝑡 −𝑡 )
𝑘=1

𝑘

𝑗

𝑘

where 𝑚 𝑗 is the associated user’s follower count, 𝑡 𝑗 is the time
of the event, and 𝜙 (𝑚, Δ𝑡) = 𝜅𝜃𝑚 𝛽 𝑒 −𝜃 Δ𝑡 is the marked Hawkes
exponential kernel of parameters 𝜅, 𝛽 and 𝜃 . The pairwise influence
represents the probability that 𝑣𝑖 indirectly generates 𝑣 𝑗 , and is
Í 𝑗−1
computed as 𝑟𝑖 𝑗 = 𝑘=𝑖 𝑟𝑖𝑘 𝑝𝑘 𝑗 when 𝑖 < 𝑗, 𝑟𝑖𝑖 = 1, and is 0 otherwise. Furthermore, a tweet’s influence is the sum of its pairwise
influences, and a user’s influence is its tweets’ influences averaged.

3

PACKAGE OVERVIEW

In this section, we give an overview of birdspotter and birdspotter.ml, and describe their usage, functionalities, and design.

3.1

birdspotter

birdspotter labels users and measures influence on previously
collected tweets in the standard jsonl or json format.
Measuring influence. birdspotter measures user influence as
outlined in Section 2, using by default a marked Hawkes exponential
kernel with parameters 𝛽 = 1, 𝜅 = 𝜃1 and 𝜃 = 6.8 × 10−4 . These
were tuned on a large collection of real cascades [9], and can be
customized using the function getInfluenceScores().
Usage and functionalities. Given a dataset of tweets collected externally (e.g. leveraging the Twitter Filter API), birdspotter’s core
functionality revolves around two steps. In the first step, birdspotter loads the Twitter dataset, extracts retweet cascades, and compiles the user-level information. In the second step, it performs
the influence analysis and user labeling. The former is achieved
by simply invoking the BirdSpotter constructor, while the latter is achieved by calling the function getLabeledUsers(), which
returns a table with the user features detailed above. For every observed cascade, birdspotter also computes the most likely branching structure (see 𝑝𝑖 𝑗 in Section 2). This can be achieved using the
function getCascadesDataFrame(), which returns the reshare cascades (i.e. original tweet and all its retweets) with the additional
column expected_parent indicating a retweet’s most likely parent
tweet.
For power users, birdspotter provides a number of robust configurations — such as changing the parameters of the Hawkes kernel or using user-defined word embeddings — documented using
its readthedocs3 documentation. A usage tutorial is available on
birdspotter’s repository1 . For users who prefer to analyze the results outside python, birdspotter can dump the user table and the

High

Mean AUC ± s.d.

0.953
1.00

0.988

0.987

0.922

0.997

0.998
0.982

0.95

0.927

0.90

0.887
0.866

0.85
0.80
BS

BT

HT

SM

TU

SM

T
T
M
+ HU + H + S
T
TU

0.82

0.39

(a)

Feature Value

veriﬁed
friends_count
years_on_twitter
n_quotes
retweet_count
status_text_n_mentions
favourite_count
des_w2v_211
statuses_rate
iphone
des_w2v_31
ﬀ_ratio
status_text_n_extraspaces
con_w2v_247
android
con_w2v_239
con_w2v_12
des_w2v_123
listed_count
con_w2v_226

<- Human-like
4

(b)

3

2

Bot-like ->
1

0

1

2

3

Low

SHAP value (impact on model output)

(c)

Figure 2: (a) Mean AUC +/- standard deviation, varying ablated models and botometer. Models/Features are indicated by BS
(birdspotter), BT (botometer), HT (Hashtags), SM (Semantic),and TU (Twitter User). (b) Mean 𝐹 1 score versus bot threshold
for birdspotter and botometer. (c) SHAP summary plot where points indicate classifier decisions, y-axis shows features in
decreasing importance, x-axis shows SHAP impact value, and color indicates feature value. Positive SHAP indicates bots.
reshare cascades in Comma Separated Values (CSV) files, that can be
loaded in outside tools. All birdspotter functionalities can be accessed in R via reticulate (https://github.com/rstudio/reticulate).
Feature Construction. birdspotter constructs user features1 in
three categories: Twitter user, semantic, and topic-based features.
Twitter user features are engineered directly from twitter user attributes and capture heuristics of common bot behavior. Semantic
features are constructed (by default) from FastText 300d word2vec
embeddings [7] of users’ tweets content and descriptions. Content
embeddings are averages of tweet embeddings, which are averages of word embeddings. Topic-based features are the vectors
of the 1,000 most frequent hashtags, scored for each user using the
term frequency-inverse document frequency scheme. birdspotter
is designed to be easily extended with any arbitrary (numerical)
features to allow for rapidly evolving bot strategies [12].
User labeling. birdspotter implements a supervised labeler. It
engineers a large selection of features, and it uses a Gradient Boosting Machine model (XGBoost [2] implementation), with hyperparameters tuned via Random Search and 5-fold cross-validation.
Beyond bot prediction. Birdspotter ships by default a pre-trained
bot classifier (see Section 4), however birdspotter can be customized to a particular application or dataset through labeling and
re-training. The function getBotAnnotationTemplate() outputs
a CSV that can be annotated by the user, and trainClassifierModel() re-trains the classifier with this annotated data. An option
controls whether the model is further tuned starting from the existing model (useful for adapting bot detection to a particular dataset)
or retrained from scratch. We exemplify this in Section 4.
Data Structures. birdspotter’s main class, called BirdSpotter,
is used to access methods and attributes.
birdspotter makes accessible three pandas dataframes through
the main object after processing: featuresDataframe (users and
their extracted features), cascadeDataframe (tweets and cascade
information), and hashtagDataframe (TF-IDF of hashtags).
Performance. birdspotter performed the extraction, processing,
and profiling of a dataset of 196,269 tweets and 129,778 users, in
just 5.7 ms per tweet, with an Intel Xeon W-2145 CPU.
Installation. birdspotter installs in the canonical Python way:
pip install birdspotter.

3.2

birdspotter.ml visualiser

birdspotter.ml2 is a visualizer built on top of birdspotter, and
designed to analyze Twitter users engaged in online discussions.
The visualisation provides both broad and specific views of the data,
via the three components shown in Fig. 1: a scatter plot component,
a user information component, and a cascade view component.
The Scatter Plot. The left panel contains the scatter-plot showing
the influence percentile (on the y-axis) and botness (on the x-axis) of
a random sample of the users from the dataset, and the underlying
2-D density over the entire data set. Users are colored based on the
hashtag they use most and, when selected, the user and cascade
views are populated. The plot is pan-able and zoom-able. The view
starts with a random sample of 1,000 users and is dynamically
populated as practitioners explore cascades.
The User View. The top-right panel provides information about a
selected user, including their Twitter image (hyperlink to the user’s
profile), screen name, location, the hashtags they used, and basic
Twitter metrics (such as the number of followers or tweets).
The Cascade View. The bottom-right panel shows the cascades
the selected user participates in, which are select-able via a carousel.
The component shows the text of the original tweet, the retweets’
timing, and the most-likely branching structure inferred using
birdspotter. The points on this component are select-able and
hover-able in the same way as the scatter plot. The component also
is pan-able and zoom-able.

4

BUILDING A BOT DETECTOR

In this section, we train birdspotter as a bot classifier with better
performances than the state of the art botometer. We showcase
birdspotter to profile a topical COVID-19 Twitter dataset.
Training data. birdspotter provides the functionality to retrain
and update the current model, which we leverage to build a bot detector. We train on four public bot datasets, including {botometerfeedback-2019, political-bots-2019} [12], and {verified-2019,
botwiki-2019} [13], sourced from Bot Repository 9 .
Training. The Bot Repository only provides account-level data,
whereas birdspotter is designed to utilize tweet jsonl. We use the
tool twarc to acquire the timeline of each available user’s first 200
9 available

from https://botometer.osome.iu.edu/bot-repository/datasets.html

3

10−5

10−3

1.7

10−3

CCDF

1

10−1

3.2

CCDF

0.27

density

10−1
2

10−5

0
0

0.5

1

botness

(a)

1

102

influence

104

1

101

102

103

user activity

(b)

Figure 3: Quantifying user botness and influence analysis on COVID-19 dataset. (a) Code required to load a Twitter dump,
generate cascade and user information, annotate and fine-tune the bot classifier. (b) A density plot of user botness scores, and
complementary cumulative density plots (CCDF) of user influence and user activity. The red lines show the mean values.
tweets, to construct jsonl training data. We extract and preprocess
the data with BirdSpotter(), label the resulting dataframe with
users’ ground truth values, and run trainClassifierModel() on
this training data to acquire our final model. We ship this model as
the default at birdspotter’s installation.
Botometer comparison. We compare the derived model against
botometer, by acquiring their bot scores (universal CAP [12]) for
available users through their API. Fig. 2a shows that birdspotter
out-performs botometer in terms of mean AUC, despite using less
information to make predictions – botometer uses more user features extracted from the online API. Fig. 2b shows that birdspotter consistently out-performs botometer with respect to mean 𝐹 1
scores, over all bot score thresholds.
Ablation study. We test the importance of each set of features
through various ablations of our main model. Fig. 2a shows the
mean AUC obtained for subsets of features. It shows that Twitter
user features and semantic features are both informative of bot-like
behavior, while hashtag features show more variation. The hashtag
model performance may be an artifact of training on the mixture of
bot datasets (containing hashtags relating to different topics). We
retain hashtag features in birdspotter, for better generalizability
when users train and test on their own domain datasets. The best
performing model uses Twitter user features and semantic features.
SHAP analysis. We use shap [6] for explaining the impact of
features in our tree ensemble model. Fig. 2c shows that the Twitter
user features form the majority, and semantic features a minority
of the impactful features, in line with the ablation study.
COVID-19 Application Dataset. We apply birdspotter to a
COVID-19 dataset [1], supplied as tweet IDs which were re-hydrated
with twarc to a jsonl format, recovering 68.8% . We limit our analysis to the ∼ 1.5M unique tweets relating to posts on January the
31st, resulting in ∼ 0.28M users and ∼ 0.42M cascades.
Dataset profiling. Fig. 3b shows the empirical distributions of
botness, influence, and activity (i.e., the number of cascades a user
participates in). The distribution of botness indicates two maxima;
the larger indicating the humans and the smaller indicating the
bots . Conforming with the literature [9], influence and activity are
long-tailed (following a “rich-get-richer” paradigm).
(Re-)Labeling Users. Exploring birdspotter.ml we observe humans — @DumplingSays, @eddfuentess, and @marat_dospolov —
with bot scores of 0.873, 0.83, and 0.925 respectively. Using getAnnotationTemplate (see Fig. 3a, line 8) we label each user as human,
and update the classifier with trainClassifier (Fig. 3a, line 10).
The new bot scores are 0.375, 0.296, and 0.559, respectively. Practitioners can use birdspotter to classify any latent user attribute.

5

CONCLUSION

We presented birdspotter, a Twitter user analysis tool aimed at
non-data science experts who analyze discourse and user activity
on social media. It provides an end-to-end analysis of users’ online
characteristics, and populates a visualizer facilitating both broad
views of a user population and individual exploration. As with
many open-source classifiers, we know that birdspotter could be
leveraged to infer sensitive features. However, we are currently not
aware of any protections that we could implement to prevent this.
Tools like birdspotter are integral to the timely, performant,
and reproducible analysis of social media users for understanding
discourse and society.

Acknowledgments
This research was partially funded by Facebook Research under the Content
Policy Research Initiative grants and the Defence Science and Technology
Group of the Australian Department of Defence.

REFERENCES
[1] Emily Chen, Kristina Lerman, and Emilio Ferrara. 2020. Tracking Social Media
Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus
Twitter Data Set. JMIR (2020).
[2] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In KDD’16.
[3] Jean-Valère Cossu, Vincent Labatut, and Nicolas Dugué. 2016. A review of features
for the discrimination of twitter users: Application to the prediction of offline
influence. SNAM (2016).
[4] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and
Filippo Menczer. 2016. Botornot: A system to evaluate social bots. In WWW.
[5] Manuel Gomez-Rodriguez, Le Song, Nan Du, Hongyuan Zha, and Bernhard
Schölkopf. 2016. Influence Estimation and Maximization in Continuous-Time
Diffusion Networks. ACM Transactions on Information Systems (2016).
[6] Scott M Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model
Predictions. In NeurIPS’17.
[7] Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and Armand Joulin. 2018. Advances in Pre-Training Distributed Word Representations.
In LREC 2018.
[8] Fabián Riquelme and Pablo González-Cantergiani. 2016. Measuring user influence
on Twitter: A survey. Information processing & management (2016).
[9] Marian-Andrei Rizoiu, Timothy Graham, Rui Zhang, Yifei Zhang, Robert Ackland,
and Lexing Xie. 2018. # DebateNight: The Role and Influence of Socialbots on
Twitter During the 1st 2016 US Presidential Debate. In ICWSM.
[10] Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie. 2017. A
Tutorial on Hawkes Processes for Events in Social Media. In Research Frontiers of
Multimedia.
[11] Mohsen Sayyadiharikandeh, Onur Varol, Kai-Cheng Yang, Alessandro Flammini,
and Filippo Menczer. 2020. Detection of Novel Social Bots by Ensembles of
Specialized Classifiers. CIKM (2020).
[12] Kai-Cheng Yang, Onur Varol, Clayton A Davis, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. 2019. Arming the public with artificial intelligence to
counter social bots. Human Behavior and Emerging Technologies (2019).
[13] Kai-Cheng Yang, Onur Varol, Pik-Mai Hui, and Filippo Menczer. 2020. Scalable
and generalizable social bot detection through data selection. In AAAI.
[14] Zizhu Zhang, Weiliang Zhao, Jian Yang, Cecile Paris, and Surya Nepal. 2019.
Learning Influence Probabilities and Modelling Influence Diffusion in Twitter. In
WWW.

Accompanying the submission Birdspotter: A Tool for Analyzing
and Labeling Twitter Users.

A

ADDITIONAL RELATED WORK

In this section, we outline other approaches to bot detection and
influence measurement in the literature.
Detecting Twitter bots. There have been a myriad of approaches
to detect bots on Twitter. There are three motifs within the literature. The first motif are supervised methods used to determine if
an individual user is a bot, usually employing feature construction.
Such approaches include NLP approaches [4, 13], deep-learning
approaches [14], feature-engineering [3, 6, 23] and other methods
[9, 15]. The second motif are unsupervised methods used to discover coordinated online behavior/real-time online campaigns; and
the third motif are adversarial methods which achieve better bot
detection by generating better bots.
birdspotter falls in the first category. It uses a supervised approach to retrospectively analyze datasets. It satisfies a different
use case than coordinated online behavior tools like BotSlayer [12].
Adversarial approaches are fairly novel, however it is unclear whether
they might simply improve bot technology, as they provide recipes
to build better bots.
The de-facto bot detection tool in the social science community
is Botometer (formerly BotOrNot) [6], which uses more than 1000
user- and recent activity-related features to train a Random Forest
classifier. Botometer is currently at version 4, at the time of writing,
and serves half a million queries a day [21].
The main limitation of botometer for practitioners is its dependence on an online API. It cannot be used to profile the users in
offline Twitter datasets which have been collected in the past (like
used in many works [1, 8, 22]). Furthermore, the API is rate-limited
by Twitter, and requires registration through both Twitter and
RapidAPI service. For scientific purposes, botometer makes local
reproducibility difficult to achieve, since deactivated, protected, and
suspended users can no longer be retrieved, and botometer scores
are likely to vary with user activity and botometer versioning.
Birdspotter addresses the above-stated shortcomings by producing bot predictions on already collected Twitter dumps, and
exposing a simple interface to allows researchers to annotate their
own Twitter user collection.
Tools for quantifying online influence. There are many features used to score the influence, reputation or popularity of online
users. We delineate these into three areas: those using static user
attributes (including lexical features and information on a user’s
profile) [5], those that analyze the online social graph (e.g. degree,
PageRank, HITs, etc.) [2, 18], and those modeling information diffusion [25]. However, few of these have translated into accessible
tools for the non-experts in the field. For instance, Cossu et al. [5]
provide a set of scripts to perform their influence measurement
method. Other tools, like ConTinEst [7, 10], require knowledge of
the social graph (which is often prohibitively expensive to obtain)
on which it performs random walks (which are very slow on large
social graphs). Birdspotter estimates user influence from reshare
dynamics, in the absence of knowledge about the social graph, and
provides an end-to-end tool to analyze Twitter users.

B

INFLUENCE MEASURE

We review the theoretical prerequisites concerning modeling reshare cascades using point processes, and estimating reshare influence.
Reshare cascades. birdspotter analyzes the spread of online
information in the form of online reshare cascades. A reshare cascade consists of an initial user post and some reshare events of
the post by other users. On Twitter, for example, this can happen
when users use the retweet functionality. We denote a cascade
observed up to time 𝑇 as H (𝑇 ) = {𝑡 0, 𝑡 1, . . . } where 𝑡𝑖 ∈ H (𝑇 )
are the event times relative to the first event (𝑡 0 = 0). We denote cascades with additional information about events — dubbed
here as event marks — as marked cascades. We use the notation
H 𝑚 (𝑇 ) = {(𝑡 0, 𝑚 0 ), (𝑡 1, 𝑚 1 ), . . . }, where each event is a tuple of
the event time and the event mark. For example, for retweet cascades, the numbers of followers of a Twitter user are commonly
adopted as event marks [16, 17, 26].
The Hawkes processes. birdspotter models reshare cascades
using Hawkes processes [11] — a type of point processes with
the self-exciting property, i.e., the occurrence of past events increases the likelihood of future events. The occurrence of events in
a Hawkes process is controlled by the event intensity function:
∑︁
𝜆(𝑡 | H (𝑇 )) = 𝜇 (𝑡) +
𝜙 (𝑡 − 𝑡𝑖 )
(1)
𝑡𝑖 <𝑡

where 𝜇 (𝑡) is the background intensity function and 𝜙 : R+ → R+ is
a kernel function capturing the decaying influence from a historical
event. We note that, for reshare cascades, all events are considered
to be offspring of the initial event, i.e. there is no background event
rate 𝜇 (𝑡) = 0. Two widely adopted parametric forms for the kernel
function 𝜙 include the exponential function 𝜙 𝐸𝑋 𝑃 (𝑡) = 𝜅𝜃𝑒 −𝜃𝑡 and
the power-law function 𝜙 𝑃𝐿 (𝑡) = 𝜅 (𝑡 + 𝑐) −(1+𝜃 ) .
Marked Models. birdspotter implements marked versions of
the point processes, where the mark is the number of followers
that the user emitting the tweet has. This is because the mark of
each event governs the number of future events, e.g., a tweet from a
largely followed user is likely to attract more retweets. The marked
versions of Hawkes processes [16] are then derived by rescaling the
kernel functions with the marks, i.e., 𝜙 (𝑚, 𝑡) = 𝑚 𝛽 𝜙 (𝑡); 𝛽 controls
the warping effect of the mark.
User influence estimation. birdspotter adopts the following
definition for user influence, widely used in literature [7, 19, 24]:
Definition B.1. Online user influence 𝜑 (𝑢) is defined as the mean
number of reshares generated directly and indirectly by a message
posted by 𝑢, irrespective if it is an original message or a reshare.
Estimating influence from retweet cascades has the additional difficulty of not observing the branching structure of the diffusion
— i.e., the Twitter API attributes all retweets to the original tweet.
birdspotter estimates Twitter user influence using only the observed retweet cascade H 𝑚 (𝑇 ) = {𝑣 0 = (𝑡 0, 𝑚 0 ), 𝑣 1 = (𝑡 1, 𝑚 1 ), . . . },
where marks correspond to users’ number of followers.
Rizoiu et al. [19] propose a method to estimate user influence in
the absence of the branching structure by assuming that retweets
arrive following a Hawkes point process [20]. We can quantify the
probability that an event 𝑣 𝑗 is generated by a previous event 𝑣𝑖
as the ratio of the event intensity generated by 𝑣𝑖 and the total

intensity at time 𝑡 𝑗 . Formally, the probability 𝑣 𝑗 retweets 𝑣𝑖 is
𝜙 (𝑡 𝑗 − 𝑡𝑖 )
𝑝𝑖 𝑗 = Í 𝑗−1
𝜙 (𝑡 𝑗 − 𝑡𝑘 )
𝑘=1

(2)

Rizoiu et al. [19] also introduce the pairwise influence score 𝑚𝑖 𝑗 ,
intuitively defined as the amount of influence that 𝑣𝑖 exerts over
𝑣 𝑗 either directly (when 𝑣 𝑗 is a direct retweet of 𝑣𝑖 ) or indirectly
(when 𝑣 𝑗 is a retweet of a descendant of 𝑣𝑖 ):
Í 𝑗−1


𝑚 𝑝
,𝑖 ≤ 𝑘 < 𝑗

 𝑘=𝑖 𝑖𝑘 𝑘 𝑗

𝑚𝑖 𝑗 = 1
,
(3)
,𝑖 = 𝑗


0
,𝑖 > 𝑗

Í
Finally, the influence of 𝑣𝑖 is 𝜑 (𝑣𝑖 ) = 𝑛𝑘=𝑖 𝑚𝑖𝑘 , and the influence
of a user 𝑢 is the average of the influences of all of their tweets:
Í
𝑣 ∈ T (𝑢) 𝜑 (𝑣)
𝜑 (𝑢) =
(4)
|T (𝑢)|
where T (𝑢) is the set of all the tweets emitted by user 𝑢.

REFERENCES
[1] Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US
Presidential election online discussion. First Monday (2016).
[2] Meeyoung Cha, Hamed Haddadi, Fabricio Benevenuto, and Krishna P Gummadi.
2010. Measuring user influence in twitter: The million follower fallacy. In ICWSM.
[3] Zi Chu, Steven Gianvecchio, Aaron Koehl, Haining Wang, and Sushil Jajodia.
2013. Blog or block: Detecting blog bots through behavioral biometrics. Computer
Networks (2013).
[4] Eric M Clark, Jake Ryland Williams, Chris A Jones, Richard A Galbraith, Christopher M Danforth, and Peter Sheridan Dodds. 2016. Sifting robotic from organic
text: a natural language approach for detecting automation on Twitter. Journal
of Computational Science (2016).
[5] Jean-Valère Cossu, Vincent Labatut, and Nicolas Dugué. 2016. A review of features
for the discrimination of twitter users: Application to the prediction of offline
influence. SNAM (2016).
[6] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and
Filippo Menczer. 2016. Botornot: A system to evaluate social bots. In WWW.
[7] Nan Du, Le Song, Manuel Gomez-Rodriguez, and Hongyuan Zha. 2013. Scalable
Influence Estimation in Continuous-Time Diffusion Networks. In NeurIPS.
[8] Emilio Ferrara. 2020. # covid-19 on twitter: Bots, conspiracies, and social media
activism. arXiv (2020).
[9] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro
Flammini. 2016. The rise of social bots. Comm. ACM (2016).
[10] Manuel Gomez-Rodriguez, Le Song, Nan Du, Hongyuan Zha, and Bernhard
Schölkopf. 2016. Influence Estimation and Maximization in Continuous-Time
Diffusion Networks. ACM Transactions on Information Systems (2016).
[11] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point
processes. Biometrika (1971).
[12] Pik-Mai Hui, Kai-Cheng Yang, Christopher Torres-Lugo, Zachary Monroe, Marc
McCarty, Benjamin Serrette, Valentin Pentchev, and Filippo Menczer. 2019. BotSlayer: real-time detection of bot amplification on Twitter. Journal of Open Source
Software (2019).
[13] Jürgen Knauth. 2019. Language-Agnostic Twitter-Bot Detection. In RANLP 2019.
[14] Sneha Kudugunta and Emilio Ferrara. 2018. Deep neural networks for bot
detection. Information Sciences (2018).
[15] Michele Mazza, Stefano Cresci, Marco Avvenuti, Walter Quattrociocchi, and
Maurizio Tesconi. 2019. RTbust: exploiting temporal patterns for botnet detection
on twitter. In Proceedings of the 10th ACM Conference on Web Science.
[16] Swapnil Mishra, Marian-Andrei Rizoiu, and Lexing Xie. 2016. Feature Driven
and Point Process Approaches for Popularity Prediction. In CIKM.
[17] Swapnil Mishra, Marian-Andrei Rizoiu, and Lexing Xie. 2018. Modeling Popularity in Asynchronous Social Media Streams with Recurrent Neural Networks. In
ICWSM.
[18] Fabián Riquelme and Pablo González-Cantergiani. 2016. Measuring user influence
on Twitter: A survey. Information processing & management (2016).
[19] Marian-Andrei Rizoiu, Timothy Graham, Rui Zhang, Yifei Zhang, Robert Ackland,
and Lexing Xie. 2018. # DebateNight: The Role and Influence of Socialbots on
Twitter During the 1st 2016 US Presidential Debate. In ICWSM.
[20] Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie. 2017. A
Tutorial on Hawkes Processes for Events in Social Media. In Research Frontiers of
Multimedia.

[21] Mohsen Sayyadiharikandeh, Onur Varol, Kai-Cheng Yang, Alessandro Flammini,
and Filippo Menczer. 2020. Detection of Novel Social Bots by Ensembles of
Specialized Classifiers. CIKM (2020).
[22] Stefan Wojcik, Solomon Messing, Aaron Smith, Lee Rainie, and Paul Hitlin. 2018.
Bots in the Twittersphere. Pew Research Center. Retrieved May (2018).
[23] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai.
2014. Uncovering social network sybils in the wild. TKDD (2014).
[24] Ali Zarezade, Utkarsh Upadhyay, Hamid Rabiee, and Manuel Gomez Rodriguez.
2017. RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks.
In WSDM.
[25] Zizhu Zhang, Weiliang Zhao, Jian Yang, Cecile Paris, and Surya Nepal. 2019.
Learning Influence Probabilities and Modelling Influence Diffusion in Twitter. In
WWW.
[26] Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, Anand Rajaraman, and Jure
Leskovec. 2015. SEISMIC: A Self-Exciting Point Process Model for Predicting
Tweet Popularity. In KDD.

