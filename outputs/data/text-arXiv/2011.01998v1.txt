ADAPTIVE TEST ALLOCATION FOR OUTBREAK DETECTION
AND TRACKING IN SOCIAL CONTACT NETWORKS∗

arXiv:2011.01998v1 [cs.SI] 3 Nov 2020

PAU BATLLE† , JOAN BRUNA† , CARLOS FERNANDEZ-GRANDA† , AND VICTOR M.
PRECIADO‡
Abstract. We present a general framework for adaptive allocation of viral tests in social contact
networks. We pose and solve several complementary problems. First, we consider the design of
a social sensing system whose objective is the early detection of a novel epidemic outbreak. In
particular, we propose an algorithm to select a subset of individuals to be tested in order to detect
the onset of an epidemic outbreak as fast as possible. We pose this problem as a hitting time
probability maximization problem and use submodularity optimization techniques to derive explicit
quality guarantees for the proposed solution. Second, once an epidemic outbreak has been detected,
we consider the problem of adaptively distributing viral tests over time in order to maximize the
information gained about the current state of the epidemic. We formalize this problem in terms of
information entropy and mutual information and propose an adaptive allocation strategy with quality
guarantees. For these problems, we derive analytical solutions for any stochastic compartmental
epidemic model with Markovian dynamics, as well as efficient Monte-Carlo-based algorithms for nonMarkovian dynamics. Finally, we illustrate the performance of the proposed framework in numerical
experiments involving a model of Covid-19 applied to a real human contact network.
Key words. Epidemiology, Social networks, Markov chains, Submodular optimization, entropybased sampling
AMS subject classifications. 92D30, 91D30, 60J20, 90C35, 94A17

1. Introduction. In December 31st 2019, The Municipal Health Commission of
Wuhan (China) reported a cluster of cases of pneumonia caused by a novel coronavirus
[3]. This new virus rapidly propagated worldwide through the air transportation
network and many countries decided to implement severe mobility restrictions and
social distancing policies to “flatten the curve” of the pandemic. However, as society
reopens, mobility increases, and social distancing relaxes, new epidemic outbreaks
become a very real threat. In this situation, it is of upmost societal importance to
develop efficient strategies for early detection and tracking of epidemic outbreaks.
In this paper, we study the problem of allocating viral tests [2] in order to (i )
detect a novel epidemic outbreak as early as possible, as well as (ii ) to retrieve as
much information as possible about the evolution of the epidemic. In our work, we
consider a social contact network over which a disease is spreading according to a
stochastic compartmental model [21]. The main questions explored in this article are:
1. Early detection of epidemic outbreaks with limited viral tests: In particular,
what nodes should we test in a contact social graph to maximize the probability of
early detection? We will pose this problem in terms of hitting times of an stochastic
process associated to the social graph and propose an algorithm to solve it with quality
guarantees based on submodular optimization.
2. Estimation of past and current state of the disease: Given the results of a
∗ Funding: Pau Batlle was partially supported by Capital One Inc. and the Cellex Foundation.
Joan Bruna acknowledges partial support by Alfred P. Sloan Foundation, NSF RI-1816753 and NSF
CAREER CIF 1845360. Carlos Fernandez-Granda was partially supported by NSF DMS 2009752.
Victor M. Preciado was partially supported by NSF-CAREER-ECCS-1651433, NSF-III-200884556,
and the Rockefeller Foundation.
† Courant Institute of Mathematical Sciences, Center for Data Science, New York University, NY.
‡ Department of Electrical and Systems Engineering, Applied Mathematics and Computational
Science, University of Pennsylvania, PA

1

2

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

collection of viral tests, what are the probabilities of infection for each individual in
the social network? Furthermore, we analyze the past evolution of the epidemic to
estimate where and when the infection is most likely to have started.
3. Adaptive test allocation for epidemic tracking: Once an epidemic outbreak
has been detected, how should we dynamically allocate viral tests to gain as much
information as possible about the current state of the epidemic?
General work on stochastic compartmental models in networks include [17], [20],
[14]. Additionally, [21] and [7] provide a general survey of problems involving spreading processes in networks. In [18], van Mieghen et al. study the spread of malware
in computer networks using Markov chains; however, their focus is on mean-field approximations derived from continuous-time Markov chains, while our work focuses on
the exact stochastic model of the epidemic process. In [16], Leskovec et al. propose
a sensor placement framework, similar to the test placement in our work, to detect
outbreaks of water contaminants and other spreads; however, the authors use a deterministic propagation model over a directed network, instead of a stochastic epidemic
model. In [23], Shah et al. study the culprit detection problem for the popular SI
epidemic model on a network using the so-called rumor centrality. In [24], Spinelli et
al. also study the culprit detection problem for a specific family of spreading models
without any concerns about early detection. In [27], Yan et al. consider the independent cascade model and study the problem of immunizing edges in order to minimize
the expected number of infected nodes at the conclusion of the spreading process. As
far as testing is concerned, there is literature that gives results on different network
monitoring techniques [8] [11] [22] [25] [12]; however, these works do not aim to find an
optimal solution according to any metric, but analyze the performance of particular
heuristics. Finally, the works in [6], [9] and [15] analyze several heuristics for epidemic
detection based on different network centrality measures.
The article is organized as follows. In section 2, we formalize our theoretical setup
and discuss the models to which this framework is applicable. The three questions
described above are explored in section 3, section 4 and section 5, respectively. Finally,
section 6 presents experiments in a real dataset of human interactions where we apply
our framework using a realistic model of the spread of Covid-19 [10].
2. Notation and preliminaries. For a given n ∈ N, we let [n] be the set
{1, . . . , n}. We consider a given network G = (V, E) where V = [n], and a continuoustime stochastic compartmental epidemic process, denoted by {X(t)}t≥0 , running over
G. At every t ∈ R+ , each of the n nodes in the network is in one out of s possible
states, where each state represents a compartment in the epidemic model. Since we
have n nodes, the networked stochastic process {X(t)}t≥0 has a finite state space
S with |S| = sn . One of the simplest networked compartmental models is the SIR
model [4], which presents three compartments: Susceptible, Infectious, and Removed.
In this model, infectious nodes may infect healthy neighbors with probability rate β
and may transition into the removed compartment (i.e., no longer infectious) with
probability rate γ.
In the rest of the paper, we assume that the initial state X(0) of the epidemic
process is randomly chosen from a known probability distribution D supported in S,
and that all subsequent probabilities are conditioned on the realization of X(0). If
the epidemic process {X(t)}t≥0 is Markovian, we can derive analytical solutions to
the problems under consideration (shown in Appendix A). However, these analytical
solutions are usable in practice only for relatively small graphs. In the following
sections, we will provide computational tools to analyze non-Markovian epidemic

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

3

processes running over large graphs. In this more general case, instead of using
untractable analytical solutions, we will provide efficient numerical algorithms to solve
different problems of interest.
3. Early detection of epidemic outbreaks with limited viral tests. The
first key question we address is how to optimally monitor a contact network for early
detection of a new outbreak with limited resources. We assume that we are able to
continuously monitor the health of k nodes of the network before the onset of an
outbreak. We aim to answer two optimization questions:
Q1A (Test placement with monitoring constraint): For a given k ∈ N and
τ > 0, which k nodes should we continuously monitor to detect a novel outbreak before
a certain time τ (counting from the onset of the outbreak) with the highest possible
probability?
Q1B (Test placement with probability constraint): Given a threshold time
τ > 0 and a probability P , what is the minimum number k of nodes we need to monitor
to detect the epidemic outbreak before time τ with a probability P ? Where should we
place them?
To analyze these questions, we assume that those nodes being monitored are
frequently tested. We assume that the available tests provide partial information
about the state of the node. In particular, we consider a partition of the set of s
possible states into two non-empty subsets, G+ and G− , and assume that the test
is able to determine in what subset the state of the monitored node is. In practice,
the set G+ (resp., G− ) represent node states that would result in a positive (resp.,
negative) viral test result. We say that the a node is detectable if its state is in G+ , and
that the epidemic is detected when one of the monitored nodes becomes detectable
for the first time.
In order to track the time it takes for the epidemic to be detected, we use the
concept of stopping time of a stochastic process. Given a network stochastic process
{X(t)}t≥0 and a subset A ⊂ S, its stopping time TA is defined as the random variable
min{t ≥ 0 : X(t) ∈ A}, where X(t) ∈ S is the state of the stochastic process at time
t. If the process never reaches A, we set TA = ∞. Given a subset of nodes W ⊂ V ,
we additionally define the detection set of W , denoted by DW , as the subset of S
consisting of those network states in which at least one of the nodes in W is in a
detectable state (i.e., one of the nodes in W test positive). This means that if we
monitor the nodes in W , the epidemic outbreak is detected when the network process
{X(t)}t≥0 reaches one of the states in DW ; however, the exact network state will still
be unknown.
Now, Question Q1A can be formalized as follows: Given a time horizon τ > 0,
we want to monitor k nodes of the network in order to maximize the probability that
the process reaches the detection set DW before time t = τ (counting from the onset
of the epidemic outbreak). Hence, the optimal set of nodes to be monitored can be
found as the solution of the following optimization problem:
(Q1A)

argmax P (TDW ≤ τ ) .
W ⊂V,|W |=k

Similarly, the answer to Question Q1B is the solution to the following optimization:
(Q1B)

argmin
W ⊂V s.t P(TDW ≤τ )≥P

|W |,

4

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

i.e, the smallest set of nodes that we need to monitor such that the probability of
detecting the epidemic outbreak before time t = τ is greater than P . We conveniently define the optimization objective function over subsets of nodes for a given
τ as fτ : W 7→ P (TDW ≤ τ ), so that equations (Q1A) and (Q1B) can be written,
respectively, as
(3.1)

argmax fτ (W )
W ⊂V,|W |=k

and

argmin

|W | .

W ⊂V,fτ (W )≥P

Notice that these are combinatorial optimization problems and finding the optimal
solutions is exponentially hard. In the rest of the paper, we focus on finding approximate solutions with quality guarantees. In this direction, there are two separate
subproblems we need to address: First of all, the function fτ can only be computed
for Markovian epidemic processes taking place in small networks (see Appendix B);
hence, we need to approximate this objective function for non-Markovian processes
over large networks. Secondly, we also need an optimization scheme to find an approximated solution with qualities guarantees (without evaluating fτ an exponential
number of times).
3.1. Function evaluation. The function fτ can be approximated using Monte
Carlo samples, as described below. First, we simulate the stochastic epidemic process
NR times, where each simulation will be stopped when one of two things happen:
Either we reach an absorbing state, or all the nodes have already reached a detectable
state at least once. Then, fτ can be approximated as follows: Let L be a NR × n
matrix such that, for every run of the process r ∈ [NR ]
(3.2)

L[r, j] = min{T ∈ R+ : Xj (T ) ∈ G+ in run r} ,

where Xj (t) is the state of node j at time t and L[r, j] = ∞ if node j is never detectable
in run r. Given the matrix L and any time τ , an estimator for fτ , denoted by fˆτ , can
be calculated as follows: fˆτ (W ) = N1R |{r ∈ [NR ] : mini∈W L[r, i] ≤ τ }|. As NR → ∞,
we have that fˆτ → fτ uniformly, because of the law of large numbers.
3.2. Optimization of fτ via submodularity. The combinatorial structure of
the problem requires not only a way to rapidly evaluate the objective function but
an optimization scheme that avoids evaluating an exponential number of possible
node monitorizations. In order to do that, we prove and exploit the submodularity
properties of fτ combined with fundamental results about submodular optimization.
If Ω is a finite set, a function h : P(Ω) → R is called submodular if it satisfies
one of these three equivalent conditions: (Condition 1) ∀X, Y ⊆ Ω with X ⊆ Y and
every x ∈ Ω \ Y , we have that h(X ∪ {x}) − h(X) ≥ h(Y ∪ {x}) − h(Y );
(Condition 2) ∀S, T ⊆ Ω we have that h(S) + h(T ) ≥ h(S ∪ T ) + h(S ∩ T );
(Condition 3) ∀X ⊆ Ω and x1 , x2 ∈ Ω\X such that x1 6= x2 , h(X ∪ {x1 }) + h(X ∪
{x2 }) ≥ h(X ∪{x1 , x2 })+h(X). We aim to prove that fτ is a non-negative, monotone
(i.e., fτ (X) ≤ fτ (Y ) for X ⊂ Y ) and submodular function. The non-negativity is
trivial from the definition of probability, and monotonicity comes from the fact that
for A ⊂ B, DA ⊂ DB , and so the event TDA ≤ τ implies that TDB ≤ τ , hence,
fτ (A) ≤ fτ (B). Furthermore, fτ is submodular (as proved in Appendix B).
Theorem 3.1. The set-function fτ : W 7→ P (TDW ≤ τ ) is submodular.
We can now invoke two well-known results in submodular optimization theory to
derive quality guarantees of greedy-like optimization schemes aiming to solve Problems

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

5

(Q1A) and (Q1B), using Algorithm 3.1 and Algorithm 3.2, described below. Both
algorithms run in polynomial time and only require O(n2 ) evaluations of the objective
function.
Theorem 3.2 ([19]). If a set-function f is monotone, submodular and nonnegative, the greedy scheme in Algorithm 3.1 applied to Problem (Q1A) returns a
solution S 0 for which f (S 0 ) ≥ (1 − 1e )f (S ∗ ) where S ∗ is the optimal set.
Algorithm 3.1 Greedy scheme applicable to (Q1A) when f = fτ
Input: k ∈ N, f function over subsets of V
Output: S ⊂ V with |S| = k, an approximate solution to (Q1A)
S ← ∅, i ← 0
while i ≤ k do
S ← S ∪ argmax f (S ∪ {v})
v∈V \S

i←i+1
return S
Theorem 3.3 ([26]).

If f is monotone and submodular, the greedy scheme in
|S 0 |
Algorithm 3.2 applied to Problem (Q1B) returns a solution S 0 for which
≤
|S ∗ |
f (V ) − f (∅)
, where S ∗ is the optimal set and S−1 is the solution set at the
1 + log
f (S 0 ) − f (S−1 )
iteration prior to the termination of Algorithm 3.2.
Algorithm 3.2 Greedy scheme applicable to (Q1B) when f = fτ
Input: P ∈ [0, 1], f set-function over subsets of V
Output: S ⊂ V with f (S) ≥ P , an approximate solution to (Q1B)
S←∅
while f (S) < P do
S ← S ∪ argmax f (S ∪ {v})
v∈V \S

return S
Note that in the case of non-Markovian epidemic models and/or large networks, we
cannot directly evaluate fτ , but an approximation fˆτ . A natural question is whether
fˆτ has similar properties as fτ , so that we can guarantee quality of the optimization.
Theorem 3.4. The approximation function fˆτ , defined in subsection 3.1, is nonnegative, monotone and submodular for all NR ∈ N
Using this result (proved in Appendix B), we conclude that the quality guarantees in
Theorem 3.2 and Theorem 3.3 are also applicable to the approximation function fˆτ .
3.3. Toy example in a small network. We illustrate our procedures using the
graph in Figure 1. We use a SIR model with β = 0.5, δ = 0.25, and a single initially
infected node chosen uniformly at random. Setting τ = 0.5, the set of k = 2 nodes to
be monitored such that fτ is maximized is {1, 5} (circled in black in the figure) with a
value of fτ ({1, 5}) = 0.442; in other words, monitoring these two nodes, we are able to
detect the epidemic outbreak before 0.5 time units with a probability equal to 0.442.
This solution is obtained via an exhaustive combinatorial search. If, in contrast, we

6

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

use the greedy-scheme in Algorithm 3.1, we obtain {3, 0} as our approximate solution
and fτ ({3, 0}) = 0.438. Theorem 3.4 ensures that the greedy solution (i.e., 0.438) is
not worse than (1 − 1/e) × 0.442 = 0.279 (notice that the greedy solution is much
better than that worst case value).

Fig. 1. Toy example used in subsection 3.3, with n = 7 nodes. For τ = 0.5, nodes 1 and 5 are
the optimal set, but a greedy approach selects nodes 3 and 0.

4. Estimation of past and current state of the disease. Once an epidemic
outbreak has been detected, it is of practical interest to use the results of the tests
used during the monitoring phase to estimate the network state of the disease. In
this section, estimate the global state of the network using the information obtained
from the viral test results retrieved from a subset of nodes. In this direction, given
test results for a subset of nodes, we formulate two different subquestions:
Q2A (Patient zero detection): What is the probability of each node being
patient zero?
Q2B (Outbreak time estimation): How much time has passed since the outbreak started?
Q2C (Current network status assessment): What is the probability of each
individual node being infected?
Assuming that nodes v1 , . . . , vk ∈ V are our k monitoring nodes, we define the
k dimensional vector O such that Oi = 1 when vi have tested positive during the
monitoring phase and Oi = 0 otherwise. Hence, assuming that xi ∈ S is the network
state in which only node i is infected, Q2A asks us to estimate
(Q2A)

P(X(0) = xi |O) ∝ P(O|X(0) = xi )P(X(0) = xi ), ∀i

while Q2B asks us about the distribution of the time t since the beginning of the
epidemic outbreak conditioned to our observation O, i.e., P(t ≤ u|O) for u ∈ R+ .
In subproblem Q2C, we aim to estimate P(X = x|O), where X is the state of
the stochastic process at the present time. However, since the number of possible
network states grows exponentially with the number of nodes, it is computationally
untractable to solve Q2C. Alternatively, we will aim to estimate the n × s marginal
probabilities {P(Si = sj |O)}i=1:n,j=1:s , where Si ∈ [s] is the current state of node i
and sj is one of the possible s states or compartments.
To estimate solutions to questions Q2A, Q2B and Q2C, we are using the Monte
Carlo estimator for conditioned probability, as described in the previous section. Here,

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

7

Obsr ∈ {0, 1}k refers to the observation vector O at detection time tr obtained in the rth run of the Monte Carlo iteration with initial state X r (0). Hence, the approximate
solution for Q2A (Patient zero detection) is the following distribution over initial
states:

(4.1)

P̂(X(0) = xi |O) =

|{r ∈ [NR ] : X r (0) = xi ∩ Obsr = O}|
.
|{r ∈ [NR ] : Obsr = O}|

For Q2B (outbreak time estimation), our empirical distribution of times depends
on how long it took to detect the outbreak in those runs producing an observation
Obsr = O, as stated in the following equation:

(4.2)

P̂(t ≤ k|O) =

|{r ∈ [NR ] : tr ≤ k ∩ Obsr = O}|
.
|{r ∈ [NR ] : Obsr = O}|

Defining Sir as the status of node i at the time of detection of run r, we have the
following approximation for Q2C (current status assessment):

(4.3)

P̂(Si = sj |O) =

{|r ∈ [NR ] : Sir = sj ∩ Obsr = O|}
.
|{r ∈ [NR ] : Obsr = O}|

4.1. Toy example in a small network. Consider an SIR epidemic model on
the network in Figure 1 using same settings as in subsection 3.3. Let us assume that we
are continuously monitoring nodes 1 and 5. Suppose that the first time a test detects
the epidemic, node 5 is infectious. Using our results, we can calculate the posterior
distribution of patient-zero probabilities and the time-since-outbreak t, which are
plotted in Figure 2 and Figure 3, respectively. The probability of t = 0 (detection
immediately after outbreak) is 0.416, in agreement with the posterior distribution of
patient zero in Figure 2. The expected value of the distribution is 0.760. Finally, in
Figure 4 the estimated marginal distributions for each node and state can be observed.

Fig. 2. Posterior distribution of patientzero probabilities for example in subsection 4.1.

Fig. 3. Posterior distribution of timesince-outbreak for the example in subsection 4.1.

8

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

Fig. 4. Marginal distributions of the current state of the network after detection, given the
observation of node 5 as the first infectious between nodes 1 and 5

5. Dynamic allocation for epidemic tracking. In a practical scenario, once
an epidemic is detected, we may be interested in retrieving as much information as
possible about the state of the epidemics. In this section, we address this problem by
sequentially testing nodes over time, where we have the freedom to choose the location
of new tests. Let t0 be the time at which an epidemic outbreak is first detected and
consider that, afterwards, we are able to perform a number of new tests at times
t1 < t2 < . . . < tn . Question Q3, stated below, is concerned with the design of a
testing strategy aiming to maximize the amount of information extracted about the
state of the disease using this series of tests.
Q3 (Optimal dynamic test allocation after detection): Assuming that we
are free to sequentially allocate a number of tests at different times {ti }ni=0 , which
nodes should we test at each time to maximize the ‘information’ about the state of the
disease? We assume that the tests have a known specificity Sp and sensitivity Sn .
To formalize this question, we use the classical concepts of entropy and mutual
information. At the time
P of (first) detection, our distribution of states X has an
entropy of H(X|O) = − x∈S P(X = x|O) log P(X = x|O), where O is the observations at detection time. As described above, we aim to minimize the entropy of X by
performing a series of tests to a fixed number of nodes. Assume we test the subset
of nodes W 0 . We denote by TW 0 the outcome of these |W 0 | tests, taking values in
0
{0, 1}|W | . Thus, the average entropy of X after testing W 0 is:
X
H(X|O,TW 0 ) =
P(TW 0 = i)H(X|O, TW 0 = i)
i∈{0,1}|W 0 |

(5.1)

=−

X
i∈{0,1}|W 0 |

P(TW 0 = i)

X

P(X = x|O, TW 0 = i) log P(X = x|O, TW 0 = i).

x∈S

The problem we aim to solve is the maximization of the mutual information
(5.2)

argmax I(X|O; TW 0 ) = argmax H(X|O) − H(X|O, TW 0 ) .
W 0 ⊂V

W 0 ⊂V

As mentioned before, computing the full distribution P(X = x|O) is unfeasible due to
the exponential size of the probability space;hence, we propose below an approximation to this problem using the information we have from solving previous questions.

9

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

Assume that we have access to an estimation of the marginals {P(Si = sj |O)}i,j .
n
Since we have no more information about the distributions, we can
Qn assume {Si }i=1
are independent to obtain P(S1 = s1 , S2 = s2 , . . . , Sn = sn |O) = i=1 P(Si = si |O) .
Making the (approximate) assumption that the testing process does not destroy this
independence, we obtain
(5.3)
H(X|O, TW 0 ) = H((S1 , S2 , . . . , Sn )|O, TW 0 ) =

X

H(Si |O, TW 0 ) +

i∈W 0

X

H(Si |O) ,

i6∈W 0

where the last equality comes from the fact that a test on W 0 does not change our
knowledge of other nodes under the independence assumption. Hence,
(5.4) H(X|O) − H(X|O, TW 0 ) =

n
X

H(Si |O) −

i=1

(5.5)

=

X

X

H(Si |O, TW 0 ) −

i∈W 0

X

H(Si |O)

i6∈W 0

(H(Si |O) − H(Si |O, T{i} )) .

i∈W 0

This means that we can effectively rank the nodes, with a score equal to H(Si |O) −
H(Si |O, T{i} ) ≥ 0, and include in W 0 the desired number of nodes of the highest score.
This score can be computed with our estimated marginals from Q2C, as follows. On
the one hand, by the definition of entropy, we have that
(5.6)

H(Si |O) = −

s
X

P(Si = sj |O) log P(Si = sj |O) .

j=1

On the other hand, H(Si |O, T{i} ) depends on the capacity of the tests to distinguish
states (determined by their sensitivity and specificity). In particular, we consider
(binary) tests with known specificity Sp and sensitivity Sn . We denote by +, − the
positive and negative results in one such test, and Si ∈ D the event that node i is
a detectable state. Under these assumptions, the expected entropy after the test is
given by:
(5.7) H(Si |O, T{i} ) = P(Ti = +)H(Si |O, T{i} = +) + P(Ti = −)H(Si |O, T{i} = −)
We can calculate each one of the terms in this expression as follows: P(Ti = +) =
Sn P(Si ∈ D) + (1 − Sp )(1 − P(Si ∈ D)) and P(Ti = −) = (1 − Sn )P(Si ∈ D) + Sp (1 −
P(Si ∈ D)) = 1 − P(Ti = +). Also, H(Si |O, T{i} = +) and H(Si |O, T{i} = −) are the
entropies of Bernoulli variables with parameters P(Si ∈ D|Ti = +) and P(Si ∈ D|Ti =
P(Si ∈D)
n )P(Si ∈D)
and P(Si ∈ D|Ti = −) = (1−S
−). Finally, P(Si ∈ D|Ti = +) = SnP(T
P(Ti =−)
i =+)
from a direct application of Bayes’ Formula.
The computation of H(Si |O) − H(Si |O, T{i} ) reveals that, if the test deviates
from the ideal test with Sp = Sn = 1, then the optimal distribution to test deviates
from the uniform P(+) = P(−) = 0.5. The optimal P(+) solves a transcendental
equation as a function of Sp and Sn . As an example, if Sn = 0.957 and Sp = 0.99
(as obtained from real data in the Autobio Diagnostics Co. RDT IgM Covid-19
tests [1]), the probability of testing positive before the test resulting in a maximal
mutual information is P(+) = 0.4836. Using this procedure we can rank the nodes
and choose the top ki scores to allocate ki tests at the time instance ti . The full

10

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

procedure alternates between testing and simulations to update the current status of
the network and dynamically decide on subsequent tests. After tests at time ti are
taken, we define Di as the distribution over nodes conditioned on the test results. If
the process is Markov, the conditions needed to start the model are just the status
of all nodes. For non-markovian processes, other elements, such as how much time
a node has been in its status, need to be considered. We include these under Di ,
understanding that we sample all the values needed to uniquely determine the system
current status and evolution. We use the Monte Carlo simulator with initial states
sampled from Di until t = ti+1 − ti . After we have enough runs, one can estimate
the marginal distributions using (4.3), then use (5.5), (5.6), and (5.7) to decide where
the new ki+1 tests are allocated, and then calculate Di+1 using the results from the
test. This procedure is conceptually similar to particle filtering or sequential Monte
Carlo methods, in which measurements of reality are combined sequentially with a
simulator of the associated dynamics.
5.1. Toy example in a small network. Figure 5 shows the process of adaptive
testing in the case of the toy example in Figure 1. We start with the marginals in
Figure 4, which are used to calculate their entropies and decide the optimal nodes to
test next. After the test is taken, one uses the information to update the marginals
and use them to sample the initial condition for subsequent Monte Carlo runs, in
which we simulate the stochastic process until the time in which we are allowed to
allocate more tests (e.g., every week). After that, we can update the marginals, decide
on next tests to take, and repeat the cycle.

Fig. 5. Dynamic testing process, consisting on alternating testing and simulation, applied to
the toy example network

6. Experiments. In this section we illustrate the proposed procedures to a nonmarkovian model of Covid-19 in a real human interaction network. In order to simulate the stochastic processes, we use an event-driven simulation algorithm in which the
next events (infections, recoveries, etc.) are stored in a priority queue and processed
in order of time [14]. This method can be used to efficiently simulate many stochastic
models such as the model studied here. We use the Hypertext 2009 network [5], a
network of human-to-human interactions, in our simulations. The ACM Conference
on Hypertext and Hypermedia 2009 was held in Turin, Italy in 2009 and, during the
conference, the conference badges included Radio-Frequency Identification (RFI) devices able to mine face-to-face proximity relations [13]. The exchange of radio packets
between badges implies a proximity of less than 1-1.5 m, a distance in which contagious diseases could spread. In this network, a node represents a conference visitor

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

11

and an edge represents a face-to-face contact that was active for at least 20 seconds.
The network has n = 100 nodes and m = 946 edges once we aggregate edges over
time during the first day of the conference.
For this network, we use an adaptation to networks of a realistic non-markovian
model of Covid-19 proposed in [10]. In this work, the authors infer that, for Covid-19,
the incubation period (time between contracting the disease and showing symptoms)
follows a lognormal distribution with meanlog 1.644 and sdlog 0.363, and the generation time (time between infection of the source and infection of the tarauthor follows
a Weibull distribution with shape parameter 2.826 and scale parameter 5.665. Additionally, the authors infers that the proportion of infectious individuals who are
asymptomatic is 0.4, and that asymptomatic transmission rate is 10 times lower than
for symptomatic patients. We use this data to create a non-markovian model with susceptible, presymptomatic, symptomatic, asymptomatic, and removed compartments
in which each node can independently infect its neighbours as long as it is not susceptible nor removed. The times for that infection to occur and symptoms to appear is
sampled from the distributions in [10]. We draw the random time to full recovery from
first infection to removal from a normal distribution of mean 14 and standard deviation 2, both for symptomatic and asymptomatic carriers. The model is summarized
in Figure 6.

Fig. 6. Summary of the non-markovian model of Covid-19 spreading in networks based in [10]

We assume that the outbreak is started by a single infectious node chosen uniformly at random. We then monitor k = 10 nodes decided according to the greedy
scheme in Algorithm 3.1, which aims to maximize the probability of detection during
the first τ = 3 days of the outbreak. We test the greedy algorithm against three
simple baselines: uniformly random node subset selection, random node subset selection weighted by node degree, and random node selection eliminating neighbors
from chosen nodes iteratively. Figure 7 summarizes the results, where the greedy
algorithm outperforms all the strategies by around 3% in probability. In order to understand how this translates to real scenarios in practice, we run 105 simulations for
the greedy test placement and 105 for the best randomly found placement in which we
set lockdown measures as soon as the epidemic is detected in each case. The curves
of infectious (asymptomatic + symptomatic + presymptomatic) and recovered nodes
for each case can be seen in Figure 8. On average, 4 nodes out of the 100 nodes do
not contract the disease by using the greedy placement instead of the best random
placement.

12

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

Fig. 7. Histogram of results after using
the three baseline random placement strategies in comparison to the greedy algorithm in
order to place k = 10 tests. The greedy algorithm scores a detection probability of 0.57
while the best random solution scores 0.542

Fig. 8. Infectious (asymptomatic +
symptomatic + presymptomatic) and recovered mean curves for 105 runs in which lockdown is imposed once detecting the epidemic.
The small probabililty gain of using the set of
sensors found with the greedy strategy translates to 4 less nodes being infectious on average

A similar analysis as the one performed in the toy example in subsection 4.1
can be performed to estimate patient zero and results can be seen in Figure 9. The
most likely node is in this case the node in which the epidemic was detected, which is
placed in the middle of the graph in Figure 9. Similarly as before, we can estimate the
probability density function of time-since-outbreak at the time of detection. Here, we
do it for three different kinds of tests: tests that detect antibodies (meaning all kind
of non-susceptible nodes), ‘tests’ that detect symptoms only, and ‘tests’ that detect
removed people only. These two last cases correspond to the cases in which epidemic
outbreaks are detected late instead of using actual viral tests, simulating scenarios in
which countries or populations are unprepared for an outbreak and can only detect it
after the first death (or person with symptoms) is detected. The results can be seen
in Figure 10, in which we can observe that the difference is of the order of several
days in each case.

Fig. 9. Probability distribution of being
patient zero, after detection in node 53 (in
the center of the graph) is taken into account.
Node size is proportional to probability

Fig. 10. Probability density functions of
times between disease outbreak and detection
for optimal monitorization of k = 10 nodes
using tests of different type, corresponding to
being able to test people, detecting just the
symptoms or just the death of patients

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

13

Finally, we illustrate the proposed adaptive testing algorithm with a fixed amount
of tests at t = t0 and every 3 days, up to 4 times. We compare it with a baseline
algorithm of randomly selecting which nodes to choose at each iteration. In this comparison, testing is only used to monitor the epidemic (i.e no lockdown measures are
imposed regardless of test results). In Figure 11, the classification accuracy compared
to the real run (taking the most likely class in the estimated marginals as the prediction) and mean entropy of the predicted marginal distributions are plotted over
time, averaging over 104 different real runs. As expected, more tests translates to
higher accuracy and distributions with less entropy. By comparing testing strategies,
it can be observed how the proposed strategy maintains the classification accuracy
but improves on the uncertainty that the distributions convey. The time of higher
uncertainty is around 6 days after detection, as there are more possible scenarios of
the current state of the pandemic than later on. The reason for this is that, in this
non-lockdown scenario, after a certain point most of the nodes will most likely have
been infected.

Fig. 11. Accuracy and mean entropy time evolution in the dynamic testing scenario in which
a fixed number of tests are used every 3 days, up to 12 days after the outbreak is detected. Averages
of 104 runs

7. Conclusions. We have introduced a flexible framework to analyze problems
concerning the early detection of epidemic outbreaks, as well as the dynamic allocation of tests to maximize the information retrieved about the state of the infection.
The proposed framework is able to handle any discrete-time compartmental stochastic
process and tests with a given specificity and sensitivity. We have stated and solved
several problems of practical interest by analyzing continuous-time stochastic compartmental models over complex networks. First, we have considered the problem of
designing a monitoring system whose objective is to detect a novel epidemic outbreak
as soon as possible. In particular, we have developed an algorithm able to select a
subset of individuals to be continuously monitored in order to detect the onset of
an epidemic as fast as possible. We have mathematically described this problem as a
hitting-time probability maximization and use submodularity optimization techniques
to derive explicit quality guarantees for the proposed solution. Second, assuming that
an epidemic outbreak has been detected, we have also considered the problem of dynamically allocating viral tests over time in order to maximize the amount of informa-

14

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

tion gained about the state of the epidemic. We have proposed an adaptive allocation
strategy with quality guarantees based on the concepts of information entropy and
mutual information. For all these problems, we have derived analytical solutions for
Markovian stochastic compartmental models, as well as efficient Monte-Carlo-based
algorithms for non-Markovian dynamics and large-scale networks. We have illustrated
the performance of the proposed algorithms using numerical experiments involving a
model of Covid-19 applied to a real human contact network.
Appendix A. Analytical solution for Markov chains. In this section we
provide analytical solutions for the questions from section 1 in the case the Markov
Property holds and the epidemic model defines a continuous-time Markov chain. Similarly as in the general case, the epidemic model can be formulated as a continuous time
Markov chain of state space S with |S| = sn if the Markov property holds. An initial
probability distribution D such that X(0) ∼ D is also assumed. The continuous-time
Markov chain is characterized by a transition rate matrix Q of dimensions sn × sn .
A.1. Early detection of epidemic outbreaks with limited viral tests.
We use the same notation as in the general case: TDW is the minimum time in which
the Markov chain reaches the detection set of W ⊂ V . We can analytically calculate
P (TDW ≤ τ ) = P (TDW ≤ τ | TDW < ∞)P (TDW < ∞), where P (TDW < ∞) refers to
the probability of the Markov Process ending in an absorbing state in DW . Some
models, such as SIR, have absorbing states which represent the epidemic ”dying” before any detection is done (for example, the first person gets cured before transmitting
it to anyone), which might therefore not be part of DW . To treat that, we use the
jump matrix of the Markov chain. If Q is the transition rate matrix of a continuoustime and discrete space-Markov chain and we are at state i, the probability of the
Q
next jump of the Markov chain being to state j 6= i is −Qijii . This lets us define
P
Qij
the jump matrix M , where Mij =
if i 6= j and Mii = 1 − i6=j Mij , which
−Qii
corresponds to the matrix of a discrete time Markov chain describing the jumps the
Markov chain makes without taking into account how long it takes to do such jumps.
For calculations such as the probability of being absorbed in a particular state, we
can use the jump matrix and theory from discrete-time absorbing Markov chains. In
particular, we can calculate P (TDW < ∞) from the fundamental matrix of the jump
matrix created from Q.
Conditional absorption Markov chain theory. To calculate P (TDW ≤ τ | TDW <
∞) we need to eliminate the absorbing states not in DW from the chain, which we
denote S − . The dynamics of those runs that do not end in S − are Markovian, and
its rate transition matrix can be found according to the following proposition.
Proposition 1. Given a Markov chain with two sets of absorbing states S + and
S and a rate transition matrix Q, one can construct a matrix Q+ corresponding to
the Markovian dynamics of those processes that get absorbed at S + (which we can
write as X∞ ∈ S + ) as follows:

+
Q P (X∞ ∈ S |X(0) = j)
P (X∞ ∈ S + |X(0) = i) 6= 0
ij
+
P (X∞ ∈ S + |X(0) = i)
(A.1)
Qij =

0
P (X∞ ∈ S + |X(0) = i) = 0
−

Furthermore, the initial probability distribution {P(X(0) = i)}i also gets modified:
(A.2)

P(X∞ ∈ S + |X(0) = i)P(X(0) = i)
P(X(0) = i|X∞ ∈ S + ) = P
+
j P(X∞ ∈ S |X(0) = j)P(X(0) = j)

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

15

Proof. The initial distribution modification is a direct application of Bayes’ Theorem. For a state i such that P(X∞ ∈ S + |X(0) = i) = 0, then P(X(0) = i|X∞ ∈
S + ) = 0, and P(X(t) = i|X∞ ∈ S + ) = 0 must also hold for all t > 0. This means
that all Qki for k 6= i = 0, and therefore state i will not be reached at all in the new
dynamics. We can therefore safely remove such states from the chain, or assign its
transitions rate a value of 0 so that they act as absorbing non-achievable states. For a
state i such that P(X∞ ∈ S + |X(0) = i) > 0, remembering that the matrix Q satisfies
Qij = lim

h→0

P(X(h) = j|X(0) = i) − δij
h

we can derive that
P(X(h) = j|X(0) = i, X∞ = S + ) − δij
Q+
ij = lim
h→0
h
P(X(h) = j|X(0) = i)P(X∞ = S + |X(h) = j, X(0) = i)
− δij
P(X∞ = S + |X(0) = i)
= lim
h→0
h
P(X(h) = j|X(0) = i)P(X∞ = S + |X(0) = j)
− δij
P(X∞ = S + |X(0) = i)
= lim
h→0
h
P(X∞ = S + |X(0) = j)
P(X(h) = j|X(0) = i) − δij
=
lim
P(X∞ = S + |X(0) = i) h→0
h
+
P(X∞ = S |X(0) = j)
Qij
=
P(X∞ = S + |X(0) = i)
+

P(X∞ =S |X(0)=i)
where we used δij P(X
= δij
+
∞ =S |X(0)=j)

In practice, the quantities {P (X∞ ∈ S + |X0 = i)}i can be found from the fundamental matrix of the jump matrix
Once we have a Markov chain with the only set of absorbing states S + (and
therefore P(X∞ ∈ S + ) = 1) the distribution of stopping times (usually called hitting
times in the context of Markov chains) to S + follows a phase-type distribution. If
we collapse all the states of S + into one (by adding the probability rates that reach
it), the hitting times are unchanged and the rate matrix of the Markov chain with Nt
transient states
(Nt depends
on the choice of compartment model and n) takes the


0 0
0
form Q =
, where S is a Nt ×Nt matrix and S0 is equal to −S~1, where ~1 is
S0 S
the column vector of all ones. The time it takes to be absorbed in state 0 starting from
a vector of initial probabilities α
~ is distributed according to the distribution function
F (t) = P(TS + ≤ t) = 1 − α
~ exp(St)~1, where exp(·) denotes the matrix exponential.
The expected value is −~
αS −1~1.
The full equation reads

(A.3)

P(TDW ≤ τ ) = P(TDW < ∞)P(TDW ≤ τ |TDW < ∞)
= P(TDW < ∞)(1 − α
~ exp(St)~1) .

where S is obtained by the process of first conditioning and then collapsing the absorbing states and α also comes from conditioning D and then collapsing the states
in DW .
However, this is infeasible in practice as S scales roughly as Q, which is sn × sn .

16

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

A.2. Estimation of the state of the disease. We now continue to solve
analytically the rest of the tasks. Q2A and Q2B ask about patient zero posterior
probabilities and outbreak time estimation.
We define a state of the Markov chain to be compatible with our observation if in
that state the tested nodes are in a state which agrees with the tests. These include
all possibilities for non-tested nodes but may include some variations in tested-nodes
if the tests do not perfectly distinguish all states. We let C ⊂ DW ⊂ S be the set of
compatible states, and O denote our observation.
For Q2A we can apply Bayes’ Theorem
P(O|X0 = x)P(X0 = x)
∝ P(O|X0 = x)P(X0 = x) ,
P(O)
P
as P(O) is just a constant that ensures i∈S P(X0 = i|O) = 1. We know P(X0 = x),
as the initial distribution D is known. For P(O|X0 = x), we again consider all states of
the detection set of the placed tests as absorbing, and we need to sum the probabilities
of getting absorbed to exactly those states in the detection set which are compatible
with our observation. Therefore
X
(A.5)
P(O|X0 = x) =
P(X∞ = α|X0 = x) .
(A.4)

P(X0 = x|O) =

α∈C

The probability of ending in a specific absorbing state starting from a specific transient state can be found with the fundamental matrix of the jump Markov chain
matrix. Q2B asks about the distribution of time since the epidemic began. To
calculate the distribution function P(t ≤ k|O) conditioned on the absorption happening on a compatible state we can do exactly the same as we have done to calculate
P (TDW ≤ τ | TDW < ∞) except for replacing DW for its subset C. Q2C asks about
the probability distributions of the current state over the states in DW . This is
calculated using the same idea as Q2A. We denote X the actual state
(A.6)
P(X = x|O) =

P(O|X = x)P(X = x)
∝ P(O|X = x)P(X = x) = I(x ∈ C)P(X = x) .
P(O)

P(X = x) is the probability of being absorbed at state x, which is known a priori
with the fundamental matrix. Therefore, we see that the observation just restricts the
probability distribution from DW to its subset C. We can now solve for the probability
of node i being in state sl by summing over the posterior probabilities of all states in
which i is in sl .
A.3. Dynamic allocation for epidemic tracking. Note that if we perfectly
0
know P (X = x|O), then we are able to evaluate the expression for H(X|O,
P TW ), since
0
if Ci ⊂ C are the compatible states with test output ti , P(TW = ti ) = α∈Ci P(α|O)
and similarly as before,
(A.7)
P(X = x|O, TW 0 = ti ) ∝ P(TW 0 = ti |O, X = x)P(X = x|O) = I(x ∈ Ci )P(X = x|O) .
We can now evaluate the mutual information for all tests to obtain the best one.
Therefore, in this case we can perform the following iterative procedure:

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

17

• At t = ti , we test nodes according to the entropy criterion. After the tests
we update the distributions conditioned on test results using Bayes’ theorem.
Let Di be the distribution over nodes conditioned on the test results
• Run the Markov chain analytically until t = ti+1 − ti with initial distribution
Di
• Calculate the state distributions at time ti+1
• Decide which nodes to test at time ti+1 according to the criteria in Q5, and
calculate Di+1 with the obtained results

Appendix B. Proof of Theorem 3.1 and Theorem 3.4.

B.1. Proof of Theorem 3.1.

Theorem B.1 (Submodularity of fτ ). fτ : W 7→ P (TDW ≤ τ ) is a submodular
function.

Lemma B.2. Let S be a finite set and consider M a continuous time stochastic
process over the states of S. Then, for τ ∈ R+ the function h(W ) : W 7→ P (TW ≤ τ ),
where W ∈ P(S) is submodular.

Proof. We want to see that for X ⊂ Y and x ∈ S \ Y , P(TX∪{x} ≤ τ ) −
P(TX ≤ τ ) ≥ P(TY ∪{x} ≤ τ ) − P(TY ≤ τ ). For Z ⊂ S, P(TZ∪{x} ≤ τ ) − P(TZ ≤
τ ) = P(T{x} ≤ τ ∩ TZ > τ ). But since X ⊂ Y , TY ≥ τ =⇒ TX ≥ τ , and so
P(T{x} ≤ τ ∩ TX ≥ τ ) ≥ P(T{x} ≤ τ ∩ TY ≥ τ ) and we are done.

The second part of the submodularity proof for fτ concerns being able to conserve
the submodularity of h under composition with functions of certain properties.

Lemma B.3. (Conservation of submodularity under pullback). Let V, S be finite
sets, and let h : P(S) → R be monotone submodular. Let g : P(V ) → P(S) be a
function satisfying g(A ∪ B) = g(A) ∪ g(B) and A ⊂ B =⇒ g(A) ⊂ g(B) for A,
B ⊂ V . Then, h ◦ g : P(V ) → R is monotone submodular.
(Note that by g(A) we do not mean {g(x)|x ∈ A} but rather the image under g of
A as an element g({A}), but we omit the brackets. A is a subset of V but an element
of P(V), and therefore g sends it to a subset of S, element of P(S))

Figure 12 provides a scheme of the situation, in which we have used the explicit
notation.

18

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

Fig. 12. Scheme of Lemma B.3. We want to see that given that h is monotone submodular
and g satisfies certain conditions, the submodularity is conserved under the composition h ◦ g

Proof. The monotonicity of h ◦ g comes from the monotonicity of h and g. For
the submodularity, we want to see that for all S, T ⊂ V ,
(h ◦ g)(S) + (h ◦ g)(T ) ≥ (h ◦ g)(S ∪ T ) + (h ◦ g)(S ∩ T )
h(g(S)) + h(g(T )) ≥ h(g(S ∪ T )) + h(g(S ∩ T ))
h(g(S)) + h(g(T )) ≥ h(g(S) ∪ g(T ))) + h(g(S ∩ T ))
Since h is submodular and g(S) and g(T ) are subsets of S, we know that
h(g(S)) + h(g(T )) ≥ h(g(S) ∪ g(T ))) + h(g(S) ∩ g(T ))
But since g is monotonous we have g(S ∩T ) ⊂ (g(S)∩g(T )) and since h is monotonous
h(g(S ∩ T )) ≤ h(g(S) ∩ g(T )) and so we have h(g(S)) + h(g(T )) ≥ h(g(S) ∪ g(T ))) +
h(g(S ∩ T ))
Proof of Theorem 3.1:. We apply Lemma B.3 to the composition h ◦ D, where
D is the detection set function D : P(V) → P(S) mapping W to DW , where V is
the set of vertices in the graph and S the set of states of the stochastic process. By
Lemma B.2 h is submodular and it is also clearly monotonous by the same argument
that we have shown that fτ is monotonous. By definition of the detection set function
D, DA ⊂ DB if A ⊂ B and DA∪B = DA ∪ DB . Therefore, f = h ◦ D is submodular.
.
B.2. Proof of Theorem 3.4.
Theorem B.4. The sample approximation of fτ , fˆτ defined in subsection 3.1, is
non-negative, monotone and submodular for all NR ∈ N
Proof. Non-negativity is true by definition, and monotonicity comes from the fact
that if A ⊂ B, mink∈A L[i, k] ≥ mink∈B L[i, k] and so for a lesser or equal number
of runs the minimum over A will be less or equal than the minimum over B, so
f (A) ≤ f (B). For submodularity, we want to prove that for X ⊂ Y and x ∈ V \ Y
(B.1)

fˆ(X ∪ {x}) − fˆ(X) ≥ fˆ(Y ) − fˆ(Y ∪ {x}) .

ADAPTIVE TEST ALLOCATION FOR OUTBREAK TRACKING

19

The left hand side is
|i ∈ [NR ] s.t

min
k∈X∪{x}

L[i, k] <= τ | − |i ∈ [NR ] s.t min L[i, k] <= τ |
k∈X

which equals |i ∈ [NR ] s.t (mink∈X L[i, k] > τ ) ∩ (L[i, x] ≤ τ )|. Similarly, the right
hand side is |i ∈ [NR ] s.t (mink∈Y L[i, k] > τ ) ∩ (L[i, x] ≤ τ )|. As mink∈Y L[i, k] >
τ =⇒ mink∈X L[i, k] > τ , there are at least as many elements in the set of the
left-hand side than in the set of the right-hand side, proving the inequality.
Taking limits in the submodularity inequality for fˆτ provides an alternative proof that
fτ is submodular.
REFERENCES
[1] Global progress on covid-19 serology-based testing. https://www.centerforhealthsecurity.org/
resources/COVID-19/serology/Serology-based-tests-for-COVID-19.html. (Accessed on
07/22/2020).
[2] Test for current infection — cdc.
https://www.cdc.gov/coronavirus/2019-ncov/testing/
diagnostic-testing.html. (Accessed on 07/17/2020).
[3] Timeline of who’s response to covid-19.
https://www.who.int/news-room/detail/
29-06-2020-covidtimeline. (Accessed on 07/17/2020).
[4] A contribution to the mathematical theory of epidemics, Proceedings of the Royal Society
of London. Series A, Containing Papers of a Mathematical and Physical Character, 115
(1927), pp. 700–721, https://doi.org/10.1098/rspa.1927.0118.
[5] Hypertext 2009 network dataset – KONECT, Sept. 2016, http://konect.uni-koblenz.de/
networks/sociopatterns-hypertext.
[6] S. P. Borgatti, Centrality and network flow, Social Networks, 27 (2005), pp. 55–71, https:
//doi.org/10.1016/j.socnet.2004.11.008.
[7] T. Britton, Epidemic models on social networks – with inference, arXiv: Populations and
Evolution, (2019).
[8] N. A. Christakis and J. H. Fowler, Social network sensors for early detection of contagious
outbreaks, PLoS ONE, 5 (2010), p. e12948, https://doi.org/10.1371/journal.pone.0012948.
[9] R. M. Christley, G. L. Pinchbeck, R. G. Bowers, D. Clancy, N. P. French, R. Bennett,
and J. Turner, Infection in social networks: Using network analysis to identify highrisk individuals, American Journal of Epidemiology, 162 (2005), pp. 1024–1031, https:
//doi.org/10.1093/aje/kwi308.
[10] L. Ferretti, C. Wymant, M. Kendall, L. Zhao, A. Nurtay, L. Abeler-Dörner,
M. Parker, D. Bonsall, and C. Fraser, Quantifying SARS-CoV-2 transmission suggests epidemic control with digital contact tracing, Science, 368 (2020), p. eabb6936,
https://doi.org/10.1126/science.abb6936.
[11] M. Garcia-Herranz, E. Moro, M. Cebrian, N. A. Christakis, and J. H. Fowler, Using friends as sensors to detect global-scale contagious outbreaks, PLoS ONE, 9 (2014),
p. e92413, https://doi.org/10.1371/journal.pone.0092413.
[12] J. L. Herrera, R. Srinivasan, J. S. Brownstein, A. P. Galvani, and L. A. Meyers,
Disease surveillance on complex social networks, PLOS Computational Biology, 12 (2016),
p. e1004928, https://doi.org/10.1371/journal.pcbi.1004928.
[13] L. Isella, J. Stehlé, A. Barrat, C. Cattuto, J.-F. Pinton, and W. V. den Broeck,
What's in a crowd? analysis of face-to-face behavioral networks, Journal of Theoretical
Biology, 271 (2011), pp. 166–180, https://doi.org/10.1016/j.jtbi.2010.11.033.
[14] I. Z. Kiss, J. C. Miller, and P. L. Simon, Mathematics of Epidemics on Networks, Springer
International Publishing, 2017, https://doi.org/10.1007/978-3-319-50806-1.
[15] M. Kitsak, L. K. Gallos, S. Havlin, F. Liljeros, L. Muchnik, H. E. Stanley, and H. A.
Makse, Identification of influential spreaders in complex networks, Nature Physics, 6
(2010), pp. 888–893, https://doi.org/10.1038/nphys1746.
[16] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, J. VanBriesen, and N. Glance,
Cost-effective outbreak detection in networks, in Proceedings of the 13th ACM SIGKDD
international conference on Knowledge discovery and data mining - KDD '07, ACM Press,
2007, https://doi.org/10.1145/1281192.1281239.

20

P. BATLLE, C. FERNANDEZ-GRANDA, J. BRUNA AND V. M. PRECIADO

[17] L. A. Meyers, Contact network epidemiology: Bond percolation applied to infectious disease
prediction and control, Bulletin of the American Mathematical Society, 44 (2006), pp. 63–
87, https://doi.org/10.1090/s0273-0979-06-01148-7.
[18] P. V. Mieghem, J. Omic, and R. Kooij, Virus spread in networks, IEEE/ACM Transactions
on Networking, 17 (2009), pp. 1–14, https://doi.org/10.1109/tnet.2008.925623.
[19] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher, An analysis of approximations for
maximizing submodular set functions—i, Mathematical Programming, 14 (1978), pp. 265–
294, https://doi.org/10.1007/bf01588971.
[20] M. E. J. Newman, Exact Solutions of Epidemic Models on Networks, Working Papers 01-12073, Santa Fe Institute, Dec. 2001, https://ideas.repec.org/p/wop/safiwp/01-12-073.html.
[21] C. Nowzari, V. M. Preciado, and G. J. Pappas, Analysis and control of epidemics: A survey
of spreading processes on complex networks, 2015, https://arxiv.org/abs/arXiv:1505.00768.
[22] M. Salathe, M. Kazandjieva, J. W. Lee, P. Levis, M. W. Feldman, and J. H. Jones, A
high-resolution human contact network for infectious disease transmission, Proceedings of
the National Academy of Sciences, 107 (2010), pp. 22020–22025, https://doi.org/10.1073/
pnas.1009094108.
[23] D. Shah and T. Zaman, Rumors in a network: Who's the culprit?, IEEE Transactions on
Information Theory, 57 (2011), pp. 5163–5181, https://doi.org/10.1109/tit.2011.2158885,
https://doi.org/10.1109/tit.2011.2158885.
[24] B. Spinelli, L. E. Celis, and P. Thiran, A general framework for sensor placement in source
localization, IEEE Transactions on Network Science and Engineering, 6 (2019), pp. 86–102,
https://doi.org/10.1109/tnse.2017.2787551.
[25] L. Sun, K. W. Axhausen, D.-H. Lee, and M. Cebrian, Efficient detection of contagious
outbreaks in massive metropolitan encounter networks, Scientific Reports, 4 (2014), https:
//doi.org/10.1038/srep05099.
[26] L. A. Wolsey, An analysis of the greedy algorithm for the submodular set covering problem,
Combinatorica, 2 (1982), pp. 385–393, https://doi.org/10.1007/bf02579435.
[27] W. Yan, P.-L. Loh, C. Li, Y. Huang, and L. Yang, Conquering the worst case of infections
in networks, IEEE Access, 8 (2020), pp. 2835–2846, https://doi.org/10.1109/access.2019.
2962197.

