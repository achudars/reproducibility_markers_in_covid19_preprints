Selecting Treatment Effects Models for
Domain Adaptation Using Causal Knowledge

Trent Kyono * 1 Ioana Bica * 2 3 Zhaozhi Qian 4 Mihaela van der Schaar 3 1 4

arXiv:2102.06271v1 [cs.LG] 11 Feb 2021

Abstract
While a large number of causal inference models for estimating individualized treatment effects
(ITE) have been developed, selecting the best one
poses a unique challenge since the counterfactuals
are never observed. The problem is challenged
further in the unsupervised domain adaptation
(UDA) setting where we have access to labeled
samples in the source domain, but desire selecting
an ITE model that achieves good performance on
a target domain where only unlabeled samples
are available. Existing selection techniques for
UDA are designed for predictive models and are
sub-optimal for causal inference because they (1)
do not account for the missing counterfactuals
and (2) only examine the discriminative density
ratios between the input covariates in the source
and target domain and do not factor in the model’s
predictions in the target domain. We leverage the
invariance of causal structures across domains to
introduce a novel model selection metric specifically designed for ITE models under the UDA
setting. We propose selecting models whose predictions of the effects of interventions satisfy invariant causal structures in the target domain. Experimentally, our method selects ITE models that
are more robust to covariate shifts on several synthetic and real healthcare datasets, including estimating the effect of ventilation in COVID-19
patients from different geographic locations.

1. Introduction
Causal inference models for estimating individualized treatment effects (ITE) are designed to provide actionable intelligence as part of decision support systems and, when
*

Equal contribution 1 UCLA, Los Angeles, USA 2 University
of Oxford, Oxford, United Kingdom 3 The Alan Turing Institute, London, United Kingdom 4 University of Cambridge, Cambridge, United Kingdom. Correspondence to: Trent Kyono <tmkyono@gmail.com>, Ioana Bica <ioana.bica@eng.ox.ac.uk>.
Preprint. Work in progress. Copyright 2021 by the author(s).

Invariant underlying causal mechanisms
Causal graph G describing
data generating process.

Interventional causal
graph GT

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

X2

X1

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

Intervene on

T

<latexit sha1_base64="(null)">(null)</latexit>

T

Y

X2

X1

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>

do(T = t)

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

T

Y
<latexit sha1_base64="(null)">(null)</latexit>
<latexit

Assess fitness of
predictions to

GT
<latexit sha1_base64="(null)">(null)</latexit>

Dsrc

Train

<latexit sha1_base64="(null)">(null)</latexit>

x ⇠ pµ (X)

Candidate ITE
models

Source domain

<latexit sha1_base64="(null)">(null)</latexit>

x ⇠ p⇡ (X)
<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>

Observational
training dataset

Dtgt

Test

<latexit sha1_base64="(null)">(null)</latexit>

pµ (X) 6= p⇡ (X)
Covariate shifts
between domains

Test dataset

Select causal
inference model
robust to
distributional
shift in target
domain

Target domain

Figure 1. Method overview. We propose selecting ITE models
whose predictions of treatment effects on the target domain satisfy
the causal relationships in the interventional causal graph GT .

deployed on mission-critical domains, such as healthcare,
require safety and robustness above all (Shalit et al., 2017;
Alaa & van der Schaar, 2017). In healthcare, it is often the
case that the observational data used to train an ITE model
may come from a setting where the distribution of patient
features is different from the one in the deployment (target) environment, for example, when transferring models
across hospitals or countries. Because of this, it is imperative to select ITE models that are robust to these covariate
shifts across disparate patient populations. In this paper,
we address the problem of ITE model selection in the unsupervised domain adaptation (UDA) setting where we have
access to the response to treatments for patients on a source
domain, and we desire to select ITE models that can reliably
estimate treatment effects on a target domain containing
only unlabeled data, i.e., patient features.
UDA has been successfully studied in the predictive setting to transfer knowledge from existing labeled data in the
source domain to unlabeled target data (Ganin et al., 2016;
Tzeng et al., 2017). In this context, several model selection scores have been proposed to select predictive models
that are most robust to the covariate shifts between domains
(Sugiyama et al., 2007; You et al., 2019). These methods approximate the performance of a model on the target domain
(target risk) by weighting the performance on the validation
set (source risk) with known (or estimated) density ratios.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

However, ITE model selection for UDA differs significantly
in comparison to selecting predictive models for UDA (Stuart et al., 2013). Notably, we can only approximate the estimated counterfactual error (Alaa & van der Schaar, 2019),
since we only observe the factual outcome for the received
treatment and cannot observe the counterfactual outcomes
under other treatment options (Spirtes et al., 2000). Consequently, existing methods for selecting predictive models for
UDA that compute a weighted sum of the validation error
as a proxy of the target risk (You et al., 2019) is sub-optimal
for selecting ITE models, as their validation error in itself
is only an approximation of the model’s ability to estimate
counterfactual outcomes on the source domain.
To better approximate target risk, we propose to leverage
the invariance of causal graphs across domains and select
ITE models whose predictions of the treatment effects also
satisfy known or discovered causal relationships. It is wellknown that causality is a property of the physical world, and
therefore the physical (functional) relationships between
variables remain invariant across domains (Schoelkopf et al.,
2012; Bareinboim & Pearl, 2016; Rojas-Carulla et al., 2018;
Magliacane et al., 2018). As shown in Figure 1, we assume
the existence of an underlying causal graph that describes
the generating process of the observational data. We represent the selection bias present in the source observational
datasets by arrows between the features {X1 , X2 }, and treatment T . In the target domain, we only have access to the
patient features, and we want to estimate the patient outcome
(Y ) under different settings of the treatment (intervention).
When performing such interventions, the causal structure
remains unchanged except for the arrows into the treatment
node, which are removed.
Contributions. To the best of our knowledge, we present
the first UDA selection method specifically tailored for machine learning models that estimate ITE. Our ITE model
selection score uniquely leverages the estimated patient
outcomes under different treatment settings on the target
domain by incorporating a measurement of how well these
outcomes satisfy the causal relationships in the interventional causal graph GT . This measure, which we refer to
as causal risk, is computed using a log-likelihood function
quantifying the model predictions’ fitness to the underlying causal graph. We provide a theoretical justification for
using the causal risk, and we prove that our proposed ITE
model selection metric for UDA prefers models whose predictions satisfy the conditional independence relationships
in GT and are thus more robust to changes in the distribution of the patient features. Experimentally, we show
that adding the causal risk to existing state-of-the-art model
selection scores for UDA results in selecting ITE models
with improved performance on the target domain. We perform extensive ablation studies to show the robustness of
our method when only partial causal knowledge is available,


and to assess its sensitivity to misspecification of the causal
structure. Finally, we provide an illustrative example of
model selection for several real-world datasets for UDA,
including ventilator assignment for COVID-19.

2. Related Works
Our work is related to causal inference and domain adaptation. We describe existing methods for ITE estimation and
selection, UDA model selection in the predictive setting,
and domain adaptation from a causal perspective.
ITE models. Recently, a large number of machine learning methods for estimating heterogeneous ITE from observational data have been developed, leveraging ideas from
representation learning (Johansson et al., 2016; Shalit et al.,
2017; Yao et al., 2018), adversarial training, (Yoon et al.,
2018), causal random forests (Wager & Athey, 2018) and
Gaussian processes (Alaa & van der Schaar, 2017; 2018).
Nevertheless, no single model will achieve the best performance on all types of observational data (Dorie et al., 2019)
and even for the same model, different hyperparameter settings or training iterations will yield different performance.


ITE model selection. Evaluating ITE models’ performance is challenging since counterfactual data is unavailable, and consequently, the true causal effects cannot be
computed. Several heuristics for estimating model performance have been used in practice (Schuler et al., 2018;
Van der Laan & Robins, 2003). Factual model selection
only computes the error of the ITE model in estimating the
factual patient outcomes. Alternatively, inverse propensity
weighted (IPTW) selection uses the estimated propensity
score to weigh each sample’s factual error and thus obtain
an unbiased estimate (Van der Laan & Robins, 2003). Alternatively, Alaa & van der Schaar (2017) propose using
influence functions to approximate ITE models’ error in
predicting both factual and counterfactual outcomes. However, existing ITE selection methods are not designed to
select models robust to distributional changes in the patient
populations, i.e., for domain adaptation.


UDA model selection. UDA is a special case of domain
adaptation, where we have access to unlabeled samples
from the test or target domain. Several methods for selecting predictive models for UDA have been proposed (Pan &
Yang, 2010). Here we focus on the ones that can be adapted
for the ITE setting. The first unsupervised model selection method was proposed by Long et al. (2018), who used
Importance-Weighted Cross-Validation (IWCV) (Sugiyama
et al., 2007) to select hyperparameters and models for covariate shift. IWCV requires that the importance weights (or
density ratio) be provided or known ahead of time, which is
not always feasible in practice. Later, Deep Embedded Validation (DEV), proposed by You et al. (2019), was built on
IWCV by using a discriminative neural network to learn the


Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

target distribution density ratio to provide an unbiased estimation of the target risk with bounded variance. However,
these proposed methods do not consider model predictions
on the target domain and are agnostic of causal structure.
Causal structure for domain adaptation. Kyono &
van der Schaar (2019) proposed Causal Assurance (CA)
as a domain adaptation selection method for predictive models that leverages prior knowledge in the form of a causal
graph. In addition to not being a UDA method, their work is
centered around predictive models and is thus sub-optimal
for ITE models, where the edges into the treatment (or intervention) will capture the selection bias of the observational
data. Moreover, their method does not allow for examining
the target domain predictions, which is a key novelty of this
work. We leverage do-calculus (Pearl, 2009) to manipulate
the underlying directed acyclical graph (DAG) into an interventional DAG that more appropriately fits the ITE regime.
Researchers have also focused on leveraging the causal
structure for predictive models by identifying subsets of
variables that serve as invariant conditionals (Rojas-Carulla
et al., 2018; Magliacane et al., 2018).


3. Preliminaries
3.1. Individualized treatment effects and model
selection for UDA
src src Nsrc
Consider a training dataset Dsrc = {(xsrc
i , ti , yi )}i=1
consisting of Nsrc independent realizations, one for each
individual i, of the random variables (X, T, Y ) drawn from
the source joint distribution pµ (X, T, Y ). Let pµ (X) be the
marginal distribution of X. Assume that we also have access
Ntgt
to a test dataset Dtgt = {xtgt
i }i=1 from the target domain,
consisting of Ntgt independent realizations of X drawn
from the target distribution pπ (X), where pµ (X) 6= pπ (X).
Let the random variable X ∈ X represent the context (e.g.
patient features) and let T ∈ T describe the intervention
(treatment) assigned to the patient. Without loss of generality, consider the case when the treatment is binary, such
that T = {0, 1}. However, note that our model selection
method is also applicable for any number of treatments. We
use the potential outcomes framework (Rubin, 2005) to describe the result of performing an intervention t ∈ T as
the potential outcome Y (t) ∈ Y. Let Y (1) represent the
potential outcome under treatment and Y (0) the potential
outcome under control. Note that for each individual, we
can only observe one of potential outcomes Y (0) or Y (1).
We assume that the potential outcomes have a stationary distribution pµ (Y (t) | X) = pπ (Y (t) | X) given the context
X; this represents the covariate shift assumption in domain
adaptation (Shimodaira, 2000).

Observational data can be used to estimate E[Y | X =
x, T = t] through regression. Assumption 1 describes
the causal identification conditions (Rosenbaum & Rubin,

1983), such that the potential outcomes are the same as the
conditional expectation: E[Y (t) | X = x] = E[Y | X =
x, T = t].
Assumption 1 (Consistency, Ignorability and Overlap).
For any individual i, receiving treatment ti , we observe
Yi = Y (ti ). Moreover, {Y (0), Y (1)} and the data
generating process p(X, T, Y ) satisfy strong ignorability
Y (0), Y (1) ⊥⊥ T | X and overlap ∀x if P (X = x) > 0
then P (T | X = x) > 0 .
The ignorability assumption, also known as the no hidden
confounders (unconfoundedness), means that we observe
all variables X that causally affect the assignment of the
intervention and the outcome. Under unconfoundedness, X
blocks all backdoor paths between Y and T (Pearl, 2009).
Under Assumption 1, the conditional expectation of the potential outcomes can also be written as the interventional
distribution obtained by applying the do−operator under
the causal framework of Pearl (2009): E[Y (t) | X = x] =
E[Y | X = x, do(T = t)]. This equivalence will enable us
to reason about causal graphs and interventions on causal
graphs in the context of selecting ITE methods for estimating potential outcomes.
Evaluating ITE models. Methods for estimating ITE
learn predictors f : X × T → Y such that f (x, t) approximates E[Y | X = x, T = t] = E[Y (t) | X = x] = E[Y |
X = x, do(T = t)]. The goal is to estimate the ITE, also
known as the conditional average treatment effect (CATE):


τ (x) = E[Y (1) | X = x] − E[Y (0) | X = x]

(1)

The CATE is essential for individualized decision making as it guides treatment assignment policies. A trained
ITE predictor f (x, t) approximates CATE as: τ̂ (x) =
f (x, 1) − f (x, 0). Commonly used to assess ITE models is
the precision of estimating heterogeneous effects (PEHE)
(Hill, 2011):
P EHE = Ex∼p(x) [(τ (x) − τ̂ (x))2 ],

(2)

which quantifies a model’s estimate of the heterogeneous
treatment effects for patients in a population.
UDA model selection. Given a set F = {f1 , . . . fm } of
candidate ITE models trained on the source domain Dsrc ,
our aim is to select the model that achieves the lowest target
risk, that is the lowest PEHE on the target domain Dtgt .
Thus, ITE model selection for UDA involves finding:


fˆ = arg min Ex∼pπ (x) [(τ (x) − τ̂ (x))2 ]

(3)

f ∈F

= arg min Ex∼pπ (x) [(τ (x) − (f (x, 1) − f (x, 0)))2 ].

(4)

f ∈F

To achieve this, we propose using the invariance of causal
graphs across domains to select ITE models that are robust
to distributional shifts in the marginal distribution of X.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

3.2. Causal graphs framework
In this work, we use the semantic framework of causal
graphs (Pearl, 2009) to reason about causality in the context
of model selection. We assume that the unknown data generating process in the source domain can be described by the
causal directed acyclic graph (DAG) G, which contains the
relationships between the variables V = (X, T, Y ) consisting of the patient features X, treatment T , and outcome Y .
We operate under the Markov and faithfulness conditions
(Richardson, 2003; Pearl, 2009), where any conditional independencies in the joint distribution of pµ (X, T, Y ) are
indicated by d-separation in G and vice-versa.
In this framework, an intervention on the treatment variable
T ∈ V is denoted through the do-operation do(T = t) and
induces the interventional DAG GT , where the edges into
T are removed. The interventional DAG GT corresponds to
the interventional distribution pµ (X, Y | do(T = t)) (Pearl,
2009). The only node on which we perform interventions
in the target domain is the treatment node. Consequently,
this node will have the edges into it removed, while the
remainder of the DAG is unchanged. We assume that the
causal graph is invariant across domains (Schoelkopf et al.,
2012; Ghassami et al., 2017; Magliacane et al., 2018) which
we formalize for interventions as follows:
Assumption 2 (Causal invariance). Let V = (X, T, Y )
be a set of variables consisting of patient features X, treatment T , and outcome Y . Let ∆ be a set of domains,
pδ (X, Y | do(T = t)) be the corresponding interventional
distribution on V in domain δ ∈ ∆, and I(pδ (V )) denote
the set of all conditional independence relationships embodied in pδ (V ), then
∀δi , δj ∈ ∆, I(pδi (X, Y | do(T = t))) =

I(pδj (X, Y | do(T = t))). (5)

4. ITE Model Selection for UDA
Let F = {f1 , f2 , . . . fm } be a set of candidate ITE models
trained on the data from the source domain Dsrc . Our
aim is to select the model f ∈ F that achieves the lowest
PEHE on the target domain Dtgt , as described in Equation
3. Let G be a causal graph, either known or discovered,
that describes the causal relationships between the variables
in X, the treatment T and the outcome Y . Let GT be the
interventional causal graph of G that has edges removed
into the treatment variable T .
 Prior causal knowledge and graph discovery. The invariant graph G can be arrived at in two primary ways. The
first would be through experimental means, such as randomized trials, which does not scale to a large number of
covariates due to financial or ethical impediments. The second would be through the causal discovery of DAG structure

from observational data (for a listing of current algorithms
we refer to (Glymour et al., 2019b)), which is more feasible
in practice. Under the assumption of no hidden confounding
variables, score-based causal discovery algorithms output a
completed partially directed acyclical graph (CPDAG) representing the Markov equivalence class (MEC) of graphs,
i.e., those graphs which are statistically indistinguishable
given the observational data and therefore share the same
conditional independencies. Provided a CPDAG, it is up to
an expert (or further experiments) to orient any undirected
edges of the CPDAG to convert it into the DAG (Pearl,
2009). This step is the most error-prone, and we show in our
real data experiments how a subgraph (using only the known
edges) can still improve model selection performance.
Improving target risk estimation. For the trained ITE
model f , let ŷ(0) = f (x, 0) and let ŷ(1) = f (x, 1) be the
predicted potential outcomes for x ∼ pπ (x). We develop a
selection method that prefers models whose predictions on
the target domain preserve the conditional independence relationships between X, T and Y in the interventional DAG
GT with edges removed into the treatment T . We first propose a Theorem, which we later exploit for model selection.


Theorem 1. Let pµ (X, T, Y ) be a source distribution with
corresponding DAG G. If Y = f (X, T ), i.e., f is an optimal
ITE model, then
IG (GT ) = I(pπ (X, f (X, t) | do(T = t))),

(6)

where pπ (X, f (X, t) | do(T = t)) is the interventional distribution for the target domain and IG (GT ) and
I(pπ (X, f (X, t) | do(T = t))) returns all the conditional
independence relationships in GT and pπ (X, f (X, t) |
do(T = t)), respectively.
For details and proof of Theorem 1 see Appendix B. Theorem 1 provides an equality relating the predictions of f in the
target domain to the interventional DAG GT . Therefore we
desire the set of independence relationships in GT to equal
I(pπ (X, f (X, t) | do(T = t))). In our case, we do not have
access to the true interventional distribution pπ (X, f (X, t) |
do(T = t)), but we can approximate it from the dataset
obtained by augmenting the unlabeled target dataset Dtgt
with the model’s predictions of the potential outcomes:
Ntgt
tgt
tgt
tgt
D̂tgt = {(xtgt
i , 0, ŷi (0)), (xi , 1, ŷi (1))}i=1 , where
tgt
tgt
tgt
ŷi (t) = f (xi , t), for xi ∈ Dtgt . We propose to improve the formalization in Eq. 3 by adding a constraint on
preserving the conditional independencies of GT as follows:
arg min RT (f ) s.t. E[N CI(GT , D̂tgt )] = 0,

(7)

f ∈F

where RT (f ) is a function that approximates the target risk
for a model f , N CI(GT , D̂tgt ) is the number of conditional
independence relationships in the graph GT that are not

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

satisfied by the test dataset augmented with the model’s
predictions of the potential outcomes D̂tgt .
Interventional causal model selection. Consider the
schematic in Figure 2. We propose an interventional causal
model selection (ICMS) score that takes into account the
model’s risk on the source domain, but also the fitness to
the interventional causal graph GT on the target domain
according to Eq. 3. A score that satisfies this is provided by
the Lagrangian method:


L = RT (f ) + λE[N CI(GT , D̂tgt )].

(8)

The first term RT (f ) is equivalent to the expected test
PEHE which at selection time can be approximated by
the validation risk (either source or target risk), which
we represent as vr (f, Dv , Dtgt ).
The second term,
E[N CI(GT , D̂tgt )], which is derived from Theorem 1, evaluates the number of conditional independence relationships
resulting from d-separation in the graph GT that are not
satisfied by the test dataset augmented with the model’s predictions of the potential outcomes D̂tgt . However, this term
may never equal 0 and directly minimizing N CI(GT , D̂tgt )
involves evaluating conditional independence relationships,
which is a hard statistical problem, especially for continuous
variables (Shah et al., 2020). Because of this, we approximate N CI by using a causal fitness score that measures
the likelihood of a DAG given the augmented dataset Dtgt ,
which we rewrite as cr (f, Dtgt , GT ). This represents an
alternative and equivalent approach, also used by scorebased causal discovery methods (Ramsey et al., 2017b; Glymour et al., 2019c). Consider partitioning the source dataset
src src Nsrc
Dsrc = {(xsrc
i , ti , yi )}i=1 into a training dataset Dtr
and a validation dataset Dv such that Dsrc = Dtr ∪ Dv .
From Eq. 8 we define our ICMS score r as follows:
Definition 1 (ICMS score). Let f be an ITE predictor
Ntgt
trained on Dtr . Let Dtgt = {(xtgt
i )}i=1 be test dataset
and let GT be the interventional causal graph. We define
the following selection score:
r(f, Dv , Dtgt , GT ) = vr (f, Dv ,Dtgt )+

λcr (f, Dtgt , GT )

(9)

where vr measures the validation risk on the validation set Dv and cr is a scoring function, which we
call causal risk, that measures the fitness of the interventional causal graph GT to the dataset D̂tgt =
Ntgt
tgt
tgt
tgt
tgt
{(xtgt
i , 0, ŷi (0)), (xi , 1, ŷi (1))}i=1 , where ŷi (t) =
tgt
tgt
f (xi , t), for xi ∈ Dtgt .
The validation risk vr (f, Dv , Dtgt ) can either be (1) source
risk where we use existing model selection scores for ITE
(Alaa & van der Schaar, 2019; Van der Laan & Robins,
2003), or (2) an approximation of target risk using the preexisting methods of IWCV or DEV (Sugiyama et al., 2007;

You et al., 2019). We describe in the following section how
to compute the causal risk cr (f, Dtgt , GT ). λ is a tuning
factor between our causal risk term and validation risk vr .
We currently set λ = 1 for our experiments, but ideally, λ
would be proportional to our certainty in our causal graph.
We discuss alternative methods for selecting λ, as well as a λ
sensitivity analysis in Appendix F. We provide ICMS pseudocode and a graphical illustration for calculating ICMS in
Appendix C.
Assessing causal graph fitness. The causal risk term
cr (f, Dtgt , GT ) as part of our ICMS score requires assessing the fitness of the dataset D̂tgt to the invariant
causal knowledge in GT . Some options include noteworthy
maximum-likelihood algorithms such as the Akaike Information Criterion (AIC) (Akaike, 1998) and Bayesian Information Criterion (BIC) (Schwarz, 1978). Both the BIC and
AIC are penalized versions of the log-likelihood function
of a DAG given data, e.g., LL(GT | D̂tgt ). In score based
causal discovery, the DAG that best fits the data will maximize the LL(GT | D̂tgt ) subject to some model complexity
penalty constraints. In this work, we are not searching between candidate causal graphs and only care about maximizing our DAG to dataset fitness. Thus, we use the negative
log-likelihood of G given D̂tgt , i.e., −LL(GT | D̂tgt ), for
our causal risk term cr . The −LL(GT | D̂tgt ) has a smaller
value when G is closer to modeling the probability distribution in D̂tgt , i.e., the predicted potential outcomes satisfy
the conditional independence relationships in G.


In score-based causal discovery, the Bayesian Information
Criterion (BIC) is a common score that is used to discover
the completed partially directed acyclic graph (CPDAG),
representing all DAGs in the MEC, from observational data.
Under the Markov and faithfullness assumptions, every conditional independence in the MEC of G is also in D. The
BIC score is defined as:


log2 N
BIC(G|D) = −LL(G|D) +
||G||, (10)
2
where N is the data set size and ||G|| is the dimensionality
of G. For our function f in Eq. 9, we use the BIC score.
However, since N and ||G|| are held constant in our proposed method our function f ∝ −LL(G|D). To find the
LL(G|D) we use the following decomposition:
X
LL(G|D) = −N
HD (Xi |P Ai ),
(11)
Xi P Ai

where N is the dataset size, P Ai are the parent nodes of
Xi in G, and H is the conditional entropy function which
is given by (Darwiche, 2009) for discrete variables and by
(Ross, 2014) for continuous or mixed variables.
Limitations of UDA selection methods In the ideal scenario, we would be able to leverage labeled samples in the


Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

Source
Dataset

Dsrc =
<latexit sha1_base64="(null)">(null)</latexit>

Train treatment effects
model f on

tgt
D̂tgt = {(xtgt
i , 0, ŷi (0)),

<latexit sha1_base64="(null)">(null)</latexit>

Dtr

<latexit sha1_base64="(null)">(null)</latexit>

Predictions on Target Data

Interventional

Source
Validation Loss

X1

Density Ratio

<latexit sha1_base64="(null)">(null)</latexit>

LL(GT | D̂tgt )

DAG

X2

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>

<latexit sha1_base64="(null)">(null)</latexit>
<latexit

Dtgt

cr (f,Dtgt , GT ) =
<latexit sha1_base64="(null)">(null)</latexit>

Dtr [ Dv

Target
Dataset
(unlabeled)

Causal Risk

N

tgt
tgt
(xtgt
i , 1, ŷi (1))}i=1

<latexit sha1_base64="(null)">(null)</latexit>

T

Y
<latexit sha1_base64="(null)">(null)</latexit>
<latexit

Target Risk Estimate
(Validation Risk)

vr (f, Dv , Dtgt )

ICMS

<latexit sha1_base64="(null)">(null)</latexit>

Figure 2. ICMS is unique in that it calculates a causal risk (green)
using predictions on target data. Purple arrows denote pathways
unique to ICMS.

target domain to estimate the target risk of a machine learning model. We can express the target risk Rtgt in terms of
the testing loss as follows:
1 X
Rtgt =
((Y tgt (1) − Y tgt (0))−
Ntgt
(12)
tgt
tgt
2
(f (x , 1) − f (x , 0))
However, in general, we do not have access to the treatment responses for patients in the target set and, even if we
did, we can only observe the factual outcome. Moreover,
existing model selection methods for UDA only consider
predictions on the source domain and do not take into account the predictions of the candidate model in the target
domain. Specifically, DEV and IWCV calculate a density
ratio or importance weight between the source and target
domain as follows:
wf (x) =

p(d = 1|x) N src
,
p(d = 0|x) N test

(13)

where d designates dataset domain (source is 0, target is 1),
and p(d=1|x)
p(d=0|x) can be estimated by a discriminative model to
distinguish source from target samples (You et al., 2019).
Both calculate their score as a function of ∆ as follows:
∆=

Nv
1 X
wf (xvi )l(yiv , f (xvi , 0), f (xvi , 1))
Nv i=1

(14)

where l(·, ·, ·) is a validation loss, such as influence-function
based validation (Alaa & van der Schaar, 2019). Note that
the functions l and w are only defined in terms of validation
features xvi from the source dataset. Such selection scores
can be used to compute the validation score vr (f, Dv , Dtgt )
part of the ICMS score.
However, our ICMS score also computes the likelihood of
the interventional causal graph given the predictions of the
model in the target domain as a proxy for the risk in the
target domain. By adding the causal risk, we the improve
the estimation of target risk. Additionally, we specifically
make use of the estimated potential outcomes on the test set
f (xtgt , 0) and f (xtgt , 1) to calculate our selection score as
shown in Eq. 9. Fig. 2 depicts how we use the predictions
of the target data to calculate our ICMS score.

5. Experiments
We perform extensive experiments to evaluate ICMS. For
validation and for ablation studies we use synthetic data
where the true causal structure is known (Section 5.1). We
also evaluate ICMS on standard ITE benchmark datasets,
IHDP (Hill, 2011) and Twins (Almond et al., 2005), and on a
prostate cancer dataset; for these datasets we perform causal
discovery to obtain the causal graph needed for computing
the causal risk as part of ICMS (Appendix I). Finally, we
show how ICMS can be used for selecting the best ITE
models for estimating the effect of ventilator on COVID-19
patients from different geographic locations (Section 5.2).
We implemented ICMS in tensorflow1 .
Benchmark ITE models. We show how the ICMS score
improves model selection for state-of-the-art ITE methods
based on neural networks: GANITE (Yoon et al., 2018),
CFRNet (Johansson et al., 2018), TARNet (Johansson et al.,
2018), SITE (Yao et al., 2018) and Gaussian processes:
CMGP (Alaa & van der Schaar, 2017) and NSGP (Alaa &
van der Schaar, 2018). These ITE methods use different
techniques for estimating ITE and currently achieve the best
performance on standard benchmark observational datasets
(Alaa & van der Schaar, 2019). We iterate over each model
multiple times and compare against various DAGs and heldout test sets. Having various DAG structures results in varying magnitudes of test error. Therefore, without changing
the ranking of the models, we min-max normalize our test
error between 0 and 1 for each DAG, such that equal weight
is given to each experimental run, and a relative comparison
across benchmark ITE models can be made.


Benchmark methods. We benchmark our proposed ITE
model selection score ICMS against each of the following
UDA selection methods developed for predictive models:
IWCV (Long et al., 2018) and DEV (You et al., 2019). To
approximate the source risk, i.e., the error of ITE methods
in predicting potential outcomes on the source domain (validation set Dv ), we use the following standard ITE scores:
MSE on the factual outcomes, inverse propensity weighted
factual error (IPTW) (Van der Laan & Robins, 2003) and influence functions (IF) (Alaa & van der Schaar, 2019). Note
that each score (MSE, IPTW, etc.) can be used to estimate
the target risk in the UDA selection methods: IWCV, DEV,
or ICMS. Specifically, we benchmark our method in conjunction with each combination of ITE model errors {MSE,
IPTW, IF} with validation risk {∅, IWCV, DEV}. We include experiments with ∅, to demonstrate using source risk
as an estimation of validation risk.


Evaluation metrics. We evaluate methods by the test
performance in terms of the average PEHE of the top 10%
of models in the list returned by the model selection bench

1

Code will be made available upon acceptance.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Table 1. PEHE-10 performance (with standard error) using ICMS on top of existing UDA methods. ICMS() means that the  was used
as the validation risk vr in the ICMS. For example, ICMS(DEV(?)) represents DEV(?) selection used as the validation risk vr in the
ICMS. The ? indicates the method used to approximate the validation error on the source dataset. Our method (in bold) improves over
each selection method over all models and source risk scores (Src.).
S ELECTION M ETHOD

GANITE

CFR

SITE

CMGP

NSGP

MSE
ICMS(MSE)
IWCV(MSE)
ICMS(IWCV(MSE))
DEV(MSE)
ICMS(DEV(MSE))

0.395
0.222
0.348
0.212
0.398
0.224

(0.051)
(0.049)
(0.046)
(0.043)
(0.056)
(0.042)

0.363
0.212
0.393
0.220
0.414
0.210

(0.042)
(0.036)
(0.044)
(0.051)
(0.042)
(0.039)

0.391
0.264
0.364
0.256
0.427
0.269

(0.050)
(0.034)
(0.052)
(0.039)
(0.049)
(0.035)

0.157
0.126
0.185
0.149
0.198
0.120

(0.035)
(0.027)
(0.033)
(0.033)
(0.038)
(0.040)

0.131
0.120
0.201
0.183
0.239
0.160

(0.046)
(0.050)
(0.041)
(0.055)
(0.058)
(0.047)

0.282
0.210
0.209
0.172
0.183
0.160

(0.049)
(0.047)
(0.040)
(0.043)
(0.048)
(0.042)

IPTW
ICMS(IPTW)
IWCV(IPTW)
ICMS(IWCV(IPTW))
DEV(IPTW)
ICMS(DEV(IPTW))

0.381
0.220
0.269
0.053
0.302
0.087

(0.049)
(0.049)
(0.055)
(0.028)
(0.072)
(0.035)

0.355
0.217
0.518
0.121
0.472
0.194

(0.046)
(0.039)
(0.049)
(0.034)
(0.056)
(0.052)

0.394
0.272
0.433
0.119
0.414
0.120

(0.052)
(0.032)
(0.038)
(0.035)
(0.049)
(0.027)

0.357
0.228
0.416
0.207
0.400
0.220

(0.045)
(0.031)
(0.053)
(0.039)
(0.057)
(0.031)

0.182 (0.046)
0.140 (0.050)
0.417 (0.043)
0.304 (0.059)
0.441 (0.071)
0.282 (0.041)

0.292
0.207
0.475
0.328
0.493
0.355

(0.045)
(0.047)
(0.053)
(0.058)
(0.086)
(0.050)

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

0.222
0.127
0.180
0.058
0.193
0.069

(0.041)
(0.039)
(0.059)
(0.018)
(0.058)
(0.026)

0.255
0.166
0.364
0.104
0.415
0.191

(0.050)
(0.042)
(0.051)
(0.025)
(0.045)
(0.048)

0.250
0.190
0.286
0.108
0.292
0.107

(0.046)
(0.044)
(0.041)
(0.033)
(0.046)
(0.029)

0.321
0.215
0.293
0.173
0.214
0.147

(0.059)
(0.056)
(0.043)
(0.028)
(0.038)
(0.025)

0.392
0.212
0.415
0.292
0.490
0.229

0.376
0.250
0.437
0.331
0.544
0.364

(0.057)
(0.054)
(0.057)
(0.051)
(0.053)
(0.056)

marks. We will refer to this as the PEHE-10 test error. We
provide additional metrics for our results in Appendix G.1.
5.1. Synthetic UDA model selection
Data generation. In this section, we evaluate our method
in comparison to related selection methods on synthetic data.
For each of the simulations, we generated a random DAG,
G, with n vertices and up to n(n − 1)/2 edges (the asymptotic maximum number of edges in a DAG) between them.
We construct our datasets with functional relationships between variables with directed edges between them in G and
applied Gaussian noise (0 mean and 1 variance) to each. We
provide further details and pseudocode in Appendix G.1.
Using the structure of G, we synthesized 2000 samples for
our observational source dataset Dsrc . We randomly split
Dsrc into a training set Dtr and validation set Dv with 80%
and 20% of the samples, respectively. To generate the testing dataset Dtgt , we use G to generate 1000 samples where
half of the dataset receives treatment, and the other half does
not. For Dtgt , we randomly shift the mean between 1 and
10 of at least one ancestor of Y in G, whereas in Dsrc a
mean of 0 is used. It is important to note that the actual outcome or response is never seen when selecting our models.
Furthermore, the training dataset Dsrc is observational and
contains selection bias into the treatment node, whereas the
synthetic test set Dtgt does not, since it was generated by
intervention at the treatment node. Our algorithm has only
access to the covariates X in Dtgt .


TAR

(0.051)
(0.053)
(0.048)
(0.062)
(0.043)
(0.054)

Improved selection for all ITE models. Table 1 shows
results of ICMS on synthetic data over the benchmark ITE
models. Here, we evaluate three different types of selection
baseline methods: MSE, IPTW, and IF. We then compare
each baseline selection method with UDA methods: IWCV,
DEV, and ICMS (proposed). We repeated the experiment
over 50 different DAGs with 30 candidate models for each
architecture. Each of the candidate algorithms was trained
using their published settings and hyperparameters, as detailed in Appendix E. In Table 1, we see that our proposed
method (ICMS) improves on each baseline selection method
by having a lower testing error in terms of PEHE-10 (and
inversion count in Appendix G.1) over all treatment models.



Ablation studies. We provide additional practical considerations and experiments regarding computational complexity, a subgraph analysis, sensitivity to causal graph misspecifications, ICMS selection on tree-based methods, ICMS
selection on causally invariant features, noisiness of fitness
score, and additional further discussion in Appendix H.


5.2. Application to the COVID-19 Response
ICMS facilitates and improves model transfer across domains with disparate distributions, i.e., time, geographical
location, etc., which we will demonstrate in this section for
COVID-19. The COVID-19 pandemic challenged healthcare systems worldwide. At the peak of the outbreak, many
countries experienced a shortage of life-saving equipment,
such as ventilators and ICU beds.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

2 weeks

Urban

Rural

63

68

Sex: male

65%

61%

Chronic Resp. Disease

3.7%

5.6%

Chronic Heart Disease

3.5%

8.1%

Age (median)

Obesity
Hypertension

5.5%

4.1%

12.8%

14.6%

Obesity

Chronic
Heart

Chronic
Resp.

Treatment
(ventilate)

COVID-19
Mortality

Diabetes

Asthma

Hypertens.

Chronic
Renal

Age

Gender

Figure 3. Left: COVID-19 pandemic hit urban areas before spreading to rural areas. Middle: Feature subset showing there exists a
significant covariate shift between urban and rural populations with the urban population younger and with fewer preexisting conditions.
Right: Discovered COVID-19 DAG.

Considering data from the UK outbreak, the pandemic hit
the urban population before spreading to the rural areas (Figure 3). This implies that if we reacted in a timely manner,
we could transfer models trained on the urban population to
the rural population. However, there is a significant domain
shift as the rural population is older and has more preexisting conditions (Armstrong et al., 2020). Furthermore,
at the time of model deployment in rural areas, there may
be no labeled samples available. The characteristics of the
two populations are summarized in Figure 3. We provide
detailed dataset details and patient statistics in Appendix J.
COVID-19 Ventilation UK (urban) → UK (rural). Using the urban dataset, we performed causal discovery on
the relationships between the patient covariates, treatment,
and outcome. The discovered graph (Figure 3) agree well
with the literature (Williamson et al., 2020; Niedzwiedz
et al., 2020). To be able to evaluate the ITE methods on how
well they estimate all counterfactual outcomes, we created
a semi-synthetic version of the dataset with outcomes simulated according to the causal graph. Refer to Appendix J for
details of the semi-synthetic data simulation. Our training
observational dataset consists of the patient features, ventilator assignment (treatment) for the COVID-19 patients in
the urban area, and the synthetic outcome generated based
on the causal graph.
Improving model selection for GANITE
Patients with improved outcomes



40
35
30
25

mortality. We used the same training regime as in the synthetic experiments and the discovered COVID-19 causal
DAG using FGES (Ramsey et al., 2017a)) shown in Figure 3.
We evaluated the best ITE model selected by each model
selection method in a ventilator assignment task. Using
each selected ITE model, we assigned 2000 ventilators to
the rural area patients that would have the highest estimated
benefit (individualized treatment effect) from receiving the
ventilator. Using the known synthetic outcomes for each
patient, we then computed how many patients would have
improved outcomes using each selected ITE model for assigning ventilators. By considering selection based on the
factual outcome (MSE) on the source dataset as a baseline,
in Figure 4, we computed the additional number of patients
with improved outcomes by using ICMS on top of existing
UDA methods when selecting GANITE models with different settings of the hyperparameters. We see that ICMS (in
blue) identified the GANITE models that resulted in better
patient outcomes in the UK’s rural areas without access to
labeled data. Additional results are included in Appendix J.
Additional experiments. On the TWINS dataset (Almond et al., 2005) (in Appendix I), we show how our method
improves UDA model selection even with partial knowledge
of the causal graph (i.e., using only a known subgraph for
computing the ICMS score). Note also that in the Twins
dataset, we have access to real patient outcomes. Moreover,
we also provide additional UDA model selection results for
transferring domains on a prostate cancer dataset and the
Infant Health and Development Program (IHDP) dataset
(Hill, 2011) in Appendix I.


20

6. Conclusion

15
10
5
0

IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

DEV(IF) ICMS(DEV(IF))

Figure 4. Performance of model selection methods in terms of the
additional number of patients with improved outcomes compared
to selecting models based on the factual error on the source domain.

For each benchmark ITE model, we used 30 different hyperparameter settings and trained the various models to
estimate the effect of ventilator use on the patient risk of

We provide a novel ITE model selection method for UDA
that uniquely leverages the predictions of candidate models
on a target domain by preserving invariant causal relationships. To the best of our knowledge, we have provided the
first model selection method for ITE models specifically for
UDA. We provide a theoretical justification for using ICMS
and have shown on a variety of synthetic, semi-synthetic,
and real data that our method can improve on existing stateof-the-art UDA methods.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

Acknowledgments
This work was supported by the US Office of Naval Research (ONR), and the National Science Foundation (NSF):
grant numbers 1407712, 1462245, 1524417, 1533983,
1722516 and by The Alan Turing Institute, under the EPSRC
grant EP/N510129/1.

References
Akaike, H. Information Theory and an Extension of the
Maximum Likelihood Principle, pp. 199–213. Springer
New York, New York, NY, 1998. ISBN 978-1-4612-16940. doi: 10.1007/978-1-4612-1694-0_15.
Alaa, A. and van der Schaar, M. Limits of estimating heterogeneous treatment effects: Guidelines for practical
algorithm design. In Dy, J. and Krause, A. (eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine
Learning Research, pp. 129–138, 2018.
Alaa, A. and van der Schaar, M. Validating causal inference
models via influence functions. In Chaudhuri, K. and
Salakhutdinov, R. (eds.), Proceedings of the 36th International Conference on Machine Learning, volume 97 of
Proceedings of Machine Learning Research, pp. 191–201,
2019.
Alaa, A. M. and van der Schaar, M. Bayesian inference of
individualized treatment effects using multi-task gaussian
processes. In Advances in Neural Information Processing
Systems, pp. 3424–3432, 2017.
Alaa, A. M., Weisz, M., and Van Der Schaar, M. Deep
counterfactual networks with propensity-dropout. arXiv
preprint arXiv:1706.05966, 2017.
Almond, D., Chay, K. Y., and Lee, D. S. The costs of low
birth weight. The Quarterly Journal of Economics, 120
(3):1031–1083, 2005.
Armstrong, J., Rudkin, J. K., Allen, N., Crook, D. W.,
Wilson, D. J., Wyllie, D. H., and O’Connell, A. M.
Dynamic linkage of covid-19 test results between public
health england’s second generation surveillance system
and uk biobank. Microbial Genomics, 6(7):e000397,
2020. doi: https://doi.org/10.1099/mgen.0.000397. URL
https://www.microbiologyresearch.org/
content/journal/mgen/10.1099/mgen.0.
000397.
Bareinboim, E. and Pearl, J. Causal inference and the datafusion problem. Proceedings of the National Academy
of Sciences, 113(27):7345–7352, 2016. ISSN 0027-8424.
doi: 10.1073/pnas.1510507113.

Chipman, H. A., George, E. I., and McCulloch, R. E. Bart:
Bayesian additive regression trees. Annals of Applied
Statistics, 4(1):266–298, 2010.
Darwiche, A. Modeling and Reasoning with Bayesian Networks. Cambridge University Press, New York, NY, USA,
1st edition, 2009. ISBN 0521884381, 9780521884389.
Dorie, V., Hill, J., Shalit, U., Scott, M., Cervone, D., et al.
Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition.
Statistical Science, 34(1):43–68, 2019.
Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle,
H., Laviolette, F., Marchand, M., and Lempitsky, V.
Domain-adversarial training of neural networks. The
Journal of Machine Learning Research, 17(1):2096–2030,
2016.
Ghassami, A., Salehkaleybar, S., Kiyavash, N., and Zhang,
K. Learning causal structures using regression invariance.
In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H.,
Fergus, R., Vishwanathan, S., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 30, pp.
3011–3021. Curran Associates, Inc., 2017.
Glymour, C., Scheines, R., Spirtes, P., and Ramsey, J.
Tetrad, 2019a. URL http://www.phil.cmu.edu/
tetrad/index.html.
Glymour, C., Zhang, K., and Spirtes, P. Review of causal
discovery methods based on graphical models. Frontiers
in Genetics, 10:524, 2019b.
Glymour, C., Zhang, K., and Spirtes, P. Review of causal
discovery methods based on graphical models. Frontiers
in genetics, 10:524, 2019c.
Hill, J. L. Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics,
20(1):217–240, 2011.
Johansson, F., Shalit, U., and Sontag, D. Learning representations for counterfactual inference. In International
conference on machine learning, pp. 3020–3029, 2016.
Johansson, F. D., Kallus, N., Shalit, U., and Sontag, D.
Learning weighted representations for generalization
across designs. arXiv preprint arXiv:1802.08598, 2018.
Kyono, T. and van der Schaar, M. Improving model robustness using causal knowledge. CoRR, abs/1911.12441,
2019.
Long, M., CAO, Z., Wang, J., and Jordan, M. I. Conditional
adversarial domain adaptation. In Bengio, S., Wallach,
H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and
Garnett, R. (eds.), Advances in Neural Information Processing Systems 31, pp. 1640–1650. Curran Associates,
Inc., 2018.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

Magliacane, S., van Ommen, T., Claassen, T., Bongers, S.,
Versteeg, P., and Mooij, J. M. Domain adaptation by
using causal inference to predict invariant conditional
distributions. In Bengio, S., Wallach, H., Larochelle, H.,
Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.),
Advances in Neural Information Processing Systems 31,
pp. 10846–10856. Curran Associates, Inc., 2018.
Niedzwiedz, C. L., O’Donnell, C. A., Jani, B. D., Demou,
E., Ho, F. K., Celis-Morales, C., Nicholl, B. I., Mair,
F., Welsh, P., Sattar, N., Pell, J., and Katikireddi, S. V.
Ethnic and socioeconomic differences in sars-cov-2
infection: prospective cohort study using uk biobank.
medRxiv, 2020. doi: 10.1101/2020.04.22.20075663.
URL https://www.medrxiv.org/content/
early/2020/04/30/2020.04.22.20075663.
Pan, S. J. and Yang, Q. A survey on transfer learning.
IEEE Transactions on Knowledge and Data Engineering,
22(10):1345–1359, Oct 2010. ISSN 1041-4347. doi:
10.1109/TKDE.2009.191.
Pearl, J. Causality. Causality: Models, Reasoning, and
Inference. Cambridge University Press, 2009. ISBN
9780521895606.
Ramsey, J., Glymour, M., Sanchez-Romero, R., and Glymour, C. A million variables and more: the fast
greedy equivalence search algorithm for learning highdimensional graphical causal models, with an application to functional magnetic resonance images. International Journal of Data Science and Analytics, 3(2):
121–129, Mar 2017a. ISSN 2364-4168. doi: 10.1007/
s41060-016-0032-z.
Ramsey, J., Glymour, M., Sanchez-Romero, R., and Glymour, C. A million variables and more: the fast
greedy equivalence search algorithm for learning highdimensional graphical causal models, with an application to functional magnetic resonance images. International journal of data science and analytics, 3(2):121–
129, 2017b.
Richardson, T. Markov properties for acyclic directed mixed
graphs. Scandinavian Journal of Statistics, 30(1):145–
157, 2003.
Rojas-Carulla, M., Schölkopf, B., Turner, R., and Peters, J.
Invariant models for causal transfer learning. Journal of
Machine Learning Research, 19(36):1–34, 2018.

Rubin, D. B. Causal inference using potential outcomes:
Design, modeling, decisions. Journal of the American
Statistical Association, 100(469):322–331, 2005.
Schoelkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang,
K., and Mooij, J. On causal and anticausal learning.
Proceedings of the 29th International Conference on Machine Learning, ICML 2012, 2, 06 2012.
Schuler, A., Baiocchi, M., Tibshirani, R., and Shah, N.
A comparison of methods for model selection when estimating individual treatment effects. arXiv preprint
arXiv:1804.05146, 2018.
Schwarz, G. Estimating the dimension of a model. The
Annals of Statistics, 6(2):461–464, 1978. ISSN 00905364.
Shah, R. D., Peters, J., et al. The hardness of conditional
independence testing and the generalised covariance measure. Annals of Statistics, 48(3):1514–1538, 2020.
Shalit, U., Johansson, F. D., and Sontag, D. Estimating
individual treatment effect: generalization bounds and
algorithms. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70, pp. 3076–
3085. JMLR. org, 2017.
Shimodaira, H. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of statistical planning and inference, 90(2):227–244,
2000.
Shpitser, I. and Sherman, E. Identification of personalized
effects associated with causal pathways. Conference on
Uncertainty in Artificial Intelligence, 2018, 08 2018.
Spirtes, P., Glymour, C., N., S., and Richard. Causation,
Prediction, and Search. Mit Press: Cambridge, 2000.
Stuart, E. A., DuGoff, E., Abrams, M., Salkever, D., and
Steinwachs, D. Estimating causal effects in observational studies using electronic health data: challenges and
(some) solutions. Egems, 1(3), 2013.
Sugiyama, M., Krauledat, M., and Müller, K.-R. Covariate
shift adaptation by importance weighted cross validation.
J. Mach. Learn. Res., 8:985–1005, December 2007. ISSN
1532-4435.

Rosenbaum, P. R. and Rubin, D. B. The central role of
the propensity score in observational studies for causal
effects. Biometrika, 70(1):41–55, 1983.

Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T. Adversarial discriminative domain adaptation. In Proceedings
of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 7167–7176, 2017.

Ross, B. C. Mutual information between discrete and continuous data sets. PLOS ONE, 9(2):1–5, 02 2014. doi:
10.1371/journal.pone.0087357.

Van der Laan, M. J. and Robins, J. M. Unified methods
for censored longitudinal data and causality. Springer
Science & Business Media, 2003.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

Wager, S. and Athey, S. Estimation and inference of heterogeneous treatment effects using random forests. Journal
of the American Statistical Association, 113(523):1228–
1242, 2018.
Williamson, E., Walker, A. J., Bhaskaran, K. J., Bacon,
S., Bates, C., Morton, C. E., Curtis, H. J., Mehrkar, A.,
Evans, D., Inglesby, P., Cockburn, J., Mcdonald, H. I.,
MacKenna, B., Tomlinson, L., Douglas, I. J., Rentsch,
C. T., Mathur, R., Wong, A., Grieve, R., Harrison, D.,
Forbes, H., Schultze, A., Croker, R. T., Parry, J., Hester,
F., Harper, S., Perera, R., Evans, S., Smeeth, L., and
Goldacre, B. Factors associated with covid-19-related
death using opensafely. Nature, 584, 2020. doi: 10.1038/
s41586-020-2521-4.
Yao, L., Li, S., Li, Y., Huai, M., Gao, J., and Zhang, A. Representation learning for treatment effect estimation from
observational data. In Advances in Neural Information
Processing Systems, pp. 2633–2643, 2018.
Yoon, J., Jordon, J., and van der Schaar, M. Ganite: Estimation of individualized treatment effects using generative
adversarial nets. International Conference on Learning
Representations (ICLR), 2018.
You, K., Wang, X., Long, M., and Jordan, M. Towards
accurate model selection in deep unsupervised domain
adaptation. In Chaudhuri, K. and Salakhutdinov, R. (eds.),
Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pp. 7124–7133, Long Beach, California, USA, 09–15 Jun 2019. PMLR.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

A. Why use causal graphs for UDA?
To motivate our method, consider the following hypothetical
scenario. Suppose we have X1 , X2 , T , and Y representing
age, respiratory comorbidities, treatment, and COVID-19
mortality, respectively, and the causal graph has structure
X1 → X2 → Y ← T . Suppose that each node was a
simple linear function of its predecessor with i.i.d. additive
Gaussian noise terms. Now consider we have two countries
A and B, where A has already been hit by COVID-19 and
B is just seeing cases increase (therefore have no observed
outcomes yet). B would like to select a machine learning
model trained on the patient outcomes from A. However,
A and B differ in distributions of age X1 . Consider the
regression of Y on X1 , X2 and T , i.e., Y = c1 X1 + c2 X2 +
c3 T , by two models f1 and f2 that are fit on the source
domain and evaluated on the target domain. Suppose that
f1 and f2 have the same value for c2 and c3 , but differ in
c1 , where c1 = 0 for f1 and c1 6= 0 for f2 . We know that
Y is a function of only X1 and T . Thus in the shifted test
domain, f1 must have a lower testing error than f2 , since
the predictions of f2 use X1 (since c1 6= 0) and f1 does
not. Furthermore the predictions of f1 have the same causal
relationships and conditional independencies as Y , such as
f1 (X1 , X2 , T ) ⊥
⊥ X2 | X1 . This is not the case for f2 ,
where f2 (X1 , X2 , T ) ⊥
6 ⊥ X2 | X1 . Motivated by this, we
can use a metric of graphical fitness of the predictions of
fi to the underlying graphical structure to select models in
shifted domains when all we have are unlabeled samples.
As an added bonus, which we will highlight later, unlike
existing UDA selection methods our method can be used
without needing to share data between A and B, which can
help overcome patient privacy barriers that are ubiquitous
in the healthcare setting.

B. Proof of Theorem 1
In this section, we present a proof for Theorem 1.
Proof. In the source domain, by the Markov and faithfullness assumptions the conditional independencies in G are
the same in pµ (X, T, Y ), such that
IG (G) = I(pµ (X, T, Y )).

(15)

To estimate the potential outcomes Y (t), we apply the dooperator to obtain the interventional DAG GT and interventional distribution pµ (X, Y | do(T = t)), such that:
IG (GT ) = I(pµ (X, Y | do(T = t))).

(16)

Since we assume Y = f (X, T ) we obtain:
IG (GT ) = I(pµ (X, f (X, t) | do(T = t))).

(17)

By Assumption 2, we know that the conditional independence relationships in the interventional distribution are the
same in any environment, so that
I(pµ (X, f (X, t) |do(T = t))) =

I(pπ (X, f (X, t) | do(T = t))), (18)

such that we obtain:
IG (GT ) = I(pπ (X, f (X, t) | do(T = t))).

(19)

C. ICMS Additional Details
To clarify our methodology further we have provided pseudocode in Algorithms 1 and 2. Algorithm 1 calculates the
ICMS score (from Eq. 9) from a given model. The values for
cr and vr are min-max normalized between 0 and 1 across
all models. Algorithm 2 returns a ranked list of models by
ICMS score from a set of ITE models F. It takes optional
prior knowledge in the form of a causal graph or known
connections.
In Figure 5, we provide a graphical illustration for calculating N CI.
Algorithm 1 Calculate ICMS
Input: ITE model f ; source validation dataset Dv ; unNtgt
labeled target test set Dtgt = {xtgt
i }i=1 ; interventional
DAG GT ; scale factor λ.
Output: ICMS score: r(f, Dv , Dtgt , GT )
Function: ICMS(f, Dv , Dtgt , GT , λ):
tgt
ŷitgt (t) ← f (xtgt
∈ Dtgt
i , t), for xi
Ntgt
tgt
tgt
tgt
D̂tgt ← {(xtgt
,
0,
ŷ
(0)),
(x
i
i
i , 1, ŷi (1))}i=1
cr ← Measure of D̂tgt to DAG GT fitness.
vr ← Validation risk of f on Dv and Dtgt .
return cr + λvr (from Eq. 9).

Algorithm 2 ICMS Selection
src src Nsrc
Input: Source dataset Dsrc = {(xsrc
i , ti , yi )}i=1
split into a training set Dtr and validation set Dv ; set
of ITE models F trained Dtr ; unlabeled test set Dtgt ;
optional prior knowledge in the form of a DAG Gπ , scale
factor λ.
Output: A list F 0 of models in F ranked by ICMS score.
Function: ICMS_sel(F, Dtr , Dv , Dtgt , λ, Gπ = ∅):
Gd ← causal discovery on Dtr
G ← assumed invariant DAG from Gπ or Gd
GT ← interventional DAG of G (remove edges into T )
F 0 ← Sort F by ICMS(f, Dv , Dtgt , GT , λ) ascending
return F 0 .

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Intervene
on T

Figure 5. Schematic demonstrating calculation of N CI.

D. Causal discovery algorithm details

E. Hyperparameters for ITE models

In this section we discuss our causal discovery algorithms
used. For real data, where we did not know all of the connections between variables, we discovered the remaining causal
connections from the data using the Fast Greedy Equivalence Search (FGES) algorithm by (Ramsey et al., 2017a)
on the entire dataset using the Tetrad software package
(Glymour et al., 2019a). FGES assumes that all variables be
observed and there is a linear Gaussian relationship between
each node and its parent. Tetrad allows prior knowledge
to be specified in terms of required edges that must exist, forbidden edges that will never exist, and temporal restrictions
(variables that must precede other variables). Using our
prior knowledge, we used the FGES algorithm in Tetrad
to discover the causal DAGs for each of the public datasets.
Only the directed edges that were output in the CPDAG
by FGES were considered as known edges in the causal
graphs. The Tetrad software package automatically handles continuous, discrete, and mixed connections, i.e., edges
between discrete and continuous variables. If not using
Tetrad for mixed variables, the method from (Ross, 2014)
can be used.

E.1. GANITE
We used the publicly available implementation of GANITE2 ,
with the hyperparameters set as indicated in Table 2:
E.2. CFR and TAR
For the implementation of CFR and TAR (Johansson et al.,
2018), we used the publicly available code3 , with hyperameters set as described in Table 3. Note that for CFR we
used Wasserstein regulatization, while for TAR the penalty
imbalance parameter is set to 0.
E.3. SITE
For the implementation of SITE (Yao et al., 2018), we used
the publicly available code4 , with hyperameters set as described in Table 4.
E.4. CMGP and NSGP
CMGP (Alaa et al., 2017) and NSGP (Alaa & van der
Schaar, 2018) are ITE methods based on Gaussian Process
models for which we used the publicly available implementation5 . Note that for these ITE methods, the hyperparameters associated with the Gaussian Process are internally
optimized.
2

https://bitbucket.org/
mvdschaar/mlforhealthlabpub/src/
70a6f6130f90b7b2693505bb2f9ff78444541983/
alg/ganite/
3
https://github.com/clinicalml/cfrnet
4
https://github.com/Osier-Yi/SITE
5
https://bitbucket.org/
mvdschaar/mlforhealthlabpub/src/
70a6f6130f90b7b2693505bb2f9ff78444541983/
alg/causal_multitask_gaussian_processes_
ite/

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Hyperparameter

Value

Optimization
Batch size
α
Number of iterations
Number of units per hidden layer
Number of hidden layers

Adam Moment Optimization
128
1
5000
s
2

Table 2. Hyperparameters used for GANITE. s represents the number of input features.
Hyperparameter

Value

Optimization
Batch size
Num. of representation layers
Num. of hypothesis layers
Dim. of representation layers
Dim. of hypothesis layers

Adam Moment Optimization
100
3
3
200
100

Table 3. Hyperparameters used for CFR and TAR.
Hyperparameter

Value

Optimization
Batch size
Num. of representation layers
Num. of hypothesis layers
Dim. of representation layers
Dim. of hypothesis layers
λ

Adam Moment Optimization
100
3
3
200
100
10−4

Table 4. Hyperparameters used for SITE.

F. Lambda

λ=

|E(G)|
,
|E(Gπ ) ∪ E(Gd )|

(20)

where E(G) represents the set of edges of G and |E(G)| is
the cardinality or number of edges in G. Intuitively, as the
number of edges in our truthful dag G decreases relative to
our prior knowledge and what is discoverable from data, the
less belief we have in our truth causal DAG. In the event that
all causal edges are known ahead of time and is discoverable
from data appropriately, then λ = 1.

0.200
0.175

PEHE-10

We base our choice of λ to be proportional to our belief in
our causal DAG that we use for UDA selection. If we are
given prior knowledge in the form of a causal graph Gπ . Gπ
is optional and can be an empty graph as well. In either case
we can use causal discovery on our observational dataset to
discover a DAG Gd . Determining the edges that are truthful
(and therefore invariant), in practice comes down to using
human/expert knowledge to select the DAG that is most
copacetic with existing beliefs of the natural world (Pearl,
2009). We refer to the selected truthful DAG as G, and we
define λ as follows:

0.150
0.125
0.100
0.075

DEV(IF)
IWCV(DEV(IF))

0.050
0.0

0.2

0.4

0.6

0.8

1.0

Figure 6. λ sensitivity analysis.
 Lambda sensitivity. We analyze the sensitivity of our
method to the parameter λ in Eq. 9. We used the same experimental set-up used for the synthetic experiments. Figure 6
shows the sensitivity of our method to λ for GANITE using
DEV and IF for calculating the validation risk vr .

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

G. Synthetic data generation
Here we describe our synthetic data generation process
(DGP). Algorithm 3 generates observational data according
to a given invariant DAG G. Algorithm 4 generates interventional or treatment data according to a given invariant
DAG G, where the treatment node is binarized and forced
to have the value of 0 for half of the samples and 1 for the
remainder.
Algorithm 3 Generate Observational Data
Input: A Graphical structure G, a mean µ, standard
deviation σ, edge weights w and a dataset size n.
Output: An observation dataset according to G with n
samples.
Function: gen_obs_data(G, µ, σ, w, n):
e ← edges of G
Gsorted ← topological_sort(G)
ret ← empty list
for node ∈ G do
Append to ret[node] a list of Gaussian (µ and σ) randomly sampled list of size n
end for
for node ∈ Gsorted do
for par ∈ {parents(node)} do
ret[node] += ret[par] ∗ w(par, node), where
w(par, node) is the edge weight from par to node.
end for
end for
Apply sigmoid function to the treatment node and binarize.
return ret.

G.1. Additional metrics for synthetic experiments
We use an inversion count over the entire list of models, and
provides a measure of list “sortedness”. If we normalize
this between the maximum number of inversions n(n −
1)/2, where n is the number of models in the list, then a
completely sorted list in ascending order will have a value
of 0. Similarly, a monotonically descending ordered list will
have a value of 1. We provide additional synthetic results in
terms of inversion count in Table 5.

Algorithm 4 Generate Treatment Data with perturbation
Input: A Graphical structure G, a mean µ, standard deviation σ, edge weights w, a dataset size n, a list of perturbation nodes p, a perturbation mean µp and a perturbation
standard deviation σp .
Output: An treatment dataset according to G with n
samples and perturbation applied at nodes p.
Function: gen_treat_data(G, µ, σ, w, n, µp , σp ):
e ← edges of G
Gsorted ← topological_sort(G)
ret ← empty list
for node ∈ G do
if node ∈ p then
Append to ret[node] a list of Gaussian (µp and σp )
randomly sampled list of size n.
else
Append to ret[node] a list of Gaussian (µ and σ)
randomly sampled list of size n.
end if
end for
for node ∈ Gsorted do
for par ∈ {parents(node)} do
if node ∈
/ treatment or response node then
ret[node] += ret[par] ∗ w(par, node), where
w(par, node) is the edge weight from par to
node.
end if
end for
end for
Binarize ret[treat] into 50% with 0 value and the rest
with 1 value.
ret[response] ← incoming edges in G multiplied by
edge weights w.
return ret.

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Table 5. Inversion count using ICMS on top of existing UDA methods. ICMS() means that the  was used as the validation risk vr in
the ICMS. For example, ICMS(DEV(?)) represents DEV(?) selection used as the validation risk vr in the ICMS. The ? indicates the
method used to approximate the validation error on the source dataset. Our method (in bold) improves over each selection method over all
models and source risk scores (Src.).
S ELECTION M ETHOD

CFR

TAR

SITE

CMGP

MSE
ICMS(MSE)
IWCV(MSE)
ICMS(IWCV(MSE))
DEV(MSE)
ICMS(DEV(MSE))

0.395
0.372
0.348
0.352
0.398
0.374

GANITE
(0.071)
(0.069)
(0.056)
(0.063)
(0.076)
(0.062)

0.363 (0.042)
0.212 (0.036)
0.393 (0.064)
0.220 (0.051)
0.414 (0.062)
0.210 (0.049)

0.391 (0.050)
0.264 (0.034)
0.364 (0.052)
0.256 (0.039)
0.427 (0.049)
0.269 (0.035)

0.157 (0.035)
0.126 (0.027)
0.185 (0.033)
0.149 (0.033)
0.198 (0.038)
0.120 (0.040)

0.131 (0.046)
0.120 (0.050)
0.191 (0.081)
0.183 (0.075)
0.239 (0.078)
0.160 (0.067)

0.282
0.210
0.209
0.172
0.163
0.160

NSGP

IPTW
ICMS(IPTW)
IWCV(IPTW)
ICMS(IWCV(IPTW))
DEV(IPTW)
ICMS(DEV(IPTW))

0.395 (0.071)
0.373 (0.069)
0.269 (0.075)
0.073 (0.028)
0.302 (0.072)
0.087 (0.035)

0.355 (0.046)
0.217 (0.039)
0.518 (0.059)
0.121 (0.034)
0.472 (0.056)
0.194 (0.052)

0.391 (0.050)
0.272 (0.032)
0.433 (0.058)
0.119 (0.035)
0.414 (0.049)
0.120 (0.027)

0.157 (0.035)
0.128 (0.031)
0.416 (0.053)
0.207 (0.039)
0.400 (0.057)
0.220 (0.031)

0.182 (0.046)
0.140 (0.050)
0.417 (0.063)
0.304 (0.079)
0.441 (0.071)
0.282 (0.041)

0.292 (0.075)
0.207 (0.067)
0.475 (0.083)
0.328 (0.078)
0.493 (0.086)
0.355 (0.077)

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

0.222 (0.041)
0.127 (0.039)
0.18 (0.059)
0.058 (0.018)
0.193 (0.058)
0.069 (0.026)

0.255 (0.050)
0.166 (0.042)
0.364 (0.051)
0.104 (0.025)
0.415 (0.075)
0.191 (0.048)

0.250 (0.046)
0.190 (0.044)
0.286 (0.061)
0.108 (0.033)
0.292 (0.056)
0.107 (0.029)

0.321 (0.059)
0.215 (0.076)
0.293 (0.043)
0.173 (0.028)
0.214 (0.038)
0.147 (0.025)

0.392 (0.091)
0.212 (0.073)
0.415 (0.058)
0.292 (0.082)
0.490 (0.063)
0.229 (0.074)

0.376 (0.097)
0.250 (0.084)
0.437 (0.087)
0.331 (0.077)
0.544 (0.093)
0.364 (0.076)

(0.069)
(0.067)
(0.060)
(0.063)
(0.068)
(0.062)

H. Practical considerations
0.20

Computational complexity. The computational complexity of ICMS as shown in Algorithm 1 and 2 scales linear
with the number of models in F. Specifically, the computational complexity is O(Nf × Q(G, D)), where Nf is
the number of candidate models in F and Q(G, D) is the
computational complexity of calculating the fitness score
of dataset D to G. In our case, we use the log-likelihood
score, which requires calculating the conditional entropy
between each parent node and child. In the worst case, this
has a computational complexity of O(VG2 ), where VG is the
number of vertices (or variables) in G since a DAG with VG
vertices will have an asymptotic number of edges VG (V2G −1) .

PEHE-10

Here we provide a discussion on some practical considerations.


Utilization of subgraphs. In practice, we will likely not
know the true underlying causal graph completely. Due to
experimental, economical or ethical limitations, we often
can not determine the orientation of all edges completely.
Additionally, the process of causal discovery is not perfect
and likely will result in unoriented, missing, or spurious
edges that result from noisiness and biases in the observational dataset used. In Figure 7, we plot the performance
of our ICMS method when selecting GANITE models as
we increase the percentage of known edges into the outcome node in the causal subgraph used. We indeed prefer
subgraphs that contain information about the parents of the


0.15
0.10

ICMD(DEV(IF))
DEV(IF)
20
40

60

80

100

Percentage of known edges into outcome

Figure 7. Performance gain in terms of known edges into the outcome node.

outcome node. We conclude that it is perfectly admissible
to use our methodology with a subgraph as input with the
understanding that as edges are missing, performance degrades. However, the performance is still better than without
using our ICMS score.
Analysis of causal graph correctness. We investigate
our method’s sensitivity to incorrect causal knowledge.
Here, we maliciously reverse or add spurious edges to our
causal DAG when calculating ICMS. We used our same
synthetic experimental setup, except we mutilate our oracle DAGs to form incorrect DAGs. We set λ to 1 since
we assume the graph is truth (even though it is incorrect).
We use GANITE with DEV and IF as our validation risk
metric and show our results in Fig. 8, which shows the
∆PEHE-10 error, i.e., the difference in PEHE-10 error of


PEHE-10 Error
(PEHE-10 GT - PEHE-10 GT)

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

observational dataset with no genetic information about each
patient. At inference time assuming that we know which
genetic group a patient belongs to (and corresponding causal
graph), we hypothesize that we can select the models that
will administer the more appropriate treatment for each
genetic population using our proposed ICMS score.

DEV(IF)
IWCV(DEV(IF)) GT (oracle)
IWCV(DEV(IF)) GT

0.30
0.25
0.20
0.15
0.10

Tree-based methods. Here we provide a brief experiment showing that ICMS improves over non-deep neural
network approaches of Bayesian additive regression tree
(BART) (Chipman et al., 2010) and Causal Forest (Wager &
Athey, 2018) as well. Replicating our synthetic experiments,
we evaluated BART and Causal Forest using ICMS with
DEV, IWCV, and IF for a validation risk. In Table 6, we see
that even for tree-based methods our ICMS metric is still
able to select models that generalize best to the test domain.


0.05
0.00
0%
(Identical)

20%

40%

60%

80%

100%

Percentage difference between GT and GT
Figure 8. Performance of ICMS on incorrect graphs using
IWCV(DEV(IF)). ∆PEHE-10 error is the difference of the PEHE10 error of GT and GT using ICMS versus the percentage of
graphical distance (in terms of total edges). GT is the oracle
causal graph and is held static across the x-axis.

the erroneous DAG GT and the oracle DAG GT , versus the
percentage graph difference (between GT and GT ). The
graphical difference is calculated in terms of the percentage
of edges that are mutated or removed. Fig. 8 shows the
correlation between the correctness of the causal graph and
the relative model selection improvement. This correlation
testifies to the validity of ICMS, where a counterexample
of our method would be incorrect DAGs leading to ICMS
selecting better models (which is not the case).
Noisiness of fitness score or graphs. We would like
to point out that there is noisiness in the fitness score that
we use. The likelihood requires estimating the conditional
entropy between each variable given their parents. This step
is not perfect and there are many permutations of graphical
structures that could have scores that are very close. We
hypothesize that improving our fitness scores will likely
improve the efficacy of our approach in general.


Table 6. Additional PEHE-10 (with standard error) results for
BART and Causal Forest using DEV and IF as validation risk.

S EL . M ETHOD
IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))
 Application:

BART

C SL F OREST

0.205 (0.032)
0.098(0.030)
0.297 (0.039)
0.094(0.031)
0.214 (0.036)
0.082(0.023)

0.253 (0.036)
0.175(0.038)
0.288 (0.036)
0.189(0.029)
0.308 (0.038)
0.194(0.029)

towards personalized model selection. In
some instances, various target domains may be represented
by different underlying causal graphs (Shpitser & Sherman,
2018). Consider the following clinical scenario. Suppose
that we have two target genetic populations A and B that
each have their own unique causal graph. We have a large

Table 7. Additional PEHE-10 (with standard error) results for
Rojas-Carulla et al. (2018) (R.C. (2018)) and Magliacane et al.
(2018) (Mag. (2018)) performance (with standard error) using
DEV and IF as validation risk.

S EL . M ETHOD
IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

R.C. (2018)

M AG . (2018)

0.312 (0.033)
0.192(0.021)
0.240 (0.029)
0.136(0.036)
0.257 (0.025)
0.110(0.024)

0.381 (0.022)
0.258(0.030)
0.292 (0.041)
0.183(0.037)
0.212 (0.035)
0.127(0.044)

 Model selection on causally invariant features. Here
we provide a brief experiment showing that ICMS can be
used as a selection method for the causal feature selection
algorithms of Rojas-Carulla et al. (2018); Magliacane et al.
(2018). It is important to note that model selection is still
important for models that are trained on an invariant set of
causal features. These models can still converge to different
local minima and have disparate performances on the target
domain. Replicating our synthetic experiments, we used
Rojas-Carulla et al. (2018) and Magliacane et al. (2018) to
select causally invariant features, which we use for training
and testing our model. We then selected models using ICMS
and compared against our standard benchmarks using GANITE. In Table 7, we see that even for these feature selection
methods our ICMS metric is still able to select models that
generalize best to the test domain (in comparison to DEV,
IWCV, and IF).

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

I. Experimental set-up for semi-synthetic
datasets and additional results.
In this section, we highlight additional experiments performed on real datasets with semi-synthetic outcomes. Since
real-world data rarely contains information about the ground
truth causal effects, existing literature uses semi-synthetic
datasets, where either the treatment or the outcome are simulated (Shalit et al., 2017). Thus, we evaluate our model
selection method on a prostate cancer dataset and the IHDP
dataset where the outcomes are simulated and on the Twins
dataset (Almond et al., 2005) where the treatments are simulated. Furthermore, we provide UDA selection results on
the prostate cancer dataset for factual outcomes as well.
IHDP dataset. The dataset was created by (Hill, 2011)
from the Infant Health and Development Program (IHDP)6
and contains information about the effects of specialist home
visits on future cognitive scores. The dataset contains 747
samples (139 treated and 608 control) and 25 covariates
about the children and their mothers. We use a set-up similar
Weight
Smoking
Gestation
to the one in (Dorie
et al., 2019)
to simulate gain
the outcome,
while at the same time building the causal graph G.


Since we do not have access to any real outcomes for this
1-year
Treatment
dataset,
we build the DAG inmortality
Figure 9, such that a subset of
the features affect the simulated outcome. Let x represent
the patient covariates and let v be the covariates affecting the
outcome in theDrinking
DAG represented
in Figure 9.Mother
We build the
Anemia
outcome for the treated patients f (x, 1) and for age
the untreated
patients f (x, 0) as follows: f (x, 0) = exp(β(v + 21 )) + 
and f (x, 1) = βv+η where β consists of random regression
coefficients uniformly sampled from [0.1, 0.2, 0.3, 0.4] and
 ∼ N (0, 1), η ∼ N (0, 1) are noise terms.
Head
circumference

Treatment

Weeks
pre-term

Neonatal
health

Outcome

Body weight

Figure 9. Interventional DAG for computing ICMS score on IHDP
dataset.

To create a target dataset with covariate shifts for the IHDP,
we hold out the samples where the continuous variables
neonatal health, head circumference and mom age have
extreme values (either in the top 20% or the lowest 20%).
We again ran 20 experiments and for each experiment we
trained 30 candidate models for each model architecture.
We use IF validation to approximate the source risk and we
report the PEHE-10 test error. Table 8 illustrates the results
6

The dataset can be found as part of the Supplementary
Files at https://www.tandfonline.com/doi/suppl/
10.1198/jcgs.2010.08162?scroll=top

on the IHDP dataset.
TWINS dataset. The TWINS dataset contains information about twin births in the US between 1989-1991 (Almond et al., 2005) 7 . The treatment t = 1 is defined as being
the heavier twin and the outcome corresponds to the 1-year
mortality. Since the dataset contains information about both
twins we can consider their outcomes as being the potential
outcomes for the treatment of being heavier at birth. The
dataset consists of 11,400 pairs of twins and for each pair we
have information about 30 variables related to their parents,
pregnancy and birth.



We use the same set-up as in (Yoon et al., 2018) to create
an observational study by selectively observing one of the
twins based on their features (therefore inducing selection
bias) as follows: t | x ∼ Bernoulli(sigmoid(wT x + n))
where w ∼ U((−0.1, 0.1)30×1 ) and n ∼ N (0, 0.1).
Since we have access to the twins outcomes, we perform
causal discovery to find causal relationships between the
context features and the outcome. However, due to the fact
that we do not have prior knowledge of the relationships
between all 30 variables, we restrict the causal graph used to
compute the causal risk to only contain a subset of variables,
as illustrated in Figure 10.
Table 8 illustrates the results for the Twins dataset. Note
that in this case, we use real outcomes and we also show
the applicability of our method when only a subgraph of the
true causal graph is known.
Smoking

Gestation

Weight
gain

1-year
mortality

Treatment

Drinking

Anemia

Mother
age

Figure 10. Interventional DAG for computing ICMS score on
Twins dataset. The DAG contains a subset of the features available
in the dataset for which we discovered causal relationships with
the outcome indicated by the probability of 1-year mortality of the
twin.
 Prostate cancer datasets.

In this case, we are a interested
in deploying a machine learning model for prostate cancer
but have access to only labeled data in the UK Biobank
dataset, which has approximately 10,000 patients. We would
like to deploy our models in the United States, where we
7
Data
for
TWINS
dataset
can
be
found
at
https://data.nber.org/data/
linked-birth-infant-death-data-vital-statistics-data.
html

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Table 8. Results on IHDP, prostate cancer, and TWINS datasets. IF validation is used to compute the source risk. We report the PEHE-10
test error (with standard error) of various selections methods on ITE models. Our method (in bold) improves in terms of PEHE-10 over all
methods and ITE models.

DATASET

M ETHOD

GANITE

CFR

TAR

SITE

CMGP

NSGP

IHDP

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV
ICMS(DEV(IF))

0.186 (0.040)
0.105 (0.031)
0.134 (0.059)
0.106 (0.023)
0.174 (0.050)
0.095 (0.025)

0.448 (0.052)
0.386 (0.045)
0.493 (0.055)
0.447 (0.036)
0.462 (0.036)
0.438 (0.036)

0.444 (0.066)
0.246 (0.045)
0.412 (0.057)
0.360 (0.047)
0.403 (0.046)
0.427 (0.065)

0.430 (0.050)
0.342 (0.051)
0.491 (0.057)
0.488 (0.073)
0.458 (0.043)
0.405 (0.049)

0.461 (0.038)
0.380 (0.053)
0.519 (0.072)
0.372 (0.095)
0.550 (0.174)
0.475 (0.199)

0.473 (0.066)
0.462 (0.053)
0.647 (0.090)
0.576 (0.019)
0.654 (0.097)
0.583 (0.026)

PC(UK)→
SEER(US)

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

0.298
0.092
0.125
0.018
0.239
0.036

(0.053)
(0.057)
(0.058)
(0.011)
(0.068)
(0.013)

0.377 (0.054)
0.143 (0.026)
0.340 (0.060)
0.146 (0.054)
0.308 (0.037)
0.120 (0.038)

0.419 (0.054)
0.148 (0.054)
0.366 (0.035)
0.218 (0.051)
0.361 (0.064)
0.168 (0.057)

0.194 (0.048)
0.161 (0.039)
0.398 (0.073)
0.331 (0.055)
0.348 (0.078)
0.318 (0.062)

0.771 (0.042)
0.538 (0.028)
0.238 (0.051)
0.161 (0.038)
0.253 (0.065)
0.203 (0.032)

0.679 (0.061)
0.505 (0.051)
0.481 (0.032)
0.329 (0.049)
0.480 (0.041)
0.254 (0.057)

TWINS→
TWINS( SEMI )

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

0.286
0.193
0.495
0.288
0.435
0.277

(0.027)
(0.022)
(0.054)
(0.059)
(0.059)
(0.054)

0.527 (0.054)
0.370 (0.065)
0.538 (0.051)
0.497 (0.074)
0.584 (0.084)
0.512 (0.086)

0.464 (0.067)
0.309 (0.040)
0.574 (0.066)
0.508 (0.048)
0.518 (0.101)
0.475 (0.040)

0.468 (0.102)
0.299 (0.097)
0.611 (0.075)
0.500 (0.077)
0.484 (0.115)
0.447 (0.074)

0.223 (0.082)
0.152 (0.039)
0.438 (0.069)
0.218 (0.055)
0.351 (0.074)
0.227 (0.043)

0.488 (0.087)
0.164 (0.029)
0.444 (0.077)
0.375 (0.099)
0.480 (0.089)
0.411 (0.104)

Table 9. Results on predicting the outcome of prostate cancer given a treatment from models trained on the Prostate Cancer UK (PCUK)
dataset and tested on the SEER dataset (United States). IF validation is used to compute the source risk. Here we show the factual error
(of the top 10% of selected models) in terms of MSE of various selections methods on ITE models. Our method (in bold) improves in
terms of test error over all methods and ITE models. The standard error is shown in parentheses.

DATASET

M ETHOD

PC(UK)→ PC(US)
( REAL OUTCOMES )

IF
ICMS(IF)
IWCV(IF)
ICMS(IWCV(IF))
DEV(IF)
ICMS(DEV(IF))

GANITE
0.256
0.108
0.280
0.230
0.231
0.123

(0.061)
(0.015)
(0.081)
(0.014)
(0.160)
(0.017)

CFR

TAR

SITE

CMGP

NSGP

0.183 (0.078)
0.127 (0.052)
0.714 (0.061)
0.361 (0.035)
0.361 (0.129)
0.313 (0.047)

0.319 (0.078)
0.311 (0.031)
0.595 (0.043)
0.518 (0.049)
0.448 (0.162)
0.396 (0.052)

0.321 (0.013)
0.243 (0.080)
0.345 (0.051)
0.287 (0.037)
0.471 (0.172)
0.326 (0.029)

0.305 (0.074)
0.258 (0.078)
0.297 (0.032)
0.282 (0.042)
0.379 (0.112)
0.332 (0.032)

0.360 (0.082)
0.294 (0.053)
0.554 (0.057)
0.493 (0.019)
0.465 (0.163)
0.412 (0.041)

have access to many samples of patient features, but no
labeled outcome. For this target domain, we use the SEER
dataset, which has over 100,000 samples. Our objective is
to predict the patient mortality, given the patient features
and treatment provided.
Comorbid.

Gleason1

Grade

Gleason 2

Stage

Treatment

Age

Cancer
Mortality

PSA

Figure 11. Interventional DAG for Prostate dataset.

To be able to evaluate the methods on predicting counterfactual outcomes on the target domain (and thus compute
the PEHE), we create a semi-synthetic dataset where the

outcomes are simulated according to the discovered causal
graph. Thus, we build the semi-synthetic outcomes for the
prostate cancer dataset similarly to the IHDP dataset. Let x
represent the patient covariates and let v be the covariates
affecting the outcome. We build the outcome for the treated
patients f (x, 1) and for the untreated patients f (x, 0) as follows: f (x, 0) = exp(β(v + 12 )) +  and f (x, 1) = βv + η
where β consists of random regression coefficients uniformly sampled from [0.1, 0.2, 0.3, 0.4] and  ∼ N (0, 0.1),
η ∼ N (0, 0.1) are noise terms.
For the prostate cancer datasets, we also perform an experiment where we do not use semi-synthetic data (to generate
the counterfactual outcomes), but use only the factual outcomes of the SEER dataset to evaluate our method. We
train 30 models with identical hyperparameters as done in

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge

our synthetic and semi-synthetic experiments. We repeat
this for all of our ITE methods. Table 9 shows that ICMS
improves over all methods and ITE models.
Computational settings. All experiments were performed on an Ubuntu 18.04 system with 12 CPUs and 64
GB of RAM.


J. COVID-19 Experimental Details
J.1. Dataset
We obtained de-identified COVID-19 Hospitalization in
England Surveillance System (CHESS) data from Public
Health England (PHE) for the period from 8th February
(data collection start) to 14th April 2020, which contains
7,714 hospital admissions, including 3,092 ICU admissions
from 94 NHS trusts across England. The data set features
comprehensive information on patients’ general health condition, COVID-19 specific risk factors (e.g., comorbidities),
basic demographic information (age, sex, etc.), and tracks
the entire patient treatment journey: hospitalization time,
ICU admission, what treatment (e.g., ventilation) they received, and their outcome by April 20th, 2020 (609 deaths
and 384 discharges). We split the data set into a source
dataset containing 2,552 patients from urban areas (mostly
Greater London area) and a target dataset of the remaining
5,162 rural patients.

J.3. COVID-19 patient statistics across geographical
locations
Figure 12 shows the histogram of age distribution for urban
and rural patients. It is clear from the plot that the rural
population is older, and therefore at higher risk of COVID19. Table 10 presents statistics about the prevalence of
preexisting medical conditions, the treatments received, and
the final outcomes for patients in urban and rural areas. We
can see that the rural patients tend to have more preexisting
conditions such as chronic heart disease and hypertension.
The higher prevalence’s of comorbid conditions complicates
the treatment for this population.

J.2. About the CHESS data set
COVID-19 Hospitalizations in England Surveillance System (CHESS) is a surveillance scheme for monitoring hospitalized COVID-19 patients. The scheme has been created
in response to the rapidly evolving COVID-19 outbreak
and has been developed by Public Health England (PHE).
The scheme has been designed to monitor and estimate the
impact of COVID-19 on the population in a timely fashion, to identify those who are most at risk and evaluate the
effectiveness of countermeasures.
The CHESS data therefore captures information to fulfill
the following objectives:
1. To monitor and estimate the impact of COVID-19 infection on the population, including estimating the
proportion and rates of COVID-19 cases requiring hospitalisation and/or ICU/HDU admission
2. To describe the epidemiology of COVID-19 infection
associated with hospital/ICU admission in terms of age,
sex and underlying risk factors, and outcomes
3. To monitor pressures on acute health services
4. To inform transmission dynamic models to forecast
healthcare burden and severity estimates

Figure 12. Age distribution for urban and rural patients. The median age of rural patients is five years older than the urban ones.

J.4. Data simulation and additional results using ICMS
In the CHESS dataset, we only observe the factual patient
outcomes. However, to be able to evaluate the selected ITE
models on how well they estimate the treatment effects, we
need to have access to both the factual and counterfactual
outcomes. Thus, we have built a semi-synthetic version of
the dataset, with potential outcomes simulated according to
the causal graph discovered for the COVID-19 patients in
Figure 3.
Let x represent the patient covariates and let v be the covariates affecting the outcome in the DAG represented in
Figure 3. Let f (x, 1) be the outcome for the patients that
have received the ventilator (treatment) and let f (x, 0) be
the outcome for the patients that have not received the ventilator. The outcomes are simulated as follows: f (x, 0) =
βv + η and f (x, 1) = exp(βv) − 1 + , where β consists of random regression coefficients uniformly sampled

Selecting Treatment Effects Models for Domain Adaptation Using Causal Knowledge
Table 10. Comparison of key features of urban and rural COVID-19 patients in the data set.
Urban
Percentage Count
Sex at Birth
Chonic Respiratory
Obesity
Chronic Heart
Hypertension
Asthma
Diabetes
Chronic Renal
Noninvasive Ventilation
Invasive Ventilation
Death
Discharge

30
25
20
15
10
5
IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

DEV(IF) ICMS(DEV(IF))

20
15
10
5
0

IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

Improving model selection for CMGP

20
15
10
5

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

(d) SITE

DEV(IF) ICMS(DEV(IF))

20
15
10
5

IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

(e) CMGP

35
30
25
20
15
10
5
0

IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

DEV(IF) ICMS(DEV(IF))

(c) TAR

25

0

Improving model selection for TAR

DEV(IF) ICMS(DEV(IF))

Improving model selection for SITE

25

IF

25

(b) CFR

30

0

30

(a) GANITE
35

3388
310
225
444
798
326
589
175
342
879
1014
1164

Improving model selection for NSGP
Patients with improved outcomes

0

62%
6%
4%
8%
15%
6%
11%
3%
6%
16%
19%
21%

Patients with improved outcomes

Patients with improved outcomes

35

1446
81
121
80
285
92
197
45
160
456
402
276

Improving model selection for CFR

Patients with improved outcomes

Patients with improved outcomes

Patients with improved outcomes

Improving model selection for GANITE
40

65%
4%
5%
4%
13%
4%
9%
2%
7%
21%
18%
12%

Rural
Percentage Count

DEV(IF) ICMS(DEV(IF))

30
25
20
15
10
5
0

IF

ICMS(IF)

IWCV(IF) ICMS(IWCV(IF))

DEV(IF) ICMS(DEV(IF))

(f) NSGP

Figure 13. Performance of model selection methods in terms on additional number of patients with improved outcomes compared to
selecting models based on the factual error on the source domain for all ITE models.

from [0.1, 0.2, 0.3, 0.4] and  ∼ N (0, 0.1), η ∼ N (0, 0.1)
are noise terms. We consider that the patient survives if
f (x, t) > 0, where t ∈ {0, 1} indicates the treatment received.
Our training observational dataset consists of the patient features x, ventilator assignment (treatment) t for the COVID19 patients in the urban area and the synthetic outcome
generated using f (x, t). For evaluation, we use the set-up
described in Section 5.2 for assigning ventilators to patients
in the rural area based on their estimated treatment effects.
In Figure 13, we indicate the additional number of patients
with improved outcomes by using ICMS on top of existing
UDA methods when selecting ITE models with different
settings of the hyperparameters.

