Dual-Attention Residual Network for Automatic
Diagnosis of COVID-19
Jun Shi1 , Huite Yi1 , Xiaoyu Hao1 , Hong An1 , and Wei Wei2

arXiv:2105.06779v1 [eess.IV] 14 May 2021

1

2

University of Science and Technology of China
Department of Radiology, The First Affiliated Hospital, Division of Life Sciences
and Medicine, University of Science and Technology of China

Abstract. The ongoing global pandemic of Coronavirus Disease 2019
(COVID-19) has posed a serious threat to public health and the economy. Rapid and accurate diagnosis of COVID-19 is crucial to prevent the
further spread of the disease and reduce its mortality. Chest computed
tomography (CT) is an effective tool for the early diagnosis of lung diseases including pneumonia. However, detecting COVID-19 from CT is
demanding and prone to human errors as some early-stage patients may
have negative findings on images. In this study, we propose a novel residual network to automatically identify COVID-19 from other common
pneumonia and normal people using CT images. Specifically, we employ
the modified 3D ResNet18 as the backbone network, which is equipped
with both channel-wise attention (CA) and depth-wise attention (DA)
modules to further improve the diagnostic performance. Experimental
results on the large open-source dataset show that our method can differentiate COVID-19 from the other two classes with 94.7% accuracy,
93.73% sensitivity, 98.28% specificity, 95.26% F1-score, and an area under the receiver operating characteristic curve (AUC) of 0.99, outperforming baseline methods. These results demonstrate that the proposed
method could potentially assist the clinicians in performing a quick diagnosis to fight COVID-19.
Keywords: COVID-19 · Automatic Diagnosis · Residual Network.

1

Introduction

The Coronavirus Disease 2019 (COVID-19), caused by the severe acute respiratory symptom coronavirus 2 (SARS-CoV-2), is spreading rapidly across the
world through extensive person-to-person transmission [4]. The World Health
Organization (WHO) officially declared the COVID-19 a pandemic on 11 March
2020. As of 20 February 2021, the COVID-19 has infected more than 110 million
people in more than 192 countries and territories and caused more than 2.45
million deaths [5]. Due to the persistent lack of clinically proven antiviral drugs
and vaccines available for treatment, the COVID-19 pandemic has had a devastating impact on public health and the economy. It is of great importance to
conduct early diagnosis of COVID-19, for preventing the further spread of the
disease and delivering proper treatment regimen.

2

Jun Shi et al.

The real-time reverse transcription-polymerase chain reaction (RT-PCR) test
is the golden standard for the diagnosis of COVID-19 infection [28]. However,
the high false-negative rate [4] of RT-PCR may delay the diagnosis of potential
cases. Moreover, RT-PCR testing is often time-consuming, and the clinicians
suffer from the risk of infection. These factors underline the urgent need for
alternative methods for rapid and accurate diagnosis of COVID-19.
Chest X-ray and computed tomography (CT) are two valuable tools for the
early diagnosis of patients suspected of SARS-CoV-2 infection [13]. Compared
with X-ray images, chest CT scans have higher sensitivity in diagnosing COVID19 infection, and can provide more detailed information about the lesion, which
is helpful for quantitative analysis [1]. Early investigations have observed typical radiographic features on chest CT images such as ground-glass opacities
(GGO), multifocal patchy consolidation, and vascular dilation in the lesions
[21,19,18,2]. However, detecting COVID-19 from CT images is demanding and
prone to human errors as some early-stage patients may have normal imaging
features. Besides, the similar imaging findings between COVID-19 and other
common pneumonia on the image make it difficult to differentiate.
Therefore, we propose a dual-attention residual network to automatically
diagnose COVID-19 from other common pneumonia and normal people using
CT images. In our method, the 3D variant of ResNet18 [8] is used as the backbone network, which takes a full 3D chest CT image as input. To improve the
diagnostic performance, we employ two attention mechanisms: 1) channel-wise
attention and 2) depth-wise attention, to refine the hidden features. The former
is first proposed in [11], and we implement its 3D extension. In this study, we develop the latter, which can adaptively assign depth-level weights to each feature
map during the training. We evaluate our method on the largest open-source
CT image dataset, to the best of our knowledge. The experimental results show
that the proposed method outperforms the baseline method and some existing
methods. We further provide ablation studies and prove the effectiveness of the
proposed depth-wise attention module in improving the classification accuracy
and the interpretability of the model.
As a summary, we propose a dual-attention convolutional neural network
(CNN) that may meet the urgent need for the automatic diagnosis of COVID19 in clinical practice. Our work has three major contributions as follows:
– We develop a 3D network to realize automatic and accurate diagnosis of
COVID-19 using CT images. Evaluated on a large open-source dataset, the
proposed method can identify COVID-19 from other common pneumonia
and the normal with 94.7% accuracy, 93.73% sensitivity, 98.28% specificity,
95.26% F1-score, and an area under the receiver operating characteristic
curve (AUC) of 0.99.
– The depth-wise attention module we proposed can improve the classification
performance and the interpretability of 3D ResNet with only a slight increase
in computational complexity. Moreover, the module has good scalability and
can be easily inserted into any 3D CNN-based method along with other
attention mechanisms.

Dual-Attention Residual Network for Automatic Diagnosis of COVID-19

3

– Our method is end-to-end trainable and readily applicable to other clinical
diagnostic problems, such as predicting pneumonia subtypes.

2

Related Work

Automatic Diagnosis of COVID-19: Recently, the successful application
of artificial intelligence (AI) in medical image analysis [16] has promoted the
development of radiological diagnosis technology. To combat the current pandemic, plenty of research efforts have been carried out over the past few months
to design an AI system for the early diagnosis of COVID-19 via radiological
imaging. Wang et al. [23] and Zhang et al. [24] employ CNNs to automatically
identify COVID-19 infection from chest X-ray images and obtain promising results. However, it is still a challenging task due to the low contrast and the lack
of significant features caused by the high overlapping of ribs and soft tissues.
Compared with a single X-ray image, a chest CT scan composed of hundreds of 2D slices can reflect more detailed radiographic features about the
lesions, such as GGO and consolidation. To simplify the computation, several
keyframe-based methods [18,7] are proposed to diagnose COVID-19 in CT images. Although these methods ignore the inter-slice information of CT images
and highly rely on the accurate detection of abnormal slices. Besides, [25,20,15]
propose the segmentation-based approaches that can generate more specific lesion information, such as the number and volume of lesions, which is valuable
for the quantitative analysis in COVID-19 diagnosis. However, obtaining large
amounts of annotated CT data is the primary challenge of these methods. We
thus develop a novel 3D network to identify COVID-19 in an end-to-end fashion,
which only takes a full chest CT image as input and can achieve competitive
classification performance.

Attention Mechanism: Attention mechanism is an effective way to improve
network performance by enhancing the learned features. Hu et al. [11] propose
the channel-wise attention (CA) to refine the hidden features in the channel
dimension during training, which can make the network more focused on the
important regions. The effectiveness of the CA module has been proved in many
applications [3,6,26]. Inspired by this, we develop a novel attention mechanism
called depth-wise attention (DA) to weight the depth-level features to further
improve the representation ability of the 3D network.

Class Activation Mapping: To explore the interpretability of CNN-based
methods, some visualization techniques have been proposed such as class activation mapping (CAM) [27] and Grad-CAM [22], which can reveal the discriminative regions affecting the network prediction. In this study, we apply CAM to
analyze the differences in decision-making factors among different networks.

4

Jun Shi et al.

(a) The schema of 3D CA module.

(b) The schema of 3D DA module.

Fig. 1. Illustration of the channel-wise attention (CA) and the proposed depthattention (DA) modules in our method. D, H, W , and C represent the depth, height,
width, and input channels of the feature map, and r refers to the reduction ratio.

3
3.1

Method
Backbone Network

Considering the computation complexity and GPU memory capacity, we use the
3D ResNet18 [8] as the backbone network. Then, we replace the original residual
block with a new one, which consists of two consecutive 3D convolutional layers
followed by two attention mechanisms: 1) channel-wise attention and 2) depthwise attention. Besides, we set the stride of the depth dimension as 1 in the first
convolutional layer and reduce one downsampling operation. In this way, the
input CT image is downsampled by a factor of 8 in the depth dimension and
a factor of 16 in the other two dimensions. The higher-resolution feature maps
retain more contextual information, which is conducive to visual analysis.
3.2

Depth-wise Attention Module

A CT image is usually composed of hundreds of 2D slices stacked in sequence.
These slices have high spatial continuity and content relevance, constituting the
complete contextual information of the lungs. Moreover, we observe that the
lesions of various sizes appear randomly in the lungs, resulting in only a portion
of the slices containing visible disease characterizations. The spatial correlations
of different dimensions and the inter-slice information will be entangled by a 3D
convolution operator when using 3D CNN to directly classify CT images. Hu
et al. [11] propose the channel-wise attention (CA) module to enhance channel
independence and thereby improve the performance of the networks. Inspired by
this, we design a novel mechanism called depth-wise attention (DA) module for
3D CNN to weight the depth-level features, which can make the network more
sensitive to the important regions of the images.

Dual-Attention Residual Network for Automatic Diagnosis of COVID-19

5

In the DA module, the spatial information is aggregated first along the depth
axis by global average pooling (GAP) layer, as shown in Fig. 1. Considering
the input feature map Fin ∈ RC×D×H×W and Fin = [f 1,1 , f 1,2 , ..., f i,j , ..., f C,D ],
where C, D, H, and W are the input channels, depth, height, and width, respectively, and f i,j ∈ RH×W . The output of the GAP represented by Z ∈ RC×D×1×1
with its element
z i,j =

H X
W
X
1
f i,j (h, w).
H ×W
w=1

(1)

h=1

Then, a gating mechanism is designed to the learn non-linear and nonmutually-exclusive relationships in the depth dimension. The gating mechanism
is parameterized by two fully-connected layers and two non-linearity activation
functions. The output is Ẑ = σ(W2 (ξ(W1 Z))), with W1 , W2 being the weights
of two fully-connected layers, the ReLU function ξ(·) and the sigmoid function
σ(·). The resultant tensor is used to refine Fin to
Fout = [ẑ 1,1 f 1,1 , ẑ 1,2 f 1,2 , ..., ẑ i,j f i,j , ..., ẑ C,D f C,D ].

(2)

The DA module recalibrates the depth-level features by adaptively assigning
weights, which can make the network more focused on the important regions distributed sparsely along the depth dimension. By combining DA and CA modules,
we construct the dual-attention residual module for our network.

4

Experiments

4.1

Dataset and Metrics

Table 1. The statistics and division of our dataset. The dataset is divided into the
training and test cohorts.
#Scan
COVID-19 Common pneumonia Normal controls In total
Training cohort
1320
1328
952
3600
Test cohort
169
177
126
472
In total
1489
1505
1078
4072

In this study, we collect 4,072 full chest CT scans from the website1 of China
Consortium of Chest CT Image Investigation (CC-CCII). The CT dataset contains 1,489 CT scans of COVID-19 patients, 1,505 CT scans of common pneumonia patients, and 1,078 CT scans of normal controls. As shown in Table 1, 3600
scans (1320 COVID-19 cases, 1328 common pneumonia cases, and 952 normal
controls) and 472 scans (169 COVID-19 cases, 177 common pneumonia cases,
1

http://ncov-ai.big.ac.cn/download?lang=en

6

Jun Shi et al.

and 126 normal controls) are used for training and independent testing, respectively. Besides, the training set is randomly divided into five folds on patient
level for cross-validation.
In the test stage, we apply several classification metrics including the area
under the receiver operating characteristic curve (AUC), accuracy, sensitivity,
specificity, and F1-score, to evaluate the performance of different networks.
4.2

Implementation Details

Pytorch is adopted to implement our proposed method. For training the network, we use Adam optimizer [14] to minimize the cross-entropy loss with an
initial learning rate of 10−3 . The convolutional layer weights are initialized by
the Kaiming Normalization [9] and the biases are set to 0. Besides, we apply the
cosine annealing strategy [17] to control the change of the learning rate during
training. Given the limitation of GPU memory, the batch size is set to 4 and the
size of all scans is fixed to 64 × 224 × 224 by under-sampling or up-sampling. To
alleviate the overfitting problem, we conduct online data augmentation including random flipping, rotation, translation, and scaling. The codes used in the
experiments will be made publicly available.
4.3

Comparison of Different Methods

Table 2. The performance comparison between different methods of identifying
COVID-19 on the different test sets (all from CC-CCII). For the results on the independent test set of the baseline model (ResNet18) and our method, we show the
mean±std (standard deviation) scores of five trained models of each training-validation
fold. Larger values indicate better performance, and - denotes no relevant data.
Method
Test cohort(#Scan)
AUC

ResNet18

[25]

[12]

[10]

Ours

472

389

3784

798

472

0.9890±0.0045 0.9797 0.9212 0.9400 0.9900±0.0016

Accuracy

0.9250±0.0219 0.9249

Sensitivity

0.9124±0.0597 0.9493 0.7799 0.8609 0.9373±0.0090

Specificity

0.9881±0.0098 0.9113 0.9355 0.9435 0.9828±0.0137

F1-score

0.9429±0.0288

-

-

-

0.8863 0.9470±0.0054

0.8814 0.9526±0.0072

We use 3D ResNet18 as the baseline model and compare the performance
of our method with several existing methods. The test cohorts of different sizes
used by these methods all come from CC-CCII. In particular, [25] and [12] are
segmentation-based methods, which rely on accurate segmentation of the lesions.
[10] provides a benchmark for COVID-19 detection using deep learning models.
The benchmark tests multiple models and we choose the best performing one for

Dual-Attention Residual Network for Automatic Diagnosis of COVID-19

7

comparison. As shown in Table 2, we can see that the proposed method achieves
the best performance with 94.7% accuracy, 93.73% sensitivity, 98.28% specificity,
95.26% F1-score, and AUC of 0.99. These results prove the superiority of our
method in identifying COVID-19 from other common pneumonia and the normal. Besides, the comparison between ResNet18 and our method, demonstrates
that our modification has a practical effect on improving performance.
4.4

Ablation Studies of Different Modules

Table 3. For COVID-19 versus the other two classes (common pneumonia and the
normal controls), we compare the results of the ablation studies on DA module and
√
CA module ( /× denotes with/without). Five folds cross-validation is used.
Network
DA

ResNet18
×

CA

×

AUC
Accuracy

CA-ResNet18
×
√

DA-ResNet18
√
×

0.9890±0.0045 0.9930±0.0014 0.9892±0.0027

Ours
√
√
0.9900±0.0016

0.9250±0.0219

0.9385±0.0113

0.9407±0.0095 0.9470±0.0054

Sensitivity 0.9124±0.0597

0.9373±0.0123

0.9243±0.0164 0.9373±0.0090

Specificity 0.9881±0.0098 0.9908±0.0118 0.9901±0.0040
F1-score
Parameters

0.9429±0.0288 0.9648±0.0126 0.9518±0.0074
33.15M

33.24M

35.24M

0.9828±0.0137
0.9526±0.0072
35.15M

To validate the effectiveness of the proposed attention module, we conduct
ablation studies on CA and DA modules. Table 3 quantitatively compare the
performance of different networks on the same test set. For COVID-19 versus
the other two classes (common pneumonia and the normal controls), our method
equipped with both CA and DA modules achieves the highest accuracy and sensitivity, while the parameter is only increased by ∼ 6.3% compared with ResNet18.
The results of the ablation experiments prove the effectiveness of the CA and
DA modules in improving the classification performance of ResNet18. Especially,
the dual-attention module can achieve a higher performance improvement than
a single CA or DA module in this task.
4.5

Visualization and Analysis

To explore the interpretability of the proposed method, we employ CAM [27] to
visualize the discriminative regions of different networks in diagnosing COVID19. Fig. 2 shows the visualization results on three COVID-19 cases with different
degrees (mild, moderate, and severe) of infection, highlighting the regions that
the network focuses on when making decisions. We can see that the outputs
of the networks with CA or DA module added can roughly indicate the lesion

8

Jun Shi et al.

Fig. 2. Visualization results of different methods on three COVID-19 cases with different degrees of infection are shown from top to down, respectively. The discriminative
regions of different networks are highlighted.

location. In contrast, only ResNet18 is less sensitive to lesions, and may even be
disturbed by the information outside the lung area. The above results demonstrate that DA and CA modules can enhance the learned features to ensure that
the decisions made by the network depend mainly on the infection regions, rather
than the irrelevant parts of the images. More importantly, the results show that
our method has better interpretability and reliability in diagnosing COVID-19,
which is the basis for its application in clinical practice.

5

Conclusion

In this work, we propose a dual-attention residual network that can realize the
automatic and accurate diagnosis of COVID-19 using CT images. In our method,
we develop a depth-wise attention module to refine the hidden depth-level features by adaptively assigning weights during training. This module can improve
the performance and interpretability of 3D ResNet, while only slightly increasing the computational complexity. We evaluate our method on the largest public
CT dataset (to the best of our knowledge). The experimental results show that
the proposed method outperforms the baseline method and some existing methods. In future work, we will use more data to test the generalization ability of
our method. Moreover, we are interested in extending the proposed approach to
other clinical diagnostic problems, such as predicting pneumonia subtypes.

Dual-Attention Residual Network for Automatic Diagnosis of COVID-19

9

References
1. Ai, T., Yang, Z., Hou, H., et al.: Correlation of Chest CT and RT-PCR Testing
for Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases.
Radiology 296(2), E32–E40 (2020)
2. Butt, C., Gill, J., Chun, D., Babu, B.A.: Deep learning system to screen coronavirus
disease 2019 pneumonia. Applied Intelligence (2020)
3. Cao, Y., Xu, J., Lin, S., Wei, F., Hu, H.: GCNet: Non-local networks meet squeezeexcitation networks and beyond. Proceedings - 2019 International Conference on
Computer Vision Workshop, ICCVW 2019 pp. 1971–1980 (2019)
4. Chan, J.F.W., Yuan, S., Kok, K.H., et al.: A familial cluster of pneumonia associated with the 2019 novel coronavirus indicating person-to-person transmission: a
study of a family cluster. The Lancet 395(10223), 514–523 (Feb 2020)
5. Dong, E., Du, H., Gardner, L.: An interactive web-based dashboard to track covid19 in real time. The Lancet Infectious Diseases 20(5), 533–534 (May 2020)
6. Gao, S., Cheng, M.M., Zhao, K., Zhang, X.Y., Yang, M.H., Torr, P.H.: Res2Net: A
New Multi-scale Backbone Architecture. IEEE Transactions on Pattern Analysis
and Machine Intelligence 8828(c), 1–1 (2019)
7. Hasan, A.M., Al-Jawad, M.M., et al.: Classification of Covid-19 coronavirus, pneumonia and healthy lungs in CT scans using Q-deformed entropy and deep learning
features. Entropy 22(5) (2020)
8. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
CoRR abs/1512.03385 (2015)
9. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification. arXiv preprint arXiv: 1502.01852
(2015)
10. He, X., Wang, S., Shi, S., Chu, X., et al.: Benchmarking deep learning models and
automated model design for COVID-19 detection with chest CT scans. medRxiv
pp. 1–13 (2020). https://doi.org/10.1101/2020.06.08.20125963
11. Hu, J., Shen, L., Sun, G.: Squeeze-and-excitation networks. CoRR
abs/1709.01507 (2017)
12. Jin, C., Chen, W., Cao, Y., et al. Jie, Shi, H., Feng, J.: Development and evaluation
of an artificial intelligence system for COVID-19 diagnosis. Nature Communications 11(1) (2020). https://doi.org/10.1038/s41467-020-18685-1
13. Kadry, S., Rajinikanth, V., Rho, S., Raja, N.S.M., Rao, V.S., Thanaraj, K.P.:
Development of a Machine-Learning System to Classify Lung CT Scan Images
into Normal/COVID-19 Class. arXiv preprint arXiv: 2004.13122 (2020)
14. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint
arXiv: 1412.6980 (2014)
15. Li, L., Qin, L., Xu, Z., et al.: Using artificial intelligence to detect covid-19 and
community-acquired pneumonia based on pulmonary ct: Evaluation of the diagnostic accuracy. Radiology 296(2), E65–E71 (Aug 2020)
16. Litjens, G., Kooi, T., Bejnordi, B.E., et al.: A survey on deep learning in medical
image analysis. Medical Image Analysis 42, 60 – 88 (2017)
17. Loshchilov, I., Hutter, F.: SGDR: stochastic gradient descent with restarts. CoRR
abs/1608.03983 (2016)
18. Mei, X., Lee, H.C., et al.: Artificial intelligence–enabled rapid diagnosis of patients
with COVID-19. Nature Medicine 26(8), 1224–1228 (2020)
19. Nishiura, H., Jung, S.M., Linton, N.M., Kinoshita, R., Yang, Y., et al.: The extent
of transmission of novel coronavirus in wuhan, china, 2020. Journal of clinical
medicine 9(2), 330 (Jan 2020)

10

Jun Shi et al.

20. Ouyang, X., Huo, J., Xia, L., et al.: Dual-Sampling Attention Network for Diagnosis of COVID-19 from Community Acquired Pneumonia. IEEE Transactions on
Medical Imaging 39(8), 2595–2605 (2020)
21. Phelan, A.L., Katz, R., Gostin, L.O.: The Novel Coronavirus Originating in
Wuhan, China: Challenges for Global Health Governance. JAMA 323(8), 709–710
(02 2020)
22. Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.: GradCAM: Visual Explanations from Deep Networks via Gradient-Based Localization.
International Journal of Computer Vision 128(2), 336–359 (2020)
23. Wang, L., Wong, A.: COVID-Net: A Tailored Deep Convolutional Neural Network
Design for Detection of COVID-19 Cases from Chest X-Ray Images. arXiv preprint
arXiv: 2003.09871 (2020)
24. Zhang, J., Xie, Y., Liao, Z., Pang, G., Verjans, J., Li, W., Sun, Z., He, J., Li,
Y., Shen, C., Xia, Y.: Viral Pneumonia Screening on Chest X-ray Images Using
Confidence-Aware Anomaly Detection. arXiv preprint arXiv: 2003.11988 (2020)
25. Zhang, K., Liu, X., Shen, J., et al., He, J., et al.: Clinically applicable ai system for accurate diagnosis, quantitative measurements, and prognosis of covid-19
pneumonia using computed tomography. Cell 181(6), 1423 – 1433.e11 (2020)
26. Zhao, Q., Sheng, T., Wang, Y., Tang, Z., Chen, Y., Cai, L., Ling, H.: M2Det:
A Single-Shot Object Detector Based on Multi-Level Feature Pyramid Network.
Proceedings of the AAAI Conference on Artificial Intelligence 33, 9259–9266 (2019)
27. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.: Learning deep features
for discriminative localization. In: 2016 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR). pp. 2921–2929 (2016)
28. Zu, Z.Y., Di Jiang, M., Xu, P.P., Chen, W., Ni, Q.Q., Lu, G.M., Zhang, L.J.: Coronavirus Disease 2019 (COVID-19): A Perspective from China. Radiology 296(2),
E15–E25 (2020)

