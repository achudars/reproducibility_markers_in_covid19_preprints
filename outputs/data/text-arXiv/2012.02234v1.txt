COVID-CLNet: COVID-19 Detection with
Compressive Deep Learning Approaches
Khalfalla Awedat∗ and Almabrok Essa†
∗ Department

arXiv:2012.02234v1 [eess.IV] 3 Dec 2020

† Department

of Computer Science, Pacific Lutheran University, Tacoma, WA, USA
of Electrical Engineering and Computer Science, Cleveland State University, Cleveland, OH, USA
Email:∗ awedatka@plu.edu; † a.essa@csuohio.edu

Abstract—One of the most serious global health threat is
COVID-19 pandemic. The emphasis on improving diagnosis and
increasing the diagnostic capability helps stopping its spread
significantly. Therefore, to assist the radiologist or other medical
professional to detect and identify the COVID-19 cases in the
shortest possible time, we propose a computer-aided detection
(CADe) system that uses the computed tomography (CT) scan
images. This proposed boosted deep learning network (CLNet) is
based on the implementation of Deep Learning (DL) networks as
a complementary to the Compressive Learning (CL). We utilize
our inception feature extraction technique in the measurement
domain using CL to represent the data features into a new space
with less dimensionality before accessing the Convolutional Neural Network. All original features have been contributed equally
in the new space using a sensing matrix. Experiments performed
on different compressed methods show promising results for
COVID-19 detection. In addition, our novel weighted method
based on different sensing matrices that used to capture boosted
features demonstrates an improvement in the performance of the
proposed method.
Index Terms—COVID-19, Compressive Learning (CL), Deep
Learning (DL), Compressive Sensing (CS), Computed Tomography (CT) Scan Images.

I. I NTRODUCTION
Coronavirus Disease 2019 (COVID-19) is a novel (new)
virus that first identified in Wuhan, Hubei Province, China in
December 2019. COVID-19 is contagious respiratory illnesses
that is caused by infection with a new coronavirus (called
SARS-CoV-2), which affects different people in different
ways. The centers for disease control and prevention (CDC) is
closely monitoring the spread of cases caused by this disease.
As of the best of our knowledge while we write this article
and according to the World Health Organization (WHO), more
than 60 million confirmed cases globally, and more than 1 million deaths. One of the assessment or examination processes
to identify COVID-19 is the chest CT, which is recommended
to be used as the primary screening or diagnostic method.
Therefore, the CADe systems are recommended to detect
the earliest signs of ground-glass nodules in thoracic CT
that are caused by this disease, which may not be detected
by the radiologist or other medical professional at the early
times. Fig. 1 shows that COVID-19 causes multiple peripheral
ground-glass opacities in lung that did not spare the subpleural
regions, image A in the figure, which progressive produced
pulmonary opacities after 3 days, image B in the figure [1].

Fig. 1: Unenhanced CT images. According to [1], image
A shows multiple ground-glass opacities in bilateral lungs.
While image B which obtained 3 days after follow-up shows
progressive ground-glass opacities in the posterior segment of
right upper lobe and apical posterior segment of left superior
lobe.

The main motivation of this research is to assist accelerating
the diagnostic process and help stopping this widespread
pandemic. Therefore, we introduce the CADe system that
applies the advanced deep learning-based radiology image
analysis methods as a complementary to the compressive
learning (CL), which is based on different sensing matrices
weighted strategy. This CADe system could outperform many
state-of-the-art methods.
A. Deep Learning
Currently, COVID-19 radiology literature based on Deep
Learning (DL) methods has been explored the use of CT
images extensively and shown promising detection accuracy
of COVID-19 [2–5]. DL approaches like machine learning which can be categorized as follows: supervised, semisupervised, and unsupervised learning. In addition, there is
another category of learning called reinforcement learning or
deep reinforcement learning which are often considered to be
a special case of semi supervised or sometimes unsupervised
learning approaches [6].
1) Deep Unsupervised Learning: Unsupervised learning
grants the learning algorithm to find the structure in its input
since no labels are given by discovering the hidden patterns
within the input data. Often clustering, dimensionality reduction, and generative techniques are considered as unsupervised
learning approaches, such as Encoders (AE), Restricted Boltz-

mann Machines (RBM), and the recently developed Generative
Adversarial Networks (GAN).
2) Deep Semi-supervised Learning: Semi-supervised learning provides powerful framework for leveraging unlabeled data
when labels are limited by combining that limited number of
labels and a large number of unlabeled datasets (partially labeled datasets) to construct a model or classifier feature. Semisupervised learning is between supervised and unsupervised
learning. In some cases, Deep Reinforcement Learning (DRL)
and GAN are used as semi-supervised learning techniques.
3) Deep Supervised Learning: supervised learning is a
learning technique that uses labeled data to infer the relationship between the observed data and a predetermined
dependent variable. In the case of supervised DL approaches,
the predetermined dependent variable has a set of inputs
and corresponding outputs. After successful training, and the
goal is to learn a general rule that maps inputs to outputs.
There are different supervised learning approaches for deep
leaning including Deep Neural Networks (DNN), Convolutional Neural Networks (CNN), Recurrent Neural Networks
(RNN) including Long Short-Term Memory (LSTM), and
Gated Recurrent Units (GRU).
4) Deep Reinforcement Learning (DRL): DRL is a learning
technique for use in unknown environments where a system
interacts with a dynamic environment in which it must perform
a certain goal. In this case, there is a straightforward loss
function that means do not have full access to the function
you are trying to optimize. Therefore, the system is provided
feedback in terms of rewards and punishments as it navigates
its problem space. DLR is the appropriate way to go if the
problem has a lot of parameters to be optimized.
B. Compressive Sensing (CS)
One of the very powerful signal processing techniques is
the Compressive Sensing (CS), which has provided fast and
efficient data acquisition in many applications. Based on the
assumption that each data has a sparse representation in some
basis [7–10]. It has been built based on the fact that the sparse
signals can be recovered with high accuracy by projecting or
sensing the data into the measurement domain. The sensing
data can be achieved using sensing matrix which should satisfy
the incoherent, restricted isometry property (RIP) [11]. Most
of CS works have been focused on providing theories for reconstruction the original sparse data [12, 13]. Mathematically,
for a signal x ∈ <N is sparse s = kxk0 ∈ <N (wherekxk0
is number of nonzero entiries). Due the sparsity x can be
manipulate in new domain y ∈ <M where M  N by linear
system as
y = φ.x
(1)
where φ ∈ <M ×N is sensing (or measurements) matrix.
Decoding process focuses on finding back the sparse signal
x from a given measurement y. For this purpose, the optimization method needs to apply as
min kyk0

subjectto

φ.x = y

(2)

However, this problem is NP-hard. Instead, the reconstruction
can be done use L1-minimization
min kyk1

subjectto

φ.x = y

(3)

Generally, the CS can be optimized in coding procedure by
implement different coding matrices [14], or using different
optimization methods to reconstruct the original signals [13].
While the reconstruction sparse signal is the main objective
of CS, the compressed signal can be very useful in the
applications that detecting certain patterns or features for
classification [15, 16]. Moreover, in some scenarios related
to information privacy, reconstruction is undesirable [17].
Therefore, the Compressive Learning (CL) has been proposed
[15, 18, 19] where the system is built based on the compressed
measurements without the reconstruction step. Since CL has
been built based on all features of data that are combined to
reduce the dimensionality, it still can be used for learning task.
In other words, sine all the original features have been involved
in projected domain, the new low dimension projected features
can be applied to distinguish the original pattern or class [20].
This study is inspired by [20], and based on the observation
that the new low dimension projected features which can be
obtained by CL are great source of information to pass through
advanced deep learning methods. Therefore, we propose the
CL to employ our inception feature extraction technique in
the measurement domain for representing the data features
into a new space with less dimensionality before accessing
the deep learning network. The novel scientific contributions
in this paper are summarized as follows:
• It introduces a computer-aided detection (CADe) system
based on the boosted deep learning network (CLNet),
which uses compressive learning based deep learning
approach.
• The evaluation process of the proposed CLNet technique
has been conducted on raw CT images without any
preprocessing and has shown signs of high performance.
The rest of this paper is organized as the following: The
related work is covered in Section 2. The proposed approach
is presented in Section 3. Section 4 discusses in details
the experimental setup including data description, obtained
results, detailed discussion, and the work limitations. Section
5 concludes the work and introduces the future work plans.
II. R ELATED WORK
The effort of developing deep learning technique for diagnose COVID-19 has been gradually increased since the
outbreak. To illustrate the importance of early detection and
management of COVID19 patients, a detailed study has been
conducted in [21, 22]. Some literature reviews demonstrate
that the multiple peripheral ground-glass opacities in lung
which are caused by COVID-19 disease are appeared on CT
images 1 sometimes are not appeared on the chest X-ray
(CXR) [1, 23]. Due to superior ability of deep learning of
image classification, there are several Artificial Intelligence
(AI) systems that have been proposed for COVID-19 detection

based on medical imaging. While some literature reviews
show that DL methods using CT images have been achieved
promising detection accuracy of COVID-19, the DL based
approaches also have been utilized extensively on CXR images
and successfully have provided high performance. The authors
in [24, 25] proposed convolutional neural network (CNN) for
the detection of coronavirus pneumonia infected patient using
chest X-ray radiographs. On the other hand, the authors in
[26] applied 2D and 3D deep learning to classify CT samples
with COVID-19, Influenza viral pneumonia cases and noinfection cases. [27] has been built a database of COVID-19
based on CT images. The diagnosis method was based on concatenating both lung masks and lesion masks. [28] proposed
DenseNet201 based deep transfer learning (DTL) to classify
the patients as COVID infected. There are many studies have
been proposed to diagnosis coronavirus using deep learning
[2, 4, 5, 29]. According to various studies presented in the
literature, the learning framework has been applied on medical
images with different approaches for preprocessing methods.
In our study, by taking the advantage of CL that the images can
be represented in new domains with small number of features,
and then combining these features would be useful to improve
the diagnosis accuracy.
III. P ROPOSED M ETHOD
In this implementation, to investigate the appearance of
coronavirus (COVID-19) on CT images, we have utilized our
inception feature extraction network based on the compressing
learning (CL) to represent the data features into a new space
with less dimensionality before accessing the advanced deep
learning network. The end-to-end training pipeline of the
proposed CLNet is shown in Fig. 2.
A. Feature Extraction
In this stage, the appropriate features that are required
for an accurate distinguishing between infected and noninfected images will be extracted. Our method is based on
the principle of CL where all features of the input image
will be preserved in low dimension representation. Since the
compressing procedure is done using a sensing matrix, we
claim that different sensing matrices will hold the original
features in different weights. Fig. 3 shows an example for
applying different measurement matrices on an image.
It is obviously that the image has been represented in a new
domain differently in every single matrix. The authors in [20]
have addressed this issue and proved that the classification performance of the classifier is varied based on the sensing matrix
and the compression ratio. In our technique, we went further
and stated that the selected features for classification would
be composed from three different manipulation matrices. The
input features to the classifier contain three channels and every
channel is a representation of images under one sensing matrix
Φ. Each image has been represented by one channel. The three
channels produce concatenating image under Φ1 ,Φ2 , and Φ3 .
These matrices could be any combination of sensing matrices
that proposed or applied for compressing sensing. Basically,

Fig. 2: Block diagram of the proposed COV ID−CLN et
method for COV ID − 19 detection.

Fig. 3: Feature extraction of input image using three different
measurement matrices. Where ΦG is Gaussian matrix, ΦC is
Circulant matrix, and ΦT is Toeplitz matrix. The compression
ratio is 30%.

the raw data has been directly compressed and forwarded as
features for classification purpose. In this study, we applied
Gaussian matrix, Circulant matrix, and Toeplitz matrix. This
selection is not unique, but it is just to confirm the effectiveness
of our technique.
B. Data Classification
Once the features of input CT images have been selected,
the next step in our method is the classification process.
We have implemented deep learning network with several
convolution and pooling layers. Then feed-forward backpropagation method is used for the learning rule selection
to extract the features to classify the positive and negative
COVID-19 samples. The Max pooling is utilized with kernel
size of 2 × 2 to minimize the size of the convolved features.
There is no need to resize the input feeding images to the
classifier since they are already compressed to the required
size using sensing matrix.
IV. E XPERIMENTAL SETUP
The proposed CADe system is developed using deep learning based on compressing learning models for classification
of the raw data without any kind of preprocessing. The implementation process was conducted using Python programming
language on 24 Intel(R) Xeon(R) CPU E5-4607 0 @ 2.20GHz,
377G memory and two Quadro P2000.
A. Dataset (CT Images)
The COVID-CT dataset that has been used in this study is
is publicly available [27]. There are 349 images of COVID-19
collected from 216 patients. The non-COVID-19 data contains
397 samples. The images collected from four sources MedPix,
LUNA, PubMed Central (PMC), and Radiopaedia website.
Fig. 4 shows some positive and negative samples of the CT
images.
In this study, the collected CT images have different sizes.
Therefore, the first step was to resize the entire images into one
scale. All input images have been resized to 120 × 120, which

Fig. 4: CT positive and negative samples from the dataset for
COVID-19 diagnosis.
should be very efficient and accurate size for compressing
images using a single sensing matrix. Since the proposed
approach depends on the use of more than one sensing matrix,
the entire images are represented in the grayscale domain.
Then the three sensing different matrices are set to have the
same size, which accordingly produces output compressed
images with final size of 64 × 64.
B. Results
After the model has been built successfully and to avoid
any bias, the dataset used was randomly split into two independent parts training and testing respectively. Then K-fold
cross validation method was applied to obtain several results
according to each observation from the raw dataset, which
means each sample could be considered in both cases training
set and testing set. After successfully training the model, we
have divided the testing images equally between two categories
at each fold. The positive and negative COVID images are
randomly mixed. Fig. 5 displays how testing and training sets
are selected.
All trained models are evaluated using the accuracy and
validation loss (val-loss). The starting point is that testing
the CL technique for the classification. We have applied
three sensing matrices Gaussian, Circulant, and Toeplitz to
manipulate the images into the size of 64 × 64. Then apply
a quick comparison with the original images where there
is not any kind of compression sensing (No CS). In the
classifier, the original images resized to the same size of
compressed images. The CT images dataset was randomly split
into two independent parts with 80% and 20% for training and
testing respectively. The quantitative results based on k-fold
cross validation method and according to 5 different k values
(k = 1 − 5) show around 86.08% testing accuracy on the
overall completely different testing samples. Table I shows the
experimental result comparisons where it is obviously when
the CL has been applied the classification accuracy is improved
at all three different matrices comparing to the case of no
compression sensing is applied.
The experimental results also show that the classifier performance can be improved with a minimum margin around 15%,

Circulant respectively. Table II shows all possible combinations of these three channels. However, the best performance
could be achieved when the three channels are totally different,
which can be applied to define the severity of the COVID-19
disease. The main reason behind that is the selected features
after representing the images in low dimensions are promoted
by the combination of the three different channels. We also
observed that increases the accuracy and validation loss as
long as the selected features have been increased.
C. Discussion

Fig. 5: K-fold cross validation for the input CT images. Every
fold contains the same number of images from each class.
TABLE I: Comparison of non-compression sensing and compression sensing with different compressing methods.

To evaluate our proposed method, we have made a comparison with the DenseNet-169 [30], which has been trained under
different pretraining methods according to [27], named random
initialization, Transfer learning (TL), and TL with contrastive
self-supervised learning (CSSL). More details can be found in
[27]. In addition, to avoid any bias, we select the same number
of CT images for testing and 16-fold cross validation has been
applied.
The proposed COVID-CLNet detection method shows
around 91.98% testing accuracy whereas the highest accuracy
of the comparison papers TL-CSSL shows 89.1% testing
accuracy. Thus, our COVID-CLNet based detection model
shows around 2.88% higher testing accuracy than the mentioned comparison methods. Although all these methods need
some preprocessing steps such as lesion segmentation and
lung mask, our proposed approach does not need any kind
of preprocessing. The main observation of these qualitative
results is shown in Table III.
TABLE II: Performance comparison of different sensing matrices at different number of testing samples.

which means the evaluation parameters would be affected by
the compression sensing method. As we can see that Circulant
matrix outperforms other matrices with a small margin around
1.5%. Notice that the input features to the classifier are
different from three sources of compression.
In addition, for quantitative justification after confirming
that the CL can be involved to improve the performance of
the classifier, we have investigated the combination of these
three different methods for classification extensively. As shown
in Fig. 2, the three compressed features from every image
are concatenated into one channel. Every channel has a size
64 × 64. First, we investigate all concatenation options to
identify which one provides the best performance. Then in
the second part, we compare our results with other methods
that have been listed in [27]. Table II and Fig. 6 show the
experimental results for two testing sets. In the first set, we
have left 6.5% of the data samples for testing and have used
the rest training. While in the second set, we have utilized
10% for testing and the rest for training.
In general, the quantitative analysis that has been applied using all different concatenation options shows promising results
that higher accuracy than the case of single channel method
even though when the three channels are from the same
sensing matrix (TTT, GGG, and CCC) Toeplitz, Gaussian, and

R EFERENCES

Fig. 6: The validation loss comparison for different combination methods.

TABLE III: Comparison of the proposed method with different
pretrained methods.

D. Limitations
Even though our proposed CLNet has shown signs of high
performance using raw CT images without any preprocessing,
the main prevalent challenge of this work is to access a big
data. Currently, most of COVID-19 datasets are limited due
to the nature of the disease, patient privacy, and the requirements of the radiologist or other medical professional to data
labeling. From our point of observation, data augmentation
could be an option to improve the system performance and to
avoid the overfitting. In our technique, there are more options
to expand the dataset where augmentation could be performed
on either the original dataset images or on the CL features
level.
V. C ONCLUSION
The proposed CADe system for COVID-19 detection could
be a great and inexpensive tool to assist the radiologists or
other medical professionals to detect and identify the COVID19 cases at early infection stages and in the shortest possible
time. Our improved deep learning network model based on the
compressive learning (COVID-CLNet) is applied on computed
tomography (CT) images directly and without any kind of
preprocessing. The observed results show very promising
detection precision with 91.98% testing accuracy. The work is
in progress to improve the performance of our CADe system,
which could be done by either collecting more COVID-19
affected samples, applying data augmentation as preprocessing
to the system, or combining the CL with different deep
learning networks.

[1] J. Lei, J. Li, X. Li, and X. Qi, “Ct imaging of the 2019
novel coronavirus (2019-ncov) pneumonia,” Radiology,
vol. 295, no. 1, pp. 18–18, 2020.
[2] X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu,
Q. Ni, Y. Chen, J. Su et al., “A deep learning system
to screen novel coronavirus disease 2019 pneumonia,”
Engineering, 2020.
[3] O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning,
H. Zhang, W. Ji, A. Bernheim, and E. Siegel, “Rapid ai
development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient
monitoring using deep learning ct image analysis,” 2020.
[4] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo,
M. Cai, J. Yang, Y. Li, X. Meng et al., “A deep learning
algorithm using ct images to screen for corona virus
disease (covid-19),” MedRxiv, 2020.
[5] H. Ko, H. Chung, W. S. Kang, K. W. Kim, Y. Shin, S. J.
Kang, J. H. Lee, Y. J. Kim, N. Y. Kim, H. Jung et al.,
“Covid-19 pneumonia diagnosis using a simple 2d deep
learning framework with a single chest ct image: Model
development and validation,” Journal of Medical Internet
Research, vol. 22, no. 6, p. e19569, 2020.
[6] M. Z. Alom, T. M. Taha, C. Yakopcic, S. Westberg,
P. Sidike, M. S. Nasrin, B. C. Van Esesn, A. A. S.
Awwal, and V. K. Asari, “The history began from alexnet:
A comprehensive survey on deep learning approaches,”
arXiv preprint arXiv:1803.01164, 2018.
[7] E. J. Candes, J. K. Romberg, and T. Tao, “Stable signal
recovery from incomplete and inaccurate measurements,”
Communications on Pure and Applied Mathematics: A
Journal Issued by the Courant Institute of Mathematical
Sciences, vol. 59, no. 8, pp. 1207–1223, 2006.
[8] D. L. Donoho, “Compressed sensing,” IEEE Transactions
on Information Theory, vol. 52, no. 4, pp. 1289–1306,
2006.
[9] K. Awedat, A. Essa, and V. Asari, “Sparse representation
classification based linear integration of `1 norm and `2
norm for robust face recognition,” in 2017 IEEE International Conference on Electro Information Technology
(EIT). IEEE, 2017, pp. 447–451.
[10] K. Awedat, A. Essa, V. Asari, and D. Stoppenbrink,
“Sparse representation based classification performance
under different optimization forms for face recognition,”
in 2017 IEEE National Aerospace and Electronics Conference (NAECON). IEEE, 2017, pp. 34–37.
[11] E. J. Candes and T. Tao, “Decoding by linear programming,” IEEE transactions on information theory, vol. 51,
no. 12, pp. 4203–4215, 2005.
[12] A. Draganić, I. Orović, and S. Stanković, “On some
common compressive sensing recovery algorithms and
applications,” Facta universitatis-series: Electronics and
Energetics, vol. 30, no. 4, pp. 477–510, 2017.
[13] G. Pope, “Compressive sensing: A summary of reconstruction algorithms,” Master’s thesis, ETH, Swiss

[14]

[15]

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]

[25]

[26]

[27]

Federal Institute of Technology Zurich, Department of
Computer Science, 2009.
Y. Arjoune, N. Kaabouch, H. El Ghazi, and A. Tamtaoui,
“A performance comparison of measurement matrices in
compressive sensing,” International Journal of Communication Systems, vol. 31, no. 10, p. e3576, 2018.
R. Calderbank and S. Jafarpour, “Finding needles in
compressed haystacks,” in 2012 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, 2012, pp. 3441–3444.
J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and
Y. Ma, “Robust face recognition via sparse representation,” IEEE transactions on pattern analysis and machine
intelligence, vol. 31, no. 2, pp. 210–227, 2008.
P. Mohassel and Y. Zhang, “Secureml: A system for
scalable privacy-preserving machine learning,” in 2017
IEEE Symposium on Security and Privacy (SP). IEEE,
2017, pp. 19–38.
M. A. Davenport, M. F. Duarte, M. B. Wakin, J. N.
Laska, D. Takhar, K. F. Kelly, and R. G. Baraniuk, “The
smashed filter for compressive classification and target
recognition,” in Computational Imaging V, vol. 6498.
International Society for Optics and Photonics, 2007, p.
64980H.
M. A. Davenport, P. T. Boufounos, M. B. Wakin, and
R. G. Baraniuk, “Signal processing with compressive
measurements,” IEEE Journal of Selected topics in Signal processing, vol. 4, no. 2, pp. 445–460, 2010.
K. Awedat, A. Essa, and I. Abdel-Qader, “Compressive
sensing evaluation strategy for prostate cancer classification,” in 2020 IEEE International Conference on Electro
Information Technology (EIT), 2020, pp. 423–428.
W. Yang and F. Yan, “Patients with rt-pcr-confirmed
covid-19 and normal chest ct,” Radiology, vol. 295, no. 2,
pp. E3–E3, 2020.
M. Z. Alom, M. Rahman, M. S. Nasrin, T. M. Taha,
and V. K. Asari, “Covid mtnet: Covid-19 detection with
multi-task deep learning approaches,” arXiv preprint
arXiv:2004.03747, 2020.
M.-Y. Ng, E. Y. Lee, J. Yang, F. Yang, X. Li, H. Wang,
M. M.-s. Lui, C. S.-Y. Lo, B. Leung, P.-L. Khong et al.,
“Imaging profile of the covid-19 infection: radiologic
findings and literature review,” Radiology: Cardiothoracic Imaging, vol. 2, no. 1, p. e200034, 2020.
J. Civit-Masot, F. Luna-Perejón, M. Domı́nguez Morales,
and A. Civit, “Deep learning system for covid-19 diagnosis aid using x-ray pulmonary images,” Applied Sciences,
vol. 10, no. 13, p. 4640, 2020.
A. Narin, C. Kaya, and Z. Pamuk, “Automatic detection
of coronavirus disease (covid-19) using x-ray images
and deep convolutional neural networks,” arXiv preprint
arXiv:2003.10849, 2020.
C. Butt, J. Gill, D. Chun, and B. A. Babu, “Deep learning
system to screen coronavirus disease 2019 pneumonia,”
Applied Intelligence, p. 1, 2020.
X. Yang, X. He, J. Zhao, Y. Zhang, S. Zhang, and

P. Xie, “Covid-ct-dataset: a ct scan dataset about covid19,” arXiv e-prints, pp. arXiv–2003, 2020.
[28] A. Jaiswal, N. Gianchandani, D. Singh, V. Kumar, and
M. Kaur, “Classification of the covid-19 infected patients
using densenet201 based deep transfer learning,” Journal
of Biomolecular Structure and Dynamics, pp. 1–8, 2020.
[29] T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu,
O. Yildirim, and U. R. Acharya, “Automated detection
of covid-19 cases using deep neural networks with x-ray
images,” Computers in Biology and Medicine, p. 103792,
2020.
[30] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely connected convolutional networks,” in
Proceedings of the IEEE conference on computer vision
and pattern recognition, 2017, pp. 4700–4708.

