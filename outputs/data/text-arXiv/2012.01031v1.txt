Biomedical Knowledge Graph Refinement with Embedding and Logic Rules

arXiv:2012.01031v1 [cs.AI] 2 Dec 2020

Sendong Zhao1 , Bing Qin1 , Ting Liu1 , Fei Wang2
1
Faculty of Computing, Harbin Institute of Technology
2
Weill Cornell Medical College, Cornell University
{sdzhao, bqin, tliu}@ir.hit.edu.cn, few2001@med.cornell.edu

Abstract
Currently, there is a rapidly increasing need
for high-quality biomedical knowledge graphs
(BioKG) that provide direct and precise biomedical
knowledge. In the context of COVID-19, this issue
is even more necessary to be highlighted. However,
most BioKG construction inevitably includes
numerous conflicts and noises deriving from
incorrect knowledge descriptions in literature and
defective information extraction techniques. Many
studies have demonstrated that reasoning upon the
knowledge graph is effective in eliminating such
conflicts and noises. This paper proposes a method
BioGRER to improve the BioKG’s quality, which
comprehensively combines the knowledge graph
embedding and logic rules that support and negate
triplets in the BioKG. In the proposed model,
the BioKG refinement problem is formulated
as the probability estimation for triplets in the
BioKG. We employ the variational EM algorithm
to optimize knowledge graph embedding and logic
rule inference alternately. In this way, our model
could combine efforts from both the knowledge
graph embedding and logic rules, leading to better
results than using them alone. We evaluate our
model over a COVID-19 knowledge graph and
obtain competitive results.

Introduction
Collecting structured biomedical knowledge has become a
crucial task to provide physicians and doctors with direct
and precise biomedical knowledge for decision-making, especially for some new dangerous diseases like COVID-19.
By the end of July 2020, there had been 646,949 deaths
worldwide because of COVID-19, and this number is still increasing Viglione [2020]. In the face of this global pandemic,
great research interest has been attracted, and the literature
of COVID-19 is very dynamics and being updated very fast
Xiang et al. [2020]. According to LitCOVID Chen et al.
[2020b], there have already been more than 47,758 research
articles about COVID-19 until Aug. 2020. In reality, it is
almost impossible for the readers to keep up with all the articles they are interested in. This makes automatic knowledge

graph curation from COVID-9 articles highly demanding.
Such knowledge graphs can accelerate the understanding of
the transmission and prevention of COVID-19 and help with
the battle of COVID-19.
However, the majority of BioKGs curated with information
extraction techniques tend to suffer from low-quality. These
BioKGs, which comprise biomedical entities and relations,
can be built with NLP techniques including biomedical relation extraction and biomedical named entity recognition.
These NLP techniques might bring noises due to their inherent defects. In particular, some non-existing relations might
be extracted from biomedical literature. Some biomedical
named entities might not be recognized precisely. The correct
knowledge described in literature can be misextracted by
the NLP models, let alone the incorrect descriptions. There
is usually unreliable knowledge in biomedical literature.
Unreliable knowledge could be incorrect conclusions, inconsistent and even conflicting answers for the same question
in different articles. For example, “Young adults have a
very low risk of COVID-19Adams et al. [2020]” has been
proved to be seriously misleading Viglione [2020]. Besides,
there is another example. The evidence in Cardwell et al.
[2010] indicates that oral bisphosphonates are not associated
with esophageal cancer. However, Green et al. Green et al.
[2010] reached a completely contradictory conclusion that
bisphosphonates are associated with esophageal cancer.
Noises from different ways mentioned above severely
diminish the utility of the BioKG. Therefore, it encourages
more and more interest in BioKG refinement. However,
related studies are all conducted on general knowledge graph
like Freebase, Wikidata, and YAGO. These studies can be
generally summarized into three categories that are 1) the
web-search based knowledge verification models, 2) fact
check models with pattern matching, and 3) hybrid models
by combining different resources to verify the knowledge
graph. Fionda et al. Fionda and Pirrò [2018] leveraged the
knowledge schema to generate evidence patterns and check
facts in a knowledge graph with patterns. Chen et al. Chen et
al. [2020a] proposed a knowledge graph refinement model,
which combines lexical matching, graph embedding, soft
rule patterns, and semantic consistency checking. The above
studies have proved that it is effective to verify general
knowledge graphs with links of knowledge graph and logic
rules.

In a BioKG, each triplet with form (head, relation, tail),
denoted as (h, r, t), is composed of a link r and two nodes
(h,t). BioKG refinement is to quantize the plausibility of
each triplet (h, r, t). Knowledge graph embedding has been
developed as a promising method for this purpose. This
method can learn continuous representations for links and
nodes in the knowledge graph to effectively measure the
plausibility of triplets with a score function Bordes et al.
[2013]. However, one limitation is that they do not consider
logic rules which can directly infer knowledge.
In another line of this topic, rule-based approaches Lin et
al. [2018]; Fionda and Pirrò [2018]; Lin et al. [2019] are
utilized for knowledge graph refinement. Logic rules can be
either manually generated by domain experts or mined from
the knowledge graph itself. They are used as triplet checking
patterns and suggest the correctness of triplets. However,
logic rules can only cover a small portion of triplets, thus
limiting the effectiveness of methods that are purely based
on logic rules.
In this paper, we introduce a model for BioKG refinement, which leverages the best of both worlds by combining
two clues: 1) knowledge graph embedding which encodes
underlying semantics of BioKG; 2) supporting rules and
negating-like rules that can be directly applied to support
and negate triplets in the BioKG. In the proposed model,
the BioKG refinement is formulated as the plausibility estimation for each triplet. A variational EM algorithm is
utilized for training knowledge graph embedding and logic
rule inference alternately. Both efforts from the underlying
knowledge graph and logic rules can be combined with this
alternating process of learning. Experimental results over a
COVID-19 knowledge graph demonstrate that our model can
significantly outperform competitive baselines.

Related Work
It is critical to verify the correctness of the collected structured knowledge, claim, and statement for real-world usage.
Therefore, this topic has drawn extensive attention from
both the research and industrial community. In general, there
are two types of knowledge verification, including factchecking in free text and fact-checking in the knowledge
graph. Specifically, fact-checking in free text is to verify
textual contents such as claims and statements. Fact-checking
in the knowledge graph is to check the correctness of triplets
in a given knowledge graph. Here, we survey related work of
knowledge verification in the context of knowledge graphs.
There exist three types of approaches for knowledge verification in the knowledge graph.
Knowledge graph embedding models can learn representations of links and nodes in knowledge graph and compute
plausibility of triplet candidates with a score function. For
the knowledge graph embedding models, we choose five
representative models to compare with, including ConvE
Dettmers et al. [2018], ComplEx Trouillon et al. [2016],
HolE Nickel et al. [2015b], DistMult Yang et al. [2015] and
TransE Bordes et al. [2013].
Another solution is to apply knowledge graph schema,
patterns, or rules to measure the correctness of triplets Lin

et al. [2018]; Fionda and Pirrò [2018]; Lin et al. [2019]. Lin
et al. Lin et al. [2018] introduced a fact-checking method
for knowledge graph with graph fact-checking rules. These
rules incorporate expressive subgraph patterns to describe
constraints in the knowledge graph. Likewise, Fionda et al.
Fionda and Pirrò [2018] leveraged the knowledge schema
to generate schema-level paths as patterns and check facts
in a knowledge graph with patterns. Lin et al. Lin et al.
[2019] further extended their method in Lin et al. [2018]
for identifying and exploiting similar facts. Therefore, their
method is able to check the fact that may not exactly match
any known patterns.
There is a third line of researches which apply multiple
resources for fact-checking in knowledge graph Li et al.
[2017]; Chen et al. [2020a]; Gad-Elrab et al. [2019b,a];
Cao et al. [2020]. Li et al. Li et al. [2017] used various
evidence collection techniques to collect evidence from the
knowledge graph, the web, and query logs and checked
triplets with knowledge fusion. A tool was designed to incorporate both evidence in textual sources and the underlying
knowledge graph Gad-Elrab et al. [2019b]. Similarly, another
tool ExFaKT Gad-Elrab et al. [2019a] was proposed to
compute explanations over the content of knowledge graphs
and textual resources. Cao et al. Cao et al. [2020] proposed
a probabilistic graphical model to infer the truthfulness of
extracted facts from different evidence sources.

Problem Statement
A BioKG is a collection of biomedical relational facts, each
of which is represented as a triplet (h, r, t). The problem
of noises in BioKG could cause undesired impacts in both
research and clinical decision-making process. Therefore, a
critical problem of BioKGs is to verify the correctness of
triplets.
Formally, given a BioKG G = (E, R, T, M ), where E is a
set of biomedical entities, R is a set of biomedical relations,
T is a set of true triplets (h, r, t) in the BioKG, M is a set
of triplets (h, r, t) whose correctness is uncertain in BioKG,
the goal is to verify the correctness of each triplet candidate
τ ∈M
Definition 1 (Biomeical Knowledge Graph Refinement).
Given a BioKG G consists of triplets (h, r, t),
biomedical knowledge graph refinement decides if each
triplet in M is true.
Thus, it is natural to consider this task as a binary classification task that takes as input BioKG G and the triplet candidate
(h, r, t) to be verified. Following a previous study Nickel et
al. [2015a], we can formulate this problem in a probabilistic
way. We take the indicator V(h,r,t) of each triplet (h, r, t) as
a probabilistic variable. V(h,r,t) = 1 represents (h, r, t) is a
true triplet, and V(h,r,t) = 0 otherwise. Given the BioKG
comprise triplets (h, r, t), we aim to estimate the probability
of V(h,r,t) for (h, r, t) ∈ M , i.e., p(V(h,r,t)∈M ).

Method
In this section, we introduce our proposed approach of
Biomedical knowledge Graph Refinement with knowledge

graph Embedding and logic Rules (BioGRER). This
approach incorporates logic rules and the knowledge graph
embedding with underlying semantics. To better use the
logic rules driving from knowledge graph schema, BioGRER
considers supporting rules and negating-like rules with a
logistic regression model and quantifies the plausibility of
given triplets. The knowledge graph embedding model can
learn embeddings of entities and relations with triplets in the
knowledge graph. BioGRER incorporates a knowledge graph
embedding model to predict the correctness of given triplets
with the learned entity and relation embeddings. These two
components are not independent and should augment each
other’s capability. Therefore, we jointly train these two
components with the variational EM algorithm and allow
them alternating between a variational E-step and an M-step.
In the E step, we use knowledge graph embeddings to predict
given triplets to be verified. In the M step, the weights of
rules in the logistic regression model are updated based on
the true and verified true triplets in BioKG. An overview of
our model BioGRER is given in Figure 1.

Supporting and Negating-like Rules Modeling
We apply a logic regression model to incorporate supporting
rules and negating-like rules. The supporting logic rules
enhance the triplet that can be inferred from them. Domain
knowledge can be directly encoded in these supporting rules.
These supporting logic rules include:
• Transitive Rules. A relation rk is a transitive equivalence of ri and rj means that for any three entities x, y,
z, if x has relation ri with y, and y has relation rj with
z, then x has relation rk with z. We formally define this
rule as ∀x, y, z ∈ E, V (x, ri , y) = 1 ∧ V (y, rj , z) =
1 ⇒ V (x, rk , z) = 1.
• Symmetric Rules. A relation r is symmetric means that
for any entity pair x and y, if x has relation r with y,
then y also has relation r with x. We formally define this
rule as ∀x, y ∈ E, V (x, r, y) = 1 ⇒ V (y, r, x) = 1.
The negating-like rules negate the triplets that are denied
by them. In particular, links in the BioKG can be blocked by
negating-like rules. These negating-like rules include:
• Block Rules. A relation rk is a block of ri and rj means
that for any three entities x, y, z, if x has relation ri
with y, and y has relation rj with z, then x may not have
relation rk with z with a high rate. We formally define
this rule as ∀x, y, z ∈ E, V (x, ri , y) = 1∧V (y, rj , z) =
1 ⇒ V (x, rk , z) = 0.
• Conflict Rules. A relation rj is a conflict of ri indicates
that for any entity pair x and y, if x and y have relation
ri , then x may not have have relation rj . We formally
define this rule as ∀x, y ∈ E, V (x, ri , y) = 1 ⇒
V (x, rj , y) = 0.
In this study, we use logistic regression to model these
above supporting and negating-like rules. The supporting
rules should increase the plausibility of triplets. Otherwise,
the negating-like rules should decrease the plausibility of
triplets. Therefore, we design a positive indicator for supporting rules and a negative indicator for negating-like rules. We

have the logistic regression model to quantize the plausibility
of each triplet as follows:
1

Prule (τ ) =

e−f (τ,T )

+1

,

(1)

where τ is a given triplet which needs to be verified, T is
the set of true triplets in BioKG. f () is the linear function to
combine logic rules which can be directly applied to the given
triplet, which is defined as
X
f (τ, T ) =
Il wl N (l, τ, T ),
(2)
l∈L
|L|

where l is logic rule, L is a set of logic rules L = {l1 }, wl
is the weight of the rule l, Il is the indicator for the rule l

+1 when l is a supporting rule
(3)
Il =
−1 when l is a negating-like rule
and N (l, τ, T ) is the number of true groundings of the logic
rule l according to the specific rule l, the given triplet τ and
neighboring triplets in T . Figure 2 shows an example of
true groundings of logic rule for triplet candidate (MKRN3,
has gene product, nptx1 human). To negate this triplet, the
block rule pattern “has gene product ∧ interacts with ⇒
has gene product is invalid” can be applied with the true
grounding V (MKRN3, has gene product, mkrn3 human)=1
∧ V (mkrn3 human, interacts with, nptx1 human)=1 ⇒
V (MKRN3, has gene product, nptx1 human)=0.
We assume the network consists of all triplets in BioKG
as a Markov logic network because a triplet’s correctness
depends on its neighboring triplets with a certain degree.
Therefore, a triplet is conditionally independent of all other
triplets given its Markov blanket in the network. We define
the probabilistic joint distribution of all true triplets T and
triplet candidates M as
Y
P (VT , VM ) ≥
Prule (τ ),
(4)
τ ∈T ∪M

since Prule (τ ) and Prule (ς) are not independent if triplet τ
and triplet ς share the same neighbor(s). In following sections, we will discuss the estimation of this joint distribution.

Knowledge Graph Embedding
Different from the logic rule-based model, the knowledge
graph embedding methods learn embeddings of entities and
relations with the true triplets T in knowledge graph, and
then predict the the correctness of a given triplet τ with the
learned entity and relation embeddings. Formally, head entity
h ∈ E, tail entity t ∈ E and relation r ∈ R are associated
with embeddings xh , xt and xr . Then the distribution of the
given triplet is defined as:
Pembedding (τ ) = Ber(V (τ )|f (xh , xr , xt )).

(5)

where Ber stands for the Bernoulli distribution, f (xh , xr , xt )
computes the probability that the triplet τ = (h, r, t) is
true, with f (., ., .) being a scoring function on the entity and
relation embeddings. For example in the knowledge graph
embedding model TransE Bordes et al. [2013], the score

mkrn3_human
Protein

E-Step:

Block Rule: has_gene_product ∧ interacts_with
⇏ has_gene_product

ha

ith

s_

ge

_w

ne

cts

_p

ro
d

era
int

uc

t

Update distribution of triplets
which need to be verified.

?
has_gene_product

Gene

MKRN3

relate ?
d_to

Protein

Transitive Rule: related_to ∧ related_to
⇒ related_to

nptx1_human

la
re

decrease

ted
o
_t

Disease

𝑃=

1
1 + 𝑒 !(#$%&')

increase

to

ted_
rela

Chemical

CCP

M-Step:

GnRH

Update weight of each logic
rule pattern.

Biomedical Knowledge Graph

Variational EM

Logic Rules Modeling

Figure 1: Overview of the BioGRER for combining logic rules and knowledge graph embedding using the variational EM
framework.
mkrn3_human

requires integrating over all variables VM and VT . We instead
optimize the variational evidence lower bound (ELBO) of the
data log-likelihood, as follows:

ha

th
wi

s_

ts_

ge
n

e_

rac

MKRN3

log P (VT ) ≥ log P (VT ) − KL[Q(VM )||P (VM |VT )]
Z
= (Q(VM ) log P (VT , VM ) − Q(VM ) log Q(VM ))dVM ,

e
int

pr
od
uc

t

Protein

Gene

Protein

nptx1_human

has_gene_product

Figure 2: True groundings of block rule for negating triplet
candidate (MKRN3, has gene product, nptx1 human).
function f can be formulated as σ(γ − ||xh + xr − xt )||)
according to Sun et al. [2019], where σ is the sigmoid
function and γ is a fixed bias. To learn the entity and
relation embeddings, these methods typically treat observed
ture triplets and verified triplets as positive examples and
the hidden triplets as negative ones. In other words, these
methods seek to maximize
Y
Q(VT , VM ) =
Pembedding (τ ).
(6)
τ ∈T ∪M

The whole framework can be efficiently optimized with the
stochastic gradient descent algorithm.

Variational EM
We introduce the variational EM framework to combine logic
rule modeling and knowledge graph embedding together.
The logistic regression model in Equation (1) models the
probabilistic joint distribution of all triplets as in Equation (4).
We can optimize this model by maximizing the log-likelihood
of all triplets, no matter true or false in a BioKG. However,
it is intractable to maximize the objective directly, since it

where KL denotes the KL divergence, and Q represents
the variational distribution of triplet candidates to be
verified. Equality in the above equation holds when
Q(VM ) = P (VM |VT ). We then use the variational EM
algorithm Ghahramani et al. [2000] to effectively optimize
the ELBO. The variational EM algorithm consists of an
expectation step (E-step) and a maximization step (M-step),
which will be called in an alternating fashion to train the
model: 1) In the E-step, we infer the posterior distribution
of the latent variables, where P is fixed, and Q is optimized
to minimize the KL divergence between Q(VM ) and
P (VM |VT ); 2) In the M-step, we learn the weights of the
logic rules wl in logistic region model, where Q is fixed, and
P is optimized to maximize the log-likelihood.
E-step: Inference Procedure
In the variational E-step, we fix P and update Q by inferring the posterior distribution with mean-field approximation,
which is based on the learned embeddings of the knowledge
embedding model we have trained,
Y
Q(VM ) =
Pembedding (τ ).
(7)
τ ∈M

Through minimizing the KL divergence between Q(VM )
and the true posterior distribution P (VM |VT ), the optimal
Q(VM ) is computed as
log Q(VM ) = EQ(VM B ) [log P (VM |VM B )] + const,

where VM B is the Markov blanket of VM , which contains
the triplets that appear together with VM in any grounding of
the logic rules. If there exists any triplet candidate that is not
verified yet in VM B , we replace it with a candidate which is
predicted as a true triplet by the knowledge graph embedding
model. With the equation above, our goal becomes finding a
distribution Q that satisfies the condition. To further optimize
the objective, we enhance the knowledge embedding model
by updating its training dataset with added verified triples,
which are predicted by the logistic regression model. In
particular, we first compute Prule (Vτ |VM B ) for each triplet
candidate τ . If P (Vτ = 1|VM B ) ≥ δ with δ being a
hyperparameter, then we treat τ as a true triplet and train
the knowledge graph embedding model to maximize the loglikelihood log Pembedding (Vτ = 1). Otherwise, the triplet is
treated as a negative example. In this way, the knowledge
captured by logic rules can be effectively distilled into the
knowledge graph embedding model.
M-step: Learning Procedure
In the M-step, which is also known as the learning step,
we learn the weights of logic rules in the logistic regression model. We fix Q and update the weights of logic
rules wl by maximizing the pseudo-likelihood function, i.e.,
EQ(VM ) [log P (VT , VM )].
EQ(VM ) [log P (VT , VM )]
X
= EQ(VM ) [
log Prule (VτM , VτT )]
τM ∈M,τT ∈T

= EQ(VM ) [

X

log Prule (Vτ |VM B )],

τ ∈M ∪T

where Vτ is the indicator of triplet τ . Vτ = 1 represents τ
being a true triplet. Otherwise, Vτ = 0 represents τ being a
false triplet.
In particular, for each true triplet τ ∈ T , we seek to
maximize Prule (Vτ = 1|VM B ). For each triplet candidate
τ ∈ M which needs to be verified, we treat Pembedding (Vτ =
1) as target for updating the probability Prule (Vτ = 1|VM B )
to minimize the difference between these two. In this way, the
knowledge graph embedding model essentially provides extra
supervision to benefit in learning the weights of logic rules.
Besides, triplets candidates distinguished by the knowledge
embedding model in E-step are filled into the Markov blanket.
Therefore, by alternating between the variational E-step and
an M-step, BioGRER allows information sharing between
the knowledge graph embedding model and the logistic
regression model, thus combines efforts from both sides, as
shown in Figure 1.

Experiments
Dataset
We evaluate the BioGRER on a open available COVID-19
knowledge graph (kg-covid-19)1 . This knowledge graph
incorporates up-to-date data extracted from biomedical
databases and literature, including drug, protein-protein
1

https://github.com/Knowledge-Graph-Hub/kg-covid-19/wiki

interactions, SARS-CoV-2 gene annotations, concept and
publication data from the CORD19 Wang et al. [2020]
data set. Since the entire graph of this kg-covid-19 is
super large, we sample a sub-graph (sub-kg-covid-19) for
experiments. Table 1 shows the detailed statistics of the
extracted sub-graph of kg-covid-19.
Data Set
sub-kg-covid-19

#Node
3,000

#Link
376,505

#Relation
107

Table 1: The statistics of the sub-kg-covid-19.

Evaluation Metrics and Settings
Poisoning Triplet Detection (PTD)
We define a task named poisoning triplet detection for
BioKG. Specifically, we put new false links to a given
knowledge graph and generate new false triplets accordingly.
This task is to identify all these new added false triplets.
However, annotating these false triplets is tedious for
checkers to make sure triplets are genuinely false. Therefore,
how to generate false triplets becomes a big concern. To
this end, we randomly generate new links and develop new
triplets for sub-kg-covid-19. In this process, we check the
entire knowledge graph to ensure that these new triplets do
not exist in kg-covid-19. We take these randomly generated
triplets as false triplets and get 10,000 at last. We take
5,000 of these false triplets and 5000 existing true triplets to
compose the validation set. We take the rest 5,000 of false
triplets and other 5,000 existing true triplets to compose the
testing set. We call this testing set as the “Large” testing set.
Some of new generated false triples may be missing true
triplets. However, the number of these cases is relatively
small in such a dense graph like kg-covid-19. We sample 100
triplets from 10,000 generated false triplets and manually
check them via searching in PubMed and Google. The result
is 97% of them cannot be supported by any evidence from
PubMed and Google. In other words, 97% of them are true
false triplets. We take these 97 manually labeled false triplets
and other 103 true triplets to compose a testing set of 200
samples. We call it the “Small” testing set.
Missing Triplet Prediction (MTP)
Missing triplets prediction is a knowledge graph completion
task, which is targeted at assessing the plausibility of triples
not present in a knowledge graph. For this task, we randomly
take out 10,000 triplets from sub-kg-covid-19 as the validation set and take out the other 10,000 triplets as the testing
set.
Metrics
We compare different methods on the tasks of poisoning
triplet detection and missing triplet prediction. We formulate
poisoning triplet detection as a triplet classification task. For
each triplet in the testing set, our model predicts whether it
is true or false. Therefore, we follow the standard evaluation
metrics for the classification task, i.e., Precision (P), Recall
(R) and F-score (F). We formulate missing triplets prediction
as a ranking task. For each triplet in the testing set, we mask
the head or the tail entity, and let each compared method
predict the masked entity. Following existing studies Bordes
et al. [2013], we apply the filtered setting during evaluation.

The Mean Rank (MR), Mean Reciprocal Rank (MRR) and
Hit@K (H@K) are treated as the evaluation metrics.

matching, semantic embedding, soft constraint mining, and
semantic consistency checking.

Settings
We search for all the possible supporting rules and negatinglike rules from the observed triplets to generate the candidate
logic rules. We compute the empirical precision of each rule
|
for supporting rules, i.e., pl = |R∩T
|R| . R is the set of triplets
generated with logic rule l in the knowledge graph. They
may or may not exist in the knowledge graph. T is the
set of true triplets that do exist in knowledge graph. In our
study, we assume all triplets in the sub-kg-covid-19 are true.
We only select supporting rules whose empirical precision is
larger than a threshold β. Besides, we compute the empirical
|
precision of each negating-like rule as pl = |D∩T
|D| . D is
the set of triplets that should be negated with logic rule
l in the knowledge graph. However, some of them might
exist in the knowledge graph. We only keep supporting rules
whose empirical precision is 1. We consider two variants
for our approach, where BioGRER uses only Q to infer
the plausibility of triplet candidates during the evaluation.
In contrast, BioGRER* uses a weighted-sum of Q and P ,
i.e., Q + λP . We use TransE Bordes et al. [2013] as the
default knowledge graph embedding model to optimize Q.
We update the weights of logic rules with gradient descent.
We select the learning rate λ for stochastic gradient descent
among {0.001, 0.01, 0.1}, the margin γ among {1, 2, 10},
and the dimension of embedding d in {10, 20, 30, 40, 50} on
the validation set. The optimal configurations are d = 30, γ
= 1, β = 0.3, λ = 1.

Main Results

Compared Models
For BioKG refinement tasks, we compare with the following
three types of baselines to evaluate BioGRER.
Rule-based models apply rules to measure the correctness of triplet candidates. For the rule-based methods, we
compare with the Markov logic network (MLN) Richardson
and Domingos [2006] and the Bayesian logic programming
(BLP) method De Raedt and Kersting [2008], which model
logic rules with Markov networks and Bayesian networks
respectively. Besides, we compare with CHEEP Fionda and
Pirrò [2018] which leveraged the knowledge schema to generate schema-level patterns and verify the knowledge graph
with patterns.
Knowledge graph embedding models can learn representations of links and nodes in knowledge graph and compute
plausibility of triplet candidates with a score function. For
the knowledge graph embedding models, we choose five
representative models to compare with, including ConvE
Dettmers et al. [2018], ComplEx Trouillon et al. [2016],
HolE Nickel et al. [2015b], DistMult Yang et al. [2015] and
TransE Bordes et al. [2013].
Hybrid models combine different resources to verify the
correctness of triplet candidates. We compare with pLogicNet
Qu and Tang [2019], RUGE Guo et al. [2018] and NNE-AER
Ding et al. [2018], which are hybrid methods that combine
knowledge graph embedding and logic rules. We also compare Node+Path Chen et al. [2020a], which combines lexical

We conduct experiments for poisoning triplet detection task
and missing triplet prediction task with different models. A
summary of the results is displayed in table 2. The “P@L”,
“R@L” and “F@L” columns show the results on the large
testing set for the poisoning triplet detection task. The
“P@S”, “R@S” and “F@S” columns show the results on the
manually labeled small testing set for the poisoning triplet
detection task. It is apparent that BioGRER significantly
outperforms all baseline models, including rule-based
models, knowledge graph embedding models, and hybrid
models on poisoning triplets detection. Compared with
rule-based models, BioGRER applies the knowledge graph
embedding technique to improve detection performance.
In addition to those rules that support triplets, our model
encodes all possible rules that negate triplets. This is a
different way of encoding logic rules compared with existing
rule-based studies. BioGRER outperforms knowledge graph
embedding models, as it exploits the knowledge encoded
within the logic rules. Moreover, BioGRER consistently
performs better than hybrid methods, which shows the
superiority of negating-like rules for poisoning triplet
detection. BioGRER* slightly outperforms BioGRER due to
the complementary information captured by Q and P . It is
reasonable that combining them is better than using single
alone. For the missing triplet prediction, BioGRER shares a
similar trend with the poisoning triplet detection task but the
improvements are limited, indicating that negating-like rules
for the missing triplet prediction task are not as effective as
for the poisoning triplet detection task.

Analysis of Different Rule Patterns
We consider four rule patterns, including two supporting rule
patterns and two negating-like rule patterns in our model.
To deep understand these rule patterns, we systematically
investigate the effect of each rule pattern. The results of varying combinations are presented in table 3. The results show
that most rule patterns can lead to improvement compared
to the model without logic rules. Moreover, the effects of
different rule patterns are quite different. Negating-like rule
patterns are more effective than supporting rule patterns. In
negating-like rule patterns, the “Block” rule achieves better
performances than the “Conflict” rule.

Effect of Knowledge Graph Embedding Models
Different knowledge graph embedding models might affect
the BioGRER differently. Thus, we compare the performance
of BioGRER* with representative knowledge graph embedding models for both tasks. The results are displayed in
table 4. “PTD@L” and “PTD@S” columns report the F-score
of poisoning triplet detection over the large and small testing
set. The “MTP” column presents the H@1 of missing triplet
prediction task. The results indicate that our model is stable
for different knowledge graph embedding models.

Model Type
Rule-based

KG Embedding

Hybrid
Our Model

Poisoning Triplet Detection

Model
BLP
MLN
CHEEP
TransE
DistMult
HolE
ComplEx
ConvE
RUGE
NNE-AER
pLogicNet
Node+Path
BioGRER
BioGRER*

P@L
1.07
1.46
99.73
6.79
6.43
4.31
5.07
5.11
9.31
8.63
9.77
16.16
67.21
75.13

R@L
1.22
1.87
2.67
8.14
7.36
4.73
5.74
5.33
8.76
7.87
8.63
10.21
28.32
29.21

F@L
1.14
1.63
5.20
7.40
6.86
4.51
5.38
5.21
9.02
8.23
9.16
12.51
39.85
42.06

P@S
0.55
1.06
100
6.06
6
4.08
4.95
4.9
8.43
7.14
8.86
15.71
65.85
72.5

R@S
1.03
2.06
3.09
6.18
5.15
4.12
5.15
5.15
7.21
6.18
7.21
11.34
27.83
29.89

Missing Triplet Prediction
F@S
0.71
1.39
5.99
6.12
5.54
4.09
5.05
5.02
7.77
6.62
7.95
13.17
39.12
42.32

H@1
0.03
0.03
0.03
3.83
1.26
0.07
0.12
0.10
3.92
5.64
4.17
5.37
6.31
6.46

MRR
0.007
0.009
0.011
0.082
0.037
0.016
0.031
0.027
0.082
0.103
0.084
0.096
0.115
0.117

MR
4765
4431
4167
820
1125
2763
1638
1869
816
567
817
779
579
564

Table 2: The overall performance of two tasks over COVID-19 knowledge graph. H@1, P, R and F are %. (p-value ≤ 0.05)
Poisoning Triplet Detection

Logic Rule
Without All
Without Support
Without Negate
Symmetric
Transitive
Conflict
Block

P@L
6.79
71.34
9.79
9.71
8.84
17.16
70.23

R@L
8.14
29.21
8.62
8.62
8.62
8.93
28.89

F@L
7.40
41.45
9.17
9.13
8.73
11.75
40.94

P@S
6.06
69.04
9.33
8.43
8.23
15.68
67.5

R@S
6.18
29.89
7.21
7.21
7.21
8.24
27.83

Missing Triplet Prediction
F@S
6.12
13.06
8.13
7.77
7.69
10.80
39.41

H@1
3.83
6.13
4.17
4.13
4.15
4.66
5.87

MRR
0.082
0.115
0.085
0.077
0.081
0.101
0.114

MR
820
571
812
817
813
764
581

Table 3: The overall performance of two tasks over COVID-19 knowledge graph. H@1, P, R and F are %. (p-value ≤ 0.05)
KGE
PTD@L PTD@S MTP
protein)=1 ⇒ V(MKRN3 gene, has gene product, NPTX1
TransE
42.06
42.32
6.46
human protein)=0. Given MKRN3 gene, located at the
DistMult
41.66
41.07
6.46
15th human chromosome, producing MKRN3 human
ComplEx
40.91
40.31
6.14
protein and MKRN3 human protein interacting with NPTX1
human protein, it is impossible to have MKRN3 gene
Table 4: The performance of the BioGRER* with different
producing NPTX1 human protein, which is produced by
knowledge graph embedding models.
NPTX1 gene, located at the 17th human chromosome.
Case Study of Logic Rules
This block rule is very effective for negating the triplet
(MKRN3 gene, has gene product, NPTX1 human protein).
Last but not least, we conduct case studies to better
All knowledge graph embedding baselines predict this triplet
understand the extracted logic rule patterns and specific logic
as true, while BioGRER predicts it as false because of
rules. Transitive Rule The transitive rule “tributary of (x,y)
incorporating this block rule. Conflict Rule. The conflict
∧ drains(y,z) ⇒ part of (x,z)” has an example, i.e.,
rule “has primary input(x,y) ⇒ has primary output(x,y)=0”
V(facial vein, tributary of, internal jugular vein)=1 ∧
has an example, i.e., V(morphine catabolic process,
V(internal jugular vein, drains, face)=1 ⇒ V(facial vein,
has primary input, morphine)=1 ⇒ V(morphine catabolic
part of, face)=1. Given facial vein being a tributary of
process, has primary output, morphine)=0. The morphine
internal jugular vein, and internal jugular vein draining
catabolic
process, which is a biological process, takes
from face, we have facial vein being a part of face.
the morphine as input resulting in the breakdown of
This example shows that the transitive rule is reasonable
morphine. Therefore, morphine catabolic process is
and benefit the verification of “part of” links in BioKG.
not able to have “has primary output” relation with
Symmetric Rule. The symmetric rule “interacts with(x,y)
morphine. This conflict rule is very effective to negate
⇒ interacts with(y,x)” has an example, i.e., V(CASP1
the triplet has primary output(x,y) with the valid
gene, interacts with, IFITM2 protein)=1 ⇒ V(IFITM2
has
primary input(x,y).
protein, interacts with, CASP1 gene)=1. Given CASP1
gene interacting with IFITM2 protein, we have IFITM2
Conclusions
protein interacting with CASP1 gene. This rule could
This paper studied the knowledge graph refinement problem
increase the plausibility of interacts with(A,B) links with
the existence of interacts with(B,A). Block Rule. The
and proposed BioGRER to combine the advantages of supblock rule “has gene product(x,y) ∧ interacts with(y,z) ⇒
porting and negating-like logic rules and graph embedding
has gene produc(x,z)=0” has an example, i.e., V(MKRN3
for triplet verification. To jointly model these two clues, we
gene, has gene product, MKRN3 human protein)=1 ∧
trained them alternatively with the variational EM algorithm.
V(MKRN3 human protein, interacts with, NPTX1 human
To evaluate the effectiveness of BioGRER, we defined the

poisoning triplet detection task and conducted experiments
for this task. Besides, we conducted experiments on a standard knowledge graph completion task. Experimental results
on both tasks demonstrated that our model could significantly
outperform competitive baselines. Furthermore, BioGRER
only utilized the information of the BioKG itself instead of
external evidence resources. Therefore, our model can be
incremented by adding external evidence resources for better
performance.

References
Sally H Adams, M Jane Park, Jason P Schaub, Claire D
Brindis, and Charles E Irwin Jr. Medical vulnerability
of young adults to severe covid-19 illness—data from the
national health interview survey. Journal of Adolescent
Health, 2020.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,
Jason Weston, and Oksana Yakhnenko.
Translating
embeddings for modeling multi-relational data.
In
Advances in neural information processing systems, pages
2787–2795, 2013.
Ermei Cao, Difeng Wang, Jiacheng Huang, and Wei Hu.
Open knowledge enrichment for long-tail entities. In
Proceedings of The Web Conference 2020, pages 384–394,
2020.
Chris R Cardwell, Christian C Abnet, Marie M Cantwell, and
Liam J Murray. Exposure to oral bisphosphonates and risk
of esophageal cancer. JAMA, 304(6):657–663, 2010.
Jiaoyan Chen, Xi Chen, Ian Horrocks, Erik B. Myklebust,
and Ernesto Jimenez-Ruiz. Correcting knowledge base
assertions. In Proceedings of The Web Conference 2020,
pages 1537–1547, 2020.
Q Chen, A Allot, and Z Lu. Keep up with the latest
coronavirus research. Nature, 579(7798):193, 2020.
Luc De Raedt and Kristian Kersting. Probabilistic inductive
logic programming. In Probabilistic Inductive Logic
Programming, pages 1–27. Springer, 2008.
Tim Dettmers, Minervini Pasquale, Stenetorp Pontus, and
Sebastian Riedel. Convolutional 2d knowledge graph
embeddings. In Proceedings of the 32th AAAI Conference
on Artificial Intelligence, pages 1811–1818, February
2018.
Boyang Ding, Quan Wang, Bin Wang, and Li Guo.
Improving knowledge graph embedding using simple
constraints. In Proceedings of the 56th Annual Meeting
of the Association for Computational Linguistics, pages
110–121, Melbourne, Australia, 2018. Association for
Computational Linguistics.
Valeria Fionda and Giuseppe Pirrò. Fact checking via
evidence patterns. In Proceedings of the 27th International
Joint Conference on Artificial Intelligence, pages 3755–
3761, 2018.
Mohamed H Gad-Elrab, Daria Stepanova, Jacopo Urbani, and
Gerhard Weikum. Exfakt: A framework for explaining
facts over knowledge graphs and text. In Proceedings of

the Twelfth ACM International Conference on Web Search
and Data Mining, pages 87–95, 2019.
Mohamed H Gad-Elrab, Daria Stepanova, Jacopo Urbani, and
Gerhard Weikum. Tracy: Tracing facts over knowledge
graphs and text. In The World Wide Web Conference, pages
3516–3520, 2019.
Zoubin Ghahramani, Matthew J Beal, et al. Graphical models
and variational methods. Advanced mean field methodstheory and practice. MIT Press, 2000.
Jane Green, Gabriela Czanner, Gillian Reeves, Joanna
Watson, Lesley Wise, and Valerie Beral. Oral bisphosphonates and risk of cancer of oesophagus, stomach, and
colorectum: case-control analysis within a uk primary care
cohort. BMJ, 341, 2010.
Shu Guo, Quan Wang, Lihong Wang, Bin Wang, and Li Guo.
Knowledge graph embedding with iterative guidance from
soft rules. In Proceedings of the Thirty-Second AAAI
Conference on Artificial Intelligence, 2018.
Furong Li, Xin Luna Dong, Anno Langen, and Yang Li.
Knowledge verification for long-tail verticals. Proceedings
of the VLDB Endowment, 10(11):1370–1381, 2017.
Peng Lin, Qi Song, and Yinghui Wu. Fact checking in
knowledge graphs with ontological subgraph patterns.
Data Science and Engineering, 3(4):341–358, 2018.
Peng Lin, Qi Song, Yinghui Wu, and Jiaxing Pi. Discovering
patterns for fact checking in knowledge graphs. Journal of
Data and Information Quality (JDIQ), 11(3):1–27, 2019.
Maximilian Nickel, Kevin Murphy, Volker Tresp, and
Evgeniy Gabrilovich. A review of relational machine
learning for knowledge graphs. Proceedings of the IEEE,
104(1):11–33, 2015.
Maximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio.
Holographic embeddings of knowledge graphs.
In
Proceedings of the Thirtieth AAAI Conference on Artificial
Intelligence, February 12-17, 2016, Phoenix, Arizona,
USA, pages 1955–1961. AAAI Press, 2015.
Meng Qu and Jian Tang. Probabilistic logic neural networks
for reasoning.
In Advances in Neural Information
Processing Systems, pages 7712–7722, 2019.
Matthew Richardson and Pedro Domingos. Markov logic
networks. Machine learning, 62(1-2):107–136, 2006.
Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang.
Rotate: Knowledge graph embedding by relational rotation
in complex space. In 7th International Conference on
Learning Representations, ICLR 2019, New Orleans, LA,
USA, May 6-9, 2019, 2019.
Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric
Gaussier, and Guillaume Bouchard. Complex embeddings
for simple link prediction.
In Proceedings of the
33nd International Conference on Machine Learning,
ICML 2016, New York City, NY, USA, June 19-24,
2016, volume 48 of JMLR Workshop and Conference
Proceedings, pages 2071–2080. JMLR.org, 2016.

Giuliana Viglione. How many people has the coronavirus
killed? Nature, 585(7823):22–24, 2020.
Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell
Reas, Jiangjiang Yang, Darrin Eide, Kathryn Funk, Rodney
Kinney, Ziyang Liu, William Merrill, et al. Cord-19: The
covid-19 open research dataset. ArXiv, 2020.
Yu-Tao Xiang, Wen Li, Qinge Zhang, Yu Jin, Wen-Wang
Rao, Liang-Nan Zeng, Grace KI Lok, Ines HI Chow, Teris
Cheung, and Brian J Hall. Timely research papers about
covid-19 in china. The Lancet, 2020.
Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and
Li Deng. Embedding entities and relations for learning
and inference in knowledge bases. In 3rd International
Conference on Learning Representations, ICLR 2015,
San Diego, CA, USA, May 7-9, 2015, Conference Track
Proceedings, 2015.

