Developments and applications of Shapley effects to reliability-oriented
sensitivity analysis with correlated inputs
Marouane Il Idrissia , Vincent Chabridona,b , Bertrand Ioossa,b,c,d

arXiv:2101.08083v1 [math.ST] 20 Jan 2021

a EDF

Lab Chatou, 6 Quai Watier, 78401 Chatou, France
b SINCLAIR AI Lab., Saclay, France
c Institut de Mathématiques de Toulouse, 31062 Toulouse, France
d Corresponding Author - Email: bertrand.iooss@edf.fr - Phone: +33130877969

Abstract
Reliability-oriented sensitivity analysis methods have been developed for understanding the influence
of model inputs relatively to events characterizing the failure of a system (e.g., a threshold exceedance
of the model output). In this field, the target sensitivity analysis focuses primarily on capturing
the influence of the inputs on the occurrence of such a critical event. This paper proposes new
target sensitivity indices, based on the Shapley values and called “target Shapley effects”, allowing
for interpretable influence measures of each input in the case of dependence between the inputs. Two
algorithms (a Monte Carlo sampling one, and a given-data algorithm) are proposed for the estimation
of these target Shapley effects based on the ℓ2 norm. Additionally, the behavior of these target Shapley
effects are theoretically and empirically studied through various toy-cases. Finally, applications on two
realistic use-cases (a river flood model and a COVID-19 epidemiological model) are discussed.
Keywords: sensitivity analysis, reliability analysis, Sobol’ indices, Shapley effects, input correlation

1. Introduction
Nowadays, numerical models are intensively used in all industrial and scientific disciplines to describe physical phenomena (e.g., systems of ordinary differential equations in ecosystem modeling,
finite element models in structural mechanics, finite volume schemes in computational fluid dynamics)
in order to design, analyze or optimize various processes and systems. In addition to this tremendous
growth in computational modeling and simulation, the identification and treatment of the multiple
sources of uncertainties has become an essential task from the early design stage to the whole system
life cycle. As an example, such a task is crucial in the management of complex systems such as those
encountered in energy exploration and production [1] and in sustainable resource development [2].
In addition, the emergence of global sensitivity analysis (GSA) of model outputs played a fundamental role in the development and enhancement of these numerical models (see, e.g., [3, 4] for recent
reviews). Mathematically, if the model inputs (resp. output) are denoted by X (resp. Y ) and the
model is written G(·), such as
Y = G(X),

(1)

GSA aims at understanding the behavior of Y with respect to (w.r.t. ) X = (X1 , . . . , Xd )⊤ the vector
of d inputs. GSA has been intensively used as a versatile tool to achieve various goals: for instance,

quantifying the relative importance of inputs regarding their influence on the output (a.k.a. ”ranking”),
identifying the most influential inputs among a large number of inputs (a.k.a. screening) or analyzing
the input-output code behavior [5, 6].
When the complex systems are critical or need to be highly safe, numerical models can also be of
great help for risk and reliability assessment [7]. Indeed, to track potential failures of a system (which
could lead to dramatic environmental, human or financial consequences), numerical models allow to
simulate its behavior far from its nominal one (see, e.g., [8] in flood hazard assessment). Analytical
or experimental approaches are often out of the question here. Based on these simulations, the tail
behavior of the output distribution can be studied and typical risk measures can be estimated [9].
Among others, the probability that the output Y exceeds a given threshold value t ∈ R, given by
P(Y > t) and often called a failure probability, is widely used in many applications. When {Y >
t} is a rare event (i.e., associated to a very low failure probability), advanced sampling-based or
approximation-based techniques [10] are required to estimate properly the failure probability. In this
very specific context, dedicated sensitivity analysis methods have been developed, especially in the
structural reliability community (see, e.g., [11, 12, 13]). In such a framework, called reliability-oriented
sensitivity analysis (ROSA) [14, 15], the idea is to provide importance measures dedicated to the
problem of rare event estimation.
To make it more formal, standard GSA methods mostly focus on quantities of interest (QoI)
characterizing the central part of the output distribution (e.g., the variance for Sobol’ indices [16], the
entire distribution for moment-independent indices [17]), while ROSA methods focus on risk measures
and their associated practical difficulties (e.g., costly to estimate, inducing a conditioning on the
distributions, non-trivial interpretation of the indices). Following [18], ROSA methods can be analyzed
regarding the type of study they consider, i.e., according the following two categories:
• target sensitivity analysis (TSA) aims at catching the influence of the inputs (considering their
entire input domain) on the occurrence of the failure event. Basically, this implies to consider
the random variable defined by the indicator function 1{G(X)>t} of the failure domain ;
• conditional sensitivity analysis aims at studying the influence of the inputs on the conditional
distribution of the output Y |{G(X) > t}, i.e., exclusively within the critical domain. By Eq. (1),
a conditioning also appears on the inputs’ domain.
Various indices have been proposed to tackle these two types of studies (see, e.g., [19, 13, 15, 20]).
The present paper is dedicated to ROSA (under the assumption that the QoI is a failure probability)
and focuses on a TSA study. However, a new issue for TSA is addressed here: the possible statistical
dependence between the inputs.
Indeed, most of the common GSA methods (and it is similar for the ROSA ones) have been
developed under the assumption of independent inputs. As an example, the well-known Sobol’ indices
[16] which rely on the so-called functional analysis of variance (ANOVA) and Hoeffding decomposition
[21], can be directly interpreted as shares of the output variance that are due to each input and
combination of inputs (called “interactions”) as long as the inputs are independent.
When the inputs are dependent, the inputs’ correlations dramatically alter the interpretation of
the Sobol’ indices. To handle this issue, several approaches have been investigated in the literature.

2

For instance, [22] proposed to estimate indices for groups of correlated inputs. However, this approach
does not allow to quantify the influence of individual inputs. Amongst other similar works, [23, 24]
proposed to extend the functional ANOVA decomposition to a more general one (e.g., taking the
covariance into account). However, the indices obtained for these approaches can be negative, which
limits their practical use due to interpretability issues. Parallel to this, other works (see, e.g., [25, 26])
considered a Gram–Schmidt procedure to decorrelate the inputs and proposed to estimate two kinds of
contributions for each variable (an uncorrelated one and a correlated one). These works finally resulted
in the proposition of a set of four Sobol’ indices (instead of the two standard ones which are the firstorder index and total index in the independent case) which enable to fully capture the correlation
effects in the GSA [27]. Despite this achievement, this approach remains difficult to implement in
practice (see [28] for extensive studies). Finally, the VARS approach [29] (allowing a thorough analysis
of the inputs-output relationships) can handle inputs’ correlation but is out of scope of the present
work which only focuses on variance-based sensitivity indices, directly computed from the numerical
model.
Recently, another research track has been developed by considering another type of indices: the
Shapley effects. The initial formulation originates from the “Shapley values” developed in the field of
Game Theory [30, 31]. The underlying idea is to fairly distribute both gains and costs to multiple
players working cooperatively. By analogy with the GSA framework, the inputs can be seen as the
players while the overall process can be seen as attributing shares of the output variability to the
inputs. Considering the variance of the output in a GSA formulation leads to the so-called “Shapley
effects” proposed by [32]. In the same vein, [33, 34, 28] bridge the gap between Sobol’ indices and
Shapley effects while illustrating the usefulness of these new indices to handle correlated inputs in the
GSA framework.
Thus, the present work tries to extend the use of Shapley effects to the ROSA context. To sum
up, the idea is to provide a ROSA index enabling to perform TSA (i.e., capturing the influence of
the inputs on a risk measure, typically a failure probability here) under the constraint of dependent
inputs. Moreover, this work relies on the use of recent promising results and numerical tools (both in
field of TSA [35] and Shapley effects’ estimation [36]).
The outline of this paper is the following. Section 2 is devoted to a pedagogical introduction of
the statistical dependence issues for variance-based sensitivity indices, that can be solved by Shapley
effects. Section 3 presents a new formulation of TSA based on Shapley effects leading to target Shapley
effects, while Section 4 develops two algorithms for their estimation. Section 5 provides illustrations
on simple toy-cases which give analytical expressions of the target Shapley effects, allowing to deeply
study their behavior. Section 6 applies these new sensitivity indices to two use-cases: a simplified
model of a river flood and an epidemiological model related to the Covid-19 disease. Finally, Section
7 gives conclusions and research perspectives.
All along the paper, the mathematical notation E(·) (resp. V(·)) will represent the expectation
(resp. variance) operator.

3

2. Variance-based sensitivity analysis with dependent inputs: the Shapley solution
While devoted to computer experiments, GSA has closed connections with multivariate data analysis and statistical learning [37, 38]. Indeed, in all these topics, one important issue is often to provide
a weight to some variables (the inputs) w.r.t. its impact on another variables (the outputs). Depending
on the domain, such a weight can be either called a “sensitivity index” or an “importance measure”.
A very convenient way is to base these weights on the ANOVA (analysis of variance) decomposition
[37, 16] of the output variance. Indeed, such a decomposition provides a natural sharing of the output
variance in shares due to each input. The principle of the “variance-based sensitivity indices” [5] consists then in understanding how to separate the contribution of each Xi in the variance of Y . However,
due to potential statistical dependencies between inputs, this sharing cannot be directly performed.
Starting from a simple case such as the linear model, chosen for pedagogical purposes, this section
provides a reminder on this topic while illustrating the great interest of Shapley effects in practice.
2.1. Understanding the correlation issues via the linear model case
In this section, the aim is to quantify the relative importance of d scalar inputs Xj (j = 1, . . . , d)
by fitting on a data sample (coming from the model Eq. (1)) a linear regression model so as to predict
a scalar output Y :
Y (X) =

d
X

βj X j + ǫ ,

(2)

j=0

where X0 = 1, β = (β0 , . . . , βd )⊤ ∈ Rd+1 is the effects
vector and ǫ ∈R the model’s error of variance σ 2 .

(i)

(i)

If a sample of inputs and outputs (Xn , Yn ) = X1 , . . . , Xd , Y (i)

i=1,...,n

is available (with n > d),

the Ordinary Least Squares method (see, e.g., [37]) can easily be used to estimate the parameters β
and σ 2 in the linear regression model in Eq. (2). Moreover, one obtains the predictor Yb (x∗ ) of Y at

any prediction point x∗ . An important validation metric of this model is the classical coefficient of
determination given by:

RY2 (X) =

n h
i2  h
i2
X
Yb (X (i) ) − Ȳ
Y (i) − Ȳ

(3)

i=1

where Ȳ is the output empirical mean. RY2 (X) represents the percentage of output variability explained
by the linear regression model of Y on X. Finally, from Eq. (2), the variance decomposition expresses
as:
d
X
X
βj2 V(Xj ) + 2
βj βk Cov(Xj , Xk ) + σ 2 .
(4)
V(Y ) =
j=1

k>j

In the specific case of independent inputs, the covariance terms cancel and the standard ANOVA
P 2
(i.e., V(Y ) =
βj V(Xj ) + σ 2 ) is obtained. Then, global sensitivity indices, called Standardized

Regression Coefficients (SRC), can be directly computed:
SRCj = βj

q
V(Xj )/V(Y ) .

(5)

The estimation of the SRC is made by replacing the terms in Eq. (5) by their estimates. Interestingly,
this metric for relative importance is signed (thanks to the regression coefficient sign), giving the sense

4

of variation of the output w.r.t. each input. Moreover, SRC2j represents a share of variance and the
sum of all the SRC2j approaches R2 (i.e., the amount of explained variance by the linear model). Note
that, in a perfect linear regression model (i.e., without any random error term ǫ), SRCj is equal to
the linear Pearson’s correlation coefficient between Xj and Y (denoted by ρ(Xj , Y )). Note also that
the ANOVA and SRC2 extend to the functional ANOVA and Sobol’ indices in the general (non-linear
model) case (see Appendix A).
When the inputs are dependent, the main concern is to allocate the covariance terms in Eq. (4) to
the various inputs. In this case, the Partial Correlation Coefficient (PCC) has been promoted in GSA
[39, 5] as a substitute to the SRC, in order to cancel the effects of other inputs when allocating the
weight of one input Xj in the variance of Y :
d
d
PCCj = ρ(Xj − X
−j , Y − Y−j )

(6)

d
where X−j is the vector of all the d inputs except Xj , X
−j is the prediction of the linear model
expressing Xj w.r.t. X−j and Yd
is
the
prediction
of
the
linear
model Y w.r.t. X−j . However, PCC
−j

is not a right sensitivity index of the input. Indeed, it consists in measuring the linear correlation
between Y and Xj by fixing X−j , and is then a measure of the linearity (and not the importance)
between the output and one input.
Instead of controlling other inputs X−j such as done in the PCC, the Semi-Partial Correlation
Coefficient (SPCC) quantifies the proportion of the output variance explained by Xj after removing
the information brought by X−j (on Xj ) [40]:
d
SPCCj = ρ(Xj − X
−j , Y ) .

(7)

SPCC can also be expressed by using the relation SPCC2j = RY2 (X) − RY2 (X−j ) , which clearly shows

that SPCC gives the additional explanatory power of the input Xj in the linear regression model of Y

on X. However, the SPCC of highly correlated inputs will be small, despite their “real” explanatory
power on the output. This aspect seems to be the main drawback of SPCC and probably explains its
lack of popularity for GSA purposes.
In order to give an intuitive view of the multicollinearity issue (i.e., multiple linear regression with
correlated inputs), we use Venn diagrams (see Figure 1), by considering two inputs X1 and X2 and
one output Y . From Figure 1, the coefficient of determination can be written as:
RY2 (X1 ,X2 ) =

a+b+c
,
a + b + c + σ2

(8)

where a + b + c + σ 2 is equal to the variance of Y and a + b + c represents the part of explained
variance by the regression model (with b = 0 in the uncorrelated case). In this elementary example,
the previously introduced sensitivity indices are given by [41]:
SRC21
PCC21
SPCC21

= (a + b)/(a + b + c + σ 2 ) , SRC22
= a/(a + σ 2 ) ,
PCC22
SPCC22

2

= a/(a + b + c + σ ) ,

5

=
=
=

(c + b)/(a + b + c + σ 2 ) ,
c/(c + σ 2 ) ,
2

c/(a + b + c + σ ) .

(9)

Thus, one can understand the limitations of SRC, PCC and SPCC when correlation is present: the
variance share which comes from the correlation between inputs (i.e., the b value in Figure 1 - right) is
allocated two times with the SRC but not allocated at all with SPCC, while PCC does not represent
any variance sharing.

Figure 1: Inspired from [41]. Illustration scheme of the effect of two inputs X1 and X2 on an output variable Y when
they are: uncorrelated (left) or correlated (right).

The three problems above can be solved by using another sensitivity index which finds a way
to partition the R2 among the d inputs: the LMG [42, 43] (acronym based on the authors’ names,
i.e., “Lindeman - Merenda - Gold”) uses sequential sums of squares from the linear model and obtains
an overall measure by averaging over all orderings of inputs. Mathematically, let u be a subset of
indices in the set of all subsets of {1, . . . , d} and Xu = (Xj : j ∈ u) a group of inputs. LMG is based on

the measure of the elementary contribution of any given variable Xj to a given subset model Y (Xu )
by the increase in R2 that results from adding that predictive variable to the regression model:
LMGj =

1
d!

X

π∈permutations
of {1,...,d}

i
h
RY2 (Xv∪{j} ) − RY2 (Xv )

(10)

with v the indices entered before j in the order π. In Eq. (10), the sum is performed over all the
permutations of {1, . . . , d}. For the case of two inputs (see Figure 1), we can easily show that:
LMG1 = (a + b/2)/(a + b + c + σ 2 ) , LMG2 = (c + b/2)/(a + b + c + σ 2 ) .

(11)

Then, in the LMG framework, the RY2 (X1 ,X2 ) has been perfectly shared into two parts with an equitable
distribution of the b term between X1 and X2 .
This allocation principle exactly corresponds to the application of the Shapley values [30] on the
linear model. This attribution method has been primarily used in cooperative game theory, allowing
for a cooperative allocation of resources between players based on their collective production (see
Appendix B for a more formal definition). The Shapley values solution consists in fairly distributing
both gains and costs to several actors working in coalition. In situations when the contributions of
each actor are unequal, it ensures that each actor gains as much or more as they would have from
acting independently. Now, if the actors are identified with a set of inputs and the value assigned
to each coalition is identified to the explanatory power of the subset of model inputs composing the
coalition, one obtains the LMG in Eq. (10).

6

2.2. Shapley effects
In the general case with no hypothesis on the form of the model G(·) (Eq. (1)), variance-based
sensitivity indices have been extensively developed [16, 5] and applied for GSA of complex models
(see, e.g., [44]). Indeed, in the independent inputs’ case, it allows a variance decomposition of the
model output in different shares (called “Sobol’ indices”) induced by each input and each possible
interaction between inputs in the model (see Appendix A for the theoretical details).
For the dependent inputs’ case, ideas coming from game theory and Shapley values (as for LMG
in Eq. (10)), have been recently introduced [32] in order to measure input influence by
Shj =

1
d

X d − 1−1
(val(A ∪ {j}) − val(A)) ,
|A|

(12)

A⊂{−j}

where val(A) is the so-called value function (which is, somehow a cost function) assigned to a subset
A ∈ Pd of inputs, Pd is the set of all possible subsets of {1, . . . , d}, {−j} denotes the set of indices

{1, . . . , d} \ j and |A| is the cardinal of A.
For GSA purposes, [32] proposes to use the so-called “closed Sobol’ indices” as the value function:
clos
val(A) = SA
=



V E G(X) XA
,
V (G(X))

(13)

where XA denotes the subset of inputs selected by the indices in A (XA = (Xi )i∈A ). The attribution
properties of the Shapley values applied to this particular cost function, leads to the definition of the
Shapley effects:

−1 

1 X
d−1
clos
clos
Shj =
(14)
− SA
SA∪{j}
d
|A|
A⊂{−j}

These Shapley effects allow for a quantification of influence for each input, which intrinsically takes
into account both interaction and dependence. Moreover, two important properties of the Shapley
effects (Shj , j = 1, . . . , d) allows for an easy interpretation: they sum up to one and are non-negative.
They allow for input ranking, in terms of influence, by allocating each input a percentage of the model
output’s variance. These indices have been extensively studied in [33, 34]. An alternate way of defining
the Shapley effects has been proposed, by taking the following cost function:
val(A) =



E V G(X)|XA
V (G(X))

(15)

where A = {1, . . . , d} \ A which lead to the equivalent definition of the Shapley effects in Eq. (14).
This results allows for alternate estimation methods, as outlined in [45].
In order to illustrate the allocation system of the Shapley effects, one can first consider a model

7

with three inputs X = (X1 , X2 , X3 )⊤ . From Eq. (14), one gets:
1 clos
S
3 1
h
i

1
clos
clos
− S3clos
− S2clos + S{1,3}
S{1,2}
+
6

1 clos
clos
+ S{1,2,3} − S{2,3}
.
3

Sh1 =

In the case where the three inputs are independent, one obtains:

1
1
1
Sh1 = S1 + S{1,2} + S{1,3} + S{1,2,3}
2
2
3
where one can notice that the Shapley values quantification (in the independent case) consists of the
initial Sobol’ index of the studied input, plus an equal share of the interaction effects between all the
involved inputs. However, if dependence between inputs is assumed, this behavior cannot be clearly
illustrated, except in the linear case (see Subsection 2.1).

clos
clos
The Shapley increment SA∪{j}
− SA
can be interpreted as being a quantification of the residual

clos
effects of the input j in relation to the subset of variables A. If SA
is believed to contain the initial

effects of A, plus their interaction effects, and any effects due to the dependence of the inputs in A,
then the Shapley increment quantifies the initial effect of the input j, its interaction effect with A, and
the effects due to its dependence with the inputs in A. Then, the Shapley attribution system weights
all these residual effects, in order to equally redistribute the interaction or dependence effects between
the involved inputs, in the same fashion as the LMG in the linear model case, as depicted in Section
2.1.
It is important to note that the above mentioned behavior of the Shapley effects cannot be verified
for any type of dependence structure, due to the lack of a univocal functional decomposition in the case
of dependent inputs. However, this behavior has been highlighted in analytical cases in [34] (mainly
for Gaussian inputs with a linear correlation structure).
3. Reliability-oriented Shapley effects for target sensitivity analysis
3.1. A brief overview of reliability-oriented sensitivity analysis
When focusing on complex systems, one often needs to prevent from possible critical events, which
have a low probability of occurring but are associated to a failure of the system. Such a failure might
have possible dramatic consequences regarding various factors (e.g., human, environmental, financial).
Such a task is covered by the fields of reliability assessment and risk analysis [7, 8]. Mathematically,
such a problem implies to focus on a risk measure computed from the tail of the output distribution
[9]. Performing sensitivity analysis in such a context requires to use dedicated tools which have
been gathered by various authors under the denomination of “reliability-oriented sensitivity analysis”
(ROSA) (see, e.g., [15, 46, 20]). A large panel of ROSA methods have been proposed in the structural
reliability community such as, for example, several variance-based approaches (see, e.g., [47, 13, 15, 48])
and moment-independent approaches (see, e.g., [49, 19, 46]). From the GSA community, several
extensions have also been proposed as extensions to handle risk or reliability measures. Among others,
8

one can mention, for instance, the contrast-based indices proposed by [50] as a versatile tool to handle
several types of QoI and then studied by [51, 52] for quantile-oriented formulations, the quantile-based
global sensitivity measures [53] or, finally, other indices related to dependence measures [18, 20].
In the context of reliability assessment, a typical risk measure is the failure probability given by:


def
pYt = P (Y > t) = P (G(X) > t) = E 1{G(X)>t} (X) = E [1Ft (X)]

(16)

where t represents a certain scalar threshold value characterizing the state of the system. Typically,
the event {Y > t} denotes the failure event. As for Ft , it represents the input failure domain,
def

i.e., Ft = {X | G(X) > t}. Thus, performing a ROSA study induces a few challenges: firstly, the

variable of interest here is no more Y , but can be, for instance, a binary event whose occurrence is
characterized by the indicator function 1Ft (X); secondly, this event is likely to be a “rare event”

associated to a low failure probability which might be difficult to estimate in practice [10]; thirdly,
the type of study one desires to perform has to be reinterpreted regarding the new QoI. Regarding
this last point, [18] proposes to focus on two types of studies when dealing with critical events: the
first one, called target sensitivity analysis (TSA), aims at catching the influence of the inputs on the
occurrence of the failure event, while the second one, called “conditional sensitivity analysis” aims at
studying the influence of the inputs once the threshold value has been reached (i.e., within the failure
domain). The present paper is dedicated to ROSA (under the assumption that the QoI is a failure
probability given by Eq. (16)) and focuses on a TSA study.
To illustrate this in plain text, one can use the example of the modeling of the water level in a river
protected by a dyke. From the traditional GSA point of view, the central question would be “Which
inputs influence the water level?”, while in the TSA paradigm, one focuses more on the question
“Which inputs influence the occurrence of a specific flood level?”. Note that this particular example
is more specifically studied in Subsection 6.1.
In the case of independent inputs, a first category of sensitivity indices dedicated to TSA is the
“target Sobol’ indices” whose first formulation has been proposed by [19]. Similarly, one uses here the
closed Sobol’ index (see Appendix A) as follows:
T-SA =

V (E [1Ft (X) | XA ])
.
V (1Ft (X))

(17)

where V (1Ft (X)) = pYt (1−pYt ). Several estimation schemes for these indices have been proposed in the

rare event context [13, 15, 54]. To illustrate the behavior of this type of basic index, one can consider

the additive model given by Y = X1 + X2 + X3 , with X = (X1 , X2 , X3 )⊤ , three independent standard
Gaussian random variables. The left plot of Figure 2 represents the probability density function (pdf)
of Y , with four different values for the threshold t, corresponding to four different failure probability
levels. The right plot of Figure 2 presents the different values of T-SA . Note that, for this specific
example, the second-order indices verify T-S{1,2} = T-S{1,3} = T-S{2,3} . Moreover, one can remark
that the more t is restrictive or loose (i.e., the failure probability being “close” to 0 or 1), the more the
third-order closed Sobol’ index for TSA increases, indicating high interaction effects between the three
inputs. Note that the understandings of this behavior falls under the conditional sensitivity analysis
paradigm, which is out of the scope of this paper. However, the acknowledgment of this phenomenon
9

0.10

0.6

0.15

t=6

t=2

0.2

0.4

t=4

0.05

Density

First−Order T−Sobol
Second−Order T−Sobol
Third−Order T−Sobol

0.8

0.20

1.0

remains important for better understanding the behavior of the new indices proposed further in the
paper.

0.0

0.00

t=0

−8

−4

0

2

4

6

8

−6

Y

−4

−2

0

2

4

6

t

Figure 2: Probability density function of the output with four different threshold values (left) and the related target
Sobol’ indices (right) for Y being the sum of three independent Gaussian random variables.

Another category of sensitivity indices dedicated to TSA gathers the “moment-independent” ROSA
indices. Among others, one can mention the two indices proposed by [49] which are given by:
i
1 h Y
Y |X
E pt − pt A
2 
2 
1 
Y |X
δA = E pYt − pt A
.
2

ηA =

Y |XA

where pt

(18a)
(18b)

denotes the conditional failure probability when XA is fixed. Note that, if the first

index does not require any independence assumption for quantifying input influence, it is known to
be difficult to estimate in practice [46]. As for the second one, it is simply proportional to the target
Sobol’ index given in Eq. (17). Note that an extension of the δA index has been proposed in [55]
for correlated inputs. It relies on a similar orthogonalization procedure strategy as proposed by [26].
However, as mentioned previously, this tends to increase the number of indices to estimate so as to
properly interpret the results.
The following section develops the distance-based TSA indices, highlighting their links with existing TSA indices and proposing new TSA indices inspired from the Shapley framework presented in
Subsection 2.2.
3.2. Distance-based TSA indices

i
h
2
As recalled by several authors [50, 18], one can notice that V (E [Y |XA ]) = E (E [Y |XA ] − E [Y ]) .
This equality can be interpreted as the expected squared distance between two expectations, and thus
10

allows to apprehend Sobol’ indices (see Eq. (13)) as distance-based indices. Such a general point of
view has been adopted by [50] to provide a generalization of the Sobol’ indices using contrast functions.
By applying a similar idea in the TSA paradigm, one can extend the standard T-SA and ηA indices
to more general cases using statistical distances. Thus, one can define the distance-based TSA index,
relative to a subset of inputs A ∈ Pd , as follows:

i
h 
Y |X
E D pYt , pt A
i
h 
T-SD
A =
Y |X
E D pYt , pt

(19)

where D(·, ·) denotes any distance function. Links can be made between these indices and the one
previously presented, through the use of specific distance functions. For example, by choosing the
distance derived from the ℓ1 norm (i.e., the absolute difference), one can find that the corresponding
distance-based TSA index is proportional to the ηA index, that is:
1

T-SℓA

i
h
E E[1Ft (X)] − E[1Ft (X)|XA ]
2
i
i ηA
h
= h
=
E 1Ft (X) − E [1Ft (X)]
E 1Ft (X) − E [1Ft (X)]

(20)

Moreover, if using the distance derived from the ℓ2 norm (i.e., the squared difference), one can
remark the related distance-based TSA indices are equal to the closed Sobol’ index for TSA, as defined
in Eq. (17):
 

(X)
X
V
E
1
A
Ft
2


.
(21)
T-SℓA = T-SA =
V 1Ft (X)
This framework of distance-based TSA indices allows to quantify the influence of inputs (or subsets

of inputs), but the previously introduced indices are not suited for the case of dependent inputs.
However, such a framework enables to produce relevant candidates as cost functions for the Shapley
setting as presented in the following.
3.3. (D)-target Shapley effects
In this subsection, a novel family of TSA indices is proposed, namely the (D)-target Shapley
effects. As mentioned above, these indices are built by taking the distance-based TSA indices, defined
in Eq. (19), as cost functions in a Shapley attribution procedure (see Eq. (12)). For a specific input
j ∈ {1, . . . , d}, its (D)-target Shapley effects can be defined as being:
T-ShD
j

1
=
d


X d − 1−1 
D
T-SD
A∪{j} − T-SA
|A|

(22)

A⊂{−j}

where {−j} = {1, . . . , d} \ j. The main property allowing for a clear interpretation of the (D)-target
Shapley effects is the following:

Property 1 ((D)-target Shapley effects decomposition). Let A ∈ Pd , and val(A) = T-SD
A . For any

11

distance function D(., .), the following property holds:
d
X

T-ShD
j = 1.

(23)

j=1

It is important to note that this decomposition property does not rely on any independence assumption on the inputs of the numerical model. However, in order to ensure a meaningful interpretation of
these indices, (e.g., such as a percentage of a meaningful statistic in terms of input importance), one
needs to ensure that the T-Shj are non-negative, for all j = 1, . . . , d.
1
By choosing the cost function being equal to T-SℓA (i.e., D(x, y) = |x − y|), one can define the
(ℓ1 )-target Shapley effect associated to a variable j ∈ {1, . . . , d} as being:
1

T-Shℓj =

1
d


X d − 1−1 
1
1
T-SℓA∪{j} − T-SℓA .
|A|

(24)

A⊂{−j}

These indices are non-negative (see the proof in Appendix C.1) which allows the (ℓ1 )-target Shapley
effects hto be interpreted as the
i percentage of the mean absolute deviation of the indicator function
(i.e., E 1Ft (X) − E [1Ft (X)] ) one can allocate to each input Xj with j ∈ {1, . . . , d}.
2

By choosing T-SℓA as the cost function in the Shapley framework (i.e., D(x, y) = (x − y)2 ), the

(ℓ2 )-target Shapley effect associated to the variable j ∈ {1, . . . , d} can be defined as:
2

T-Shℓj =

1
d


X d − 1−1 
2
2
T-SℓA∪{j} − T-SℓA
|A|

(25)

A⊂{−j}

Being also non-negative (see the proof in Appendix C.2), they can be interpreted as a percentage of
the variance of the indicator function allocated to the input Xj with j ∈ {1, . . . , d}. Moreover, using

Eq. (21), by analogy with Eqs. (13) and (15), if one chooses to define the cost function as being:
h
i
(X)|X
E
V
1
F
t
A
def


val(A) = T-EA =
V 1Ft (X)

(26)

with A = {1, . . . , d} \ A, then one has an equivalent way of defining the (ℓ2 )-target Shapley effect.
2

In the following, by analogy to T-SℓA = T-SA and to simplify the terminology and notations, the
2
2
(ℓ )-target Shapley effect T-Shℓj will be called the target Shapley effect and denoted T-Shj :
def

2

T-Shj = T-Shℓj .

(27)

4. Estimation methods and practical implementation of target Shapley effects
The estimation of the target Shapley effects Eq. (25) can be split into two steps:
• Step #1: estimation of the conditional elements, i.e., the estimation of T-SA or T-EA for all
A ∈ Pd ;
12

• Step #2: an aggregation procedure, i.e., a step to compute the T-Shj by plugging in the previous
estimations of Step #1 in Eq. (25).
In the following, two estimation methods are proposed: the first one based on a Monte Carlo sampling
procedure, and the second one based on a nearest-neighbor approximation technique.
4.1. Monte Carlo sampling-based estimation
This procedure, introduced in [45] for the estimation of Shapley effects, relies on a Monte Carlo
estimation of the conditional elements. It requires the knowledge and the ability to sample from the
marginal distributions of the inputs, that is PXA for all A ⊆ {1, . . . , d} \ ∅, as well as from all the

conditional distributions, that is PXA |XA , for all possible subsets of inputs A. Additionally, one also
needs to be able to evaluate the model G(·) which is mostly the case in the context of uncertainty
quantification of numerical computer models (ignoring the potential difficulties related to the cost of
a single evaluation of G(·)) [1].
In order to estimate a conditional element T-SA , one needs to draw several i.i.d. samples:
• an i.i.d. sample of size N drawn from PX and denoted by (X (1) , . . . , X (N ) );
(1)

(Nv )

• another i.i.d. sample of size Nv drawn from PXA and denoted by (XA , . . . , XA

);

(i)

• for each element XA , i = 1, . . . , Nv , a corresponding sample of size Np drawn from PXA |XA given
(i)
e (Np) ).
e (1) , . . . , X
that XA = XA and denoted by (X
i
i

Then, the Monte Carlo estimator of T-SA can be defined as:

with

d A,MC =
T-S

PNv 
i=1

pbYt

1
Np

PNp

j=1

e (j) , X (i) ) − pbY
1Ft (X
t
i
A

(Nv − 1)b
pYt (1 − pbYt )

2

N
1 X
=
1F (X (i) ).
N i=1 t

(28)

(29)

Finally, the aggregation procedure gives:
[ j,MC = 1
T-Sh
d


X d − 1−1 
d A∪{j},MC − T-S
d A,MC .
T-S
|A|

(30)

A⊂{−j}

[ j,MC is an unbiased consistent estimator of T-Shj .
Thus, one gets that T-Sh
Algorithm 1 provides a detailed description on how to implement this estimator in practice. This
estimation method requires (N + d! × (d − 1) × Nv × Np ) calls to the numerical model G(·). As
expected, this first estimation method can become quite expensive in practice. Moreover, numerical
models usually encountered in industrial studies can be costly-to-evaluate, which can become a strong
limitation for the use of this method.
Another algorithm has been proposed in [45], by leveraging an equivalent definition of the Shapley
attribution system, as an arithmetic mean over all the d! permutations of {1, . . . , d}. In the same
13

Algorithm 1: Target Shapley effects estimation by a Monte Carlo procedure.
Input: G, t, d, N, Nv , Np , simJoint, simMarginal, simConditional
[ j,MC )j=1,...,d
Output: (T-Sh
/* Sample from the joint distribution
1

*/

(X (1) , . . . , X (N ) ) ← sim joint(N )
/* Estimate the failure probability

2

3

pbYt ←

1
N

*/

PN

(i)
i=1 1{G(X (i) )>t} (X )

/* For every subsets of inputs

*/

for A ∈ Pd do

*/

/* Sample from the marginal distribution
(1)

(Nv )

) ← simMarginal(A, Nv )

4

(XA , . . . , XA

5

for i = 1, . . . , Nv do

/* For every element of the marginal distribution sample

*/

/* Sample from the conditional distribution given the element of the marginal distribution
*/
6

e (Np ) ) ← simConditional(A, Np , X (i) )
e (1) , . . . , X
(X
i
i
A

/* Compute the conditional element
7

dA ←
T-S

1
Nv −1

PNv 
i=1

1
Np

/* Aggregation step
8
9
10

for j = 1, . . . , d do
[ j,MC ← 0
T-Sh
for A ⊂ {−j} do

PNp

e (j) (i)
j=1 1Ft (Xi , XA )

− pbYt

2

*/

×

1
p
bY
pY
t (1−b
t )

*/

/* Apply the Shapley weights to every computed increments

11

[ j,MC + =
T-Sh


1 d−1 −1
d |A|



d A∪{j} − T-S
dA
T-S

*/



fashion as in Eq. (10), it writes:
[j = 1
T-Sh
m

X

π∈permutations
of {1,...,d}



d v∪{j},MC − T-S
d v,MC
T-S



(31)

with v being the indices before j in the order π. In Eq. (31), the sum is not performed over all
the permutations of {1, . . . , d} but only on m randomly chosen permutations. By sampling m < d!
permutations, one can drive the computational cost of this algorithm to (N + m × (d − 1) × Nv × Np )
calls to G(·), for a less precise, but still convergent estimator.

4.2. Given-data estimation
A “given-data” estimation method has been introduced in [36] to get the Shapley effects. This
method can be seen as an extension of the Monte Carlo estimator when only a single i.i.d. inputoutput sample is available. This method is appropriate when the input distributions are not known
or when the numerical model G(·) is no more available. The main idea behind this method is to
replace the exact samples from the conditional distributions PXA |XA by approximated ones based on
a non-parametric nearest-neighbor procedure.

A
Let X (1) , . . . , X (N ) be an i.i.d. sample of the inputs X and A ∈ Pd \ {∅, [1 : d]}. Let kN
(l, n)
14



(kA (l,n))
(l)
(1)
(N )
be the index such that XA N
is the n-th closest element to XA in XA , . . . , XA . Note that,
(l)

if two observations are at an equal distance from XA , then one of the two is uniformly randomly
selected. Finally, one can define an estimator of the equivalent cost function defined in Eq. (26):
PN

l=1

d A,KNN =
T-E

1
Ns −1

PNs

i=1



 

A
(l,i)
kN
−
1F t X

1
Ns

N pbYt (1 − pbYt )

!
 
 2
A
(l,h)
kN
h=1 1Ft X

PNs

.

(32)

Under some mild assumptions, [36] showed that this estimator does asymptotically converge towards
T-EA . With estimates for the conditional elements, one can then define the following plug-in estimator:
1
[ j,KNN = 1
T-Sh
d


X d − 1−1 
d A∪{j},KNN − T-E
d A,KNN
T-E
|A|

(33)

A⊂{−j}

where pbYt is the empirical mean of 1Ft (X) on the i.i.d. sample. Algorithm 2 represents the procedure

for this given-data estimator. This method is less computationally expensive (in terms of model evaluations) compared to the Monte Carlo sampling-based method, since no additional model evaluation,
other than the ones in the i.i.d. sample, is required in order to produce estimates of the target Shapley
effects. Since the samples of the conditional and marginal distributions are approximated by a nonparametric procedure, this method also allows to reduce the possible input modeling error (e.g., in the
context of ill-defined input distributions), at the cost of less accurate estimates. Another constraint
is due to the fact that the input-output sample has to be i.i.d. which prevents from its use with, for
instance, advanced design of computer experiments.
In [36], a random permutation algorithm, homologous to Eq. (31), has been developed, which allows
for reducing the overall complexity of the method, which, for the sake of conciseness, is not developed
in this paper.
4.3. Software and reproducibility of results
The algorithms described in the preceding subsections have been implemented in the sensitivity
R package [56]. More precisely, the shapleyPermEx() (sampling-based algorithm) and sobolshap knn()
(given-data algorithm) functions can be directly used for the estimation of the target Shapley effects. In
the applications of Section 6, only the sobolshap knn() function will be used for numerical tractability. Appendix D provides some minimal code examples for the implementation of the aforementioned
algorithms, along with their random permutation variants [36].
All further results can be accessed on a GitLab platform1 , along with the data used in the following
sections. R code files are available, with explicit code, along with all custom-made functions, in order
to reproduce the analyses presented in this paper. The procedures for the theoretical approximations of
Section 5 are made available, along with the data-simulation functions for the flood case in Subsection
6.1. The two datasets used for Subsection 6.2 are also available. Finally, all the figures can be
reproduced by simply re-running the different RMarkdown files in the aforementioned GitLab repository.
1 https://gitlab.com/milidris/review

l2tse

15

Algorithm 2: Target Shapley effects estimation by a nearest-neighbor procedure.
Input: X, Y, t
[ j,KNN )j=1,...,d
Output: (T-Sh
/* Estimate the failure probability
1

2

pbYt ←

1
N

*/

PN

(i)
i=1 1{G(X (i) )>t} (X )

/* For every subsets of inputs

*/

for A ∈ Pd do

*/

/* Sample of X A

3
4

5

(j)

XA ← (Xi )i∈A
j=1,...,n
for i = 1, . . . , N do
/* For each row i of X A, find the N s nearest rows in X

*/

e A,(j) )j=1,...,Ns ← KNN(X (i) , X, Ns )
(X
i
A

*/

/* Compute the conditional element
6

dA ←
T-E

PN

l=1



/* Aggregation step
7
8
9



PNs h
1
e A,(i) −
1
X
F
t
i=1
l
Ns −1

for j = 1, . . . , d do
[ j,MC ← 0
T-Sh
for A ⊂ {−j} do

1
Ns


i2 
−1
A,(h)
e
× N pbYt (1 − pbYt )
h=1 1Ft Xl

PNs

*/

/* Apply the Shapley weights to every computed increments

10

[ j,MC + =
T-Sh


1 d−1 −1
d |A|



d A∪{j} − T-E
dA
T-E

*/



5. Analytical results using a linear model with Gaussian inputs
To illustrate the behavior of the proposed indices, a first toy-case involving a linear model and
multivariate Gaussian inputs is presented. The main advantage is that analytical results can be
derived for the marginal distributions of all subsets of inputs, their conditional distribution, and the
distribution of the output given a subset of inputs. Moreover, analytical formulas can be obtained for
both the target Sobol’ indices and the target Shapley effects.
Let (β0 , β) = (β0 , β1 , . . . , βd )⊤ ∈ Rd+1 , µ = (µ1 , . . . , µd )⊤ ∈ Rd and Σ ∈ Md (R) a full-rank
symmetric (d × d) square matrix. Assume that X ∼ Nd (µ, Σ), and that the model output writes
Y = β0 + β ⊤ X.

(34)




e A with
Then, one has Y ∼ N β0 + β ⊤ µ, β ⊤ Σβ and, for any A ∈ Pd , (Y |XA = xA ) ∼ N µ
eA , Σ
⊤
⊤
(µA + ΣA,12 Σ−1
µ
eA = β0 + βA
xa + βA
A,22 (xa − µA )),

Moreover, one also needs to recall that

(XA , XA )⊤ ∼ Nd

µA
µA

!

, ΣA =

16

e A = β ⊤ (ΣA,11 − ΣA,12 Σ−1 ΣA,21 )β .
Σ
A,22
A
A
ΣA,11

ΣA,12

ΣA,21

ΣA,22

!!

!
(d − |A|) × (d − |A|) (d − |A|) × |A|
with the partitions of ΣA having sizes
. These results will lead
|A| × (d − |A|)
|A| × |A|
to some numerical approximations of the theoretical values of T-Shj for all j = 1, . . . , d using standard
multidimensional integration tools. Here, the function adaptIntegrate() from the cubature package
of the R software has been used, with a fixed error tolerance set to 10−8 . This allows for studying
basic scenarios in order to validate the behavior of the target Shapley effects.
In the following, the independent inputs’ case is firstly studied w.r.t. the threshold t. Then, a
case involving linear correlation between inputs (driven by the parameter ρ) is studied accordingly.
Finally, a last case where an exogenous input is added. Such case appears as soon as an extra input
is correlated to another one without being explicitly involved in the model G(·).
5.1. Independent standard Gaussian inputs
The first toy-case can be specified by:
  
 
1 0
0
X1
  
 
X2  ∼ N3 0 , 0 1
0 0
0
X3


0

0 ,
1

Y =

3
X

Xi .

(35)

i=1

In this scenario, the three inputs are equally important in terms of defining Y , but they should also be
equally important for the variable of interest 1Ft (X), as assessed by the target Sobol’ indices defined

in Eq. (17).
From [19, 57], one can easily deduce that the first-order (FO) target Sobol’ indices are all equal to
each other. Thus, one has:
def

T-SFO = T-S1 = T-S2 = T-S3 =

 

√
V Φ t−X
2
V (1Ft (X))

,

(36)

while the second-order (SO) target Sobol’ indices are given by:
def

T-SSO = T-S{1,2} = T-S{1,3} = T-S{2,3} =

V (Φ (t − X ′ ))
V (1Ft (X))

(37)

where Φ(.) is the standard Gaussian cumulative distribution function (cdf), X ∼ N (0, 1) and X ′ ∼

N (0, 2). Finally, one can also show that the third-order (TO) target Sobol’ indices are equal to:
def

T-STO = T-S{1,2,3} = 1.

(38)

From Eqs. (36), (37), and (38), and from Property 1, one can deduce that:
T-Sh1 = T-Sh2 = T-Sh3 =

1
.
3

(39)

Additionally, as the inputs are independent, interpreting the closed target Sobol’ indices is meaningful,

17

and they are equal to:
T-SFO = T-SFO

(40)

T-SSO = T-SSO − 2T-SFO
T-STO = T-SSO − 3

T-S1FO

+

T-S1SO



(41)
.

(42)

These results are illustrated in Figure 3. One can remark that, studying the indicator variable
1Ft (X) instead of the model output Y leads to interaction effects between the inputs, while the target
Shapley effects remain constant for all threshold values t. Such a behavior was expected. However,
it highlights the fact the target Shapley effects do not report clearly the interaction effects as target
Sobol’ indices would do (by considering all the various orders). In some sense, it summarizes the

1.0

1.0

information into a single index which focuses only on correlation effects.
2

0.2

0.4

0.6

0.8

First−Order Sobol
Second−Order Sobol
Third−Order Sobol

0.0

0.0

0.2

0.4

0.6

0.8

T−Shl
pYt

−6

−4

−2

0

2

4

6

−6

−4

−2

t

0

2

4

6

t

Figure 3: Target Shapley effects (left) and target Sobol’ indices (right) for the linear model with standard independent
multivariate Gaussian inputs, w.r.t. t.

5.2. Correlated Gaussian inputs with unit variance
The behavior of the target Shapley effects are now studied when a linear dependence is added to
the inputs. Since Property 1 still holds without any condition on the dependence structure on the
input variables, these indices remain relevant while conveying a practical ease of interpretation. The
following model is used:
  
1
0
  
 
,
∼
N
0
X
 2
3   0
0
0
X3


X1



18

0
1
ρ

0




ρ ,
1

Y =

3
X
i=1

Xi .

(43)

where −1 < ρ < 1. In this scenario one has

 
V Φ √t−X

2(1+ρ)



,
V (1Ft (X))
 

√
V Φ t−X
2
T-S2 = T-S3 =
,
V (1Ft (X))
V (Φ (t − X ′ ))
,
T-S{1,2} = T-S{1,3} =
V (1Ft (X))
V (Φ (t − X ′′ ))
T-S{2,3} =
V (1Ft (X))
T-S1 =

(44)

(45)
(46)
(47)

where X ′ ∼ N (0, 1), X ′ ∼ N (0, 2) and X ′′ ∼ N (0, 2(1 + ρ)).

From these results, one can directly remark that T-Sh2 = T-Sh3 . Note that the values of the

target Shapley effects can also be obtained by combinations of target Sobol’ indices (see Eq. (25)).
These results are illustrated in Figure 4. For fixed threshold values t, the target Shapley effects of the
correlated inputs X2 and X3 increases when ρ increases. This is an expected behavior since, in this
case:




t
t
V (1Ft (X)) = Φ √
1−Φ √
,
(48)
3 + 2ρ
3 + 2ρ
and subsequently, for a fixed t, the variance of the variable of interest will grow with ρ, as illustrated
in Figure 5. This increase in variance due to the correlation between X2 and X3 is then allocated
through T-Sh2 and T-Sh3 , which increase with ρ. On the other hand, T-Sh1 decreases accordingly, to
accommodate Property 1.
In Figure 4, the behavior of the indices w.r.t. ρ can also be clearly seen, as T-Sh1 is predominantly
above T-Sh2 and T-Sh3 when ρ is negative, and below when it is positive. This can be explained by the
fact that, X2 and X3 cancel each other out when their correlation is negative, thus lowering the value
of T-S{2,3} below T-S{1,2} and T-S{1,3} , automatically increasing T-Sh1 in accordance to Property 1.

In the other hand, for positive values of ρ, T-S{2,3} is higher than T-S{1,2} and T-S{1,3} , which in turn

corresponds to T-Sh1 being lower than T-Sh2 = T-Sh3 .

5.3. Quantifying the importance of an exogenous input in the Gaussian setting
In this use case, inspired by [57], the following model is considered:
  
 
1 0
0
X1
  
 
  
X2 
  ∼ N4 0 , 0 1
0 0 0
X 
  
 3
0 ρ
0
X4

0
0
1
0

0





ρ
 ,

0


Y = X1 + 6X2 + 4X3

(49)

1

where X4 is an exogenous input, but correlated to X2 , which should be the most important variable
in terms of variance. The threshold is fixed at t = 16. This scenario enables to check that the target
Shapley effects allow for quantifying the importance of X4 through its correlation with an endogenous
input, even though it does not appear directly in the model. Indeed, from the results given in Figure 6,

19

1.0

T−Sh for t=−1

1.0

T−Sh for t=−5

0.2

0.4

0.6

0.8

T−Sh1
T−Sh2
T−Sh3
pYt

0.0

0.0

0.2

0.4

0.6

0.8

T−Sh1
T−Sh2
T−Sh3
pYt

0.0

0.2

0.4

0.6

0.8

−0.8

−0.4

0.0

0.2

ρ

ρ

T−Sh for t=0

T−Sh for t=5

0.6

0.6
0.4
0.2
0.0

0.0

0.2

0.4

0.6

0.8

T−Sh1
T−Sh2
T−Sh3
pYt

0.8

T−Sh1
T−Sh2
T−Sh3
pYt

0.8

0.4

1.0

−0.4

1.0

−0.8

−0.8

−0.4

0.0

0.2

0.4

0.6

0.8

−0.8

ρ

−0.4

0.0

0.2

0.4

0.6

0.8

ρ

Figure 4: Evolution, w.r.t. ρ and for various threshold values, of the target Shapley effects of correlated Gaussian
standard inputs in a linear model.

one can remark that T-Sh4 increases when ρ goes to either 1 or −1, despite the fact that it is not used
directly in the model G(·).
6. Applications
In this section, two models related to real phenomena and including dependent random inputs are
studied in the context of TSA.
6.1. A simplified flood model
The target Shapley effects are firstly computed on a simplified model of a river flood [57, 6]. The
aim of this model is to study the behavior of the river’s water level, by comparison with a fixed dyke
height. After a strong simplification of the one-dimensional Saint-Venant equation (with uniform and
constant flow rate), the maximal annual water level h is modeled as


h=

BKs

Q
q

Zm −Zv
L

20

 35

 ,

(50)

0.25

0.20

0.5

0.05

0.10

0.10

0.20

0.10

0.15

0.05

−0.5

0.15

0.0

0.20

ρ

0.15

0.05

0.00

−4

−2

0

2

4

t

Figure 5: Variance of 1Ft (X) w.r.t. ρ and t for correlated Gaussian standard inputs with a linear model.

0.0

0.1

0.2

0.3

0.4

0.5

0.6

T−Sh1
T−Sh2
T−Sh3
T−Sh4

−0.5

0.0

0.5

ρ
Figure 6: Target Shapley effects for the Gaussian Linear model with an exogenous input, w.r.t. ρ.

while the model output writes
Y = Zv + h.

(51)

The inputs’ modeling and threshold value are described in Table 1. The problem is of dimension d = 6.
In the present TSA study, the variable of interest is 1{G(X)>t} (X) with t being the dyke height, fixed

to t = 54.5 m. The reference failure probability, computed here with a Monte Carlo sample of large
size (here 107 samples) is equal to pYt = 4.5 × 10−3 .
As in [24], three pairs of inputs are assumed to be linearly dependent: Q and Ks with ρ(Q, Ks ) =
0.5, Zv and Zm with ρ(Zv , Zm ) = 0.3, L and B with ρ(L, B) = 0.3. The aim of this use-case is to

assess the interest of the target Shapley effects in a complex environment. From [24], it can be shown
that, from a GSA standpoint (using a generalized variance decomposition for dependent variables),
the two most influential inputs on the annual water level are Q, the maximal annual flow rate, and
21

Input
Q
Ks
Zv
Zm
L
B
t

Description
maximal annual flow rate
Strickler friction coefficient
river downstream level
river upstream level
length of the river stretch
river width
dyke height (threshold)

Unit
m3 .s−1
m
m
m
m
m

Distribution
Gumbel(1013, 558) truncated to [500, 3000]
Normal(30, 7) truncated to [15, +∞)
Triangular(49, 50, 51)
Triangular(54, 55, 56)
Triangular(4990, 5000, 5010)
Triangular(295, 300, 305)
Fixed to 54.5

Table 1: Input variables and distributions for the flood model.

Zv , the river downstream level.
A Monte Carlo sample of N = 2 × 105 input realizations is drawn (note that the correlations are
injected following the algorithm proposed by [58]). Thus, this procedure leads to the computation of N

model output values. Figure 7 represents the estimated target Shapley effects on the flood case, using
the nearest-neighbor procedure depicted in Subsection 4.2 with an arbitrary number of neighbors set
at Ns = 2. Moreover, 300 repetitions of the simulation and the estimation procedure give access to
confidence intervals of the estimates (represented by boxplots in Figure 7). From these TSA results,
one can notice that Q is granted an influence of 24.3% (± 1.3%), Ks has 22.6% (±1.3%) and Zv around
16.7% (± 1%). The other inputs present a share of around 12%. Compared to results obtained by
GSA without correlations [6] and with correlations [24], these TSA results with correlations present a
much larger effect for Ks and non-negligible effects for Zm , L and B. This was expected due to the
interactions induced by the considered TSA variable of interest. This example illustrates the ability
of the target Shapley effects to quantify the relative importance of input variables in a complex model

0.0

0.1

0.2

0.3

0.4

presenting statistical dependence between them.

Q

Ks

Zv

Zm

L

Inputs
Figure 7: Estimated target Shapley effects for the flood case.

22

B

6.2. A COVID-19 epidemiological model
In 2020, the COVID-19 crisis has raised major issues in the usefulness of epidemic modeling in
order to give useful insights to public policy decision makers. [59] have taken this example to insist
on the essential use of GSA on such models, which claim to predict the potential consequences of
intervention policies. A first study has been proposed by [60], in the context of COVID-19 in Italy,
to assess the sensitivity of model outputs such as quarantined, recovered or dead people to inputs
driving intervention policies. Another GSA has been performed in [61] in the French context of the
first COVID-19 wave. By using data coming from this last analysis (thanks to the authors’ agreement),
the goal of this section is to demonstrate how TSA can help to characterize the influence of various
uncertain parameters on a real-scale model.
6.2.1. Description of the model and its inputs
The deterministic compartmental model developed in [61] (also presented in [62]) is representative
of the COVID-19 French epidemic (from March to May) by taking into account the asymptomatic
individuals, the testing strategies, the hospitalized individuals, and people going to Intensive Care
Unit (ICU). Using several assumptions, it is based on a system of 10 ordinary differential equations
which are not developed here for a sake of conciseness (see [62, 61] for more information).
Table 2 presents the 20 input parameters with their prior distribution (chosen from literature
studies), which form the inputs X, assumed to be independent between each other. For the present
study, our variable of interest, which is a particular model output, then writes
p
Umax
=

n

max

v∈time range

o
Uv (X)

(52)

p
stands
where Uv is the the number of hospitalized patients in ICU at time v. Note that the “p” in Umax

for “prior” as this quantity corresponds to the variable of interest before any calibration w.r.t. the
available data.
In [61], after a first screening step allowing to suppress non-influential inputs, the model is calibrated
on real data by using a Bayesian calibration technique. After the analysis of this step, the selected
remaining inputs are
Xsel = (pa , Na , Ns , R0 , t0 , µ, N, I0− )⊤

(53)

and their distributions are obtained from a sample given by the calibration process. The non-influential
inputs are fixed to their nominal values and the posterior variable of interest becomes
Umax =

max

n

v∈time range

o
Uv (Xsel )

(54)

with Umax being the maximum number of hospitalized people in ICU who need special medical care
on the studied temporal range, and Uv is the number of hospitalized patients in ICU at time v.
6.2.2. Input importance for ICU bed shortage
The central question of this study would be to determine which inputs influence the event of
a country experiencing a shortage of ICU bed during the time period. For that purpose, one can
introduce a threshold t, which represents the total number of ICU beds in the country, which is
23

Input
pa
pH
pU
pHD
pUD
Na
Ns
NIH
NHD
NUD
NHR
NUR
R0
t0
µ
N
λ1
pHU
NHU
I0−

Description
Conditioned on being infected, the probability of having light symptoms or no symptoms
Conditioned on being mild/severely ill, the probability of needing hospitalization (H or U )
Conditioned on going to hospital, the probability of needing ICU
Conditioned on being hospitalized but not in ICU, the probability of
dying
Conditioned on being admitted to ICU, the probability of dying
If asymptomatic, number of days until recovery
If symptomatic, number of days until recovery without hospital
If severe symptomatic, number of days until hospitalization
If in H, number of days until death
If in ICU, number of days until death
If hospitalized but not in ICU, the number of days until recovery
If in ICU, number of days until recovery
Basic reproducing number
Starting date of epidemics (in 2020)
Decaying rate for transmission (after social distanciation and lockdown)
Date of effect of social distanciation and lockdown
Type-1 testing rate
Conditioned on being hospitalized in H, the probability of needing
ICU
If in H, number of days until ICU
Number of infected undetected at the start of epidemics

Prior distribution
U(0.5, 0.9)
U(0.15, 0.2)
U(0.15, 0.2)
U(0.15, 0.25)
U(0.2, 0.3)
U(8, 12)
U(8, 12)
U(8, 12)
U(15, 20)
U(8, 12)
U(15, 25)
U(15, 25)
U(3, 3.5)
U(01/25, 02/24)
U(0.03, 0.08)
U(20, 50)
U(1e − 4, 1e − 3)
U(0.15, 0.2)
U(1, 10)
U(1, 100)

Table 2: Model inputs and their prior distribution. H is the number of hospitalized individuals with severe symptoms.
U is the number of hospitalized individuals in ICU.

assumed to be constant during the studied time period. The new variable of interest would then be
P
1{Umax
>t} (X) for the full compartmental model (preliminary study) and 1{Umax>t } (Xsel ) for the model
with selected inputs (post-calibration study). Two input-output samples of size n = 5000 are available.

The first one (preliminary study) includes all the inputs following their prior distribution (see Table 2)
P
and the corresponding output Umax
of the compartmental model. The second one (post-calibration
study) is composed of a sample of Xsel after the Bayesian calibration, and the corresponding output
Umax of the compartmental model with the non-selected inputs fixed to their nominal values.
P
Five different thresholds are studied on Umax
: 5 · 103 , 104 , 5 · 104 , 105 and 2 · 105 , with respectively
58.1%, 7.7%, 22%, 10.1% and 2.2% of the total output samples being in a failure state. This allows

to illustrate the behavior of the target Shapley effects when the failure probability decreases. The
threshold of 6300 has been chosen for Umax , with 10.9% of the total output samples being above
this threshold. Figure 8 illustrates two different thresholds, and the corresponding estimated failure
probability on the histogram of both outputs.
The target Shapley effects have been estimated using a variant of the estimation scheme presented
in Subsection 4.2, with a fixed number of random permutations of 103 , and with a number of neighbors
set to 3, following the rule of thumb guideline of [36], due to the sheer complexity of this estimation
algorithm. Since the compartmental model is deterministic, the target Shapley effects have been forced
24

8e−05

Threshold: 6300
Failure %: 10.9%

0.005

0.010

Density

4e−05

0.000

0e+00

2e−05

Density

6e−05

0.015

Threshold: 50000
Failure %: 22.04%

0

50000

150000

250000

6200

UPmax

6250

6300

6350

Umax

P
Figure 8: Illustration of thresholds on the histograms of Umax
(left) and Umax (right).

P
, with the red dotted line being the
to sum up to one. Figure 9 presents the main results for Umax
1
). One can remark that for less
average influence of an input, in the case of similar importance (i.e., 20
restrictive thresholds (i.e., threshold for which the failure probability is high), the input N , the effective

date of lockdown/social distanciation measures, seem to be the most influential, reaching more than
50% of the TSA variable of interest’s variance. However, as soon as the threshold becomes more and
more restrictive (i.e., the failure probability decomes lower and lower), the effect of N decreases, and
the effects of the other inputs increase accordingly, in order to reach what seem to be an equilibrium
at the value

1
20 .

This behavior can be explained by two main reasons:

• As outlined in Subsection 3.1, the nature of a restrictive TSA variable of interest induces high
interaction between the inputs;
• The Shapley allocation system, when applied to variance as a production value, redistributes the
interaction effects equally between all inputs (there is no correlation between inputs in this prior
study).
One can argue that, as soon as t becomes very restrictive, the combined interaction effects outweights
the effect of N itself, and since these effects are equitably distributed among all the inputs, their share
1
will tend to go towards 20
.
For the post-calibration study, some selected inputs Xsel are linearly correlated (see Figure 10 - top

left). This is typically the case for N and µ, with an estimated correlation coefficient ρ̂(N, µ) = 0.69,
and for R0 and N with an estimated correlation coefficient of ρ̂(N, R0 ) = −0.66. This correlation
25

0.4
0.3
0.2
0.0

0.1

(l²)−target Shapley effect

0.5

pa
Na
R0
N
NHU
Mean influence
Other inputs

0

50000

100000

150000

200000

Threshold
Figure 9: Target Shapley effects for 1{U P >t} (X) for different thresholds.
max

structure does not allow to get interpretable Sobol’ indices, as outlined in Section 2, which motivates
the use of Shapley-inspired indices. The Shapley effects and the target Shapley effects of Xsel for Umax
have been computed using the nearest-neighbor procedure, with a fixed number of neighbors of 3, and
forced to sum to one because of the deterministic nature of the model.
One can remark that Na , the number of days until recovery, seem to be the most important input
in explaining the number maximum number of ICU patients on the studied time range, with a Shapley
effect of around 35% of the output variance. The inputs pa , Ns , R0 and N seem to present average
effects, that is around 18 , while t0 , µ and I0− seem to be less influential, with around 5% of explained
variance each.
However, focusing on the event of a ICU bed shortage, one can remark that the target Shapley
effect of Na is lower (around 22%), with the influence of N being higher (around 15%) than their
Shapley effects. Moreover, t0 , µ and I0− present higher TSA effects, i.e., slightly under 10%, due to
the interaction induced by the indicator function. One can also remark that the influence of Ns is
higher than the one of R0 in the TSA setting, which was the other way around for the Shapley effects.
This would indicate that Ns , the number of days until recovery for a symptomatic patient without
hospitalization, influences more the event of a bed shortage than the basic reproducing number of the
virus, R0 .
7. Conclusion
This paper aims at proposing a set of new indices adapted to target sensitivity analysis while
being able to handle correlated inputs. The goal is to quantify the importance of inputs on the
occurrence of critical failure event of the system under study. The proposed indices are based on a
cooperative Shapley procedure which aims at allocating the effects of the interaction and correlation

26

0.4

Iminus0

N

Mu

t0

R0

Ns

Na

pa

Shapley effects

1
0.8

Na −0.19 1 −0.53 0.45 0.04 0.38 0.04 0.14

0.6

Ns 0.03 −0.53 1

0.4

R0 0.23 0.45 −0.1

−0.1 0.06 0.03 0.12 0.14
1

0.11 0.04 −0.66−0.36

0.2
0

t0 0.01 0.04 0.06 0.11

1

0.3

1 −0.19 0.03 0.23 0.01 −0.18−0.24 0.41

0.2

pa

0.02 −0.06−0.01

N −0.24 0.04 0.12 −0.66−0.06 0.69

0.69 0.22
1

Iminus0 0.41 0.14 0.14 −0.36−0.01 0.22 0.55

−0.4

0.55

−0.6

1

−0.8
−1

0.0

1

0.1

−0.2

Mu −0.18 0.38 0.03 0.04 0.02

Na

Ns

0.4

pa

R0

t0

Mu

N Iminus0

0.0

0.1

0.2

0.3

(l²)−target Shapley effects

pa

Na

Ns

R0

t0

Mu

N

Iminus0

Figure 10: Input correlation matrix (top left), Shapley effects for Umax (top right) and target Shapley effects (bottom)
for 1{Umax>t } (Xsel ).

equally between all the inputs in the same manner as done by the Shapley effects in global sensitivity
analysis. Thus, a general class of distance-based indices is proposed, namely the (D)-target Shapley
effects and some relevant properties are highlighted. Depending on the choice of the distance D, well-

known preexisting indices can be used as cost functions in the Shapley formulation. Therefore, these
indices allow for the allocation, among the different inputs, of shares of several dispersion statistics

(e.g., mean absolute deviation for the ℓ1 case, variance for the ℓ2 case). This produces easily usable
indices in practice, as they can directly be interpreted as percentage of the dispersion statistic, allocated
to each input. This versatile procedure allows to produce input importance measures according to a

27

specific metric, driven by the choice of the distance.
In particular, the (ℓ2 )-target Shapley effects (called target Shapley effects to simplify), which represents percentages of variance, have been studied more intensively and two dedicated estimation
methods have been proposed. These particular indices have then been applied, analyzed and discussed
through simple Gaussian toy-cases. Finally, two real-world use-cases have been studied: the modeling
of a river flood and the problem of ICU bed shortage during the COVID-19 pandemic. These indices
reveal to be able to detect influential inputs in the context of correlated inputs. For target sensitivity
analysis, such a tool is valuable and can be used as a complement of more standard procedures. The
clear advantage is that only one set of indices is required by an analyst in order to produce easily
interpretable and meaningful insights. Moreover, the proposed indices can be estimated in the context
of given-data which can be adapted to real applications for which no computer model is available.
However, the major drawbacks of the approach are mainly related to the target aspect of the analysis.
Indeed, as soon as the event gets more and more rare, all the inputs tend to be influential and making
a clear distinction between interactions and correlation effects becomes difficult.
A first perspective could be to improve the estimation strategies. The sampling-based method could
benefit from a better sampling scheme, such as importance sampling, as described in [63], which could
reduce the estimator’s variance. Recent results from [64] using copulas also shows promising tracks to
have efficient estimation of Shapley effects. Moreover, adapting recent results from [35], with a link
between the target Sobol’ indices and the Squared Mutual Information [65], should allow for other
possibilities of given-data estimation methods. Another method based on a random forest given-data
procedure, explored in [66] in the context of quantile-oriented importance measure estimation, could
also yield promising results if transposed to a reliability-oriented setting.
Finally, even if the Shapley attribution system allows to deal with input statistical dependencies, a
finer decomposition is lacking in order to quantify the origin of each effect (e.g., statistical dependence
and interaction). Further works should use the recent developments in [67] in order to quantify
interaction effects, with a transposition to the target sensitivity analysis setting. Finally, it has been
shown in [68] that the Shapley attribution system is equivalent to a maximum entropy distribution
(e.g., uniform) over all possible orderings of inputs (the Shapley weights). Developments towards other
forms of allocation systems where the allocation is driven from data could also open a path for further
developments.
Acknowledments
We are grateful to as Sébastien Da Veiga, Clémentine Prieur and Fabrice Gamboa for helpful
discussions and for having provided the dataset on the COVID-19 model.
References
[1] E. De Rocquigny, N. Devictor, S. Tarantola, Uncertainty in industrial practice: a guide to quantitative uncertainty management, Wiley, 2008.
[2] K. Beven, Environmental Modelling: An Uncertain Future?, CRC Press, 2008.

28

[3] F. Pianosi, K. Beven, J. Freer, J. Hall, J. Rougier, D. Stephenson, T. Wagener, Sensitivity analysis
of environmental models: A systematic review with practical workflow, Environmental Modelling
& Software 79 (2016) 214–232.
[4] S. Razavi, A. Jakeman, A. Saltelli, C. Prieur, B. Iooss, E. Borgonovo, E. Plischke, S. Lo Piano,
T. Iwanaga, W. Becker, S. Tarantola, J. Guillaume, J. Jakeman, H. Gupta, N. Melillo, G. Rabiti,
V. Chabridon, Q. Duan, X. Sun, S. Smith, R. Sheikholeslami, N. Hosseini, M. Asadzadeh, A. Puy,
S. Kucherenko, H. Maier, The future of sensitivity analysis: An essential discipline for systems
modelling and policy making, Environmental Modelling and Software, In press (104954) (2020).
[5] A. Saltelli, M. Ratto, T. Andres, F. Campolongo, J. Cariboni, D. Gatelli, M. Saisana, S. Tarantola,
Global Sensitivity Analysis. The Primer, Wiley, 2008.
[6] B. Iooss, P. Lemaı̂tre, A review on global sensitivity analysis methods, in: C. Meloni, G. Dellino
(Eds.), Uncertainty management in Simulation-Optimization of Complex Systems: Algorithms
and Applications, Springer, 2015, pp. 101–122.
[7] M. Lemaire, A. Chateauneuf, J.-C. Mitteau, Structural Reliability, ISTE Ltd & John Wiley &
Sons, Inc., 2009.
[8] Y. Richet, V. Bacchi, Inversion algorithm for civil flood defense optimization: Application to twodimensional numerical model of the garonne river in france, Frontiers in Environmental Science 7
(2019) 160.
[9] R. T. Rockafellar, J. O. Royset, Engineering Decisions under Risk Averseness, ASCE-ASME
Journal of Risk and Uncertainty in Engineering Systems, Part A: Civil Engineering 1 (2) (2015)
1–12.
[10] J. Morio, M. Balesdent, Estimation of Rare Event Probabilities in Complex Aerospace and Other
Systems: A Practical Approach, Woodhead Publishing, Elsevier, 2015.
[11] Y.-T. Wu, Computational Methods for Efficient Structural Reliability and Reliability Sensitivity
Analysis, AIAA Journal 32 (8) (1994) 1717–1723.
[12] S. Song, Z. Lu, H. Qiao, Subset simulation for structural reliability sensitivity analysis, Reliability
Engineering and System Safety 94 (2) (2009) 658–665.
[13] P. Wei, Z. Lu, W. Hao, J. Feng, B. Wang, Efficient sampling methods for global reliability sensitivity analysis, Computer Physics Communications 183 (2012) 1728–1743.
[14] V. Chabridon, Reliability-oriented sensitivity analysis under probabilistic model uncertainty –
Application to aerospace systems, Ph.D. thesis, Université Clermont Auvergne (2018).
[15] G. Perrin, G. Defaux, Efficient Evaluation of Reliability-Oriented Sensitivity Indices, Journal of
Scientific Computing (2019) 1–23.
[16] I. M. Sobol, Sensitivity estimates for nonlinear mathematical models, Mathematical Modelling
and Computational Experiments 1 (1993) 407–414.
29

[17] E. Borgonovo, A new uncertainty importance measure, Reliability Engineering & System Safety
92 (6) (2007) 771–784.
[18] H. Raguet, A. Marrel, Target and conditional sensitivity analysis with emphasis on dependence
measures, Working paper (2018, URL https://arxiv.org/abs/1801.10047).
[19] L. Li, Z. Lu, F. Jun, W. Bintuan, Moment-independent importance measure of basic variable and
its state dependent parameter solution, Structural Safety 38 (2012) 40–47.
[20] A. Marrel, V. Chabridon, Statistical developments for target and conditional sensitivity analysis: application on safety studies for nuclear reactor, Preprint HAL, hal-02541142v2 (2020, URL
https://hal.archives-ouvertes.fr/hal-02541142v2).
[21] W. Hoeffding, A class of statistics with asymptotically normal distribution, The Annals of Mathematical Statistics 19 (3) (1948) 293–325.
[22] J. Jacques, C. Lavergne, N. Devictor, Sensitivity analysis in presence of model uncertainty and
correlated inputs, Reliability Engineering & System Safety 91 (2006) 1126–1134.
[23] G. Li, H. Rabitz, P. Yelvington, O. Oluwole, F. Bacon, C. Kolb, J. Schoendorf, Global sensitivity
analysis for systems with independent and/or correlated inputs, Journal of Physical Chemistry
114 (2010) 6022–6032.
[24] G. Chastaing, F. Gamboa, C. Prieur, Generalized Hoeffding-Sobol decomposition for dependent
variables - Application to sensitivity analysis, Electronic Journal of Statistics 6 (2012) 2420–2448.
[25] C. Xu, G. Z. Gertner, Uncertainty and sensitivity analysis for models with correlated parameters,
Reliability Engineering & System Safety 93 (2008) 1563–1573.
[26] T. Mara, S. Tarantola, Variance-based sensitivity indices for models with dependent inputs, Reliability Engineering & System Safety 107 (2012) 115–121.
[27] T. Mara, S. Tarantola, P. Annoni, Non-parametric methods for global sensitivity analysis of model
output with dependent inputs, Environmental Modeling & Software 72 (2015) 173–183.
[28] N. Benoumechiara, K. Elie-Dit-Cosaque, Shapley effects for sensitivity analysis with dependent
inputs: bootstrap and kriging-based algorithms, ESAIM: Proceedings and Surveys 65 (2019) 266–
293.
[29] N. Do, S. Razavi, Correlation effects? A major but often neglected component in sensitivity and
uncertainty analysis, Water Resources Research 56 (e2019WR025436) (2020).
[30] L. S. Shapley, A value for n-person games, in: H. Kuhn, A. W. Tucker (Eds.), Contributions to
the Theory of Games, Volume II, Annals of Mathematics Studies, Princeton University Press,
Princeton, NJ, 1953, Ch. 17, pp. 307–317.
[31] M. Osborne, A. Rubinstein, A Course in Game Theory, MIT Press, 1994.

30

[32] A. B. Owen, Sobol’ indices and Shapley value, SIAM/ASA Journal of Uncertainty Quantification
2 (2014) 245–251.
[33] A. B. Owen, C. Prieur, On Shapley value for measuring importance of dependent inputs,
SIAM/ASA Journal of Uncertainty Quantification 5 (2017) 986–1002.
[34] B. Iooss, C. Prieur, Shapley effects for Sensitivity Analysis with correlated inputs : Comparisons
with Sobol’ Indices, Numerical Estimation and Applications, International Journal for Uncertainty
Quantification 9 (5) (2019) 493–514.
[35] A. Spagnol, Kernel-based sensitivity indices for high-dimensional optimization problems, Ph.D.
thesis, Ecole des Mines de Saint-Etienne (2020).
[36] B. Broto, F. Bachoc, M. Depecker, Variance reduction for estimation of shapley effects and adaptation to unknown input distribution, SIAM/ASA Journal on Uncertainty Quantification 8 (2)
(2020) 693–716.
[37] R. Christensen, Linear models for multivariate, time series and spatial data, Springer-Verlag,
1990.
[38] T. Hastie, R. Tibshirani, J. Friedman, The elements of statistical learning, Springer, 2002.
[39] J. Helton, J. Johnson, C. Salaberry, C. Storlie, Survey of sampling-based methods for uncertainty
and sensitivity analysis, Reliability Engineering & System Safety 91 (2006) 1175–1209.
[40] J. Johnson, J. LeBreton, History and use of relative importance indices in organizational research,
Organizational Research Methods 7 (2004) 238–257.
[41] L. Clouvel, Uncertainty quantification of the fast flux calculation for a PWR vessel, Ph.D. thesis,
Université Paris-Saclay (2019).
[42] R. H. Lindeman, P. F. Merenda, R. Z. Gold, Introduction to bivariate and multivariate analysis,
Scott Foresman and Company, Glenview, IL, 1980.
[43] U. Grömping, Relative importance for linear regression in R: the Package relaimpo, Journal of
Statistical Software 17 (2006) 1–27.
[44] J. Nossent, P. Elsen, W. Bauwens, Sobol’ sensitivity analysis of a complex environmental model,
Environmental Modelling & Software 26 (12) (2011) 1515 – 1525.
[45] E. Song, B. Nelson, J. Staum, Shapley effects for global sensitivity analysis: Theory and computation, SIAM/ASA Journal on Uncertainty Quantification 4 (1) (2016) 1060–1083.
[46] P. Derennes, J. Morio, F. Simatos, Simultaneous estimation of complementary moment independent and reliability-oriented sensitivity measures, Mathematics and Computers in Simulation 182
(2021) 721–737.
[47] J. Morio, Extreme quantile estimation with nonparametric adaptive importance sampling, Simulation Modelling Practice and Theory 27 (2012) 76–89.
31

[48] V. Chabridon, M. Balesdent, G. Perrin, J. Morio, J.-M. Bourinet, N. Gayton, Mechanical Engineering Under Uncertainties, Wiley - ISTE Ltd, 2020, Ch. ‘Global reliability-oriented sensitivity
analysis under distribution parameter uncertainty’, pp. 1–43.
[49] L. Cui, Z. Lu, X. Zhao, Moment-independent importance measure of basic random variable and its
probability density evolution solution, Science China Technical Sciences 53 (10) (2010) 1138–1145.
[50] J.-C. Fort, T. Klein, N. Rachdi, New sensitivity analysis subordinated to a contrast, Communications in Statistics - Theory and Methods 45 (15) (2016) 4349–4364.
[51] T. Browne, J.-C. Fort, B. Iooss, L. Le Gratiet, Estimate of quantile-oriented sensitivity indices,
HAL, hal-01450891, version 1 (2017).
[52] V. Maume-Deschamps, I. Niang, Estimation of quantile oriented sensitivity indices, Statistics and
Probability Letters 134 (2018) 122–127.
[53] S. Kucherenko, S. Song, L. Wang, Quantile based global sensitivity measures, Reliability Engineering and System Safety 185 (2019) 35–48.
[54] L. Li, I. Papaioannou, D. Straub, Global reliability sensitivity estimation based on failure samples,
Structural Safety 81 (2019) 101871.
[55] L. Li, Z. Lu, C. Chen, Moment-independent importance measure of correlated input variable and
its state dependent parameter solution, Aerospace Science and Technology 48 (2016) 281–290.
[56] B. Iooss, S. Da Veiga, A. Janon, G. Pujol, sensitivity: Global Sensitivity Analysis of Model Outputs,
R package version 1.23.1 (2020).
URL https://CRAN.R-project.org/package=sensitivity
[57] P. Lemaitre, Analyse de sensibilité en fiabilité des structures (in English), Ph.D. thesis, Université
de Bordeaux (2014).
[58] E. Schumann, Generating correlated uniform variates. (2009).
URL http://comisef.wikidot.com/tutorial:correlateduniformvariates
[59] A. Saltelli, G. Bammer, I. Bruno, E. Charters, M. D. Fiore, et al., Five ways to ensure that models
serve society: a manifesto (short comments), Nature 582 (2020) 482–484.
[60] X. Lu, E. Borgonovo, Is time to intervention in the COVID-19 outbreak really important? A
global sensitivity analysis approach, Preprint (2020, arXiv:2005.01833).
[61] S. Da Veiga, F. Gamboa, C. Prieur, B. Iooss, Basics and trends in sensitivity analysis, SIAM, In
revision, 2021.
[62] S. Da Veiga, Calibration and sensitivity analysis of a COVID-19 epidemics model, Meeting AppliBUGS (Applications du Bayesian Unified Group of Statisticians), December 2020.
URL http://genome.jouy.inra.fr/applibugs/applibugs.rencontres.html

32

[63] R. Y. Rubinstein, D. P. Kroese, Simulation and the Monte Carlo method, Second Edition, Wiley,
2008.
[64] G. Sarazin, P. Derennes, J. Morio, Estimation of high-order moment-independent importance
measures for Shapley value analysis, Applied Mathematical Modelling 88 (2020) 396–417.
[65] M. Sugiyama, Machine learning with squared-loss mutual information, Entropy 15 (1) (2012)
80–112.
[66] K. Elie-Dit-Cosaque, Développement de mesures d’incertitudes pour le risque de modèle dans des
contextes incluant de la dépendance stochastique (in English), Ph.D. thesis, Université Claude
Bernard Lyon 1 (2020).
[67] G. Rabitti, E. Borgonovo, A Shapley–Owen index for interaction quantification, SIAM/ASA Journal on Uncertainty Quantification 7 (3) (2019) 1060–1075.
[68] E. S. Soofi, J. J. Retzer, M. Yasai-Ardekani, A framework for measuring the importance of variables with applications to management research and decision models, Decision Sciences 31 (2000)
595 – 625.
Appendix A. ANOVA and Sobol’ indices
In the general non-linear case, as for the ANOVA of the linear model case (see Subsection 2.1),
the idea is to find a general decomposition of the output variance. This can be done through the
decomposition of a function with finite variance (L2 mathematical property), called the Hoeffding
decomposition [21], which allows to rewrite G(X) as a sum of centered components related to each
possible subset of inputs. For example, in the case of a model with three inputs X = (X1 , X2 , X3 ),
G(X) can be decomposed into four components:
G(X) = G∅

(Mean behavior)

+ G1 (X1 ) + G2 (X2 ) + G3 (X3 )

(First-order)

+ G{1,2} (X1 , X2 ) + G{1,3} (X1 , X3 ) + G{2,3} (X2 , X3 )
+ G{1,2,3} (X) .

(Second-order)
(Third-order)

Moreover, if the inputs are assumed to be independent, each term is orthogonal to one another and
writes
X
GA (xA ) =
(−1)|A|−|B|E [G(X)|XB = xB ]
(A.1)
B⊂A

where A ∈ Pd is a subset of indices and Pd the set of all possible subsets of {1, . . . , d}, |A| is the

cardinal of A and XA denotes the subset of inputs, selected by the indices in A (XA = (Xi )i∈A ).
Then, the Hoeffding decomposition is unique and leads to a variance decomposition called “functional
ANOVA”:
V[G(X)] =

X

A∈Pd ,A6=0

33

V[GA (xA )] .

(A.2)

This leads to the definition of the Sobol’ indices [16]:
V[GA (XA )]
=
SA =
V[G(X)]

P



E G(X) XB
.
V[G(X)]

|A|−|B|
V
B⊂A (−1)

(A.3)

The sum of the Sobol’ indices over all subset on inputs A ∈ Pd being equal to one, they can be directly

interpreted as the percentage of the output variance due to each subset of input [16, 5]. The Sobol’
indices of higher orders than one can be interpreted as a means of quantifying the share of variance
due to the interaction effects induced by the structure of the model G(·) between the selected subset
of inputs.
Another useful sensitivity index is the closed Sobol’ index [16] which writes
clos
SA

=

X

B⊂A



V E G(X) XA
SB =
V[G(X)]

(A.4)

In the independent setting, it can be interpreted as the percentage of variability induced by all the
variables in a selected subset and their interactions. Figure A.11 provides an illustration of the Sobol’
indices and the closed Sobol’ indices for a model with three inputs. Each Venn diagram represents
the variance of the output, with the representation of each of the two Sobol’ indices presented above.
While this representation is useful in the GSA context, it relies on the assumption of independence
between the inputs.

Figure A.11: Sobol’ indices (left) and closed Sobol’ indices (right).

Appendix B. Axioms of Shapley values
Consider a game with d players, and let val(A) ∈ R be the cost function quantifying the production

value of a coalition (i.e., set of players) A ∈ Pd , under the assumption that val(∅) = 0. The Shapley
value φj = φj (val), j = 1, . . . , d attributed to each player can be defined by the following set of axioms:
1. (Efficiency)

Pd

j=1

φj = val({1 . . . , d}), meaning that the sum of the allocated values have to be

equal to the value produced by the cooperation of all the players.

34

2. (Symmetry) If val(A ∪ {i}) = val(A ∪ {j}) for all A ∈ Pd , then φi = φj , meaning that if two
players allow for the same contribution to every coalition, their attribution should be the same.
3. (Dummy) If val(A ∪ {i}) = val(A) for all A ∈ Pd , then φi = 0, meaning that if a player does
not contribute the the production of resources for all coalition, he should not be attributed any
resources.
4. (Additivity) If val and val′ have Shapley Values φ and φ′ respectively, then the game with cost
function val + val′ has Shapley values φj + φ′j for j ∈ {1, . . . , d}.
These four axioms guarantee a cooperative allocation of val({1, . . . , d}). The unique attribution
method that satisfies these four axioms are the Shapley values [31], defined by:
φj =


−1
1 X d−1
(val(A ∪ {j}) − val(A)),
d
|A|

j = 1, . . . , d

(B.1)

A⊂−j

where {−j} = {1, . . . , d}\j. One can additionally remark that φj (val) is a linear operator, meaning
that for some constant c ∈ R, φj (c × val) = c × φj (val).
Appendix C. Mathematical proofs
Appendix C.1. Positivity of the (ℓ1 )-target Shapley effects
Let A ⊆ {1, . . . , d} \ {j}, for j ∈ {1, . . . , d}. In order to show that the (ℓ1 )-target Shapley effects

are positive, one needs to prove that:

1

1

T-SℓA∪{j} ≥ T-SℓA .

(C.1)

In [49], it was shown that the following property holds:
ηA∪{j} ≥ ηA

(C.2)
1

with ηA being defined in Eq. (18). From the definition of T-SℓA ,
1

T-SℓA =

2
i ηA ,
h
E 1Ft (X) − E [1Ft (X)]

(C.3)

one gets immediately the property C.1.
Appendix C.2. Positivity of the (ℓ2 )-target Shapley effects
Let X = (X1 , . . . , Xd ) ∈ Rd , be a real-valued random vector admitting a probability measure PX

on the usual real measurable
space. Let L2 (PX ) be the functional space such that, for a measurable
Z
def
function f , kf kL2 =
f 2 (x)dPX (x) < +∞. Let G(·) ∈ L2 be the studied numerical model, and
Rd

denote the random variable Y = G(X) be the model output (or Y = 1G(X)>t (X) the TSA variable of
interest, without loss of generality). Let A ⊆ {1, . . . , d} \ {j} be the indices of the subset of inputs XA

and j ∈ {1, . . . , d}. In order to show that T-Shj ≥ 0, one needs to prove that:
T-SA∪{j} − T-SA ≥ 0
35

(C.4)

which is equivalent to



 

V E [Y |XA ] ≤ V E Y |XA∪{j} .

(C.5)

From the Pythagorean theorem, one has:

kY kL2 = E Y

which is equivalent to

XA

h 
 
E Y2 =E E Y



XA

L2

2 i


+ Y −E Y

XA

h

+E Y −E Y



XA

 2
By removing E Y
to both sides of the equality, one obtains:

,

(C.6)

2 i
.

(C.7)

L2



V E [Y |XA ] = V (Y ) − kY − E [Y |XA ]kL2 .

(C.8)



By using the formula E Y XA = argmin kY − ZkL2 , with σ(XA ) being the span of XA , we deduce



 Z∈σ(XA ) 

that E Y XA ≤ E Y XA∪{j} since σ XA ⊆ σ XA∪{j} . This leads to

V (Y ) − Y − E Y

XA



L2


≤ V (Y ) − Y − E Y

XA∪{j}

Finally, from Eq. (C.8) and Eq. (C.9), we obtain

which concludes the proof.

 
V E Y

XA



 
≤V E Y

XA∪{j}





Appendix D. Minimal R code examples for the estimation methods
Appendix D.1. Monte Carlo sampling estimator
# Packages
library ( sensitivity )
library ( mvtnorm )
library ( condMVNorm )
# Model definition
model . linear <- function ( X ) as . numeric ( apply (X ,1 , sum ) >0)
# Parameters
d <- 3
mu <- rep (0 , d )
sig <- c (1 ,1 ,2)
ro <- 0.9
Cormat <- matrix ( c (1 ,0 ,0 ,0 ,1 , ro ,0 , ro ,1) , d , d )
Covmat <- ( sig % * % t ( sig ) ) * Cormat

36

L2

.

(C.9)

(C.10)

# Total and marginal simulation function
Xall <- function ( n ) mvtnorm :: rmvnorm (n , mu , Covmat )
# Conditional simulation function
Xset <- function (n , Sj , Sjc , xjc ){
if ( is . null ( Sjc )){
if ( length ( Sj ) == 1){ rnorm (n , mu [ Sj ] , sqrt ( Covmat [ Sj , Sj ]))
} else {
mvtnorm :: rmvnorm (n , mu [ Sj ] , Covmat [ Sj , Sj ])
}
} else {
condMVNorm :: rcmvnorm (n ,
mu ,
Covmat ,
dependent . ind = Sj ,
given . ind = Sjc ,
X . given = xjc )
}
}
# ( l2 ) - target Shapley effects estimation
l2 _ tse . mc <- shapleyPermEx ( model = modlin ,
Xall = Xall ,
Xset = Xset ,
d =d ,
Nv =1 e4 ,
No = 1 e3 ,
Ni = 3)
# Plot the results
print ( l2 _ tse . mc )
# ( l2 ) - target Shapley effects estimation with random permutations
l2 _ tse . mc . randperm <- shapleyPerm Ra n d ( model = modlin ,
Xall = Xall ,
Xset = Xset ,
d =d ,
Nv =1 e4 ,
No = 1 e3 ,
Ni = 3 ,
m =5)
# Plot the results
plot ( l2 _ tse . mc . randperm )
Listing 1: Minimal R code example for the Monte Carlo estimation.

37

Appendix D.2. Nearest-neighbor estimator
# Packages
library ( sensitivity )
library ( mvtnorm )
# Random sample of inputs - output
X <- rmvnorm (2000 , rep (0 ,3) , diag (3))
Y <- rbinom (2000 , 1 , 0.7)
# ( l2 ) - target Shapley effects estimation
l2 _ tse . knn <- sobolshap _ knn ( model = NULL ,
X=X)
tell ( l2 _ tse . knn , Y )
# Plot the results
plot ( l2 _ tse . knn )
# ( l2 ) - target Shapley effects estimation with random permutations
l2 _ tse . knn . randperm <- sobolshap _ knn ( model = NULL ,
X =X ,
rand . perm =T ,
n . perm =5)
tell ( l2 _ tse . knn . randperm , Y )
# Plot the results
plot ( l2 _ tse . knn . randperm )
Listing 2: Minimal R code example for the nearest-neighbor estimation.

38

