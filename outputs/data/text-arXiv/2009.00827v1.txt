Estimating the reciprocal of a binomial proportion
Jiajin Wei1,2 , Ping He1,∗ and Tiejun Tong2, †

arXiv:2009.00827v1 [stat.ME] 2 Sep 2020

1 Division

of Science and Technology, BNU-HKBU United International College,
Zhuhai, China

2 Department

of Mathematics, Hong Kong Baptist University, Hong Kong

September 3, 2020

Abstract
As a classic parameter from the binomial distribution, the binomial proportion
has been well studied in the literature owing to its wide range of applications.
In contrast, the reciprocal of the binomial proportion, also known as the inverse
proportion, is often overlooked, even though it also plays an important role in
various fields including clinical studies and random sampling. The maximum likelihood estimator of the inverse proportion suffers from the zero-event problem,
and to overcome it, alternative methods have been developed in the literature.
Nevertheless, there is little work addressing the optimality of the existing estimators, as well as their practical performance comparison. Inspired by this, we
propose to further advance the literature by developing an optimal estimator for
the inverse proportion in a family of shrinkage estimators. We further derive
the explicit and approximate formulas for the optimal shrinkage parameter under different settings. Simulation studies show that the performance of our new
estimator performs better than, or as well as, the existing competitors in most
practical settings. Finally, to illustrate the usefulness of our new method, we
also revisit a recent meta-analysis on COVID-19 data for assessing the relative
risks of physical distancing on the infection of coronavirus, in which six out of
seven studies encounter the zero-event problem.
Key words: Binomial proportion, Inverse proportion, Relative risk, Shrinkage
estimator, Zero-event problem

∗
†

Co-corresponding author. E-mail: heping@uic.edu.hk
Co-corresponding author. E-mail: tongt@hkbu.edu.hk

1

1

Introduction

The binomial distribution is one of the most important distributions in statistics, which
has been extensively studied in the literature with a wide range of applications. This
classical distribution has two parameters n and p, where n is the number of independent Bernoulli trials and p is the probability of success in each trial (Hogg, McKean,
and Craig, 2005). The probability of success, p, is also referred to as the binomial
proportion. For excellent reviews on its estimation and inference, one may refer to, for
example, Agresti and Coull (1998) and Brown, Cai, and DasGupta (2001).
Apart from the parameter p, it is known that some of its functions, say p(1 − p)
and ln(p), also play important roles in statistics and have received much attention. In
this article, we are interested in the reciprocal function
1
θ= ,
p

(1)

which is another important function of p yet is often overlooked in the literature.
For convenience, we also refer to θ in formula (1) as the inverse proportion of the
binomial distribution. To demonstrate its usefulness, we will introduce some motivating
examples in Section 2 that connect the inverse proportion with the relative risk (RR)
in clinical studies, and with the Horvitz-Thompson estimator (Horvitz and Thompson,
1952; Fattorini, 2006). Moreover, we will also introduce in Section 6 a relationship of
the inverse proportion to the number needed to treat (NNT) in clinical studies and
present some future directions (Altman, 1998; Laupacis, Sackett, and Roberts, 1988;
Hutton, 2000).
To start with, let X =

Pn

i=1

Xi , where Xi are independent and identically dis-

tributed random variables from a Bernoulli distribution with success probability p ∈
(0, 1). Then equivalently, X follows a binomial distribution with parameters n ≥ 1 and
p. Now if we want to estimate the inverse proportion θ, a simple method will be to

2

apply the maximum likelihood estimation (MLE) and it yields
θ̂MLE =

n
.
X

(2)

This estimator is, however, not a valid estimator because it is not defined when X = 0,
i.e. when there is no successful event in n trials. We refer to this problem as the
zero-event problem in the point estimation of θ. In fact, the same problem also exists
in the interval estimation of p. Specifically by Hogg, McKean, and Craig (2005), the
100(1 − α)% Wald interval is given as

p̂ ± zα/2

r

p̂(1 − p̂)
,
n

(3)

where p̂ = X/n, and zα/2 is the upper α/2 percentile of the standard normal distribution. When X = 0, the lower and upper limits of the Wald interval are both zero; and
consequently, they will not be able to provide a (1 − α) coverage probability for the
true proportion.
To overcome the zero-event problem, Hanley and Lippman-Hand (1983) proposed
the “Rule of Three” to approximate the upper limit of the 95% confidence interval
(CI) for p. Specifically, since the upper limit of the one-sided CI for p is 1 − 0.051/n
when X = 0, the authors suggested to approximate this upper limit by 3/n, which
then yields the simplified CI as (0, 3/n). For more discussion on the “Rule of Three”,
one may refer to Tuyl, Gerlach, and Mengersen (2009) and the references therein.
In particular, we note that the Wilson interval (Wilson, 1927) and the Agresti-Coull
interval (Agresti and Coull, 1998) for p have also been referred to as the variations of
the “Rule of Three”.
The Wilson interval was originated from Laplace who proposed the “Law of Succession” in the 18th century. As mentioned in Good (1980), Laplace’s estimator for the
binomial proportion was given as (X +1)/(n+2), which is indeed a shrinkage estimator
for p. Wilson (1927) generalized the shrinkage idea and proposed an updated “Law

3

of Succession” as p̃ = (X + c)/(n + 2c), where c > 0 is a regularization parameter.
Following the Wilson estimator, Agresti and Coull (1998) proposed to substitute p̃ for
p̂ in the Wald interval (3) and yields the Agresti-Coull interval as

p̃ ± zα/2

r

p̃(1 − p̃)
.
n

(4)

It is known that the Agresti-Coull interval (4) always performs better than the Wald
interval (3), no matter whether n is large or small (Brown et al., 2001).
By applying the Wilson estimator p̃, one may estimate the inverse proportion as
θ̃(c) =

n + 2c
,
X +c

c > 0.

(5)

Note that the family of estimators in (5) do not suffer from the zero-event problem,
and so θ̃(c) is a valid estimator for θ. On the other side, however, we find that θ̃(c)
may not provide an optimal estimate for θ in some common settings. For illustration,
we will show in Section 2.3 that there does not exist a finite value c > 0 such that θ̃ is
an unbiased estimator of θ when θ = 2, or equivalently, when p = 0.5.
In view of the inherent limitations in estimator (5), we propose to consider another
family of shrinkage estimators as
θ̂(c) =

n+c
,
X +c

c > 0.

(6)

It is interesting to point out that, as a special case, θ̂(1) = (n + 1)/(X + 1) has been
previously studied in the literature (Chao and Strawderman, 1972). More recently,
Fattorini (2006) applied θ̂(1) to estimate θ in sampling designs and demonstrated that
it provided a good performance when n is large. Moreover, Seber (2013) showed that
θ̂(1) is an asymptotically unbiased estimator of θ as n tends to infinity. When n is small,
however, θ̂(1) may not perform well due to the non-negligible bias in the estimator.
In this paper, we propose to develop an optimal estimator for the inverse proportion
in the family of shrinkage estimators (6) and also systematically study its statistical
4

properties. In Section 2, we introduce two real situations where an estimate of the
inverse proportion is needed, and meanwhile, we review the Haldane estimator and the
Fattorini estimator that have been well applied in practice. In Section 3, we reveal
the effect of the shrinkage parameter on the unbiasedness of the estimator and derive
the optimal shrinkage parameter c such that E[θ̂(c)] = θ. In Section 4, we conduct
simulation studies to evaluate the performance of our new estimator, and compare it
with existing competitors including the Fattorini estimator, the Haldane estimator and
a piecewise estimator. In Section 5, we revisit a recent meta-analysis on COVID-19
data by Chu et al. (2020) for assessing the relative risks of physical distancing on the
infection of coronavirus, and also apply our new estimator to overcome the zero-event
problem on the relative risks. Lastly, we conclude the paper in Section 6 with some
discussion and future work, and postpone the technical results in the Appendix.

2

Motivating examples

In this section, we present two motivating examples in which an estimate of the inverse
proportion θ is highly desired. The first example is related to the relative risk, and the
second example is related to the Horvitz-Thompson estimator.

2.1

The relative risk

In clinical studies, the relative risk (RR), also known as the risk ratio, is a commonly
used effect size for measuring the effectiveness of a treatment or intervention. Specifically, RR is defined as
RR =

p1
,
p2

(7)

where p1 is the event probability in the exposed group, and p2 is the event probability
in the unexposed group.
To estimate RR, we assume that there are n1 samples in the exposed group with
5

X1 being the number of events, and n2 samples in the unexposed group with X2 being
the number of events. Let also X1 follow a binomial distribution with parameters n1
and p1 , X2 follow a binomial distribution with parameters n2 and p2 , and that they
are independent of each other. Then by (7) and applying the MLEs of p1 and p2
respectively, RR can be estimated by
c = X1 /n1 = X1 n2 .
RR
X2 /n2
X2 n1

(8)

A problem of this estimator is, however, that it will suffer from the zero-event problem
when X2 = 0, which is the same problem as mentioned in Section 1.
To avoid the zero-event problem in estimator (8), Haldane (1956) recommended to
add 0.5 to all the counts of events, and that yields the modified estimator of RR as
f
RR(0.5)
= (X1 + 0.5)(n2 + 1)/[(X2 + 0.5)(n1 + 1)]. Following this idea, the inverse

proportion of the unexposed group is, in fact, estimated by
θ̃(0.5) =

n2 + 1
,
X2 + 0.5

which is a special case of estimator (5) with c = 0.5. For ease of presentation, we
refer to it as the Haldane estimator. Nevertheless, as will be shown in Section 4, the
Haldane estimator may not provide a satisfactory performance when it is applied to
estimate the inverse proportion. For additional evaluation on the Haldane estimator,
one may refer to Carter et al. (2010) and the references therein.
Besides, we note that an estimate of the inverse proportion is also needed, for
c and in the variance of ln(OR),
d where OR
d = p1 (1 −
example, in the variance of ln(RR)

p2 )/[p2 (1 − p1 )] is the estimated odds ratio. Specifically by Goodman (1964) and Gart

and Zweifel (1967), these two variances can be approximated as
1
1
1
1
−
+
− ,
n1 p1 n1 n2 p2 n2
1
1
1
d ≈ 1 +
Var(ln(OR))
+
+
,
n1 p1 n1 (1 − p1 ) n2 p2 n2 (1 − p2 )

c ≈
Var(ln(RR))

6

(9)

where the inverse proportions of the exposed and unexposed groups are, again, needed
to be estimated without suffering from the zero-event problem.

2.2

The Horvitz-Thompson estimator

On random sampling without replacement from a finite population, it is known that
the Horvitz-Thompson estimator has played an important role in the literature for
estimating the population total (Horvitz and Thompson, 1952; Cochran, 2007).
Let U be a population composed of t units {u1 , . . . , ut }, and pi be the first-order
selection probability associated with unit ui . Let also Ω be a random variable associated
with the population U, and Ωi be the value of Ω determined by unit ui . Following
P
these notations, the population total of Ω can be defined as T = ti=1 Ωi . Then as an
unbiased estimator of T , the Horvitz-Thompson estimator is given as
T̂ =

X

ωj θj =

j∈V

X ωj
j∈V

pj

,

(10)

where ωj is the observed value of Ωj , and V ⊆ {1, . . . , t} is a subset of samples selected
for estimating the population total. In practice, the inverse proportions θj = 1/pj are
often unknown and need to be estimated.
To estimate θj in (10), Fattorini (2006) proposed a numerical method via Monte
Carlo simulations. Specifically in each simulation, a total of n samples were selected
independently with replacement from the population U, with Xj being the number
of samples that contain the jth unit, where j ∈ V . Further to avoid the zero-event
problem on Xj , Fattorini applied estimator (6) with c = 1 to estimate the inverse
proportions by
θ̂j (1) =

n+1
,
Xj + 1

j ∈ V,

which then yields the modified Horvitz-Thompson estimator T̂m as T̂m =

(11)
P

j∈V

ωj θ̂j (1).

Unless otherwise specified, we will ignore the subscript j in (11) and refer to θ̂(1) as
7

the Fattorini estimator. Fattorini (2006) further showed that the modified HorvitzThompson estimator converges almost surely to T̂ in (10) with known pj when n tends
to infinity.

2.3

A comparison between the two families of estimators

For the Fattorini estimator in family (6) with c = 1, Seber (2013) showed that
E[θ̂(1)] = E



n+1
X +1



n+1

1 − (1 − p)n+1
1
=
=θ−θ 1−
.
p
θ

(12)

Then by the fact that limn→∞ Bias[θ̂(1)] = limn→∞ [−θ(1 − 1/θ)n+1 ] = 0 for any fixed
θ ∈ (1, ∞), the Fattorini estimator is an asymptotically unbiased estimator of θ when
n is large. In addition, when p is large enough, or equivalently when θ is close to 1,
the estimation bias of the Fattorini estimator is often negligible no matter whether n
is larger or small.
In contrast, for the estimator θ̃(1) = (n + 2)/(X + 1) in family (5) with c = 1, by
(12) we have
Bias[θ̃(1)] =



n+2
n+1



θ
E[θ̂(1)] − θ =
−θ
n+1



n+2
n+1


n+1
1
1−
.
θ

When θ is close to 1, the bias of θ̃(1) will converge to 1/(n + 1), which may not be negligible when n is small. As a numerical comparison between the two estimators, we let
p = 0.9 and n = 10, and it yields that Bias[θ̂(1)] ≈ −1.1 × 10−11 and Bias[θ̃(1)] ≈ 0.10.
Moreover, we present another evidence in the following theorem that the shrinkage
estimators in family (5) can be suboptimal, with the proof given in Appendix A.
Theorem 1 Let X be a binomial random variable with parameters n and p. Then for
the estimators in family (5), there does not exist a shrinkage parameter c such that
E[θ̃(c)] = θ when p = 0.5, or equivalently, when θ = 2.
In view of the above comparison, we will focus on the shrinkage estimators in family
8

(6) in this paper. Specifically in Section 3, we show that the Fattorini estimator θ̂(1)
is still suboptimal, and then propose the optimal estimation of the inverse proportion
to further advance the literature.

3

Optimal estimation of θ

Although the Fattorini estimator has some nice properties, it may not provide an
accurate estimate for θ when p is small. To illustrate this point, we consider n = 10
and p = 0.01, which yields the relative bias of the Fattorini estimator as large as
E[θ̂(1)] − θ
× 100% = −(1 − 0.01)11 × 100% ≈ −89.53%.
θ
This indicates that the Fattorini estimator θ̂(1) may still be suboptimal and needs to be
further improved. In addition by (12), the expected value of the Fattorini estimator is
always lower than θ; that is, the shrinkage estimator (6) with c = 1 is always negatively
biased. Inspired by this, we propose to probe into the whole family of estimators (6)
and find the optimal shrinkage parameter by solving the equation E[θ̂(c)] = θ.

3.1

Methodology

For ease of notation, we denote the expected value of θ̂(c) as
g(c) = E[θ̂(c)] =

 
n 
X
n+c
n
x=0

x+c

x

px (1 − p)n−x .

(13)

To assess the effect of the shrinkage parameter c on the unbiasedness of the estimator, we then treat g(c) as a function of the shrinkage parameter c and explore its
fundamental properties including the continuity, monotonicity and convexity.
Theorem 2 For the expected value function g(c) in (13) with any finite integer n, we
have the following properties: (i) g(c) is a continuous function of c on (0, ∞) with
9

limc→0 g(c) = ∞ and limc→∞ g(c) = 1; (ii) g(c) is a strictly decreasing function of c on
(0, ∞); and (iii) g(c) is a strictly convex function of c on (0, ∞).
The proof of Theorem 2 is given in Appendix B. Note that the inverse proportion
θ takes value on (1, ∞) and also g(1) < θ from formula (12). Then by Theorem 2 and
the Intermediate Value Theorem, there exists a unique solution c ∈ (0, 1) such that
g(c) = θ, or equivalently,
 
n 
X
1
n+c
n x
p (1 − p)n−x = .
g(c) =
x
x+c
p
x=0

(14)

When n is small, in particular for n = 1 or n = 2, we can derive the explicit solution
of c from equation (14). When n is large, since the degree of equation as a function
of c is with n + 1, there may not have an explicit solution for c in mathematics. To
summarize, we have the following theorem with the proof in Appendix C.
Theorem 3 When n is less than 3, the solution of c in equation (14) is given by

 p
cn =
 p − 0.5 + p0.5 − (p − 0.5)2

n = 1,
n = 2.

When n ≥ 3, we have the approximate solution of c as
cn ≈ 1 −

p−1 (1 − p)n+1
,
(n + 1)(1 + D1 )D2 − D1

(15)

where
1
[1 − (1 − p)n+1 ],
p(n + 1)
1
D2 = 2
[1 − (1 − p)n+2 − (n + 2)p(1 − p)n+1 ].
p (n + 1)(n + 2)

D1 =

To check the accuracy of the approximate solution in Theorem 3, we also plot the
10

numerical results of the true and approximate solutions of c as a function of p in Figure
1. Under various settings, we note that the true solution of c is given as a monotonically
increasing function of p with the upper bound 1. And in addition, our approximate
solution always works well as long as n or p is not extremely small.
n=25

0.0

0.0

0.2

0.2

0.4

0.4

0.6

0.6

0.8

0.8

1.0

1.0

n=10

0.0

0.2

0.4

p

0.6

0.8

1.0

0.0

0.2

p

0.6

0.8

1.0

0.8

1.0

n=100

0.2

0.2

0.4

0.4

0.6

0.6

0.8

0.8

1.0

1.0

n=50

0.4

0.0

0.2

0.4

p

0.6

0.8

1.0

0.0

0.2

0.4

p

0.6

Figure 1: The true and approximate solutions of c with n =10, 25, 50 or 100. The
empty circles represent the values of the true solution, and the solid lines represent the
values of the approximate solution.

11

3.2

Plug-in estimator

To apply Theorem 3 for the optimal shrinkage parameter, we need a plug-in estimator
for the unknown p. Intuitively, the MLE of p, p̂MLE = X/n, can serve as a natural
choice. By doing so, however, for n = 1 we have ĉ1 = p̂MLE = X and further it yields
that θ̂(ĉ1 ) = (1 + ĉ1 )/(X + ĉ1 ) = (1 + X)/2X, which then suffers from the zero-event
problem. For n = 2, it is noted that the same problem also remains. While for n ≥ 3,
the approximate solution will no longer suffer from the zero-event problem; but on
the other side, the denominator term, (n + 1)(1 + D1 )D2 − D1 , in (15) will be zero
when X = n, and consequently the approximate solution is still not be applicable.
To conclude, the MLE of p cannot be directly applied as the plug-in estimator when
applying Theorem 3 to estimate the inverse proportion.
To overcome the boundary problems on both sides, we consider the plug-in estimator of p with the following structure:
p̃plug (α) = min(max(p̂MLE , α), 1 − α),
where 0 < α ≤ 0.5 is the threshold parameter. Then with p̃plug (α) as the plug-in
estimator of p, we let c̃n (α) be the estimator of cn in Theorem 3. To determine the
best threshold value for practical use, we take several different α and then compute the
relative bias of the estimator, θ−1 E[θ̂(c̃n (α))] − 1, for numerical evaluation. Specifically
in Figure 2, we plot the relative biases of the estimator as functions of θ for α = 0.1,
0.2, 0.3, 0.4, 0.5 and n = 1, 2, 10, 50. While for comparison, the relative biases of the
Fattorini estimator are also presented in Figure 2.
In the top two panels of Figure 2, it is evident that a small threshold value, say
α = 0.1 or 0.2, may not provide an adequate remedy for the boundary problems when
n is extremely small. Note also that p̃plug (α) = 0.5 when α = 0.5. Then by Figure 1
that cn is always close to 1 when p = 0.5, the resulting estimator of θ with α = 0.5
will be nearly the same as the Fattorini estimator when n is large. And for moderate
sample sizes, say n = 10 and n = 50, the bottom two panels of Figure 2 show that the
12

n=1
1.0

1

1.5

1

n=2

1

1
1
1

1

1

2
3
4
5
0

1
2

1
2
3
4
5
0

2
3
4
5
0

3
4
5
0

2
3
4
5
0

2

2
3
4
5
0

3
4
5
0

1

2
3
4
5
0

1

2
3
4
5
0

1
2
3
4
5
0

1
2
3
4
5
0

0.0

0
5
4
3
2

3
4
5
0

1

2

1
2
3
4
5
0

1

1
2
3
0
4
5

2
3
4
5
0

3
4
5
0

1

2

1
2

3
4
5
0

−0.5

0.5

2

1

0.5

1

−0.5

1

1

2
2

3
4
5
0

3
4
5
0

3
4
5
0

2

2

3
4
5
0

3
4
5
0

2
3
4
5
0

2

2

3
4
5
0

3
4
5
0

1

2
3
4
5
0

1

2
3
4
5
0

−1.0

−1.5

1

2

4

θ

6

8

10

2

4

θ

n=10
1

1

1

1
1
1
2
3
4
5
0

2

2
3
4
5
0

2
3
4
5
0

2
3
4
5
0

4

2
3
4
5
0

2
3
4
5
0

θ

2
3
4
5
0

6

10

2
3
4
5
0

2

2

3
4
5
0

2

3
4
5
0

2

3
4
5
0

3
4
5
0

8

10

1

1

1

1

1
1
5
3
0
1
2
4

−0.005

Relative bias

0.5

1

1

0.001

1

5
3
0
1
2
4

5
3
0
1
2
4

5
1
3
0
2
4

1
2
5
3
0
4

1
5
3
0
2
4

2
5
3
0
4

1
2
5
3
0
4

2
5
3
0
4

−0.001

1

1

1
3
5
2
0
4

8

2
5
3
0
4
2
5
3
0
4
2
5
3
0
4

−0.003

1.0

1

5
3
0
1
2
4

6

n=50

1

0.0

1

2
5
3
0
4

2
5
3
0
4

2

4

θ

6

8

10

Figure 2: The relative biases of θ̂(c̃n ) with α = 0.1, 0.2, 0.3, 0.4 or 0.5. “1” represents
the relative biases associated with α = 0.1, “2” represents the relative biases associated
with α = 0.2, “3” represents the relative biases associated with α = 0.3, “4” represents
the relative biases associated with α = 0.4, and “5” represents the relative biases
associated with α = 0.5. And for comparison, “0” represents the relative biases of the
Fattorini estimator.
best value of α should be neither too small or too large. Taken together, we recommend
to apply αn = 1/(2 + ln(n)) as the adaptive threshold value, which follows a decreasing
trend, say, for example, α1 = 0.5, α10 = 0.23, α100 = 0.15, and α1000 = 0.11. Then with
p̃plug (αn ) = min(max(p̂MLE , αn ), 1 − αn ) as the plug-in estimator, our final estimator of
13

the inverse proportion is given by
θ̂(c̃n ) =

n + c̃n
,
X + c̃n

(16)

where c̃n = cn (p̃plug (αn )) is the estimator of cn given in Theorem 3.

4

Simulation studies

In this section, we conduct simulation studies to evaluate the finite sample performance
of our new estimator of the inverse proportion. As a baseline for comparison, we also
propose a piecewise estimator of θ as
θ̂PE =

n
,
X + I(X = 0)

(17)

where I(·) is the indicator function. In essence, the piecewise estimator (17) is a hardthresholding version of the MLE; and with X = 0 replaced by X = 1, the zero-event
problem in the MLE of θ will no longer exist. Moreover, the Fattorini estimator θ̂(1)
and the Haldane estimator are also included in the simulations for assessing how much
improvement our new estimators can achieve.
To generate the simulation data, we let θ range from 1.02 up to 50, which is equivalent to p ranging from 0.98 down to 0.02. We also consider n = 1, 2, 10 and 50
as four different sample sizes. Then for each combination of θ and n, we generate
N = 10, 000 data sets from the binomial distribution, estimate θ by the four estimators, and compute their empirical relative biases and mean squared errors (MSEs) as
follows:
!
θ̂k
−1 ,
θ
!2
N
1 X θ̂k
MSE[θ̂k ] =
−1 ,
N k=1 θ
N
1 X
Bias[θ̂k ] =
N k=1

14

where θ̂k is a generic notation for the kth estimate from each of the four estimators.
For illustration and comparison, we present the simulation results of the relative biases
and MSEs for n = 1 and 2 in Figure 3, and for n = 10 and 50 in Figure 4.

Figure 3: Comparison of the four estimators with n = 1 or 2. The solid circles
represent the simulation results of our new estimator θ̂(c̃n ), the empty circles represent
the simulation results of the Fattorini estimator θ̂(1), the empty rectangles represent
the simulation results of the Haldane estimator, and the empty triangles represent the
simulation results of the piecewise estimator θ̂PE .
The results with n = 1 or n = 2 in Figure 3 show that the new estimator θ̂(c̃n ) per15

Figure 4: Comparison of the four estimators with n = 10 or 50. The solid circles
represent the simulation results of our new estimator θ̂(c̃n ), the empty circles represent
the simulation results of the Fattorini estimator θ̂(1), the empty rectangles represent
the simulation results of the Haldane estimator, and the empty triangles represent the
simulation results of the piecewise estimator θ̂PE .
forms better than the Fattorini estimator and the piecewise estimator in both relative
biases and MSEs in most settings, as long as θ is not very small. The Haldance estimator is better than the other three estimators for large θ, while it performs poorly when
θ is close to 1. In addition, the Fattorini estimator is always better than the piecewise
estimator. From the top two panels in Figure 4 with n = 10, it is also evident that
16

the new estimator θ̂(c̃n ) provides the most reliable estimates for the inverse proportion
in most settings. In particular, we note that the piecewise estimator θ̂PE and the Haldane estimator fail to provide a stable performance; the new estimator θ̂(c̃n ) always
provides a smaller relative bias than the Fattorini estimator as long as θ is not close
to 1; and the new estimator θ̂(c̃n ) is also able to provide a MSE that is comparable to
the Fattorini estimator along with different values of θ. From the bottom two panels
in Figure 4 with n = 50, it is shown that our new estimator θ̂(c̃n ) and the Fattorini
estimator perform nearly the same, which coincides the findings in Figure 1 that the
optimal value of c is close to 1 when n is large. And once again, we note that the
piecewise estimator and the Haldane estimator do not provide a stable estimation.
To conclude, the new estimator θ̂(c̃n ) is better than, or at least as good as, the
Fattorini estimator in most settings, in particular when n is small. Moreover, the
piecewise estimator and the Haldane estimator fail to provide a stable performance,
although they perform well in some limited settings. Our new estimator θ̂(c̃n ) can
serve as a reliable estimator of the inverse proportion for practical use. For ease of
comparison, we also provide the summarized description for the four estimators in
Table 1.
Estimators
The optimal estimator
The Fattorini estimator
The Haldane estimator
The piecewise estimator

Applicability
Recommended no matter whether n is large
or small.
Recommended when n is large.
Not recommended when n is large.
Not recommended.

Table 1: Comparison among the optimal estimator, the Fattorini estimator, the Haldane estimator and the piecewise estimator.

17

5

An application to zero-event studies

In this section, we apply our new estimator into a recent meta-analysis on COVID-19
data with zero-event studies. Chu et al. (2020) carried out an excellent review to
investigate effects of physical distancing, face masks and eye protection on the infection of severe acute respiratory syndrome (SARS), Middle East respiratory syndrome
(MERS) and severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). This
systematic review was published in June 2020 and is now attracting more and more
attention, for example in Google Scholar as of 25 August 2020, their paper has already
received a total of 247 citations. Also as commented by MacIntyre and Wang (2020),
this systematic review provides a landmark for people to be aware of the importance
of physical distancing and face protection. In particular for physical distancing, they
applied the relative risks as effect sizes and concluded that the virus transmission is
significantly reduced with a further distance.
In the top panel of Figure 5, seven studies were included in their meta-analysis
of physical distancing for COVID-19 data, where six studies therein suffered from the
zero-event problem. For the four single-zero-event studies, the 0.5 continuity correction
was added to all the counts of events, while for the two double-zero-event studies, they
were not included in the meta-analysis. By Xu et al. (2020) and our simulation results,
adding the 0.5 continuity correction is suboptimal. Moreover, Xu et al. (2020) also
showed that the double-zero-event studies may also be informative, and so excluding
them can be questionable and/or even alter the results. In view of the above limitations,
we have re-conducted the meta-analysis on COVID-19 data that also include the two
double-zero-event studies. Specifically by applying our new estimator in (16), the
relative risks are estimated by
c n ) = (X1 + c̃n1 )(n2 + c̃n2 ) ,
RR(c̃
(X2 + c̃n2 )(n1 + c̃n1 )

(18)

where c̃n1 and c̃n2 are the estimates of the optimal shrinkage parameter for the exposed
group and the unexposed group, respectively. While for comparison, we also conduct
18

a meta-analysis for all seven studies by the 0.5 continuity correction, and then present
all the forest plots in Figure 5.

Figure 5: Forest plots on the relative risk between physical distancing and infection for
COVID-19 data.
From the middle and bottom panels of Figure 5, it is evident that the new metaanalytical results with the double-zero-event studies also support the claim that a
further distance will reduce the virus infection. On the other hand, the evidence

19

becomes less significant as the combined relative risks get larger. Moreover, by comparing the two forest plots that both include the double-zero-event studies, we also
note that our new estimator in (18) is able to yield a larger combined relative risk with
c in (9), the 0.5 cona narrower confidence interval. By the variance function of ln(RR)
tinuity correction may lead to a large estimate of the relative risk after the exponential
transformation, especially when the zero-event problem occurs. Hence, the confidence
intervals of the relative risks in the two double-zero-event studies are very wide, which
can indicate that there may exist high uncertainty in the interval estimation. In contrast, by applying our new estimator of the inverse proportion, the confidence intervals
for the double-zero-event studies will be much narrower.

6

Conclusion

The binomial proportion is a classic parameter originated from the binomial distribution, which has been well studied in the literature because of its wide range of
applications. In contrast, the reciprocal of the binomial proportion, also known as
the inverse proportion, is often overlooked, although it also plays an important role
in various fields including clinical studies and random sampling. However, it is known
that the MLE of the inverse proportion suffers from the zero-event problem. To overcome this problem, there have been existing estimators in the literature for the inverse
proportion including, for example, the Haldane estimator and the Fattorini estimator.
To further advance the literature, we first introduced two motivating examples
where an accurate estimate of the inverse proportion is desired. We then compared
two shrinkage families of estimators and figured out the family with better statistical
properties. Finally, we proposed a new estimator of the inverse proportion by deriving
the optimal shrinkage parameter c in the family of estimators (6). To be more specific,
we derived the explicit formula for the optimal c in Theorem 3 for n = 1 or 2, and an
approximate formula for the optimal c for n ≥ 3. Further to estimate the unknown p in
the formula of the optimal shrinkage parameter, a plug-in estimator was also introduced
20

and that also overcame the boundary problem of p. Simulation studies showed that
our new estimator performs better than, or as well as, the existing competitors in most
practical settings, and it can thus be recommended to estimate the inverse proportion
for practical application. Finally, we also applied our new estimator to a recent metaanalysis on COVID-19 data with the zero-event problem, and it yielded more reliable
results for the scientific question how physical distancing can effectively prevent the
infection of the new coronavirus.
To conclude the paper, we have made a good effort in finding the optimal estimator
for the inverse proportion related to the binomial distribution. According to Gupta
(1967), there does not exist an unbiased estimator for the inverse proportion θ. To verify this result, by the proof-by-contradiction we assume that θ̂u = η(X) is an unbiased

P
estimator of θ. Then by definition, E(θ̂u ) = nx=0 η(x) nx px (1 − p)n−x = θ. From the

left-hand side, the expected value of θ̂u is a polynomial of p with degree n. While for
P
i
the right-hand side, by the Taylor expansion we have θ = 1/p = ∞
i=0 (1 − p) , which

is a polynomial of p with infinite degree. This shows that the unbiasedness cannot be

held for any finite n. In view of this property, there is probably no uniformly best
estimator for the inverse proportion. Although we have conducted some nice work in
this paper, we believe that more advanced research is still needed to further improve
the estimation accuracy of the inverse proportion. For example, one may consider to
develop a better and more robust approximation for the optimal shrinkage parameter when the binomial proportion p is extremely small. In addition, other families
of shrinkage estimators can also be considered to see whether they can yield better
estimators for the inverse proportion.
Last but not least, we note that our new estimation of the inverse proportion can
have many other real applications. For instance, the spirit of our new method may also
be applied to estimate the number needed to treat (NNT), which is another important
medical term and was first introduced by Laupacis et al. (1988). Specifically, NNT is
defined as NNT = 1/(p1 − p2 ), where p1 is the event probability in the exposed group
and p2 is the event probability in the unexposed group. Noting also that p1 − p2 is
21

the absolute risk reduction (ARR), NNT can be explained as the average number of
patients who are needed to be treated to obtain one more patient cured compared with
a control in a clinical trial (Hutton, 2000). Nevertheless, the estimation of NNT will
be more challenging than the estimation of the inverse proportion, mainly because the
estimate of p1 − p2 can be either positive or negative, in addition to the zero-event
problem in the denominator. More recently, Veroniki et al. (2019) also referred to this
situation as the statistically nonsignificant result, which may lead to an unexpected
calculation complication. We expect that our new work in this paper will shed light
on new directions on the NNT estimation, which can be particularly useful in clinical
trials and evidence-based medicine.

References
Agresti, A., and Coull, B. A. (1998). Approximate is better than “exact for interval
estimation of binomial proportions. The American Statistician 52, 119–126.
Altman, D. G. (1998). Confidence intervals for the number needed to treat. British
Medical Journal 317, 1309–1312.
Brown, L. D., Cai, T. T., and DasGupta, A. (2001). Interval estimation for a binomial
proportion. Statistical Science 16, 101–117.
Carter, R. E., Lin, Y., Lipsitz, S. R., Newcombe, R. G., and Hermayer, K. L. (2010).
Relative risk estimated from the ratio of two median unbiased estimates. Journal of
the Royal Statistical Society: Series C 59, 657–671.
Casella, G., and Berger, R. L. (2002). Statistical Inference. Pacific Grove: Duxbury.
Chao, M. T., and Strawderman, W. E. (1972). Negative moments of positive random
variables. Journal of the American Statistical Association 67, 429–431.
Chu, D. K., Akl, E. A., Duda, S., Solo, K., Yaacoub, S., Schnemann, H. J., & COVID19 Systematic Urgent Review Group Effort (SURGE) study authors (2020). Physical
distancing, face masks, and eye protection to prevent person-to-person transmission
of SARS-CoV-2 and COVID-19: a systematic review and meta-analysis. Lancet 395,
1973–1987.

22

Cochran, W. G. (2007). Sampling Techniques. New York: John Wiley & Sons.
Fattorini, L. (2006). Applying the Horvitz-Thompson criterion in complex designs: a
computer-intensive perspective for estimating inclusion probabilities. Biometrika 93,
269–278.
Gamrot, W. (2013). On a class of estimators for a reciprocal of Bernoulli parameter.
Studia Ekonomiczne 133, 71–85.
Gart, J. J., and Zweifel, J. R. (1967). On the bias of various estimators of the logit
and its variance with application to quantal bioassay. Biometrika 54, 181–187.
Good, I. J. (1980). Some history of the hierarchical Bayesian methodology. In J. M.
Bernardo, M. H. DeGroot, D. V. Lindley, and A. F. M. Smith (Eds.), Bayesian
Statistics, 489–519. Valencia: University Press.
Goodman, L. A. (1964). Interactions in multidimensional contingency tables. Annals
of Mathematical Statistics 35, 832–646.
Gupta, M. K. (1967). Unbiased estimate for 1/p. Annals of the Institute of Statistical
Mathematics 19, 413–416.
Haldane, J. B. S. (1956). The estimation and significance of the logarithm of a ratio
of frequencies. Annals of human genetics 20, 309–311.
Hanley, J. A., and Lippman-Hand, A. (1983). If nothing goes wrong, is everything all
right? Interpreting zero numerators. Journal of the American Medical Association
249, 1743–1745.
Hogg, R. V., McKean, J., and Craig, A. T. (2005). Introduction to Mathematical
Statistics. Boston: Pearson Education.
Horvitz, D. G., and Thompson, D. J. (1952). A generalization of sampling without
replacement from a finite universe. Journal of the American Statistical Association
47, 663–685.
Hutton, J. L. (2000). Number needed to treat: properties and problems. Journal of
the Royal Statistical Society: Series A 163, 381–402.
Jovanovic, B. D., and Levy, P. S. (1997). A look at the rule of three. The American
Statistician 51, 137–139.
Laupacis, A., Sackett, D. L., and Roberts, R. S. (1988). An assessment of clinically
useful measures of the consequences of treatment. New England Journal of Medicine
318, 1728–1733.
23

MacIntyre, C. R., and Wang, Q. (2020). Physical distancing, face masks, and eye
protection for prevention of COVID-19. Lancet 395, 1973–1987.
Seber, G. A. (2013). Statistical Models for Proportions and Probabilities. Heidelberg:
Springer.
Tuyl, F., Gerlach, R., and Mengersen, K. (2009). The rule of three, its variants and
extensions. International Statistical Review 77, 266–275.
Veroniki, A. A., Bender, R., Glasziou, P., Straus, S. E., and Tricco, A. C. (2019).
The number needed to treat in pairwise and network meta-analysis and its graphical
representation. Journal of Clinical Epidemiology 111, 11–22.
Wilson, E. B. (1927). Probable inference, the law of succession, and statistical inference.
Journal of the American Statistical Association 22, 209–212.
Xu, C., Li, L., Lin, L., Chu, H., Thabane, L., Zou, K., and Sun, X. (2020). Exclusion
of studies with no events in both arms in meta-analysis impacted the conclusions.
Journal of Clinical Epidemiology. 123, 91–99.

24

Appendix A: Proof of Theorem 1
Proof. Assume that there exists a value c > 0 such that E[θ̃(c)] = θ. When p = 0.5,
by definition we have
E[θ̃(c)] =

 
n 
X
n
n + 2c
x+c

x=0

x

px (1 − p)n−x =

1
h(c),
2n

where
 
n 
X
n + 2c
n
h(c) =
.
x
x
+
c
x=0
Hence to show that the estimator is unbiased for θ = p−1 = 2, it is equivalent to show
that there exists a value c > 0 such that h(c) = 2n+1 .
The first derivative of h(c) is
 
n
X
2x − n n
.
h (c) =
2 x
(x
+
c)
x=0
′

When n is an even number, by noting that
derivative as

n
x



=

(19)


n
n−x

, we can rewrite the first

n/2−1 


 

2x − n n
2(n − x) − n
n
h (c) =
+
2 x
(x
+
c)
(n − x + c)2 n − x
x=0
 
n/2−1 
X 2x − n n
n − 2x
n
=
+
,
2
2
(x + c) x
(n − x + c) x
x=0
′

X

where the term with x = n/2 is zero and so is excluded. Note also that, for any
x = 0, . . . , n/2 − 1, we have n − x > x and further
 
 
 
 
2x − n n
n − 2x
2x − n n
n − 2x n
n
+
<
+
= 0.
(x + c)2 x
(n − x + c)2 x
(x + c)2 x
(x + c)2 x
This shows that h′ (c) < 0 for any c > 0. When n is an odd number, we can write the

25

first derivative of h(c) as

′

h (c) =

(n−1)/2 

X
x=0


 

2(n − x) − n
n
2x − n n
+
.
(x + c)2 x
(n − x + c)2 n − x

And similarly, we can show that h′ (c) < 0 for any c > 0. Combining the above results,
h(c) is a strictly decreasing function of c on (0, ∞).
In addition, for any finite n we note that
lim h(c) =

c→∞

n
X
x=0

lim

c→∞



n + 2c
x+c

 
n  
X
n
n
= 2n+1 .
=2
x
x
x=0

This shows that there does not exist a finite value of c > 0 such that h(c) = 2n+1 , and
so Theorem 1 holds.

Appendix B: Proof of Theorem 2
Proof. To prove (i), we note that (n + c)/(x + c) is a rational function of c and so
is always continuous on the domain of (0, ∞). Now since n is also finite, g(c) is a
continuous function of c on (0, ∞). Also for the limit of g(c),
#
" n 
X n + c  n
x
n−x
p (1 − p)
lim g(c) = lim
c→0
c→0
x
x+c
x=0



 
n 
X
n+c
n x
n+c
n−x
n
= lim
p (1 − p)
(1 − p) +
lim
c→0
c→0 x + c
x
c
x=1
= ∞,

"

#
 
n 
X
n+c
n x
n−x
lim g(c) = lim
p (1 − p)
c→∞
c→∞
x
x+c
x=0

 
n 
X
n+c
n x
n−x
=
lim
p (1 − p)
c→∞ x + c
x
x=0
= 1.

26

To prove (ii), we verify that the first derivative of g(c)
 
n−1
X
x−n n x
p (1 − p)n−x < 0.
g (c) =
2
(x + c) x
x=0
′

Hence, g(c) is a strictly decreasing functon of c on (0, ∞).
To proof (iii), we show that the second derivative of g(c)
 
n−1
X
2(n − x) n x
g (c) =
p (1 − p)n−x > 0.
3
(x + c) x
x=0
′′

As a consequence, g(c) is a strictly convex function of c on (0, ∞).

Appendix C: Proof of Theorem 3
Proof. When n = 1, equation (14) becomes



1+c
1
(1 − p) + p = ,
c
p

from which we obtain c1 = p.
When n = 2, it is necessary to solve


2+c
c



2

(1 − p) + 2



2+c
1+c



1
p(1 − p) + p2 = .
p

After factorizing this equation, we have
c2 + (1 − 2p)c − 2p(1 − p) = 0.
p
0.5 − (p − 0.5)2 . To remain a positive value of the
p
estimator, the value of c is required to be positive, so c2 = p − 0.5 + 0.5 − (p − 0.5)2 .
The solutions are c = p − 0.5 ±

To get the solution of c when n ≥ 3, we apply the Taylor expansion of 1/(X + c)

27

around c = 1 and it yields that
1
c−1
1
=
−
+ O((c − 1)2 ).
2
X +c
X + 1 (X + 1)

(20)

By (13) and (20), for any finite n we have



(n + c)(c − 1)
n+c
−E
+ O((c − 1)2 )
g(c) = E
2
X +1
(X + 1)




n+c
(n + 1)(c − 1)
(c − 1)2
=E
−E
+ O((c − 1)2 )
+
2
2
X +1
(X + 1)
(X + 1)




(n + 1)(c − 1)
n+c
−E
+ O((c − 1)2 ).
=E
X +1
(X + 1)2


(21)

Let D1 = E[1/(X + 1)] and D2 = E[1/(X + 1)(X + 2)]. For D1 , we have
 
n
1 Xn+1 n x
D1 =
p (1 − p)n−x
n + 1 x=0 x + 1 x
n

X
1
(n + 1)!
=
px+1 (1 − p)n+1−(x+1)
p(n + 1) x=0 (x + 1)!(n − x)!

n+1 
X
1
n+1 s
p (1 − p)n+1−s
=
s
p(n + 1) s=1
=

1
[1 − (1 − p)n+1 ],
p(n + 1)

where s = x + 1. And for D2 , we have
 
n
X
1
(n + 1)(n + 2) n x
D2 =
p (1 − p)n−x
(n + 1)(n + 2) x=0 (x + 1)(x + 2) x
n

=
=

X
1
(n + 2)!
px+2 (1 − p)n+2−(x+2)
2
p (n + 1)(n + 2) x=0 (x + 2)!(n − x)!
p2 (n

1
[1 − (1 − p)n+2 − (n + 2)p(1 − p)n+1 ].
+ 1)(n + 2)

Now with D1 and D2 , to derive the solution of c, we take the approximation E[1/(X +
1)2 ] ≈ (1 + D1 )D2 and also ignore the remainder term O((c − 1)2 ) in (20). Then

28

consequently, we have the approximate equation as (n+c)D1 −(n+1)(c−1)(1+D1)D2 ≈
1/p, which yields the approximate solution of c as
cn ≈ 1 −

p−1 (1 − p)n+1
1/p − (n + 1)D1
=1−
.
(n + 1)(1 + D1 )D2 − D1
(n + 1)(1 + D1 )D2 − D1

29

(22)

