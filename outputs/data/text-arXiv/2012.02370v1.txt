Birdspotter: A Tool for Analyzing and Labeling Twitter Users
Rohit Ram

Quyu Kong

Marian-Andrei Rizoiu

University of Technology Sydney
Sydney, Australia
rohit.ram@uts.edu.au

Australian National University &
UTS & Data61, CSIRO
Canberra, Australia
quyu.kong@anu.edu.au

University of Technology Sydney &
Data61, CSIRO
Sydney, Australia
marian-andrei.rizoiu@uts.edu.au

arXiv:2012.02370v1 [cs.CY] 4 Dec 2020

ABSTRACT
The impact of online social media on societal events and institutions
is profound; and with the rapid increases in user uptake, we are
just starting to understand its ramifications. Social scientists and
practitioners who model online discourse as a proxy for real-world
behavior, often curate large social media datasets. A lack of available tooling aimed at non-data science experts frequently leaves
this data (and the insights it holds) underutilized. Here, we propose
birdspotter – a tool to analyze and label Twitter users –, and
birdspotter.ml – an exploratory visualizer for the computed metrics. birdspotter provides an end-to-end analysis pipeline, from
the processing of pre-collected Twitter data, to general-purpose
labeling of users, and estimating their social influence, within a
few lines of code. The package features tutorials and detailed documentation. We also illustrate how to train birdspotter into a
fully-fledged bot detector that achieves better than state-of-the-art
performances without making any Twitter API online calls, and we
showcase its usage in an exploratory analysis of a topical COVID-19
dataset.

1

INTRODUCTION

Barely a decade old, social media in general — and Twitter in particular — are becoming increasingly important in shaping societal
events. They serve as novel fora for a wide array of users who express themselves, discuss, but also promote agendas and attempt to
influence the outcome of the said societal events. As a result, social
and political scientists, but also journalists and communication scientists, turn to social media increasingly often as a proxy to study
society. They carefully curate and label large social media datasets,
and here a gap emerges. There is a limited offer of tools aimed at
non-machine learning experts to analyze users in already existing
datasets without making additional web API calls, which can limit
the amount of retrieved data. This work aims to fill in this gap by
proposing birdspotter, a package aimed at non-computing practitioners with quantitative expertise (basic R or Python), to analyze,
describe and automatically label users in Twitter datasets.
This work addresses three specific open questions concerning
analyzing Twitter users. The first question relates to the availability of user analysis tools. Existing tools are typically designed for
Twitter branding and management, i.e. to either analyze a user’s
or organization’s own account (Twitter Analytics6 , or Brandwatch
Consumer Research7 ) or one given user account (Account Analysis
1 birdspotter

source code, tutorial, and feature list: https://github.com/behavioralds/BirdSpotter
2 birdspotter.ml public installation: https://www.birdspotter.ml
3 birdspotter documentation: https://birdspotter.readthedocs.io
4 COVID-19 tutorial: https://github.com/behavioral-ds/user-analysis
5 Supplementary Material: https://bit.ly/3d0EE0r

Figure 1: The birdspotter.ml visualization system: Twitter
users are plotted based on their user influence and botness
(left panel), and a selected user’s profile (top-right) and cascade history (bottom-right) are shown.
Tool8 ). The question is does there exist a tool to retrospectively
analyze and label all the users in Twitter dumps, aimed at
non-data science experts with computational expertise? We
address this question by proposing birdspotter1 , an integrated
Twitter user analysis tool, that can achieve three types of analysis
in only a couple of lines of code. First, it processes existing Twitter
datasets (e.g. jsonl data dumps collected through the Streaming
API). Second, it describes users using three types of features (relating to the user, content semantics, and hashtag usage). Last, it
trains a classifier against a labeled user subset, which can be used
to automatically label the rest of the dataset.
The second open question relates to profiling user botness and
influence on previously collected data. The state-of-the-art bot detector, botometer [12], can only be accessed through its web APIs
and cannot produce predictions for users that are no longer accessible, such as suspended accounts. Since bots have a high tendency
of being suspended by Twitter, measuring botness a while after
collecting data risks missing a large proportion of the bots involved
in discussions. Similarly, existing influence estimation tools require
knowledge of the social graph, which is sometimes impossible to
capture retrospectively. The question is: can we design a tool that
quantifies users’ botness and influence on existing curated
datasets, without the need of online API calls of supplementary information? We address this question two-fold. First, using
6 Twitter

Analytics: https://analytics.twitter.com/
Consumer Research: https://www.brandwatch.com
8 Account Analysis Tool: https://accountanalysis.app

7 Brandwatch

Conference’17, July 2017, Washington, DC, USA

four existing Twitter bot datasets, we train birdspotter to detect bots without requiring additional API calls. We show that
birdspotter achieves a higher performance than the current stateof-the-art botometer [12]; birdspotter ships the bot detector by
default, with the package. Second, we implement a diffusion-based
influence estimation [11], which has been shown to be as accurate
as using the social graph.
The third open question is can we visualize and explore both
broad and specific views of Twitter users and their activity?
We address this question by proposing birdspotter.ml2 , a tool
that provides both broad views of the user population’s botness
and influence, and allows individual inspection and exploration of
the activity of users (see Fig. 1 for the main interface of birdspotter.ml).
The main contributions of this paper are as follows:
• birdspotter1 — a software package designed to label online
users from already collected data, and to estimate online user
influence based on the reshare cascades.
• birdspotter.ml2 — an online visualizer designed to perform
exploratory analysis of online Twitter users.
• We build an offline bot detector using four public labeled datasets,
and we show it achieves better performance than the state-ofthe-art; we showcase the trained detector on an example analysis
of users discussing COVID-194 .
Related work. Here, we present the prior work most relevant to
birdspotter. For a complete related work discussion, please refer
to the online appendix5 .
Tree-based ensemble methods have been shown to dominate
social bot detection (over deep learning), due to the heterogeneity
in bots and relative sparsity of training data. However, deep learning performance has been demonstrated at a tweet-level [6]. The
de-facto bot detection tool is botometer (formerly BotOrNot) [4],
which uses more than 1000 user- and recent activity-related features
to train a Random Forest classifier. The main limitations of botometer are 1) its dependence on an online API which is rate-limited
by Twitter, 2) lack of reproducibility, since deactivated, protected,
and suspended users can no longer be retrieved, and 3) botometer
scores are likely to vary with user activity and botometer versioning. Birdspotter addresses the above by producing bot predictions
on pre-collected Twitter dumps.
User influence is typically measured using static user attributes [3],
analyzing the online social graph [9], and modeling information diffusion [15]. Closest to our work is ConTinEst [5], which requires
knowledge of the social graph (often prohibitively expensive to
obtain) on which it performs random walks (very slow on large
social graphs). Birdspotter estimates user influence from reshare
dynamics, in the absence of knowledge about the social graph.

2

PRELIMINARIES

In this section, we briefly outline prerequisites concerning influence
estimation using point-process models. For a thorough construction
of the influence estimation, please refer to the online appendix5 .
User influence estimation. birdspotter implements the algorithm in [10], estimating online influence as the mean number of
retweets generated, directly and indirectly, by a user’s (re)tweet.
Rizoiu et al. [10] estimate user influence, absent of the retweet

Rohit Ram, Quyu Kong, and Marian-Andrei Rizoiu

branching structure, by assuming that retweets arrive following a
Hawkes point process [11]. They estimate the probability that the
𝜙 (𝑚𝑖 ,𝑡 𝑗 −𝑡𝑖 )
,
𝜙 (𝑚𝑘 ,𝑡 𝑗 −𝑡𝑘 )

tweet 𝑣 𝑗 = (𝑚 𝑗 , 𝑡 𝑗 ) is a direct retweet of 𝑣𝑖 as 𝑝𝑖 𝑗 = Í 𝑗 −1

𝑘=1

where 𝑚 𝑗 is the associated user’s follower count, 𝑡 𝑗 is the time of
the event, and 𝜙 (𝑚, Δ𝑡) = 𝜅𝜃𝑚 𝛽 𝑒 −𝜃 Δ𝑡 is the marked Hawkes exponential kernel of parameters 𝜅, 𝛽 and 𝜃 . The pairwise influence
represents the probability that 𝑣𝑖 indirectly generates 𝑣 𝑗 , and is
Í 𝑗−1
computed as 𝑟𝑖 𝑗 = 𝑘=𝑖 𝑟𝑖𝑘 𝑝𝑘 𝑗 when 𝑖 < 𝑗, 𝑟𝑖𝑖 = 1, and is 0 otherwise. Furthermore, a tweet’s influence is the sum of its pairwise
influences, and a user’s influence is the average of the tweets’ influences.

3

PACKAGE OVERVIEW

In this section, we give an overview of birdspotter and birdspotter.ml, and describe their usage, functionalities, and design.

3.1

birdspotter

birdspotter labels users and measures influence on previously
collected tweets in the standard jsonl or json format.
Measuring influence. birdspotter measures user influence as
outlined in Section 2, using by default a marked Hawkes exponential
kernel with parameters 𝛽 = 1, 𝜅 = 𝜃1 and 𝜃 = 6.8 × 10−4 . These
were tuned on a large collection of real cascades [10], and can be
customized using the function getInfluenceScores().
Usage and functionalities. Given a dataset of tweets collected
externally (e.g. leveraging the Twitter Filter API), birdspotter’s
core functionality revolves around two steps. First, it loads the
Twitter dataset, extracts retweet cascades, and compiles the userlevel information. In the second step, it performs the influence
analysis and user labeling. The former is achieved by simply invoking the BirdSpotter constructor, while the latter is achieved
by calling the function getLabeledUsers(), which returns a table
with the user features detailed above. For every observed cascade,
birdspotter also computes the most likely branching structure
(see 𝑝𝑖 𝑗 in Section 2). This can be achieved using the function getCascadesDataFrame(), which returns the reshare cascades (i.e.
original tweet and all its retweets) with the additional column expected_parent indicating a retweet’s most likely parent tweet.
For power users, birdspotter provides a number of robust configurations — such as changing the parameters of the Hawkes kernel or using user-defined word embeddings — documented using
its readthedocs3 documentation. A usage tutorial is available on
birdspotter’s repository1 . For users who prefer to analyze the results outside python, birdspotter can dump the user table and the
reshare cascades in Comma Separated Values (CSV) files, that can be
loaded in outside tools. All birdspotter functionalities can be accessed in R via reticulate (https://github.com/rstudio/reticulate).
Feature Construction. birdspotter constructs user features1 in
three categories: Twitter user, semantic, and topic-based features.
Twitter user features are engineered directly from twitter user attributes and capture heuristics of common bot behavior. Semantic
features are constructed (by default) from FastText 300d word2vec
embeddings [8] of users’ tweets content and descriptions. Content
embeddings are averages of tweet embeddings, which are averages of word embeddings. Topic-based features are the vectors
of the 1,000 most frequent hashtags, scored for each user using the

Birdspotter: A Tool for Analyzing and Labeling Twitter Users

Conference’17, July 2017, Washington, DC, USA
High

1.00

0.988

0.987

0.997

0.998

0.953

0.922

0.982

0.95

0.927

0.90

0.887
0.866

0.85
0.80
BS

BT

HT

SM

TU

SM

T
T
M
+ HU + H + S
T
TU

0.82

0.39

(a)

Feature Value

Mean AUC ± s.d.

veriﬁed
friends_count
years_on_twitter
n_quotes
retweet_count
status_text_n_mentions
favourite_count
des_w2v_211
statuses_rate
iphone
des_w2v_31
ﬀ_ratio
status_text_n_extraspaces
con_w2v_247
android
con_w2v_239
con_w2v_12
des_w2v_123
listed_count
con_w2v_226

<- Human-like
4

3

2

Bot-like ->
1

0

1

2

3

Low

SHAP value (impact on model output)

(b)

(c)

Figure 2: (a) Mean AUC +/- standard deviation, varying ablated models and botometer. Models/Features are indicated by BS
(birdspotter), BT (botometer), HT (Hashtags), SM (Semantic),and TU (Twitter User). (b) Mean 𝐹 1 score versus bot threshold,
for birdspotter and botometer. (c) SHAP summary plot where points indicate classifier decisions, y-axis shows features in
decreasing importance, x-axis shows SHAP impact value, and color indicates feature value. Positive SHAP indicates bots.
term frequency-inverse document frequency scheme. birdspotter
is designed to be easily extended with any arbitrary (numerical)
features to allow for rapidly evolving bot strategies [13].
User labeling. birdspotter implements a supervised labeler. It
engineers a large selection of features, and it uses a Gradient Boosting Machine model (XGBoost [2] implementation), with hyperparameters tuned via Random Search and 5-fold cross-validation.
Beyond bot prediction. Birdspotter ships by default a pre-trained
bot classifier (see Section 4), however birdspotter can be customized to a particular application or dataset through labeling and
re-training. The function getBotAnnotationTemplate() outputs
a CSV that can be annotated by the user, and trainClassifierModel() re-trains the classifier with this annotated data. An option
controls whether the model is further tuned starting from the existing model (useful for adapting bot detection to a particular dataset)
or retrained from scratch. We exemplify this in Section 4.
Data Structures. birdspotter’s main class, called BirdSpotter,
is used to access methods and attributes. birdspotter makes accessible three pandas dataframes through the main object after processing: featuresDataframe (users and their extracted features),
cascadeDataframe (tweets and cascade information), and hashtagDataframe (TF-IDF of hashtags).
Performance. birdspotter performed the extraction, processing,
and profiling of a dataset of 196,269 tweets and 129,778 users, in
just 5.7 milliseconds per tweet, on a machine with an Intel Xeon
W-2145 CPU.
Installation. birdspotter installs in the canonical Python way:
pip install birdspotter.

3.2

birdspotter.ml visualiser

birdspotter.ml2 is a visualizer built on top of birdspotter, and
designed to analyze Twitter users engaged in online discussions.
The visualisation provides both broad and specific views of the data,
via the three components shown in Fig. 1: a scatter plot component,
a user information component, and a cascade view component.
The Scatter Plot. The left panel contains the scatter-plot showing
the influence percentile (on the x-axis) and botness (on the y-axis)
of a random sample of the users from the dataset, and the underlying 2-D density over the entire data set. Users are colored based

on the hashtag they use most and, when selected, the user and cascade views are populated. The plot is pan-able and zoom-able. The
view starts with a random sample 1,000 users, and is dynamically
populated as practitioners explore cascades.
The User View. The top-right panel provides information about
a selected user, including their Twitter image (hyper-link to the
user’s profile), screen name, location, the hashtags they used, and
some basic metrics.
The Cascade View. The bottom-right panel shows the cascades
the selected user participates in, which are select-able via a carousel.
The component shows the text of the original tweet, the timing
of the retweets and the most-likely branching structure inferred
using birdspotter. The points on this component are select-able
and hover-able in the same way as the scatter plot. The component
also is pan-able and zoom-able.

4

BUILDING A BOT DETECTOR

In this section, we show how birdspotter can be trained as a bot
classifier, achieve comparable performances to the state of the art
botometer, and used to profile a topical COVID-19 Twitter dataset.
Training data. birdspotter provides the functionality to retrain
and update the current model, which we leverage to build a bot detector. We train on four public bot datasets, including {botometerfeedback-2019, political-bots-2019} [13], and {verified-2019,
botwiki-2019} [14], sourced from Bot Repository 9 .
Training. The Bot Repository only provides account level data,
whereas birdspotter is designed to utilize tweet jsonl. We use the
tool twarc to acquire the timeline of each available user’s first 200
tweets, to construct jsonl training data. We extract and preprocess
the data with BirdSpotter(), label the resulting dataframe with
users’ ground truth values, and run trainClassifierModel() on
this training data to acquire our final model. This model is shipped
as the default at birdspotter installation.
Botometer comparison. We compare the derived model against
botometer, by acquiring their bot scores (universal CAP [13]) for
available users through their API. Our training data is a subset
of botometer’s as botometer more user features extracted from
9 available

from https://botometer.osome.iu.edu/bot-repository/datasets.html

Conference’17, July 2017, Washington, DC, USA

Rohit Ram, Quyu Kong, and Marian-Andrei Rizoiu
3

10−5

10−3

1.7

10−3

CCDF

1

10−1

3.2

CCDF

0.27

density

10−1
2

10−5

0
0

0.5

1

botness

(a)

1

102

influence

104

1

101

102

103

user activity

(b)

Figure 3: Quantifying user botness and influence analysis on COVID-19 dataset. (a) Code required to perform the core birdspotter functionalities: load a Twitter dump, generate cascade and user information, annotate and fine-tune the bot classifier. (b)
A density plot of user botness scores, and complementary cumulative density plots (CCDF) of user influence and user activity.
The dashed red lines show the mean values.
the online API. Fig. 2a shows that birdspotter marginally outperforms botometer in terms of mean AUC. Fig. 2b shows that
birdspotter consistently out-performs botometer with respect
to mean 𝐹 1 scores, over all bot score thresholds.
Ablation study. We test the importance of each set of features
through various ablations of our main model. Fig. 2a shows the
mean AUC for various subsets of features. It shows that Twitter
user features and semantic features are independently informative
of bot-like behaviour, while hashtag features show more variation.
The hashtag model performance may be due to the attrition caused
by user availability, or an artifact of training on the mixture of
bot datasets (within which hashtags relate to different topics). Despite this we retain hashtag features in birdspotter, for better
generalizability when users train and test on their own domain
datasets. The most performative model uses Twitter user features
and semantic features.
SHAP analysis. We use shap [7] for explaining the impact of
features in our tree ensemble model. Fig. 2c shows that the Twitter
user features form the majority, and semantic features a minority
of the impactful features, in line with the ablation study.
COVID-19 Application Dataset. We apply birdspotter to a
COVID-19 dataset [1], supplied as tweet IDs which were re-hydrated
with twarc to a jsonl format, recovering 68.8% of the original
dataset. We limit our analysis to the ∼ 1.5M unique tweets relating to posts on January the 31st, resulting in ∼ 0.28M users and
∼ 0.42M cascades.
Dataset profiling. Fig. 3b shows the empirical distributions of
botness, influence and activity (i.e., the number of cascades a user
participates in). The distribution of botness indicates two maxima;
the larger indicating the humans and the smaller indicating the
bots (i.e. a non-trivial participation of bots). Conforming with the
literature [10], influence and activity are long-tailed (following a
“rich-get-richer” paradigm).
(Re-)Labeling Users. Exploring birdspotter.ml we observe humans — @DumplingSays, @eddfuentess, and @marat_dospolov —
with bot scores of 0.873, 0.83, and 0.925 respectively. Using getAnnotationTemplate (see Fig. 3a, line 8) we label each user as human, and update the classifier with trainClassifier, see Fig. 3a,
line 10). The updated bot scores, 0.375, 0.296, and 0.559, respectively indicate an improvement. In theory, practitioners can retrain
birdspotter to classify any latent user attribute (of a type supported by XGboost).

5

CONCLUSION

In this work, we present a Twitter user analysis tool, aimed at nondata science experts who analyze discourse and user activity on
social media. It provides an end-to-end analysis of users’ online
characteristics, and populates a visualizer facilitating both broad
views of a user population and individual exploration. As with many
open-source classifiers, we are aware that birdspotter could be
leveraged to infer sensitive features, however we are currently not
aware of any protections that we could implement to prevent this.
Tools like birdspotter are integral to the timely, performant,
and reproducible analysis of social media users, for understanding
discourse and society.

REFERENCES
[1] Emily Chen, Kristina Lerman, and Emilio Ferrara. 2020. Tracking Social Media
Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus
Twitter Data Set. JMIR (2020).
[2] Tianqi Chen and Carlos Guestrin. 2016. Xgboost: A scalable tree boosting system.
In KDD’16.
[3] Jean-Valère Cossu, Vincent Labatut, and Nicolas Dugué. 2016. A review of features
for the discrimination of twitter users: Application to the prediction of offline
influence. SNAM (2016).
[4] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and
Filippo Menczer. 2016. Botornot: A system to evaluate social bots. In WWW.
[5] Manuel Gomez-Rodriguez, Le Song, Nan Du, Hongyuan Zha, and Bernhard
Schölkopf. 2016. Influence Estimation and Maximization in Continuous-Time
Diffusion Networks. ACM Transactions on Information Systems (2016).
[6] Sneha Kudugunta and Emilio Ferrara. 2018. Deep neural networks for bot
detection. Information Sciences (2018).
[7] Scott M Lundberg and Su-In Lee. 2017. A Unified Approach to Interpreting Model
Predictions. In NeurIPS’17.
[8] Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and Armand Joulin. 2018. Advances in Pre-Training Distributed Word Representations.
In LREC 2018.
[9] Fabián Riquelme and Pablo González-Cantergiani. 2016. Measuring user influence
on Twitter: A survey. Information processing & management (2016).
[10] Marian-Andrei Rizoiu, Timothy Graham, Rui Zhang, Yifei Zhang, Robert Ackland,
and Lexing Xie. 2018. # DebateNight: The Role and Influence of Socialbots on
Twitter During the 1st 2016 US Presidential Debate. In ICWSM.
[11] Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie. 2017. A
Tutorial on Hawkes Processes for Events in Social Media. In Research Frontiers of
Multimedia.
[12] Mohsen Sayyadiharikandeh, Onur Varol, Kai-Cheng Yang, Alessandro Flammini,
and Filippo Menczer. 2020. Detection of Novel Social Bots by Ensembles of
Specialized Classifiers. CIKM (2020).
[13] Kai-Cheng Yang, Onur Varol, Clayton A Davis, Emilio Ferrara, Alessandro Flammini, and Filippo Menczer. 2019. Arming the public with artificial intelligence to
counter social bots. Human Behavior and Emerging Technologies (2019).
[14] Kai-Cheng Yang, Onur Varol, Pik-Mai Hui, and Filippo Menczer. 2020. Scalable
and generalizable social bot detection through data selection. In AAAI.
[15] Zizhu Zhang, Weiliang Zhao, Jian Yang, Cecile Paris, and Surya Nepal. 2019.
Learning Influence Probabilities and Modelling Influence Diffusion in Twitter. In
WWW.

Birdspotter: A Tool for Analyzing and Labeling Twitter Users

Accompanying the submission Birdspotter: A Tool for Analyzing
and Labeling Twitter Users.

A

ADDITIONAL RELATED WORK

In this section, we outline other approaches to bot detection and
influence measurement in the literature.
Detecting Twitter bots. There have been a myriad of approaches
to detect bots on Twitter. There are three motifs within the literature. The first motif are supervised methods used to determine if
an individual user is a bot, usually employing feature construction.
Such approaches include NLP approaches [4, 13], deep-learning
approaches [14], feature-engineering [3, 6, 22] and other methods
[9, 15]. The second motif are unsupervised methods used to discover coordinated online behavior/real-time online campaigns; and
the third motif are adversarial methods which achieve better bot
detection by generating better bots.
birdspotter falls in the first category. It uses a supervised approach to retrospectively analyze datasets. It satisfies a different
use case than coordinated online behavior tools like BotSlayer [12].
Adversarial approaches are fairly novel, however it is unclear whether
they might simply improve bot technology, as they provide recipes
to build better bots.
The de-facto bot detection tool in the social science community
is Botometer (formerly BotOrNot) [6], which uses more than 1000
user- and recent activity-related features to train a Random Forest
classifier. Botometer is currently at version 4, at the time of writing,
and serves half a million queries a day [20].
The main limitation of botometer for practitioners is its dependence on an online API. It cannot be used to profile the users in
offline Twitter datasets which have been collected in the past (like
used in many works [1, 8, 21]). Furthermore, the API is rate-limited
by Twitter, and requires registration through both Twitter and
RapidAPI service. For scientific purposes, botometer makes local
reproducibility difficult to achieve, since deactivated, protected, and
suspended users can no longer be retrieved, and botometer scores
are likely to vary with user activity and botometer versioning.
Birdspotter addresses the above-stated shortcomings by producing bot predictions on already collected Twitter dumps, and
exposing a simple interface to allows researchers to annotate their
own Twitter user collection.
Tools for quantifying online influence. There are many features used to score the influence, reputation or popularity of online
users. We delineate these into three areas: those using static user
attributes (including lexical features and information on a user’s
profile) [5], those that analyze the online social graph (e.g. degree,
PageRank, HITs, etc.) [2, 17], and those modeling information diffusion [24]. However, few of these have translated into accessible
tools for the non-experts in the field. For instance, Cossu et al. [5]
provide a set of scripts to perform their influence measurement
method. Other tools, like ConTinEst [7, 10], require knowledge of
the social graph (which is often prohibitively expensive to obtain)
on which it performs random walks (which are very slow on large
social graphs). Birdspotter estimates user influence from reshare
dynamics, in the absence of knowledge about the social graph, and
provides an end-to-end tool to analyze Twitter users.

Conference’17, July 2017, Washington, DC, USA

B

INFLUENCE MEASURE

We review the theoretical prerequisites concerning modeling reshare cascades using point processes, and estimating reshare influence.
Reshare cascades. birdspotter analyzes the spread of online
information in the form of online reshare cascades. A reshare cascade consists of an initial user post and some reshare events of
the post by other users. On Twitter, for example, this can happen
when users use the retweet functionality. We denote a cascade
observed up to time 𝑇 as H (𝑇 ) = {𝑡 0, 𝑡 1, . . . } where 𝑡𝑖 ∈ H (𝑇 )
are the event times relative to the first event (𝑡 0 = 0). We denote cascades with additional information about events — dubbed
here as event marks — as marked cascades. We use the notation
H 𝑚 (𝑇 ) = {(𝑡 0, 𝑚 0 ), (𝑡 1, 𝑚 1 ), . . . }, where each event is a tuple of
the event time and the event mark. For example, for retweet cascades, the numbers of followers of a Twitter user are commonly
adopted as event marks [16, 25].
The Hawkes processes. birdspotter models reshare cascades
using Hawkes processes [11] — a type of point processes with
the self-exciting property, i.e., the occurrence of past events increases the likelihood of future events. The occurrence of events in
a Hawkes process is controlled by the event intensity function:
∑︁
𝜆(𝑡 | H (𝑇 )) = 𝜇 (𝑡) +
𝜙 (𝑡 − 𝑡𝑖 )
(1)
𝑡𝑖 <𝑡

where 𝜇 (𝑡) is the background intensity function and 𝜙 : R+ → R+ is
a kernel function capturing the decaying influence from a historical
event. We note that, for reshare cascades, all events are considered
to be offspring of the initial event, i.e. there is no background event
rate 𝜇 (𝑡) = 0. Two widely adopted parametric forms for the kernel
function 𝜙 include the exponential function 𝜙 𝐸𝑋 𝑃 (𝑡) = 𝜅𝜃𝑒 −𝜃𝑡 and
the power-law function 𝜙 𝑃𝐿 (𝑡) = 𝜅 (𝑡 + 𝑐) −(1+𝜃 ) .
Marked Models. birdspotter implements marked versions of
the point processes, where the mark is the number of followers
that the user emitting the tweet has. This is because the mark of
each event governs the number of future events, e.g., a tweet from a
largely followed user is likely to attract more retweets. The marked
versions of Hawkes processes [16] are then derived by rescaling the
kernel functions with the marks, i.e., 𝜙 (𝑚, 𝑡) = 𝑚 𝛽 𝜙 (𝑡); 𝛽 controls
the warping effect of the mark.
User influence estimation. birdspotter adopts the following
definition for user influence, widely used in literature [7, 18, 23]:
Definition B.1. Online user influence 𝜑 (𝑢) is defined as the mean
number of reshares generated directly and indirectly by a message
posted by 𝑢, irrespective if it is an original message or a reshare.
Estimating influence from retweet cascades has the additional difficulty of not observing the branching structure of the diffusion
— i.e., the Twitter API attributes all retweets to the original tweet.
birdspotter estimates Twitter user influence using only the observed retweet cascade H 𝑚 (𝑇 ) = {𝑣 0 = (𝑡 0, 𝑚 0 ), 𝑣 1 = (𝑡 1, 𝑚 1 ), . . . },
where marks correspond to users’ number of followers.
Rizoiu et al. [18] propose a method to estimate user influence in
the absence of the branching structure by assuming that retweets
arrive following a Hawkes point process [19]. We can quantify the
probability that an event 𝑣 𝑗 is generated by a previous event 𝑣𝑖
as the ratio of the event intensity generated by 𝑣𝑖 and the total

Conference’17, July 2017, Washington, DC, USA

Rohit Ram, Quyu Kong, and Marian-Andrei Rizoiu

intensity at time 𝑡 𝑗 . Formally, the probability 𝑣 𝑗 retweets 𝑣𝑖 is
𝜙 (𝑡 𝑗 − 𝑡𝑖 )
𝑝𝑖 𝑗 = Í 𝑗−1
𝜙 (𝑡 𝑗 − 𝑡𝑘 )
𝑘=1

(2)

Rizoiu et al. [18] also introduce the pairwise influence score 𝑚𝑖 𝑗 ,
intuitively defined as the amount of influence that 𝑣𝑖 exerts over
𝑣 𝑗 either directly (when 𝑣 𝑗 is a direct retweet of 𝑣𝑖 ) or indirectly
(when 𝑣 𝑗 is a retweet of a descendant of 𝑣𝑖 ):
Í 𝑗−1


𝑚 𝑝
,𝑖 ≤ 𝑘 < 𝑗

 𝑘=𝑖 𝑖𝑘 𝑘 𝑗

𝑚𝑖 𝑗 = 1
,
(3)
,𝑖 = 𝑗


0
,𝑖 > 𝑗

Í
Finally, the influence of 𝑣𝑖 is 𝜑 (𝑣𝑖 ) = 𝑛𝑘=𝑖 𝑚𝑖𝑘 , and the influence
of a user 𝑢 is the average of the influences of all of their tweets:
Í
𝑣 ∈ T (𝑢) 𝜑 (𝑣)
𝜑 (𝑢) =
(4)
|T (𝑢)|
where T (𝑢) is the set of all the tweets emitted by user 𝑢.

REFERENCES
[1] Alessandro Bessi and Emilio Ferrara. 2016. Social bots distort the 2016 US
Presidential election online discussion. First Monday (2016).
[2] Meeyoung Cha, Hamed Haddadi, Fabricio Benevenuto, and Krishna P Gummadi.
2010. Measuring user influence in twitter: The million follower fallacy. In ICWSM.
[3] Zi Chu, Steven Gianvecchio, Aaron Koehl, Haining Wang, and Sushil Jajodia.
2013. Blog or block: Detecting blog bots through behavioral biometrics. Computer
Networks (2013).
[4] Eric M Clark, Jake Ryland Williams, Chris A Jones, Richard A Galbraith, Christopher M Danforth, and Peter Sheridan Dodds. 2016. Sifting robotic from organic
text: a natural language approach for detecting automation on Twitter. Journal
of Computational Science (2016).
[5] Jean-Valère Cossu, Vincent Labatut, and Nicolas Dugué. 2016. A review of features
for the discrimination of twitter users: Application to the prediction of offline
influence. SNAM (2016).
[6] Clayton Allen Davis, Onur Varol, Emilio Ferrara, Alessandro Flammini, and
Filippo Menczer. 2016. Botornot: A system to evaluate social bots. In WWW.
[7] Nan Du, Le Song, Manuel Gomez-Rodriguez, and Hongyuan Zha. 2013. Scalable
Influence Estimation in Continuous-Time Diffusion Networks. In NeurIPS.
[8] Emilio Ferrara. 2020. # covid-19 on twitter: Bots, conspiracies, and social media
activism. arXiv (2020).
[9] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro
Flammini. 2016. The rise of social bots. Comm. ACM (2016).
[10] Manuel Gomez-Rodriguez, Le Song, Nan Du, Hongyuan Zha, and Bernhard
Schölkopf. 2016. Influence Estimation and Maximization in Continuous-Time
Diffusion Networks. ACM Transactions on Information Systems (2016).
[11] Alan G Hawkes. 1971. Spectra of some self-exciting and mutually exciting point
processes. Biometrika (1971).
[12] Pik-Mai Hui, Kai-Cheng Yang, Christopher Torres-Lugo, Zachary Monroe, Marc
McCarty, Benjamin Serrette, Valentin Pentchev, and Filippo Menczer. 2019. BotSlayer: real-time detection of bot amplification on Twitter. Journal of Open Source
Software (2019).
[13] Jürgen Knauth. 2019. Language-Agnostic Twitter-Bot Detection. In RANLP 2019.
[14] Sneha Kudugunta and Emilio Ferrara. 2018. Deep neural networks for bot
detection. Information Sciences (2018).
[15] Michele Mazza, Stefano Cresci, Marco Avvenuti, Walter Quattrociocchi, and
Maurizio Tesconi. 2019. RTbust: exploiting temporal patterns for botnet detection
on twitter. In Proceedings of the 10th ACM Conference on Web Science.
[16] Swapnil Mishra, Marian-Andrei Rizoiu, and Lexing Xie. 2016. Feature Driven
and Point Process Approaches for Popularity Prediction. In CIKM.
[17] Fabián Riquelme and Pablo González-Cantergiani. 2016. Measuring user influence
on Twitter: A survey. Information processing & management (2016).
[18] Marian-Andrei Rizoiu, Timothy Graham, Rui Zhang, Yifei Zhang, Robert Ackland,
and Lexing Xie. 2018. # DebateNight: The Role and Influence of Socialbots on
Twitter During the 1st 2016 US Presidential Debate. In ICWSM.
[19] Marian-Andrei Rizoiu, Young Lee, Swapnil Mishra, and Lexing Xie. 2017. A
Tutorial on Hawkes Processes for Events in Social Media. In Research Frontiers of
Multimedia.
[20] Mohsen Sayyadiharikandeh, Onur Varol, Kai-Cheng Yang, Alessandro Flammini,
and Filippo Menczer. 2020. Detection of Novel Social Bots by Ensembles of
Specialized Classifiers. CIKM (2020).

[21] Stefan Wojcik, Solomon Messing, Aaron Smith, Lee Rainie, and Paul Hitlin. 2018.
Bots in the Twittersphere. Pew Research Center. Retrieved May (2018).
[22] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai.
2014. Uncovering social network sybils in the wild. TKDD (2014).
[23] Ali Zarezade, Utkarsh Upadhyay, Hamid Rabiee, and Manuel Gomez Rodriguez.
2017. RedQueen: An Online Algorithm for Smart Broadcasting in Social Networks.
In WSDM.
[24] Zizhu Zhang, Weiliang Zhao, Jian Yang, Cecile Paris, and Surya Nepal. 2019.
Learning Influence Probabilities and Modelling Influence Diffusion in Twitter. In
WWW.
[25] Qingyuan Zhao, Murat A. Erdogdu, Hera Y. He, Anand Rajaraman, and Jure
Leskovec. 2015. SEISMIC: A Self-Exciting Point Process Model for Predicting
Tweet Popularity. In KDD.

