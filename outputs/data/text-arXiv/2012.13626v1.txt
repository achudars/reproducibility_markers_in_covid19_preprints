Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 1 (33)

Original research article: Detecting the patient’s need for help with machine learning.
Corresponding author: Lauri Lahti (email: lauri.lahti@aalto.fi).
This research article manuscript version was completed on 24 December 2020 and it was selfarchived on the open-access Arxiv repository (https://arxiv.org) on 24 December 2020.
This article contains 21 pages, 6 tables and 5 figures. Supplemented with Appendix A (12 pages).

Detecting the patient’s need for help with machine learning
Lauri Lahti
Department of Computer Science, Aalto University, Finland
Abstract:
Background: Developing machine learning models to support health analytics requires increased
understanding about statistical properties of self-rated expression statements used in health-related
communication and decision making. To address this, our current research analyzes self-rated
expression statements concerning the coronavirus COVID-19 epidemic to identify statistically
significant differences between groups of respondents and to detect the patient’s need for help with
machine learning.
Methods: A quantitative study gathering the “need for help” ratings for twenty health-related
expression statements concerning the coronavirus epidemic on a 11-point Likert scale, and nine
answers about the person’s health and wellbeing, sex and age. The study involved online respondents
between 30 May and 3 August 2020 recruited from Finnish patient and disabled people’s
organizations, other health-related organizations and professionals, and educational institutions
(n=673). We analyzed rating differences and dependencies with Kendall rank-correlation and cosine
similarity measures and tests of Wilcoxon rank-sum, Kruskal-Wallis and one-way analysis of
variance (ANOVA) between groups, and carried out machine learning experiments with a basic
implementation of a convolutional neural network algorithm.
Results: We found statistically significant correlations and high cosine similarity values between
various health-related expression statement pairs concerning the “need for help” ratings and a
background question pair. We also identified statistically significant rating differences for several
health-related expression statements in respect to groupings based on the answer values of
background questions, such as the ratings of suspecting to have the coronavirus infection and having
it depending on the estimated health condition, quality of life and sex. Our machine learning
experiments with a convolutional neural network algorithm showed the applicability of machine
learning to support detecting the need for help in the patient’s expressions.
Conclusions: The self-rated “need for help” concerning health-related expression statements differs
statistically significantly depending on the person’s background information, such as his/her
estimated health condition, quality of life and sex. Based on the ratings machine learning can support
detecting the need for help in the patient’s expressions thus enabling to develop computational
methods to identify, interpret and address the patient’s needs to enable well personalized care.
Keywords: health questionnaire; convolutional neural network; personalized care; self-rating;
patient; disabled; the need for help; expression; interpretation; decision making; coronavirus;
COVID-19
Ethics approval and consent to participate and for publication: Aalto University Research Ethics
Committee has carried out an ethical evaluation concerning the personal data acquisition of the

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 2 (33)

current research project “Development of method for interpretation of health expressions based on
machine learning to support various care events and persons” (DIHEML, see Lahti, 2017; Lahti,
2018) and has given a supporting ethical statement for it on 18 June 2019. DIHEML research project
addresses the General Data Protection Regulation of the European Union in handling the research
data. An informed consent was obtained from all individual persons participating in the data
acquisition and regarding publishing their anonymized data sets.
Availability of data and materials: The data set supporting the conclusions of this article is included
within the article and its supplementing Appendix A. While taking appropriate and sufficient
anonymization actions in respect to addressing the General Data Protection Regulation of the
European Union in handling the research data, DIHEML research project publishes an anonymized
version of the current research data (an open access data set “Need for help related to the coronavirus
COVID-19 epidemic”) in the supplementing Appendix A, to be used by anyone for non-commercial
purposes (while citing this publication).
Competing interests: The author declares that he has no competing interests.
Funding: The author did not receive any specific funding for this research work.
Author contributions: The contributions of the author Lauri Lahti include: conceived and developed
the research plan; created the research design; designed the experiment; recruited the population
sample and collected data; developed and implemented the online questionnaire system and its
models, algorithms, data and materials; performed traditional statistical analyses; performed machine
learning analyses; wrote the first and subsequent drafts and the final version of the manuscript;
prepared tables, figures and the appendix; reviewed and commented the manuscript; performed
editing of the manuscript.
Acknowledgement: The author wants to express gratitude to all the people who have kindly
participated in answering the online questionnaire of the research. Special thanks to the people
associated with various Finnish patient and disabled people’s organizations, other health and wellness
organizations, and educational institutions as well as organizations of healthcare professionals,
including also the representatives of Finnish Association for Emergency Medicine.
1. Background
A self-rated health condition answered to a single question has shown a strong validity and reliability
for measuring and predicting multiple dimensions of the person’s health (Gallagher et al., 2016; Wu
et al., 2013). However, the self-rated health is affected by the phrasing, scales and ordering used in
questions and answer options (Cullati et al., 2020; Garbarski et al., 2016; Joffer et al 2016; Borraccino
et al., 2019). On the other hand, comprehensive modular questionnaire systems have been proposed
and implemented, for example relying on International Classification of Functioning, Health and
Disability, and Patient-Reported Outcomes Measurement Information System (PROMIS) (Tucker et
al., 2014; Anttila et al., 2017). Despite the possibility to offer increasingly specifically tailored
question sets and to create links between them (Jacobson et al., 2020; Schalet et al., 2015), a general
challenge is to interpret the gained specific answers in greater agglomerated entities to make analytic
conclusions and predictions in a broader context of the person’s health and wellbeing, such as in a
long-term care planning and clinical decision making (Deo, 2015).
Furthermore, besides using predefined questionnaire structures there is a great interest for
developing adaptive methods that can identify the patient’s needs from any kind of free text passages,
such as from healthcare chatbots, patient diaries, online guidance and screening for care, or their
derivatives, for example emergency phone calls that are immediately annotated with a speech

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 3 (33)

recognition (resembling the proposals of Zhao et al., 2017; Gehrmann et al., 2018; Rojas-Barahona
et al., 2018; Shickel et al., 2019). However, according to two reviews there is still a lack of systematic
development for reliable evaluation metrics for healthcare chatbots (Abd-Alrazaq et al., 2020) and
their algorithms have challenges in semantic understanding (Laranjo et al., 2018).
Think-aloud studies about self-rated health have identified sex- and age-dependent variations
in the diversity and complexity of conceptualizations in interpretations and reasoning (Joffer et al
2016) and core categories that people use to describe and perceive health (Borraccino et al., 2019).
Age-related differences in self-reported opinions, attitudes or behaviors about health can also be
influenced by age-induced changes in cognitive and communicative functioning (Knäuper et al.,
2016). There is a need to advance understandable and accurate communication between the patient
and healthcare personnel and the patient’s appropriate and sufficient involvement in decision making
that addresses his/her needs (Sinclair, Jaggi, Hack, Russell et al., 2020; Sinclair, Jaggi, Hack,
McClement et al., 2020).
These current challenges motivate us now to address two main research questions (RQ):
RQ1) How different people rate the “need for help” for a set of health-related expression
statements and how this rating depends on the background information about the person (such as
his/her demographic information and evaluation about own health and wellbeing)?
RQ2) What kind of results can be gained when training a convolutional neural network based
on the “need for help” ratings to classify persons into groups based on their background information?
Relying on the methods and results developed in our previous research (Lahti 2017; Lahti
2018), we now analyze experimental measurements (n=674) including the “need for help” ratings for
twenty health-related expression statements concerning COVID-19 epidemic, and nine answers about
the person’s health and wellbeing, sex and age. Our measuring methodology is adapted from the
dimensional affective models which suggest that dimensions of pleasure, arousal, dominance and
approach-avoidance have a fundamental role in human experience and response systems (Bradley &
Lang, 1999a; Warriner et al., 2013; Mauss & Robinson, 2009). Our approach is also motivated by the
previous research that has experimentally gathered a list of self-identified most significant mental
imagery describing the patient's pain combined with associated triggers, affects, meanings and
avoidance patterns (Berna et al., 2011).
Resembling the previous research in the context of artificial intelligence (Zhao et al., 2017;
Gehrmann et al., 2018; Rojas-Barahona et al., 2018; Shickel et al., 2019), we wanted to evaluate the
applicability of machine learning to support interpretation of the need for help in the patient’s
expressions. Machine learning is a methodology that aims at learning to recognize statistical patterns
in data, typically relying on either an unsupervised or supervised approach. Unsupervised learning
aims at identifying naturally occurring patterns or groupings which are present in the input data and
it is often challenging for humans to judge the actual appropriateness and meaningfulness of the
generated groupings (Deo 2015). On the other hand, supervised learning is often carried out with an
aim to predict an outcome that is based on approximating an appropriate human-made classification.
Supervised learning usually tries to perform classification by choosing among subgroups such a
subgroup that can best describe a new instance of data and also to produce a prediction that consists
of estimating an unknown parameter (Deo 2015). Supervised learning is also actively used to estimate
risk and this can be considered to extend further than just approximating the human performance and
to aim at identifying hidden characteristics of data (Deo 2015).
Since we aimed at identifying how the “need for help” ratings of expression statements can
be used to classify persons into groups based on their background information, it was natural for us
to focus now on experimenting with the supervised learning approach. To implement supervised
learning, various alternative types of functions can be chosen to relate predicted values to the features
that are present in the data, and these functions typically offer more flexibility for modeling than for
example logistic regression models of traditional statistics (Deo 2015). These functions can be based
on various alternative machine learning models, and among them artificial neural networks have
achieved a high accuracy in classification tasks (Gehrmann et al., 2018). We decided to use a
convolutional neural network model in our machine learning experiments since it has been

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 4 (33)

successfully applied in classification of medical literature, patient records, clinical narratives and
patient phenotypes (Hughes et al., 2017; Zhao et al., 2017; Gehrmann et al., 2018; Rojas-Barahona
et al., 2018; Yao et al., 2019; Qing et al., 2019; Shickel et al., 2019), and it achieves good results with
both image and textual input data (Bhandare et al., 2016).
In respect to the coronavirus COVID-19 epidemic, artificial neural networks have been
applied to classify coronavirus-related online discussions and then to supply them with an emotional
labeling based on a pre-existing emotion vocabulary and rules (Jelodar et al., 2020).

2. Materials and Methods
In the time period ranging from 30 May to 3 August 2020 we gathered with an online questionnaire
from 673 unique persons twenty rating answers that measured the degree of the “need for help” that
the person associated with the imagined care situations related to the coronavirus COVID-19
epidemic. In addition, we gathered nine answers about the person’s background information. All these
answers were gathered as a part of a greater data acquisition entity (Lahti, 2020) with some
supplementing questionnaire items that will be reported in a more detail in another future publication.
The respondents were recruited from various Finnish patient and disabled people’s organizations,
other health and wellness organizations, and educational institutions as well as organizations of
healthcare professionals. When accessing the online questionnaire, the person was informed that only
persons who are at least 16 years old are allowed to participate. Furthermore, to address the General
Data Protection Regulation of the European Union a privacy notice about the research was shown to
the person and he/she was asked to give an approval for handling his/her data.
Before the online questionnaire started to collect actual answers, the person was provided with
the following guidance texts about how he/she should perform the interpretation tasks: "We ask you
to evaluate different expressions, for example ‘I am happy’. Interpret how much each expression tells
about the need for help. Give your interpretation about the expression on a numeric scale 0-10. 0
indicates the smallest possible need for help and 10 indicates the greatest possible need for help."
Then a small training phase allowed the person to get accustomed to give the "need for help" ratings
by rating three expression statements: “I have a good health condition.”, “I have a bad health
condition.” and “I have an ordinary health condition.” The answers that the person gave during the
training phase were excluded from the data set that we use in the following analysis.
After the training phase, the person was provided with the following guidance texts to still
further clarify how he/she should perform the interpretation tasks: “Do not interpret how much the
expression tells about just your own situation. Instead, interpret what kind of impression this
expression induces in you. Thus give your interpretation about the expression's meaning in respect
to the mentioned property.” After showing those guidance texts, the person was allowed to start
giving actual answers, i.e. to perform the actual interpretation tasks.
In the actual interpretation tasks, our online questionnaire asked the person to give a rating of
the “need for help” for twenty expression statements (ES) that we had extracted with the method we
developed and reported in our previous research (Lahti et al., 2018) from official national guidelines
of National Institute for Health and Welfare in Finland (THL) (2020) and international guidelines of
World Health Organization (WHO) (2020) concerning the coronavirus COVID-19 epidemic. These
twenty expression statements ES1-ES20 included among others descriptions of possible symptoms
of the coronavirus, how to deal mild cases of the coronavirus with just self-care, when one should
seek admission for professional care and what kind of practicalities are suggested as a prevention (see
Table 1). The expression statements were shown, one at a time, in a speech bubble above a simple
briefly animating face figure that remained the same for all the expression statements (see Figure 1
and further details in Appendix A).
Furthermore, the person was asked to answer to nine background questions (BQ, see Table
2). These gathered four answers concerning his/her evaluation about own health, quality of life, and
satisfaction about health and ability, responded on a 9-point Likert scale (BQ1 and BQ5-BQ7, adapted

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 5 (33)

from de Bruin et al., 1996; Nosikov & Gudex, 2003; Koskinen et al., 2012; Aalto et al., 2013). In
addition, binary no/yes answers were gathered to questions asking if a health problem reduces the
person's ability (BQ2) and if he/she has a continuous or repeated need for a doctor's care (BQ4)
(adapted from Koskinen et al., 2012). The person was also asked to tell his/her sex (BQ8) and age
(BQ9) and to indicate if a doctor had identified one or more diseases in him/her and to describe them
(BQ3) (in a form adapted from Koskinen et al., 2012).

Figure 1. Gathering the “need for help” rating for an expression statement on a 11-point Likert scale
with an online questionnaire.
We have gathered questionnaire answers in Finnish language but we now report our results in
English (see original Finnish texts in Appendix A). Due to inherent linguistic and cultural differences
we assume that the semantic meanings in the translated English versions of expression statements
cannot fully match with the original Finnish meanings. On the other hand, we have aimed to follow
carefully also those adapted Finnish translations that have been used already earlier in Finnish
national health surveys (Koskinen et al., 2012; Aalto et al., 2013).
Table 1. Expression statements (ES) concerning the coronavirus COVID-19 epidemic that were rated
by the person in respect to the impression about the “need for help”.
Compact notation

Expression statement

ES1
ES2
ES3
ES4
ES5
ES6
ES7
ES8
ES9
ES10
ES11

“I have a flu.”
“I have a cough.”
“I have a shortness of breath.”
“My health condition is weakening.”
“I have a sore throat.”
“I have muscular ache.”
“I have a fever.”
“A sudden fever rises for me with 38 degrees of Celsius or more.”
“I suspect that I have now become infected by the coronavirus.”
“I have now become infected by the coronavirus.”
“I am quarantined from meeting other people ordinarily so that
the spreading of an infectious disease could be prevented.”
“I must be inside a house without getting out.”
“I must be without a human companion.”
“I do not cope in everyday life independently without getting help
from other persons.”
“I do not cope at home independently without getting help from
persons who originate outside of my home.”
“I have an infectious disease.”
“I have an infectious disease that has been verified by a doctor.”
“I suspect that I have an infectious disease.”
“I have a bad health condition.”
“I have an ordinary health condition.”

ES12
ES13
ES14
ES15
ES16
ES17
ES18
ES19
ES20

Range of values for the person’s answer
(indicating the “need for help” rating)
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 6 (33)

Table 2. Background questions (BQ) presented to the person.
Compact
notation
BQ1: an
estimated
health
condition
BQ2: a health
problem
reduces ability

BQ3: one or
more diseases
identified by a
doctor
BQ4: a
continuous or
repeated need
for a doctor's
care
BQ5: the
quality of life

BQ6: the
satisfaction
about health
BQ7: the
satisfaction
about ability

BQ8: the sex

BQ9: the age

Question about the person’s background
information
“What kind of health condition you have
currently according to your opinion?” (de
Bruin et al., 1996; Koskinen et al., 2012)

Range of values for the person’s answer

"Do have a permanent or long-lasting
disease or such deficit, ailment or disability
that reduces your ability to work or to
perform your daily living activities?"
(Koskinen et al., 2012)
"Has there been a situation that a doctor has
identified in you one or several of the
following diseases?" (Koskinen et al., 2012)

No or yes

"Do you need continuously or repeatedly
care given by a doctor for a long-lasting
disease, deficit or disability that you have
just mentioned?" (Koskinen et al., 2012)
“How would you rate your quality of life?
Give your estimate based on the latest two
weeks.” (Nosikov & Gudex, 2003; Aalto et
al., 2013)
“How satisfied are you with your health?
Give your estimate based on the latest two
weeks.” (Nosikov & Gudex, 2003; Aalto et
al., 2013)
“How satisfied are you with your ability to
perform your daily living activities currently
according to your opinion? Give your
estimate based on the latest two weeks.”
(Nosikov & Gudex, 2003; Aalto et al., 2013)
“Tell what is your sex. The answer
alternatives are similar as in the earlier
health surveys of National Institute for Health
and Welfare in Finland (THL) to maintain
comparability with the earlier results.”
(Koskinen et al., 2012)
“Tell what is your age.” (Koskinen et al.,
2012)

A 9-point Likert scale supplied with the following partial labeling: “9
Good”, “8 –“, “7 Rather good”, “6 –“, “5 Medium”, “4 –“, “3 Rather
bad”, “2 –“, “1 Bad”.

The person answers by selecting one or more options from a list of
diseases (Koskinen et al., 2012), see details in Appendix A. For
some options there is a question “other, what?” and an adjacent
text input box so that the person can write some additional
information concerning that option.
No or yes

A 9-point Likert scale supplied with the following partial labeling: “9
Very good”, “8 –“, “7 Good”, “6 –“, “5 Neither good nor bad”, “4 –“,
“3 Bad”, “2 –“, “1 Very bad”.
A 9-point Likert scale supplied with the following partial labeling: “9
Very satisfied”, “8 –“, “7 Satisfied”, “6 –“, “5 Neither satisfied nor
unsatisfied”, “4 –“, “3 Unsatisfied”, “2 –“, “1 Very unsatisfied”.
A 9-point Likert scale supplied with the following partial labeling: “9
Very satisfied”, “8 –“, “7 Satisfied”, “6 –“, “5 Neither satisfied nor
unsatisfied”, “4 –“, “3 Unsatisfied”, “2 –“, “1 Very unsatisfied”.

Man or woman

16 years, 17 years, ..., 99 years, 100 years or more

To address our main research question RQ1, we use traditional statistical tests to evaluate
overall answer distributions. We compute Kendall rank-correlation and cosine similarity measures
for each comparable pair of parameter values of the “need for help” ratings of expression statements
and the answers of the background questions. Then we compute Wilcoxon rank-sum test (i.e., Mann–
Whitney U test) between two groups and Kruskal-Wallis test between three groups to identify
statistically significant rating differences for each expression statement in respect to groupings based
on the answer values of each background question. We supplement this with tests of one-way analysis
of variance (ANOVA).
To address our main research question RQ2, we carry out machine learning experiments with
a basic implementation of a convolutional neural network algorithm that we run in a TensorFlow
programming environment (TensorFlow image classification tutorial, 2020). This enables to evaluate
the general applicability of machine learning approach in this knowledge context. We train the model
with the same groups that we use to identify statistically significant rating differences, and this offers
insight about how the dependencies between ratings and background information can influence the
results of machine learning. Based on the gained findings we then make some conclusions motivated
by the previous research and discuss about implications for developing the methodology for
interpretation of the patient’s expressions to support his/her personalized care.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 7 (33)

3. Results
We gained a diverse distribution of answer values for the background questions (n=673). Table 3
shows the frequencies of persons giving the answer values 1-9 for the background questions BQ1 and
BQ5-BQ7, and Table 4 describes the distribution of answer values for the background questions BQ2BQ4 and BQ8-BQ9.
Table 3. Frequencies of persons giving the answer values 1-9 for the background questions BQ1
and BQ5-BQ7 (n=673). M=mean, Mdn=median, SD=standard deviation.
Background
question (BQ)

Answer value
1

2

3

4

5

6

7

8

9

M

BQ1: an
estimated health
condition
BQ5: the quality
of life
BQ6: the
satisfaction
about health
BQ7: the
satisfaction
about ability

11
(2%)

3
(~0%)

40
(6%)

66
(10%)

98
(15%)

45
(7%)

162
(24%)

129
(19%)

119
(18%)

6.53

7

1.97

7 (1%)

6 (1%)

101
(15%)
84
(12%)

84
(12%)
78
(12%)

187
(28%)
151
(22%)

123
(18%)
138
(21%)

89
(13%)
66
(10%)

7

1.77

10
(1%)

47
(7%)
61
(9%)

6.53

17
(3%)

6.13

7

2.04

8 (1%)

9 (1%)

29
(4%)
68
(10
%)
44
(7%)

28
(4%)

54 (8%)

58
(9%)

156
(23%)

128
(19%)

188
(28%)

6.98

7

1.98

Mdn

SD

Table 4. The distribution of answer values for the background questions BQ2-BQ4 and BQ8-BQ9.
M=mean, Mdn=median, SD=standard deviation.
Background question (BQ)
BQ2: a health problem reduces
ability
BQ3: one or more diseases
identified by a doctor
BQ4: a continuous or repeated
need for a doctor's care
BQ8: the sex
BQ9: the age

Answer value
No (coded as 1): 219 (33%); Yes (coded as 2): 454 (67%) (M=1.67; Mdn=2; SD=0.47)
Disease category (the number of unique persons who selected the category): Lung diseases:
126; Heart and circulatory diseases: 177; Joint and back diseases: 301; Injuries:103; Mental
health problems: 188; Vision and hearing deficits: 191; Other diseases: 345
No (coded as 1): 364 (54%); Yes (coded as 2): 309 (46%) (M=1.46; Mdn=1; SD=0.50)
Man (coded as 1): 123 (18%); Woman (coded as 2): 550 (82%) (M=1.82; Mdn=2; SD=0.39)
Belonging to an age range category (the lower bound is included in the range but not the upper
bound): 16-20 years: 143 (21%); 20-30 years: 21 (3%); 30-40 years: 61 (9%); 40-50 years: 96
(14%); 50-60 years: 135 (20%); 60-70 years: 141 (21%); 70-80 years: 64 (10%); 80-90 years: 12
(2%); 90 years or more: 0 (0%) (M=46.93; Mdn=51; SD=19.57)

To address our main research question RQ1, we evaluated how the “need for help” ratings
depended on the background information about the person. For the further analysis, the original “need
for help” rating values in the range 0-10 were transformed linearly to a new range 0.0-1.0. Figures 2
and 3 show for five expression statements ES4, ES9-ES10 and ES19-ES20 how the “need for help”
ratings depend on the person’s answer value to the background question BQ1 that is the person’s
estimation about his/her health condition. Figure 2a shows rating mean values for the nine separate
groups of respondents corresponding to each possible answer alternative about the health condition
(in the range 1-9). Figures 2b and 2c show the increase of the “need for help” rating mean values
from the baseline rating mean value of ES20. On the other hand, Figure 3 illustrates in a more detail
the distribution of the relative frequency of respondents for each alternative rating value in the range
0.0-1.0, in respect to the background questions BQ1 and BQ9.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 8 (33)

Figure 2. a) The “need for help” rating mean values (transformed into the range 0.0-1.0) for
expression statements ES4, ES9-ES10 and ES19-ES20 in respect to the person’s answer value to the
background question BQ1 (an estimated health condition, 1-9), n=673. b)-c) Increase of the “need for
help” rating mean values from the baseline rating mean value that the person gives for the expression
statement ES20 (“I have an ordinary health condition.”), n=673.

Figure 3. a)-e) The relative frequency of respondents for each alternative “need for help” rating value
(transformed into the range 0.0-1.0) concerning expression statements ES4, ES9-ES10 and ES19ES20 in respect to the person’s answer value to the background question BQ1 (an estimated health
condition) and BQ9 (the age), n=673. f) Rating value distributions for the expression statements ES4,
ES9-ES10 and ES19-ES20 in respect to all respondents together, n=673.
We computed Kendall rank-correlation and cosine similarity measures for each comparable
pair of parameter values of the “need for help” ratings of expression statements ES1-ES20 and the
answers of the background questions BQ1 and BQ5-BQ7. Motivated by a recommendation of Akoglu
(2018) we considered a Kendall rank-correlation measure greater than or equal to 0.70 to indicate a
significant correlation and the statistical significance levels were defined as p<0.05, p<0.01 and
p<0.001. Before computing cosine similarity measures the answer values of each parameter were
normalized by the formula (x - min(x))/(max(x)-min(x)) and then these new values were shifted so
that the mean value was positioned to the zero by the formula (x - mean(x)).
A significant correlation was found between the expression statement pairs ES16&ES17
(0.91), ES14&ES15 (0.86), ES9&ES10 (0.79), ES16&ES18 (0.78), ES17&ES18 (0.77), ES7&ES8

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 9 (33)

(0.75) and ES1&ES2 (0.73), and between the background question pair BQ1&BQ6 (0.71), all these
were statistically significant with the level p<0.001. The highest cosine similarity values included the
same pairs of expression statements and the pair of background questions, thus reaching the following
values: ES16&ES17 (0.97), ES14&ES15 (0.95), ES9&ES10 (0.92), ES16&ES18 (0.90),
ES17&ES18 (0.89), ES7&ES8 (0.87), ES1&ES2 (0.80), and BQ1&BQ6 (0.82). This same highest
cosine similarity value range was reached also by the pairs ES8&ES9 (0.87), ES3&ES4 (0.83),
ES10&ES17 (0.82), ES9&ES17 (0.81), ES10&ES16 (0.80) and BQ5&BQ6 (0.80).
We computed Wilcoxon rank-sum test (i.e., Mann–Whitney U test) between two groups and
Kruskal-Wallis test between three groups to identify statistically significant rating differences for
expression statements ES1-ES20 in respect to groupings based on the answer values of each
background question (BQ), as shown in Table 5. We created groupings of two groups so that the
“group 1” contained those respondents who gave an answer value that was lower than the mean value
of all the answer values to the background question, and the “group 2” contained all the other
respondents. We created groupings of three groups so that the respondents could be divided the most
evenly into three ranges of answer values of the background question. The statistical significance
levels were defined as p<0.05, p<0.01 and p<0.001. Table 5 shows also the differences of mean
ratings for the groupings. For example, for ES4 (a weakening health condition) the younger
respondents gave a mean rating value 0.66 that was 0.10 greater than the mean rating value 0.56 given
by the older respondents (BQ9, for two groups).
Supplementing tests of one-way analysis of variance (ANOVA) indicated statistically
significant rating differences largely for the same expression statements as Wilcoxon rank-sum test
and Kruskal-Wallis test. However, this significance did not reappear with ANOVA tests for ES5 in
respect to BQ1 for three groups, ES14 in respect to BQ2 for two groups, ES19 in respect to BQ9 for
three groups, and ES20 in respect to BQ5 for three groups. ANOVA tests indicated also some
additional significant rating differences, such as for ES9-ES10 and E17 in respect to BQ2 for two
groups, E9-E10 in respect to BQ9 for two groups, and ES4 in respect to BQ7 for two groups.
A complete listing of means, medians and standard deviations of the “need for help” ratings
for the groupings is provided in Appendix A which includes also a comprehensive listing of Kendall
rank-correlation and cosine similarity measures, and tests of Wilcoxon rank-sum, Kruskal-Wallis and
one-way analysis of variance (ANOVA).
Figure 4 illustrates for all the twenty expression statements ES1-ES20 how the “need for help”
rating mean values differ between the respondents who indicate a lower estimated health condition
and the respondents who indicate a higher estimated health condition (BQ1, for two groups). Besides
comparing just single expression statements between groups, we can now also identify the emergence
of two different ranking orders for all the twenty expression statements ES1-ES20 in respect to the
grouping based on the answer values of the background question BQ1.
To address our main research question RQ2, we carried out machine learning experiments
with a basic implementation of a convolutional neural network algorithm that we run in a TensorFlow
programming environment (adapted from TensorFlow image classification tutorial, 2020). Our
approach consisted of creating an image classifier using a keras.Sequential model with
layers.Conv2D layers and then providing input data to the model in the form of images. We used a
model consisting of three convolution blocks with a max pool layer in each of them and having on
the top a fully connected layer that is activated by a relu activation function. We compiled our model
with the optimizers.Adam optimizer and the losses.SparseCategoricalCrossentropy loss function.
Table 6 describes layers of the convolutional neural network model used in the machine learning
experiments.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 10 (33)

Table 5. Groupings based on the answer values of each background question (BQ) that enable to
compute the differences of mean ratings for expression statements ES1-ES20 concerning the “need
for help” ratings. For groupings of two groups the difference of mean ratings (each mean rating in the
range 0.0-1.0) is computed by the formula (M1-M2), and for groupings of three groups by the formula
max({(M1-M3),(M1-M2),(M2-M3)}). Wilcoxon rank-sum test (for two groups) and Kruskal-Wallis test
(for three groups) indicate the statistically significant differences with levels p<0.05, p<0.01 and
p<0.001, denoted by the symbols *, ** and ***, respectively. Training and validation metrics of the
convolutional neural network model are averaged from 100 separate training and validation
sequences to learn a labeling that matches the grouping (n=673). M=mean, Mdn=median,
SD=standard deviation.
Statistically significant rating differences
Grouping based on
the answer value (x)
of the background
question (BQ)
BQ1, two groups:
x<7 (n1=263),
x>=7 (n2=410)
BQ1, three groups:
x<6 (n1= 218),
6<=x<8 (n2=207),
x>=8 (n3=248)
BQ2, two groups:
x<2 (n1=219),
x>=2 (n2=454)
BQ4, two groups:
x<2 (n1=364),
x>=2 (n2=309)
BQ5, two groups:
x<7 (n1=274),
x>=7 (n2=399)
BQ5, three groups:
x<6 (n1=190),
6<=x<8 (n2=271),
x>=8 (n3=212)
BQ6, two groups:
x<7 (n1=318),
x>=7 (n2=355)
BQ6, three groups:
x<6 (n1=240),
6<=x<8 (n2=229),
x>=8 (n3=204)
BQ7, two groups:
x<7 (n1=201),
x>=7 (n2=472)
BQ7, three groups:
x<6 (n1=143),
6<=x<8 (n2=214),
x>=8 (n3=316)
BQ8, two groups:
x<2 (n1=123),
x>=2 (n2=550)

BQ9, two groups:
x<51 (n1=333),
x>=51 (n2=340)

BQ9, three groups:
x<40 (n1=225),
40<=x<60 (n2=231),
x>=60 (n3=217)

Expression statements (ES) having
statistically significant rating differences in
the grouping (the difference of mean ratings
about the need for help)
ES6 (0.07)***, ES8 (-0.08)**, ES9 (-0.08)**,
ES10 (-0.09)**, ES7 (-0.05)*, ES16 (-0.06)*,
ES17 (-0.08)*, ES18 (-0.05)*
ES6 (0.08)**, ES5 (-0.05)*, ES8 (-0.08)*,
ES9 (-0.09)*, ES11 (0.08)*

Training and validation metrics of the convolutional neural
network model to learn a labeling that matches the grouping
Epoch
Training
Training
Validation Validation
step
loss
accuracy
loss
accuracy

M=11.26
Mdn=11
SD=2.39
M=4.85
Mdn=4
SD=1.8

M=0.55
Mdn=0.55
SD=0.03
M=1.02
Mdn=1.03
SD=0.03

M=0.73
Mdn=0.72
SD=0.02
M=0.48
Mdn=0.47
SD=0.03

M=0.59
Mdn=0.59
SD=0.01
M=1.06
Mdn=1.06
SD=0.01

M=0.69
Mdn=0.69
SD=0.02
M=0.40
Mdn=0.40
SD=0.02

M=5.55
Mdn=6
SD=2.91
M=3.44
Mdn=3
SD=1.28
M=3.27
Mdn=3
SD=1.65
M=3.63
Mdn=4
SD=1.33

M=0.57
Mdn=0.56
SD=0.04
M=0.67
Mdn=0.67
SD=0.01
M=0.64
Mdn=0.63
SD=0.02
M=1.05
Mdn=1.05
SD=0.02

M=0.69
Mdn=0.69
SD=0.02
M=0.59
Mdn=0.60
SD=0.02
M=0.65
Mdn=0.65
SD=0.03
M=0.44
Mdn=0.44
SD=0.03

M=0.63
Mdn=0.63
SD=0.01
M=0.68
Mdn=0.67
SD=0
M=0.66
Mdn=0.67
SD=0
M=1.07
Mdn=1.07
SD=0.01

M=0.66
Mdn=0.66
SD=0.02
M=0.57
Mdn=0.57
SD=0.02
M=0.60
Mdn=0.60
SD=0.02
M=0.42
Mdn=0.43
SD=0.03

M=5.35
Mdn=5
SD=1.61
M=3.89
Mdn=4
SD=1.8

M=0.62
Mdn=0.63
SD=0.02
M=1.05
Mdn=1.06
SD=0.03

M=0.63
Mdn=0.63
SD=0.03
M=0.41
Mdn=0.41
SD=0.03

M=0.65
Mdn=0.65
SD=0
M=1.08
Mdn=1.08
SD=0

M=0.60
Mdn=0.60
SD=0,02
M=0.39
Mdn=0.39
SD=0.03

M=7.26
Mdn=7
SD=1.63
M=1.31
Mdn=1
SD=0.61

M=0.53
Mdn=0.54
SD=0.02
M=1.05
Mdn=1.06
SD=0.02

M=0.75
Mdn=0.74
SD=0.01
M=0.45
Mdn=0.45
SD=0.02

M=0.59
Mdn=0.59
SD=0
M=1.07
Mdn=1.07
SD=0.01

M=0.72
Mdn=0.72
SD=0.01
M=0.47
Mdn=0.48
SD=0.02

ES4 (-0.11)***, ES12 (-0.13)***, ES14 (0.20)***, ES15 (-0.20)***, ES3 (-0.10)**,
ES10 (-0.12)**, ES11 (-0.08)**, ES8 (0.09)*, ES9 (-0.10)*, ES13 (-0.07)*, ES16 (0.10)*, ES17 (-0.09)*, ES18 (-0.08)*
ES1 (0.09)***, ES2 (0.10)***, ES3 (0.13)***,
ES4 (0.10)***, ES5 (0.08)***, ES14
(0.14)***, ES15 (0.14)***, ES7 (0.06)*, ES8
(0.09)*, ES11 (-0.05)*, ES13 (0.06)*, ES19
(0.04)*

M=6.14
Mdn=6
SD=1.69

M=0.42
Mdn=0.42
SD=0.02

M=0.83
Mdn=0.83
SD=0.01

M=0.48
Mdn=0.48
SD=0.01

M=0.79
Mdn=0.78
SD=0.01

M=5.79
Mdn=6
SD=1.44

M=0.58
Mdn=0.58
SD=0.02

M=0.69
Mdn=0.69
SD=0.02

M=0.61
Mdn=0.61
SD=0.01

M=0.68
Mdn=0.68
SD=0.02

ES1 (0.10)***, ES2 (0.12)***, ES3 (0.17)***,
ES4 (0.13)***, ES5 (0.09)***, ES14
(0.17)***, ES15 (0.18)***, ES7 (0.09)**,
ES11 (-0.10)**, ES8 (0.13)*, ES10 (0.14)*,
ES19 (0.06)*, ES20 (-0.08)*

M=7.13
Mdn=7
SD=1.45

M=0.93
Mdn=0.93
SD=0.03

M=0.54
Mdn=0.54
SD=0.03

M=0.98
Mdn=0.98
SD=0.01

M=0.50
Mdn=0.50
SD=0.03

ES11 (-0.08)***, ES6 (-0.06)**, ES3 (0.06)*,
ES14 (0.06)*, ES15 (0.08)*
ES6 (-0.06)**, ES11 (-0.06)*

ES6 (0.06)**, ES9 (-0.08)**, ES10 (-0.09)**,
ES11 (0.06)*, ES16 (-0.06)*, ES17 (-0.07)*
ES9 (-0.15)***, ES10 (-0.15)***, ES6
(0.07)**, ES8 (-0.11)*, ES16 (-0.09)*, ES17
(-0.10)*, ES20 (0.05)*
ES11 (0.08)***, ES6 (0.06)**

ES11 (0.09)**, ES6 (0.07)*

ES6 (0.08)***, ES11 (0.07)**, ES19 (0.07)**

ES6 (0.09)**, ES11 (0.10)**

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 11 (33)

Figure 4. The “need for help” rating mean values of expression statements ES1-ES20 (transformed
into the range 0.0-1.0) in respect to two groups based on the answer values of the background question
BQ1 (in the range 1-9). The “group 1” contains those respondents who gave an answer value that was
lower than 7 (n1=263), and the “group 2” contains all the other respondents (n2=410).
Table 6. Layers of the convolutional neural network model used in the machine learning experiments.
Model: "sequential"
Parameters: total 73112; trainable: 73112; non-trainable: 0
Layer (type)
Output shape
rescaling_1 (Rescaling)
(None, 20, 25, 3)
conv2d (Conv2D)
(None, 20, 25, 16)
max_pooling2d (MaxPooling2D)
(None, 10, 12, 16)
conv2d_1 (Conv2D)
(None, 10, 12, 32)
max_pooling2d_1 (MaxPooling2D)
(None, 5, 6, 32)
conv2d_2 (Conv2D)
(None, 5, 6, 64)
max_pooling2d_2 (MaxPooling2D)
(None, 2, 3, 64)
flatten (Flatten)
(None, 384)
dense (Dense)
(None, 128)
dense_1 (Dense)
(None, 2)

Number of parameters
0
448
0
4640
0
18496
0
0
49280
258

Since the convolutional neural network model required labeled input data in the form of
images, we transformed with a R language script our originally character-encoded questionnaire data
into a set of grayscale raster images before feeding it to the model.
First the original rating answer values in the range 0-10 were transformed linearly into the
range 0.0-1.0. Each entity of twenty rating answers (in the range 0.0-1.0) of expression statements
ES1-ES20 given by a certain person were transformed into an individual raster image so that each
single rating answer value was represented by a region of 25 pixels (width 5 pixels and height 5
pixels) having a brightness value in the range 0-255 directly proportional to the greatness of the
transformed answer value in the range 0.0-1.0. All the twenty separate 25-pixel-sized regions were
then joined as a 5×4 matrix to form a combined grayscale raster image (width 25 pixels and height
20 pixels).

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 12 (33)

We performed machine learning experiments with labeled images so that their labeling
matched the groupings that we have just previously analyzed with Wilcoxon rank-sum test (i.e.,
Mann–Whitney U test) between two groups and Kruskal-Wallis test between three groups to identify
statistically significant rating differences (see Table 5). We allocated for the training and validation
80 percent and 20 percent of the data, respectively.
Table 5 shows our results about training and validation of the convolutional neural network
model based on the labeling in respect to groupings based on the answer values of each background
question, among questions BQ1-BQ2 and BQ4-BQ9 (n=673). For each grouping we report training
and validation metrics gained when reaching the lowest value for the validation loss (ensured by
further 50 evaluation steps with a patience procedure), averaged from 100 separate training and
validation sequences.
Figure 5 illustrates the loss and accuracy for training and validation of the convolutional
neural network model for one sequence based on the labeling in respect to the grouping of two groups
based on the answer values of the background question BQ1 (n=673). In this illustrated single
sequence the lowest value for the validation loss was reached at the epoch step 11 and at that step the
following metrics were gained: training loss 0.53, training accuracy 0.73, validation loss 0.60 and
validation accuracy 0.67.

Figure 5. Loss and accuracy for training and validation of the convolutional neural network model
for one sequence based on the labeling in respect to the grouping of two groups based on the answer
values of the background question BQ1 (n=673).

4. Discussion
In respect to our main research question RQ1, we have analyzed how different people rate the “need
for help” for expression statements concerning imagined care situations related to the coronavirus
COVID-19 epidemic and how this rating depends on the background information about the person.
When we computed Kendall rank-correlation measures for each comparable pair of parameter
values of the “need for help” ratings, we found significant correlation linking expression statements
in five thematic subentities. These are: an infectious disease (suspecting to have an infectious disease,
having it, or having it with a doctor's verification; ES16-ES18), a lack of coping independently (a
lack of coping independently in everyday life or at home; ES14-ES15), the coronavirus (suspecting
to have the coronavirus infection or having it; ES9-ES10), a fever (having a fever or a sudden rise of
fever; ES7-ES8), and a flu/cough (having a flu or a cough; ES1-ES2). Furthermore, a significant
correlation linked background questions in a subentity about health (an estimated health condition or
the satisfaction about health; BQ1&BQ6). The highest cosine similarity values emerging among the
same value pairs seemed to support the clusters just identified by the correlation. In the same highest
range of cosine similarity values, other linked expression statement pairs included having a sudden

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 13 (33)

rise of fever and suspecting to have the coronavirus infection, having a shortness of breath and a
weakening health condition, and having a sore throat and muscular ache.
We identified statistically significant rating differences for expression statements in respect
to groupings based on the answer values of each background question, between two groups and
between three groups (with Wilcoxon rank-sum test and Kruskal-Wallis test, respectively), as shown
in Table 5. Supplementing tests of one-way analysis of variance (ANOVA) also largely supported
these findings, and indicated even some other significant rating differences. To keep our analysis
compact, we now discuss about the significant rating differences especially in respect to Wilcoxon
rank-sum test and Kruskal-Wallis test but similar notions apply well also in respect to ANOVA tests.
In groupings of two groups, the highest number of statistically significant rating differences
(p<0.05) emerged for the expression statements ES11 (7 groupings) and ES6 (10). The rating for
ES11 differed significantly for all the background questions, except BQ1, between two groups (lower
answer values vs. higher answer values). The mean rating of ES11 was higher when getting lower
answer values to BQ5-BQ7 (“group 1”) than when getting higher answer values to BQ5-BQ7 (“group
2”). In contrast, the mean rating of ES11 was lower when getting lower answer values to BQ2, BQ4,
BQ8 and BQ9 (“group 1”) than when getting higher answer values to BQ2, BQ4, BQ8 and BQ9
(“group 2”).
Since ES11 refers to an essential coronavirus-related situation (to be quarantined from
meeting other people to prevent spreading an infectious disease), this emerging high differentiation
of the “need for help” ratings can be considered as an important new finding that should be addressed
when interpreting a person’s need for help during an epidemic (such as the coronavirus COVID-19
epidemic). For example, the respondents who indicated a lower quality of life (BQ5) gave for ES11
a mean rating of 0.47, whereas the respondents who indicated a higher quality of life gave a mean
rating of 0.41. On the other hand, the respondents who indicated a lower age (BQ9) gave for ES11 a
mean rating of 0.41, whereas the respondents who indicated a higher age gave a mean rating of 0.46.
Besides groupings of two groups, ES11 and ES6 gained the highest number of statistically
significant rating differences also in respect to groupings of three groups (4 groupings for both ES11
and ES6). Other expression statements having a high number of statistically significant rating
differences in groupings of two or three groups include ES8-ES10 (5 or 6 groupings). Since ES8ES10 refer to an essential coronavirus-related situation (having a sudden rise of fever, suspecting to
have the coronavirus infection or having it), also this emerging high differentiation of the “need for
help” ratings can be considered as an important new finding that should be addressed when
interpreting a person’s need for help, for example to support personalized screening, diagnosis and
care planning These three expression statements ES8-ES10 gained lower mean ratings from
respondent groups who indicated a lower estimated health condition (BQ1), a lower quality of life
(BQ5) and being a man (BQ8), and higher mean ratings from the opposite groups, respectively.
Statistically significant rating differences in groupings of two groups emerged the most for
the background question BQ8 (13 expression statements), then followed by BQ9 (12), BQ1 (8), BQ5
(6), BQ2 (5), BQ7 (3), BQ4 (2), and BQ6 (2). Relatively similarly, in groupings of three groups,
significant rating differences emerged the most for the background question BQ9 (13 expression
statements), then followed by BQ5 (7), BQ1 (5), BQ6 (2), and BQ7 (2).
Figure 4 illustrates the emergence of two different ranking orders for the “need for help”
ratings of expression statements ES1-ES20 in respect to the grouping based on the answer values of
the background question BQ1. Already these kinds of rankings can assist addressing the needs of the
patient depending on his/her background information, but the ratings can be exploited also in many
other ways to create rankings that can support personalizing the care. Each background question is
linked to a specific set of expression statements (if any) that show statistically significant rating
differences for this background question. Based on the rating differences and the strengths of
significance, a ranking order can be identified for those expression statements that are linked to by
the same background question. On the other hand, an expression statement can get different rating
differences and strengths of significance for different background questions (if any). This enables to
identify for each expression statement a ranking order of background questions that link to it.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 14 (33)

These various ranking orders offer an opportunity to find some distinctive link patterns
between the person’s “need for help” ratings for expression statements and his/her answer values to
background questions, and vice versa. For example, in groupings of two groups, ES14 and ES15 show
statistically significant rating differences for BQ2 (0.06 and 0.08, respectively) but not for BQ5, and
on the other hand ES16 and ES17 show statistically significant rating differences for BQ5 (-0.06 and
-0.07, respectively) but not for BQ2. This emerging differentiation may enable a conclusion that the
“need for help” ratings about coping independently (ES14-ES15) are more closely linked to having a
health problem that reduces ability (BQ2) than to the quality of life (BQ5). Similarly, it may be
concluded that the “need for help” ratings about an infectious disease (ES16-ES17) are more closely
linked to the quality of life (BQ5) than to having a health problem that reduces ability (BQ2).
In respect to our main research question RQ2, we performed machine learning experiments
with the answer value sets transformed to labeled raster images so that their labeling matched the
groupings that we have just previously analyzed with Wilcoxon rank-sum test and Kruskal-Wallis
test. This was motivated by the assumption that machine learning enables more flexibility for
modeling than for example logistic regression models of traditional statistics (Deo 2015). We trained
and validated a convolutional neural network model to learn a labeling that matches the grouping. In
groupings of two groups, the highest mean values of validation accuracy emerged for the background
question BQ8 (0.79), then followed by BQ7 (0.72), BQ1 (0.69), BQ9 (0.68), BQ2 (0.66), BQ5 (0.60),
BQ6 (0.60) and BQ4 (0.57). In groupings of three groups, the highest mean values of validation
accuracy emerged for the background question BQ9 (0.50), then followed by BQ7 (0.47), BQ5 (0.42),
BQ1 (0.40) and BQ6 (0.39). Although the mean values of validation accuracy remained relatively
low, our machine learning experiments showed the applicability of a convolutional neural network
model to support detecting the need for help in the patient’s expressions based on the ratings.
These our notions are motivated by the previous research that has shown the applicability of
an artificial neural network model in identifying the affectivity of online messages about the
coronavirus (Jelodar et al., 2020) by reaching a testing accuracy of 81.15 percent in classification that
relied on a training set of 338666 messages and a testing set of 112888 messages about the
coronavirus extracted from the online messaging service Reddit between 20 January and 19 March
2020. Besides having a bigger data set than ours, Jelodar et al. (2020) used additional methods of
Latent Dirichlet Allocation (LDA) and a pre-existing emotion vocabulary and rules (SentiStrength
algorithm) to supplement a Long Short-Term Memory (LSTM) recurrent neural network (RNN)
algorithm. In contrast, our results purposefully rely on using just a basic implementation of a
convolutional neural network algorithm (TensorFlow image classification tutorial, 2020) that we feed
with our gathered questionnaire answers (n=673).
Since we used a relatively small data set of answers and the distributions of some answer
values were positioned in a relatively narrow or skewed subrange of the scale range, this may have
limited the classification ability of our machine learning model. However, we gained some emerging
link patterns between our results of machine learning and traditional statistical analysis. For two
groups and three groups, the highest mean values of validation accuracy emerged for the background
questions BQ8 and BQ9, respectively, which also reached the highest number of statistically
significant rating differences with Wilcoxon rank-sum test and Kruskal-Wallis test for the same
groupings in respect to expression statements (see Table 5). Anyway, we expect that by accumulating
a larger data set of answers, the validation accuracy of machine learning results can be enhanced and
more detailed understanding about the dependencies between the answers can be achieved with
further finetuning the models of machine learning.
Accumulating knowledge from even sparse data points of diverse single-time interpretative
measurements with machine learning gets fruitful support from the previous research that has found
relatively good reliability even for single-item observations with increasing efficiency, avoiding
confusion and enabling to accumulate answers from people who are hard to reach (Boateng et al.,
2018; Kulikowski, 2018; Siegel & van Dolen, 2020; Tolvanen et al., 2019). We now present a new
comparative analysis approach to identify and evaluate with traditional statistical methods the
dependencies that can explain the machine learning results. Thus our analysis approach enables to

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 15 (33)

develop better human-understandable machine learning and so helps to address the traditional
challenges of interpreting reliably and intuitively machine learning results (Deo 2015). Therefore, our
analysis approach can offer also support for developing reliable evaluation metrics for healthcare
chatbots (Abd-Alrazaq et al., 2020) and their ability for semantic understanding (Laranjo et al., 2018).
Our results can be considered as a supplement to already existing machine learning
approaches that have been applied in classification of medical literature, patient records, clinical
narratives and patient phenotypes (Hughes et al., 2017; Zhao et al., 2017; Gehrmann et al., 2018;
Rojas-Barahona et al., 2018; Yao et al., 2019; Qing et al., 2019; Shickel et al., 2019). However, a
specific novelty in our approach is that besides gathering answers about the person’s current real-life
situation, we also gathered rating answers that measured the degree of the “need for help” that the
person associated with the given imagined care situations. Thus with our “need for help” rating model
(Lahti, 2017; Lahti 2018) we developed a new methodology that extracts the person’s behavioral
patterns (such as conceptualizations, attitudes and reasonings) associated with various possible future
care situations depicted by expression statements. With machine learning these identified behavioral
patterns are then linked to certain background information about the person thus enabling to create
predictive models. For example, in the context of clinical decision support systems (CDSS), our
results can assist in detecting the patient’s need for help and thus enhance reasoning that addresses
distinctive and differentiated needs of the patient to enable personalized screening, diagnosis and care
planning. Also in self-care and rehabilitation, our results can assist to implement monitoring and
recording of the emerging need for help in the person’s everyday life so that necessary assistance can
be alerted.
We decided to gather now ratings in respect to the “need for help” since this semantic
dimension emerged strongly in the context of health-related online discussions in our previous
analysis (Lahti et al., 2018). However, the selection of the “need for help” dimension can be motivated
also by its intuitive relatedness to the dominance dimension (Bradley & Lang, 1999a; Warriner et al.,
2013) that reflects the degree of ability to cope and to be in the control of one’s own life situations,
and also to the approach-avoidance dimension (Mauss & Robinson, 2009) that reflects the desire to
reach some relieving assistance or to be reached by this assistance.
Our results indicated significant rating differences depending on the person’s sex and age that
can be considered to get support from corresponding previous results (Warriner et al., 2013) in which
female and older respondents gave on average smaller rating values of pleasure, arousal and
dominance than male and younger respondents, respectively, for a diverse set of words. Furthermore,
our results concerning significant rating differences depending on the person’s health and wellbeing
get support from the previous findings of Warriner et al. (2013) in which the most feared medical
conditions were also rated to be among the diseases that represent the lowest rating values of pleasure
and dominance and the highest rating values of arousal.
To measure the “need for help” ratings the most reliably, the measurements should be done
in real-life situations that involve negative experiences but since that is ethically challenging, we now
measured the “need for help” with imagined situations. Anyway, experimental setups containing reallife exposure to pain and threats to pain (Sullivan et al., 1995) indicated that helplessness correlated
highly with rumination and moderately with magnification. Since this previous result has resemblance
with our significant correlation between ratings of suspecting to have the coronavirus infection or
having it (ES9-ES10) and between ratings of suspecting to have an infectious disease, having it, or
having it with a doctor’s verification (ES16-ES18), this offers support that our measurements of
imagined situations can indeed be relatively reliably paralleled with real-life situations. In addition,
Berna et al. (2011) have found links between self-identified most significant mental imagery
describing the patient's pain and associated triggers, affects, meanings and avoidance patterns.
Our aim to generalize imaginary-based measurement results to corresponding real-life
situations gets also support from the previous findings that the patterns of neural activation during
imagery and actual perception have a strong overlap (Ganis et al., 2004; McNorgan, 2012).
Neuroimaging experiments have indicated that self-report ratings of vividness of mental imagery can
correlate with activation of the same sensory-specific cortices as activated in perception (Cui et al.,

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 16 (33)

2007; Herholz et al., 2012; Belardinelli et al., 2009). Anyway, there is evidence that imagining a
future event increases the person’s perception concerning the probability that the imagined event will
occur (Carroll, 1978, Sherman et al., 1985). It has been also shown that people perceive the likelihood
of contracting a disease higher when the description of the disease is easier to imagine than when it
is harder to imagine (Sherman et al., 1985), and for imagined symptoms people prioritized selecting
a simple separate cause than a more complex combination of causes even if the likelihood value for
the combination of all the causes was displayed to be higher than for simple separate causes
(Lombrozo 2007).

Conclusions
We found statistically significant correlations and high cosine similarity values between various
health-related expression statement pairs concerning the “need for help” ratings and a background
question pair. We also identified statistically significant rating differences for several health-related
expression statements in respect to groupings based on the answer values of background questions,
such as the ratings of suspecting to have the coronavirus infection and having it depending on the
estimated health condition, quality of life and sex.
Resembling the previous research that has developed machine learning methods for extracting
health-related knowledge (Hughes et al., 2017; Zhao et al., 2017; Gehrmann et al., 2018; RojasBarahona et al., 2018; Yao et al., 2019; Qing et al., 2019; Shickel et al., 2019) and evaluated the
affectivity of online messages about the coronavirus (Jelodar et al., 2020), our results offer insight
about the applicability of machine learning to extract useful knowledge from health-related
expression statements to support healthcare services, such as to provide personalized screening and
care. However, to our best knowledge our research is the first of its kind to develop and use the “need
for help” rating model (Lahti, 2017; Lahti, 2018) to gather self-rated interpretations about healthrelated expression statements that are then analyzed to identify statistically significant rating
differences in respect to groupings based on the answer values of background questions, and then
also to show the applicability of machine learning to learn the groupings based on the ratings.
Our research contribution gets some additional value also from the successful data acquisition
process that involved respondents belonging to Finnish patient and disabled people’s organizations,
other health-related organizations and professionals, and educational institutions (n=673) and thus
representing a diversity of health conditions, abilities and attitudes. In addition, our results enable to
compare the statistically significant rating differences in groupings in respect to the person’s
background information and to further contrast them with the training and validation metrics gained
in machine learning experiments based on the same groupings (see Table 5). We also publish an open
access data set about our measurements and results in the supplementing Appendix A.
Future research should continue exploring and analyzing how different people interpret and
evaluate health-related expression statements and how this possibly depends on the person’s
background information. A specific emphasis should be given for developing adaptive modular
methods that can be flexibly applied for various purposes of health analytics and also enhance fertile
standardized practices that ensure comparability. Furthermore, the emerging new methods and
algorithms should be well human-understandable for everyone and provided with open access,
accompanied with appropriately and sufficiently anonymized data sets. In this spirit, we suggest that
also our current findings and results can be used as a part of a greater reasoning entity to develop
computational methods to identify, interpret and address the needs of the patient in diverse knowledge
processes of healthcare to support personalized care.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 17 (33)

Abbreviations
ANOVA: analysis of variance
BQ: background question
CDSS: clinical decision support system
COVID-19: coronavirus disease 2019
DIHEML: the research project “Development of method for interpretation of health expressions
based on machine learning to support various care events and persons”
ES: expression statement
LDA: Latent Dirichlet Allocation
LSTM: Long Short-Term Memory
M: mean
Mdn: median
RNN: recurrent neural network
RQ: research question
SD: standard deviation
THL: National Institute for Health and Welfare in Finland (Terveyden ja hyvinvoinnin laitos, THL)
WHO: World Health Organization

References
Aalto, A., Korpilahti, U., Sainio, P., Malmivaara, A., Koskinen, S., Saarni, S., Valkeinen, H., &
Luoma, M. (2013). Aikuisten geneeriset elämänlaatumittarit terveys- ja hyvinvointitutkimuksessa
sekä terveys- ja kuntoutuspalvelujen vaikutusten arvioinnissa. Terveyden ja hyvinvoinnin laitos
(THL). TOIMIA-suositus, TOIMIA-verkosto. http://urn.fi/URN:NBN:fi-fe2016092224121;
https://www.terveysportti.fi/dtk/tmi/tms00040
Abd-Alrazaq, A., Safi, Z., Alajlani, M., Warren, J., Househ, M., & Denecke, K. (2020). Technical
Metrics Used to Evaluate Health Care Chatbots: Scoping Review. Journal of medical Internet
research, 22(6), e18301. https://doi.org/10.2196/18301
Akoglu, H. (2018). User's guide to correlation coefficients. Turkish journal of emergency medicine,
18(3), 91–93. https://doi.org/10.1016/j.tjem.2018.08.001
Anttila, H., Kokko, K., Hiekkala, S., Weckström, P., & Paltamaa, J. (2017). Asiakaslähtöinen
Toimintakykyni-sovellus. Kehittäminen ja käytettävyystutkimus. Kansaneläkelaitos (Kela),
Työpapereita 119, ISSN: 2323-9239. http://hdl.handle.net/10138/187061
Belardinelli, M., Palmiero, M., Sestieri, C., Nardo, D., Di Matteo, R., Londei, A., D’Ausilio, A.,
Ferretti, A., Del Gratta, C., & Romani, G. (2009). An fMRI investigation on image generation in
different sensory modalities: The influence of vividness. Acta Psychologica, 132,190-200. DOI:
10.1016/j.actpsy.2009.06.009
Berna, C., Vincent, K., Moore, J., Tracey, I., Goodwin, G., & Holmes, E. (2011). Presence of Mental
Imagery Associated with Chronic Pelvic Pain: A Pilot Study, Pain Medicine, Volume 12, Issue 7,
July 2011, Pages 1086–1093, https://doi.org/10.1111/j.1526-4637.2011.01152.x
Bhandare, A., Bhide, M., Gokhale, P., & Chandavarkar, R. (2016). Applications of Convolutional
Neural Networks. International Journal of Computer Science and Information Technologies
(IJCSIT),
Vol.
7
(5),
2016,
2206-2215.
https://ijcsit.com/docs/Volume%207/vol7issue5/ijcsit20160705014.pdf
Boateng, G. O., Neilands, T. B., Frongillo, E. A., Melgar-Quiñonez, H. R., & Young, S. L. (2018).
Best Practices for Developing and Validating Scales for Health, Social, and Behavioral Research:
A Primer. Frontiers in public health, 6, 149. https://doi.org/10.3389/fpubh.2018.00149
Borraccino, A., Pera, R., & Lemma, P. (2019). "What being healthy means to me": A qualitative
analysis uncovering the core categories of adolescents' perception of health. PloS one, 14(6),
e0218727. https://doi.org/10.1371/journal.pone.0218727

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 18 (33)

Bradley, M.M., & Lang, P.J. (1999). Affective norms for English words (ANEW): Instruction manual
and affective ratings. Technical Report C-1, The Center for Research in Psychophysiology,
University of Florida.
de Bruin, A., Picavet, H., & Nossikov, A. (eds.) (1996). Health interview surveys: towards
international harmonization of methods and instruments. World Health Organization (WHO).
WHO regional publications, European series, no. 58. ISBN 92-890-1322-2.
https://www.euro.who.int/__data/assets/pdf_file/0017/111149/E72841.pdf
Carroll, J.S. (1978). The effect of imagining an event on expectations for the event: an interpretation
in terms of the availability heuristic. Journal of Experimental Social Psychology, 14 (1) (1978),
pp. 88-96.
Cui, X., Jeter, C. B., Yang, D., Montague, P. R., & Eagleman, D. M. (2007). Vividness of mental
imagery: Individual variability can be measured objectively. Vision Research, 47(4), 474-478.
DOI: 10.1016/j.visres.2006.11.013
Cullati, S., Bochatay, N., Rossier, C., Guessous, I., Burton-Jeangros, C., & Courvoisier, D. S. (2020).
Does the single-item self-rated health measure the same thing across different wordings? Construct
validity study. Quality of life research: an international journal of quality of life aspects of
treatment, care and rehabilitation, 29(9), 2593–2604. https://doi.org/10.1007/s11136-020-025332
Deo, R. C. (2015). Machine Learning in Medicine. Circulation, 132(20), 1920–1930.
https://doi.org/10.1161/CIRCULATIONAHA.115.001593
Gallagher, J.E., Wilkie, A.A., Cordner, A., Hudgens, E., Ghio, A., Birch, R., & Wade, T. (2016).
Factors associated with self-reported health: implications for screening level community-based
health and environmental studies. BMC Public Health 16, 640 (2016).
https://doi.org/10.1186/s12889-016-3321-5
Ganis, G., Thompson, W. L., & Kosslyn, S. M. (2004). Brain areas underlying visual mental imagery
and visual perception: An fMRI study. Cognitive Brain Research, 20(2),226-241. DOI:
10.1016/j.cogbrainres.2004.02.012
Garbarski, D., Schaeffer, N. C., & Dykema, J. (2016). The effect of response option order on selfrated health: a replication study. Quality of life research: an international journal of quality of life
aspects of treatment, care and rehabilitation, 25(8), 2117–2121. https://doi.org/10.1007/s11136016-1249-y
Gehrmann, S., Dernoncourt, F., Li, Y., Carlson, E., Wu, J., Welt, J., Foote Jr., J., Moseley, E., Grant,
D., Tyler, P., & Celi, L. (2018). Comparing deep learning and concept extraction based methods
for patient phenotyping from clinical narratives. PLoS ONE 13(2): e0192360.
https://doi.org/10.1371/journal.pone.0192360
Herholz, S. C., Halpern, A. R., & Zatorre, R. J. (2012). Neuronal correlates of perception, imagery,
and memory for familiar tunes. Journal of Cognitive Neuroscience, 24(6),1382–97. DOI:
10.1162/jocn_a_00216
Hughes, M., Li, I., Kotoulas, S., & Suzumura, T. (2017). Medical Text Classification Using
Convolutional Neural Networks. Stud Health Technol Inform. 2017;235:246-250. PMID:
28423791.
Jacobson, R. P., Kang, D., & Houck, J. (2020). Can Patient-Reported Outcomes Measurement
Information System® (PROMIS) measures accurately enhance understanding of acceptable
symptoms and functioning in primary care? Journal of patient-reported outcomes, 4(1), 39.
https://doi.org/10.1186/s41687-020-00206-9
Jelodar, H., Wang, Y., Orji, R., & Huang, S. (2020). Deep Sentiment Classification and Topic
Discovery on Novel Coronavirus or COVID-19 Online Discussions: NLP Using LSTM Recurrent
Neural Network Approach," in IEEE Journal of Biomedical and Health Informatics, vol. 24, no.
10, pp. 2733-2742, Oct. 2020, doi: 10.1109/JBHI.2020.3001216.
Joffer, J., Jerdén, L., Öhman, A., & Flacking, R. (2016). Exploring self-rated health among
adolescents: a think-aloud study. BMC Public Health, 16, 156. https://doi.org/10.1186/s12889016-2837-z

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 19 (33)

Knäuper, B., Carrière, K., Chamandy, M., Xu, Z., Schwarz, N., & Rosen, N. O. (2016). How aging
affects self-reports. European journal of ageing, 13(2), 185–193. https://doi.org/10.1007/s10433016-0369-0
Koskinen, S., Lundqvist, A., & Ristiluoma, N. (eds.) (2012). Health, functional capacity and welfare
in Finland in 2011. National Institute for Health and Welfare in Finland (THL), Report 68/2012.
290 pages. Helsinki, Finland, 2012. ISBN 978-952-245-768-4 (printed), ISBN 978-952-245-7691 (online publication). A health questionnaire appendix "Terveys 2011, tutkimus suomalaisten
terveydestä
ja
toimintakyvystä,
terveyskysely",
form
T4095,
https://thl.fi/documents/10531/2797097/T4095_terveyskysely.pdf
Kulikowski, K. (2018). Measurement of work engagement with single-item measure. Polish
Psychological Bulletin2018, vol. 49(4) 406–415. DOI - 10.24425/119509
Lahti, Lauri (2017). Interpretation of health-related expressions and dialogues: enabling personalized
care with contextual measuring and machine learning. International Journal of New Technology
and Research (IJNTR), Volume 3, Issue 11, November 2017, pages 171-179, ISSN 2454-4116.
https://www.ijntr.org/download_data/IJNTR03110081.pdf and http://urn.fi/URN:NBN:fi:aalto201712298340
Lahti, Lauri (2018). Supporting care by interpretation of expressions about patient experience with
machine learning. International Journal of New Technology and Research (IJNTR). Volume 4,
Issue 12, December 2018, pages 27-34. ISSN 2454-4116. DOI: 10.31871/IJNTR.4.12.16.
https://www.ijntr.org/download_data/IJNTR04120016.pdf and http://urn.fi/URN:NBN:fi:aalto201812015463
Lahti, Lauri (2020). Interpretation of the patient’s need for help can be supported with machine
learning. In Mansnérus, Juli, Lahti, Raimo, & Blick, Amanda (eds.), Personalized medicine: legal
and ethical challenges. Faculty of Law, University of Helsinki, Finland, Forum Iuris Series,
Helsinki, 2020. ISBN 978-951-51-6940-2 (printed), ISBN 978-951-51-5021-9 (pdf), ISSN 26701219. DOI: 10.31885/9789515150219
Lahti, Lauri, Tenhunen, Henni, & Nieminen, Marko (2018). How patients talk about care? Identifying
patient experience expressions from online discussions. Proc. Medical Informatics Europe (MIE
2018), 24-26 April 2018, Gothenburg, Sweden (eds. Ugon, A., Karlsson, D., Klein, G., & Moen,
A.), 116-120. European Federation for Medical Informatics (EFMI). ISBN 978-1-61499-851-8
(print) and ISBN 978-1-61499-852-5 (online). http://ebooks.iospress.nl/volumearticle/48765
Laranjo, L., Dunn, A., Tong, H., Kocaballi, A., Chen, J., Bashir, R., Surian, D., Gallego, B., Magrabi,
F., Lau, A., & Coiera, E. (2018). Conversational agents in healthcare: a systematic review. J Am
Med Inform Assoc. 2018 Sep 01;25(9):1248–1258. doi: 10.1093/jamia/ocy072.
http://europepmc.org/abstract/MED/30010941.
Lombrozo, T. (2007). Simplicity and probability in causal explanation. Cognitive Psychology, 55,
232-257.
Mauss, I. B., & Robinson, M. D. (2009). Measures of emotion: A review. Cognition & emotion,
23(2), 209–237. https://doi.org/10.1080/02699930802204677
McNorgan, C. (2012). A meta-analytic review of multisensory imagery identifies the neural correlates
of modality-specific and modality-general imagery. Frontiers in Human Neuroscience, 6, Article
285. DOI: 10.3389/fnhum.2012.00285
National Institute for Health and Welfare in Finland (2020). Web pages offering guidelines about
coronavirus (COVID-19) disease. When to seek admission for care and guidance concerning the
symptoms and care. Published in Finnish. Terveyden ja hyvinvoinnin laitos (THL).
https://thl.fi/fi/web/infektiotaudit-ja-rokotukset/taudit-ja-torjunta/taudit-ja-taudinaiheuttajat-ao/koronavirus-covid-19/koronavirustauti-milloin-on-hakeuduttava-hoitoon;
https://thl.fi/fi/web/infektiotaudit-ja-rokotukset/ajankohtaista/ajankohtaista-koronaviruksestacovid-19/oireet-ja-hoito-koronavirus/koronaviruksen-hoito-ja-ohjeet-sairastuneelle;
https://thl.fi/fi/web/infektiotaudit-ja-rokotukset/ajankohtaista/ajankohtaista-koronaviruksestacovid-19/oireet-ja-hoito-koronavirus

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 20 (33)

Nosikov, A., & Gudex, C. (eds.) (2003). EUROHIS: Developing common instruments for health
surveys. World Health Organization (WHO) and IOS Press, Amsterdam, the Netherlands. 2003.
https://www.euro.who.int/__data/assets/pdf_file/0015/101193/WA9502003EU.pdf
Pearson, D., Deeprose, C., Wallace-Hadrill, S., Heyes, S.B., & Holmes, E. (2013). Assessing mental
imagery in clinical psychology: A review of imagery measures and a guiding framework. Clinical
Psychology Review, Volume 33,
Issue 1, February
2013, Pages 1-23.
https://doi.org/10.1016/j.cpr.2012.09.001
Qing, L., Linhong, W., & Xuehai, D. (2019). A Novel Neural Network-Based Method for Medical
Text Classification. Future Internet2019,11, 255; doi:10.3390/fi11120255.
Rojas-Barahona, L., Tseng. B., Dai, Y., Mansfield, C., Ramadan, O., Ultes, S., Crawford, M., &
Gašić, M. (2018). Deep Learning for Language Understanding of Mental Health Concepts Derived
from Cognitive Behavioural Therapy. Proceedings of the Ninth International Workshop on Health
Text Mining and Information Analysis, 2018, doi:10.18653/v1/w18–5606.
Schalet, B. D., Revicki, D. A., Cook, K. F., Krishnan, E., Fries, J. F., & Cella, D. (2015). Establishing
a Common Metric for Physical Function: Linking the HAQ-DI and SF-36 PF Subscale to PROMIS
Physical Function. Journal of general internal medicine, 30(10), 1517–1523.
https://doi.org/10.1007/s11606-015-3360-0
Sherman, S.J., Cialdini, R.B., Schwartzman, D.F., & Reynolds, K.D. (1985). Imagining can heighten
or lower the perceived likelihood of contracting a disease: the mediating effect of ease of imagery.
Personality and Social Psychology Bulletin, 11 (1) (1985), pp. 118-127.
Shickel, B., Siegel, S., Heesacker, M., Benton, S., & Rashidi, P. (2019). Automatic detection and
classification of cognitive distortions in mental health text. Research article manuscript published
on 23 September 2019 at https://arxiv.org/abs/1909.07502
Siegel, Josh & van Dolen, Willemijn. (2020). Child helplines: Exploring determinants and boundary
conditions of volunteer encounter satisfaction. Journal of Services Marketing. 10.1108/JSM-052019-0200.
Sinclair, S., Jaggi, P., Hack, T.F., Russell, L., McClement, S., Cuthbertson, L., Selman, L. & Leget,
C. (2020). Initial Validation of a Patient-Reported Measure of Compassion: Determining the
Content Validity and Clinical Sensibility among Patients Living with a Life-Limiting and
Incurable Illness. Patient 13, 327–337 (2020). https://doi.org/10.1007/s40271-020-00409-8
Sinclair, S., Jaggi, P., Hack, T.F., McClement, S.E., & Cuthbertson, L.A. (2020). Practical Guide for
Item Generation in Measure Development: Insights From the Development of a Patient-Reported
Experience Measure of Compassion. J Nurs Meas. 2020 Mar 16:JNM-D-19-00020. doi:
10.1891/JNM-D-19-00020. Epub ahead of print. PMID: 32179717.
Sullivan, M., Bishop, S., & Pivik, J. (1995). The Pain Catastrophizing Scale: Development and
Validation. Psychological Assessment1995, Vol. 7, No. 4, 524-53.
TensorFlow image classification tutorial (2020). TensorFlow image classification tutorial with
Python
language
scripts.
https://www.tensorflow.org/tutorials/images/classification;
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb;
https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D
Tolvanen, E., Koskela, T. H., & Kosunen, E. (2019). Comparison of the Patient Enablement
Instrument (PEI) with two single-item measures among Finnish Health care centre patients. BMC
health services research, 19(1), 376. https://doi.org/10.1186/s12913-019-4182-2
Tucker, C. A., Escorpizo, R., Cieza, A., Lai, J. S., Stucki, G., Ustun, T. B., Kostanjsek, N., Cella, D.,
& Forrest, C. B. (2014). Mapping the content of the Patient-Reported Outcomes Measurement
Information System (PROMIS®) using the International Classification of Functioning, Health and
Disability. Quality of life research: an international journal of quality of life aspects of treatment,
care and rehabilitation, 23(9), 2431–2438. https://doi.org/10.1007/s11136-014-0691-y
Warriner, A., Kuperman, V., & Brysbaert, M. (2013). Norms of valence, arousal, and dominance for
13,915 English lemmas. Behav Res Methods. 2013 Dec; 45(4):1191-207.
http://link.springer.com/article/10.3758/s13428-012-0314-x

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org. 21 (33)

World Health Organization (2020). Coronavirus. A web page offering guidelines about coronavirus
(COVID-19) disease. World Health Organization (WHO). https://www.who.int/healthtopics/coronavirus
Wu, S., Wang, R., Zhao, Y., Ma, X., Wu, M., Yan, X., & He, J. (2013). The relationship between
self-rated health and objective health status: a population-based study. BMC Public Health, 13,
320. https://doi.org/10.1186/1471-2458-13-320
Yao, L., Mao, C. & Luo, Y. (2019). Clinical text classification with rule-based features and
knowledge-guided convolutional neural networks. BMC Med Inform Decis Mak 19, 71 (2019).
https://doi.org/10.1186/s12911-019-0781-4
Zhao, X., Miao, C., & Xing. Z. (2017). Identifying Cognitive Distortion by Convolutional Neural
Network based Text Classification. International Journal of Information Technology, Vol. 23, No.
12017.
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

22 (33)

Appendix A for the research article "Detecting the patient’s need for help with machine learning"
Lauri Lahti, Department of Computer Science, Aalto University, Finland, lauri.lahti@aalto.fi, 20201224

Table A1. Kendall rank-correlation and cosine similarity measures for each comparable pair of parameter values of the "need for help" ratings of expression statements ES1-ES20 and the
answers of the background questions BQ1 and BQ5-BQ7 (n=673).
Kendall rank-correlation measures are shown on the upper-right region of the table and cosine similarity measures are shown on the lower-left region of the table.
Before computing cosine similarity measures the answer values of each parameter were normalized by the formula (x - min(x))/(max(x)-min(x)) and then these new values were shifted so that the mean
value was positioned to the zero by the formula (x - mean(x)). The statistical significance levels were defined as p<0,05, p<0,01 and p<0,001, denoted by symbols *, ** and ***, respectively.
ES1
ES1
ES2
ES3
ES4
ES5
ES6
ES7
ES8
ES9
ES10
ES11
ES12
ES13
ES14
ES15
ES16
ES17
ES18
ES19
ES20
BQ1
BQ5
BQ6
BQ7

0.80
0.44
0.35
0.60
0.45
0.43
0.33
0.27
0.27
0.20
0.25
0.27
0.27
0.26
0.27
0.26
0.31
0.43
0.13
0.00
-0.03
-0.04
-0.03

ES2
0.73***
0.65
0.52
0.73
0.54
0.59
0.49
0.44
0.43
0.24
0.37
0.36
0.41
0.38
0.39
0.39
0.41
0.48
-0.01
0.01
0.00
-0.02
-0.03

ES3
0.40***
0.56***
0.83
0.62
0.43
0.71
0.73
0.70
0.71
0.27
0.55
0.46
0.69
0.70
0.60
0.62
0.58
0.53
-0.31
0.03
0.08
0.00
0.01

ES4
0.32***
0.43***
0.67***
0.62
0.49
0.74
0.78
0.76
0.76
0.31
0.58
0.51
0.70
0.69
0.64
0.65
0.61
0.57
-0.35
-0.04
0.02
-0.08
-0.09

ES5
0.55***
0.64***
0.52***
0.50***
0.66
0.75
0.65
0.60
0.58
0.34
0.48
0.46
0.49
0.48
0.55
0.55
0.57
0.57
-0.06
0.03
0.02
0.00
-0.01

ES6
0.40***
0.45***
0.34***
0.38***
0.57***
0.57
0.43
0.40
0.36
0.28
0.33
0.37
0.34
0.30
0.35
0.35
0.37
0.50
0.04
-0.15
-0.11
-0.15
-0.15

ES7
0.40***
0.51***
0.56***
0.57***
0.65***
0.49***
0.87
0.78
0.77
0.35
0.59
0.52
0.62
0.63
0.68
0.69
0.67
0.59
-0.23
0.08
0.08
0.04
0.00

ES8
0.33***
0.43***
0.55***
0.59***
0.57***
0.40***
0.75***
0.87
0.86
0.36
0.64
0.58
0.69
0.71
0.75
0.77
0.72
0.58
-0.36
0.11
0.11
0.07
0.03

ES9
0.26***
0.38***
0.51***
0.56***
0.51***
0.35***
0.62***
0.67***
0.92
0.37
0.64
0.57
0.69
0.71
0.79
0.81
0.78
0.58
-0.40
0.10
0.13
0.06
0.03

ES10
0.26***
0.36***
0.51***
0.55***
0.49***
0.31***
0.61***
0.64***
0.79***
0.35
0.63
0.55
0.68
0.71
0.80
0.82
0.75
0.55
-0.42
0.09
0.12
0.05
0.03

ES11
0.16***
0.19***
0.20***
0.24***
0.26***
0.23***
0.27***
0.28***
0.28***
0.28***
0.66
0.60
0.38
0.36
0.44
0.42
0.44
0.42
-0.02
-0.09
-0.09
-0.11
-0.10

ES12
0.22***
0.30***
0.40***
0.43***
0.38***
0.26***
0.45***
0.47***
0.47***
0.47***
0.56***
0.77
0.69
0.67
0.66
0.66
0.65
0.55
-0.24
0.01
0.02
-0.02
-0.05

ES13
0.24***
0.30***
0.34***
0.38***
0.38***
0.30***
0.41***
0.45***
0.43***
0.42***
0.49***
0.65***
0.62
0.60
0.62
0.61
0.63
0.58
-0.17
0.01
0.02
-0.02
-0.04

ES14
0.23***
0.32***
0.51***
0.52***
0.38***
0.25***
0.46***
0.49***
0.49***
0.48***
0.32***
0.57***
0.51***
0.95
0.70
0.70
0.67
0.55
-0.36
0.00
0.03
-0.02
-0.07

ES15
0.22***
0.31***
0.52***
0.53***
0.38***
0.24***
0.47***
0.51***
0.51***
0.52***
0.31***
0.54***
0.49***
0.86***
0.72
0.71
0.68
0.52
-0.37
0.04
0.05
0.01
-0.02

ES16
0.24***
0.31***
0.43***
0.45***
0.45***
0.28***
0.53***
0.55***
0.61***
0.64***
0.35***
0.51***
0.49***
0.51***
0.54***
0.97
0.90
0.62
-0.36
0.05
0.09
0.03
0.00

ES17
0.23***
0.30***
0.43***
0.44***
0.44***
0.27***
0.53***
0.55***
0.60***
0.65***
0.33***
0.50***
0.47***
0.49***
0.52***
0.91***
0.89
0.62
-0.36
0.07
0.10
0.03
0.00

ES18
0.28***
0.34***
0.43***
0.44***
0.47***
0.30***
0.54***
0.54***
0.63***
0.60***
0.35***
0.51***
0.50***
0.50***
0.52***
0.78***
0.77***
0.70
-0.28
0.06
0.09
0.03
0.00

ES19
0.36***
0.40***
0.41***
0.44***
0.47***
0.40***
0.49***
0.46***
0.46***
0.43***
0.33***
0.43***
0.47***
0.42***
0.40***
0.50***
0.49***
0.58***
-0.15
-0.08
-0.05
-0.11
-0.11

ES20
0.16***
0.07*
-0.13***
-0.13***
0.05
0.12***
-0.06*
-0.13***
-0.18***
-0.21***
0.06*
-0.09**
-0.02
-0.16***
-0.18***
-0.14***
-0.15***
-0.07*
0.03
0.03
-0.01
0.04
0.02

BQ1
-0.01
0.00
0.03
0.01
0.02
-0.11***
0.05
0.08**
0.07*
0.07*
-0.08**
0.01
0.00
0.02
0.04
0.04
0.05
0.04
-0.06
-0.01
0.75
0.82
0.70

BQ5
-0.01
0.00
0.06*
0.04
0.02
-0.10***
0.05
0.07*
0.10***
0.10***
-0.07*
0.01
0.01
0.04
0.05
0.07*
0.07*
0.06
-0.05
-0.05
0.63***
0.80
0.71

BQ6
-0.03
-0.01
0.01
-0.03
0.01
-0.11***
0.03
0.04
0.05
0.05
-0.10***
-0.02
-0.02
0.00
0.01
0.02
0.02
0.02
-0.07*
0.00
0.71***
0.68***
0.77

BQ7
-0.03
-0.03
0.01
-0.04
-0.02
-0.11***
-0.01
0.01
0.02
0.02
-0.10**
-0.05
-0.04
-0.04
-0.02
-0.01
-0.01
-0.02
-0.08**
-0.02
0.57***
0.58***
0.63***

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

23 (33)

Table A2. The mean values of the “need for help” ratings of each expression statement (ES1-ES20) in respect to groupings based on the answer values of the background question (BQ), for
two groups or three groups.
M1, M2 and M3 show the mean values for each group and the number of persons is denoted by n1, n2 and n3 (n=673). We computed Wilcoxon rank-sum test (i.e., Mann–Whitney U test) between two
groups to identify statistically significant rating differences at significance levels p<0,05, p<0,01 and p<0,001, denoted by symbols *, ** and ***, respectively.
Grouping based on the
answer value of the
background question
BQ1, two groups: x<7
(n1=263), x>=7 (n2=410)
BQ1, three groups: x<6 (n1=
218), 6<=x<8 (n2=207), x>=8
(n3=248)
BQ2, two groups: x<2
(n1=219), x>=2 (n2=454)
BQ4, two groups: x<2
(n1=364), x>=2 (n2=309)
BQ5, two groups: x<7
(n1=274), x>=7 (n2=399)
BQ5, three groups: x<6
(n1=190), 6<=x<8 (n2=271),
x>=8 (n3=212)
BQ6, two groups: x<7
(n1=318), x>=7 (n2=355)
BQ6, three groups: x<6
(n1=240), 6<=x<8 (n2=229),
x>=8 (n3=204)
BQ7, two groups: x<7
(n1=201), x>=7 (n2=472)
BQ7, three groups: x<6
(n1=143), 6<=x<8 (n2=214),
x>=8 (n3=316)

ES1

ES2

ES3

ES4

ES5

ES6

ES7

ES8

ES9

ES10

ES11

ES12

ES13

ES14

ES15

ES16

ES17

ES18

ES19

ES20

M1=0.247
M2=0.243
M1=0.238
M2=0.256
M3=0.241
M1=0.253
M2=0.241
M1=0.249
M2=0.239
M1=0.252
M2=0.239
M1=0.242
M2=0.257
M3=0.232
M1=0.247
M2=0.243
M1=0.256
M2=0.241
M3=0.235
M1=0.262
M2=0.237
M1=0.243
M2=0.250
M3=0.241

M1=0.282
M2=0.286
M1=0.271
M2=0.307
M3=0.278
M1=0.300
M2=0.277
M1=0.290
M2=0.278
M1=0.287
M2=0.283
M1=0.273
M2=0.296
M3=0.280
M1=0.280
M2=0.289
M1=0.285
M2=0.286
M3=0.282
M1=0.300
M2=0.278
M1=0.281
M2=0.291
M3=0.282

M1=0.523
M2=0.553
M1=0.522
M2=0.550
M3=0.552
M1=0.583
M2=0.521 *
M1=0.549
M2=0.533
M1=0.521
M2=0.556
M1=0.496
M2=0.554
M3=0.567
M1=0.536
M2=0.546
M1=0.531
M2=0.549
M3=0.545
M1=0.550
M2=0.538
M1=0.520
M2=0.549
M3=0.547

M1=0.612
M2=0.604
M1=0.622
M2=0.600
M3=0.601
M1=0.622
M2=0.600
M1=0.615
M2=0.599
M1=0.603
M2=0.611
M1=0.594
M2=0.606
M3=0.621
M1=0.621
M2=0.595
M1=0.628
M2=0.598
M3=0.594
M1=0.657
M2=0.586
M1=0.659
M2=0.597
M3=0.591

M1=0.267
M2=0.292
M1=0.264
M2=0.312
M3=0.273 *
M1=0.288
M2=0.279
M1=0.285
M2=0.279
M1=0.274
M2=0.288
M1=0.262
M2=0.304
M3=0.273
M1=0.280
M2=0.284
M1=0.270
M2=0.293
M3=0.284
M1=0.287
M2=0.280
M1=0.278
M2=0.292
M3=0.278

M1=0.421
M2=0.353 ***
M1=0.422
M2=0.383
M3=0.339 **
M1=0.337
M2=0.400 **
M1=0.354
M2=0.409 **
M1=0.415
M2=0.355 **
M1=0.412
M2=0.389
M3=0.338 **
M1=0.409
M2=0.353 **
M1=0.414
M2=0.374
M3=0.345 *
M1=0.434
M2=0.356 ***
M1=0.432
M2=0.393
M3=0.347 **

M1=0.370
M2=0.422 *
M1=0.370
M2=0.414
M3=0.418
M1=0.421
M2=0.392
M1=0.413
M2=0.388
M1=0.378
M2=0.417
M1=0.362
M2=0.414
M3=0.420
M1=0.387
M2=0.414
M1=0.381
M2=0.401
M3=0.425
M1=0.405
M2=0.400
M1=0.400
M2=0.400
M3=0.403

M1=0.497
M2=0.577 **
M1=0.493
M2=0.567
M3=0.575 *
M1=0.580
M2=0.529
M1=0.570
M2=0.517
M1=0.510
M2=0.570
M1=0.476
M2=0.565
M3=0.583 *
M1=0.522
M2=0.567
M1=0.506
M2=0.565
M3=0.571
M1=0.536
M2=0.550
M1=0.520
M2=0.550
M3=0.554

M1=0.511
M2=0.594 **
M1=0.506
M2=0.584
M3=0.591 *
M1=0.615
M2=0.536
M1=0.580
M2=0.540
M1=0.515
M2=0.593 **
M1=0.478
M2=0.571
M3=0.624 ***
M1=0.541
M2=0.580
M1=0.523
M2=0.580
M3=0.586
M1=0.541
M2=0.570
M1=0.528
M2=0.567
M3=0.573

M1=0.552
M2=0.640 **
M1=0.551
M2=0.624
M3=0.638
M1=0.660
M2=0.579
M1=0.633
M2=0.574
M1=0.555
M2=0.640 **
M1=0.520
M2=0.614
M3=0.671 ***
M1=0.592
M2=0.618
M1=0.573
M2=0.616
M3=0.632
M1=0.590
M2=0.613
M1=0.589
M2=0.599
M3=0.618

M1=0.464
M2=0.414
M1=0.465
M2=0.457
M3=0.386 *
M1=0.378
M2=0.461 ***
M1=0.408
M2=0.464 *
M1=0.470
M2=0.409 *
M1=0.461
M2=0.441
M3=0.400
M1=0.478
M2=0.394 ***
M1=0.470
M2=0.443
M3=0.380 **
M1=0.484
M2=0.412 **
M1=0.487
M2=0.460
M3=0.392 **

M1=0.440
M2=0.454
M1=0.437
M2=0.463
M3=0.448
M1=0.463
M2=0.442
M1=0.464
M2=0.431
M1=0.441
M2=0.454
M1=0.419
M2=0.472
M3=0.446
M1=0.448
M2=0.450
M1=0.439
M2=0.465
M3=0.443
M1=0.466
M2=0.442
M1=0.457
M2=0.459
M3=0.438

M1=0.605
M2=0.625
M1=0.616
M2=0.604
M3=0.628
M1=0.655
M2=0.599 *
M1=0.630
M2=0.601
M1=0.598
M2=0.630
M1=0.589
M2=0.617
M3=0.641
M1=0.620
M2=0.614
M1=0.616
M2=0.611
M3=0.625
M1=0.655
M2=0.601
M1=0.648
M2=0.621
M3=0.600

M1=0.584
M2=0.629
M1=0.593
M2=0.601
M3=0.635
M1=0.663
M2=0.587 *
M1=0.635
M2=0.583
M1=0.584
M2=0.630
M1=0.562
M2=0.619
M3=0.646
M1=0.609
M2=0.614
M1=0.595
M2=0.610
M3=0.631
M1=0.622
M2=0.607
M1=0.609
M2=0.627
M3=0.602

M1=0.460
M2=0.521 *
M1=0.469
M2=0.514
M3=0.509
M1=0.534
M2=0.480
M1=0.512
M2=0.480
M1=0.459
M2=0.523 *
M1=0.435
M2=0.517
M3=0.528 *
M1=0.486
M2=0.508
M1=0.480
M2=0.503
M3=0.511
M1=0.492
M2=0.500
M1=0.494
M2=0.503
M3=0.495

M1=0.484
M2=0.560 *
M1=0.488
M2=0.558
M3=0.546
M1=0.573
M2=0.511
M1=0.551
M2=0.507
M1=0.491
M2=0.558 *
M1=0.467
M2=0.546
M3=0.568 *
M1=0.519
M2=0.542
M1=0.513
M2=0.540
M3=0.542
M1=0.533
M2=0.530
M1=0.536
M2=0.529
M3=0.530

M1=0.385
M2=0.439 *
M1=0.385
M2=0.442
M3=0.426
M1=0.448
M2=0.403
M1=0.428
M2=0.405
M1=0.391
M2=0.436
M1=0.373
M2=0.431
M3=0.440
M1=0.412
M2=0.422
M1=0.403
M2=0.420
M3=0.432
M1=0.419
M2=0.417
M1=0.410
M2=0.431
M3=0.411

M1=0.396
M2=0.370
M1=0.400
M2=0.392
M3=0.352
M1=0.369
M2=0.386
M1=0.373
M2=0.389
M1=0.404
M2=0.364
M1=0.402
M2=0.381
M3=0.360
M1=0.403
M2=0.360
M1=0.405
M2=0.373
M3=0.360
M1=0.427
M2=0.360 **
M1=0.420
M2=0.382
M3=0.361

M1=0.257
M2=0.261
M1=0.246
M2=0.279
M3=0.255
M1=0.233
M2=0.272
M1=0.252
M2=0.268
M1=0.255
M2=0.262
M1=0.265
M2=0.279
M3=0.230 *
M1=0.250
M2=0.268
M1=0.258
M2=0.251
M3=0.270
M1=0.259
M2=0.259
M1=0.248
M2=0.269
M3=0.258

BQ8, two groups: x<2
(n1=123), x>=2 (n2=550)

M1=0.241
M2=0.245

M1=0.269
M2=0.288

M1=0.460
M2=0.560 **

M1=0.516
M2=0.628 ***

M1=0.284
M2=0.282

M1=0.390
M2=0.377

M1=0.359
M2=0.411

M1=0.474
M2=0.562 *

M1=0.477
M2=0.580 *

M1=0.509
M2=0.627 **

M1=0.367
M2=0.449 **

M1=0.389
M2=0.462 *

M1=0.454
M2=0.653 ***

M1=0.447
M2=0.648 ***

M1=0.420
M2=0.515 *

M1=0.454
M2=0.548 *

M1=0.355
M2=0.431 *

M1=0.354
M2=0.386

M1=0.257
M2=0.260

BQ9, two groups: x<51
(n1=333), x>=51 (n2=340)
BQ9, three groups: x<40
(n1=225), 40<=x<60 (n2=231),
x>=60 (n3=217)

M1=0.288
M2=0.202 ***
M1=0.301
M2=0.229
M3=0.203 ***

M1=0.333
M2=0.237 ***
M1=0.347
M2=0.276
M3=0.229 ***

M1=0.606
M2=0.479 ***
M1=0.618
M2=0.553
M3=0.450 ***

M1=0.659
M2=0.557 ***
M1=0.655
M2=0.639
M3=0.525 ***

M1=0.320
M2=0.245 ***
M1=0.321
M2=0.287
M3=0.236 ***

M1=0.394
M2=0.365
M1=0.391
M2=0.388
M3=0.359

M1=0.430
M2=0.373 *
M1=0.434
M2=0.423
M3=0.344 **

M1=0.592
M2=0.501 *
M1=0.597
M2=0.571
M3=0.465 *

M1=0.598
M2=0.526
M1=0.606
M2=0.568
M3=0.507

M1=0.655
M2=0.557
M1=0.659
M2=0.639
M3=0.515 *

M1=0.410
M2=0.457 *
M1=0.374
M2=0.471
M3=0.456 **

M1=0.465
M2=0.495
M1=0.473
M2=0.492
M3=0.485
M1=0.477
M2=0.487
M1=0.481
M2=0.486
M1=0.477
M2=0.487
M1=0.464
M2=0.495
M3=0.486
M1=0.489
M2=0.479
M1=0.483
M2=0.491
M3=0.475
M1=0.513
M2=0.471
M1=0.505
M2=0.498
M3=0.464
M1=0.376
M2=0.507
***
M1=0.491
M2=0.476
M1=0.467
M2=0.511
M3=0.471

M1=0.477
M2=0.422 *
M1=0.480
M2=0.437
M3=0.429

M1=0.686
M2=0.549 ***
M1=0.691
M2=0.639
M3=0.517 ***

M1=0.684
M2=0.540 ***
M1=0.692
M2=0.628
M3=0.510 ***

M1=0.508
M2=0.487
M1=0.502
M2=0.506
M3=0.484

M1=0.547
M2=0.515
M1=0.545
M2=0.540
M3=0.506

M1=0.422
M2=0.414
M1=0.419
M2=0.409
M3=0.425

M1=0.402
M2=0.359 *
M1=0.411
M2=0.378
M3=0.351 *

M1=0.241
M2=0.277
M1=0.240
M2=0.231
M3=0.309 *

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

24 (33)

Table A3. The median values of the “need for help” ratings of each expression statement (ES1-ES20) in respect to groupings based on the answer values of the background question (BQ), for
two groups or three groups.
Mdn1, Mdn2 and Mdn3 show the median values for each group and the number of persons is denoted by n1, n2 and n3 (n=673).
Grouping based on the answer
value of the background
question
BQ1, two groups: x<7
(n1=263), x>=7 (n2=410)
BQ1, three groups: x<6 (n1=
218), 6<=x<8 (n2=207), x>=8
(n3=248)
BQ2, two groups: x<2
(n1=219), x>=2 (n2=454)
BQ4, two groups: x<2
(n1=364), x>=2 (n2=309)
BQ5, two groups: x<7
(n1=274), x>=7 (n2=399)
BQ5, three groups: x<6
(n1=190), 6<=x<8 (n2=271),
x>=8 (n3=212)
BQ6, two groups: x<7
(n1=318), x>=7 (n2=355)
BQ6, three groups: x<6
(n1=240), 6<=x<8 (n2=229),
x>=8 (n3=204)
BQ7, two groups: x<7
(n1=201), x>=7 (n2=472)
BQ7, three groups: x<6
(n1=143), 6<=x<8 (n2=214),
x>=8 (n3=316)
BQ8, two groups: x<2
(n1=123), x>=2 (n2=550)
BQ9, two groups: x<51
(n1=333), x>=51 (n2=340)
BQ9, three groups: x<40
(n1=225), 40<=x<60 (n2=231),
x>=60 (n3=217)

ES1

ES2

ES3

ES4

ES5

ES6

ES7

ES8

ES9

ES10

ES11

ES12

ES13

ES14

ES15

ES16

ES17

ES18

ES19

ES20

Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn3=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn3=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn3=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn3=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.2
Mdn1=0.3
Mdn2=0.2
Mdn3=0.1

Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.25
Mdn1=0.3
Mdn2=0.2
Mdn1=0.3
Mdn2=0.2
Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.2
Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.2
Mdn1=0.3
Mdn2=0.2
Mdn1=0.2
Mdn2=0.3
Mdn3=0.2
Mdn1=0.2
Mdn2=0.25
Mdn1=0.3
Mdn2=0.2
Mdn1=0.3
Mdn2=0.2
Mdn3=0.2

Mdn1=0.6
Mdn2=0.7
Mdn1=0.6
Mdn2=0.7
Mdn3=0.65
Mdn1=0.7
Mdn2=0.6
Mdn1=0.65
Mdn2=0.6
Mdn1=0.6
Mdn2=0.7
Mdn1=0.55
Mdn2=0.7
Mdn3=0.7
Mdn1=0.6
Mdn2=0.7
Mdn1=0.6
Mdn2=0.6
Mdn3=0.65
Mdn1=0.6
Mdn2=0.6
Mdn1=0.6
Mdn2=0.65
Mdn3=0.65
Mdn1=0.5
Mdn2=0.7
Mdn1=0.7
Mdn2=0.5
Mdn1=0.7
Mdn2=0.7
Mdn3=0.5

Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn3=0.7
Mdn1=0.6
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.8
Mdn3=0.6

Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.2
Mdn1=0.3
Mdn2=0.2
Mdn1=0.3
Mdn2=0.2
Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.2
Mdn1=0.2
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.3
Mdn1=0.3
Mdn2=0.3
Mdn1=0.2
Mdn2=0.3
Mdn3=0.25
Mdn1=0.2
Mdn2=0.3
Mdn1=0.3
Mdn2=0.2
Mdn1=0.3
Mdn2=0.2
Mdn3=0.2

Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.3
Mdn2=0.4
Mdn1=0.3
Mdn2=0.4
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3

Mdn1=0.3
Mdn2=0.5
Mdn1=0.3
Mdn2=0.5
Mdn3=0.45
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.4
Mdn1=0.3
Mdn2=0.4
Mdn1=0.3
Mdn2=0.5
Mdn3=0.4
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.4
Mdn3=0.5
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.5
Mdn3=0.4
Mdn1=0.3
Mdn2=0.4
Mdn1=0.5
Mdn2=0.4
Mdn1=0.5
Mdn2=0.4
Mdn3=0.3

Mdn1=0.6
Mdn2=0.7
Mdn1=0.6
Mdn2=0.7
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.6
Mdn2=0.7
Mdn1=0.6
Mdn2=0.8
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.6
Mdn2=0.7
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.6
Mdn2=0.7
Mdn3=0.7
Mdn1=0.6
Mdn2=0.7
Mdn1=0.7
Mdn2=0.6
Mdn1=0.7
Mdn2=0.7
Mdn3=0.6

Mdn1=0.6
Mdn2=0.8
Mdn1=0.6
Mdn2=0.8
Mdn3=0.75
Mdn1=0.8
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.8
Mdn1=0.55
Mdn2=0.8
Mdn3=0.8
Mdn1=0.7
Mdn2=0.7
Mdn1=0.6
Mdn2=0.8
Mdn3=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.6
Mdn2=0.8
Mdn3=0.7
Mdn1=0.5
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn1=0.7
Mdn2=0.7
Mdn3=0.7

Mdn1=0.8
Mdn2=0.8
Mdn1=0.7
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.7
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.6
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.7

Mdn1=0.5
Mdn2=0.4
Mdn1=0.5
Mdn2=0.4
Mdn3=0.3
Mdn1=0.3
Mdn2=0.5
Mdn1=0.35
Mdn2=0.5
Mdn1=0.5
Mdn2=0.4
Mdn1=0.5
Mdn2=0.4
Mdn3=0.3
Mdn1=0.5
Mdn2=0.3
Mdn1=0.5
Mdn2=0.4
Mdn3=0.3
Mdn1=0.5
Mdn2=0.4
Mdn1=0.5
Mdn2=0.5
Mdn3=0.3
Mdn1=0.3
Mdn2=0.4
Mdn1=0.4
Mdn2=0.5
Mdn1=0.3
Mdn2=0.5
Mdn3=0.5

Mdn1=0.5
Mdn2=0.6
Mdn1=0.5
Mdn2=0.6
Mdn3=0.5
Mdn1=0.5
Mdn2=0.5
Mdn1=0.5
Mdn2=0.6
Mdn1=0.5
Mdn2=0.5
Mdn1=0.5
Mdn2=0.5
Mdn3=0.5
Mdn1=0.55
Mdn2=0.5
Mdn1=0.5
Mdn2=0.5
Mdn3=0.5
Mdn1=0.6
Mdn2=0.5
Mdn1=0.6
Mdn2=0.6
Mdn3=0.5
Mdn1=0.3
Mdn2=0.6
Mdn1=0.5
Mdn2=0.5
Mdn1=0.5
Mdn2=0.6
Mdn3=0.5

Mdn1=0.5
Mdn2=0.5
Mdn1=0.4
Mdn2=0.5
Mdn3=0.5
Mdn1=0.5
Mdn2=0.5
Mdn1=0.5
Mdn2=0.4
Mdn1=0.45
Mdn2=0.5
Mdn1=0.4
Mdn2=0.5
Mdn3=0.45
Mdn1=0.5
Mdn2=0.5
Mdn1=0.4
Mdn2=0.5
Mdn3=0.5
Mdn1=0.5
Mdn2=0.5
Mdn1=0.5
Mdn2=0.5
Mdn3=0.45
Mdn1=0.4
Mdn2=0.5
Mdn1=0.5
Mdn2=0.4
Mdn1=0.5
Mdn2=0.4
Mdn3=0.4

Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.5
Mdn2=0.8
Mdn1=0.8
Mdn2=0.7
Mdn1=0.8
Mdn2=0.8
Mdn3=0.5

Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.75
Mdn2=0.8
Mdn1=0.7
Mdn2=0.8
Mdn3=0.9
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.8
Mdn2=0.8
Mdn1=0.8
Mdn2=0.8
Mdn3=0.8
Mdn1=0.5
Mdn2=0.8
Mdn1=0.8
Mdn2=0.7
Mdn1=0.8
Mdn2=0.8
Mdn3=0.5

Mdn1=0.5
Mdn2=0.6
Mdn1=0.5
Mdn2=0.6
Mdn3=0.55
Mdn1=0.6
Mdn2=0.5
Mdn1=0.6
Mdn2=0.5
Mdn1=0.5
Mdn2=0.6
Mdn1=0.5
Mdn2=0.6
Mdn3=0.6
Mdn1=0.5
Mdn2=0.6
Mdn1=0.5
Mdn2=0.5
Mdn3=0.6
Mdn1=0.6
Mdn2=0.5
Mdn1=0.6
Mdn2=0.6
Mdn3=0.5
Mdn1=0.5
Mdn2=0.6
Mdn1=0.6
Mdn2=0.5
Mdn1=0.5
Mdn2=0.6
Mdn3=0.6

Mdn1=0.5
Mdn2=0.7
Mdn1=0.5
Mdn2=0.7
Mdn3=0.6
Mdn1=0.7
Mdn2=0.6
Mdn1=0.6
Mdn2=0.6
Mdn1=0.6
Mdn2=0.7
Mdn1=0.5
Mdn2=0.6
Mdn3=0.7
Mdn1=0.6
Mdn2=0.6
Mdn1=0.6
Mdn2=0.7
Mdn3=0.6
Mdn1=0.6
Mdn2=0.6
Mdn1=0.6
Mdn2=0.6
Mdn3=0.6
Mdn1=0.5
Mdn2=0.65
Mdn1=0.6
Mdn2=0.6
Mdn1=0.6
Mdn2=0.6
Mdn3=0.6

Mdn1=0.3
Mdn2=0.5
Mdn1=0.3
Mdn2=0.5
Mdn3=0.5
Mdn1=0.5
Mdn2=0.4
Mdn1=0.45
Mdn2=0.4
Mdn1=0.4
Mdn2=0.5
Mdn1=0.3
Mdn2=0.5
Mdn3=0.5
Mdn1=0.4
Mdn2=0.5
Mdn1=0.4
Mdn2=0.4
Mdn3=0.5
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.5
Mdn3=0.4
Mdn1=0.3
Mdn2=0.5
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.4
Mdn3=0.5

Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.4
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3
Mdn1=0.4
Mdn2=0.35
Mdn1=0.4
Mdn2=0.4
Mdn3=0.4
Mdn1=0.3
Mdn2=0.4
Mdn1=0.4
Mdn2=0.3
Mdn1=0.4
Mdn2=0.4
Mdn3=0.3

Mdn1=0.2
Mdn2=0.1
Mdn1=0.1
Mdn2=0.2
Mdn3=0.1
Mdn1=0.1
Mdn2=0.2
Mdn1=0.1
Mdn2=0.2
Mdn1=0.2
Mdn2=0.1
Mdn1=0.2
Mdn2=0.2
Mdn3=0.1
Mdn1=0.2
Mdn2=0.2
Mdn1=0.2
Mdn2=0.1
Mdn3=0.1
Mdn1=0.2
Mdn2=0.1
Mdn1=0.2
Mdn2=0.2
Mdn3=0.1
Mdn1=0.1
Mdn2=0.2
Mdn1=0.2
Mdn2=0.15
Mdn1=0.2
Mdn2=0.1
Mdn3=0.2

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

25 (33)

Table A4. The standard deviation values of the “need for help” ratings of each expression statement (ES1-ES20) in respect to groupings based on the answer values of the background
question (BQ), for two groups or three groups.
SD1, SD2 and SD3 show the standard deviation values for each group and the number of persons is denoted by n1, n2 and n3 (n=673).
Grouping based on the answer
value of the background
question
BQ1, two groups: x<7 (n1=263),
x>=7 (n2=410)
BQ1, three groups: x<6 (n1=
218), 6<=x<8 (n2=207), x>=8
(n3=248)
BQ2, two groups: x<2 (n1=219),
x>=2 (n2=454)
BQ4, two groups: x<2 (n1=364),
x>=2 (n2=309)
BQ5, two groups: x<7 (n1=274),
x>=7 (n2=399)
BQ5, three groups: x<6
(n1=190), 6<=x<8 (n2=271),
x>=8 (n3=212)
BQ6, two groups: x<7 (n1=318),
x>=7 (n2=355)
BQ6, three groups: x<6
(n1=240), 6<=x<8 (n2=229),
x>=8 (n3=204)
BQ7, two groups: x<7 (n1=201),
x>=7 (n2=472)
BQ7, three groups: x<6
(n1=143), 6<=x<8 (n2=214),
x>=8 (n3=316)
BQ8, two groups: x<2 (n1=123),
x>=2 (n2=550)
BQ9, two groups: x<51
(n1=333), x>=51 (n2=340)
BQ9, three groups: x<40
(n1=225), 40<=x<60 (n2=231),
x>=60 (n3=217)

ES1

ES2

ES3

ES4

ES5

ES6

ES7

ES8

ES9

ES10

ES11

ES12

ES13

ES14

ES15

ES16

ES17

ES18

ES19

ES20

SD1=0.22
SD2=0.21
SD1=0.22
SD2=0.21
SD3=0.21
SD1=0.21
SD2=0.22
SD1=0.21
SD2=0.22
SD1=0.23
SD2=0.21
SD1=0.24
SD2=0.21
SD3=0.21
SD1=0.22
SD2=0.21
SD1=0.23
SD2=0.21
SD3=0.21
SD1=0.22
SD2=0.21
SD1=0.22
SD2=0.22
SD3=0.21
SD1=0.23
SD2=0.21
SD1=0.22
SD2=0.2
SD1=0.22
SD2=0.21
SD3=0.21

SD1=0.23
SD2=0.22
SD1=0.23
SD2=0.23
SD3=0.22
SD1=0.22
SD2=0.23
SD1=0.22
SD2=0.23
SD1=0.23
SD2=0.22
SD1=0.24
SD2=0.22
SD3=0.22
SD1=0.23
SD2=0.22
SD1=0.23
SD2=0.23
SD3=0.22
SD1=0.23
SD2=0.23
SD1=0.23
SD2=0.22
SD3=0.23
SD1=0.25
SD2=0.22
SD1=0.22
SD2=0.22
SD1=0.22
SD2=0.22
SD3=0.22

SD1=0.32
SD2=0.34
SD1=0.32
SD2=0.33
SD3=0.34
SD1=0.31
SD2=0.34
SD1=0.33
SD2=0.33
SD1=0.32
SD2=0.34
SD1=0.33
SD2=0.32
SD3=0.34
SD1=0.32
SD2=0.34
SD1=0.32
SD2=0.33
SD3=0.34
SD1=0.31
SD2=0.34
SD1=0.32
SD2=0.31
SD3=0.35
SD1=0.33
SD2=0.33
SD1=0.31
SD2=0.35
SD1=0.29
SD2=0.34
SD3=0.34

SD1=0.29
SD2=0.34
SD1=0.29
SD2=0.32
SD3=0.36
SD1=0.32
SD2=0.32
SD1=0.32
SD2=0.33
SD1=0.3
SD2=0.34
SD1=0.3
SD2=0.32
SD3=0.34
SD1=0.3
SD2=0.34
SD1=0.29
SD2=0.32
SD3=0.36
SD1=0.28
SD2=0.34
SD1=0.27
SD2=0.32
SD3=0.35
SD1=0.32
SD2=0.32
SD1=0.29
SD2=0.34
SD1=0.28
SD2=0.33
SD3=0.35

SD1=0.24
SD2=0.24
SD1=0.25
SD2=0.24
SD3=0.23
SD1=0.21
SD2=0.25
SD1=0.23
SD2=0.25
SD1=0.24
SD2=0.24
SD1=0.25
SD2=0.24
SD3=0.23
SD1=0.25
SD2=0.23
SD1=0.24
SD2=0.24
SD3=0.23
SD1=0.24
SD2=0.24
SD1=0.24
SD2=0.25
SD3=0.23
SD1=0.26
SD2=0.23
SD1=0.23
SD2=0.24
SD1=0.22
SD2=0.24
SD3=0.25

SD1=0.26
SD2=0.24
SD1=0.26
SD2=0.24
SD3=0.23
SD1=0.22
SD2=0.26
SD1=0.23
SD2=0.26
SD1=0.26
SD2=0.24
SD1=0.26
SD2=0.24
SD3=0.23
SD1=0.25
SD2=0.24
SD1=0.26
SD2=0.23
SD3=0.24
SD1=0.26
SD2=0.24
SD1=0.26
SD2=0.25
SD3=0.23
SD1=0.26
SD2=0.24
SD1=0.24
SD2=0.26
SD1=0.24
SD2=0.25
SD3=0.25

SD1=0.31
SD2=0.3
SD1=0.31
SD2=0.3
SD3=0.3
SD1=0.28
SD2=0.32
SD1=0.3
SD2=0.32
SD1=0.31
SD2=0.3
SD1=0.32
SD2=0.3
SD3=0.3
SD1=0.31
SD2=0.3
SD1=0.31
SD2=0.3
SD3=0.31
SD1=0.31
SD2=0.31
SD1=0.31
SD2=0.31
SD3=0.31
SD1=0.31
SD2=0.3
SD1=0.28
SD2=0.33
SD1=0.28
SD2=0.31
SD3=0.33

SD1=0.37
SD2=0.36
SD1=0.37
SD2=0.36
SD3=0.36
SD1=0.34
SD2=0.38
SD1=0.35
SD2=0.38
SD1=0.37
SD2=0.36
SD1=0.38
SD2=0.37
SD3=0.35
SD1=0.37
SD2=0.36
SD1=0.37
SD2=0.36
SD3=0.36
SD1=0.36
SD2=0.37
SD1=0.36
SD2=0.37
SD3=0.36
SD1=0.38
SD2=0.36
SD1=0.33
SD2=0.39
SD1=0.33
SD2=0.36
SD3=0.39

SD1=0.39
SD2=0.38
SD1=0.39
SD2=0.39
SD3=0.38
SD1=0.36
SD2=0.4
SD1=0.38
SD2=0.4
SD1=0.39
SD2=0.38
SD1=0.4
SD2=0.39
SD3=0.37
SD1=0.39
SD2=0.39
SD1=0.39
SD2=0.38
SD3=0.39
SD1=0.38
SD2=0.39
SD1=0.38
SD2=0.39
SD3=0.39
SD1=0.4
SD2=0.38
SD1=0.36
SD2=0.41
SD1=0.35
SD2=0.38
SD3=0.43

SD1=0.42
SD2=0.41
SD1=0.42
SD2=0.42
SD3=0.4
SD1=0.38
SD2=0.43
SD1=0.4
SD2=0.43
SD1=0.42
SD2=0.41
SD1=0.42
SD2=0.42
SD3=0.39
SD1=0.42
SD2=0.41
SD1=0.42
SD2=0.41
SD3=0.41
SD1=0.41
SD2=0.42
SD1=0.42
SD2=0.41
SD3=0.42
SD1=0.42
SD2=0.41
SD1=0.38
SD2=0.44
SD1=0.37
SD2=0.4
SD3=0.45

SD1=0.32
SD2=0.3
SD1=0.32
SD2=0.3
SD3=0.3
SD1=0.29
SD2=0.31
SD1=0.31
SD2=0.31
SD1=0.32
SD2=0.3
SD1=0.32
SD2=0.31
SD3=0.3
SD1=0.32
SD2=0.3
SD1=0.31
SD2=0.31
SD3=0.3
SD1=0.31
SD2=0.31
SD1=0.32
SD2=0.31
SD3=0.3
SD1=0.32
SD2=0.3
SD1=0.3
SD2=0.31
SD1=0.29
SD2=0.32
SD3=0.31

SD1=0.35
SD2=0.34
SD1=0.35
SD2=0.33
SD3=0.34
SD1=0.33
SD2=0.35
SD1=0.34
SD2=0.35
SD1=0.35
SD2=0.34
SD1=0.36
SD2=0.33
SD3=0.34
SD1=0.35
SD2=0.33
SD1=0.36
SD2=0.33
SD3=0.34
SD1=0.35
SD2=0.34
SD1=0.35
SD2=0.33
SD3=0.34
SD1=0.34
SD2=0.34
SD1=0.32
SD2=0.36
SD1=0.31
SD2=0.35
SD3=0.37

SD1=0.32
SD2=0.32
SD1=0.33
SD2=0.31
SD3=0.32
SD1=0.31
SD2=0.33
SD1=0.32
SD2=0.32
SD1=0.33
SD2=0.32
SD1=0.33
SD2=0.32
SD3=0.31
SD1=0.33
SD2=0.32
SD1=0.33
SD2=0.32
SD3=0.32
SD1=0.32
SD2=0.32
SD1=0.32
SD2=0.32
SD3=0.32
SD1=0.32
SD2=0.32
SD1=0.31
SD2=0.33
SD1=0.3
SD2=0.32
SD3=0.34

SD1=0.37
SD2=0.38
SD1=0.37
SD2=0.37
SD3=0.39
SD1=0.38
SD2=0.38
SD1=0.38
SD2=0.38
SD1=0.37
SD2=0.38
SD1=0.38
SD2=0.37
SD3=0.39
SD1=0.37
SD2=0.39
SD1=0.37
SD2=0.38
SD3=0.39
SD1=0.35
SD2=0.39
SD1=0.35
SD2=0.37
SD3=0.4
SD1=0.38
SD2=0.37
SD1=0.35
SD2=0.4
SD1=0.33
SD2=0.38
SD3=0.4

SD1=0.39
SD2=0.4
SD1=0.39
SD2=0.39
SD3=0.4
SD1=0.38
SD2=0.4
SD1=0.39
SD2=0.4
SD1=0.39
SD2=0.4
SD1=0.4
SD2=0.39
SD3=0.4
SD1=0.39
SD2=0.4
SD1=0.39
SD2=0.39
SD3=0.4
SD1=0.38
SD2=0.4
SD1=0.38
SD2=0.38
SD3=0.41
SD1=0.39
SD2=0.39
SD1=0.36
SD2=0.41
SD1=0.35
SD2=0.4
SD3=0.42

SD1=0.37
SD2=0.36
SD1=0.38
SD2=0.36
SD3=0.36
SD1=0.34
SD2=0.38
SD1=0.36
SD2=0.38
SD1=0.37
SD2=0.36
SD1=0.38
SD2=0.36
SD3=0.36
SD1=0.37
SD2=0.37
SD1=0.38
SD2=0.36
SD3=0.37
SD1=0.37
SD2=0.37
SD1=0.37
SD2=0.38
SD3=0.36
SD1=0.38
SD2=0.36
SD1=0.33
SD2=0.4
SD1=0.32
SD2=0.36
SD3=0.42

SD1=0.38
SD2=0.37
SD1=0.39
SD2=0.38
SD3=0.37
SD1=0.35
SD2=0.39
SD1=0.37
SD2=0.39
SD1=0.38
SD2=0.37
SD1=0.39
SD2=0.37
SD3=0.37
SD1=0.38
SD2=0.38
SD1=0.39
SD2=0.36
SD3=0.38
SD1=0.38
SD2=0.38
SD1=0.38
SD2=0.38
SD3=0.37
SD1=0.4
SD2=0.37
SD1=0.34
SD2=0.41
SD1=0.33
SD2=0.37
SD3=0.43

SD1=0.32
SD2=0.31
SD1=0.32
SD2=0.32
SD3=0.31
SD1=0.3
SD2=0.33
SD1=0.31
SD2=0.33
SD1=0.32
SD2=0.31
SD1=0.33
SD2=0.31
SD3=0.31
SD1=0.32
SD2=0.32
SD1=0.33
SD2=0.31
SD3=0.32
SD1=0.32
SD2=0.32
SD1=0.31
SD2=0.33
SD3=0.32
SD1=0.33
SD2=0.31
SD1=0.29
SD2=0.35
SD1=0.28
SD2=0.31
SD3=0.37

SD1=0.27
SD2=0.27
SD1=0.28
SD2=0.26
SD3=0.27
SD1=0.26
SD2=0.28
SD1=0.26
SD2=0.28
SD1=0.27
SD2=0.27
SD1=0.28
SD2=0.27
SD3=0.26
SD1=0.27
SD2=0.27
SD1=0.27
SD2=0.26
SD3=0.28
SD1=0.27
SD2=0.27
SD1=0.26
SD2=0.27
SD3=0.27
SD1=0.28
SD2=0.27
SD1=0.25
SD2=0.29
SD1=0.24
SD2=0.26
SD3=0.3

SD1=0.27
SD2=0.3
SD1=0.27
SD2=0.29
SD3=0.3
SD1=0.27
SD2=0.29
SD1=0.29
SD2=0.29
SD1=0.26
SD2=0.3
SD1=0.26
SD2=0.29
SD3=0.3
SD1=0.27
SD2=0.3
SD1=0.27
SD2=0.29
SD3=0.31
SD1=0.27
SD2=0.3
SD1=0.26
SD2=0.29
SD3=0.3
SD1=0.29
SD2=0.29
SD1=0.27
SD2=0.3
SD1=0.26
SD2=0.28
SD3=0.32

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

26 (33)

Table A5. Results of Wilcoxon rank-sum test (i.e., Mann–Whitney U test) between two groups and the Kruskal-Wallis test between three groups to identify statistically significant rating
differences for expression statements ES1-ES20 in respect to groupings based on the answer values of each background question (BQ).
This table shows the p-values concerning the rating differences between groups when the statistical significance levels were defined as p<0.05, p<0.01 and p<0.001, denoted by symbols *, ** and ***
respectively.
Grouping based on the answer value of the background
question

ES1

ES2

ES3

ES4

ES5

ES6

ES7

BQ1, two groups: x<7 (n1=263), x>=7 (n2=410)

0.9197

0.6643

0.1491

0.4769

0.1094

0.001105_*
*

0.03835_* 0.007304_
**

BQ1, three groups: x<6 (n1= 218), 6<=x<8 (n2=207), x>=8
(n3=248)

0.331

0.1774

0.4204

0.815

0.04487_*

0.002876_*
*

0.2161

BQ2, two groups: x<2 (n1=219), x>=2 (n2=454)

0.2048

0.1175

0.04755_*

0.4151

0.2517

0.003857_*
*

BQ4, two groups: x<2 (n1=364), x>=2 (n2=309)

0.3973

0.3349

0.5797

0.5483

0.3886

BQ5, two groups: x<7 (n1=274), x>=7 (n2=399)

0.7408

0.9772

0.1047

0.292

BQ5, three groups: x<6 (n1=190), 6<=x<8 (n2=271), x>=8
(n3=212)

0.1532

0.2886

0.07562

BQ6, two groups: x<7 (n1=318), x>=7 (n2=355)

0.9496

0.4908

BQ6, three groups: x<6 (n1=240), 6<=x<8 (n2=229), x>=8
(n3=204)

0.6204

BQ7, two groups: x<7 (n1=201), x>=7 (n2=472)

ES12

ES13

ES14

ES15

ES16

0.006771_** 0.004866_** 0.05642

0.3291

0.6438

0.3987

0.1316

0.04889_*

0.03546_*

0.05269

0.01077_*

0.9052

0.7382

0.4413

0.269

0.2825

0.05099

0.0657

0.001373_** 0.6126

0.4365

0.006364_*
*

0.2846

0.1325

0.2279

0.09887

0.01654_*

0.8479

0.4035

0.002381_*
*

0.1343

0.05747

0.00434_**

0.003607_** 0.01683_*

0.3356

0.06069

0.00926_**

0.1414

0.01166_* 0.0006896_* 0.0005286_*
**
**

0.5658

0.7009

0.5836

0.005581_*
*

0.3036

0.1441

0.1953

0.9745

0.7312

0.8557

0.44

0.01988_*

0.3726

0.1359

0.1691

0.2554

0.8877

0.07533

0.6983

0.000459_*
**

0.7582

BQ7, three groups: x<6 (n1=143), 6<=x<8 (n2=214), x>=8
(n3=316)

0.8834

0.7608

0.5168

0.3388

0.8597

0.004156_*
*

BQ8, two groups: x<2 (n1=123), x>=2 (n2=550)

0.5048

0.2059

0.003137_**

0.0001024_*
**

0.8198

BQ9, two groups: x<51 (n1=333), x>=51 (n2=340)

6.116e09_***

3.613e09_***

4.392e06_***

2.82e08_***

6.349e06_***

BQ9, three groups: x<40 (n1=225), 40<=x<60 (n2=231), x>=60 1.808e(n3=217)
07_***

ES8

ES9

ES10

ES11

ES19

ES20

0.04026_ 0.01429_
0.0358_*
*
*

0.3167

0.5732

0.398

0.4829

0.2057

0.168

0.1383

0.3959

0.04_*

0.01885_*

0.122

0.1097

0.09556

0.5401

0.1131

0.1744

0.361

0.1451

0.2824

0.1716

0.3776

0.5248

0.3334

0.8051

0.6267

0.1929

0.1205

0.0271_*

0.03034_ 0.08549
*

0.06951

0.5023

0.168

0.6902

0.2367

0.2365

0.09009

0.03014_ 0.03286_ 0.09426
*
*

0.3523

0.01388_
*

0.289

0.0005744_*
**

0.5883

0.9916

0.9809

0.9041

0.4146

0.4478

0.6883

0.05302

0.9842

0.1467

0.1851

0.009845_** 0.9204

0.6588

0.6927

0.602

0.6682

0.7609

0.625

0.262

0.6617

0.6412

0.3008

0.3424

0.00778_**

0.3437

0.1559

0.5785

0.7799

0.9402

0.8928

0.004751_
**

0.5095

1

0.6272

0.4356

0.6223

0.003545_** 0.349

0.6863

0.687

0.948

0.9213

0.9675

0.7298

0.1105

0.684

0.5797

0.09938

0.02251_*

0.01417_*

0.00504_**

1.453e0.005765_** 0.0001656_* 0.02226_
08_***
**
*

1.18e0.000614_*** 06_***

0.07347

0.01332_*

0.04664_*

0.1505

0.0585

0.04851_*

3.191e0.0004377_*
05_***
**

0.2526

0.004295_
**

0.01155_*

0.2856

0.0245_*

0.001738_** 0.2289

0.1283

0.742

9.661e0.02965_
05_***
*
0.222

1.59e08_***
9.863e05_***

0.0002202_* 0.000565_**
**
*

ES17

ES18

0.01594_ 0.03187_ 0.02422_ 0.2095
*
*
*

0.7081

0.9912

0.978

0.8095

0.01925_*

0.3238

0.8223

0.8839

0.8217

0.03513_* 0.02525_
*

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

27 (33)

Table A6. Results of one-way analysis of variance (ANOVA) between two groups and between three groups to identify statistically significant rating differences for expression statements ES1ES20 in respect to groupings based on the answer values of each background question (BQ).
This table shows the p-values concerning the rating differences between groups when the statistical significance levels were defined as p<0.05, p<0.01 and p<0.001, denoted by symbols *, ** and ***
respectively.
Grouping based on the answer value of the background question

ES1

ES2

ES3

ES4

ES5

BQ1, two groups: x<7 (n1=263), x>=7 (n2=410)

0.833

0.814

0.253

0.761

0.184

ES8

ES9

ES11

ES12

ES13

ES14

ES15

ES16

0.00591_**

0.00703_** 0.00759_**

0.0427_*

0.257

0.579

0.512

0.158

0.0348_*

0.0945

ES6
ES7
0.000523_**
0.031_*
*
0.00115_** 0.186

BQ1, three groups: x<6 (n1= 218), 6<=x<8 (n2=207), x>=8 (n3=248)

0.646

0.23

0.561

0.705

BQ2, two groups: x<2 (n1=219), x>=2 (n2=454)

0.483

0.211

0.0237_*

BQ4, two groups: x<2 (n1=364), x>=2 (n2=309)

0.548

0.502

BQ5, two groups: x<7 (n1=274), x>=7 (n2=399)

0.448

BQ5, three groups: x<6 (n1=190), 6<=x<8 (n2=271), x>=8 (n3=212)

0.0325_*

0.0368_*

0.0561

0.00935_**

0.845

0.711

0.8

0.469

0.375

0.405

0.653

0.00207_**

0.247

0.0905

0.0135_*

0.0174_*

0.00104_**

0.727

0.414

0.0724

0.0194_*

0.0733

0.543

0.535

0.748

0.0037_**

0.299

0.0653

0.185

0.0661

0.0176_*

0.849

0.177

0.315

0.093

0.249

0.811

0.181

0.765

0.467

0.00174_**

0.108

0.037_*

0.0108_*

0.00916_**

0.0123_*

0.707

0.592

0.279

0.137

0.0265_*

0.432

0.526

0.0788

0.702

0.133

0.00783_**

0.105

0.00669_**

0.00069_**
0.00109_**
*

0.125

0.624

0.217

0.397

0.0944

0.0211_*

BQ6, two groups: x<7 (n1=318), x>=7 (n2=355)

0.823

0.626

0.713

0.301

0.814

0.00346_**

0.254

0.112

0.189

0.424

0.953

0.821

0.877

BQ6, three groups: x<6 (n1=240), 6<=x<8 (n2=229), x>=8 (n3=204)

0.572

0.976

0.819

0.455

0.588

0.108

0.159

0.288

0.653

0.936

BQ7, two groups: x<7 (n1=201), x>=7 (n2=472)

0.179

0.239

0.654

0.00977_**

0.729

0.667

0.382

0.511

0.00576_**

0.137

0.363

BQ7, three groups: x<6 (n1=143), 6<=x<8 (n2=214), x>=8 (n3=316)

0.902

0.896

0.673

0.641

0.505

0.757

0.00286_**

BQ8, two groups: x<2 (n1=123), x>=2 (n2=550)

0.86

0.4

0.0026_**

0.0935
0.783
0.000519_**
0.936
*

0.0119_*
0.316
0.000157_**
0.841
*
0.00171_** 0.993

0.000383_**
0.703
*
0.00789_** 0.891

0.593

0.0159_*

0.00782_** 0.00413_**

1.49e07_***
3.51e06_***

2.65e08_***

0.377
0.709
0.00012_** 0.0213_
*
*
0.0268_
0.568
*

BQ9, two groups: x<51 (n1=333), x>=51 (n2=340)
BQ9, three groups: x<40 (n1=225), 40<=x<60 (n2=231), x>=60
(n3=217)

5.44e07_***
4.82e2.3e-07_***
07_***

0.0924

4.5e-05_***

3.52e-05_*** 0.124

0.0149_*

2.2e-05_***

0.000736_**
0.313
*

0.00341_* 0.000308_**
0.0263_*
*
*

0.00118_**

0.0157_*

ES10

0.00207_**

0.00849_**
0.0479_*

0.000401_**
0.00145_**
*

0.309

0.19

ES17
0.0101_
*
0.115
0.0461_
*
0.135
0.0232_
*
0.0183_
*

ES18
ES19
0.0322_
0.231
*
0.16
0.118

ES20

0.0801

0.452

0.0966

0.341

0.456

0.453

0.0675

0.0545

0.775

0.0726

0.303

0.169

0.443

0.428

0.684

0.0371_*

0.426

0.642

0.658

0.647

0.627

0.092

0.65

0.79

0.908

0.921

0.444

0.777
2.82e07_***
2.14e06_***
5.23e06_***

0.193
0.786
0.00306_*
0.996
*
0.0905
0.788

0.959
0.984
0.745
0.00918_* 0.0123_ 0.0162_
0.242
*
*
*

1e-07_***
2.66e06_***
4.26e06_***

0.87
0.474

0.919

0.451

0.275

0.741

0.0375_*

0.11

0.802

0.511

0.868

0.0672

0.00704_*
*

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

28 (33)

Table A7. Guidance texts of the online questionnaire.

Figure 1. Gathering the “need for help” rating for an expression statement on a 11-point Likert scale with an online questionnaire.
Before the online questionnaire started to collect actual answers, the person was provided with the following guidance texts about how he/she should perform the interpretation tasks: "We ask you to
evaluate different expressions, for example ‘I am happy’. Interpret how much each expression tells about the need for help. Give your interpretation about the expression on a numeric scale 0-10. 0 indicates
the smallest possible need for help and 10 indicates the greatest possible need for help."
In Finnish:
Pyydämme sinua arvioimaan erilaisia ilmaisuja, esimerkiksi ilmaisua olen iloinen"". Tulkitse, kuinka paljon kukin ilmaisu kertoo avun tarpeesta. Anna tulkintasi ilmaisusta numeroasteikolla 0-10. 0 tarkoittaa
mahdollisimman pientä avun tarvetta ja 10 tarkoittaa mahdollisimman suurta avun tarvetta."""
Then a small training phase allowed the person to get accustomed to give the "need for help" ratings by rating three expression statements: “I have a good health condition.”, “I have a bad health condition.”
and “I have an ordinary health condition.” The answers that the person gave during the training phase were not included in our major analysis data set.
In Finnish:
Minulla on hyvä olo. / Minulla on huono olo. / Minulla on tavallinen olo."
After the training phase, the person was provided with the following guidance texts to still further clarify how he/she should perform the interpretation tasks: “Do not interpret how much the expression tells
about just your own situation. Instead, interpret what kind of impression this expression induces in you. Thus give your interpretation about the expression's meaning in respect to the mentioned property.”
After showing those guidance texts, the person was allowed to start giving actual answers, i.e. to perform the actual interpretation tasks.
In Finnish:
Älä tulkitse, kuinka paljon ilmaisu kertoo juuri sinun omasta tilanteestasi. Sen sijaan tulkitse, minkälaisen vaikutelman tämä ilmaisu herättää sinussa. Siis anna tulkintasi ilmaisun merkityksestä suhteessa
mainittuun ominaisuuteen."

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

29 (33)

Table A8. Expression statements (ES) concerning the coronavirus epidemic that were rated by the person in respect to the impression about the “need for help”.
Compact notation

Expression statement

Expression statement in Finnish

ES1
ES2
ES3
ES4
ES5
ES6
ES7
ES8
ES9
ES10

“I have a flu.”
“I have a cough.”
“I have a shortness of breath.”
“My health condition is weakening.”
“I have a sore throat.”
“I have muscular ache.”
“I have a fever.”
“A sudden fever rises for me with 38 degrees of Celsius or more.”
“I suspect that I have now become infected by the coronavirus.”
“I have now become infected by the coronavirus.”
“I am quarantined from meeting other people ordinarily so that the spreading of an infectious disease could be
prevented.”
“I must be inside a house without getting out.”
“I must be without a human companion.”
“I do not cope in everyday life independently without getting help from other persons.”
“I do not cope at home independently without getting help from persons who originate outside of my home.”
“I have an infectious disease.”
“I have an infectious disease that has been verified by a doctor.”
“I suspect that I have an infectious disease.”
“I have a bad health condition.”
“I have an ordinary health condition.”

“Minulla on nuhaa.”
“Minulle on yskää.”
“Minulla on hengenahdistusta.”
“Yleistilani heikkenee.”
“Minulla on kurkkukipua. “
“Minulla on lihassärkyä.”
“Minulla on kuumetta.”
“Minulle nousee äkillinen kuume, joka on 38 astetta Celsiusta tai enemmän.”
“Epäilen, että olen nyt sairastunut koronavirukseen.”
“Olen nyt sairastunut koronavirukseen.”

Range of values for the person’s
answer (indicating the “need for help”
rating)
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10

“Olen eristettynä ihmisten tavanomaiselta tapaamiselta, jotta tartuntataudin leviäminen estyisi.”

0-10

“Joudun olemaan talon sisällä ilman ulospääsyä.”
“Joudun olemaan ilman ihmisseuraa.”
“En pärjää arkielämässä itsenäisesti ilman avun saamista muilta henkilöiltä.”
“En pärjää kotona itsenäisesti ilman avun saamista kotini ulkopuolisilta henkilöiltä.”
“Minulla on tartuntatauti.”
“Minulla on tartuntatauti, jonka lääkäri on varmistanut.”
“Epäilen, että minulla on tartuntatauti.”
“Minulla on huono olo.”
“Minulla on tavallinen olo.”

0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10
0-10

ES11
ES12
ES13
ES14
ES15
ES16
ES17
ES18
ES19
ES20

Table A9. Background questions (BQ) presented to the person.
Compact notation

Question about the person’s background information

Question about the person’s background information in Finnish

BQ1: an estimated health condition

“What kind of health condition you have currently according to your
opinion?” (de Bruin et al., 1996; Koskinen et al., 2012)

“Minkälainen terveydentilasi on mielestäsi nykyisin?” (de Bruin et al., 1996;
Koskinen et al., 2012)

BQ2: a health problem reduces ability

"Do have a permanent or long-lasting disease or such deficit,
ailment or disability that reduces your ability to work or to perform
your daily living activities?" (Koskinen et al., 2012)

"Onko sinulla jokin pysyvä tai pitkäaikainen sairaus tai jokin sellainen vika,
vaiva tai vamma, joka vähentää työ- tai toimintakykyäsi?" (Koskinen et al.,
2012)

BQ3: one or more diseases identified by a "Has there been a situation that a doctor has identified in you one or "Onko lääkäri joskus todennut sinulla jonkin/joitakin seuraavista
doctor
several of the following diseases?" (Koskinen et al., 2012)
sairauksista?" (Koskinen et al., 2012)

BQ4: a continuous or repeated need fora
doctor's care
BQ5: the quality of life

BQ6: the satisfaction about health

BQ7: the satisfaction about ability

BQ8: sex:
BQ9: age:

Range of values for the person’s answer
A 9-point Likert scale supplied with the following partial
labeling: “9 Good”, “8 –“, “7 Rather good”, “6 –“, “5
Medium”, “4 –“, “3 Rather bad”, “2 –“, “1 Bad”.

Range of values for the person’s answer in Finnish
A 9-point Likert scale supplied with the following partial labeling: “9 Hyvä”,
“8 –“, “7 Melko hyvä”, “6 –“, “5 Keskitasoinen”, “4 –“, “3 Melko huono”, “2
–“, “1 Huono”.

No or yes

Ei or kyllä

The person answers by selecting one or more options from
a list of diseases (Koskinen et al., 2012), see Appendix A.
For some options there is a question “other, what?” and an
adjacent text input box so that the person can write some
additional information concerning that option.

Henkilö vastaa valitsemalla yhden tai useampia vaihtoehtoja sairauksia
sisältävästä luettelosta (Koskinen et al., 2012), katso Appendix A.
Joidenkin vaihtoehtojen kohdalla on kysymys "muu, mikä?" ja sen
vieressä tekstin syöttämislaatikko, johon henkilö voi kirjoittaa täydentävää
tietoa koskien kyseistä vaihtoehtoa.

"Do you need continuously or repeatedly care given by a doctor for a "Tarvitsetko jatkuvasti tai toistuvasti lääkärinhoitoa jonkin äsken
long-lasting disease, deficit or disability that you have just
mainitsemasi pitkäaikaisen sairauden, vian tai vamman takia?" (Koskinen et No or yes
mentioned?" (Koskinen et al., 2012)
al., 2012)
A 9-point Likert scale supplied with the following partial
“How would you rate your quality of life? Give your estimate based
“Minkälaiseksi arvioit elämänlaatusi? Anna arviosi viimeisimpien kahden
labeling: “9 Very good”, “8 –“, “7 Good”, “6 –“, “5 Neither
on the latest two weeks.” (Nosikov & Gudex 2003; Aalto et al., 2013) viikon ajalta.” (Nosikov & Gudex 2003; Aalto et al., 2013)
good nor bad”, “4 –“, “3 Bad”, “2 –“, “1 Very bad”.
A 9-point Likert scale supplied with the following partial
“How satisfied are you with your health? Give your estimate based
“Kuinka tyytyväinen olet terveyteesi? Anna arviosi viimeisimpien kahden
labeling: “9 Very satisfied”, “8 –“, “7 Satisfied”, “6 –“, “5
on the latest two weeks.” (Nosikov & Gudex 2003; Aalto et al., 2013) viikon ajalta.” (Nosikov & Gudex 2003; Aalto et al., 2013)
Neither satisfied nor unsatisfied”, “4 –“, “3 Unsatisfied”, “2 –
“, “1 Very unsatisfied”.
“How satisfied are you with your ability to perform your daily living
A 9-point Likert scale supplied with the following partial
“Kuinka tyytyväinen olet kykyysi selviytyä päivittäisistä toiminnoistasi? Anna
activities currently according to your opinion? Give your estimate
labeling: “9 Very satisfied”, “8 –“, “7 Satisfied”, “6 –“, “5
arviosi viimeisimpien kahden viikon ajalta.” (Nosikov & Gudex 2003; Aalto et
based on the latest two weeks.” (Nosikov & Gudex 2003; Aalto et al.,
Neither satisfied nor unsatisfied”, “4 –“, “3 Unsatisfied”, “2 –
al., 2013)
2013)
“, “1 Very unsatisfied”.
“Tell what is your sex. The answer alternatives are similar as in the
“Kerro sukupuolesi. Vastausvaihtoehdot ovat samankaltaiset kuin aiemmissa
earlier health surveys of National Institute for Health and Welfare in
THL:n terveystutkimuksissa, jotta säilyisi vertailtavuus aiempiin tuloksiin.”
Man or woman
Finland (THL) to maintain comparability with the earlier results.”
(Koskinen et al., 2012)
(Koskinen et al., 2012)
“Tell what is your age.” (Koskinen et al., 2012)
“Kerro ikäsi.” (Koskinen et al., 2012)
16 years, 17 years, ..., 99 years, 100 years or more

En or Kyllä
A 9-point Likert scale supplied with the following partial labeling: “9
Erittäin hyväksi”, “8 –“, “7 Hyväksi”, “6 –“, “5 Ei hyväksi eikä huonoksi”, “4
–“, “3 Huonoksi”, “2 –“, “1 Erittäin huonoksi”.
A 9-point Likert scale supplied with the following partial labeling: “9
Erittäin tyytyväinen”, “8 –“, “7 Tyytyväinen”, “6 –“, “5 Ei tyytyväinen eikä
tyytymätön”, “4 –“, “3 Tyytymätön”, “2 –“, “1 Erittäin tyytymätön”.
A 9-point Likert scale supplied with the following partial labeling: “9
Erittäin tyytyväinen”, “8 –“, “7 Tyytyväinen”, “6 –“, “5 Ei tyytyväinen eikä
tyytymätön”, “4 –“, “3 Tyytymätön”, “2 –“, “1 Erittäin tyytymätön”.

Mies or Nainen
16 vuotta, 17 vuotta, ..., 99 vuotta, 100 vuotta tai enemmän

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

30 (33)

Table A10. Background question BQ3.
Compact notation

Question about the person’s background
information

Question about the person’s background
information in Finnish

BQ3: one or more diseases identified by a doctor

"Has there been a situation that a doctor has
"Onko lääkäri joskus todennut sinulla
identified in you one or several of the following
jonkin/joitakin seuraavista sairauksista?"
diseases?" (Koskinen et al. 2012)

Range of values for the person’s answer

Range of values for the person’s answer in Finnish

The person answers by selecting one or more options from a list of diseases
(Koskinen et al., 2012). For some options there is a question “other, what?” and an
adjacent text input box so that the person can write some additional information
concerning that option.

Henkilö vastaa valitsemalla yhden tai useampia vaihtoehtoja sairauksia
sisältävästä luettelosta (Koskinen et al., 2012). Joidenkin vaihtoehtojen kohdalla on
kysymys "muu, mikä?" ja sen vieressä tekstilaatikko, johon henkilö voi kirjoittaa
täydentävää tietoa koskien kyseistä vaihtoehtoa.

The person was asked to indicate if a doctor had identified one or more diseases in him/her and to describe them (BQ3) (in a form adapted from Koskinen et al., 2012).
_____________________________________________________________________________

Onko lääkäri joskus todennut sinulla jonkin/joitakin seuraavista sairauksista?
Valitse kaikki vastaukseesi kuuluvat sairaudet seuraavasti:
Napauta sairauden nimen vasemmalla puolella olevaa ruutua, jolloin siihen ilmestyy valintamerkki. Voit poistaa valinnan uudella napautuksella.
Tarvittaessa vastaa kysymyksiin "muu, mikä?" seuraavasti: Napauta kysymyksen vieressä näkyvää laatikkoa ja kirjoita siihen vastauksesi.
Lopuksi paina painiketta "Tallennan vastaukseni ja jatkan eteenpäin".

KEUHKOSAIRAUDET
[_] 1. astma
[_] 2. keuhkoputkien ahtauma (COPD)
[_] 3. krooninen keuhkoputkentulehdus (krooninen bronkiitti, keuhkokatarri)
SYDÄN- JA VERISUONISAIRAUDET
[_] 4. sydänveritulppa eli sydäninfarkti
[_] 5. sepelvaltimotauti (sepelvaltimoiden ahtauma, angina pectoris)
[_] 6. sydämen vajaatoiminta
[_] 7. kohonnut verenpaine, verenpainetauti
[_] 8. aivohalvaus (aivoverenvuoto, aivoveritulppa)
NIVEL- JA SELKÄSAIRAUDET
[_] 9. nivelreuma
[_] 10. nivelkuluma (nivelrikko)
10a. Jos vastasit kysymykseen 10 kyllä, missä nivelissä se on todettu?
Voit valita useamman vastausvaihtoehdon.
[_] polvi
[_] lonkka
[_] käsi
[_] ranka
[_] muu, mikä? [____________________]
[_] 11. selkäsairaus tai muu selkävika
[_] 12. niskasairaus tai muu niskavika
TAPATURMAT
[_] 13. tapaturman aiheuttama pysyvä vamma

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.
13a. Jos vastasit kysymykseen 13 kyllä, minkälainen pysyvä vamma on kyseessä?
Voit valita useamman vastausvaihtoehdon.
[_] kasvo- tai leukavamma
[_] jokin muu pää- tai aivovamma
[_] näkövamma
[_] kuulovamma
[_] vamma yläraajassa/-raajoissa
[_] lonkkamurtuma tai sen jälkitila
[_] jokin muu vamma alaraajassa/-raajoissa
[_] vamma vartalossa tai selässä
[_] keuhkovamma
[_] jokin muu vamma, mikä? [____________________]
MIELENTERVEYDEN ONGELMAT
[_] 14. psyykkinen tai mielenterveyteen liittyvä sairaus
14a. Jos vastasit kysymykseen 14 kyllä, minkälainen sairaus on kyseessä?
Voit valita useamman vastausvaihtoehdon.
[_] psykoosi
[_] masennus
[_] ahdistus
[_] päihdeongelma
[_] muu, mikä? [____________________]
NÄKÖ- JA KUULOVIAT
[_] 15. silmien harmaakaihi
15a. Jos vastasit kysymykseen 15 kyllä, oletko ollut sen takia silmäleikkauksessa?
[_] Kyllä olen.
[_] 16. silmien glaukooma (silmänpainetauti, viherkaihi)
[_] 17. silmänpohjan rappeuma
[_] 18. kuulovika, kuulovamma tai kuuloa heikentävä sairaus
MUUT SAIRAUDET
[_] 19. diabetes (sokeritauti)
[_] 20. syöpätauti (pahanlaatuinen kasvain)
[_] 21. Parkinsonintauti
[_] 22. virtsan pidättämisen vaikeuksia, virtsan karkailua tai inkontinenssi
23. Onko sinulla vielä jokin muu lääkärin toteama pitkäaikainen sairaus, vika, vaiva tai vamma?
[_] Kyllä on.
[_] 23a. Jos vastasit kysymykseen 23 kyllä, mikä muu? [____________________]

Painike "Tallennan vastaukseni ja jatkan eteenpäin"
_____________________________________________________________________________

31 (33)

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

32 (33)

Table A11. Animation of the face figure.
The online questionnaire shows each health expression statement as a speech bubble and below that an animation of a face figure is shown. The animation is based on 18 image frames that are illustrated
in the following table. The animation is defined to present the frames 1-18 with the speed of 10 frames per second. In the end, the last frame 18 remains permanently displayed, thus there is no looping of
the animation.

Lahti, Lauri (2020). Detecting the patient’s need for help with machine learning. Manuscript 24 December 2020 at Arxiv.org.

33 (33)

Table A12. Open data availability.
While taking appropriate and sufficient anonymization actions in respect to addressing the General Data Protection Regulation of the European Union in handling the research data, DIHEML research project
publishes an anonymized version of the current research data (an open access data set “Need for help related to the coronavirus COVID-19 epidemic”) in the supplementing Appendix A, to be used by
anyone for non-commercial purposes (while citing this publication).
An open access data set “Need for help related to the coronavirus COVID-19 epidemic” to be used by anyone for non-commercial purposes (while citing this publication).
The data set will be added to this table at a later moment.

