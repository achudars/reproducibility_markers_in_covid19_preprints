arXiv:2011.05136v2 [q-bio.QM] 13 Apr 2021

Application and Comparison of Deep Learning
Methods in the Prediction of RNA Sequence
Degradation and Stability
Ankit Singhal
February 2021
Abstract
mRNA vaccines are receiving increased interest as potential alternatives to conventional methods for the prevention of several diseases,
including Covid-19. This paper proposes and evaluates three deep
learning models (Long Short Term Memory networks, Gated Recurrent Unit networks, and Graph Convolutional Networks) as a method
to predict the stability/reactivity and risk of degradation of sequences
of RNA. These predictions can be very useful in the development of
mRNA vaccines as they can reduce the number of sequences synthesized and tested by helping to identify the most promising candidates.
Reasonably accurate results were able to be generated with the Graph
Convolutional Network being the best predictor of reactivity (RMSE
= 0.249) while the Gated Recurrent Unit Network was the best at
predicting risks of degradation under various circumstances (RMSE
= 0.266). Overall, combining all target variables, the GRU performed
the best with an accuracy value of 76%. Results suggest feasibility of
applying such methods in mRNA vaccine research in the near future.

1

Contents
1 Introduction

3

2 Materials and Methods
2.1 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.1 Software/Packages Used . . . . . . . . . . . . . . . .
2.1.2 Dataset Description . . . . . . . . . . . . . . . . . . .
2.1.3 Data Representation . . . . . . . . . . . . . . . . . .
2.2 Methods and Models . . . . . . . . . . . . . . . . . . . . . .
2.2.1 Data Processing and Overall Model Architecture . . .
2.2.2 Machine Learning, Deep Learning, and Neural Networks Background . . . . . . . . . . . . . . . . . . .
2.2.3 Long Short Term Memory Networks . . . . . . . . .
2.2.4 Gated Recurrent Unit Networks . . . . . . . . . . . .
2.2.5 Graph Convolutional Networks . . . . . . . . . . . .
2.2.6 Performance Assessment . . . . . . . . . . . . . . . .

4
4
4
4
5
6
6

.
.
.
.
.
.

. 7
. 9
. 10
. 11
. 11

3 Results
12
3.1 Initial Training and Validation . . . . . . . . . . . . . . . . . . 12
3.2 Model Comparison . . . . . . . . . . . . . . . . . . . . . . . . 13
4 Discussion and Conclusion

15

5 Appendix
5.1 Figure
5.2 Figure
5.3 Figure
5.4 Figure
5.5 Figure
5.6 Figure

19
19
20
21
22
23
24

12
13
14
15
16
17

-

Hot encoding . . . . . . . . . . . . . . . . .
Basic Artificial Neural Network Architecture
LSTM Diagram . . . . . . . . . . . . . . . .
GRU Diagram . . . . . . . . . . . . . . . . .
GCN Diagram . . . . . . . . . . . . . . . . .
Loss Function Error Term Comparison . . .

2

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

1

Introduction

Over the last two decades, there has been increasing interest in the field
of RNA-based technologies in the creation of prophylactic vaccines. They are
widely regarded to be plausible alternatives to conventional approaches due
to their high potency, capacity for quick and low-cost manufacturing, and
relatively safe administration. They are currently being researched for many
diseases, with the Pfizer-BioNTech vaccine against SARS-CoV-2 being the
first to be approved for human use [1–3]. One of the primary barriers in the
creation of such therapeutics is the fragility of the RNA molecule; they are
susceptible to rapid degradation within minutes to hours [4] and as such need
to be freeze dried or incubated at low temperatures in order to be kept stable.
In the current pandemic, vaccines are seen as the most promising means
to control the novel coronavirus, but with current limitations on mRNA
vaccines, efficient in vivo delivery of such mRNA molecules seems improbable;
it would likely only reach a fraction of the population, mostly relegated to
countries with a higher level of infrastructural development [5].
Therefore, research into the the stability and degradation of RNA molecules has received continued interest, to date largely consisting of traditional
statistical approaches and biophysical models. However, it still remains unclear exactly which parts of RNA molecules are more prone to spontaneous
degradation and thus difficult to accurately predict the reactivity and degradation of mRNA [6]. Therefore, experimentation, an incredibly time consuming process, is the default method in determining these values.
The aim of this manuscript is to present three possible Deep Learning
approaches to this problem through the usage of the Stanford OpenVaccine
dataset. Two variants of Recurrent Neural Networks (RNNs) are employed,
Long Short Term Memory Networks (LSTMs) and Gated Recurrent Unit
Networks (GRUs), along with a variant of a Graph Neural Network (GNN),
the Graph Convolutional Network (GCN). These models are applied and
compared to assess whether Machine Learning methods can provide helpful
results in predicting the reactivity and degradation of mRNA molecules.
This can save significant resources in the development of mRNA vaccines by
helping identify the most promsing candidates using in silico methods.

3

2
2.1
2.1.1

Materials and Methods
Materials
Software/Packages Used

The majority of this work was done in the Python programming language
using a TensorFlow back end with a surface level Keras API. Refer to Table
1 for all the software/packages used throughout the creation and testing of
the models along with related information [7–15].
Software/Package
Python 3.7
TensorFlow
Keras
SKLearn
Pandas
Numpy
Matplotlib
ARNiE

Use
Used to write the code for the models
discussed.
Used as a backend for the majority of
the models presented.
Used as a high level API for some
parts of the model.
Used for k-Fold Cross Validation.
Used for data handling.
Used for data handling.
Used to create figures in manuscript.
Used to generate augmentation data.

Developer
Python Software Foundation
Google
Google
Cornapeau and Matthieu
McKinney
Oliphant
Droettboom and Caswell
DAS Labs

Table 1: All the packages/software used in the creation of the models presented.

2.1.2

Dataset Description

The dataset used in this manuscript to evaluate the models is called the
”Stanford OpenVaccine” dataset [16]. It consists of 6034 RNA sequences.
The training/validation set consisted of 3029 of these sequences with a length
of 107 nucleotide bases. The testing dataset consists of 3005 sequences with a
length of 130 nucleotide bases. Due to experimental limitations (in collecting
the data according to the researchers at Stanford [16]), measurements on the
final bases in the sequences cannot be carried out, therefore, only 68 (for
the sequences with length 107) and 91 (for the sequences with length 130) of
the first bases in the respective sequences have experimental data associated
with them.
Three predictors were associated with each sequence: the sequence itself
(described in A,G,C, and U bases), the expected structure of the molecule,
and the Predicted Loop Type (derived from a simulation of the secondary
structure of the RNA molecule). A Base Pair Probability Matrix was also
provided for each individual sequence indicating the probability of certain
base-pair interactions. Five experimentally-determined sets of values (henceforth referred to as ’target values’) were also given for the first 68 or 91 base
4

pairs in the sequence: Reactivity values, degradation values at pH 10, degradation values at pH 10 with added Magnesium, degradation values at 50◦ ,
and degradation values at 50◦ with added Magnesium. Refer to Table 2 for
more information.
Feature

Classification

Sequence

Input

Structure

Input

Predicted
loop type

Input

Reactivity

Target

Deg pH 10

Target

Deg pH 10 Mg

Target

Deg 50◦ C

Target

Deg 50◦ C Mg

Target

Description
A sequence of 107 letters corresponding
to the four bases in the sequence.
Expected structure of the molecule
(length = 107). ’(’ and ’)’ refer to a base
pair interaction. All ’.’ in the middle are
associated with no BP interactions.
Predicted secondary structure of the
RNA molecule at different points. ’S’
refers to a stem structure, ’M’ multiloop,
’I’ internal loop, ’B’ bulge, ’H’ hairpin
loop, ’E’ dangling end, ’X’ external loop.
Reactivity values at each individual
point in thesequence.
Degradation values at pH 10.
Degradation values at pH 10 with
added Mg.
Degradation values at 50◦ C.
Degradation values at 50◦ C
with added Mg.

Sample
A, G, U, U, C, ...

(..()...)()(... ...

S, S, M, S, H, ...

1.23, 3.46, ...
0.89, 2.44, ...
1.28, 0.88, ...
2.02, 1.87, ...
1.11, 2.44, ...

Table 2: Inputs and target features of the Stanford OpenVaccine dataset.

The task of the algorithms that are presented in this paper is to take the
sequence and other structural features of an RNA molecule (features marked
as ’inputs’) and predict its stability (through the five target values).
2.1.3

Data Representation

As mentioned earlier, each base of the sequence has five target and two further
structural features associated with it. This will be represented as a feature
matrix for all three ML models. What is of particular interest however, is
the Base Pair Probability Matrix associated with each sequence which takes
the form N × N , where N is the number of bases in the sequence. It can be
represented as a standard matrix (refer to Figure 1 for visualization) or as a
graph (refer to Figure 2) with nodes and edges. This distinction is important
for the former form is used for the two RNN architectures whereas the latter
is used for the GCN.

5

Figure 1: Visualization of a sample BPPM Matrix. Purple indicates no base pair interaction, the more
green a color, the higher the interaction between those two bases (produced by author).

Figure 2: Visualization of a an excerpt from sample graph structure of a BPPM. Information in the nodes
correspond to the type of base and its place on the sequence, the width and number next to the edges
refer to the interaction between the two bases with values ranging from 0-1 (produced by author).

2.2
2.2.1

Methods and Models
Data Processing and Overall Model Architecture

Data from the dataset was first mapped to vector matrices and hot encoded,
to ensure the data could be processed by a computer. Essentially, they were
mapped onto a vector of the shape 1 × n where n is the number of possible
options present for that specific feature. For example, since there are four
nitrogenous bases, the vector shape to denote a single base was 1 × 4 and the
total sequence vector for one strand of RNA took the shape 1 × 4 × 107 (refer
to Table 2 and Figure 12 for information about the number of features and
a visual explanantion of the hot encoding process, respectively).
After splitting the training and testing data according to the specifications lined out in Section 2.1.2, the training data was augmented using the
ARNiE package, the same package used to create the data in the first place.
Data augmentation is a technique to artificially create new training data
from the existing data to improve the performance of ML models [17]. The
6

part of the package, Vienna2, that was originally used to predicts the RNA
structures for the sequences, is based off of thermodynamic experiments and
finds the structure by modelling the position of the lowest possible entropy.
To augment the data, an alternate method was employed, CONTRAfold,
that uses statistical methods to predict the structure. Therefore, for every
sequence, new structures and predicted loop types were generated, effectively
allowing for the training data to be doubled.
Finally, the resulting data was used to create the model using the architectures explained in Figure 3 and the model was evaluated on the testing
data. In terms of hyperparameter optimization, the number of epochs was
set to 50 and the batch size was set to 64. K-Fold cross validation was also
conducted with k = 4. These values were determined through a simple grid
search method to find the optimal quantity/quantity after which returns were
negligible. An ADAM optimzer was also utilized with the learning rate set
to a standard 1.0 · 10−3 , due to the fact that the model was running on a
Tensorflow backend.

Figure 3: High level diagram of the overall model architecture. ’Model’ in the diagram refers to one of
the three ML approaches discussed in the next section (produced by author).

2.2.2

Machine Learning, Deep Learning, and Neural Networks
Background

Although words such as ’Artificial Intelligence’, ’Machine Learning’, ’Deep
Learning’, and ’Neural Networks’ have become popularized as buzzwords and
seem to be synonymous with one another, there are important distinctions
between them that must be understood.
Artificial Intelligence is the broadest term that denotes any computational
technique that allows an algorithm to mimic human behaviour by making decisions based on logic. It was first coined by John McCarthy in 1956 [18] and
over the past 60 years fields within AI have undergone rapid advancement including but not limited to: searching algorithms, evolutionary computation,
7

and robotics[19–21].
Machine Learning is one such subfield in AI that refers to the techniques
that give computers the ability to learn and carry out tasks without explicitly programmed instructions. This usually entails a program performing
statistical operations on a large dataset and discovering underlying patterns.
For example, a Support Vector Machine (a type of ML algorithm) might be
able to analyze labeled patient data then categorize unlabeled data into risk
classes of a certain disease.
Finally, Deep Learning is an even more specific term that refers to the
subset of ML which employs multi-layer neural network algorithms to learn
[22]. For certain tasks, such as in Computer Vision or Natural Language
Processing, the usage of such networks can recognize patterns that may be
hidden to simpler forms of ML, therefore improving the performance of these
algorithms.
Neural networks are computational models that are loosely based on the
human brain. Neurons in the brain are connected to many other and are
continuously recieving electrical impulses at their dendrites which eventually
reach the cell body. Here, they are integrated in some way and, crudely
speaking, once some threshold is reached, the neuron ’fires’ and an impulse
is transmitted to other neurons through a synapse. Nodes (or neurons) in an
artificial neural network operate in a similar fashion. They recieve data from
a node in a previous layer, perform a learnable computation on them, then
output the result to the next layer in the network (refer to Figure 13 in the
Appendix for a visualization of a sample network). A general computation
taking place in a single node follows the form:
nl+1 = σ(Wl · nl + bl )

(1)

Where nl+1 is the node which is being updated, nl represents all the
previous nodes connected to nl+1 , Wl are the weights, bl are the biases, and
σ is the activation function. These weights and biases are learnable, i.e.
these are the values that through backpropagation and gradient descent, the
computer is trying to optimize. The activation function is analogous to the
binary threshold of the neuron in the brain to determine whether or not it
will fire, however, in modern networks, more sophisiticated functions are used
such as the sigmoid, ReLu, or hyperbolic tangent functions [22–24]. Figure
4 shows a visual comparison of biological and artificial neural networks.

8

Figure 4: Comparison of neurons, nodes, synnapses, and network connections between cell bodies and an
artificial network (Kim [25]).

The type of neural networks that will be discussed in this paper are
known as Recurrent Neural Networks (RNNs). They are, roughly speaking,
repeating ANNs that allow for information through data in which spatial
or temporal information is important [26]. For example, an algorithm in a
messaging app that has the aim of predicting the next word in the sentence
not only needs information about the preceeding words in the sentence, but
also the order in which they are located.
2.2.3

Long Short Term Memory Networks

A Long Short Term Memory Network (LSTM) is a type of RNN introduced
by Hochreiter & Schmidhuber in 1997 [27] and further popularized by many
other pieces of work following it. Like other RNNs, it essentially consists of
copies of the same network in which the output of the previous network (or
cell) informs the next one, allowing information to persist. A single cell in
an LSTM, consists of four distinct neural network layers, three of which are
ones that make ’decisions’ about the persistence of information as shown in
equations 2 - 4:
ft = σ(Wf [ht−1 , xt ] + bf )
(2)
it = σ(Wi [ht−1 , xt ] + bi )

(3)

ot = σ(Wo [ht−1 , xt ] + bo )

(4)

9

Here the output of the previous cell along with the new input is passed
through a basic neural layer with a non-linear activation function (traditionally sigmoid functions were used but in this paper, all activation functions
denoted by σ were ReLu). In parallel, candidate values for the cell state are
also produced as shown by equation 5:
C̃t = φh (WC [ht−1 , xt ] + bC )

(5)

Where the activation function in this case is a hyperbolic tangent function
(compressing the values between -1 and 1). Finally using these output matrices, one can then update the cell state as given by equation 6 and produce
new outputs as shown in equation 7:
Ct = ft · Ct−1 + C̃t · it

(6)

ht = ot · φh (Ct )

(7)

This output is then fed into the next cell (refer to diagram in Figure 14 in
the Appendix). This model was used with the normal vector matrix BPPM
as represented in Figure 1.
2.2.4

Gated Recurrent Unit Networks

Introduce by Cho et al. in 2014 [28], a Gated Recurrent Unit Network is a
variation of traditional LSTM networks that have the primary advantage of
faster computation (due to less neural nets in each cell). Like in the LSTM,
decision matrices are produced through two non-linear activation function
based neural networks as shown in equations 8 and 9:
rt = σ(Wr [ht−1 , xt ] + br )

(8)

zt = σ(Wz [ht−1 , xt ] + bz )

(9)

Candidate values are also generated through a hyperbolic-tangent-based network, however, in this case it is done directly for the output as there is no cell
state, unlike in an LSTM. The candidates are then chosen by the ’decision’
matrices to produce the output as shown in equations 10 and 11:
h̃t = φh (Wh [ht−1 , xt ] + bh )

(10)

ht = (1 − zt ) · ht−1 + h̃t · zt

(11)

Like any other form of RNN, this output is then passed to the next hidden
layer (refer to diagram in Figure 15 in the Appendix).
10

2.2.5

Graph Convolutional Networks

Graph Convolutional Networks were introduced by Kipf & Welling in 2017
[29] and provide a novel way to analyze arbitrarily structured data in the
form of a graph. A GCN is not a form of an RNN although they are both
connectionist models. A GCN operates on a graph defined by G = (V, E)
where V is the set of nodes and E the set of edges. Nodes in the graph aggregate the features of the surrounding nodes and itself and use the following
neural net (refer to 12 to generate an output which is then assigned to the
node:
ht = σ(Wh · D−1 [ht−1 , Â] + bh )
(12)
Where D is the diagonal node degree matrix of the graph and Â is equal
to A + I, A being the adjacency matrix (taking the form N × N ) representing
the graph (in this case, the BPPM - see Figure 2). h0 = N · F0 i.e. it is a
feature matrix. After an output is generated, this process can be repeated
each time the output of the nodes propagating outwards (refer to diagram
in Figure 16 in the Appendix). Due to the localization of such a problem, I
only had two repetitions, any more resulted in negligible influences.
2.2.6

Performance Assessment

The models will be evaluated based on the error produced in the prediction
of the target values. The two loss measures employed in this paper are Mean
Absolute Error (MAE) and Root Mean Square Error (RMSE) described in
equations 13 and 14.
r
Σni=1 (ŷi − yi )2
(13)
RM SE =
n
1 n
Σ |ŷi − yi |
(14)
n i=1
The difference between the two metrics is that in MAE, all the errors are
averaged by weighting them equally, however, since RMSE has a quadratic
term, larger individual errors will be punished more than smaller ones (refer
to Figure 17 in the Appendix) .
M AE =

11

3
3.1

Results
Initial Training and Validation

After being built using the specifications discussed earlier in this manuscript,
the models were trained on the ’training’ dataset discussed in section 2.1.2.
For k-fold cross validation, in the models presented, k = 4 and this was initially repeated three times to improve accuracy. The model was split into
four groups for cross validation as larger values of k were found to have negligible influence on the model results. Training and validation loss (RMSE)
for the three models are show in Figure 5 and Table 3.

(a) LSTM Model

(b) GRU Model

(c) GCN Model

Figure 5: Training and validation loss for the twelve histories of the ML Models (produced by author).

Training
Validation
RMSE MAE RMSE MAE
LSTM 0.1089 0.0663 0.1758 0.1052
GRU
0.1143 0.0693 0.1787 0.1072
GCN
0.1752 0.1055 0.2232 0.1394
Table 3: Mean loss values of models after the training and validation processes.

As can be seen after the initial training and validation phase, the LSTM
maintains the best performance. The GRU scores were similar to that of
the LSTM, however, the GCN was in a distant third place averaging about
0.05-0.06 higher RMSE values in comparison to the other two.

12

3.2

Model Comparison

The performance for the three machine learning models on the training
dataset are presented in Figures 6 - 10. The GRU maintained the lowest loss
values for all target values, with the only exception being the reactivity (see
Figure 6) and the degradation at pH 10 (only the RMSE - see Figure 7) in
which the GCN had the best predictions. Notably, in Figures 8, 9, and 10,
the GCN had lower RMSE values than the LSTM, however the opposite was
true for the MAE values suggesting that the GCN is not as prone to large,
individual errors.

Figure 6: Results (loss) for over 20 trials of the models predicting the reactivity values of the training
set sequences (note change in scale between plots). The GCN performed the best, both in terms of RMSE
and MAE, followed by the GRU and LSTM respectively. Boxplots show the minimum, maximum, and
median values along with the 25th and 75th quartiles (produced by author).

Figure 7: Results (loss) for over 20 trials of the models predicting the degradation at pH 10 of the
training set sequences (note change in scale between plots). The GCN performed the best in terms of
RMSE, however, the GRU performed better in terms of MAE, suggesting the GRU is more prone to larger
errors. Boxplots show the minimum, maximum, and median values along with the 25th and 75th quartiles
(produced by author).

13

Figure 8: Results (loss) for over 20 trials of the models predicting the degradation at pH 10 with added
Magnesium of the training set sequences (note change in scale between plots). The GRU performed
the best, both in terms of RMSE and MAE, followed by the GCN in RMSE and LSTM in MAE, further
reaffirming the notion that the GCN is less prone to larger individual errors. Boxplots show the minimum,
maximum, and median values along with the 25th and 75th quartiles (produced by author).

Figure 9: Results (loss) for over 20 trials of the models predicting the degradation at 50◦ C of the
training set sequences (note change in scale between plots). The GRU performed the best, both in terms
of RMSE and MAE, the GCN in RMSE and LSTM in MAE, similar to Figure 8. Boxplots show the
minimum, maximum, and median values along with the 25th and 75th quartiles (produced by author).

14

Figure 10: Results (loss) for over 20 trials of the models predicting the degradation at 50◦ C with added
Magnesium of the training set sequences (note change in scale between plots). The GRU performed the
best, both in terms of RMSE and MAE, the GCN in RMSE and LSTM in MAE, similar to Figures 8 and
9. Boxplots show the minimum, maximum, and median values along with the 25th and 75th quartiles
(produced by author).

Mean loss across the 20 trials for each individual target were calculated
along with that of all targets combined for each model. Results are shown
in Figure 11.

Figure 11: Mean loss results (RMSE and MAE - note change in scale between plots) for the three machine
learning methods. The GRU performed the best across both metrics (produced by author).

4

Discussion and Conclusion

Although the creation of stable mRNA molecules remains difficult, datasets
of sequences and corresponding information are becoming more popular and
widely available. Through the use of deep learning architectures, reasonable
predictions of structural features can be obtained, as demonstrated in this
manuscript, with mean RMSE values ranging from 0.24 to 0.31. The usage
15

of such techniques has the capacity to increase the speed and efficiency of
mRNA vaccine discovery and has further implications in other related fields
of research.
However, such methods, as presented in this paper, are not without their
limitations. It is important to note that while reasonably accurate results
are produced, the error, when taking into account the scale of the values
being predicted (0.5 - 4) is not insignificant; in fact, it equates to a 24%
Mean Absolute Percentage Error. Therefore, this could have the potential
of incorrectly predicting the stability of an important molecule which may
be overlooked during the discovery phase. Thus, in its current state, as an
extension, I would suggest a simple binary classification system to predict
whether the molecule is stable, at the end of each of the models that would
aim to minimize the False Negative rate - effectively resulting in the model
being used as a screening test to remove highly unstable sequences, rather
than a full-fledged research tool.
Another limitation of this method is the length of the sequences of the
mRNA molecules used. The length used in this paper ranged from 107-130
bases, while an actual Covid-19 vaccine would likely range from 3000-4000
[2] bases long. As an improvement, this model could be trained on and
applied to longer RNA sequences to see how this impacts the accuracy of
such methods.
Despite these limitations, the results of this work show that such prediction algorithms are feasible and have the potential to save time during research processes, an especially valuable commodity during disease outbreaks.
In the long term, such techniques may also better help researches in understanding the reasoning behind the stability of certain RNA molecules and aid
in the development of related technologies. It is hoped that this work will
be of some use to other data scientists as well in creating better prediction
models for this field.

16

References
(1) Pardi, N.; Hogan, M. J.; Porter, F. W.; Weissman, D. Nature reviews
Drug discovery 2018, 17, 261.
(2) Zhang, C.; Maruggi, G.; Shan, H.; Li, J. Frontiers in Immunology
2019, 10, 594.
(3) Polack, F. P.; Thomas, S. J.; Kitchin, N.; Absalon, J.; Gurtman, A.;
Lockhart, S.; Perez, J. L.; Pérez Marc, G.; Moreira, E. D.; Zerbini, C.,
et al. New England Journal of Medicine 2020, 383, 2603–2615.
(4) Conger, K. Stanford biochemist works with gamers to develop COVID19 vaccine, https : / / scopeblog . stanford . edu / 2020 / 05 / 20 /
stanford- biochemist- works- with- gamers- to- develop- covid19-vaccine/, 2020.
(5) Swift, R.; Cha, S.; Morales, N. J. How Pfizer vaccine could be cold comfort for some Asian nations, https://www.reuters.com/article/
us - health - coronavirus - vaccines - pfizer - as / how - pfizer vaccine - could - be - cold - comfort - for - some - asian - nations idUSKBN27Q1G1, 2020.
(6) Wayment-Steele, H. K.; Choe, C. A.; Nicol, J. J.; Wellington-Oguri,
R.; Sparberg, R. A. P.; Huang, P.; Das, R., et al. BioRxiv 2020.
(7) Van Rossum, G.; Drake, F. L., Python 3 Reference Manual ; CreateSpace: Scotts Valley, CA, 2009.
(8) Martin Abadi et al. TensorFlow: Large-Scale Machine Learning on
Heterogeneous Systems, Software available from tensorflow.org, 2015.
(9) Chollet, F. et al. Keras, https://keras.io, 2015.
(10) Pedregosa, F. et al. Journal of Machine Learning Research 2011, 12,
2825–2830.
(11) McKinney, W. In Proceedings of the 9th Python in Science Conference,
ed. by van der Walt, S.; Millman, J., 2010, pp 56–61.
(12) Harris, C. R. et al. Nature 2020, 585, 357–362.
(13) Hunter, J. D. Computing in Science & Engineering 2007, 9, 90–95.
(14) Lorenz, R.; Bernhart, S. H.; Zu Siederdissen, C. H.; Tafer, H.; Flamm,
C.; Stadler, P. F.; Hofacker, I. L. Algorithms for molecular biology
2011, 6, 1–14.
17

(15) Do, C. B.; Woods, D. A.; Batzoglou, S. Bioinformatics 2006, 22, e90–
e98.
(16) Eterna OpenVaccine: mRNA Vaccine Degradation Prediction, https:
//www.kaggle.com/c/stanford-covid-vaccine/overview, 2020.
(17) Wong, S. C.; Gatt, A.; Stamatescu, V.; McDonnell, M. D. In 2016
international conference on digital image computing: techniques and
applications (DICTA), 2016, pp 1–6.
(18) Smith, C.; McGuire, B.; Huang, T.; Yang, G. History of Artificial Intelligence, https://courses.cs.washington.edu/courses/csep590/
06au/projects/history-ai.pdf, 2006.
(19) Kotsiantis, S. B.; Zaharakis, I. D.; Pintelas, P. E. Artificial Intelligence
Review 2006, 26, 159–190.
(20) Mitchell, M.; Taylor, C. E. Annual Review of Ecology and Systematics
1999, 30, 593–616.
(21) Kaartemo, V.; Helkkula, A. Journal of Creating Value 2018, 4, 211–
228.
(22) Goodfellow, I.; Bengio, Y.; Courville, A., Deep Learning, http://www.
deeplearningbook.org; MIT Press: 2016.
(23) Schmidhuber, J. CoRR 2014, abs/1404.7828.
(24) Emmert-Streib, F.; Yang, Z.; Feng, H.; Tripathi, S.; Dehmer, M. Frontiers in Artificial Intelligence 2020, 3, 4.
(25) Kim, R. Debate on the Relationship between Neural Network and the
Brain. https://wp.nyu.edu/yungjurick/2020/03/15/debate-onthe - relationship - between - neural - network - and - the - brain/,
2020.
(26) Yu, Y.; Si, X.; Hu, C.; Zhang, J. Neural computation 2019, 31, 1235–
1270.
(27) Hochreiter, S.; Schmidhuber, J. Neural Comput. 1997, 9, 1735–1780.
(28) Cho, K.; van Merrienboer, B.; Gülçehre, Ç.; Bougares, F.; Schwenk,
H.; Bengio, Y. CoRR 2014.
(29) Kipf, T. N.; Welling, M. CoRR 2016, abs/1609.02907.

18

5
5.1

Appendix
Figure 12 - Hot encoding

Figure 12: Hot encoding process for the features that are described in Table 2 (produced by author).

19

5.2

Figure 13 - Basic Artificial Neural Network Architecture

Figure 13: Simple visualization of an Artificial Neural Network with neurons (blue), and four (one input,
two hidden, one output) fully connected layers (produced by author).

20

5.3

Figure 14 - LSTM Diagram

Figure 14: A diagram visualization of equations 2 - 7 i.e. of a single cell in a Long Short Term Memory
Network (produced by author).

21

5.4

Figure 15 - GRU Diagram

Figure 15: A diagram visualization of equations 8 - 11 i.e. of a single cell in a Gated Recurrent Unit
Network (produced by author).

22

5.5

Figure 16 - GCN Diagram

Figure 16: A diagram visualization of an aggregation in a Graph Convolutional Network that then proceeds
to follow equation 12 (produced by author).

23

5.6

Figure 17 - Loss Function Error Term Comparison

Figure 17: A simple graph to visually illustrate the differences in the error terms between the qudratic
one in RMSE and the absolute one in MAE (produced by author).

24

