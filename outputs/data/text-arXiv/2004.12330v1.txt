arXiv:2004.12330v1 [cs.AI] 26 Apr 2020

Detecting fake news for the new coronavirus
by reasoning on the Covid-19 ontology
Adrian Groza
Computer Science Department, Technical University of Cluj-Napoca,
Memorandumului 14, Cluj-Napoca, Romania
adrian.groza@cs.utcluj.ro
April 28, 2020
Abstract
In the context of the Covid-19 pandemic, many were quick to spread deceptive
information [7]. I investigate here how reasoning in Description Logics (DLs) can
detect inconsistencies between trusted medical sources and not trusted ones. The
not-trusted information comes in natural language (e.g. ”Covid-19 affects only
the elderly”). To automatically convert into DLs, I used the FRED converter [12].
Reasoning in Description Logics is then performed with the Racer tool [15].

1

Introduction

In the context of Covid-19 pandemic, many were quick to spread deceptive information [7]. Fighting against misinformation requires tools from various domains like law,
education, and also from information technology [21, 16].
Since there is a lot of trusted medical knowledge already formalised, I investigate
here how an ontology on Covid-19 could be used to signal fake news.
I investigate here how reasoning in description logic can detect inconsistencies between a trusted medical source and not trusted ones. The not-trusted information comes
in natural language (e.g. ”Covid-19 affects only elderly”). To automatically convert
into description logic (DL), I used the FRED converter [12]. Reasoning in Description
Logics is then performed with the Racer reasoner [15]1
The rest of the paper is organised as follows: Section 2 succinctly introduces the
syntax of description logic and shows how inconsistency can be detected by reasoning.
Section 4 analyses FRED translations for the Covid-19 myths. Section 5 illustrates how
to formalise knowledge patterns for automatic conflict detection. Section 6 browses
related work, while section 7 concludes the paper.
1 The Python sources and the formalisation in Description Logics (KRSS syntax) are available at
https://github.com/APGroza/ontologies

1

Table 1: Syntax and semantics of DL
Constructor
conjunction
disjunction
existential restriction
value restriction
individual assertion
role assertion

2
2.1

Syntax
CuD
CtD
∃r.C
∀r.C
a:C
r(a, b)

Semantics
CI ∩ DI
CI ∪ DI
{x ∈ ∆I |∃y : (x, y) ∈ rI ∧ y ∈ CI }
{x ∈ ∆I |∀y : (x, y) ∈ rI → y ∈ CI }
{a} ∈ CI
(a, b) ∈ rI

Finding inconsistencies using Description Logics
Description Logics

In the Description Logics, concepts are built using the set of constructors formed by
negation, conjunction, disjunction, value restriction, and existential restriction [4] (Table 1). Here, C and D represent concept descriptions, while r is a role name. The
semantics is defined based on an interpretation I = (∆I , ·I ), where the domain ∆I of I
contains a non-empty set of individuals, and the interpretation function ·I maps each
concept name C to a set of individuals CI ∈ ∆I and each role r to a binary relation
rI ∈ ∆I × ∆I . The last column of Table 1 shows the extension of ·I for non-atomic
concepts.
A terminology TBox is a finite set of terminological axioms of the forms C ≡ D or
C v D.
Example 1 (Terminological box) ”Coronavirus disease (Covid-19 ) is an infectious
disease caused by a newly discovered coronavirus” can be formalised as:
Covid-19 ≡ CoronavirusDisease

(1)

In f ectiousDisease v Disease

(2)

CoronavirusDisease v In f ectiosDisease u ∀causedBy.NewCoronavirus

(3)

Here the concept Covid-19 is the same as the concept CoronavirusDisease. We know
that an infectious disease is a disease (i.e. the concept In f ectiousDisease is included
in the more general concept Disease). We also learn from (3) that the coronovirus
disease in included the intersection of two sets: the set In f ectionDisease and the set of
individuals for which all the roles causedBy points towards instances from the concept
NewCoronavirus.
An assertional box ABox is a finite set of concept assertions i : C or role assertions
r(i,j), where C designates a concept, r a role, and i and j are two individuals.
Example 2 (Assertional Box) SARS-CoV-2 : Virus says that the individual SARS-CoV-2
is an instance of the concept Virus. hasSource(SARS-CoV-2, bat) formalises the information that SARS-Cov-2 comes from the bats. Here the role hasSource relates two
individuals SARS-CoV-2 and bat that is an instance of mammals (i.e. bat : Mammal).
A concept C is satisfied if there exists an interpretation I such that CI 6= 0.
/ The
concept D subsumes the concept C (C v D) if CI ⊆ DI for all interpretations I. Constraints on concepts (i.e. disjoint) or on roles (domain, range, inverse role, or transitive
properties) can be specified in more expressive description logics2 . By reasoning on
2 I provide only some basic terminologies of description logics in this paper to make it self-contained. For
a detailed explanation about families of Description Logics, the reader is referred to [4].

2

this mathematical constraints, one can detect inconsistencies among different pieces of
knowledge, as illustrated in the following inconsistency patterns.

2.2

Inconsistency patterns

An ontology O is incoherent iff there exists an unsatisfiable concept in O.
Example 3 (Incoherent ontology)
Covid-19 v In f ectionDisease

(4)

Covid-19 v ¬In f ectionDisease

(5)

is incoherent because COV ID19 is unsatisfiable in O since it included to two disjoint
sets.
In most of the cases, reasoning is required to signal that a concept is includes in
two disjoint concepts.
Example 4 (Reasoning to detect incoherence)
Covid-19 v In f ectionDisease (6)
In f ectiousDisease v Disease u ∃causedBy.(Bacteria tVirus t Fungi t Parasites) (7)
Covid-19 v ¬Disease (8)
From axioms 6 and 7, one can deduce that Covid-19 is included in the concept Disease.
From axiom 8, one learns the opposite: Covid-19 is outside the same set Disease. A
reasoner on Description Logics will signal an incoherence.
An ontology is inconsistent when an unsatisfiable concept is instantiated. For instance, inconsistency occurs when the same individual is an instance of two disjoint
concepts
Example 5 (Inconsistent ontology)
SARS-CoV-2 : Virus

(9)

SARS-CoV-2 : Bacteria

(10)

Virus v Bacteria

(11)

We learn that SARS-CoV-2 is an instance of both Virus and Bacteria concepts. Axiom (8) states the viruses are disjoint of bacteria. A reasoner on Description Logics
will signal an inconsistency.
Two more examples of such antipatterns3 are:
Antipattern 1 (Onlyness Is Loneliness - OIL)
OIL1 : A v ∀r.B

(12)

OIL2 : A v ∀r.C

(13)

OIL3 : B v ¬C

(14)

Here, concept A can only be linked with role r to B. Next, A can only be linked with
role r to C, disjoint with B.
3 There

are more such antipatterns [18] that trigger both incoherence and inconsistency.

3

Example 6 (OIL antipattern)
OIL1 : Antibiotics v ∀kills.Virus

(15)

OIL2 : Antibiotics v ∀kills.Bacteria

(16)

OIL3 : Virus v ¬Bacteria

(17)

Antipattern 2 (Universal Existence - UE)
UE1 : A v ∀r.C

(18)

UE2 : A v ∃r.B

(19)

UE3 : B v ¬C

(20)

Axiom UE2 adds an existential restriction for the concept A conflicting with the existence of an universal restriction for the same concept A in UE1 .
Example 7 (UE antipattern)
UE1 : Antibiotics v ∀kills.Virus

(21)

UE2 : Antibiotics v ∃kills.Bacteria

(22)

UE3 : Virus v ¬Bacteria

(23)

Assume that axioms UE2 and UE3 comes from a trusted source, while axiom UE1
from the social web. By combining all three axioms, a reasoner will signal the inconsistency or incoherence. The technical difficulty is that information from social web
comes in natural language.

3

Analysing misconceptions with Covid-19 ontology

Sample medical misconceptions on Covid-19 are collected in Table 2). Organisations
such as WHO provides facts for some myths (denoted fi in the table).
Let for instance myth m1 with the formalisation:
5G : MobileNetwork

(24)

covid19 : Virus

(25)

spread(5G, covid19)

(26)

Assume the following formalisation for the corresponding fact f1 :
Virus v ¬(∃travel.(RadioWaves t MobileNetworks))

(27)

The following line of reasoning signals that the ontology is inconsistent:
Virus v ¬(∃travel.MobileNetworks)

(28)

Virus v ∀travel.¬MobileNetworks

(29)

Virus v ∀spread.¬MobileNetworks

(30)

Here we need the subsumption relation between roles (travel v spread). The reasoner
finds that the individual 5G (which is a mobile network by axiom (24)) that spreads
COV ID19 (which is a virus by axiom (25)) is in conflict with the axiom (30).
4

Table 2: Sample of myths versus facts on Covid-19
m1
m2
m3

Myth
5G mobile networks spread Covid-19
Exposing yourself to the sun or to temperatures higher
than 25C degrees prevents the coronavirus disease
You can not recover from the coronavirus infection

f1
f2
f3

Covid-19 can not be transmitted in areas with hot and humid climates
Drinking excessive amounts of water can flush out the
virus
Regularly rinsing your nose with saline help prevent infection with Covid-19

f4

m7

Eating raw ginger counters the coronavirus

f7

m9
m10
m11
m12
m13

The new coronavirus can be spread by Chinese food
Hand dryers are effective in killing the new coronavirus
Cold weather and snow can kill the new coronavirus
Taking a hot bath prevents the new coronavirus disease
Ultraviolet disinfection lamp kills the new coronavirus

f9
f10
f11
f12
f13

m14

Spraying alcohol or chlorine all over your body kills the
new coronavirus
Vaccines against pneumonia protect against the new coronavirus

f14

Antibiotics are effective in preventing and treating the new
coronavirus
High dose of Vitamin C heals Covid-19
The pets transmit the Coronavirus to humans

f16

If you can’t hold your breath for 10 seconds, you have a
coronavirus disease
Drinking alcohol prevents Covid-19

f22

f27
f29

m31

Eating raw lemon counters coronavirus
Zinc supplements can lower the risk of contracting Covid19
Vaccines against flu protect against the new coronavirus

m32

The new coronavirus can be transmitted through mosquito

f32

m33

Covid-19 can affect elderly only

f33

m4
m5
m6

m15

m16
m17
m19
m22
m24
m27
m29

5

f5
f6

f15

f17
f19

f24

f31

Fact
Viruses can not travel on radio waves/mobile networks
You can catch Covid-19 , no matter how sunny or hot the
weather is
Most of the people who catch Covid-19 can recover and
eliminate the virus from their bodies.
Covid-19 can be transmitted in all areas
Drinking excessive amounts of water can not flush out the
virus
There is no evidence that regularly rinsing the nose with
saline has protected people from infection with the new
coronavirus
There is no evidence that eating garlic has protected people from the new coronavirus
The new coronavirus can not be transmitted through food
Hand dryers are not effective in killing the 2019-nCoV
Cold weather and snow can not kill the new coronavirus
Taking a hot bath will not prevent from catching Covid-19
Ultraviolet lamps should not be used to sterilize hands or
other areas of skin as UV radiation can cause skin irritation
Spraying alcohol or chlorine all over your body will not
kill viruses that have already entered your body
Vaccines against pneumonia, such as pneumococcal vaccine and Haemophilus influenza type B (Hib) vaccine, do
not provide protection against the new coronavirus
Antibiotics do not work against viruses, only bacteria.
No supplement cures or prevents disease
There are currently no reported cases of people catching
the coronavirus from animals
You can not confirm coranovirus disease with breathing
exercise
Drinking alcohol does not protect against Covid-19 and
can be dangerous
No food cures or prevents disease
No supplement cures or prevents disease
Vaccines against flu do not protect against the new coronavirus
The new coronavirus can not be transmitted through
mosquito
Covid-19 can affect anyone

As a second example, let the myth m33 in Table 2:
Covid-19 v ∀a f f ects.Elderly

(31)

The corresponding fact f33 states:
Covid-19 v ∀a f f ects.Person

(32)

The inconsistency will be detected on the Abox contains and individual affected by
Covid-19 and who is not elderly:
a f f ectedBy( jon, Covid-19)

(33)

hasAge( jon, 40)

(34)

We need also some background knowledge:
Elderly v Person u (> hasAge 65)

(35)

−

a f f ects ≡ a f f ectedBy

(36)

Covid-19 ≡ one − o f (Covid-19)

(37)

Based on the definition of Elderly and on jon’s age, the reasoner learns that jon does
not belong to that concept (i.e jon : ¬Elderly). From the inverse roles a f f ects− ≡
a f f ectedBy, one learns that the virus Covid-19 affects jon. Since the concept Covid-19
includes only the individual with the same name Covid-19 (defined with the constructor
one − o f for nominals), the reasoner will be able to detect inconsistency.
Note that we need some background knowledge (like definition of Elderly) to signal conflict. Note also the need of a trusted Covid-19 ontology.
There is ongoing work on formalising knowledge about Covid-19 . First,Coronavirus
Infectious Disease Ontology (CIDO) 4 . Second, the Semantics for Covid-19 Discovery5 adds semantic annotations to the CORD-19 dataset. The CORD-19 dataset was
obtained by automatically analysing publications on Covid-19 .
Note also that the above formalisation was manually obtained. Yet, in most of the
cases we need automatic translation from natural language to description logic.

4

Automatic conversion of the Covid-19 myth into Description Logic with FRED

Transforming unstructured text into a formal representation is an important task for the
Semantic Web. Several tools are contributing towards this aim: FRED [12], OpenEI [17],
controlled languages based approach (e.g. ACE), Framester [11], or KNEWS [2]. We
here the FRED tool, that takes a text an natural language and outputs a formalisation in
description logic.
FRED is a machine reader for the Semantic Web that relies on Discourse Representation Theory, Frame semantics and Ontology Design Patterns6 [8, 12]. FRED
leverages multiple natural language processing (NLP) components by integrating their
outputs into a unified result, which is formalised as an RDF/OWL graph. Fred relies on
4 http://bioportal.bioontology.org/ontologies/CIDO
5 https://github.com/fhircat/CORD-19-on-FHIR
6 http://ontologydesignpatterns.org/ont

6

Table 3: FRED’s knowledge resources and their prefixes used for the Covid-19 myts
ontology
Ontology
Covid-19 myths
VerbNet roles
VerbNet concepts
FrameNet frame
FrameNet element
DOLCE+DnS Ultra Light
WordNet
Boxer
Boxing
DBpedia
schema.org
Quantity

Prefix
covid19.m:
vn.role:
vn.data:
ff:
fe:
dul:
wn30:
boxer:
boxing:
dbpedia:
schemaorg:
q:

Name Space
http://www.ontologydesignpatterns.org/ont/Covid-19 /covid-19-myths.owl#
http://www.ontologydesignpatterns.org/ont/vn/abox/role/
http://www.ontologydesignpatterns.org/ont/vn/data/
http://www.ontologydesignpatterns.org/ont/framenet/abox/frame/
http://www.ontologydesignpatterns.org/ont/framenet/abox/fe/
http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#
http://www.w3.org/2006/03/wn/wn30/instances/
http://ontologydesignpatterns.org/ont/boxer/boxer.owl#
http://ontologydesignpatterns.org/ont/boxer/boxing.owl#
http://dbpedia.org/resource/
http://schema.org/

Figure 1: Translating the myth: ”Hand dryers are effective in killing the new coronavirus” in description logic
several NLP knowledge resources (see Table 3). VerbNet [19] contains semantic roles
and patterns that are structure into a taxonomy. FrameNet [5] introduces frames to describe a situation, state or action. The elements of a frame include: agent, patient, time,
location. A frame is usually expressed by verbs or other linguistic constructions, hence
all occurrences of frames are formalised as OWL n-ary relations, all being instances of
some type of event or situation.
We exemplify next, how FRED handles linked data, compositional semantics, plurals, modality and negations with examples related to Covid-19 :

4.1

Linked Data and compositional semantics

Let the myth ”Hand dryers are effective in killing the new coronavirus”, whose automatic translation in DL appears in Figure 1. Fred creates the individual situation1 :
Situation. The role involves from the boxing ontology is used to relate situation1 with
the instance hand dryers:
boxing : involves(situation1 , hand dryers1 )

(38)

Note that hand dryers1 is an instance of the concept Hand dryer from the DBpedia.
The plural is formalised by the role hasQuanti f ier from the Quant ontology:
q : hasQuanti f ier(hand dryers1 , q : multiple)

7

(39)

The information that hand dryers are effective is modeled with the role hasQuality
from the Dolce ontology:
dul : hasQuality(hand dryers1 , e f f ective)

(40)

Note also that the instance e f f ective is related to the instance situation1 with the role
involves:
boxing : involves(situation1 , e f f ective)
(41)
The instance kill1 is identified as an instance of the Kill42030000 verb from the VerbNet
and also as an instance of the Event concept from the Dolce ontology:
kill1 : Kill

(42)

Kill ≡ vn.data : Kill42030000

(43)

Kill v dul : Event

(44)

Fred creates the new complex concept NewCoronavirus that is a subclass of the
Coronavirus concept from DBpedia and has quality New:
NewCoronavirus v dbpedia : Coronavirus u dul : hasQuality.(New)

(45)

New v dul : Quality

(46)

Here the concept New is identified as a subclass of the Quality concept from Dolce.
Note that Fred has successfully linked the information from the myth with relevant
concepts from DBpedia, Verbnet, or Dolce ontologies. It also nicely formalises the plural of ”dryers”,uses compositional semantics for ”hand dryers” and ”new coronavirus”,
Here, the instance kill1 has the object coronavirus1 as patient. (Note that the Patient
role has the semantics from the VerbNet ontology and there is no connection with
the patient as a person suffering from the disease). Also the instance kill1 has Agent
something (i.e. thing1 ) to which the situation1 is in:
in(situation1 ,thing1 )

(47)

vn.role : Agent(kill1 ,thing1 )

(48)

vn.role : Patient(kill1 , coronavirus1 )

(49)

The translating meaning would be: ”The situation involving hand dryers is in something that kills the new coronavirus”.
One possible flaw in the automatic translation from Figure 1 is that hand dryers are
identified as the same individual as coronavirus:
owl : sameAs(hand dryers1 , coronavirus1 )

(50)

This might be because the term ”are” from the myth (”Hand dryers are ....”) which
signals a possible definition or equivalence. These flaw requires post-processing. For
instance, we can automatically remove all the relations sameAs from the generated
Abox.
Actually, the information encapsulated in the given sentence is: ”Hand dryers kill
coronavirus”. Given this simplified version of the myth, Fred outputs the translation
in Figure 2. Here the individual kill1 is correctly linked with the corresponding verb
from VerbNet and also identified as an event in Dolce. The instance kill1 has the agent
dryer1 and the patient coronavirus1 . This corresponds to the intended semantics: hand
dryers kill coronavirus.
8

Figure 2: Translating the simplified sentence: ”Hand dryers kill coronavirus”

Figure 3: Translating myths with modalities: ”You should take vitamin C”

4.2

Modalities and disambiguation

Deceptive information makes extensively use of modalities.
Since OWL lacks formal constructs to express modality, FRED uses the Modality
class from the Boxing ontology:
• boxing:Necessary: e.g., will, must, should
• boxing:Possible: e.g. may, might
where Necessary v Modality and Possible v Modality
Let the following myth related to Covid-19 ”You should take vitamin C” (Figure 3).
The frame is formalised around the instance take1 . The instance is related to the corresponding verb from the VerbNet and also as an event from the Dolce ontology. The
agent of the take verb is a person and has the modality necessary. The individual C is
an instance of concept Vitamin.
Although the above formalisation is correct, the following axioms are wrong. First,
Fred links the concept Vitamin from the Covid-19 ontology with the Vitamin C singer
from DBpedia. Second, the concept Person from the Covid-19 ontology is linked with
Hybrid theory album from the DBpedia, instead of the Person from schema.org. By
performing word sense disambiguation (see Figure 4, Fred correctly links the vitamin
C concept with the noun vitamin from WordNet that is a subclass of the substance
concept in the word net and aslo of PhysicalOb ject from Dolce.

9

Figure 4: Word sense disambiguation for: ”You should take vitamin C”

Figure 5: Formalising negations: ”You can not recover from the coronavirus infection”

4.3

Handling negation

Most of the myths are in positive form. For instance, in Table 2 only myths m3 and
m22 includes negation. Let the translation of myth m3 in Figure 5. The frame is built
around the recover1 event (recover1 is an instance of dul : event concept) Indeed, FRED
signals that the event recover1 :
• has truth value false (axiom 51)
• has modality ”possible” (axiom 52)
• has agent a person (axiom 53)
• has source an infection of type coronavirus (axiom 54)

boxing : hasTruthValue(recover1 , boxing : False) (51)
boxing : hasModality(recover1 , boxing : Possible) (52)
vn.role : Agent(recover1 , person1 ) (53)
vn.role : Source(recover1 , in f ection1 ) (54)
in f ection1 : CoronavirusIn f ection (55)
CoronavirusIn f ection) v dbpedia : In f ection u ∃hasQuality.(dbpedia : Coronavirus) (56)
10

Fred Automatically translating the myth into DL: “Covid-19 can
Figure 6: Step 1: M33
affect elderly only“

However, FRED does not make any assumption on the impact of negation over
logical quantification and scope. The boxing : f alse is the only element that one can
use to signal conflict between positive and negated information.

5

Fake news detection by reasoning in Description Logics

Given a possible myth mi automatically translated by Fred into the ontology MiFred ,
we tackle to fake detection task with three approaches:
1. signal conflict between Mi and scientific facts f j also automatically translated
by Fred MiFred
2. signal conflict between Mi and the Covid-19 ontology designed by the human
agent

5.1

Detecting conflicts between automatic translation of myths and
facts

1. Translating the myth mi in DL using Fred: MiFred
2. Translating the fact fi in DL using Fred F jFred
3. Merging the two ontologies MiFred and F jFred
4. Checking the coherence and consistency of the merged ontology M F Fred
ij
5. If conflict is detected, Verbalise explanations for the inconsistency
6. If conflict is not detected import relevant knowledge that may signal the conflict
Consider the pair:
Myth m33 :
Fact f33 :

Covid-19 can affect elderly only.
Covid-19 can affect anyone.

Figure 8 shows the relevant knowledge used to detect conflict (Note that the prefix
for the Covid-19 -Myths ontology has been removed). The FRED tool has detected the
modality possible for the individual a f f ect1 . The same instance a f f ect1 has quality

11

Fred Automatically translating the fact into DL: “Covid-19 can
Figure 7: Step 2: F33
affect anyone.“

A f f ect v dul : Event

(57)

a f f ect1 : A f f ect

(58)

elderly1 : Elderly

(59)

person1 : Person

(60)

boxing : hasModality(a f f ect1 , boxing : Possible)

(61)

dul : hasQuality(a f f ect1 , only)

(62)

vn.role : Cause(a f f ect1 , covid − 19)

(63)

vn.role : Experiencer(a f f ect1 , elderly1 )

(64)

vn.role : Experiencer(a f f ect1 , person1 )

(65)

Figure 8: Step 3: Sample of knowledge from the merged ontology M F Fred
(33)(33)

Elderly v Person (66)
person1 : ¬Elderly (67)
(?x Only hasQuality) ∧ (?x ?y Experiencer) ∧ (?x ?z Experiencer) ∧ (?y Elderly)
→ (?z Elderly) (68)
Figure 9: Step 4: Conflict detection based on the pattern ∃dul : hasQuality.Only

12

Not-trusted
information

Machine generated
knowledge

Human generated
knowledge

Model of the
not-trusted
information

Patterns
for conflict
detection
(DL axioms
SWRL rules)

NL2DL

FRED
translater

OWL
verbaliser
Covid-19
ontology
Model of
the trusted
information

Trusted
information

Explaining
Conflict

Reasoning in Description Logics

Racer reasoner

Figure 10: A Covid-19 ontology is enriched using FRED with trusted facts and medical
myths. Racer reasoner is used to detect inconsitencies in the enriched ontology, based
on some patterns manually formalised in Description Logics or SWRL
Only. However, the role experiencer relates the instance a f f ect1 with two individuals:
elderly1 and person1 .
The axioms in Figure 9 state that an elderly is a person and that the instance person1
is not elderly. The conflict detection pattern is defined as: ∃dul : hasQuality.Only The
SWRL rule states that for each individual ?x with the quality only that is related via the
role experiencer with two distinct individuals ?y and ?z (where ?y is an instance of the
concept Elderly), then the individual ?z is also an instance of Elderly.
The conflict comes from the fact that person1 is not an instance of Elderly, but still
he/she is affected by COVID (i.e. experiencer(a f f ect1 , person1 )).
The system architecture appears in Figure 10. We start with a core ontology for
Covid-19 . This ontology is enriched with trusted facts on COVID using the FRED
converter. Information from untrusted sources is also formalised in DL using FRED.
The merged axioms are given to Racer that is able to signal conflicts.
To support the user understanding which knowledge from the ontology is causing
incoherences, we use the Racer’s explanation capabilities. RacerPro provides explanations for unsatisfiable concepts, for subsumption relationships, and for unsatisfiable
A-boxes through the commands (check-abox-coherence), (check-tbox-coherence) and
(check-ontology) or (retrieve-with-explanation). These explanations are given to an
ontology verbalizer in order to generated natural language explanation of the conflict.
We aim to collect a corpus of common misconceptions that are spread in online

13

media. We aim to analyse these misconceptions and to build evidence-based counter
arguments to each piece of deceptive information. We aim to annotate this corpus with
concepts and roles from trusted medical ontologies.

6

Discussion and related work

Our topic is related to the more general issue of fake news [9]. Particular to medical domain, there has been a continuous concern of reliability of online heath information [1].
In this line, Waszak et al. have recently investigated the spread of fake medical news in
social media [22]. Amith and Tao have formalised the Vaccine Misinformation Ontology (VAXMO) [3]. VAXMO extends the Misinformation Ontology, aiming to support
vaccine misinformation detection and analysis7 .
Teymourlouie et al. have recently analyse the importance of contextual knowledge
in detecting ontology conflicts. The added contextual knowledge is applied in [20]8 to
the task fo debugging ontologies. In our case, the contextual ontology is represented
by patterns of conflict detection between two merged ontologies. The output of FRED
is given to the Racer reasoner that detects conflict based on trusted medical source and
conflict detection patterns.
FiB system [10] labels news as verified or non-verified. It crawls the Web for
similar news to the current one and summarised them The user reads the summaries
and figures out which information from the initial new might be fake. We aim a step
forward, towards automatically identify possible inconsistencies between a given news
and the verified medical content.
MERGILO tool reconciles knowledge graphs extracted from text, using graph alignment and word similarity [2]. One application area is to detect knowledge evolution
across document versions. To obtain the formalisation of events, MERGILO used both
FRED and Framester. Instead of using metrics for compute graph similarity, I used
here knowledge patterns to detect conflict.
Enriching ontologies with complex axioms has been given some consideration in
literature [13, 14]. The aim would be bridge the gap between a document-centric and a
model-centric view of information [14]. Gyawali et al translate text in the SIDP format
(i.e. System Installation Design Principle) to axioms in description logic. The proposed
system combines an automatically derived lexicon with a hand-written grammar to
automatically generates axioms. Here, the core Covid-19 ontology is enriched with
axioms generated by Fred fed with facts in natural language. Instead of grammar, I
formalised knowledge patterns (e.g. axioms in DL or SWRL rules) to detect conflicts.
Conflict detection depends heavily on the performance of the FRED translator One
can replace FRED by related tools such as Framester [11] or KNEWS [6]. Framester
is a large RDF knowledge graph (about 30 million RDF triples) acting as a umbrella
for FrameNet, WordNet, VerbNet, BabelNet, Predicate Matrix. In contrast to FRED,
KNEWS (Knowledge Extraction With Semantics) can be configured to use different
external modules a s input, but also different output modes (i.e. frame instances, word
aligned semantics or first order logic9 ). Frame representation outputs RDF tuples in
line with the FrameBase10 model. First-order logic formulae in syntax similar to TPTP
and they include WordNet synsets and DBpedia ids as symbols [6].
7 http://www.violinet.org/vaccineontology/
8 https://github.com/teymourlouie/ontodebugger
9 https://github.com/valeriobasile/learningbyreading
10 http://www.framebase.org/

14

7

Conclusion

Even if fake news in the health domain is old hat, many technical challenges remain
to effective fight against medical myths. This is preliminary work on combining two
heavy machineries: natural language processing and ontology reasoning aiming to signal fake information related to Covid-19 .
The ongoing work includes: i) system evaluation and ii) verbalising explanations
for each identified conflict.

References
[1] Samantha A. Adams. Revisiting the online health information reliability debate
in the wake of web 2.0: An inter-disciplinary literature and website review. International Journal of Medical Informatics, 79(6):391 – 400, 2010. Special Issue:
Information Technology in Health Care: Socio-technical Approaches.
[2] Mehwish Alam, Diego Reforgiato Recupero, Misael Mongiovi, Aldo Gangemi,
and Petar Ristoski. Event-based knowledge reconciliation using frame embeddings and frame similarity. Knowledge-Based Systems, 135:192–203, 2017.
[3] Muhammad Amith and Cui Tao. Representing vaccine misinformation using ontologies. Journal of biomedical semantics, 9(1):22, 2018.
[4] Franz Baader, Diego Calvanese, Deborah McGuinness, Peter Patel-Schneider,
Daniele Nardi, et al. The description logic handbook: Theory, implementation
and applications. Cambridge university press, 2003.
[5] Collin F Baker, Charles J Fillmore, and John B Lowe. The berkeley framenet
project. In Proceedings of the 17th international conference on Computational
linguistics-Volume 1, pages 86–90. Association for Computational Linguistics,
1998.
[6] Valerio Basile, Elena Cabrio, and Claudia Schon. Knews: Using logical and
lexical semantics to extract knowledge from natural language. 2016.
[7] Matteo Cinelli, Walter Quattrociocchi, Alessandro Galeazzi, Carlo Michele
Valensise, Emanuele Brugnoli, Ana Lucia Schmidt, Paola Zola, Fabiana Zollo,
and Antonio Scala. The covid-19 social media infodemic. arXiv preprint
arXiv:2003.05004, 2020.
[8] Francesco Draicchio, Aldo Gangemi, Valentina Presutti, and Andrea Giovanni
Nuzzolese. Fred: From natural language text to rdf and owl in one click. In
Extended Semantic Web Conference, pages 263–267. Springer, 2013.
[9] Alvaro Figueira and Luciana Oliveira. The current state of fake news: challenges
and opportunities. Procedia Computer Science, 121:817 – 825, 2017.
[10] Alvaro Figueira and Luciana Oliveira. The current state of fake news: challenges
and opportunities. Procedia Computer Science, 121:817–825, 2017.
[11] Aldo Gangemi, Mehwish Alam, Luigi Asprino, Valentina Presutti, and Diego Reforgiato Recupero. Framester: a wide coverage linguistic linked data hub. In
European Knowledge Acquisition Workshop, pages 239–254. Springer, 2016.
15

[12] Aldo Gangemi, Valentina Presutti, Diego Reforgiato Recupero, Andrea Giovanni
Nuzzolese, Francesco Draicchio, and Misael Mongiovı̀. Semantic web machine
reading with fred. Semantic Web, 8(6):873–893, 2017.
[13] Marius Georgiu and Adrian Groza. Ontology enrichment using semantic wikis
and design patterns. Studia Universitatis Babes-Bolyai, Informatica, 56(2):31,
2011.
[14] Bikash Gyawali, Anastasia Shimorina, Claire Gardent, Samuel Cruz-Lara, and
Mariem Mahfoudh. Mapping natural language to description logic. In European
Semantic Web Conference, pages 273–288. Springer, 2017.
[15] Volker Haarslev, Kay Hidde, Ralf Möller, and Michael Wessel. The racerpro
knowledge representation and reasoning system. Semantic Web, 3(3):267–277,
2012.
[16] David MJ Lazer, Matthew A Baum, Yochai Benkler, Adam J Berinsky, Kelly M
Greenhill, Filippo Menczer, Miriam J Metzger, Brendan Nyhan, Gordon Pennycook, David Rothschild, et al. The science of fake news. Science,
359(6380):1094–1096, 2018.
[17] Jose L Martinez-Rodriguez, Ivan Lopez-Arevalo, and Ana B Rios-Alvarado.
Openie-based approach for knowledge graph construction from text. Expert Systems with Applications, 113:339–355, 2018.
[18] Catherine Roussey and A Zamazal. Antipattern detection: how to debug an ontology without a reasoner. 2013.
[19] Karin Kipper Schuler. Verbnet: A broad-coverage, comprehensive verb lexicon.
2005.
[20] Mehdi Teymourlouie, Ahmad Zaeri, Mohammadali Nematbakhsh, Matthias
Thimm, and Steffen Staab. Detecting hidden errors in an ontology using contextual knowledge. Expert Systems with Applications, 95:312–323, 2018.
[21] Soroush Vosoughi, Deb Roy, and Sinan Aral. The spread of true and false news
online. Science, 359(6380):1146–1151, 2018.
[22] Przemyslaw M Waszak, Wioleta Kasprzycka-Waszak, and Alicja Kubanek. The
spread of medical fake news in social media–the pilot quantitative study. Health
Policy and Technology, 2018.

16

