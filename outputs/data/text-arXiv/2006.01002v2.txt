Interpretable modeling for short- and medium-term
electricity load forecasting
Kei Hirose

1,2

1

Institute of Mathematics for Industry, Kyushu University, 744 Motooka, Nishi-ku, Fukuoka 819-0395, Japan

2

RIKEN Center for Advanced Intelligence Project, 1-4-1 Nihonbashi, Chuo-ku, Tokyo 103-0027, Japan

E-mail: hirose@imi.kyushu-u.ac.jp

arXiv:2006.01002v2 [stat.ME] 2 Jul 2020

Abstract
We consider the problem of short- and medium-term electricity load forecasting by using past loads and daily weather forecast information. Conventionally, many researchers
have directly applied regression analysis. However, interpreting the effect of weather on
these loads is difficult with the existing methods. In this study, we build a statistical model
that resolves this interpretation issue. A varying coefficient model with basis expansion
is used to capture the nonlinear structure of the weather effect. This approach results in
an interpretable model when the regression coefficients are nonnegative. To estimate the
nonnegative regression coefficients, we employ nonnegative least squares. Three real data
analyses show the practicality of our proposed statistical modeling. Two of them demonstrate good forecast accuracy and interpretability of our proposed method. In the third
example, we investigate the effect of COVID-19 on electricity loads. The interpretation
would help make strategies for energy-saving interventions and demand response.

Key Words: basis expansion; COVID-19; nonnegative least squares; short-term load forecasting; varying coefficient model

1

Introduction
Short- and medium-term load forecasting with high accuracy is essential for decision making

during the trade on electricity markets and operation of power systems. Conventionally, several
researchers have used previous loads, weather, and other factors as exploratory variables (e.g.,
Lusis et al., 2017) and directly applied regression analyses to forecast loads. As methodologies
for regression analysis, linear regression (Amral et al., 2008; Dudek, 2016; Saber and Alam, 2017)
and smoothing spline (Engle et al., 1986; Harvey and Kopman, 1993) have been traditionally
used. Recently, several studies have applied functional data analysis, where the daily curves of
electricity loads are expressed as functions (Cabrera and Schulz, 2017; Vilar et al., 2018). It
1

should be noted that most statistical approaches are based on probabilistic forecasts, and the
distribution of forecast values is helpful for risk management (Cabrera and Schulz, 2017). On
the other hand, machine learning techniques have attracted attention in recent years, such as
support vector machine (SVM; Chen et al., 2017; Jiang et al., 2018; Yang et al., 2019), neural
networks (He, 2017; Kong et al., 2018; Guo et al., 2018b; Bedi and Toshniwal, 2019; Wang et al.,
2019), gradient boosting (Zhang et al., 2019), and hybrids of multiple forecasting techniques
(Miswan et al., 2016; Liu et al., 2017; de Oliveira and Oliveira, 2018; Haq and Ni, 2019).
These techniques capture complex nonlinear structures; therefore, high forecast accuracies are
expected.
In practice, the time intervals are different among exploratory variables. For example,
assume that loads are forecasted for a single day that will occur several days in the future, at
30-minute intervals; this is a common scenario for market transactions in electricity exchanges
(e.g., the day-ahead market in the European Power Exchange, EPEX). In this example, the
electricity loads would be collected at 30-minute intervals using a smart meter, whereas weather
forecast information, such as maximum temperature and average humidity, would typically be
observed at intervals of one day. In this study, we use past loads at 30-minute or 1-hour intervals
and daily information (e.g., maximum temperature) on the forecast day as exploratory variables.
We note that our proposed model, which will be described in Section 2, is directly applicable
to any time resolution of data, such as the load in 1-minute intervals and temperature forecast
in 1-hour intervals.
From a suppliers’ point of view, it is crucial to produce an interpretable model to investigate
the impact of weather on the loads. For example, estimating the fluctuations of electric power
caused by weather would help develop strategies for energy-saving interventions (e.g., Guo et al.,
2018a; Wang et al., 2018) and demand response (e.g., Ruiz-Abellón et al., 2020). To produce
an interpretable model, one can directly add weather forecast information to the exploratory
variables in the regression model (Hong et al., 2010) and investigate the estimator of regression
coefficients. More generally, techniques for interpreting any type of black-box model, including
the deep neural networks, have been recently proposed, such as the Local Interpretable Modelagnostic Explanations (LIME; Ribeiro et al., 2016) and SHapley Additive exPlanations (SHAP;
Lundberg and Lee, 2017). However, these methods are used for variable selection, i.e., a set
of variables that plays an essential role in the forecast is selected. Variable selection cannot
estimate the fluctuations in electric power caused by weather.
In contrast to variable selection, decomposition of the electricity load at time t, say yt , into

2

two parts is useful for interpretation:
yt ≈ µt + bt ,

(1)

where µt and bt are the effects of past loads and weather forecast information, respectively.
Typically, we use loads at the same time interval of the previous days as exploratory variables
(e.g., Lusis et al., 2017), and regression analysis is separately conducted on each time interval.
We then construct estimators of µt and bt , say µ̂t and b̂t , respectively. The interpretation is
carried out by plotting a curve of b̂t . However, without elaborate construction and estimation
of bt , we face two issues.
The first issue is that the curve of b̂t often becomes non-smooth at any time interval (i.e.,
every 30 minutes) in our experience. The non-smooth daily curve of bt is unrealistic because it
implies the impact of daily weather forecast on loads changes non-smoothly every 30 minutes.
This problem is caused by the fact that the regression analysis is separately conducted at each
time interval. To address this issue, we should estimate parameters under the assumption that
bt is smooth.
The second issue is related to the parameter estimation procedure. In many cases, the
regression coefficients are estimated through the least squares method. However, in our experience, the estimate of regression coefficients related to bt can be negative, leading to a negative
value of b̂t . Since b̂t is the fluctuations of electric power caused by weather, the interpretation becomes unclear. To alleviate this problem, we need to restrict the regression coefficients
associated with bt to nonnegative values.
In this study, we develop a statistical model that elaborately captures the nonlinear structure of daily weather information to address two challenges, as mentioned earlier. We employ
the varying coefficient model (Hastie and Tibshirani, 1993; Fan and Zhang, 1999) with basis
expansion, where the regression coefficients associated with weather are assumed to be different depending on the time intervals. The regression coefficients are expressed by a nonlinear
smooth function with basis expansion, which allows us to generate a smooth function of b̂t .
Furthermore, the weather effect b̂t is also expressed as a nonlinear smooth function. To generate nonnegative regression coefficients, we employ the nonnegative least squares (NNLS, e.g.,
Lawson and Hanson, 1995) estimation. NNLS estimates parameters under the constraint that
all regression coefficients are nonnegative. With the NNLS estimation, the value of b̂t is always
nonnegative; thus, the interpretation becomes clear.
The usefulness of our proposed method is investigated through the application to three real
datasets. The results for two of the datasets show that the NNLS can appropriately capture
3

the fluctuations of electric power caused by weather. Furthermore, our proposed method yields
better forecast accuracy than the existing machine learning techniques. In the third example,
we investigate our proposed method’s practical usage when COVID-19 influences the electrical
loads (e.g., facility closure or recommendation of telework). Our proposed method is directly
applicable in such a situation; in addition to the daily weather forecast, we use the average
number of infections in the past several days as exploratory variables. The result shows that
our proposed method can adequately capture the effect of COVID-19 and also improve forecast
accuracy.
The remainder of this paper is organized as follows: Section 2 describes our proposed model
based on the varying coefficient model. In Section 3, we present the parameter estimation via
nonnegative least squares. Section 4 presents the analysis of data from Tokyo Electric Power
Company Holdings. In Section 5, we investigate the impact of COVID-19 on electrical loads
through the analysis of data from one selected research facility in Japan. Concluding remarks
are given in Section 6, and technical proofs are deferred to the Appendices.

2

Proposed model
Short- and medium-term forecasting is often used for trading electricity in the market.

Among various electricity markets, the day-ahead (or spot) and the intraday markets are
popular in electricity exchanges, including the European Power Exchange (EPEX) (https://
www.epexspot.com/en/market-data/dayaheadauction) and Japan Electric Power Exchange
(JEPX) (http://www.jepx.org/english/index.html). In the day-ahead market, contracts
for the delivery of electricity on the following day are made. In the intraday market, the power
will be delivered several tens of minutes (e.g., 1 hour in JEPX) after the order is closed. In
both markets, transactions are typically made in 30-minute intervals; thus, the suppliers must
forecast the loads in 30-minute intervals. In this study, we consider the problem of forecasting
loads that can be applied to both day-ahead and intraday markets.
Let yij be the electricity load at jth time interval on ith date (i = 1, ..., n, j = 1, ..., J).
Typically, J = 48, because we usually forecast the loads in 30-minute intervals. We consider
the following model:
yij = µij + bij + εij ,

(2)

where µij is the effect of past electricity load, bij is the effect of weather, such as temperature
and humidity, and εij are error terms with E[εij ] = 0.
4

Typically, the error variances in the daytime are larger than those at midnight because of
the uncertainty of human behavior in the daytime. Therefore, it would be reasonable to assume
that V [εij ] = σj2 , i.e., the error variances depend on the time interval. One may assume the
correlation of errors for different time intervals, i.e., Cor(εij , εij 0 ) 6= 0 for some j 6= j 0 ; however,
the number of parameters becomes large. For this reason, we consider only the case where
the errors are uncorrelated. Note that the final implementation of our proposed procedure
described later is independent of the assumption of the correlation structure in errors.
One can express bij and µij as linear or nonlinear functions of predictors and conduct the
linear regression analysis. With this procedure, however, we face two issues, as mentioned in
the introduction; thus, we carefully construct appropriate functions of bij and µij .

2.1

Expression of bij

Weather forecast information is typically observed at intervals of one day and not 30 minutes
(e.g., the maximum temperature of average humidity). For this reason, we assume that the
weather forecast information does not depend on j. Let a vector of weather information be si .
We express bij as a function of si . Here, we assume two structures as follows:
• It is well known that the relationship between weather variables and consumption is nonlinear. For example, the relationship between maximum temperature and consumption
is approximated by a quadratic function (e.g., Hong et al., 2010) because air conditioners
are used on both hot and cold days. For this reason, it is assumed that bij is expressed
as some nonlinear function of si .
• Although si does not depend on j, the effect of weather, bij , may depend on j. For
example, consumption in the daytime is affected by the maximum temperature more
than that at midnight. In this case, the regression coefficients associated with si change
according to the time interval j. However, if we assume different parameters at each time
interval, the number of parameters can be large, resulting in poor forecast accuracy. To
decrease the number of parameters, we use the varying coefficient model, in which the
coefficients are expressed as a smooth function of the time interval.
Under the above considerations, we propose expressing bij as follows:
bij =

M
X

βm (j)gm (si ),

(3)

m=1

where gm (si ) (m = 1, ..., M ) are basis functions given beforehand, βm (j) are functions of
regression coefficients, and M is the number of basis functions.
5

We also use the basis expansion for βm (j):
βm (j) =

Q
X

γqm hq (j),

(4)

q=1

where hq (j) (q = 1, ..., Q) are basis functions given beforehand and γqm are the elements of the
coefficient matrix Γ = (γqm ). Substituting (4) into (3) results in the following:
bij =

Q
M X
X

γqm hq (j)gm (si ).

(5)

m=1 q=1

Because hq (j) and gm (si ) are known functions, the parameters concerning bij are γqm .
Since the effect of weather is assumed to be smooth according to both j and si , we use basis
functions hq (j) and gm (si ), which produce a smooth function, such as B-spline and the radial
basis function (RBF).

2.2

Expression of µij

Since µij is the effect of past consumption, one can assume that µij is expressed as a linear
combination of past consumption y(i−t−Lα )j , i.e.,
µij =

T
X

αjt y(i−t−Lα )j +

U
X

βju yi(j−u−Lβ ) ,

(6)

u=1

t=1

where T and U are positive integers, which denote how far we trace back through the data
and αjt (t = 1, ..., T ) and βju (u = 1, ..., U ) are positive values given beforehand. Here, Lα
and Lβ are nonnegative integers that describe the lags; these values change according to the
closing time of transactions∗ . The regression coefficients αjt correspond to the effects of past
consumptions for the same time interval on previous days, while βjt are the coefficients for
different time intervals on the same day. For the day-ahead market, we assume that βju ≡ 0.
In practice, however, it is assumed that past consumption also depends on past weather,
such as daily temperature. For example, suppose that it was exceptionally hot yesterday and it
is cooler today. In this case, it is not desirable to directly use past consumption as the predictor;
it is better to remove the effect of past temperature from past consumption. In other words,
we can use y(i−t−Lα )j − b(i−t−Lα )j and yi(j−u−Lβ ) − bi(j−u−Lβ ) instead of y(i−t−Lα )j , and yi(j−u−Lβ ) ,
respectively. As a result, µij is expressed as follows:
µij =

T
X
t=1

∗

αjt (y(i−t−Lα )j − b(i−t−Lα )j ) +

U
X
u=1

βju (yi(j−u−Lβ ) − bi(j−u−Lβ ) ).

(7)

For example, transactions of the day-ahead market in the JEPX close at 5:00 pm every day. For the forecast

of the 5:30–6:00 pm interval tomorrow, we cannot use the information of today’s consumption at the 5:30–6:00
pm interval due to the trading hours of the market, which implies Lα = 1.

6

Substituting (5) into (7) results in the following:
µij =

T
X
t=1

+

αjt y(i−t−Lα )j −

U
X
u=1

Q
T X
M X
X

αjt γqm hq (j)gm (si−t−Lα )

t=1 m=1 q=1

βju yi(j−u−Lβ ) −

Q
U X
M X
X
u=1 m=1 q=1

βju γqm hq (j − u − Lβ )gm (si ).

(8)

The appropriate values of αjt and βju are chosen by several approaches. A simple method
is αjt = 1/T and βju = 1/U , which implies µij is the sample mean of the past consumption.
Another method is based on the AR(1) structure, i.e., αjt = ρtα and βju = ρuβ , where ρα and ρβ
P
P
P
satisfy Tt=1 ρtα = 1 and Uu=1 ρuβ = 1, respectively. Note that Tt=1 ρt = ρ(1 − ρT )/(1 − ρ), so
PT t
T +1
− 2ρ + 1 = 0, whose numerical solution is easily obtained.
t=1 ρ = 1 is equivalent to ρ

2.3

Proposed model

By combining the expressions of bij in (5) and µij in (8), the model (2) is expressed as
follows:
Q
T
T
M
1X
1 XXX
yij =
y(i−t−Lα )j −
γqm hq (j)gm (si−t−Lα )
T t=1
T t=1 m=1 q=1
Q
U
U
M
1 X
1 XXX
+
yi(j−u−Lβ ) −
γqm hq (j − u − Lβ )gm (si )
U u=1
U u=1 m=1 q=1

+

Q
M X
X

γqm hq (j)gm (si ) + εij .

(9)

m=1 q=1

The model (9) is equivalent to the linear regression model
ỹ = Xγ + ε,

(10)

where γ = vec(Γ) and ε = vec(E) with E = (εij ). Here, X and ỹ are considered as the design
matrix and the response vector, respectively. The definitions of ỹ and X are given in Appendix
A.

3

Estimation

3.1

Nonnegative least squares

To estimate the regression coefficient vector γ, one can use the least squares estimation
(LSE)
min kỹ − Xγk22 .
γ

7

In our experience, however, the elements of least squares estimate γ̂ often become negative.
In such cases, the estimate of bij is negative because the basis functions hq (j) and gm (si )
generally take positive values. When bij < 0, one can interpret the weather effect is negative.
Nevertheless, the one-day curve of b̂ij turns out to be counterintuitive; the effect of weather
negatively increases as the electricity loads increase. In other words, bij is negatively large at
working hours and small at midnight. As a result, µij becomes extremely large in the working
time. We observe this phenomenon on the analysis of three datasets presented in this study;
one of them is the well-known Global Energy Forecasting Competition 2014 (GEFCom2014)
data. Therefore, this phenomenon could occur in other datasets.
A clear interpretation is realized when the weather effect bij is nonnegative. To achieve this,
we employ the nonnegative least squares (NNLS) estimation, in which we minimize the loss
function under a constraint the the regression coefficients are nonnegative:
min kỹ − Xγk22
γ

subject to γ ≥ 0.

(11)

The optimization problem (11) is a special case of quadratic programming with nonnegativity constraints (e.g., Franc et al., 2005). As a result, the NNLS problem becomes a convex
optimization problem. Several efficient algorithms to obtain the solution in (11) have been
proposed in the literature (e.g., Lawson and Hanson, 1995; Bro and DeJong, 1997; Timotheou,
2016).
We add the ridge penalty (Hoerl and Kennard, 1970) to the loss function of the NNLS
estimation:
min kỹ − Xγk22 + λkγk22
γ

subject to γ ≥ 0,

(12)

where λ > 0 is a regularization parameter. In our experience, the ridge penalization improves
the forecast accuracy, and also produces b̂ij that is easier to interpret than the unpenalized
NNLS.

3.2

Forecast

For the day-ahead forecast, we forecast the loads on the next day, ŷ(i+1)j , for the given NNLS
estimate γ̂ and weather information si+1 . The forecast value ŷ(i+1)j is expressed as follows:
ŷ(i+1),j = µ̂(i+1)j + b̂(i+1)j
Here, b̂(i+1)j =

PM

m=1

PQ

q=1

γ̂qm hq (j)gm (si+1 ) and µ̂(i+1)j =

PT

t=1

αjt (y(i+1−t−Lα )j − b̂(i+1−t−Lα )j ).

On the intraday forecast, we may use information about the loads on that day so that µ̂(i+1)j
8

is expressed as
µ̂(i+1)j =

T
X
t=1

αjt (y(i+1−t−Lα )j − b̂(i+1−t−Lα )j ) +

U
X
u=1

βju (y(i+1)(j−u−Lβ ) − b̂(i+1)(j−u−Lβ ) ).

Construction of a forecast interval based on (11) or (12) is not easy due to the constraints
of the parameter. To derive the forecast interval, we employ a two-stage procedure; first, we
estimate the parameter via NNLS to extract variables that correspond to nonzero coefficients.
Then, we employ the least squares estimation based on the variables selected in the first step.
With this procedure, we should derive the forecast interval after model selection. To achieve
this result, the post-selection inference (Lee and Taylor, 2014; Lee et al., 2016) is employed.
The post-selection inference for the NNLS estimation is detailed in Appendix B.

4

Application to demand data from Tokyo Electric Power
Company Holdings
The performance of our proposed method is investigated through the analysis of electricity

load data collected from Tokyo Electric Power Company Holdings, available at https://www.
tepco.co.jp/en/forecast/html/download-e.html. The dataset consists of electricity loads
from April 1st, 2016, to March 30th, 2020. The loads are shown in MW at 1-hour intervals
(i.e., J = 24).
We forecast the loads from April 1st, 2019 to March 30th, 2020 (data in 2016–2018 are
only used for training). The training data consist of all load data up to the previous day of
the forecast day; for example, when we forecast the loads on February 4th, 2020, the training
data are loads from April 1st, 2016, to February 3rd, 2020. We consider the problem of the
day-ahead forecast, that is, βju ≡ 0.

4.1

Basis functions

We use maximum temperature in Tokyo as the weather variable si , available at Japan Meteorological Agency (https://www.jma.go.jp/jma/indexe.html). Figure 1 shows the relationship between the maximum temperature and loads. We depict this relationship in different
time intervals for Sunday, Monday, and Wednesday. The curves are depicted by fitting the
ordinary least squares estimation with the cubic B-spline function (e.g., Hastie et al., 2008)
with equally-spaced knots. The number of basis functions is M = 5. For all settings, the

9

9:00−10:00

15:00−16:00

3000

2500

18:00−19:00

4500

4000

Load (10MW)

Load (10MW)

Sunday

Load (10MW)

3500

3500
3000

4000
3500
3000

2500
2500
10

20

30

10

Temperature (°C)

10

15:00−16:00

3500
3000
2500

18:00−19:00

4500
4000
3500

20

4500
4000
3500
3000

3000
10

30

10

Temperature (°C)

20

30

10

Temperature (°C)

9:00−10:00

20

30

Temperature (°C)

15:00−16:00

4500

30

5000

Load (10MW)

4000

20

Temperature (°C)

5000

Load (10MW)

Load (10MW)

Monday

30

Temperature (°C)

9:00−10:00

4500

20

18:00−19:00

5500

4000
3500
3000

5000

Load (10MW)

Load (10MW)

Wednesday

Load (10MW)

5000

4500
4000
3500

4500
4000
3500

3000
10

20

30

10

Temperature (°C)

20

30

Temperature (°C)

10

20

30

Temperature (°C)

Figure 1: Relationship between maximum temperature and loads for different time intervals on
Sunday, Monday, and Wednesday. The curves are depicted by fitting the ordinary least squares
estimation with the cubic B-spline function.
curve-fitting works well, which implies the usage of the B-spline function as a basis function
g(si ) would be reasonable.
The curve shape for 9:00–10:00 is different from that for 15:00–16:00, which suggests that
the regression coefficients must be different among time intervals. Meanwhile, the curve shapes
for 15:00–16:00 and 18:00–19:00 are similar. In this case, it is reasonable to assume that
the regression coefficients for 15:00–16:00 are similar to those for 18:00–19:00. The regression
coefficients are assumed to change depending on the time interval yet to be smooth according
to the time interval. To achieve a smooth function of βm (j), we also use the cubic B-spline as
a basis function of hq (j). As the ordinary B-spline function cannot produce a smooth curve
around the boundary (i.e., 23:00–0:00 and 0:00–1:00), we employ the cyclic B-spline function,
where the basis functions wrap at the first and last knot locations. The cyclic B-spline function
is implemented in the cSplineDes function in the mgcv package in R.
We also observe that the curve shapes are different among each day of the week. Therefore,
we construct the statistical models by day of the week separately; seven statistical models are
constructed. To forecast the loads, we select a model that matches the day of the week. All

10

national holidays are regarded as Sunday; therefore, the number of observations on Sunday is
larger than on other weekdays.

4.2

Candidates of tuning parameters

We employ our proposed method based on two estimation procedures: ridge estimation
min kỹ − Xγk22 + λkγk22 ,
γ

and NNLS estimation with the ridge penalty in (12). We label these estimation procedures
as “LSE” and “NNLS,” respectively. For both LSE and NNLS, we prepare a wide variety of
statistical models by changing the tuning parameters. Here, we review the role of each tuning
parameter and present their candidates as follows:
• Q: the number of basis functions in the varying coefficient model. As Q increases, the
electricity fluctuations caused by weather becomes large in time interval j (j = 1, . . . , J).
The candidates of Q are Q = 5, 10.
• M : the number of basis functions for the impact of weather on loads. As M increases,
the electricity fluctuations caused by weather becomes large in temperature si . The
candidates of M are M = 5, 10.
• T : the number of past loads for forecasting. In other words, we use loads in the past T
days to forecast loads. The candidates of T is T = 2, 4.
• λ: regularization parameter for ridge regression. As λ increases, the regression coefficients
become stable. Small λ prevents the overfitting, but too large λ leads to large bias. The
candidates of λ are 20 sequences from 10−5 to 1.0 on a log-scale. We also set λ = 0 to
investigate the impact of the ridge parameter on the forecast accuracy.
In addition to the above candidates of models, we consider two types of αjt : sample mean of the
past loads (i.e., αjt = 1/T ) and AR(1) structure. Details of the AR(1) structure are presented
at the end of Section 2.2. As a result, the total number of candidates of the models is 336
(= 2 × 2 × 2 × (20 + 1) × 2).

4.3

Impact of tuning parameters on forecast accuracy

The forecast accuracy of our proposed method depends on the tuning parameters presented
above. We investigate the impact of tuning parameters on the mean average percentage error
11

(Q, M, T) = (5, 5, 2)

(Q, M, T) = (5, 10, 2)

−9

−6

log λ

−3

0.05
0.04
−12

0

(Q, M, T) = (5, 5, 4)

−3

0.05

−6

log λ

−3

0

−9

−6

log λ

−3

0.05

−9

−6

log λ

−3

0.05

(Q, M, T) = (10, 5, 4)

0.06

0.04
−12

0.06

0.04
−12

0

0

−6

log λ

−3

0

0.07

0.06
0.05
0.04
−12

−9

(Q, M, T) = (10, 10, 4)

0.07

MAPE

0.06

−9

0.05
0.04
−12

0

0.07

MAPE

MAPE

−6

log λ

0.06

(Q, M, T) = (5, 10, 4)

0.07

0.04
−12

−9

MAPE

0.06

0.07

MAPE

0.05

(Q, M, T) = (10, 10, 2)

0.07

MAPE

0.06

0.04
−12

(Q, M, T) = (10, 5, 2)

0.07

MAPE

MAPE

0.07

−9

−6

log λ

−3

0

0.06
0.05
0.04
−12

−9

−6

log λ

−3

0

Figure 2: Impact of regularization parameter λ on the MAPE, investigated for all combinations
of (Q, M, T ). The dashed line indicates αjt = 1/T and the solid line corresponds to the AR(1)
structure.
(MAPE) defined as
n

MAPE =

J

1 X X |yij − ŷij |
.
Jn i=1 j=1
yij

(13)

Figure 2 shows the relationship between regularization parameter λ and MAPE. The relationships are investigated for all combinations of (Q, M, T ). The result shows that the AR(1)
structure on αjt produces smaller MAPE than the mean structure (αjt = 1/T ) for all candidates of ridge parameter λ. For AR(1) model, the performance for T = 4 is better than that
for T = 2. We observe that a large value of λ may result in poor forecast accuracy; meanwhile,
a small amount of λ generally results in good accuracy. The result for λ = 0 is not displayed
here because the MAPE can be extremely large due to the non-convergence of parameters; the
ridge penalty helps avoid such a non-convergence. In summary, the AR(1) structure on αjt ,
T = 4, and a small value of λ will result in a small MAPE for this dataset.

4.4

Forecast accuracy

We compare the performance of our proposed method with the following popular machine
learning techniques: random forest (RF), support vector machine (SVM), least absolute shrinkage and selection operator (Lasso), and LightGBM (LGBM; Ke et al., 2017). We use R packages
randomForest, ksvm, glmnet, and lgbm to implement these machine learning techniques. The
LightGBM is based on the gradient boosting decision tree and achieves good forecast accuracy in various fields of research including energy (e.g., Ju et al., 2019). For these machine
learning techniques, the forecast is made by the electricity loads of past T days and maximum

12

Table 1: Monthly MAPE for our proposed methods (NNLS and LSE) and existing machine
learning techniques (SVM, RF, Lasso, and LGBM) on the dataset from Tokyo Electric Power
Company Holdings from April 2019 to March 2020. The smallest MAPE is written in bold.
Apr

May

NNLS

4.0

LSE

Jun

Jul

Aug

Sep

Oct

Nov

Dec

Jan

Feb

Mar

total

3.7

3.3 3.9

4.5

4.8

3.3

3.2

4.4

4.2

4.7

4.9

4.6

4.0

3.7

3.3

3.9

4.5

4.8

3.3

3.2

4.4

4.2

4.7

4.9

4.6

SVM

6.1

4.1

3.4

6.1

9.6

7.4

4.9

4.9

6.8

5.4

5.6

6.4

6.4

RF

6.9

4.3

3.5

6.9

8.3

7.3

5.4

4.8

6.6

5.6

5.8

6.4

6.5

Lasso

8.9

5.8

4.3

9.0

11.7

10.5

8.7

5.5

7.0

6.7

7.0

9.2

8.2

LGBM

6.7

5.1

4.0

6.8

8.1

7.5

5.6

5.1

6.7

5.7

6.1

6.6

6.7

temperature, that is, ŷij = f (si , y(i−1)j , . . . , y(i−T +1)j ).
In practice, we need to select a set of tuning parameters among candidates. The candidates
of the tuning parameters for the proposed method are presented in Section 4.3. For machine
learning methods, the candidates are detailed in Appendix C. For all methods, a set of tuning
parameters is selected so that the MAPE in the past one year is minimized. The values of
tuning parameters are changed every month.
Table 1 shows the monthly MAPE for our proposed method and existing methods from
April 2019 to March 2020. The result shows that the proposed method performs better than
existing machine learning techniques. Although the SVM yields better performance than other
existing methods in total, it yields poor performance in August (i.e., hot season). The RF and
LGBM yield similar performance and these methods produce larger MAPE than our proposed
method. The lasso yields the worst performance in total, probably because it cannot capture
the nonlinear relationship between temperature and loads, as in Figure 1. We observe that the
NNLS and LSE result in similar values of MAPE.
We also compute the MAPE for well-known Global Energy Forecasting Competition 2014
(GEFCom2014) data (Hong and Fan, 2016), and obtain a similar result as that shown in Table
1. For detail, please refer to Appendix D.

4.5

Interpretation

With our proposed method, the estimated model can be interpreted by decomposing the
forecast value by the effects of temperature and past loads: ŷij = b̂ij + µ̂ij . The values, b̂ij and
µ̂ij , for NNLS and LSE from October 1st to 14th, 2019, are depicted in Figure 3.
Although the forecast accuracy of the LSE estimation is similar to that of the NNLS es13

NNLS (

0)

Load (10MW)

4000
3000
2000
1000
0
01

02

03

04

05

06

07

08

09

10

11

12

13

14

10

11

12

13

14

Date

Load (10MW)

LSE ( : free)
4000
2000
0
01

02

03

04

05

06

07

08

09

Date
Actual load

Figure 3: The values, b̂ij and µ̂ij , for NNLS (upper panel) and LSE (lower panel) from October
1st to 14th, 2019.
timation, as shown in Table 1, the results of the decomposition ŷij = b̂ij + µ̂ij for these two
methods are unalike in terms of values. The LSE often results in negative values of b̂ij , and
then µ̂ij becomes substantially larger than the actual load. In particular, the value of b̂ij at
working hours is negatively larger than that at midnight; on the other hand, the electricity is
used primarily during working hours. As a result, the behavior of b̂ij is counterintuitive; b̂ij
becomes negatively larger as ŷij increases. Thus, interpreting the effect of weather turns out
to be difficult with LSE. This issue occurs because there are no restrictions on the sign of b̂ij .
We observe a similar behavior of b̂ij on other datasets, including GEFCom2014.
In contrast, the effect of weather is appropriately captured by the NNLS estimation. Indeed,
in many cases, the value of b̂ij at working hours is positively larger than that at midnight. The
constraint on nonnegativeness of γ significantly improves the interpretation of the weather
effect while still maintaining excellent forecast accuracy.
To further investigate the effect of temperature, we depict b̂ij on Tuesday when maximum
temperatures are 5◦ C (cold day), 20◦ C (cool day), and 35◦ C (hot day), which is shown in Figure
4. For existing methods, it is difficult to depict b̂ij because these methods do not assume the

14

Proposed method
−5

01:00

09:00

800
400
01:00

time

09:00

b (10MW)

1200

17:00

1000
500
0

17:00

09:00

17:00

01:00

−2

01:00

09:00

−500

17:00

01:00

time

09:00

500
0
−500
−1000
01:00

17:00

b (10MW)

−500

b (10MW)

b (10MW)

0

(M, λ) = (10, 10 )

800

500
0

time

17:00

( : free)

(M, λ) = (10, 10 )

(M, λ) = (5, 10 )

09:00

time

−5

−2

500

500

time

Proposed method
(M, λ) = (5, 10 )

1000

0
01:00

time

−5

b (10MW)

(M, λ) = (10, 10 )

1500

b (10MW)

b (10MW)

b (10MW)

1000

−2

(M, λ) = (10, 10 )

(M, λ) = (5, 10 )
1600

2000

0)
−5

−2

(M, λ) = (5, 10 )

(

09:00

400
0
−400
−800

17:00

01:00

time

09:00

17:00

time

Existing methods (input: 2019.10.08)
SVM

Random Forest

Lasso

400
0

500
250

09:00

17:00

0
−10
−20

0
01:00

10

b (10MW)

800

750

b (10MW)

b (10MW)

b (10MW)

LGBM

20

1200

01:00

time

09:00

17:00

800
400
0
−400

01:00

time

09:00

17:00

01:00

time

09:00

17:00

time

Existing methods (input: 2019.10.15)
SVM

Random Forest

Lasso

LGBM

20

250

400
200

01:00

09:00

time

17:00

0
−10
−20

0

0

600

10

b (10MW)

500

b (10MW)

600

750

b (10MW)

b (10MW)

1000

01:00

09:00

17:00

200
0

01:00

time

09:00

17:00

time

20 ℃

5℃

400

01:00

09:00

17:00

time

35 ℃

Figure 4: Estimate of the weather effect bij on Tuesday for the proposed method and existing
methods. For existing methods, the weather effect depends on the input. We depict the weather
effect on October 8th, 2019, and October 15th, 2019, for existing methods; both of these days
are Tuesday.
existence of b̂ij . For existing methods, instead of b̂ij , the weather effect is calculated depending
on the input: we forecast the load with specific temperature (5◦ C, 20◦ C, and 35◦ C) and average
annual temperature (21.7◦ C in this case), and subtract the forecast value with average annual
temperature from that with a specific temperature. We depict the weather effect on October
8th, 2019, and October 15th, 2019, for existing methods; both of these days are Tuesday. For
both our proposed method and existing methods, the parameter is estimated by using the
dataset from April 1st, 2016, to October 7th, 2019.
15

The results of our proposed procedure show that b̂ij is highly dependent on the temperature:
the weather effect may be substantial for cold and hot days due to air conditioner use. For
NNLS, the weather effect is always positive, which allows clear interpretation compared with
LSE. Both NNLS and LSE result in smooth curves due to the smooth basis function of the
regression coefficients. We observe that the weather effect is stable unless M is large and λ is
excessively small.
For existing methods, all methods except for the Lasso are unstable and highly depend
on the input. With the Lasso, the impact of temperature is almost zero, which implies that
the weather effect cannot be captured. As a result, our proposed method is more suitable for
interpreting the weather effect than the existing methods.

5

Application to data from one selected research facility
in Japan
In the second real data example, we apply our proposed method to the demand data from

one selected research facility in Japan. The raw data cannot be published due to confidentiality.
This dataset consists of loads from January 1st, 2017 to May 30th, 2020. At certain times,
loads are either not observed or include outliers due to electricity meter failures or blackouts.
The daily data that contain such missing values and outliers are removed, resulting in 1164
days of complete data. The loads are shown in kW at 1-hour intervals (J = 24).
We observe that COVID-19 greatly influences the usage of this research facility’s electricity
pattern due to the recommendation of telework. In present times, it is essential to forecast the
loads for this extraordinary situation. To this end, our proposed method is directly applicable
to the input of daily data related to COVID-19, and we focus our attention on the forecast
accuracy in March, April, and May 2020.

5.1

Input of COVID-19 information

In Japan, the most frequently-used daily information about COVID-19 is the daily number
of infections, available at https://www3.nhk.or.jp/news/special/coronavirus/data-all/.
However, this variable turns out to be relatively unstable. In order to use more stable information about COVID-19, we may use the moving average of the number of infections; that is,
the average number of infections in the past several days.
Figure 5 shows the relationship between the number of daily infections and loads, and
16

The number of infections
9:00−10:00

15:00−16:00

18:00−19:00

75

65
60
55
50

Load (kW)

Load (kW)

Load (kW)

120

120

70

100
80

200

400

600

80
60

60
0

100

0

Number of infections

200

400

600

0

Number of infections

200

400

600

Number of infections

Mean value of the number of infections in the past 14 days
9:00−10:00

15:00−16:00

18:00−19:00

75

65
60
55
50

Load (kW)

Load (kW)

Load (kW)

120

120

70

100
80
60

0

100

200

300

400

500

Number of infections in the past

100
80
60

0

100

200

300

400

500

Number of infections in the past

0

100

200

300

400

500

Number of infections in the past

Figure 5: Relationship between the number of daily infections and loads (upper panels), and
between the average number of infections in the past 14 days and loads (lower panels). We
depict these plots on working days. The curve fitting is done by polynomial regression with
cubic function.
between the average number of infections in the past 14 days and loads. We depict these plots
on working days. The curve fitting is done by polynomial regression with cubic function. The
B-spline may not be suitable in this case due to the limited number of observations.
The number of daily infections includes outliers; thus resulting in unstable curve fitting. For
example, when the number of infections is relatively large, the loads increase as the number
of infections increases. This phenomenon is counterintuitive because this facility encourages
working at home as much as possible to prevent infections. On the other hand, the average
number of infections in the past 14 days is negatively correlated with the loads, and the curve
fitting of the cubic function works well. For this reason, we use the average number of infections
in the past 14 days as daily information about COVID-19. As a result, the daily variable si
becomes a two-dimensional vector that consists of the maximum temperature and the average
number of infections in the past 14 days. We use the cubic B-spline function as a basis function
of maximum temperature, and the cubic function as a basis function of the average number of
infections in the past 14 days.

17

Load (kW)

100

80

60

01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20

Date
Actual load

Forecast value using
information about COVID-19

Forecast value not using
information about COVID-19

Figure 6: Actual loads and forecast values from April 1st, 2020 to April 20th, 2020.

5.2

Forecast accuracy

In the previous real data example, we construct the statistical models by day of the week
separately. However, in this case, the number of observations affected by COVID-19 is excessively small. Thus, only two statistical models are constructed based on working days (from
Monday to Friday) and holidays (Saturday, Sunday, and national holidays). We consider the
problem of the day-ahead forecast from March 1st, 2020 to May 30th, 2020 (data in 2017–2019
are only used for training). The training data consist of all load data up to the previous day
of the forecast day.
We investigate how the input of COVID-19 information improves the forecast accuracy.
The NNLS does not produce negative regression coefficients but we observe that the electricity
usage decreases as the average number of infections in the past 14 days increases, as shown in
Figure 5. Thus, the electricity fluctuation caused by COVID-19, say bcovid19
, should be negative.
ij
As the basis function, we use the cubic function of negative number of infections in the past 14
days; that is, bcovid19
= β1 (j)(−scovid19
)3 + β2 (j)(−scovid19
)2 + β3 (j)(−scovid19
), where scovid19
is
ij
i
i
i
i
the number of infections in the past 14 days.
Figure 6 shows the forecast values with our proposed method using NNLS and the actual
loads. We depict two forecast values: one uses the information about COVID-19 and the other
does not. The result shows that the usage of the COVID-19 data slightly improves the accuracy;
for example, on the 10th and 13th.
Figure 7 shows b̂ij of both temperature and COVID-19. The results show that after April
10th, the negative effect of COVID-19 is observed. The government declared a state of emergency on April 7th, and following this, the usage pattern of the electricity changed. The change
18

Load (kW)

5

0

−5

01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20

Date

Figure 7: b̂ij for temperature (dotted line) and COVID-19 (dashed line).
Table 2: Monthly MAPE for our proposed methods (NNLS and LSE) and existing machine
learning techniques (SVM, RF, Lasso, and LGBM) on the dataset from one selected research
facility in March, April, and May 2020. The smallest MAPE is written in bold.
Including COVID-19 information

Not including COVID-19 information

NNLS

SVM

RF

Lasso

LGBM

NNLS

SVM

RF

Lasso

LGBM

Mar

3.5

5.6

3.9

4.3

3.9

3.4

3.8

3.9

4.1

4.3

Apr

4.0

5.0

4.3

3.9

6.0

5.2

5.3

6.5

6.0

7.8

May

3.1

3.1

3.5

2.9

3.4

3.3

3.2

3.5

3.4

3.3

in electricity pattern on the 8th and 9th may not be captured due to excessively small sample
sizes related to the number of infections. However, after the 9th, the effect of COVID-19 is
captured.
Table 2 shows MAPE for our proposed method and existing methods on March, April,
and May 2020. We also compare the performance of two estimation procedures: one uses the
information about COVID-19 and the other does not. In March, the result shows that the
proposed method performs the best and Lasso yields the worst performance. This is because
the effect of temperature can be appropriately captured as shown in the previous example. The
effect of COVID-19 is not crucial in March because the performance becomes worse when the
COVID-19 information is included.
In April and May, the information about COVID-19 significantly improves the performance
for almost all methods. In particular, our proposed method and Lasso both produce small
MAPE values, and interestingly, Lasso performs slightly better than our proposed method.
There are two reasons to explain the superiority of Lasso. First, the relationship between the
number of infections and the loads is approximated by a linear function, as shown in Figure
19

5. Second, the temperature effect is not crucial because the temperature does not change
much in April and May. The nonlinear machine learning techniques, such as SVM, RF, and
LGBM, yield large MAPE in April, probably due to the small number of observations related
to COVID-19; these techniques result in overfitting. As a result, only our proposed method
can capture the effect of both temperature and COVID-19.

6

Concluding remarks
We have constructed a statistical model for forecasting future electricity loads. To capture

the nonlinear effect of weather information, we employed the varying coefficient model. With
the ordinary least squares estimation (LSE), the estimate of bij , say b̂ij , became negative because
some of the elements of regression coefficients γ̂ were negative. The negative weather effect led
to the difficulty in the interpretation of the weather effect. To address this issue, we employed
the NNLS estimation; this estimation is performed under the constraint that all of the elements
of γ̂ are nonnegative. The practicality is illustrated through three real data examples. Two of
these examples showed that our method performed better than the existing machine learning
techniques. In the third example, our proposed method adequately captured the impact of
COVID-19. Estimating the fluctuations of electric power caused by weather and COVID-19
would help make strategies for energy-saving interventions and demand response.
The proposed method is carried out under the assumption that the errors are uncorrelated.
In practice, however, the errors among near time intervals may be correlated. As a future
research topic, it would be interesting to assume a correlation among time intervals and estimate
a regression model that includes the correlation parameter.

Acknowledgements
The author would like to thank Professor Hiroki Masuda and Dr. Maiya Hori for helpful
comments and discussions. This work was partially supported by the Japan Society for the
Promotion of Science KAKENHI 19K11862 and the Center of Innovation Program (COI) from
JST, Japan.

20

Appendix A

Matrix notation of our proposed regression
model

To show that our proposed model (9) is a regression model, we denote the following:
y̆ijα =

PT

αjt y(i−t−Lα )j ,

y̆ijβ =

PT

βjt yi(j−u−Lβ ) ,

t=1

u=1

h(j) = (h1 (j), . . . , hQ (j))T ,
P
h̆j = Uu=1 βjt h(j − u − Lβ ),
Γ = (γqm ),

γ = vec(Γ),
P
ğm,i = Tt=1 αjt gm (s(i−t−Lα ) ),
ği = (ğ1,i , . . . , ğM,i )T ,
gi = (g1 (si ), . . . , gM (si ))T .
The model (9) is then expressed as follows:
yij = y̆ijα − h(j)T Γği + y̆ijβ − h̆Tj Γgi + h(j)T Γgi + εij
n
oT
= y̆ijα + y̆ijβ + gi ⊗ h(j) − ği ⊗ h(j) − gi ⊗ h̆j γ + εij .
Note that we use the following formula for matrices A, B, and C:
vec(ABC T ) = (C ⊗ A)vec(B),
(A ⊗ B)T = AT ⊗ B T .
Furthermore, we denote the following:
qi = (y̆i1α + y̆i1β , . . . , y̆iJα + y̆iJβ )T ,
ỹi = yi − qi ,

ỹ = (ỹ1T , . . . , ỹnT )T ,
H = (h(1) . . . , h(J)),
H̆ = (h̆(1), . . . , h̆(J)),
Li = (gi ⊗ H − ği ⊗ H − gi ⊗ H̆),
L = (L1 , . . . , Ln )T ,

Thus, we have a linear regression model (10).

21

Appendix B

Post-selection inference for the NNLS estimation

Appendix B.1

Selection event of NNLS

In this section, ỹ and γ are referred to as y and β, respectively, which leads to a standard
notation of the linear regression model:
y = Xβ + ε.
The post-selection inference for the NNLS estimation has already been proposed by Lee and
Taylor (2014), but these authors lack a parameter constraint. We have added a constraint on
the parameter of the selection event. Let Ŝ be indices that correspond to variables selected on
the basis of the NNLS estimation, i.e., Ŝ = {j | β̂j 6= 0}. Let −Ŝ be indices of variables not
selected in Ŝ. The KKT condition in the NNLS estimation (Franc et al., 2005; Chen et al.,
2011) is
∂L(β, µ)
∂ β̂

= X T X β̂ − X T y − µ = 0,

(14)

β̂ ≥ 0,

(15)

µ ≥ 0,

(16)

β̂ T µ = 0,

(17)

T T
where µ is the Lagrange multiplier. Substituting β̂ = (β̂ŜT , β̂−
) into (14) – (17) results in
Ŝ

−XŜT (y − XŜ β̂Ŝ ) ≥ 0,

(18)

−X−T Ŝ (y − XŜ β̂Ŝ ) ≥ 0,

(19)

β̂Ŝ > 0,

(20)

β̂−Ŝ = 0,
β̂ŜT XŜT (y − XŜ β̂Ŝ ) = 0.

(21)

By combining (18), (20), and (21), we obtain
XŜT (y − XŜ β̂Ŝ ) = 0.

(22)

β̂Ŝ = (XŜT XŜ )−1 XŜT y.

(23)

Then, we obtain

22

Eq. (23) implies the NNLS estimate for the active set coincides with the LSE using the active
set. Substituting (23) into (19) and (20) results in
−X−T Ŝ (I − XŜ (XŜT XŜ )−1 XŜT )y > 0,

(24)

(XŜT XŜ )−1 XŜT y ≥ 0.

(25)

The selection event constructed by (24) and (25) is expressed as
Ê(y) = {y | A(Ŝ) ≥ 0},
where A(Ŝ) is given by
A(Ŝ) =

!
X−T Ŝ (I − XŜ XŜ† )
−XŜ†

.

This selection event for the NNLS estimation has already been studied by Lee and Taylor (2014)
but Lee and Taylor (2014) did not include the first inequality (24).

Appendix B.2

Distribution of the forecast value after model selection

Suppose that y ∼ N (µ, σ 2 I), and consider the problem of deriving the following distribution:
η T y | {Ay ≤ b}.
Here, η is an n-dimensional vector given beforehand. For example, if η = XŜ†T ej , then η T y =
β̂j . If
c = η(η T η)−1 ,
z = (In − cη T )y,
then
η T y | {Ay ≤ b, z = z0 } ∼ TN(η T µ, σ 2 kηk2 , V − (z0 ), V + (z0 )),
where
bj − (Az)j
,
j:(Ac)j <0
(Ac)j
bj − (Az)j
V + (z) = min
.
j:(Ac)j >0
(Ac)j
V − (z) = max

23

Algorithm 1 Selective inference for NNLS
1:

Conduct NNLS, and obtain a set of indices for the nonzero coefficients Ŝ.

2:

Calculate XŜ† = (XŜT XŜ )−1 XŜT .

3:

Define the matrix of selection event A(Ŝ) =

4:

for j = 1, . . . , |Ŝ| do

!
X−T Ŝ (I − XŜ XŜ† )
−XŜ†

5:

Let η = XŜ†T ej .

6:

Calculate c = Ση(η T Ση)−1 , z = (In − cη T )y.

7:

Calculate V − (z) = max

8:

Find L and U , which satisfies FL,ηT Ση

9:

.

−(Az)j +
−(Az)j
, V (z) = min
.
j:(Ac)j <0 (Ac)j
j:(Ac)j >0 (Ac)j
[V −(z) ,V +(z) ]

(η T y) =

α
α
[V −(z) ,V +(z) ]
and FU,ηT Ση
(η T y) = 1 − .
2
2

end for

However, we only observe the distribution of η T y for a given z. We consider the marginalization
with respect to z. To explain this result, we consider the distribution of a truncated normal
distribution
[a,b]

Fµ,σ2 (x) =

Φ((x − µ)/σ) − Φ((a − µ)/σ)
.
Φ((b − µ)/σ) − Φ((a − µ)/σ)

Then, we have
[V −(z) ,V +(z) ]

FηT µ,σ2 kηk2 (η T y) | {Ay ≤ b} ∼ U (0, 1),
which implies
P

α
2

≤


α
≤ 1 − | Ay ≤ b = 1 − α.
2

[V −(z) ,V +(z) ]
FηT µ,σ2 kηk2 (η T y)

To construct the confidence interval for a given new input x, we let η = XŜ†T x, and we find L
and U , which satisfies the following equation:
[V −(z) ,V +(z) ]

FL,σ2 kηk2

(η T y) =

α
,
2

[V −(z) ,V +(z) ]

FU,σ2 kηk2

(η T y) = 1 −

α
.
2

Letting y ∗ = (y T , ε)T with ε ∼ N (0, σ 2 ) and η = (xT , 1)T , we construct the prediction interval.
The algorithm of the post-selection inference for the NNLS estimation procedure is shown in
Algorithm 1.

Appendix C

Tuning parameter for existing methods

For all existing methods, we use T = 2 and T = 4. Tuning parameters in existing machine
learning techniques are summarized as follows
24

• In SVM, we use the Gaussian Kernel as a Kernel function.

In this case, we have

three tuning parameters: σ, C, and . σ is used in the Gaussian Kernel given by
K(x, x0 ) = exp(−σkx − x0 k2 ), and C corresponds to the regularization parameter in the
SVM problem.  is used in the regression version of SVM; data in -tube around the prediction value is not penalized. The candidates for these parameters are σ = 0.001, 0.01, 0.1,
C = 1, 10, 100 and  = 0.001, 0.01, 0.1.
• The tuning parameters of random forest include the number of trees, ntrees , and the
number of variables sampled at each split, nvar . The candidates of these parameters are
ntrees = 50, 100, 500 and nvar = 1, 2, 3.
• In the lasso, the tuning parameter is the regularization parameter, λ. The candidates of
regularization parameter λ are set as follows: maximum and minimum values of λ are
defined by λmax = 200 and λmin = 0.01, respectively, and 100 grids are constructed on a
log scale.
• For LGBM, we change two tuning parameters: the number of boosting iterations, niterations ,
and the learning rate, LR. We set candidates of these parameters as niterations = 50, 100, 500,
and LR = 0.01, 0.05, 0.1, 0.2, 0.5, 1. Other parameters are set to be default of the LightGBM package in https://github.com/microsoft/LightGBM/tree/master/R-package.

Appendix D

Application to GEFCom2014 data

We apply our method to the Global Energy Forecasting Competition 2014 (GEFCom2014)
data (Hong and Fan, 2016), available at http://blog.drhongtao.com/2017/03/gefcom2014load-forecasting-data.html. The dataset consists of electricity loads from January 1st,
2006, to December 31th, 2014. The loads are shown in MW at 1-hour intervals (i.e., J = 24).
The temperature in 1-hour intervals is available, but we only use the maximum temperature
as inputs. The forecasting strategies, including the tuning parameter selection, are the same
as described in Section 4.
We forecast the loads from January 1st, 2012 to December 31th, 2014. Table 3 shows
the monthly MAPE for our proposed methods and machine learning techniques. Each value
represents the average value of the MAPEs in three years. The result is similar to that of
Tokyo Electric Power Company Holdings in Table 1; our proposed method performs better
than existing methods, and LSE and NNLS result in similar MAPE.

25

Table 3: Monthly MAPE for our proposed methods (NNLS and LSE) and existing machine
learning techniques (SVM, RF, Lasso, and LGBM) on the dataset from Global Energy Forecasting Competition 2014. Each value represents the average value of the MAPEs in 2012–2014.
The smallest MAPE is written in bold.
Jan

Feb

Mar

Apr

May

Jun

Jul

Aug

Sep

Oct

Nov

Dec

total

NNLS

3.4

2.9

3.0

2.6

3.0

4.1

4.9

4.0

4.9

2.1

3.8

3.9

3.5

LSE

3.4

2.9

3.0

2.6

3.0

4.1

4.9

4.0

4.9

2.1

3.7

3.9

3.5

SVM

4.5

4.1

4.1

3.6

3.5

4.6

6.4

5.3

5.7

2.6

5.2

5.1

4.6

RF

4.5

4.1

4.2

3.7

3.5

5.0

6.2

5.3

6.3

2.5

4.9

5.0

4.6

Lasso

6.1

4.3

4.7

5.1

4.1

6.4

8.7

6.5

9.0

2.8

5.4

5.9

5.8

LGBM

4.4

4.2

4.3

3.7

3.6

5.0

6.0

5.4

6.0

2.7

5.1

5.0

4.6

References
N. Amral, C. S. Ozveren, and D. King. Short term load forecasting using Multiple Linear
Regression. In 2007 42nd International Universities Power Engineering Conference, pages
1192–1198. IEEE, Feb. 2008.
J. Bedi and D. Toshniwal. Deep learning framework to forecast electricity demand. Applied
Energy, 238:1312–1326, Mar. 2019.
R. Bro and S. DeJong. A fast non-negativity-constrained least squares algorithm. Journal of
Chemometrics, 11(5):393–401, 1997.
B. L. Cabrera and F. Schulz. Forecasting Generalized Quantiles of Electricity Demand: A
Functional Data Approach. Journal of the American Statistical Association, 112(517):127–
136, Mar. 2017.
D. Chen, R. P. T. b. o. n. analysis, and 2010. Nonnegativity constraints in numerical analysis.
World Scientific, pages 109–139, Nov. 2011.
Y. Chen, P. Xu, Y. Chu, W. Li, Y. Wu, L. Ni, Y. Bao, and K. Wang. Short-term electrical
load forecasting using the Support Vector Regression (SVR) model to calculate the demand
response baseline for office buildings. Applied Energy, 195:659–670, June 2017.
E. M. de Oliveira and F. L. C. Oliveira. Forecasting mid-long term electric energy consumption
through bagging ARIMA and exponential smoothing methods. Energy, 144:776–788, Feb.
2018.
26

G. Dudek. Pattern-based local linear regression models for short-term load forecasting. Electric
Power Systems Research, 130:139–147, Jan. 2016.
R. F. Engle, C. W. Granger, J. Rice, and A. Weiss. Semiparametric estimates of the relation
between weather and electricity sales. Journal of the American Statistical Association, 81
(394):310–320, Jan. 1986.
J. Q. Fan and W. Y. Zhang. Statistical estimation in varying coefficient models. The Annals
of Statistics, 27(5):1491–1518, Oct. 1999.
V. Franc, V. Hlavac, and M. Navara. Sequential coordinate-wise algorithm for the non-negative
least squares problem. Computer Analysis of Images and Patterns, Proceedings, 3691:407–
414, 2005.
Z. Guo, K. Zhou, C. Zhang, X. Lu, W. Chen, and S. Yang. Residential electricity consumption
behavior: Influencing factors, related theories and intervention strategies. Renewable and
Sustainable Energy Reviews, 81:399–412, 2018a.
Z. Guo, K. Zhou, X. Zhang, and S. Yang. A deep learning model for short-term power load
and probability density forecasting. Energy, 160:1186–1200, Oct. 2018b.
M. R. Haq and Z. Ni. A new hybrid model for short-term electricity load forecasting. IEEE
Access, 7:125413–125423, 2019.
A. Harvey and S. J. Kopman. Forecasting Hourly Electricity Demand Using Time-Varying
Splines. Journal of the American Statistical Association, 88(424):1228–1236, Dec. 1993.
T. Hastie and R. Tibshirani. Varying-Coefficient Models. Journal of the Royal Statistical
Society Series B-Methodological, 55(4):757–796, Jan. 1993.
T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning. Springer, New
York, 2nd edition, 2008.
W. He. Load Forecasting via Deep Neural Networks. Procedia Computer Science, 122:308–314,
2017.
A. E. Hoerl and R. W. Kennard. Ridge Regression: Biased Estimation for Nonorthogonal
Problems. Technometrics, 12(1):55–67, Feb. 1970.
T. Hong and S. Fan. Probabilistic electric load forecasting: A tutorial review. International
Journal of Forecasting, 32(3):914–938, 2016.
27

T. Hong, M. Gui, M. E. Baran, and H. L. Willis. Modeling and forecasting hourly electric load
by multiple linear regression with interactions. IEEE PES General Meeting, pages 1–8, July
2010.
H. Jiang, Y. Zhang, E. Muljadi, J. J. Zhang, and D. W. Gao. A Short-Term and HighResolution Distribution System Load Forecasting Approach Using Support Vector Regression
With Hybrid Parameters Optimization. IEEE Transactions on Smart Grid, 9(4):3341–3350,
July 2018.
Y. Ju, G. Sun, Q. Chen, M. Zhang, H. Zhu, and M. U. Rehman. A model combining convolutional neural network and lightgbm algorithm for ultra-short-term wind power forecasting.
IEEE Access, 7:28309–28318, 2019.
G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.-Y. Liu. Lightgbm: A
highly efficient gradient boosting decision tree. In Advances in neural information processing
systems, pages 3146–3154, 2017.
W. Kong, Z. Y. Dong, Y. Jia, D. J. Hill, Y. Xu, and Y. Zhang. Short-Term Residential Load
Forecasting Based on LSTM Recurrent Neural Network. IEEE Transactions on Smart Grid,
10(1):841–851, Dec. 2018.
C. L. Lawson and R. J. Hanson. Solving Least Squares Problems. Society for Industrial and
Applied Mathematics, 1995. doi: 10.1137/1.9781611971217. URL https://epubs.siam.
org/doi/abs/10.1137/1.9781611971217.
J. D. Lee and J. E. Taylor. Exact Post Model Selection Inference for Marginal Screening.
arXiv.1402.5596, 2014.
J. D. Lee, D. L. Sun, Y. Sun, and J. E. Taylor. Exact post-selection inference, with application
to the lasso. The Annals of Statistics, 44(3):907–927, June 2016.
B. Liu, J. Nowotarski, T. Hong, and R. Weron. Probabilistic Load Forecasting via Quantile
Regression Averaging on Sister Forecasts. IEEE Transactions on Smart Grid, 8(2):730–737,
Mar. 2017.
S. M. Lundberg and S.-I. Lee. A unified approach to interpreting model predictions. In Advances
in neural information processing systems, pages 4765–4774, 2017.
P. Lusis, K. R. Khalilpour, L. Andrew, and A. Liebman. Short-term residential load forecasting:
Impact of calendar effects and forecast granularity. Applied Energy, 205:654–669, Nov. 2017.
28

N. H. Miswan, R. M. Said, and S. H. H. Anuar. ARIMA with regression model in modelling electricity load demand. Journal of Telecommunication, Electronic and Computer Engineering,
8(12):113–116, Jan. 2016.
M. T. Ribeiro, S. Singh, and C. Guestrin. “Why should I trust you?” Explaining the predictions
of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on
knowledge discovery and data mining, pages 1135–1144, 2016.
M. C. Ruiz-Abellón, L. A. Fernández-Jiménez, A. Guillamón, A. Falces, A. Garcı́a-Garre, and
A. Gabaldón. Integration of demand response and short-term forecasting for the management
of prosumers demand and generation. Energies, 13(1):11, 2020.
A. Y. Saber and A. K. M. R. Alam. Short term load forecasting using multiple linear regression
for big data. In 2017 IEEE Symposium Series on Computational Intelligence (SSCI), pages
1–6, Nov 2017. doi: 10.1109/SSCI.2017.8285261.
S. Timotheou. FAST NON-NEGATIVE LEAST-SQUARES LEARNING in the RANDOM
NEURAL NETWORK. Probability in the Engineering and Informational Sciences, 30(3):
379–402, Jan. 2016.
J. Vilar, G. Aneiros, and P. Raña. Prediction intervals for electricity demand and price using
functional data. Electrical Power and Energy Systems, 96:457–472, Mar. 2018.
F. Wang, L. Liu, Y. Yu, G. Li, J. Li, M. Shafie-Khah, and J. a. P. Catalão. Impact analysis
of customized feedback interventions on residential electricity load consumption behavior for
demand response. Energies, 11(4):770, 2018.
Y. Wang, D. Gan, M. Sun, N. Zhang, Z. Lu, and C. Kang. Probabilistic individual load
forecasting using pinball loss guided lstm. Applied Energy, 235:10–20, 2019.
A. Yang, W. Li, and X. Yang. Short-term electricity load forecasting based on feature selection
and least squares support vector machines. Knowledge-Based Systems, 163:159–173, 2019.
N. Zhang, Z. Li, X. Zou, and S. M. Quiring. Comparison of three short-term load forecast
models in southern california. Energy, 189:116358, 2019.

29

