Model Generalization on COVID-19 Fake News
Detection

arXiv:2101.03841v1 [cs.CL] 11 Jan 2021

Yejin Bang∗ , Etsuko Ishii∗ , Samuel Cahyawĳaya∗ , Ziwei Ji∗ , and Pascale Fung
Center for Artificial Intelligence Research (CAiRE)
Department of Electronic and Computer Engineering
The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong
{yjbang,eishii,scahyawijaya,zjiad}@connect.ust.hk

Abstract. Amid the pandemic COVID-19, the world is facing unprecedented
infodemic with the proliferation of both fake and real information. Considering
the problematic consequences that the COVID-19 fake-news have brought, the
scientific community has put effort to tackle it. To contribute to this fight against
the infodemic, we aim to achieve a robust model for the COVID-19 fake-news
detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking two
separate approaches: 1) fine-tuning transformers based language models with
robust loss functions and 2) removing harmful training instances through influence
calculation. We further evaluate the robustness of our models by evaluating on
different COVID-19 misinformation test set (Tweets-19) to understand model
generalization ability. With the first approach, we achieve 98.13% for weighted F1
score (W-F1) for the shared task, whereas 38.18% W-F1 on the Tweets-19 highest.
On the contrary, by performing influence data cleansing, our model with 99%
cleansing percentage can achieve 54.33% W-F1 score on Tweets-19 with a
trade-off. By evaluating our models on two COVID-19 fake-news test sets, we
suggest the importance of model generalization ability in this task to step forward
to tackle the COVID-19 fake-news problem in online social media platforms.
Keywords: COVID-19, Infodemic, Fake News, Robust Loss, Influence-based
Cleansing, Generalizability

1

Introduction

As the whole world is going through a tough time due to the pandemic COVID-19, the
information about COVID-19 online grew exponentially. It is the first global pandemic
with the 4th industrial revolution, which led to the rapid spread of information through
various online platforms. It came along with Infodemic. The infodemic results in serious
problems that even affects people’s lives, for instance, a fake news “Drinking bleach can
cure coronavirus disease” led people to death1. Not only the physical health is threatened
due to the fake-news, but the easily spread fake-news even affects the mental health of
the public with restless anxiety or fear induced by the misinformation [38].
∗

These authors contributed equally.
1https://www.bbc.com/news/world-53755067

2

Bang et al.

Table 1: Dataset Statistics.
Label

FakeNews-19

Tweets-19

Train Valid Test

Valid Test

Real 3360 1120 1120
Fake 3060 1020 1020

51
9

172
28

Total 6420 2140 2140

60

200

With the urgent calls to combat the infodemic, the scientific community has produced
intensive research and applications for analyzing contents, source, propagators, and
propagation of the misinformation [26,22,11,2,14] and providing accurate information
through various user-friendly platforms [16,30]. The early published fact sheet about
the COVID-19 misinformation suggested 59% of the sampled pandemic-related Twitter
posts are evaluated as fake-news [2]. To address this, a huge amount of tweets is
collected to disseminate the misinformation [21,23,27,1]. Understanding the problematic
consequences of the fake-news, the online platform providers have started flag COVID-19
related information with an “alert” so the audience could be aware of the content.
However, the massive amount of information flooding the internet on daily basis makes it
challenging for human fact-checkers to keep up with the speed of information proliferation
[28]. The automatic way to aid the human fact-checker is in need, not just for COVID-19
but also for any infodemic that could happen unexpectedly in the future.
In this work, we aim to achieve a robust model for the COVID-19 fake-news detection
shared task proposed by Patwa. et al. [25] with two approaches 1) fine-tuning classifiers
with robust loss functions and 2) removing harmful training instances through influence
calculation. We also further evaluate the adaptability of our method out of the shared task
domain through evaluations on different COVID-19 misinformation tweet test set [1]. We
show a robust model with high performance over two different test sets to step forward to
tackle the COVID-19 fake-news problem in social media platforms.

2

Dataset

Fake-News COVID-19 (FakeNews-19) A dataset released for the shared task of CONSTRAINT 2021 workshop [24], which aims to combat the infodemic regarding COVID-19
across social media platforms such as Twitter, Facebook, Instagram, and any other popular
press releases. The dataset consists of 10,700 social media posts and articles of real and
fake news, all in English. The details of the statistic are listed in Table 1. Each social
media post is manually annotated either as “Fake” or “Real”, depending on its veracity.
Tweets COVID-19 (Tweets-19) To evaluate the generalizability of trained models
test setting, we take the test set from [1], which is also released for fighting for the
COVID-19 Infodemic tweets. The tweets are annotated with fine-grained labels related to
disinformation about COVID-19, depending on the interest of different parties involved
in the Infodemic. We took the second question, “To what extent does the tweet appear
to contain false information?”, to incorporate with our binary setting. Originally, it is

Model Generalization on COVID-19 Fake News Detection

3

Table 2: Top-10 most frequent words on FakeNews-19 and Tweets-19
Dataset

Label

Most frequent words

FakeNews-19 cases, #covid19, new, covid, tests, people, states, deaths, total, testing

Real

Tweets-19
Fake

#coronavirus, covid, cases, #covid19, people, virus, corona, health, spread, us

FakeNews-19 covid, coronavirus, people, virus, vaccine, #coronavirus, trump, says, new, #covid19
Tweets-19

virus, corona, coronavirus, covid, #coronavirus, fake, news, get, really, media

answered in five labels based on the degree of the falseness of the tweet. Instead of using
the multi-labels, we follow the binary setting as the data releaser did to map to “Real”
and “Fake” labels for our experiments. For our cleansing experiment, we split the dataset
into validation and test set with equal label distribution. The detail is listed in Table 1.
The most frequent words after removing stopwords on each dataset is listed in Table 2.

3
3.1

Methodology
Task and Objective

The main task is a binary classification to determine the veracity for the given piece of
text from social media platforms and assign the label either “Fake” or “Real”. We aim
to achieve a robust model in this task with a consideration on both high performance
on predicting labels on FakeNews-19 shared task and generalization ability through
performance on Tweets-19 with two separate approaches described in the following
Sections (3.2 and 3.3). Note that models are trained only with FakeNews-19 train set.
3.2

Approach 1: Fine-tuning Pre-trained Transformer based Language Models
with Robust Loss Functions

When handling text data, Transformers [31] based language models (LM) are commonly
used as feature extractors [4,13,17] thanks to publicly released large-scale pre-trained
language models (LMs). We adopt different Transformer LMs with a feed-forward
classifier trained on top of each model. The list and details of models are described in
Section 4.1. As reported in [37,9,12], robust loss functions help to improve the deep
neural network performance especially with noisy datasets constructed from social
medium. In addition to the standard cross-entropy loss (CE), we explore the following
robust loss functions: symmetric cross-entropy (SCE) [33], the generalized cross-entropy
(GCE) [39], and curriculum loss (CL) [19]. Inspired by the symmetric Kullback-Leibler
divergence, SCE takes an additional term called reverse cross-entropy to enhance CE
symmetricity. GCE takes the advantages of both mean absolute error being noise-robust
and CE performing well with challenging datasets. CL is a recently proposed 0-1 loss
function which is a tighter upper bound compared with conventional summation based
surrogate losses, which follows the investigation of 0-1 loss being robust [7].

4

3.3

Bang et al.

Approach 2: Data Noise Cleansing based on Training Instance Influence

This approach is inspired by the work of Kobayashi et al. [10], which proposes an
efficient method to estimate the influence of training instances given a target instance
by introducing turn-over dropout mechanism. We define 𝐷 trn = {𝑑1trn , 𝑑2trn , . . . , 𝑑 trn
𝑘 }
as a training dataset with 𝑘 training sample and L ( 𝑓 , 𝑑) as a loss function calculated
from a model 𝑓 and a labelled sample 𝑑. In turn-over dropout, a specific dropout mask
𝑚 𝑖 ∈ {0, 𝑝1 } with dropout probability 𝑝 is applied during training to zeroed-out a set of
parameters 𝜃 ∈ R𝑛 from the model 𝑓 for each training instance 𝑑𝑖trn . With this approach,
every single sample in the training set is trained on a unique sub-network of the model.
We define ℎ(𝑑𝑖trn ) is a function to map a training data 𝑑𝑖trn into the specific mask 𝑚 𝑖 .
The influence score 𝐼 (𝑑 tgt , 𝑑𝑖trn , 𝑓 ) for each target sample 𝑑 tgt is defined as follow:
trn

trn


𝐼 (𝑑 tgt , 𝑑𝑖trn , 𝑓 ) = L ( 𝑓 ℎ (𝑑𝑖 ) , 𝑑 tgt ) − L ( 𝑓 ℎ (𝑑𝑖 ) , 𝑑 tgt ),
where 𝑚
f𝑖 is the flipped mask of the original mask 𝑚 𝑖 , i.e., 𝑚
f𝑖 = 𝑝1 − 𝑚 𝑖 , and 𝑓 𝑚𝑖 is
the sub-network of the model with the mask 𝑚 𝑖 applied. Intuitively, the influence score
indicates the contribution of a training instance 𝑑𝑖trn to the target instance 𝑑 tgt . A positive
influence score indicates 𝑑𝑖trn reduces the loss of 𝑑 tgt and a negative influence score
indicates 𝑑𝑖trn increases the loss of 𝑑 tgt , and the magnitude of the score indicates how
strong the influence is. To calculate the total influence score of a training data 𝑑𝑖trn over
tgt tgt
tgt
multiple samples from a given target set 𝐷 tgt = {𝑑1 , 𝑑2 , . . . , 𝑑 𝑘 }, we accumulate each
individual influence score by:
𝐼tot (𝐷 tgt , 𝑑𝑖trn , 𝑓 ) =

𝐾
∑︁

tgt

𝐼 (𝑑 𝑗 , 𝑑𝑖trn , 𝑓 ).

𝑗=1

The total influence score 𝐼tot can be used to remove harmful instances, which only
add noise or hinder generalization of the model, from the training set by removing top-𝑛%
of training instances with the smallest total influence score from the training data. We
refer to our data cleansing method as influence-based cleansing which can remove noisy
data and further improve model robustness and adaptability.

4
4.1

Experiment 1: Fine-tuning LMs with Robust Loss Functions
Experiment Set-up

We set up the baseline of our experiment from [25], an SVM model trained with features
extracted from extracted by using TF-IDF. We try five different pre-trained BERT-based
models, including ALBERT-base [13], BERT-base, BERT-large [4], RoBERTa-base,
and RoBERTa-large [17]. We fine-tune the models on FakeNews-19 train set with
the classification layers on the top exploiting the pre-trained models provided by [36].
We train each model with four different loss functions, which are CE, SCE, GCE,
and CL. The hyperparameters are searched with learning rate of 1e−6, 3e−6, 5e−6
and epoch of 1, 3, 5, 10 and the best combination is chosen based on performance on
FakeNews-19 validation set. The robustness of fine-tune models is then evaluated on

Model Generalization on COVID-19 Fake News Detection

5

Table 3: Results on FakeNews-19 test set using large language models. Underline
indicates the best performance on each model. Acc. and W-F1 stands for Accuracy and
weighted F1 respectively. SVM is placed under the column of CE for ease of comparison.
Loss Functions
Models
TF-IDF SVM [25]
ALBERT-base
BERT-base
BERT-large
RoBERTa-base
RoBERTa-large

CE

SCE

GCE

CL

Acc. W-F1 Acc. W-F1 Acc. W-F1 Acc. W-F1
93.32
97.34
97.99
97.15
97.94
98.13

93.32
97.33
97.99
97.14
97.94
98.13

96.82
97.15
96.92
97.52
97.90

96.82
97.14
96.91
97.51
97.89

96.45
97.66
97.29
97.57
97.48

96.44
97.66
97.28
97.56
97.47

96.73
97.71
97.24
97.62
97.48

96.72
97.7
97.23
97.61
97.47

both FakeNews-19 and Tweets-19 test sets. In this experiment, we mainly focus our
evaluation on the Weighted-F1 (W-F1) score.

4.2

Experimental Results

Table 3 reports the result of on FakeNews-19 task. Across all settings, RoBERTa-large
trained with CE loss function achieved the highest W-F1 scores, 98.13%, with a gain
of 4.81% in W-F1 compared to the TF-IDF SVM baseline. Except for BERT-large, all
other models achieved their best performance when fine-tuned with CE loss function.
The robust loss functions did not contribute in terms of improving the performance of
predicting the labels. In other words, the large-scale LMs could extract high-quality
features that the noise with FakeNews-19 was barely available for the robust loss
functions to contribute.
In Table 4, we show the inference results on Tweets-19; unlike the successful result
on FakeNews-19 RoBERTa-large with CE scores only 33.65% of W-F1 on Tweets-19,
showing that the generalization of the model is not successful. Instead, the highest
performance could be achieved with BERT-large with SCE with 38.18%, which is 4.53%
gain compared to RoBERTa-large with CE. Interestingly, across all models, the highest
performance when fine-tuned with the robust loss functions, SCE, GCE, and CL. This
shows the robust loss functions help to improve the generalization ability of models.
For instance, the RoBERTa-large could gain 3.85% with CL loss function, compared to
its performance with CE. Considering that RoBERTa-large with CL achieves 97.47%,
which is only 0.66% loss from the highest performance, it can be considered as a fair
trade-off for selecting RoBERTa-large with CL could as a robust model, which achieves
high performance on FakeNews-19 as well as generalizes better on Tweets-19.
Overall, while LMs with robust loss functions could achieve the highest 98.13% and
lowest 96.44% on FakeNews-19, performance on Tweets-19 is comparatively poor
as lower than 40% and even results in 22.85% lowest for W-F1. It could be inferred
that the test set distributions are distinct although they are both related to COVID-19
infodemic and share the same data source, Twitter. This could be explained that CL is

6

Bang et al.

Table 4: Results on Tweets-19 test set of large language model classifiers. Underlined
results indicate the highest performance within each model.
Loss Functions

CE

SCE

GCE

CL

Models

Acc. W-F1

Acc. W-F1

Acc. W-F1

Acc. W-F1

ALBERT-base
BERT-base
BERT-large
RoBERTa-base
RoBERTa-large

35.38
23.08
32.69
28.08
33.85

35.07
22.85
32.57
28.08
33.65

36.15
33.08
38.85
36.92
31.54

35.69
32.93
38.18
36.38
31.47

37.69
31.15
32.69
33.46
31.92

37.16
31.10
32.57
33.24
31.84

33.85
24.62
31.54
29.62
38.08

33.59
24.50
31.47
29.61
37.50

more robust to noisy labels, where FakeNews-19 labels are considered to be noisy to
Tweets-19 test set. Further analysis is in Section 6.1.

5
5.1

Experiment 2: Data Cleansing with Influence Calculation
Experiment Set-up

We first fine-tune a pre-trained RoBERTa-large model with FakeNews-19 train set while
applying turn-over dropout to the weight matrix on the last affine transformation layer
of the model with dropout probability of 𝑝 = 0.5. We calculate the total influence
score from the resulting model to the validation sets of FakeNews-19 and Tweets-19.
We investigate the effectiveness of our data cleansing approach by removing 𝑛% of
training instances with the smallest total influence score with 𝑛 = {1, 25, 50, 75, 99}.
Then, we retrain the models from the remaining training data and perform an evaluation
of the retrained model. All the models are trained with Cross-Entropy loss function
with a fixed learning rate of 3e−6. We run the model for 15 epochs with the early
stopping of 3. As the baseline, we compare our method with three different approaches:
1) pre-trained RoBERTa-large model without additional fine-tuning, 2) RoBERTa-large
model fine-tuned with all training data without performing any data cleansing, and 3)
model trained with random cleansing using the same cleansing percentage. We run each
experiment five times with different random seeds to measure the evaluation performance
statistics from each experiment.
5.2

Experiment Result

Based on our experiment results in Table 5, our influence-based cleansing method
performs best for Tweets-19 when the cleansing percentage is at 99% by only using
64 most influential training data. When cleansing percentage ≥ 25%, our influencecleansed model outperforms the model without cleansing and the model with the
random cleansing approach in terms of both accuracy and W-F1. The pre-trained model
without fine-tuning (i.e. 0 training instance) results in 34.36% and 46.24% W-F1 on
FakeNews-19 and Tweets-19 respectively. Our best model produces a significantly
higher F1-score compared to the pre-trained model without fine-tuning by a large margin

Model Generalization on COVID-19 Fake News Detection

7

Table 5: Results on FakeNews-19 test set and Tweets-19 test set using Data cleansing
approach. Model performance is explored when 𝑛% of harmful instances are dropped
from the training. We run the experiments 5 times and report the mean. The underlined
value indicates a higher value for comparing Influence vs. Random for each test set and
each row.
Drop of
Instance

Training
Instance

%

#

#

0%
1%
25%
50%
75%
99%

0
64
1605
3210
4815
6356

6420
6356
4815
3210
1605
64

FakeNews-19

Tweets-19

Influence

Random

Influence

Random

Acc. W-F1

Acc. W-F1

Acc. W-F1

Acc. W-F1

98.13
97.96
97.25
97.01
96.27
87.79

98.13
97.96
97.24
97.00
96.26
87.69

98.13
97.40
97.14
88.29
96.34
89.13

98.13
97.40
97.13
86.38
96.32
89.09

33.85
32.00
36.70
37.70
39.50
61.10

33.65
31.76
36.12
37.09
38.62
54.33

33.85
30.60
32.60
30.80
38.50
48.00

33.65
30.39
32.33
30.19
37.58
45.45

on both FakeNews-19 and Tweets-19, which means that the small set of the most
influential training data helps to significantly boost the generalization ability on both
datasets. Furthermore, even with a high cleansing percentage, our model can maintain
high evaluation performance on the FakeNews-19. Specifically, our model with a 99%
cleansing percentage can produce an evaluation performance of 61.10% accuracy score
and 54.33% W-F1 score on Tweets-19 and 87.79% accuracy score and 87.69% W-F1
score on FakeNews-19. With this method, we could achieve an absolute gain of 20.69
W-F1 on Tweets-19, a much-improved generalization ability. Compared to the highest
score achieved with using the full data for training, however, there is a trade-off with
10.44% loss for FakeNews-19. This trade-off in performances on two test sets suggests
a potential for handling unseen data set during the training phase.

6
6.1

Discussion
Data Distribution between different FakeNews-19 and Tweets-19 Test Sets

Although both data set built to address COVID-19 fake-news and share the same data
collection source, tweets, the results show that the models trained on FakeNews-19 could
achieve relatively lower performance on Tweets-19 test set. (Note that the Tweets-19 consists of the only test set with relatively smaller scale compared to FakeNews-19.) For
further understanding, we visualize features extracted by the best performing model
right before the classification layers with t-SNE. As shown in Figure 1, even though
the features of FakeNews-19 test set can distinguish the “Fake” and “Real” labels, the
features of Tweets-19 cannot separate the two labels quite well.
6.2

How did smaller data help for generalization ability of the model?

As mentioned in Subsection 5.2, higher cleansing percentage tends to lead to higher
evaluation F1 score. By using the model trained with top 1% influential instances, we

8

Bang et al.

80

80

train_fake
train_real
test_fake
test_real

60

train_fake
train_real
test_fake
test_real

60

40

40

20

20

0

0

20

20

40

40

60

60
80

80
80

60

40

20

0

20

40

60

80

(a) FakeNews-19 test set.

60

40

20

0

20

40

60

(b) Tweets-19 test set.

Fig. 1: Datasets distribution comparison with FakeNews-19 training set using t-SNE.
While the distributions within FakeNews-19 kept to be similar, the distribution of
Tweets-19 is significantly different.

train_whole_fake
train_whole_real
train_fake
train_real

60

40

20

20

0

0

20

20

40

40

60

60
75

50

25

0

25

50

75

(a) FakeNews-19 train set.

train_fake
train_real
test_fake
test_real

60

40

80

train_fake
train_real
test_fake
test_real

60
40
20
0
20
40
60

75

50

25

0

25

50

75

(b) FakeNews-19 test set.

75

50

25

0

25

50

75

(c) Tweets-19 test set.

Fig. 2: Datasets distribution comparison with top 1% influential training samples using
t-SNE. Top 1% influential samples are distributed fairly evenly over the whole training set
(a), thus the extracted test features remain separable (b), and the Tweets-19 distribution
is captured better than trained with the full training set (c).

extract sentence representation as depicted in Figure 2. Similar to in Figure 1, the same
number of instances from the test set are randomly selected for better understanding. Top
1% influential instances are fairly evenly sampled from the whole training set, and this
small subset of the training set is enough to produce the distribution to separate the test
features, which supports the effectiveness of the influential score. Moreover, since the
top 1% samples are more sparse, the trained model can flexibly deal with samples from
unseen distributions, resulting in extracted features of higher quality.
For the performance on Tweets-19 test set, we take additional consideration on
binary-Recall (B-Rec.), binary-Precision (B-Prec.), and binary-F1 (B-F1) scores to
further analyze the generalization ability of the model. As shown in Table 6, the model
with around 99% data cleansing achieves the best per class F1-score with 37.17% B-F1
score on the fake label and 71.50% on the real label. In general, the “Fake” B-Pre and
“Real” B-Rec scores increase as the cleansing percentage increase, while “Real” B-Pre
and “Fake” B-Rec behave the other way around, which means the model with higher
cleansing percentage capture more real news and reduce the number of false “Fake” label

Model Generalization on COVID-19 Fake News Detection

9

Table 6: Binary evaluation results of influence-based data cleansing model on
Tweets-19 test set. B-F1, B-Rec., and B-Pre. denotes binary F1, binary recall, and binary
precision scores respectively. Bold denotes the best performance over all experiments.

Drop

Fake

Real

%

B-F1

B-Rec.

B-Pre.

B-F1

B-Rec.

B-Pre.

0%
1%
25%
50%
75%
99%

28.80 ± 1.06
29.06 ± 1.17
30.56 ± 1.23
31.02 ± 0.75
31.51 ± 0.85
37.17 ± 2.20

99.29 ± 1.60
99.29 ± 1.60
99.29 ± 1.60
100.0 ± 0.00
99.29 ± 1.60
81.43 ± 9.24

16.85 ± 0.71
17.03 ± 0.82
18.07 ± 0.88
18.36 ± 0.52
18.73 ± 0.66
24.28 ± 2.53

33.33 ± 5.25
34.46 ± 7.49
41.67 ± 6.11
43.16 ± 3.02
45.72 ± 4.47
71.50 ± 6.92

20.12 ± 3.80
21.05 ± 5.43
26.51 ± 5.01
27.56 ± 2.49
29.77 ± 3.97
57.79 ± 9.59

99.44 ± 1.24
99.58 ± 0.93
99.65 ± 0.78
100.0 ± 0.00
99.69 ± 0.70
95.23 ± 1.65

with the trade-off of capturing less true ‘Fake” label. Overall, the B-F1 for each labels
increases as the cleansing percentage increase. Our influence-based cleansing method
outperforms the model without data cleansing by a large margin with 8.37% for the
“Fake” B-F1 and 38.17% for the “Real” B-F1.

7

Related Works

COVID-19 Infodemic Research in Natural Language Processing In recent months,
researchers took various approaches to tackle the problem of COVID-19 Infodemic.
Wang et. al [32] released centralized data CORD-19 that covers 59,000 scholarly articles
about COVID-19 and other related coronaviruses to encourage other studies. Singh
et. al [29] analyzed the global trend of tweets at the first emergence of COVID-19. To
understand the diffusion of information, [3,27] analyze the patterns of spreading COVID19 related information and also quantify the rumor amplification across different social
media platforms. Alam et. al [1] focuses on fine-grained disinformation analysis on both
English and Arabic tweets for the interests of multiple stakeholders such as journalists,
fact-checkers, and policymakers. Kar et. al [8] proposes a multilingual approach to detect
fake news about COVID-19 from Twitter posts.
Generalization ability of models As described in the previous section, several NLP
studies involve emerging COVID-19 infodemic yet the generalization aspect is neglected
although it is essential to accelerate industrial application development. In recent years,
along with the introduction of numerous tasks in various domains, the importance of
model generalization ability with a tiny amount or even without additional training
datasets has been intensely discussed. In general, recent works on model generalizability
can be divided into two different directions: 1) adaptive training and 2) robust loss function.
In adaptive training, different meta-learning [5] and fast adaptation [20,35,18] approaches
have been developed and show promising result for improving the generalization of the
model over different domains. Another meta-learning approach, called meta transfer

10

Bang et al.

learning [34], improves the generalization ability for a low-resource domain by leveraging
a high-resource domain dataset. In robust loss function, different kind of robust loss
functions such as symmetric cross-entropy [33], generalized cross-entropy [39], and
curriculum loss [19] have been shown to produce a more generalized model compared
to cross-entropy loss due to its robustness towards noisy-labeled instances or so-called
outliers from the training data. In addition to these approaches, data de-noising could
actually improve model performance [15], thus, a data cleansing technique with identifying
influential instances in the training dataset is proposed to further improve the evaluation
performance and generalization ability of the models [6,10].

8

Conclusion

We investigated the COVID-19 fake-news detection task with an aim of achieving a
robust model that could perform high for the CONSTRAINT shared task and also have
high generalization ability with two separate approaches. The robust loss functions,
compared to the traditional cross-entropy loss function, do not help much in improving
F1-score on FakeNews-19 but showed better generalization ability on Tweets-19 with
a fair trade-off as shown with the result comparison between RoBERTa-large with CE
and CL. By performing influence data cleansing with high cleansing percentage (≥
25%), we can achieve a better F1-score over multiple test sets. Our best model with 99%
cleansing percentage can achieve the best evaluation performance on Tweets-19 with
61.10% accuracy score and 54.33% W-F1 score while still maintaining high enough
test performance on FakeNews-19. This suggests how we could use the labeled data to
solve the problem of fake-news detection while model generalization ability should also
be taken into account. For future work, we would like to combine the adaptive training,
robust loss function with the influence score data cleansing method such that the resulting
influence score can be made more robust for handling unseen or noisy data.

References
1. Alam, F., Dalvi, F., Shaar, S., Durrani, N., Mubarak, H., Nikolov, A., Martino, G.D.S., Abdelali,
A., Sajjad, H., Darwish, K., Nakov, P.: Fighting the covid-19 infodemic in social media: A
holistic perspective and a call to arms (2020)
2. Brennen, J.S., Simon, F., Howard, P.N., Nielsen, R.K.: Types, sources, and claims of covid-19
misinformation. Reuters Institute 7, 3–1 (2020)
3. Cinelli, M., Quattrociocchi, W., Galeazzi, A., Valensise, C.M., Brugnoli, E., Schmidt,
A.L., Zola, P., Zollo, F., Scala, A.: The covid-19 social media infodemic. arXiv preprint
arXiv:2003.05004 (2020)
4. Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: BERT: Pre-training of deep bidirectional
transformers for language understanding. In: Proceedings of the 2019 Conference of the
North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1. pp. 4171–4186. ACL, Minneapolis, Minnesota (Jun 2019).
https://doi.org/10.18653/v1/N19-1423, https://www.aclweb.org/anthology/N19-1423
5. Finn, C., Abbeel, P., Levine, S.: Model-agnostic meta-learning for fast adaptation of deep
networks. In: Precup, D., Teh, Y.W. (eds.) Proceedings of the 34th International Conference
on Machine Learning. Proceedings of Machine Learning Research, vol. 70, pp. 1126–1135.
PMLR, International Convention Centre, Sydney, Australia (06–11 Aug 2017)

Model Generalization on COVID-19 Fake News Detection

11

6. Hara, S., Nitanda, A., Maehara, T.: Data cleansing for models trained with sgd. In: Wallach,
H., Larochelle, H., Beygelzimer, A., d'Alché-Buc, F., Fox, E., Garnett, R. (eds.) Advances
in Neural Information Processing Systems. vol. 32, pp. 4213–4222. Curran Associates, Inc.
(2019)
7. Hu, W., Niu, G., Sato, I., Sugiyama, M.: Does distributionally robust supervised learning give
robust classifiers? In: International Conference on Machine Learning. pp. 2029–2037. PMLR
(2018)
8. Kar, D., Bhardwaj, M., Samanta, S., Azad, A.P.: No rumours please! a multi-indic-lingual
approach for covid fake-tweet detection (2020)
9. Karimi, D., Dou, H., Warfield, S.K., Gholipour, A.: Deep learning with noisy labels: exploring
techniques and remedies in medical image analysis. Medical Image Analysis 65, 101759
(2020)
10. Kobayashi, S., Yokoi, S., Suzuki, J., Inui, K.: Efficient estimation of influence of a training
instance. In: Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language
Processing. pp. 41–47 (2020)
11. Kouzy, R., Abi Jaoude, J., Kraitem, A., El Alam, M.B., Karam, B., Adib, E., Zarka, J.,
Traboulsi, C., Akl, E.W., Baddour, K.: Coronavirus goes viral: quantifying the covid-19
misinformation epidemic on twitter. Cureus 12(3) (2020)
12. Kumar, H., Sastry, P.: Robust loss functions for learning multi-class classifiers. In: 2018 IEEE
International Conference on Systems, Man, and Cybernetics (SMC). pp. 687–692. IEEE
(2018)
13. Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut, R.: Albert: A lite bert for
self-supervised learning of language representations. arXiv preprint arXiv:1909.11942 (2019)
14. Lee, N., Bang, Y., Madotto, A., Fung, P.: Misinformation has high perplexity (2020)
15. Lee, N., Liu, Z., Fung, P.: Team yeon-zi at semeval-2019 task 4: Hyperpartisan news detection
by de-noising weakly-labeled data. In: Proceedings of the 13th International Workshop on
Semantic Evaluation. pp. 1052–1056 (2019)
16. Li, Y., Grandison, T., Silveyra, P., Douraghy, A., Guan, X., Kieselbach, T., Li, C., Zhang, H.:
Jennifer for COVID-19: An NLP-powered chatbot built for the people and by the people to
combat misinformation. In: Proceedings of the 1st Workshop on NLP for COVID-19 at ACL
2020. ACL, Online (Jul 2020), https://www.aclweb.org/anthology/2020.nlpcovid19-acl.9
17. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V.: Roberta: A robustly optimized BERT pretraining approach. CoRR abs/1907.11692
(2019), http://arxiv.org/abs/1907.11692
18. Liu, Z., Xu, Y., Yu, T., Dai, W., Ji, Z., Cahyawĳaya, S., Madotto, A., Fung, P.: Crossner:
Evaluating cross-domain named entity recognition (2020)
19. Lyu, Y., Tsang, I.W.: Curriculum loss: Robust learning and generalization against label
corruption. arXiv preprint arXiv:1905.10045 (2019)
20. Madotto, A., Lin, Z., Bang, Y., Fung, P.: The adapter-bot: All-in-one controllable conversational
model (2020)
21. Medford, R.J., Saleh, S.N., Sumarsono, A., Perl, T.M., Lehmann, C.U.: An" infodemic":
Leveraging high-volume twitter data to understand public sentiment for the covid-19 outbreak.
medRxiv (2020)
22. Mian, A., Khan, S.: Coronavirus: the spread of misinformation. BMC medicine 18(1), 1–2
(2020)
23. Mourad, A., Srour, A., Harmanani, H., Jenainatiy, C., Arafeh, M.: Critical impact of social
networks infodemic on defeating coronavirus covid-19 pandemic: Twitter-based study and
research directions. arXiv preprint arXiv:2005.08820 (2020)
24. Patwa, P., Bhardwaj, M., Guptha, V., Kumari, G., Sharma, S., PYKL, S., Das, A., Ekbal,
A., Akhtar, M.S., Chakraborty, T.: Overview of constraint 2021 shared tasks: Detecting

12

25.
26.

27.
28.
29.

30.

31.

32.

33.

34.

35.

36.

37.
38.

39.

Bang et al.
english covid-19 fake news and hindi hostile posts. In: Proceedings of the First Workshop
on Combating Online Hostile Posts in Regional Languages during Emergency Situation
(CONSTRAINT). Springer (2021)
Patwa, P., Sharma, S., PYKL, S., Guptha, V., Kumari, G., Akhtar, M.S., Ekbal, A., Das, A.,
Chakraborty, T.: Fighting an infodemic: Covid-19 fake news dataset (2020)
Pennycook, G., McPhetres, J., Zhang, Y., Lu, J.G., Rand, D.G.: Fighting covid-19 misinformation on social media: Experimental evidence for a scalable accuracy-nudge intervention.
Psychological science 31(7), 770–780 (2020)
Shahi, G.K., Dirkson, A., Majchrzak, T.A.: An exploratory study of covid-19 misinformation
on twitter (2020)
Shao, C., Hui, P.M., Wang, L., Jiang, X., Flammini, A., Menczer, F., Ciampaglia, G.L.:
Anatomy of an online misinformation network. PloS one 13(4), e0196087 (2018)
Singh, L., Bansal, S., Bode, L., Budak, C., Chi, G., Kawintiranon, K., Padden, C., Vanarsdall,
R., Vraga, E., Wang, Y.: A first look at covid-19 information and misinformation sharing on
twitter. arXiv preprint arXiv:2003.13907 (2020)
Su, D., Xu, Y., Yu, T., Siddique, F.B., Barezi, E.J., Fung, P.: Caire-covid: A question
answering and multi-document summarization system for covid-19 research. arXiv preprint
arXiv:2005.03975 (2020)
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L.,
Polosukhin, I.: Attention is all you need. CoRR abs/1706.03762 (2017), http://arxiv.org/abs/
1706.03762
Wang, L.L., Lo, K., Chandrasekhar, Y., Reas, R., Yang, J., Eide, D., Funk, K., Kinney, R.M.,
Liu, Z., Merrill, W., Mooney, P., Murdick, D., Rishi, D., Sheehan, J., Shen, Z., Stilson, B.,
Wade, A.D., Wang, K., Wilhelm, C., Xie, B., Raymond, D., Weld, D.S., Etzioni, O., Kohlmeier,
S.: Cord-19: The covid-19 open research dataset. ArXiv (2020)
Wang, Y., Ma, X., Chen, Z., Luo, Y., Yi, J., Bailey, J.: Symmetric cross entropy for robust
learning with noisy labels. In: Proceedings of the IEEE International Conference on Computer
Vision. pp. 322–330 (2019)
Winata, G.I., Cahyawĳaya, S., Lin, Z., Liu, Z., Xu, P., Fung, P.: Meta-transfer learning
for code-switched speech recognition. In: Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics. pp. 3770–3776. ACL, Online (Jul 2020).
https://doi.org/10.18653/v1/2020.acl-main.348, https://www.aclweb.org/anthology/2020.aclmain.348
Winata, G.I., Cahyawĳaya, S., Liu, Z., Lin, Z., Madotto, A., Xu, P., Fung, P.: Learning
fast adaptation on cross-accented speech recognition. In: Meng, H., Xu, B., Zheng, T.F.
(eds.) Interspeech 2020, 21st Annual Conference of the International Speech Communication
Association. pp. 1276–1280. ISCA (2020). https://doi.org/10.21437/Interspeech.2020-0045
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf,
R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C.,
Le Scao, T., Gugger, S., Drame, M., Lhoest, Q., Rush, A.: Transformers: State-of-the-art natural
language processing. In: Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing: System Demonstrations. pp. 38–45. Association for Computational
Linguistics (Oct 2020)
Xia, X., Liu, T., Han, B., Wang, N., Gong, M., Liu, H., Niu, G., Tao, D., Sugiyama, M.:
Part-dependent label noise: Towards instance-dependent label noise (2020)
Xiong, J., Lipsitz, O., Nasri, F., Lui, L.M., Gill, H., Phan, L., Chen-Li, D., Iacobucci, M., Ho,
R., Majeed, A., et al.: Impact of covid-19 pandemic on mental health in the general population:
A systematic review. Journal of affective disorders (2020)
Zhang, Z., Sabuncu, M.: Generalized cross entropy loss for training deep neural networks with
noisy labels. In: Advances in neural information processing systems. pp. 8778–8788 (2018)

