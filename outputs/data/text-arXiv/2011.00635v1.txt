1

Screening for an Infectious Disease
as a Problem in Stochastic Control
arXiv:2011.00635v1 [physics.soc-ph] 1 Nov 2020

Jakub Mareček

Abstract—There has been much recent interest in screening populations for an infectious disease. Here, we present a
stochastic-control model, wherein the optimum screening policy
is provably difficult to find, but wherein Thompson sampling
has provably optimal performance guarantees in the form of
Bayesian regret. Thompson sampling seems applicable especially
to diseases, for which we do not understand the dynamics well,
such as to the super-spreading COVID-19.

I. I NTRODUCTION
There has been much recent interest in screening populations for a an infectious disease. In the case of COVID-19,
data from contact-tracing apps [1, 2, 3, 4, 3, e.g.], esp. [5],
suggest that mortality is negatively associated with the number
of tests performed in the given community, esp. in low-income
countries and countries with lower government-effectiveness
scores [5, 6]. While the association does not imply causation,
once the number of tests required by contact tracing exceeds
the capacity for performing tests [3], or once the contact
tracing becomes futile by other means, the importance of
statistical approaches to the allocation of tests to communities
[7, 8, 9] and, hypothetically, [10], individuals, becomes clear.
Screening for an infectious disease, especially in a pandemic, has two conflicting goals: one goal is to stop the spread
of the disease and one goal is to understand the spread of the
disease as precisely as possible. The former goal may lead
to increasing the intensity of testing in communities, where
the disease has spread widely. The latter goal may lead to
uniform sampling from the population, perhaps using tests of
limited accuracy, as exemplified by Slovakia [11], which has
tested the entirety of its population with immunoassays over
a weekend. These two goals are conflicting, but their conflict
is well understood in Stochastic Control [12, 13].
Indeed, Stochastic Control could be seen as a field concerned with the balancing the trade-off between “exploration”
and “exploitation” [13]. In exploration, we aim to learn the
stochastic processes [14] involved. In exploitation, one wishes
to utilise the current estimates of the stochastic processes
involved to optimize a functional, such as the long-run sum
of the persons infected. Notice that the exploitation and
exploration does not necessarily map to the short-term and
long-term objectives in disease control: long-term disease
control requires both exploration and exploitation, and hence
the balancing the trade-off.
In contrast, there seems to be a mismatch between the
techniques used for screening for an infectious diseases at the
J. Marecek is at the Czech Technical University, Prague, the Czech
Republic.
Manuscript received November 3, 2020.

moment and the challenges of COVID-19. Some of the methods for screening for an infectious diseases [9, e.g.] are rooted
in traditional compartmental models of Epidemiology, while
others are data-driven. In Computer Science and Statistics,
date-driven models are often based on multi-agent techniques
[15, 16, e.g.], or graph-theoretic considerations [10, e.g.].
In Epidemiology [17], there are very many compartmental
models [17], raging from the simple SIR model [18], which
recognises three stages,to SIDARTHE [4], which recognises
eight stages of infection. It is, however, increasingly recognised [19, 20] that such models may be of limited utility in
screening for novel diseases, which are super-spreading, allow
for reinfections, and may overwhelm the healthcare system, for
several reasons: First, it is non-trivial to identify parameters of
the compartmental models, until a substantial number of cases
of the novel disease is documented in a particular intervention
regime. Second, and more importantly, the compartmental
models underestimate the variance of the associated stochastic
processes in so-called super-spreading diseases.1 Third, many
widely studied compartmental models (SI, SIR, SEIR, . . . ,
SIDARTHE) do not model reinfections2 , not only because of
the prevalence of diseases with “immunizing infections,” but
also for technical reasons [28]. Fourth, compartmental models
that allow for the study of the impact of a test assume that
individuals can be effectively isolated, once tested positive,
while the overloaded healthcare systems may not be able to
prevent further infections by those who have tested positive.
While one can and should make forecasts based on the current
models [29], one should also realise that the dynamics are
uncertain [29] and that that modelling the stochastic aspects
better [14] may be beneficial [30].
Based on a long history of work in Stochastic Control [12,
13], we present several insights into monitoring the spread of
diseases, for which we do not understand the dynamics well,
such as the super-spreading COVID-19. Overall, our aims are
three-fold:
•
•

•

to remove as many assumptions from the screening for
an infectious disease as possible,
to study the computational complexity [31] of allocating
the budget of tests [32] independent of any conjectures
?
(e.g., P=NP [31]), and
to guarantee optimality of practical algorithms for the
same problem.

1 Statements such as “offspring distribution of COVID-19 is highly overdispersed” with k = 0.1 [21] suggests that “10% of cases lead to 80% of the
spread” [21], which is hard to model in the compartmental models.
2 Reinfections are also well documented [22, 23], although their numbers
[24, 25, 26, 27] and impact [27] are still unclear.

2

II. O UR A PPROACH
Stochastic Models: Our first suggestion is to consider the
stochastic aspects of the problem explicitly, starting with the
fact that the tests are imperfect.3 Consider the hypothetical
situation, where we performed multiple low-accuracy tests of
a single person, or perhaps a sequence of tests of increasing
accuracy. We should like to consider both the outcomes of the
tests for that person, as in their mean, but also some measure
of variance of the outcomes for that person, in deciding
whether to test further.4 If at some point, everyone quarantined
perfectly, and there were an unlimited capacity to perform
the tests, the screening would be reduced to the so-called
multi-armed bandit problem (MAB) [13] in Stochastic Control
[12, 13]. (See the Supplementary material for a definition.)
If the capacity to perform tests were limited, this would
correspond to the combinatorial variant [35, 36] of the MAB,
which is substantially harder [37]. If, however, the disease
spreads, these models are no longer useful and one has to
consider the so-called restless bandits [38, 13].
In particular, in modelling the spread of the disease as
restless bandits, the stochastic process could be the positivity
rate in a particular region or community, for example with the
sampling frequency of a day. One could have several stochastic
processes, one for each community. There are no assumptions
on the evolution of the stochastic process, including no assumptions of the independently identically distributed random
variables.
Computational Complexity: Consider problem of whom
to test given a budget of tests [32]. For example in COVID-19,
the reported symptom of loss of taste and/or smell was most
strongly associated with a positive test result [1, 39], so in the
short term, it may be beneficial to test symptomatic patients.
It is clear, however, that this is suboptimal in the long run,
where one also needs to test asymptomatic individuals [9] in
communities where no (or few) tests have been positive, so
far. Our second insight is that in the restless-bandit model
outlined in the previous paragraph, the problem of whom to
test given a budget of tests [32], is computationally hard. In the
language of computational complexity, its approximation to
any non-trivial factor is complete for polynomial-space Turing
machines [40]. This suggests that independent of any unproven
conjectures, the problem is as hard as any computation that
can be performed using a polynomial amount of space on
the Turing machine in any amount of time. This is based on
the well-known complexity results for the restless multi-armed
3 The probability of detecting disease conditional on the person tested being
infected is less than one. This is true for chest CT and RT-PCR [33] and
immunoassays. Likewise, the probability of detecting disease conditional on
the person tested not being infected is larger than zero [33]. The probability
of a person passing the infection, conditional on them testing positive, is still
very much less than one for superspreading [19] diseases.
4 A classical policy [12] considers the so-called upper confidence bound
(UCB1) based on Hoeffding’s Inequality [12]. Following n tests in aggregate,
out of which ni tests have been performed on individual
i with mean outcome
q
ln n
. Each day, individuals
µi , individual i will receive an “index” µi + 2 n
i
with the highest indices are chosen for a test, up to the capacity. An alternative
policy, known as Thompson sampling [34], selects the individual according
to the probability that it is optimal, considering some prior.

bandit problem [38, 41, 13], under very modest assumptions,
as we detail in the Supplementary Material.
Optimality of Thompson sampling: Our third insight is
that there are (asymptotically) optimal algorithms for the
screening problem, despite the complexity results. Moreover,
these optimal algorithms can be as simple as Thompson sampling [34, 42], which is a natural approach, wherein one draws
a random sample θl from a prior, applies actions that maximize
expected reward considering the sample θl drawn, observes
the outcome, and updates the prior using the observation of
the outcome. This is repeated, possibly daily, as suggested in
Algorithm 1 in the Supplementary Material.
While the second and third insights may seem contradictory,
especially considering that – until recently – the best guarantees [43]
√ for the restless multi-armed bandit problem suggested
an Õ( T ) bound on the average of the distance between the
optimal action and the action chosen by the algorithm (regret)
by time T for an algorithm that is intractable
in general. More
√
recent work [44, 45] allows for the Õ( T ) bound on the regret
using Thompson sampling, the classic algorithm [34, 42], both
in the special case of binary rewards, where in the testing of
individuals there are binary [44] (either an infected person tests
positive with reward 1, or we do not receive any reward), and
in a more general episodic case [45]. These are applicable to
the two variants of the problem discussed above.
This can be seen as a complement to the more traditional
model-based optimal control [46, 47, 48, 49, 50, 51, 52, 53]
for the introduction of the restrictions.
Making it Practical: In order to make the optimal algorithms practically relevant, one needs to choose the prior
wisely. The specifics depend, obviously, on the nature of the
data available. CMU Delphi lab 5 , for instance, makes 10
different graphs available, outside of any data from any testand-trace application. On such a dataset, for instance, Kemenybased priors [10] or highest-degree-first [54, e.g.] priors may
work well, as documented by clinical trials in other diseases
[54, e.g.]. One may also consider extensions drawing on work
in reinforcement learning [55].
III. C ONCLUSIONS
There has been a substantial amount of proposal as to how
to screen for COVID-19, under a variety of strong assumptions. We present a very natural approach to removing the
assumptions. This seems particularly useful in diseases, whose
dynamics are poorly understood, but may be superspreading
and allow for reinfections, e.g., COVID-19. Within this model,
well-known policies from stochastic control come with strong
performance guarantees (Bayesian regret bounds) relative to
the best possible deterministic policies in hindsight. Such an
optimum deterministic policy, e.g., based on contact tracing,
are, however, unknown a priori. Our guarantees are optimal
up to a logarithmic factor.

5 https://cmu-delphi.github.io/delphi-epidata/api/covidcast

signals.html

3

R EFERENCES
[1] W. E. Allen, H. Altae-Tran, J. Briggs, X. Jin, G. McGee,
A. Shi, R. Raghavan, M. Kamariza, N. Nova, A. Pereta
et al., “Population-scale longitudinal mapping of covid19 symptoms, behaviour and testing,” Nature Human
Behaviour, vol. 4, no. 9, pp. 972–982, 2020.
[2] J. A. Schneider and H. A. Pollack, “Flipping the script
for coronavirus disease 2019 contact tracing,” in JAMA
Health Forum, vol. 1, no. 9. American Medical Association, 2020, pp. e201 129–e201 129.
[3] A. Aleta, D. Martı́n-Corral, A. P. y Piontti, M. Ajelli,
M. Litvinova, M. Chinazzi, N. E. Dean, M. E. Halloran,
I. M. Longini Jr, S. Merler et al., “Modelling the impact
of testing, contact tracing and household quarantine on
second waves of covid-19,” Nature Human Behaviour,
vol. 4, no. 9, pp. 964–971, 2020.
[4] G. Giordano, F. Blanchini, R. Bruno, P. Colaneri,
A. Di Filippo, A. Di Matteo, and M. Colaneri, “Modelling the covid-19 epidemic and implementation of
population-wide interventions in italy,” Nature Medicine,
pp. 1–6, 2020.
[5] L.-L. Liang, C.-H. Tseng, H. J. Ho, and C.-Y. Wu,
“Covid-19 mortality is negatively associated with test
number and government effectiveness,” Scientific reports,
vol. 10, no. 1, pp. 1–7, 2020.
[6] L. Brotherhood, P. Kircher, C. Santos, and M. Tertilt,
“An economic model of the covid-19 epidemic: The
importance of testing and age-specific policies,” 2020.
[7] M. E. Kretzschmar, G. Rozhnova, M. C. J. Bootsma,
M. van Boven, J. H. H. M. van de Wijgert, and M. J. M.
Bonten, “Impact of delays on effectiveness of contact
tracing strategies for covid-19: a modelling study,” The
Lancet Public Health, vol. 5, no. 8, pp. e452 – e459,
2020.
[8] D. M. Gray, A. Anyane-Yeboa, S. Balzora, R. B. Issaka,
and F. P. May, “Covid-19 and the other pandemic: populations made vulnerable by systemic inequity,” Nature
Reviews Gastroenterology & Hepatology, vol. 17, no. 9,
pp. 520–522, 2020.
[9] M. Mueller, P. M. Derlet, C. Mudry, and G. Aeppli,
“Testing of asymptomatic individuals for fast feedbackcontrol of covid-19 pandemics,” Physical Biology, 2020.
[10] S. Yilmaz, E. Dudkina, M. Bin, E. Crisostomi, P. Ferraro,
R. Murray-Smith, T. Parisini, L. Stone, and R. Shorten,
“Kemeny-based testing for covid-19,” arXiv e-prints, pp.
arXiv–2006, 2020.
[11] E. Holt, “Slovakia to test all adults for sars-cov-2,” The
Lancet, vol. 396, no. 10260, pp. 1386 – 1387, 2020.
[12] N. Cesa-Bianchi and G. Lugosi, Prediction, learning, and
games. Cambridge university press, 2006.
[13] J. Gittins, K. Glazebrook, and R. Weber, Multi-armed
bandit allocation indices. John Wiley & Sons, 2011.
[14] J. Dureau, K. Kalogeropoulos, and M. Baguelin, “Capturing the time-varying drivers of an epidemic using
stochastic dynamical systems,” Biostatistics, vol. 14,
no. 3, pp. 541–555, 2013.
[15] D. Adam, “Special report: The simulations driving the

[16]

[17]

[18]

[19]

[20]

[21]

[22]

[23]

[24]
[25]

[26]
[27]

[28]

[29]

[30]

world’s response to covid-19.” Nature, vol. 580, no. 7803,
p. 316, 2020.
N. Ferguson, D. Laydon, G. Nedjati Gilani, N. Imai,
K. Ainslie, M. Baguelin, S. Bhatia, A. Boonyasiri, Z. Cucunuba Perez, G. Cuomo-Dannenburg et al., “Report
9: Impact of non-pharmaceutical interventions (npis) to
reduce covid19 mortality and healthcare demand,” 2020.
R. M. Anderson, B. Anderson, and R. M. May, Infectious
diseases of humans: dynamics and control.
Oxford
university press, 1992.
W. O. Kermack and A. G. McKendrick, “A contribution
to the mathematical theory of epidemics,” Proceedings of
the Royal society of London. Series A, Containing papers
of a mathematical and physical character, vol. 115, no.
772, pp. 700–721, 1927.
J. O. Lloyd-Smith, S. J. Schreiber, P. E. Kopp, and
W. M. Getz, “Superspreading and the effect of individual
variation on disease emergence,” Nature, vol. 438, no.
7066, pp. 355–359, 2005.
D. Adam, P. Wu, J. Wong, E. Lau, T. Tsang,
S. Cauchemez, G. Leung, and B. Cowling, “Clustering
and superspreading potential of severe acute respiratory
syndrome coronavirus 2 (sars-cov-2) infections in hong
kong,” 2020.
A. Endo, S. Abbott, A. J. Kucharski, S. Funk et al.,
“Estimating the overdispersion in covid-19 transmission
using outbreak sizes outside china,” Wellcome Open
Research, vol. 5, no. 67, p. 67, 2020.
N. M. Duggan, S. M. Ludy, B. C. Shannon, A. T. Reisner,
and S. R. Wilcox, “A case report of possible novel
coronavirus 2019 reinfection,” The American journal of
emergency medicine, 2020.
K. K.-W. To, I. F.-N. Hung, K.-H. Chan, S. Yuan, W.-K.
To, D. N.-C. Tsang, V. C.-C. Cheng, Z. Chen, K.-H. Kok,
and K.-Y. Yuen, “Serum antibody profile of a patient with
covid-19 reinfection,” Clinical Infectious Diseases, 2020.
M. Ota, “Will we see protection or reinfection in covid19?” 2020.
M. Gousseff, P. Penot, L. Gallay, D. Batisse, N. Benech,
K. Bouiller, R. Collarino, A. Conrad, D. Slama, C. Joseph
et al., “Clinical recurrences of covid-19 symptoms after
recovery: viral relapse, reinfection or inflammatory rebound?” Journal of Infection, 2020.
S. Roy, “Covid-19 reinfection: Myth or truth?” SN Comprehensive Clinical Medicine, pp. 1–4, 2020.
M. A. Çenesiz and L. Guimarães, “Covid-19: What
if immunity wanes?” arXiv preprint arXiv:2008.03283,
2020.
M. J. Keeling, T. House, A. J. Cooper, and L. Pellis, “Systematic approximations to susceptible-infectioussusceptible dynamics on networks,” PLoS computational
biology, vol. 12, no. 12, p. e1005296, 2016.
C. M. Saad-Roy, C. E. Wagner, R. E. Baker, S. E.
Morris, J. Farrar, A. L. Graham, S. A. Levin, M. J. Mina,
C. J. E. Metcalf, and B. T. Grenfell, “Immune life history,
vaccination, and the dynamics of sars-cov-2 over the next
5 years,” Science, 2020.
D. S. W. Ting, L. Carin, V. Dzau, and T. Y. Wong,

4

[31]
[32]

[33]

[34]

[35]

[36]

[37]

[38]

[39]

[40]

[41]

[42]

[43]

[44]

“Digital technology and covid-19,” Nature medicine,
vol. 26, no. 4, pp. 459–461, 2020.
S. Arora and B. Barak, Computational complexity: a
modern approach. Cambridge University Press, 2009.
E. J. Emanuel, G. Persad, R. Upshur, B. Thome,
M. Parker, A. Glickman, C. Zhang, C. Boyle, M. Smith,
and J. P. Phillips, “Fair allocation of scarce medical
resources in the time of covid-19,” 2020.
T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao,
Z. Sun, and L. Xia, “Correlation of chest ct and rt-pcr
testing in coronavirus disease 2019 (covid-19) in china:
a report of 1014 cases,” Radiology, p. 200642, 2020.
W. R. Thompson, “On the likelihood that one unknown
probability exceeds another in view of the evidence of
two samples,” Biometrika, vol. 25, no. 3/4, pp. 285–294,
1933.
N. Cesa-Bianchi and G. Lugosi, “Combinatorial bandits,”
Journal of Computer and System Sciences, vol. 78, no. 5,
pp. 1404 – 1422, 2012, jCSS Special Issue: Cloud
Computing 2011.
R. Combes, M. S. T. M. Shahi, A. Proutiere et al.,
“Combinatorial bandits revisited,” in Advances in Neural
Information Processing Systems, 2015, pp. 2116–2124.
N. Merlis and S. Mannor, “Tight lower bounds for
combinatorial multi-armed bandits,” ser. Proceedings of
Machine Learning Research, J. Abernethy and S. Agarwal, Eds., vol. 125. PMLR, 09–12 Jul 2020, pp. 2830–
2857.
P. Whittle, “Restless bandits: Activity allocation in a
changing world,” Journal of applied probability, pp. 287–
298, 1988.
D. Pierron, V. Pereda-Loth, M. Mantel, M. Moranges,
E. Bignon, O. Alva, J. Kabous, M. Heiske, J. Pacalon,
R. David et al., “Smell and taste changes are early indicators of the covid-19 pandemic and political decision
effectiveness,” Nature Communications, vol. 11, no. 1,
pp. 1–8, 2020.
C. H. Papadimitriou and J. N. Tsitsiklis, “The complexity
of optimal queuing network control,” Mathematics of
Operations Research, pp. 293–305, 1999.
R. R. Weber and G. Weiss, “On an index policy for
restless bandits,” Journal of applied probability, pp. 637–
648, 1990.
D. Russo, B. Van Roy, A. Kazerouni, I. Osband, and
Z. Wen, A Tutorial on Thompson Sampling, ser. Foundations and Trends in Machine Learning Series. Now
Publishers, 2018.
R. Ortner and D. Ryabko, “Online regret bounds for
undiscounted continuous reinforcement learning,” in Advances in Neural Information Processing Systems 25,
F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2012, pp. 1763–
1771.
Y. H. Jung and A. Tewari, “Regret bounds for thompson sampling in episodic restless bandit problems,” in
Advances in Neural Information Processing Systems 32,
H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché
Buc, E. Fox, and R. Garnett, Eds. Curran Associates,

Inc., 2019, pp. 9007–9016.
[45] Y. H. Jung, M. Abeille, and A. Tewari, “Thompson
sampling in non-episodic restless bandits,” arXiv preprint
arXiv:1910.05654, 2019.
[46] C. Tsay, F. Lejarza, M. A. Stadtherr, and M. Baldea,
“Modeling, state estimation, and optimal control for the
us covid-19 outbreak,” arXiv preprint arXiv:2004.06291,
2020.
[47] F. Piguillem and L. Shi, “Optimal covid-19 quarantine
and testing policies,” 2020.
[48] T. Kruse and P. Strack, “Optimal control of an epidemic
through social distancing,” 2020.
[49] M. Bin, P. Cheung, E. Crisostomi, P. Ferraro, C. Myant,
T. Parisini, and R. Shorten, “On fast multi-shot epidemic interventions for post lock-down mitigation: Implications for simple covid-19 models,” arXiv preprint
arXiv:2003.09930, 2020.
[50] J. Köhler, L. Schwenkel, A. Koch, J. Berberich,
P. Pauli, and F. Allgöwer, “Robust and optimal predictive control of the covid-19 outbreak,” arXiv preprint
arXiv:2005.03580, 2020.
[51] Q. Ma, Y.-Y. Liu, and A. Olshevsky, “Optimal lockdown
for pandemic stabilization,” 2020.
[52] D. Acemoglu, V. Chernozhukov, I. Werning, and M. D.
Whinston, “Optimal targeted lockdowns in a multi-group
sir model,” NBER Working Paper, vol. 27102, 2020.
[53] J. R. Birge, O. Candogan, and Y. Feng, “Controlling
epidemic spread: Reducing economic losses with targeted
closures,” University of Chicago, Becker Friedman Institute for Economics Working Paper, no. 2020-57, 2020.
[54] B. Wilder, L. Onasch-Vera, G. Diguiseppi, R. Petering,
C. Hill, A. Yadav, E. Rice, and M. Tambe, “Clinical
trial of an ai-augmented intervention for hiv prevention in youth experiencing homelessness,” arXiv preprint
arXiv:2009.09559, 2020.
[55] K. Avrachenkov and V. S. Borkar, “Whittle index based
q-learning for restless bandits with average reward,”
arXiv preprint arXiv:2004.14427, 2020.
[56] D. Bertsimas and J. Niño-Mora, “Restless bandits, linear programming relaxations, and a primal-dual index
heuristic,” Operations Research, vol. 48, no. 1, pp. 80–
90, 2000.
[57] O. Besbes, Y. Gur, and A. Zeevi, “Stochastic multiarmed-bandit problem with non-stationary rewards,” in
Advances in neural information processing systems,
2014, pp. 199–207.
[58] S. Guha, K. Munagala, and P. Shi, “Approximation
algorithms for restless bandit problems,” Journal of the
ACM (JACM), vol. 58, no. 1, pp. 1–50, 2010.

5

A PPENDIX
S UPPLEMENTARY M ATERIAL
In Section A of the Supplementary Material, we introduce
the stochastic models involved, following [40]. In Section
B, we summarize the guarantees for Thompson sampling,
following [44].
A. Definitions and Related Work
For three decades, one of the best studied problems in
applied probability and stochastic analysis has been the restless
multi-armed bandit problem, [38, 41, 13]. Formally, in the
restless bandits problem, we are given n Markov chains
(bandits) Xi (0), i = 1, . . . , n, f = 0, 1, .., that evolve on
a common finite state space S = 1, ..., M . We are also
given the initial state of each chain. At each time t, bandit
i(t) is chosen. For i = i(t), X(t + 1) is determined by
a transition matrix P . For every i 6= i(t), X(t + 1) is
determined by some other transition matrix Q.
PAt each time
step, we incur a cost C(t) = c(Xi(t) ) + i6i(t) d(Xi (t))
for some rational-valued functions c and d defined on the
state space S. Given states of the different bandits, policy
π : S n → 1, ..., n decides which bandit should be played next;
that is, i(t) = π(X1 (f ), . . . , Xn (t)). Its average expected cost
is defined as
T
1X
E[C(t)],
lim sup
t→∞ T
t=1
and we are interested in finding a policy minimizing the
average expected cost. The multi-armed bandit problem is a
special case of restless bandits, in which bandits that are not
played do not change their state and do not incur any cost,
i.e., we have Q equal to the identity matrix and d = 0. It is
well known that:
Theorem 1 (Theorem 4 in [40]). Restless bandits are
PSPACE-hard.
Actually, the proof of Theorem 4 in [40] shows that deciding
if the optimal reward is non-zero is also PSPACE-hard, hence
ruling out any algorithm with non-trivial approximation ratio.
Furthermore, the result holds [40], even if matrices P , Q
correspond to one deterministic transition rule for all bandits
that are not played and another deterministic transition rule
applying to the bandit that is played.
In the general case, [56] introduce a hierarchy of N (where
N is the number of bandits) increasingly stronger linear
programming relaxations, the last of which is exact and corresponds to the (exponential size) formulation of the problem as
a Markov decision chain, while the other relaxations provide
bounds and are efficiently computed. They also propose a
priority-index heuristic scheduling policy from the solution
to the first-order relaxation, where the indices are defined in
terms of optimal dual variables. Similarly, [43] present strong
guarantees, but for an algorithm that is not tractable.
Under stricter assumptions, better guarantees are possible.
Under assumptions on the rate of change, [57] present a
framework for reasoning about regret of policies computable in
polynomial time. Other assumptions [58, 44] also yield guarantees on the approximation ratio. Specifically, [44] consider

Algorithm 1 Thompson sampling for COVID-19 screening,
based on [44]
1: Input prior Q, episode length L, policy mapping µ
2: Initialize posterior Q1 = Q, history H = ∅
3: for episodes l = 1, · · · , m do
4:
Draw a parameter θl ∼ Ql and compute the policy
πl = µ(θl )
5:
Set H0 = ∅
6:
for t = 1, · · · , L do
7:
Select N communities to test in At = πl (t, Ht−1 )
8:
Evaluate tests to obtain rewards Xt,At
9:
Update Ht
10:
end for
11:
Append HL to H and update posterior distribution Ql+1
using H
12: end for

guarantees in the case of the rewards being binary, which is
indeed the case in COVID-19 screening.
B. The Guarantees
Our guarantees are relative to a broad class of benchmark
policies including the optimal fixed policy, the myopic policy,
or the index-based policy, all of which are:
Definition 2 ([13, 44]). A deterministic policy π takes time
index and history (t, Ht−1 ) as an input and outputs a fixed
action At = π(t, Ht−1 ). A deterministic policy mapping
µ takes a system parameter θ as an input and outputs a
deterministic policy π = µ(θ).
In particular, we bound:
Definition 3 ([13]). Regret is:
⋆

R(T ; θ⋆ ) = mVπθ⋆ ,1 (∅) − Eθ⋆

T
X
t=1

At · Xt .

(1)

where the value function is:
θ
Vπ,i
(H) = Eθ,π [

L
X
j=i

Aj · Xj |H].

(2)

A variant of the regret, where one assumes we have access
to a prior distribution Q over the set of system parameters Θ:
Definition 4 ([44]). Bayesian regret is
BR(T ) = Eθ⋆ ∼Q R(T ; θ⋆ ),
The bound is as follows:
Theorem 5. (Bayesian regret bound of Thompson sampling) The Bayesian regret of Algorithm 1 satisfies the following bound
p
p
BR(T ) = O( KL3 N 3 T log T ) = O( mKL4 N 3 log(mL)).
Proof. The proof is by straightforward application of Theorem
1 of [44].
It is known [44] that this bound is tight for L = 1, N = 1.

