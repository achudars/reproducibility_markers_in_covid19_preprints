TDA-Net: Fusion of Persistent Homology and
Deep Learning Features for COVID-19
Detection in Chest X-Ray Images

arXiv:2101.08398v1 [cs.CV] 21 Jan 2021

Mustafa Hajij1∗ , Ghada Zamzmi2∗ , and Fawwaz Batayneh3
1

2

3

Santa Clara University, Santa Clara, CA, USA
mhajij@scu.edu
University of South Florida. Tampa, Florida, USA
ghadh@mail.usf.edu
The University of Queensland, Brisbane, Australia
f.batayneh@uq.edu.au
*indicates joint first author

Abstract. Topological Data Analysis (TDA) has emerged recently as a
robust tool to extract and compare the structure of datasets. TDA identifies features in data such as connected components and holes and assigns
a quantitative measure to these features. Several studies reported that
topological features extracted by TDA tools provide unique information
about the data, discover new insights, and determine which feature is
more related to the outcome. On the other hand, the overwhelming success of deep neural networks in learning patterns and relationships has
been proven on a vast array of data applications, images in particular. To
capture the characteristics of both powerful tools, we propose TDA-Net,
a novel ensemble network that fuses topological and deep features for the
purpose of enhancing model generalizability and accuracy. We apply the
proposed TDA-Net to a critical application, which is the automated detection of COVID-19 from CXR images. The experimental results showed
that the proposed network achieved excellent performance and suggests
the applicability of our method in practice.
Keywords: Topological Data Analysis, Convolutional Neural Networks.

1

Introduction

Deeply concerned by the alarming levels of spread and severity, the World Health
Organization (WHO) declared COVID-19 as an ongoing pandemic in March 11,
2020. Since then, there has been more than 14 million confirmed cases and over
150 thousand reported death worldwide [15]. The real time reverse transcriptase
polymerase chain reaction (RT-PCR) remains the current standard for diagnosing COVID-19 disease [27]. Other diagnostic tests for COVID-19 include the
loop-mediated isothermal amplification (LAMP), the lateral flow, and enzymelinked immunosorbent assay (ELISA) [27].

2

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh

In addition to these techniques, imaging techniques, such as Chest X-ray
(CXR) and computed tomography (CT), have been used for early COVID-19 diagnosis and predication of disease progression [24]. While CT scans have shown
higher sensitivity in detecting pneumonia infection and pulmonary manifestations [24] as compared to CXR, CT imaging techniques is not widely used for
COVID-19 diagnosis due to several issues including the high cost of CT, nonportability, and cross-contamination issues [24]. CXR imaging technique provides
a cheaper alternative that facilitates the diagnosis of patients who cannot move,
and hence reduces cross-contamination. Since the pandemic started, the shortage
of expert radiologists has been increasing especially in third-world countries [12].
To mitigate this shortage and speedup the diagnosis of COVID-19, artificial intelligence (AI) driven computer-aided diagnostic (CADx) tools can be used for
Point-of-Care Testing (POCT).
Deep learning provides powerful tools for extracting features that carry rich
texture information about the images. Since early this year, Covid-19 has attracted much attention from the deep learning community. Numerous works
(e.g., [5, 18, 22, 29]) propose to use convolutional neural network (CNN) for detecting COVID-19 viral pneumonia from CXR [21, 22] and CT images [5, 18, 29].
TDA [8,14] has emerged recently as a robust tool to extract and compare the
structure of datasets. TDA identifies the features such as connected components
and holes in the images and describes the extent to which they persist across
the image. Several studies reported that [16, 19] topological features extracted
by TDA tools, such as persistent homology [13] and Mapper [26], provide unique
information about the data, discover uncovering insights, and determine which
predictors are more related to the outcome. These characteristics allow TDA to
provide better explainability as compared to deep learning methods. In addition,
the topological analysis of the image allows to extract features that are invariant
to the spatial transformation and more robust to noise [4, 30]. This work is the
first that utilizes the quantitative power available in TDA tools and apply it to
detect COVID-19 from CXR images.
The main contribution of this paper can be summarized as follows:
– We propose TDA-Net, a novel neural network that fuses topological and deep
features for detecting COVID-19 from CXR images. TDA-Net contains two
branches: a deep branch that takes a raw image as input and a topological
branch that takes a topological feature vector as input. The outputs of both
branches are then fused and used to perform classification. The deep branch
provides rich texture information while the topological branch provides rich
representation of the data shape, and extract invariant and robust features.
To the best of our knowledge, we are the first to fuse topological and deep
learning features extracted from medical images.
– We propose to apply our proposed network to a novel and critical application, which is the automated detection of COVID-19 from CXR images.
The experimental results showed that our proposed network suggesting that
utilizing of our method in practice may yield better working models.

Title Suppressed Due to Excessive Length

2

3

Background

In this section we explain the technical details of converting a given tensor, i.e.
a multidimensional array such as a 2d image, to a vectorized representation of
its persistence diagram.
2.1

Homology

Homology deals with topological features of a space. Given a topological space
X, the 0-, 1-, and 2-dimensional homology groups, denoted as H0 (X), H1 (X), and
H2 (X) respectively, correspond to (connected) components, tunnels, and voids of
X. In general, the k-th homology group Hk (X) describes the k-dimensional holes
in X; the k-th Betti number βk is the rank of this group, that is, β0 is the number
of components, β1 is the number of 1-dimensional (circular) holes/tunnels, and
β2 is the number of 2-dimensional holes/voids.

Fig. 1: Computing Betti numbers for a sphere and torus.

For example, a circle contains a single component and a 1-dimensional tunnel,
but no higher-dimensional holes—β0 = 1, β1 = 1 and βi = 0 (i > 1); a sphere
(Figure 1) contains a single component and a 2-dimensional void, but no 1dimensional tunnel—β0 = 1, β1 = 0, β2 = 1 and βi = 0 (i > 2); and a torus
(Figure 1) contains a single component, 2 tunnels (Figure 1 (bottom) one in blue
and one in pink), and a void—β0 = 1, β1 = 2, β2 = 1 and βi = 0 (i > 2).
2.2

Persistent Homology on Tensors

While homology is applicable immediately on simplicial complexes, it is not immediately applicable to real-world data such as images. This is where persistent
homology comes into play. Essentially, persistent Homology quantifies the same
topological information in data by transforming it into a filtration (a nested
sequence of spaces), and then performing persistent homology computation on
the filtration and store the final result into a multi-set structure in R2 called
the persistence diagram. Intuitively, a filtration in our context is the tool to
extract features from the tenors and the persistence diagram is the data structure that stores these features. On the other hand the persistence diagram can
be thought of as a function that takes a filtration as an input and produces

4

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh

a multi-set in of points R2 . Precisely, let K be a simplicial complex. We will
denote the vertices of K by V (K). Let S be an ordered sequence σ1 , · · · , σn of
all simplices in K, such that for simplex σ ∈ K every face of σ appear before it
σ in S. Then S induces a nested sequence of subcomplexes called a filtration:
φ = K0 ⊂ K1 ⊂ ... ⊂ Kn = K. A d-homology class α ∈ Hd (Ki ) is said to be
born at the time i if it appears for the first time as a homology class in Hd (Ki ).
A class α dies at time j if it is trivial Hd (Kj ) but not trivial in Hd (Kj−1 ). The
persistence of α is defined to be j −i. Persistent homology captures the birth and
death events in a given filtration and summarizes them in a multi-set structure
called the persistence diagram P d (φ). Specifically, for any integer d ≥ 0, the
d-persistence diagram of the filtration φ is a collection of pairs (i, j) in the plane
where each (i, j) indicates a d-homology class that is created at time i in the
filtration φ and killed entering time j.
Persistent homology can be defined given any filtration. For the purpose of
this work, the input is a 2-d tensor and we can utilize this tensor to build a
lower-star filtration which reflects sublevel topology of this tensor. We illustrate
next how to covert a tensor to a simplicial complex.
From a tensor M specified as an 2-d array we build a 1-d simplicial complex
K(M ) = (V (M ), E(M )) as follows. Every pixel in the tensor is a vertex v in
the set of vertices V (M ), and every vertex v in V (M ) is connected to the set of
neighbor pixels in M that are immediately adjacent to v. In our case we connect
every pixel to the 8 other vertices obtained by considering the 8 immediate
neighbors the pixel that this vertex represents. Clearly, at the boundary of a
tensor, every vertex is connected to a fewer vertices. See Figure 3 for an example
of converting 2d-tensor M to the complex K(M ) 4 .

M

K(M)

Fig. 2: Converting an image M to a 1-d simplicial complex K(M ).

4

This method can be generalized to n-d multidimensional tensors similarly. Moreover,
there are multiple ways to build a complex out of a tensor. Typically, in the context
of images, cubical complexes are popular because they are more efficient [3]. For our
particular case study the difference in complex size is negligible.

Title Suppressed Due to Excessive Length

5

Using the above construction we can think about a single channel image
M as piece-wise linear function fM : K(M ) → R defined on the vertices of
complex K(M ) where the value of fM at the a certain vertex is simply the value
of the corresponding pixel. We extend f to edge of K(M ) by taken to be the
maximum of the two pixel values they connect. Now let V (M ) = {v1 , · · · , vn } be
the set of vertices of K(M ) sorted in non-decreasing order of their f -values, and
let Ki (M ) := {σ ∈ K(M )| maxv∈σ fM (v) ≤ fM (vi )}. The lower-star filtration,
denoted by Ff (K(M )), is defined as:
φ = K0 (M ) ⊂ K1 (M ) ⊂ ... ⊂ Kn (M ) = K(M ).

(1)

The lower-star filtration reflects the topology of the function fM in the sense that
the persistence homology induced by filtration 1 is identical to the persistent
homology of the sublevel sets of the function fM . In this work, we will only
consider the 0-dimensional persistence diagram of the lower-star filtration of M
and we will denote to it by P D0 (M ). Computing the 0-persistence diagram of a
1-d tensor is illustrated in Figure 3.
2.3

Vector Representation of the Persistence Diagram

Recently, there have been many attempts to vectorize the persistence diagram
in order to utilize it within a traditional machine learning framework. Generally speaking, vectorization framework of the persistence diagram, illustrated in
Figure 4, starts with a set data of interest, say a set of images. Each object in
this set is then converted to a persistence-based representation. Viewing these
persistence representations as points in a feature space, we can then define an
appropriate distance or a kernel inside this feature space and then perform a
data analysis task.
Many such vectorization schemes have been suggested recently. This includes
betti curve [28], the persistence landscape [7], the persistence image [2] and many
other [6,9,17]. In a TDA-Net architecture one may consider utilizing any of these
tensors into the topological stream. For our study here we choose to work with
the betti curves [28] represeantation of the persistence diagram.

3
3.1

Approach
TDA-Net

A TDA-Net consists of two sub-neural networks. The two neural networks, indicated in figure 5, consider two different data input : the raw pixel image,
denoted by x, and the a vector version of the persistence diagram of the input
image x. Figure 5 illustrates an abstraction for a general purpose TDA-net. We
will call the sub-network of a TDA-Net that take the raw data the deep stream
and similarly we will call the sub-net that takes the persistence diagram the
topological stream. Note that the design of the network admits multiple variations. In particular, the persistence diagram can be injected into the topological

6

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh

1.3

1.3
0.7
1

2

3

4

5

6

7

8

0.7

0.7
9

10

1

2

3

4

(a)

2

3

1.3

5

6

7

8

1.5

9

10

1

2

3

4

3

5

1.3
6

7

8

9

1.5

1

3

9

10

3

2

3

1.3

5

6

7

8

1.3
6

(g)

1.5

0.7

0.7
4

4.6

9

10

4.6

4

7

8

9

10

4
3

1.5

1.5

1.3

0.7

0.7
5

8

4

1.5

4

7

3

3

1.3

6

1.5

(f)

4

2

1.3
0.7

1.5

1.3

10

(e)

1

10

3

0.7

0.7
4

5

3

1.5

1.3

0.7
9

(d)

3

2

8

0.7

(c)

1

7

1.5

1.3

0.7

0.7
4

6

(b)

1.5

1.3
1

5

1

2

1.3
0.7

3

4

5

6

7

8

1.5

0.7
9

10

(h)

Fig. 3: An example of computing the persistence diagram of 1-d tensor. The
persistence diagram consists of a collection of bars each bar represents a topological feature and is encoded by a pair (u, v) ∈ R2 which represent the birth
and the death of topological feature. The persistence of (u, v) is simply given by
|v −u|. Features with higher persistence values carry more significant topological
information. On the other hand, features with low persistence are considered to
be noise. In this example the persistence diagram consists of three features :
(0.7, 4.5), (1.3, 3) and (1.5, 4).

stream immediately as an input (as indicated in the yellow arrow labeled by
”2” in Figure 5 ) or concatenated to a later activation (as indicated by the red
arrow labeled by ”3” in Figure 5) or both. Moreover, one can may add various
connections between the two stream. We explore multiple versions of TDA-Nets
in the experimentation section 4.

Title Suppressed Due to Excessive Length
Vectorized version of PD(x)

PD(x)
daeth

An input tensor x

7

y=x

birth

(a)

(b)

(c)

Fig. 4: Converting an input tensor to a vectorized version of the persistence
diagram.
deep stream
1

An Image input x

4

2

A vector version
of the PD of the Image x

loss function

Additional layers

Layers

Layers
3

topological stream

Fig. 5: An abstract sketch of the a general purpose TDA-Net. The input for the
model consists of the raw image data and a vector version of the persistence
diagram. The PD can be injected into the model as an input along with the
raw image data (as indicated in the yellow arrow) or concatenated to a later
activation (as indicated red arrow) or both.

4

Experimentations and Results

In this section we test 3 different TDA-Nets against a simple base CNN model.
The models we study here are given in Figure 6.
All our networks have been chosen to be simple and with small number
of parameters because we bare in mind that our particular application should
execute in real-time on a small device. Moreover, as we mentioned earlier, TDANets can be considered as a type of an ensemble model where the deep stream
the topological stream can be thought of as simple models that are combined
together to obtain a better model. Finally, the complexity of the model makes
it hard to analyse which features are more useful and effective for the learning
application we are trying to execute.

200,Dense,

softmax
flatten

100,Dense,

200,Dense,

1,X,1,2,conv,

200,Dense,

600,Dense,

7,X,7,10,conv,

200,Dense,

300,Dense,

(a)

7,X,7,10,conv,

BettiCurve(x)

softmax

flatten

10,Dense,

1,X,1,2,conv,

3,X,3,,4,conv

An,Image,
input,x

7,X,7,10,conv,

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh
7,X,7,10,conv,

8

(b)

(c)

topological,stream

softmax

10,Dense,

concatenate

BettiCurve(x)

BettiCurve(x)

softmax

10,Dense,

flatten

1,X,1,2,conv,

topological,stream

An,Image,
input,x
concatenate

200,Dense,

100,Dense,

7,X,7,10,conv,

3,X,3,,4,conv

200,Dense,

BettiCurve(x)

An,Image,
input,x

7,X,7,10,conv,

deep,stream

3,X,3,,4,conv

deep,stream

(d)

Fig. 6: The four neural networks we trained for our experimentations. These nets
are (a) the base model, (b) T DA − N et1 a model that takes only the betti curve
as input, (c) T DA − N et1,2 a model that takes model the raw image data and
betti curve as input and finally (d) T DA − N et1,2,3 a model that takes the betti
curve of an image and the raw image data as input but also injects the betti
curve into a later activation layer.

4.1

Data Prepossessing

We consider two open-source datasets on chest X-ray and CT images. The first
dataset [11] consists of an open-source dataset of a 351 chest X-ray and CT
images which are positive or suspected of COVID-19, as well as other lung conditions. The dataset is composed of a 351 samples, 287 of which are COVIDpositive. We only selected the Covid-positive labeled images from this data.
On the other hand, we utilize another dataset from Kaggle [20] to obtain our
negatively labeled images. This dataset has 112120 X-ray image. To obtain a
balanced dataset we selected 287 samples of chest X-ray images of viral and
bacterial pneumonia from this data. During training all images were scaled to
128 × 128.
On the other hand, in order to incorporate the data for the topological stream
we compute the persistence diagrams of all images in the constructed data then
we compute the betti curve vector representations of these diagrams. We chose
to embed the betti curve vector in R100 5 . The pipeline of converting a dataset
into its topological incarnation is described in Figure 3
Finally, the data was split into two parts a training part and a leave-Out part.
The leave-Out part consists of 20% of the total dataset which is 116 samples
divided equally between the positive and the negative classes.
5

We empirically found this length to be sufficient to store all topological features in
our dataset.

Title Suppressed Due to Excessive Length

4.2

9

Networks Design and Training

Four networks were trained to test our method. The first model is the base
neural network that is a simple CNN model that consists of 4 conv-layers and
two dense layers. More specifically, the input for the neural network is input layer
128 × 128 × 3. This input then goes through 4 conv layers of sizes indicated in
Figure 6 part (a). The final layer a softmax layer. In the second neural network we
consider a TDA-net that consists only of a topological stream. For this network
we only utilize the Betti-curve of the image x as an input for the input and we do
not use any raw data information. Since the Bettie curve is essentially a vector
we choose a fully connected neural network architecture on this type of data.
The details of this architecture is given in Figure 6. We will call this network
T DA−N et1 since it only has a connection of type 1 as indicated in Figure 5. The
third neural network is a TDA-Net that has both topological and deep stream.
The deep stream architecture is identical the architecture of the base network.
On the other hand, the layers in the topological stream are chosen to be dense
layers since the input, the betti-curve, is essentially a vector. The design of the
network is given in Figure 6 part (c). We denote this network by T DA − N et1,2
since it has connections of type 1 and 2 as indicated in Figure 5. The forth neural
network is similar to the third one except that in addition to inject the betticurve to a later activation as indicated in the Figure 6 part (d). We denote this
network by T DA − N et1,2,3 . All our networks have been trained using Keras [10]
using the TensorFlow backend [1]. The computation of the persistence diagram
and its vectorized version were performed using scikit-tda [23].
4.3

Results

To study the applicability of the proposed model above with our small dataset,
we perform the typical metrics on the validation dataset. The initial results,
if they can be improved, show promising and interesting numbers. The results
are reported in Table 1. The most notable result for us is that the model that
considers topological features alone, model T DA − N et1 , performs very closely
to the base CNN model which processes the raw data alone. On the other hand,
ensemble TDA-nets models, T DA − N et1,2 and T DA − N et1,2,3 yielded the
better results. Specifically, while T DA − N et1,2,3 yield the highest accuracy, in
this case, model T DA−N et1,2 is preferred because it yields lower specificity/true
negative rate (TNR) while maintaining very close accuracy.

5

Conclusion and Future Work

We proposed TDA-Net an ensemble deep learning network that fuses topological
and deep learning features into one network for the purpose of enhancing generalizability and accuracy. The initial study on Covid-19 x-ray images is promising
and suggests the applicability of the proposed method in practice.
The study herein has multiple limitations that must be addressed in future
work. On one hand, a larger dataset must be selected to further establish the

10

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh

Accuracy
Precision
Recall
f-1 score
AUC
TNR

Base model T DA − N et1 T DA − N et1,2 T DA − N et1,2,3
0.87
0.89
0.92
0.93
.84
0.84
0.95
0.88
.87
0.87
0.85
0.95
0.86
0.86
0.9
0.92
1
1
1
1
0.89
0.88
0.97
0.91

Table 1: Results on the four models specified in Figure 6.

applicability of our of method in a practical setting. Furthermore, the four models
that we selected were trained from scratch on our dataset. A transfer learning
comparison utilizing base classical CNN models such as VGG-16 [25] would most
likely improve the results for all suggested models.

References
1. M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow: A system for large-scale machine
learning. In 12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16), pages 265–283, 2016.
2. H. Adams, T. Emerson, M. Kirby, R. Neville, C. Peterson, P. Shipman, S. Chepushtanova, E. Hanson, F. Motta, and L. Ziegelmeier. Persistence images: A stable
vector representation of persistent homology. The Journal of Machine Learning
Research, 18(1):218–252, 2017.
3. M. Allili, K. Mischaikow, and A. Tannenbaum. Cubical homology and the topological classification of 2d and 3d imagery. In Proceedings 2001 international conference
on image processing (Cat. No. 01CH37205), volume 2, pages 173–176. IEEE, 2001.
4. W. Bae, J. Yoo, and J. Chul Ye. Beyond deep residual learning for image restoration: Persistent homology-guided manifold simplification. In Proceedings of the
IEEE conference on computer vision and pattern recognition workshops, pages 145–
153, 2017.
5. H. X. Bai, B. Hsieh, Z. Xiong, K. Halsey, J. W. Choi, T. M. L. Tran, I. Pan,
L.-B. Shi, D.-C. Wang, J. Mei, et al. Performance of radiologists in differentiating
covid-19 from viral pneumonia on chest ct. Radiology, page 200823, 2020.
6. E. Berry, Y.-C. Chen, J. Cisewski-Kehe, and B. T. Fasy. Functional summaries of
persistence diagrams. J. Appl. Comput. Topol., 4(2):211–262, 2020.
7. P. Bubenik. Statistical topological data analysis using persistence landscapes. The
Journal of Machine Learning Research, 16(1):77–102, 2015.
8. G. Carlsson. Topology and data. Bulletin of the American Mathematical Society,
46(2):255–308, 2009.
9. Y.-C. Chen, D. Wang, A. Rinaldo, and L. Wasserman. Statistical analysis of
persistence intensity functions. arXiv preprint arXiv:1510.02502, 2015.
10. F. Chollet et al. Keras. https://keras.io, 2015.
11. J. P. Cohen. Covid chest x-ray dataset. https://github.com/ieee8023/
covid-chestxray-dataset, 2020.

Title Suppressed Due to Excessive Length

11

12. A. H. Davarpanah, A. Mahdavi, A. Sabri, T. F. Langroudi, S. Kahkouee, S. Haseli,
M. A. Kazemi, P. Mehrian, A. Mahdavi, F. Falahati, et al. Novel screening and
triage strategy in iran during deadly coronavirus disease 2019 (covid-19) epidemic:
value of humanitarian teleconsultation service. Journal of the American College of
Radiology, 17(6):734–738, 2020.
13. H. Edelsbrunner and J. Harer. Persistent homology-a survey. Contemporary mathematics, 453:257–282, 2008.
14. H. Edelsbrunner and J. Harer. Computational topology: an introduction. American
Mathematical Soc., 2010.
15. C. for Disease Control and Prevention. Covid-19 world map. Centers for Disease
Control and Prevention, 24/07/2020.
16. M. Joshi and D. Joshi. A survey of topological data analysis methods for big data
in healthcare intelligence. Int. J. Appl. Eng. Res, 14:584–588, 2019.
17. G. Kusano, Y. Hiraoka, and K. Fukumizu. Persistence weighted gaussian kernel
for topological data analysis. In International Conference on Machine Learning,
pages 2004–2013, 2016.
18. L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang, Q. Song,
et al. Artificial intelligence distinguishes covid-19 from community acquired pneumonia on chest ct. Radiology, page 200905, 2020.
19. J. L. Nielson, J. Paquette, A. W. Liu, C. F. Guandique, C. A. Tovar, T. Inoue,
K.-A. Irvine, J. C. Gensel, J. Kloke, T. C. Petrossian, et al. Topological data
analysis for discovery in preclinical spinal cord injury and traumatic brain injury.
Nature communications, 6(1):1–12, 2015.
20. NIH.
Nih chest x-ray dataset of 14 common thorax disease
categories.
https://www.nih.gov/news-events/news-releases/
nih-clinical-center-provides-one-largestpublicly-available-chest-x-ray-datasets-scientific-commun
2020.
21. T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu, O. Yildirim, and U. R. Acharya.
Automated detection of covid-19 cases using deep neural networks with x-ray images. Computers in Biology and Medicine, page 103792, 2020.
22. S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio, and S. K.
Antani. Iteratively pruned deep learning ensembles for covid-19 detection in chest
x-rays. arXiv preprint arXiv:2004.08379, 2020.
23. N. Saul and C. Tralie. Scikit-tda: Topological data analysis for python, 2019.
24. F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, K. He, Y. Shi, and D. Shen. Review of artificial intelligence techniques in imaging data acquisition, segmentation
and diagnosis for covid-19. IEEE reviews in biomedical engineering, 2020.
25. K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale
image recognition. arXiv preprint arXiv:1409.1556, 2014.
26. G. Singh, F. Mémoli, and G. E. Carlsson. Topological methods for the analysis
of high dimensional data sets and 3d object recognition. In SPBG, pages 91–100,
2007.
27. B. Udugama, P. Kadhiresan, H. N. Kozlowski, A. Malekjahani, M. Osborne, V. Y.
Li, H. Chen, S. Mubareka, J. B. Gubbay, and W. C. Chan. Diagnosing covid-19:
the disease and tools for detection. ACS nano, 14(4):3822–3835, 2020.
28. Y. Umeda. Time series classification via topological data analysis. Information
and Media Technologies, 12:228–239, 2017.
29. Y.-H. Wu, S.-H. Gao, J. Mei, J. Xu, D.-P. Fan, C.-W. Zhao, and M.-M. Cheng. Jcs:
An explainable covid-19 diagnosis system by joint classification and segmentation.
arXiv preprint arXiv:2004.07054, 2020.

12

Mustafa Hajij, Ghada Zamzmi, and Fawwaz Batayneh

30. Y. Zheng. Application of Persistent Homology in Signal and Image Denoising.
PhD thesis, Niedersächsische Staats-und Universitätsbibliothek Göttingen, 2015.

