Fines and progressive ideology promote social
distancing
arXiv:2012.12118v1 [econ.GN] 22 Dec 2020

Edoardo Gallo, Darija Halatova, Alastair Langtry
December 23, 2020

Abstract
Social distancing has been one of the core public policy measures used to mitigate the
economic and health impacts of the COVID-19 pandemic. Such widespread adoption of
social distancing measures is wholly unprecedented, and governments have implemented
a variety of policies to encourage compliance. These typically rely on financial penalties
(fines) and/or informational messages (nudges). There is, however, a lack of evidence on
the impact of these policies. We examine the effectiveness of fines and nudges in promoting social distancing in a web-based interactive experiment. The study involves a nearrepresentative sample of 400 participants from the US population, and it was conducted in
May 2020 at the height of the pandemic. Fines significantly promote distancing, but nudges
only have a marginal impact. Political ideology also has a causal impact – progressives are
more likely to practice distancing, and are marginally more responsive to fines. Further,
individuals do more social distancing when they know they may be a superspreader. Our
results highlight the crucial role of web-based interactive experiments in informing governments on the causal impact of policies at a time when lab and/or field-based experimental
research is not feasible.

JEL: C99, D85, D91, I12
Keywords: social distancing, online experiment, nudge, superspreader, political ideology

Authors affiliation: Faculty of Economics, University of Cambridge, Sidgwick Avenue, Cambridge, UK.
Edoardo Gallo and Darija Halatova have contributed equally to this work. The authors are grateful to Matthew
Elliott, Freya Jephcott, Frederic Moisan, Gabriella Santangelo and Flavio Toxvaerd for helpful comments and
suggestions, and to Ilia Shumailov for technical assistance. Thanks to seminar participants at the Large Scale
Experiments Webinar (University of Cambridge) and Cambridge-INET Networks Reading Group. Edoardo Gallo
acknowledges support from the Cambridge Endowment for Research in Finance, and the Cambridge Humanities
Research Grant Scheme. Darija Halatova and Alastair Langtry acknowledge support from the Economic and Social
Research Council. This work is the sole responsibility of the authors, and does not necessarily represent the official
views of any of the funding agencies.

1

The COVID-19 pandemic is causing the most significantglobal disruption in the post-war
period, and it will impact the global economy at least until a vaccine is widely available [1–4].
In the meantime, governments worldwide are acting to prevent their healthcare systems from
being overwhelmed and to reduce the number of deaths [5–8]. Regulations to minimize social
interactions by self-isolating and/or limiting exposure to others (social distancing) have emerged
as a primary policy tool to manage infection levels in the short and medium term [5, 9, 10].
Widespread adoption of, and compliance with, social distancing guidelines is unprecedented, and governments have used different policy tools to promote social distancing behavior.
Some countries impose heavy fines on anyone found breaching social distancing measures. For
instance, Singapore punishes first time offenders with up to 10,000 SGD (approx. 7,000 USD)
fine, and repeated violators can be jailed [11]. At the other end of the spectrum, some countries
decided to rely on informational campaigns to nudge people to adopt social distancing. India
and the UK relied heavily on informational messages (nudges hereafter) early on, but then introduced fines after violations turned out to be common [12–14]. The reality is that the novelty and
scale of social distancing policies is uncharted territory, and governments lack robust scientific
evidence on the relative effectiveness of different policies.
We investigate the effectiveness of different policy interventions in promoting social distancing by conducting a web-based interactive experiment. The subject pool is a near-representative
sample of the US population in terms of age, gender and geographical location. All sessions
took place in May 2020 at the height of the first wave of the COVID-19 pandemic. The first
policy intervention we examine is a fine for participants who choose not to social distance. The
second one is a nudge in the form of a video that explains the harm to others of not social
distancing.
In addition to the policy intervention, we investigate two further determinants of social distancing decisions. First, we vary the network structure of interactions by assigning participants
to either a homogeneous or a heterogeneous group. In the former, each participant interacts with
all the others. In the latter, all interactions involve one superspreader participant. Second, we
vary the contagiousness of the disease assigning participants to either a high or a low contagion
treatment.
This is, to our knowledge, the first study that investigates experimentally the effectiveness of
different policies in promoting social distancing. We show that the elicitation of actual behavior in an experimental setting gives different results to survey-data self-reported by participants
(see Discussion below for further details). Our main finding that fines are effective in promoting social distancing provides crucial information to policymakers who are fighting to limit the
impact of the pandemic. In addition, our results on how individual characteristics (e.g. political
ideology, age, gender) relate to social distancing behavior is consistent and complementary to
recent empirical studies based on sociomobility data [15]. Experiments can investigate counterfactual policies and cleanly identify causal behavior, while empirical studies directly achieve
external validity by measuring behavior in the real world.

1

Experimental Design

We recruit a standing panel of US-based participants using a short survey on Amazon Mechanical Turk. The survey contains standard sociodemographics questions plus the Social Value
Orientation (SVO) task [16] to elicit social preferences. During recruitment, we use the 2018
2

No
No!

Yes

Social distancing

Practice
social
distancing?

no (-f)

Choosing
patient
zero

yes (-c)
Infection status
healthy (+b)
infected (0)

Allocation
of
positions

No!
No

Contagion

Payoffs

Contagion

Link types
protected
contagion with
probability α
no contagion with
probability (1-α)
Current spreader

Figure 1: Flow of a typical round of baseline and intervention. In the experiment, we use the
following parameterization: f = 0 or 15 (fine intervention only); c = 35; b = 100; α =
0.15 (low contagion) or 0.65 (high contagion). Final payoffs for the round are a combination
of individual social distancing choice and infection status. For example, a participant who
practices social distancing and is healthy, receives (−c + b) or 65 points. In the figure, the
chosen network architecture is the star. In the experiment, half of the treatments had the star
network architecture and the other half had the complete.
US Census data to generate a representative panel in terms of age, gender and geographical location. Despite the possibility of selection bias in participating in the experimental session, we
obtain a near-representative sample of n = 400 participants completing the experiment. Workflow is similar to lab-based procedures with participants reading the instructions and completing the experiment in one uninterrupted session. Analogously to recent contributions [17, 18],
multiple participation is not allowed even by participants who have only seen the instructions
(Appendices A.2.2 and A.2.3).
Each participant is assigned to a group of 5 that remains the same throughout the experiment.
Figure 1 illustrates the flow of one round of the experiment. At the beginning of a round,
participants are randomly allocated to one of the positions in a network (top left). One and
only one participant is randomly picked to contract COVID-19 directly – in the example in
Figure 1, the top right panel shows it is one of the peripheral participants. Before the random
pick, each individual has to decide whether to practice social distancing at a known cost c = 35
(top center).
The first benefit of social distancing is that if the individual is randomly picked to contract
COVID-19 then she becomes infected with 50% probability, rather than for sure. The second
benefit is that any individual who practices distancing cannot transmit COVID-19 to others or
contract it from infected individuals.
COVID-19 can then spread through the commonly known network from infected to healthy
individuals who do not practice social distancing through contagion with a known probability
α. The bottom panels of Figure 1 show a possible spread in the example with three individuals
infected and two healthy at the end of the contagion process. At the end of the game, healthy
3

individuals receive a benefit b = 100, whereas those infected receive zero benefit. Any individual who chose to practice social distancing pays the cost c irrespective of their final infection
status.
After participants play 20 rounds of the above baseline game, their group is treated with
one of the policy interventions. In the nudge treatment, every participant must watch a 3minute video explaining how failing to practice social distancing may harm others. In the fine
treatment, whenever a participant decides not to practice social distancing she receives a fine of
f = 15 points, independent of her infection status at the end of the round. The same group of 5
participants then play 20 rounds of the game under one of the policy interventions so we adopt
a within-subjects design to investigate the impact of each policy on social distancing behavior.
We investigate two further treatment dimensions using a between-subjects design – the level
of contagiousness and the type of social environment. Throughout the experiment participants
experience either a high (α = 0.65) or a low (α = 0.15) level of contagiousness of COVID-19.
At the beginning of the experiment, they are also assigned to one of two social environments.
The first social environment is a complete network represented on the left side of Figure 2B – all
participants are in a close-knit position as they interact with all others in the group. The second
social environment is the star network on the right side of Figure 2B – one superspreader participant interacts with all other (peripheral) participants who only interact with the superspreader.

2

Results

Figure 2A shows the evolution of social distancing levels aggregated over contagiousness and
network treatments. In the fine intervention, a structural break analysis always identifies a
change in the evolution of social distancing at round 21, immediately after the implementation
of the fine (Wald test, p < 0.001 for all data and subdivided by the other treatments). The same
break at round 21 occurs in the nudge intervention in the aggregate data (Wald, p < 0.001),
but the result is not robust once we subdivide by the other treatments (Appendix A.3.1). The
introduction of the fine has, therefore, an immediate impact on social distancing behavior, while
the impact of the nudge is less clear-cut. Figure 2A also shows a downward trend in social
distancing behavior in the first rounds. A convergence analysis shows that at least 80% of
participants converge to a stable strategy in every treatment after the first 10 rounds. Throughout
the analysis, therefore, we focus on the last 10 rounds of the baseline and intervention, but the
results are robust to including all the data (Appendix A.4).
Fines increase the level of social distancing, and the effect is significant both in the nonparametric (Wilcoxon Sign Rank test, WSR hereafter, p = 0.0008) and in the regression (Random Effects Logit, REL hereafter, p = 0.001) analyses. The increase in social distancing
behavior is present both in low (WSR, p = 0.04) and high (WSR, p = 0.003) contagion environments. In the last 10 rounds of the fine intervention, there is an 8% increase in social
distancing compared to the last 10 rounds of the pooled baseline so the effect of the fine is
sizeable and long-lasting.
In contrast, the impact of the nudge intervention is marginal and not robust to all specifications (WSR, p = 0.008; REL, p = 0.09). Interestingly, narrowing the focus to a specific
contagion environment, the nudge significantly increases distancing with high contagion (WSR,
p = 0.0003) but it has no effect with low contagion (WSR, p = 0.5). Comparing the two
policies, the impact of the fine is marginally higher than the nudge (Mann-Whitney test, MW
4

Figure 2: Policy and network position. (A) Evolution of aggregate probability of distancing
split by policy intervention. (B) Probability of distancing split by network position and policy
intervention. Node size is proportional to distancing probability. Width of dotted band around
the circumference of each circle indicates 95% confidence intervals.
hereafter, p = 0.08). Overall, the increase in social distancing in the last 10 rounds due to the
nudge intervention is only 2% so the effect of the nudge is negligible and short-lasting.
A crucial driver in the spread of COVID-19 is the presence of superspreaders – individuals
who go on to infect a much larger number of others than the average [19, 20]. A primary determinant of being a superspreader is biological – something that cannot be varied experimentally
and is outside of the scope of this study. However, there is also a social element driven by
the wide variations in the number of social interactions across individuals [21]. An important
difference between biological and social drivers of being a superspreader is that an individual is
aware of the latter, and therefore the tendency to social distance may vary with position in the
network.
Figure 2B illustrates the three positions in our experiment drawn with the node size proportional to the amount of social distancing in that position for each policy treatment. On the left
side, there is the complete network in which all participants are in what we dub a close-knit
position. On the right side, there is the star network with one participant – the superspreader –
interacting with all others in what we dub a peripheral position (because they only interact with
the superspreader). Superspreaders practice more social distancing than peripheral participants
both in the baseline and policy interventions (MW and REL, p < 0.0001 for all). Moreover, superspreaders also practice social distancing more than close-knit participants (MW, p = 0.004;
REL, p = 0.05) despite having the same number of interactions. This may be because they are
aware of their central role in spreading COVID-19 and want to protect the group, or because
they realize peripheral participants are less likely to distance due to their isolated position.
In a post-experimental survey, we collect sociodemographic characteristics and elicit participants’ beliefs on several issues. Self-reported Democrats are significantly more likely to
practice distancing than Republicans (REL, p = 0.02). In order to obtain a more fine-grained
picture of participants’ political leanings, we construct an ideology index, with a score for each
subject based on responses to three questions about (1) support for President Trump’s handling
of the COVID-19 pandemic, (2) support for universal healthcare, and (3) belief that social distancing measures impose unjustified economic costs. Questions are on a 5-point Likert scale,
5

Figure 3: Ideology and social preferences. (A) Probability of distancing and (B) percentage
change in probability of distancing split by policy intervention and quintile of ideology index.
(C) Probability of distancing split by social preference and policy intervention. Vertical bars
indicate 95% confidence intervals.
so we obtain a 0-12 index with 0 and 12 indicating extremely progressive and extremely conservative participants respectively (Appendix A.3.3).
Figure 3A shows that the probability of practicing distancing decreases the more conservative a participant is – an increase in ideology index from 1 to 5 (25th to 75th percentile among
our subjects) corresponds to a 14.6% decrease in the probability of distancing. The ideology
index is a highly significant correlate of social distancing decisions (REL, p < 0.0001) – this is
in line with recent sociomobility and survey-based studies in the US [22–24].
Our experimental design exogenously varies the policy intervention, allowing us to make
causal inferences. The same is obviously not possible with ideology. We investigate the causal
effect of ideology with an instrumental variable approach (IV hereafter), using a measure of
participants’ skepticism of global warming as the instrument. As a partisan issue in the US,
attitudes toward global warming are strongly correlated with political ideology [25, 26]. The
exclusion restriction our IV identification relies on is that global warming attitudes do not affect
social distancing decisions separately from their association with ideology (Appendix A.3.3).
Political ideology is a significant causal determinant of social distancing, with conservatives less likely to practice distancing (IV, p = 0.04). Figure 3B illustrates an interesting further
interaction between political ideology and the type of policy intervention. While the nudge
intervention has no differential impact on subjects with different ideology, conservative participants are marginally less responsive to the fine (IV, p = 0.08).
Social preferences play an important role in decisions to social distance. A theoretical analysis of equilibrium social distancing decisions with self-interested individuals predicts levels of
social distancing that are significantly lower than participants’ decisions in all treatments (MW,
p < 0.0001; Appendices A.1 A.3.2). Using the Social Value Orientation elicitation task [16],
we classify subjects into individualistic and pro-social. As Figure 3C illustrates, pro-social
participants are 20% more likely to choose distancing (REL, p < 0.0001). There are no significant interactions between social preferences and the effect of the nudge, but prosocials are
marginally less responsive to the fine (REL, p=0.07).
The nonlinearity of the Random Effects Logit (REL) model means it is not straightforward
to read off the size of the effects of the different variables in our analysis. In order to compare
the size of different factors, we compute the Average Partial Effects (APE) calibrated on the

6

Figure 4: Average Partial Effects (APE) for variables that are significant in the REL main specification. Bar boundaries indicate 25th and 75th percentiles, vertical line inside bars indicate
50th percentile, and black dots show the mean. Variables not included because they are not
significant include: education, religion, labor force participation, case numbers, and geography
controls.
characteristics and/or decisions of the subjects in our experiment (Appendix A.3.3). Figure 4
shows the APEs for all variables that are significant in our main specification. Blue bars indicate
causal effects from our treatment variables. The fine has twice the impact of the nudge, and the
magnitude of the fine effect is similar to awareness of being the superspreader compared to
the close-knit baseline. As expected, high contagiousness leads to significantly more social
distancing (REL, p < 0.0001), and the size of the effect is similar to the difference between
being in the close-knit and peripheral positions. Participants in a high contagion setting are also
relatively more responsive to the nudge (REL, p = 0.006).
In terms of sociodemographics, females (REL, p = 0.002) and older individuals (REL,
p < 0.0001) are more likely to distance. From the data, being female translates to a 12.6%
increase in the probability of distancing, and there are no significant interactions between gender and the effect of each policy intervention. Social distancing is increasing with age – an
average 60-year-old is 40.1% more likely to distance than an otherwise identical 20-year-old.
Interestingly, older subjects are relatively more responsive to the nudge (REL, p = 0.02) and
relatively less responsive to the fine (REL, p < 0.0001). Whites are less likely to distance (REL,
p = 0.04), but the effect is not robust. Education, religion and employment status are not associated with distancing behavior. These associations between sociodemographic characteristics
and distancing are broadly consistent with evidence from sociomobility [15], and survey-based
data [27–30].
We elicit participants’ risk preferences using the “Bomb risk elicitation task” [31]. As expected, risk seeking individuals are less likely to practice social distancing (REL, p = 0.001),
and the effect is about half the size of being pro-social in the SVO task. The post-experimental
survey includes a question asking why subjects choose to stay at home – participants who
list “protecting others” as one of the stated reasons are more likely to social distance (REL,
p = 0.007) and the effect is similar in size to being risk-averse.
There is no association between distancing and the geographical evolution of the pandemic
7

as captured by new cases, cumulative cases and total deaths at the state level on the day of
participation in the experiment. Similarly, institutional decisions such as the timing of stay-athome orders in different states are unrelated to social distancing decisions (Appendix A.3.3).

3

Discussion

The sudden disruption brought by the COVID-19 pandemic demanded a quick response from
policymakers who had to implement novel policies whose success determined the fate of tens of
thousands of lives. This work illustrates the crucial role interactive web-based experiments can
play in investigating behavioral responses to the pandemic. During the COVID-19 crisis, lab
and/or field experiments ground to a halt, depriving researchers of the standard tools to identify
causal effects [32]. In contrast, web-based experiments are unaffected and can be deployed at
large-scale, without geographic boundaries, and in a short time-frame.
Our first result is that fines significantly increase the level of social distancing, while nudges
have a negligible effect. This finding is consistent with the shift in policy in many countries
to enforce distancing rules using financial penalties rather than just relying on informational
messages as in the early stages of the pandemic [6,13]. In our experiment, we examine a specific
type of nudge in the form of a video about the harm caused to others by not social distancing. A
promising area of future research is to examine the efficacy of nudges with alternative mediums
and different content to promote social distancing as they have been explored in other areas of
economics [33].
Our second result is that the probability of practicing distancing is decreasing in how politically conservative participants are. Using an instrumental variable approach, we argue that
this relationship is causal. The COVID-19 pandemic response is characterized by a fractured
political divide in the US [22, 34] that is consistent with our result – Conservatives argue for
laissez-faire policies while Democrats favor aggressive intervention. An open question for future inquiry is whether the prominent role of ideology is specific to the US context or extends
to other countries.
Our third result is that knowing one’s position in a network of interactions matters for decisions to social distance. In particular, superspreaders who have more interactions than others
in their group tend to distance more compared to peripheral individuals and/or individuals with
the same number of interactions in a homogenous group. Superspreaders have played a pivotal
role in the diffusion of the pandemic, but, to our knowledge, research has been largely limited
to the biological element [19, 20]. Our findings show that the social dimension leads to behavioral responses that are absent in the biological realm. This is because individuals are aware of
being a superspreader in their social interactions, but are typically unaware of their biological
propensity to spread the virus. Further investigation of these behavioral responses and how to
incorporate them into policy is an interesting avenue for future research.
In terms of methodology, evidence to understand people’s behavioral responses to social
distancing policies has been based so far on either sociomobility data or survey-based studies
based on self-reported beliefs. Our study illustrates the importance of interactive web-based
experiments to complement and enhance these widely used methodologies.
Interactive web-based experiments offer insights complementary to studies based on mobility data. Experiments allow unambiguous identification of causal effects and can explore the
impact of counterfactuals – policies that have not been applied (yet) in the real world and for
8

which there is no observational data available. Moreover, though very rich, mobility data is
usually stripped of any personal information, including sociodemographics, so that inferences
about the effects of those variables can only be made for geographic units rather than individuals. Mobility data provides information on behavior in real-life settings that can uncover
the external validity of web-based experiments. For instance, recent studies using media data
validate our finding that conservative leaning individuals practice less social distancing [22,24].
In our post-experimental survey, we ask participants to estimate how effective fines and
nudges are in promoting social distancing. Participants significantly overestimate the efficacy
of nudges compared to their actual choices in the experiment independently on whether they
are in the fine (MW, p < 0.0001) or nudge (WSR, p = 0.001) treatment (Appendix A.3.2).
This difference between survey-based self-reported intentions and actual behavior is consistent
with recent evidence on the short-lived efficacy of nudges [35]. In other words, picking a
policy based on self-reported measures may lead policymakers to opt for the wrong solution.
These results caution against an excessive reliance on survey-based self-reported data to gauge
behavioral responses.

References
[1] S. M. Kissler, C. Tedijanto, E. Goldstein, Y. H. Grad, and M. Lipsitch, “Projecting the
transmission dynamics of sars-cov-2 through the postpandemic period,” Science, vol. 368,
no. 6493, pp. 860–868, 2020.
[2] R. Baldwin and B. Weder di Mauro, “Economics in the time of covid-19: A new ebook,”
VOX CEPR Policy Portal, 2020.
[3] M. S. Eichenbaum, S. Rebelo, and M. Trabandt, “The macroeconomics of epidemics,”
Working Paper 26882, National Bureau of Economic Research, March 2020.
[4] A. Chudik, K. Mohaddes, M. H. Pesaran, M. Raissi, and A. Rebucci, “A counterfactual
economic analysis of covid-19 using a threshold augmented multi-country model,” Working Paper 27855, National Bureau of Economic Research, September 2020.
[5] T. Hale et al., “Oxford covid-19 government response tracker,” 2020.
[6] C. J. Murray, “Forecasting covid-19 impact on hospital bed-days, icu-days, ventilator-days
and deaths by us state in the next 4 months,” medRxiv, 2020.
[7] F. Verelst, E. Kuylen, and P. Beutels, “Indications for healthcare surge capacity in european
countries facing an exponential increase in coronavirus disease (covid-19) cases, march
2020,” Eurosurveillance, vol. 25, no. 13, p. 2000323, 2020.
[8] J. M. Brauner, S. Mindermann, M. Sharma, D. Johnston, J. Salvatier, T. Gavenčiak, A. B.
Stephenson, G. Leech, G. Altman, V. Mikulik, A. J. Norman, J. T. Monrad, T. Besiroglu,
H. Ge, M. A. Hartwick, Y. W. Teh, L. Chindelevitch, Y. Gal, and J. Kulveit, “Inferring the
effectiveness of government interventions against covid-19,” Science, 2020.
[9] International Monetary Fund, “Policy responses to covid-19,” 2020.

9

[10] P. Block, M. Hoffman, I. J. Raabe, J. B. Dowd, C. Rahal, R. Kashyap, and M. C.
Mills, “Social network-based distancing strategies to flatten the covid-19 curve in a postlockdown world,” Nature Human Behaviour, pp. 1–9, 2020.
[11] Singapore Ministry of Health, “Infectious diseases (covid-19 – stay orders) regulations
2020,” 2020.
[12] R. Debnath and R. Bardhan, “India nudges to contain covid-19 pandemic: A reactive public policy analysis using machine-learning based topic modelling,” PLOS ONE, vol. 15,
pp. 1–25, 09 2020.
[13] D. J. Hunter, “Covid-19 and the stiff upper lip—the pandemic response in the united kingdom,” New England Journal of Medicine, vol. 382, no. 16, p. e31, 2020.
[14] A.-L. Sibony, “The uk covid-19 response: A behavioural irony?,” European Journal of
Risk Regulation, pp. 1–8, 2020.
[15] G. Baradaran Motie and C. Biolsi, “County-level determinants of social distancing (or
lack thereof) during the covid-19 pandemic,” Contemporary Economic Policy, 2020.
[16] R. O. Murphy, K. A. Ackermann, and M. Handgraaf, “Measuring social value orientation,”
Judgment and Decision making, vol. 6, no. 8, pp. 771–781, 2011.
[17] D. G. Rand, S. Arbesman, and N. A. Christakis, “Dynamic social networks promote cooperation in experiments with humans,” Proceedings of the National Academy of Sciences,
vol. 108, no. 48, pp. 19193–19198, 2011.
[18] E. Gallo and C. Yan, “The effects of reputational and social knowledge on cooperation,”
Proceedings of the National Academy of Sciences, vol. 112, no. 12, pp. 3647–3652, 2015.
[19] D. Adam, P. Wu, J. Wong, E. Lau, T. Tsang, S. Cauchemez, G. Leung, and B. Cowling,
“Clustering and superspreading potential of severe acute respiratory syndrome coronavirus
2 (sars-cov-2) infections in hong kong,” Nature Medicine, 2020.
[20] M. S. Lau, B. Grenfell, M. Thomas, M. Bryan, K. Nelson, and B. Lopman, “Characterizing
superspreading events and age-specific infectiousness of sars-cov-2 transmission in georgia, usa,” Proceedings of the National Academy of Sciences, vol. 117, no. 36, pp. 22430–
22435, 2020.
[21] A.-L. Barabási and R. Albert, “Emergence of scaling in random networks,” Science,
vol. 286, no. 5439, pp. 509–512, 1999.
[22] H. Allcott, L. Boxell, J. Conway, M. Gentzkow, M. Thaler, and D. Y. Yang, “Polarization and public health: Partisan differences in social distancing during the coronavirus
pandemic,” NBER Working Paper, no. w26946, 2020.
[23] J. M. Barrios and Y. Hochberg, “Risk perception through the lens of politics in the time of
the covid-19 pandemic,” tech. rep., National Bureau of Economic Research, 2020.

10

[24] A. Simonov, S. K. Sacher, J.-P. H. Dubé, and S. Biswas, “The persuasive effect of fox
news: non-compliance with social distancing during the covid-19 pandemic,” tech. rep.,
National Bureau of Economic Research, 2020.
[25] M. J. Hornsey, E. A. Harris, P. G. Bain, and K. S. Fielding, “Meta-analyses of the determinants and outcomes of belief in climate change,” Nature climate change, vol. 6, no. 6,
pp. 622–626, 2016.
[26] Pew Research Center, “U.S. public views on climate and energy,” 2019.
[27] N. B. Masters, S.-F. Shih, A. Bukoff, K. B. Akel, L. C. Kobayashi, A. L. Miller, H. Harapan, Y. Lu, and A. L. Wagner, “Social distancing in response to the novel coronavirus
(covid-19) in the united states,” PloS one, vol. 15, no. 9, p. e0239025, 2020.
[28] V. Galasso, V. Pons, P. Profeta, M. Becher, S. Brouard, and M. Foucault, “Gender differences in covid-19 related attitudes and behavior: Evidence from a panel survey in eight
oecd countries,” NBER Working Paper, no. w27359, 2020.
[29] M. J. Pedersen and N. Favero, “Social distancing during the covid-19 pandemic: Who are
the present and future non-compliers?,” Public Administration Review, 2020.
[30] N. W. Papageorge, M. V. Zahn, M. Belot, E. van den Broek-Altenburg, S. Choi, J. C.
Jamison, E. Tripodi, et al., “Socio-demographic factors associated with self-protecting
behavior during the covid-19 pandemic,” tech. rep., Institute of Labor Economics (IZA),
2020.
[31] P. Crosetto and A. Filippin, “The “bomb” risk elicitation task,” Journal of Risk and Uncertainty, vol. 47, no. 1, pp. 31–65, 2013.
[32] J. Haushofer and C. J. E. Metcalf, “Which interventions work best in a pandemic?,” Science, vol. 368, no. 6495, pp. 1063–1065, 2020.
[33] R. H. Thaler and C. R. Sunstein, “Nudge: Improving decisions about health, wealth, and
happiness,” 2009.
[34] A. Gollwitzer, C. Martel, W. J. Brady, P. Pärnamets, I. G. Freedman, E. D. Knowles, and
J. J. Van Bavel, “Partisan differences in physical distancing are linked to health outcomes
during the covid-19 pandemic,” Nature human behaviour, pp. 1–12, 2020.
[35] A. Brandon, P. J. Ferraro, J. A. List, R. D. Metcalfe, M. K. Price, and F. Rundhammer,
“Do the effects of social nudges persist? theory and evidence from 38 natural field experiments,” tech. rep., National Bureau of Economic Research, 2017.

11

A

Supplementary Information

This Appendix contains additional information. Appendix A.1 presents the theoretical framework and derives the hypotheses that we investigate in the experiment. Appendix A.2 summarizes our experimental design along with implementation and describes the resulting dataset.
Appendix A.3 contains details of the analysis and is followed by Appendix A.4 which describes
our robustness checks.

A.1

Theory

Consider a set of N = 1, 2, . . . , n risk-neutral agents on an unweighted and undirected network
G. If a link between agents i and j is present, then Gij = Gji = 1. Otherwise Gij = Gji = 0.
Each agent i simultaneously chooses whether to practice social distancing, at a cost c > 0 to
herself.
After agents make this choice, exactly one agent is chosen uniformly at random to be exposed to COVID-19. Call this agent patient zero. If patient zero is practicing social distancing,
then she becomes infected with probability γ < 1, and cannot pass COVID-19 on to anyone else. Otherwise, she becomes infected with probability 1, and passes it on to each of her
neighbors who are also not practicing social distancing uniformly at random with probability
α ∈ [0, 1].
Any other agent j who becomes infected with COVID-19 passes it on to each of her own
neighbors who are not practicing social distancing with probability α ∈ [0, 1], again uniformly
at random. An agent does not pass it on to any neighbor who is practicing social distancing.
Therefore, an agent who practices social distancing may only become infected if she is patient
zero.
At the end of the game, an agent receives a benefit b > c if she is not infected, and 0
otherwise. Additionally, an agent pays a fine, f ≥ 0 if she did not practice social distancing
– regardless of whether she infected anyone else or became infected herself. Note that setting
f = 0 means no fine is present.
When a subset of agents S ⊆ N practice social distancing, the probability that agent i
becomes infected is pi|Si . This depends on the network structure and on who practices social
distancing. Notice that if i ∈ S then pi|Si = γ/n, since she can only become infected if she is
patient zero.
We assume that all agents are self-interested – they care only about themselves and so ignore
any effects their choices have on others. Then agent i receives an expected payoff, πi , of:
(
(1 − nγ )b − c, if i ∈ S
(1)
πi =
pi|Si · b − f,
otherwise
Parameterization. We now set out some of the parameter values and the networks we use in the
experiment. Doing so allows us to state the hypotheses clearly. We have two different networks:
a 5-node complete network, and a 5-node star network. In the complete network each agent is
connected to every other agent. In the star network one agent is connected to every other agent,
and there is no other link in the network. We call agents in the complete network “close-knit”,
agents at the center of the star “superspreaders”, and agents on the arms of the star “peripheral”.
Denote these agents C, S, and P respectively.
12

We set the cost c of practicing social distancing equal to 35 points, the benefit b of avoiding
infection equal to 100 points, and the probability γ of patient zero becoming infected if she is
practicing social distancing equal to 0.5. This allows us to investigate how the Nash equilibrium
predictions and efficiency vary as the rate of contagion α is varied in [0, 1]. Figure A1 shows
the equilibrium and socially efficient sets in the complete network and the star network for all
values of α. A set is socially efficient if it maximizes the sum of the expected payoffs. In
the experiment, we focus on two different levels of contagion: α = 0.15 (low contagion), and
α = 0.65 (high contagion).
Complete network
0

1 2
2 3
.1.14 .19 .24.28

0

0

0

1

3

1

3

.49

2

4

.62

3

3

Star network
0

.13

0
0
Efficiency:

S
0

.31

S

.57

S

S
.63
S or
2P

S

.72

S

Rate of contagion
efficient inefficient Equilibrium:

S
S or 3P
1

efficient inefficient

Figure A1: Equilibrium and socially efficient outcomes for the rate of contagion α ∈ [0, 1]. The
other parameters are set at: b = 100, c = 35, γ = 0.5, N = 5. For the complete network, digits
indicate the number of close-knit agents practicing social distancing in an equilibrium/efficient
outcome. For the star network, S stands for the superspreader, and #P indicates the number of
peripheral agents practicing social distancing in an equilibrium/efficient outcome.
Below, we formulate a set of hypotheses which are the focus of our analysis. First, notice
that fines for failing to practice social distancing make it (social distancing) relatively more
attractive, and so we expect that they weakly increase the amount of social distancing in society.
Note that due to the non-uniqueness of equilibria, it is possible that different agents practice
social distancing when fines are present.
Hypothesis 1. A fine f > 0 for agents who do not practice social distancing weakly increases
the number of agents practicing social distancing.
The model assumes that agents are self-interested and fully rational. Therefore, while fines
can affect agents’ behavior, a behavioral ‘nudge’ should have no impact – it neither provides
new information to agents, nor does it change their preferences.
Hypothesis 2. A behavioral ‘nudge’, in the form of an informational video, has no impact on
the social distancing decisions of any agent.

13

An obvious consequence of these two hypotheses is that a fine has a weakly greater effect
on social distancing decisions than a nudge.
Hypothesis 3. A fine f > 0 increases the amount of social distancing weakly more than a
behavioral ‘nudge’.
The model predicts that the network position also plays an important role in determining
social distancing decisions. Even though close-knit agents and superspreaders have the same
number of links – and close-knit agents actually have a higher probability of becoming infected
if nobody practices social social distancing – superspreaders practice weakly more social distancing. This is because superspreaders are surrounded by peripheral agents who, with only one
link, have a low incentive to practice social distancing themselves. This leaves it all up to the
superspreader to protect themselves.
Both superspreaders and close-knit agents practice more social distancing than peripheral
agents. They have more links, and so a higher probability of becoming infected (if nobody else
practices distancing).
Hypothesis 4. Superspreaders practice more social distancing than close-knit agents, and in
turn close-knit agents practice more social distancing than peripheral agents.
We can see this from Figure A1, which sets out the equilibrium and socially efficient outcomes. In the low contagion setting, no agents practice social distancing in equilibrium (in
either the star or the complete network). In the high contagion setting, a superspreader always
practices distancing, a (randomly chosen) close-knit agent does so three fifths of the time, while
a peripheral agent never does so.
Further, agents are more likely to practice social distancing in the high contagion setting
than in the low contagion setting. This is because an agent faces a greater chance of becoming
infected by her neighbors.
Hypothesis 5. Conditional on her position in the network, an agent practices more social distancing in the high contagion setting than in the low contagion setting.
Regardless of their position in the network and the level of contagion, self-interested agents
do not account for the benefits they provide to others – in the form of reduced infection risk –
when they practice social distancing. Therefore, we expect that agents practice less social distancing than would be optimal. Hypothesis 6 confirms this intuition for the complete network,
while Hypothesis 7 shows that the there can be too little or the right amount of social distancing
(relative to the social optimum) in the star. Moreover, for certain other values of α, too much
social distancing is also possible, due to the presence of multiple equilibria in the star network.
Hypothesis 6. In the complete network, the Nash equilibrium involves fewer agents practicing
social distancing than the social optimum.
Proof. First, let us look at the Nash equilibria. Replace the probability of becoming
patient zero with its actual value in the 5-node network – i.e. 1/n = 0.2. Notice that,
if the expected payoff of practicing social distancing is weakly greater than that of not
doing so when everybody else practices social distancing, then everybody should opt
for social distancing. That is, if (1 − 0.2γ)b − c ≥ (1 − 0.2)b, then there is a unique
equilibrium in with all agents practice social distancing.
14

Conversely, if (1 − 0.2γ)b − c < (1 − pi|∅ )b, where pi|∅ is the probability that the
close-knit agent becomes infected given that nobody practices social distancing, then
the unique equilibrium is such that nobody practices distancing.
Between these two boundaries on the cost of social distancing, given a fixed parameterization, the number of agents practicing social distancing in a Nash equilibrium rises monotonically. For example, when (1 − 0.2γ)b − c < (1 − 0.2)b and
(1 − 0.2γ)b − c ≥ (1 − pi|3 )b, where pi|3 is the probability that the close-knit agent
becomes infected given that three other close-knit agents practice distancing, four
agents practice social distancing in the unique equilibrium. It is easy to show, that
nobody wants to deviate from the chosen strategy, if the above conditions hold. The
conditions which ensure that two or one agents practice social distancing in a Nash
equilibrium are determined analogously.
Let us now turn to efficiency. First, note that if (1 − 0.2γ)b − c ≥ (1 − 0.2)b
then the expected total social payoff is maximized when everybody practices social
distancing. Next, there is a range of parameters, for which efficiency demands that
exactly four agents practice social distancing. This requires that c > 0.2(1 − γ)b and
c ≤ (2pi|3 − 0.2 − 0.2γ)b. Other intervals can be established in an analogous manner.
The top panel of Figure A1 shows how equilibrium and efficient sets of agents
who practice social distancing in a complete network change when the rate of contagion α is varied. All other parameters are fixed according to our parameterization.
Observe that in the low contagion environment (α = 0.15) nobody practices social
distancing in the unique Nash equilibrium, yet, efficiency demands that exactly two
agents undertake social distancing. Similarly, in high contagion (α = 0.65), three
agents practice social distancing in an equilibrium while the efficient outcome is four
agents doing distancing.

Next, Hypothesis 7 shows that, depending on the parameterization, the level of social distancing practiced in a Nash equilibrium in the star network can be below, coincide with, or
exceed the efficient outcome.
Hypothesis 7. In the star network: (1) in the low contagiousness environment, the Nash equilibrium involves fewer agents practicing social distancing than the social optimum; (2) in the
high contagiousness environment, the Nash equilibrium and the social optimum coincide (with
the hub agent practicing social distancing).
Proof. First, let us look at the Nash equilibria. Analogously to the proof for the
complete network, if (1−0.2γ)b−c ≥ (1−0.2)b, then there is a unique equilibrium in
with all agents practice social distancing. This is because everybody should practice
social distancing when the expected payoff of doing it is weakly greater than that of
not doing so even when everybody else practices social distancing.
On the other hand, if the expected payoff of practicing social distancing for both
the superspreader and the peripheral agent is lower than that of not doing so, even
if everybody else does not practice distancing, then nobody should opt for social
distancing in equilibrium. Using the notation, that means that there is a unique equilibrium where nobody practices social distancing if (1 − 0.2γ)b − c < (1 − pS|∅ )b and
(1 − 0.2γ)b − c < (1 − pP |∅ )b, where pS|∅ (pP |∅ ) is the probabilities that the superspreader (peripheral agents) becomes infected if nobody practices social distancing..

15

It follows trivially then that for all the rest of the parameter space, there is an
equilibrium such that only the superspreader practices social distancing, while all
peripheral agents do not. This is, however, not always the unique equilibrium. In
fact, for some values of the parameters, there could also be an equilibrium where the
superspreader does not undertake social distancing but (some of the) peripheral agents
do. For example, in our parameterisation, for α ∈ (0.72, 1] there is an equilibrium in
which three peripheral agents practice social distancing. To see this, note that nobody
of the three peripheral agents who practice social distancing want to deviate because
(1 − 0.2γ)b − c ≥ (1 − pP |2P ), where pP |2P = 0.2 + 0.2α + 0.2α2 – the pribability
that a peripheral agents becomes infected if two other peripheral agents practice social
distancing. Moreover, both the superspreader and the fourth peripheral agent do not
want to deviate because (1 − 0.2γ)b − c < (1 − pS|3P )b, and pS|3P = pP |3P =
0.2 + 0.2α.
Now to efficiency. Observe that, depending on the parameterisation, efficiency
permits only one of the three possible outcomes. The first one is the case where
everyone undertakes social distancing. This is efficient if the total expected payoff
of everyone practicing social distancing exceeds that of the case where all but one
agent practice distancing. Mathematically, this means that 5 × [(1 − 0.2γ)b − c] ≥
4 × [(1 − 0.2γ)b − c] + (1 − 0.2)b.
Next, note that for some values of the parameters, efficiency demands that nobody
undertakes social distancing. For this to be true, it must be that the total expected
payoff when exactly one agent practices social distancing is lower than when nobody
does distancing. It must therefore be true that 4 × (1 − pP |∅ )b + (1 − pS|∅ )b >
4 × (1 − 0.2)b + (1 − 0.2γ)b − c and 4 × (1 − pP |∅ )b + (1 − pS|∅ )b > 3 × (1 − pP |1P )b +
(1 − pS|1P )b + (1 − 0.2γ)b − c. Note that, for α ∈ (0, 1), the second condition is
automatically satisfied when the first one holds because 0.2 is strictly less than both
pS|1P and pS|1P .
Finally, for 0.2(1 − γ)b ≤ c < 0.2(4 + 8α + 12α2 − γ)b efficiency requires that
the superspreader practices social distancing but not the peripherals. This follows
trivially since the benefit created when the superspreader practices social distancing
is larger by that of the peripheral agent, yet the costs are the same.
Figure A1 shows how equilibrium and efficient sets of agents who practice social distancing change when the rate of contagion α is varied. All other parameters
are fixed according to our calibration. Now to the specific values chosen in our parameterisation. Observe that in the low contagion environment (α = 0.15) nobody
practices social distancing in the unique Nash equilibrium, yet, efficiency demands
that the superspreader opts for distancing. Conversely, in high contagion (α = 0.65),
equilibrium and efficiency coincide with only the superspreader practicing social distancing. One can also show that the equilibrium for α = 0.65 is unique.

When an agent practices social distancing, she gets a fixed payoff in all cases except when
she is patient zero and becomes infected. This latter scenario occurs with probability nγ . When
she does not practice social distancing, then her payoff depends on other agents’ behavior, and
on how COVID-19 randomly spreads through the network. The payoff is more variable when
she does not practice social distancing. Therefore, a risk averse agent will practice weakly
more social distancing than the model predicts. There are of course many ways of modeling
16

risk aversion, but the qualitative impact of higher risk aversion on social distancing decisions
does not depend on the particular modeling choices. It will always weakly increase the amount
of social distancing an agent practices.
Hypothesis 8. The amount of social distancing an agent practices is weakly increasing in her
level of risk aversion.
An agent might also care about other agents’ welfare (as captured by their payoffs). That
is, they might have altruistic preferences. Choosing to practice social distancing has a spillover
effect – it reduces the probability that some other agent becomes infected with COVID-19, at no
cost to that other agent. The spillover can only be positive. If agent i chooses to practice social
distancing, this never imposes a cost on anyone else, and can provide a benefit to some others.
Therefore, altruistic preferences can only (weakly) increase the amount of social distancing that
an agent does. This does not depend on how one chooses to model altruistic preferences.
Hypothesis 9. An agent with other-regarding (i.e. altruistic) preferences practices weakly more
social distancing than in the Nash equilibrium.

A.2

Experiment

This section explains the design and implementation of the experiment and describes the data.
Appendix A.2.1 describes the design of the experiment and presents the flow of the experimental session. Next, in Appendix A.2.2, we summarize the details of our implementation, including technical aspects and sampling procedures. Finally, in Appendix A.2.3 we summarize our
dataset.
A.2.1

Design

Calibration. Throughout the experiment, we set the cost of social distancing at c = 35 points,
and the benefit of not getting infected at b = 100 points. We also set the probability of patient
zero becoming infected if she practices social distancing at γ = 0.5. Further, our experiment
has three dimensions which are varied in our treatments. These are:
• two 5-node networks: (1) a complete network, where everyone is connected to everyone
else, and (2) a star network, where one node is connected to all other nodes which are not
connected between themselves;
• two levels of the rate of contagion: (1) low (α = 15%), and (2) high (α = 65%).
• two types of intervention: (1) a fine for not practicing social distancing f = 15 points,
and (2) a behavioral nudge highlighting the harm caused to others by not practicing social
distancing.
Consequently, we have a 2 × 2 × 2 full-factorial design, with a total of 8 treatments. We run
each treatment 10 times, resulting in a final sample of 400 participants. Further details on the
resulting sample are in Appendix A.2.3.
In the remainder of this section, we set out the flow of the experiment. For expository
purposes, we focus on the star network, 65% rate of contagion treatment. We also explain both
fine and nudge interventions.
17

No
No!

Yes

Practice
social
distancing?

Social distancing
no (-f)

Choosing
patient
zero

yes (-c)
Infection status
healthy (+b)
infected (0)

Allocation
of
positions

No!
No

Contagion

Payoffs

Contagion

Link types
protected
contagion with
probability α
no contagion with
probability (1-α)
Current spreader

Figure A2: Flow of a typical round of Baseline and Intervention. In the experiment, we use
the following parameterization: f = 0 or 15 (fine Intervention only); c = 35; b = 100; α =
0.15 (low contagion) or 0.65 (high contagion). Final payoffs for the round are a combination
of individual social distancing choice and infection status. For example, a participant who
practices social distancing and is healthy, receives (−c + b) or 65 points. In the figure, the
chosen network architecture is the star. In the experiment, half of the treatments had the star
network architecture and the other half had the complete.
Once a participant joins the session, she enters her ID and starts working on instructions for
the first part of the experiment, which we refer to as the Baseline. To qualify for the experiment
she must read the instructions and pass an understanding quiz. The instructions together with
the quiz take an average of 8.8 minutes (s.d. 3.3 minutes) to complete. As part of the instructions, the participant is explicitly primed to think about COVID-19. In particular, we explicitly
describe the main symptoms of COVID-19 using official US guidelines. Full instructions are in
Appendix B.1. Upon successfully completing the quiz, the subjects joins a waiting room where
she waits to be matched with 4 others. Rather than being allocated into groups on a first-comefirst-served basis, group allocation is randomized. Once a group is formed, participants proceed
to the Baseline where they play 20 rounds of the same game.
Figure A2 presents the flow of a typical round. At the beginning, participants are randomly
allocated to the five positions on the network (top-left corner of Figure A2) which is fixed
throughout the whole experiment. In this example, the network is a star. The participant is asked
to privately make her social distancing decision (top-center part of Figure A2). Practicing social
distancing costs 35 points, while not practicing social distancing is free. The participant has 20
seconds to make her decision, otherwise she receives a penalty of 200 points and her decision
is automatically recorded as a “No”. A participant who fails to submit her decisions in three
consecutive rounds is disqualified from the experiment and does not receive any compensation.
Once everyone in the group has made their decisions, the computer randomly selects exactly
one participant to be patient zero (top-right corner of Figure A2). If patient zero is not practicing
social distancing she becomes infected with COVID-19 with certainty. If patient is practicing
social distancing, however, she becomes infected with probability 50%. In the example in
18

Figure A2, patient zero decided not to practice social distancing, and therefore she becomes
infected.
As explained in Appendix A.1, since patient zero is infected and does not practice social
distancing, she may pass COVID-19 to other participants. In our example, patient zero only
interacts with the superspreader – who is not practicing social distancing. Therefore, the superspreader becomes infected with probability α = 0.65. In our example, contagion is successful,
and the superspreader becomes infected (bottom-right corner of Figure A2). Next, the superspreader can potentially infect two out of three other participants in peripheral positions, since
one of them is practicing social distancing and so is protected from contagion. In our example,
one of the participants in the peripheral position becomes infected, which happens with probability 65%, and the other remains healthy, which occurs with probability 35%, as shown in the
bottom-center part of Figure A2.
At the end of the contagion process, payoffs for the round are determined based on participants’ social distancing decisions and infection status. Healthy participants receive a bonus of
b = 100 points while infected ones get 0 points, minus the cost of social distancing c = 35
points if applicable. In our example, three participants end up with a payoff of zero points, one
gets 65, and one 100 (bottom left corner of Figure A2).
At the end of each round, a participant is informed of her health outcome and the number of
points earned, and is also reminded about her position within the network and social distancing
choice. This information is presented for the last five rounds, and the participant has 15 seconds
to review this information. Notice that the participant is not informed about decisions and
outcomes of other members of her group at any point during the experiment.
Once participants complete the Baseline, they are taken to the instructions for the second
part of the experiment, to which we refer as Intervention. The instructions for the Intervention differ depending on the treatment. In our example, the intervention is the fine. Therefore,
participants are shown textual instructions explaining how the fine works. If instead the intervention is the nudge, participants are shown a three-minute video highlighting the harm to
others caused by not practicing social distancing. Further details and instructions for the two
types of intervention are in Appendix B.1. Upon completing the instructions, participants must
pass a one-question understanding quiz. Once all five participants pass the quiz, they proceed
to the Intervention.
In the Intervention, participants play 20 rounds of the same game as in the Baseline. In
particular, the network and the rate of contagion remain unchanged. For nudge treatments,
payments also remain unchanged. In the fine treatment, participants who decide not to practice
social distancing receive a fine of f = 15 points, irrespective of their health outcome. That is,
a participant who does not practice social distancing in a round can receive either 85 points or
-15 points depending on her health outcome.
Once participants have completed the Intervention, the interactive part of the experiment is
over, and they proceed to the Post-experimental Questionnaire. Here, we ask the same set of
demographics questions as in the recruitment survey. In addition, we ask a set of knowledge and
attitudes questions on a range of topics including the COVID-19 pandemic, social distancing,
religion, global warming, ideology and political affiliation.
Finally, a participant completes a Bonus Task which is the Bomb Risk Elicitation Task
(BRET) [31, 36] to elicit risk preferences. The participant is presented with 100 boxes arranged
in a 10 × 10 matrix. Of these, one randomly chosen box contains a bomb, but the location
of the bomb is unknown. The participant is asked to choose how many boxes she wants to
19

collect. Boxes are collected from the top-left corner of the matrix, left to right, at a rate of one
box per second. The participant must decide when to stop collecting the boxes. The value of
each box is 2 cents. After she is done with collecting boxes, the subject opens them. If one
of her collected boxes contains the bomb, it explodes and reduces participant’s earnings for the
Bonus Task to zero. If the bomb is not in the collected boxes, the participant earns 2 cents
for each collected box. Assuming a power utility function1 , a risk-neutral participant opens
50 boxes. If a participant opens fewer than 50 boxes, she is considered risk-averse, and if she
opens more than 50 boxes she is considered risk-seeking. Instructions for the BRET together
with screenshots of the interface are in Appendix B.3.
Once the participant completes the Bonus Task, she is taken to the Payment Page, where she
can see her earnings for the experiment. She can also browse her history of play in the Baseline
and Intervention. All participants are paid a fixed fee of $1. Additionally, participants earn a
performance-based bonus for the interactive part of the experiment, as well as the Bonus Task.
In particular, to reduce wealth effects [37], subjects are paid for 4 randomly chosen rounds in
Baseline and Intervention.
A.2.2

Implementation

We conducted the experiment on Amazon Mechanical Turk (henceforth, Mturk; www.mturk.
com) between May 4th and May 29th 2020. The experiment involves two separate processes
– recruitment and the main experiment. We used Qualtrics (www.qualtrics.com) for recruitment, and the main experiment was programmed in o-Tree (www.otree.org) [38] with
a server deployed on Heroku (www.heroku.com).
For recruitment, we set qualifications on MTurk to make our survey visible to US residents
who have completed at least 500 Human Intelligence Tasks (HITs) on the platform and have an
approval rate of at least 96%. We also utilize location and age qualifications provided by MTurk
to get a sample that is broadly representative of the US population.
The recruitment survey takes an average of 5 minutes (s.d. 3 minutes) to complete and pays a
fixed reward of $1. As part of the survey, we collect information about participants’ age, gender,
experience with decision-making experiments, and self-reported attitudes to risk [39]. Additionally, we inform participants about the upcoming interactive experiment and collect their consent
for participation. Further, the survey contains several questions that test understanding of basic
concepts of probability. Only those participants who correctly answer the qualifying questions
and give their consent for participation are subsequently invited to the main experiment.
Participants who correctly answer the qualifying questions take part in a bonus task for a
chance to win an amount in the $0.6-4.0 range. The bonus task is the 6-item Social Value Orientation (SVO) task [16]. The underlying idea of the SVO framework is that people vary in terms
of their motivations when evaluating different allocations of resources between themselves and
others. Consequently, the SVO scale identifies four different types of preferences: individualistic, competitive, prosocial, and altruistic. On a practical level, for each of the 6 items of
the SVO scale, participants are asked to choose between nine different allocations of money
between self and another person. These preferences are then used to determine subjects’ types.
Further details on the distribution of types in our sample is in Appendix A.2.3. The instructions
for the SVO scale along with screenshots of the interface from the recruitment survey are in
Appendix B.2.
1

Utility of payoff x is defined as u(x) = xr , where r is the risk aversion coefficient.

20

We use the U.S. Census Bureau 2018 estimates of the demographics composition of US
states to get age-gender-state distribution of the adult American population [40]. With respect
to age, we use 6 categories that match those provided by MTurk qualifications: 18-25, 25-30,
30-35, 35-45, 45-55, and 55+. We also group US states into 10 Standard Federal Regions as
defined by the Office of Management and Budget.2 Figure A4 shows the map of the US divided
into these 10 regions. The resulting distribution is presented in Table A2. Note that we do not
consider US territories.
During recruitment, we use the distribution in Table A2 to generate a diverse standing panel
of qualified participants. We then email a random sample from the panel, inviting them to the
experiment. In the invitation email, we ask participants to search for the experiment on MTurk
at the specified time, and click on the link provided in the description of the HIT. Doing this
transfers them to our application on Heroku.
For a typical session of the experiment, we invite a representative sample of 150-200 participants to fill 30-35 places on a first-come-first-served basis. We rely on the distribution in
Table A2 to determine the demographics of the invitees and then draw a random sample with
the required characteristics from our standing panel. Throughout the experiment, we keep track
of the demographics of those participants who have completed the experiment to minimize overand under-sampling. Finally, to ensure random assignment into treatments, we randomize the
order of experimental sessions.
It is important to note, however, that it is impossible to control precisely the demographics
of the participants who actually (a) show up, and (b) complete all parts of the experiment.
Nevertheless, the final sample is very diverse and near-representative in terms of age, gender and
geographic location. Further details on the sample and its characteristics and representativeness
of the adult US population are in Appendix A.2.3.
On average, the experiment takes 30 minutes (s.d. 6 minutes) to complete and pays $5.81
(s.d. $1.1) including a $1 fixed fee. Upon completing the experiment, participants receive a
code to submit on MTurk.
Throughout the experiment, we keep track of the IP addresses of those participants who
already took the experiment, and exclude participants with duplicate IP addresses from our
standing panel.
A.2.3

Data

The experimental data contains decisions of 400 participants. Each participant took part in one
session, so she took part in one of the eight treatments. For all treatments, we collected data
for 10 groups of 5 participants each. In each treatment, participants interacted for a total of 40
rounds, so we have 16,000 decisions in total. We also match the experimental data with data
from the recruitment survey.
To check there are no biases in assigning subjects to treatments, we run a chi-squared test
on participants’ assignment to treatment (a categorical variable with 8 options) and gender,
age category, and geographical location variables. Results indicate that subjects in all eight
experimental treatments are not significantly different from each other (two-sided χ2 , p > 0.05).
This suggests that our randomization procedures outlined in Appendix A.2.2 was effective.
Apart from data on subjects’ decisions in the experiment, we collect data on a set of variables, which can be broadly categorized as follows: demographic controls, preference controls,
2

Circular A-105, “Standard Federal Regions,” April, 1974.

21

and location-based controls. Table A1 presents summary statistics for some of these controls.
Table A1: Summary statistics the main controls.
Variable
Demographic controls
Age
Gender
Race
Education
Out of labor force
Unemployed
Christian religion
Other religion
Preference controls
Protect others
Ideology score
Global warming skepticism score
BRET score
SVO type
Location-based controls
Population density
Cumulative cases
Daily deaths
Stay-at-home-orders

X̄

s.d.

43.91 14.13
0.47
0.02
0.84
0.02
15.34 2.04
0.19
0.02
0.11
0.02
0.39
0.02
0.12
0.02

Comments
Measured in years
Female = 1
White = 1
measured in the number of years
Yes = 1
Yes = 1
Yes = 1
Yes = 1

0.57
0.02 Yes = 1, see text for details
3.08
3.06 ∈ [0, 12], see text for construction details
1.99
3.10 ∈ [0, 12], see text for construction details
34.73 18.23 ∈ [0, 100]
0.58
0.02 Prosocial = 1
2.35
6.32
63.43 86.33
54.81 64.23
0.62
0.02

Measured in 1,000’s at county level
Measured in 1,000’s at state level
Measured at state level
Yes = 1, measured at state level

Sample size is 400, except for SVO Scale task which 6 subjects did not complete; X̄ – mean value,
or proportion in case of binary variables; s.d. – standard deviation.
Demographic controls. All participants are resident in the US, 47% are female, and the
mean age is just under 44 years. 84% of our subjects are white, and 70% are employed (either
full- or part-time). Further, we estimate the number of years of education received based educational attainment.3 Based on this, the average subject in our sample has 15.3 years of education.
Finally, 51% of our participants consider themselves religious, with 39% reporting Christianity
as their religion.
Preference controls. A total of 92.5% of subjects reported that they try to stay at home
as much as possible because of the COVID-19 pandemic. Of these, 61.6% (or 57% of the full
sample) report that the desire to ‘protect others’ is one of the main reasons behind this decision.
To capture subjects’ political ideology, we construct an index from three questions in the
Post-experimental Questionnaire. These questions ask about: 1) subjects’ support for President
Donald Trump’s handling of the COVID-19 pandemic, 2) their support for universal healthcare,
and 3) their belief that social distancing measures impose unjustified economic costs. All are on
a 5-point Likert scale [41], and so yield a 13-point index (0-12). Responses that indicate support
for President Trump, opposition to universal healthcare, and belief in the unjustified economic
3

To do this we assume that all subjects took the standard number of years to complete each qualification, and
undertook no education that did not lead to a qualification.

22

costs of social distancing measures are scored positively. Higher scores therefore indicate a
more Conservative ideology. In our sample, the mean ideology score is 3.1 (s.d. 3.1), and over
75% of subjects have a score of 5 or less.
We also collect information on participants’ attitudes to climate change. Specifically, we our
post-experimental survey includes three 5-point Likert scale questions asking whether subjects
believe that global warming is (1) happening, (2) caused mostly by human activity, and (3)
affecting weather in the United States [42]. The resulting climate change attitudes index is on a
0-12 scale, with higher scores indicating greater skepticism towards climate change. The mean
score in our sample is 1.99.

(a) BRET, n=400

0

20

40

60

(b) SVO Scale, n=394

80

100 -12.04°

22.45°

57.15°

Figure A3: Bomb Risk Elicitation Task (BRET) and Social Value Orientation (SVO) Scale
distributions for the sample. We draw a vertical line on the subplots for each subject whose
score in BRET/SVO is of the corresponding value. More intense line color indicates that more
subjects are concentrated at that value.
Further, as explained in the previous sections, we also collect information on subjects’ social value (SVO) and risk (BRET) preferences. Figure A3 presents the distributions of these
preferences for our sample. The average subject in the sample is moderately risk averse, with a
BRET score of 34.73 boxes. When it comes to social values, the majority of our subjects (58%)
are classified as prosocial (with SVO angle ≥ 22.45◦ and < 57.15◦ ). The second largest category in the sample are individualists (the angle is ≥ 12.04◦ and < 22.45◦ ). Notice that we only
have 1 subject who is classified as competitive (angle < −12.04◦ ), and no subjects classified as
altruistic (angle ≥ 57.1◦ ).
Location-based controls. As part of both recruitment and the experiment, we collect subjects’ IP-addresses. We use these to infer their geographic location, down to the county-level.
Figure A4 shows the region-level distribution of our sample.
Further, using location information, we create a set of location-based control variables. First,
for each subject, we record population density at the county level. The average density in the
sample is 2.4k per square mile [43, 44]. Second, we use location data together with data on the
development of the COVID-19 pandemic in the US. In particular, for each subject we record
the number of cumulative COVID-19 cases (average 63.4k) and new COVID-19 related deaths
(average 59) in the state on the day of the experiment. We also record whether stay-at-home
orders were in place in the participant’s state on the day of the experiment. In our sample, 62%
of the subjects had stay-at-home orders in place on the day they participated in our experiment.
Sample representativeness. We check the representativeness of our sample along the three
23

Table A2: Age-gender-location distribution of the US adult population.
Region
I
II
III
IV
V
VI
VII
VIII
IX
X

18-25
M
F
0.29
0.51
0.56
1.21
0.99
0.83
0.28
0.25
0.98
0.26

0.29
0.50
0.54
1.15
0.95
0.78
0.26
0.23
0.92
0.24

25-30
M
F
0.20
0.41
0.43
0.92
0.73
0.63
0.19
0.19
0.81
0.22

0.19
0.40
0.42
0.91
0.70
0.61
0.18
0.18
0.76
0.2

30-35
M
F
0.19
0.39
0.41
0.83
0.67
0.60
0.18
0.18
0.75
0.21

0.19
0.39
0.41
0.84
0.66
0.58
0.18
0.17
0.71
0.20

35-45
M
F
0.34
0.70
0.74
1.58
1.27
1.10
0.34
0.33
1.34
0.38

0.35
0.71
0.76
1.65
1.27
1.10
0.34
0.31
1.31
0.36

45-55
M
F
0.38
0.73
0.78
1.66
1.31
1.01
0.33
0.28
1.27
0.34

0.41
0.77
0.81
1.74
1.33
1.03
0.33
0.27
1.28
0.34

55+
M

F

0.85
1.51
1.70
3.64
2.88
1.97
0.77
0.60
2.54
0.76

1.00
1.83
2.01
4.33
3.33
2.29
0.89
0.65
2.92
0.85

Total: 100%
All numbers are in percentage terms; ‘18-25’ etc. – age categories; ‘M’ – males, ‘F’ – females;
we divide states into 10 Standard Federal Regions (Office of Management and Budget) defined
as follows: I – CT, ME, MA, NH, RI, VT; II – NJ, NY; III – DE, DC, MD, PA, VA, WV; IV
– AL, FL, GA, KY, MS, NC, SC, TN; V – IL, IN, MI, MN, OH, WI; VI – AR, LA, NM, OK,
TX; VII – IA, KS, MO, NE; VIII – CO, MT, ND, SD, UT, WY; IX – AZ, CA, HI, NV; X –
AK, ID, OR, WA. Note that we exclude US territories.
dimensions as defined in Appendix A.2.1 – i.e. age, gender, location. Table A2 presents the
distribution of the US adult population. The gender distribution of our sample is not statistically
different from that of the adult US population (two-sided t-test, p = 0.11). Further, Figure A4
presents a map of the US divided into the 10 Standard Federal Region. For each region, we
indicate the target number of people and the realized count in our sample. The difference between the observed and target location distributions is not significant (two-sided χ2 , p = 0.08).
When it comes to age, our distribution is unfortunately not quite representative of the adult US
distribution (two-sided χ2 , p < 0.0001). In particular, the 35-45 and 45-55 age categories are
over-represented, while the 55+ is under-represented.

A.3

Statistical analysis

This section presents detailed statistical analysis. Appendix A.3.1 tests for a structural break
in the data between Baseline and Intervention. Appendix A.3.2 then presents analysis at the
aggregate (group) level, and Appendix A.3.3 focuses on the individual level.
A.3.1

Structural break identification

We use a Wald test to look for a single structural break in social distancing decisions over time.
This involves performing a simple linear regression of social distancing decisions (left-hand
side) on the round number (right-hand side), and then testing whether the coefficient on the
time variable exhibits a structural break. The test assumes there is at most one structural break,
but is agnostic as to at what point it may occur.
24

Region
X
22/17

§

Region II
46/35

L

.

Region VIII
13/14

I

:*

"

t:*

←

"

¥

Region IX
58/62

.

.

!

Hmmm

÷

Region X

\

is IT
.

Region VII
22/17

-

"

/

¥1\
,

'

Region V
75/64

imma:÷

Region IV
66/82

←

Region I
21/19

and

?TE÷i

"

I

Region III
41/38

-

TEES

undersampled by 21-30%
undersampled by 11-20%
within +/-10%
oversampled by 11-20%
oversampled by 21-30%

Region VI
36/50

Region IX

Figure A4: Location distribution, created with www.mapchart.net. States are divided into 10
Standard Federal Regions, using the same definition as Table A2. X/Y indicate participants
counts, where X indicates the actual count in our sample, and Y – the target representative
count. We divide states into 10 Standard Federal Regions (Office of Management and Budget)
defined as follows: I – CT, ME, MA, NH, RI, VT; II – NJ, NY; III – DE, DC, MD, PA, VA,
WV; IV – AL, FL, GA, KY, MS, NC, SC, TN; V – IL, IN, MI, MN, OH, WI; VI – AR, LA,
NM, OK, TX; VII – IA, KS, MO, NE; VIII – CO, MT, ND, SD, UT, WY; IX – AZ, CA, HI,
NV; X – AK, ID, OR, WA. Note that we exclude US territories.
We perform this test on the data at three levels of aggregation. First, we consider all observations together. Second, we split by the rate of contagion and the policy intervention. This
gives four equal sized group: (1) 15% contagion, fine; (2) 15% contagion, nudge; (3) 65% contagion, fine; and (4) 65% contagion, nudge. Finally, we subdivide each of the four groups above
by network type (i.e. complete vs star).
If the policy intervention is effective then we expect the test would find a structural break
at round 21. With all observations together, the Wald test finds the structural break at round 21
(p < 0.001). When considering the dis-aggregated data, the Wald test finds a structural break at
round 21 for each of the subsets, except for complete networks with the nudge treatment.

25

Table A3: Results from Structural Break analysis using the Wald Test
Low contagion:
Treatment Network
fine
all
fine
complete
fine
star
nudge
all
nudge
complete
nudge
star
A.3.2

α = 0.15
Break p-value
21
< 0.001
21
< 0.001
21
< 0.001
21
< 0.001
7
< 0.001
21
< 0.001

High contagion α = 0.65
Treatment Network Break p-value
fine
all
21
< 0.001
fine
complete 21
< 0.001
fine
star
21
< 0.001
nudge
all
21
< 0.001
nudge
complete 16
< 0.001
nudge
star
21
0.009

Aggregate level

In this section, we focus on aggregate analysis of the decision data and conduct a set of nonparametric tests. Since individual observations are correlated at the group level, our unit of observation is a group of 5 participants. Recall that we have 80 groups in total, equally distributed
across 8 treatments. For each group, we calculate the average proportion of participants that
practice social distancing in the last 10 rounds of both parts of the experiment. Below, we refer
to this average as ‘distancing levels’. We discard the first 10 rounds of both parts of the experiment because our participants display clear convergence behavior. In particular, by round 11, in
both Baseline and Intervention at least 80% of participants converge to a particular strategy in
all treatments. Further details on convergence behavior is in Appendix A.4.1. Appendix A.4.2
shows that most of the results below are robust to including all 20 rounds of both parts of the
experiment.
Results. Table A4 presents the results of the non-parametric tests – Mann-Whitney U-test
(MW) [45] for unmatched samples and Wilcoxon Signed-Rank test (WSR) [46] for matched
samples. Samples are matched when they are generated by same set of groups (e.g. comparing
distancing levels in Baseline with those in Intervention after the introduction of a fine). On the
other hand, when we make comparisons across groups from different treatments (e.g. those
that were exposed to low rate of contagion versus high rate) then samples are independent or
unmatched. Appendix A.4.2 shows that all of the findings of this section are robust to using
parametric analogues of these non-parametric tests.
In our aggregate analysis, we test the set of hypotheses in Appendix A.1. Note that we
cannot test Hypotheses 8 and 9 here, which are instead covered in Appendix A.3.3. Part 1 of
Table A4 shows that the data from the Baseline from fine and nudge treatments can be pulled
together as these samples are statistically identical at all conventional significance levels. This
result is robust to various specifications.
In Part 2 of Table A4 we examine the effect of introducing a fine in Intervention. From
the table, it is evident that a fine has a positive and statistically significant effect on distancing
levels compared to the Baseline with no fine in all specifications considered. Most results in this
part are statistically significant at least at the 5% level. The effect of the fine is also sizable – it
results in an increase in mean distancing levels of 5% to 9% depending on the specification. The
following result summarizes the above observations. Notice that the numbering of all results in
this section corresponds to the numbering of Hypotheses in Appendix A.1.
Result A-1. Introduction of the fine increases the level of social distancing. The effect is observed for all three positions as well as for the two rates of contagion. The effect is both
26

Table A4: Non-parametric analysis at the aggregate level, last 10 rounds used.
Null Hypothesis

Rate of
contagion

Position

Alt

Test

n

∆X̄

∆X̃

p-val

.03
.01
.02
.07
.02
.05

.05
0
.15
.1
-.01
.01

.33
.81
.47
.20
.73
.34

.07
.07
.09
.07
.05
.09

.03
.07
0
0
.03
.1

.0008
.01
.09
.04
.04
.003

***
**
*
**
**
***

.04
.04
.01
.04
0.0
.07

.04
.07
.05
.06
-0.1
.08

.008
.05
.50
.06
.50
.0003

***
**

.07
.04
.1
.09
.07
.07

.04
0
.1
.04
.03
.03

.08
.24
.06
.14
.15
.12

*

Sig

Part 1. Baseline
all
all
40
all
close-knit
20
all
superspreader
20
Fine vs nudge
2-sided MW
all
peripheral
20
15%
all
20
65%
all
20
Part 2. Intervention vs Baseline. Hypothesis 1 (fine has an effect)
all
all
40
all
close-knit
20
Fine: Intervention
all
superspreader
20
1-sided WSR
vs Baseline
all
peripheral
20
20
15%
all
65%
all
20
Part 3. Intervention vs Baseline. Hypothesis 2 (nudge has an effect)
40
all
all
all
close-knit
20
Nudge: Intervention
all
superspreader
20
1-sided WSR
all
peripheral
20
vs Baseline
15%
all
20
65%
all
20
Part 4. Intervention. Hypothesis 3 (fine is more effective than nudge)
all
all
40
20
all
close-knit
all
superspreader
20
Fine vs nudge
1-sided MW
all
peripheral
20
15%
all
20
65%
all
20
Part 5. Baseline. Hypothesis 4 (superspreader > close-knit > peripheral)
all
–
40
Superspreader vs
15%
–
1-sided MW 20
close-knit
65%
–
20
all
–
40
Close-knit vs
1-sided MW 20
15%
–
peripheral
65%
–
20
all
–
40
Superspreader vs
15%
–
1-sided WSR 20
peripheral
65%
–
20

27

*
***

*

.1
.19
.004
***
.1
.18
.03
**
.1
.21
.03
**
.16 .11
.0001 ***
.17 .20
.006
***
.15 .01
.003
***
.26 .30 <.0001 ***
.27 .38
.0007 ***
.25 .31
.0001 ***
Continued on next page

Continued from previous page
Null Hypothesis

Rate of
contagion

Position

Alt

Test

n

∆X̄

∆X̃

p-val

Sig

Part 6. Intervention. Hypothesis 4 (superspreader > close-knit > peripheral)
40 .1
.17
.002
***
all
–
Super-spreader vs
15%
–
.01
**
1-sided MW 20 .12 .16
close-knit
20 .08 . 12
.01
**
65%
–
all
–
40 .16 .16
.0002 ***
Close-knit vs
1-sided MW 20 .21 .18
.0009 ***
15%
–
peripheral
65%
–
20 .11 .16
.02
**
40 .25 .33 <.0001 ***
all
–
Superspreader vs
.0001 ***
15%
–
1-sided WSR 20 .32 .34
peripheral
65%
–
20 .19 .28
.0007 ***
Part 7. Baseline. Hypothesis 5 (more distancing in high contagion compared to low contagion)
40 .1
.06
.01
**
all
all
65% vs 15% rate of
all
close-knit
20 .09 .07
.09
*
1-sided MW
20 .09
.1
.16
contagion
all
superspreader
all
peripheral
20 .11 .16
.03
**
Part 8. Intervention. Hypothesis 5 (more distancing in high contagion compared to low contagion)
40 .15 .14
.0002 ***
all
all
65% vs 15% rate of
all
close-knit
20 .12 .14
.009
***
1-sided MW
20 .08
.1
.05
**
contagion
all
superspreader
all
peripheral
20 .22 .16
.002
***
Part 9. Baseline. Hypothesis 6 (actual versus equilibrium/efficient outcomes in complete network)
Actual vs
15%
all
20 .63 .62 <.0001 ***
1-sided MW
20 .11 .09
.004
***
equilibrium
65%
all
15%
all
20 .23 .22 <.0001 ***
Actual vs efficient
1-sided MW
20 -.09 -.11
.01
**
65%
all
Part 10. Baseline. Hypothesis 7 (actual versus equilibrium/efficient outcomes in star network)
superspreader
20 .73
.8 <.0001 ***
15%
Actual vs
peripheral
20 .46 .42 <.0001 ***
1-sided MW
equilibrium
superspreader
20 -.18 -.1 <.0001 ***
65%
peripheral
20 .57 .59 <.0001 ***
superspreader
20 -.27 -.2 <.0001 ***
Actual vs efficient
15%
1-sided MW
peripheral
20 .46 .42 <.0001 ***
Null Hypothesis: for each hypothesis, sample #1 and sample #2 appear consecutively in italics; Alt:
either 2-sided or 1-sided alternative, a 1-sided alternative is always s.t. median(sample #1) > median(sample #2); Test: Mann-Whitney U-test (MW) for unmatched samples and Wilcoxon Signed-Rank
test (WSR) for matched samples; n: the number of observations per sample, where one observation is
one group of 5 subjects; ∆X̄: difference in means between the two samples; ∆X̃: difference in medians
between the two samples; p-val: p-value for the test of the Null Hypothesis against the Alternative; Sig:
significance of the test where * – 10%, ** – 5%, *** – 1%.

28

statistically significant (WSR, p < 0.05 in all but one specification where p = 0.09) and sizable
in magnitude.
In Part 3 of Table A4 we repeat the analysis from Part 2, but now looking at the nudge
Intervention rather than the fine. The tests find a statistically significant effect of the nudge in
only 4 of the 6 specifications. Generally, we can see that the nudge has a smaller effect which
is not as robust as that of the fine. In particular, the effect of the nudge is very significant and
large in magnitude (7%) under high contagion, but disappears completely both statistically and
in terms of economic magnitude under low contagion. Also, the nudge seems to have no effect
on the superspreader. Note also that the effects of the nudge are not robust to using data from
all rounds of Baseline and Intervention (see Appendix A.4.2 for more details).
Result A-2. Introduction of the nudge generally increases the levels of social distancing. The
effect, however, is not robust to alternative specifications, and is smaller in magnitude than that
of the fine. In particular, the effect is statistically significant (WSR, p = 0.0003) and sizeable in
magnitude under high contagion, but not low contagion (WSR, p = 0.5). Further, a statistically
significant effect is observed for the close-knit (p = 0.05) and peripheral (WSR, p = 0.06)
participants but not for superspreaders.
Part 4 of Table A4 shows that the data from the Intervention in the second part of the experiment is not statistically different for the fine and nudge treatments. In particular, even though
the mean levels of distancing in Intervention in fine treatments is higher than those in nudge
treatments, our non-parametric testing fails to find any difference between them in 4 out of 6
specifications. We do, however, find evidence that the fine is more effective than the nudge (1)
when data is pulled across treatments, and (2) for the superspreader. The effect is substantial in
magnitude (7-10%) and significant at 10% level.
Result A-3. There is limited evidence that the fine is more effective than the nudge, and the
effect is not robust. In particular, the fine increases distancing levels by more than the nudge
(1) when all data is pulled together (MW, p = 0.08), and (2) separately for the superspreader
(MW, p = 0.06). The effect, however, is not statistically significant for other specifications.
In Part 5 of Table A4 we compare distancing levels in the three positions – close-knit,
superspreader and peripheral – in Baseline. From the table, we can see that (1) distancing levels
are higher in the superspreader position relative to both the close-knit and the peripheral, and (2)
higher in the close-knit relative to the peripheral. We run hypothesis tests both (a) aggregating
over the rate of contagion, and (b) separately by two levels of the rate of contagion. All results in
this part of the table are significant at the 5% level, with most also being significant at 1%. The
differences between mean distancing levels in different positions are also large in magnitude –
between 10% and 27% depending on the specification.
Part 6 of Table A4 repeats the analysis in Part 5, but now focusing on Intervention, rather
than Baseline. The conclusions here are the same as above, with all results being significant at
the 5% and most also at the 1% level.
Result A-4. Superspreaders practice more social distancing than close-knit participants, who,
in turn, practice more distancing than peripheral participants. The differences are both statistically significant (MW, p < 0.05) and large in magnitude in all specifications.

29

In Parts 7 and 8 of Table A4 we investigate the effects on the rate of contagion on distancing
behavior, separately for Baseline and Intervention. We find that there is generally significantly
more social distancing under 65% rate of contagion relative to 15%. The test is not statistically
significant only for the superspreader in Baseline. The effect is also large in magnitude – an
average of 8-22% depending on the specification. Note that the effect on superspreaders is
smallest, but is probably explained, at least in part, by ceiling effects. In particular, in all
treatments, the mean distancing levels in the last 10 rounds in the superspreader position are at
least 70%, so there is limited room for a further increase.
Result A-5. Subjects in the experiment generally practice more social distancing in high contagion environments relative to low contagion environments. The effect is statistically significant
for close-knit (MW, p = 0.9 in Baseline and p = 0.009 in Intervention) and peripheral (MW,
p = 0.03 and p = 0.002 in Baseline and Interventon respectively) subjects. For superspreaders,
the effect is relatively smaller, and less robust to specifications (MW, p = 0.16 in Baseline and
p = 0.05 in Intervention).
Finally, in Parts 9 and 10 of the table, we focus on testing Hypotheses 6 and 7. Specifically,
we compare the outcomes in the complete and the star networks to (1) predictions of the Nash
equilibrium, and (2) efficient outcomes. We find that the levels of social distancing are not in
line with theoretical predictions, with all tests being statistically significant at least at the 5%
level. In particular, distancing levels in the complete network are well above those predicted
by Nash equilibrium. The difference is particularly large in the low contagion environment,
where the equilibrium prediction is no social distancing, but the actual average level of social
distancing in the last 10 rounds of Baseline stands at 62%. Distancing levels are also higher than
those predicted by efficiency under low contagion. On the other hand, in the high contagion
environment, the actual distancing levels are below efficiency requirements.
Result A-6. Prior to intervention, the observed levels of social distancing in the complete differ
from equilibrium and efficiency predictions. In particular, more social distancing is observed
than predicted by Nash equilibrium. When it comes to efficiency, actual levels of distancing are
above efficient under low contagion, but below efficient under high contagion. All results are
statistically significant (MW, p ≤ 0.01).
In the star network, the amount of social distancing done by the peripheral participants is
well above both equilibrium predictions and efficiency requirements. On the other hand, the
levels of social distancing observed for the superspreaders is above the equilibrium but below
the efficient level for low contagion, and below both the equilibrium and efficient levels for high
contagion.
Result A-7. Prior to intervention, the observed levels of social distancing in the star network
differ from equilibrium and efficiency predictions. The result is true for both positions and both
rates of contagion. In low contagion, participants in both positions practice more distancing
than predicted by equilibrium analysis, while in high contagion superspreaders practice less
and peripheral participants practice more than predicted. When it comes to efficiency, peripheral agents practice more social distancing and superspreaders practice less social distancing
in both high and low contagion. All results are statistically significant (MW, p < 0.0001).
Perception and Behavior. As part of the Post-experimental Questionnaire, subjects are
asked whether they agree that fines and nudges are effective in promoting social distancing.
30

These two questions are both on a 5-point Likert scale, with higher values indicating greater
disagreement with the statements. Table A5 summarizes individual self-reported perceptions of
fines and nudges in our sample. The majority of subjects believe that nudges are effective in
promoting social distancing, while attitudes to fines appear to be polarized.
Table A5: Self-reported perception of fines and nudges, n = 400.
strongly agree

agree

11.75%
31%

35.5%
50.5%

fines are effective
nudges are effective

neither agree
disagree
nor disagree
21.25%
13.75%

20.25%
3.5%

strongly disagree
9.25%
1.25%

We construct a group-level index for the perception of fines, equal to one if at least three
subjects in a network believe that fines are effective, i.e. they (strongly) agree with the corresponding statement, and an identical index for the perception of nudges. We then construct
another index that captures changes in the observed behavior. This index is equal to one if the
average level of social distancing in the last 10 rounds of Intervention is higher than in the last
10 rounds of Baseline. We then compare the perception indices to the behavior index.
Figure A5: Perception of effectiveness of fines and nudges versus observed effectiveness.
1.0

Share of groups

0.8

Survey (fine treatment)
Survey (nudge treatment)
Experiment

0.95

0.70

0.6
0.4

0.98

0.65

0.55
0.42

0.2
0.0

Fine

Nudge

Figure A5 summarizes how group-level perception of fines and nudges compares to behavior. Two patterns emerge. First, subjects seem to underestimate the effectiveness of fines: only
42% of groups in the fine treatment (55% in the nudge treatment) believe in the effectiveness of
fines, whereas 70% of groups subjected to fines show an increase in average distancing levels.
Second, participants seem to overestimate the effectiveness of nudges – 95% of the groups in
the nudge treatment (98% in the fine treatment) believe that nudges are effective, while only
65% of the groups actually increase their average distancing levels when subjected to nudges.
To test this formally, we use non-parametric analysis with the three group-level indices. We
find that irrespective of treatment they were placed in, subjects’ perception of fines matches
their (fines’) measured effectiveness (WSR and MW, p = 0.99 and p > 0.92 respectively). On
the other hand, participants overestimate the effectiveness of nudges (WSR and MW, p = 0.001
p < 0.0001 respectively).
31

A.3.3

Individual level

We now turn to individual behavior, and examine the determinants of individual social distancing decisions. To do this, we use a Random Effects Logit model. This implicitly models the
following Random Utility framework for binary choice.
yit = 1 ⇐⇒ xit β + vi + it > 0

(2)

According to this model, subjects choose to practice social distancing if and only if they
receive greater utility from doing so than from not doing so. Note that (implicitly) we have
normalized the utility from not distancing to zero – this is without loss of generality. This is
a flexible and tractable way to model binary decisions. The model assumes that the subjectspecific random effect, vi , is normally distributed, and that it follows the logistic distribution.
In addition, we only use data from the final 10 rounds of each part of the experiment, because it takes time for subjects’ behavior to converge as shown in the convergence analysis in
Appendix A.4.1. Appendix A.4.3 shows that the results are not sensitive to either using the
Logit modeling framework, or restricting the data to the final 10 rounds of each part.
Having set out the econometric framework, we now need a set of control variables that
might plausibly explain social distancing decisions. Clearly it is neither possible nor desirable to
control for every conceivable covariate, but we have five categories of controls that collectively
cover a wide variety of factors. First, and most obviously, we control for the experimental
treatments: the fine, nudge, rate of contagion and network position (model 1 of table A6).
As we randomly assign subjects to these treatments, we can be confident that their effects are
causal.
Next, we add controls for social demographics (in model 2), geographic and institutional
factors (in model 3), social and risk preferences (in model 4), and finally, ideology (in model 5).
To complete our model, we also control for interactions between ideology and the policy interventions (fine/nudge). This is because we find that subjects’ responsiveness to the fine depends
on their ideology – more conservative subjects are less responsive to the fine.
Results. Ex ante, it seems plausible that each of the controls could be related to social distancing
decisions. However, as we can see in model 6, only some of them are.4 All experimental
treatments have a significant effect – both statistically and in terms of economic relevance –
and their direction is intuitive. Statistical tests are t-test on coefficients in the Random Effects
Logit regression (REL hereafter), or t-test on coefficients in the Instrumental Variables Random
Effect Logit (IV, hereafter).
First, the fine significantly increases social distancing (Hypothesis 1), and the nudge marginally
increases social distancing (Hypothesis 2). Qualitatively, the fine is more effective (the statistical significance of the nudge is also not robust), but in our preferred model, the difference
between the two effects is not statistically significant (Hypothesis 3). Note that the numbering
of the results corresponds exactly to the number of the hypotheses in Appendix A.1, and the “I”
prefix denotes individual-level results.
Result I-1. The fine increases the probability that an individual practices social distancing
(REL, p = 0.001).
4

The p-values in all results relate to model 6.

32

Result I-2. The nudge marginally increases the probability that an individual practices social
distancing (REL, p = 0.09). The effect is approximately half that of the fine, and is not robust
to changes in the regression specification.
Result I-3. The effect of the fine is larger than the effect of the nudge, but the difference is not
statistically significant (REL, p = 0.11).
Second, superspreaders distance more than ‘close-knit’ agents, even though they have the
same number of links in the network (Hypothesis 4). This suggests that when subjects know
they are highly connected, they take some action to compensate. Note that our experimental
design cannot identify why they do this – whether to protect themselves or to protect others.
Peripheral agents distance significantly less – being less exposed to community contagion in
the first place reduces the likelihood that agents take protective action. Further, subjects do
more social distancing in a high contagion environment than in a low contagion environment,
irrespective of their network position (Hypothesis 5).
Result I-4. Superspreaders practice social distancing with a greater probability than closeknits subjects (REL, p = 0.05), who in turn, practice social distancing with a greater probability
than peripheral subjects (REL, p < 0.0001).
Result I-5. Subjects practice social distancing with a greater probability in the high contagion
setting than in the low contagion setting (REL, p < 0.0001).
Beyond the experimental treatments we find significant effects for age, gender, race, social
and risk preferences, and ideology. Older, female and non-white subjects all practice more
social distancing. More risk-averse agents, and prosocial agents (as classified by the SVO task)
also practice more social distancing (Hypothesis 8 and Hypothesis 9).
Result I-8. More risk averse subjects practice social distancing with a higher probability (REL,
p = 0.001).
Result I-9. Subjects who indicate greater concern for others’ well-being practice social distancing with a higher probability (REL, p < 0.0001).
Perhaps the most interesting non-treatment effect is subjects’ political ideology. Subjects
with stronger Conservative ideology practice less social distancing, and are marginally less
responsive to fines. Recall that our ideology index is constructed from subjects’ responses to
three questions from the post-experiment questionnaire. They ask about subjects’ support for
President Donald Trump’s handling of the COVID-19 pandemic, their support for universal
healthcare, and their belief that social distancing measures impose unjustified economic costs.
Result I-10. More conservative subjects both practice distancing with a lower probability (iv,
p = 0.04) and are marginally less responsive to the fine (IV, p = 0.08).
It is important to bear in mind that subjects were not randomly allocated to their ideology
(as they were to the experimental treatments) – clearly that would not be feasible. As such,
the association we have found between ideology and social distancing decisions may not be
causal – it is possible that ideology is endogeneous. That is, it could be correlated with some
unobserved factor that affects social distancing decisions.
33

Table A6: Main logit regression results.
Variable

(1)

(2)

(3)

Treatment
Fine

0.755*** 0.752*** 0.752***
(0.231)
(0.234)
(0.234)
Nudge
0.347**
0.353**
0.353**
(0.157)
(0.154)
(0.154)
High contagion
1.330*** 1.477*** 1.404***
(0.336)
(0.334)
(0.318)
Superspreader
0.975**
1.234*** 1.184***
(0.438)
(0.450)
(0.423)
Peripheral
-1.608*** -1.364*** -1.416***
(0.322)
(0.332)
(0.319)
Demographic controls
Age (years)
0.0859*** 0.0858***
(0.0129)
(0.0135)
1.237*** 1.193***
Female
(0.352)
(0.367)
-1.310*** -1.553***
Race = white
(0.462)
(0.480)
0.106
0.0490
Education (years)
(0.0908)
(0.0916)
-0.517
-0.443
Religion = Christian
(0.409)
(0.410)
Religion = other
-0.166
-0.0445
(0.543)
(0.560)
0.0943
0.164
Out of labor force
(0.455)
(0.484)
Unemployed
0.752
0.611
(0.592)
(0.571)
Location-based controls
Population density
0.0320
(0.0334)
Cumulative cases
0.00572
(0.00475)
Daily deaths
-0.001131
(3.626)
Stay-at-home order
-0.355
(0.501)
Region controls
No
No
Yes

(4)

(5)

(6)
Main

(7)
IV

0.762***
(0.242)
0.344**
(0.155)
1.529***
(0.330)
0.927**
(0.427)
-1.684***
(0.334)

0.761***
(0.242)
0.343**
(0.155)
1.537***
(0.323)
0.830**
(0.421)
-1.780***
(0.333)

1.146***
(0.352)
0.438*
(0.261)
1.547***
(0.323)
0.833**
(0.424)
-1.785***
(0.333)

1.147***
(0.352)
0.437*
(0.261)
1.543***
(0.322)
0.846**
(0.429)
-1.771***
(0.340)

0.0813***
(0.0144)
0.909**
(0.374)
-1.149**
(0.463)
0.0104
(0.0958)
-0.287
(0.413)
0.278
(0.542)
-0.0715
(0.486)
0.273
(0.568)

0.0793***
(0.0137)
1.069***
(0.372)
-0.960**
(0.469)
0.00341
(0.0984)
0.0632
(0.436)
0.384
(0.525)
0.0233
(0.481)
0.301
(0.538)

0.0796***
(0.0139)
1.072***
(0.372)
-0.955**
(0.468)
0.00423
(0.0984)
0.0616
(0.437)
0.370
(0.525)
0.00933
(0.484)
0.301
(0.542)

0.0796***
(0.0139)
1.054***
(0.380)
-0.986**
(0.464)
0.00713
(0.0977)
0.00188
(0.439)
0.347
(0.523)
-0.00632
(0.488)
0.299
(0.543)

0.0409
(0.0300)
0.00570
(0.00442)
-0.004514
(3.576)
-0.343
(0.492)
Yes

0.0429
(0.0293)
0.00444
(0.00418)
-0.003625
(3.627)
-0.446
(0.452)
Yes

0.0435
(0.0294)
0.00450
(0.00418)
-0.00366
(3.632)
-0.451
(0.456)
Yes

0.0430
(0.0293)
0.00470
(0.00423)
-0.00382
(0.00371)
-0.433
(0.466)
Yes

Continued on next page

34

Continued from previous page
Variable

(1)

(2)

(3)

Preference controls
Bomb risk score

(4)

-0.0339***
(0.00934)
1.564***
(0.338)
1.512***
(0.332)

Prosocial values
Protect others
Quiz attempts
Ideology
Conservative
ideology
Fine–ideology
interaction
Nudge–ideology
interaction
Residual
Constant

Observations
No of subjects

(5)

(6)
Main

-0.0296*** -0.0296***
(0.00889)
(0.00896)
1.485***
1.495***
(0.334)
(0.335)
0.918***
0.926***
(0.342)
(0.346)
0.189
0.197
(0.170)
(0.171)
-0.282***
(0.0565)

-0.250***
(0.0591)
-0.110*
(0.0618)
-0.0266
(0.0447)

(7)
IV
-0.0300***
(0.00885)
1.503***
(0.334)
1.017**
(0.395)
0.197
(0.171)

1.456***
(0.312)

-3.547**
(1.611)

-2.753*
(1.627)

-2.927*
(1.579)

-2.051
(1.670)

-2.213
(1.666)

-0.207**
(0.0995)
-0.110*
(0.0618)
-0.0265
(0.0448)
-0.0663
(0.120)
-2.415
(1.700)

8,000
400

8,000
400

8,000
400

7,880
394

7,880
394

7,880
394

7,880
394

The variable “Quiz attempts” measure the number of attempts subjects required to pass the quiz prior to the main
experiment. It is a proxy for a subject’s sophistication.
Population density = 1000’s of people per square mile. Cumulative cases = 1000’s of confirmed cases in state.
Significance levels: * – 10%, ** – 5%, *** – 1%.
Therefore, we use an Instrumental Variables approach to deal with possible endogeneity.
We use a measure of subjects’ scepticism of global warming as the instrument. As a partisan
issue in the United States, this is strongly correlated with political ideology [47]. However,
as it is unrelated to COVID-19 and the types of decisions that we ask subjects to make in this
experiment, it should not have a separate effect on social distancing decisions.
Mathematically, this means that after we have controlled for ideology, then scepticism of
global warming is uncorrelated with the error term, , in the regression. This property is required
for the instrument to be valid, and so to give consistent estimates. Note that it is not possible to
test this – it is an assumption.5
Like the ideology index, our index of global warming scepticism is constructed from subjects’ responses to three questions from the post-experiment questionnaire. They ask whether
global warming is (1) happening, (2) caused mostly by human activity, and (3) affecting weather
5

See, for example, [48].

35

in the United States [42].
As we are using a Logit specification, it is not possible to do standard 2-Stage Least Squares.
Instead we use a Control Function method [49]. The Control Function method takes predicted
residuals from the first stage regression, and adds them into the Logit regression. This is in
contrast to 2-Stage Least Squares, which takes predicted values from the first stage, and uses
them instead of the (potentially) endogenous variable in the second stage.
Model 7 of table A6 reports the preferred regression specification with the Instrumental
Variables method. Using the instrument does not have a large impact on the point estimate for
the ideology variable. This suggests that there may in fact be a causal relationship between
ideology and social distancing decisions – conservatives practice less social distancing.
Partial Effects. Using our preferred Logit specification – model 6 of table A6 – we can
predict the probability that an agent chooses to practice social distancing. With estimated regression coefficients β̂ and a set of subject characteristics x, then;
0

eβ̂ x
P r(yit = 1|xit ) =
0
1 + eβ̂ x

(3)

However, calculating partial effects with a Logit model is far from straightforward. In a
non-linear model the partial effect of one variable depends on the full set of an individual’s
characteristics, and so is highly heterogeneous. For example, the estimated partial effect of age
depends on an agent’s gender, race, religion, degree of risk aversion – and all other variables in
the model. Note that this even includes variables which are not statistically significant.
Given this, we calculate a variant on Average Partial Effects (APE). This is more useful than
a Partial Effect at the Average; especially given our extensive use of binary variables – a Partial
Effect at the Average would give us the partial effect for a subject who is 47% female, 85%
white, and at a node position that simply does not exist (50% ‘close-knit’, 40% peripheral, and
10% superspreader).
To calculate our variant on an APE for a variable, for example gender, we predicted probability of social distancing for each of our 400 subjects, first assuming that they are all male,
and then second assuming that they are all female. This gives us an individual partial effect of
gender for each subject – taking an average across all subjects yields the variant on an APE.
We assume that subjects are not exposed to a policy intervention (fine/nudge) when calculating
APEs for all (other) variables.
When the variable is continuous, we first assume that all subjects are at the 25th percentile
of that variable (based on the actual distribution in the experiment), and second that they are at
the 75th percentile.
We use this variant – only looking at the 400 subjects in our experiment – due to data constraints. While data is readily available on the population-wide distributions of most of the
individual variables, they are only available as marginal distributions, not as joint distributions.
That is, one can easily find an age distribution, a gender distribution, and an education distribution for the US population; but they are only available separately. A joint distribution –
especially over all of the variables in our preferred specification is not available. Therefore, our
variant allows us to calculate partial effects for individuals who actually exist, and so makes our
APE meaningful.
Figure A6 shows a box plot Partial Effects for variables that are statistically significant. The
colored bars cover the 25th to 75th percentiles of estimated partial effects. The vertical line in
each bar shows the 50th percentile, and the black dot shows the mean (the APE).
36

Figure A6: Average partial effects. Note that all variables from model 6 of Table A6 are used
in calculations, but we only report APEs for statistically significant variables.

Fine
Nudge
Superspreader
Peripheral
High contagion
Age
Female
Race = white
Risk seeking
Prosocial values
Protecting others
Conservative ideology

A.4

40

30

20

10

0

10

20

average partial effect (%)

30

40

Further analysis

This section presents additional statistical analysis. Appendix A.4.1 presents convergence analysis for Baseline and Intervention. Appendix A.4.2 summarizes robustness checks performed at
the aggregate (group) level, and Appendix A.4.3 focuses on robustness checks at the individual
level.
A.4.1

Convergence

The analysis in Appendices A.3.2 and A.3.3 focuses on the last 10 rounds of Baseline and
Intervention. In this section, we validate this choice by showing that the majority of participants
exhibit clear convergence behavior after the first 10 rounds in both parts of the experiment.
We define individual convergence as follows:
Definition 1. A participant converges to a strategy s by round n if (i) she used this strategy
for the last k rounds (including n), and (ii) in all subsequent rounds [n + 1, 20] the number of
consecutive deviations from the chosen strategy does not exceed a.
We consider three types of convergence strategies as follows:
1. The subject always chooses the same action. We define this strategy for both the complete
and the star networks.
2. The participant always choose the same action when she is the superspreader, and the
complement action when she is peripheral. We define this strategy for the star network
only.
3. The subject always chooses the same action when she is the superspreader, and alternates
between the two actions when she is peripheral. We define this strategy for the star
network only.

37

Table A7: Individual convergence analysis.
Type of
intervention

Network
Baseline
all
complete
star
Intervention
all
complete
star
all
all
complete
star

>80% converged
by round ...

n

all
all
all

400
200
200

9
8
11

84.25
86
82.5

all
all
all
fine
nudge
fine
nudge
fine
nudge

400
200
200
200
200
100
100
100
100

7
6
9
7
8
6
6
7
9

87.5
89.5
85.5
90
85
92
87
88
83

(a) Baseline
% of converged subjects

...% converged
by round 11

(b) Intervention

90
80
70
60

4

6

8

10

12 14
round

16

18

20

4

6

8

10

12
round

Deviations Allowed:
a=1
a=2
a=3
14 16 18 20

Figure A7: Evolution of the share of converged participants throughout the xxperiment separately for Baseline and Intervention, a ∈ [1, 3]. Note: we exclude the first 3 rounds in both parts
since k = 4.
We set k = 4 and a = 2. This means that the earliest a participant can be considered to
converge to a particular strategy is by round 4, if she has not deviated from this strategy in the
last four rounds, and in all subsequent rounds she never performs more than two consecutive
deviations.
Table A7 summarizes convergence analysis using the above definition. From the table, we
can see that by round 11 at least 80% of our participants have converged to a certain strategy
in all parameterizations. In fact, the lowest and highest convergence rates are 82.5% and 92%
respectively, while the weighted mean convergence rate is 85.9% across the two parts of the experiment. Convergence is higher (a) in the complete network, and (b) with the fine intervention.
Note that we did not discretize by the rate of contagion, although the findings are robust to this.
However, with this discretization, the lowest observed convergence rate falls to 79% (Baseline
38

with the star network under 15% rate of contagion).
As a robustness check, we also consider a = 1 and a = 3, allowing for one and three
consecutive deviations respectively. Figure A7 plots the share of converged participants for
each round separately by parts for a ∈ [1, 3]. We can see that the share of converged subjects
does not change much when we allow for a more/less conservative definition. In particular,
with a = 1 the share of subjects who converge by round 11 in Baseline drops to 79.8% while in
Intervention it reaches 83.5%. With a = 3 the share of subjects who converge by round 11 in
Baseline and Intervention stands at 86.3% and 90% respectively.
The above analysis suggests that it is reasonable to claim that the absolute majority of subjects converge to a particular strategy by round 11 in both parts of the experiment.
A.4.2

Aggregate analysis

We test the robustness of findings in Appendix A.3.2 in two ways: (1) using data from all 20
rounds of both parts of the experiment, and (2) employing parametric rather than non-parametric
tests on the data from the last 10 rounds of both parts. Table A8 summarizes the results of these
robustness checks.
Table A8: Robustness checks at the aggregate level, all 20 rounds (Robustness #1) or last 10
rounds (Robustness #2) used.
Null Hypothesis

Rate of
contagion

Position

Alt

Robustness #1
Test
p-val
Sig

Robustness #2
Test p-val
Sig

Part 1. Baseline
MW
all
all
all
close-knit
MW
all
superspreader
MW
Fine vs nudge
2-sided
all
peripheral
MW
15%
all
MW
65%
all
MW
Part 2. Intervention vs Baseline. Hypothesis 1 (fine has an effect)
all
all
WSR
all
close-knit
WSR
Fine: Intervention
all
superspreader
WSR
1-sided
vs Baseline
all
peripheral
WSR
15%
all
WSR
65%
all
WSR
Part 3. Intervention vs Baseline. Hypothesis 2 (nudge has an effect)
all
all
WSR
all
close-knit
WSR
all
superspreader
Nudge: Intervention
WSR
1-sided
all
peripheral
WSR
vs Baseline
15%
all
WSR
65%
all
WSR

39

.73
.82
.90
.21
.98
.62
.003
.04
.08
.04
.09
.005
.40
.36
.05
.18
.20
.07

***
**
*
**
*
***

UT
UT
UT
UT
UT
UT

.38
.85
.78
.22
.79
.27

PT
PT
PT
PT
PT
PT

.001
.01
.05
.06
.07
.002

***
**
*
*
*
***

PT
.01
**
PT
.06
*
*
PT
.39
PT
.05
*
PT
.48
*
PT
.0002 ***
Continued on next page

Continued from previous page
Null Hypothesis

Rate of
contagion

Position

Alt

Robustness #1
Test
p-val
Sig

Robustness #2
Test p-val
Sig

Part 4. Intervention. Hypothesis 3 (fine is more effective than nudge)
all
all
MW
.06
*
UT
.05
*
all
close-knit
MW
.17
UT
.20
all
superspreader
MW
.06
*
UT
.05
**
Fine vs nudge
1-sided
all
peripheral
MW
.13
UT
.10
15%
all
MW
.17
UT
.12
65%
all
MW
.06
*
UT
.09
*
Part 5. Baseline. Hypothesis 4 (superspreader > close-knit > peripheral)
MW
.0009 *** UT
.01
**
all
–
Superspreader vs
15%
–
.03
** UT
.08
*
1-sided MW
close-knit
MW
.008
*** UT
.03
**
65%
–
all
–
MW <.0001 *** UT <.0001 ***
Close-knit vs
1-sided MW
.002
*** UT
.003
***
15%
–
peripheral
MW
.0005 *** UT
.001
***
65%
–
all
–
WSR <.0001 *** PT <.0001 ***
Superspreader vs
15%
–
1-sided WSR .0002 *** PT
.0002 ***
peripheral
65%
–
WSR .0001 *** PT <.0001 ***
Part 6. Intervention. Hypothesis 4 (superspreader > close-knit > peripheral)
MW
.003
*** UT
.007
***
all
–
Superspreader vs
15%
–
.009
*** UT
.02
**
1-sided MW
close-knit
65%
–
MW
.07
*
UT
.07
*
MW
.0004 *** UT
.0002 ***
all
–
Close-knit vs
.004
*** UT
.0003 ***
15%
–
1-sided MW
peripheral
65%
–
MW
.01
** UT
.02
**
WSR <.0001 *** PT <.0001 ***
all
–
Superspreader vs
15%
–
1-sided WSR <.0001 *** PT <.0001 ***
peripheral
WSR
.001
*** PT
.0003 ***
65%
–
Part 7. Baseline. Hypothesis 5 (more distancing in high contagion compared to low contagion)
MW
.015
** UT
.005
***
all
all
65% vs 15% rate of
all
close-knit
MW
.08
*
UT
.05
**
1-sided
contagion
all
superspreader
MW
.18
UT
.10
*
all
peripheral
MW
.04
** UT
.02
**
Part 8. Intervention. Hypothesis 5 (more distancing in high contagion compared to low contagion)
all
all
MW
.0005 *** UT <.0001 ***
65% vs 15% rate of
all
close-knit
MW
.008
*** UT
.007
***
1-sided
contagion
all
superspreader
MW
.23
UT
.09
*
all
peripheral
MW
.005
*** UT
.0004 ***
Continued on next page

40

Continued from previous page
Null Hypothesis

Rate of
contagion

Position

Alt

Robustness #1
Test
p-val
Sig

Robustness #2
Test p-val
Sig

Part 9. Baseline. Hypothesis 6 (actual versus equilibrium/efficient outcomes in complete network)
Actual vs
15%
all
MW <.0001 *** UT <.0001
1-sided
equilibrium
65%
all
MW <.0001 *** UT
.002
15%
all
MW <.0001 *** UT <.0001
Actual vs efficient
1-sided
65%
all
MW
.04
** UT
.01
Part 10. Baseline. Hypothesis 7 (actual versus equilibrium/efficient outcomes in star network)
superspreader
MW <.0001 *** UT <.0001
15%
Actual vs
MW <.0001 *** UT <.0001
peripheral
1-sided
MW <.0001 *** UT <.0001
equilibrium
superspreader
65%
peripheral
MW <.0001 *** UT <.0001
superspreader
MW <.0001 *** UT <.0001
Actual vs efficient
15%
1-sided
MW <.0001 *** UT <.0001
peripheral

***
***
***
**
***
***
***
***
***
***

Null Hypothesis: for each hypothesis, sample #1 and sample #2 appear consecutively in italics; Alt: either
2-sided or 1-sided alternative, a 1-sided alternative is always s.t. median(sample #1) > median(sample #2) or
mean(sample #1) > mean(sample #2) as appropriate; Test: non-parametric: Mann-Whitney U-test (MW) for
unmatched samples and Wilcoxon Signed-Rank test (WSR) for matched samples; analogously for parametric:
unpaired t-test (UT) and paired t-test (PT); p-val: p-value for the test of the Null Hypothesis against the
Alternative; Sig: significance of the test where * – 10%, ** – 5%, *** – 1%.
In the columns under ‘Robustness #1’ we present the results of our hypothesis tests when
using decision data from all rounds. From the tables, we can see that most of the results from
Appendix A.3.2 are robust to using data from all 20 rather than last 10 rounds of both part of
the experiment. Further, recall that we observed previously that the nudge effects appear to be
small and sensitive to specification. Part 3 of Table A8 provides further evidence strengthening
this observation – we see that the effects of the nudge on distancing levels is now insignificant
in most of the specifications.
In our second robustness check, we use the standard unpaired t-test (UT) on unmatched
samples instead on the MW test, and the paired version of the t-test (PT) on matched samples
in place of the WSR test. In the columns under ‘Robustness #2’ of Table A8, we repeat the
analysis from Appendix A.3.2 using these parametric tests. Comparing the tables, we can see
that all significant effects are still present if we use parametric rather than non-parametric tests.
Overall, the findings of this section suggest that the observations made in Appendix A.3.2
are robust to changes in the distributional assumptions of the tests, and inclusion of all observations.
A.4.3

Individual analysis

We now test the robustness of the parametric analysis in Section A.3.3. Model 1 of Table A9
restates our preferred specification to aid comparison. Models 2 and 3 vary the type of model:
they use a Linear Probability Model (LPM) and a Probit model, respectively. Both include
random effects, to allow for individual heterogeneity. Changing the type of model used does
not materially affect the results. Note that the coefficients are not directly comparable across
41

Logit, LPM, and Probit. Figure A8 shows the average partial effects under each type of model
– as we can see, the differences are small. Model 4 shows that our results are not sensitive to
excluding the period before subjects converge – they are little affected by including all rounds.
Figure A8: Average Partial Effects under different models

Fine
Nudge
Superspreader
Peripheral
High contagion
Age
Female
Race = white
Risk seeking
Prosocial values
Protecting others
Conservative ideology

Logit
Probit
LPM

20

10
0
10
20
average partial effect (%)

The results could also be driven by subjects who either might not be paying attention, or
who might have a poor understanding of the game. To test for this, we exclude any subjects
who chose to practice social distancing in all 40 rounds (there are 122 subjects who do this)
in model 5. Then in model 6, we exclude subjects failing the quiz between the two parts of
the experiment more than once, or who failed the post-experiment attention check.6 Finally,
Model 7 tests an alternative specification of the instrument – only using subjects’ responses to
the question of whether global warming is caused by humans.7
While clearly not definitive, these suggest that our findings are robust, and in particular are
not driven by the choices we made on the econometric model and which, if any, observations to
exclude.
In our main analysis, we used a ideology index, constructed from subjects’ responses to
questions immediately asked after the experiment. Table A10 shows that these results hold
even if we use political party affiliation – a much coarser, but much more widely available,
measure of ideology. Apart from the ideology control, all variables are the same as in the main
model, so we suppress them in the table for convenience. Model 1 shows the main Random
Effects Logit model for reference. Model 2 uses a dummies for self-identified Republicans,
and for ‘Other’ (leaving self-identified Democrats as the base category). Model 3 omits the
‘Other’ category – leaving a direct comparison of Republicans and democrats. Model 4 uses
6

A question in the post-experiment survey asked subjects to select a particular option to demonstrate that they
were paying attention.
7
Using the final question on its own also gives similar results in terms of magnitude and statistical significance.
The question regarding whether global warming is happening gives non-significant estimates – likely driven by the
fact that there is very little variation in the responses to this question. 353 (out of 394) subjects respond that global
warming is happening.

42

Table A9: Robustness tests of main specification.
Variable

(1)
Main

(2)
LPM

Fine

1.146*** 0.0953***
(0.352)
(0.0279)
Nudge
0.438*
0.0358*
(0.261)
(0.0204)
High contagion 1.547*** 0.151***
(0.323)
(0.0303)
0.833**
0.0777**
Superspeader
(0.424)
(0.0329)
Peripheral
-1.785*** -0.174***
(0.333)
(0.0328)
a
Yes
Yes
Controls

(3)
Probit

(4)
(5) Not Always
(6)
All Rounds
Distancing
≤ 1 Quiz Fails

0.640***
(0.196)
0.226
(0.142)
0.855***
(0.187)
0.416*
(0.235)
-0.999***
(0.190)
Yes

0.969***
(0.297)
0.0771
(0.215)
1.236***
(0.286)
0.614*
(0.347)
-1.619***
(0.296)
Yes

1.152***
(0.350)
0.429*
(0.256)
1.374***
(0.284)
1.521***
(0.390)
-0.999***
(0.314)
Yes

1.341***
(0.409)
0.776**
(0.320)
1.718***
(0.340)
0.985**
(0.475)
-1.623***
(0.367)
Yes

1.148***
(0.352)
0.436*
(0.261)
1.542***
(0.323)
0.851**
(0.429)
-1.767***
(0.338)
Yes

Residuals
Constant

Observations
No of subjects

(7)
IV

-2.213
(1.666)

0.284*
(0.151)

-1.192
(0.960)

-1.380
(1.483)

-3.481**
(1.370)

-3.439*
(1.880)

-0.0809
(0.120)
-2.487
(1.722)

7,880
394

7,880
394

7,880
394

15,760
394

5,440
272

6,340
317

7,880
394

a

– all other controls from the main model.
Significance levels: * – 10%, ** – 5%, *** – 1%.
the Instrumental Variables method. Note that we only have one instrument, so it is not possible
to instrument for both Republicans and Independents in the same regression.
Our preferred specification only contains a single type of heterogeneous treatment effect –
the effect of the fine varies with subjects’ ideology. There also appear to be some other interaction effects present. Table A11 summarizes heterogeneous treatment effects. Older subjects
are relatively less responsive to the fine (REL, p < 0.0001); although the fine does still increase
their probability of social distancing (REL, p < 0.0001). Prosocial subjects are also marginally
less responsive to the fine (REL, p = 0.07). Subjects in a high contagion setting, and older subjects are relatively more responsive to the nudge (REL, p = 0.006 and p = 0.02 respectively).
This suggests that the impact of policy interventions may vary across groups, and perhaps more
importantly may vary with how contagious the disease is.

43

Table A10: Robustness tests of main specification.
Variable
Ideology

(1)
Main

-0.859
(0.613)
-0.936**
(0.467)

Republican

Observations
No of subjects

(4)
IV

-0.250***
(0.0591)

Independent

Fine–ideology
interaction
Nudge–ideology
interaction
Fine–Republican
interaction
Nudge-Republican
interaction
Fine–Independent
interaction
Nudge–Independent
interaction
Controlsa

(2)
(3) Omit
Political Party Independents

-1.601**
(0.684)

-1.976**
(0.921)

0.329
(0.554)
-0.231
(0.336)

-0.231
(0.336)
0.328
(0.555)

Yes

0.348
(0.556)
-0.249
(0.336)
0.704
(0.541)
-0.0360
(0.368)
Yes

Yes

Yes

7,880
394

7,880
394

7,880
394

7,880
394

-0.110*
(0.0618)
-0.0266
(0.0447)

a

– all other controls from the main model.
Significance levels: * – 10%, ** – 5%, *** – 1%.

44

Table A11: Checks for heterogeneous treatment effect.
Variable

High
Contagion

Peripheral

Superspreader

Age

Prosocial

Risk

0.754***
(0.252)
0.389**
(0.159)
1.538***
(0.323)
0.942**
(0.436)
-1.785***
(0.334)
0.0793***
(0.0137)
-0.0297***
(0.00889)
1.488***
(0.333)
-0.281***
(0.0566)
Yes

3.023***
(0.515)
-0.928
(0.582)
1.561***
(0.326)
0.845**
(0.425)
-1.819***
(0.338)
0.0867***
(0.0142)
-0.0297***
(0.00894)
1.478***
(0.337)
-0.278***
(0.0567)
Yes

1.201***
(0.333)
0.409**
(0.208)
1.558***
(0.327)
0.815*
(0.423)
-1.796***
(0.335)
0.0793***
(0.0138)
-0.0301***
(0.00890)
1.685***
(0.366)
-0.282***
(0.0565)
Yes

1.458**
(0.590)
0.468
(0.405)
1.538***
(0.323)
0.827**
(0.422)
-1.789***
(0.333)
0.0794***
(0.0138)
-0.0247***
(0.00853)
1.483***
(0.334)
-0.282***
(0.0563)
Yes

Fine

0.475
0.814***
(0.336)
(0.273)
Nudge
-0.0445
0.305
(0.225)
(0.206)
1.216***
1.535***
High contagion
(0.339)
(0.324)
0.837**
0.835**
Superspeader
(0.424)
(0.418)
Peripheral
-1.787*** -1.776***
(0.334)
(0.354)
0.0796*** 0.0793***
Age (years)
(0.0138)
(0.0137)
-0.0298*** -0.0297***
Bomb risk score
(0.00893)
(0.00891)
Prosocial values
1.493***
1.482***
(0.337)
(0.336)
Conservative ideology -0.283*** -0.282***
(0.0568)
(0.0565)
a
Yes
Yes
Controls

Interaction with
fine treatment
Interaction with
nudge treatment

Constant

Observations
No of subjects

0.611

-0.115

0.177

-0.0505***

-0.722*

-0.0181

(0.482)

(0.458)

(0.595)

(0.0112)

(0.403)

(0.0115)

0.788***

0.0870

-0.496

0.0309**

-0.148

-0.00374

(0.288)

(0.292)

(0.381)

(0.0130)

(0.313)

(0.0112)

-1.877
(1.665)

-2.054
(1.665)

-2.069
(1.670)

-2.537
(1.722)

-2.152
(1.673)

-2.172
(1.685)

7,880
394

7,880
394

7,880
394

7,880
394

7,880
394

7,880
394

a

– all other controls from the main model.
Significance levels: * – 10%, ** – 5%, *** – 1%.
Specification is same as main model except for the interaction term. Instead of interacting policy interventions
with ideology, they are interacted with the variable in the column heading.

45

References
[36] F. Holzmeister and A. Pfurtscheller, “oTree: the “bomb” risk elicitation task,” Journal of
Behavioral and Experimental Finance, vol. 10, pp. 105–108, 2016.
[37] G. Charness, U. Gneezy, and B. Halladay, “Experimental methods: Pay one or pay all,”
Journal of Economic Behavior and Organization, vol. 131, pp. 141 – 150, 2016.
[38] D. L. Chen, M. Schonger, and C. Wickens, “oTree – an open-source platform for laboratory, online, and field experiments,” Journal of Behavioral and Experimental Finance,
vol. 9, pp. 88–97, 2016.
[39] E. U. Weber, A.-R. Blais, and N. E. Betz, “A domain-specific risk-attitude scale: measuring risk perceptions and risk behaviors,” Journal of Behavioral Decision Making, vol. 15,
no. 4, pp. 263–290, 2002.
[40] U.S. Census Bureau, “Single Year of Age and Sex Population Estimates: April
1, 2010 to July 1, 2019 - CIVILIAN (SC-EST2019-AGESEX-CIV),” 2019. Retrieved from URL=https://www.census.gov/data/tables/time-series/demo/popest/2010sstate-detail.html.
[41] R. Likert, “A technique for the measurement of attitudes.,” Archives of Psychology,
vol. 140, no. 22, pp. 5–55, 1932.
[42] P. D. Howe, M. Mildenberger, J. R. Marlon, and A. Leiserowitz, “Geographic variation in
opinions on climate change at state and local scales in the usa,” Nature Climate Change,
vol. 5, no. 6, p. 596–603, 2015.
[43] U.S.
Census
Bureau,
“Land
Area,”
2011.
Retrieved
URL=https://www.census.gov/library/publications/2011/compendia/usa-counties2011.html.

from

[44] U.S. Census Bureau, “County Population by Characteristics: 2010-2019,” 2019. Retrieved from URL=https://www.census.gov/data/datasets/time-series/demo/popest/2010scounties-detail.html.
[45] H. B. Mann and D. R. Whitney, “On a test of whether one of two random variables is
stochastically larger than the other,” The annals of Mathematical Statistics, vol. 18, no. 1,
pp. 50–60, 1947.
[46] F. Wilcoxon, “Individual comparisons by ranking methods,” Biometrics, vol. 1, no. 6,
pp. 80–83, 1945.
[47] A. M. McCright and R. E. Dunlap, “The politicization of climate change and polarization
in the american public’s views of global warming, 2001–2010,” The Sociological Quarterly, vol. 52, no. 2, pp. 155–194, 2011.
[48] J. M. Wooldridge, Econometric analysis of cross section and panel data. MIT press, 2010.
[49] K. E. Train, Discrete choice methods with simulation. Cambridge university press, 2009.
46

B

Experimental Instructions

Appendix B.1 presents instructions and the interface for the experiment. Analogously, Appendices B.2 and B.3 present instructions and the interface for the social preferences (SVO) and
risk preferences (BRET) elicitation tasks respectively.

B.1

Main Experiment

This section contains instructions for the Baseline and Intervention parts of the experiment. For
the Baseline (Part 1), the rate of contagion is set at 65%. Note that the type of network and
intervention do not feature in this part of instructions. For the Intervention (Part 2), we show
instructions for the fine. Instructions for the nudge are similar, except that instead of explaining
how the fine is implemented, participants are asked to watch a 3-minute video. The video can
be accessed online at https://youtu.be/tyf6EpSMeGs. The section concludes with
Figure B1, which shows the decision and results interfaces from the main experiment.
Part 1: Instructions (page 1/6)
Welcome to this interactive experiment!
This experiment consists of two parts. You will be paid a fixed reward of $1 for completing
all parts of the experiment. Additionally, you can earn points for your choices in Parts 1 and 2,
which will be converted into $ at the end of this experiment. There may also be a Bonus Task
at the end of the experiment.
In Parts 1 and 2 of the experiment, you will interact with a group of other real people recruited through MTurk. Recall that you will never learn the identities of other people and no
one will learn about your identity.
The expected duration of the experiment is 30-40 minutes and your average expected total
earnings will be $3-6 excluding the Bonus Task. Note that you can earn less or more than this
amount depending on your choices and the choices of others in your group.
At the beginning of Part 1 of the experiment, you will be randomly allocated to a group of 5
and you will remain in this group for the duration of Parts 1 and 2 of the experiment. Note that
you might have to wait while we are matching you with 4 other people, but we will compensate
you for the time you wait.
Since this experiment is interactive, it is important that you remain continuously attentive,
otherwise you may slow down others and may even be disqualified from the experiment.
In Part 1 of the experiment, you will be asked to play a game with the other members of your
group. The instructions on the next 5 pages explain the rules of the game. You will receive
more information about Part 2 after you complete Part 1.
All participants are given the same instructions. It is important that you read these instructions
carefully. Note that there is no deception in this experiment.
Once you read the instructions, you will be required to pass a short understanding Quiz. If you
fail the Quiz, you will not be allowed to take part in the experiment and will not receive
the fixed reward.
47

To continue to the instructions, press the Next button below.
Part 1: Instructions (page 2/6)
In Part 1 of the experiment you are asked to play a game with the other members of your group.
In what follows, you and the other members of your group are referred to as participants.
At the start of the game, you are presented with a diagram with 5 circles labeled by capital
letters (P, E, C, M, Q) and lines between them.
Each circle represents a position – one for each participant. At the start of the game, each
participant is randomly allocated to one of these positions in the diagram. Your position is the
one colored in blue.
The lines between positions indicate the structure of interactions between participants in these
positions. These lines indicate which participants interact with one another in the game.
An example is the diagram below. Here, you are in position M and directly interact with participants in positions P and E, but you do not interact directly with C and Q.

The next page of the instructions explains the choice you need to make in the game.
To continue to the next page, press the Next button below. To go to the previous page, press the
Back button.
Part 1: Instructions (page 3/6)
In the game, you and the other participants face a risk of getting infected with COVID-19
(commonly known as coronavirus).
The main symptoms of COVID-19 are shortness of breath, a high fever and a new, continuous cough. Most patients experience mild symptoms and recover in 1-2 weeks, but cases can
progress to pneumonia and organ failure in the most vulnerable individuals.
After you learn your position in the diagram, your need to choose whether to practice social
distancing. Below you can see what the buttons to make your choice look like.

You have 20 seconds to make your choice and the timer is displayed at the top of the interface
throughout the experiment. If you do not make a choice within the allowed time, your choice is
automatically recorded as a ‘No’.
After everyone in your group has made their social distancing choice, the computer randomly
chooses one and only one participant to contract COVID-19 directly. If a participant does
48

not practice social distancing and is randomly picked by the computer then s/he gets infected
for sure. In other words, if you do not practice social distancing there is a 20% chance you
get infected with COVID-19 directly.
Social distancing gives you some level of protection against COVID-19. If you practice social
distancing and you are the participant randomly chosen by the computer to be infected then the
computer flips a fair coin. If the coin flip is Head you are infected with COVID-19. If the coin
flip is Tail then you are not infected with COVID-19. In other words, if you practice social
distancing there is a 10% chance you get infected with COVID-19 directly.
A participant who practices social distancing cannot pass COVID-19 to other participants and
cannot be infected with COVID-19 by another participant.
On the other hand, an infected participant who does not practice social distancing may infect
other participants through contagion. In particular, other participants who do not practice social
distancing face a risk of getting infected because COVID-19 may spread through interactions
between the participants.
The next page of the instructions explains how COVID-19 spreads through interactions between
participants.
To continue to the next page, press the Next button below. To go to the previous page, press the
Back button.
Part 1: Instructions (page 4/6)
A healthy participant who does not practice social distancing may get infected with COVID-19
through contagion by interacting with infected participants who do not practice social distancing. The probability a participant contracts COVID-19 through interaction with another
participant is referred to as the rate of contagiousness of COVID-19.
Throughout Part 1 of the experiment the rate of contagiousness of COVID-19 is fixed at
65%.
Consider again the example diagram of interactions and, as an example, suppose that:

• You (participant M) do not practice social distancing.
• Participants in position E and Q practice social distancing, while participants in positions
P and C do not.
In this example, suppose C is randomly picked by the computer to contract COVID-19 directly.
First, C has chosen not to practice social distancing so s/he gets infected for sure. Moreover, C
can pass COVID-19 to other participants because s/he does not practice social distancing.
49

Second, E and Q cannot get infected with COVID-19 through contagion because they practice
social distancing.
Next, P may get infected through contagion because s/he does not practice social distancing and
interacts with C. This can happen with probability 65% – the rate of contagiousness.
Finally, you may also become infected by contagion through your interaction with P. Specifically, there is a 65% probability you might get infected through your interaction with P if s/he
becomes infected. However, if P remains healthy you will also remain healthy for the duration
of the game.
It follows that in this example if 1) you do not practice social distancing, 2) E and Q practice
social distancing whereas P and C do not, and 3) C contracts COVID-19 directly, then you may
become infected with probability 42.25%. The diagram below shows how this percentage is
computed.

Note that you will not be informed of the choices of other participants at any point during the
experiment.
The next page of the instructions explains how you earn points in Part 1 of the experiment.
To continue to the next page, press the Next button below. To go to the previous page, press the
Back button.
Part 1: Instructions (page 5/6)
At the end of the game you earn the following points depending on your social distancing choice
and infection status:
• 100 points: if you did not practice social distancing and did not get infected;
• 65 points: if you practiced social distancing and did not get infected (100 points for being
healthy minus 35 points cost of social distancing);
• 0 points: if you did not practice social distancing and got infected;
• -35 points: if you practiced social distancing and got infected (0 points for being infected
minus 35 points cost of social distancing).
Note that if you fail to submit your social distancing choice then you will receive a penalty of
200 points.
The information about the points you can earn, the rate of contagiousness of COVID-19, the
structure of interactions between participants and your position are always displayed on the
screen when you make your social distancing choice.
50

Below you can see an example of how this part of the interface looks like. The diagram of
interactions is on the right, while the textual information on the left reminds you of the rate of
contagiousness and the possible outcomes.

At the end of the game, you are reminded of the structure of interactions between participants,
your position within that structure, and your social distancing choice. You are also informed of
your infection status and the number of points earned.
Below you can see an example of how this part of the interface looks like.

You have 15 seconds to review this information and the timer is always displayed at the top of
the interface.
The next page of the instructions explains how points are converted into your earnings in $.
To continue to the next page, press the Next button below. To go to the previous page, press the
Back button.
Part 1: Instructions (page 6/6)
Part 1 of the experiment has 20 separate games as described in these instructions. The choice
you make in one game has no effect on other games.
The only variation between games is the random reassignment of the positions of all the participants (including you) in the diagram of interactions. The participants assigned to your group,
the structure of interactions between positions, the probability of contracting COVID-19 directly, the rate of contagiousness of COVID-19 and the number of points earned depending on
social distancing choice and infection status remain unchanged.
At the end of each game, you can review the history of your choices and outcomes for the last
5 games. The table below shows an example of how your history after 9 games might look like.

51

It is important that you make a choice in every game. If you fail to make a choice for 3 consecutive games, you will be disqualified from the experiment. In this case, you will not receive
any payment for this experiment.
At the end of this experiment, the computer randomly picks 4 out of 20 games to determine
your earnings for Part 1 of the experiment.
The points are converted to $ at a rate of 115 points per $1.
Suppose that you earn 260 points in the 4 randomly drawn games. Then, your total earnings for
Part 1 are $2.26.
To continue to the short Quiz, press the Next button below. To go to the previous page of the
instructions, press the Back button.
Part 2: Instructions
You have completed Part 1 of the experiment and will now proceed to Part 2.
Below are the instructions for Part 2 of the experiment. It is important that you read these
instructions carefully.
This part of the experiment also has 20 games, and you are assigned to the same group of
5 people as in Part 1. The structure of interactions between participants, the probability of
contracting COVID-19 directly and the rate of contagiousness of COVID-19 are the same as in
Part 1.
The single difference from Part 1 is that in Part 2 of the experiment you will receive a fine
of 15 points in any game in which you do not practice social distancing.
Hence, in Part 2 of the experiment the points you earn at the end of the game are:
• 85 points: if you did not practice social distancing and did not get infected (100 points
for being healthy minus 15 points fine);
• 65 points: if you practised social distancing and did not get infected (100 points for being
healthy minus 35 points cost of social distancing);
• -15 points: if you did not practice social distancing and got infected (0 points for being
infected minus 15 points fine);
52

• -35 points: if you practised social distancing and got infected (0 points for being infected
minus 35 points cost of social distancing).
Note that if you fail to submit your social distancing choice then you will receive a penalty of
200 points.
Your earnings for Part 2 are computed in the same way as in Part 1. At the end of this experiment, the computer randomly picks 4 out of 20 games to determine your earnings for Part 2 of
the experiment.
As in Part 1, the points are converted to $ at a rate of 115 points per $1.
Suppose that you earn 300 points in the 4 randomly drawn games. Then, your total earnings for
Part 2 are $2.61.
Before you can start Part 2 of the experiment, you must answer a Quiz question on the instructions above. If you fail to answer the question correctly, you will not be able to continue
to Part 2 of the experiment.
To continue to the short Quiz, press the Next button below.
The experiment: Interface
Figure B1 shows the decision and results interface from the main experiment. We focus on
game 5 of the Intervention part of the experiment, where the rate of contagion is set at 65%,
the network is the star, and fine is the intervention. In this game, our example participant is
assigned to position P. She decides to practice social distancing, and does not get infected.

B.2

Social Value Orientation (SVO) Slider Measure

This section contains instructions from and interface of the Social value Orientation (SVO) task
which participants complete as part of the recruitment survey.
SVO: Instructions
You have answered the qualifying questions correctly and are now in the Bonus Task.
In this Bonus Task you will be making a series of decisions about allocating money between
you and another anonymous Turker (hereafter, Other). All of your decisions will be completely
confidential.
There is a total of 6 decisions to make which are independent of each other. For each decision,
you are asked to pick the distribution of money between yourself and Other that you prefer, all
values are stated in cents. After you have made your decision, select the resulting distribution of
money by clicking on the button below your choice. As you will see, your choices will influence
both the amount of money you receive as well as the amount of money the Other receives.
There are no right or wrong answers, this is all about personal preferences.
Every time 50 Turkers complete the task, we will randomly pick two of them and pay them for
the Bonus Task as follows. We will pick one of the 6 decisions, and randomly implement the
decision of one of the two chosen Turkers.
53

For example, suppose we randomly chose Turkers X and Y out of those 50 Turkers, and that we
further randomly chose to implement decision 3 of Turker Y. Suppose that in decision 3 Turker
Y allocated 150 cents to themselves, and 140 cents to Other. Therefore, Turkers X and Y will
be paid 140 and 150 cents respectively.
SVO: Interface
Figure B2 presents part of the interface of the SVO task. We focus on one of the six decisions.
In this example, a participant decided to allocate 288 cents to self and 188 cents to other.

B.3

Bomb Risk Elicitation Task (BRET)

This section contains instructions from and interface of the Bomb Risk Elicitation Task (BRET)
which participants complete after the main experiment.
BRET: Instructions
Thank you very much for taking part in the experiment!
You are now in the Bonus Task in which you have an opportunity to earn an extra payment.
On the next page, you will see 100 boxes. As soon as you start the task by pressing the ‘Start’
button, one box is collected per second starting from the top left corner. Once collected, the box
is marked by a tick symbol.
For each box collected, you earn 2 cents.
One of the 100 boxes contains a bomb that destroys all of your earnings. You do not know
where the bomb is located. You only know that the bomb can be in any box with equal
probability.
Your task is to choose when to stop collecting the boxes and open those you have collected. You
stop collecting boxes by pressing ‘Stop’ at any time. After that you open the boxes you have
collected by pressing the ‘Open’ button. Note that once you press ‘Stop’ you cannot restart
collecting boxes.
A dollar or a bomb symbol will be shown on each of the boxes you have collected.
If the bomb symbol does not appear, that means that you have not collected the box with the
bomb. In this case, you earn the amount accumulated by the boxes you have collected.
If the bomb symbol appears, that means that you have collected the box with the bomb. In
this case, you earn zero for the Bonus Task.
To proceed to the Bonus Task, press the button below.
BRET: Interface
Figure B3 presents the interface of the BRET. Figure B3a shows an example of the interface
after a participant has stopped collecting boxes. We can see that she opened 56 boxes. Figure B3b shows the interface after she opened the boxes. We can see that the bomb is among the
56 collected boxes. Consequently, in this example the participant earns zero for the BRET.

54

(a) Decision interface

(b) Results interface

Figure B1: Game 5 of the Intervention: interface
55

Figure B2: Social Value Orientation (SVO) Slider Measure: Decision interface

(a) Decision interface

(b) Results interface

Figure B3: Bomb Risk Elicitation Task (BRET) interface

56

