PREPRINT 1–15, 2020

Preprint-version

Pay Attention to the cough:
Early Diagnosis of COVID-19 using Interpretable Symptoms
Embeddings with Cough Sound Signal Processing
Ankit Pal

ANKIT. PAL @ SAAMA . COM

Saama AI Research, Chennai, India

arXiv:2010.02417v2 [cs.LG] 12 Oct 2020

Malaikannan Sankarasubbu

MALAIKANNAN . SANKARASUBBU @ SAAMA . COM

Saama AI Research, Chennai, India

Abstract
COVID-19 (coronavirus disease 2019)
pandemic caused by SARS-CoV-2 has led
to a treacherous and devastating catastrophe for humanity. At the time of writing, no specific antivirus drugs or vaccines are recommended to control infection transmission and spread. The current diagnosis of COVID-19 is done by
Reverse-Transcription Polymer Chain Reaction (RT-PCR) testing. However, this
method is expensive, time-consuming, and
not easily available in straitened regions.
An interpretable and COVID-19 diagnosis AI framework is devised and developed
based on the cough sounds features and
symptoms metadata to overcome these limitations. The proposed framework’s performance was evaluated using a medical
dataset containing Symptoms and Demographic data of 30000 audio segments, 328
cough sounds from 150 patients with four
cough classes ( COVID-19, Asthma, Bronchitis, and Healthy). Experiments’ results
show that the model captures the better and
robust feature embedding to distinguish between COVID-19 patient coughs and several types of non-COVID-19 coughs with
higher specificity and accuracy of 95.04 ±
0.18 % and 96.83± 0.18 % respectively, all
the while maintaining interpretability.
Keywords: COVID-19, Audio Analysis,
Deep Learning, Medical Data, Machine
Learning
© 2020 A. Pal & M. Sankarasubbu.

1. Introduction
The novel coronavirus (COVID-19) disease has
affected over 31.2 million lives, claiming more
than 1.02 million fatalities globally, representing an epoch-making global crisis in health
care. At the time of writing, no specific
antivirus drugs or vaccines are recommended
to control transmission and spread infection.
The current diagnosis of COVID-19 is made
by Reverse-Transcription Polymer Chain Reaction (RT-PCR) testing, which utilizes several
primer-probe sets depending on the assay utilized (Emery et al., 2004). However, this method
is time-consuming, expensive, and not easily
available in straitened regions due to lack of adequate supplies, healthcare facilities, and medical
professionals. A low-cost, rapid, and an easily
accessible testing solution is needed to increase
the diagnostic capability and devise a treatment
plan. Computed Tomography(CT) helps clinicians perform complete patient assessments and
describe the specific characteristic manifestations in the lungs associated with COVID-19 (Li
et al., 2020). Hence, serving as an efficient tool
for early screening and diagnosis of COVID-19.
In analyzing medical images, AI-based methods
have shown great success (Du et al., 2018; Heidari et al., 2018, 2020). These methods are scalable, automatable, and easy to apply in clinical
environments (Ahmed et al., 2020; Shah et al.,
2019). Significant attempts have been made

PAY ATTENTION TO THE C OUGH

non-stationary signals. In a study by (Swarnkar
et al., 2012), a Logistic Regression model was
utilized to classify the dry and wet cough from
pediatric patients with different respiratory illnesses. For pertussis cough classification, three
separate classifiers’ performance was analyzed
in (Parker et al., 2013) research. Several AIbased approaches, motivated by prior work, have
been presented to detect patients with COVID19 using cough sound analysis. (Deshpande
and Schuller, 2020) gives an overview of Audio,
Signal, Speech, NLP for COVID-19, (Orlandic
et al., 2020; Brown et al., 2020; Sharma et al.,
2020) have collected a crowdsourced dataset of
respiratory sounds and shared the findings over
a subset of the dataset. Imran et al. (2020); Furman et al. (2020) performed similar analyses on
cough data and achieved good accuracy. Most
studies use short-term magnitude spectrograms
transformed from cough sound data to the convolutional neural network (CNN). However, these
methods have the following limitations :

to use x-ray images for automatic diagnosis of
COVID-19 (Pereira et al., 2020; Narin et al.,
2020; Zhang et al., 2020; Apostolopoulos and
Mpesiana, 2020). Studies dealing with the classification of COVID-19 show promising results
in this task.
However, in (Cohen et al., 2020) work, the
classification limitations of x-ray images are examined since the network may learn more unique
features to the dataset than those unique to the
disease. Despite its success, the CT scan displays similar imaging characteristics, making it
difficult to distinguish between COVID-19 and
other pneumonia types. Moreover, CT-based
methods can be integrated only with the Healthcare system to help clinical doctors, radiologists,
and specialists detect COVID-19 patients using
chest CT images. Unfortunately, an individual
cannot utilize this method at home. To obtain
the CT scan image and report, one must visit a
well-equipped clinical facility or diagnostic center, which may increase the risk of exposure to
the virus. According to the WHO and CDC official report, the four primary symptoms of the
COVID are dry cough, fever, tiredness, and difficulty in breathing. (CDC). However, cough is
more common as it is one of the early symptoms
of respiratory tract infections. Studies show that
it occurs in 68% to 83% of the people showing
up for the medical examination. Cough classification is usually carried out manually during
a physical examination, and the clinician may
listen to several episodes of voluntary or natural coughs to classify them. This information is
crucial in diagnosis and treatment.
In previous studies, several methods with
speech features have been proposed to automate
different cough types classification. In the study
published by (Knocikova et al., 2008), the sound
of voluntary cough in patients with respiratory
diseases was investigated. Later, in 2015, (Guclu
et al., 2015) published the study on the analysis
of asthmatic breathing sounds. These studies utilized the wavelet transformation, which is a type
of signal processing technique, generally used on

• Ignoring domain-specific sound information Cough is a non-stationary acoustic
event. CNN is based only on a spectrogram input; some domain-specific important characteristics (besides spectrogram)
of cough sounds might be overlooked in the
feature space.
• Using cough features only These methods
exploit the cough features only, ignoring
patient characteristics, medical conditions,
and symptoms data. Both cough features
and other symptoms accompanied by demographic data are responsible for COVID19 infection. Wherein the prior carries vital information about the respiratory system and the pathologies involved, the latter
encodes patient characteristics, signs, and
health conditions (fever, chest pain, dyspnea). However, their existence alone is
not a precise enough marker of the disease.
Therefore, determining the symptoms (besides cough) presented by suspected cases,
2

PAY ATTENTION TO THE C OUGH

is a low-cost, rapid, and easily accessible
testing solution to increase the diagnostic
capability and devise a treatment plan in
areas where adequate supplies, healthcare
facilities, and medical professionals are not
available.

as best predictors of a positive diagnosis
would be useful to make rapid decisions on
treatment and isolation needs.
• Lack of interpretability In AI research,
the model is not limited to accuracy and
sensitivity reports; instead, it is expected
to describe the predictions’ underlying reasons and enhance medical understanding
and knowledge. Clinical selection of an
algorithm depends on two main factors,
its clinical usefulness, and trustworthiness.
When the prediction does not directly explain a particular clinical question, its use
is limited.

• In this study, an interpretable diagnosis solution is presented, capable of explaining
and establishing a dialogue with its endusers about the underlying process. Hence,
resulting in transparent human interpretable
outputs.
• Three binary and one multi-class classification tasks are developed in this study;
Task 1 uses only cough features to classify
between COVID-19 positive and COVID19 negative. In Task 2, only demographic
and symptoms data is used, and in Task 3,
both types of information are used, which
helps the model learn deeper relationships
between temporal acoustic characteristics
of cough sounds and Symptoms’ features
and hence perform better. In Task 4, multiclass classification is performed to explain
the proposed model’s effectiveness in classifying between four cough types, including Bronchitis, Asthma, COVID-19 Positive, and COVID-19 Negative.

To overcome the limitation of the existing methods, A novel interpretable COVID-19 diagnosis
AI framework is proposed in this study, which
uses symptoms and cough features to classify the
COVID-19 cases from non-COVID-19 cases accurately. A three-layer Deep Neural Network
model is used to generate cough embeddings
from the handcrafted signal processing features
and symptoms embeddings are generated by a
transformer-based self-attention network called
TabNet. Arik and Pfister (2020) Finally, the
prediction score is obtained by concatenating
the Symptoms Embeddings with Cough Embeddings, followed by a Fully Connected layer. In
a sensitive discipline such as healthcare, where
any decision comes with an extended and long
term responsibility, making wrong predictions
can lead to critical judgments in life and death
situations.
In this study, it is illustrated that this framework is not limited to accurate predictions or
projections. Instead, it explains the underlying
reasons for the same and answers the question as
to why the model predicts it. The contributions
of the paper can be summarized as follows:

• An in-depth analysis is performed for different cough sounds. The observations
and findings are presented, distinguishing COVID-19 cough from other types of
cough.
• A python module was developed to extract
better and re-boost cough features from
raw cough sounds. This module is opensourced to help users, developers, and researchers. Those are not necessarily experts in domain-specific cough feature extraction, contributing to real-time cough
based research application, and provide better mobile health solutions.

• A novel explainable & interpretable
COVID-19 diagnosis framework based on
deep learning (AI) uses the information
from symptoms and cough signal processing features. The proposed solution
3

PAY ATTENTION TO THE C OUGH

• This study hence provides a medically- attention bottleneck respectively. After nth step
two outputs are produced.
vetted approach.
• Mask outputs are aggregated from all the
decision steps to provide model interpretability result. Figure 7 and Figure 8
shows the interpretability result.

2. Model Architecture
The model architecture consists of two subnetworks components, including the Symptoms
Embedddings and Cough Embeddings , that process the data from different modalities.

• The final output is a linear combination of
the all the summed decision steps, similar
to the decision tree result.

2.1. Symptoms Embeddings

Nsteps

Symptoms Embeddings capture the hidden feadout = ∑ ReLU(d[i])
(2)
tures of patient characteristics, diagnosis, sympi=1
toms. A feature that has been masked a lot has
low importance for the model and vice-versa. Pairwise dot product was computed between outAveraged Attention masks are used to explain put dout and FC layer to obtain the Symptoms
the overall importance of symptoms features.
Embeddings Se ∈ RB×F where B is the batch size
and F is the output dimension.
2.1.1. D ECISION S TEP (DS)
2.1.2. S YMPTOMS E MBEDDING L OSS

TabNet stacks the subsequent DS one after the
other. Decision steps are composed of a Feature Transformer(FT) Appendix B.0.2, an Attentive Transformer(AT)Appendix B.0.3 and feature masking. Symptoms features are mapped
into a D-dimensional trainable embeddings q ∈
RB×D , where B is the batch size, and D is the
feature dimension. A batch normalization (BN)
is performed across the whole batch. For the selection of specific soft features and explain the
feature importance TabNet uses a learnable mask
M[i] ∈ RB×D . Each decision step has a specific
mask and selects its own features; steps are sequential, so the second step needs the first to be
finished.
We obtain the mask(M) output at each decision step by multiplying the mask with Normalised symptoms features qi M[i] · q Normalized domain features are passed to FT, and a split
block divides the processed representation into
two chunks for the next decision step.

TabNet uses regularized sparse entropy loss to
control the sparsity of attentive features. The
regularization factor is a mathematical aggregation of the attention mask.
Nsteps B

D

−Mb, j [i]
log(Mb, j [i] + ε)
i=1 b=1 j=1 Nsteps B
(3)
Where ε is a small positive value.

Lossse = ∑ ∑

∑

2.2. Cough Embeddings
Cough Embeddigs learn and capture deeper
features in temporal acoustic characteristics of
cough sounds.
2.2.1. S IGNAL P REPROCESSING

Before extracting cough features and feeding
it to Deep Neural Networks(DNN), some pre

processing of raw audio data is needed. Each
d[i], a[i] = qi (M[i] · q)
(1)
cough recording was downsampled to 16 kHz;
B×n
B×n
a
d
where d[i] ∈ R
and a[i] ∈ R
. and nd , normalization was applied to the cough signal
na are size of the decision layer and size of the level with a target amplitude of -28.0 dBFS to
4

PAY ATTENTION TO THE C OUGH

Figure 1: Illustration of the overall structure of Proposed Model, The model consists of two subnetworks that process the
data from different modalities. The TabNet network at the top, process the features that include symptoms & Demographic
data, while the network in the bottom processes the audio signal from cough. Attention Masks from each decision step
are aggregated to provide model interpretability results

keep the future features as close as possible to
the same level.
Normalized features were split into cough segments based on the silence threshold. Let s[t]
be the discrete-time cough sound recording. The
expression of signal s[t] can be written as:
s[t] = y[t] + b[t]

see Appendix C for detailed information about
our data collection process. The final feature
matrix was grouped by chunks of n Consecutive
feature matrix, and A total of 44 cough features
were extracted by taking the mean and standard
deviation for all the cough features in each chunked matrix.
Later we feed the final feature matrix to 3 layers Deep Neural Network(DNN) with ReLu activation function to get the final Cough Embeddings Ce ∈ RB×F where B is the batch size and
F is the output dimension.

(4)

Where y[t] denotes the cough signal b[t] denotes the noise in the signal. To reduce the noise
and get y[t] a High Pass Filter(HPF) was applied
on s[t]. Cough segments y[t] were divided into
sub segments of non-overlapping Hammingwindowed frames. Let yi [t], i = 1, 2, 3, . . . n denotes the ith cough sub-segment from signal y[t]
with length N.
A total of 22 cough features were extracted
from each cough recording segment y[t], including 12 MFCC features, 4 Formant frequencies,
Zcr, Kurtosis feature, Log energy, Skewness feature, Entropy, and Fundamental frequency(F0).
Please see Appendix A for cough features. Also

2.2.2. C OUGH E MBEDDINGS L OSS
In Multi-class classification setting, we use Categorical Crossentropy loss function to calculate
the loss of Cough Embeddings
N

Lossce = − ∑ yi · log ŷi

(5)

i=1

where N is the number of classes in dataset, ŷi
denotes the i-th predicted class in the model out5

PAY ATTENTION TO THE C OUGH

F1-score

Precision

Sensitivity

Specificity

Accuracy

Covid-19 Positive
Covid-19 Negative
Bronchitis
Asthma

86.38 ± 0.03%

81.88 ± 0.01%

91.39 ± 0.04%

97.49 ± 0.03%

96.81 ± 0.05%

92.16 ± 0.01%

95.09 ± 0.02%

89.41 ± 0.08%

98.64 ± 0.05%

96.55 ± 0.11%

92.85 ± 0.04%

97.70 ± 0.05%

88.45 ± 0.05%

98.08 ± 0.12%

93.46 ± 0.02%

83.88 ± 0.13%

75.46 ± 0.03%

94.41 ± 0.04%

93.10 ± 0.01%

93.34 ± 0.05%

Overall

90.09 ± 0.17%

90.92 ± 0.09%

90.41 ± 0.14%

96.83 ± 0.06%

95.04 ± 0.18%

Table 1: Model performance metrics across four different diseases
put and yi is the corresponding target value. In a
binary setting, we use the Binary Cross-Entropy
loss function.

Lossce = −

1 N
∑ [yn log ŷn + (1 − yn ) log (1 − ŷn )]
N n=1
(6)

2.3. Classification layer

• Task 2, Using Demographic & Symptoms
Data Only In this setup, experiments were
conducted on Demographic & Symptoms
data. The symptoms ( Fever, Headache,
aches, sore throat, etc.) were used to train
the model and classify between cover-19
positive and negative cases.

We get the prediction score by concatenating
the Symptoms Embeddings with Cough Embeddings followed by a FC layer.


ŷ = Se ,Ce ·FC
(7)
| {z }
Concatenate

Figure 1 shows the overall structure of the proposed architecture. After this, Total loss was calculated as follows
Losstotal = (1 − α) Lossce + α Lossse
|
{z
} | {z }
Cough
Embeddings Loss

• Task 1, Using cough data only In this
experiment setup, only cough features
were utilized from the collected dataset to
train the Model and distinguish between
COVID-19 positive and negative cases.
Cough features were extracted using the
signal processing pipeline, as described in
section 1.

• Task 3, Using Both when using both types
of data, including cough features from section 3 with Demographic & Symptoms
data, Model learn the hidden patterns and
relationship between both types of features
and classify between COVID-19 positive
and negative cases.

(8)

Symptoms
Embeddings Loss

Where α is a small constant value to balance
the contribution of the different losses.

• Task 4, Using Both with different Cough
Types, to demonstrate the effectiveness of
the Model, the Model is trained on four different types of cough, including COVID19, Bronchitis, Asthma, and Healthy using
both types of data.

3. Experiments
3.1. Evaluation
In this section, a comprehensive evaluation is
carried out to investigate the results of four clinical classification tasks. Based on the dataset collected, the model was trained on the following
combination of features.

The five standard evaluation metrics (Accuracy,
specificity, sensitivity/recall, precision, and F1score) are adopted to evaluate the Model on the
test dataset. Several iterations were performed,
6

PAY ATTENTION TO THE C OUGH

Cough data

Symptoms data

Both

F1-score

Precision

Sensitivity

Specificity

Accuracy

Covid-19 Positive
Covid-19 Negative

90.6 ± 0.2%
90.6 ± 0.1%

89.1 ± 0.4%
91.7 ± 0.1%

86.2 ± 0.3%
94.3 ± 0.3%

92.4 ± 0.2%
89.3 ± 0.1%

89.3 ± 0.1%
92.4 ± 0.1%

Overall

90.6 ± 0.3%

90.4 ± 0.5%

90.1 ± 0.6%

90.3 ± 0.3%

90.8 ± 0.2%

Covid-19 Positive
Covid-19 Negative

91.5 ± 0.2%
91.5 ± 0.1%

86.9 ± 0.5%
93.7 ± 0.3%

87.8 ± 0.2%
93.3 ± 0.2%

86.0 ± 0.3%
94.1 ± 0.1%

94.1 ± 0.6%
86.0 ± 0.2%

Overall

91.5 ± 0.3%

90.3 ± 0.8%

90.5 ± 0.4%

90.8 ± 0.3%

91.1 ± 0.8%

Covid-19 Positive
Covid-19 Negative

96.8 ± 0.4%
96.8 ± 0.1%

95.1 ± 0.1%
97.6 ± 0.3%

94.6 ± 0.3%
97.8 ± 0.4%

95.6 ± 0.1%
97.3 ± 0.2%

97.3 ± 0.2%
95.6 ± 0.3%

Overall

96.8 ± 0.5%

96.3 ± 0.4%

96.2 ± 0.7%

96.5 ± 0.3%

96.5 ± 0.5%

Table 2: Model performance metrics across different models on Covid-19 data
• In Task 3, the Model makes better use
of available data by combining both types
of representation, which complement each
other and significantly improve the classification’s performance with the Accuracy,
Specificity, and Sensitivity of 96.5 ± 0.5%,
96.5 ± 0.3% and 96.2 ± 0.7%. It is observed that one data type, either cough features or symptoms’ features, is insufficient
to capture the features predicting COVID19 disease effectively.

and results were reported. Table 1 and Table 2
represents the classification of results along with
the following observations:

• The Model achieves Accuracy, Specificity,
and Sensitivity of 90.8 ± 0.2%, 90.3 ±
0.3%, 90.1 ± 0.6% respectively. Task 1, using only the cough features. It demonstrates
that Cough provides requisite data about
the respiratory system and the pathogenies
involved. Signal processing characteristics enable the Model to capture the hidden cough sound signatures and diagnose
COVID-19 with sufficient sensitivity and
specificity.

• To further demonstrate the proposed
Model’s flexibility, the Model was trained
with a multi-class classification setting to
distinguish between four types of cough
classes, including Bronchitis, Asthma,
COVID-19 Positive, and COVID-19
Negative. The experimental results of
Multi-class classification are presented
in Table 1. Results show that the Model
can certainly classify between four types
of cough classes with Accuracy, Specificity, and Sensitivity of 95.04 ± 96.83 ±
0.06%,90.41 ± 0.14% respectively.

• When using symptoms and demographic
data, the Model’s performance represents a
slight increase in Accuracy, Specificity, and
Sensitivity 91.1 ± 0.8%, 90.8 ± 0.3%, and
90.5 ± 0.4%. Compared to Task 1. This
increase is attributed to the rich categorical
information present in Demographic and
Symptoms data about suspected infection
cases and Transformer based network; TabNet exploits attention mechanism to learn
the characteristics, diagnosis automatically,
and symptoms based on information in their
dataset.

Both types of data enable the Model to
learn deeper relationships between temporal acoustic characteristics of cough sounds
and Symptoms’ features and hence perform
better.
7

PAY ATTENTION TO THE C OUGH

Figure 2: Healthy Cough

Figure 3: Asthma Cough

Figure 4: Bronchitis Cough

Figure 5: COVID-19 Cough

Figure 6: Four types of cough with their original sound, FFT output, and 1D image representation in Figure 2: Healthy
cough, Figure 3: Asthma Cough, Figure 4: Bronchitis cough, and Figure 5: Covid-19 positive cough
3.2. Interpretability

3.3. In Depth Clinical Analysis

It is demonstrated that the proposed framework
benefits from the high accuracy and generality of
deep neural networks and TabNet’s interpretability, which is crucial for AI-empowered healthcare. Figure 7 and Figure 8 visualizes the symptoms of a healthy and COVID-19 infected individual. It shows that the model comprehends the
hidden pattern in symptoms data and its relationship with cough sounds. To intuitively show the
representation’s quality, the cough features using
t-sne and symptoms correlation matrix are visualized in Figure 9 and Figure 10

An in-depth analysis is conducted for different
cough sounds diagnosed with different diseases
based on the collected data. Different types of
cough samples are visualized in Figure 6. Based
on the analyzed data, the findings are as follows.
The coughing sound consists of three phasesPhase 1- Initial burst, Phase 2- Noisy airflow, and
Phase 3- Glottal closure. It is observed that in
the cough sample of healthy individuals, phase 3
finished with vocal folds activity. Figure 2 shows
that after Phase 1, i.e., initial burst, the energy
levels are high at higher frequencies.
8

PAY ATTENTION TO THE C OUGH

Figure 7: Attention distribution over the Symptoms of a Healthy(COVID-19 Negative) person. The color depth expresses the seriousness of a symptom.

Figure 8: Attention distribution over the Symptoms of a COVID-19 infected person. Fever, Cough, Dizziness, or
Confusion, Chest pain is with high color depth, showing that the model has learned the symptoms embedding based on
demographic & cough features.

Figure 3 and Figure 4 shows these characteristics
and the energy level.
It is observed that COVID-19 cough is continuous; energy distribution is spread across frequencies preceded by a short catch. By analyzing the mean energy distribution of many
COVID-19 cough sounds, Energy distribution
was high in Phase 2 and Phase 3. The abnormal oscillatory motion in the vocal folds may be
produced by altered aerodynamics over the glottis due to respiratory irritation. Figure 5 shows
the result
Figure 9: t-SNE visualization of four types of Cough features

4. Conclusion

Asthma & Bronchitis comes under the wet
cough (carries mucus and sputum caused by
bacteria or viruses, secretion in the lower airways) category. In particular, vocal fold activity
looks random, and the energy is expended over
a broader frequency band. Asthma & Bronchitis

Mass COVID-19 monitoring has proved essential for governments to successfully track the disease’s spread, isolate infected individuals, and
effectively ”flatten the curve” of the infection
over time. In the wake of the COVID-19 pandemic, many countries cannot conduct rapid
enough tests; hence an alternative could prove
9

PAY ATTENTION TO THE C OUGH

the output of the log filter bank in order to get
the MFCCs :

very useful. This study brings forth a Low cost,
accurate and interpretable AI-based diagnostic
tool for COVID-19 screening by incorporating
the demographic, symptoms, and cough features
and achieving mean accuracy, precision, and
precision in the mentioned tasks. This significant achievement supports large-scale COVID19 disease screening and areas where healthcare
facilities are not easily accessible. Data collection is being performed daily. Experiments
will be carried out in the future by incorporating different voice data features such as breathing sound, counting sound (natural voice samples), and sustained vowel phonation. The results prove to be transparent, interpretable, and
multi-model learning in cough classification research.

r



2 M
πi
c(i) =
∑ log(E(m)) cos M (m − 0.5)
M m=1
(10)
where i = 1, 2, . . . , l, l denotes the cepstrum order, E(m) and M are the filter bank energies and
total number of mel-filters respectively.
A.2. Log energy
To calculate the log energy of each sub-segment,
the following formula was used:
1 N
Lt = 10 log 10 ε + ∑ yi (t)2
N t=1

Appendix A. Cough Features

!
(11)

where ε is a minimal positive value.

A.1. Mel Frequency Cepstral coefficients
(MFCCs)

A.3. Zero crossing rate(ZCR)

Mel Frequency Cepstral coefficients represent
the short-term power spectrum of a signal on the
Mel-scale of the frequency. The hearing mechanism of human beings inspires MFCC. The coefficients of MEL-frequency that represent this
transformation are called MFCCs. First, we
apply the Discrete Fourier Transform(DFT) on
each cough sub-segment

ZCR is used to calculate the number of times a
signal crosses the zero axis. To detect the cough
signal’s periodic nature, we compute the number
of zero crossings for each sub-segment.
Zt =

1 N−1
∑ Π [yi (t)yi (t − 1)]
N − 1 t=1

(12)

Where Π[A] is a indicator function and is defined
as
N−1
(
Y (k) = ∑ yi [t]w(t) exp(−2πikt/N),
1, if A < 0
Π[A] =
t=0
k = 0, 1, . . . , N − 1 (9)
0, otherwise
Where N denotes the number of samples in
frame, yi [t] is the discrete time domain cough
signal, obtained in Section 2.2.1, w(t) is the
window function in time domain and Y (k) is
the kth harmonic corresponding to the frequency
f (k) = kFs /N where Fs is the sampling frequency. MFCCs use Mel filter bank or triangular
bandpass filter on each cough signal’s DFT output, equally spaced on the Mel-scale. At last, we
apply the Discrete Cosine Transform(DCT) on

A.4. Skewness
Skewness is the third order moment of a signal,
Which measures the symmetry in a probability
distribution.
E (yi [t] − µ)3
(13)
σ3
Where µ and σ is mean and stand deviation of
the sub-segment yi [t] respectively.

10

St =

PAY ATTENTION TO THE C OUGH

A.5. Entropy

Appendix B. TabNet Components

We compute the Entropy for each sub-segment B.0.1. G ATED L INEAR U NIT (GLU)
of the cough signal to capture the difference beGLU (Dauphin et al., 2017) layer consist of
tween signal energy distributions.
Fully connected layer (FC), Ghost batch normalization (GBN) (Hoffer et al., 2018) and GLU.
N−1
FC layer map the input features to 2(nd + na )
Et = − ∑ yi (t)2 ln(yi (t)2 ), 1 ≤ t ≤ N − 1
where nd and na are size of the decision layer
t=1
(14) and size of the attention bottleneck respectively.
GBN splits each batch in chunks of virtual batch
size(BS), standard Batch normalization(BN) applies separately to each of these, and concateA.6. Formant frequencies
nates the results back into the original batch.
In the analysis of speech signals, Formant frequencies are used to capture a human vocal tract
resonance’s characteristics. We compute the
Formant frequencies by peak picking the Linear
Predictive Coding(LPC) spectrum. We used the
Levinson-Durbin recursive procedure to select
the parameters for the 14th order LPC model.
The first four Formant frequencies(F1-F4) are
enough to discriminate various acoustic features
of airways.

A.7. Kurtosis

B.0.2. F EATURE T RANSFORMER (FT)
The feature transformer is one of the main components of TabNet; it consists of 4 GLU layers,
two are shared across the entire network, and two
are step-dependent across each decision step allowing for more modeling flexibility. GLU layers are concatenated with each other after√being
multiplied by a constant scaling factor( 0.5).
Feature Transformer process the filtered features
by looking at all the symptoms features assessed
and deciding which ones indicate which class.

Kurtosis can be defined as the fourth-order mo- B.0.3. ATTENTIVE T RANSFORMER (AT)
ment of a signal, which measures the peakiAttention Transformer is another main componess or heaviness associated with the cough subnent of TabNet architecture. It utilizes sparse
segment probability distribution.
intense wise features selection based on learned
symptoms dataset and directs the model’s attenE (yi [t] − µ)4
kt =
(15) tion by forcing the sparsity into the feature set,
σ4
focusing on specific symptoms features only. It
is a powerful way of prioritizing which features
Where µ and σ is mean and stand deviation of
to look at for each decision step. The FC handles
the sub-segment yi [t] respectively.
the learning part of this block. TabNet uses the
Sparsemax, Martins and Astudillo (2016) an alternative of softmax function for soft feature seA.8. Fundamental frequency(F0)
lection. Sparsemax activation function is differTo estimate the fundamental frequency (F0) of entiable and has forward and backward propagathe cough sub-segment, we used the center- tion. Due to projection and thresholding, sparseclipped auto-correlation method by removing the max process sparse probabilities lead to a selecformant structure from the auto-correlation of tive and more compact attention focus on symptoms features.
the cough signal.
11

PAY ATTENTION TO THE C OUGH

Figure 10: Correlation matrix for Symptoms and medical conditions data

12

PAY ATTENTION TO THE C OUGH

Appendix C. Data Acquisition
All the COVID-19 data utilized in this study
were obtained from 200 subjects in a Dr. Ram
Manohar Lohia Hospital, New Delhi, India. Out
of 100 were confirmed positive from COVID-19
reverse transcription-polymerase chain reaction
(RT-PCR) results. The Clinical Trials RegistryIndia (CTRI) had approved the study protocols
and the patient recruitment procedure. After
data preprocessing and Out of 200 samples, 50
samples were discarded due to low data quality. Aside from COVID-19 and healthy data,
We also collected Bronchitis and Asthma cough
from different online and offline sources. The
data collection person followed all the clinical
safety measures and inclusion-exclusion criteria
and the cough sounds, breathing sounds, counting 1 to 10 ( natural voice samples ), sustained
phonation of ’a,’ ’e,’ ’o’ vowel, demographic,
symptoms data such as fever, headache, sore
Thorat, or any other medical conditions were
also collected at the same time. The average interaction time with the subject was 10–12 mins.

References

convolutional neural networks.
Physical
and Engineering Sciences in Medicine,
43:635–640, 6 2020.
ISSN 2662-4729.
doi: 10.1007/s13246-020-00865-4. URL
http://link.springer.com/10.1007/
s13246-020-00865-4.
Sercan O. Arik and Tomas Pfister. Tabnet: Attentive interpretable tabular learning, 2020.
Chloë Brown, Jagmohan Chauhan, Andreas
Grammenos, Jing Han, Apinan Hasthanasombat, Dimitris Spathis, Tong Xia, Pietro Cicuta,
and Cecilia Mascolo. Exploring automatic diagnosis of covid-19 from crowdsourced respiratory sound data, 2020.
Joseph Paul Cohen, Mohammad Hashir, Rupert
Brooks, and Hadrien Bertrand. On the limits
of cross-domain generalization in automated
x-ray prediction, 2020.
Yann N. Dauphin, Angela Fan, Michael Auli,
and David Grangier. Language modeling with
gated convolutional networks, 2017.
Gauri Deshpande and Björn Schuller.
An
overview on audio, signal, speech, & language
processing for covid-19, 2020.

centers for disease control and prevention. URL
https://www.cdc.gov/coronavirus/
Yue Du, Roy Zhang, Abolfazl Zargari,
2019-ncov/symptoms-testing/
Theresa C. Thai, Camille C. Gunderson,
symptoms.html.
Katherine M. Moxley, Hong Liu, Bin Zheng,
and Yuchen Qiu. Classification of tumor
Zeeshan Ahmed, Khalid Mohamed, Saman
epithelium and stroma by exploiting image
Zeeshan, and XinQi Dong. Artificial infeatures learned by deep convolutional neural
telligence with multi-functional machine
networks. Annals of Biomedical Engineering,
learning platform development for bet46:1988–1999, 12 2018. ISSN 0090-6964.
ter healthcare and precision medicine.
doi: 10.1007/s10439-018-2095-6.
URL
Database, 2020, 1 2020. ISSN 1758-0463.
http://link.springer.com/10.1007/
doi:
10.1093/database/baaa010.
URL
s10439-018-2095-6.
https://academic.oup.com/database/
Shannon L. Emery, Dean D. Erdman, Michael D.
article/doi/10.1093/database/
Bowen, Bruce R. Newton, Jonas M. Winchell,
baaa010/5809229.
Richard F. Meyer, Suxiang Tong, Byron T.
Cook, Brian P. Holloway, Karen A. McCaustIoannis D. Apostolopoulos and Tzani A. Mpeland, Paul A. Rota, Bettina Bankamp, Luis E.
siana. Covid-19: automatic detection from
Lowe, Tom G. Ksiazek, William J. Bellini,
x-ray images utilizing transfer learning with
13

PAY ATTENTION TO THE C OUGH

and Larry J. Anderson. Real-time reverse Ali Imran, Iryna Posokhova, Haneya N. Qureshi,
Usama Masood, Muhammad Sajid Riaz,
transcription–polymerase chain reaction assay
Kamran Ali, Charles N. John, MD Iftikhar
for sars-associated coronavirus. Emerging InHussain, and Muhammad Nabeel. Ai4covidfectious Diseases, 10:311–316, 2 2004. ISSN
19:
Ai enabled preliminary diagnosis
1080-6040. doi: 10.3201/eid1002.030759.
for covid-19 from cough samples via
URL
http://wwwnc.cdc.gov/eid/
an app.
Informatics in Medicine Unarticle/10/2/03-0759_article.htm.
locked, 20:100378, 2020. ISSN 23529148.
É G Furman, A Charushin, E Eirikh, S Malinin,
doi: 10.1016/j.imu.2020.100378.
URL
V Shelud’ko, V Sokolovsky, and G Furman.
https://linkinghub.elsevier.com/
The remote analysis of breath sound in covidretrieve/pii/S2352914820303026.
19 patients: A series of clinical cases. 2020.
Juliana Knocikova, J Korpas, M Vrabec, and
Gunes Guclu, Fatma Göğüş, and Bekir KarMichal Javorka. Wavelet analysis of volunlik. Classification of asthmatic breath sounds
tary cough sound in patients with respiratory
by using wavelet transforms and neural netdiseases. Journal of physiology and pharmaworks. International Journal of Signal Procology, 59 Suppl 6:331–340, 10 2008.
cessing Systems, 3, 10 2015.
Lin Li, Lixin Qin, Zeguo Xu, Youbing Yin, Xin
Morteza Heidari, Abolfazl Zargari Khuzani,
Wang, Bin Kong, Junjie Bai, Yi Lu, ZhengAlan B Hollingsworth, Gopichandh Danala,
han Fang, Qi Song, Kunlin Cao, Daliang
Seyedehnafiseh Mirniaharikandehei, Yuchen
Liu, Guisheng Wang, Qizhong Xu, Xisheng
Qiu, Hong Liu, and Bin Zheng. Prediction of
Fang, Shiqin Zhang, Juan Xia, and Jun Xia.
breast cancer risk using a machine learning
Using artificial intelligence to detect covidapproach embedded with a locality preserving
19 and community-acquired pneumonia based
projection algorithm. Physics in Medicine
on pulmonary ct: Evaluation of the diagnos& Biology, 63:035020, 1 2018.
ISSN
tic accuracy. Radiology, 296:E65–E71, 8
1361-6560. doi: 10.1088/1361-6560/aaa1ca.
2020. ISSN 0033-8419. doi: 10.1148/radiol.
URL
https://iopscience.iop.org/
2020200905.
URL http://pubs.rsna.
article/10.1088/1361-6560/aaa1ca.
org/doi/10.1148/radiol.2020200905.
Morteza Heidari,
Seyedehnafiseh Mir- André F. T. Martins and Ramón Fernandez Astudillo. From softmax to sparsemax: A sparse
niaharikandehei,
Wei Liu,
Alan B.
model of attention and multi-label classificaHollingsworth, Hong Liu, and Bin Zheng.
tion, 2016.
Development and assessment of a new
global mammographic image feature analysis
Ali Narin, Ceren Kaya, and Ziynet Pamuk.
scheme to predict likelihood of malignant
Automatic detection of coronavirus disease
cases.
IEEE Transactions on Medical
(covid-19) using x-ray images and deep conImaging, 39:1235–1244, 4 2020.
ISSN
volutional neural networks, 2020.
0278-0062. doi: 10.1109/TMI.2019.2946490.
URL
https://ieeexplore.ieee.org/ Lara Orlandic, Tomás Teijeiro, and D Atienza.
document/8863397/.
The coughvid crowdsourcing dataset: A corpus for the study of large-scale cough analysis
Elad Hoffer, Itay Hubara, and Daniel Soudry.
algorithms. ArXiv, abs/2009.11644, 2020.
Train longer, generalize better: closing the
generalization gap in large batch training of Danny Parker, Joseph Picone, Amir Harati,
Shuang Lu, Marion H. Jenkyns, and Philip M.
neural networks, 2018.
14

PAY ATTENTION TO THE C OUGH

Polgreen. Detecting paroxysmal coughing
from pertussis cases using voice recognition
technology. PLoS ONE, 8:e82971, 12 2013.
ISSN 1932-6203. doi: 10.1371/journal.pone.
0082971. URL https://dx.plos.org/10.
1371/journal.pone.0082971.
Rodolfo M. Pereira, Diego Bertolini, Lucas O.
Teixeira, Carlos N. Silla, and Yandre M.G.
Costa. Covid-19 identification in chest x-ray
images on flat and hierarchical classification
scenarios. Computer Methods and Programs
in Biomedicine, 194:105532, 10 2020. ISSN
01692607. doi: 10.1016/j.cmpb.2020.105532.
URL
https://linkinghub.elsevier.
com/retrieve/pii/S0169260720309664.
Pratik Shah, Francis Kendall, Sean Khozin,
Ryan Goosen, Jianying Hu, Jason Laramie,
Michael Ringel, and Nicholas Schork. Artificial intelligence and machine learning
in clinical development: a translational
perspective.
npj Digital Medicine, 2:
69, 12 2019.
ISSN 2398-6352.
doi:
10.1038/s41746-019-0148-3.
URL
http://www.nature.com/articles/
s41746-019-0148-3.
Neeraj Sharma, Prashant Krishnan, Rohit Kumar, Shreyas Ramoji, Srikanth Raj Chetupalli,
Nirmala R., Prasanta Kumar Ghosh, and Sriram Ganapathy. Coswara – a database of
breathing, cough, and voice sounds for covid19 diagnosis, 2020.
V. Swarnkar, U. R. Abeyratne, Y. A. Amrulloh, and A. Chang. Automated algorithm for wet/dry cough sounds classification. pages 3147–3150, 8 2012. ISBN 9781-4577-1787-1. doi: 10.1109/EMBC.2012.
6346632. URL http://ieeexplore.ieee.
org/document/6346632/.
Jianpeng Zhang, Yutong Xie, Guansong Pang,
Zhibin Liao, Johan Verjans, Wenxin Li,
Zongji Sun, Jian He, Yi Li, Chunhua Shen,
and Yong Xia. Viral pneumonia screening
15

on chest x-ray images using confidence-aware
anomaly detection, 2020.

