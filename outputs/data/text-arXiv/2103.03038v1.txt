Mobile Touchless Fingerprint Recognition:
Implementation, Performance and Usability Aspects
Jannis Priesnitza,c,∗, Rolf Huesmannb , Christian Rathgeba , Nicolas Buchmannc , Christoph Buscha
a da/sec

– Biometrics and Internet Security Research Group, Hochschule Darmstadt, Schöfferstraße 8b, 64295 Darmstadt, Germany
– User-Centered Security Research Group, Hochschule Darmstadt, Schöfferstraße 8b, 64295 Darmstadt, Germany
c Freie Universität Berlin, Takustraße 9, 14195 Berlin, Germany

b UCS

Abstract
This work presents an automated touchless fingerprint recognition system for smartphones. We provide a comprehensive
description of the entire recognition pipeline and discuss important requirements for a fully automated capturing system. Also, our implementation is made publicly available for research purposes. During a database acquisition, a total
number of 1,360 touchless and touch-based samples of 29 subjects are captured in two different environmental situations.
Experiments on the acquired database show a comparable performance of our touchless scheme and the touch-based
baseline scheme under constrained environmental influences. A comparative usability study on both capturing device
types indicates that the majority of subjects prefer the touchless capturing method. Based on our experimental results
we analyze the impact of the current COVID-19 pandemic on fingerprint recognition systems. Finally, implementation
aspects of touchless fingerprint recognition are summarized.
Keywords: Biometrics, Fingerprint Recognition, Touchless Fingerprint, Usability, Biometric Performance
1. Introduction
Fingerprints are one of the most important biometric
characteristic due to their known uniqueness and persistence properties. Fingerprint recognition systems are not
only used worldwide by law enforcement and forensic agencies, they are also deployed in the mobile devices as well
as in nation-wide applications. The vast majority of fingerprint capturing schemes requires contact between the finger
and the capturing device’s surface. These systems suffer
from distinct problems, e.g. low contrast caused by dirt
or humidity on the capturing device plate or latent fingerprints of previous users (ghost fingerprints). Especially in
multi-user applications hygienic concerns lower the acceptability of touch-based fingerprint systems and hence, limit
their deployment. In a comprehensive study, Okereafor et
al. [1] analyze the risk of an infection by touch-based fingerprint recognition schemes and the hygienic concerns of
their users. The authors conclude that touch-based fingerprint recognition carries a high risk of an infection if a
previous user has contaminated the capturing device surface, e.g. with the SARS-CoV-2 virus.
To tackle these shortcomings of touch-based schemes,
touchless fingerprint recognition systems have been researched for more than a decade. Touchless capturing
schemes operate without any contact between the finger
and the capturing device. Several contributions to the
research area paved the way for a practical implementation of touchless capturing schemes. Specialized stationary
capturing devices based on multi-camera setups combined
∗ Corresponding

author
Email address: jannis.priesnitz@h-da.de (Jannis Priesnitz)
URL: dasec.h-da.de (Jannis Priesnitz)

Preprint submitted to Elsevier

with a powerful processing have already been implemented
in a practical way [16]. However, to the best of the authors’ knowledge no approach to mobile touchless recognition scheme based on of-the-shelf components has been
documented so far.
In this work, we propose a mobile touchless fingerprint
recognition scheme based for smartphones. We provide a
fully automated capturing scheme with integrated quality
assessment in form of an Android app. All components of
the processing pipeline will be made publicly available for
research purposes. The rest of the recognition pipeline is
composed of open source algorithms for feature extraction
and comparison.
To benchmark our proposed recognition pipeline we acquired a database under real life conditions. A number of
29 subjects have been captured by two touchless capturing
devices in different environmental situations. Moreover,
touch-based samples have been acquired as baseline and
to measure the interoperability between both schemes. A
usability study, which has been conducted after the capturing, reviews the users’ experiences with both capturing device types. This paper details on every implementation step
of the processing pipeline and summarizes our database
acquisition setup in detail. Further, we evaluate the biometric performance of our acquired database and discusses
the outcomes of our usability study. Based on our experimental results we elaborate on the impact of the current
COVID-19 pandemic on fingerprint recognition in terms of
biometric performance and user acceptance. Further we
summarize implementation aspects which we consider as
beneficial for mobile touchless fingerprint recognition.
The rest of the paper is structured as follows: Section 2
gives an overview on touchless end-to-end schemes proposed in the scientific literature. In Section 3, the proposed
March 5, 2021

Table 1: Overview on selected recognition workflows with biometric performance. (Device type: P = Prototypical hardware, S = Smartphone,
W = Webcam)
Mobile /
Amount Automatic Free finger
On-device
Biometric
Device
Authors
Year
type
capturing positioning
processing
Performance
Stationary of fingers
Hiew et al. [2]
2007
P
S
1
N
N
N
EER: 5.63%
Piuri et al. [3]
2008
W
S
1
N
N
N
EER: 0.04%
Wang et al. [4]
2009
P
S
1
N
N
N
EER: 0.0% 1
Kumar and Zhou [5]
2011
W
S
1
N
N
N
EER: 0.32%
Derawi et al. [6]
2011
S
S
1
N
N
N
EER: 4.5%
Noh et al. [7]
2011
P
S
5
Y
N
N
EER: 6.5%
Stein et al. [8]
2013
S
M
1
Y
Y
Y
EER: 1.2%
Raghavendra et al. [9]
2014
P
S
1
N
Y
N
EER: 6.63%
Tiwari et al. [10]
2015
S
M
1
N
Y
N
EER: 3.33%
Sankaran et al. [11]
2015
S
M
1
Y
N
N
EER: 3.56%
FAR = 0.01% @
Carney et al. [12]
2017
S
M
4
Y
N
Y
FRR = 1%
TAR = 98.55% @
Deb et al. [13]
2018
S
M
1
Y
Y
Y
FAR = 1.0%
FRR 1.2% @
Weissenfeld et al. [14]
2018
P
M
4
Y
Y
Y
FAR 0.01%
Birajadar et al. [15]
2019
S
M
1
Y
N
N
EER: 1.18%
Our method
2021
S
M
4
Y
Y
Y
EER: 5.36%

Figure 1: Overview on the most relevant steps of our proposed method.

processing pipeline is presented. In Section 4, we describe
our experimental setup and provide details about the captured database and the usability study. The results of our
experiments are reported in Section 5. The influence of the
COVID-19 pandemic on fingerprint recognition is discussed
in Section 6. Section 7 discusses implementation aspects.
Finally, Section 8 concludes.

app and manually transferred to a remote device where the
processing is performed [10, 11]. The improvement of the
camera and processing power in current smartphones has
made it possible to capture multiple fingers in in a single
capture attempt and process them on the device. Stein et
al. [8] showed that it is feasible for the automated capturing of a single finger image using a smartphone. Carney
et al. [12] presented the first four-finger capturing scheme.
Weissenfeld et al. [14] proposed a system with a free positioning of four fingers in a mobile prototypical hardware
setup.
In summary, it can be observed that the evolution of
touchless fingerprint technologies has moved towards outof-the-box device and a more convenient and practically
relevant recognition process. Table 1 also indicates that
both an accurate recognition and a convenient capturing
are hard to achieve. It should be further noted that the
level of constraints during the capturing has a major influence on the recognition performance.

2. Related Work
In this section, we present an overview on touchless fingerprint end-to-end solutions along with reported biometric performance. Table 1 summarizes most relevant related
works and their properties. For a comprehensive overview
on the topic of touchless fingerprint recognition the reader
is referred to [17].
The research on touchless fingerprint recognition has
evolved from bulky single finger devices to more convenient multi-finger capturing schemes. First end-to-end approaches with prototypical hardware setups were presented
by Hiew et al. [2] and Wang et al. [4]. Both works employed huge capturing devices for one single finger acquisition within a hole-like guidance.
For remote user authentication, Piuri et al. [3] and Kumar et al. [5] investigated the use of webcams as fingerprint capturing device. Both schemes showed a very low
EER in experimental results. However, the database capturing process was not reported precisely. In addition, the
usability and user acceptance of such an approach should
be further investigated.
More recent works use smartphones for touchless fingerprint capturing. Here, a finger image is taken by a photo

3. Mobile Touchless Recognition Pipeline
An unconstrained and automated touchless fingerprint
recognition system usually requires a more elaborated processing compared to touch-based schemes. Figure 1 gives
an overview on the key processing steps of the proposed
recognition pipeline. Our method features an on-device
capturing, pre-processing, and quality assessment whereas
the biometric identification workflow is implemented on a
back-end system. This section describes each component
of the recognition pipeline in detail.
The proposed method combines three implementation
aspects seen as beneficial for an efficient and convenient
recognition:

1 The authors only report the EER on a score level fusion of 8
sequentially acquired fingerprints.

2

Figure 2: Overview of the segmentation of connected components from a continuous stream of input images.

Figure 3: Overview of the coarse rotation correction, separation of fingerprint images from each other, fine rotation correction, fingertip
cropping and normalization of the fingerprint size.

• A smartphone as hardware platform which captures
the finger image and obtains a fingerprint images from
it.

Otsu’s adaptive threshold is preferable over static thresholding. Combinations of different color channels also show
superior results compared to schemes based on one channel
[18, 19, 20, 21].
Figure 2 presents an overview of the segmentation workflow. We adopt this method and analyze the Cr component
of the yCbCr color model and the H component of the HSV
color model. As first step we normalize the color channels
to the full range of the histogram. Subsequently, the Otsu’s
threshold determines the local minimum in the histogram
curve. A binary mask is created where all pixel values below the threshold are set to black and all pixels above the
threshold are set to white.
Additionally, our algorithm analyzes the largest connected components within the segmentation mask. Ideally the segmentation mask should only contain one to four
dominant components: from one hand area up to four finger areas, respectively. The method also checks the size
and shape of segmented areas.

• A free positioning of the fingers without guidelines or
framing.
• A fully automated capturing and processing with an
integrated quality assessment and user feedback.
The whole capturing and processing pipeline discussed
in this section is made publicly available2 .
3.1. Capturing
The vast majority of mobile touchless recognition
schemes rely on state-of-the-art smartphones as capturing
devices. Smartphones offer a high-resolution camera unit, a
powerful processor, an integrated user feedback via display
and speaker, as well as a mobile internet connection for
on-demand comparison against centrally stored databases.
In our case, the capturing as well as the processing is
embedded in an Android App. Once the recognition process is started the application analyzes the live-view image
and automatically captures a finger image if the quality parameters fit the requirements. During capturing the user is
able to see his/her fingers through a live-view on the screen
and is able to adjust the finger position. In addition, the
capturing progress is displayed.

3.3. Rotation Correction, Fingertip Detection and Normalization
The rotation correction transforms every finger image
in a way that the final fingerprint image is oriented in an
upright position.
Figure 3 presents an overview of the rotation correction,
fingertip detection and normalization. Our method features two rotation steps: First a coarse rotation on the full
hand and second a fine rotation on the separated finger. A
robust separation and identification of the fingers requires
that the hand is rotated to an upright position. Here the
image border of the binary segmentation mask is analyzed.
Many white border pixels indicate that the hand is placed
into the sensor area from this particular direction. For this
reason, we search for the border area with the most white

3.2. Segmentation of the Hand Area
Proposed strategies for the segmentation mainly rely on
color and contrast. Many works use color models for segmenting the hand color from the background. Here an
2 Source code will be made available at: https://gitlab.com/
jannispriesnitz/mtfr

3

Figure 4: Detailed workflow of the coarse rotation correction.

Figure 5: Overview of gray-scale conversion, application of CLAHE and cropping of the fingerprint Region Of Interest (ROI). This process is
executed on every separated finger.

pixels and calculate a rotation angle from this coordinate.
Figure 4 illustrates this method.
After the coarse rotation the fingertips are separated.
To this end, the amount of contours of considerable size
is compared to a pre-configured value. If there are fewer
contours than expected it is most likely that the finger
images contain part of the palm of the hand. In this case
pixels are cut out from the bottom of the image and the
sample is tested again. In the case of more considerable
contours, the finger image is discarded in order to avoid
processing wrong finger-IDs.
An upright rotated hand area does not necessarily mean
that the fingers are accurately rotated because fingers can
be spread. A fine rotation is computed on every finger image to correct such cases. Here, a rotated minimal rectangle is placed around every dominant contour. This minimal
rectangle is then rotated into an upright position.
Additionally, the hight of each finger image needs to be
reduced to the area which contains the fingerprint impression. Other works have proposed algorithms which search
for the first finger knuckle [22, 23]. We implemented a simpler method which cuts the hight of the finger image to
the double of its width. In our use case this method leads
to slightly less accurate result but is much more robust
against outliers.
Touchless fingerprint images captured in different sessions or processed by different workflows do not necessarily
have the same size. The distance between sensor and finger
defines the scale of the resulting image. For a minutiaebased comparison it is crucial that both samples have the
same size. Moreover, in a touchless-to-touch-based interoperability scenario the sample size has to be aligned to
the standardized resolution, e.g. 500dpi. Therefore, we
normalize the fingerprint image to a width of 300px. This
size approximately corresponds to the size touch-based fingerprints captured with 500dpi.
Together with the information which hand is captured,
an accurate rotation correction also enables a robust identification of the finger ID, e.g. index, middle, ring or pinky

finger.
3.4. Fingerprint Processing
The pre-processed fingerprint image is aligned to resemble the impression of a touch-based fingerprint. Figure 5
presents the conversion from a finger image to a touchless
fingerprint. We use the Contrast Limited Adaptive Histogram Equalization (CLAHE) on a gray scale converted
fingerprint image to emphasize the ridge-line characteristics.
Preliminary experiments showed that the used feature
extractor detects many false minutiae at the border region
of touchless fingerprint samples. For this reason, we crop
approx. 15 pixel of the border region. That is, the segmentation mask is dilated in order to reduce the size of the
fingerprint image.
3.5. Quality Assessment
Quality assessment is a crucial task for touch-based
and touchless fingerprint recognition schemes. We distinguish between two types of quality assessment: An integrated plausibility check at certain points of the processing
pipeline and a quality assessment on the final sample.
The integrated plausibility check is an essential precondition for a successful completion of an automated recognition scheme. It ensures that only samples which passed
the check of a processing stage are handed over to the next
stage. In the proposed pre-processing pipeline we implement three plausibility checks:
• Segmentation: Analysis of the dominant components
in the binary mask. Here the amount of dominant
contours as well as their shape, size and position are
analyzed. Also, the relative positions to each other are
inspected.
• Capturing: Evaluation of the fingerprint sharpness. A
Sobel filter evaluates the sharpness of the processed
gray scale fingerprint image. A square of 32×32 pixels
at the center of the image is considered. A histogram
analysis then assesses the sharpness of the image.
4

(a) Box setup

(b) Tripod setup

(c) Touch-based capturing device

Figure 6: Capturing device setups during our experiments.

Table 2: Overview on selected recognition workflows with biometric performance.
Type
Setup
Device
Subjects captured
Rounds
Samples
Touchless
Box
Google Pixel 4
28
2
448
Touchless
Tripod
Huawei P20 Pro
28
2
448
Touch-based
–
Crossmatch Guardian 100
29
2
464

The combination of these plausibility checks has shown to
be robust and accurate in our processing pipeline. Every
sample passing all three checks is considered as a candidate for the final sample. For every finger ID five samples
are captured and processed. All five samples are finally assessed by NFIQ2.0 and the sample with the highest quality
score is considered as the final sample. An assessment on
the applicability of NFIQ2.0 on touchless fingerprint presented is shown in [24]. Especially for selecting the best
sample from a series of the same subject, NFIQ2.0 is wellsuited.

25

Amount of subjects

Amount of subjects

• Rotation, Cropping: Assessment of the fingerprint
size. The size of the fingerprint image after the cropping stage shows if the fingerprint image is of sufficient
quality.

20
15
10
5
0
Age
20 – 24
35 – 39

25 – 29
> 40

25
20
15
10
5
0
Skin color types

30 – 34

(a) Age distribution

1
4

2
5

3
6

(b) Skin color distribution

Figure 7: Distribution of age and skin color according to Fitzpatrick
metric [25] of the subjects.

to place their fingers freely. Secondly, a tripod-setup simulates a fully free capturing setup where the instructor or
the subject holds the capturing device 3 .
For the touchless database capturing we used two different Smartphones: the Huawei P20 Pro (tripod setup) and
the Google Pixel 4 (box setup). The finger images are captured with the highest possible resolution. The flashlight
was turned on during the capturing process by default.
Also, touch-based samples were captured to compare the
results of the proposed setup against an established system.
On every capturing device the four inner hand fingers (finger IDs 2 – 5 and 7 – 10 according to ISO/IEC 19794-4[26])
were captured. The capturing of with three capturing devices shown in Figure 6 was conducted in two rounds.
To measure the biometric performance of the proposed
system, we captured a database of 29 subjects. The age
and skin color distribution can be seen in Figure 7. Table 2 summarizes the database capturing method. During
the capturing of one subject, Failure-To-Acquire (FTA) errors according to ISO/IEC 19795-1 [27] occurred on both

3.6. Feature Extraction and Comparison
As mentioned earlier, the presented touchless fingerprint
processing pipeline is designed in a way that obtained fingerprints are compatible with existing touch-based minutiae extractors and comparators. This enables the application of existing feature extraction and comparator modules within the proposed pipeline and facilitates a touchbased-to-touchless fingerprint comparison. Details of the
employed feature extractor and comparator are provided
in Section 5.
4. Experimental Setup
To benchmark our implemented app we conducted a data
acquisition along with a usability study. Each volunteering
subject first participated in a data acquisition session and
then was asked to answer a questionnaire.
4.1. Database Acquisition

3 The capture subjects handled the capturing devices without interaction of the instructor. This simulates an unattended capturing
process and fulfilled the hygienic regulations during the database acquisition.

For the capturing of touchless samples two different setups were used: Firstly, a box-setup simulates a predictable
dark environment. Nevertheless, the subject was still able
5

Table 3: Overview on the NFIQ2.0 quality scores and the EER of all
captured fingers (finger IDs 2 – 5 and 7 – 10) separated by sensors.
Avg. NFIQ2.0
Capturing device
Subset
EER (%)
score
Touchless Box
all fingers
44.80 (± 13.51)
10.71
Touchless Tripod
all fingers
36.15 (± 14.45)
30.41
Touch-based
all fingers
38.15 (± 19.33 )
8.19

Touchless Box
Touchless Tripod
Touch-based

0.8

Touchless Box
Touchless Tripod
Touch-based

4

probability

0.6
FNMR

·10−2

5

1

0.4
0.2

Table 4: Overview on the NFIQ2.0 quality scores and the EER of
individual fingers: index fingers (IDs 2, 7), middle fingers (IDs 3, 8),
ring fingers (IDs 4, 9) and little fingers (IDs 5, 10).
Capturing
Avg. NFIQ2.0
EER
Fingers
device
score
(%)
Touchless Box
index fingers
53.16 (± 11.27)
7.14
Touchless Box
middle fingers
45.59 (± 11.06)
8.91
Touchless Box
ring fingers
41.57 (± 12.89)
7.14
Touchless Box
little fingers
38.88 (± 14.21)
21.43
Touchless Tripod
index fingers
41.38 (± 14.29)
21.81
Touchless Tripod
middle fingers
36.68 (± 13.01)
28.58
Touchless Tripod
ring fingers
34.68 (± 14.28)
29.62
Touchless Tripod
little fingers
31.79 (± 14.63)
38.98
Touch-based
index fingers
44.06 (± 17.53 )
8.62
Touch-based
middle fingers
41.08 (± 19.71 )
1.72
Touch-based
ring fingers
37.68 (± 17.08 )
6.90
Touch-based
little fingers
29.78 (± 19.94 )
13.79

3

2

1

0
0

0.2

0.4

0.6

0.8

FMR

(a) DET curves

1

0

0

20

40

60

80

100

NFIQ2.0 score

Table 5: Overview on the EER in a fingerprint fusion approach: Fusion over the 4 inner-hand fingers of the left hand (IDs 2 – 4) and
right hand (IDs 7 – 10) fusing and fusion over 8 fingers of both inner
hands (IDs: 2 – 4, 7 – 10).
Capturing device
Fusion approach
EER (%)
Touchless Box
4 fingers
5.36
Touchless Box
8 fingers
0.00
Touchless Tripod
4 fingers
21.42
Touchless Tripod
8 fingers
14.29
Touch-based
4 finger
2.22
Touch-based
8 finger
0.00

(b) Probability density functions
of NFIQ2.0 scores

Figure 8: NFIQ2.0 score distribution and biometric performance obtained from single finger comparisons.

touchless capturing devices. Interestingly, this was most
likely caused by the length of the subject’s fingernails. For
more information the reader is referred to Section 7.6. In
total, we captured and processed 1,360 fingerprints.

5. Results
4.2. Usability Study Design

This section presents the biometric performance achieved
by the entire recognition pipeline and the outcome of our
usability study.

A usability study was conducted with each subject after
they had interacted with the capturing devices. Each subject was asked about their individual preferences in terms
of hygiene and convenience during the capturing process.
Parts of our usability study are based on [28, 14]. We ensured that the questionnaire is as short and formulated as
clearly as possible such that the participants understood
all question correctly [29].
The questionnaire is provided as supplemental material.
It contains three parts: The first part contains questions
about the subject’s personal preferences. The Question
1.2b and 1.2c are aligned with Furman et al. [28]. Here the
different perceptions for personal hygiene before and during
the COVID-19 pandemic were asked. The answer options
of Question 1.5 were rated by the capture subjects using the
Rohrmann scale [30] (strongly disagree, fairly disagree, undecided, fairly agree, strongly agree). The questions were
intended to find out the subjects’ perception regarding hygienic concerns during the fingerprint capturing process.
The second part of the questionnaire contains questions
about the dedicated usability of a capturing device. The
same questions were answered by the subject for both devices. This part was designed so that the same questions for both capturing devices were asked separately from
each other in blocks. The intention behind this is to conduct comparisons between the different capturing devices.
Again, the Rohrman scale was used and sub-questions were
arranged randomly. In the last part of the questionnaire,
the subjects were asked about the personal preference between both capturing devices. Here, the subjects had to
choose one preferred capturing device.

5.1. Biometric Performance
In our experiments, we first estimate the distributions of
NFIQ2.0 scores for the captured data set. Additionally, the
biometric performance is evaluated employing open-source
fingerprint recognition systems. The features (minutiae
triplets – 2-D location and angle) are extracted using a
neural network-based approach. In particular, the feature
extraction method of Tang et al. [31] is employed. For this
feature extractor pre-trained models are made available by
the authors. To compare extracted templates, a minutiae
pairing and scoring algorithm of the sourceAFIS system of
Važan [32] is used4 .
In a first experiment, we compare the biometric performance on all fingers between the different sub data sets.
From the Table 3 we can see that the touchless box setup
obtains an Equal Error Rate (EER) of 10.71% which is
comparable to the touch-based setup (8.19%). Figure 8
(a) presents the corresponding Detection Error Trade-Off
(DET) curve whereas Figure 8 (b) shows the probability
density functions of NFIQ2.0 scores. In contrast, the performance of the open setup massively drops to an EER of
30.41%. The corresponding NFIQ2.0 scores do not reflect
4 The original algorithm uses minutiae quadruplets, i.e. additionally considers the minutiae type (e.g. ridge ending or bifurcation).
Since only minutiae triplets are extracted by the used minutiae extractors, the algorithm has been modified to ignore the type information.

6

1

1
Index
Middle
Ring
Little

0.8

0.8

0.2

0.6
FNMR

0.4

0.4
0.2

0
0.2

0.4

0.6

0.8

1

0.4
0.2

0
0

Index
Middle
Ring
Little

0.8

0.6
FNMR

0.6
FNMR

1
Index
Middle
Ring
Pinky

0
0

0.2

0.4

FMR

0.6

0.8

1

0

0.2

0.4

FMR

(a) Touchless box setup

0.6

0.8

1

FMR

(b) Touchless tripod setup

(c) Touch-based setup

avg.NFIQ2.0 Score

Figure 9: DET curves obtained from individual finger comparisons: index fingers (IDs 2, 7), middle fingers (IDs 3, 8), ring fingers (IDs 4, 9)
and little fingers (IDs 5, 10).

60

Table 6: Overview on the interoperability of different subset of the
collected data: Comparison of fingerprints captured with different setups. All captured fingers (finger IDs 2 – 5 and 7 – 10) are considered.
Device A
Device B
EER (%)
Touchless Box
Touchless Tripod
27.27
Touchless Box
Touch-based
15.71
Touchless Tripod
Touch-based
32.02

50
40
30
20
10
0
Crossmatch

Google Pixel 4

all fingers
ring fingers

index fingers
little fingers

Huawei P20 Pro
middle fingers

1
Touchless Tripod – Touch-based
Touchless Box – Touchless Tripod
Touchless Box – Touch-based

0.8
0.6
FNMR

Figure 10: Averaged NFIQ2.0 scores obtained from the considered
databases: average over all fingers (IDs 2 – 4, 6 – 10), index fingers
(IDs 2, 7), middle fingers (IDs 3, 8), ring fingers (IDs 4, 9) and little
fingers (IDs 5, 10).

0.4
0.2
0

1

1
Touchless Box
Touchless Tripod
Touch-based

0.8

0.8

0.4
0.2

0.4

0.6

0.8

1

Figure 12: DET curves obtained from the interoperability of different
subset of the collected data: Comparison of fingerprints captured with
different setups. All captured fingers (finger IDs 2 – 5 and 7 – 10) are
considered.

0.4
0.2

0

0.2

FMR

0.6
FNMR

FNMR

0.6

0

Touchless Box
Touchless Tripod
Touch-based

0
0

0.2

0.4

0.6

0.8

FMR

(a) Fusion over 4 fingers

1

0

0.2

0.4

0.6

0.8

1

the fusion improves the EER on all sub data sets. In particular, the fusion of 8 fingers shows a huge performance gain
(see Figure 11). The box setup and the touch-based sensor
show an EER of 0% which means that matches and nonmatches are completely separated. The open setup also
achieves a considerably high performance gain trough the
fusion. Here, the inclusion of all fingers makes the process
much more robust especially in challenging environmental
situations.
In our last experiment we analyze the interoperability
between the different subsets of the collected data. Table 6
summarizes the EERs achieved by comparing the samples
of different setups and Figure 12 presents the corresponding DET curves. The touchless box setup shows a good
interoperability to the touch-based setup (15.71%). The
EER of the open setup again significantly drops (27.27%
to touchless box and 32.02% to touch-based).
It should be noted, that all data sets, touchless as well as
touch-based show a biometric performance which is inferior
compared to the state-of-the-art. This is caused mainly by
two reasons: On the one hand, all data sets were captured
under realistic scenarios. The amount of instructions given
to the capturing subject were limited to a minimum. Further, no re-capturing of poor quality samples took place.
On the other hand, hygienic measures have an impact on

FMR

(b) Fusion over 8 fingers

Figure 11: DET curves obtained in a fingerprint fusion approach:
Fusion over the 4 inner-hand fingers of the left hand (IDs 2 – 4) and
right hand (IDs 7 – 10) fusing (a) and fusion over 8 fingers of both
inner hands (IDs: 2 – 4, 7 – 10) (b).

this drop in terms of EER. Here, all three data sets have a
comparable average score.
In a second experiment, we compute the biometric performance for every finger separately5 . From Table 4 and
Figure 9 we can see that on all subsets the performance of
the little finger drops compared to the other fingers. On
the touch-based sub data set the middle finger has a much
lower EER (1.72%) than the rest. This could be because
it might be easiest for users to apply the correct pressure
to the middle finger. From Figure 10 it is observable that
there is only a small drop of NFIQ2.0 quality scores on the
little finger.
Further we applied a score level fusion on 4 and 8 fingers.
Obtained EERs are summarized in Table 5. As expected,
5 In this experiment we consider only the same finger IDs from a
different subject as false match.

7

y
irl

ag
re
e
y

)

st

fa

(5

(4
)

(3
)

ro
ng
l

id
ed

un
de
c

y
irl
fa
)

(2

ag
re
e

ee

gr
ee

di
sa
gr

di
sa
ly
ng
ro
st
)
(1

No. 1.5a: I am generally skeptical about the fingerprint technology.
No. 1.5b: I generally have concerns about touching
surfaces in public places that are often touched by
other people.
No. 1.5c: I have major personal hygienic concerns
related to the Covid19 situation.

all test persons

re
e
re
e
st
)
(5

fa
i
)
(4

ro

rly

ng
ly

ag

ed
cid

ag

ee
(3

)

un

de

di
sa
gr

fa
irl
y

(2
)

(1
)

st

ro

ng

ly

di

sa

gr

ee

Figure 13: General assessment on fingerprint technology and hygienic concerns.

No. 2.1a: I think the fingerprint scanner was too
slow.
No. 2.1b: I found it hard to take the right position
for the recording process.
No. 2.1c: I found it hard to keep the position for the
recording process.
No. 2.1d: I always knew if the recording process was
in progress.
No. 2.1e: I would consider using this capturing device
in public places.
No. 2.1f: I found the recording process comfortable.
No. 2.1g: I have hygienic concerns about using the
capturing device.
touchless capturing device

touch-based capturing device

Figure 14: Usability assessment of the touchless and touch-based capturing device in comparison to each other.

biometric performance which is discussed in detail in Section 6.

lated to the COVID-19 pandemic (Statement 1.5c). From
the small difference in terms of perception before and during the COVID-19 pandemic it can be observed that the
pandemic has only a small influence on the general hygienic
awareness of the tested subjects.

5.2. Usability Study
We present the results of our usability study based on
the questionnaire introduced in Section 4.2. The questionnaire was answered by 27 subjects (8 female, 19 male).
The subjects were between 22 and 60 years old (average
age: 31.22 years, median age: 28 years). The age distribution is presented in Figure 7. The exact result in terms of
median and standard deviation is provided as supplemental
material. The majority of subjects have used professional
fingerprint scanners before this study. A large proportion
of the data subjects also use any type of fingerprint capturing device regularly at least once per week, e.g. to unlock
mobile devices.
Figure 13 presents the perceptions of the subjects regarding general hygiene. The subjects tend to have general concerns about touching surfaces in public places (Statement
1.5b). Moreover, the majority has personal concerns re-

The usability assessment of the touchless and touchbased capturing devices is presented in Figure 14. In most
statements, both capturing devices were rated fairly similar. The touchless capturing device has a slight advantage
in terms of capturing speed (Statement 2.1a). The touchbased capturing device tends to be rated better in taking
and keeping the capturing position during the whole process (Statements 2.1b and 2.1c). Also, the subjects found it
slightly easier to assess if the capturing process is running
(Statement 2.1d). Moreover, it can be observed that the
subjects highly prefer the comfort of the touchless device
(Statement 2.1f). Most notably, the subjects have much
less hygienic concerns using the touchless device in public
places (Statements 2.1.e and 2.1g). In these cases, a U-Test
[33] shows a two-sided significance with a level of α = 5%.
8

No. 3.1: Which sensor would you prefer
regarding its usability?
No. 3.2: Which type of sensor would
you prefer for hygiene reasons?
0 10 20 30 40 50 60 70 80 90 100
avg. approval in %
touch based sensor

touchless sensor

Figure 15: Comparative assessment of the capturing device type preference.

(a) Before COVID-19

(b) During COVID-19

(c) Finger image

(d) Touchless sample

Figure 16: Four samples of the same subject: Sample (a) was captured before the COVID-19 pandemic using a touch-based capturing device
whereas samples (b – d) were captured during the COVID-19 pandemic. Sample (a) and (b) were captured with the same capturing device
whereas (c) and (d) are captured and processed using our method.

Figure 15 illustrates the comparative results. In a direct comparison of the different capturing device types the
advantage of hygiene outweighs the disadvantages of hand
positioning. The slight majority of subjects would prefer
the touchless capturing device over a touch-based one in
terms of general usability (Question 3.1). Considering hygienic aspects the vast majority would choose the touchless
capturing device over the touch-based one (Question 3.2).
This highly correlates to the assessment of hygienic concerns of the statement 1.5c.

moisture has a significant impact on the biometric performance of touch-based fingerprint recognition systems.
The authors tested five capturing devices with normal, wet
and dry fingers. Especially dry fingers have been shown to
be challenging. Also, medical studies have shown that a
frequent hand disinfection causes dermatological problems
[38, 39]. The disinfection liquids dry out the skin and cause
chaps in the epidermis and dermis.
Thus, we can infer that the regular hand disinfection
leads to two interconnected problems which reduce the
recognition performance: Dry fingers show low contrast
during the capturing due to insufficient moisture. In addition, disinfection liquids lead to chaps on the finger surface.
Figure 16 shows touch-based fingerprints captured before
the COVID-19 pandemic (a) and during the COVID-19
pandemic (b). Both samples were captured from the same
subject using the same capturing device. It is observable
that the sample (b) exhibits more impairments in the ridgeline pattern compared to sample (a). Moreover, the finger
image (c) clearly shows chaps in the finger surface which are
likely caused by hygienic measures. The processed touchless sample (d) shows these impairments, too.

6. Impact of the COVID-19 Pandemic on Fingerprint Recognition
The accuracy of some biometric characteristics may be
negatively impacted by the COVID-19 pandemic. The pandemic and its related measures have no direct impact on the
operation of fingerprint recognition. Nevertheless, there are
important factors that may indirectly reduce the recognition performance and user acceptance of fingerprint recognition.

Table 7 summarizes the biometric performance achieved
on different databases using the proposed recognition
pipeline. We can see that the biometric performance on
the fingerprint subcorpus of the MCYT bimodal database
[34] and the Fingerprint Verification Contest 2006 (FVC06)

6.1. Impact of Hand Disinfection on Biometric Performance
The biometric performance drops due to dry and worn
out fingertips. Olsen et al. [37] showed that the level of
9

Table 7: Average NFIQ2.0 scores and biometric performance obtained from touchless and touch-based databases including the fingerprint
subcorpus of the MCYT Database [34], the FVC2006 Database [35], the Hong Kong Polytechnic University Contactless 2D to Contact-based
2D Fingerprint Images Database Version 1.0 [36].
Database
Subset
Avg. NFIQ2.0 score
EER (%)
dp
37.58 (±15.17)
0.48
MCYT
pb
33.02 (±13.99)
1.35
FVC06
DB2-A
36.07 (±9.07)
0.15
Contactless Session 1
47.71 (±10.86)
3.91
PolyU
Contactless Session 2
47.08 (±13.21)
3.17
Touch-based
38.15 (± 19.33 )
8.19
Our database
Touchless Box
44.80 (± 13.51)
10.71

[35] show a good performance. Moreover, the touchless subset of the Hong Kong Polytechnic University Contactless
2D to Contact-based 2D Fingerprint Images Database Version 1.0 (PolyU) [36] shows an competitive performance of
3.50% EER. Compared to these baselines the performance
achieved on our database is inferior which is most likely the
impact of the unconstrained acquisition scenario as well as
the use of hand disinfection measures.

ages. This requires a more elaborated processing but has
two major advantages:
• Faster and more accurate recognition process: Due to
a larger proportion of finger area in the image, focusing
algorithms work more precisely. This results in less
miss-focusing and segmentation issues.
• Improved biometric performance: The direct capturing of four fingerprints in one single capturing attempt
is highly suitable for biometric fusion. As show in Table 5 this lowers the EER without any additional capturing and very little additional processing.

6.2. User Acceptance
Viruses, e.g. SARS-CoV-2, have four main transmission
routes: droplet, airborne, direct contact, and indirect contact via surfaces. In the last case an infected individual
contaminates a surface by touching it. A susceptible individual who touches the surface afterwards has a high risk of
infection via this indirect transmission route. Otter et al.
[40] present an overview on the transmission of different
viruses (including SARS coronaviruses) via dry surfaces.
The authors conclude that SARS coronaviruses can survive for extended periods on surfaces and for this reason
form a high risk of infection.
Especially in large scale implementations e.g. the Schengen Entry/Exit System (EES) [41] were many individuals
touch the surface of a capturing device, the users are exposed to a major risk of infection. The only way of a safe
touch-based fingerprint recognition in such application scenarios is to apply a disinfection of the capturing device after
every subject.
Nevertheless, the requirement of touching a surface can
lower the user acceptance of touch-based fingerprint recognition. The results of our usability studies in Subsection 5.2
show that the asked individuals are fairly skeptical about
touching capturing device surfaces in public places and
that (in a direct comparison) they would prefer a touchless
capturing device. For this reason the touchless capturing
schemes could lead to a higher user acceptance. However,
it should be noted that our tested group was very small
and user acceptance is dependent to the capturing device
design.

However, a major obstacle for touchless schemes is to
capture the thumbs accurately and conveniently. In most
environments, the best results are achieved with the innerhand fingers facing upwards. This is ergonomically hard to
achieve with thumbs.
7.2. Automatic Capturing and On-Device Processing
State-of-the-art smartphones feature powerful processing
units which are capable to execute the described processing
pipeline in a reasonable amount of time. We have shown
that a robust and convenient capturing relies on an automatic capturing with integrated plausibility checks. Also,
the amount of data which has to be transferred to a remote
recognition workflow is reduced by an on-device processing
and the recognition workflow can be based on standard
components.
Especially in a biometric authentication scenario, it can
be beneficial to integrate the feature extraction and comparison into the mobile device. In this case, an authentication of a previously enrolled subject can be implemented
on a stand-alone device.
7.3. Environmental Influences
Touchless fingerprint recognition in unconstrained environmental situations may be negatively affected by varying and heterogeneous influences. In our experiments, we
showed that our touchless setup performs rather good under a semi-controlled environment. The performance of
the same recognition pipeline drastically drops in an uncontrolled environment. Here, it is observable that different stages of the processing pipeline suffer from challenging
environments:

7. Implementation Aspects
This section summarizes aspects which are considered
beneficial for a practical implementation.
7.1. Four-Finger Capturing

• Focusing of the hand area needs to be very accurate
and fast in order to provide sharp finger images. Here,
a focus point which is missed by a few millimeters
causes a blurred and unusable image. Figure 17(a, d)

As it has been shown in previous works, our proposed
recognition pipeline demonstrates that it is possible to process four fingerprints from a continuous stream of input im10

(a) Sharpness assessment input

(b) Segmentation input

(c) CLAHE input

(d) Sharpness assessment result

(e) Segmentation result

(f) CLAHE result

Figure 17: Illustration of accurate and challenging input images and corresponding result images for sharpness assessment (a, d), segmentation
(b, e) and contrast adjustment (c, f). The left images of each block represent an accurate images the right one a challenging one.

illustrate the difference between a sharp finger image
and a slightly de-focused image with help of a Sobel
filter. Additionally, the focus has to follow the hand
movement in order to achieve a continuous stream of
sharp images. The focus of our tested devices tend to
fail under challenging illuminations which was not the
case in the constrained environment.
• Segmentation, rotation and finger separation rely on
a binary mask in which the hand area is clearly separated from the background. Figure 17(b, e) show examples of a successful and unsuccessful segmentation.
Impurities in the segmentation mask lead to connected
areas between the fingertips and artifacts at the border
region of the image. This causes inaccurate detection
and separation of the fingertips and incorrect rotation
results. Because of heterogeneous background this in
more often the case in unconstrained setups.

Figure 18: Illustration of a minutiae-based comparison of two touchless fingerprint samples. The features are extracted using the method
described in Section 4. The blue lines indicate mated minutiae.

• Finger image enhancement using the CLAHE algorithm normalizes dark and bright areas on the finger
image. From Figure 17(c, e) we can see that this also
works on samples of high contrast. Nevertheless, the
results on challenging images may become more blurry.

e.g. by changing the focusing method or segmentation
scheme. This approach could lead to more robustness and
hence improved usability in different environments.
7.4. Feature Extraction Strategies

The discussed challenges lead to a longer capturing time
and for this reason lower the usability and user acceptance.
Further, the recognition performance in unconstrained environments is limited. Here, a weighing between usability
and performance should be done based on the intended use
case of the capturing device. The quality assessments implemented in our scheme detect these circumstances and
discard finger images with said shortcomings. More elaborated methods could directly adapt to challenging images,

Feature extraction techniques are vital to achieve a high
biometric performance. In our experiments, we used an
open-source feature extractor which is able to process
touch-based and touchless samples. Figure 18 shows an
example of this minutiae-based feature extraction and comparison scheme. With this method we were able to test the
interoperability between capturing device types. Nevertheless, the overall performance may be improved by more so11

phisticated methods, e.g. commercial of-the-shelf-systems
like the VeriFinger SDK [42].
Touchless fingerprint images do not correspond to the
standardized 500dpi resolution of touch-based capturing
devices because of a varying distance between capturing
device and finger. Here a feature extractor which is robust
against these resolution differences or a dedicated processing step is beneficial.
Also, dedicated touchless feature extraction methods can
increase the performance as shown in [11, 43]. Here the authors are able to tune their feature extractor to their capturing and processing and propose an end-to-end recognition system.

The presented usability study shows that the majority
of users prefer a touchless recognition system over a touchbased one for hygienic reasons. Also, the usability of the
touchless capturing device was seen as slightly better. Nevertheless, the user experience of the tested touchless devices
can be further improved.
The COVID-19 pandemic also has an influence on the
performance and acceptance of fingerprint recognition systems. Here hygienic measures lower the recognition performance and users are more concerned touching surfaces in
public areas.
Our proposed method forms a baseline for a mobile automatic touchless fingerprint recognition system and is made
publicly available. Researchers are encouraged to integrate
their algorithms into our system and contribute to an more
accurate, robust and secure touchless fingerprint recognition scheme.

7.5. Visual Instruction
According to the presented results in Subsection 5.2, the
visual feedback of the touchless capturing device have also
been rated to be inferior compared to the touch-based one.
Here the smartphone display is well-suited to show further
information about the capturing process. Additionally, an
actionable feedback can be given on the positioning of the
fingers, as suggested in [12].

Acknowledgments
The authors acknowledge the financial support by the
Federal Ministry of Education and Research of Germany
in the framework of MEDIAN (FKZ 13N14798). This research work has been partially funded by the German Federal Ministry of Education and Research and the Hessian
Ministry of Higher Education, Research, Science and the
Arts within their joint support of the National Research
Center for Applied Cybersecurity ATHENE.

7.6. Robust Capturing of different Skin Colors and Finger
Characteristics
An important implementation aspect of biometric systems is that they must not discriminate certain user groups
based on skin color or other characteristics. During our
database capturing subjects of different skin color types
were successfully captured. Nevertheless, it must be noted
that the amount of subjects is too small to make a general
statement about the fairness of the presented approach.
As already mentioned in Section 4.1, we observed one
single failure to acquire (FTA) during our database acquisition. Most likely the cause for this was that the subject
had very long fingernails which were segmented as finger
area. Here the plausibility check during the segmentation
failed and a capturing of the subject was not possible. To
overcome this flaw a fingernail detection could be implemented in the segmentation workflow.

References
[1] K. Okereafor, I. Ekong, I. Okon Markson, K. Enwere, Fingerprint Biometric System Hygiene and the Risk of COVID19 Transmission, JMIR Biomedical Engineering 5 (1) (2020)
e19623. doi:10.2196/19623.
URL http://biomedeng.jmir.org/2020/1/e19623/
[2] B. Y. Hiew, A. B. J. Teoh, Y. H. Pang, Digital camera based
fingerprint recognition, in: International Conference on Telecommunications and Malaysia International Conference on Communications, 2007, pp. 676–681.
[3] V. Piuri, F. Scotti, Fingerprint Biometrics via Low-cost capturing devices and Webcams, in: Second International Conference
on Biometrics: Theory, Applications and Systems (BTAS), 2008,
pp. 1–6.
[4] L. Wang, R. H. A. El-Maksoud, J. M. Sasian, W. P. Kuhn,
K. Gee, V. S. Valencia, A novel contactless aliveness-testing (cat)
fingerprint capturing device, in: Novel Optical Systems Design
and Optimization XII, Vol. 7429, 2009, p. 742915.
[5] A. Kumar, Y. Zhou, Contactless fingerprint identification using level zero features, in: Conference on Computer Vision and
Pattern Recognition Workshops (CVPRW), 2011, pp. 114–119.
[6] M. O. Derawi, B. Yang, C. Busch, Fingerprint recognition with
embedded cameras on mobile phones, in: Security and Privacy in
Mobile Information and Communication Systems (ICST), 2012,
pp. 136–147.
[7] D. Noh, H. Choi, J. Kim, Touchless capturing device capturing
five fingerprint images by one rotating camera, Optical Engineering 50 (11) (2011) 113202.
[8] C. Stein, V. Bouatou, C. Busch, Video-based fingerphoto recognition with anti-spoofing techniques with smartphone cameras,
in: International Conference of the Biometric Special Interest
Group (BIOSIG), 2013, pp. 1–12.
[9] R. Raghavendra, K. B. Raja, J. Surbiryala, C. Busch, A low-cost
multimodal biometric capturing device to capture finger vein and
fingerprint, IEEE International Joint Conference on Biometrics
(2014) 1–7.
[10] K. Tiwari, P. Gupta, A touch-less fingerphoto recognition system
for mobile hand-held devices, in: International Conference on
Biometrics (ICB), 2015, pp. 151–156.

8. Conclusion
In this work, we proposed a fingerprint recognition workflow for state-of-the-art smartphones. The method is able
to automatically capture the four inner-hand fingers of a
subject and process them to separated fingerprint images.
With this scheme we captured a database of 1,360 fingerprints from 29 subjects. Here we used two different setups:
a box setup with constrained environmental influences and
a tripod setup. Additionally, we captured touch-based fingerprints as baseline. During a usability study after the
capturing the subjects were asked about their experience
with the different capturing device types.
Our investigations show that the overall biometric performance of the touchless box setup is comparable to the
touch-based baseline whereas the unconstrained touchless
tripod setup shows inferior results. All setups benefit from
a biometric fusion. A further experiment on the interoperability between touchless and touch-based samples (box
setup) shows that the performance drops only slightly.
12

[11] A. Sankaran, A. Malhotra, A. Mittal, M. Vatsa, R. Singh, On
smartphone camera based fingerphoto authentication, in: 7th International Conference on Biometrics Theory, Applications and
Systems (BTAS), 2015, pp. 1–7.
[12] L. A. Carney, J. Kane, J. F. Mather, A. Othman, A. G. Simpson, A. Tavanai, R. A. Tyson, Y. Xue, A multi-finger touchless
fingerprinting system: Mobile fingerphoto and legacy database
interoperability, in: 4th International Conference on Biomedical
and Bioinformatics Engineering (ICBBE), 2017, p. 139–147.
[13] D. Deb, T. Chugh, J. Engelsma, K. Cao, N. Nain, J. Kendall,
A. K. Jain, Matching fingerphotos to slap fingerprint images,
arXiv preprint arXiv:1804.08122 (2018).
[14] A. Weissenfeld, B. Strobl, F. Daubner, Contactless finger and
face capturing on a secure handheld embedded device, in:
2018 Design, Automation Test in Europe Conference Exhibition
(DATE), 2018, pp. 1321–1326.
[15] P. Birajadar, M. Haria, P. Kulkarni, S. Gupta, P. Joshi,
B. Singh, V. Gadre, Towards smartphone-based touchless fingerprint recognition, Sādhanā 44 (7) (2019) 161.
[16] Y. Chen, G. Parziale, E. Diaz-Santana, A. K. Jain, 3d touchless fingerprints: compatibility with legacy rolled images, in:
Biometric Consortium Conference, 2006 Biometrics Symposium:
Special Session on Research at the, 2006, pp. 1–6.
[17] J. Priesnitz, C. Rathgeb, N. Buchmann, C. Busch, An overview
of touchless 2d fingerprint recognition, EURASIP Journal on
Image and Video Processing 2021 (2021) 25.
[18] B. Y. Hiew, A. B. J. Teoh, D. C. L. Ngo, Automatic Digital Camera Based Fingerprint Image Preprocessing, in: International
Conference on Computer Graphics, Imaging and Visualisation
(CGIV), 2006, pp. 182–189.
[19] D. S. Sisodia, T. Vandana, M. Choudhary, A conglomerate technique for finger print recognition using phone camera captured
images, in: International Conference on Power, Control, Signals and Instrumentation Engineering (ICPCSI), 2017, pp. 2740–
2746.
[20] K. Wang, H. Cui, Y. Cao, X. Xing, R. Zhang, A preprocessing
algorithm for touchless fingerprint images, in: Biometric Recognition, 2016, pp. 224–234.
[21] A. Malhotra, A. Sankaran, A. Mittal, M. Vatsa, R. Singh, Chapter 6 - fingerphoto authentication using smartphone camera
captured under varying environmental conditions, in: Human
Recognition in Unconstrained Environments, 2017, pp. 119 –
144.
[22] R. Raghavendra, C. Busch, B. Yang, Scaling-robust fingerprint
verification with smartphone camera in real-life scenarios, in:
Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), 2013, pp. 1–8.
[23] C. Stein, C. Nickel, C. Busch, Fingerphoto recognition with
smartphone cameras, in: International Conference of Biometrics
Special Interest Group (BIOSIG), 2012, pp. 1–12.
[24] J. Priesnitz, C. Rathgeb, N. Buchmann, C. Busch, Touchless
fingerprint sample quality: Prerequisites for the applicability of
nfiq2. 0, in: International Conference of the Biometrics Special
Interest Group (BIOSIG), 2020, pp. 1–5.
[25] T. B. Fitzpatrick, The Validity and Practicality of Sun-Reactive
Skin Types I Through VI, Archives of Dermatology 124 (6)
(1988) 869–871.
[26] ISO, ISO/IEC 19794-4:2011: Information technology – Biometric data interchange formats – Part 4: Finger image data, Standard, International Organization for Standardization (2011).
[27] I. ISO, Iec 19795-1: Information technology–biometric performance testing and reporting-part 1: Principles and framework,
ISO/IEC, Editor 1 (3) (2006) 5.
[28] S. M. Furman, B. C. Stanton, M. F. Theofanos, J. M. Libert, J. D. Grantham, Contactless fingerprint devices usability
test, Tech. Rep. NIST IR 8171, National Institute of Standards and Technology, Gaithersburg, MD (Mar. 2017). doi:
10.6028/NIST.IR.8171.
URL https://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.
8171.pdf
[29] R. Porst, Fragebogen: ein Arbeitsbuch, 4th Edition, Studienskripten zur Soziologie, Springer VS, Wiesbaden, 2014, oCLC:
870294421.
[30] B. Rohrmann, Empirische Studien zur Entwicklung von
Antwortskalen für die sozialwissenschaftliche Forschung,
Zeitschrift für Sozialpsychologie 9 (3) (1978) 222–245.

[31] Y. Tang, F. Gao, J. Feng, Y. Liu, FingerNet: An unified deep
network for fingerprint minutiae extraction, in: International
Joint Conference on Biometrics (IJCB), IEEE, 2017, pp. 108–
116.
[32] R. Važan, SourceAFIS – opensource fingerprint matcher,
https://sourceafis.machinezoo.com/, last accessed: March 5,
2021(2019).
[33] H. B. Mann, D. R. Whitney, On a Test of Whether one of Two
Random Variables is Stochastically Larger than the Other, The
Annals of Mathematical Statistics 18 (1) (1947) 50–60.
URL www.jstor.org/stable/2236101
[34] J. Ortega-Garcia, J. Fierrez-Aguilar, D. Simon, J. Gonzalez,
M. Faundez-Zanuy, V. Espinosa, A. Satue, I. Hernaez, J. .
Igarza, C. Vivaracho, D. Escudero, Q. . Moro, Mcyt baseline
corpus: a bimodal biometric database, IEE Proceedings - Vision, Image and Signal Processing 150 (6) (2003) 395–401.
[35] R. Cappelli, M. Ferrara, A. Franco, D. Maltoni, Fingerprint verification competition 2006, Biometric Technology Today 15 (7-8)
(2007) 7–9.
[36] A. Kumar, The Hong Kong Polytechnic University Contactless
2D to Contact-based 2D Fingerprint Images Database Version
1.0 (2017).
URL
http://www4.comp.polyu.edu.hk/csajaykr/
fingerprint.htm
[37] M. A. Olsen, M. Dusio, C. Busch, Fingerprint skin moisture impact on biometric performance, in: 3rd International Workshop
on Biometrics and Forensics (IWBF 2015), 2015, pp. 1–6.
[38] K. A. O’Connell, C. W. Enos, E. Prodanovic, Case Report:
Handwashing-Induced Dermatitis During the COVID-19 Pandemic, American Family Physician 102 (6) (2020) 327–328.
[39] S. W. Tan, C. C. Oh, Contact Dermatitis from Hand Hygiene
Practices in the COVID-19 Pandemic, Annals of the Academy
of Medicine, Singapore 49 (9) (2020) 674–676.
[40] J. A. Otter, C. Donskey, S. Yezli, S. Douthwaite, S. D. Goldenberg, D. J. Weber, Transmission of SARS and MERS coronaviruses and influenza virus in healthcare settings: the possible
role of dry surface contamination, Journal of Hospital Infection
92 (3) (2016) 235–250.
[41] E. Union, Commission implementing decision (eu) 2019/329 of
25 february 2019 laying down the specifications for the quality,
resolution and use of fingerprints and facial image for biometric
verification and identification in the entry/exit system (ees), Official Journal of the European Union (2019) 18–28.
URL http://data.europa.eu/eli/dec_impl/2019/329/oj
[42] S. VeriFinger, Neuro Technology, VeriFinger, SDK Neuro Technology (2010).
[43] R. Vyas, A. Kumar, A Collaborative Approach using RidgeValley Minutiae for More Accurate Contactless Fingerprint Identification, arXiv:1909.06045 [cs, eess] (Sep. 2019).

13

