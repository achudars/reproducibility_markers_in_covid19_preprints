arXiv:2004.08052v2 [eess.IV] 4 May 2021

A M ODIFIED D EEP C ONVOLUTIONAL N EURAL N ETWORK FOR
D ETECTING COVID-19 AND P NEUMONIA FROM C HEST X- RAY
I MAGES BASED ON THE C ONCATENATION OF X CEPTION AND
R ES N ET 50V2

Mohammad Rahimzadeh
School of Computer Engineering
Iran University of Science and Technology, Iran
mr7495@yahoo.com
ORCID: 0000-0002-8550-8967
Corresponding author

Abolfazl Attar
Department of Electrical Engineering
Sharif University of Technology, Iran
attar.abolfazl@ee.sharif.edu
ORCID: 0000-0001-6727-432X

May 5, 2021

A BSTRACT
In this paper, we have trained several deep convolutional networks with the introduced training
techniques for classifying X-ray images into three classes: normal, pneumonia, and COVID-19, based
on two open-source datasets. Our data contains 180 X-ray images that belong to persons infected to
COVID-19, so we tried to apply methods to achieve the best possible results. In this research, we
introduce some training techniques that help the network learn better when we have an unbalanced
dataset(fewer cases of COVID-19 along with more cases from other classes). We also propose a
neural network that is a concatenation of Xception and ResNet50V2 networks. This network achieved
the best accuracy by utilizing multiple features extracted by two robust networks. For evaluating
our network, we have tested our network on 11302 images to report the actual accuracy our network
can achieve in real circumstances. The average accuracy of the proposed network for detecting
COVID-19 cases is 99.50%, and the overall average accuracy for all classes is 91.4%.
Keywords Deep learning · Convolutional Neural netwroks · COVID-19 · Coronavirus · Transfer Learning · deep
feature extraction · chest X-ray images

1

Introduction

The pervasive spread of the coronavirus around the world has quarantined many people and crippled many industries,
which has had a devastating effect on human life quality. So far, the coronavirus has killed at least 1.5 million patients
and at least 80,000 people [19]. Due to the high transmissibility of coronavirus, the detection of this disease (COVID-19)
plays an important role in controlling and planning to prevent it.
On the other hand, demographic conditions such as age and sex of individuals and many urban parameters such as
temperature and humidity affect the prevalence of this disease in different parts of the world, which is more effective in
spreading this disease [22, 21].
The lack of detective tools and the limitations in their production has slowed down the disease detection; as a result, it
increases the number of patients and casualties. The incidence of other diseases and the prevalence and the number of
casualties due to COVID-19 disease will decrease if it is detected quickly.
The first step is to get the detection, recognize the symptoms of the disease, and use distinctive signs to detect the
coronavirus accurately. Depending on the type of coronavirus, symptoms can range from symptoms of the common

A PREPRINT - M AY 5, 2021

cold to fever, cough, shortness of breath, and acute respiratory problems. The patient may also have a few days of
cough for no apparent reason[32].
Unlike SARS, coronavirus affects not only the respiratory system but also other vital organs in the body, such as the
kidneys and liver [18]. Symptoms of a new coronavirus leading to COVID-19 usually begin a few days after the person
becomes infected, where, in some people, the symptoms may appear a little later. According to [13, 36], Respiratory
problems are one of the main symptoms of COVID-19, which can be detected by the X-ray imaging of the chest. CT
scans of the chest can also show a disease that has mild symptoms, so analyzing these images can well detect the
presence of the disease in suspicious people and even without symptoms at first [29]. Using these data can also cover
the limitations of other tools, such as the lack of diagnostic kits and the limitations of their production. The advantage
of using CT scans and X-ray images is the availability of CT scan devices and x-ray imaging systems in most hospitals
and laboratories, and the ease of access to the data needed to train the network and thus detect the disease. In the
absence of common symptoms such as fever, the use of CT scans and X-ray images of the chest has a relatively good
ability to detect the disease [1].
The use of specialized human beings to diagnose the disease is a common method of detecting COVID-19 in laboratories.
In this method, the specialist uses the symptoms and injuries in the chest radiology image to detect COVID-19 disease
from a healthy person or person that suffering from other diseases. This procedure has costs and, most importantly,
long-term detection [13, 28].
In recent years, computer vision and Deep Learning have been used to detect many different diseases and lesions in the
body automatically [17].
Some examples are: Detection of tumor types and volume in lungs, breast, head and brain [3, 14], state-of-the-art bone
suppression in x-rays, diabetic retinopathy classification, prostate segmentation, nodule classification [17], skin lesion
classification, analysis of the myocardium in coronary CT angiography [40], sperm detection and tracking [24], etc.
Given that chest CT scan or X-ray images analysis is one of the methods of diagnosing COVID-19, the use of computer
vision and Deep Learning can play a beneficial role in diagnosing this disease. Since the disease became widespread,
many researchers have used machine vision and Deep Learning methods and obtained good results.
Due to the sensitivity of the Covid-19 diagnosis, the diagnosis’s accuracy is one of the main challenges we face in our
research. On the other hand, our focus is on increasing the detection efficiency due to the limited open-source data
available.
In this article, we try to improve COVID-19 detection and decreasing wrong COVID-19 detections. This is done by
combining two robust deep convolutional neural networks and optimizing the training parameters. Besides, we also
propose a method for training the network when the dataset is imbalanced.
In [1, 38], statistical analysis of CT scans was performed by several specialists and diagnosticians, who classified the
suspects into several classes for diagnosis and treatment.
Because of the superiority of computer vision and Deep Learning in the analysis of medical images, after the reliability
of CT scans of the chest for COVID-19 detection, the researchers used these tools to diagnose COVID-19. Immediately,
artificial intelligence began to detect the disease and measure the rate of infection and damage to the lungs using CT
scans and the course of the disease, with promising results [9].
IN [34], they have used an innovative CNN to classify and predict COVID-19 using lung CT scans. [9] has used
Deep Learning to detect COVID-19 and segment the lung masses caused by the coronavirus using 2D and 3D images.
COVID-Net uses a lightweight residual projection-expansion- projection-extension (PEPX) design pattern to investigate
quantitative analysis and qualitative analysis [33].In another research, pre-trained ResNet50, InceptionV3, and Inception
ResNetV2 models have used with transfer learning techniques to classify Chest X-ray images normal and COVID-19
classes [20]. In [15], they present COVNet for predict COVID-19 from CT scans that have segmented using U-net [25].
Another research has combined the Human-In-The-Loop(HITL) strategy that involved a group of chest radiologists
with deep learning-based methods to segment and measure infection in CT scans [26]. In [37], they have tried to detect
COVID-19 and Influenza-A-viral-pneumonia from their data; They have used classical ResNet-18 network structure to
extract the features, and another Innovative CNN network uses these features by creating the location-attention oriented
model to classify the data.
The paper is organized as follows: In Section 2, we describe the proposed neural network, the dataset, and training
techniques. In Section 3, we have presented the experimental results, and then the paper is discussed in Section 4. In
Section 5, we concluded our paper, and in 6, we presented the trained networks and the codes used in this research.

2

A PREPRINT - M AY 5, 2021

2
2.1

Methodology
Neural Networks

Deep convolutional neural networks have made a mutation in machine vision tasks. These layers have created advances
in many field like Agriculture [23], medical disease diagnosis [16, 35], industry [7]. The superiority of these networks
comes from the robust and valuable semantic features they generate from the input data. Here the main job of the deep
networks is detecting the infections and the kind of those in the X-ray images, so classifying the X-ray images into
normal, pneumonia or COVID-19. Some of the powerful and mostly used deep convolutional networks are VGG [27],
ResNet [10], DenseNet [12], Inception [31], Xception [4].
Xception is a deep convolutional neural network that introduced new inception layers. These inception layers are
constructed from depthwise separable convolution layers, followed by a point-wise convolution layer. Xception achieved
the third-best results on the ImageNet dataset [8] after InceptionresnetV2 [30] and NasNet Large [39]. ResNet50V2
[11] is a modified version of ResNet50 that performs better than ResNet50 and ResNet101 on the Imagenet dataset. In
ResNet50V2, a modification was made in the propagation formulation of the connections between blocks. ResNet50V2
also achieves a good result on the ImageNet dataset.
The pre-processed input images of our dataset are 300*300 pixels. Xception generates a 10*10*2048 feature map on its
last feature extractor layer from the input image, and ResNet50V2 also produces the same size of feature map on its
final layer. As both networks generate the same size of feature maps, we concatenated their features so that by using
both of the inception-based layers and residual-based layers, the quality of the generated semantic features be enhanced.
The concatenated neural network is designed by concatenating the extracted features of Xception and ResNet50V2 and
then connecting the concatenated features to a convolutional layer that is connected to the classifier. The kernel size
of the convolutional layer that was added after the concatenated features was 1*1 with 1024 filters and no activation
function. This layer was added to extract a more valuable semantic feature out of the features of a spatial point between
all the channels, which each channel is a feature map. This convolutional layer helps the network learn better from the
concatenated features extracted from Xception and ResNet50V2. The architecture of the concatenated network has
been depicted in figure 1.
Covid-19

Xpection
netwrok
Pneumonia

Concatenated
Features

10*10*2048

Parallel Deep
Feature Extractors

10*10*4096

Normal

Normal
Covid19
Pneumonia

Dropout
(50%)

ResNet50V2
Network
10*10*2048

Conv2D
Filters=1024
Kernel=(1,1)
With Padding
No activation
Flatted
Features
(102400)

Figure 1: The architecture of the concatenated network

3

Classifier
Activation:
Softmax

A PREPRINT - M AY 5, 2021

2.2

Dataset

We have used two open-source datasets in our work. The covid chestxray dataset is taken from this GitHub repository
(https://github.com/ieee8023/covid-chestxray-dataset), which has
been prepared by [6]. This dataset consists of X-ray and CT scan images of patients infected to COVID-19, SARS,
Streptococcus, ARDS, Pneumocystis, and other types of pneumonia from different patients.
In this dataset, we only considered the x-ray images, and in total, there were 180 images from 118 cases with COVID-19
and 42 images from 25 cases with Pneumocystis, Streptococcus, and SARS that were considered as pneumonia. The
second dataset was taken from (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge), which
contains 6012 cases with pneumonia, and 8851 normal cases. We combined these two datasets, and the details are listed
in table 1.

Table 1: Composition of the number of allocated images to training and validation set in both datasets

Dataset

COVID-19

Pneumonia

Normal

covid chestxray dataset

180

42

0

rsna pneumonia detection challenge

0

6012

8851

Total

180

6054

8851

Training Set

149

1634

2000

Validation Set

31

4420

6851

As stated, we only had 180 cases infected to COVID-19, which is almost a few data for a class compared to other
classes. If we had combined lots of images from normal or pneumonia classes with few COVID-19 images for training,
the network would become able to detect pneumonia and normal classes very well, but not the COVID-19 class because
of the unbalanced dataset. In that case, although the network can not identify COVID-19 properly, as there are many
more images of pneumonia and normal classes than the COVID-19 class, the general accuracy would become very high,
not the COVID-19 detection accuracy. This condition is not our goal because the main purpose here is to achieve good
results in detecting COVID-19 cases and not identifying wrong COVID-19 cases.
The best way to solve this problem is to make the dataset balanced and give the network almost equal data of each class
when training, so the network learn to identify all the classes. Here because we do not access more open-source datasets
of COVID-19 to increase this class data, we chose the number of pneumonia and normal classes almost equal to the
COVID-19 number of images.
We decided to train the networks for 8 consecutive phases. In each phase, we selected 250 cases of normal class and
234 cases of pneumonia class along with the 149 COVID-19 cases. In total, we had 633 cases for each training phase.
All the COVID-19 images and 34 of the pneumonia images were common between each training phase and 250 normal
cases, and 200 pneumonia cases were unique in each training phase. The common 149 COVID-19 and 34 pneumonia
cases between all the training phases were from the covid chestxray dataset [6], and the rest of the data were from the
other dataset. Based on this categorizing, our training set includes 8 phases and 3783 images.
By doing so, the network sees an almost equal number of images for each class, so it helps to improve the COVID-19
detection along detecting pneumonia and normal cases. But as we had more pneumonia and normal cases, we showed
the network different pneumonia and normal cases with COVID-19 cases in each phase. Implementing this method
results in two advantages. One is that the network learns COVID-19 class features better along with the other classes;
second, the normal and pneumonia classes’ detection improves very much. Better detecting pneumonia and normal
cases mean not detecting wrong COViD-19 cases, which is one of our goals. In another meaning running this method
helps the network better identify COVID-19 and not detect faulty COVID-19 cases.
This method can be used for all the circumstances that there is a highly unbalanced dataset. We presented our way of
allocating the images of the datasets into eight different phases in flowchart 3. Some of the images of our dataset are
shown in figure 2.
4

A PREPRINT - M AY 5, 2021

(a) normal persons

(b) Patients with COVID-19

(c) Patients with pneumonia

Figure 2: Examples of the images in our dataset

2.3

Training phase

We described in the dataset subsection 2.2 that we allocated 8 phases for training. For reporting more reliable results,
we chose five folds for training, which in every fold the training set was made of 8 phases as it is mentioned.
We have trained ResNet50V2 [11], Xception [4], and a concatenation of Xception and ResNet50V2 neural networks
based on the explained method. This concatenated Neural Network has shown higher accuracy comparing to the others.
5

A PREPRINT - M AY 5, 2021

rsna pneumonia
detection challenge

Training Set (T1):
2000 Normal
&
1600 PNEUMONIA
cases

covid chestxray
dataset

Validation Set (V1):
6851 Normal
&
4420 PNEUMONIA
cases

Training Set (T2):
149 COVID-19
&
34 PNEUMONIA
cases

Validation Set (V2):
31 COVID-19
&
8 PNEUMONIA
cases

Divide T1 to 8
different datasets
(D1,D2,...,D8)

Combine each of the
D1 to D8 with T2

8 different training
datasets
(DT1,DT2,...,DT8)
Select one
training dataset
from
(DT1,DT2,...,DT8)

Combine
V1 with V2

Final
Validation Set

Train on
the selected
training dataset

No

Trained
on all of the
training
datasets
Yes
Test the trained
network on the
ﬁnal validation Set

Results

Figure 3: The flowchart of the proposed method for training set preperation
6

A PREPRINT - M AY 5, 2021

As we have tested several networks in our project, the Xception [4] and ResNet50V2 [11] networks work almost better
than other ones in extracting deep features. By concatenating the output features of both networks, we helped the
network learn to classify the input image from both feature vectors, which resulted in better accuracy. The training
parameters have been described in table 2.
Based on table 2 we trained the networks using Categorical cross-entropy loss function and Nadam optimizer. The
learning rate was set to 1e-4. We trained the network for 100 epochs in each training phase and, because of having 8
training phases, the models were trained for 800 epochs. For the Xception and ResNet50V2, we selected the batch size
equal to 30. But as the concatenated network had more parameters than Xception and ResNet50V2, we set the batch
size equal to 20. Data augmentation methods were also implemented to increase training efficiency and prevent the
model from overfitting.
We implemented the neural networks with Keras [5] library on a Tesla P100 GPU and 25GB RAM that were provided
by Google Colaboratory Notebooks.
Table 2: In this table, we have listed the parameters and functions we used in the training procedure.
Training Parameters

Xception

ResNet50V2

Concatenated
Network

Learning Rate

1e-4

1e-4

1e-4

Batch Size

30

30

20

Optimizer

Nadam

Nadam

Nadam

Categorical

Categorical

Categorical

Crossentopy

Crossentopy

Crossentopy

100

100

100

Yes

Yes

Yes

Zoom Range

5%

5%

5%

Rotation Range

0 - 360 degree

0 - 360 degree

0 - 360 degree

5%

5%

5%

Shift Range

5%

5%

5%

Re-scaling

1/255

1/255

1/255

Loss Function
Epochs per each
Training Phase
Horizontal/Vertical
flipping

Width / Height
Shifting

3

Results

We validated our networks on 31 cases of COVID-19, 4420 cases of pneumonia, and 6851 normal cases. The reason
our training data was less than validation data is that we had a few cases of COVID-19 among lots of normal and with
pneumonia cases. Therefore, we could not use lots of images of the two other classes with COVID-19 fewer cases for
training because it would have made the network not to learn COVID-19 features. To solve this issue, we selected 3783
images for training in 8 different phases. We evaluated our network on the rest of the data so that our trained network’s
ultimate performance be clear. It must be noticed that exceptionally, in the fold3, we had 30 cases of COVID-19 for
validation, and 150 other cases were allocated for training.
It is noteworthy that we used transfer learning in training precess. For all the networks, we used the pre-trained
ImageNet weights [8] at the beginning of the training and then resumed training based on the explained conditions on
our dataset. We also used the accuracy metric for monitoring the network results on the validation set after each epoch
to find the best and most converged version of the trained network.
7

A PREPRINT - M AY 5, 2021

The evaluation results of the neural networks are presented in figure 4 that shows the confusion matrices of each network
for fold one and three. Table 3 and table 4 show the details of our results. We reported the four different metrics for
evaluating our network for each of the three class as follows:
Accuracy (f or each class) =

TP + TN
TP + FP + TN + FN

(1)

Specif icity =

TN
TN + FP

(2)

sensitivity =

TP
TP + FN

(3)

P recision =

TP
TP + FP

(4)

We also reported the overall accuracy metric, defined as:
Accuracy (f or all the classes) =

N umber of Correct Classif ied Images
N umber of All Images

(5)

In these equations, T P (True Positive) is the number of correctly classified images of a class, F P (False Positive) is the
number of the wrong classified images of a class, F N (False Negative) is the number of images of a class that have
been detected as another class, and T N (True Negative) is the number of images that do not belong to a class and did
not be classified as that class.
Table 3: This table reports the number of true and false positives and false negatives for each class

Fold

1

2

3

4

5

COVID-19

COVID-19

COVID-19

PNEUMONIA

PNEUMONIA

PNEUMONIA

NORMAL

NORMAL

NORMAL

Correct

Not

Wrong

Correct

Not

Wrong

Correct

Not

Wrong

detected

detected

detected

detected

detected

detected

detected

detected

detected

Xception

26

5

101

3983

437

569

6245

606

378

ResNet50V2

27

4

96

3858

562

480

6334

517

507

Concatenated

26

5

68

3745

675

309

6526

325

628

Xception

23

8

42

3874

546

409

6426

425

528

ResNet50V2

22

9

67

3659

761

501

6340

511

713

Concatenated

23

8

27

3913

507

434

6413

438

492

Xception

21

9

28

3942

478

436

6411

440

463

ResNet50V2

22

8

97

3770

650

392

6433

418

587

Concatenated

25

5

35

3847

573

342

6502

349

550

Xception

22

9

42

3818

602

433

6411

440

576

ResNet50V2

22

9

78

4015

405

758

6065

786

364

Concatenated

26

5

77

3860

560

480

6340

511

519

Xception

21

10

41

4041

379

502

6335

516

362

ResNet50V2

21

10

42

3604

816

284

6549

302

802

Concatenated

24

7

43

3941

479

390

6442

409

462

Network

8

A PREPRINT - M AY 5, 2021

Confusion Matrix for the concatenated network-fold1

NORMAL

6526

307

18

376

3983

61

NORMAL

6245

566

40

AL
NO
RM

PN

CO
VID

Predicted Label

Predicted Label

(a) Concatenated network-Fold1

(b) Xception-Fold1

56

NORMAL

6334

477

40

547

3847

26

NORMAL

6502

340

9

RM

AL

-19

PN
EU

NO

VID
CO

Predicted Label

Predicted Label

(c) ResNet50V2-Fold1

(d) Concatenated network-Fold3

Confusion Matrix for Xception-fold3

NORMAL

6411

430

10

584

3770

66

NORMAL

6433

387

31

RM

AL

19
CO

NO

VID
-

ON
PN
E

UM

AL
RM
NO

Ground Truth Label

PNEUMONIA

Predicted Label

19

18

VID
-

3942

22

CO

460

5

IA

PNEUMONIA

3

COVID-19

ON

21
Ground Truth Label

6

IA

3

COVID-19

Confusion Matrix for ResNet50V2-fold3

UM

PN
EU

NO

MO

RM

AL

Ground Truth Label

PNEUMONIA

-19

3858

25

VID

506

2

CO

PNEUMONIA

3

COVID-19

MO

27
Ground Truth Label

3

NIA

1

COVID-19

Confusion Matrix for the concatenated network-fold3

NIA

Confusion Matrix for ResNet50V2-fold1

PN
E

PN

EU

NO
RM

AL

Ground Truth Label

PNEUMONIA

-19

50

CO
VID

3745

26

MO
NIA

625

3

EU

PNEUMONIA

2

COVID-19
Ground Truth Label

26

-19

2

MO
NIA

3

COVID-19

Confusion Matrix for Xception-fold1

Predicted Label

(e) Xception-Fold3

(f) ResNet50V2-Fold3

Figure 4: This figure shows the confusion matrix of the network for fold 1 and 3

9

A PREPRINT - M AY 5, 2021

Table 4: Some of the evaluation metrics have been reported in this table.
Fold

Network

1

2

3

4

5

Average

4

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

sensitivity

sensitivity

sensitivity

Specificity

Specificity

Specificity

Accuracy

Accuracy

Accuracy

Precision

Precision

Precision

Accuracy

Xception

90.72

83.87

90.11

91.15

99.1

91.73

91.51

99.06

91.10

91.29

20.47

87.50

94.29

ResNet50V2

90.41

87.09

87.28

92.45

99.15

93.03

88.61

99.12

90.78

90.94

21.95

88.93

92.58

Concatenated

91.10

83.87

84.72

95.25

99.4

95.51

85.89

99.35

91.29

91.57

27.65

92.37

91.22

Xception

91.33

74.19

87.64

93.79

99.63

94.06

88.14

99.56

91.55

91.57

35.38

90.45

92.40

ResNet50V2

88.66

70.96

82.78

92.54

99.41

92.72

83.98

99.33

88.83

89.17

24.71

87.95

89.89

Concatenated

91.56

74.19

88.52

93.60

99.76

93.69

88.95

99.69

91.67

91.77

46

90.01

92.87

Xception

91.79

70

89.18

93.57

99.75

93.66

89.6

99.67

91.91

92.01

42.85

90.04

93.26

ResNet50V2

90.47

73.33

85.29

93.89

99.14

94.30

86.81

99.07

90.78

91.11

18.48

90.58

91.63

Concatenated

91.79

83.33

87.03

94.90

99.69

95.03

87.64

99.65

91.90

92.04

41.66

91.83

92.20

Xception

90.70

70.96

86.38

93.57

99.63

93.71

87.06

99.55

90.84

91.01

34.37

89.81

91.75

ResNet50V2

89.38

70.96

90.83

88.52

99.31

88.99

91.82

99.23

89.71

89.82

22

84.11

94.33

Concatenated

90.47

83.87

87.33

92.54

99.32

93.03

88.34

99.27

90.8

90.89

25.24

88.94

92.43

Xception

91.99

67.74

91.42

92.46

99.64

92.71

91.87

99.55

92.20

92.23

33.87

88.95

94.59

ResNet50V2

90.01

67.74

81.53

95.59

99.63

95.87

81.98

99.54

90.27

90.23

33.33

92.69

89.08

Concatenated

92.08

77.41

89.16

94.03

99.62

94.33

89.62

99.56

92.31

92.29

35.82

90.99

93.30

Xception

91.31

73.35

88.95

92.91

99.55

93.17

89.63

99.48

91.52

91.62

33.39

89.35

93.26

ResNet50V2

89.79

74.02

85.54

92.60

99.33

92.98

86.64

99.26

90.07

90.25

24.09

88.85

91.50

Concatenated

91.40

80.53

87.35

94.06

99.56

94.32

88.09

99.50

91.60

91.71

35.27

90.83

92.40

Discussion

It can be understood from the confusion matrices and the tables that the concatenated network performs better in
detecting COVID-19 and not detecting false cases of COVID-19 and outputs better overall accuracy. Although we
had an unbalanced dataset and a few cases of COVID-19, by using the proposed technique, we could have improved
COVID-19 detection along with the other classes detection. The reason the precision of COVID-19 class is low is that
in our work, despite some other researches that worked on detecting COVID-19 from X-ray images, we tested our
neural nets on a massive number of images. Our test images were much more than our train images. As it is explained
above, because we had only 31 cases of COVID-19 and 11271 cases from the other two classes, the false positives of
the COVID-19 class would become more than true positives. For example, in the first fold, the concatenated network
detected 26 cases correctly out of 31 COVID-19 cases, and from 11271 other cases, only mistakenly identify 68 cases
as COVID-19. If we had equal samples from COVID-19 class as the other classes, the precision would become high
value. Still, because having few COVID-19 cases and lots of other cases for validation, the precision would become a
low value.
In another study, the results were presented in two forms, 2 and 3 classes, that due to the imbalance in the dataset, there
are several meaningless results [2]. We have presented the results for each class and for all the classes with meaningful
results that are more practical. We could have tested our network on a few cases like some of the other researches
done recently, but we wanted to show the real performance of our network with few COVID-19 cases. As mentioned,
mistakenly detecting 68 cases from 11271 cases to be infected to COVID-19 is not very much but not very well also,
and we hope that by using much-provided data from patients infected, COVID-19, the detection accuracy will rise
much more.

5

Conclusion

In this paper, we presented a concatenated neural network based on Xception and ResNet50V2 networks for classifying
the chest X-ray images into three categories of normal, pneumonia, and COVID-19. We used two open-source datasets
that contained 180 and 6054 images from patients infected to COVID-19 and pneumonia, respectively, and 8851 images
from normal people. As we had a few images of COVID-19 class, we proposed a method for training the neural network
when we the dataset is unbalanced. We separated the training set into 8 successive phases, in which there were 633
images(149 COVID-19, 234 pneumonia, 250 normal) in each phase. We selected the number of each class almost equal
to each other in each phase so that our network also learns COVID-19 class characteristics, not only the other two
class features. In each phase, the images from normal and pneumonia classes were different so that the network can
distinguish COVID-19 from other classes better. Our training set included 3783 images, and the rest of the images were
10

A PREPRINT - M AY 5, 2021

allocated for evaluating the network. We tried to test our model on a large number of images so that our real achieved
accuracy be clear. We achieved an average accuracy of 99.50%, and 80.53% sensitivity for the COVID-19 class, and
the overall accuracy equal to 91.4% between five folds. We hope that our trained network that is publicly available
be helpful for medical diagnosis. We also hope that in the future, larger datasets from COVID-19 patients become
available, and by using them, the accuracy of our proposed network increases for good.

6

Code Availability

In this GitHub profile (https://github.com/mr7495/covid19), we have shared the trained networks and all the
used code in this paper. We hope our work be useful to help in future researches.

Acknowledgment
We would like to appreciate Joseph Paul Cohen and the others who provided these x-ray images from patients infected
to COVID-19. We thank Linda Wang and Alexander Wong for making their code available, in which we have used a
part of it on our research for preparing our dataset. We also thank Google Colab server for providing free GPU.
This is a preprint of an article published in Informatics in Medicine Unlocked journal. The final authenticated version is
available online at 10.1016/j.imu.2020.100360.

References
[1] P. An, H. Chen, X. Jiang, J. Su, Y. Xiao, Y. Ding, H. Ren, M. Ji, Y. Chen, W. Chen, et al. Clinical features of 2019
novel coronavirus pneumonia presented gastrointestinal symptoms but without fever onset. arxiv, 2020.
[2] I. D. Apostolopoulos and T. A. Mpesiana. Covid-19: automatic detection from x-ray images utilizing transfer
learning with convolutional neural networks. Physical and Engineering Sciences in Medicine, page 1, 2020.
[3] J.-Z. Cheng, D. Ni, Y.-H. Chou, J. Qin, C.-M. Tiu, Y.-C. Chang, C.-S. Huang, D. Shen, and C.-M. Chen. Computeraided diagnosis with deep learning architecture: applications to breast lesions in us images and pulmonary nodules
in ct scans. Scientific reports, 6(1):1–13, 2016.
[4] F. Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 1251–1258, 2017.
[5] F. Chollet and Others. keras, 2015.
[6] J. P. Cohen, P. Morrison, and L. Dao. Covid-19 image data collection. arXiv preprint arXiv:2003.11597, 2020.
[7] J. Dekhtiar, A. Durupt, M. Bricogne, B. Eynard, H. Rowson, and D. Kiritsis. Deep learning for big data applications
in cad and plm–research review, opportunities and case study. Computers in Industry, 100:227–243, 2018.
[8] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database.
In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee, 2009.
[9] O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning, H. Zhang, W. Ji, A. Bernheim, and E. Siegel. Rapid ai
development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient
monitoring using deep learning ct image analysis. arXiv preprint arXiv:2003.05037, 2020.
[10] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition, 2015.
[11] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In European conference on
computer vision, pages 630–645. Springer, 2016.
[12] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks, 2016.
[13] F. Jiang, L. Deng, L. Zhang, Y. Cai, C. W. Cheung, and Z. Xia. Review of the clinical characteristics of coronavirus
disease 2019 (covid-19). Journal of General Internal Medicine, pages 1–5, 2020.
[14] S. Lakshmanaprabu, S. N. Mohanty, K. Shankar, N. Arunkumar, and G. Ramirez. Optimal deep learning model
for classification of lung cancer on ct images. Future Generation Computer Systems, 92:374–382, 2019.
[15] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang, Q. Song, et al. Artificial intelligence
distinguishes covid-19 from community acquired pneumonia on chest ct. Radiology, page 200905, 2020.
[16] O. S. Lih, V. Jahmunah, T. R. San, E. J. Ciaccio, T. Yamakawa, M. Tanabe, M. Kobayashi, O. Faust, and
U. R. Acharya. Comprehensive electrocardiographic diagnosis based on deep learning. Artificial Intelligence in
Medicine, 103:101789, 2020.
11

A PREPRINT - M AY 5, 2021

[17] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian, J. A. Van Der Laak, B. Van Ginneken,
and C. I. Sánchez. A survey on deep learning in medical image analysis. Medical image analysis, 42:60–88, 2017.
[18] K. McIntosh. Coronavirus disease 2019 (COVID-19): Epidemiology, virology, clinical features, diagnosis, and
prevention, 2020-04-10.
[19] W. Meters. COVID-19 CORONAVIRUS PANDEMIC https: // www. worldometers. info/ coronavirus ,
2020-04-10.
[20] A. Narin, C. Kaya, and Z. Pamuk. Automatic detection of coronavirus disease (covid-19) using x-ray images and
deep convolutional neural networks. arXiv preprint arXiv:2003.10849, 2020.
[21] B. Pirouz, S. Shaffiee Haghshenas, B. Pirouz, S. Shaffiee Haghshenas, and P. Piro. Development of an assessment
method for investigating the impact of climate and urban parameters in confirmed cases of covid-19: A new
challenge in sustainable development. International Journal of Environmental Research and Public Health,
17(8):2801, 2020.
[22] B. Pirouz, S. Shaffiee Haghshenas, S. Shaffiee Haghshenas, and P. Piro. Investigating a serious challenge in the
sustainable development process: analysis of confirmed cases of covid-19 (new type of coronavirus) through a
binary classification using artificial intelligence and regression analysis. Sustainability, 12(6):2427, 2020.
[23] M. Rahimzadeh and A. Attar. Introduction of a new dataset and method for detecting and counting the pistachios
based on deep learning. arXiv preprint arXiv:2005.03990, 2020.
[24] M. Rahimzadeh, A. Attar, et al. Sperm detection and tracking in phase-contrast microscopy image sequences
using deep learning and modified csr-dcf. arXiv preprint arXiv:2002.04034, 2020.
[25] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation.
In International Conference on Medical image computing and computer-assisted intervention, pages 234–241.
Springer, 2015.
[26] F. Shan+, Y. Gao+, J. Wang, W. Shi, N. Shi, M. Han, Z. Xue, D. Shen, and Y. Shi. Lung infection quantification of
covid-19 in ct images with deep learning. arXiv preprint arXiv:2003.04655, 2020.
[27] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition, 2014.
[28] F. Song, N. Shi, F. Shan, Z. Zhang, J. Shen, H. Lu, Y. Ling, Y. Jiang, and Y. Shi. Emerging 2019 novel coronavirus
(2019-ncov) pneumonia. Radiology, page 200274, 2020.
[29] D. Sun, H. Li, X.-X. Lu, H. Xiao, J. Ren, F.-R. Zhang, and Z.-S. Liu. Clinical features of severe pediatric patients
with coronavirus disease 2019 in wuhan: a single center’s observational study. World Journal of Pediatrics, pages
1–9, 2020.
[30] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. Alemi. Inception-v4, inception-resnet and the impact of residual
connections on learning, 2016.
[31] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich.
Going deeper with convolutions, 2014.
[32] univers1. Everything about the Corona virus https: // medicine-and-mental-health. xyz/ archives/
4510 , 2020-04-12.
[33] L. Wang and A. Wong. Covid-net: A tailored deep convolutional neural network design for detection of covid-19
cases from chest radiography images. arXiv preprint arXiv:2003.09871, 2020.
[34] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang, Y. Li, X. Meng, et al. A deep learning
algorithm using ct images to screen for corona virus disease (covid-19). medRxiv, 2020.
[35] X. Wang, H. Qian, E. J. Ciaccio, S. K. Lewis, G. Bhagat, P. H. Green, S. Xu, L. Huang, R. Gao, and Y. Liu.
Celiac disease diagnosis from videocapsule endoscopy images with residual learning and deep feature extraction.
Computer Methods and Programs in Biomedicine, 187:105236, 2020.
[36] WHO. https: // www. who. int , 2020-04-10.
[37] X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu, Y. Chen, J. Su, G. Lang, et al. Deep learning system to screen
coronavirus disease 2019 pneumonia. arXiv preprint arXiv:2002.09334, 2020.
[38] R. Yang, X. Li, H. Liu, Y. Zhen, X. Zhang, Q. Xiong, Y. Luo, C. Gao, and W. Zeng. Chest ct severity score: An
imaging tool for assessing severe covid-19. Radiology: Cardiothoracic Imaging, 2(2):e200047, 2020.
[39] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. Learning transferable architectures for scalable image recognition,
2017.
12

A PREPRINT - M AY 5, 2021

[40] M. Zreik, N. Lessmann, R. W. van Hamersvelt, J. M. Wolterink, M. Voskuil, M. A. Viergever, T. Leiner, and
I. Išgum. Deep learning analysis of the myocardium in coronary ct angiography for identification of patients with
functionally significant coronary artery stenosis. Medical image analysis, 44:72–85, 2018.

13

