arXiv:2012.11967v3 [cs.CL] 13 Jan 2021

g2tmn at Constraint@AAAI2021: Exploiting
CT-BERT and Ensembling Learning for
COVID-19 Fake News Detection
Anna Glazkova1[0000−0001−8409−6457] , Maksim Glazkov2[0000−0002−4290−2059] ,
and Timofey Trifonov1,2[0000−0001−7996−0044]
1

2

University of Tyumen, ul. Volodarskogo 6, 625003 Tyumen, Russia
a.v.glazkova@utmn.ru, timak474@gmail.com
”Organization of cognitive associative systems” LLC, ul. Gertsena 64, 625000
Tyumen, Russia my.eye.off@gmail.com

Abstract. The COVID-19 pandemic has had a huge impact on various
areas of human life. Hence, the coronavirus pandemic and its consequences are being actively discussed on social media. However, not all
social media posts are truthful. Many of them spread fake news that
cause panic among readers, misinform people and thus exacerbate the
effect of the pandemic. In this paper, we present our results at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in English. In particular, we propose our approach using the transformer-based
ensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the
models used, the ways of text preprocessing and adding extra data. As a
result, our best model achieved the weighted F1-score of 98.69 on the test
set (the first place in the leaderboard) of this shared task that attracted
166 submitted teams in total.
Keywords: COVID-Twitter-BERT, social media, fake news, ensembling
learning, coronavirus, infodemic, text classification

1

Introduction

Social media is a unique source of information. On the one hand, their low cost,
easy access and distribution speed make it possible to quickly share the news.
On the other hand, the quality and reliability of social media news is difficult
to verify [38]. This is the source of a lot of false information that has a negative
impact on society.
Over the past year, the world has been watching the situation developing
around the novel coronavirus pandemic. The COVID-19 pandemic has become
a significant newsworthy event of 2020. Therefore, news related to COVID-19
are actively discussed on social media and this topic generates a lot of misinformation. Fake news related to the pandemic have large-scale negative social
consequences, they provoke huge public rumor spreading and misunderstanding
about the COVID-19 and aggravate effects of the pandemic. Moreover, recent
studies [22] show an increase in symptoms such as anxiety and depression in

2

A. Glazkova et al.

connection with the pandemic. This is closely related to the spread of misinformation, because fake news can be more successful when the population is
experiencing a stressful psychological situation [25]. The popularity of fake news
on social media can rapidly increase, because the rebuttal is always published
too late. In this regard, there is evidence that the development of tools for automatic COVID-19 fake news detection plays a crucial role in the regulation of
information flows.
In this paper, we present our approach for the Constraint@AAAI2021 Shared
Task: COVID-19 Fake News Detection in English [29] that attracted 433 participants on CodaLab. This approach achieved the weighted F1-score of 98.69
(the first place in the leaderboard) on the test set among 166 submitted teams
in total.
The rest of the paper is organized as follows. A brief review of related work
is given in Section 2. The definition of the task has been summarized in Section
3, followed by a brief description of the data used in Section 4. The proposed
methods and experimental settings have been elaborated in Section 5. Section 6
contains the results and error analysis respectively. Section 7 is a conclusion.

2

Related Work

In recent years, the task of detecting fake news and rumors is extremely relevant. False information spreading involves various research tasks, including: fact
checking [4,40], topic credibility [15,41], fake news spreaders profiling [34], and
manipulation techniques detection [8]. Various technologies and approaches in
this field range from traditional machine learning methods [5,23,33], to state-ofthe-art transformers [24,47].
A overview of fake news detection approaches and challenges on social media
has been discussed in [38,50]. Many scholars have proposed their solutions to
this problem in different subject areas (in particular, [6,35]). Up to now, a large
number of studies in fake news detection have used supervised methods including
models based on transformers-based architecture [13,17,49].
Some recent work have focused on detecting fake news about COVID-19.
For example, the predictors of the sharing of false information about the pandemic are discussed in [3]. In [44], a novel COVID-19 fact checking algorithm
is proposed that retrieves the most relevant facts concerning user claims about
particular facts. A number of studies have begun to examine COVID-19 fake
news detection methods for non-English languages [10,14,48].
In addition, several competitions have been announced over the past year
related to the analysis of posts about COVID-19 on social media [1,27,36].

3

Task Definition

The task focused on the detection of COVID-19-related fake news in English. The
sources of data was various social-media platforms such as Twitter, Facebook,
Instagram, etc. Formally, the task is described as follows.

CT-BERT and Ensembling Learning for COVID-19 Fake News Detection

3

– Input. Given a social media post.
– Output. One of two different labels, such as ”fake” or ”real”.
The official competition metric was F1-score averaged across the classes (the
weighted F1-score). The participants were allowed five submissions per team
throughout the test phase.

4

Dataset

The dataset [28] provided to the participants of the shared task contains 10,700
manually annotated social media posts divided into training (6420), validation
(2140), and test (2140) sets. The vocabulary size (i.e., unique words) of the
dataset is 37,505 with 5141 common words in both fake and real news. The
dataset contains the post ID, the post, and the corresponding label which is
”fake” or ”real” (see Table 1).
Table 1: Some examples of fake and real posts
Label
real

real

fake

fake

5

Post
The CDC currently reports 99031 deaths. In general the discrepancies in death counts between different sources are small and explicable. The death toll stands at roughly 100000 people today
#IndiaFightsCorona: We have 1524 #COVID testing laboratories
in India and as on 25th August 2020 36827520 tests have been
done : @ProfBhargava DG @ICMRDELHI #StaySafe #IndiaWillWin https://t.co/Yh3ZxknnhZ
Politically Correct Woman (Almost) Uses Pandemic as Excuse
Not to Reuse Plastic Bag https://t.co/thF8GuNFPe #coronavirus
#nashville
Obama Calls Trump’s Coronavirus Response A Chaotic Disaster
https://t.co/DeDqZEhAsB

Our Approach

In this section, we describe the approaches that we evaluated on the validation
data during the validation phase. We used transformer-based models as they
demonstrate state-of-the-art results in most text classification tasks. We also
evaluated the empirical effectiveness of a Linear Support Vector baseline (Linear
SVC) and different text preprocessing techniques and adding extra data. The
results are shown in the next section.
5.1

Data Preprocessing

Our approaches to text preprocessing for transformer-based models are various
combinations of the following steps, most of which have been inspired by [18,42]:

4

A. Glazkova et al.

– removing or tokenizing hashtags, URLs, emoji, and mentions using a preprocessing library for tweet data written in Python [43]. Tokenization means
the replacement of URLs, mentions, and emoji with special tokens, such as
$URL$, $MENTION$, and $HASHTAG$ respectively (for example ”HHS
to distribute $4 billion to #COVID hot spots; $340 million already paid
out. https://t.co/uAj29XA1Y5” (original) → ”HHS to distribute $4 billion
to $HASHTAG$ hot spots; $340 million already paid out. $URL$” (tokenizing); ”HHS to distribute $4 billion to hot spots; $340 million already paid
out.” (removing));
– using the Python emoji library to replace the emoji with short textual description [11], for example :red heart:, :thumbs up:, etc.;
– converting hashtags to words (”#COVID” → ”COVID”);
– translating in the lowercase.
In the case of the baseline, we translated the text to the lowercase, removed
punctuation and special characters, and then lemmatized the words. Further, we
converted texts into the form of a token counts matrix (a bag of words model).
5.2

Models

We experimented with the following transformer-based models:
– BERT [9]. BERT is a language representation model presented by Google,
which stands for Bidirectional Encoder Representations from Transformers.
BERT-based models show great results in many natural language processing
tasks. In our work, we used BERT-base-uncased, which is pretrained on texts
from Wikipedia.
– RoBERTa [19]. RoBERTa is a robustly optimized BERT approach introduced at Facebook. Unlike BERT, RoBERTa removes the Next Sentence Prediction task from the pretraining process. RoBERTa also uses larger batch
sizes and dynamic masking so that the masked token changes while training
instead of the static masking pattern used in BERT. We experimented with
RoBERTa-large.
– COVID-Twitter-BERT [26]. CT-BERT is a transformer-based model,
pretrained on a large corpus of Twitter messages on the topic of COVID-19
collected during the period from January 12 to April 16, 2020. CT-BERT is
optimised to be used on COVID-19 content, in particular social media posts
from Twitter. This model showed a 10–30% marginal improvement compared
to its base model, BERT-large, on five different specialised datasets. Moreover, it was successfully used for a variety of natural language tasks, such as
identification of informative COVID-19 tweets [18], sentiment analysis [16],
and claims verification [2,45].
5.3

Additional Data

To improve the quality of our approach, we made attempts to add extra data
to the model. For this purpose we used two datasets related to the topic of
COVID-19 fake news:

CT-BERT and Ensembling Learning for COVID-19 Fake News Detection

5

– CoAID: COVID-19 Healthcare Misinformation Dataset [7]. The dataset
includes 4251 health-related fake news posted on websites and social platforms.
– FakeCovid - A Multilingual Cross-domain Fact Check News Dataset
for COVID-19 [37]. The dataset contains 5182 fact-checked news articles
for COVID-19 collected from January to May 2020.
In our experiments, we added news headlines to the training set.
5.4

Experimental Settings

We conducted our experiments on Google Colab Pro (CPU: Intel(R) Xeon(R)
CPU @ 2.20GHz; RAM: 25.51 GB; GPU: Tesla P100-PCIE-16GB with CUDA
10.1). Each model was trained on the training set for 3 epochs and evaluated on
the validation set. As our resources are constrained, we used random seeds to
fine-tune pre-trained language models and made attempts to combine them with
other parameters. The models are optimised using AdamW [21] with a learning
rate of 2e-5 and epsilon of 1e-8, max sequence length of 128 tokens, and a batch
size of 8. We implemented our models using Pytorch [30] and Huggingface’s
Transformers [46] libraries.
The Linear SVC was implemented with Scikit-learn [31]. For text preprocessing, we used NLTK [20] and Scikit-learn’s CountVectorizer with a built-in list
of English stop-words and a maximum feature count of 10,000.

6

Results and Discussion

6.1

Comparison of Models for Fake News Detection

In Table 2, we present the results of our experiments in a step by step manner.
We started with a Linear SVC baseline and then evaluated BERT-based models
using a variety of text preprocessing and adding extra data techniques. Note
that we evaluated our models using F1-score for the fake class while the official
competition metric was the weighted F1-score.
Table 2: Evaluation results
Model

LinearSVC
BERT
RoBERTa
RoBERTa

Data preprocessing

Additional F1-Score
data
(%, for fake
class)
converting into a bag of words no
88.39
lowercase
no
96.75
lowercase
no
97.62
removing
hashtags,
URLs, no
95.79
emoji + lowercase

6

A. Glazkova et al.

RoBERTa

CT-BERT
CT-BERT

CT-BERT
CT-BERT
CT-BERT
CT-BERT

removing URLs and emoji + no
converting hashtags to words +
lowercase
lowercase
no
tokenizing URLs and mentions no
+ converting emoji to words +
lowercase
converting emoji to words + no
lowercase
tokenizing URLs + converting no
emoji to words + lowercase
tokenizing URLs + converting FakeCovid
emoji to words + lowercase
tokenizing URLs + converting CoAID
emoji to words + lowercase

95.68

98.07
97.87

98.32
98.42
98.23
98.37

As can be seen from the table above, CT-BERT models showed absolutely
better results compared to BERT- and RoBERTa-based classifiers. Our work
doesn’t contain a detailed comparative analysis of text preprocessing techniques
for this task. Still we can see that text preprocessing can affect the quality of
fake news detection. For example, there was no evidence that removing emoji
and mentions improve the model results. A clear benefit of converting hashtags
into words could not be identified during this evaluation. Also, as a result of our
experiments, we decided not to tokenize links to other user’s accounts (mentions).
This can be seen in the case of mentions of major news channels like CNN that
tend to indicate that the post is real. The next section of the model evaluation
was concerned with using additional datasets. We noticed that adding extra data
did not show any benefits in our experiments
6.2

Final Submissions

As it was mentioned above, the participants of the shared task were allowed
five submissions per team throughout the test phase. Our best model based on
experimental results (subsection 5.1) included the following preprocessing steps:
tokenizing URLs, converting emoji to words, and lowercase. As final submissions,
we used the results of hard voting ensembles of three such models with random
seed values and with different data splitting into training and validation samples.
The final architecture of our solution is shown in Figure 1.
Four of our five submitted models were trained entirely on the dataset provided by the competition organizers [28]. The last model was trained on the
competition data and on additional datasets [7,37]. The training details and the
results of our final submissions are summarised in Table 3.

CT-BERT and Ensembling Learning for COVID-19 Fake News Detection

Fig. 1. Our approach to COVID-19 fake news detection.

Table 3: Final submissions
Place
Submission
among all name
submissions
1
g2tmn 2.csv

6

11

15

Weighted Training details
F1-score
(%)
98.69
All models were trained both on
training and validation sets with no
hold out validation. We trained 3
models and then used hard-voting to
ensemble their predictions together.
g2tmn 4.csv 98.51
1000 random posts were used for
hold-out validation. Models were
trained on all other data. We trained
5 models with random seed values
and choose 3 models with the best
F1-score performances to ensemble
them together.
g2tmn 1.csv 98.37
Models were trained on the official training set. The validation
set was used for hold-out validation. We trained 5 models with
random seed values and choose 3
best-performance models to ensemble their predictions.
g2tmn 3.csv 98.32
This submission was similar to
g2tmn 1.csv but it had different
seed values.

7

8

A. Glazkova et al.

25

g2tmn 5.csv 98.18

1000 random posts were used for
hold-out validation. Models were
trained on all other official data,
CoAID and FakeCovid data. We
trained 5 models with random seed
values and used 3 best-performance
models for ensembling learning.

It can be seen from the data in Table 3 that, with the weighted F1-score, our
model performance is 98.69% (the random seeds are 23, 30, and 42), which was
ranked the first place of the leaderboard of this task.
6.3

Error Analysis

Error analysis allows us to further evaluate the quality of the machine learning
model and conduct a quantitative analysis of errors. Figure 2 provides the confusion matrix for our best solution when detecting fake news about COVID-19 on
the test set. As can be seen from the figure, the precision of our system is slightly
higher than its recall. In other words, the false positive value is greater that false
negative. Table 4 shows the examples of false negative and false positive errors.
We noticed that the type of error is frequently related to the topic of the
post. For example, the model often misclassifies false reports about the number
of people infected. At the same time, true posts related to the coronavirus vaccine
or to political topics can be identified as false.

Fig. 2. Confusion matrix of our best-performance ensemble for COVID-19 fake news
detection (for the fake class).

CT-BERT and Ensembling Learning for COVID-19 Fake News Detection

9

Table 4: Some examples of misclassified posts
True label
real

real

real

fake

fake

fake

7

Prediction Post
fake
Scientists ask: Without trial data how can we trust
Russia’s #COVID vaccine? https://t.co/gArcUf0Pji
https://t.co/0bdcA7lf56
fake
*DNA Vaccine: injecting genetic material into the
host so that host cells create proteins that are similar
to those in the virus against which the host then
creates antibodies
fake
Donald Trump has claimed he ”up-played” the seriousness of the coronavirus pandemic - despite admitting earlier this year he had ”wanted to always
play it down” https://t.co/wEgnnZzrNW
real
Govt has added #Corona disease in all existing mediclaim insurances as a special case
#COVID2019India https://t.co/39vpW7tBqq
real
As tuberculosis shaped modernism, so COVID-19
and our collective experience of staying inside for
months on end will influence architecture’s near future, @chaykak writes. https://t.co/ag34yZckbU
real
Northern Ireland was testing for COVID-19 at a rate
10 times that of Scotland reported on 9 May 2020.

Conclusion

In this work, we propose a simple but effective approach to COVID-19 fake
news detection based on CT-BERT and ensembling learning. Our experiments
confirmed that BERT-based models specialized in the subject area successfully
cope with such tasks and perform high-quality binary classification.
The experimental results showed that our solution achieved 98.69% of the
weighted F1-score on test data and ranked in the first place in the Constraint@AAAI2021 shared task. For future work, we can experiment with different training and data augmentation techniques. We can also apply and evaluate hybrid
models combining BERT-based architectures with other methods of natural language processing [32,39].

References
1. Alam F., et al.: Fighting the COVID-19 Infodemic: Modeling the Perspective of
Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society.
arXiv preprint arXiv:2005.00033 (2020)
2. Alkhalifa R. et al.: QMUL-SDS at CheckThat! 2020: determining COVID-19 tweet
check-worthiness using an enhanced CT-BERT with numeric expressions. arXiv
preprint arXiv:2008.13160 (2020).

10

A. Glazkova et al.

3. Apuke O. D., Omar B.: Fake news and COVID-19: modelling the predictors of
fake news sharing among social media users. Telematics and Informatics 56, 101475
(2020)
4. Atanasova P. et al.: Overview of the CLEF-2019 CheckThat! Lab: Automatic Identification and Verification of Claims. Task 1: Check-Worthiness. In: CLEF (Working
Notes) (2019)
5. Buda J., Bolonyai F.: An Ensemble Model Using N-grams and Statistical Features
to Identify Fake News Spreaders on Twitter. In: CLEF (2020)
6. Chernyaev A. et al.: A Rumor Detection in Russian Tweets. In: Speech and Computer, 22nd International Conference, SPECOM 2020, pp. 108-118. Springer, Cham
(2020)
7. Cui L., Lee D.: CoAID: COVID-19 Healthcare Misinformation Dataset. arXiv
preprint arXiv:2006.00885 (2020)
8. Da San Martino G. et al.: SemEval-2020 task 11: Detection of propaganda techniques in news articles. In: Proceedings of the Fourteenth Workshop on Semantic
Evaluation, pp. 1377-1414 (2020)
9. Devlin J. et al.: Bert: Pre-training of deep bidirectional transformers for language
understanding. arXiv preprint arXiv:1810.04805 (2018)
10. Elhadad M. K., Li K. F., Gebali F.: COVID-19-FAKES: A twitter (Arabic/English)
dataset for detecting misleading information on COVID-19. In: International Conference on Intelligent Networking and Collaborative Systems, pp. 256-268 (2020)
11. emoji 0.6.0, https://pypi.org/project/tweet-emoji/. Last accessed 14 Dec
2020
12. g2tmn at Constraint@AAAI2021 - COVID19 Fake News Detection in English,
https://github.com/oldaandozerskaya/covid_news. Last accessed 14 Dec 2020
13. Jwa H. et al.: exBAKE: Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Transformers (BERT). Applied Sciences 919,
4062 (2019)
14. Kar D. et al.: No Rumours Please! A Multi-Indic-Lingual Approach for COVID
Fake-Tweet Detection. arXiv preprint arXiv:2010.06906 (2020)
15. Kim D. et al.: Analysing user identity via time-sensitive semantic edit distance
(t-SED): a case study of Russian trolls on Twitter. Journal of Computational Social
Science 22, 331-351 (2019)
16. Kruspe A. et al.: Cross-language sentiment analysis of European Twitter messages
during the COVID-19 pandemic. arXiv preprint arXiv:2008.12172 (2020)
17. Kula S., Choraś M., Kozik R.: Application of the BERT-Based Architecture in Fake
News Detection. In: Conference on Complex, Intelligent, and Software Intensive
Systems, pp. 239-249. Springer, Cham (2020)
18. Kumar P., Singh A.: NutCracker at WNUT-2020 Task 2: Robustly Identifying Informative COVID-19 Tweets using Ensembling and Adversarial Training. In: Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020), pp.
404-408 (2020)
19. Liu Y. et al.: Roberta: A robustly optimized bert pretraining approach. arXiv
preprint arXiv:1907.11692 (2019)
20. Loper E., Bird S.: NLTK: The Natural Language Toolkit. In: Proceedings of the
ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics, pp. 63-70 (2002)
21. Loshchilov I., Hutter F.: Fixing weight decay regularization in adam. arXiv preprint
arXiv:1711.05101 (2017)

CT-BERT and Ensembling Learning for COVID-19 Fake News Detection

11

22. Mazza C. et al.: A nationwide survey of psychological distress among Italian people
during the COVID-19 pandemic: Immediate psychological responses and associated
factors. International Journal of Environmental Research and Public Health 179,
3165 (2020)
23. Mikhalkova E. et al.: UTMN at SemEval-2020 Task 11: A Kitchen Solution to
Automatic Propaganda Detection. In: Proceedings of the Fourteenth Workshop on
Semantic Evaluation, pp. 1858-1864 (2020)
24. Morio G. et al.: Hitachi at SemEval-2020 Task 11: An empirical study of pre-trained
transformer family for propaganda detection. In: Proceedings of the Fourteenth
Workshop on Semantic Evaluation, pp. 1739-1748 (2020)
25. Moscadelli A. et al.: Fake news and covid-19 in Italy: Results of a quantitative observational study. International journal of environmental research and public health
1716, 5850 (2020)
26. Müller M., Salathé M., Kummervold P. E.: COVID-Twitter-BERT: A Natural Language Processing Model to Analyse COVID-19 Content on Twitter. arXiv preprint
arXiv:2005.07503 (2020)
27. Nguyen D. Q. et al.: WNUT-2020 Task 2: Identification of Informative COVID-19
English Tweets. In: Proceedings of the Sixth Workshop on Noisy User-generated
Text (W-NUT 2020), pp. 314-318 (2020)
28. Patwa P. et al.: Fighting an Infodemic: COVID-19 Fake News Dataset. arXiv
preprint arXiv:2011.03327 (2020)
29. Patwa P. et al.: Overview of CONSTRAINT 2021 Shared Tasks: Detecting English
COVID-19 Fake News and Hindi Hostile Posts. In: Proceedings of the First Workshop on Combating Online Hostile Posts in Regional Languages during Emergency
Situation (CONSTRAINT), Springer (2021)
30. Paszke A. et al.: Pytorch: An imperative style, high-performance deep learning
library. Advances in neural information processing systems, 8026–8037 (2019)
31. Pedregosa F. et al.: Scikit-learn: Machine learning in Python. The Journal of machine Learning research 12, 2825-2830 (2011)
32. Peinelt N., Nguyen D., Liakata M. tBERT: Topic models and BERT joining forces
for semantic similarity detection. In: Proceedings of the 58th Annual Meeting of the
Association for Computational Linguistics, pp. 7047-7055 (2020)
33. Pizarro J.: Using N-grams to detect Fake News Spreaders on Twitter. In: CLEF
(2020)
34. Rangel F. et al.: Overview of the 8th Author Profiling Task at PAN 2020: Profiling
Fake News Spreaders on Twitter. In: CLEF (2020)
35. Reis J. C. S. et al.: Supervised learning for fake news detection. IEEE Intelligent
Systems 234, 76–81 (2019)
36. Shaar S. et al.: Overview of CheckThat! 2020 English: Automatic identification
and verification of claims in social media. arXiv preprint arXiv:2007.07997 (2020)
37. Shahi G. K., Nandini D.: FakeCovid–A Multilingual Cross-domain Fact Check
News Dataset for COVID-19. arXiv preprint arXiv:2006.11343 (2020)
38. Shu K. et al.: Fake news detection on social media: A data mining perspective.
ACM SIGKDD explorations newsletter 119, 22–36 (2017)
39. Tang L.: UZH at SemEval-2020 Task 3: Combining BERT with WordNet sense
embeddings to predict graded word similarity changes. In: Proceedings of the Fourteenth Workshop on Semantic Evaluation, pp. 166-170 (2020)
40. Thorne J. et al.: FEVER: a Large-scale Dataset for Fact Extraction and VERification. In: Proceedings of the 2018 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technologies, Volume
1 (Long Papers), pp. 809-819 (2018)

12

A. Glazkova et al.

41. Thorne J. et al.: The FEVER2. 0 shared task. In: Proceedings of the Second
Workshop on Fact Extraction and VERification (FEVER), pp. 1-6 (2019)
42. Tran K. V. et al.: UIT-HSE at WNUT-2020 Task 2: Exploiting CT-BERT for
Identifying COVID-19 Information on the Twitter Social Network. In: Proceedings
of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020), pp. 383-387
(2020)
43. tweet-preprocessor 0.6.0, https://pypi.org/project/tweet-preprocessor/.
Last accessed 14 Dec 2020
44. Vijjali R. et al.: Two stage transformer model for covid-19 fake news detection and
fact checking. arXiv preprint arXiv:2011.13253 (2020)
45. Williams E., Rodrigues P., Novak V.: Accenture at CheckThat! 2020: If you say
so: Post-hoc fact-checking of claims using transformer-based models. arXiv preprint
arXiv:2009.02431 (2020)
46. Wolf T. et al.: Transformers: State-of-the-art natural language processing. In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pp. 38–45 (2020)
47. Wu S. H., Chien S. L.: A BERT based Two-stage Fake News Spreaders Profiling
System. In: CLEF (2020)
48. Yang C., Zhou X., Zafarani R.: CHECKED: Chinese COVID-19 Fake News
Dataset. arXiv preprint arXiv:2010.09029 (2020)
49. Zhang T. et al.: BDANN: BERT-Based Domain Adaptation Neural Network for
Multi-Modal Fake News Detection. In: 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1–8. IEEE (2020)
50. Zhou X. et al.: Fake news: Fundamental theories, detection strategies and challenges. In: Proceedings of the twelfth ACM international conference on web search
and data mining, pp. 836-837 (2019)

