On the Age of Information in Internet of Things
Systems with Correlated Devices
Bo Zhou and Walid Saad

arXiv:2001.11162v3 [cs.IT] 14 Apr 2020

Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA,
Emails: {ecebo, walids}@vt.edu

Abstract—In this paper, a real-time Internet of Things (IoT)
monitoring system is considered in which multiple IoT devices
must transmit timely updates on the status information of a
common underlying physical process to a common destination.
In particular, a real-world IoT scenario is considered in which
multiple (partially) observed status information by different IoT
devices are required at the destination, so that the real-time
status of the physical process can be properly re-constructed.
By taking into account such correlated status information at the
IoT devices, the problem of IoT device scheduling is studied
in order to jointly minimize the average age of information
(AoI) at the destination and the average energy cost at the IoT
devices. Particularly, two types of IoT devices are considered:
Type-I devices whose status updates randomly arrive and typeII devices whose status updates can be generated-at-will with an
associated sampling cost. This stochastic problem is formulated
as an infinite horizon average cost Markov decision process
(MDP). The optimal scheduling policy is shown to be thresholdbased with respect to the AoI at the destination, and the threshold
is non-increasing with the channel condition of each device. For a
special case in which all devices are type-II, the original MDP can
be reduced to an MDP with much smaller state and action spaces.
The optimal policy is further shown to have a similar thresholdbased structure and the threshold is non-decreasing with an
energy cost function of the devices. Simulation results illustrate
the structure of the optimal policy and show the effectiveness of
the optimal policy compared with a myopic baseline policy.
Index Terms—Internet of things, status update, age of information, scheduling.

I. I NTRODUCTION
In emerging Internet of Things (IoT) applications [1]–[3],
such as environmental monitoring, drone control, and smart
surveillance, it is critical to ensure a timely delivery of status
information of the underlying physical processes that are being
monitored by various of IoT devices. However, conventional
performance measures, such as delay and throughput, cannot
properly capture the timeliness of the status information from
the perspective of the information destination. In particularly,
minimizing the delay or maximizing the throughput, may not
maintain the status information at the destination as fresh as
possible [4].
Recently, the notion of age of information (AoI) has been
proposed as a promising candidate for quantifying the freshness of IoT status information [5]. Typically, the AoI is defined
This research was supported by the U.S. Office of Naval Research (ONR)
under Grant N00014-15-1-2709.

as the time elapsed since the most recently received status
packet at the destination was collected by the IoT devices,
and hence it naturally captures how fresh the information
is from the destinations perspective. Due to the importance
of information freshness in the IoT, the concept of AoI has
received significant attention in a variety of scenarios that
include multi-user networks [6]–[9], multi-hop networks [10],
[11], IoT monitoring systems [12]–[14], energy harvesting
systems [15]–[17], cognitive networks [18], [19], and remote
estimation systems [20].
These existing works, e.g., [4]–[20], assume that different
devices are associated with different independent physical
processes and, hence, the AoI at the destination will change
upon receiving a “fresher” status update from only one device.
However, for certain IoT applications, updates from different
devices could be correlated in the sense that multiple devices
can be associated with one common physical process. In these
scenarios, the (partially) observed status updates by multiple
devices are required at the destination, so that the real-time status information can be properly re-constructed. For example,
for smart camera networks [2], in which multiple cameras with
possible overlapping fields of view are monitoring a common
scene, the remote monitor can only re-construct the full image
of the scene after receiving the images acquired from multiple
cameras. Thus, for such scenarios, the AoI at the destination
will only change upon receiving the fresher status updates
from multiple devices, which renders the existing approaches
in [4]–[20] no longer applicable.
Recently, the works in [21] and [22] considered remote
estimation systems with spatially correlated processes and
proposed updating strategies to improve the estimation error.
For monitoring systems with common observations, the work
in [23] proposed scheduling policies to minimize the average
AoI and the work in [24] analyzed the average AoI from a
queueing theoretic perspective. However, the authors in [23]
and [24] assume that the AoI at the destination changes if
a fresh status update from only one device is delivered. In
[25], the authors study joint node assignment and scheduling
to minimize the maximum peak AoI for wireless camera
networks with multi-view processing. However, the status
packets at each camera are assumed be already enqueued in
its buffer. Clearly, it remains unknown how to schedule the
IoT devices to minimize the average AoI for IoT monitoring

WŚǇƐŝĐĂů
ƉƌŽĐĞƐƐ

ďƵĨĨĞƌ

ƐĐŚĞĚƵůŝŶŐ

ƐĂŵƉůĞƌ

ƐĐŚĞĚƵůŝŶŐ

ƐĂŵƉůĞƌ

͘͘͘

͘͘͘

^ƚĂƚƵƐƵƉĚĂƚĞ
ŐĞŶĞƌĂƚĞͲĂƚͲǁŝůů

ƐĐŚĞĚƵůŝŶŐ

͘͘͘

As illustrated in Fig. 1, we consider a real-time IoT
monitoring system in which a set N of N IoT devices
can collect the real-time status information of a common
underlying physical process and update the status packets to
a common remote destination node (e.g., a base station or
fusion center). In our model, each IoT device can only observe
partial status information of its underlying physical process,
and, hence, multiple status packets from different IoT devices
are required at the destination so that the real-time status of the
physical process can be properly re-constructed. Let M ≥ 2
be the number of different IoT devices that are needed at
the destination for successful status reconstruction. Such a
scenario with correlated IoT devices is relevant to practical
IoT applications, for example, smart camera networks with
overlapping fields of view [2]. Note that, this is different from
prior works [4]–[20] in which different devices are associated
with different independent physical processes and the status
packet from only one device is needed to re-construct the
real-time status of the corresponding physical process.
We consider a discrete-time system with unit slot length
that is indexed by t = 1, 2, · · · . For each IoT device n ∈ N ,
let hn (t) ∈ Hn be the channel state at time slot t, where Hn
is the finite channel state space of device n. We assume i.i.d.

ďƵĨĨĞƌ

͘͘͘

II. S YSTEM M ODEL

dǇƉĞͲ//ŽdĚĞǀŝĐĞƐ

^ƚĂƚƵƐƵƉĚĂƚĞ
ƌĂŶĚŽŵĂƌƌŝǀĂů
͘͘͘

systems, in which multiple updates from different devices are
required at the destination and the status packets can randomly
arrive or be generated at the devices.
The main contribution of this paper is, thus, a novel design
of the optimal IoT device scheduling policy that jointly
minimizes the average AoI at the destination and the energy
cost at the IoT devices for a real-time IoT monitoring system
with correlated devices. We consider two types of correlated
devices: type-I devices whose status updates randomly arrive
and type-II devices whose status updates can be generated-atwill. We formulate this problem as an infinite horizon average
cost Markov decision process (MDP). By exploiting the properties of the AoI dynamics and analyzing the monotonicity
property of the value function for the MDP, we show that the
optimal scheduling policy is threshold-based with respect to
the AoI at the destination and the threshold is non-increasing
with the channel condition of each device. For a special case
with only type-II devices, we reduce the original MDP to an
MDP with much smaller state and action spaces, and we show
that the optimal scheduling policy is also threshold-based and
the threshold is non-decreasing with an energy cost function
of the IoT devices. Simulation results validate the structural
analysis of the optimal policy and show its effectiveness over
a myopic baseline policy.
The rest of this paper is organized as follows. Section II
introduces the system model. In Section III, we present the
problem formulation and the optimality equation. In Section
IV, we characterize the structural properties of the optimal
policy. Section V presents the analysis for a special IoT case.
Simulation results and analysis are provided in Section VI.
Finally, conclusions are drawn in Section VII.

tŝƌĞůĞƐƐ
ĨĂĚŝŶŐ
ĐŚĂŶŶĞů

ĞƐƚŝŶĂƚŝŽŶ
ŶŽĚĞ

ƐĐŚĞĚƵůŝŶŐ

dǇƉĞͲ///ŽdĚĞǀŝĐĞƐ

Fig. 1: Illustration of a real-time monitoring system with two
types of correlated IoT devices.

block fading wireless channels for all devices, and we consider
the channel state processes {hn (t)}(n ∈ N ) toQbe mutually
independent. Let h(t) , (hn (t))n∈N ∈ H , n∈N Hn be
the system channel state vector at slot t, where H is the system
channel state space.
We consider two types of IoT devices, namely, a set
N1 ⊆ N of N1 type-I devices and a set N2 = N \ N1 of
N2 type II devices. For each type-I device, at the beginning
of each slot, a (partially observed) status packet (if any) of
the underlying physical process randomly arrives and will be
stored in its buffer while replacing the older one (if any)
that was not transmitted. We assume that the status packet
arrivals for different type-I devices are mutually independent,
and for each type-I device n ∈ N1 , the process of the status
packet arrivals is an i.i.d. Bernoulli process with mean rate
λn ∈ [0, 1]. On the other hand, at each slot, each type-II
device can collect the partially observed real-time status of
the physical process and generate a status packet at will.
We assume that the time for generating a status packet is
negligible for each type-II device, as is commonly used in the
literature (e.g., [4], [8], [9] and [11]).
A. Monitoring Model
In each slot, the network must decide which IoT devices
must be scheduled so as to update their status packets to the
destination. For each IoT device n ∈ N , let un (t) ∈ {0, 1}
be the scheduling action at slot t, where un (t) = 1 indicates device n is scheduled to transmit its status packet
and un (t) = 0, otherwise. In each slot, we consider that
at most M IoT devices can transmit their status packets
concurrently without transmission collisions
over different
P
orthogonal channels. Thus, we have n∈N un (t) ≤ M for
all t. Let u(t) , (un (t))n∈N ∈ U be the system scheduling
action atPslot t, where U , {(un )n∈N |un ∈ {0, 1}, ∀n ∈
N and
n∈N un ≤ M } is the feasible system scheduling
action space.
For each device n ∈ N , let Cnu (hn ) be the minimum
transmission power required by device n to deliver its status
packet to the destination within a slot when its channel state
is hn . Without loss of generality, we assume that Cnu (hn ) is
non-increasing with hn , i.e., a large hn implies better channel

condition. Each type-II device n ∈ N2 will incur an nonzero sampling cost Cns for generating a status packet. Note
that, there is no such sampling cost for any type-I devices.
For notational convenience, we set Cns = 0 for each type-I
device n ∈ N1 . Then, for each device n ∈ N , the energy
cost associated with action un (t) under channel state hn (t) is
given by: Cn (un (t), hn (t)) = un (t)(Cns + Cnu (hn (t))).
B. Age of Information Model

III. P ROBLEM F ORMULATION

AND

O PTIMALITY

A. Problem Formulation

The AoI is adopted as the performance metric to quantify
the freshness of the status information update at the destination, which is defined as the time elapsed since the most
recent status update of the physical process was received (reconstructed) at the destination. Let ∆(t) be the AoI at the
destination at the beginning of slot t. Note that, a type-I
device can only transmit its currently available status packet
to the destination, and, thus, the AoI at the destination ∆(t)
would depend on the age of the status packet in the buffer
of each type-I device. For each type-I device n ∈ N1 , let
An (t) be the AoI at device n at the beginning of slot t. We
ˆ the upper limits of the AoI at typedenote by Ân and ∆
I device n and the AoI at the destination, respectively. We
ˆ are finite, as a status packet with
assume that Ân and ∆
an infinite age is not
Q meaningful for a real-time monitoring
ˆ be,
system. Let A , n∈N1 An and ∆ , {1, 2, · · · , ∆}
respectively, the state spaces for the AoI at type-I devices
and the AoI at the destination, where An , {1, 2, · · · , Ân }.
Let A(t) , (An (t))n∈N1 ∈ A be the system AoI state at
type-I devices. Note that, a type-II device can immediately
generate a status packet if scheduled. Thus, with a slight abuse
of notation, we also denote by An (t) the AoI at each type-II
device n ∈ N2 , and we set An (t) = 0 for all n ∈ N2 and t.
We can now show how A(t) and ∆(t) evolve with the
scheduling action u(t). For the AoI at a type-I device, if there
is a status packet arriving at device n ∈ N1 at slot t, then
the AoI An (t) will decrease to one, otherwise, the AoI will
increase by one. Thus, the dynamics of An (t) for each type-I
device n ∈ N1 are given by:
(
1, if a status update arrives at device n at t,
An (t + 1) =
min{An (t) + 1, Ân }, otherwise.
(1)
For the AoI at the destination, if fewer than M devices
are scheduled at slot t, then the AoI ∆(t) will increase by
one, otherwise, to re-construct the status information of the
physical process according to the received status packets from
M devices, the AoI will be the largest age of the received
status packets from all the scheduled devices plus one. Thus,
the AoI dynamics of the destination are given by:
∆(t + 1)
(
ˆ
min{max un (t)An (t) + 1, ∆},
n∈N
=
ˆ
min{∆(t) + 1, ∆},

not benefit from receiving status packets from fewer than M
devices, yielding energy waste at the devices. Note that, the
dynamics in (2) are different from those in prior art [4]–[20]
in which the status packet from only one device is required
for the destination to re-construct the real-time status of the
physical process.

(2)
if

P

n∈N

un (t) = M,

otherwise.

Clearly, it is notP
optimal to choose the scheduling action
u such that 0 <
n∈N un < M , as the destination will

We aim at controlling the IoT devices scheduling process
so as to jointly minimize the average AoI at the destination
and the energy cost at the IoT devices, under correlated IoT
devices. Given an observed system AoI state at type-I devices
A, the AoI state at the destination ∆, and the system channel
state h, we can determine the system scheduling action u
according to the following policy.
Definition 1: A feasible stationary scheduling policy π
is a mapping from the state spaces for the AoI at type-I
devices, the AoI at the destination, and the system channel
A × ∆ × H to the feasible system scheduling action space U,
i.e., π(A, ∆, h) = u.
Under the dynamics in (1) and (2), the induced random
process {A(t), ∆(t), h(t)} for a given feasible stationary
scheduling policy π is a controlled Markov chain with the
following transition probability:
Pr[A′ , ∆′ , h′ |A, ∆, h, u]
Y
Y
=
Pr[A′n |An ] Pr[∆′ |A, ∆, u]
Pr[h′n ],

(3)

Pr[A′n |An ] = Pr[An (t + 1) = An |An (t) = An ]


if A′n = 1,
λn ,
= 1 − λn , if A′n = min{An + 1, Ân },


0,
otherwise,

(4)

n∈N1

n∈N

where

and

Pr[∆′ |A, ∆, u]
= Pr[∆′ (t + 1) = ∆′ |A(t + 1) = A, ∆(t) = ∆, u(t) = u]
(
1, if ∆′ satisfies the dynamics of in (2),
=
(5)
0, otherwise.
Then, under a feasible stationary policy π and a given initial
system state (A1 , ∆1 , h1 ) ∈ A × ∆ × H, the average AoI at
the destination and the average energy cost for device n ∈ N
are respectively given by:
T
X
¯ π , lim sup 1
∆
E [∆(t)|A1 , ∆1 , h1 ] ,
T →∞ T t=1

C̄nπ , lim sup
T →∞

T
1 X
E [un (t)(Cns + Cnu (hn (t))|A1 , ∆1 , h1 ] ,
T t=1

where the expectations are taken with respect to the measure induced by policy π. Our goal is to find the optimal

scheduling policy π that jointly minimizes the average AoI
at the destination and the average energy cost for all IoT
devices. By using the widely used weighted-sum method for
multi-objective optimization problems [26], we formulate the
following problem:
X
¯π +
min ∆
(6)
βn C̄nπ ,
π

n∈N

where π is a feasible stationary policy in Definition 1 and
βn > 0 for all n ∈ N are the weighting factors on the average
energy cost for device n, mimicking the soft constraints on the
average energy cost for each device. The problem in (6) is an
infinite horizon average cost MDP. To guarantee the existence
of optimal stationary polices, we focus on stationary unichain
polices, as is commonly done (e.g., [9] and [27]).
B. Optimality Equation
According to [28, Propositions 5.2.1, 5.2.3, and 5.2.5], the
optimal scheduling policy π ∗ can be obtained by solving the
following Bellman equation:
n
X
θ + V (A, ∆, h) = min ∆ +
βn un (Cns + Cnu (hn ))
u∈U

n∈N

+

X

o
Pr[A , ∆ , h |A, ∆, h, u]V (A′ , ∆′ , h′ ) , (7)
′

A′ ,∆,h′

′

′

where Pr[A′ , ∆′ , h′ |A, ∆, h, u] is given by (3), θ is the
optimal value for all initial system states (A1 , ∆1 , h1 ) ∈
A×∆×H, and V (A, ∆, h) is the value function. The optimal
policy achieving the optimal value θ is given by:
n
X
π ∗ (A, ∆, h) = arg min ∆ +
βn un (Cns + Cnu (hn ))
u∈U

n∈N

+

X

A′ ,∆,h′

o
Pr[A , ∆ , h |A, ∆, h, u]V (A′ , ∆′ , h′ ) .
′

′

′

(8)

It can be seen that obtaining the optimal policy π ∗ in (8)
requires determining the value function V (·) by solving the
Bellman equation in (7), for which, there is generally no
closed-form solution. Moreover, the numerical solutions (e.g.,
value iteration) do not usually provide many design insights,
which further motivate us to study the structural properties of
the optimal policy π ∗ for a better understanding of the system.
IV. S TRUCTURAL P ROPERTIES

OF THE

O PTIMAL P OLICY

We characterize the structural properties of the optimal
policy π ∗ to the MDP in (6). First, by using the dynamics
in (1) and (2), we first show the monotonicity property of the
value function V (A, ∆, h) in the following Lemma.1
Lemma 1: V (A, ∆, h) is non-decreasing with An for all
n ∈ N1 and ∆, and is non-increasing with hn for all n ∈ N .
Then, we present the structure of optimal policy π ∗ . Before
that, we define the following function:
(
min Φu (A, h), if Φu (A, h) 6= ∅,
φu (A, h) ,
, (9)
+∞,
otherwise,
1 All

proof are omitted due to space limitations.

6

6

5

5

4

4

3

3

2

2

1

1

2

3

4

5

(a) Fixed A \ A1 and h.

6

1
1.24

1.29

1.33

1.34

1.74

(b) Fixed A and h \ h1 .

Fig. 2: Structure of the optimal scheduling policy π ∗ . N1 = 2,
ˆ = Ân = 6, |Hn | = 5, and βn = 1,
N2 = 3, M = 2, ∆
∀n ∈ N .
where Φu (A, h) , {∆|∆ ∈ ∆ and J(A, ∆, h, u) ≤
J(A, ∆, h, v), ∀v
∈ P U and v
6=
u} and
s
u
β
u
(C
+
C
J(A,
∆,
h,
u)
,
∆
+
n
n
n
n (hn )) +
n∈N
P
′
′
′
′
′
′
Pr[A
,
∆
,
h
|A,
∆,
h,
u]V
(A
,
∆
,
h
),
which is
′
′
A ,∆,h
related to the right-hand side of the Bellman equation in (7).
Theorem 1: If ∃n ∈ N , such that u∗n = 1, then
∗
π (A, ∆, h) = u∗ for all (A, ∆, h) ∈ A × ∆ × H such
that
(10)
∆ ≥ φu∗ (A, h).
Moreover, φu∗ (A, h) is non-increasing with hn , ∀n ∈ N .
From Theorem 1, we know that, for given A and h, the
optimal scheduling policy is threshold-based with respect to
the AoI at the destination ∆. Fig. 2 illustrates the analytical
results of Theorem 1. Fig. 2 shows that, when ∆ is small,
it is not efficient to schedule the IoT devices to update
their status packets to the destination, as a higher energy
cost per age reduction is consumed. Meanwhile, whenever
∆ is large, it is more efficient to schedule the devices, as
the previous re-constructed status of the physical process
becomes rather outdated. Moreover, the monotonicity of the
threshold φu∗ (A, h) in Fig. 2(b) indicates that, when the
channel condition is better, it is more efficient to schedule
the IoT devices, as a lower energy cost is consumed. Such
a threshold-based structure can be exploited to design lowcomplexity structure-aware optimal algorithms, by following
approaches similar to those in [12] and [13].
V. S PECIAL C ASE : I OT M ONITORING S YSTEM WITH O NLY
T YPE -II DEVICES
We now consider a special IoT monitoring system with only
type-II devices, i.e., N2 = N . Note that, here, the system
states consist of only the AoI at the destination ∆ and the
system channel state h. The dynamics of the AoI at the
destination are given by
(
P
1,
if
n∈N u(t) = M,
∆(t + 1) =
ˆ
min{∆(t) + 1, ∆},
otherwise.
(11)
Given an observed ∆ and h, the system scheduling action
u is determined according to a feasible stationary scheduling

policy π (with some abuse of notation), which is a mapping
from the system state space ∆ × H to the feasible system
action space U, i.e., π(∆, h) = u. Under the dynamics (11),
the induced random process {∆(t), h(t)} for a given policy
π is a controlled Markov chain with
Q the transition probability
Pr[∆′ , h′ |∆, h, u] = Pr[∆′ |∆, u] n∈N Pr[h′n ], where
Pr[∆′ |∆, u] = Pr[∆′ (t + 1) = ∆′ |∆(t) = ∆, u(t) = u]
(
1, if ∆′ satisfies the dynamics of in (11),
=
(12)
0, otherwise.

As previously done, we can formulate the problem as in (6)
and obtain the associated Bellman equation:
n
X
βn un (Cns + Cnu (hn ))
θ + V (∆, h) = min ∆ +
u∈U

n∈N

o
X
+
Pr[∆′ , h′ |∆, h, u]V (∆′ , h′ ) .

(13)

6
5
4
3
2
1
3.69

4.09

4.66

4.95

5.82

Fig. 3: Structure of the optimal scheduling policy π ∗ for the
special case of an IoT with only type-II devices. N = 3,
ˆ = Ân = 6, |Hn | = 4, and βn = 1, ∀n.
M = 2, ∆

∆,h′

The optimal policy π ∗ can be determined by:
n
X
π ∗ (∆, h) = arg min ∆ +
βn un (Cns + Cnu (hn ))
u∈U

n∈N

+

X

∆,h′

o
Pr[∆ , h′ |∆, h, u]V (∆′ , h′ ) .
′

(14)

From (11), we can see that, for given (∆, h), the next AoI
state at the destination ∆′ is the same for any M scheduled
devices. Thus, by (14), we know that if π ∗ (∆, h) 6= 0N , then
π ∗ (∆, h) = u† must satisfy that:
(
1, if n ∈ N (h),
†
un =
(15)
0, otherwise.
Here, N (h) = {i ∈ N : |j ∈ N : βi (Cis + Ciu (hi )) >
βj (Cjs + Cju (hj ))| < M } is the set of the devices having the M smallest values of the weighted energy cost
s
u
β
for each h ∈ H, define Ch ,
Pn (Cn + Cn (hsn )). Now,
u
(h
))
as the energy cost state of all
+
C
β
(C
n
n
n
n∈N (h) n
IoT devices. Let Ch be the set of all possible Ch . Clearly, the
optimal control policy π ∗ in (14) depends on ∆ and Ch . Thus,
we can obtain an equivalent MDP, in which, the system state
space is ∆× Ch and the action space is Ũ(Ch ) = {0N , u† }. It
can be seen that the equivalent MDP has smaller state and ac
N
tion spaces as |Ch | ≤ |H| and |Ũ(Ch )| = 2 ≤ |U| = 1 + M
.
Then, we have the corresponding Bellman equation as follows:
n
ˆ Ch′ )],
θ + V (∆, Ch ) = min ∆ + E[V (min{∆ + 1, ∆},
o
∆ + Ch + E[V (1, Ch′ )] ,
(16)

where the expectation is taken over the distribution of Ch .
Along the structural analysis in Section IV, we characterize
the structural properties of the optimal policy π ∗ for the
special case with only type-II devices.
Theorem 2: For each (∆, Ch ) ∈ ∆ × Ch , there exists a
threshold ψ(Ch ) such that
(
u† , if ∆ ≥ ψ(Ch ),
∗
π (∆, Ch ) =
(17)
0N , otherwise.

In (17), ψ(Ch ) is non-decreasing with Ch .
Theorem 2 reveals that the scheduling action is thresholdbased with respect to ∆, as illustrated in Fig. 3. Moreover,
the monotonicity property of ψ(Ch ) shown in Fig. 3 indicates
that it is more efficient to schedule the IoT devices when the
channel condition is better, as Ch is non-increasing with h.
VI. S IMULATION R ESULTS AND A NALYSIS
In this section, we compare the performance of the optimal
policy with a myopic baseline policy for the system in which
there are N1 = 2 type-I devices and N2 = 3 type-II devices,
and the status packets from M = 2 devices are needed
at the destination. For the myopic policy, in each slot, we
choose the scheduling action that maximizes the AoI reduction at the destination minus the weighted
P energy cost, i.e.,
u(t) = arg minu(t)∈U ∆(t)−∆(t+1)− n∈N βn un (t)(Cns +
Cnu (hn (t))). We consider that there are in total 4 possible
channel states for each device, which are randomly selected
from [1, 2] and the corresponding distribution probabilities are
{1/4, 1/4, 1/4, 1/4}. We assume that the arrival rate λn for
each type-I device is randomly selected from [0.3, 0.8], the
updating cost for each device is Cnu (hn ) = Cnu /hn , where
Cnu is randomly selected from [2, 3], and the sampling cost
Cns for each type-II device is randomly selected from [1, 2].
The weighting factors are assumed to be same for all devices.
Fig. 4 shows the average weighted cost, the average AoI at
the destination, and the average energy cost, resulting from the
optimal policy and the myopic baseline policy, under different
weighting factors β. The simulation results are obtained by
averaging over 50, 000 time slots. Fig. 4 demonstrates that the
optimal policy can respectively reduce the average weighed
cost and the average AoI at the destination by up to 14% and
36% over the myopic baseline policy, with a higher energy
cost. Hence, the optimal policy can make better decisions by
fully utilizing the energy at the IoT device. Moreover, for both
polices, when the weighting factor β increases, the average
AoI at the destination increases while the average energy cost

5.5

5

2

Optimal policy
Myopic policy

Optimal policy
Myopic policy

4.5

5

1.5

4
4.5
1

3.5
4

3

0.5

Optimal policy
Myopic policy
3.5
0.6

0.7

0.8

0.9

1

1.1

(a) Average weighted cost.

2.5
0.6

0.7

0.8

0.9

1

(b) Average AoI at the destination.

1.1

0.7

0.9

1.1

0.7

0.9

1.1

(c) Average energy cost at the devices.

Fig. 4: Performance comparison between the optimal policy and the myopic baseline policy.

decreases. This reveals the tradeoff between the AoI at the
destination and the energy cost at the devices.
VII. C ONCLUSION
In this paper, we have studied the optimal device scheduling
process that jointly minimizes the average AoI at the destination and the energy cost at the devices for a real-time
IoT monitoring system with two types of correlated devices.
We have formulated this problem as an infinite horizon MDP
and shown that the optimal policy is threshold-based with
respect to the AoI at the destination and the threshold is
non-increasing with the channel condition. For a special case
with only type-II devices, we have reduced the original MDP
to an MDP with smaller state and action spaces, and shown
a threshold-based structure of the optimal policy, for which,
the threshold is non-decreasing with an energy cost function.
Simulation results have verified the analytical results and
illustrated the effectiveness of the optimal policy.
R EFERENCES
[1] M. Mozaffari, A. T. Z. Kasgari, W. Saad, M. Bennis, and M. Debbah,
“Beyond 5G with UAVs: Foundations of a 3D wireless cellular network,” IEEE Trans. Wireless Commun., vol. 18, no. 1, pp. 357–372,
Jan 2019.
[2] X. Wang, “Intelligent multi-camera video surveillance: A review,”
Pattern Recognit Lett, vol. 34, no. 1, pp. 3–19, 2013.
[3] M. Chen, M. Mozaffari, W. Saad, C. Yin, M. Debbah, and C. S. Hong,
“Caching in the sky: Proactive deployment of cache-enabled unmanned
aerial vehicles for optimized quality-of-experience,” IEEE J. Sel. Areas
Commun., vol. 35, no. 5, pp. 1046–1061, May 2017.
[4] Y. Sun, E. Uysal-Biyikoglu, R. D. Yates, C. E. Koksal, and N. B. Shroff,
“Update or wait: How to keep your data fresh,” IEEE Trans. Inf. Theory,
vol. 63, no. 11, pp. 7492–7508, Nov 2017.
[5] S. Kaul, R. Yates, and M. Gruteser, “Real-time status: How often should
one update?” in Proc. of IEEE International Conference on Computer
Communications (INFOCOM), Orlando, FL, USA, March 2012.
[6] R. D. Yates and S. K. Kaul, “The age of information: Real-time status
updating by multiple sources,” IEEE Trans. Inf. Theory, vol. 65, no. 3,
pp. 1807–1827, March 2019.
[7] A. Maatouk, M. Assaad, and A. Ephremides, “Minimizing the age
of information in a CSMA environment,” in Proc. of International
Symposium on Modeling and Optimization in Mobile, Ad Hoc, and
Wireless Networks (WiOpt), Avignon, France, June 2019.

[8] H. Tang, J. Wang, L. Song, and J. Song, “Scheduling to minimize
age of information in multi-state time-varying networks with power
constraints,” in Proc. of IEEE Annual Allerton Conference on Communication, Control, and Computing (Allerton), Monticello, IL, USA,
Sep. 2019.
[9] E. T. Ceran, D. Gündüz, and A. György, “A reinforcement learning
approach to age of information in multi-user networks,” arXiv preprint
arXiv:1806.00336, 2018.
[10] A. M. Bedewy, Y. Sun, and N. B. Shroff, “The age of information in
multihop networks,” IEEE/ACM Trans. Netw., vol. 27, no. 3, pp. 1248–
1257, June 2019.
[11] R. Talak, S. Karaman, and E. Modiano, “Minimizing age-of-information
in multi-hop wireless networks,” in Proc. of IEEE Annual Allerton
Conference on Communication, Control, and Computing (Allerton),
Monticello, IL, USA, Oct 2017.
[12] B. Zhou and W. Saad, “Joint status sampling and updating for minimizing age of information in the Internet of Things,” IEEE Trans. Commun.,
vol. 67, no. 11, pp. 7468–7482, Nov. 2019.
[13] ——, “Minimum age of information in the Internet of Things with nonuniform status packet sizes,” IEEE Trans. Wireless Commun., pp. 1–1,
2019.
[14] C. Li, S. Li, Y. Chen, T. Hou, and W. Lou, “Minimizing age of
information under general models for IoT data collection,” IEEE Trans.
Netw. Sci. Eng., pp. 1–1, 2019.
[15] A. Arafa, J. Yang, S. Ulukus, and H. V. Poor, “Age-minimal transmission for energy harvesting sensors with finite batteries: Online policies,”
IEEE Trans. Inf. Theory, vol. 66, no. 1, pp. 534–556, Jan 2020.
[16] M. A. Abd-Elmagid, H. S. Dhillon, and N. Pappas, “A reinforcement
learning framework for optimizing age-of-information in RF-powered
communication systems,” arXiv preprint arXiv:1908.06367, 2019.
[17] A. Baknina, S. Ulukus, O. Oze, J. Yang, and A. Yener, “Sening
information through status updates,” in Proc. of IEEE International
Symposium on Information Theory (ISIT), Colorado, USA, 2018.
[18] Q. Wang, H. Chen, Y. Gu, Y. Li, and B. Vucetic, “Minimizing the age
of information of cognitive radio-based IoT systems under a collision
constraint,” arXiv preprint arXiv:2001.02482, 2020.
[19] Y. Zhao, B. Zhou, W. Saad, and X. Luo, “Age of information analysis
for dynamic spectrum sharing,” in Proc. of IEEE Global Conference on
Signal and Information Processing (GlobalSIP), Ottawa, Canada, Nov.
2019.
[20] T. Z. Ornee and Y. Sun, “Sampling for remote estimation through
queues: Age of information and beyond,” in Proc. of International
Symposium on Modeling and Optimization in Mobile, Ad Hoc, and
Wireless Networks (WiOpt), Avignon, France, June 2019.
[21] Z. Jiang and S. Zhou, “Status from a random field: How densely should
one update?” in Proc. of IEEE International Symposium on Information
Theory (ISIT), Paris, France, July 2019.
[22] J. Hribar, M. Costa, N. Kaminski, and L. A. DaSilva, “Using correlated
information to extend device lifetime,” IEEE Internet Things J., vol. 6,
no. 2, pp. 2439–2448, April 2019.

[23] A. E. Kalr and P. Popovski, “Minimizing the age of information from
sensors with common observations,” IEEE Wireless Commun. Lett.,
vol. 8, no. 5, pp. 1390–1393, Oct 2019.
[24] A. Javani, M. Zorgui, and Z. Wang, “Age of information in multiple
sensing,” arXiv preprint arXiv:1902.01975, 2019.
[25] Q. He, G. Dn, and V. Fodor, “Joint assignment and scheduling for
minimizing age of correlated information,” IEEE/ACM Trans. Netw.,
vol. 27, no. 5, pp. 1887–1900, Oct 2019.
[26] K. Deb, “Multi-objective optimization,” in Search methodologies.
Springer, 2014, pp. 403–449.
[27] D. V. Djonin and V. Krishnamurthy, “MIMO transmission control in
fading channels–a constrained Markov decision process formulation
with monotone randomized policies,” IEEE Trans. Signal Process.,
vol. 55, no. 10, pp. 5069–5083, 2007.
[28] D. P. Bertsekas, Dynamic programming and optimal control, 4th edition,
volume II. Belmont, MA: Athena Scientific, 2012.

