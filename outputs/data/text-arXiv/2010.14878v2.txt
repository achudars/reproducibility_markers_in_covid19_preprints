A N O PTIMAL C ONTROL A PPROACH TO L EARNING IN
SIDARTHE E PIDEMIC MODEL
A P REPRINT

arXiv:2010.14878v2 [cs.LG] 28 Jan 2021

Andrea Zugarini∗ Enrico Meloni∗ Alessandro Betti†

Andrea Panizza†

Marco Corneli‡

Marco Gori§

January 29, 2021

A BSTRACT
The COVID-19 outbreak has stimulated the interest in the proposal of novel epidemiological models
to predict the course of the epidemic so as to help planning effective control strategies. In particular,
in order to properly interpret the available data, it has become clear that one must go beyond most
classic epidemiological models and consider models that, like the recently proposed SIDARTHE,
offer a richer description of the stages of infection. The problem of learning the parameters of these
models is of crucial importance especially when assuming that they are time-variant, which further
enriches their effectiveness. In this paper we propose a general approach for learning time-variant
parameters of dynamic compartmental models from epidemic data. We formulate the problem in
terms of a functional risk that depends on the learning variables through the solutions of a dynamic
system. The resulting variational problem is then solved by using a gradient flow on a suitable,
regularized functional. We forecast the epidemic evolution in Italy and France. Results indicate
that the model provides reliable and challenging predictions over all available data as well as the
fundamental role of the chosen strategy on the time-variant parameters.

1

Introduction

The novel coronavirus that emerged in Wuhan, China, at the end of 2019, severe acute respiratory syndrome coronavirus
2 (SARS-CoV-2) [1], quickly spread in China and then to the rest of the world. As of September 30th 2020, at least
215 countries have been impacted, with over 33 millions detected cases, and over 1 million deaths5 . Huge efforts are
underway to contain the pandemic. In absence of specific vaccines or effective drugs against COVID-19, the disease
caused by SARS-CoV-2, governments have resorted to non-pharmaceutical interventions to prevent its spread, such as
social distancing, mask wearing, isolation of the infected and their contacts, and in many cases national lockdowns.
In the meantime, many researchers have focused their efforts on analyzing and forecasting the spread of COVID-19
[2, 3, 4, 5, 6]. Predicting the effect of interventions, the evolution of the size of the outbreak, or the expected date
for peak of active cases, are all results of paramount importance, that help policy makers to take the best decisions
in the face of uncertainty. In order to obtain these results, a widely used class of epidemiological models is that of
compartmental models, such as the classical Susceptible-Infectious-Recovered (SIR) [7] and the Susceptible-ExposedInfectious-Recovered (SEIR) models [8]. Compartmental models partition the population in disjoint groups, and, under
the assumption of a homogeneous and uniformly mixed population [9], they model the dynamics of each group as a
system of constant-coefficient nonlinear Ordinary Differential Equations (ODE). The SIR and SEIR models, as well as
variants such as SIDR [10] and SEIRDC [11], have been widely used to model the COVID-19 pandemic [2, 12, 13],
fitting the model parameters to the available public data. The mathematical properties of these models, such as the
∗

Universities of Florence and Siena, Italy. {andrea.zugarini,enrico.meloni}@unifi.it.
University of Siena, Siena, Italy. alessandro.betti2@unisi.it, andrea.panizza75@gmail.com.
‡
Université Côte d’Azur Center of Modeling, Simulation & Interaction, Nice, France and Inria, CNRS, Laboratoire J.A.
Dieudonné, Maasai research team, Nice, France. marco.corneli@univ-cotedazur.fr.
§
University of Siena, Siena, Italy and Inria, CNRS, I3S, Maasai, Université Côte d’Azur, Côte d’Azur, France.
marco@diism.unisi.it.
5
https://www.ecdc.europa.eu/en/geographical-distribution-2019-ncov-cases
†

A PREPRINT - JANUARY 29, 2021

existence of a threshold phenomenon, the possibility to estimate the final size of the epidemic, the maximum number of
infectious individuals at a given time and so on, are well-known and described for example in [9, 8, 14].
An issue with fitting the standard SIR and SEIR models to publicly available data is the existence of a large fraction of
undetected but infectious cases. As discussed in [6] and [4], these undetected infections can often go unrecognized due
to mildness of symptoms or lack thereof, thus exposing a far greater portion of the population to the virus than it would
otherwise occur.
In order to face the transmission due to undetected cases, in [4], the authors consider a new epidemiological model,
SIDARTHE, which extends the classical SIR model by discriminating between detected and undetected cases of
infection, and different severity of illness. The complex dynamic of the model is well suited for forecasting multiple
aspects of the infection spread, and it achieves very interesting performance on predicting the pandemic evolution in
both the Italian and French territories.
Typically, all the compartmental models assume rate coefficients to be constant in time. However, this assumption
yields quite poor approximations over large observation windows during an outbreak. Clearly, the diffusion of a virus
depends on multiple aspects that can change over time. A striking example is the case of national lock-downs aimed
at dramatically containing the spread of the disease. In [4], this issue is dealt with by assigning piece-wise constant
coefficients in correspondence of lockdown policies changes, while in [15], the authors model the coefficients as
constant values separated by three linear transitions. However, such solutions require either precise knowledge of when
and how the scenario changes or at least fixing a priori the number of breakpoints. This becomes unfeasible when there
are multiple interacting phenomena such as local lockdowns, virus mutations, variations of treatments, therapies or
infection screening.
In this paper, we propose an approach for learning time variant parameters of dynamic compartmental models and
present an approach that nicely reflects the spirit of most machine learning algorithms. We formulate the learning
process within the framework of optimal control theory [16, 17, 18]. Then we attack the problem of parameter estimation
by using a gradient flow algorithm that, throughout the paper, is referred to as GF . The algorithm, which alternates
steps of ODE solutions with gradient estimation, is shown to be very effective thanks to an appropriate regularization of
the model parameters which properly identifies their weight along the temporal window of simulation. In particular, we
learn time-variant coefficients of SIDARTHE, but clearly the algorithm is suitable for any other compartmental model
whenever supervised data is available.
This paper is organized as follows. After a brief review of SIDARTHE (Section 2), we introduce the proposed learning
framework in Section 3, and report the experiments in Section 4. Finally, some conclusions are drawn in Section 5.

2

SIDARTHE

In order to define the terminology and the notations that we will use in the remainder of the paper, in this section,
we give a brief review of SIDARTHE [4]. The model is a dynamical system described by eight ordinary differential
equations in the variables
S(t), I(t), D(t), A(t), R(t), T (t), H(t), E(t).

(1)

Each of these quantities represents the population of a different compartment of the model at a certain temporal instant
t. In particular each temporal instant t is mapped to:
S(t) = # susceptible individuals,
I(t) = # asymptomatic infected which are undetected,
D(t) = # asymptomatic infected which have been detected,
A(t) = # symptomatic infected which are undetected,
R(t) = # symptomatic infected which have been detected,
T (t) = # acutely symptomatic infecteddetected,
H(t) = # healed,
E(t) = # deceased.
2

A PREPRINT - JANUARY 29, 2021

µ

LEGEND

T
τ

A
ζ
α, β, γ, δ

S

φ

κ

Vertices
: A state of SIDARTHE

E

θ

: An undetected state of SIDARTHE

ν

I

λ

χ

ε

: A fitted state of SIDARTHE

σ

Arcs
: Critical symptoms rates
: Death rates
: Healing rates

H
D

ρ
η

ξ

S: Susceptibles
I: Undetected asymptomatic
D: Detected asymptomatic
A: Undetected with symptoms
R: Detected with symptoms
T : Detected with acute symptoms
H: Healed
E: Deceased

R

Figure 1: A DAG that shows the flow of a population through the compartments of the SIDARTHE model.
The problem is then formally defined in terms of the Cauchy problem for the following ODE system6


;

Ṡ(t) = −S(t) αI(t)+βD(t)+γA(t)+δR(t)



˙ = S(t) αI(t)+βD(t)+γA(t)+δR(t) −(ε+ζ+λ)I(t);
I(t)





Ḋ(t) = εI(t)−(η+ρ)D(t);



Ȧ(t) = ζI(t)−(θ+µ+κ+φ)A(t);
Ṙ(t) = ηD(t)+θA(t)−(ν+ξ+χ)R(t);




Ṫ (t) = µA(t)+νR(t)−(σ+τ )T (t);




Ḣ(t) = λI(t)+ρD(t)+κA(t)+ξR(t)+σT (t);



Ė(t) = φA(t)+χR(t)+τ T (t),

(2)

where
α, β, γ, δ, ε, ζ, η, θ, κ, λ, µ, ν, ξ, ρ, σ, φ, χ, τ,
(3)
are the rates that specify the velocity of the flows between the compartments of the model, with the initial conditions
(S 0 , I 0 , D0 , A0 , R0 , T 0 , H 0 , E 0 ) =: z0 .

(4)

In particular (see also Fig. 1) we have that α, β, γ and δ are the infection rates between S and I, D, A and R respectively.
Notice that these rates could be compared with the infection rate of the plain SIR model (the term in front of the
bilinear term in the update rules of the susceptible and the infected). The coefficients ε and θ govern the rate at which
the asymptomatic and symptomatic undetected infected I and A are detected, while ζ and η are responsible for the
transition between the asymptomatic and symptomatic classes (namely from I and D to A and R). The quantities µ
and ν control the flow from the symptomatic infected detected R and the symptomatic infected undetected A to the
acutely symptomatic infected class T that, in turn, is connected to the set of deceased individuals E through the rate τ .
We also extend the SIDARTHE model presented in [4] with connections from A and R to E, namely φ and χ, to detect
deceases outside Intensive Care Units (ICUs), as the ones occurred in elderly care facilities. Finally, κ, λ, ξ, ρ and σ
represent the recovery rates. Since the flows of the population through the eight compartments are directed (indeed the
graph in Fig. 1 is a dag) all the rates must be non-negative.
The constants S 0 , I 0 , D0 , A0 , R0 , T 0 , H 0 and E 0 in Eq. (4) are assumed to be real non-negative values and coupled
with the SIDARTHE differential equations they specify a Cauchy problem. Notice that if I 0 = D0 = A0 = R0 ≡ 0
then the infection cannot begin. From Eq. (2) it is also immediate to see that the total population is conserved since
Ṡ + I˙ + Ḋ + Ȧ + Ṙ + Ṫ + Ḣ + Ė = 0. As it is argued in [4] an appropriate definition of the basic reproduction
number in this model is

1
βε
γζ
R0 :=
α+
+
ε+ξ
η+ρ θ+µ+κ+φ


(5)
δ
ηε
ζθ
+
+
.
ν+ξ+χ η+ρ θ+µ+κ
Equation 5 was appropriately modified to account for the inclusion of φ and χ. In the SIDARTHE model, all the rates
in Eq. (3) are constant over time, and are only changed in windows where different lockdown policies are defined.
6

In [4] they choose φ = χ ≡ 0.

3

A PREPRINT - JANUARY 29, 2021

However, virus aggressiveness, social behavior, climate changes and different treatment of the disease, may all change
during the development of the outbreak, motivating the extension of Eq. (2) to the case of truly time-variant coefficients.
In the next section we will discuss how it is possible to learn from data, in a meaningful way, the coefficients in Eq. (3)
as functions of time over the horizon [0, T ].

3

Learning the SIDARTHE coefficients

Let u : [0, T ] → R18 be the map
u(t) =(α(t), β(t), γ(t), δ(t), ε(t), ζ(t), η(t), θ(t), κ(t),
λ(t), µ(t), ν(t), ξ(t), ρ(t), σ(t), φ(t), χ(t), τ (t)),
belonging to the functional space7 X, and z : [0, T ] → R8 the vector valued function
z(t) := (S(t), I(t), D(t), A(t), R(t), T (t), H(t), E(t)).
Let D(·, u, z0 ) be the solution for the variable D of Eq. (2) when the coefficients are the components of the function u,
and the initial values of the compartments are specified by the values of z0 ∈ R8 . In a similar manner let us also define
R, T and E so that each of such quantities, considered as functions of all their arguments, maps [0, T ] × X × R8 → R.
Lastly let
Z t
H d (t, u, z0 ) :=
ρ(s)D(s, u, z0 ) + ξ(s)R(s, u, z0 )
(6)
0
+ σ(s)T (s, u, z0 ) ds,
which, roughly speaking, represents the number of diagnosed individuals who recovered when we initialize Eq. (2) with
z0 and for a given choice u of the various rates.
The quantities D, R, T , H d and E are the basic ingredients to define the risk that we will use to define the learning
task. Indeed let us define ϕ : [0, T ] × X → R the following quadratic error
eD
eR
(D(t, u, z0 )−D̂(t))2+ (R(t, u, z0 )−R̂(t))2
2
2
eT
2 eH
+ (T (t, u, z0 )−T̂ (t)) + (H d (t, u, z0 )−Ĥ(t))2
2
2
eE
2
+ (E(t, u, z0 )−Ê(t)) ,
2
where D̂, R̂, T̂ , Ĥ and Ê are the observed time series and eD , eR , eT , eH and eE are positive constants.
ϕ(t, u) :=

Let F : X → R be8
Z

T

m
|u̇(t)|2 + ϕ(t, u) dt,
(7)
2
0
with m > 0. Notice that this is an integral of a Lagrangian that is non-local in time since ϕ depends on the whole
trajectory of the variables u and not just on the their values at time t. Then, the learning of u corresponds to the
following optimization problem
min F (u).
(8)
F (u) :=

u∈X

This problem resembles identification and optimal control problems that are associated with the minimization of F , that
can be tackled by means of the theory of Lagrange’s multipliers [16]. In this case the states z are promoted to variables
of the problem, so that the quadratic error ϕ can be written directly in terms of the components of z; for example the
term (D(t, u) − D̂)2 → (z3 − D̂)2 . The minimization problem then is solved under the constrained dynamic of z
given by the SIDARTHE system of the form ż(t) = Φ(z(t), u(t)) (Φ here can be deduced by the right-hand-side of the
differential equation in (2)). Then the problem Eq. (8) can be recast into the following form:
Z T
m 2 eD
eR
|u̇| + (z3−D̂)2+ (z5−R̂)2
2
2
2
0
min
u∈X
eT
e
(9)
H
z∈Y
+ (z6−T̂ )2+ (Hd (·, z, u)−Ĥ)2 ;
2
2
subject to ż = Φ(z, u),
7
8

Here we assume that X is Hilbert.
An appropriate choice for the functional space X in this case could be X = H 1 ([0, T ]; R18 ).

4

A PREPRINT - JANUARY 29, 2021

where Y is an appropriate functional space that contains functions z satisfying the initial condition z(0) = z0 and
Z t
Hd (t, z, u) :=
u14 z3 + u13 z5 + u15 z6 .
(10)
0

Following this approach, the solution is usually achieved by imposing the stationarity condition on (9), which yields
the Euler-Lagrange differential equations with appropriate boundary conditions over the temporal variable t. In this
problem, however, the presence of the additional non-locality due to (10) that persists also in the reformulation (9)
requires, for instance, to regard Hd as another variable and to add the differential equation for Ḣd , that can be readily
be inferred from Eq (10), to the constraints ż = Φ(z, u).
While the parameter estimation based on Eq. (9) constitutes by itself a very interesting and promising research direction,
in this paper, we propose to pursue the minimization of (7) through a more direct approach, i.e. by approximating the
gradient flow u0 = −∇F (see [19]) by an explicit method that updates the trajectories t 7→ u(t) starting from a fixed
initial configuration u0 ∈ X. For this reason we are referring to the learning approach proposed in this paper as GF
(Gradient Flow). In practice the proposed learning algorithm is an implementation of the following update rule
uk+1 = uk − ∇F (uk ),

k ≥ 0,
0

(11)
2

where ∇F is (when it exists) the Fréchet derivative (see [20]) of F and u ∈ X is assigned. The term |u̇| /2 in Eq. (7)
is extremely important for the well-posedness of the learning problem: the minimization of the mean quadratic loss
alone could in principle lead to highly irregular solutions that have a low degree of generalization power. Moreover the
term ku̇kL2 gives coerciveness to the whole functional making it more suitable to be the objective of a minimization
problem. This term yields a parsimonious solution where abrupt changes are penalized. Due to the presence of |u̇|2 ,
the stationarity condition on the functional in Eq. (7) also suggests that the derivatives of stationary points of F on
the boundaries t = 0 and t = T must be vanishing, thus offering an interesting consistency check for the numerical
solutions that we find. Indeed, we verified experimentally that this condition generally holds true on the learned
parameters.
Before going on to the description of the algorithm in terms of a time discrete version of (11) which is machine
implementable, we notice that we can softly enforce the positivity of the parameters by adding to the functional F the
RT
term eP 0 1{u(t)<0} (t) dt, where 1A is the indicator function of the set A and eP is a positive constant.
Algorithmic details Consider a uniform partition 0 = t0 < t1 < · · · < tN = T of the interval [0, T ] where
|ti+1 − ti | =: ∆t for all i = 0, . . . , N − 1. Let f : R18(N +1) → [0, +∞) that maps x 7→ f (x) to be the “discretized”
version of the functional F where a point x ∈ R18(N +1) in its domain can be tought as the concatenation of all the
parameters sampled at the time grid defined above. The discrete counterpart of (11) is a classical gradient descent
method which starts from the value x0 (whose components are the sampling of u0 on the various tj ) and compute the
vector sequence x1 , x2 , . . . according to the update rule
xk+1 = xk − π∇f (xk ),

(12)

where π > 0 is the learning rate, and where now ∇f is the ordinary gradient in R18(N +1) which can be computed at
each step once we choose a numerical solver for Eq. (2). After that the SIDARTHE equations are numerically integrated,
the non-local term ϕ becomes simply a function of the variable x ∈ R18(N +1) . We found that the update rule (12) that
defines the gradient flow suffers a normalization problem which affects the parameters at different time. Basically,
since the term ϕ in Eq. (7) depends on the variables x though a numerical integration of (2), changes in early (in time)
parameters result in greater variations of ϕ than changes in later (in time) parameters, since the latter will only affect
the solution of the SIDARTHE in the last part of the interval [0, T ], whereas the former parameters contribute to modify
the potential ϕ on most of the interval. This suggest that the components of ∇f that corresponds to ti close to T are
negligible with respect to the same quantity evaluated at earlier times. This makes the learning process either extremely
unstable or exceedingly slow. In order to overcome this problem we modified the update rule (12) by introducing a
regularization that is conceived for propagating the gradients from earlier to later times:
(
x̂ki−π0 (∇fˆ(x̂k ))0
if i = 0;
k+1
x̂i =
(13)
k+1
k
k
k
ˆ
x̂i −πi (∇f (x̂ ))i+ωi (x̂i−1 −x̂i−1 ) if i > 0,
where x̂i ∈ R18 for i = 0, . . . , N are the slices of x that correspond to the value of the parameters at time ti . The
function fˆ is defined accordingly (for further details see Appendix 5). We choose
πi ≡ π(ti ) :=

π0
,
1 + ati

ωi ≡ ω(ti ) :=
5

1
,
1 + e−bti

(14)

A PREPRINT - JANUARY 29, 2021

   

   

   

   

    
    
    
 1 R Q H

   
   

    

    

    
 D

    

    

   
  

 E

    
    
    
 1 R Q H

 

   

   

   

 7 H V W  O R V V

 D

    
    
    
 1 R Q H

 7 H V W  O R V V

 7 H V W  O R V V

 E

   

   

   

   

   

   

   

 E

  

  

  
 7 U D L Q  V L ] H

   

   

Figure 2: Test loss values for different values of a, b and T . Red line is the baseline where temporal momentum is
disabled. Values are reported with 95% confidence intervals.
where π0 , a and b positive parameters.
Note that the above scheme makes sense when we pass to the continuous limit with respect to the index i. For this
reason the following proposition is of interest
Proposition 1. If the solutions of the gradient flow u0 = −∇F (u) are continuous function of time, then Eq. (13) is a
discrete approximation of the following update rule for u:
π(t)
(∇F (uk ))(t).
uk+1 (t) = uk (t) −
1 − ω(t)
Proof. It is sufficient to notice that, since we look for a solution which is continuous in t in the limit ∆t → 0 we must
have, for each k ≥ 0, |x̂ki−1 − x̂ki | → 0. Then Eq. (13) in the continuous limit becomes
(1 − ω(t))(uk+1 (t) − uk (t)) = −π(t)(∇F (uk ))(t),
which is exactly what we wanted to prove.
This proposition shows that the update scheme defined in Eq. (13) is basically equivalent to introducing an increasing,
time-dependent learning rate. Notice that, the term proportional to ω in Eq. (13) is reminiscent of the classic momentum
term [21]. However, it also involves relations in the temporal domain which are neglected in other frameworks. Due to
this similarity, in what follows, we refer to this term as the temporal momentum.
Function π(t)/(1 − ω(t)) is, with appropriate choices of the parameters a and b, a monotonically increasing function
for t > 0 and in particular for large t we have π(t)/(1 − ω(t)) ' π0 ebt /at.

4

Experiments

The analysis of our learning framework is carried out on the Italian9 and French10 epidemiological data, gathered from
official daily reports up to September 30, 2020. This section is divided in two parts. First, we discuss the results of the
ablation study, confirming the importance of both the regularization term (Eq. (7)) and the update rule (Eq. (13)) for the
learning process. Then, we fit SIDARTHE on the Italian and French data. The code to reproduce all the experiments is
available online11 . The differential equations were solved by Heun’s method [22], implemented in PyTorch [23]. The
automatic differentiation in PyTorch computes the gradient ∇f for each time-variant parameter.
4.1

Ablation study

The learning of the SIDARTHE rates is performed via the update rule in Eq. (13), under the constraint on the first order
derivative u̇(t) introduced in Eq. (7). The impact of these two components (update rule and first order constraint) on the
learning process depends on the values of the hyper-parameters {a, b} in Eq. (14) and m in Eq. (7), respectively. The
aim of this section is to discuss and quantify the role of these hyper-parameters.
The Italian data set alone is considered in this section. Each experiment is repeated 20 times, provided with a random
initialization x0 of the model parameters. Unless specified differently, the training data set counts 120 consecutive data
points and the subsequent 20 samples are used for test.
9

https://github.com/pcm-dpc/COVID-19/tree/master/
https://github.com/opencovid19-fr/data
11
https://github.com/sailab-code/learning-sidarthe
10

6

A PREPRINT - JANUARY 29, 2021

  H 

 7 H V W  O R V V

 ' H U L Y D W L Y H  Q R U P

 5 H J X O D U L ] H G
 1 R Q H

 
 
 
 

   

   

 P

   

    

      
      
      

 5 H J X O D U L ] H G
 1 R Q H
   

   

 P

   

    

Figure 3: Test loss values for different values of a, b and T . Red line is the baseline where momentum is disabled.
Values are reported with 95% confidence intervals.
Temporal momentum. We performed a grid search on the hyper-parameter space of {a, b}. For a we considered 5
equally spaced values in the interval [0, 0.2]. For b we considered 6 equally spaced values in the interval [0, 0.5]. For
each pair {a, b} we trained 20 models. Additionally, we trained other 20 models where temporal momentum (henceforth,
momentum) was disabled (i.e. ωi = 0 for all i, thus reducing to a standard gradient descent). In total, we trained
5 × 6 × 20 + 20 = 620 different models. The results are presented in Fig. 2. The plots clearly show that the momentum
term improves the stability of the learning process. In particular, we see that the improvement saturates for b > 0.1.
Conversely, a > 0 deteriorates the performances. Since the y axis is plotted with logarithmic scale, the confidence
intervals are even narrower for b > 0.1 and a = 0.
We then performed a second grid search on the hyper-parameter space of {b, T }, where the values of b are the same as
described above, and we considered 5 equally spaced values of T in [40, 120]. In this case too, for each value of the
pair {b, T }, 20 models were trained. In addition, for each value of T , we trained additional 20 models with momentum
disabled. In this setting, a total of 5 × 6 × 20 + 5 × 20 = 700 models were trained. Results are presented in Fig. ??.
The plot shows that when the momentum term is disabled, the model performs poorly on test, and the learning has wider
confidence intervals. Instead, when momentum is enabled with a high enough value for b, the test loss becomes lower
and the confidence intervals significantly narrow down. These experiments show that the momentum term dramatically
improves the learning process, by further minimizing the (test) loss function and also reducing the dependency on the
initial value u0 .
Regularization. To evaluate the effectiveness of the derivative term, we performed a grid search on the hyperparameter space of m ∈ {0, 1., 103 , 105 , 108 , 1011 , 1013 }. For each value of m we trained 20 models, for a total of
7 × 20 = 140 trained models. We plot the test loss as function of the weight, as shown in Fig. Figure 3. The results show
that, except for m = 1011 , the derivative term is not significantly changing the test loss. Instead, we see that the norm
of the derivative of the parameters steadily decreases for m > 105 . This means that the derivative term contributes to
enforcing parameters as smoother functions of time, without significantly degrading the generalization of the learning.
4.2

Outbreak Forecasting

We forecast the epidemic spreading in Italy and France. We trained our models in the time span going from February,
the 24th, to August, the 30th, i.e. overall 188 days. The following 31 days were used for validation and test. In particular,
we considered the period August, the 31st up to September, the 6th, for validation (7 days) and September, the 7th,
up to September, the 30th, for test (25 days). The fitting was performed on the time series appearing in the functional
risk F in Eq.(7). i.e. D̂, R̂, T̂ , Ĥ, Ê. These values are all available from the Italian reports, whereas in the French
official data, only R̂, T̂ , Ê are explicitly observed, along with the cumulative number of infectious and the number of
hospitalized individuals that recovered, defined here as CI (t) and Hh (t), respectively. Instead, hospitalized infected
individuals corresponding to D (i.e. the proxy of the asymptomatic detected people) are not traced. Consequently, we
did not have direct information about their number and recovery date. To extract D̂ and Ĥ we made the assumption that
asymptomatic individuals heal after a period d, that was set to 14 days, i.e. the quarantine period commonly established
by national governments. In such a way, active asymptomatic infectious D̂ and recovered individuals Ĥ were estimated
(at time t) as follows:
D̂(t) = CI (t) − T̂ (t) − R̂(t) − D̂(t − d)
Ĥ(t) = Hh (t) + D̂(t − d)
Moreover, some daily French reports have partial or total missing information, causing the presence of many missing
data. Due to the rich presence of noise and missing data in the early stages of French outbreak, the model fitting begins
7

A PREPRINT - JANUARY 29, 2021

from March, the 17th instead of February, the 24th, while validation and test dates were left unchanged. The remaining
missing targets within training/validation/test periods were simply ignored for learning and evaluation.
 6    W U D L Q  Y D O L G D W L R Q  W H V W

  H 

 ,    W U D L Q  Y D O L G D W L R Q  W H V W

    

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

    
    
    
    
 0 D U
    

 0 D \

 $ S U

 - X Q

 - X O

 $ X J

 6 H S

 $    W U D L Q  Y D O L G D W L R Q  W H V W
    

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

    

 
 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 0 D U
    

     
     

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

      
      
     
 
 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

    
    
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 0 D U
    

 $ S U

 (    W U D L Q  Y D O L G D W L R Q  W H V W

 6 H S

 0 D \

     
     
 
 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 - X Q

 - X O

 $ X J

 6 H S

 5     W U D L Q  Y D O L G D W L R Q  W H V W
 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

     

 6 H S

 $ X J

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

   
 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

 - X O

 
 0 D U
    

 + B ' ( 7 ( & 7 ( '    W U D L Q  Y D O L G D W L R Q  W H V W
      

 - X Q

    

 
 $ S U

 0 D \

 7    W U D L Q  Y D O L G D W L R Q  W H V W
 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

    
 0 D U
    

 $ S U

 5    W U D L Q  Y D O L G D W L R Q  W H V W

     

 

     

     

     
    

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

     

     

     

    

 '    W U D L Q  Y D O L G D W L R Q  W H V W
 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

     
     
     
     
     
    
 

 $ X J

 6 H S

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

   
   
   
   
   
 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

Figure 4: Epidemic evolution of COVID-19 in Italy.

 , Q I H F W L R Q  5 D W H V
   
   
   
   
   
   

 6 \ P S W R P V  ' H Y H O R S P H Q W  5 D W H V

 ' H W H F W L R Q  5 D W H V

    

    

    

    

    

    

    

    

    

    

    

    
    

 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 0 D U
    

 $ S U

 0 D \

 $ F X W H  6 \ P S W R P V  ' H Y H O R S P H Q W  5 D W H V

 - X Q

 - X O

 $ X J

 0 D U
    

 6 H S

 $ S U

 0 D \

 5 H F R Y H U \  5 D W H V

 - X O

 $ X J

 6 H S

 $ X J

 6 H S

 ' H D W K  5 D W H V

    

    

 - X Q

    

    

    

    

    

    

    

    

    

    

    

    

 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

    

    
 0 D U
    

 $ S U

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 0 D U
    

Figure 5: Time-variant parameters dynamics in Italy.

8

 $ S U

 0 D \

 - X Q

 - X O

A PREPRINT - JANUARY 29, 2021

Table 1: Model forecast on Italian and French Test data. Mean Absolute Percentage Error (MAPE), and the fraction of
days d where the predictions are within an error threshold of 30%.
Italy
MAPE
d
D
R
T
H
E

16%
8%
19%
4%
6%

France
MAPE
d

20/25
25/25
25/25
25/25
25/25

41%
84%
16%
2%
5%

10/25
3/25
25/25
24/24
25/25

In addition to restricting the space of the solutions to the problem in Eq.(8) by means of the first order constraint
(previously discussed), we furthermore decided to reduce the number of learnable parameters. The learning of some
pairs of parameters was tied together. In particular we tied β and δ, ξ and κ, λ and ρ, η and ζ. As initial conditions of
the dynamical system we used the following values: I 0 = D0 = D̂(0), A0 = R0 = Â(0), T 0 = T̂ (0), Hd0 = Ĥ(0),
E 0 = Ê(0), S 0 = N − (I 0 + D0 + A0 + R0 + T 0 + H 0 + E 0 ), where N is the size of the population considered. We
found that starting from a good initialization of the parameters u(t) facilitates the learning and leads to better results. In
the Italian case, we initialized all the parameters with the values provided in [4], whereas for the French data set we
initialised u(t) as a constant (not time dependent) such that R0 = 1.95.
We performed model selection based on the best solution in the validation period. The best models were obtained
through grid search in the space of the hyper-parameters. In particular the positive constants eT , eR , eD , eH , eE that
weigh the terms T , R, D, H d , E in the functional risk F , the coefficient m that acts on the derivative term |u̇|2 /2, the
factor ep that enforces the positivity of the solutions, the parameters a and b that define the ω function in Eq. (14) span

    

 6    W U D L Q  Y D O L G D W L R Q  W H V W

  H 

    
    
    
    

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

    
 $ S U
    

 0 D \

 - X Q

 - X O

 ,    W U D L Q  Y D O L G D W L R Q  W H V W

      
      
      
      
     
     
     
 

 $ X J

 6 H S

    

      
     
 
 $ S U
    

 0 D \

     

    

    

 
 - X Q

 - X O

 $ X J

 6 H S

 $ S U
    

 0 D \

 + B ' ( 7 ( & 7 ( '    W U D L Q  Y D O L G D W L R Q  W H V W
      

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

      
      
      

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 $ S U
    

 0 D \

 $ X J

 6 H S

 - X Q

 - X O

 $ X J

 6 H S

 $ X J

 - X Q

 - X O

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

 $ S U
    

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 $ X J

 6 H S

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

   
   
   
   
 $ S U
    

Figure 6: Epidemic evolution of COVID-19 in France.
9

 6 H S

 5     W U D L Q  Y D O L G D W L R Q  W H V W
 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

 0 D \

 - X O

 7    W U D L Q  Y D O L G D W L R Q  W H V W

 (    W U D L Q  Y D O L G D W L R Q  W H V W

 $ S U
    

 - X Q

    
    
    
    
    
    
    
 

     
     
     
     
     
    
 

 
 $ S U
    

 - X O

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

     

    

 0 D \

 - X Q

     

     

    

 $ S U
    

      

 5    W U D L Q  Y D O L G D W L R Q  W H V W
 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

    

 3 U H G L F W L R Q   W U D L Q 
 7 D U J H W   W U D L Q 
 0 L V V L Q J   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 7 D U J H W   Y D O 
 0 L V V L Q J   Y D O 
 3 U H G L F W L R Q   W H V W 
 7 D U J H W   W H V W 
 0 L V V L Q J   W H V W 

      
      

 $    W U D L Q  Y D O L G D W L R Q  W H V W
    

 '    W U D L Q  Y D O L G D W L R Q  W H V W

      

 3 U H G L F W L R Q   W U D L Q 
 3 U H G L F W L R Q   Y D O 
 3 U H G L F W L R Q   W H V W 

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

A PREPRINT - JANUARY 29, 2021

 , Q I H F W L R Q  5 D W H V

 6 \ P S W R P V  ' H Y H O R S P H Q W  5 D W H V

 ' H W H F W L R Q  5 D W H V

    

    

    

    

    

    

    
    
    
    
    
    
    

    

    

    

    
 $ S U
    

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 $ F X W H  6 \ P S W R P V  ' H Y H O R S P H Q W  5 D W H V
    

 $ S U
    

 0 D \

 - X Q

 - X O

 $ X J

 0 D \

 5 H F R Y H U \  5 D W H V

    

 - X Q

 - X O

 $ X J

 6 H S

 $ X J

 6 H S

 ' H D W K  5 D W H V
    

    

    

    

    

 $ S U
    

 6 H S

    

    

    

    

    

    

    

    

    

 $ S U
    

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 $ S U
    

 0 D \

 - X Q

 - X O

 $ X J

 6 H S

 $ S U
    

 0 D \

 - X Q

 - X O

Figure 7: Time-variant parameters dynamics in France.
the hyper-parameters space of the learning method. Based on the findings of the ablation study in Section 4.1, we can
narrow the search in the hyper-parameters space by setting a = 0, b ∈ [0.05, 0.125] and m ∈ [105 , 1011 ]. The learning
rate π0 , was set to 10−5 .
In order to provide a better understanding of the predictive capabilities of our model, we also report in Table 1 the Mean
Absolute Percentage Error (MAPE) and the fraction of test days where the model predictions are beyond a certain
tolerance error threshold, that we call d. We conclude this section with some remarks specific to each data set.
Italy. The epidemic spreading in Italy is showed in Fig. 4. It turns out that the model predictions are quite accurate
over windows of a few weeks. The MAPE is on average always under 20% for each state variable, moreover it remains
below the tolerance threshold of 30% in the test with the exception of the last 5 days of D (see Table 1). The obtained
basic reproduction number R0 reflects consistently the epidemic spreading and its values are coherent with the results
reported in [24] for single Italian regions. It is worth mentioning that in this paper R0 refers to the system dynamics
interpretation associated with SIDARTHE model, which might somewhat depart from other estimations. All the model
parameters are presented in Figure 5. Interestingly enough, recovery rates σ, ξ (tied with κ), ρ (tied with λ) associated
to ICU patients, detected and undetected symptomatic individuals, respectively, steadily increase over time, suggesting
that hospitals are more and more prepared and trained to face the complications linked with the virus.
France. The French outbreak forecast is presented in Fig. 6. Despite the significant presence of noisy and missing
data, we observe that the model succeeds in forecasting the state variables T, H, E, always within the tolerance. Instead,
the state variable R is clearly overestimated. We believe it is caused by two main reasons: first, the overestimation
of D overflows to R, and second an abrupt change in the data distribution, since the growth of target data D̂(t) is not
reflected by a similar increase of R̂(t). The trend of the model parameters (see Fig. 7) is similar to the one obtained for
Italy. Recovery rates tend to grow, detection rates quickly increase and then stabilize, symptoms development decreases
significantly.

5

Conclusions

In this paper we have discussed the problem of learning time-variant coefficients in compartmental models, with special
attention on SIDARTHE [4], a recently introduced epidemiological model which offers a very rich description of the
stages of an epidemic infection. The major contribution of the paper consists of extending the challenging features
of SIDARTHE model to the case of time-variant parameters that are properly learned from examples. This is carried
out within a functional formulation of learning which is based on a special interpretation of gradient-flow, which
allowed us to obtain a reliable forecasting of most critical indicators of the outbreak severity (i.e. deaths, recoveries
and hospitalized in ICU individuals) of the COVID-19 epidemic outbreak. A massive experimentation in Italy and
10

A PREPRINT - JANUARY 29, 2021

France has shown promising results over large windows in the last few months. We are confident that the proposed
enrichment of SIDARTHE model, which is one of top level models for COVID-19 prediction, might be useful for
supporting critical policies to face the diffusion of the infection all around the world.
[Details on algorithmic issues] Given a function u ∈ X and the temporal partition 0 ≡ t = t0 < t1 < · · · < tN ≡ T ,
in this appendix we show how to explicitly construct its discrete counterpart as an element of the domain of the function
f and subsequently how to rearrange its components to precisely define the quantities x̂ and fˆ that are used in Eq. (13).
Let ui,j := ui (tj ) the components of the matrix U ∈ R18×(N +1) whose rows are the sampling on the temporal
partition t0 , t1 , . . . , tN of the coordinates of u. Instead of working with matrices we exploit the isomorphism between
R18×(N +1) and R18(N +1) that maps
U → vec(U ) := (u1,0 , u2,0 , . . . , u18,0 , . . . , u1,N , . . . , u18,N )0 .
With this mapping we can transform the initial point u0 of the flow defined by (11) into the initial point x0 necessary to
start the gradient descent in Eq. (12) 12 : x0 = vec((u0i,j )) ∈ R18(N +1) .
The relation between x and x̂j for j = 0, . . . , N and between f and fˆ instead naturally follows once we explicitly state
QN +1
the relation between the the domain of the function f with the product space (R18 )N +1 := α=1 R18 . Indeed the
projections pj : (R18 )N +1 → R18 map x 7→ pj (x) = (x18j+1 , . . . , x18(j+1) )0 =: x̂j for j = 0, . . . , N . Following the
same line of thoughts it is natural to define fˆ: (R18 )N +1 → [0, +∞) simply as
y 7→ fˆ(y) ≡ fˆ(y0 , . . . , yN ) := f (c(y0 , . . . , yN )),
where c : (R18 )N +1 → R18(N +1) realizes the isomorphism
(y0 , . . . , yN ) → (y0 1 , . . . , y0 18 , y1 1 , . . . , y1 18 , . . . , yN 18 )0 .
Notice that with this definition (∇fˆ)i ∈ R18 for all i = 1, . . . , N + 1, while (∇f )j ∈ R for all j = 1, . . . , 18(N + 1).
This being said all quantities used in Eq. (13) are precisely defined once we specify that x̂ is used as a shortcut for
x̂0 , . . . , x̂N .

Acknowledgments
We thank Stefano Merler (FBK) for insightful discussions.

References
[1] J. F.-W. Chan, S. Yuan, K.-H. Kok, K. K.-W. To, H. Chu, J. Yang, F. Xing, J. Liu, C. C.-Y. Yip, R. W.-S. Poon,
H.-W. Tsoi, S. K.-F. Lo, K.-H. Chan, V. K.-M. Poon, W.-M. Chan, J. D. Ip, J.-P. Cai, V. C.-C. Cheng, H. Chen,
C. K.-M. Hui, and K.-Y. Yuen, “A familial cluster of pneumonia associated with the 2019 novel coronavirus
indicating person-to-person transmission: a study of a family cluster,” The Lancet, vol. 395, no. 10223, pp.
514–523, Feb. 2020, publisher: Elsevier. [Online]. Available: https://doi.org/10.1016/S0140-6736(20)30154-9
[2] M. Chinazzi, J. T. Davis, M. Ajelli, C. Gioannini, M. Litvinova, S. Merler, A. P. y. Piontti, K. Mu, L. Rossi,
K. Sun, C. Viboud, X. Xiong, H. Yu, M. E. Halloran, I. M. Longini, and A. Vespignani, “The effect of travel
restrictions on the spread of the 2019 novel coronavirus (COVID-19) outbreak,” Science, vol. 368, no. 6489, pp.
395–400, Apr. 2020, publisher: American Association for the Advancement of Science Section: Research Article.
[Online]. Available: https://science.sciencemag.org/content/368/6489/395
[3] A. L. Bertozzi, E. Franco, G. Mohler, M. B. Short, and D. Sledge, “The challenges of modeling and forecasting
the spread of covid-19,” arXiv preprint arXiv:2004.04741, 2020.
[4] G. Giordano, F. Blanchini, R. Bruno, P. Colaneri, A. Di Filippo, A. Di Matteo, and M. Colaneri, “Modelling the
covid-19 epidemic and implementation of population-wide interventions in italy,” Nature Medicine, Apr 2020.
[Online]. Available: https://doi.org/10.1038/s41591-020-0883-7
[5] D. Zou, L. Wang, P. Xu, J. Chen, W. Zhang, and Q. Gu, “Epidemic Model Guided Machine Learning for
COVID-19 Forecasts in the United States,” medRxiv, p. 2020.05.24.20111989, May 2020, publisher: Cold Spring
Harbor Laboratory Press. [Online]. Available: https://www.medrxiv.org/content/10.1101/2020.05.24.20111989v1
12

We adopt the notation (aij ) to denote the matrix whose ij-th element is aij .

11

A PREPRINT - JANUARY 29, 2021

[6] L. Ferretti, C. Wymant, M. Kendall, L. Zhao, A. Nurtay, L. Abeler-Dörner, M. Parker, D. Bonsall, and C. Fraser,
“Quantifying SARS-CoV-2 transmission suggests epidemic control with digital contact tracing,” Science, vol. 368,
no. 6491, May 2020, publisher: American Association for the Advancement of Science Section: Research Article.
[Online]. Available: https://science.sciencemag.org/content/368/6491/eabb6936
[7] W. O. Kermack and A. G. McKendrick, “A contribution to the mathematical theory of epidemics,” Proceedings of
the royal society of london. Series A, Containing papers of a mathematical and physical character, vol. 115, no.
772, pp. 700–721, 1927.
[8] H. W. Hethcote, “The mathematics of infectious diseases,” SIAM review, vol. 42, no. 4, pp. 599–653, 2000.
[9] J. D. Murray, Mathematical Biology: I. An Introduction, 3rd ed., ser. Interdisciplinary Applied
Mathematics, Mathematical Biology. New York: Springer-Verlag, 2002. [Online]. Available: https:
//www.springer.com/gp/book/9780387952239
[10] C. Anastassopoulou, L. Russo, A. Tsakris, and C. Siettos, “Data-based analysis, modelling and forecasting
of the covid-19 outbreak,” PLOS ONE, vol. 15, no. 3, pp. 1–21, 03 2020. [Online]. Available:
https://doi.org/10.1371/journal.pone.0230405
[11] Q. Lin, S. Zhao, D. Gao, Y. Lou, S. Yang, S. S. Musa, M. H. Wang, Y. Cai, W. Wang, L. Yang et al., “A
conceptual model for the coronavirus disease 2019 (covid-19) outbreak in wuhan, china with individual reaction
and governmental action,” International journal of infectious diseases, vol. 93, pp. 211–216, 2020.
[12] R. Li, S. Pei, B. Chen, Y. Song, T. Zhang, W. Yang, and J. Shaman, “Substantial undocumented infection
facilitates the rapid dissemination of novel coronavirus (SARS-CoV-2),” Science, vol. 368, no. 6490, pp. 489–493,
May 2020, publisher: American Association for the Advancement of Science Section: Research Article. [Online].
Available: https://science.sciencemag.org/content/368/6490/489
[13] N. Ferguson, D. Laydon, G. Nedjati Gilani, N. Imai, K. Ainslie, M. Baguelin, S. Bhatia, A. Boonyasiri, Z. Cucunuba Perez, G. Cuomo-Dannenburg et al., “Report 9: Impact of non-pharmaceutical interventions (npis) to
reduce covid19 mortality and healthcare demand,” Imperial College London, Tech. Rep., 2020.
[14] T. Britton, “Stochastic epidemic models: a survey,” Mathematical biosciences, vol. 225, no. 1, pp. 24–35, 2010.
[15] J. Dehning, J. Zierenberg, F. P. Spitzner, M. Wibral, J. P. Neto, M. Wilczek, and V. Priesemann, “Inferring
change points in the spread of COVID-19 reveals the effectiveness of interventions,” Science, May 2020,
publisher: American Association for the Advancement of Science Section: Research Article. [Online]. Available:
https://science.sciencemag.org/content/early/2020/05/14/science.abb9789
[16] H. Kwakernak and R. Sivan, Linear Optimal Control Systems. Willey & Sons. Inc, 1972.
[17] J. L. Lions, Optimal Control of Systems Governed by Partial Differential Equations, ser. Grundlehren
der mathematischen Wissenschaften. Berlin Heidelberg: Springer-Verlag, 1971. [Online]. Available:
https://www.springer.com/gp/book/9783642650260
[18] R. Becker, H. Kapp, and R. Rannacher, “Adaptive finite element methods for optimal control of partial differential
equations: Basic concept,” SIAM Journal on Control and Optimization, vol. 39, no. 1, pp. 113–132, 2000.
[19] L. Ambrosio, N. Gigli, and G. Savaré, Gradient flows: in metric spaces and in the space of probability measures.
Springer Science & Business Media, 2008.
[20] A. Ambrosetti and G. Prodi, A primer of nonlinear analysis. Cambridge University Press, 1995, no. 34.
[21] J. L. McClelland, D. E. Rumelhart, P. R. Group et al., “Parallel distributed processing,” Explorations in the
Microstructure of Cognition, vol. 2, pp. 216–271, 1986.
[22] A. Quarteroni, R. Sacco, and F. Saleri, Numerical Mathematics, 2nd ed., ser. Texts in Applied Mathematics. Berlin
Heidelberg: Springer-Verlag, 2007. [Online]. Available: https://www.springer.com/gp/book/9783540346586
[23] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga, and A. Lerer,
“Automatic differentiation in pytorch,” in NIPS-W, 2017.
[24] P. Cintia, D. Fadda, F. Giannotti, L. Pappalardo, G. Rossetti, D. Pedreschi, S. Rinzivillo, P. Bonato, F. Fabbri,
F. Penone et al., “The relationship between human mobility and viral transmissibility during the covid-19
epidemics in italy,” arXiv preprint arXiv:2006.03141, 2020.

12

