Proceedings of Machine Learning Research ML4H Extended Abstract Arxiv Index:1–6, 2020

arXiv:2008.03323v3 [cs.AI] 30 Nov 2020

COVID-19 in Differential Diagnosis
of Online Symptom Assessments
Anitha Kannan
Richard Chen
Vignesh Venkataraman
Geoffrey Chen
Xavier Amatriain

anitha@curai.com
ricky@curai.com
viggy@curai.com
geoff@curai.com
xavier@curai.com

Curai

Abstract
The COVID-19 pandemic has magnified an already existing trend of people looking for answers to their healthcare concerns online. Symptom checkers are a common approach to provide an online assessment, but the use
of rule-based systems introduces important limitations. This leads to COVID19 symptom checkers not being able to
provide a differential diagnosis. In this
paper we present an approach that combines the strengths of traditional AI expert systems with novel deep learning
models to leverage prior knowledge as
well as any amount of existing data.
We combine synthetic data generated
from an expert system with real-world
data coming from an online COVID-19
symptom checker to train a COVID-19
aware differential diagnosis deep learning model and show that our approach
is able to accurately model new incoming data about COVID-19 while still
preserving accuracy on other diagnosis.

1. Introduction
AI has been connected to medicine since almost its inception when expert systems designed by doctors were introduced as medical decision support tools. Modern online
COVID-19 symptom checkers, which share
the same underlying rule-based approach,

are not able to provide a holistic diagnostic of the patient. In other words, they cannot tell the patient that e.g. while they are
unlikely to have COVID-19 they should instead worry about strep throat. This highlights one of the main shortcoming of expert
systems: they are hard to scale and lack flexibility since adding a new condition requires
re-tuning the system mostly manually. A
very different approach to building diagnosis models is to use data to machine learn
a model (see Shickel et al. (2017) for example). Large data repositories can be mined
to automatically learn fine-grained diagnosis
models that can be easily extended and updated as new data becomes available. On the
flip side, these models will only be as good
as the data on which they are trained. This
becomes particularly limiting in a situation
like the current one in which data is hardly
available and of limited quality.
In this paper we address the question of
whether we can quickly learn a generalizable
diagnosis model when a new condition like
COVID-19 appears. We present a machine
learning approach to quickly enhance an existing AI diagnosis model to incorporate a
novel disease like COVID-19. We show that
the resulting model is accurate in including
COVID-19 in the differential diagnosis, without losing accuracy for other diseases. Fi-

© 2020 A. Kannan, R. Chen, V. Venkataraman, G. Chen & X. Amatriain.

COVID-19 in Differential Diagnosisof Online Symptom Assessments

nally, we also show that the approach is eas- version of the QMR knowledge base Miller
ily extensible as new evidence about the new and Masarie Jr (1990) that consists of 830
diseases and 2052 findings (covering sympdiseases are surfaced.
toms, signs, and demographic variables),
2. Datasets used in this study
and their relationships. We sample cases on
Dataset from COVID-19 assessment a per-disease basis (c.f.(Parker and Miller,
tool (COVID-Assessment) : We have ac- 1989; Ravuri et al., 2018)). Unlike in prior
cess to a publicly deployed virtual diagnostic works, we label each case as a distribution
assessment tool (Appendix B, Fig. 1). This over the possible diagnosis by using the
tool guides users through a comprehensive inference algorithm of the expert system. In
set of clinical questions to determine the like- the end, we simulate 65,000 clinical cases
lihood of COVID-19 infection and associated corresponding to 437 diseases covering 1418
complications from the disease. The users on findings, with each disease having at least
this system are also optionally connected to 50 clinical cases. Details of the algorithm
a practitioner for further evaluation of their and examples of clinical cases are provided
risk. Questions in the assessment is based in Appendix C.
on guidance provided by the United States
Centers for Disease Control and Prevention
(CDC), and hence elicits information regarding clinical factors including demographic information, symptoms, COVID-19 exposure
risks and medical history of the patient. For
example, a younger user with a weakened immune system with a recent exposure to the
virus would likely have milder or no symptoms as compared to an older user with lung
disease with exposure seven days prior to undergoing the assessment.
We used the derived dataset from this tool
to build a dataset of COVID-19 clinical cases.
In particular, the assessment flow that resulted in medium or high risk are considered as positive examples of COVID-19 (Appendix B, Fig. 5 for example cases). We
used two variants of data gathered by the
assessment. In one variant, we restricted to
only findings (symptoms) that are also part
of the expert system, and in another variant,
we used all the findings (findings unique to
COVID-19 in Appendix B tbl. 6). In total,
we have 100 clinical cases from this dataset
of which we use 70:30 split for training and
evaluation.
Dataset from expert system (Simfrom-Expert-System) : We use an extended

Semigran: This a publicly available dataset
Semigran et al. (2015) on which over fifty online symptom checkers were evaluated. The
dataset consists of 45 standardized patient
clinical vignettes, corresponding to 39 unique
diseases. We used the simplified inputs
provided along with the clinical vignettes,
as previously used in other studies Razzaki
et al. (2018); Kannan et al. (2020). This
dataset has been studied in Fraser et al.
(2018) where twenty medical experts studied each case and came to consensus, results
of which we report in tbl. 1.
For training the model, we use COVIDAssessment and Sim-from-Expert-System.
Combining these two sources allows the consideration of COVID-19 in a differential diagnosis whenever appropriate while also modeling competing hypothesis. For evaluation,
we use Semigran and 30% of data from
COVID-Assessment.

3. Approach
Notation: Let F = {f1 , · · · , fK } be the universe of findings/symptoms (e.g ‘eye pain’,
‘nausea’) that can be elicited from the patients. Let Y = {1, ..., L} be the universe
of diagnoses (e.g. ‘COVID-19’, ‘arthritis’
2

COVID-19 in Differential Diagnosisof Online Symptom Assessments

jected to a fully connected layer. After a log
soft-max transformation, this is additively
combined with log softmax transformation of
demographic variable representation.
The embedding vectors for the nondemographic findings are initialized randomly in the range [-.05,.05] and dropout
of .7 to regularize the model. Models are
trained with minibatches of size 512 usX
p(y|x)
DKL (p k g) =
p(y|x) log(
) (1) ing ADAM with initial learning rate of
g(x)[y]
y∈Y
0.01, and trained for fixed number of fifteen
This optimizes to capture all disease labels y epochs. Models implemented using PyTorch
for which p(y|x) > 0, potentially at the ex- is trained on single NVIDIA Tesla K80 GPU.
pense of some erroneous diagnosis. However,
this is the correct thing to do in differential 4. Experiments
diagnosis when there is only partial informaMetrics: We report top-k accuracy a.k.a
tion - to err on the side of over prediction
recall@k (k ∈ {1, 3, 5}). When evaluating
than as failure to consider any potential dismodel performance on cases from COVIDease. When the ground truth label is a single
19 assessment data, we report accuracy of
disease, KL divergence is same as the cross
predicting COVID-19 within top-k.
entropy criterion.
Model variants: Ours-BASE is trained with
Model architecture: The model for g(x)
Sim-from-Expert-System to re-establish that
has separate input streams for the demoexpert systems can be modeled as data prior
graphic and non-demographic input findings.
through simulation. Ours-BASE-COVID uses
Demographic variables, such as the gender
Sim-from-Expert-System and training set of
and age, impose an implicit prior over disCOVID-Assessment, while ensuring that the
eases that are impossible, and serves as botuniverse of findings F is same as Ours-BASE.
tle neck for diagnoses based only on the nonOurs-BASE-COVID-FULL is same as Oursdemographic variables. As examples, its alBASE-COVID but all symptoms are used.
most impossible for an infant to be diagnosed
with ‘dementia’, or a biologically male pa4.1. Results
tient with ‘pregnancy’. When a biologically
male patient have symptoms of nausea and Approach efficacy: Table 1 compares our
vomiting, these priors guide the model (espe- model to existing published results on Semcially in early iterations) to correctly place igran dataset. Ours-BASE performs best
close to zero probability mass over women- across all models, closing the gap with the
related health issues. We use dense trainable AI expert system that was used to simuL-dimensional embeddings initialized with late the datase, while re-establishing that expert systems as a data prior continues to
uniform prior over all plausible diseases.
Non-demographic findings are separately hold in new settings, with different datasets
modeled for their presence and absence and machine learning model. Adding the exstate. Each finding-state is a 1024 embed- tra disease label (COVID-19) does not deding space followed by dropout for regular- teriorate the performance as evidenced by
ization. Then, the embeddings for all the ob- Ours-BASE-COVID. We also analyzed test
served findings are average pooled and pro- cases with (22 cases) and without (23 cases)
and ‘common cold’) A clinical case is set
of findings x = xpos ∪ xneg and p(y|x).
xpos ∈ F and xneg ∈ F are findings that are
present and explicitly absent, respectively,
while p(y|x) captures the uncertainty in diagnosis (differential diagnosis).
Loss function: We use Kullback-Leibler divergence from g(x) to p(y|x)

3

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Approach

top-1

top-3

Human-Doctors Fraser et al. (2018)
AI expert system
Razzaki et al. (2018)
Kannan et al. (2020)

72.1%
66%
46.6%
50.67% (1.86)
67.6% (.023)
61.8% (.029)
65.5% (.012)

84.3 %
75%
64.67%
75.11% (1.86)
85.8% (.025)
84.4% (.027)
84.4% (.041)

Ours-BASE
Ours-BASE-COVID
Ours-BASE-COVID-FULL

top-5
86%
82.22% (1.56)
92.9% (.009)
93.3% (.000)
93.3% (.000)

Table 1: Comparison on Semigran dataset. Standard deviation (in brackets) computed
on five models trained with random initialization. Razzaki et al. (2018) considered only 30 clinical cases and we extrapolated assuming remaining 15 cases were
wrongly diagnosed. For qualitative comparisons, please see Appendix A Tbl. 3

top-k

Ours-BASECOVID

Ours-BASECOVID-FULL

1
3
5

40%
60%
73%

87%
100%
100%

eases. On examining cases where COVID19 was not part of its prediction, we found
these to mainly correspond to those cases
where input findings do not sufficiently overlap with the modeled findings in Ours-BASECOVID, which is overcome by Ours-BASECOVID-FULL that uses all the findings.

Table 2: Comparison on COVID assessment 5. Conclusions
data. Ours-BASE and AI expert
In this paper we have presented a novel apsystem will have 0%. Qualitative
proach to quickly enhance a diagnosis model
examples in Appendix A Tbl. 4
that is effective even when a new previously unknown condition appears and compromises prior medical knowledge. Our apoverlapping symptoms with COVID-19 and proach combines the strengths of two very
found that performance drop in comparison different AI formulations: traditional expert
to Ours-BASE is only caused by cases with systems, with state-of-the-art deep learning
overlapping symptoms. Ours-BASE-COVID- models. We leverage expert systems as a
FULL with additional COVID-19 findings do way to input prior knowledge into the learned
not change the prediction accuracy as much model as synthetic data, and use deep learnas Ours-BASE-COVID as it can use these ad- ing to learn a generalizable model on the
ditional findings specific to COVID-19.
combination of old and new data. Our model
COVID-19 in differential diagnosis is able to capture the nuances of a new condiTable. 2 compares the performance of tion like COVID-19 without losing the preOurs-BASE-COVID and Ours-BASE-COVID- existing medical knowledge accumulated in
FULL on COVID-Assessment tsst dataset. the expert system. Our paper also demonBy including COVID-19 in 73% of the cases, strates the efficiency of the approach even in
Ours-BASE-COVID establishes that it can situations where there is little data available
model COVID-19 in the light of other dis- to model new diseases.
4

COVID-19 in Differential Diagnosisof Online Symptom Assessments

References

diagnosis and triage: audit study. BMJ,
351:h3480, 2015.

Hamish Fraser, Enrico Coiera, and David
Wong. Safety of patient-facing digital
symptom checkers. The Lancent, 392,
B. Shickel, P. Tighe, A. Bihorac, and
2018.
P. Rashidi. Deep ehr: A survey of recent advances on deep learning techniques
Anitha Kannan, Jason A. Fries, Eric
for electronic health record (EHR) analKramer, Jen Jen Chen, Nigam Shah, and
ysis. arXiv:1706.03446, abs/1706.03446,
Xavier Amatriain. The accuracy vs. covJune 2017. URL http://arxiv.org/abs/
erage trade-off in patient-facing diagnosis
1706.03446.
models. AMIA Informatics Summit, 2020.
Randolph A Miller and Fred E Masarie Jr.
Quick medical reference (qmr):
A
microcomputer-based diagnostic decisionsupport system for general internal
medicine. In Proceedings. Symposium on
Computer Applications in Medical Care,
Appendix A. Qualitative results
pages 986–988, 1990.
Tbl. 4 provides qualitative examples comparing the three models on the data from
COVID-19 assessments. These are cases
with low to moderate risk of contracting
COVID-19.
Ours-BASE and Ours-BASECOVID considers only the findings in column 1 as inputs, while Ours-BASE-COVIDFULL use the union of the first two columns
as input. In the final example, as observed in
Semigran cases, Ours-BASE-COVID differential diagnosis is consistent with Ours-BASE.
However, once the model gets an added input of the patient being a healthcare worker,
Ours-BASE-COVID-FULL includes COVID19 in one of its top 5 position.

R. C. Parker and R. A. Miller. Creation of
realistic appearing simulated patient cases
using the internist-1/qmr knowledge base
and interrelationship properties of manifestations. Methods of information in
medicine, 28:346–51, 12 1989.
Murali Ravuri, Anitha Kannan, Geoffrey J.
Tso, and Xavier Amatriain. Learning from
the experts: From expert systems to machine learned diagnosis models. Machine
Learning for Health Care, 2018.
Salman Razzaki, Adam Baker, Yura Perov,
Katherine Middleton, Janie Baxter,
Daniel Mullarkey, Davinder Sangar,
Michael Taliercio, Mobasher Butt, Azeem
Majeed, Arnold DoRosario, Megan Mahoney, and Saurabh Johri. A comparative
study of artificial intelligence and human
doctors for the purpose of triage and
diagnosis. CoRR, abs/1806.10698, 2018.

As an example, consider first example in
tbl. 3. Ours-BASE-COVID includes COVID19 in the differential because of the overlapping findings between viral respiratory infections and COVID-19. In contrast, in second
example, with symptoms such as neck stiffness, severe headache and photophobia, the
Hannah L Semigran, Jeffrey A Linder, model continues to maintain its prediction to
Courtney Gidengil, and Ateev Mehrotra. be more close to the differential diagnosis of
Evaluation of symptom checkers for self Ours-BASE.
5

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Figure 1: Example screenshots from publicly deployed COVID-19 assessment flow from which the data for
our work is derived.

Appendix B. COVID-Assessment
In Fig. 1 we provide the screenshots from an
online telehealth service from which we obtained the COVID assessment data. Tbl. 5
provides examples of COVID-19 cases that
we generated from this tool. Tbl. 6 provides the list of findings that are uniquely
present in this dataset, which is included in
the model Ours-BASE-COVID-FULL.

Appendix C. Sim-from-Expert-System
In Algorithm 1, we provide more details
into the algorithm for clinical case simulation
from expert system. While the simulation
starts with a single disease, the algorithm itself returns the differential diagnosis, as opposed to the initial starting disease. Differential diagnosis consists of rank-ordered list
of diseases, along with their scores under the
expert system’s inference algorithm. Tbl. 7,
provides qualitative examples from the simulation.

6

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Findings
30 y/o m
2 day HX of runny nose
sore throat
hot, sweaty
mild headache
cough with clear sputum
muscle aches
no fever or neck stiffness

18 y/o m
3 days severe headache
fever
photophobia,
neck stiffness

Findings in our feature space
male
young adult (18 to 40 yrs)
brief (6-48 hours)
nose discharge
sore throat
sweating increase
headache
productive cough
generalized myalgia
no fever
no neck stiffness
male
young adult (18 to 40 yrs)
severe headache
fever
photophobia
neck stiffness

Label

Ours-BASE

Ours-BASE-COVID

viral upper respiratory

viral upper respiratory (0.415)
influenza (0.298)
acute sinusitis (0.044)
streptococcal pharyngitis (0.028)
bacterial pneumonia (0.026)

viral upper respiratory (0.257)
influenza (0.218)
COVID-19 (0.181)
streptococcal pharyngitis (0.029)
opioid withdrawal (0.022)

meningitis

meningitis (0.869)
West Nile fever (0.102)
Rocky Mountain spotted fever (0.009)
influenza (0.005)
relapsing fever (0.002)

meningitis (0.771)
West Nile fever (0.200)
Rocky Mountain spotted fever (0.009)
influenza (0.005)
epidemic myalgic encephalomyelitis (0.002)

Table 3: Sample model predictions for examples from Semigran. Column 1-2 correspond
to set of findings provided in Semigran et al. (2015) and their transformation to
findings understood. Column 3 is the ground truth label. Columns 4-5 are the
top 5 diseases predicted by models and the corresponding probabilities. We can
see that for the first example with ‘viral upper respiratory infection’, COVID-19
is in the top-5 diseases under Ours-BASE-COVID.

Common symptoms
male
young adult (18 to 40 yrs)
fever
cough
female
young adult (18 to 40 yrs)
chest pain
cough
dyspnea
nasal congestion
female
middle age (41 to 70 yrs)
cough
sore throat
nasal congestion
foreign travel history
female
middle age (41 to 70 yrs)
generalized myalgia
headache
neck stiffness

Specific to Ours-BASE-COVID-FULL

Ours-BASE

Ours-BASE-COVID

Ours-BASE-COVID-FULL

prolonged exposure to
person with confirmed COVID-19 case
(but not close contact)

influenza (.882)
bacterial pneumonia (.073)
common cold (0.029)
acute sinusitis (0.006)
asthma (0.006)

influenza (.779)
bacterial pneumonia (.131)
COVID-19 (0.038)
common cold (0.022)
asthma (0.015)

COVID-19 (0.761)
influenza (.106)
bacterial pneumonia (0.06)
common cold (0.018)
acute sinusitis (0.012)

dyspnea at rest
been in Europe in the past
14 days prior to the onset of symptom

pulmonary embolism (.372)
chronic bronchitis (.213)
asthma (0.198)
bacterial pneumonia (0.101)
influenza (0.051)

pulmonary embolism (.258)
asthma (0.216)
chronic bronchitis (.182)
bacterial pneumonia (0.151)
influenza (0.060)

COVID-19 (0.492)
pulmonary embolism (.088)
acute bronchitis (.084)
asthma (0.076)
bacterial pneumonia (0.064)

None

common cold (0.843)
infectious mononucleosis (0.064)
influenza (0.029)
measles (0.018)
acute sinusitis (0.01)

COVID-19 (0.977)
common cold (0.015)
measles (0.003)
infectious mononucleosis (0.001)
influenza (.0003)

COVID-19 (0.770)
common cold (0.145)
infectious mononucleosis (0.032)
measles (0.0165)
influenza (.010)

hospital personnel

West Nile fever (0.356)
bacterial meningitis (0.305)
Saint Louis encephalitis (0.249)
Lyme disease (0.069)
Rocky Mountain fever(0.005)

Saint Louis encephalitis (0.341)
West Nile fever (0.308)
bacterial meningitis (0.247)
Lyme disease (0.073)
Rocky Mountain fever(0.011)

Saint Louis encephalitis (0.398)
West Nile fever (0.320)
Lyme disease (0.078)
COVID-19 (0.053)
bacterial meningitis (0.031)

Table 4: Model predictions (along with scores) for test data from COVID-19 risk assessment. Column 1 corresponds to findings used as input in all three models. Column
2 are the additional findings used by only Ours-BASE-COVID-FULL.

7

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Moderate COVID-19 risk
• male, middle age (41 to 70 yrs), nasal congestion, nose discharge, been in Japan in
the past 14 days prior to the onset of symptoms prolonged exposure to person with
confirmed COVID-19 case (but not close contact)
• female, middle age (41 to 70 yrs), lightheadedness, dyspnea, chest pain, dyspnea, exertional, foreign travel history, hospital personnel, dyspnea at rest
Low COVID-19 risk
• female, middle age (41 to 70 yrs), cough, headache, hospital personnel, cigarette smoking, nose discharge
• male, middle age (41 to 70 yrs), lightheadedness, cough , nasal congestion, sore throat,
headache, hospital personnel, nose discharge
Table 5: Examples of cases from COVID assessment flow.

in China in the past 14 days prior to symptoms onset
in Europe in the past 14 days prior to symptoms onset
in Iran in the past 14 days prior to symptoms onset
in Japan in the past 14 days prior to symptoms onset
dyspnea at rest
hospital personnel
exposure to COVID- 2019 within the last 14 days
from symptom onset
healthcare contact with confirmed COVID-19 case
not using any personal protective equipment
household contact with confirmed COVID-19 case
prolonged exposure to person with confirmed COVID-19 case
(but not close contact)
recent close contact with a person with
symptomatic confirmed COVID-19 case

Table 6: Findings unique to COVID-19 assessment data, in comparison to data simulated
from expert system.

8

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Algorithm 1: Clinical case simulation using expert system
Input: Medical knowledge base of diseases (D) and findings (F). Term-frequency
F REQ(d, f ) with d ∈ D and f ∈ F; number of cases T. Expert Inference engine
ExpertInf erence that takes us input a set of findings and provides the differential diagnosis.
Output: {fpos (t) , fneg (t) , ddx(t) }Tt=1 pairs. ddx is differential diagnosis consisting of top
K pairs of (y ∈ D, s ≥ 0) .
for t = 1 to T do
y ∼ U nif orm(D∗ ) {Candidate disease label for this case}
f (t) ← ∅
F ∗ = sort(F, F REQ(y, :))
for f ∈ Demographics(F) do
if f ∈ F ∗ and rand() > F REQ(f, y) then
fpos (t) ← fpos (t) ∪ {f }
F ∗ ← RemoveMutex(F ∗ , fpos (t) )
end if
end for
L = randint(5, |F ∗ |) + |fpos (t) |
F ∗ ← F \ Demographics(F)
while |f (t) | ≤ L do
f ∗ ← GetNext(F ∗ )
if F REQ(f, y (t) ) ≥ .2 and rand() < F REQ(f, y (t) ) then
fpos (t) ← fpos (t) ∪ {f ∗ }
F ∗ ← F ∗ \ {f ∗ }
F ∗ ← RemoveMutex(F ∗ , fpos (t) )
else if F REQ(f, y (t) ) < .2 and rand() > 0.75 then
fneg (t) ← fneg (t) ∪ {f ∗ }
F ∗ ← F ∗ \ {f ∗ }
end if
end while
ddx(t) ← ExpertInference(fpos (t) , fneg (t) )
end for

9

COVID-19 in Differential Diagnosisof Online Symptom Assessments

Findings
female
young adult (18 to 40 yrs)
few days (2-7 days)
cough
productive cough
malaise
fever
nose discharge
male
middle age (41 to 70 yrs)
prolonged (1-4 weeks)
foot pain
heel pain
movement pain
walking pain
limping
female
middle age (41 to 70 yrs)
chronic (> 4 weeks)
urinary urgency
change in bladder habits
nocturia
urinary frequency

Differential Diagnosis

bacterial pneumonia (26.9)
influenza (23.4)
acute sinusitis (22.9)

plantar fasciitis (38.9)
stress fracture (31.5)

female urethritis (32.9)
overactive bladder (26.9)

Table 7: Examples of clinical cases using
simulation from expert system.
Raw scores (shown) converted to
probabilities using softmax.

10

