Hostility Detection and Covid-19 Fake News
Detection in Social Media
Ayush Gupta∗ , Rohan Sukumaran1∗ , Kevin John2∗ , and Sundeep Teki
1

PathCheck Foundation, Cambridge
Indian Institute of Information Technology, Sri City, India
ayush.goc@gmail.com, {rohan.s16, kevin.j17}@iiits.in,
sundeep.teki@gmail.com,

arXiv:2101.05953v1 [cs.CL] 15 Jan 2021

2

Abstract. With the advent of social media, there has been an extremely
rapid increase in the content shared online. Consequently, the propagation of fake news and hostile messages on social media platforms has also
skyrocketed. In this paper, we address the problem of detecting hostile
and fake content in the Devanagari (Hindi) script as a multi-class, multilabel problem. Using NLP techniques, we build a model that makes use of
an abusive language detector coupled with features extracted via Hindi
BERT and Hindi FastText models and metadata. Our model achieves
a 0.97 F1 score on coarse grain evaluation on Hostility detection task.
Additionally, we built models to identify fake news related to Covid-19
in English tweets. We leverage entity information extracted from the
tweets along with textual representations learned from word embeddings
and achieve a 0.93 F1 score on the English fake news detection task.
Keywords: Hostility Detection, Hate Speech, Fake News, Misinformation, COVID-19, Infodemic, Social Media, Devanagari

1

Introduction

With the proliferation of social media platforms, information dissemination knows
no bounds. The public discourse that occurs on social media platforms leads to a
lot of information being shared and consumed, that more often than not, cannot
be verified as hostile free content or fact-checked for authenticity. Usually, such
harmful content is used to defame and hurt people, especially from minority
groups, specific countries, the LGBTQ community, and several other organizations. Recently, as the COVID-19 pandemic is devastating humanity, hostile content and misinformation on social media have transformed into an “Infodemic”,
further expediting the need for control of such content. This being said, fake
news and hostility detection are daunting tasks owing to the context, domain
knowledge, and the inherent complexity of the natural language constructs, like
different forms of hatred, target groups, ambiguous word representations, and
more, are required to understand it.
1

*Denotes equal contribution.

2

Gupta, Sukumaran, John and Teki

In this paper, as part of the Shared Task organized in CONSTRAINT 2020
[1,18,19], we look at fake news detection for English and Hindi (Devanagari )
tweets, as well as hostility detection for Hindi tweets. We evaluated machine
learning and deep learning models and propose an ensemble model that combines
language representations with the features (linguistic and otherwise) extracted
from the data. Furthermore, we measure the differential impact of each feature
and also notice that our model was able to provide the correct annotation for a
few of the miss-annotated samples in the English fake news dataset, opening up
to possibilities of weak supervision for labeling.
Our contributions in this paper are primarily the identification of entities
pertinent to fake news detection and data analysis steps that can be taken to
understand such micro-blogging data. We show that a lightweight ensemble of
Word2Vec [15] coupled with entity information gives better performance in English fake news detection than larger BERT [6] based models. Our ensemble
model achieved 0.93 F1 score (above the baseline scores). Furthermore, we
perform Hostility detection by ensembling models based on Hindi BERT and
Hindi FastText. Further, we create various simple but effective text features
extracted from the tweets to be fed in the model and also compile a list of abusive words that are used in an abusive words detector, which further boosts the
accuracy. Our methods obtained a weighted F1 score of 0.97 in coarse-grain
classification for Hostility task and ranked 5th out of 45 teams. For the finegrain classification, our model obtained a weighted F1 of 0.62 and ranked 7th
out of 45 teams.

2

Related Works

Riedel et al., (2017) [20] used TF-IDF similarity scores between the title of the
news and the content concatenated with the corresponding TF-IDF vectors. This
was further fed into a fully connected neural network. Albeit impressive results,
this approach is not useful for identifying fake news that is spreading via microblogging sites. Further, work from Khatter et al. (2019) [9] looks at solving the
problem using a multimodal approach. The authors make use of a Variational
Autoencoder to learn the representation of a social media post, combining the
textual and image representations. More recent work from Lee et al. (2020) [12]
utilizes a language model as a zero-shot fact-checker. A masked language model
(MLM) training followed by entailment check is adapted. The model is tested
in a closed-book setting. The results look promising but require the presence
of large scale fact-based data to enable such training. Vijjali et al. (2020) [22]
looked at the problem of claim verification by following a two-stage pipeline. The
paper uses a combination of BERT [6] and ALBERT [11] models - for identifying
explanations based on the claims from a large dataset and checking if the claims
are entailment of the explanations.
Bohra et al. (2018)[3] uses various linguistic features such as character, word,
and lexicon-based features on Hindi-English code-mixed tweets into Hate speech
or Normal speech and attain 71.7% accuracy with an SVM model. In [24] the

Hostility Detection and Covid-19 Fake News Detection in Social Media

3

authors use sentiment analysis to detect bullying in tweets and Latent Dirichlet
Allocation (LDA) topic models [2]. Also, hate speech detection is a widely studied
topic [7,10] with most of the work focused on developing binary classification
models for English.
Research in Hostility detection is more focused on learning the discriminatory features via Deep Learning models instead of relying on hand-crafted
features. Bhardwaj et al. (2020) [1] computes input embedding with help of a
pre-trained multilingual BERT(m-BERT) model[6],and is then fed into several
machine learning models like Random Forest (RF), SVM, and Linear Regression (LR). Hostility detection on Devanagari is scant, and we apply Hindi FastText and mBERT embeddings for hostility detection in Hindi; the classes for
fine-grain classification: Hate, offensive, Defamation, Fake, and non-hostile, and
coarse-grain classification: Hostile or non-hostile.

3

Method

3.1

English Fake News

Preprocessing As the data in Patwa et al. (2020) [19] are based on tweets
scraped from the internet - abbreviations, social media lingo, URLs amongst
other tokens are present in the dataset. The dataset contained an almost 5050 split of real and fake tweets in train, validation and test. In order to create
embeddings from the data using Word2Vec[15], FastText[4], BERT[6] and many
more, we used multiple preprocessing steps. The data was initially rid of contractions, for instance - y’all → you all, how’re → how are,and so on. These

Fig. 1: Data and modeling pipeline for English Fake News detection

contractions were identified through a combination of regex pattern matches
and simple rules. Further, occurrences of URLs, mentions, emojis, numbers and
so on were cleaned and removed with the help of tweet-preprocessor3 library,
the punctuation and special characters were stripped and the remaining text
was tokenized with the help of NLTK libraries.
3

https://pypi.org/project/tweet-preprocessor/

4

Gupta, Sukumaran, John and Teki

Rule-based models Based on data analysis we observed that length of tweets,
number of hashtags, number of mentions, etc. had a statistically significant impact in the class labels. All such similar patterns specific to the dataset were
analysed and added as features to the model.
Distributional embeddings Using distributional word embeddings like Word2Vec
[15], FastText [4] etc. has seen huge success in text classification. Word2Vec being a word level embedding suffers from the issue of Out Of Vocabulary (OOV)
distributions. To mitigate this, an often adapted strategy is making use of subword level embeddings like FastText, BERT and more. All these models were
used to convert raw text into a fixed-length embedding vectors.
Adding entity-based information using Bag of Words (BoW) The data
has significant presence of entities like names of government bodies, scientific
journals, places, organizations, etc and the distribution varies per class. Using
TF-IDF based rankings, we built a Bag of Words (BoW) feature vector. This
would indicate the presence or absence of each of the corresponding terms in a
given sentence.
Contextual embeddings - BERT based models Transformer models [21]
like BERT [6], RoBERTa [14], ALBERT [11], ELECTRA [5], have shown success
on NLP tasks like text classification, question answering sequence labeling and
more. We make use of these models to find meaningful representations of the
input sentences.
Ensemble model The idea behind the ensemble technique is to leverage the
performance and robustness captured by the different models. Ensembling can
be done using a range of methods from using a logical OR/logical AND operation
over the “n” models’ predictions, to using fully connected neural network layers
to learn the representations of the models. Here, we also combine the metadata
(length of tweet, number of mentions, etc.) and Bag of Words along with the
predictions from different models, into a single vector representation and fed
into a fully connected neural network for ensembling. The overview of the data
pipeline is mentioned in Figure 1.
3.2

Hostility and Fake News Detection Hindi

Problem Formulation The Devanagari dataset demanded a coarse grained
evaluation (Hostile or not) as well as a fine grained one(Non-Hostile, Hate, offensive, Fake and Defamation).
Data and Preprocessing Data distribution can be seen from Table 1. Prior
to training the models, we perform a few preprocessing steps as follows:

Hostility Detection and Covid-19 Fake News Detection in Social Media

Fake
Train 1144
validation 160
Test
334
Overall 1638

Hostile posts
Hate Offensive Defame
792
742
564
103
110
77
237
219
169
1132
1071
810

5

Non-Hostile
Total
2678
376
780
3834

3050
435
873
4358

Table 1: The data distribution for Hindi Hostility Dataset.

– Tokenization and removal: We designed a tweet-tokenizer to parse and
remove every username-mention, hashtags, and URLs present.
– Stopword Removal: Tokenized tweets were passed through a customized
stop word removal for the Hindi language.
– Emoji Removal: Demoji library4 was used to identify and remove emojis.
– Tweet cleaning: Removes all punctuation, new line, Unicode characters
(u200B, u200C, u200D) which are zero-length white spaces.
Baseline Classifier As baselines, we experiment with three broad representations. (1)TF-IDF (2)mBERT Embedding (3)FastText Embedding
TF-IDF feature TF-IDF as the basic approach for text representation is widely
used to score words thus helping in applications like text classification, topic
modeling, etc. We clean the tweets by passing them through the above four
preprocessing steps. The feature vector created from the clean tweets is passed
into the machine learning models.
mBERT Embedding The initial baseline was defined by using the multilingual
BERT (m-bert) model [13] to handle the Hindi data. We use the approach defined
by the authors[1] to replicate the results for baseline. The preprocessing was a
four-step process, defined in the previous subsection. We calculate the word
embedding for each sentence in a tweet by tokenizing it and passing through the
embedding matrix defined using the mBERT model. We use sentence embeddings
as a feature for machine learning models.
FastText Embedding FastText5 is an open-source, lightweight library trained
on 157 different languages, that allows users to learn text representations and
text classifiers. FastText treats each word as a composition of character n-grams
thereby the word representation is created by the sum of the character n-gram
representations. The method of calculating sentence embedding is the same as
described in the previous section.
4
5

https://pypi.org/project/demoji/
https://fasttext.cc/

6

Gupta, Sukumaran, John and Teki

Feature Identification and Extraction The feature Extractor module is
used to identify and extract linguistic features from a given natural unstructured tweet. The feature Extraction module leverages several natural language
processing (NLP) and regex techniques to extract these features. We have categorized them broadly into the following 3 modules: a) Abusive Language Detector
b) Username Mention, URL, and Hashtag count c) Emoji Detector.
Abusive Language Detector We hypothesize that giving a count of abusive
words as a feature to the classification model boosts the accuracy in detecting
offensive tweets. To validate our hypothesis, we manually curated a list of commonly used 84 profane words in Hindi. We measure the presence of these profane
words per tweet and use this count as a feature for the classification model.
Username Mention, URL, and Hashtag counter On analyzing the dataset,
we found that on an average there were more hashtags and URLs in the nonhostile tweets as compared to the hostile ones, whereas there are more user
mentions in the Hate tweets. Informed by this, we hypothesize that the user
mention, presence of URL or Hashtag can have differential impact on the finegrain classes (Hate, Offensive, Fake, and Defamation). Therefore we design a
rule-based method to parse each tweet to extract the count of the occurrence of
these entities and use the count as an input feature.
Emoji Detector The inherent nature of micro-blogging(short messages) has
made people use acronyms, emoticons, and various other special characters to
express their message. We hypothesize that the use of emoji as a feature for
hostility detection could increase the accuracy, as similar results were observed
in sentiment analysis[23]. To validate this hypothesis, we use the demoji library
to extract all the emojis present in the tweet and pass the count corresponding
to each tweet as a feature to the classification model along with other features.

Fig. 2: Data and modeling pipeline for Hindi Hostility Classification

Hostility Detection and Covid-19 Fake News Detection in Social Media

7

FastText based LSTM + FastText Classifier FastText represents a text by
average of word vector and it also allows the word vector to be updated through
back-propagation while training. FastText classifier uses (multinomial) logistic
regression for training on the vector average and leverages Hierarchical Softmax
to reduce computational complexity. We pass the cleaned training data to the
FastText, and use grid search to find the optimal hyperparameter for the model.
For the multi-label classification we use one-vs-all strategy.
FastText based LSTM + Features In this paper, we built the hostility
classification model using the LSTM[8] model with FastText embedding and
metadata. We use the LSTM model owing to its internal memory to process
long-range dependencies in sequential inputs like tweets. This model takes two
inputs, the first being V = {v1, v2, ..., vn} the FastText Embedding, where each
vi represents a cleaned tweet in vector space and the second MD = {A, E, H, M,
U} the 5-tuplet metadata representation where A, E, H, M, U are the count of
abusive words, emoji, hashtag, mention, and URL per clean tweet respectively.
We use keras6 to define and train our model.
BERT-Hindi Embedding with BERT model Recent papers using BERT
based contextual embedding models have shown SOTA performance in Hostile
language identification[16,17]. We use Hindi-BERT pre-trained model7 and finetune it on our dataset. The Hindi BERT model has 12 hidden layers, with an
encoding layer of 256 dimensions instead of 786, the model has 4 attention heads
for each attention layer. The dimension of the feed-forward layer is kept as 1024
instead of 3072 which is the default in BERT models. We find the best learning
rate (i.e., 1.2e-4 here) for the model by simulating the training data briefly with
different learning rates and choose the one with minimum loss. For training, we
pass the preprocessed tweets into the BERT model and train the model for 12
epochs with a batch size of 8.
Ensemble Model In this approach, we ensemble three base classifier, which are
FastText Embedding with FastText classifier, FastText Embedding with LSTM
model, and Hindi BERT Embedding with BERT model. The whole framework
of ensemble setting is illustrated in Fig. 2. Each of the base classifier is explained
in the above subsection. The final classification is made by fusing the outputs of
all three base classifiers through majority voting.

4

Experiments

4.1

English Fake News

Models We experimented by using the word embeddings extracted from FastText and Word2Vec and we used the mean of these word embeddings of the tweet
6
7

https://keras.io/
https://huggingface.co/models

8

Gupta, Sukumaran, John and Teki

as input to the machine learning models, as shown in Figure 1. By examining
the predictions of our best models, we noticed a pattern of misclassification. In
order to mitigate this, we include entity level information extracted from the
data.
TF-IDF scoring for entities We used a scoring factor to determine useful
words to be included in the BoW method by first calculating the tf-idf of misclassified tweets in the validation data separated by the class(real/fake), and
then comparing those scores with the TF-IDF scores in the train data separated by class(real/fake). For a real Tweet misclassified in validation data, let
Vr be the TF-IDF score of a word among the real misclassified tweets. Let Tr
and Tf be the TF-IDF score of a word from the real and fake tweets in train
respectively. Further, we find words which have high scores for Vr and Tr while
simultaneously have low scores of Tf to included these words to the BoW feature
vector.
Contextual Embedding Owing to the success of BERT based models in a
suite of NLP tasks, we calculated the contextual embeddings constructed from
BERT. This embeddings, concatenated with the meta features as shown in Fig
1, was further fed as input to the machine learning or deep learning models.
4.2

Hindi Hostility Detection and Fake News

We set up our experiment in three parts. Firstly, for baseline accuracy, embeddings - TF-IDF, mBERT, and Hindi FastText - and models - RF, LR, SVM,
Gradient Boosting(GB), MLP - are set up. We use grid search for hyperparameter tuning. The results of the baseline classifiers are shown in Table 3 in the
TF-IDF, mBERT, FastText sections.
Secondly, we do an ablation study to determine the effectiveness of the linguistic features extracted from tweets. For this, we chose FastText Embedding
as the base classifier and conducted a combination of experiments utilizing m1,
m2, m3 metadata. The results are shown in Table 3.
Finally, we test our proposed models that are FastText Classifier(FC), BERTHindi Embedding with the BERT model, FastText Embedding with LSTM plus
all metadata. Further, conducted experiments with the combination of the an
ensemble model, due to limited space we only show the best ensemble model in
the Table 3 in the Proposed Model section All the experiments for coarse-grain
and fine-grain are conducted in two parts, one on the validation dataset, and the
other on the testing dataset and weighted F1 score is used as evaluation metrics.

5
5.1

Results and Discussions
English Fake News Result

As seen from Table 2, the model which makes use of the metadata and BoW
features along with embeddings and pseudo labeling gives the best performance.

Hostility Detection and Covid-19 Fake News Detection in Social Media
Model
Meta with SVM
Meta + BoW with SVM
Meta + BoW Ensemble OR
Meta + BoW Ensemble Majority Vote
Meta + BoW with SVM Pseudo-labelling

9

Val Score (%) Test Score (%)
93.59
93.45
93.74
93.41
91.86
91.66
93.55
93.10
93.64
93.41

Table 2: The weighted F1 scores on the English Fake news dataset. We notice that
simple distributed embedding based models coupled with meta-data and entity
information (via BoW features) exhibit the best performance. The pseudolabelling was done on the test data

We hypothesize and validate the presence of entities involved in hostility and
fake news detection. Adding such entities via a BoW feature vector increases
the performance of the model. We also notice that contextual embeddings based
on BERT architecture didn’t provide huge improvements and in fact performed
worse than our best model. This could possibly due to the nature of the dataset
and the annotation strategy adapted. Furthermore, it is also important to note
that there were a few samples in the English fake news dataset which were
mis-annotated, but were correctly labeled by our model.

Fig. 3: Confusion Matrix of Hindi Hostility coarse-grain classification (left) &
English Fake News classification (right)

5.2

Hindi Hostility Detection Results

Baseline Classifiers: We see that the FastText based feature combined with
LSTM yields the best result, equally matched by the mBERT based embeddings.
TF-IDF based models perform poorly, due to the lack of contextual understanding of the text. (Table 3)
Ablation Study: In Table 3, the addition of metadata (m1,m2,m3) increases
the F1 score by 1% in coarse-grain and 2% in fine-grain respectively. But when
m1 and m3 are given together F1 increases by 4%, suggesting a better combination. When all are provided together to the model, an increase of 7% F1 can

10

Gupta, Sukumaran, John and Teki

Coarse Grain Fine Grain
w.F-1
w.F-1
Validation Test Validation Test
TF-IDF + RF
0.78
0.77
0.35
0.34
TF-IDF + SVM
0.79
0.80
0.34
0.36
TF-IDF
TF-IDF + LR
0.76
0.75
0.33
0.32
TF-IDF + GB
0.79
0.79
0.34
0.35
TF-IDF + MLP
0.71
0.69
0.29
0.29
mE +RF
0.79
0.80
0.53
0.51
mE + SVM
0.84
0.84
0.54
0.54
mBERT based
mE + LR
0.83
0.84
0.51
0.51
mE + GB
0.81
0.81
0.52
0.52
mE + LSTM
0.83
0.83
0.54
0.53
FE+ RF
0.83
0.82
0.51
0.50
FE+ SVM
0.87
0.87
0.55
0.55
FastText based
FE+ LR
0.85
0.86
0.52
0.52
FE+ GB
0.85
0.84
0.52
0.53
FE+ LSTM
0.91
0.91
0.56
0.56
FE + LSTM + m1
0.92
0.92
0.58
0.58
FE + LSTM + m2
0.92
0.92
0.57
0.58
Meta Data Ablation
FE + LSTM + m3
0.93
0.93
0.58
0.58
FE + LSTM + m1 +m2
0.92
0.92
0.58
0.58
FE + LSTM + m1 +m3
0.94
0.93
0.59
0.60
FE + LSTM + m2 +m3
0.93
0.93
0.58
0.58
FE+ LSTM + m1 + m2 + m3
0.94
0.95
0.59
0.63
FE + FC
0.92
0.92
0.58
0.58
Proposed Model
HBE + Bert
0.96
0.96
0.60
0.61
Ensemble Model
0.97
0.97
0.61
0.62
Method

Models

Table 3: The results on the Hindi Hostility dataset. Here m1, m2, m3 are abusive
language count, URL, mention, Hashtag count, and emoji count, respectively.
FE, mE, HBE, are FastText, mBERT, and Hindi-BERT Embedding.

Class Name
Non-Hostile
Hostile
W.avg/Total

Precision
0.98
0.96
0.97

Recall
0.96
0.97
0.97

F1
0.97
0.97
0.97

Class name precision Recall F1 Support
Defamation
0.30
0.72 0.42
169
Fake
0.67
0.84 0.77
334
Hate
0.44
0.80 0.57
237
Offensive
0.46
0.79 0.59
219
W.avg/Total
0.50
0.80 0.62
959

Table 4: The Coarse-grain performance (left) & the Fine-grain performance of
the best Ensemble Model (right).

be observed in test data yielding to best F1 in fine-grain. Based on Table 3 we
observe that the fake tweet are easier to detect as compared to other classes. We
also see that, due to the abusive language detector(m1) as a feature, we are able
to detect the offensive tweets better.

Hostility Detection and Covid-19 Fake News Detection in Social Media

11

Proposed Model: As an individual model, Hindi BERT Embedding with BERT
model yields the best result for coarse-grain classification and FastText-LSTM
with metadata yields best result on fine-grain classification on test data. Our
best score is achieved on the Hindi-Hostility task, where we secured 5th rank
out of 45 teams using an ensemble model. From Figure 3 we can see our Ensemble model predicts only 20 out of 1653 tweets as False Negative and 35 out of
1653 detected as a false negative, yielding 0.97 F1.

6

Conclusion

In this paper, we address hostility and fake news detection on the Devanagari
(Hindi language) script using an ensemble model, coupled with abusive language
detector and metadata to attain an F1 score of 0.97. Furthermore, we also attained an F1 score of 0.93 on the English fake news detection task using a model
based on Word2Vec embeddings, metadata, and entity features. Our results highlight that representation learning models augmented with data specific rules and
features outperform the vanilla deep learning models.
Both the tasks attempted in our paper are far from solved and bringing in
modalities like, images or videos, social network structures, user-based embeddings, event-based embeddings and more could help improve the current model.
Furthermore, as the manual curation of such datasets is laborious and prone to
errors, methods from semi-supervised learning and weak supervision could be
leveraged.

References
1. Mohit Bhardwaj, Md Shad Akhtar, Asif Ekbal, Amitava Das, and Tanmoy Chakraborty.
Hostility detection dataset in hindi.
arXiv preprint
arXiv:2011.03588, 2020.
2. David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation.
Journal of machine Learning research, 3(Jan):993–1022, 2003.
3. Aditya Bohra, Deepanshu Vijay, Vinay Singh, Syed Sarfaraz Akhtar, and Manish
Shrivastava. A dataset of hindi-english code-mixed social media text for hate speech
detection. In Proceedings of the second workshop on computational modeling of
people’s opinions, personality, and emotions in social media, pages 36–41, 2018.
4. Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. Enriching word vectors with subword information. Transactions of the Association for
Computational Linguistics, 5:135–146, 2017.
5. Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D Manning. Electra: Pre-training text encoders as discriminators rather than generators. arXiv
preprint arXiv:2003.10555, 2020.
6. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pretraining of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805, 2018.
7. Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic,
and Narayan Bhamidipati. Hate speech detection with comment embeddings. In

12

8.
9.

10.

11.

12.

13.
14.

15.
16.

17.

18.

19.

20.

21.

22.

23.

Gupta, Sukumaran, John and Teki
Proceedings of the 24th international conference on world wide web, pages 29–30,
2015.
Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.
Dhruv Khattar, Jaipal Singh Goud, Manish Gupta, and Vasudeva Varma. Mvae:
Multimodal variational autoencoder for fake news detection. In The World Wide
Web Conference, pages 2915–2921, 2019.
Irene Kwok and Yuzhou Wang. Locate the hate: Detecting tweets against blacks.
In Proceedings of the twenty-seventh AAAI conference on artificial intelligence,
pages 1621–1622, 2013.
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, and Radu Soricut. Albert: A lite bert for self-supervised learning of
language representations. arXiv preprint arXiv:1909.11942, 2019.
Nayeon Lee, Belinda Z Li, Sinong Wang, Wen-tau Yih, Hao Ma, and Madian
Khabsa. Language models as fact checkers? arXiv preprint arXiv:2006.04102,
2020.
Jindřich Libovickỳ, Rudolf Rosa, and Alexander Fraser. How language-neutral is
multilingual bert? arXiv preprint arXiv:1911.03310, 2019.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly
optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation
of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.
Marzieh Mozafari, Reza Farahbakhsh, and Noël Crespi. A bert-based transfer
learning approach for hate speech detection in online social media. In International
Conference on Complex Networks and Their Applications, pages 928–940. Springer,
2019.
Alex Nikolov and Victor Radivchev. Nikolov-radivchev at semeval-2019 task 6:
Offensive tweet classification with bert and ensembles. In Proceedings of the 13th
International Workshop on Semantic Evaluation, pages 691–695, 2019.
Parth Patwa, Mohit Bhardwaj, Vineeth Guptha, Gitanjali Kumari, Shivam
Sharma, Srinivas PYKL, Amitava Das, Asif Ekbal, Shad Akhtar, and Tanmoy
Chakraborty. Overview of constraint 2021 shared tasks: Detecting english covid19 fake news and hindi hostile posts. In Proceedings of the First Workshop on
Combating Online Hostile Posts in Regional Languages during Emergency Situation (CONSTRAINT). Springer, 2021.
Parth Patwa, Shivam Sharma, Srinivas PYKL, Vineeth Guptha, Gitanjali Kumari,
Md Shad Akhtar, Asif Ekbal, Amitava Das, and Tanmoy Chakraborty. Fighting
an infodemic: Covid-19 fake news dataset. arXiv preprint arXiv:2011.03327, 2020.
Benjamin Riedel, Isabelle Augenstein, Georgios P Spithourakis, and Sebastian
Riedel. A simple but tough-to-beat baseline for the fake news challenge stance
detection task. arXiv preprint arXiv:1707.03264, 2017.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need.
In Advances in neural information processing systems, pages 5998–6008, 2017.
Rutvik Vijjali, Prathyush Potluri, Siddharth Kumar, and Sundeep Teki. Two
stage transformer model for covid-19 fake news detection and fact checking. arXiv
preprint arXiv:2011.13253, 2020.
Wieslaw Wolny. Emotion analysis of twitter data that use emoticons and emoji
ideograms. 2016.

Hostility Detection and Covid-19 Fake News Detection in Social Media

13

24. Jun-Ming Xu, Kwang-Sung Jun, Xiaojin Zhu, and Amy Bellmore. Learning from
bullying traces in social media. In Proceedings of the 2012 conference of the North
American chapter of the association for computational linguistics: Human language
technologies, pages 656–666, 2012.

