Date of publication xxxx xx, xxxx, date of current version xxxx xx, xxxx.
Digital Object Identifier xxxxxx/ACCESS.20xx.DOI

A Novel Strategy for COVID-19
Classification from Chest X-ray Images
Using Deep Stacked-Ensembles.
arXiv:2010.05690v1 [cs.CV] 7 Oct 2020

LALITH BHARADWAJ B1 , ROHIT BODDEDA2 , SAI VARDHAN K1 , SAI MOHAN G 1 , SAI
DEEPAK V1 , SHILHORA AKSHAY1 ,
1
2

Dept. of Information Technology , VNR Vignana Jyothi Institutions of Engg. & Technology, Hyderabad-90, TS, India (e-mail: lalithbharadwaj313@gmail.com)
Dept. of Computer Science , VNR Vignana Jyothi Institutions of Engg. & Technology, Hyderabad-90, TS, India (e-mail: rohitboddeda@gmail.com)

Corresponding author: xxxxxxxxxxxxxxxxxxxxxxxxxxx

ABSTRACT The issue of COVID-19, increasing notably with a massive mortality rate has led to the WHO
declaring it as a pandemic. The unavailability of an antiviral drug has also led to dismay world-wide. The
diagnostic tests are performed by collecting samples inserting a swab into the nasal or oral cavity. These
collected samples and then sent to laboratories for viral-tests. Recently, chest radiographs are used to observe
the proportion of virus in the lungs at various section-scans. As laboratory testing is time-consuming with a
lot of human effort, diagnosis using chest radio-graphs is considered to be a befitting choice.
In this research, a stacked-ensemble model is designed to classify whether a patient is infected with COVID19, viral-pneumonia or has a healthy profile by considering chest X-ray images. A lot of complications were
observed from existing literature in classifying COVID-19 radiographic images and are eliminated using
our methodology. A training algorithm is constructed to speed up the training process which acquired good
generalisations. The proposed model resulted in state-of-the-art outcomes with an accuracy score of 99.48%
for binary classification and 97.4% for tri-class classification. Additionally, visualisations are illustrated for
a detailed comprehension of the model’s perception for the information provided to it.
INDEX TERMS COVID-19 classification, deep neural networks , feature visualisations, stacked-ensemble,
training algorithm.

I. INTRODUCTION

In December 2019, Wuhan City (Hubei, China) had an outbreak with the evolution of new coronavirus. This is a virus
transmitted from person to person causing COVID-19. It was
reported that this virus evolved because to zoonotic transmission and with a detailed study of its biological properties, a
survey concluded that it belongs to the family of coronaviridae and is named as 2019-nCoV (novel coronavirus). This
novel coronavirus is a single-stranded RNA genome with a
strong capsid. A person infected with 2019-nCoV eventually
develops mild symptoms such as sore throat, dry cough, and
fever. If 2019-nCoV host the human body for longer periods,
it can cause severe respiratory illness and, in the worst case,
can lead to death. Four main stages1 are considered to analyse
the severity of the virus in the human body. The first stage lies
from zero to four days, i.e. the asymptomatic stage from the
1 These

observations were reported with clinical experimentation[2].

VOLUME 4, 2016

day of infection. The second stage is progressive stage, it lies
from the five to eight days where one might develop mild
symptoms. Stage three is considered as a peak stage ranging
from 9th -13th day. The final stage is an absorption stage
where a load of virus exponentially increases [1]. Observing
the extremity, during the end of January W.H.O declared
the situation as a public emergency due to the rapid spread
of this virus. Further, 2019-nCoV was properly amended
as SARS-CoV-2 beta-coronavirus[7](by Coronavirus Virus
Study Group(CVSG)) due to its potential characteristics to
affect the human respiratory tract with high similarities with
the genomic structure of SARS-CoV[8][9].
The upsurge of COVID-19 led to its declaration as a pandemic. Due to its rapid growth scientists are striving to provide proper vaccination and medication. COVID-19 erupted
progressively by increasing mortality rate in various regions
of the world [3]. Many preventive measures such as social
1

Lalith et al.: Preparation of Papers for IEEE Access

Figure 1: An upsurge in no. of cases & death rate from
January to July is depicted. An exponential increment in
death rate & infected people increased to a factor of ≈ 105
during a span of 6 months.

distancing, proper sanitization and face-cover have been in
practice. Even then people are encountered with the virus
causing fatal deaths. According to Chinese N.H.C (National
Health Commission), there was 2.1% & 0.2% mortality rate
in and outside of China (as of February 4th, 2020). With a
high mortality rate, the propulsion of virus spread worldwide
havoc. This led to worldwide panic with unavailability of
proper medication. In recent survey, there were contradictory
studies stating asymptomatic spread of the virus and under
certain circumstances they can be erroneous if the person is
having direct contact with the patient infected with COVID19 or the symptoms which are self-reported[5][6]. To avail
proper information about a patient’s health, precise and
proper diagnostic-tests are required. The diagnostic tests are
performed either by collecting samples from the individual
patient for testing in a laboratory or point-care-testing is
performed [4]. Manual testing consumes time with a lot of
human effort and it is unfit in a pandemic. To overcome such
problems, in this urgency, AI-based computerized techniques
are adapted for faster & feasible outcomes using the deeplearning approach[51]. The radiologists examined patients’
Chest X-ray (CXR) and Computed-Tomography (CT) images to assess the severity of infection in the lungs [2]. These
examinations led to aid people to depict infection under
various scans under different lesions of Chest. With these
observations, a lot of computer scientists developed machinevision models to combat COVID-19 by diagnosing either
with CXR or CT images. In this research, a stacked-ensemble
is proposed for the classification of patients’ CXR images as
Pneumonic, COVID-19 infected or uninfected.
II. RECENT RESEARCH

There are several works proposed in automated detection,
classification and segmentation for COVID-19 diagnosis
from CXR and CT images imparting deep learning [52].
2

Figure 2: This figure illustrates the samples of Chest X-ray
images considered from the dataset of patients infected with
COVID-19, viral-pneumonia and having no lung abnormalities. ( The COVID-19 (1) image is used in Fig. 5).

These works include lung lesion segmentation and classification of CXR or CT images by extracting a generic
feature-vector representing higher dimensional features with
great precision. F. Deng-ping et al., (2020) [18] proposed
a segmentation network, Inf-Net, for segmentation of patients infected with COVID-19 using Transverse C.T images.
The network architecture has Res2Net as a backbone. Their
model Inf-Net attains a dice score of 0.682 and also, a
Semi-Inf-Net model which in turn attains highest dice score
of 0.739. Fengshi et al., (2020) [23] classified C.T images
containing pneumonia and COVID-19 using Random-Forest
by attaining an accuracy score of 0.87 and with high sensitivity of 0.907 on 5 fold cross-validation. L. Wang et al.,
(2020) [15] tailored a deep network using the concept of
Identity mapping (residual connections) by classifying them
as Normal, Pneumonic & COVID-19 infected Chest-X Ray
images and named it as CovidNet. They attained an overall
accuracy score of 93.3% over sequential training for very few
epochs. Zhenyu Tang et al., (2020) [17] considered COVID19 infected patients’ CXR images to classify the severity
of the patient. The severity classification is trained using
Random Forest and attained an accuracy score of 87.5% by
3-fold cross-validation. Xiaocong et al., (2020) [16] developed a U-Net architecture constructing intermediate Residual
VOLUME 4, 2016

Lalith et al.: Preparation of Papers for IEEE Access

connections (U-Net+ResNext) for segmentation & detection
of 110 axial C.T images of patients infected with COVID19. This model attained an accuracy score of 79% without
augmentation and 89% with the use of augmentation. Yugin
et al., (2020) [13] implemented 2 different approaches, global
patch matching and local patch matching for the purpose of
segmentation & classification. Their method used ResNet18 as the backbone to classify variant lung infections (4Classes) similar to that of COVID-19 and attained the highest
accuracy score of 88.9% & specificity of 0.946 on randomly
cropped patches using local-approach.
Rahimzadeh et al., (2020) [10] constructed an 8-phase
training concatenating Xception and ResNet-50 architectures. In each phase, samples were trained using a proper
stratification in-order to overcome class imbalance for 100
epochs. This model attained an overall accuracy score of
91.4%by cross-validating on 5-folds. Tulin et al., (2020)
[11] proposed a Dark-CovidNet model for binary and triclass classification of CXR images infected with COVID19. This model was trained by constructing a deep neural
architecture with a series of convolutional layers and maxpooling layers by attaining accuracy scores of 98.3% (binary
classification) and 87.2% (Tri-class classification) on 5-fold
cross-validation. Ioannis et al., (2020) [12] applied transfer
learning using diverse pre-trained architectures on two different datasets for the classification of CXR images consisting
of COVID-19. Their transfer learning methodology attained
an accuracy score of 98.75% using VGG-19 pre-trained
weights for binary classification and accuracy of 94.7% using
MobileNet-V2 for classification of CXR images consisting of
3-classes. M. Farooq et al., (2020) [14] developed a model using ResNet-50 as the backbone and performed training CXR
images consisting of COVID-19 in three different stages. In
each stage, the model is fine-tuned on decreasing learning
schedules and attained an accuracy of 96.23% on data with
four non-identical classes of CXR images. E. Hemdian et al.,
(2020) [19] implemented models by sharing weights from
pre-trained models and attained the highest accuracy score
of 90% by training over 50 epochs. L. Li et al., (2020) [20]
proposed a network named ‘CovNet’ by training a deepmodel with ResNet-50 as a backbone for sharing weights
and attained an accuracy of 96%. Charmaine et al., (2020)
[21] considered Transverse-section of CT sample images as
the dataset for training the model where ResNet-18 pertains
as the backbone. This classifies CT images consisting of
COVID-19 by extracting lung lesions with location-attention
procedure with an accuracy score of 86.7%. A. Iqbal et at.,
(2020) [22] designed CoroNet-architecture with Xception as
an underlying weight-sharing model. This model achieved
an accuracy score of 99% (binary classification), 95% for
three non-identical classes (one class belongs to COVID-19)
and 89.6% for four variant classes with constructing a 4-fold
cross-validation framework.
Most of the existing literature for classification & segmentation were proposed on deep neural-networks with their versatile nature of the weight-sharing mechanism and high perVOLUME 4, 2016

formance. Despite this most of the proposed deep-networks
for COVID-19 classification had drawbacks.
•

•

•

•

As mentioned, most of the models were trained for
a longer training schedules and this eventually causes
overwhelmed understanding of training samples (overfitting).
The data is chosen to have identical class distributions during training but in real-world scenarios, classimbalance is commonly seen.
Individual pixels play a significant role in understanding
entities inside an image and extracting features without
losing information is challenging.
Inappropriate generalizations can mislead diagnostic
performance by misclassifying the samples.

In this research, we address these drawbacks and proposed
a novel stacked-ensemble neural network for classifying existence of COVID-19 in a given CXR image by vanquishing the problem of longer training schedules, proper pixelresolution and generalization constraints.
III. METHODOLOGY
A. DATASET DESCRIPTION

The complete data is collected from the mentioned repository2 . The total dataset consists of 3 non-identical classes
of CXR images either infected with COVID-19, viralPneumonia or having a healthy profile. The COVID-19 class
consists of 219 CXR images. Whereas, viral-pneumonia and
normal class contain 1345, 1341 CXR images. The dataset of
whole comprises of 2905 CXR images. The CXR images in
the database are visually depicted in Fig. 2. This database was
developed from major research contributed institutes such as
Italian Society of Medical and Interventional Radiology and
also from variant standard publications. The collected data
curated with appropriate labels and used for the purpose of
research.
Now, it is attempted to divide the complete dataset (Dtotal )
into 2 divisions: The first division comprises of training
samples (Dtrain ) i.e. samples that are to be fed into a
neural network for learning. The next division consists of
testing samples (Dtest ) and obliges to generalize model. The
training and testing divisions are partitioned into 80% − 20%
by maintaining consistency in class labels at each partition (But, overall class imbalance is present throughout the
training data) . To assess partition consistency, Dtotal is
randomly divided into train-test divisions multiple times (5
times) and newly shuffled samples are examined. During the
examination, it is found that each randomly shuffled sample
maintained utmost consistency in stratifying class labels. All
these partitioned samples are gradually evaluated to assess
the performance of the model and aided network with careful
generalization.

2 https://www.kaggle.com/tawsifurrahman/covid19-radiography-database

3

Lalith et al.: Preparation of Papers for IEEE Access

Figure 3: The above figure illustrates the complete methodology from data collection to that of classification. Initially, various
samples are considered and are pre-processed to a certain resolution (224x224x3). These pre-processed images are further
fed into various deep-networks designed on variant paradigms for extracting features to certain latent dimensions. Then,
assessments for extracted feature-vectors are done and among them, two best performing models are chosen to form a stacked
ensemble. This ensemble is evaluated by classifying input to a tri-class and a binary class where COVID-19 class in given more
importance.
Table 1: Performance of Individual model Class-wise

Models
DenseNet121
DenseNet169
DenseNet201
InceptionResNet
InceptionV3
MobileNet
NasNet-Large
NasNet-Mobile
ResNet50
ResNet101
ResNet152
Xception
VGG16
VGG19

Accuracy(Error)
%
48.0(52.0)
19.7(80.3)
31.4(68.6)
47.6(52.4)
34.2(65.8)
48.0(52.0)
06.8(93.2)
06.8(93.2)
85.7(14.3)
82.0(18.0)
58.1(41.9)
46.0(54.0)
95.1(4.9)
95.3(4.7)

COVID-19
0.29
0.11
0.10
0.44
0.04
0.25
0.07
0.07
0.00
1.00
0.00
0.07
0.95
1.00

Precision
Pneumonia
0.48
0.00
0.70
0.44
0.39
0.00
0.00
0.00
0.93
0.76
0.97
0.00
0.94
0.94

B. NEURAL NETWORKS FOR FEATURE EXTRACTION

The Convolutional Neural Networks (CNN’s) had a great
impact in computer-vision by its excessive use in detecting, classifying, localizing and segmenting real-world data
[26]. This resurgence of CNN’s started with its application
in large-scale image recognition challenge (ILSVRC-2010
[27]), where AlexNet [28] stood top by minimizing error
by using deep-CNN’s. This motivated many researchers in
developing high-end applications which employed on multidisciplinary tasks [29]. The architecture of CNN’s varied
by increasing width, depth and channels (activation-maps) to
4

Normal
0.53
0.29
1.00
0.48
0.20
0.48
0.00
0.00
0.80
0.90
0.54
0.53
0.96
0.96

COVID-19
0.25
0.88
0.90
0.28
0.05
0.03
1.00
1.00
0.00
0.03
0.00
0.12
0.93
0.97

Sensitivity
Pneumonia
0.77
0.00
0.55
0.02
0.71
0.00
0.00
0.00
0.87
0.99
0.23
0.00
0.96
0.97

Normal
0.24
0.29
0.01
0.94
0.04
1.00
0.00
0.00
0.97
0.77
1.00
0.96
0.95
0.95

drop error by decreasing parametric-weight and improving
performance with appropriate generalizations. These networks did have a great opportunity to access weights from
one network to other. The property of parametric weight
sharing technique advanced feature extraction in most of the
networks and obliged by decreasing a lot of computational
cost & training cost[30] [31]. Variant and vibrant networks
used in the field of computer vision for extracting features by
reducing input to low dimensional latent representations are
discussed.

VOLUME 4, 2016

Lalith et al.: Preparation of Papers for IEEE Access

sampling held to extract generic features at rearmost layer
for 16 & 19 layered VGG Networks. Their choice of using
small receptive fields (5x5, 3x3) led to capture small features
to maintain precisive information. The fine-tuning and appropriate learning schedules by decreasing learning rate and
consistent error drop led to greater generalization even for
highly correlated inputs [33].
c: Res-Nets

(a) Feature-vector activations for model VGG-16.

The variant forms in Res-Net’s addresses the problem of
vanishing gradients by imparting identity mapping in largescale networks. They reformulated deep layers by aggregating learned activations from a prior layer to form a residual
connection. This residual learning minimizes the problem
of degradation and exploding gradients in the deeper networks. These residual connections help in addressing learned
activations from preceding layers to maintain consistency
in information flow throughout the network and eventually
reduce the computational cost to a greater extent [34][36].
d: Inception-Res-Nets

This network inspired from the concept of Inception-module
of Inception Network and identity mappings from ResNets.
This method integrates dimensionality reduced Inception
modules with sequential residual connections to have greater
learning capability and eventually reduces computational
cost with better generalization ability compared to various
versions of ResNet & Inception Networks [35].
(b) Feature-vector activations for model VGG-19.

Figure 4: t-sne effectively visualizes the class distribution
for a given input. Where, the above figure illustrates t-sne
visualizations for Vgg-Nets for a certain tuned parameters

a: Inception

The Subsequent work after AlexNet was Inception in which,
they designed a new architecture with the ideology of the
novel inception module. This network architecture is trained
by widening layers and increasing depth of network with few
computational parameters. The inception had two versions
one is a naïve & other is dimensionality reduced one. The
Inception module consists of 3 levels and the bottom level
of inception sends it to feed to four different layers stacked
by width. These intermediate layers extract spatial information individually to maintain a spatial correlation amongst
these layers. The final layer concatenates all the intermediate
layer’s feature-maps to maintain a hierarchy of feature for
better perception for the network [32].

e: Xception

This network was proposed to compete Inception Network
by addressing flaws and eventually diminishing them. The
simultaneous mapping of spatial and cross-channel correlations guides for proper learning with small receptive fields
and improves perceptive ability. The depth-wise separable
convolutional layers enhance the learning by detailed feature extraction. These networks are computationally less
expensive and have high performance compared to Inception
Network [37].
f: Dense-Nets

b: Vgg-Nets

These densely connected CNN’s are motivated from the
residual connection of Res-Nets and imposed long-chained
residual connections to form dense blocks. In Dense-Net’s,
for N layers there are N (N2+1) connections(including residual connections) which enhances network capability of extracting detailed features and vanquishes degradation. The
sequential dense block and transition blocks provide a collection of knowledge and a bottleneck receptive field of 3x3
out-turns computational efficiency. The fine-tuning of larger
weights improved generalization in deeper networks ranging
its depth from 121-201 layers [38].

Soon after Inception, VGG networks were developed by a
sequential convolutional layer with a pooling layer. These
sequential models varied from a depth of 11 layers to 19
layers. Proper use of max-pooling layers for spatial sub-

The intention of Mobile-Nets is to design an effective neural
network for mobile application under a constrained environ-

VOLUME 4, 2016

g: Mobile-Nets

5

Lalith et al.: Preparation of Papers for IEEE Access

Algorithm 1 Training Neural-Network
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:

procedure T RAINING (Dtrain ,N N )
Xtrain , ytrain ← Dtrain ;
αo ← 16278;
. Parametric Initialization
βo ← 10;
. Parametric Initialization
o ← 10−5 ;
. Parametric Initialization
iters ← [0, 1, 2];
(v)
(v)
L ← Σv max(0, 21 − ypred ∗ ytrue ); . Hinge2 Loss
for i in iters do
if i == 0 then
. 1st Iteration
α ← α0 ; β ← βo ;  ← 10 ∗ 0 ;
opt ← Ad();
N N.train(Xtrain , ytrain , opt, L, α, β);
else if i == 1 then
. 2nd Iteration
α ← 2 ∗ α0 ; β ← βo + 10;  ← 100 ∗ 0 ;
opt ← Ad();
N N.train(Xtrain , ytrain , opt, L, α, β);
else if i == 2 then
. 3rd Iteration
α ← 1.857 ∗ α0 ; β ← βo + 15;  ← 100 ∗ 0 ;
opt ← Ad();
N N.train(Xtrain , ytrain , opt, L, α, β);
else
break
. Halt Training
return NN
M odel ← TRAINING(Dtrain , Nv−16 )
predictions ← M odel.predit(Dtest )

ment. The major contribution is designing inverted residual
layers combining with linear bottlenecks. Constructed deepnetwork accrues a low-dimensional input and eventually expands by elevating dimensional space. This elevated features
are filtered via depth-wise separable CNN’s and furtherly
projected back onto a low-dimensional space using linear
CNN’s. This contribution reduces accessing main memory
(from mobile-applications) providing faster executions utilizing cache-memory [39][50].
h: Nas-Nets

This demonstrated learning paradigm for convolution-cells
by learning from distinct classification tasks. This network is
designed by stacking normal cell & reduction cell by stacking
depth-wise providing an appropriate search space by decoupling sophisticated architectural design. This adaptability of
Nas-Nets tends to perform well even to mobile applications.
The computational cost is reduced to a greater extent and
performance was varied by enhancing the depth [40].
The divided training samples, Dtrain , are inserted into
each model to capture latent feature-vectors3 . Now, a feedforward neural network is built to classify these extracted
feature vectors. So, individual models are trained using Algorithm: 1 and access the performance of each network. The
3 The word ’Latent’ is mentioned, as the extracted feature vectors dimensions are not similar.

6

extracted feature-vector is of three dimensions with varying shape based on the model. These latent representations
are classified by attaching a dense layer consisting of 256
neurons followed by dropout [41] and batch-normalization
[42] layers for the purpose of regularization. The final layer
consists of softmax activations layer with c neurons (where,
c: no. of classes). The choice for dropout percentage is
carefully tuned to 30%. The assessment for generalization is
obtained for individual models.
During construction of the model architecture, ReLU[43]
is chosen as non-linearity for all the layers except the final
layer, where in that case feed is forwarded by softmax. Initializations for most of the layers are chosen to be glorot[44]but,
for only dropout layer, glorot normalization constraint is
considered for initializations. These initializations with appropriate activations led to extract intricate features at deeper
layers.
The performance of each model is evaluated, employing
standard classification metrics used for a bio-medical problem statement [45]. The chosen metrics are accuracy score,
Precision (PPV) & Sensitivity (recall). Accuracy score is a
typical classification metric determining robustness of classification but, in the presence of class-imbalance, models tend
to attain acceptable accuracy score deteriorating performance
by misclassifying the samples in a class with low in number.
To be well informed, individual class scores are calculated
and tabulated (Table: 2).
The above table concludes that both the VGG-Nets outperform existing models on test samples (Dtest with an error
rate of 4.7-4.9 % . Res-Net models (comprising 50, 101layers) competed Vgg-Nets with a close error of 14.3-18%.
This stunning outcome of Vgg-Nets with lowest error values
deemed us to analyse it performance to farther extent. To
understand Vgg-Nets, analysing invariances is considered to
be a crucial part. Hence visualization of individual layer
activation-maps is found to be necessary[46]. Visualizing
features gives intuition of network’s ability to perceive and
projections of pixels at each layer. The visualizations of
individual activation-maps for a layer illustrate the visual
perception for captured features (including shape, size, orientation etc.) during the process of training with updated
weights. Now, these visualizations assist in analysing spatial
structures of latent feature-vectors.
In presence of huge activation maps at each layer of a deepnetwork, complete visualization for the individual layers can
be sophisticated to comprehend. feature-vectors are adapted
to depict the model robustness by visualizing first, intermediate and final layers 4 .
Additionally, t-sne visualizations[55] are adapted to observe underling distribution pattern for the data(D) and the

4 Complete visualizations of individual layer for 32 feature-maps activations are plotted in the appendix section.
VOLUME 4, 2016

Lalith et al.: Preparation of Papers for IEEE Access

(a) Histogram of an individual image (COVID- (b) Histogram of the same input and feature- (c) Histogram of the same input and feature19 (1) from Fig. 2) by aggregating RGB chan- vector is extracted using VGG-16(aggregating vector is extracted using VGG-19(aggregating
nels.
512 feature-maps).
512 feature-maps).

Figure 5: A Histogram explains the property of an image i.e. information residing an image & influence of individual pixel by
constructing their distribution pattern. The distribution pattern and properties for the feature-vectors extracted using VGG-16
& 19 are visually elucidated.
Table 2: Variables used their description
Variables
Dtrain
Dtest
Xtrain ;Xtest
ytrain ;ytest
αo
βo
Ad(lr)
o
L
ypred
ytrue
Nv−16 ;Nv−19
Pv−16 ;Pv−19
f (.)

Act(.)

Description
Training data
Test data for generalization
Training feature set; Testing feature set
Training label set; Testing label set
Initial no of iterations
Initial no of batches considered
to fit into a NN
Adam optimizer with learning
rate as a parameter
Initial learning rate
Loss function considered(Squared-Hinge)
Predicted labels during training/testing
Ground truth labels
Altered VGG16 VGG-19 network
architectures designed for the
purpose of classification
Trained network architectures
(VGG-16 and VGG-19)
a feed forward dense network with
2 parameters one is input and other
is no of hidden neurons:
f (x, n) = W.x + b(W:weight matrix;b:bias;
n:no.of neurons determining shape of W,b)
Activation function
xi
softmax: Act(xi ) = Σe.exi
i

parameters involved are described5 .Further, to analyse these
feature-vectors a histogram plot is outlined (Fig. x) to inspect
amount of information.
In this research, we propose stacked-ensemble by considering Vgg-Nets as our individual networks as they manifest
5 The parameters involved are, angle ← 0.6; iterations ← 2 ∗
103 ; perplexity ← 102 ; distance = Euclidean; initializations =
P CA; method = Barneshut. Approximately 8.23 minutes was consumed for visualizing each input
VOLUME 4, 2016

Algorithm 2 Stacked-Ensemble-Network Architecture
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

procedure E NSEMBLE (Dtrain )
Pv−16 ← TRAINING(Dtrain , Nv−16 )
Pv−19 ← TRAINING(Dtrain , Nv−19 )
P̂v−16 ← Pv−16 .predict(Dtest )
P̂v−19 ← Pv−19 .predict(Dtest )
stack ← Concatenate[P̂v−16 , P̂v−19 ]
Dense ← f (stack, 16)
f inal ← Act(Dense)
. Final Activation vector
arch ← [Dtrain , f inal]
. Architecture:i/p & o/p
return arch
Ensemble ← TRAINING(DT rain ,ENSEMBLE(Dtrain ))
EP red ← Ensemble.predict(Dtest )

rich features with significant performance in classification .
Ensembling two Vgg-Nets performs well by reducing generalization error to substantial amount. The performance
of joint networks is always higher compared to that of a
single Network[47][48]. The error attained by Vgg-Nets can
be further decreased by coupling them to aggregate learning capacity. Eventually, generalization increases combining
these two networks. So, Our present ensemble model construction using Vgg-Nets is described in Algorithm: 2 using
Tensorflow6 [49]. As mentioned, the VGG-16 and VGG-19
network’s final activations are captured and are stacked by
aggregating them along their vertical dimensions( As mentioned at step:6 in Algorithm.2). This stacked vector is fed
into a series of fully connected layers with ReLU as activa6 Tensorflow (Version 1.15) is chosen as the execution platform for
constructing deep architectures provided by a hardware acceleration using
Nvidia-1660 Ti GPU and a CPU with Intel i7-8700

7

Lalith et al.: Preparation of Papers for IEEE Access

tion. Finally, the feed is forwarded with softmax as activation
to predict whether the given CXR input has COVID-19(either
in binary or tri-class classification).
The idea of generalization-error attained by stacking various deep learning models is theoretically analysed and mathematically evaluated. Here we considered our network to be
a function that predicts for a certain input x, where our true
function is Ti (x) and approximated function is f (x) ∀ i =
1, 2.
Suppose,
Ti = f (x) + ri

intern can increase error to a an estimated amount. So, we
consider rij 6= 0



2
1 X  2 X
Zstack = E
ri +
ri rj 
4
i=1
j6=i

2

Zstack =

i6=j

Zstack =

Where, ri is generalization error ∀ i = 1, 2
ri = residual = {Ti (x) − f (x)}
ri2 = {Ti (x) − f (x)}2

2

1X
1 XX
E[ri2 ] +
E[ri rj ]
4 i=1
4 i=1
1
Zavg + e
2

This constant ’e’ is additional error caused due to the covariances obtained in the perception of individual networks.
Now this intuition drives to evaluate the predictive capacity
of the designed stacked-ensemble model both on binary and
tri-class classification.

Zi = E[ri2 ]
Where, Zi is the individual estimated error for the model.
Z
E[ri2 ] = ri2 (x)p(x)dx
So,the average error settled from the networks estimating
individually is,
2
1X
E[ri2 ]
(1)
Zavg =
2 i=1
Now, we introduce learning of a ensemble i.e. group of VGGNets(VGG-16 & VGG-19)
2

Tstack (x) =

1X
Ti (x)
2 i=1

Estimated error resided by stacking these ensembles,
h
i
2
Zstack = E (Tstack (x) − f (x))
Suppose,
E[ri = 0] & E[rij ] = 0 if i 6= j

!2 
X
1
Zstack = E 
r2 
2 i=2 i
2

Zstack =

1X
E[ri2 ]
4 i=1

Substituting equation (1) in Zstack ,
Zstack =

1
Zavg
2

If individual network do not persist any correlation among
themselves stacking an ensemble halves the original generalization of the individual networks. But, in most of the real
world scenario correlation in generalization do exist which
8

IV. RESULTS AND DISCUSSIONS

In this section, the complete training process and results
obtained preferring Algorithm-1 are described.A detailed
explanation is obtained by explaining computational reason
in using it. In most of the recent research, models are trained
for higher values of iterations (epochs). Larger iterations
can mislead predictions by over-fitting i.e. model properly
fits on training samples but declines its performance on test
samples[10][11][13]. Some of the researchers consider a relatively low resolution for training and this low-pixel density
results is dropping the quality of an image [22][12][14]. For
a bio-medical problem quality of input is a considered to
be crucial as low-quality images capture poor features and
cannot be apt for real-world situations. A generic model is
the one which even sustains the problem of class-imbalance.
Most of the designed models are trained to stratify their training set [10][12][13][22] which can be bothering in actuality.
Most importantly, generalization is crucial in determining the
robustness of the model. The ensemble model is designed
is resilient to class imbalance as the number of COVID-19
samples fed into the networks are few (≈ 7 − 8%) compared to that of healthy and viral-pneumonia samples. The
ensemble model constructed acquires input with a resolution
of 224x224 with 3 channel variants (RGB) CXR images. The
designed training algorithm is a generic training algorithm
which aids training process by acquiring faster convergence
and with low-computations (Iterations). During the process
of training, at each iteration, the batch size is increased and
moderately learning rate is increased for a balanced criterion.
This conception was perceived from Smith et al., (2017) [53].
As noise during training can be reduced by properly choosing
the parameters which are batches fed into network, learning
rate of the optimizer and momentum assigned for a faster
search.
The noise due to training is theoretically represented as,
noise ∝


(Xtrain )
β
VOLUME 4, 2016

Lalith et al.: Preparation of Papers for IEEE Access

(a) Confusion matrix of the tri-class stacked-ensemble.

(b) Confusion matrix of the binary stacked-ensemble

Figure 6: A confusion matrix gives complete data about model’s performance class-wise. These two confusion matrices
obtained for the proposed Stacked-Ensemble with highest performance.

(assuming momentum is constant). Conceptualizing the
noise constraint, a training algorithm is developed. Just by
decaying learning rate can decrease the noise but the computational time for training increases gradually. Lowering batch
size can also reduce noise but it leads to lowering the generalizing capacity of the model. To overcome these problems
by attaining faster convergence with better generalizations,
the algorithm is developed by increasing batch size during
the specified iteration and cautiously increasing the learning
rate. Firstly the algorithm is iterated for 16278 steps which
is considered as iteration 1, where the learning rate is set
to 10−4 by sending 15 samples as a batch at a time. In the
next iteration (iteration 2), the batch size is increased by a
factor of 50% and the learning rate is increased by 10 times.
To maintain a consistent trade-off between generalization and
faster convergence batch size is increased by a factor of 150%
and the learning rate is tuned as of previous. During experimentation, it is found that the proposed training procedure
led to a faster convergence by training on few steps (≈ 20
epochs). Appropriate training with fine-tuning the ensemble
was critical to attaining insightful outcomes.
As mentioned training and testing, samples were randomly
shuffled into different patterns at a fixed size (i.e. 80-20).
Test for generalization is done at each level i.e. each shuffled
sample is trained on the given ensemble by maintaining
stratification. During shuffling, different accuracy score is
obtained for each shuffle different samples are constructed
by maintaining stratification in the available data. At a certain
shuffling pattern, highest accuracy score of 97.4% is obtained
for 3 class classification and for binary classification an
VOLUME 4, 2016

accuracy score of 99.48% is obtained for most of the shuffle
pattern. It is observed that the use of dropout and batchnormalization layers sustainably increased training process
and improved models performance significantly. Adam optimizer aided for faster convergence by tweaking learning rate
at a consistent frequency. To assess the predictive capacity
of ensemble confusion matrices are obtained for both the
classes to represent individual class performance. For the
binary classification problem, misclassification of COVID-19
samples as Non-COVID-19 was 3 by attaining a sensitivity of
100% and specificity of 99.44%. Then for 3 class classification ensemble model, the highest accuracy score of 97.4%
is obtained and an average score of 96.16±0.9%(aggregating
all the shuffles). These results reveal utmost consistency for
both the classification problems. Finally, the novelty of the
developed stacked-ensembles is evaluated by comparing the
performance with existing literature (Table ).
V. CONCLUSION

In our research, A stacked-ensemble is proposed using VggNets for binary and tri-class classification of CXR images
infected with COVID-19 with state-of-the-art performance.
The least classification error of 2.6% and highest sensitivity,
PPV of 100%, 97.5% are attained for COVID-19 class. In
the case of binary classification, the least error of 0.52% is
obtained. These on par outcomes determine the robustness
of the ensemble model. The proposed model vanquishes
the pitfalls of the existing model by visually understanding
the extracted feature pattern and to provide a great deal of
generalization with variant shuffles.
9

Lalith et al.: Preparation of Papers for IEEE Access

Table 3: Comparison of novelty with existing literature
Literature
(Prev. Works)
Mohammad Ret al., [10]

Image-Kind
(CT or CXR)
CXR

Model (generalization-test)
(Network Used)
Xception+ResNet50v2 (5 fold cv)

Binary Classification
91.4

Accuracy(%)
3-class Classification
-

4-class Classification
-

T. Ozturk et al., [11]

CXR

DarkCovidNet (5 fold cv)

98.3

87.2

-

Apostolopoulos et al., [12]

CXR

Transfer-Learning (Train-Test)

98.75

94.7

-

Yujin et al., [13]

CXR

Segmentation+ResNet-18 (Train-Test)

-

-

88.9

M.Farooq et al., [14]

CXR

COVID-ResNet-50 (Train-Test)

-

-

96.23

Linda Wang et al., [15]

CXR

CovidNet (∗)

-

93.3

-

Zhenyu Tang et al., [17]

CT

RandomForest (3 fold cv)

87.5

-

-

Hemdan, E.E.D et al., [19]

CXR

COVIDx (Train-Test)

90.0

-

-

Lin Li et al., [20]

CT

COVNET (Train-Test)

-

96.0

-

A.Iqbal Khan et al., [22]

CXR

CORONET (4 fold cv)

99.0

95.0

89.6

Ying et al., [24]

CT

DRE-Net

86.0

-

-

Wang et al., [25]

CT

M-Inception

82.9

-

-

Proposed

CXR

Stacked VGG Ensemble (Train-Test)

99.48

97.4

-

* Lack of information regarding testing procedure

Even with a great deal of success, some of the challenges
are yet to compete with a vigilant observance. These challenges include training of multiple neural networks to the
ensemble model, which consumes dual effort by training
individual models as well as the ensemble. As observed
noise in data might affect testing performance by attaining
distinct accuracy scores during the variant shuffling of data
with little inconsistency in the predictions. Further, crossvalidating deep neural networks with divergent folds are
significant but due to computational constraints, the train-test
scheme is chosen. Finally, overcoming these loopholes and
developing a versatile model which is capable of identifying
the severity by analysing the evolving pattern of the virus in
the lungs periodically from CXR images is considered as a
challenge for the future work.
References
[1] Sohrabi, C., Alsafi, Z., O’Neill, N., Khan, M., Kerwan, A., Al-Jabir, A.,
Iosifidis, C. and Agha, R., 2020. World Health Organization declares
global emergency: A review of the 2019 novel coronavirus (COVID-19).
International Journal of Surgery.
[2] Pan, F., Ye, T., Sun, P., Gui, S., Liang, B., Li, L., Zheng, D., Wang, J.,
Hesketh, R.L., Yang, L. and Zheng, C., 2020. Time course of lung changes
on chest CT during recovery from 2019 novel coronavirus (COVID-19)
pneumonia. Radiology, p.200370.
[3] Zhou, F., Yu, T., Du, R., Fan, G., Liu, Y., Liu, Z., Xiang, J., Wang, Y.,
Song, B., Gu, X. and Guan, L., 2020. Clinical course and risk factors
for mortality of adult inpatients with COVID-19 in Wuhan, China: a
retrospective cohort study. The lancet.
[4] Li, Z., Yi, Y., Luo, X., Xiong, N., Liu, Y., Li, S., Sun, R., Wang, Y., Hu,
B., Chen, W. and Zhang, Y., 2020. Development and clinical application
of a rapid IgM-IgG combined antibody test for SARS-CoV-2 infection
diagnosis. Journal of medical virology.
[5] Rothe, C., Schunk, M., Sothmann, P., Bretzel, G., Froeschl, G., Wallrauch,
C., Zimmer, T., Thiel, V., Janke, C., Guggemos, W. and Seilmaier, M.,
2020. Transmission of 2019-nCoV infection from an asymptomatic contact in Germany. New England Journal of Medicine, 382(10), pp.970-971.
10

[6] Bai, Y., Yao, L., Wei, T., Tian, F., Jin, D.Y., Chen, L. and Wang, M.,
2020. Presumed asymptomatic carrier transmission of COVID-19. Jama,
323(14), pp.1406-1407.
[7] Gorbalenya, A.E., Baker, S.C., Baric, R., Groot, R.J.D., Drosten, C.,
Gulyaeva, A.A., Haagmans, B.L., Lauber, C., Leontovich, A.M., Neuman,
B.W. and Penzar, D., 2020. Severe acute respiratory syndrome-related
coronavirus: The species and its viruses–a statement of the Coronavirus
Study Group.
[8] Wang, D., Hu, B., Hu, C., Zhu, F., Liu, X., Zhang, J., Wang, B., Xiang, H.,
Cheng, Z., Xiong, Y. and Zhao, Y., 2020. Clinical characteristics of 138
hospitalized patients with 2019 novel coronavirus–infected pneumonia in
Wuhan, China. Jama, 323(11), pp.1061-1069.
[9] Chang, D., Lin, M., Wei, L., Xie, L., Zhu, G., Cruz, C.S.D. and Sharma,
L., 2020. Epidemiologic and clinical characteristics of novel coronavirus
infections involving 13 patients outside Wuhan, China. Jama, 323(11),
pp.1092-1093.
[10] Rahimzadeh, M. and Attar, A., 2020. A modified deep convolutional
neural network for detecting COVID-19 and pneumonia from chest Xray images based on the concatenation of Xception and ResNet50V2.
Informatics in Medicine Unlocked, p.100360.
[11] Ozturk, T., Talo, M., Yildirim, E.A., Baloglu, U.B., Yildirim, O. and
Acharya, U.R., 2020. Automated detection of COVID-19 cases using deep
neural networks with X-ray images. Computers in Biology and Medicine,
p.103792.
[12] Apostolopoulos, I.D. and Mpesiana, T.A., 2020. Covid-19: automatic
detection from x-ray images utilizing transfer learning with convolutional
neural networks. Physical and Engineering Sciences in Medicine, p.1.
[13] Oh, Y., Park, S. and Ye, J.C., 2020. Deep learning covid-19 features on cxr
using limited training data sets. IEEE Transactions on Medical Imaging.
[14] Farooq, M. and Hafeez, A., 2020. Covid-resnet: A deep learning
framework for screening of covid19 from radiographs. arXiv preprint
arXiv:2003.14395.
[15] Wang, L. and Wong, A., 2020. COVID-Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19 Cases from
Chest X-Ray Images. arXiv preprint arXiv:2003.09871.
[16] Chen, X., Yao, L. and Zhang, Y., 2020. Residual Attention U-Net for
Automated Multi-Class Segmentation of COVID-19 Chest CT Images.
arXiv preprint arXiv:2004.05645.
[17] Tang, Z., Zhao, W., Xie, X., Zhong, Z., Shi, F., Liu, J. and Shen, D., 2020.
Severity assessment of coronavirus disease 2019 (COVID-19) using quantitative features from chest CT images. arXiv preprint arXiv:2003.11988.
[18] Fan, D.P., Zhou, T., Ji, G.P., Zhou, Y., Chen, G., Fu, H., Shen, J. and Shao,
VOLUME 4, 2016

Lalith et al.: Preparation of Papers for IEEE Access

[19]

[20]

[21]
[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]
[31]

[32]

[33]
[34]

[35]

[36]

[37]
[38]

[39]

[40]

[41]

L., 2020. Inf-Net: Automatic COVID-19 Lung Infection Segmentation
from CT Images. IEEE Transactions on Medical Imaging.
Hemdan, E.E.D., Shouman, M.A. and Karar, M.E., 2020. Covidx-net:
A framework of deep learning classifiers to diagnose covid-19 in x-ray
images. arXiv preprint arXiv:2003.11055.
Li, L., Qin, L., Xu, Z., Yin, Y., Wang, X., Kong, B., Bai, J., Lu, Y.,
Fang, Z., Song, Q. and Cao, K., 2020. Artificial intelligence distinguishes
COVID-19 from community acquired pneumonia on chest CT. Radiology,
p.200905.
Butt, C., Gill, J., Chun, D. and Babu, B.A., 2020. Deep learning system to
screen coronavirus disease 2019 pneumonia. Applied Intelligence, p.1.
Khan, A.I., Shah, J.L. and Bhat, M.M., 2020. Coronet: A deep neural network for detection and diagnosis of COVID-19 from chest x-ray images.
Computer Methods and Programs in Biomedicine, p.105581.
Shi, F., Xia, L., Shan, F., Wu, D., Wei, Y., Yuan, H., Jiang, H., Gao,
Y., Sui, H. and Shen, D., 2020. Large-scale screening of covid-19 from
community acquired pneumonia using infection size-aware classification.
arXiv preprint arXiv:2003.09860.
Y. Song, S. Zheng, L. Li, X. Zhang, X. Zhang, Z. Huang, Y. Chong, Deep
learning enables accurate diagnosis of novel coronavirus (COVID-19) with
CT images, medRxiv (2020).
Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., Cai, M., Yang, J.,
Li, Y., Meng, X. and Xu, B., 2020. A deep learning algorithm using CT
images to screen for Corona Virus Disease (COVID-19). MedRxiv.
Bengio, Y., Courville, A. and Vincent, P., 2013. Representation learning:
A review and new perspectives. IEEE transactions on pattern analysis and
machine intelligence, 35(8), pp.1798-1828.
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S.,
Huang, Z., Karpathy, A., Khosla, A., Bernstein, M. and Berg, A.C., 2015.
Imagenet large scale visual recognition challenge. International journal of
computer vision, 115(3), pp.211-252.
Krizhevsky, A., Sutskever, I. and Hinton, G.E., 2012. Imagenet classification with deep convolutional neural networks. In Advances in neural
information processing systems (pp. 1097-1105).
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
Ozair, S., Courville, A. and Bengio, Y., 2014. Generative adversarial nets.
In Advances in neural information processing systems(pp. 2672-2680).
Pan, S.J. and Yang, Q., 2009. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10), pp.1345-1359.
Dai, W., Yang, Q., Xue, G.R. and Yu, Y., 2007, June. Boosting for transfer
learning. In Proceedings of the 24th international conference on Machine
learning (pp. 193-200).
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D.,
Erhan, D., Vanhoucke, V. and Rabinovich, A., 2015. Going deeper with
convolutions. In Proceedings of the IEEE conference on computer vision
and pattern recognition (pp. 1-9).
Simonyan, K. and Zisserman, A., 2014. Very deep convolutional networks
for large-scale image recognition. arXiv preprint arXiv:1409.1556.
He, K., Zhang, X., Ren, S. and Sun, J., 2016. Deep residual learning for
image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition (pp. 770-778).
Szegedy, C., Ioffe, S., Vanhoucke, V. and Alemi, A.A., 2017, February.
Inception-v4, inception-resnet and the impact of residual connections on
learning. In Thirty-first AAAI conference on artificial intelligence.
He, Kaiming, Xiangyu Zhang, ShaoqingRen, and Jian Sun. "Identity
mappings in deep residual networks."In European conference on computer
vision, pp. 630-645.Springer, Cham, 2016.
Chollet, Francois. (2017). Xception: Deep Learning with Depthwise Separable Convolutions. 1800-1807. 10.1109/CVPR.2017.195.
Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely connected
convolutional networks. InProceedings of the IEEE conference on computer vision and pattern recognition 2017 (pp. 4700-4708).
M. Sandler, A. Howard, M. Zhu, A. Zhmoginov and L. Chen, "MobileNetV2: Inverted Residuals and Linear Bottlenecks," 2018 IEEE/CVF
Conference on Computer Vision and Pattern Recognition, Salt Lake City,
UT, 2018, pp. 4510-4520.
Zoph, B., Vasudevan, V., Shlens, J. and Le, Q.V., 2018. Learning transferable architectures for scalable image recognition. In Proceedings of the
IEEE conference on computer vision and pattern recognition (pp. 86978710).
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. and Salakhutdinov,
R., 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), pp.1929-1958.

VOLUME 4, 2016

[42] Ioffe, S. and Szegedy, C., 2015. Batch normalization: Accelerating deep
network training by reducing internal covariate shift. arXiv preprint
arXiv:1502.03167.
[43] Nair, V. and Hinton, G.E., 2010, January. Rectified linear units improve
restricted boltzmann machines. In ICML.
[44] Glorot, X. and Bengio, Y., 2010, March. Understanding the difficulty of
training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics(pp.
249-256).
[45] Reitsma, J.B., Glas, A.S., Rutjes, A.W., Scholten, R.J., Bossuyt, P.M. and
Zwinderman, A.H., 2005. Bivariate analysis of sensitivity and specificity
produces informative summary measures in diagnostic reviews. Journal of
clinical epidemiology, 58(10), pp.982-990.
[46] Zeiler, M.D. and Fergus, R., 2014, September. Visualizing and understanding convolutional networks. In European conference on computer
vision(pp. 818-833). Springer, Cham.
[47] Hansen, L.K. and Salamon, P., 1990. Neural network ensembles. IEEE
transactions on pattern analysis and machine intelligence, 12(10), pp.9931001.
[48] Krogh, A. and Vedelsby, J., 1995. Neural network ensembles, cross validation, and active learning. In Advances in neural information processing
systems (pp. 231-238).
[49] Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
Ghemawat, S., Irving, G., Isard, M. and Kudlur, M., 2016. Tensorflow: A
system for large-scale machine learning. In 12th USENIX symposium on
operating systems design and implementation (OSDI 16) (pp. 265-283).
[50] Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand,
T., Andreetto, M., & Adam, H. (2017). MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. ArXiv,
abs/1704.04861.
[51] LeCun, Y., Bengio, Y. and Hinton, G., 2015. Deep learning. nature,
521(7553), pp.436-444.
[52] Goodfellow, I., Bengio, Y. and Courville, A., 2016. Deep learning. MIT
press.
[53] Smith, S.L., Kindermans, P.J., Ying, C. and Le, Q.V., 2017. Don’t decay
the learning rate, increase the batch size. arXiv preprint arXiv:1711.00489.
[54] Chen, L., Wang, H., Zhao, J., Papailiopoulos, D. and Koutris, P., 2018.
The effect of network width on the performance of large-batch training. In
Advances in Neural Information Processing Systems (pp. 9302-9309).
[55] Maaten, L.V.D. and Hinton, G., 2008. Visualizing data using t-SNE.
Journal of machine learning research, 9(Nov), pp.2579-2605.

11

