Diagnosis of COVID-19 and Non-COVID-19 Patients by Classifying Only a Single Cough
Sound
Masoud MALEKI (Mesut MELEK) (Asst. Prof. Dr.)
Gumushane University
Department of Electronics and Automation
29100 Gumushane/TURKEY
Phone (mobile): (+90) 538 578 7035
E-mail: masoud.maleki1361@gmail.com
E-mail: mesutmelek@gumushane.edu.tr
ORCID: 0000-0002-7152-7788

1

Diagnosis of COVID-19 and Non-COVID-19 Patients by Classifying Only a Single Cough
Sound
Masoud MALEKI
Department of Electronics and Automation, Gumushane University, Gumushane, Turkey

This paper is dedicated to the memory of the late Dr. Mohsen MALEKI, who passed away from
COVID-19 in November 2020.

Abstract

In the last month of 2019, a new virus emerged in China, spreading rapidly and affecting the whole world.
This virus, which is called corona, is the most contagious type of virus that humanity has ever encountered.
The virus has caused a huge crisis worldwide as it leads to severe infections and eventually death in humans.
On March 11, 2020, it was announced by the World Health Organization that a COVID-19 outbreak has
occurred. Computer-aided digital technologies, which eliminate many problems and provide convenience
in people's lives, did not leave humanity alone in this regard and rushed to provide a solution for this
unfortunate event. One of the important aspects in which computer-aided digital technologies can be
effective is the diagnosis of the disease. Reverse transcription-polymerase chain reaction (RT-PCR), which
is a standard and precise technique for diagnosing the disease, is an expensive and time-consuming method.
Moreover, its availability is not the same all over the world. For this reason, it can be very attractive and
important to distinguish the COVID-19 disease from a cold or flu through a cough sound analysis via
smartphones which have entered into the lives of many people in recent years. In this study, we proposed a
machine learning-based system to distinguish patients with COVID-19 from non-COVID-19 patients by
analyzing only a single cough sound. Two different data sets were used, one accessible for the public and
the other available on request. After combining the data sets, the features were obtained from the cough
sounds using the mel-frequency cepstral coefficients (MFCCs) method, and then they were classified with
seven different machine learning classifiers. To determine the optimum values of hyperparameters for
MFCCs and classifiers, the leave-one-out cross-validation (LOO-CV) strategy was implemented. Based on
the results, the k-nearest neighbors classifier based on the Euclidean distance (k-NN Euclidean) with the
accuracy rate, sensitivity of COVID-19, sensitivity of non-COVID-19, F-measure, and area under the ROC
2

curve (AUC) of 0.9833, 1.0000, 0.9720, 0.9799, and 0.9860, respectively, is more successful than other
classifiers. Finally, the best and most effective features were determined for each classifier using the
sequential forward selection (SFS) method. According to the results, the proposed system is excellent
compared with similar studies in the literature and can be easily used in smartphones and facilitate the
diagnosis of COVID-19 patients. In addition, since the used data set includes reflex and unconscious
coughs, the results showed that conscious or unconscious coughing has no effect on the diagnosis of
COVID-19 patients based on the cough sound.

Keywords: Cough sound, Classification, Machine learning, COVID-19, Coronavirus, Computer-aided
digital technologies.

1. Introduction
A pandemic was declared by the World Health Organization on March 11, 2020. The cause of the disease
was stated to be the new coronavirus 2 (SARS-CoV-2), which causes severe acute respiratory syndrome
[1]. This epidemic disease, called COVID-19, affected the lifestyle, economy, social life, and education of
billions of people. This disease, which is highly contagious and has no fully medically proven cure, has
caused more than 1.94 M deaths worldwide by January 2021. The symptoms in patients with COVID-19
vary significantly depending on the individual, and it may take up to 14 days for the symptoms to appear
[2]. Fever, fatigue, and dry cough are the most common symptoms [3] which can easily be mistaken for a
cold or flu [2].

Since the day the pandemic started, healthcare teams around the world have been working on the diagnosis,
follow-up, and treatment of patients. Moreover, most of the researchers are trying to help humans to go
through these difficult days more easily by examining this event in their field [4], [5], [6], [7]. In this case,
studies on COVID-19 are expected from artificial intelligence (AI) and machine/deep learning (ML)
techniques. These techniques, which are generally known as computer-aided digital technologies, have
affected and changed human life, especially in recent years. A system based on machine learning techniques
is an intelligent system that gains experience from past occurrences and adapts to new situations without the
need for explicit programming [8], [9]. These systems are used to solve a variety of computer science
problems, from bio-informatics to image processing [10]. Therefore, machine learning systems and

3

computer-aided digital technologies, in general, can be used on many fronts to combat COVID-19 [11],
[12].

Early diagnosis of COVID-19 is important as many other diseases. The standard and definitive diagnosis
of the COVID-19 is made via the reverse transcription-polymerase chain reaction (RT-PCR) test of the
infected secretions from the nasal or throat cavity [13]. The results of this test can sometimes take up to 48
hours to come out. In addition, in order for the test to be effective, patients must remain isolated during this
time. RT-PCR test is not only time-consuming but also expensive and problems occur in large-scale
deployments [14]. The cost of each test in the United States is approximately 23 dollars [15]. The
governments try to test as much as they can every day, as they do not have the chance to test and control
the whole country on one day. Moreover, the availability of the RT-PCR test is not the same all over the
world. Therefore, it is of great importance to have a fast, simple, accurate, cheap, and easily accessible test.

One of the aspects in which machine learning can be effective is the early diagnosis of COVID-19. As
mentioned previously, one of the most common and early symptoms of COVID-19 is coughing [2]. If noncoronavirus-induced coughs are distinguished from coronavirus-induced coughs through machine learning
techniques, a cost-effective, easy, fast, and early diagnosis system can be offered. In this way, in addition
to the low cost, suspected candidates can record the cough sounds on their smartphones whenever they want
and perform a preliminary determination for their status. It can also reduce the burden of healthcare teams
by effectively reducing the congestion in hospitals. This system, which is based on cough sounds, can also
be used as a scanning method in airports, buses, waiting rooms of hospitals, nursing homes, and similar
crowded environments [16].

In humans, different viruses, bacteria, or other acute and chronic health conditions, or even substances such
as smoke and dust entering the lungs can cause coughing. In medicine, it is important for physicians to
know whether the cough is wet, dry, or a wheezing, and whooping cough, in addition to how often and how
severely the patient coughs [16]. Machine learning-based systems can detect the type of coughs (wet, dry,
wheezing, and whooping cough) by providing medical professionals with more accurate clinical
information about the frequency and severity of cough episodes. For this reason, even before the COVID19 outbreak, studies on these issues were implemented. In a study [17], which was performed in 2011, two
features that can be used to analyze cough sounds and distinguish between dry and wet cough sounds were
identified. However, a clear distinction was observed by using only eight dry and eight wet cough sounds.
4

Pramono et al. [18] presented a system for diagnosing whooping cough in young children, which can be
fatal if untreated. In their study, audio recordings from 38 patients were used for automatic diagnosis of
pertussis by analyzing the cough and whooping sounds. The algorithm was able to successfully detect
whooping cough from sound recordings and automatically detect individual cough sounds with 92%
accuracy. As mentioned earlier, the frequency of coughs provides information for physicians to diagnose
diseases. In [19], deep neural networks were used for cough detection. The accuracy rate of the system was
reported to be 82.5% for the three classes defined, namely, cough, speech, and other. A preprocessing
method was proposed for the detection of coughs in a noisy environment [20]. Next, a methodology for
automated analysis of cough sounds using support vector machines (SVM) was presented.

Since the start of the pandemic, researchers working on computer-aided digital technologies have offered
different ideas, solutions, and methods based on previous experiences. This covers a range from the analysis
of the CT scans and X-ray images [21], [22], [23], [24], [25] for the diagnosis of COVID-19 to emotional
and sentiment analysis from social media [26], [27], [28]. One of the parameters that has the greatest impact
on machine learning studies is the data set. Since COVID-19 is a newly emerging disease and more
importantly considering the status of the COVID-19 patients, it is very difficult to collect and access data
sets. However, despite all these difficulties, studies on sound and especially on cough sound appear in the
literature. Although most of these studies are not peer-reviewed yet, they can be obtained from different
preprint banks. In [29], respiratory sounds of COVID-19 patients, with the help of a binary classifier, were
distinguished from respiratory sounds of healthy people with an area under the curve (AUC) exceeding
0.80. Ali et al. [30] presented a mobile application that records and analyzes 3-second cough sounds through
an application called AI4COVID-19. A total of 328 cough sounds of four different types including COVID19, asthma, bronchitis, and healthy from 150 people were recorded and classified. The accuracy rate of the
system was calculated as 92.85%. In a study based on deep neural network (DNN), coughs of people with
COVID-19 were distinguished from those of healthy people with an accuracy of 96.83% [31]. In [32],
cough sounds that were collected from 3621 people via mobile phones were classified with 0.72 AUC. In
[33] cough sounds were classified with a 95.86% accuracy rate with SVM's RBF kernel function classifier
by obtaining features by the MFCCs method. The sensitivity of the system to COVID-19 cough sounds was
calculated as 98.6% and the sensitivity was obtained as 91.7%.

Most of the studies conducted have been based on recordings involving a few coughs. That is, for example,
a 9-second recording has 3 or 4 coughs. In addition, all of the studies have been conducted on mandatory
5

and conscious cough sounds. In this study, considering these two important points, two different datasets
were combined and used. The virufy [34] data set is a public data set and contains 121 single cough records.
The novel coronavirus cough database (NoCoCoDa) [16] is available to researchers free of charge upon
request. This data set contains 73 single coughs that include reflex COVID-19 cough sounds and are not
mandatory. The features were obtained by the MFCCs method on the data set acquired by combining these
two data sets and classified with seven different classifiers. The optimum values of the hyperparameters of
the system were determined based on the leave-one-out cross-validation (LOO-CV) strategy. Finally,
effective features were determined separately for each classifier using the sequential forward selection
(SFS) method. In this way, mandatory and conscious single cough sounds, in addition to reflex single cough
sounds of COVID-19 patients, were successfully distinguished from single cough sounds of non-COVID19 patients in the present study. The results showed that the proposed system is more successful than other
systems. In addition, the results revealed that conscious or unconscious coughs have no effect on the
diagnosis of COVID-19 patients with cough sounds.

In the following section, materials and methods are explained. In the third section, the results are given and
in the fourth section, the results are discussed. Section 5 presents the conclusion.

2. Materials and methods

2.1 Data set description

2.1.1 Virufy COVID-19 open cough data set

The virufy COVID-19 open cough data set is the first free, publicly available data set containing COVID19 cough sounds [34]. COVID-19 PCR test results were also given along with the demographics of all the
patients in the data set. After obtaining informed patient consent, the data were collected from patients in a
hospital and under surveillance and verified by physicians, following standard operating procedures
(SOPs). These cough sounds, which were collected from 16 patients, were recorded at a sampling frequency
of 48 kHz. Then each recording was split so that it contained only one cough with the duration of 1.645
seconds. Thus, the data set consists of 121 single cough records, 48 of which were reported to have a
positive PCR test result, and 73 were reported to have a negative test result. The original format of the
records (before splitting) is also given in the data set.
6

2.1.2 NoCoCoDa

In [16], public media interviews with COVID-19 patients were manually reviewed and the cough sounds
were separated one by one and recorded. These interviews were broadcasted online by news sources. This
database, called the NoCoCoDa, contains a total of 73 single cough sounds and is available to researchers
free of charge upon request. This data set, with a total of 13 interviews attended by 10 people, includes
reflex COVID-19 cough sounds. The cough sounds were recorded as a .WAV file with a sampling
frequency of 44.1 kHz. In addition to the data, information about the patients is given in an additional file.
Since NoCoCoDa is derived from reports and news programs, other sounds such as speech or music are
heard in the background in some cough recordings. In a few, a mixture of throat clearing and coughing was
also found. All this is specified in the additional file.

In the present study, these noisy and suspicious coughs were removed from the NoCoCoDa data set and the
remaining 59 coughs were used. After combining these two data sets, the distribution of cough sounds
between the two classes is given in Table 1. As can be seen, a total of 180 cough sounds from 107 COVID19 patients and 73 cough sounds from non-COVID-19 patients were used in this study.

Table 1. Distribution of cough sounds between the two classes
Data set
Virufy
NoCoCoDa
Total

COVID-19
48
59
107

Non-COVID-19
73
0
73

Total
107
59
180

2.2. Mel-frequency cepstral coefficients (MFCCs)

MFCCs are one of the popular and successful methods for obtaining features in voice analysis and automatic
speech recognition systems [35]. MFCCs is a digital technical analysis that simulates the perception of
human ears and is calculated on the basis of Fast Fourier Transform (FFT). Since the characteristics of
speech signals remain stable in a very small time interval (about 20-30 ms), they are processed in very short
time intervals [36], [37]. This short interval is called the frame. Frames are usually chosen to overlap to
make transitions between frames smoother. Similar to the calculation of spectrogram, here, the windowing
process takes place to avoid a discontinuity at the beginning and end of the frames. The commonly used
window structure is Hamming. After windowing, FFT is applied to transform each frame from the time
7

domain to the frequency domain. The mel unit is a unit designed to imitate the perceptual feature of the
human ear. Conversion between the mel scale and the frequency scale is provided by the equation given
below.

𝑚𝑒𝑙 (𝑓) = 2595 × log (1 +

𝑓
)
700

(1)

In this way, MFCCs are the expression of the short-time power spectrum of the sound signal on the mel
scale [38], [39]. When MFCCs are calculated for a cough sound, a matrix is obtained in the M×N matrix,
where M is the number of MFCCs and N is the number of segments (the number of frames).

In the literature, MFCCs was used for the classification of cough sounds. For example, in [17], the features
were extracted by the MFCCs method for the classification of dry and wet coughs. In order to obtain
features with the MFCCs method, attention should be paid to important factors, called hyperparameters,
which include the type of window used, frame length, frame overlap length, number of segments used for
feature extraction, and number of MFCCs. In this study, the chosen window type was Hamming, and the
frame overlap length was half of the frame length. The optimum values of the other three hyperparameters
(the frame length, number of MFCCs, and number of segments used for feature extraction) were chosen
using the LOO-CV strategy.

2.3. Classification

Today, classification is used in various fields, from medical or genomic predictions to systems such as spam
detection and face recognition, and even in finance [40]. In the classification process, a classifier is trained
with samples with certain labels and a model is created. Then, the model is used to guess the label of
unknown samples [41]. Many classifiers based on machine/deep learning methods were used in the
classification of cough sounds. For example, in [42], Logistic regression (LR), support vector machines
(SVM), multilayer perceptrons (MLP), convolutional neural networks (CNN), long-short term memory
(LSTM), and residual-based neural network architecture (Resnet50) was used.

In this study, popular classifiers in machine learning systems were used to classify COVID-19 and nonCOVID-19 cough sounds. These are SVM, linear discriminant analysis (LDA), k-nearest neighbors (k8

NN), and partial least squares regression (PLSR). In SVM, LDA, and k-NN classifiers, two different
structures of the model were implemented. In SVM, two different non-linear kernels, namely radial basis
function and polynomial kernels were used. In k-NN, Euclidean and Chebyshev distance metrics, and in
LDA, linear and quadratic decision surfaces were tested. By adding PLSR to these six classifiers, a total of
seven different classifiers were created and the results of each classifier were calculated. To determine the
values of the hyperparameters in each classifier, the LOO-CV strategy was used.

2.4. Measuring the performance of the system

The performance of a classification system can be measured with different metrics. In this study, the
accuracy rate, AUC, F-measure, sensitivity, and specificity were used to measure the performance of the
system. There are different strategies for calculating these metrics. One of the popular strategies is LOOCV [43]. The LOO-CV strategy is adopted in a system when the number of samples in the data set or even
just the number of samples in a class is low [44]. In this strategy, the data set containing N samples is
divided into two sections. The N-1 sample is used for training the classifier and the single remaining sample
is used for testing the model. All the samples are used for testing only once, so the process is repeated N
times and, in this way, different metrics can be computed. In this study, the LOO-CV strategy was used to
calculate the metrics, taking into account the total number of samples (180 samples) in the two classes.

3. Results

A method was proposed based on machine learning to diagnose COVID-19 patients from non-COVID-19
patients by cough sounds. The proposed method was tested on a data set that includes virufy and NoCoCoDa
data sets. The features were extracted from cough sounds using the MFCCs method and classified with
seven different classifiers. To select values of hyperparameters in feature extraction and classification
processes, the accuracy rate metric was calculated according to the LOO-CV strategy. In searching for the
optimum value of a hyperparameter, all the other hyperparameters were kept constant. The value reaching
the highest accuracy rate in the searched range was selected as the optimum value of that hyperparameter.
In all of the steps of the study, for the MFCCs method, the window type was chosen as Hamming, and the
frame overlap length was half of the frame length.

9

3.1. Determination of the values of hyperparameters in the feature extraction phase

As mentioned earlier, in the MFCCs method, three hyperparameters were taken into account. These are the
frame length, number of MFCCs, and number of segments used for feature extraction. Frames lengths of
512, 1024, 2048, and 4096 samples were tested to determine the optimum frame length. In this case, the
number of MFCCs was selected as 13, and the number of segments used for feature extraction was selected
as N. That is, for each cough, a 13xN matrix was obtained, and by averaging in all N segments, a 13x1
feature vector was obtained. Then the feature vectors were transferred to the classifiers and classified. The
accuracy rate obtained for each frame length based on the LOO-CV strategy is separately presented for
each classifier in Table 2. The hyperparameters of the selected classifiers also appear in the table. As can
be seen, the Chebychev-kNN classifier successfully classified the cough sounds recorded from COVID-19
and non-COVID-19 patients for the 2048 frame length with an accuracy rate of 0.9389, followed by the
Euclidean-kNN classifier with an accuracy of 0.9167. By looking at the results in general, all the classifiers
achieved higher accuracy for the 2048 frame lengths. Therefore, for the continuation of the study, the
optimum value of the frame length hyperparameter was chosen as 2048 samples.

Table 2. Classification results for different frame lengths
Frame lengths
(samples)

Polynomial-SVM
Order=2

RBF-SVM
Sigma =1

LinearLDA
Gamma=0

QuadraticLDA
Gamma=0

ChebychevkNN
K=1

Euclidean kNN
K=1

PLSR
component=13

512
1024
2048
4096

0.8667
0.8722
0.8722
0.8667

0.8944
0.8944
0.8944
0.8944

0.8944
0.9000
0.9056
0.9000

0.8278
0.8389
0.8556
0.8500

0.9056
0.9222
0.9389
0.9056

0.9111
0.9111
0.9167
0.9167

0.8278
0.8444
0.8556
0.8500

To determine the optimum number of MFCCs, a scanning between 2 and 39 was performed. For this, as in
the previous step, the number of segments used for feature extraction was selected as N. In this way, for
example, when the number of MFCCs is 2, two features, and when it is 39, 39 features are extracted. The
performance of all the classifiers was measured by the accuracy rate metric using the LOO-CV strategy.
The classifiers' hyperparameter was adjusted as in the previous step. The results are given in Fig. 1. As it
turns out, Euclidean-kNN achieved the best performance using 19 MFCCs with an accuracy rate of 0.9500
followed by Chebychev-kNN and polynomial-SVM with an accuracy rate of 0.9389. These ratios were
obtained using 13 and 17 MFCCs, respectively. Therefore, the number of MFCCs was determined as 19
for the continuation of the study.
10

1
0.95

Accuracy rate

0.9
0.85
0.8
0.75
0.7
0.65
2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39

Number of MFCCs
polynomial-SVM

RBF-SVM

linear-LDA

Euclidean-kNN

Chebychev-kNN

PLSR

quadratic-LDA

Fig. 1. Classification results for different numbers of MFCCs

The last hyperparameter in the feature extraction phase is the number of segments used for this phase. In
order to obtain the optimum segment number, numbers from 1 to 50 were used and the averages were
obtained. For this purpose, only the first segment of the first 19-MFCCs was used as the feature vector and
classified by classifiers. Then, 19 features obtained by the average of the first two segments of 19-MFCCs
were classified. This process continued until 50. The hyperparameters of the classifiers were chosen as in
the previous steps. The results are shown in Fig. 2. Euclidean-kNN appears to be the most successful
classifier in using 17 segments, with an accuracy rate of 0.9833. After determining the optimum values of
the hyperparameters in the feature extraction phase, the striking point is the approximately 7% increase in
the accuracy of the Euclidean-kNN classifier.

11

1
0.95

Accuracy rate

0.9
0.85
0.8
0.75
0.7
0.65
1

3

5

7

9

11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49

Number of Segments
polynomial-SVM

RBF-SVM

linear-LDA

Euclidean-kNN

Chebychev-kNN

PLSR

quadratic-LDA

Fig. 2. Classification results for different numbers of segments used for feature extraction

3.2. Determination of the values of hyperparameters in the classification phase

To determine the optimum hyperparameter values of the classifiers, the accuracy rate metric obtained by
the LOO-CV strategy was used. In the RBF-SVM classifier, the range of 0 to 3 was screened by steps 0.1
to determine sigma. The results are given in Fig. A-1. When sigma=1.3, the accuracy rates reached 0.9611.
In the polynomial-SVM classifier, the order hyperparameter was searched between 1 to 4. The highest
accuracy rate (0.9556) was achieved when the third-order kernel function was used.

Different gammas from 0 to 1 were tested by steps 0.1 to determine gamma in the linear-LDA classifier.
The results showed that the highest accuracy was at gamma = 0.6, as given in Fig. A-2. The gamma was
changed to 0 and 1 in the quadratic-LDA classifier and the accuracy rate was calculated. A higher accuracy
rate (0.9056) was calculated at gamma = 0.

12

In order to determine k in both types of k-NN classifiers, the classification accuracy rate was calculated
from 1 to 25 by steps 1. The results are given in Fig. A-3. The highest accuracy rates at k = 1 were calculated
for both classifiers. Thus, the accuracy rates did not change for these classifiers.

Different components were tested by steps 1 from 2 to 19 in order to determine the component in the PLSR
classifier. The results show that the highest accuracy rate was when the component = 4, as given in Fig. A4. Thus, the PLSR classifier classified the cough sounds of COVID-19 and non-COVID-19 patients with
an accuracy rate of 0.8111, such as the linear-LDA.

In order to see the system performance more clearly, after determining the optimum hyperparameter values
of the classifiers, in addition to the accuracy rate, four more metrics were calculated. The determined
hyperparameter values and calculated metrics are given in Table 3. As it turns out, Euclidean-kNN is more
successful than the other classifiers in all the metrics. The Euclidean-kNN classifier showed 0.9720 and
1.0000 sensitivity to the COVID-19 and non-COVID-19 class, respectively.

Table 3. The results of classification by tuning hyperparameters in classifiers
Classifier

Hyperparameter

ACC

Polynomial-SVM
RBF-SVM
Linear-LDA
Quadratic-LDA
Euclidean-kNN
Chebychev-kNN
PLSR

order=3
sigma=1.3
gamma=0.6
gamma=0
k=1
k=1
component =4

0.9556
0.9611
0.8111
0.9056
0.9833
0.9056
0.8111

Sen.
Non-COVID-19
0.9452
0.9583
0.7808
0.8082
1.0000
0.8904
0.7808

Sen.
COVID-19
0.9626
0.9630
0.8318
0.9720
0.9720
0.9159
0.8318

F-measure

AUC

0.9452
0.9517
0.7703
0.8741
0.9799
0.8844
0.7703

0.9539
0.9606
0.8063
0.8901
0.9860
0.9031
0.8063

3.3. Feature selection based on SFS

In the last step of the study, the feature selection process based on the SFS method was performed separately
for each classifier. The results of this step are given in Table 4. In order to see whether the SFS method has
any effect, the accuracy rates calculated in the previous step are also shown in the table. As seen, there
appears to be an increase for all the other classifiers, with the exception of the Polynomial-SVM and
Euclidean-kNN classifiers.
13

Table 4. Effect of the SFS method on classification results
Classifier

Used Features

Polynomial-SVM
RBF-SVM
Linear-LDA
Quadratic-LDA
Euclidean-kNN
Chebychev-kNN
PLSR

19
18
11
15
19
13
17

ACC
(after used SFS)
0.9556
0.9667
0.8388
0.9111
0.9833
0.9444
0.8277

ACC
(before used SFS)
0.9556
0.9611
0.8111
0.9056
0.9833
0.9056
0.8111

4. Discussion

In this study, for the first time, the cough sounds of conscious and unconscious COVID-19 patients (in the
same class) were classified against the cough sounds of non-COVID-19 patients. The results showed that
this process was successful by the Euclidean-kNN classifier with an accuracy rate of 0.9833. Thus, it was
observed that conscious or unconscious cough sounds did not have any significance in the diagnosis of
COVID-19.

As said earlier, few studies have been conducted to distinguish between COVID-19 and non-COVID-19
patients based on cough sounds in the literature. None of these studies have yet been peer-reviewed.
However, they are available from preprint banks. Moreover, most of these studies have classified recorded
cough sounds that include several (3-5) coughs. In Table 5, the results of these studies and the results of the
proposed study are presented for comparison. Except for [33], other studies used data sets that include
several cough sounds in each sample. Although samples containing a single cough sound were used in this
study, as can be seen, all the metrics of the proposed study were higher than those of the other studies. An
important issue to note is the sensitivity of the system in the diagnosis of COVID-19 patients. The proposed
study is more successful than other studies with a sensitivity of 0.9720 to COVID-19 patients.

Table 5. Comparison of the results of the proposed study with the results of other studies
Study \ Metrics

ACC

[30]
[33]
[42]
Proposed method

0.9285
0.9586
0.9501
0.9833

Sen.
Non-COVID-19
0.9114
0.9863
0.9800
1.0000
14

Sen.
COVID-19
0.9457
0.9167
0.9300
0.9720

F-measure

AUC

0.9297
----0.9799

----0.9632
0.9860

5. Conclusion

To diagnosis the COVID-19 disease, it is essential to have a cost-effective, fast, easy, and accurate method,
considering the high cost of clinical tests, long turnaround time, and lack of equal access around the world.
Therefore, it is quite interesting and essential to distinguish COVID-19 patients from non-COVID-19 ones
by evaluating their cough sound via a mobile application based on computer-aided digital technologies. In
this way, the user can undergo constant self-surveillance wherever and whenever they want, which leads to
infrequent medical visits as well as reducing the crowd in hospitals and the burden of healthcare teams. In
this study, a method based on machine learning systems was presented to diagnose COVID-19 and nonCOVID-19 patients with a single cough sound. The features were obtained by the MFCCs method from
cough sounds and classified with seven different classifiers. The optimum hyperparameters of the system
were selected according to the accuracy rate calculated with the LOO-CV strategy. In this way, COVID-19
and non-COVID-19 patients were classified with an accuracy rate of 0.9833, observing an increase in the
accuracy of the most successful classifier (Euclidean-kNN) by around 7%. The system showed no error in
the diagnosis of non-COVID-19 patients; however, it exhibited a sensitivity of 0.9720 for COVID-19
patients, which shows that it is quite successful compared with the systems available in the literature.
Moreover, in this study, the used data set includes the unconscious and reflex cough sounds of COVID-19
patients. The results showed that conscious or unconscious cough sounds did not have any significance in
the diagnosis of COVID-19. For future studies, it is planned to test the system on a higher number of
samples and on an online platform.

Acknowledgment

The author thanks all the healthcare teams for their hard work during the COVID-19 pandemic. Also, the
author thanks Madison COHEN-MCFARLANE for sharing the NoCoCoDa data set.

Appendix

See Figures A-1, A-2, A-3, and A-4.

15

1

0.95

Accuracy rate

0.9
0.85
0.8
0.75
0.7
0.65
0.1 0.3 0.5 0.7 0.9 1.1 1.3 1.5 1.7 1.9 2.1 2.3 2.5 2.7 2.9

sigma

Fig. A-1. The accuracy rate of the RBF-SVM classifier for different sigma values

0.82
0.815

Accuracy rate

0.81

0.805
0.8
0.795
0.79
0.785
0.78
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

gamma

Fig. A-2. The accuracy rate of the linear-LDA classifier for different gamma values

16

1

Accuracy rate

0.95
0.9
0.85
0.8
0.75
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

k
Chebychev-kNN

Euclidean-kNN

Fig. A-3. The accuracy rate of Chebychev-kNN and Euclidean-kNN classifiers for different k values

0.85

Accuracy rate

0.8
0.75
0.7

0.65
0.6
0.55
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19

component

Fig. A-4. The accuracy rate of the PLSR classifier for different components

References

[1]

K. G. Andersen, A. Rambaut, W. I. Lipkin, E. C. Holmes, and R. F. Garry, “The proximal origin of
SARS-CoV-2,” Nature Medicine, vol. 26, no. 4. Nature Research, pp. 450–452, Apr. 01, 2020, doi:
17

10.1038/s41591-020-0820-9.
[2]

“Coronavirus

Disease

(COVID-19)

Situation

https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports

Reports.”
(accessed

Feb. 06, 2021).
[3]

D. Wang et al., “Clinical Characteristics of 138 Hospitalized Patients with 2019 Novel CoronavirusInfected Pneumonia in Wuhan, China,” JAMA - J. Am. Med. Assoc., vol. 323, no. 11, pp. 1061–
1069, Mar. 2020, doi: 10.1001/jama.2020.1585.

[4]

C. Uysal, A. Onat, and T. Filik, “Non-Contact Respiratory Rate Estimation in Real-Time with
Modified Joint Unscented Kalman Filter,” IEEE Access, vol. 8, pp. 99445–99457, 2020, doi:
10.1109/ACCESS.2020.2998117.

[5]

A. Waheed, M. Goyal, D. Gupta, A. Khanna, F. Al-Turjman, and P. R. Pinheiro, “CovidGAN: Data
Augmentation Using Auxiliary Classifier GAN for Improved Covid-19 Detection,” IEEE Access,
vol. 8, pp. 91916–91923, 2020, doi: 10.1109/ACCESS.2020.2994762.

[6]

S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio, and S. K. Antani, “Iteratively
Pruned Deep Learning Ensembles for COVID-19 Detection in Chest X-Rays,” IEEE Access, vol. 8,
pp. 115041–115050, 2020, doi: 10.1109/ACCESS.2020.3003810.

[7]

V. Chamola, V. Hassija, V. Gupta, and M. Guizani, “A Comprehensive Review of the COVID-19
Pandemic and the Role of IoT, Drones, AI, Blockchain, and 5G in Managing its Impact,” IEEE
Access, vol. 8, pp. 90225–90265, 2020, doi: 10.1109/ACCESS.2020.2992341.

[8]

K. Lan, D. tong Wang, S. Fong, L. sheng Liu, K. K. L. Wong, and N. Dey, “A Survey of Data
Mining and Deep Learning in Bioinformatics,” Journal of Medical Systems, vol. 42, no. 8. Springer
New York LLC, pp. 1–20, Aug. 01, 2018, doi: 10.1007/s10916-018-1003-9.

[9]

M. Ali Humayun et al., “Regularized Urdu Speech Recognition with Semi-Supervised Deep
Learning,” Appl. Sci., vol. 9, no. 9, p. 1956, May 2019, doi: 10.3390/app9091956.

[10]

J. Shuja, E. Alanazi, W. Alasmary, and A. Alashaikh, “COVID-19 open source data sets: a
comprehensive survey,” Appl. Intell., p. 1, 2020, doi: 10.1007/s10489-020-01862-6.

[11]

A. S. R. Srinivasa Rao and J. A. Vazquez, “Identification of COVID-19 can be quicker through
artificial intelligence framework using a mobile phone-based survey when cities and towns are under
quarantine,” Infection Control and Hospital Epidemiology, vol. 41, no. 7. Cambridge University
Press, pp. 826–830, Jul. 01, 2020, doi: 10.1017/ice.2020.61.

[12]

F. Shi et al., “Review of Artificial Intelligence Techniques in Imaging Data Acquisition,
Segmentation and Diagnosis for COVID-19,” IEEE Rev. Biomed. Eng., 2020, doi:
18

10.1109/RBME.2020.2987975.
[13]

N. Sharma et al., “Coswara -- A Database of Breathing, Cough, and Voice Sounds for COVID-19
Diagnosis,” Proc. Annu. Conf. Int. Speech Commun. Assoc. INTERSPEECH, vol. 2020-October, pp.
4811–4815,

May

2020,

Accessed:

Feb.

06,

2021.

[Online].

Available:

http://arxiv.org/abs/2005.10548.
[14]

B. Udugama et al., “Diagnosing COVID-19: The Disease and Tools for Detection,” ACS nano, vol.
14, no. 4. NLM (Medline), pp. 3822–3835, Apr. 28, 2020, doi: 10.1021/acsnano.0c02624.

[15]

“Why your coronavirus test could cost $23—or $2,315.” https://www.advisory.com/dailybriefing/2020/06/17/covid-test-cost (accessed Feb. 06, 2021).

[16]

M. Cohen-Mcfarlane, R. Goubran, and F. Knoefel, “Novel Coronavirus Cough Database:
NoCoCoDa,”

IEEE

Access,

vol.

8,

pp.

154087–154094,

2020,

doi:

10.1109/ACCESS.2020.3018028.
[17]

H. Chatrzarrin, A. Arcelus, R. Goubran, and F. Knoefel, “Feature extraction for the differentiation
of dry and wet cough sounds,” in MeMeA 2011 - 2011 IEEE International Symposium on Medical
Measurements

and

Applications,

Proceedings,

2011,

pp.

162–166,

doi:

10.1109/MeMeA.2011.5966670.
[18]

R. X. A. Pramono, S. A. Imtiaz, and E. Rodriguez-Villegas, “A Cough-Based Algorithm for
Automatic Diagnosis of Pertussis,” PLoS One, vol. 11, no. 9, p. e0162128, Sep. 2016, doi:
10.1371/journal.pone.0162128.

[19]

J. Amoh and K. Odame, “Deep Neural Networks for Identifying Cough Sounds,” IEEE Trans.
Biomed.

Circuits

Syst.,

vol.

10,

no.

5,

pp.

1003–1011,

Oct.

2016,

doi:

10.1109/TBCAS.2016.2598794.
[20]

V. Bhateja, A. Taquee, and D. K. Sharma, “Pre-Processing and Classification of Cough Sounds in
Noisy Environment using SVM,” in 2019 4th International Conference on Information Systems and
Computer

Networks,

ISCON

2019,

Nov.

2019,

pp.

822–826,

doi:

10.1109/ISCON47742.2019.9036277.
[21]

J. P. Cohen, P. Morrison, L. Dao, K. Roth, T. Q. Duong, and M. Ghassemi, “COVID-19 Image Data
Collection: Prospective Predictions Are the Future,” J. Mach. Learn. Biomed. Imaging, vol. 2020,
pp. 2–3, Jun. 2020, Accessed: Feb. 07, 2021. [Online]. Available: http://arxiv.org/abs/2006.11988.

[22]

J. P. Cohen, P. Bertin, and V. Frappier, “Chester: A Web Delivered Locally Computed Chest X-Ray
Disease Prediction System,” arXiv, pp. 1–12, Jan. 2019, Accessed: Feb. 07, 2021. [Online].
Available: http://arxiv.org/abs/1901.11210.
19

[23]

X. Yang, X. He, J. Zhao, Y. Zhang, S. Zhang, and P. Xie, “COVID-CT-Dataset: A CT Scan Dataset
about COVID-19,” arXiv, Mar. 2020, Accessed: Feb. 07, 2021. [Online]. Available:
http://arxiv.org/abs/2003.13865.

[24]

S. Wang et al., “A deep learning algorithm using CT images to screen for Corona Virus Disease
(COVID-19),” medRxiv. medRxiv, Apr. 24, 2020, doi: 10.1101/2020.02.14.20023028.

[25]

L. Wang, Z. Q. Lin, and A. Wong, “COVID-Net: a tailored deep convolutional neural network
design for detection of COVID-19 cases from chest X-ray images,” Sci. Rep., vol. 10, no. 1, pp. 1–
12, Dec. 2020, doi: 10.1038/s41598-020-76550-z.

[26]

B. Kleinberg, I. van der Vegt, and M. Mozes, “Measuring Emotions in the COVID-19 Real World
Worry Dataset,” arXiv, Apr. 2020, Accessed: Feb. 07, 2021. [Online]. Available:
http://arxiv.org/abs/2004.04225.

[27]

J. M. Banda et al., “A large-scale COVID-19 Twitter chatter dataset for open scientific research -an international collaboration,” arXiv, Apr. 2020, Accessed: Feb. 07, 2021. [Online]. Available:
http://arxiv.org/abs/2004.03688.

[28]

E. Chen, K. Lerman, and E. Ferrara, “Tracking social media discourse about the COVID-19
pandemic: Development of a public coronavirus Twitter data set,” JMIR Public Heal. Surveill., vol.
6, no. 2, p. e19273, Apr. 2020, doi: 10.2196/19273.

[29]

C. Brown et al., “Exploring Automatic Diagnosis of COVID-19 from Crowdsourced Respiratory
Sound Data,” in Proceedings of the ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, Aug. 2020, vol. 11, pp. 3474–3484, doi: 10.1145/3394486.3412865.

[30]

A. Imran et al., “AI4COVID-19: AI enabled preliminary diagnosis for COVID-19 from cough
samples via an app,” Informatics Med. Unlocked, vol. 20, p. 100378, Jan. 2020, doi:
10.1016/j.imu.2020.100378.

[31]

A. Pal and M. Sankarasubbu, “Pay Attention to the cough: Early Diagnosis of COVID-19 using
Interpretable Symptoms Embeddings with Cough Sound Signal Processing,” arXiv, Oct. 2020,
Accessed: Feb. 06, 2021. [Online]. Available: http://arxiv.org/abs/2010.02417.

[32]

P. Bagad et al., “Cough Against COVID: Evidence of COVID-19 Signature in Cough Sounds,”
arXiv, Sep. 2020, Accessed: Feb. 06, 2021. [Online]. Available: http://arxiv.org/abs/2009.08790.

[33]

N. Manshouri, “Identifying COVID-19 by Using Spectral analysis of Cough Recordings: A
Distinctive Classification Study Identifying COVID-19 by Using Spectral analysis of Cough
Recordings: A Distinctive Classification Study Negin MANSHOURI,” Preprints, Jan. 2021.
Accessed: Feb. 06, 2021. [Online]. Available: www.preprints.org.
20

[34]

G. Chaudhari et al., “Virufy: Global Applicability of Crowdsourced and Clinical Datasets for AI
Detection of COVID-19 from Cough,” arXiv, Nov. 2020, Accessed: Feb. 06, 2021. [Online].
Available: http://arxiv.org/abs/2011.13320.

[35]

W. Han, C. F. Chan, C. S. Choy, and K. P. Pun, “An efficient MFCC extraction method in speech
recognition,” in Proceedings - IEEE International Symposium on Circuits and Systems, 2006, pp.
145–148, doi: 10.1109/iscas.2006.1692543.

[36]

R. W. Schafer and L. R. Rabiner, “Digital Representations of Speech Signals,” Proc. IEEE, vol. 63,
no. 4, pp. 662–677, 1975, doi: 10.1109/PROC.1975.9799.

[37]

B. S. Atal, “Automatic Recognition of Speakers from Their Voices,” Proc. IEEE, vol. 64, no. 4, pp.
460–475, 1976, doi: 10.1109/PROC.1976.10155.

[38]

K. Patel and R. K. Prasad, “Speech Recognition and Verification Using MFCC & VQ,” 2013.

[39]

S. B. Davis and P. Mermelstein, “Comparison of Parametric Representations for Monosyllabic
Word Recognition in Continuously Spoken Sentences,” IEEE Transactions on Acoustics, Speech,
and Signal Processing, vol. 28, no. 4. pp. 357–366, 1980, doi: 10.1109/TASSP.1980.1163420.

[40]

R. Bost, R. A. Popa, S. Tu, and S. Goldwasser, “Machine Learning Classification over Encrypted
Data,” Feb. 2015, doi: 10.14722/ndss.2015.23241.

[41]

M. Melek, N. Manshouri, and T. Kayikcioglu, “Low-Cost Brain-Computer Interface Using the
Emotiv Epoc Headset Based on Rotating Vanes,” Trait. du Signal, vol. 37, no. 5, pp. 831–837, Nov.
2020, doi: 10.18280/ts.370516.

[42]

M. Pahar, M. Klopper, R. Warren, and T. Niesler, “COVID-19 Cough Classification using Machine
Learning and Global Smartphone Recordings,” Dec. 2020, Accessed: Feb. 06, 2021. [Online].
Available: http://arxiv.org/abs/2012.01926.

[43]

M. Melek, N. Manshouri, and T. Kayikcioglu, “An automatic EEG-based sleep staging system with
introducing NAoSP and NAoGP as new metrics for sleep staging systems,” Cogn. Neurodyn., pp.
1–19, Oct. 2020, doi: 10.1007/s11571-020-09641-2.

[44]

G. I. Webb et al., “Leave-One-Out Cross-Validation,” in Encyclopedia of Machine Learning,
Springer US, 2011, pp. 600–601.

21

