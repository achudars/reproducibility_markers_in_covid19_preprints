H YBRID QUANTUM CONVOLUTIONAL NEURAL NETWORKS
MODEL FOR COVID-19 PREDICTION USING CHEST X-R AY
IMAGES

arXiv:2102.06535v1 [eess.IV] 8 Feb 2021

A P REPRINT
Essam H. Houssein
Faculty of Computers and Information
Minia University
Egypt
essam.halim@mu.edu.eg
Mohamed Elhoseny
Department of Computer Science
American University in the Emirates
Dubai, UAE.
melhoseny@ieee.org

Zainab Abohashima
Faculty of Computer Science
Nahda University in Beni-Suef
Egypt
zeinababohashima20@gmail.com
Waleed M. Mohamed
Faculty of Computers and Information
Minia University
Egypt
waleedmakram@mu.edu.eg

February 15, 2021

A BSTRACT
Despite the great efforts to find an effective way for COVID-19 prediction, the virus nature and
mutation represent a critical challenge to diagnose the covered cases. However, developing a model
to predict COVID-19 via Chest X-Ray (CXR) images with accurate performance is necessary to
help in early diagnosis. In this paper, a hybrid quantum-classical convolutional Neural Networks
(HQCNN) model used the random quantum circuits (RQCs) as a base to detect COVID-19 patients
with CXR images. A collection of 6952 CXR images, including 1161 COVID-19, 1575 normal,
and 5216 pneumonia images, were used as a dataset in this work. The proposed HQCNN model
achieved higher performance with an accuracy of 98.4% and a sensitivity of 99.3% on the first dataset
cases. Besides, it obtained an accuracy of 99% and a sensitivity of 99.7% on the second dataset cases.
Also, it achieved accuracy, and sensitivity of 88.6%, and 88.7%, respectively, on the third multi-class
dataset cases. Furthermore, the HQCNN model outperforms various models in balanced accuracy,
precision, F1-measure, and AUC-ROC score. The experimental results are achieved by the proposed
model prove its ability in predicting positive COVID-19 cases.

Keywords COVID-19, Convolutional Neural Networks (CNN), Chest X-Ray, Medical Image Classification, pneumonia,
Quantum Circuit, Quantum Computing, SARS-CoV-2.

Abbreviations
CNNs
QC
ReLU
Conv
CT

Convolutional Neural Networks
Quantum Computing
Rectified Linear Unit
Convolutional
Computed Tomography

RQCs
COVID-19
DL
CXR

Random Quantum Circuits
Coronavirus Disease 2019
Deep Learning
Chest X-Ray

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

1

Introduction

Recently, COVID-19 has been rapidly spreading in several countries caused by infection of human beings with severe
acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [1]. The ongoing COVID-19 pandemic attacks human health
causing respiratory disease and acute kidney injury [2]. COVID-19 stands for coronavirus disease 2019, which is a
new type of coronavirus and falls as a subtype of RNA viruses [3]. The genetic structure of COVID-19 is identical
to bat-coronavirus RaTG13, MERS-coronavirus, and SARS-coronavirus by 95%, 50%, and 82% respectively [4, 5].
The first outbreak of the disease was in China at the end of 2019. The most common clinical symptoms of the disease
are fever, sore throat, cough, dyspnea, and muscle pain [6]. In March 2020, the World Health Organization (WHO)
reported COVID-19 as a pandemic [1]. The most common diagnostic tool used for COVID-19 prediction is a real-time
"reverse transcription-polymerase chain reaction" (RT-PCR) [7], even though RT-PCR has low sensitivity with the early
phases [8]. Alternative imaging tools (i.e., chest X-ray (CXR) and computed tomography (CT) scans) play an important
and critical role in COVID-19 prediction [9]. Radiologists prefer to use the CXR to diagnose chest diseases. The CXR
has been used to detect infected COVID-19 cases [10]. Thus utilizing the artificial neural networks to detect COVID-19
in CXR has become needed.
The use of Artificial Neural Networks (ANNs) in medical data has significantly advanced. The CNNs are one of the
most powerful, and widespread deep learning models in pattern recognition and image classification. Furthermore,
CNNs have achieved superior performance in medical image detection [11]. Various works for the prediction of
COVID-19 cases using CNNs structure have been proposed, these works are presented in detail in section "Related
Work". Chowdhury et al. [12] proposed deep CNNs models to pre-trained their model using transfer learning to
discuss the leverage of artificial intelligence (AI) for classification COVID-19 on CXR images. Especially that the
computational power of classical ANNs can’t learn large training data with low-cost [13]. In a particular, it is not
capable of generating more kernels (kernel estimation) with high-dimensional features [14, 15]. Effortlessly, quantum
computing is capable of performing complex kernels in n-dimensional space.
On the other hand, the quantum computing (QC) field has proven its significant role in intractable problems with
classical counterparts via quantum supremacy [16, 17] and with the upgrowth of the concept of quantum computing
(QC) and its improvements in the machine learning field (i.e., learning capacity, run-time, and learning efficiency) [18].
Quantum computing has also demonstrated a remarkable influence in machine learning (ML) on near-term quantum
computers [19]. Quantum neural network approaches have been proposed such as [20, 21]. According to our best
of knowledge, the start point of QNNs was in 1995. Kak [22] introduced NNs concepts in the quantum computing
world. This study focuses on the hybrid “quantum-classical” approach. Henderson et al. [23] presented a new quantum
convolutional layer within CNNs based on quantum circuits to estimate kernel in high-dimensionality. In a similar
work [14], Havlicek et al. proposed a quantum kernel algorithm of support vector machines to estimate kernel with
a quantum circuit and to deal with huge features by estimating kernel in n-dimensionality space. Mitarai et al. [24]
proposed a new hybrid method called QC learning (QCL) based on a quantum circuit. QCL works with large datasets
for clustering, regression, and classification tasks.
Therefore, the motivation behind this work is to combine the advantage of the quantum convolutional layer with CNNs
and CXR images as an important tool and cheapest diagnostic technique of COVID-19 to produce a new proposed
HQCNN model. This model aims to improve the performance of CNNs to detect coronavirus cases in early phases
and to speed up the diagnosis and remedy. The HQCNN model is measured with two angle encoding gates and a
different number of shots. The better results have been achieved by the Ry angle gate and 1000 shots. The proposed
HQCNN model achieved higher performance with an accuracy of 98.4%, 99%, and 88.6% on the first dataset( normal
and COVID-19 cases), the second dataset (COVID-19 and pneumonia cases), and the third dataset (normal, COVID-19,
and pneumonia cases), respectively. Also, the higher sensitivity and AUC-ROC scores have been achieved with 99.3%,
and 100%, respectively on the COVID-19 and pneumonia dataset. Besides, the HQCNN model outperforms various
models in specificity, balanced accuracy, precision, F1-measure, and AUC-ROC score. The experimental results show
the ability of the proposed HQCNN model to classify positive COVID-19 cases. The restrictions of the HQCNN model
are highlighted in Section 5.
The main contributions of this work are:
• A new hybrid CNNs model combined with a quantum circuit called HQCNN for COVID-19 prediction based
chest X-ray images is proposed.
• The comparative performance investigates of HQCNN model using encoding angle methods and a various
number of shots on the quantum device for COVID-19 classification cases.
• HQCNN model is evaluated on binary and multi-class datasets with confirmed COVID-19 cases.
2

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

• An exhaustive and a comparative experimental discussion is presented in terms of accuracy, balanced accuracy,
sensitivity, specificity, precision, F1-measure, FBeta-measure, AUC-ROC curve, and confusion matrix to
evaluate the performance of the proposed HQCNN model.
The remainder of this paper is organized as follows: Section 2 gives an overview of recent COVID-19 classification
based the CNNs with CXR and CT images and shows a comparative performance of previous works. Background
about the concept of quantum computing (Qubits, and quantum gates) and CNNs are presented in Section 3. The
hybrid proposed HQCNN model is introduced in detail in Section 4. Section 5 presents the used datasets, performance
measures, and the experimental results of the hybrid HQCNN model. Finally, the conclusion of this work and future
research are delineated in Section 6.

2

Related Work

This section provides various works of COVID-19 classification based on CNNs that had recently been presented by
researchers. Related works are divided into studies based on CXR images and studies based on CT scans.
In [25], a CNNs model (i.e., VGG19, Xception, MobileNetv2) based on transfer learning is proposed to extract
meaningful biomarkers of coronavirus patients. Furthermore, the used dataset is collected with 224 COVID-19, 714
pneumonia (bacterial and viral), and 504 normal CXR images to evaluate the performance of CNNs models on the
classification of medical images. The results are reported with 96.78% accuracy, 98.66% sensitivity, and 96.46%
specificity. A patch-based technique utilizing statistical analysis with ResNet18 and fully convolutional-DenseNet103
architectures is presented in [26]. Due to the lack of CXR images for COVID-19, this technique is used with a small
dataset to classify COVID-19 patients. Moreover, the proposed technique has achieved an accuracy of 88.9% and a
precision of 83.4%. In another study [27], a deep CNNs model is introduced to detect positive patients of COVID-19,
called Truncated InceptionNet. The inceptionNetV3 is modified with the Truncated model to deal with limited datasets
of COVID-19 to reduce over-fitting. Besides, 162 COVID-19 confirmed cases are added to six several datasets. The
proposed model is evaluated with different datasets to test the ability of the Truncated InceptionNet model for predicting
positive cases of COVID-19 of each dataset. This model achieved 99.9% accuracy for the fifth dataset with 162
COVID-19,1583 normal, and 4280 pneumonia. The DarkNet technique is presented for COVID-19 classification on
CXR images in [28]. This model is predicted COVID-19 cases without using a feature extractor algorithms. The
DarkNet model is applied as a classifier for YOLO object detection. This model is used with binary and multi-class
COVID-19 classification. The DarkNet model is achieved 98.08%, 95.13%,95.30%, 96.51% for accuracy, sensitivity,
specificity, and F1-measure, respectively. Besides, the model is achieved 87.02% of accuracy for a multi-class dataset.
In another work [29], a hybrid CNN-LSTM model is presented using CNNs and long short-term memory to detect
COVID-19 cases. The CNNs are utilized for feature extraction and LSTM for the classification of images. The
CNN-LSTM model is used with 4,575 CXR images, including 1525 COVID-19 images. The CNN-LSTM model
has achieved higher results with 99.4%, 99.3%, 99.2%,99.9%, and 99.9% for accuracy, sensitivity, specificity, AUC
score, and F1-measure, respectively. Also, The AUC-ROC curve and confusion matrix are provided to evaluate the
CNN-LSTM model.
In [30], a deep CNN based on Xception model is introduced, called CoroNet. The proposed model utilized an ImageNet
dataset for the pre-trained process. This model is evaluated on binary and multi-class datasets with 284 COVID-19
images. The proposed CoroNet model accomplished an accuracy of 99%, 95%,89.6% for binary, three-class, and
four-classes datasets. The overall accuracy is achieved with 89.6%. In this study [31], The VGG16 architecture is used
with transfer learning for COVID-19 classification from CXR images. The two models are proposed to classify between
(COVID-19 vs. healthy) and (COVID-19 vs. pulmonary) for the first and second models, respectively. The first model
achieved 96% of accuracy and sensitivity, 98% of specificity, and 94% of F1-measure. The results 98%, 87%, 94%,
and 89% for accuracy, sensitivity, specificity, and F1-measure, respectively, are achieved by the second model. On the
other side, a hybrid GSA-DenseNet121 DL model is presented using a gravitational search optimizer [32]. The GSA
is used to the hyper−parameters tuning of the DenseNet121 model. The random copying is performed to a balance
the used dataset. The GSA-DesneNet121 model is applied with 306 CXR images, including 99 positive COVID-19
and 207 Non-COVID-19. The proposed model achieved 98.3% of accuracy. In a similar work [33], a hybrid CNN’s
technique is proposed using a swarm-based optimizer for COVID-19 classification. The hybrid technique is combined
among inception model, Marine Predators, and fractional-order calculus algorithms. The Inception CNNs model is
used for feature extraction. The Marine Predators algorithm is applied to reduce extractor features by the selection of
meaningful features. The proposed technique (IFM) is improved using the fractional-order calculus algorithm. This
technique is evaluated on two COVID-19 datasets: the first dataset includes 200 and the second dataset contains 219
COVID-19 CXR images. The proposed IFM technique achieved 98.7% of accuracy and 98.2% of f1-score for the first
dataset. The results 99.6%of accuracy, and 99% of f1-score are obtained for the second dataset.
3

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

A new approach [34] is proposed utilizing capsule network and CXR images for COVID-19 cases detection called the
CapsNet model. This model is evaluated on binary and multi-class datasets. This model has used 1050 CXR images for
COVID-19, normal, and pneumonia classes. For binary dataset, The CapsNet model is accomplished 97.24%, 97.42%,
97.04%, 97.08%, and 97.24% for accuracy, recall, specificity, precision, and F1-measure, respectively. Also, the results
84.22% of accuracy, 84.22% of recall, 91.79% of specificity, 84.61% of precision, and 84.21% of F1-measure are
achieved for the multi-class dataset. In another separate study [35], a novel system using the EfficientNet model to
diagnose COVID-19 patients. The EfficientNet has used a 10-fold cross-validation technique for binary and multi-class
classification with 1,508 a total number of CXR images. This model has reported binary class results 99.62% of
accuracy, 99.63% recall, 99.64% of precision, and 99.62% of f1-score. The model achieved 96.70%, 96.69%, 97.59%,
and 97.11% for accuracy, recall, precision, and F1-score, respectively with multi-class classification.
In [36], a 3D CNNs is introduced based on the location-attention model to distinguish COVID-19 patients from CT
images. The dataset images are composed of 219 COVID-19, 224 pneumonia, and 175 normal images. This model
is achieved 86.7% of classification accuracy. In another study with CT images [37], the CNNs model is proposed
with multi-objective differential evolution for tuning hyper-parameters of CNNs. The results are reported with 0.92%
accuracy, 0.90% for sensitivity, specificity, and F1-measure.
The ResNet50 model is used with multi-view images for the classification of COVID-19 patients with chest CT scans.
The proposed model is achieved an AUC of 81.9%, the sensitivity of 81.8%, accuracy of 76%, and specificity of 61.5%
in [38]. In [39], a deep learning technique is proposed using DenseNet−201 model and transfer learning. The proposed
technique is used on 2492 CT images, including 1262 COVID-19, and 1230 Non-COVID-19 images. The proposed
technique is applied with learned weights of the ImageNet dataset to extract features. It is achieved accuracy with 97%
compared to Resnet152V2, VGG16 models. Besides, it obtained AUC- ROC score with 0.97%.
The previous studies faced inconsistency issues due to a variety of methods, images, a variety of data. A brief
comparison of the previous research has been presented in terms of the applied methods, images, data, and classification
performance (as shown in Table 1). Since chest CXR and CT scans are the second tools to diagnose and detect the
COVID-19 pandemic, so the classification of COVID-19 has become a hot area of research. The researchers collected
datasets from several resources to train and test the models as shown in Table 1. There is no a standard dataset due to
the shortage of COVID-19 images. Most of the state-of-the-art COVID-19 classification is designed to fit the currently
limited images as [26, 27] and to help in early diagnosis for COVID-19 cases. There studies focus on prediction
confirmed COVID-19 from COVID-19 and normal datasets such as [28] and another focus on differentiating confirmed
COVID-19 from other pneumonia diseases [27, 38, 32]. Therefore, the prediction of COVID-19 still needs to further
accurate and faster models to assist the radiologists in coming early diagnosis and treatment.

3

Preliminaries

In this section, an introduction about some of the concepts quantum computing used in this work like the quantum bit,
quantum gates, and architecture of convolutional neural networks (CNNs). If the reader is familiar with these concepts
may skip this subsection.
3.1

Quantum computing

Quantum computing relies on postulates and characteristics of quantum mechanics (i.e., quantum bits, interference,
superposition, and entanglement) to information processing. Quantum computing gives us the ability to solve complex
problems better and faster than classical computing [40, 41]. Qubit is the small unit to process information in a quantum
computer like the bit in classical computing. A qubit can also be in one-state, zero-state, or both of states at the same
time known as linear superposition. The qubit is a state vector in Hilbert space.
 
θ
|ψi =
= θ|0i + δ|1i
(1)
δ
Where θ and δ are the probability amplitudes that represented by complex numbers and |θ2 | + |δ 2 | = 1
From the postulates of quantum mechanics, any unitary transformation (unitary matrix) is a quantum gate. Matrix to be
unitary, the following condition must be verified:
U U † = U †U = I
†

(2)

where U is the conjugate transpose of a matrix U and I is an identity matrix. Quantum gates can be classified based on
numbers of qubits: one-qubit gates, two-qubits gates, and multiple-qubits gates [42, 43]. Firstly, from the most popular
and widely used gate in one-qubit gates is a Hadamard gate or square-root of NOT gate. The use of the Hadamard
4

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 1
Comparison of classification performance for existing related work.
Work
[25]

Images
224 COVID-19 714 pneumonia 504 normal

Type
CXR

Method
MobileNetV2

Data
imbalanced

ACC.(%)
96.78

[26]

180 COVID-19 191 normal 131 others

CXR

ResNet18

imbalanced

88.9

[27]

162 COVID-19

CXR

CNNs

imbalanced

99.9

[28]

125 COVID-19 500 normal

CXR

DarkNet

imbalanced

98.08

[29]

1525 COVID-19 1525 normal 1525 pneumonia

CXR

CNN+LSTM

balanced

99.4

[30]

284 COVID-19 330 bacterial 310 normal 327 Viral

CXR

Xception

balanced

89.6

[31]

250 COVID-19 2753 pneumonia 3520 normal

CXR

VGG16

imbalanced

96

[32]

99 COVID-19 207 Non-COVID-19

CXR

DenseNet121+GSA

balanced

98.3

[33]

200 COVID-19 1,675 Non-COVID-19

CXR

Inception+FO-MPA

imbalanced

98.7

[33]

219 COVID-19 1,341 Non-COVID-19

CXR

Inception+FO-MPA

imbalanced

99.6

[34]

1050 COVID-19 1050 normal

CXR

Capsule Network

balanced

97.24

[34]

1050 COVID-19 1050 normal 1050 pneumonia

CXR

Capsule Network

balanced

84.22

[35]

504 COVID-19 500 normal

CXR

EfficientNet

balanced

99.62

[35]

504 COVID-19 500 normal 504 pneumonia

CXR

EfficientNet

balanced

96.70

[36]

219 COVID-19 175 normal 224 pneumonia

CT

3D-DL

balanced

86.7

[37]

73 COVID-19

CT

CNNs+MODE

-

92

[38]

368 COVID-19 127 pneumonia

CT

ResNet50

imbalanced

76

[39]

1262 COVID-19 1230 Non−COVID-19

CT

DenseNet201

balanced

97

gate to present qubits into superposition. Pauli gates also are one-qubit gates. Secondly, two-qubits gates which work
on 4x4 unitary matrices. For example, Controlled NOT, and swap gate. Lastly, multiple-qubits gates which work on
multiple qubits as 2n x 2n unitary matrices such as Toffoli and SWAP gates. Table 2 shows quantum gates with circuit
representation, unitary matrix, the number of qubits, and the operation of the gate.
3.2

Convolutional Neural Networks

Convolutional Neural Networks (CNNs) [44] inspired by convolution operation to produce a convolutional (Conv)
layer that is the heart of the CNNs. As illustrated in Figure 1, the basic architecture of CNNs is similar to a multi-layer
perceptron starts with the input image and sequence of hidden layers to predict labels over the output layer. The layers
of CNNs are explained in detail in Section 4. The CNNs play a critical role in computer vision applications such as
image classification [27], image segmentation [45], object detection [46], and signal processing [47]. Various models
had been developed based on the concepts of CNNs as ResNet50, and VGG-19.

4

Proposed HQCNN Model

The proposed hybrid quantum-classical CNNs model (HQCNN) aims to improve CNNs classification for medical
images and predict COVID-19 and healthy patients in early stages. The main idea of the HQCNN model is based
on hybrid computation to enhance the performance of classical learning [48]. The proposed model consists of two
parts: first, the quantum part has utilized the quantum Conv layer, which is proposed by Henderson et al. [23]. Second,
the classical part with CNNs structure. As shown in Figure 2, the HQCNN model has one quantum Conv layer, three
Conv layers followed by the rectified linear unit activation function, two max-pooling layers, and followed by two fully
connected layers. The layers of the model are presented in detail in the following steps.
5

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 2
summarizes standard quantum computing gates.
Gate

Notation

Matrix
1
√
2

Hadamard




Pauli-X


Pauli-Y


Pauli-Z



Toffoli

4.1











1
0
0
0
0
0
0
0

1
−1

0 1
1 0
0
i

−i
0



1
0

0
−1



0
0
1
0

0
1
0
0


0
0 
0 
1

0
1
0
0
0
0
0
0

0
0
0
1
0
0
0
0

0
0
0
0
1
0
0
0

0
0
0
0
0
1
0
0

0
0
1
0
0
0
0
0

Use

1

Create superposition state between two quantum bits.

1

Flip quantum bit from state
to another.

1

Make π-rotation for quantum
bit around the Y-axis.

1

Make π -rotation for quantum bit around the Z-axis.

2

Swap two quantum bits
states.

3

Controlled-Controlled NOT
(CC Not) gate. Flip target
quantum bit if both control
two quantum bits equal one.



1
 0
 0
0


Swap

1
1

Qbit


0
0
0
0
0
0
0
1

0
0
0
0
0
0
1
0












Quantum convolutional layer

The proposed HQCNN model has used quantum convolution that is presented by the Maxwell Henderson et al. [23].
Quantum convolution works as small random quantum circuits (RQCs) to calculate convolution operation and can
implement on near-term quantum hardware. This circuit has applied with local locations of input images to extract
elementary and informative features. The quantum convolution layer consists of three phases: encoding, random
quantum circuit, and decoding(as shown in Figure 2).
4.1.1

Encoding

Up till now, the encoding data to quantum is a challenge in quantum machine learning (QML) [49]. Several encoding
methods have been discussed in [50]. In this work, angle encoding has been used to transform input data into rotation
angles of quantum states. The angle rotations gates are the simplest encoding methods to access data into a quantum
circuit. In this study, due to needing the single quantum gate for each entry to encode data. These gates are corresponding
to encode classical pixel data to a quantum state. Rotation matrices are rotation operators of Pauli-matrices in the form
of exponential around X, Y , Z axes (as seen in Table 1). Three rotation gates Rx, Ry, Rz are a single quantum bit
rotation via angle α around X, Y , and Z axes, respectively. The RY and RX rotation gates can be represented by the
following equations.


 
cos α2  −i sin α2
Rx (α) =
(3)
−i sin α2
cos α2


 
cos α2  − sin α2
Ry (α) =
(4)
cos α2
sin α2
4.1.2

Random Quantum Circuit

A quantum circuit is a series of quantum unitary operations (or gates) and measurements connected via wires (Qubits).
Just like the classical Conv layer, quantum Conv layer composed of quantum kernels apply to the input image. The
main idea of quantum convolution utilizing random quantum circuits to split input image into small local locations to
extract meaningful features. The advantages of the quantum circuit in quantum convolution works with a few quantum
bits and shallow-depth of quantum circuits.
6

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Figure 1: Illustrates the general architecture of the CNNs: The CNNs consists of feature extraction and classification
parts. First of all, the input image is pushed to the Conv layer as a matrix of pixels to extract features and patterns from
images by apply kernels on the input image. Then, the pooling layer is applied to reduce the number of features and fast
training time. The next layer is applied convolution operation on convoluted features with the kernels to extract more
invariant and local features and so on. With the last pooled feature map flatten layer has been applied. Finally, fully
connected layers have been used for train and classification.

4.1.3

Measurement

The measurement phase is also known as the decoding phase. Decoding is measuring quantum data to transform into
classical form. Pauli matrices can use as measurement methods [51]. In the HQCNN model, the Pauli-Z gate is used to
the decoding phase (as seen in Table 2).
4.2

Convolutional layer

Conv layer is the pivotal and significant layer in the feature extraction part of CNN. This layer performs convolution
operation on input features with kernels to extract invariant and informative features from images as convoluted features
map to the next layer. Convolution operation computes dot products between small local locations of the input image
and kernels[28, 52].
XX
(F ∗ K)(i, j) =
K(m, n)F (i − m, j − n)
(5)
m

n

Where ∗ is the convolution operation to produce a convoluted feature map, F is the input feature, and K is kernel
or filter. Conv layer has been followed by the ReLU function transformation to add activation values into the model
network. The function returns 0 for all negative values and returns the maximum value for all positive values. The
ReLU function can be defined by the following formula:
ReLU (x) = max(0, x)
Where x is an input value.
7

(6)

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Figure 2: Block diagram for proposed HQCNN model.
4.3

Max-pooling layer

Max-pooling layer has used to reduce computational learning by selection the most important and valuable features.
Convoluted feature maps have been divided into small regions based on the stride number. The max-pooling idea has
taken the maximum value of each small location to produce pooled feature maps. Before the classification part, flatten
is used to link two parts in CNNs by converting the max-pooled feature map into a 1-dimensional array.
4.4

Fully Connected Layer

The Fully Connected (FC) layer is the second part of the CNNs structure. The fully connected layers perform the
classification process after the flattening layer by applied weights to predict classes. The dropout layer is used after the
FC layer to reduce the overfitting of the model (as shown in Figure 2).
Figure 3 illustrates the flowchart of the HQCNN model: the proposed HQCNN model has nine layers, one quantum
Conv layer, three classical Conv layers with ReLU function, two max-pooling layers, two FC layers with ReLU function,
and one output layer is applied with a softmax activation function. The quantum Conv layer is used encoding method
with RY rotation gate and decoding with the Pauli-Z gate. The three classical Conv layers are used with 2D CNNs
and are combined with the max-pooling layer. Each max-pooling layer is performed with a 2 x 2 kernel size and the
stride equal to 2, followed by a dropout layer with a 0.2 dropout rate. The two FC layers are applied with 300 and 100
neurons for the first and second layers, respectively. The total parameters for the HQCNN model are 120,394. Table 3
shows the summary layers of the proposed HQCNN model.

5

Experimental Results and Discussion

This section introduces the used images dataset, the performance measures to evaluate the HQCNN model, and the
analysis and discussion of experimental results.
5.1

Dataset

The used CXR COVID-19 images in this study are collected from two collections. Firstly, COVID-19 image dataset [53]
is made by Joseph Cohen. This dataset includes COVID-19, viral, MERS, SARS, and pneumonia. For this study, only
670 CXR COVID-19 images are adapted. Secondly, the augmented COVID-19 dataset[54] is made by Walid El-Shafai.
This dataset includes CXR and CT COVID-19 images with augmentation. For this study, only 491 the CXR COVID-19
images without augmentation are adapted. The pneumonia dataset [55] is used for normal and pneumonia (viral and
8

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Figure 3: Flowchart for proposed HQCNN model.

Table 3
Shows the summary of the HQCNN model.
Layer
1

Type
Quantum Conv

Units
4

Kernel Size
2x2

Input size
(28 x 28 x 1)

No. of parameters
-

2

Conv2D

16

2x2

(14 x 14 x 4)

272

3

MaxPooling2D

-

2x2

(14 x 14 x 4)

-

4

Conv2D

16

2x2

(7 x 7 x4)

1040

5

Conv2D

32

2x2

(7 x 7 x 32)

2080

6

MaxPooling2D

-

2x2

(7 x 7 x 8)

-

7

FC1

300

-

(288)

86,700

8

FC2

100

-

(300)

30,100

9

Output

2

-

(100)

202

bacterial) CXR images. The pneumonia dataset includes 5216 train images (1341 normal and 3875 pneumonia) and
624 test images (234 normal and 390 pneumonia). The images are divided into three datasets to evaluate the ability of
the proposed HQCNN model to detect COVID-19 cases. The first binary dataset (D1) including 1161 COVID-19 and
1575 normal images. The second binary dataset (D2) includes 1161 COVID-19 and 4247 pneumonia images. The third
multi-class dataset (D3) includes 1161 COVID-19, 1575 normal, and 4247 pneumonia images. Table 4 summarizes the
used CXR images in this work. Figure 4 shows samples from the used images.
9

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 4
Summarizes of three datasets are used in this work.
dataset

COVID-19

normal

pneumonia

D1

1161

1575

-

Train
1010
COVID-19
1341 normal

Test
151 COVID-19 234
normal

D2

1161

-

D3

1161

1575

Total

5216

1000
COVID-19
3875 normal

161 COVID-19 390
pneumonia

5377

5216

1341 normal 1000
COVID-19
3875
pneumonia

161 COVID-19 390
pneumonia 234 normal

6952

2736

Figure 4: Samples of used images.
5.2

Performance measures

The most common measures for evaluating classification models are confusion matrix with measures metrics like
accuracy, specificity (or true-negative rate), sensitivity (Recall or true-positive rate), precision, and F1-measure.
Measures metrics can compute by terms TP, TN, FP, FN as the following formulas:
• True Positives (TP): The proposed HQCNN model correctly predicts COVID-19 cases and labelled as COVID19.
• True Negatives (TN): The proposed HQCNN model correctly predicts normal cases and labelled as normal.
• False Positive (FP): The proposed HQCNN model incorrectly predicts normal cases and labelled as normal.
• False Negatives (FN): The proposed HQCNN model incorrectly predicts COVID-19 cases and labelled as
COVID-19.
Accuracy(Acc.) = T P + T N/(T P + T N + F P + F N )

(7)

Sensitivity(Sns.) = T P/T P + F N

(8)

Specif icity(Spc.) = T N/T N + F P

(9)

P recision(P rc.) = T P/T P + F P

(10)

F 1 − measure = 2 ∗ (P recision ∗ Recall)/(P recision + Recall)

(11)

10

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Figure 5: Samples of normal, COVID-19, and pneumonia images are processed by random quantum circuit.

BalancedAccuracy = 1/2(T P/T P + F P + T N/T N + F N )

(12)

F Beta − measure = (1 + β 2 )(P recision ∗ Recall)/(β 2 ∗
(P recision + Recall))

(13)

F alseP ositiveRate = F P/F P + T N

(14)

Receiver Operating Characteristic (ROC) curve identifies as ROC-Area Under Curve (ROC-AUC) is the method to
measure the ability of the classifier to predict the right labels. The ROC is a curve between the true-positive rate
(sensitivity) and the false-positive rate (1 − sensitivity). Fbeta-measure is the weighted harmonic average of precision
and recall of the HQCNN model.
5.3

Discussion

Experimental results have been implemented on Google Colaboratory by using PennyLane and TensorFlow with Keras.
PennyLane is a cross-platform Python library for hybrid quantum-classical computation [48]. The main aim of the
HQCNN model is to use the concept of the quantum circuit to enhance the performance of the classical CNNs model
and the prediction of infected cases of COVID-19 with higher results. RQC works with (2x2) small squares of an input
image. Each (2x2) square of the image is encoded into a quantum state by the RY gate. The decoding of the quantum
state into classical produces a new four features of a small square. Figure 5 shows samples of normal, pneumonia, and
COVID-19 images, which are examined by the RQC. The first column shows the input image with 28 x 28 size and
divided by 250. The quantum Conv layer assigns a feature map into four channels. The quantum Conv layer is used
only as a preprocessing layer to CXR images. The train and test phases will be completed on quantum preprocess data
with CNNs layers.
At the beginning of the evaluation, the proposed model is evaluated with RY and RX gates to encode data into RQC.
RY and RX gates have been used with a different number of shots (500 and 1000). As to be noted from Table 5, the RY
gate (1000 shots) achieved higher results 97.6%, 99.3%, 96.5%, 94.9, and 97% for accuracy, sensitivity, specificity,
precision, and F1-measure, respectively.
As shown in Figure 6a, the RY gate (1000 shots) achieved 97.9 % of balanced accuracy. Besides, the RY gate (1000
shots) obtained the largest AUC-ROC with 99.7% closer to 1. The test loss curve of the HQCNN model with RY (1000
shots) continues to reduce until the end of the test phase. The test loss with RY (1000 shots) is 0.07%. In addition, the
test loss with RY (500 shots) is 0.09%, the RX achieved 0.9% and 0.1% of test loss for 1000 and 500 shots, respectively
(see Figure 7). Figure 8 shows the confusion matrix for RY and RX with a different number of shots. The RY (1000
11

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 5
The performance of HQCNN model with rotation gates and number of shots on D1.

Rotation gate
RY
RX
RY
RX

Shots
1000
500

ACC.(%)
97.6
95.8
96.8
94.5

Sns.(%)
99.3
97.3
98
98

Spc.(%)
96.5
94.8
96.1
92.3

Prc.(%)
94.9
92.4
94.2
89.1

F1-measure(%)
97
94.8
96.1
96.1

(a)
(b)

Figure 6: (a) comparative analysis of balanced accuracy, FBeta-measure(β=0.5), and FBeta-measure(β=2) for D1. (b)
visualization of the ROC curve.

shots) has predicted the highest number of positive cases of COVID-19 (150 of 151 cases), as shown in Figure 8c.
Increasing the number of shots will calculate the better estimation of the output statistic of observables (i.e., expectation
value and variance).
As mentioned above, increasing the number of shots increases the performance of the model. Besides, the encoding
method (RY) can be improved the overall results of the model. So, the experimental results will be completed with an
encoding angle (RY gate) and 1000 shots.
The proposed HQCNN model results are compared with the CNNs, multi-layer perceptron (MLP), support vector
machines(SVMs), k-nearest neighbours (KNN), AdaBoost, random forest (RF), bagging classifier (BC), decision tree

(a)

(b)

Figure 7: Visualization of the learning curve for both (a) test accuracy and (b) test loss for D1 with 20 epochs.
12

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

(a)

(b)

(c)

(d)

Figure 8: The confusion matrix of the proposed HQCNN with RY and RX gates. (a) RY(500 shots), (b) RX(500 shots),
(c) RY (1000 shots), and (d) RX (1000 shots).

(DT), Gaussian Naive Bayes (GNB), and XGBoost classifiers. In classical CNN, the quantum layer has been replaced
by the classical Conv layer with four filters. The HQCNN model is optimized with the Adam algorithm with a learning
rate of 0.0001. The performance of HQCNN model is evaluated with measures metrics as represented in Equations
7, 8, 9, 10, and 11. Besides, balanced accuracy 12 to calculate the accuracy in an imbalanced dataset, Fbeta-measure
13, and the AUC-ROC curve. The experimental results of HQCNN are divided into four parts to measure the ability
of the proposed model for the classification of COVID-19 patients. The first part presents the classification results of
the HQCNN model between normal and COVID-19 cases 5.3.1. The second part discusses the experimental results
of the HQCNN model between COVID-19 and pneumonia patients 5.3.2. The last part debates the performance of
the HQCNN model for a multi-class dataset among normal, COVID-19, and pneumonia patients 5.3.3. The last part
compares the HQCNN model to CXR existing studies in this work 5.3.4.
5.3.1

The experimental results on D1

As shown in Table 6, the performance HQCNN model outperforms CNN and other models. The hybrid proposed model
has predicted COVID-19, and normal patients with 98.4% of accuracy, 99.3% of sensitivity, 97.8% of specificity, 96.7%
of precision, and 98% of F1-measure. The MLP model outperforms the HQCNN model in measure of sensitivity,
it achieved a sensitivity of 100%. Besides, as observed from Figure 9a proposed hybrid model has achieved higher
balanced accuracy and Fbeta-measure with 98.6% and 98.4%, respectively. Additionally, The HQCNN model scored
the largest AUC of ROC curve with 0.99%(near to 1) compared by various models, as shown in Figure 10a. The
confusion matrices of binary D1 is displayed in Figure 11. The confusion matrix of the HQCNN model, among of 151
COVID-19 images, one patient is misclassified by the HQCNN model. From a total of 234 normal cases, five cases are
misclassified by the HQCNN model.
5.3.2

The experimental results on D2

Here, Table 7 reports the results of the HQCNN model compared to various models on D2. the HQCNN model
achieved 99%, 99.3%, 98.9%, 99.7%, and 97.5% for accuracy, F1-measure, precision, sensitivity, and specificity,
respectively. Besides, better-balanced accuracy has been achieved with 98.6%, 98% for HQCNN, and CNN+KNN
models, respectively as shown in Figure 9b. From Figure 10b, the proposed HQCNN model achieved AUC-ROC
score 100% (equal to 1). The HQCNN model distinguished between COVID-19 and pneumonia with higher efficiency.
The confusion matrices of D2 have been shown in Figure 12. From a total of 161 COVID-19 cases, four cases are
13

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 6
Comparison of classification performance between proposed HQCNN and different models on D1.

Model
HQCNN
CNN
MLP
CNN+SVM(RBF)
CNN+SVM(Poly)
CNN+KNN
CNN+AdaBoost
CNN+RF
CNN+BC
CNN+DT
CNN+GNB
CNN+XGBoost

ACC.(%)
98.4
96.8
92.9
94.5
93.5
95.5
94.5
94.2
94.5
95
94.8
95

Sns.(%)
99.3
98.6
100
98.6
99.3
98.6
99.3
98.6
98.6
99.3
98.6
99.3

(a)

Spc.(%)
97.8
95.7
88.4
91.8
89.7
93.5
91.4
91.4
91.8
92.3
92.3
92.3

Prc.(%)
96.7
93.7
84.8
88.6
86.2
90.8
88.2
88.1
88.6
89.2
89.2
89.2

F1-measure(%)
98
96
91.7
93.4
92.3
94.6
93.4
93.1
93.4
94
93.7
94

(c)

(b)

Figure 9: Comparative analysis of balanced accuracy, FBeta-measure(β=0.5), and FBeta-measure(β=2) for (a) D1, (b)
D2, and (c) D3.

misclassified by the HQCNN model. Among 390 pneumonia images, one patient is misclassified by the HQCNN
model.
Table 7
Comparison of classification performance between proposed HQCNN and different models on D2.
Model
HQCNN
CNN
MLP
CNN+SVM(RBF)
CNN+SVM(Poly)
CNN+KNN
CNN+AdaBoost
CNN+RF
CNN+BC
CNN+DT
CNN+GNB
CNN+XGBoost

5.3.3

ACC.(%)
99
97.4
96.3
97.8
96.9
98.5
97
96.5
97.8
97
97.8
98

Sns.(%)
99.7
99.7
99.7
99.7
99.7
99.2
99.2
97.6
99.7
99.2
98.9
99.2

Spc.(%)
97.5
91.9
88.1
93.1
90
96.8
91.9
93.7
93.1
91.9
95
95

Prc.(%)
98.9
96.7
95.3
97.2
96
98.7
96.7
97.4
97.2
96.7
97.9
97.9

F1-measure(%)
99.3
98.2
97.4
98.4
97.8
98.9
97.9
97.5
98.4
97.9
98.4
98.5

The experimental results on D3

To further evaluate, the imbalanced multi-class dataset is used to evaluate HQCNN performance. The dataset is
combined with normal, COVID-19, and pneumonia images. Table 8 presents the classification results of the HQCNN
model and other models on an imbalanced multi-class dataset. The best results have been evaluated with 88.6%, 88.7%,
89.3%, and 88.8% for accuracy, sensitivity, precision, and F1-measure. Besides, the HQCNN model achieved 90.4%
of balanced accuracy compared to various models. In Figure 13, The AUC-ROC curve has been exhibited with three
normal, COVID-19, and pneumonia classes. It can be noted that the HQCNN distinguished among three classes with
higher AUC values 0.97%, 0.99%, and 0.97% for normal, COVID-19, and pneumonia classes. The confusion matrices
are shown in Figure 14. The confusion matrix of the HQCNN model, among 161 COVID-19 images, four patients are
14

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

(b)

(a)

Figure 10: The AUC-ROC curve of QHCNN and different models on (a) D1, and (b) D2.
Table 8
Comparison of classification performance between proposed HQCNN and different models on D3.
Model
HQCNN
CNN
MLP
CNN+SVM(RBF)
CNN+SVM(Poly)
CNN+KNN
CNN+AdaBoost
CNN+RF
CNN+BC
CNN+DT
CNN+GNB
CNN+XGBoost

ACC.(%)
88.6
87.7
77.9
82.3
84.2
83.4
78.8
81.4
82
83.8
82.9
82.2

Sns.(%)
88.7
87.7
78
82.2
84.2
82
78.8
81.2
82.2
83
82.9
82.1

Prc.(%)
89.3
88.8
81.5
83.1
84.7
83.6
79.8
81.2
83.3
83.8
83.4
83.3

F1-measure(%)
88.8
88.2
74
80.9
83.2
82.5
77.3
80.3
80.8
82.9
81.8
80.7

misclassified. From a total of 234 normal cases, 25 cases are misclassified. From 390 pneumonia patients, 60 patients
are misclassified by the HQCNN model.
5.3.4

Comparison with CXR existing studies

To boost the effectiveness of the HQCNN model in classifying the COVID-19 cases, the HQCNN model is compared to
CXR existing studies, as shown in Table 9. The HQCNN model outperforms previous studies with CXR images in
terms of sensitivity and F1-measure. The Truncated InceptionNet and CNN+LSTM models outperform the HQCNN
model with a term of accuracy. The Truncated InceptionNet achieved 99.9% accuracy for one dataset but, the overall
accuracy was 98.77%. The Truncated InceptionNet is based on a large InceptionNetV3 model. The CNN+LSTM has
20 layers, including 12 Conv layers. The HQCNN model achieved better results with nine layers, including four Conv
layers (one quantum layer and three classical layers).
In summary, as mentioned in 5.3.1, 5.3.2, 5.3.3, and 5.3.4, the proposed HQCNN model achieved a sensitivity of 99.3%,
99.7%, and 88.7% on D1, D2, D3, respectively. Table 10 shows the results of the HQCNN model with each class
on D1, D2, and D3. In D1, the COVID-19 class is predicted with high accuracy of 99.3%, sensitivity of 97%, and
F1-measure of 98%. In normal cases, The HQCNN model obtained 100% sensitivity. In imbalanced binary D2, the
COVID-19 class is categorized with 97.5%, 99%, and 98% for accuracy, sensitivity, and F1-measure, respectively. The
pneumonia class achieved 100% precision, 99.7% accuracy, and 99% for sensitivity and F1-measure. Furthermore, in
the imbalanced multi-class D3, the higher results are obtained with COVID-19 class. It classified the COVID-19 cases
with an accuracy of 97.5%, sensitivity of 99%, and F1-measure of 98%. Besides, with pneumonia category achieved a
15

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

Figure 11: The confusion matrix of the proposed HQCNN and different models for D1.
high 92% sensitivity. The lower sensitivity is achieved with 77% in normal cases. The higher precision is achieved with
100% in pneumonia patients.
The limitations of the HQCNN model in this work are:
• The size of the COVID-19 image is used with 28x28 pixels which are divided into 4x4 pixel.
• The architecture of the HQCNN model is a small to compatible with 4 qubits in the quantum simulator.
• The used random quantum circuit works as preprocessing layer for images.
• The size of the used images in the training phase is small.

6

Conclusion and Future Work

In this work, a new hybrid quantum-classical CNNs (HQCNN) model has been proposed for COVID-19 classification
with chest radiography images. The aim of the HQCNN model combines the random quantum circuit with CNNs and
to enhance the performance. The HQCNN model has been used the random quantum circuit as a quantum convolution
layer to compute convolution operation on a quantum device. The HQCNN model has been evaluated on binary and
16

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

Figure 12: The confusion matrix of the proposed HQCNN and different models on D2.

(a)

(b)

(c)

Figure 13: The AUC-ROC curve of QHCNN and different models for D3.

17

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

Table 9
Comparison with CXR existing studies.
Study
MobileNetV2 [25]
ResNet18 [26]
Truncated InceptionNet [27]
DarkNet [28]
DarkNet [28]
CNN+LSTM [29]
CoroNet [30]
CoroNet [30]
VGG16 [31]
GSA-DenseNet121
[32]
Inception+FOMPA[33]
Inception+FOMPA[33]
CapsNet[34]
CapsNet[34]
EfficientNet[35]
EfficientNet[35]
HQCNN
HQCNN

COVID-19 Images
224
180

Class
multi
multi

ACC.(%)
96.7
88.9

Sns.(%)
98.66
85.9

F1-measure(%)
84.4

162

multi

99.9

98

98

125
125
1512
280
280
250

binary
multi
binary
binary
multi
binary

98.08
87.02
99.4
99
95
96

95.13
85.35
99.3
99.3
96.9
96

96.51
87.37
99.9
98.5
95.6
94

99

binary

98.38

98.5

98

200

binary

98.7

-

98.2

219

binary

99.6

-

99

1050
1050
504
504
1161
1161

binary
multi
binary
multi
binary
multi

97.24
84.22
99.62
96.70
99
88.6

97.42
84.22
99.63
96.69
99.7
88.7

97.24
84.21
99.62
97.11
99.3
88.8

Table 10
The HQCNN model performance with each class on D1, D2, and D3.
Class

ACC.(%)

Sns.(%)

Prc.(%)

F1-measure(%)

100
97

98
99

99
98

99
99

98
100

98
99

77
99
92

89
98
85

83
98
88

D1
normal
COVID-19

97.8
99.3

COVID-19
pneumonia

97.5
99.7

normal
COVID-19
pneumonia

89.3
97.5
94.6

D2
D3

multi-class COVID-19 datasets, it outperformed classical CNNs and various models. It achieved an accuracy of 99%
and 88.6%, a sensitivity of 99.3%, and 88.7% for binary, and multi-class datasets, respectively. The future work will be
highly focused on using different encoding methods (i.e., amplitude encoding) with further quantum convolutional
layers. Also, we will enhance the HQCNN architecture to overcome on limitations of the proposed model.

Author Contribution statement
Essam H. Houssein: Supervision, Methodology, Conceptualization, Formal analysis, Writing - review & editing. Zainab
Abohashima: Software, Resources, Data Curation, Writing - original draft. Mohamed Elhoseny: Conceptualization,
Formal analysis, Writing - review & editing. Waleed M. Mohamed: Conceptualization, Formal analysis, Writing review & editing. All authors read and approved the final paper.

Conflict of interest
The authors declare that there is no conflict of interest. Non-financial competing interests.

Compliance with ethical standards
This article does not contain any studies with human participants or animals performed by any of the authors.
18

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

(a)

(b)

(c)

(d)

(e)

(f)

(g)

(h)

(i)

(j)

(k)

(l)

Figure 14: The confusion matrix of the proposed HQCNN and different models on D3.

Acknowledgments
The authors would like to thank Pennylane’s team members for helpful discussions, especially, Dr Andrea Mari for
valuable discussions.

References
[1] Yan Li and Liming Xia. Coronavirus disease 2019 (covid-19): role of chest ct in diagnosis and management.
American Journal of Roentgenology, 214(6):1280–1286, 2020.
[2] Meghan E Sise, Meridale V Baggett, Jo-Anne O Shepard, Jacob S Stevens, and Eugene P Rhee. Case 17-2020: A
68-year-old man with covid-19 and acute kidney injury. New England Journal of Medicine, 382(22):2147–2156,
2020.
[3] Soheil Kooraki, Melina Hosseiny, Lee Myers, and Ali Gholamrezanezhad. Coronavirus (covid-19) outbreak: what
the department of radiology should know. Journal of the American college of radiology, 2020.
19

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

[4] Syed Faraz Ahmed, Ahmed A Quadeer, and Matthew R McKay. Preliminary identification of potential vaccine
targets for the covid-19 coronavirus (sars-cov-2) based on sars-cov immunological studies. Viruses, 12(3):254,
2020.
[5] Buddhisha Udugama, Pranav Kadhiresan, Hannah N Kozlowski, Ayden Malekjahani, Matthew Osborne,
Vanessa YC Li, Hongmin Chen, Samira Mubareka, Jonathan B Gubbay, and Warren CW Chan. Diagnosing
covid-19: the disease and tools for detection. ACS nano, 14(4):3822–3835, 2020.
[6] Shazia Jamil, Nick Mark, Graham Carlos, Charles S Dela Cruz, Jane E Gross, and Susan Pasnick. Diagnosis and
management of covid-19 disease. American Journal of Respiratory and Critical Care Medicine, 201(10):P19–P20,
2020.
[7] Sana Salehi, Aidin Abedi, Sudheer Balakrishnan, and Ali Gholamrezanezhad. Coronavirus disease 2019 (covid19): a systematic review of imaging findings in 919 patients. American Journal of Roentgenology, pages 1–7,
2020.
[8] Xingzhi Xie, Zheng Zhong, Wei Zhao, Chao Zheng, Fei Wang, and Jun Liu. Chest ct for typical 2019-ncov
pneumonia: relationship to negative rt-pcr testing. Radiology, page 200343, 2020.
[9] Xiaoming Li, Wenbing Zeng, Xiang Li, Haonan Chen, Linping Shi, Xinghui Li, Hongnian Xiang, Yang Cao,
Hui Chen, Chen Liu, et al. Ct imaging changes of corona virus disease 2019 (covid-19): a multi-center study in
southwest china. Journal of translational medicine, 18:1–8, 2020.
[10] Nanshan Chen, Min Zhou, Xuan Dong, Jieming Qu, Fengyun Gong, Yang Han, Yang Qiu, Jingli Wang, Ying Liu,
Yuan Wei, et al. Epidemiological and clinical characteristics of 99 cases of 2019 novel coronavirus pneumonia in
wuhan, china: a descriptive study. The Lancet, 395(10223):507–513, 2020.
[11] D Douglas Miller and Eric W Brown. Artificial intelligence in medical practice: the question to the answer? The
American journal of medicine, 131(2):129–133, 2018.
[12] Muhammad EH Chowdhury, Tawsifur Rahman, Amith Khandakar, Rashid Mazhar, Muhammad Abdul Kadir,
Zaid Bin Mahbub, Khandaker Reajul Islam, Muhammad Salman Khan, Atif Iqbal, Nasser Al-Emadi, et al. Can ai
help in screening viral and covid-19 pneumonia? arXiv preprint arXiv:2003.13145, 2020.
[13] Alexander Selvikvåg Lundervold and Arvid Lundervold. An overview of deep learning in medical imaging
focusing on mri. Zeitschrift für Medizinische Physik, 29(2):102–127, 2019.
[14] Vojtěch Havlíček, Antonio D Córcoles, Kristan Temme, Aram W Harrow, Abhinav Kandala, Jerry M Chow, and
Jay M Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature, 567(7747):209–212, 2019.
[15] Maria Schuld and Nathan Killoran. Quantum machine learning in feature hilbert spaces. Physical review letters,
122(4):040504, 2019.
[16] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio
Boixo, Fernando GSL Brandao, David A Buell, et al. Quantum supremacy using a programmable superconducting
processor. Nature, 574(7779):505–510, 2019.
[17] Sergio Boixo, Sergei V Isakov, Vadim N Smelyanskiy, Ryan Babbush, Nan Ding, Zhang Jiang, Michael J Bremner,
John M Martinis, and Hartmut Neven. Characterizing quantum supremacy in near-term devices. Nature Physics,
14(6):595–600, 2018.
[18] Vedran Dunjko and Hans J Briegel. Machine learning & artificial intelligence in the quantum domain: a review of
recent progress. Reports on Progress in Physics, 81(7):074001, 2018.
[19] Nathan Killoran, Thomas R Bromley, Juan Miguel Arrazola, Maria Schuld, Nicolás Quesada, and Seth Lloyd.
Continuous-variable quantum neural networks. Physical Review Research, 1(3):033063, 2019.
[20] SK Jeswal and S Chakraverty. Recent developments and applications in quantum neural network: a review.
Archives of Computational Methods in Engineering, 26(4):793–807, 2019.
[21] Edward Farhi and Hartmut Neven. Classification with quantum neural networks on near term processors. arXiv
preprint arXiv:1802.06002, 2018.
[22] Subhash C Kak. Quantum neural computing. In Advances in imaging and electron physics, volume 94, pages
259–313. Elsevier, 1995.
[23] Maxwell Henderson, Samriddhi Shakya, Shashindra Pradhan, and Tristan Cook. Quanvolutional neural networks:
powering image recognition with quantum circuits. Quantum Machine Intelligence, 2(1):1–9, 2020.
[24] Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa, and Keisuke Fujii. Quantum circuit learning. Physical
Review A, 98(3):032309, 2018.
20

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

[25] Ioannis D Apostolopoulos and Tzani A Mpesiana. Covid-19: automatic detection from x-ray images utilizing
transfer learning with convolutional neural networks. Physical and Engineering Sciences in Medicine, page 1,
2020.
[26] Yujin Oh, Sangjoon Park, and Jong Chul Ye. Deep learning covid-19 features on cxr using limited training data
sets. IEEE Transactions on Medical Imaging, 2020.
[27] Dipayan Das, KC Santosh, and Umapada Pal. Truncated inception net: Covid-19 outbreak screening using chest
x-rays. Physical and engineering sciences in medicine, pages 1–11, 2020.
[28] Tulin Ozturk, Muhammed Talo, Eylul Azra Yildirim, Ulas Baran Baloglu, Ozal Yildirim, and U Rajendra Acharya.
Automated detection of covid-19 cases using deep neural networks with x-ray images. Computers in Biology and
Medicine, page 103792, 2020.
[29] Md Zabirul Islam, Md Milon Islam, and Amanullah Asraf. A combined deep cnn-lstm network for the detection
of novel coronavirus (covid-19) using x-ray images. Informatics in Medicine Unlocked, page 100412, 2020.
[30] Asif Iqbal Khan, Junaid Latief Shah, and Mohammad Mudasir Bhat. Coronet: A deep neural network for detection
and diagnosis of covid-19 from chest x-ray images. Computer Methods and Programs in Biomedicine, page
105581, 2020.
[31] Luca Brunese, Francesco Mercaldo, Alfonso Reginelli, and Antonella Santone. Explainable deep learning
for pulmonary disease and coronavirus covid-19 detection from x-rays. Computer Methods and Programs in
Biomedicine, page 105608, 2020.
[32] Dalia Ezzat, Hassan Aboul Ella, and Hassan Aboul Ella. An optimized deep learning architecture for the diagnosis
of covid-19 disease based on gravitational search optimization. Applied Soft Computing Journal, 2020.
[33] Ahmed T Sahlol, Dalia Yousri, Ahmed A Ewees, Mohammed AA Al-Qaness, Robertas Damasevicius, and
Mohamed Abd Elaziz. Covid-19 image classification using deep features and fractional-order marine predators
algorithm. Scientific Reports, 10(1):1–15, 2020.
[34] Suat Toraman, Talha Burak Alakus, and Ibrahim Turkoglu. Convolutional capsnet: A novel artificial neural
network approach to detect covid-19 disease from x-ray images using capsule networks. Chaos, Solitons &
Fractals, 140:110122, 2020.
[35] Gonçalo Marques, Deevyankar Agarwal, and Isabel de la Torre Díez. Automated medical diagnosis of covid-19
through efficientnet convolutional neural network. Applied Soft Computing, page 106691, 2020.
[36] Xiaowei Xu, Xiangao Jiang, Chunlian Ma, Peng Du, Xukun Li, Shuangzhi Lv, Liang Yu, Qin Ni, Yanfei Chen,
Junwei Su, et al. A deep learning system to screen novel coronavirus disease 2019 pneumonia. Engineering, 2020.
[37] Dilbag Singh, Vijay Kumar, and Manjit Kaur. Classification of covid-19 patients from chest ct images using multiobjective differential evolution–based convolutional neural networks. European Journal of Clinical Microbiology
& Infectious Diseases, pages 1–11, 2020.
[38] Xiangjun Wu, Hui Hui, Meng Niu, Liang Li, Li Wang, Bingxi He, Xin Yang, Li Li, Hongjun Li, Jie Tian, et al.
Deep learning-based multi-view fusion model for screening 2019 novel coronavirus pneumonia: a multicentre
study. European Journal of Radiology, page 109041, 2020.
[39] Aayush Jaiswal, Neha Gianchandani, Dilbag Singh, Vijay Kumar, and Manjit Kaur. Classification of the covid-19
infected patients using densenet201 based deep transfer learning. Journal of Biomolecular Structure and Dynamics,
pages 1–8, 2020.
[40] Vedran Dunjko, Jacob M Taylor, and Hans J Briegel. Quantum-enhanced machine learning. Physical review
letters, 117(13):130501, 2016.
[41] Esma Aïmeur, Gilles Brassard, and Sébastien Gambs. Machine learning in a quantum world. In Conference of the
Canadian Society for Computational Studies of Intelligence, pages 431–442. Springer, 2006.
[42] Phillip Kaye, Raymond Laflamme, Michele Mosca, et al. An introduction to quantum computing. Oxford
university press, 2007.
[43] Michael A Nielsen and Isaac Chuang. Quantum computation and quantum information, 2002.
[44] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and
Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541–
551, 1989.
[45] Xiaolong Liu, Zhidong Deng, and Yuhan Yang. Recent progress in semantic image segmentation. Artificial
Intelligence Review, 52(2):1089–1106, 2019.
21

Hybrid quantum convolutional neural networks model for COVID-19 prediction using chest X-Ray images
A P REPRINT

[46] Zhuoling Li, Minghui Dong, Shiping Wen, Xiang Hu, Pan Zhou, and Zhigang Zeng. Clu-cnns: Object detection
for medical images. Neurocomputing, 350:53–59, 2019.
[47] Lazaros Vrysis, Nikolaos Tsipas, Iordanis Thoidis, and Charalampos Dimoulas. 1d/2d deep cnns vs. temporal
feature integration for general audio classification. Journal of the Audio Engineering Society, 68(1/2):66–77,
2020.
[48] Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Carsten Blank, Keri McKiernan, and Nathan
Killoran. Pennylane: Automatic differentiation of hybrid quantum-classical computations. arXiv preprint
arXiv:1811.04968, 2018.
[49] Zainab Abohashima, Mohamed Elhosen, Essam H Houssein, and Waleed M Mohamed. Classification with
quantum machine learning: A survey. arXiv preprint arXiv:2006.12270, 2020.
[50] Seth Lloyd, Maria Schuld, Aroosa Ijaz, Josh Izaac, and Nathan Killoran. Quantum embeddings for machine
learning. arXiv preprint arXiv:2001.03622, 2020.
[51] Yuki Takeuchi, Tomoyuki Morimae, and Masahito Hayashi. Quantum computational universality of hypergraph
states with pauli-x and z basis measurements. Scientific reports, 9(1):1–14, 2019.
[52] Liangpei Zhang, Lefei Zhang, and Bo Du. Deep learning for remote sensing data: A technical tutorial on the state
of the art. IEEE Geoscience and Remote Sensing Magazine, 4(2):22–40, 2016.
[53] Joseph Paul Cohen, Paul Morrison, Lan Dao, Karsten Roth, Tim Q Duong, and Marzyeh Ghassemi. Covid-19
image data collection: Prospective predictions are the future. arXiv 2006.11988, 2020.
[54] Walid El-Shafai and Abd El-Samie Fathi. Extensive and augmented covid-19 x-ray and ct chest images dataset.
Mendeley, 2020.
[55] Daniel S Kermany, Michael Goldbaum, Wenjia Cai, Carolina CS Valentim, Huiying Liang, Sally L Baxter, Alex
McKeown, Ge Yang, Xiaokang Wu, Fangbing Yan, et al. Identifying medical diagnoses and treatable diseases by
image-based deep learning. Cell, 172(5):1122–1131, 2018.

22

