1

Automated Detection and Forecasting of COVID-19
using Deep Learning Techniques: A Review

arXiv:2007.10785v3 [cs.LG] 27 Jul 2020

Afshin Shoeibi, Marjane Khodatars, Roohallah Alizadehsani, Member, IEEE, Navid Ghassemi, Mahboobeh Jafari,
Parisa Moridian, Ali Khadem, Delaram Sadeghi, Sadiq Hussain, Assef Zare, Zahra Alizadeh Sani, Javad Bazeli
and Fahime Khozeimeh, Abbas Khosravi, Member, IEEE, Saeid Nahavandi, Fellow, IEEE,
U. Rajendra Acharya, Senior Member, IEEE, Peng Shi, Fellow, IEEE

Abstract—Coronavirus, or COVID-19, is a hazardous disease
that has endangered the health of many people around the world
by directly affecting the lungs. COVID-19 is a medium-sized,
coated virus with a single-stranded RNA. This virus has one of
the largest RNA genomes and is approximately 120 nm. The
X-Ray and computed tomography (CT) imaging modalities are
widely used to obtain a fast and accurate medical diagnosis.
Identifying COVID-19 from these medical images is extremely
challenging as it is time-consuming, demanding, and prone to
human errors. Hence, artificial intelligence (AI) methodologies
can be used to obtain consistent high performance. Among
the AI methodologies, deep learning (DL) networks have
gained much popularity compared to traditional machine
learning (ML) methods. Unlike ML techniques, all stages
of feature extraction, feature selection, and classification are
accomplished automatically in DL models. In this paper, a
complete survey of studies on the application of DL techniques
for COVID-19 diagnostic and automated segmentation of lungs
is discussed, concentrating on works that used X-Ray and CT
images. Additionally, a review of papers on the forecasting of
coronavirus prevalence in different parts of the world with
DL techniques is presented. Lastly, the challenges faced in the
automated detection of COVID-19 using DL techniques and
directions for future research are discussed.
A. Shoeibi and N. Ghassemi are with the Faculty of Electrical Engineering,
Biomedical Data Acquisition Lab (BDAL), K. N. Toosi University of Technology, Tehran, Iran, and the Computer Engineering Department, Ferdowsi
University of Mashhad, Mashhad, Iran.
M. Khodatars and D. Sadeghi are with the Dept. of Medical Engineering,
Mashhad Branch, Islamic Azad University, Mashhad, Iran.
R. Alizadehsani, A. Khosravi and S. Nahavandi. are with the Institute
for Intelligent Systems Research and Innovation (IISRI), Deakin University,
Victoria 3217, Australia. (Corresponding author: Abbas Khosravi, email:
abbas.khosravi@deakin.edu.au).
M. Jafari is with Electrical and Computer Engineering Faculty, Semnan
University, Semnan, Iran.
P. Moridian is with the Faculty of Engineering, Science and Research
Branch, Islamic Azad University, Tehran, Iran.
A. Khadem is with the Faculty of Electrical Engineering, K. N. Toosi
University of Technology, Tehran, Iran.
Sadiq Hussain is System Administrator at Dibrugarh University, Assam,
India, 786004.
A. Zare is with Faculty of Electrical Engineering, Gonabad Branch, Islamic
Azad University, Gonabad, Iran.
Z. Alizadeh Sani is with Rajaie Cardiovascular Medical and Research
Center, and Iran University of Medical Sciences, Tehran, Iran.
F. Khozeimeh is with Faculty of Medicine, Mashhad University of Medical
Sciences, Mashhad, Iran.
U. R. Acharya is with the Dept. of Electronics and Computer Engineering,
Ngee Ann Polytechnic, Singapore 599489, Singapore, the Dept. of Biomedical
Informatics and Medical Engineering, Asia University, Taichung, Taiwan, and
the Dept. of Biomedical Engineering, School of Science and Technology,
Singapore University of Social Sciences, Singapore.
P. Shi is with the School of Electrical and Electronic Engineering, University of Adelaide, Adelaide, SA 5005, Australia.

Index Terms—COVID-19, Diagnosis, Deep Learning, Classification, Segmentation, Forecasting.

I. I NTRODUCTION
The novel COVID-19 virus came to light in December 2019
in Wuhan Province, China, where it originated from animals
and quickly spread around the world [1]. The easiest way to
transmit COVID-19 is through the air and physical contact,
such as hand contact with an infected person [2]. The virus
inserts itself into the lung cells through the respiratory system
and replicates there, destroying these cells [3]. COVID-19
comprises an RNA and is very difficult to diagnose and treat
due to its mutation characteristics [4]. The most common
symptoms of COVID-19 include fever, cough, and shortness
of breath, dizziness, headache, and muscle aches [5]. The
virus is so perilous and can provoke the death of people with
weakened immune systems [6]. Infectious disease specialists
and physicians around the world are working to discover a
treatment for the disease. COVID-19 is currently the leading
cause of death for thousands of countries worldwide, including
the USA, Spain, Italy, China, the United Kingdom, Iran, and
others. Figure 1 exhibits the latest number of infected people
worldwide due to COVID-19.
The detection of COVID-19 is crucially significant and vital
in its early stages. Various methods have been proposed to
diagnose COVID-19, containing a variety of medical imaging
techniques, blood tests (CBCs), and PCR. According to the
WHO, all diagnoses of corona disease must be confirmed by
reverse-transcription polymerase chain reaction (RT-PCR) [7].
However, testing with RT-PCR is highly time-consuming, and
this issue is risky for people with COVID-19. Hence, first,
medical imaging is carried out for the primary detection of
COVID-19, then the RT-PCR test is performed to aid the
physicians in making final accurate detection. Two medical
imaging techniques, X-ray and CT-scan, are employed to
diagnose COVID-19 [8], [9].
X-ray modality is the first procedure to diagnose COVID19, which has the advantage of being inexpensive and low-risk
from radiation hazards to human health [10], [11]. In the Xray method, detecting COVID-19 is a relatively complicated
task. In these images, the radiologist must attentively recognize
the white spots that contain water and pus, which is very prolonged and problematic. A radiologist or specialist doctor may
also mistakenly diagnose other diseases, such as pulmonary
tuberculosis, as COVID-19 [12].

2

Fig. 1: Detailed statistics of COVID-19 infected people worldwide [13].

The X-ray procedure has a high error rate; hence CT images
can be used for more precise detection [14]. Nevertheless,
these CT images are far more expensive than X-rays for
patients [15]. At the time of CT-scan recording, several slices
are provided from each person suspected of COVID-19. The
large volume of CT-Scan images calls for a high workload on
physicians and radiologists to diagnose COVID-19.
In recent years, applications of artificial intelligence in
medicine have led to a variety of studies aiming to diagnose
varied diseases, including brain tumors from MR images [16],
[17], multiple types of brain disorders such from EEG [18],
[19], breast cancer from mammographic images [20], [21]
and pulmonary diseases such as Covid-19 from X-Ray [22]
and CT-Scan [23]. In the last decade, Deep Learning (DL),
a branch of machine learning, has changed the expectations
in many applications of artificial intelligence in data processing by reaching human-level accuracies [24] in many tasks,
including medical image analysis [25].
In this paper, an overview of COVID-19 diagnostic approaches utilizing DL networks is presented. Section II explains the search strategy, and various DL models developed
for COVID-19 detection are described in Section III. Section
IV of the DL techniques used for the detection, segmentation,
and prediction of COVID-19 patients. Section V discusses the
reviewed papers on diagnosis, segmentation, and prediction of
COVID-19 patients. Challenges in diagnosing, segmentation,
and prediction of COVID-19 patients are provided in Section
VI. Finally, the summary and future work are delineated in
Section VII.
II. S EARCH S TRATEGY
In this study, valid databases, including IEEE Xplore, ScienceDirect, SpringerLink, ACM, and ArXiv, have been used
to search for Covid-19 papers. Moreover, a more detailed
Google Scholar search is employed. The articles are selected
using the keywords COVID-19, Corona Virus, Deep Learning,
Segmentation, and Forecasting. The latest selection of papers
is done with the mentioned keywords on July 11th, 2020.
Figure 2 indicates the number of papers published or indexed
by COVID-19 using DL techniques using various databases.

Fig. 2: Number of papers published on COVID-19 using DL
techniques.

III. D EEP L EARNING T ECHNIQUES FOR COVID-19
D ETECTION
Traditional machine learning and DL are the two significant
branches of AI, but DL is essentially a more advanced version
of traditional machine learning (ML). Various DL networks
have been extensively used to diagnose the COVID-19 accurately using many public databases.
DL architectures, namely convolutional neural networks
(CNNs), recurrent neural networks (RNNs), Autoencoders
(AEs), deep belief networks (DBNs), generative adversarial
networks (GANs), and hybrid networks such as CNN-RNN
and CNN-AE have been developed for automated detection
of COVID-19. Figure 3 exhibits the subcategories of DL
networks.
IV. C OMPUTER A IDED D IAGNOSIS S YSTEM (CADS) FOR
COVID-19 D ETECTION
Many CADS have been developed using DL methods using
X-ray and CT images. Two types of systems: (i) classification
and (ii) segmentation using DL methods have been developed.
In classification-based CADS, the main objective is to identify
COVID-19 patients, which involves the process of extracting
features, selecting features, and classifying using deep layers.
The second type, CAD, is for the segmentation of X-Ray
and CT-Scan images of each infected person with COVID19. Segmentation implies dividing images into meaningful
areas and is of particular notability in medicine. Manual segmentation of medical images takes much time; thus, applying
machine learning models is crucially paramount. Among the
most important segmentation models, the various types of
fuzzy clustering methods [26], [27] and DL procedures such
as U-Net [28] can be expressed. In the CADS, with the
segmentation approach, patients’ CT-Scan images and their
manual segments labeled by doctors are fed to the DL network.
Then, during the training process, the DL network is trained
on manual segments to segment raw input images. Finally,
in deep network output, segmented images are presented
with segmentation accuracy. The components of DL-based
CADS for COVID-19 detection are shown in Figure 4. In

3

Fig. 3: Illustration of various DL methods used for COVID-19 detection.
TABLE II: Public COVID-19 forecasting databases used for
forecasting.

Fig. 4: Block diagram for COVID-19 detection using DL
technique.
TABLE I: Public databases used for COVID-19 detection.
Dataset
J. P. Cohens GitHub [29]
European Society of Radiology
SIRM
BSTI
UCSD-AI4H [30]
MedSeg
Kaggle
Point-of-Care Ultrasound
(POCUS) [31]
Actualmed COVID-19 Chest
X-ray Dataset Initiative
COVID-19 Chest X-ray
Dataset Initiative
Georgia State Universitys
Panacea Lab [32]
Twitter COVID19 CXR dataset
COVID-19 [33]
COVIDx [34]

Modality
X-ray and CT
X-ray and CT
X-ray and CT
X-ray and CT
CT
CT
X-ray and CT
Lung Ultrasound
Images and Videos

Link
https://github.com/ieee8023/covid-chestxray-dataset
https://www.eurorad.org/advanced-search?search=COVID
https://www.sirm.org/category/senza-categoria/covid-19
https://www.bsti.org.uk/covid-19-resources
https://github.com/UCSD-AI4H/COVID-CT
http://medicalsegmentation.com/covid19
https://www.kaggle.com/datasets?search=covid

X-ray

https://github.com/agchung/Actualmed-COVID-chestxray-dataset

X-ray

https://github.com/agchung/Figure1-COVID-chestxray-dataset

Twitter Chatter
Dataset
X-ray
CT
X-ray

Dataset
China CDC Weekly
The Ministry of Health and Family
Welfare (Government of India)
Johns Hopkins University
WHO COVID-19 Dashboard

Modality
Daily Number of Cases in China

U.S. CDC

Daily Number of Cases in U.S.

Worldometer
Open Source COVID-19
Painel Coronavrus
GOV.UK

Global Collection
Global Collection
Daily Number of Cases in Brazil
Daily Number of Cases in UK

Link
http://weekly.chinacdc.cn/news/TrackingtheEpidemic.htm

Daily Number of Cases in India

https://www.mohfw.gov.in

Tracking COVID-19 Spread
Global Statistics

https://systems.jhu.edu
https://covid19.who.int
https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html
https://www.cdc.gov/coronavirus/2019-ncov/covid-data/data-visualization.htm
https://www.worldometers.info/coronavirus
http://open-source-covid-19.weileizeng.com
https://covid.saude.gov.br
https://coronavirus.data.gov.uk
http://www.salute.gov.it/portale/nuovocoronavirus/
homeNuovoCoronavirus.jsp?lingua=english
https://www.mscbs.gob.es/profesionales/saludPublica/ccayes/alertasActual/
nCov-China/situacionActual.htm
https://cnecovid.isciii.es/covid19

Ministero della Salute

Daily Number of Cases in Italy

Ministry of health

Daily Number of Cases in Spain

https://github.com/jannisborn/covid19 pocus ultrasound

https://github.com/thepanacealab/covid19 twitter
https://twitter.com/ChestImaging
https://github.com/KevinHuRunWen/COVID-19
https://github.com/lindawangg/COVID-Net

the following section, we will first mention the important data
available for COVID-19. Then, the DL methods exploited in
the research are introduced.
A. Public Databases used for COVID-19 Detection and Forecasting
Various public databases (X-ray and CT images) available
for the detection and prediction of COVID-19 are listed in
Table I. Also, the databases used to predict the corona spread
in leading countries of the world are shown in Table II.
B. Deep Learning Methods
DL networks developed for classification, segmentation,
and prediction of COVID-19 disease will be analyzed in this
section. Various applied DL architectures are discussed briefly
in the following sections.
1) Classification Models: Various DL methods presented
for the automated detection of COVID-19 are discussed in
this section. 2D CNN, AlexNet, Visual Geometry Group
(VGG) network, GoogLeNet, DenseNet, XceptionNet, MobileNet, SqueezeNet, Inception-ResNet, CapsNet, NasNetmobile, ShuffleNet, EfficientNet, and Generative Adversarial
Networks (GAN) have been used for the automated detection
of COVID-19 patients using X-ray and CT images.

Fig. 5: Typical 2D-CNN architecture used for COVID-19
detection.

S TANDARD 2D-CNN
The primary issue in training the deep models is the
concern of overfitting that occurs from the gap between the
limited number of training samples and a large number of
learnable parameters. Convolutional networks try to overcome
this by using convolutional layers. CNNs require minimal
pre-processing by considering the 2-dimensional (2D) images
as input, and hence it is designed to retain and utilize the
structural information among neighboring pixels or voxels.
A differentiable function is utilized to transform one volume
of actions by each layer to the other as it is a sequence of
layers structurally. Figure 6 represents the architecture for
a usual computer vision job that comprises of three neural
layers: convolutional, pooling, and fully connected layers. The
convolutional layers are usually combined with the pooling
layers, and their output is fed to the fully connected layers
[35]. Also, a variety of methods like dropout and batch
normalization help these networks to learn better [35].
A LEX N ET
As the first famous deep learning network, Alexnet is still
the center of attention in many studies. Figure 6 depicts the
architecture of AlexNet. In this network, two new perspectives
dropout, and local response normalization (LRN) are used
to help the network learn better. Dropout is applied in two
FC layers employed in the end. On the other hand, LRN,

4

Fig. 6: A typical AlexNet architecture used for COVID-19
detection.

Fig. 8: Naive version of inception layer.

Fig. 7: A typical VGG architecture used for COVID-19
detection.

Fig. 9: Inception layer with dimension reduction.

utilized in convolutional layers, can be employed in two
different ways: Firstly, applying single channel or feature
maps, where the same feature map normalizes depending on
the neighborhood values and selects the NN patch. Secondly,
LRN can be exploited across the channels or feature maps
[36], [37].
VGGN ET
The VGG architecture comprised of a few convolutional
layers, each of that utilizes the ReLU activation function. For
classification, this network uses a softmax classifier in the final
layer of the model. Filter size for convolutional layers is picked
equal to 3x3, with a stride of 2 in VGG-E. VGG-11, VGG-16,
and VGG-19 are three variants of the VGG-E model that have
11, 16, and 19 layers correspondingly. All variants of VGGE architecture end with three FC layers. Nevertheless, the
numbers of convolution layers are different; VGG-19 contains
16 convolution layers, VGG-16 has 13 convolution layers,
and VGG-11 has eight convolution layers. Figure 7 depicts
the building block of the VGG network used for COVID-19
detection [36], [38].
G OOG L E N ET
Different receptive fields, generated by various kernel sizes,
form Inception layers, which are incorporated in this model.
Operations generated by these receptive fields records sparse
correlation patterns in the novel feature map stack [36]. Figure
8 describes the initial concept of the inception layer. A stack
of inception layers is utilized by GoogLeNet to enhance
recognition accuracy, as shown in Figure 9. The difference
between the final inception layer and the nave inception layer
is the inclusion of 1x1 convolution kernels, which performs
a dimensionality reduction, consequently reducing the computational cost. Another idea in GooGLeNet is the gradient
injection, which aims to overcome the gradient vanishing

problem. GoogLeNet comprises of a total of 22 layers that is
greater than any previous network. However, GoogLeNet uses
much fewer parameters compared to its predecessors VGG or
AlexNet [36], [39].
R ES N ET
The Residual Network (ResNet) is created with various
numbers of layers; 1202,152, 101, 50, and 34. ResNet50 is
one of the popular variants containing 49 convolution layers
and 1 FC layer at the end of it. The total number of MACs
and weights are 3.9M and 25.5M, respectively [36], [40],
[41]. Figure 10 shows a typical ResNet architecture used for
COVID-19 detection.
D ENSE N ET
The DenseNet that comprised of densely connected CNN
layers, in a dense block [36], [43] with the outputs of
each layer are connected with all descendant layers. Due to
the dense connectivity between the layers, it is termed as
DenseNet. Network parameters are reduced dramatically by
efficient utilization of feature reuse. DenseNet comprises of
various transition blocks and dense blocks that are situated in
between two adjacent dense blocks. Figure 11 describes the
conceptual diagram of a dense block [36].
X CEPTION N ET
The Xception architecture is based on Inception V3. The
Xception architecture is a linear stack of depth-wise separable
convolution layers with residual connections. The network
entails 36 layers of convolution organized in 14 modules, all of
which contain linear residual connections around them, except
for the first and last modules. Utilizing residual connections
in Xception architecture will lead to faster convergence and
superior final performance [44].
M OBILE N ET
The novel model called MobileNets is aimed to be used

5

Fig. 10: A typical ResNet architecture used for COVID-19
detection [42].
Fig. 12: Left: standard CNN layer with BN and ReLU. Right:
Depth-wise separable convolutions with depth-wise and Pointwise layers followed by BN and ReLU.

Fig. 11: A 4-layer dense block with growth rate of k=3 used
for COVID-19 detection [36].

in mobile and embedded machine vision applications [45].
The main layers exploited in this architecture are known
as depthwise separable convolution. The depthwise separable
convolution consists of two layers: depthwise convolution,
and pointwise convolution. The depthwise convolution is used
to apply a single filter to each input channel (input depth).
Then the pointwise convolution, simple 1x1 convolution, is
employed to create a linear combination of depthwise layer
outputs. After both of these layers, a ReLU and batch normalization (BN) are placed (Figure 12) [46].
S QUEEZE N ET
Using three architectural design strategies, this structure
has introduced a fire module [47]. The module consists of
a squeeze-convolution layer that has only 1x1 filters, followed by an expansion layer that has a set of 1x1 and 3x3
convolution filters. With slight modification and optimization
in the original SqueezeNet architecture, two other architectures, SqueezeNet with simple bypass and SqueezeNet with
complex bypass, were also demonstrated. By benchmarking
the SqueezeNet architecture on the ImageNet database and
comparing its results with the AlexNet architecture, it was
found that the SqueezeNet accuracy is at the AlexNet level,
but the 50X has a lower parameter, and the model size is less
than 0.5MB [47].
I NCEPTION -R ES N ET
In 2016, Szegedy et al. proposed the idea of integrating
Inception architecture with residual connections, meaning that
the filter concatenation stage in Inception architecture would
be replaced by residual connections [41]. The idea led to a new
architecture called Inception-ResNet, which has two versions,
V1 and V2. At the same time, another architecture named
Inception V4 was introduced, in which reduction blocks were
exploited. These blocks are modified versions of Inception

modules. Finally, it was perceived that introducing residual
connections to Inception architecture significantly improves
training speed. Also, both of these architectures have outperformed than previous architects [41].
C APS N ET
With advancements of CNNs and new structures, they have
reached high accuracies on many tasks. However, one of the
deficiencies of CNN models is when they face samples drown
from a dataset with a different orientation than a training
dataset. To address this, CapsNet was proposed. The central
idea behind this network is to create a network that implicitly
performs an operation similar to inverse graphics; i.e., it tries
to find graphical shapes in an image. The building block of
this structure is capsules, which try to determine whether an
object is presented at a given location and find its instantiation.
With the help of these capsules, CapsNet performs better than
its prior models in many tasks and specifically in cases where
two classes have a considerable overlap [48].
NAS N ET-M OBILE
In a try to find a method to learn architecture directly from
data instead of handly designing it [49], NASNet was created.
First, the best normal convolution cell and the reduction
convolution cell are found in NASNet’s search space by
applying the RNN controller, on a small dataset. The RNN
controller then stacks multiple copies of these cells with
various parameters to acquire NASNet architecture. A new
regularization technique called ScheduledDropPath has also
been stated, which dramatically meliorate the generalizability
of NASNet models. The architectures obtained on the COCO
object detection database have also been evaluated in all cases,
showing that the architectures could achieve state-of-the-art
performance [49].
S HUFFLE N ET
ShuffleNet is specially designed for mobile devices with
minimal computing power [50], [51]. This architecture employs two operations, pointwise group convolution and channel
shuffle, to maintain the network’s accuracy while reducing
the computational cost. ShuffleNet architecture embraces a
convolution layer, two pooling layers, a stack of ShuffleNet
units that are structured in three stages, and finally, an FC
layer. Although ShuffleNet is designed for small models, it still

6

Fig. 13: A typical ShuffleNet for COVID-19 detection [52].

Fig. 15: A typical FCN architecture used for segmentation of
lung in COVID-19 patients.

Fig. 14: A Simple GAN architecture.

surpasses MobileNet (lower computation cost, higher training
speed). Figure 13 shows a general form of ShuffleNet used
for COVID-19 detection.
E FFICIENT N ET
The fundamental building block in EfficientNet was to
overcome the MBConv mobile bottleneck. The EfficientNet
architecture developed using the compound scaling method,
which led to the EfficientNet-B0 to B7. It is found that this
architecture has fewer parameters of 8.4x and a faster running
time of 6.1x [53].
2) Generative Adversarial Networks (GAN): A primary
problem in training deep models is limits in dataset size. Using
generative models for data augmentation is one solution to
this issue. Due to the high quality of generated data, GANs
have attracted attention in the medical imaging community
[54]. The basic idea in training a GAN is a simple minimax
game, in which one network tries to distinguish between real
data and generates one, and the other tries to create data
undistinguishable by the first network [55], therefor creating
images similar to real data. Figure 14 shows a simple gan
architecture.
3) Segmentation Models: In this section, various DL models developed to segment the lung region to detect the COVID19 patients accurately are discussed. FCN network, SegNet,
U-Net, and Res2Net DL models are widely used for the
segmentation of lungs and are briefly discussed below.
F ULLY C ONVOLUTIONAL N ETWORK (FCN)
In this model, popular networks have transformed entirely
convolutional models by replacing FC layers with convolution
layers to capture output as a local map. These maps are upsampled using the introduced method, which uses a backward
convolution with stride size f, capable of learning. At the end
of the network, there is a 1x1 convolution layer that yields the
corresponding pixel label as the output. The exiting stride in

Fig. 16: A typical SegNet architecture used to segment lung
in COVID-19 patients [58].

the deconvolution stage constraints the output detail quantity
of this layer. To address this issue and enhance the quality
of the result, several skip connections have been added to the
network from the lower layers to the end layer [56]. Figure
15 shows a general form of FCN used for the segmentation
of lung in COVID-19 patients.
S EG N ET
Generally, in segmentation techniques, a network created for
classification is chosen, and the FC layers of that network are
removed; the resulting network is called the encoder network.
Then a decoder is created to transform these low-resolution
maps to the original resolution. In SegNet [57], the decoder
is created such that for each down-sampling layer in the
encoding section, an up-sampling layer is positioned in the
decoder. These layers, unlike the deconvolution layers of FCN
networks, are not capable of learning, and the values are placed
at the locations from which the corresponding max-pooling
layer is extracted, and the rest of the output cells become
zero. Figure 16 shows a general form of SegNet used for the
segmentation of lung in COVID-19patients.
U-N ET
The U-Net network [59], like SegNet, consists of the
identical numbers of pooling and up-sampling layers, but the
network utilizes trainable deconvolution layers. Also, in this
network, there is a corresponding skip connection between
the up-sampling and down-sampling layers. Figure 17 shows

7

Fig. 17: A typical U-Net architecture used to segment the lung
in COVID-19 patients [60].

a general form of U-Net architecture used to segment the lung
in COVID-19 patients.
R ES 2N ET
In the Res2Net module, after the 1*1 convolution, the
feature maps are divided into several subsets, then passed
through a set of 3*3 filters. Their outputs are concatenated
together and then go through the 1*1 convolution [61]. The
set of this process is residually structured. For that reason,
it is named as Res2Net module. This module introduces a
new control parameter called the scale dimension (the number
of feature groups in the Res2Net block); with an increase of
scale, features with richer receptive field sizes are learned by
the model. The Res2Net module is capable of integrating with
modern modules such as cardinality dimension and squeeze
and excitation (SE). It can also be integrated easily with stateof-the-art models, such as ResNet, ResNeXt, DLA, Big-Little
Net, which are called Res2Net, Res2NeXt, Res2Net-DLA, and
bLRes2Net-50, respectively [61].
4) Forecasting Models: R ECURRENT N EURAL N ETWORK (RNN)
A feed-forward neural network is extended to create RNN,
aiming to capture the long term dependencies and features
from the sequential and time-series data. The most commonly
used RNN is the long-short term memory (LSTM), which
composed of a memory cell Ct, a forget cell ft, the input
gate it, and output gate ot (figure 18(a)). These gates make
the decision that which information needs to be remembered
or discarded from the memory cell and also organizes the
activation signals from different sources.
LSTM decides whether to keep or remove the memory by
using these gates, unlike vanilla RNN, LSTM can preserve the
potential long term dependencies of a feature, which is learned
from the input sequential data. One LSTM variant is Gated
Recurrent Unit (GRU) [62], which integrates the forget and
input gates into a single update gate and combines the memory
cell state and the hidden state into one state (figure 18(b)).
Update gate makes a decision on the amount of information
to be added or discarded, and the reset gate decides on how
much earlier information is to be forgotten. This technique
makes GRU simpler than LSTM.
AUTOENCODERS (AE S )

Fig. 18: Architecture of LSTM (a) and GRU (b). In the figure
a, the yellow, green and blue represent output gate, input gate
and forget gate respectively. In the figure b, the yellow and
blue represent the update and reset gate respectively. Biases
are not shown to keep the figure simple [35].

Fig. 19: Diagram of Autoencoder.

Autoencoder (AE) is a neural network method with competent data encoding and decoding strategies used for unsupervised feature learning [35]. The primary purpose of AE
is usually to learn and representation of data (encoding), as
well as dimensionality reduction of data, fusion, compression,
and many more [63], [64]. The AE models comprised of two
phases: encoder and decoder. The input samples are mapped
typically to a lower-dimensional space with beneficial feature
representation in the encoding part. Reverse processing is
applied in the decoding phase to revert data to its original
space, trying to create data from lower space representation.
Figure 19 depicts the conceptual diagram of AE with encoding
and decoding phases.

8

TABLE III: Summary of state-of-art DL techniques used for the automated detection of COVID-19 patients.
Work

Dataset

Modalities

Number of Cases

Preprocessing

DNN toolbox

DNN

Number of
Layers

Classifier

Post Processing

K-Fold

[65]

COVIDx

X-ray

45 COVID-19, 1203 Normal, 931 Bacterial Pneumonia,
660 Viral Pneumonia Patients

Data Augmentation (DA),
Rescaling, Normalizing

Fastai Library

COVID-ResNet
(ResNet-50)

Modified
Version

Softmax

NA

NA

[66]

Combination of
Different Datasets

X-ray

50 COVID-19, 50 Normal Images

Rescaling

NA

ResNet50

Modified
Version

Softmax

NA

5

Combination of
Different Datasets

X-ray,
CT-Scan

85 COVID-19 X-ray, 203 COVID-19 CT-scan, 85
Normal X-ray, 153 Normal CT-scan

Cropping, resizing

NA

AlexNet

Modified
Version

Softmax

NA

NA

COVIDX-Net
(VGG19,
DenseNet201)

Standard
Version

Softmax

NA

NA

[67]

[68]

Cohens GitHub

X-ray

25 COVID-19, 25 Normal Cases

Rescaling

Keras with TensorFlow2 Backend

[69]

Combination of
Different Datasets

X-ray

70 COVID-19 subjects, 1008 Pneumonia Subjects

Rescaling, DA

NA

ResNet-18

Standard
Version + 8

Sigmoid

Grad-CAM

NA

[70]

COVIDx

X-ray

266 COVID-19 Patient Cases, 8,066 Normal Patient
Cases, 5,538 Non-COVID19 Pneumonia Patient Cases

DA

Keras with TensorFlow Backend

COVID-Net

87

Softmax

Explainability-Driven
Audit (GSInquire Method)

NA

[71]

COVIDx

X-ray

76 COVID-19, 1583 Normal, 4290 Pneumonia Cases

DA, RGB format, Normalizing

MATLAB

COVIDiagnosis-Net

Standard
Version

Decision-Making
System

Class Activation
Mapping Visualization

NA

[72]

Combination of
Different Datasets

X-ray

68 COVID-19, 1583 Normal, 2786 Bacterial Pneumonia,
1504 Viral Pneumonia Images

Resizing, Standardizing, DA

Keras

ResNet50-V2

Modified
Version

Softmax

saliency Maps Visualization,
Different Gradient Methods

NA

[73]

Combination of
Different Datasets

295 COVID-19, 65 Normal, 98 Pneumonia Images

Fuzzy Color Method, Image
Stacking Technique

MATLAB

MobileNetV2
SqueezeNet

Standard
Version

SMO, SVM

Social Mimic Optimization
Method

5

Keras

ResNet50

Modified
Version

Dense Layer

NA

NA

X-ray

[74]

Clinical

CT-Scan

368 COVID-19 Patients, 127 Patients with Other Pneumonia

Segmentation, Rescaling,
Multi-view Fusion

[75]

Combination of
Different Datasets

X-ray

127 COVID-19, 500 No-Findings
and 500 Pneumonia Images

NA

NA

DarkCovidNet (CNN)

39

Linear

Interpretation of Heatmaps
Results of the DarkCovidNet
Model by an
Expert Radiologist

5

[76]

Clinical

CT-Scan

108 COVID-19, 86 Non-COVID-19 Patients

Different Methods

NA

ResNet-101,
Xception

Standard
Version

Softmax

NA

NA

[77]

Combination of
Different Datasets

X-ray

105 COVID-19 ,11 SARS, 80 Normal Samples

DA, Histogram, Feature Extraction
using AlexNet, PCA, K-means

MATLAB

DeTraC (ResNet18)

Standard
Version

Softmax

Composition Phase

NA

X-ray

90 COVID-19, 10 MERS, 11 SARS, 10 Varicella,
12 Streptococcus, 11 Pneumocystis Samples

Different Features, Early Fusion, Late
Fusion, Different Resampling Algorithms

Inception-V3

Standard
Version

MLP
Clus-HMC
Framework

Friedman Statistical
Test for Ranking

NA

Softmax

NA

NA

[78]

RYDLS-20

NA

[79]

Pneumonia Dataset

X-ray

624 Images in 2 Categories: Normal and Pneumonia

GAN

MATLAB

ResNet18

Standard
Version

[80]

SIRM Dataset

CT-Scan

53 Infected CT Images

Two Different Patch Datasets

NA

VGG-16, GoogleNet
and ResNet-50
(Feature Extraction)

Standard
Version

SVM

NA

NA

[81]

COVIDx

X-ray

NA

NA

NA

COVID-CAPS

9

Capsule Layer

NA

NA

[82]

Combination of
Different Datasets

X-ray

284 Covid-19, 310 Normal, 330 Pneumonia Bacterial,
327 Pneumonia Viral Images

Rescaling

Keras with TensorFlow Backend

CoroNet

Modified
Version

Softmax

NA

NA

Rescaling

DenseNet169

Standard
Version

Softmax

NA

NA

Intensity Normalization, DA

EfficientNet B3

50

Softmax

Activation Map
Visualization

NA
5

NA

[83]

Kaggle

X-ray

5,863 X-Ray Images in Two Classes Normal and
Pneumonia, 145 Chest X-ray Images of COVID-19

[84]

COVIDx

X-ray

13; 800 Images from 13; 645 Individuals

Keras with TensorFlow Backend
Keras with TensorFlow Backend

[42]

3 Different
COVIDx Datasets

X-ray

Different Number of Cases

Different Methods

Keras with TensorFlow Backend

DenseNet-161

Modified
Version

Softmax

Grad-CAM, Grad-CAM++,
LRP Visualizations

[85]

UCSD-AI4H

CT-Scan

349 COVID-19 Images, 397 Non-COVID-19 Images

GAN, Rescaling, Cropping

NA

DECAPS
Architecture

Proposed
Method

HAMs

Peekaboo Strategy

Performance
Criteria (%)
Acc=96.23
Sen=100
Pre=100
F1-Score=100
Acc=98
Recall=96
Spe=100
Acc=98
Sen=100
Spe=96
Acc=90
Pre=83
F1-Score=91
Sen=96
Spe=70.65
AUC=95.18
Acc=93.3
Sen=91
PPV=98.9
Acc=98.3
Spe=99.13
F1-Score=98.3
Predictive
Entropy=99.68
BALD=88.73
Acc=99.27
Acc=76
Sen=81.1
Spe=61.5
2-classes:
Acc=98.08
Spe=95.3
Sen=95.13
Pre=98.03
F1-Score=96.51
3 classes:
Acc=87.02
Spe=92.18
Sen=85.35
Pre=89.96
F1-Score=87.37
Sen=98.04
Spe=100
Acc=99.02
Acc=95.12
Sen=97.91
Spe=91.87
F1-Score=83.33
F1-Score=88.89
Acc=99
Pre=98.97
F1-Score=98.97
Acc=98.27
Sen=98.93
Spe=97.60
Pre=97.63
F1-Score=98.28
Acc=95.7
Sen=90
Spe=95.8
Acc=89.5
Pre=97
F1-Score=98
Avg Acc=95.72
Acc=93.9
Sen=96.8
Pre=94
Recall=95
F1-Score=94.5
Acc=87.6
Pre=84.3
Spe=85.2
F1-Score=87.1

[86]

Combination of
Different Datasets

X-ray

99 COVID-19 Cases From the COVID19 Chest
X-ray Dataset, 207 Images From Both Dataset

Balancing dataset, DA

Keras

GSA-DenseNet121COVID-19

Modified
Version

Softmax

NA

NA

[87]

COVID-Xray5k Dataset

X-ray

536 COVID-19 Images, 5000 Non-COVID19

DA, Down Sampling

PyTorch

SqueezeNet

Standard
Version

Softmax

NA

NA

[88]

Combination of
Different Datasets

X-ray

207 COVID-19 Images, 5,863 Non-COVID-19 Images

DA

NA

DenseNet-161

Modified
Version

Softmax

NA

NA

[89]

Combination of
Different Datasets

X-ray

239 COVID-19 cases, 1,000 Bacterial or Viral Pneumonia
Cases, 1,000 Healthy People

DA

Keras.

DCSL
Framework

Modified
Version

Softmax

T-SNE

5

[90]

Combination of
Different Datasets

X-ray

108 COVID-19, 515 Other Pneumonia, 453 Normal

Class Balancing Methods, Binary
Thresholding, Adaptive Total
Variation Method

NA

NASNetLarge

Modified
Version

Softmax

CAM and LIME
Techniques

NA

[91]

Combination of
Different Datasets

X-ray

225 COVID-19 Images, 108,948 Frontal View
Images From 32,717 Unique Patients

DA

Keras with TensorFlow Backend

CN

12

FCMLP

Grad-CAM

5

[92]

Combination of
Different Datasets

X-ray

180 COVID-19 Images, 6054 Pneumonia,
8851 Normal

Keras

Concatenation of
Xception and
ResNet50V2

Modified
Version

Softmax

NA

5

[93]

Combination of
Different Datasets

X-ray

NA

Different Methods

PyTorch

COVID-DA

Modified
Version

NA

Grad-CAM

NA

[94]

Combination of
Different Datasets

X-ray

NA

Cropping, CLAHE Method, Resizing,
DA

NA

CovIDNet

15

Softmax

NA

NA

DA, Oversampling

NA

3 ResNet18

Modified
Version

Ensemble
Models

NA

5

NA

Acc=98
Pre=98
F1-Score=98
Sen=97.5
Spec=97.8
Acc=99
Pre=100
F1-Score=99
Acc=97.01
Pre=97
Sen=97.09
F1-Score=96.98
Acc=98
Pre=88
Spe=95
F1-Score=89
Acc=95.3
Acc=99.56
F1-Score=92.98
Pre=98.15
AUC=98.5
Acc=98.4
Sen=100
Spe=96.97

[95]

Different Datasets

X-ray

Dataset A (1579 Normal and 4429 Diseased),
Dataset B (4245 Pneumonia and 1763 Non-Pneumonia),
Dataset C (184 COVID-19 and 5824 Non-COVID19),
Dataset D (1579 Normal, 4245 Pneumonia, and
184 COVID-19)

[96]

Clinical

CT-Scan

88 COVID-19 Patients, 100 Bacteria Pneumonia
Patients, 86 Healthy Persons

Different Methods

OpenCV

DRE-Net
(ResNet-50
Backbone)

Modified
Version

Aggregation

Visualization

NA

[97]

Clinical

CT-Scan

1495 Patients of COVID-19 and 1027 Patients of
Community Acquired Pneumonia (CAP)

Segmentation using VBNet,
Feature Extraction

NA

AFS-DF

Proposed
Architecture

Ensemble the
Predicted
Value

NA

5

[98]

Combination of
Different Datasets

X-Ray,
CT-Scan

200 of COVID-19, 200 Healthy, 200 Bacterial
Pneumonia 200 Viral Pneumonia

NA

Caffe

ResNet101

Standard
Version

Softmax

NA

10

[99]

Cohens GitHub

X-ray,
CT-Scan

4 ARDS, 101 COVID-19, 2 No finding,
2 Pneumocystis-Pneumonia, 11 SARS, 6 Streptococcus

DA, Different Features,
Feature Merging,
Data Over-Sampling
using SMOTE

NA

SAE (Feature
Reduction)

6

SVM

NA

NA

[100]

Clinical

CT-Scan

44 COVID-19, 55 Typical Viral Pneumonia

ROIs Extraction Visual Inspection

NA

M-Inception

Modified
Version

Combined
Decision
Tree and
Adaboost

NA

NA

[101]

Combination of
Different Datasets

X-ray

314 COVID-19

Keras with TensorFlow Backend

VGG16

Standard
Version

Softmax

GradCAM

NA

Acc=99.26

[102]

Clinical

CT-Scan

109 COVID-19, 201 Non-COVID-19

NA

CovidCTNet

19

Softmax

NA

NA

Acc=90
Sen=83
Spe=92.85

[103]

Kaggle Data
Repository

X-ray

150 COVID-19

Segmentation using UNet,
Standard Preprocessing,
WeaklyLabeled DA
Standard Preprocessing, Generating
Pseudo-Infection Anomalies
using BCDU-Net
Filtering, Segmentation using
Thresholding

NA

NA

[52]

Combination of
Different Datasets

CT-Scan

521 COVID-19, 521 Non-COVID-19

[104]

COVIDx

X-ray

[105]

Different Datasets

CT-Scan

NA

CNN

11

Softmax

DA, Random Cropping Operation

NA

CNN with
ShuffleNetV2 as
the backbone

Standard
Version

Linear
Layer

NA

NA

99 COVID-19, 18529 Non-COVID-19

DA

PyTorch

CoroNet (TFEN
+ CIN modules)

2 Independent
FPAE +
ResNet18

Softmax

Perturbation-based Algorithms for Generating
Attribution Maps

NA

349 COVID-19, 397 Non-COVID-19

DA, Self-Trans Method

PyTorch

DenseNet-169

Standard
Version

Softmax

Grad-CAM

NA

Modified
Version

Ensemble
Learning

Grad-CAM

5

Modified
Version

Softmax

Grad-CAM

10

[106]

Clinical

CT-Scan

3389 COVID-19, 1593 Non-COVID-19

Standard Preprocessing, VB-Net
Toolkit for Segmentation
and Lung Mask Generation

PyTorch

3D ResNet34
Models with the
Online
Attention Module

[107]

COVIDx

X-ray

238 COVID-19, 14896 Non-COVID-19

DA

TensorFlow

DenseNet-121

Acc=95.5
MCC=89.6
Pre=94
Recall=100
F1-Score=96.6
Acc=94
AUC=99
Pre=96
F1-Score=94
Acc=91.79
Sen=93.05
Spe=89.95
AUC=96.35
Acc=98.75
Spe=97.50
Sen=100
Pre=96.43
Acc=71.92
Sen=68.91
Spe=93.91
Pre=69.89
F1-Score=69.13
Acc=82.9
Sen=81
Spe=84
AUC=90
F1-Score=77

Acc=93
Acc=91.21
Sen=90.52
Spe=91.58
Acc=93.50
Sen=90
Pre=93.63
F1-Score=93.51
Acc=86
F1-Score=85
AUC=94
Acc=87.5
Sen=86.9
Spe=90.1
AUC=94.4
F1-Score=82.0
Acc=96.4
Pre=96
Recall=96
F1-Score=96

9

10

[108]

Clinical

CT-Scan

146 COVID-19, 149 Non-COVID-19

DA

PyTorch

DenseNet

Standard
Version

[109]

Combination of
Different Datasets

X-ray

158 COVID-19, 158 Non-COVID-19

NA

MATLAB

ResNet50

Softmax

CAM

NA

Standard
Version

SVM

NA

NA

NA

NA

Acc=92
Sen=97
Spe=87
F1-Score=93
Acc=95.38
Sen=97.29
Spe=93.47
Acc=86.7
Pre=81.3
F1-Score=83.9
Acc=99.18
Sen=97.36
Spe=99.42
Acc=95
Sen=90
Spe=97
Acc=92.18
Sen=92.11
Spec=96.06
Pre=92.38
F1-Score=92.07
Acc=100
Pre=100
F1-Score=100

[110]

Clinical

CT-Scan

219 COVID-19, 399 Non-COVID-19

Preprocessing Based on HU Values

NA

ResNet18

29

Noisy-or
Bayesian
Function

[111]

Combination of
Different Datasets

X-ray

455 COVID-19 Images, 2109 Non-COVID-19 Images

Rescaling, DA

Keras with TensorFlow Backend

MobileNet V2

Modified
Version

NA

NA

10

[112]

Combination of
Different Datasets

X-ray

403 COVID-19 Images, 721 Non-COVID-19 Images

Resizing, Normalizing, DA using
CovidGAN Based AC-GAN

Keras

VGG16

Standard
Version

Softmax

PCA Visualization

NA

[113]

Combination of
Different Datasets

X-ray,
CT-scan

6087 images (2780 Bacterial Pneumonia, 1724 Coronavirus
(1493 Viral Pneumonia, 231 Covid19), 1583 Normal)

Intensity Normalization,
CLAHE Method, DA, Resizing

Keras with TensorFlow Backend

Inception
ResNetV2

Standard
Version

MLP

NA

5

[114]

Combination of
Different Datasets

X-ray

69 COVID-19 Images, 79 Normal, 79 Pneumonia
Bacterial, 79 Pneumonia Viruses

DA using GAN

MATLAB

GoogLeNet

Standard
Version

Softmax

NA

NA

[115]

Combination of
Different Datasets

MATLAB

CNN (Feature
Extraction)

12

LSTM

NA

NA

Acc=99.68

DA

NA

Resnet50,
VGG16,
Small CNN

Modified
Version

Snapshot
Ensemble of
21 Models

NA

10

Acc=91.24
AUC=94

CT-Scan

1118 COVID-19 Images, 96 Pneumonia Images,
107 Healthy Images
135 chest X-rays of COVID-19 and 320 Chest
X-rays of Viral and Bacterial Pneumonia
Unseen Data Consisting of 33 COVID-19 Data
Cases, and 218 Pneumonia Cases

Different Methods

[116]

Combination of
Different Datasets

X-ray

[117]

Combination of
Different Datasets

X-ray

224 Covid-19 cases, 504 Healthy Cases,
400 Bacteria, 314 Viral Pneumonia

Resizing

NA

MobileNet

Modified
Version

NA

NA

NA

[118]

Combination of
Different Datasets

X-ray

219 COVID-19 Images, 1341 Normal Lung Images,
1345 Viral Pneumonia Images

Manually editing, Reshaping,
DA

PyTorch

CheXNet
(DenseNet121
Backbone)

Modified
Version

Sigmoid

Heatmaps Generation
using LRP

NA

[119]

Different Datasets

X-ray

49 COVID-19 Images, 88,079 Non-COVID-19 Images

Standard Preprocessing

TorchXRayVision Library

DenseNet

Modified
Version

Sigmoid,
LR

t-SNE, Saliency Maps

NA

[120]

Combination of
Different Datasets

X-ray

190 COVID-19, 1345 Viral Pneumonia,
and 1341 Normal Chest X-ray Images

Resizing, Normalization, DA

MATLAB

SqueezeNet

Modified
Version

Softmax

NA

5

[121]

COVID-CTDataset

CT-Scan

345 COVID-19, 397 Non COVID-19

Resizing, DA using CGAN,
Normalizing

TensorFlow

ResNet50

Modified
Version

Softmax

NA

NA

Modified
Version

Softmax

NA

5

Modified
Version

Softmax

NA

NA

NA

NA

Concatenation
of the Xception
and ResNet50V2
VGG16,
VGG19

Acc=96.78
Sen=98.66
Spe=96.46
Acc=98.3
Pre=98.3
F1-score=98.3
MAE=1.14
Acc=98.3
Sen=96.7
Spe=100
Pre=100
Acc=82.91
Sen=80.85
Spe=91.43

[122]

Combination of
Different Datasets

X-ray

180 COVID-19 cases, 6054 Pneumonia Cases,
8851 Normal Cases

DA

Keras

[123]

Kaggle

X-ray

70 COVID-19 and 80 Normal Images

Resizing, DA

NA

[124]

Combination of
Different Datasets

X-ray

215 COVID-19, 6045 CAP, 8851 Normal Images

DA

PyTorch

Different
PreTrain Deep
Networks

Modified
Version

Softmax

[125]

Combination of
Different Datasets

X-ray

69 COVID-19, 79 Normal, 79 Pneumonia Bacterial,
79 Pneumonia Virus Images

Resizing, Neutrosophic Image
Domain Conversion, Normalizing

MATLAB

GoogLeNet

Standard
Version

Softmax

NA

NA

Acc=73.12

[126]

Combination of
Different Datasets

X-ray,
CT-scan

117 X-ray and 20 CT Scan of COVID-19,
117 Healthy X-ray Images, 20 Healthy CT Scan Images

Resizing, Normalizing

Keras with TensorFlow Backend

DenseNet121

Standard
Version

Bagging
Tree

Web-Based
Application

10

Acc=99
Pre=96
F1-Score=96

[127]

Combination of
Different Datasets

X-ray

181 COVID-19 Images, 364 Healthy Images

Normalizing, Resizing

NA

VGG-19

Modified
Version

Softmax

NA

NA

Acc=96.3

NA

AUC=70

10

Acc=95.78
AUC=99.4

Visual Interpretation
by Two Experienced
Radiologists
Interpretation by 6
Radiologists, t-SNE
Method

Acc=91.4
Acc=97
Sen=100
Spe=94
Ensemble of
Models:
Acc=89.4
F1-Score=64

[128]

Clinical

CT-Scan

151 COVID-19 Patient, 498 Non-COVID-19 Patient

Resizing, Padding, DA

NA

3D-CNN

15

Softmax

[129]

Public Datasets
& Private Datasets

CT-Scan

1,684 COVID-19 Patient, 1,055 Pneumonia,
914 Normal Patients

Resizing

NA

Inception V1

Modified
Version

Softmax

[130]

Combination of
Different Datasets

CT-Scan

413 COVID-19 Images and 439 Normal or Pneumonia
Infected Patients Images

ResNet50 (Feature
Extraction)

NA

CNN

14

Softmax

NA

10

[131]

Combination of
Different Datasets

X-ray

142 COVID-19 Images, 142 Normal Images

Resizing, DA

NA

NCOVnet
(VGG-16)

Modified
Version

Softmax

NA

NA

[132]

Combination of
Different Datasets

X-ray

326 COVID 19 Images, 984 Non-COVID-19
Images

Manual Annotation, Data Balancing
and Augmentation Strategies,
Normalizing, Resizing

NA

CNN with
YOLO
Predictor

54

Tensor of
Prediction
(ToP)

NA

5

Acc=97.40
Spe=99.056
Sen=85.15

[133]

Combination of
Different Datasets

X-ray

250 COVID-19, 2,753 Other Pulmonary
Diseases, 3,520 Healthy Images

Resizing, DA

NA

VGG-16

Modified
Version

Softmax

Grad-CAM

NA

Acc=97
Sen=87
Spe=94

Acc=93.01
Spe=94.77
Sen=91.45
Pre=95.18
Acc=97.62
Sen=97.62
Spe=78.57

[134]

Combination of
Different Datasets

X-ray

179 COVID-19, 179 Pneumonia, 179 Normal Images

Create a Noisy Snapshot Dataset

PyTorch

DenseNet-121,
ShuffleNetV2,
MobileNetV2

Modified/
Standard
Versions

NA

t-SNE, GRAD-CAM

NA

[135]

Another
Reference

CT-Scan

73 Patients with COVID-19

MODE Algorithm for
Hyper-Parameter Tuning

MATLAB

CNN

7

NA

NA

20

[136]

Clinical
(3 Datasets)

Reshaping to Different Resolutions,
Normalizing

NA

Stacked MultiResolution
CovXNet

Different
Number of
Layers

Stacking
using
Meta-Learner

Grad-CAM

5

1583 Normal, 1493 Non-COVID Viral Pneumonia,
2780 Bacterial Pneumonia Images
X-ray

305 COVID 19 Images
305 COVID-19,305 Normal, 305 Viral,
305 Bacterial Pneumonia Images

Acc=84.3
AUROC=94
Acc=92
F1-Score=90
Sen=90
Spe=90
Acc=97.4
Spe=94.7
F1-score=97.1
Recall=97.8
Pre=96.3
AUC=96.9
AUC=97.2
Sen=92
Spe=91
Acc=98.77
Sen=95
Spe=99
Pre=99
F1-score=97
Acc=90.61
Recall=90.80
Pre=89.76
F1-Score=90.13
Acc=99.4
Pre=99.5
F1-Score=99.4
Binary Acc=99.58
Multi-Class
Acc=96.43

[137]

Clinical

CT-Scan

98 COVID-19 Patients, 103 Non-COVID-19
Patients

Visual Inspection

Google
Colaboratory

BigBiGAN

NA

Linear Classifier

NA

NA

[138]

Combination of
Different Datasets

X-ray

162 COVID-19 Images, 2003 Healthy, 4280 Viral
and Bacterial Pneumonia, 400 Tuberculosis

Resizing, Normalizing

NA

Truncated
InceptionNet V3

Modified
Version

Softmax

Activation Maps
Generation

10

[139]

UCSD-AI4H
Datasets

CT-Scan

349 Patients with Confirmed COVID
and 397 Healthy Subjects

Resizing, Normalizing

Keras with TensorFlow Backed

DenseNet121

Standard Version

Nu-SVM

Web based CAD
Implementation with
Flask RESTful

10

[140]

Different Datasets

X-ray

219 COVID-19, 1341 Normal, 1345 Viral
Pneumonia Images

Resizing, Normalizing, DA

PyTorch,
Keras with TensorFlow Backend

DenseNet-201

Modified
Version

Sigmoid

LRP

NA

X-ray

536 COVID-19 Images, 619 Viral Pneumonia,
and 668 Normal Images

White Balance Algorithm, CLAHE,
Normalizing, Resizing

Keras with TensorFlow Backend

Softmax

t-SNE,S Maps,
Grad-CAM, LIME

5

5

Pre=86.4
Recall=84.5
F1-score=85.4

[141]

Different Datasets

COVIDLite

38

DenseNet161

Standard
Version

Sigmoid

Occlusion, Saliency,
Input X Gradient,
Guided Backpropagation,
Integrated Gradients,
DeepLIFT

NA

VGG16

Modified
Version

Softmax

NA

5

Acc=84.1

Standard
Version

NA

UAPs using FGSM

NA

Acc=92.6
Avg Acc=94.4

[142]

Combination of
Different Datasets

X-ray

236 COVID-19 Images, 500 Healthy, 250 Viral
Pneumonia, 250 Bacterial Pneumonia Images

Resizing, Zero-Padding, Percentile
Cropping, Intensity Normalization

PyTorch

[143]

Combination of
Different Datasets

X-ray

X-rays of 327 Patients

Resizing, DA, Normalizing
NA

NA

COVIDNet-CXR
Small and COVIDNet-CXR Large

[144]

COVIDx

X-ray

183 COVID-19 Images, 5551 Pneumonia
Images, 8066 Normal Images

[145]

Combination of
Different Datasets

X-ray

127 COVID-19 Images, 127 Pneumonia
Images, 127 Healthy Images

NA

MATLAB

ResNet50

Standard
Version

SVM

NA

NA

[146]

Combination of
Different Datasets

X-ray

738 Images of COVID-19, 5000 Normal,
4600 Images of CAP

DA, Normalization, Resizing,
CLAHE, BEASF

NA

CNN

8

NA

Grad-CAM, LIME

NA

[147]

Clinical

CT-Scan

79 Patients with COVID-19, 100 Patients
with Common Pneumonia, 130 People
without Pneumonia.

DA

PyTorch

AD3D-MIL

Proposed
Method

Bernouli
Distribution

CAM

5

Acc=95.33
Sen=95.33
F1-Score=95.34
Acc=98.68
AUC=99.84
F1-Score=94
Acc=97.9
AUC=99
F1-Score=97.9
Pre=97.9
Recall=97.9

TABLE IV: Summary of DL segmentation methods used for COVID-19 detection.
Work

Dataset

Modalities

Number of Cases

Preprocessing

DNN toolbox

DNN

NA

ResNet50

Number of
Layers

Classifier

Post Processing

K-Fold

Standard

Corona Score
Computation

Grad-Cam,
3D Visualization

NA

[148]

Different Clinical
Datasets

CT-Scan

157 International Patients

Detect and Measure Nodules, Lung Crop
using U-net, DA

[149]

Clinical

CT-Scan

549 COVID-19 Patients

HITL Strategy

NA

VB-Net

8 Block

NA

Quantitative Metrics
Measurements

NA

[150]

Combination of
Different Datasets

CT-Scan

610 COVID-19 Images, 695 Non-COVID-19 Images

Resizing, DA

PyTorch

DenseNet-169
+ ASPP Layer

Standard

NA

NA

NA

X-ray and
CT-Scan

1,341 Normal Samples, 3,875 Pneumonia Samples,
420 CT-Scan samples where 247 Normal Samples,
178 COVID-19 Samples
704 Chest X-ray Images with Corresponding Masks,
267 CT-Scan Samples with Corresponding Masks

Resizing, DA, NABLA-3
Network for ROI Detection

TensorFlow

IRRCNN
Model

7

Softmax

NA

NA

NA

Residual
Attention U-Net

9 ResNeXt
blocks+14 Layers

[151]

[152]

[153]

Combination of
Different Datasets

Different Datasets

Different Datasets

CT-Scan

CT-Scan

110 Axial CT-Scan Images From 60 Patients

Different Number of Cases

Resizing, Grey Scaling (GL), DA

NA

ResNet50

Standard

Visualization

10

Sigmoid

GradCam, Combine the
Fine Grain Maps to Create 3D
Localization Maps, K-Means

NA

X-ray:
Acc=84.67
CT:
Acc=98.78
Acc=89
Pre=95
DSC=94
AUC=99.4
Sen=94
Spec=98

11

Lung Segmentation using U-net with
a VGG-16 Based Encoder, DA

Sigmoid

Performance
Criteria (%)
AUC=99.6
Sen=98.2
Spe=92.2
DSC=91.6
Mean POI
Estimation
Error=0.3
F1-score=84.6
AUC=94.8
Acc=83

12

[154]

COVID-CS Dataset

CT-Scan

144,167 CT-Scan Images of 400
COVID-19 Patients and 350 Uninfected Cases

DA, Segmentation
using Encoder-Decoder Model

NA

Res2Net

Standard

Softmax

Visualization of
Activation Mapping

NA

[155]

Italian Society of
Medical and
Interventional Radiology

CT-Scan

473 CT Slices for COVID-19

Resizing, GL, Intensity Normalization

Keras

U-Net

50

Sigmoid

Visualization

NA

[156]

6 Different Datasets

X-ray

Different Number of Cases

Histogram, Segmentation using U-Net,
Intensity Normalization

PyTorch

ResNet18

Standard

Softmax

t-SNE Clustering

NA

[157]

COPD Dataset (Pretrain)
COVID-19 Set

CT-Scan

Standard Preprocessing

PyTorch

RTSU-Net

2 RU-Net

Sigmoid,
Softmax

Different Methods

NA

Probabilistic Grad-CAM
Saliency Map Visualization

NA

[158]

Different Dataset

X-ray

TCIA Dataset (Pretrain)

5000 COPDGene, Subjects
470 COVID-19 Subjects
180 Images of 118 COVID-19 Subjects,
191 Normal, 54 Bacterial Pneumonia,
57 Tuberculosis, 20 Viral Pneumonia

Standard Preprocessing,
Segmentation using FC-DenseNet103

PyTorch

ResNet18

Standard

Majority
Voting

DA, Fixed-Sized Sliding Window,
Segmentation using U-Net

TensorFlow

CNN

27

Softmax

Multi-Window Voting PostProcessing Procedure and a
Sequential Information Attention
Module, CAM, CategoricalSpecific Joint Saliency

5

60 3D CT-Scan Lung

[159]

COVID-19
Clinical Dataset

CT-Scan

150 3D Volumetric Chest CT Exams of
COVID-19, CAP and NP Patients

[160]

COVID-19 Dataset

CT-Scan

60 Patients with COVID-19

Resizing, DA

PyTorch

MiniSeg

Proposed
Structure

Sigmoid and
Softmax

NA

NA

[161]

Combination of
Different Dataset

X-ray

313 COVID-19 Images, 7595 Normal,
6012 Pneumonia of Unknown Type,
2780 Bacterial Pneumonia Images

Segmentation using U-Net,
Standard Preprocessing

NA

VGG-16, VGG-19,
Inception-V3

Modified
Version

Weighted Average Ensemble
Method

Grad-CAM

NA

Sigmoid

NA

NA

[162]

COVID-SemiSeg

CT-Scan

Dataset I
[163]

Pseudo Label Generation

PyTorch

Semi-Supervised
Inf-Net+MultiClass Segmentation

Modified
Res2Net+
U-Net as
Backbones

Adaptive Histogram, CLAHE Method,
MoEx, Use U-Net to Segment
Lung Area (VGG19), DA

NA

CascadeSEMENet

Modified
Version

Sigmoid

Grad-CAM

NA

210 COVID-19, 330 Others

COVID-SegNet

11 Blocks

Softmax

NA

NA

100 Labeled Images, 1600 Unlabeled
Images of COVID-19
466 Normal, 860 Bacteria, 433 Viruses

X-ray
Dataset II

[58]

Clinical

CT-Scan

21,658 Images From 861 COVID-19 Patients

Cropping

Pytorch

[164]

Clinical

CT-Scan

10 Axial Volumetric CT-Scans
of COVID-19 Pneumonia Patients

Under-Sampling of
the Majority Class

Keras with TensorFlow Backend

FCN-8s

NA

NA

NA

NA

Keras with TensorFlow Backend

Encoder and Two
Decoders (2D U-NET
Architecture)
and MLP

24, 24, 15

Sigmoid

NA

NA

PyTorch

DeCoVNet

20

Softmax

NA

NA

PyTorch

ResNet50

Standard
Version

Softmax

NA

NA

Modified
Version

Softmax

Heatmap Visualization

5

Loss Function

Segmentation

5

[165]

Combination of
Different Dataset

CT-Scan

449 COVID-19 Patients, 100 Normal,
98 Lung Cancer, 397 Other Pathology

[166]

Clinical

CT-Scan

313 COVID-19, 229 Non-COVID-19

Resizing, Intensity Normalization

Normalizing, Resampling, DA, 3D Lung
Mask Generation using 2D U-Net
Visual Data Annotation and Quality,
Normalization, 3D
U-Net++ for Segmentation, DA

[167]

Clinical

CT-Scan

877 COVID-19, 991 Non-COVID-19

[168]

Clinical

CT-Scan

1315 COVID-19 Scans, 3342 Non-COVID-19 Scans

Lobe Segmentation using 3D-Unet,
Cropping, Resizing, DA

Keras with TensorFlow Backend

3D-ResNets with
Prior-Attention
Mechanism

[169]

Clinical

LUS Images

17 COVID-19 Patients, 4 Were COVID-19
Suspected, and 14 Were Healthy

Labelling Process, DA, Reg-STN Model

NA

CNN

NA

CT-Scan

296 COVID-19 Images, 1735 CAP,
1325 Non-Pneumonia Images

Lung Segmentation using U-net

COVNet

Modified
Version

Keras

COVID-19Net

[170]

Clinical

NA

Softmax

Grad-CAM

NA

4 Dense
Blocks
+9 Layers

Sigmoid

Combined Feature Vectors,
Multivariate Cox Proportional
Hazard Model,
Visualizations

NA

Avg Sen=95
Spe=93
Dice Score=78.3
Dice Score=83.1
Sen=86.7
Spe=99.3
Acc=100
Sen=100
Spec=100
F1-score=100
IOU=92.2
ASSD=86.6
Sen=100
Pre=76.9
Acc=96.2
Pre=97.3
Sen=94.5
Spe=95.3
AUC=97
Sen=83.62
Spe=97.42
DSC=77.28
HD=68.07
Acc=99.01
Sen=99.01
Pre=99.01
AUC=99.72
Dice=54.1
Sen=56.4
Spe=96.7
MAE=5.7
Acc=85.6
F1-Score=86
Acc=97.1
F1-Score=97
DSC=72.6
Sen=75.1
Pre=72.6
Acc=100
F1-Score=90
Pre=98
Acc=86
Sen=94
Spe=79
AUC=93
DSC=78.5
Acc=90.8
Sen=97.4
Spe=92.2
AUC=99.1
Acc=93.3
Sen=87.6
Spe=95.5
NA
AUC=96
Sen=90
Spe=96
Acc=81.24
AUC=0.90
Sen=78.93
Spe=89.93
F1-Score=86.92

[171]

Clinical

CT-Scan

1266 COVID-19 Patients, 4106 Patients
with Lung Cancer (Auxiliary Training Set)

DenseNet121-FPN for Lung
Segmentation, 3-Dimensional Bounding
Box, Non-Lung Area
Suppression Operation

[172]

Clinical

CT-scan

219 From 110 Patients with COVID-19,
224 CT-Scan from patients, 175
CT-Scan From Healthy People

Segmentation using VNET-IR-RPN, DA

NA

ResNet-18 with
Location-Attention
Mechanism

Modified
Version

Voting
Strategy

Total Infection Confidence
Score Calculation using
Probability Formula of the
Noisy-or Bayesian Function

NA

[173]

Clinical

CT-Scan

129 COVID-19 images

Segmentation Using U-Net,
Different Preprocessing Methods

NA

ResNet18

Modified
Version

Softmax

Calculate the Proportion of
Infected Regions in Lung

NA

[174]

Clinical

CT-Scan

100 COVID-19 and 100 healthy controls

lDRL Landmarks, DI2IN Segmentation,
Alignment, Resampling

Pytorch

DenseUNet

Modified
Version

Softmax

Visualization

NA

Proposed
Architecture

NA

Proposed
Loss Function

NA

Dice=80.72
RVE=15.96

NA

NA

NA

3

AUC=95.1
Spearman
Correlation=98

[175]

Clinical

CT-Scan

558 COVID-19 Patients

2D CNNs for the Segmentation

PyTorch

Student COPLE-Net+
EMA for Adaptive teacher+
Teacher COPLE-Net

[176]

Combination of
Different Datasets

CT-Scan

33 COVID-19 Patients, 32 Healthy Patients,
36 Patients with Other Lung Pathologies

Rescaling, Intensity Normalization,
Creating Feature Map using U-Net

NA

Different
Architectures

Acc=86.7
Acc=93.8
AUC=91.3
m-Dice=74.3
Different
Parameters

13

Fig. 20: Total number of investigations conducted in the field
of classification, segmentation, and prediction of COVID-19
patients using DL techniques.

Fig. 21: Number of datasets used for COVID-19 detection and
prediction based on the published papers using DL methods.

V. D ISCUSSION
The main focus of this work is to select the best DL
models employed to detect, segment the lungs, and predict
the COVID-19 patients using DL techniques. The summary
of works done on classification, segmentation, and prediction
are presented in Tables III, IV, and V, respectively. Figure
20 depicts the total number of investigations conducted in the
field of classification, segmentation, and prediction of COVID19 using DL models. It can be noted from the figure that most
works have been done on the detection of COVID-19 patients,
and the least works are done on the forecasting due to shortage
of available public databases.
The X-ray and CT images have been used to develop
classification and segmentation DL models. Figure 21 shows
the total number of times each modality is used in reviewed
studies. It can be observed that most of the researchers have
used X-ray images. This may be due to cheaper registration
fees, and the fact that slice selection is not needed. Also,
very few researches have used combined modalities of X-ray
and CT images due to the absence of such a comprehensive
database.
Various DL models developed for the automated detection
of COVID-19 patients is shown in Figure 22. It can be noted
from the figure that; different types of convolutional networks
have been commonly used. Also, for the automated segmentation of lungs, various types of U-Net are more common.
Nowadays, a variety of toolboxes have been used to implement DL models. The number of toolboxes used for automated
detection of COVID-19 by researches is shown in Figure 23.
It can be noted that Keras toolbox is the most widely used for
automated detection of COVID-19 patients; this is due to its
simplicity and also availability of pre-trained models in this
library, which are widely used by researchers.
The last part of this study is devoted to the classification
algorithms developed using DL architectures. The softmax
is most employed for automated detection of COVID-19
patients (Tables III to V). Figure 24 shows the number of

Fig. 22: Number of DL architectures used for COVID-19
detection and prediction based on published papers.

various classification algorithms used for automated detection
of COVID-19 patients using DL techniques.
VI. C HALLENGES
With the rapid growth and spread of COVID-19 globally,
researchers have confronted many serious challenges in designing and implementing CADS to diagnose and predict
the disease. The most significant challenges associated with
COVID-19 are data availability, DL networks architecture
fixing, and hardware resources. Lack of availability of a huge
public database comprising X-ray and CT images is the first
challenge. Due to the limited number of patient data, many researchers have used pre-trained networks such as GoogLeNet
and AlexNet. Nevertheless, the number of studies conducted
on forecasting is limited as it requires a vast database.
One of the problems of employing pre-trained networks is
that these models are often trained on the ImageNet database,
which is entirely different from medical images. Hence, implementing efficient CADS to accurately and swiftly diagnose
COVID-19 from X-Ray or CT images is still a challenging
work. Physicians are not just convinced with X-ray or CT-scan
images of patients to accurately diagnose COVID-19; they

14

TABLE V: Summary of DL models developed for the forecasting spread of COVID-19.
Work

Dataset

Preprocessing

DNN
Toolbox

DNN

Number
of layers

K-Fold

Post
Processing

[177]

Johns Hopkins University and Canadian Health Authority

WT, ADF test

NA

LSTM

3

NA

NA

[178]

Surging News Network (a Media Outlet) and WHO

Reshaping

NA

CNN

7

NA

NA

Performance
Criteria
RMSE=45.70
Acc=92.67%
MAE=102.943
RMSE=109.439

[179]

Google Trends Website

NA

LSTM

3

10

NA

RMSE=27.187

[180]

India Government

NA

LSTM

NA

NA

Curves

[181]

Times Series Dataset of COVID-19 Confirmed Cases for Tunisia and China

Grid Search Technique,
Sliding Window (SW)

NA
DNN: 5
LSTM:5
CNN: 7

NA

Augmented
Prediction

Acc=99%
RMSE=2,396
Curves

[182]
[183]

Cumulative and New Confirmed Cases of Covid-19 in All of China and 31 Provinces/
Cities in Mainland and Three Other Regions (Hong Kong, Macau and Taiwan)
COVID-19 Confirmed Data from Iran Ministry of Health and Medical
Education, IRNA, ISNA Sources in Provincial Level and National Level

[184]

Combined of Local Trend Data and Weather Data

[185]

WHO and Johns Hopkins University Datasets

[186]

Johns Hopkins University, Lockdown dates of Countries Datasets

[187]

John Hopkins University,
Oxford COVID-19 Government Response Tracker

[188]

TheMinistry of Health and Family Welfare
(Government of India)

Keras with TensorFlow Backend
MATLAB
NA

Stacked Ensemble
Meta-Learners

Windowing, Normalizing

NA

Modified AutoEncoders (MAE)

3

5

k-Means

NA

TensorFlow

LSTM

NA

NA

NA

Curves
RMSE=2300.8
Acc=78%
Curves
Curves
Curves

Feature Selection using
OLS Regression, Network
Hyper-Parameters Search
Normalizing
Windowing, Normalization,
Proposed Improved Method
Feature Selection, Spatially
Weighted Adjacency Matrix
Computation, Reshaping to 3D Tensor
Linear Weighted Moving Average
Technique

Fig. 23: Number of DL tools used for COVID-19 detection
and prediction based on the published papers.

Fig. 24: Illustration of number of various classifier algorithms
used in DL networks for automated detection of COVID-19
patients.

NA

LSTM

3

NA

NA

LSTM

4

NA

Fuzzy RuleBased Risk
Categorization
RMSLE

NA

LSTM

4

NA

NA

NA

Variational LSTMAutoencoder with SelfAttention Mechanism

3 Blocks

NA

NA

Curves

NA

MAPE Less
Than 3%

Keras with TensorFlow Backend

Bi-LSTM

3

NA

CT-Scan datasets from various datasets, which may disrupt
network training. Yielding the combined X-Ray and CT-Scan
datasets pave the path to help quickly identify COVID-19
alongside DL networks. The third challenge in the data section
is the non-reporting of phenotypic information, such as age
and gender. The utilization of this information can amend and
enhance the performance of DL algorithms.
Table IV summarizes the DL-based segmentation algorithms
aimed at identifying areas suspected of corona in the X-ray
and CT-scan images. One of the obstacles with databases is the
absence of manual or ground truths for COVID-19 image segmentation areas. Therefore, many researchers have delineated
these areas with the help of radiologists and trained the models
such as U-Net, which is time-consuming. Consequently, the
presence of dedicated databases of segmented images will
help to get the best performing model. Also, it becomes easy
to compare the performances with other authors who have
worked on the same images.
In order to predict the prevalence of corona using DL methods, the nature of the COVID-19 is still relatively unknown,
and the probability of mutation is a big issue. Therefore, to
predict the prevalence of the disease, many factors like the
average age of the society, policies to impede the spread of
the disease by countries, climatic conditions, and infection of
neighbor/friend/family member.
Lack of access to appropriate hardware resources is another
challenge. Implementing DL architectures in CADS for corona
diagnosis demands strong hardware resources, which unfortunately is not ordinarily accessible for many researchers. Although tools such as Google Colab have partially obviated this
problem, employing these tools in real medical applications is
still challenging. For this reason, in most studies, researchers
have not provided practical CADS systems such as web or
Windows software to detect COVID-19.
VII. C ONCLUSION AND F UTURE W ORKS

may use both modalities simultaneously. However, complete
and comprehensive databases of the X-ray and CT-scan hybrid
modalities for CADS research and implementation have not
been provided for researchers’ in the machine learning scope.
For this reason, researchers combine different X-ray and

COVID-19 is an emerging pandemic disease that, in a short
period of time, can severely endanger the health of many
people throughout the world. It directly affects the lung cells,
and if not accurately diagnosed early, can cause irreversible
damage, including death. The disease is accurately detected by
the specialists using X-ray or CT images together with PCR

15

results. The PCR results indicate the type of lung disease,
such as pulmonary tuberculosis, instead of COVID-19. In this
study, a comprehensive review of the accomplished studies of
COVID-19 diagnosis was carried out using DL networks. The
public databases available to diagnose and predict COVID19 are presented. The state-of-art DL techniques employed
for the diagnosis, segmentation, and forecasting of the spread
of COVID-19 are presented in Tables III, IV, V, respectively.
One of the challenges to develop a robust and accurate COVID
19 diagnosis system is the availability of an extensive public
database. We strongly feel that, with more public databases,
better DL models can be developed by researchers to detect
and predict the COVID19 accurately. Hence, this will help to
develop the best performing model. We feel that data fusion
models can help to improve the performance of diagnosis and
prediction. The features extracted from the ML and DL models
can be fused to develop an accurate model.
Also, developing the accurate segmentation model is challenging as it involves delineating the lungs by the experts.
Having an accurate ground truth is another challenge.

C. Accuracy
Accuracy verifies that how many samples are correctly
classified.
Accuracy(Acc) =

TP + TN
TP + TN + FP + FN

(3)

D. Specificity
It is the rate of recognition of negative samples correctly.
Specif icity(Spe) =

TN
TN + FP

(4)

E. Sensitivity
It is the rate of recognition of positive samples correctly.
Sensitivity(Sen) =

TP
TP + FN

(5)

F. Precision
A PPENDIX A
E VALUATION M ETRICS

It calculates how precise the model performs by examining
the correct true positives from the predicted ones.

This section discusses the evaluation metrics used in different studies. In these metrics, True positive (TP) is the correct
classification ratio of the positive class, False positive (FP)
is the incorrect prediction ratio of the positives, True negative
(TN) is the correct classification ratio of the negative class, and
finally False negative (FN) is the incorrect prediction ratio of
the negatives [189].

P recision(P re) =

F1-score is the function of sensitivity and precision, which
tries to find a balance between sensitivity and precision.

A. Receiver Operating Characteristic Curve (ROC-Curve)

TPR =

TP
TP + FN

FP
FPR =
FP + TN

(1)

(6)

G. F1-Score

F 1 − Score = 2 ∗
The receiver operating characteristic curve (ROC-curve)
illustrates the performance of the proposed model at all
classification thresholds. It is the graph of true positive rate
vs. false positive rate (TPR vs. FPR).

TP
TP + FP

P re ∗ Sen
P re + Sen

(7)

H. Average Accuracy
It is a measure of effectiveness of the classification technique.
Pn
T P +T N
T P +T N +F P +F N

AvgAcc =

n

(8)

where n is the total number of outputs of the system.
(2)
I. Jaccard Index

B. Area under the ROC Curve (AUC)
AUC depicts the area under the ROC-curve incorporated
from (0, 0) to (1, 1). It presents the cumulative measure of all
possible classification thresholds. AUC has a range from 0 to 1.
A 100% wrong classification will have AUC value 0.0, while
a 100% correct classified version will have the AUC value 1.0.
It has two folded benefits; first, it is scale-invariant, meaning
that entailed value shows how well the model is predicted
rather than examining the absolute values. The second benefit
is that it is classification-threshold invariant, as it will validate
the models performance irrespective of the threshold being
chosen.

It is a measure of similarity rate between two sample groups.
Jacidx =

TP
TP + FP + FN

(9)

J. Dice-Coefficient
It is a statistical measure of similarity rate between two
sample groups.
Dicecof =

2 ∗ TP
2 ∗ TP + FP + FN

(10)

16

R EFERENCES
[1] J. F.-W. Chan, S. Yuan, K.-H. Kok, K. K.-W. To, H. Chu, J. Yang,
F. Xing, J. Liu, C. C.-Y. Yip, R. W.-S. Poon et al., “A familial cluster
of pneumonia associated with the 2019 novel coronavirus indicating
person-to-person transmission: a study of a family cluster,” The Lancet,
vol. 395, no. 10223, pp. 514–523, 2020.
[2] X. Peng, X. Xu, Y. Li, L. Cheng, X. Zhou, and B. Ren, “Transmission
routes of 2019-ncov and controls in dental practice,” International
Journal of Oral Science, vol. 12, no. 1, pp. 1–6, 2020.
[3] S. Tian, W. Hu, L. Niu, H. Liu, H. Xu, and S.-Y. Xiao, “Pulmonary
pathology of early phase 2019 novel coronavirus (covid-19) pneumonia
in two patients with lung cancer,” Journal of Thoracic Oncology, 2020.
[4] T. C. Lan, M. F. Allan, L. Malsick, S. Khandwala, S. S. Nyeo,
M. Bathe, A. Griffiths, and S. Rouskin, “Structure of the full sarscov-2 rna genome in infected cells,” bioRxiv, 2020.
[5] M. S. Razai, K. Doerholt, S. Ladhani, and P. Oakeshott, “Coronavirus
disease 2019 (covid-19): a guide for uk gps,” BMJ, vol. 368, 2020.
[6] A. Remuzzi and G. Remuzzi, “Covid-19 and italy: what next?” The
Lancet, 2020.
[7] C. Sohrabi, Z. Alsafi, N. ONeill, M. Khan, A. Kerwan, A. Al-Jabir,
C. Iosifidis, and R. Agha, “World health organization declares global
emergency: A review of the 2019 novel coronavirus (covid-19),”
International Journal of Surgery, 2020.
[8] A. E. Hassanien, L. N. Mahdy, K. A. Ezzat, H. H. Elmousalami,
and H. A. Ella, “Automatic x-ray covid-19 lung image classification
system based on multi-level thresholding and support vector machine,”
medRxiv, 2020.
[9] S. Kadry, V. Rajinikanth, S. Rho, N. S. M. Raja, V. S. Rao, and
K. P. Thanaraj, “Development of a machine-learning system to classify lung ct scan images into normal/covid-19 class,” arXiv preprint
arXiv:2004.13122, 2020.
[10] W. H. Self, D. M. Courtney, C. D. McNaughton, R. G. Wunderink, and
J. A. Kline, “High discordance of chest x-ray and computed tomography for detection of pulmonary opacities in ed patients: implications for
diagnosing pneumonia,” The American journal of emergency medicine,
vol. 31, no. 2, pp. 401–405, 2013.
[11] G. D. Rubin, C. J. Ryerson, L. B. Haramati, N. Sverzellati, J. P. Kanne,
S. Raoof, N. W. Schluger, A. Volpi, J.-J. Yim, I. B. Martin et al.,
“The role of chest imaging in patient management during the covid19 pandemic: a multinational consensus statement from the fleischner
society,” Chest, 2020.
[12] L. Orioli, M. P. Hermans, J.-P. Thissen, D. Maiter, B. Vandeleene, and
J.-C. Yombi, “Covid-19 in diabetic patients: related risks and specifics
of management,” in Annales D’endocrinologie. Elsevier, 2020.
[13] “https://www.ecdc.europa.eu/en/geographical-distribution2019-ncov-cases,”
https://www.ecdc.europa.eu/en/
geographical-distribution-2019-ncov-cases, 2020.
[14] R. Alizadehsani, M. Behjati, Z. Roshanzamir, S. Hussain, N. Abedini,
F. Hasanzadeh, A. Khosravi, A. Shoeibi, M. Roshanzamir, P. Moradnejad et al., “Risk factors prediction, clinical outcomes, and mortality
of covid-19 patients,” medRxiv, 2020.
[15] L. J. Kroft, L. van der Velden, I. H. Girón, J. J. Roelofs, A. de Roos,
and J. Geleijns, “Added value of ultra–low-dose computed tomography, dose equivalent to chest x-ray radiography, for diagnosing chest
pathology,” Journal of thoracic imaging, vol. 34, no. 3, p. 179, 2019.
[16] N. Ghassemi, A. Shoeibi, and M. Rouhani, “Deep neural network
with generative adversarial networks pre-training for brain tumor
classification based on mr images,” Biomedical Signal Processing and
Control, vol. 57, p. 101678, 2020.
[17] M. Talo, O. Yildirim, U. B. Baloglu, G. Aydin, and U. R. Acharya,
“Convolutional neural networks for multi-class brain disease detection
using mri images,” Computerized Medical Imaging and Graphics,
vol. 78, p. 101673, 2019.
[18] N. Ghassemi, A. Shoeibi, M. Rouhani, and H. Hosseini-Nejad, “Epileptic seizures detection in eeg signals using tqwt and ensemble learning,”
in 2019 9th International Conference on Computer and Knowledge
Engineering (ICCKE). IEEE, 2019, pp. 403–408.
[19] U. R. Acharya, S. L. Oh, Y. Hagiwara, J. H. Tan, and H. Adeli, “Deep
convolutional neural network for the automated detection and diagnosis
of seizure using eeg signals,” Computers in biology and medicine, vol.
100, pp. 270–278, 2018.
[20] M. Mohammadpoor, A. Shoeibi, H. Zare, and H. Shojaee, “A hierarchical classification method for breast tumor detection,” Iranian Journal
of Medical Physics, vol. 13, no. 4, pp. 261–268, 2016.

[21] D. Arefan, A. A. Mohamed, W. A. Berg, M. L. Zuley, J. H. Sumkin,
and S. Wu, “Deep learning modeling using normal mammograms for
predicting breast cancer risk,” Medical physics, vol. 47, no. 1, pp. 110–
118, 2020.
[22] A. Z. Khuzani, M. Heidari, and S. A. Shariati, “Covid-classifier: An
automated machine learning model to assist in the diagnosis of covid19 infection in chest x-ray images,” medRxiv, 2020.
[23] X. Mei, H.-C. Lee, K.-y. Diao, M. Huang, B. Lin, C. Liu, Z. Xie,
Y. Ma, P. M. Robson, M. Chung et al., “Artificial intelligence–enabled
rapid diagnosis of patients with covid-19,” Nature Medicine, pp. 1–5,
2020.
[24] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau,
and S. Thrun, “Dermatologist-level classification of skin cancer with
deep neural networks,” nature, vol. 542, no. 7639, pp. 115–118, 2017.
[25] M. A. Mazurowski, M. Buda, A. Saha, and M. R. Bashir, “Deep
learning in radiology: An overview of the concepts and a survey of
the state of the art with focus on mri,” Journal of magnetic resonance
imaging, vol. 49, no. 4, pp. 939–954, 2019.
[26] T. M. Tuan, T. T. Ngan, C. N. Giap et al., “Semisupervised fuzzy
clustering methods for x-ray image segmentation,” in Handbook of
Data Science Approaches for Biomedical Engineering. Elsevier, 2020,
pp. 251–289.
[27] A. Shoeibi, N. Ghassemi, H. Hosseini-Nejad, and M. Rouhani, “An
efficient brain mr images segmentation hardware using kernel fuzzy
c-means,” in 2019 26th National and 4th International Iranian Conference on Biomedical Engineering (ICBME). IEEE, 2019, pp. 93–99.
[28] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention.
Springer, 2015, pp. 234–241.
[29] J. P. Cohen, P. Morrison, L. Dao, K. Roth, T. Q. Duong,
and M. Ghassemi, “Covid-19 image data collection: Prospective
predictions are the future,” arXiv 2006.11988, 2020. [Online].
Available: https://github.com/ieee8023/covid-chestxray-dataset
[30] J. Zhao, Y. Zhang, X. He, and P. Xie, “Covid-ct-dataset: a ct scan
dataset about covid-19,” arXiv preprint arXiv:2003.13865, 2020.
[31] J. Born, G. Brändle, M. Cossio, M. Disdier, J. Goulet, J. Roulin,
and N. Wiedemann, “Pocovid-net: Automatic detection of covid-19
from a new lung ultrasound imaging dataset (pocus),” arXiv preprint
arXiv:2004.12084, 2020.
[32] J. M. Banda, R. Tekumalla, G. Wang, J. Yu, T. Liu, Y. Ding,
and G. Chowell, “A large-scale covid-19 twitter chatter dataset for
open scientific research–an international collaboration,” arXiv preprint
arXiv:2004.03688, 2020.
[33] R. Hu, G. Ruan, S. Xiang, M. Huang, Q. Liang, and J. Li, “Automated
diagnosis of covid-19 using deep learning and data augmentation on
chest ct,” medRxiv, 2020.
[34] Z. Q. L. Linda Wang and A. Wong, “Covid-net: A tailored deep
convolutional neural network design for detection of covid-19 cases
from chest radiography images,” 2020.
[35] L. Zhang, M. Wang, M. Liu, and D. Zhang, “A survey on deep learning for neuroimaging-based brain disorder analysis,” arXiv preprint
arXiv:2005.04573, 2020.
[36] M. Z. Alom, T. M. Taha, C. Yakopcic, S. Westberg, P. Sidike, M. S.
Nasrin, B. C. Van Esesn, A. A. S. Awwal, and V. K. Asari, “The
history began from alexnet: A comprehensive survey on deep learning
approaches,” arXiv preprint arXiv:1803.01164, 2018.
[37] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” in Advances in neural
information processing systems, 2012, pp. 1097–1105.
[38] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014.
[39] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,
D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with
convolutions,” in Proceedings of the IEEE conference on computer
vision and pattern recognition, 2015, pp. 1–9.
[40] K. He, X. Zhang, S. Ren, and J. Sun, “Identity mappings in deep residual networks,” in European conference on computer vision. Springer,
2016, pp. 630–645.
[41] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi, “Inception-v4,
inception-resnet and the impact of residual connections on learning,”
in Thirty-first AAAI conference on artificial intelligence, 2017.
[42] M. Karim, T. Döhmen, D. Rebholz-Schuhmann, S. Decker, M. Cochez,
O. Beyan et al., “Deepcovidexplainer: Explainable covid-19 predictions
based on chest x-ray images,” arXiv preprint arXiv:2004.04582, 2020.
[43] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger,
“Densely connected convolutional networks,” in Proceedings of the

17

[44]

[45]

[46]

[47]

[48]

[49]

[50]

[51]

[52]

[53]
[54]

[55]

[56]

[57]

[58]

[59]

[60]

[61]

[62]

[63]

[64]
[65]

IEEE conference on computer vision and pattern recognition, 2017,
pp. 4700–4708.
F. Chollet, “Xception: Deep learning with depthwise separable convolutions,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2017, pp. 1251–1258.
A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang,
T. Weyand, M. Andreetto, and H. Adam, “Mobilenets: Efficient convolutional neural networks for mobile vision applications,” arXiv preprint
arXiv:1704.04861, 2017.
M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen, “Mobilenetv2: Inverted residuals and linear bottlenecks,” in Proceedings of
the IEEE conference on computer vision and pattern recognition, 2018,
pp. 4510–4520.
F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally,
and K. Keutzer, “Squeezenet: Alexnet-level accuracy with 50x fewer
parameters and¡ 0.5 mb model size,” arXiv preprint arXiv:1602.07360,
2016.
S. Sabour, N. Frosst, and G. E. Hinton, “Dynamic routing between
capsules,” in Advances in neural information processing systems, 2017,
pp. 3856–3866.
B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, “Learning transferable
architectures for scalable image recognition,” in Proceedings of the
IEEE conference on computer vision and pattern recognition, 2018,
pp. 8697–8710.
X. Zhang, X. Zhou, M. Lin, and J. Sun, “Shufflenet: An extremely efficient convolutional neural network for mobile devices,” in Proceedings
of the IEEE conference on computer vision and pattern recognition,
2018, pp. 6848–6856.
N. Ma, X. Zhang, H.-T. Zheng, and J. Sun, “Shufflenet v2: Practical
guidelines for efficient cnn architecture design,” in Proceedings of the
European conference on computer vision (ECCV), 2018, pp. 116–131.
R. Hu, G. Ruan, S. Xiang, M. Huang, Q. Liang, and J. Li, “Automated
diagnosis of covid-19 using deep learning and data augmentation on
chest ct,” medRxiv, 2020.
M. Tan and Q. V. Le, “Efficientnet: Rethinking model scaling for convolutional neural networks,” arXiv preprint arXiv:1905.11946, 2019.
X. Yi, E. Walia, and P. Babyn, “Generative adversarial network in
medical imaging: A review,” Medical image analysis, vol. 58, p.
101552, 2019.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in neural information processing systems, 2014, pp. 2672–
2680.
J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks
for semantic segmentation,” in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2015, pp. 3431–3440.
V. Badrinarayanan, A. Kendall, and R. Cipolla, “Segnet: A deep convolutional encoder-decoder architecture for image segmentation,” IEEE
transactions on pattern analysis and machine intelligence, vol. 39,
no. 12, pp. 2481–2495, 2017.
Q. Yan, B. Wang, D. Gong, C. Luo, W. Zhao, J. Shen, Q. Shi,
S. Jin, L. Zhang, and Z. You, “Covid-19 chest ct image segmentation–
a deep convolutional neural network solution,” arXiv preprint
arXiv:2004.10987, 2020.
O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in International Conference on Medical image computing and computer-assisted intervention.
Springer, 2015, pp. 234–241.
T. Zhou, S. Canu, and S. Ruan, “An automatic covid-19 ct segmentation
network using spatial and channel attention mechanism.” arXiv preprint
arXiv:2004.06673, 2020.
S. Gao, M.-M. Cheng, K. Zhao, X.-Y. Zhang, M.-H. Yang, and
P. H. Torr, “Res2net: A new multi-scale backbone architecture,” IEEE
transactions on pattern analysis and machine intelligence, 2019.
J. Chung, C. Gulcehre, K. Cho, and Y. Bengio, “Empirical evaluation of
gated recurrent neural networks on sequence modeling,” arXiv preprint
arXiv:1412.3555, 2014.
P. Baldi, “Autoencoders, unsupervised learning, and deep architectures,” in Proceedings of ICML workshop on unsupervised and transfer
learning, 2012, pp. 37–49.
I. Tolstikhin, O. Bousquet, S. Gelly, and B. Schoelkopf, “Wasserstein
auto-encoders,” arXiv preprint arXiv:1711.01558, 2017.
M. Farooq and A. Hafeez, “Covid-resnet: A deep learning framework for screening of covid19 from radiographs,” arXiv preprint
arXiv:2003.14395, 2020.

[66] A. Narin, C. Kaya, and Z. Pamuk, “Automatic detection of coronavirus
disease (covid-19) using x-ray images and deep convolutional neural
networks,” arXiv preprint arXiv:2003.10849, 2020.
[67] H. S. Maghdid, A. T. Asaad, K. Z. Ghafoor, A. S. Sadiq, and M. K.
Khan, “Diagnosing covid-19 pneumonia from x-ray and ct images
using deep learning and transfer learning algorithms,” arXiv preprint
arXiv:2004.00038, 2020.
[68] E. E.-D. Hemdan, M. A. Shouman, and M. E. Karar, “Covidx-net: A
framework of deep learning classifiers to diagnose covid-19 in x-ray
images,” arXiv preprint arXiv:2003.11055, 2020.
[69] J. Zhang, Y. Xie, Y. Li, C. Shen, and Y. Xia, “Covid-19 screening
on chest x-ray images using deep learning based anomaly detection,”
arXiv preprint arXiv:2003.12338, 2020.
[70] L. Wang and A. Wong, “Covid-net: A tailored deep convolutional
neural network design for detection of covid-19 cases from chest x-ray
images,” arXiv preprint arXiv:2003.09871, 2020.
[71] F. Ucar and D. Korkmaz, “Covidiagnosis-net: Deep bayes-squeezenet
based diagnostic of the coronavirus disease 2019 (covid-19) from x-ray
images,” Medical Hypotheses, p. 109761, 2020.
[72] B. Ghoshal and A. Tucker, “Estimating uncertainty and interpretability
in deep learning for coronavirus (covid-19) detection,” arXiv preprint
arXiv:2003.10769, 2020.
[73] M. Toğaçar, B. Ergen, and Z. Cömert, “Covid-19 detection using deep
learning models to exploit social mimic optimization and structured
chest x-ray images using fuzzy color and stacking approaches,” Computers in Biology and Medicine, p. 103805, 2020.
[74] X. Wu, H. Hui, M. Niu, L. Li, L. Wang, B. He, X. Yang, L. Li,
H. Li, J. Tian et al., “Deep learning-based multi-view fusion model
for screening 2019 novel coronavirus pneumonia: a multicentre study,”
European Journal of Radiology, p. 109041, 2020.
[75] T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu, O. Yildirim,
and U. R. Acharya, “Automated detection of covid-19 cases using
deep neural networks with x-ray images,” Computers in Biology and
Medicine, p. 103792, 2020.
[76] A. A. Ardakani, A. R. Kanafi, U. R. Acharya, N. Khadem, and
A. Mohammadi, “Application of deep learning technique to manage
covid-19 in routine clinical practice using ct images: Results of 10
convolutional neural networks,” Computers in Biology and Medicine,
p. 103795, 2020.
[77] A. Abbas, M. M. Abdelsamea, and M. M. Gaber, “Classification of
covid-19 in chest x-ray images using detrac deep convolutional neural
network,” arXiv preprint arXiv:2003.13815, 2020.
[78] R. M. Pereira, D. Bertolini, L. O. Teixeira, C. N. Silla Jr, and Y. M.
Costa, “Covid-19 identification in chest x-ray images on flat and
hierarchical classification scenarios,” Computer Methods and Programs
in Biomedicine, p. 105532, 2020.
[79] N. E. M. Khalifa, M. H. N. Taha, A. E. Hassanien, and S. Elghamrawy,
“Detection of coronavirus (covid-19) associated pneumonia based on
generative adversarial networks and a fine-tuned deep transfer learning
model using chest x-ray dataset,” arXiv preprint arXiv:2004.01184,
2020.
[80] U. Ozkaya, S. Ozturk, and M. Barstugan, “Coronavirus (covid-19)
classification using deep features fusion and ranking technique,” arXiv
preprint arXiv:2004.03698, 2020.
[81] P. Afshar, S. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis, and A. Mohammadi, “Covid-caps: A capsule network-based
framework for identification of covid-19 cases from x-ray images,”
arXiv preprint arXiv:2004.02696, 2020.
[82] A. I. Khan, J. L. Shah, and M. M. Bhat, “Coronet: A deep neural
network for detection and diagnosis of covid-19 from chest x-ray
images,” Computer Methods and Programs in Biomedicine, p. 105581,
2020.
[83] K. Hammoudi, H. Benhabiles, M. Melkemi, F. Dornaika, I. ArgandaCarreras, D. Collard, and A. Scherpereel, “Deep learning on chest x-ray
images to detect and evaluate pneumonia cases at the era of covid-19,”
arXiv preprint arXiv:2004.03399, 2020.
[84] E. Luz, P. L. Silva, R. Silva, and G. Moreira, “Towards an efficient
deep learning model for covid-19 patterns detection in x-ray images,”
arXiv preprint arXiv:2004.05717, 2020.
[85] A. Mobiny, P. A. Cicalese, S. Zare, P. Yuan, M. Abavisani, C. C.
Wu, J. Ahuja, P. M. de Groot, and H. Van Nguyen, “Radiologistlevel covid-19 detection using ct scans with detail-oriented capsule
networks,” arXiv preprint arXiv:2004.07407, 2020.
[86] D. Ezzat, H. A. Ella et al., “Gsa-densenet121-covid-19: a hybrid
deep learning architecture for the diagnosis of covid-19 disease
based on gravitational search optimization algorithm,” arXiv preprint
arXiv:2004.05084, 2020.

18

[87] S. Minaee, R. Kafieh, M. Sonka, S. Yazdani, and G. J. Soufi, “Deepcovid: Predicting covid-19 from chest x-ray images using deep transfer
learning,” arXiv preprint arXiv:2004.09363, 2020.
[88] J. de Moura, L. Ramos, P. L. Vidal, M. Cruz, L. Abelairas, E. Castro,
J. Novo, and M. Ortega, “Deep convolutional approaches for the
analysis of covid-19 using chest x-ray images from portable devices,”
medRxiv, 2020.
[89] T. Li, Z. Han, B. Wei, Y. Zheng, Y. Hong, and J. Cong, “Robust
screening of covid-19 from chest x-ray via discriminative cost-sensitive
learning,” arXiv preprint arXiv:2004.12592, 2020.
[90] N. S. Punn and S. Agarwal, “Automated diagnosis of covid-19 with
limited posteroanterior chest x-ray images using fine-tuned deep neural
networks,” arXiv preprint arXiv:2004.11676, 2020.
[91] S. Basu and S. Mitra, “Deep learning for screening covid-19 using
chest x-ray images,” arXiv preprint arXiv:2004.10507, 2020.
[92] M. Rahimzadeh and A. Attar, “A new modified deep convolutional
neural network for detecting covid-19 from x-ray images,” arXiv
preprint arXiv:2004.08052, 2020.
[93] Y. Zhang, S. Niu, Z. Qiu, Y. Wei, P. Zhao, J. Yao, J. Huang, Q. Wu, and
M. Tan, “Covid-da: Deep domain adaptation from typical pneumonia
to covid-19,” arXiv preprint arXiv:2005.01577, 2020.
[94] M. Ramadhan, A. Faza, L. Lubis, R. Yunus, T. Salamah, D. Handayani,
I. Lestariningsih, A. Resa, C. Alam, P. Prajitno et al., “Fast and accurate
detection of covid-19-related pneumonia from chest x-ray images with
novel deep learning model,” arXiv preprint arXiv:2005.04562, 2020.
[95] S. Misra, S. Jeon, S. Lee, R. Managuli, and C. Kim, “Multi-channel
transfer learning of chest x-ray images for screening of covid-19,” arXiv
preprint arXiv:2005.05576, 2020.
[96] Y. Song, S. Zheng, L. Li, X. Zhang, X. Zhang, Z. Huang, J. Chen,
H. Zhao, Y. Jie, R. Wang et al., “Deep learning enables accurate
diagnosis of novel coronavirus (covid-19) with ct images,” medRxiv,
2020.
[97] L. Sun, Z. Mo, F. Yan, L. Xia, F. Shan, Z. Ding, W. Shao,
F. Shi, H. Yuan, H. Jiang et al., “Adaptive feature selection guided
deep forest for covid-19 classification with chest ct,” arXiv preprint
arXiv:2005.03264, 2020.
[98] I. Razzak, S. Naz, A. Rehman, A. Khan, and A. Zaib, “Improving coronavirus (covid-19) diagnosis using deep transfer learning,” medRxiv,
2020.
[99] S. Ozturk, U. Ozkaya, and M. Barstugan, “Classification of coronavirus
images using shrunken features,” medRxiv, 2020.
[100] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang,
Y. Li, X. Meng et al., “A deep learning algorithm using ct images to
screen for corona virus disease (covid-19),” MedRxiv, 2020.
[101] S. Rajaraman and S. Antani, “Training deep learning algorithms with
weakly labeled pneumonia chest x-ray data for covid-19 detection,”
medRxiv, 2020.
[102] T. Javaheri, M. Homayounfar, Z. Amoozgar, R. Reiazi, F. Homayounieh, E. Abbas, A. Laali, A. R. Radmard, M. H. Gharib, S. A. J.
Mousavi et al., “Covidctnet: An open-source deep learning approach
to identify covid-19 using ct image,” arXiv preprint arXiv:2005.03059,
2020.
[103] M. Jamil, I. Hussain et al., “Automatic detection of covid-19 infection
from chest x-ray using deep learning,” medRxiv, 2020.
[104] S. Khobahi, C. Agarwal, and M. Soltanalian, “Coronet: A deep network
architecture for semi-supervised task-based identification of covid-19
from chest x-ray images,” medRxiv, 2020.
[105] X. He, X. Yang, S. Zhang, J. Zhao, Y. Zhang, E. Xing, and P. Xie,
“Sample-efficient deep learning for covid-19 diagnosis based on ct
scans,” medRxiv, 2020.
[106] X. Ouyang, J. Huo, L. Xia, F. Shan, J. Liu, Z. Mo, F. Yan, Z. Ding,
Q. Yang, B. Song et al., “Dual-sampling attention network for diagnosis
of covid-19 from community acquired pneumonia,” IEEE Transactions
on Medical Imaging, 2020.
[107] L. Sarker, M. Islam, T. Hannan, and A. Zakaria, “Covid-densenet:
A deep learning architecture to detect covid-19 from chest radiology
images,” Preprints, 2020.
[108] S. Yang, L. Jiang, Z. Cao, L. Wang, J. Cao, R. Feng, Z. Zhang,
X. Xue, Y. Shi, and F. Shan, “Deep learning for detecting corona virus
disease 2019 (covid-19) on high-resolution computed tomography: a
pilot study,” Annals of Translational Medicine, vol. 8, no. 7, 2020.
[109] P. K. Sethy and S. K. Behera, “Detection of coronavirus disease (covid19) based on deep features,” Preprints, vol. 2020030300, p. 2020, 2020.
[110] C. Butt, J. Gill, D. Chun, and B. A. Babu, “Deep learning system
to screen coronavirus disease 2019 pneumonia,” Applied Intelligence,
p. 1, 2020.

[111] I. D. Apostolopoulos, S. I. Aznaouridis, and M. A. Tzani, “Extracting
possibly representative covid-19 biomarkers from x-ray images with
deep learning approach and image data related to pulmonary diseases,”
Journal of Medical and Biological Engineering, p. 1, 2020.
[112] A. Waheed, M. Goyal, D. Gupta, A. Khanna, F. Al-Turjman, and P. R.
Pinheiro, “Covidgan: Data augmentation using auxiliary classifier gan
for improved covid-19 detection,” IEEE Access, vol. 8, pp. 91 916–
91 923, 2020.
[113] K. Elasnaoui and Y. Chawki, “Using x-ray images and deep learning for
automated detection of coronavirus disease,” Journal of Biomolecular
Structure and Dynamics, no. just-accepted, pp. 1–22, 2020.
[114] M. Loey, F. Smarandache, and N. E. M Khalifa, “Within the lack of
chest covid-19 x-ray dataset: A novel detection model based on gan
and deep transfer learning,” Symmetry, vol. 12, no. 4, p. 651, 2020.
[115] A. M. Hasan, M. M. AL-Jawad, H. A. Jalab, H. Shaiba, R. W. Ibrahim,
and A. R. AL-Shamasneh, “Classification of covid-19 coronavirus,
pneumonia and healthy lungs in ct scans using q-deformed entropy
and deep learning features,” Entropy, vol. 22, no. 5, p. 517, 2020.
[116] L. O. Hall, R. Paul, D. B. Goldgof, and G. M. Goldgof, “Finding covid19 from chest x-rays using deep learning on a small dataset,” arXiv
preprint arXiv:2004.02060, 2020.
[117] I. D. Apostolopoulos and T. A. Mpesiana, “Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional
neural networks,” Physical and Engineering Sciences in Medicine, p. 1,
2020.
[118] P. R. Bassi and R. Attux, “A deep convolutional neural network for covid-19 detection using chest x-rays,” arXiv preprint
arXiv:2005.01578, 2020.
[119] J. P. Cohen, L. Dao, P. Morrison, K. Roth, Y. Bengio, B. Shen,
A. Abbasi, M. Hoshmand-Kochi, M. Ghassemi, H. Li et al., “Predicting
covid-19 pneumonia severity on chest x-ray with deep learning,” arXiv
preprint arXiv:2005.11856, 2020.
[120] M. E. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir,
Z. B. Mahbub, K. R. Islam, M. S. Khan, A. Iqbal, N. Al-Emadi
et al., “Can ai help in screening viral and covid-19 pneumonia?” arXiv
preprint arXiv:2003.13145, 2020.
[121] M. Loey, G. Manogaran, and N. E. M. Khalifa, “A deep transfer
learning model with classical data augmentation and cgan to detect
covid-19 from chest ct radiography digital images,” 2020.
[122] M. Rahimzadeh and A. Attar, “A modified deep convolutional neural
network for detecting covid-19 and pneumonia from chest x-ray images
based on the concatenation of xception and resnet50v2,” Informatics
in Medicine Unlocked, p. 100360, 2020.
[123] N. Bansal and S. Sridhar, “Classification of x-ray images for detecting
covid-19 using deep transfer learning,” 2020.
[124] B. D. Goodwin, C. Jaskolski, C. Zhong, and H. Asmani, “Intra-model
variability in covid-19 classification using chest x-ray images,” arXiv
preprint arXiv:2005.02167, 2020.
[125] N. E. M. Khalifa, F. Smarandache, and M. Loey, “A study of the
neutrosophic set significance on deep transfer learning models: An
experimental case on a limited covid-19 chest x-ray dataset,” Preprints,
2020.
[126] S. H. Kassani, P. H. Kassasni, M. J. Wesolowski, K. A. Schneider,
and R. Deters, “Automatic detection of coronavirus disease (covid-19)
in x-ray and ct images: A machine learning-based approach,” arXiv
preprint arXiv:2004.10641, 2020.
[127] S. Vaid, R. Kalantar, and M. Bhandari, “Deep learning covid-19
detection bias: accuracy through artificial intelligence,” International
Orthopaedics, p. 1, 2020.
[128] J. Pu, J. Leader, A. Bandos, J. Shi, P. Du, J. Yu, B. Yang, S. Ke,
Y. Guo, J. B. Field et al., “Any unique image biomarkers associated
with covid-19?” European Radiology, p. 1, 2020.
[129] K. Yang, X. Liu, Y. Yang, X. Liao, R. Wang, X. Zeng, Y. Wang,
M. Zhang, and T. Zhang, “End-to-end covid-19 screening with 3d deep
learning on chest computed tomography,” 2020.
[130] Y. Pathak, P. K. Shukla, A. Tiwari, S. Stalin, S. Singh, and P. K.
Shukla, “Deep transfer learning based classification model for covid19 disease,” IRBM, 2020.
[131] H. Panwar, P. Gupta, M. K. Siddiqui, R. Morales-Menendez, and
V. Singh, “Application of deep learning for fast detection of covid19 in x-rays using ncovnet,” Chaos, Solitons & Fractals, p. 109944,
2020.
[132] M. A. Al-antari, C.-H. Hua, and S. Lee, “Fast deep learning computeraided diagnosis against the novel covid-19 pandemic from digital chest
x-ray images,” 2020.

19

[133] L. Brunese, F. Mercaldo, A. Reginelli, and A. Santone, “Explainable
deep learning for pulmonary disease and coronavirus covid-19 detection from x-rays,” Computer Methods and Programs in Biomedicine,
p. 105608, 2020.
[134] X. Li, C. Li, and D. Zhu, “Covid-mobilexpert: On-device covid19 screening using snapshots of chest x-ray,” arXiv preprint
arXiv:2004.03042, 2020.
[135] D. Singh, V. Kumar, and M. Kaur, “Classification of covid-19 patients
from chest ct images using multi-objective differential evolution–
based convolutional neural networks,” European Journal of Clinical
Microbiology & Infectious Diseases, pp. 1–11, 2020.
[136] T. Mahmud, M. A. Rahman, and S. A. Fattah, “Covxnet: A multidilation convolutional neural network for automatic covid-19 and other
pneumonia detection from chest x-ray images with transferable multireceptive feature optimization,” Computers in Biology and Medicine,
p. 103869, 2020.
[137] J. Song, H. Wang, Y. Liu, W. Wu, G. Dai, Z. Wu, P. Zhu, W. Zhang,
K. W. Yeom, and K. Deng, “End-to-end automatic differentiation of
the coronavirus disease 2019 (covid-19) from viral pneumonia based
on chest ct,” European journal of nuclear medicine and molecular
imaging, pp. 1–9, 2020.
[138] D. Das, K. Santosh, and U. Pal, “Truncated inception net: Covid19 outbreak screening using chest x-rays,” Physical and engineering
sciences in medicine, pp. 1–11, 2020.
[139] A. Saeedi, M. Saeedi, and A. Maghsoudi, “A novel and reliable deep
learning web-based tool to detect covid-19 infection form chest ctscan,” arXiv preprint arXiv:2006.14419, 2020.
[140] P. R. Bassi and R. Attux, “A deep convolutional neural network for covid-19 detection using chest x-rays,” arXiv preprint
arXiv:2005.01578, 2020.
[141] M. Siddhartha and A. Santra, “Covidlite: A depth-wise separable deep
neural network with white balance and clahe for detection of covid-19,”
arXiv preprint arXiv:2006.13873, 2020.
[142] S. Chatterjee, F. Saad, C. Sarasaen, S. Ghosh, R. Khatun, P. Radeva,
G. Rose, S. Stober, O. Speck, and A. Nürnberger, “Exploration of
interpretability techniques for deep covid-19 classification using chest
x-ray images,” arXiv preprint arXiv:2006.02570, 2020.
[143] P. G. Moutounet-Cartan, “Deep convolutional neural networks to
diagnose covid-19 and other pneumonia diseases from posteroanterior
chest x-rays,” arXiv preprint arXiv:2005.00845, 2020.
[144] H. Hirano, K. Koga, and K. Takemoto, “Vulnerability of deep neural
networks for detecting covid-19 cases from chest x-ray images to
universal adversarial attacks,” arXiv preprint arXiv:2005.11061, 2020.
[145] P. K. Sethy, S. K. Behera, P. K. Ratha, and P. Biswas, “Detection
of coronavirus disease (covid-19) based on deep features and support
vector machine.”
[146] A. Haghanifar, M. M. Majdabadi, and S. Ko, “Covid-cxnet: Detecting
covid-19 in frontal chest x-ray images using deep learning,” arXiv
preprint arXiv:2006.13807, 2020.
[147] G. Wang, X. Liu, C. Li, Z. Xu, J. Ruan, H. Zhu, T. Meng, K. Li,
N. Huang, and S. Zhang, “A noise-robust framework for automatic
segmentation of covid-19 pneumonia lesions from ct images,” IEEE
Transactions on Medical Imaging, 2020.
[148] O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning, H. Zhang,
W. Ji, A. Bernheim, and E. Siegel, “Rapid ai development cycle for the
coronavirus (covid-19) pandemic: Initial results for automated detection
& patient monitoring using deep learning ct image analysis,” arXiv
preprint arXiv:2003.05037, 2020.
[149] F. Shan, Y. Gao, J. Wang, W. Shi, N. Shi, M. Han, Z. Xue, and
Y. Shi, “Lung infection quantification of covid-19 in ct images with
deep learning,” arXiv preprint arXiv:2003.04655, 2020.
[150] J. Zhao, Y. Zhang, X. He, and P. Xie, “Covid-ct-dataset: a ct scan
dataset about covid-19,” arXiv preprint arXiv:2003.13865, 2020.
[151] M. Z. Alom, M. Rahman, M. S. Nasrin, T. M. Taha, and V. K.
Asari, “Covid mtnet: Covid-19 detection with multi-task deep learning
approaches,” arXiv preprint arXiv:2004.03747, 2020.
[152] X. Chen, L. Yao, and Y. Zhang, “Residual attention u-net for automated
multi-class segmentation of covid-19 chest ct images,” arXiv preprint
arXiv:2004.05645, 2020.
[153] O. Gozes, M. Frid-Adar, N. Sagie, H. Zhang, W. Ji, and H. Greenspan,
“Coronavirus detection and analysis on chest ct with deep learning,”
arXiv preprint arXiv:2004.02640, 2020.
[154] Y.-H. Wu, S.-H. Gao, J. Mei, J. Xu, D.-P. Fan, C.-W. Zhao, and M.M. Cheng, “Jcs: An explainable covid-19 diagnosis system by joint
classification and segmentation,” arXiv preprint arXiv:2004.07054,
2020.

[155] T. Zhou, S. Canu, and S. Ruan, “An automatic covid-19 ct segmentation based on u-net with attention mechanism,” arXiv preprint
arXiv:2004.06673, 2020.
[156] E. Tartaglione, C. A. Barbano, C. Berzovini, M. Calandri, and
M. Grangetto, “Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data,” arXiv preprint arXiv:2004.05405,
2020.
[157] W. Xie, C. Jacobs, J.-P. Charbonnier, and B. van Ginneken, “Relational
modeling for robust and efficient pulmonary lobe segmentation in ct
scans,” IEEE Transactions on Medical Imaging, 2020.
[158] Y. Oh, S. Park, and J. C. Ye, “Deep learning covid-19 features on
cxr using limited training data sets,” IEEE Transactions on Medical
Imaging, 2020.
[159] S. Hu, Y. Gao, Z. Niu, Y. Jiang, L. Li, X. Xiao, M. Wang, E. F. Fang,
W. Menpes-Smith, J. Xia et al., “Weakly supervised deep learning for
covid-19 infection detection and classification from ct images,” IEEE
Access, 2020.
[160] Y. Qiu, Y. Liu, and J. Xu, “Miniseg: An extremely minimum network
for efficient covid-19 segmentation,” arXiv preprint arXiv:2004.09750,
2020.
[161] S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio, and
S. K. Antani, “Iteratively pruned deep learning ensembles for covid-19
detection in chest x-rays,” arXiv preprint arXiv:2004.08379, 2020.
[162] D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, H. Fu, J. Shen, and
L. Shao, “Inf-net: Automatic covid-19 lung infection segmentation
from ct images,” IEEE Transactions on Medical Imaging, 2020.
[163] D. Lv, W. Qi, Y. Li, L. Sun, and Y. Wang, “A cascade network for detecting covid-19 using chest x-rays,” arXiv preprint arXiv:2005.01468,
2020.
[164] A. Voulodimos, E. Protopapadakis, I. Katsamenis, A. Doulamis, and
N. Doulamis, “Deep learning models for covid-19 infected area segmentation in ct images,” medRxiv, 2020.
[165] A. Amyar, R. Modzelewski, and S. Ruan, “Multi-task deep learning
based ct imaging analysis for covid-19: Classification and segmentation,” medRxiv, 2020.
[166] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and
X. Wang, “Deep learning-based detection for covid-19 from chest ct
using weak label,” medRxiv, 2020.
[167] S. Jin, B. Wang, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou, W. Ma,
Z. Xu, Z. Zheng et al., “Ai-assisted ct imaging analysis for covid-19
screening: Building and deploying a medical ai system in four weeks,”
medRxiv, 2020.
[168] J. Wang, Y. Bao, Y. Wen, H. Lu, H. Luo, Y. Xiang, X. Li, C. Liu,
and D. Qian, “Prior-attention residual learning for more discriminative
covid-19 screening in ct images,” IEEE Transactions on Medical
Imaging, 2020.
[169] S. Roy, W. Menapace, S. Oei, B. Luijten, E. Fini, C. Saltori, I. Huijben,
N. Chennakeshava, F. Mento, A. Sentelli et al., “Deep learning for
classification and localization of covid-19 markers in point-of-care lung
ultrasound,” IEEE Transactions on Medical Imaging, 2020.
[170] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu,
Z. Fang, Q. Song et al., “Artificial intelligence distinguishes covid19 from community acquired pneumonia on chest ct,” Radiology, p.
200905, 2020.
[171] S. Wang, Y. Zha, W. Li, Q. Wu, X. Li, M. Niu, M. Wang, X. Qiu,
H. Li, H. Yu et al., “A fully automatic deep learning system for covid19 diagnostic and prognostic analysis,” European Respiratory Journal,
2020.
[172] C. Butt, J. Gill, D. Chun, and B. A. Babu, “Deep learning system
to screen coronavirus disease 2019 pneumonia,” Applied Intelligence,
p. 1, 2020.
[173] W. Wu, Y. Shi, X. Li, Y. Zhou, P. Du, S. Lv, T. Liang, and J. Sheng,
“Deep learning to estimate the physical proportion of infected region
of lung for covid-19 pneumonia with ct image set,” arXiv preprint
arXiv:2006.05018, 2020.
[174] S. Chaganti, A. Balachandran, G. Chabin, S. Cohen, T. Flohr,
B. Georgescu, P. Grenier, S. Grbic, S. Liu, F. Mellot et al., “Quantification of tomographic patterns associated with covid-19 from chest
ct,” arXiv preprint arXiv:2004.01279, 2020.
[175] Z. Han, B. Wei, Y. Hong, T. Li, J. Cong, X. Zhu, H. Wei, and W. Zhang,
“Accurate screening of covid-19 using attention based deep 3d multiple
instance learning,” IEEE Transactions on Medical Imaging, 2020.
[176] M. Goncharov, M. Pisov, A. Shevtsov, B. Shirokikh, A. Kurmukov,
I. Blokhin, V. Chernina, A. Solovev, V. Gombolevskiy, S. Morozov et al., “Ct-based covid-19 triage: Deep multitask learning improves joint identification and severity quantification,” arXiv preprint
arXiv:2006.01441, 2020.

20

[177] V. K. R. Chimmula and L. Zhang, “Time series forecasting of covid19 transmission in canada using lstm networks,” Chaos, Solitons &
Fractals, p. 109864, 2020.
[178] C.-J. Huang and P.-H. Kuo, “Multiple-input deep convolutional neural
network model for short-term photovoltaic power forecasting,” IEEE
Access, vol. 7, pp. 74 822–74 834, 2019.
[179] S. M. Ayyoubzadeh, S. M. Ayyoubzadeh, H. Zahedi, M. Ahmadi, and
S. R. N. Kalhori, “Predicting covid-19 incidence through analysis of
google trends data in iran: data mining and deep learning pilot study,”
JMIR Public Health and Surveillance, vol. 6, no. 2, p. e18828, 2020.
[180] A. Tomar and N. Gupta, “Prediction for the spread of covid-19 in
india and effectiveness of preventive measures,” Science of The Total
Environment, p. 138762, 2020.
[181] N. B. Yahia, M. D. Kandara, and N. B. B. Saoud, “Deep ensemble
learning method to forecast covid-19 outbreak,” 2020.
[182] Z. Hu, Q. Ge, L. Jin, and M. Xiong, “Artificial intelligence forecasting
of covid-19 in china,” arXiv preprint arXiv:2002.07112, 2020.
[183] M. Azarafza, M. Azarafza, and J. Tanha, “Covid-19 infection forecasting based on deep learning in iran,” medRxiv, 2020.
[184] R. Pal, A. A. Sekh, S. Kar, and D. K. Prasad, “Neural network
based country wise risk prediction of covid-19,” arXiv preprint
arXiv:2004.00959, 2020.
[185] L. R. Kolozsvari, T. Berczes, A. Hajdu, R. Gesztelyi, A. TIba, I. Varga,
G. J. Szollosi, S. Harsanyi, S. Garboczy, and J. Zsuga, “Predicting the
epidemic curve of the coronavirus (sars-cov-2) disease (covid-19) using
artificial intelligence,” medRxiv, 2020.
[186] B. Yan, X. Tang, B. Liu, J. Wang, Y. Zhou, G. Zheng, Q. Zou,
Y. Lu, and W. Tu, “An improved method of covid-19 case fitting and
prediction based on lstm,” arXiv preprint arXiv:2005.03446, 2020.
[187] M. R. Ibrahim, J. Haworth, A. Lipani, N. Aslam, T. Cheng, and
N. Christie, “Variational-lstm autoencoder to forecast the spread of
coronavirus across the globe,” medRxiv, 2020.
[188] P. Arora, H. Kumar, and B. K. Panigrahi, “Prediction and analysis of
covid-19 positive cases using deep learning models: A descriptive case
study of india,” Chaos, Solitons & Fractals, p. 110017, 2020.
[189] K. Munir, H. Elahi, A. Ayub, F. Frezza, and A. Rizzi, “Cancer diagnosis
using deep learning: a bibliographic review,” Cancers, vol. 11, no. 9,
p. 1235, 2019.

