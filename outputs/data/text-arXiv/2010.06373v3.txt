Generalized Rescaled PoÃÅlya urn and its statistical applications
Giacomo Aletti

‚àó

and

Irene Crimaldi

‚Ä†

March 8, 2021

arXiv:2010.06373v3 [math.ST] 5 Mar 2021

Abstract
We introduce the Generalized Rescaled PoÃÅlya (GRP) urn, that provides a generative model for a chisquared test of goodness of fit for the long-term probabilities of clustered data, with independence between
clusters and correlation, due to a reinforcement mechanism, inside each cluster. We apply the proposed test
to a data set of Twitter posts about COVID-19 pandemic: in a few words, for a classical chi-squared test
the data result strongly significant for the rejection of the null hypothesis (the daily long-run sentiment rate
remains constant), but, taking into account the correlation among data, the introduced test leads to a different conclusion. Beside the statistical application, we point out that the GRP urn is a simple variant of the
standard Eggenberger-PoÃÅlya urn, that, with suitable choices of the parameters, shows ‚Äúlocal‚Äù reinforcement,
almost sure convergence of the empirical mean to a deterministic limit and different asymptotic behaviours
of the predictive mean. Moreover, the study of this model provides the opportunity to analyze stochastic
approximation dynamics, that are unusual in the related literature.
Keywords: central limit theorem, chi-squared test, PoÃÅlya urn, preferential attachment, reinforcement learning, reinforced stochastic process, stochastic approximation, urn model.
MSC2010 Classification: 60F05, 60F15, 62F03, Secondary 62F05, 62L20.

Contents
Page
1 Introduction

2

2 The Generalized Rescaled PoÃÅlya (GRP) urn

3

3 Related literature

5

4 Main theorem: goodness of fit result

6

5 Statistical applications
5.1 Estimation of the parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7
8

6 COVID-19 epidemic Twitter analysis

10

7 Asymptotic results for the empirical means

13

8 Proof of Theorem 7.2

13

References

17

‚àó ADAMSS
‚Ä† IMT

Center, UniversitaÃÄ degli Studi di Milano, Milan, Italy, giacomo.aletti@unimi.it
School for Advanced Studies, Lucca, Italy, irene.crimaldi@imtlucca.it

1

Page
SM Supplemental Materials

S1

S1 Proofs and intermediate results
S1
S1.1 Proof of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 1
S1.2 A preliminary central limit theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 2
S1.3 Proof of Proposition 7.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . S 2
S2 Case

P

n n

< +‚àû

S3

S3 Computations regarding the local
S3.1 Case Œ± = Œ≤ ‚àà (0, 1) . . . . . . . .
S3.2 Case Œ± = Œ≤ = 1 . . . . . . . . . .
S3.3 Case 0 < Œ± < Œ≤ < (1 + Œ±)/2 . . .

reinforcement
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

S4 Technical results

S6
S7
S7
S8
S9

S5 Some stochastic approximation results

S 10

S6 Stable convergence

S 12

SR References

S 13

1

Introduction

The standard Eggenberger-PoÃÅlya urn (see EggPol23,mah) has been widely studied and generalized (for
instance, some recent variants can be found in [7, 8, 11, 15, 18, 33, 34, 35]). In its simplest form, this model
with k-colors works as follows. An urn contains N0 i balls of color i, for i = 1, . . . , k, and, at each discrete
time, a ball is extracted from the urn and then it is returned inside the urn together with Œ± > 0 additional
balls of the same color. Therefore, if we denote by Nn i the number of balls of color i in the urn at time n,
we have
Nn i = Nn‚àí1 i + Œ±Œæn i
for n ‚â• 1,
where Œæn i = 1 if the extracted ball at time n is of color i, and Œæn i = 0 otherwise. TheP
parameter Œ± regulates
the reinforcement mechanism: the greater Œ±, the greater the dependence of Nn i on n
h=1 Œæh i .
The Generalized Rescaled PoÃÅlya (GRP) urn model is characterized by the introduction of the sequence
(Œ≤n )n of parameters, together with the replacement of the parameter Œ± of the original model by a sequence
(Œ±n )n , so that
Nn i = b0 i + Bn i
with
Bn+1 i = Œ≤n Bn i + Œ±n+1 Œæn+1 i

n ‚â• 0.

Therefore, the urn initially contains b0 i +B0 i balls of color i and the parameters Œ≤n ‚â• 0, together with Œ±n > 0,
regulate the reinforcement mechanism. More precisely, the term Œ≤n Bn i links Nn+1 i to the ‚Äúconfiguration‚Äù
at time n through the ‚Äúscaling‚Äù parameter Œ≤n , and the term Œ±n+1 Œæn+1 i links Nn+1 i to the outcome of the
extraction at time n + 1 through the parameter Œ±n+1 .
We are going to show that, with a suitable
choice of the model parameters, we have a long-term
almost
P
Pn
sure convergence of the empirical mean N
n=1 Œæn i /N to the deterministic limit p0 i = b0 i /
i=1 b0 i , and a
chi-squared goodness of fit result for the long-term probabilities {p0 1 , . . . , p0 k }. In particular, regarding the
last point, we have that the chi-squared statistics
œá2 = N

k
k
X
X
(Oi ‚àí N p0 i )2
(b
p i ‚àí p 0 i )2
=
,
p
N p0 i
0i
i=1
i=1

(1.1)

PN
where N is the size of the sample, pbi = Oi /N , with Oi =
n=1 Œæn i the number of observations equal
2
to i in the sample, is asymptotically distributed as œá (k ‚àí 1)Œª, with Œª > 1, or œá2 (k ‚àí 1)N 1‚àí2e Œª, where
Œª > 0 may be smaller than 1, but e is always strictly smaller than 1/2. In both cases, the presence of

2

correlation among units mitigates the effect in (1.1) of the sample size N , that multiplies the chi-squared
distance between the observed frequencies and the expected probabilities. This aspect is important for the
statistical applications in the context of a ‚Äúbig sample‚Äù, when a small value of the chi-squared distance
might be significant, and hence a correction related to the correlation between observations is desirable (see,
for instance, [9, 12, 14, 26, 27, 31, 38, 42, 43, 45]). More precisely, in the first case, the observed value of
the chi-squared distance has to be compared with the ‚Äúcritical‚Äù value œá21‚àíŒ∏ (k ‚àí 1)Œª/N , where œá21‚àíŒ∏ (k ‚àí 1)
denotes the quantile of order 1 ‚àí Œ∏ of the chi-squared distribution œá2 (k ‚àí 1). In the second case, the critical
value for the chi-squared distance becomes œá21‚àíŒ∏ (k ‚àí1)Œª/N 2e , where, although the constant Œª may be smaller
than 1, the effect of the sample size N is mitigated by the exponent 2e < 1. In other words, for this second
case, the Fisher information given by the sample does not scale with the sample size N , but with rate N 2e .
Hence, since the long-term correlation, collecting more and more data does not provide a linear increment
of the information.
Summing up, the GRP urn provides a theoretical framework for a chi-squared test of goodness of fit for the
long-term probabilities of correlated data, generated according to a reinforcement mechanism. Specifically,
we describe a possible application in the context of clustered data, with independence between clusters and
correlation, due to a reinforcement mechanism, inside each cluster. In particular, we develop a suitable
estimation technique for the fundamental model parameters. We then apply the proposed test to a data set
of Twitter posts about COVID-19 pandemic. Given the null hypothesis that the daily long-run sentiment
rate of the posts is the same for all the considered days (suitably spaced days in the period February 20th April 20th 2020), performing a classical œá2 test, the data result strongly significant for the rejection of the
null hypothesis, while, taking into account the correlation among posts sent in the same day, the proposed
test leads to a different conclusion.
The sequel of the paper is so structured. In Section 2 we set up the notation and we define the GRP
urn. In Section 3 we illustrate its relationships with previous models and we discuss the connections with
related literature. In particular, the object of the present work gives us the opportunity to study Stochastic
Approximation (SA) dynamics, which are infrequent in SA literature and so fill in some theoretical gaps.
In Section 4 we provide the main result of this work, that is the almost sure convergence of the empirical
means to the deterministic limits p0 i and the goodness of fit result for the long-term probabilities p0 i ,
together with comments and examples. In Section 5 we describe a possible statistical application of the
GRP urn and the related results: a chi-squared test of goodness of fit for the long-term probabilities of
clustered data, with independence between clusters and correlation, due to a reinforcement mechanism,
inside each cluster. We apply the proposed test to a data set of Twitter posts about COVID-19 pandemic.
In Section 7 we state two convergence results for the empirical means, which are the basis for the proof of the
main theorem. All the shown theoretical results are analytically proven. The proofs are left to Section S1
in the Supplementary Material [2], except for the proof of Theorem 7.2, which is methodologically new
and emphasizes new techniques of martingale limit theory and so it is illustrated in Section 8. Finally, in
the Supplementary Material we also provide some complements, some technical lemmas and some recalls
about stochastic approximation theory and about stable convergence. When necessary, the references to the
Supplementary Material are preceded by an ‚ÄúS‚Äù, so that (S1.2) will refer to the equation (S1.2) in [2].

2

The Generalized Rescaled PoÃÅlya (GRP) urn

In all the sequel, we suppose given two sequences of parametersP
(Œ±n )n‚â•1 , with Œ±n > 0 and (Œ≤nP
)n‚â•0 with
Œ≤n ‚â• 0. Given a vector x = (x1 , . . . , xk )> ‚àà Rk , we set |x| = ki=1 |xi | and kxk2 = x> x = ki=1 |xi |2 .
Moreover we denote by 1 and 0 the vectors with all the components equal to 1 and equal to 0, respectively.
The urn initially contains b0 i + B0 i > 0 distinct balls of color i, with i = 1, . . . , k. We set b0 =
(b0 1 , . . . , b0 k )> and B0 = (B0 1 , . . . , B0 k )> . We assume |b0 | > 0 and we set p0 = |bb00 | . At each discrete time
(n+1) ‚â• 1, a ball is drawn at random from the urn, obtaining the random vector Œæn+1 = (Œæn+1 1 , . . . , Œæn+1 k )>
defined as
(
1 when the extracted ball at time n + 1 is of color i
Œæn+1 i =
0 otherwise,
and the number of balls in the urn is so updated:
Nn+1 = b0 + Bn+1

with

Bn+1 = Œ≤n Bn + Œ±n+1 Œæn+1 ,

3

(2.1)

which gives (since |Œæn+1 | = 1)
|Bn+1 | = Œ≤n |Bn | + Œ±n+1 .
Therefore, setting

rn‚àó

= |Nn | = |b0 | + |Bn |, we get
‚àó
rn+1
= rn‚àó + (Œ≤n ‚àí 1)|Bn | + Œ±n+1 ,

(2.2)

‚àó
rn+1
‚àí rn‚àó = |b0 |(1 ‚àí Œ≤n ) ‚àí rn‚àó (1 ‚àí Œ≤n ) + Œ±n+1 .

(2.3)

that is
Moreover, setting F0 equal to the trivial œÉ-field and Fn = œÉ(Œæ1 , . . . , Œæn ) for n ‚â• 1, the conditional probabilities œàn = (œàn 1 , . . . , œàn k )> of the extraction process, also called predictive means, are
œàn = E[Œæn+1 |Fn ] =

Nn
b0 + Bn
=
|Nn |
rn‚àó

n ‚â• 0.

(2.4)

It is obvious that we have |œàn | = 1. Moreover, when Œ≤n > 0 for all n, the probability œàn i results increasing
with the number of times we observed the value i, that is the random variables Œæn i are generated according to
a reinforcement mechanism: the probability that the extraction of color i occurs has an increasing dependence
on the number of extractions of color i occurred in the past (see, e.g. [41]). More precisely, we have
Pn  Qn‚àí1 
Q
b0 + B0 n‚àí1
j=h Œ≤j Œæh
h=1 Œ±h
j=0 Œ≤j +
(2.5)
œàn =
Pn  Qn‚àí1  .
Qn‚àí1
|b0 | + |B0 | j=0 Œ≤j + h=1 Œ±h j=h Œ≤j
Q
The dependence of œàn on Œæh depends on the factor f (h, n) = Œ±h n‚àí1
j=h Œ≤j , with 1 ‚â§ h ‚â§ n, n ‚â• 0. In
the case of the standard Eggenberger-PoÃÅlya urn, that corresponds to Œ±n = Œ± > 0 and Œ≤n = 1 for all n,
each observation Œæh has the same ‚Äúweight‚Äù f (h, n) = Œ±. Instead, if the factor f (h, n) increases with h,
then the main contribution is given by the most recent extractions. We refer to this phenomenon as ‚Äúlocal‚Äù
reinforcement. For instance, this is the case when (Œ±n ) is increasing and Œ≤n = 1 for all n. Another case is
when Œ±n = Œ± > 0 and Œ≤n < 1 for all n. The case Œ≤n = 0 for
Q all n is an extreme case, for which œàn depends
only on the last extraction Œæn (recall that conventionally n‚àí1
j=n = 1). For the next examples, we will show
that they exhibit a broader sense local reinforcement, in the sense that the ‚Äúweight‚Äù of the observations is
eventually increasing with time.
By means of (2.4), together with (2.1) and (2.2), we have
œàn+1 ‚àí œàn = ‚àí

 Œ±n+1

(1 ‚àí Œ≤n )
|b0 | œàn ‚àí p0 + ‚àó
Œæn+1 ‚àí œàn .
‚àó
rn+1
rn+1

(2.6)

n)
and
Setting Œ∏n = œàn ‚àí p0 and ‚àÜMn+1 = Œæn+1 ‚àí œàn = Œæn+1 ‚àí p0 ‚àí Œ∏n and letting n = |b0 | (1‚àíŒ≤
r‚àó
n+1

‚àó
Œ¥n = Œ±n+1 /rn+1
, from (2.6) we obtain

œàn+1 ‚àí œàn = ‚àín (œàn ‚àí p0 ) + Œ¥n ‚àÜMn+1

(2.7)

Œ∏n+1 ‚àí Œ∏n = ‚àín Œ∏n + Œ¥n ‚àÜMn+1 .

(2.8)

and so
Therefore, the asymptotic behaviour of (Œ∏nP
) depends on the two sequences (n )n and (Œ¥n )n .
Finally, we observe that, setting ŒæN = N
n=1 Œæn /N and ¬µn = Œæ n ‚àí p0 , we have the equality
1
1
¬µn+1 ‚àí ¬µn = ‚àí (¬µn ‚àí Œ∏n ) + ‚àÜMn+1 ,
n
n

(2.9)

that links the asymptotic behaviour of (¬µn ) and the one of (Œ∏n ).
Different kinds of sequences (n )n and (Œ¥n )n provide different kinds of asymptotic behaviour of Œ∏n , i.e. of
the empirical mean ŒæN . In Section 4, we P
provide two cases in which we have a long-term almost sure
convergence of the empirical mean Oi /N = N
n=1 Œæn i /N toward the constant p0i = b0 i /|b0 |, together with
a chi-squared goodness of fit result. In particular, the quantities p0 1 , . . . , p0 k can be seen as a long-run
probability distribution on the possible values (colors) {1, . . . , k}.

4

3

Related literature

The particular case when in the GRP urn model we have Œ≤n = Œ≤ = 0 for all n corresponds to a version of
the so-called ‚Äúmemory-1 senile reinforced random walk‚Äù on a star-shaped graph introduced in [29]. The case
Œ±n = Œ± > 0 and Œ≤n = Œ≤ = 1 for all n corresponds to the standard Eggenberger-PoÃÅlya urn with an initial
number N0 i = b0 i + B0 i of balls of color i. When (Œ±n ) is a not-constant sequence, while Œ≤n = Œ≤ = 1 for
all n, the GRP urn coincides with the variant of the Eggenberger-PoÃÅlya urn introduced in [40] (see also [41,
Sec. 3.2]). Instead, when Œ≤ 6= 1, the GRP urn does not fall in any variants of the Eggenberger-PoÃÅlya urn
discussed in [41, Sec. 3.2].
The case when Œ±n = Œ± > 0 and Œ≤n = Œ≤ ‚â• 0 for all n corresponds to the Rescaled PoÃÅlya (RP) urn
introduced and studied in [1] and applied in [6]. It is worthwhile to point out that the two cases studied in
the present work do not include (and are not included in) the case studied in [1]. Moreover, the techniques
employed here and in [1] are completely different: when Œ≤n = Œ≤ ‚àà [0, 1) as in [1], the jumps ‚àÜœàn do not
vanish and the process œà = (œàn )n converges to a stationary Markov chain and so the appropriate Markov
ergodic theory is employed; in this work, we have |‚àÜœàn | = o(1), so that the martingale limit theory is here
exploited to achieve the asymptotic results. Obviously, the two techniques are not exchangeable or adaptable
from one contest to the other one.
When (Œ≤n ) is not identically equal to 1, since the first term in the right hand of the above relation, the
GRP urn does not belong to the class of Reinforced Stochastic Processes (RSPs) studied in [3, 5, 4, 20, 21, 23].
Indeed, the RSPs are characterized by a ‚Äústrict‚Äù reinforcement mechanism such that Œæn i = 1 implies œàn i >
œàn‚àí1 i and so, as a consequence, œàn i has an increasing dependence on the number of times we have Œæh i = 1
for h = 1, . . . , n. When (Œ≤n ) is not identically equal to 1, the GRP urn does not satisfy the ‚Äústrict‚Äù
reinforcement mechanism, because the first term is positive or negative according to the sign of (1 ‚àí Œ≤n ) and
of (œàn ‚àí p0 ). Furthermore, we observe that equation (2.6) recalls the dynamics of a RSP with a ‚Äúforcing
input‚Äù (see [3, 20, 44]), but the main difference relies on the fact that such a process is driven by a classical
stochastic
P approximationPdynamics, that is a dynamics of the kind (2.7) with n = Œ¥n (up to a constant)
with n n = +‚àû and n 2n < +‚àû, while the GRP urn model also allows for n and Œ¥n with different
rates and also for
P
P 2
‚Ä¢
n n = +‚àû and
n Œ¥n = +‚àû or
P
‚Ä¢
n n < +‚àû.
Since (2.7) is the fundamental equation of the Stochastic Approximation (SA) theory, we deem it appropriate
to say a few more words on the relationship of the present work with the SA literature. The case when
Œ¥n = cn in (2.7) is essentially covered by the Stochastic Approximation
S5, where
P (SA) theory (see
P Section
2
we refer to [25,
32,
37,
39,
48]).
The
most
known
case
is
when


<
+‚àû.
The
n = +‚àû and
n
n
n
P 2
P

=
+‚àû
is
less
usual
in
literature,
but
it
is
well
characterized
in

=
+‚àû
and
case n ‚Üí 0,
n
n n
n
[32]. The case when (n )n and (Œ¥n )n in (2.7) go to zero with different rates is typically neglected in SA
literature. To our best knowledge, it is taken into consideration only in [39], where the weak convergence
rate of the sequence (œàN ) toward a certain point œà ‚àó is established under suitable assumptions, given the
event {œàN ‚Üí œà ‚àó }. No result is given for the empirical mean ŒæN , which instead is the focus of the present
paper (see Theorem 4.1 below, whose proof is based on Theorem 7.2). More precisely, the assumptions on
n and Œ¥n in the following Theorem 7.2 imply assumption (A1.3) in [39] and so Theorem 1 in that paper
provides the weak convergence rate of the sequence (œàN ‚àí œà ‚àó ) given the event {œàN ‚Üí œà ‚àó }. However, this
result is not useful for our scope because of two reasons: first, we need convergence results for the empirical
mean ŒæN , not for the predictive mean œàN ; second, in one case included in Theorem 7.2 (see Section 7 for
more details), it seems to us not immediate to check the convergence of the predictive means and so we
develop another technique that does not ask for this convergence (see Section 8). Hence, the contribution
of Theorem 7.2 to the SA literature is that, for a dynamics of the type (2.7) with (n )n and (Œ¥n )n going to
zero with
P different rates,Pit provides the asymptotic behaviour of the empirical mean ŒæN , covering a case
when n n = +‚àû and n Œ¥n2 = +‚àû and without requiring the convergence ofPthe empirical means œàN .
Finally, it is worthwhile to point out that we also analyze the case when n n < +‚àû, which is also
excluded in SA literature and so it could be relevant in that field. Specifically, we prove almost sure
convergence of the predictive means and of the empirical means toward a random variable and we give a
central limit theorem in the sense of stable convergence. However, even if interesting from a theoretical
point of view, we collect these results in Section S2, because they are not related to the chi-squared test of
goodness of fit.
The following statistical application of the GRP urn was inspired by [1, 12, 36]. However, those papers

5

only deal with the case when the statistics (1.1) is asymptotically distributed as œá2 (k ‚àí 1)Œª, with Œª > 1,
while we also face the case when the statistics (1.1) is asymptotically distributed as œá2 (k ‚àí 1)N 1‚àí2e Œª,
illustrating a suitable estimation procedure for the fundamental parameters Œ∑ = 1 ‚àí 2e and Œª. To the best
of our knowledge, this is the first work presenting a model that provides a theoretical framework for a such
chi-squared test of goodness of fit.

4

Main theorem: goodness of fit result

Given a sample (Œæ1 , . . . , ŒæN ) generated by a GRP urn, the statistics
N
X

Oi = #{n = 1, . . . , N : Œæn i = 1} =

Œæn i ,

i = 1, . . . , k,

n=1

counts the number of times we observed the value i. The theorem below
states, under suitable assumptions,
P
the almost sure convergence of the empirical mean pbi = Oi /N = N
n=1 Œæn i /N toward the probability p0 i ,
together with a chi-squared goodness of fit test for the long-term probabilities p0 1 , . . . , p0 k . More precisely,
we prove the following result:
Theorem 4.1. Assume p0 i > 0 for all i = 1, . . . , k and suppose to be in one of the following cases:
a) n = (n + 1)‚àí and Œ¥n = cn , with  ‚àà (0, 1] and c > 0, or
b) n = (n + 1)‚àí , Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with  ‚àà (0, 1), Œ¥ ‚àà (/2, ) and c > 0.
Define the constants e and Œª as
(
1/2
e=
1/2 ‚àí ( ‚àí Œ¥) < 1/2

in case a)
in case b)

and
Ô£±
2
Ô£¥
Ô£≤(c + 1)
Œª = (c + 1)2 + c2 = [2c(c + 1) + 1]
Ô£¥
Ô£≥ c2
1+2(‚àíŒ¥)

in case a) with  ‚àà (0, 1) ,
in case a) with  = 1 ,
in case b) .

(4.1)

a.s.

Then pbi = Oi /N ‚àí‚Üí p0 i and
1
N 1‚àí2e

k
k
X
X
(Oi ‚àí N p0 i )2
(b
p i ‚àí p 0 i )2 d
‚àí‚Üí W‚àó = ŒªW0
= N 2e
N ‚Üí‚àû
N p0 i
p0 i
i=1
i=1

where W0 has distribution œá2 (k ‚àí 1) = Œì

k‚àí1 1
, 2)
2

and, consequently, W‚àó has distribution Œì

k‚àí1 1
, 2Œª
2


.

We note that Œª is a constant greater than 1 in case a); while, in case b), it is a strictly positive quantity.
Moreover, in case b), we have 0 < ( ‚àí Œ¥) < /2 < 1/2 and so (1 ‚àí 2e) = 2( ‚àí Œ¥) ‚àà (0, 1). As a consequence,
we have N 1‚àí2e Œª > 1 for N large enough.
In the next two examples we show that it is possible to construct suitable sequences (Œ±n )n and (Œ≤n )n
of the model such that the corresponding sequences (n )n and (Œ¥n ) converge to zero with the same rate or
with different rates and satisfy the assumptions a) or b) of the above theorem, respectively.
Example 4.2. (Case n = (n + 1)‚àí and Œ¥n = cn , with  > 0 and c > 0 )
Take Œ±n+1 = c|b0 |(1 ‚àí Œ≤n ), with Œ≤n ‚àà [0, 1) and c > 0, that implies Œ¥n =

Œ±n+1
‚àó
rn+1

n)
= c |b0r|(1‚àíŒ≤
= cn . Set
‚àó

rn‚àó = (1 + c)|b0 |(1 ‚àí tn ) so that from (2.3) we obtain tn+1 = Œ≤n tn . Hence, we have
tn+1 = t0

n
Y
k=0

Œ≤k =

n
c|b0 | ‚àí |B0 | Y
Œ≤k
(1 + c)|b0 |
k=0

and so
‚àó
rn+1
= (1 + c)|b0 | + |B0 | ‚àí c|b0 |

n
Y
k=0

6

Œ≤k .

n+1

Q
‚àó
‚àó
‚àó
Therefore, setting Œ≤ ‚àó = ‚àû
k=0 Œ≤k ‚àà [0, 1), we get rn ‚àí‚Üí r = (1 + c)|b0 | + (|B0 | ‚àí c|b0 |)Œ≤ > 0. If we choose
‚àó
|B0 | = c|b0 |, then rn = r‚àó = (1 + c)|b0 | for each n and so, setting Œ≤n = 1 ‚àí (1 + c)(1 + n)‚àí with  > 0,
we obtain n = (1 + n)‚àí and Œ¥n = cn . Taking  ‚àà (0, 1], we have that n and Œ¥n satisfy assumption a)
of Theorem 4.1. Moreover, we have Q
Œ±n = c|b0 |(1 + c)n‚àí and 1 ‚àí Œ≤n = (1 + c)(1 + n)‚àí and so, for the
n‚àí1
Œ≤j in (2.5), we refer to Section S3.
behaviour of the factor f (h, n) = Œ±h j=h
Example 4.3. (Case n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with 0 < Œ¥ <  < 1 and c > 0)
Take 0 < Œ¥ <  < 1 and set Œ≥ =  ‚àí Œ¥ > 0, rn‚àó = nŒ≥ and (1 ‚àí Œ≤n ) = |b0 |‚àí1 (1 + n)‚àíŒ¥ . We immediately have
n = |b0 |

(1 ‚àí Œ≤n )
= (1 + n)‚àíŒ¥‚àíŒ≥ = (n + 1)‚àí
‚àó
rn+1

and (2.3) yields Œ±n+1 = (n + 1)Œ≥ ‚àí nŒ≥ [1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ] ‚àí (1 + n)‚àíŒ¥ , so that


Œ±n+1
Œ±n+1
1 Œ≥ 
Œ¥n = ‚àó
=
=
1
‚àí
1
‚àí
1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ‚àí (1 + n)‚àíŒ¥‚àíŒ≥
rn+1
(n + 1)Œ≥
n+1



= 1 ‚àí 1 ‚àí Œ≥(n + 1)‚àí1 + O(n‚àí2 ) 1 ‚àí |b0 |‚àí1 (1 + n)‚àíŒ¥ ‚àí (1 + n)‚àí


= |b0 |‚àí1 (1 + n)‚àíŒ¥ 1 + Œ≥|b0 |(n + 1)‚àí1+Œ¥ ‚àí |b0 |(1 + n)‚àí+Œ¥ ‚àí Œ≥(n + 1)‚àí1 + O(n‚àí2+Œ¥ ) .
Setting c = |b0 |‚àí1 > 0, we obtain n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ . Taking Œ¥ ‚àà (/2, ), we have
that n and Œ¥n satisfy assumption b) of Theorem 4.1. Moreover, we have Œ±n = cn‚àí(2Œ¥‚àí) (1 + Œ≥c‚àí1 n‚àí1+Œ¥ ‚àí
c‚àí1 n‚àí+Œ¥ ‚àí Œ≥n‚àí1 + O(n‚àí2+Œ¥ )) and (1 ‚àí Œ≤
) = c(1 + n)‚àíŒ¥ , with 0 < 2Œ¥ ‚àí  < Œ¥ < (1 + 2Œ¥ ‚àí )/2, and so, for
Qnn‚àí1
the behaviour of the factor f (h, n) = Œ±h j=h Œ≤j in (2.5), we refer to Section S3.

5

Statistical applications

In a big sample the units typically can not be assumed independent and identically distributed, but they
exhibit a structure in clusters, with independence between clusters and with correlation inside each cluster
[12, 17, 30, 36, 46, 47]. The model and the related results presented in [1] and in the present paper may
be useful in the situation when inside each cluster the probability that a certain unit chooses the value i is
affected by the number of units in the same cluster that have already chosen the value i, hence according to
a reinforcement rule. Formally, given a ‚Äúbig‚Äù sample {Œæn : n = 1, . . . , N }, we suppose that the N units are
ordered so that we have the following L clusters of units:
( `‚àí1
)
`
X
X
C` =
Nl + 1, . . . ,
Nl ,
` = 1, . . . , L.
l=1

l=1

Therefore, the cardinality of each cluster C` is N` . We assume that the units in different clusters are
independent, that is
[Œæ1 , . . . , ŒæN1 ], . . . , [ŒæP`‚àí1 N
l=1

l +1

, . . . , ŒæP`

l=1

Nl ],

. . . , [ŒæPL‚àí1 N
l=1

l +1

, . . . , ŒæN ]

are L independent multidimensional random variables. Moreover, we assume that the observations inside
each cluster can be modelled as a GRP satisfying case a) or case b) of Theorem 4.1. Given certain (strictly
positive) intrinsic probabilities p‚àó0 1 (`), . . . , p‚àó0 k (`) for each cluster C` , we firstly want to estimate the model
parameters and then perform a test with null hypothesis
H0 :

p0 i (`) = p‚àó0 i (`)

‚àÄi = 1, . . . , k

based on the the statistics
Q` =

1
2(‚àíŒ¥)

N`

k
X
Oi (`) ‚àí N` p‚àó0 i (`)
N` p‚àó0 i (`)
i=1

2
,

with Oi (`) = #{n ‚àà C` : Œæn i = 1},

(5.1)


1
and its corresponding asymptotic distribution Œì k‚àí1
, 2Œª
, where Œª is given in (4.1). Note that we can
2
perform the
above
test
for
a
certain
cluster
`,
or
we
can
consider
all the clusters together using the aggregate
P
L(k‚àí1) 1
statistics L
, 2Œª ).
`=1 Q` and its corresponding distribution Œì(
2
Regarding the probabilities p‚àó0 i (`), some possibilities are:

7

‚Ä¢ we can take p‚àó0 i (`) = 1/k for all i = 1, . . . , k if we want to test possible differences in the probabilities
for the k different values;
(1)

‚Ä¢ we can suppose to have two different periods of times, and so two samples, say {Œæn : n = 1, . . . , N }
P
(2)
(1)
and {Œæn : n = 1, . . . , N }, take p‚àó0 i (`) = n‚ààC` Œæn i /N` for all i = 1, . . . , k, and perform the test on
the second sample in order to check possible changes in the intrinsic long-run probabilities;
P
‚Ä¢ we can take one of the clusters as benchmark, say `‚àó , set p‚àó0 i (`) = n‚ààC`‚àó Œæn i /N`‚àó for all i = 1, . . . , k
and ` 6= `‚àó , and perform the test for the other L ‚àí 1 clusters in order to check differences with the
benchmark cluster `‚àó .
P
Finally, if we want to test possible differences in the clusters, then we can take p‚àó0 i (`) = p‚àó0 i = N
n=1 Œæn i /N
PL
for all ` = 1, . . . , L and perform the test using the aggregate statistics `=1 Q` with asymptotic distribution
1
, 2Œª
).
Œì( (L‚àí1)(k‚àí1)
2

5.1

Estimation of the parameters

The model parameters are , Œ¥ and c. However, as we have seen, the fundamental quantities are Œ∑ = 2( ‚àí Œ¥)
and Œª given in (4.1). Moreover, recall that in case a), we have Œ∑ = 0 and Œª > 1 and, in case b), we
have Œ∑ ‚àà (0, 1) and Œª > 0. Therefore, according the considered model, the pair (Œ∑, Œª) belongs to S =
{0} √ó (1, +‚àû) ‚à™ (0, 1) √ó (0, +‚àû). In order to estimate the pair (Œ∑, Œª) ‚àà S, we define
T` = N`Œ∑ Q` =

k
X
Oi (`) ‚àí N` p‚àó0 i (`)
N` p‚àó0 i (`)
i=1

2
.

Given the observed values t1 , . . . , tL , the log-likelihood function of Q` reads
L

ln(L(Œ∑, Œª)) = ln L(Œ∑, Œª; t1 , . . . , tL ) = ‚àí

k‚àí1 X
k‚àí1
L ln(Œª) ‚àí
Œ∑
ln(N` ) ‚àí
2
2
`=1

1
2Œª

L
X
`=1

t`
Œ∑
N`

+ R1 ,

where R1 is a remainder term that does not depend on (Œ∑, Œª). Now, we look for the maximum likelihood
estimator of the two parameters (Œ∑, Œª).
We immediately observe that, when all the clusters have the same cardinality, that is all the N` are equal
to a certain N0 , then we cannot hope to estimate Œ∑ and Œª, separately. Indeed, the log-likelihood function
becomes
ln(L(Œ∑, Œª)) = ln L(Œ∑, Œª; t1 , . . . , tL ) = ‚àí

i
k‚àí1 h
L ln(Œª) + Œ∑ ln(N0 ) ‚àí
2

1
Œ∑
2ŒªN0

L
X

t` + R1 = f (ŒªN0Œ∑ ) .

`=1

dŒ∑ = PL t` /(k ‚àí 1)L.
This fact implies that it possible to estimate only the parameter (ŒªN0Œ∑ ) as ŒªN
0
`=1
From now on, we assume that at least two clusters have different cardinality, that is at least a pair
of cardinalities N` are different. We have to find (if they exist!) the maximum points of the function
(Œ∑, Œª) 7‚Üí ln(L(Œ∑, Œª)) on the set S, which is not closed nor limited. First of all, we note that ln(L(Œ∑, Œª)) ‚Üí ‚àí‚àû
for Œª ‚Üí +‚àû and Œª ‚Üí 0. Thus, the log-likelihood function has maximum value on the closure S of S and
its maximum points are stationary points belonging to (0, 1) √ó (0, +‚àû) or they belong to {0, 1} √ó (0, +‚àû).
For detecting the points of the first type, we compute the gradient of the log-likelihood function, obtaining
PL
PL t` ln(N` ) !
1
‚àí k‚àí1
Œ∑
`=1 ln(N` ) + 2Œª
`=1
2
N`
P
‚àá(Œ∑, Œª) ln L =
.
L
t`
1
L
+
‚àí k‚àí1
Œ∑
2
`=1 N
2Œª
2Œª
`

Hence, the stationary points (Œ∑, Œª) of the log-likelihood function are solutions of the system
Ô£± PL t`
PL
Ô£¥
Ô£¥ `=1 N`Œ∑ ln(N` )
`=1 ln(N` )
Ô£¥
Ô£¥
=
P
Ô£¥
L
t`
Ô£≤
L
Œ∑
`=1 N
`

PL t`
Ô£¥
Ô£¥
Ô£¥
`=1 N Œ∑
Ô£¥
Ô£¥
`
Ô£≥Œª =
.
L(k ‚àí 1)

8

In particular, we get that the stationary points are of the form (Œ∑, Œª(Œ∑)), with
PL t`
Œª(Œ∑) =

`=1 N Œ∑
`

L(k ‚àí 1)

.

(5.2)

In order to find the maximum points on the border, that is belonging to {0, 1} √ó (0, +‚àû), we observe
that, fixed any Œ∑, the function
Œª 7‚Üí ‚àí

k‚àí1
L ln(Œª) ‚àí
2

1
2Œª

L
X
`=1

t`
Œ∑
N`

+ R2 ,

where R2 is a remainder term not depending on Œª, takes its maximum value at the point Œª(Œ∑) defined in
(5.2).
Summing up, the problem of detecting the maximum points of the log-likelihood function on S reduces
to the study of the maximum points on [0, 1] of the function
Œ∑ 7‚Üí ln(L(Œ∑, Œª(Œ∑))) = ‚àí

L

L

`=1

`=1

X t  k ‚àí 1 X
k‚àí1
`
L ln
‚àí
Œ∑
ln(N` ) + R3 ,
2
N`Œ∑
2

(5.3)

where R3 is a remainder term not depending on Œ∑. To this purpose, we note that we have
Ô£Æ PL t
Ô£π
PL
`
ln(L(Œ∑, Œª(Œ∑))
(k ‚àí 1)L
k ‚àí 1 Ô£∞ `=1 N`Œ∑ ln(N` )
`=1 ln(N` ) Ô£ª
d
‚àí
=
L
g(Œ∑) ,
=
PL t`
dŒ∑
2
L
2
Œ∑
`=1
N`

where

PL
g(x) =

t`
`=1 N`x ln(N` )
PL t`
`=1 N`x

PL

ln(N` )
.
L

`=1

‚àí

Setting
t`
N`x

p(x, `) = PL

tl
l=1 Nlx

and denoting by Ex [¬∑] and by Eu [¬∑] the mean value with respect to the discrete probability distribution {p(x, `) : ` = 1, . . . , L} on {N1 , . . . , NL } and with respect to the uniform discrete distribution on
{N1 , . . . , NL } respectively, the above function g can be written as
PL
L
X
ln(N` )
g(x) =
p(x, `) ln(N` ) ‚àí `=1
= Ex [ln(N )] ‚àí Eu [ln(N )] .
L
`=1

Moreover, we have

0

‚àí

PL

g (x) =

t`
`=1 N`x

ln2 (N` )

 P

L
t`
`=1 N`x

P

L
t`
`=1 N`x

=‚àí

L
X
`=1

p(x, `) ln2 (N` ) +

L
X



+

P

L
t`
`=1 N`x

ln(N` )

2

2

p(x, `) ln(N` )

2

= ‚àí V arx [ln(N )] ,

`=1

where V arx [¬∑] denotes the variance with respect to the discrete probability distribution {p(x, `) : ` =
1, . . . , L} on {N1 , . . . , NL }. Since, we are assuming that at least two N` are different, we have V arx [ln(N )] >
0 and so the function g is strictly decreasing. Finally, we observe that we have
PL
PL
P
PL
t` L
t`
`=1 t` ln(N` )
`=1 ln(N` )
Covu (ln(N ), T ) =
‚àí `=1
= g(0) `=1
L
L
L
L
and
PL t`
PL t` PL
PL t`
`=1 N` ln(N` )
`=1 N`
`=1 N`
T
`=1 ln(N` )
Covu (ln(N ), N
)=
‚àí
= g(1)
,
L
L
L
L
where Covu (¬∑, ¬∑) denotes the covariance with respect to the discrete joint distribution concentrated on the
diagonal and such that P {N = N` , T = t` } = 1/L with ` = 1, . . . , L. Hence, we distinguish the following
cases.

9

First case: Covu (ln(N ), T ) ‚â§ 0
We are in the case when g(0) ‚â§ 0 and so the function (5.3) is strictly decreasing for Œ∑ > 0. Thus, its
PL

t

b = Œª(0) = `=1 ` . Recall that
maximum value on [0, 1] is assumed at Œ∑b = 0. Consequently, we have Œª
L(k‚àí1)
b ‚àà S and so Œª
b > 1. If the model fits well the data, this is a consequence. Indeed, Œª
b is an
we need (0, Œª)
d
b ‚àº Œì(L(k ‚àí 1)/2, 1/(2Œª)) and so E[Œª]
b = Œª > 1. A value Œª
b ‚â§ 1 means a bad fit of the
unbiased estimator: Œª
consider model to the data (the smaller the value of Œª, the worse the fitting). Note that in the threshold
b = 1), the corresponding test statistics (5.1) and its distribution coincide with the classical
case (b
Œ∑ = 0, Œª
ones used for independent observations.
T
Second case: Covu (ln(N ), T ) > 0 and Covu (ln(N ), N
)<0

We are in the case when g(0) > 0 and g(1) < 0. Hence, the function (5.3) has a unique stationary point
PL

`=1

b = Œª(b
Œ∑b ‚àà (0, 1), which is the maximum point. Consequently, we have Œª
Œ∑) =
belongs to S.

t`
Œ∑
b

N`
L(k‚àí1)

b
> 0. The point (b
Œ∑ , Œª)

T
Third case: Covu (ln(N ), N
)‚â•0

We are in the case when g(1) ‚â• 0 and so the function (5.3) is strictly increasing on [0, 1]. Hence, its
PL

t`

b = Œª(1) = `=1 N` . However, the point (1, Œª)
b does
maximum point is at Œ∑b = 1, and, accordingly, we have Œª
L(k‚àí1)
not belong to S and so, in this case, we conclude that we have a bad fit of the model to the data. Note
d
that, if the considered model fits well the data, then we have T /N ‚àº Œªe(Œ∑‚àí1) ln(N ) œá2 (k ‚àí 1) with Œ∑ < 1
T
and, consequently, we expect Covu (ln(N ), N ) < 0. Moreover, a value Œ∑ ‚â• 1 in the statistics (5.1) means a
d

central limit theorem of the type N (1‚àíŒ∑)/2 (ŒæN ‚àí p0 ) ‚àº N (0, CŒì) with (1 ‚àí Œ∑)/2 ‚â§ 0. This is impossible
since (ŒæN ‚àí p0 ) is bounded.

6

COVID-19 epidemic Twitter analysis

We illustrate the application of the above statistical methodology to a data set containing posts on the
on-line social network Twitter about the COVID-19 epidemic. More precisely, the data set covers the period
from February 20th (h. 11pm) to April to 20th (h. 10pm) 2020, including tweets in Italian language. More
details on the keywords used for the query can be found in [13]. For every message, the relative sentiment
has been calculated using the polyglot python module developed in [16]. This module provides a numerical
value v for the sentiment and we have fixed a threshold T = 0.35 so that we have classified as a tweet with
positive sentiment those with v > T and as a tweet with negative sentiment those with v < ‚àíT . We have
discarded tweets with a value v ‚àà [‚àíT, T ].
We are in the case k = 2 and the random variables Œæn = Œæn 1 take the value 1 when the sentiment of the
post n is positive and the value 0 when the sentiment of the post n is negative. We have partitioned the data
so that each set Pd collect the messages of the single day d, for d = 1(February 20st), . . . , 61(April 20th)
and then, in order to obtain independent clusters, we have set C` = P1+3(`‚àí1) , for ` = 1, . . . , 21 = L. (We
have tested the independence of the timed sequence {Q` : ` = 1, . . . , 21} with a Ljung‚ÄìBox test and we give
the results
in Table 2.) Therefore N` is the total number of tweets posted during the day 1 + 3(` ‚àí 1) and
P
N= L
`=1 N` = 699 450 is the sample size.
It is plausible that inside each cluster the sentiment associated to each message is driven by a reinforcement mechanism, that can be modelled by means of a GRP: the probability to have a tweet with positive
sentiment is increasing with the number of past tweets with positive sentiment and the reinforcement is
mostly driven by the most recent tweets, in the sense explained in Section 2. Note that the main effect of
the GRP urn model is the presence of ‚Äúlocal fashions‚Äù, resulting in unexpected excursions of œàn around the
long-run probabilities p0 . In order to point out that the considered data set exhibits this characteristics,
for each `, we have computed the daily sentiment rate pb0 (`), then, according to this probability, we have
generated an independent sequence (Œæn0 ) of bernoulli variables, finally we have used the same smoothing
procedure (i.e. classical cubic spline given in R package) to get an estimate of œàn = œàn 1 , for both the real
and the simulated independent data. In Fig. 1 the daily curves clearly show different behaviors in the two
cases, highlighting a local reinforcement among tweets.

10

Figure 1: Smoothed daily estimate of œàn 1 for the Twitter dataset (left) and for the simulated independent data
(right). The daily mean rate pb0 (`) is the same for both the left and the right panel. x-axis: daily time. y-axis:
cubic spline smoothing of the observed data Œæn and of the simulated independent data Œæn0 .

Figure 2: Plot of the function (5.3). Its maximum point gives the estimated value of the model parameter Œ∑.
‚àó
‚àó
PN Our purpose is to test the null hypothesis H0 : p0 (`) = p0 for any `. Therefore, taking p0 1 (`) = p0 =
Œæ
/N
for
each
`,
we
have
firstly
estimated
the
model
parameters
and
then
we
have
performed
the
n=1 n
PL
chi-squared test based on the aggregate statistics
Q
and
its
corresponding
asymptotic
distribution
`
`=1
1
b = 2.728098 (in Fig. 2 we plot the function
Œì( (L‚àí1)(k‚àí1)
, 2Œª
). The estimated values are Œ∑b = 0.4363572 and Œª
2
(5.3)).
The contingency table and the associated statistics for testing H0 is given in Table 1. The obtained
œá2 -statistics for a usual œá2 -test is 5507.803, which is significant atPany level of confidence. Under the
proposed GRP model and the null hypothesis, the aggregate statistics L
`=1 Q` has (asymptotic) distribution
, 21Œªb ) and the corresponding p-value associated to the data is equal to 0.4579297. The null hypothesis
Œì( L‚àí1
2
that the daily long-run sentiment rate of the posts is the same for all the considered days is therefore
strongly rejected with a classical œá2 test, while the same hypothesis is accepted if we take into account the
reinforcement mechanism of correlation given in GRP model.
In Fig. 3 there are the values of the single statistics Q` compared to the 95th-quantile of the distribution
Œì( 12 , 21Œªb ).

11

Date
2020-02-20
2020-02-23
2020-02-26
2020-02-29
2020-03-03
2020-03-06
2020-03-09
2020-03-12
2020-03-15
2020-03-18
2020-03-21
2020-03-24
2020-03-27
2020-03-30
2020-04-02
2020-04-05
2020-04-08
2020-04-11
2020-04-14
2020-04-17
2020-04-20

Obs+
25
53564
29831
18220
16801
27906
41650
255
14193
12064
11571
13339
14798
12689
12714
13373
14889
12153
13406
13977
13753

Obs‚àí
43
60476
37175
22184
14834
27030
34769
156
13562
10089
10026
9172
10039
10651
9300
10815
11987
10777
11430
11371
12393

Exp+
35.11
58886.18
34599.51
20863.18
16335.18
28366.99
39460.04
212.23
14331.69
11439.02
11151.92
11623.88
12824.94
12051.94
11367.24
12489.82
13877.81
11840.23
12824.42
13088.80
13500.86

Exp‚àí
32.89
55153.82
32406.49
19540.82
15299.82
26569.01
36958.96
198.77
13423.31
10713.98
10445.08
10887.12
12012.06
11288.06
10646.76
11698.18
12998.19
11089.77
12011.58
12259.20
12645.14

œá2+
2.91
481.02
657.20
334.87
13.28
7.49
121.54
8.62
1.34
34.15
15.75
253.07
303.55
33.67
159.56
62.45
73.68
8.26
26.37
60.27
4.71

œá2‚àí
3.11
513.58
701.67
357.53
14.18
8.00
129.76
9.20
1.43
36.46
16.81
270.20
324.09
35.95
170.36
66.68
78.67
8.82
28.16
64.35
5.03

(c)

œá2+
0.46
2.99
5.15
3.27
0.14
0.06
0.90
0.62
0.02
0.43
0.20
3.19
3.67
0.42
2.03
0.76
0.86
0.10
0.32
0.72
0.06

(c)

œá2‚àí
0.49
3.19
5.50
3.49
0.15
0.07
0.96
0.67
0.02
0.46
0.22
3.41
3.92
0.45
2.17
0.82
0.92
0.11
0.34
0.77
0.06

Table 1: Contingency table associated to COVID-Twitter data: Obs+ (Obs‚àí ) are the number of posts with positive (negative) sentiment posted in the day ` reported in the first column (DataTime); Exp+ (Exp‚àí ) corresponds
to N` p‚àó0 (resp. N` (1 ‚àí p‚àó0 )), where N` = Obs+ + Obs‚àí ; œá2+ (œá2‚àí ) is the quantity (Obs+ ‚àí Exp+ )2 /Exp+ (resp.
(Obs‚àí ‚àí Exp‚àí )2 /Exp‚àí ); œá2+
œá2+

(c)

+ œá2‚àí

(c)

(c)

(œá2‚àí

(c)

) is the quantity œá2+ /N`Œ∑b (resp. œá2‚àí /N`Œ∑b). The statistics Q` corresponds to

.

Figure 3: Plot of the Q` -series. The black line corresponds to the value of 95th-quantile of the distribution
Œì( 12 , 1b ), that is 10.48.
2Œª

12

Df
œá2
p‚àívalue

1
3.454
0.063

2
3.624
0.163

3
4.209
0.240

4
4.640
0.326

5
5.065
0.408

6
7.103
0.311

7
8.660
0.278

8
8.812
0.358

9
10.360
0.322

10
12.852
0.232

Table 2: Summary of Ljung‚ÄìBox test for autocorrelation of {Q` : ` = 1, . . . , 21}, with different numbers of autocorrelation lags being tested. Df: number of lags under investigation; œá2 : Ljung‚ÄìBox test statistics, which is
distributed as a œá2 distribution with Df degrees of freedom under the null hypothesis of independence; p‚àívalue:
p‚àívalue of the Ljung‚ÄìBox test.
The strong emotional involvement of the considered period had a ‚Äúmixing effect‚Äù that cancelled possible significant autocorrelation during different 3-delayed days.

7

Asymptotic results for the empirical means

Theorem 4.1 is a consequence of the following Proposition7.1 and Theorem 7.2 for the empirical means ŒæN .
s
In the sequel, we will use the symbol ‚àí‚Üí in order to denote the stable convergence (for a brief review on
stable convergence, see Section S6).
Leveraging the Stochastic Approximation results collected in Section S5, we prove in Section S1.3 the
following result:
Proposition 7.1. Take n = (n+1)‚àí and Œ¥n = cn , with  ‚àà (0, 1] and c > 0, and set Œì = diag(p0 )‚àíp0 p0 > .
a.s.
Then ŒæN ‚àí‚Üí p0 and
‚àö
 s
N ŒæN ‚àí p0 ‚àí‚Üí N (0, ŒªŒì) ,
with Œª = (c + 1)2 when 0 <  < 1 and Œª = (c + 1)2 + c2 = 2c(c + 1) + 1 when  = 1.
For the case when (n )n and (Œ¥n )n in (2.7) go to zero with different rates, we prove the following theorem
(the proof is illustrated in Section 8):
Theorem 7.2. Take n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ , with  ‚àà (0, 1), Œ¥ ‚àà (/2, ) and c > 0. Then
a.s.
ŒæN ‚àí‚Üí p0 and


 s
c2
Œì ,
N 1/2‚àí(‚àíŒ¥) ŒæN ‚àí p0 ‚àí‚Üí N 0,
1 + 2( ‚àí Œ¥)
with Œì = diag(p0 ) ‚àí p0 p0 > .
In the framework of the above theorem, we can distinguish the following two cases:
1)  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ) or
2)  ‚àà (0, 1) and Œ¥ ‚àà (/2, min{, 1/2}] \ {}.
P
P
P
In case 1), we have n n = +‚àû, n 2n < +‚àû and n Œ¥n2 < +‚àû and so the typical asymptoticP
behaviour of
the predictive
mean
of
an
urn
process,
that
is
its
almost
sure
convergence.
In
case
2),
we
have
n n = +‚àû
P
P
and n Œ¥n2 = +‚àû (while the series n 2n may be convergent or divergent) and it seems to us not immediate
to check the convergence of the predict means. Therefore, for the proof of Theorem 7.2 in this last case, we
will employ a different technique, which is based on the L2 -estimate of Lemma 8.1 for the predictive mean
œàN and the almost sure convergence of the corresponding empirical mean œà N ‚àí1 .

8

Proof of Theorem 7.2

P
PN
For all the sequel, we set œà N ‚àí1 = N
n=1 œàn‚àí1 /N and Œ∏ N ‚àí1 =
n=1 Œ∏n‚àí1 /N . To the proof of Theorem
7.2, we premise some intermediate results.
Lemma 8.1. Under the same assumptions of Theorem 7.2, we have E[kŒ∏n k2 ] = O(n‚àí2Œ¥ ) ‚Üí 0.
Proof. We observe that, starting from (2.7), we get
kŒ∏n+1 k2 = Œ∏n+1 > Œ∏n+1 = (1 ‚àí n )2 kŒ∏n k2 + Œ¥n2 k‚àÜMn+1 k2 + 2(1 ‚àí n )Œ¥n Œ∏n > ‚àÜMn+1
and so
E[kŒ∏n+1 k2 |Fn ] = (1 ‚àí n )2 kŒ∏n k2 + Œ¥n2 E[k‚àÜMn+1 k2 |Fn ] .

13

(8.1)

Hence, setting xn = E[kŒ∏n k2 ], we get
xn+1 = (1 ‚àí 2n )xn + 2n xn + Œ¥n2 E[k‚àÜMn+1 k2 ]


Œ¥2
= (1 ‚àí 2n )xn + n n xn + n E[k‚àÜMn+1 k2 ]
n

with 0 ‚â§ Œ∂n =



= (1 ‚àí 2n )xn + 2n Œ∂n ,

Œ¥2
n xn + nn E[k‚àÜMn+1 k2 ] /2. Applying Lemma S4.4 (with Œ≥n = 2n ), we find that

lim supn xn ‚â§ lim supn Œ∂n . On the other hand, since (‚àÜMn+1 )n is uniformly bounded and 2n /Œ¥n2 ‚àº
2
2
c‚àí2 n‚àí2(‚àíŒ¥) ‚Üí 0, we have Œ∂n = O(n + Œ¥n2 ‚àí1
n ) = O(Œ¥n /n ) and so xn = O(Œ¥n /n ). We can conclude
2
2 ‚àí2Œ¥
recalling that Œ¥n /n ‚àº c n
.
Lemma 8.2. Under the same assumptions of Theorem 7.2, we have
Œ∏ N ‚àí1 =

N ‚àí1
N
1 X
1 X Œ¥n
‚àÜMn+1 + RN ,
Œ∏n‚àí1 =
N n=1
N n=0 n

(8.2)



a.s.
where RN ‚àí‚Üí 0 and N e E |RN | ‚àí‚Üí 0 with e = 1/2 ‚àí ( ‚àí Œ¥) ‚àà (0, 1/2).
Proof. By (2.8), we have
Œ∏n = ‚àí

1
Œ¥n
(Œ∏n+1 ‚àí Œ∏n ) +
‚àÜMn+1 .
n
n

Therefore, we can write
N
‚àí1
X
n=0

N
‚àí1
X
Œ¥n
1
(Œ∏n+1 ‚àí Œ∏n ) +
‚àÜMn+1

n
n
n=0
n=0

 N

‚àí1 
N
‚àí1
X
X
Œ∏N
Œ∏0
1
1
Œ¥n
=‚àí
‚àí
‚àí
‚àí
Œ∏n +
‚àÜMn+1 ,
N ‚àí1
0


n
n‚àí1
n
n=1
n=0

Œ∏n = ‚àí

N
‚àí1
X

where the second equality is due to the Abel transformation for a series. It follows the decomposition (8.2)
with



N ‚àí1 
1
Œ∏N
Œ∏0
1 X
1
1
RN = ‚àí
‚àí
‚àí
‚àí
Œ∏n .
(8.3)
N N ‚àí1
0
N n=1 n‚àí1
n
Since |Œ∏n | = O(1), we have
|RN | =

O(N ‚àí1 ‚àí1
N ‚àí1 )

+O

N

‚àí1

N
‚àí1
X

!
|‚àí1
n‚àí1

‚àí

‚àí1
n |

n=1

PN ‚àí1 ‚àí1
‚àí1
‚àí1
Note that
‚àí ‚àí1
N ‚àí1 when (n ) is decreasing and so the last term in the above
n=1 |n‚àí1 ‚àí n | = 0
‚àí1 ‚àí1
expression is O(N N ‚àí1 ). Therefore, since  < 1 by assumption, we have |RN | = O(N ‚àí(1‚àí) ) ‚Üí 0.
Regarding

 the last statement of the lemma, we observe that, from what we have proven before, we obtain
N e E |RN | = O(N e‚àí(1‚àí) ) = O(N Œ¥‚àí1/2 ) ‚Üí 0 when Œ¥ < 1/2. However, in the considered cases 1) and 2),
we might have Œ¥ ‚â• 1/2. Therefore, we need other arguments in order to prove the last statement. To this
purpose, we observe that, by Lemma 8.1, we have E[ |Œ∏n | ] = O(n/2‚àíŒ¥ ) and so, by (8.3), we have
!
N ‚àí1

1 X ‚àí1
e 
‚àí(1‚àíe) 3/2‚àíŒ¥
‚àí1 /2‚àíŒ¥
N E |RN | = O(N
N
)+O
|
‚àí n |n
N 1‚àíe n=1 n‚àí1
!
N ‚àí1
1 X ‚àí1
‚àí(1‚àí)/2
‚àí1 /2‚àíŒ¥
= O(N
)+O
|
‚àí n |n
.
N 1‚àíe n=1 n‚àí1
Moreover, we have
N
‚àí1
X
n=1

‚àí1 /2‚àíŒ¥
|‚àí1
=
n‚àí1 ‚àí n |n

N
‚àí1
X

[(n ‚àí 1) ‚àí n ] n/2‚àíŒ¥ =

n=1

N
‚àí1
X

n‚àí1+/2‚àíŒ¥ ‚àº N 3/2‚àíŒ¥ = o(N 1‚àíe ) ,

n=1

because e = 1/2 ‚àí ( ‚àí Œ¥) and  < 1. Summing up, we have N e E[|RN |] = O(N ‚àí(1‚àí)/2 ) + o(1) ‚Üí 0.

14

a.s.

a.s.

Lemma 8.3. Under the same assumptions of Theorem 7.2, we have Œ∏ N ‚àí1 ‚àí‚Üí 0, that is œà N ‚àí1 ‚àí‚Üí p0 .
a.s.
a.s.
In particular, when  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ), we have Œ∏N ‚àí‚Üí 0, that is œàN ‚àí‚Üí p0 .
Proof. Let us distinguish the following two cases:
1)  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ) or
2)  ‚àà (0, 1) and Œ¥ ‚àà (/2, min{, 1/2}] \ {}.
For the case 1), we observe that, by (8.1), we have
E[kŒ∏n+1 k2 |Fn ] ‚â§ (1 + 2n )E[kŒ∏n k2 |Fn ] + Œ¥n2 E[k‚àÜMn+1 k2 |Fn ].
P
P
Therefore, since (‚àÜMn+1 )n is uniformly bounded and, in case 1), we have n 2n < +‚àû and n Œ¥n2 < +‚àû,
2
the sequence (kŒ∏n k )n is a bounded non-negative almost supermartingale. As a consequence, it converges
almost surely to a certain random variable. This limit random variable is necessarily equal to 0 because,
by Lemma 8.1, we have E[kŒ∏n k2 ] = O(n‚àí2Œ¥ ) ‚Üí 0. Hence, we have the almost sure convergence of Œ∏N to
0 and, consequently, the almost sure convergence of Œ∏ N ‚àí1 to 0 follows by Lemma S4.2 and Remark S4.3
(with cn = n and vN,n = n/N ), because E[Œ∏n‚àí1 |Fn‚àí2 ] = (1 ‚àí n‚àí2 )Œ∏n‚àí2 ‚Üí 0 almost surely.
a.s.
For the case 2), we use Lemma 8.2, that gives the
(8.2), with RN ‚àí‚Üí 0. Indeed, by this
Pdecomposition
N ‚àí1 Œ¥n
decomposition, it is enough to prove that the term n=0 n ‚àÜMn+1 /N converges almost surely to 0. To
this purpose, we observe that, if we set
Ln =

n
X
1 Œ¥j‚àí1
‚àÜMj ,
j j‚àí1
j=1

then (Ln ) is a square integrable martingale. Indeed, we have
+‚àû
2
X
1 Œ¥n‚àí1
E[k‚àÜMn k2 ] = O
2
2
n

n‚àí1
n=1

Therefore, (Ln ) converges almost surely, that is we have
Lemma S4.1 (with vN,n = n/N ), we find

+‚àû
X
n=1

P

!

1
n1+2e

< +‚àû .

1 Œ¥n‚àí1
n n n‚àí1 ‚àÜMn

< +‚àû almost surely. Applying

N ‚àí1
N
X
1 Œ¥n‚àí1
1 X Œ¥n
a.s.
‚àÜMn+1 =
vN,n
‚àÜMn ‚àí‚Üí 0
N n=0 n
n

n‚àí1
n=1
a.s.

and so Œ∏ N ‚àí1 ‚àí‚Üí 0.
Proof of Theorem 7.2. Set e = 1/2 ‚àí ( ‚àí Œ¥) ‚àà (0, 1/2) and Œª = c2 /[2(1 ‚àí e)] = c2 /[1 + 2( ‚àí Œ¥)]. Moreover,
let us distinguish the following two cases:
1)  ‚àà (1/2, 1) and Œ¥ ‚àà (1/2, ) or
2)  ‚àà (0, 1) and Œ¥ ‚àà (/2, min{, 1/2}] \ {}.
Almost sure convergence: In case 1), by Lemma 8.3, œàN converges almost surely to p0 . Therefore, the almost
sure convergence of ŒæN to p0 follows by Lemma S4.2
P(with cn = n and vN,n = n/N ),
P and Remark S4.3
because E[Œæn+1 |Fn ] = œàn ‚Üí p0 almost surely and n E[kŒæn k2 ]n‚àí2 ‚â§ n n‚àí2 < +‚àû.
In case 2), we use a different argument. Take Œ≥ ‚àà [0, e) and set
Ln =

n
X
j=1

1 Œ¥j‚àí1
‚àÜMj .
j 1‚àíŒ≥ j‚àí1

Then (Ln ) is a square integrable martingale, because we have
+‚àû
X
n=1

1
n2‚àí2Œ≥

2
Œ¥n‚àí1
E[k‚àÜMn k2 ] = O
2n‚àí1

15

+‚àû
X
n=1

1
n1+2e‚àí2Œ≥

!
< +‚àû .

Therefore, (Ln ) converges almost surely, that is we have

Lemma S4.1 (with vN,n = (n/N )1‚àíŒ≥ n‚àí1 /Œ¥n‚àí1 ‚àº n1‚àíŒ≥‚àí+Œ¥ /N
N
‚àí1
X

1
N 1‚àíŒ≥

‚àÜMn+1 =

n=0

N
X

vN,n

n=1

Œ¥n‚àí1
1
n n1‚àíŒ≥ n‚àí1 ‚àÜMn
1‚àíŒ≥

P

< +‚àû almost surely. By

), we get

1 Œ¥n‚àí1
a.s.
‚àÜMn ‚àí‚Üí 0.
n1‚àíŒ≥ n‚àí1

Therefore, we have

N Œ≥ ŒæN ‚àí œà N ‚àí1 =

N
‚àí1
X

1
N 1‚àíŒ≥

a.s.

‚àÜMn+1 ‚àí‚Üí 0,

n=0


that is ŒæN ‚àí œà N ‚àí1 = o(N ‚àíŒ≥ ) for each Œ≥ ‚àà [0, e). Recalling Lemma 8.3, we obtain in particular that ŒæN
converges almost surely to p0 .
Second order asymptotic behaviour: We have
‚àö


N e ŒæN ‚àí p0 = N e ¬µN = N e‚àí1/2 N ¬µN ‚àí Œ∏ N ‚àí1 + N e Œ∏ N ‚àí1 .
(8.4)
Moreover, by Lemma 8.1, we have
N ‚àí1
N
X
1 X
E[|Œ∏n |] = O(N ‚àí1
n/2‚àíŒ¥ ) = O(N ‚àí1‚àíŒ¥+/2+1 ) = O(N /2‚àíŒ¥ ) ‚Üí 0 ,
N n=0
n=1
N ‚àí1
N
X
1 X
E[kŒ∏n k2 ] = O(N ‚àí1
n‚àí2Œ¥ ) = O(N ‚àí1‚àí2Œ¥++1 ) = O(N ‚àí2Œ¥ ) ‚Üí 0 ,
N n=0
n=1

and so Theorem S1.1 holds true with V = Œì (see Remark S1.2). Therefore, the first term in the right side
of (8.4) converges in probability to 0 because e < 1/2. Hence, if we prove that
s

N e Œ∏ N ‚àí1 ‚àí‚Üí N (0, ŒªŒì) ,

(8.5)

then the proof is concluded.
In order to prove (8.5), we observe that, by decomposition (8.2) in Lemma 8.2, we have
N e Œ∏ N ‚àí1 =

N
X

YN,n + N e RN ,

n=1
Œ¥n‚àí1
‚àÜMn
N 1‚àíe n‚àí1


and N RN converges in probability to 0 (because N e E |RN |] ‚Üí 0). TherePN
fore, it is enough to prove that the term n=1 YN,n stably converges to the Gaussian kernel N (0, ŒªŒì), with
P
Œª = c2 /[2(1 ‚àí e)] = c2 /[1 + 2( ‚àí Œ¥)]. To this purpose, we observe that E[YN,n |Fn‚àí1 ] = 0 and so N
n=1 YN,n
converges stably to N (0, ŒªŒì) if the conditions (c1) and (c2) of Theorem S6.1, with V = ŒªŒì, hold true.
Regarding (c1), we note that Œ¥n‚àí1 /n‚àí1 ‚àº cn‚àíŒ¥ = cn1/2‚àíe and so we have
where YN,n =

e

1

max |YN,n | ‚â§ N ‚àí(1‚àíe) max

1‚â§n‚â§N

1‚â§n‚â§N

Œ¥n‚àí1
Œ¥n‚àí1
|Œæn ‚àí œàn‚àí1 | ‚â§ N ‚àí(1‚àíe) max
= O(N ‚àí1/2 ) ‚Üí 0 .
1‚â§n‚â§N n‚àí1
n‚àí1

Condition (c2) means
1
N 2(1‚àíe)
We note that N ‚àí2(1‚àíe)

PN

n=1

N
2
X
Œ¥n‚àí1
P
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí ŒªŒì.
2

n‚àí1
n=1

(8.6)

2
2
Œ¥n‚àí1
/2n‚àí1 ‚Üí Œª, because Œ¥n‚àí1
/2n‚àí1 ‚àº c2 n1‚àí2e , and

E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > .
Therefore, in case 1), condition (8.6) immediately follows by the almost sure convergence of œàn to p0 .
2
It is enough to apply Lemma S4.2 and Remark S4.3 with cn = n and vN,n = nŒ¥n‚àí1
/(N 2(1‚àíe) 2n‚àí1 ) ‚àº
2 1+2(‚àíŒ¥)
2‚àí2e
2
2(1‚àíe)
c n
/N
= c (n/N )
. In case 2), we apply again Lemma S4.2 with the above cn and vN,n ,
but we note that œàn = Œ∏n + p0 and so condition (S4.1) in Lemma S4.2, with V = ŒªŒì, is equivalent to
1
N 2‚àí2e

N
‚àí1
X
n=0

Œ¥n2
P
Œ∏n ‚àí‚Üí 0
2n

1

and

N 2‚àí2e

16

N
‚àí1
X
n=0

Œ¥n2
P
Œ∏n Œ∏n > ‚àí‚Üí 0k√ók .
2n

These two convergences hold true because, by Lemma 8.1, we have
N
‚àí1
X

1
N 2‚àí2e
1
N 2‚àí2e

n=0

N
‚àí1
X
n=0

N
X
Œ¥n2
E[|Œ∏n |] = O(N ‚àí2+2e
n‚àí2Œ¥+2‚àíŒ¥+/2 ) = O(N ‚àí2+2e‚àí3Œ¥+5/2+1 ) = O(N ‚àíŒ¥+/2 ) ‚Üí 0 ,
2
n
n=1

N
X
Œ¥n2
E[kŒ∏n k2 ] = O(N ‚àí2+2e
n‚àí2Œ¥+2‚àí2Œ¥+ ) = O(N ‚àí2+2e‚àí4Œ¥+3+1 ) = O(N ‚àí2Œ¥+ ) ‚Üí 0 .
2
n
n=1

Therefore, in both cases 1) and 2), conditions c1) and c2) of Theorem S6.1 are satisfied and so
stably converges to the Gaussian kernel N (0, ŒªŒì).
Declaration

PN

n=1

YN,n

Both authors equally contributed to this work.
Acknowledgments
Giacomo Aletti is a member of the Italian Group ‚ÄúGruppo Nazionale per il Calcolo Scientifico‚Äù of the Italian Institute ‚ÄúIstituto Nazionale di Alta Matematica‚Äù and Irene Crimaldi is a member of the Italian Group
‚ÄúGruppo Nazionale per l‚ÄôAnalisi Matematica, la ProbabilitaÃÄ e le loro Applicazioni‚Äù of the Italian Institute
‚ÄúIstituto Nazionale di Alta Matematica‚Äù.
Funding Sources
Irene Crimaldi is partially supported by the Italian ‚ÄúProgramma di AttivitaÃÄ Integrata‚Äù (PAI), project ‚ÄúTOol
for Fighting FakEs‚Äù (TOFFE) funded by IMT School for Advanced Studies Lucca.

References
[1] G. Aletti and I. Crimaldi. The rescaled PoÃÅlya urn: local reinforcement and chi-squared goodness of fit
test. arXiv:1906.10951, 2019.
[2] G. Aletti and I. Crimaldi. Generalized rescaled PoÃÅlya urn and its statistical applications. Supplementary
Material of this article, 2020.
[3] G. Aletti, I. Crimaldi, and A. Ghiglietti. Synchronization of reinforced stochastic processes with a
network-based interaction. Ann. Appl. Probab., 27(6):3787‚Äì3844, 2017.
[4] G. Aletti, I. Crimaldi, and A. Ghiglietti. Networks of reinforced stochastic processes: asymptotics for
the empirical means. Bernoulli, 25(4B):3339‚Äì3378, 2019.
[5] G. Aletti, I. Crimaldi, and A. Ghiglietti. Interacting reinforced stochastic processes: Statistical inference
based on the weighted empirical means. Bernoulli, 26(2):1098‚Äì1138, 2020.
[6] G. Aletti, I. Crimaldi, and F. Saracco. A model for the twitter sentiment curve. arXiv:2011.05933,
2020.
[7] G. Aletti, A. Ghiglietti, and W. F. Rosenberger. Nonparametric covariate-adjusted response-adaptive
design based on a functional urn model. Ann. Statist., 46(6B):3838‚Äì3866, 2018.
[8] G. Aletti, A. Ghiglietti, and A. N. Vidyashankar. Dynamics of an adaptive randomly reinforced urn.
Bernoulli, 24(3):2204‚Äì2255, 2018.
[9] D. Bergh. Sample size and chi-squared test of fit‚Äî a comparison between a random sample approach
and a chi-square value adjustment method using swedish adolescent data. In Q. Zhang and H. Yang,
editors, Pacific Rim Objective Measurement Symposium (PROMS) 2014 Conference Proceedings, pages
197‚Äì211, Berlin, Heidelberg, 2015. Springer Berlin Heidelberg.
[10] P. Berti, I. Crimaldi, L. Pratelli, and P. Rigo. A central limit theorem and its applications to multicolor
randomly reinforced urns. J. Appl. Probab., 48(2):527‚Äì546, 2011.
[11] P. Berti, I. Crimaldi, L. Pratelli, and P. Rigo. Asymptotics for randomly reinforced urns with random
barriers. J. Appl. Probab., 53(4):1206‚Äì1220, 2016.

17

[12] D. Bertoni, G. Aletti, G. Ferrandi, A. Micheletti, D. Cavicchioli, and R. Pretolani. Farmland use
transitions after the cap greening: a preliminary analysis using markov chains approach. Land Use
Policy, 79:789 ‚Äì 800, 2018.
[13] G. Caldarelli, R. de Nicola, M. Petrocchi, M. Pratelli, and F. Saracco. Analysis of online misinformation
during the peak of the covid-19 pandemics in italy. arXiv: 2010.01913, 2020.
[14] K. C. Chanda. Chi-squared tests of goodness-of-fit for dependent observations. In Asymptotics, NonParametrics and Time Series, Statist. Textbooks Monogr., volume 158, pages 743‚Äì756. Dekker, 1999.
[15] M.-R. Chen and M. Kuba. On generalized poÃÅlya urn models. J. Appl. Probab., 50(4):1169‚Äì1186, 12
2013.
[16] Y. Chen and S. Skiena. Building sentiment lexicons for all major languages. In Proceedings of the 52nd
Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 383‚Äì389, 2014.
[17] A. Chessa, I. Crimaldi, M. Riccaboni, and L. Trapin. Cluster analysis of weighted bipartite networks:
A new copula-based approach. PLOS ONE, 9(10):1‚Äì12, 10 2014.
[18] A. Collevecchio, C. Cotar, and M. LiCalzi. On a preferential attachment and generalized poÃÅlya‚Äôs urn
model. Ann. Appl. Probab., 23(3):1219‚Äì1253, 06 2013.
[19] I. Crimaldi. Introduzione alla nozione di convergenza stabile e sue varianti (Introduction to the notion of
stable convergence and its variants), volume 57. Unione Matematica Italiana, Monograf s.r.l., Bologna,
Italy., 2016. Book written in Italian.
[20] I. Crimaldi, P. Dai Pra, P.-Y. Louis, and I. G. Minelli. Synchronization and functional central limit theorems for interacting reinforced random walks. Stochastic Processes and their Applications, 129(1):70‚Äì
101, 2019.
[21] I. Crimaldi, P. Dai Pra, and I. G. Minelli. Fluctuation theorems for synchronization of interacting
PoÃÅlya‚Äôs urns. Stochastic Process. Appl., 126(3):930‚Äì947, 2016.
[22] I. Crimaldi, G. Letta, and L. Pratelli. A Strong Form of Stable Convergence, volume 1899, pages
203‚Äì225. Springer, 2007.
[23] P. Dai Pra, P.-Y. Louis, and I. G. Minelli. Synchronization via interacting reinforcement. J. Appl.
Probab., 51(2):556‚Äì568, 2014.
[24] F. Eggenberger and G. PoÃÅlya. UÃàber die statistik verketteter vorgaÃànge. ZAMM - Journal of Applied
Mathematics and Mechanics / Zeitschrift fuÃàr Angewandte Mathematik und Mechanik, 3(4):279‚Äì289,
1923.
[25] G. Fort. Central limit theorems for stochastic approximation with controlled markov chain dynamics.
ESAIM: PS, 19:60‚Äì80, 2015.
[26] T. Gasser. Goodness-of-fit tests for correlated data. Biometrika, 62(3):563‚Äì570, 1975.
[27] L. J. Gleser and D. S. Moore. The effect of dependence on chi-squared and empiric distribution tests
of fit. The Annals of Statistics, 11(4):1100‚Äì1108, 1983.
[28] P. Hall and C. C. Heyde. Martingale limit theory and its application. Academic Press Inc. [Harcourt
Brace Jovanovich Publishers], New York, 1980. Probability and Mathematical Statistics.
[29] M. Holmes and A. Sakai. Senile reinforced random walks. Stochastic Processes and their Applications,
117(10):1519‚Äì1539, 2007.
[30] F. Ieva, A. M. Paganoni, D. Pigoli, and V. Vitelli. Multivariate functional clustering for the morphological analysis of electrocardiograph curves. Journal of the Royal Statistical Society. Series C (Applied
Statistics), 62(3):401‚Äì418, 2013.
[31] D. Knoke, G. W. Bohrnstedt, and A. Potter Mee. Statistics for Social Data Analysis. F.E.Peacock
Publishers, 2002.
[32] H. J. Kushner and G. G. Yin. Stochastic approximation and recursive algorithms and applications,
volume 35 of Applications of Mathematics (New York). Springer-Verlag, New York, second edition,
2003. Stochastic Modelling and Applied Probability.
[33] S. Laruelle and G. PageÃÅs. Randomized urn models revisited using stochastic approximation. Ann. Appl.
Proba., 23(4):1409‚Äì1436, 2013.

18

[34] N. Lasmar, C. Mailler, and O. Selmi. Multiple drawing multi-colour urns by stochastic approximation.
J. Appl. Probab., 55(1):254‚Äì281, 2018.
[35] H. M. Mahmoud. PoÃÅlya urn models. Texts in Statistical Science Series. CRC Press, Boca Raton, FL,
2009.
[36] A. Micheletti, G. Aletti, G. Ferrandi, D. Bertoni, D. Cavicchioli, and R. Pretolani. A weighted œá2 test
to detect the presence of a major change point in non-stationary Markov chains. Stat. Methods Appl.,
29(4):899‚Äì912, 2020.
[37] A. Mokkadem and M. Pelletier. Convergence rate and averaging of nonlinear two-time-scale stochastic
approximation algorithms. Ann. Appl. Probab., 16(3):1671‚Äì1702, 08 2006.
[38] W. Pan. Goodness-of-fit tests for GEE with correlated binary data. Scand. J. Statist., 29(1):101‚Äì110,
2002.
[39] M. Pelletier. Weak convergence rates for stochastic approximation with application to multiple targets
and simulated annealing. Ann. Appl. Probab., 8(1):10‚Äì44, 1998.
[40] R. Pemantle. A time-dependent version of poÃÅlya‚Äôs urn. J. Theor. Probab., 3:627‚Äì637, 1990.
[41] R. Pemantle. A survey of random processes with reinforcement. Probab. Surveys, 4:1‚Äì79, 2007.
[42] R. Radlow and E. F. Alf Jr. An alternate multinomial assessment of the accuracy of the œá2 test of
goodness of fit. Journal of the American Statistical Association, 70(352):811‚Äì813, 1975.
[43] J. N. K. Rao and A. J. Scott. The analysis of categorical data from complex sample surveys: chi-squared
tests for goodness of fit and independence in two-way tables. J. Amer. Statist. Assoc., 76(374):221‚Äì230,
1981.
[44] N. Sahasrabudhe. Synchronization and fluctuation theorems for interacting Friedman urns. J. Appl.
Probab., 53(4):1221‚Äì1239, 2016.
[45] M.-L. Tang, Y.-B. Pei, W.-K. Wong, and J.-L. Li. Goodness-of-fit tests for correlated paired binary
data. Stat. Methods Med. Res., 21(4):331‚Äì345, 2012.
[46] A. Tharwat. Independent component analysis: An introduction. Applied Computing and Informatics,
2018.
[47] D. Xu and Y. Tian. A comprehensive survey of clustering algorithms. Annals of Data Science, 2(2):165‚Äì
193, 2015.
[48] L.-X. Zhang. Central limit theorems of a recursive stochastic algorithm with applications to adaptive
designs. Ann. Appl. Probab., 26(6):3630‚Äì3658, 2016.

19

SM Supplemental Materials
In this document we collect some proofs, complements, technical results and recalls, useful for [S2]. Therefore,
the notation and the assumptions used here are the same as those used in that paper.

S1

Proofs and intermediate results

We here collect some proofs omitted in the main text of the paper [S2].

S1.1

Proof of Theorem 4.1

The proof is based on Proposition 7.1 (for case a)) and Theorem 7.2 (for case b)). The almost sure convergence of Oi /N immediately follows since Oi /N = Œæ N i . In order to prove the stated convergence in
distribution, we mimic the classical proof for the Pearson chi-squared test based on the Sherman Morison
formula (see [S18]), but see also [S16, Corollary 2].
We start recalling the Sherman Morison formula: if A is an invertible square matrix and we have 1 ‚àí
v > A‚àí1 u 6= 0, then
A‚àí1 uv > A‚àí1
(A ‚àí uv > )‚àí1 = A‚àí1 +
.
1 ‚àí v > A‚àí1 u
‚àó
Given the observation Œæn = (Œæn 1 , . . . , Œæn k )> , we define the ‚Äútruncated‚Äù vector Œæn
= (Œæn‚àó 1 , . . . , Œæn‚àó k‚àí1 )> , given
by the first k ‚àí 1 components of Œæn . Proposition 7.1 (for case a)) and Theorem 7.2 (for case b)) give the
second order asymptotic behaviour of (Œæn ), that immediately implies
PN
‚àó
‚àó
 ‚àó

n=1 (Œæn ‚àí p ) d
N e ŒæN ‚àí p‚àó =
‚àí‚Üí N (0, Œì‚àó ),
(S1.1)
N 1‚àíe

where p‚àó is given by the first k ‚àí 1 components of p0 and Œì‚àó = Œª(diag(p‚àó ) ‚àí p‚àó p‚àóT ). By assumption p0 i > 0
1
for all i = 1, . . . , k and so diag(p‚àó ) is invertible with inverse diag(p‚àó )‚àí1 = diag( p01 1 , . . . , p0 k‚àí1
) and, since
(diag(p‚àó )‚àí1 )p‚àó = 1 ‚àà Rk‚àí1 , we have
1 ‚àí p‚àóT diag(p‚àó )‚àí1 p‚àó = 1 ‚àí

k‚àí1
X

p0 i =

i=1

k
X
i=1

p0 i ‚àí

k‚àí1
X

p0 i = p0 k > 0.

i=1

Therefore we can use the Sherman Morison formula with A = diag(p‚àó ) and u = v = p‚àó , and we obtain

1
1
1
1
(Œì‚àó )‚àí1 = (diag(p‚àó ) ‚àí p‚àó p‚àóT )‚àí1 =
diag( p01 1 , . . . , p0 k‚àí1
)+
11> .
(S1.2)
Œª
Œª
p0 k
P
P
Now, since ki=1 (Œæ N i ‚àí p0 i ) = 0, then Œæ N k ‚àí p0 k = k‚àí1
i=1 (Œæ N i ‚àí p0 i ) and so we get
k
k
h k‚àí1
X
X
X (Œæ ‚àí p0 i )2
(Oi ‚àí N p0 i )2
(Œæ N i ‚àí p0 i )2
(Œæ
‚àí p0 k )2 i
Ni
=N
=N
+ Nk
N p0 i
p0 i
p0 i
p0 k
i=1
i=1
i=1
P
k‚àí1
k‚àí1
h X (Œæ ‚àí p )2
( i=1
(Œæ N i ‚àí p0 i ))2 i
0i
Ni
=N
+
p0 i
p0 k
i=1

=N

k‚àí1
X
i1 ,i2


1
1 
(Œæ N i1 ‚àí p0 i1 )(Œæ N i2 ‚àí p0 i2 ) Ii1 ,i2
+
,
p0 i 1
p0 k
=1

where Ii1 i2 is equal to 1 if i1 = i2 and equal to zero otherwise. Finally, from the above equalities, recalling
(S1.1) and (S1.2), we obtain
1
N 1‚àí2e

k
X
(Oi ‚àí N p0 i )2
‚àó
‚àó
d
= ŒªN 2e (ŒæN ‚àí p‚àó )> (Œì‚àó )‚àí1 (ŒæN ‚àí p‚àó ) ‚àí‚Üí ŒªW0 = W‚àó ,
N
p
0i
i=1

S1

where 1 ‚àí 2e ‚â• 0 and W0 is a random variable with distribution œá2 (k ‚àí 1) = Œì((k ‚àí 1)/2, 1/2), where Œì(a, b)
denotes the Gamma distribution with density function
f (w) =

ba a‚àí1 ‚àíbw
w
e
.
Œì(a)

As a consequence, W‚àó has distribution Œì((k ‚àí 1)/2, 1/(2Œª)).

S1.2

A preliminary central limit theorem

The following preliminary central limit theorem is useful for the proofs of the other central limit theorems
stated in [S2] and in Section S2.
Theorem S1.1. If
N
1 X
P
diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚àí‚Üí V ,
N n=1

(S1.3)

where V is a random variable with values in the space of positive semidefinite k √ó k-matrices, then
‚àö
 ‚àö
 s
N ¬µN ‚àí Œ∏ N ‚àí1 = N ŒæN ‚àí œà N ‚àí1 ‚àí‚Üí N (0, V ) .
Proof. We can write
‚àö

N


1
1 X
N ŒæN ‚àí œà N ‚àí1 = ‚àö N ŒæN ‚àí œà N ‚àí1 = ‚àö
(Œæn ‚àí œàn‚àí1 )
N
N n=1
N
N
X
1 X
= ‚àö
‚àÜMn =
YN,n ,
N n=1
n=1

P
with YN,n = N ‚àí1/2 ‚àÜMn . For the convergence of N
n=1 YN,n , we observe that E[YN,k |Fk‚àí1 ] = 0 and so,
by Theorem S6.1, it converges stably to N (0, V ) if the conditions (c1)‚àöand (c2) hold true. Regarding (c1),
we note that max1‚â§n‚â§N |YN,n | ‚â§ ‚àö1N max1‚â§n‚â§N |Œæn ‚àí œàn‚àí1 | = O(1/ N ) ‚Üí 0. Condition (c2) means
N
X
n=1

YN,n Y >
N,n =

N
1 X
P
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí V.
N n=1

The above convergence
holds true by Assumption
P (S1.3) and Lemma S4.2 (with cn = n and vN,n = n/N ).
P
Indeed, we have n‚â•1 E[kŒæn ‚àí œàn‚àí1 k2 ]/n2 ‚â§ n‚â•1 n‚àí2 < +‚àû and
E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > .

Remark S1.2. Recalling that œàn = Œ∏n + p0 , the convergence (S1.3) with V = Œì = diag(p0 ) ‚àí p0 p0 > , means
Œ∏ N ‚àí1 =

N
1 X
P
Œ∏n‚àí1 ‚àí‚Üí 0
N n=1

and

N
1 X
P
Œ∏n‚àí1 Œ∏n‚àí1 > ‚àí‚Üí 0k√ók ,
N n=1

where 0k√ók is the null matrix with dimension k √ó k.

S1.3

Proof of Proposition 7.1

By Lemma S4.2 (with cn = n and vN,n = n/N ), Remark S4.3 and Theorem S5.1,Pwe immediately get
ŒæN ‚Üí p0 almost surely. Indeed, we have E[Œæn+1 |Fn ] = œàn ‚Üí p0 almost surely and n‚â•1 E[kŒæn k2 ]n‚àí2 ‚â§
P
‚àí2
< +‚àû.
n‚â•1 n
Regarding the central limit theorem for ŒæN , we have to distinguish the two cases 1/2 <  ‚â§ 1 or
0 <  ‚â§ 1/2. In the first case, the result follows from Theorem S5.3, because (2.9) and the fact that

S2

E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚Üí Œì almost surely; while for the second case the
result follows from Theorem S1.1. Indeed, we have
‚àö
 ‚àö

 ‚àö
N ŒæN ‚àí p0 = N ŒæN ‚àí œà N ‚àí1 + N œà N ‚àí1 ‚àí p0
‚àö
 ‚àö
= (c + 1) N ŒæN ‚àí œà N ‚àí1 ‚àí N DN ,
‚àö



where D N = c ŒæN ‚àí œà N ‚àí1 ‚àí œà N ‚àí1 ‚àí p0 . By Theorem S1.1, the term (c + 1) N ŒæN ‚àí œà N ‚àí1 stably
2
converges to N (0, (c + 1) Œì) (note that assumption (S1.3) is satisfied‚àöwith V = Œì, because œàn ‚Üí p0 almost
surely). Therefore, in order to conclude, it is enough to show that N DN converges in probability to 0.
To this purpose, we observe that, by (2.7) with Œ¥n = cn , we have
œàn ‚àí œàn‚àí1 = n‚àí1 [c(Œæn ‚àí œàn‚àí1 ) ‚àí (œàn‚àí1 ‚àí p0 )]
and so
DN =

N
1 X œàn ‚àí œàn‚àí1
.
N n=1
n‚àí1

P
Moreover, we note that +‚àû
n=1 (œàn ‚àí œàn‚àí1 ) = limN œàN ‚àí œà0 = p0 ‚àí œà0 < +‚àû and, by Lemma S4.1 (with
vN,n = N ‚àí1 /n‚àí1 ), we get
N
X
œàn ‚àí œàn‚àí1 a.s.
‚àí‚Üí 0.
N ‚àí1
n‚àí1
n=1
For  ‚â§ 1/2, this fact implies
‚àö

N DN = ‚àö

N
‚àí1
X
œàn ‚àí œàn‚àí1 a.s.
1
N ‚àí1
‚àí‚Üí 0 .
n‚àí1
N N ‚àí1
n=1

The proof is thus concluded.

S2

Case

P

n n

< +‚àû

P
In this section we provide some results regarding the case n n < +‚àû, even if, as we will see, this case
is not interesting for the chi-squared test of goodness of fit. Indeed, as shown in the following result, the
empirical mean almost surely converges to a random variable, which does not coincide almost surely with a
deterministic vector.
P
a.s.
Theorem S2.1. If +‚àû
n=0 n < +‚àû, then Œæ N ‚àí‚Üí œà‚àû , where œà‚àû is a random variable, which is not almost
surely equal to a deterministic vector, that is P (œà‚àû 6= q0 ) > 0 for all q0 ‚àà Rk .
P
Proof. When +‚àû
n=0 n < +‚àû, the sequence (œàn ) is a (bounded) non-negative almost supermartingale (see
[S17]) because, by (2.7), we have
E[œàn+1 |Fn ] = œàn (1 ‚àí n ) + n p0 ‚â§ œàn + n p0 .
As a consequence, it converges almost surely (and in Lp with p ‚â• 1) to a certain random
P variable œà‚àû . An
alternativeP
proof of this fact follows from quasi-martingale theory [S12]: indeed, since n E[ |E[œàn+1 |Fn ] ‚àí
œàn | ] = O( n n ) < +‚àû, the stochastic process (œàn ) is a non-negative quasi-martingale and so it converges
almost surely (and in Lp with p ‚â• 1) to a certain random variable œà‚àû .
The almost sure convergence of Œæn to œà‚àû follows by Lemma S4.2
(with cn = n and
P and Remark S4.3 P
vN,n = n/N ), because E[Œæn+1 |Fn ] = œàn ‚Üí œà‚àû almost surely and n‚â•1 E[kŒæn k2 ]n‚àí2 ‚â§ n‚â•1 n‚àí2 < +‚àû.
In order to show that œà‚àû is not almost surely equal to a deterministic vector, we set
yn = E[kœàn ‚àí p0 k2 ] ‚àí kE[œàn ‚àí p0 ]k2 =

k
X

V ar[œàn i ‚àí p0 i ]

i=1

and observe that, starting from (2.7), we get
œàn+1 ‚àí p0 = (1 ‚àí n )(œàn ‚àí p0 ) + Œ¥n ‚àÜMn+1

S3

and so
kE[œàn ‚àí p0 ]k2 = E[œàn ‚àí p0 ]> E[œàn ‚àí p0 ] = (1 ‚àí n )2 kE[œàn ‚àí p0 ]k2
and
E[kœàn+1 ‚àí p0 k2 ] = E[(œàn+1 ‚àí p0 )> (œàn+1 ‚àí p0 )]
= (1 ‚àí n )2 E[kœàn ‚àí p0 k2 ] + Œ¥n2 E[k‚àÜMn+1 k2 ] .
Hence, we obtain
yn+1 = (1 ‚àí n )2 yn + Œ¥n2 E[k‚àÜMn+1 k2 ] = (1 ‚àí 2n )yn + Œ∂en

(S2.1)

2
with Œ∂en =
yn + Œ¥n2 E[k‚àÜMn+1 k2 ] ‚â• 0. It
QNn‚àí1
yN ‚â• ynÃÉ n=nÃÉ (1 ‚àí 2n ) for each N ‚â• nÃÉ and

E[kœà‚àû ‚àí p0 k2 ] ‚àí kE[œà‚àû ‚àí p0 ]k2 = y‚àû

follows that, given nÃÉ such that n < 1/2 for n ‚â• nÃÉ, we have
so
!
+‚àû
+‚àû
Y
X
= lim yN ‚â• ynÃÉ
(1 ‚àí 2n ) = ynÃÉ exp
ln(1 ‚àí 2n ) .
N ‚Üí+‚àû

n=nÃÉ

P+‚àû

n=nÃÉ

P+‚àû

The above exponential is strictly greater than 0 because n=nÃÉ ln(1 ‚àí 2n ) ‚àº ‚àí2 n=nÃÉ n > ‚àí‚àû. Therefore,
if ynÃÉ > 0, then we have y‚àû > 0. This means that œà‚àû ‚àí p0 , and consequently œà‚àû , is not almost surely
equal to a deterministic vector, that is P (œà‚àû 6= q0 ) > 0 for all q0 ‚àà Rk . If ynÃÉ = 0, that is if œànÃÉ is almost
e then, by (S2.1), we get
surely equal to a deterministic vector œà,
e 2] > 0 ,
ynÃÉ+1 = Œ¥n2 E[k‚àÜMn+1 k2 ] = Œ¥nÃÉ2 E[kŒænÃÉ+1 ‚àí œàk
e is different from a vector of the canonical base of Rk by means of the
because Œ¥n > 0 for each n and œà
assumption b0 i + B0 i > 0 and equality (2.4). It follows that we can repeat the above argument replacing nÃÉ
by nÃÉ + 1 and conclude that œà‚àû is not almost surely equal to a deterministic vector.
As a consequence of the above theorem, if P
we aim at having the almost sure convergence of ŒæN to a
deterministic vector, we have to avoid the case +‚àû
n=0 n < +‚àû. However, for the sake of completeness, we
provide a second-order convergence result also in this case. First, we note that Theorem S1.1 still holds true
with V = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > . Indeed, assumption (S1.3) is satisfied by Lemma S4.2 and Remark S4.3
(with cn = n and vN,n = n/N ), because of the almost sure convergence of œàn to œà‚àû . Moreover, we have
the following theorem:
Theorem S2.2. Suppose to be in one of the following two cases:
‚àö
‚àö
PN
PN
a)
n=1 nn‚àí1 = o( N ) and
n=1 nŒ¥n‚àí1 = o( N );
b) n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0, Œ¥ ‚àà (1/2, 1) and  > Œ¥ + 1/2 ( = +‚àû included, that
means n = 0 for all n).
Set e = 1/2 and Œª = 1 in case a) and e = Œ¥ ‚àí 1/2 ‚àà (0, 1/2) and Œª = c2 /[2(1 ‚àí e)] = c2 /(3 ‚àí 2Œ¥) in case b).
Then, we have
 s
N e ŒæN ‚àí œàN ‚àí‚Üí N (0, ŒªŒì) ,
where Œì = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > .
When (œàN ‚àí œà‚àû ) = oP (N ‚àíe ), we also have
 s
N e ŒæN ‚àí œà‚àû ‚àí‚Üí N (0, ŒªŒì) .
Note that case a) covers the case n = (n + 1)‚àí and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and min{, Œ¥} > 3/2.
The case n = 0 (that is Œ≤n = 1) for all n corresponds to the case considered in [S15], but in that paper
the author studies only the limit œà‚àû and he does not provide second-order convergence results.
Proof. We have

N e ŒæN ‚àí œàN =

1

1
N 1‚àíe
=


N ŒæN ‚àí N œàN =

N 1‚àíe
N
X

(Œæn ‚àí œàn‚àí1 ) +

n=1

1
N 1/2‚àíe

N
X
n=1

YN,n +

[Œæn ‚àí œàn‚àí1 + n(œàn‚àí1 ‚àí œàn )]

n=1

N
X

1
N 1‚àíe

N
X

N
X

1
N 1‚àíe

nn‚àí1 (œàn‚àí1 ‚àí p0 ) ‚àí

n=1

ZN,n + QN ,

n=1

S4

1
N 1‚àíe

N
X
n=1

nŒ¥n‚àí1 ‚àÜMn

where
YN,n =

Œæn ‚àí œàn‚àí1
‚àÜMn
‚àö
= ‚àö
,
N
N

ZN,n = ‚àí

nŒ¥n‚àí1 (Œæn ‚àí œàn‚àí1 )
nŒ¥n‚àí1 ‚àÜMn
=
N 1‚àíe
N 1‚àíe

and
QN =

1
N 1‚àíe

N
X

nn‚àí1 (œàn‚àí1 ‚àí p0 ).

n=1

P
1‚àíe
) and so QN converges almost surely to 0. Moreover,
In both cases a) and b), we have N
n=1 nn‚àí1 = o(N
PN
by Theorem S1.1, n=1 YN,n stable converges to N (0, V ) with V = Œì = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > . Therefore
P
it is enough to study the convergence of N
n=1 ZN,n . To this purpose, we observe that, if we are in case a),
PN
then n=1 ZN,n converges almost surely to 0 and so
‚àö
 s
N ŒæN ‚àí œàN ‚àí‚Üí N (0, Œì).
PN
Otherwise, if we are in case b), we observe that E[ZN,n |Fn‚àí1 ] = 0 and so
n=1 ZN,n converges stably
to N (0, ŒªŒì) if the conditions (c1) and (c2) of Theorem S6.1, with V = ŒªŒì, hold
‚àö true. Regarding (c1), we
1
observe that max1‚â§n‚â§N |ZN,n | ‚â§ N 1‚àíe
max1‚â§n‚â§N nŒ¥n‚àí1 |Œæn ‚àí œàn‚àí1 | = O(1/ N ). Regarding condition
(c2), that is
N
X

ZN,n ZN,n > =

n=1

N
X

1
N 2(1‚àíe)

P

2
n2 Œ¥n‚àí1
(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> ‚àí‚Üí

n=1

c2
Œì,
2(1 ‚àí e)

PN
2 2
2
2
1
we observe that it holds true even almost surely, because N 2(1‚àíe)
n=1 n Œ¥n‚àí1 ‚Üí c /[2(1 ‚àí e)] = c /(3 ‚àí 2Œ¥)
and
a.s.
E[(Œæn ‚àí œàn‚àí1 )(Œæn ‚àí œàn‚àí1 )> |Fn‚àí1 ] = diag(œàn‚àí1 ) ‚àí œàn‚àí1 œàn‚àí1 > ‚àí‚Üí Œì
2
(see Lemma S4.2 and Remark S4.3 with cn = n and vN,n = n3 Œ¥n‚àí1
/N 2(1‚àíe) ‚àº c2 (n/N )3‚àí2Œ¥ ). Therefore, we
have
 s

N e ŒæN ‚àí œàN ‚àí‚Üí N 0, c2 (3 ‚àí 2Œ¥)‚àí1 Œì .

Finally, we observe that


N e ŒæN ‚àí œà‚àû = N e ŒæN ‚àí œàN + N e (œàN ‚àí œà‚àû ) .
Therefore, when (œàN ‚àí œà‚àû ) = oP (N ‚àíe ), we have
 s
N e ŒæN ‚àí œà‚àû ‚àí‚Üí N (0, ŒªŒì) .

An example of the case a) of Theorem S2.2 with (œàN ‚àí œà‚àû ) = oP (N ‚àíe ) is the RP urn with Œ±n = Œ± > 0
and Œ≤n = Œ≤ > 1 (see [S1]). Indeed, in this case, we have n ‚àº c Œ≤ ‚àín and Œ¥n ‚àº cŒ¥ Œ≤ ‚àín , where c > 0
and cŒ¥ > 0 are suitable constants, and (œàN ‚àí œà‚àû ) = O(Œ≤ ‚àíN ). We conclude this section with other two
examples regarding the case n = 0 (that is Œ≤n = 1) for all n.
Example S2.3. (Case n = 0 and Œ¥n ‚àº c(n + 1)‚àíŒ¥Pwith c > 0 and Œ¥ > 3/2)
n
‚àíŒ¥
If n = 0 for all n, then we have rn‚àó = |b0 | + |B0 | + P
, with Œ¥ > 3/2,
h=1 Œ±h . Therefore, if we take Œ±n = n
‚àíŒ¥
‚àó
‚àíŒ¥
then rn‚àó converges to the constant r‚àó = |b0 | + |B0 | + +‚àû
h
and
Œ¥
=
Œ±
/r
‚àº
cŒ±
,
n
n+1
n+1 = c(n + 1)
n+1
h=1
‚àó
with
c
=
1/r
.
Moreover,
since
Œ¥
>
3/2,
assumption
a)
of
Theorem
S2.2
is
satisfied.
We
also
observe
that
P 2
n Œ¥n < +‚àû and so œà‚àû i is not concentrated on {0, 1} and has no atoms in (0, 1) (see [S15, Th. 2 and
Th. 3]). More precisely, we have
P
b0 + B0 + +‚àû
n=1 Œ±n Œæn
œà‚àû =
P
|b0 | + |B0 | + +‚àû
n=1 Œ±n
and so
œàN ‚àí œà‚àû =
P
P
PN
P
(b0 + B0 + N
n=1 Œ±n Œæn )
n‚â•N +1 Œ±n ‚àí (|b0 | + |B0 | +
n=1 Œ±n )
n‚â•N +1 Œ±n Œæn
=
P
P+‚àû
(|b0 | + |B0 | + N
Œ±
)(|b
|
+
|B
|
+
Œ±
)
0
0
n=1 n
n=1 n
Ô£´
Ô£∂


X
OÔ£≠
Œ±n Ô£∏ = O N 1‚àíŒ¥ .
n‚â•N +1

S5

Since Œ¥ > 3/2, we get (œàN ‚àí œà‚àû ) = o(N ‚àí1/2 ). This fact can also be obtained as a consequence of Theorem
S2.5 below. Indeed, this theorem states that the rate of convergence of œàN to œà‚àû is N ‚àí(Œ¥‚àí1/2) .
Note that, since Œ≤n = 1 for all n, the factor f (h, n) in (2.5) coincides with Œ±h and so, in this case, it is
decreasing.
Example S2.4. (Case n = 0 and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and Œ¥ ‚àà (1/2, 1))
P
As in the
since n = 0 for all n, we have rn‚àó = |b0 | + |B0 | + n
h=1 Œ±h . Let us set
Pn previous example,
Œ±
‚àó
An =
h=1 Œ±h = exp(bn ) with b > 0 and Œ± ‚àà (0, 1/2), which brings to rn ‚àº An ‚Üë +‚àû and Œ±n =
exp(bnŒ± ) ‚àí exp(b(n ‚àí 1)Œ± ) and
Pn‚àí1
Œ±h
Œ±n
Œ¥n‚àí1 =
‚àº 1 ‚àí Ph=1
n
Œ±
|b0 | + |B0 | + An
h=1 h
= 1 ‚àí exp [b ((n ‚àí 1)Œ± ‚àí nŒ± )]



= bnŒ± 1 ‚àí (1 ‚àí n‚àí1 )Œ± + O n2Œ± (1 ‚àí (1 ‚àí n‚àí1 )Œ± )2 = bnŒ± Œ±n‚àí1 + O(n‚àí2 ) + O(n‚àí(2‚àí2Œ±) )
= bŒ±n‚àí(1‚àíŒ±) + O(n‚àí(2‚àíŒ±) ) + O(n‚àí(2‚àí2Œ±) ) = bŒ±n‚àí(1‚àíŒ±) + O(n‚àí2(1‚àíŒ±) ),
so that Œ¥ = (1 ‚àí Œ±) ‚àà (1/2, 1) and c = bŒ± > 0. P
Hence, we have Œ¥n ‚àº c(n + 1)‚àíŒ¥ and assumption b) of
2
Theorem S2.2 is satisfied. We also observe that
n Œ¥n < +‚àû and so œà‚àû i is not concentrated on {0, 1}
and has no atoms in (0, 1) (see [S15,
 Th. 2 and Th. 3]). Moreover, by Theorem S2.5 below, we get that
N e (œà N ‚àí œà‚àû ) ‚àí‚ÜíN 0, c2 (2e)‚àí1 Œì , where e = Œ¥ ‚àí 1/2. Hence, applying Theorem S6.3, we obtain

 s
N e ŒæN ‚àí œà‚àû ‚àí‚Üí N 0, c2 [2e(1 ‚àí e)]‚àí1 Œì .
Finally, note that, as before, since Œ≤n = 1 for all n, the factor f (h, n) in (2.5) coincides with Œ±h and so, in
this case, `(h) = ln(f (h, n)) = ln(Œ±h ) ‚àº ln(Œ¥h‚àí1 ) + bhŒ± ‚àº bhŒ± ‚àí bŒ±(1 ‚àí Œ±) ln(h). Hence, there exists h‚àó such
that h 7‚Üí `(h) is increasing for h ‚â• h‚àó . Since maxh‚â§h‚àó `(h) ‚â§ C, for a suitable constant C, the contributions
of the observations until h‚àó are eventually smaller than those with h ‚â• h‚àó , that are increasing with h.
Theorem S2.5. For n = 0 for all n and Œ¥n ‚àº c(n + 1)‚àíŒ¥ with c > 0 and 1/2 < Œ¥ ‚â§ 1, we have

1
N Œ¥‚àí 2 (œà N ‚àí œà‚àû ) ‚àí‚ÜíN 0, c2 (2Œ¥ ‚àí 1)‚àí1 Œì
stably in the strong sense w.r.t. F,
where Œì = diag(œà‚àû ) ‚àí œà‚àû œà‚àû > .
Proof. We want to apply Theorem S6.2. To this purpose, we recall that, when n = 0 for all n, the process
(œàn ) is a martingale with respect to F. Moreover, it converges almost surely and in mean to œà‚àû . Therefore,
in order to conclude, it is enough to check conditions (c1) and (c2) of Theorem S6.2. Regarding the first
condition, we note that
N Œ¥‚àí1/2 sup |œàn ‚àí œàn+1 | = N Œ¥‚àí1/2 sup Œ¥n |‚àÜMn+1 | = O(N Œ¥‚àí1/2‚àíŒ¥ ) = O(N ‚àí1/2 ) ‚àí‚Üí 0.
n‚â•N

n‚â•N

Finally, regarding the second condition, we observe that
X
X
N 2Œ¥‚àí1
(œàn ‚àí œàn+1 )(œàn ‚àí œàn+1 )> ‚àº N 2Œ¥‚àí1 c2
(n + 1)‚àí2Œ¥ (‚àÜMn+1 )(‚àÜMn+1 )>
n‚â•N

n‚â•N
a.s.

‚àí‚Üí

2

c
Œì,
(2Œ¥ ‚àí 1)

where the almost sure convergence follows from [S6, Lemma 4.1] and the fact that
a.s.

E[(‚àÜMn+1 )(‚àÜMn+1 )> |Fn ] = E[(Œæn+1 ‚àí œàn )(Œæn+1 ‚àí œàn )> |Fn ] ‚àí‚Üí Œì.

S3

Computations regarding the local reinforcement

Suppose Œ±n ‚àº an‚àíŒ± for n ‚â• 1 and (1Q‚àí Œ≤n ) ‚àº b(n + 1)‚àíŒ≤ for n ‚â• 0. In the following subsections we study the
behaviour of the factor f (h, n) = Œ±h n‚àí1
j=h Œ≤j in some particular cases that cover the cases of the two examples
Qn‚àí1
P
in Section 4. Specifically, for all the considered cases, we set `(h, n) = ln(Œ±h j=h
Œ≤j ) = ln(Œ±h )+ n‚àí1
j=h ln(Œ≤j )
for n ‚â• h and we prove that there exists h‚àó such that maxh‚â§h‚àó `(h, n) ‚â§ `(h‚àó , n) and h 7‚Üí `(h, n) is increasing
for h ‚â• h‚àó . This means that the weights f (h, n) of the observations until h‚àó are smaller than those with
h ‚â• h‚àó and the contribution of the observation for h ‚â• h‚àó is increasing with h.

S6

S3.1

Case Œ± = Œ≤ ‚àà (0, 1)

Suppose Œ±n = an‚àíŒ± and 1 ‚àí Œ≤n = b(n + 1)‚àíŒ± , with a, b > 0 and Œ± ‚àà (0, 1). For n ‚â• h, we have
`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àíŒ± ) ‚àí ln(ah‚àíŒ± ) ‚àí ln(1 ‚àí b(h + 1)‚àíŒ± )



1
b
Œ±
b
= ‚àíŒ± ln 1 +
‚àí ln 1 ‚àí
=‚àí +
.
Œ±
h
(h + 1)
h
(h + 1)Œ±
Since Œ± < 1, there exists h0 such that the function h 7‚Üí `(h, n) is monotonically increasing for h ‚â• h0 . Now,
‚àíŒ±
fix Œ∑ > 0 and let j0 such that j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj1+Œ∑ . Then take h‚àó ‚â• max(h0 , j0 ) + 1 and h ‚â§ h0 ‚àí 1.
For h‚àó large enough, we get
`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

‚àíŒ±
ln(Œ≤j ) = ln(ah‚àíŒ±
)‚àí
‚àó ) ‚àí ln(ah

j=h

‚â• ln(h‚àíŒ±
‚àó )+

hX
‚àó ‚àí1
j=max(h0 ,j0 )

‚â• ‚àíŒ± ln(h‚àó ) + C1 +

hX
‚àó ‚àí1

ln(Œ≤j )

j=h

bj ‚àíŒ±
1+Œ∑
Z h‚àó ‚àí1

b
1+Œ∑

x‚àíŒ± dx

max(h0 ,j0 )



b
(h‚àó ‚àí 1)1‚àíŒ± ‚àí max(h0 , j0 )1‚àíŒ±
(1 + Œ∑)(1 ‚àí Œ±)
b
= C2 ‚àí Œ± ln(h‚àó ) +
(h‚àó ‚àí 1)1‚àíŒ± ‚â• 0 .
(1 + Œ∑)(1 ‚àí Œ±)
= ‚àíŒ± ln(h‚àó ) + C1 +

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n) ‚à® maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S3.2

Case Œ± = Œ≤ = 1

Suppose Œ±n = an‚àí1 and 1 ‚àí Œ≤n = b(n + 1)‚àí1 , with a > 0 and b > 1. For n ‚â• h, we have
`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àí1 ) ‚àí ln(ah‚àí1 ) ‚àí ln(1 ‚àí b(h + 1)‚àí1 )


b 
b‚àí1
1
‚àí ln 1 ‚àí
=
+ o(h‚àí1 ).
= ‚àí ln 1 +
h
(h + 1)
h+1
Since b > 1, we can argue as in the previous subsection. Therefore, there exists h0 such that the function
h 7‚Üí `(h, n) is monotonically increasing for h ‚â• h0 . Now, fix Œ∑ = (b ‚àí 1)/(b + 1) > 0 and let j0 such that
‚àí1
j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj
. Then take h‚àó ‚â• max(h0 , j0 ) + 1 and h ‚â§ h0 ‚àí 1. For h‚àó large enough, we get
1+Œ∑
`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

‚àí1
ln(Œ≤j ) = ln(ah‚àí1
)‚àí
‚àó ) ‚àí ln(ah

j=h

‚â• ln(h‚àí1
‚àó )+

hX
‚àó ‚àí1
j=max(h0 ,j0 )

‚â• ‚àí ln(h‚àó ) + C1 +
= ‚àí ln(h‚àó ) + C1 +

b
1+Œ∑

hX
‚àó ‚àí1

ln(Œ≤j )

j=h

bj ‚àí1
1+Œ∑
Z h‚àó ‚àí1

x‚àí1 dx

max(h0 ,j0 )


b 
ln(h‚àó ‚àí 1) ‚àí ln(max(h0 , j0 ))
(1 + Œ∑)

b‚àí1‚àíŒ∑
ln(h‚àó ) ‚àí O(1/h‚àó )
(1 + Œ∑)
b(b ‚àí 1)
= C2 +
ln(h‚àó ) ‚àí O(1/h‚àó ) ‚â• 0 .
2b

= C2 +

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n) ‚à® maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S7

S3.3

Case 0 < Œ± < Œ≤ < (1 + Œ±)/2

Suppose


c3
+ O(1/n2‚àíŒ≤ )
n
and 1 ‚àí Œ≤n = b(n + 1)‚àíŒ≤ , with a, b > 0, 0 < Œ± < Œ≤ < (1 + Œ±)/2 and c1 , c2 , c3 ‚àà R. Set Œ≥ = Œ≤ ‚àí Œ± ‚àà (0, 1/2).
For n ‚â• h, we have

Œ±n = an‚àíŒ± 1 +

c1
n1‚àíŒ≤

+

c2
nŒ≤‚àíŒ±

+

`(h + 1, n) ‚àí `(h, n) = ln(a(h + 1)‚àíŒ± ) ‚àí ln(ah‚àíŒ± ) ‚àí ln(1 ‚àí b(h + 1)‚àíŒ≤ )
+ ln 1 + c1 /(h + 1)1‚àíŒ≤ + c2 /(h + 1)Œ≥ + c3 /(h + 1) + O(1/h2‚àíŒ≤ )

‚àí ln 1 + c1 /h1‚àíŒ≤ + c2 /hŒ≥ + c3 /h + O(1/h2‚àíŒ≤ ) .



(S3.1)

Now, we aim at obtaining a series expansion with a reminder term of the type o(1/hŒ≤ ). Since Œ≤ < 1, the
first three terms of the right-hand side of the above equation give



b
b
1
ln(a(h + 1)‚àíŒ± ) ‚àí ln(ah‚àíŒ± ) ‚àí ln(1 ‚àí b(h + 1)‚àíŒ≤ ) = ‚àíŒ± ln 1 +
‚àí ln 1 ‚àí
=
+ o(h‚àíŒ≤ ).
Œ≤
h
(h + 1)
(h + 1)Œ≤
We deal now with the last two terms of (S3.1). We recall that
ln(1 + x) = x ‚àí

x2
x3
xj
+
+ ¬∑ ¬∑ ¬∑ + (‚àí1)j‚àí1
+ o(xj ) ,
2
3
j

and therefore, since 2 ‚àí Œ≤ = 1 + 1 ‚àí Œ≤ > 1 > Œ≤ and j(1 ‚àí Œ≤) > Œ≤ and jŒ≥ = j(Œ≤ ‚àí Œ±) > Œ≤ for j large enough,
there are only a finite number J0 of terms with an order œÑj ‚â§ Œ≤. In other words, we can write

ln 1 + c1 /(h + 1)1‚àíŒ≤ + c2 /(h + 1)Œ≥ + c3 /(h + 1) + O(1/n2‚àíŒ≤ )

‚àí ln 1 + c1 /h1‚àíŒ≤ + c2 /hŒ≥ + c3 /h + O(1/n2‚àíŒ≤ )
=

J0
X

Cj (h + 1)‚àíœÑj ‚àí

=

Cj h‚àíœÑj + o(1/hŒ≤ )

j=1

j=1
J0
X

J0
X

J0
X




Cj h‚àíœÑj (1 + h‚àí1 )‚àíœÑj ‚àí 1 + o(1/hŒ≤ )
Cj (h + 1)‚àíœÑj ‚àí h‚àíœÑj + o(1/hŒ≤ ) =
j=1

j=1
J0

=

X


Cj h‚àíœÑj (œÑj h‚àí1 + o(1/h) + o(1/hŒ≤ ) = o(1/hŒ≤ ) .

j=1

Summing up, we have
b
+ o(h‚àíŒ≤ ).
(h + 1)Œ≤
Then there exists h0 such that the function h 7‚Üí `(h, n) is monotonically increasing for h ‚â• h0 . Now, fix
‚àíŒ≤
. Then take h‚àó ‚â• max(h0 , j0 ) + 1 and h ‚â§ h0 ‚àí 1.
Œ∑ > 0 and let j0 such that j ‚â• j0 implies ln(Œ≤j ) ‚â§ ‚àí bj
1+Œ∑
Since Œ≤ < (1 + Œ±)/2, we have Œ±n = an‚àíŒ± (1 + O(1/nŒ≥ )) and so, for h‚àó large enough, we get
`(h + 1, n) ‚àí `(h, n) =

`(h‚àó , n) ‚àí `(h, n) = ln(Œ±h‚àó ) ‚àí ln(Œ±h ) ‚àí

hX
‚àó ‚àí1

ln(Œ≤j )

j=h
‚àíŒ±
= ln(ah‚àíŒ±
) + ln(1 + O(h‚àíŒ≥
‚àó ) ‚àí ln(ah
‚àó )) + C1 ‚àí

hX
‚àó ‚àí1

ln(Œ≤j )

j=h
hX
‚àó ‚àí1

‚àíŒ≥
‚â• ln(h‚àíŒ±
‚àó ) + ln(1 + O(h‚àó )) + C1 +

j=max(h0 ,j0 )

b
‚â• ‚àíŒ± ln(h‚àó ) + O(h‚àíŒ≥
‚àó ) + C2 +
1+Œ∑

Z

h‚àó ‚àí1

bj ‚àíŒ≤
1+Œ∑
x‚àíŒ≤ dx

max(h0 ,j0 )



b
(h‚àó ‚àí 1)1‚àíŒ≤ ‚àí max(h0 , j0 )1‚àíŒ≤
(1 + Œ∑)(1 ‚àí Œ≤)
b
‚àíŒ≥
= C3 + O(h‚àó ) ‚àí Œ± ln(h‚àó ) +
(h‚àó ‚àí 1)1‚àíŒ≤ ‚â• 0 .
(1 + Œ∑)(1 ‚àí Œ≤)

= ‚àíŒ± ln(h‚àó ) + O(h‚àíŒ≥
‚àó ) + C2 +

S8

Therefore, taking h‚àó large enough, we have maxh‚â§h‚àó `(h, n) = maxh‚â§h0 ‚àí1 `(h, n) ‚à® maxh0 ‚â§h‚â§h‚àó `(h, n) ‚â§
`(h‚àó , n).

S4

Technical results

We recall the generalized Kronecker lemma [S3, Corollary A.1]:
Lemma S4.1. (Generalized Kronecker Lemma)
Let {vN,n : 1 ‚â§ n ‚â§ N } and (zn )n be respectively a triangular array and a sequence of complex numbers such
that vN,n 6= 0 and
lim vN,n = 0,

lim vn,n exists finite,
n

N

and

P

n

zn is convergent. Then limN

N
X

|vN,n ‚àí vN,n‚àí1 | = O(1)

n=1

PN

n=1

vN,n zn = 0.

The above corollary is useful to get the following result for complex random variables, which slightly
extends the version provided in [S3, Lemma A.2]:
Lemma S4.2. Let H = (Hn )n be a filtration and (Yn )n a H-adapted sequence

 random variables.
P of complex
Moreover, let (cn )n be a sequence of strictly positive real numbers such that n E |Yn |2 /c2n < +‚àû and let
{vN,n , 1 ‚â§ n ‚â§ N } be a triangular array of complex numbers such that vN,n 6= 0 and
lim vN,n = 0,
N

lim vn,n exists finite,
n

N
X

|vN,n ‚àí vN,n‚àí1 | = O(1) .

n=1

Suppose that
N
X

vN,n

n=1

where V is a suitable random variable. Then

E[Yn |Hn‚àí1 ] P
‚àí‚Üí V,
cn

PN

n=1

(S4.1)

P

vN,n Yn /cn ‚àí‚Üí V .

If the convergence in (S4.1) is almost sure, then also the convergence of
almost sure.

PN

n=1

vN,n Yn /cn toward V is

Proof. Consider the martingale (Mn )n defined by
Mn =
It is bounded in L2 since

P

n

E[|Yn |2 ]
c2
n

n
X
Yj ‚àí E[Yj |Hj‚àí1 ]
.
cj
j=1

< +‚àû by assumption and so it is almost surely convergent, that means

X Yn (œâ) ‚àí E[Yn |Hn‚àí1 ](œâ)
< +‚àû
cn
n
Y (œâ)‚àíE[Yn |Hn‚àí1 ](œâ)
,
cn

for œâ ‚àà B with P (B) = 1. Therefore, fixing œâ ‚àà B and setting zn = n
we get
N
X
Yn (œâ) ‚àí E[Yn |Hn‚àí1 ](œâ)
lim
vN,n
= 0,
N
cn
n=1
that is
N
X
n=1

vN,n

Yn ‚àí E[Yn |Hn‚àí1 ] a.s.
‚àí‚Üí 0.
cn

In order to conclude, it is enough to observe that
N
X

vN,n

n=1

N
N
X
Yn ‚àí E[Yn |Hn‚àí1 ] X
E[Yn |Hn‚àí1 ]
Yn
=
vN,n
+
vN,n
cn
c
cn
n
n=1
n=1

and use assumption (S4.1).

S9

by Lemma S4.1,

PN |vN,n |
P
a.s.
vN,n
Remark S4.3. If we have
= O(1), limN N
= Œª ‚àà C and E[Yn |Hn‚àí1 ] ‚àí‚Üí Y , then
n=1
n=1 cn
cn
(S4.1) is satisfied with almost sure convergence and V = ŒªY . Indeed, if we denote by A an event such that
P (A) = 1 and limn E[Yn |Hn‚àí1 ](œâ) = Y (œâ) for each œâ ‚àà A, then we can fix œâ ‚àà A, set wn = E[Yn |Hn‚àí1 ](œâ)
and w = Y (œâ), and apply the generalized Toeplitz lemma [S3, Lemma A.1] (with zN,n
n Œª) and
P = vN,n /(c
wn
s = 1 when Œª 6= 0 and with zN,n = vN,n /cn and s = 0 when Œª = 0) in order to get N
n=1 vN,n cn ‚Üí ŒªY
almost surely.
The proof of the following lemma can be found in [S8]. We here rewrite the proof only for the reader‚Äôs
convenience.
Lemma S4.4. ([S8], Lemma 18)
Let xn , Œ∂n , Œ≥n be non-negative sequences such that Œ≥n ‚Üí 0,

P

n

Œ≥n = +‚àû and

xn ‚â§ (1 ‚àí Œ≥n )xn‚àí1 + Œ≥n Œ∂n .
Then lim supn xn ‚â§ lim supn Œ∂n .
Proof. Take L > lim supn Œ∂n and n‚àó large enough so that Œ∂n < L and Œ≥n ‚â§ 1 when n ‚â• n‚àó . Then, using
that (x + y)+ ‚â§ x+ + y + , we have for n ‚â• n‚àó
(xn ‚àí L)+ ‚â§ ((1 ‚àí Œ≥n )(xn‚àí1 ‚àí L) + Œ≥n (Œ∂n ‚àí L))+
‚â§ (1 ‚àí Œ≥n )(xn‚àí1 ‚àí L)+ + Œ≥n (Œ∂n ‚àí L)+
‚â§ (1 ‚àí Œ≥n )(xn‚àí1 ‚àí L)+ .
P
+
Since
= 0. This is enough to conclude,
n Œ≥n = +‚àû, the above inequality implies that limn (xn ‚àí L)
because we can choose L arbitrarily close to lim supn Œ∂n .

S5

Some stochastic approximation results

Consider a stochastic process (Œ∏n ) taking values in Œò = [‚àí1, 1]k , adapted to a filtration F = (Fn )n and
following the dynamics
Œ∏n+1 = (1 ‚àí n )Œ∏n + cn ‚àÜMn+1 ,
(S5.1)
where c > 0, (‚àÜMn+1 )n is a uniformly bounded martingale difference sequence with respect to F and
P
fn+1 = c‚àÜMn+1 , equation
n = (n + 1)‚àí with  ‚àà (0, 1] so that n ‚Üí 0 and n n = +‚àû. Setting ‚àÜM
(S5.1) becomes
fn+1 .
Œ∏n+1 = (1 ‚àí n )Œ∏n + n ‚àÜM
Then:
a.s.

Theorem S5.1. In the above setting, we have Œ∏N ‚àí‚Üí 0 .
Proof. We have the following two cases:
P
‚Ä¢  ‚àà (1/2, 1] so that n 2n < +‚àû or
P
‚Ä¢  ‚àà (0, 1/2] so that n 2n = +‚àû.
For the first case, we refer to [S11, Cap. 5, Th. 2.1]. For the second case, we refer to [S11, Cap. 5, Th. 3.1]).
fn ) are uniformly bounded, the key assumption to be verified in order to
In this case, since (Œ∏n ) and (‚àÜM
apply [S11, Cap. 5, Th. 3.1] is the ‚Äúrate of change‚Äù condition (see [S11, p. 137]), that is
lim sup sup |M 0 (N + t) ‚àí M 0 (N )| = 0,
N

a.s.

t‚àà[0,1]

Pm(t)‚àí1
fj+1 and m(t) = inf{n : t < tn+1 = Pn j } (see [S11, p. 122]). Since
where M 0 (t) =
j ‚àÜM
j=0
j=0
fn ) is uniformly bounded, the above condition is satisfied when the following simpler conditions are
(‚àÜM
satisfied (see [S11, pp. 139-141]):
P
(i) For each u > 0 n e‚àíu/n < +‚àû;
(ii) For some T < +‚àû, there exists a constant c(T ) < +‚àû such that supn‚â§j‚â§m(tn +T )

S 10

j
n

‚â§ c(T ).

‚àí

When n = (1 + n)‚àí , condition (i) is obviously verified, because we have limn n2 /eu(1+n) = 0. Finally,
condition (ii) is always satisfied when n is decreasing, as it is in the case n = (1 + n)‚àí . Indeed, we simply
have supn‚â§j‚â§m(tn +T ) j /n = n /n = 1.
a.s.

Theorem S5.2. In the above setting, if we have E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì with Œì a symmetric positive
definite matrix, then we have
1
d
‚àö Œ∏N ‚àí‚Üí N (0, Œ£),
N
where Œ£ = c2 Œì/2 when  ‚àà (0, 1) and Œ£ = c2 Œì when  = 1.
a.s.

Proof. We have Œ∏N ‚àí‚Üí 0 and 0 belongs to the interior part of Œò. Moreover, we have
a.s. 2
fn+1 ‚àÜM
fn+1 > |Fn ] ‚àí‚Üí
E[‚àÜM
c Œì.

For the case  ‚àà (1/2, 1], we refer to [S9, Th. 2.1] (with h = Id, U‚àó = c2 Œì and Œ≥‚àó = 1) and [S14, Th. 1]
(with H = ‚àíId, Œ≥n = œÉn = n and so Œ≥0 = 1 and Œ≤ = ). For the case  ‚àà (0, 1/2], we refer to [S11, cap.10,
‚àö
Th. 2.1] (with A = ‚àíId). The key assumption for applying this theorem is Œ∏n / n tight. On the other
hand, in the considered setting, this last condition is satisfied because of [S11, Th. 4.1]. Note that the limit
distribution corresponds to the stationary distribution of the diffusion
dUt = (‚àíId + c()) Ut dt + cŒì1/2 dWt ,
where W = (Wt )t is a standard Wiener process and
(
0 for  < 1
c() =
1/2 for  = 1.
Therefore the limit covariance matrix is determined by solving the associated Lyapunov‚Äôs equation [S14],
that, in the considered case, simply is
2 (‚àíId + c()Id) Œ£ = ‚àíc2 Œì.

Theorem S5.3. In the above setting, let (¬µn ) be another stochastic process taking values in Œò = [‚àí1, 1]k ,
adapted to a filtration F and following the dynamics
1
1
¬µn+1 ‚àí ¬µn = ‚àí (¬µn ‚àí Œ∏n ) + ‚àÜMn+1 .
n
n
a.s.

Suppose that E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì. If  ‚àà (1/2, 1), then we have
!
‚àö
 

(c + 1)2 Œì
0
N ¬µN
d
‚àí‚Üí
N
0,
.
2
‚àí1/2
c
0
Œì
N Œ∏ N
2
If  = 1, then we have
!
‚àö
 
N ¬µN
[(c + 1)2 + c2 ]Œì
d
‚àí‚Üí N 0,
‚àí1/2
c(c + 1)Œì
N Œ∏ N

c(c + 1)Œì
c2 Œì


.

Proof. The dynamics for the pair (¬µn , Œ∏n )n is
(
¬µn+1 ‚àí ¬µn = ‚àí n1 (¬µn ‚àí Œ∏n ) + n1 ‚àÜMn+1
fn+1 .
Œ∏n+1 ‚àí Œ∏n = ‚àín Œ∏n + cn ‚àÜMn+1 = ‚àín Œ∏n + n ‚àÜM
a.s.

with E[‚àÜMn+1 ‚àÜMn+1 > |Fn ] ‚àí‚Üí Œì. Therefore, when 1/2 <  < 1, the statement follows from [S13] (with
Q11 = Q22 = ‚àíId, Q12 = Id, Q21 = 0, b = Œ≤0 = 1, a = , Œì11 = Œì, Œì22 = c2 Œì and Œì12 = Œì21 = cŒì).
In particular, the two blocks of the limit covariance matrix, say Œ£¬µ and Œ£Œ∏ , are determined solving the
equations
1
1
(H + Id)Œ£¬µ + Œ£¬µ (H > + Id) = ‚àíŒì¬µ ,
2
2

S 11

‚àí1
‚àí1 > >
‚àí1 > >
where H = Q11 ‚àí Q12 Q‚àí1
22 Q21 = ‚àíId + 0 and Œì¬µ = Œì11 + Q12 Q22 Œì22 (Q22 ) Q12 ‚àí Œì12 (Q22 ) Q12 ‚àí
2
2
Q12 Q‚àí1
Œì
=
Œì
+
c
Œì
+
cŒì
+
cŒì
=
(c
+
1)
Œì,
and
22 21

Q22 Œ£Œ∏ + Œ£Œ∏ Q>
22 = ‚àíŒì22 .
When  = 1, we can conclude by [S14] or [S19] taking Xn = (¬µn , Œ∏n )> . Indeed, in this case the
covariance matrix is given by
1
1
e
(H + Id)Œ£ + Œ£(H > + Id) = ‚àíŒì,
2
2
where




‚àíId
Id
cŒì
e= Œì
H=
and Œì
.
0
‚àíId
cŒì c2 Œì
Therefore, if we split Œ£ in blocks, say Œ£¬µ , Œ£Œ∏ and Œ£¬µŒ∏ , we find the system
‚àíŒ£¬µ + 2Œ£¬µŒ∏ = ‚àíŒì
‚àíŒ£¬µŒ∏ + Œ£Œ∏ = ‚àícŒì
‚àíŒ£Œ∏ = ‚àíc2 Œì
and so the proof is concluded by solving this system.

S6

Stable convergence

This brief section contains some basic definitions and results concerning stable convergence. For more details, we refer the reader to [S5, S7, S10] and the references therein.
Let (‚Ñ¶, A, P ) be a probability space, and let S be a Polish space, endowed with its Borel œÉ-field. A kernel
on S, or a random probability measure on S, is a collection K = {K(œâ) : œâ ‚àà ‚Ñ¶} of probability measures
on the Borel œÉ-field of S such that, for each bounded Borel real function f on S, the map
Z
œâ 7‚Üí Kf (œâ) = f (x) K(œâ)(dx)
is A-measurable. Given a sub-œÉ-field H of A, a kernel K is said H-measurable if all the above random
variables Kf are H-measurable. A probability measure ŒΩ can be identified with a constant kernel K(œâ) = ŒΩ
for each œâ.
On (‚Ñ¶, A, P ), let (Yn )n be a sequence of S-valued random variables, let H be a sub-œÉ-field of A, and let
K be a H-measurable kernel on S. Then, we say that Yn converges H-stably to K, and we write Yn ‚àí‚Üí K
H-stably, if
weakly
P (Yn ‚àà ¬∑ | H) ‚àí‚Üí E [K(¬∑) | H]
for all H ‚àà H with P (H) > 0,
where K(¬∑) denotes the random variable defined, for each Borel set B of S, as œâ 7‚Üí KIB (œâ) = K(œâ)(B). In
the case when H = A, we simply say that Yn converges stably to K and we write Yn ‚àí‚Üí K stably. Clearly, if
Yn ‚àí‚Üí K H-stably, then Yn converges in distribution to the probability distribution E[K(¬∑)]. The H-stable
convergence of Yn to K can be stated in terms of the following convergence of conditional expectations:
E[f (Yn ) | H]

œÉ(L1 , L‚àû )

‚àí‚Üí

Kf

(S6.1)

for each bounded continuous real function f on S. In [S7] the notion of H-stable convergence is firstly
generalized in a natural way replacing in (S6.1) the single sub-œÉ-field H by a collection G = (Gn ) (called
conditioning system) of sub-œÉ-fields of A and then it is strengthened by substituting the convergence in
œÉ(L1 , L‚àû ) by the one in probability (i.e. in L1 , since f is bounded). Hence, according to [S7], we say that
Yn converges to K stably in the strong sense, with respect to G = (Gn ), if
P

E [f (Yn ) | Gn ] ‚àí‚Üí Kf
for each bounded continuous real function f on S.
We now conclude this section recalling some convergence results that we apply in our proofs.
From [S10, Th. 3.2] (see also [S7, Th. 5 and Cor. 7] or [S5, Th. 5.5.1 and Cor. 5.5.2]), we get:

S 12

Theorem S6.1. Given a filtration F = (Fn )n , let (YN,n )N,n be a triangular array of random variables
with values in Rk such that YN,n is Fn -measurable and E[YN,n |Fn‚àí1 ] = 0. Suppose that the following two
conditions are satisfied:
(c1) E [ max1‚â§n‚â§N |YN,n | ] ‚Üí 0 and
PN
> P
‚àí‚Üí V , where V is a random variable with values in the space of positive semidefinite
(c2)
n=1 YN,n YN,n
k √ó k-matrices.
P
Then N
n=1 YN,n converges stably to the Gaussian kernel N (0, V ).
From [S7, Th. 5, Cor. 7, Rem. 4] or [S5, Th. 5.5.1, Cor. 5.5.2, Rem. 5.5.2]), we obtain:
Theorem S6.2. Let (Ln ) be a Rk -valued martingale with respect to the filtration F = (Fn ). Suppose that
a.s., L1

Ln ‚àí‚Üí L for some Rk -valued random variable L and
(c1) ne E[supj‚â•n |Lj‚àí1 ‚àí Lj | ] ‚àí‚Üí 0 and
P
P
(c2) n2e j‚â•n (Lj‚àí1 ‚àí Lj )(Lj‚àí1 ‚àí Lj )> ‚àí‚Üí V , where V is a random variable with values in the space of
positive semidefinite k √ó k-matrices.
Then

ne Ln ‚àí L ‚àí‚Üí N (0, V )

stably in strong sense w.r.t. F.

P Indeed, following [S7, Example 6], it is enough to observe that Ln ‚àí L can be written as Ln ‚àí L =
j‚â•n (Lj ‚àí Lj+1 ).
Finally, the following result combines together a stable convergence and a stable convergence in the
strong sense [S4, Lemma 1].
Theorem S6.3. Suppose that Cn and Dn are S-valued random variables, that M and N are kernels on S,
and that G = (Gn )n is an (increasing) filtration satisfying for all n

S
œÉ(Cn )‚äÇGn and œÉ(Dn )‚äÇœÉ
n Gn .
If Cn stably converges to M and Dn converges to N stably in the strong sense, with respect to G, then
[Cn , Dn ] ‚àí‚Üí M ‚äó N

stably.

(Here, M ‚äó N is the kernel on S √ó S such that (M ‚äó N )(œâ) = M (œâ) ‚äó N (œâ) for all œâ.)
This last result contains as a special case the fact that stable convergence and convergence in probability
combine well: that is, if Cn stably converges to M and Dn converges in probability to a random variable D,
then (Cn , Dn ) stably converges to M ‚äó Œ¥D , where Œ¥D denotes the Dirac kernel concentrated in D.

SR References
[S1] G. Aletti and I. Crimaldi. The rescaled PoÃÅlya urn: local reinforcement and chi-squared goodness of
fit test. arXiv:1906.10951, 2019.
[S2] G. Aletti and I. Crimaldi. Generalized rescaled PoÃÅlya urn and its statistical applications. Main Article
of this supplementary material, 2020.
[S3] G. Aletti, I. Crimaldi, and A. Ghiglietti. Networks of reinforced stochastic processes: asymptotics for
the empirical means. Bernoulli, 25(4B):3339‚Äì3378, 2019.
[S4] P. Berti, I. Crimaldi, L. Pratelli, and P. Rigo. A central limit theorem and its applications to multicolor
randomly reinforced urns. J. Appl. Probab., 48(2):527‚Äì546, 2011.
[S5] I. Crimaldi. Introduzione alla nozione di convergenza stabile e sue varianti (Introduction to the notion
of stable convergence and its variants), volume 57. Unione Matematica Italiana, Monograf s.r.l.,
Bologna, Italy., 2016. Book written in Italian.
[S6] I. Crimaldi, P. Dai Pra, and I. G. Minelli. Fluctuation theorems for synchronization of interacting
PoÃÅlya‚Äôs urns. Stochastic Process. Appl., 126(3):930‚Äì947, 2016.
[S7] I. Crimaldi, G. Letta, and L. Pratelli. A Strong Form of Stable Convergence, volume 1899, pages
203‚Äì225. Springer, 2007.

S 13

[S8] B. Delyon. Stochastic approximation with decreasing gain: Convergence and asymptotic theory.
Technical report, 2000.
[S9] G. Fort. Central limit theorems for stochastic approximation with controlled markov chain dynamics.
ESAIM: PS, 19:60‚Äì80, 2015.
[S10] P. Hall and C. C. Heyde. Martingale limit theory and its application. Academic Press Inc. [Harcourt
Brace Jovanovich Publishers], New York, 1980. Probability and Mathematical Statistics.
[S11] H. J. Kushner and G. G. Yin. Stochastic approximation and recursive algorithms and applications,
volume 35 of Applications of Mathematics (New York). Springer-Verlag, New York, second edition,
2003. Stochastic Modelling and Applied Probability.
[S12] M. MeÃÅtivier. Semimartingales. Walter de Gruyter and Co., Berlin, 1982.
[S13] A. Mokkadem and M. Pelletier. Convergence rate and averaging of nonlinear two-time-scale stochastic
approximation algorithms. Ann. Appl. Probab., 16(3):1671‚Äì1702, 08 2006.
[S14] M. Pelletier. Weak convergence rates for stochastic approximation with application to multiple targets
and simulated annealing. Ann. Appl. Probab., 8(1):10‚Äì44, 1998.
[S15] R. Pemantle. A time-dependent version of poÃÅlya‚Äôs urn. J. Theor. Probab., 3:627‚Äì637, 1990.
[S16] J. N. K. Rao and A. J. Scott. The analysis of categorical data from complex sample surveys: chi-squared
tests for goodness of fit and independence in two-way tables. J. Amer. Statist. Assoc., 76(374):221‚Äì230,
1981.
[S17] H. Robbins and D. Siegmund. A convergence theorem for non negative almost supermartingales and
some applications. In Optimizing Methods in Statistics, pages 233‚Äì257. Academic Press, 1971.
[S18] J. Sherman and W. J. Morrison. Adjustment of an inverse matrix corresponding to a change in one
element of a given matrix. Ann. Math. Statist., 21(1):124‚Äì127, 03 1950.
[S19] L.-X. Zhang. Central limit theorems of a recursive stochastic algorithm with applications to adaptive
designs. Ann. Appl. Probab., 26(6):3630‚Äì3658, 2016.

S 14

