Remote teaching data-driven physical modeling through a COVID-19 data challenge.
Marco Cosentino Lagomarsino,1, 2 Guglielmo Pacifico,3 Valerio Firmano,3 Edoardo Bella,3 Pietro
Benzoni,3 Jacopo Grilli,4 Federico Bassetti,5 Fabrizio Capuani,6 Pietro Cicuta,7 and Marco Gherardi2

arXiv:2104.09394v1 [physics.ed-ph] 19 Apr 2021

2

1
IFOM Foundation, FIRC Institute of Molecular Oncology, Milan, Italy
Dipartimento di Fisica, Università degli Studi di Milano, and I.N.F.N, via Celoria 16 Milano, Italy∗
3
Dipartimento di Fisica, Università degli Studi di Milano, via Celoria 16 Milano, Italy
4
The Abdus Salam International Centre for Theoretical Physics (ICTP), Trieste, Italy.
5
Politecnico di Milano, Piazza Leonardo da Vinci 32, Milano, Italy
6
I.N.F.N. Sezione di Roma - Sapienza. Piazzale Aldo Moro 2, Roma, Italy
7
Cavendish Laboratory, Cambridge University, Cambridge, United Kingdom

Physics can be seen as a conceptual approach to scientific problems, a method for discovery, but
teaching this aspect of our discipline can be a challenge. We report on a first-time remote teaching
experience for a computational physics third-year physics laboratory class taught in the first part of
the 2020 COVID-19 pandemic (March-May 2020). To convey a “physics of data” approach to data
analysis and data-driven physical modeling we used interdisciplinary data sources, with a “COVID19 data challenge” theme as the core of the course. COVID-19 epidemiological data provided an
ideal setting for the students to practice dealing with complex problems, where there is no unique or
preconceived solution. By breaking the students’ expectations of unidirectionality, remote teaching
provided unexpected opportunities to promote this sort of active work, and resulted in an active
learning experience for the students.

INTRODUCTION

Physics is on one hand a corpus of knowledge and a
set of technical and quantitative tools, but on the other
hand it is also a conceptual approach to scientific problems, a way of “discovering” that has had a profound
impact on other fields of science [1–3]. When we teach
a physics class, the corpus may be technical and difficult to convey, but it is straightforward and usually well
defined. For a particular “subject matter”, the set of
facts and techniques is also what the students instinctively expect to learn. Conversely, the flavor for what is
a “physics approach” is comparatively elusive and complex to communicate. It is rooted in how we “do” physics,
how physicists perform their work in research. Once data
is collected (the act of ‘measuring’ and acquiring data is
the other specialty of physicists) physics digs into this information through “physical models”, simple mathematical representations of empirical observations that have
the ambition to capture the essence of a process. These
physics models thus aim to be predictive, i.e. able to
forecast the outcome of independent experiments [1], ideally also beyond the range used to inspire and test the
model [4]. This approach is extremely successful within
various branches of physics, and today thanks to detailed
datasets from various other fields it also has a great potential in interdisciplinary and traditionally non-physical
science fields. Teaching how to use the physics approach
productively is difficult, because it is an unstructured and
complex set of skills, composed of different layers. For
many students the acquisition of these skills is delayed
to the first time they are required to produce original re-

∗

marco.cosentino-lagomarsino@ifom.eu

search, such as in their graduation or PhD work, and for
some others these skills are just not acquired.
Certainly what a physicist would call ‘doing physics’
includes many skills that apply well to all sciences, such
as the ability to formulate hypotheses [5], and a set of
problem-solving and guess-stimating skills [6], which include being able to question and “filter” information,
data, common beliefs, as well as our own results [7]. Some
of these skills intersect with what is sometimes called the
“nature of science” [8], a label that characterizes the research process as well as the scientific knowledge including socio-cultural aspects. They also represent what is
at the heart of theoretical science, and one of the most
creative and arguably most significant parts of our work
as scientists in general.
During the COVID-19 crisis in Italy, Two of us (MCL
and MG) were teaching for the first time a computational
physics laboratory class for third-year physics students
(the other authors of this studies contributed as students
or external supervisors, see below). Our aim was to convey a “physics of data” approach to data analysis and
data-driven physical modeling. We were also committed
to using interdisciplinary data sources rather than conventional physics data sets, in order to show the students
the interdisciplinary potential of a physics approach to
data [9]. The course started in March 2020, when a national lockdown took effect, so that we had to rapidly
convert the material of the course previously conceived
for traditional frontal live teaching to remote teaching,
and we decided to use “hot” data from the ongoing pandemic. What follows is an account of this teaching experience with two objectives: (1) describe how the “hands
on” philosophy described above was formalized and put
in practice and (2) the role of the remote-teaching settings in this experience. We found that remote teaching,
while being a big challenge, also offered significant and

2
unexpected opportunities for this course, leading to effective bi-directional communication with the students.
BOX 1: course essential content.
• The scientific toolbox of the course (covered
in approximately 16h of lectures) aims to provide a bare-bone scientific set of tools for
model-driven data analysis, including basic
tools from modeling, critical scientific thinking, essential probability and statistics and
data visualization.
• The computational toolbox of the course (estimated in 16h of lectures) includes essential Python tools to treat, analyze and plot
data (based on the Scipy package, and using NumPy, Pandas, and Matplotlib libraries),
and typesetting of LaTex documents, useful
for the reports. We also provided commandline tools to treat, analyze and plot data
(based essentially on Bash scripting, the awk
language, and the gnuplot plotting program)
and an introduction to C++ tools for efficient
data analysis and simulations (including Standard Template Library data structures).

STRUCTURE AND CONTENT OF THE COURSE

The course fits in the 3rd year physics curriculum at
the University of Milan as a computational physics laboratory class. It is scheduled over 66 hours during one
semester, which are normally spent “in the lab” with the
teaching shared across two instructors. The expected
hours of coursework are approximately 30-40. The purpose of the course is to provide (i) basic notions of computational tools (C++, shell and scripting languages,
python, latex) and (ii) skills in “physics of data”, i.e.
model-guided data analysis and data visualization, in the
form of three short projects.
The course was structured in a two parts. The first
part of the course (described in BOX 1) is an essential
technical and scientific toolbox for taking off with the
projects. The second part of the course addresses three
one-week long “data challenge” individual projects (DC1,
DC2, DC3). In these data challenges, students start from
a dataset and work on it to extract and present conclusions. At the end of each data challenge, students submit
a three-page report written in LaTeX, to describe the results achieved and to include their own graphics and figures. We decided that DC1 would be fully supervised and
guided, with the students working in close contact with
the tutors. DC2 and DC3 would be more autonomous.
To be able to manage the supervision of the students, we
restricted the attendance to a maximum of 25 students
(originally the restriction was also due to the number of
available workstations in the classroom).

The data challenges followed the pipeline: “Get data
→ Clean up data → Explore data → Model data → Interpret data”. And the students were given the prescriptions
to take into account the limits (and possible biases) of the
data, to prefer models with fewer parameters, and to be
strict and question every interpretation. They were also
warned about the relevant cultural problems that emerge
in interdisciplinary applications of physics there, where
it is necessary to acquire some specific knowledge of the
domain, to be humble and trust the experts of the field.

CONVERSION TO REMOTE TEACHING.

Soon before the course started in early March 2020, it
became clear that it would have to be delivered remotely.
We decided to use a Slack workspace and Zoom meetings.
Lectures were mostly asynchronous, delivered as posts
on the Slack space, which students had to go through on
their own. Lectures were posted on Slack using text and
externally linked material (example code, lecture notes,
external resources). For example, the YouTube channel “Calling Bullshit in the Age of Big Data” [7] was
used as a complement for several aspects of statistics,
data visualization, Fermi estimates, etc. but we also gave
the students our own lecture notes and handouts on all
these topics, including exercises and example codes to
plot data, perform fits (see BOX 1 and the Supplementary Appendix, providing a compendium of the course).
After each set of lectures, we organized a “Questions
and Answers” session (Q&A) on Zoom, where we discussed the material with the students. Next to the material, we also posted guided exercises on the computational
and scientific parts of the course. In each Q&A session,
besides leaving the meeting open to any questions, each
student was interviewed and requested to update the instructors on the study work and exercises that he/she had
already done, whether she/he encountered any difficulty,
and was asked to state her/his plans for the coming days.
These sessions lasted 2-3 hours and took place roughly
once a week.
The Slack space was an efficient way to interact bidirectionally with the students throughout the week (Fig. 1).
We structured it in several channels for posting teaching material, planning of the course, receiving material
from the students (e.g. the reports from the data challenges), and we included a forum where instructors, supervisors and students could post material, tips, pointers
to external materials and data sets, problems and general
questions. The forum turned out to be a very active platform during the course. One-to-one chats were used and
proved efficient for replying to specific questions. Slack
includes an App for cell phones, which we found useful for
real-time communication (and depending on the teacher’s
availability, it can be silenced for prescribed time periods,
whilst avoiding email clutter).
Most students had the right resources to take the
course from home. Five students dropped out when we

3

A

B

C

Figure 1: The Slack space facilitates organization of the
course, posting of lecture material and bi-directional
communication. A. Subdivision of information into channels
for planning of the lectures and Q&A sessions, posting of
lecture material, turning in data challenge reports. Channels
are accessible from a side pane of the PC app and as a menu
for the mobile app. B. Example of a portion of a posted
lecture on Python, with highlighted code. Through the
interface, a lecturer can include attachments in several
formats (code, pdf, images, etc.) and links to external
websites, which the app automatically shows in pretty-print
preview. C. Example of the interactive “forum” channels
where teachers could post external material, and the
students could post questions publicly. Questions can be
addressed in a connected “thread” conversation (right-hand
panel).

announced the switch to remote or during the course. We
contacted them through the Slack and email, but it was
difficult to reconstruct the precise reasons (e.g. pressure
from other courses or lack of equipment). We provided instructions to install all necessary code at home, but each
student could also connect remotely to Linux-based university machines where all the softwares were available.
All codes, software, compilers supported by the course
(essentially, Python, C++, gnuplot, shell scripting and
LaTex for typesetting) were free, although the students
were left free to adopt any tool and judged solely by the
end results of their work.

THE COVID-19 DATA CHALLENGE.

With the pandemic expanding globally, we decided
that the first data challenge would be a COVID-19 data
challenge, and given the broad nature of the challenge
we called on four extra “external supervisors”. We kept

the second data challenge as a more standard physics
project on multiplicative diffusion processes, which used
data on software packages [10, 11]. As the course got under way, we saw that DC1 had (perhaps in hindsight not
surprisingly) taken a lot of time and commitment on both
student and teaching staff. Extensive feedback was being provided to the students on their projects DC1, so to
provide an outcome for this we switched our original plan
and made DC3 optional, and to consist of an update and
integration the work carried out in DC1. This enabled
students to build on the detailed feedback provided by
the instructors on the student reports for DC1. 14 out
of 21 students chose to address DC3. The feedback to
students included a number of positive propositions to
expand and revise aspects of each project. Given the
challenges presented by the first data challenge, it was
clearly very instructive for many students to go back and
correct, integrate or improve the work done (both on the
technical/scientific level and on the level of the efficiency
in communication and data visualization).
We planned the first data challenge DC1 to be a supervised project, so the students were free to ask questions and seek advice on any level. Since the course
started during the COVID-19 crisis (and during the complete lockdown) in Lombardy and Italy, we thought that
putting their hands on the surge of data that were discussed every day all over the news and the internet
could be both motivating and challenging. As mentioned
above, in order to supervise the projects more efficiently
during that week, we obtained the help of four (volunteers) external “supervisors” for DC1. These scientists
provided some ideas for the projects and interacted directly with the students, individually and through the
Slack forum. The supervisors were based in other cities
in Italy and in the UK, but the Slack interface made it
easy for them to interact with the students through the
forum and individually, and to help them carry out their
individual projects.
Part of the instructions provided for the DC1 were
tips on where to get the data, but the students were encouraged to explore autonomously different data sources.
Part of the technical skills that they acquired from the
first part of the course were on how to “scrape” data using command line and Python, and how to manipulate
data and assemble an organized data set (for example,
using the Pandas and Numpy packages in Python). As a
basis, the students were encouraged to get the daily data
from:
• the Italian Civil Protection agency. [12]
• The COVID-19 Repository at Johns Hopkins University [13][14]
• Our World in Data [15]
• the EU ECDC web site [16]
• national data from the Italian, French and German
ministries of health.

4
• the Italian
(ISTAT)[17]

National

Institute

of

Statistics

The challenge was divided into a first point (A) that
was common to all students and a second one (B) that the
students could choose. The common point was the empirical prediction of the “infection peak”. The students
were asked to find a suitable and efficient empirical definition of the peak of the infection. The challenge was to
provide an empirical estimate of the peak using data from
different countries and regions, and propose/validate an
empirical method to predict the peak as accurately as
possible. The assignment also provided some tips on the
limitations of the data, some caveats on the requested
analysis, and different possibilities to tackle the question.
Point (B) of the challenge was to identify and address
a well-defined question within a theme chosen from a set
of the following proposed options, all of which concern
open scientific problems.
• (B1) Fit / analysis using a standard epidemiological (SIR or SEIR) model, asking whether unified
parameters could be defined for the spreading of
the SARS-CoV-2 virus before the lockdown[18].
• (B2) Use fits from a SIR/SEIR model to estimate
the reaction (change in parameters) to containment/lockdown measures [19].
• (B3) Empirical correlative analysis. In the wake of
point (A), define some purely empirical observables
from the data such as delay outbreak-intervention
time, delay infections / death etc. evaluate these
quantities in various regions (see above, staying as
local as possible) and correlate them with other
possibly interesting covariates such as population
density, public transport / commuting properties,
fine dust pollution, temperature, capacity of hospitals, etc[20, 21].
• (B4) “Bullshit calling” exercise. Find on the web
or in the news a scientific claim made by a scientist
in a pseudoscientific context (e.g. a plot posted on
facebook or twitter, there are various Italian and
international threads) and then challenge, refute or
debunk it using data (and models if necessary).
• (B5) Explore possible explanations for the very
large variations of case/fatality ratios across countries and regions (e.g. 14% case fatality ratio in
Italy vs 0.6% in Germany. The case fatality ratio
is known to be a very bad estimate of the death rate
because of delays and other factors [22, 23]. A circulating hypothesis was that a confounding factor
is the age distribution: the Italians are older and
therefore die more likely of the disease. Another
common hypothesis (which quickly turned out to
be the most reasonable) was that there were many
more infected than measured. Another possibility
(now ruled out) was that a strain of the virus has
different death rates.

• (B6) Spatial spreading. Identify simple observables
to quantify spatial spreading from available data.
Check whether containment measures have an effect on this observable. Test if the opposite has
happened: when the measures are announced, everyone jumps on the train and spreads the virus
around the country [24].
From the educational viewpoint, the problem setting
was conceived to encourage the students to put critical thinking into practice and search for original solutions. Encouragingly, multiple students came up with
approaches to the data that were original and effective.
Perhaps even more importantly, some students able to reflect critically on their own work, revising and correcting
their own analyses. For example, one student developed
a technique to predict the infection peak from a logistic fit of the cumulative curve. In the second report for
DC2, she decided to perform a critical analysis of her
own proposition, showing that it did not work well with
data.
What follows is a list of some remarkable findings by
the students, some of which are presented in more detail
in Appendix (Figures A1 and A2).
• The time delay between the first case in a given
Italian province and the first case reported in Italy
correlated negatively with provincial mobility estimated from 2011 census data.
• There was a factor of 1.5-2.5 (varying from city to
city) between total deaths in March in cities in the
Bergamo area and the sum of COVID-19 registered
deaths plus the average deaths in the three previous years in the same month. Assuming the measured 1.2% mortality, one student could estimate
that total cases could be up to 50 fold larger than
the number of registered cases.
• Compared to a suitable null model, Italian
provinces with a first-reported new infected tend
to be statistically closer to provinces with already
ongoing COVID-19 outbreaks.
• There is a phenomenological (mildly sublinear)
power law relating the number of reported infected
at the peak, and its value on the day a lockdown
was put into effect, valid across regional data from
China, Italy and Spain.
• The date of the infection peak is roughly independent from the date of the lockdown measures, using
as reference system for time an origin when the new
cases are 25.
• Bad or biased sampling can be spotted by the time
constancy of the ratio of positive/tested individuals.
Beyond the scientific results above, which were only a
part of the goals (see below), we believe that the COVID19 data challenge conveyed important specific lessons to

5

grade DC2

A 10

B

9
8
7
6
5
5

6

7 8 9
grade DC1

10

grade increase DC1 to DC3

the students. First, to address questions with modesty.
Physics provides modeling and data analysis skills, but
no knowledge of epidemiology or other disciplines. First
of all, one must be aware that one is not an expert in
trying to figure out simple things from the data. Second, choosing circumscribed questions, makes it feasible
to reach a goal. Third, an important result can be positive or negative, but in both cases the conclusions must
be argued carefully, and supported with the appropriate
controls.
2.5
2
1.5
1
0.5
0
5

6

7 8 9
grade DC1

10

decided that enrolling in the voluntary DC3 could not
lower the grade obtained with the first two data challenges, at worst it would leave it unchanged. For those
who were not satisfied by the final grade, we made it possible to request an oral exam. The oral exam could cause
both reduction and increase of the grade based on the
students’ reports. No student opted for the oral exam.
Fig. 2 summarizes the grading across the three data
challenges. Grades received in DC1 and DC2 were correlated only very mildly (Pearson r=0.39, Fig. 2A). This
suggests that the two dissimilar challenges allowed us to
evaluate complementary skills and therefore reach a more
comprehensive evaluation of each student. On the other
hand, all of the 14 students who addressed DC3 received
a grade at least equal to that of DC1, with 5 students
increasing by more than 1 grade (Fig. 2B). Moreover,
the increase in grade was negatively correlated with the
grade obtained in DC1 (Pearson r=-0.63), showing that
lower performing students managed to capitalize on the
feedback they received.

Figure 2: The three-challenge layout allowed comprehensive
evaluations and offered the students the possibility to
increase their marks significantly. A. DC1 grades (x axis)
and DC2 grades (y axis) obtained by all students (circles
correspond to those who also completed DC3, squares are
the others). B. The net increase in grade between DC1 and
DC3 (y axis) versus the grade obtained in DC1. Dashed
lines are the bisectors y = x, as a guide to the eye.

CRITERIA FOR EVALUATION OF THE
REPORTS.

Ours was a laboratory course, focused on the practical aspects, and whose cornerstone are the data challenges. It was not trivial to develop suitable criteria for
the evaluation. We wanted the final grade to reflect the
quality of the “practical” work done rather than the acquisition of notions (which can easily be evaluated by an
oral exam). Hence, we decided that the grade should
be based on assessing the reports of the three data challenges. The reports were graded based on four criteria:
(i) Logical structure and communication; (ii) Data visualization; (iii) Technical aspects of the analysis; (iv) Scientific aspects of the analysis and support of the claims.
Additionally to the grade, we provided extensive feedback for DC1, from two instructor, in a form similar to
a manuscript “referee report” for each student, which included discussion of the weak and strong points of his/her
work and suggestions to correct and/or improve specific
technical, scientific and presentation aspects. The final
grade was proposed based on the results of all the data
challenges carried out by each student. For those students who did three data challenges, the final grade was
the sum of the three grades. For those who did two data
challenges, we based it on the sum multiplied by 1.5. We

DISCUSSION

Unfortunately with the COVID-19 crisis there is likely
to be a big turn away from the experiments in teaching
physics in the coming years, although some initiatives
are trying to address practical teaching suitable for social
distancing and remote learning [25]. It seems urgent and
useful to set up and systematically improve teaching materials and experiences such as the one we experimented
on here. Such a setting would lead students to work on
real data, analyze curves and distributions, perform fits,
ask questions and look for answers in the data. It would
be a recovery of an important part of what a student
normally learns in laboratory work.
Beyond the contingency of a completely remote learning, the course offered us an occasion to reflect on general
problems related to the formalization and the implementation of a hands-on approach in a course aimed at teaching through the supervision of active student projects.
We believe that the structure of our course is solid, and
that it can be replicated in other experiences, not only to
physics students, but also in other quantitative curricula
such as mathematics, engineering or computer science. A
crucial aspect is how many students such a course structure can support. With two instructors we found that 25
students is a realistic sustainable upper bound. However,
during DC1, the presence of the external supervisors was
essential. These are 10-15 days of the course where at
least 2-3 extra teachers are involved to support the students’ questions and provide feedback. This need should
not be underestimated when planning a similar course,
but we believe it would not be too hard to implement it
e.g. through PhD students or postdocs (also providing
a valid supervision experience for early-career scientists).
Not to underestimate, the supervision activity is probably easier to implement remotely than in a classroom

6
setting. In such a setting, the extra supervisors can provide feedback through a chat interface in the time slots
and time-frame they want, and the forum structure leaves
a question open to be addressed for any supervisor (or
even other students). It also leaves answered questions
available to any students, who may spot a relevant issue
even in cases when they are not able to crystallize it in a
well-defined question.
At the University of Milan, student feedback is provided through anonymous questionnaires based on a set
of closed-answers questions, plus space for open comments. Generally the questionnaires are filled by a small
fraction of students, but this was not the case for our
course. We carefully read the answers to the open questions. From these comments it is clear that the course
has aroused “high variance” reactions, both positive and
negative. Multiple students felt they were thrown into
deep waters in a “sink or swim” approach, which disappointed them. Others were enthusiastic about some
aspects of the course, such as being given an opportunity
to develop their independence, or praising the detailed
and constructive feedback that we provided for their reports, or some specific lectures, such as the lecture on
data visualization (defined by one student as a “gem”).
5/20 students later on decided to carry out their Undergraduate thesis projects under the supervision of one of
the teachers. The large amount of feedback provided by
the students is positive in itself, in the sense that it testifies that the course has aroused interest and commitment
on the part of the students, albeit with a great variability
of starting points in terms of independence and scientific
maturity, which definitely needs to be addressed in the
next editions of this course.
We think a crucial aspect that explains the almost bimodal reactions is linked to the independence that we
asked students to achieve: one of the training objectives
is precisely to make them autonomous in learning new
tools for analyzing and exploring data. Before the conversion to remote teaching, the philosophy behind the course
was already to promote active learning through dataanalysis projects. However, some students, due to lack of
information, or simply due to the fact that the course has
radically changed compared to previous years, expected a
more standard course. This impact should automatically
soften over time. “Inquiry-based learning” [26–28] is an
approach to teaching that starts from the assumption
that a primary route for a student to learn something
is to ask him/herself questions and then actively look
for answers on his/her own (by contrast classic teaching
may give answers to questions that many would never
ask). For this approach, there are various schools. Typically one tries to engage the students on a problem by
arousing curiosity and stimulating questions. A “gradual
release of responsibility” strategy [29] fits our project, as
it aims at the gradual empowerment of students for their
activities, by showing examples, and gradually “ramping
up” the scale of difficulty and independence (which is the

most delicate step).
CONCLUSIONS

In brief, we judge that the practical implementation of
the philosophy behind the course was successful, but a
crucial aspect is to soften as much as possible the initial
barrier for a student to become active on the “data challenge” projects. Keeping the focus on our main objectives, which are defining for the course, we are intervening in several ways in the new 2021 edition of the course:
a) clarifying from the beginning which skills (soft and
hard) we expect the students to develop, and how they
are evaluated in the exam; b) expanding the description
of specific tools, so that students can be immediately
operational; c) providing lectures including “frontal” explanations, combined to the posted study material and
the individual Q&A tutoring sessions on Zoom, in order
to reduce the amount of material to be processed individually; d) reducing the overall load, passing from three to
two data challenges, and extending the time dedicated
to each, so that students can work under a lower time
pressure.
From the point of view of Faculty in the physics curriculum, the constraints enforced by the pandemic led us
to innovate on both the teaching methodology and the
subject matter, in ways that we had not previously explored. While admittedly far from perfect, we believe
that our experience is something to build on. While
the course corpus and toolbox can be improved, they are
nothing special per se. It is the “hands on” part of the
course that provided a valuable access for the students to
elements of knowledge, practice and “nature of science”
that are typically not accessible in standard courses,
and are often developed through laboratory practical
experiences. For many, learning “the physics way” of
addressing problem was a real hitpoint of the course.
Two aspects where specifically very interesting. First,
COVID-19 data was an ideal setting to learn how to deal
with poorly defined “messy” problems, where there is no
unique or preconceived solution [9]. The students had to
come to terms with the exercise of isolating well-defined
sub-problems, and to find compromises of different kinds
in order to analyze the data and draw conclusions, which
is what invariably happens outside of a classroom, in a
research or a workplace setting. To this end, the interactive Q&A sessions on Zoom where each student could
report their findings and questions were particularly effective. Second, remote teaching provided unexpected
opportunities to stimulate an active role of students, via
oral and written communication. The possibility to keep
a constant communication feedback collectively and individually via the Slack space was certainly an unexpected
benefit for us. Additionally, and perhaps more importantly, remote teaching breaks the student expectations
of unidirectionality. Looking at a frontal lecture on line
may become extremely boring, and exploring alternatives
is a necessity, but also an opportunity to promote active
work and active learning from the students.

7

[1] Laurie M. Brown and Richard Tilghman Weidner,
“Physics,” in Encyclopaedia Britannica (2020).
[2] Philip Nelson, Physical models of living systems (W.H.
Freeman & Company, New York, NY, 2015).
[3] Lena Hansson and Lotta Leden, “Working with the nature of science in physics class: turning ‘ordinary’ classroom situations into nature of science learning situations,” Physics Education 51, 055001 (2016).
[4] Note that “model” is a concept used with quite distinct
meaning in various fields of science: physics, chemistry,
biology, engineering. We will use “model” as shorthand
for “physical model”.
[5] Itai Yanai and Martin Lercher, “Night science,” Genome
Biology 20 (2019), 10.1186/s13059-019-1800-6.
[6] Clifford Swartz, Cliff ’s nodes : editorials from the physics
teacher (Johns Hopkins University Press, Baltimore,
2006).
[7] Carl Bergstrom and Jevin West, Calling bullshit : the
art of skepticism in a data-driven world (Random House,
New York, 2020).
[8] Randy L Bell, “Teaching the nature of science: Three
critical questions,” Best Practices in Science Education
22, 1–6 (2010).
[9] Erin L. Dolan and James P. Collins, “We must teach more
effectively: here are four ways to get started,” Molecular
Biology of the Cell 26, 2151–2155 (2015).
[10] Marco Gherardi, Salvatore Mandrà, Bruno Bassetti,
and Marco Cosentino Lagomarsino, “Evidence for soft bounds in ubuntu package sizes and
mammalian body masses,” Proceedings of the National Academy of Sciences 110, 21054–21058 (2013),
https://www.pnas.org/content/110/52/21054.full.pdf.
[11] Salvatore Mandrà, Marco Cosentino Lagomarsino, and
Marco Gherardi, “Soft bounds on diffusion produce
skewed distributions and gompertz growth,” Phys. Rev.
E 90, 032805 (2014).
[12] Https://github.com/pcm-dpc/COVID-19.
[13] (JHU
CSSE
COVID-19
Data
https://github.com/CSSEGISandData/COVID-19.
[14] Ensheng Dong, Hongru Du, and Lauren Gardner, “An
interactive web-based dashboard to track COVID-19 in
real time,” The Lancet Infectious Diseases 20, 533–534
(2020).
[15] Https://ourworldindata.org/coronavirus.
[16] Https://data.europa.eu/euodp/en/data/dataset/covid19-coronavirus-data.
[17] Http://dati.istat.it/.
[18] Anca Rǎdulescu, Cassandra Williams, and Kieran Cavanagh, “Management strategies in a SEIR-type model
of COVID 19 community spread,” Scientific Reports 10
(2020), 10.1038/s41598-020-77628-4.
[19] Giulia Giordano, Franco Blanchini, Raffaele Bruno, Patrizio Colaneri, Alessandro Di Filippo, Angela Di Matteo,
and Marta Colaneri, “Modelling the COVID-19 epidemic
and implementation of population-wide interventions in
italy,” Nature Medicine 26, 855–860 (2020).
[20] Andrew J. Stier, Marc G. Berman, and Luis M. A.
Bettencourt, “COVID-19 attack rate increases with city
size,” (2020), 10.1101/2020.03.22.20041004.
[21] Haroldo V. Ribeiro, Andre S. Sunahara, Jack Sutton,
Matjaž Perc, and Quentin S. Hanley, “City size and

[22]

[23]

[24]

[25]
[26]

[27]

[28]

[29]

[30]

[31]

the spreading of COVID-19 in brazil,” PLOS ONE 15,
e0239699 (2020).
Nick Wilson, Amanda Kvalsvig, Lucy Telfar Barnard,
and Michael G. Baker, “Case-fatality risk estimates
for COVID-19 calculated by using a lag time for
fatality,” Emerging Infectious Diseases 26 (2020),
10.3201/eid2606.200320.
Tetsuro Kobayashi, Sung mok Jung, Natalie M. Linton, Ryo Kinoshita, Katsuma Hayashi, Takeshi Miyama,
Asami Anzai, Yichi Yang, Baoyin Yuan, Andrei R.
Akhmetzhanov, Ayako Suzuki, and Hiroshi Nishiura,
“Communicating the risk of death from novel coronavirus
disease (COVID-19),” Journal of Clinical Medicine 9, 580
(2020).
Marino Gatto, Enrico Bertuzzo, Lorenzo Mari, Stefano Miccoli, Luca Carraro, Renato Casagrandi,
and Andrea Rinaldo, “Spread and dynamics of
the covid-19 epidemic in italy: Effects of emergency containment measures,” Proceedings of the National Academy of Sciences 117, 10484–10491 (2020),
https://www.pnas.org/content/117/19/10484.full.pdf.
Https://www.smartphysicslab.org/.
Angela Brew, “Teaching and research: New relationships and their implications for inquiry-based teaching
and learning in higher education,” Higher Education Research & Development 22, 3–18 (2003).
Rachel Spronken-Smith and Rebecca Walker, “Can
inquiry-based learning strengthen the links between
teaching and disciplinary research?” Studies in Higher
Education 35, 723–740 (2010).
Margus Pedaste, Mario Mäeots, Leo A. Siiman, Ton de
Jong, Siswa A.N. van Riesen, Ellen T. Kamp, Constantinos C. Manoli, Zacharias C. Zacharia, and Eleftheria
Tsourlidaki, “Phases of inquiry-based learning: Definitions and the inquiry cycle,” Educational Research Review 14, 47–61 (2015).
P. David Pearson and Margaret C. Gallagher, “The instruction of reading comprehension,” Contemporary Educational Psychology 8, 317–344 (1983).
Robert Verity, Lucy C Okell, Ilaria Dorigatti, Peter Winskill, Charles Whittaker, Natsuko Imai, Gina
Cuomo-Dannenburg, Hayley Thompson, Patrick G T
Walker, Han Fu, Amy Dighe, Jamie T Griffin, Marc
Baguelin, Sangeeta Bhatia, Adhiratha Boonyasiri, Anne
Cori, Zulma Cucunubá, Rich FitzJohn, Katy Gaythorpe,
Will Green, Arran Hamlet, Wes Hinsley, Daniel Laydon,
Gemma Nedjati-Gilani, Steven Riley, Sabine van Elsland,
Erik Volz, Haowei Wang, Yuanrong Wang, Xiaoyue Xi,
Christl A Donnelly, Azra C Ghani, and Neil M Ferguson,
“Estimates of the severity of coronavirus disease 2019: a
model-based analysis,” The Lancet Infectious Diseases
20, 669–677 (2020).
Eco di Bergamo, “Coronavirus, the real death toll: 4.500
victims in one month in the province of bergamo,”
(2020).

8
Appendix: Examples of students’ results.

# Deaths

A 600
400

200

0

B 10
# Cases

Mean 2015-2019
March 2020
Reported as Covid-19

Bergamo

Treviglio

Nembro

Clusone

6

105
104
Reported
Estimated

103
0

10
20
30
40
Days from case 172 (24 Feb 2020)

50

Figure A1: Examples of students’ results on COVID-19 epidemiological data combined with mortality data. Panel A
compares the total deaths reported in four cities in the Bergamo area in March 2020 (blue bars) with the sum of the
COVID-19 deaths reported in the same month (orange bars) and the average of the total reported deaths in the same month
of the previous five years (green bars). In all cases the sum of average mortality and reported COVID deaths (green plus
orange) was well below the total mortality, pointing to widespread unreported cases. Panel B reports an estimate of the
actual total number of cases in Lombardy (orange stars) from the number of reported cases (blue circles) based on the excess
mortality. The estimate assumed a common overall fatality rate for the virus of 1.2 % and an average delay of 18 days
between infection and death [30]. Based on these estimates, the actual number of cases in that area could have been between
one and two orders of magnitude higher than estimated from swabs. 2015-2019 mortality data was downloaded from the
Italian National Institute of Statistics (ISTAT). Mortality data from the cities in the Bergamo area were obtained from the
newspaper l’Eco di Bergamo (each city had shared these data directly with this newspaper [31]). Data were obtained from the
Italian Civil Protection Repository.

9

Infection peak day

A

Italy regions
China regions

30
20
10
0

10
5
0
5
10
15
20
Days between 25 new cases and lockdown
SIR
SIR + migration
#cases
pre lockdown
post lockdown

5

0

0

Delay

10
Lockdown Day

# Cases (x1000)

B

20

Actual end
of the wave

40
60
80
Days from case 100

100

120

Figure A2: Examples of students’ results on COVID-19 epidemiological data. A. The infection peak, defined empirically as
the maximum in the observed new cases after a lockdown, depends on the level of the infection at lockdown. The scatter plot
reports the day of the infection peak (y axis, defined as the maximum in the number of current cases vs the time from
lockdown, measured in days from lockdown) reached by a region compared to the delay between the implementation of
lockdown and the day the number of new cases reached 25 (x axis). Italian regions (red circles) are compared to Chinese
regions (blue pentagons). The plot shows that different regions took a similar time to reach the infection peak after lockdown,
but the delay was longer in Italy than in China, possibly because of underreporting or less strict confinement measures. B.
Different infection models lead to different predictions. The plot shows two fits of SIR disease spreading models performed by
two students, using two different model variants on data from the Veneto region (triangles). One model (green solid line) was
the standard SIR, while another model (light blue solid line) also included immigration/emigration. This variant of the SIR
model adds parameters that describe immigration (Λ) and emigration (µ) and both variants were used to estimate the
effective transmission rate (β), the hospitalization rate (γ) and the basic reproduction number (R0 = β/γ). The model
divides the total population (N ) into three categories: susceptible (S), infected (I), and removed (R), with N = S + I + R,
and following the ODEs dS/dt = Λ − µS − βSI/N ; dI/dt = βSI/N − (γ + µ)I; dR/dt = γI = µR. The standard SIR model
has Λ = µ = 0. Introducing the model variant lead to a different prediction of the end of the epidemic wave. The actual data,
which came after the Data Challenge, displayed a behavior in between the two model predictions. The end of the wave took
place about 110 days after lockdown (cyan circles), so that the model with migration parameters resulted to be more
accurate. The model fits kept into account the fact that the the average number of contacts per unit time changed after
lockdown (blue triangles), compared to before (red triangles) considering a delay of 9 days for developing the disease. Data
from the the Italian Civil Protection and the JHU CSSE COVID-19 Data Repositories.

