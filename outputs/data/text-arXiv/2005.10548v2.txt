Coswara - A Database of Breathing, Cough, and Voice Sounds for COVID-19
Diagnosis
Neeraj Sharma, Prashant Krishnan, Rohit Kumar, Shreyas Ramoji, Srikanth Raj Chetupalli,
Nirmala R., Prasanta Kumar Ghosh, and Sriram Ganapathy
Indian Institute of Science, Bengaluru, India, 560012
sriramg@iisc.ac.in
100

1. Introduction
The COVID-19 is a respiratory infection caused by severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2) [1]. The
disease, officially declared a pandemic, has infected millions of
humans across the globe, and has a fatality rate between 1−10%
in most countries. Fig. 1 shows the cumulative number of cases
(and casualties) as of August 7, 2020, and there is still no sign
of flattening. This trajectory of growth started on 4 Jan 2020,
and has forced many countries to take serious containment measures such as nation-wide lockdowns and scaling up of the isolation facilities in hospitals. The lockdown is useful as it gives
time for large scale testing of individuals. The gold standard
for COVID-19 diagnosis is the reverse transcription polymerase
chain reaction (RT-PCR) of infected secretions (from nasal or
throat cavity). The results of a RT-PCR test are available in
2 − 48 hours. The limitations of the testing include: (i) violation of social distancing which increases the chance of infection
spread, (ii) expenses involved in the chemical reagents and devices, (iii) testing time in hours and needs expertise, and (iv)
difficulty in large scale deployment. Foreseeing a rise in number of COVID-19 cases, this has also led to a spur in proposals
on technology solutions for healthcare. Specifically, the need
for the development of simplistic, cost effective and fast testing,
yet accurate methodologies for infection diagnosis has become

101

10

1

10

2

10

1

10

3

10

2

10

3

10

4

10

4

10

5

10

5

10

6

10

6

100

04 Jan

04 Feb 04 Mar

04 Apr 04 May
DATES in 2020

04 Jun

04 Jul

CONFIRMED CASES [in Millions]

The COVID-19 pandemic presents global challenges transcending boundaries of country, race, religion, and economy. The
current gold standard method for COVID-19 detection is the
reverse transcription polymerase chain reaction (RT-PCR) testing. However, this method is expensive, time-consuming, and
violates social distancing. Also, as the pandemic is expected to
stay for a while, there is a need for an alternate diagnosis tool
which overcomes these limitations, and is deployable at a large
scale. The prominent symptoms of COVID-19 include cough
and breathing difficulties. We foresee that respiratory sounds,
when analyzed using machine learning techniques, can provide
useful insights, enabling the design of a diagnostic tool. Towards this, the paper presents an early effort in creating (and
analyzing) a database, called Coswara, of respiratory sounds,
namely, cough, breath, and voice. The sound samples are collected via worldwide crowdsourcing using a website application. The curated dataset is released as open access. As the
pandemic is evolving, the data collection and analysis is a work
in progress. We believe that insights from analysis of Coswara
can be effective in enabling sound based technology solutions
for point-of-care diagnosis of respiratory infection, and in the
near future this can help to diagnose COVID-19.
Index Terms: COVID-19, Cough, Breath, Voice, Random Forest

CONFIRMED DEATHS [in Millions]

arXiv:2005.10548v2 [eess.AS] 11 Aug 2020

Abstract

07 Aug

Figure 1: Evolution of COVID-19 cases and deaths. The data
is obtained from the WHO Coronavirus Disease (COVID-19)
Dashboard on 07 August 2020.
crucial for healthcare, policy making, and economic revival in
several countries. The focus is also on point-of-care diagnostic tools, technology solutions which can be deployed rapidly,
pre-screening tools, and cheaper alternatives to RT-PCR test,
overcoming the limitations of chemical testing.
The research and the understanding of the novel virus and
COVID-19 is a work in progress at various laboratories around
the world. As of 16 May, the WHO and the CDC have listed dry
cough, difficulty in breathing, chest pain (or pressure), and loss
of speech or movement as key symptoms of this viral infection,
visible between 2 − 14 days after exposure to the virus. Also,
a recent modeling study of symptoms data collected from a
pool of 7178 COVID-19 positive individuals validated the presence of these symptoms, and proposed a real-time prediction
and tracking approach [2]. Medical literature shows that speech
breathing patterns are intricately tied to changes in anatomy and
physiology of the respiratory system [3]. Drawn by these observations, we identify an opportunity to make impact on point-ofcare diagnosis using speech and acoustics research. Bringing
together a large dataset of respiratory sounds, machine learning, and respiratory infection expertise from doctors can help in
evaluating the potential in using respiratory sound samples for
diagnosis of COVID-19. The goal is not to replace the existing
chemical testing methodologies but to supplement them with a
cost effective, fast and simpler technique. This paper presents
our efforts along this direction.
The project is named Coswara, a combination of the initials of coronavirus and swara (referring to sound in Sanskrit).
The scientific rationale behind the conception of this project is
presented in Section 2. Section 3 presents an overview of the
project. In Section 4 a summary of the dataset collected and

(a)

(b)

(c)

Figure 2: Spectrogram of recordings from a healthy adult, (a) Sustained vowel /ey/ as in made, (b) Heavy cough, and (c) Breathing:
Inhalation followed by exhalation.

released openly as of 7 August 2020 is presented. We conclude
with a discussion in Section 5.

2. Scientific Rationale
2.1. Cough Sounds
Cough is a powerful reflex mechanism for the clearance of the
central airways (trachea and the main stem bronchi) of inhaled
and secreted material. Typically, it follows a well defined pattern, with an initial inspiration, glottal closure and development
of high thoracic pressure, followed by an explosive expiratory
flow as the glottis opens with continued expiratory effort [4].
The reflex is initiated by cough receptors within the central airways that are sensitive to both mechanical and chemical stimuli. Sound is generated during cough by air turbulence, vibration of the tissue, and movement of fluid through the airways
[5]. This turbulence generates sound with a broadband “noisy”
character, whose frequency content depends on the velocity,
density of the gas, and dimensions of the airways from source
till the mouth. A cough sound is usually composed of three
temporal phases: explosive, intermediate, and voicing phase.
Fig. 2(b) shows a wide-band spectrogram of a sequence of three
heavy cough sound signals. Each cough lasts close to 300 ms,
and the spectrum exhibits broad spectral spread over 500 Hz,
1.5 kHz, and 3.8 kHz. Interestingly, over one hundred pathological conditions are associated with cough [6]. The acoustic
features of a cough sound depend on the air flow velocity as
well as the dimensions of vocal tract and airways [4]. This
makes it possible to detect cough sounds [7] in audio recordings. As the physical structure of the respiratory system gets
altered with respiratory infections, it is even possible to classify pathological condition based on a cough sound. Pertussis
is a contagious respiratory disease which mainly affects young
children and can be fatal if left untreated. Pramono et al. [8]
presented an algorithm for automated diagnosis of pertussis using audio signals by analyzing cough and whoop sounds. Several other recent studies have attempted to identify chronic obstructive pulmonary disease (COPD) (a disease caused primarily due to smoking) [9], and tuberculosis (an infectious disease
usually caused by mycobacterium tuberculosis (MTB) bacteria
that affects the lungs) [10]. In addition, for respiratory disorders
like asthma and pneumonia, algorithms based on cough sounds
recorded using a smartphone provides a high level of accuracy
[11]. For COVID-19 detection and diagnostics, the research
initiatives from University of Cambridge [12], Carnegie Mellon
University [13], Wadhwani AI institute [14] and a project from

EPFL [15] have already been launched. Also, a recent work by
Imran et al. [16] suggests a good accuracy for cough based detection of COVID-19 using a preliminary investigation with a
small number of subjects.
2.2. Breath sounds
Breathing difficulty is another common symptom for COVID19. This is often exhibited as a shortness of breath. The early
work by Anderson et al., [17] reported that the spectrogram
of breath sounds captured by a smartphone shows distinct patterns for asthmatic conditions compared to healthy individuals.
For the diagnostics of COVID-19, the use of breathe sounds
is also being attempted by a research group at New York University [18]. Fig. 2(c) shows the wide-band spectrograms of
inhaling and exhaling cycles while breathing.
2.3. Voice sounds
The studies show that lung diseases have distinct bio-markers
in the speech breathing cycles [19]. The study reported in [20]
showed that the phonation threshold pressure, defined as the
minimal lung pressure required to initiate and sustain vocal fold
oscillation, is correlated with vocal fatigue. The impact of laryngeal dysfunction in breathing patterns of read speech was analyzed in [21]. Fig. 2(a) depicts the spectrogram of a sustained
phonation of /ey/ vowel (as in made). In contrast to cough and
breath sound sample, there is a clear voicing seen as harmonics and localized concentration of energy at regions defined by
formants.

3. Coswara Overview
Coswara [22] is an attempt to provide a simple and cost effective
tool for diagnosis of COVID-19 using breath, cough and speech
sounds. As most of the major symptoms of the disease include
respiratory problems, the proposed project aims to detect and
quantify the bio-markers of the disease in the acoustics of the
these sounds. The project has three stages, depicted in Fig. 3.
Below we briefly describe each stage.
3.1. Data collection
The goal is to create a dataset of sound samples from
healthy and unhealthy individuals, including those identified
as COVID-19. For sound data, we focus on nine different
The web application for data collection is designed using HTML,
and can be accessed at https://coswara.iisc.ac.in/.

Stage-2

Stage-1

Audio Dataset Metadata
Data analysis to build classification
models for respiratory disease detection

Respiratory
sound sample
collection via
Crowdsourcing

Curated and publicly
released for open and
free access

Stage-3

CoVID-19
Alert

Performance
evaluation by
healthcare authorities

Public Release of
tool for sound
based COVID-19
Diagnosis

Figure 3: Different stages in the proposed Coswara project - (1) Data collection, (2) Modeling, (3) Diagnostic tool development.

categories, namely, breathing (two kinds; shallow and deep),
cough (two kinds; shallow and heavy), sustained vowel phonation (three kinds; /ey/ as in made, /i/ as in beet, /u:/ as in cool),
and one to twenty digit counting (two kinds; normal and fast
paced). We also collect some metadata information, namely,
age, gender, location (country, state/province), current health
status (healthy / exposed / cured / infected) and the presence
of co-morbidity (pre-existing medical conditions). No personally identifiable information is collected. The data is also
anonymized during storage.
3.2. Modeling
The collected data will be analysed using signal processing and
machine learning techniques. The goal is to build mathematical models aiding identification of bio-markers from sound
samples. This stage is a work-in-progress while we create the
dataset. We have also initiated regular release of the curated
dataset as open access via GitHub platform1 .
3.3. Diagnosis tool
We aim to release the diagnosis tool as a web/mobile application. The application prompts the user to record voice samples,
similar to the dataset collection stage, and provides a score indicating the probability of COVID-19 infection. The final deployment of tool is subject to validation with clinical findings, and
authorization /approval from competent healthcare authorities.
Given the highly simplistic and cost effective nature of the tool,
we hypothesize that, even a partial success for the tool would
enable a massive deployment as a first line diagnostic tool to
pre-screen the infection.

4. Dataset Description
The project is currently on going. The collection, release, and
analysis of the dataset are in progress. Below we provide a
description of the most recent release of the dataset.
4.1. Data collection methodology
The data collection strategy focused on reaching out to the human population across the globe. For this, we created a website
application providing a simple and interactive user interface. A
1 The dataset and information about licensing can be accessed at
https://github.com/iiscleap/Coswara-Data

user could open the application in a web browser (laptop or
mobile phone), provide metadata, and proceed to recording the
sound samples using the device microphone. The average interaction time with the application is 5 − 7 mins. The user was
prompted to use personal device and wipe off the device with a
sanitizer before and after recording, and keep the device 10 cm
from the mouth during recording.
4.2. Metadata description
The currently released dataset (as of 07 August 2020) has a participant count of 941. Fig. 4 shows the distribution of the participants across gender, age, country (grouped into India and
outside), Indian states, and health status (grouped into healthy
and unhealthy). Each participant provides 9 audio files, one for
each of the sound category.
4.3. Annotation
The audio samples are recorded at a sampling frequency of
48 kHz. All sound files were manually curated. A web interface was designed allowing the annotator (human) to listen to
every sound file and answer some questions (a screenshot of the
interface is shown in Fig. 5). These questions helped verify the
category label, and the quality of the audio file. The annotator
was also provide an option to provide any additional comments
for each audio file. Fig. 4(f) depicts the quality count of the
recordings, pooling all the nine sound categories. Majority of
the audio files were rated as clean. While we had 13 annotators,
each file was listened by only one annotator. In total, the dataset
has 6507 clean, 1117 noisy, and remaining highly degraded audio files corresponding to respiratory sound samples from 941
participants.
4.4. Acoustic Properties
The 9 sound categories (or classes) are chosen such that physical state of the respiratory system is well captured just by using
the sound samples. We tested the complementarity across these
sound categories by building a multi-class classifier trained and
tested on acoustic features extracted from the different sound
samples. The goal was to build a 9-class (corresponding to the
9 sound categories) classifier and evaluate the confusion matrix.
The clean audio recordings were pooled and grouped by 9
sound categories. A set of different short-time (500 msec, with
hop of 100 msec) temporal and spectral acoustic features were

(a)

(b)

(d)

(c)

(e)

(f)

TRUE CLASS

Figure 4: Metadata of the Coswara database: Participant count across (a) country, (b) Indian states, (c) age, (d) gender (only top 5
are shown), (e) health status, and (f) sound category.

Figure 5: A screenshot of the designed tool for annotation.
extracted from the audio files. These included spectral contrast
(7-D), MFCCs (13-D), spectral roll-off (1-D), spectral centroid
(1-D), mean square energy (1-D), polynomial fit to the spectrum (2-D), zero-crossing rate (1-D), spectral bandwidth (1-D),
and spectral flatness (1−D). After concatenation each 500 msec
segment of audio was represented by a 28-D feature. A random
forest classifier (see [?], built with default parameters and 30
trees) was trained on a 70 − 30% train-test split for classifying
every 500 msec segment into one of the 9 sound categories.
The accuracy on test data was 66.74%. Fig. 6 shows resulting confusion matrix for the test data. The test data had an
equal share from every class. It is interesting to note that the
vowels are less confused, and the digit counting samples are
more confused between themselves. This is also the case for
cough samples and breathing samples.

5. Conclusion
We have described our efforts towards a sound based diagnostic
tool for COVID-19. The tool, named Coswara, built upon prior
studies that have shown good accuracy for detecting other res-

PREDICTED CLASS

Figure 6: Confusion matrix (on test data) obtained on classifying 9 categories of sounds using a random forest classifier.
piratory disorders like asthma, pertussis, tuberculosis and pneumonia. We highlight the rationale for choosing different stimuli in the Coswara database. The progress in data collection in
terms of meta data statistics are described. We also highlight
the complimentary nature of the stimuli chosen. The next phase
in the diagnostic tool development will attempt the use of machine learning algorithms to classify different health conditions
and try to identify sound based bio-markers for Covid-19.

6. Acknowledgements
We thank Anand Mohan for his enormous help in web design
and data collection efforts, which allowed the recording of data
from general public. We also thank Chandrika Thunga, Sonali
Singh, Sakya Basak, Venkat Krishnamohan, Jaswanth Reddy,
Ananya Muguli, Anirudh Sreeram and Anagha Rajeev for their
contribution in annotating the dataset.

7. References
[1] “Naming the coronavirus disease (COVID-19) and the virus
that causes it,” World Health Organization. https://www.who.
int/emergencies/diseases/novel-coronavirus-2019/technicalguidance/naming-the-coronavirus-disease-(covid-2019)-and-thevirus-that-causes-it, 2020.
[2] C. Menni, A. M. Valdes, M. B. Freidin, C. H. Sudre, L. H.
Nguyen, D. A. Drew, S. Ganesh, T. Varsavsky, M. J. Cardoso,
J. S. El-Sayed Moustafa, A. Visconti, P. Hysi, R. C. E.
Bowyer, M. Mangino, M. Falchi, J. Wolf, S. Ourselin,
A. T. Chan, C. J. Steves, and T. D. Spector, “Realtime tracking of self-reported symptoms to predict potential
COVID-19,” Nature Medicine, 2020. [Online]. Available:
https://doi.org/10.1038/s41591-020-0916-2
[3] J. E. Huber and E. T. Stathopoulos, Speech Breathing Across the
Life Span and in Disease. John Wiley & Sons, Ltd, 2015, ch. 2,
pp. 11–33.
[4] W. Thorpe, M. Kurver, G. King, and C. Salome, “Acoustic analysis of cough,” in The Seventh Australian and New Zealand Intelligent Information Systems Conference. IEEE, 2001, pp. 391–394.
[5] M. Polverino, F. Polverino, M. Fasolino, F. Andò, A. Alfieri, and
F. De Blasio, “Anatomy and neuro-pathophysiology of the cough
reflex arc,” Multidisciplinary respiratory medicine, vol. 7, no. 1,
p. 5, 2012.
[6] G. A. Fontana and J. Widdicombe, “What is cough and what
should be measured?” Pulmonary pharmacology & therapeutics,
vol. 20, no. 4, pp. 307–312, 2007.
[7] C. Pham, “Mobicough: Real-time cough detection and monitoring using low-cost mobile devices,” in Intelligent Information and
Database Systems, N. T. Nguyen, B. Trawiński, H. Fujita, and T.P. Hong, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg,
2016, pp. 300–309.
[8] R. X. A. Pramono, S. A. Imtiaz, and E. Rodriguez-Villegas, “A
cough-based algorithm for automatic diagnosis of pertussis,” PloS
one, vol. 11, no. 9, 2016.
[9] A. Windmon, M. Minakshi, P. Bharti, S. Chellappan, M. Johansson, B. A. Jenkins, and P. R. Athilingam, “Tussiswatch: A smartphone system to identify cough episodes as early symptoms of
chronic obstructive pulmonary disease and congestive heart failure,” IEEE journal of biomedical and health informatics, vol. 23,
no. 4, pp. 1566–1573, 2018.
[10] G. Botha, G. Theron, R. Warren, M. Klopper, K. Dheda,
P. Van Helden, and T. Niesler, “Detection of tuberculosis by automatic cough sound analysis,” Physiological measurement, vol. 39,
no. 4, p. 045005, 2018.
[11] P. Porter, U. Abeyratne, V. Swarnkar, J. Tan, T.-w. Ng, J. M. Brisbane, D. Speldewinde, J. Choveaux, R. Sharan, K. Kosasih et al.,
“A prospective multicentre study testing the diagnostic accuracy
of an automated cough sound centred analytic system for the identification of common respiratory disorders in children,” Respiratory research, vol. 20, no. 1, p. 81, 2019.
[12] “Cambridge university, UK - COVID-19 sounds app,” Weblink
https://covid-19-sounds.org/en/, last accessed May 8, 2020.
[13] “CMU
sounds
for
covid
project,”
Weblink
https://node.dev.cvd.lti.cmu.edu/, last accessed May 8, 2020.
[14] “Cough against covid - wadhwani AI institute,” Weblink
https://coughagainstcovid.org/, 2020.
[15] “Cough
for
COVID-19
detection,”
https://coughvid.epfl.ch/, last accessed May 8, 2020.

Weblink

[16] A. Imran, I. Posokhova, H. N. Qureshi, U. Masood, S. Riaz,
K. Ali, C. N. John, and M. Nabeel, “AI4COVID-19: AI enabled
preliminary diagnosis for COVID-19 from cough samples via an
app,” arXiv preprint arXiv:2004.01275, 2020.
[17] K. Anderson, Y. Qiu, A. R. Whittaker, and M. Lucas, “Breath
sounds, asthma, and the mobile phone,” The Lancet, vol. 358, no.
9290, pp. 1343–1344, 2001.

[18] “Breathing
sounds
for
COVID-19,”
Weblink
https://breatheforscience.com/, last accessed May 8, 2020.
[19] L. Lee, R. G. Loudon, B. H. Jacobson, and R. Stuebing, “Speech
breathing in patients with lung disease,” American Review of Respiratory Disease, vol. 147, pp. 1199–1199, 1993.
[20] A. Chang and M. P. Karnell, “Perceived phonatory effort and
phonation threshold pressure across a prolonged voice loading
task: a study of vocal fatigue,” Journal of Voice, vol. 18, no. 4,
pp. 454–466, 2004.
[21] C. M. Sapienza, E. T. Stathopoulos, and W. Brown Jr, “Speech
breathing during reading in women with vocal nodules,” Journal
of Voice, vol. 11, no. 2, pp. 195–201, 1997.
[22] “Indian institute of science - Coswara: A sound based diagnostic tool for covid19,” Weblink https://coswara.iisc.ac.in/, last accessed May 8, 2020.

