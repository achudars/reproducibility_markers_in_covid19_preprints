CovidCare: Transferring Knowledge from Existing EMR to
Emerging Epidemic for Interpretable Prognosis
Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan,
Yasha Wang, Wen Tang, and Jiangtao Wang
1 Key

Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China
Engineering Research Center of Software Engineering, Peking University, Beijing, China
3 School of Electronics Engineering and Computer Science, Peking University, Beijing, China
4 School of Computing and Communications, Lancaster University, UK
5 Division of Nephrology, Peking University Third Hospital, Beijing, China
malt@pku.edu.cn

arXiv:2007.08848v1 [cs.LG] 17 Jul 2020

2 National

ABSTRACT
Due to the characteristics of COVID-19, the epidemic develops
rapidly and overwhelms health service systems worldwide. Many
patients suffer from systemic life-threatening problems and need
to be carefully monitored in ICUs. Thus the intelligent prognosis is
in an urgent need to assist physicians to take an early intervention,
prevent the adverse outcome, and optimize the medical resource
allocation. However, in the early stage of the epidemic outbreak,
the data available for analysis is limited due to the lack of effective
diagnostic mechanisms, rarity of the cases, and privacy concerns. In
this paper, we propose a deep-learning-based approach, CovidCare,
which leverages the existing electronic medical records to enhance
the prognosis for inpatients with emerging infectious diseases. It
learns to embed the COVID-19-related medical features based on
massive existing EMR data via transfer learning. The transferred
parameters are further trained to imitate the teacher model’s representation behavior based on knowledge distillation, which embeds
the health status more comprehensively in the source dataset. We
conduct the length of stay prediction experiments for patients on
a real-world COVID-19 dataset. The experiment results indicate
that our proposed model consistently outperforms the comparative
baseline methods. CovidCare also reveals that, 1) hs-cTnI, hs-CRP
and Platelet Counts are the most fatal biomarkers, whose abnormal
values usually indicate emergency adverse outcome. 2) Normal
values of γ -GT, AP and eGFR indicate the overall improvement of
health. The medical findings extracted by CovidCare are empirically confirmed by human experts and medical literatures.

CCS CONCEPTS
• Information systems → Data mining; • Applied computing → Health informatics; • Computing methodologies →
Knowledge representation and reasoning.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Woodstock ’20, 2020, Woodstock
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00

KEYWORDS
COVID-19, Transfer Learning, Healthcare Informatics
ACM Reference Format:
Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao,
Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang. 2020. CovidCare:
Transferring Knowledge from Existing EMR to Emerging Epidemic for
Interpretable Prognosis. In Woodstock ’20: ACM, 2020, Woodstock. ACM,
New York, NY, USA, 10 pages.

1

INTRODUCTION

The whole world is now facing the unprecedented crisis brought
by COVID-19. The exponential growth of COVID-19 patients has
brought massive pressure on the health systems tragically, such
as overwhelming the national health service and exhausting the
intensive care units (ICUs). It is crucially essential to personalize
prognosis for the individual patient by considering her/his specific
health condition to enable a timely and early medical intervention,
as shown in Figure 1. The accurate prediction of the remaining
length-of-stay for inpatients is critical for scheduling and optimizing limited hospital resources [14].
However, for newly-emerged infectious diseases (e.g., COVID19, SARS) and rare diseases, the prognosis performed by human
physicians may not meet the clinical demand, especially in rural areas and developing countries. Moreover, the precise risk prediction
requires a high level of clinical expertise and experience [28]. However, the accumulation of clinical experience is time-consuming
and difficult at the early outbreak of the new emerging infectious
disease (EID). Thus it is difficult for human physicians to comprehensively evaluate the health of patients and accurately identify
the key factors, especially in a situation where the deterioration of
some EIDs in the early stage is usually not evident [20]. So during
treating COVID-19, it is not so rare that physicians omit the ominous signs and miss the chance of early intervention, especially
when the clinical resources are insufficient.
As a result, intelligent prognosis is in an urgent need against
EID and rare diseases. It not only can assist physicians to perform
early diagnosis, select personalized treatments, and prevent adverse
outcomes, but also optimize the allocation of medical resources and
reduce the medical cost [37]. Recently, many deep learning-based
models have been developed to enable intelligent prognosis by
analyzing electronic medical records (EMRs), including mortality
prediction [24, 25], disease diagnosis prediction [22], and patient

Woodstock ’20, 2020, Woodstock

EMR

Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang

Health Status
Prognosis

Lab Test

Current time
Diagnosis

record1record2ŏ recordt

Time
Future

Figure 1: Performing health evaluation is crucial for early
clinical intervention and medical resource management.

phenotype identification [1]. To enrich the feature extraction and
health status representation, most existing research works utilize
sophisticated modules to extract health status representations that
require a large amount of labeled training data. However, the quantity of labeled clinical data available for prognosis may not be ideal
in practice in the early stage of the EID outbreak [16], due to the following reasons. 1) The precise diagnostic mechanism has not been
established in the early outbreak. Before introducing the nucleic
acid detection mechanism, it is difficult to confirm whether a patient
is really infected with COVID-19. For example, there are only 41
patients diagnosed with COVID-19 due to the lack of valid testing
methods at the early outbreak in Wuhan, [16]. 2) The disease is still
progressing for patients. The collection of enough outcomes needs
to take a long time. 3) There are serious privacy concerns about
electronic medical records, so the data-sharing mechanism for EID
across multiple hospitals worldwide usually cannot be established
timely. Therefore, the scarce labeled data will decrease the performance of deep learning models due to the potential over-fitting.
Recently some researchers try to exploit additional information
to deal with the scarcity of clinical data. On one hand, some researches encode ontology resources and structured relationships
among medical codes (e.g., diagnosis of diabetes) in the network
to enhance the representation learning. For example, GRAM [5]
and KAME [23] introduce the external well-organized ontology
information (e.g., International Classification of Diseases Codes) to
represent the medical concept as a combination of its ancestors in
the ontology via an attention mechanism. However, for the new
EIDs like COVID-19, such relationship and ontology information
are also difficult to acquire. On the other hand, some researchers
try to make full use of the existing time series data through transfer
learning. For instance, Doctor AI [4] and Gupta [12] train deep models at one hospital and transfer them to another hospital. However,
these methods can only be adapted for the same tasks with similar
clinical features between the source and target dataset. TimeNet
[12] has been trained on different non-clinical time series datasets
via an RNN autoencoder in an unsupervised manner to extract
generic features for patient phenotyping. However, the extracted
general-purpose features may not be suitable for a specific clinical
task, leading to the underperformance of the model.
Therefore, for the prognosis of EIDs with limited data, such a
research challenge remains: How to make full use of the existing EMR

data to learn the robust health status representation, when tackling
tasks with different clinical feature sets?
In this paper, we propose a novel healthcare predictive approach,
CovidCare, based on transfer learning from existing EMR data
(i.e., source dataset) to the new dataset (i.e., target dataset) with
knowledge distillation. To improve the compatibility across source
dataset and target dataset with different feature sets, CovidCare
evaluates the health status of patients mainly from the perspective
of clinical features rather than visits. The time series of each feature
is embedded separately by GRUs. When training on the target
dataset, the shared features of both datasets are specifically encoded
by a pre-trained GRU. The model with private features trained on
the source dataset is treated as a teacher network to guide the
embedding behavior of the shared features. Doing so is able to
further explore and leverage the information stored in the source
dataset. Finally, feature-wise attention is deployed to abstract the
biomarkers and adaptively identify the critical features for patients
in diverse health conditions. In summary, CovidCare contributes
to the community from the following aspects:
• We propose a transfer-learning-based medical feature embedding approach, CovidCare, to perform clinical prediction for
EIDs with limited data .Multi-channel architecture is developed
to improve the compatibility across source and target datasets
with different feature sets. By jointly optimizing the prediction
loss and similarity loss, the student model with shared features
is learned to imitate the teacher model’s encoding behavior with
full features on the source dataset. We further use the feature
re-calibration module to provide the interpretability, which explicitly enhances high-risk features.
• We conduct length-of-stay prediction experiments for inpatients
with COVID-19. The results show that CovidCare significantly
and consistently outperforms the baseline approaches for all
evaluation metrics.
• CovidCare can extract valuable medical findings for COVID-19:
– Hypersensitive Cardiac Troponin, Hypersensitive C-Reactive Protein and Platelet Counts are the most fatal biomarkers, whose
abnormal values usually indicate emergency adverse outcome.
– Normal values of γ -Glutamyl Transpeptidase, Alkaline Phosphatase and estimated Glomerular Filtration Rate indicate the
overall improvement of health.
We invite medical practitioners to evaluate the extracted medical
knowledge and prognosis cases. Human experts positively confirmed the clinical significance in the aspects of early prediction,
key biomarkers extraction, and clinical resources management.
• Beyond COVID-19, we also conduct mortality risk prediction
for outpatients with end-stage renal diseases (ESRD) to verify
the applicability of CovidCare to other diseases with limited
EMR. The extensive experiments demonstrate that CovidCare
can significantly benefit the prognosis for future pandemics and
rare diseases.

2 RELATED WORK
2.1 Prognosis for COVID-19
Outbreaks of the COVID-19 epidemic have been causing worldwide health concerns and was officially declared a pandemic by the
World Health Organization (WHO) on March 11, 2020. Although

CovidCare: Transferring Knowledge from Existing EMR to Emerging Epidemic for Interpretable Prognosis

the ultimate impact of COVID-19 is uncertain, it has significantly
overwhelmed health care infrastructure. All emerging viral pandemics can place extraordinary and sustained demands on public
health and health systems and providers of essential community services [27]. Limited health-care resource availability will increase the
chance of being infected while waiting for treatment and also the
mortality rate [18]. This eventually leads to an increase in the severity of the pandemic. The rapidly growing imbalance between supply
and demand for medical resources in many countries presents an
inherent normative question: How can we make early and accurate
risk prediction to allocate medical resources effectively during a
pandemic?
Many COVID-related researches focus on the severity of disease
rather than the clinical outcome of mortality [8, 10, 36]. These
studies answer key clinical questions on COVID-19 evolution and
outcomes, as well as potential risk factors leading to hospital and
ICU admission. However, they cannot make individualized risk
predictions for patients. Recently, Li et al. [38] use machine learningbased methods such as decision tree to make risk prediction for
COVID-19 patients. However, as discussed above, many challenges,
such as data scarcity and model interpretability, have not been
adequately addressed. To optimize patient care and appropriately
deploy health care resources during this pandemic, effective and
reliable early risk prediction is still an essential and urgent problem.

2.2

Deep-Learning-Based EMR Analysis

With the prevalence of electronic healthcare information systems
in various healthcare institutions, a large amount of Electronic
Medical Records (EMR) have been accumulated over time[21, 32].
EMR is a type of multivariate time series data that records patients’
visits in hospitals (e.g., diagnoses, lab tests, as shown in Figure 2).
This provides essential healthcare information for the data-driven
clinical status prediction. Deep learning-based models have shown
the capability to perform mortality prediction [9, 11, 15, 34], patients
subtyping [1], and diagnosis prediction [1, 6, 22, 26, 29, 31]. For
most of the researches, extracting advanced clinical features and
learning the compressed representation of the sparse EMR data are
fundamental procedures of clinical healthcare prediction.
EMR is longitudinally complex [7, 40]. Extracting the advanced
clinical representation would introduce more parameters into the
model, making the model more complex and hard to train. For EIDs
and some rare diseases, the quantity of labeled data is much less,
which can not support a model to be trained thoroughly. In order
to deal with this issue, some researches try to introduce additional
information about the data.
On one hand, GRAM [5] and KAME [23] incorporate the external
medical information (e.g., ontologies of the medical codes), which
makes the model to be trained more sufficiently. They exploit medical knowledge in the whole prediction process by using a given
medical ontology (i.e., knowledge graph), such as the International
Classification of Diseases (ICD), to learn the representations of medical codes and obtain the embeddings of medical codes’ ancestors.
MIME [7] learns the multi-level embedding of data according to the
knowledge about the inherent EMR structure (e.g., the multi-level
relationship among medical codes). However, such external structured information and the extra knowledge about the data are often

Woodstock ’20, 2020, Woodstock

Table 1: Notations used in CovidCare
Notation
yT ,t ar
ŷT ,t ar
yT ,sr c
ŷT ,sr c
Rsr c
Rt ar
R̃t ar
ri
fi
fi∗
s
X t ea
X stu
X t ar

Definition
Groundtruth of LOS prediction at T -th admission on target dataset
Prediction result at T -th admission on source dataset
Groundtruth of prediction at T -th admission on source dataset
Prediction result at T -th admission on source dataset
The whole source dataset
The whole target dataset
Target dataset (only included shared features with source dataset)
A time series record of the i-th medical feature
Embedding of the i-th medical feature
Embedding of the i-th medical feature after self-attention
Overall representation of patient
Model/Embeddings/Parameters used in Teacher model
Model/Embeddings/Parameters used in Student model
Model/Embeddings/Parameters used in Target model

not easy to be accessed or used in the clinical practice for EIDs.
Ontology information is usually designed to handle the medical
codes. It is not suitable for dealing with numerical lab tests, which
also are essential clinical features to capture health status.
On the other hand, some researchers try to explore the existing
EMR data. Choi [4] empirically confirms that RNN models possess
great potential for transfer learning across different medical institutions. Gupta [12] trains a deep RNN to identify several patient
phenotypes on time series from MIMIC-III database, and then uses
the features extracted using that RNN to build classifiers for identifying previously unseen phenotypes. However, these methods can
only be utilized for the same tasks with the same clinical feature
sets between source and target datasets. TimeNet [13] is pre-trained
on non-medical time series in an unsupervised manner and further
utilized to extract features for clinical prediction. Nevertheless, the
extracted general-purpose features may not be suitable for exploring the specific clinical task, thus leading to limited performance.

3

PROBLEM FORMULATION

Many patients suffering from COVID-19 face severe life threats and
need careful health monitoring and medical treatment in ICU. Typically, some biomarkers, such as Hypersensitive C-Reactive Protein,
are recorded through the treatment trajectories, and further have
been taken into consideration for the prognosis. Accurate prediction
of health status can help with assessing the severity of illness; and
determining the value of novel treatments, interventions, and health
care policies [30]. Besides, due to the characteristics of COVID-19,
large numbers of sick people appear for treatment during peak
illness periods. Clinics and hospitals are overwhelmed. Predicting
remaining time spent in ICU (i.e., length of stay) for admission is
also vital for scheduling and hospital resource management.
Below we define the data and task studied in this work and
provide the list of notations used in CovidCare in Table 1.
Definition: Electronic Medical Records (EMR) Electronic
Medical Records (EMR) data are routinely collected patient observations from hospitals through the clinical admissions, including
discrete time-series data (e.g., medication, diagnosis) and continuous multivariate data (e.g., vital signs, laboratory measurements),
as shown in Figure 2. The admissions generating N features such
as different lab test results denoted as r i ∈ RT (i = 1, 2, · · · , N ).
Each medical feature contains T timesteps, as shown in Figure 2. As

Woodstock ’20, 2020, Woodstock

…

…

ce
r
Ca
n

We
ig

…

UR
TI

Physical lab test New-onset complications

ht

um
in
Alb

te
Da

Pa

tie
n

t ID

Blood lab test

Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang

98 19/12/2015

35.0

66.3

0

0

98 22/01/2016

38.2

65.2

1

0

118 09/07/2015

32.8

49.8

0

1

…

…

Figure 2: Medical features. The physician conducts the necessary lab tests for the patient at each admission.

a result, such a clinical sequence can be formulated as a âĂĲlongitudinal patient matrixâĂİ record, where one dimension represents
medical features and the other denotes admission timestamps [21].
Problem: Length of stay prediction The prediction problem
in this paper can be formulated as given Nr historic EMR data of
a patient, i.e., (r 1 , · · · , r N ), how to predict the patient’s remaining time spent in ICU, ŷ (i.e., length of stay). We frame length of
stay (LOS) prediction as a classification problem with 12 classes
(discharging in 1/2/3/5/10/10+ days, suffering adverse outcome in
1/2/3/5/10/10+ days).

4 METHODOLOGY
4.1 Overview
Figure 3 shows the framework of the proposed CovidCare, which
comprises of the following procedures. The whole model training
process is shown in the Appendix, Algorithm 1.
• Multivariate time series with all features are fed into the healthcare representation learning module as a teacher model to build
the comprehensive embedding in the source dataset.
• The student model in the source dataset learns to embed the
proper health status based on features that are shared with the
target dataset, by imitating the teacher model’s embedding behavior.
• The learned parameters of feature embedding are transferred
to the healthcare representation learning model for the target
dataset, and further fine-tuned to perform the task-specific prediction.

4.2

Healthcare Representation Learning

In this subsection, we will introduce the patient health status embedding module based on ConCare [25], which is a healthcare
context representation learning method. There are three layers designed in this module, which consist of the feature extracting layer,
self-attention layer, and prediction layer.
We utilized the multichannel GRU mechanism in the feature
extracting layer to capture different patterns of each medical feature
individually, which is also designed to improve the scalability and
compatibility of the feature-specific model transfer. Specifically,
we apply N different GRUs to embed the N medical features. Each
feature i can be described as a time series r i = (r i1 , r i2 , · · · , r iT ),
and will be fed into the corresponding GRUi to generate feature
embedding fi : fi = GRUi (r i1 , r i2 , · · · , r iT ). The feature embedding
matrix F = (f1 , f2 , · · · , f N )T .

In the self-attention layer, we employ the multi-head self-attention
mechanism to obtain information from the health context and better understand the correlations between medical features. This
mechanism makes each feature adaptively interact with all other
features, and combine information from the related ones according
to self-attention weights. Mathematically, the self-attention weight
matrix of head i:
Qi KT
Ai = Softmax( p i )
(1)
dk
Q

where Qi = F · Wi , Ki = F · WiK , and dk is the size of the row
vector of matrix Ki . And the result of feature interaction in head i:
headi = Ai Vi
where Vi = F ·
And finally, the embedding matrix
feature interaction:

(2)
F∗

after

F∗ = (f1∗ , ..., f N∗ )T = (head 0 ⊕ head 1 ⊕ ... ⊕ headm )WO

(3)

WiV .

We also utilize the attention mechanism to integrate embeddings of all features fi∗ into an overall representation of patient
s, and interpret the importance of medical features at the same
time. Eventually, in the prediction layer, we apply a full-connection
layer to conduct corresponding prediction tasks, and we select
cross-entropy as the loss term Lpr ed .
Lpr ed = CE(ŷT , yT ) = −

B
1Õ b
[yT log(ŷTb ) + (1 − yTb ) log(1 − ŷTb )]
B
b=1

(4)

4.3

Knowledge Distillation

Firstly, we will introduce the feature-specific transfer learning mechanism. As we mentioned before, a small data volume of the dataset
may restrict a deep learning model’s training performance. If our
target task only consists of relatively few data items, it is necessary
to make use of the existing EMR dataset with a bigger data volume
to help our model training. Because the information and pattern
extracted from a bigger dataset are always more stable and general,
which is also useful to our target model.
Based on the patient health status embedding module introduced
above, we conduct feature-specific transfer learning on feature
extraction layer, since this layer mainly captures the general pattern
of medical features, which is independent of patient cohorts and
prediction tasks. Concretely, we transfer GRUs of shared features
from the source model to the target model, so that we can make
up for the shortcomings of small data volume by transfer obtained
knowledge from a bigger dataset.
However, we have not sufficiently extracted information from
our source dataset since some private features remain unused, and
it is obvious that unused features in the source dataset can also
provide sufficient significant information. In other words, with a
complete source dataset, we can capture correlations between features more sufficiently, and thus generating a more comprehensive
representation of patients.
Therefore, we proposed a knowledge distillation method to construct a more comprehensive transfer source model. We divide the
source model into two parts, teacher model and student model. The

CovidCare: Transferring Knowledge from Existing EMR to Emerging Epidemic for Interpretable Prognosis

y^T,src
Similar

……

fNsrc*

f1*

fNsrc

f1

Feature Extraction Layer
GRUs for
shared features

r0,src

ri,src
Teacher Model

f1*

fNsrc*

……

f2

fC

f1

……

f2

……

fNtar*

……

fNtar

Feature Extraction Layer
GRUs for
shared features

GRUs for
shared features

……

f2*

Self Attention Layer

Feature Extraction Layer

GRUs for
private features

……

……

f2*

Self Attention Layer

……

f2

+

+

Self Attention Layer
f1

star

sstu

+

f2*

Prediction Layer

Prediction Layer

Linear

stea

f1*

y^T,tar

y^T,src

^
stea

Prediction Layer

Woodstock ’20, 2020, Woodstock

Transfer Pre-trained GRUs

r0,tar

r0,src
Student Model

GRUs for
private features

……

ri,tar
Target Model

……

Target Dataset & Task

Source Dataset & Task
Figure 3: The CovidCare Framework
student model is trained on the source dataset with only shared features (R̃sr c ) and will be transferred to the target model. While the
teacher model is trained on the complete dataset with all features
(Rsr c ), but only auxiliary to student model and will not be transferred. Specifically, ’Knowledge distillation’ exactly means we hope
the student model could imitate the behavior of the teacher model
to learn a more comprehensive representation of patients, just like
the teacher model does. We design an additional loss term for this,
which encourages the student model to restore the representation
learned by the teacher model.
In detail, we first train the teacher model to generate representation st ea for every patient with loss term Lt ea = Lpr ed . We
then train the student model, where the representation sstu should
perform two functions, to predict corresponding task labels, and
to imitate st ea by a linear layer as much as possible. We use KLdivergence to calculate the similarity of the two representations.
ŝt ea = sstu · Wstu

(5)

Lemb = D K L (Softmax(ŝt ea )||Softmax(st ea ))

(6)

D K L (P ||Q) =

Õ
i

Pi log(

Pi
)
Qi

(7)

The loss of student model (Lstu ) is described as the sum of two
parts accordingly, Lstu = Lpr ed + Lemb . And finally we tranfer
GRUs from student model to target model, and fine tune the target
model with target dataset(Rt ar ) using loss term Lt ar = Lpr ed .

5

EXPERIMENT

We conduct the experiment that leveraging data from PhysioNet
Source Dataset [33] to enhance the LOS prediction for COVID19 [38].

Table 2: Statistics of the Datasets
Dataset

PhysioNet

COVID-19

# of patients
# of admissions
Avg. # of admissions per patient
Max. # of admissions per patient
Min. # of admissions per patient
# of features
# of adverse outcomes
% of adverse outcomes

40,336
1,552,210
38.48
336
8
33
2,932
7.26%

375
6,120
16.32
59
1
74
174
46.40%

5.1

Data Description

5.1.1 COVID-19 target Dataset. We take the COVID-19 dataset
[38] as the target dataset and perform the LOS prediction. The medical information of all patients collected between 10 January and
18 February 2020 was used for model development. The average
age of the patients was 58.83 years, and 59.7% were male. Of the
375 cases included in the subsequent analysis, 201 recovered from
COVID-19 and were discharged from the hospital, while 174 died.
Statistics of source dataset and target dataset are listed in the Appendix. Statistics of the LOS are listed in Table 5. Without loss of
generality, we perform the length of stay prediction for patients
at 10th admission in this paper. The distribution of days to the
outcome for admissions are shown in Figure 5. Medical features
recorded in COVID-19 target dataset are listed in Table 6.
5.1.2 PhysioNet Source Dataset. We take the PhysioNet Dataset [33]
as the source dataset and pre-train the medical feature embedding
based on the Sepsis prediction. This dataset is sourced from ICU
patients in two separate U.S. hospital systems. These data were
collected over the past decade with approval from the appropriate

Woodstock ’20, 2020, Woodstock

Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang

Table 3: Length of Stay Prediction Performance

Methods

Transfer

GRU
MC-GRU
ConCare
TimeNet
MC-GRUt
CovidCare s t u
CovidCare

×
×
×
√
√
√
√

Length of Stay Prediction Performance on COVID-19 Dataset
AUPRC
AUROC-Macro AUROC-Micro
min(Se, P+)
0.2146 (0.0343)
0.2603 (0.0331)
0.3046 (0.0312)
0.2908 (0.0325)
0.2946 (0.0331)
0.2989 (0.0342)
0.3252 (0.0457)

Institutional Review Boards. They are labeled by Sepsis-3 clinical
criteria. The cleaned dataset consists of 40,336 patients and consists
of a combination of hourly vital sign summaries (e.g., heart rate,
systolic blood pressure), laboratory values (e.g., Chloride, Glucose).
In particular, the data contained 33 clinical variables: 8 vital sign
variables and 25 laboratory variables. The statistics of the datasets
are presented in Table 2. Medical features recorded in the PhysioNet
source dataset are listed in Table 6.

5.2

Experimental Setup

5.2.1 Evaluation Preparation. Due to the limited amount of data,
5-fold cross-validation is employed on the prediction task. We do
not separate independent test data. We assess the performance
of multi-classification using the area under the receiver operating characteristic curve (AUROC-Micro/Macro), area under the
precision-recall curve (AUPRC), the minimum of precision and sensitivity Min(Se, P+). Note that Micro calculates metrics globally by
considering each element of the label indicator matrix as a label.
Macro calculates metrics for each label and find their unweighted
mean. This does not take label imbalance into account.
5.2.2 Baseline Approaches. We introduce several deep-learningbased models as our baseline approaches without additional labeled
data or external ontology resources.
• GRU is the basic Gated Recurrent Unit network.
• MC-GRUs embeds the clinical feature via separate GRUs.
• MC-GRUst is pre-trained at the source dataset to obtain the
parameters of corresponding GRUs.
• ConCare (AAAI 2020) [25] embeds the feature sequences separately and uses the self-attention to model dynamic features and
static baseline information.
• TimeNet (IJCAI 2018) [13] maps variable-length clinical time
series to fixed-dimensional feature vectors separately, and acts
as an off-the-shelf feature extractor. It is pre-trained on the UCR
time series Repository.
• CovidCare stu is the proposed CovidCare without knowledge
distillation from the teacher model.

5.3

Experiment Results

As is shown in Table 3 CovidCare consistently outperforms both
transfer-based and non-transfer-based baselines, demonstrating its
ability to learn a robust representation. CovidCare achieves 6.8%
relative higher AUPRC and 1.5% higher min(Se, P+) compared to
the best state-of-the-art models ConCare and TimeNet. Comparing

0.6636 (0.0464)
0.7702 (0.0334)
0.7792 (0.0214)
0.7752 (0.0299)
0.7761 (0.0300)
0.7768 (0.0160)
0.7859 (0.0202)

0.7325 (0.0362)
0.8044 (0.0247)
0.8199 (0.0186)
0.8093 (0.0229)
0.8155 (0.0189)
0.8146 (0.0130)
0.8245 (0.0230)

0.2608 (0.0435)
0.3038 (0.0276)
0.3483 (0.0114)
0.3354 (0.0356)
0.3413 (0.0308)
0.3236 (0.0231)
0.3538 (0.0246)

all the methods with and without transfer mechanism, we can tell
that utilizing preset knowledge from existing EMR can significantly
promote the prediction performance of all models, indicating the
effectiveness of the transfer learning mechanism. Moreover, we
can see that CovidCare shows a higher performance than TimeNet.
Both models employ feature-level transfer. However, our model
CovidCare executes a more adaptive and reasonable transfer, which
explains the superiority of our model’s performance. The knowledge distillation mechanism makes sense as well. Compared to
the reduced CovidCarestu model, CovidCare also achieves higher
performance in terms of all metrics. This indicates that developing knowledge distillation based on leveraging existing EMR can
enhance healthcare prediction.

5.4

Implications for COVID-19

To quantitatively identify the reasonability of feature recalibration
from an overall perspective and extract useful medical knowledge,
we calculate the average importance weights of biomarkers for
patients in diverse conditions. As shown in Figure 4, some essential medical knowledge learned by CovidCare can be summarized.
Many of them have been proved or mentioned in COVID-19 related
medical literature. We also invite medical practitioners to evaluate
the findings empirically.
• Hypersensitive Cardiac Troponin has the most distinct difference
between discharging and death cases, which means that CovidCare
considers it as a significant mortality risk indicator. According to
Chapman et al [2], troponin is elevated in one in five patients who
have (confirmed) COVID-19 and that the presence of elevated
troponin in COVID-19 may be associated with higher mortality risk. COVID-19 patients with elevated troponin may also be
more likely to require ventilation and develop acute respiratory
distress syndrome. For these patients, if clinicians are reluctant
to measure cardiac troponin, they may ignore the plethora of
ischaemic and non-ischaemic causes of myocardial injury related
to COVID-19, which leads to a higher mortality rate.
• γ -Glutamyl Transpeptidase (GGT) and Alkaline Phosphatase are
another two key features that CovidCare identified. They are
significant biomarkers related to liver injury. According to a recent study published in the Lancet [39], they are all related to
COVID-19 patients’ health status. Liver damage in mild cases
of COVID-19 is often transient and can return to normal without any special treatment. However, when severe liver damage
occurs, liver protective drugs have usually been given to such
patients. In their case studies, GGT is elevated in 30 (54%) of 56

CovidCare: Transferring Knowledge from Existing EMR to Emerging Epidemic for Interpretable Prognosis

Woodstock ’20, 2020, Woodstock

      

  , P S U R Y H   ' L V F K D U J H  
 ' L V F K D U J H  

      

 ' D \ V  W R  2 X W F R P H

 ' L V F K D U J H  
 ' L V F K D U J H  

      

 ' L V F K D U J H   
 ' L V F K D U J H !  

      

 ' H D W K !  
      

 ' H D W K   
 ' H D W K  

      

 ' H D W K  
 ' H D W K  

      

 +  + V
 6 H  H P   F 7
 3 U  U X P  R J  Q ,
 R W    O R E
 K U  F K  L Q
 R P  O R
 3 U  E L Q  U L G H
 ( R  R F D   W L P
 V L  O F  H
 $ O
 Q R  L W R
 N D
 S K  Q L
 O L Q
 L O V  Q
 H 
  
 S K
 R V  , /   
 S K   5
 D W
 D
 E D  D O E  V H
 X
 , Q  V R S  P L
 W H  K  Q
 U  L
 7 R  O H X  O  
 W  N L  
 3 O  D O  E  Q  
 D  L O  
 0  W H O H  L U X E
 R Q  W   L Q
 R  F R
 $ Q  F \ W H  X Q W
 W L W  V 
 ,  K U  
 , Q  Q W H  R P  
 G L  U O H  E L
 U H  X  Q
 F W  N L
 4
  E  Q 
 X D
 L O L U  
 Q W
 X E
 Q H
 L I L
 L Q
 F D
 X W
 U R  5 '
 W L R
 Q   W  S K  :
 R I  R W  L O V
 3 U   7  D O   
 R W  3    S U  
 K U  D Q  R W
 R P  W L  H L
 E L  E R G  Q
 Q   L H
 D F  V
 W L Y
 +  L W \
 % V
 $
 7 X
 K H  0  J
 P
 P  & 9
 R U
 D W
  Q
 R F
 H F
 U
 U R
 V L  :  L W
 V   %
 I D  &
 F W
 R
 0  U
 &
 I
 , Q  L E U L  + &
 W H  Q R
 U O H  J
 X N  H Q
 O \
 P
 L Q
 S K
 
 R F  8  
 \ W  U H
 H   D
 F
 3 +  R X
  Y  Q W
 ( R
 D O
 X H
 &  V L Q
 R U  R
 U  S  5
 6 H  H F W H  K L O  F  % &
 U X  G   R X
 P  F D  Q W
  S  O F
 R W  L X
 D V  P
 1
 H X
 V
 W U R  *  L X P
 0
 S K  O X F
 H D  '  L O  R V
 Q   L U H  V  F  H
 5
 S O  F W   R X
 % &
 D W  E  Q
 H O  L O L U  W
  G
 H W  X E
 L V
  Y  L Q
 W U L
 R O
 E X
 X P
 W L R
 +
 Q  I H  H
 &
 7 K   Z  U U L W
 9 
 D Q
 U R  L G  L Q
 W L E     P E  W K  6
 R G   O \  L Q  '
 \   P   W L P
 T X  S K  H
 D Q  R F
 W L  \
 7 R  '  I L F D  W H
 W D   '  W L R
 O  F   G  Q
 K R  L P
 O H  H U
 V W
 H U
 R O
 8  $ 6
 U L F  7
  D
 / D
 +  F L G
 &
 F W
 2
 D W
 H   1  & D   
 G H  7  O F L
 K \   S U  X P
 G U  R %
 R J  1
 H Q  3
 D
 , Q  3  V H
 W H   /
 U O H  &
 X N  5
 3 /  P R
 L Q
 7   Q R
 G L  F \  )   
 V W  W H  '
  J
 U L E  V  3
 , Q  O X W D
 X W   F R
 W H  P
 L
 R
 U Q  \
  
 Q   X Q W
 D W  O  W U
 Z
  
 L R  D  J  L G
  Q
 Q D  Q V  O R  W K
 P  & R
 O  V  S H  E X
 H D  9   E  W D  S  O L Q
 Q   Q X  D V  Q G  W L G
 F R  F O  R S  D  D V
 U S  H L F  K  U G   H
 X V   D  L O  F  U D
 F X  F L G  R X  W L R
 O D   G  Q W
 U  K  H   
 H P  W H F  
 +
 , 9
 R J  W L R Q
  D
 O R
 Q W
 E L
 L E
 Q
 R G
 D  
 \ 
 T X  +  3 7 7
 D  V
 V H  Q W L  & 5
 U X  I L F D  3
 W K  P  W
 U R   V  L R
 P  R G  Q
 E R  L X
 F \  P
 W R
 F U
 L
 ( 6  W
 5
 *
 3 7
 H
 *
 F U
 H D  ) 5
 W L Q
 L Q
 H

  & U L W L F D O   ' H D W K  

 % L R P D U N H U

Figure 4: Importance of Medical Features Differentiated by CovidCare. Features marked in red are fatal indicators for patients in critical conditions, whose abnormal values indicate the emergency adverse outcome. Features marked in green are
discharging indicators, whose normal values indicate an overall improvement and soon discharging.
Table 4: Mortality Prediction Performance for ESRD

Methods

Trans.

GRU
MC-GRU
ConCare
TimeNet
MC-GRUt
CovidCare s t u
CovidCare

×
×
×
√
√
√
√

Mortality Prediction Performance
AUPRC
AUROC
min(Se, P+)
0.7142 (.0883)
0.7335 (.0757)
0.7291 (.0827)
0.6328 (.0310)
0.7466 (.0486)
0.7414 (.0692)
0.7614 (.0584)

0.8094 (.0547)
0.8193 (.0468)
0.8259 (.0456)
0.7311 (.0262)
0.8260 (.0330)
0.8263 (.0427)
0.8361 (.0385)

0.6668 (.0544)
0.6670 (.0645)
0.6784 (.0573)
0.5926 (.0194)
0.6963 (.0306)
0.6723 (.0523)
0.7046 (.0353)

patients with COVID-19 during hospitalization in their center.
They also mention that elevated alkaline phosphatase levels are
observed in one (1Âů8%) of 56 patients with COVID-19 during
hospitalization.
• estimated Glomerular Filtration Rate (eGFR), Urea and Creatinie
are kidney injury-related biomarkers, and their difference between live and death cases are also distinct. According to Cheng
et al [3], for on admission COVID-19 patients, Creatinie and Urea
are elevated in 14.4% and 13.1% of the patients, respectively. eGFR
< 60 ml/min per 1.73 m2 is reported in 13.1% of patients. Compared with patients with normal Creatinie, those who entered the
hospital with an elevated Creatinie are older and more severely
ill. The incidence of in-hospital death in patients with elevated
baseline serum creatinine is 33.7%, which is significantly higher
than in those with normal baseline serum creatinine (13.2%).

6

EXTENDED DATASET EVALUATION

In order to further verify the generality of CovidCare, we also conduct an additional experiment on end-stage renal disease (ESRD)
dataset. We take the ESRD dataset as the target dataset and perform
the mortality prediction. Currently, many people are suffered from
ESRD in the world [17, 35]. They face severe life threats and need
lifelong treatments with periodic visits to the hospitals for multifarious tests (e.g., blood routine examination). The whole procedure
needs a dynamic patient health risk prediction to help patients
recover smoothly and prevent the adverse outcome, based on the

medical records collected along with the visits. The core task of
CovidCare is to learn the health status representation of the patient
and perform the healthcare prediction.
In this study, all ESRD patients who received therapy from January 1, 2006, to March 1, 2018, in a real-world hospital are included
to form this dataset. During and after data collection and analysis,
we did not identify individual participants as the patients’ names,
and they were replaced by patient ID. This study was approved by
the Medical Scientific Research Ethical Committee. We drop the
patients whose all entries of one feature are missing and select the
observed features in more than 60% of patients’ records. For missing values, we fill the missing front cells with the data backward
to prevent future information leakage. If the patient’s backward
record is missing, we impute it with the first front observed record
of the patient.
The cleaned dataset consists of 662 patients and 13,108 visits.
The statistics of the ESRD dataset are presented in Table 7. Medical
features recorded in the ESRD target dataset are listed in Table 8.
The mortality prediction task on ESRD datasets is defined as a
binary classification task of predicting the death of a patient in one
year.
For the binary classification task, we assess performance using
the area under the receiver operating characteristic curve (AUROC), area under the precision-recall curve (AUPRC), and the minimum of precision and sensitivity Min(Se, P+). According to Table 4,
CovidCare consistently outperforms other baseline approaches for
all metrics. The experiment results verify the applicability of our
proposed framework. CovidCare can not only predict LOS for new
EID, but also perform mortality prediction for ESRD, which is the
disease with limited EMR.

7

CONCLUSIONS

In this paper, we propose a transfer learning-based prognosis solution, CovidCare, to perform the length of stay prediction for
patients with COVID-19. In order to embed the medical features
robustly, the model is trained to imitate the teacher model’s medical
embedding behavior via knowledge distillation. The experimental
results on the real-world COVID-19 dataset show that CovidCare

      

Woodstock ’20, 2020, Woodstock

Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang

consistently outperforms several competitive baseline methods.
More importantly, CovidCare identifies several key indicators (e.g.,
hs-cTnI, hs-CRP and Platelet Counts) for patients with critical conditions, and those abnormal values indicate potential emergent
adverse outcomes. CovidCare also reveals that normal values of
γ -GT, AP and eGFR indicate the overall improvement of health
and a possible early-discharging. The medical findings extracted
by CovidCare are empirically validated and confirmed by human
experts and medical literature. We believe the proposed model,
CovidCare, will significantly benefit the intelligent prognosis for
tackling future emerging infectious diseases such as COVID-19.

REFERENCES
[1] Inci M Baytas, Cao Xiao, Xi Zhang, Fei Wang, Anil K Jain, and Jiayu Zhou. 2017.
Patient subtyping via time-aware LSTM networks. In Proceedings of the 23rd ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM,
65–74.
[2] Andrew R Chapman, Anda Bularga, and Nicholas L Mills. 2020. High-sensitivity
cardiac troponin can be an ally in the fight against COVID-19. Circulation (2020).
[3] Yichun Cheng, Ran Luo, Kun Wang, Meng Zhang, Zhixiang Wang, Lei Dong,
Junhua Li, Ying Yao, Shuwang Ge, and Gang Xu. 2020. Kidney disease is associated
with in-hospital death of patients with COVID-19. Kidney International (2020).
[4] Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F Stewart, and
Jimeng Sun. 2015. Doctor AI: Predicting Clinical Events via Recurrent Neural
Networks. (2015).
[5] Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F Stewart, and Jimeng
Sun. 2017. GRAM: graph-based attention model for healthcare representation
learning. In Proceedings of the 23rd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining. ACM, 787–795.
[6] Edward Choi, Mohammad Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy
Schuetz, and Walter Stewart. 2016. Retain: An interpretable predictive model
for healthcare using reverse time attention mechanism. In Advances in Neural
Information Processing Systems. 3504–3512.
[7] Edward Choi, Cao Xiao, Walter Stewart, and Jimeng Sun. 2018. Mime: Multilevel
medical embedding of electronic health records for predictive healthcare. In
Advances in Neural Information Processing Systems. 4547–4557.
[8] Amir Emami, Fatemeh Javanmardi, Neda Pirbonyeh, and Ali Akbari. 2020. Prevalence of underlying diseases in hospitalized patients with COVID-19: a systematic
review and meta-analysis. Archives of academic emergency medicine 8, 1 (2020).
[9] Cristóbal Esteban, Oliver Staeck, Stephan Baier, Yinchong Yang, and Volker Tresp.
2016. Predicting clinical events by combining static and dynamic information
using recurrent neural networks. In Healthcare Informatics (ICHI), 2016 IEEE
International Conference on. Ieee, 93–101.
[10] Leiwen Fu, Bingyi Wang, Tanwei Yuan, Xiaoting Chen, Yunlong Ao, Tom Fitzpatrick, Peiyang Li, Yiguo Zhou, Yifan Lin, Qibin Duan, et al. 2020. Clinical
characteristics of coronavirus disease 2019 (COVID-19) in China: a systematic
review and meta-analysis. Journal of Infection (2020).
[11] Junyi Gao, Cao Xiao, Yasha Wang, Wen Tang, Lucas M Glass, and Jimeng Sun.
2020. StageNet: Stage-Aware Neural Networks for Health Risk Prediction. In
Proceedings of The Web Conference 2020. 530–540.
[12] Priyanka Gupta, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff. 2018. Transfer Learning for Clinical Time Series Analysis using Recurrent Neural Networks.
arXiv preprint arXiv:1807.01705 (2018).
[13] Priyanka Gupta, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff. 2018. Using
Features from Pre-trained TimeNet for Clinical Predictions. In The 3rd International Workshop on Knowledge Discovery in Healthcare Data at IJCAI.
[14] Hrayr Harutyunyan, Hrant Khachatrian, David C Kale, Greg Ver Steeg, and Aram
Galstyan. 2019. Multitask learning and benchmarking with clinical time series
data. Scientific data 6, 1 (2019), 1–18.
[15] Jay Heo, Hae Beom Lee, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho Yang,
and Sung Ju Hwang. 2018. Uncertainty-aware attention for reliable interpretation
and prediction. In Advances in Neural Information Processing Systems. 909–918.
[16] Chaolin Huang, Yeming Wang, Xingwang Li, Lili Ren, Jianping Zhao, Yi Hu, Li
Zhang, Guohui Fan, Jiuyang Xu, Xiaoying Gu, et al. 2020. Clinical features of
patients infected with 2019 novel coronavirus in Wuhan, China. The lancet 395,
10223 (2020), 497–506.
[17] Tamara Isakova, Huiliang Xie, Wei Yang, Dawei Xie, Amanda Hyre Anderson,
Julia Scialla, Patricia Wahl, Orlando M Gutiérrez, Susan Steigerwalt, Jiang He,
et al. 2011. Fibroblast growth factor 23 and risks of mortality and end-stage renal
disease in patients with chronic kidney disease. Jama 305, 23 (2011), 2432–2439.
[18] Yunpeng Ji, Zhongren Ma, Maikel P Peppelenbosch, and Qiuwei Pan. 2020. Potential association between COVID-19 mortality and health-care resource availability.
The Lancet Global Health 8, 4 (2020), e480.

[19] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014).
[20] Stephen A Lauer, Kyra H Grantz, Qifang Bi, Forrest K Jones, Qulu Zheng, Hannah R Meredith, Andrew S Azman, Nicholas G Reich, and Justin Lessler. 2020.
The incubation period of coronavirus disease 2019 (COVID-19) from publicly
reported confirmed cases: estimation and application. Annals of internal medicine
172, 9 (2020), 577–582.
[21] Chonho Lee, Zhaojing Luo, Kee Yuan Ngiam, Meihui Zhang, Kaiping Zheng,
Gang Chen, Beng Chin Ooi, and Wei Luen James Yip. 2017. Big healthcare data
analytics: Challenges and applications. In Handbook of Large-Scale Distributed
Computing in Smart Healthcare. Springer, 11–41.
[22] Wonsung Lee, Sungrae Park, Weonyoung Joo, and Il-Chul Moon. 2018. Diagnosis
Prediction via Medical Context Attention Networks Using Deep Generative
Modeling. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE,
1104–1109.
[23] Fenglong Ma, Quanzeng You, Houping Xiao, Radha Chitta, Jing Zhou, and Jing
Gao. 2018. Kame: Knowledge-based attention model for diagnosis prediction in
healthcare. In Proceedings of the 27th ACM International Conference on Information
and Knowledge Management. ACM, 743–752.
[24] Liantao Ma, Junyi Gao, Yasha Wang, Chaohe Zhang, Jiangtao Wang, Wenjie Ruan,
Wen Tang, Xin Gao, and Xinyu Ma. 2020. AdaCare: AdaCare: Explainable Clinical
Health Status Representation Learning via Scale-Adaptive Feature Extraction
and Recalibration. In Thirty-Fourth AAAI Conference on Artificial Intelligence.
[25] Liantao Ma, Chaohe Zhang, Yasha Wang, Wenjie Ruan, Jiangtao Wang, Wen
Tang, Xinyu Ma, Xin Gao, and Junyi Gao. 2020. ConCare: Personalized Clinical
Feature Embedding via Capturing the Healthcare Context. In Thirty-Fourth AAAI
Conference on Artificial Intelligence.
[26] Tengfei Ma, Cao Xiao, and Fei Wang. 2018. Health-ATM: A Deep Architecture
for Multifaceted Patient Health Record Representation and Risk Prediction. In
Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM,
261–269.
[27] US Department of Health, Human Services, et al. 2017. Pandemic influenza plan:
2017 Update. URL https://www. cdc. gov/flu/pandemic-resources/pdf/pan-flu-report2017v2. pdf (2017).
[28] T Pedersen, K Eliasen, and Eet al Henriksen. 1990. A prospective study of
mortality associated with anaesthesia and surgery: risk indicators of mortality in
hospital. Acta Anaesthesiologica Scandinavica 34, 3 (1990), 176–182.
[29] Trang Pham, Truyen Tran, Dinh Phung, and Svetha Venkatesh. 2016. Deepcare: A
deep dynamic memory model for predictive medicine. In Pacific-Asia Conference
on Knowledge Discovery and Data Mining. Springer, 30–41.
[30] Sanjay Purushotham, Chuizheng Meng, Zhengping Che, and Yan Liu. 2017. Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets. arXiv:
Learning (2017).
[31] Zhi Qiao, Shiwan Zhao, Cao Xiao, Xiang Li, Yong Qin, and Fei Wang. 2018.
Pairwise-Ranking based Collaborative Recurrent Neural Networks for Clinical
Event Prediction.. In IJCAI. 3520–3526.
[32] Chandan K Reddy and Charu C Aggarwal. 2015. Healthcare data analytics.
Chapman and Hall/CRC.
[33] Matthew A Reyna, Christopher S Josef, Russell Jeter, Supreeth P Shashikumar,
M Brandon Westover, Shamim Nemati, Gari D Clifford, and Ashish Sharma.
2019. Early prediction of sepsis from clinical data: the PhysioNet/Computing in
Cardiology Challenge 2019. Critical Care Medicine (2019).
[34] Harini Suresh, Jen J Gong, and John Guttag. 2018. Learning Tasks for Multitask Learning: Heterogenous Patient Populations in the ICU. arXiv preprint
arXiv:1806.02878 (2018).
[35] Navdeep Tangri, David Ansell, and David Naimark. 2011. Determining factors
that predict technique survival on peritoneal dialysis: application of regression
and artificial neural network methods. Nephron Clinical Practice 118, 2 (2011),
c93–c100.
[36] Xinhui Wang, Xuexian Fang, Zhaoxian Cai, Xiaotian Wu, Xiaotong Gao, Junxia
Min, Fudi Wang, et al. 2020. Comorbid Chronic Diseases and Acute Organ Injuries
Are Strongly Correlated with Disease Severity and Mortality among COVID-19
Patients: A Systemic Review and Meta-Analysis. Research 2020 (2020), 2402961.
[37] Gary E Weissman, Andrew Crane-Droesch, Corey Chivers, ThaiBinh Luong, Asaf
Hanish, Michael Z Levy, Jason Lubken, Michael Becker, Michael E Draugelis,
George L Anesi, et al. 2020. Locally informed simulation to predict hospital
capacity needs during the COVID-19 pandemic. Annals of internal medicine
(2020).
[38] Li Yan, Hai-Tao Zhang, Jorge Goncalves, Yang Xiao, Maolin Wang, Yuqi Guo,
Chuan Sun, Xiuchuan Tang, Liang Jing, Mingyang Zhang, et al. 2020. An interpretable mortality prediction model for COVID-19 patients. Nature Machine
Intelligence (2020), 1–6.
[39] Chao Zhang, Lei Shi, and Fu-Sheng Wang. 2020. Liver injury in COVID-19:
management and challenges. The lancet Gastroenterology & hepatology 5, 5 (2020),
428–430.
[40] Kaiping Zheng, Jinyang Gao, Kee Yuan Ngiam, Beng Chin Ooi, and Wei
Luen James Yip. 2017. Resolving the bias in electronic medical records. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery

CovidCare: Transferring Knowledge from Existing EMR to Emerging Epidemic for Interpretable Prognosis

Table 6: Features Recorded in COVID-19 and PhysioNet
Dataset
Shared Features
Hs-cTnI
Hemoglobin
Serum chloride
Alkaline phosphatase
Total bilirubin
Creatinine
Hematocrit
WBC
Fibrinogen
Urea
PH value
Serum potassium
Glucose
Direct bilirubin
HCO3Calcium
aPTT

Private in PhysioNet
Heart rate
Pulse oximetry
Temperature
Systolic BP
MAP
Platelet count
Diastolic BP
Respiration rate
EtCO2
Excess HCO3
FiO2
PaCO2
SaO2
AST
Lactic acid
Magnesium
Phosphate

Private in COVID-19
γ -GT
Procalcitonin
Albumin
HBsAg
Globulin
HsCRP
Serum sodium
Red blood cell count
nucleic acid detection
Monocytes
Antithrombin
Total protein
HCV-AQ
Total cholesterol
Lactate dehydrogenase
HIV-AQ
...

Algorithm 1 CovidCare (Rsr c , Rt ar )
1:
2:
3:
4:
5:
6:
7:
8:

while not convergence do:
Compute ŷT ,sr c , st ea = CovidCaret ea (Rsr c )
Compute Lpr ed = CE(ŷT ,sr c , yT ,sr c )
Compute Lt ea = Lpr ed
Update parameters of CovidCaret ea by optimizing Lt ea
using back-propagation
end while
Randomly initializing parameters in Student Model CovidCare
stu

9:
10:
11:
12:
13:
14:
15:

16:

Value
656
244
261
13091
1196
10804
1091
49%

Randomly initializing parameters in Teacher Model CovidCare
t ea

Table 7: Statistics of ESRD Dataset
Statistic
# patients
# patient with diabetes
# patient died
# visit
# visit in high risk
# visit in low risk
# visit in uncertain
% female

17:
18:
19:
20:
21:

while not convergence do:
Compute ŷT ,sr c , ŝt ea = CovidCarestu (R̃sr c )
Compute Lpr ed = CE(ŷT ,sr c , yT ,sr c ),
Lemb =
D K L (Softmax(ŝt ea )||Softmax(st ea ))
Compute Lstu = Lpr ed + Lemb
Update parameters of CovidCarestu by optimizing Lstu
using back-propagation
end while
Transfer parameters of shared GRUs from CovidCare stu to
Target Model CovidCare t ar , and randomly initializing other
parameters in CovidCare t ar
while not convergence do:
Compute ŷT ,t ar = CovidCarestu (Rt ar )
Compute Lpr ed = CE(ŷT ,t ar , yT ,t ar )
Compute Lt ar = Lpr ed
Update parameters of CovidCaret ar by optimizing Lt ar
using back-propagation
end while
Table 5: Statistics of Length of Stay for COVID-19

Table 8: Features Recorded in ESRD Target Dataset
Shared Features
Systolic BP
Diastolic BP
Urea
Calcium
Chloride
Creatinine
Glucose
Phosphate
Potassium
Hemoglobin
WBC Count

Private in ESRD
Sodium
CO2CP
Albumin
hs-CRP
Weight
Amount

Woodstock ’20, 2020, Woodstock

Avg. # of admissions per patient
Avg. # of LOS per patient
Avg. # of LOS per admission

All

Discharging

Death

16.29
10.85
8.2

16
13.45
9.71

16.7
7.85
6.52

and Data Mining. ACM, 2171–2180.

A APPENDIX
A.1 Experiment Environment
The experiment environment is a machine equipped with CPU: Intel
Xeon E5-2630, 256GB RAM, and GPU: Nvidia RTX8000. The code
is implemented based on Pytorch 1.5.0. To train the model, we use
Adam [19] with the batch size of 256, and the learning rate is set to
1e −3. To fairly compare different approaches, the hyper-parameters
of the baseline models are fine-tuned by the grid-searching strategy.

Woodstock ’20, 2020, Woodstock

80
70

Liantao Ma, Xinyu Ma, Junyi Gao, Chaohe Zhang, Zhihao Yu, Xianfeng Jiao, Wenjie Ruan, Yasha Wang, Wen Tang, and Jiangtao Wang

Discharge
Death

Patient

60
50
40
30
20
10
0

Day<1

Day<2

Day<3

Day<5

Day<10 Day>10

Days to Outcome

Figure 5: Days to Outcome for Admissions of Patients with
COVID-19

