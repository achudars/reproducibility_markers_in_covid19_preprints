arXiv:2101.07433v2 [eess.IV] 26 Jan 2021

COVID-Net CT-2: Enhanced Deep Neural Networks
for Detection of COVID-19 from Chest CT Images
Through Bigger, More Diverse Learning

1

Hayden Gunraj1,∗ , Ali Sabri5 , David Koff6 , and Alexander Wong2,3,4,∗
Department of Mechanical and Mechatronics Engineering, University of Waterloo, Canada
2
Department of Systems Design Engineering, University of Waterloo, Canada
3
Waterloo Artificial Intelligence Institute, Canada
4
DarwinAI Corp., Canada
5
Department of Radiology, Niagara Health, McMaster University, Canada
6
Department of Radiology, Hamilton Health Sciences, McMaster University, Canada
∗
Corresponding authors: {hayden.gunraj,a28wong}@uwaterloo.ca

Abstract
Background: The COVID-19 pandemic continues to rage on around the world,
with multiple waves causing substantial harm to health and economies around the
world. Motivated by the use of computed tomography (CT) imaging at clinical
institutes around the world as an effective complementary screening method to
RT-PCR testing, we introduced COVID-Net CT, a deep neural network tailored
for detection of COVID-19 cases from chest CT images, along with a large curated benchmark dataset comprising 1,489 patient cases as part of the open source
COVID-Net initiative. However, one potential limiting factor is restricted quantity
and diversity given the single nation patient cohort used in the study.
Methods: Motivated by the success of COVID-Net CT, we introduce COVIDNet CT-2, enhanced deep neural networks for COVID-19 detection from chest CT
images trained on the largest quantity and diversity of multinational patient cases
in research literature. We accomplish this through the introduction of two new CT
benchmark datasets, the largest of which comprises a multinational cohort of 4,501
patients from at least 15 countries. To the best of our knowledge, this represents the
largest, most diverse multinational cohort for COVID-19 CT images in open access
form. We leverage explainability to investigate the decision-making behaviour of
COVID-Net CT-2 to ensure that decisions are based on relevant indicators, with the
results for select cases reviewed and reported on by two board-certified radiologists
with over 10 and 30 years of experience, respectively.
Results: The COVID-Net CT-2 neural networks achieved accuracy, COVID-19
sensitivity, positive predictive value, specificity, and negative predictive value of
98.1%/96.2%/96.7%/99%/98.8% and 97.9%/95.7%/96.4%/98.9%/98.7%, respectively. Explainability-driven performance validation shows that COVID-Net CT-2’s
decision-making behaviour is consistent with radiologist interpretation by leveraging correct, clinically relevant critical factors.
Conclusions: The results are promising and suggest the strong potential of deep
neural networks as an effective tool for computer-aided COVID-19 assessment.
While not a production-ready solution, we hope the open-source, open-access
release of COVID-Net CT-2 and benchmark datasets1 will continue to enable
researchers, clinicians, and citizen data scientists alike to build upon them.
1

https://github.com/haydengunraj/COVIDNet-CT

Preprint. Under review.

1

Introduction

The coronavirus disease 2019 (COVID-19) pandemic, caused by severe acute respiratory syndrome
coronavirus 2 (SARS-CoV-2), continues to rage on around the world, with multiple waves causing
substantial harm to health and economies around the world. Real-time reverse transcription polymerase chain reaction (RT-PCR) testing remains the primary screening tool for COVID-19, where
SARS-CoV-2 ribonucleic acid (RNA) is detected within an upper respiratory tract sputum sample [1].
However, despite being highly specific, the sensitivity of RT-PCR can be relatively low [2, 3] and can
vary greatly depending on the time since symptom onset as well as sampling method [4, 3, 5].
Clinical institutes around the world have explored the use of computed tomography (CT) imaging as
an effective, complementary screening tool alongside RT-PCR [2, 5, 6]. In particular, studies have
shown CT to have great utility in detecting COVID-19 infections during routine CT examinations
for non-COVID-19 related reasons such as elective surgical procedure monitoring and neurological
examinations [7, 8]. Other scenarios where CT imaging has been leveraged include cases where
patients have worsening respiratory complications, as well as cases where patients with negative
RT-PCR test results are suspected to be COVID-19 positive due to other factors. Early studies have
shown that a number of potential indicators for COVID-19 infections may be present in chest CT
images [9, 10, 11, 12, 2, 5, 6], but may also be present in non-COVID-19 infections. This can lead to
challenges for radiologists in distinguishing COVID-19 infections from non-COVID-19 infections
using chest CT [13, 14].
Inspired by the potential of CT imaging as a complementary screening method and the challenges of
CT interpretation for COVID-19 screening, we previously introduced COVID-Net CT [15], a deep
convolutional neural network tailored for detection of COVID-19 cases from chest CT images. We
further introduced COVIDx CT, a large curated benchmark dataset comprising of chest CT scans from
a cohort of 1,489 patients derived from a collection by the China National Center for Bioinformation
(CNCB) [16]. Both COVID-Net CT and COVIDx CT were made publicly available as part of the
COVID-Net [17, 18] initiative, an open source initiative2 aimed at accelerating advancement and
adoption of deep learning in the fight against the COVID-19 pandemic. While COVID-Net CT was
able to achieve state-of-the-art COVID-19 detection performance, one potential limiting factor is
the restricted quantity and diversity of CT imaging data used to learn the deep neural network given
the entirely Chinese patient cohort used in the study. As such, a greater quantity and diversity in
the patient cohort has the potential to improve generalization, particularly when COVID-Net CT is
leveraged under different clinical settings around the world.
Motivated by the success and widespread adoption of COVID-Net CT and COVIDx CT, as well as
its potential data quantity and diversity limitations, in this study we introduce COVID-Net CT-2,
enhanced deep convolutional neural networks for COVID-19 detection from chest CT images that
are trained on a large, diverse, multinational patient cohort. More specifically, we accomplish this
through the introduction of two new CT benchmark datasets (COVIDx CT-2A and COVIDx CT-2B),
the largest of which comprises a multinational cohort of 4,501 patients from at least 15 countries.
To the best of the authors’ knowledge, these benchmark datasets represent the largest, most diverse
multinational cohorts for COVID-19 CT images available in open access form. Finally, we leverage
explainability to investigate the decision-making behaviour of COVID-Net CT-2 to ensure decisions
are based on relevant visual indicators in CT images, with the results for select patient cases being
reviewed and reported on by two board-certified radiologists with 10 and 30 years of experience,
respectively. The COVID-Net CT-2 networks and corresponding COVIDx CT-2 datasets are publicly
available as part of the COVID-Net initiative [17, 18]. While not a production-ready solution, we
hope the open-source, open-access release of the COVID-Net CT-2 networks and the corresponding
COVIDx CT-2 benchmark datasets will enable researchers, clinicians, and citizen data scientists alike
to build upon them.

2

Methods

In this study, we introduce COVID-Net CT-2 L and COVID-Net CT-2 S, a pair of enhanced deep
convolutional neural networks for the detection of COVID-19 from chest CT. To train and test
these networks, we further introduce two COVIDx CT-2 benchmark datasets which represent the
2

https://alexswong.github.io/COVID-Net

2

Figure 1: COVID-Net CT-2 architecture design and COVIDx CT-2 benchmark. We leverage the
COVID-Net CT network architecture [15] as the core of the COVID-Net CT-2 networks (COVIDNet CT-2 L network shown in figure, with COVID-Net CT-2 S network sharing same macroarchitecture design but fewer parameters), which was discovered automatically via machine-driven design
exploration. Some interesting characteristics about the COVID-Net CT-2 design include a very diverse
yet lightweight designs (∼16.8× and ∼52.6× lower architectural complexity than ResNet-50 [19]
for COVID-Net CT-2 L and S networks, respectively) and selective long-range connectivity to draw a
balance between complexity and representational power. The COVID-Net CT-2 design was trained
on CT scans from a large, diverse, multinational cohort of patient cases across at least 15 countries
(i.e., COVIDx CT-2).
largest, most diverse multinational patient cohorts for COVID-19 CT images available in open
access form, spanning cases from at least 15 countries. A visual overview of COVID-Net CT-2
and COVIDx CT-2 is shown in Figure 1. The methodology behind the preparation of the two
COVIDx CT-2 benchmark datasets, the construction and learning of the COVID-Net CT-2 networks,
and the explainability-driven performance validation process are described in detail below.
2.1

COVIDx CT-2 benchmark dataset preparation

The original COVIDx CT benchmark dataset consists of chest CT scans collected by the China
National Center for Bioinformation (CNCB) [16] which were carefully processed and selected to
form a cohort of 1,489 patient cases. While COVIDx CT is significantly larger than many CT datasets
for COVID-19 detection in literature, a potential limitation with leveraging COVIDx CT for learning
deep neural networks is the limited diversity in terms of patient demographics. More specifically,
the cohort of patients used in COVIDx CT are collected in different provinces of China, and as such
the characteristics of COVID-19 infection as observed in the chest CT images may not generalize to
patients around the world outside of China. Therefore, increasing the quantity and diversity of the
patient cohort in constructing new benchmark datasets could result in more diverse, well-rounded
learning of deep neural networks. In doing so, improved generalization and applicability for use
under different clinical environments around the world can be achieved.
In this study, we carefully processed and curated CT images from several patient cohorts from around
the world which were collected using a variety of CT equipment types, protocols, and levels of
validation. By unifying CT imaging data from several cohorts from around the world, we created two
diverse, large-scale benchmark datasets:
• COVIDx CT-2A: This benchmark dataset comprises 194,922 CT images from a multinational cohort of 3,745 patients between 0 and 93 years old (median age of 51) with strongly
clinically-verified findings. The multinational cohort consists of patient cases collected
by the following organizations and initiatives from around the world: (1) China National
Center for Bioinformation (CNCB) [16] (China), (2) National Institutes of Health Intramural
Targeted Anti-COVID-19 (ITAC) Program (hosted by TCIA [20], countries unknown), (3)
Negin Radiology Medical Center [21] (Iran), (4) Union Hospital and Liyuan Hospital of
3

Figure 2: Patient distribution across training, validation, and test for COVIDx CT-2A (left) and
COVIDx CT-2B (right).

Huazhong University of Science and Technology [22] (China), (5) COVID-19 CT Lung and
Infection Segmentation initiative, annotated and verified by Nanjing Drum Tower Hospital [23] (Iran, Italy, Turkey, Ukraine, Belgium, some countries unknown), (6) Lung Image
Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) [24] (countries
unknown), and (7) Radiopaedia collection [25] (Iran, Italy, Australia, Afghanistan, Scotland,
Lebanon, England, Algeria, Peru, Azerbaijan, some countries unknown).
• COVIDx CT-2B: This benchmark dataset comprises 201,103 CT images from a multinational cohort of 4,501 patients between 0 and 93 years old (median age of 51) with a mix of
strongly verified findings and weakly verified findings. The patient cohort in COVIDx CT2B consists of the multinational patient cohort we leveraged to construct COVIDx CT-2A,
which have strongly clinically-verified findings, with additional patient cases with weakly
verified findings collected by the Research and Practical Clinical Center of Diagnostics
and Telemedicine Technologies, Department of Health Care of Moscow (MosMed) [26]
(Russia). Notably, these additional cases are only included in the training dataset, and as
such the validation and test datasets are identical to those of COVIDx CT-2A.
In both COVIDx CT-2 benchmark datasets, the findings for the chest CT volumes corresponds to
three different infection types: (1) novel coronavirus pneumonia due to SARS-CoV-2 viral infection
(NCP), (2) common pneumonia (CP), and (3) normal controls, with the patient distribution for the
three infection types across training, validation, and test shown in Figure 2. For CT volumes labelled
as NCP or CP, slices containing abnormalities were identified and assigned the same labels as the CT
volumes. Notably, patient age was not available for all cases, and as such the age ranges and median
ages reported above are based on patient cases for which age was available. For images which were
originally in Hounsfield units (HU), a standard lung window centered at -600 HU with a width of
1500 HU was used to map the images to unsigned 8-bit integer range (i.e., [0, 255]).
The rationale for creating two different COVIDx CT-2 benchmark datasets stems from the availability
of weakly verified findings (i.e., findings not based on RT-PCR test results or final radiology reports),
which can be useful for further increasing the quantity and diversity of patient cases that a deep
neural network can be exposed to and can be of great interest for researchers, clinicians, and citizen
scientists to explore and build upon while being made aware of the fact some of the CT scans do
not have strongly verified findings available. Both COVIDx CT-2A and COVIDx CT-2B benchmark
datasets are publicly available3 as part of the COVID-Net initiative, with example CT images from
each type of infection shown in Figure 3.
3

https://www.kaggle.com/hgunraj/covidxct

4

2.2

COVID-Net CT-2 construction and learning

By leveraging the COVIDx CT-2 benchmark datasets introduced in the previous section, we build the
COVID-Net CT-2 deep convolutional neural networks in a way that is more generalizable and more
readily adoptable to a wider range of clinical scenarios around the world through bigger, more diverse
learning on the largest quantity and diversity of multinational patient cases in research literature.
More specifically, two COVID-Net CT-2 networks are built (COVID-Net CT-2 L and COVID-Net CT2 S), with both sharing the same macroarchitecture design but different number of parameters. The
COVID-Net CT-2 architecture is shown in Figure 1, and the networks are made publicly available4 .
More specifically, we leverage the COVID-Net CT network architecture design proposed in [15]
as the core of the architecture designs of the COVID-Net CT-2 networks. The architecture designs
were discovered automatically via a machine-driven design exploration process using generative
synthesis [27], where the macroarchitecture and microarchitecture designs of a tailored deep neural
network architecture for the task and data at hand is determined via iterative constrained optimization
based on a universal performance function (e.g., [28]) and a set of quantitative constraints. The
result is highly customized architecture designs that strike a strong balance between complexity and
representational power beyond what a human designer can achieve alone.
The COVID-Net CT-2 designs possess several interesting architectural characteristics. First, COVIDNet CT-2 designs exhibit very diverse yet lightweight designs composed largely of a heterogeneous
combination of strided and unstrided depthwise convolutions as well as pointwise convolutions, with
unique microarchitecture design characteristics tailored during the machine-driven design exploration
process. Second, COVID-Net CT-2 leverages selective long-range connectivity through several point
convolution hubs to draw a balance between architectural complexity and representational power. As
a result of these macroarchitecture and microarchitecture design traits tailored around COVID-19
detection from CT images, the COVID-Net CT-2 architecture designs have, at ∼1.4M parameters
and ∼0.45M parameters, approximately ∼16.8× and ∼52.6× lower architectural complexity than
ResNet-50 [19], respectively.
The constructed COVID-Net CT-2 deep convolutional neural networks were trained on the
COVIDx CT-2A benchmark dataset via stochastic gradient descent with momentum [29], where
the following hyperparameters were leveraged: learning rate=5e-4, momentum=0.9, number of
epochs=25, batch size=64. To further increase data diversity beyond what is provided by the large
multinational cohort in order to improve the generalization of COVID-Net CT-2, we leveraged data
augmentation in the form of cropping box jitter, rotation, horizontal and vertical shear, horizontal
flip, and intensity shift and scaling. The construction, training, and evaluation of COVID-Net CT-2
networks were conducted using the TensorFlow [30] machine learning library.
2.3

Explainability-driven performance validation via model auditing

As with COVID-Net CT [15], we utilize GSInquire [31] as the explainability method of choice to
conduct explainability-driven performance validation, Using GSInquire, we audit the trained COVIDNet CT-2 to better understanding and verify its decision-making behaviour when analyzing CT
images to predict the condition of a patient. This form of performance validation via model auditing
is particularly important in a clinical context, as the decisions made about a patient’s conditions
can affect the health of patients via treatment and care decisions made using a model’s predictions.
Therefore, examining the decision-making behaviour through model auditing is key to ensuring that
the right visual indicators in the CT scans (in the case of COVID-19 infections, visual anomalies
such as ground-glass opacities and bilateral abnormalities) are leveraged for making a prediction as
opposed to irrelevant visual cues (e.g., synthetic padding, circular scan artifacts, patient table, etc.).
Furthermore, incorporating interpretability in the validation process also increases the level of trust
that a clinician has in leveraging such models for clinical decision support by adding an extra degree
of algorithmic transparency.
To facilitate explainability-driven performance validation via model auditing, GSInquire provides
an explanation of how a model makes a decision based on input data by identifying a set of critical
factors within the input data that impact the decision-making process of the deep neural network in
a quantitatively significant way. This is accomplished by probing the model with an input signal
(in this case, a CT image) as the targeted stimulus signal and observing the reactionary response
4

https://github.com/haydengunraj/COVIDNet-CT

5

Figure 3: Example CT images from the COVIDx CT-2 benchmark datasets from each type of
infection: (1) normal coronavirus pneumonia due to SARS-CoV-2 infection (NCP), (2) common
pneumonia (CP), and (3) normal controls.

signals throughout the model, thus enabling quantitative insights to be derived through the inquisition
process. These quantitative insights are then transformed and projected into the same space as the
input signal to produce an interpretation (in this case, a set of critical factors in the CT image that
quantitatively led to the prediction of the patient’s condition). These interpretations can be visualized
spatially relative to the CT images for greater insights into the decision-level behaviour of COVIDNet CT-2. Compared to other explainability methods [32, 33, 34, 35, 36], this interesting nature of
GSInquire in identifying quantitative impactful critical factors enables it to achieve explanations
that better reflect the decision-making process of models when compared to other state-of-the-art
explainability methods [31]. This makes it particularly suitable for quality assurance of models prior
to clinical deployment to identify errors, biases, and anomalies that can lead to ‘right decisions for
the wrong reasons’. The results obtained during the explainability-driven performance validation via
model auditing for select patient cases are further reviewed and reported on by two board-certified
radiologists (A.S. and D.K.). The first radiologist (A.S.) has over 10 years of experience, while the
second radiologist (D.K.) has over 30 years of radiology experience.
6

Table 1: Accuracy (image level) for the tested networks on the COVIDx CT-2 benchmark test dataset.
Best results highlighted in bold.

3
3.1

Network

Accuracy (%)

COVID-Net CT-1 [15]
COVID-Net CT-2 L
COVID-Net CT-2 S

94.5
98.1
97.9

Results
Quantitative analysis

To explore the efficacy of the COVID-Net CT-2 networks for COVID-19 detection from CT images,
we conducted a quantitative evaluation of the trained deep neural networks using the COVIDx CT-2
test dataset. For comparison purposes, we also conduct a quantitative comparison with COVIDNet CT [15] (referred from here on as COVID-Net CT-1 for clarity), which was previously shown
to achieve state-of-the-art performance when compared with state-of-the-art deep neural network
architectures such as ResNet-50 [37], NASNet-A-Mobile [38], and EfficientNet-B0 [39] for the task
of COVID-19 detection from CT images. The test accuracy of the COVID-Net CT-2 networks and
COVID-Net CT-1 are shown in Table 1. It can be observed that COVID-Net CT-2 L and COVIDNet CT-2 S achieved strong test accuracies of 98.1% and 97.9%, respectively, on the COVIDx CT-2
test dataset, while at the same time possessing low architectural complexity (∼1.4M parameters
and ∼0.45M parameters, respectively) and low computational complexity (∼4.18 GFLOPs and
∼1.94 GFLOPs). Compared to COVID-Net CT-1, it can be observed that COVID-Net CT-2 S and
COVID-Net CT-2 L achieved 3.4% and 3.6% higher accuracy, respectively.
The sensitivity and positive predictive value (PPV) for each infection type on the COVIDx CT-2 test
dataset is shown in Table 2 and Table 3, respectively. It can be observed that COVID-Net CT-2 L
and COVID-Net CT-2 S were able to achieve both high COVID-19 sensitivity (96.2% and 95.7%,
respectively) and high COVID-19 PPV (96.7% and 96.4%, respectively). Compared to COVIDNet CT-1, it can be observed that COVID-Net CT-2 S and COVID-Net CT-2 L achieved 15.5%
and 16% higher COVID-19 sensitivity, respectively. At the cost of significantly lower COVID-19
sensitivity, COVID-Net CT-1 is able to achieve 0.9% and 1.2% higher COVID-19 PPV than COVIDNet CT-2 L and COVID-Net CT-2 S, respectively. From a clinical perspective, high sensitivity ensures
few false negatives which would lead to missed patients with COVID-19 infections, whereas high
PPV ensures few false positives which add an unnecessary burden on the healthcare system, which is
already stressed due to the ongoing pandemic.
The specificity and negative predictive value (NPV) for each infection type on the COVIDx CT-2 test
dataset is shown in Table 4 and Table 5, respectively. It can be observed that COVID-Net CT-2 L
and COVID-Net CT-2 S were able to achieve both high COVID-19 specificity (99% and 98.9%,
respectively) and high COVID-19 NPV (98.8% and 98.7%, respectively). Compared to COVIDNet CT-1, it can be observed that COVID-Net CT-2 S and COVID-Net CT-2 L achieved 4.5% and
4.6% higher COVID-19 NPV, respectively. Notably, COVID-Net CT-1 achieves 0.4% and 0.5%
higher COVID-19 specificity than COVID-Net CT-2 L and COVID-Net CT-2 S, respectively, but
as previously mentioned this comes at the cost of significantly lower COVID-19 sensitivity. The
high specificity and NPV achieved by COVID-Net CT-2 are important from a clinical perspective to
ensure that COVID-19-negative predictions are indeed true negatives in the vast majority of cases,
which facilitates rapid identification of COVID-19-negative patients.
These experimental results are particularly promising in terms of model generalization and applicability for use under different clinical environments given the much more diverse nature of the
COVIDx CT-2 test dataset. As such, these results demonstrate the potential value of COVID-Net CT-2
as an effective clinical decision support tool to aid with COVID-19 screening.
3.2

Qualitative analysis

To audit the decision-making behaviour of COVID-Net CT-2 and ensure that it is leveraging relevant
visual indicators when predicting the condition of a patient, we conducted explainability-driven
7

Table 2: Sensitivity for each infection type at the image level on the COVIDx CT-2 benchmark test
dataset. Best results highlighted in bold.
Network

Sensitivity (%)

COVID-Net CT-1 [15]
COVID-Net CT-2 L
COVID-Net CT-2 S

Normal

CP

NCP

98.8
99.0
98.9

99.0
98.2
98.1

80.2
96.2
95.7

Table 3: Positive predictive value (PPV) for each infection type at the image level on the COVIDx CT2 benchmark test dataset. Best results highlighted in bold.
Network

PPV (%)

COVID-Net CT-1 [15]
COVID-Net CT-2 L
COVID-Net CT-2 S

Normal

CP

NCP

96.1
99.4
99.3

90.2
97.2
97.0

97.6
96.7
96.4

performance validation using the COVIDx CT-2 benchmark test dataset, and the results obtained
using COVID-Net CT-2 L for select patient cases are further reviewed and reported on by two
board-certified radiologists. The critical factors identified by GSInquire for example chest CT images
from the four COVID-19-positive cases that were reviewed are shown in Figure 4, and additional
examples for COVID-Net CT-2 S are shown in Figure 5.
Overall, it can be observed from the GSInquire-generated visual explanations that both COVIDNet CT-2 L and COVID-Net CT-2 S are mainly utilizing visible lung abnormalities to distinguish
between COVID-19-positive and COVID-19-negative cases. As such, this auditing process allows us
to determine that COVID-Net CT-2 is indeed leveraging relevant visual indicators in the decisionmaking process as opposed to irrelevant visual indicators such as imaging artifacts, artificial padding,
and patient tables. This performance validation process also reinforces the importance of utilizing
explainability methods to confirm proper decision-making behaviour in deep neural networks designed
for clinical decision support.
3.3

Radiologist findings

The expert radiologist findings and observations with regards to the critical factors identified by
GSInquire for each of the four patient cases shown in Figure 4 are as follows. In all four cases,
COVID-Net CT-2 L detected them to be novel coronavirus pneumonia due to SARS-CoV-2 viral
infection, which was clinically confirmed.
Case 1 (top-left of Figure 4). It was observed by one of the radiologists that there are bilateral
peripheral mixed ground-glass and patchy opacities with subpleural sparing, which is consistent with
the identified critical factors leveraged by COVID-Net CT-2 L. The absence of large lymph nodes
and effusion further helped the radiologist point to novel coronavirus pneumonia due to SARS-CoV-2
viral infection. The degree of severity is observed to be moderate to high. It was confirmed by the
second radiologist that the identified critical factors leveraged by COVID-Net CT-2 L are correct
areas of concern and represent areas of consolidation with a geographic distribution that is in favour
of novel coronavirus pneumonia due to SARS-CoV-2 viral infection.
Case 2 (top-right of Figure 4). It was observed by one of the radiologists that there are bilateral
peripherally-located ground-glass opacities with subpleural sparing, which is consistent with the
identified critical factors leveraged by COVID-Net CT-2 L. As in Case 1, the absence of large lymph
nodes and large effusion further helped the radiologist point to novel coronavirus pneumonia due
to SARS-CoV-2 viral infection. The degree of severity is observed to be moderate to high. It was
confirmed by the second radiologist that the identified critical factors leveraged by COVID-Net CT8

Table 4: Specificity for each infection type at the image level on the COVIDx CT-2 benchmark test
dataset. Best results highlighted in bold.
Network

Specificity (%)

COVID-Net CT-1 [15]
COVID-Net CT-2 L
COVID-Net CT-2 S

Normal

CP

NCP

96.3
99.5
99.3

95.7
98.8
98.8

99.4
99.0
98.9

Table 5: Negative predictive value (NPV) for each infection type at the image level on the COVIDx CT2 benchmark test dataset. Best results highlighted in bold.
Network

NPV (%)

COVID-Net CT-1 [15]
COVID-Net CT-2 L
COVID-Net CT-2 S

Normal

CP

NCP

98.9
99.1
99.0

99.6
99.3
99.2

94.2
98.8
98.7

2 L are correct areas of concern and represent areas of consolidation with a geographic distribution
that is in favour of novel coronavirus pneumonia due to SARS-CoV-2 viral infection.
Case 3 (bottom-left of Figure 4). It was observed by one of the radiologists that there are peripheral
bilateral patchy opacities, which is consistent with the identified critical factors leveraged by COVIDNet CT-2 L. Unlike the first two cases, there is small right effusion. However, as in Cases 1 and 2, the
absence of large effusion further helped the radiologist point to novel coronavirus pneumonia due to
SARS-CoV-2 viral infection. Considering that the opacities are at the base, a differential of atelectasis
change was also provided. The degree of severity is observed to be moderate. It was confirmed by
the second radiologist that the identified critical factors leveraged by COVID-Net CT-2 L are correct
areas of concern and represent areas of consolidation.
Case 4 (bottom-right of Figure 4). It was observed by one of the radiologists that there are
peripherally located asymmetrical bilateral patchy opacities, which is consistent with the identified
critical factors leveraged by COVID-Net CT-2 L. As in Cases 1 and 2, the absence of lymph nodes
and large effusion further helped the radiologist point to novel coronavirus pneumonia due to SARSCoV-2 viral infection, but a differential of bacterial pneumonia was also provided considering
the bronchovascular distribution of patchy opacities. In addition, there is no subpleural sparing.
This highlights the potential difficulties in differentiating between novel coronavirus pneumonia
and common pneumonia. It was confirmed by the second of the radiologists that the identified
critical factors leveraged by COVID-Net CT-2 L are correct areas of concern and represent areas of
consolidation with a geographic distribution that is in favour of novel coronavirus pneumonia due to
SARS-CoV-2 viral infection.
Therefore, it can be observed that the explainability-driven validation process shows consistency
between the decision-making process of COVID-Net CT-2 and radiologist interpretation, which
suggests strong potential for computer-aided COVID-19 assessment within a clinical environment.
Based on both quantitative and qualitative results, it can be seen that not only does COVID-Net CT
achieve high performance, but it is leveraging relevant abnormalities in the lungs in its decisionmaking process rather than erroneous visual cues.

4

Conclusions and Discussion

In this work, we introduced COVID-Net CT-2, enhanced deep convolutional neural networks tailored
for the purpose of COVID-19 detection from chest CT images via more diverse learning on the
largest quantity and diversity of multinational patient cases in research literature. Two new CT
benchmark datasets were introduced and used to facilitate the learning of COVID-Net CT-2, and
9

Figure 4: Example chest CT images from four COVID-19 cases reviewed and reported on by two
board-certified radiologists, and the associated critical factors (highlighted in red) as identified by
GSInquire [31] for COVID-Net CT-2 L. Based on the observations made by two expert radiologists,
it was found that the critical factors leveraged by COVID-Net CT-2 L are consistent with radiologist
interpretation.

these datasets represent the largest, most diverse, multinational cohorts of their kind available in
open access form, spanning cases from at least 15 countries. Experimental results show that the
COVID-Net CT-2 networks are capable of not only achieving strong test accuracy, sensitivity, and
positive predictive value, but also do so in a manner that is consistent with radiologist interpretation
via explainability-driven performance validation. The results are promising and suggest the strong
potential of deep neural networks as an effective tool for computer-aided COVID-19 assessment.
Given the severity of the COVID-19 pandemic and the potential for deep learning as a potential
tool to facilitate computer-assisted COVID-19 clinical decision support, a number of deep learning
systems have been proposed in research literature for detecting SARS-CoV-2 infections using CT
images [14, 16, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 15, 22]. While some proposed deep
learning systems focus on binary detection (SARS-CoV-2 positive vs. negative) [51], several proposed
systems operate at a finer level of granularity by further identifying whether SARS-CoV-2 negative
cases are normal control [16, 40, 48, 49], SARS-CoV-2 negative pneumonia (e.g., bacterial pneumonia,
viral pneumonia, community-acquired pneumonia (CAP), etc.) [16, 40, 41, 42, 43, 49, 50], or nonpneumonia [42].
10

Figure 5: Example chest CT images from four COVID-19 cases, and the associated critical factors
(highlighted in red) as identified by GSInquire [31] for COVID-Net CT-2 S.
The majority of the proposed deep learning systems for COVID-19 detection from CT images rely
on pre-existing network architectures that were designed for other image classification tasks. A
large number of proposed systems additionally rely on segmentation of the lung region and/or lung
lesions [14, 16, 40, 41, 42, 45, 46, 48, 49]. Some proposed systems also augment pre-existing network
architectures, with Xu et al. [40] augmenting a pre-existing ResNet-18 [19] backbone architecture with
location-attention classification, and Li et al. [42] and Bai et al. [41] augmenting pre-existing network
architectures with pooling operations for volume-driven detection. Of the deep learning systems that
proposed new deep neural network architectures, Shah et al. [44] proposed a 10-layer convolutional
neural network architecture named CTnet-10, which ultimately showed lower detection performance
than pre-existing architectures in literature. Zheng et al. [46] proposed a 3D convolutional neural
network architecture named DeCovNet which is capable of volume-driven detection. Finally, in
the system introduced by Gunraj et al. [15], machine-driven design exploration was leveraged to
construct a deep neural network architecture that is tailored specifically for COVID-19 detection
using CT images.
While the concept of leveraging deep learning for COVID-19 detection from CT images has been
previously explored, even the largest studies in research literature in this area have been limited
in terms of quantity and/or diversity of patients, with many limited to single-nation cohorts. For
example, the studies by Mei et al. [14], Gunraj et al. [15], Ning et al. [22], and Zhang et al. [16] were
all limited to Chinese patient cohorts consisting of 905 patients, 1,489 patients, 1,521 patients, and
3,777 patients, respectively. The largest multinational study in research literature was conducted by
11

Harmon et al. [51], which leveraged a cohort of 2,617 patients across 4 countries. To the best of
the authors’ knowledge, the largest of the unified multinational patient cohorts introduced in this
study represents the largest, most diverse multinational patient cohort at 4,501 patients across at
least 15 countries. By building the proposed COVID-Net CT-2 deep neural networks using a large
multinational patient cohort, we can better study the generalization capabilities and applicability
of deep learning for computer-assisted assessment under a wider diversity of clinical scenarios and
demographics.
With the tremendous burden the ongoing COVID-19 pandemic has put on healthcare systems and
healthcare workers around the world, the hope is that research such as COVID-Net CT-2 and open
source initiatives such as the COVID-Net initiative can accelerate the advancement and adoption
of deep learning solutions within a clinical setting to aid front-line health workers and healthcare
systems in improving clinical workflow efficiency and effectiveness in the fight against the COVID19 pandemic. While to the best of the authors’ knowledge this research does not put anyone at
a disadvantage, it is important to note that COVID-Net CT-2 is not a production-ready solution
and is meant for research purposes. As such, predictions made by COVID-Net CT-2 should not
be utilized blindly and should instead be built upon and leveraged in a human-in-the-loop fashion
by researchers, clinicians, and citizen data scientists alike. Future work involves leveraging the
core COVID-Net CT-2 backbone for downstream tasks such as lung function prediction, severity
assessment, and actionable predictions for guiding personalized treatment and care for SARS-CoV-2
positive patients.

Acknowledgments
We thank the Natural Sciences and Engineering Research Council of Canada (NSERC), the Canada
Research Chairs program, the Canadian Institute for Advanced Research (CIFAR), DarwinAI Corp.,
Justin Kirby of the Frederick National Laboratory for Cancer Research, and the various organizations
and initiatives from around the world collecting valuable COVID-19 data to advance science and
knowledge. The study has received ethics clearance from the University of Waterloo (42235).

Author contributions statement
H.G. and A.W. conceived the experiments, H.G. conducted the experiments, all authors analysed the
results, D.K. and A.S. reviewed and reported on select patient cases and corresponding explainability
results illustrating model’s decision-making behaviour, and all authors reviewed the manuscript.

Declaration of interests
A.W. is affiliated with DarwinAI Corp.

References
[1] W. Wang, Y. Xu, R. Gao, R. Lu, K. Han, G. Wu, and W. Tan, “Detection of sars-cov-2 in
different types of clinical specimens,” JAMA, vol. 323, no. 18, pp. 1843–1844, 05 2020.
[2] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, and W. Ji, “Sensitivity of chest ct for
covid-19: Comparison to rt-pcr,” Radiology, vol. 296, no. 2, pp. E115–E117, 2020, pMID:
32073353.
[3] Y. Li, L. Yao, J. Li, L. Chen, Y. Song, Z. Cai, and C. Yang, “Stability issues of rt-pcr testing
of sars-cov-2 for hospitalized patients clinically diagnosed with covid-19,” Journal of Medical
Virology, vol. 92, no. 7, pp. 903–908, 2020.
[4] Y. Yang, M. Yang, C. Shen, F. Wang, J. Yuan, J. Li, M. Zhang, Z. Wang, L. Xing, J. Wei,
L. Peng, G. Wong, H. Zheng, M. Liao, K. Feng, J. Li, Q. Yang, J. Zhao, Z. Zhang, L. Liu, and
Y. Liu, “Evaluating the accuracy of different respiratory specimens in the laboratory diagnosis
and monitoring the viral shedding of 2019-ncov infections,” medRxiv, 2020.
[5] T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao, Z. Sun, and L. Xia, “Correlation of
chest ct and rt-pcr testing for coronavirus disease 2019 (covid-19) in china: A report of 1014
cases,” Radiology, vol. 296, no. 2, pp. E32–E40, 2020, pMID: 32101510.
12

[6] X. Xie, Z. Zhong, W. Zhao, C. Zheng, F. Wang, and J. Liu, “Chest ct for typical coronavirus
disease 2019 (covid-19) pneumonia: Relationship to negative rt-pcr testing,” Radiology, vol.
296, no. 2, pp. E41–E45, 2020, pMID: 32049601.
[7] S. Tian, W. Hu, L. Niu, H. Liu, H. Xu, and S.-Y. Xiao, “Pulmonary pathology of early-phase
2019 novel coronavirus (covid-19) pneumonia in two patients with lung cancer,” Journal of
Thoracic Oncology, 2020.
[8] J. Shatri, L. Tafilaj, A. Turkaj, K. Dedushi1, M. Shatri, S. Bexheti, and S. K. Mucaj, “The role
of chest computed tomography in asymptomatic patients of positive coronavirus disease 2019:
A case and literature review,” Journal of Clinical Imaging Science, 2020.
[9] W.-j. Guan, Z.-y. Ni, Y. Hu, W.-h. Liang, C.-q. Ou, J.-x. He, L. Liu, H. Shan, C.-l. Lei, D. S. Hui,
B. Du, L.-j. Li, G. Zeng, K.-Y. Yuen, R.-c. Chen, C.-l. Tang, T. Wang, P.-y. Chen, J. Xiang, S.-y.
Li, J.-l. Wang, Z.-j. Liang, Y.-x. Peng, L. Wei, Y. Liu, Y.-h. Hu, P. Peng, J.-m. Wang, J.-y. Liu,
Z. Chen, G. Li, Z.-j. Zheng, S.-q. Qiu, J. Luo, C.-j. Ye, S.-y. Zhu, and N.-s. Zhong, “Clinical
characteristics of coronavirus disease 2019 in china,” New England Journal of Medicine, vol.
382, no. 18, pp. 1708–1720, 2020.
[10] D. Wang, B. Hu, C. Hu, F. Zhu, X. Liu, J. Zhang, B. Wang, H. Xiang, Z. Cheng, Y. Xiong,
Y. Zhao, Y. Li, X. Wang, and Z. Peng, “Clinical characteristics of 138 hospitalized patients
with 2019 novel coronavirus–infected pneumonia in wuhan, china,” JAMA, vol. 323, no. 11, pp.
1061–1069, 03 2020.
[11] M. Chung, A. Bernheim, X. Mei, N. Zhang, M. Huang, X. Zeng, J. Cui, W. Xu, Y. Yang, Z. A.
Fayad, A. Jacobi, K. Li, S. Li, and H. Shan, “Ct imaging features of 2019 novel coronavirus
(2019-ncov),” Radiology, vol. 295, no. 1, pp. 202–207, 2020, pMID: 32017661.
[12] F. Pan, T. Ye, P. Sun, S. Gui, B. Liang, L. Li, D. Zheng, J. Wang, R. L. Hesketh, L. Yang, and
C. Zheng, “Time course of lung changes at chest ct during recovery from coronavirus disease
2019 (covid-19),” Radiology, vol. 295, no. 3, pp. 715–721, 2020, pMID: 32053470.
[13] H. X. Bai, B. Hsieh, Z. Xiong, K. Halsey, J. W. Choi, T. M. L. Tran, I. Pan, L.-B. Shi, D.-C.
Wang, J. Mei, X.-L. Jiang, Q.-H. Zeng, T. K. Egglin, P.-F. Hu, S. Agarwal, F.-F. Xie, S. Li,
T. Healey, M. K. Atalay, and W.-H. Liao, “Performance of radiologists in differentiating covid19 from non-covid-19 viral pneumonia at chest ct,” Radiology, vol. 296, no. 2, pp. E46–E54,
2020, pMID: 32155105.
[14] X. Mei, H.-C. Lee, K.-y. Diao, M. Huang, B. Lin, C. Liu, Z. Xie, Y. Ma, P. Robson, M. Chung,
A. Bernheim, V. Mani, C. Calcagno, K. Li, S. Li, H. Shan, J. Lv, T. Zhao, J. Xia, and Y. Yang,
“Artificial intelligence–enabled rapid diagnosis of patients with covid-19,” Nature Medicine, pp.
1–5, 05 2020.
[15] H. Gunraj, L. Wang, and A. Wong, “COVIDNet-CT: A tailored deep convolutional neural
network design for detection of COVID-19 cases from chest CT images,” Frontiers in Medicine,
2020. [Online]. Available: https://doi.org/10.3389/fmed.2020.608525
[16] K. Zhang, X. Liu, J. Shen, Z. Li, Y. Sang, X. Wu, Y. Zha, W. Liang, C. Wang, K. Wang,
L. Ye, M. Gao, Z. Zhou, L. Li, J. Wang, Z. Yang, H. Cai, J. Xu, L. Yang, W. Cai, W. Xu,
S. Wu, W. Zhang, S. Jiang, L. Zheng, X. Zhang, L. Wang, L. Lu, J. Li, H. Yin, W. Wang,
O. Li, C. Zhang, L. Liang, T. Wu, R. Deng, K. Wei, Y. Zhou, T. Chen, J. Y.-N. Lau, M. Fok,
J. He, T. Lin, W. Li, and G. Wang, “Clinically applicable ai system for accurate diagnosis,
quantitative measurements, and prognosis of covid-19 pneumonia using computed tomography,”
Cell, vol. 18, no. 6, pp. 1423–1433, 2020.
[17] L. Wang, Z. Q. Lin, and A. Wong, “Covid-net: A tailored deep convolutional neural network
design for detection of covid-19 cases from chest x-ray images,” Scientific Reports, 2020.
[18] A. Wong, Z. Q. Lin, L. Wang, A. G. Chung, B. Shen, A. Abbasi, M. Hoshmand-Kochi, and T. Q.
Duong, “Covidnet-s: Towards computer-aided severity assessment via training and validation
of deep neural networks for geographic extent and opacity extent scoring of chest x-rays for
sars-cov-2 lung disease severity,” 2020.
[19] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in 2016
IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770–778.
[20] A. P, X. S, H. SA, T. EB, S. TH, A. A, K. M, V. N, B. M, A. V, P. F, C. G, T. BT, and W. BJ, “Ct
images in covid-19 [data set],” in The Cancer Imaging Archive, 2020. [Online]. Available:
https://doi.org/10.7937/tcia.2020.gqry-nc81
13

[21] M. Rahimzadeh, A. Attar, and S. M. Sakhaei, “A fully automated deep learning-based network
for detecting covid-19 from a new and large lung ct scan dataset,” medRxiv, 2020. [Online].
Available: https://www.medrxiv.org/content/early/2020/06/12/2020.06.08.20121541
[22] W. Ning, S. Lei, J. Yang et al., “Open resource of clinical data from patients with pneumonia
for the prediction of covid-19 outcomes via deep learning,” Nature Biomedical Engineering,
vol. 4, pp. 1197–1207, 2020.
[23] M. Jun, W. Yixin, A. Xingle, G. Cheng, Y. Ziqi, C. Jianan, Z. Qiongjie, D. Guoqiang, H. Jian,
H. Zhiqiang, N. Ziwei, and Y. Xiaoping, “Towards efficient covid-19 ct annotation: A benchmark
for lung and infection segmentation,” arXiv preprint arXiv:2004.12537, 2020.
[24] S. Armato III, G. McLennan, L. Bidaut, M. McNitt-Gray, C. Meyer, A. Reeves, B. Zhao,
D. Aberle, C. Henschke, E. A. Hoffman, E. Kazerooni, H. MacMahon, E. van Beek,
D. Yankelevitz, A. Biancardi, P. Bland, M. Brown, R. Engelmann, G. Laderach, D. Max,
R. Pais, D. Qing, R. Roberts, A. Smith, A. Starkey, P. Batra, P. Caligiuri, A. Farooqi, G. Gladish,
C. Jude, R. Munden, I. Petkovska, L. Quint, L. Schwartz, B. Sundaram, L. Dodd, C. Fenimore,
D. Gur, N. Petrick, J. Freymann, J. Kirby, B. Hughes, A. Casteele, S. Gupte, M. Sallam,
M. Heath, M. Kuhn, E. Dharaiya, R. Burns, D. Fryd, M. Salganicoff, V. Anand, U. Shreter,
S. Vastagh, B. Croft, and L. Clarke, “Data from lidc-idri,” in The Cancer Imaging Archive,
2015. [Online]. Available: http://doi.org/10.7937/K9/TCIA.2015.LO9QL9SX
[25] “Covid-19,” Radiopaedia. [Online]. Available: https://radiopaedia.org/articles/covid-19-4
[26] S. Morozov, A. Andreychenko, N. Pavlov, A. Vladzymyrskyy, N. Ledikhova, V. Gombolevskiy,
I. Blokhin, P. Gelezhe, A. Gonchar, and V. Chernina, “Mosmeddata: Chest ct
scans with covid-19 related findings dataset,” medRxiv, 2020. [Online]. Available:
https://www.medrxiv.org/content/early/2020/05/22/2020.05.20.20100362
[27] A. Wong, M. J. Shafiee, B. Chwyl, and F. Li, “Ferminets: Learning generative machines to
generate efficient neural networks via generative synthesis,” 2018.
[28] A. Wong, “Netscore: Towards universal metrics for large-scale performance analysis of deep
neural networks for practical usage,” CoRR, vol. abs/1806.05512, 2018. [Online]. Available:
http://arxiv.org/abs/1806.05512
[29] N. Qian, “On the momentum term in gradient descent learning algorithms,” Neural Networks,
vol. 12, no. 1, pp. 145–151, 1999.
[30] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis,
J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah,
M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng,
“TensorFlow: Large-scale machine learning on heterogeneous systems,” 2015, software available
from tensorflow.org.
[31] Z. Q. Lin, M. J. Shafiee, S. Bochkarev, M. S. Jules, X. Y. Wang, and A. Wong, “Do explanations
reflect decisions? a machine-centric strategy to quantify the performance of explainability
algorithms,” 2019.
[32] D. Kumar, A. Wong, and G. W. Taylor, “Explaining the unexplained: A class-enhanced
attentive response (clear) approach to understanding deep neural networks,” IEEE Conference
on Computer Vision and Pattern Recognition Workshops, 2017.
[33] S. Lundberg and S.-I. Lee, “A unified approach to interpreting model predictions,” 2017.
[34] M. T. Ribeiro, S. Singh, and C. Guestrin, “"why should i trust you?": Explaining the predictions
of any classifier,” 2016.
[35] G. Erion, J. D. Janizek, P. Sturmfels, S. Lundberg, and S.-I. Lee, “Improving performance of
deep learning models with axiomatic attribution priors and expected gradients,” 2020.
[36] D. Kumar, G. W. Taylor, and A. Wong, “Discovery radiomics with clear-dr: Interpretable
computer aided diagnosis of diabetic retinopathy,” 2017.
[37] K. He, X. Zhang, S. Ren, and J. Sun, “Identity mappings in deep residual networks,” in Computer
Vision - ECCV 2016, B. Leibe, J. Matas, N. Sebe, and M. Welling, Eds. Cham: Springer
International Publishing, 2016, pp. 630–645.
14

[38] B. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, “Learning Transferable Architectures for
Scalable Image Recognition,” in 2018 IEEE/CVF Conference on Computer Vision and Pattern
Recognition, 2018, pp. 8697–8710.
[39] M. Tan and Q. Le, “EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,”
in 2019 International Conference on Machine Learning (ICML), 2019.
[40] X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu, Q. Ni, Y. Chen, J. Su, G. Lang, Y. Li,
H. Zhao, J. Liu, K. Xu, L. Ruan, J. Sheng, Y. Qiu, W. Wu, T. Liang, and L. Li, “A deep learning
system to screen novel coronavirus disease 2019 pneumonia,” Engineering, 2020.
[41] H. X. Bai, R. Wang, Z. Xiong, B. Hsieh, K. Chang, K. Halsey, T. M. L. Tran, J. W. Choi,
D.-C. Wang, L.-B. Shi, J. Mei, X.-L. Jiang, I. Pan, Q.-H. Zeng, P.-F. Hu, Y.-H. Li, F.-X.
Fu, R. Y. Huang, R. Sebro, Q.-Z. Yu, M. K. Atalay, and W.-H. Liao, “Ai augmentation of
radiologist performance in distinguishing covid-19 from pneumonia of other etiology on chest
ct,” Radiology, vol. 0, no. 0, p. 201491, 0, pMID: 32339081.
[42] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang, Q. Song, K. Cao,
D. Liu, G. Wang, Q. Xu, X. Fang, S. Zhang, J. Xia, and J. Xia, “Using artificial intelligence to
detect covid-19 and community-acquired pneumonia based on pulmonary ct: Evaluation of the
diagnostic accuracy,” Radiology, vol. 296, no. 2, pp. E65–E71, 2020, pMID: 32191588.
[43] A. A. Ardakani, A. R. Kanafi, U. R. Acharya, N. Khadem, and A. Mohammadi, “Application of
deep learning technique to manage covid-19 in routine clinical practice using ct images: Results
of 10 convolutional neural networks,” Computers in Biology and Medicine, vol. 121, p. 103795,
2020.
[44] V. Shah, R. Keniya, A. Shridharani, M. Punjabi, J. Shah, and N. Mehendale, “Diagnosis of
covid-19 using ct scan images and deep learning techniques,” medRxiv, 2020.
[45] J. Chen, L. Wu, J. Zhang, L. Zhang, D. Gong, Y. Zhao, S. Hu, Y. Wang, X. Hu, B. Zheng,
K. Zhang, H. Wu, Z. Dong, Y. Xu, Y. Zhu, X. Chen, L. Yu, and H. Yu, “Deep learningbased model for detecting 2019 novel coronavirus pneumonia on high-resolution computed
tomography: a prospective study,” medRxiv, 2020.
[46] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and X. Wang, “Deep learning-based
detection for covid-19 from chest ct using weak label,” medRxiv, 2020.
[47] S. Jin, B. Wang, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou, W. Ma, Z. Xu, Z. Zheng, W. Sun,
L. Lan, W. Zhang, X. Mu, C. Shi, Z. Wang, J. Lee, Z. Jin, M. Lin, H. Jin, L. Zhang, J. Guo,
B. Zhao, Z. Ren, S. Wang, Z. You, J. Dong, X. Wang, J. Wang, and W. Xu, “Ai-assisted ct
imaging analysis for covid-19 screening: Building and deploying a medical ai system in four
weeks,” medRxiv, 2020.
[48] C. Jin, W. Chen, Y. Cao, Z. Xu, Z. Tan, X. Zhang, L. Deng, C. Zheng, J. Zhou, H. Shi, and
J. Feng, “Development and evaluation of an ai system for covid-19 diagnosis,” medRxiv, 2020.
[49] Y. Song, S. Zheng, L. Li, X. Zhang, X. Zhang, Z. Huang, J. Chen, H. Zhao, Y. Jie, R. Wang,
Y. Chong, J. Shen, Y. Zha, and Y. Yang, “Deep learning enables accurate diagnosis of novel
coronavirus (covid-19) with ct images,” medRxiv, 2020.
[50] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang, Y. Li, X. Meng, and
B. Xu, “A deep learning algorithm using ct images to screen for corona virus disease (covid-19),”
medRxiv, 2020.
[51] S. A. Harmon, T. H. Sanford et al., “Artificial intelligence for the detection of covid-19
pneumonia on chest ct using multinational datasets,” Nature Communications, vol. 11, no. 4080,
2020.

15

