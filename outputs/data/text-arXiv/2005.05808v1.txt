Modelling the Extremes of Seasonal Viruses and
Hospital Congestion: The Example of Flu in a Swiss
Hospital

arXiv:2005.05808v1 [stat.ME] 12 May 2020

Setareh Ranjbar(1) , Eva Cantoni(2) , Valérie Chavez-Demoulin(1) , Giampiero
Marra(3) , Rosalba Radice(4) , Katia Jaton-Ogay(5)
(1)

Faculty of Business and Economics, University of Lausanne,
Research Center for Statistics, GSEM, University of Geneva
(3) Department of Statistical Science, University College London
(4) Faculty of Actuarial Science and Insurance, Cass Business School
(5) Institut Universitaire de Microbiologie, CHUV, Lausanne
(2)

Abstract
Viruses causing flu or milder coronavirus colds are often referred to as “seasonal
viruses” as they tend to subside in warmer months. In other words, meteorological conditions tend to impact the activity of viruses, and this information can be
exploited for the operational management of hospitals. In this study, we use three
years of daily data from one of the biggest hospitals in Switzerland and focus on
modelling the extremes of hospital visits from patients showing flu-like symptoms
and the number of positive cases of flu. We propose employing a discrete Generalized
Pareto distribution for the number of positive and negative cases, and a Generalized
Pareto distribution for the odds of positive cases. Our modelling framework allows
for the parameters of these distributions to be linked to covariate effects, and for
outlying observations to be dealt with via a robust estimation approach. Because meteorological conditions may vary over time, we use meteorological and not calendar
variations to explain hospital charge extremes, and our empirical findings highlight
their significance. We propose a measure of hospital congestion and a related tool
to estimate the resulting CaRe (Charge-at-Risk-estimation) under different meteorological conditions. The relevant numerical computations can be easily carried out
using the freely available GJRM R package. The introduced approach could be applied
to several types of seasonal disease data such as those derived from the new virus
SARS-CoV-2 and its COVID-19 disease which is at the moment wreaking havoc
worldwide. The empirical effectiveness of the proposed method is assessed through
a simulation study.

KEYWORDS: flu outbreak, extreme values, outliers, distributional regression.

1

1

Introduction

Congestion is of paramount concern for most large size hospitals. At the time of writing,
hospitals across the world are experiencing congestion due to the coronavirus pandemic.
Predicting both the number of visits to the hospital and potential pandemic considerably
helps the operational management of hospitals. Empirical evidence suggests that the flu
virus is more vulnerable in warm weather, hence making it more common for epidemics
to proliferate in fall and winter months in the northern hemisphere. The role of weather
in the spread of flu is not yet fully understood and researchers have attempted to address
this question. Roussel et al. (2016) studied the impact of six climate variables (related to
temperature, humidity and sunshine) on flu spread, whereas Towers et al. (2013) analysed
waves of influenza and climate patterns. Davis et al. (2012) examined the hypothesis that
cold and/or dry weather enhances human pneumonia and influenza mortality, whereas
Firestone et al. (2012) quantified the association between the hazard of flu infection and
air temperature, humidity, rainfall and wind velocity. It has been generally found that
flu’s transmission is mostly dependent on humidity and temperature (Lowen and Steel,
2014), with cold and dry weather making flu more active. In this paper, we approach
the problem from the point of view of hospitals facing the risk of congestion and hence
the need for assessing the efficiency of the flu testing process. Specifically, we aim at
understanding and quantifying the impact of weather related variables on the probability
of obtaining: a high number of positive flu tested patients (epidemic), a high number of
negative flu tested patients (inefficiency), and high values of positive odds (number of
positive flu over negative flu tested patients).
We use three years (2016/2017, 2017/2018 and 2018/2019) of daily data from 01/07/2016
to 21/06/2019 which give us n = 1086 observations on the number of visits and positive
cases for flu at the Lausanne University Hospital1 (CHUV), one of the largest hospitals
in Switzerland, with a capacity of 1000 somatic beds.
CHUV data
●

●

●
● ●

15

●

●●

●

The odds of positive

●●

●
●
●

●

●

●

●
●

●

●●
●●

10

●

●

●● ●●

●

●●●● ●

●●
●

●●●● ●
●
●
●● ●

Year
●

●

●●
●

●●
●
●
●

●● ●

●
●
●

●

●
●●● ●● ●
● ●
●●
●

●
●
●

●
●●●
●
●
●
●

●●

●

●

0

●

●

●

●

●● ●
●●
●●

●●●
●●●●
●
●
●
●
●●●
●
●
●
●
●
●
●

●

1 Oct

●●●

●● ●●●●

●
●

●●●●●● ●●●●●

●●
● ●
● ●●●
●● ●●
●●●
●
●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●● ●
● ●
●

1 Jul

2016−2017
2017−2018
2018−2019

●● ● ●●●
●●

● ●
●●
●
●●●
●
●

●●
●● ● ●●
● ●●●
●
●
●●
●●
●
●●●
●●
●●●
●
●

●

●

●●

● ● ●
● ● ●●●
●
●●

5

●

●
●
●
●●
●
●

● ●●●●
● ●
●●
●
●●●
●
● ●
●
●
●
●
●●
●
●
●●●●●●●
● ●
●●

● ●

●

● ●
●
●
●●●
●
●●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

1 Jan
Date

1 Apt

Figure 1: Daily number of flu positive cases tested patients from 01/07/2016 to
21/06/2019. The red line shows the threshold defining exceedances.
1

https://www.lausanneuniversityhospital.com/home

2

CHUV data

Number of negative test results

●

40
●

●

●
●

30

20

10

0

●
●
●

●
●
●
●
●●● ●
● ●
●
●
● ● ● ●●
●
●
● ● ●●
● ●●
●
●●● ●●● ● ●
●
●
●
● ●
●●
●
●
●
●
●●
●
●
●●●●
● ●●●●
● ●
●
●
● ●● ● ●● ●● ● ● ●
●
●
●
●
●
● ● ● ●● ●
●
●
● ● ●
●
●
●
●●● ●● ●●
●● ●
●●
●
●●
●● ●● ●●
● ●
●● ●
● ● ●●● ● ●
●● ● ●
●●●● ● ●●● ● ●●
●
●
●
●
● ●●●
●
●
● ● ● ●●●
●
●● ●
●●● ●
●
●
●
●
●
●● ● ●●●
●
●●
●
● ●
●
●●
●● ● ●
●
●● ●
● ●●●●
● ●●
● ●
● ●
●● ● ●
●●●●●
● ● ●● ●
●
●
● ● ●●
● ●● ● ● ● ● ●●
●●
●
●
●
●
● ●●●
●● ● ● ●
● ● ●
●
● ● ●
●●
●
●
●●●●
●
●
●
●● ●
●● ●
●
●●
●
●● ●
●
●
●
●●
●
● ● ●
●
●●
●
●
●●
●●
●
●
● ●
● ●
●
●
●
● ● ●●
●
●
●
● ●●
●
●● ● ● ●●● ●
●
●●● ●
●
●●● ●● ●●
● ● ●● ● ● ● ● ●●
● ● ●● ●
●
● ●
●●●
● ● ●
●
● ●●
●●●
●
●
●●● ● ●
●●
● ● ● ●●
● ●
●
●
●
● ● ●● ●
● ● ● ● ●●●● ● ●●●
●
● ●
●
●●
●●● ● ●●
●●
●●● ● ●● ●●●● ●●●● ●●●● ●
● ●
● ●●
●
●● ●●●●
● ● ●●
● ● ●●●
●
●
●
●●
●● ●●●
●
● ●●●
●
●●
●
●●
● ●
●
●
●●●
● ●● ●●●● ● ●
●●●●
●
●
●
●●●●
●●●
● ● ● ●
●
● ●●
●
●
●● ● ●
●
●●
●●●●
●
●●●●
●●
●●
●
● ●
● ●●●●●
● ●●●●●●● ●●●
● ●
●●● ●●●●
●●●
●●●●
●●
●
●●●●
●●●●
●●●
●
●
●●
●
●
●
●
●●●●
●
●
●
●
●●●
●
●●
●
●●
●
●●●●
●
●
●
●
●●
●
●●
● ●●●●●●●
●
●
●●
●●● ●●●●●●●
●
●
●
●
●●●
●●
●●
●
● ●
●●
●
●
●●
●●
●●
●●●
●
●
●
●
●
●
●
●
●
●●●●●
●
●
● ●
● ●● ●
●
●●●
●●●●
●●
●
●●●●
●
●
●●●●●
●●
●●
●
●
●●
●
●●●●
●
●●●●●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●
●
●
●
●
●
●●
●
●
●●
●●
●
●
●●
●
●
●●
●●
●●
●
●
●
●●●
●●
●
●
●●
●
● ●●
●
●●
●●
●
●●●●●●●
●
●●
●
●
●●
●
●
●●●

1 Jul

1 Oct

1 Jan
Date

Year
●
●
●

2016−2017
2017−2018
2018−2019

1 Apt

Figure 2: Daily umber of negatively flu tested patients from 01/07/2016 to 21/06/2019.
The red line shows the threshold defining exceedances.
Figure 1 shows the number of positive cases for the three years considered in this study.
Recording a case of flu is per se an extreme event in the sense there are generally no
flu cases registered on a "normal" day. This justifies the use of exceedances of positive
cases over the threshold of 1, and then to model these 290 exceedances using extreme value
theory. Although flu positive cases are registered roughly between November and May, the
epidemic appears at a different time each year, with patterns that differ across the years.
Similar considerations apply to the negative cases shown in Figure 2, where the chosen
threshold is 15, which gives us 230 exceedances. The choice of threshold corresponds to a
certain level of inefficiency of the flu testing process (each test is expensive and costs 180
Swiss francs). It is not economically desirable to have too many negative cases. Consider,
for example, the current case of SARS-CoV-2. Some countries do not have enough testing
kits and those that are available tend to be used to detect/confirm positive cases. The
different patterns observed across years suggest that the calendar day variable is not a good
predictor for use within the framework of hospital management of flu (positive or negative)
cases. This may be in part due to meteorological variation across years and perhaps also to
climate change. As for the latter, we do not have enough data to test for a long term effect.
Regarding the meteorological aspect, we propose to build a model for non-identically
distributed discrete extremes where covariate effects can be accounted for. The discrete
generalized Pareto distribution (D-GPD) provides a theoretically justified law for discrete
extremes (Hitz et al., 2017), whereas, in the same spirit of generalized additive models for
location, scale and shape (Rigby and Stasinopoulos, 2005), distributional parameters are
made dependent on meteorological effects. The estimation approach needs to account for
outlying observations as elaborated further in the next paragraph.
From the point of view of the management of hospital congestion due to an epidemic, a
measure of interest is the odds of positive cases as shown in Figure 3 (recall that this is
the ratio between the number of positive and negative cases). This value is continuous
and a high number reflects a state of epidemic which in turn means that the hospital
has to prepare for congestion. We define these odds to be high if they are above a
threshold of 0.05, a value that is justified by a graphical technique explained in Section
2.1. The number of threshold exceedances in this case is 280. As shown in Figure 3,
some isolated extreme values appear outside the periods of flu epidemic. These points are
3

found either at the very beginning of the flu period (a bell of alarm for hospitals since
there are far more positive than negative cases) or at the end of the epidemic in early
spring (corresponding to residual cases). Based on classical extreme value theory (EVT)
the Generalized Pareto distribution (GPD) is the appropriate distribution to model such
extremes and we build a model based on the GPD where the distributional parameters
depend on meteorological factors. It is important to stress that testing patients for flu in
hospital is a process that requires human intervention. As such, the recording process on
certain days (e.g., 31st of December) will be different as compared to that of other days.
This contaminates the underlying distribution of the data by creating outliers which have
to be dealt with. To this end, we adapt the methodology introduced by Aeberhard et al.
(2019) to the specific context of this paper. To the best of our knowledge no previous
work has attempted to build extreme value models based on GPD and D-GPD, where
the distributional parameters are allowed to be specified as functions of covariates and
the presence of outlying observations is accounted for by using a theoretically founded
robust estimation approach. The newly introduced models are available through the GJRM
R package (Marra and Radice, 2020) which greatly simplifies the implementation of our
approach, making it as simple as a canned procedure.
When we apply our proposed approach to the hospital data, we find that our three
responses of interest depend on meteorological conditions. Specifically, our results suggest
that the risk of congestion (extreme positive cases) increases when temperatures go down,
and in periods of no sun and no rain. The risk of testing inefficiently (extreme negative
cases) significantly increases in periods of no sun and no rain. The risk of outbreak
(extreme odds of positive cases) increases in cold periods. We quantify these results in
Section 3.
In Section 2, we describe the proposed robust regression methodology for extremes. Section 3 reports the results of the empirical analysis for the flu hospital data while Section
4 presents the findings from a simulation study. We conclude in Section 5.
CHUV data

The odds of positive

2.0

*
(3.95)
2017−11−08

●

1.5
●

Year
●

1.0

●

●●●

●
●

●

●

●

2016−2017
2017−2018
2018−2019

●
●
● ● ●
●
●●
●
● ● ●●
●
●
●● ●
●
● ●
● ●●
● ●
●
●●
●●
●
●●
●● ● ●
● ● ●
● ● ●● ●
●
● ● ● ● ●
● ●
●
●
● ● ●● ● ●●●●● ●
●
●● ● ●
● ●●●
●
●
●●
●
●●●●●
●
●● ●●
●
●
●
● ●●● ●●
●
● ●
● ●
●
● ●
●●
●●
●
●
●●● ●
●
●
●
●● ●●●
●●
●
● ●
●●●●
●●●
●●● ●●
●
●●
●
● ●● ●●
●
● ●
●●●●
●
● ●
●
● ●
●
●●●
●●●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●● ●
●
●
● ●●●
● ●
● ●●●
●●
●●●
●●
● ●●● ●●
●●●●●● ●●
●
●
●
●
●
●
●
●
●
●
● ●
●●
●●●
●
●
● ● ●
●
●●● ● ●
●● ●
●
●
●
● ●●
● ●●● ●
●
●
●
●●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●
●
●●●
●
●●
●
●●
●
●●
●
●
●●●●●
●●
●
●
●
●
●●●
●
●
●
●
●
●●
●
●●
●●
●
●●
●
●
●
●
●
●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●●
●
●
●●
●
●
●
●●
●
●
●
●
●
●
●●●
●
●
●
●●
●
●
●●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●● ●
● ●
●
●● ● ●
●
●
●●●
●
●●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

0.5

0.0

1 Jul

1 Oct

1 Jan
Date

1 Apt

Figure 3: Daily odds of positive tested cases from 01/07/2016 to 21/06/2019. The red
line shows the threshold defining exceedances.

4

2

Robust Regression Methodology for Peaks-Over-Threshold

Extreme value theory is the field of statistics dedicated to the study of events with low
occurrence frequencies and large amplitudes. Such events are rare in relation to the bulk
of a population, which makes them hard to model and difficult to predict. Section 2.1
discusses the concepts of peaks-over-threshold and Charge-at-Risk-estimation (CaRe), and
describes the approach used to derive the extreme distribution used to analyze the discrete
outcomes of this paper. Section 2.2 discusses the robust approach used to estimate GPD
and D-GPD models whose distributional parameters are allowed to depend on covariate
effects.

2.1

GPD, D-GPD and CaRe

One of the classical theories of extremes for a common continuous random variable is based
on the probabilistic limit result for exceedances of high thresholds. The so-called peaksover-threshold (POT) consists of a limiting result for the times and sizes of exceedances
over some high level. Letting (Yi )i≥1 be a sequence of independent and identically distributed (iid) random variables in [0, yF ), with common continuous distribution F , we
concentrate on the sizes of exceedances over some high threshold. In other words, the
focus is on the right tail of distribution F . The result by Balkema and de Haan (1974)
allows for the approximation of the conditional distribution of the exceedances above a
high threshold u. If there exist normalizing sequences {an > 0} and {bn } such that for
u → yF ,
d

a−1
n (Y − u) |Y ≥ u → Z

(1)
d

for some Z following a non-degenerate probability distribution on [0, ∞), where → denotes
weak convergence, then it is possible to model the limiting distribution of the exceedances
Y − u|Y > u with a Generalized Pareto distribution (GPD), that is,
(
−1/ξ

1 + ξy/σ + , ξ 6= 0,
Pr Y > u + y | Y > u −→ G(σ,ξ) (y) =
(2)
u→yF
exp(−y/σ),
ξ = 0,
where ξ ∈ IR is the shape parameter and σ > 0 the scale parameter. The case ξ = 0 is
interpreted as the limit. Parameter ξ provides information about the heaviness of the tail
of the underlying distribution F . More formally, condition (1) means that Y belongs to
the maximum domain of attraction of an extreme value distribution with shape parameter
ξ and we write Y ∈ MDA(ξ). Some examples are the Pareto distribution,
α

κ
, α, κ > 0, x ≥ 0,
F (y) = 1 −
κ+y
for which we take an = κn1/α /α, bn = κn1/α − κ, and is in MDA(1/α) (Fréchet case).
The exponential distribution, F (y) = 1 − e−λy , λ > 0, y ≥ 0, for which we take an = 1/λ,
bn = (log n)/λ, and is in MDA(0) (Gumbel-case).
Essentially all commonly encountered continuous distributions are in the maximum domain of attraction of an extreme value distribution. If the tail of F decays like a power
5

function then F is in MDA(ξ > 0). Distributions such as Burr, log-gamma, Cauchy,
Pareto and Student-t as well as various mixture models are heavy-tailed. The Gumbel
class characterized by ξ = 0 contains light-tailed distributions such as the Gaussian, lognormal, exponential and gamma whose tail decay roughly exponentially. The so-called
Weibull class, defined by ξ < 0, contains distributions that are bounded above (e.g.,
uniform and Beta distributions). In other words, for a wide class of distributions, the
distribution of the excesses over a high threshold can be approximated by the GPD. This
result suggests that if we choose u high enough then we can assume that result (2) holds
for some parameters ξ and σ. In practice, such parameters are estimated by fitting a
GPD to the excess amounts over the threshold u, relying on the standard properties of
maximum likelihood estimators for ξ > −0.5.
The choice of u is important; a very low threshold would lead to high bias whereas a very
high threshold to high variance. For practical purposes, a suitable threshold u is chosen
using data-analytic tools such as the mean residual life plot. This is based on the fact
that if excess losses over threshold u can be characterized by a GPD with parameters
ξ < 1 and σ, then it is easy to show that for any higher threshold v ≥ u
E(Y − v | Y > v) =

σ + ξ(v − u)
,
1−ξ

(3)

so that the mean excess function is linear in v above u. In empirical applications, the mean
residual life plot (which shows the empirical mean excess against increasing threshold
values) is a useful tool to choose the threshold and also to determine the adequacy of
the GPD model as an approximation of the excess distribution. For a linear mean excess
function characterizing the GPD class, the best threshold candidate is any value for which
the mean excess looks linear. Figure 5 shows mean residual life plots for the odds of
positive cases without removing outliers (top panel) and after removing 1% of the largest
values (bottom panel). The graphs support the presence of a contamination effect due to
outliers, which may indeed make the choice of the threshold difficult. This is standard for
mixed distributions.
Taking the point of view of the hospital’s risk management, an important quantity is the
quantile of Y given that Y > u because it quantifies the information about the charge
load the hospital has to be ready for under different scenarios of congestion. In practice,
for a fixed threshold u, given that Y > u, and a horizon of h days, the p-quantity, called
Charge-at-Risk-estimation (CaRe), is the value of Y that might be exceeded one time in
h days. This is defined as
o
σn
(1 − p)(−ξ) − 1 ,
(4)
CaRe(p)GPD = u +
ξ
where h = 1/(1 − p). As an example, during a flu period (Y > u), 97%-CaRe roughly
corresponds to the value of Y that might be exceeded once in a month. In a financial
context, a related value is the co-called Value-at-Risk imposed by the Basel committee
and used, for instance, to measure the risk of loss on a specific portfolio of financial assets.
For a discrete random variable R, using the GPD to approximate the distribution’s tail
behaviour can be inappropriate. As pointed out by Hitz et al. (2017), many common distributions such as the Poisson, geometric and negative binomial are not in any maximum
domain of interest. Hitz et al. (2017) proposed two methods for modelling the tails of
6

discrete observations from distributions with infinite support. In this paper, we briefly
recall one of them. Defining the discrete maximum domain of attraction as D-MDA, we
write R ∈D-MDA(ξ) with ξ ≥ 0 if there exists a continuous random variable Y such
that P (R ≥ r) = P (Y ≥ r) for r = 0, 1, 2, . . .. Then, for large integers u, we have
P (R − u = r|R ≥ u) = P (Y − u ≥ r|Y ≥ u) − P (Y − u ≥ r + 1|Y ≥ u), which, from (2),
tends to a discrete generalized Pareto distribution (D-GPD) defined by
DG(σ,ξ) (r) = Ḡ(σ,ξ) (r) − Ḡ(σ,ξ) (r + 1),

(5)

for r = 0, 1, 2, . . ., where Ḡ denotes the survival function of G (see Hitz et al. (2017) and
references therein).
In risk management, as mentioned ealier, the quantile is a quantity of interest. In what
follows, we derive such an expression for the D-GPD. Let p ∈ (0, 1) be the probability for
which we seek a quantile, we then solve

(−1/ξ) X
(−1/ξ)
q 
q 
X
ξ(1 + r)
ξr
−
1+
1+
p=
σ
σ
r=0
r=0
(−1/ξ) X
(−1/ξ)

(−1/ξ)
1+q 
q 
X
ξ(1 + q)
ξz
ξr
−
=1− 1+
.
=1+
1+
1+
σ
σ
σ
z=1
r=1
As in (4) for the continuous context, the p%-CaRe for the discrete case is

o
σn
(−ξ)
CaRe(p)D-GPD = u +
(1 − p)
− 1 − 1,
ξ

(6)

where d e denotes the ceiling function (the smallest integer greater than or equal to).
The next section provides details on the robust estimation approach employed to fit
extreme value models based on the GPD and D-GPD, where σ and ξ can be specified as
functions of covariate effects.

2.2

Covariate Effects and Parameter Estimation

In the context of POT models for continuous variables through GPD excess size approximations, employing techniques that allow for flexible forms of dependence on covariates
are very attractive in empirical applications (Davison and Smith, 1990). To this end,
Chavez-Demoulin and Davison (2005) employed the framework of generalized additive
models (Hastie and Tibshirani, 1990; Wood, 2017) to estimate flexibly the shape and
scale parameters of an orthogonal reparametrization of the GPD. Yee and Stephenson
(2007) proposed instead the use of vector generalized additive models. These modelling
strategies are philosophically consistent with generalized additive models for location,
scale and shape (Rigby and Stasinopoulos, 2005), where, for any continuous or discrete
distribution Fθ , with θ being a d-dimensional parameter vector with virtually any d > 0,
all distributional parameters are allowed to depend on covariate effects. This type of
modelling has received a great deal of interest since its introduction and some researchers
7

also refer to it as distributional or multi-parameter regression. The classical and perhaps
most commonly known software implementation of such models is the gamlss R package
(Rigby and Stasinopoulos, 2005). Another implementation is available via the gamlss()
function from the GJRM R package (Marra and Radice, 2020) which has been extended to
incorporate the models developed in this paper.
For i = 1, . . . , n, where n denotes the sample size, let Yi be independently sampled from
Fθi (with density or probability function fθi ), where θi = (θi1 , . . . , θid ) and xi is a vector of
covariates of dimension p (which can include binary, categorical, and continuous variables,
for instance). The distributional assumption of Yi is understood to be conditional on all
covariates. This is achieved by assuming for each parameter θij , for j = 1, . . . , d, that

gj θij = βj0 + fj1 (xij1 ) + . . . + fjk (xijk ) + . . . + fjKj (xijKj ),
(7)
where the gj are one-to-one transformations or link functions (ensuring that the parameters range restrictions are met), βj0 ∈ R are overall intercepts, xijk denotes the kth
sub-vector of covariates pertaining to term j and observation i, and the Kj functions
fjk (·) represent generic covariate effects (which can be of any pre-specified parametric
form such as linear or quadratic, or can be non-parametric). Each of these functions
are approximated by a linear combination of Jkj basis functions bkjl (xikj ) and regression
PJkj
coefficients βkjl ∈ R, that is, fjk (xijk ) ≈ l=1
βdkj bkjl (xikj ). This (regression spline) approach allows for a vast variety of covariate effects. We refer the reader to Wood (2017)
for all the options available and that are supported by our implementation. Note that, in
our case study, linear specifications were deemed to be sufficient to model the variation
in the response variables of interest.
For GPD and D-GDP, we have that θi = (θi1 , θi2 ) = (ξi , σi ), hence d = 2. The choices of
one-to-one transformations have to guarantee that the parameters lie in their admissible
definition spaces. For GPD, with probability function defined as in Equation (2), we have
g1 (ξi ) = log (ξi + 0.5) and g2 (σi ) = log (σi ) .
For D-GDP, with probability function given by Equation (5), we employ
p
g1 (ξi ) = ξi and g2 (σi ) = log (σi ) .
The above choices ensure that σi is positive for both distributions, that ξi > −0.5 for
GPD (otherwise parameter estimation is non-regular in the sense that the score statistic
is not asymptotically normal as argued by Davison and Smith (1990)), and that ξi > 0
for D-GDP as required (Hitz et al., 2017).
Let δ be the vector of the model’s parameters to be estimated. This includes the coefficients associatedPwith (7). Model
by maximizing the log-likelihood

Pn fitting is performed
n
function `(δ) =
i=1 `(δ)i =
i=1 log f yi |θ . Note that, although not required for
our case study, our implementation supports the presence of non-parametric components.
In this case, the objective function would be augmented by a penalty term defined as
0
1/2δ Sδ, where S is a matrix that depends on the choice of basis functions for the nonparametric terms, and on a set of smoothing parameters that controls the trade-off between fit and smoothness.
If outlying observations occur in the data, classical model fitting will suffer from a lack
of robustness, which will adversely affect parameter estimates. To deal with this, we
8

adopt the methodology of Aeberhard et al. (2019) which essentially consists of reducing
the likelihood contributions of low log-likelihood values while leaving large log-likelihood
evaluations essentially unchanged. This is achieved through a function ρP
c applied to the

˜
log-likelihood components, so that the objective function becomes `(δ) = ni=1 ρc `(δ)i −
bρ (δ), where
n
n Z
X
X

bρ (δ) =
bρ (δ)i =
ρ?c log f (y|δ) dy
i=1

i=1

is a correction factor ensuring
Fisher consistency, and ρ?c is directly derived from the
R
z
specified ρc through ρ?c (z) = −∞ exp(s)ρ0c (s) ds with ρ0c (s) = ∂ρc (s)/∂s.
The tuning constant c > 0 in ρc regulates the trade-off between loss of estimation efficiency (should the data exactly come from the assumed model) and the magnitude of the
maximum estimation bias (should the data not come from the postulated model). For
any given c, ρc is assumed to be convex, monotonically increasing and twice continuously
differentiable over R, and to have bounded first derivative ρ0c within [0, 1]. The latter can
be interpreted as a multiplicative robustness weight, as one would add when weighting
the estimating equations in robust M -estimation. An advantage of the approach is that
it leads to a natural definition of robust information criteria.
Regarding the choice of ρc , Aeberhard et al. (2019) recommend using the log-logistic
, for c > 0, with
function first proposed by Eguchi and Kano (2001): ρc (z) = log 1+exp(z+c)
1+exp(c)

0
?
corresponding ρc (z) = exp(z)
 − exp(c) log 1 + exp(z + c) and first derivative ρc (z) =
exp(z + c)/ 1 + exp(z + c) . It holds that limc→∞ ρc (z) = z so that an increasingly large
c value leads to the (non-robust) original `(δ). The value of c is tuned via a simulation
based procedure that controls how the robustness weights at the score level (represented
by ρ0c ) behave under data generated from the assumed model. The user can decide the
level of down-weighting to be achieved with respect to maximum likelihood (e.g., 95%).
Aeberhard et al. (2019) established the Fisher consistency of δ̂ as well as its asymptotic
Gaussian distribution and asymptotic variance-covariance matrix which can be used to
construct confidence intervals. The authors discussed a Bayesian inferential result as well.
This is advantageous because such a result does not rely on asymptotic considerations, and
intervals for non-linear functions of the model’s parameters (e.g., CaRe) can be reliably
and efficiently obtained via posterior simulation. The adopted estimation framework
allows for the elegant construction of robust information criteria such as the robust AIC,
that is,
˜ + 2edf,
RAIC(λ) = −2`(δ)
(8)
where edf denotes the effective degrees of freedom which is given by the trace of a matrix
that depends on components of the asymptotic variance-covariance matrix of δ̂ (Aeberhard
et al., 2019).
In order to estimate the model’s coefficients, we have extended the efficient and stable
trust region algorithm proposed by Marra and Radice (2019) to our context. One of the
many advantages of such an algorithm is that it does not require the orthogonality of the
distributional parameters (in this case, ξ and σ). The implementation of the trust region
approach required the analytical score and Hessian of the model’s log-likelihood which
were derived and are reported in Supplementary Section A.

9

Although robust models for extremes have been developed in the literature (see, e.g.,
Dupuis and Field, 1998; Dupuis and Victoria-Feser, 2006; Dell’Aquila and Embrechts,
2006), we would like to stress that, to the best of our knowledge, there are no alternative
robust regression models for extreme distributions, nor respective software implementations, of the type discussed in this paper. While the construction and estimation of the
proposed model rely on the infrastructure and modelling framework of GJRM, extending
the software to accommodate the developments needed to address the challenges of our
case study required a great deal of work. Supplementary Section B provides details on
the usage of function gamlss() from the GJRM R package.

3

Modelling Flu Extremes

Flu is contagious and it can spread by airborne respiratory droplets, saliva or skin-to-skin
contact and by touching a contaminated surface. In Switzerland, a sentinel surveillance
system and a mandatory reporting system are used to register flu data. Flu monitoring
in hospitalized patients has also been in a testing phase since 2018. From a health care
managerial point of view, the number of negative cases among tested patients showing
flu-like symptoms is as important as the number of positive cases. An extreme number
of positive cases may indicate an epidemic of such a viral infection. An extreme number
of negatives can instead indicate management inefficiency and hence excessive financial
costs as well as congestion in the hospital units that are involved in diagnostics and pretreatment. The contagion aspect of hospitalized patients also needs to be taken into
account in the bed organization of the hospital.
As shown in Figures 1, 2 and 3, the annual calendar variable does not seem to provide
important insights into managing and/or preventing congestion due to a flu epidemic.
Based on the literature on flu transmission, we use meteorological variables for modelling
the extremes of: positive flu cases, negative cases (visiting the hospital for a flu check)
and the odds of positives. The meteorological variables are represented by L3 Xt = Xt−3 ,
where L is the usual lag operator and Xt can be each of the variables in Table 1. For
each meteorological factor, we consider the respective L3 Xt value, because, for flu, the
incubation time is usually between 24 and 48 hours, and sometimes 72 hours. When
discussing the models used for the analyses, extension L3 at the end of each covariate’s
name refers to L3 Xt values.
Name
Definition
Mintemp
daily minimum temperature at 2m above ground level
Radiation
daily mean radiation
Humidity
daily mean relative air humidity at 2 m from the ground
Wind
daily maximum wind (integration 1 s)
Precipitation daily sum of precipitation
Pressure
daily mean atmospheric pressure with (QNH)

Unit
o
C
W/m2
%
m/s
mm
hP a

Table 1: Potential meteorological covariates.
As for the flu data, the meteorological variables were measured in Lausanne (Switzerland)
from July 1, 2016 to June 21, 2019 and are available at https://gate.meteoswiss.ch/idaweb/.
10

Figure 4 shows a correlation plot between the meteorological variables, highlighting, as
expected, that humidity and radiation are highly and negatively correlated, whereas radiation and minimum temperature are positively correlated. Recall that the aim is to
quantify the effect of meteorological factors on the extremes of positive, negative, and the
odds of positive cases. For these responses, we specify three different models (estimated
using the approach described in Section 2.2) based on the D-GPD for the two discrete responses and on the GPD for the odds of positive extremes. The models robustness tuning
constants c were set to 6.1, 6.7 and 2.6, respectively, to achieve a level of down-weighting
of 95%.

●

Mintemp

●

●

●

Radiation

●

●

Humidity

●

●

Wind

●

Precipitation

●

−1

−0.8

Pressure

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

Figure 4: Correlation between meteorological covariates.
Since the odds of positive cases is a continuous variable, we employed the mean residual life
plot, based on (3), to choose the threshold defining the tail of the underlying distribution.
Figure 5 shows such a plot when using all the odds data (upper panel) and without 1%
of the largest values (lower panel). Looking at the upper panel, it is difficult to decide
the threshold value: the mean excess curve exhibits very little linear stability and the
confidence bounds become increasingly wide. In this case we choose 0.05, the value for
which the mean excess tends to increase in a roughly linear manner. The lower panel,
which excludes potential outliers, confirms the adequacy of the chosen threshold value.
It is interesting to note that, in agreement with the analysis of Nešlehová et al. (2006)
for mean excess plots in the presence of contaminated data, the results shown in Figure
11

5 support the presence of contamination due to outlying observations. More precisely,
the different nature of the largest values makes the mean excess curve of the upper panel
difficult to interpret.

2
1
−1

0

Mean Excess

3

All data points

0

1

2

3

4

Threshold

0.20
0.15
0.10
0.05

Mean Excess

0.25

Without 1% largest values

0.0

0.05

0.1

0.2

0.3

0.4

0.5

0.6

Threshold

Figure 5: Mean residual life plots for the odds of positive cases.
Forward variable selection (based on the RAIC defined in Equation (8)) was performed
for the three models. We checked for linear and non-linear covariate effects; as mentioned
in Section 2.2, linear specifications were found to be adequate for the modelling purposes
of our dataset.
For all responses, a constant model was selected for the shape parameter ξ. This is not
surprising, first, because this parameter is difficult to estimate (Hosking and Wallis, 1987),
and, second, because it concerns the tail behavior of the underlying process, a characteristic that is not likely to vary with meteorological factors. The estimated shape parameters
related to the two discrete variables (positive and negative) are close to zero, meaning an
underlying light tail that in fact many common discrete distributions, including geometric, Poisson and negative binomial distributions have (Hitz et al., 2017). The estimated
shape parameter for the odds of positive has a negative sign, which makes sense as one can
expect this odd to be bounded above. As for the scale parameter σ, we found significant
and linear effects for some meteorological variables. Below we present the results for each
response variable.
Number of positive cases
In this case, the final fitted D-GPD model is based on the following equations and estimates:
q
ξˆ = α̂0 ,
with α̂0 = −1.974e-06 (and standard error of 3.719e-01) and
log(σ̂) = β̂0 + β̂1 MintempL3 + β̂2 RadiationL3 + β̂3 PrecipitationL3.
12

The estimated coefficients are reported in Table 2 and their effects graphically shown in
Figure S1 in Supplementary Section C.
Table 2: Estimated coefficients for the final D-GPD model fitted to positive cases.
log(σ̂)
Estimate Std. Error Z- value P-value
Signif
Intercept
2.037
0.138
14.79
0.000
***
MintempL3
-0.054
0.021
-2.54
0.011
*
RadiationL3
-0.005
0.001
-3.62
0.000
***
PrecipitationL3
-0.009
0.004
-2.11
0.035
*
−3 :
Signif. codes: 0 < p-value < 1e
∗ ∗ ∗, p-value < 0.01 : ∗∗, p-value < 0.05 : ∗

The resulting estimated value for ξ is very close to zero, implying a probability mass
function that may belong to the discrete maximum domain of attraction with ξ = 0 (Hitz
et al., 2017). The equation for the scale parameter σ explains both the variable’s variance
and mean. For the latter, for GPD and therefore also for D-GPD, recall that the mean
excess depends on the scale parameter as shown in Equation (3). A broad interpretation
of the results is that the warmer and nicer the weather, the lower the number of extreme
positive cases, variability and mean. Interestingly, radiation seems to better explain the
response than humidity does, which is the factor ommonly used to explain flu spread
(Lowen and Steel, 2014). As highlighted by Figure 4, radiation and precipitation provide
complementary proxies of humidity.
Number of negative test results
The final fitted D-GPD model is based on the following equations and estimates:
q
ξˆ = α̂0 ,
with α̂0 = 4.505e-05 (1.142e-01) and
log(σ̂) = β̂0 + β̂1 RadiationL3 + β̂2 PrecipitationL3.
The estimated coefficients are reported in Table 3 and their effects shown in Figure S2 in
Supplementary Section C.
Table 3: Estimated coefficients for the final D-GPD model fitted to negative cases.
log(σ̂)
Estimate Std. Error Z- value P-value
Signif
Intercept
2.483
0.151
16.43
0.000
***
RadiationL3
-0.003
0.001
-2.15
0.031
*
PrecipitationL3
-0.010
0.005
-2.01
0.045
*
−3 :
Signif. codes: 0 < p-value < 1e
∗ ∗ ∗, p-value < 0.01 : ∗∗, p-value < 0.05 : ∗

As compared to the previous model, minimum temperature does not seem to explain
the variability and mean of the number of negative extremes. This may be due to the
fact that cold weather activates the virus which in turn leads to more positive cases.
Both the effects of radiation and precipitation are less important than those found when
modelling positive cases. This may be explained by the fact that better meteorological
13

conditions (warmer months and sun) simply decrease the number of test cases. For positive
cases, favorable meteorological conditions also decrease the probability of catching the flu
during the autumn/winter time. In other words, the evidence suggests that radiation and
precipitation, which commonly affect the positive and negative cases, mostly influence the
total number of tests that are carried out. During warmer months, summer or when the
weather is good during winter time, individuals tend not to go the hospital. The analysis
suggests that minimum temperature influences only the spread of flu.
Odds of positive cases
The final fitted GPD model is based on the following equations and estimates:
log(ξˆ + 0.5) = α̂0 ,
with α̂0 = −3.293(0.671) and
log(σ̂) = β̂0 + β̂1 MintempL3.
The estimated coefficient for MintempL3 is reported in Table 4 and its effect displayed in
Figure S3 in Supplementary Section C.
Table 4: Estimated coefficients for the final GPD model fitted to the odds positive cases.
log(σ̂)
Estimate Std. Error Z- value P-value
Signif
Intercept
-1.272
0.051
-25.03
0.000
***
MintempL3
-0.098
0.009
-11.17
0.000
***
−3 :
Signif. codes: 0 < p-value < 1e
∗ ∗ ∗, p-value < 0.01 : ∗∗, p-value < 0.05 : ∗

In this case the resulting estimated value of ξ is negative, implying that the underlying
distribution is bounded above, that is, the ratio cannot reach extremely large values.
Unsurprisingly the extremes of the odds positive do not depend on meteorological factors
other than those explaining positive and negative extreme cases. However, this was not
obvious because the threshold choice for the odds positive was not given by the threshold
for the positive and negative cases. In this model, only minimum temperature influences
the response. All in all, among the different meteorological factors observed, humidity,
wind and pressure do not exhibit an effect as compared to radiation, precipitation and
minimum temperature; the latter being more responsible for the epidemiological aspect
of the analysis.

3.1

Hospital congestion

From a risk management point of view, a quantity of high interest is the CaRe defined in
Equation (4) for GPD, and in Equation(6) for D-GPD. These values constitute important
risk measures for the hospital. Intervals are also crucial as they provide information about
the estimates’ uncertainty.
For the positive cases, the p%-CaRe corresponds to the regime of congestion. Figures
6, 7 and 8 show some p%-CaRe estimated curves and respective intervals obtained via
posterior simulation, based on different values of the meteorological factors. For instance,
14

the bottom panel of Figure 6 corresponds to the 0.86%-CaRe, that is the number of
positive cases that can be exceeded one time over a time horizon of 7 days. This point
estimate decreases from 18, for a minimum temperature of -10 degC, to 11, for 0 degC.
For a horizon of 7 days, the bottom left panel of Figure 7 shows that the number of
positive cases that can be exceeded once a week decreases from 16, in the case of no sun,
to 3, when radiation is at its highest value. This evidence should, however, be interpreted
bearing in mind the widths of the intervals which are large.

15

125

CaRe_30 days

100

75

50

25

●●●●●
●●●●●●
●●●●●
●●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●
●●●●

−10

−5

0

5

10

15

60

CaRe_14 days

50
40
30
20
10

●●●
●●●
●●●●
●●●
●●●●
●●●●
●●●●●
●●●●
●●●●●
●●●●●●
●●●●●
●●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●●●●●●●●●
●●●●

−10

−5

0

5

10

15

CaRe_7 days

40

30

20

10

●●●●
●●●●●
●●●●●
●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●

−10

−5

0

5

10

15

MintempL3

Figure 6: Positive cases: estimated CaRe for h = 30, 14, 7 days (panels from top to
bottom, respectively) with respect to lagged minimum temperature. The bars correspond
to 95% intervals. The other covariates are fixed to their mean values.

16

CaRe_30 days

80

60

40

●●●●●●
●●●●●●●●
●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●

20

0

100

200

300

60

CaRe_14 days

50
40
30
20
●●●
●●●●●
●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●
●●●●

10

0

100

200

300

CaRe_7 days

20

●●●●
●●●●●●●
●●●●●●●

10

●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●
●●●●●

0

100

200

300

RadiationL3

Figure 7: Positive cases: estimated CaRe for h = 30, 14, 7 days (panels from top to
bottom) with respect to lagged radiation. The bars correspond to 95% intervals. The
other covariates are fixed to their mean values.

17

CaRe_30 days

60

40

20

●
●●●●●●
●●●●●●●
●●●●●●●●
●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●●●●●
●●●●

0

25

50

75

100

CaRe_14 days

30

20

10

●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●

0

25

50

75

100

CaRe_7 days

30

20

10

●●●●●●●
●●●●●●●●●●●●●
●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●

0

25

50
PrecipitationL3

75

100

Figure 8: Positive cases: estimated CaRe for h = 30, 14, 7 days (panels from top to
bottom) with respect to lagged precipitation. The bars correspond to 95% intervals. The
other covariates are fixed to their mean values.
Supplementary Figures S4 and S5 show the CaRe estimated values with their simulated
intervals as a function of meteorological predictors, for different time horizons for negative
cases. These values convey information on the risk of inefficiency in the flu testing process,
revealed by a very high number of negative cases. The risk of inefficiency considerably
decreases both in sunny and raining periods. The top panel of Figure S5 shows the
18

estimated number of negative cases that can be exceeded once a month in terms of amount
of precipitation. For a 30-day horizon, CaRe goes from 50, in the scenario of no rain, to
30 when it rains.
Large estimated p%-CaRe values for the odds positives, as shown in Figure S6 with their
simulated intervals, correspond to the epidemic regime. Note that the intervals are thinner
as compared to those obtained for the discrete responses, but the values themselves are
smaller (between 0 and 1).

3.2

Outliers detection

The hospital flu testing process depends on managerial and/or decision making instances
and may lead to outlying records; our robust methodology is capable of detecting these
abnormal values. Figures 9, 10 and 11 show the robustness weight w = ρ0c (see Section 2.2)
for each observation. These are obtained as a by product of the parameter estimation
process. The size of the circles is proportional to (1 − w). These weights can be used to
identify outliers: the lower the weight, the more likely the observation is to be outlying.
We identify the points with the smallest weights, accompanied by their date of occurrence,
from the figures. The observations with the smallest weights are not systematically those
with large observed values, and, conversely, the largest observations are not systematically
considered outliers. This can be seen in particular for the odds of positive cases.
Dates such as 03/01/2017 and 02/01/2018 (which are after the Christmas break) are
typically regarded as special days in the flu recording process. Days in February 2019
such as 24/02/2019 and 26/02/2019 in Figure 9 relate to positive cases and correspond
to school holidays. At school, children are super-spreaders. This is not the case during
holidays when children are with their families. This and the fact that people are less
tested during holidays contribute to a significant slow-down of the flu epidemic.

19

● 2018−01−02

● 2019−02−12

●

●

●
●

●

●●
●
●

●

●
●

15

●

●

●
●

●

●

2019−02−15
●
●

●●
●
●

●
●

● 2019−02−26

Number of positive cases

●
●

●

●
●

10

●●
● ●
● ●
●
●

●
●●
●
●
●

● ●
●
●
●
●
●

● ●
●
●

●
●
●●
●
●
● ●
●
●
●
●
●

●
●

●
●●●
●
●

●

●

●●
●
●
●
●

●●
●●
●
●●
●
●

5

●●
●●
●
●

● ●●● ●

0

●● ●
●●
●●
●●
●●
●
●●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●

●●

●
●
●
●●
●

● ●

●
●

●●
●
● ●●
●
●
●

●
●●
●●
●
●

●●
●
●
●●
●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●●

2017

●●
●
●
●
●

●
●

●● ●
●●● ●●●

●
●
●
●
●

●
● ●●●
●
●●
● ●●
●
●● ●●

● ●

●●

●

●●
●
●

●
●●
●
●
●
●
●
●
●

●
●
●
●●●
●
●
●
●● ●
●
●●●●
●
●
● ●●
● ●●
●

●●

●
●● ●
● ●●

●
●

●
●●
●
●
●

●●
●●
●●
●
●
●
●

●●
●●
●
●
● ●
● ●
● ●
●
●
●
●
●
●

●
● ●● ● ●
● ●
●

●
●
●
●
●
●
●

●
●

● ●
●●
●
●

●●
●
●
●
●

●
●
●
●

●
●

● 0.1
● 0.2
● 0.3

●●
●
●●
●
●
●
●
●
●
●
●

● ●
●
●
●

●
●
●
●

●
●

●●
●
● ●
●
●
●

●

●
●

● ●
●
●

● ●
●
●●
●
●
●

●
●●
●●
●
●
●
●
●
●

1−Robust weights

●●
● ●
●●
●
●

●●

● ●
●●
●●
●
●
●
●

2019−02−24

● ●
●
●

● ●
●
●

● ●
●
●

●
●
●●
●
●
●
●
●
●

●●

●●
●●
●
●

●●●●●

●●

●

●
●● ●●
●
● ●

● ●●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●●
●

2018
Date

●

●

●●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

2019

Figure 9: Robustness weights from the model fitted to positive cases.

●
●

2019−02−19
40
●●

●
●

●

●

●
●

●
●

●●
●
●

Number of negative test results

●
●
● ●
●
●
●
●
●
●
●
●
● ●
● ●
●
●
●
●

●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●●
●
●
●●
●
●

●●
●
●
●
●

30

●●
●
●
●
● ●
●

●
● ●
●
●
●
●
●
●
●
●

●
●

● ●
●
●

●
●

●
●

●
●
●

●●
●●
● ●
●●
● ●
● ●
●
● ●
●●
●
●
●

●
● ●
●●
●●
● ●
● ●
●
●●
● ●
●
●
●
●

●●

●

●

●

●

●●
●●

●

●

● ●

●

● ●

●

●●
●
●

●

●
●●

●●
● ●● ●
●
●
●
● ●
● ●●

●●●

●

●

● ●

● ●● ●
●●
●
● ●
●
●
●●●
●
●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●
●
●
● ●●●
●● ●
●● ●
●●
●●

2017

●

●
●

● ● ●● ●

●

●●

●

●

●● ● ●

●
●

●

● ●●

●●● ● ●● ●
●
●

●
●● ●

● ●

●●

● ● ● ●● ●

●●
●●
●●
●● ●
●

● ●
●●●●●
●●
●

●

●●
●
●
●

●

●

●●
●● ●
●
● ●

●●
●
●

●
●
●
●
●
●
●● ● ●
●
●

●
●

● ●●
●
● ●●

●
● ● ● ● ●●

●
● ●●
●
●
● ● ●●
●

● ●● ●
●●●

●
●
●●
●
● ●
●
●
●
●

● ●●●● ●
●
●
●
●
●
● ●●● ●

●●●
●

●

●
●●
●

●

●

●

●

●

●●

●
●
●
●

●

●●

●

●

●●

●

●

●

●●

●

●

●●

●
●

●●

●

●●
●●●
● ●● ●
●●●
●
●●
●
●●● ●
●

●

●
●●
●
●
●●
●●●
●
●
●
●●
●
●
●●
●●
●
●●
●●●●

●●
●● ●●

●
● ●●

● ● ●

●
●●● ●
●●
●
●●
●●
●

●●
● ●●
●●● ●
●● ●●
●●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●●
●●●
●
●●●

2018
Date

● ● ●

●

●● ●
●
●
● ● ●●

●● ● ● ●

●● ●

●

●●
●● ●
●

●

● ●● ●
●●
●●● ● ●
●
●
●● ● ●
●
●
●●
● ●●● ●
●
●●●
●
●
●
●
●
●●
● ●● ●
●● ● ● ●
●●
●●
●
●●●
●●
●●
●● ●
●
●
●

●
●
●

●

●●
●

● ●●
●

●
●
● ●
●
● ●
●

●●
● ●
●
●● ●

●
●
●
●●● ●
●●
●
●
●
●●
●● ● ●●
●

● ●

●
●

●● ●●

●●●
●
●● ●

●

●
●
●

● ●●

●

●

●

●

●●
●
●
●

●
●

●
●

●

●

●
●

●

●●

●●● ●

●●
●

●
●

●

●
●●

● ● ●●
●

●
● ● ●●

●

●

●
●●
●
●● ●
●●
● ●● ●●
●
●●●
●● ●●
● ● ●● ●●
●
●
●
●
●
●
● ●●
●
●
●
●
●●● ●
●●

0

●

● ●●
●
●

●

● ● ●●

●●
●

●●

● ●
●

●
●

●
● ●

●

●

●
● ●
●

●

● ●

●

●

10

●

●
●

●
●

●●

● ●●

●

●

●
● ●●
●

●

● ●●
●
●

●
● ●

●● ● ●
● ●●

●

●
● ● ●● ●

● 0.1
● 0.2
● 0.3

●●
●
●
● ●
●
●

●

●

● ● ● ●●

1−Robust weights

●●
●
● ●
●
●
●

●
●
●
●
●
●

●●
● ●
●
● ●
●●
●
●
●
●
●
●
●

●
●

● ●● ●●●●
●
●●

●

● ●
●●
●
●

●
●

●●
● ●
●
●

●
●

●

● ●
●
●

●●
●
●
● ●
● ●
●●
●
●

● ●
●
●

● ●
●●
●●
●
●

20

●
●

●●
●
●●
●●
●
●

●
●
●●
● ●
●
●

●
●●
●●
● ●
●
●
●
●●
● ●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●

●
●

●●

●

●●

● ●
●●

●● ●
●

●●
●●

●

●● ●
●
●
● ●●●
●
●
●●
●● ●
●
●●
●●

● ●●
●

●
●●

2019

Figure 10: Robustness weights from the model fitted to negative cases.

20

* ●
(3.95)

2.0

●

1.5

Odds of positive

●
●

1−Robust weights

1.0

●
●

●
●

●
●

● 0.1
● 0.2
● 0.3

●

●●

●
●

●
●

● ●
●
●

●
●2017−01−03
●
●

●
●

●

●

●
●
●
●

●

●
●
●
●
●
●

●●
●
●

● ●
●
●
● ●●
●
●
●
●

●
●
●

0.5

●
●

●
●
●
●
● ●
●●
●
● ●
●
●
●
●
●
●
●
●

●
●
●●
●
●

●
●
●
● ●
●
●

● ●
●●
● ●
●●
●
●
● ●
●
●
●●
●
●

●

●
●

0.0

●

●

● ●●
●
●
● ●●
●
●

●
●
●
●
●
●
●● ●
●●
● ●●●
●●
●
●●●
●●
●●
●●●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●

●●2018−01−04
●●
●
●

●●
●●
●

●

●
●
●

● ●
●
●
●
●

●● ●
●

●

●

●
●

●

●●
●
●

●
●
●
●

●●
●
●
●
●
●
●

●
●
●
●

●
●●
●●
●●
● ●●
●
●
● ●●
●
●
● ● ●●
● ●
●●
●
● ●
● ●
● ●
●
● ● ●●
●
●
●
●

●●
●
●
●●
●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●
●
●●

2017

●
●●

●
●
● ●
● ●
●
●
●
●
● ●
●
●
●●
●
●●●
●

●●

●
●

●
● ●●

●
●

●
●
●
●
●●
●●
●
●
●●
●
●
●
●
●

●
●

●●
●
●
●
● ●
●
● ●
●
●
● ●●
●
●
●
●
●
●
●
●
●

●
●

●
●
●
●
●
●

●
●

●

●
●
●
●

●
●

●
●

●
●

●

●

●

●●
●
●
●●
●
● ●
●
●● ● ● ●
●

●●

●

2018
Date

● ●●
●●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●

●
●
●
●
●
●
●
●
●
●
●

2019−02−13
●
●

●
●
●●
●
●
●
●
●
●
● ●
● ●
●
●

●
●
●
●
●
●
●
● ●
●
● ●
●

●
●

●●
●
●
●
● ●
●
● ●
●●
●
●
●
●●
●●
●
●
●
●●
●
●
●
●
●

●

●●
●●●●
●
●●
● ●●●
●●
●● ●
●
●
●
●●
●● ●● ●●
●
●●●
●●
●
●
●●
●
●
●●
●
●●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●●
●

●● ●
●●
● ●●

●
●

●

●● ●
● ●
●
●
●
●●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●

2019

Figure 11: Robustness weights from the model fitted to odds of positive cases. The star
(*) at the top of the graph indicates that an observation (odds = 3.95 on 08/11/2017 and
robustness weight = 0.93) has not been represented.

4

Simulation Study

To assess the empirical properties of our proposal in finite samples, we designed a simulation study inspired by our data analysis in Section 3. We will look at the quality of
the estimated parameters and CaRe obtained using the proposed approach, both under
the assumed (D-GPD or GPD) model and under contamination (i.e., in the presence of
observations that deviate from the assumed model).

4.1

D-GPD

For D-GPD responses, we generated "clean" datasets from the model
p
ξ = α0 and log(σ) = β0 + β1 x1 + β2 x2 + β3 x3 ,

(9)

where the covariates distributions were chosen to mimic the behavior of MintempL3,
RadiationL3 and PrecipitationL3 in the application. More precisely, we simulated the
covariates as follows: x1 ∼ N (2.3, 14), x2 ∼ Γ(1.55, 0.02) and x3 ∼ lognormal(0.71, 3.12).
These were kept fixed throughout the simulation replicates. The parameters, inspired by
our case study, were set to α = 0.01 (hence ξ = 10−4 ), and β = (2, −0.05, −0.005, −0.01)T .
Contaminated datasets were obtained by randomly setting 5% of the response values to
the maximum value observed in the sample. Again, this was inspired by the empirical
application.
21

The sample size was set to n = 250 (hence consistent with our application) and the number
of replications to 500. We fitted models based on the robust and classical maximum
likelihood estimators. For the robust approach, we chose c = 5.8 to achieve a downweighting of 0.95.

0.5

^ 0 − α0
α

●
●
●
●

0.0

Clean

Contaminated

−0.5

●

classical

robust

classical

robust

^
β1 − β1
●

●
●

●

●

0.05

●
●
●

●
●

●
●
●
●
●
●
●

classical

robust

●
●

●
●
●

classical

robust

●
●

classical

robust

robust

0.010

●
●
●

●

0.000

●

●
●

●
●

classical

−0.010

0.000

0.004

classical

^
β3 − β3
●
●
●

●

●
●

●

^
β2 − β2

−0.004

●
●
●

●
●

−0.05

−0.8 −0.4

0.0

0.4

^
β0 − β0

robust

●

classical

●
●

robust

●
●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●

classical

robust

●
●

●
●
●
●
●
●
●
●
●

classical

robust

●
●

Figure 12: Boxplots of the centered parameter estimates for model (9). In each panel,
the left boxplots refer to the clean data setting, and the right ones to the contaminated
data setting.
Figure 12 shows the centered estimated parameter estimates for model (9). By looking at
the left boxplots of each panel, corresponding to the clean data setting, we see that both
boxplots are centered around zero suggesting unbiased estimation of the model parameters. We also see that the variability of the robust estimator’s estimates are slightly larger
than the variability of those obtained using its classical counterpart; this is expected because of the loss of efficiency of the robust estimator with respect to maximum likelihood.
The story is different when looking at the right boxplots of each panel, corresponding to
the contaminated data. All in all, the robust estimator performs much better than the
classical one. For all the components of β, except β2 , the robust estimator shows no bias.
This is not the case for the classical estimator, which is influenced by the outliers, sometimes heavily, notably for β0 and β3 . Surprisingly, the robust estimator shows some bias
for β2 , but its magnitude is small. Also note that contamination affects the variability
of the classical estimator, which is larger than that of the robust estimator for all the
22

components of β. The estimation of α0 under contamination seems more difficult. Both
estimators show bias, even though that bias is much smaller for the robust estimator. It
is worth recalling that a robust estimator guarantees that the bias under contamination
does not explode, but it does not guarantee that it will vanish. Had we increased the
amount of contamination or its strength, we would have expected the bias of the classical
estimator to explode, but not that of the robust approach.
h=7
350
250
150
0
25

0

1

17

22

0

2

4

8 10

0

2

300
100
0
2

4

6

8 10

0

2

4

6

8 10

6

300
100

0

0

100

200

300
200

300
100

8 12

4

6

8

0

400
300
200
100
0

0

0

100

100

200

200

300

300

400

400

500

0

4

400

1

0

200

300
100
0

0
400

1

200

300
200
100
0
0

100

200

300

400

500

19

0

100
0
1

0

400
0

13

200

300
200

300
200
0

1

400

0

0 4 8

400

2
400

1

robust

50

150
50
0

0 50
0

400

2

400

1

100

mean(x1)
Q3(x1)
max(x1)

250

350
250
150

250
150
0 50

min(x1)

0

classical

350

robust

350

classical

0

2

4

6

8

0

2

4

6

Figure 13: CaRe estimates for h = 7 for four values of x1 : its minimum value (first row),
its average (second row), its third quartile (third row) and its maximum (fourth row). The
other covariates are fixed at their mean values. The true population value is identified
by a darker bar. The first two columns correspond to the clean data setting, whereas the
last two columns correspond to the contaminated data setting.

23

10

Figure 13 reports the estimated CaRe for h = 7 as a function of x1 , with x2 and x3
fixed at their mean values. CaRe is a discrete positive value (with relatively few different
values in our simulation setting) and we depict it using barplots (histograms) for four
representative values across the range of x1 : its minimum (first row), its average (second
row), its third quartile (third row) and its maximum (fourth row). In each panel, the true
population value is identified by the dark bar. The comparison of the first two columns
confirms that the robust and classical estimators perform equally well and their estimates
either match the population value or are just off by one unit. Looking at the results under
contamination and comparing the last two columns of the figure, we observed that the
robust estimator performs much better than the classical one in that it identifies the true
population value more often (roughly 95% of the times, except for min(x1 ) where this is
about 80%). In contrast, the classical CaRe estimator shows large variability and misses
the population target quite often. The quality of the CaRe estimates is not uniform across
the range of x1 , with lower values of the covariate being more challenging.
We provide in the supplementary material similar figures for all the other combinations
of horizons h and covariates; the conclusions do not change. Moreover, as expected, we
observe that the performance of both estimators worsen as h increases, and that the CaRe
seems to be difficult to estimate for low values of x3 .
To sum up, our simulation study demonstrates that our distributional regression approach
is effective in estimating models with D-GPD responses, and that the robust version of
the estimator can successfully cope with contaminated data.

4.2

GPD

In this case, we generated data using the model
log(ξ + 0.5) = α0

and

log(σ) = β0 + β1 x1 ,

(10)

where x1 ∼ N (2.3, 14), which reproduces what we see in our application for MintempL3.
We consider α = −2 (hence ξ = −0.36) and β = (−1.3, −0.1)T . Contaminated datasets
were obtained by randomly setting 5% of the response values to the maximum value observed in the sample. The sample size was set to n = 250 and the number of replications to
500. Here as well, we fitted models based on the robust and classical maximum likelihood
estimators, and for the robust approach, we chose c = 2.3 to achieve a downweighting of
0.95.

24

2

^ 0 − α0
α
●

0

1

●
●

Contaminated

−3

−2

−1

Clean

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

●
●
●
●

●
●
●
●

●
●
●
●

●
●
●
●
●
●

●
●

●
classical
robust
classical robust
●

●
●

●
●
●

0.2

●

^
β1 − β1
●
●
●
●

●
●
●
●
●

0.0

●

●
●
●
●
●

●
●
●
●

●

●
●

0.00

●
●

●
●

0.04

●

●
●
●
●
●

●
●
●
●

−0.04

●
●
●

−0.4

−0.2

^
β0 − β0

classical robust classical robust

●
●

●
●

●

●

●
●

classical robust classical robust

Figure 14: Boxplots of the centered parameter estimates of model (10). In each panel, the
left boxplots are for the clean data setting, and the right boxplots for the contaminated
data setting.
The analysis of the boxplots of the centered parameter estimates for model (10) conveys
the same conclusions as for the case of D-GPD: the robust estimator performs as well as its
classical counterpart when using clean data, and outperforms the classical estimator under
contamination. Furthermore, it is known that the GPD is difficult to fit and our findings
suggest that our robust approach has a stabilizing property even for clean data where it
corrects what seems to be a finite sample bias of the maximum likelihood estimator when
estimating α0 . It has been previously observed in the literature that robust estimators
converge faster than their classical counterparts to their asymptotic distribution.
Figure 15 shows functional boxplots (Sun and Genton, 2011) for the CaRe estimates as a
function of x1 . The solid red line is the median curve and the envelope represents the 50%
deepest, or most central, curves, much like the interquartile range in a regular boxplot.
The black dashed line is the true population CaRe. The first two rows of the panels refer
to the clean data setting, whereas the last two rows to the contaminated data setting.

25

1.4
0.6
0.2

0

5

10

10

5

10

5

10

5

10

5

10

0.6
0

5

10

x1

x1

−5

0
x1

0.5

1.5
0

0

10

1.5
−5

0.5

0.5

−5

−5

5

1.5

5
x1

0

0.5

0.5
0

2.5

0.5

−5

−5

0.2

0.6
0.2

x1

1.5

2.5

0.2
classical
1.5

2.5

−5

10

1.4

10

5

1.0

5

0

2.5

0

−5

2.5

−5

h=7

1.0

1.4
1.0
0.2
10

1.0

5

1.4

0.2
1.4

0

robust
0.6
1.0

−5

robust
1.5

2.5

h = 14

0.6

classical
0.6
1.0

1.4

h = 30

−5

x1

0

5
x1

10

−5

0
x1

Figure 15: Functional boxplots of CaRe estimates as a function of x1 for h = 30 (first
column), h = 14 (second column) and h = 7 (third column). The solid red line is the
median curve and the envelope represents the 50% deepest, or most central, observations.
The black dashed line is the true population CaRe. The first two rows of panels are for
the clean data setting, the last two rows are for the contaminated data setting.
From the two top rows, we observe that for clean data both the classical and robust estimates are aligned with the population values. When the data are contaminated (third
and fourth rows of panels) the classical estimator completely misses the target by overestimating the CaRe, whereas the robust estimator continues to perform well. The wider
pink envelopes also suggest that the classical estimator has larger variability than the
robust one under contamination. The unsatisfactory behavior of the classical estimator
26

worsens with an increasing h, as one would expect.
In summary, once again, we observe that our distributional regression approach works well
in estimating models with GPD responses, with the robust version being rather stable
under contamination.

5

Conclusion

Seasonal epidemics may lead to hospitals congestion. In this paper, we use extreme value
theory to study the occurrence of large numbers of flu cases in a hospital. To this end, we
developed and implemented in GJRM a robust regression-type methodology that allows for
non-identically distributed discrete and continuous extremes, and that deals with outlying
data. The response variables of interest (the positive and negative cases together with
the odds of positives) are statistically explained by meteorological variables. Although
the models selected for this case study are based on parametric covariate effects, our
software implementation allows for very general non-parametric functional forms, which
would most likely be required for larger datasets.
Taking the point of view of the hospital, which needs to manage admission capacities,
we introduced the notion of charge-at-risk whose estimation, based on meteorological
factors, can serve as a quantitative tool to alert the hospital and allow time to prepare
for a possible congestion. The introduced approach could be applied to several types of
seasonal virus data such as those deriving from the new virus SARS-CoV-2.

Acknowledgments
The simulations were performed at the University of Geneva using the Baobab cluster.
The research was partially funded by the Swiss National Science Foundation SNF (first
and third authors).

References
Aeberhard, W.H., Cantoni, E., Marra, G., Radice, R., 2019. Robust fitting for generalized
additive models for location, scale and shape. arXiv:1911.05125 .
Balkema, A.A., de Haan, L., 1974. Residual life time at great age. The Annals of
Probability , 792–804.
Chavez-Demoulin, V., Davison, A.C., 2005. Generalized additive modelling of sample
extremes. Journal of the Royal Statistical Society: Series C (Applied Statistics) 54,
207–222.
Davis, R.E., Rossier, C.E., Enfield, K.B., 2012. The impact of weather on influenza and
pneumonia mortality in new york city, 1975-2002: A retrospective study. Plos one
doi:10.1371/journal.pone.0034091.
27

Davison, A.C., Smith, R.L., 1990. Models for exceedances over high thresholds (with
discussion). Journal of the Royal Statistical Society. Series B 52, 393–442.
Dell’Aquila, R., Embrechts, P., 2006. Extremes and robustness: a contradiction? Fin
Mkts Portfolio Mgmt 20, 103–118.
Dupuis, D., Field, C., 1998. Robust estimation of extremes. Canadian Journal of Statistics
26, 199–215.
Dupuis, D., Victoria-Feser, M.P., 2006. A robust prediction error criterion for pareto
modeling of upper tails. Canadian Journal of Statistics 34, 639–358.
Eguchi, S., Kano, Y., 2001. Robustifing Maximum Likelihood Estimation by Psidivergence. Research Memorandum 802. Institute of Statistical Mathematics (ISM).
Tokyo, Japan.
Firestone, S.M., Cogger, N., Ward, M.P., Toribio, J.A.L.M.L., Moloney, B.J., Dhand,
N.K., 2012. The influence of meteorology on the spread of influenza: Survival analysis of
an equine influenza (a/h3n8) outbreak. Plos one doi:10.1371/journal.pone.0035284.
Hastie, T.J., Tibshirani, R.J., 1990. Generalized Additive Models. Chapman & Hall/CRC,
New York, NY.
Hitz, A., Davis, R., Samorodnitsky,
https://arxiv.org/pdf/1707.05033.pdf .

G.,

2017.

Discrete

extremes.

Hosking, J., Wallis, J., 1987. Parameter and quantile estimation for the generalized pareto
distribution. Technometrics 29, 339–349.
Lowen, A.C., Steel, J., 2014. Roles of humidity and temperature in shaping influenza
seasonality. J Virol. 88, 7692–7695. doi:10.1128/JVI.03544-13.
Marra, G., Radice, R., 2019. Copula link-based additive models for right-censored event
time data. Journal of the American Statistical Association, in press .
Marra, G., Radice, R., 2020. GJRM: Generalised Joint Regression Modelling. URL:
http://CRAN.R-project.org/package=GRJM. r package version 0.2-2.
Nešlehová, J., Embrechts, P., Chavez-Demoulin, V., 2006. Infinite-mean models and the
lda for operational risk. Journal of Operational Risk 1, 3–25.
Rigby, R.A., Stasinopoulos, D.M., 2005. Generalized additive models for location, scale
and shape (with discussion). Applied Statistics 54, 507–554.
Roussel, M., Pontier, D., Cohen, J.M., Lina, B., Fouchet, D., 2016. Quantifying the role
of weather on seasonal influenza. BMC Public Health 16.
Sun, Y., Genton, M.G., 2011. Functional boxplots. Journal of Computational and Graphical Statistics 20, 316–334.
Towers, S., Chowell, G., Hameed, R., Jastrebski, M., Khan, M., Meeks, J., Mubayi, A.,
Harris, G., 2013. Climate change and influenza: the likelihood of early and severe
influenza seasons following warmer than average winters. PLoS Currents doi:10.1371/
currents.flu.3679b56a3a5313dc7c043fb944c6f138.
28

Wood, S.N., 2017. Generalized Additive Models: An Introduction with R. 2 ed., Chapman
and Hall/CRC, Boca Raton, FL.
Yee, T.W., Stephenson, A.G., 2007. Vector generalized linear and additive extreme value
models. Extremes 9, 1–19.

29

Supplementary Materials for
Modelling the Extremes of Seasonal Viruses and Hospital
Congestion: The Example of Flu in a Swiss Hospital
by Setareh Ranjbar, Eva Cantoni, Valérie Chavez-Demoulin,
Giampiero Marra, Rosalba Radice, Katia Jaton-Ogay
A

Analytical Derivatives

This section provides the analytical score and Hessian components of the model’s loglikelihood, for the GPD and D-GPD distributions. We also report the expectations and
variances for the two distributions, and for the D-GPD we explain how variates are simulated.

A.1

GPD

If Y follows a GPD distribution with shape parameter ξ and scale parameter σ, then its
cumulative distribution function is F(σ,ξ) (y) = 1 − G(σ,ξ) (y) (with G(σ,ξ) (y) given in (2))
> 0}.
which is defined for σ > 0 and for {y : y > 0 and 1 + ξy
σ
Then the probability density function is
1
g(σ,ξ) (y) =
σ
The expectation of Y is E(Y ) =

σ
1−ξ


(−1/ξ−1)
ξy
.
1+
σ

and the variance is V ar(Y ) =

σ2
.
(1+ξ)2 (1−2ξ)

Having observed y = {y1 , y2 , · · · , yn } as independent realizations of Y the log-likelihood
is

l(y; ξ, σ) = log 

n
Y


g(σ,ξ) (yi ) = −n log(σ) − 1 + 1/ξ

i=1

n
X
i=1



ξyi
log 1 +
.
σ

The first and second derivatives with respect to ξ and σ are


n
n
X
1 X
ξyi
y /σ
 i
,
lξ = 2
log 1 +
− (1 + 1/ξ)
ξ i=1
σ
1 + ξyi
i=1
σ

n

n

ξyi
X yi − σ
X
n
σ2

=
lσ = − + (1 + 1/ξ)
,
σ
σ(σ + ξyi )
1 + ξyi
i=1
i=1
σ

1



n  2
n
n
X
yi
−2 X
ξyi
2 X yi
1
1

 + (1 + 1/ξ)
lξξ = 3
log 1 +
+ 2
2 ,

ξ i=1
σ
ξ i=1 σ 1 + ξyi
σ
ξyi
i=1
1+ σ
σ
ξy 2

n

lσσ

lσξ

n

i
X σ 2 − ξy 2 − 2σyi
 X −2ξy
− σ4i
n
3
i
= 2 + 1 + 1/ξ
,
σ
2 =
2 (σ + ξy )2
σ
σ
ξyi
i
i=1
i=1
1+ σ

−2 X
n
n
n 
X
1 X yi /σ 2
yi (yi − σ)
ξyi

 + (1 + 1/ξ)
=−
=
.
1+
ξ i=1 1 + ξyi
σ
σ(σ + ξyi )2
i=1
i=1
σ

A.2

D-GDP

If Y follows a D-GPD distribution with shape parameter ξ and scale parameter σ then the
probability mass function of Y = r, where r ∈ N0 = {0, 1, 2, ...} is, using Equation (5),
(−1/ξ) 
(−1/ξ)

ξ(1 + r)
ξr
− 1+
,
DG(σ,ξ) (r) = 1 +
σ
σ
which is defined for σ > 0 and for {r : 1 +

ξr
σ

>0

1+

and

ξ(r+1)
σ

> 0}.

The mean and variance have to be calculated numerically. Specifically,

E(Y ) =

∞ 
X
r=1

ξr
1+
σ

−1/ξ
,ξ > 0
+

and

−1/ξ "X
−1/ξ #2
∞
∞ 
X
ξr
ξr
(2r − 1) 1 +
V ar(Y ) = E(Y 2 ) − [E(Y )]2 =
−
1+
.
σ +
σ +
r=1
r=1
Having observed y = {y1 , y2 , . . . , yn } as independent realizations of Y , the log-likelihood
is
n
X
l(y; ξ, σ) =
log(pi ),
i=1

where

pi =

ξyi
1+
σ

(−1/ξ)



ξ(1 + yi )
− 1+
σ

(−1/ξ)

The first and second derivatives with respect to ξ and σ are
n

∂pi

X ∂ξ
∂l
lξ =
=
,
∂ξ
pi
i=1
2

.

n

X ∂pi
∂l
∂σ
lσ =
=
,
∂σ
p
i
i=1
 2
2
n ∂ pi p − ∂pi
2
X
i
∂ξ 2
∂ξ
∂ l
,
lξξ = 2 =
2
∂ξ
p
i
i=1
2

lσσ =

∂ l
=
∂σ 2

2

lσξ =

∂ l
=
∂σ∂ξ

2
n ∂ pi .p
X
i
∂σ 2



−

∂pi
∂σ

2

p2i

i=1

2
n ∂ pi p
X
∂σ∂ξ i

−



∂pi
∂σ

p2i

i=1



,

∂pi
∂ξ


,

the elements of which are
#

−1/ξ "
log(1 + ξyσi )
∂pi
ξyi
yi
= 1+
−
+
∂ξ
σ
ξ2
σξ(1 + ξyσi )
"
#

−1/ξ
ξ(yi +1)
log(1
+
)
ξ(yi + 1)
(yi + 1)
σ
− 1+
−
+
,
ξ(y
+1)
2
i
σ
ξ
σξ(1 + σ )
yi
∂pi
= 2
∂σ
σ


∂ pi  log
=
∂ξ 2
2



(yi +1)ξ
σ



+1

ξ2




(yi +1)ξ
σ

ξyi
1+
σ

−1/ξ−1

(yi + 1)
−
σ2


−1/ξ−1
ξ(yi + 1)
1+
,
σ

2





yi + 1

−
σξ



(yi +1)ξ
σ

+1




(yi + 1) ξ
+1
σ

 −1
ξ






 −1
ξ
 (yi + 1) ξ
2 (yi + 1)
(yi + 1)2



+
+
+
1


2
ξ3
σ
σξ 2 (yi +1)ξ
+1
σ 2 ξ (yi +1)ξ
+
1
σ
σ

2


yi ξ
 −1

ξ
yi
yi ξ
 log σ + 1



+
−
+
1

ξ2
σ
σξ yσi ξ + 1




yi ξ

 −1
2
ξ
 2 log σ + 1
 yi ξ
2y
y
i
i



+
−
+
+
+
1
,


2
 σ

yi ξ
ξ3
2
y
ξ
i
2
σξ
+1
σ ξ σ +1
σ
 2 log
+
−

+1


(−1/ξ−2)

−1/ξ−1
∂ 2 pi
yi2
ξyi
2yi
ξyi
= 4 (1 + ξ) 1 +
− 3 1+
∂σ 2
σ
σ
σ
σ

(−1/ξ−2)

−1/ξ−1
2
(yi + 1)
ξ(yi + 1)
2(yi + 1)
ξ(yi + 1)
−
(1 + ξ) 1 +
+
1+
,
σ4
σ
σ3
σ
3

#

(−1/ξ−1) "

−1


ξyi
yi
ξyi
1
ξyi
1+
(−1/ξ − 1)( ) 1 +
( 2)
+ log 1 +
σ
σ
σ
σ
ξ

(−1/ξ−1)
ξ(yi − 1)
−(yi − 1)
1
+
+
σ2
σ
"
#

−1


(yi − 1)
ξ(yi − 1)
ξ(yi − 1)
1
(−1/ξ − 1)(
) 1+
+ log 1 +
( 2) .
σ
σ
σ
ξ

∂ 2 pi
yi
= 2
∂σ∂ξ
σ

B

R code

In this section, we illustrate the usage of the GJRM package (Marra and Radice, 2020) to
fit the extreme value models introduced in this article. The examples below are based on
artificial data sets.
library(GJRM)
n.size <- 250
x1 <- rnorm(n.size)
x2 <- rnorm(n.size)
x3 <- rnorm(n.size)
XX
<- data.frame(x1 = x1, x2 = x2, x3 = x3)
Xmat <- model.matrix( ~ x1 + x2 + x3)
##############################################################################
# D-GPD (discrete case)
##############################################################################
set.seed(239)
# Simulate Data
###############################################################3
DGPD.alpha <- 0.01
DGPD.beta <- c(1, -0.5, -0.5, -0.1)
DGPD.eta1 <- matrix(rep(DGPD.alpha,n.size), ncol = 1)
DGPD.eta2 <- Xmat%*%DGPD.beta
yy <- r.resp(margin = "DGPII", n.size, eta1 = DGPD.eta1, eta2 = DGPD.eta2)
DGPD.data <- data.frame(y = yy, X = XX)
form.DGPD <- list(y ~ 1, ~ x1 + x2 + x3)
# Classical fit
############################################################
DGPD.classical <- gamlss(form.DGPD, margin = "DGPII", data = DGPD.data)
4

conv.check(DGPD.classical)
post.check(DGPD.classical)
summary(DGPD.classical)
plot(DGPD.classical, eq = 2, all.terms = TRUE, pages = 1)
DGPD.AIC <- AIC(DGPD.classical)
# CaRe (and CIs) computation as a function of x3 (grid on its range)
# (The other covariates are fixed to their mean values)
# p = c(0.86, 0.93, 0.97) for horizon h = (7, 14, 30) days
#####################################################################
newx3 <- data.frame(x1 = rep(mean(x1), length=100),
x2 = rep(mean(x2), length = 100), x3 = seq(min(x3), max(x3), length.out = 100))
CaRe7.classical <- pred.gp(DGPD.classical, p=0.86, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
CaRe14.classical <- pred.gp(DGPD.classical, p = 0.93, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
CaRe30.classical <- pred.gp(DGPD.classical, p = 0.97,newdata = newx3,
n.sim = 250, prob.lev = 0.05)
# point estimates
CaRe7.classical$qp # threshold u to be added, if necessary
# Interval estimates
CaRe7.classical$CIqp
# Robust fit
#######################################################
DGPD.rob.rc <- 5.7
DGPD.robust <- gamlss(form.DGPD, margin = "DGPII", robust = TRUE,
rc = DGPD.rob.rc, data = DGPD.data)
conv.check(DGPD.robust)
# check tuning constant, m1 should be around, e.g., 0.95
# If not, refit with another rc value
rob.const(DGPD.robust)$m1
summary(DGPD.robust)
plot(DGPD.robust, eq = 2, all.terms = TRUE, pages = 1)
DGPD.rAIC <- rIC(DGPD.robust)$rAIC
# CaRe (and CIs) computation as a function of x3 (grid on its range)
# (The other covariates are fixed to their mean values)
# p = c(0.86, 0.93, 0.97) for horizon h = (7, 14, 30) days
5

#####################################################################
DGPD.CaRe7.robust <- pred.gp(DGPD.robust, p = 0.86, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
DGPD.CaRe14.robust <- pred.gp(DGPD.robust, p = 0.93, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
DGPD.CaRe30.robust <- pred.gp(DGPD.robust, p = 0.97, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
# point estimates (h = 7)
DGPD.CaRe7.robust$qp # threshold u to be added, if necessary
# Interval estimates (h = 7)
DGPD.CaRe7.robust$CIqp

###############################################################################
# GPD (continuous case)
###############################################################################
set.seed(2256)
GPD.alpha <- -2
GPD.beta <- c(1, -0.5, -0.5, -0.1)
GPD.eta1 <- matrix(rep(GPD.alpha, n.size), ncol = 1)
GPD.eta2 <- Xmat%*%GPD.beta
yy <- r.resp(margin = "GPII", n.size, eta1 = GPD.eta1, eta2 = GPD.eta2)
GPD.data <- data.frame(y = yy, X = XX)
form.GPD <- list(y ~ 1, ~ x1 + x2 + x3)
# Classical fit
############################################################
GPD.classical <- gamlss(form.GPD, margin = "GPII", data = GPD.data)
conv.check(GPD.classical)
post.check(GPD.classical)
summary(GPD.classical)
plot(GPD.classical, eq = 2, all.terms = TRUE, pages = 1)
GPD.AIC <- AIC(GPD.classical)
# CaRe (and CIs) computation as a function of x3 (grid on its range)
# (The other covariates are fixed to their mean values)
# p = c(0.86, 0.93, 0.97) for horizon h = (7, 14, 30) days
#####################################################################
GPD.CaRe7.classical <- pred.gp(GPD.classical, p = 0.86, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
6

GPD.CaRe14.classical <n.sim = 250, prob.lev =
GPD.CaRe30.classical <n.sim = 250, prob.lev =

pred.gp(GPD.classical, p = 0.93, newdata = newx3,
0.05)
pred.gp(GPD.classical, p = 0.97, newdata = newx3,
0.05)

# point estimates
GPD.CaRe7.classical$qp # threshold u to be added, if necessary
# Interval estimates
GPD.CaRe7.classical$CIqp
# Robust fit
#######################################################
# robustness tuning constant
GPD.rob.rc <- 6
# integral bounds
bound <- rob.int(GPD.classical, rc = GPD.rob.rc, var.range = c(1e-5,1000))
lB <- bound[[1]]
uB <- ceiling(bound[[2]])
GPD.robust <- gamlss(form.GPD, margin = "GPII", robust = TRUE, rc = GPD.rob.rc,
lB = lB, uB = uB, data = GPD.data)
conv.check(GPD.robust)
# check tuning constant, m1 should be around, e.g., 0.95
# If not, refit with another rc value
rob.const(GPD.robust)$m1
summary(GPD.robust)
plot(GPD.robust, eq = 2, all.terms = TRUE, pages = 1)
GPD.rAIC <- rIC(GPD.robust)$rAIC

# CaRe (and CIs) computation as a function of x3 (grid on its range)
# (The other covariates are fixed to their mean values)
# p = c(0.86, 0.93, 0.97) for horizon h = (7, 14, 30) days
#####################################################################
GPD.CaRe7.robust <- pred.gp(GPD.robust, p = 0.86,newdata = newx3,
n.sim = 250, prob.lev = 0.05)
GPD.CaRe14.robust <- pred.gp(GPD.robust, p = 0.93, newdata = newx3,
n.sim = 250, prob.lev = 0.05)
GPD.CaRe30.robust <- pred.gp(GPD.robust, p = 0.97, newdata = newx3,
n.sim = 250, prob.lev = 0.05)

7

# Point estimates
GPD.CaRe7.robust$qp # threshold u to be added, if necessary
# Interval estimates
GPD.CaRe7.robust$CIqp # threshold u to be added, if necessary

C

Models graphical results

0.5
−0.5
−1.5
−2.5

−1.5

−0.5

Partial for radiationL3

0.5

radiationL3

−2.5

Partial for mintempL3

mintempL3

−10

−5

0

5

10

15

0

mintempL3

50

100 150 200 250 300
radiationL3

0.5
−0.5
−1.5
−2.5

Partial for precipitationL3

precipitationL3

0

20

40

60

80

100

precipitationL3

Figure S1: Covariate effects on the scale parameter σ of the D-GPD for positive cases,
and 95% intervals.

8

0

50 100

−0.5 0.0
−1.5

−0.5 0.0

Partial for precipitationL3

precipitationL3

−1.5

Partial for radiationL3

radiationL3

200

0

radiationL3

20

40

60

80

precipitationL3

Figure S2: Covariate effects on the scale parameter σ of the D-GPD for negative cases,
and 95% intervals.

0.0
−0.5
−2.0

−1.5

−1.0

Partial for mintempL3

0.5

1.0

mintempL3

−10

−5

0

5

10

15

mintempL3

Figure S3: Covariate effect on the scale parameter σ of the GPD for odds of positive
cases, and 95% intervals.

9

CaRe_30 days

60

●●
●●●
●●●●
●●●●
●●●●
●●●●
●●●●
●●●●●
●●●●
●●●●●
●●●●●
●●●●●
●●●●●
●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●
●●●●●●●
●●●●●●●●
●

50

40

30
0

100

200

CaRe_14 days

50

●●●
●●●●●
●●●●●
●●●●●
●●●●●●
●●●●●
●●●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●●●
●●●●●●●●
●●●●●●●●
●●●●●●●●●
●●●●●●●●●
●●●

40

30

0

100

200

40

CaRe_7 days

●●●

35

●●●●●●
●●●●●●●
●●●●●●●●
●●●●●●●●
●●●●●●●●

30

●●●●●●●●●
●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●●

25

20

●●●●●●●●

0

100

200
RadiationL3

Figure S4: Negative cases: estimated CaRe for h = 30, 14, 7 days (panels from top to
bottom) with respect to lagged radiation. The bars correspond to 95% intervals. The
other covariates are fixed to their mean values.

10

CaRe_30 days

50

40

30

●●●●
●●●
●●●●
●●●●
●●●●
●●●●
●●●●●
●●●●
●●●●●
●●●●●
●●●●●
●●●●●●
●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●
●●●●●●●●
●

0

CaRe_14 days

40

30

20

20

40

60

80

●●●●
●●●●●
●●●●●
●●●●●
●●●●●●
●●●●●●
●●●●●●
●●●●●●●
●●●●●●
●●●●●●●●
●●●●●●●●
●●●●●●●●
●●●●●●●●●
●●●●●●●●●●
●●●●●●●

0

20

40

60

80

35
●●●●●●●

CaRe_7 days

●●●●●●●
●●●●●●●
●●●●●●●●

30

●●●●●●●●
●●●●●●●●●
●●●●●●●●●●
●●●●●●●●●●●
●●●●●●●●●●●

25

●●●●●●●●●●●●●
●●●●●●●●●

20
0

20

40
PrecipitationL3

60

80

Figure S5: Negative cases: estimated CaRe for h = 30, 14, 7 days (panels from top to
bottom) with respect to lagged precipitation. The bars correspond to 95% intervals. The
other covariates are fixed to their mean values.

11

CaRe_30 days

1.5

1.0

0.5

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●●
●●●
●●●
●●●
●●●
●●●●
●●●●
●●●●
●●●●●●
●●●●●●
●●●●●●
●●●●●●●●
●●●●

−10

−5

0

5

10

15

1.6

CaRe_14 days

1.2

0.8

0.4

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●●
●●●
●●●
●●●
●●●
●●●●
●●●●
●●●●
●●●●●●
●●●●●●
●●●●●●
●●●●●●●●
●●

−10

CaRe_7 days

1.0

0.5

−5

0

5

10

15

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●
●●●
●●●
●●●
●●●
●●●
●●●●
●●●●
●●●●
●●●●●●
●●●●●●
●●●●●●
●●●●●●●●
●●●

−10

−5

0

5

10

15

MintempL3

Figure S6: Odds of positive cases: estimated CaRe for h = 30, 14, 7 days (panels from top
to bottom) with respect to lagged minimum temperature. The bars correspond to 95%
intervals.

12

D

Additional simulations results for D-GPD
h=7
400

robust

0

100

200

300

400
200
100
0
1

0 3 6 9

13 17

0

3

6

9 12

16

400
200
100
0

2

4

6

8

0

2

4

6

8

0

2

0

2

4

6

0

2

4

6

0

0

400
300
200
100
0
400
300
200
100
0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

0

0

100

100

200

200

300

300

400

400

500

0

0

0

0

100

100

200

200

300

400
300

400
300

400
300
200
100
0
500
400
300
200
0

100

Q3(x2)

300

400
300
200
0

0

0

max(x2)

classical

500

1

500

0

mean(x2)

robust

100

200
0

100

min(x2)

300

400

classical

4

6

8

0 1 2 3 4 5 6

Figure S7: CaRe estimates for h = 7 for four values of x2 : its minimum value (first row),
its average (second row), its third quartile (third row) and its maximum (fourth row). The
other covariates are fixed at their mean values. The true population value is identified
by a darker bar. The first two columns correspond to the clean data setting, whereas the
last two columns correspond to the contaminated data setting.

13

h=7

6

10

4

6

8 10

150
100
0

50

100
50
2

0 2 4 6 8

11

14

0 2 4 6 8

11

14

400
200
0

100
0

100

200

300

400
300

400
200
100
0

0 5 11 18 25 32

0

6

13

21

29

37

0

8 17 27 37 47

400
300
200
100
0
0

7 15 24 33 42

0

0

400
300
200
100
0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

Q3(x3)

0
0

300

400
300
200
0

100

mean(x3)

8

500

4

robust

150

100 150 200 250
0

0

2

500

0

max(x3)

classical

50

100 150 200 250

robust

50

min(x3)

classical

0 25 55 85 119 157

0 33 72 116 166

Figure S8: CaRe estimates for h = 7 for four values of x3 : its minimum value (first row),
its average (second row), its third quartile (third row) and its maximum (fourth row). The
other covariates are fixed at their mean values. The true population value is identified
by a darker bar. The first two columns correspond to the clean data setting, whereas the
last two columns correspond to the contaminated data setting.

14

3

200
150
50
0
0

3

6

9

13

17

0

3

6

9 12

16

0

1

0

1

13

21

29

0

3

6

0

3

6

9 12

0

2

4

6

37

300
100
0

9

13

17

300
100
300
100

200

300
200
100
0
0 2 4 6 8

11

14

8 10

Figure S9: CaRe estimates for h = 14 for four values of x1 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

15

16

400

0
400

0

100

200

300
200

300
100
0
400
300
200
100
0

6

400

1

0

200

300
100
0
0

200

300
200
100
0
400
300
200
100
0

40

0

1

31

400

0

22

200

300
100
0
1

0 6 13

400

2

400
0

100

150
100
50
0
1

400

0

200

300
200
0

1

400

0

robust

200

100 150 200 250
3
400

2

100

mean(x1)
Q3(x1)

classical

0

0

1

400

0

max(x1)

robust

50

100 150 200 250

classical

50

min(x1)

h=14

h=14

200

200
1

2

50 100
0

50 100
0
0

0 5 11 18 25 32

0 4 8 13

19

25

400
300
200
0

100

100
0

0
0 2 4 6 8

11

14

0 2 4 6 8

11

14

0 2 4 6 8

11

400
300
200
100
0
0

2

4

6

8

11

0

0

400
300
200
100
0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

100

200

300

300

400

400

500

2

200

300
200
0

100

mean(x2)

400

500

1

0

Q3(x2)

robust

150
0

50

150
0

50

min(x2)

0

max(x2)

classical

250

robust

250

classical

0 2 4 6 8

11

0

2

4

6

8

Figure S10: CaRe estimates for h = 14 for four values of x2 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

16

10

h=14

12 15

3

6

9

12

16

80
40
20
0

20
0
0

robust

60

80
40

9

0

4

8

13 18 23

0 3 6 9

13

18

400
200
100
0 8

18 29 40 51

0 9 20 32 44 56
400
300
200
100
0

0 13 28 43 58 73

0 14 31 48 65 82

0

0

400
300
200
100
0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

0

0

100

100

200

200

300

300

400

400

500

0

0

0

0

100

100

200

200

300

400
300

400
300

400
300
200
100
0
500
400
300
200
0

100

Q3(x3)

60

150
50
0
6

0

max(x3)

classical

500

3

500

0

mean(x3)

robust

100

100
0

50

min(x3)

150

classical

0 41 89 144 206

0 54 126 207 288

Figure S11: CaRe estimates for h = 14 for four values of x3 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

17

4

150
100
50

0
0

1

2

3

4

5

0

50

100

150

100 150 200 250

3

robust

0 12 26 40 54 68

0 9 20 33 46 59

250
50

25

18

0

4

8 12

25

32

0

5 10 16 22 28

300
0

100

200

300
100

17

22

0 3 6 9

13 17

Figure S12: CaRe estimates for h = 30 for four values of x1 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

18

32

250
11

0

100
0

18

50
5

200

300
200

300
200
100
0

11

400

1

0
400

0

5

0

50
0

0 50
1

1

400
0

0

0

150

250
150

250
150

250
150
0 50

1

400

0

0 5 11 18 25 32
350

2

0

50
0
1

350

0
350

2

350

1

150

250
150

250
150
0

0

50

150

250

350

2

50

mean(x1)

0

Q3(x1)

classical

0

0

1

350

0

max(x1)

robust

50

100 150 200 250

classical

50

min(x1)

h=30

h=30

1

200
150
50
0
8

13 18 23

0

4

8 12

0

4

22

300
0

100

200

300
100
0

100

17

300
4

17

22

0 3 6 9

13

18

0

0

400
300
200
100
0

0

0

100

100

200

200

300

300

400

400

500

0

8 12

45

100
0

200

300
200

300
200
100
0
0

100

200

300

400

500

35

400

0

25

0

100
0
1
400

1

0

0 7 15

200

300
200

300
100
0
0

0 11 24 37 50 63
400

3

400

1

400

0

100

150
100
50
0
2

400

1

200

300
200
0

100

mean(x2)
Q3(x2)

0

400

2

robust

200

100 150 200 250
0

0

1

400

0

max(x2)

classical

50

100 150 200 250

robust

50

min(x2)

classical

0 3 6 9

13 17

0

3

6

9 12

Figure S13: CaRe estimates for h = 30 for four values of x2 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

19

16

classical

8 12

17

22

40
0

10

20

30

40
20
10
4

0

7 15 24 33 42

0 5 11 18 25 32
400
200
0

100
0

100

200

300

400
300

400
300
100
0

0 16 34 52 70 88

0 18 39 60 81 105
400
100

0

0

100

200

300
200

300
200
100
0

0 21 45 69 93 120

0 23 50 77 108 143

0

0

400
300
200
100
0

0

100

100

200

200

300

300

400

400

500

0

0

0

100

200

300

400

500

0

300

400

500

0

400

500
400
300
200
0

100

Q3(x3)

0

20
0
0

robust

500

18

200

300
200
0

100

mean(x3)

400

500

13

0

max(x3)

30

100
60

100
60
0

20

min(x3)

0 3 6 9

50

robust

50

classical

140

140

h=30

0 69 160 263 366

0 89 207 340 473

Figure S14: CaRe estimates for h = 30 for four values of x3 : its minimum value (first
row), its average (second row), its third quartile (third row) and its maximum (fourth
row). The other covariates are fixed at their mean values. The true population value is
identified by a darker bar. The first two columns correspond to the clean data setting,
whereas the last two columns correspond to the contaminated data setting.

20

