1

GraphXCOVID: Explainable Deep Graph
Diffusion Pseudo-Labelling for Identifying
COVID-19 on Chest X-rays

arXiv:2010.00378v2 [cs.LG] 4 Jul 2021

Angelica I. Aviles-Rivero, Philip Sellars, Carola-Bibiane Schönlieb and Nicolas Papadakis

Abstract—Can one learn to diagnosis COVID-19 under extreme minimal supervision? Since the outbreak of the novel
COVID-19 there has been a rush for developing Artificial Intelligence techniques for expert-level disease identification on Chest
X-ray data. In particular, the use of deep supervised learning has
become the go-to paradigm. However, the performance of such
models is heavily dependent on the availability of a large and
representative labelled dataset. The creation of which is a heavily
expensive and time consuming task, and especially imposes a
great challenge for a novel disease. Semi-supervised learning
has shown the ability to match the incredible performance of
supervised models whilst requiring a small fraction of the labelled
examples. This makes the semi supervised paradigm an attractive
option for identifying COVID-19. In this work, we introduce
a graph based deep semi-supervised framework for classifying
COVID-19 from chest X-rays. Our framework introduces an
optimisation model for graph diffusion that reinforces the natural
relation among the tiny labelled set and the vast unlabelled
data. We then connect the diffusion prediction output as pseudolabels that are used in an iterative scheme in a deep net. We
demonstrate, through our experiments, that our model is able
to outperform the current leading supervised model with a tiny
fraction of the labelled examples. Finally, we provide attention
maps to accommodate the radiologist’s mental model, better
fitting their perceptual and cognitive abilities. These visualisation
aims to assist the radiologist in judging whether the diagnostic
is correct or not, and in consequence to accelerate the decision.
Index Terms—COVID-19, Chest X-ray, Semi-Supervised
Learning, Deep Learning, Explainability

I. I NTRODUCTION
INCE the outbreak of the novel coranavirus disease 2019
(COVID-19), which is caused by severe acute respiratory
syndrome coronavirus 2 (SARS-CoV-2), there have been more
than 30 million confirmed infected cases and more than 1
million deaths has been reported worldwide (as on September
1st). This threat has encouraged joint efforts to obtain accurate
early detection of COVID-19 to try and limit the spread of the
pandemic.
Whilst real-time reverse transcription polymerase chain reaction (RT-PCR) COVID-19 test is the current gold standard
for diagnostis, this type of test has demonstrated several limits
and burdens. Firstly, it is prone to false negatives that heavily

S

AI Aviles-Rivero is with the Department of Pure Mathematics and Mathematical Statistics, University of Cambridge, UK. e-mail: ai323@cam.ac.uk.
P. Sellars and C.-B. Schönlieb are with Department of Applied Mathematics and Theoretical Physics, University of Cambridge, UK. e-mail:
{ps644,cbs31}@cam.ac.uk
N. Papadakis is with the Université de Bordeaux, IMB, Bordeaux INP, CNRS, UMR 5251. F 33-400, Talence, France. email:
nicolas.papadakis@math.u-bordeaux.fr

rely on the sample acquisition characteristics including insufficient quantities and location (nasal, throat or sputum) [1], [2].
Secondly, the limitation of several world regions in obtaining
fast accessibility to the test. The use of imaging techniques,
including computerised tomography and chest x-rays, has
been suggested as a parallel option to RT-PCR test. Clinical
manifestation of COVID-19 is that of a respiratory infection,
which is associated with viral pneumonia. Distinguishing viral
pneumonia from bacterial pneumonia is a challenging task.
This task becomes even harder when a large number of
suspected patients need to be screened. This time consuming
task strains already limited medical resources, thus reducing
the efficiency of the diagnostic.
Computerised tomography (CT) has been a focus of attention in the literature for COVID-19 e.g. [3], [4]. However, the
burden imposed in terms of infection control using CT scan
suites and the inefficiencies relating to room decontamination
and access restriction from several world regions make CT
challenging to be used as a routinely basis – despite its high
sensitivity [5]. Due to its wide availability and inexpensive
screening, a great focus has been placed on Chest X-rays
(CXR) for both clinical and AI areas e.g. [6]–[9]. These advantages make CXR a perfect alternative and complement to the
RT-PCR. Despite the CXRs advantages, accurate interpretation
still remains a challenge [10]. This is because the accuracy of
the interpretation relies on the radiologist’s expertise level and
there is still a substantial clinical error on the outcome [11].
Therefore, there is an urge for fast automated evaluations of
CXRs, to quickly explore the vast amount of data which will
save time in evaluating the diseases.
For the task of classifying COVID-19 using CXRs data,
there has been a fast development of deep learning techniques e.g. [12]–[16], in which supervised learning is the goto paradigm. However, the performance of these techniques
strongly rely on a large and representative corpus of labelled
data. In the medical domain and in particular with a new
disease, this might be a strong assumption in the design of
a solution, as it involves scarce annotations that might contain
strong human bias. The current leading supervised model for
COVID, COVID-Net [9], has reported promising results with
a sensitivity of 91% for COVID-19. Hence there is still plenty
of room for improvements, namely on how to use the vast
amount of available unlabelled data to prevent labelling errors
and uncertainties from affecting the classification output.
Motivated by the above limitations in current techniques, we
address the following problem – Can one get a robust classifier

2

with performance higher or comparable to the current leading
supervised technique for COVID-19 using far less labels? To
answer to this question we propose a deep semi-supervised
framework to go beyond human bias and the limited amount of
labelled data. We remark that many deep SSL techniques e.g.
[17]–[20], have only been considered for natural images. No
work has evaluated the performance outside this domain, by
considering the fundamental differences between natural and
medical images [21]. This paper extends our work in [22] with
noticeable differences. Firstly, we construct the graph based on
the initial embeddings coming from a deep net, making for an
accurate first construction. Secondly, we use our optimisation
diffusion model as means for generating pseudo-labels that
can be updated iteratively in a trained deep net. Moreover,
unlike the pseudo-label perspective of [23], our technique is a
graph based approach and the pseudo-labels are computed by
our diffusion model rather than the network. Our contributions
are as follows:
• We propose a deep semi-supervised framework, in which
we highlight:
– An optimisation model with strong class priors for
multi-class graph diffusion, which is based on normalised and non-smooth p = 1 Dirichlet energy. Our
method offers theoretical guarantees and efficient
solving.
– The connection of our diffusion model to the generation of meaningful pseudo-labels, which avoids
the current SSL trend on the use of consistency
regularisation.
We show that our framework reinforces the natural relation among the tiny labelled set and the vast unlabelled
data.
• We evaluate our technique with several numerical, statistical and visual results using an unified dataset that
contains highly diverse samples from different sources.
To the best of our knowledge, this is the first graph based
deep semi-supervised technique proposed for identifying
COVID-19. Moreover, we also report explainable results
from our prediction scores to assist and accelerate the
radiologist diagnosis.
• We demonstrate that our technique reports higher sensitivity in COVID-19 and global performance than the
current leading deep supervised technique for such application whilst requiring far less labelled data.
II. R ELATED W ORK
The recent problem of classifying CXRs for COVID-19 has
observed a fast growing in the literature. Existing techniques
are reviewed in this section.
A. Chest X-ray Classification for COVID-19
The task of classifying CXRs has been widely investigated
in the community. The go-to paradigm to address this problem
is deep learning [24], [25], [25], [26]. The fast development
of these techniques has been motivated by the release of
several benchmarking datasets including ChestXray14 [24]

and CheXpert [27], in which a large number of annotated
samples from different pathologies (classes) are contained in
each dataset. With new diseases such as COVID-19, where
the annotated data is limited, one needs to rethink the whole
design of the techniques. In this work, we motivate the power
of semi-supervised learning for COVID-19. In what follows,
we review related COVID-19 and SSL techniques.
The bulk of literature addressing the task of classifying
CXRs for COVID-19 is largely based on deep supervised
learning e.g. [9], [12]–[16], [28], and several techniques arise
every single day. Most of approaches apply pre-trained off-theshelf networks; in which diverse generic architectures, including ResNet [29], DenseNet [30] and VGG [31]. Existing works
thus leverage on fine tuned networks and networks trained
from scratch on CXRs data. However, there are fundamental
differences between natural and medical image classification
including features and data size. Hence, as shown in [21],
transfer learning might offer little benefit to performance due
to the over-parameterisation of standard models. Moreover, the
samples available for COVID-19 are scarse in comparison to
other type of pneumonia, and one needs to deal with highly
imbalanced datasets.
The key assumption of supervised techniques is a wellrepresentative labelled dataset, and in new diseases, such as
COVID-19, this core assumption is a strong one. Moreover,
the available annotations might be far from being a definite
expression of ground truth [32]. Therefore, by using deep
supervised learning techniques are prone to labelling error
and uncertainty that adversely affect the classification output.
Although transfer learning [33] and Generative Adversarial
Networks [34] mitigate, at some level, the lack of a large and
representative dataset, they weakly account for the mismatch
between expert annotation and ground truth annotation, which
is generated by human bias and uncertainty, and the performance can be limited due to the differences among datasets
as demonstrated in [21].
Motivated by the above-mentioned drawbacks in deep supervised learning and with the goal of generating a high
sensitivity technique that largely decrease the need for large
annotation set, we introduce a deep semi-supervised technique
for the application to COVID-19 identification, which to our
knowledge it is the first in its type. In the next subsection we
discuss recent techniques in deep SSL for other domains and
how they differ to ours.
B. Semi-Supervised Classification for Medical Images
Semi-supervised learning has been applied in the medical
domain since its early developments, in which model based
techniques have been the main focus of attention e.g. [35]–
[39]. These approaches have demonstrated the potential of
SSL- but the generalisation of the feature space along with
the computational requirements have raised limitations. Recently, with the advent of deep learning, deep semi-supervised
learning has been investigated.
In the past few years, there has been a silent revolution
in deep SSL techniques, e.g. [18]–[20], that have sought
to combine the theoretical underpinning of SSL [40] with

3

Pneumonia

Tiny Labelled Set
+ Unlabelled
Data
Labelled Sample
Class:2

Iterative Process

COVID-19

Optimise(2)

Output Samples

Construct
Graph using :

Feature
Extraction

FC+Softmax

Labelled Sample
Class: 0

Explainability
Output Sample:

Optimise (5)

Optimise (7)
Labelled Sample
Class: 1

Healthy

Fig. 1. Workflow of our proposed technique. We use a tiny labelled set and large unlabelled set. First our technique optimise over the labelled set using (2),
this seek to extract meaningful features to construct a strong graph. We then use our proposed diffusion model (5), which results in generated pseudo-labels
than then are iteratively optimised using (7). The output is the confidence score per class and the attention map.

the generalisation and feature extraction of deep neural networks. The largest trend for new deep SSL methods involves
consistency regularisation [17]–[20]. The core idea of this
perspective is to, for both labelled and unlabelled examples,
induce perturbations δ and then add a regularisation term to the
loss function such that the prediction of the model is invariant
to the perturbation, i.e. f (x + δ) = f (x). The main variety
between approaches stem from how to generate perturbations
δ. The definition of perturbations is indeed a complex problem,
and no work has ever evaluated the performance of consistency
based approaches outside the natural image domain.
To the best of our knowledge, there has been no deep
SSL approach proposed for COVID-19 analysis. The potential
performance of SSL has nevertheless been shown in our prior
work [22] on CXRs analysis. We readily competed with SOTA
supervised techniques for identification of several pathologies
in CXRs, using a small fraction of the available labels. In this
work, we extend this framework to build upon the concept of
pseudo-labels, first introduced in [23]. However, compared to
that initial work, there are now several key differences since a
graph based approach is considered and the pseudo-labels are
predicted from our diffusion model rather than the deep net.
III. G RAPH X-COVID F RAMEWORK
This section presents the three parts of our proposed technique: i) data representation and robust graph construction,
ii) optimisation model for graph diffusion and iii) driving
optimisation that connects our diffusion model with deep nets.
The overview of our GraphXCOVID is illustrated in Fig. 1.
Problem Definition. Given a small amount of labelled data
DL = {(xh , yh )}lh=1 with provided labels L = {1, .., L}
and yh ∈ L, and a large amount of unlabelled data Xu =
{xk }nm=l+1 . The whole set of data is thus X = XL ∪ XU ,
where XL = {x1 , ..., xl }. We seek to infer a function
f : X n 7→ Y n such that f gets a good estimate for {xk }nm=l+1
with minimum generalisation error.

In particular, in a deep semi-supervised setting, one seeks
to minimise a functional of the form:
labelled set

min
θ

z X
(x,y)∈DL

unlabelled set

}|
{
{
zX }|
LS (x, y; θ) + γ
LU (x; θ),

(1)

x∈Xu

where LS is the per example loss for the labelled set (e.g.
standard cross-entropy) and LU denotes a loss defined on the
unlabelled set (e.g. consistency loss). Moreover, γ ∈ R+ is a
weighting parameter to balance the two terms, and θ is the
network parameters to estimate.
The current go-to perspective in deep SSL is to apply
consistency regularisation for LU in (1), which enforces invariant network predictions with respect to perturbations on
the unlabelled data Xu , e.g. [17]–[20] However, the definition
of such δ-pertubations, e.g. flip-and-shift, rotate, posterise and
sharpness, is not trivial. In this work, we avoid the explicit
definition of such δ by taking a proxy-based perspective. In
particular, we rely on the concept of pseudo-labels [23] ŷi for
images of the unlabelled set xi ∈ Xu . In this work, the pseudolabels are generated by optimising our graph-based model. Our
framework is an iterative two-part technique, the first part concerns pseudo-label generation, including graph representation
(see Subsection A) and label diffusion (Subsection B). The
second step deals with the update of the generated pseudolabels (Subsection C).
A. Feature Extraction & Graph Construction
The most common data representation is a Euclidean or
grid-like structure. We rather define our data in a nonEuclidean domain with a graph. This framework offers different benefits including mathematical properties such as sparseness which allows for fast computation, and the ability to
correct initially mislabelled data by smoothing the embeddings. We represent the dataset X as a graph, where each
node is an image, to produce pseudo-labels. Then, unlike pure
model-based approaches or pure deep learning techniques, we

4

examples. For each image, our method also assigns a score
reflecting the uncertainty of the produced pseudo-label (see
subsection C). To do this, we first generate the pseudo-labels
through an optimisation model based on the normalised graph
p-Dirichlet energy expressed as:

Features Samples
Feature
Extraction

Features Samples

∆p (u) =

X

wij

i,j

Fig. 2. Visualisation of feature extracted from Chest X-ray data.

introduce a hybrid model – that is, a combination between a
model-based (energy model) and a deep learning framework.
A deep network fθ is considered for updating the pseudolabels generated by our optimisation model. It is initialised
from the tiny labelled set (x, y) ∼ DL by minimising:
LS (XL , YL ; θ) :=

l
X

`H (fθ (xh ), yh ),

(2)

h=1

where the loss function `H is cross entropy, which is the most
common choice for classification tasks. This optimisation process only involves the provided small labelled set to construct
the initial graph (i.e. it is run once as initialisation).
More precisely, a given set of data (or features) can be
represented as an undirected weighted graph by G = (V, E, W)
composed of n nodes V = {v1 , ..., vn }, which are connected
by edges E = {{vi , vj } : vi , vj ∈ V} with weights wij =
S(i, j) ≥ 0 that correspond to some similarity measure S
between the features of nodes i ∈ V and j ∈ V, and wij = 0
if (i, j) ∈
/ E. In our setting, a node vi represents an image
of the set xi ∈ X. A fundamental question when using graph
based approaches is how to effectively extract representative
features to construct a robust graph. In order to avoid the
sensitive task of hand-crafted feature selection, we rely on
embeddings automatically produced by (2). Hence we reduce
the potentially large generalisation error that appear when
extracting hand-crafted features on a small training set XL .
We consider as feature extractor the function ϕθ : X → RP ,
given by the bottleneck of the current network fθ , that maps
the input to some feature space of dimension P . To construct
our graph, we compute, for each sample, the set of descriptors
by ci = ϕθ (xi ) ∈ RP for xi ∈ X, and connections are created
through the k nearest neighbours (k-NN) approach in RP . An
illustration of extracted features is given in Fig. 2.
Notice that the model fθ and the feature extractor ϕθ are
updated (subsection C) through the exposition to pseudo-labels
of unlabelled data. The graph thus evolves along our process.
We now detail how pseudo-labels are obtained on the graph
by following a transductive strategy.
B. Label Diffusion as Pseudo-Labelling
Pseudo-labels are estimated through a diffusion process
on the whole graph containing both labeled and unlabelled

ui
1/p

uj

−

di

1/p

dj

p

, p ≥ 1, di =

X

wij > 0,

j

(3)
where the degree of the node i is denoted by di , and the
weights are computed from the descriptors described in previous section. The minimisation of this energy allows the
diffusion of a labelling variable u. Whilst techniques in this
line have been reported in the medical domain e.g. [36], [37],
[41] and in the pure machine learning community e.g. [42],
[43], they only seek to use eigenfunctions of a normalised
Dirichlet energy based on the graph Laplacian for p = 2 or
only approximate p → 1. However, latter machine learning
works [44] has demonstrated that using the non smooth p = 1
Dirichlet energy (related to total variation) achieves better
performance for label propagation.
With this motivation in mind, we introduce an optimisation
model based on the normalised and non smooth p = 1
Dirichlet energy. In the case p = 1, model (3) is thus defined
as ∆1 (u) = |W D−1 u|, where D is the diagonal matrix
containing the degrees di and the m × n matrix W encodes
the m edges in the graph. Each of these edges is represented
on a different line i of the matrix W , with the value wij (resp.
−wij ) on the column i (resp. j).
We now detail our multi-class model that will be applied to
L = 3 classes: 0: Healthy, 1: Pneumonia and 2: COVID-19.
For each class k = 1 · · · L, we set a variable uk that contains
the node values for class k and denote u = [u1 , · · · uL ]. For
unlabelled nodes
PL i k> l, we couple the L variables with the
constraint:
k=1 ui = 0, ∀i > l. We make the standard
assumption that there exists a non empty set of labelled nodes
Ik ⊂ {1 · · · l} for each class k. For these nodes, we set uki ≥ 
0
if i ∈ Ik (positive response for the class), and uki ≤ − if
i ∈ Ik and k 0 6= k (negative output for the other classes).
Under such constraints, we seek to minimise the multi-class
functional [45] that contains the sum of normalised ratios :
min

||u||=1

L
X
∆1 uk
k=1

|uk |

.

(4)

We consider an iterative scheme to optimise this problem:
u(t+1) = argmin
u

+

L 
X
k=1

ku − u(t) k2
2∆t

∆1 (uk ) −


∆1 (uk,(t) )
k,(t)
k
hsign(u
),
u
i
,
|uk,(t) |
(5)

where t is a time index associated to the step ∆t > 0. This
process diffuses information from labelled nodes to unlabelled
ones. To avoid trivial solutions [46], [47], we apply shifting
uk,(t+1) = uk,(t+1) − median(uk,(t+1) ) and normalisation
u(t+1) = u(t+1) /||u(t+1) || steps at the end of each iteration.

5

From (5), one can see that the solution uk,(t+1) satisfies:
L
X

∆1 (uk,(t+1) ) ≤

k=1

≤

L
X
∆1 (uk,(t) )
k=1
L
X

|uk,(t) |

hsign(uk,(t) ), uk,(t+1) i

∆1 (uk,(t) ) k,(t+1)
|u
|,
|uk,(t) |
k=1
(6)

so that we get a reduction of the normalised ratio
∆1 (uk,(t) )/|uk,(t) | along iterations k. When L = 1, the
scheme uk,(t) converges to a local minima of (4) which
corresponds to a bivalued function that naturally segments the
graph [47]. In the general case L > 1, the convergence to a
local minima of (4) can be ensured by using a modification of
the scheme (5) as proposed in [48]. However, such adaptation
comes at the cost of an important additional computational
cost. Even of there is no theoretical guarantee for that, we
observe a monotonous decrease of (4) with the scheme (5). As
a consequence, we suggest to use the flow (5) that presents an
acceptable trade-off between theoretical and practical aspects.
Once uk has converged to some u∗ = [u∗,1 , · · · , u∗,L ], the
label of each node is finally given by ybi = argmaxj u∗,j
i . In
practice, our model (5) is solved using an accelerated primal
dual algorithm [49]. Our generated pseudo-labels are denoted
YbU = {b
yk }nk=l+1 and used to update the classification network
fθ as explained in the next section.
We remark that there are several differences between our
pseudo-label approach and that of [22], [23]. Firstly and unlike [22], our work generates and updates the embeddings from
a deep net to construct, since the beginning, a stronger graph.
Secondly, our optimisation model generates pseudo-labels,
outside the deep net, and then they are iteratively updated
from a deep net. Thirdly, our current model is designed to
generate highly certain pseudo-labels since early stages by
integrating an uncertainty measure, and also is equipped with
a class balance term (see Section C). With respect to [23], our
model follows different principle when generating the pseudolabels. Firstly, unlike [23], our technique is a graph based
model. Secondly, [23] generates the pseudo-labels directly
from the deep net (i.e. inside the network) by taking maximum
predicted probability from the network. On the other hand, we
generate the pseudo-labels from our new optimisation model
(drawn from the normalised graph p-Dirichlet energy) which
is decoupled from the network (i.e. outside the network).
C. Deep Graph Pseudo-Labelling Update
Although our graph diffusion model (5) generates relevant
pseudo-labels [22], one can further decrease the uncertainty
over time. This can be achieved if we consider the two major
bottlenecks in real-world problems. A first prevalent issue in
the medical domain is to face highly imbalanced class samples.
As illustrated in Fig. 3, this is particularly true in the COVIDx
dataset. The second one is to deal with inferred pseudo-labels
with different levels of uncertainty. As it has been shown in
several works e.g. [50]–[53], these problems can be mitigated
by weighting the importance over the inferred pseudo-labels
and the classes.

The problem of classifying with a highly imbalanced dataset
has been widely studied in the literature, e.g. [50], [54]. We
apply a common strategy for imbalanced class population [50],
[55] and add a weighting factor inversely proportional to the
effective number of samples for class k : ωk ∝ 1/En , n ∈ Z>0
where En is the total number of samples. For the second problem, we associate an uncertainty weighing factor, υi , to each
uŷi generated in the diffusion process. We use entropy as the
measure for uncertainty, given by υi = 1 − (H(uŷi )/ log(L)),
where H refers to the entropy and uŷi is normalised beforehand with respect to the values in u∗i .
We finally define the main driving optimisation (i.e. estimation of network parameters) as:
min
θ

l
X

ωyi `H (fθ (xi ), yi ) +

i=1

n
X

υi ωybi `H (fθ (xi ), ybi ),

i=l+1

(7)
the loss in (7) is connected with model (1) but unlike the
typical consistency loss, for LU , we are using the philosophy
of pseudo-labels which are generated by our diffusion model.
Let us summarise the overall process. We first optimise (2)
for a set of epochs, this serves for extracting the embeddings
from the deep net to construct a graph. We then perform
(5) to diffuse the small labelled set to the unlabelled data.
The output of this process is the generation of pseudo-labels
for the unlabelled set. These pseudo-labels are then used to
optimise (7), which in turn updates the model parameters. The
whole process (feature extraction, graph update, pseudo label
diffusion, network update) is then iterated.
IV. E XPERIMENTAL R ESULTS
In this section, we detail the set of experiments conducted
to validate our technique.
A. Dataset Description
We evaluate our approach on the COVIDx Dataset which
was introduced in [9]. The dataset is composed of a total
of 15,254 CXR images. The official partition only considers
13,975 CXR images across 13,870 patients, with a training
set composed of 13,675 images and a test test of 300 (1579
for the test set on the full dataset). This dataset is, up to our
knowledge, the largest and most diverse one for COVID-19.
COVIDx indeed merges five different datasets repositories:
COVID-19 image data collection [8], Actualmed COVID-19
Chest X-ray Dataset Initiative [56], COVID-19 Chest X-ray
Dataset Initiative [57], RSNA Pneumonia Challenge dataset
[24], [58] and COVID-19 Radiography Database [59].
The COVIDx dataset contains three classes: Healthy, Pneumonia and COVID-19. The class breakdown, for the full and
official partition CXR images, is illustrated in Fig. 3. As it
can be observed from these plots, it is a highly imbalanced
dataset, in which COVID-19 samples are much smaller than
for the other other two classes.
Moreover, to further support the performance of our technique, we use an external dataset to evaluate the generalisation
to out-of-distribution samples. To do this, we use the external

Training (Total=13,675)
Test (Total=1579)

Pneumonia
Healthy
Number of Images

COVID-19

Training (Total=13,675)
Test (Total=300)

Pneumonia
Healthy
Number of Images

Fig. 3. Class distribution of COVIDx dataset. From top to bottom: samples/class distribution over the full COVIDx dataset and the official partition
from COVIDx. We conducted experiments in both sets. This dataset imposes
several challenges due to the highly imbalanced classes, in which COVID-19
samples are significantly less than the Pneumonia and Healthy classes.

dataset BIMCV-COVID19 [60] , which is composed of images
from 11 hospitals from the Valencian Region, Spain. We randomly selected a subset of 200 patient-level samples covering
all hospitals, where 75% were COVID-19 confirmed cases as
one is interested in show generalisation for the target disease.
B. Evaluation Methodology & Implementation Details
We validate our proposed technique as follows. First we
evaluate the performance of our approach compared to supervised techniques including the leading fully supervised paper
in the field COVID-Net [9]. These comparisons include VGG16 [31], ResNet-18 and ResNet-50 [29], InceptionV3 [61]
and DenseNet-121 [30]. The selection of these architectures
follows the same line of motivation as in [9]: they offer a
clear advantage for dealing with the unique traits of COVID.
Our experiments are then conducted using: i) the official
partition, in which the test set is 300 samples split evenly
across the classes; ii) the full COVIDx dataset, in which
the main differences with respect i) is that the test set is
composed of 1,579 samples (see Fig. 3); and iii) an additional
random partition. We ran all the experiments under the same
conditions, and followed standard pre-processing protocol to
normalise the images to have zero mean and unit variance.
The images we resized to the resolution 480×480.
The evaluation is addressed from both qualitative and quantitative points of view. The former is based on visual outputs of
our classification. The latter present the per class computation
of sensitivity, positive predictive value and F1-scores. The
overall performance is computed in terms of accuracy and
error rate. Furthermore, for sake of completeness and guided
by the field of estimation statistics, we report along with the
error rate the confidence intervals (95%) of all techniques.
Finally, we performed a data ablation study of our SSL method
by using 10%, 20% and 30% of labels.

Random Partition

COVID-19

GraphXCOVID
Covid-Net
ResNet-50
Pseudo-Label
ResNet-18
DenseNet-121
InceptionV3
Vgg-16
GraphXCOVID
Covid-Net
ResNet-50
Pseudo-Label
ResNet-18
DenseNet-121
InceptionV3
Vgg-16

Official Partition

Official COVIDx
Class Partition

Full COVIDx
Class Distribution

6

0

5

10

15

20

% Error Rate & 95%CI
Fig. 4. Error rates on the full dataset. Performance comparison error-wise
along with confidence intervals of the compared techniques and ours. Top
plot displays results from a random partition, while bottom plot corresponds
to the official partition. Our technique reported the lowest error rate (95%CI)
while using only 30% of labelled samples.

We now give implementation details. For the COVIDNet [9] technique, we used the implementation and parameters
provided by the authors. In particular, we considered the
latest suggested model COVIDNet-CXR3-B. For the compared
techniques, we used weight decay= 5e-4, momentum= 0.9
and learning rate 1e-2 (1e-3 for [23], and ResNet-18 for a
fair comparison). For our technique, the k-NN neighborhood
graph has been built with k = 50. A ResNet-18 architecture
has been used for the deep network fθ . In practice, we used
a total number of epochs of 210 with and a weight decay of
2 × 10−4 and learning rate was set to 5e-2 decreasing with
cosine annealing. Furthermore, we follow standard protocol in
semi-supervised learning to report our results, we randomly
select the labelled samples over five repeated times, that isone has five different splits. We then report the mean error
over the splits. All techniques were implemented in PyTorch
and using Stochastic Gradient Descent (SGD) as optimiser.
C. Results & Discussion
We begin by evaluating the different methods on the
official COVIDx partition. As a baseline comparison, we
consider six supervised techniques: VGG-16 [31], ResNet18 and ResNet-50 [29], InceptionV3 [61], DenseNet-121 [30]
and COVID-Net [9]. To the best of our knowledge, there
exists no semi-supervised technique dedicated to COVID19 identification that we can compare. Hence, for the sake
of fairness, we also adapted one semi-supervised technique,
Pseudo-Labelling [23], that has a philosophy close to ours but
builds on different principles including a minimum entropy
criterion. The supervised methods use the full training set,
whereas the SSL techniques only consider 30% of the labelled
set.

7

TABLE I
N UMERICAL COMPARISON OF OUR TECHNIQUE VS FULLY SUPERVISED APPROACHES . T HE RESULTS REPORT PER CLASS METRICS , INCLUDING
SENSITIVITY, POSITIVE PREDICTIVE VALUE AND F1- SCORES ALONG WITH THE OVERALL ACCURACY. O UR TECHNIQUE READILY COMPETES WITH ALL
SUPERVISED TECHNIQUES WHILST USING FAR LESS LABELLED DATA . † DENOTES THE SCORE REPORTED IN [9].

X

R ES N ET-18 [29]

X
X

P SEUDO -L ABELLING [23]

R ES N ET-50 [29]

X

I NCEPTION V3 [61]

X

D ENSE N ET-121 [30]

X

COVID-N ET [9]

X

G RAPH XCOVID

X

H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19
H EALTHY
P NEUMONIA
COVID-19

TABLE II
P ERFORMANCE COMPARISON OF COVID-N ET AND OUR TECHNIQUE
USING THE FULL DATASET.

COVID-Net
GraphXCOVID
COVID-Net
GraphXCOVID
COVID-Net
GraphXCOVID

H EALTHY
P NEUMONIA
COVID-19
P OSITIVE P REDICTIVE VALUE (PPV)
0.96
0.91
0.93
0.97
0.92
0.95
S ENSITIVITY
0.93
0.95
0.91
0.94
0.95
0.93
F1-S CORES
0.95
0.93
0.92
0.96
0.94
0.94

We provide a detailed quantitative analysis to understand
the performance of the different techniques. The per class
metrics across the official data partition are thus reported
in Table I. Concerning positive predictive values, we observe that our GraphXCOVID approach performs the best for
healthy and pneumonia classes and it readily competes with
COVID-Net in the COVID-19 class. Due to design limitations,
VGG-16 performed the worst, whereas ResNet-50 presents
performances closer to GraphXCOVID thanks to its residual
architecture. We also observe that excepting for the COVID-19
class, InceptionV3 and DenseNet-121 both sightly outperform
ResNet-50. In order to show the robustness of our technique,
we also considered the full COVIDx dataset, a scenario closer
to a real medical setting. We compared our method with
the supervised approach of COVID-Net, the second better
method on the official partition. As reported in Table II,
GraphXCOVID here performs better for all classes and all

P OSITIVE P REDICTIVE
VALUE (PPV)
0.83
0.76
0.88
0.84
0.85
0.90
0.90
0.88
0.84
0.88
0.87
0.95
0.93
0.90
0.92
0.92
0.90
0.93
0.90
0.91
0.98
0.93
0.96
0.95

Labelled Set

VGG-16 [31]

C LASS

S ENSITIVITY

F1-S CORES

0.95
0.89
0.60
0.91
0.90
0.79
0.90
0.85
0.86
0.97
0.91
0.82
0.91
0.92
0.88
0.94
0.93
0.88
0.95
0.94
0.91
0.92
0.96
0.94

0.88
0.82
0.71
0.87
0.87
0.84
0.90
0.87
0.84
0.92
0.89
0.88
0.92
0.91
0.90
0.93
0.91
0.90
0.93
0.93
0.95
0.98
0.92
0.95

ACCURACY
in 10−2
81.3

86.7

87.3

90.0
90.6†
91.0

91.7

93.3

94.6

GraphXCOVID

30%
20%
10%

0

Error Rate

L EARNING PARADIGM
SL
SSL

T ECHNIQUE

10

20

Error Rate & 95%CI

40

30

GraphXCOVID (30%)

20
0

0

60

120

#Epochs

180

Fig. 5. From top to bottom. Error rate comparison (95%CI) of our technique
using different label set counts. Error rate vs epochs (i.e iterative process
displayed at the center part of Fig. 1) using 30% of labels.

considered metrics, while only using 30% of the labelled set.
The second evaluation is done in terms of sensitivity. As
shown in tables I and II, GraphXCOVID reports the highest
values for pneumonia and COVID-19. For COVID-19, the
true positive proportion is significantly higher for our method
(0.94) and COVID-Net (0.91) than for other ones (≤0.88).
This observation is confirmed with the sensitivity results on
the highly imbalanced full dataset (see Table II).
To give a view of the relative performance of all techniques,
the F1-scores are respectively reported in Tables I and II for
the official and full partitions. It still underlines that VGG-16,

8

Healthy

Healthy
Pneumonia

COVID-19

Healthy

Ours
COVID-19

GT: COVID-19

Healthy
Pneumonia

Healthy

Ours
Pneumonia

GT: Pneumonia

Healthy

Ours
Pneumonia

GT: Pneumonia

Ours
COVID-19

GT: COVID-19

Pneumonia
COVID-19

Ours

Ours
Pneumonia
COVID-19

COVID-19

Healthy
Pneumonia

Ours
Healthy

GT: Healthy

COVID-19

Ours

GT: Healthy

Pneumonia
COVID-19

COVID-19

Healthy
Pneumonia

GT: COVID-19

COVID-19

Healthy

Ours
Healthy

Healthy
Pneumonia

Ours
Pneumonia
COVID-19

GT: Healthy

GT: Healthy

Pneumonia

GT: Pneumonia

COVID-19

Ours

Ours

Ours

COVID-19

GT: COVID-19

COVID-19

Healthy

GT: COVID-19

GT: COVID-19

Healthy
Pneumonia

Healthy

Ours
Pneumonia

GT: Pneumonia

Ours
COVID-19

GT: COVID-19

Healthy
Pneumonia

Ours
Pneumonia
COVID-19

GT: Healthy

Fig. 6. Visualisation of results: the probability score for each class and compared with the human diagnostic (GT). We see from the confidence measures,
that the model has clearly separated normal x-rays from injected x-rays as well as distinguished between pneumonia and COVID-19.

ResNet-50, DenseNet-121 and InceptionV3 are not sufficiently
competitive, whereas COVID-Net and our GraphXCOVID
technique are readily performing in a similar level. However,
looking deeper into the performance of these two last techniques, we observe that within a highly imbalanced scenario
(see Table II), our approach outperforms COVID-Net.
We also compare our technique to a SSL technique, with
similar philosophy than ours but different in design, PseudoLabelling [23]. This technique generates the pseudo-labels
directly from the network whilst our approach considers labels
coming from the diffusion model. From Table I, one can observe that G RAPH XCOVID offers a substantial improvement
over Pseudo-Labelling for all metrics. Overall, we achieve
better accuracy with an improvement of 8%, and reduce the
error rate (±1.20CI) by more than half as displayed in Fig
4. The improvement comes from two parts. The first major
benefit is related to pseudo-labels generation. The work of [23]
provides naive pseudo-labels with the network itself, while

our technique generates more certain ones that are iteratively
updated using both our diffusion models and the network,
along with a uncertainty weight. Secondly, our technique also
accounts for imbalanced class distribution.
To further support the previous results and give a global
performance view, we compute the error rate and the confidence intervals for each model. The results are reported in
Fig. 4 for the official and a random partition of this set. For
both experiments, VGG-16 reported the worst performance
followed by ResNet-18. Our model performed the best among
all the compared models, reporting an error of 5.4 ± 1.1 at the
95% confidence level. As for the other criteria, COVID-Net
ranked second, reporting an error of the model of 6.7±1.23 at
the 95% confidence level. One can also observe from the top
of Fig. 4 that supervised techniques are highly variable at the
change of partition. Such approaches are indeed heavily reliant
on the training set being well-representative and balance. In
comparison, the variation is negligible with our SSL approach.

9

Attention Levels
Abnormal

Normal

Attention Levels
Abnormal

Normal

Attention Levels
Abnormal

Normal

GT: COVID-19

GT: Healthy

GT: COVID-19

GT: Pneumonia

Ours: COVID-19

Ours: Healthy

Ours: COVID-19

Ours: Pneumonia

GT: Healthy

GT: COVID-19

GT: Pneumonia

GT: Healthy

Ours: Healthy

Ours: COVID-19

Ours: Pneumonia

Ours: Healthy

GT: COVID-19

GT: Pneumonia

GT: Healthy

GT: COVID-19

Ours: COVID-19

Ours: Pneumonia

Ours: Healthy

Ours: COVID-19

Fig. 7. Visualisation of the attention maps overlaid on the corresponding chest x-ray image. Our prediction output is also displayed (see bottom part of each
output sample) along with the ground truth (GT) which denotes the human consensus prediction (see top part of each output sample). The attention maps
highlight abnormal and normal regions to assist the radiologist in making decisions.

In order to analyse the robustness of our model, we run
an ablation study for different label counts. In Fig. 5 (top),
we present the error rates and confidence intervals obtained
by GraphXCOVID with 10%, 20% and 30% of the available
labels. Why do not increase the percentage of labels? First, we
want to use the lowest possible number of labels. Secondly, we
seek to keep the advantage of transductive inference. Indeed,
as pointed out in early works e.g. [62], the benefit of a
transductive model is decreased when a large number of labels
is considered. This effect was observed in our experiments. We
finally illustrate in Fig. 5 (bottom), the behaviour of our model
along iterations. Around 200 epochs were required to reach a
stable error rate when considering 30% of labels.
A visual illustration of the result is next provided in Fig. 6,
where the probability scores of our technique are reported and
compared with the human prediction (GT). One can see that
the obtained classifier fθ easily differentiate between classes.
However, the probability scores (from Fig. 6) are not enough to
assist the radiologist in making the decision. To accommodate
with this issue, we use a Gradient-weighted Class Activation
Mapping [63] type solution to highlight abnormal and normal
areas in the lungs, in which Pneumonia and COVID-19 are
linked to abnormally regions. Samples outputs of the attention
maps are displayed in Fig. 7 and compared with the human

prediction (GT). The attention maps aims to accommodate
with the mental model on how the radiologists work in a
clinical scenario. Therefore, we project the attention only in
the lungs areas. This tool is designed to help, in a friendly
user-interface, the radiologist judging whether the diagnostic
is correct or not, and in consequence to accelerate the decision.
Additionally in Fig. 8, we also display some misclassified
samples. The intuition behind these cases is as follows. Firstly,
the inherent complex appearance of the pathologies projected
in the chest X-ray imposes a challenge in the predictive
capability of the model. Secondly, the outcome is also effected
by the difference in acquisition protocol and vendor machines,
which introduce artifacts, blurry effects and noise in the chest
x-ray images. This is translated to a tail distribution problem
that affects the model’s capability to make predictions. However, we remark that the generalisation error is reduced with
the proposed pseudo-labelling and uncertainty mechanism. In
particular, we reported less missing cases of COVID than the
compared techniques (see the per class result in Tables I and
II), and our model globally performs better than the compared
techniques including when handling external data (see Fig. 12
along with the discussion).
Ablation Study. Finally and to further support the design
of our technique, we performed an ablation study regarding

10

Ours

Ours

Pneumonia
COVID-19

Healthy

GT: COVID-19

Ours
Healthy

Healthy

Pneumonia
COVID-19

Pneumonia

Healthy

GT: Pneumonia

COVID-19

COVID-19

Ours

GT: COVID-19

COVID-19

Ours

Pneumonia

GT: Healthy

Healthy

Healthy

GT: COVID-19

Healthy
Pneumonia

COVID-19

Healthy

Ours
Pneumonia
COVID-19

GT: Pneumonia

Ours

Pneumonia

GT: Pneumonia

Pneumonia

Ours

COVID-19

GT: Healthy

Uncertainty
Factor
# Images
# Images

Weighting
Factors

Fig. 8. Visual examples of incorrectly classified samples. The results display the predicted probability score and the comparison with the human diagnostic
(GT: ground truth).

Epoch 0

0

0

5
10
% Error Rate & 95%CI

0

0.5

1

0.5

1

Epoch 100

Fig. 9. (Left side) Ablation study on the influence of the weighting factors, υ and ω, in the performance of our model. The plot displays the error rate
(95%CI) using 30% of the labels. (Right side) Effect of the uncertainty mechanism in the pseudo-labels. Correct pseudo-labels are displayed in green and
incorrect ones in red.

the influence of the weighting factors, υ and ω, in our model.
We first report a performance comparison of our technique,
in terms of error rate and using 30% of labelled data, when
considering one, both and none of the two factors. The results
are reported at the left side of Fig. 9. We notice that removing
both factors (red bar) increases more than twice the error. In
contrast, we observe that a substantial decrease in the error
rate is achieved when considering both factors (blue bar). In
a closer look at the effect of each factor, we observed that
while both factors (green and orange bars) indeed improve the
performance, the factor with more influence is the uncertainty
mechanism (υ, see orange bar). We suggest that measuring
the uncertainty of the pseudo-labels prevents from obtaining
certain incorrect pseudo-labels in early training stages, that are
propagated in the next epochs. This effect is illustrated in the
right side of Fig. 9. In this illustration, we display υ for all
the unlabelled samples, and plots reflect the comparison of
the pseudo-label prediction with respect of the ground truth.

The red and green areas denote the incorrect and correct
pseudo-labels (wrt the ground truth). From this figure, we can
observe that the certainty in the pseudo-labels is improved as
the epochs evolve. This plot support the strength of υ in our
model.
Additionally, we performed another ablation study to evaluate the performance of our technique with different amounts
of labelled data data in the training set. This is illustrated
in Fig. 10. We observed that the results using 30% of the
labelled set is a good trade-off between number of labels
vs performance due to the transductivity behaviour. In line
with earlier works in transduction e.g. [62], [64], a significant
increase in performance is gained from an initial increase in
the labelled percentage, from 5% to 30%. After 30%, the
introduction of additional labelled data provides a tiny amount
of extra accuracy. This highlights the success of our approach
in its core aim, that is using semi-supervised learning to
alleviate the need for large labelled datasets for COVID X-

11

[5%]

Accuracy
0.95

[10%]

[60%]

0.70
0.50

MT
[20%]

[50%]

GraphXCOVID

[40%]

GCN
0

5

0.946

15
20
10
% Error Rate & 95%CI

[30%]

Fig. 10. Performance comparison of our technique under different percentage
of labelled data. The performance of the model increases with more labeled
data, but the increase in performance slows drastically past 30%.

Fig. 11. Performance comparison of our technique (with and without
including our weighting factors) against two deep SSL techniques GCN [65]
and MT [19]. The results are reported, using 30% of labelled data, in terms
of the error rate (95%)

COVID-19 Class

ray classification.
Moreover, we compared our technique (with and without
our weighting factors) against two recent deep SSL approaches: MT [65] and GCN [19]. We considered the same
label count of 30% and used the parameters suggested in these
works. The results are reported in Fig. 11. We observe that
our technique (with the weighing factors) performs the best.
MT competes readily with the basic version of our model, i.e.
without uncertainty and balance parameters. Finally, GCN was
clearly outperformed by all compared models. The intuition
behind our performance gain is three-fold. Firstly, our proposed optimisation model itself enforces the inherent relation
between the unlabelled and labelled data. Secondly, the generation of accurate pseudo-labels with uncertainty estimation
increases generalisation. Thirdly, our approach better deals
with imbalance datasets where the number of COVID images
makes up a tiny fraction of the data.
External Testing. As a final set of experiments, we test
the generalisation capability of our technique, and COVIDNet,
to external datasets by including a performance comparison
using the BIMCV-COVID19 [60] dataset (see Subsection 4.1.
for details on the experiment). The results are displayed in
Fig. 12 and show the error rate at the 95% confidence level.
From the plots, we can observe that COVIDNet exhibits a
substantial decrease in performance on the external dataset
whilst our technique is more robust in this regard. Particularly,
a strong degradation was observed in the COVID-19 class
(see left side plot in Fig. 12). This is an expected behaviour
of deep learning models, and is particularly noticed in the
medical domain e.g. [66], as one assumes that the testing set
should have similar distribution to the training set. Why is
our model more robust to external data? Our technique has
been carefully designed to mitigate, at some level, external
distributions. This is achieved by discarding irrelevant samples
with low confidence scores. More precisely, GraphXCOVID
controls the predictive uncertainty on the generated pseudolabels, which narrows the discrepancy between the external
distribution samples. Contrary, COVIDNet is not equipped
with any mechanism to accommodate with external distributions.

COVIDNet

Overall Performance
COVIDNet
GraphXCOV
ID

GraphXCOVID

0

10

0
20
% Error Rate & 95%CI

10

20

Fig. 12. Performance comparison of our technique and COVIDNet using the
BIMCV-COVID19 [60] dataset as a external set. Left side displays the error
rate for the COVID-19 class whilst the right side the overall performance of
both techniques.

From the aforementioned findings, we emphasise a central
message: the strong performance when using far less labelled
data than the compared techniques is a core strength of our
SSL technique. Moreover, we also underline the robustness of
our technique when handling external data. We highlight the
value of the vast available unlabelled data in medical domain,
and in particular the potentials and benefits for diagnostic
COVID-19 disease.
V. C ONCLUSION
In this work, we propose a graph-based deep semisupervised framework for classifying COVID-19 Chext X-ray
images based on an optimisation model for label diffusion.
Through the minimisation of a normalised and non-smooth
p = 1 Dirichlet energy, the model generates meaningful
pseudo-labels that are iteratively used to update a deep
net. To our knowledge, this is the first graph based deep
semi-supervised technique for COVID-19 analysis. From our
results, we demonstrated that our technique reports higher
sensitivity in COVID-19 and better global performances than
the current leading deep supervised technique, while requiring
a very reduced set of labels. We also provide attention maps
as means to visualise the output of our technique. These
visualisation aims to assist the radiologist in judging whether
the diagnosis is correct. With this work, we investigate the use
of deep semi-supervised learning for novel disease prediction,
as for COVID-19. Such approaches alleviate the need for a
large labelled dataset, which is costly and time consuming
to produce especially for emerging pandemic diseases where

12

both human and monetary resources are stretched thin. Future
work includes the exploration of other strategies to measure
the uncertainty, e.g. [67], and how this can be adapted to the
pseudo-labelling setting. Moreover, the transfer of our findings
in a more thorough experimental study to test its clinical
potential on a larger patient cohort.
ACKNOWLEDGMENTS
AIAR gratefully acknowledges support from CMIH and
CCIMI, University of Cambridge. PS is supported by EPSRC
and NPL. CBS acknowledges support from the Leverhulme
Trust project on ’Breaking the non-convexity barrier’, the
Philip Leverhulme Prize, the Royal Society Wolfson Fellowship, the EPSRC grants EP/S026045/1 and EP/T003553/1,
the EPSRC Centre EP/N014588/1, the Wellcome Innovator
Award RG98755, European Union Horizon 2020 research
and innovation programmes under the Marie Skodowska-Curie
grant agreement 777826 NoMADS and 691070 CHiPS, the
CCIMI and the Alan Turing Institute. AIAR and CBS also
thank the team of the project ’AI assisted diagnosis and
prognostication in Covid-19’ for very helpful discussions. NP
acknowledges H2020 RISE project NoMADS.
R EFERENCES
[1] X. Xie, Z. Zhong, W. Zhao, C. Zheng, F. Wang, and J. Liu, “Chest ct
for typical 2019-ncov pneumonia: relationship to negative rt-pcr testing,”
Radiology, p. 200343, 2020.
[2] P. Wikramaratna, R. S. Paton, M. Ghafari, and J. Lourenco, “Estimating
false-negative detection rate of sars-cov-2 by rt-pcr,” medRxiv, 2020.
[3] S. Zhou, Y. Wang, T. Zhu, and L. Xia, “Ct features of coronavirus disease
2019 (covid-19) pneumonia in 62 patients in wuhan, china,” American
Journal of Roentgenology, pp. 1–8, 2020.
[4] M. Chung and et al., “Ct imaging features of 2019 novel coronavirus
(2019-ncov),” Radiology, vol. 295, no. 1, pp. 202–207, 2020.
[5] Y. Fang and et al., “Sensitivity of chest ct for covid-19: comparison to
rt-pcr,” Radiology, p. 200432, 2020.
[6] A. Jacobi, M. Chung, A. Bernheim, and C. Eber, “Portable chest xray in coronavirus disease-19 (covid-19): A pictorial review,” Clinical
Imaging, 2020.
[7] H. Y. F. Wong and et al., “Frequency and distribution of chest radiographic findings in covid-19 positive patients,” Radiology, p. 201160,
2020.
[8] J. P. Cohen, P. Morrison, and L. Dao, “Covid-19 image data collection,”
arXiv preprint arXiv:2003.11597, 2020.
[9] L. Wang and A. Wong, “Covid-net: A tailored deep convolutional neural
network design for detection of covid19 cases from chest radiography
images,” [Online] Available: https://arxiv.org/abs/2003.09871, 2020.
[10] L. R. Folio, Chest imaging: an algorithmic approach to learning.
Springer Science & Business Media, 2012.
[11] M. A. Bruno, E. A. Walker, and H. H. Abujudeh, “Understanding and
confronting our mistakes: the epidemiology of error in radiology and
strategies for error reduction,” Radiographics, pp. 1668–1676, 2015.
[12] A. Narin, C. Kaya, and Z. Pamuk, “Automatic detection of coronavirus
disease (covid-19) using x-ray images and deep convolutional neural
networks,” arXiv preprint arXiv:2003.10849, 2020.
[13] I. D. Apostolopoulos, S. I. Aznaouridis, and M. A. Tzani, “Extracting
possibly representative covid-19 biomarkers from x-ray images with
deep learning approach and image data related to pulmonary diseases,”
Journal of Medical and Biological Engineering, p. 1, 2020.
[14] M. Farooq and A. Hafeez, “Covid-resnet: A deep learning framework for screening of covid19 from radiographs,” arXiv preprint
arXiv:2003.14395, 2020.
[15] E. E.-D. Hemdan, M. A. Shouman, and M. E. Karar, “Covidx-net: A
framework of deep learning classifiers to diagnose covid-19 in x-ray
images,” arXiv preprint arXiv:2003.11055, 2020.
[16] P. Afshar, S. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis,
and A. Mohammadi, “Covid-caps: A capsule network-based framework
for identification of covid-19 cases from x-ray images,” arXiv preprint
arXiv:2004.02696, 2020.

[17] S. Laine and T. Aila, “Temporal ensembling for semi-supervised learning,” International Conference on Learning Representations, 2016.
[18] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, and C. A.
Raffel, “Mixmatch: A holistic approach to semisupervised learning,” in
In Advances in Neural Information Processing Systems, 2019.
[19] A. Tarvainen and H. Valpola, “Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep
learning results,” in Advances in neural information processing systems
(NIPS), 2017, pp. 1195–1204.
[20] V. Verma, A. Lamb, J. Kannala, Y. Bengio, and D. Lopez-Paz, “Interpolation consistency training for semi-supervised learning,” International
Joint Conference on Artificial Intelligence (IJCAI), 2019.
[21] M. Raghu, C. Zhang, J. Kleinberg, and S. Bengio, “Transfusion:
Understanding transfer learning for medical imaging,” in Advances in
Neural Information Processing Systems, 2019, pp. 3342–3352.
[22] A. I. Aviles-Rivero and et al., “Graphx-net - chest x-ray classification
under extreme minimal supervision,” in International Conference on
Medical Image Computing and Computer-Assisted Intervention, 2019,
pp. 504–512.
[23] D.-H. Lee, “Pseudo-label: The simple and efficient semi-supervised
learning method for deep neural networks,” in Workshop on Challenges
in Representation Learning, ICML, vol. 3, 2013, p. 2.
[24] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers,
“Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on
weakly-supervised classification and localization of common thorax
diseases,” in IEEE Conference on Computer Vision and Pattern Recognition, 2017, pp. 2097–2106.
[25] L. Yao, J. Prosky, E. Poblenz, B. Covington, and K. Lyman, “Weakly supervised medical diagnosis and localization from multiple resolutions,”
arXiv preprint arXiv:1803.07703, 2018.
[26] I. Baltruschat, H. Nickisch, M. Grass, T. Knopp, and A. Saalbach,
“Comparison of deep learning approaches for multi-label chest x-ray
classification,” Scientific reports, pp. 1–10, 2019.
[27] J. Irvin and et al., “Chexpert: A large chest radiograph dataset with
uncertainty labels and expert comparison,” in Proceedings of the AAAI
Conference on Artificial Intelligence, 2019.
[28] J. Zhang, Y. Xie, Y. Li, C. Shen, and Y. Xia, “Covid-19 screening on
chest x-ray images using deep learning based anomaly detection,” arXiv
preprint arXiv:2003.12338, 2020.
[29] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[30] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in IEEE conference on Computer
Vision and Pattern Recognition (CVPR), 2017.
[31] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” in International Conference on Learning
Representations, 2015.
[32] M. D. Kohli, R. M. Summers, and J. R. Geis, “Medical image data
and datasets in the era of machine learning—whitepaper from the 2016
c-mimi meeting dataset session,” Journal of digital imaging, 2017.
[33] Y. Bar, I. Diamant, L. Wolf, S. Lieberman, E. Konen, and H. Greenspan,
“Chest pathology detection using deep learning with non-medical training,” in International Symposium on Biomedical Imaging, 2015, pp.
294–297.
[34] E. Moradi and et al., “Machine learning framework for early mri-based
alzheimer’s conversion prediction in mci subjects,” Neuroimage, vol.
104, pp. 398–412, 2015.
[35] R. Filipovych, C. Davatzikos, A. D. N. Initiative et al., “Semi-supervised
pattern classification of medical images: application to mild cognitive
impairment (mci),” NeuroImage, vol. 55, no. 3, pp. 1109–1119, 2011.
[36] H. Chen and et al., “Inferring group-wise consistent multimodal brain
networks via multi-view spectral clustering,” IEEE Transactions on
Medical Imaging (TMI), pp. 1576–1586, 2013.
[37] L. Dodero, A. Gozzi, A. Liska, V. Murino, and D. Sona, “Groupwise functional community detection through joint laplacian diagonalization,” in International Conference on Medical Image Computing and
Computer-Assisted Intervention, 2014, pp. 708–715.
[38] L. An, E. Adeli, M. Liu, J. Zhang, and D. Shen, “Semi-supervised hierarchical multimodal feature and sample selection for alzheimer’s disease
diagnosis,” in International Conference on Medical Image Computing
and Computer-Assisted Intervention, 2016, pp. 79–87.
[39] W. Sun, T.-L. B. Tseng, J. Zhang, and W. Qian, “Computerized
breast cancer analysis system using three stage semi-supervised learning
method,” Computer methods and programs in biomedicine, 2016.
[40] O. Chapelle, B. Scholkopf, and A. Zien, “Semi-supervised learning,”
IEEE Transactions on Neural Networks, vol. 20, no. 3, 2009.

13

[41] Z. Wang and et al., “Progressive graph-based transductive learning for
multi-modal classification of brain disorder disease,” in International
Conference on Medical Image Computing and Computer-Assisted Intervention, 2016, pp. 291–299.
[42] M. Belkin and P. Niyogi, “Laplacian eigenmaps for dimensionality
reduction and data representation,” Neural Computation, 2003.
[43] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Schölkopf, “Learning
with local and global consistency,” in Advances in Neural Information
Processing Systems (NIPS), 2004, pp. 321–328.
[44] T. Bühler and M. Hein, “Spectral clustering based on the graph plaplacian,” International Conference on Machine Learning, 2009.
[45] X. Bresson, T. Laurent, D. Uminsky, and J. Von Brecht, “Multiclass
total variation clustering,” in Advances in Neural Information Processing
Systems, 2013.
[46] M. Hein, S. Setzer, L. Jost, and S. S. Rangapuram, “The total variation
on hypergraphs-learning on hypergraphs revisited,” in Advances in
Neural Information Processing Systems, 2013, pp. 2427–2435.
[47] T. M. Feld, J.-F. Aujol, G. Gilboa, and N. Papadakis, “Rayleigh quotient minimization for absolutely one-homogeneous functionals.” Inverse
Problems, 2019.
[48] S. S. Rangapuram, P. K. Mudrakarta, and M. Hein, “Tight continuous
relaxation of the balanced k-cut problem,” in Advances in Neural
Information Processing Systems (NIPS), 2014, pp. 3131–3139.
[49] A. Chambolle and T. Pock, “A first-order primal-dual algorithm for
convex problems with applications to imaging,” Journal of mathematical
imaging and vision, 2011.
[50] H. He and Y. Ma, Imbalanced learning: foundations, algorithms, and
applications. John Wiley & Sons, 2013.
[51] W. Shi, Y. Gong, C. Ding, Z. MaXiaoyu Tao, and N. Zheng, “Transductive semi-supervised deep learning using min-max features,” in European
Conference on Computer Vision (ECCV), 2018, pp. 299–315.
[52] A. Iscen, G. Tolias, Y. Avrithis, and O. Chum, “Label propagation for
deep semi-supervised learning,” in IEEE Conference on Computer Vision
and Pattern Recognition, 2019, pp. 5070–5079.
[53] P. Sellars, A. Aviles-Rivero, and C. B. Schönlieb, “Two cycle learning:
Clustering based regularisation for deep semi-supervised classification,”
arXiv preprint arXiv:2001.05317, 2020.
[54] M. Kukar, I. Kononenko et al., “Cost-sensitive learning with neural
networks,” in Proceedings of the 13th European Conference on Artificial
Intelligence, vol. 98, 1998, pp. 445–449.
[55] A. Fernandez, S. Garcı́a, M. Galar, R. C. Prati, B. Krawczyk, and
F. Herrera, Learning from Imbalanced Data Sets. Springer, 2018.
[56] L. Wang and et al., “Actualmed covid-19 chest x-ray dataset
initiative,”
[Online]
Available:
https:// github.com/ agchung/
Actualmed-COVID-chestxray-dataset, 2020.
[57] ——, “Figure 1 covid-19 chest x-ray dataset initiative,” [Online]: https:
// github.com/ agchung/ Figure1-COVID-chestxray-dataset, 2020.
[58] RSNA, “The radiological society of north america,” [Online]: https:
// www.kaggle.com/ c/ rsna-pneumonia-detection-challenge/ data, 2019.
[59] M. Chowdhury and et al., “Covid-19 radiography database,”
[Online]
Available:
https:// www.kaggle.com/ tawsifurrahman/
covid19-radiography-database, 2020.
[60] M. De La Iglesia Vayá, J. M. Saborit, J. A. Montell, A. Pertusa, A. Bustos, M. Cazorla, J. Galant, X. Barber, D. Orozco-Beltrán, F. Garcı́aGarcı́a et al., “Bimcv covid-19+: a large annotated dataset of rx and ct
images from covid-19 patients,” arXiv preprint arXiv:2006.01174, 2020.
[61] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking
the inception architecture for computer vision,” in IEEE conference on
computer vision and pattern recognition, 2016, pp. 2818–2826.
[62] T. Joachims, “Transductive inference for text classification using support
vector machines,” in Icml, vol. 99, 1999, pp. 200–209.
[63] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and
D. Batra, “Grad-cam: Visual explanations from deep networks via
gradient-based localization,” in Proceedings of the IEEE international
conference on computer vision, 2017, pp. 618–626.
[64] V. Vapnik and V. Vapnik, “Statistical learning theory 156–160,” 1998.
[65] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
convolutional networks,” arXiv preprint arXiv:1609.02907, 2016.
[66] X. Wang, G. Liang, Y. Zhang, H. Blanton, Z. Bessinger, and N. Jacobs,
“Inconsistent performance of deep learning models on mammogram
classification,” Journal of the American College of Radiology, vol. 17,
no. 6, pp. 796–803, 2020.
[67] M. Abdar, F. Pourpanah, S. Hussain, D. Rezazadegan, L. Liu,
M. Ghavamzadeh, P. Fieguth, X. Cao, A. Khosravi, U. R. Acharya et al.,
“A review of uncertainty quantification in deep learning: Techniques,
applications and challenges,” Information Fusion, 2021.

