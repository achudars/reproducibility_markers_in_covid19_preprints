Markovian And Non-Markovian Processes with Active Decision
Making Strategies For Addressing The COVID-19 Pandemic

arXiv:2008.00375v2 [stat.AP] 5 Aug 2020

Hamid Eftekhari, Debarghya Mukherjee,
Moulinath Banerjee and Ya’acov Ritov
August 6, 2020

Abstract
We study and predict the evolution of Covid-19 in six US states from the period May
1 through August 31 using a discrete compartment-based model and prescribe active
intervention policies, like lockdowns, on the basis of minimizing a loss function, within
the broad framework of partially observed Markov decision processes. For each state,
Covid-19 data for 40 days (starting from May 1 for two northern states and June 1
for four southern states) are analyzed to estimate the transition probabilities between
compartments and other parameters associated with the evolution of the epidemic.These
quantities are then used to predict the course of the epidemic in the given state for the
next 50 days (test period) under various policy allocations, leading to different values
of the loss function over the training horizon. The optimal policy allocation is the one
corresponding to the smallest loss. Our analysis shows that none of the six states need
lockdowns over the test period, though the ‘no lockdown’ prescription is to be interpreted
with caution: responsible mask use and social distancing of course need to be continued.
The caveats involved in modeling epidemic propagation of this sort are discussed at
length. A sketch of a non-Markovian formulation of Covid-19 propagation (and more
general epidemic propagation) is presented as an attractive avenue for future research in
this area.

1

Introduction

The Coronavirus COVID-19 pandemic is one of the gravest global public health crises that the
world has seen in the past100 years, with echoes of the Spanish Flu of the early 20’th century.
A highly contagious respiratory virus, it triggers problematic immune responses in enough
individuals, especially among those with certain co-morbidities and the elderly, while also
1

ravaging the lungs and other vital organs. Governments have had to force extensive lockdowns
all over the world in a bid to control its rampant spread, engendering in the process, a massive
economic downturn, the long term effects of which are largely unpredictable as of even date.
This combination of a medical and fiscal crisis has brought forth an unprecedented response
from several sections of society, almost on a war-like footing, with medical professionals at the
helm, along with epidemiologists, economists, and last but not least data scientists bringing
their combined expertise together to grapple with this threat, e.g. [35], [9], [24], [24], [25],
[33] (and references therein) to name a few.
This paper aims to address the temporal evolution of epidemic diseases in a population,
paying attention to realistic features of the COVID epidemic, in conjunction with an active
[i.e. in real time] decision making strategy depending on the observables of the epidemic
process. We model the flow of the epidemic using an SEIRD (Susceptible-Exposed-InfectedRecovered-Deceased) model, which is an extension of the traditional SIR model with two
additional compartments, Exposed and Deceased, and the Infected compartment is split into
two sub-compartments: mildly infected and severely infected. Instead of analyzing a continuous time evolution via differential equations, we confine ourselves to a discrete time Markovian
process, taking the point of view that days are a natural unit of measurement. We note that
Markov processes have a long history in the study of infectious diseases, started by the work
of Kermack and McKendrick [19, 20, 21] and more recent works [4, 5, 40]. Furthermore,
dynamic policies for the control of Markov decision processes have also been studied in some
detail [39],[31], [32], [15], [11], [22].
We say that a compartment B is accessible from another compartment A (write A → B)
if it is possible to move from A to B directly without hitting other compartments. For
example, if we denote by S the compartment of susceptible people and by E the compartment
of latent/exposed people then it is immediate that S → E, but S 9 R where R is the
compartment of recovered people, as a person cannot go to the recovery compartment directly
from the susceptible one without hitting E: see figure 1 for a detailed diagram of flow. We
assume that at each time point, an individual has two options: either stay in the same
compartment as they were in at the previous time, or move to another reachable compartment.
The probability of transition to the next state is universal in the sense that it does not
depend on the individuals but may depend on the previous state. This mechanism generates
a Markov process on the number of individuals in each compartment. Some core features of
our proposed Markovian model to be elaborated on in Section 2 are:
(a) Allowing distinction between mild and severe infections and the subsequent evolution
of such individuals in time.
(b) Explicit incorporation of an observed process generated from a partially observed parent
2

process via a simple testing based mechanism.
(c) Active decision-making strategies based on the history of the epidemic.
(d) Optimizing decision making strategies in terms of an expected loss/reward function
that measures the trade-off between the economic costs of lockdowns and the cost of
lost lives or costs due to treatment denial. Clarification and detailed analysis of each
of these aspects are provided in Section 2.
We also present some ideas about a non-Markovian process that models each individual separately allowing their personal characteristics to determine their evolution, as a potential
recipe for future studies. The non-Markovian model captures spatial heterogeneity by allowing the transition probability from susceptible to latent to depend on the distance between
individuals. Section 3 deals with such details. Section 4 concludes with a discussion of various
possible directions for future research.

2

Markovian Model

Our first, and more parsimonious approach, is related to the paradigm of Partially Observed
Markov Decision Processes (henceforth POMDP) which have been used extensively in monitoring processes evolving over a state space with active intervention and decision making
strategies (see [31], [32], [15], [11], [22] and references therein).

2.1

Model structure

Consider the following model for an epidemic: S denotes the class of susceptibles, L denotes
latent individuals who are infected but cannot infect others as yet, Im comprises the (mildly)
infected, Is the severely ill, R those that have recovered and D the deceased from the disease.
The transition chain is from S via L to Im and from Im either to R or to Is and from Is either
to R or D. A susceptible person only gets infected upon contact with an infected person, but
not through a latent individual. Define N as the total number of people in a fixed location
which will be assumed to stay constant over the time horizon. The state space for this Markov
process is X = N6 , where a generic element of X should be thought as a vector of numbers
of individuals in each compartment. The true numbers in the different compartments are
driven by an underlying (hidden, henceforth to be referred to as population) Markov process
which is not observed directly . We only observe (random or deterministic) fractions of these
numbers, which gives rise to the observed Markov process. Write the population Markov
process as {Xt ∈ N6 }t=1,...,T over a finite horizon of time, where Xt,j denotes the number
of individuals in compartment j ∈ {S, L, Im , Is , R, D} at time t. We denote the observed
3

R

S

L

Im

Is

D
Figure 1: Flow of the Markovian process: S ← Susceptible, L ← Latent/Exposed, Im ←
Mildly infected, Is ←Severely infected, D ← Deceased, R ← Recovered. An individual can
move from compartment A to compartment B if A → B.
Markov Process as XtO described next: On each day, we observe a cohort of mildly infected
people and a cohort of severely ill individuals via testing. The former are typically asked
to quarantine at home and self-treat, while the latter require immediate medical assistance
and are hospitalized subject to capacity constraints. Furthermore, we record a fraction of
recovered and deceased people, who are documented. The number of individuals that showed
up for testing and tested negative [and can be taken to belong to the S ∪ L group] are not
tracked. We assume therefore that we have a partially observed process: XtO ∈ N4 where
O}
XtO = {Xt,j
j∈Im ,Is ,R,D . We take our action space to be A = {0, 1, 2} where 0 indicates no
lockdown, 1 indicates partial lockdown, i.e. some essential businesses and organizations stay
open and 2 denotes a full lockdown, where only the most essential activities are sustained.
Before proceeding further, let us articulate our convention about compartment numbers:
any compartment number at a given time t is taken to be the total count recorded by the end
of day t, thus the number in a compartment at (the end of) day t + 1 is given by the number
at day t plus movement into and out of the compartment in day t + 1 where the parameters
for such movements are either time invariant or depend upon the numbers recorded (at the
end of) day t. The action at (which is 0, 1 or 2) is proposed at the end of day t and affects
the infection dynamics from day t + 1 onwards: at = 0 corresponds to ‘no lockdown’ which
we interpret broadly to mean that most activities are in place though people are practicing
generally responsible behavior by and large, while at = 1 means ‘mild lockdown’ where a
substantial number of activities are closed, and at = 2 means ‘severe lockdown’ where most
activities have been restricted and human contact is minimal . Policy (decision) making, i.e.
4

which action to take at what time, is based on the numbers for the observed process via an
optimization scheme based on a reward.

2.2

Population process and transition probabilities

The transition probability from the Susceptible to the Latent state on day t + 1 is given by


at
Im →Is
Im →R Xt (Im )
S→L
+P
)
Pat ,t+1 = 1 − exp −R0 (P
.
N
where

R0at




R

 0
= R0 + r1



R0 + r2

if at = 2
if at = 1
if at = 0,

with R0 denoting the basic reproductive number under severe lockdown and r1 < r2 . The
basic reproduction number during any fixed lockdown phase is the average number of persons
that an infected person transmits in that phase over the course of their illness when the
proportion of susceptibles is near 1, i.e. the epidemic is in a controlled phase. Even though
the early estimates of the basic reproductive number (under no lockdown) were between
2.43 to 3.10 [13], we assume that over our period of analysis [May 2020 onwards by which
time the epidemic had spread considerably at least in the northern US states] the value of
Rat remains smaller than 2 due to increased awareness in society. Specifically, we assume
that after reopening, the value of Rat is 1.8 under no lockdown, while it assumes the values
1.3 and 0.8 respectively (drops of 0.5) under the first and second levels of lockdown.1 The
probabilties P Im →Is and P Im →R are the chance of transiting from the Im state to states Is
and R respectively on day t and are not taken to depend on t. The mathematical derivation
of this formula is given in Section 5.
For the other transition probabilities, we assume that on any given day, an individual
moves from L to Im with probability P L→Im . Similarly an individual in Im will either move
to Is (w.p. P Im →Is ), or to R (w.p. P Im →R ) or stay in Im (w.p. 1 − P Im →Is − P Im →R ). For
an individual in Is , they can go to R (w.p. P Is →R ), or to D (w.p. P Is →D ) or stay in Is (w.p.
1 − P Is →R − PtIs →D ). The transition probability from Is to D depends on time t through the
number of severely ill people in that location. If this exceeds the medical capacity, a severely
ill person cannot be accommodated and the subsequent lack of medical care will affect the
1

Estimating the effect of lockdowns on the basic reproductive number (r1 and r2 ) is difficult given the
available data, so we set r1 = 0.5 and r2 = 1 for our analysis. In principle, one can also estimate these
parameters if more data is available.

5

prognosis of illness, leading to a higher probability of death. Specifically, we use a simple
dichotomous form:
Is →D
Pt+1
= P1Is →D 1(Xt,Is ≤ cap) + P2Is →D 1(Xt,Is > cap) ,

where cap is hospitalization capacity at the location, and P2Is →D is generally taken to be a
multiple of P1Is →D (which we took to be 3 in our implementation) for our presented analysis.
The other two compartments R and D are terminal compartments, i.e. if a person is in one
of these compartments, their status changes no further. The transition process from Xt to
Xt+1 under action at can be summarized via the following mechanism:
1. Generate the random variables Y1 , Y2 , Y3 , Y4 , Y5 , Y6 as (henceforth Bin and Mult are
abbreviations of Binomial and Multinomial respectively):
Y1 ∼ Bin Xt,S , PaS→L
t ,t+1



Y2 ∼ Bin Xt,L , P L→Im



(Y3 , Y4 ) ∼ M ult Xt,Im , P Im →Is , P Im →R


Is →D
(Y5 , Y6 ) ∼ M ult Xt,Is , P Is →R , Pt+1



2. Update the state:
Xt+1,S = Xt,S − Y1 ,
Xt+1,L = Xt,L + Y1 − Y2 ,
Xt+1,Im = Xt,Im + Y2 − Y3 − Y4 ,
Xt+1,Is = Xt,Is + Y3 − Y5 − Y6 ,
Xt+1,R = Xt,R + Y4 + Y5 ,
Xt+1,D = Xt,D + Y6 .

2.3

Observed process and parameter estimation

The observed process denoted by XtO is driven by two mechanisms: First, the observed
compartments themselves follow the same transitions as the population process, and second, at each point in time there is a flow from the population process to the observed: a
number of individuals are tested and added to the observed compartments. Note that an
0
0 ) will enter into
individual in Xt,Im but not in Xt,I
(respectively in Xt,Is but not in Xt,I
m
s
6

O
O
Xt+1,I
(respectively into Xt+1,I
) if they are tested positive. We assume that the number
m
s
of individuals that test positive on day t + 1 and are mildly infected (e.g. do not require
O
immediate medical attention) follows a binomial distribution with parameters Xt,Im − Xt,I
m
test,mild
and Pt+1 (presents for testing | mildly infected), henceforth denoted by Pt+1
. Similarly
the number of individuals that test positive on day t + 1 and are severely infected (e.g. need
O
immediate medical attention) follows a binomial distribution with parameters Xt,Is − Xt,I
s
test,severe
and Pt+1 (presents for testing | severely infected), henceforth denoted by Pt+1
. The
process evolution can be summarized as follows:

1. Generate the following random variables:

O
(ZIm →Is , ZIm →R ) ∼ M ult Xt,I
, P Im →Is , P Im →R
m


Is →D
O
Is →R
,
P
,
P
(ZIs →R , ZIs →D ) ∼ M ult Xt,I
t+1
s


test,mild
O
Tm (t + 1) ∼ Bin Xt,Im − Xt,I
,
P
t+1
m


test,severe
O
Ts (t + 1) ∼ Bin Xt,Is − Xt,I
,
P
t+1
s

2. Then update the observed process as:
O
O
Xt+1,I
= Xt,I
− ZIm →Is − ZIm →R + Tm (t + 1),
m
m
O
O
Xt+1,I
= Xt,I
− ZIs →R − ZIs →D + ZIm →Is + Ts (t + 1)
s
s
O
O
Xt+1,R
= Xt,R
+ ZIm →R + ZIs →R
O
O
Xt+1,D
= Xt,D
+ ZIs →D .

In order to simulate such a process over a time horizon t = 1, . . . , T , we need four sets of
quantities:
1. The numbers in the compartments of the population process at day 1.
2. The numbers in the compartments of the observed process at day 1.
3. Vector of transition probabilities between the compartments.
4. Testing probabilities i.e. Pttest,mild , Pttest,severe .
We will discuss points 1 and 2 later, but briefly speaking, we set them based on real data and
some inflation factor (viewing the population process as an inflated version of the observed
7

process). So, assume for the moment that we have X1 and X1O . Coming to points 3 and 4,
we estimate the parameters (both transition probabilities and testing probabilities) jointly,
based on the real data. To sketch the idea, we essentially use a co-ordinate descent approach,
i.e. we update the transition probability vector and testing probabilities iteratively. Given
an initial vector of transition probabilities, P0 , one can generate the population process
over the training period as described in Section 2.2. Now, as far as the observed process is
concerned, note that we cannot generate Tm , Ts as we don’t know the testing probabilities
yet. An intuitive and effective way is to replace them by the real data on daily new cases,
appropriately divided into mild and severe compartments: say at day t, we see T̂m = new
mild cases and T̂s = new severe cases. Starting from Day 1, and using {(T̂m (t), T̂s (t))} we
can generate a version of the observed process, say X̂tO over the training period via steps (1)
and (2) displayed above in this section [obviously ignoring the last two lines of (1)]. Next,
the testing probabilities are estimated via the maximum likelihood principle as the ratio of
observed mild cases and observed severe cases to the number of unobserved mild and severe
cases respectively, since the denominators can be recovered from the infected numbers for the
hidden and observed processes.
Given these testing probabilities one can simulate the observed process Xt0 for any transition probability vector P via steps (1) and (2) above, and determine the one which emulates
the real process the best, i.e. minimizes a loss function measuring the discrepancy between
Xt0 and the real data process. We now set the value of this minimizer to P 0 and repeat the two
updating steps. We keep on updating both parameters over a fixed number of iterations and
choose our final estimate as the one corresponding to that iteration which gives the smallest
minimum loss over all iterations. The following algorithm summarizes this discussion:
Algorithm 1: Joint Estimation of Transition and Test Probabilities
Input: Initial estimate of transition probabilities P̂init and the number of iterations
K ;
Set P̂ (0) = P̂init ;
for k = 1, . . . , K do
test,mild(k)

Given P̂ (k−1) , obtain estimate of test probabilities Pt
using Algorithm 2.
test,mild(k)

test,severe(k)

test,severe(k)

and Pt

Using Pt
and Pt
, obtain the updated transition probabilities
(k)
P̂
by minimizing the loss in Equation (2.1) and let loss(k) be the value of this
minimized loss.
end
Set kmin = argmink loss(k) .
test,mild(kmin )
test,severe(kmin )
Return P̂ ≡ P̂ (kmin ) and Pt
and Pt
.

8

We next describe each part of the iterative update procedure in detail. We start with the
method of obtaining estimates of Pttest,mild and Ptsevere,mild given a set of values P for the
transition probabilities. Given T (t) new cases on day t based on real data [14], we set
T̂m (t) = pm T and T̂s (t) = ps T
where ps is the proportion of severe cases and pm ≡ 1 − ps the proportion of mild cases.
Exact values for these proportions are presented in Section 2.6 where we do a state by state
analysis. The generation of the process X̂t0 incorporating real data is described next:
1. Generate the random variables Y1O , Y2O , Y3O , Y4O as:
O
(Y1O , Y2O ) ∼ M ult Xt,I
, P Im →Is , P Im →R
m


(Y3O , Y4O ) ∼ M ult Xt,Is , P Is →R , PtIs →D



2. Update the state:
0
O
X̂t+1,I
= X̂t,I
− Y1O − Y2O + T̂m (t + 1),
m
m
O
O
X̂t+1,I
= X̂t,I
+ Y1O − Y3O − Y4O + T̂s (t + 1),
s
s
O
O
X̂t+1,R
= X̂t,R
+ Y2O + Y3O ,
O
O
X̂t+1,D
= X̂t,D
+ Y4O .

The processes {Xt } and {X̂tO } are simulated for T days where T is the time length of the
training period [taken to be 40 days] and the testing probabilites calculated as the proportion

9

of daily new cases to unobserved cases, as in the below algorithm.
Algorithm 2: Calculating testing probabilities
Input: Start with the data on daily new cases for T consecutive days and estimates
of transition probabilities between compartments;
Set T̂m (t) = T (t) ∗ pm ;
Set T̂s (t) = T (t) ∗ ps ;
Generate the processes Xt and X̂tO for days 2 through T with initial values for X1 and
X̂1O ;
while 2 ≤ t ≤ T do
Set Pttest,mild =

T̂m (t)
O
Xt−1,Im −X̂t−1,I
m

;

T̂s (t)
O
Xt−1,Is −X̂t−1,I
s

;

Set Pttest,severe =

Update t ← t + 1.
end
The initialization of the two processes as well as the elicitation of the initial transition
probabilities will be discussed later. Observe that the above algorithm gives us testing probabilities for days 2 through T . Note that, testing probabilities on day 1 are not required as
we are not generating data on day 1, we are fixing it based on real data.
We next estimate the parameters P = (P L→Im , P Im →R , P Im →Is , P Is →R , P1Is →D ) (the
inter-compartment transition probabilites) of the epidemic propagation2 . This is based on a
discrepancy calculation: For days 1 through T , we have real data available on the number
of infected as well as the number of epidemic related deaths in the location of interest. Note
that the first is not a cumulative quantity, while the second is. This provides our real observed
real
real ) for 1 ≤ t ≤ T . On the other hand, for any parameter vector P ,
data process: (Xt,active
, Xt,D
we can generate the population process Xt from 1 through T , and also the observed process
XtO using the testing probabilities just determined.
The process X O should be differentiated from the process X̂ O from the previous section,
as there is no real data directly involved in the former’s construction. The goal of generating
this new process is to obtain the infected and deceased numbers at each time t and then
compare them to the corresponding numbers for the real observed process. The parameter
vector that minimizes the average discrepancy between
n
oT
 O
T
real
real
O
(Xt,active
, Xt,D
)
and (Xt,active
, Xt,D
) t=1
is our

estimate.3

Note that

O
Xt,active

=

t=1
O
Xt,I
m

O .
+ Xt,I
s

2

Note that the probability of transition from S to L at any given time is known once these probabilities
and the action status a are known.
3
We deliberately leave recovery compartment from the parameter estimation procedure due to lack of real

10

More specifically, we first obtain the smoothed daily numbers of deaths as follows. Since
O is the cumulative number of deaths up to time t, the 7-day moving average of daily
Xt,D
deaths is obtained via
Dtsmooth obs.

t+3
O
O
Xt+3,D
− Xt−4,D
1 X O
O
Xs,D − Xs−1,D =
.
=
7
7
s=t−3

real −
Similarly, the smoothed daily number of deaths is obtained via Dtsmoothed real = (Xt+3,D
real )/7.
Xt−4,D

The following loss is now optimized over a grid of parameter values:

!2 
2
T  smooth obs
O
O
X
Xt,Im + Xt,Is
Dt
−1 +
− 1 ,
L(R0 , P, ϕ) = E 
smooth
real
real
D
X
t
t,active
t=1

(2.1)

where P = (P L→Im , P Im →R , P Im →Is , P Is →R , P1Is →D ) denotes the vector of transition probabilities and ϕ (taken to be 10 [38]) is an inflation factor that is used to generate the initial
unobserved states from the initial observed real data. That is, for the observed process, we
set the initial states by
O
O
real
X̂1,I
= X1,I
= pS · X1,active
s
s
O
O
real
X̂1,I
= X1,I
= (1 − pS ) · X1,active
m
m
O
O
real
X̂1,D
= X1,D
= X1,D
O
O
real
X̂1,R
= X1,R
= X1,R
,

where pS is the proportion of severe infections among the active cases. For the population
process, the initial states are set to
O
X1,j = ϕ · X̂1,j

for j ∈ {Im , Is , R, D},

X1,L = 0.5 · X1,Im .
Finally, we note that the reason we used ratios instead of differences in the loss is that the
numbers in different compartments have different orders of magnitude. For example, the
number of infected cases is much larger than the number of deaths. The expectation in the
above loss function is computed empirically by taking the average of the loss function over
several runs of the processes.
Initial Estimates. Referring back to Algorithm 1, note that we need P̂init : initial estimates of the inter-compartmental probabilities to start the algorithm. These estimates were
data on recovery for some of the states that we analyzed. With more data one can incorporate this in the
procedure to obtain a better fit.

11

obtained by matching certain features of the process with the available data. For example,
since the time to transition from state L to state Im is geometric with probability P L→Im , its
expected value will be 1/PL→Im . On the other hand, from studies on the incubation period
of the disease[23], we known that the average time from latent to mildly infected is 5 days.
L→Im
Thus, we obtain the initial estimate P̂init
= 0.2. Similar calculations for other transition
probabilities yield:

2.4

Im →Is
P̂init
= 0.017,

Im →R
P̂init
= 0.024

Is →R
P̂init
= 0.012,

Is →D
P̂1,init
= 0.009.

Prediction and Policy Optimization

Extrapolating beyond day T (prediction): Given the parameter estimates obtained in
the last section, we can now project into the future and optimize the lockdown strategy based
on these projections. This is of critical importance as it can serve as a principled guide for
real world policy makers. Consider running the population process for T̃ days from day 1
(where T̃ > T ) for forecasting purposes. We can extrapolate the testing probability for the
additional T̃ − T days in terms of the testing probabilities obtained for the first T days via
the following rule: if there is no trend in the testing rates over the first T days one can use
the average, whereas if there is a monotone trend, one can use the value at time T .
Note that for the training period 1 ≤ t ≤ T , the actions are known and fixed, as they are
dictated by real-world measures taken during this period, and therefore the policy optimization only takes place during the test period T + 1 ≤ t ≤ T̃ .
Policies and actions. POMDP models are difficult to optimize in full generality, and as
our model has several compartments, and will be run with reasonably large populations, the
problem of finding the globally optimal policy via maximizing a value function is essentially
computationally intractable. Hence, we confine ourselves to the class of so-called bang-bang
policies (see [6], [3], [17], [34] and references therein)– impose or lift lockdowns. These are
relatively easy to optimize over and allow us to avoid formal belief update methods. In
our implementations, these policies can be parametrized by three thresholds, henceforth
denoted by l, u1 and u2 , and a parameter θ ∈ [0, 1] that produces a linear combination
O + (1 − θ) · X O )/N that is compared to the three thresholds. Specifically, at
w = (θ · Xt,I
t,Is
m
each time t where t is divisible by 14,
• if w ≥ u2 , the highest level of lockdown is enforced for the next 14 days (at0 = 2 for
t ≤ t0 ≤ t + 13),
• if u1 ≤ w < u2 , a lower level of lockdown is enforced (at0 = 1 for t ≤ t0 ≤ t + 13),
12

• if w ≤ l, then all lockdown is released (at0 = 0 for t ≤ t0 ≤ t + 13),
• if none of the above holds, i.e. l < w < u1 , then the status quo is maintained for the
next fourteen days (at0 = at−1 for for t ≤ t0 ≤ t + 13).
We denote this class of policies by ΠB = {(l, u1 , u2 , θ) : 0 < l < u1 < u2 < 1 and 0 ≤ θ ≤ 1}.
Given the policy class, we next explain how to quantify the costs associated with a particular
policy.
Immediate reward function and Policies: In order to quantify the various costs
related to the epidemic and the actions taken, we propose the following immediate (daily)
reward function given a fixed policy (that is, given the thresholds l, u1 , u2 , θ). Given that at
the end of day t we are at state Xt and propose action at [which depends on the threshold
parameters as explained above], the immediate reward function [observed at end of day t + 1
under policy at ] is given by:
a 
t
CE + ρCL (Xt+1,Is − cap)+ ,
−rXt ,Xt+1 ,at (l, u1 , u2 , θ) = CL (Xt+1,D − Xt,D ) +
2
where CE is the daily economic cost of lockdown for each particular state obtained via scaling
the cost for the US according to GDPs:
CE (state) =

GDP of state
· (Daily cost of lockdown for the US in $million).
GDP of United States

(See Table 1 and Section 2.6 for the numeric values of these quantities). CL is cost of
life, the loss incurred due to the death of an individual (see Section 2.6). The factor ρ < 1 is
introduced to account for the loss due to treatment denial once hospital capacity (taken to
be 40% of hospital beds in the state [7]) is exceeded: we take this to be a quarter of the life
cost. We then optimize over l, u1 , u2 , θ [via grid-search] by maximizing the expected sum of
the immediate reward functions over the time horizon of interest:
(l? , u?1 , u?2 , θ? ) = argmax

T̃
−1
X

l,u1 ,u2 ,θ t=T

E[rXt ,Xt+1 ,at (l, u1 , u2 , θ)],

with the expectation computed by averaging over several runs of the process. We reiterate
that in the definition of rXt ,Xt+1 ,at , the action at depends on the policy parameters l, u1 , u2 , θ,
and Xt itself depends on the actions taken in the history of the process. Note that since the
action at assumes a value of 2 under full lockdown, in the reward function we divide the
action by 2 so that the economic cost under full lockdown is CE and under partial lockdown
CE /2.

13

For concreteness, we present the policy optimization procedure in Algorithm 3. In practice
we replace the class of policies ΠB by a discretized version Πd .
Algorithm 3: Finding Optimal Policies
Input: Fitted parameters P̂ , The class of policies Πd , Number of replicates J ;
for (l, u1 , u2 , θ) ∈ Πd do
for j = 1, . . . , J do
Run the population process X(t) for days 1 through T̃ with estimated
parameters P̂ and policy (l, u1 , u2 , θ) to compute
P
R(j) (l, u1 , u2 , θ) = T̃t=T +1 rXt ,Xt+1 ,at (l, u1 , u2 , θ) ;
end
P
Approximate the expected reward by R̄(l, u1 , u2 , θ)) = J −1 Jj=1 R(j) (l, u1 , u2 , θ) ;
end
Find the optimal policy (l? , u?1 , u?2 , θ? ) = argmax(l,u1 ,u2 ,θ)∈Πd R̄(l, u1 , u2 , θ));
Output: Return (l? , u?1 , u?2 , θ? ).

2.5

Sensitivity analysis

Once the optimal policy for a given location has been determined till time T̃ one can plot
the evolution of the mean curve of the population process from days T + 1 through T̃ under
the optimal policy for any compartment of interest (e.g. deaths or infected), with compartment probabilities given by the least squares estimates P̂ . We next discuss quantifying the
sensitivity around such a mean curve. There are two sources of uncertainty: (1) Variability
in the process given a fixed set of parameters for its evolution, and (2) Error in estimating
the parameters. We combine these two sources of variation to generate a prediction band.
Towards that end, we perturb the estimated parameters by adding some noise to the log-odds
of these probabilities and transforming back to the original scale. However we do not change
the optimal policy: we run the population process using this noisy version of the optimal transition probabilities over a certain time horizon (T̃ − T = 50 days) multiple times, starting
from the end of the training period and obtain the mean curve, which takes care of the first
source of variation. We then repeat this experiment multiple times with different sets of noisy
parameters which accounts for the second source of variation. Finally, we calculate upper
and lower 5th percentiles of the mean curves thus produced (for each time t) to generate the
sensitivity band. Our algorithm can be summarized as follows:

14

Algorithm 4: Getting the uncertainty band
Input: The estimated parameters P̂ , The (simulated) state of epidemic XT at the
end of training period, generated under P̂ ;
Outer loop iterations: Set number of outer loop iterations = O ;
Inner loop iterations: Set number of inner loop iterations = I;
Initialization: Set the variables x = y = 1;
Set `j = log(P̂j /(1 − P̂j )) for j = 1, . . . , 5.;
while x ≤ O do
Generate `˜j ∼ N (µ = `j , σ = `j /3) for j = 1, . . . , 5;
Set P̂jnow = (1 + exp(−`˜j ))−1 ;
while y ≤ I do
Generate the population process using P̂ now starting at XT and keeping the
threshold parameters (determining the actions) at their optimized values.
end
Store the mean curve of the output curves from the inner loop.
end
Quantile selection: For each day, select the 5% and 95% percentile value of the O
many mean curves;
Upper band: The curve traced out by the O many 95% quantiles ;
Lower curve: The curve traced out by the O many 5% quantiles.
The perturbations are in the log-odds scale to avoid boundary issues involving the intercompartment probabilities, as many of them are small numbers. The choice of a standard
deviation for the noise of the same order as the mean but smaller than it allows exploration
of parameters that are on the same scale as P̂ , but not too far from it.

2.6

Statewise Numerical Analysis

In this section we provide detailed analysis of six states: Michigan (MI), New Jersey (NJ),
Florida (FL), Arizona (AZ), Texas (TX) and California (CA). For each state, optimal values
of the inter-compartmental transition probabilities were obtained by analyzing data from its
training period. Given these estimates from the respective training periods, policy optimization was accomplished as described in Section 2.4. Recall from subsection 2.4, that we need
both the cost of lockdown CE and the cost of life CL to obtain the optimal policy. These
were calculated in the following way:
1. For CE , we started with a suggested $7 trillion per year for the United States [10], that
15

State

Econ. cost

Medical capacity [7]

(Per day in millions)

(No. of beds for Covid patients)

AZ

341.8

6537

CA

2928

34242

FL

978.6

24208

MI

484.7

11320

NJ

577.1

10398

TX

1761

30784

Table 1: Economic cost of lockdown and medical capacity. The number of available hospital
beds for Covid patients at each state is taken to be 40% of all available beds [7].
is, roughly $20 billion per day for all the states combined. Then we scaled this number
by the fraction of the GDP of each state to the US GDP to obtain the economic cost
(under lockdown) to the GDP for the state of interest. These numbers are displayed in
the second column of Table 1.
2. For the cost of life CL we use [12], where $4.7 million is given as value of statistical life
year (VSLY) and a lower value of $1.5 million is obtained as the equal-value life year
gained (see [12, Figure 2] for a comparison of these estimates). We ran our simulation
under both these costs.
The six states were divided into two broad categories: northern states (MI, NJ) and southern
states (TX, AZ, CA and FL). For each of the states, we trained using real data from 40 days,
then predicted the process for the next 50 days (thus, a total 90 days starting from the start
of the training period). For northern states our training data starts from May 1 and for the
southern states from June 1, the reason for this discrepancy being the recent surge of covid
cases in the southern states, which renders the data from May less informative for prediction
purposes at this time. We present MI, TX and FL in the main body of the paper and the
remaining three states in the supplement.
For each of three states (MI, FL, TX) we present three pictures: One for the time-varying
policy, i.e. lockdown status over 90 days, the second showing the number of people in the
infected compartment (sum of mildly ill and severely ill people) and the third exhibiting the
number of deaths. Recall that lockdown status is coded as 2 for full lockdown, 1 for partial
16

(a)

(b)

(c)

(d)

(e)

(f)

Figure 2: Analysis of MI and TX
lockdown and 0 for no lockdown. For MI (and NJ, see supplement), we work under a full
lockdown status over the training period [since both these states were under strict controls
during this time] and for TX (as well as CA and AZ, see supplement) we work under partial
lockdown over the training period [these states had a number of restrictions in place but
17

(b)

(a)

(c)

Figure 3: Analysis of FL

18

(b)

(a)

(c)

Figure 4: Severe Cases vs Hospital Capacity

19

many activities and businesses were still functional] and optimize the policy for the next 50
days. FL was trained under no lockdown in keeping with its status during the training phase.
In the pictures corresponding to the infected and death compartments, we display 3 curves:
the blue curve corresponds to the evolution of the process using P̂ (the least squares estimate
from Algorithm 1) labeled as Estimated Curve, the green curve labeled as Real shows the
actual observed numbers for that state and the Mean Curve in orange is the mean of the
trajectories of the process using the perturbed parameters. More precisely, as described in
Algorithm 4, we obtain a mean process for each set of perturbed parameters and the Mean
Curve is the just the mean of those mean curves. The shaded region represents the 90% band
based on the mean curves generated by the perturbed parameters as described previously.
The dashed vertical line separates the training period from the test period.
For pS we use (for all states but NJ) an estimated value of 0.07 which is approximately the
proportion of daily active cases that are hospitalized. This quantity generally ranges between
5 and 8 during the training period for all the states we consider other than NJ [1, 14, 18].
For NJ we use an estimated value of 0.15 [2].
We performed our analysis twice for each state, once for high life cost and once for low life
cost, and in each case we obtained the same optimal policy: lift the lock down (i.e. a(t) = 0
after training period). This may seem surprising at first sight given that the numbers are
rising fast especially in the southern states but a closer inspection of the available data
provides some justification for the prescribed optimal policy.
Consider the the projected numbers of severely infected and the figures on the number of
hospital beds allocated for covid patients in Table 2. It is projected that MI will have in the
ballpark of 700 severe cases by the end of July.4 On the other hand MI has around 11000
hospital beds for Covid patients, which is clearly more than sufficient. While the projected
number of deaths in Michigan shown by the blue curve in Figure (c) over the test period [till
July 25th] is over-estimating the real death curve [orange] which is quite flat, the divergence
is still modest, and the a(t) = 0 policy over the training period is quite compatible with
the slow growth rate of both projected and real death curves. As far as Texas and Florida
are concerned, unlike Michigan (and New Jersey, shown in the supplement), the number of
active severe cases is projected to increase through the end of August, in keeping with the
growing phase of the epidemic at present, but the growth of severe cases is not particularly
fast: for FL, AZ the projected curves are concave whereas for TX and CA they have a roughly
linear trend; at any rate there is no ‘shooting-up’ that might cause grave alarm. As for MI,
4

At the time of writing at the end of July, MI has 438 hospitalized cases, which suggests our prediction is
over-estimating even if we account for some unobserved severe cases. On the other hand, at the end of July,
NJ reported about 700 hospitalized cases, which is higher than our projection of 501. (Similar data for other
states, corresponding to the end of August, is not available at the time of writing.)

20

State

Active Severe Cases

Hospital Capacity

Number of Deaths

AZ

4599

6537

5389

CA

15617

34242

12386

FL

19435

24208

10086

MI

725

11320

7342

NJ

501

10398

14029

TX

18396

30784

9216

Table 2: The number of active severe cases and the cumulative number of deaths predicted
on day T̃ = 90.
the projected number of severe cases stays well below hospital capacity, i.e. the ‘curve stays
flat’. In summary, for each state under consideration, given the available number of (COVID)
hospitable beds, the number of people who currently are (and predicted to be in the future)
severely ill, and the current and predicted numbers of deaths, the policy finds the economic
cost incurred due to lockdown to be too high from the optimization point of view. It is also
evident from our picture, especially from the test region, that our model has overall decent
predictions and the projected numbers lie inside the band in most cases. Two further points
need to be noted. First, the presented bands are not based on a strict inferential principle and
must be interpreted as a rough exploration of variability (sensitivity to perturbations of the
least squares estimated) more than anything else. As far as the numbers of infected go, the
bands generally tend to be overly conservative on the lower end, whereas in terms of number
of deaths one notices just the opposite trend: the upper bounds are ultra conservative now.
More insights into the performance of these bands is needed. Second, the policy a(t) = 0
over the test period should be interpreted with caution. Recall that for us a(t) = 0 still
corresponds to an R0 value that is appreciably smaller than the values around 2.5 or more
that were estimated in the pre-epidemic phase: in other words, no lockdown is not equated
to a return to normal pre-pandemic life, but public health informed behavior with adequate
distancing whenever possible and use of masks while generally going about one’s business.
Most activities and occupations can continue under such circumstances. See also the caveats
we discuss in Section 4 in connection with the interpretation of prescribed policies.

21

Figure 5: A disease history of a patient

3

Non-Markovian Model

The vast majority of existing literature on pandemic modeling focuses on Markovian processes, not least owing to a broader understanding of decision making strategies in such
frameworks and optimization techniques thereof, as well as the existence of ready software.
While non-Markovian processes have been investigated in epidemic propagation contexts,
and mostly so in network based analysis (see [26], [29], [41], [37] and references therein),
the literature in this arena is significantly sparser, and very few works in the recent slew of
papers on the pandemic have considered this angle. However, we believe that exploration of
non-Markovian models is quite important since the standard Markovian compartment models
used in practice do not quite describe epidemic transmission accurately. While they provide
good working approximations, they are not good at capturing natural delays, and accounting
for the fact that the probability of an individual transitioning from one compartment (say Im )
to another (say R) typically depends on their history in the Im compartment and is actually
time-dependent. In the case of COVID, for example, the delay between being acquiring the
infection (L) to being able to transmit the virus (Im ) has a mode at 5-7 days [23], while the
delay between being the Im state and death has a mode of around 3 weeks [see here]. The
parsimonious Markovian model is restricted to geometric delays with a mode at 0: under a
geometric assumption, the memoryless property guarantees the Markovian property with a
time-homogeneous transition probability (for i.i.d. individual trajectories). It is, of course,
possible to extend the model by including compartments for each day between infection and
disease: e.g., from the compartment of 3 days after acquiring the infection, a subject moves
either to the compartment of 1st day of disease or to the compartment of 4th day of infection. But this becomes exceedingly cumbersome. Another issue to keep in mind is that in
a decision based framework, the effect of imposing a lockdown typically influences infection
rates between households but not within, and therefore a reduction in transmission propensity uniformly over all individuals may not conform to a good modeling strategy especially
22

in locations with typically large households. Also, the effect of imposing a lockdown is not
immediate, there are natural delays in its coming into effect, so to speak. It is considerably
easier to accommodate these diverse issues in a non-Markovian framework. Towards that
end, we next present some ideas for a more flexible non-Markovian model which, instead of
modeling the compartments, models each person separately. The development at this point
is preliminary, however as these ideas bear promise and point to new paradigms for studying
future epidemics, we deem it worth a discussion.
Consider a population of N members (for our current simulation N = 5 × 106 , from
which some results are displayed below) who are located in K (= 9 in the current simulation)
clusters, each further divided into communities. For better understanding, one may think
clusters as states and communities as counties [or on a shorter scale, clusters as counties and
communities as various municipalities within the county]. The population is divided into
two sub-groups based on their risk of severe illness upon infection: each member i has an
independent risk factor ρi , primarily governed by his/her medical profile and age, with ρi > r
considered high-risk, and low risk otherwise. An infected member i can potentially infect
Ii ∼ Poi(λ) members, with λ = R0 . The natural history of a typical subject after being
infected is described in Figure 5. After the incubation period (L), a subject moves either to
be “asymptomatic” or “mildly” ill (defined as a carrier that is not hospitalized). During these
two periods the subject may infect others. From the asymptomatic state, the subject recovers
after a few days, while from the mild illness state, the subject may transit to recovery, die
without hospitalization or become “severely ill” (i.e. is hospitalized and recorded as being
severely ill). By the end of this interval, she may die, recover or become “critically ill” (i.e.,
transferred to the ICU). Finally, after the ICU period, she may recover or die.
The probability of a susceptible picking up the infection depends on the social-distancing
policy enforced at the time of the potential infection, since that influences R0 . Once infected,
the transit probabilities between the different stages depend on the risk factors, e.g. a person
in the high risk group will be more likely to be in the severely ill compartment, whereas,
a person in the low risk group will either recover from the asymptomatic stage or the mild
infection stage with high probability. The period of time a person is capable of infecting
others is taken to be i.i.d. (the common distribution was taken as a Beta (3,6) distribution
scaled to the maximum duration of the mild/asymptomatic intervals for our simulations)
across different individuals. Denote by Inf(j), the set of individuals infected by an person j.
We pick every member of Inf(j) from a mixture distribution such that with high probability
they are in close proximity to j [i.e. in the same community] and with small probability
at a substantial distance [other communities and clusters]. Define by Hkt (respectively Lkt )
the number of active cases at time t in cluster k who are at high risk (respectively low
risk). An individual j, at the end of their latency plus disease period, dies with probability

23

P
q(ρj , k Hkt ) on day t for some function q (or recovers otherwise). The function q is chosen
so that it enables modeling the chance of dying in terms of the person’s individual risk as
well as the available medical facilities (which would be typically overburdened for high values
of the sum in the second argument).
The process starts with N0 newly infected members. The current implementation enables
importing a small number of cases from outside (outside of the clusters considered) daily.
The following social-distancing policy is simulated: If for some function h, h(Lkt , Hkt ) < c1 ,
social-distance restriction is relaxed. If h(Lkt , Hkt ) > c2 social distancing is enforced on highrisk members of cluster k, and if also Lkt /Hkt > c3 , it is applied to all members of the cluster.
We take h in our simulations to be a convex combination of the proportions of low risk and
and high risk people. The constants c1 , c2 , c3 are optimized to minimize a loss function which
depends on the number of days each of the social distancing policies is applied (economic
cost), the total number of deaths and the number of hospitalization days of severely ill cases,
similar to the loss function we used in the Markovian framework. Figures 6a - 6d represent
one such simulation result.

(a) Daily cases in different clusters and the average over clusters

24

(b) Various pandemic numbers over time

(c) Lockdown enforced on low risk individuals by cluster

25

(d) Lockdown enforced on high risk individuals by cluster

Figure 6: Plots of the Non-Markovian model: For plot (a), X-axis denotes the time horizon
and Y -axis denotes the no. of cases. In (b) we plot daily deaths (red), severely ill (yellow)
and ICU capacity (magenta) per 10K people. The blue line in (b) denotes the cumulative
proportion of infected people over time. In plots (c) and (d) the Y -axis represents clusters and
X-axis represents the no. of days. The shaded area denotes time duration when lockdown
was enforced. The optimal lockdown policies conform to the intuition that frequent and
more extensive lockdowns on high risk people are essential. The different shades denoting
the lockdowns simply conform to different clusters and carry no other meaning.

4

Extensions and Future Work

In this paper we have presented a study of Covid-19 evolution via an SEIRD model within the
broad framework of optimal decision making (in terms of lockdown policies) and provided,
what appear to be reasonable policies for the states under consideration. We have also
sketched some ideas for future development of non-Markovian epidemic propagation models
that show considerable promise for the future. In our concluding section, we point out
possible extensions and future work in this direction, along with certain caveats of the current
approach.

4.1

Possible extensions

Our Markovian model was developed in the framework of optimal bang-bang control policies.
One important extension is to allow more complex policies into our set-up, but this requires
more involved computation (see [8], [28], [16], [36] and [27] and references therein). Typically,
lockdowns are often imposed in a phased fashion with essential goods and services phased out

26

last and also made operational first. Such nuances would require introducing more fine-tuned
lockdown statuses than the ones we have used in this paper. Furthermore, it may also be of
importance to develop more fine-tuned loss functions using input from economists to calibrate
the losses due to different phases of lockdown, i.e. differentiate more carefully between the
lockdown costs of essential services and goods and their non-essential versions. As of now,
we operate under the assumption that the economic impact of a partial lockdown is half of
that of full lockdown, but this factor itself needs more investigation. An important feature
of our non-Markovian model is the incorporation of a risk score for each individual in terms
of demographic covariates, which allows the enforcement of movement or social distancing
restrictions on people depending on their age, health status and medical conditions. This
is, in fact, one of the key issues with COVID, as there is enough evidence that the virus
can be extremely harsh on older and/or unwell people. We note that a similar distinction
between high and low risk individuals can also be incorporated in the Markovian formulation
by subdividing each compartment into high risk and low risk compartments, and indeed, our
initial strategy for data analysis was to take this into account. Unfortunately, the available
data sources do not provide enough information to subdivide these compartments reliably,
and we chose to adopt the more parsimonious approach. However, future extensions of this
type, should more data become available, would be useful. Finally, the Markovian model we
used is purely temporal in the sense that we do not consider spatial effects on transmission
of infection, which can sometimes be quite informative. This is not particularly difficult to
take into account by sub-dividing a state into sub-regions and using a connectivity matrix to
quantify the chance of a random person in a particular sub-region (say, a county) traveling
to another sub-region (or staying put), and using this matrix to calculate the chance of a
susceptible person picking up the infection by an extension of the current formula at the
beginning of Section 2.2.
As far as the non-Markovian approach is concerned, we note that the model advocated
above is flexible enough to incorporate different types of testing (both PCR and serum),
more flexible social distancing and social behavior (e.g. networks of members), and different
levels of identifiability (e.g., the effect of asymptomatic patients), which could be considered
carefully in future work. Furthemore, modeling individual level variability as opposed to a
compartment as a whole, allows a considerable amount of heterogeneity into the framework.
The non-Markovian model however suffers from the cons of being computationally more
demanding. In order to make a case for broader adoption of this approach, there is a need
for innovative optimization techniques to make such models scalable with respect to the
population size, which presents another direction of research.
Structured inference for process parameters is yet another direction where more work
needs to be done. Currently, the bands that are generated around the mean prediction

27

curves (for the infected and deceased compartments) use some ‘common-sense’ perturbations
of the estimated population parameters (from training data), but clearly more objectivity is
needed. As discussed previously, the bands need to be interpreted with a certain grain of salt.
Appropriate calibration of the variability of the obtained estimates remains an interesting
and open question.

4.2

Caveats

We end our discussion with some caveats that are critical to keep in mind while interpreting
the results of our research and similar other works on Covid predictions and analyses. While
the model presented in this paper generally exhibits good fit to the training data and reasonable projections for the test period (to the extent that such data are available, since at
the time of writing (in July) future data from August which constitutes one month of test
data for the southern states are unavailable), some of the simplifying assumptions that were
made in the interests of tractability should be mentioned.
1. Proper modeling of active case counts depends heavily on who receives the tests and
how the number of tests changes over time [30]. The testing mechanism in this paper is
somewhat idealized: an individual is only tested once and further it is assumed that the
compartment status of an individual is determined at the end of the day on which they are
tested. This latter assumption ignores delays in getting test results which were somewhat of
an issue especially in the earlier phases of the epidemic. Also, we have made the assumption
that tests give precise results. We have not taken into account the false positive and negative
rates of tests in our model.
2. In reality, patients and hospitals are not distributed uniformly across each state.
Rather, there are usually centers of high concentration of infected cases, especially in crowded
urban areas. Similarly, economic lockdowns do not always apply to whole states but rather
strict lockdowns are enforced only on centers of spread at the county level. This, in turn,
affects the cost and duration of lockdowns. In this work, we consider a state as one single unit,
and therefore no differentiation is made at more granular levels (e.g. counties). However, as
pointed out in the previous subsection, a spatio-temporal model for a state where one treats
counties as units of location, can alleviate some of these issues.
3. In our analysis the economic cost of lockdowns is assumed to increase linearly in
the duration of lockdown. This assumption can be violated in practice as longer lockdowns
tend to have longer lasting and more devastating effects. For example, many businesses may
be able to endure one week of lockdown, say with a cost c to the economy. However, a
lockdown of 4 weeks could make the business shutter permanently, leading to a cost much
higher than 4c to the economy. Furthermore, the loss function that was optimized to obtain
28

recommended policies, while designed to trade-off the natural losses against each other, can
certainly be embellished with more input from economists and government policy makers.
Our loss function is meant to serve as a broad template, but depending on the specific
applications and goals, other fine-tuned loss functions can certainly be used.
4. As evidenced by the sensitivity bands in our plots, the projections of the model are
sensitive to parameter specifications. Consequently, the optimal lockdown policy can change
sharply for slight changes in parameter estimates. As an example, we repeated our analysis
for MI (for the high value of cost of life 4.7) with pS = 0.155 and the other parameters set
or optimized as before. In this perturbation scenario, we obtain full lockdowns (status =
2) for the whole 90-day period under consideration (see Figure 7) whereas previously (with
pS = 0.07) the optimal policy enforced no lockdown beyond the training period for high and
low cost of life. Thus, any policy specification should be examined and considered carefully by
policy-makers, possibly with some sensitivity analysis, and also keeping in mind the situation
on the ground which the modeler has no access to when they are making predictions.
5. Building upon the previous point, an important question arises as to how far down the
road predictions of such models should be relied upon. While we have predicted up to a period
of 50 days, in practice we recommend updating predictions much before a 7 week duration,
since prediction errors can increase quickly with longer time horizons and the consequence
of mis-matched predictions (generally unavoidable) is often human lives. One may want to
update predictions once every 2 weeks (especially if the spread is unchecked over a certain
region), or 4 weeks (if the spread is generally well controlled). The dynamics of contagious
disease propagation involve a slew of intangibles and imponderables that no mathematical
model can really capture, since human behavior is quite non-robust to shocks. For example,
turmoil in the US over both racial issues and political partisanship has manifested itself in
massive demonstrations and public rallies as well as multiple civilian-police confrontations in
recent months. Such mass-events have the potential to cause spikes in infection and change
the subsequent dynamics of the disease. Obviously, no degree of quantitative modeling can
account for the exact nature of such disturbances.
5

This corresponds to the higher hospitalization rates seen in April, while the May rates were lower.

29

(b)

(a)

(d)

(c)

Figure 7: Perturbation analysis of MI with the proportion of severe cases pS = 0.15.

5

Acknowledgements

This work was done under the auspices of a grant awarded by the MIDAS Propelling Original
Data Science (PODS) pilot funding program at University of Michigan.

6
6.1

Supplements
Additional mathematical details

We derive below the form of the transition probability from compartment S to L. At the
outset let us define a few quantities and articulate the underlying assumptions:
By Ra(t) we denote the basic reproduction number under lockdown status a(t): it is on
30

an average the number of people to whom an infected person transmits the virus over the
number of days that he/she is capable of infecting [which for our model is the average number
of days D that they stay in state Im ] under the assumption that the proportion of susceptibles is close to 1. We assume that the number of people N that a random person comes into
contact with on a daily basis follows Poisson(µa(t) ) where µa(t) varies by lockdown status.
A strict lockdown corresponds to a small value for this number. If β is the probability of
transmission of infection per contact between an individual in state S and one in state Im ,
then:
Ra(t) = µa(t) βD .
Now,
PtS→L = P (A person in S is infected at time t + 1)
=

∞
X

P (Infection | Meet n people) P (Meet n people)

n=1



j 
n−j
∞
n  
X
X
e−µa(t) µna(t)

Xt (Im )
Xt (Im )
n
j 

1−
1 − (1 − β)
=
N
N
n!
j
n=1

j=0


  −µ
n
Xt (Im ) n e a(t) µa(t)
=
1− 1−β
N
n!
n=1
 −µ
n
∞ 
X
Xt (Im ) n e a(t) µa(t)
=1−
1−β
N
n!
∞ 
X

n=1

= 1 − e−µa(t) β

Xt (Im )
N

The above formula admits a ready approximation in terms of the quantity Ra(t) which is
described next: consider the situation where the status a(t) remains unchanged over the
period of time during which an infected person is in state Im . On an average, the person meets
µa(t) people every day of which a proportion Xt (s)/N are susceptible and each such contact
spreads the infection with probability β. Thus, the average number of people infected on day t
is µa(t) Xt (S)/N β. The average infected over the entire period can therefore be approximated
by summing this quantity over the average number of days in the Im compartment, which is
D. If we assume that the proportion Xt (S)/N does not change dramatically over this period,
we have µa(t) × (Xt (S)/N ) × β × D as the average infected over the entire period. On the
other hand, the average infected over the entire period is also approximately Ra(t) ×Xt (S)/N :
this follows from the fact that we are working under the assumption that a(t) is fixed over
the duration of the infecting phase and the rough constancy of the proportion of susceptibles
over this phase, leading us to:
D × µa(t) ×

Xt (S)
Xt (S)
× β = Ra(t) ×
.
N
N
31

Hence we have:

a(t)

µa(t) × β =

R0
.
D

Putting this back in the main equation we get:
PtS→L

−

=1−e

a(t)
R0
Xt (Im )
D
N



a(t)
Im →Is
Im →R Xt (Im )
= 1 − exp −R0 (P
+P
)
,
N

upon noting that the number of days D spent in state Im is a geometric random variable
with mean 1/(P Im →Is + P Im →R ).

6.2

Additional plots

In this subsection we include the plots for FL, AZ and NJ.

32

(b)

(a)

(c)

(d)

(e)

(f)

Figure 8: Analysis of AZ and CA

33

Figure 10: Analysis of NJ

References
[1] Florida’s covid-19 data and surveillance dashboard, 2020. https://experience.
arcgis.com/experience/96dd742462124fa0b38ddedb9b25e429.
[2] Live updates: Tracking the coronavirus in new jersey, 2020. https://www.njtvonline.
org/news/uncategorized/tracking-the-coronavirus-in-new-jersey.
[3] TS Angell. Existence of optimal control without convexity and a bang-bang theorem for
linear volterra equations. Journal of Optimization Theory and Applications, 19(1):63–79,
1976.
[4] Jose Angulo, Hwa-Lung Yu, Andrea Langousis, Alexander Kolovos, Jinfeng Wang,
Ana Esther Madrid, and George Christakos. Spatiotemporal infectious disease modeling: a bme-sir approach. PloS one, 8(9):e72168, 2013.
[5] José Miguel Angulo, Hwa-Lung Yu, Andreas Langousis, Ana Esther Madrid, and George
34

(a)

(b)

(c)

Figure 11: Severe Cases vs. Hospital Capacity

35

Christakos. Modeling of space–time infectious disease spread under conditions of uncertainty. International Journal of Geographical Information Science, 26(10):1751–1772,
2012.
[6] Zvi Artstein. Discrete and continuous bang-bang and facial spaces or: look for the
extreme points. Siam Review, 22(2):172–185, 1980.
[7] American Hospital. Association. Fast facts on us hospitals, 2020. https://www.aha.
org/statistics/fast-facts-us-hospitals.
[8] Karl Johan Åström. Optimal control of markov processes with incomplete state information. Journal of Mathematical Analysis and Applications, 10(1):174–205, 1965.
[9] Andrew Atkeson. What will be the economic impact of covid-19 in the us? rough
estimates of disease scenarios. Technical report, National Bureau of Economic Research,
2020.
[10] Robert H. Topel Casey B. Mulligan, Kevin M. Murphy. Some basic economics of covid-19
policy, 2020. Chicago Booth Review, https://review.chicagobooth.edu/economics/
2020/article/some-basic-economics-covid-19-policy, Accessed: 07/15/2020.
[11] Bibhas Chakraborty and Erica EM Moodie. Statistical reinforcement learning. In Statistical Methods for Dynamic Treatment Regimes, pages 31–52. Springer, 2013.
[12] The Apothecary Chris Conover. How economists calculate the costs and benefits of covid19 lockdowns, 2020. https://www.forbes.com/sites/theapothecary/2020/03/27/
how-economists-calculate-the-costs-and-benefits-of-covid-19-lockdowns/
#3a9d612f6f63.
[13] Marco D’Arienzo and Angela Coniglio. Assessment of the sars-cov-2 basic reproduction
number, r0, based on the early phase of covid-19 outbreak in italy. Biosafety and Health,
2020.
[14] Johns Hopkins University Center for Systems Science and Engineering. Covid-19 data
repository by the center for systems science and engineering (csse) at johns hopkins university, 2020. https://github.com/CSSEGISandData/COVID-19, Accessed: 7/5/2020.
[15] Tanmay Gangwani, Joel Lehman, Qiang Liu, and Jian Peng. Learning belief representations for imitation learning in pomdps. arXiv preprint arXiv:1906.09510, 2019.
[16] Eric A Hansen. Solving pomdps by searching in policy space.
arXiv:1301.7380, 2013.

arXiv preprint

[17] Henry Hermes et al. Functional analysis and time optimal control. 1969.
36

[18] Dave Bartkowiak Jr. Ken Haddad.
Tracking michigan covid-19 hospitalization
data trends, 2020.
https://www.clickondetroit.com/news/local/2020/05/16/
tracking-michigan-covid-19-hospitalization-data-trends.
[19] William Ogilvy Kermack and Anderson G McKendrick. A contribution to the mathematical theory of epidemics. Proceedings of the royal society of london. Series A, Containing
papers of a mathematical and physical character, 115(772):700–721, 1927.
[20] William Ogilvy Kermack and Anderson G McKendrick. Contributions to the mathematical theory of epidemics. ii.—the problem of endemicity. Proceedings of the Royal
Society of London. Series A, containing papers of a mathematical and physical character,
138(834):55–83, 1932.
[21] William Ogilvy Kermack and Anderson G McKendrick. Contributions to the mathematical theory of epidemics. iii.—further studies of the problem of endemicity. Proceedings
of the Royal Society of London. Series A, Containing Papers of a Mathematical and
Physical Character, 141(843):94–122, 1933.
[22] Vikram Krishnamurthy. Partially observed Markov decision processes. Cambridge University Press, 2016.
[23] Stephen A Lauer, Kyra H Grantz, Qifang Bi, Forrest K Jones, Qulu Zheng, Hannah R
Meredith, Andrew S Azman, Nicholas G Reich, and Justin Lessler. The incubation
period of coronavirus disease 2019 (covid-19) from publicly reported confirmed cases:
estimation and application. Annals of internal medicine, 172(9):577–582, 2020.
[24] Yan-Chao Li, Wan-Zhu Bai, and Tsutomu Hashikawa. The neuroinvasive potential of
sars-cov2 may play a role in the respiratory failure of covid-19 patients. Journal of
medical virology, 2020.
[25] Warwick J McKibbin and Roshen Fernando. The global macroeconomic impacts of
covid-19: Seven scenarios. 2020.
[26] Guodong Pang and Etienne Pardoux. Functional limit theorems for non-markovian
epidemic models. arXiv preprint arXiv:2003.03249, 2020.
[27] Joelle Pineau, Geoff Gordon, Sebastian Thrun, et al. Point-based value iteration: An
anytime algorithm for pomdps. In IJCAI, volume 3, pages 1025–1032, 2003.
[28] Nicholas Roy, Geoffrey Gordon, and Sebastian Thrun. Finding approximate pomdp
solutions through belief compression. Journal of artificial intelligence research, 23:1–40,
2005.

37

[29] Neil Sherborne, Joel C Miller, Konstantin B Blyuss, and Istvan Z Kiss. Mean-field
models for non-markovian epidemics on networks. Journal of mathematical biology,
76(3):755–778, 2018.
[30] Nate Silver.
Coronavirus case counts are meaningless, 2020.
https://
fivethirtyeight.com/features/coronavirus-case-counts-are-meaningless, Accessed: 7/5/2020.
[31] Richard D Smallwood and Edward J Sondik. The optimal control of partially observable
markov processes over a finite horizon. Operations research, 21(5):1071–1088, 1973.
[32] Edward J Sondik. The optimal control of partially observable markov processes over the
infinite horizon: Discounted costs. Operations research, 26(2):282–304, 1978.
[33] Peter X Song, Lili Wang, Yiwang Zhou, Jie He, Bin Zhu, Fei Wang, Lu Tang, and Marisa
Eisenberg. An epidemiological forecast model and software assessing interventions on
covid-19 epidemic in china. medRxiv, 2020.
[34] LM Sonneborn and FS Van Vleck. The bang-bang principle for linear control systems. Journal of the Society for Industrial and Applied Mathematics, Series A: Control,
2(2):151–159, 1964.
[35] Pengfei Sun, Xiaosheng Lu, Chao Xu, Wenjuan Sun, and Bo Pan. Understanding of
covid-19 based on current evidence. Journal of medical virology, 2020.
[36] Daniel Szer, François Charpillet, and Shlomo Zilberstein. Maa*: A heuristic search
algorithm for solving decentralized pomdps. arXiv preprint arXiv:1207.1359, 2012.
[37] Zsolt Vizi. Pairwise models for non-Markovian epidemics on networks. PhD thesis, szte,
2017.
[38] Daniel M Weinberger, Jenny Chen, Ted Cohen, Forrest W Crawford, Farzad Mostashari,
Don Olson, Virginia E Pitzer, Nicholas G Reich, Marcus Russi, Lone Simonsen, et al.
Estimation of excess deaths associated with the covid-19 pandemic in the united states,
march to may 2020. JAMA Internal Medicine, 2020.
[39] Reza Yaesoubi and Ted Cohen. Dynamic health policies for controlling the spread of
emerging infections: influenza as an example. PloS one, 6(9), 2011.
[40] Reza Yaesoubi and Ted Cohen. Generalized markov models of infectious disease spread:
A novel framework for developing dynamic health policies. European Journal of Operational Research, 215(3):679–687, 2011.
[41] GL Yang. Empirical study of a non-markovian epidemic model. Mathematical Biosciences, 14(1-2):65–84, 1972.
38

