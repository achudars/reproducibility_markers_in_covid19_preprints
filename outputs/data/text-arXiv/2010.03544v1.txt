arXiv:2010.03544v1 [cs.IR] 7 Oct 2020

A S ELF - SUPERVISED A PPROACH FOR S EMANTIC I NDEXING IN
THE C ONTEXT OF COVID-19 PANDEMIC

Nima Ebadi
Department of Electrical and Computer Engineering
University of Texas at San Antonio
San Antonio, SA 78249
nima.ebadi@utsa.edu

Peyman Najafirad
Department of Information Systems and Security
University of Texas at San Antonio
San Antonio, TX 78249
peyman.najafirad@utsa.edu

October 8, 2020

A BSTRACT
The pandemic has accelerated the pace at which COVID-19 scientific papers are published. In
addition, the process of manually assigning semantic indexes to these papers by experts is even more
time-consuming and overwhelming in the current health crisis. Therefore, there is an urgent need for
automatic semantic indexing models which can effectively scale-up to newly introduced concepts
and rapidly evolving distributions of the hyperfocused related literature. In this research, we present a
novel semantic indexing approach based on the state-of-the-art self-supervised representation learning
and transformer encoding exclusively suitable for pandemic crises. We present a case study on a
novel dataset that is based on COVID-19 papers published and manually indexed in PubMed. Our
study shows that our self-supervised model outperforms the best performing models of BioASQ Task
8a by micro-F1 score of 0.1 and LCA-F score of 0.08 on average. Our model also shows superior
performance on detecting the supplementary concepts which is quite important when the focus of the
literature has drastically shifted towards specific concepts related to the pandemic. Our study sheds
light on the main challenges confronting semantic indexing models during a pandemic, namely new
domains and drastic changes of their distributions, and as a superior alternative for such situations,
propose a model founded on approaches which have shown auspicious performance in improving
generalization and data efficiency in various NLP tasks. We also show the joint indexing of major
Medical Subject Headings (MeSH) and supplementary concepts improves the overall performance.

1

INTRODUCTION AND BACKGROUND

To facilitate literature search and storage, curators at National Library of Medicine (NLM) annotate every article with a
set of concepts from established categorical semantic terminologies.[1] This annotation process of scientific articles
is generally referred to as semantic indexing. Nevertheless, the manual process of biomedical semantic indexing is
time-consuming and financially expensive.[2, 3] Therefore, several automated semantic indexing models have been
proposed in the literature, including NLM’s official Medical Text Indexing tool (MTI).[4, 5, 6, 7, 8, 9]
A pandemic situation, however, is an extreme scenario which highlights the importance of automated semantic indexing
as researchers desperately require a well compartmentalized database to gain insights about the recent findings.[10]
During the current pandemic so many related papers are being published at a much faster pace,[11] and the focus of
the literature has drastically shifted towards COVID-19 related topics and subtopics,[12] some of them have not had a
standard name until a couple of month ago. [13] Such conditions cause challenges for the automatic semantic indexing
systems which are based on substantial supervisions and hand-coded features. Albeit the importance of semantic
indexing in the pandemic situation, there is a lack of study on the performance of such automated models on the rapidly
evolving corpus of COVID-19 related documents.[10] In this research, we present a case study on the state-of-the-art
semantic indexing models in the context of COVID-19 pandemic. We analyze the key challenges of these models
performing various evaluation (training and testing) schema. We find out the key aspects of the pandemic causing
challenges for automatic semantic indexing models are the abrupt changes in the distribution of these indexes, rapid

A PREPRINT - O CTOBER 8, 2020

growth of specific topics regarding few indexes from a relatively large set of indexes, and lack of standard terms for
newly introduced topics.
In this research, we attempt to tackle the problem of semantic indexing exclusively in the pandemic situation. We
propose a novel semantic indexing methodology suitable for the aforementioned challenges, i.e. that is able to effectively
scale-up to COVID-19 literature. Inspired by the state-of-the-art performance of self-supervised learning (SSL) models
in various NLP,[14, 15] and BioNLP,[16] tasks–specifically their generalization and data efficiency capabilities–as well
as the best performing models in BioASQ Task 8a,[5, 6] we design our methodology based on transformers encoding
and attention mechanism between the document and candidate indexes. Our experimental results denote our model as
a superior alternative over the best-performing models of BioASQ challenge during health crisis situations, like the
current one. The main contributions of this study are as follows:
1. We propose a novel semantic indexing approach which can effectively scale up to new distributions, thereby
suitable for emergency situations like the current pandemic where the related literature is rapidly evolving.
2. Our study bring attention to the main challenges confronting semantic indexing models in the pandemic crises,
and attempts to address them by proposing a novel model inspired by the best-performing models of BioASQ
challenge, but unlike them, able to leverage self-supervised representation learning and transformer language
model to improve efficiency and generalization.
3. We present a case study on a novel semantic indexing dataset that is based on the COVID-19 related research
articles published and manually indexed in PubMed. We use flat and hierarchical measures to evaluate the
performance of our model along with the state-of-the-art benchmarks. Our study demonstrate the superiority
of our self-supervised approach in scaling to the novel pandemic situation with the relatively small amount of
labeled data available.
4. We also discuss the importance of more fine-grained categorization of documents to supplementary concepts,
and show their indexing can actually improve the MeSH indexing performance when performed simultaneously.
In addition to major MeSH indexing, we evaluate the performance of simultaneous indexing of both major
MeSH and supplementary concepts.
5. This paper aims to offer some aid in the process of semantic indexing of the novel COVID-19 literature so as
to lighten the load on NLM indexers.
1.1

Biomedical Semantic Indexing

Biomedical literature has been collected by the National Library of Medicine (NLM) for the last 150 years. As of
2020, PubMed database contains about 30 Million biomedical journal citations. This number has risen from 12 Million
citations in 2004 to 30 Million citations in 2020 having a growth rate of 4% per year. Through a laborious process,
NLM curators fully examine every document and annotate it with a set of hierarchically-organized terminologies
developed by NLM called Medical Subject Headings (MeSH1 ) along with supplementary concepts for more fine-grained
categorization.[17] In 2019, more than 900K biomedical citations were added to PubMed and manually indexed to
more than 29K MeSH concept categories2 .
In the light of the size and growth rate of such databases, several automated models have been developed to improve the
time-consuming and financially expensive process of biomedical semantic indexing through annual competitions such as
BioASQ Task a,[18] and presented models, [6, 5] as well as other BioNLP research venues.[19, 9, 7] These approaches
are either based on i) simple retrieval systems; such as SNOKES team which participated in BioASQ 6th and uses search
engine methods along with UMIA concept extractor,[20] Iria another participating team which combines ensemble
of the best performing models from previous years challenges with k-NN MeSH masking algorithms,[21] Segura et
al. utilize ElasticSearch to manage the "scalability" issue of the task and the enhanced NLM Medical Text Indexing
(MTI),[8] Zavorin et al. combines L2R with Medical Text Indexing;[9] or ii) deep learning models with substantial
hand-coded features and supervision. DeepMesh which is the best performing model of a couple of edition of BioASQ
challenge that combines document to vector models with crafted features from the document and MeSH indexes along
with ensemble models fed by those features. Other deep learning approaches include UIMA concept extractor links,[5]
and AUTH that also uses document to vector approach with an ensemble of machine learning classifier (SVM) fed
with document-MeSH features.[17] Jin et al. and Xun et al. combined retrieval systems with deep recurrent neural
networks and attention mechanism and also provide explainability for MeSH indexing decisions.[6, 7] The amount of
hand-crafted features and supervision required for these models make it difficult for them to effectively scale-up as the
biomedical databases do during pandemic crises.[22]
1
2

https://www.nlm.nih.gov/mesh/meshhome.html
https://www.nlm.nih.gov/pubs/techbull/mj18/brief/mj18_updates_2018_baseline_stats.html

2

A PREPRINT - O CTOBER 8, 2020

1.2

Semantic Indexing in Pandemic

These semantic indexing models are proposed to perform well in normal situations, when there is no specific interest
towards specific concepts, and are evaluated based on their overall performance on all major MeSH indexes. [23] In
the pandemic situation, however, the focus of the literature has drastically shifted towards the specific concepts and
sub-concepts related to the current Coronavirus disease. The number of published documents related to Coronavirus
have risen from to a few articles per month to more than 10K articles in June 2020–roughly 1 out of every 11.5
citations are about Coronavirus these days.[24] The rapidly growing and evolving literature of COVID-19 causes
challenges for automatic semantic indexing models.[10] Previously introduced semantic indexing models are based on
supervised learning approaches and heavily hand-coded features; therefore, they require significant amount of labeled
data regarding a specific concept to show decent performance in indexing related documents, and have challenges to
effectively scale-up to newly introduced terminologies and sub-concepts; thereby, not suitable for emergency situations
like the ongoing health crisis.
On the other hand, self-supervised learning (SSL), where a model is initially trained on a data-rich unsupervised pretext
task then fine-tuned on a downstream task, has recently emerged as an effective technique in almost every deep learning
problem ranging from computer vision,[25, 26] NLP,[27, 15, 28] to Bioinformatics,[29, 30] and IoT security.[31, 32, 33]
Self-supervised learning is known to enhance data efficiency,[34] and generalization,[35] because the SSL-based model
learns some general auxiliary knowledge from the pre-text task that allows the model to "understand" the downstream
task better.[36] Therefore, SSL-based models are more robust towards changing domains and scaling up to new
distributions.[37]
In order for a deep SSL algorithm to be effective, the pre-text learning process should be susceptible to downstream
learning.[36] However, as for the proposed semantic indexing models in the literature, either their architecture or the
representation learning objective of the downstream task does not allow pre-training in an unsupervised manner that is
useful for the downstream learning. In DeepMeSH only the TF-IDF vectorization can be updated with unlabeled data,
without any word-level representation learning.[5] In AttenMeSH word-level encoding of the document can be updated
by pre-training the Bi-GRU on an masked language modeling (MLM) pretext task, but these encodings wouldn’t be
appropriate enough for the downstream task because i) it cannot involve the document-index attention in the encoding,
and ii) more sophisticated architectures have been proven to be more effective in this regard such as transformers.[38]

2

MATERIALS AND METHODS

2.1

Self-supervised Learning Pre-text Task and Document Representations

As for the initial representations of documents, we use the word representations provided by BioASQ organizers which
is a pre-trained word embedding trained on large-scale corpus of biomedical documents3 . We also use BioASQ provided
word tokenizer to parse documents’s title and abstract to a list of the constituting words4 . We perform stemming and
eliminate the stop words as different variants of an individual word or a stop words does not affect the semantic index
of a document.
Afterwards Bag-of-Word representation of each document is computed according to the following equation:
where wj ∈ Rde1

D = [w1 , w2 , ...w|D| ]

(1)

Where |D| is the number of non-stopwords in the document, and de1 is the word embedding size.
For the model to get acquainted with COVID-19 context, we leverage an unlabeled corpus of COVID-19 related
documents, called CORD-19,[40] which is significantly larger than our labeled dataset of indexed documents. We
pre-train a bi-directional transformer on masked language modeling (MLM) task with word-tokenized representation of
the documents shown in Eq. 1, along with those of candidate similar indexes5 .[38, 41] Such algorithms have shown
promising results in many NLP problems regarding deep semantic analysis of scientific documents, such as SciBERT
and BioBERT.[42, 16] In this regard, the document representation D is masked and fed to the transformers model and
passed through a positional encoding approach following the original implementation of transformers.[38] Similar
semantic indexes are also fed to the transformer and through a joint document-index attention, index specific encoding
of the document is generated. The retrieval and embedding of candidate indexes is discussed in the next section. Next,
the transformer model gets trained to predict masked tokens from the index specific encoding (similar to 1.b) but the
3

http://participants-area.bioasq.org/tools/BioASQword2vec
http://participants-area.bioasq.org/tools/
5
Note: in the pre-text task we also feed the potentially related indexes for every document to learn latent representations based on
the index specific encodings and reinforce the consistency between the pretext and downstream tasks
4

3

A PREPRINT - O CTOBER 8, 2020

Figure 1: Our proposed semantic indexing methodology consists of a self-supervised learning stage (Fig. a) and a fine-tuning stage
(Fig. b and c). Fig. a) shows a bi-directional transformers model trained on unlabeled data (i.e. CORD-19) via masked language
modeling and next sentence prediction tasks. Fig. b) Every PubMed document along with a set of candidate indexes are encoded via
bidirectional transformers self-attention, and cross-attention between every input token/word and index are computed. Fig. c) index
specific context vectors (computed by a weighted sum) is passed through a linear projection layer and thresholding process to detect
the final semantic indexes which should be assigned to the document. (Example absract is from Yang et al., (2020).[39])
softmax is applied over the index axis). Unlike BERT and BioBERT, we do not leverage the next sentence prediction
(NSP) task for two reasons: 1) sentences ordering is required for QA type of inferences, not semantic indexing and text
classifications. 2) It has been proven to be ineffective.[15, 14]
2.2

Candidate MeSH Retrieval and Index Representations

Inspired by Jin et al., as for major MeSH indexes, we initially use a retrieval system to retrieve a subset of related MeSH
categories from relevant documents6 .[6] Note: we only perform this retrieval process for major MeSH indexes, not for
supplementary concepts since there is only 19 of them in COVID-19 dataset.
In this regard, we translate the target biomedical document into a query to extract the relevant ones from the annotated
database. We follow the same pre-process of parsing, stemming and stopwords removal of Section 2.1. Every document
is represented by their both TF-IDF and BM25 weighted sum of their words, following weighting schems of Wang et
al.,[43] and Paik et al.,[44] respectively.
Each document as query is represented as follows:
Pn
TF − IDF/BM25(wi , d) × vwi
Pn
d = i=1
i=1 TF − IDF/BM25(wi , d)

(2)

Where, wi is the ith word in document d, and vwi is the word vector from the provided pre-trained embeddings.
Next using cosine similarity scores between the target document and other ones, we find the K relevant documents.
Next, we use scoring scheme to re-rank and collect the candidate MeSH indexes. We score every MeSH term by
6

We can regard this module as a weak classifier which filter out the negative data which is far more than the positive ones (29K
total number of MeSH terms vs. 12.6 terms for every document on average). Jin et al. shows doing so enhances the efficiency
and performance of the indexing models as the classifier only focuses on the detection of correct MeSH indexes from a subset of
plausible ones.

4

A PREPRINT - O CTOBER 8, 2020

summing their IDF weights in the documents and rank them. The top M with the highest scores are considered for
indexing and passed to the next stage.
Semantic indexes representations are quite straight-forward to extract as they are single words. The indexes’ embeddings
are as follows:
M = [m1 , m2 , ...m|M | ]
where mj ∈ Rde2
(3)
Where |M | is the number of filtered indexes, and de2 is the embedding size of every index mj . To simplify the model,
we make de1 = de2 = dmodel .
2.3

Index Specific Context Vectors

After candidate indexes are retrieved, the document BoW representation D along with those of indexes M are fed to the
bi-directional transformers which is pre-trained on the self-supervised pre-text task. Positional encoding is performed
0
for documents, not for indexes, to bring in their words’ ordering. Initially, D and M are separately encoded to D
0
and M with self-attention mechanism allowing words to only attend other words, and indexes to attend other indexes
0
(there is no cross attention between words and indexes). Self-attention mechanism for D is to capture context-aware
0
representation of words, and for M is to capture correlation and dependencies between indexes which has been shown
important. [5, 45]
Next, cross-attention between encodings of words and indexes are computed using scaled dot-product attention function,
[38, 46] as follows:
0

0T

0
M D
O = Softmax( √
)D ∈ R|M |×dmodel
dmodel
0

(4)

0T

where M D ∈ R|M |×|D| is the dot product between every index and every word packed together into a matrix
multiplication. Softmax is performed over word axis to get attention weights for every index. Finally, O is the index
specific context vectors each of which is based on a weighted sum of the word vectors.
2.4

Projection Layer and Final Prediction

To compute the likelihood scores of indexes, we apply a linear projection layer with a non-linear activation function σ
0
on the context specific vectors O and index encodings M , as following equation:
Ŷ = σ(U · OT + V · M

0T

+ B)

(5)

where Ŷ ∈ R|M |×1 is the set of likelihood scores for candidate indexes, and U, V ∈ R1×dmodel and B ∈ R|M |×1 are
trainable parameters.
Finally, the predicted indexes are computed through thresholding over every likelihood score. Thresholds are defined by
maximizing the micro f-measure in the training set, following. [47]

3

RESULTS

3.1

Dataset

For self-supervised representation learning (pre-training) stage of our methodology, we use CORD-19 dataset which
includes 141K research articles about Coronavirus published in peer-reviewed venues and archival services such as
bioRxiv7 and medRxiv8 .[40] These articles are crawled from various medical databases including PubMed’s PMC
(using the query: COVID-19 and coronavirus research), a COVID-19 corpus maintained by WHO, Elsevier and the
aforementioned archival services. A great portion of the dataset (i.e. 48K) of these articles have been published in 2020,
in the context of pandemic.
For supervised training we use two sets: i) BioASQ Task 8a Test Sets (from 2015-2019): The training set consists of
2,501,982 annotated articles from PubMed. MeSH labels are manually assigned to the articles by National Library of
7
8

https://www.biorxiv.org
https://www.medrxiv.org

5

A PREPRINT - O CTOBER 8, 2020

Dataset

No. of
Documents

COVID
SSL

141,764

No. of
MeSH Indexes
-

No. of Supp.
Concepts
-

27,114
(12.84/doc.)
COVID
14,335
18
10,210
Train
(16.6/doc.)
(1.97/doc.)
COVID
10,922
15
3,463
Test
(17.9/doc.)
(1.92/doc.)
Table 1: Data Descriptive for self-supervised representation learning and supervised semantic indexing (training and
evaluation) datasets.
BioASQ

2,501,982

Figure 2: Semantic Indexes of Coronavirus. The major MeSH and supplementary concepts form a Directed Acyclic
Graph (DAG). In this figure, supplementary concepts have been added only for two of the nodes.

Medicine indexers. The dataset includes journal name in which the article has been published, article’s title and abstract
along with MeSH indexes for the training sets. On average, each article is indexed with 12.84 MeSH categories.[18] ii)
Recently collected COVID-19 related documents from PubMed: we use 13K latest documents, published and annotated
in 2020, related to COVID-19 crawled from PubMed using this query: covid-19 AND severe acute repository syndrome
2 AND sars-cov-2,[24] and evaluation results are calculated by this dataset. Table 1 provide information about the
statistics of the datasets. We utilize the MeSH majors from both sets as well as the supplementary concept from our set
to measure the performance in detail. As shown in Figure 2 major MeSH indexes and supplementary concepts form a
Directed Acyclic Graph (DAG) where there is a hierarchical relation between two major MeSH (parent-child) and a
mapping relation between mesh and supplementary concepts.
3.2

Experimental Setup

As for the MeSH retrieval part of our methodology, we use bm25/tf-idf bag-of-words representation methods with
vocabulary size of 90K. The retrieval components, i.e. vectorization global features as well as the thresholding features,
are trained using the train set only to avoid data bleeding.[48] The bi-directional transformer is implemented using
TensorFlow (2.0) Eager,[49, 50] and tensor-2-tensor9 library. The hyperparameter values are shown in Table 2. We use
Adam optimizer and early stopping strategies.[51] We apply three versions of our methodology: i) base bi-transformer
without self-supervised training: where the model is not pre-trained on CORD-19 dataset, section b) and c) of Figure 1
with random initialization of the parameters; ii) base bi-transformer with masked language modeling (MLM) as the
self-supervised pre-text task; and iii) large bi-transformer with MLM self-supervised tasks.
9

https://github.com/tensorflow/tensor2tensor

6

A PREPRINT - O CTOBER 8, 2020

Hyperparameter
Value(s)
|V |
900K, 1800K
Number of Retrieved Documents
0.1K , 0.5K, 5K
Number of MeSH Candidates
128, 256, 512, 1024
Word Embedding Size for Documents
128, 256, 512, 1024∗
Hidden Size
128, 256, 512, 1024∗
Feed Forward
256, 384, 512∗
Number of Layers
4, 5, 6∗ , 7, 8
Learning Rate
0.002, 0.001, 0.0005, 0.0001
Table 2: Hyperparameters values. We use bold text for the optimal ones among all tried values.
Bi-Trans Large.

3.3

∗

refer to those for

Evaluation Metrics

Following BioASQ challenge, we evaluate the performance of the semantic indexing models based on two sets of
evaluation measures: i) flat: Accuracy,Micro and Macro F-measures, and ii) hierarchical: lowest common Ancestor
F-measure (LCA-F).
Accuracy is the fraction of correct predictions. However, in multi-label classification problems true and predicted
classes could be a set of labels for every example; therefore, there is an additional notion on partially correct. To capture
this, precision and recall measures are computed for every class separately. Then, the results are aggregated using
micro-averaging and macro-averaging strategies to compute micro (MiP/MiR) and macro precision/recall (MaP/MaR)
respectively. Micro-averaging is evaluating the average difference between the predicted labels and the actual labels
globally for each test example, and then averaging over all examples in the test set. The second strategy is macroaveraging evaluation in which each label is evaluated separately then averaged over all the labels. Finally the micro and
macro f-measures (MiF and MaF) are computed base on the harmonic mean of the corresponding precision and recall.
MiF is more affected by the performance of frequent indexes, while MaF treats every index equally.[52] Following
BioASQ, MiF is the major flat measure in our presented case study.
As shown in Figure 2, semantic indexes have a hierarchical relation between one another. Therefore, in addition to flat
measures, hierarchical measures are also used to evaluate the hierarchical classification performance of the semantic
indexing models. In this regard, we leverage Lowest Common Ancestor F-measure (LCA-F) the algorithm provided by
Kosmopoulos et al.,[53] which is the same algorithm used in BioASQ challenge10 . In LCA-F measure, sets of true
class and predicted class are compared based on union of their corresponding augmented graphs which encompass all
the lowest common ancestors between every pair. The algorithm has shown desirable results in various hierarchical text
classification tasks.
3.4

Major MeSH Indexing

Table 3 shows the performance of the semantic indexing models with the aim of indexing only major subject headings
(i.e. major MeSH). The models are trained on BioASQ data from 2015-2019 (excluding the recent COVID-19
documents) as well as COVID training set. They are tested on COVID testing set. As shown in Table 3, semantic
Model
Medical Text Indexer (MTI) (Default)
MTI (First Line Index)
Deep MeSH
Attention MeSH
iria
xgx
MeSHmallow
BioTrans (Base) (w/o SSL)
BioTrans (Base) (w/ MLM SSL)
BioTrans (Large) (w/ MLM SSL)

LCA-F
0.5083
0.5011
0.5732
0.5417
0.4542
0.4266
0.3751
0.4899
0.5211
0.5683

Micro F1
0.6521
0.6152
0.6974
0.6571
0.4908
0.6368
0.5172
0.6013
0.6588
0.7071

Macro-F
0.4553
0.5038
0.5024
0.4928
0.3491
0.4934
0.3570
0.3725
0.4733
0.5044

Accuracy
0.4267
0.4419
0.4612
0.5147
0.2179
0.5018
0.3916
0.3309
0.5096
0.5319

Table 3: MeSH indexing performances of our deep transformer and self-supervised learning based models along with
the state-of-the-art ones in terms of LCA F-measure (hierarchical measure) as well as accuracy, micro and macro
F-measure (flat measure).
indexing models which are based on deep representation learning algorithm demonstrate better performance in scaling
10

https://github.com/BioASQ/Evaluation-Measures/tree/master/hierarchical

7

A PREPRINT - O CTOBER 8, 2020

up to novel pandemic situation. Our base and large model with self-supervised training perform state-of-the-art beating
most of the baselines by 0.1 micro f-measure. The self-supervised training has shown significant improvement over the
vanilla version. Large transformer model also shows better capacity to scale up to new concepts.
The higher performance of self-supervised models reveals that the models learn some sort of common sense (acquire
general knowledge) about the pandemic and new distribution of major MeSH indexes.

3.5

Efficiency w.r.t COVID-19 Training Data

To evaluate how efficiently the semantic indexing models scale-up to the novel Coronavirus related literature, we
chronologically sort the COVID-19 training dataset, and train each model with the following proportions of the data to
evaluate their zero- and few-shot performance along with their data efficiency: 0.0 (zero-shot evaluation), 0.05, 0.1, 0.2,
0.5 and 1 (the whole data). Figure 3 shows the MeSH indexing performance of the top performing models from Table 3
based on the size of the exclusive COVID-19 training data. The beginning performance is their zero-shot performance,
when the models have only been trained on BioASQ dataset and have not seen a COVID-19 paper yet. The SSL-based
versions of our BioTrans model achieve substantially superior performance until almost half of the training data is fed,
especially in the very beginning. They reach 0.95 of their optimum performance by only 0.2 of the data. Other models
reach this point once half of the training data is fed which means a couple of months delay, an essential issue for a
pandemic crisis. Our BioTrans model which is not pre-trained on COVID-19 SSL dataset does not learn effectively

Figure 3: MeSH indexing performance w.r.t the size of COVID-19 training data based on their Micro-F score. COVID19 related data is chronologically ordered and then divided; therefore, the horizontal axis is directly related to the date
these papers are published.
with the COVID-19 supervised data, and simply follows similar learning speed to those of AttenMeSH and DeepMeSH
as it has been inspired by these techniques. This shows that the major strength of using such architecture–bi-directional
transformers encoding with attention between documents and indexes–emerges when it undergoes a self-supervised
learning process.

3.6

Indexing of Major MeSH and Supplementary Concepts

As the literature gets hyper-focused towards specific topics in the context of pandemic, classification to more finegrained indexes becomes critical. Therefore, we also present evaluation of simultaneous indexing of major Mesh and
supplementary concepts. In this regard, the trained models on BioASQ are simply fine-tuned to detect supplementary
concepts of COVID training set in addition to the major mesh indexes. Supplementary concepts are added as new
classes to the potential indexes.
As demonstrated in Table 4 the performance of the baselines is improved by fine-tuning them to detect supplementary
concepts as well. This shows the importance of more fine-grained indexing. In comparison to baselines our model
improved even more with the aid of supplementary concepts.
8

A PREPRINT - O CTOBER 8, 2020

Model
MTI (Default)
MTI (First Line Index)
DeepMeSH
AttentionMeSH
iria
xgx
MeSHmallow
BioTrans (Base) (w/o SSL)
BioTrans (Base) (w/ MLM SSL)
BioTrans (Large) (w/ MLM SSL)

Major MeSH
0.6188
0.6591
0.7732
0.7417
0.5663
0.6202
0.5779
0.6977
0.7283
0.7840

Micro-F
Supp. Concepts
0.7478
0.7247
0.8143
0.7991
0.6127
0.7728
0.6187
0.7513
0.8092
0.8372

Both
0.6581
0.6713
0.79011
0.7551
0.5985
0.6730
0.6004
0.7199
0.7560
0.8067

Table 4: Performance of simultaneous indexing major MeSH and supplementary concepts in the context of COVID-19.
Micro F-measure has been calculated for supplementary concepts and major MeSH separately and jointly.

4

CONCLUSION AND DISCUSSION

In this research, we propose a novel semantic indexing approach based on self-supervised deep representation learning
models to tackle this task in the current health crisis. We present a case study on COVID-19 literature collected
from recently indexed documents in PubMed. We compare the performance of our model with the state-of-the-art
baselines based on flat and hierarchical measures. Our study shows the presented self-supervised model outperforms the
baselines with the small amount of labeled data available. We further evaluate the indexing of supplementary concepts
along with the major MeSH indexes demonstrating the state-of-the-art performance. We also show that the indexing
of supplementary concepts improves MeSH indexing performance of our model explaining the importance of more
fine-grained categorization of documents in the current pandemic situation. In future, we will attempt to continue our
case study as COVID-19 documents are being published and indexed in PubMed. We will mainly focus on improving
the data efficiency and generalization aspects of semantic indexing models as COVID-19 literature is rapidly evolving.
We will also try sophisticated few- and zero-shot learning techniques to better handle newly introduced concepts.

FUNDING
The authors gratefully acknowledge the use of the services of Jetstream cloud, funded by National Science Foundation
(NSF) awards 1445604, and the Cloud Technology Endowed Professorship.

References
[1] George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Michael R
Alvers, Dirk Weissenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopoulos, et al. An overview of
the bioasq large-scale biomedical semantic indexing and question answering competition. BMC bioinformatics,
16(1):138, 2015.
[2] Minlie Huang, Aurélie Névéol, and Zhiyong Lu. Recommending mesh terms for annotating biomedical articles.
Journal of the American Medical Informatics Association, 18(5):660–667, 2011.
[3] James G Mork, Antonio Jimeno-Yepes, and Alan R Aronson. The nlm medical text indexer system for indexing
biomedical literature. In BioASQ@ CLEF, 2013.
[4] Qiao Jin, Haoyang Ding, Linfeng Li, Haitao Huang, Lei Wang, and Jun Yan. Tackling mesh indexing dataset shift
with time-aware concept embedding learning. In International Conference on Database Systems for Advanced
Applications, pages 474–488. Springer, 2020.
[5] Shengwen Peng, Ronghui You, Hongning Wang, Chengxiang Zhai, Hiroshi Mamitsuka, and Shanfeng Zhu.
Deepmesh: deep semantic representation for improving large-scale mesh indexing. Bioinformatics, 32(12):i70–
i79, 2016.
[6] Qiao Jin, Bhuwan Dhingra, William Cohen, and Xinghua Lu. Attentionmesh: Simple, effective and interpretable
automatic mesh indexer. In Proceedings of the 6th BioASQ Workshop A challenge on large-scale biomedical
semantic indexing and question answering, pages 47–56, 2018.
[7] Guangxu Xun, Kishlay Jha, Ye Yuan, Yaqing Wang, and Aidong Zhang. Meshprobenet: a self-attentive probe net
for mesh indexing. Bioinformatics, 35(19):3794–3802, 2019.
[8] Isabel Segura-Bedmar, Adrián Carruana, and Paloma Martínez. Labda at the 2016 bioasq challenge task 4a:
Semantic indexing by using elasticsearch. In Proceedings of the Fourth BioASQ workshop, pages 16–22, 2016.
9

A PREPRINT - O CTOBER 8, 2020

[9] Ilya Zavorin, James Mork, and Dina Demner-Fushman. Using learning-to-rank to enhance nlm medical text
indexer results. In Proceedings of the Fourth BioASQ workshop, pages 8–15, 2016.
[10] Farhad Shokraneh and Tony Russell-Rose. Lessons from covid-19 to future evidence synthesis efforts: first
living search strategy and out of date scientific publishing and indexing industry (submitted). Journal of Clinical
Epidemiology, 2020.
[11] Andre Esteva, Anuprit Kale, Romain Paulus, Kazuma Hashimoto, Wenpeng Yin, Dragomir Radev, and Richard
Socher. Co-search: Covid-19 information retrieval with semantic search, question answering, and abstractive
summarization. arXiv preprint arXiv:2006.09595, 2020.
[12] Kirk Roberts, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman, Kyle Lo, Ian Soboroff, Ellen Voorhees,
Lucy Lu Wang, and William R Hersh. Trec-covid: Rationale and structure of an information retrieval shared task
for covid-19. Journal of the American Medical Informatics Association, 2020.
[13] H Raghav Rao, Naga Vemprala, Patricia Akello, and Rohit Valecha. Retweets of officials’ alarming vs reassuring
messages during the covid-19 pandemic: Implications for crisis management. International Journal of Information
Management, page 102187, 2020.
[14] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert:
A lite bert for self-supervised learning of language representations. In International Conference on Learning
Representations, 2019.
[15] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke
Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint
arXiv:1907.11692, 2019.
[16] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang.
Biobert: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics,
36(4):1234–1240, 2020.
[17] Eirini Papagiannopoulou, Yiannis Papanikolaou, Dimitris Dimitriadis, Sakis Lagopoulos, Grigorios Tsoumakas,
Manos Laliotis, Nikos Markantonatos, and Ioannis Vlahavas. Large-scale semantic indexing and question
answering in biomedicine. In Proceedings of the Fourth BioASQ workshop, pages 50–54, 2016.
[18] George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke, Michael R
Alvers, Dirk Weissenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopoulos, Yannis Almirantis,
John Pavlopoulos, Nicolas Baskiotis, Patrick Gallinari, Thierry Artieres, Axel Ngonga, Norman Heino, Eric
Gaussier, Liliana Barrio-Alvers, Michael Schroeder, Ion Androutsopoulos, and Georgios Paliouras. An overview
of the bioasq large-scale biomedical semantic indexing and question answering competition. BMC Bioinformatics,
16:138, 2015.
[19] Bernd Müller, Christoph Poley, Jana Pössel, Alexandra Hagelstein, and Thomas Gübitz. Livivo–the vertical search
engine for life sciences. Datenbank-Spektrum, 17(1):29–34, 2017.
[20] Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara, Georgios Paliouras, and Ioannis Kakadiaris.
Results of the fifth edition of the bioasq challenge. In BioNLP 2017, pages 48–57, 2017.
[21] Francisco J Ribadas, Luis M De Campos, Vıctor M Darriba, and Alfonso E Romero. Cole and utai at bioasq 2015:
experiments with similarity based descriptor assignment. In Working Notes of CLEF 2015 - Conference and Labs
of the Evaluation forum, Toulouse, France, September 8-11, 2015, 2015.
[22] Ali Foroughi Pour, Maciej Pietrzak, Lori A Dalton, and Grzegorz A Rempała. High dimensional model representation of log-likelihood ratio: binary classification with expression data. BMC bioinformatics, 21:1–27,
2020.
[23] Anastasios Nentidis, Konstantinos Bougiatiotis, Anastasia Krithara, and Georgios Paliouras. Results of the seventh
edition of the bioasq challenge. In Joint European Conference on Machine Learning and Knowledge Discovery in
Databases, pages 553–568. Springer, 2019.
[24] Q. Chen, A. Allot, and Z. Lu. Keep up with the latest coronavirus research. Nature, 579(7798):193, 2020.
[25] Hsiao-Yu Tung, Hsiao-Wei Tung, Ersin Yumer, and Katerina Fragkiadaki. Self-supervised learning of motion
capture. In Advances in Neural Information Processing Systems, pages 5236–5246, 2017.
[26] Ishan Misra and Laurens van der Maaten. Self-supervised learning of pretext-invariant representations. In
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6707–6717, 2020.
[27] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. Xlnet:
Generalized autoregressive pretraining for language understanding. In Advances in neural information processing
systems, pages 5753–5763, 2019.
10

A PREPRINT - O CTOBER 8, 2020

[28] Mirco Ravanelli, Jianyuan Zhong, Santiago Pascual, Pawel Swietojanski, Joao Monteiro, Jan Trmal, and Yoshua
Bengio. Multi-task self-supervised learning for robust speech recognition. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 6989–6993. IEEE, 2020.
[29] Ammara Masood, Adel Al-Jumaily, and Khairul Anam. Self-supervised learning model for skin cancer diagnosis.
In 2015 7th International IEEE/EMBS Conference on Neural Engineering (NER), pages 1012–1015. IEEE, 2015.
[30] Javad Noorbakhsh, Saman Farahmand, Sandeep Namburi, Dennis Caruana, David Rimm, Mohammad Soltaniehha, Kourosh Zarringhalam, Jeffrey H Chuang, et al. Deep learning-based cross-classifications reveal conserved
spatial behaviors within tumor histological images. bioRxiv, page 715656, 2020.
[31] Morteza Safaei Pour, Antonio Mangino, Kurt Friday, Matthias Rathbun, Elias Bou-Harb, Farkhund Iqbal, Sagar
Samtani, Jorge Crichigno, and Nasir Ghani. On data-driven curation, learning, and analysis for inferring evolving
internet-of-things (iot) botnets in the wild. Computers & Security, 91:101707, 2020.
[32] Antonio Mangino, Morteza Safaei Pour, and Elias Bou-Harb. Internet-scale insecurity of consumer internet of
things: An empirical measurements perspective. ACM Transactions on Management Information Systems (TMIS).
[33] Gonzalo De La Torre Parra, Paul Rad, Kim-Kwang Raymond Choo, and Nicole Beebe. Detecting internet of
things attacks using distributed deep learning. Journal of Network and Computer Applications, page 102662,
2020.
[34] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive
learning of visual representations. arXiv preprint arXiv:2002.05709, 2020.
[35] Tianlong Chen, Sijia Liu, Shiyu Chang, Yu Cheng, Lisa Amini, and Zhangyang Wang. Adversarial robustness:
From self-supervised pre-training to fine-tuning. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 699–708, 2020.
[36] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei
Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint
arXiv:1910.10683, 2019.
[37] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are
unsupervised multitask learners. OpenAI Blog, 1(8):9, 2019.
[38] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages
5998–6008, 2017.
[39] Xuemei Yang, Ning Dong, Edward Wai-Chi Chan, and Sheng Chen. Genetic cluster analysis of sars-cov-2 and the
identification of those responsible for the major outbreaks in various countries. Emerging Microbes & Infections,
9(1):1287–1299, 2020.
[40] Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Darrin Eide, Kathryn Funk,
Rodney Michael Kinney, Ziyang Liu, William. Merrill, Paul Mooney, Dewey A. Murdick, Devvret Rishi, Jerry
Sheehan, Zhihong Shen, Brandon Stilson, Alex D. Wade, Kuansan Wang, Christopher Wilhelm, Boya Xie,
Douglas M. Raymond, Daniel S. Weld, Oren Etzioni, and Sebastian Kohlmeier. Cord-19: The covid-19 open
research dataset. ArXiv, 2020.
[41] Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. Mass: Masked sequence to sequence pre-training
for language generation. In International Conference on Machine Learning, pages 5926–5936, 2019.
[42] Iz Beltagy, Kyle Lo, and Arman Cohan. Scibert: A pretrained language model for scientific text. In Proceedings
of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3606–3611, 2019.
[43] Xingheng Wang, Jun Cao, Yao Liu, Shi Gao, and Xue Deng. Text clustering based on the improved tfidf by
the iterative algorithm. In Electrical & Electronics Engineering (EEESYM), 2012 IEEE Symposium on, pages
140–143. IEEE, 2012.
[44] Jiaul H Paik. A novel tf-idf weighting scheme for effective ranking. In Proceedings of the 36th international ACM
SIGIR conference on Research and development in information retrieval, pages 343–352. ACM, 2013.
[45] Ramin Sahba, Nima Ebadi, Mo Jamshidi, and Paul Rad. Automatic text summarization using customizable fuzzy
features and attention on the context and vocabulary. In 2018 World Automation Congress (WAC), pages 1–5.
IEEE, 2018.
[46] Nihar Bendre, Nima Ebadi, John J Prevost, and Peyman Najafirad. Human action performance using deep
neuro-fuzzy recurrent attention model. IEEE Access, 8:57749–57761, 2020.
11

A PREPRINT - O CTOBER 8, 2020

[47] Ignazio Pillai, Giorgio Fumera, and Fabio Roli. Threshold optimisation for multi-label classifiers. Pattern
Recognition, 46(7):2055–2065, 2013.
[48] Benjamin Riedel, Isabelle Augenstein, Georgios P Spithourakis, and Sebastian Riedel. A simple but tough-to-beat
baseline for the fake news challenge stance detection task. arXiv preprint arXiv:1707.03264, 2017.
[49] Akshay Agrawal, Akshay Naresh Modi, Alexandre Passos, Allen Lavoie, Ashish Agarwal, Asim Shankar, Igor
Ganichev, Josh Levenberg, Mingsheng Hong, Rajat Monga, et al. Tensorflow eager: A multi-stage, pythonembedded dsl for machine learning. arXiv preprint arXiv:1903.01855, 2019.
[50] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado,
Andy Davis, Jeffrey Dean, Matthieu Devin, et al. Tensorflow: Large-scale machine learning on heterogeneous
distributed systems. arXiv preprint arXiv:1603.04467, 2016.
[51] Yuan Yao, Lorenzo Rosasco, and Andrea Caponnetto. On early stopping in gradient descent learning. Constructive
Approximation, 26(2):289–315, 2007.
[52] Nima Ebadi, Brandon Lwowski, Mehrad Jaloli, and Paul Rad. Implicit life event discovery from call transcripts
using temporal input transformation network. IEEE Access, 7:172178–172189, 2019.
[53] Aris Kosmopoulos, Ioannis Partalas, Eric Gaussier, Georgios Paliouras, and Ion Androutsopoulos. Evaluation
measures for hierarchical classification: a unified view and novel approaches. Data Mining and Knowledge
Discovery, 29(3):820–865, 2015.

12

