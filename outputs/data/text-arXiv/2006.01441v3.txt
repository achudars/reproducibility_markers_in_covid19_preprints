arXiv:2006.01441v3 [eess.IV] 26 Nov 2020

CT-based COVID-19 Triage: Deep Multitask Learning
Improves Joint Identification and Severity
Quantification
Mikhail Goncharova,b,1 , Maxim Pisova,b,1 , Alexey Shevtsovb,1 , Boris
Shirokikha,b,1 , Anvar Kurmukovb , Ivan Blokhinc , Valeria Cherninac , Alexander
Solovevd , Victor Gombolevskiyc , Sergey Morozovc , Mikhail Belyaeva,∗
a Skolkovo

Institute of Science and Technology, Moscow, Russia
Institute for Information Transmission Problems, Moscow, Russia
c Research and Practical Clinical Center for Diagnostics and Telemedicine Technologies of
the Moscow Health Care Department
d Sklifosovsky Clinical and Research Institute for Emergency Medicine, Moscow, Russia
b Kharkevich

Abstract
The current COVID-19 pandemic overloads healthcare systems, including radiology departments. Though several deep learning approaches were developed
to assist in CT analysis, nobody considered study triage directly as a computer
science problem. We describe two basic setups: Identification of COVID-19 to
prioritize studies of potentially infected patients to isolate them as early as possible; Severity quantification to highlight studies of severe patients and direct
them to a hospital or provide emergency medical care. We formalize these tasks
as binary classification and estimation of affected lung percentage. Though
similar problems were well-studied separately, we show that existing methods
provide reasonable quality only for one of these setups. We employ a multitask
approach to consolidate both triage approaches and propose a convolutional
neural network to combine all available labels within a single model. In contrast with the most popular multitask approaches, we add classification layers
to the most spatially detailed upper part of U-Net instead of the bottom, less
detailed latent representation. We train our model on approximately 2000 publicly available CT studies and test it with a carefully designed set consisting of
32 COVID-19 studies, 30 cases with bacterial pneumonia, 31 healthy patients,
and 30 patients with other lung pathologies to emulate a typical patient flow in
an out-patient hospital. The proposed multitask model outperforms the latentbased one and achieves ROC AUC scores ranging from 0.87 ± 0.01 (bacterial
pneumonia) to 0.97±0.01 (healthy controls) for Identification of COVID-19 and
0.97 ± 0.01 Spearman Correlation for Severity quantification. We release all the
code and create a public leaderboard, where other community members can test
∗ Corresponding

author
Email address: m.belyaev@skoltech.ru (Mikhail Belyaev)
1 Equal contribution

Preprint submitted to Medical Image Analysis

November 30, 2020

their models on our test dataset.
Keywords: COVID-19, Triage, Convolutional Neural Network, Chest
Computed Tomography

1. Introduction
During the first months of 2020, COVID-19 infection spread worldwide and
affected millions of people (Li et al., 2020b). Though a virus-specific reverse
transcription-polymerase chain reaction (RT-PCR) testing remains the gold
standard (Organization et al.), chest imaging, including computed tomography (CT), is helpful in diagnosis and patient management (Bernheim et al.,
2020; Akl et al., 2020; Rubin et al., 2020). Moreover, compared to RT-PCR,
CT has higher sensitivity (98% compared to 71% at p ≤ 0.001) for some cohorts Fang et al. (2020). Fleischner Society has addressed the role of thoracic
imaging in COVID-19, providing recommendations intended to guide medical
practitioners with one scenario including medical triage in moderate-to-severe
clinical features and a high pretest probability of disease (Rubin et al., 2020).
Radiology departments can respond to the pandemic by division into four areas
(contaminated, semi-contaminated, buffer, and clean), strict disinfection and
management criteria (Huang et al., 2020b). The International Society of Radiology surveyed current practices in managing patients with COVID-19 in 50
radiology departments representing 33 countries across all continents. In symptomatic patients with suspected COVID-19, imaging was performed in 89% of
cases, in 34% of cases - chest CT. Faster results than molecular tests (51%) and
easy access (39%) were the main reasons for imaging use (Blažić et al., 2020).
The pandemic dramatically increased the need for medical care and resulted
in the overloading of healthcare systems (Tanne et al., 2020). Many classification and segmentation algorithms were developed to assist radiologists in

Study0001

Study0002

P = 0.97

Study0002

Study0001

P = 0.71

Study0003

Study0004

P = 0.68

Study0004

Automatic
Triage

Study0003

P = 0.11

Study0005

Study0005

P = 0.04

Study0006

Study0006

P = 0.01

Worklist before triage

Worklist after triage

Emergency care

Second wave
(infected)
Third wave
(normal)
Lesion quantification

Figure 1: A schematic representation of the automatic triage process. Left: the chronological
order of the studies. Center: re-prioritized order to highlight findings requiring radiologist’s
attention (P denotes COVID-19 Identification probability). Right: accompanying algorithmgenerated X-ray-like series to assist the radiologist in fast decision making (color bar from
green to red denotes Severity of local COVID-19-related changes).

2

COVID-19 identification and severity quantification, see Sec. 1.1.1. However,
little research has been conducted to investigate automatic image analysis for
triage, i.e. ranking of CT studies. During an outbreak, many CT scans require
rapid decision-making to sort patients into those who need care right now and
those who will need scheduled care (Mei et al., 2020). Therefore, the study list
triage is relevant and may shorten the report turnaround time by increasing
the priority of CT scans with suspected pathology for faster interpretation by
a radiologist compared to other studies, see Fig. 1.
The triage differs from other medical image analysis tasks, as in this case,
automatic programs provide the first reading. The radiologist then becomes
the second reading. Technically, many of the developed methods may provide a
priority score for triage, e.g., output probability of a classifier or the total lesion
volume extracted from a binary segmentation mask. However, these scores must
be properly used. We assume that there are two different triage problems:
1. Identification. The first challenging task is to identify studies of patients
with COVID-19 and prioritize them so the physician can isolate potentially
infected patients as early as possible (Sverzellati et al., 2020).
2. Severity quantification. Second, within COVID-19 patients, a triage algorithm must prioritize those who will require emergency medical care
(Kherad et al., 2020).
Binary classification provides a direct way to formalize Identification, but
the optimal computer science approach to estimate Severity is not as obvious.
It was shown that human-based quantitative analysis of chest CT helps assess
the clinical severity of COVID-19. (Colombi et al., 2020) had quantified affected pulmonary tissue and established a high correlation between the healthy
pulmonary tissue volume and the outcomes (transfer to an intensive care unit
or death). The threshold value for the volume of healthy pulmonary tissue
was 73%. This result and similar ones motivate clinical recommendations in
several countries: COVID-19 patients need to be sorted based on quantitative
evaluation of lung lesions.
In particular, the Russian Federation adopted the following approach (Morozov et al., 2020e): the volume ratio of lesions in each lung is calculated separately
and the maximal ratio is treated as the overall severity score. However, manual binary segmentation of the affected lung tissue is extremely time-consuming
and may take several hours (Shan et al., 2020). For this reason, a visual semiquantitative scale was implemented rather than a fully quantitative one. The
original continuous index is split up into five categories: from CT-0 to CT-4
with a 25% step so that CT-0 corresponds to normal cohort and CT-4 - to
75%-100% of damaged lung tissue. Patients with CT-3 (severe pneumonia) are
hospitalized, and CT-4 (critical pneumonia) are admitted to an intensive care
unit. The scale is based on a visual evaluation of approximate lesion volume in
both lungs (regardless of postoperative changes).
A retrospective study (Morozov et al., 2020b) analyzed the CT 0-4 scores and
lethal outcomes in 13003 COVID-19 patients. The trend of directional changes

3

Study0001

Study0002

Study0003

Study0004

Study0005

Study0006

Figure 2: An example of joint COVID-19 identification and severity estimation by the proposed method for several studies.

in the deceased patient proportion using CT 0-4 score demonstrated a statistically significant result (p < 0.0001). The chance of a lethal outcome increased
from CT-0 to CT-4 by 38% on the average (95% CI 17.1-62.6%). Another retrospective analysis (Petrikov et al., 2020) found a significant correlation between
an increase of CT grade and clinical condition deterioration (r = 0.577).
These two triage strategies, Identification and Severity quantification, are
not mutually exclusive, and their priority may change depending on the patient
population structure and current epidemiological situation.
• An outpatient hospital in an area with a small number of infected patients
may rely on Identification solely.
• An infectious diseases hospital may use Severity quantification to predict
the need for artificial pulmonary ventilation and intensive care units.
• Finally, an outpatient hospital during an outbreak needs both systems to
identify and isolate COVID patients as well as quantify disease severity
and route severe cases accordingly.
This paper explores the automation of both Identification and Severity quantification intending to create a robust system for all scenarios, see Fig. 2.
1.1. Related work
1.1.1. CT analysis for COVID-19 Identification and Severity Estimation
As briefly discussed above, there are two main machine learning-based approaches to analyze COVID-19 chest CTs: identification and severity quantification. In both cases, researchers usually calculate a continuous index of
4

Table 1: Overview of continuous output indices proposed in previous works. The Type column
denotes index type: COVID-19 identification, COVID-19 severity or both. Type of the Identification is given in brackets COVID vs : P - Pneumonia, NP - non-Pneumonia, HC - Healthy
controls, N - Nodules, C - Cancer. The Metric column contains reported ROC AUC values
unless otherwise indicated. Remarks. 1. Accuracy because ROC AUC was not reported. 2.
The metric was provided for the identification problem only. 3. Pearson correlation. 4. The
average volume error, measured in cm3 . 5. The paper does not provide an index, Dice score
for the output masks is reported.

Paper

Ranking index description

Type

Bai et al. (2020)
Kang et al. (2020)
Shi et al. (2020b)
Li et al. (2020a)
Wang et al. (2020a)
Han et al. (2020)
Jin et al. (2020b)
Jin et al. (2020a)
Gozes et al. (2020a)
Amine et al. (2020)
Wang et al. (2020b)
Chen et al. (2020)
Gozes et al. (2020b)
Chaganti et al. (2020)
Huang et al. (2020a)
Shen et al. (2020)
Shan et al. (2020)
Fan et al. (2020)
Tang et al. (2020)

Probabilities of 2.5D EfficientNet
Probabilities of a NN for raidomics
Probabilities of RF for radiomics
Probabilities of 2.5D ResNet50
Probabilities of a 3D Resnet-based NN
Probabilities of a 3D CNN
Probabilities of ResNet50
Custom aggregation of a 2D CNN predicitons
Fractions of affected slices (by 2D ResNet)
Probabilities of 3D Unet (encoder part)
Probabilities of a 3D CNN
2D Bounding boxes + post-processing
A score based on 2D ResNet attention
Affected lung percentage, a combined score
Affected lung percentage by 2D Unet
Affected lung percentage by non trainable CV
Volume of segm. masks by a 3D CNN
Segmentation mask
Random Forrest probabilities

Iden. (P)
Iden. (P)
Iden. (P)
Iden. (P, NP)
Iden. (HC, P)
Iden. (HC, P)
Iden. (HC, P, N)
Iden. (HC, P)
Iden. (HC, C)
Iden. (HC, P)
Iden. (HC)
Iden. (other disease)
Both (fever)
Sev.
Sev.
Sev.
Sev.
Sev.
Sev.

Metric
.95
Acc.1 .96
.94
.96
.97
.99
.99
.97
.99
.97
.96
Acc.1 .99
.952
Corr.3 .95
N/A
Corr.3 .81
Vol.4 10.7
Dice5 .60
.91

COVID-19 presence or severity (depending on their task). An overview of the
existed indices can be found in Tab. 1. Below, we present only some of the
existing CT-based algorithms for a more comprehensive review we refer to (Shi
et al., 2020a).
The majority of reviewed works use a pre-trained network for lung extraction
or bounding box estimation as a necessary preprocessing step. We will skip the
description of this step below for all works.
Identification. Researchers usually treat this problem as binary classification,
e.g. COVID-19 versus all other studies. Likely, the most direct way to classify
CT images with varying slice thicknesses is to train well established 2D convolutional neural networks. For example, authors of (Jin et al., 2020b) trained
ResNet-50 (He et al., 2016a) to classify images using the obtained lung mask.
An interesting and interpretable way to aggregate slice predictions into wholestudy predictions was proposed in (Gozes et al., 2020a), where the number
of affected slices was used as the final output of the model. Also, this work
employed Grad-cam (Selvaraju et al., 2017) to visualize network attention. A
custom slice-level prediction aggregation was proposed in (Jin et al., 2020a) to
filter out false positives.
The need for a post-training aggregation of slice prediction can be avoided
by using 3D convolutional networks, (Han et al., 2020; Wang et al., 2020b).
(Wang et al., 2020a) proposed a two-headed architecture based on 3D-ResNet.
5

This approach is a way to obtain hierarchical classification as the first head
was trained to classify CTs with and without pneumonia. In contrast, the
second one aimed to distinguish COVID-19 from other types of pneumonia.
Alternatively, slice aggregation may be inserted into network architectures to
obtain an end-to-end pipeline, as was proposed in (Li et al., 2020a; Bai et al.,
2020). Within this setup, all slices are processed by a 2D backbone (ResNet50
for (Li et al., 2020a), EfficientNet (Tan and Le, 2019) for (Bai et al., 2020)) while
the final classification layers operate with a pooled version of feature maps from
all slices. Amine et al. (2020) proposed a multi-head architecture to solve both
Segmentation and Identification problems in an end-to-end manner. They have
used a 3D Unet backbone with an additional classification head after the encoder
part. Even though they did not tackle the problem of severity identification,
they demonstrate that solving two tasks jointly could benefit both.
Segmentation. The majority of papers for tackling severity estimation are segmentation based. For example, the total absolute volume of involved lung
parenchyma can be used as a quantitative index (Shan et al., 2020). Relative
volume (i.e., normalized by the total lung volume) is a more robust approach
taking into account the normal variation of lung sizes. Affected lung percentage was estimated in several ways including a non-trainable Computer Vision
algorithm (Shen et al., 2020), 2D Unet (Huang et al., 2020a), and 3D Unet
(Chaganti et al., 2020). Alternatively, an algorithm may predict the severity
directly, e.g., with Random Forrest based on a set of radiomics features (Tang
et al., 2020) or a neural network.
As discussed above, many papers address either COVID-19 identification or
severity estimation. However, little research has been conducted to study both
tasks simultaneously. (Gozes et al., 2020b) proposed an original Grad-cambased approach to calculate a single attention-based score. Though the authors
mentioned both identification and severity quantification in the papers, they do
not provide direct quality metrics for the latter.
1.1.2. Deep learning for triage
As mentioned above, we consider triage to be the process of ordering studies
to be examined by a radiologist. There are two major scenarios where such an
approach can be useful:
• Studies with a high probability of dangerous findings must be prioritized.
The most important example is triage within emergency departments,
where minutes of acceleration may save lives (Faita, 2020), but it may be
useful for other departments as well. For example, the study (Annarumma
et al., 2019) estimates the average reporting delay in chest radiographs as
11.2 days for critical imaging findings and 7.6 days for urgent imaging
findings.
• The majority of studies do not contain critical findings. This is a common
situation for screening programs, e.g., CT-based lung cancer screening
(Team, 2011). In this scenario, triage systems aim to exclude studies
6

with the smallest probability of important findings to reduce radiologists’
workload.
Medical imaging may provide detailed information useful for automatic patient triage, as shown in several studies. (Annarumma et al., 2019) developed
a deep learning-based algorithm to estimate the urgency of imaging findings on
adult chest radiographs. The dataset included 470388 studies annotated in an
automated way via text report mining. The Inception v3 architecture (Szegedy
et al., 2016) was used to model clinical priority as ordinal data via solving several
binary classification problems as proposed in (Lin and Li, 2012). The average
reporting delay was reduced to 2.7 and 4.1 days for critical and urgent imaging
findings correspondingly in a simulation on historical data.
A triage system for screening mammograms, another 2D image modality,
was developed in (Yala et al., 2019). The authors draw attention to reducing
the radiologist’s load by maximizing system recall. The underlying architecture
is ResNet-18 (He et al., 2016a), which was trained on 223109 screening mammograms. The model achieved 0.82 ROC AUC on the whole test population
and demonstrated the capability to reduce workload by 20% while preserving
the same level of diagnostic accuracy.
Prior research confirms that deep learning may assist in triage of more complex images such as volumetric CT. A deep learning-based system for rapid
diagnosis of acute neurological conditions caused by stroke or traumatic brain
injury was proposed in (Titano et al., 2018). A 3D adaption of ResNet-50 (Korolev et al., 2017) analyzed head CT images to predict critical findings. To
train the model, the authors utilized 37236 studies; labels were also generated
by text reports mining. The classifier’s output probabilities served as ranks for
triage, and the system achieved ROC AUC 0.73-0.88. Stronger supervision was
investigated in (Chang et al., 2018), where authors used 3D masks of all hemorrhage subtypes of 10159 non-contrast CT. The detection and quantification of
5 subtypes of hemorrhages were based on a modified Mask R-CNN (He et al.,
2017) extended by pyramid pooling to map 3D input to 2D feature maps (Lin
et al., 2017). More detailed and informative labels combined with an accurately
designed method provide reliable performance as ROC AUC varies from 0.85 to
0.99 depending on hemorrhage type and size. A similar finding was reported in
(De Fauw et al., 2018) for optical coherence tomography (OCT). The authors
employed a two-stage approach. First, 3D-Unet (Çiçek et al., 2016) was trained
on 877 studies with dense 21-class segmentation masks. Then output maps for
another 14884 cases were processed by a 3D version of DenseNet (Huang et al.,
2017) to identify urgent cases. The obtained combination of two networks provided excellent performance achieving 0.99 ROC AUC.
1.2. Contribution
First, we highlighted the need for triage systems of two types for COVID-19
identification and severity quantification. We studied existing approaches and
demonstrated that a system trained for one task shows low performance in the
other. Second, we developed a multitask learning-based approach to create a
7

triage system for both types of problems, which achieves top results in both
tasks. Finally, we provided a framework for reproducible comparison of various
models (see the details below).
1.2.1. Reproducible research
A critical meta-review (Wynants et al., 2020) of machine learning models for
COVID-19 diagnosis highlights low reliability and high risk of biased results for
all 27 reviewed papers, mostly due to a non-representative selection of control
patients and poor analysis of results, including possible model overfitting. The
authors used (Wolff et al., 2019) PROBAST (Prediction model Risk Of Bias
Assessment Tool), a systematic approach to validate the performance of machine
learning-based approaches in medicine and identified the following issues.
1. Poor patient structure of the validation set, including several studies where
control studies were sampled from different populations.
2. Unreliable annotation protocol where only one rater assessed each study
without subsequent quality control or the model output influenced annotation.
3. Lack of comparison with other well-established methods for similar tasks.
4. Low reproducibility due to several factors such as unclear model description and incorrect validation approaches (e.g., slice-level prediction rather
than study-level prediction).
The authors concluded the paper with a call to share data and code to develop an
established system for validating and comparing different models collaboratively.
Though (Wynants et al., 2020) is an early review and does not include
many properly peer-reviewed papers mentioned above, we agree that current
algorithmic research lacks reproducibility. Indeed, only one paper (Fan et al.,
2020) among 18 papers from section 1.1.1 used open datasets for training and
released the code. We aim to follow the best practices of reproducible research
and address these issues in the following way.
1. We selected fully independent test dataset and retrieved all COVID-19
positive and COVID-19 negative cases from the same population and the
same healthcare system, see details in Sec. 3.5.
2. Two raters annotated the test data independently. If raters contours are
not aligned, the meta-rater requested annotation correction, see Sec. 3.5.
3. We carefully selected several key ideas from the reviewed works and implemented them within the same pipeline as our method, see Sec. 2.
4. We publicly release the code to share technical details of the compared
architectures2 .
Finally, we used solely open datasets for training; the test set includes some
private images. We have also established an online leaderboard3 to compare
different segmentation and classification methods on our test data.
2 https://github.com/neuro-ml/covid-19-multitask
3 https://github.com/neuro-ml/covid-19-multitask/wiki/Leaderboard

8

2. Method
As discussed in Sec. 1 method should solve two tasks: identification of
COVID-19 cases and ranking them in descending order of severity. Therefore,
we structure Sec. 2 as follows.
• In Sec. 2.1 we describe lungs segmentation as a common preprocessing
step for all methods.
• In Sec. 2.2 we tackle the severity quantification task. We describe methods which predict segmentation mask of lesions caused by COVID-19 and
provide a severity score based on that.
• In Sec. 2.3 we discuss two straightforward baselines for the identification
task. First is to use segmentation results and identify patients with nonempty lesions masks as COVID-19 positive. Second is to use separate
neural network for classification of patients into COVID-19 positive or
negative. However, as we show in Sec. 5 these methods yield poor identification quality, especially due to false positive alarms in patients with
bacterial pneumonia.
• In Sec. 2.4 we propose a multitask model which achieves better COVID19 identification results than the baselines. In particular, as we show
in Sec. 5, this model successfully distinguishes between COVID-19 and
bacterial pneumonia cases.
• In Sec. 2.5 we introduce quality metrics for both identification and severity
quantification tasks to formalize the comparison of the methods.
2.1. Lungs segmentation
We segment lungs in two steps. First, we predict single binary mask for
both lungs including pathological findings, e.g. ground-glass opacity, consolidation, nodules and pleural effusion. Then we split the obtained mask into
separate left and right lungs’ masks. Binary segmentation is performed via
fully-convolutional neural network in a standard fashion. Details of the architecture and training setup are given in Section 4.2.
On the second step voxels within the lungs are clustered using k-means
algorithm (k = 2) with Euclidean distance as a metric between voxels. Then
we treat resulting clusters as separate lungs.
2.2. COVID-19 severity quantification
To quantify COVID-19 severity we solve COVID-19-specific lesions segmentation task. Using predicted lungs’ and lesions’ masks, we calculate the lesions’
to lung’s volume ratio for each lung and use the maximum of two ratios as a
final severity score for triage, according to recommendations discussed in Sec. 1.

9

Threshold-based. As a baseline for lesions segmentation, we choose the thresholdingbased method (since pathological tissues are denser than healthy ones, corresponding CT voxels have greater intensities in Hounsfield Units). The method
consists of three steps. The first step implements thresholding: voxels with intensity value between HUmin and HUmax within the lung mask are assigned to
the positive class. At the second step, we apply Gaussian blur with smoothing
parameter σ to the resulting binary mask and reassign the positive class to voxels
with values greater than 0.5. Finally, we remove 3D binary connected components with volumes smaller than Vmin . The hyperparameters HUmin = −700,
HUmax = 300, σ = 4 and Vmin = 0.1% are chosen via a grid-search in order
to maximize the average Dice score between predicted and ground truth lesions
masks for series from training dataset.
U-Net. The de facto standard approach for medical image segmentation is the
U-Net model (Ronneberger et al., 2015). We trained two U-Net-based architectures for lung parenchyma involvement segmentation which we refer to as 2D
U-Net and 3D U-Net. 2D U-Net independently processes the axial slices of the
input 3D series. 3D U-Net processes 3D sub-patches of size 160 × 160 × 160 and
then stacks predictions for individual sub-patches to obtain prediction for the
whole input 3D series. Thus, we do not need to downsample the input image
under the GPU memory restrictions. For each model, we replace plain 2D and
3D convolutional layers with 2D and 3D residual convolutional blocks (He et al.,
2016b), correspondingly. Both models were trained using the standard binary
cross-entropy loss (see other details in Sec. 4.3).
2.3. COVID-19 Identification
We formalize COVID-19 identification task as a binary classification of 3D
CT series. CT series of patients with verified COVID-19 are positive class. CT
series of patients with other lung diseases, e.g. bacterial pneumonia, non-small
cell lung cancer, etc., as well as normal patients are negative class.
Segmentation-based. One possible approach is to base the decision rule on the
segmentation results: classify a series as positive if the segmentation-based
severity score exceeds some threshold. We show that this leads to a tradeoff between severity quantification and identification qualities: models which
yield the best ranking results perform worse in terms of classification, and vice
versa. Moreover, despite some segmentation-based methods accurately classify
COVID-19 positive and normal cases, all of them yields a significant number of
false positives in patients with bacterial pneumonia (see Sec. 5.1).
ResNet50. Another approach is to tackle the classification task separately from
segmentation and explicitly predict the probability that a given series is COVID19 positive. The advantage of this strategy is that we only need weak labels
for model training, which are much more available than ground truth segmentations.

10

Pyramid Pooling

FC Layers

Slice-wise backbone

U-Net

Feature
map

Identification Score

Severity Score
(Affected Lung Percentage)

Stack

2D Feat

ure Map
s

Slice-wise 2D Convolutions
Segmen
tation M
ask

Figure 3: Schematic representation of the Multitask-Spatial-1 model. Identification score is the
probability of being a COVID-19 positive series; Severity score is calculated using predicted
lesions’ mask and precomputed lungs’ masks.

To assess the performance of this approach we follow the authors of (Li et al.,
2020a; Bai et al., 2020) and train the ResNet50 (He et al., 2016b) which takes a
series of axial slices as input and independently extracts feature vectors for each
slice. After that the feature vectors are combined via a pyramid max-pooling
operation (He et al., 2014) along all the slices. The resulting vector is passed
into two fully connected layers followed by sigmoid activation which predicts
the final COVID-19 probability for the whole series. In our paper, we denote
this architecture as ResNet50 (see other details in Section 4.4).
2.4. Multitask
Baselines for the identification task described in Sec 2.3 do not perform
well, as we show in Sec. 5. Therefore, we propose to solve the identification task
simultaneously with the segmentation task via a single two-headed convolutional
neural network.
The segmentation part of the architecture is slice-wise 2D U-Net model. As
earlier, its output is used for the evaluation of the severity score.
The classification head shares a common intermediate feature map (per slice)
with the segmentation part. These feature maps are stacked and aggregated into
a feature vector via a pyramid pooling layer (He et al., 2014). Finally, two fully
connected layers followed by sigmoid activation transform the feature vector to
the COVID-19 probability.
Following (Amine et al., 2020), the shared feature maps can be the outputs
of the U-Net’s encoder and have no explicit spatial structure in the axial plane.
We refer to this approach as Multitask-Latent. In contrast, we argue that the
identification task is connected to the segmentation task and the classification
model can benefit from the spatial structure of the input features. Therefore, we
propose to share the feature map from the very end of the U-Net architecture,
as shown in Fig. 3. We refer to the resulting architecture as Multitask-Spatial-1.
More generally, shared feature maps can be taken from the l-th upper level of the
U-Net’s decoder. Together they form a 3D spatial feature map, which is aligned
with the input 3D series downsampled in the axial plane by a factor of 2l−1 . We
denote this approach as Multitask-Spatial-l. Since 2D U-Net architecture has 7
levels, l can vary from 1 to 7.

11

As a loss function we optimize a weighted combination of binary cross entropies for segmentation and classification (see other details in Section 4).
2.5. Metrics
To assess the quality of classification of patients into positive, i.e. infected
by COVID-19, and negative, i.e. with other lung pathologies or normal, we use
areas under the ROC-curves (ROC-AUC) calculated on several subsamples of
the test sample described in Sec. 3.5.
• The first subsample contains only COVID-19 positive and healthy subjects, while studies with other pathological findings are excluded (ROCAUC COVID-19 vs Normal).
• The second subsample contains only patients infected by COVID-19 or
bacterial pneumonia (ROC-AUC COVID-19 vs Bac. Pneum.).
• The third subsample contains COVID-19 positive patients and patients
with lung nodules typical for non-small cell lung cancer (ROC-AUC COVID19 vs Nodules).
• The last ROC-AUC is calculated on the whole test sample (ROC AUC
COVID-19 vs All others).
ROC-curves are obtained by thresholding the predicted probabilities for ResNet50
and multitask models, and by thresholding the predicted severity score for
segmentation-based methods.
We evaluate the quality of ranking studies in order of descending COVID-19
severity on the test subsample, which contains only COVID-19 positive patients.
As a quality metric, we use Spearman’s rank correlation coefficient (Spearman’s
ρ) between the severity scores ytrue calculated for ground truth segmentations
and the predicted severity scores ypred . It is defined as
ρ(ytrue , ypred ) =

cov(rg(ytrue ), rg(ypred ))
,
σ(rg(ytrue )) · σ(rg(ypred ))

where cov(·, ·) is a sample covariance, σ(·) is a sample standard deviation and
rg(y) is the vector of ranks, i.e. resulting indices of y elements after their sorting
in the descending order.
To evaluate the COVID-19 lesions segmentation quality we use Dice score
coefficient between the predicted and the ground truth segmentation masks.
Similar to Spearman’s ρ, we evaluate the mean Dice score only for COVID-19
positive cases.
3. Data
We used several public datasets in our experiments:
• NSCLC-Radiomics and LUNA16 to create a robust lung segmentation
algorithm.
12

• Mosmed-1110, MedSeg-29 and NSCLC-Radiomics to train and validate
all the triage models.
• Mosmed-Test as a hold-out test set to assess the final performance of all
the methods.
3.1. Mosmed-1110
1110 CT scans from Moscow outpatient clinics were collected from 1st of
March, 2020 to 25th of April, 2020, within the framework of outpatient computed tomography centers in Moscow, Russia (Morozov et al., 2020a).
Scans were performed on Canon (Toshiba) Aquilion 64 units in with standard scanner protocols and, particularly 0.8 mm inter-slice distance. However,
the public version of the dataset contains every 10th slice of the original study,
so the effective inter-slice distance is 8mm.
The quantification of COVID-19 severity in CT was performed with the
visual semi-quantitative scale adopted in the Russian Federation and Moscow
in particular (Morozov et al., 2020e). According to this grading, the dataset
contains 254 images without COVID-19 symptoms. The rest is split into 4
categories: CT1 (affected lung percentage 25% or below, 684 images), CT2
(from 25% to 50%, 125 images), CT3 (from 50% to 75%, 45 images), CT4 (75%
and above, 2 images).
Radiologists performed an initial reading of CT scans in clinics, after which
experts from the advisory department of the Center for Diagnostics and Telemedicine
(CDT) independently conducted the second reading as a part of a total audit
targeting all CT studies with suspected COVID-19.
Additionally, 50 CT scans were annotated with binary masks depicting regions of interest (ground-glass opacities and consolidation).
3.2. MedSeg-29
MedSeg web-site4 shares 2 publicly available datasets of annotated volumetric CT images. The first dataset consists of 9 volumetric CT scans from a
web-site5 that were converted from JPG to Nifti format. The annotations of this
dataset include lung masks and COVID-19 masks segmented by a radiologist.
The second dataset consists of 20 volumetric CT scans shared by (Jun et al.,
2020). The left and rights lungs, and infections are labeled by two radiologists
and verified by an experienced radiologist.
3.3. NSCLC-Radiomics
NSCLC-Radiomics dataset (Kiser et al., 2020; Aerts et al., 2015) represents
a subset of The Cancer Imaging Archive NSCLC Radiomics collection (Clark
et al., 2013). It contains left and right lungs segmentations annotated on 3D
4 https://medicalsegmentation.com/covid19/
5 https://radiopaedia.org/articles/covid-19-3

13

thoracic CT series of 402 patients with diseased lungs. Pathologies – lung cancerous nodules, atelectasis and pleural effusion – are included in the lung volume
masks. Pleural effusion and cancerous nodules are also delineated separately,
when present.
Automatic approaches for lungs segmentation often perform inconsistently
for patients with diseased lungs, while it is usually the main case of interest.
Thus, we use NSCLC-Radiomics to create robust for pathological cases lungs
segmentation algorithm. Other pathologies, e.g. pneumothorax, that are not
presented in NSCLC-Radiomics could also lead to poor performance of lungs
segmentation. But the appearance of such pathologies among COVID-19 cases
is extremely rare. For instance, it is less than 1% for pneumothorax (Zantah
et al., 2020). Therefore, we ignore the possible presence of other pathology
cases, while training and evaluating our algorithm.
3.4. LUNA16
LUNA16 (Jacobs et al., 2016) is a public dataset for cancerous lung nodules segmentation. It includes 888 annotated 3D thoracic CT scans from the
LIDC/IDRI database (Armato III et al., 2011). Scans widely differ by scanner manufacturers (17 scanner models), slice thicknesses (from 0.6 to 5.0 mm),
in-plane pixel resolution (from 0.461 to 0.977 mm), and other parameters. Annotations for every image contain binary masks for the left and right lungs, the
trachea and main stem bronchi, and the cancerous nodules. The lung and trachea masks were originally obtained using an automatic algorithm (van Rikxoort
et al., 2009) and the lung nodules were annotated by 4 radiologists (Armato III
et al., 2011). We also excluded 7 cases with absent or completely broken lung
masks and extremely noisy scans.
3.5. Mosmed-Test
We created a test set as a combination of public and private datasets to
ensure the following properties
• All cases are full series without missing slices and/or lacking metadata
fields (e.g., information about original Hounsfield units).
• Data for all classes comes from the same population and the same healthcare system to avoid domain shifts within test data.
COVID-19 positive. It is a subsample (Morozov et al., 2020d) of 42 CT studies
collected from 20 patients in an infectious diseases hospital during the second
half of February 2020, at the beginning of the Russian outbreak. We removed
5 cases with artifacts related to patients’ movements while scanning. The remaining 37 cases were independently assessed by two raters (radiologists with 2
and 5 years of experience) who have annotated regions of interest (ground-glass

14

opacities and consolidation) via MedSeg6 annotation tool for every of the 37
Mosmed-Test series.
During this annotation process, we identified that 5 cases have no radiological
signs of COVID-19, so we removed these studies from the list of COVID-19
positives. We iteratively verified annotations based on two factors: Dice Score
between two rates and missing (by one of the raters) large connected components
of the mask. The discrepancy between the two raters has been analyzed until
we reached a consensus – 0.87 ± 0.17 Dice Score over 32 COVID-19 infected
cases.
It’s also important to note that (Morozov et al., 2020d) data were collected
at inpatient clinics, whereas Mosmed-1110 is a subset of Moscow out-patient
clinics database created from two to six weeks later, which guarantees that
studies are not duplicated.
Bacterial pneumonia. We randomly selected 30 studies from a list of patients
with radiological signs of community-acquired bacterial pneumonia; images were
acquired in 2019. This database is a private one as we do not aware of public
bacterial pneumonia data coming from this population.
Lung nodules. We use a subset of a public dataset (Morozov et al., 2020c)
containing 500 chests CT scans randomly selected from patients over 50 years
of age. We selected 30 cases randomly among cases with radiologically verified
lung nodules.
Normal controls. This subset consists of two parts: 5 cases mentioned above
from (Morozov et al., 2020d) without radiological signs of COVID-19 and 26
studies (Morozov et al., 2020c) without lung nodules larger than 5mm and other
lung pathologies.
4. Experiments
We design our experiments in order to objectively compare all the triage
models described in Sec. 2. For that purposes all the methods are evaluated
using the mean values and the standard deviations of the same quality metrics
defined in Sec. 2.5 on the same hold-out test dataset described in Sec. 3.5. We
believe, that the experimental design for training neural networks for triage
described in Sec. 4.3 and 4.4 exclude overfitting.
All computational experiments were conducted on Zhores supercomputer
Zacharov et al. (2019).
6 https://www.medseg.ai/

15

4.1. Preprocessing
In all our experiments we use the same preprocessing applied separately for
each axial slice: rescaling to a pixel spacing of 2 × 2mm and intensity normalization to the [0, 1] range.
In our COVID-19 identification and segmentation experiments we crop the
input series to the bounding box of the lungs’ mask predicted by our lungs
segmentation network.
We further show (Sec. 5) that this preprocessing is sufficient for all models.
Despite the diversity of the training dataset, all models successfully adapt to
the test dataset.
4.2. Lungs segmentation
For the lungs segmentation task we choose a basic U-Net (Ronneberger et al.,
2015) architecture with 2D convolutional layers, individually apply to each axial
slice of an incoming series. The model was trained on NSCLC-Radiomics and
LUNA16 datasets for 16k batches of size 30. We use Adam (Kingma and Ba,
2014) optimizer with default parameters and an initial learning rate of 0.001,
which was decreased to 0.0001 after 8k batches.
We assess the model’s performance using 3-fold cross-validation and additionally using MedSeg-29 dataset as hold-out set. Dice Score of cross-validation
is 0.976 ± 0.023 for both LUNA16 and NSCLC-Radiomics datasets, and 0.962 ±
0.023 only on NSCLC-Radiomics dataset. The latter result confirms our model
to be robust to the cases with pleural effusion. Dice Score on MedSeg-29 dataset
is 0.976±0.013, which shows the robustness of our model to the COVID-19 cases.
4.3. COVID-19 segmentation
We use all the available 79 images of COVID-19 positive patients with annotated lesions masks (50 images from Mosmed-1110 and 29 images from MedSeg29) to train the threshold-based, 2D U-Net, 3D U-Net models.
Additionally, we train the 2D U-Net’s architecture on the same 79 cases
along with 402 images from the NSCLC-Radiomics dataset. These 402 images
were acquired long before the COVID-19 pandemic, therefore we assume that
ground truth segmentations for them are zero masks. During training this model
we resample series such that batches contain approximately equal numbers of
COVID-19 positive and negative cases. We refer to this model as 2D U-Net+.
2D U-Net and 2D U-Net+ were trained for 15k batches using Adam (Kingma
and Ba, 2014) optimizer with default parameters and an initial learning rate of
0.0003. Each batch contains 5 series of axial slices. 3D U-Net was optimized via
plain stochastic gradient descent for 10k batches using a learning rate of 0.01.
Each batch consists of 16 3D patches.
In order to estimate mean values and standard deviations of models’ quality
metrics defined in Sec. 2.5 each segmentation network was trained 3 times with
different random seeds. Resulting networks were evaluated on the hold-out test
dataset, described in Sec. 3.5.

16

4.4. ResNet50 and multitask models
The remaining 806 positive images without ground truth segmentations
and 254 negative images from the Mosmed-1110 and 402 negative images from
NSCLC-Radiomics were split 5 times in a stratified manner into a training set
and a validation set. Each of the 5 validation sets contains 30 random images.
For each split we train the ResNet50 and the classification heads of MultitaskLatent, Multitask-Spatial-1 and Multitask-Spatial-4 models on the defined training set, while segmentation heads of the multitask models were trained on the
same 79 images, as 2D U-Net (see Sec. 4.3).
For each network on each training epoch we evaluate the ROC-AUC between
the predicted COVID-19 probabilities and the ground truth labels on the validation set. We save the networks’ weights which resulted in the highest validation
ROC-AUC during training. For all the multitask models as well as for ResNet50
top validation ROC-AUCs exceeded 0.9 for all splits.
All the networks were trained for 30k batches using Adam (Kingma and Ba,
2014) optimizer with default parameters and an initial learning rate of 0.0003
reduced to 0.0001 after 24k batches. Each batch contained 5 series of axial
slices.
During training the multitask models we resample examples such that batches
contained an approximately equal number of examples which were used to penalize either classification or segmentation head. However, we multiplied by
0.1 the loss for the classification head, because it resulted in better validation
ROC-AUCs.
For each of 5 splits, we evaluated each trained network on the hold-out test
dataset described in Sec. 3.5. We report the resulting mean values and standard
deviations of the quality metrics in Sec. 5.
5. Results
In this section we report and discuss the results of the experiments described
in Sec. 4. In Tab. 2 we compare all the methods described in Sec. 2 using quality
metrics defined in Sec. 2.5 and evaluated on the test dataset described in Sec. 3.5.

17

Table 2: Quantitative comparison of all the methods discussed in Section 2. Trade-off between
qualities of COVID-19 identification and ranking by severity is observed for segmentationbased methods. The proposed Multitask-Spatial-1 model yields the best identification results.
Results are given as mean ± std.
ROC-AUC (COVID-19 vs ·)

Spearman’s ρ

Dice Score

vs All others

vs Normal

vs Bac. Pneum.

vs Nodules

Thresholding

.51 ± .00

.68 ± .00

.46 ± .00

.45 ± .00

.92 ± .00

.42 ± .00

3D U-Net

.76 ± .02

.89 ± .02

.59 ± .01

.79 ± .03

.97 ± .01

.65 ± .00

2D U-Net

.78 ± .01

.93 ± .01

.62 ± .01

.79 ± .00

.97 ± .00

.63 ± .00

2D U-Net+

.86 ± .01

.98 ± .01

.68 ± .02

.91 ± .01

.80 ± .03

.59 ± .01

ResNet50

.62 ± .19

.67 ± .21

.55 ± .13

.65 ± .22

N/A

N/A

Multitask-Latent

.79 ± .06

.84 ± .05

.73 ± .06

.80 ± .07

.97 ± .00

.61 ± .02

Multitask-Spatial-4

.89 ± .03

.94 ± .03

.83 ± .05

.91 ± .03

.98 ± .00

.61 ± .02

Multitask-Spatial-1

.93 ± .01

.97 ± .01

.87 ± .01

.93 ± .00

.97 ± .01

.61 ± .02

5.1. Segmentation-based methods
In this subsection we discuss the performance of four methods: the thresholdbased baseline, 3D U-Net, 2D U-Net and 2D U-Net+.
We expect two major weaknesses of the threshold-based method: False Positive (FP) predictions on the vessels and bronchi, and inability to distinguish
COVID-19 related lesions from other pathological findings. It is clearly seen
from the extremely low ROC-AUC scores (Tab. 2). One could also notice massive FP predictions even in healthy cases (Fig. 4, column B). However, the
method often provides a reasonable segmentation of the lesion area (Fig. 4,
column A).
Neural networks considerably outperform the threshold-based baseline in
terms of any quality metric. We observe neither quantitative (Tab. 2) nor
qualitative (Fig. 4) significant difference between 2D U-Net’s and 3D U-Net’s
performances. They yield accurate severity scores within the COVID-19 positive
population (Spearman’s ρ = 0.97). However, severity scores quantified for the
whole test dataset do not allow to accurately distinguish between COVID-19
positive cases and cases with other pathological findings (ROC-AUC COVID-19
vs Bac. Pneum. ≈ 0.6, ROC-AUC COVID-19 vs Nodules = 0.79) due to FP
segmentations (Fig. 4, columns B and C).
As one could expect, training on images with non-small cell lung cancer tumors from NSCLS-Radiomics dataset results in the enhancement of ROC-AUC
vs Nodules (0.91 for 2D U-Net+ compared to 0.79 for 2D U-Net). Interestingly, in this experiment we observe a degradation in terms of Spearman’s ρ for
ranking of COVID-19 positive cases (0.8 for 2D U-Net+ compared to 0.97 for
2D U-Net). We conclude that one should account for this trade-off and use an
appropriate training setup depending on the task.
All the segmentation-based models perform poorly in terms of classification into COVID-19 and bacterial pneumonia (ROC AUC COVID-19 vs Bac.
Pneum. ≤ 0.7). This motivates to discuss the other methods.

18

Figure 4: Examples of axial CT slices from the test dataset along with ground truth annotations (first row) and predicted masks (second row) of COVID-19-specific lesions. Column A:
COVID-19 positive case; Column B : normal case; Column C : case with bacterial pneumonia.
Lesions’ masks are represented by the contours of their borders for clarity.

5.2. ResNet50
Despite that validation ROC-AUCs for all the trained ResNet50 networks
exceed 0.9, their performance on the test dataset is extremely unstable: ROCAUC COVID-19 vs All varies from 0.43 to 0.85 (also see standard deviations in
Tab. 2).
5.3. Multitask models
In this subsection we discuss the performance of Multitask-Latent, MultitaskSpatial-4 and the proposed Multitask-Spatial-1 models on identification, segmentation and severity quantification tasks in comparison to each other, ResNet50
and segmentation-based methods.
As seen from mean values and standard deviations of ROC-AUC scores in
Tab. 2, Multitask-Latent model yields better and more stable identification results than ResNet50. Both these models classify the latent representations of
the input images. We show that sharing these features with the segmentation
head, i.e. decoder of the U-Net architecture improves the classification quality.
Moreover, one can see in Tab. 2 that this effect is enhanced by sharing the spatial feature maps from the upper levels of the U-Net’s decoder. The proposed
Multitask-Spatial-1 architecture (see Fig. 3) with shallow segmentation and classification heads directly sharing the same spatial feature map shows the top classification results. Especially, it most accurately distinguish between COVID-19
and other lung diseases (ROC-AUC COVID-19 vs Bac. Pneum. = 0.87, ROCAUC COVID-19 vs Nodules = 0.93).

19

Negative

Positive

COVID-19

1

31

Bac. Pneum.

22

8

Nodules

26

4

Normal

31

0

Ranked predicted positives

Ground truth label

COVID-19 Prediction

Predicted severity score
Figure 5: COVID-19 triage: identification of COVID-19 positive patients (left) and ranking
them in the descending order of severity (right) via the proposed single Multitask-Spatial1 model. In the right plot bars correspond to the ranked studies. Absolute values of the
predicted affected lungs fractions are represented as bars’ lengths along the x-axis. The bars’
colors denote ground truth labels.

As seen in Tab. 2 and Fig. 4 there is no significant difference in terms of
segmentation and severity quantification qualities between the multitask models
and the neural networks for single segmentation task.
Therefore, the single proposed Multitask-Spatial-1 model can be applied for
both triage problems: identification of COVID-19 patients followed by their
ranking according to the severity. In Fig. 5 we visualize these two steps of
triage pipeline for the test dataset, described in Sec. 3.5. One can see the
several false positive alarms in cases with non-COVID-19 pathological findings.
We discuss the possible ways to resolve them in Sec. 6. The overall pipeline
for triage, including preprocessing, lungs segmentation, and multitask inference
takes 8s and 20s using nVidia V100 and GTX 980 GPUs respectively.
6. Discussion
We have highlighted two important scores: COVID-19 Identification and
Severity and discussed their priorities in different clinical scenarios. We have
shown that these two scores aren’t aligned well. Existing methods operate either
with Identification or Severity and demonstrate deteriorated performance for
the other task. We have presented a new method for joint estimation of COVID19 Identification and Severity score and showed that the proposed multitask
architecture achieves top quality metrics for both tasks simultaneously. Finally,
we have released the code and used public data for training, so our results are
fully reproducible.

20

26%
CT-3

50

CT-2

<0.1%
25

CT-2

CT-3
CT-4

CT-1

CT-1

17%

0

Expected severity classes’ fractions

Predicted affected lungs fraction

CT-4
75

Figure 6: Predicted Severity for weakly annotated cases from the Mosmed-1110 dataset. Note
the inconsistency of visual subjective estimation. The lines denote the correspondence between
some visually underestimated cases and their representative axial slices.

However, as we show in Fig. 5 the proposed triage pipeline yields a relatively
small number of false-positive alarms in patients with non-COVID-19 lungs
diseases. But in practice, usage of an automated triage system always implies
second reading. Therefore these false positives can be resolved by a radiologist.
Moreover, it can be impossible to diagnose COVID-19 based only on CT image
as PCR testing remains a gold-standard method. Thus, we conclude that the
identification part may be used as a high sensitivity first reading tool to highlight
patients with suspicious changes in their lungs.
The role of the Severity Quantification part is more straightforward. As
we mentioned in Section 1, radiologists perform the severity classification into
groups from CT0 (no COVID-19 related lesions) and CT1 (up to 25% of lungs
affected) to CT4 (more than 75%) in a visual semi-quantitative fashion. We
believe that such estimation may be highly subjective and may contain severe
discrepancies. To validate this assumption, we additionally analyzed Mosmed1110, which includes not only 50 segmentation masks but also 1110 multiclass
labels CT0-CT4. Within our experiments, we binarized these labels and effectively removed information about COVID-19 severity. We examined mask predictions for the remaining 1050 cases, excluding healthy patients (CT0 group)
and grouped the predictions by these weak labels, as shown in Fig. 6. An expert
radiologist validated analyzed the most extreme mismatches visualized in Fig. 6
and confirmed the correctness of our model’s predictions. As we see, the severity
of many studies was highly underestimated during the visual semi-quantitative
analysis. This result implies that deep-learning-based medical image analysis
algorithms, including the proposed method, are great intelligent radiologists’
assistants in a fast and reliable estimation of time-consuming biomarkers such
as COVID-19 severity.

21

References
Aerts, H., Velazquez, E.R., Leijenaar, R.T., Parmar, C., Grossmann, P., Cavalho, S., Bussink, J., Monshouwer, R., Haibe-Kains, B., Rietveld, D., et al.,
2015. Data from nsclc-radiomics. The cancer imaging archive .
Akl, E.A., Blazic, I., Yaacoub, S., Frija, G., Chou, R., Appiah, J.A., Fatehi, M.,
Flor, N., Hitti, E., Jafri, H., et al., 2020. Use of chest imaging in the diagnosis
and management of covid-19: a who rapid advice guide. Radiology , 203173.
Amine, A., Modzelewski, R., Li, H., Ruan, S., 2020. Multi-task deep learning
based ct imaging analysis for covid-19 pneumonia: Classification and segmentation. Computers in Biology and Medicine 126.
Annarumma, M., Withey, S.J., Bakewell, R.J., Pesce, E., Goh, V., Montana,
G., 2019. Automated triaging of adult chest radiographs with deep artificial
neural networks. Radiology 291, 196–202.
Armato III, S.G., McLennan, G., Bidaut, L., McNitt-Gray, M.F., Meyer, C.R.,
Reeves, A.P., Zhao, B., Aberle, D.R., Henschke, C.I., Hoffman, E.A., et al.,
2011. The lung image database consortium (lidc) and image database resource
initiative (idri): a completed reference database of lung nodules on ct scans.
Medical physics 38, 915–931.
Bai, H.X., Wang, R., Xiong, Z., Hsieh, B., Chang, K., Halsey, K., Tran, T.M.L.,
Choi, J.W., Wang, D.C., Shi, L.B., et al., 2020. Ai augmentation of radiologist
performance in distinguishing covid-19 from pneumonia of other etiology on
chest ct. Radiology , 201491.
Bernheim, A., Mei, X., Huang, M., Yang, Y., Fayad, Z.A., Zhang, N., Diao, K.,
Lin, B., Zhu, X., Li, K., et al., 2020. Chest ct findings in coronavirus disease19 (covid-19): relationship to duration of infection. Radiology , 200463.
Blažić, I., Brkljačić, B., Frija, G., 2020. The use of imaging in covid-19—results
of a global survey by the international society of radiology. European radiology
, 1–9.
Chaganti, S., Balachandran, A., Chabin, G., Cohen, S., Flohr, T., Georgescu,
B., Grenier, P., Grbic, S., Liu, S., Mellot, F., et al., 2020. Quantification of
tomographic patterns associated with covid-19 from chest ct. arXiv preprint
arXiv:2004.01279 .
Chang, P.D., Kuoy, E., Grinband, J., Weinberg, B.D., Thompson, M., Homo,
R., Chen, J., Abcede, H., Shafie, M., Sugrue, L., et al., 2018. Hybrid 3d/2d
convolutional neural network for hemorrhage evaluation on head ct. American
Journal of Neuroradiology 39, 1609–1616.
Chen, J., Wu, L., Zhang, J., Zhang, L., Gong, D., Zhao, Y., Hu, S., Wang,
Y., Hu, X., Zheng, B., et al., 2020. Deep learning-based model for detecting
2019 novel coronavirus pneumonia on high-resolution computed tomography:
a prospective study. medRxiv .
22

Çiçek, Ö., Abdulkadir, A., Lienkamp, S.S., Brox, T., Ronneberger, O., 2016.
3d u-net: learning dense volumetric segmentation from sparse annotation, in:
International conference on medical image computing and computer-assisted
intervention, Springer. pp. 424–432.
Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S.,
Phillips, S., Maffitt, D., Pringle, M., et al., 2013. The cancer imaging archive
(tcia): maintaining and operating a public information repository. Journal of
digital imaging 26, 1045–1057.
Colombi, D., Bodini, F.C., Petrini, M., Maffi, G., Morelli, N., Milanese, G.,
Silva, M., Sverzellati, N., Michieletti, E., 2020. Well-aerated lung on admitting chest ct to predict adverse outcome in covid-19 pneumonia. Radiology ,
201433.
De Fauw, J., Ledsam, J.R., Romera-Paredes, B., Nikolov, S., Tomasev, N.,
Blackwell, S., Askham, H., Glorot, X., O’Donoghue, B., Visentin, D., et al.,
2018. Clinically applicable deep learning for diagnosis and referral in retinal
disease. Nature medicine 24, 1342–1350.
Faita, F., 2020. Deep learning in emergency medicine: Recent contributions and
methodological challenges. Emergency Care Journal 16.
Fan, D.P., Zhou, T., Ji, G.P., Zhou, Y., Chen, G., Fu, H., Shen, J., Shao, L.,
2020. Inf-net: Automatic covid-19 lung infection segmentation from ct scans.
arXiv preprint arXiv:2004.14133 .
Fang, Y., Zhang, H., Xie, J., Lin, M., Ying, L., Pang, P., Ji, W., 2020. Sensitivity
of chest ct for covid-19: comparison to rt-pcr. Radiology , 200432.
Gozes, O., Frid-Adar, M., Greenspan, H., Browning, P.D., Zhang, H., Ji,
W., Bernheim, A., Siegel, E., 2020a. Rapid ai development cycle for the
coronavirus (covid-19) pandemic: Initial results for automated detection &
patient monitoring using deep learning ct image analysis. arXiv preprint
arXiv:2003.05037 .
Gozes, O., Frid-Adar, M., Sagie, N., Zhang, H., Ji, W., Greenspan, H., 2020b.
Coronavirus detection and analysis on chest ct with deep learning. arXiv
preprint arXiv:2004.02640 .
Han, Z., Wei, B., Hong, Y., Li, T., Cong, J., Zhu, X., Wei, H., Zhang, W.,
2020. Accurate screening of covid-19 using attention based deep 3d multiple
instance learning. IEEE Transactions on Medical Imaging , 1–1.
He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask r-cnn, in: Proceedings
of the IEEE international conference on computer vision, pp. 2961–2969.
He, K., Zhang, X., Ren, S., Sun, J., 2014. Spatial pyramid pooling in deep
convolutional networks for visual recognition. CoRR abs/1406.4729. URL:
http://arxiv.org/abs/1406.4729, arXiv:1406.4729.
23

He, K., Zhang, X., Ren, S., Sun, J., 2016a. Deep residual learning for image
recognition, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, pp. 770–778.
He, K., Zhang, X., Ren, S., Sun, J., 2016b. Deep residual learning for image
recognition, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, pp. 770–778.
Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely
connected convolutional networks, in: Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 4700–4708.
Huang, L., Han, R., Ai, T., Yu, P., Kang, H., Tao, Q., Xia, L., 2020a. Serial
quantitative chest ct assessment of covid-19: deep-learning approach. Radiology: Cardiothoracic Imaging 2, e200075.
Huang, Z., Zhao, S., Li, Z., Chen, W., Zhao, L., Deng, L., Song, B., 2020b. The
battle against coronavirus disease 2019 (covid-19): emergency management
and infection control in a radiology department. Journal of the american
college of radiology .
Jacobs, C., Setio, A.A.A., Traverso, A., van Ginneken, B., 2016. Lung nodule
analysis 2016. URL: https://luna16.grand-challenge.org.
Jin, C., Chen, W., Cao, Y., Xu, Z., Zhang, X., Deng, L., Zheng, C., Zhou, J.,
Shi, H., Feng, J., 2020a. Development and evaluation of an ai system for
covid-19 diagnosis. medRxiv .
Jin, S., Wang, B., Xu, H., Luo, C., Wei, L., Zhao, W., Hou, X., Ma, W., Xu, Z.,
Zheng, Z., et al., 2020b. Ai-assisted ct imaging analysis for covid-19 screening:
Building and deploying a medical ai system in four weeks. medRxiv .
Jun, M., Cheng, G., Yixin, W., Xingle, A., Jiantao, G., Ziqi, Y., Minqing, Z.,
Xin, L., Xueyuan, D., Shucheng, C., Hao, W., Sen, M., Xiaoyu, Y., Ziwei,
N., Chen, L., Lu, T., Yuntao, Z., Qiongjie, Z., Guoqiang, D., Jian, H., 2020.
COVID-19 CT Lung and Infection Segmentation Dataset. URL: https:
//doi.org/10.5281/zenodo.3757476, doi:10.5281/zenodo.3757476.
Kang, H., Xia, L., Yan, F., Wan, Z., Shi, F., Yuan, H., Jiang, H., Wu, D., Sui,
H., Zhang, C., et al., 2020. Diagnosis of coronavirus disease 2019 (covid-19)
with structured latent multi-view representation learning. IEEE transactions
on medical imaging .
Kherad, O., Moret, B.M., Fumeaux, T., 2020. Computed tomography (ct)
utility for diagnosis and triage during covid-19 pandemic. Revue medicale
suisse 16, 955.
Kingma, D.P., Ba, J., 2014. Adam: A method for stochastic optimization. arXiv
preprint arXiv:1412.6980 .

24

Kiser, K., Ahmed, S., Stieb, S., et al., 2020. Data from the thoracic volume
and pleural effusion segmentations in diseased lungs for benchmarking chest
ct processing pipelines [dataset]. The Cancer Imaging Archive .
Korolev, S., Safiullin, A., Belyaev, M., Dodonova, Y., 2017. Residual and plain
convolutional neural networks for 3d brain mri classification, in: 2017 IEEE
14th International Symposium on Biomedical Imaging (ISBI 2017), IEEE. pp.
835–838.
Li, L., Qin, L., Xu, Z., Yin, Y., Wang, X., Kong, B., Bai, J., Lu, Y., Fang,
Z., Song, Q., et al., 2020a. Artificial intelligence distinguishes covid-19 from
community acquired pneumonia on chest ct. Radiology , 200905.
Li, Q., Guan, X., Wu, P., Wang, X., Zhou, L., Tong, Y., Ren, R., Leung, K.S.,
Lau, E.H., Wong, J.Y., et al., 2020b. Early transmission dynamics in wuhan,
china, of novel coronavirus–infected pneumonia. New England Journal of
Medicine .
Lin, H.T., Li, L., 2012. Reduction from cost-sensitive ordinal ranking to
weighted binary classification. Neural Computation 24, 1329–1367.
Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S., 2017.
Feature pyramid networks for object detection, in: Proceedings of the IEEE
conference on computer vision and pattern recognition, pp. 2117–2125.
Mei, X., Lee, H.C., Diao, K.y., Huang, M., Lin, B., Liu, C., Xie, Z., Ma, Y.,
Robson, P.M., Chung, M., et al., 2020. Artificial intelligence–enabled rapid
diagnosis of patients with covid-19. Nature Medicine , 1–5.
Morozov, S., Andreychenko, A., Pavlov, N., Vladzymyrskyy, A., Ledikhova, N.,
Gombolevskiy, V., Blokhin, I., Gelezhe, P., Gonchar, A., Chernina, V.Y.,
2020a. Mosmeddata: Chest ct scans with covid-19 related findings dataset.
arXiv preprint arXiv:2005.06465 .
Morozov, S., Gombolevskiy, V., Chernina, V., Blokhin, I., Mokienko, O., Vladzimirskiy, A., Belevskiy, A., Protsenko, D., Lysenko, M., Zayratyants, O.,
Nikonov, E., 2020b. Prediction of lethal outcomes in covid-19 cases based on
the results chest computed tomography. Tuberculosis and Lung Diseases 98.
doi:10.21292/2075-1230-2020-98-6-7-14.
Morozov, S., Kulberg, N., Gombolevskiy, V., Ledikhova, N., Sokolina, E.,
Vladzymyrskyy, A., Bardin, A., 2020c. Mosmeddata: 500 lung cancer chest
ct. URL: https://storage.yandexcloud.net/selftest/For Publication
v3.zip.
Morozov, S., Protsenko, D., Smetanina, S., Ambrosi, O., Andreychenko, A., Balanyuk, E., Vladzymyrskyy, A., Gombolevskiy, V., Ledikhova, N., Lobanov,
M., Pavlov, N., 2020d. Mosmeddata: Imaging studies of patients with covid19 infection, 2020, v. 1.0. URL: https://mosmed.ai/datasets/covid19.
25

Morozov, S.P., Protsenko, D., Smetanina, S.e.a., 2020e. Imaging of coronavirus
disease (covid-19): Organization, methodology, interpretation: Preprint no.
cdt - 2020 - ii. version 2 of 17.04.2020.
Organization, W.H., et al., . Clinical management of covid-19. who reference
number: Who/2019-ncov/clinical/2020.5. 2020.[internet] 2020.
Petrikov, S., Popugaev, K., Barmina, T., Zabavskaya, O., Sharifullin, F., Kokov,
L., 2020. Comparison of clinical data and computed tomography semiotics of
the lungs in covid-19. Tuberculosis and Lung Diseases 98. doi:10.21292/207
5-1230-2020-98-7-14-25.
van Rikxoort, E.M., de Hoop, B., Viergever, M.A., Prokop, M., van Ginneken,
B., 2009. Automatic lung segmentation from thoracic computed tomography
scans using a hybrid approach with error detection. Medical physics 36, 2934–
2947.
Ronneberger, O., Fischer, P., Brox, T., 2015. U-net: Convolutional networks
for biomedical image segmentation, in: International Conference on Medical
image computing and computer-assisted intervention, Springer. pp. 234–241.
Rubin, G., Ryerson, C., Haramati, L., Sverzellati, N., Kanne, J., 2020. others,“the role of chest imaging in patient management during the covid-19
pandemic: a multinational consensus statement from the fleischner society,”.
Chest .
Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D.,
2017. Grad-cam: Visual explanations from deep networks via gradient-based
localization, in: Proceedings of the IEEE international conference on computer vision, pp. 618–626.
Shan, F., Gao, Y., Wang, J., Shi, W., Shi, N., Han, M., Xue, Z., Shi, Y., 2020.
Lung infection quantification of covid-19 in ct images with deep learning.
arXiv preprint arXiv:2003.04655 .
Shen, C., Yu, N., Cai, S., Zhou, J., Sheng, J., Liu, K., Zhou, H., Guo, Y.,
Niu, G., 2020. Quantitative computed tomography analysis for stratifying
the severity of coronavirus disease 2019. Journal of Pharmaceutical Analysis
.
Shi, F., Wang, J., Shi, J., Wu, Z., Wang, Q., Tang, Z., He, K., Shi, Y., Shen,
D., 2020a. Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19. IEEE Reviews in Biomedical
Engineering .
Shi, F., Xia, L., Shan, F., Wu, D., Wei, Y., Yuan, H., Jiang, H., Gao, Y.,
Sui, H., Shen, D., 2020b. Large-scale screening of covid-19 from community
acquired pneumonia using infection size-aware classification. arXiv preprint
arXiv:2003.09860 .

26

Sverzellati, N., Milanese, G., Milone, F., Balbi, M., Ledda, R.E., Silva, M., 2020.
Integrated radiologic algorithm for covid-19 pandemic. J Thorac Imaging .
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., 2016. Rethinking
the inception architecture for computer vision, in: Proceedings of the IEEE
conference on computer vision and pattern recognition, pp. 2818–2826.
Tan, M., Le, Q.V., 2019. Efficientnet: Rethinking model scaling for convolutional neural networks. arXiv preprint arXiv:1905.11946 .
Tang, Z., Zhao, W., Xie, X., Zhong, Z., Shi, F., Liu, J., Shen, D., 2020. Severity
assessment of coronavirus disease 2019 (covid-19) using quantitative features
from chest ct images. arXiv preprint arXiv:2003.11988 .
Tanne, J.H., Hayasaki, E., Zastrow, M., Pulla, P., Smith, P., Rada, A.G., 2020.
Covid-19: how doctors and healthcare systems are tackling coronavirus worldwide. Bmj 368.
Team, N.L.S.T.R., 2011. The national lung screening trial: overview and study
design. Radiology 258, 243–253.
Titano, J.J., Badgeley, M., Schefflein, J., Pain, M., Su, A., Cai, M., Swinburne,
N., Zech, J., Kim, J., Bederson, J., et al., 2018. Automated deep-neuralnetwork surveillance of cranial images for acute neurologic events. Nature
medicine 24, 1337–1341.
Wang, J., Bao, Y., Wen, Y., Lu, H., Luo, H., Xiang, Y., Li, X., Liu, C., Qian,
D., 2020a. Prior-attention residual learning for more discriminative covid-19
screening in ct images. IEEE Transactions on Medical Imaging .
Wang, X., Deng, X., Fu, Q., Zhou, Q., Feng, J., Ma, H., Liu, W., Zheng, C.,
2020b. A weakly-supervised framework for covid-19 classification and lesion
localization from chest ct. IEEE Transactions on Medical Imaging , 1–1.
Wolff, R.F., Moons, K.G., Riley, R.D., Whiting, P.F., Westwood, M., Collins,
G.S., Reitsma, J.B., Kleijnen, J., Mallett, S., 2019. Probast: a tool to assess the risk of bias and applicability of prediction model studies. Annals of
internal medicine 170, 51–58.
Wynants, L., Van Calster, B., Bonten, M.M., Collins, G.S., Debray, T.P.,
De Vos, M., Haller, M.C., Heinze, G., Moons, K.G., Riley, R.D., et al., 2020.
Systematic review and critical appraisal of prediction models for diagnosis
and prognosis of covid-19 infection. medRxiv .
Yala, A., Schuster, T., Miles, R., Barzilay, R., Lehman, C., 2019. A deep learning
model to triage screening mammograms: a simulation study. Radiology 293,
38–46.

27

Zacharov, I., Arslanov, R., Gunin, M., Stefonishin, D., Pavlov, S., Panarin, O., Maliutin, A., Rykovanov, S., Fedorov, M., 2019. ’Zhores’ –
petaflops supercomputer for data-driven modeling, machine learning and artificial intelligence installed in skolkovo institute of science and technology.
arXiv:1902.07490.
Zantah, M., Castillo, E.D., Townsend, R., Dikengil, F., Criner, G.J., 2020.
Pneumothorax in covid-19 disease-incidence and clinical characteristics. Respiratory Research 21, 1–9.

28

