arXiv:2005.12093v2 [math.ST] 13 Aug 2020

Mixing properties of integer-valued GARCH processes

Paul Doukhan
Université Cergy-Pontoise
UMR 8088 Analyse, Géométrie et Modélisation
2, avenue Adolphe Chauvin
95302 Cergy-Pontoise Cedex
France
E-mail: doukhan@cyu.fr

Naushad Mamode Khan
University of Mauritius
Department of Economics and Statistics
Reduit 80837
Mauritius
E-mail: n.mamodekhan@uom.ac.mu

Michael H. Neumann
Friedrich-Schiller-Universität Jena
Institut für Mathematik
Ernst-Abbe-Platz 2
D – 07743 Jena
Germany
E-mail: michael.neumann@uni-jena.de

Abstract
We consider models for count variables with a GARCH-type structure. Such a process
consists of an integer-valued component and a volatility process. Using arguments for contractive Markov chains we prove that this bivariate process has a unique stationary regime.
Furthermore, we show absolute regularity (β-mixing) with geometrically decaying coefficients for the count process. These probabilistic results are complemented by a statistical
analysis and a few simulations.

2010 Mathematics Subject Classification: Primary 60G10; secondary 60J05.
Keywords and Phrases: Absolute regularity, coupling, GARCH, integer-valued process,
mixing, Skellam distribution.
Short title: Mixing of INGARCH processes.
version: August 14, 2020

1

1. Introduction and notation
Models involving integer-valued random variables have attracted increasing attention in
the recent years. In most cases, the random variables are assumed to be non-negative, since
they represent numbers of counts as e.g. the series of road traffic accidents, the monthly
or annual numbers of deaths due to accidents or diseases, or more recently, the striking
daily numbers of infected people and deaths due the novel corona virus. Sometimes, it
is however necessary to allow for both non-negative and negative integer-valued random
variables. A typical field of application is the description of score differences in sports,
e.g. the number of goals of the home team minus that of the away team. Another common example is that of price changes in finance, such as the tick by tick data in a Trade
and Quote database, that are often represented as a combination of positive and negative
integer values. Furthermore, similar types of observations also appear in differenced series
that are initially non-stationary. While in many applications a serial dependence between
the observations is not taken into account, we consider models which allow to describe and
exploit dependencies between consecutive variables. In view of their popularity in financial
time series analysis and because of their flexibility we focus here on models with a GARCHtype structure. Adapting the structure of the classical GARCH model by Bollerslev (1986),
Fokianos and Tjøstheim (2011, 2012) considered such models for non-negative count variables and investigated conditional maximum likelihood estimators of the corresponding
parameters. These authors assumed that the count variable Xt at time t conditioned on
the past has a Poisson distribution with an intensity λt which itself is random and depends
on lagged values of the count and intensity processes. Since in case of a Poisson distribution
the variance is equal to the mean, a GARCH-type structure is imposed by the equation
λt = ω + α1 Xt−1 + ⋯ + αp Xt−p + β1 λt−1 + ⋯ + βq λt−q

(1.1)

2
2
vt = f (Xt−1
, . . . , Xt−p
, vt−1 , . . . , vt−q ).

(1.2)

or by nonlinear variants, λt = fθ (Xt−1 , . . . , Xt−q , λt−1 , . . . , λt−q ), where θ is a suitable parameter.
In this paper, we consider once more processes with a GARCH-type structure. In contrast to the papers mentioned above, we allow for integer-valued variables which can attain
both non-negative and negative values. The most prominent example is the distribution
introduced by Skellam (1946), which is the distribution of the difference of two independent Poisson variates with respective parameters λ1 and λ2 , In the special case of λ1 = λ2
considered by Irwin (1937), the corresponding distribution has zero mean. Therefore and
in contrast to (1.1), the conditional mean is no longer suitable to generate a GARCH-type
structure. We will focus on second moments and consider processes where the integer-valued
variables Xt have a conditional distribution Qvt where ∫ x2 dQv (x) = v and
Alomani et al. (2018) considered such a Skellam-GARCH process of order p = q = 1 and
derived the estimating equations for a conditional maximum likelihood estimator of the
parameters. However, perhaps because of the absence of suitable probabilistic tools for
such models, they did not provide a further analysis of the asymptotic properties of this
estimator. These authors also provided an overview of related results and applied the model
to differences of non-negative data of counts of monthly drug crimes.
In this contribution, we primarily focus on stochastic properties such as existence and
uniqueness of a stationary distribution and absolute regularity of integer-valued GARCH
processes. In the related case of Poisson-GARCH processes with linear or nonlinear specifications λt = f (Xt−1 , . . . , Xt−p , λt−1 , . . . , λt−q ), there are several forerunners of the present
work and it turns out that we can build on the methods derived there. Mixing properties

2

of such processes have been derived for a first time in Neumann (2011), for INGARCH(1,1)
processes under a contractive condition. This has been generalized in Doukhan and Neumann
(2019) for the INGARCH(p,q) case and under a weaker semi-contractive condition which resulted in a somewhat unusual subexponential decay of the mixing coefficients. Doukhan, Leucht, and Neumann
(2020) proved absolute regularity of the count process again in the INGARCH(1,1) case but
allowing a possibly non-stationary (explosive) behavior of the process. Finally, Neumann
(2020) proved absolute regularity with an exponential decay of the mixing coefficients for
INGARCH(p,q) processes under a fully contractive condition,
q

p

∣f (x1 , . . . , xp , λ1 , . . . , λq ) − f (x′1 , . . . , x′p , λ′1 , . . . , λ′q )∣ ≤ ∑ ci ∣xi − x′i ∣ + ∑ dj ∣λj − λ′j ∣, (1.3)
j=1
p
∑i=1 ci

i=1

where c1 , . . . , cp , d1 , . . . , dq are non-negative constants are such that
+ ∑qj=1 dj < 1.
We will also impose the contractive condition (1.3) on the volatility function f , however, in
contrast to the papers mentioned above, the arguments of this function reflect second-order
properties of the process (Xt )t . Note that (Yt )t and (Zt )t with Yt = (Xt , . . . , Xt−p+1 , vt , . . . , vt−q+1 )
2
and Zt = (Xt2 , . . . , Xt−p+1
, vt , . . . , vt−q+1 ) are both (first-oder) Markov chains. We show in
Section 2 that the contractive condition on f yields a contraction property for (Zt )t in
terms of a suitable Wasserstein metric. This implies by the Banach fixed point theorem
that (Zt )t possesses a unique stationary distribution, and a simple extra argument shows
that the same property holds true for the process (Yt )t which is of actual interest here. Furthermore, we use the contraction property once more to prove almost effortlessly absolute
regularity (β-mixing) with exponentially decaying coefficients of the count process (Xt )t .
We are convinced that these results can serve as a basis for further work with such
models without any hassle. As an example, population dynamics can be considered after
differentiation, in order to rate the speed or the acceleration of the evolution of species
under consideration; indeed both characteristics may be either positive or negative. As
an illustration of their usefulness, we apply in Section 3 our results to prove asymptotic
normality of a least squares estimator of the parameters of a Skellam-ARCH model. All
proofs and a few auxiliary results are collected in a final Section 4.
2. Main results
2.1. Assumptions and a preview of the results. We consider a class of integer-valued
processes (Xt )t∈Z defined on some probability space (Ω, F, P), where, for all t ∈ Z,
Xt ∣ Ft−1 ∼ Qvt ,
vt =

(2.1a)

2
2
, vt−1 , . . . , vt−q ),
, . . . , Xt−p
f (Xt−1

(2.1b)

and Fs = σ(Xs , λs , Xs−1 , λs−1 , . . .) denotes the σ-field generated by the random variables
up to time s. Assuming that f takes values in some set V ⊆ [0, ∞), this function has to
be defined on Np0 × V q . The parameter vt stands for the conditional second moment of Xt ,
i.e. the family of distributions (Qv )v∈V on (Z, P(Z)) is parametrized such that
2
∫ x dQv (x) = v

∀v ∈ V.

(2.1c)

A frequently considered special case is that of a linear model of order p, q, where
p

q

i=1

j=1

f (x1 , . . . , xp , v1 , . . . , vq ) = ω + ∑ αi xi + ∑ βj vj .

(2.2)

It is clear that the processes Y = (Yt )t∈Z and Z = (Zt )t∈Z with Yt = (Xt , . . . , Xt−p+1 , vt , . . . , vt−q+1 )
2
, vt , . . . , vt−q+1 ) are time-homogeneous Markov chains with state
and Zt = (Xt2 , . . . , Xt−p+1

3

spaces S = Zp × V q and S ≥ = Np0 × V q , respectively. The following conditions ensure existence and uniqueness of a stationary distribution of (Zt )t∈Z , and eventually of (Yt )t∈Z as
well. Furthermore, they also yield absolute regularity of the count process (Xt )t∈Z .
p

q

i=1

j=1

(A1) There exist non-negative constants c1 , . . . , cp , d1 , . . . , dq such that ∑ ci + ∑ dj < 1
and
p

q

i=1

j=1

∣f (x1 , . . . , xp , v1 , . . . , vq ) − f (x′1 , . . . , x′p , v1′ , . . . , vq′ )∣ ≤ ∑ ci ∣xi − x′i ∣ + ∑ dj ∣vj − vj′ ∣
holds for all (x1 , . . . , xp , λ1 , . . . , λq ), (x′1 , . . . , x′p , λ′1 , . . . , λ′q ) ∈ S ≥ .
(A2) The family of distributions (Qv )v∈V is increasing in the following sense: If, v < v ′ ,
X ∼ Qv , and X ′ ∼ Qv′ , then ∣X∣ is stochastically not greater than ∣X ′ ∣, i.e.
P (∣X∣ ≤ k) ≥ P (∣X ′ ∣ ≤ k),

∀k ∈ N.

Examples
1) Symmetric Skellam distributions
Let, for v ∈ V , Qv = Skellam(v/2, v/2) be a Skellam distribution with parameters v/2,
v/2, i.e. Qv is the distribution of two independent Poisson variates with parameter
v/2 each. Suppose that X1 , X2 ∼ Pois(v/2) are independent. Then
2
∫ x dQv (x) = var(X1 − X2 ) = var(X1 ) + var(X2 ) = v,

i.e. (2.1c) is satisfied. To prove that (A2) is fulfilled by the family (Qv )v∈V , suppose
that v < v ′ . If Y ∼ Skellam(v/2, v/2) and Z ∼ Skellam((v ′ − v)/2, (v ′ − v)/2) are
independent, it follows from the properties of Poisson distributions that Y + Z ∼
Skellam(v ′ /2, v ′ /2). Since the probability mass function of Y is symmetric and
unimodal (see e.g. Alzaid and Omair (2010)) we have that
P (∣Y ∣ ≤ k) ≥ P (∣Y + l∣ ≤ k),

∀(l, k) ∈ Z × N0 ,

which implies that
P (∣Y ∣ ≤ k) ≥ ∑ P (∣Y + l∣ ≤ k)P (Z = l) = P (∣Y + Z∣ ≤ k),
l∈Z

∀k ∈ N0 .

Hence, ∣Y ∣ is stochastically not greater than ∣Y + Z∣.
2) Mixtures of symmetric Skellam distributions
Let G be the distribution of a non-negative random variable with ∫[0,∞) x dG(x) =
µ ∈ (0, ∞).
Then
vx vx
Qv = ∫
Skellam ( , ) dG(x)
2µ 2µ
[0,∞)
is a mixture of symmetric Skellam distributions. We have that
2
∫ x dQv (x) = ∫

[0,∞)

2
∫ x d Skellam (

vx vx
vx
, ) dG(x) = ∫
dG(x) = v,
2µ 2µ
[0,∞) µ

4

and, for v < v ′ ,

vx vx
, )({−k, . . . , k}) dG(x)
2µ 2µ
[0,∞)
v′ x v′ x
)({−k, . . . , k}) dG(x)
≥ ∫
Skellam (
,
[0,∞)
2µ 2µ
= Qv′ ({−k, . . . , k}),

Qv ({−k, . . . , k}) = ∫

Skellam (

i.e. (2.1c) and (A2) are satisfied.
A notable special case is that of a zero-inflated Skellam distribution, where B ∼ G
follows a Bernoulli distribution with parameter p ∈ (0, 1). If B and X ∼ Skellam(v/(2p), v/(2p))
are independent, then BX has a zero-inflated Skellam distribution. Such a distribution was used by Karlis and Ntzoufras (2006) and Andersson and Karlis (2014)
to account for an excess of zero counts in certain medical data.
3) Poisson distributions
2
2
If
0 if and only if λ =
√ X ∼ Pois(λ), then EX = λ + λ. This is equal to v > √
v + 1/4 − 1/2. In order to obey (2.1c) we choose Qv = Pois( v + 1/4 − 1/2). For
√
√
√
v < v ′ we have that v + 1/4 − 1/2 < v ′ + 1/4 − 1/2. Since X ∼ Pois( v + 1/4 − 1/2)
√
is stochastically not greater than X ∼ Pois( v ′ + 1/4 − 1/2) we see that condition
(A2) is satisfied.
4) Mixtures of Poisson distributions
Let, as in Example 2, G be the distribution function of a non-negative random
∞
variable with ∫0 x dG(x) = µ ∈ (0, ∞). Then
√
∞
Pois ( vx/µ + 1/4 − 1/2) dG(x)
Qv = ∫
0

is a mixture of Poisson distributions. Then condition (A2) is obviously fulfilled.
Furthermore, since
√
vx
2
2
∫ x dQv (x) = ∫[0,∞) ∫ x d Pois ( vx/µ + 1/4 − 1/2) dG(x) = ∫[0,∞) µ dG(x) = v
we see that (2.1c) is also satisfied. Poisson distributions can be used for modeling
data from various fields, e.g. the number of financial transactions within a certain
time period or the number of claims in an insurance context. When dealing with
a collection of individual transactions corresponding to different trading strategies
or with a collection of claim numbers from persons with different features (age,
health state,...) an appropriate mixture of Poisson distributions seems to be more
adequate. Notable special cases are that of a zero-inflated Poisson distribution
which appears in case of G a Bernoulli distribution with parameter p ∈ (0, 1) or a
negative binomial distribution, if G has a Gamma distribution. A negative binomial
distribution is often preferred to a Poisson distribution if data are overdispersed,
i.e. if their variance is greater than their mean (as this is the case for all mixed
Poison distributions).
5) Binomial distributions
A Bin(n, p) distribution (p ∈ (0, 1)) can be used for modeling underdispersed data
since its variance np(1 − p) is less than its mean np. To satisfy (2.1c), we set
Qv = Bin (n, g(v)),

where g∶ (0, n2 ) → (0, 1) is a strictly monotonic function such that
2
∫ x d Bin(n, g(v)) = ng(v) + n(n − 1)(g(v)) = v.
2

5

To see that (A2) is fulfilled, let U1 , . . . , Un be independent and uniformly distributed on [0, 1]. Let v, v ′ ∈ (0, n2 ). Then X ∶= ∑ni=1 1{Ui ≤g(v)} ∼ Qv and X ′ ∶=
∑ni=1 1{Ui ≤g(v′ )} ∼ Qv′ . If v < v ′ , then it follows from the construction that X ≤ X ′
with probability one which implies that X is stochastically not greater than X ′ .
6) Some asymmetric distributions over Z
Let Qv ba any of the above distributions and let Y ∼ Qv and R be independent,
where P (R ∈ {−1, 1}) = 1. If P (R = 1) ≠ 1, then the distributions of the random
variable X = RY is asymmetric over Z and obeys (2.1c). The corresponding family
of distributions satisfies A2) as soon as (Qv )v∈V does.
In the following we derive a contraction property of (Zt )t in terms of a suitable Wasserstein
metric. As shown in Eberle (2019, Chapter 3) and Douc et al. (2018, Theorem 20.3.4),
this implies by the Banach fixed point theorem that (Zt )t possesses a unique stationary
distribution. A simple extra argument shows that the same property holds true for the
process (Yt )t which is of actual interest here. Furthermore, we use the contraction property
once more to prove almost effortlessly absolute regularity (β-mixing) with exponentially
decaying coefficients of the count process (Xt )t .
2.2. Contraction. First of all, we transfer the contraction condition (A1) for the intensity
process into a contraction property for the Zt .
We consider the following metric on S ≥ :
p

q

i=1

j=1

∆γ,δ ((x1 , . . . , xp , v1 , . . . , vq ), (x′1 , . . . , x′p , v1′ , . . . , vq′ )) = ∑ γi ∣xi − x′i ∣ + ∑ δj ∣vj − vj′ ∣,
where γ1 , . . . , γp , δ1 , . . . , δq are strictly positive constants. Let y = (x1 , . . . , xp , v1 , . . . , vq ),
y ′ = (x′1 , . . . , x′p , v1′ , . . . , vq′ ) ∈ S be arbitrary and, accordingly z = (x21 , . . . , x2p , v1 , . . . , vq ),
2
2
z ′ = (x′1 , . . . , x′p , v1′ , . . . , vq′ ) ∈ S ≥ . With an appropriate choice of γ1 , . . . , γp , δ1 , . . . , δq , we
can construct random vectors Y = (X, x1 , . . . , xp−1 , λ, λ1 , . . . , λq−1 ) and
̃ F̃, P̃) such that
Y ′ = (X ′ , x′1 , . . . , x′p−1 , λ′ , λ′1 , . . . , λ′q−1 ) on a suitable probability space (Ω,
P̃Y = PYt ∣Yt−1 =y = PYt ∣Zt−1 =z ,

′
′
′
P̃Y = PYt ∣Yt−1 =y = PYt ∣Zt−1 =z ,

(2.3)

and, for Z = (X 2 , x1 , . . . , xp−1 , λ, λ1 , . . . , λq−1 ) and Z ′ = (X , x′1 , . . . , x′p−1 , λ′ , λ′1 , . . . , λ′q−1 ),
′2

̃ γ,δ (Z, Z ′ ) ≤ κ ∆γ,δ (z, z ′ )
E∆

(2.4)

holds for some κ < 1. Actually, according to the model equation (2.1b), we have to set
̃ F̃, P̃)
v = f (x21 , . . . , x2p , v1 , . . . , vq ) and v ′ = f (x′1 2 , . . . , x′p 2 , v1′ , . . . , vq′ ). Suppose that (Ω,
admits the construction of independend random variables U and V , both following a uniform
2
distribution on [0, 1]. Let Gv and Gv′ be the respective distribution functions of PXt ∣vt =v
2
′
2
′
−1
and PXt ∣vt =v . We define versions of X 2 and X ′ by W ∶= G−1
v (U ) and W ∶= Gv′ (U ),
where G−1 denotes the generalized inverse of a generic distribution function G, G−1 (t) =
inf{x∶ G(x) ≥ t}. We still have to determine the signs of X and X ′ , taking into account
that the values of X 2 = W and X ′ 2 = W ′ are already determined. With a view to our proof
of absolute regularity, and since the probability P (∣X∣ = ∣X ′ ∣) is under control, we will do
this in such way that the probability P (∣X∣ = ∣X ′ ∣, X ≠ X ′ ) is as small as possible. Let
pl = P(Xt = l ∣ vt = v) and p′l = P(Xt = l ∣ vt = v ′ ). If (pk ∧ p′k )+ (p−k ∧ p′−k ) ≤ P (W = W ′ = k2 ),
then we can couple the signs of X and X ′ such that
P (W = W ′ = k2 , X = X ′ = k) = pk ∧ p′k

and

P (W = W ′ = k2 , X = X ′ = −k) = p−k ∧ p′−k .

6

In this case,
P (∣X∣ = ∣X ′ ∣ = ∣k∣, X ≠ X ′ ) = P (∣X∣ = ∣X ′ ∣ = ∣k∣) − pk ∧ p′k − p−k ∧ p′−k .

(2.5a)

On the other hand, if (pk ∧ p′k ) + (p−k ∧ p′−k ) > P (W = W ′ = k2 ), then we couple X and X ′
such that
P (W = W = k , X = X = ±k) =
′

′

2

P (W = W ′ = k2 )

p±k ∧ p′±k

(pk ∧ p′k ) + (p−k ∧ p′−k )

which leads to

P (∣X∣ = ∣X ′ ∣ = ∣k∣, X ≠ X ′ ) = 0.
′

,

(2.5b)
′

We denote the corresponding Markov kernels by π Y,Y and π Z,Z , respectively. This contruction produces a pair (X, X ′ ) such that
P̃(X = k) = P(Xt = k ∣ Yt−1 = y)

and

P̃(X ′ = k) = P(Xt = k ∣ Yt−1 = y ′ )

∀k ∈ Z,

which means that (2.3) is satisfied. Furthermore, it follows from (A2) that X 2 is stochas2
tically not greater than X ′ if v ≤ v and vice versa. Since the coupling of these random
variables is based on the quantile transform we obtain by (2.1c)
̃ 2 − X ′ 2 ∣ = ∣E[X
̃ 2 − X ′ 2 ]∣ = ∣v − v ′ ∣.
E∣X

(2.6)

Since P (∣X∣ = ∣X ′ ∣ = ∣k∣) ≤ (pk + p−k ) ∧ (p′k ∨ p′−k ) ≤ (pk + p′k + p−k + p′−k )/2 we obtain from
(2.5a) and (2.5b) that
∞

P (∣X∣ = ∣X ′ ∣, X ≠ X ′ ) = ∑ P (∣X∣ = ∣X ′ ∣ = k, X ≠ X ′ )
k=1
∞

≤ ∑ (pk + p′k + p−k + p′−k )/2 − pk ∧ p′k − p−k ∧ p′−k
≤

k=1
∞

pk + p′k
1 ∞
′
− pk ∧ p′k =
∑ ∣pk − pk ∣.
2
2
k=−∞
k=−∞
∑

(2.7)

It follows from (2.6) and by (A1) that
̃ γ,δ (Z, Z ′ )
E∆

= (γ1 + δ1 ) ∣f (x21 , . . . , x2p , v1 , . . . , vq ) − f (x′1 , . . . , x′p , v1′ , . . . , vq′ )∣
p

2

q

′
∣
+ ∑ γi ∣x2i−1 − x′i−1 ∣ + ∑ δj ∣vj−1 − vj−1
i=2

2

2

(2.8)

j=2

q
p
q
⎞
⎛p
2
2
′
∣.
≤ (γ1 + δ1 ) ∑ ci ∣x2i − x′i ∣ + ∑ dj ∣vj − vj′ ∣ + ∑ γi ∣x2i−1 − x′i−1 ∣ + ∑ δj ∣vj−1 − vj−1
⎠ i=2
⎝i=1
j=2
j=1

̃
The desired relation of E∆(Z,
Z ′ ) ≤ κ∆(z, z ′ ) would be guaranteed to hold if we find
strictly positive γ1 , . . . , γp , δ1 , . . . , δp such that the right-hand side of (2.8) is less than or
2
equal to κ∆(z, z ′ ) = κ( ∑pi=1 γi ∣x2i − x′i ∣ + ∑qj=1 δj ∣vj − vj′ ∣), for all (x21 , . . . , x2p , v1 , . . . , vq ),
(x′1 2 , . . . , x′p 2 , v1′ , . . . , vq′ ) ∈ S ≥ . The following lemma provides a bridge from the contraction
property (A1) for the volatility function to a contraction property for Zt .

7

Lemma 2.1. Let c1 , . . . , cp , d1 , . . . , dq be non-negative constants with ∑pi=1 ci + ∑qj=1 dj < 1.
Then there exist strictly positive constants γ1 , . . . , γp , λ1 , . . . , λq and some κ < 1 such that
p

q

p

q

p

q

i=1

j=1

i=2

j=2

i=1

j=1

(γ1 + δ1 ) ( ∑ ci yi + ∑ dj zj ) + ∑ γi yi−1 + ∑ δj zj−1 ≤ κ ( ∑ γi yi + ∑ δj zj )

(2.9)

holds for all y1 , . . . , yp , z1 , . . . , zq ≥ 0.
′

′

Let π Y,Y and π Z,Z be the Markov kernels which provide the above coupling, that
is, for the above pairs of random variables (Y, Y ′ ) and (Z, Z ′ ) we have that (Y, Y ′ ) ∼
′
′
π Y,Y ((y, y ′ ), ⋅) and (Z, Z ′ ) ∼ π Z,Z ((z, z ′ ), ⋅), respectively.
The following proposition provides the contraction property which will be instrumental
for the proof of the existence and uniqueness of a stationary distribution as well as for the
derivation of absolute regularity of the count process.
Proposition 2.1. Suppose that conditions (A1) and (A2) are fulfilled. Let γ1 , . . . , γp , δ1 , . . . , δp
and κ < 1 be chosen as in Lemma 2.1. Then
′
(i) Let z, z ′ ∈ S ≥ be arbitrary. If (Z, Z ′ ) ∼ π Z,Z ((z, z ′ ), ⋅), then
Z ∼ PZt ∣Zt−1 =z

and
̃t , Z
̃′ ))t∈Z
(ii) Let ((Z
t

and

Z ′ ∼ PZt ∣Zt−1 =z

′

̃ γ,δ (Z, Z ′ ) ≤ κ ∆γ,δ (z, z ′ ).
E∆
̃ F̃, P̃) with transition kernel π Z,Z ′ . Then
be a Markov chain on (Ω,
′
̃ γ,δ (Z
̃ γ,δ (Z
̃t , Z
̃t′ ) ≤ κ E∆
̃t−1 , Z
̃t−1
).
E∆

In order to derive stationarity properties of the process (Zt )t∈Z , we further translate
the contraction result in Proposition 2.1 into a contraction property of the corresponding
distributions. For the metric ∆γ,δ on S ≥ , we define
P(S ≥ ) = {Q∶

Q is a probability distribution on S ≥ with ∫ ∆γ,δ (z0 , z) dQ(z) < ∞},

where z0 ∈ S ≥ is arbitrary. For two probability measures Q, Q′ ∈ P(S ≥ ), we define the
Kantorovich distance based on the metric ∆γ,δ (also known as Wasserstein L1 distance) by
K(Q, Q′ ) ∶=

inf

Z∼Q,Z ′ ∼Q′

̃
E∆(Z,
Z ′ ),

where the infimum is taken over all random variables Z and Z ′ defined on a common
̃ F̃, P̃) with respective laws Q and Q′ . We denote the Markov kernel of
probability space (Ω,
the processes (Yt )t∈Z and (Zt )t∈Z by π Y and π Z , respectively. The following result follows
immediately from Proposition 2.1.
Proposition 2.2. Suppose that conditions (A1) and (A2) are fulfilled. Let Q, Q′ ∈ P(S ≥ )
be arbitrary distributions. Then, for κ < 1 given in Lemma 2.1,
K(QπθZ , Q′ πθZ ) ≤ κ K(Q, Q′ ).

8

2.3. Existence and uniqueness of a stationary distribution. Proposition 2.2 shows
that the mapping π Z is contractive. Therefore, we can conclude by the Banach fixed point
theorem that the Markov process (Zt )t∈Z has a unique stationary distribution. A simple
extra argument shows that that the Markov process (Yt )t∈Z has this property as well.
Theorem 2.1. Suppose that conditions (A1) and (A2) are fulfilled.
(i) The Markov process (Zt )t∈Z with transition kernel π Z has a unique stationary dis2
tribution QZ . For Z0 = (X02 , . . . , X1−p
, v0 , . . . , v1−q ), we have that
E [X02 + v0 ] < ∞.

(2.10)

(ii) The Markov process (Yt )t∈Z with transition kernel π Y has a unique stationary distribution QY .
Remark 2.1. The reader might wonder why we don’t derive weak dependence properties
introduced by Doukhan and Louhichi (1999). Indeed e.g. Doukhan and Neumann (2008)
describe statistical procedures where mixing can be replaced by weak dependence conditions. If X ∼ Qv = Skellam(v/2, v/2) is symmetric, then EX = 0 and EX 2 = v. Therefore
it is natural to model the volatility process as in (2.1b), where the volatilities appear linearly while the count variables are squared. The properties of Skellam models make also
natural the inhomogeneity of (2.1a) and (2.1b) which include both linear and squared fac2
tors. In the simplest case of a SkellamARCH(1)-process, with vt = f (Xt−1
), the function
2
x ↦ f (x ) may not be Lipschitz and thus contraction does not hold. Anyway, the prois again contractive if Lip f < 1. Symmetry of the distribution Qv implies
cess Yt = Xt2 √
that Xt = σt Yt is a solution of (2.1a) and (2.1b) if (σt )t is an iid sequence of symmetric signs (P (σt = ±1) = 1/2). Then τ −dependence of the process (Yt ) follows as in
√
Doukhan and Wintenberger (2008). Now, since the 1-Lipschitz function g(y) = y ∧ y
√
equals y ↦ y on N0 , then Xt = σt g(Yt ); heredity properties of weak dependence imply
geometric τ −dependence of (Xt )t ; see Dedecker et al. (2007). We proved τ −dependence in
this very special symmetric case; in order to work in a more general setting we switch in
Subsection 2.4 to the more standard β−mixing condition to derive asymptotic theory for
the statistical analysis.
2.4. Absolute regularity. For the related case of Poisson count processes with a GARCHtype structure, absolute regularity has been first proved for contractive INGARCH(1,1)
processes in Neumann (2011). This has been generalized in Doukhan and Neumann (2019)
to semi-contractive models and in Doukhan, Leucht, and Neumann (2020) to the case of
possibly non-stationary processes. In all of these papers, the mixing properties were derived
by an explicit coupling of two versions of the processes which were tailor-made for the
respective properties of the processes. In the current work, our approach is slightly different.
We derive both stationarity and mixing properties on the basis of a one-step contractivity
property given in Proposition 2.1.
Let (Ω, A, P ) be a probability space and A1 , A2 be two sub-σ-algebras of A. Then the
coefficient of absolute regularity is defined as
β(A1 , A2 ) = E [sup {∣P (B ∣ A1 ) − P (B)∣∶ B ∈ A2 }] .

For a strictly stationary process Y = (Yt )t on (Ω, A, P ), the coefficients of absolute regularity are defined as
β Y (n) = β (σ(Y0 , Y−1 , . . .), σ(Yn , Yn+1 , . . .)) .

9

For the count process (Xt )t on (Ω, F, P), we obtain the following estimate of the coefficients
of absolute regularity.
β X (n)

= β(σ(X0 , X−1 , . . .), σ(Xn , Xn+1 , . . .))
≤ β(F0 , σ(Xn , Xn+1 , . . .))

= β(σ(Y0 ), σ(Xn , Xn+1 , . . .))
⎡
⎤
⎢
⎥
= E ⎢ sup {∣Pθ ((Xn , Xn+1 , . . .) ∈ C ∣ Zk ) − Pθ ((Xn , Xn+1 , . . .) ∈ C)∣}⎥ ,
⎥
⎢C∈σ(Z)
⎦
⎣

(2.11)

where Z = {A × Z × Z × ⋯ ∣ A ⊆ Zm , m ∈ N} is the system of cylinder sets. At this point we
employ a coupling argument. Let ((Ỹt , Ỹt′ ))t∈N0 be a Markov chain on a probability space
̃ F̃, P̃) with transition kernel π Y,Y ′ and independent variables Ỹ0 , Ỹ ′ ∼ PZk . Then
(Ω,
0
θ
⎤
⎡
⎥
⎢
E ⎢ sup {∣Pθ ((Xk , Xn+1 , . . .) ∈ C ∣ Zk ) − Pθ ((Xk , Xn+1 , . . .) ∈ C)∣}⎥
⎥
⎢C∈σ(Z)
⎦
⎣
̃n , X
̃n+1 , . . .) ∈ C ∣ Ỹ0 ) − P̃ ((X
̃′ , X
̃ ′ , . . .) ∈ C ∣ Ỹ ′ ) ∣}]
̃ sup {∣P̃ ((X
≤ E[
n
n+1
0
C∈σ(Z)

̃n+k ≠ X
̃′
≤ P̃ (X
n+k

for some k ≥ 0)

̃n+k ≠ X
̃′ ) .
≤ ∑ P̃ (X
n+k
∞

(2.12)

k=0

At this point we will more closely examine the remaining part of our approach to derive
upper estimates for the mixing coefficients. If the count variables are non-negative, then
̃n+k = X
̃ ′ is equivalent to ∣X
̃n+k ∣ = ∣X
̃ ′ ∣. Moreover, if the probability mass functions of
X
n+k
n+k
̃n+k and X
̃ ′ have
the Qv are symmetric about zero, then (2.5a) and (2.5b) ensure that X
n+k
̃n+k = X
̃ ′ is equivalent to ∣X
̃n+k ∣ = ∣X
̃ ′ ∣.
always the same sign which means again that X
n+k
n+k
In both cases, we conclude from (2.11) and (2.12) that
̃n+k ≠ X
̃′ )
β X (n) ≤ ∑ P̃ (X
n+k
∞

k=0

≤
≤

1 ∞ ̃
̃n+k , Z
̃′ )
∑ E∆γ,δ (Z
n+k
γ1 k=0
1 κn ̃
̃0 , Z
̃0′ ).
E∆γ,δ (Z
γ1 1 − κ

(2.13)

Otherwise, we assume that (Qv )v∈V is such that, for some K < ∞,
1 ∞
′
∑ ∣Qv ({k}) − Qv′ ({k})∣ ≤ K ∣v − v ∣
2 k=−∞

∀v, v ′ ∈ V.

Then we obtain by (2.7) that
̃n+k ≠ X
̃′ )
̃n+k ∣ = ∣X
̃ ′ ∣, X
̃n+k ∣ ≠ ∣X
̃ ′ ∣) + P̃(∣X
̃n+k ≠ X
̃ ′ ) = P̃(∣X
P̃(X
n+k
n+k
n+k
n+k
′
′
̃
̃
̃
≤ P (∣Xn+k ∣ ≠ ∣Xn+k ∣) + K ∣vn+k − vn+k ∣.

(2.14)

10

In this case, we obtain that
K ∞
1
̃n+k , Z
̃′ )
+ ) ∑ ∆γ,δ (Z
n+k
γ1
δ1 k=0
1
K
κn ̃
̃0 , Z
̃′ ).
E∆γ,δ (Z
≤ (
+ )
0
γ1
δ1 1 − κ

β X (n) ≤ (

(2.15)

Theorem 2.2. Suppose that conditions (A1) and (A2) are fulfilled and that the process
(Yt )t∈Z is stationary. Furthermore we assume that (Qv )v∈V satisfies one of the following
conditions.
a)
b)
c)

Qv (N0 ) = 1 ∀v ∈ V ,
the probability mass functions of (Qv )v∈V are symmetric about zero,
(2.14) is fulfilled for some K < ∞.

Then there exists some ρ < 1 such that

β X (n) = O (ρn ) .

Remark 2.2. The results of our paper are heavily based on the (fully) contractive condition
(A1) on the volatility function f . In a related work, Doukhan and Neumann (2019), a
weaker so-called semi-contractive condition,
q

∣f (x1 , . . . , xp , λ1 , . . . , λq ) − f (x1 , . . . , xp , λ′1 , . . . , λ′q )∣ ≤ ∑ dj ∣λj − λ′ ∣,
j=1

for some non-negative d1 , . . . , dq such that ∑qj=1 dj < 1, was imposed which then resulted a
a slower subexponential decay of the coefficients of absolute regularity. In our context, it
seems also be possible to derive properties such as existence and uniqueness of a stationary
distribution and absolute regularity under a semi-contractive condition if some appropriate drift condition is added. Without any kind of contractivity condition, the approach
used in this paper fails and there are counterexamples showing that then our results are
non longer valid. Consider the special case of the linear model (2.2), where ω > 0 and
α1 , . . . , αp , β1 , . . . , βq are non-negative with ∑pi=1 αi + ∑qj=1 βj ≥ 1. Then
p

q

i=1

j=1

Evt = ω + ∑ αi Evt−i + ∑ βj Evt−j ,
which shows that a stationary process ((Xt , vt ))t∈Z satisfying (2.1a) to (2.1c) does not exist.

3. Applications
We choose to develop the asymptotic theory for the OLSE of Skellam models (3.1) as the
most standard application of the above results. Much more may be done including tests of
goodness-of-fit as in Doukhan, Leucht, and Neumann (2020). Prediction or model selection
issues are also important and should be developed theoretically. Additional research work
will make use of the bound of absolute regularity for many other questions such a more
quantitative study of prediction, qualitative tests of goodness-of-fit such as model choice
problems, or more nonparametric based statistics or resampling or subsampling procedures.

11

3.1. OLSE of a Skellam-ARCH model. We consider the special case of an SkellamARCH(p) model, where (2.1b) reduces to
p

2
.
vt = ω + ∑ αi Xt−i

(3.1)

√
We assume that ω > 0, and that α1 , . . . , αp are non-negative with α = ∑pi=1 αi < 1/ 3. We
further assume that the process ((Xt , vt ))t∈Z is in its unique stationary regime. On the
basis of observations X1 , . . . , Xn , we intend to estimate the vector of unknown parameters
θ = (ω, α1 , . . . , αp )T . We embed the observed random variables into a linear regression
model,
i=1

p

2
αi + εt ,
Xt2 = ω + ∑ Xt−i

t = p + 1, . . . , n,

i=1

where εt = Xt2 − vt satisfies E(εt ∣ Ft−1 ) = 0 a.s. Then the ordinary least squares estimator
is given by
θ̂n

n

2
2
))
+ ⋯ + αp Xt−p
∈ arg min ∑ (Xt2 − (ω + α1 Xt−1
θ

2

t=p+1

= arg min ∥Y(n) − X(n) θ∥ ,
2

θ

where
Y(n)

2
⎛ Xp+1 ⎞
= ⎜ ⋮ ⎟,
⎝ Xn2 ⎠

X(n)

2
2
⎛ 1 Xp ⋯ X1 ⎞
⋮
⋱
⋮ ⎟.
=⎜ ⋮
2
2
⎠
⎝ 1 Xn−1
⋯ Xn−p

T
If the matrix X(n)
X(n) is regular, then θ̂n is uniquely defined and
T
X(n) )
θ̂n = (X(n)

−1

which implies that

√

T
Y(n) ,
X(n)

1 T
n (θ̂n − θ) = ( X(n)
X(n) )
n

−1

(3.2)

1
T
√ X(n)
ε(n) ,
n

(3.3)

where ε(n) = (εp+1 , . . . , εn )T .
√
The condition ∑pi=1 αi < 1/ 3 ensures by Lemma 4.1 that EX04 < ∞. Hence, we obtain
from the ergodic theorem that
1 T
X X(n)
n (n)

EX12
⋯
EXp2
⎛ 1
2
2 2
a.s.
⎜ EX1 EX1 X1 ⋯ EX12 Xp2
Ð→ Σ = ⎜
⎜ ⋮
⋮
⋱
⋮
⎝ EX 2 EX 2 X 2 ⋯ EX 2 X 2
p
p 1
p p

⎞
⎟
⎟.
⎟
⎠

(3.4)

Lemma 4.2 below shows that Σ is a regular matrix which means that equation (3.3) holds
true with a probability tending to 1. Furthermore, it follows from a central limit theorem
for sums of martingale differences (Corollary 3.1 in Hall and Heyde (1980) page 58) and
the Cramér-Wold device that
1
d
T
Wn ∶= √ X(n)
ε(n) Ð→ Z0 ,
(3.5)
n

where Z0 ∼ N (0p+1 , η 2 Σ) and η 2 = Eε2t .
From (3.3) to (3.5) we conclude that
√
d
n (θ̂n − θ) Ð→ Z ∼ N (0p+1 , η 2 Σ−1 ).

(3.6)

12

3.2. Simulation study. We simulate a process ((Xt , vt ))t , where vt obeys (3.1) and
Xt ∣ Ft ∼ Qvt √
= Skellam(vt /2, vt /2). The parameters in (3.1) are chosen such that ω > 0
and ∑ αi < 1/ 3, which ensures finiteness of fourth moments of the count variables; see
Lemma 4.1 below. We assume a suitable set of values for the different order p, α1 = 0.26,
α2 = 0.16, α3 = 0.11, α4 = 0.02, for sample sizes T = 30, 80, 100, 500, and 1000. 1000
replication are made for each sample size and the simulated mean estimates and their
corresponding standard errors as deduced from the result (3.6).
p
1

2

3

4

T
30
80
100
500
1000
30
80
100
500
1000
30
80
100
500
1000
30
80
100
500
1000

ω = 1.50
1.251 (0.321)
1.355 (0.151)
1.751 (0.101)
1.442 (0.087)
1.542 (0.075)
1.389 (0.278)
1.477 (0.150)
1.511 (0.081)
1.552 (0.032)
1.467 (0.022)
1.481 (0.455)
1.551 (0.210)
1.462 (0.111)
1. 541 (0.088)
1.4601 (0.061)
1.495 (0.323)
1.510 (0.188)
1.498 (0.092)
1.502 (0.088)
1.489 (0.052)

α1 = 0.26
0.178 (0.211)
0.225 (0.188)
0.231 (0.124)
0.244 (0.091)
0.136 (0.088)
0.232 (0.209)
0.246 (0.123)
0.271 (0.099)
0.276 (0.042)
0.255 (0.031)
0.244 (0.303)
0.232 (0.155)
0.255 (0.101)
0.275 (0.076)
0.266 (0.045)
0.255 (0.212)
0.276 (0.124)
0.237 (0.110)
0.242 (0.064)
0.262 (0.043)

α2 = 0.16

0.152
0.166
0.148
0.152
0.169
0.152
0.166
0.147
0.158
0.166
0.152
0.164
0.166
0.167
0.159

(0.327)
(0.111)
(0.098)
(0.038)
(0.021)
(0.276)
(0.101)
(0.089)
(0.042)
(0.034)
(0.318)
(0.232)
(0.101)
(0.054)
(0.038)

α3 = 0.11

0.104
0.119
0.114
0.121
0.111
0.112
0.114
0.110
0.113
0.109

(0.152)
(0.110)
(0.088)
(0.034)
(0.026)
(0.176)
(0.123)
(0.075)
(0.033)
(0.018)

α4 = 0.02

0.018
0.015
0.019
0.017
0.018

(0.272)
(0.103)
(0.064)
(0.042)
(0.028)

Table 1. Simulated Mean estimates and standard errors/100 Simulations

The estimates reflect that for increased sample size, the values of the different parameters
become more consistent with the standard errors that are seen to be constantly decreasing;
see Table 1. It is worth reporting that for some simulation processes, the standard OLS
equation (3.3) does not yield relevant output estimates since the constraints on the α
̂i and
ω
̂ were not conformed. To overcome this shortcomings, we apply the QP.solve routine
with the appropriate constraint matrix to obtain reliable results. Furthermore, for p = 4,
some simulations initially failed since the Hessian matrix was near to ill-conditioned and
the evaluation of the inverse was then suitably handled by the ginv function. Broadly,
after accommodating these computational amendments, the average number of convergent
simulations turn around 92 %, 87 %, 85 % and 75 % for p = 1, 2, 3, 4 respectively. As
noticed from these percentages, as we increase the order p, we expect some number of
failed simulations.

4. Proofs and some auxiliary results
4.1. Proofs of the main results.

13

Proof of Lemma 2.1. A comparison of coefficients in (2.9) reveals that it suffices to find
strictly positive constants γ1 , . . . , γp , δ1 , . . . , δq such that the following inequalities are satisfied.
(γ1 + δ1 ) c1 + γ2 ≤ κ γ1
⋮
(γ1 + δ1 ) cp−1 + γp ≤ κ γp−1
(γ1 + δ1 ) cp ≤ κ γp

(γ1 + δ1 ) d1 + δ2 ≤ κ δ1
⋮
(γ1 + δ1 ) dq−1 + δq ≤ κ δq−1
(γ1 + δ1 ) dq ≤ κ δq .

(4.1)

We set, w.l.o.g., γ1 + δ1 = 1. Let ǫ = (1 − L)/(p + q). We consider the following system of
equations.
cp + ǫ = γp
cp−1 + γp + ǫ = γp−1
⋮
c1 + γ2 + ǫ = γ1
dq + ǫ = δq
dq−1 + δq + ǫ = δq−1
⋮
d1 + δ2 + ǫ = δ1 .

It is obvious that this system of equations has a unique solution with strictly positive
γ1 , . . . , γp , δ1 , . . . , δq . Moreover, it follows from
p

q

p

q

p

q

i=1

j=1

i=2

j=2

i=1

j=1

∑ ci + ∑ dj + ∑ γi + ∑ δj + (p + q) ǫ = ∑ γi + ∑ δj

that γ1 +δ1 = 1, as required. Therefore, we see that, with such a choice of γ1 , . . . , γp , δ1 , . . . , δq ,
the following strict inequalities are fulfilled.
c1 + γ2 <
⋮
cp−1 + γp <
cp <
d1 + δ2 <
⋮
dq−1 + δq <
dq <

γ1
γp−1
γp
δ1
δq−1
δq .

Choosing κ = max{(c1 +γ2 )/γ1 , . . . , (cp−1 +γp )/γp−1 , cp /γp , (d1 +δ2 )/δ1 , . . . , (dq−1 +δq )/δq−1 , dq /δq }
we obtain that the system of inequalities (4.1) is satisfied.


14

Proof of Proposition 2.1. (i) follows from (2.8) and (2.9), and (ii) is an immediate consequence of (i).


Proof of Proposition 2.2. Let Q and Q′ be arbitrary probability measures supported in S ≥
and let ξ be the optimal coupling of Q and Q′ w.r.t. the Kantorovich distance, that is,
K(Q, Q′ ) = ∫

S ≥ ×S ≥

∆γ,δ (z, z ′ ) ξ(dz, dz ′ ).

′

Then ξπ Z,Z is a coupling of Qπ Z and Q′ π Z and it follows from Proposition ??(i) that
K(Qπ, Q′ π) ≤ ∫ ∆γ,δ (u, u′ ) ξπ Z,Z (du, du′ )
′

= ∫ [∫ ∆γ,δ (u, u′ ) π Z,Z ((z, z ′ ), du du′ )] ξ(dz, dz ′ )
′

≤ κ ∫ ∆γ,δ (z, z ′ ) ξ(dz, dz ′ ) = κ K(Q, Q′ ).



Proof of Theorem 2.1. We consider first the Markov process (Zt )t∈Z . Let
2p

P = {Q∶ Q is a probability distribution based in S ≥ , ∫ ∑ ∣xi ∣ Q(dx) < ∞} .
S i=1

It is well known that the space P equipped with the Kantorovich metric K is complete.
Since by Proposition 2.2 the mapping π Z is contractive it follows by the Banach fixed point
theorem that the Markov kernel π Z admits a unique fixed point QZ , i.e. QZ π Z = QZ . In
other words, QZ is the unique stationary distribution of the process (Zt )t∈Z .
Now we consider the process (Yt )t∈Z . If the Xt are non-negative random variables, then
2
we have a one-to-one relationship between Zt and Yt and, for Z0 = (X02 , . . . , X1−p
, v0 , . . . , v1−q ) ∼
Z
Q , the distribution of the vector Y0 = (X0 , . . . , X1−p , v0 , . . . , v1−q ) is the unique stationary
distribution of (Yt )t∈Z .
If Xt attains both positive and negative values, we need a simple extra argument.
2
Suppose that Z0 = (X02 , . . . , X1−p
, v0 , . . . , v1−q ) ∼ QZ . Now we can recursively generate
2
, v0 , . . . , v1−q ) and
suitable (v1 , X1 ), . . . , (vp , Xp ) as follows. We set v1 = f (X02 , . . . , X1−p
2
2
generate X1 ∼ Qv1 . Then we set v2 = f (X1 , . . . , X−p , v1 , . . . , v−q ) and choose X1 ∼ Qv1 , and
so on. After p such steps we have collected enough Xt s with suitable signs and the random
vector Yp ∶= (Xp , . . . , X1 , vp , . . . , vp−q+1 ) has the unique stationary distribution, say QY , of
(Yt )t∈Z .


̃ γ,δ (Z
̃0 , Z
̃′ ) < ∞, this theorem is an immediate
Proof of Theorem 2.2. Since by (2.10) E∆
0
consequence of (2.13) and (2.15).


15

4.2. Some auxiliary results.
Lemma 4.1. Let ((Xt , vt ))t∈Z be a stationary process satisfying (3.1), where ω, α1 , . . . , αp
are non-negative constants and let Xt ∣ Ft−1 ∼ Skellam(vt /2, vt /2).
n

(i) If α = ∑ αi < 1, then EX02 < ∞.
i=1
n

1
(ii) If α = ∑ αi < √ , then EX04 < ∞.
3
i=1
̃t , ̃
Proof of Lemma 4.1. Let ((X
vt ))t∈N be Skellam-ARCH process satisfying (3.1), but with
√
̃
̃
initial values X1 = ⋯ = Xp = ω. (The latter condition is imposed to ensure that
d
̃4, . . . , EX
̃ 4 are guaranteed to be finite.) Since X
̃n Ð→
EX
X0 it follows from Theop
1
rem III.6.31 in Pollard (1984, page 58) that we can construct a coupling of these random
variables where we have almost sure convergence rather than convergence in probability.
Hence, we obtain by Fatou’s lemma that
̃ k , for k = 2, 4.
(4.2)
EX k ≤ lim inf E X
0

n→∞

n

(i) It follows from (3.1) that, for t > p,

̃ 2 }.
̃2 , . . . , EX
̃2 = ̃
vt ≤ ω + α max{E X
EX
t−p
t−1
t

̃t2 , . . . , E X
̃2
Let Zt = max{E X
t−p+1 }. We obtain from the previous display the recursion
Zt ≤ max{ω + α Zt−1 , Zt−1 }.
Therefore,
̃t2 ≤ ω ,
EX
1−α
which yields in conjunction with (4.2) that (i) holds true.
(ii) If X ∼ Skellam(v/2, v/2), then EX 4 = v + 3v 2 . Hence, for t > p
2 2
2
̃t−i
̃t−i
̃t4 = ω + ∑ αi E X
) ]
+ 3 E [(ω + ∑ αi X
EX
p

p

i=1

i=1

̃2 }
̃2 , . . . , EX
≤ ω + 3 ω + (1 + 6ω) α max{E X
t−p
t−1
2
4
4
̃
̃
+ 3 α max{E Xt−1 , . . . , E Xt−p }.
2

2
̃4, . . . , EX
̃4
With Z̄t = max{E X
t
t−p+1 } and ω̄ = ω + 3ω + (1 + 6ω)α ⋅

the recursion

which leads to

Z̄t ≤ max{ω̄ + 3 α2 Z̄t−1 , Z̄t−1 },
̃4 ≤
EX
t

ω
, we obtain
1−α

ω̄
.
1 − 3 α2

(ii) follows now from (4.2).

̃t , ̃
Lemma 4.2. Let ((X
λt ))t∈Z be a stationary Skellam-ARCH process satisfying (2.1a) and
(3.1) and with ω > 0. Then the matrix Σ defined in (3.4) is regular.

16

Proof of Lemma 4.2. We have that
Σ = E[ZZ T ],

where Z = (1, Xp2 , . . . , X12 )T .
Assume that Σ is singular: then there exists some γ = (γ0 , . . . , γp )T ≠ 0p+1 such that
which implies that
This means that

0 = γ T Σγ = E[(Z T γ)2 ],
P (Z T γ = 0) = 1.
p

2
γi = 0
γ0 + ∑ Xt−i+1
i=1

holds with probability 1. Since γ1 = ⋯ = γp = 0 would then imply that γ = 0p+1 , there exists
some i0 ≥ 1 such that γ1 = ⋯ = γi0 −1 = 0 and γi0 ≠ 0. Then
⎫
⎧
p
⎪
1 ⎪
⎪
⎪
2
2
⎨γ0 + ∑ γi Xt−i+1 ⎬
Xt−i0 =
⎪
⎪
γi 0 ⎪
⎪
i=i0 +1
⎭
⎩
2
that is, Xt−i0 is fully determined by the past values of the count process. This, however,
leads to a contradiction since
Xt−i0 ∣ Ft−i0 −1 ∼ Skellam(vt−i0 /2, vt−i0 /2)

with vt−i0 ≥ ω > 0. Hence, Σ is a regular matrix.



Acknowledgement We are especially thankful to Bozidar Popovic and Miroslav Ristic for
initiating us to investigate Skellam models. Various preliminary discussions and suggestions
concerning simple Skellam models were very fruitful and led to other considerations beyond
those in the current paper.
This work was funded by CY Initiative of Excellence (grant ”Investissements d’Avenir”
ANR-16-IDEX-0008), Project ”EcoDep”, PSI-AAP2020-0000000013.
References
Alomani, G. A., Alzaid, A. A., and Omair, M. A. (2018). A Skellam GARCH model.
Brazilian Journal of Probability and Statistics 32(1), 200–214.
Alzaid, A. A. and Omair, M. A. (2010). On the Poisson difference distribution inference
and applications. Bulletin of the Malaysian Mathematical Society. 33(1), 17–45.
Andersson, J. and Karlis, D. (2014). A parametric time series model with covariates
for integers in Z. Statistical Modelling 14(2), 135–156.
Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal
of Econometrics 31, 307–327.
Dedecker, J., Doukhan, P., Lang, G., León, J. R., Louhichi S., and Prieur, C.
(2007). Weak Dependence: With Examples and Applications. Lecture Notes in Statistics
190, Springer.
Douc, R., Moulines, E., Priouret, P., and Soulier, P. (2018). Markov Chains.
Springer Series in Operations Research and Financial Engineering.
Doukhan, P., Leucht, A., and Neumann, M. H. (2020). Mixing properties of nonstationary INGARCH(1,1) processes. Manuscript.
Doukhan, P. and Louhichi, S. (1999). A new weak dependence condition and applications to moment inequalities. Stochastic Processes and their Applications 84(2), 313–342.

17

Doukhan, P. and Neumann, M. H. (2008). The notion of ψ-weak dependence and its
applications to bootstrapping time series. Probability Surveys 5, 146–168.
Doukhan, P. and Neumann, M. H. (2019). Absolute regularity of semi-contractive
GARCH-type processes. Journal of Applied Probability 56, 91–115.
Doukhan, P. and Wintenberger, O. (2008). Weakly dependent chains with infinite
memory. Stochastic Processes and their Applications 118, 1997–2013.
Eberle, A. (2019). Markov processes, Lecture Notes University of Bonn.
https://wt.iam.uni-bonn.de/fileadmin/WT/Inhalt/people/Andreas_Eberle/MarkovProcesses1920/Ma
Fokianos, K. and Tjøstheim, D. (2011). Log-linear Poisson autoregression. Journal of Multivariate Analysis 102, 563–578.
Fokianos, K. and Tjøstheim, D. (2012). Nonlinear Poisson autoregression. Annals of the
Institute for Statistical Mathematics 64, 1205–1225.
Hall, P. and Heyde, C. C. (1980). Martingale Limit Theory and Its Application. Academic Press.
Irwin, J. O. (1937). The frequency distribution of the difference between two independent
variates following the same Poisson distribution. Journal of the Royal Statistical Society,
Series A. 100, 415-416.
Karlis, D. and Ntzoufras, I. (2006). Bayesian analysis of the differences of count data.
Statistics in Medicine 25, 1885–1905.
Neumann, M. H. (2011). Absolute regularity and ergodicity of Poisson count processes.
Bernoulli 17, 1268–1284.
Neumann, M. H. (2020). Bootstrap for integer-valued GARCH(p,q) processes. Manuscript.
Pollard, D. (1980). Convergence of Stochastic Processes. Springer, New York.
Skellam, J. G. (1946). The frequency distribution of the difference between two Poisson variates belonging to different populations. Journal of the Royal Statistical Society,
Series A. 109(3), 296.

