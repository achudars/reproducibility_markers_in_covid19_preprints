1

Towards Data-Efficient Learning: A Benchmark for
COVID-19 CT Lung and Infection Segmentation
Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen, Qiongjie Zhu, Guoqiang Dong, Jian He,
Zhiqiang He, Tianjia Cao, Yuntao Zhu, Ziwei Nie, Xiaoping Yang

arXiv:2004.12537v2 [eess.IV] 3 Dec 2020

Abstract
Purpose: Accurate segmentation of lung and infection in COVID-19 CT scans plays an important role in the quantitative
management of patients. Most of the existing studies are based on large and private annotated datasets that are impractical
to obtain from a single institution, especially when radiologists are busy fighting the coronavirus disease. Furthermore, it is hard
to compare current COVID-19 CT segmentation methods as they are developed on different datasets, trained in different settings,
and evaluated with different metrics.
Methods: To promote the development of data-efficient deep learning methods, in this paper, we built three benchmarks for lung
and infection segmentation based on 70 annotated COVID-19 cases, which contain current active research areas, e.g., few-shot
learning, domain generalization, and knowledge transfer. For a fair comparison among different segmentation methods, we also
provide standard training, validation and testing splits, evaluation metrics and, the corresponding code.
Results: Based on the state-of-the-art network, we provide more than 40 pre-trained baseline models, which not only serve as
out-of-the-box segmentation tools but also save computational time for researchers who are interested in COVID-19 lung and
infection segmentation. We achieve average Dice Similarity Coefficient (DSC) scores of 97.3%, 97.7%, and 67.3% and average
Normalized Surface Dice (NSD) scores of 90.6%, 91.4%, and 70.0% for left lung, right lung, and infection, respectively.
Conclusions: To the best of our knowledge, this work presents the first data-efficient learning benchmark for medical image
segmentation, and the largest number of pre-trained models up to now. All these resources are publicly available, and our work
lays the foundation for promoting the development of deep learning methods for efficient COVID-19 CT segmentation with limited
data.

Index Terms
COVID-19 CT, lung and infection segmentation, few-shot learning, domain generalization, knowledge transfer

I. I NTRODUCTION
OVID-19 (coronavirus disease 2019) has spread all over the world during the past few months and caused over 61,000,000
people infected as of 30th November 2020 according to WHO statistics1 . Computed tomography (CT) is playing an
important role in the fight against COVID-19 [1], [2], [3]. CT is shown to be more sensitive in the early diagnosis of COIVD19 infection compared to Reverse Transcription-Polymerase Chain Reaction (RT-PCR) tests [4]. Wang et al. trained a deep
learning model on 325 COVID-19 CT scans and 740 typical pneumonia scans. Their model can identify 46 COVID-19 cases
that were previously missed by the RT-PCR test [5]. Further, quantitative information from CT images, such as the lung
burden, the percentage of high opacity, and the lung severity score, can be used to monitor the disease progression and help
us understand the course of COVID-19 [6], [7].
Artificial Intelligence (AI) methods, especially deep learning-based methods, have been widely applied in medical image
analysis to combat COVID-19 [8]. For example, AI can be used for building a contactless imaging workflow to prevent
transmission from patients to health care providers [9]. In addition, most screening and segmentation algorithms for COVID19 are developed with deep learning models, and the automatic diagnosis and COVID-19 infection quantification systems
usually rely on the segmentation results generated by deep neural networks[10], [11], [12], [13].

C

Jun Ma (corresponding author) is with Department of Mathematics, Nanjing University of Science and Technology, Nanjing, 210094, P. R. China
(junma@njust.edu.cn).
Yixin Wang is with Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, 100190, P.
R. China (wangyixin19g@ict.ac.cn).
Xingle An is with China Electronics Cloud Brain (Tianjin) Technology CO., LTD, P. R. China (anxingle820@gmail.com).
Cheng Ge is with Institute of Bioinformatics and Medical Engineering, Jiangsu University of Technology, Changzhou, 213001, P. R. China.
Ziqi Yu is with Institute of Science and Technology for Brain-inspired Intelligence, Fudan University, Shanghai, P. R. China.
Jianan Chen is with Department of Medical Biophysics, University of Toronto, Toronto, ON, CA (chenjn2010@gmail.com).
Qiongjie Zhu, Guoqiang Dong, and Jian He is with Department of Radiology, Nanjing Drum Tower Hospital, the Affiliated Hospital of Nanjing University
Medical School, Nanjing, 210008, P. R. China
Zhiqiang He is with Lenovo Ltd., Beijing, 100094, P. R. China.
Tianjia Cao is with China Electronics Cloud Brain (Tianjin) Technology CO., LTD, P. R. China.
Yuntao Zhu, Ziwei, Nie, and Xiaoping Yang (corresponding author) is with Department of Mathematics, Nanjing University, Nanjing, 210093, P. R. China
(xpyang@nju.edu.cn).
1 https://covid19.who.int/

2

Although several studies show that deep learning methods have potential for providing accurate and quantitative assessment
of COVID-19 infection in CT images [8], the solutions mainly rely on large private datasets. Due to the patient privacy and
intellectual property issues, the datasets and solutions may not be publicly available. However, researchers may hope that the
datasets, entire source code and trained models could be provided by authors [14].
Existing studies demonstrate that the classical U-Net (or V-Net) can achieve promising segmentation performance if hundreds
of well-labelled training cases are available [12], [15]. 83.1% to 91.6% of segmentation performance in Dice score coefficient
was reported in various U-Net-based approaches on different private datasets. Shan et al. developed a neural network based on
V-Net and the bottle-neck structure to segment and quantify infection regions [15], [16]. In their human-in-the-loop strategy,
they achieved 85.1%, 91.0% and 91.6% dice with 36, 114, and 249 labelled CT scans, respectively. Huang et al. [12] employed
U-Net [17] for lung and infection using an annotated dataset of 774 cases, and demonstrated that the trained model could
be used for quantifying the disease burden and monitoring disease progressions or treatment responses. In general, we have
observed a trend that training deep learning models with more annotations will decrease the time needed for contouring the
infection, and increase segmentation accuracy, which is consistent with the Shan et al.’s findings [15]. However, annotations
for 3D CT volume data are expensive to acquire because it not only relies on professional diagnosis knowledge of radiologists,
but also takes much time and labor, especially in current situation. Thus, a critical question would be:
how can we automatically annotate COVID-19 CT scans with limited training data?
Towards this question, three basic but important problems remain unsolved:
• There is no publicly well-labelled COVID-19 CT 3D dataset; Data collection is the first and essential step to develop deep
learning methods for COVID-19 segmentation. Most of the existing studies rely on large private dataset with hundreds of
annotated CT scans.
• There are no public benchmarks to evaluate different deep learning-based solutions, and different studies often use various
evaluation metrics. Similarly, datasets for training, validating and testing are split diversely, which also makes it hard
for readers to compare those methods. For example, although MedSeg (http://medicalsegmentation.com/covid19/) dataset
with 100 annotated slices were used in [18], [19], [20], [21], and [22] to develop COVID-19 segmentation methods, it
was split in different ways and the developed methods were evaluated by different metrics.
• There are no publicly available trained baseline models for COVID-19. U-Net, a well-known segmentation architecture,
is commonly used as a baseline network in many studies. However, due to different implementations, the reported
performance varies in different studies [19], [22], even though the experiments are conducted on the same dataset.
In this paper, we focus on annotation-efficient deep learning solutions and aim to alleviate the above problems by providing
a well-labelled COVID-19 CT dataset and a benchmark. In particular, we first provide a COVID-19 3D CT dataset with left
lung, right lung, and infection annotations, and then establish three benchmark tasks to explore different deep learning strategies
with limited training cases. Finally, we build comprehensive baselines for each task based on U-Net.
Our tasks target on three popular research fields in medical imaging community:
• Few-shot learning: building high performance models from very few samples. Although most existing approaches focus
on natural images, it has received growing attention in medical imaging because generating labels for medical images is
much more difficult [23], [24].
• Domain generalization: learning from known domains and applying to an unknown target domain that has different data
distribution [25]. The ultimate goal of domain generalization is to train robust models that are generalizable to new unseen
domains. Recently, model-agnostic learning has been an emerging research topic to achieve this goal [26].
• Knowledge transfer: reusing existing annotations to boost the training/fine-tuning on a new dataset or a related new task.
In contrast to domain generalization, both the source domain/task and the target domain/task are known, and we focus on
storing and reusing knowledge gained from the source domain/task. This task has achieved significant attention in recent
studies, such as using transfer learning or generative adversarial network to transfer knowledge from publicly available
annotated datasets to new datasets [27], [28] in segmentation tasks.
Large-scale data remedies of lung and infection segmentation have been well studied [12], [13]. In this paper, we focus on
small-data learning tasks because it is a more practical problem and large-scale annotated datasets are expensive and timeconsuming to collect. Moreover, the goal is to lay the foundation for important machine learning tasks when only limited cases
are available. Designing novel methods is beyond the scope of this paper. Our contributions can be summarized as follows.
• We present a new COVID-19 CT datasets and the left lung, the right lung, and the infections are well annotated by chest
radiologists.
• We set up 3 benchmark tasks to promote the studies on data-efficient deep learning for COVID-19 CT scans segmentation.
Specifically, we focus on few-shot learning, domain generalization, and knowledge transfer that are also current research
hotspots. To the best of our knowledge, this is the first data-efficient learning benchmark in medical image segmentation.
• We provide 40+ trained state-of-the-art models and corresponding segmentation results are publicly available, which can
serve as strong baselines. More importantly, these trained models can be used as out-of-the-box tools for COVID-19 CT
lung and infection segmentation, which could reduce the annotation time for radiologists.

3

II. M ATERIALS
Annotations of COVID-19 CT scans are scarce, but several lung CT annotations with other diseases are publicly available.
Thus, one of the main goals of our benchmark is to explore whether it is possible for using these existing annotations to
assist COVID-19 CT segmentation. This section introduces the public datasets used in our segmentation benchmarks. Figure
1 presents some examples from each dataset.

Lung Tumor

Pleural Effusion

StructSeg

Lung Tumor

NSCLC

MSD Lung Tumor

COVID-19 Infection

COVID-19-CT-Seg

COVID-19 Infection
Infection
COVID-19

MosMed

Fig. 1: Examples of five lung CT datasets. The 1st and 2nd row denote original non-contrast CT images and corresponding
ground truth of lung and lesions, respectively. The 3rd row shows the 3D rendering results of ground truth. MSD Lung Tumor
and MosMed datasets (3rd column) do not provide lung masks. The red, green, blue color denote left lung, right lung, and
lung lesions, respectively. The blue legend in the 3rd rows stands for different lung lesion types.

A. Existing lung CT segmentation datasets
1) StructSeg lung organ segmentation: 50 lung cancer patient CT scans are accessible, and all the cases are from one medical
center. This dataset served as a segmentation challenge2 during MICCAI 2019. Six organs are annotated, including left lung,
right lung, spinal cord, esophagus, heart, and trachea. In this paper, we only use the left lung and right lung annotations.
2) NSCLC left and right lung segmentation: This dataset consists of left and right thoracic volume segmentations delineated
on 402 CT scans from The Cancer Imaging Archive NSCLC Radiomics [29], [30], [31].
B. Existing lung lesion CT segmentation datasets
1) MSD Lung tumor segmentation: This dataset is comprised of patients with non-small cell lung cancer from Stanford
University (Palo Alto, CA, USA) publicly available through TCIA. The dataset served as a segmentation challenge3 during
MICCAI 2018. The tumor is annotated by an expert thoracic radiologist, and 63 labelled CT scans are available.
2) StructSeg Gross Target Volume segmentation of lung cancer: The same 50 lung cancer patient CT scans as the above
StructSeg lung organ segmentation dataset are provided, and gross target volumes of tumors are annotated in each case.
3) NSCLC Pleural Effusion (PE) segmentation: The CT scans in this dataset are the same as those in NSCLC left and right
lung segmentation dataset, while pleural effusion is delineated for 78 cases [29], [30], [31].
4) MosMed Dataset: This dataset contains 50 annotated COVID-19 CT scans that are provided by municipal hospitals in
Moscow, Russia [32]. To evaluate the generalization ability of deep learning models, we used this dataset as an independent
testing set in following benchmark settings.
C. Our COVID-19-CT-Seg dataset
We collected 20 public COVID-19 CT scans from the Coronacases Initiative and Radiopaedia, which can be freely downloaded4 with CC BY-NC-SA license. All the cases contain COVID-19 infections. The proportion of infections in the lungs
2 MICCAI

2019 StructSeg: https://structseg2019.grand-challenge.org
2018 MSD: http://medicaldecathlon.com/
4 https://github.com/ieee8023/covid-chestxray-dataset
3 MICCAI

4

ranges from 0.01%-59%. The left lung, right lung, and infection5 were firstly delineated by junior annotators with 1-5 years
experience, then refined by two radiologists with 5-10 years experience, and finally all the annotations were verified and refined
by a senior radiologist with more than 10 years experience in chest radiology. The whole lung mask includes both normal and
pathological regions. All the annotations were manually performed by ITK-SNAP in a slice-by-slice manner on axial images.
On average, it takes about 400 ± 45 minutes to delineate one CT scan with 250 slices. There are totally 300+ infections
with 1800+ slices. We have made all the annotations publicly available [33] at https://zenodo.org/record/3757476 with CC
BY-NC-SA license.
III. M ETHODS
As mentioned in Section 1, there is a need for innovative strategies that enable data-efficient methods for COVID-CT
segmentation. Thus, we set up three tasks to evaluate potential annotation-efficient strategies. In particular, we focus on
learning to segment left lung, right lung and infection in COVID-19 CT scans using
• pure but limited COVID-19 CT scans;
• existing annotated lung CT scans from other non-COVID-19 lung diseases;
• heterogeneous datasets include both COVID-19 and non-COVID-19 CT scans.
Furthermore, we also provide unified data (training, validation, and testing) splits, experimental settings, and evaluation metrics
to standardize the deep learning-based segmentation protocols that can enable fair comparisons between different studies.
A. Task 1: Learning with limited annotations
Task 1 (Table I) is designed to address the problem of few-shot learning, where few annotations are available for training.
This task is based on the COVID-19-CT-Seg dataset only. It contains three subtasks aiming to segment lung, infection and both
of them, respectively. For each subtask, 5-fold cross validation results (based on a pre-defined dataset split file) are reported.
In each fold, 4 training cases are used for training and the rest 16 cases are used for validation. Moreover, MosMed dataset
is used as an independent testing set.
TABLE I: Experimental settings of Task 1 (Learning with limited annotations) for lung and infection segmentation in COVID19 CT scans. All the experiments are base on the COVID-19-CT-Seg dataset. (Number) denotes the number of cases in the
dataset.
Seg. Task
Lung
Infection
Lung and infection

Training and Validation
5-fold cross validation
4 cases (20% for training)
16 cases (80% for validation)

Testing
MosMed (50)

TABLE II: Experimental settings of Task 2 (Learning to segment COVID-19 CT scans from non-COVID-19 CT scans) for
lung and infection segmentation in COVID-19 CT scans. (Number) denotes the number of cases in the dataset.
Seg. Task
Lung
Infection

Training
StructSeg Lung (40)
NSCLC Lung (322)
MSD Lung Tumor (51)
StructSeg Gross Target (40)
NSCLC Pleural Effusion (62)

In-domain Testing
StructSeg Lung (10)
NSCLC Lung (80)
MSD Lung Tumor (12)
StructSeg Gross Target (10)
NSCLC Pleural Effusion (16)

(Unseen) Testing 1
COVID-CT-Seg
Lung (20)
COVID-CT-Seg
Infection (20)

(Unseen) Testing 2
MosMed (50)

TABLE III: Experimental settings of Task 3 (Learning with both COVID-19 and non-COVID-19 CT scans) for lung and
infection segmentation in COVID-19 CT scans. (Number) denotes the number of cases in the dataset.
Seg. Task
Lung
Infection

Training
StructSeg Lung (40)
NSCLC Lung (322)
MSD Lung Tumor (51)
StructSeg Gross Target (40)
NSCLC Pleural Effusion (62)

COVID-CT-Seg
Lung (4)
COVID-CT-Seg
Infection (4)

Validation
StructSeg Lung (10)
NSCLC Lung (80)
MSD Lung Tumor (12)
StructSeg Gross Target (10)
NSCLC Pleural Effusion (16)

Testing 1
COVID-CT-Seg
Lung (16)
COVID-CT-Seg
Infection (16)

Testing 2
MosMed (50)

B. Task 2: Learning to segment COVID-19 CT scans from non-COVID-19 CT scans
Task 2 (Table II) is designed to address the problem of domain generalization, where only out-of-domain data (non-COVID19 datasets) are available for training. Specifically, in the first subtask, the StructSeg Lung dataset and the NSCLC Lung
dataset are used for training. In the second subtask, the MSD Lung Tumor, the StructSeg Gross Target and the NSCLC Pleural
Effusion datasets are used as training sets. For both subtasks, 80% of the data are randomly selected for training and the rest
20% are held-out as in-domain testing sets. All cases in two labelled COVID-19 CT datasets are kept for testing.
5 The

infection means to include all visibly affected regions of the lungs.

5

C. Task 3: Learning with both COVID-19 and non-COVID-19 CT scans
Task 3 (Table III) is designed to address the problem of knowledge transfer with heterogeneous datasets, where both indomain and out-of-domain data are included in the training set. Specifically, in both subtasks (lung segmentation and lung
infection segmentation), 80% non-COVID-19 data and 20% COVID-19 data are used for training, while remained 20% and
80% data are used for validation and testing, respectively. Besides, MosMed dataset is used as an additional testing set.
D. Evaluation metrics
Motivated by the evaluation methods of the well-known medical image segmentation decathlon6 , we also employ two
complementary metrics to evaluate the segmentation performance. Dice similarity coefficient, a region-based measure, is used
to evaluate the region overlap. Normalized surface Dice [34], a boundary-based measure is used to evaluate how close the
segmentation and ground truth surfaces are to each other at a specified tolerance τ . For both two metrics, higher scores admit
better segmentation performance, and 100% means perfect segmentation. Let G, S denote the ground truth and the segmentation
result, respectively. We formulate the definitions of the two measures as follows:
1) Region-based measure:
2|G ∩ S|
;
DSC(G, S) =
|G| + |S|
2) Boundary-based measure:
(τ )

N SD(G, S) =
(τ )

(τ )

|∂G ∩ B∂S | + |∂S ∩ B∂G |
|∂G| + |∂S|

(τ )

where B∂G , B∂S ⊂ R3 denote the border region of ground truth and segmentation surface at tolerance τ , which are defined
(τ )
(τ )
as B∂G = {x ∈ R3 | ∃x̃ ∈ ∂G, ||x − x̃|| ≤ τ } and B∂S = {x ∈ R3 | ∃x̃ ∈ ∂S, ||x − x̃|| ≤ τ }, respectively. We set tolerance τ
as 1mm and 3mm for lung segmentation and infection segmentation, respectively. The tolerance is computed by measuring
the inter-rater segmentation variation between two different radiologists, which is also in accordance with another independent
study [34]. Python implementations of the two metrics are publicly available7 .
The main benefit of introducing Surface Dice is that it ignores small boundary deviations because small inter-observer errors
are also unavoidable and often not clinically relevant when segmenting the objects by radiologists.
E. U-Net baselines: oldies but goldies
U-Net ([17], [35]) has been proposed for 5 years, and many variants have been proposed to improve it. However, recent study
[36] demonstrates that it is still hard to surpass a basic U-Net if the corresponding pipeline is designed adequately. In particular,
nnU-Net (no-new-U-Net) [36] was proposed to automatically adapt preprocessing strategies and network architectures (i.e.,
the number of pooling, convolutional kernel size, and stride size) to a given 3D medical dataset. Without manual tuning,
nnU-Net can achieve better performance than most specialised deep learning pipelines in 19 public international segmentation
competitions and set a new state-of-the-art in the majority of 49 tasks. The source code is publicly available at https://github.
com/MIC-DKFZ/nnUNet.
TABLE IV: Quantitative Results of 5-fold cross validation on COVID-19-CT-Seg dataset for Task 1: Learning with limited
annotations. For each fold, average DSC and NSD values are reported. The last row shows the average results of 80 (= 5
folds ×16 testing cases per fold) testing cases.
Subtask
Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg

Lung
Left Lung
Right Lung
DSC (%)
NSD (%)
DSC (%)
NSD (%)
84.9 ± 8.2 68.7 ± 13.3 85.2 ± 13.0 70.6 ± 15.8
80.3 ± 14.5 61.8 ± 15.1 83.9 ± 9.6 68.3 ± 9.0
87.1 ± 12.1 74.3 ± 16.0 90.3 ± 8.2 78.5 ± 12.0
88.4 ± 7.0 75.2 ± 8.8 89.9 ± 6.3 78.5 ± 8.0
88.3 ± 7.6 75.8 ± 11.0 90.2 ± 7.0 78.3 ± 10.2
85.8 ± 10.5 71.2 ± 13.8 87.9 ± 9.3 74.8 ± 11.9

Infection
DSC (%)
68.1 ± 20.5
71.3 ± 20.5
66.2 ± 21.7
68.1 ± 23.1
62.7 ± 26.9
67.3 ± 22.3

NSD (%)
70.9 ± 21.3
71.8 ± 23.0
71.7 ± 24.2
70.8 ± 27.1
64.9 ± 28.2
70.0 ± 24.4

Lung and Infection Union Segmentation
Left Lung
Right Lung
Infection
DSC (%)
NSD (%)
DSC (%)
NSD (%)
DSC (%)
NSD (%)
50.5 ± 30.4 36.9 ± 19.6 64.8 ± 18.9 47.1 ± 13.8 66.5 ± 23.4 68.7 ± 22.5
40.3 ± 18.7 27.5 ± 12.0 60.1 ± 11.1 41.7 ± 9.9 64.7 ± 21.8 60.6 ± 25.1
80.3 ± 18.8 66.8 ± 18.8 85.2 ± 12.4 68.6 ± 15.1 60.7 ± 27.6 62.5 ± 28.9
79.7 ± 13.6 65.4 ± 14.4 84.0 ± 9.8 67.7 ± 13.0 62.0 ± 27.9 65.3 ± 28.9
72.4 ± 21.1 58.6 ± 20.8 80.9 ± 13.4 63.4 ± 15.9 51.4 ± 30.2 51.9 ± 31.0
64.6 ± 26.4 51.1 ± 23.4 75.0 ± 16.8 57.7 ± 17.4 61.0 ± 26.2 61.8 ± 27.4

U-Net is often used as a baseline model in existing COVID-19 CT segmentation studies. However, reported results vary
a lot even in the same dataset, which make it hard to compare different studies. To standardize the U-Net performance, we
build our baselines on nnU-Net that is the most powerful U-Net implementation to the best of our knowledge. To make it
comparable between different tasks, we manually adjust the patch sizes and network architectures in Task 2 and Task 3 to be
the same as Task 1. Figure 2 shows details of the U-Net architecture.
6 http://medicaldecathlon.com/files/MSD-Ranking-scheme.pdf
7 https://github.com/JunMa11/COVID-19-CT-Seg-Benchmark/blob/master/utils/COVID-19-Seg-Evaluation.py

6

32x56x160x192

64x56x80x96
1,2,2
128x28x40x48

Input

2,2,2
2,2,2

Output (1x1x1 Conv
followed by softmax)

256x14x20x24

Conv - IN - LReLU
(kernel size 1x3x3)

320x7x10x12
2,2,2

320x7x5x6

Conv - IN - LReLU
(kernel size 3x3x3)
Convolution
Transposed

1,2,2

Skip Connction

Fig. 2: Details of the 3D U-Net architecture that is used in this work. The numbers (e.g. 32 × 56 × 160 × 92) near convolutional
blocks denote feature map size in each resolution, and the numbers in white rectangles (e.g., 1, 2, 2) denote stride sizes of
convolutional kernels.

TABLE V: Quantitative results (mean ± standard deviation) of Lung segmentation in Task 2.
Subtask
StructSeg Lung
NSCLC Lung

In-domain Testing Set
Left Lung
Right Lung
DSC (%)
NSD (%)
DSC (%)
NSD (%)
96.4 ± 1.4
74.6 ± 9.1
97.3 ± 0.3
74.3 ± 7.2
95.3 ± 4.9
80.2 ± 8.3
95.4 ± 10.9
80.7 ± 10.7

(Unseen) Testing Set 1
Left Lung
Right Lung
DSC (%)
NSD (%)
DSC (%)
NSD (%)
92.2 ± 19.7
82.0 ± 15.7
95.5 ± 7.2
84.2 ± 11.6
57.5 ± 21.5
46.9 ± 16.9
72.2 ± 15.3
51.7 ± 16.8

TABLE VI: Quantitative results (mean ± standard deviation) of Infection segmentation in Task2.
In-domain
DSC (%)
MSD Lung Tumor 67.2 ± 27.1
StructSeg Tumor 71.3 ± 29.6
64.4 ± 45.5
NSCLC-PE
Subtask

Testing Set
(Unseen) Testing Set 1
NSD (%)
DSC (%)
NSD (%)
77.1 ± 31.4 25.2 ± 27.4 26.0 ± 28.5
70.3 ± 29.5 6.0 ± 12.7 5.5 ± 10.7
73.7 ± 12.9 0.4 ± 0.8 3.7 ± 4.8

TABLE VII: Quantitative Results of 5-fold cross validation of left lung and right lung segmentation in Task 3.
Subtask

StructSeg

NSCLC

Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg
Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg

Validation Set
Left Lung
Right
DSC (%)
NSD (%)
DSC (%)
96.3 ± 0.1
79.9 ± 8.5
97.2 ± 0.4
96.3 ± 1.2
73.7 ± 8.4
97.1 ± 0.4
96.4 ± 1.3
74.3 ± 8.5
97.2 ± 0.3
96.3 ± 1.2
73.9 ± 8.5
97.2 ± 0.3
96.3 ± 1.3
73.8 ± 8.9
97.2 ± 0.4
96.3 ± 1.2
73.9 ± 8.2
97.2 ± 0.3
95.7 ± 4.6
81.2 ± 7.5
95.5 ± 10.9
95.4 ± 5.0
80.5 ± 8.7
95.2 ± 11.1
95.4 ± 4.9
79.7 ± 8.2
95.2 ± 10.9
95.4 ± 4.9
79.8 ± 7.7
94.8 ± 11.2
95.7 ± 4.6
81.1 ± 7.9
95.5 ± 10.9
95.5 ± 4.8
80.5 ± 8.0
95.2 ± 10.9

Lung
NSD (%)
73.9 ± 7.0
73.4 ± 7.0
74.0 ± 6.9
73.9 ± 7.0
73.8 ± 7.3
73.8 ± 6.7
81.0 ± 10.9
80.5 ± 11.4
80.0 ± 11.3
79.5 ± 11.6
80.9 ± 11.0
80.4 ± 11.2

Testing
Left Lung
DSC (%)
NSD (%)
97.4 ± 1.9
97.6 ± 2.0
97.7 ± 1.3
91.0 ± 5.3
96.8 ± 3.1
89.4 ± 8.8
96.9 ± 2.5
90.7 ± 5.6
97.8 ± 1.3
91.6 ± 5.3
97.3 ± 2.1
90.6 ± 6.2
92.7 ± 6.3
75.4 ± 14.5
92.2 ± 7.2
73.6 ± 17.5
94.1 ± 4.1
77.4 ± 12.0
93.6 ± 5.1
77.9 ± 11.6
94.8 ± 3.8
80.5 ± 10.5
93.5 ± 5.4
76.9 ± 13.3

Set 1
Right
DSC (%)
90.3 ± 5.9
98.0 ± 1.1
97.6 ± 2.8
97.3 ± 2.5
98.0 ± 1.3
97.7 ± 2.1
93.0 ± 7.0
94.3 ± 3.8
93.8 ± 5.8
93.6 ± 5.9
95.1 ± 3.3
94.0 ± 5.3

Lung
NSD (%)
90.8 ± 6.1
91.8 ± 4.9
90.9 ± 7.8
91.3 ± 6.3
92.0 ± 5.7
91.4 ± 6.1
85.3 ± 16.0
76.7 ± 14.3
75.6 ± 16.2
78.2 ± 13.3
80.5 ± 11.1
77.2 ± 14.1

7

During pre-processing, we apply Z-score (mean subtraction and division by standard deviation) to normalize the image
intensities. During training, we use the standard training scheme of nnU-Net. For example, The sum between cross entropy
and Dice loss is used as the loss function. The optimizer is stochastic gradient descent with initial learning rate (0.01) and a
large nesterov momentum (0.99) and, ‘PolyLR’ schedule [37] is used to reduce the learning rate. We randomly sample image
patches with size 192 × 192 × 64. All training procedures run for a fixed length of 1000 epochs, where each epoch is defined
as 250 training iterations (batch size 2). During testing, we use the same patch size with sliding window to infer testing cases
and the sliding stride is half the patch size8 .
IV. R ESULTS AND D ISCUSSION
This section presents the quantitative segmentation results in each task. For clarity, the first three subsections show the
segmentation results on the validation set and the first testing set for each task. We summarize all the segmentation results on
the second testing set (MosMed dataset) and compare the results of three tasks in the last subsection.
A. Results of Task 1: Learning with limited annotations
Table IV presents average DSC and NSD results of lung and infection of each subtask in Task 1. It can be found that
• the average DSC and NSD values among different folds vary greatly. This is because the testing cases in each fold have
different degrees of difficulty, which demonstrates that reporting 5-fold cross validation results is necessary to obtain an
objective evaluation as 1-fold results may be biased.
• promising results for left and right lung segmentation in COVID-19 CT scans can be achieved with as few as four training
cases. Models trained for segmenting lung obtain significantly better results compared with those trained for segmenting
lung and infection simultaneously.
• there is still large room for improving infection segmentation with limited annotations.
Figure 3 presents some visualized segmentation results in Task 1. It can be found that the separate training manner yields
better results, especially for the left lung and right lung segmentation. The union training manner could confuse left and right
lung, adversely affecting the infection segmentation. This is because multi-task segmentation is much harder than single task,
especially when each separate task is challenging.
Case 11

Case 3

Case 14

Case 1

Case 7

Case 15

Input Image

Ground Truth

Task1-Separate

Task1-Union

Fig. 3: Visualized examples of segmentation results in Task 1. Task1-Separate means the results of training separate networks
for lung and infection segmentation. Task1-Union means training a single model for both lung and infection segmentation.
The red, green, and blue color denote the left lung, the right lung, and the infection, respectively.

B. Results of Task 2: Learning to segment COVID-19 CT scans from non-COVID-19 CT scans
This task is quite challenging as the model does not see any cases from target domain during training. In other words,
the trained models are expected to generalize to the unseen domain (COVID-19 CT). Table V shows left lung and right lung
segmentation results in terms of average and standard deviation values of DSC and NSD. It can be found that
• 3D U-Net achieves excellent performance in terms of DSC on the in-domain set. Average NSD values are lower than
DSC values, implying that most of the errors come from the boundaries.
• the performance on the testing set drops significantly on both subtasks. The performance of the model trained on NSCLC
Lung dataset is worse than the model trained on StuctSeg lung. The potential reason could be the difference in the
distribution lung appearance is smaller between StructSeg and COVID-19-CT.

8

TABLE VIII: Quantitative Results of 5-fold cross validation of infection segmentation in Task 3.
Subtask

MSD
Lung
Tumor

StructSeg
Tumor

NSCLC

Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg
Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg
Fold-0
Fold-1
Fold-2
Fold-3
Fold-4
Avg

Validation Set
DSC (%)
NSD (%)
67.2 ± 26.7
78.1 ± 30.8
66.3 ± 26.1
76.9 ± 29.6
67.1 ± 25.4
77.4 ± 27.8
63.9 ± 26.6
73.8 ± 31.1
68.0 ± 25.9
78.8 ± 29.9
66.5 ± 25.3
77.0 ± 28.9
78.2 ± 14.1
75.4 ± 17.5
78.6 ± 14.0
76.1 ± 18.1
77.0 ± 13.7
73.0 ± 17.0
78.8 ± 13.6
76.0 ± 17.5
77.5 ± 13.7
74.6 ± 18.4
78.0 ± 13.3
75.0 ± 17.0
65.5 ± 15.4
74.3 ± 13.2
64.7 ± 15.4
73.8 ± 14.3
65.5 ± 15.2
74.8 ± 13.7
64.7 ± 16.0
74.0 ± 13.6
65.2 ± 15.6
74.7 ± 13.0
65.1 ± 15.2
74.3 ± 13.2

Testing
DSC (%)
68.0 ± 22.5
67.0 ± 22.0
63.0 ± 27.9
61.7 ± 24.5
51.9 ± 30.6
62.3 ± 25.7
69.3 ± 20.5
68.3 ± 22.4
63.6 ± 25.4
67.0 ± 24.1
52.6 ± 28.7
64.2 ± 24.5
69.2 ± 20.7
59.7 ± 22.7
61.6 ± 28.2
62.7 ± 25.7
47.7 ± 27.2
60.2 ± 25.4

Set 1
NSD (%)
66.6 ± 23.7
65.1 ± 25.9
64.4 ± 28.7
59.8 ± 28.5
50.6 ± 30.9
61.3 ± 27.6
68.0 ± 21.8
64.8 ± 26.3
66.1 ± 25.5
66.4 ± 25.2
51.2 ± 28.5
63.3 ± 25.7
66.5 ± 22.4
55.8 ± 25.5
61.7 ± 29.1
62.0 ± 27.7
46.5 ± 27.0
58.5 ± 26.7

Table VI shows quantitative infection segmentation results in terms of average and standard deviation values of DSC and
NSD. It can be found that
• on the in-domain testing set, the performance of lesion segmentation is not as good as the performance of lung segmentation
(Table V), which means that tumor segmentation remains a challenging problem. This observation is in line with recent
results in MICCAI tumor segmentation challenge, i.e. liver tumor segmentation [38] and kidney tumor segmentation [39].
• the models almost fail to predict COVID-19 infections on testing set, which highlights that the lesion appearances differ
significantly among lung cancer, pleural effusion, and COVID-19 infections in CT scans.
C. Results of Task 3: Learning with both COVID-19 and non-COVID-19 CT scans
In Task 3, heterogeneous cases from both COVID-19 and non-COVID-19 datasets are leveraged to train for segmenting lung
and infections on COVID-19 CT scans. Due to the gap between multiple domains, this data fusion is expected to explore how
fusing different annotations influences the model’s performance on each individual dataset separately.
Table VII presents quantitative 5-fold cross validation results of left lung and right lung segmentation in terms of average
DSC and NSD. It can be found that
• on the validation set, the average DSC and NSD values are basically consistent with the results in Task 2, achieving high
performance with up to 96.4% in DSC for left lung segmentation and 97.2% in DSC for right lung segmentation.
• on the testing set, however, the average DSC and NSD values slightly drop, indicating that though segmenting the same
organ lung on CT scans, there still exists some domain gaps between non-COVID-19 and COVID-19 CT datasets.
Table VIII present quantitative 5-fold cross validation results of the infection segmentation, it can be found that
• even large amounts of lung lesion annotations from non-COVID-19 dataset are used, the variance among the results of
5-fold cross validation is obvious. Thus, reporting 5-fold cross validation results is necessary in this task for reliable and
robust evaluation.
• compared with the results in Task 2 (Table VI), including four COVID-19 cases bring remarkable improvements with up
to 7.5% in DSC for StructSeg tumor segmentation, and 1.1% in DSC for NSCLC pleural effusion segmentation, while
the performance drops up to 3.3% in DSC for MSD lung tumor segmentation. These results imply that including few
out-of-domain cases in a training set can lead to significant change to the model’s performance.
• on the testing set, the relative performance drops about 4%-14% in DSC and 11%-16% in NSD, indicating that simply
fusing both COVID-19 and non-COVID-19 cases is still inefficient to segment infections on COVID-19 CT scans.
Therefore, there remains much scope for improvement to bridge the gap among many non-COVID-19 lung lesion cases
and limited COVID-19 cases by advanced knowledge transfer techniques.
D. Comparison among different tasks
Tasks 1-3 correspond to different strategies for lung and infection segmentation in COVID-19 CT scans with limited indomain training cases and out-of-domain datasets. The testing cases are the same in Tasks 1-3, so it is feasible and reasonable
to conduct comparison among different tasks. Table IX presents quantitative results on all testing sets of the three tasks in terms
of average DSC and NSD. Task 1-Separate and -Union denote training the network to segment lung and infection separately
8 We

do not apply post-processing to refine the network predictions.

9

TABLE IX: Quantitative comparison of COVID-19 CT lung and infection segmentation results among different tasks on testing
set in terms of average DSC and NSD values of all testing cases.
Left Lung
DSC (%)
NSD (%)
85.8 ± 10.5
71.2 ± 13.8
64.6 ± 26.4
51.1 ± 23.4
92.2 ± 19.7
82.0 ± 15.7
57.5 ± 21.5
46.9 ± 17.0
97.3 ± 2.1
90.6 ± 6.2
93.5 ± 5.4
76.9 ± 13.3

Subtask
Task1-Separate
Task1-Union
Task2-MSD
Task2-StructSeg
Task2-NSCLC
Task3-MSD
Task3-StructSeg
Task3-NSCLC

Right Lung
DSC (%)
NSD (%)
87.9 ± 9.3
74.8 ± 11.9
75.0 ± 16.8
57.7 ± 17.4
95.5 ± 7.2
84.2 ± 11.6
72.2 ± 15.3
51.7 ± 16.8
97.7 ± 2.1
91.4 ± 6.1
94.0 ± 5.3
77.2 ± 14.1

Infection (COVID-19-CT-Seg)
DSC (%)
NSD (%)
67.3 ± 22.3
70.0 ± 24.4
61.0 ± 26.2
61.8 ± 27.4
25.2 ± 27.4
26.0 ± 28.5
6.0 ± 12.7
5.5 ± 10.7
0.4 ± 0.9
3.7 ± 4.8
62.3 ± 25.7
61.3 ± 27.6
64.2 ± 24.5
63.3 ± 25.7
60.2 ± 25.4
58.5 ± 26.7

Infection (MosMed)
DSC (%)
NSD (%)
58.8 ± 20.6
66.4 ± 20.3
48.2 ± 22.1
41.4 ± 19.1
16.2 ± 23.2
17.5 ± 23.4
2.6 ± 9.5
3.3 ± 9.9
0.0 ± 0.0
0.5 ± 1.4
39.2 ± 30.6
41.3 ± 30.5
44.3 ± 25.3
49.1 ± 25.8
30.1 ± 26.7
33.4 ± 27.1

TABLE X: Quantitative comparison of COVID-19 CT lung and infection segmentation results among different tasks on testing
set in terms of average sensitivity and specificity values of all testing cases.
Left Lung
Right Lung
Infection (COVID-19-CT-Seg)
Infection (MosMed)
Sensitivity (%) Specificity (%) Sensitivity (%) Specificity (%) Sensitivity (%) Specificity (%) Sensitivity (%) Specificity (%)
Task1-Separate
86.2 ± 11.6
99.2 ± 1.5
89.7 ± 12.3
99.1 ± 7.3
62.0 ± 23.7
99.9 ± 15.9
57.5 ± 23.8
99.9 ± 0.0
Task1-Union
67.0 ± 28.5
98.8 ± 1.2
81.4 ± 19.5
98.2 ± 1.6
62.8 ± 27.1
99.7 ± 3.0
60.1 ± 24.3
99.9 ± 0.2
Task2-MSD
18.6 ± 23.1
100 ± 0.1
13.1 ± 22.9
100 ± 0.0
Task2-StructSeg 91.7 ± 20.8
99.9 ± 0.1
95.3 ± 10.2
99.8 ± 0.2
1.2 ± 2.4
100 ± 0.0
1.8 ± 6.9
100 ± 0.0
Task2-NSCLC
47.6 ± 23.4
99.4 ± 0.6
81.6 ± 21.7
97.4 ± 1.9
37.6 ± 26.6
100 ± 0.0
0.0 ± 0.0
100 ± 0.0
Task3-MSD
63.0 ± 27.4
99.8 ± 0.3
36.4 ± 32.7
100 ± 0.0
Task3-StructSeg
97.5 ± 2.7
99.9 ± 0.2
98.0 ± 2.0
99.8 ± 0.2
64.8 ± 25.3
99.8 ± 0.3
42.2 ± 29.5
100 ± 0.1
93.4 ± 7.1
99.7 ± 0.3
96.1 ± 3.4
99.5 ± 0.6
62.4 ± 26.7
99.7 ± 0.4
24.9 ± 25.9
100 ± 0.0
Task3-NSCLC
Subtask

Left Lung
Recall (%) Precision (%)
Task1-Separate 86.9 ± 11.2 79.6 ± 19.6
Task1-Union 67.0 ± 28.5 71.6 ± 23.9
Task2-MSD
Task2-StructSeg 91.7 ± 20.8 97.0 ± 2.1
Task2-NSCLC 47.6 ± 23.4 80.2 ± 15.0
Task3-MSD
Task3-StructSeg 97.5 ± 2.7 97.2 ± 2.8
Task3-NSCLC 93.7 ± 6.8 93.6 ± 5.9

Right Lung
Recall (%) Precision (%)
90.2 ± 13.4 77.6 ± 14.7
81.4 ± 19.5 72.8 ± 17.9
95.3 ± 10.2 96.3 ± 3.2
81.6 ± 21.7 67.3 ± 11.7
98.0 ± 2.0 97.4 ± 2.7
95.9 ± 3.8 92.3 ± 7.7

Subtask

Infection (COVID-19-CT-Seg)
Recall (%)
Precision (%)
62.0 ± 23.7
84.0 ± 19.6
62.8 ± 27.1
74.1 ± 26.2
18.6 ± 23.1
78.7 ± 34.3
1.2 ± 2.4
22.6 ± 32.8
20.7 ± 49.8
6.8 ± 11.3
63.0 ± 27.4
75.0 ± 26.1
64.8 ± 25.3
76.8 ± 24.8
62.4 ± 27.3
73.1 ± 26.9

Infection
Recall (%)
57.5 ± 23.8
60.1 ± 24.3
13.1 ± 22.9
1.8 ± 6.9
9.0 ± 3.5
36.4 ± 32.7
42.2 ± 29.5
24.9 ± 25.9

(MosMed)
Precision (%)
67.9 ± 21.7
57.7 ± 28.2
47.9 ± 38.6
9.3 ± 22.3
17.6 ± 71.8
61.4 ± 30.4
60.7 ± 26.0
61.4 ± 33.0

and simultaneously, respectively. Figure 4 shows the violin plots of left lung, right lung, and infection segmentation results
on COVID-19-CT-Seg dataset in terms of DSC and NSD for all tasks. The violin plot shows not only the summary statistics
such as median and interquartile ranges, but also the entire distribution of the quantitative results.
1.2

Left lung segmentation

1.2

Right lung segmentation

0.8

0.8

0.8

0.6

0.6

0.6

0.4
0.2

DSC

1

NSD

DSC

Left lung segmentation

1

1

0.4

0.4

0.2

0

0.2

0
0

−0.2

−0.2
Tas
k1

-S e
par

Tas
k1

Tas
k2

-U
nio

-Str

n

ate

uctS

Tas
k2
eg

-N
SC
LC

Tas
k3

-Str

uctS

Tas
k3
eg

Tas
k1
-S e
par

-N
SC
LC

Right lung segmentation

ate

Tas
k1
-U
nio
n

Tas
k2
-S

Tas
Tas
Tas
k2
k3
k3
-N
-Str
-N
tru
SC
SC
uctS
ctS
LC
LC
eg
eg

Tas
k1
-S

Infection segmentation

1

epa
r

ate

Tas
k1
-U
nio

n

Tas
k2
-Str

uctS

Tas
Tas
Tas
k2
k3
k3
-N
-Str
-N
SC
SC
uctS
LC
LC
eg

eg

Infection segmentation

1.2

1
1
0.8

0.8

0.8

DSC

NSD

NSD

0.6

0.6

0.4

0.4
0.2
0.2

0
Tas
k1

-S e
par

Tas
k1
ate

Tas
k2

-U
nio

n

-Str

uctS

Tas
k2
eg

-N
SC
LC

Tas
k3

-Str

uctS

Tas
k3
eg

-N
SC
LC

0.6
0.4
0.2

0

0

−0.2

−0.2
Tas
k1
-S

Tas
Tas
Tas
Tas
Tas
Tas
Tas
k1
k2
k2
k2
k3
k3
k3
-U
-M
-Str
-N
-M
-Str
-N
nio
SC
SC
SD
SD
uctS
uctS
LC
LC
n
ate
eg
eg

epa
r

Tas
k1
-S

Tas
Tas
Tas
Tas
Tas
Tas
Tas
k1
k2
k2
k2
k3
k3
k3
-U
-M
-Str
-N
-M
-Str
-N
nio
SC
SC
SD
SD
uctS
uctS
LC
LC
n
ate
eg
eg

epa
r

Fig. 4: The violin plots present the performances (DSC or NSD) of different methods for left lung, right lung, and infection
segmentation on COVID-19-CT-Seg testing set.
For lung segmentation,
• Task 3 achieves the best performance reaching up to 97.3% in DSC and 90.6% in NSD for left lung segmentation, and

10

97.7% in DSC and 91.4% in NSD for right lung segmentation.
comparison of the results between Task 1 and Task 2, StructSeg achieves significantly better performance than NSCLC
on the unseen testing set, indicating that the domain gap of lung between StructSeg and COVID-19 CT is smaller. The
results on NSCLC dataset with 300+ training cases are worse than the results on COVID-19 dataset with four training
cases, indicating that the number of training cases is not the most important while including the in-domain data during
learning process is much more important.
• comparison of the results between Task 1 and Task 3, adding both out-of-domain datasets (StructSeg and NSCLC) can
boost performance of left and right lung segmentation. The results imply that existing non-COVID CT annotations can be
used to assist lung segmentation in COVID-19 CT scans. This finding is very encouraging for fast developing a COVID-19
lung segmentation system with limited data especially COVID-19 CT annotations are scarce at present.
• comparison of the results between Task 2 and Task 3, adding COVID-19 cases into training set can obtain performance
gains on both subtasks (StructSeg and NSCLC), especially for NSCLC that achieves a significant increase of up to 34%
in DSC for left lung segmentation. This result highlights that including few COVID-19 cases in training set is critical for
lung segmentation.
For infection segmentation,
• Task 1 achieves the best performance in both two testing set reaching up to 67.3% in DSC and 70.0% in NSD.
• comparison of the results between Task 1 and Task 2, using four COVID-19 CT training cases obtains significant better
results than using other lung lesion cases (i.e. lung cancer and pleural effusion), which highlights the importance of
in-domain data when developing the COVID-19 infection segmentation system.
• comparison of the results between Task 1 and Task 3, adding many (40−62) non-COVID-19 cases during training degrades
instead of increasing the performance, implying that out-of-domain lung lesion data can bias the model’s representation
ability for COVID-19 infection segmentation.
• comparison of the results between Task 2 and Task 3: using only out-of-domain cases can not predict COVID-19 infections
while adding a few COVID-19 cases can significantly boost the performance, which highlights that including a few indomain cases during training is very critical for developing infection segmentation models.
In addition, it can be found that the infection segmentation performance is lower than lung segmentation in all the experiments.
There are two main reasons. First, the task setting is few-shot learning, where only limited labelled cases are allowed to train
networks. Second, compared with the lung, the infection areas are relatively small and most of the infections have weak
boundaries. Thus, infection segmentation is much more challenging than lung segmentation. Table X shows the recall and
precision of the segmentation results in different tasks. It can be found that the infection segmentation results have relatively
high precision scores and low recall scores, indicating that the model fails more in detecting all infections. Lung segmentation
results achieve better recall and precision scores because the lung tissues have more clear boundaries and larger sizes. Figure 5
presents some visualized segmentation results in different tasks. We can find that the lung segmentation mostly failed due to
the confusion between the left lung and the right lung because they share very similar appearances. The large and obvious
infections have better segmentation results. However, the infections in small sizes or with weak boundaries are the most often
failed cases.
In summary, using the non-COVID-19 chest CT dataset can directly improve the lung segmentation results significantly,
but it has few positive impacts on the infection segmentation because of the large domain gap. We found that the infections
with good contrast and clear boundaries can be well segmented even with only four training cases. However, the trained
models often miss the small infections and weak-boundary infections, indicating that it is hard for the models to capture these
features during learning process. Our results also highlight the need of efficient learning methods with limited annotated data.
Although including more training cases could be a simple and direct way to boost the infection segmentation performance,
one should keep in mind that, in clinical practice, it is impractical to manually annotate many 3D COVID-19 CT scans for
each medical center especially when the radiologists are busy with fighting the pandemic. This is our main motivation to set
up the data-efficient learning benchmark.
There are some potential solutions for the performance improvements. For example, in few-shot learning task (Task 1), one
can use more advanced data augmentation methods [40] to increase the training set. In addition, designing task-specific data
augmentation methods is also a promising solution, such as augment more cases with small and weak boundary infections.
In domain generalization task (Task 2), the models trained with only non-COVID-19 dataset fail to segment infections. One
can introduce more advanced model-agnostic learning methods to handle the domain gap, such as meta-learning [41], [42]. In
knowledge transfer task (Task 3), simply fusing non-COVID-19 and COVID-19 dataset with the SOTA network could bias the
model to learn more non-COVID-19 features. One can use more robust and powerful domain adaptation methods to handle
heterogeneous datasets, such as self-supervised learning [43], cross-domain adaptation [44], [45].
•

E. Limitation
One possible limitation is that the number of cases in our dataset is relatively small. However, this paper focuses on how to
learn from limited training cases. Thus, we believe the number of training cases is acceptable for our benchmark tasks. More

11

Case6

Case 8

Case 4

Case 9

Case 1

Case 12

Input Image

Ground Truth

Task1-Separate

Task1-Union

Task2-MSD

Task2-StructSeg

Task2-NSCLC

Task3-MSD

Task3-StructSeg

Task3-NSCLC

Fig. 5: Visualized examples of segmentation results in different tasks. The red, green, and blue color denote the left lung, the
right lung, and the infection, respectively.

importantly, this benchmark is also applicable to general small-sample learning problems. In addition, the number of cases (16
or 20 cases) for the first testing set (COVID-19-CT-Seg) and 50 cases for the second testing set (MosMed) is comparable with
recent MICCAI 2020 segmentation challenges. For example, StructSeg (Automatic Structure Segmentation for Radiotherapy
Planning Challenge 2020) has 10 testing cases [46] and ASOCA (Automated Segmentation Of Coronary Arteries) has 20 testing
cases [47]. Another limitation is that the innovative methodology contribution is limited. However, this is not the primary goal
in this paper. Rather, our main goal is to lay the foundation for future work in learning with limited annotated data, and we
believe the dataset and the tasks mentioned in the benchmark could attract attentions in the field.
V. C ONCLUSION
With the outbreak of COVID-19 around the world, it has become an emergency need to develop deep learning-based COVID19 image analysis tools with limited data. To promote the research towards this goal, in this paper, we created a COVID-19 CT
dataset, established three segmentation benchmark tasks, and provided 40+ baselines models based on state-of-the-art segmentation architectures. All the related results are publicly available at https://github.com/JunMa11/COVID-19-CT-Seg-Benchmark.
The unified task settings can make the comparison between studies more feasible. The public baselines can save model training
time for researchers so that they can focus on developing their own methods. We hope this work could accelerate the COVID-19
studies on learning with limited data for years to come.
ACKNOWLEDGMENT
This project is supported by the National Natural Science Foundation of China (No. 91630311, No. 11971229). We would like
to thank all the organizers of MICCAI 2018 Medical Segmentation Decathlon, MICCAI 2019 Automatic Structure Segmentation

12

for Radiotherapy Planning Challenge, the Coronacases Initiative and Radiopaedia, and Moscow municipal hospitals for their
publicly available lung CT dataset. We also thank Joseph Paul Cohen for providing the convenient download link of 20 COVID19 CT scans, and all the contributors of NSCLC and COVID-19-Seg-CT dataset for providing the annotations of lung, pleural
effusion and COVID-19 infection. We are grateful to the contributors of the two great COVID-19 related resources: COVID19
imaging AI paper list9 and MedSeg10 for their timely update about COVID-19 publications and datasets. Last but not least,
we thank the anonymous reviewers, Chen Chen, Xin Yang, and Yao Zhang for their important and valuable feedback on this
work.
R EFERENCES
[1] A. M. Foust, G. S. Phillips, W. C. Chu, P. Daltro, K. M. Das, P. Garcia-Peña, T. Kilborn, A. J. Winant, and E. Y. Lee, “International expert consensus
statement on chest imaging in pediatric covid-19 patient management: Imaging findings, imaging study reporting and imaging study recommendations,”
Radiology: Cardiothoracic Imaging, vol. 2, no. 2, p. e200214, 2020.
[2] M. Oudkerk, H. R. Büller, D. Kuijpers, N. van Es, S. F. Oudkerk, T. C. McLoud, D. Gommers, J. van Dissel, H. ten Cate, and E. J. van Beek, “Diagnosis,
prevention, and treatment of thromboembolic complications in covid-19: Report of the national institute for public health of the netherlands,” Radiology,
vol. 0, no. 0, p. 201629, 2020.
[3] P. J. Mazzone, M. K. Gould, D. A. Arenberg, A. C. Chen, H. K. Choi, F. C. Detterbeck, F. Farjah, K. M. Fong, J. M. Iaccarino, S. M. Janes, J. P.
Kanne, E. A. Kazerooni, H. MacMahon, D. P. Naidich, C. A. Powell, S. Raoof, M. P. Rivera, N. T. Tanner, L. K. Tanoue, A. Tremblay, A. Vachani,
C. S. White, R. S. Wiener, and G. A. Silvestri, “Management of lung nodules and lung cancer screening during the covid-19 pandemic: Chest expert
panel report,” Radiology: Imaging Cancer, vol. 2, no. 3, p. e204013, 2020.
[4] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, and W. Ji, “Sensitivity of chest ct for covid-19: comparison to rt-pcr,” Radiology, p. 200432, 2020.
[5] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang, Y. Li, X. Meng, et al., “A deep learning algorithm using ct images to screen for
corona virus disease (covid-19),” MedRxiv, 2020.
[6] G. Chassagnon, M. Vakalopoulou, E. Battistella, S. Christodoulidis, T.-N. Hoang-Thi, S. Dangeard, E. Deutsch, F. Andre, E. Guillo, N. Halm, S. El Hajj,
F. Bompard, S. Neveu, C. Hani, I. Saab, A. Campredon, H. Koulakian, S. Bennani, G. Freche, A. Lombard, L. Fournier, H. Monnier, T. Grand, J. Gregory,
A. Khalil, E. Mahdjoub, P.-Y. Brillet, S. Tran Ba, V. Bousson, M.-P. Revel, and N. Paragios, “Ai-driven ct-based quantification, staging and short-term
outcome prediction of covid-19 pneumonia,” medRxiv, 2020.
[7] S. Chaganti, A. Balachandran, G. Chabin, S. Cohen, T. Flohr, B. Georgescu, P. Grenier, S. Grbic, S. Liu, F. Mellot, et al., “Quantification of tomographic
patterns associated with covid-19 from chest ct,” arXiv preprint arXiv:2004.01279, 2020.
[8] F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, K. He, Y. Shi, and D. Shen, “Review of artificial intelligence techniques in imaging data acquisition,
segmentation and diagnosis for covid-19,” IEEE Reviews in Biomedical Engineering, 2020.
[9] Y. Wang, X. Lu, Y. Zhang, X. Zhang, K. Wang, J. Liu, X. Li, R. Hu, X. Meng, S. Dou, et al., “Precise pulmonary scanning and reducing medical
radiation exposure by developing a clinically applicable intelligent ct system: Toward improving patient care,” EBioMedicine, vol. 54, p. 102724, 2020.
[10] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and X. Wang, “Deep learning-based detection for covid-19 from chest ct using weak
label,” medRxiv, 2020.
[11] Y. Cao, Z. Xu, J. Feng, C. Jin, X. Han, H. Wu, and H. Shi, “Longitudinal assessment of covid-19 using a deep learning–based quantitative ct pipeline:
Illustration of two cases,” Radiology: Cardiothoracic Imaging, vol. 2, no. 2, p. e200082, 2020.
[12] L. Huang, R. Han, T. Ai, P. Yu, H. Kang, Q. Tao, and L. Xia, “Serial quantitative chest ct assessment of covid-19: Deep-learning approach,” Radiology:
Cardiothoracic Imaging, vol. 2, no. 2, p. e200075, 2020.
[13] K. Zhang, X. Liu, J. Shen, Z. Li, Y. Sang, X. Wu, Y. Cha, W. Liang, C. Wang, et al., and G. Wang, “Clinically applicable ai system for accurate
diagnosis, quantitative measurements and prognosis of covid-19 pneumonia using computed tomography,” Cell, 2020.
[14] A. M. V. Dadário, J. P. Q. Paiva, R. C. Chate, B. S. Machado, and G. Szarf, “Regarding ”artificial intelligence distinguishes covid-19 from community
acquired pneumonia on chest ct”,” Radiology, p. 201178, 2020.
[15] F. Shan, Y. Gao, J. Wang, W. Shi, N. Shi, M. Han, Z. Xue, D. Shen, and Y. Shi, “Lung infection quantification of covid-19 in ct images with deep
learning,” arXiv preprint arXiv:2003.04655, 2020.
[16] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in Proceedings of the IEEE conference on computer vision and
pattern recognition, 2016, pp. 770–778.
[17] O. Ronneberger, P. Fischer, and T. Brox, “U-net: convolutional networks for biomedical image segmentation,” in International Conference on Medical
image computing and computer-assisted intervention, 2015, pp. 234–241.
[18] D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, H. Fu, J. Shen, and L. Shao, “Inf-net: Automatic covid-19 lung infection segmentation from ct scans,”
arXiv, 2020.
[19] T. Zhou, S. Canu, and S. Ruan, “An automatic covid-19 ct segmentation network using spatial and channel attention mechanism,” arXiv preprint
arXiv:2004.06673, 2020.
[20] Q. Yu, Y. Liu, and J. Xu, “Miniseg: An extremely minimum network for efficient covid-19 segmentation,” arXiv preprint arXiv:2004.09750, 2020.
[21] A. Amyar, R. Modzelewski, and S. Ruan, “Multi-task deep learning based ct imaging analysis for covid-19: Classification and segmentation,” medRxiv,
2020.
[22] X. Chen, L. Yao, and Y. Zhang, “Residual attention u-net for automated multi-class segmentation of covid-19 chest ct images,” arXiv preprint
arXiv:2004.05645, 2020.
[23] A. Zhao, G. Balakrishnan, F. Durand, J. V. Guttag, and A. V. Dalca, “Data augmentation using learned transformations for one-shot medical image
segmentation,” in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.
[24] A. G. Roy, S. Siddiqui, S. Pölsterl, N. Navab, and C. Wachinger, “‘squeeze & excite’guided few-shot segmentation of volumetric images,” Medical
image analysis, vol. 59, p. 101587, 2020.
[25] D. Li, J. Zhang, Y. Yang, C. Liu, Y.-Z. Song, and T. M. Hospedales, “Episodic training for domain generalization,” in Proceedings of the IEEE
International Conference on Computer Vision, 2019, pp. 1446–1455.
[26] Q. Dou, D. C. de Castro, K. Kamnitsas, and B. Glocker, “Domain generalization via model-agnostic learning of semantic features,” in Advances in
Neural Information Processing Systems, 2019, pp. 6450–6461.
[27] F. Yu, J. Zhao, Y. Gong, Z. Wang, Y. Li, F. Yang, B. Dong, Q. Li, and L. Zhang, “Annotation-free cardiac vessel segmentation via knowledge transfer
from retinal images,” in International Conference on Medical Image Computing and Computer-Assisted Intervention, 2019, pp. 714–722.
[28] D. Eschweiler, T. Klose, F. N. Müller-Fouarge, M. Kopaczka, and J. Stegmaier, “Towards annotation-free segmentation of fluorescently labeled cell
membranes in confocal microscopy images,” in International Workshop on Simulation and Synthesis in Medical Imaging, 2019, pp. 81–89.
9 https://github.com/HzFu/COVID19

imaging AI paper list

10 http://medicalsegmentation.com/covid19/

13

[29] K. Kiser, S. Ahmed, S. Stieb, A. Mohamed, H. Elhalawani, P. Park, N. Doyle, B. Wang, A. Barman, C. Fuller, and L. Giancardo, “Data from the thoracic
volume and pleural effusion segmentations in diseased lungs for benchmarking chest ct processing pipelines,” The Cancer Imaging Archive, 2020.
[30] H. J. Aerts, E. R. Velazquez, R. T. Leijenaar, C. Parmar, P. Grossmann, S. Carvalho, J. Bussink, R. Monshouwer, B. Haibe-Kains, D. Rietveld, et al.,
“Decoding tumour phenotype by noninvasive imaging using a quantitative radiomics approach,” Nature communications, vol. 5, no. 1, pp. 1–9, 2014.
[31] K. W. Clark, B. A. Vendt, K. E. Smith, J. B. Freymann, J. S. Kirby, P. Koppel, S. M. Moore, S. R. Phillips, D. R. Maffitt, M. Pringle, L. Tarbox, and
F. W. Prior, “The cancer imaging archive (tcia): Maintaining and operating a public information repository,” J. Digital Imaging, no. 6, pp. 1045–1057,
2013.
[32] S. Morozov, A. Andreychenko, N. Pavlov, A. Vladzymyrskyy, N. Ledikhova, V. Gombolevskiy, I. Blokhin, P. Gelezhe, A. Gonchar, V. Chernina, and
V. Babkin, “Mosmeddata: Chest ct scans with covid-19 related findings,” medRxiv, 2020.
[33] J. Ma, C. Ge, Y. Wang, X. An, J. Gao, Z. Yu, M. Zhang, X. Liu, X. Deng, S. Cao, H. Wei, S. Mei, X. Yang, Z. Nie, C. Li, L. Tian, Y. Zhu, Q. Zhu,
G. Dong, and J. He, “COVID-19 CT Lung and Infection Segmentation Dataset,” 2020. [Online]. Available: https://doi.org/10.5281/zenodo.3757476
[34] S. Nikolov, S. Blackwell, R. Mendes, J. De Fauw, C. Meyer, C. Hughes, H. Askham, B. Romera-Paredes, A. Karthikesalingam, C. Chu, et al., “Deep
learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy,” arXiv preprint arXiv:1809.04430, 2018.
[35] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger, “3d u-net: learning dense volumetric segmentation from sparse annotation,” in
International conference on medical image computing and computer-assisted intervention, 2016, pp. 424–432.
[36] F. Isensee, J. Petersen, S. A. A. Kohl, P. F. Jäger, and K. H. Maier-Hein, “nnu-net: Breaking the spell on successful medical image segmentation,” arXiv
preprint arXiv:1904.08128, 2020.
[37] L. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, “Deeplab: Semantic image segmentation with deep convolutional nets, atrous
convolution, and fully connected crfs,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 40, no. 4, pp. 834–848, 2018.
[38] P. Bilic, P. F. Christ, E. Vorontsov, G. Chlebus, H. Chen, Q. Dou, C.-W. Fu, X. Han, P.-A. Heng, J. Hesser, et al., “The liver tumor segmentation
benchmark (lits),” arXiv preprint arXiv:1901.04056, 2019.
[39] N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, Y. Nan, G. Mu, Z. Lin, M. Han, et al., “The state of the art in kidney and kidney tumor
segmentation in contrast-enhanced ct imaging: Results of the kits19 challenge,” arXiv preprint arXiv:1912.01054, 2019.
[40] J. Xu, M. Li, and Z. Zhu, “Automatic data augmentation for 3d medical image segmentation,” in International Conference on Medical Image Computing
and Computer-Assisted Intervention, 2020, pp. 378–387.
[41] Q. Dou, D. Coelho de Castro, K. Kamnitsas, and B. Glocker, “Domain generalization via model-agnostic learning of semantic features,” Advances in
Neural Information Processing Systems, vol. 32, pp. 6450–6461, 2019.
[42] P. Khandelwal and P. Yushkevich, “Domain generalizer: A few-shot meta learning framework for domain generalization in medical imaging,” in Domain
Adaptation and Representation Transfer, and Distributed and Collaborative Learning, 2020, pp. 73–84.
[43] Z. Zhou, V. Sodha, M. M. Rahman Siddiquee, R. Feng, N. Tajbakhsh, M. B. Gotway, and J. Liang, “Models genesis: Generic autodidactic models for
3d medical image analysis,” in Medical Image Computing and Computer Assisted Intervention – MICCAI 2019, 2019, pp. 384–393.
[44] C. Chen, Q. Dou, H. Chen, J. Qin, and P. A. Heng, “Unsupervised bidirectional cross-modality adaptation via deeply synergistic image and feature
alignment for medical image segmentation,” IEEE Transactions on Medical Imaging, 2020.
[45] Q. Liu, Q. Dou, L. Yu, and P. A. Heng, “Ms-net: Multi-site network for improving prostate segmentation with heterogeneous mri data,” IEEE Transactions
on Medical Imaging, 2020.
[46] H. Li and M. Chen, “Automatic Structure Segmentation for Radiotherapy Planning Challenge 2020,” 2020. [Online]. Available: https:
//doi.org/10.5281/zenodo.3718885
[47] R. Gharleghi, D. G. Samarasinghe, P. A. Sowmya, and D. S. Beier, “Automated segmentation of coronary arteries,” 2020. [Online]. Available:
https://doi.org/10.5281/zenodo.3714986

