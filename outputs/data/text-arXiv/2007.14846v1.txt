1

An Uncertainty-aware Transfer Learning-based
Framework for Covid-19 Diagnosis

arXiv:2007.14846v1 [eess.IV] 26 Jul 2020

Afshar Shamsi Jokandan, Hamzeh Asgharnezhad, Shirin Shamsi Jokandan,
Abbas Khosravi, Parham M. Kebria, Darius Nahavandi, Saeid Nahavandi, and Dipti Srinivasan

Abstract—The early and reliable detection of COVID-19 infected patients is essential to prevent and limit its outbreak.
The PCR tests for COVID-19 detection are not available in
many countries and also there are genuine concerns about their
reliability and performance. Motivated by these shortcomings,
this paper proposes a deep uncertainty-aware transfer learning
framework for COVID-19 detection using medical images. Four
popular convolutional neural networks (CNNs) including VGG16,
ResNet50, DenseNet121, and InceptionResNetV2 are first applied
to extract deep features from chest X-ray and computed tomography (CT) images. Extracted features are then processed by
different machine learning and statistical modelling techniques
to identify COVID-19 cases. We also calculate and report the
epistemic uncertainty of classification results to identify regions
where the trained models are not confident about their decisions
(out of distribution problem). Comprehensive simulation results
for X-ray and CT image datasets indicate that linear support
vector machine and neural network models achieve the best
results as measured by accuracy, sensitivity, specificity, and AUC.
Also it is found that predictive uncertainty estimates are much
higher for CT images compared to X-ray images.
Index Terms—COVID-19, deep learning, transfer learning,
uncertainty quantification, classification

I. I NTRODUCTION

T

HE novel corona virus disease pneumonia (COVID-19)
is a newly emerged viral disease causing a world-wide
pandemic. The World Health Organization (WHO) [1] has
already listed the COVID-19 outbreak as the sixth international public health emergency, following H1N1 (2009), polio
(2014), Ebola in West Africa (2014), Zika (2016) and Ebola
in the Democratic Republic of Congo (2019). As of May
2020, it has impacted around 170 countries and regions. There
are globally more than 4m identified COVID-19 cases and
the number of death is fast approaching 300k. Lock downs
and restrictions have been applied by authorities in different
countries to slow down its spread. The impact on the world
economy has been massive due to restrictions applied to
people’s movement and the disruption of supply chains.
Screening suspected patients and the early diagnosis of
COVID-19 is the best way to prevent its outbreak within a
A. Sh. Jokandan and Sh. Sh. Jokandan are with ASR group, Tehran, Iran
(e-mails: {afshar.shamsi.j@gmail.com, shirinshamsijokandan@yahoo.com}).
H. Asgharnezhad is an individual researcher, Tehran, Iran (e-mail:
dara1400@gmail.com).
A. Khosravi, P. M. Kebria, D. Nahavandi, and S. Nahavandi are with the
Institute for Intelligent Systems Research and Innovation (IISRI), Deakin
University, Australia (e-mails: {abbas.khosravi, kebria, darius.nahavandi,
saeid.nahavandi}@deakin.edu.au).
D. Srinivasan is with Department of Electrical and Computer Engineering,
National University of Singapore (e-mail: dipti@nus.edu.sg).

society. The sooner the diagnosis, the faster and smoother
the medical recovery. The real-time polymerase chain reaction
(real-time PCR) is the standard test for diagnosis of COVID19 [2]. There are other complementary testing frameworks as
well. Chest radiography (X-ray) [3] and computed tomography
(CT) scanning have been used for the detection of COVID-19
[4]. These imaging techniques are more accessible in common
health settings in many countries. Besides, as real-time PCR
is not available at scale in many countries, the interest for
COVID-19 diagnosis using medical imaging techniques has
increased.
Machine learning techniques, deep learning models, and
convolutional neural networks (CNNs) have been widely applied in recent years for medical imaging computer aided
diagnosis [5], [6], [7], [8], [9]. A deep learning framework
for detection pneumonia in chest X-ray images is proposed
in [10]. Authors use region-based CNNs to configure regional
context which helps finding accurate results. [11] proposes a
novel deep learning algorithm that can detect pneumonia from
chest X-rays at a level exceeding practicing radiologists. The
CheXNet is a 121 CNN which has been trained using 112,120
frontal-view chest X-ray images individually labeled [11].
Training multilayer CNNs requires a massive amount of
data and compute resources. Currently the availability of thousands of images with proper labels is a barrier for developing
reliable CNNs for the detection of COVID-19 using computer
vision techniques. [12] proposed a transfer learning-based
framework for early detection of COVID-19 cases using X-ray
images. The obtained accuracies for binary and multi-classes
are 98.08% and 87.02% respectively. Authors in [13] apply
the transfer learning concept and use five pretrained CNNs
for extracting features and processing them using feedforward
neural networks. Obtained results indicate that the VGG19 and
the MobileNet outperform others in terms of the classification
accuracy. Also, it is observed that the MobileNet outperforms
VGG19 in terms of specificity [13]. ResNet50, InceptionV3,
and InceptionResNetV2 networks are used in [14] for automatic detection of COVID-19 using X-rays. Performance
results suggest that the ResNet50 pretrained model achieves
the highest accuracy of 98% amongst considered CNNs.
A deep learning-based framework for COVID-19 detection
using CT images was proposed in [15]. The reported experimental results in the paper show that the proposed model
model precisely identifies the COVID-19 cases from others
with an AUC of 0.99 and recall (sensitivity) of 0.93. In
[16], machine learning techniques are applied for detection
of COVID-19 cases from patches obtained from 150 CT

2

images. Authors in [17] demonstrate that weakly-supervised
deep learning algorithms could achieve promising results for
COVID-19 detection. The number of collected sample is 499
which are processed using segmentation techniques and 3D
CNNs. A deep learning framework is also proposed in [18]
for detection COVID-19 and influenza-A viral pneumonia. The
overall accuracy of developed models for 618 CT images is
86.7%.
All these studies report promising results for CNN models trained using a limited number of images. Deep neural
networks often have hundred and thousands of trainable parameters that their fine tuning requires massive amounts of
data. Besides, the limited number of samples raise concerns
about epistemic uncertainty [19]. It is not clear how one can
trust these models for a new case assuming they have been
developed using a very limited number of training samples.
These models could easily fail in real world applications if the
training and testing samples are different [20] or far from the
support of the training set (out of distribution samples) [21].
None of these models are able to report their lack of confidence for new cases. That information is essential for their
widespread deployment as a reliable medical diagnosis tool
[22]. Identifying and flagging these difficult to predict samples
has much more practical values than correctly classifying
them. A radiologist may consult with their senior colleagues
when dealing with ambiguous or unknown cases. Accordingly,
it is too important for DNNs to generate uncertainties as an
additional insight to their point estimates [23]. This extra
insight greatly improves the overall reliability in decisionmaking as the user will know when and where they can trust
predictions generated by the model. The unflagged erroneous
diagnosis could lead to unfortunate life losses which could
easily blockade further machine and deep learning applications
in medicine [19].
Motivated by these shortcomings, this paper proposes a
novel transfer learning-based and uncertainty-aware framework for reliable detection of COVID-19 cases from Xray and CT images. We use four pretrained CNN models
(VGG16, DenseNet121, InceptinResNetV2 and ResNet50) to
hierarchically extract informative and discriminative features
from X-ray and CT images. This transfer learning approach
is essential and efficient considering the limited number of
samples. Extracted deep features are then passed to a number
of machine learning model for the supervised classification
task. Different performance metrics are computed for the
comprehensive evaluation and the fair comparison of obtained
results from different CNN architectures and classifiers. Last
but not least, we also investigate the impact of lack of data
on the reliability and quality of the classification results.
The type of uncertainty that is important for deep learning
models used for COVID-19 diagnosis is epistemic uncertainty
which captures the model lack of knowledge about the data
[24]. We then develop an ensemble of neural network models
trained using different deep features to generate predictive
uncertainty estimates. The quantified epistemic uncertainties
provide informative hints about where and how much one can
trust the model predictions.
The rest of the paper is organized as follows. Section II

introduces our proposed method for classification and uncertainty quantification. Datasets and classification techniques are
explained and introduced in section III. Section IV discusses
obtained results and simulations in detail. Finally, the study is
summarized in section V.
II. P ROPOSED M ETHOD
A. Transfer Learning-based Classification
We will here apply the transfer learning approach to train
machine learning models for COVID-19 detection. Two major
issues motivate us to solve the COVID-19 detection using a
transfer learning framework: (i) training DNN/CNN models
require massive amount of data. This is not practical for
COVID-19 as the number of collected and labeled images
is very limited and often in the order of a few hundreds;
(ii) training DNN/CNN models is computationally demanding.
Even if thousands and millions of images are available, still it
makes sense to first check the usefulness of existing pretrained
models for data representation and feature extraction.
The proposed framework purely uses information content
of X-rays and CT images to identify the presence of COVID19. Here we consider five pretrained networks on ImageNet
dataset and import and adapt them for the task of COVID19 detection. These networks are VGG16 [25], ResNet50
[26], DenseNet121, and InceptionResNetV2 [27]. All these
networks have achieved state of the art performance for
correctly classifying images of the ImageNet dataset. Training
of these networks is computationally very demanding as they
have many layers and millions of trainable parameters. The
main hypothesis in the proposed framework is that there are
fundamental similarities between image detection/recognition
tasks and the binary classification problem of COVID-19 using
images. Accordingly, learnings from the former one can be
safely ported to the later one to shorten the training process.
While all five pretrained networks have been developed using
non-medical images, it is reasonable to assume that their
transformation of X-ray and CT image pixels could make the
classification task easier.
As shown in Fig. 1, the parameters of the convolutional
layers are kept frozen during the training process. The convolutional layers of these five pretrained models are fed by X-ray
and CT images for hierarchical feature extractions. The front
end of the pretrained networks is then replaced by different
machine learning classifiers to separate Covid and non-Covid
cases. It is important to mention that we drop the pooling
operation in the last convolutional layer of these pretrained
networks. This is to avoid loosing informative features before
passing them to the classification models.
B. Uncertainty Quantification
Any classification study without reporting the predictive
uncertainty estimates is not complete. There are two types of
uncertainties which needs to be considered for deep learning
models [28]:
• Aleatoric uncertainty which is related to the noise inherent in the data generating process. This type of uncertainty is irreducible.

3

Pre-Trained Deep Convolution Models:
DenseNet121, InceptionResNetV2, ResNet50, VGG16

FC Layers
1000 classes:
dog
cat
lion
bicycle
⋮

Transferring Weights
Chest X-ray
and CT Images

Pre-Trained Convolution Layers

(a) Covid

Trainable Parameters:
The 8 Classifiers

Fig. (2)

(b) Normal

Two sample images from X-ray dataset.

2 Classes:
COVID-19
COVID-19

Fig. (1) Block diagram of the proposed transfer learningbased framework for the COVID-19 detection using X-ray and
CT images.

Epistemic uncertainty which captures the ignorance about
the model. In contrast to aleatoric uncertainty, epistemic
uncertainty is reducible with collection of more training
samples from diverse scenarios [29].
In this paper, we mainly focus on epistemic uncertainty as
it closely relates to the generalization power of models for
new samples [30] [31] [32]. Here we will use an ensemble
of diverse models to obtain uncertainties associated with
made inferences [30]. An ensemble consists of several models
developed with different architectures, types, and sampled
subsets. These model development differences cause diversity
in the generalization power of models. Predictions obtained
from individual models are then aggregated to obtain the
final prediction. The prediction variance could be used for the
calculation of the epistemic uncertainty [33].
Similar to work in [24] and [34], we calculate the prediction
entropy as a measure of the epistemic uncertainty. the prediction entropy is a metric to measure the uncertainty in scores
generated by different models [34]. The ensemble epistemic
uncertainty is calculated as the entropy of the mean predictive
distribution (by averaging all predicted distribution):

(a) Covid

•

p̂(y|x) =

H(p̂(y|x)) =

N
1 X
pθ (y|x)
N i=1 i
C
X

p̂(yi |x) log p̂(yi |x)

(1)

(2)

i=0

where θi is the set of parameters for ith network element, and
C ranges over all classes. For instance, suppose for a given
input, an individual neural network predicts that the input is
belongs to class 1 with x amount of probability and to class 0
with y amount. If we repeat this procedure 10 times for that
specified input, it is similar to ensembling 10 networks for
predicting the output probability. The final output probability
can be calculated using Eq. 1. Now, imagine the average
probability predicts that an input belongs to class 1 and 0
with 0.6 and 0.4 respectively. Based on Eq. 2, the prediction
entropy can be calculated as 0.6∗log(0.6)+0.4∗log(0.4). It is
obvious that the prediction entropy is become zero when the

Fig. (3)

(b) Normal

Two sample images from CT dataset.

output is assigned to a class with high probability, and become
maximum when the network is uncertain about its outcome.
III. E XPERIMENT S ETUP
A. Datasets
There are two types of datasets used in this study: chest Xray and breast CT scan. These two types of imagery datasets
are the main sources of information that clinicians use for
COVID-19 diagnosis. The description of these datasets is
provided in this section. Also statistical and machine learning
classifiers applied to process features extracted by CNNs are
briefly introduced.
1) Chest X-ray Dataset: This dataset is formed by taking 25
images of COVID-19 from [35] in the first step. We then add
another 75 non-Covid cases of chest X-ray image from [36]. It
is important to note that these non-Covid (normal) cases might
consist of other unhealthy conditions such as bacterial or viral
infections, chronic obstructive pulmonary disease and even a
combination of two or more. Accordingly, what we mean by a
normal or non-Covid case does not necessarily infer a healthy
lower respiratory system. Two images of covid and normal
classes are shown in Fig. 2. Fig. 2b displays a normal (nonCovid) case, yet virally infected. All images in this dataset are
accessible via this link: https://github.com/dara1400/Covid19Xray-Dataset.
2) CT Dataset: CT dataset has 349 Covid images and 397
non-Covid images [37]. Health professionals prefer breast CT
scans as they carry more information compared to chest Xrays to use for medical diagnosis. Fig. 3 shows both a Covid
and a non-Covid case from the CT database.
B. Pretrained Models
Here we briefly introduce the four CNNs used in this study
for extracting features.

4

1) VGG16: [25] This model is similar to AlexNet and
consists of 13 convolution, nonlinear rectification, pooling and
3 fully connected layers [38]. The filter size of convolutional
network is 3 ∗ 3 and the pooling size is 2 ∗ 2. Due to its simple
architecture, VGG network is performed better than AlexNet.
2) ResNet50: [26] Residual convolutional network
(ResNet) is one the most popular deep structure which is used
for classification problem (winner of ImageNet competition
in 2015). Residual blocks enables the network to provide
direct path to its early layers. This helps the gradient flow
easily in the back propagation algorithm.
3) DenseNet121: [39] DenseNet won the ImageNet competition in 2017. Traditional deep networks have only one
connection between layers. However in DenseNet, all layers
receive all feature maps from previous layers as input [39].
This helps the network to decrease the number of parameters
and also relieve the gradient vanishing.
4) InceptionResNetV2: Szegedy et al [27] presented a novel
structure which helps to go deeper through convolution networks. Deep networks are prone to overfitting. They solve
this solution using inception blocks. Further, they use residual
blocks and create InceptionResNetV2 which use the combination of residual and inception blocks wisely.
High level information about these pretrained models is
provided in Table I. As illustrated in Fig. 1, network weights
are kept frozen during the transfer learning procedure. The
size of our input images is 224×224 for VGG16, ResNet50
and DenseNet121. The input size for the InceptionResNetV2
architecture is 299×299.
C. Classification Methods
The COVID-19 detection is a binary classification problem
where the input is an image (chest X-ray or CT image)
and the output is a binary label representing the presence or
absence of COVID-19. Here images are first processed by the
convolutional layers of five pretrained networks. Hierarchically
extracted features are then processed by multiple classifiers.
We use eight classifiers to process features: k-nearest neighbors (NN), linear support vector machine (linear SVM), radial
basis function (RBF) SVM, Gaussian process (GP), random
forest (RF), multi-layer perceptron (NN), Adaboost, and Naive
Bayes. These classifiers are briefly introduced below:
1) k-Nearest Neighbor (kNN): kNN is one of the simplest
classification algorithm. It keeps a copy of all samples and
classifies samples based on a similarity measure. This similarity measure is usually a kind of distance in the feature
space. Most commonly used distance measures are Euclidean
and Minkowski. In this paper, we use k = 2 and Minkowski
distance metric for the classification task. The Minkowski is
calculated as this:

D(x, y) =

n
X

!1/p
p

|xi − yi |

2) Support Vector Machine (SVM): It is a practical solution
for classification problem especially in high dimensions. SVM
uses line or hyperplane for dividing the data into appropriate
classes. It tries to find a hyperplane with the largest distance
to the most near data for each class (margin). The lower
generalization error will be achieved when the margin becomes
large [40].
3) RBF SVM: It is a kind of SVM which uses the radial
basis function (RBF) kernel for calculating the similarity
(distance) between two samples. RBF kernel for two typical
samples (x, y) can be calculated as below:
||x − y||
)
(4)
2σ 2
4) Gaussian Process (GP): It is a set of random variables
in a way that each set is described by a multivariate normal
distribution. The final distribution of a GP is a joint distribution
of all those random variables. GP uses covariance matrix
and its inversion thus it will be a lazy learning algorithm
in high dimension space. It outputs a distribution which not
only estimates the prediction, but also provides prediction
uncertainty estimates. We use RBF kernel with a length-scale
equal to one for GP classifiers in this study.
5) Neural Network (NN): A feedforward NN finds a nonlinear mapping between the fixed size inputs and the output
(target). The network is composed of several hidden layers and
processing units called neurons. A neuron receives inputs from
neurons of the previous layer and generates its own output
based on the assigned activation function. The connection
weights between layers of the network are trained using
training algorithms such as stochastic gradient descent or
adaptive moment estimation (Adam).
6) Random forest (RF): RF classifier includes several decision trees developed in parallel. These trees are developed
by randomly selecting a subset of features and samples from
the original training samples. Each tree will vote and the class
which has the most votes will be the final prediction. In this
paper, we set the number of decision trees to 10.
7) Adaboost: Adaboost forms an efficient classifier by
mixing several weak classifiers. Classifiers are formed in a
serial approach in contrast to RF where classifiers are formed
in parallel. Each classifier focuses on fixing mistakes made by
previous classifiers. We here set the number of weak classifiers
to 50.
8) Naive Bayes: Naive Bayes classifiers are the simplest
Bayesian networks that use Bayes theorem. We use Gaussian
naive Bayes which predict a posterior using a normal prior
based on the Bayes theory.
Full information about these classifiers could be found in
basic machine learning and statistical books [41], [42], [43],
[44].
K(x, y) = exp(−

IV. S IMULATIONS AND R ESULTS
(3)

i=1

If p =2, the Minkowski distance is the same as the Euclidean
distance.

The simulation results and discussions are provided in this
section. We first present results obtained by different classifiers
processing features extracted by pretrained CNNs. We then
focus on the uncertainty quantification problem using NN

5

TABLE (I)
Architecture
VGG16
ResNet50
DenseNet121
InceptionResNetV2

Information about four considered architectures for transfer learning
Paper
2014
2015
2017
2015

Year Proposed
[25]
[26]
[39]
[27]

Input Size
224×224
224×224
224×224
299×299

Number of Features
25,088
100,352
50,176
98,304

Number of Parameters
14,714,688
23,587,712
7,037,504
54,336,736

AdaBoost

Gaussian Process

Linear SVM

Naive Bayes

Nearest Neighbors

Neural Net

Random Forest

RBF SVM

1.00
0.75
0.50
0.25
0.00

1.00
0.75
0.50
0.25
0.00
Accuracy

(a) CT

Specificity

Accuracy

Sensitivity

Specificity

Accuracy

Sensitivity

Specificity

Accuracy

Sensitivity

Specificity

(a) CT

(b) X-ray

Fig. (4) 2D representation of X-ray and CT images processed
by VGG16 and principal component analysis.

Sensitivity

AdaBoost

Gaussian Process

Linear SVM

Naive Bayes

Nearest Neighbors

Neural Net

Random Forest

RBF SVM

1.00
0.75
0.50
0.25
0.00

1.00

models and discuss its importance for the diagnosis of COVID19.
To build an intuition about samples, we first extract deep
features using the method shown in Fig. 1 and then map them
to the 2D space using principal component analysis (PCA)
algorithm. Fig. 4 displays VGG16 features in the 2D space.
As reported in Table I, the total number of extracted features
for VGG16 is 25,088. Obviously, the number of samples for
CT dataset is much higher and it is more balanced than the
X-ray dataset. Also, it is interesting to see that normal (nonCovid) and Covid cases are fairly distinguishable for X-ray
images in 2D space. In contrast, the decision boundary cannot
be reasonably drawn in two dimensions for CT images.
Accuracy, sensitivity, and specificity are considered for the
model evaluation. Purely relying on accuracy could lead to
misleading results as both datasets and in particular X-ray one
are imbalanced. For obtaining statistically valid conclusions,
we train every single classifier 100 times using obtained
features from pretrained CNNs. For each run, the performance
metrics are calculated and then the box plot graph is generated.
Fig. 5 represents the box plots for CT and X-ray datasets,
respectively for the accuracy, sensitivity and specificity. It is
noted that those values are calculated without PCA for all
classifiers trained 100 times (all features passed to classifiers).
It is observed that the more the number of features, the
less the ability of RBF SVM and GP to correctly classify
samples. This is because they use the covariance matrix and
its inversion, which in turn drops the sensitivity value to zero,
making them unreliable. In contrast, linear SVM and NN
prove to be the best ones among considered classifiers. This
is because they use simple hyperplanes to separate features of
two classes.
ROC curves for all pretrained CNNs and classifiers are
shown in Fig. 6 for a typical run. As expected, linear SVM
and NN models have the highest AUC values amongst all
classifiers. An important observation is that the performance of

0.75
0.50
0.25
0.00
Accuracy

Sensitivity

Specificity

Accuracy

Sensitivity

Specificity

Accuracy

Sensitivity

Specificity

Accuracy

Sensitivity

Specificity

(b) X-ray

Fig. (5) The figures represent the distribution of Accuracy,
Sensitivity and Specificity associated with CT and X-ray
datasets, respectively (the top results are for CT dataset of
our different classifiers).

classifiers significantly varies based on hierarchically extracted
features by convolutional layers of four pretrained CNNs.
To comprehensively compare different architectures for feature extraction, we train and evaluate each classifier 100 times.
Then we average all predictions to obtain a reliable estimate
of the sample label. Then performance metrics including
accuracy, sensitivity, specificity, and AUC value are calculated.
Table II and III report these performance metrics for CT and
X-ray datasets. Reported values are given in percent. Having
compared all models, we find that no model outperforms
others for most cases than others. Linear SVM also achieves
best results for each model.
Comparing the designed network to that of [37], our transfer
learning-based method outperforms theirs. The best results
are achieved using ResNet50 and linear SVM classifier (an
accuracy of 87.9%). This is more than 3% better than the best
results reported in [37]. (84.7% accuracy). This improvement
is mainly due to a better hierarchical extraction of features
using ResNet50 and an optimal selection of the classifier
(linear SVM).
It is also important to consider the network size and the
number of deep features when comparing performance of
pretrained CNNs for COVID-19 detection. Fig. 7 and Fig. 8
show the average of the classification performance (accuracy
and AUC) for linear SVM and NN models in the 2D space

6

(a) VGG16

(b) InceptionResNetV2

(c) ResNet50

(d) DenseNet121

Fig. (6) ROC-AUC plots are shown for CT images using 4 architectures (VGG16, InceptionResNetV2, ResNet50, and
DenseNet121) and 8 classifiers. As can be seen, linear SVM and NN (MLP) are the bests and their AUC value s are greater
than others. Also it is noted that the performance of classifiers closely depends on the quality of features extracted by the
convolutional layers of four considered architectures.

Model

Model

Specificity
80.1 ± 8.4
1.0
86.8 ± 6.3
77 ± 11.5
88.8 ± 5.3
84.6 ± 24
1.0
76.3 ± 11.7
77.5 ± 9.7
1.0
91.9 ± 7.4
75 ± 12.8
92 ± 4.4
82.6 ± 29
1.0
73.4 ± 13
78 ± 9.8
1.0
89.1 ± 5.4
50 ± 25.4
91.1 ± 4.8
88.3 ± 27.9
1.0
80.6 ± 10.1
79.2 ± 8.9
1.0
88.1 ± 5.9
55 ± 22.5
97.1 ± 2.5
87.6 ± 27
1.0
82 ± 9.5

AUC
81.9 ± 5.8
0.5 ± 0.9
93.1 ± 3.4
77 ± 9.1
86.8 ± 5.4
92.7 ± 13.4
57 ± 3.1
67.4 ± 10.3
82.7 ± 7.4
0.5 ± 0.4
91.9 ± 4.1
77.3 ± 13.6
84.4 ± 6.8
87.8 ± 15.6
55 ± 2.4
68.7 ± 11.6
83.9 ± 7.6
0.5 ± 0.4
94.2 ± 2.9
60.1 ± 5.5
87.2 ± 6.4
91.7 ± 16.7
51 ± 0.8
63.3 ± 11.4
84.2 ± 7.1
0.5 ± 0.4
93.3 ± 3.3
64.8 ± 8.9
83.8 ± 6.2
92.8 ± 18.6
0.5 ± 0.4
64.2 ± 11.8

formed by the number of CNN parameters (millions) and
the number of features (ten thousands). The size of each
point represents the accuracy and AUC metrics of the trained
classifiers using features extracted by pretrained CNNs. The
bigger the point, the better the performance. We generate
these charts only for linear SVM and NN models as they
are the best performing ones according to results presented
in Table II and Table III. According to Fig. 7 and Fig. 8,
VGG16 is the most efficient pretrained CNNs for COVID19 detection. It has the least number of parameters and
extracts the smallest number of features. Those features are the
most informative and discriminative ones as both linear and
NN models achieve the best results using them. In contrast,
the massive network of InceptionResNetV2 offers the most

InceptionResNetV2

Sensitivity
76.5 ± 11.5
0.0
84.9 ± 8.4
72.4 ± 24.4
69.7 ± 13.5
82 ± 28
0.0
46.2 ± 17.7
72.6 ± 12.8
0.0
83.2 ± 9
76.6 ± 3.8
57.3 ± 14.9
79.4 ± 28.1
0.0
42.3 ± 18
73.9 ± 13.5
0.0
86.5 ± 7.1
70.1 ± 30.6
65.2 ± 14.4
83.1 ± 30.4
0.0
35.1 ± 16.4
73.9 ± 13.1
0.0
84.8 ± 8.2
74.5 ± 18.9
42.3 ± 14
85.8 ± 32.1
0.0
34.4 ± 16.4

ResNet50

Accuracy
78.9 ± 7.6
53.1 ± 10.9
85.9 ± 5.9
74.9 ± 5.5
79.8 ± 6
83.4 ± 14.4
53.1 ± 2.3
62.3 ± 9.2
75.2 ± 8.3
53.1 ± 10.9
84.3 ± 7.3
75.7 ± 2.5
75.8 ± 8.2
80.7 ± 16.5
53.1 ± 11
59.1 ± 9.9
76.1 ± 9.4
53.1 ± 11
87.9 ± 5.8
59.5 ± 9.8
78.9 ± 8.2
84.6 ± 16.4
53.1 ± 11
59.3 ± 9.1
76.8 ± 7.8
53.1 ± 11
86.5 ± 5.8
64.2 ± 12.2
71.4 ± 6.9
84.6 ± 16.3
53.1 ± 11
59.7 ± 9

VGG16

InceptionResNetV2
ResNet50
VGG16

Classifier
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest

DenseNet121

TABLE (III) Performance comparison of 4 architectures and
8 classifiers (32 combinations) for X-ray images. All values
are given in percent.

DenseNet121

TABLE (II) Performance comparison of 4 architectures and
8 classifiers (32 combinations) for CT images. All values are
given in percent.

Classifier
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest
AdaBoost
Gaussian Process
Linear SVM
Naive Bayes
Nearest Neighbors
Neural Net
RBF SVM
Random Forest

Accuracy
91 ± 5.9
74.8 ± 1.7
96.4 ± 3.1
82.3 ± 5
89.4 ± 4.6
93.2 ± 5.7
75 ± 1.7
78.9 ± 4.3
89.5 ± 5.6
74.8 ± 1.7
98 ± 3.2
75.3 ± 2
89.9 ± 5.4
89.9 ± 12.6
75.1 ± 1.7
77.6 ± 4.3
92.6 ± 6.1
75.1 ± 1.6
98.6 ± 2.1
77.8 ± 3.9
94 ± 4.4
92.5 ± 6.4
75 ± 1.7
76.3 ± 3.3
89.9 ± 5.5
74.1 ± 1.7
96.6 ± 3.4
90.2 ± 5.1
89.3 ± 4.5
94.3 ± 6.1
76.1 ± 1.7
76.5 ± 3.1

Sensitivity
77.7 ± 15.8
0.0
93.9 ± 9.3
31.6 ± 18.5
64.1 ± 18.1
80.7 ± 24.1
0.0
20 ± 15.5
73.8 ± 17.8
0.0
96.3 ± 7.8
1.1
62.2 ± 20.3
72.7 ± 24.6
0.0
13.9 ± 13.8
84.4 ± 17.1
0.0
99.9 ± 1.2
12.5 ± 12.5
78.4 ± 17.7
85.5 ± 24.1
0.0
80 ± 10.8
85.9 ± 17.9
0.0
98.8 ± 9.9
70.8 ± 20.3
57.3 ± 7
98.8 ± 25.3
0.0
13.2 ± 10.2

Specificity
95.4 ± 5.2
1.0
97.2 ± 3.7
99.4 ± 0.5
97.8 ± 2.9
97.4 ± 2.9
1.0
98.5 ± 2.6
94.8 ± 5.2
1.0
98.5 ± 3.5
1.0
99.3 ± 2.3
95.6 ± 17.1
1.0
98.9 ± 2.1
95.3 ± 5.5
1.0
98.2 ± 2.8
1.0
99.2 ± 2.6
94.8 ± 7.3
1.0
99.1 ± 2
94.9 ± 4.8
1.0
98.3 ± 3.1
99.3 ± 1.6
98.9 ± 3
97.5 ± 5.7
1.0
99.5 ± 1.6

AUC
96.6 ± 3.9
51 ± 0.8
99.5 ± 0.8
65.5 ± 9.2
95.4 ± 4.2
98.9 ± 1.2
51 ± 1.1
82.3 ± 9.3
94.9 ± 5.4
51 ± 1.1
99.8 ± 0.6
50.5 ± 1.8
96 ± 4.7
97.5 ± 8.5
51 ± 1.1
80.6 ± 9.7
97.6 ± 4.1
51 ± 1.1
99.7 ± 0.6
56.3 ± 6.7
97.7 ± 4.9
98 ± 3.2
51 ± 1.1
80.8 ± 9.6
94.1 ± 6.8
51 ± 1
99.6 ± 0.7
75 ± 10
83.9 ± 8.3
98.3 ± 2.1
51 ± 1
82.8 ± 9.3

number of features that have least information content amongst
investigated network. Another key observation is the choice of
the pretrained CNN has a direct and profound impact on the
overall performance of the COVID-19 classification model.
Last but not least, one may conclude that bigger networks
such as ResNet50 and InceptionResNetV2 do not necessarily
extract more informative and discriminative features.
It is also quite important to quantify uncertainties associated
with predictions. Here, we generate predictive uncertainty estimates for NN models. As mentioned before, there are several
ways of generating ensemble networks. We use the entire
dataset in the training step because the availability of more
samples improves the generalization power of NN models.
Twenty individual NN models with different architectures are

7

Linear SVM
●

10

●
ResNet50

●
InceptionResNetV2

ResNet50

●

InceptionResNetV2

8
6
●

4

CT

●

DenseNet121

DenseNet121

●

2

●
VGG16

VGG16

Accuracy
0

● 85
● 90

●
ResNet50

10

●

●

ResNet50

InceptionResNetV2

● 95

●
InceptionResNetV2

6

●

4

●

DenseNet121

DenseNet121

●

2

V. C ONCLUSION

●

VGG16

VGG16

0
0

10

20

30

40

50

60

0

10

20

30

40

50

60

Total Parameters (Millions)

Fig. (7) The accuracy average in the 2D space of the number
of CNN parameters (millions) and the number of features (ten
thousands). The size of each point is an indication of the
classifier accuracy (mean value in 100 runs).
Linear SVM

Neural Net

●

10

●

●

ResNet50

●

ResNet50

InceptionResNetV2

InceptionResNetV2

8
6
●

4

CT

●

DenseNet121

DenseNet121

●

2

●

VGG16

VGG16

AUC
●

0

90.0

● 92.5

●

10

●

●

ResNet50

●

ResNet50

InceptionResNetV2

● 95.0

● 97.5

InceptionResNetV2

8
X−ray

Number of Features (Ten Thousands)

tive uncertainty estimates for CT images are quite high. This is
evident from the large dark area in Fig. 9e-9h. These indicate
that individual NN models in the ensemble have a different
generalization power and produce significantly inconsistent
results. There is no perfect agreement between all models
about the predictive labels of these samples. Accordingly,
more care should be exercised when using machine learning
predictions for COVID-19 diagnosis using CT images.

8
X−ray

Number of Features (Ten Thousands)

Neural Net

6

●

4

●

DenseNet121

DenseNet121

●

2

●

VGG16

VGG16

0
0

10

20

30

40

50

60

0

10

20

30

40

50

60

Total Parameters (Millions)

Fig. (8) The AUC average in the 2D space of the number
of CNN parameters (millions) and the number of features (ten
thousands). The size of each point is an indication of the AUC
metric (mean value in 100 runs).

first trained to form an ensemble. NN models have a hidden
layer and their number of hidden neurons is randomly selected
between 50 to 400.
Fig. 9 shows the predictive uncertainty estimates for both
Covid and non-Covid cases in a 2D space. Fig. 9a-9d display
epistemic uncertainties for the X-ray dataset. Fig. 9e-9h show
epistemic uncertainties for the CT dataset. The 2D space
is obtained after applying PCA to reduce dimensionality of
obtained features from pretrained CNNs. This projection to the
2D space is done to ensure that samples could be visualized
against calculated predictive uncertainty estimates. The darker
the color of filled area, the higher the uncertainty level.
According Fig. 9a-9d, the level of epistemic uncertainty for
the X-ray dataset is fairly low. While the projected features
in the 2D space are in different locations for four pretrained
CNNs, the NN classifiers generate very similar results. This
consistency leads to a low uncertainty. In contrast, the predic-

The purpose of this study was to investigate the suitability of
deep transfer learning for COVID-19 diagnosis using medical
imaging. The key motivation was the lack of access to large
repositories of images for developing deep neural networks
from scratch. Leveraging the transfer learning framework,
we apply 4 pretrained deep convolutional neural networks
(VGG16, ResNet50, DenseNet121, and InceptionResNetV2)
to hierarchically extract informative and discriminative features from chest X-ray and CT images. The parameters of
the convolutional layers are kept frozen during the training
process. Extracted features are then processed by multiple
classification techniques. Obtained results indicate that linear
SVM and multi-layer perceptron outperforms others methods
in terms of the medical diagnosis accuracy for both X-ray and
CT images. It is also observed that better prediction results and
medical diagnosis could be achieved using CT images as they
are much richer in information compared to X-ray images.
There are many rooms for improvement and further exploration. The performance of transfer learning algorithms could
be majorly improved by fine tuning them to extract more
informative and discriminative features. Features obtained
from different transfer learning models could be combined
to develop hybrid models. Also, predictions from individual
models could be combined to form ensembles. Last but not
least, state of the art method could be applied for more
comprehensive estimation of the uncertainty measures.
R EFERENCES
[1] “Coronavirus disease 2019 (covid-19).” https://www.who.int/
emergencies/diseases/novel-coronavirus-2019/situation-reports,
2020
(February 27, 2020).
[2] “Emergency approval to use diagnostic test for coronavirus.”
https://www.reuters.com/article/us-china-health-cdc/u-s-cdcseeks-emergency-approval-to-use-diagnostic-test-for-coronavirusidUSKBN1ZM2XS, Jan 23, 2020.
[3] I. I. Bogoch, A. Watts, A. Thomas-Bachli, C. Huber, M. U. Kraemer, and
K. Khan, “Pneumonia of unknown etiology in wuhan, china: Potential
for international spread via commercial air travel,” Journal of Travel
Medicine, 2020.
[4] C. Huang, Y. Wang, X. Li, L. Ren, J. Zhao, Y. Hu, L. Zhang, G. Fan,
J. Xu, X. Gu, et al., “Clinical features of patients infected with 2019
novel coronavirus in wuhan, china,” The Lancet, vol. 395, no. 10223,
pp. 497–506, 2020.
[5] R. Alizadehsani, M. Abdar, M. Roshanzamir, A. Khosravi, P. M.
Kebria, F. Khozeimeh, S. Nahavandi, N. Sarrafzadegan, and U. R.
Acharya, “Machine learning-based coronary artery disease diagnosis: A
comprehensive review,” Computers in Biology and Medicine, vol. 111,
p. 103346, 2019.
[6] A. Janowczyk and A. Madabhushi, “Deep learning for digital pathology
image analysis: A comprehensive tutorial with selected use cases,”
Journal of pathology informatics, vol. 7, 2016.

8

Normal

125

Covid

Normal

Covid

Normal

Covid

100

300

400

Normal

Covid

100

75

75

200
50

50

200
25

25
100

0

0
0
0

25

25

50
50
200
100
75
75
200

0

200

400

600

50
75

(a) VGG16

25

0

25

50

75

100

125

200

(b) InceptionResNetV2

Normal

40

50

Covid

30

40

Normal

Covid

100

0

100

200

Normal

50

100

(d) DenseNet121

(c) ResNet50

40

0

300

Covid

Normal

Covid

40

30
30

20

20
20

20

10

10

10

0

0

0
0

10
10

10

20

20

20

20

30
30

30

40
40

20

0

20

40
40

40
40

(e) VGG16

20

0

20

40

40
40

(f) InceptionResNetV2

20

0

20

(g) ResNet50

20

0

20

40

40

(h) DenseNet121

Fig. (9) Uncertainty quantification using 20 individual neural networks working as an ensemble. They differ in the number of
neurons in their hidden layer before applying multi-layer perceptron classifier. The darker the color, the higher the uncertainty
level. Samples on dark parts of the plot have a high level of predictive uncertainty as the 20 models could not all agree on
the predicted label..

[7] B. Korbar, A. M. Olofson, A. P. Miraflor, C. M. Nicka, M. A.
Suriawinata, L. Torresani, A. A. Suriawinata, and S. Hassanpour, “Deep
learning for classification of colorectal polyps on whole-slide images,”
Journal of pathology informatics, vol. 8, 2017.
[8] C. Vununu, S.-H. Lee, and K.-R. Kwon, “A deep feature extraction
method for hep-2 cell image classification,” Electronics, vol. 8, no. 1,
p. 20, 2019.
[9] R. Alizadehsani, M. Roshanzamir, M. Abdar, A. Beykikhoshk, M. H.
Zangooei, A. Khosravi, S. Nahavandi, R. S. Tan, and U. R. Acharya,
“Model uncertainty quantification for diagnosis of each main coronary
artery stenosis,” Soft Computing, 11 2019.
[10] A. K. Jaiswal, P. Tiwari, S. Kumar, D. Gupta, A. Khanna, and J. J.
Rodrigues, “Identifying pneumonia in chest x-rays: A deep learning
approach,” Measurement, vol. 145, pp. 511 – 518, 2019.
[11] P. Rajpurkar, J. Irvin, K. Zhu, B. o. Yang, H. Mehta, T. Duan, D. Ding,
A. Bagul, C. Langlotz, K. Shpanskaya, M. P. Lungren, and A. Y. Ng,
“CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays
with Deep Learning,” arXiv e-prints, Nov. 2017.
[12] T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu, O. Yildirim, and U. R.
Acharya], “Automated detection of covid-19 cases using deep neural
networks with x-ray images,” Computers in Biology and Medicine,
vol. 121, p. 103792, 2020.
[13] I. D. Apostolopoulos and T. Bessiana, “Covid-19: Automatic detection
from X-Ray images utilizing Transfer Learning with Convolutional
Neural Networks,” arXiv e-prints, Mar. 2020.
[14] A. Narin, C. Kaya, and Z. Pamuk, “Automatic Detection of Coronavirus
Disease (COVID-19) Using X-ray Images and Deep Convolutional
Neural Networks,” arXiv e-prints, Mar. 2020.
[15] Y. Song, S. Zheng, L. Li, X. Zhang, X. Zhang, Z. Huang, J. Chen,
H. Zhao, Y. Jie, R. Wang, Y. Chong, J. Shen, Y. Zha, and Y. Yang,
“Deep learning enables accurate diagnosis of novel coronavirus (covid19) with ct images,” medRxiv, 2020.
[16] M. Barstugan, U. Ozkaya, and S. Ozturk, “Coronavirus (COVID-19)
Classification using CT Images by Machine Learning Methods,” arXiv
e-prints, Mar. 2020.
[17] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and

[18]

[19]
[20]
[21]

[22]
[23]
[24]
[25]
[26]
[27]

[28]

X. Wang, “Deep learning-based detection for covid-19 from chest ct
using weak label,” medRxiv, 2020.
X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu, Y. Chen, J. Su,
G. Lang, Y. Li, H. Zhao, K. Xu, L. Ruan, and W. Wu, “Deep Learning
System to Screen Coronavirus Disease 2019 Pneumonia,” arXiv e-prints,
Feb. 2020.
J. Postels, F. Ferroni, H. Coskun, N. Navab, and F. Tombari, “Samplingfree Epistemic Uncertainty Estimation Using Approximated Variance
Propagation,” arXiv e-prints, Aug. 2019.
D. Hendrycks and K. Gimpel, “A Baseline for Detecting Misclassified
and Out-of-Distribution Examples in Neural Networks,” arXiv e-prints,
Oct. 2016.
J. Z. Liu, Z. Lin, S. Padhy, D. Tran, T. Bedrax-Weiss, and B. Lakshminarayanan, “Simple and principled uncertainty estimation with
deterministic deep learning via distance awareness,” arXiv preprint
arXiv:2006.10108, 2020.
D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and
D. Mané, “Concrete Problems in AI Safety,” arXiv e-prints, June 2016.
B. Ghoshal and A. Tucker, “Estimating uncertainty and interpretability
in deep learning for coronavirus (covid-19) detection,” arXiv preprint
arXiv:2003.10769.
J. van Amersfoort, L. Smith, Y. Whye Teh, and Y. Gal, “Simple
and Scalable Epistemic Uncertainty Estimation Using a Single Deep
Deterministic Neural Network,” arXiv e-prints, Mar. 2020.
K. Simonyan and A. Zisserman, “Very Deep Convolutional Networks
for Large-Scale Image Recognition,” arXiv e-prints, Sept. 2014.
K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for
Image Recognition,” arXiv e-prints, Dec. 2015.
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan,
V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,”
in Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 1–9, 2015.
A. Kendall and Y. Gal, “What uncertainties do we need in bayesian
deep learning for computer vision?,” in Advances in Neural Information
Processing Systems 30 (I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett, eds.), pp. 5574–5584,
Curran Associates, Inc., 2017.

9

[29] R. Alizadehsani, M. Roshanzamir, M. Abdar, A. Beykikhoshk, M. H.
Zangooei, A. Khosravi, S. Nahavandi, R. S. Tan, and U. R. Acharya,
“Model uncertainty quantification for diagnosis of each main coronary
artery stenosis,” Soft Computing, 11 2019.
[30] B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and Scalable
Predictive Uncertainty Estimation using Deep Ensembles,” arXiv eprints, Dec. 2016.
[31] H. M. D. Kabir, A. Khosravi, M. A. Hosen, and S. Nahavandi, “Neural
network-based uncertainty quantification: A survey of methodologies
and applications,” IEEE Access, vol. 6, pp. 36218–36234, 2018.
[32] H. Quan, A. Khosravi, D. Yang, and D. Srinivasan, “A survey of computational intelligence techniques for wind power uncertainty quantification
in smart grids,” IEEE Transactions on Neural Networks and Learning
Systems, pp. 1–18, 2019.
[33] M. A. Hosen, A. Khosravi, S. Nahavandi, and D. Creighton, “Improving
the quality of prediction intervals through optimal aggregation,” IEEE
Transactions on Industrial Electronics, vol. 62, no. 7, pp. 4420–4429,
2015.
[34] Y. Gal, “Uncertainty in deep learning,” University of Cambridge, vol. 1,
p. 3, 2016.
[35] J. P. Cohen, P. Morrison, and L. Dao, “Covid-19 image data collection,”
arXiv 2003.11597, 2020.
[36] “Chest x-ray images (pneumonia).” https://www.kaggle.com/
paultimothymooney/chest-xray-pneumonia, 2020 (February 17,
2020).
[37] J. Zhao, Y. Zhang, X. He, and P. Xie, “Covid-ct-dataset: a ct scan dataset
about covid-19,” arXiv preprint arXiv:2003.13865, 2020.
[38] K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014.
[39] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4700–4708, 2017.
[40] J. Friedman, T. Hastie, and R. Tibshirani, The elements of statistical
learning, vol. 1. Springer series in statistics New York, 2001.
[41] G. James, D. Witten, T. Hastie, and R. Tibshirani, An introduction to
statistical learning, vol. 112. Springer, 2013.
[42] C. M. Bishop, Pattern recognition and machine learning. springer, 2006.
[43] T. Hastie, R. Tibshirani, and J. Friedman, The elements of statistical
learning: data mining, inference, and prediction. Springer Science &
Business Media, 2009.
[44] K. P. Murphy, Machine learning: a probabilistic perspective. MIT press,
2012.

