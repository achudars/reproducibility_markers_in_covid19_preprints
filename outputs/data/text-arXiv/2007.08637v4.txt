COV-ELM Classifier: An Extreme Learning Machine based identification of
COVID-19 using Chest X-Ray Images
Sheetal Rajpala , Manoj Agarwalb,∗, Ankit Rajpala , Navin Lakhyanic , Naveen Kumara
a Department

of Computer Science, University of Delhi, Delhi, India
of Computer Science, Hansraj College, University of Delhi, Delhi, India
c Department of Radiology, Saral Diagnostics, Pitampura, Delhi -110034, India

arXiv:2007.08637v4 [eess.IV] 12 Mar 2021

b Department

Abstract
Coronaviruses constitute a family of viruses that gives rise to respiratory diseases. COVID-19 is an infectious
disease caused by a newly discovered coronavirus also termed Severe acute respiratory syndrome coronavirus
2 (SARS-CoV-2). As COVID-19 is highly contagious, early diagnosis of COVID-19 is crucial for an effective
treatment strategy. However, the reverse transcription-polymerase chain reaction (RT-PCR) test which is
considered to be a gold standard in the diagnosis of COVID-19 suffers from a high false-negative rate.
Therefore, the research community is exploring alternative diagnostic mechanisms. Chest X-ray (CXR) image
analysis has emerged as a feasible and effective diagnostic technique towards this objective. In this work,
we propose the COVID-19 classification problem as a three-class classification problem namely COVID-19,
normal, and pneumonia. We propose a three-stage framework, named COV-ELM based on extreme learning
machine (ELM). Our dataset comprises CXR images in a frontal view, namely Poster anterior (PA) and
Erect anteroposterior (AP). Stage one deals with preprocessing and transformation, stage 2 deals with the
challenge of extracting relevant features which are passed as input to the ELM at the third stage, resulting
in the identification of COVID-19. The choice of ELM in this work has been motivated by its significantly
shorter training time as compared to conventional gradient-based learning algorithms. As bigger and diverse
datasets become available, it can be quickly retrained as compared to its gradient-based competitor models.
We use 10-fold cross-validation to evaluate the results of applying COV-ELM. The COV-ELM achieved
a macro average F1-score of 0.95 and the overall sensitivity of 0.94 ± 0.02 at a 95% confidence interval.
When compared to state-of-the-art machine learning algorithms, the COV-ELM is found to outperform its
competitors in a three-class classification scenario.
Keywords: COVID-19, Extreme Learning Machine, chest X-rays, Pneumonia viral, Pneumonia bacterial.

1. Introduction
Coronavirus disease 2019 (COVID-19), known to originate from Wuhan City in Hubei Province, China is a
contagious infection resulting in respiratory illness in most cases. COVID-19 is caused by a novel coronavirus,
∗ Corresponding

author
Email addresses: sheetal.rajpal.09@gmail.com (Sheetal Rajpal), agar.manoj@gmail.com (Manoj Agarwal ),
arajpal@cs.du.ac.in (Ankit Rajpal), navinlakhyani@gmail.com (Navin Lakhyani), nk.cs.du@gmail.com (Naveen Kumar)

widely recognized as severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2; previously known as
2019-nCoV) [1]. As the COVID-19 outbreak has become a global health emergency, on March 11, 2020, the
WHO declared COVID-19 a global pandemic [2]. Moreover, COVID-19 disease shares similar characteristics
as observed in other forms of viral or bacterial Pneumonia, making it difficult to separate between the two
classes at the early stages. Thus, early accurate diagnosis of COVID-19 is critically important to contain the
spread and the treatment of the affected subjects.
The Reverse transcription-polymerase chain reaction (RT-PCR) test is popularly used for the detection of
SARS-CoV-2. Although COVID-19 may be asymptotic in several instances, it has been reported that even
many symptomatic cases showing characteristics of COVID-19 were not correctly diagnosed by RT-PCR test
[3]. This has led to the search for alternative mechanisms that may be more accurate in the identification
of COVID-19 disease. Traditionally, chest X-ray images (CXRs) have been the popular choice for diagnosis
and treatment of respiratory disorders such as Pneumonia [4, 5]. As a result, several research groups are
working on developing models based on CXR images [6, 7, 8, 9]. However, most of them are struggling with
the challenge to distinguish COVID-19 patients against those suffering from other forms of pneumonia [10].
Although, deep neural networks have emerged as a popular tool for image-based analysis, these require
tuning millions of parameters and search for the optimal value of hyper-parameters [7, 11, 12, 13]. Also, it
is well known that the training of a deep neural network is a time-consuming task even on high-performance
computing platforms.
Khan et al. [7] proposed a deep convolutional neural network (DCNN) model to automate the detection of
COVID-19 based on chest X-ray images. The model is based on Xception architecture [14] pre-trained on
ImageNet [15] and achieved an overall accuracy of 89.6%. Jain et al. [16] proposed a deep residual network
for the automatic detection of COVID-19 in CXR image by differentiating it with the CXR images of bacterial pneumonia, viral pneumonia, and normal cases and exhibited an accuracy of 93.01% in differentiating
three classes using their first-stage model. They have further analyzed the CXR images showing the viral
pneumonia features for the identification of COVID-19 case in their second stage model showing an exceptional performance with an accuracy of 97.22%. Altan et al. [17] used an efficient hybrid model consisting
of two-dimensional (2D) curvelet transformation for the feature extraction, chaotic salp swarm algorithm
(CSSA) to optimize the feature matrix, and EfficientNet-B0 model for the identification of COVID-19 cases.
The model achieved an accuracy of 99.69%. Mahmud et al. [8] proposed a DCNN model using a variation in
dilation rate to extract distinguishing features from chest X-ray images and achieved an accuracy of 90.2%
for multi-class classification (COVID-19/Normal/Pneumonia). They also used Gradient-weighted Class Activation Mapping (Grad-CAM) to visualize the abnormal regions in CXR scans. Wang et al. [9] developed a
computer-aided screening tool for detection of COVID-19 from CXR images based on a pre-trained network
on ImageNet, tuned with the Adam optimizer, and achieved 91% sensitivity for the COVID-19 class. Basu
et al. [18] used domain extension transfer learning (DETL) framework comprising 12 layers. They used
an already-trained network on the National Institutes of Health (NIH) CXR image dataset [4] (comprising

2

108,948 frontal view X-ray images of 32,717 unique patients) which was fine-tuned for the COVID-19 dataset
to obtain an overall accuracy 95.3% ± 0.02 on 5-fold cross-validation. Marques et al. [19] made a novel
attempt of applying EfficientNet [20] (claimed to achieve an accuracy of 84.3% top-1 accuracy on ImageNet)
and evaluated their model using 10-fold stratified cross-validation method. 1092 samples have been used for
training, and 122 images have been used for testing. They have achieved an average F1-score value of 0.97
in multi-class scenarios whereas 0.99 in the case of binary classification. Rajaraman et al. [21] iteratively
pruned the task-specific models (VGG-16, VGG-19, and Inception-V3) by pruning 2% of the neurons in each
convolutional layer and retrained the model to obtain a macro averaged F1-score of 0.99. Das et al. [11]
proposed a deep transfer learning approach for automated detection of COVID-19 disease. The network is
fed with the features extracted using the Xception network. They obtained 97% sensitivity for classifying
COVID-19 cases from Pneumonia and respiratory diseases. They further show that their proposed model
outperformed other popular deep networks such as VGGNet, ResNet50, AlexNet, GoogLeNet.
Khuzani et al. [10] used multilayer neural networks (MLNN) to distinguish the CXR images of COVID-19
patients from other forms of pneumonia. They extracted a set of spatial and frequency domain features
from X-ray images. Based on the evaluation of extracted features, they concluded that while Fast Fourier
Transform (FFT) features were best suited in detecting the COVID-19, the normal class was best determined
by the gray level difference method (GLDM). Principal Component Analysis (PCA) was applied to generate
an optimized set of synthetic features that served as input to an MLNN to distinguish COVID-19 images
from the non-COVID-19 ones with an accuracy of 94%.
It is evident from the above discussion that so far the research groups have mainly focused on the use of deep
neural networks which require millions of parameters and the optimal choice of hyper-parameters. However, it
is well known that the training of a deep neural network is a time-consuming task even on high-performance
computing platforms.

Therefore, in order to improve the computational efficiency of the classification

models, in this work, we have proposed the use of a single hidden layer feed-forward neural network (SLFN)
known as extreme learning machine (ELM) [22, 23]. The ELM is a batch learning algorithm proposed by
Huang et al. [22] and has been used extensively in different domains like ECG signal classification [24] and
identification of arrhythmia disease [25]. The ELM and its variants have also been applied in applications
such as fingerprint identification [26], lung cancer detection [27], image and video watermarking [28, 29], and
3D object recognition [30]. The applicability of ELM in various domains is due to its fast learning, good
generalization performance, and ease of implementation.
The main contribution of this paper is to explore the suitability of ELM in the diagnosis of COVID-19 using
CXR images. The faster convergence of ELM with only one tunable parameter made it more efficient as
compared to conventional gradient-based learning algorithms. Another challenge addressed in this work is
the identification of localized patterns to differentiate between the classes, namely, COVID-19, Pneumonia,
and Normal.
The rest of the paper is organized as follows: Section 2 gives the dataset description followed by the

3

detailed methodology, preprocessing of the dataset, review of Extreme Learning Machine, outcomes of the
experiments, and analysis of the results have been discussed in Section 3, finally, the conclusions and scope
for future work are discussed in Section 4.

2. Material and Methods
In this section, we present a list of CXR image datasets used for experimentation in this work, followed by
details of the proposed methodology.
2.1. Dataset Description
In the present work, we have used the following publicly available CXR datasets for COVID-19, Normal, and
Pneumonia.
• COVID-19 Image Data Collection [6]. It comprises 760 samples, COVID-19: 538, ARDS: 14, Other
Diseases: 222.
• COVID-19 Radiography Database (Kaggle) [31]. It comprises 2905 samples, COVID-19: 219, Normal:
1341, Viral Pneumonia: 1345.
• Mendeley Chest X-ray Images [32]. It comprises 5856 samples, Pneumonia (Viral and Bacterial) : 4273,
Normal:1583.
In this work, we only consider the CXR images in a frontal view, namely Poster anterior (PA) and Erect
anteroposterior (AP). The first two databases in the above list comprise 520 such images. For the training
purpose, we have used these images along with 520 CXR images of normal and pneumonia cases from
COVID-19 Radiography Database (Kaggle) [31] and Mendeley Chest X-ray Images [32].
2.2. Preprocessing
Due to diversity in the CXR image collection, they are resized and subjected to min-max normalization
[33] to ensure uniformity. Further, to enhance the local contrast in the CXRs, Contrast Limited Adaptive
Histogram Equalization (CLAHE), a variant of adaptive histogram equalization is applied. Figure 1 depicts
the framework of the three-staged proposed model. In stage one, the preprocessing includes resizing, normalization, and CLAHE [34] applied in the sequence shown. The preprocessed CXRs are passed to stage 2
of the framework for feature extraction.
2.3. Feature Extraction
Texture plays a significant role in the identification of the region of interest (ROI) and classification of images
[35]. In this stage, we consider two types of features: texture and frequency-based as shown in Figure 1.
The texture features consisted of four groups. The first group of features is directly generated from the
preprocessed image of 512 × 512. These include area, mean, standard deviation, skewness, kurtosis, energy,
4

Figure 1: COV-ELM Framework: Dataset Preprocessing, Feature Extraction, and ELM based classification model.

entropy, max, min, mean absolute deviation, median, range, root mean square, and uniformity. Remaining
texture features are obtained by applying gray-level co-occurrence matrix (GLCM) [36, 37], histogram of
oriented gradients (HOG) [38, 39, 40], and gray-level difference matrix (GLDM) [41, 10]. Apart from texture
features, the use of frequency features also plays an important role in developing efficient classifiers in medical
imaging [42, 43, 44]. In the present work, the frequency features are extracted using Fast Fourier Transform
(FFT) and Discrete Wavelet Transform (DWT). Zargari et al. [45] used the aforementioned statistical features
for predicting chemotherapy response in ovarian cancer patients. Drawing inspiration from their work, we
computed these features for the FFT map and three-level (LL3) DWT coefficients to generate a vector of
frequency features. Finally, a vector of features is obtained by concatenating the textural feature vector of
length (140) with the frequency vector of length (28) to generate a vector of size 168 for each CXR image.
2.4. Extreme Learning Machine
In stage three, the features extracted at stage 2 are passed as input to the Extreme Learning Machine (ELM)
based classification model as shown in Figure 1. ELM was proposed by Huang et al. as an efficient alternative
to the backpropagation algorithm for single-layer feed-forward networks (SNFN) [22]. It is a fast learning
algorithm with good generalization performance as compared to other traditional feed-forward networks.
An ELM works by initializing a set of weights randomly and computing the output weights analytically by
Moore-Penrose Matrix Inverse [46]. Figure 2 depicts the overall ELM architecture and the details of its
5

functioning are provided in Algorithm 1.

Figure 2: ELM Architecture: The ELM network comprises an input layer, a hidden layer, and an output layer

Given a training set (xj , tj ), xj ∈ Rn , tj ∈ Rm for j = 1, 2, . . . , N , where the pairs (xj , tj ) denote the training
vectors and the corresponding target values, following [22], the standard ELM having L nodes is modeled as:
L
X

βi gi (ai .xj + bi ) = tj

(1)

i=1

In Equation (1), ai denotes the weight vector that connects the input layer to the ith hidden node and bi
denotes the corresponding bias. Further, βi denotes the weight vector connecting the ith hidden node and
the output neurons. The above N equations may also be represented as:

Gβ = T

(2)

The form of the hidden layer output matrix G, mentioned in Equation (2), is given in Equation (3). The
form of vectors β and T is given in Equation (4).



g(a1 .x1 + b1 ) . . .

..

G=
.
...

g(a1 .xN + b1 ) . . .

 
βT
 1
 . 
β =  .. 
 
βLT


g(aL .x1 + bL )

..


.

g(aL .xN + bL )

(3)

N ×L



and


tT1
 
 . 
T =  .. 
 
tTN

N ×m

L×m

6

(4)

The solution of the above system of linear equations is obtained using Moore-Penrose generalized inverse
(Equation (5)).
β = G† T

(5)

In Equation (5), G† = (GT G)−1 GT denotes the Moore-Penrose generalized inverse [46] of matrix G.
Algorithm 1 ELM Algorithm
Input:
Training set: (xj , tj ), xj ∈ Rn , tj ∈ Rm for j = 1, 2, . . . , N
Activation function: g : R → R
Number of hidden nodes: L
Output:
Optimized weight matrix: β
1. Randomly assign hidden node parameters (ai , bi ), i = 1, 2, . . . , L;
2. Compute the hidden-layer output matrix G;
3. Compute output weight vector β = G† T

Huang et al. [47] argue that ELM outperforms the conventional learning algorithms in terms of learning
speed, and in most of the cases shows better generalization capability than the conventional gradient-based
learning algorithms such as backpropagation where the weights are adjusted with a non-linear relationship
between the input and the output [46]. They further stated that ELM can compute the desired weights of
the network in a single step in comparison to classical methods.
2.5. COV-ELM
In this work, we use ELM discussed in Section 2.4 to develop an ELM classifier (COV-ELM) for detection of
COVID-19 in CXR images. Based on experimentation, we used L2-normalized radial basis function (rbf-l2)
activation function. We also experimented with the different number of neurons in the hidden layer. Using
10-fold cross-validation, we observed that with an increase in the number of neurons in the hidden layer,
accuracy increases up to L = 140 neurons, and the highest 10-fold cross-validation accuracy of 94.10% was
reached when the number of hidden neurons was L = 350. Experimenting with different seeds, we found the
peak accuracy was reached for the number of hidden neurons in the range 350 to 380 but without any further
increase in 10-fold cross-validation accuracy. So, for further experiments, we fixed the number of hidden
neurons as L = 350.

7

Figure 3: Effect of the increase in the number of hidden neurons (L) on 10-fold cross-validation accuracy. Accuracy increases
with increase in L upto L = 140, and witnessed highest 10-fold cross-validation accuracy of 94.10% at L = 350

Boxplot in Figure 4 depicts the variation in sensitivity value. It is evident from the results that the texture
features score over frequency features. We also examined the influence of a combined set of features (168)
on the classification process. It may be noted that the model yields median sensitivity of 0.945 using the
combined set of features which scores over the median sensitivity values considering the frequency and texture
features separately, exhibiting 0.90 and 0.93 respectively.

Figure 4: Boxplot for sensitivity (recall) values using frequency features, texture features, and combined set of frequency and
texture features. The combined set of features depicts the median sensitivity of 0.945 which scores over the median values
considering frequency and texture features separately.

8

(a) ROC Curve (COVID-19 vs other classes)

(b) ROC Curve (Normal vs other classes)

(c) ROC Curve (Pneumonia vs other classes)

Figure 5: AUC is near unity for each of the three classes namely COVID-19, Normal, and Pneumonia in one vs all setting.

3. Results and Discussion
We have carried out all the experiments using Python 3.6.9 on the NVIDIA Tesla K80 GPU provided by
Google Colaboratory. To evaluate the performance of the proposed method for the three-class classification
problem, we trained the model on the CXR dataset using 10-fold cross-validation. Following Handy and
Till [48], we depict the receiver operating characteristic (ROC) curves for each of the three classes, namely
COVID-19, Normal, and Pneumonia for one fold (please see in Figure 5). It is apparent from the ROC curves
that AUC is near unity for all three classes which shows a good generalization performance of COV-ELM.
To evaluate the performance of the proposed classifier, we carried out 10-fold cross-validation. Figure 6 depicts
the confusion matrix and the heatmap for 10-fold cross-validation. The results of the 10-fold cross-validation
are summarized in a confusion matrix (Figure 6(a)). It shows that out of 380 COVID-19 patients, 364 were
correctly identified, three were misclassified as normal and thirteen were labeled as pneumonia. Similarly,
pneumonia and normal subjects were also labeled by the system quite accurately. Thus, we obtained an
overall accuracy of 94.40% and a high recall rate of 95.78%, 95.53%, and 92.41% for COVID-19, Normal,
and Pneumonia classes respectively. The macro average of the f1-score is 0.95 as depicted in the heatmap

9

(Figure 6(b)). As shown in Table 1, COV-ELM identified COVID-19, Normal, and Pneumonia classes with
sensitivity 0.96 ± 0.04, 0.96 ± 0.01, and 0.92 ± 0.03 respectively at 95% confidence interval.
Table 1: Sensitivity (Recall) values for COVID-19, Normal, and Pneumonia at 95% confidence interval.

Sensitivity at 95% CI
COVID-19

Normal

Pneumonia

0.96 ± 0.04

0.96 ± 0.01

0.92 ± 0.03

(a) Confusion matrix summarizing number fo instances correctly (b) Heatmap summarizing performance metrics: precision, recall
classified across diagonal elements.

and f1-score

Figure 6: The classification error in classifying COVID-19, Normal, and Pneumonia is 3.68%, 4.46%, and 7.58% respectively
and the macro average of f1-score is 0.95.

To establish the effectiveness of our approach, the COV-ELM is compared with the state-of-the-art machine
learning algorithms, namely support vector classifier (SVC) using rbf and linear kernels, gradient boosting
classifier (GBC), random forest ensemble (RBE), artificial neural networks (ANN), decision tree classifier
(DTC), and voting classifier (VC) ensemble of (logistic regression (LR), SVC, and GBC) in terms of sensitivity
at 95% confidence interval (CI) (please see Table 2). It is clear that COV-ELM has higher sensitivity as
compared to its competitors. It is evident from the table that the proposed approach achieves a sensitivity
of 0.94 ± 0.02 and scores over other state-of-the-art classifiers.

10

Table 2: Comparison of COV-ELM with other state-of-the-art classifiers in terms of sensitivity value at 95% confidence interval.

Classifier

Sensitivity

ELM (L=350, rbf-l2)

0.94 ± 0.02

GBC (learning rate=1.0)

0.91 ± 0.05

SVC (C=1.0, kernel=’rbf’)

0.86 ± 0.06

SVC (C=1.0, kernel=’linear’)

0.90 ± 0.05

RBE (min samples split=2)

0.89 ± 0.05

ANN (23,747 Parameters)

0.85 ± 0.08

DTC (min samples leaf=1)

0.82 ± 0.07

VC (LR, SVC, GBC)

0.89 ± 0.05

4. Conclusions
The current research is focused on the accurate diagnosis of COVID-19 with high sensitivity. In this direction,
the paper evaluates the applicability of ELM as a classifier. We use a combination of texture (Spatial, GLDM,
HOG, AND GLDM) and frequency features (FFT and DWT) for the classification of COVID-19 patients
against pneumonia and normal patients. The proposed model has been evaluated using CXR images from
three publicly available sources. As opposed to a deep neural network that requires millions of parameters for
training, the number of parameters in ELM is considerably less, compared to a conventional neural network
requiring thousands of parameters. We found that the 10-fold cross-validation accuracy increases with an
increase in the number of hidden neurons 140, then it stabilizes more or less, finally reaching the peak
accuracy of 94.10% at 350 hidden neurons. The proposed method achieved a macro average f1-score of 0.95
in a three-class classification scenario and an overall accuracy of 94.40%. The COV-ELM outperforms other
competitive machine learning algorithms with a sensitivity of 0.94% ± 0.02 at a 95% confidence interval.
The training time of COV-ELM being quite low, compared to its gradient-based competitor models, it can
be quickly trained on bigger and diverse datasets that may become available in the future.

As part of

future work, we will like to investigate whether segmentation of the lung region could help to improve the
classification results.

References
[1] M.-Y. Ng, E. Y. Lee, J. Yang, F. Yang, X. Li, H. Wang, M. M.-s. Lui, C. S.-Y. Lo, B. Leung, P.-L.
Khong, et al., Imaging profile of the COVID-19 infection: radiologic findings and literature review,
Radiology: Cardiothoracic Imaging 2 (1) (2020) e200034.
[2] WHO,

Archived:

WHO

Timeline

-

COVID-19,

27-04-2020-who-timeline---covid-19 (2020).

11

https://www.who.int/news-room/detail/

[3] A. Tahamtan, A. Ardebili, Real-time RT-PCR in COVID-19 detection: issues affecting the results (2020).
[4] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, R. M. Summers, Chestx-ray8: Hospital-scale chest xray database and benchmarks on weakly-supervised classification and localization of common thorax
diseases, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp.
2097–2106.
[5] L. Nanni, A. Lumini, S. Brahnam, Local binary patterns variants as texture descriptors for medical
image analysis, Artificial intelligence in medicine 49 (2) (2010) 117–125.
[6] J. P. Cohen, P. Morrison, L. Dao, K. Roth, T. Q. Duong, M. Ghassemi, COVID-19 Image Data Collection: Prospective Predictions Are the Future, arXiv preprint arXiv:2006.11988 (2020).
[7] A. I. Khan, J. L. Shah, M. M. Bhat, Coronet: A deep neural network for detection and diagnosis of
COVID-19 from chest x-ray images, Computer Methods and Programs in Biomedicine (2020) 105581.
[8] T. Mahmud, M. A. Rahman, S. A. Fattah, CovXNet: A multi-dilation convolutional neural network
for automatic COVID-19 and other pneumonia detection from chest X-ray images with transferable
multi-receptive feature optimization, Computers in Biology and Medicine (2020) 103869.
[9] L. Wang, Z. Q. Lin, A. Wong, Covid-net: A tailored deep convolutional neural network design for
detection of covid-19 cases from chest x-ray images, Scientific Reports 10 (1) (2020) 1–12.
[10] A. Z. Khuzani, M. Heidari, S. A. Shariati, COVID-Classifier: An automated machine learning model to
assist in the diagnosis of COVID-19 infection in chest x-ray images, medRxiv (2020).
[11] N. N. Das, N. Kumar, M. Kaur, V. Kumar, D. Singh, Automated deep transfer learning-based approach
for detection of COVID-19 infection in chest X-rays, Irbm (2020).
[12] M. Shorfuzzaman, M. S. Hossain, Metacovid: A siamese neural network framework with contrastive loss
for n-shot diagnosis of covid-19 patients, Pattern Recognition (2020) 107700.
[13] Y. Pathak, P. K. Shukla, A. Tiwari, S. Stalin, S. Singh, P. K. Shukla, Deep Transfer Learning based
Classification Model for COVID-19 Disease, IRBM (2020).
[14] F. Chollet, Xception: Deep learning with depthwise separable convolutions, in: Proceedings of the IEEE
conference on computer vision and pattern recognition, 2017, pp. 1251–1258.
[15] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with deep convolutional neural networks, in: Advances in neural information processing systems, 2012, pp. 1097–1105.
[16] G. Jain, D. Mittal, D. Thakur, M. K. Mittal, A deep learning approach to detect Covid-19 coronavirus
with X-Ray images, Biocybernetics and Biomedical Engineering 40 (4) (2020) 1391–1405.

12

[17] A. Altan, S. Karasu, Recognition of COVID-19 disease from X-ray images by hybrid model consisting
of 2D curvelet transform, chaotic salp swarm algorithm and deep learning technique, Chaos, Solitons &
Fractals 140 (2020) 110071.
[18] S. Basu, S. Mitra, Deep Learning for Screening COVID-19 using Chest X-Ray Images, arXiv preprint
arXiv:2004.10507 (2020).
[19] G. Marques, D. Agarwal, I. de la Torre Dı́ez, Automated medical diagnosis of COVID-19 through
EfficientNet convolutional neural network, Applied Soft Computing 96 (2020) 106691.
[20] M. Tan, Q. V. Le, Efficientnet: Rethinking model scaling for convolutional neural networks, arXiv
preprint arXiv:1905.11946 (2019).
[21] S. Rajaraman, J. Siegelman, P. O. Alderson, L. S. Folio, L. R. Folio, S. K. Antani, Iteratively Pruned
Deep Learning Ensembles for COVID-19 Detection in Chest X-rays, arXiv preprint arXiv:2004.08379
(2020).
[22] G.-B. Huang, Q.-Y. Zhu, C.-K. Siew, Extreme learning machine: a new learning scheme of feedforward
neural networks, in: 2004 IEEE international joint conference on neural networks (IEEE Cat. No.
04CH37541), Vol. 2, IEEE, 2004, pp. 985–990.
[23] A. Akusok, K.-M. Björk, Y. Miche, A. Lendasse, High-performance extreme learning machines: a complete toolbox for big data applications, IEEE Access 3 (2015) 1011–1025.
[24] S. Karpagachelvi, M. Arthanari, M. Sivakumar, Classification of electrocardiogram signals with support
vector machines and extreme learning machine, Neural Computing and Applications 21 (6) (2012) 1331–
1339.
[25] J. Kim, H. S. Shin, K. Shin, M. Lee, Robust algorithm for arrhythmia classification in ECG using
extreme learning machine, Biomedical engineering online 8 (1) (2009) 31.
[26] J. Yang, S. Xie, S. Yoon, D. Park, Z. Fang, S. Yang, Fingerprint matching based on extreme learning
machine, Neural Computing and Applications 22 (3-4) (2013) 435–445.
[27] M. R. Daliri, A hybrid automatic system for the diagnosis of lung cancer based on genetic algorithm
and fuzzy extreme learning machines, Journal of medical systems 36 (2) (2012) 1001–1005.
[28] A. Rajpal, A. Mishra, R. Bala, A Novel fuzzy frame selection based watermarking scheme for MPEG-4
videos using Bi-directional extreme learning machine, Applied Soft Computing 74 (2019) 603–620.
[29] A. Mishra, A. Rajpal, R. Bala, Bi-directional extreme learning machine for semi-blind watermarking of
compressed images, Journal of information security and applications 38 (2018) 71–84.

13

[30] R. Nian, B. He, A. Lendasse, 3D object recognition based on a geometrical topology model and extreme
learning machine, Neural Computing and Applications 22 (3-4) (2013) 427–433.
[31] T. Rahman, M. Chowdhury, A. Khandakar, COVID-19 Radiography Database — Kaggle, https://
www.kaggle.com/tawsifurrahman/covid19-radiography-database (2020).
[32] D. Kermany, K. Zhang, M. Goldbaum, Large dataset of labeled optical coherence tomography (oct) and
chest x-ray images, Mendeley Data, v3 http://dx. doi. org/10.17632/rscbjbr9sj 3 (2018).
[33] A. Jain, K. Nandakumar, A. Ross, Score normalization in multimodal biometric systems, Pattern recognition 38 (12) (2005) 2270–2285.
[34] S. A. Ahmad, M. N. Taib, N. E. A. Khalid, H. Taib, An analysis of image enhancement techniques
for dental X-ray image interpretation, International Journal of Machine Learning and Computing 2 (3)
(2012) 292.
[35] R. M. Haralick, K. Shanmugam, I. H. Dinstein, Textural features for image classification, IEEE Transactions on systems, man, and cybernetics 6 (1973) 610–621.
[36] M. R. Zare, W. C. Seng, A. Mueen, Automatic classification of medical x-ray images, Malaysian Journal
of Computer Science 26 (1) (2013) 9–22.
[37] MathWorks,
(GLCM)

Texture
-

MATLAB

Analysis
&

Using

the

Simulink,

Gray-Level

Co-Occurrence

Matrix

https://www.mathworks.com/help/images/

texture-analysis-using-the-gray-level-co-occurrence-matrix-glcm.html#:~:text=More-,
Texture%20Analysis%20Using%20the%20Gray%2DLevel%20Co%2DOccurrence%20Matrix%20(,gray%
2Dlevel%20spatial%20dependence%20matrix. (2020).
[38] N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, in: 2005 IEEE computer
society conference on computer vision and pattern recognition (CVPR’05), Vol. 1, IEEE, 2005, pp.
886–893.
[39] GitHub, Histogram of Oriented Gradients, https://scikit-image.org/docs/dev/auto_examples/
features_detection/plot_hog.html (2020).
[40] Z. Xue, D. You, S. Candemir, S. Jaeger, S. Antani, L. R. Long, G. R. Thoma, Chest x-ray image
view classification, in: 2015 IEEE 28th International Symposium on Computer-Based Medical Systems,
IEEE, 2015, pp. 66–71.
[41] J. K. Kim, H. W. Park, Statistical textural features for detection of microcalcifications in digitized
mammograms, IEEE transactions on medical imaging 18 (3) (1999) 231–238.
[42] N. V. Shree, T. Kumar, Identification and classification of brain tumor MRI images with feature extraction using DWT and probabilistic neural network, Brain informatics 5 (1) (2018) 23–30.
14

[43] J. M. Leibstein, A. L. Nel, Detecting tuberculosis in chest radiographs using image processing techniques,
University of Johannesburg (2006).
[44] N. Parveen, M. M. Sathik, Detection of pneumonia in chest X-ray images, Journal of X-ray Science and
Technology 19 (4) (2011) 423–428.
[45] A. Zargari, Y. Du, M. Heidari, T. C. Thai, C. C. Gunderson, K. Moore, R. S. Mannel, H. Liu, B. Zheng,
Y. Qiu, Prediction of chemotherapy response in ovarian cancer patients using a new clustered quantitative
image marker, Physics in Medicine & Biology 63 (15) (2018) 155020.
[46] J. A. Fill, D. E. Fishkind, The Moore–Penrose Generalized Inverse for Sums of Matrices, SIAM Journal
on Matrix Analysis and Applications 21 (2) (2000) 629–635.
[47] G.-B. Huang, Q.-Y. Zhu, C.-K. Siew, Extreme learning machine: theory and applications, Neurocomputing 70 (1-3) (2006) 489–501.
[48] D. J. Hand, R. J. Till, A simple generalisation of the area under the ROC curve for multiple class
classification problems, Machine learning 45 (2) (2001) 171–186.

15

