arXiv:2004.08052v1 [eess.IV] 17 Apr 2020

A N EW M ODIFIED D EEP C ONVOLUTIONAL N EURAL N ETWORK
FOR DETECTING COVID-19 FROM X- RAY IMAGES

Mohammad Rahimzadeh
School of Computer Engineering
Iran University of Science and Technology, Iran
mh_rahimzadeh@elec.iust.ac.ir

Abolfazl Attar
Department of Electrical Engineering
Sharif University of Technology, Iran
attar.abolfazl@ee.sharif.edu

April 20, 2020

A BSTRACT
COVID-19 has become a serious health problem all around the world. It is confirmed that this virus has
taken over 126,607 lives until today. Since the beginning of its spreading, many Artificial Intelligence
researchers developed systems and methods for predicting the virus’s behavior or detecting the
infection. One of the possible ways of determining the patient infection to COVID-19 is through
analyzing the chest X-ray images. As there are a large number of patients in hospitals, it would be
time-consuming and difficult to examine lots of X-ray images, so it can be very useful to develop an
AI network that does this job automatically. In this paper, we have trained several deep convolutional
networks with the introduced training techniques for classifying X-ray images into three classes:
normal, pneumonia, and COVID-19, based on two open-source datasets. Unfortunately, most of the
previous works on this subject have not shared their dataset, and we had to deal with few data on
covid19 cases. Our data contains 180 X-ray images that belong to persons infected to COVID-19, so
we tried to apply methods to achieve the best possible results. In this research, we introduce some
training techniques that help the network learn better when we have few cases of COVID-19, and also
we propose a neural network that is a concatenation of Xception and ResNet50V2 networks. This
network achieved the best accuracy by utilizing multiple features extracted by two robust networks.
In this paper, despite some other researches, we have tested our network on 11302 images to report
the actual accuracy our network can achieve in real circumstances. The average accuracy of the
proposed network for detecting COVID-19 cases is 99.56%, and the overall average accuracy for all
classes is 91.4%.
Keywords Deep learning · Convolutional Neural netwroks · COVID-19 · Coronavirus · Transfer Learning · deep
feature extraction

1

Introduction

The pervasive spread of the coronavirus around the world has quarantined many people and crippled many industries,
which has had a devastating effect on human life quality. So far, the coronavirus has infected at least 1.9 million people
and killed around 126,607 patients[14]. Due to the high transmissibility of coronavirus, the detection of coronavirus
disease-19 (COVID-19) plays an essential role in how to control and plan to prevent COVID-19 [24]. On the other
hand, the lack of detective tools and the limitations in medical equipment and experts has slowed down the disease
detection. As a result, it increases the number of patients and casualties. If the disease is detected quickly, its prevalence
and the number of casualties due to COVID-19 disease will decrease.
The first step is to get the detection, recognize the symptoms of the disease, and use special signs to detect the
coronavirus accurately. Depending on the type of coronavirus, symptoms can range from a common cold to fever,
cough, shortness of breath, and acute respiratory problems, whereas the patient may also have a few days of cough for
no apparent reason[21]. Unlike SARS, coronavirus affects not only the respiratory system but also other vital organs in

A PREPRINT - A PRIL 20, 2020

the body, such as the kidneys and liver [13]. Symptoms of a new coronavirus leading to COVID-19 usually begin a few
days after the person becomes infected, where, in some people, the symptoms may appear a little later[9].
According to [9, 24], Respiratory problems are one of the main symptoms of COVID-19, which can be detected by the
X-ray imaging of the chest. CT scans of the chest can also show a disease that has mild symptoms, so analyzing these
images can well detect the presence of the disease in suspicious people and even without symptoms at first [20]. Using
these data can also cover other problems, such as the lack of diagnostic kits and the limitations of their production. The
advantage of using CT scans is the availability of CT scan devices in most hospitals and laboratories, and the doctors
mostly use CT scan images to detect the infection. In the absence of common symptoms such as fever, the use of CT
scans of the chest has a relatively good ability to detect the disease [1].
The use of specialized human beings to diagnose the disease is a common way of detecting COVID-19 in laboratories.
In this way, the specialist examines the symptoms and injuries in the chest radiology image to detect COVID-19
disease from a healthy person or person that suffering from other diseases, whereas this procedure has costs and, most
importantly, long-term detection [9, 19].
In recent years, computer vision and Deep Learning have been used to detect many different diseases and lesions in the
body automatically [12]. Some examples are: Detection of tumor types and volume in lungs, breast, head and brain
[2, 10], state-of-the-art bone suppression in x-rays, diabetic retinopathy classification, prostate segmentation, skin lesion
classification, analysis of the myocardium in coronary CT angiography [27],nodule classification [12], sperm detection
and tracking for male fertility analysis [16], etc. Given that chest CT scan and X-ray images analysis is one of the ways
for diagnosing COVID-19, the use of computer vision and Deep Learning can play a beneficial role in the diagnosis of
this disease. Since the disease became widespread, many researchers have used machine vision and Deep Learning
methods and obtained good results [1, 26].
The paper is organized as follows: In Section 2, the previous works related to our work are presented. In Section 3, we
describe the used Dataset, and we explain the utilized neural networks and training techniques. In Section 4, we have
presented the experimental results, and then the paper is concluded in Section 5. In Section 6, we presented the trained
networks and the codes used in this research.

2

Related works

In [1, 26], statistical analysis of CT scans was performed by several specialists and diagnosticians, who classified the
suspects into several classes for diagnosis and treatment.
Because of the superiority of computer vision and Deep Learning in the analysis of medical images, after the reliability
of CT scans of the chest for COVID-19 detection, the researchers used these tools to diagnose COVID-19. Immediately,
artificial intelligence began to detect the disease and measure the rate of infection and damage to the lungs using
CT scans and the course of the disease, with promising results [7]. IN [23], they have used an innovative CNN to
classify and predict COVID-19 using lung CT scans. [7] has used Deep Learning to detect COVID-19 and segment the
lung masses caused by the coronavirus using 2D and 3D images. COVID-Net uses a lightweight residual projectionexpansion- projection-extension (PEPX) design pattern to investigate quantitative analysis and qualitative analysis
[22].In another research, pre-trained ResNet50, InceptionV3, and Inception ResNetV2 models have used with transfer
learning techniques to classify Chest X-ray images normal and COVID-19 classes [15]. In [11], they present COVNet
for predict COVID-19 from CT scans that have segmented using U-net [17].
Another research has combined the Human-In-The-Loop(HITL) strategy that involved a group of chest radiologists
with deep learning-based methods to segment and measures infection in CT scans [18]. In [25], they have tried to detect
COVID-19 and Influenza-A-viral-pneumonia from their data; They have used classical ResNet-18 network structure to
extract the features, and another Innovative CNN network uses these features by creating the location-attention oriented
model to classify the data.

3
3.1

Materials and Methods
Dataset

We have used two open-source datasets in our work. The first dataset is taken from this GitHub repository (https:
//github.com/ieee8023/covid-chestxray-dataset), which has been prepared by [5]. This dataset consists of
X-ray and Ct scan images of patients infected to COVID-19, SARS, Streptococcus, ARDS, Pneumocystis, and other
types of pneumonia from different patients.

2

A PREPRINT - A PRIL 20, 2020

Table 1: Composition of the number of allocated images to training and validation set in both datasets
Dataset

COVID-19

Pneumonia

Normal

covid chestxray dataset

180

42

0

rsna pneumonia detection challenge

0

6012

8851

Total

180

6054

8851

All Training Sets

149

1634

2000

Validation Set

31

4420

6851

In this dataset, we only considered the x-ray images, and in total, there were 180 images from 118 cases with COVID-19
and 42 images from 25 cases with Pneumocystis, Streptococcus, and SARS that were considered as pneumonia. The
second dataset was taken from (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge), which
contains 6012 cases with pneumonia, and 8851 normal cases. We combined these two datasets, and the details are listed
in table 1.
As it is stated, we only had 180 cases infected to COVID-19, which is almost a few numbers of data for a class. If we
had combined lots of images from normal or pneumonia classes with few images of COVID-19 class, the network
would become able to detect pneumonia and normal classes very well, but not the COVID-19 class. In that case, as
there are many more images of pneumonia and normal classes than the COVID-19 class, the general accuracy would
become very high, not the COVID-19 detection accuracy, which is not our goal because the main purpose here is to
achieve good results in detecting COVID-19 cases and not detecting false COVID-19 cases.
We decided to select 250 random cases of normal class and 234 random cases of pneumonia class along with the 149
COVID-19 cases for training. In total, we had 633 cases for the training set. We used another method for also improving
the general detection accuracy. In this method, we selected eight different training sets with 633 cases that 149 of
them were COVID-19 cases and 34 pneumonia cases from the first dataset that is common between all sets. Each
set contained 250 normal and 200 pneumonia cases that are unique. Based on this categorizing, our training set than
includes eight sets is made of 3783 images. By doing so, we show different normal and pneumonia cases to the network
in each training phase along with the same COVID-19 cases. This makes the network better be able to distinguish the
COVID-19 cases from the other ones, so the rate of false detected COVID-19 cases decreases. This condition also
causes the network to learn other classes features better, so the general accuracy will increase.
We allocated 8 phases for training, which in each training phase one train set was fed to the network for training during
100 epochs; in total, we trained the network for 800 epochs. For reporting more accurate results, we chose five folds for
training, which in every fold the training set was made of 8 phases as it is mentioned. Some of the images of our dataset
are shown in figure 1.
3.2

Neural Networks and Training

We have trained ResNet50V2[8], Xception[3], and a concatenation of Xception and ResNet50V2 neural networks
based on the explained method. The concatenated neural network is designed by concatenating the extracted features of
Xception and ResNet50V2 and then connecting the concatenated features to a convolutional layer that is connected
to the classifier. This Neural Network has shown higher accuracy comparing to the others. As we have tested several
networks in our project, the Xception[3] and ResNet50V2[8] networks works almost better than other ones in extracting
deep features. By concatenating the output features of both networks, we helped the network to learn to classify the
input image from both feature vectors, and this has resulted in better accuracy. The architecture of the concatenated
network has been depicted in figure 2, and the training parameters have been described in table2.
We implemented the neural networks with Keras[4] library on a Tesla P100 GPU and 25GB RAM that were provided
by Google Colaboratory Notebooks.

3

A PREPRINT - A PRIL 20, 2020

(a) normal persons

(b) Patients with COVID-19

(c) Patients with pneumonia

Figure 1: Examples of the images in our dataset

4

Experimental Results

We validated our data on 31 cases of COVID-19, 4420 cases of pneumonia, and 6851 normal cases. The reason our
training data was less than validation data is that, because having few cases of COVID-19 among lots of normal and
with pneumonia cases, we could not use lots of images of 2 other classes because it would cause the network not to learn
4

A PREPRINT - A PRIL 20, 2020

COVID-19 features. We selected a part of the dataset for eight phases of training in each fold, as it is mentioned before,
and we evaluated our network on the rest of the data so that the ultimate performance of our trained network be clear.
It is noteworthy that we used transfer learning in training precess. For all the networks, we used the pre-trained
ImageNet weights[6] at the beginning of the training and then resumed training based on the explained conditions on
our dataset. The evaluation results of the neural networks are presented in figure 3 that shows the confusion matrixes
of each network for fold one and three. Tables 3 and 4 show the details of our results. The metrics we reported for
evaluating our network are described below:
Accuracy (f or all the classes) =

N umber of Correct Classif ied Images
N umber of All Images

Accuracy (f or each class) =

(2)

TN
TN + FP

Specif icity =
Recall =

TP + TN
TP + FP + TN + FN

(3)

TP
TP + FN

P recision =

(1)

(4)

TP
TP + FP

(5)

In these equations, T P (true positive) is the number of correctly classified images of a class, F P (false positive) is the
number of the wrong classified images of a class, F N (false negative) is the number of images of a class that have been
detected as another class, and T N (true negative) is the number of images that do not belong to a class and won’t be
classified as that class.

Covid-19

Xpection
netwrok
10*10*2048

Pneumonia

Concatenated
Features

Parallel Feature
Extractors

Normal
Covid19
Pneumonia

Dropout
(50%)

10*10*4096

ResNet50 V2
Network
10*10*2048

Classifier
Activation:
Softmax

Conv2D
Filters=1024
Kernel=(1,1)
With Padding
No activation
Flatted
Features
(204800)

Normal

Figure 2: The architecture of the concatenated network
5

A PREPRINT - A PRIL 20, 2020

Table 2: In this table, we have listed the parameters and functions we used in the training procedure.
Training Parameters

Xception

ResNet50V2

Concatenated
Network

Learning Rate

1e-4

1e-4

1e-4

Batch Size

30

30

20

Optimizer

Nadam

Nadam

Nadam

Categorical

Categorical

Categorical

Crossentopy

Crossentopy

Crossentopy

100

100

100

Yes

Yes

Yes

Zoom Range

5%

5%

5%

Rotation Range

0 - 360 degree

0 - 360 degree

0 - 360 degree

5%

5%

5%

Shift Range

5%

5%

5%

Re-scaling

1/255

1/255

1/255

Loss Function
Epochs per each
Training Phase
Horizontal/Vertical
flipping

Width / Height
Shifting

Table 3: This table reports the number of true and false positives and false negatives for each class

Fold

1

2

3

4

5

COVID-19

COVID-19

COVID-19

PNEUMONIA

PNEUMONIA

PNEUMONIA

NORMAL

NORMAL

NORMAL

Correct

Not

Wrong

Correct

Not

Wrong

Correct

Not

Wrong

detected

detected

detected

detected

detected

detected

detected

detected

detected

Xception

26

5

101

3983

437

569

6245

606

378

ResNet50V2

27

4

96

3858

562

480

6334

517

507

Concatenated

26

5

68

3745

675

309

6526

325

628

Xception

23

8

42

3874

546

409

6426

425

528

ResNet50V2

22

9

67

3659

761

501

6340

511

713

Concatenated

23

8

27

3913

507

434

6413

438

492

Xception

21

9

28

3942

478

436

6411

440

463

ResNet50V2

22

8

97

3770

650

392

6433

418

587

Concatenated

25

5

35

3847

573

342

6502

349

550

Xception

22

9

42

3818

602

433

6411

440

576

ResNet50V2

22

9

78

4015

405

758

6065

786

364

Concatenated

26

5

77

3860

560

480

6340

511

519

Xception

21

10

41

4041

379

502

6335

516

362

ResNet50V2

21

10

42

3604

816

284

6549

302

802

Concatenated

24

7

43

3941

479

390

6442

409

462

Network

6

A PREPRINT - A PRIL 20, 2020

It can be understood from the confusion matrixes and the tables that the concatenated network performs better in
detecting COVID-19 and not detecting false cases of COVID-19 and outputs better accuracy overall. The reason
the precision of COVID-19 class is low is that in our work, despite some other researches that worked on detecting
COVID-19 from X-ray images, we tested our neural nets on a massive number of images. Our test images were much
more than our train images. As it is explained above, because we had only 31 cases of COVID-19 and 11271 cases
from other two classes, the false positives of the COVID-19 class would become more than true positives, e.g., the
concatenated network in the first fold, detected 26 cases correctly out of 31 COVID-19 cases and from 11271 other
cases, only mistakenly detects 68 cases as COVID-19. If we had equal samples from COVID-19 class as the other
classes, the precision would become a high value, but because having few COVID-19 cases and lots of other cases for
validation, the precision would become a low value. We could have tested our network on a few cases like some of
the other researches done recently, but we wanted to show the real performance of our network with few COVID-19
cases. As mentioned, mistakenly detecting 68 cases from 11271 cases to be infected to COVID-19 is not very much but
not very well also, and we hope that by using much-provided data from patients infected, COVID-19, the detection
accuracy will rise much more.

5

Conclusion

In this paper, we presented a concatenated neural network based on Xception and ResNet50V2 networks for classifying
the chest X-ray images into three categories of normal, pneumonia, and COVID-19. We used two open-source datasets
that contained 180 and 6054 images from patients infected to COVID-19 and pneumonia, respectively, and 8851
images from normal people. Although we had a few images of COVID-19 class, we selected 633 images for training
in each phase, so that our network learn COVID-19 class characteristics better, not only the other two classes. We
considered eight phases for the training process, which in every phase the images from normal and pneumonia classes
were different so that the network can distinguish COVID-19 from other classes better. In total out training set included
3783 images, and The rest of the images were chosen for evaluating the network. We tried to test our model on a large
number of images so that our real achieved accuracy be clear to everyone. We achieved an average accuracy of 99.56%,
and 80.53% recall for the COVID-19 class, and the overall accuracy equal to 91.4% between five folds. We hope that
our trained network that is available for the public comes with the help of medical diagnosis. We also hope that in the
future, larger datasets from COVID-19 patients become available, and by using them, the accuracy of our network
increases for good.

Table 4: Some of the evaluation metrics have been reported in this table.
Fold

1

2

3

4

5

Average

Network

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

COVID-19

PNEUMONIA

NORMAL

Recall

Recall

Recall

Specificity

Specificity

Specificity

Accuracy

Accuracy

Accuracy

Precision

Precision

Precision

Accuracy

Xception

90.72

83.87

90.11

91.15

99.1

91.73

91.51

99.06

91.10

91.29

20.47

87.50

94.29

ResNet50V2

90.41

87.09

87.28

92.45

99.15

93.03

88.61

99.12

90.78

90.94

21.95

88.93

92.58

Concatenated

91.10

83.87

84.72

95.25

99.4

95.51

85.89

99.35

91.29

91.57

27.65

92.37

91.22

Xception

91.33

74.19

87.64

93.79

99.63

94.06

88.14

99.56

91.55

91.57

35.38

90.45

92.40

ResNet50V2

88.66

70.96

82.78

92.54

99.41

92.72

83.98

99.33

88.83

89.17

24.71

87.95

89.89

Concatenated

91.56

74.19

88.52

93.60

99.76

93.69

88.95

99.69

91.67

91.77

46

90.01

92.87

Xception

91.79

70

89.18

93.57

99.75

93.66

89.6

99.67

91.91

92.01

42.85

90.04

93.26

ResNet50V2

90.47

73.33

85.29

93.89

99.14

94.30

86.81

99.07

90.78

91.11

18.48

90.58

91.63

Concatenated

91.79

83.33

87.03

94.90

99.69

95.03

87.64

99.65

91.90

92.04

41.66

91.83

92.20

Xception

90.70

70.96

86.38

93.57

99.63

93.71

87.06

99.55

90.84

91.01

34.37

89.81

91.75

ResNet50V2

89.38

70.96

90.83

88.52

99.31

88.99

91.82

99.23

89.71

89.82

22

84.11

94.33

Concatenated

90.47

83.87

87.33

92.54

99.32

93.03

88.34

99.27

90.8

90.89

25.24

88.94

92.43

Xception

91.99

67.74

91.42

92.46

99.64

92.71

91.87

99.55

92.20

92.23

33.87

88.95

94.59

ResNet50V2

90.01

67.74

81.53

95.59

99.63

95.87

81.98

99.54

90.27

90.23

33.33

92.69

89.08

Concatenated

92.08

77.41

89.16

94.03

99.62

94.33

89.62

99.56

92.31

92.29

35.82

90.99

93.30

Xception

91.31

73.35

88.95

92.91

99.55

93.17

89.63

99.48

91.52

91.62

33.39

89.35

93.26

ResNet50V2

89.79

74.02

85.54

92.60

99.33

92.98

86.64

99.26

90.07

90.25

24.09

88.85

91.50

Concatenated

91.40

80.53

87.35

94.06

99.56

94.32

88.09

99.50

91.60

91.71

35.27

90.83

92.40

7

A PREPRINT - A PRIL 20, 2020

Confusion Matrix for the concatenated network-fold1

NORMAL

6526

307

18

376

3983

61

NORMAL

6245

566

40

AL
NO
RM

PN

CO
VID

Predicted Label

Predicted Label

(a) Concatenated network-Fold1

(b) Xception-Fold1

56

NORMAL

6334

477

40

547

3847

26

NORMAL

6502

340

9

RM

AL

-19

PN
EU

NO

VID
CO

Predicted Label

Predicted Label

(c) ResNet50V2-Fold1

(d) Concatenated network-Fold3

Confusion Matrix for Xception-fold3

NORMAL

6411

430

10

584

3770

66

NORMAL

6433

387

31

RM

AL

19
CO

NO

VID
-

ON
PN
E

UM

AL
RM
NO

Ground Truth Label

PNEUMONIA

Predicted Label

19

18

VID
-

3942

22

CO

460

5

IA

PNEUMONIA

3

COVID-19

ON

21
Ground Truth Label

6

IA

3

COVID-19

Confusion Matrix for ResNet50V2-fold3

UM

PN
EU

NO

MO

RM

AL

Ground Truth Label

PNEUMONIA

-19

3858

25

VID

506

2

CO

PNEUMONIA

3

COVID-19

MO

27
Ground Truth Label

3

NIA

1

COVID-19

Confusion Matrix for the concatenated network-fold3

NIA

Confusion Matrix for ResNet50V2-fold1

PN
E

PN

EU

NO
RM

AL

Ground Truth Label

PNEUMONIA

-19

50

CO
VID

3745

26

MO
NIA

625

3

EU

PNEUMONIA

2

COVID-19
Ground Truth Label

26

-19

2

MO
NIA

3

COVID-19

Confusion Matrix for Xception-fold1

Predicted Label

(e) Xception-Fold3

(f) ResNet50V2-Fold3

Figure 3: This figure shows the confusion matrix of the network for fold 1 and 3

8

A PREPRINT - A PRIL 20, 2020

6

Code Availability

In this GitHub profile (https://github.com/mr7495/covid19), we have shared the trained networks and all the
used code in this paper. We hope our work be useful to help in future researches.

Acknowledgment
We would like to appreciate Joseph Paul Cohen and the others who provided these x-ray images from patients infected
to COVID-19. We thank Linda Wang and Alexander Wong for making their code available, in which we have used
some of it on our research for preparing our dataset. We also thank Google Colab server for providing free GPU.

References
[1] P. An, H. Chen, X. Jiang, J. Su, Y. Xiao, Y. Ding, H. Ren, M. Ji, Y. Chen, W. Chen, et al. Clinical features of 2019
novel coronavirus pneumonia presented gastrointestinal symptoms but without fever onset. arxiv, 2020.
[2] J.-Z. Cheng, D. Ni, Y.-H. Chou, J. Qin, C.-M. Tiu, Y.-C. Chang, C.-S. Huang, D. Shen, and C.-M. Chen. Computeraided diagnosis with deep learning architecture: applications to breast lesions in us images and pulmonary nodules
in ct scans. Scientific reports, 6(1):1–13, 2016.
[3] F. Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE conference
on computer vision and pattern recognition, pages 1251–1258, 2017.
[4] F. Chollet and Others. keras, 2015.
[5] J. P. Cohen, P. Morrison, and L. Dao. Covid-19 image data collection. arXiv preprint arXiv:2003.11597, 2020.
[6] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database.
In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee, 2009.
[7] O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning, H. Zhang, W. Ji, A. Bernheim, and E. Siegel. Rapid ai
development cycle for the coronavirus (covid-19) pandemic: Initial results for automated detection & patient
monitoring using deep learning ct image analysis. arXiv preprint arXiv:2003.05037, 2020.
[8] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In European conference on
computer vision, pages 630–645. Springer, 2016.
[9] F. Jiang, L. Deng, L. Zhang, Y. Cai, C. W. Cheung, and Z. Xia. Review of the clinical characteristics of coronavirus
disease 2019 (covid-19). Journal of General Internal Medicine, pages 1–5, 2020.
[10] S. Lakshmanaprabu, S. N. Mohanty, K. Shankar, N. Arunkumar, and G. Ramirez. Optimal deep learning model
for classification of lung cancer on ct images. Future Generation Computer Systems, 92:374–382, 2019.
[11] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang, Q. Song, et al. Artificial intelligence
distinguishes covid-19 from community acquired pneumonia on chest ct. Radiology, page 200905, 2020.
[12] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian, J. A. Van Der Laak, B. Van Ginneken,
and C. I. Sánchez. A survey on deep learning in medical image analysis. Medical image analysis, 42:60–88, 2017.
[13] K. McIntosh. Coronavirus disease 2019 (COVID-19): Epidemiology, virology, clinical features, diagnosis, and
prevention, 2020-04-10.
[14] W. Meters. COVID-19 CORONAVIRUS PANDEMIC https: // www. worldometers. info/ coronavirus ,
2020-04-10.
[15] A. Narin, C. Kaya, and Z. Pamuk. Automatic detection of coronavirus disease (covid-19) using x-ray images and
deep convolutional neural networks. arXiv preprint arXiv:2003.10849, 2020.
[16] M. Rahimzadeh, A. Attar, et al. Sperm detection and tracking in phase-contrast microscopy image sequences
using deep learning and modified csr-dcf. arXiv preprint arXiv:2002.04034, 2020.
[17] O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation.
In International Conference on Medical image computing and computer-assisted intervention, pages 234–241.
Springer, 2015.
[18] F. Shan+, Y. Gao+, J. Wang, W. Shi, N. Shi, M. Han, Z. Xue, D. Shen, and Y. Shi. Lung infection quantification of
covid-19 in ct images with deep learning. arXiv preprint arXiv:2003.04655, 2020.
[19] F. Song, N. Shi, F. Shan, Z. Zhang, J. Shen, H. Lu, Y. Ling, Y. Jiang, and Y. Shi. Emerging 2019 novel coronavirus
(2019-ncov) pneumonia. Radiology, page 200274, 2020.
9

A PREPRINT - A PRIL 20, 2020

[20] D. Sun, H. Li, X.-X. Lu, H. Xiao, J. Ren, F.-R. Zhang, and Z.-S. Liu. Clinical features of severe pediatric patients
with coronavirus disease 2019 in wuhan: a single center’s observational study. World Journal of Pediatrics, pages
1–9, 2020.
[21] univers1. Everything about the Corona virus https: // medicine-and-mental-health. xyz/ archives/
4510 , 2020-04-12.
[22] L. Wang and A. Wong. Covid-net: A tailored deep convolutional neural network design for detection of covid-19
cases from chest radiography images. arXiv preprint arXiv:2003.09871, 2020.
[23] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang, Y. Li, X. Meng, et al. A deep learning
algorithm using ct images to screen for corona virus disease (covid-19). medRxiv, 2020.
[24] WHO. https: // www. who. int , 2020-04-10.
[25] X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu, Y. Chen, J. Su, G. Lang, et al. Deep learning system to screen
coronavirus disease 2019 pneumonia. arXiv preprint arXiv:2002.09334, 2020.
[26] R. Yang, X. Li, H. Liu, Y. Zhen, X. Zhang, Q. Xiong, Y. Luo, C. Gao, and W. Zeng. Chest ct severity score: An
imaging tool for assessing severe covid-19. Radiology: Cardiothoracic Imaging, 2(2):e200047, 2020.
[27] M. Zreik, N. Lessmann, R. W. van Hamersvelt, J. M. Wolterink, M. Voskuil, M. A. Viergever, T. Leiner, and
I. Išgum. Deep learning analysis of the myocardium in coronary ct angiography for identification of patients with
functionally significant coronary artery stenosis. Medical image analysis, 44:72–85, 2018.

10

