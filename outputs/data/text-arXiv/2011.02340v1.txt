TUNISIAN REPUBLIC
MINISTRY OF HIGHER EDUCATION AND SCIENTIFIC RESEARCH
TUNIS EL MANAR UNIVERSITY

arXiv:2011.02340v1 [cs.AI] 2 Nov 2020

FACULTY OF SCIENCES OF TUNIS

Master Thesis
Submitted for a
Research Master’s Degree in Computer Science
By

Khouloud Hwerbi

Ontology-Based Chatbot for
Disaster Management:
Use Case CoronaVirus
Defended on October 9, 2020 in front of the following jury:
President
Reporter
Co-Supervisor
Supervisor

Hella Kaffel Ben Ayed
Narjes Doggaz
Salvatore Flavio Pileggi
Sadok Ben Yahia

Associate Professor at FST
Assistant Professor at FST
Lecturer at UTS
Full Professor at FST

In the Laboratory: LIPAH

2019–2020

Abstract
Today is the era of intelligence in machines. With the advances in Artificial
Intelligence, machines have started to impersonate different human traits, a
chatbot is the next big thing in the domain of conversational services. A chatbot
is a virtual person who is capable to carry out a natural conversation with
people. They can include skills that enable them to converse with the humans
in audio, visual, or textual formats. Artificial intelligence conversational entities,
also called chatbots, conversational agents, or dialogue system, are an excellent
example of such machines.
Obtaining the right information at the right time and place is the key to
effective disaster management. The term "disaster management" encompasses
both natural and human-caused disasters. To assist citizens, our project is to
create a COVID Assistant to provide the need of up to date information to
be available 24 hours. With the growth in the World Wide Web, it is quite
intelligible that users are interested in the swift and relatedly correct information
for their hunt. A chatbot can be seen as a question-and-answer system in which
experts provide knowledge to solicit users.
This master thesis is dedicated to discuss COVID Assistant chatbot and
explain each component in detail. The design of the proposed chatbot is introduced by its seven components: Ontology, Web Scraping module, DB, State
Machine, keyword Extractor, Trained chatbot, and User Interface.
Keywords:

Chatbot, Conversational Agent, Ontology, Finite State Ma-

chine, Disaster Management, Covid-19

Dedication

To my parents
To my sister
To my friends
To all my family

Acknowledgement
I would like to thank Mr. Sadok Ben Yahia, Professor at the Faculty of Sciences of Tunis and director of the Laboratory of Computer
Science in Programming, Algorithms, and Heuristics (LIPAH), for
the trust he has accorded to me by agreeing to direct my master’s
work. I thank him for his continuous availability and I would like to
express my great and sincere gratitude to him;
I would like to thank my co-director, Mr. Salvatore Flavio Pileggi,
Lecturer at University of Technology Sydney for his support, for the
ideas he’s given to me throughout this master’s thesis and sound and
precious advice;
I would like to express my gratitude to Mrs. Hella Kaffal, Professor
at the Faculty of Sciences of Tunis, for the honor she has done me by
accepting to preside over the jury;
I would also like to thank Mrs. Narjes Doggaz, Assistant Professor
at the Faculty of Sciences of Tunis, for agreeing to join this jury as
rapporteur;
I would like to express my gratitude to Mr. Mohamed Taha Bennani,
Assistant Professor at the Faculty of Sciences of Tunis, for the help
he gave me;
I would also thank Ines Osman, a Ph.D. student at the Faculty of
Sciences of Tunis, for the help she gave me throughout this master
thesis.

Contents
Contents

1

List of Figures

4

List of Tables

6

1 Introduction

7

1.1

Purpose . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9

1.2

Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

2 Background

11

2.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.2

Artifial Intelligence . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.3

2.4

Chatbot history . . . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.3.1

Turing Test . . . . . . . . . . . . . . . . . . . . . . . . . .

12

2.3.2

ELIZA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.3.3

PARRY . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.3.4

A.L.I.C.E . . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.3.5

Mitsuku . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18

2.3.6

IBM’s Watson . . . . . . . . . . . . . . . . . . . . . . . .

18

2.3.7

Apple’s Siri . . . . . . . . . . . . . . . . . . . . . . . . . .

19

2.3.8

Amazon’s Alexa . . . . . . . . . . . . . . . . . . . . . . .

20

2.3.9

Microsoft’s Cortana . . . . . . . . . . . . . . . . . . . . .

20

2.3.10 Google assistant . . . . . . . . . . . . . . . . . . . . . . .

21

2.3.11 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . .

21

Foundation of the Semantic Web . . . . . . . . . . . . . . . . . .

24

2.4.1

Concept of the semantic web . . . . . . . . . . . . . . . .

24

2.4.2

Ontology . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

1

Contents

2.4.3

Representation languages . . . . . . . . . . . . . . . . . .

26

2.5

Finite State Machine . . . . . . . . . . . . . . . . . . . . . . . . .

28

2.6

Conclusion

29

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Chatbot Architecture

30

3.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

31

3.2

Architecture Components . . . . . . . . . . . . . . . . . . . . . .

31

3.2.1

Ontology . . . . . . . . . . . . . . . . . . . . . . . . . . .

32

3.2.2

Web scaping . . . . . . . . . . . . . . . . . . . . . . . . .

35

3.2.3

Database . . . . . . . . . . . . . . . . . . . . . . . . . . .

36

3.2.4

State Machine . . . . . . . . . . . . . . . . . . . . . . . .

37

3.2.5

Keyword Extraction . . . . . . . . . . . . . . . . . . . . .

40

3.2.6
3.2.7

Trained Chatbot . . . . . . . . . . . . . . . . . . . . . . .
User Interface . . . . . . . . . . . . . . . . . . . . . . . . .

41
42

3.3

Conclusion

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Conceptual study and Implementation

42
43

4.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

44

4.2

Conceptual study . . . . . . . . . . . . . . . . . . . . . . . . . . .

44

4.2.1
4.2.2

Static view . . . . . . . . . . . . . . . . . . . . . . . . . .
Dynamic view . . . . . . . . . . . . . . . . . . . . . . . . .

44
45

Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.3.1

Python . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.3.2

Protégé . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.3.3

MySQL/ MySQL Workbench . . . . . . . . . . . . . . . .

52

4.3.4

StarUML . . . . . . . . . . . . . . . . . . . . . . . . . . .

52

4.3.5

Uppaal

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

53

4.3.6

Python libraries . . . . . . . . . . . . . . . . . . . . . . .

53

4.3

4.4

Conclusion

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

54

5 Result

55

5.1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

56

5.2

Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

56

5.3

5.4

Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

61

5.3.1

Ontology . . . . . . . . . . . . . . . . . . . . . . . . . . .

61

5.3.2

State machine . . . . . . . . . . . . . . . . . . . . . . . . .

62

Conclusion

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

65

Contents

6 Conclusion and futur work
6.1

66

Futur work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Bibliography

67
68

3

List of Figures
2.1

ELIZA interface . . . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.2

A.L.I.C.E interface . . . . . . . . . . . . . . . . . . . . . . . . . .

16

2.3

Mitsuku . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18

2.4

IBM Watson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18

2.5

Siri . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

19

2.6

Amazon Alexa . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2.7

Cortana . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

2.8

Google Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . .

21

2.9

Chatbot design . . . . . . . . . . . . . . . . . . . . . . . . . . . .

22

3.1

Reference Architecture . . . . . . . . . . . . . . . . . . . . . . . .

31

3.2

Class Hierarchy of CVIO . . . . . . . . . . . . . . . . . . . . . . .

33

3.3

Example of an individual . . . . . . . . . . . . . . . . . . . . . .

35

3.4

Web scraping technique . . . . . . . . . . . . . . . . . . . . . . .

35

3.5

Current status of different country . . . . . . . . . . . . . . . . .

36

3.6

State Machine Structure . . . . . . . . . . . . . . . . . . . . . . .

37

3.7

ChatterBot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

41

3.8

Training Packages . . . . . . . . . . . . . . . . . . . . . . . . . .

42

4.1

General use case diagram . . . . . . . . . . . . . . . . . . . . . .

44

4.2

Management of name retrieval

. . . . . . . . . . . . . . . . . . .

46

4.3
4.4

Management of a country request (version 1) . . . . . . . . . . .
Management of a country request (version 2) . . . . . . . . . . .

47
48

4.5

Management of COVID-19 request . . . . . . . . . . . . . . . . .

49

4.6

Management of symptom request . . . . . . . . . . . . . . . . . .

49

4.7

Management of general talk request . . . . . . . . . . . . . . . .

50

4.8

Python

51

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4

List of Figures

4.9

Protégé . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.10 MySQL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

52

4.11 StartUml . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

52

4.12 Uppaal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

53

5.1

Covid Assistant . . . . . . . . . . . . . . . . . . . . . . . . . . . .

56

5.2

Example 1 and 2 . . . . . . . . . . . . . . . . . . . . . . . . . . .

57

5.3

Covid-19 Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

58

5.4

Current Status of Tunisia . . . . . . . . . . . . . . . . . . . . . .

58

5.5

Example 3 and 4 . . . . . . . . . . . . . . . . . . . . . . . . . . .

59

5.6

Example 5 and 6 . . . . . . . . . . . . . . . . . . . . . . . . . . .

60

5.7

Model desinged . . . . . . . . . . . . . . . . . . . . . . . . . . . .

62

5.8

Properties Verification . . . . . . . . . . . . . . . . . . . . . . . .

63

5.9

Parallel verification . . . . . . . . . . . . . . . . . . . . . . . . . .

64

5.10 Simulated execution . . . . . . . . . . . . . . . . . . . . . . . . .

65

5

List of Tables
2.1

Typical conversation with ELIZA [63] . . . . . . . . . . . . . . .

15

2.2

Example of ALICE’s AIML structure [59] . . . . . . . . . . . . .

17

2.3

Rank List [51]

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

23

3.1

The main symptoms of COVID-19 . . . . . . . . . . . . . . . . .

32

4.1

General Use Case Diagram Table . . . . . . . . . . . . . . . . . .

45

4.2

List of Python libraries

53

. . . . . . . . . . . . . . . . . . . . . . .

6

Chapter 1

Introduction
Contents
1.1

Purpose . . . . . . . . . . . . . . . . . . . . . . . . .

9

1.2

Structure . . . . . . . . . . . . . . . . . . . . . . . .

10

7

Chapter 1. Introduction

The idea of building an artificial intelligent program dates back at least as
far as Turing’s paper on “Computing Machinery and Intelligence” (Turing, 1950)
was published, in which he asked the famous question “Can a machine think?”,
and in the ongoing of the answer to this question, it can be said that the entire
field of Artificial Intelligence (AI) has been enhanced.
Artificial intelligence (AI) is being utilized to improve technology development
and applications due to its unbelievable capability of dealing with big data,
complexity, high accuracy, and speedy processing. Marvin Lee Minsky, an
American mathematician and computer scientist, one of the founding fathers of
the science of artificial intelligence (AI), defined AI as “the science of making
machines do things that would require intelligence if done by men.”
The AI assistants/chatbots have revolutionized by understanding human
queries in different languages and appropriately extraction the meaningful information. The main aim of these chatbots is to supply informative, immediate,
meaningful, and context-oriented responses to assist their users in the asked
questions.
Chatbot is a computer program that interacts with users using natural
Languages. Chatbot systems permit to realize simply a dialogue system based
on natural language. chatbot can be used in multiple cases entertainment
chatbots (Zeka [54], museumBot [61], etc.), educational chatbots (TutorBot [33],
FreudBot [27], etc.), health care chatbots (SPeCECA [41], MedBot [34], Mandy
[37], etc.), and banking service chatbots ([19], [5]) and many more other domains.
The influence and the spreading of chatbots in society grow constantly, so we
can take advantage of this aspect in an emergency situation like, the one which
the whole world suffers these days, Covid-19 infection. The usage of chatbots
could reduce the insufficient of real, correct, and availability of information
provided to citizens. As machines do not need a break like human beings, they
could ensure a 24-hour service for anyone who has access to a computer or to a
smartphone. Citizens, therefore, does not need to conform to the opening hours
of medical call centers.
Furthermore, chatbots are able to reply instantly and increase the accessibility
of psychological support in such an emergency situation due to that Coronavirus
is a new disease. Another benefit of using chatbots in emergency situations is
the scalability of chatbots as they can respond to multiple users at the same
time and can consequently reduce personnel costs.
The AI Chatbots retrieve information through different approaches. In
modern practice, these approaches use a variety of repository structures such as
8

Chapter 1. Introduction

conventional (Relational) and modern (NoSQL) database systems, ontologies,
AIML, JSON files, etc.
In recent years, the development of ontologies has moved from the realm of
artificial intelligence laboratories to the offices of experts in the field. Ontologies
have become commonplace on the World Wide Web and a modeling trend in the
development of information systems where we can take advantage of the great
benefits they provide. Ontologies are comprehensive, human-readable, sharable,
and formal it means that they are expressed in a language that has a well-defined
semantics. Ontologies are important for application integration solutions because
they enable a common and shared understanding of the data that exists within
an application. Ontologies also make the communication between people and
information systems easier.

In [3], [35] and [18] Knowledge of the Semantic Web

was used to enhance the capabilities of a language-independent conversational
agent-oriented towards solving question-answering tasks. Currently, developers
who wish to use ontology repositories needs should learn about the contents of
the ontology, which means understanding OWL or RDF, and to query these
ontologies we need an ontology query language like SPARQL. Such requirements
are some of the major causes, the Semantic Web has not become the main trend
as fewer than expected users are utilizing such knowledge.

1.1

Purpose

In this master thesis, an ontology-based chatbot “COVID Assistant” is proposed
to provide an easy to use, domain-independent, scalable, dynamic, and smart
conversational agent.
The proposed system provides a text-to-text conversational agent to simulate
a human conversation; the chatbot architecture integrates an NLP tool kit to
extract and understand the user input, an ontology as a Knowledge-base, a finite
state machine as the engine of the chatbot.
COVID Assistant Chatbot, developed in Python, covers all necessary and
general information relevant to the Coronavirus disease, current status of contamination, trends, etc. For example, a chatbot user can ask: “what is the current
status of Tunisia?” or “Tell me about the contamination status of the Corona
Virus in Tunisia”, etc. To do so, we populated the ontology using web scraping
technique on Covid-19 news from google web site to ensure that information
provided to the user is always up to date, other information also are extracted

9

Chapter 1. Introduction

from trusted sources.

1.2

Structure

This dissertation is organized as follows:
1. The next chapter introduces the essential concepts for defining the field
of study. indeed, a bibliographical study on the famous chatbots of the
literature as well as a discussion is carried out on the different chatbots.
Then, the foundation of the Semantic Web is studied. In the latter, we
discussed the appearance of the semantic web, the ontological components
and we cited the main languages of representation of ontologies. The last
section is dedicated to the study of finite state machines.
2. The third chapter presents the architecture of COVID Assistant and
explains the work of each component separately.
3. The fourth chapter is devoted to the presentation of the conceptual
study in which we studied the static and the dynamic view by defining a
general use case diagram and a sequence diagram for each use case and an
implementation section which describes technical details.
4. The fifth chapter is composed of two sections, the first one presents
some screenshots of the execution of the chatbot and the second section
contains a description of the validation step.

10

Chapter 2

Background
Contents
2.1

Introduction

. . . . . . . . . . . . . . . . . . . . . .

12

2.2

Artifial Intelligence . . . . . . . . . . . . . . . . . .

12

2.3

Chatbot history . . . . . . . . . . . . . . . . . . . .

12

2.4

2.3.1

Turing Test . . . . . . . . . . . . . . . . . . . . . . .

12

2.3.2

ELIZA . . . . . . . . . . . . . . . . . . . . . . . . . .

13

2.3.3

PARRY . . . . . . . . . . . . . . . . . . . . . . . . .

15

2.3.4

A.L.I.C.E . . . . . . . . . . . . . . . . . . . . . . . .

16

2.3.5

Mitsuku . . . . . . . . . . . . . . . . . . . . . . . . .

18

2.3.6

IBM’s Watson

. . . . . . . . . . . . . . . . . . . . .

18

2.3.7

Apple’s Siri . . . . . . . . . . . . . . . . . . . . . . .

19

2.3.8

Amazon’s Alexa . . . . . . . . . . . . . . . . . . . .

20

2.3.9

Microsoft’s Cortana . . . . . . . . . . . . . . . . . .

20

2.3.10 Google assistant . . . . . . . . . . . . . . . . . . . .

21

2.3.11 Discussion . . . . . . . . . . . . . . . . . . . . . . . .

21

Foundation of the Semantic Web . . . . . . . . . .

24

2.4.1

Concept of the semantic web . . . . . . . . . . . . .

24

2.4.2

Ontology . . . . . . . . . . . . . . . . . . . . . . . .

25

2.4.3

Representation languages . . . . . . . . . . . . . . .

26

2.5

Finite State Machine . . . . . . . . . . . . . . . . .

28

2.6

Conclusion

29

. . . . . . . . . . . . . . . . . . . . . . .

11

Chapter 2. Background

2.1

Introduction

In this chapter, we start by talking about artificial intelligence, the field that
includes chatbots, then we recall the appearance of chatbots, citing the most
important ones in the literature up to today’s famous ones, then we start the
foundation of the semantic web and the state machine.

2.2

Artifial Intelligence

In computer science, artificial intelligence (AI), also called machine intelligence, is
the intelligence demonstrated by machines, as opposed to the natural intelligence
displayed by humans. According to AI textbooks, Artificial Intelligence is based
on how a machine can perceive its environment and take actions that maximize
its chance of successfully achieving its goals. In everyday language, the term
"artificial intelligence" is often used to describe machines (or computers) that
mimic the "cognitive" functions that humans associate with the human mind,
such as "learning" and "problem-solving". AI gives the supreme power to
simulate human behaving to a computer.
Chatbots are a real example of artificial intelligence, a chatbot is a conversational software system that is designed to emulate the communication capabilities
of a human being that interacts automatically with a user. It employs Natural
Language Processing and Pattern Recognition techniques to identify the meaning
and provide meaningful responses to questions posed by humans.
It represents a modern form of customer assistance powered by artificial
intelligence via a chat interface. For example, it makes it easy for customers to
get responses to their queries in a convenient way without spending their time
waiting in phone queues or send repeated emails.

2.3
2.3.1

Chatbot history
Turing Test

In 1950, a British mathematician, Alan Turing published a paper entitled
“Computing Machinery and Intelligence” [60] where he asked the famous question
”Can a machine think?” and he proposed the Turing test. It’s a test that somehow
answers his question. The fame of this question motivated the development
of the first chatbot in 1966 ELIZA. And to answer the latter, in this paper
12

Chapter 2. Background

Turing suggested ”The Imitating Game”. The Imitation Game can be played
between three people: (A) who is a man, (B) who is a woman, and (C) who
is the interrogator and who can be a man or a woman. The purpose of the
interrogator is to determine who is the woman and who is the man.
Turing then wonders what will happen if A is replaced by a machine; can
the interrogator tell the difference between the two? According to him, if
the interrogator who converses with an unknown entity (via the keyboard, for
example) thinks that this entity is human when the entity is in fact a computer,
then this computer has managed to pass the Turing test.
ELIZA and PARRY are the first two programs that have passed the Turing
Test. This article is widely regarded as one of the fundamental foundations of
artificial intelligence and the Turing test which has been proposed in this article
can be considered as a reference for assessing the intelligence of a computer
system [16] . In 1990, an agreement was reached between Hugh Loebner and the
Cambridge Center for Behavioral Studies to establish a competition based on
the application of the Turing test.

2.3.2

ELIZA

ELIZA is the first conversational agent,
developed between 1964 and 1966, by
Joseph Weizenbaum. It is a system
allowing human-machine interaction
via natural language, it was designed
to imitate a psychotherapist [63] .
The program procedure is quite simple:
ELIZA searches for text entered by
the user and detects the presence of

Figure 2.1: ELIZA interface

keywords. When such a word is found,
it then applies pre-programmed rules

to generate appropriate responses based on these keywords, otherwise, if a user
does not enter a keyword, ELIZA responds with a default phrase, such as "Very
interesting", "Please continue." or "Can you think of a specific example?"
The mechanisms behind the transformation rule are a number of functions that
serve to:
• Break down a character string according to certain criteria.

13

Chapter 2. Background

• Re-assemble a decomposed chain according to certain specifications.
Considering the sentence "I am very unhappy these days" ELIZA’s answer
will be "How long have you been unhappy these days" applying the mechanism
of transformation rules the chain is broken down into two parts, the first "I am"
is replaced by "How long have you been" and the second part has remained
stable. This transformation is in the form "I am BLAH" is transformed into
"How long have you been BLAH", regardless of the meaning of BLAH.
A slightly more complicated example is given by the sentence "It seems that you
hate me" the answer will be "what makes you think I hate you" the program
applied a decomposition into four parts (It seems that you, hate, me ). The
transformation will be to throw out the first part, translate the two known words
("you" into "me" and "me" into "you"), add a common phrase "what makes you
think" and keep the third part.
Although using a simple technique, ELIZA was able to deceive a large number
of people who believed that the program really listened to their problems. Here
is an example of a conversation with ELIZA:
ELIZA generally asked users questions to raise them and minimize the risk of
error. This type of approach is frequently used in chatbots to make them look
more human. But, being a rules-based system, ELIZA could not have meaningful
conversations with humans, but rather it could deceive a human into giving the
illusion that it is not a computer program.

14

Chapter 2. Background

• User: Men are all alike.
• ELIZA: IN WHAT WAY?
• User: They’re always bugging us about something or other.
• ELIZA: CAN YOU THINK OF A SPECIFIC EXAMPLE?
• User: Well, my boyfriend made me come here.
• ELIZA: YOUR BOYFRIEND MADE YOU COME HERE
• User: He says I’m depressed much of the time.
• ELIZA: I AM SORRY TO HEAR YOU ARE DEPRESSED.
• User: It’s true. I am unhappy
• ELIZA: DO YOU THINK COMING HERE WILL HELP YOU
NOT TO BE UNHAPPY
• User: I need some help, that much seems certain.
• ELIZA: WHAT WOULD IT MEAN TO YOU IF YOU GOT SOME
HELP
• User: Perhaps I could learn to get along with my mother.
• ELIZA: TELL ME MORE ABOUT YOUR FAMILY
• ...
Table 2.1: Typical conversation with ELIZA [63]

2.3.3

PARRY

After ELIZA, Kenneth Colby, a psychiatrist, developed PARRY at Stanford
University. PARRY was written to imitate a person with paranoid schizophrenia.
PARRY was tested in the early 1970s using a variant of the Turing test. A
group of experienced psychiatrists analyzed a combination of real patients and
computers running PARRY via teletypewriter. Psychiatrists were only able to
make the correct identification 48% of the time [29].
Despite everything, Parry is still rule-based and has a response model structure
similar to ELIZA, but it has an advanced control structure, language comprehension capabilities and above all a mental model that can simulate emotions of the
bot like anger, fear. . . For example, Parry will respond with hostility if the level

15

Chapter 2. Background

of anger is high [52]. PARRY’s goal was not to help mental health therapy; but
rather to show how technology could be used to imitate a person with mental
health problems [55]

2.3.4

A.L.I.C.E

Figure 2.2: A.L.I.C.E interface

Artificial Linguistic Internet Chat Entity or ALICE, developed in 1995 by
Richard Wallace, is an open source natural language processing chatbot, inspired
by ELIZA. Richard Wallace, has hand-written a database of thousands of possible
conversational gambits.
ALICE uses AIML (Artificial Intelligence Mark-up Language), an XMLlike language designed to create stimulus-response chat robots. The ALICE
knowledge base is made up of question and answer modules, called categories,
and structured with AIML. The learning model in ALICE is called supervised
learning because a person, called a botmaster, plays a crucial role. In fact, the
botmaster monitors robots’ conversations and creates new AIML content to
make responses more appropriate, precise or believable [3].
Each category includes a response model and a set of conditions that give meaning to the model known as context. Then the model prepares it and compares
it to the nodes of the decision tree. When user data is associated, the chatbot
responds or performs an action. AIML models repeat user input using recursive
techniques and these are not always meaningful responses. Therefore, rules based
on character strings are necessary to determine whether the response creates a
16

Chapter 2. Background

correct or meaningful response [38]. The authors of [49] consider ALICE to be
the head and the shoulders above the other conversational agents. ALICE was
the recipient of Loebner’s annual instantiation of the Turing test for artificial
intelligence three times in 2000, 2001, and 2004.
As this is a predefined set of questions and answer questions, it cannot satisfactorily answer each question [57]. There are several notable research studies where
ALICE has been used. The first was an English and German conversational
partner for Chinese students [21]. However, a large proportion of students did
not like the chatterbot responses and made poor comments on the system [48].
Despite all of its drawbacks, none of today’s chatbots would have been possible
without the revolutionary work of Dr. Wallace. Additionally, Wallace’s bot
served as inspiration for the associated operating system in Spike Jonze’s 2013
sci-fi romance film Her [50].
<aiml version=1.0.1 encoding=UTF-8>
< category >
< pattern > HELLO BOT < /pattern >
< template >
< random >
< li > Hi! Nice to meet you< /li >
< li > Hello, How are you?< /li >
< li > Hello! < /li >
< /random >
< /template >
< /category >
< /aiml >
Table 2.2: Example of ALICE’s AIML structure [59]

Richard Wallace created Alice, and it was launched in November 1995, it was
rewritten in 1998 in Java language.

17

Chapter 2. Background

2.3.5

Mitsuku
Mitsuku is a chatbot created by Steve
Worswick. He has won the Loebner
Prize five times (in 2013, 2016, 2017,
2018 and 2019). It was designed for
general typed conversation based on
rules written in AIML.
Mitsuku can hold a long conversation, learn from the conversation,
remember personal details about the
user (age, location, gender, etc.). Its
functionality includes the possibility
of reasoning with specific objects. For

Figure 2.3: Mitsuku

instance, if someone asks, "Can you

eat a car? Mitsuku searches for the properties of "because" finds that the value
of "made from" is set to "steal" and responds to "no" because a car is not edible
[51]. Mitsuku is a multilingual bot and uses supervised machine learning. As
he learns something new, the data is sent to the human manager for verification. Only verified data can be integrated and used by the application [38].
Mitsuku is available as a flash game on Mousebreaker Games and Facebook
Messenger, Twitch group chat, Telegram, and Kik Messenger under the username
"Pandorabots".

2.3.6

IBM’s Watson
Watson1 , is a rules-based conversational agent, developed in 2006 by
an IBM team as part of the DeepQA
project.

The Agent is a Question-

Answer framework was designed specifically to win the American TV show
Jeopardy. What he did in 2011.
Since then, IBM Watson has offered services to create chatbots for difFigure 2.4: IBM Watson

ferent domains that can process large

1 https://www.ibm.com/watson

18

Chapter 2. Background

amounts of data [10]. Watson was designed to apply advanced technologies for natural language processing, information retrieval, knowledge representation, automated reasoning, and machine
learning. Watson integrates a variety of technologies, including Hadoop, the
Apache Unstructured Information Management Architecture (UIMA) framework
to examine the sentence structure and grammar of the question to better assess
what is being asked [38].

2.3.7

Apple’s Siri
Apple released Siri2 in 2011.
Since then, several Intelligent
Personal Assistants (IPAs) have
been built and introduced to the
market. Siri is a virtual assistant specifically available on Apple products and has access to
Apple applications.
Siri can read user emails, text
contacts, change music, make

Figure 2.5: Siri

phone app calls, find restau-

rants, find books, set alarms, and give directions. The user can dictate an
SMS to send, a search to be done on the web with Safari or even he can chat
with it. The genre, accent, and language of Siri are configurable and changeable.
Siri uses ASR (Automatic speech recognition) to translate human speech into
text. Using natural language processing (part of speech tagging, noun-phrase
chunking, dependency, and constitute parsing), it translates the transcribed text
into “parsed-text". Using question and intent analysis, it analyzes the parsed
text and detects user commands and actions.

2 https://www.apple.com/siri/

19

Chapter 2. Background

2.3.8

Amazon’s Alexa
Amazon Alexa3 , also known as
Alexa, is a virtual assistant AI
technology developed by Amazon in November 2014, first used
in Amazon Echo smart speakers and then Alexa became the
voice service that powers many
Amazon devices like Dot, Spot,
Show, and Amazon Fire TV. It

Figure 2.6: Amazon Alexa

provides capabilities and skills

that allow customers to interact with devices more intuitively using voice. Alexa
uses natural language processing algorithms for voice interaction. It uses these
algorithms to receive, recognize, and respond to voice commands [29]. It is
capable of voice interaction, reading music, making to-do lists, setting alarms,
reading podcasts and audiobooks, and giving the weather, traffic, and other
information in real-time. Currently, interaction and communication with Alexa
is available in English, French, Spanish, German, and Japanese.

2.3.9

Microsoft’s Cortana
Cortana4 is the name of the intelligent personal assistant and knowledge
browser for Windows Mobile and Windows 10. Cortana was introduced for
the first time at the Microsoft BUILD
Developer Conference in April 2014 in
San Francisco. He is named after Cortana, a synthetic intelligence character
from Microsoft’s Halo video game fran-

Figure 2.7: Cortana

chise, written in C#.
There are two ways to use Cortana:

you can use voice commands or you can type your commands from the Start
menu. Cortana can be utilized for basic search functions (e.g. weather), can
access users’ Google calendars, read Outlook emails, give travel time estimates,
3 https://fr.wikipedia.org/wiki/Amazon_Alexa
4 https://support.microsoft.com/en-us/help/17214/cortana-what-is

20

Chapter 2. Background

provide directions and integrate to OneNote to display user ratings.

2.3.10

Google assistant
Google Assistant5 is Google’s artificial intelligence announced at the Google I/O conference in May 2016. In line with Alexa,
the assistant created by Amazon, or Apple’s Siri, Google Assistant is not the first
attempt Google on the subject. Its predeces-

Figure 2.8: Google Assistant

sor, Google Now, already made it possible to
make requests via voice recognition on compatible devices. Google Assistant, unveiled in

2016, introduces a conversational dimension, the assistant being able to maintain
a dialogue with the user and understand natural language. It is able to recognize
up to six different voices and associate them with their respective Google account.
The Google Assistant is built into most Android 5.0 and above smartphones
and can communicate with the user via voice or IM-like interaction. It is also
found in the Google Home range, Google Allo, in some versions of Android Wear
Since then, Google has extended the presence of Google Assistant to its system
for connected watches, Wear OS by Google, and Android TV, its interface for
connected TV. The assistant manages simple requests (weather, day schedule
...), can answer questions, tell stories, or give information on traffic or opening
hours of shops or administrations.

2.3.11

Discussion

In this section, we provide a study of chatbots construction and enhancement
methods. We first introduce three chatbot designs like in [2] and [42], which are:
rule-based, retrieval-based and generation-based methods, followed by second
way of decomposing that is proposed in [47] and [4] they specify two categories
of conversation agents, namely task-oriented and non-task-oriented. Finally,
we present a comparative study conducted by authors in [51] in which they
rank eight chatbot according to their performance in i) Assessment of Factual
Questions, ii). Assessment of Conversational Attributes, and iii). Evaluation of
Exceptional queries.
5 https://assistant.google.com/explore

21

Chapter 2. Background

The image 2.9 explains the first proposed decomposition and gives some
example for each design.

Figure 2.9: Chatbot design

22

Chapter 2. Background

The second classification goal-oriented or non-goal-oriented is now presented.
• A goal-oriented system is one that is designed to help users achieve their
goals or complete a specific task in a specific domain such as making a
booking, education, healthcare, shopping, or ordering food. They are
focusing on developing natural language understanding (NLU) methods
which parse the utterance from the user into predefined semantic.
• A non-goal-oriented dialogue system provides users with the means to
participate in different domains such as a game, chitchat, or entertainment,
without providing the user the help to complete any task in a specific job.
An example of this system is the chatbot which chats with the user in a
similar way to a human and provides reasonable and relevant responses
ELIZA, PARRY.
Authors in [51] evaluated eight chatbots in the literature based on their performance in all the tests carried out, namely i) Assessment of Factual Questions,
ii) Assessment of Conversational Attributes and iii) Assessment of Exceptional
Queries. The results are as follows
Rank
1. Mitsuku
2. Google Assistant
3. Siri
4. A.L.I.C.E.
5. Rose
6. Jabberwacky
7. Machine Comprehension Chat Bot
8. Eliza
Table 2.3: Rank List [51]

Mitsuku performed the best on all three parameters. It provided appropriate
responses and scored better on all parameters than the other chatbots included
in the study. Mitsuku could access factual information about the query and it
was able to carry the conversation by starting new topics and handled insults
appropriately. Google Assistant was reasonably good in all the assessments viz
factual questions, conversational attributes, and exceptional queries. In factual
questions, it was quite descriptive. In conversational attributes, it conversed
23

Chapter 2. Background

well and was quite informative as it can surf the internet. And in exceptional
queries, its performance as well and ranked just below Mitsuki. Even though
Siri fared well in all the three parameters, it still lagged behind Google Assistant
and Mitsuku in the final averages. This underlines the fact that Siri is mainly
designed to be a virtual assistant and not a fully functional chatbot, which
explains its delay in the parameter "Ability of the chatbot to launch new topics".
ALICE fares well in all the metrics but lacking in the ability to access chat
history but like, Mitsuku, it performed the best in the Assessment of factual
questions parameters and satisfactorily in the Assessment of Exceptional Queries
parameter, as compared to other chatbots included in the study and below its
rank. Eliza, an early chatbot designed in 1966 at the MIT Artificial Intelligence
Lab, imitates a Rogerian Psychotherapist. A final comparative analysis founds
Eliza to be the weakest performing chatbot out of all the chatbots included in
this study.

2.4
2.4.1

Foundation of the Semantic Web
Concept of the semantic web

The current Web is a set of documents dedicated to humans, stored and manipulated in a purely syntactic way. So, the current Web cannot be manipulated in
an intelligent way by computer programs because they are human-oriented.
The growing interest in searching for information on the Web has given rise
to the Semantic Web initiative. The Semantic Web, also known as the Intelligent
Web, is a body of knowledge where all machines can semantically link data on the
Web, thus understanding their meanings, and access them more intelligently, to
improve the dialogue between applications and the interaction with the user by
providing a better quality of search tasks. It can also be seen as a supplementary
layer of knowledge above the current Web or an extension of the current Web.
To reach the goal of creating an intelligent web that will allow reporting
on semantics through the handling of the meaning of information through
ontologies... Ontologies propose semantic representations of knowledge that can
be manipulated by machines.
The main objective of ontologies is to provide the Web with a semantic layer
that ensures information retrieval at both the syntactic and semantic levels [66].

24

Chapter 2. Background

2.4.2

Ontology

Review of ontology definitions
The word ontology is the union of two terms ”onto” and ”logy”. The first term
”onto” (or ”ontif”) means ”I am”. The second term ”logy” (or ”logos”) is a Greek
suffix meaning ”science” or ”speech”. In the philosophical field, Aristotle defined
ontology as the science of Being [66].
For the past decade, computer scientists have been using the term "Ontology",
The definition proposed by Gruber 1993 in [21] "An ontology is an explicit
specification of a conceptualization".
One of the first definitions was given by [36] "An ontology defines the basic
terms and relations comprising the vocabulary of a topic area as well as the rules
for combining terms and relations to define extensions to the vocabulary".
In [56] "An ontology is a formal, explicit specification of a shared conceptualization"
• A ‘conceptualization’ refers to an abstract model of some phenomenon in
the world by having identified the relevant concepts of that phenomenon
• ‘Explicit’ means that the type of concepts used, and the constraints on
their use are explicitly defined.
• ‘Formal’ refers to the fact that the ontology should be machine-readable,
which excludes natural language.
• ‘Shared’ reflects the notion that an ontology captures consensual knowledge,
that is, it is not private to some individual, but accepted by a group.
Compostion
Despite the diversity of ontological models, they are based on the following main
concepts following [7]:
• Concepts (classes or entities).

A concept can represent a material

object, a notion or an idea. A concept can be divided into three parts:
one or more terms, a notion, and a set of objects. The intension contains
the semantics of the concept. It is expressed in terms of properties and
attributes, rules, and so on. and constraints. The set of objects is also
called an extension of the concept [66].

25

Chapter 2. Background

• Instances (individuals or objects). Constitute the extended definition/extension of concepts, they represent all the individuals in the ontology.
Instances can be linked by conceptual relations of identity and difference.
• Attributes (properties). Properties are used to define links for individuals in the domain of ontology. They describe and characterize instances
of ontology concepts with characteristic values or associations with other
concepts. annotation property, data property, object property.
• The relations. These are the defined associations between concepts in
the ontology, such as, for example, the "is-a" subsumption relationship
that is used to organize concepts into a hierarchy.
• Axiomes: The latter refer to statements and assertions accepted as true
in the field of ontology. They are used to verify the consistency of the
ontology and to infer new knowledge. they are entity-related assertions.
Instead of relying on entity labels and terms to convey semantics, the
designer of ontologies must constrain the possible interpretation of entities
through the judicious use of logical axioms to make their meanings much
more precise.

2.4.3

Representation languages

In the literature, several languages have been used for the description of ontologies.
These languages offer different levels of expressiveness [66].
• Extensible Markup Language[45] (XML). is a simple text-based
format for representing structured information: documents, data, configuration, books, transactions, invoices, and much more. It was derived from
an older standard format called SGML (ISO 8879), in order to be more
suitable for Web use.
It does not allow to impose semantic constraints on the meaning of the
described documents. An XML schema is a description of the type of
an XML document. The schema contains a set of rules. These rules are
constraints on the structure and content of the XML document. An XML
document must respect the XML schema dedicated to it in order to to
ensure the validity of the document according to its scheme. The DTD
(Document Type Definition) is used to define a grammar to check the

26

Chapter 2. Background

conformity of the XML document. The DTD and the XML schema are
developed to express XML schemas.
• Resource Description Framework (RDF) [30]. is an infrastructure
that enables the encoding, exchange, and reuse of structured metadata.
RDF additionally provides a means for publishing both human-readable
and machine-readable vocabularies designed to encourage the reuse and
extension of metadata semantics among disparate information communities.
To identify resources, RDF uses URIs (Uniform Resource Identifiers). RDF
declarations take the form of triplets : (i ) a subject designating the resource
to be described, (ii ) a predicate representing an attribute or a property
applied to the resource, and (iii ) an object representing the value of the
property. RDF triplets can be represented graphically through a graph
or described in XML. RDF has been extended by a set of manufacturers
giving rise to the RDF-Schéma (or RDFS) model.
• RDF scheme (RDFS) [14]. RDFS allows us to build concepts, possibly
defined from other concepts, shared on the web. RDFS expressions are
written in the form of RDF triplets. It provides mechanisms for the description of similar resources and the relationships between these resources.
The descriptions of the RDF scheme RDFS vocabulary are written in
RDF. The two RDF languages and RDF schema are referenced by RDFS.
The RDFS has mechanisms for the description of the resources and their
characteristics.
• Darpa Modeling Language of Ontology + Ontology Inference
Layer (DAML+OIL) [15]. is a semantic markup language for Web
resources. It builds on earlier W3C standards such as RDF and RDF
Schema and extends these languages with richer modeling primitives.
DAML+OIL provides modeling primitives commonly found in frame-based
languages. DAML+OIL (March 2001) extends DAML+OIL (December
2000) with values from XML Schema datatypes. DAML+OIL was built
from the original DAML ontology language DAML-ONT (October 2000)
in an effort to combine many of the language components of OIL. The
language has a clean and well-defined semantics this is a fusion between
two languages DAML and OIL. The Darpa Modeling Language of Ontology
aims to provide the foundation for the generation of the Semantic Web.
The language first adopted RDF / RDFS as an ontology language to
27

Chapter 2. Background

ensure semantic interoperability. As RDF(S) not sufficiently expressive,
with respect to the requirements of the future Web, a new language was
adopted named DAMLONT. The latter represents an extension of RDF(S)
with the capabilities of a knowledge representation language. In the same
period, a group of European researchers developed an ontology language
called OIL. This language has a syntax based on RDF. It has been built in
such a way that its semantics can be specified through a description. very
expressive logic.
• Ontology Web Language (OWL) [53].

It enriches the of the RDF

schema by defining more vocabulary for the description of complex ontologies. The OWL language is based on formal semantics denied by a
rigorous syntax. The OWL language is a language for the representation
of ontologies within the Semantic Web. It is an RDF-based language.
The OWL language is derived from the ontology language DAML+OIL.
OWL allows, in addition to RDF(S) primitives, relations between classes
(disjunction, intersection, union, etc.), equality, cardinality, etc. The OWL
language allows the definition of property types (object property, annotation property, data property), property characteristics, and enumerated
classes. The OWL ontology language is split into three sub-languages with
an ascending expressivity, namely: OWL-Lite, OWL-DL (Ontology Web
Language-Description Logic) and OWL-Full.

2.5

Finite State Machine

Finite State Machine have been used in the construction of conversational agents
workflow for example the work of [64], [1] and [43].
A finite state machine contains a finite number of states and produces outputs
on state transitions after receiving inputs. Finite state machines are widely used
to model systems in diverse areas, including sequential circuits, certain types of
programs, and, more recently, communication protocols.
A finite state machine contains a finite number of states and produces outputs
on state transitions after receiving inputs. Finite state machines are widely
used to model systems in diverse areas, including sequential circuits, certain
types of programs, and, more recently, communication protocols. In the 1960s
and early 1970s, several researchers proposed models to explain the rhythmic
turn-taking patterns in human conversation. In particular, Jaffe and Feldstein
28

Chapter 2. Background

(1970) studied the mean duration of pauses, switching pauses (when a different
speaker takes the floor), simultaneous speech, and (singlespeaker) vocalizations
in recorded dyadic conversations. Based on their observation that these durations
follow exponential distributions, they proposed first-order Markov models to
capture the alternation of speech and silence in the dialog. Their initial model
had four states: only participant A is speaking; only participant B is speaking;
both participants are speaking, and neither participant is speaking. However,
such a model fails to distinguish switching pauses from A to B from switching
pauses from B to A. Based on this observation, they extend their model to a
six-state model which they found to better fit their data than the four-state
model. Around the same time, Brady (1969) developed a very similar six-state
model. He trained the parameters on a recorded conversation and compared the
generated conversations to the original real one along several dimensions (pause
and speech segment durations, overlaps, etc), finding that his model generally
produced a good fit of the data [43].

2.6

Conclusion

This chapter presented the key fundamental concepts that are related to the
creation of our chatbot. The next chapter will explain each component of the
chatbot architecture apart.

29

Chapter 3

Chatbot Architecture
Contents
3.1

Introduction

. . . . . . . . . . . . . . . . . . . . . .

31

3.2

Architecture Components . . . . . . . . . . . . . .

31

3.3

3.2.1

Ontology . . . . . . . . . . . . . . . . . . . . . . . .

32

3.2.2

Web scaping . . . . . . . . . . . . . . . . . . . . . .

35

3.2.3

Database . . . . . . . . . . . . . . . . . . . . . . . .

36

3.2.4

State Machine

. . . . . . . . . . . . . . . . . . . . .

37

3.2.5

Keyword Extraction . . . . . . . . . . . . . . . . . .

40

3.2.6

Trained Chatbot . . . . . . . . . . . . . . . . . . . .

41

3.2.7

User Interface . . . . . . . . . . . . . . . . . . . . . .

42

Conclusion

. . . . . . . . . . . . . . . . . . . . . . .

30

42

Chapter 3. Chatbot Architecture

3.1

Introduction

This chapter will be devoted to the presentation of a new architecture that
integrates an Ontology, a Finite State Machine, a trained Chatbot and several
other modules that contributed to the construction of our chatbot.

3.2

Architecture Components

Following this architecture in Figure3.1, we are going to implement an intelligent
chatbot support system for the COVID-19 virus, that will provide an effective
response to user’s queries. Our conversational system is a mixed system, the
response provided to the user can be generated either by information retrieved
from the ontology or by a trained bot.

Figure 3.1: Reference Architecture
As for the programming language of our chatbot we decided for Python.

31

Chapter 3. Chatbot Architecture

3.2.1

Ontology

We offer Corona Virus Infection Ontology (CVIO) which covers concepts related
to COVID-19 virus such as countries that have COVID-19 infection, global data,
and symptoms.
To build such an ontology we used existing biomedical ontologies, we started by
analyzing Human Disease Ontology (DOID) which provides disease information
and Symptom Ontology (SYMP) which provides different symptoms of a certain
type. They are published in BioPortal, one of the exceptional references, the
world’s largest online ontology repository hosting more than 450 biomedical
ontologies and more than 6 million classes that define the terms [39] . Indeed,
biomedical ontologies are becoming increasingly important in order to provide an
effective representation of knowledge to support the diagnostic process. The next
step is to define a global ontology that contain both disease and symptoms. Then
we added other concepts like global data and the current state of contamination.
The ontology engineering process spans different stages, below we will explain
these stages one by one.
1. Knowledge acquisition. Data is collected via different sources from the
web through web scraping and articles related to coronavirus infection
such as [62] from which we extract the main symptoms.The following table
presents the symptoms in decreasing order of the percentage of appearance
for the patients (there are others but with small percentage).
Symptom
Fever
Fatigue
Dry cough
Myalgia
Dyspnea

Percentage
98,6%
69,6 %
59,4 %
34,8 %
31,2 %

Table 3.1: The main symptoms of COVID-19

2. Competency Questions (CQs.) After data acquisition, the first step
towards developing the ontology is to define the vital questions that an
ontology must answer. In the proposed project, for example, the competency questions can be: “Does Fever is a COVID-19 symptom?”, “Which
32

Chapter 3. Chatbot Architecture

countries have COVID-19 infection?” etc.
3. Concepts. Next step, is to define concepts, which concepts are necessary
to answer the previous predefined questions. A concept is the basic building
of an ontology, which can be designed as a set of individuals.
4. Properties. The last step in the ontology engineering process is to define
the properties, properties of the concepts, properties of individuals, and
properties between individuals.
The hierarchy of our ontology is presented in Figure3.2.

Figure 3.2: Class Hierarchy of CVIO

Classes::
• Country. a concept that brings together countries that have COVID-19
infection;
• Global data. a concept that represents the current status of the world;
• Infection.
– Current status. a concept that represents the basic information
about the state of the contamination of each country;
– Trend. a concept that represents trend for Covid-19 contamination.
In our case, we manage a weekly trend which can be "weekly trend:
increasing / decreasing";
33

Chapter 3. Chatbot Architecture

• Region. a concept that contains the individual "world" which has a current
status but it is not a country. Region is disjoined with the Country;
• Symptom. a concept that contains symptoms extracted from [62] ;
• RelatedWord. This class contains words related to COVID-19, it helps
to manage the dialogue. When we find one of these words in the user’s
query, we know that the user is requesting general information regarding
COVID-19 infection worldwide.
Properties ::
• Data property. is applied to each individual in current status concept.
Cases (represent the total number of COVID-19 infected person), Recovered (represent the number of recovered people), Deaths (represent
the number of deaths) and Retrieved (represent the date on which this
information are retrieved). The domain of the properties is current status
concept or even Infection.
• Object property. is applied between two individuals. In our ontology
we defined two object properties Region and Country. For example:
Tunisia_Status Country Tunisia.
• Annotation Property. is a property and can be applied to every thing.
In our ontology we defined Has Synonym used for symptom individuals,
Creator and Creation date for the ontology and Data Source and
Data Publisher for information in current Status individuals.

34

Chapter 3. Chatbot Architecture

Figure 3.3: Example of an individual
Figure 3.3 shows an example of a current status individual tunisia_status
which has the object property (Country), the data properties (Cases, Recovered,
Deaths, Retrieved) and Annotation properties (Data Source, Data Publisher).

3.2.2

Web scaping

Figure 3.4: Web scraping technique
The ontology is populated with data from a web site, which is continuously
updated, in this case, we need to apply web scraping techniques. Web scraping
is defined as: "a tool for turning the unstructured data on the web into machinereadable, structured data which is ready for analysis"1 .
The source of the data must be a very reputable website to guarantee the
correctness of information populated to the ontology, also if the page is not
stable enough the crawler won’t work anymore. For this we choose to scrap data
from google but crawling was not allowed, so we scraped data from wiki site2 in
which coronavirus table is referred by google site3 . The website we are going to
1 https://www.freecodecamp.org/news/better-web-scraping-in-python-with-seleniumbeautiful-soup-and-pandas-d6390592e251/
2 https://en.wikipedia.org/wiki/COVID-19_pandemic
3 https://google.com/covid19-map/?hl=en

35

Chapter 3. Chatbot Architecture

Figure 3.5: Current status of different country
use contains a table in which there is the current status of every country that
has covid-19 infection shown in the Figure3.5. To do so, we used libraries such
as BeautifulSoup which is a package for parsing HTML and XML documents.
It creates parse trees that are helpful to extract the data easily and Selenium
which is a web testing library. It is used to automate browser activities. Finally,
data retrieved are stored in a local database and arranged by retrieval date.

3.2.3

Database

Added to the ontology which stores the most recent retrieved data, we store the
data in a local database. The use of a DBMS (Database Management System),
that is requested anytime the amount of the information you deal with becomes
relevant. Using a file (in XML format in this case) is unreliable and not practical
at all. In concrete, a database is requested because:
PERFORMANCE. The size of the ontology will increase quite soon if we
store all the data retrieved on it. So the idea is to only keep the most recent
status (e.g. today’s data concerning infections) in the ontology and the computed
info (component 6 in the architecture), i.e. “Weekly trend: decreasing”, “Weekly
trend: increasing”. Raw data will ONLY be stored in the database.
COMPUTATIONS. Performing computations on semantic data, even with
the support of SPARQL (the equivalent of SQL for semantic data), can be a
nightmare once the algorithm is not obvious, while it is relatively simple on raw
data stored in a common format.
DATA CONSISTENCY. The retrieval components and the Chatbot have
different status. Updating the ontology means to update the reasoner status
too. It is advisable to keep the database in the middle to assure flexibility and
36

Chapter 3. Chatbot Architecture

independent behaviors.

3.2.4

State Machine

In this section, we are going to describe the engine of our COVID Assistant
which is a state machine. In order to model dialogues, we made 6 states and
defined 9 transitions using a python library. When our system is initialized,
it enters ‘Start’ state. The structure of the state machine is presented in the
Figure3.6.

Figure 3.6: State Machine Structure

37

Chapter 3. Chatbot Architecture

• Start. It represents the initial state, in which the chatbot will present
itself in a fun and informative way. The user has the right to know whether
he is speaking with a real person or with a bot. For this, the welcome
message must clearly indicate that the customer is chatting with a chatbot.
In addition, the chatbot gets the name of the user.
• Discovery. Discovery state is the state in which the user types the
input/request. Then, a keyword extractor is applied (RAKE) in our case.
It extracts the keywords from the user input and sorts them by order of
importance.
• Classification. We go now to the classification state where we iterate
the list of keywords, and we try to understand the user request. In this
state, we manage four classes. First, when the user request contains the
name of a specific country. In this case, we understand that the user wants
to get information about the current state of this country, Then we pass
to the confirmation state. Second, the request may contain the name of
a symptom of covid-19, so we can provide him with a list of the most
common symptoms. The third classification is that the user would like
to know about global data something like the current state of the world
in this case, he just has to type any word related to COVID-19. The last
type of classification is that we don’t know what the user is talking about,
it can be a welcome message, a goodbye or a general conversation, in this
case, we forward the request to the TrainedBot state.
We store the keyword, after classification, in our context variable except
the last type so we can respond appropriately.
• TrainedBot. The purpose of the Trainedbot state is to try to get the user
to speak when we don’t understand him. Hopefully, we can find a keyword
in the next entry. In this case, an automatic response is generated.
• Confirmation. If the state machine is in the Confirmation state, this
means that we have found a country name, we send a message asking for
user confirmation. If the answer is "no", we return to the Discovery state,
otherwise we go to the Ontology state.
• Ontology. The ontology state is the final state in which, depending on
the value we have in the context variable. We extract the appropriate
information from the ontology and, finally, the user obtains the response
to his request.
38

Chapter 3. Chatbot Architecture

Now we will describe the meaning of each transition apart:
• Conversation Starts. This transition executed once the system obtains
the user’s name, at that point the conversation will start.
• Get Type. After getting input from the user "Get Type" transition will
be executed in order to understand the user’s request.
• Get Response2. When the system is in "Classification State", it has
three possibilities, one of them is "Get Response2" which means the user
wants information either about symptoms or about COVID-19 general
information.
• Need Confirmation. The second possibility, is when the user request
contains one or more country names, so the "Need Confirmation" transition
is executed to pass the system into the "Confirmation State".
• keep Speaking. Otherwise, the "Keep Speaking" transition is executed,
this transition exchanges the current status of the system and executes the
"Trained Bot" state.
• New Request. This transition is executed when the chatbot has already
answered the user and let him type a new request.
• Get Response1. If the system gets a positive confirmation result it means
that the country name it has is correct. So, this transition exchanges the
current state of the system to the "Ontology" state.
• Not Confirm. This transition means that the system gets negative
confirmation, so this transition will go to the "Discovery" state where the
user can type another request.
• Go Discovery. This transition has a similar functionality as "New Request". The source state of the transition is the only difference between
the two.
The state machine module is developed with a state machine library, access to
the ontology data is done with owlready2.

39

Chapter 3. Chatbot Architecture

3.2.5

Keyword Extraction

In this section, we will explain how we extract the keywords from our input.
Keyword extraction (also known as keyword detection) is a text analysis technique
that is concerned with the automatic extraction of a set of terms or phrases within
unstructured text. This includes emails, social media posts, chat conversations
and any other types of data that are not organized in any predefined way.
This task is commonly used for information retrieval, text mining, summarizing,
and other text analysis tasks. The conventional method for extracting keywords
is the TD-IDF measure, which targets words that frequently appear in one
document in a corpus but rarely appear in the rest of the corpus.
There are different techniques you can use for automated keyword extraction:
statistical approaches, Linguistic Approaches, Graph-based Approaches, Machine
Learning Approaches.
We choose a statistical approach, Rapid Automatic Keyword Extraction (RAKE)
is a well-known keyword extraction method that uses a list of stopwords and
phrase delimiters to detect the most relevant words or phrases in a text. RAKE
was developed by Rose, Engel and Cramer [45] as an alternative to corpus-based
keyword extraction methods. Unlike traditional methods that compare word
frequencies, RAKE operates on the premise that keywords and key phrases
do not overlap with stopwords, and that the more non-stop words are found
adjacent to each other, the higher the probability that it is a keyphrase [32].
• Candidate keywords. To produce the list of candidate keywords/phrases,
the first thing the method does is splitting the text into a list of words and
remove stopwords from that list. This returns a list of what is known as
content words. Candidates do not include phrase delimiters or stopwords.
• Co-occurrence graph. Once the candidate keywords are chosen, a cooccurrence graph is built to identify the frequency that words are associated
together in those phrases.
• keyword scores. After that graph is built, words are given a score. That
score is calculated for each individual word as the degree (number of times
it appears + number of additional words it appears with) of a word divided
by its frequency (number of times it appears), which weights towards longer
phrases. The expressions are also given a score, which is computed as the
sum of the individual scores of words.

40

Chapter 3. Chatbot Architecture

• Adjoining keywords. If two keywords or phrases appear together in the
same order more than twice, a new key phrase is created, regardless of how
many stop words the key phrase contains in the original text. The score of
this key phrase is calculated as the score of a single key phrase.
• Extracted keywords. The top T keywords are then extracted from the
content, where T, According to the original paper [45] is one-third of the
number of words in the graph

3.2.6

Trained Chatbot

For general conversation management, we integrated a trained chatbot component
in our architecture. This component implements Chatterbot.
ChatterBot is a machine-learning
based conversational dialog engine
build in Python which makes it possible to generate responses based on collections of known conversations. The
Figure 3.7: ChatterBot

language independent design of ChatterBot allows it to be trained to speak

any language. It uses a selection of machine learning algorithms to produce
different types of responses.
ChatterBot comes with a data utility module that can be used to train
chatbots. At the moment there is training data for over a dozen languages in
this module. These modules are used to quickly train ChatterBot to respond
to various inputs. Thus, it is trained with different packages such as greetings,
gossip, history, etc. as shown in Figure3.8.

41

Chapter 3. Chatbot Architecture

Figure 3.8: Training Packages

3.2.7

User Interface

The last component in our architecture is the user interface (UI), which a very
important one and has a great impact on the usability of the chatbot.
Customers will likely abandon your chatbot if it can’t keep up with them
or is too frustrating to use. Putting careful thought into your chatbot’s user
interface is the first step to avoiding this.

3.3

Conclusion

In this third chapter, we discussed the architecture of Covid-19 Assistant and in
the next chapter, we will describe the conceptual study and the implementation
details.

42

Chapter 4

Conceptual study and
Implementation
Contents
4.1

Introduction

. . . . . . . . . . . . . . . . . . . . . .

44

4.2

Conceptual study . . . . . . . . . . . . . . . . . . .

44

4.3

4.4

4.2.1

Static view . . . . . . . . . . . . . . . . . . . . . . .

44

4.2.2

Dynamic view . . . . . . . . . . . . . . . . . . . . . .

45

Implementation

. . . . . . . . . . . . . . . . . . . .

51

4.3.1

Python . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.3.2

Protégé . . . . . . . . . . . . . . . . . . . . . . . . .

51

4.3.3

MySQL/ MySQL Workbench . . . . . . . . . . . . .

52

4.3.4

StarUML . . . . . . . . . . . . . . . . . . . . . . . .

52

4.3.5

Uppaal

53

4.3.6

Python libraries

Conclusion

. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . .

43

53
54

Chapter 4. Conceptual study and Implementation

4.1

Introduction

After the analysis and specification of our system, we dedicate this chapter to
conceptual study. This design phase has great importance in our development
cycle and whose objective is to create a robust, well structured, and scalable
system. The second part of this chapter will be devoted to the implementation
where the technical specification will be discussed.

4.2

Conceptual study

The modeling of our project was based on the Unified Modeling Language
(UML).

4.2.1

Static view

In this part, we start by designing the general use case diagram. This use case
diagram (UCD) is a UML diagram used to express user needs. In other words,
it allows us to give a global vision of the functioning of the chatbot.

Figure 4.1: General use case diagram
44

Chapter 4. Conceptual study and Implementation

In the case of our chatbot, a user can be, an internet user, who will ask the
chatbot for information, namely the state of contamination of COVID-19 in the
world Figure 4.1 illustrates the general use case diagram that allows us to see
the functionality provided to our actor.
Action
Start

Covid-19
Symptom
Country
General Conversation

Description
This service represents the initial state of our chatbot. It
lets the user know that he is talking to a chatbot while
giving him the illusion that he is talking to a human
assistant.
Then the user must enter his name in the chatbot to go
to the next state.
Once the knowledge step is done: the user can request
to know what is Corona Virus? or the current state of
contamination of Corona Virus infection in the world.
To know the different symptoms of COVID-19:
the user just needs to type in the request the word symptom or any symptom of Coronavirus.
To know the contamination status of a specific country:
the user has to enter the name of the country or the name
of any city it contains.
This state will be visited if the user enters a request that
does not contain any keyword that the chatbot might
know.
So the trained chatbot will respond.

Table 4.1: General Use Case Diagram Table

4.2.2

Dynamic view

The dynamic axis in our design will be represented by sequence diagrams. These
diagrams are the graphic representation of the interactions between the actors
and the system in chronological order. A sequence diagram describes a scenario
of a use case. In the following, we will detail the different diagrams:

45

Chapter 4. Conceptual study and Implementation

Sequence diagram "Get started"
This sequence diagram represents the procedure of getting started to talk with
the chatbot. Once the user opens the chat application the chatbot begins by
sending welcome message and introducing himself. Then he asks the user for his
name, if the user answers it in a good way it retrieves the name, else, it re-send
an example of the way he must answer with. To represent this we used a loop
and alternative (alt) fragments.

Figure 4.2: Management of name retrieval

Sequence diagram: "Managing a request for a country name (version
1)"
To search for information about a specific country the user has to type the name
of a country or a city that it contains like in the example. The user didn’t
type Tunisia but he types the capital name Tunis. The keyword, in this case,
is "Tunis", then in the classification state, the system will associate "Tunisia"
to "Tunis" automatically. Once a country name is found the chatbot will ask
the user for the confirmation. To represent it we use a loop and an alternative
46

Chapter 4. Conceptual study and Implementation

fragment, at this stage the user has to type "yes" or "no" if he types anything
else, the chatbot re-send to him the confirmation message.

Figure 4.3: Management of a country request (version 1)

Sequence diagram: "Managing a request for a country name (version
2)"
In this second version of managing a request for the country information, the
user types a message that contains more than one country name. In this case,
after recognizing the country names in the classification state, the chatbot will
send to the user the list of country names and the user has to choose one of
47

Chapter 4. Conceptual study and Implementation

them by typing the number of the name in the list. Until a correct number is
typed the system will still in the loop and alternative frame. Once a correct
number is entered the system pass to the ontology state and sends to the user
the appropriate answer.

Figure 4.4: Management of a country request (version 2)

48

Chapter 4. Conceptual study and Implementation

Sequence diagram: "Managing a request of covid-19 general information"

Figure 4.5: Management of COVID-19 request

Sequence diagram: "Managing a request related to COVID-19 symptoms"

Figure 4.6: Management of symptom request
In the Sequence diagram "Managing a request related to COVID-19 symptoms" and Sequence diagram "Managing a request of COVID-19 general informa49

Chapter 4. Conceptual study and Implementation

tion" the same procedure is required. The first step, of course after passing the
start state, the user types a message that contains a keyword related either to
COVID-19 in general or a name of a symptom. The discovery state will extract
keywords then the classification state will recognize the type of this keywords.
Finally, the system passes the type detected to the ontology state which provides
the appropriate response to the user.
Sequence diagram: "Managing a general conversation"

Figure 4.7: Management of general talk request
Two types of messages lead the conversation to do this interaction, either
the user types a message like in the example shown that do not contain any
keyword or it contains keywords that the system can’t classify it. So, it passes
the message to a trained bot that is trained to answer the general conversations.

50

Chapter 4. Conceptual study and Implementation

4.3
4.3.1

Implementation
Python
Python1 is an interpreted, multi-paradigm, multiplatform programming language designed by Guido
van Rossum in February 20, 1991. It supports structured, functional, and object-oriented imperative
programming. It has strong dynamic typing, au-

Figure 4.8: Python

tomatic garbage collection memory management,
and exception handling, making it similar to Perl,
Ruby, Scheme, Smalltalk, and Tcl. In our chatbot,

we used python 3.5 version. We used anaconda2 as it is a free and open-source
distribution, applied to perform data science and machine learning applications,
with over 20 million users worldwide.

4.3.2

Protégé
Protégé3 plug-in architecture can be adapted to
build both simple and complex ontology-based applications. Developers can integrate the output of
Protégé with rule systems or other problem solvers
to construct a wide range of intelligent systems.

Figure 4.9: Protégé

To visualize our ontology we used OWLViz which
Enables class hierarchies in an OWL ontology to
be viewed and incrementally navigated, allowing

comparison of the asserted class hierarchy and the inferred class hierarchy.

1 https://www.python.org
2 https://www.anaconda.com
3 https://protege.stanford.edu

51

Chapter 4. Conceptual study and Implementation

4.3.3

MySQL/ MySQL Workbench
MySQL4 is the world’s most popular open-source
database. Despite its powerful features, MySQL is
simple to set up and easy to use. MySQL Workbench5 is a unified visual tool for database architects,
developers, and DBAs. MySQL Workbench enables
a DBA, developer, or data architect to visually de-

Figure 4.10: MySQL

sign, model, generate, and manage databases. It includes everything a data modeler needs for creating
complex ER models, forward and reverse engineer-

ing, and also delivers key features for performing difficult change management
and documentation tasks that normally require much time and effort.

4.3.4

StarUML
StarUML6 is a sophisticated software modeler aimed
to support agile and concise modeling. It is a UML
modeling software, which has been released as open
source by its publisher, at the end of its commercial
exploitation (which obviously continues. . . ), under
a modified license of GNU GPL. Today the ver-

Figure 4.11: StartUml

sion StarUML V3 exists only in proprietary license.
StarUML supports most of the diagrams specified

in the UML 2.0 standard. StarUML is written in Delphi, and it depends on
proprietary which is non open-source Delphi components.

4 https://www.mysql.com
5 https://www.mysql.com/fr/products/workbench/
6 http://staruml.io

52

Chapter 4. Conceptual study and Implementation

4.3.5

Uppaal
Uppaal is a toolbox for verification of realtime systems jointly developed by Uppsala
University and Aalborg University. It has
been applied successfully in case studies ranging from communication protocols to mul-

Figure 4.12: Uppaal

timedia applications. The tool is designed
to verify systems that can be modelled as
networks of timed automata extended with

integer variables, structured data types, user defined functions, and channel
synchronisation.

4.3.6

Python libraries

Library
pycountry
geocoder
tkinter
chatterbot
rake-nltk
state-machine
graphviz
owlready2
beautiful soup
selinum
folum

Description
This python library is used in the Classification state. It is
capable of returning a country name from a city name.
This library helped us is the creation of the data visualisation
(Covid-19 map). It provides the location of a given country
The User Interface component is created with tkinter library.
We used chatterBot because of it’s ability to respond to general
conversations.
Rake is used in Discovery state, in which our chatbot tries to
understant the request of the user by extracting the important
keywords.
This library is the engine of our chatbot. The state machine
describes the workflow of the system.
This library is used to visualize the state machine.
Owlready2 makes the management of the ontology simple. It
enables the creation, the removal of individuals.
This library makes HTML code easy to be scrapped.
This library is used to automate web browser interaction from
Python.
This library is used to visualize the data on the Covid-19 map.
Table 4.2: List of Python libraries

53

Chapter 4. Conceptual study and Implementation

4.4

Conclusion

In this chapter, we have described our design as well as our working environment.
The next chapter will be devoted to the experiment and a validation step.

54

Chapter 5

Result
Contents
5.1

Introduction

. . . . . . . . . . . . . . . . . . . . . .

56

5.2

Execution . . . . . . . . . . . . . . . . . . . . . . . .

56

5.3

Validation . . . . . . . . . . . . . . . . . . . . . . . .

61

5.4

5.3.1

Ontology . . . . . . . . . . . . . . . . . . . . . . . .

61

5.3.2

State machine . . . . . . . . . . . . . . . . . . . . . .

62

Conclusion

. . . . . . . . . . . . . . . . . . . . . . .

55

65

Chapter 5. Result

5.1

Introduction

This chapter of experiments will allow us to see the execution of our chatbot
which proved its efficiency, and capability of maintaining a conversation while
generating good quality responses to the user. The second part of this chapter
will be devoted to a validation process in which we validated the ontology and
the state machine components.

Figure 5.1: Covid Assistant

5.2

Execution

In this part we will present some examples of conversation scenarios that can
be modeled between the Chatbot and the user. These scenarios are proved to
be compatible with the conceptualization defined above. The figures bellow
show how our Chatbot react. Its response shows its capability of creating a
conversation having a human aspect.
Use case shown in Figure 5.2 corresponds to sequence diagram: "Get
started" in which the chatbot manage the name retrieval task and the Sequence
diagram: "Managing a request of covid-19 general information" respectively.

56

Chapter 5. Result

Figure 5.2: Example 1 and 2
As the user asks about covid-19 general information the chatbot provides to
him: what is covid-19 pandemic?, Numbers that represent the current status of
contamination in the world and a Covid-19 Map. The map will be explained in
the next section.
Data Vizualisation
Data visualization techniques are applied to provide a visual represntation of
the data we have. Thanks to libraries like folium which is used here to create
a COVID-19 map of contamination distributions. Also we used pycountry and
geocoder libraries to create this attractive and informative map.

57

Chapter 5. Result

Figure 5.3: Covid-19 Map
Data scraped from the web can be viewed as an interactive visual representation, so we create an attractive and informative map of certain numbers
that shows the Covid-19 distributions around the world. When the user asks
about global data, the response of our Covid-19 assistant will be like in a specific
country use case, a message that contains: the total number of cases, the number
of deaths, recovered people and an interactive map, which we called Covid-19
Map 5.3.
This second map, Figure 5.4, represents an example of data for a specific
country, Tunisia, the user then can
zoom in the principal map to see details about the current status of each
country apart. Maps make the visualization of available data more effectively. It displays the geographical related data and presents the matching
information on the map, this kind of
information expression is clearer and it
will be eye-catching. We can visually
see the distribution or proportion of

Figure 5.4: Current Status of Tunisia

data in each region.
58

Chapter 5. Result

Now we illustrate in this example, Figure 5.5 how the Chatbot answers a
request of information concerning symptoms which is designed by Sequence
diagram: "Managing a request related to covid-19 symptoms". When
the system extracts a word that matches with corona virus symptoms it responds
by listing the principal symptoms that are stored in the ontology and their
synonyms. Figure 5.5 represents also the scenario of Sequence diagram:
"Managing a request for a country name (version 2)" is executed.

Figure 5.5: Example 3 and 4
The next Figure 5.6 represents scenarios explained in Sequence diagram:
"Managing a request for a country name (version 2)" and Sequence
diagram: "Managing a general conversation".

59

Chapter 5. Result

Figure 5.6: Example 5 and 6

60

Chapter 5. Result

5.3

Validation

The objective is that the chatbot delivers answers to citizen’s questions. This
developed chatbot has reached this objective as seen in the example of executions
in the first part. Now we will move on to validation two principal components of
the chatbot architecture which are the ontology, our knowledge base, and the
finite state machine, the engine of the chatbot.

5.3.1

Ontology

It should be noted that the validation of ontologies is a central question in knowledge engineering. It revolves around two complementary issues: i ) structural
validation and ii ) semantic validation [44].
Structural validation
• Validation of consistency using PELLET
To validate our ontology we used PELLET reasoner. The choice of the
PELLET reasoner to validate the consistency of our ontology was a natural
one, given that we are using the Protégé 5.5.0 ontology editor in which it
is integrated. PELLET thus allowed us to verify that our ontology did not
contain contradictory classes to lead to an inconsistency state.
Validation of semantics: Suitability for the modeled domain
• This stage brings into play communication aspects between actors from
different areas of expertise: ontologists and specialists in the domain
modeled in ontology. In our case the ontology is a functional component
which organizes and integrates data in a way that is directly usable by the
chatbot as an unique source. So, if our use cases are supported by the
chatbot, then, the ontology is validated.

61

Chapter 5. Result

5.3.2

State machine

To validate the engine of the chatbot we used a model checker. Model checker
or property controller is a method of checking whether a finite state machine of
a system satisfies a given specification or accuracy.
In an attempt to solve such a problem algorithmically, both the finite state
machine of the system and its specification are formulated in a precise mathematical language. For this purpose, we used the Uppaal model checker. Uppaal is a
toolbox for validation (by graphical simulation) and verification (by automatic
model verification) of real-time systems.
The requirement specification must be expressed in a formally well-defined
and machine readable language. Uppaal uses a simplified version of CTL. We
first create our state machine as shown in the Figure 5.7. we will start by

Figure 5.7: Model desinged
demonstrating the sequential composition of the model and then demonstrate
the parallel composition
Sequential Composition:
For our model we are going to check reachability, safety, and liveness properties.
• Reachability Properties. are the simplest form of properties. They ask
whether a given state formula, ϕ, possibly can be satisfied. Does there
exist a path starting at the initial state, such that ϕ is eventually satisfied
along that path. we use the formula: E<> Chatbot.Ontology to verify
62

Chapter 5. Result

if the Ontology state is reachable. We did the same thing with all other
states.
• Safety Properties. are on the form: “something bad will never happen”.
We used this formule E<> (Chatbot.Ontology or Chatbot.TrainedBot)
to grantee there should exist a maximal path such that a response is always
generated to the user.
• Liveness Properties. are of the form: something will eventually happen,
We check that the system is deadlock-free with the property A[] not
deadlock
All the properties previously discussed are shown in the Figure 5.8.

Figure 5.8: Properties Verification

Parallel Composition:
For checking the parallel aspect in our chatbot we have created two instances
of the system: chatbot and chatbot2. We will check that the user will always
get a result either from the ontology or through the TrainedBot. To do this,
the following three formulas are created i ) there is an execution of the system
that allows us to put the first instance "chatbot" in the Ontology state and
the second instance "chatbot2" in the TrainedBot state through the formula
"E<> ( chatbot.Ontology and chatbot2.TrainedBot)". ii ) there is a system execution that puts the first instance "chatbot" in the TrainedBot state
63

Chapter 5. Result

and the second instance "chatbot2" in the Ontology state using the formula
"E<> ( chatbot.TrainedBot and chatbot2.Ontology)". iii ) there is an
execution of the system which allows to put the two instances in the Ontology
state because, the chatbot has a read-only access to the ontology so two simultaneous accesses does not generate a problem "E<> ( chatbot.Ontology and
chatbot2.Ontology)". We can clearly see from the image 5.9 that all these
rules are marked in green so validated.

Figure 5.9: Parallel verification
We will then access the simulator integrated into Uppaal, to see how the two
instances of chatbot work. As shown in Figure 5.10(1) the first instance is in
the Ontology state and the second is in the TrainedBot state (this is the rule
(i ) defined before). In Figure 5.10(2) both instances of the system are in the
Ontology state (this is the rule (iii )).

64

Chapter 5. Result

Figure 5.10: Simulated execution

5.4

Conclusion

In this chapter, We have illustrated the chatbot use by simulating some examples
of conversations. Finally, we validate both the ontology and the state machine.
The next chapter will summarize the content of all previous sections to recap
what has been accomplished. It will give a global view of the completed system
as well as providing pointers for future developments.

65

Chapter 6

Conclusion and futur work
In this master thesis, we have made a chatbot with a new and innovative
architecture which integrate several component, which are not integrated in this
way before. The objective of our chatbot was to support citizens in emergency
situations, and provide to them correct information and 24 hours of availability.
With the rapid advancement of technology, chatbots have become increasingly
important in various domains. They are a big step forward in enhancing human
computer interactions. Below I summarize the most important steps in the
creation of our conversational agent.
1. We created an ontology-driven chatbot;
2. We populated the ontology using web scraping technique;
3. Then we designed our use cases;
4. We implemented the state machine;
5. We integrated a trained chatbot;
6. We created the data visualization module;
7. And finally we added the user interface.
Although all research has been done in a careful manner, some limitations
must be taken into consideration, our future perspective to ameliorate our
chatbot are described below.

66

Chapter 6. Conclusion and futur work

6.1

Futur work

Universal chatbot:
We aim to develop a universal chatbot, to reach this, in the future we will make
it support many other languages.
Make it smarter:
To make our Covid-19 smarter we think about using more efficient NLP procedure,
integrate a more sophisticated trained bot. Also we aim to apply voice recognition
techniques.
More Informative
To do so, the first step is to enrich the ontology with more information, such as
trends and advises.

67

Bibliography
[1] Gregory D Abowd, Hung-Ming Wang, and Andrew F Monk. A formal
technique for automated dialogue development. In Proceedings of the 1st
conference on Designing interactive systems: Processes, practices, methods,
& techniques, pages 219–226, 1995.
[2] Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah
Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade,
Yifeng Lu, et al. Towards a human-like open-domain chatbot. arXiv preprint
arXiv:2001.09977, 2020.
[3] Hadeel Al-Zubaide and Ayman A Issa. Ontbot: Ontology based chatbot.
In International Symposium on Innovations in Information and Communications Technology, pages 7–12. IEEE, 2011.
[4] Ebtesam H Almansor and Farookh Khadeer Hussain. Survey on intelligent
chatbots: State-of-the-art and future research directions. In Conference
on Complex, Intelligent, and Software Intensive Systems, pages 534–543.
Springer, 2019.
[5] Duygu Altinok. An ontology-based dialogue management system for banking
and finance dialogue systems. arXiv preprint arXiv:1804.04838, 2018.
[6] Sarra Ayouni, Sadok Ben Yahia, and Anne Laurent. Extracting compact
and information lossless sets of fuzzy association rules. Fuzzy Sets and
Systems, 183(1):1–25, 2011.
[7] Okba Barkat. Utilisation conjointe des ontologies et du contexte pour la
conception des systèmes de stockage de données. PhD thesis, 2017.
[8] Sadok Ben Yahia and Engelbert Mephu Nguifo. Emulating a cooperative
behavior in a generic association rule visualization tool. In 16th IEEE
68

Bibliography

International Conference on Tools with Artificial Intelligence, pages 148–
155. IEEE, 2004.
[9] Sadok Ben Yahia and Engelbert Mephu Nguifo. Revisiting generic bases of
association rules. In International Conference on Data Warehousing and
Knowledge Discovery, pages 58–67. Springer, 2004.
[10] Vyas Ajay Bhagwat. Deep learning for chatbots. 2018.
[11] Ines Bouzouita, Samir Elloumi, and Sadok Ben Yahia. GARC: A new
associative classification approach. In International Conference on Data
Warehousing and Knowledge Discovery, pages 554–565. Springer, 2006.
[12] Hanen Brahmi, Imen Brahmi, and Sadok Ben Yahia. OMC-IDS: At the crossroads of OLAP mining and intrusion detection. In Pacific-Asia Conference
on Knowledge Discovery and Data Mining, pages 13–24. Springer, 2012.
[13] Imen Brahmi, Sadok Ben Yahia, and Pascal Poncelet. MAD-IDS: Novel
intrusion detection system using mobile agents and data mining approaches.
In Pacific-Asia Workshop on Intelligence and Security Informatics, pages
73–76. Springer, 2010.
[14] Dan Brickley, Ramanathan V Guha, and Andrew Layman. Resource description framework (rdf) schema specification. 1999.
[15] Dan Connolly. Daml+ oil (march 2001) reference description. http://www.
w3. org/TR/daml+ oil-reference, 2001.
[16] Aditya Deshpande, Alisha Shahane, Darshana Gadre, Mrunmayi Deshpande,
and Prachi M Joshi. A survey of various chatbot implementation techniques.
International Journal of Computer Engineering and Applications, 11, 2017.
[17] Warith Eddine Djeddi, Mohamed Tarek Khadir, and Sadok Ben Yahia.
XMap++: Results for OAEI 2014. In OM, pages 163–169. Citeseer, 2014.
[18] TA Dobrila. From semantic web knowledge to a functional conversational
agent: A practical approach, 2009.
[19] Aniket Dole, Hrushikesh Sansare, Ritesh Harekar, and Sprooha Athalye.
Intelligent chat bot for banking system. International Journal of Emerging
Trends & Technology in Computer Science (IJETTCS), 4(5):49–51, 2015.

69

Bibliography

[20] Ghada Gasmi, Sadok Ben Yahia, Engelbert Mephu Nguifo, and Yahya Slimani. IGB: Une nouvelle base générique informative des règles d’association.
Revue I3 (Information-Interaction-Intelligence), 6(1):31–67, 2006.
[21] Thomas R Gruber et al. A translation approach to portable ontology
specifications. Knowledge acquisition, 5(2):199–220, 1993.
[22] Sana Hamdi, Amel Bouzeghoub, Alda Lopes Gancarski, and Sadok
Ben Yahia. Trust inference computation for online social networks. In
2013 12th IEEE International Conference on Trust, Security and Privacy
in Computing and Communications, pages 210–217. IEEE, 2013.
[23] Sana Hamdi, Alda Lopes Gancarski, Amel Bouzeghoub, and Sadok
Ben Yahia. TISoN: Trust inference in trust-oriented social networks. ACM
Transactions on Information Systems (TOIS), 34(3):1–32, 2016.
[24] Tarek Hamrouni, Sadok Ben Yahia, and Engelbert Mephu Nguifo. Succinct
system of minimal generators: A thorough study, limitations and new
definitions. In International Conference on Concept Lattices and Their
Applications, pages 80–95. Springer, 2006.
[25] Tarek Hamrouni, Sadok Ben Yahia, and Engelbert Mephu Nguifo. Generalization of association rules through disjunction. Annals of Mathematics
and Artificial Intelligence, 59(2):201–222, 2010.
[26] Tarek Hamrouni, Sadok Ben Yahia, and Engelbert Mephu Nguifo. Looking
for a structural characterization of the sparseness measure of (frequent
closed) itemset contexts. Information Sciences, 222:343–361, 2013.
[27] Bob Heller, Mike Proctor, Dean Mah, Lisa Jewell, and Bill Cheung. Freudbot: An investigation of chatbot technology in distance education. In
EdMedia+ Innovate Learning, pages 3913–3918. Association for the Advancement of Computing in Education (AACE), 2005.
[28] M Nidhal Jelassi, Christine Largeron, and Sadok Ben Yahia. Efficient
unveiling of multi-members in a social network. Journal of Systems and
Software, 94:30–38, 2014.
[29] Mr Nikhil R Khante and Mr KN Hande. A survey to chatbot system with
knowledge base database by using artificial intelligence & expert systems.
2019.
70

Bibliography

[30] Graham Klyne, Jeremy J Carroll, and B McBride. Resource description
framework (rdf): concepts and abstract syntax, 2004. February. URL:
http://www. w3. org/TR/2004/REC-rdf-concepts-20040210, 2009.
[31] Olga Koutsoni, Mourad Barhoumi, Ikram Guizani, and Eleni Dotsika.
Leishmania eukaryotic initiation factor (leif) inhibits parasite growth in
murine macrophages. PLoS One, 9(5):e97319, 2014.
[32] A Leung. Evaluating automatic keyword extraction for internet reviews.
Unıversıty Of Lorraıne Realself INC, 2016.
[33] Chun-Hung Lu, Guey-Fa Chiou, Min-Yuh Day, Chorng-Shyong Ong, and
Wen-Lian Hsu. Using instant messaging to provide an intelligent learning
environment. In International Conference on Intelligent Tutoring Systems,
pages 575–583. Springer, 2006.
[34] Harshada Modak, Rohini Pise, Sayali More, Rishabh Gupta, and Anuja
Bhagwat. Voice assistance based telecommunication system. Technical
report, EasyChair, 2020.
[35] Aisha Nazir, Muhammad Yaseen Khan, Tafseer Ahmed, Syed Imran Jami,
and Shaukat Wasi. A novel approach for ontology-driven information
retrieving chatbot for fashion brands. Int. J. Adv. Comput. Sci. Appl.
IJACSA, 10(9), 2019.
[36] Robert Neches, Richard E Fikes, Tim Finin, Thomas Gruber, Ramesh Patil,
Ted Senator, and William R Swartout. Enabling technology for knowledge
sharing. AI magazine, 12(3):36–36, 1991.
[37] Lin Ni, Chenhao Lu, Niu Liu, and Jiamou Liu. Mandy: Towards a smart
primary care chatbot application. In International symposium on knowledge
and systems sciences, pages 38–52. Springer, 2017.
[38] Mohammad Nuruzzaman and Omar Khadeer Hussain. A survey on chatbot
implementation in customer service industry through deep neural networks.
In 2018 IEEE 15th International Conference on e-Business Engineering
(ICEBE), pages 54–61. IEEE, 2018.
[39] Christopher Ochs, Zhe He, Ling Zheng, James Geller, Yehoshua Perl, George
Hripcsak, and Mark A. Musen. Utilizing a structural meta-ontology for
family-based quality assurance of the bioportal ontologies. J. Biomed.
Informatics, 61:63–76, 2016.
71

Bibliography

[40] Leila Ben Othman and Sadok Ben Yahia. Yet another approach for completing missing values. In International Conference on Concept Lattices and
Their Applications, pages 155–169. Springer, 2006.
[41] Nourchène Ouerhani, Ahmed Maalel, and Henda Ben Ghézela. SPeCECA:
A smart pervasive chatbot for emergency case assistance based on cloud
computing. Cluster Computing, pages 1–12, 2019.
[42] Zhenhui Peng and Xiaojuan Ma. A survey on construction and enhancement methods in service chatbots design. CCF Transactions on Pervasive
Computing and Interaction, 1(3):204–223, 2019.
[43] Antoine Raux and Maxine Eskenazi. A finite-state turn-taking model for
spoken dialog systems. In Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chapter of the Association
for Computational Linguistics, pages 629–637, 2009.
[44] Marion Richard, Xavier Aimé, Marie-Odile Krebs, and Jean Charlet.
LOVMI: vers une méthode interactive pour la validation d’ontologies. 2015.
[45] Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley. Automatic
keyword extraction from individual documents. Text mining: Applications
and theory, 1:1–20, 2010.
[46] Ahmed Samet, Eric Lefèvre, and Sadok Ben Yahia. Evidential data mining:
Precise support and confidence. Journal of Intelligent Information Systems,
47(1):135–163, 2016.
[47] Léon-Paul Schaub and Cyndel Vaudapiviz. Les systèmes de dialogue orientésbut: état de l’art et perspectives d’amélioration. 2019.
[48] Robert P Schumaker and Hsinchun Chen. Interaction analysis of the alice
chatterbot: A two-study investigation of dialog and domain questioning.
IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and
Humans, 40(1):40–51, 2009.
[49] Huma Shah. ALICE: An ace in digitaland. tripleC: Communication, Capitalism & Critique. Open Access Journal for a Global Sustainable Information
Society, 4(2):284–292, 2006.
[50] Aafiya Shaikh, Dipti More, Ruchika Puttoo, Sayli Shrivastav, and Swati
Shinde. A survey paper on chatbots. 2019.
72

Bibliography

[51] Moolchand Sharma, Shivang Verma, and Lakshay Sahni. Comparative
analysis of chatbots. Available at SSRN 3563674, 2020.
[52] Heung-Yeung Shum, Xiao-dong He, and Di Li. From eliza to xiaoice:
Challenges and opportunities with social chatbots. Frontiers of Information
Technology & Electronic Engineering, 19(1):10–26, 2018.
[53] Michael K Smith. Owl web ontology language guide, w3c recommendation.
http://www. w3. org/TR/2004/REC-owl-guide-20040210/, 2004.
[54] Rialda Spahic, Dzana Basic, and Emina Yaman. Zeka-friendy chatterbot.
Southeast Europe Journal of Soft Computing, 8(1), 2019.
[55] Scott Stiefel. The chatbot will see you now: Protecting mental health
confidentiality in software applications. Colum. Sci. & Tech. L. Rev., 20:333,
2018.
[56] Rudi Studer, V Richard Benjamins, and Dieter Fensel. Knowledge engineering: Principles and methods. Data & knowledge engineering, 25(1-2):161–
197, 1998.
[57] Sandeep A Thorat and Vishakha Jadhav. A review on implementation
issues of rule-based chatbot systems. Available at SSRN 3567047, 2020.
[58] Chiraz Trabelsi, Aicha Ben Jrad, and Sadok Ben Yahia. Bridging folksonomies and domain ontologies: Getting out non-taxonomic relations. In
2010 IEEE International Conference on Data Mining Workshops, pages
369–379. IEEE, 2010.
[59] Aarsh Trivedi, Vatsal Gor, and Zalak Thakkar. Chatbot generation and
integration: A review. 2019.
[60] Alan M Turing. Computing machinery and intelligence. In Parsing the
Turing Test, pages 23–65. Springer, 2009.
[61] Savvas Varitimiadis, Konstantinos Kotis, Andreas Skamagis, Alexandros
Tzortzakakis, George Tsekouras, and Dimitris Spiliotopoulos. Towards implementing an ai chatbot platform for museums. In International Conference
on Cultural Informatics, Communication & Media Studies, volume 1, 2020.
[62] Dawei Wang, Bo Hu, Chang Hu, Fangfang Zhu, Xing Liu, Jing Zhang,
Binbin Wang, Hui Xiang, Zhenshun Cheng, Yong Xiong, Yan Zhao, Yirong
73

Bibliography

Li, Xinghuan Wang, and Zhiyong Peng. Clinical Characteristics of 138
Hospitalized Patients With 2019 Novel Coronavirus–Infected Pneumonia in
Wuhan, China. JAMA, 323(11):1061–1069, 03 2020.
[63] Joseph Weizenbaum. Eliza—a computer program for the study of natural
language communication between man and machine. Communications of
the ACM, 9(1):36–45, 1966.
[64] Sanghyun Yi and Kyomin Jung. A chatbot by combining finite state machine,
information retrieval, and bot-initiative strategy. Proc. Alexa Prize, 2017.
[65] Nassima Ben Younes, Tarek Hamrouni, and Sadok Ben Yahia. Bridging
conjunctive and disjunctive search spaces for mining a new concise and
exact representation of correlated patterns. In International Conference on
Discovery Science, pages 189–204. Springer, 2010.
[66] Sami Zghal. Contributions à l’alignement d’ontologies OWL par agrégation
de similarités. PhD thesis, Artois, 2010.
[67] Sami Zghal, Sadok Ben Yahia, Engelbert Mephu Nguifo, and Yahya Slimani.
SODA: An OWL-DL based ontology matching system. In Proceedings of
the 2nd International Conference on Ontology Matching-Volume 304, pages
261–267. CEUR-WS. org, 2007.

74

Résumé
Aujourd’hui, c’est l’ère de l’intelligence dans les machines. Avec le progrès
de l’intelligence artificielle, les machines ont commencé à imiter les humains, le
chatbot est la prochaine grande chose dans le domaine des services de conversation. Un chatbot est une entité virtuelle capable de mener une conversation
naturelle avec des personnes. Il peut inclure de compétences qui lui permettent
de converser avec les humains sous forme audio, visuelle ou textuelle. Obtenir les
bonnes informations au bon moment et au bon endroit est la clé d’une gestion
efficace des catastrophes. Le terme "gestion des catastrophes" englobe à la fois
les catastrophes naturelles et celles causées par l’homme. Pour aider les citoyens,
notre projet est de créer Covid Assistant pour répondre au besoin d’informations
actualisées qui doivent être disponibles 24 heures sur 24. Un chatbot peut
être considéré comme un système de questions-réponses dans lequel des experts
fournissent des connaissances pour solliciter les utilisateurs. Cette thèse de mastère est consacrée à la discussion du chatbot Covid Assistant et à l’explication
détaillée de chaque élément. La conception du chatbot proposé est introduite
par ses sept composantes : Ontologie, module de grattage Web, base de données,
machine d’état, extracteur de mots-clés, un chatbot formé et interface utilisateur.
Mots clés:Chatbot, Agent conversationnel, Ontologie, Machine à Etat Fini,
Gestion des catastrophes, Covid-19

