IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

Distant Domain Transfer Learning for Medical
Imaging

arXiv:2012.06346v1 [eess.IV] 10 Dec 2020

Shuteng Niu, Meryl Liu, Yongxin Liu, Jian Wang, and Houbing Song, Senior Member, IEEE

Abstract— Medical image processing is one of the most
important topics in the field of the Internet of Medical
Things (IoMT). Recently, deep learning methods have carried out state-of-the-art performances on medical image
tasks. However, conventional deep learning have two main
drawbacks: 1) insufficient training data and 2) the domain
mismatch between the training data and the testing data. In
this paper, we propose a distant domain transfer learning
(DDTL) method for medical image classification. Moreover,
we apply our methods to a recent issue (Coronavirus diagnose). Several current studies indicate that lung Computed Tomography (CT) images can be used for a fast and
accurate COVID-19 diagnosis. However, the well-labeled
training data cannot be easily accessed due to the novelty
of the disease and a number of privacy policies. Moreover,
the proposed method has two components: Reduced-size
Unet Segmentation model and Distant Feature Fusion (DFF)
classification model. It is related to a not well-investigated
but important transfer learning problem, termed Distant
Domain Transfer Learning (DDTL). DDTL aims to make
efficient transfers even when the domains or the tasks
are entirely different. In this study, we develop a DDTL
model for COVID-19 diagnose using unlabeled Office-31,
Catech-256, and chest X-ray image data sets as the source
data, and a small set of COVID-19 lung CT as the target
data. The main contributions of this study: 1) the proposed
method benefits from unlabeled data collected from distant
domains which can be easily accessed, 2) it can effectively
handle the distribution shift between the training data and
the testing data, 3) it has achieved 96% classification accuracy, which is 13% higher classification accuracy than
”non-transfer” algorithms, and 8% higher than existing
transfer and distant transfer algorithms.
Index Terms— COVID-19 Diagnosis, Medical Image Processing, Machine Learning, Deep Learning, Transfer Learning, Distant Transfer Learning, Domain Adaptation.

I. I NTRODUCTION
Recently, with state-of-art performance, deep learning methods have dominated the field of image processing. However,
deep learning methods require a massive amount of welllabeled training data, and the majority of deep leaning methods
are sensitive to the domain shift. Therefore, transfer learning
(TL) has been introduced to deal with those two issues. In
this paper, we propose a novel medical image classification
algorithm. Moreover, we implement the proposed algorithm on
a COVID-19 diagnose application. Generally, medical image
data sets are difficult to access due the rarity of diseases
and privacy policies. Moreover, it is difficult to manually
collect a massive amount of high-quality labeled lung CT
scans associated with of COVID-19. Thus, the performance of

machine learning models can be unsatisfying with insufficient
training data. To overcome this obstacle, artificial and synthetic
data can be used to expand the volume of the data. However,
these methods cannot handle the performance degradation
caused by the distribution mismatch between the training data
and the testing data. Therefore, transfer learning is considered
to be one of the most effective ways to solve both problems at
the same time. Theoretically, transfer learning algorithms aim
to develop robust target models by using only a small set of
target training data and transferring knowledge learned from
other domains and tasks. Previously, [1] proposed an adaptation layer with domain distance measurements to transfer
knowledge between deep neural networks. In general, conventional transfer learning algorithms assume that the source
domains and the targets share a certain amount of information.
However, this assumption does not always hold in many realworld applications, such as medical image processing [2],
[3], rare species detection [4] and recommendation systems
[5], [6]. Moreover, transferring between two loosely related
domains usually causes negative transfer [7], meaning that
the knowledge transfer starts hurting the performance on the
task in the target domain, producing worse performance than
non-transfer models. For instance, building a dog classification
model by directly transferring knowledge from a car classification model would likely to lead to negative transfer due to
the weak connection between the two domains. Therefore, it
is not always feasible to apply transfer learning to areas where
we cannot easily obtain enough source domain data related to
the target domain. COVID-19 diagnosis based on lung CT is
a typical example where we cannot easily find related source
data for training, so conventional transfer learning can lead to
negative transfer.
In this paper, we develop a lung CT scan-based COVID-19
classification framework by studying a challenging problem,
distant domain transfer learning (DDTL), which aims to deal
with the shortcomings of traditional machine learning and
conventional transfer learning. As shown in Fig. 1, the proposed framework contains two parts: semantic segmentation
and distant feature fusion. It can perform knowledge transfer between distant domains which are seemingly unrelated.
Moreover, DDTL [8] is a newly introduced transfer learning
method that mainly aims to address the issue of negative
transfer caused by loose relations of the source domains and
the target domains. In other words, it allows us to safely
and effectively perform the knowledge transfer when the
source domains and target domains only share a very weak

1

2

IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

Fig. 1: Architecture Overview of Distant Feature Fusion Model

connection. Unlike conventional TL methods, the proposed
DDTL algorithm benefits from fusing distant features extracted from distant domains. Moreover, the inspiration for
DDTL lies in the ability of human beings to learn new things
by building on knowledge acquired from several seemingly
independent things. For example, a human who knows birds
and airplanes can recognize a rocket even without seeing any
rockets previously. Therefore, DDTL dramatically extends the
use of transfer learning to more areas, and applications where
do not always have adequate related source data. As mentioned
previously, there is no easy access to a sufficient amount of
well-labeled lung CT images of COVID-19 because of the
labeling difficulty, and patient privacy policies. Therefore, we
consider this task as a DDTL problem that can benefit from
distant but more accessible domains. For instance, we use three
open-source image data sets as source domain data sets to
develop a robust COVID-19 classification method based on
lung CT images.
Moreover, unlike most existing methods, we introduce a
feature-based algorithm with a novel distant feature fusion
process. Previously, there are few proposed distant transfer
algorithms [8], [9], but most of them are task-specific and lack
stability in performance. Inspired by an instance-based method
[9] and multi-task learning [10], we build a DDTL algorithm to
solve COVID-19 classification tasks by extracting and fusing
distant features. There are two main improvements made by
our algorithm. Firstly, it does not require any labeled source
domain data, and the source domains can be completely different from the target domain. The proposed model only needs
a small amount of labeled target domain and can produce
very promising classification accuracy on the target domain.
Secondly, it only focuses on improving the performance of the
target task in the target domain. To the best of our knowledge,
it is the first time that DDTL has been applied to medical
image classification. Furthermore, we introduce a novel feature
selection method, Distant Feature Fusion (DFF), to discover
general features across distant domains and tasks by using
convolutional autoencoders with a domain distance measurement. To outline, there are four main contributions made in this
study: 1) Propose a new DDTL algorithm for fast and accurate

COVID-19 diagnose based on lung CT, 2) Examine existing
deep learning models (transfer and non-transfer) on COVID19 classification problem, 3) The proposed algorithms has
achieved the highest accuracy on this task, which has a small
set of labeled target data and some unlabeled source data from
different domains. Moreover, compared with other transfer
learning methods, supervised learning methods, and existing
DDTL methods, the proposed DFF model has achieved up
to 34% higher classification accuracy and 4) The proposed
algorithms can be easily generalized to other medical image
processing problems.
The remainder of this paper is structured as follows: In
Section II, we first review the most recent DTTL works. And
then, we formulate the problem definition in Section III. Next,
we present the details of the proposed algorithm in Section IV.
After that, we present experimental results and analysis in
Section V. Lastly, we conclude the paper and discuss future
directions in Section VI.
II. R ELATED W ORK
Insufficient training data and domain distribution mismatch
have become the two most difficult challenges in the study
of machine learning. To address these two issues, transfer
learning has emerged a lot of attention due to its training efficiency and domain shift robustness. However, transfer learning
also suffers from a critical shortcoming, negative transfer [11],
which significantly limits the use and performance of transfer
learning. In this section, we introduce some related works
in three fields: conventional transfer learning, DDTL, and
existing ML methods for COVID-19 classification.
A. Conventional Transfer Learning
First of all, transfer learning aims to find and transfer
the common knowledge in the source domain and the target
domain. Furthermore, [12]–[14] expanded the use of transfer
learning from traditional machine learning models to deep
neural networks. Typically, there are two types of accessible
transfer learning: feature-based and instance-based. Moreover,
both types focus on closing the distribution distance between

FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF JOURNAL OF BIOMEDICAL HEALTH INFORMATICS

the source domain and the target domain. In instance-based
algorithms, the goal is to discover source instances similar
to target instances, so that highly unrelated source samples
would be eliminated. Differently, feature-based algorithms aim
to map source features and target features into a common
feature space where the distribution mismatch is minimized.
However, both of them naturally assume that the source
domain and the target domain share a fairly strong connection.
Unlike conventional transfer learning, our work can transfer
knowledge between different domains and tasks that are not
closely related.
B. DDTL
Secondly, most DDTL algorithms are similar to multi-task
learning [15], which also benefits from shared knowledge
in multiple different but related domains. Generally, multitask learning tends to improve the performance on all tasks.
Differently, DDTL only focuses on using the knowledge in
other domains to improve the performance of the target task in
the target domain. Moreover, most previous studies of DDTL
focus on instance-based methods and tend to take advantage of
massive related source data. Firstly, [8] introduced an instancebased algorithm, transitive transfer learning (TTL). It transfers
knowledge between text data in the source domain and the
image data in the target domain by using annotated image
data as a bridge. However, TTL is highly case-dependent
and unstable in performance. Similarly, [9] introduced another instance-based algorithm with a novel instance selection
method, Selective Learning Algorithm (SLA). Moreover, SLA
is used to select helpful instances from a number of unrelated
intermediate domains to expand the source domain’s volume.
However, this algorithm can only handle binary classification
problems. Furthermore, [16] proposed another feature-based
method to deal with scarce satellite image data. It predicts
the poverty based on daytime satellite images by transferring knowledge learned from an object classification tasks
with the aid of nighttime light intensity information as a
bridge. However, this method relies heavily on a massive
amount of labeled intermediate training data, which can be
too expensive to apply. Unlike existing DDTL algorithms,
our method benefits from multiple source domains without
labeled data, and those source domains can have significant
discrepancies. Furthermore, our method can also handle multiclass classification while consistently producing promising
results.

3

the domain discrepancy between the source data and the target
data.
III. P ROBLEM S TATEMENT
In this DDTL problem, we assume that the data of each
target domain is not enough to train a robust model. And
we have
of unlabeled source domains denoted as
 a number
nS
n
S = (x11 , ..., x1 S1 ), ..., (xS1N , ..., xSNN ) , where n and SN
represent the number of samples in each source domain and
the number of source domains. Then we denote one or multiple
labeled target domains as:
n

n

nT

nT

T = [(x11 , y11 ), ..., (x1 T1 , y1 T1 )],
..., [(x1TN , yT1 N ), ..., (xTNN , yTNN )]

(1)

, where n and TN represent the number of samples in each
source domain and the number of source domains. Let P (x),
P (y|x) be the marginal and the conditional distributions of a
data set. In this DDTL problem, we have the following:
PS1 −SN (x) 6= PT1 −TN ,

(2)

PT1 (y|x) 6= PT2 (y|x) 6= ... 6= PTN (y|x).

(3)

The main objective of the proposed work is to develop a
model for the target domain with a minimal amount of labeled
data by finding generic features from distant unlabeled source
domain data. The motivation behind this study is that data in
distant domains is usually seemingly unrelated in the instancelevel but related in the feature-level. However, the connection
on the feature level from one distant domain can be too weak
to be used to train an accurate model. As such, simply using
one or two sets of source data is likely to fail in building the
target model. Therefore, we leverage from multiple unlabeled
distant source domains to obtain enough information for the
target task.
IV. M ETHODOLOGY
In this section, we introduce the proposed COVID-19 diagnose framework. Firstly, we present the reduced-size ResNet
segmentation model. After that, we introduce the novel DDTL
algorithm, Distant Feature Fusion (DFF).
A. Lung CT Segmentation by Reduced-size ResUnet

C. Machine Learning for COVID-19 Diagnosis
Moreover, to overcome the shortage of COVID-19 testing
toolkits, many efforts have been made to search for alternative
solutions. [17] shows that lung CT images can be used for
diagnosis. Furthermore, several studies [18]–[20] introduce
machine techniques to COVID-19 diagnosis, including but
not limited to, convolutional neural networks (CNN), transfer
learning, empirical modeling. However, most existing models
suffer from a common shortcoming that is insufficient welllabeled training data. And transfer leanings methods can carry
out fairly decent classifications, but they are still limited by

First of all, extracting features from a full size lung CT
image with a small training set can be difficult because the
model might end up focusing on noise in the useless parts of
the images. Therefore, we propose to pre-process the image
to improve the performance of the distant feature fusion by
applying semantic segmentation. By doing this, as shown in
Figure. 2, we can remove random noise and preserve the
important information in the lung area of a image. Moreover, a
small data set for training can lead to a over-fitting situation in
a deep neural network. Therefore, we develop a reduced-size
ResNet for this Covid-19 diagnose task.

4

IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

B. DFF

Fig. 2: Segmented Lung Area

Similar to the original Unet [21], the proposed reducedsize ResUnet contains two feature extraction parts: four convolutional blocks layers with down-sampling and four deconvolutional layers with up-sampling. However, the lung-CT
data set used for training is smaller than the data set used
in the original paper. Therefore, we reduce the numbers of
convolutional layers and deconvolutional layers, and apply
dropout layers to prevent over-fitting. Furthermore, we adopt
skip-connection to prevent two main problems in the training
process: gradient explode and gradient disappear. In this study,
we implement a single skip-connection to form convolutional
and deconvolutional blocks. By doing this, the convergence
time of the model is faster and the training process is more
stable.
Furthermore, image segmentation tasks require to perform
accurate pixel-level classification on the input images. Therefore, it is critical to design a proper loss function based on
each task. In this study, the final loss function is composed
by a soft-max function over the last feature map combined
with the cross-entropy loss. The expressions of the soft-max
function and cross-entropy functions are:
pk (x) = exp(fk (x))/

K
X

exp(fk (x)),

(4)

k=1

E=

X

ω(x)log(p(l(x) )(x)),

(5)

x

where fk (x) represents the activation map of the kth feature
at xth pixel and K is the total number of classes, and
the cross-entropy penalizes at each position the deviation of
p(l(x) ). Furthermore, the segmentation boarder is computed
with morphological operations. The weight map is expressed
as:
(d1 (x) + d2 (x))2
),
(6)
2σ 2
where ωc is the weight map to balance the class frequencies,
d1 and d2 are the distances between a pixel to the closest
boarder and the second coolest boarder, and ω0 and σ are the
initialization values.
ω(x) = ωc (x)ω0 exp(−

As shown in Fig. 3, there are three main components
in DFF: distant feature extractor, distant feature adaptation,
and the target classification. There are three types of losses
from three components: reconstruction loss, domain loss, and
classification loss.
1) Distant Feature Extraction: As one of the inspirations
of this study, a convolutional autoencoder pair is used as
a feature extractor in DFF. As a variant of autoencoders,
convolutional autoencoders [22] are usually beneficial for
unsupervised image processing related problems. First of all,
a convolutional autoencoder is a feed-forward neural network
working in an unsupervised manner, which suits this DDTL
problem perfectly since there is no labeled data in source
domains. Generally, a convolutional autoencoder pair contains
one input layer, one output layer, one up-sampling layer, and
multiple convolutional layers. Moreover, there are two main
components: encoder EConv (·) and decoder DConv (·). The
standard process of convolutional autoencoder pairs can be
demonstrated as:
Encoding : f = EConv (x), Decoding : x̂ = DConv (f̂ ), (7)
where f is the extracted features of x, and x̂ is the reconstructed x. In addition, the way to tune the parameters of
a convolutional autoencoder pair is to minimize the reconstruction error on all the training instances. Conceptually, the
output of the encoder can be considered as high-level features
of the unlabeled training data. Furthermore, these features are
learned in an unsupervised manner, so they are robust if the
reconstruction error is lower than a certain threshold.
In this DDTL problem, as shown in Fig. ??, we use
a convolutional autoencoder pair to discover robust feature
representation from unlabeled source domain data sets and the
labeled target data sets simultaneously. And more, M odule2
and M odule3 are the encoder and the decoder. The structure
of the auto-encoder pair contains two convolutional layers
and two pooling layers in both the encoder and decoder. Upsampling is applied to the encoder to ensure the quality of
the reconstructed images. The process of feature selection has
three main steps: feature extraction, instance reconstruction,
and reconstruction measurement. First, we feed both the source
data and the target data into the encoder to obtain high-level
features fS and fT . Then, extracted features are sent into the
decoder to get reconstructions, XˆS and XˆT . The equations of
the first two steps are expressed as:
fS = EConv (XS ), fT = EConv (XT );

(8)

XˆS = DConv (fS ), XˆT = DConv (fT );

(9)

where XS and XT are the source and the target samples, and
fS and fT are the source and the target features. Finally, we
define the reconstruction errors from both the source domains
and the target domains as the loss function of the feature
extractor, LR as follow:

FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF JOURNAL OF BIOMEDICAL HEALTH INFORMATICS

5

Fig. 3: DFF Architecture

nSi

LR =

SN X
X
1
j
jˆ
)2 +
− XX
(XX
Si
Si
n
S
i
i=1 j=1
nTi
ST X
X
1
j
jˆ
)2 .
− XX
(XX
Ti
Ti
n
T
i
i=1 j=1

(10)

feature adaptation layer to the convolutional autoencoder pair
to measure the domain loss, LD . The maximum mean discrepancy (MMD) [23], an important statistical domain distance
estimator, is used as the domain distance measurement metric.
The domain loss is expressed as:
nS i
n Ti
SN X
ST X
X
X
LD = M M D(
fSj i ,
fTj i ),

where SN and ST are the numbers of the source domains and
the target domains, nSi and nSi are the numbers of instances
in the ith source domain and the target domain.

i=1 j=1

M M D(X, Y ) =k
Algorithm 1: Distant Feature Fusion Algorithm
Input: S = XS , T = XT , YT .
Max Iteration: I, Batch Number: N.
for i = 1, ...., I do
for j = 1, ...., N do
Feature Extraction: fS = EConv (XS ),
fT = EConv (XT )
Instance Reconstruction: XˆS = DConv (XS ),
XˆT = DConv (XS )
Label Prediction: XPT red = CT (fT )
Calculate LR , LD , LC
Update θE , θD , ΘC
end
end
Output: XPT red
2) Distant Feature Adaptation: Commonly, minimizing the
reconstruction error LR can discover a set of high-level
features of the given input data. However, the distribution
mismatch between the source and the target domains is
significant, so minimizingLR alone is insufficient to extract
robust and domain-invariant features. Therefore, we need extra
side information to close the domain distance, so the extracted
features are robust to both the source domains and the target
domains. In this research, as shown in Fig. 3, we add a distant

(11)

i=1 j=1

n1
n2
1 X
1 X
ϕ(xi ) +
ϕ(yj ) k,
n1 i=1
n2

(12)

f =1

where n1 and n2 are the numbers of instances of two different
domains, and ϕ(·) is the kernel that converts two sets of features to a common reproducing kernel Hilbert space (RKHS)
where the distance of two domains is maximized.
3) Target Classifier: Furthermore, with extracted high-level
features, we add two fully-connected layers after the encoder
to build a target classifier, CT , for the target task in the
target domain. As the motivation of this step, [24] proves that
convolutional layers can discover features, and fully-connected
layers can find the best feature combination for each class in
the target task. In other words, fully-connected layers do not
learn more new features but connect each class to a specific
set of features with different weights. In this work, there is
only one fully-connected layer followed by the output layer
with cross-entropy loss, LC :
LC = −x[Class] +

n Ti
TN X
X

exp(XTj i ).

(13)

i=1 j=1

where XTj i is the jth sample in the ith target domain. Finally,
by embedding all three losses from 10, 11, and 13, the overall
objective function of DFF is formulated as:
Minimize L = LR + LD + LC ,
θE ,θD ,ΘC

(14)

6

IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

where θE , θD , ΘC are the parameters of the encoder, decoder,
and the classifier, respectively. Moreover, L is the final loss
constructed by the reconstruction error, domain loss, and
classification loss. Finally, all the parameters are optimized
by minimizing the objective function in Equation 14.
4) Algorithm Summary: Lastly, an overview of the proposed
work is summarized in Algorithm 1.
V. E XPERIMENT AND A NALYSIS
In this section, we introduce a number of benchmark models, such as supervised learning models, conventional transfer
learning models, and DDTL models. Then we set up several
different combinations of the source and the target to conduct
a number of experiments. Moreover, we represent results from
the proposed models and comparisons with benchmark models
and other TL models. Finally, we present training details and
the analysis of experimental results.
A. Benchmark Models
In this study, as shown in Table. I, we choose several common transfer models and non-transfer models for comparisons.
By comparing results from different methods, we can justify
the improvements made by the proposed methods. Firstly, we
select three supervised non-transfer baseline models: convolutional neural works (CNN), Alexnet [24], and Resnet [25].
For CNN, the model is constructed with three convolutional
layers with 3 × 3 kernels followed by a 2 × 2 max polling
kernel. Secondly, we also choose three conventional transfer
learning models: fine-tuned Alexnet, fine-tuned Resnet, and
self-transfer (SelfTran) model [18]. Moreover, the convolutional layers of the Alexnet model and Resnet model remain
frozen during the fine-tuning, and only the fully-connected
layers are re-trained. What is more, we choose one instancebased DDTL method: selective learning algorithm (SLA) [9].
However, this DDTL model cannot be completely reproduced
with many details not being introduced in the papers, and there
is no accessible source code. As such, reproduced accuracy
of this algorithm can be potentially improved with more
careful tuning. Finally, we produce multiple experiments on
the proposed DFF and ADFE algorithms. Furthermore, all
details of each benchmark model are specified in Table. I.
B. Date Sets and Experiment Setups
In this study, as shown in Table. II, we totally use six opensource data sets: Catech-256 [26], Office-31 [27], chest X-Ray
for pneumonia detection [28], Lung CT [29], and Covid19CT [30]. The first, Catech-256 is an image data set that
includes labeled data of 256 different classes. For each class,
the number of instances is from 80 to 827. Then, Office-31
has three collections of 31 different common office objects,
with total 4110 instances collected from three different data
sources: ”amazon”, ”webcam”, and ”dslr”. However, Office31 is acknowledged as an extremely unbalanced data set
because the numbers of samples from the three domains are
very different. Moreover, the chest X-Ray data set contains
5226 well-labeled images. Intuitively, the chest X-Ray images

should have the most similarity with lung X-Ray images,
so we wonder if directly transfer and fine-tune on this data
set would carry out better performance than the proposed
methods. Moreover, Covid19-CT contains 565 labeled lung
CT images: 349 positive samples, and 216 negative samples.
It is considered as a fairly small data set for training deep
learning models. Finally, we use the lung CT data set for the
segmentation model. The data set has 367 lung CT images
with pixel-level masks.
Moreover, we run each experiment five times to investigate the accuracy fluctuation range. Firstly, we produce 4
experiments on CNN and conventional TL models with the
Covid19-CT data. In addition, Alexnet and SelfTran models
are initialized with the parameter pre-trained on the ImageNet
data set, and the CNN model is trained from scratch. And
then, we set up a series of experiments on DDTL models with
single source domain and multi-source domains to explore
the potential of the learning method. As shown in Table. V,
there are five unlabeled source domains data sets: Catech-256,
Amazon, Amazon, Webcam, Chest X-Ray, and one labeled
target data set: Lung CT for Covid-19. What is more, another
regular Lung CT contains masks for segmentation. Moreover,
the first four source domains are seemingly unrelated to the
target domain, but the last source domain is visually related
to the target domain.
Furthermore, unlike previous methods, the proposed method
is able to utilize multiple source domains to improve the
performance in the target domain. Therefore, as we can tell
from Table. VI, we choose four primary source domains and
use the Chest X-Ray data set as the auxiliary domain. In the
following sections, we will present the results and analysis.
C. Performance and Analysis
In this section, we first present the performance of the
segmentation model. After that, we give an overview of results
of all examined classification methods and present insights on
differences in performance. Then, we provide training details
and analysis of our proposed DDTL algorithm.
1) Segmentation Performance: Firstly, the most informative
part of a lung CT is the lung area, and it allows machines
to better imitate the behaviors of real specialists. The proposed reduced-size ResUnet is trained from scratch because
there is no pre-trained weights can fit this novel architecture.
Moreover, the drop-out layers and the skip-connections are
applied to prevent over-fitting and non-convergence problems.
As we can tell from figure. 2, the segmented image shows
an accurate and clear contour of the lung area, so we can
select only the lung area as the input for the DFF model.
Furthermore, Figure. 4 shows a better visual results of the
segmentation model. The first column presents the original
image, the second column shows the ground truth of the lung
area, the third column gives the pixel-level classification of
the model, and the fourth column illustrates the pixel-level
difference between the ground truth and the prediction.
Moreover, we use two common evaluation metrics for image
segmentation tasks to quantify the performance. In the study,
we use IoU (intersection over union), Dice (F1 Score), and

FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF JOURNAL OF BIOMEDICAL HEALTH INFORMATICS

7

TABLE I: Model Comparison

Transferable
Base Model
Loss Type
Learning Type

CNN

Alexnet

Resnet

SelfTran

SLA

DFF

No
Discriminative
Entropy
Feature-based

Yes
Discriminative
Entropy
Feature-based

Yes
Discriminative
Entropy
Feature-based

Yes
Discriminative
Entropy
Feature-based

Yes
Discriminative
Entropy&MMD
Instance-based

Yes
Discriminative
Entropy&MMD
Feature-based

TABLE II: Data Sets
Data Set

Total Classes

Total Samples

Label

Mask

Catech-256
Office-31
Chest Xray
Lung-CT
Covid19-CT

256
31
4
4
2

30670
4110
562
367
565

Y es
Y es
Y es
Y es
Y es

No
No
No
Y es
No

Fig. 4: Lung CT Segmentation
TABLE III: Segmentation Performance

Reduced-ResUnet
Unet

IoU

Dice

Accuracy

0.96
0.86

0.97
0.88

0.96
0.87

Accuracy =

pixel-level accuracy as the evaluation metrics. The definitions
of them are:
IoU =

TP
,
TP + FP + FN

(15)

Dice =

2T P
,
2T P + F P + F N

(16)

TP + TN
.
TP + TN + FP + FN

(17)

Furthermore, for the comparison, we also conduct experiments
on the original Unet with the same data set. The details
are shown in Table. III. Obviously, the reduced-size ResUnet
outperforms the original Unet. The possible reasons are: 1)
the original Unet cannot effectively prevent the model learning
from noise, 2) the skip-connections help the model to extract
deeper features.
2) Classification Performance Overview: As demonstrated
in Table. IV, the proposed DFF algorithm outperforms the
highest test classification accuracy (96%). And more, the CNN
model is only at (78%) classification accuracy. Intuitively, it

8

IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

TABLE IV: Top Accuracies (%) of Examined Models

Testing Accuracy (Raw-Image)
Testing Accuracy (Segmented-Image)

CNN

Alexnet

Resnet

SelfTran

SLA

DFF

74 ± 1
78 ± 2

82 ± 3
85 ± 2

86 ± 3
88 ± 3

83 ± 1
87 ± 3

54 ± 2
62 ± 1

93 ± 1
96 ± 1

TABLE V: Accuracies (%) of DDTL Models with Single Source Domain
DDTL Models
Source Domain

Catech256

Amazon

Webcam

Dslr

Chest X-Ray

SLA (Raw-Image)
SLA (Segmented-Image)
DFF (Raw-Image)
DFF (Segmented-Image)

54 ± 2
62 ± 1
88 ± 2
90 ± 1

52 ± 1
54 ± 1
78 ± 3
76 ± 1

48 ± 2
46 ± 3
73 ± 2
76 ± 2

48 ± 3
56 ± 1
70 ± 1
74 ± 3

52 ± 4
61 ± 2
63 ± 3
69 ± 2

77 ± 1
80 ± 2
66 ± 2
72 ± 1

61 ± 2
64 ± 1
57 ± 3
61 ± 1

64 ± 1
68 ± 3
61 ± 1
64 ± 2

51 ± 2
52 ± 2
54 ± 1
62 ± 3

73 ± 3
81 ± 1
64 ± 2
65 ± 2

Conventional TL Models
Fine-tuned
Fine-tuned
Fine-tuned
Fine-tuned

Alexnet (Raw-Image)
Alexnet (Segmented-Image)
Resnet (Raw-Image)
Resnet (Segmented-Image)

TABLE VI: Accuracies (%) of DDTL Models with Multiple Source Domains
Primary Source Domain
Auxiliary Source Domain

Catech256

SLA (Raw-Image)
SLA (Segmented-Image)
DFF (Raw-Image)
DFF (Segmented-Image)

54 ± 2
62 ± 1
93 ± 1
96 ± 1

is caused by insufficient training data. Moreover, the Alexnet
and SelfTran result in promising accuracies (85%, 88%). In
theory, initializing with pre-trained parameters can be the
main reason to allow them achieve better because the [retrained model was trained on a massive amount of images.
However, in this case, the settings are more or less similar
to TL, and the accuracies are still lower than the proposed
DDTL method. This performance gap can be caused by large
domain statistical discrepancy between two distant domains.
In other words, the pretraining data sets have large domain
distribution mismatches with the Covid19-CT data set, and the
traditional models are not able to close the domain distance.
Therefore, performance degradation cannot be avoided, but
there is no evidence of any negative transfer in the finetuning models. Furthermore, an instance-based DDTL model
(SLA) outputs the worst accuracy (62%), which is clearly
a negative transfer case. The theoretical reason for it is
that the instance selection by the re-weighting matrix ends
up eliminating most source domain samples due to a large
distribution discrepancy. As such, the selected instances are
not enough to extract enough information for the knowledge
transfer, which can be considered as the same situation as
the CNN model with insufficient training data. Furthermore,
it clearly shows that pre-processing the data with semantic
segmentation can improve the performance. It justifies that
preserving the most informative part by eliminating random
noise from a Small data set can enhance the final classification
performance.
Furthermore, there are other interesting things we can
observe from the same table. First of all, feature-based algo-

Amazon
Webcam
Chest X-Ray
52 ± 1
55 ± 3
73 ± 3
75 ± 2

48 ± 2
51 ± 1
64 ± 2
66 ± 1

Dslr
48 ± 3
47 ± 2
86 ± 3
87 ± 1

rithms have more promising performances in this COVID-19
classification problem. Compared with feature-based methods,
the instance-based method completely failed to solve this task.
Intuitively, samples in distant domains are seemingly unrelated
at the instance level, but they might still share common information at the feature level. Therefore, the instance selection
method can easily miss important information since it can only
study data sets at the visual-level. Differently, the featurebased models tend to ignore the large discrepancy at the
visual-level. Instead, they aim to discover the relationship of
two domains at the feature-level and close the distribution
mismatch by extracting domain-confusing features.
Moreover, Table. V shows performances of conventional TF
models and DDTL models with single source domain. First
of all, there are two completely different results from two
DDTL methods. The proposed DDTL algorithm achieves the
highest classification accuracy (90%, but the previous instancebased SLA method occurs negative transfer on all five source
domains. It further approves that instance selection process
might carry out decent results when the source domain and the
target domain have close relationships, but it does not suit the
cases where two domains share a loose connection. Differently,
feature-based methods are more reliable on DDTL problems.
However, the advantage of SLA is that it does not require
labeled target data, while the proposed method needs labeled
target data. Moreover, not all source domains are suitable
for distant knowledge transfer. The seemingly related domain,
chest X-Ray, is actually not the most transfer-friendly for this
task. Other data sets that are visually distant from the target
domain carry out better results. It approves the theory that

FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF JOURNAL OF BIOMEDICAL HEALTH INFORMATICS

10

20

5

10

10
10

20

30

0

10

Iteration
Reconstruction Loss

1

Domain Loss

20

30

0

Multi-Source
Single-Source

0.5

0
10

20

30

Multi-Source
Single-Source

2

1

3
2

20

30

1

10

20

30

30

3
2.5

10

20

30

0

10

20

30

Iteration

(b) Amazon-COVID19

40

Multi-Source
Single-Source

Total Loss

Classification Loss

Multi-Source
Single-Source

Iteration

22
20

4
3.5

2
0

(a) Catech256-COVID19

Total Loss

0

Iteration

Multi-Source
Single-Source

4

Iteration

20

15

30

0
10

Iteration

25

20

5

3

0

Multi-Source
Single-Source

20

Multi-Source
Single-Source

Iteration

0
0

10

Iteration

Domain Loss

0

30

Reconstruction Loss

15

15

25
Multi-Source
Single-Source

40

18
16

22

Multi-Source
Single-Source

Classification Loss

20

50
Multi-Source
Single-Source

20

Total Loss

Classification Loss

Total Loss

Multi-Source
Single-Source

25

Classification Loss

25

30

9

35
30
25
20

Multi-Source
Single-Source

20
18
16

15
0

10

20

30

0

10

Iteration

20

30

0

Iteration

20

30

0

0

2.9
2.8
2.7
2.6

0

10

20

Iteration

30

Multi-Source
Single-Source

0.5

0
0

10

20

30

Iteration

(c) Webcam-COVID19

30

3

Reconstruction Loss

Domain Loss

Reconstruction Loss

0.5

Multi-Source
Single-Source

3

20

Iteration

1
Multi-Source
Single-Source

10

Iteration

1

Domain Loss

10

Multi-Source
Single-Source

2.5

2

1.5
0

10

20

30

0

10

Iteration

20

30

Iteration

(d) Dslr-COVID19

Fig. 5: Training Details of experiments on ADFE with 4 setups: Catech-256 to Covid19-CT, Office-31-Amazon to Covid19-CT,
Office-31-Webcam to Covid19-CT, Office-31-dslr to Covid19-CT. In each sub-figure, up left is total loss, up right is target
classification loss, down left is domain distance, and down right is reconstruction error.

seemingly unrelated domains might be statistically connected
in the feature-level. We will provide more evidences in later
contents.
What is more, the best performance of conventional TL
models is (88% which is better than non-transfer methods.
Initializing with pre-trained weights only yields a faster convergence but it is not very helpful to improve the performance.
Accuracies from experiments of Chest X-Ray to Covid19-CT
turns out to be worse than other experiment setups even the
chest X-Ray is commonly assumed to be the most similar
to the target domain. However, as shown in Fig. 6, the
domain loss between the Covid19-Xray and chest X-Ray is
the greatest among all experiments. Therefore, it also proves
that seemingly related domains might be distant in the feature
level, so it is not always reliable to hand-pick source domains
in DDTL problems.
Moreover, the enhancement from semantic segmentation is
still not good enough to reach the human-level performance.
Therefore, unlike most existing DDTL algorithms, we wish to
even improve the performance by using more than one source
domain. Importantly, in DDTL problems, finding shared information cross different domains is the key to perform a

safe knowledge transfer. However, the amount of common
information extracted from a single distant domain might not
be sufficient. As shown in Table. VI, the proposed method
achieves (96% classification accuracy with using Catech-256
as the primary source domain and Chest X-Ray as the auxiliary
source domain. It means that these two data sets have less
information overlapping, so the DFF model can extract more
useful shared knowledge to transfer to the target domain.
Differently, performance degradation appears in others multisource domain experiments, which means others pairs have
shared information that causes over-fitting.
However, one significant weakness of DDTL models is
that they are highly dependent on the quantity and versatility
of the source domains. As we can tell from Table. V, the
performances of the DFF model and the ADFE model decrease
dramatically when the webcam and the dslr data sets of Office31 are set as the source domains. The cause of the performance
drop is simple. Theoretically, DDTL models benefit from
extracting the common knowledge of the source domain and
the target domain, but they cannot complete this type of feature
extraction when the source data set is small. There are only
550 and 640 samples in the webcam and the Dslr data sets,

10

IEEE JOURNAL OF BIOMEDICAL HEALTH INFORMATICS, VOL. 00, NO. 0, MONTH 2020

which are less than the target samples. Therefore, it is not easy
to safely and effectively transfer knowledge between different
domains. On the contrary, the Catech-31 data set has over
33000 samples from 256 different classes, so it is easier to
perform the knowledge transfer.
0.5
Dslr
Amazom
Webcam
Catech256
Chest X-Ray

0.45
0.4

Domain Loss

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0

5

10

15

20

25

30

Iteration

Fig. 6: DFF Domain Losses with Single Source Domain
3) Analysis of DFF: Fig. 5a-5d shows details of the DDF
models in single source domain setting and the multi-source
domain settings, illustrating four types of losses: total training
loss, target classification loss, domain loss, and reconstruction
loss. Firstly, The proposed DFF algorithm has achieved the
highest test classification accuracy when the Catech-256 data
set is chosen as the primary source domain and the chest
X-Ray data set as the auxiliary source domain. Overall, it
has the most smooth curves and the smallest domain loss.
Moreover, with the additional information from the auxiliary
source domain, its classification loss and reconstruction loss
are dramatically reduced. In other words, the model is able to
extract additional features from the auxiliary domain, and use
it as a bridge to close the distance from the target domain.
Moreover, large declines in performance appear in the other
experiments with Amazon and Webcam. As mentioned earlier,
the performance degradation can be caused by overlapping
information in the primary and the secondary source domains.
The model tends to over-fit on the repeated knowledge in
two source domains. Especially, in the experiment 5b, the
domain loss is increased and the classification loss can not
be lowered. Furthermore, this provides another approve that
seemingly distant instances might share a certain amount
of common features, and such features can be extracted by
properly adding a domain loss to the loss function. Moreover,
Fig. 6 supports another point: the smaller domain loss means
a closer distance between two domains. As we can tell from
the figure, the Catech-256 to Covid19-CT combination has
the lowest domain loss, and it also has the best classification
accuracy. Furthermore, the domain loss curve of Dslr data set
increases during the training, indicating that the quantity and
the versatility of the source data set play an important role in
this task. Finally, we quantify the performance of DFF model
with four evaluation metrics: accuracy, precision, recall, and
F1 score.

VI. C ONCLUSION & F UTURE W ORK
To draw a conclusion, in this paper, we introduce a novel
DDTL algorithms, DFF, for a COVID-19 diagnostic method
based on lung CT images. To distinguish from all conventional TL algorithms, the propose methods can use seemingly
unrelated data sets to develop an efficient classification model
for COVID-19 diagnose. Unlike previous DDTL models, our
method enables knowledge transfer from multiple distant
source domains, and it can effectively enhance the performance. Moreover, the proposed methods greatly expand the
usage of transfer learning on medical image processing by
safely transferring the knowledge in distant source domains,
which can be completely different from the target domain.
Moreover, this study is related to one of the most challenging
problems in transfer learning, negative transfer. To the best
of our knowledge, this is the first study that uses distant
domain source data for COVID-19 diagnosis and outperforms
promising test classification accuracy. Four contributions of
this paper are made: 1) it successfully adopts DDTL methods
to COVID-19 diagnosis, 2) we introduce a novel feature-based
DDTL classification algorithms, 3) the proposed methods
achieve state-of-art results, and 4) proposed methods can be
easily expanded to other medical image processing problems.
However, there are several drawbacks of DDTL algorithms:
1) most algorithms tend to be case-specific, 2) source domain
selection is too complicated in some cases, 3) distant feature
extraction process is computationally expensive.
In the future, there are a number of research directions
regarding COVID-19 diagnosis and DDTL problems. Firstly,
the explainability of the feature-based DDTL algorithm is a
challenging but essential topic. Visualizing the changes on
features in deep layers through the training process can not
only help us to better understand the domain adaptation in
the feature level and decision making process of deep ANN
models, but also discover the relationship between two distant
domains. Moreover, how to improve the efficiency of feature
extraction process is another key to improve the performance.
Commonly, generative adversarial networks (GANs) is widely
acknowledged as a better feature extraction method. However,
how to avoid non-convergence in the training process of
adversarial networks is very challenging, and gradient explode
and disappear make the training process for adversarial networks extremely difficult. As an inspiration, designing new
adversarial loss functions is a possible way of dealing with
this problem. Additionally, cross-modality TL, such as from
image to audio, can be another potential solution to DDTL
problem since semantic information can also exist in different
cross-modality domains. Solving this problem can expand the
use of transfer learning to an even higher level. Furthermore,
for multi-source DDTL algorithms, source domain selection is
important to stabilize the performance. Recently, active learning methods attract more and more attention from researchers.
Finally, using medical CT images from other diseases as the
source domain might or might be able to produce better
results because seemingly related domains can also have large
discrepancies in the feature level. Moreover, image data sets
are usually not easy to access, so it is not always feasible to

FIRST A. AUTHOR et al.: BARE DEMO OF IEEETAI.CLS FOR IEEE JOURNALS OF JOURNAL OF BIOMEDICAL HEALTH INFORMATICS

11

TABLE VII: DFF Performance
DFF

Accuracy

Precision

Recall

F1

Single Source
Multi-Source
Segmented Multi-Source

0.86
0.88
0.96

0.92
0.92
0.97

0.86
0.93
0.98

0.88
0.92
0.97

develop a TL model by using medical image data from other
diseases. Therefore, granting access to medical image data
sets to the public and generating distribution shift embedded
artificial data is a promising future research direction in the
field of medical image processing.
R EFERENCES
[1] B. Sun and K. Saenko, “Deep coral: Correlation alignment for deep domain adaptation,” in European conference on computer vision. Springer,
2016, pp. 443–450.
[2] H.-C. Shin, H. R. Roth, M. Gao, L. Lu, Z. Xu, I. Nogues, J. Yao,
D. Mollura, and R. M. Summers, “Deep convolutional neural networks
for computer-aided detection: Cnn architectures, dataset characteristics
and transfer learning,” IEEE transactions on medical imaging, vol. 35,
no. 5, pp. 1285–1298, 2016.
[3] V. Cheplygina, M. de Bruijne, and J. P. Pluim, “Not-so-supervised:
a survey of semi-supervised, multi-instance, and transfer learning in
medical image analysis,” Medical image analysis, vol. 54, pp. 280–296,
2019.
[4] J. N. Taroni, P. C. Grayson, Q. Hu, S. Eddy, M. Kretzler, P. A.
Merkel, and C. S. Greene, “Multiplier: a transfer learning framework for
transcriptomics reveals systemic features of rare disease,” Cell systems,
vol. 8, no. 5, pp. 380–394, 2019.
[5] W. Pan, E. W. Xiang, N. N. Liu, and Q. Yang, “Transfer learning in
collaborative filtering for sparsity reduction,” in Twenty-fourth AAAI
conference on artificial intelligence, 2010.
[6] W. Pan, N. N. Liu, E. W. Xiang, and Q. Yang, “Transfer learning to
predict missing ratings via heterogeneous user feedbacks,” in TwentySecond International Joint Conference on Artificial Intelligence, 2011.
[7] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Transactions on knowledge and data engineering, vol. 22, no. 10, pp. 1345–
1359, 2009.
[8] B. Tan, Y. Song, E. Zhong, and Q. Yang, “Transitive transfer learning,”
in Proceedings of the 21th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, 2015, pp. 1155–1164.
[9] B. Tan, Y. Zhang, S. J. Pan, and Q. Yang, “Distant domain transfer
learning,” in Thirty-First AAAI Conference on Artificial Intelligence,
2017.
[10] Z. Zhang, P. Luo, C. C. Loy, and X. Tang, “Facial landmark detection by
deep multi-task learning,” in European conference on computer vision.
Springer, 2014, pp. 94–108.
[11] L. Ge, J. Gao, H. Ngo, K. Li, and A. Zhang, “On handling negative transfer and imbalanced distributions in multiple source transfer learning,”
Statistical Analysis and Data Mining: The ASA Data Science Journal,
vol. 7, no. 4, pp. 254–271, 2014.
[12] M. Long, H. Zhu, J. Wang, and M. I. Jordan, “Deep transfer learning
with joint adaptation networks,” in Proceedings of the 34th International
Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp.
2208–2217.
[13] S. Niu, J. Wang, Y. Liu, and H. Song, “Transfer learning based DataEfficient machine learning enabled classification,” in The 6th International Conference on Cloud and Big Data Computing (2020) (CBDCom
2020), Aug. 2020.
[14] N. S. S. H. Liu Y., Wang J., “(2020) deep learning enabled reliable
identity verification and spoofing detection,” 2020.
[15] W. Zhang, R. Li, T. Zeng, Q. Sun, S. Kumar, J. Ye, and S. Ji,
“Deep model based transfer and multi-task learning for biological image
analysis,” IEEE transactions on Big Data, 2016.
[16] M. Xie, N. Jean, M. Burke, D. Lobell, and S. Ermon, “Transfer learning
from deep features for remote sensing and poverty mapping,” in Thirtieth
AAAI Conference on Artificial Intelligence, 2016.
[17] A. Bernheim, X. Mei, M. Huang, Y. Yang, Z. Fayad, N. Zhang, K. Diao,
B. Lin, X. Zhu, K. Li, S. Li, H. Shan, A. Jacobi, and M. Chung, “Chest
ct findings in coronavirus disease-19 (covid-19): Relationship to duration
of infection,” Radiology, vol. 295, p. 200463, 02 2020.

[18] X. He, X. Yang, S. Zhang, J. Zhao, Y. Zhang, E. Xing, and P. Xie,
“Sample-efficient deep learning for covid-19 diagnosis based on ct
scans,” medrxiv, 2020.
[19] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, “A simple framework for contrastive learning of visual representations,” arXiv preprint
arXiv:2002.05709, 2020.
[20] M. Barstugan, U. Ozkaya, and S. Ozturk, “Coronavirus (covid-19)
classification using ct images by machine learning methods,” arXiv
preprint arXiv:2003.09424, 2020.
[21] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in International Conference on
Medical image computing and computer-assisted intervention. Springer,
2015, pp. 234–241.
[22] V. Turchenko, E. Chalmers, and A. Luczak, “A deep convolutional
auto-encoder with pooling-unpooling layers in caffe,” arXiv preprint
arXiv:1701.04949, 2017.
[23] K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel, B. Schölkopf,
and A. J. Smola, “Integrating structured biological data by kernel
maximum mean discrepancy,” Bioinformatics, vol. 22, no. 14, pp. e49–
e57, 2006.
[24] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” in Advances in neural information processing systems, 2012, pp. 1097–1105.
[25] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in 2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR), 2016, pp. 770–778.
[26] G. Griffin, A. Holub, and P. Perona, “Caltech-256 object category
dataset,” 2007.
[27] Y. Zhao, H. Ali, and R. Vidal, “Stretching domain adaptation: How far
is too far?” ArXiv, vol. abs/1712.02286, 2017.
[28] D. S. Kermany, M. Goldbaum, W. Cai, C. C. Valentim, H. Liang, S. L.
Baxter, A. McKeown, G. Yang, X. Wu, F. Yan et al., “Identifying
medical diagnoses and treatable diseases by image-based deep learning,”
Cell, vol. 172, no. 5, pp. 1122–1131, 2018.
[29] S. G. Armato III, G. McLennan, L. Bidaut, M. F. McNitt-Gray, C. R.
Meyer, A. P. Reeves, B. Zhao, D. R. Aberle, C. I. Henschke, E. A.
Hoffman et al., “The lung image database consortium (lidc) and image
database resource initiative (idri): a completed reference database of
lung nodules on ct scans,” Medical physics, vol. 38, no. 2, pp. 915–931,
2011.
[30] J. Zhao, Y. Zhang, X. He, and P. Xie, “Covid-ct-dataset: a ct scan dataset
about covid-19,” arXiv preprint arXiv:2003.13865, 2020.

