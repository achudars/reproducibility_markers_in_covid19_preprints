CAUSAL INFERENCE IN THE TIME OF COVID-19

*

B Y M ATTEO B ONVINI 1,* , E DWARD H. K ENNEDY 1,† VALERIE V ENTURA
1,2,‡
AND L ARRY WASSERMAN 1,2,§
1 Department of Statistics and Data Science, Carnegie Mellon University
2 Delphi Group, Carnegie Mellon University

*

MBONVINI @ STAT. CMU . EDU ; † EDWARD @ STAT. CMU . EDU ;
VVENTURA @ STAT. CMU . EDU ; § LARRY @ STAT. CMU . EDU

arXiv:2103.04472v1 [stat.ME] 7 Mar 2021

‡

March 7 2021
In this paper we develop statistical methods for causal inference in epidemics. Our focus is in estimating the effect of social mobility on deaths in
the Covid-19 pandemic. We propose a marginal structural model motivated
by a modified version of a basic epidemic model. We estimate the counterfactual time series of deaths under interventions on mobility. We conduct
several types of sensitivity analyses. We find that the data support the idea
that reduced mobility causes reduced deaths, but the conclusion comes with
caveats. There is evidence of sensitivity to model misspecification and unmeasured confounding which implies that the size of the causal effect needs
to be interpreted with caution. While there is little doubt the the effect is real,
our work highlights the challenges in drawing causal inferences from pandemic data.

1. Introduction. During a pandemic, it is reasonable to expect that reduced social mobility will lead to fewer deaths. But how do we quantify this effect? In this paper we combine
mechanistic epidemic models with modern causal inference tools to answer this question using state level data on deaths and mobility. Our goal is not to provide definitive estimates
for the effects but rather to develop some methods and highlight the challenges in doing
causal inference for pandemics. We also show how a generative epidemic model motivates a
semiparametric causal model.
Epidemics are usually modeled by using outcome models (or generative models), which
fully specify the distribution of the outcome (deaths). The most common epidemic model
relates exposure, infections, recoveries and deaths by way of a set of differential equations.
The simplest version is the SIR model (susceptible, infected, recovered) but there are many
flavors of the model. We review the basic model in Section 4.
Instead of an outcome model, we use a marginal structural model (MSM) (Robins, Hernan
and Brumback (2000); Robins (2000)). An MSM is a semiparametric model that directly
models the effect of mobility on death without specifying an outcome model. Because it is
semiparametric, it makes fewer assumptions than an outcome model. However, our MSM is
motivated by a modified SIR-type outcome model.
We model deaths in each state separately to reduce confounding due to state differences.
After obtaining model parameter estimates for each state, we estimate counterfactual quantities such as: how many deaths would have occurred if mobility had been reduced earlier, or
if people had remained more vigilant throughout? Finally, we conduct a thorough sensitivity
* Ventura and Wasserman are members of the Delphi Group at CMU delphi.cmu.edu. This project arose
from their work with Delphi. We are grateful for their help and support. We thank Rob Tibshirani for suggestions
that greatly improved the paper. All the data can be obtained from the Delphi website covidcast.cmu.edu.
Keywords and phrases: Causal Inference, Marginal Structural Model, Covid-19.

1

2

analysis to explore the potential impact of model assumptions, model misspecification and
unobserved confounding.
We will see that the data provide evidence for an effect of mobility. But the data are very
limited. As mentioned above, we use state-specific models with weekly resolution due to
concerns about data quality and unmeasured confounding due to geographic differences. The
result is that we have about 40 observations per state. With so little data, we are restricted
to use fairly simple models. We do find significant causal effects but we conduct sensitivity
analyses that show that the effects need to be interpreted cautiously.
Related Work. A number of researchers have considered modeling the effect of interventions on the spread of Covid-19. Notable examples are Unwin et al. (2020), Chang et al.
(2020), and IHME (2020). These authors develop very detailed epidemic models of the dynamics of the disease. One advantage of such an approach is that one can then consider the
effects of a large array of potential interventions. Further, the models themselves are of great
interest for understanding the progression of Covid-19. However, these models are very complex, and they involve a large number of parameters including parameters for various latent
variables. Fitting such models and assessing uncertainty is challenging. Some authors take a
Bayesian approach with informative priors. Others use heuristics such as reporting intervals
based on using various settings of the parameters. To the best of our knowledge, it is not
known how to get valid, frequentist confidence intervals in these complex models. This is not
meant as a criticism of these papers but rather, this reflects the intrinsic difficulty of dealing
with such models.
In contrast, our goal is to make the model as simple as possible and to use standard estimating equation methods so that standard errors can be obtained fairly easily. We do not
claim that our approach is superior but we do believe that the model and the resulting confidence intervals are more transparent. Getting precise results from our simple model turns
out to be challenging and raises doubts about the accuracy of published studies using highly
complex models.
The papers by Chernozhukov, Kasaha and Schrimpf (2020) and Xiong et al. (2020) are
much closer to ours. The authors of Chernozhukov, Kasaha and Schrimpf (2020) use a set
of causal linear structural equations to model weekly cases as a function of social behavior
(mobility) and social behavior as a function of policies. They model several policies simultaneously and they model all states simultaneously. They do obtain valid frequentist confidence
intervals. Xiong et al. (2020) construct a measure of mobility inflow and using daily county
level cases they fit a linear structural model to relate cases to mobility inflow. Our approach
differs in several ways: we model deaths, we focus only on the effect of mobility, we model
one state at a time, and we use a MSM rather than a regression outcome model. By modeling within each state, we have much less data at our disposal, which makes modeling very
challenging. On the other hand, the threat of confounding due to state differences is reduced.
By using a marginal structural model, our approach is semiparametric and so makes fewer
assumptions. We focus on deaths instead of cases because we find the data on cases to be
quite unreliable in general; for example, the availability of testing changed over time in various ways within and across states. Also, we place a strong emphasis on sensitivity analysis.
These analyses complement each other nicely.
Paper Outline. We describe the data in Section 2. In Section 3 we review some basics of
causal inference. In Section 4 we construct the models that we will use and we explain how
the models are fit in Section 5. The results are presented in Section 6. Concluding remarks
are in Section 7.

3

0.50

CAUSAL INFERENCE IN THE TIME OF COVID

0

10

20

30

40

0.40
0.35
0.30

Deaths (log−scale)

0

New York
Florida
Texas
California

0.25

4
2

Deaths (log−scale)

6

0.45

8

New York
Florida
Texas
California

0

Time

10

20

30

40

Time

F IG 1. Left: Plot of log deaths versus time (weeks), from Feb 15 2020 (week 1) to December 25 2020 (week 45),
for four populous states. Right: Plot of a anti-mobility measure called “stay at home” versus week.

2. Data. As mentioned earlier, we model each state separately, at the weekly level. The
data are available at the daily county level but the weekly state level data are more reliable.
Indeed, the data are subject to many reporting issues. It is not uncommon for a state to fail
to report many deaths for a period and then suddenly report a bunch of unreported deaths
on a single day. The problems are worse at the county level. Also, there are many small
counties with very little data. We find using weekly state level data to be a good compromise
between the quantity and quality of the data. We also note that epidemic analyses, such as flu
surveillance, are generally done at the weekly level.
The data for each state have the form
(A1 , Y1 ), . . . , (AT , YT )

where At is mobility on week t and Yt is the number of deaths due to Covid-19 on week t. We
obtain our data from CMU’s Delphi group (cmu.covidcast.edu) which gets the death
data from Johns Hopkins (https://coronavirus.jhu.edu) and the mobility data
from Safegraph (safegraph.com). The data are from Feb 15 2020 (week 1) to December
25 2020 (week 45).
Figure 1 shows log deaths Lt = log(Yt + 1) and “proportion at home” At which is one
of the mobility measures, for four states. This is the fraction of mobile devices that did not
leave the immediate area of their home. In this case, a higher value means less mobility so
we can think of this measure as anti-mobility. This is the variable we will use throughout. In
the rest of the paper we standardize mobility by subtracting A1 from each value of At so that
mobility starts at zero.
3. Causal Inference. In this section, we briefly review basic ideas from causal inference.
Consider weekly mobility and death data (A1 , Y1 ), . . . , (AT , YT ) in one state. Define At =
(A1 , . . . , At ) and Y t = (Y1 , . . . , Yt ) for t ≥ 1.
Now consider the causal question: what would Yt be if we set At equal to some value at =
(a1 , . . . , at )? Let Ytat denote this counterfactual quantity. It is important to distinguish the
observed data (AT , Y T ) from the collection of unobserved counterfactual random variables
n
o
Y aT : aT ∈ RT ,

4

which is an infinite collection of random vectors, one for each possible mobility trajectory
AT

aT . We make the usual consistency assumption that Y T = Y T . To make sure this is clear,
consider a simple case where a subject gets either treatment A = 1 or control A = 0. In
this case, the random variables are (A, Y, Y 0 , Y 1 ) and the consistency assumption is that the
observed outcome Y satisfies Y = Y 1 if A = 1 and Y = Y 0 if A = 0.
Causal inference when the treatment varies over time is subtle. It may be tempting to
simply regress YT on the past and get the regression coefficient for mobility. This strategy
has serious problems because Y T −1 are both confounding and mediating variables. Indeed,
previous deaths can affect both future mobility and future deaths, while also being affected
by previous mobility. More precisely, a large number of deaths implies a large number of
infections which can cause future infections which then cause future deaths, and a large
number of deaths might scare people into staying home. So we must adjust for past deaths.
A common principle in epidemiology is to adjust for pre-treatment variables but not for posttreatment variables. But Ys comes after As−1 and before As+1 making it both a pre-treatment
and post-treatment variable. So how do we properly define the causal effect?
The solution is to use Robins’ g -formula. Assuming for the moment that there are no other
confounding variables except past deaths, Robins (1986) proved that the mean of Ytat is given
by the g-formula:
Z
Z
t−1
Y
at
(1)
ψ(at ) ≡ E[Yt ] = · · · E[Yt |At = at , Y t−1 = y t−1 ]
p(ys |y s−1 , as ) dys .
s=1

Some authors denote E[Ytat ] by E[Yt |do(at )]. When there are other confounders Xt besides
past deaths, the formula becomes
Z
Z
t−1
Y
p(ys , xs |y s−1 , as , xs−1 ) dys dxs .
ψ(at ) ≡ · · · E[Yt |At = at , Y t−1 = y t−1 , X t−1 = xt−1 ]
s=1

Intuitively, the g -formula can be obtained as follows. The density of (y t , at ) can be written
as
(2)

p(y t , at ) =

t
Y

p(ys |y s−1 , as )p(as |as−1 , y s−1 ).

s=1

Now replace p(as |as−1 , y s−1 ) with a point mass at as and then find of the mean of Yt from
this new distribution. It will be useful later in the paper to bear in mind that ψ(at ) ≡ ψ(at , p)
is a functional of the joint density p from (2).
The next question is: how do we estimate ψ(at )? A natural idea is to plug-in estimates of
all the unknown quantities in the g -formula which leads to
Z
Z
t−1
Y
b
b
(3)
ψ(at ) ≡ · · · E[Yt |At = at , Y t−1 = y t−1 ]
pb(ys |y s−1 , as ) dys .
s=1

As discussed in Robins, Hernan and Brumback (2000); Robins (2000, 1989) there are a
number of problems with this approach, called g-computation. If we plug-in nonparametric
estimates, we quickly face the curse of dimensionality. If we use parametric estimates, we
encounter the null-paradox (Robins and Wasserman (1997)): there may be no setting of the
parameters which can represent the case where there is no treatment effect, i.e., there is no
setting of the parameters which makes ψ(at ) a constant function of at .
An alternative approach to estimating ψ(at ) (Robins, Hernan and Brumback (2000)) is to
directly specify a parametric functional form g(at , β) for ψ(at ). Such a model is called a

CAUSAL INFERENCE IN THE TIME OF COVID

5

marginal structural model (MSM). Robins, Hernan and Brumback (2000) showed that β can
be estimated by solving the following inverse-probability-weighted estimating equation:
X
b = 0,
(4)
Wt∗ h∗ (At )(Yt − g(At , β))
t

where the function h∗ will be described shortly and the weights Wt∗ are defined by
Wt∗ =

(5)

t
Y

1

s=1

π(As |As−1 , Y s−1 )

,

where π(at |·) is the conditional density of mobility, assumed to be positive. For notational
simplicity, we dropped the potential dependence on t in the functions g(at , β) = gt (at , β)
and h∗ (at ) = h∗t (at ), however they do differ across timepoints.
If the MSM is correctly specified, the function h∗ (at ) is arbitrary; each choice of h yields
a consistent estimator. However, the choice of h∗ affects the efficiency of the estimator. We
follow the common practice of choosing a stabilized h∗ of the form
h∗ (at ) = h(at )

t
Y

π(As | As−1 )

s=1

for some h; a common choice is h(at ) = ∂g(at , β)/∂β . We will then find it convenient to
rewrite (4) as
X
b =0
Wt h(At )(Yt − g(At , β))
(6)
t

where
Wt =

(7)

t
Y

π(As |As−1 )
.
π(As |As−1 , Y s−1 )
s=1

We refer to Wt as the stabilized weights.
R EMARK . There is a difference between the standard MSM setup and the one we are
considering that warrants mentioning. Typically one assumes access to n different time series (Z1 , ..., Zn ), with each series Z = {(A1 , Y1 ), ..., (AT , YT )} = (AT , Y T ) observed for n
different independent units (e.g., states). There, one could have a different estimating equation at each time, for example,
X
b =0
Wti ht (Ati )(Yti − gt (Ati , β))
i

where the i subscript denotes weights, treatments, outcomes, etc. for series i. If there are
common parameters across timepoints, then these estimating equations could be combined,
for example by summing over time, or using a generalized method of moments approach, etc.
However, we model states individually, and so do not assume different states are independent.
This leaves us with one observation per state at each time, which we then combine across time
(but only within state) to obtain estimating equation (6). This represents the trade-off between
independence versus modeling assumptions (e.g., Markov assumptions in the weights, or
linearity in g(·)): the less we require of one, the more we require of the other.

6

An MSM is a semiparametric model in the sense that it leaves the data generating process
unspecified, subject to the restriction that the functional ψ(at ) has a specific form. Specifically, let us write ψ(at ) as ψ(at , p) to make it clear that ψ(at , p) depends on the joint density
of the data p(aT , y T ) from (2). The model we are using is then
n
o
(8)
P = p(aT , y T ) : there exists β such that ψ(at , p) = g(at , β) for all t .
The model
P g is typically chosen to be interpretable. For example, suppose that g(at , β) =
β0 + β1 s as . Then the effect of the parameter settings is simple (i.e., mean outcomes only
depend linearly on the amount of cumulative treatment), and the null (of no treatment effect)
simply corresponds to β1 = 0. It is important to keep in mind that this is not a model for the
entire data generating process, just for marginal treatment effects, i.e., how mean outcomes
under different treatment sequences are connected. In the next section we introduce an MSM
motivated by an epidemic SIR model.
4. Models. Epidemics are often modeled using differential equations that describe the
evolution of certain subgroups over time. Perhaps the most common is the SIR (Susceptible,
Infected, Recovered) model (Kermack and McKendrick (1927), Brauer, Castillo-Chavez and
Castillo-Chavez (2012), Bjørnstad (2018)) described by the equations
dSt
αIt St
=−
dt
N
dIt αIt St
=
− γIt
dt
N
dRt
= γIt ,
dt
where N is population size, St is the number of susceptibles, It is the number of infected
and Rt are the removed (by death or recovery) at time t. Solving the second equation conSt
ditional on St yields It = It−1 eα N −γ , showing that, without any interventions, It grows exponentially. There are numerous generalizations of this model including stochastic versions,
discretized versions and models with more states besides S , I and R.

4.1. The Mobility Model. Our proposed MSM is
g(at , ν0 , ‫ג‬, f ) =

t
X

f (s, t)eν0 (s)+

Ps
r=1

‫(ג‬ar )

s=1

with nuisance functions f , ν0 and ‫ג‬. The model is motivated by the SIR model.
The basic idea of the SIR model is that there is a natural tendency for an epidemic to increase exponentially at the beginning. But there are also elements that reduce the epidemic
such as the depletion of susceptible individuals due to recovery and death. At the beginning
of a pandemic, reduction of susceptibles will play a negligible role. On the other hand, interventions like lockdowns, school closings etc can have a drastic effect. These considerations
lead us to the following initial model.
Let It denote new infections in week t. Let

(9)

It = ect +‫(ג‬At ) It−1 + δt
P
Yt = ts=1 f (s, t)Is + ξt

where δt and ξt are mean 0 random variables, f (s, t) denotes the probability that someone
infected at time s dies at time t, the parameter ct is a positive number and ‫ ג‬is a smooth

CAUSAL INFERENCE IN THE TIME OF COVID

7

function. Here, ct represents the evolution of the epidemic without intervention and ‫(ג‬At )
is the effect of mobility. We allow ct to vary with t to make the model more general and to
allow the spread of Covid-19 to depend on the availability of susceptibles. We write
f (s, t) = d(s)f0 (s, t)

(10)

where d(s) is the probability that someone infected at time s will eventually die and f (s, t)
is the probability that someone infected at time s and who will eventually die, will die at time
t. Following Unwin et al. (2020) we take f0 (s, t), on the scale of days, to be the density of
T1 + T2 where T1 (time from infection to symptoms) is Gamma with mean 5.1 and coefficient
of variation 0.86 and T2 (time from symptoms to death) is Gamma with mean 18.8 and
coefficient of variation 0.45. The resulting distribution can be accurately approximated by
a Gamma with mean 23.9 days and coefficient of variation 0.40. Finally, we integrate this
distribution over 7 day bins to get f (s, t) on a weekly scale.
At this point, it would be tempting to compute µt = E[Yt |At = at , Y t−1 = y t−1 ] and use
µt as the basis of inference. But there are two problems. Computing µt and applying the
g -formula in (1) to µt may be intractable. But more importantly, a non-linear, sequentially
specified parametric outcome model can suffer from serious anomalies when used for causal
inference. In particular, such a model can suffer from the null paradox (Robins (1986, 1989);
Robins and Wasserman (1997)). This means that there may be no parameter values that satisfy
(i) Yt is conditionally dependent on past values of As and such that (ii) the null hypothesis of
no treatment effect holds. We explain this point in more detail in the discussion.
Instead, we will find E[Yt |At = at ] and use the resulting function as an MSM. To find
E[Yt |At = at ], we recurse the first equation in (9) and substitute the result into the second
equation to arrive at
(11)

Yt =

t
X

Ps

f (s, t)eν0 (s)+

r=1

‫(ג‬Ar )

+ t

s=1

P
for some mean 0 random variable t , and ν0 (s) = log I1 + sr=1 cr . The latent variables It
disappear except for I1 which has been absorbed into the function ν0 (s). Hence
(12)

E[Yt |At = at ] =

t
X

Ps

f (s, t)eν0 (s)+

r=1

‫(ג‬ar )

= g(at , ν0 , ‫ג‬, f ).

s=1

Now we abandon the initial model and just interpret g(at , ν0 , ‫ג‬, f ) directly as a model for the
counterfactual E[Y at ], that is, as a MSM.
The MSM can be fit with the estimating equation (6), which corrects for confounding due
to past deaths not by modeling the entire conditional outcome process, but by weighting by
propensity weights Wt given by (7). This MSM approach allows us to be agnostic about
whether it is our motivating model that holds, or some other much more complicated datagenerating process. In fact, one can go further and take a completely agnostic view, in which
the marginal structural model is not assumed correct at all, but only viewed as an approximation to the true, and possibly very complex, underlying counterfactual mean (Neugebauer
and van der Laan, 2007).
4.2. Simplified Models. The model in (12) is not identified without further constraints.
We will take ‫(ג‬As ) = βAs so that
E[Ytat ] =

t
X
s=1

f (s, t)eβ

Ps
r=1

Ar +ν0 (s)

.

8

This model is difficult to deal with numerically so we consider two approximations. First, we
take f0 (s, t) in (10) to be a point mass at δ = 4 weeks (approximately its mean). Then we get
E[Ytat ] = ed(t−δ)+ν0 (t−δ)+βMt
where Mt ≡ M (at ) =
obtain
(13)

Pt−δ

s=1 as .

If we approximate log E[Ytat ] with E[log(Ytat )] we further

E[Lat t ] = log d(t − δ) + ν0 (t − δ) + βMt

where Lt = log(Yt + 1). Finally, we take
ν(t) ≡ log d(t − δ) + ν0 (t − δ) =

k
X

βj ψj (t)

j=1

where ψ1 , . . . , ψk are orthogonal polynomials starting with ψ1 (t) = t. This model is easy to
fit and will be used in Section 6. Note that the probability of dying d(t) is allowed to change
smoothly over time, which it likely did as hospitals were better prepared during the second
wave. Interestingly, we have consistently found that using k = 1 leads to unreasonable results
as we discuss in Section 6 but taking k > 1 solves this problems. The method for choosing
k is described in Section 6.2. Note that ∂ E[Lat t ]/∂as = β for any s ≤ t − δ so β has a clear
meaning.
The model in (13) was used independently in Shi and Ban (2020) with k = 1. They used
the model for curve fitting and they showed that this simple model fits the data surprisingly
well. However, we find that making ν(t) non-linear seems to be important.
We will also consider a different approach to fitting the model. Specifically, we will use deconvolution methods to estimate the
P unobserved infection process I1 , . . . , IT . The first equation in (9) implies E[It ] = eν(t)+β s As suggesting the MSM
E[Lat t ] = ν(t) + βMt
which is the same as (13) except that now Lt = log(It ) and Mt =
Pt−δ
s=1 as .

Pt

s=1 as

rather than Mt =

R EMARK . We have regularized the model by restricting ν(t) to have a finite basis expansion. We also considered a different approach in which ν(t) is restricted to be increasing
which seems a natural restriction if ν(t) is supposed to represent the growth of the pandemic
in lieu of intervention. Using the methods in Meyer et al. (2008, 2018); Liao and Meyer
(2018) we obtained estimates and standard errors. The results are very similar to the results
in Section 6.

Counterfactual Estimands. Now we discuss some causal quantities that we can estimate
from the model. Let at = (a1 , . . . , at ) be a mobility profile of interest. After fitting the model
we will plot estimates and confidence intervals for counterfactual deaths
n
o
(14)
θt = exp E[Lat ]
under mobility regime at , t = 1, . . . , T .
We will consider the following three interventions:
Start one week earlier : aT = (A2 , A3 , . . . , , AT +1 )
Start two weeks earlier : aT = (A3 , A4 , . . . , AT +2 )
Stay vigilant : aT = (A1 , A2 , . . . , A9 , A10 , A10 , A11 , A11 , A12 , A12 , A13 , A13 , . . .)

CAUSAL INFERENCE IN THE TIME OF COVID

9

The first two interventions aim to assess COVID-19 infections if we had started sheltering in
place one and two weeks earlier. The last intervention halves the slope of the rapid decrease
in stay at home mobility after the initial peak in week 9 that is clearly visible in Fig.1.
5. Fitting the Model. Now we discuss the method for estimating the model.
5.1. Fitting the Semiparametric Model. Recall the MSM
E[Lat t ] = ν(t) + βM (at )

(15)
where ν(t) =
(16)

Pk

j=1 βj ψj (t).

X

We estimate ν(t) and β by solving the estimating equation
b (at ))] = 0
ht (at )Wt [Lt − (νb(t) + βM

t

corresponding to (6). We discuss the estimation of the weights Wt in Section 5.2. As is often
done for MSMs we choose
ht (at ) = (1, ψ1 (t), . . . , ψk (t), M (at ))T

since solving the estimating equation then corresponds to using least squares with weights
Wt . Note that the estimating equation is the derivative of the weighted sum of squares set to
zero.
b
Recall from (14) that θt = eψ(at ) = eν(t)+βM (at ) which we estimate by θbt = eνb(t)+βM (at ) .
We obtain approximate confidence intervals using the delta method. The asymptotic variance
is based on the sandwich estimator.
5.2. Estimating the Stabilized Weights. To estimate the marginal structural model we
need to estimate the weights
Wt =

t
Y

π(As |As−1 )
.
π(As |As−1 , Y s−1 )
s=1

(We remind the reader that Wt denotes the stabilized weights which includes the numerator
density; see (5) and (7)). One approach is to plug in estimates of the densities into the formula
for Wt . But estimating these densities is not easy and ratios of density estimates can be
unstable. The problem is exacerbated when we multiply densities. Instead we use a momentbased approach as in Fong et al. (2018); Zhou and Wodtke (2018). The idea is to estimate the
vector of weights W1 , . . . , WT by noting that they need to satisfy certain moment constraints.
Our method is similar
Qto the approach in Zhou and Wodtke (2018).
We rewrite Wt = ts=1 Vs where
Vs ≡ Vs (As , Y s−1 ) =

π(As |As−1 )
.
π(As |As−1 , Y s−1 )

Let e
h1 (at ) and e
h2 (yt−1 ) be arbitrary functions and define their centered versions by
h1 (at ) = e
h1 (at ) − µt
h2 (yt−1 ) = e
h2 (yt−1 ) − νt

where the conditional means are
µt ≡ µt (At−1 ) = E[e
h1 (At )|At−1 ]
νt ≡ νt (At−δ−1 , Y t−2 ) = E[e
h2 (Yt−1 )|At−δ−1 , Y t−2 ].

10

Weighted products of these functions have mean zero since
Z
Z
E[h1 (At )h2 (Yt−1 )Wt ] = · · · h1 (at )h2 (yt−1 )p(at , y t−1 )Wt (at , y t−1 ) dat dy t−1
Z
Z
= · · · h1 (at )h2 (yt−1 )π(at |at−1 , y t−1 )p(yt−1 |at−1 , y t−2 )p(at−1 , y t−2 )
π(at |at−1 )
×
π(at |at−1 , y t−1 )

t−1
Y

!
dat dy t−1

Vs

s=1

)
Z (
Z
Z
=
ω(y t−2 , at−1 ) h1 (at )π(at |at−1 )dat
h2 (yt−1 )p(yt−1 |at−1 , y t−2 )dyt−1 dat−1 dy t−2
=0

from the definition of h1 and h2 , where
ω(y t−2 , at−1 ) = p(y t−2 , at−1 )

t−1
Y

Vs .

s=1

Thus, the weights are characterized by the moment constraints
(17)

E[h1 (At )h2 (Yt−1 )Wt ] = 0.

As in Zhou and Wodtke (2018) we estimate the weights by finding Wt to satisfy
E[h1 (At )h2 (Yt−1 )Wt ] = 0 for a set of functions h1 , h2 . This requires estimating these moments and estimating µt and νt . To proceed, we make a Markov assumption, namely
h1 (At )|At−1 , . . . , At−k ]
E[e
h1 (At )|At−1 ] = E[e

and
h2 (Yt−1 )|At−1−δ , . . . , At−k−δ , Yt−2 , . . . , Yt−k ]
E[e
h2 (Yt−1 )|At−δ−1 , Y t−2 ] = E[e

for some k . We will use k = 1 in our analysis. Moreover, we assume homogeneity so that the
functions µt and νt do not depend on t. Under the homogeneous Markov assumption, µ and
ν can be estimated by regression. For example, if k = 1, µ can be estimated by regressing
e
h1 (A2 ), . . . , e
h1 (AT ) on A1 , . . . , AT −1 . (We tried both linear and nonparametric regression
and obtained similar weights from each approach so we have used linear regression in our
results.) The sample versions of the moment conditions (17) are then
1X
Htj Wt = 0
T t
where
Htj = (e
h1j (At ) − µ
bj ))(e
h2j (Yt−1 ) − νbj )

and {(e
h1j , e
h2j ) : j = 1, . . . , J} are a set of pairs of functions, µ
bj is the estimate of
e
e
E[h1 (At )|At−1 , . . . , At−k ] and νbj is the estimate of E[h2 (Yt−1 )|At−1−δ , . . . , At−k−δ , Yt−2 , . . . , Yt−k ].
The moment conditions do not completely specify
P the weights. As in the above
Preferences
we add a regularization term, in this case, (1/2) t (Wt − 1)2 and we require t Wt = T .
This leads to the following minimization problem: minimize W1 , . . . , WT in
J

(18)

X
X X
1X
(1 − Wt )2 + λ0
(Wt − T ) +
λj
Wt Htj
2 t
t
t
j=1

CAUSAL INFERENCE IN THE TIME OF COVID

11

1. Choose the order k of the Markov
assumption.
n
o
2. Choose J pairs of functions (e
h1j (a), e
h1j (y)) : j = 1, . . . J .
3. Estimate µj = E[e
h1j (At )|At−k , . . . , At−1 ] and νj = E[e
h2j (Yt−1 )|At−k−δ−1 , . . . , At−δ−1 , Yt−1−k , . . . , Yt−2 ]
by regression.
4. Compute the weights W1 , . . . , Wn from (19).
P
5. Fit the model Lt = β t−δ
i=1 As + ν(t) + t using weighed least squares with weights W1 , . . . , Wn .
F IG 2. Steps for fitting the model.

where the λj ’s are Lagrange multipliers. The solution to the minimization is
(19)

W = 1 − H(H T H)−1 [H T 1 − D]

where W = (W1 , . . . , WT ), 1 is a vector of 10 s, D = (T, 0, . . . , 0)T and


1 H11 · · · H1N
 1 H21 · · · H2N 


H =  .. ..
.
.. 
 . . ..
. 
1 HT 1 · · · HT N

and N is the total number of moment constraints. In our case we choose h11 (a) = a, h12 (a) =
a2 , h21 (y) = y , h22 (y) = y 2 .
To include other time varying confounders Xt one should replace h2 (yt−1 ) with two functions:
h2 (yt−1 ) = e
h2 (yt−1 ) − E[e
h2 (yt−1 )|X t−1 , At−1 , Y t−2 ]

and
h3 (xt−1 ) = e
h3 (xt−1 ) − E[e
h3 (xt−1 )|X t−2 , At−1 , Y t−2 ].

The steps for fitting the model are summarized in Fig.(2).
6. Results. In this section we give results for the mobility measure ‘proportion of people
staying at home.’ We begin by showing the results of fitting the MSM to each state. Then we
report on various types of sensitivity analysis.
6.1. Main Results. Figure 3 shows 95 percent confidence intervals for βb for each state
from the marginal structural model in (15). We computed standard errors as if the weights
were known, which results in valid but potentially conservative inference as long as the
weight models are correctly specified (Tsiatis, 2007). The estimates are mostly negative,
as would be expected, since higher As means less mobility. Interestingly, we find that there
turns out to be little confounding due to past deaths, as the fits with and without the estimated
weights (not shown) are very similar. Nevertheless, we keep the weights in all the fits as a
safeguard. In Section 6.2 we investigate this further by doing a sensitivity analysis.
Figure 4 shows the estimated smooth function νb(t) in (15) for four states. The functions are
strictly increasing and nearly, but not quite, linear. This is consistent with the usual epidemic
dynamics where it is assumed that this component should grow linearly on the log-scale. The
non-linearity probably reflects the fact that the probability d(t) of dying decreases over time
due to better hospital treatment, and the number of susceptibles to COVID-19 also decreases
over time as recovered patients are likely immune for some period post-infection. Interestingly, if ν(t) is forced to be linear for all states (constant exponential growth), it causes many

0

β

5

10

12

●

●

●
●

●
●

●

●
●
●

●
●

−5

●
●

●
●

●

●

●

●

●

●
●
●
●
●

●

●

●

●

●

●

●

●
●

●

●

● ●

●

●

●

●
●

−10

●

●
●
●
●
●

14

15

16

17

Log Population

F IG 3. Plot of βb and 95 percent confidence interval from the marginal structural model (15) for each state, versus
state log population. A value of β = −5, for example, means that log deaths are reduced by 5 if As is increased
by one percent at any time s.

−15

−10

−5

ν(t)

0

5

10

New York
Florida
Texas
California

0

10

20

30

40

Time

F IG 4. Plot of νb(t) for four states.

of the βb’s to become positive which seems impossible. Allowing some non-linearity means
that we only assume locally constant exponential growth which is both a weaker assumption
than is usually made and leads to more reasonable estimates of β .
Next we consider counterfactual deaths θt = exp(E[LaT ]) in (14) for the three mobility
scenarios described at the end of section 4; two of them are shown in Figure 5 for four states.
Figure 6 shows the estimates and pointwise 95 percent confidence bands for θt for these four
states. The plots for all states are in the Supplement.
 P
P
Finally, Figure 7 shows
95 percent
confidence intervals for t exp E[Lat ] − t Yt and


P
P
P
at
for
t exp E[L ] −
t Yt /
t Yt under the ‘stay vigilant’ scenario. We refer to these

13

CAUSAL INFERENCE IN THE TIME OF COVID
New York

Texas

California

0.10

0.20

Observed
2 weeks early
Stay vigilant

0.00

Normalized mobility (%)

Tennessee

0

10

20

30

40

0

10

20

30

40

0

10

20

30

40

0

10

20

30

40

Time (weeks)

F IG 5. The observed mobility curves and hypothetical interventions for four states. Mobility has been standardized
to have value 0 at the beginning of the series. All plots are on the same scale.

as total and relative excess deaths, where a negative excess means that lives would be saved.
Of course, this number is larger for more populous states, although relative to the total number of observed deaths, all states small and large would have benefited equally from more
sustained vigilance. Note that the confidence interval for New York (fourth from right) is
very large. New York experienced the pandemic early and responded with large values of As
so it is believable that further vigilance may not have a large effect.
6.2. Sensitivity Analysis. We have made a number of strong assumptions in our model.
Our preference would be to weaken these assumptions and use nonparametric methods but
the data are too limited to do so. Instead, we now assess the sensitivity of the results to various
assumptions. We consider various perturbations of our analysis. These include: (1) changing
the model/estimation method (we replace the MSM with an outcome model), (2) assessing
the Markov assumption (which was used to estimate the weights), (3) checking the accuracy
of the point mass approximation (which was used in Section 4.2 to simplify the model) and
(4) assessing sensitivity to unmeasured confounding (we have assumed that the only time
varying confounders are past values of mobility and death).
1. An Alternative Model. Here we compare the results from the MSM in (15) to the time
series AR(1) outcome model:
(20)

Lt = Lt−1 + βAt−δ + r(t) + t

where r(t) is a polynomial of degree k − 1. This says that, apart from random error, Lt differs
from Lt−1 for two reasons, mobility At−δ and the natural increase r(t) due to epidemic
at
dynamics. If we
Ptapply the g -formula in (1) to this model, we find E[Lt ] = βM (at ) + ν(t)
where ν(t) = s=1 r(s) is a polynomial of order k . Hence, this outcome model is consistent
with the MSM. In other words, this model is contained in the semiparametric model P defined
in (8). This model resembles Robins’ blip models (Robins (2000); Vansteelandt et al. (2014);
Robins (2000)) as it measures the effect of one blip of treatment At−δ so we will refer to
(20) as the blip model. We will fit (20) by least squares. There are three reasons for fitting
this model. First, it as a point of comparison for the MSM. Second, as an outcome model,
we are able to check residuals and model fit. Third, since it is an outcome model, we can
use AIC to choose the degree k − 1 of r(t). We also use this choice of k in the MSM. The
degree k chosen by AIC is typically k = 1 for small states and k = 3 or k = 4 for the larger
states. A plot of the selected degree versus log population and versus log deaths is in the
supplementary material.

14
1 week early

2 weeks early

Stay vigilant

●

●

400

●

0

200

tn

●
●●
●
●●
● ●
●● ●
● ● ●● ●
● ● ●
●● ●
●
●●●●●●●●●●●● ●
●●

●
●●
●
●●
● ●
●● ●
● ● ●● ●
● ● ●
●● ●
●
●●●●●●●●●●●● ●
●●

●

5000

●

●

●

●
●●
●
●●
● ●
●● ●
● ● ●● ●
● ● ●
●● ●
●
●●●●●●●●●●●● ●
●●

●

●

●

●

●

● ●

● ●

● ●

ny
●
●

●●
●
●●●
●
●●●●●●●●●●●●●●●●●●●●●●●●●

●

1500

●

●

●

0

●

●

●●●●●●
●●
● ●●●

0

10

20

30

●

●●●
●●●●●●
●●
● ●●●

●

0

10

●●●●

●
●
●●
●

●

20

30

●●●
●●●●●●
●●
● ●●●

●
●
●●
●●
●●●

●
●
●
●

40

●
●

●
●●
●
●●
●
●
●●

●

●●●●
●

●
●
●●
●●
●●●

●
●
●
●

●
●

●

●
●
●
● ●
●
● ●●● ● ●●
●
●●

●
●
●
●●
●

●●

●

●●●●
●●●

●

●
● ●●

●
●

●
●●
●
●●
●
●
●●

●
●
●
● ●
●
● ●●● ● ●●
●
●●

●

●

●
●

●

●●
●
●●●
●
●●●●●●●●●●●●●●●●●●●●●●●●●

●
●

●●

●

500

ca

●
●
● ●●

●
●

●
●●
●
●●
●
●
●●

●
●
●
● ●
●
● ●●● ● ●●
●
●●

1000 1500

0

500

tx

●
●

●●

●
●

●

●
●

●●
●
●●●
●
●●●●●●●●●●●●●●●●●●●●●●●●●

●

●
● ●●

1000

Deaths

0

2000

●
●

0

10

●

●
●
●●
●●
●●●

●
●
●
●

40

●
●
●●
●

20

30

40

Weeks

F IG 6. Pointwise 95 percent confidence bands for deaths θt = exp(E[LaT ]) for the three mobility scenarios
aT described at the end of section 4; see also Figure 5. Each row is a different state. Each column is a different
scenario, start one week early, start two weeks early and stay vigilant. The epidemic in NY started early so staying
at home sooner had a large impact. The same is true for PA, IL, MI, NJ, MA. Staying home earlier would not have
had as much of an impact in states such as TN that did not suffer the epidemic early. Staying more vigilant would
have had a large impact during every wave of infections. Some lack of fit in the early time period is evident in
Texas where counterfactual deaths exceed observed deaths under ‘stay vigilant’ where mobility has not yet been
changed.

The left plot in Figure 8 shows the estimates of β and 95% confidence intervals for all
the states from the blip model in (20), and the right plot compares the estimates of β from
the MSM and blip models, where we see the similarity of the inferences. Since the blip
model is an outcome model, it makes sense to compare the observed data to the fits. Fig 9
shows the fitted values and the data for four states. The fit is not perfect but is reasonable.
We have examined the residuals and found that they show no sign of temporal dependence.
There are some large outliers in some states, mostly in the first few weeks of the pandemic
where mobility At and log deaths Lt change rapidly. Because of this we also fitted a robust
regression but the results did not change much.

15

−5000

●●

●
●

●
●●

●
●●●

●●● ●

● ● ●
●●
● ●
●
●●
●●
●●
●●
●●● ●●●
●●
●
●●
●
●
●
●

●

●

−20000

Total Excess Deaths

CAUSAL INFERENCE IN THE TIME OF COVID

●
●

14

15

16

17

0.5
0.0

●

●
●

●

−0.5

Relative Excess Deaths

log Population

●
●

●

●

●
●
●

●

●
●
●●

14

●

●

●●
●
●
●●

●
●
● ●
●
●
●
●
● ●● ●
●
●
●

15

●
●

16

●
●
● ●
●

●

●

●

17

log Population

 P
P
F IG 7. 95 percent confidence intervals for total excess deaths t exp E[Lat ] − t Yt (top) and relative
P

 P
 P
at
excess deaths
t exp E[L ] − t Yt / t Yt (bottom) under the ‘stay vigilant’ scenario. The confidence
intervals for NY (fourth from right) and a handful of other states include zero and suggests that staying more
vigilant would not have significantly impacted the death toll. On the other hand, many states, small and large,
could have reduced their death tolls by over a half.

2. The Markov Assumption. In Section 5.2, to estimate the weights, we have made the Markov
assumption that At−δ is conditionally independent of the past given (At−1−δ , Lt−1−δ ). We
also assumed that Lt is conditionally independent of the past given (At−1−δ , Lt−1 ). To assess
this assumption, we fit the models
At−δ = α0 + α1 At−1−δ + α2 At−2−δ + α3 At−3−δ + β1 Lt−1−δ + β2 Lt−2−δ + β3 Lt−3−δ + t
Lt = α0 + α1 At−δ + α2 At−δ−1 + α3 At−δ−2 + β1 Lt−1 + β2 Lt−2 + β3 Lt−3 + δt .

Figure 10 shows boxplots of the t-statistics for these parameters. The evidence suggests that
the first order Markov assumption is reasonable. The weak dependence of At on past values
of Yt is consistent with the fact that we found that the weights Wt do not have a strong effect
i.e. there is little confounding due to past deaths, However, this assessment still assumes that

−1

15

16

●

●

Blip

●
●● ●
●●
●
● ● ●●●●
●
●
●
●
●
●
●● ●●
●
● ●

●
●

● ●

●

●
●● ● ●
● ● ●
●
●

●●

● ●●
●

●

●
●
●

●

−7

−10

●

●●

●

−5

●
● ●
●

●

−6

●
●●
● ●
● ●
● ● ●
●
● ●
●

●
● ●
●

●
●●
●

−4

5
0
−5

β

●
●●
● ●●
●
●
●
●
●

−3

10

−2

●

−8

−15

●
●

14

15

16

17

−8

●

−7

−6

Log population

−5

−4

−3

−2

−1

MSM

F IG 8. Left: Estimates of β from the blip model in (20) with 95% confidence intervals. Right: Comparison of
estimates of β from the blip model and the MSM in (15).

9

New York

Florida
7.0

●
●
●

●
●

●

●
●
●
●●●●●
●

●●

10

20

6.0

40

California

●

20
Time

30

40

Log Deaths

6.0

●

●

4.0

20

Texas

●
●
● ●
●●●
●
●●
●
●

5.0

Log Deaths

10

Time

4.5 5.0 5.5 6.0 6.5 7.0 7.5

7.0

0

Time

●
●
●● ●●
●●
●
●●
●
●
●
●●
●
● ●
●
●
●●

10

●

●

30

●

0

●
●
●●●
●● ●● ●
● ●

●

●

0

●●
●
●
●
●
●●

4.0

4

●●
● ●
●

●

5.0

●●●
●

Log Deaths

●
●
●

●
●
●

6

7

●
●

●

● ●
●
●
● ●
● ●● ●
●
●
●

●
●

●
●

5

Log Deaths

8

●

30

40

●
●
●●●●
●●
●
●●●
●●
●
●● ●●●
●
●
●●
●
●●
● ●●●
●●
●●
●
●

●

●

0

10

20

30

40

Time

F IG 9. Observed log deaths in four states as functions of time with estimates (red) from the blip model in (20).

the Markov assumption is homogeneous, that is, that the law of At given (At−1 , Yt−1 ) is
constant over time. This assumption is not checkable without invoking further assumptions.

17

●

●

●
●

●

5

5

10

10

CAUSAL INFERENCE IN THE TIME OF COVID

●

●

−5

0

0

●

●
●

●

●
●

●
●

^ ^ ^
α^1 α^2 α^3 β1 β2 β3

^ ^ ^
α^1 α^2 α^3 β1 β2 β3

F IG 10. (Left) Boxplots across states of t-statistics for the parameters in the model for At as a function of the
past. The horizontal red lines are at ±2. Only α
b1 is consistently significantly different from zero across states,
suggesting that the times series of at home mobility At is a memory one process. (Right) Same for Yt . Only βb1 is
consistently significantly different from zero across states, suggesting that the deaths times series Yt is a memory
one process.

3. Point Mass Versus Deconvolution. Recall that in Section 4.2 we approximated f (s, t) with
a point mass at t − 4. An alternative to the point mass approximation is to estimate the number
of infections I by deconvolution. From the number of infections, we can estimate the model
parameters as in Section 5 without making the point mass approximation, using log(I) as the
outcome variable. We infer Iet = d(t)It from the optimization:
(21)

e 22 + λ
min kY − F Ik
I≥0

T
−1
X

(Ier − Ier−1 )2 ,

r=2

where Y denotes the vector of weekly deaths and F is a matrix with (i, j)-entry equal to
f (i, j) if j ≤ i and zero otherwise; that is, Fij is proportional to the probability of dying at
time j given that infection occurred at time i. The parameter λ is user-specified and represents a penalty imposed on non-smooth solutions. Because f is proportional to the density
of a Gamma random variable, we have Fii = f (i, i) = 0. To ensure nonzero elements on
the diagonal of F , we remove the first row and last column (all zeros) from F and solve
(eq::lambda) using Y = (Y2 , . . . , YT ), thus obtaining an estimate of Ie = (Ie1 , . . . , IeT −1 ). To
enforce nonnegative values of I , we use the constrained optimization routine L-BFGS-B
from optim in R. Using a penalty λ = 1, we report the inferred infections Ib (red line) for
California, Florida, New York and Texas in Figure 11 along with the implied deaths computed as F Ib. The latter match the observed deaths well, leading credence to this procedure.
In Figure 12, we compare the estimates of β from the MSM using the point-mass approximation and those from the MSM using the estimates of infections from the deconvolution step.
The estimates are in rough agreement as they lie near the diagonal.
4. Unmeasured Confounding. At time t, we treated (A1 , Y1 ), . . . , (At−1 , Yt−1 ) as confounders. Now suppose there is an unmeasured confounder U . We would like to assess
b where βbU is the value of our estimate if we had access to U . This quantity
|βbU − β|
is not identified and so any sensitivity analysis must invoke some extra assumption. Let
b
b denote the unobserved confounding on the standard error scale. So
∆ = |βbU − β|/se(
β)
∆ = 0 corresponds to no unmeasured confounding, ∆ = 1 corresponds to saying that the

18

20

30

1000
600

40

0

10

20
Week

New York

Texas

30

40

1000

Infections / Deaths

4000

0

2000
0

40

1500

Week

30

500

10

6000

0

Infections / Deaths

200
0

500

1500

Infections / Deaths

Florida

0

Infections / Deaths

California

0

10

20

30

40

0

10

20

Week

Week

b
F IG 11. Inferred infections in four states. The red curve is Iet , the estimate of the number of infections times
e
the probability of dying if infected by Covid-19, It = d(t)It . The black curve is deaths F Ib computed from the
optimization with λ = 1 in (21), and the dots are the observed deaths.

−15

−10

−5

λ = 0.8

−5

−5
−15 −10

0

−10

0

−15

−10

−5

λ=1

λ = 1.2

0

−5
−15 −10

0
−5

−5

β from point−mass

0

0

β from point−mass

β from deconvolution

β from point−mass

−10

0

0

λ = 0.6
β from deconvolution

β from point−mass

−15 −10
−15

0

0

β from point−mass

−5
−15

−5

β from deconvolution
−5

−15 −10

0
−5

−10

−15 −10

β from deconvolution

−15

β from deconvolution

λ = 0.4

−15 −10

β from deconvolution

λ = 0.2

−15

−10

−5

0

β from point−mass

F IG 12. Comparison of estimates of βb from the MSM using the point-mass approximation vs using estimates of
infections via deconvolution for different values of λ.

19

CAUSAL INFERENCE IN THE TIME OF COVID

●

10

12

●

●

●

8

●

●

●
●

●

∆

●

6

●
●●

●

●

●

●
●

●

●

●
●

●

4

●
●

●
●●
●

2

●

●

●

●

●
●

0

●

●

●

●

●

●
●

●

● ●
●

●

●
●●

14

15

16

17

Log Population

F IG 13. Unmeasured confounding sensitivity plots. Minimum value of ∆ versus log-population for each state,
b causes the confidence interval for β to contain 0. For most
such that unmeasured confounding of size ∆ se(β)
states, it takes a fairly large ∆ to lose statistical significance.

unmeasured confounding is the same size as the standard error, etc. For each state, we enb . We can then ask: how large would ∆ have to be so
large the confidence interval by ∆ se(β)
that the enlarged confidence interval would contain 0. Figure 13 shows this critical ∆. We
see that for most states, it takes a fairly large ∆ to lose statistical significance. Some of the
medium size states are the most robust. The larger states are not the most robust but still show
substantial robustness.
Adding other potential within state confounders would be desirable but, in a within-state
analysis, we can only accommodate time varying confounders. (A fixed confounder is a single variable with no replication and can only be used an a across state analysis.) So far we
do not have any within-state time varying variables that would be expected to directly affect
both At and Yt . One could imagine that a variable like “the percentage of rural cases” could
change over time and possibly affect both variables but we do not have such data.
Next we consider a second style of sensitivity analysis inspired by the approach in Rosenbaum et al. (2010). The effect of unmeasured confounding in our analysis is that the weights
Wt are misspecified. If there are unobserved confounders Ut , then the correct weights are
ft =
W

t
Y

π(As |As−1 )
π(As |As−1 , Y s−1 , U s−1 )
s=1

whereas we estimated the weights
Wt =

t
Y

π(As |As−1 )
.
π(As |As−1 , Y s−1 )
s=1

To assess this impact we find the maximum and minimum βb under the assumption that
Wt f
≤ Wt ≤ ΓWt
Γ

0

β

10

20

20

●
●

●

●

●
●

●

●

●●
●

●

●
●

●

●

●
●●

●
●
●

●

●
●

●
● ●
●

●

−10

●

●
●
●
●
●

●
●

●
●
●
●
●
●

●

●

●

●

●

−20

●

14

15

16

17

log Population

F IG 14. Unmeasured confounding sensitivity plots. The blue line segments span the lower and upper bounds of βb
ft /Wt ≤ Γ with Γ = 3. The black dots are the original point estimates. The effects for
over the weights 1/Γ ≤ W
most large and medium states remain significant, indicating robustness to unmeasured confounding.

for t = 1, . . . , T and some Γ ≥ 1. Similar ideas for static, binary treatments have been considered in Zhao, Small and Bhattacharya (2019); Yadlowsky et al. (2018). Figure 14 shows
the bounds on βb using Γ = 3. Even with this fairly large value of Γ the effects for most large
and medium states remain significant indicating robustness to unmeasured confounding. (The
method for computing the bounds is in Bonvini et al. (2021).)
6.3. Across Versus Within States. We have focused on within state estimation. An alternative is to fit a model across states as well. Although we are skeptical of combining data
over states we do so here for completeness. We fit the blip model with common β and, rather
than include state level covariates such as population size, proportion of residents in cities,
etc., we use a fixed effect for each state. The resulting estimates of β and standard errors for
k = 1, 2, 3, 4 are:
k
1
2
3
4

βb
-5.20
-4.60
-3.82
-2.83

standard error
0.27
0.27
0.34
0.43

The estimates are consistent with the within state models. AIC chooses k = 1, which
conflicts with the within state analysis with favors larger k for larger states. The likely reason
is that combining states adds variability in the combined dataset since β ’s and ν(t)’s are
different between states, so there is less signal compared to the noise to estimate a more
complicated relationship than a linear. A natural extension of this model is to use a random
effects approach, although we do not pursue that here.
7. Discussion. Our approach to modeling the causal effect of mobility on deaths is to
construct a marginal structural model whose parameters are estimated by solving an estimat-

CAUSAL INFERENCE IN THE TIME OF COVID

21

ing equation. We model each state separately to reduce confounding due to state differences.
Our approach has several advantages and disadvantages.
Our modeling assumptions are reasonable in the short term but not in the long term. Eventually, the effects of acquired immunity, masks, vaccinations etc might have to be accounted
for.
Estimating the model parameters comes down to solving the estimating equation (16).
Computing standard errors and confidence intervals is then straightforward. This is in contrast to more traditional and Icarian epidemic modeling which requires estimating many parameters using grid searches or MCMC. Provably valid confidence intervals are elusive for
those methods. On the other hand, the more detailed models might be more realistic and can
capture effects that our simple model cannot capture. Moreover, our inferences are asymptotic in nature. When comparing exact Bayesian methods to approximate frequentist methods
it is hard to argue that one approach is more valid than the other.
We believe that focusing on weekly data at the state level gives us the best chance of
getting data of reasonable quality and helps avoid confounding related to state differences.
Further, this allows the causal effect to vary between states. But this results in a paucity of
data, a few dozen observations per state. This limits the complexity of the models we can
fit and it requires that we make a homogeneous Markov assumption. A natural compromise
worthy of future investigation would be to use some sort of random effects model to allow
modeling all states simultaneously. This could also permit using data from other countries.
At any rate, there is a tradeoff: within state analysis requires stronger modeling assumptions
while analyzing all states together requires assuming independence and it assumes we can
model all sources of between state confounding.
Detailed dynamic modeling versus the more traditional causal modeling done here (and
in Chernozhukov, Kasaha and Schrimpf (2020)) represent two different approaches to causal
inference for epidemics. It would be interesting to see a general comparison of these approaches, perhaps eventually leading to some sort of fusion of these ideas.
Finally, we discuss a general issue about causal epidemic modeling that we mentioned earlier, namely, that some epidemic models are subject to a problem known as the null paradox
which can be avoided by using MSM’s. This problem is well known in the causal literature
(Robins (1986, 1989); Robins and Wasserman (1997)) but may not be well known in the
epidemic literature.
We’ll focus on infections It . Consider a sequentially specified epidemic model of the form
E[It |I t−1 , At−1 , X t−1 ] = f (I t−1 , At−1 , X t−1 , θt )
for some parametric model f (·; θt ). Here (X1 , . . . , XT ) are covariates and (A1 , . . . , AT ) is
the variable of interest which is mobility in this paper but could be mask wearing, school
closings, vaccines, etc. Also, let g(xt |X t−1 , I t−1 , At−1 ; αt ) be a model for Xt given the past.
The model is specified by the parameters Θ = ((θt , αt ) : t = 1, . . . , T ).
Assume that there is no unobserved confounding. Even without confounding, there will
typically still be many unobserved baseline variables U that affect the Xt ’s and the It ’s.
For example, overall health could affect infections It and covariates Xt . These are not confounders because they do not directly affect AT , thus the causal effect is still identifiable
and is still given by the g -formula. These baseline variables create conditional dependence
between IT and At given the Xs ’s, even when the treatment A has no effect. (For readers familiar with directed graphs, this can be seen by noting that the Xt ’s are colliders; see Figure
1 in Robins and Wasserman (1997).) We will call this baseline dependence.
The causal effect ψ(aT ) can be derived by inserting the model into the g -formula. Now
suppose that the treatment has no effect which we call the null case. Then ∂ψ(aT )/∂as = 0
for all as , i.e., ψ(aT ) should not depend on aT .

22

Now we can informally state the null-paradox. If the models have non-linear terms then
there is no value of the parameters such that (i) there is non-zero baseline dependence and
(ii) the null is true. Thus, in some sense, the model is trapped into being misspecified.
We can avoid the null paradox by using nonparametric models but then the model complexity explodes as T increases leading to the curse of dimensionality. Linear models avoid
the null paradox but caution is still needed since the causal effect ψ(a) involves complicated
nonlinear functions of the regression parameters. Hence, the model is very difficult to interpret and the individual regression parameters do not have a causal interpretation. (Note
that our autoregressive blip model is linear but is simple enough so that there is a single,
interpretable causal parameter.)
The quickly growing literature on using sequentially specified epidemic models does include such models. MSMs avoid the null paradox, and this is another reason for using MSMs
(or some other semiparametric causal model such as structural nested models). In our case
we motivated the MSM by starting with a sequentially specified model. This seems like a
reasonable approach for using epidemic models to define an MSM but there may be other
approaches as well.
Acknowledgments. The authors would like to thank Rob Tibshirani for providing helpful feedback on an earlier draft of the paper. Edward Kennedy gratefully acknowledges support from NSF Grant DMS1810979.
SUPPLEMENTARY MATERIAL
Supplement. Plots for all states.
().
REFERENCES
B JØRNSTAD , O. N. (2018). Epidemics. Models and data using R: Springer International Publishing 318.
B ONVINI , M., K ENNEDY, E., V ENTURA , V. and WASSERMAN , L. (2021). Propensity Scores and Sensivity
Analysis for Marginal Structural Models with Continuous Treatments. In preparation.
B RAUER , F., C ASTILLO -C HAVEZ , C. and C ASTILLO -C HAVEZ , C. (2012). Mathematical models in population
biology and epidemiology 2. Springer.
C HANG , S., P IERSON , E., KOH , P. W., G ERARDIN , J., R EDBIRD , B., G RUSKY, D. and L ESKOVEC , J. (2020).
Mobility network models of COVID-19 explain inequities and inform reopening. Nature 1–6.
C HERNOZHUKOV, V., K ASAHA , H. and S CHRIMPF, P. (2020). Causal impact of masks, policies, behavior on
early COVID-19 pandemic in the US. arXiv preprint arXiv:2005.14168.
F ONG , C., H AZLETT, C., I MAI , K. et al. (2018). Covariate balancing propensity score for a continuous treatment:
Application to the efficacy of political advertisements. The Annals of Applied Statistics 12 156–177.
IHME (2020). Modeling COVID-19 scenarios for the United States. Nature Medicine.
K ERMACK , W. O. and M C K ENDRICK , A. G. (1927). A contribution to the mathematical theory of epidemics.
Proceedings of the royal society of london. Series A, Containing papers of a mathematical and physical character 115 700–721.
L IAO , X. and M EYER , M. (2018). cgam: Constrained generalized additive model. xxxx xx xxxx.
M EYER , M. C. et al. (2008). Inference using shape-restricted regression splines. The Annals of Applied Statistics
2 1013–1033.
M EYER , M. C. et al. (2018). A framework for estimation and inference in generalized additive models with shape
and order restrictions. Statistical Science 33 595–614.
N EUGEBAUER , R. and VAN DER L AAN , M. (2007). Nonparametric causal effects based on marginal structural
models. Journal of Statistical Planning and Inference 137 419–434.
ROBINS , J. (1986). A new approach to causal inference in mortality studies with a sustained exposure period—application to control of the healthy worker survivor effect. Mathematical modelling 7 1393–1512.
ROBINS , J. M. (1989). The analysis of randomized and non-randomized AIDS treatment trials using a new
approach to causal inference in longitudinal studies. Health service research methodology: a focus on AIDS
113–159.

CAUSAL INFERENCE IN THE TIME OF COVID

23

ROBINS , J. M. (2000). Marginal structural models versus structural nested models as tools for causal inference.
In Statistical models in epidemiology, the environment, and clinical trials 95–133. Springer.
ROBINS , J. M., H ERNAN , M. A. and B RUMBACK , B. (2000). Marginal structural models and causal inference
in epidemiology.
ROBINS , J. M. and WASSERMAN , L. (1997). Estimation of Effects of Sequential Treatments by Reparameterizing Directed Acyclic Graphs. In Proceedings of the Thirteenth Conference on Uncertainty in Artificial
Intelligence 409-420. Morgan Kaufmann.
ROSENBAUM , P. R. et al. (2010). Design of observational studies 10. Springer.
S HI , Y. and BAN , X. (2020). Capping Mobility to Control COVID-19: A Collision-based Infectious Disease
Transmission Model. medRxiv.
T SIATIS , A. (2007). Semiparametric theory and missing data. Springer Science & Business Media.
U NWIN , H. J. T., M ISHRA , S., B RADLEY, V. C., G ANDY, A., M ELLAN , T. A., C OUPLAND , H., I SH H OROWICZ , J., VOLLMER , M. A., W HITTAKER , C., F ILIPPI , S. L. et al. (2020). State-level tracking of
COVID-19 in the United States. Nature communications 11 1–9.
VANSTEELANDT, S., J OFFE , M. et al. (2014). Structural nested models and G-estimation: the partially realized
promise. Statistical Science 29 707–731.
X IONG , C., H U , S., YANG , M., L UO , W. and Z HANG , L. (2020). Mobile device data reveal the dynamics in a
positive relationship between human mobility and COVID-19 infections. Proceedings of the National Academy
of Sciences 117 27087–27089.
YADLOWSKY, S., NAMKOONG , H., BASU , S., D UCHI , J. and T IAN , L. (2018). Bounds on the conditional and
average treatment effect with unobserved confounding factors. arXiv preprint arXiv:1808.09521.
Z HAO , Q., S MALL , D. S. and B HATTACHARYA , B. B. (2019). Sensitivity analysis for inverse probability
weighting estimators via the percentile bootstrap. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 81 735–761.
Z HOU , X. and W ODTKE , G. T. (2018). Residual balancing weights for marginal structural models: with application to analyses of time-varying treatments and causal mediation. arXiv preprint arXiv:1807.10869.

