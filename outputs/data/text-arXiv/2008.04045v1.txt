Towards Integrated and Open COVID-19 Data?
Georgios M. Santipantakis, George A. Vouros, and Christos Doulkeridis

arXiv:2008.04045v1 [cs.DB] 1 Aug 2020

University of Piraeus, Greece {gsant,cdoulk,georgev}@unipi.gr

Abstract. Motivated by the global unrest related to the COVID-19
pandemic, we present a system prototype for ontology-based, integration
of national data published from various countries. COVID-related data
is published from different authorities, in different formats, at varying
spatio-temporal granularity, and irregularly. Consequently, this hinders
the joint data exploration and exploitation, which could lead scientists to
acquire important insights, without having to deal with the cumbersome
task of data acquisition and integration. Motivated by this shortcoming, we propose an approach for data acquisition, ontology-based data
representation, and data transformation to RDF, which also enables interlinking with other publicly available data sources. Currently, data
coming from the following European countries has been successfully integrated: Austria, Belgium, France, Germany, Greece, Italy, and Sweden.
The knowledge base is automatically being updated, and it is available
to the public through a SPARQL endpoint and a direct download link.
Furthermore, we showcase how data integration enables spatio-temporal
data analysis and knowledge discovery, by means of meaningful queries
that would not be feasible to process otherwise.

1

Introduction

The COVID-19 virus outbreak is a major concern worldwide, as it affects both
economically and socially every country in the world. Although the first reports
had shown that the virus can be easily and sustainably transmitted between
people, not all the countries took immediate measures to restrict the spreading
of the virus. In Europe, different strategies and measures have been applied
per country, with different outcomes, since the optimal way to respond was not
clear. For example, Sweden relied at the “herd immunity” and no measures
were taken against the virus for the first few weeks of the virus outbreak in
the country, while Greece took immediate and restrictive measures when the
first cases were detected [1], isolating the population and cancelling international
flights. An important factor contributing to the different strategies is the absence
of high-quality, interlinked, globally accessible data, at various scales and levels
of detail, to estimate the criticality of the condition at the very beginning of the
?

The research work was supported by the Hellenic Foundation for Research and Innovation (H.F.R.I.) under the “First Call for H.F.R.I. Research Projects to support
Faculty members and Researchers and the procurement of high-cost research equipment grant” (Project Number: HFRI-FM17-81).

2

F. Author et al.

virus spreading. Nevertheless, this lack of data as well as the need to effectively
monitor the spread of the virus, while providing reports to the public, motivated
most countries to collect data and provide daily reports on the virus spread and
on the number of infected, recovered and deceased persons.
The wide variation of measures taken in connection to other data sources
and their recorded results in each country can be analysed for future reference.
Towards this goal, similar measures taken from different countries for their populations, need to be identified to safely evaluate their results. This task can be seen
in general as a spatio-temporal analysis process, for pattern recognition, matching and prediction. Any such analysis task needs data from various countries,
and for a large period of time. Additionally, a data set that combines reports
from various countries and their regions can show the degree at which regions
with similar characteristics have been affected and how they have affected other
regions. As an example use case, correlation factors can be computed from the
cases reported in adjacent regions of neighboring countries1 .
Towards supporting complex data analysis and joint data exploration, it
is necessary to aggregate COVID-19 data at different levels of administration
regions, from different countries, and for a large period of time in an integrated
data set. This means that data needs to be spatially and temporally aligned, and
the spatio-temporal granularity at which data is recorded should be the same
for all countries.
In this work, we process a set of data sources providing national daily reports
originating from different countries. We have developed an automated process,
based on a system for RDF data transformation (RDF-Gen [2]), that retrieves
COVID-19 data from public sources and integrates them to RDF triples under
a simple ontology. The ontology we use is built on top of well known ontologies
such as OWL-Time, GeoSPARQL, and SIOC (Semantically-Interlinked Online
Communities) Core Ontology. The resulting data set is linked to mainstream
data providers such as wikiData and EU Open Data Portal.
As such, the main contribution of this work is an approach for data integration of COVID-related data that enables complex data analysis queries that can
extract useful knowledge and insights. Specifically, our work makes the following
achievements:
– We integrate the daily reports of COVID-19 from 7 central European countries, that have followed different strategies against the outbreak. We plan
to expand the data set with more countries in the near future.
– We homogenize the COVID-19 reports of different countries under a single
schema, while providing data at a specific level of spatial and temporal granularity, converting the spatial regions reported in the original sources to the
corresponding regions using NUTS encoding for levels 1, 2, and 3.
– We show how data can be interlinked with the daily reports contextual data,
such as population density per group age, total population and administra1

A video generated from the compiled data set, that shows that there is possibly
a correlation between adjacent regions, is available online at http://83.212.169.
101/datasets/covidOutbreak.html

Towards Integrated and Open COVID-19 Data

3

tion regions of countries (along with topological relations such as “touches”
or “contains”).
– We transforms the data into RDF using commonly used ontologies such as
GeoSPARQL, RAMON, OWL-Time, SIOC (discussed briefly in Section 3),
to enable linking additional data sources with third-party resources that are
not already included in the compiled data set.
– We provide a SPARQL endpoint for data exploration through query answering, on the daily updated data set. The result set can be either rendered on
a map or displayed as a table. The complete data set is also available online.
Section 2 briefly presents the data sources accessed for the compilation of
this data set and the main issues tackled in the process. Then, in Section 3, we
present the COVID-19 ontology that we designed. Section 4 briefly analyzes the
data set of reported cases for the first 6 months of 2020 and for the selected
countries. Finally, Section 5 concludes the paper and sketches our future work.

2

Data Sources and Data Acquisition

In this section, we provide a brief description of the data sources used in our
work, along with the problems related to the published data. Then, we describe
the process of data acquisition.
2.1

Data Sources

To the best of our knowledge, the publicly available data sets related to COVID19 either report the total number of cases per country (NUTS2 level 0), or they
report the number of cases for various administration regions within a specific
country. Typical examples of the first category are the World Health Organization (WHO) Coronavirus Disease (COVID-19) Dashboard3 , the WorldOmeter4
and the Johns Hopkins University dashboard5 and the related github project6 .
However, these sources have been built mainly for reporting purposes rather
than for doing any form of analysis. For example, it is not possible to retrieve
the number of cases reported, at a specific day in the past and for a specific
administration region of some country.
On the other hand, several countries provide daily reports about the numbers of cases per administration region. A summarizing page is available at
Wikipedia7 , which also provides links to other Wikipedia pages maintained and
2

3
4
5
6
7

The regions in the retrieved data are converted to Nomenclature of Territorial Units
for Statistics (NUTS) levels 1 to 3, since each data source uses a different reference
system of regions.
https://covid19.who.int/
https://www.worldometers.info/coronavirus/
https://coronavirus.jhu.edu/map.html
https://github.com/CSSEGISandData/COVID-19
https://en.wikipedia.org/wiki/COVID-19_pandemic

4

F. Author et al.

updated by national health organizations of several countries. Nevertheless, it
requires effort to extract the time series of reported cases for each country and
their administration regions from the unstructured text.
In addition to the above, some organizations provide summaries of daily reports per region of a country, through github projects. Specifically, the daily reports of cases in Italy are available through the github project pcm-dpc/COVID19 of “Presidenza del Consiglio dei Ministri - Dipartimento della Protezione
Civile”8 . Similarly, the Greek daily reports can be accessed from the iMedd webpage9 and the github project10 . Since these data sources do not share a common
schema (or even a common format), it is not always straightforward to relate the
data provided, for obtaining a detailed view for several countries and investigate
correlations or similar patterns of virus outbreak in different countries, at the
same level of administrative regions.
2.2

Data Acquistion

The most rapid spreading of COVID-19 virus in Europe was detected in northern
Italy. For this reason our data set was compiled starting from the Italian daily
reports, and it is recursively expanded with reports of adjacent countries. We
focus on adjacent countries that share common borders, since the transportation
between regions is less likely to be affected by airport “lockdowns”. Specifically,
we access COVID-19 reports for the following countries:
– Austria: data is retrieved and processed daily from the online service at
https://www.drawingdata.net/covmap/
– Belgium: data is retrieved and processed daily from the dashboard at https:
//epistat.wiv-isp.be/
– France: data retrieved and processed from https://www.data.gouv.fr/fr/
datasets/donnees-hospitalieres-covid-19/
– Germany: data is retrieved and processed from the online dashboard at
https://corona.rki.de
– Greece: data retrieved and processed from the iMedD-Lab github project
available online at https://github.com/iMEdD-Lab/open-data/tree/master/
COVID-19
– Italy: data accessed and processed from the github project of “Presidenza
del Consiglio dei Ministri - Dipartimento della Protezione Civile” available
online at https://github.com/pcm-dpc/COVID-19
– Sweden: data retrieved and processed from the dashboard “Sweden Coronavirus stats tracker” at https://visalist.io/emergency/coronavirus/
sweden-country
The following problems were addressed in the process of data integration
from the above sources:
8
9
10

https://github.com/pcm-dpc/COVID-19
https://www.imedd.org/new-covid-19-i-watch-the-spread-of-the-disease-in-greece-and-around-the-worl
https://github.com/iMEdD-Lab

Towards Integrated and Open COVID-19 Data

5

– Different languages and encodings: Even in the same data source of a multilanguage country (for example Belgium), it may occur that daily reports use
different encodings (depending on the region and the language used in it).
This issue may result to incomplete data if not handled properly.
– Different types of sources and data formats (JSON, CSV, ESRI shapefiles):
Data sources do not share a common format and schema. For example, data
is provided in CSV tables, JSON files (e.g., GIS feature server responses),
and ESRI shapefiles (e.g., EU Eurostat data).
– Different encodings of spatial regions: Germany uses “landkreis” codes, Austria uses “Gemeindekennziffer” (GKZ) codes, Greek and Belgian sources use
region names in all official languages. We tackled this issue using a key-value
map between the region encoding used in the corresponding data source and
NUTS level 3 codes. In the case of Belgium, which uses subsections of NUTS
level 3 regions, the process aggregates the data into the corresponding NUTS
level 3 region. This approach allows the spatial integration of data.
– Data is not temporally aligned and not updated in the same interval: Austrian reports are provided in a hourly interval, while Greek reports are not
provided in a constant interval, and the rest of the data sources provide the
data in a daily interval. For this reason we retrieve the data of one day before current day, to guarantee that no further updates are expected for any
reported day in our data set.
– Undefined spatial regions for reported cases (e.g., cases on a cruiser). We
associate the reported cases with the nearest NUTS level 3 region (e.g., the
port where the cruiser has docked).
– Different update strategies: Italian reports are provided in a separate file for
each day in the corresponding github project. On the other hand, the github
project for the Greek data overwrites previous reports, thus the timeline is
only accessible through the git versioning process. Dashboard data sources
(e.g., the data source used for the German reports) do not rely on specific
files, but instead they are accessed as online endpoints.
In addition, missing records for some regions and days have been observed.

3

The COVID-19 Ontology

The COVID-19 data set is integrated into an RDF graph using a new ontology
that is based on the following imports:
– SIOC11 : The SIOC (Semantically-Interlinked Online Communities) Core Ontology provides the main concepts and properties required to describe information found on online communities such as social media, message boards,
wikis, weblogs, etc.
11

https://www.w3.org/Submission/2007/02/namespaces.zip

6

F. Author et al.

– GeoSPARQL12 : The OGC GeoSPARQL standard supports representing and
querying geospatial data on the Semantic Web. GeoSPARQL defines a vocabulary for representing geospatial data in RDF, and it defines an extension
to the SPARQL query language for processing geospatial data.
– OWL-Time13 : OWL-Time is an ontology of temporal concepts, for describing the temporal properties of resources. The vocabulary provided expresses
facts about relations among instants and intervals, as well as durations. Time
positions and durations may be expressed using either the conventional (Gregorian) calendar and clock, or using another temporal reference system such
as Unix-time, geologic time, or different calendars.
– RAMON geographic ontology14 : RAMON geographic ontology describes countries, NUTS, and Local Administrative Units (LAU) related concepts and
properties.
We combine the above ontologies using the added property cov:hasSpatialFeature,
where cov: is the prefix for the namespace of COVID-19 ontology. The domain of the added property is owl:Thing and its range is geosparql:Feature.
This means that any resource in our ontology can be related to a spatial feature, i.e. locations of various natural or artificial boundaries or shapes to help
visualize spatially-related data. Similarly, the domain of OWL-Time property
time:has time is defined to be owl:Thing, thus any resource can have a temporal constituent. The part of the resulting schema that combines concepts and
properties of the above ontologies, is illustrated in Figure 1. The rounded rectangles in the graph represent concepts, edges illustrate properties and skewed
parallelograms represent datatypes.
Regarding the association of geographical regions in NUTS geocode standard
with COVID-19 reports, we define in the ontology that nuts:GeographicalRegion
is a subclass of geosparql:Feature. We also introduce the concept cov:DailyReport
for the set of daily reports provided in the COVID-19 data set. Each daily
report is associated with geographical regions defined in RAMON ontology
and GeoVocab15 by the property cov:hasSpatialFeature. Finally, we introduce the data properties cov:hasTotalPopulation, cov:PopulationPerSQKm,
cov:populationGrpLE19, cov:populationGrp20 39, cov:populationGrp40 59,
cov:populationGrpGE60, for the total population, the population density and
population per age group respectively. We add the property cov:infected for
the reported infected cases of a region. The domain of these properties is defined
to be the concept nuts:GeographicalRegion. Figure 2 illustrates an example
of triples representing a record from the COVID-19 data set under the defined
schema. Please notice that the URI of the geographical region referred in the
triples is in the RADON ontology namespace, which enables the exploitation of
relations between geographical regions (e.g. aggregations of infected cases levels
of administration regions), as specified in the ontology.
12
13
14
15

http://www.opengis.net/ont/geosparql
https://raw.githubusercontent.com/w3c/sdw/gh-pages/time/rdf/time.ttl
https://ec.europa.eu/eurostat/ramon/ontologies/geographic.rdf
http://nuts.geovocab.org/

Towards Integrated and Open COVID-19 Data

7

Fig. 1. The concepts and properties combining SIOC, GeoSPARQL and OWL-Time
ontologies for spatio-temporal-textual evaluation. Rounded rectangles in the graph
represent concepts, edges illustrate properties and skewed parallelograms represent
datatypes of literals.

Fig. 2. Example of RDF triples generated from COVID-19 data set.

8

F. Author et al.

The transformation of data into RDF triples, is performed using RDF-Gen[2].
RDF-Gen transforms the data using a triples template, i.e. triples that allow the
use of variables or predefined functions on any of the constituent parts (subject,
predicate, object) of a triple. The process that connects to the public data, is
initialized with contextual data related to the source, such as Administrative
Regions and their geometries, population in each region and population groups
per age. The enriched data are then provided to RDF-Gen, which generates
the corresponding RDF triples. This process is automatic, repeated on a daily
interval. The generated RDF triples are stored in a triple store, which allows the
evaluation of federated SPARQL queries on the data set compiled. The triple
store is initialized with GeoVocab TTL files that describe the geometries of
NUTS regions and their topological relations. Figure 3 illustrates the overall
workflow for the data set compilation.

Fig. 3. The overall workflow for retrieving, transforming updating and publishing data
as RDF triples.

Administrative regions in our data set are linked to EU Open Data Portal16
and wikiData17 . The following query demonstrates the links to EU Open Data
Portal:

16
17

https://data.europa.eu/euodp/en/linked-data
https://www.wikidata.org/

Towards Integrated and Open COVID-19 Data

9

PREFIX : < http :// ai - group . ds . unipi . gr / covid -19# >
PREFIX owl : < http :// www . w3 . org /2002/07/ owl # >
SELECT * WHERE {
? r owl : sameAs ? u .
SERVICE < https :// data . europa . eu / euodp / sparqlep >
{? u ? p ? o }
} LIMIT 10

Similarly, the links to wikidata are demonstrated with the query:
PREFIX : < http :// ai - group . ds . unipi . gr / covid -19# >
PREFIX owl : < http :// www . w3 . org /2002/07/ owl # >
PREFIX wd : < https :// query . wikidata . org / >
SELECT * WHERE {
? r owl : sameAs ? u .
SERVICE wd : sparql
{? u ? p ? o }
}

The linkage to wikidata graph, enables our data to be also combined with
other graphs that are connected to wikidata, such as FactForge18 . For instance,
the query:
PREFIX : < http :// ai - group . ds . unipi . gr / covid -19# >
PREFIX nuts : < http :// nuts . geovocab . org / id / >
PREFIX owl : < http :// www . w3 . org /2002/07/ owl # >
PREFIX ot : < http :// ontology . ontotext . com / taxonomy / >
PREFIX ff : < http :// factforge . net / repositories / >
SELECT ? s ? p ? o WHERE {
? r nuts : code " AT130 " ; owl : sameAs ? u .
SERVICE ff : ff - news {
? s ot : exactMatch ? u .
?s ?p ?o .
}
}

will retrieve all triples related to the region in our data set, with NUTS code
“AT130” (Vienna) from the FactForge graph.

4

Evaluation

The compiled data set is available online in two ways: a) through the SPARQL
endpoint at http://83.212.169.101/datasets/yasgui.html, and b) as an
archive at the download link http://83.212.169.101/datasets/ttl.7z. The
SPARQL endpoint provides the user with spatial functions that can be used in
the queries, and the option to render the results on a map (given that the results contain a spatial representation). In this case, the user can also define the
variable that can be used to render the color of the geometries. If the variable
used for coloring the geometries takes numerical values in the results, it automatically detects the minimum and maximum values and the color is set w.r.t.
18

http://factforge.net/

10

F. Author et al.

the value of the variable in the white-red spectrum. Otherwise, if the variable
takes non-numerical values, the colors are assigned randomly.
We demonstrate the use of the compiled data set, on investigating whether
the number of infections reported in adjacent regions of different countries have
a linear correlation. The first query in this scenario, is to retrieve the adjacent
regions that belong to different countries:
PREFIX
PREFIX
PREFIX
PREFIX

geosparql : < http :// www . opengis . net / ont / geosparql # >
: < http :// ai - group . ds . unipi . gr / covid -19# >
nuts : < http :// nuts . geovocab . org / id / >
f : < java : SPARQL_functions . >

SELECT ? r1 ? r2 ? c1 ? wkt WHERE {
? r1 nuts : name ? name ; geosparql : hasGeometry / geosparql :
asWKT ? wkt . ? c1 : hasPart ? r1 .
? r2 nuts : name ? name2 ; geosparql : hasGeometry / geosparql :
asWKT ? wkt2 . ? c2 : hasPart ? r2 .
? c1 nuts : level " 0 " . ? c2 nuts : level " 0 " .
? r1 nuts : level ? l1 . ? r2 nuts : level ? l2 .
FILTER ( f : touches (? wkt ,? wkt2 ) &&(? c1 !=? c2 ) &&
((? l1 = " 2 " ) ||(? l1 = " 3 " ) ) && ((? l2 = " 2 " ) ||(? l2 = " 3 " ) ) )
}

In this query we use the spatial function touches(g1, g2), which returns true
if only the geometries g1, g2 touch at their boundaries. Since the Belgian daily
reports are assigned to regions at NUTS level 2, we include in the filter both
levels “2” and “3”. Figure 4 illustrates the 67 pairs of regions returned in the
result set of this query.

Fig. 4. Adjacent regions of NUTS level 3, that belong to different countries.

Towards Integrated and Open COVID-19 Data

11

Including in the above query the triple patterns for the daily reports of infections in these regions, results to the following query:
SELECT ? r1 ? r2 ? inf1 ? inf2 ? date WHERE {
? r1 nuts : name ? name ; geosparql : hasGeometry / geosparql :
asWKT ? wkt .
? c1 : hasPart ? r1 .
? r2 nuts : name ? name2 ; geosparql : hasGeometry / geosparql :
asWKT ? wkt2 .
? c2 : hasPart ? r2 .
? c1 nuts : level " 0 " . ? c2 nuts : level " 0 " .
? r1 nuts : level ? l1 . ? r2 nuts : level ? l2 .
? report1 : hasSpatialFeature ? r1 ; : infected ? inf1 ;
time : has_time / time : inXSDDateTimeStamp ? date .
? report2 : hasSpatialFe ature ? r2 ; : infected ? inf2 ;
time : has_time / time : inXSDDateTimeStamp ? date .
FILTER ( f : touches (? wkt ,? wkt2 ) &&(? c1 !=? c2 ) &&
((? l1 = " 2 " ) ||(? l1 = " 3 " ) ) && ((? l2 = " 2 " ) ||(? l2 = " 3 " ) ) )
} ORDER BY ? date

The results of the above query can be used to compute the Pearson correlation coefficient, on the number of cases reported on the adjacent regions.
Interestingly, the computation of Pearson correlation, indicates three cases of
correlation between regions, illustrated in the corresponding Figure 5, and Tables 1, 2. Specifically, regions that seem to be highly affected from their neighbors
(Pearson R value ranges between 0.86 and 1.00), are shown in Figure 5. We observe that higher values of the coefficient correlation are between Austrian and
German regions. The second case reported in Table 1, shows significantly lower
correlation that varies between 0.25 and 0.46. The regions involved in this case
are French and Belgian. Finally, Table 2, reports negative values of coefficient
correlation, varying between -0.04 and -0.48. The negative values are found between French and Italian regions, and it can be a result of measures taken, when
the reported numbers of infections were increased.

Table 1. Regions with high coefficient correlation on the number of reported infections.
Region
FRF31
FRF21
BE34
BE32
FRE21
FRE11
FRE11
BE34

Region Pearson R
BE34
0.46
BE35
0.45
FRF32
0.42
FRF21
0.39
BE32
0.38
BE32
0.32
BE25
0.28
FRF21
0.25

12

F. Author et al.

Fig. 5. High correlations between adjacent regions. Nodes represent regions (NUTS
level 3) and edges report the correlation value.

Towards Integrated and Open COVID-19 Data

13

Table 2. Regions with high coefficient correlation on the number of reported infections.
Region
FRF33
FRF11
DE133
FRK28
ITC31
FRF11
FRL03
BE33
FRF11
FRF33
FRF33
ITC16
FRF33
FRK27
FRF12
FRF33
BE33
FRF11
DE134
FRF12
BE33
DE139
FRL02
FRL02
ITC11

5

Region Pearson R
DEB3K
-0.04
DEB3K
-0.08
FRF11
-0.10
ITC20
-0.11
FRL03
-0.11
DEB3H
-0.11
ITC16
-0.14
DEA2D
-0.15
DE124
-0.18
DEC05
-0.19
DEC01
-0.21
FRL01
-0.22
DEC02
-0.22
ITC20
-0.23
DE133
-0.24
DEC04
-0.25
DEB23
-0.26
DEB3E
-0.33
FRF11
-0.34
DE132
-0.35
DEA28
-0.37
FRF12
-0.38
ITC16
-0.43
ITC11
-0.46
FRK27
-0.48

Conclusions

This work presents a prototype for generating and updating an Open Data set
about COVID-19 confirmed cases that enables cross-country analysis at different
levels of granularity. The compiled data set is transformed into RDF triples to
populate an ontology built on top of well-known ontologies, and resources are
linked to external Open Data repositories. We plan to expand our data set with
more countries and link the data with more portals that provide information
about social events, news feeds and human activities that possibly affect the
spreading of the virus.

References
1. H. V. Georgiou. COVID-19 outbreak in Greece has passed its rising inflection point
and stepping into its peak. medRxiv, 2020.

14

F. Author et al.

2. G. M. Santipantakis, K. I. Kotis, G. A. Vouros, and C. Doulkeridis. RDF-Gen:
Generating RDF from Streaming and Archival Data. In WIMS, pages 28:1–28:10.
ACM, 2018.

