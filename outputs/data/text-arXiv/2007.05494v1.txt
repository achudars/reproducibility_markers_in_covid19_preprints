AUTOMATIC D ETECTION OF COVID-19 C ASES ON X- RAY
IMAGES U SING C ONVOLUTIONAL N EURAL N ETWORKS

arXiv:2007.05494v1 [eess.IV] 2 Jul 2020

A P REPRINT
Lucas P. Soares ∗
MSc. student in Mineral Resources and Environment
Institute of Geosciences
University of São Paulo (USP)
São Paulo, Brazil
lpsoares@usp.br

César P. Soares †
Ph.D. candidate in Global Health and Sustainability
Faculty of Public Health
University of São Paulo (USP)
São Paulo, Brazil
cpscesar@usp.br

July 13, 2020

A BSTRACT
In recent months the world has been surprised by the rapid advance of COVID-19. In order to face
this disease and minimize its socio-economic impacts, in addition to surveillance and treatment,
diagnosis is a crucial procedure. However, the realization of this is hampered by the delay and the
limited access to laboratory tests, demanding new strategies to carry out case triage. In this scenario,
deep learning models are being proposed as a possible option to assist the diagnostic process based on
chest X-ray and computed tomography images. Therefore, this research aims to automate the process
of detecting COVID-19 cases from chest images, using convolutional neural networks (CNN) through
deep learning techniques. The results can contribute to expand access to other forms of detection
of COVID-19 and to speed up the process of identifying this disease. All databases used, the codes
built, and the results obtained from the models’ training are available for open access. This action
facilitates the involvement of other researchers in enhancing these models since this can contribute to
the improvement of results and, consequently, the progress in confronting COVID-19.
Keywords Deep Learning · Coronavirus · Convolutional Neural Networks · SARS-CoV-2

1

Introduction

In recent months the world has been surprised by the rapid advance of SARS-CoV-2 (COVID-19). Given the widespread
of this virus on all continents, the World Health Organization (WHO) has declared that we are experiencing a pandemic
of this disease.
To face this disease and minimize its socio-economic impacts, not only the surveillance and treatment are essential,
but the diagnosis is also presented as a crucial procedure [1]. However, the realization of this is hindered by the delay
and limited access to laboratory tests available to detect COVID-193 [3], thus requiring new strategies to carry out case
screening.
Studies in the area have pointed to the existence of specific indicators on the chest radiography of individuals
infected with the SARS-CoV-2 virus [4]. This fact would allow the use of these images in the diagnostic process of
COVID-19 [5], expanding access to other forms of detecting the disease and accelerating its identification process.
∗

https://lpsmlgeo.github.io/
https://cpscesar-en.github.io/
3
The Reverse-Transcriptase Polymerase Chain Reaction (RT-PCR) is considered the standard reference method for making the
diagnosis of COVID-19 infection [2].
†

A PREPRINT - J ULY 13, 2020

In this scenario, deep learning models are proposed as a possible option to assist the diagnostic process. In
particular, this technique arises intending to make the detection of cases of COVID-19 automatic from chest images X-ray and computed tomography [6, 7, 8].
This research proposes the training of models, using machine learning, to accurately detect the presence of
COVID-19 from chest radiographs. Since the dataset used in this research has only 175 images of the positive class
(COVID-19 chest X-rays), the authors trained the models using the transfer learning technique.
Complementarily, but not least, all the codes used to train the models and the data are available on GitHub4 . This
action aims to facilitate the involvement of other researchers in the process of enhancing these models, as this can
contribute to the improvement of results and, consequently, the progress in facing COVID-195 .

2

Objectives

Automate the process of detecting COVID-19 cases from chest radiograph images, using convolutional neural networks
(CNN) through deep learning techniques.

3

Methodology

Deep learning is a machine learning technique that, through deep neural networks, seeks to discover autonomously that is, without explicit programming - rules and parameters of a data set, in order to provide adequate representation
for a particular problem. The term "deep learning" derives from a large number of hidden layers between the input and
output layers of the neural network.
In this work, the convolution neural networks were trained using the supervised learning process [9]. Therefore,
the labels and the images served as input to the network, intending to minimize the loss function. This last one measures
how far the prediction is from the expected output.
The models were trained with three different architectures: Xception [10], Residual Networks (ResNet) [11], and
VGG-16 [12]. Only the fully connected layers were optimized during the training process. The convolutional layers’
weights were loaded from the ImageNet[13] dataset thought the transfer learning technique. The models were trained
for 80 epochs with a learning rate of 0.001 and a batch size of 15. Categorical cross-entropy and Adam was used as loss
and optimization function, respectively.
The images used to train the models had a size of 237 x 237 pixels and three colors channel (RGB). The training
used 10% of the images for validation and 10% to test. Models were evaluated based on the accuracy metric. The results
were plotted on a confusion matrix and analyzed using a class activation map (Grad-Cam) and by visual inspection.
The models were trained on Google Colaboratory Virtual Environment using TensorFlow [14] and Keras[15] Python
libraries.
The construction of the database aimed to maximize the number of training images. For this, two different sources
were used: one containing X-ray images of the chest of individuals infected with COVID-19 (n = 175) [16] 6 and the
other, with the same type of image, but of lungs of individuals without any infection (n = 100) and with infections
related to other virus and bacteria (n = 100) [17]7 . These datasets were used in this research because of the possibility
of free access to the image banks.

4

Results

Each trained model’s results were evaluated through the plots of the accuracy and loss function history of the training
and validation data (figure 1).

4

https://deepdados-en.github.io/
Information on the databases used in the section referring to the methodology.
6
https://github.com/ieee8023/covid-chestxray-dataset
7
https://data.mendeley.com/datasets/rscbjbr9sj/2
5

2

A PREPRINT - J ULY 13, 2020

Figure 1: Accuracy and Loss plots from the training process.
The Xception and ResNet models’ graphs showed that although the accuracy was 95,9%, 94,6%, respectively, the
models overfitted. This result can be inferred because the validation loss does not decrease according to the training
loss. Nevertheless, the VGG-16 model graphics shows that there was less overfitting since the training and validation
lines approached, and the model had the highest accuracy: 97,3%, meaning that it classified correctly 97,3% of the
images used in the validation. Therefore, from the results, it is possible to notice that the VGG-16 model presented
greater consistency and accuracy to classify the lungs’ images.
The generalization capacity of the VGG-16 model was evaluated on a test set with 75 images, that were not used
during the training process and randomly sampled from the dataset. The results were plotted in a confusion matrix.

Figure 2: Confusion matrix - Network VGG-16.
3

A PREPRINT - J ULY 13, 2020

The matrix (figure 2) pointed out that the accuracy value was 97,3%. That is, among the 75 images used for the
test, the model correctly classified 73. Accurately, the model correctly classified 100% (n = 39) of the images related
to COVID-19, 88,2% (n = 17) of the images of normal lungs, and 100% (n = 19) of the images of lungs with other
infections. Regarding the errors, the model classified 2,7% (n = 2) of the images referring to normal lungs as other
infections.

Figure 3: Results of the VGG-16 network.
The plot above (figure 3) showed that the model had high accuracy in classifying the lungs with COVID-19. The
class activation mapping below (figure 4) exposed the image locations that the model used to perform the classifications.
It is possible to observe in each image group (NORMAL, COVID, and INFECTION - other lung infections from
virus and bacteria) the most important regions for the model to detect each class. The “hotter” (color yellow), the
greater the degree of importance of the image.

4

A PREPRINT - J ULY 13, 2020

Figure 4: Class activation mapping.

5

Discussion and Conclusion

From the results, it is possible to notice that the model had high accuracy in classifying the healthy lungs, COVID-19,
and other infections, especially using the VGG-16 architecture. Nevertheless, the class activation map did not show a
clear visual pattern that allows us to infer which part of the lung the model is basing on to claim that it has COVID-19.
This fact indicates the need to improve the models presented here.
Therefore, future researches may evaluate models with different architectures, parameters, and datasets that use
augmentation techniques. Besides, considering the unknown character of COVID-19, the activation map exposed in
this research can contribute to the literature on the possible indicators of COVID-19 in the lung images of infected
individuals.
Finally, the authors highlight the importance of providing images of individuals infected with COVID-19 and also
the stage of the disease. This data can contribute to the improvement of models and progress in coping with the virus.
All models and codes used in this work were made available on the author’s blog8 .

References
[1] Matthew J Binnicker. Emergence of a novel coronavirus disease (covid-19) and the importance of diagnostic
testing: why partnership between clinical laboratories, public health agencies, and industry is essential to control
the outbreak. Clinical Chemistry, 66(5):664–666, 2020.
8

https://deepdados-en.github.io/

5

A PREPRINT - J ULY 13, 2020

[2] Cristie Columbus, Karen B Brust, and Alejandro C Arroliga. 2019 novel coronavirus: an emerging global threat.
In Baylor University Medical Center Proceedings, volume 33, pages 209–212. Taylor & Francis, 2020.
[3] World Health Organization et al. Laboratory testing strategy recommendations for covid-19: interim guidance, 22
march 2020. Technical report, World Health Organization, 2020.
[4] Ming-Yen Ng, Elaine YP Lee, Jin Yang, Fangfang Yang, Xia Li, Hongxia Wang, Macy Mei-sze Lui, Christine
Shing-Yen Lo, Barry Leung, Pek-Lan Khong, et al. Imaging profile of the covid-19 infection: radiologic findings
and literature review. Radiology: Cardiothoracic Imaging, 2(1):e200034, 2020.
[5] Tao Ai, Zhenlu Yang, Hongyan Hou, Chenao Zhan, Chong Chen, Wenzhi Lv, Qian Tao, Ziyong Sun, and Liming
Xia. Correlation of chest ct and rt-pcr testing in coronavirus disease 2019 (covid-19) in china: a report of 1014
cases. Radiology, page 200642, 2020.
[6] Ophir Gozes, Maayan Frid-Adar, Hayit Greenspan, Patrick D Browning, Huangqi Zhang, Wenbin Ji, Adam
Bernheim, and Eliot Siegel. Rapid ai development cycle for the coronavirus (covid-19) pandemic: Initial results for
automated detection & patient monitoring using deep learning ct image analysis. arXiv preprint arXiv:2003.05037,
2020.
[7] X Xu, X Jiang, C Ma, P Du, X Li, S Lv, L Yu, Y Chen, J Su, G Lang, et al. Deep learning system to screen
coronavirus disease 2019 pneumonia. arxiv 2020. arXiv preprint arXiv:2002.09334, 2020.
[8] Linda Wang and Alexander Wong. Covid-net: A tailored deep convolutional neural network design for detection
of covid-19 cases from chest x-ray images. arXiv preprint arXiv:2003.09871, 2020.
[9] Yann LeCun, Yoshua Bengio, et al. Convolutional networks for images, speech, and time series. The handbook of
brain theory and neural networks, 3361(10):1995, 1995.
[10] François Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE
conference on computer vision and pattern recognition, pages 1251–1258, 2017.
[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.
[12] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition.
arXiv preprint arXiv:1409.1556, 2014.
[13] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255. Ieee, 2009.
[14] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy
Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael
Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat
Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever,
Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden,
Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on
heterogeneous systems, 2015. Software available from tensorflow.org.
[15] François Chollet et al. Keras. https://github.com/fchollet/keras, 2015.
[16] Joseph Paul Cohen, Paul Morrison, Lan Dao, Karsten Roth, Tim Q Duong, and Marzyeh Ghassemi. Covid-19
image data collection: Prospective predictions are the future. arXiv preprint arXiv:2006.11988, 2020.
[17] Daniel Kermany, Kang Zhang, and Michael Goldbaum. Labeled optical coherence tomography (oct) and chest
x-ray images for classification. Mendeley data, 2, 2018.

6

