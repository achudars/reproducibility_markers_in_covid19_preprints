Stacked Convolutional Neural Network for Diagnosis of
COVID-19 Disease from X-ray Images
Mahesh Gour

arXiv:2006.13817v1 [eess.IV] 22 Jun 2020

1,2

1∗

, Sweta Jain

2

∗ corresponding author: maheshgour0704@gmail.com
Maulana Azad National Institute of Technology, Bhopal, MP, India 462003

Abstract
Automatic and rapid screening of COVID-19 from the chest X-ray images has
become an urgent need in this pandemic situation of SARS-CoV-2 worldwide in
2020. However, accurate and reliable screening of patients is a massive challenge
due to the discrepancy between COVID-19 and other viral pneumonia in X-ray
images. In this paper, we design a new stacked convolutional neural network
model for the automatic diagnosis of COVID-19 disease from the chest X-ray
images. We obtain different sub-models from the VGG19 and developed a 30layered CNN model (named as CovNet30) during the training, and obtained
sub-models are stacked together using logistic regression. The proposed CNN
model combines the discriminating power of the different CNN's sub-models and
classifies chest X-ray images into COVID-19, Normal, and Pneumonia classes.
In addition, we generate X-ray images dataset referred to as COVID19CXr,
which includes 2764 chest x-ray images of 1768 patients from the three publicly
available data repositories. The proposed stacked CNN achieves an accuracy
of 92.74%, the sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 for
the classification of X-ray images. Our proposed approach shows its superiority
over the existing methods for the diagnosis of the COVID-19 from the X-ray
images.
Keywords: COVID-19, automatic screening, stacked generalization, ensemble
technique, deep learning, logistic regression, chest X-ray images.

Preprint submitted to Journal of LATEX Templates

June 25, 2020

1. INTRODUCTION
The Novel coronavirus disease 2019 (COVID-19) pandemic has put the livelihoods and health of the massive population in a critical position. It has led to
the disturbance throughout the public life of the world population. The severe
acute respiratory syndrome coronavirus 2 (SARSCoV-2) belongs to the family
of Coronavirus, which get transmitted in the people based on the infection in
the form of direct contact or fomites. The primary symptoms of coronavirus
infection are fever, cough and fatigue. In several cases coronavirus cause severe
respiratory problems like Pneumonia, lung disorders and kidney malfunction.
The virus has serious consequences as its serial interval is 5 to 7.5 days, and the
rate of reproduction is 2 to 3 [1] people. The coronavirus infection can incite
SARS (Severe Acute Respiratory Syndrome), which might unfold serious health
impacts.
It is estimated that many people are healthy carriers of a virus, and they
are the reason for about 5% to 10% of acute respiratory infections [2]. A critical
step to fight against the COVID-19 is to identify the infected people so that
they get immediate treatment and isolate them to control the multiplying of
the spread of the infection.
The COVID-19 panic has increased due to the unavailability of fast and accurate diagnosis systems to test the infected people. According to the World
Health Organization (WHO), the diagnosis of COVID-19 cases must be confirmed by molecular assay, such as the reverse transcription polymerase chain
reaction (RT-PCR) pathological test using throat swab samples [3]. While RTPCR has become a standard tool for confirmation of COVID-19, but it is a very
time consuming, laborious, and manual process, and there is a limitation of availability of diagnostic kits and sample collection. The availability of COVID-19
testing kits is limited as compared to the increasing amount of infected people;
hence there is a need to rely on different diagnosis methodologies.
The coronavirus targets the epithelial cells that affect patients respiratory
tract, which can be analyzed by the radiological images of a patients lungs.

2

Some early studies also show that patients present anomalies in chest x-ray images, which are the typical characteristics of COVID-19 infected patients [4, 5].
Hence, the development of the computer-aided diagnosis system for the automatic analysis of radiological images can be very helpful in identifying infected
patients at a faster rate. Some the advantage of the using X-ray images for
COVID-19 screening as follows:
• Enable fast screening and rapid triaging of patients suspected of COVID19.
• Making use of readily available and accessible radiological images.
• Portable and easy to setup, these systems can be setup in the isolation
room, which significantly minimizes the risk of transmission.
Recent advancements in deep learning specifically in Convolution Neural
Network (CNN) motivated us to develop a highly reliable computer-aided diagnosis (CAD) systems for the rapid detection of the COVID-19 using chest X-ray
images. It will enable and enhance the automation in the screening phase, which
is the crucial part of the COVID-19 pandemic. In this study, we design a new
stacked convolutional neural network for automatic diagnosis of COVID-19 disease from the chest X-ray images. To train the proposed model, we generated
chest X-ray images dataset, with the combination and modification of three
publicly available datasets [6, 7, 8], which we will refer to as COVID19CXr.
The organization of this paper as follows: Section 2 presents the related
work. Section 3 describes the proposed stacked CNN model for the classification
of COVID-19, Normal, and Pneumonia X-ray images. Section 4 describes the
COVID19CXr dataset generation process and details the experimental results,
performance comparison. Finally, the conclusion is drawn in Section 5.

2. RELATED WORK
Over the past 40 years, many computer-aided systems have been developed
for the diagnosis of lung disease [9] and achieved promising results for automatic
3

detecting lung abnormality from the radiological images [10, 11, 12].
Recently, automatic CAD of COVID-19 using radiological images has drawn
a lot of attention of researchers and as a result several approaches have been introduced in literature. They have published a series of research articles [13, 14]
demonstrating the CAD systems for the detection of COVID-19 using radiological images. Butt at el. [15] have studied various CNN models technically
and proposed a model with the combination of 2D and 3D CNN models for
the classification of the CT images into COVID-19, Influenza viral pneumonia,
or no-infection. Their approach achieved a sensitivity of 98.2 % and specificity
of 92.2 %. Ardakani et al. [16] have presented the application of deep learning in COVID-19 detection using CT images. Authors tested ten pre-trained
CNN models namely AlexNet, MobileNet-V2 VGG-16, VGG-19, ResNet-18,
ResNet-50, ResNet-101, SqueezeNet, GoogleNet, and Xception. Their experiment results showed that ResNet101 performed best with area under the curve
(AUC) of 0.99 over 1020 CT images of 194 patients.
Similarly, Narin et al. [17] have applied ResNet50, InceptionV3 and InceptionResNetV2 using transfer learning for classification of the X-ray images into
normal and COVID-19 class. This method achieved good performance with an
accuracy of 98 % with ResNet50. However, the number of X-ray images are only
100 and the number of images was very less. Wang et al. [18] have proposed an
open-source COVID-Net model based on the projection-expansion-projection
design pattern for COVID-19 cases detection from the X-ray images. In this
study, the authors reported an accuracy of 92.6 %. Oh et al. [19] have proposed
patch-based CNN approach, to train ResNet18 model using image patches that
have been extracted from the chest x-ray images. For decision making, they
used the majority voting strategy, which resulted in an accuracy of 88.9 %.
An objected detection based DarkCovidNet model has been proposed by
Ozturk et al. [20] for automatic detection of COVID-19 cases from the Xray images. They have reported accuracy of 98.08 % for binary classification
of X-ray images into COVID-19 and no-findings, and also this approach has
achieves an accuracy of 87.02 % for multi-class classification of X-ray images
4

into COVID-19, no-findings and pneumonia. Pereira et al. [21] have proposed
a hierarchical classification approach, in which they extracted deep features by
InceptionV3 and tested texture descriptors. They investigated early and late
fusion techniques for combining the strength of descriptor and classifiers. Their
hierarchical classification approach achieved F1-Score of 0.89 for the COVID-19
identification in the X-ray images.
Attention-based deep 3D multiple instance learning approach has been proposed by the Han et al. [22] for automatic screening of COVID-19 from the
CT images. Their algorithm achieved an accuracy of 97.9%. Wang et al. [23]
developed a weakly supervised deep learning framework, in which lung region
was segmented by UNet from the CT images and 3D deep neural network is applied on the segmented region for predicting probability of COVID-19 infections.
Authors reported an accuracy of 90.10%.
Ucar et al. [24] proposed a SqueezeNet CNN model with Bayesian optimization for diagnosis of the COVID-19 from X-ray images. They reported
an accuracy of 98.26 %. Afshar et al. [25] developed a capsule network-based
framework for the classification of the X-ray images into Normal, bacterial,
Non-COVID, and COVID-19 cases. The authors reported an accuracy of 95.7
% and a sensitivity of 90 %. Sethy et al. [26] extracted deep features of X-ray
images from the pre-trained CNN, and support vector machine (SVM) has been
applied on the extracted feature to classify x-ray images. The authors achieved
an accuracy of 95.38% using ResNet50 with the SVM classifier.

3. METHODOLOGY
The Convolution Neural Network is the driving concept of deep learning
algorithms in computer vision, which led to outstanding performance in most
of the pattern recognition tasks such as image classification [27, 28, 29], object
localization, segmentation and detection [30, 31, 32]. It has also shown its superiority in the medical image analysis for image classification, and segmentation
problem [33, 34, 35, 36], especially in lung-related diseases such as lung nodule

5

detection [37], pneumonia detection [38], and pulmonary tuberculosis [39]. CNN
automatically learns a low to the high level of useful feature representations and
integrates feature extraction and classification stages in a single pipeline, which
is trainable in an end-to-end manner without requiring any manual design and
expert human intervention.
In this work, we have developed a deep learning-based stacked convolutional
neural network for the rapid screening of COVID-19 patients using X-ray images.
The proposed COVID-19 detection method includes three modules as shown in
the Figure 1. In the first module, a new 30-layered CNN model is built and
trained on the chest X-ray images from scratch, which will be referred to as
CovNet30 (Covid-19 Network of 30-layers). In the second module, a pretrained VGG19 model [27] is fine-tuned on X-ray images for the diagnosis of
COVID-19 disease. Finally, in the last module, five CNN's sub-models are
obtained, during the training of CovNet30 and VGG19 models. The output
of CNN's sub-models are stacked together by applying logistic regression [40]

Figure 1: Block diagram of proposed Stacked CNN model

6

for building a new final CNN model for diagnosis of COVID-19 disease from
X-ray images. A detailed description of the proposed approach is given in the
following section:
3.1. CovNet30 Architecture and Training
The CovNet30 is a task-specific, 30-layered convolutional neural network
for X-ray images classification. It learns the non-linear, discriminative features
directly from the chest X-ray images at multiple levels of abstraction. A detailed
layer configuration of the CovNet30 network is shown in Table 1. CovNet30 is
sequential network, in which Convolutional layer with ReLU activation, pooling
layer, Batch Normalization layer and dropout layer are added repetitively. Every
layer of CovNet30 produce a volume of activation to the next layer through a
differentiable function. Description of layers are given as follows:
• Convolution Layer extracts features from the input volume by performing
convolution operation. In the convolution operation, the dot product is
computed between the kernels and connected local regions of the input
volume of activation.
• ReLU activation function is an elementwise activation function. If x is
input of ReLU then it produce max(0, x) (non-negative value) in the
output.
• Pooling layer down sampling feature maps and reduces the computation
in the network.
• Batch Normalization layer speed up the learning process and improves
network stability by minimizing the internal covariate shift.
• Dropout is a regularization method, which prevents the network from the
overfitting by dropping out units in the network.
CovNet30 has been trained on the X-ray images in a supervised manner.
Cross-entropy loss function is used to calculate the training error and which

7

Table 1: Detailed layer configuration of CovNet30 network
Layer Name

Type

Kernal Size

Output

Parameters

conv2D 1

Convolutional + ReLU

7×7

218 × 218 × 32

4736

max pooling 1

Max Pooling

2×2

109 × 109 × 32

0

batchNo 1

Batch Normalization

-

109 × 109 × 32

128

conv2D 2

Convolutional + ReLU

5×5

105 × 105 × 64

51264

max pooling 2

Max Pooling

2×2

52 × 52 × 64

0

batchNo 2

Batch Normalization

-

52 × 52 × 64

256

dropout 1

Dropout

-

52 × 52 × 64

0

conv2D 3

Convolutional + ReLU

3×3

50 × 50 × 128

73856

max pooling 3

Max Pooling

2×2

25 × 25 × 128

0

batchNo 3

Batch Normalization

-

25 × 25 × 128

512

dropout 2

Dropout

-

25 × 25 × 128

0

conv2D 4

Convolutional + ReLU

3×3

23 × 23 × 128

147584

max pooling 4

Max Pooling

2×2

11 × 11 × 128

0

batchNo 4

Batch Normalization

-

11 × 11 × 128

512

-

11 × 11 × 128

0

3×3

9 × 9 × 256

295168

dropout 3

Dropout

conv2D 5

Convolutional + ReLU

batchNo 5

Batch Normalization

-

9 × 9 × 256

1024

dropout 4

Dropout

-

9 × 9 × 256

0

conv2D 6

Convolutional + ReLU

3×3

7 × 7 × 256

590080

batchNo 6

Batch Normalization

-

7 × 7 × 256

1024

dropout 5

Dropout

-

7 × 7 × 256

0

3×3

5 × 5 × 512

1180160

-

5 × 5 × 512

2048

-

5 × 5 × 512

0

3×3

3 × 3 × 512

2359808

conv2D 7

Convolutional + ReLU

batchNo 7

Batch Normalization

dropout 6

Dropout

conv2D 8

Convolutional + ReLU

batchNo 8

Batch Normalization

-

3 × 3 × 512

2048

dropout 7

Dropout

-

3 × 3 × 512

0

globAvgPooling

Global AvgPooling

-

512

0

FC 1

Fully Connected + ReLU

-

1000

513000

FC 2

Fully Connected + Softmax

-

3

3003

is minimize using the ADAM optimizer [41]. Cross-entropy loss function is
mathematical represented in equation (1).

8

J(T, P ) = −

C
X

ti log (pi )

(1)

i=1

Where ti and pi are the target value and predicted probability for each class i
in C.
In the experiment, the values of hyper-parameter are set as follows: learning
rate to 0.001, the batch size to 16, and dropout probability to 0.15. we experimentally find that these are the best suitable values of hyper-parameters for
network training.
3.2. Fine-Tuning of VGG19
The VGG19 is a pre-trained network that is trained on the ImageNet dataset,
which achieved state-of-the-art performance on ILSVRC Challenge 2014. It
also achieves outstanding performance on the other image recognition datasets.
Hence, we have also used VGG19 along with CovNet30 for generating submodels.
To fine-tune the VGG19 on X-ray images, the top layers (Fully-connected
layer, and Softmax layer) of the VGG19 network are removed. We added new
layers such as two Convolutional layers with ReLU activation, a Global Average
Pooling layer, a Fully-connected layer, and a Softmax layer, at the top of the
VGG19 network. Hyper parameters for the fine-tuning of VGG19 are same as
the CovNet30.
3.3. Stacked Convolutional Neural network
Stacked generalization [42] is an ensemble approach in which a new model
learns how to incorporate the best predictions of multiple existing models. The
proposed approach hypothesized that different CNN's sub-models learn nonlinear discriminative features and semantic image representation from the images at different levels. Thus a stacked ensemble CNN model will be generalized
and highly accurate. This section describes the proposed stacked convolutional
neural network.

9

The pseudo-code of sub-models generation process is given in Algorithm 1.
In this process the Covid19CXr dataset is divided in the train set, validation set
and test set. The CovNet30 and VGG19 are trained on chest x-ray images of
the training set for the 1530 iterations and 2121, respectively. During training
Algorithm 1 Sub-model Generation process
Input: X-ray images of the chest
Output: sub-models
1:

Divide Covid19CXr dataset into training set, validation set and test set.

2:

Apply data augmentation on train set.

3:

Train CovNet30 and VGG19, and generate sub-models:
Initialisation : class weight = [0:30, 1:1, 1:1]

4:

for i = 1 to N do

5:

Train(CovNet30, train img, img label, class weight)

6:

if (i == l1) then

7:
8:
9:

sub-model#1 = save(CovNet30)
end if
end for

10:

sub-model#2 = save(CovNet30)

11:

for i = 1 to M do

12:

Train(VGG19, train img, img label, class weight)

13:

if (i == l1) then

14:
15:
16:
17:
18:
19:

sub-model#3 = save(VGG19)
else
if (i == l2) then
sub-model#4 = save(VGG19)
end if
end if

20:

end for

21:

sub-model#5 = save(VGG19)

22:

return sub-models

10

of CovNet30, we have extracted the first sub-model#1 after 765 iterations and
second sub-model#2 after completion of the training. Similarly, during finetuning of VGG19, we have extracted sub-model#3 after 707 iterations, submodel#4 after 1414 iterations, and sub-model#5 at last.
To deal with the class imbalance problem, we have assigned class weights
while training of the networks. In this process, class weight in ratio of 30:1:1 is
assigned to COVID-19, Pneumonia, and Normal class, respectively.
The performance of the sub-models varies across complex CAD systems, and
it is reasonable to combine the strengths of sub-models which might result in increased overall accuracy. Hence, we combined the sub-models output by logistic
regression [40] to build a highly accurate and reliable generalized model. The
pseudo-code of the process of creating stacked CNN is represented in Algorithm
2.
Algorithm 2 Stacked Convolutional Neural network and X-ray image Classification
Input: Validation set, test set, and sub-models
Output: Classification results
1:

Sub-Models Stacking:

2:

for i = 1 to length(validation set) do

3:
4:

for j = 1 to 5 do
[P 1ji , P 2ji , P 3ji ] = sub-model#(j).predict(validation img[i])

5:

end for

6:

P = concatenation([P 1ji , P 2ji , P 3ji ]

7:

end for

8:

Fit logistic regression on feature vector P

9:

stacked model = fit.regression(P, validation label)

10:

Classifies X-ray image

11:

pred label = classify(stacked model, test img)

12:

return pred label

The hypothesis representation of logistic regression model is as shown below:
11

Hθi (x) = g(θT x)

where g(z) =

hence Hθi (x) =

(2)

1
1 + e−z

(3)

1
1 + e−θT x

(4)

Where Hθi (x) is estimated probability p(y = i/x; θ) for each class i (where
i ∈ {0 : COV ID − 19, 1 : N ormal, 2 : P neumonia}) of a image x.
Next, we train a logistic regression model Hθi (x) using a one-vs-rest scheme
[43] for each class i. For its training, we prepared dataset by providing X-ray
images from the validation set to each of the sub-models and collects predictions.
In this case, every sub-model j predicts three probabilities (P 1ji , P 2ji , P 3ji )
for each X-ray image i of that a given image i belongs to each of the COVID-19,
Normal, and Pneumonia classes. Let’s say M X-ray images in the validation set,
and we concatenate the output probabilities of these five sub-models that become our feature vector PM ×15 for the training of the logistic regression model.
After training of the stacked model, on new input image x from the test set, to
make a prediction, pick the class i that maximizes maxi (Hθi (x)).
4. EXPERIMENTS
This section presents the details of the dataset, evaluation metrics, experiments results and performance comparison.
4.1. Covid19CXr Dataset Generation
In order to train and evaluate the performance of the proposed model, we
generated X-ray images dataset, with the combination and modification of three
publicly available datasets [6, 7, 8], which are referred as COVID19CXr. The
COVID19CXr includes 2764 chest X-ray images of 1768 patients. Out of 2764
images, 270 images of 170 patients belong to a COVID-19 class, 1139 images of

12

(a) COVID-19

(b) NORMAL

(c) PNEUMONIA
Figure 2: Samples of X-ray images of Chest from the database; where image in (a) COVID-19,
(b) NORMAL, (c) PEUMONIA

1015 patients belong to Normal class and 1355 images of 583 patients belong
to a Pneumonia class. COVID-19 images are obtained from the two publicly
available repositories: 1) “Figure-1 COVID-19 Chest X-ray Dataset Initiative”
[6] and 2) “COVID-19 Image Data Collection” [7]. Pneumonia and Normal
cases images are included from the “Mendeley data 2” [8]. Figure 2 shows the
sample chest X-ray images of COVID-19, Normal and Pneumonia classes from
the COVID19CXr dataset.
For the performance assessment of the proposed method, we have used 5fold cross-validation approach, in which the dataset is divided into 5-folds at the
patient level. Table 2 gives details of the distribution of images in the training
set, validation set, and test set corresponding to each fold. The training set and

13

Table 2: Images distribution in the train set, validation set and test set, corresponding to
folds

Fold (s)

Fold1

Fold2

Fold3

Fold4

Fold5

Data set (s)

COVID-19

Normal

Pneumonia

Total

Train Set

189

798

948

1935

Validation set

25

113

136

274

Test Set

56

228

271

555

Train Set

190

799

951

1940

Validation set

27

113

135

275

Test Set

53

227

269

549

Train Set

189

798

950

1937

Validation set

26

113

134

273

Test Set

55

228

271

554

Train Set

193

797

945

1935

Validation set

27

114

136

277

Test Set

50

228

274

552

Train Set

189

798

952

1939

Validation set

25

113

136

274

Test Set

56

228

267

551

validation set are used while training the network, and an hold-out test set is
used for the performance assessment of the proposed model.
4.2. Evaluation Metrics
To assess the performance of proposed method we have used sensitivity,
specificity, accuracy, positive prediction value (PPV), F1-score, area under the
curve (AUC) and confusion matrix as evaluation metrics. The mathematical
definition for the evaluation metrics is given below (in Eqn. (5), Eqn. (6), Eqn.
(7), Eqn. (8) and Eqn. (9) respectively):

Accuracy =

(T P + T N )
(T P + T N + F P + F N )

14

(5)

TP
(T P + F P )

PPV =

(6)

Sensitivity =

TP
(T P + F N )

(7)

Specif icity =

TN
(T N + F P )

(8)

2T P
(2T P + F P + F N )

(9)

F 1 − Score =

Where true positive (TP), true negative (TN), false positive (FP), and false
negative (FN) are the parameters of confusion matrix. The present study deals
with a multi-class problem; therefore, to get the overall metric score of the
method, we calculated the mean of each metric.
4.3. Results and discussion
In order to evaluate the performance of our proposed stacked convolutional
neural network, we conduct a set of experiments. In the first experiment, data
augmentation techniques such as flip, rotation, shear, zoom, and shift have been
applied on a training set. Thereafter, the augmented training set is utilized
for the training of CovNet30 model and fine-tuning VGG19 model. In the
second experiment, the stacked CNN model is trained on the validation set.
Finally, evaluation results are produced on the test set. We repeat the same
Table 3: Diagnosis performance of stacked CNN model.
Sensitivity

Specificity

Accuracy

Err ± CI

PPV

(%)

(%)

(%)

(%)

(%)

Fold1

95.5

98.19

96.94

3.06±1.42

Fold2

92.66

94.97

91.44

8.56±2.39

Fold3

91.45

95.01

91.34

Fold4

92.47

94.77

Fold5

94.59

96.12

Mean

93.33

95.81

Fold (s)

F1-Score

AUC ± CI

97.69

0.97

0.989±0.003

91.32

0.92

0.982±0.015

8.66±2.35

92.13

0.92

0.982±0.011

90.22

9.78±2.48

85.97

0.88

0.977±0.023

93.74

6.26±2.02

93.54

0.94

0.981±0.009

92.74

7.26±2.16

92.13

0.93

0.984±0.012

“Err ± CI”: classification error (Err) with 95% confidence interval (CI).
“AUC ± CI”: area under the curve (AUC) with 95% confidence interval (CI).

15

set of experiments five times for each fold. The following sections represent the
experimental results and performance comparison.
4.3.1. Discrimination power of stacked CNN model:
Table 3 presents the diagnostic performance of stacked CNN and it shows
good discrimination ability for the diagnosis of the COVID-19 from the chest

(a) Fold1

(b) Fold2

(c) Fold3

(d) Fold4

(e) Fold5
Figure 3: Confusion matrix for stacked CNN model on the different folds.

16

X-ray images. The proposed model achieved mean sensitivity of 93.33 %, specificity of 95.81 %, PPV of 92.74 %, and accuracy of 92.74 % to classify: COVID19, Normal and Pneumonia classes. Our method achieved good sensitivity; so
that we can limit the miss classification of the COVID-19 positive cases. In ad-

(a) Fold1

(b) Fold2

(c) Fold3

(d) Fold4

(e) Fold5
Figure 4: ROC curve for stacked CNN model on the different folds.

17

dition, the confidence interval for the classification error and AUC is calculated
at the 95% confidence level. As shown in Table 3 the classification error of the
proposed model is 7.26% ± 2.16% at the 95% confidence level.
For a deeper exploration of the performances of the proposed method the
confusion matrix and receiver operating characteristic (ROC) curve (with AUC's
CI) corresponding to each fold are evaluated and shown in Figure 3 and Figure 4,
respectively. It can be observed from the confusion matrix the proposed model
produce very less false negative and false positive, specifically for the COVID-19
cases compared to other cases of COVID19CXr dataset. For COVID-19 cases,
it is essential to minimize the wrong diagnosis. On the other hand, the ROC
curve shows the stability of the proposed stacked CNN model, and the present
model achieved a mean AUC of 0.994 for COVID-19 class and a mean AUC of
0.984 along with CI of [0.012]for all categories.
4.3.2. Performance comparison:
Table 4 shows the performance comparison of the proposed method, VGG19
and CovNet30. It is observed from Table 4 that the proposed model achieves the
best accuracy of 92.74 % compared to stand-alone model VGG19 and CovNet30,
our stacked CNN model improves the diagnosis accuracy by 2.88% ∼ 5.01%.
In terms of sensitivity, specificity, and PPV, proposed model also shows sigTable 4: Performance comparison for different methods.

Method
Metric
VGG19

CovNet30

Proposed

Accuracy (%)

89.86±2.21

87.73±3.08

92.74±2.68

Sensitivity (%)

90.34±4.24

86.80±4.05

93.33±1.66

Specificity (%)

94.15±1.26

93.49±1.39

95.81±1.43

PPV (%)

90.53±2.96

84.54±5.23

92.13±4.23

F1-score

0.90±0.03

0.85±0.04

0.93±0.03

AUC

0.97±0.01

0.97±0.02

0.98±0.01

18

Table 5: Performance evaluation of the sub-models.

Model (s)

Fold1

Fold2

Fold3

Fold4

Fold5

Sub-model1

86.3

89.4

51.6

59.1

84

Sub-model2

95.7

91.1

86.5

83.5

90.4

Sub-model3

85.4

84.9

89.4

85.9

57.5

Sub-model4

93.3

87.8

79.6

90.2

79.9

Sub-model5

92.8

89.4

87.9

90.4

91.1

96.94

91.44

91.34

90.22

93.54

CovNet30

VGG19

Proposed model

nificant performance improvements by 2.99% ∼ 6.53%, 1.66% ∼ 2.32%, and
1.6% ∼ 7.59%, respectively.

Further, Table 5 represents the performance of

the individual sub-models and the proposed stacked CNN model corresponding
to each fold. Our stacked ensemble CNN model achieved better performance as
compared to all sub-models, over the each fold.
A variety of deep learning-based studies have already been proposed in past
studies for COVID-19 diagnosis from the chest X-ray images. The performance
comparison of the proposed method in the present study with some of related
studies are shown in the Table 6.
Since COVID-19 is a new epidemic and there are limited number of COVID19 X-ray images are available publicly for developing CAD systems for COVID19 detection. Studies in [26] and [17] have just developed on the 25 and 50
images for each class, respectively. Other studies in the [18, 19, 20, 21, 24] have
used less 200 COVID-19 images for developing their methods. In this study,
a total of 2764 X-ray images has been used to develop our model, including
270 COVID-19 images, which the largest number of COVID-19 images among
all the studies in Table 6. It can be observed from Table 6 that for the multiclass classification task, the proposed approach shows the superiority over the
methods in [18, 19, 20, 21], except the method in [24], which has higher accuracy.
However, sensitivity is higher for our approach.
Some of the salient features of stacked CNN can be summarized as:

19

Table 6: Performance comparison with existing methods
Dataset
Author (s)

Method

Classification Task
Modality

Narin et al. [17]

Pre-Train CNN

X-ray

Results

Subjects
50 COVID-19,

Binary: COVID-19,

50 Normal

Normal

97 % (Acc)

183 COVID-19,
Wang et al. [18]

COVID-Net

X-ray

Multiclass: COVID-19,
8066 Normal,

92.6% (Acc)

Normal, Non-COVID19
5538 non-COVID19
191 Normal,

Oh et al. [19]

ResNet18

X-ray

54 Bacterial,

Multiclass: Normal,

57 Tuberculosis,

Bacterial, Tuberculosis,

20 Viral,

Viral, COVID-19

88.9% (Acc)

180 COVID-19
127 COVID-19,
Ozturk et al. [20]

DarkCovidNet

X-ray
500 no-findings,
500 pneumonia

Binary: COVID-19,

98.08% (Acc)

No-findings
Multiclass: COVID-19,

87.02% (Acc)

No-findings, Pneumonia
200 Normal,
180 COVID-19,
Hierarchical: Normal,
22 SARS,

Deep features,
Pereira et al. [21]

Texture features,

COVID-19, SARS,

X-ray

20 MERS,

0.89 (F1-score)

MERS, Pneumocystis,
22 Pneumocystis,

Fusion techniques

Streptococcus, Varicella
24 Streptococcus,
20 Varicella
1583 Normal,
Ucar et al. [24]

SqueezeNet CNN

X-ray

Multiclass: Normal,

95.7 % (Acc),

Pneumonia, COVID-19

90 % (Sens)

4290 Pneumonia,
76 COVID-19

Sethy et al. [26]

Deep feature, SVM

X-ray

25 COVID-19+,

Binary: COVID-19+,

25 COVID-19-

COVID-19-

270 COVID-19,
Proposed Method

Stacked CNN

X-ray

95.38% (Acc)
92.74% (Acc)

Multiclass: COVID-19,
93.33 % (Sens)

1139 Normal,
Normal, Pneumonia
1355 Pneumonia

0.93 (F1-Score)

• The proposed method is based on the stacked generalization of CNN's
sub-models, which minimizes the variance of predictions and reduces generalization error. As of the result, stacked CNN yields high diagnosis
accuracy in the X-ray images.
• The proposed stacked CNN model produces very less false positive (type
1) and false negative (type 2) error, which confirms that the stacked CNN
is reliable for clinical uses.
• The proposed model is developed based on a less complex network, which
20

computationally efficient and shows its stability on a small dataset.

5. CONCLUSION
In this paper, we introduced a new stacked convolutional neural network
for the automatic diagnosis of the COVID19 from the Chest X-ray images. In
the proposed method, CNN's sub-models have obtained from our developed
CovNet30 model and pre-trained VGG19 model. Stacked CNN model ensemble
the sub-models using logistic regression, for deriving a powerful model for image
classification than individual sub-models. The proposed model is able to learn
image discriminative features and retrieved the diverse information present in
the X-ray images of the chest. It achieves a classification accuracy of 92.74%,
sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 on the chest X-ray
images of COVID19CXr dataset. Our proposed approach shows its superiority
over the existing methods for the diagnosis of the COVID-19 from the X-ray
images.
Our experiments results show the effectiveness of the stacked CNN for classification of COVID-19, Normal, and Pneumonia X-ray images. More importantly, the proposed model outperforms the pre-trained VGG19 and CovNet30
model for the classification of X-ray images.

References
[1] H. Nishiura, N. M. Linton, A. R. Akhmetzhanov, Serial interval of novel
coronavirus (covid-19) infections, International journal of infectious diseases (2020).
[2] Y. Chen, Q. Liu, D. Guo, Emerging coronaviruses: genome structure, replication, and pathogenesis, Journal of medical virology 92 (4) (2020) 418–423.
[3] W. H. Organization,
nical
World

guidance:
Health

et al.,

laboratory
Organization,

Novel coronavirus (2019-ncov) techtesting
Geneva,
21

for

2019-ncov

Switzerland.

in

humans,

https://www.

who.

int/emergencies/diseases/novel-coronavirus-2019/technical-

guidance/laboratory-guidance (2020).
[4] M.-Y. Ng, E. Y. Lee, J. Yang, F. Yang, X. Li, H. Wang, M. M.-s. Lui,
C. S.-Y. Lo, B. Leung, P.-L. Khong, et al., Imaging profile of the covid-19
infection: radiologic findings and literature review, Radiology: Cardiothoracic Imaging 2 (1) (2020) e200034.
[5] C. Huang, Y. Wang, X. Li, L. Ren, J. Zhao, Y. Hu, L. Zhang, G. Fan,
J. Xu, X. Gu, et al., Clinical features of patients infected with 2019 novel
coronavirus in wuhan, china, The lancet 395 (10223) (2020) 497–506.
[6] C. et al., Figure 1 covid-19 chest x-ray data initiative. (2020).
URL https://github.com/agchung/Figure1-COVID-chestxraydataset
[7] J. P. Cohen, P. Morrison, L. Dao, Covid-19 image data collection, arXiv
preprint arXiv:2003.11597 (2020).
URL https://github.com/ieee8023/covid-chestxray-dataset
[8] D. Kermany, K. Zhang, M. Goldbaum, Labeled optical coherence tomography (oct) and chest x-ray images for classification, Mendeley data 2 (2018).
[9] K. Doi, Computer-aided diagnosis in medical imaging: historical review,
current status and future potential, Computerized medical imaging and
graphics 31 (4-5) (2007) 198–211.
[10] G. Castellano, L. Bonilha, L. Li, F. Cendes, Texture analysis of medical
images, Clinical radiology 59 (12) (2004) 1061–1069.
[11] B. Van Ginneken, S. Katsuragawa, B. M. ter Haar Romeny, K. Doi, M. A.
Viergever, Automatic detection of abnormalities in chest radiographs using
local texture analysis, IEEE transactions on medical imaging 21 (2) (2002)
139–149.
[12] S. Jaeger, A. Karargyris, S. Candemir, L. Folio, J. Siegelman, F. Callaghan,
Z. Xue, K. Palaniappan, R. K. Singh, S. Antani, et al., Automatic tuber22

culosis screening using chest radiographs, IEEE transactions on medical
imaging 33 (2) (2013) 233–245.
[13] F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, K. He, Y. Shi, D. Shen,
Review of artificial intelligence techniques in imaging data acquisition, segmentation and diagnosis for covid-19, IEEE Reviews in Biomedical Engineering (2020).
[14] D. Dong, Z. Tang, S. Wang, H. Hui, L. Gong, Y. Lu, Z. Xue, H. Liao,
F. Chen, F. Yang, et al., The role of imaging in the detection and management of covid-19: a review, IEEE Reviews in Biomedical Engineering
(2020).
[15] C. Butt, J. Gill, D. Chun, B. A. Babu, Deep learning system to screen
coronavirus disease 2019 pneumonia, Applied Intelligence (2020) 1.
[16] A. A. Ardakani, A. R. Kanafi, U. R. Acharya, N. Khadem, A. Mohammadi,
Application of deep learning technique to manage covid-19 in routine clinical practice using ct images: Results of 10 convolutional neural networks,
Computers in Biology and Medicine (2020) 103795.
[17] A. Narin, C. Kaya, Z. Pamuk, Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks,
arXiv preprint arXiv:2003.10849 (2020).
[18] L. Wang, A. Wong, Covid-net: A tailored deep convolutional neural network design for detection of covid-19 cases from chest radiography images,
arXiv preprint arXiv:2003.09871 (2020).
[19] Y. Oh, S. Park, J. C. Ye, Deep learning covid-19 features on cxr using
limited training data sets, IEEE Transactions on Medical Imaging (2020).
[20] T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu, O. Yildirim, U. R.
Acharya, Automated detection of covid-19 cases using deep neural networks
with x-ray images, Computers in Biology and Medicine (2020) 103792.

23

[21] R. M. Pereira, D. Bertolini, L. O. Teixeira, C. N. Silla Jr, Y. M. Costa,
Covid-19 identification in chest x-ray images on flat and hierarchical classification scenarios, Computer Methods and Programs in Biomedicine (2020)
105532.
[22] J. Wang, Y. Bao, Y. Wen, H. Lu, H. Luo, Y. Xiang, X. Li, C. Liu, D. Qian,
Prior-attention residual learning for more discriminative covid-19 screening
in ct images, IEEE Transactions on Medical Imaging (2020).
[23] S. Hu, Y. Gao, Z. Niu, Y. Jiang, L. Li, X. Xiao, M. Wang, E. F. Fang,
W. Menpes-Smith, J. Xia, et al., Weakly supervised deep learning for covid19 infection detection and classification from ct images, arXiv preprint
arXiv:2004.06689 (2020).
[24] F. Ucar, D. Korkmaz, Covidiagnosis-net: Deep bayes-squeezenet based diagnostic of the coronavirus disease 2019 (covid-19) from x-ray images, Medical Hypotheses (2020) 109761.
[25] P. Afshar, S. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis, A. Mohammadi, Covid-caps: A capsule network-based framework
for identification of covid-19 cases from x-ray images, arXiv preprint
arXiv:2004.02696 (2020).
[26] P. K. Sethy, S. K. Behera, Detection of coronavirus disease (covid-19) based
on deep features, Preprints 2020030300 (2020) 2020.
[27] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with
deep convolutional neural networks, in: Advances in neural information
processing systems, 2012, pp. 1097–1105.
[28] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, 2016, pp. 770–778.
[29] K. Simonyan, A. Zisserman, Very deep convolutional networks for largescale image recognition, arXiv preprint arXiv:1409.1556 (2014).
24

[30] R. Girshick, J. Donahue, T. Darrell, J. Malik, Rich feature hierarchies for
accurate object detection and semantic segmentation, in: Proceedings of
the IEEE conference on computer vision and pattern recognition, 2014, pp.
580–587.
[31] R. Girshick, Fast r-cnn, in: Proceedings of the IEEE international conference on computer vision, 2015, pp. 1440–1448.
[32] M. Gour, S. Jain, R. Agrawal, Deeprnnetseg: Deep residual neural network for nuclei segmentation on breast cancer histopathological images,
in: International Conference on Computer Vision and Image Processing,
Springer, 2019, pp. 243–253.
[33] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for
biomedical image segmentation, in: International Conference on Medical
image computing and computer-assisted intervention, Springer, 2015, pp.
234–241.
[34] M. Gour, S. Jain, T. S. Kumar, Residual learning based cnn for breast cancer histopathological image classification, International Journal of Imaging
Systems and Technology (2020).
[35] S. M. Anwar, M. Majid, A. Qayyum, M. Awais, M. Alnowami, M. K.
Khan, Medical image analysis using convolutional neural networks: a review, Journal of medical systems 42 (11) (2018) 226.
[36] D. Shen, G. Wu, H.-I. Suk, Deep learning in medical image analysis, Annual
review of biomedical engineering 19 (2017) 221–248.
[37] X. Huang, J. Shan, V. Vaidya, Lung nodule detection in ct using 3d convolutional neural networks, in: 2017 IEEE 14th International Symposium
on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 379–383.
[38] P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding,
A. Bagul, C. Langlotz, K. Shpanskaya, et al., Chexnet: Radiologist-level

25

pneumonia detection on chest x-rays with deep learning, arXiv preprint
arXiv:1711.05225 (2017).
[39] C. Liu, Y. Cao, M. Alcantara, B. Liu, M. Brunette, J. Peinado, W. Curioso,
Tx-cnn: Detecting tuberculosis in chest x-ray images using convolutional
neural network, in: 2017 IEEE International Conference on Image Processing (ICIP), IEEE, 2017, pp. 2314–2318.
[40] L. Breiman, Stacked regressions, Machine learning 24 (1) (1996) 49–64.
[41] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv
preprint arXiv:1412.6980 (2014).
[42] D. H. Wolpert, Stacked generalization, Neural networks 5 (2) (1992) 241–
259.
[43] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay,
Scikit-learn: Machine learning in Python, Journal of Machine Learning
Research 12 (2011) 2825–2830.
URL

https://scikit-learn.org/stable/modules/generated/

sklearn.multiclass.OneVsRestClassifier.html

26

