FACE MASK ASSISTANT: DETECTION OF FACE MASK SERVICE STAGE BASED ON
MOBILE PHONE
Yuzhen Chen1 , Menghan Hu1 , Chunjun Hua1 , Guangtao Zhai2 , Jian Zhang1 ,Qingli Li1 , Simon X. Yang3
1

arXiv:2010.06421v1 [cs.CV] 9 Oct 2020

Shanghai Key Labora. of Multidim. Infor. Proce., East China Normal University, China
2
Key Laboratory of Artificial Intelligence, Ministry of Education, China
3
Advanced Robotics and Intelligent Systems Laboratory, School of Engineering, University of Guelph

ABSTRACT

Coronavirus Disease 2019 (COVID-19) has spread all over
the world since it broke out massively in December 2019,
which has caused a large loss to the whole world. Both the
confirmed cases and death cases have reached a relatively
frightening number. Syndrome coronaviruses 2 (SARS-CoV2), the cause of COVID-19, can be transmitted by small respiratory droplets. To curb its spread at the source, wearing
masks is a convenient and effective measure. In most cases,
people use face masks in a high-frequent but short-time way.
Aimed at solving the problem that we don’t know which service stage of the mask belongs to, we propose a detection system based on the mobile phone. We first extract four features
from the GLCMs of the face mask’s micro-photos. Next, a
three-result detection system is accomplished by using KNN
algorithm. The results of validation experiments show that
our system can reach a precision of 82.87%±8.50% on the
testing dataset. In future work, we plan to expand the detection objects to more mask types. This work demonstrates that
the proposed mobile microscope system can be used as an assistant for face mask being used, which may play a positive
role in fighting against COVID-19.
Index Terms— COVID-19 pandemic, use time of face
mask, textural feature, SARS-CoV-2, machine learning, image processing

This work is sponsored by the National Natural Science Foundation of
China (No. 61901172, No. 61831015, No. U1908210), the Shanghai Sailing Program (No.19YF1414100), the “Chenguang Program” supported by
Shanghai Education Development Foundation and Shanghai Municipal Education Commission (No. 19CG27), the Science and Technology Commission of Shanghai Municipality (No. 19511120100, No. 18DZ2270700, No.
14DZ2260800), the foundation of Key Laboratory of Artificial Intelligence,
Ministry of Education (No. AI2019002), and the Fundamental Research
Funds for the Central Universities.
Corresponding author: Menghan Hu (mhhu@ce.ecnu.edu.cn)

1. INTRODUCTION
COVID-19 has wreaked havoc around the world and the
spread of COVID-19 has not been curbed totally by June,
2020. According to the situation report of the WHO, there
have been 9,653,048 confirmed cases and 491,128 deaths
by 27 June 2020[1]. Recently, many researchers have developed a variety of detection methods of COVID-19, such
as reverse transcription-polymerase chain reaction (RT-PCR)
technology[2, 3], X-ray[4] and chest CT imaging[5]. In addition to the need for breakthroughs in testing techniques,
SARS-CoV-2 must be controlled at source to prevent a sustaining surge in COVID-19 confirmed and death cases. Small
respiratory droplets can transmit SARS-CoV-2, which is
known to be transmissible from presymptomatic and asymptomatic individuals[6]. One thing to reduce virus’s spreading
is wearing masks in public[6]. Advice on using face masks
proposed by the WHO[7], analysis[6] and researches[8] have
supported that wearing masks can prevent the spread of potential viruses during pandemic. An evidence research even
thinks that wearing masks in public is a symbol of social
solidarity among the response to the worldwide pandemic
[9]. The WHO recommends that the surgical face masks used
by health workers should be discarded once used and during severe shortages the extended use of faces masks can be
considered [10]. Because face masks only work when being
worn within their periods of validity. On the other hand, more
often in daily life, the majority of people wear surgical face
masks in short-time but high-frequent way and in low-risk or
middle-risk environment. The face masks may be used twice
or three times, even four or five times if in relatively safe environment and maintained properly, which is reasonable and
common especially under the condition where face masks are
in shortage.
In this case, there is no doubt that the service life of
masks depends on the use methods, use intensity, environmental condition and the material of masks, etc. In daily life,
it often happens that common people forget the service stage

of the current mask after having used it in the high-frequent
but short-time way. Meanwhile, the service life of face masks
decreases differently after being used in different conditions.
As a result, the masks’ remaining time of effective protection
varies. With those faces masks whose use time are unknown,
continuing to use them may lead to poor protection and other
unexpected incidents; discarding them directly is an inappropriate behavior. It is a waste of face masks, especially in the
case that masks are in shortage during the epidemic. It is
necessary to detect the service stage of our face masks, but
there are few researches on the service stage of face masks.
Therefore, we aim at studying what service stage the face
mask is in, which may play a positive role in protecting the
uninfected people and reducing the spread of virus.
According to Javid et al., wearing a mask in public may
become our unified action in the fight against COVID-19[11].
Due to the short service life and worldwide use of masks, it
is not practical for masks to adopt special machines to centralized detection. Hence, it is urgently needed to develop
an easy-to-operate, portable testing device for detecting anytime and anywhere. Therefore, in this research, we propose a
portable mask service stage detection system based on mobile
phone. Its work procedures are as follows: 1) users first take
a micro-photo of the mask being used with a mobile microscope; 2) then the micro-graph of the mask is uploaded in the
WeChat Applet; 3) the result of back-end detection eventually can be obtained through WeChat Applet. This detection
device is simple, easy to operate and effective.
In the common fight, the ordinary people often wear surgical masks while N95 masks are only recommended for healthcare workers or professionals at high risk of coming into contact with patients[12]. Radonovic et al. analyzed the data
which came from 7 health care delivery systems and 4 seasons
of peak viral respiratory illness, and found that in this trial,
wearing N95 respirators and wearing medical masks resulted
in no significant difference in the incidence of laboratoryconfirmed influenza[13]. Additionally, the research suggests
that N95 respirators should not be recommended for the general public, namely, those not in close contact with influenza
or suspected patients[12]. Using N95 respirators may lead to
discomfort, like headaches[14]. Even a previous study [15]
has reported that there is an inverse relationship between the
level of wearing N95 respirators and the risk of clinical respiratory illness. Therefore, we choose surgical mask as the
research object, which is the most widely used. It makes experimental data more scientific and ultimately our detection
system can benefit more people to the greatest extent. In this
study, after obtaining the micro-graphs of masks at different
wearing periods, the texture features of the photos are analyzed.
Methods of texture analysis include fractal analysis,
Fourier transformation and the gray level co-occurrence matrix (GLCM)[16]. Haralick et al. reported that the GLCM
was a method to quantify the spatial relationship between

adjacent pixels in an image[17]. GLCM is widely used in
disease detection [18, 19], skin texture analysis[20], and defect detection[21], etc. Given the above, GLCM is feasible
and efficient in image texture feature analysis. Therefore, we
choose GLCM to analyze the texture features of masks.
Due to K Nearest Neighbor (KNN) method’s simple implementation and distinguished performance in classification
tasks[22], it is widely employed in text categorization[23, 24],
medical domain[25], eating patterns exploration[26], leaf disease identification[27], indoor localization[28], etc. Hamed et
al. compared the performance of KNN variant (KNNV) algorithm (which derived from KNN) and other three algorithms
in the classification of COVID-19 patients, and found that
KNNV algorithm could classify COVID-19 patients more efficiently and accurately[25]. On the basis of the texture features extracted from the micro-photos taken in different period time, this paper employs KNN algorithm to establish the
classfiers for detecting the use time of mask.
In this paper, we propose a portable face mask service
stage detection system, which is easy to operate and can work
anytime and anywhere. It is based on the texture features of
face masks and ground-truth of mask service stage data. To
further quantify the differences of masks in different periods,
the method of texture analysis is introduced. After extracting
texture features from the micro-photos of face masks in different use periods, KNN algorithm is performed to detect which
service period the face mask belongs to. The testing data are
afterward used to validate the effectiveness of the proposed
system.
The main contributions of this paper are threefold. First,
we combine the texture features of face masks’ micro-photos
and their corresponding service stages based on the method
of texture analysis. Based on GLCM, the texture features
are successfully extracted from micro-photos obtained by
high magnification lens attached to the mobile phone. Subsequently, we propose a detection method to judge the service
stage of face masks with a KNN algorithm. Finally, based
on the two contributions mentioned above, we have implemented a detection Wechat Applet for face masks using the
data collected from three persons’ wearing face masks in
daily life, which may contribute to protecting the uninfected
people and reducing the spread of virus.
2. METHODS
A brief introduction to the proposed face mask service stage
detection method is shown below. We initially use the
portable and delicate mobile microscope device to get the
micro-photos of face masks. After obtaining the picture, the
first step is to extract texture features data from it. During
the extraction process, we use GLCM to capture the contrast, energy, correlation, and homogeneity of the object face
mask. Subsequently, KNN algorithm is employed to propose
a classification model with the input texture features and the

corresponding ground-truth use time. Eventually, we package the system into a library function in Matlab and embed
it to the Wechat Applet we develop. This has been proved
effective by similar previous researches[29, 30].
2.1. Overview of Data Acquisition

Fig. 1. The overview of the portable detection device’s “Hardware”. The “Hardware” is composed of a mobile microscope,
a phone with available system camera, etc. Specifically, a)
and b) represent the mobile microscope and system camera,
respectively; and c) shows the final removable device mainly
assembled by a) and b).

Fig. 3. The three inside photographed locations of the face
mask: left location (about one-third of the face mask and
close to the left), middle location (about two-thirds of face
mask), right (about one-third of the face mask and close to
the right).
location (about one-third of the face mask and close to the
left), middle location (about two-thirds of face mask), right
(about one-third of the face mask and close to the right), as
shown in Fig. 3. In order to contain more usage scenarios, the
face masks are worn in different conditions. Meanwhile, the
flash of the phone’s camera should be always “on” to provide
enough light. We collect the images of a face mask used from
day zero (new) to day five. Based on the conditions mentioned above, three images are immediately photographed
after the face mask has been used for an arbitrary hour of the
daytime.
2.2. Gray Level Co-Occurrence Matrix (GLCM)

Fig. 2. Scenario of the portable detection device’s working.
While the device is on work, the flash must meet the condition
that the flash is always “on” to provide enough light.
Fig. 1 displays the hardware configuration of the detection device: a mobile microphone (TIPSCOPE, Convergence(Wuhan) Technology Ltd., China), a phone with available system camera, etc. The detachable mobile microphone,
which is the key to the hardware, is particularly chosen to
display the details of face masks viz. ash particle, droplets
or other debris more explicitly. It should be noted that the
maximum magnification can reach 400x if the system camera
and mobile microscope work together. In this research, we
use system camera without magnification to get more scope
of face masks. Fig. 2 shows how to collect the experimental
data. To ensure the validity of the collected data, we photograph three inside locations of the face mask each time: left

Texture can be used to characterize the tonal or gray-level
variations in an image[31]. The gray level co-occurrence matrix (GLCM) is chosen to disclose the texture features hiding in the face masks. GLCM is a second-order statistical
method which calculates the frequency of pixel pairs with the
same gray-level in an image and uses additional knowledge
obtained from spatial pixel relations[32]. The co-occurrence
matrix uses edge information to embed the distribution of
gray-scale transformation[33]. Owing to the fact that much
of the information required is embedded in GLCM, it emerges
as a simple but effective technique.
14 measures of textural features are proposed by Haralick
et al., and some of these measures are related to specific textural characteristics of the image[17]. In our study, we choose
contrast, correlation, energy and homogeneity as measures.
Specifically, contrast refers to the drastic change in gray level
between adjacent pixels. High contrast images own high spatial frequencies. Correlation represents the linear correlation
in an image. The higher the correlation value, the more linear the gray-scale relationship between adjacent pixel pairs.

Energy stands for texture uniformity or pixel pair repetitions.
High energy is produced when the distribution of gray level
values is constant or periodic. Homogeneity is sensitive to
the existence of near diagonal elements in a GLCM, indicating the similarity of adjacent pixels in gray scale.
With the increase of the use times, the wear of the mask
causes a change in micro-structure of the mask’s some parts,
which leads to the difference between the worn-out parts and
the unworn parts. Thus, the images in different the mask’s service stage may perform variously in correlation and energy.
Meanwhile, due to humans’ respiration, cough and other respiratory related activities, more and more small particles impurities and droplets will adhere to the inside surface to the
face mask. They probably result in the difference in the four
measures mentioned above, among the images of different
service stages.
Every element in GLCM contains second-order statistics,
probability values for changes between gray levels i and j
for a particular displacement d and angle θ, labeled as p(i, j)
(normalized)[34]. Let M be the number of gray levels in the
image, thus, the size of GLCM is M × M . In this research,
we set M as 8. Subsequently, the measures are calculated as
Contrast =

−1
M
−1 M
X
X

(i − j)2 · p2 (i, j)

(1)

1
· p(i, j)
1 + (i − j)2

(2)

i=0 j=0

Homogeneity =

M
−1 M
−1
X
X
i=0 j=0

v
uM −1 M −1
uX X
Energy = t
p2 (i, j)

(3)

i=0 j=0

Correlation =

−1
M
−1 M
X
X

(i − µ) · (j − µ) · p(i, j)/σ 2 (4)

i=0 j=0

where µ is the mean of GLCM while σ 2 stands for the
variance of GLCM.
2.3. K Nearest Neighbor (KNN) Algorithm
Considering that this task is relatively simple, so the model
can be constructed with a relatively simple pattern recognition method. At the same time, in view of the deployment to
the mobile phone terminal, the established model should be
easy to deploy to the mobile phone terminal and convenient
to maintain later. Compared with other algorithms, due to its
simple implementation and significant classification performance, KNN is a very popular method in statistics and ranks
top ten data mining algorithms[35, 36, 37, 38].
KNN algorithm is different from model-based methods
which first use training samples to build a model, and then

predict the test samples through the learned model[39, 40,
41]. No training phase is required for the model-free KNN
method. Instead, it conducts classification tasks obeying the
following procedures: first, training samples are attached labels; next, the distance is calculated between the test sample and the training samples in each label; subsequently, after comparing the distances and obtaining the test’s nearest
neighbors, the serial number is obtained; finally, classification
is generated, as shown in Fig. 4. The distance is computed as:
v
uX
u n
Distance = t (test sample − training samplej )2
j=1

(5)
where the n stands for the number of labels.
The main task in our research is to train the optimal k
value after carrying out KNN classification successfully according to the efficiency of the classification performance.
2.4. Portable device based on mobile phone for detecting
use time of mask
After optimizing the system, the system is embedded to the
Wechat Applet we have developed. To enrich our experimental data, we enlarge the data collection time from the first
day to the fifth day (about an hour used time each day). It
is generally recommended to replace the surgical mask every
four hours. If the face mask is used for a long time, the large
particles will be blocked on the mask surface or the ultrafine
particles will be blocked in the pores of the mask filter material, resulting in the decrease of filtration efficiency and the
increase of respiratory resistance[42]. According to the detection time, the detection results are within three categories
viz. type I: normal use (day 0 to 1 viz. the face masks can
be used securely), type II: early warning (day 2 to 3 viz. the
face masks can be used safely, but it is close to the end of
its service life) and type III: not recommended (day 4 to 5
viz. the face mask can be used in shortage, but it is better to
change a new one). We choose the ‘day’ as unit based on the
fact that we use face masks in high-frequent but short-time
way and ordinary people hardly use face masks for 4 hours
continuously. Additionally, on basis of using the same face
mask several times, we classify the face masks belonging to
day 4 and day 5 the type ‘not recommended’ to counterbalance the increase in use times. Fig. 5 reveals the workflow
of the detection. After we have obtained the micro-photo of
the face mask with mobile microscope and registered an account in the Wechat Applet, the micro-image is uploaded to
the back-end of the system. Accordingly, the detection result
will be sent in the message from the back-end.
2.5. Evaluation Metrics
To verify the efficiency of the detection system, macromeasures viz. macro precision, macro recall, and macro

Fig. 4. The flowchart of KNN algorithm. First, labels are attached to the training samples. For every test sample, the distancei
is calculated between the test sample and the training samples in each label, which follows the equation 5. By comparing the
distances, the test sample’s nearest neighbors viz.the minimum distance are obtained, and serial number imin is then produced.
Eventually, the final classification is set as label imin .
F1 are considered.
1) Confusion matrix: we assume that “Positive” means
the positive samples and “Negative” means the negative samples. Meanwhile, “True” represents that the prediction is right
while “False” represents that the prediction is wrong. As a
result, “TP” and “TN” mean that the positive sample is classified as “Positive” and the negative sample is labeled as “Negative”, respectively. “FP” and “FN” represent that the negative
sample is labeled as “Positive” and the positive sample is classified as “False”. The four indicators make up the confusion
matrix.
2) Precision: precision is only used to evaluated the classification ability of the positive samples within the range from
0 to 1. It is obvious that the larger precision is, the more effective the system is. It is computed by:
P recision =

TP
TP + FP

(6)

3) Recall: it is a ratio from 0 to 1. Obviously, the more it
is close to 1, the better the system is. The calculation equation
is:
TP
Recall =
(7)
TP + FN
4) F1 : it is a harmonic mean of recall and precision. In
this study, we consider the weight of recall and precision the
same, which means attaching the weight of 0.5 to either of
them. It is calculated by:
F1 =

2 ∗ P recision ∗ Recall
P recision + Recall

(8)

7) Macro-measures: metrics are calculated for each label, and then the weighted means are produced (normally the
weight is the same except that the number of the samples in

each label varies greatly).
n

M acro P recision =

1X
P recisioni
n i=1

(9)

n

M acro Recall =

1X
Recalli
n i=1

(10)

n

M acro F1 =

1X
M acro F1i
n i=1

(11)

where n means the total number of labels, and the M acro F1i
is F1 of every label calculated by Equation 8.
3. EXPERIMENTAL RESULTS AND ANALYSIS
In this study, we have collected 87 micro-images (excluding
the invalid data) of surgical masks via the mobile microscope.
The life span of face masks have little relationship with different people but much with the condition of use environment.
Meanwhile, people’s doing when wearing face masks also influences the life span of face masks. As a result, the data
cover the conditions: speaking frequently, talking with others, running, shopping in supermarkets, shopping in vegetable
markets, riding and wandering, etc.
Every time three micro-photos (the left, the middle and
the right) are photographed, they are initially averaged to
eliminate existing disturbance, and then one final training
sample is produced. As a result, after extracting texture features, 29 sets of training samples are obtained. The original
87 micro-images are used to carry out validation experiments.
The evaluation indicators mentioned above are elaborated as
the follows.

Fig. 5. The workflow chart of the face mask detection system. a) stands for collecting the micro-image of the face mask being
used. b) with its branches b1), b2) and b3) means registering an account used to receive the detection result and the following
uploading task. c) is the result sent by the Wechat Applet from the back-end. (The face mask used in the sample is in its service
life of type I: normal use.)
3.1. Experimental Results
To figure out the detailed information about the classification
of the use time, we plot the confusion matrix of the three types
as demonstrated in Fig. 6. As can be seen from the results,
71 samples among 87 samples are predicted correctly, which
suggests the model performs relatively well on the whole.
Table 1. The Macro Measures of Type I, II and III.
Macro measures

Macro Precision
Macro Recall
Macro F1

82.87%±8.50%
81.98%±7.50%
81.66%±1.40%

According to the equations of macro-measures, we can
easily see that macro-measures are convincing and scientific.

The macro-precision of the system reaches 82.87%±8.50%,
which proves the efficiency of the detection system.
3.2. Influence of K Factor on the Efficiency of System
As mentioned above, we specially aim at obtaining the optimal k to get the most effective detection system. In KNN
algorithm, K plays a key role in the performance of system.
In other words, if the K factor is too small, there may exist
the following problems: 1) the phenomenon of over fitting; 2)
being easy to influenced by outliers; and 3) the system is too
complex. While the K factor is too large, there may appear
the elaborated problems: 1) the phenomenon of under fitting;
2) the system is constrained by the sample equilibrium; and
3) the system is too simple.
Hence, in this study, we analyze the correctly classified

Fig. 6. The confusion matrix of the classified results. Each
row is the number of real labels and each column is the number of classified labels. Type I, Type II and Type III represent ‘normal use’, ‘early warning’ and ‘not recommended’,
respectively.

Fig. 7. The influence of K factor on the performance of system. The Y axis on the right stands for the number of correctly
predicted samples, and the Y axis on the left shows the corresponding accuracy. Intuitively, it can be seen that the optimal
K is 6.
there exists the situation that some data don’t obey the rule.

samples’ number and accuracy under the condition that K’s
values vary from 4 to 16, as demonstrated in Fig. 7. Accordingly, we can find the optimal-k-value is 6, with the the
number TP 71 and the precision 82.87%. Additionally, K going from 4 to 6, the curve is roughly go up. For K ranging
from 6 to 16, there are two stages in the descent tendency of
the curve. First, the curve declines rapidly when K is from 6
to 9. Then it oscillates downward from 9 to 15, and the performance of system descends sharply when the K is changed
to 16. The phenomenon referred above conforms to the theoretic prediction. Surprisingly, it is exactly consistent with the
conclusion that √
the fixed optimal-k-value for all test samples
should be k = n (where n > 100 and n is the number of
training samples proposed by Lall and Sharma[43].
3.3. Comparison of measures in three types categories
we analyze the measures of all samples to inquire the tendency of modeling measures over time changes. Fig. 8
displays the micro-photos and their corresponding GLCMs’
measures of three different service stages viz. ‘normal use’
stage, ‘early warning’ stage and ‘not recommended’ stage.
As we can see from the micro-photos, when the use time increases, the mask becomes more and more dirty and there are
many impurities and small droplets in the holes of the mask.
It proves the accuracy of the analysis mentioned above that
the protection becomes less effective over time. The curves
reveal the variation tendency of the measures. Specifically,
contrast and correlation increase while energy and homogeneity decrease over time. It should be noted that this rule
can’t be applied to all data, since the detection result is determined by composite force of the four measures. As a result,

3.4. Comparison of Experimental Results using original
photos and micro-photos, respectively
To validate the necessity of microscope, we record the results
of using the original photo and micro-photo, which are shown
in Fig. 9. The two photos represent the same location of the
face mask and belong to the type ‘not recommended’. In Fig.
9, we can see many details, such as droplets in the holes, etc.
Meanwhile, we can see no details in the original photo except the obvious stain. It can be inferred that we will tell little
difference if there is no stain or other obvious dirt. The detection result of the micro-photo is ‘not recommended’ while
the original photo ’s result is ‘normal use’, which verifies the
indispensability of the microscope in this system. In other
words, the photos obtained without using microscope aren’t
able to be used as the detection input.
3.5. Dichotomous Model of Experimental Results
On the basis of system’s working normally, we further have
the idea whether we can simplify the system. As a result, we
propose a dichotomous model with only two types viz. ‘normal use’ and ‘not recommended’. Considering that ‘normal
use’ and ‘not recommended’ type face masks both can protect
people effectively, we merge them into one type named ‘normal use’. Accordingly, the other type is ‘not recommended’.
In the test samples, the number of ‘normal use’ is 60 (54 samples are detected correctly) and ‘not recommended’ is 27 (23
samples are detected correctly). To counterbalance the uneven distribution of samples, we assign the weight viz. 60
87
and 27
87 to each type. As expected, the accuracy becomes better and increases to 88.51%. Since there are two types, it

Fig. 8. The micro-photos of three types face masks and their corresponding GLCMs’ measures. a), b) and c) represent the face
masks in ‘normal use’ stage, ‘early warning’ stage and ‘not recommended’ stage, respectively. d), e), f) and g) are curve of four
measures viz. contrast, correlation, energy and homogeneity.
may also affect their use life. For example, there may be lint
inside the face mask when using face mask a few times. In
that case, we can choose to discard the mask and use a new
one to ease the discomfort. Meanwhile, if the face mask being
used gets wet by accident, we must stop using it whatever
stage it belongs to.
4. CONCLUSION

Fig. 9. The original photo and the micro-photo of the same
face mask. a) displays the micro-photo obtained by microscope while b) shows the original photo gained only by mobile phone’s camera.

is easier for the model to tell which type the detected face
mask belongs to. In some simple cases, we may consider this
scheme.
3.6. Limitation of face mask condition
Besides the system mentioned above being able to be used to
detect its service life, some conditions of the face mask itself

In this paper, we propose a service stage detection method
based on a mobile microscope which can be used to obtain
the micro-photos of the face mask being used.
In our detection method, we first get the micro-photos of
face mask being used, which may reflect some details such
as droplets or other obvious dirt. Then, we extract texture
features from the micro-photos using the method of GLCM
and choosing four measures viz. contrast, correlation, energy
and homogeneity as the features. Subsequently, KNN method
is applied to work on the detect the service stage. In validation experiments, the obtained system achieves a relatively
good result with a precision of 82.87%±8.50% on the testing dataset. The result of our experiments provide an idea
of using photos to detect the use time of face masks to distinguish whether the face mask can be used sequentially or
not. Faced with the current severe situation of COVID-19 and
possible shortage of face masks, our research may work as an
assistant to help the common people to use face masks more
correctly. Furthermore, it can exert positive influence on pro-

tecting uninfected people and stopping the possibly infected
patients from spreading virus.
In future research, based on the current portability and
practicability, we will try using a more stable algorithm to
reach the goal of achieving a higher accuracy. Besides, different types of face masks should be taken into consideration to
expand the types of detecting objects.

[13] Lewis J Radonovich, Michael S Simberkoff, Mary T Bessesen,
Alexandria C Brown, Derek AT Cummings, Charlotte A Gaydos, Jenna G Los, Amanda E Krosche, Cynthia L Gibert, Geoffrey J Gorse, et al., “N95 respirators vs medical masks for
preventing influenza among health care personnel: a randomized clinical trial,” The Journal of the American Medical Association, vol. 322, no. 9, pp. 824–833, 2019.

5. REFERENCES

[14] BJ Cowling, YDKM Zhou, DKM Ip, GM Leung, and
AE Aiello, “Face masks to prevent transmission of influenza
virus: a systematic review,” Epidemiology & infection, vol.
138, no. 4, pp. 449–456, 2010.

[1] World Health Organization et al., “Coronavirus disease (covid19) situation report-159,” 2020.
[2] Lan Lan, Dan Xu, Guangming Ye, Chen Xia, Shaokang Wang,
Yirong Li, and Haibo Xu, “Positive rt-pcr test results in patients recovered from covid-19,” The Journal of the American
Medical Association, vol. 323, no. 15, pp. 1502–1503, 2020.
[3] Heba A Hussein, Rabeay YA Hassan, Marco Chino, and Ferdinando Febbraio, “Point-of-care diagnostics of covid-19: From
current work to future perspectives,” Sensors, vol. 20, no. 15,
pp. 4289, 2020.
[4] Linda Wang and Alexander Wong, “Covid-net: A tailored
deep convolutional neural network design for detection of
covid-19 cases from chest x-ray images,” arXiv preprint
arXiv:2003.09871, 2020.
[5] Adam Bernheim, Xueyan Mei, Mingqian Huang, Yang Yang,
Zahi A Fayad, Ning Zhang, Kaiyue Diao, Bin Lin, Xiqi Zhu,
Kunwei Li, et al., “Chest ct findings in coronavirus disease-19
(covid-19): relationship to duration of infection,” Radiology,
p. 200463, 2020.
[6] Jeremy Howard, Austin Huang, Zhiyuan Li, Zeynep Tufekci,
Vladimir Zdimal, Helene-Mari van der Westhuizen, Arne von
Delft, Amy Price, Lex Fridman, Lei-Han Tang, et al., “Face
masks against covid-19: an evidence review,” 2020.
[7] World Health Organization, “Advice on the use of masks in the
context of covid-19: interim guidance, 5 june 2020,” Technical
documents, 2020.
[8] Trisha Greenhalgh, Manuel B Schmid, Thomas Czypionka,
Dirk Bassler, and Laurence Gruer, “Face masks for the public
during the covid-19 crisis,” British Medical Journal, vol. 369,
2020.

[15] Xin Chen, Abrar Ahmad Chughtai, and Chandini Raina MacIntyre, “Herd protection effect of n95 respirators in healthcare
workers,” Journal of International Medical Research, vol. 45,
no. 6, pp. 1760–1767, 2017.
[16] Ryo Kanai, Kengo Ohshima, Keiko Ishii, Masaki Sonohara,
Masahiro Ishikawa, Masahiro Yamaguchi, Yuhi Ohtani, Yukihiro Kobayashi, Hiroyoshi Ota, and Fumikazu Kimura, “Discriminant analysis and interpretation of nuclear chromatin distribution and coarseness using gray-level co-occurrence matrix
features for lobular endocervical glandular hyperplasia,” Diagnostic Cytopathology, 2020.
[17] Robert M Haralick, Karthikeyan Shanmugam, and Its’ Hak
Dinstein, “Textural features for image classification,” IEEE
Transactions on systems, man, and cybernetics, , no. 6, pp.
610–621, 1973.
[18] Peter Gibbs and Lindsay W Turnbull, “Textural analysis of
contrast-enhanced mr images of the breast,” Magnetic Resonance in Medicine: An Official Journal of the International
Society for Magnetic Resonance in Medicine, vol. 50, no. 1,
pp. 92–98, 2003.
[19] Saima Rathore, Mutawarra Hussain, Muhammad Aksam
Iftikhar, and Abdul Jalil, “Ensemble classification of colon
biopsy images based on information rich hybrid features,”
Computers in biology and medicine, vol. 47, pp. 76–92, 2014.
[20] Xiang Ou, Wei Pan, and Perry Xiao, “In vivo skin capacitive imaging analysis by using grey level co-occurrence matrix
(glcm),” International journal of pharmaceutics, vol. 460, no.
1-2, pp. 28–32, 2014.

[9] Kar Keung Cheng, Tai Hing Lam, and Chi Chiu Leung, “Wearing face masks in the community during the covid-19 pandemic: altruism and solidarity,” The Lancet, 2020.

[21] Muhammad Ahmad Shabir, Muhammad Umair Hassan, Xiangru Yu, and Jinping Li, “Tyre defect detection based on glcm
and gabor filter,” in 2019 22nd International Multitopic Conference (INMIC). IEEE, 2019, pp. 1–6.

[10] World Health Organization et al., “Rational use of personal
protective equipment for coronavirus disease (covid-19) and
considerations during severe shortages: interim guidance, 6
april 2020,” Tech. Rep., World Health Organization, 2020.

[22] Shichao Zhang, Xuelong Li, Ming Zong, Xiaofeng Zhu, and
Debo Cheng, “Learning k for knn classification,” ACM Transactions on Intelligent Systems and Technology (TIST), vol. 8,
no. 3, pp. 1–19, 2017.

[11] B Javid, MP Weekes, and NJ Matheson, “Covid-19: should the
public wear face masks?,” British Medical Journal(Clinical
Research ed.), vol. 369, pp. m1442–m1442, 2020.

[23] Shaobo Du and Jing Li, “Parallel processing of improved knn
text classification algorithm based on hadoop,” in 2019 7th
International Conference on Information, Communication and
Networks (ICICN). IEEE, 2019, pp. 167–170.

[12] Youlin Long, Tengyue Hu, Liqin Liu, Rui Chen, Qiong Guo,
Liu Yang, Yifan Cheng, Jin Huang, and Liang Du, “Effectiveness of n95 respirators versus surgical masks against influenza:
a systematic review and meta-analysis,” Journal of EvidenceBased Medicine, vol. 13, no. 2, pp. 93–101, 2020.

[24] Zhonghua Li, Liping Jia, and Bingjun Su, “Improved k-means
algorithm for finding public opinion of mount emei tourism,”
in 2019 15th International Conference on Computational Intelligence and Security (CIS). IEEE, 2019, pp. 192–196.

[25] Ahmed Hamed, Ahmed Sobhy, and Hamed Nassar, “Accurate
classification of covid-19 based on incomplete heterogeneous
data using a knn variant algorithm,” 2020.
[26] PK Newby and Katherine L Tucker, “Empirically derived eating patterns using factor or cluster analysis: a review,” Nutrition reviews, vol. 62, no. 5, pp. 177–203, 2004.
[27] N Krithika and A Grace Selvarani, “An individual grape leaf
disease identification using leaf skeletons and knn classification,” in 2017 International Conference on Innovations in Information, Embedded and Communication Systems (ICIIECS).
IEEE, 2017, pp. 1–5.
[28] Minh Tu Hoang, Yizhou Zhu, Brosnan Yuen, Tyler Reese, Xiaodai Dong, Tao Lu, Robert Westendorp, and Michael Xie, “A
soft range limited k-nearest neighbors algorithm for indoor localization enhancement,” IEEE Sensors Journal, vol. 18, no.
24, pp. 10208–10216, 2018.
[29] Zheng Jiang, Menghan Hu, Zhongpai Gao, Lei Fan, Ranran
Dai, Yaling Pan, Wei Tang, Guangtao Zhai, and Yong Lu, “Detection of respiratory infections using rgb-infrared sensors on
portable device,” IEEE Sensors Journal, 2020.
[30] Ali Imran, Iryna Posokhova, Haneya N Qureshi, Usama Masood, Sajid Riaz, Kamran Ali, Charles N John, Iftikhar Hussain, and Muhammad Nabeel, “Ai4covid-19: Ai enabled preliminary diagnosis for covid-19 from cough samples via an
app,” Informatics in Medicine Unlocked, p. 100378, 2020.
[31] Mryka Hall-Beyer, “Glcm texture: a tutorial v. 3.0 march
2017,” 2017.
[32] Qinggang Wu, Yong Gan, Bin Lin, Qiuwen Zhang, and
Huawen Chang, “An active contour model based on fused texture features for image segmentation,” Neurocomputing, vol.
151, pp. 1133–1141, 2015.
[33] Zhikai Xing and Heming Jia, “Multilevel color image segmentation based on glcm and improved salp swarm algorithm,”
IEEE Access, vol. 7, pp. 37672–37690, 2019.
[34] Tommy Löfstedt, Patrik Brynolfsson, Thomas Asklund, Tufve
Nyholm, and Anders Garpebring, “Gray-level invariant haralick texture features,” PlOS ONE, vol. 14, no. 2, pp. e0212110,
2019.
[35] Shichao Zhang, Xuelong Li, Ming Zong, Xiaofeng Zhu, and
Ruili Wang, “Efficient knn classification with different numbers of nearest neighbors,” IEEE Transactions on Neural Networks, vol. 29, no. 5, pp. 1774–1785, 2018.
[36] H. Liu, X. Li, and S. Zhang, “Learning instance correlation
functions for multilabel classification,” IEEE Transactions on
Cybernetics, vol. 47, no. 2, pp. 499–510, 2017.
[37] Xindong Wu, Vipin Kumar, J Ross Quinlan, Joydeep Ghosh,
Qiang Yang, Hiroshi Motoda, Geoffrey J Mclachlan, Angus
S K Ng, Bing Liu, Philip S Yu, et al., “Top 10 algorithms in
data mining,” Knowledge and Information Systems, vol. 14,
no. 1, pp. 1–37, 2007.
[38] Shichao Zhang, “Nearest neighbor selection for iteratively knn
imputation,” Journal of Systems and Software, vol. 85, no. 11,
pp. 2541–2552, 2012.

[39] Jifei Yu, Xinbo Gao, Dacheng Tao, Xuelong Li, and Kaibing
Zhang, “A unified learning framework for single image superresolution,” IEEE Transactions on Neural Networks, vol. 25,
no. 4, pp. 780–792, 2014.
[40] Qingsong Zhu, Ling Shao, Xuelong Li, and Lei Wang, “Targeting accurate object extraction from an image: A comprehensive study of natural image matting,” IEEE Transactions
on Neural Networks, vol. 26, no. 2, pp. 185–207, 2015.
[41] Ling Shao, Li Liu, and Xuelong Li, “Feature learning for
image classification via multiobjective genetic programming,”
IEEE Transactions on Neural Networks, vol. 25, no. 7, pp.
1359–1371, 2014.
[42] Jing Li, “How long does the surgical mask last?,” 2020, https:
//m.baidu.com/bh/m/detail/vc 7516980125353001641.
[43] Upmanu Lall and Ashish Sharma, “A nearest neighbor bootstrap for resampling hydrologic time series,” Water Resources
Research, vol. 32, no. 3, pp. 679–693, 1996.

