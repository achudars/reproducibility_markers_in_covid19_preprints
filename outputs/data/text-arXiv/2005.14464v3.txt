Analyzing COVID-19 on Online Social Media:
Trends, Sentiments and Emotions

arXiv:2005.14464v3 [cs.SI] 5 Jun 2020

Xiaoya Li♣ , Mingxin Zhou♣ , Jiawei Wu♣ , Arianna Yuan , Fei Wu♠ and Jiwei Li♣
♠ Department of Computer Science and Technology, Zhejiang University

Computer Science Department, Stanford University
♣ Shannon.AI
{xiaoya_li, mingxin_zhou, jiawei_wu, jiwei_li}@shannonai.com
xfyuan@stanford.edu, wufei@cs.zju.edu.cn

Abstract—At the time of writing, the ongoing pandemic of coronavirus disease (COVID-19) has caused severe impacts on society,
economy and people’s daily lives. People constantly express their
opinions on various aspects of the pandemic on social media, making
user-generated content an important source for understanding public
emotions and concerns.
In this paper, we perform a comprehensive analysis on the affective
trajectories of the American people and the Chinese people based on
Twitter and Weibo posts between January 20th, 2020 and May 11th
2020. Specifically, by identifying people’s sentiments, emotions (i.e.,
anger, disgust, fear, happiness, sadness, surprise) and the emotional
triggers (e.g., what a user is angry/sad about) we are able to depict the
dynamics of public affect in the time of COVID-19. By contrasting
two very different countries, China and the Unites States, we reveal
sharp differences in people’s views on COVID-19 in different cultures.
Our study provides a computational approach to unveiling public
emotions and concerns on the pandemic in real-time, which would
potentially help policy-makers better understand people’s need and
thus make optimal policy.

I. I NTRODUCTION

People constantly post about the pandemic on social media
such as Twitter, Weibo and Facebook. They express their attitudes and feelings regarding various aspects of the pandemic,
such as the medical treatments, public policy, their worry, etc.
Therefore, user-generated content on social media provides
an important source for understanding public emotions and
concerns.
In this paper, we provide a comprehensive analysis on the
affective trajectories of American people and Chinese people
based on Twitter and Weibo posts between January 20th,
2020 and May 11th 2020. We identify fine-grained emotions
(including anger, disgust, fear, happiness, sadness, surprise)
expressed on social media based on the user-generated content.
Additionally, we build NLP taggers to extract the triggers of
different emotions, e.g., why people are angry or surprised,
what they are worried, etc. We also contrast public emotions
between China and the Unites States, revealing sharp differences in public reactions towards COVID-19 related issues in
different countries.

The emergence of COVID-19 in early 2020 and its subsequent By tracking the change of public sentiment and emotion
outbreak have affected and changed the world dramatically. over time, our work sheds light on the evolution of public
According to the World Health Organization (WHO), by mid- attitude towards this global crisis. This work contributes to
May 2020, the number of confirmed COVID-19 cases has the growing body of research on social media content in the
reached 5 millions with death toll over 300,000 world wide. time of COVID-19. Our study provides a way to extracting
Several mandatory rules have been introduced by the govern- public emotion towards the pandemic in real-time, and could
ment to prevent the spread of the coronavirus, such as social potentially lead to better decision-making and the development
distancing, bans on social gatherings, store closures and school of wiser interventions to fight this global crisis.
closures. Despite their positive effects on slowing the spread
The rest of this paper is organized as follows: we briefly go
of the pandemaic, they neverthless caused severe impacts on
through some related work in Section 2. We then present the
the society, the economy and people’s everyday life. There
have been anti-lockdown and anti-social-distancing protests in analyses on topic trends in Weibo and Twitter (section 3), the
extracted emotion trajectories (section 4) and triggers of those
many places around the world. Given these difficult situations,
emotions (section 5). We finally conclude this paper in Section
it is crucial for policy-makers to understand people’s opinions
toward the pandemic so that they can (1) balance the concerns 6.
of stoping the pandemic on the one hand and keeping people
in good spirits on the other hand and (2) anticipate people’s
II. R ELATED W ORK
reactions to certain events and policy so that the policymakers can prepare in advance. More generally, a close look A. Analyses on Social Media Content about COVID-19
at the public affect during the time of COVID-19 could help
us understand people’s reaction and thoughts in the face of At the time of writing, analyses on people’s discussions and
extreme crisis, which sheds light on humanity in moments of behaviors on social media in the context of COVID-19 has
darkness.
attracted increasing attention. [1] analyzed tweets concerning

COVID-19 on Twitter by selecting important 1-grams based
on rank-turbulence divergence and compare languages used
in early 2020 with the ones used a year ago. The authors
observed the first peak of public attention to COVID-19 around
January 2020 with the first wave of infections in China, and
the second peak later when the outbreak hit many western
countries. [2] released the first COVID-19 Twitter dataset.
[3] provided a ground truth corpus by annotating 5,000 texts
(2,500 short + 2,500 long texts) in UK and showed people’s
worries about their families and economic situations. [4]
viewed emotions and sentiments on social media as indicators
of mental health issues, which result from self-quarantining
and social isolation. [5] revealed increasing amount of hateful
speech and conspiracy theories towards specific ethnic groups
such as Chinese on Twitter and 4chan’s. Other researchers
started looking at the spread of misinformation on social media
[6], [7]. [8] provide an in-depth analysis on the diffusion of
misinformation concerning COVID-19 on five different social
platforms.

B. Analyses of Emotions and Sentiments on Social Media

real-world outcomes such as economic trends [24], [28], [29],
[30], stock market [31], [32], influenza outbreak [33], and
political events [34], [35], [36], [37].
III. G ENERAL T RENDS

FOR

COVID-19 R ELATED P OSTS

In this section, we present the general trends for COVID19related posts on Twitter and Weibo. We first present the semisupervised models we used to detect COVID-19 related tweets.
Next we present the analysis on the topic trends on the two
social media platforms.

A. Retrieving COVID-19 Related Posts
For Twitter, we first obtained 1% of all tweets that are written
in English and published within the time period between
January 20th, 2020 and May 11th 2020. The next step is to
select tweets related to COVID-19. The simplest way, as in
[2], [7], is to use a handcrafted keyword list to obtain tweets
containing words found in the list. However, this method leads
to lower values in both precision and recall: for precision, usergenerated content that contains the mention of a keyword is not
necessarily related to COVID-19. For example, the keyword
list used in [2] include the word China, and it is not suprising
that a big proportion of the posts containing “China" is not
related to COVID-19; for recall, keywords for COVID-19 can
change over time and might be missing in the keyword list.

Discrete Emotion Theory [9], [10], [11] think that all humans
have an innate set of distinct basic emotions. Paul Ekman and
his colleagues [12] proposed that the six basic emotions of
humans are anger, disgust, fear, happiness, sadness, and surprise. Ekman explains that different emotions have particular
characteristics expressed in varying degrees. Researchers have
debated over the exact categories of discreate emotions. For To tackle this issue, we adopt a bootstrapping approach. The
instance, [13] proposed eight classes for emotions including bootstrapping approach is related to previous work on semilove, mirth, sorrow, anger, energy, terror, disgust and astonish- supervised data harvesting methods [38], [39], [40], in which
ment.
we build a model that recursively uses seed examples to
extract patterns, which are then used to harvest new examples.
Automatically detecting sentiments and emotions in text is a
Those new examples are further used as new seeds to get
crucial problem in NLP and there has been a large body of
new patterns. To be specific, we first obtained a starting seed
work on annotating texts based on sentiments and building
keyword list by (1) ranking words based on tf-idf scores
machine tools to automatically identify emotions and sentifrom eight COVID-19 related wikipedia articles; (2) manually
ments [14], [15], [16], [17]. [18] created the first annotated
examining the ranked word list, removing those words that are
dataset for four classes of emotions, anger, fear, joy, and
apparently not COVID-19 related, and use the top 100 words
sadness, in which each text is annotated with not only a label
in the remaining items. Then we retrieved tweets with the
of emotion category, but also the intensity of the emotion
mention of those keywords. Next, we randomly sampled 1,000
expressed based on the Best–Worst Scaling (BWS) technique
tweets from the collection and manually labeled them as either
[19]. A follow-up work by [20] created a more comprehenCOVID-19 related or not. The labeled dataset is split into the
sively annotated dataset from tweets in English, Arabic, and
training, development and test sets with ratio 8:1:1. A binary
Spanish. The dataset covers five different sub-tasks including
classification model is trained on the labeled dataset to classify
emotion classification, emotion intensity regression, emotion
whether a post with the mention of COVID-related keywords
intensity ordinal classification, valence regression and valence
is actually COVID-related. The model is trained using BERT
ordinal classification.
[41] and optimized using Adam [42]. Hyperparameters such as
There has been a number of studies on extracting aggregated the batch size, learning rate are tuned on the development set.
public mood and emotions from social media [21], [22], [23], Next, we obtain a new seed list by picking the most salient
[24]. Facebook introduced Gross National Happiness (GNH) words that contribute to the positive category in the binary
to estimate the aggregated mood of the public using the LIWC classification model based on the first-order derivative saliency
dictionary. Results show a clear weekly cycle of public mood. scores [43], [44], [45]. This marks the end of the first round
[25] and [26] specially investigate the influence of geographic of the bootstrapping. Next we used the new keyword list to
places and weather on public mood from Twitter data. The re-harvest a new dataset with the mention of the keyword,
mood indicators extracted from tweets are very predictive and 1,000 of which is selected and labeled to retrain the binary
robust [23], [27]. Therefore, they have been used to predict classification model. We repeat this process for three times.

10

4

6

3

4

2

2

1

Intensity Score (×10−2 )

8

0

# of Daily New Cases (×104 )

5
# New Cases in China
Weibo Covid-19 Related Posts

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

15

Intensity Score (×10−2 )

4

10
3

2

5
# New Cases in the US
Covid-19 Related Tweets

0

1

# of Daily New Cases (×104 )

5

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

Fig. 1: (a) Daily intensity scores for Covid-19 topics on Weibo and the number of daily cases reported by Chinese CDC. (a)
Daily intensity scores for Covid-19 topics on Twitter and the number of daily cases reported by US CDC. Intensity scores are
the number Covid related posts divided by the total number of retrieved daily posts.

F1 scores for the three rounds of binary classification are 0.74,
0.82, 0.86 respectively. After the final round of bootstrapping,
we collected a total number of 78 million English tweets
concerning the topic of COVID-19. We used this strategy to
retrieve COVID-related posts on Weibo and collected a total
number of 16 million posts.

B. Analyses
We report the intensity scores for Weibo and Twitter in Figure
1. We split all tweets by date, where Xt denotes all tweets
published on day t. The value of intensity is the number
of posts classified as COVID-related divided by the total
number of retrieved posts, i.e., |Xt |. On Weibo, we observe a
peak in late January and February, then a drop, followed by
another rise in March, and a gradual decline afterwards. The
trend on Chinese social media largely reflects the progress of
the pandemic in China: the outbreak of COVID-19 and the
spread from Wuhan to the rest of the country corresponds to

the first peak. The subsequent drop reflects the promise in
containing the virus, followed by a minor relapse in March.
For Twitter, we observe a small peak that is aligned with
the news from China about the virus. The subsequent drop
reflects the decline of the attention to the outbreak in China.
The curve progressively went up since March, corresponding
to the outbreak in the US. Upon the writing of this paper,
we have not observed a sign of drop in the intensity score of
COVID19-related posts.

IV. T HE E VOLUTION

OF

P UBLIC E MOTION

In this section, we present the analyses on the evolution of
public emotion in the time of COVID-19. We first present the
algorithms we used to identify the emotions expressed in a
given post. Next we present the results of the analyses.

A. Emotion Classification

Model
SVM biagram
BERT [41]
BERT-description [53]

Acc
51.4
65.0
66.8

micro F1
63.0
75.2
77.0

macro F1
52.7
66.1
68.3

We adopted the well-established emotion theory by Paul
Ekman [12], which groups human emotions into 6 major TABLE I: Results for the multi-label emotion classification for
categories, i.e., anger, disgust, worry, happiness, sadness, and English tweets.
surprise. Given a post from a social network user, we assign
one or multiple emotion labels to it [46], [47]. This setup is
quite common in text classification [48], [49], [50], [51], [52].
y to all the texts in that day Xt . For non COVID-related texts,
For emotion classification of English tweets, we take the P (y|x) is automatically set to 0. We thus have:
advantage of labeled datasets from the SemEval-2018 Task
1 X
1e [20], in which a tweet was associated with either the
p(y|x)
(2)
S(t, y) =
|Xt |
“neutral” label or with one or multiple emotion labels by
x∈Xt
human evaluators. The SemEval-2018 Task 1e contains eleven
emotion categories in total, i.e., anger, anticipation, disgust, For Chinese emotion classification, we used the labeled dataset
fear, joy, love, optimism, pessimism, sadness, surprise and in [54], which contains 15k labeled microblogs from weibo1 .
trust, and we only use the datasets for a six-way classification, In addition to the dataset provided by [54], we labeled
i.e., anger, disgust, fear, happiness, sadness, and surprise. COVID-related 20k microblogs. The combined dataset is then
Given that the domain of the dataset used in [20] covers used to train a multi-label classification model based on the
all kinds of tweets, and our domain of research covers only description-BERT model [53]. Everyday emotion scores for
COVID-related tweets, there is a gap between the two domains. Weibo are computed in the same way as for Twitter.
Therefore, we additionally labeled 15k COVID-related tweets
following the guidelines in [20], where each tweet can take The time series of intensity scores of six different emotions,
either the neural label or one/multiple emotion labels. Since i.e., sadness, anger, disgust, worry, happiness, surprise, for
one tweet can take on multiple emotion labels, the task is Weibo and Twitter are shown in Figures 2 and 3, respectively.
formalized as a a multi-label classification task, in which six For Weibo, as can be seen, the trend of worry is largely in
binary (one vs. the rest) classifiers are trained. We used the line with the trend of the general intensity of the COVIDdescription-based BERT model [53] as the backbone, which related posts. It reached a peak in late January, and then
achieves current SOTA performances on a wide variety of gradually went down, followed by a small relapse in midtext classification tasks. More formally, let us consider a March. For anger, the intensity first went up steeply at the
to-be-classified tweet x = {x1 , · · · , xL }, where L denotes initial stage of the outbreak, staying high for two weeks, and
the length of the text x. Each x will be tagged with one then had another sharp increase around February 8th. The
or more class labels y ∈ Y = [1, N ], where N = 6 peak on February 8th was due to the death of Wenliang Li,
denotes the number of the predefined emotion classes (the a Chinese ophthalmologist who issued the warnings about
six emotion categories). To compute the probability p(y|x), the virus. The intensity for anger then gradually decreased,
each input text x is concatenated with the description qy to with no relapse afterwards. The intensity for disgust remained
generate {[CLS]; qy ; [SEP]; x}, where [CLS] and [SEP] are relatively low across time. For sadness, the intensity reached
special tokens. The description qy is the Wikipedia description the peak at the early stage of the outbreak, then gradually
for each of the emotions. For example, qy for the category died out with no relapse. For surprise, it went up first, mostly
anger is “Anger, also known as wrath or rage, is an intense because of the fact that the public was surprised by the new
emotional state involving a strong uncomfortable and hostile virus and the unexpected outbreak, but then gradually went
response to a perceived provocation, hurt or threat." Next, the down. The intensity for happiness remained relatively low
concatenated sequence is fed to the BERT model, from which across time, with a small peak in late April, mostly because
we obtain the contextual representations h[CLS] . h[CLS] is then the countrywide lockdown was over.
transformed to a real value between 0 and 1 using the sigmoid
For Twitter, the intensity for worry went up shortly in late
function, representing the probability of assigning the emotion
January, followed by a drop. The intensity then went up steeply
label y to the input tweet x:
in mid-March in response to the pandemic breakout in the
p(y|x) = sigmoid(W2 ReLU(W1 h[CLS] + b1 ) + b2 )
(1) States, reaching a peak around March 20th, then decreased
a little bit and remained steady afterwards. The intensity for
where W1 , W2 , b1 , b2 are some parameters to optimize. Clas- anger kept going up after the outbreak in mid-March, with
sification performances for different models are presented in no drop observed. The trend for sadness is mostly similar to
Table 3.
that of the overall intensity. For surprise, the curve went up
first after the breakout in early March, reaching a peak around
Mar 20th, then dropped, and remained steady afterwards. For
happiness, the intensity remained low over time.
B. Analyses
For emotion y, its intensity score S(t, y) for day t is the
average probability (denoted by P (y|x)) of assigning label

1 The original dataset contains 7 categories of emotions, and we used only
six of them.

sadness
passed away

anger
realdonaldtrump

disgust
covid / covid-19

worry
covid / covid-19

happiness
healthy

died

lockdown

realdonaldtrump

job

help

deaths
fever
unemployed
parents
test positive
family
patients
isolation

government
quarantine
wuhan
lies
close
stayhome
WHO
trump

chinese
trump
masks
virus
pence
chinks
china
hospitals

kids
bill
unemployed
food
crisis
parents
economy
families

recover
check
return to work
reopening
vaccine
money
treatment
friends

surprise
covid / covid-19
human-to-human
transmission
outbreak
lockdown
test
deaths
pandemic
confirmed cases
total numbers
conspiracy

TABLE II: Top 10 extracted trigger spans regarding different emotions on Twitter.
China
China
Chinese
Wuhan
bat-eating
chink
chinesevirus
sinophobia
chingchong
hubei

lockdown
quarantine
stay
close
home
stayhome
boarder
shutdown
distancing
coronalockdown

Trump
realdonaldtrump
donald
lies
republicans
hydroxychloroquin
american
media
governor
pence

Hospitals
hospital
patients
test
doctor
case
healthcare
drug
vaccine
ventilator

Increasing Cases and Deaths
case
deaths
report
confirmed
report
york
us
total
government

TABLE III: Top mentions of different subcategories for anger on Twitter.
syndrome and being infected
fever
hospital
cough
test positive
icu
doctor
bed
confimed
sick

families
parents
mother
children
mom
families
father
kids
daughter
father-in-law

finance and economy
money
stock
financial
price
loan
business
debt
market
crash

jobs and food
jobs
unemployed
food
money
work
starve
unemployment
check
layoff

Increasing Cases and Deaths
deaths
spread
poll number
death toll
confirmed
rise
official
number
safe

TABLE IV: Top mentions of different subcategories for worry anger on Twitter.

sadness
anger
disgust
worry
happiness
surprise
Overall Intensity

Intensity Score (×10−3 )

10
8
6

8

6

4

4
2

2

0

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

Fig. 2: Daily intensity scores for different emotions on Weibo.

V. E MOTIONAL T RIGGERS
For a given emotion, we would like to dive deeper into its
different subcategories. For example, for worry, we wish to

know what the public is worried about, and how these triggers
of worry change over time. In this section, we first present
our methods for extracting triggers/subcategories for different
emotions, followed by some analyses and visualization on the

Overall Intensity Score (×10−2 )

10

12

sadness
anger
disgust
worry
happiness
surprise
Overall Intensity

Intensity Score (×10−3 )

10
8
6

10

5

4
2
0

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

Fig. 3: Daily intensity scores for different emotions on Twitter.

Twitter data.

A. Extracting the Triggers for Different Emotions
In order to extract the emotional triggers from Twitter’s noisy
text, we first annotate a corpus of tweets. For the ease of
annotation, each emotion is associated with only a single
trigger: the person/entity/event that a user has a specific
emotion towards/with/about. A few examples are shown as
follows with target triggers surrounded by brackets.
•

•

•

•

•
•

•

it has been shown to outperform vanilla BERT even when
less training data is used. In addition to the representation
features from BERT-MRC, we also considered the Twittertuned POS features [56], the dependency features from a
Twitter-tuned dependency parsing model [57] and the Twitter
event features [58]. The precision and recall for segmenting
emotional triggers on English tweets are reported in Table V.
The precision and recall for segmenting triggering event
phrases are reported in Table 3. We observe a significant
performance boost with linguistic features such as POS and
dependency features. This is mainly due to the small size of
the labeled dataset. The best model achieves an F1 score of
0.66.

Angry protesters are traveling 100’s of miles to join
organized rallies over COVID-19 [lockdown]attr_anger .
Feeling awfully tired after a 5.30am start for work today.
Worried too about [the early return to school]attr_worry ,
B. Clustering Trigger Mentions
my grandchildren are so very dear to me . I could not
bear to lose them to covid.
Since different extracted tokens may refer to the same concept
All
Americans
are
very
angry
with or topic, we would like to cluster the extracted trigger men[@realDonaldTrump]attr_anger 81,647 dead Americans tions. The method of supervised classification is unsuitable
would be very angry as well. If they weren’t dead.
for this purpose since (1) it is hard to predefine a list of
Fucking [bat-eating chinks]attr_anger , go die in a hole, potential triggers to people’s anger or worry; (2) it is extremely
far away from us.
labor-intensive to annotate tweets with worry types or anger
Well, I am ANGRY as hell at Trumpattr_anger .
types and (3) these types may change over time. For these
With great sadness we report the sad [loss of two dear reasons, we decided to use semi-supervised approaches that
Friends]attr_sadness
will automatically induce worry/anger types that match the
The lockdownattr_anger was implemented when there data. We adopt an approach based on LDA [59]. It was inspired
were hardly any cases and now it is above lakhs and by work on unsupervised information extraction [60], [58],
people are acting so carelessly. Making me so angry.
[61].

In order to build an emotional trigger tagger, we annotated We use the emotion anger to illustrate how trigger mentions
2,000 tweets in total, and split them into training, development are clustered. Each extracted trigger mentions for anger is
and test sets with ratio 8:1:1. We treat the problem as a modeled as a mixture of anger types. Here we use subcategory,
sequence labeling task, using Conditional Random Fields type, and topic interchangeablely, all referring to the cluster of
for learning and inference with BERT-MRC features [55]. similar mentions. Each topic is characterized by a distribution
Comparing with vanilla BERT tagger [41], the BERT-MRC over triggers, in addition to a distribution over dates on
tagger has the strength of encoding the description of the to- which a user talks about the topic. Taking dates into account
be-extracted entities, e.g., what they are worried about. As this encourages triggers that are mentioned on the same date to
description provides the prior knowledge about the entities, be assigned to the same topic. We used collapsed Gibbs

Overall Intensity Score (×10−2 )

12

Model
BERT
BERT-MRC
CRF with BERT-MRC features
CRF with BERT-MRC features, POS, event and parse tree features

Pre
0.41
0.54
0.53
0.58

Rec
0.60
0.66
0.68
0.78

F1
0.48
0.59
0.60
0.66

TABLE V: Performances of different models on emotional trigger extraction from Tweets.

Intensity Score (×10−3 )

2.5

2

1.5

china
lockdown
trump
hospitals
increasing deaths and cases

1

0.5

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

Fig. 4: Daily intensity scores for different subcategories for anger on Twitter.

Intensity Score (×10−3 )

2.5

2

1.5

syndrome and being infected
families
finance and economy
jobs and food
increasing deaths and cases

1

0.5

0
Feb.3

Feb.17

Mar.2

Mar.16
Date

Mar.30

Apr.13

Apr.27

May.11

Fig. 5: Daily intensity scores for different subcategories for worry on Twitter.

Sampling [62] for inference. For each emotion, we ran Gibbs
Sampling with 20 topics for 1,000 iterations, obtaining the
hidden variable assignments in the last iteration. Then we
manually inspected the top mentions for different topics and
abandoned the incoherent ones.
The daily intensity score for a given subcategory k belonging
to emotion y is given as follows:
S(t, y, k) =

1 X
p(k|x)I(yx = y)
|Xt |

(3)

x∈Xt

where p(k|x) is computed based on the parameters of the latent
variable model.

C. Analyses
We report the top triggers for different emotions in Table II.
We adopt a simple strategy of reporting the most frequent
triggers for different emotions. For sadness, the most frequent
triggering events and topics are being test positive, and the
death of families and friends. For anger, the top triggers are
shutdown, quarantine and other mandatory rules. People also
express their anger towards public figures such as President
Donald Trump, Mike Pence, along with China and Chinese.
For worry, the top triggers include jobs, getting the virus,
payments and families. For happiness, the top triggers are
recovering from the disease, city reopening and returning to

work. For surprise, the public are mostly surprised by the virus
itself, its spread and the mass deaths it caused.
Next we report the results of the mention clustering for anger
and worry in Tables 4 and 5, respectively. The unsupervised
clustering reveals clearer patterns in the triggering events: top
subcategories for anger include China with racist words such
as chink and chingchong; lockdown and social distancing;
public figures like President Donal Trump and Mike Pence;
treatments in hospitals, and the increasing cases and deaths;
Table 4 displays the change of intensity scores for the subcategories of anger. We observe a sharp increase in public anger
toward China and Chinese around March 20th, in coincidence
with President Donald Trump calling coronavirus ’Chinese
virus’ in his tweets. Public anger towards the lockdown sharply
escalated in mid-March, but decreased a bit after late April
when some places started to reopen.

[7] E. Ferrara, “# covid-19 on twitter: Bots, conspiracies, and social media
activism,” arXiv preprint arXiv:2004.09531, 2020.
[8] M. Cinelli, W. Quattrociocchi, A. Galeazzi, C. M. Valensise, E. Brugnoli,
A. L. Schmidt, P. Zola, F. Zollo, and A. Scala, “The covid-19 social
media infodemic,” arXiv preprint arXiv:2003.05004, 2020.
[9] R. Plutchik, “A general psychoevolutionary theory of emotion,” in
Theories of emotion. Elsevier, 1980, pp. 3–33.
[10] N. H. Frijda, “The laws of emotion.” American psychologist, vol. 43,
no. 5, p. 349, 1988.
[11] W. G. Parrott, Emotions in social psychology: Essential readings. Psychology Press, 2001.
[12] P. Ekman, “An argument for basic emotions,” Cognition & emotion,
vol. 6, no. 3-4, pp. 169–200, 1992.
[13] Rag, Number Of Rasa-S. Adyar Library Research Centre, 1975, vol. 23.
[14] C. Yang, K. H.-Y. Lin, and H.-H. Chen, “Emotion classification using
web blog corpora,” in IEEE/WIC/ACM International Conference on Web
Intelligence (WI’07). IEEE, 2007, pp. 275–278.
[15] B. Pang and L. Lee, “Opinion mining and sentiment analysis,” Foundations and trends in information retrieval, vol. 2, no. 1-2, pp. 1–135,
2008.

Top subcategories for worry include syndromes for COVID-19,
finance and economy, families, jobs and food, and increasing
cases and deaths. Table 5 displays the change of intensity
scores for subcategories of worry. People increasingly worried
about families over time. It is interesting to see that the worry
about finance and economy started going up in mid-February,
earlier than other subcategories.

[16] S. M. Mohammad, “Sentiment analysis: Detecting valence, emotions,
and other affectual states from text,” in Emotion measurement. Elsevier,
2016, pp. 201–237.

VI. C ONCLUSION

[18] S. M. Mohammad and F. Bravo-Marquez, “Wassa-2017 shared task on
emotion intensity,” arXiv preprint arXiv:1708.03700, 2017.

In this paper, we perform analyses on topic trends, sentiments
and emotions of the public in the time of COVID-19 on social
media. By tracking the change of public emotions over time,
our work reveals how the general public reacts to different
events and government policy. Our study provides a computational approach to understanding public affect towards the
pandemic in real-time, and could help create better solutions
and interventions for fighting this global crisis.

[19] J. J. Louviere and G. G. Woodworth, “Best-worst scaling: A model for
the largest difference judgments,” University of Alberta: Working Paper,
1991.

[21] G. Mishne, M. De Rijke et al., “Capturing global mood levels using
blog posts.” in AAAI spring symposium: computational approaches to
analyzing weblogs, vol. 6, 2006, pp. 145–152.

R EFERENCES

[22] Y. Liu, X. Huang, A. An, and X. Yu, “Arsa: a sentiment-aware model
for predicting sales performance using blogs,” in Proceedings of the
30th annual international ACM SIGIR conference on Research and
development in information retrieval, 2007, pp. 607–614.

[1] T. Alshaabi, J. Minot, M. Arnold, J. L. Adams, D. R. Dewhurst, A. J.
Reagan, R. Muhamad, C. M. Danforth, and P. S. Dodds, “How the
world’s collective attention is being paid to a pandemic: Covid-19
related 1-gram time series for 24 languages on twitter,” arXiv preprint
arXiv:2003.12614, 2020.
[2] E. Chen, K. Lerman, and E. Ferrara, “Covid-19: The first public
coronavirus twitter dataset,” arXiv preprint arXiv:2003.07372, 2020.
[3] B. Kleinberg, I. van der Vegt, and M. Mozes, “Measuring emotions in
the covid-19 real world worry dataset,” arXiv preprint arXiv:2004.04225,
2020.

[17] D. Tang, B. Qin, and T. Liu, “Document modeling with gated recurrent
neural network for sentiment classification,” in Proceedings of the 2015
conference on empirical methods in natural language processing, 2015,
pp. 1422–1432.

[20] S. Mohammad, F. Bravo-Marquez, M. Salameh, and S. Kiritchenko,
“Semeval-2018 task 1: Affect in tweets,” in Proceedings of the 12th
international workshop on semantic evaluation, 2018, pp. 1–17.

[23] P. S. Dodds and C. M. Danforth, “Measuring the happiness of large-scale
written expression: Songs, blogs, and presidents,” Journal of happiness
studies, vol. 11, no. 4, pp. 441–456, 2010.
[24] E. Gilbert and K. Karahalios, “Widespread worry and the stock market,”
in Fourth International AAAI Conference on Weblogs and Social Media,
2010.
[25] L. Mitchell, M. R. Frank, K. D. Harris, P. S. Dodds, and C. M.
Danforth, “The geography of happiness: Connecting twitter sentiment
and expression, demographics, and objective characteristics of place,”
PloS one, vol. 8, no. 5, 2013.

[4] J. Gao, P. Zheng, Y. Jia, H. Chen, Y. Mao, S. Chen, Y. Wang, H. Fu,
and J. Dai, “Mental health problems and social media exposure during
covid-19 outbreak,” Plos one, vol. 15, no. 4, p. e0231924, 2020.

[26] J. Li, X. Wang, and E. Hovy, “What a nasty day: Exploring moodweather relationship from twitter,” in proceedings of the 23rd ACM
International Conference on Conference on Information and Knowledge
Management, 2014, pp. 1309–1318.

[5] L. Schild, C. Ling, J. Blackburn, G. Stringhini, Y. Zhang, and S. Zannettou, “" go eat a bat, chang!": An early look on the emergence of
sinophobic behavior on web communities in the face of covid-19,” arXiv
preprint arXiv:2004.04046, 2020.

[27] P. S. Dodds, K. D. Harris, I. M. Kloumann, C. A. Bliss, and C. M.
Danforth, “Temporal patterns of happiness and information in a global
social network: Hedonometrics and twitter,” PloS one, vol. 6, no. 12,
2011.

[6] R. Gallotti, F. Valle, N. Castaldo, P. Sacco, and M. De Domenico,
“Assessing the risks of" infodemics" in response to covid-19 epidemics,”
arXiv preprint arXiv:2004.03997, 2020.

[28] T. Rao and S. Srivastava, “Tweetsmart: Hedging in markets through twitter,” in 2012 Third International Conference on Emerging Applications
of Information Technology. IEEE, 2012, pp. 193–196.

[29] ——, “Using twitter sentiments and search volumes index to predict oil,
gold, forex and markets indices,” Tech. Rep., 2012.
[30] X. Zhang, H. Fuehres, and P. A. Gloor, “Predicting stock market
indicators through twitter “i hope it is not as bad as i fear”,” ProcediaSocial and Behavioral Sciences, vol. 26, pp. 55–62, 2011.

[50] X. Zhang, J. Zhao, and Y. LeCun, “Character-level convolutional
networks for text classification,” in Advances in neural information
processing systems, 2015, pp. 649–657.
[51] C. Zhou, C. Sun, Z. Liu, and F. Lau, “A c-lstm neural network for text
classification,” arXiv preprint arXiv:1511.08630, 2015.

[31] J. Bollen, H. Mao, and X. Zeng, “Twitter mood predicts the stock
market,” Journal of computational science, vol. 2, no. 1, pp. 1–8, 2011.

[52] A. Joulin, E. Grave, P. Bojanowski, and T. Mikolov, “Bag of tricks for
efficient text classification,” arXiv preprint arXiv:1607.01759, 2016.

[32] S. Chung and S. Liu, “Predicting stock market fluctuations from twitter,”
Berkeley, California, 2011.

[53] D. Chai, W. Wu, Q. Han, F. Wu, and J. Li, “Description based text classification with reinforcement learning,” arXiv preprint arXiv:2002.03067,
2020.

[33] J. Li and C. Cardie, “Early stage influenza detection from twitter,” arXiv
preprint arXiv:1309.7340, 2013.
[34] D. J. Hopkins and G. King, “A method of automated nonparametric
content analysis for social science,” American Journal of Political
Science, vol. 54, no. 1, pp. 229–247, 2010.
[35] B. O’Connor, R. Balasubramanyan, B. R. Routledge, and N. A. Smith,
“From tweets to polls: Linking text sentiment to public opinion time
series,” in Fourth international AAAI conference on weblogs and social
media, 2010.
[36] A. Tumasjan, T. O. Sprenger, P. G. Sandner, and I. M. Welpe, “Predicting elections with twitter: What 140 characters reveal about political
sentiment,” in Fourth international AAAI conference on weblogs and
social media, 2010.
[37] A. O. Larsson and H. Moe, “Studying political microblogging: Twitter
users in the 2010 swedish election campaign,” New media & society,
vol. 14, no. 5, pp. 729–747, 2012.
[38] J. Li, A. Ritter, and E. Hovy, “Weakly supervised user profile extraction
from twitter,” in Proceedings of the 52nd Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers),
2014, pp. 165–174.
[39] D. Davidov, A. Rappoport, and M. Koppel, “Fully unsupervised discovery of concept-specific relationships by web mining,” in Proceedings of
the 45th Annual Meeting of the Association of Computational Linguistics,
2007, pp. 232–239.
[40] Z. Kozareva and E. Hovy, “Learning arguments and supertypes of
semantic relations using recursive patterns,” in Proceedings of the
48th annual meeting of the association for computational linguistics.
Association for Computational Linguistics, 2010, pp. 1482–1491.
[41] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805, 2018.
[42] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.
[43] D. Erhan, Y. Bengio, A. Courville, and P. Vincent, “Visualizing higherlayer features of a deep network,” University of Montreal, vol. 1341,
no. 3, p. 1, 2009.
[44] K. Simonyan, A. Vedaldi, and A. Zisserman, “Deep inside convolutional
networks: Visualising image classification models and saliency maps,”
arXiv preprint arXiv:1312.6034, 2013.
[45] J. Li, X. Chen, E. Hovy, and D. Jurafsky, “Visualizing and understanding
neural models in nlp,” arXiv preprint arXiv:1506.01066, 2015.
[46] S. Buechel and U. Hahn, “Emotion analysis as a regression problem—dimensional models and their implications on emotion representation and metrical evaluation,” in Proceedings of the Twenty-second
European Conference on Artificial Intelligence. IOS Press, 2016, pp.
1114–1122.
[47] D. Demszky, D. Movshovitz-Attias, J. Ko, A. Cowen, G. Nemade,
and S. Ravi, “Goemotions: A dataset of fine-grained emotions,” arXiv
preprint arXiv:2005.00547, 2020.
[48] M. Ikonomakis, S. Kotsiantis, and V. Tampakas, “Text classification
using machine learning techniques.” WSEAS transactions on computers,
vol. 4, no. 8, pp. 966–974, 2005.
[49] C. C. Aggarwal and C. Zhai, “A survey of text classification algorithms,”
in Mining text data. Springer, 2012, pp. 163–222.

[54] Y. Lai, L. Zhang, D. Han, R. Zhou, and G. Wang, “Fine-grained
emotion classification of chinese microblogs based on graph convolution
networks,” 2019.
[55] X. Li, J. Feng, Y. Meng, Q. Han, F. Wu, and J. Li, “A unified mrc framework for named entity recognition,” arXiv preprint arXiv:1910.11476,
2019.
[56] A. Ritter, S. Clark, O. Etzioni et al., “Named entity recognition in tweets:
an experimental study,” in Proceedings of the conference on empirical
methods in natural language processing. Association for Computational
Linguistics, 2011, pp. 1524–1534.
[57] L. Kong, N. Schneider, S. Swayamdipta, A. Bhatia, C. Dyer, and N. A.
Smith, “A dependency parser for tweets,” in Proceedings of the 2014
Conference on Empirical Methods in Natural Language Processing
(EMNLP), 2014, pp. 1001–1012.
[58] A. Ritter, O. Etzioni, and S. Clark, “Open domain event extraction
from twitter,” in Proceedings of the 18th ACM SIGKDD international
conference on Knowledge discovery and data mining, 2012, pp. 1104–
1112.
[59] D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent dirichlet allocation,”
Journal of machine Learning research, vol. 3, no. Jan, pp. 993–1022,
2003.
[60] N. Chambers and D. Jurafsky, “Template-based information extraction
without the templates,” in Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Human Language
Technologies-Volume 1.
Association for Computational Linguistics,
2011, pp. 976–986.
[61] J. Li, A. Ritter, C. Cardie, and E. Hovy, “Major life event extraction
from twitter based on congratulations/condolences speech acts,” in
Proceedings of the 2014 conference on empirical methods in natural
language processing (EMNLP), 2014, pp. 1997–2007.
[62] T. L. Griffiths and M. Steyvers, “Finding scientific topics,” Proceedings
of the National academy of Sciences, vol. 101, no. suppl 1, pp. 5228–
5235, 2004.

