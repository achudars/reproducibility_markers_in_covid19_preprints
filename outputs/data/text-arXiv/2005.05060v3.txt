1

Predictive Analysis of COVID-19 Time-series Data
from Johns Hopkins University

arXiv:2005.05060v3 [cs.LG] 22 May 2020

Alireza M. Javid, Xinyue Liang, Arun Venkitaraman, and Saikat Chatterjee
School of Electrical Engineering and Computer Science
KTH Royal Institute of Technology, Sweden
{almj, xinyuel, arunv, sach}@kth.se

Abstract—We provide a predictive analysis of the spread
of COVID-19, also known as SARS-CoV-2, using the dataset
made publicly available online by the Johns Hopkins University.
Our main objective is to provide predictions of the number of
infected people for different countries in the next 14 days. The
predictive analysis is done using time-series data transformed
on a logarithmic scale. We use two well-known methods for
prediction: polynomial regression and neural network. As the
number of training data for each country is limited, we use a
single-layer neural network called the extreme learning machine
(ELM) to avoid over-fitting. Due to the non-stationary nature of
the time-series, a sliding window approach is used to provide a
more accurate prediction.

TABLE I: Countries considered from JHU dataset.
Countries considered in the analysis
Sweden
Denmark
Finland
Norway
France
Italy
Spain
UK
China
India
Iran
USA

Index Terms—COVID-19, neural network, polynomial regression, extreme learning machine.

II. DATASET
I. G OAL
The COVID-19 pandemic has led to a massive global
crisis, caused by the rapid spread rate and severe fatality,
especially, among those with a weak immune system. In
this work, we use the available COVID-19 time-series of the
infected cases to build models for predicting the number of
cases in the near future. In particular, given the time-series
till a particular day, we make predictions for the number
of cases in the next τ days, where τ ∈ {1, 3, 7, 14}. This
means that we predict for the next day, after 3 days, after
7 days, and after 14 days. Our analysis is based on the
time-series data made publicly available on the COVID19 Dashboard by the Center for Systems Science and Engineering (CSSE) at the Johns Hopkins University (JHU)
(https://systems.jhu.edu/research/public-health/ncov/) [1].
Let yn denote the number of confirmed cases on the n-th
day of the time-series after start of the outbreak. Then, we
have the following
• The input consists of the last n samples of the time-series
given by yn , [y1 , y2 , · · · , yn ].
• The predicted output is tn = ŷn+τ , τ ∈ {1, 3, 7, 14}.
• Due to non-stationary nature of the time-series data, a
sliding window of size w is used over yn to make the
prediction, and w is found via cross-validation.
• The predictive function f ( · ) is modeled either by a
polynomial or a neural network, and is used to make the
prediction:
ŷn+τ = f (yn )

The dataset from JHU contains the cumulative number
of cases reported daily for different countries. We base our
analysis on 12 of the countries listed in Table I. For each
country, we consider the time-series yn starting from the day
when the first case was reported. Given the current day index
n, we predict the number of cases for the day n + τ by
considering as input the number of cases reported for the past
w days, that is, for the days n − w + 1 to n.
III. A PPROACHES
We use data-driven prediction approaches without considering any other aspect, for example, models of infectious disease
spread [2]. We apply two approaches to analyze the data to
make predictions, or in other words, to learn the function f :
• Polynomial model approach: Simplest curve fit or approximation model, where the number of cases is approximated locally with polynomials − f is a polynomial.
• Neural network approach: A supervised learning approach that uses training data in the form of input-output
pairs to learn a predictive model − f is a neural network.
We describe each approach in detail in the following subsections.
A. Polynomial model
1) Model: We model the expected value of yn as a third
degree polynomial function of the day number n:
f (n) = p0 + p1 n1 + p2 n2 + p3 n3

2

The set of coefficients {p0 , p1 , p2 , p3 } are learned using the
available training data. Given the highly non-stationary nature
of the time-series, we consider local polynomial approximations of the signal over a window of w days, instead of using
all the data to estimate a single polynomial f ( · ) for the entire
time-series. Thus, at the n-th day, we learn the corresponding
polynomial f ( · ) using yn,w , [yn−w+1 , · · · , yn−1 , yn ].
2) How the model is used: Once the polynomial is determined, we use it to predict for (n + τ )-th day as

IV. E XPERIMENTS
A. With the available data till May 4, 2020
In this subsection, we make predictions based on the timeseries data which currently is available until today May 4,
2020, for τ ∈ {1, 3, 7}. We estimate the number of cases for
the last 31 days of the countries in Table I. For each value
of τ ∈ {1, 3, 7}, we compare the estimated number of cases
ŷn+τ with the true value yn+τ and report the estimation error
in percentage, i.e.,

ŷn+τ = f (n + τ )
For every polynomial regression model, we construct the
corresponding polynomial function f ( · ) by using yn,w as the
most recent input data of size w. The appropriate window size
w is found through cross-validation.
B. Neural networks
1) Model: We use Extreme Learning Machine (ELM) as
the neural network model to avoid overfitting to the training
data. As the length of the time-series data for each country is
limited, the number of training samples for the neural network
would be quite small, which can lead to severe overfitting
in large scale neural network such as deep neural networks
(DNNs), convolutional neural networks (CNNs), etc. [3], [4].
ELM, on the other hand, is a single layer neural network which
uses random weights in its first hidden layer [5]. The use of
random weights has gained popularity due to its simplicity
and effectiveness in training [6]–[8]. We now briefly describe
ELM.
Consider a dataset containing N samples of pair-wise P dimensional input data x ∈ RP and the corresponding Qdimensional target vector t ∈ RQ as D = {(xn , tn )}N
n=1 . We
construct the feature vector as zn = g(Wxn ) ∈ Rh , where
h×P
• weight matrix W ∈ R
is an instance of Normal
distribution,
• h is the number of hidden neurons, and
• activation function g( · ) is the rectified linear unit
(ReLU).
To predict the target, we use a linear projection of feature
vector zn onto the target. Let the predicted target for the nth sample be Ozn . Note that O ∈ RQ×h . By using ℓ2 -norm
regularization, we find the optimal solution for the following
convex optimization problem
O⋆ = arg min
O

N
X

ktn − Ozn k22 + λkOk2F ,

(1)

n=1

where k · kF denotes the Frobenius norm. Once the matrix O⋆
is learned, the prediction for any new input x is now given by
t̂ = O⋆ g(Wx)
2) How the model is used: When using ELM to predict
the number of cases, we define xn = [yn−w+1 , ..., yn−1 , yn ]⊤
and tn = [yn+τ ]. Note that xn ∈ Rw and tn ∈ R. For a
fixed τ ∈ {1, 3, 7, 14}, we use cross-validation to find the
proper window size w, number of hidden neurons h, and the
regularization hyperparameter λ.

Error =

|yn+τ − ŷn+τ |
× 100.
yn+τ

(2)

We carry out two sets of experiments for each of the two
approaches (polynomial and ELM) to examine their sensitivity to the new arriving training samples. In the first set
of experiments, we implement cross-validation to find the
hyperparameters without using the observed samples of the
time-series as we proceed through 31 days span. In the second
set of experiments, we implement cross-validation in a daily
manner as we observe new samples of the time-series. In the
latter setup, the window size w varied with respect to time
to find the optimal hyperparameters as we proceed through
time. We refer to this setup as ’ELM time-varying’ and ’Poly
time-varying’ in the rest of the manuscript.
We first show the reported and estimated number of infection cases for Sweden by using ELM time-varying for different
τ ’s in Figure 1. For each τ , we estimate the number of cases
up to τ days after which JHU data is collected. In our later
experiments, we show that ELM time-varying is typically more
accurate than the other three methods (polynomial, Poly timevarying, and ELM). This better accuracy conforms to the nonstationary behavior of the time-series data, or in other words
that the best model parameters change over time. Hence, the
result of ELM time-varying is shown explicitly for Sweden.
According to our experimental result, we predict that a total of
23039, 23873, and 26184 people will be infected in Sweden
on May 5, May 7, and May 11, 2020, respectively.
Histograms of error percentage of the four methods are
shown in Figure 2 for different values of τ . The histograms
are calculated by using a nonparametric kernel-smoothing
distribution over the past 31 days for all 12 countries. The
daily error percentage for each country in Table I is shown in
Figures 7-15. Note that the reported error percentage of ELM
is averaged over 100 Monte Carlo trials. The average and the
standard deviation of the error over 31 days is reported (in
percentage) in the legend of each of the figures for all four
methods. It can be seen that daily cross-validation is crucial to
preserve a consistent performance through-out the pandemic,
resulting in a more accurate estimate. In other words, the
variations of the time-series as n increases is significant
enough to change the statistics of the training and validation
set, which, in turn, leads to different optimal hyperparameters
as the length of the time-series grows. It can also be seen
that ELM time-varying provides a more accurate estimate,
especially for large values of τ . Therefore, for the rest of
the experiments, we only focus on ELM time-varying as our
favored approach.

3

Another interesting observation is that the performance of
ELM time-varying improves as n increases. This observation
verifies the general principle that neural networks typically
perform better as more data becomes available. We report the
average error percentage of ELM time-varying over the last 10
days of the time-series in Table II. We see that as τ increases
the estimation error increases. When τ = 7, ELM time-varying
works well for most of the countries. It does not perform well
for France and India. This poor estimation for a few countries
could be due to a significant amount of noise in the timeseries data, even possibly caused by inaccurately reported daily
cases.
B. With the available data till May 12, 2020
In this subsection, we repeat the prediction based on the
time-series data which is available until today May 12, 2020,
for τ ∈ {1, 3, 7}. In Subsection IV-A, we predicted the total
number of cases in Sweden on May 5, May 7, and May 11,
2020. The reported number of cases on these days for Sweden
turned out to be 23216, 24623, and 26670, respectively, which
is in the similar range of error that is reported in Table II.
We show the reported and estimated number of infection
cases for Sweden by using ELM time-varying for different
τ ’s in Figure 3. For each τ , we estimate the number of cases
up to τ days after which JHU data is collected. According
to our experimental result, we predict that a total of 27737,
28522, and 30841 people will be infected in Sweden on May
13, May 15, and May 19, 2020, respectively.
Histograms of error percentage of the four methods are
shown in Figure 4 for different values of τ . These experiments
verify that ELM time-varying is the most consistent approach
as the length of the time-series increases from May 4 to May
12. We report the average error percentage of ELM timevarying over the last 10 days of the time-series in Table III. We
see that as τ increases the estimation error increases. When
τ = 7, ELM time-varying works well for all of the countries
except India, even though the number of training samples has
increased compared to Subsection IV-A.
C. With the available data till May 20, 2020
In this subsection, we repeat the prediction based on the
time-series data which is available until today May 20, 2020,
for τ ∈ {1, 7, 14}. In Subsection IV-B, we predicted the total
number of cases in Sweden on May 13, May 15, and May 19,
2020. The reported number of cases on these days for Sweden
turned out to be 27909, 29207, and 30799, respectively, which
is in the similar range of prediction error that is reported in
Table III.
We increase the prediction range τ in this subsection and
we show the reported and estimated number of infection cases
for Sweden by using ELM time-varying for τ = 1, 7, and 14
in Figure 5. For each τ , we estimate the number of cases up
to τ days after which JHU data is collected. According to our
experimental result, we predict that a total of 32032, 34702,
and 37188 people will be infected in Sweden on May 21, May
27, and June 3, 2020, respectively.

Histograms of error percentage of the four methods are
shown in Figure 6 for different values of τ . These experiments
verify that ELM time-varying is the most consistent approach
as the length of the time-series increases from May 12 to
May 20. We report the average error percentage of ELM timevarying over the last 10 days of the time-series in Table IV. We
see that as τ increases the estimation error increases. When
τ = 7, ELM time-varying works well for all of the countries
so we increase the prediction range to 14 days. We observe
that ELM time-varying fails to provide an accurate estimate
for several countries such as France, India, Iran, and USA.
This experiment shows that long-term prediction of the spread
COVID-19 can be investigated as an open problem. However,
by observing Tables II-IV, we expect that the performance of
ELM time-varying to improve in the future as the number of
training samples increases during the pandemic.
V. C ONCLUSION
We studied the estimation capabilities of two well-known
approaches to deal with the spread of the COVID-19 pandemic. We showed that a small-sized neural network such as
ELM provides a more consistent estimation compared to polynomial regression counterpart. We found that a daily update
of the model hyperparameters is of paramount importance to
achieve a stable prediction performance. The proposed models
currently use the only samples of the time-series data to predict
the future number of cases. A potential future direction to
improve the estimation accuracy is to incorporate constraints
such as infectious disease spread model, non-pharmaceutical
interventions, and authority policies [2].
R EFERENCES
[1] Ensheng Dong, Hongru Du, and Lauren Gardner, “An interactive webbased dashboard to track covid-19 in real time,” The Lancet Infectious
Diseases, vol. 20, no. 5, pp. 533 – 534, 2020.
[2] Folkhlsomyndigheten,
“Estimates of the peak-day and
the number of infected individuals during the covid-19
outbreak
in
the
stockholm
region,
sweden
februaryapril
2020,”
Available at: https://folkhalsomyndigheten.se/publiceratmaterial/publikationsarkiv/e/estimates-of-the-peak-day-and-the-numberof-infected-individuals-during-the-covid-19-outbreak-in-the-stockholmregion-sweden-february–april-2020/.
[3] Christian Szegedy, Alexander Toshev, and Dumitru Erhan, “Deep neural
networks for object detection,” in Advances in Neural Information
Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds., pp. 2553–2561. 2013.
[4] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton, “Imagenet
classification with deep convolutional neural networks,” in Advances in
Neural Information Processing Systems 25, pp. 1097–1105. 2012.
[5] G. Huang, G.-B. Huang, S. Song, and K. You, “Trends in extreme learning
machines: A review,” Neural Networks, vol. 61, no. Supplement C, pp.
32 – 48, 2015.
[6] R. Giryes, G. Sapiro, and A. M. Bronstein, “Deep neural networks with
random gaussian weights: A universal classification strategy?,” IEEE
Trans. Signal Process., vol. 64, no. 13, pp. 3444–3457, July 2016.
[7] Saikat Chatterjee, Alireza M. Javid, Mostafa Sadeghi, Shumpei Kikuta,
Dong Liu, Partha P. Mitra, and Mikael Skoglund, “SSFN – self sizeestimating feed-forward network with low complexity, limited need for
human intervention, and consistent behaviour across trials,” arXiv preprint
arXiv:1905.07111, 2020.
[8] A. M. Javid, A. Venkitaraman, M. Skoglund, and S. Chatterjee, “Highdimensional neural feature using rectified linear unit and random matrix
instance,” in ICASSP 2020 - 2020 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP), 2020.

4

TABLE II: Average estimation error in percentage (%) over the last 10 days for ELM time-varying. Update May 4.
Country

Sweden

Denmark

Finland

Norway

France

Italy

Spain

UK

China

India

Iran

USA

1 day prediction

0.9

0.5

0.9

0.2

0.8

0.1

0.5

0.3

0

0.7

0.1

0.4

3 days prediction

2.6

0.7

0.7

0.6

2

0.3

2.5

1.3

0

2.1

0.2

1.7

7 days prediction

2

4.8

2.2

1.2

18.2

1.1

3.1

3

0.2

8.8

0.6

4.9

104
Estimated
Reported

Cases

2
1.5
1
0.5

10

20

30

40

50

60

70

80

90

Apr 4, 2020

Day n

May 4, 2020

(a) τ = 1

10

4

Estimated
Reported

Cases

2
1.5
1
0.5

10

20

30

40

50

60

70

80

90

Apr 4, 2020

Day n

May 4, 2020

(b) τ = 3

10
2.5

Cases

2

4

Estimated
Reported

1.5
1
0.5
10

20

30

40

50

Day n

60

Apr 4, 2020

70

80

90

100

May 4, 2020

(c) τ = 7

Fig. 1: Reported and estimated cases after τ days over the last 31 days of Sweden for ELM time-varying. Update May 4.

5

7

ELM time-varying
ELM
Poly time-varying
Poly

6

Histogram

5
4
3
2
1
0

5

10

15

20

25

30

Error (%)
(a) τ = 1

ELM time-varying
ELM
Poly time-varying
Poly

3.5

Histogram

3
2.5
2
1.5
1
0.5
0

20

40

60

80

100

120

140

160

180

200

Error (%)
(b) τ = 3

ELM time-varying
ELM
Poly time-varying
Poly

20

Histogram

15

10

5

0
0

100

200

300

400

500

600

700

800

900

1000

Error (%)
(c) τ = 7

Fig. 2: Histogram of estimation error percentage over 31 days of all 12 countries for different values of τ for each of the ELM
and polynomial approaches. Update May 4.

6

TABLE III: Average estimation error in percentage (%) over the last 10 days for ELM time-varying. Update May 12.
Country

Sweden

Denmark

Finland

Norway

France

Italy

Spain

UK

China

India

Iran

USA

1 day prediction

0.7

0.2

0.6

0.1

0.5

0.1

0.3

0.3

0

0.9

0.3

0.2

3 days prediction

2.3

0.5

1

0.4

1.4

0.3

0.4

1.3

0

3.4

0.7

0.5

7 days prediction

1.8

1.2

1.4

0.8

3.6

0.7

1.3

3.8

0

10.9

2.9

2.3

104
2.5

Estimated
Reported

Cases

2
1.5
1
0.5
10

20

30

40

50

60

70

80

90

100

Apr 12, 2020

Day n

May 12, 2020

(a) τ = 1

10

4

Estimated
Reported

2.5

Cases

2
1.5
1
0.5
10

20

30

40

50

60

70

80

90

100

Apr 12, 2020

Day n

May 12, 2020

(b) τ = 3

3

Cases

2.5

10

4

Estimated
Reported

2
1.5
1
0.5
10

20

30

40

50

60

Day n

70
Apr 12, 2020

80

90

100

110

May 12, 2020

(c) τ = 7

Fig. 3: Reported and estimated cases after τ days over the last 31 days of Sweden for ELM time-varying. Update May 12.

7

ELM time-varying
ELM
Poly time-varying
Poly

Histogram

8

6

4

2

0
0

5

10

15

20

25

30

Error (%)
(a) τ = 1
14
ELM time-varying
ELM
Poly time-varying
Poly

12

Histogram

10
8
6
4
2
0
0

20

40

60

80

100

120

140

160

180

200

Error (%)
(b) τ = 3
4

ELM time-varying
ELM
Poly time-varying
Poly

3.5

Histogram

3
2.5
2
1.5
1
0.5
0

100

200

300

400

500

600

700

800

900

1000

Error (%)
(c) τ = 7

Fig. 4: Histogram of estimation error percentage over 31 days of all 12 countries for different values of τ for each of the ELM
and polynomial approaches. Update May 12.

8

TABLE IV: Average estimation error in percentage (%) over the last 10 days for ELM time-varying. Update May 20.
Country

Sweden

Denmark

Finland

Norway

France

Italy

Spain

UK

China

India

Iran

USA

1 day prediction

0.5

0.2

0.4

0.1

0.2

0.1

0.3

0.2

0

0.5

0.3

0.2

7 days prediction

1.6

1.4

1.4

0.3

1.4

0.3

1.4

1.2

0

2.9

3.6

1.2

14 days prediction

3.3

6

1.8

2.6

19.4

0.8

2.2

8.8

0.1

33.9

10.4

11.3

20

30

40

104
3

Estimated
Reported

Cases

2.5
2
1.5
1
0.5

10

50

60

70

80

Day n

90

100

Apr 20, 2020

110
May 20, 2020

(a) τ = 1

104
Estimated
Reported

3

Cases

2.5
2
1.5
1
0.5
10

20

30

40

50

60

Day n

70

80

90

100

Apr 20, 2020

110
May 20, 2020

(b) τ = 7

10

Cases

3

4

Estimated
Reported

2
1

20

40

60

Day n

80
Apr 20, 2020

100

120
May 20, 2020

(c) τ = 14

Fig. 5: Reported and estimated cases after τ days over the last 31 days of Sweden for ELM time-varying. Update May 20.

9

ELM time-varying
ELM
Poly time-varying
Poly

Histogram

4

3

2

1

0

1

2

3

4

5

6

7

8

9

10

Error (%)
(a) τ = 1

ELM time-varying
ELM
Poly time-varying
Poly

5

Histogram

4
3
2
1

0

20

40

60

80

100

120

140

160

180

200

Error (%)
(b) τ = 7
5
ELM time-varying
ELM
Poly time-varying
Poly

Histogram

4
3
2
1
0
0

200

400

600

800

1000

1200

1400

1600

1800

2000

Error (%)
(c) τ = 14

Fig. 6: Histogram of estimation error percentage over 31 days of all 12 countries for different values of τ for each of the ELM
and polynomial approaches. Update May 20.

10

14

ELM time-varying, avg = 1%, std = 1%
ELM, avg = 1.3%, std = 1.2%
Poly time-varying, avg = 3%, std = 3.4%
Poly, avg = 3.7%, std = 2.4%

12

Error (%)

10
8
6
4
2
65

70

75

80

85

90

95

Day n
(a) Sweden
4
ELM time-varying, avg = 0.7%, std = 0.6%
ELM, avg = 0.7%, std = 0.7%
Poly time-varying, avg = 1.5%, std = 1.1%
Poly, avg = 1.4%, std = 1%

3.5

Error (%)

3
2.5
2
1.5
1
0.5
40

45

50

55

60

65

Day n
(b) Denmark
14

ELM time-varying, avg = 1.6%, std = 1.9%
ELM, avg = 1.3%, std = 1.9%
Poly time-varying, avg = 3.5%, std = 3.3%
Poly, avg = 3.4%, std = 3%

12

Error (%)

10
8
6
4
2
70

75

80

85

90

95

Day n
(c) Finland
ELM time-varying, avg = 0.6%, std = 0.6%
ELM, avg = 0.5%, std = 0.5%
Poly time-varying, avg = 1.9%, std = 2.1%
Poly, avg = 2.1%, std = 2.1%

8
7

Error (%)

6
5
4
3
2
1
40

45

50

55

60

65

Day n
(d) Norway

Fig. 7: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 1.

11

ELM time-varying, avg = 2.5%, std = 3.8%
ELM, avg = 2.4%, std = 3.2%
Poly time-varying, avg = 5.4%, std = 4.1%
Poly, avg = 5.8%, std = 4.8%

Error (%)

15

10

5

75

80

85

90

95

100

Day n
(a) France
3.5
ELM time-varying, avg = 0.3%, std = 0.2%
ELM, avg = 0.5%, std = 0.3%
Poly time-varying, avg = 0.8%, std = 0.7%
Poly, avg = 1%, std = 0.9%

3

Error (%)

2.5
2
1.5
1
0.5
65

70

75

80

85

90

95

Day n
(b) Italy
12
ELM time-varying, avg = 0.9%, std = 1.2%
ELM, avg = 1%, std = 1.2%
Poly time-varying, avg = 2.2%, std = 2.3%
Poly, avg = 5.2%, std = 3.3%

Error (%)

10
8
6
4
2

65

70

75

80

85

90

Day n
(c) Spain
12
ELM time-varying, avg = 1.4%, std = 1.7%
ELM, avg = 1%, std = 1.2%
Poly time-varying, avg = 3%, std = 3.1%
Poly, avg = 3.2%, std = 3.1%

Error (%)

10
8
6
4
2

65

70

75

80

85

90

Day n
(d) UK

Fig. 8: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 1.

95

12

ELM time-varying, avg = 0%, std = 0.1%
ELM, avg = 0.1%, std = 0.1%
Poly time-varying, avg = 0.1%, std = 0.1%
Poly, avg = 0.1%, std = 0.1%

Error (%)

0.4

0.3

0.2

0.1

75

80

85

90

95

100

Day n
(a) China
40

ELM time-varying, avg = 2.7%, std = 4.2%
ELM, avg = 7.2%, std = 2.9%
Poly time-varying, avg = 8.9%, std = 9.7%
Poly, avg = 7.4%, std = 8.4%

35

Error (%)

30
25
20
15
10
5
70

75

80

85

90

95

Day n
(b) India
6
ELM time-varying, avg = 0.1%, std = 0.1%
ELM, avg = 0.1%, std = 0.1%
Poly time-varying, avg = 0.6%, std = 0.8%
Poly, avg = 1.6%, std = 1.9%

Error (%)

5
4
3
2
1

50

55

60

65

70

75

Day n
(c) Iran
25
ELM time-varying, avg = 0.5%, std = 0.4%
ELM, avg = 0.6%, std = 0.4%
Poly time-varying, avg = 2.7%, std = 3.6%
Poly, avg = 15.5%, std = 6.8%

Error (%)

20
15
10
5

75

80

85

90

95

100

Day n
(d) USA

Fig. 9: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 1.

13

80

ELM time-varying, avg = 4.2%, std = 3.8%
ELM, avg = 5%, std = 2.8%
Poly time-varying, avg = 16.6%, std = 20.1%
Poly, avg = 8.2%, std = 9.7%

70

Error (%)

60
50
40
30
20
10
65

70

75

80

85

90

95

Day n
(a) Sweden
160

ELM time-varying, avg = 2.9%, std = 2.8%
ELM, avg = 13.2%, std = 6.6%
Poly time-varying, avg = 13.3%, std = 30.2%
Poly, avg = 12.1%, std = 10.9%

140

Error (%)

120
100
80
60
40
20
40

45

50

55

60

65

Day n
(b) Denmark
ELM time-varying, avg = 3.5%, std = 3.7%
ELM, avg = 3.4%, std = 3.5%
Poly time-varying, avg = 25.2%, std = 21.6%
Poly, avg = 29.8%, std = 22.4%

80
70

Error (%)

60
50
40
30
20
10
70

75

80

85

90

95

Day n
(c) Finland
100

ELM time-varying, avg = 1.1%, std = 0.8%
ELM, avg = 0.9%, std = 0.8%
Poly time-varying, avg = 10.5%, std = 20.5%
Poly, avg = 12.4%, std = 10.2%

Error (%)

80
60
40
20

40

45

50

55

60

65

Day n
(d) Norway

Fig. 10: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 3.

14

ELM time-varying, avg = 7.1%, std = 6.2%
ELM, avg = 9.7%, std = 3%
Poly time-varying, avg = 26.1%, std = 31.5%
Poly, avg = 17.6%, std = 17.4%

160
140

Error (%)

120
100
80
60
40
20
75

80

85

90

95

100

Day n
(a) France
ELM time-varying, avg = 0.9%, std = 0.8%
ELM, avg = 6.7%, std = 11%
Poly time-varying, avg = 11.1%, std = 25.5%
Poly, avg = 2%, std = 2.2%

120

Error (%)

100
80
60
40
20
65

70

75

80

85

90

95

Day n
(b) Italy
70
ELM time-varying, avg = 2.2%, std = 1.8%
ELM, avg = 1.7%, std = 1.7%
Poly time-varying, avg = 12.4%, std = 14.1%
Poly, avg = 35.4%, std = 23.6%

60

Error (%)

50
40
30
20
10
65

70

75

80

85

90

Day n
(c) Spain
35

ELM time-varying, avg = 3.6%, std = 2.8%
ELM, avg = 21.8%, std = 5.4%
Poly time-varying, avg = 11.1%, std = 11%
Poly, avg = 11.5%, std = 8.7%

Error (%)

30
25
20
15
10
5
65

70

75

80

85

90

Day n
(d) UK

Fig. 11: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 3.

95

15

0.8

ELM time-varying, avg = 0.1%, std = 0.1%
ELM, avg = 0.4%, std = 0.2%
Poly time-varying, avg = 0.2%, std = 0.2%
Poly, avg = 0.4%, std = 0.2%

0.7

Error (%)

0.6
0.5
0.4
0.3
0.2
0.1
75

80

85

90

95

100

Day n
(a) China
ELM time-varying, avg = 5.8%, std = 6.6%
ELM, avg = 14.5%, std = 8%
Poly time-varying, avg = 34.8%, std = 39.9%
Poly, avg = 34%, std = 21.6%

Error (%)

150

100

50

70

75

80

85

90

95

Day n
(b) India
60

ELM time-varying, avg = 0.9%, std = 1.9%
ELM, avg = 2%, std = 3%
Poly time-varying, avg = 8%, std = 13.9%
Poly, avg = 8.1%, std = 8.2%

Error (%)

50
40
30
20
10

50

55

60

65

70

75

Day n
(c) Iran
60
ELM time-varying, avg = 1.8%, std = 1.2%
ELM, avg = 2%, std = 1.2%
Poly time-varying, avg = 13.1%, std = 16.4%
Poly, avg = 17.3%, std = 17.6%

Error (%)

50
40
30
20
10

75

80

85

90

95

100

Day n
(d) USA

Fig. 12: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 3.

16

400
ELM time-varying, avg = 7.2%, std = 6%
ELM, avg = 45.6%, std = 14.3%
Poly time-varying, avg = 105.7%, std = 121.1%
Poly, avg = 52.3%, std = 89.3%

350

Error (%)

300
250
200
150
100
50
65

70

75

80

85

90

95

Day n
(a) Sweden
1000
ELM time-varying, avg = 15.3%, std = 14.5%
ELM, avg = 18.5%, std = 16.1%
Poly time-varying, avg = 210.2%, std = 922%
Poly, avg = 2335%, std = 9655.6%

Error (%)

800
600
400
200
0
40

45

50

55

60

65

Day n
(b) Denmark
1000
ELM time-varying, avg = 12%, std = 15.6%
ELM, avg = 17.3%, std = 9.9%
Poly time-varying, avg = 177.6%, std = 574.6%
Poly, avg = 1868.6%, std = 5659.9%

Error (%)

800
600
400
200
0
70

75

80

85

90

95

Day n
(c) Finland
1000
ELM time-varying, avg = 4.8%, std = 5.5%
ELM, avg = 4.5%, std = 3.3%
Poly time-varying, avg = 124.8%, std = 487.1%
Poly, avg = 148.3%, std = 459.3%

Error (%)

800
600
400
200
0
40

45

50

55

60

65

Day n
(d) Norway

Fig. 13: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 7.

17

ELM time-varying, avg = 18.4%, std = 11.6%
ELM, avg = 14.4%, std = 6.4%
Poly time-varying, avg = 34%, std = 27%
Poly, avg = 55.5%, std = 54.1%

Error (%)

150

100

50

75

80

85

90

95

100

Day n
(a) France
60

ELM time-varying, avg = 3.8%, std = 5.8%
ELM, avg = 1.6%, std = 1.2%
Poly time-varying, avg = 22.9%, std = 14.7%
Poly, avg = 12.6%, std = 13.6%

Error (%)

50
40
30
20
10

65

70

75

80

85

90

95

Day n
(b) Italy
120

ELM time-varying, avg = 10%, std = 12.3%
ELM, avg = 9.2%, std = 7.3%
Poly time-varying, avg = 40.4%, std = 27.2%
Poly, avg = 43.5%, std = 30.7%

Error (%)

100
80
60
40
20

65

70

75

80

85

90

Day n
(c) Spain
200
ELM time-varying, avg = 14.1%, std = 24%
ELM, avg = 169.8%, std = 27.8%
Poly time-varying, avg = 37%, std = 30.1%
Poly, avg = 27%, std = 17.1%

Error (%)

150

100

50

65

70

75

80

85

90

Day n
(d) UK

Fig. 14: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 7.

95

18

3

ELM time-varying, avg = 0.3%, std = 0.2%
ELM, avg = 1%, std = 0.3%
Poly time-varying, avg = 1%, std = 0.7%
Poly, avg = 0.7%, std = 0.4%

Error (%)

2.5
2
1.5
1
0.5

75

80

85

90

95

100

Day n
(a) China
1000
ELM time-varying, avg = 25.9%, std = 27.5%
ELM, avg = 23.6%, std = 14.3%
Poly time-varying, avg = 161.2%, std = 609.8%
Poly, avg = 4342.9%, std = 12418%

Error (%)

800
600
400
200
0
70

75

80

85

90

95

Day n
(b) India
400
ELM time-varying, avg = 7.7%, std = 10.4%
ELM, avg = 12.9%, std = 5%
Poly time-varying, avg = 33.5%, std = 47.4%
Poly, avg = 35.2%, std = 71.8%

350

Error (%)

300
250
200
150
100
50
50

55

60

65

70

75

Day n
(c) Iran
350

ELM time-varying, avg = 24.1%, std = 69%
ELM, avg = 265%, std = 84.8%
Poly time-varying, avg = 34.5%, std = 31.2%
Poly, avg = 55.5%, std = 59.3%

300

Error (%)

250
200
150
100
50
75

80

85

90

95

100

Day n
(d) USA

Fig. 15: Daily error percentage of the last 31 days of 12 countries for ELM and polynomial regression. Here, τ = 7.

