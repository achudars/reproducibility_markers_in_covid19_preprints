Deep learning for COVID-19 diagnosis based
feature selection using binary differential
evolution algorithm
Mohammad Saber Iraji a,c, Mohammad-Reza Feizi-Derakhshib, *, Jafar Tanhac
a
b

Department of Computer Engineering and Information Technology, Payame Noor University, Tehran, Iran

Computerized Intelligence Systems Laboratory, Department of Computer Engineering, University of Tabriz,
Tabriz, Iran
c

Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran

Abstract

The new Coronavirus is spreading rapidly and it has taken the lives of many people so far. The virus has
destructive effects on the human lung and early detection is very important. Deep Convolution neural networks
are a powerful tool in classifying images. Therefore, in this paper a hybrid approach based on a deep network is
presented. Feature vectors were extracted by applying a deep convolution neural network on the images and
effective features were selected by the binary differential meta-heuristic algorithm. These optimized features were
given to the SVM classifier. A database consisting of three categories of images as COVID-19, pneumonia, and
healthy included 1092 X-ray samples was considered. The proposed method achieved an accuracy of 99.43%, a
sensitivity of 99.16%, and a specificity of 99.57%. Our results demonstrate the suggested approach is better than
recent studies on COVID-19 detection with X-ray images.

Keywords— Deep convolution, COVID-19, Metaheuristic, binary differential, Neural networks, X-ray image

1. INTRODUCTION
The rapid spread of COVID-19 has killed many people around the world. The disease is associated with
symptoms such as muscle aches, coughs, fevers, and can be detected through clinical trials and radiographic
imaging. Medical imaging is very important in diagnosing diseases. The X-rays and computed tomography (CT)
scans of the disease can be used in the deep network to help diagnose the disease more quickly.
The process of classifying and diagnosing the disease from a photo using a neural network consists of 4 main
steps: feature extraction, optimal feature selection, network training, and model performance test. Feature
extraction is of two types. In the first case: The extraction of features from images include the shape of tissues
and texture for patient classification is done using image processing techniques, algorithms, and filters. In the
second type, the original images and their actual output class were entered into the convolution network as input
data, and after the network training process and weight adjustment, the features were automatically extracted in
the last full layer.
Hemdan, Shouman, & Karar have suggested positive or negative status of COVID with deep learning models
[1]. They had reported the VGG19 model was better results with 90% accuracy on 25 COVID, 25 non-COVID
images. Toğaçar, Ergen, & Cömert have used 295 COVID, 98 pneumonia, 65 normal images into MobileNet and
SqueezeNet [2]. They have extracted features from the models trained Net and then the features were selected by
the SMO algorithm. The overall accuracy was 99.27% using the SVM classifier. Zhang, Xie, Li, Shen, & Xia
investigated a ResNet model with 18 layers for 100 COVID, 1431 pneumonia images. The value of accuracy was
achieved by 95.18% [3]. Apostolopoulos & Mpesiana offered pre-trained VGG19 based on 224 COVID, 700
pneumonia,504 normal images[4]. The accuracy of their results was 98.75%. In [5] authors considered the
DarkNet with 17 convolutional layers using 127 COVID, 500 pneumonia, 500 normal images, and the accuracy
was 98.08%. In [6] the performance of CNN was improved using pre-processing image algorithms and the model
resulted in 94.5% of accuracy.
Some features extracted from the deep network may have a detrimental effect on the accuracy of the
classification [7]. Therefore, the optimal feature selection methods are essential. Among the feature selection
methods, meta-heuristic methods have shown better performance.
There are three types of feature selection methods. The filter method, which uses the intrinsic properties of
features and statistical indicators such as fisher score, information gain, chi-square, correlation coefficient. The
wrapper method uses a learning algorithm and looks for a subset of features in the feature space that optimize
classification accuracy. Therefore, wrapper approaches are expensive because use meta-heuristic methods for

feature subset selection and cross-validation. The hybrid method applies a combination of filter and wrapper
methods [8].
Analyzing extracted features from images and selecting optimal features improves classification performance
[9] . In the field of medical imaging, it has been reported many feature selection (FS) studies such as RobustnessDriven FS (RDFS) for lung CT image [10] ، Shearlet transform FS from brain MRI image [11]، principal
component analysis for lung X-Ray Images [12], genetic algorithm (GA) for lung nodules [13]، bat algorithm
(BA) compared with particle swarm optimization (PSO) in lung X-ray images [14], flower pollination algorithm
(FPA) from lung images [15].

In [7] authors designed a COVID-19 classification method which mixed a CNN named Inception pre-trained
Imagnet as feature extractor and Marine Predators Algorithm as feature selector, KNN as classifier based on 2 datasets for
two classifications as positive, negative COVID-19 problem. Dataset1 included 200 COVID-19 positive images and 1675
negative also dataset2 contained 219 COVID-19 positive images and 1341 negative images. Accuracy was stated 98.7%,
99.6% for dataset 1, data set2. Canayaz checked a COVID-19 diagnosis model using VGG19, ResNet, AlexNet, and
GoogleNet mixed by two meta-heuristic algorithms named binary particle swarm optimization and binary gray wolf
optimization. The best overall classification accuracy was 99.38% after feature selection by binary gray wolf optimization
based on 1092 X-ray images of COVID-19, pneumonia, and healthy records [16].

In the above study, the use of different available methods for classifying COVID-19 patients from lung image
by machine vision combined with metaheuristic algorithms is propounded. Therefore, the need for an intelligent
system seems to be necessary, which helps physicians and treatment staff to classify COVID-19 patients with high
accuracy and high speed to reduce mortality from the disease. The motivation of the research is to plan a smart
manner with artificial intelligence methods to aid doctors and patients in COVID-19 prediction and with high
accuracy. The contributions of the study are as:
1- Designing an intelligent system using the deep convolutional neural network without a pre-trained network
based on lung X-ray images and extracting features from it with the minimum optimal memory required to create
and train the network.
2- Selecting the optimal features of the differential meta-heuristic method that led to the improvement of the
performance indexes
3- Increasing the accuracy of classification for multi-class problems, including three categories of patients
with COVID-19, pneumonia, and healthy.
The structure of our study is as follows :in section 2, the proposed methodology and model using deep
convolution and binary differential algorithm for COVID-19 detections is presented. Experimental results and

comparison with other previous works are shown in section 3. Finally, the study ends with a conclusion and future
works.

2. METHODOLOGY AND MODEL
The proposed model is shown in Figure 1. First, the lung images enter into the convolutional neural network.
After training the network, features are extracted from the images that are not optimal. Optimal features are
extracted using the heuristic method. The classification of the three classes named COVID-19, pneumonia, and
healthy is done with higher accuracy.
Input images (224*224)

Deep Convolution

Extracted features
From fully connect layer
Non-Optimized
features
Meta heuristic feature selectionBDE
Optimized
features
Classification
Figure 1. The proposed model for COVID-19

2.1. Deep convolution
The convolution neural network is an extractor of features and a suitable classification method in machine
learning. In the convolutional network, the input of the network is the original data such as images. The network
automatically extracts the features, through the convolution function, after the process of learning, instead of
extracting the feature manually. The matrices as the filters, slide on the main input image, and the convolution
operation is performed through equation 1. Finally, after training and mapping the input images to the output
labels, the features are extracted after several layers of convolution [17].
𝑐2−1 𝑡𝑐
(𝐼𝑀𝐺 ∗ 𝐶)𝑖𝑗 = ∑𝑐1−1
𝑝=0 ∑𝑞=0 ∑𝑐=1 𝐶𝑝,𝑞,𝑐 . 𝐼𝑀𝐺𝑖+𝑝,𝑗+𝑞,𝑐 + 𝑏𝑠

(1)

Where IMG is input image with height =H,width=W dimensions, tc is the number of image channels, C is filter
matrix with c1*c2 dimensions, bs is a bias value for each filter C, i=0…H, j=0…W
After applying the convolution, the unwanted values are removed with the ReLu layer and then the input is
reduced by the pooling layer. The effective input vector enters the fully connected layer, which has the same
function as the MLP. In the final part of the deep convolution layers, Softmax [18], classification layers, performed
the classification operation using ADAM (adaptive moment optimizer) [19], bellow lost function (equation 2).
1

𝑟
𝐿(𝑤, 𝑏) = − ∑𝑀
̂𝑚 + (1 − 𝑦𝑚 ) log(1 − 𝑦̂𝑚 )] + Γ × ∑𝑀
𝑚=1[𝑦𝑚 log 𝑦
𝑟=1‖𝑤 ‖2
𝑀

(2)

Where M is a number of sample images, 𝑦𝑚 is a true class for m-th sample, 𝑦̂𝑚 is predicted output class for mth input data, Γ is regularization coefficient.

2.2. Binary Differential Evolution
Differential evolution (DE) [20] was an evolutionary heuristic method designed for minimizing the continuous
problem. Binary differential evolution (BDE) [21] expanded for feature selection issue. It has three main builders
named mutation, crossover, and selection. First, the initial population is produced by dimensions D, which D is
the number of features that we want to optimize. For the mutation operation, three random vectors 𝑝𝑢1 , 𝑝𝑢2 , 𝑝𝑢3
are selected for vector 𝑝𝑘 such that 𝑢1 ≠ 𝑢2 ≠ 𝑢3 ≠ 𝑘., k is a vector arrangement in population
If d-th dimension of a vector 𝑝𝑢1 and vector 𝑝𝑢2 be equal, the d-th feature of the difference vector (equation
3) will be zero, otherwise, it takes the same value as a vector 𝑝𝑢1 .
𝑑𝑖𝑓𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑣𝑒𝑐𝑡𝑜𝑟𝑘𝑑 = {

𝑑
𝑑
0 𝑝𝑢1
= 𝑝𝑢2
𝑝𝑢1
𝑜𝑡ℎ𝑒𝑟

(3)

Afterward, the mutation and crossover are executed as shown in equations 4 and 5.
1, 𝑖𝑓 𝑑𝑖𝑓𝑓𝑒𝑟𝑒𝑛𝑐𝑒 𝑣𝑒𝑐𝑡𝑜𝑟𝑘𝑑 = 1
𝑚𝑢𝑡𝑒 𝑣𝑒𝑐𝑡𝑜𝑟𝑘𝑑 = { 𝑑
𝑝𝑢3 , 𝑜𝑡ℎ𝑒𝑟

(4)

𝑚𝑢𝑡𝑒 𝑣𝑒𝑐𝑡𝑜𝑟𝑘𝑑 , 𝑖𝑓 𝛾 ≤ 𝐶𝑅 ∥ 𝑑 = 𝑑𝑟𝑎𝑛𝑑𝑜𝑚
𝑊𝑘𝑑 = { 𝑑
𝑝𝑘 ,
𝑜𝑡ℎ𝑒𝑟

(5)

Where 𝑊 is the try vector, CR 𝜖 (0, 1) is crossover amount, 𝛾 𝜖 (0, 1) is a random number. In the selection procedure, if
the fitness value of the try vector 𝑊𝑘 be better than the current vector 𝑝𝑘 will replace it. Otherwise, the current vector 𝑝𝑘 is
stored for the next generation.

3. DISCUSSION AND EXPERIMENTAL RESULTS

3.1. Description of data

Canayaz created a COVID-19 X-ray data set including three classes of patients with COVID-19, pneumonia,
and healthy [16] . In this database, there are 364 images for each of the three categories that is obtained as a
balanced dataset by combining data [22-24]. The total number of images is (3*394)1092 and its dimensions are
224 x 224. In this study, the same data are used to predict COVID-19 disease with the convolutional neural
network and select optimal features by the meta-heuristic algorithm named binary differential. Figure 2 shows
one sample of three output classes as COVID-19, pneumonia, and healthy.

Figure 2. The Chest X-ray images of different conditions (a) COVID-19 (b) Pneumonia (c) Healthy

3.2. Performance evaluation
The suggested model was performed in Matlab version 9.1.0.441655 (R2018b) on a notebook PC with, 1.8
GHz CPU, and 4 Gigabyte RAM. The Accuracy, sensitivity, specificity, geometric mean, and area under curve
(AUC-ROC)[25, 26] as performance evaluation metrics (equations 6-9) were considered to measure the COVID
19 prediction model. The correctness of classification is named accuracy. The amount of the negatives that are
correctly distinguished is specificity, the amount of the positives that are correctly distinguished is sensitivity. The
second root of the product of sensitivity, specificity is called the geometric mean. Higher values of the area under
the curve (AUC) in the receiver operating characteristics indicate better classification performance.
𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =

𝑇𝑃+𝑇𝑁
𝑇𝑃+𝑇𝑁+𝐹𝑃+𝐹𝑁

(6)

Where:
True positives = the number of samples that are correctly labelled as positive
False positives = the number of samples that are wrongly labelled as positive
True negatives = the number of samples that are correctly labelled as negative
False negatives = the number of samples that are wrongly labelled as negative
Sensitivity = TP / (TP+ FN)

(7)

Specificity = TN / (FP+TN)

(8)

Geometric mean= 2√Sensitivity ∗ Specificity

3.3. Model parameters

(9)

The structure of the deep convolution neural network is shown in Figure 3. Firstly, the dimensions of images
in the image input layer were 224*224, there were 8 filters 3-by-3 for convolution operator. The local features
automatically are extracted after processing the first block of the network layers, ie image input, convolution,
Batch Normalize, ReLU, max-pooling layers, fully connected layer 400, ReLU, Drop out. Finally, the second
network block, including three- fully connected layers, softmax, classification categorizes the input images into
three output classes. The validation accuracy after 200 epochs was 97.25% using ADAM optimizer during training
and the mini-batch size was 64 (Figure 4). The batch normalization and dropout are put due to regularize neural
network and barricade overfitting.

Figure. 3. Structure of proposed model layers

Figure. 4. Accuracy and loss measure for training, validation data using convolution neural networks

Convolution networks are a method for converting the input to feature vectors. Since some network features
may cause poor performance of the model [7], therefore after extracting 400 features in the first fully Connect
layer, the met heuristic algorithm named binary differential was used to select the optimal features subset and
remove the useless features. In the binary differential algorithm, population = 20, iteration= 100 (figure 5), and a
crossover rate of 1 were the parameters of the algorithm. Amount (1- (geometric mean)) of the SVM classifier
[27] was considered as fitness values of the population (Figure 5). After executing the binary differential
algorithm, 340 optimal features were selected.

Figure. 5. Fitness curve for the Binary differential algorithm

3.4. Performance comparison
Of the total data, 70% of the data was considered for the train, 15% for the validation, and 15% for the test. To
prevent overfitting, the proposed method was applied to the data 100 runs [28]. Both the optimal selected features
by the differential algorithm and the initial extracted features from the deep convolution neural network entered
into the SVM classifier.
Table 1 demonstrated the confusion matrix using train, test, validation, and total data for original features and
optimized features are applied by SVM classifier. The tp, tn, fp, fn, accuracy, sensitivity, specificity, geometric

mean, AUC metrics for each of the three output classes, and each type of test, train, validation, and total data were
computed (Table2).
According to Table 3, the proposed model based on the extracted features from X-ray image using CNN and
selected optimized features by the binary differential meta-heuristic algorithm has attained an accuracy of
99.43%, a sensitivity of 99.16%, a specificity of 99.57%, a gmean of 99.37%, AUC of 0.99, and a root mean
square error (RMSE) of 0.1133. In this paper accuracy for the classification of the COVID -19 issue was calculated
to be 99.43%, and the count of relevant features was 304 (Table 4) whereas in the previous study [16] based on
the same data they were reported to be 99.38%, 448 features.

Table 1. Average of a confusion matrix for 100 runs with 3 classes by the (a) optimized features (b) original features based on train, test,
validation, and total data
(a) Optimized features

(b) Original features

Predicted
Optimized features
test
Covid
actual

Normal
Pneumonia

Optimized
features
validation
Covid
actual

Normal
Pneumonia

Optimized
features
train

actual

Covid

Normal

Pneumonia

51/75

0

0/2

0/15

54/9

0/1

0/4

0/55

55/95

Predicted
Covid

Normal

Pneumonia

55/05

0/05

0/45

0/05

54/4

0/3

0/4

1

52/3

Pneumonia

Covid

256/5

0

0

Normal

0

254/1

0

Pneumonia

0

0

253/4

Predicted

Optimized features

Actual

Normal
Pneumonia

Actual

Normal
Pneumonia

original features
validation
Covid
actual

Normal
Pneumonia

Covid

Normal

Pneumonia

51/65

0

0/3

0/25

54/65

0/25

0/5

0/95

55/45

Predicted
Covid

Normal

Pneumonia

54/85

0

0/7

0/15

54/2

0/4

0/55

1/2

51/95

Predicted

Normal

Covid

Covid

Predicted

Predicted
Covid

total

Original features
test

Original features
train

Covid

Normal

Pneumonia

Covid

256/45

0

0/05

Normal

0

254/1

0

Pneumonia

0

0

253/4

Actual

Predicted

original features

Covid

Normal

Pneumonia

363/3

0/05

0/65

0/2

363/4

0/4

0/8

1/55

361/65

total
Covid
actual

Normal
Pneumonia

Covid

Normal

Pneumonia

362/95

0

1/05

0/4

362/95

0/65

1/05

2/15

360/8

Table 2. Comparison of indicators (TP, TN, FP, FN, accuracy, the area under curve, sensitivity, specificity, geometric mean) for any output
class based on (a) optimized features (b) original features
(a) Optimized features

(b) Original features

Optimized
features –total

Covid

Normal

Pneumonia

TP

363/30

363/40

TN

727/00

726/40

Original
features -total

Covid

Normal

Pneumonia

361/65

TP

362/95

362/95

360/80

726/95

TN

726/55

725/85

726/30

1/45

2/15

1/70

FP

1/00

1/60

1/05

FP

FN

0/70

0/60

2/35

FN

1/05

1/05

3/20

Accuracy

99/84

99/80

99/69

Accuracy

99/77

99/71

99/55

Sensitivity

99/81

99/84

99/35

Sensitivity

99/71

99/71

99/12

Specificity

99/86

99/78

99/86

Specificity

99/80

99/70

99/77

geometric mean

99/84

99/81

99/60

geometric mean

99/76

99/71

99/44

area under curve

0/9976

0/9971

0/9944

Covid

Normal

pneumonia

TP

256/45

254/10

253/40

TN

507/50

509/90

510/55

FP

0/00

0/00

0/05

FN

0/05

0/00

0/00

area under curve

0/9984

0/9981

0/9961

Optimized
features –train

Covid

Normal

pneumonia

TP

256/50

254/10

253/40

TN

507/50

509/90

510/60

FP

0/00

0/00

0/00

FN

0/00

0/00

0/00

Accuracy

100/00

100/00

100/00

Sensitivity

100/00

100/00

100/00

Specificity

100/00

100/00

100/00

geometric mean

100/00

100/00

100/00

area under curve

1/0000

1/0000

1/0000

Optimized
features –test

Covid

Normal

Pneumonia

Original features
-train

Accuracy

99/99

100/00

99/99

Sensitivity

99/98

100/00

100/00

Specificity

100/00

100/00

99/99

geometric mean

99/99

100/00

100/00

area under curve

0/9999

1/0000

1/0000

Covid

Normal

Pneumonia

Original features
-test

TP

51/75

54/90

55/95

TP

51/65

54/65

55/45

TN

111/50

108/30

106/80

TN

111/30

107/90

106/55

FP

0/55

0/55

0/30

FP

0/75

0/95

0/55

FN

0/20

0/25

0/95

FN

0/30

0/50

1/45

Accuracy

99/54

99/51

99/24

Accuracy

99/36

99/12

98/78

Sensitivity

99/62

99/55

98/33

Sensitivity

99/42

99/09

97/45

Specificity

99/51

99/49

99/72

Specificity

99/33

99/13

99/49

geometric mean

99/56

99/52

99/02

geometric mean

99/38

99/11

98/46

area under curve

0/9956

0/9952

0/9903

area under curve

0/9937

0/9910

0/9847

Optimized
features -valid

Covid

Normal

Pneumonia

Covid

Normal

Pneumonia

TP

55/05

54/40

52/30

Original features

TN

108/00

108/20

109/55

FP

0/45

1/05

0/75

FN

0/50

0/35

1/40

Accuracy

99/42

99/15

98/69

Sensitivity

99/10

99/36

97/39

Specificity
geometric mean
area under curve

99/59
99/34
0/9934

99/04
99/20
0/9920

99/32
98/35
0/9840

-valid
TP

54/85

54/20

51/95

TN

107/75

108/05

109/20

FP

0/70

1/20

1/10

FN

0/70

0/55

1/75

Accuracy

99/15

98/93

98/26

Sensitivity

98/74

99/00

96/74

Specificity

99/35

98/90

99/00

geometric mean

99/05

98/95

97/87

area under curve

0/9904

0/9895

0/9789

Table 3. Average of confusion matrix components for 100 runs by the original features and optimized features
Area
Method

TP

TN

FP

FN

Geometric
Accuracy Sensitivity Specificity
mean

Under

RMSE

Curve
Original features by Deep convolution
Training

254/65

509/32

0/02

0/02

1/0000

0/9999

1/0000

1/0000

0/9999

0/0036

Testing

53/92

108/58

0/75

0/75

0/9909

0/9866

0/9931

0/9898

0/9898

0/1533

Validation

53/67

108/33

1/00

1/00

0/9878

0/9816

0/9909

0/9862

0/9863

0/1905

Total

362/23

726/23

1/77

1/77

0/9968

0/9951

0/9976

0/9964

0/9964

1/1543

Optimized features by Binary Deferential
Training

254/67

509/33

0/00

0/00

1/0000

1/0000

1/0000

1/0000

1/0000

0/0000

Testing

54/20

108/87

0/47

0/47

0/9943

0/9916

0/9957

0/9937

0/9937

0/1133

Validation

53/92

108/58

0/75

0/75

0/9909

0/9862

0/9931

0/9896

0/9898

0/1592

Total

362/78

726/78

1/22

1/22

0/9978

0/9967

0/9983

0/9975

0/9975

1/1543

Table 4. Comparison of the suggested approach with related prior research

research

[16]

This research

Method
Binary particle swarm optimization VGG19

Binary differential -cnn

Number of
features

Accuracy

Geometric
mean

RAM

Max Computation
time

448

99.38

-

16
gigabyte

2500s

308

99.43

99.37

4 gigabyte

2300s

4. CONCLUSION
The number of people with COVID-19 disease has rapidly expanded. The usage of machine vision techniques
and artificial intelligence as an aid plays an important role in diagnosing the disease and helping to treat it. The
purpose of this paper was to develop a method for problem COVID-19. A data set of lung images, including three
categories of pneumonia, COVID-19, healthy were considered.
A deep convolution neural network consisting of 11 layers was applied to extract the features. Relevant features
were selected by the binary differential metaheuristic method and unrelated features were removed. Lung X-ray
images were classified based on these optimal features using a SVM classifier. The results of this study showed
that the accuracy indicator, the number of relevant extracted features had better performance on the same data
than previous methods. The proposed model based on a deep neural network and meta-heuristic algorithm for
feature selection can be used in other medical applications.

For future work, using another feature selection algorithm and applying other learners may yield better results.
In addition to the images, the parameters derived from the clinical trials can create a new model with a new
combination of features to diagnose the disease or possibly predict its death. In addition to the images, the
parameters extracted from the clinical trials can create a new model with a new combination of features, which
may be effective in diagnosing the disease or possibly predicting its death.

Summary points
What was Already Known on the topic?

•chest X-ray is an imaging approach to detect COVID-19.
•Deep learning method-based X-ray with pre-train network use in features extraction of images for prediction
of COVID-19.
•More researches reported two classification problems as COVID-19, and healthy.

What this study adds to our knowledge

• using the deep convolutional neural network without a pre-trained network based on chest X-ray images and
extracting features from it can optimize the needed memory.
•Deep learning mixed Metaheuristic technique (binary differential algorithm) can enhance feature selection
and improve model performance.
• Increasing the accuracy of classification for multi-class problems, including three categories of patients with
COVID-19, pneumonia, and healthy can achieve.

Acknowledgments
The authors are grateful to all study participants.

Authors’ contributions
Iraji and Feizi-Derakhshi suggested the algorithm for image analysis; Iraji implemented it and analyzed the experimental
results; Tanha provided clinical guidance; Iraji, Feizi-Derakhshi, and Tanha consulted the obtained result. All authors read and
approved the final manuscript.

Funding
This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sectors.

Availability of data and materials
The datasets used and analyzed during the current study are available from the corresponding author on reasonable request.

DISCLOSURE OF POTENTIAL CONFLICTS OF INTEREST
Conflicts of interest
The authors declared no potential conflicts of interest with respect to the research, authorship, and/or
publication of this article.

Ethical approval
This article does not contain any data, or other information from studies or experimentation, with the involvement of
human or animal subjects.

Consent for publication
Agreed by the authors.

Competing interests
The authors declare that they have no competing interests.

REFERENCES

1
Hemdan, E.E.-D., Shouman, M.A., and Karar, M.E.: ‘Covidx-net: A framework of deep learning
classifiers to diagnose covid-19 in x-ray images’, arXiv preprint arXiv:2003.11055, 2020
2
Toğaçar, M., Ergen, B., and Cömert, Z.: ‘COVID-19 detection using deep learning models to
exploit Social Mimic Optimization and structured chest X-ray images using fuzzy color and stacking
approaches’, Computers in Biology and Medicine, 2020, pp. 103805
3
Zhang, J., Xie, Y., Li, Y., Shen, C., and Xia, Y.: ‘Covid-19 screening on chest x-ray images using
deep learning based anomaly detection’, arXiv preprint arXiv:2003.12338, 2020

4
Apostolopoulos, I.D., and Mpesiana, T.A.: ‘Covid-19: automatic detection from x-ray images
utilizing transfer learning with convolutional neural networks’, Physical and Engineering Sciences in
Medicine, 2020, pp. 1
5
Ozturk, T., Talo, M., Yildirim, E.A., Baloglu, U.B., Yildirim, O., and Acharya, U.R.: ‘Automated
detection of COVID-19 cases using deep neural networks with X-ray images’, Computers in Biology and
Medicine, 2020, pp. 103792
6
Heidari, M., Mirniaharikandehei, S., Khuzani, A.Z., Danala, G., Qiu, Y., and Zheng, B.: ‘Improving
the performance of CNN to predict the likelihood of COVID-19 using chest X-ray images with
preprocessing algorithms’, International journal of medical informatics, 2020, 144, pp. 104284
7
Sahlol, A.T., Yousri, D., Ewees, A.A., Al-Qaness, M.A., Damasevicius, R., and Abd Elaziz, M.:
‘COVID-19 image classification using deep features and fractional-order marine predators algorithm’,
Scientific Reports, 2020, 10, (1), pp. 1-15
8
Hoque, N., Bhattacharyya, D.K., and Kalita, J.K.: ‘MIFS-ND: A mutual information-based feature
selection method’, Expert Systems with Applications, 2014, 41, (14), pp. 6371-6385
9
Lambin, P., Rios-Velazquez, E., Leijenaar, R., Carvalho, S., Van Stiphout, R.G., Granton, P.,
Zegers, C.M., Gillies, R., Boellard, R., and Dekker, A.: ‘Radiomics: extracting more information from
medical images using advanced feature analysis’, European journal of cancer, 2012, 48, (4), pp. 441446
10
Chong, D.Y., Kim, H.J., Lo, P., Young, S., McNitt-Gray, M.F., Abtin, F., Goldin, J.G., and Brown,
M.S.: ‘Robustness-driven feature selection in classification of fibrotic interstitial lung disease patterns
in computed tomography using 3D texture features’, IEEE transactions on medical imaging, 2015, 35,
(1), pp. 144-157
11
Acharya, U.R., Fernandes, S.L., WeiKoh, J.E., Ciaccio, E.J., Fabell, M.K.M., Tanik, U.J.,
Rajinikanth, V., and Yeong, C.H.: ‘Automated detection of Alzheimer’s disease using brain MRI images–
a study with various feature extraction techniques’, Journal of Medical Systems, 2019, 43, (9), pp. 302
12
Afzali, A., Mofrad, F.B., and Pouladian, M.: ‘Feature Selection for Contour-based Tuberculosis
Detection from Chest X-Ray Images’, in Editor (Ed.)^(Eds.): ‘Book Feature Selection for Contour-based
Tuberculosis Detection from Chest X-Ray Images’ (IEEE, 2019, edn.), pp. 194-198
13
Da Silva, S.F., Ribeiro, M.X., Neto, J.d.E.B., Traina-Jr, C., and Traina, A.J.: ‘Improving the ranking
quality of medical image retrieval using a genetic feature selection method’, Decision support systems,
2011, 51, (4), pp. 810-820
14
Li, J., Fong, S., Liu, L.-s., Dey, N., Ashour, A.S., and Moraru, L.: ‘Dual feature selection and
rebalancing strategy using metaheuristic optimization algorithms in X-ray image datasets’, Multimedia
Tools and Applications, 2019, 78, (15), pp. 20913-20933
15
Johnson, D.S., Johnson, D.L.L., Elavarasan, P., and Karunanithi, A.: ‘Feature Selection Using
Flower Pollination Optimization to Diagnose Lung Cancer from CT Images’, in Editor (Ed.)^(Eds.): ‘Book
Feature Selection Using Flower Pollination Optimization to Diagnose Lung Cancer from CT Images’
(Springer, 2020, edn.), pp. 604-620
16
Canayaz, M.: ‘MH-COVIDNet: Diagnosis of COVID-19 using deep neural networks and metaheuristic-based feature selection on X-ray images’, Biomedical Signal Processing and Control, 2020,
64, pp. 102257
17
Gao, Y., Zhu, T., and Xu, X.: ‘Bone age assessment based on deep convolution neural network
incorporated with segmentation’, International Journal of Computer Assisted Radiology and Surgery,
2020, 15, (12), pp. 1951-1962
18
Adem, K., Kiliçarslan, S., and Cömert, O.: ‘Classification and diagnosis of cervical cancer with
stacked autoencoder and softmax classification’, Expert Systems with Applications, 2019, 115, pp.
557-564
19
Khaire, U.M., and Dhanalakshmi, R.: ‘High-dimensional microarray dataset classification using
an improved adam optimizer (iAdam)’, Journal of Ambient Intelligence and Humanized Computing,
2020, 11, (11), pp. 5187-5204

20
Storn, R., and Price, K.: ‘Differential evolution–a simple and efficient heuristic for global
optimization over continuous spaces’, Journal of global optimization, 1997, 11, (4), pp. 341-359
21
Zorarpacı, E., and Özel, S.A.: ‘A hybrid approach of differential evolution and artificial bee
colony for feature selection’, Expert Systems with Applications, 2016, 62, pp. 91-103
22
Cohen, J.P., Morrison, P., Dao, L., Roth, K., Duong, T.Q., and Ghassemi, M.: ‘Covid-19 image
data collection: Prospective predictions are the future’, arXiv preprint arXiv:2006.11988, 2020
23
Chowdhury, M.E., Rahman, T., Khandakar, A., Mazhar, R., Kadir, M.A., Mahbub, Z.B., Islam,
K.R., Khan, M.S., Iqbal, A., and Al-Emadi, N.: ‘Can AI help in screening viral and COVID-19 pneumonia?’,
arXiv preprint arXiv:2003.13145, 2020
24
Kermany, D., Zhang, K., and Goldbaum, M.: ‘Labeled optical coherence tomography (OCT) and
Chest X-Ray images for classification’, Mendeley data, 2018, 2
25
Farag, A.A., Ali, A., Elshazly, S., and Farag, A.A.: ‘Feature fusion for lung nodule classification’,
International journal of computer assisted radiology and surgery, 2017, 12, (10), pp. 1809-1818
26
Li, Z., Jiang, J., Zhou, H., Zheng, Q., Liu, X., Chen, K., Weng, H., and Chen, W.: ‘Development of
a deep learning-based image eligibility verification system for detecting and filtering out ineligible
fundus images: A multicentre study’, International Journal of Medical Informatics, 2021, 147, pp.
104363
27
Xu, L., Wang, X., Bai, L., Xiao, J., Liu, Q., Chen, E., Jiang, X., and Luo, B.: ‘Probabilistic SVM
classifier ensemble selection based on GMDH-type neural network’, Pattern Recognition, 2020, 106,
pp. 107373
28
Kuncheva, L.I.: ‘Combining pattern classifiers: methods and algorithms’ (John Wiley & Sons,
2014. 2014)

