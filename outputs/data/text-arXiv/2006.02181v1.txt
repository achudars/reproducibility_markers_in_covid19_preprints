1

arXiv:2006.02181v1 [cs.SI] 3 Jun 2020

Information Consumption and Social Response in a Segregated
Environment: the Case of Gab
GABRIELE ETTA, University of Padova
ALESSANDRO GALEAZZI, University of Brescia
MATTEO CINELLI, Ca’ Foscari University of Venice
MAURO CONTI, University of Padova
WALTER QUATTROCIOCCHI, Ca’ Foscari University of Venice

Most of the information operations involve users who may foster polarization and distrust toward science
and mainstream journalism, without these users being conscious of their role. Gab is well known to be an
extremist-friendly platform that performs little control on the posted content. Thus it represents an ideal
benchmark for studying phenomena potentially related to polarization such as misinformation spreading.
The combination of these factors may lead to hate as well as to episodes of harm in the real world. In this
work we provide a characterization of the interaction patterns within Gab around the COVID-19 topic. To
assess the spreading of different content type, we analyze consumption patterns based on both interaction
type and source reliability. Overall we find that there are no strong statistical differences in the social response
to questionable and reliable content, both following a power law distribution. However, questionable and
reliable sources display structural and topical differences in the use of hashtags. The commenting behaviour of
users in terms of both lifetime and sentiment reveals that questionable and reliable posts are perceived in the
same manner. We can conclude that despite evident differences between questionable and reliable posts Gab
users do not perform such a differentiation thus treating them as a whole. Our results provide insights toward
the understanding of coordinated inauthentic behavior and on the early-warning of information operation.
ACM Reference format:
Gabriele Etta, Alessandro Galeazzi, Matteo Cinelli, Mauro Conti, and Walter Quattrociocchi. 2016. Information
Consumption and Social Response in a Segregated Environment: the Case of Gab. 1, 1, Article 1 (January 2016),
12 pages.
DOI: 10.1145/nnnnnnn.nnnnnnn

1

INTRODUCTION

Social media platforms play a crucial role in the public sphere, shaping the public discussion on a
wide range of topics including politics, health, climate change, economics, migration [6, 7, 11, 20].
Users online have shown tendency a) to acquire information adhering to their system of beliefs [5],
b) to ignore dissenting information [46], c) to form polarized groups around a shared narrative [21].
One of the dominating traits of online social dynamics, indeed, is polarization [40]. Divided in echo
chambers, users account for the coherence with their preferred narrative rather than the true value
of the information [18, 19]. This scenario creates the perfect incubator for information operations
[13]. Among the most pressing issues is the spread of fictitious and low-quality information (e.g.,
fake news, rumors, hoaxes). Questionable means are often used to influence the public opinion
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and
the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2016 ACM. XXXX-XXXX/2016/1-ART1 $15.00
DOI: 10.1145/nnnnnnn.nnnnnnn
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:2

Etta et al.

toward polarization or to burst distrust in governments and institutions [19]. The spread of lowquality information is sometimes carried out by groups of coordinated or automated accounts
that pollute and tamper with our social environments by injecting and sharing a large number of
targeted messages [23], i.e., what Facebook calls ficoordinated inauthentic behavior” [26]. Although
some studies focused on the interplay between false and real information [41], the main point
to understand is how information fits into a larger disinformation campaign [13, 38]. Most of
the information operations involve users which are not aware of their role but which may foster
polarization and distrust toward science and mainstream journalism [4, 22, 27, 36].
In this paper we characterize users behavior in an extremist social media platform. All social
media platforms, indeed, present distinct features such as the type of content as well as users
interaction options [12, 14]. Along with mainstream platforms like Facebook, Twitter, YouTube
and Instagram, niche ones such as Gab or Reddit have been created. These platforms strongly
differ for various aspects mainly related to the political leaning of the user base and to the content
regulation policy implemented. The latter element has crucial importance, being strongly linked to
the risk of opinion polarization and to the development of hating contents [14]. Within such niche
media, biased information proliferates [15] and users, either interested in joining the community or
banned by other social media, tend to develop the feeling of community belonging with like-minded
individuals, i.e., an echo-chamber [19]. Hence, studying users interaction patterns in platforms like
Gab becomes of primary interest in order to shed light on the dynamics of content production and
information spreading in such segregated environment.
In this study, we explore different aspects related to the spreading of both questionable and
reliable contents in Gab by taking into account several aspects, namely: the users’ reactions, the
topics embedded in hashtag networks and the users’ sentiment. In more detail, we first focus on the
differences between interactions types in terms of frequency and time. Then we build statistically
validated hashtag co-occurrence networks assessing the topological differences between questionable
and reliable contents. Finally, we analyze the interplay between sentiment of comments and
commenting behavior with respect to information source questionability.
The paper is organized as follows: Section 2 describes the current state of the art of nonmainstream social media, focusing in particular on Gab. Section 3 describes the mathematical tools
behind the analysis. Section 4 describes how results are obtained, while Section 5 summarizes the
results and discusses the possible applications associated.
2

STATE OF THE ART

A wide research effort has been paid to characterize online information operations [13, 25, 28, 37, 43]
especially in the case of terrorism [9, 30, 39]. Several works addressed the analysis of social behaviors
to detect features with the aim to anticipate and thus inhibits information disorders [10, 34, 40, 44].
Most of the tactics tend to exploit the confirmation bias [19] of users to foment heated debates
[2, 42]. Niche social media performing little regulation on their contents seem to be the ideal
environment for triggering polarization dynamics that can eventually turn into actions of harm
even offline [17].
Gab is an online social platform, describing itself as “A social network that champions free
speech, individual liberty and the free flow of information online. All are welcome” [1]. Such a
claim, together with the political leaning of its founders and developers, made Gab the fisafe havenfi
for the alt-right movement. However, low moderation and regulation of contents has resulted in a
widespread of hate speech and fake news. For these reasons, it has been repeatedly suspended by
its service provider, and its mobile app has been banned from both App and Play stores [45]. In
particular, Gab attracted the interest of researchers due to its permissive content regulatory policy
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

Information Consumption and Social Response in a Segregated Environment: the Case of Gab1:3
and the political leaning of its users. In [33] authors analyze the content shared on Gab and the
leaning of users, finding a rather homogeneous environment prone to share right biased content.
Authors of [45] characterize Gab in terms of users leaning and content shared, suggesting that
it is more similar to a safe place for right wing extremist rather than a environment where free
speech is protected. Moreover, a topological analysis performed by authors of [14] reveals that Gab
users appear as one quite homogeneous cluster biased to the right. Further, differently from other
platforms such as Twitter and Facebook, in Gab there is a lack of users with leaning opposite to the
most popular one. Overall, all these studies suggest that Gab can be considered as a homogeneous
environment where biased content and misinformation may easily proliferate.
3

PRELIMINARIES AND DEFINITIONS

Networks. The basis for the conceptualization of a network is a graph G = (V , E), being V the set
of n nodes and E the set of m edges. The nodes are denoted as i, j ∈ V or, similarly, i, j = 1, . . . , n,
and the edge that formalizes the connection between i and j is denoted as (i, j) .
With A we denote the adjacency matrix, a n-squared binary matrix taking values 0 or 1, where
the element
Í Ai j = 1 if nodes i and j are connected and Ai j = 0 otherwise; the degree of the node i
is ki = j Ai j , and it quantifies the number of neighbours of the node i; the number of links in the
Í
graph G is m = 12 i j Ai j . A graph that respects the last formalized equality, called Handshaking
Lemma, is an undirected graph. Another instance that we take into account is the bipartite graph,
that is a graph in which the vertex set V is the union of two disjoint independent sets called the
partitions of G. The equivalent of an adjacency matrix for a bipartite graph is a h × p rectangular
matrix called incidence matrix B that takes values 0 or 1, where the element Bi j = 1 if nodes i and
j are connected. A bipartite graph can be easily projected onto one of its partitions by performing
an operation called one-mode projection that can be formalized in terms of the product P = BT B,
in the case we are projecting onto the partition of size p, and P = BBT if we are projecting onto
the partition of size h. P is a symmetric matrix whose elements Pi j are nonnegative numbers that
represent, in the case of off-diagonal elements, the number of common links of the nodes i and j to
the partition of size h or p. The diagonal elements of the matrix P are also nonnegative numbers
that represent the degree of the node in the bipartite graph. Since the elements on the diagonal of
the matrix P have a different meaning with respect to the elements away from the diagonal, it is
common practice to set the diagonal elements Pii = 0. The matrix P after such a treatment, can be
also called co-occurence matrix since two elements are interconnected if they are co-connected to
at least one node of the partition they don’t belong to. In addition, the number of co-connections
between i and j is represented by the link weight, i.e., by the element Pi j of the matrix P.
Hashtag Co-occurence Network. Starting from the set P of all posts and the set H of the hashtags
found in those posts, we create the bipartite network T , whose nodes are posts and hashtags. A
link between an hashtag hi and a post pi exists if the hashtag hi is used inside the post pi . From the
bipartite network T we create the hashtag co-occurrence weighted network H by projecting the
bipartite network T onto the partition H . Additionally, such a network is statistically validated by
using the methodology presented in [8, 31]. The result is hence a co-occurrence hashtag network
where two hashtag are connected if their co-occurrence in the set of posts is statistically significant.
Data Collection. Gab provides a search tool that returns a list of users, hashtags and groups
related to the keyword queried. Starting from Google Trends results, we select a set of popular
research keywords that we feed into Gab search tool and we download all hashtags linked to them.
We then inspect the results and manually filter them based on the hashtag meaning. Finally, we
download all the posts with relative comments linked to each hashtag we select. We end up with
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:4

Etta et al.

116343 posts, associated with 16144 different hashtags, that received 96757 likes, 20001 comments
and 60563 reblogs by 4293 users in the period 01/01/2020 – 31/03/2020.
Questionable and Reliable Sources. In order to evaluate the questionability of information circulating in Gab we employ a source-based approach. We build a dataset of news outlets website
domains where each domain in our dataset is labeled either as ”questionable” or ”reliable” by
means of the classification of the respective news outlet provided by a fact-checking organization
called MediaBias/FactCheck (MBFC, https://mediabiasfactcheck.com). MBFC has been frequently
used for source classification [3, 8, 14]. It provides a classification determined by ranking bias in
four different categories that are: Biased Wording/Headlines, Factual/Sourcing, Story Choices and
Political Affiliation. A score is assigned to each category per each news outlet and the average score
determined the bias of the outlet, as explained in the Methodology Section of the website. To each
news outlet is associated a label that refers either to a political bias, namely, Right, Right-Center,
Least-Biased, Left-Center and Left or to its reliability that is expressed in three labels namely,
Conspiracy-Pseudoscience, Pro-Science or Questionable. Noticeably, also the Questionable set
includes a wide range of political biases, from Extreme Left to Extreme Right. For instance, the Right
label is associated to Fox News, the Questionable label to Breitbart (the well-known extreme right
outlet) and the Pro-Science label to Science. Using such a classification, we divide the news outlets
into Questionable outlets and Reliable outlets. All the outlets already classified as Questionable
or belonging to the category Conspiracy-Pseudoscience are labelled as Questionable, the rest is
labelled as Reliable.
Considering all the 2637 news outlets that we retrieve from the list provided by MBFC we end
up with 800 outlets classified as Questionable 1837 outlets classified as Reliable.
Hashtag Questionability Index. In order to measure the extent to which an hashtag is used in
posts associated with either reliable or questionable contents, we introduce a measure called
questionability. The measure is defined in the range q ∈ [0, 1] and it equals 0 when a certain hashtag
is used exclusively in posts associated to reliable sources while it equals 1 when a certain hashtag
is used only in posts associated to questionable sources.
Formally, hashtag questionability can be defined as follows: let P be the set of all posts with a
url matching a domain in our dataset and H the set containing all the hashtags. At each element
p j ∈ P is associated a binary value l j ∈ {0, 1} based on the domain of the link contained: if the url
refers to a domain classified as questionable then l j = 1, otherwise l j = 0. Considering and hashtag
hi in the bipartite network T then the questionability index qi of hashtag hi can be defined as:
qi =

ki
1 Õ
lj ,
ki j=1

(1)

where l j is the questionability score of the j-th neighbour of the hashtag hi .
4

RESULT AND DISCUSSION

In this section we analyze and compare how users perceive news in terms of reactions to posts,
topics embedded in hashtag networks and users’ sentiment.
4.1

Consumption Patterns

We investigate the news consumption and the activity of Gab users by considering a dataset of
posts related to the COVID-19 pandemics. As shown in Figure 1, users tend to prefer a type of
interaction that is more immediate and less cognitive-demanding [32]. Indeed, the left panel of
Figure 1 shows how Likes are the most active way to engage, consequently followed by Reblogs and
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

Information Consumption and Social Response in a Segregated Environment: the Case of Gab1:5
Replies. The same behaviour is also confirmed by the cumulative number of interactions during the
analyzed period. In this case, the difference between Likes and Reblogs is less accentuated until the
beginning of February, with all distributions following an incremental trend that is comparable
with consumption patterns from other social media [15].

105●●
●
●
●
●
●

Count

Number of Interactions

104

105

3

10

102
101
100

●
● ●
● ●
●●
●
● ●●
● ●
●
● ●
●●
●
● ●●●
● ●●
●
●● ●
●
●
● ●●
● ●
●
● ●●
●
●
●● ●
●
●
● ●
●● ●●●
●
●●
●●
●
●● ● ●
●●
●● ●
●●
●
●
●
●● ●●●
●
●●
● ●●
●
●●
●
●
●●
●●
●
●
●●●
●● ●
●
●

●

104

103

102

●●●
●●●●●●
●●●●
●●●
●●●
●●●
●●●
●●●●●●
●●●●
●●●●●
●●●
●●●●●
●●
●
●
●
●
●
●
●
●
●
●● ●
●●●
●●●●
●●●●●
●●●●● ●●●●●
●●●●●
●
●●●●●
●●●●●
●
●
●
●
●
●
●
●
●
●●●
●●●● ●●●●●●●●●
●
●
●
●
●
●
●
●●
●●●
●●●●●●
●●●
●●
●●●●●
●●●●●
●●●●●
●
●●●
●●●●
●●●●●
● ●●●
●●●
● ●●● ●●●●●●●●
●●●
●●●●
●● ●● ●●●●
●●●●●
●
● ●●●●●
●
●
●●
● ●●●●
●●●●
●●●●●●
●●●●●
●●●●●
●●●
●● ●●
●●●
●●●
●●● ●
●
●● ●●
●●
●●
●●
●●
●● ●●
●●
●● ●
●●●
●
●●
●● ●●
●
●
●●
●
● ●●●
●
●
● ●●
● ●●
●
●●
●
● ●●
●●
●
● ●●
●●●
●●
●●
●
●
●
●
●●●
●●
●●
●
●●
● ●
●
●
●
●
●

●●● ●
●●
●
●
● ●●
●●●
●
●
●
●
●
●
●
●
●
●
●●
●●
●
●
●
●
●
●●●
● ● ●
●

100

100.5 101 101.5 102
Number of Interactions

102.5

gen

feb

mar

apr

Days

Fig. 1. Frequency distribution of interactions with posts (left) and their cumulative engagement (right). A
like is usually a positive feedback on a news item. A reblog indicates a desire to spread a news item to friends.
A reply can have multiple features and meanings and can generate collective debate. The left panel display
that every kind of reaction follows an heavy-tailed distribution that allows room for large deviations, i.e.,
some posts go viral. The right panel displays the evolution of the cumulative number of interactions over
time. The trend is always increasing with a rapid increase at the beginning of February that is likely to be
connected to the beginning of the COVID-19 infodemic. Both plots show how likes are the preferred type of
interaction and how their frequencies are inversely proportional to the amount of cognitive effort required.

The consumption pattern can also be analyzed considering the categorization of posts into questionable and reliable. Panel 2a of Figure 2, displays the distribution of like reaction to questionable
and reliable contents that, overall, show a rather similar behaviour. In fact, both type of posts are
subject to receive a disproportionate amount of likes.
Panel 2b of Figure 2 shows the probability distributions of the number of posts by category with
their corresponding fits.To check that those fits follow a power law distribution [16], we perform a
bootstrap procedure [24] for both categories. After having estimated xmin and α, we compute n 1 ,
i.e., the number of values below xmin from the initial dataset, and n 2 , i.e the difference with the
total cardinality n and the n 1 previously calculated. Consequently, we perform 5000 randomized
instances where, for each of them, we performed a Kolgomorov-Smirnov test between the uniform
distribution U (1, xmin ), containing n 1 values, and the power law distribution with parameter a,
containing n 2 values. We end up with obtaining a p-value that ranges from 0.90 to 0.95 for the
distribution of likes to questionable, and 0.986 to 0.992 for the reliable ones. Thus we can accept
the hypothesis that data is generated by a power law distribution. The estimated exponent is 3.36
and 3.34 for questionable and reliable sources respectively, implying the presence of very large
deviation in the number of likes for both categories.
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:6

Etta et al.
Questionable
hashtag
degree
brands
7
apology
7
dominic
7
raab
7
thanks
7
dominance
7
key
7
shitholecountry 7
-

Reliable
hashtag
outbreak
tc
wwg1wga
kag
donaldjohntrump
Coronavirus∗
boingboing
startups
walkaway
school

degree
763
422
236
173
163
147
141
137
133
122

Intersection
hashtag
degree
pandemic 235
cdc
200
who
195
news
183
cia
166
trump
164
health
156
virus
155
democrats 148
maga
147

Table 1. Top 10 hashtags in the largest connected component.∗ Translation from Tamil language.

Panels 2c and 2d of Figure 2 show the temporal evolution of the cumulative and average number
of likes to questionable and reliable contents. The matching between the two curves observed in the
panel 2c is due to an increase in the number of reliable posts rather than to an increase in the users
endorsement to such posts. Indeed, as confirmed by panel 2d of Figure 2, questionable posts receive
on average an higher number of likes. It is nonetheless interesting the inflation in the number
of reliable posts happened at the beginning of February that could be related either to a growing
concern about the global pandemic or to a growing debate around reliable news. Nonetheless, this
inflation does not reflect in a correspondent growth in the number of likes, showing a constant
interest of Gab users towards questionable sources.
4.2

Comparing Questionable and Reliable Hashtags

Hashtags are a good proxy for describing the semantic and topical elements of posts. Therefore,
investigating the interplay between the use of hashtags and the diversity of information sources
may unveil the narratives related to questionable and reliable contents. To achieve this goal,
we consider 17996 hashtags appeared in labelled posts. The hashtags can be divided into three
categories: those appearing only in questionable posts (qi ∈ [0.95, 1]), those appearing only in
reliable posts (qi ∈ [0, 0.05]) and those appearing in both types of posts (qi ∈ (0.05, 0.95)). The first
subset is made up of 1332 hashtags, the second is made up of 14565 hashtags and the third is made
up of 2099 hashtags. The hashtag questionability, described in Equation 1, follows a multimodal
distribution with peaks located at extreme values, as shown in Figure 3.
We use these sets in order to build their corresponding co-occurrence networks using the
procedure described in Section 3, which are represented in Figure 4. The ten hashtags of the largest
connected component with highest prominence in terms of degree are reported in Table 1. The
networks related to purely questionable and purely reliable contents display a strongly disconnected
structure made up of multiple connected components. In the case of questionable sources we have
a decentralized structure with a largest connected component of 8 vertices, accounting for the 2%
of the total network. We also notice how most of the other connected components are organized as
cliques. This highlights that questionable news have their own dialect in terms of hashtags. In the
case of reliable sources we have a more centralized structure due to the contribution of its largest
connected component that consists of 8527 vertices. Noticeably, the largest connected components
accounts for 77% of the number of reliable hashtags, revealing a different structure with respect to
purely Questionable hashtags.
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

Information Consumption and Social Response in a Segregated Environment: the Case of Gab1:7
1.00

10

4

10

3

●
●

●
●

●

●

0.75

●
●
●

●

●
●

●
●
●

10

●

●

2

101

0

10

0.5

10

P(x)

Number of posts

●

●

●
●
●
● ●●
●
●
●● ● ●
●● ●●
●●●
●
●●●
●
●●
●●●
●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
● ●
●●● ●
●●
●●●
●
●●
●
● ●●● ●●
●●●●●
●
●
●
●
●
●●●
●
●
●
●
●
●
●●
●●●●
●
●
● ●
● ●

1

1.5

10
10
Number of likes

10

2

0.50

0.25

●
●

10

0.00
2.5

10

0

10

● ●
●
●
● ●●
●
●
● ●●●
●
●●
●
●●
●
●●
●
●●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●
●●
●
●
●
●
●
●
● ●
●
● ●
●
●

0.5

1

10
10
Number of likes

(a)

10

3

102

●
●●●●●
●●●●
●●●
●●
●●
●●
●
●●●●●●
●●
●●●●●
●●
●●●●● ●●●●●●●●
●●●●
●●
●●● ●●●●●●●●
●●●●
●●●●● ●●●●●●●
●
●
●
●
●●● ●●●●●●●●
●●●
●
●●● ●●●●●
●● ●●●●
● ●●●
●●●●
●●●
●
●●●●
●●●
●
●
●
●
●●
●●
●●
●
●●●
●●
●●
●
●
●●●●
●● ●
● ●●●
●●●●
●●
●●
●●
●●
●
●●
●
●
●

gen

feb

mar
Days

(c)

10

2

●
●

102.5

(b)

apr

1.2
Average number of likes per post

Number of likes

104

1.5

● ●
●●●●●●
●●●
●● ●●●●●●●●●●●●
●●●
●
●●● ●
●●●● ●
●●
●
●●●●●●●●●●●●●●●●●●
●●
●
●
●

0.9

●
●
●

●

0.6

0.3

●●●
● ●●●●●●●●●
●●●
●●●●●●●●
●
●●●●
●●●
●●●●●●●●●
●
●●●
●●
●
●●
●
●●
●
●●●●●●

●
●

●
●
● ●
●●
●●●●●●●
●
●
●●
●●●●●●●
●
●
●
●
●
●
●
●●
●
●●
●●●●
●●●●●●●●●●●
●

gen

feb

mar

apr

Days

(d)

Fig. 2. Panel a: distribution of the frequency of likes obtained by posts related to questionable and reliable
sources. Panel b: Probability distribution of the number of likes to posts related to questionable and reliable
sources. Panel c: Cumulative number of like over time for questionable and reliable sources. Panel d: Average
number of likes per post over time for questionable e reliable sources. The average is computed using a time
window that contains all the posts since January the 1st . Posts from both sources are similar in terms of likes’
distribution, whilst their temporal evolution shown a differentiation starting at the beginning of February.

The investigation of those two networks is then extended by looking at the most central hashtags.
For the purely questionable network, the hashtags with the highest degree value are mostly
associated with political facts and frustration about the current pandemic. In fact, hashtags
referring to Dominic Raab (the first secretary of state in U.K.) were used, as well as hashtags like
dominance or shitholecountry. For the purely reliable network the most central hashtags are mostly
pandemic-related, e.g. outbreak and school. However, alt-right hashtags such as wwg1wga, which is
generally associated with the Q-Anon movement have an important role.
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

15000

1:8

Etta et al.
Number of hashtags

10000

10000

5000

0

1000
100
10
1

0

0.1

0.2

0.00

0.3

0.4

0.5

0.6

Questionability

0.7

0.25
0.25 0.50
0.50 0.75
0.75

0.8

0.9

1

1.00

Fig. 3. Distribution of questionability between hashtags. The two peaks at the extremes suggest there are
recurrent hashtags for posts belonging to questionable or reliable sources.

The right panel of Figure 4 displays the co-occurrence network related to hashtags that are
significantly used in both types of posts. In this case the network has a largest connected components
of 2054 nodes that is higher than in the previous cases being about 98% of the total number of
hashtags in the subset. The set of hashtags used in this case in also more general and related either
to COVID-19 (e.g., pandemics, WHO, health) or to politics (e.g., trump, maga, democrats).
●●
●●
●●
●●

●
●

●●
●
●
●●
●
●●
●

●

●●
●
●

●

●
●

●

●

●
●● ●
● ● ●
● ● ●●●●
●
● ●●
●
●
● ●●
● ● ● ●● ●
● ●
●
●● ● ●●
● ●● ●
●● ●
●● ● ●
● ●
● ●
●
●●
●● ●
●
● ●●●● ●●● ●
●
● ● ●● ●●● ●
●
●
●
●
●
●●●
●
●
●●●●● ●●● ●
●● ● ● ●
●●
●
●
● ●●●● ● ●●● ● ● ● ● ●●
●
●● ●●●●
● ● ●●●● ●●● ●● ●
●●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●●● ● ● ● ●● ● ● ●
●●● ● ●● ●
● ●●
●
●
●● ●● ● ● ● ●
●
●
●
●●●●●
●●●● ●
●● ● ●
●● ● ●●●●
●
●
● ● ●● ● ●● ●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●●● ●● ●●●● ●● ● ●●● ●
●●●●●● ●●
●
●
● ● ●● ●●
●●
●●●●●●●●●●
●●●●
●●
●●●● ●●●●●●●
●
●●
●●●●
●●
●●
●●
●
●
●
●
● ● ● ● ●
●●●●●●●● ●●
●●●
●
●●
●●
●●●
●●
●
●● ●●
●●
●●
●●
●
●
●
●●
● ● ● ● ● ● ● ●●●●
●
●●●●●
●
●●●●
●●●
●
●●
●●●●●
●●●●●●●
●●
●● ●
●●
●●●
●●
●
●
●
● ●●
●
● ●●●●●
●●●●●●
●
●●●
●●
● ●●●●
●
● ●●● ● ●
●
●
●●
●●
●
●●
●
●
●
●●
●
●
●
●
●
●●
●
●
● ● ●●●
●●● ●●●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●●●
●
●●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●●● ●●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●● ● ● ●
●●
●●●
●
●
●
●
●●●●●●●●●
●
●
●
●
●
●
●●
●
●●
●
●●
●●
●
●
●
●
●
●
●●●●●
●
●
●
●
●●
●
●
●●
●
●
●
●●
●●
●
●●
●
●
●
●
●
●●
●
●
● ● ● ● ●●●●●● ●
●●
●●
●
●
●
●●●
●
●
●
●●
●●
●
●
●●● ●
●
●
●●
●
●
●
●
● ●●●●●
●●●●
●●
●
●
●
●
●
●
●
●
●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●●●● ●●●●●●●●
●●
●
●
●●
●
●
●
●●● ●● ●● ● ● ●
●●
●
●●
●●●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●●
●●●
●●
●●●●
●
●●
●
●
●
●
●
●●
●
●●
● ●●
●
●
●●
●●●●
●
●●
●
●●
●
●
●
●
●
●
●● ●
●
●
●
●
●
●
●
● ●●
●
●●
●
●
●
● ● ●●
●
●
●
●
●
●●
●
●
●●●
●
●
●
●
●
●●
●●●
●
●
●
●
●
●
●●
●
●
●
●●●●●●●●
●
●●
●●
●
●
●●
●●
●
●●
●●
●
●
●
●
●
● ● ●●●
●●
●
●
●
●●
●
●
●●
●
●
●
●
●
●
●●
●
●●●●●●●
●
●
●
●
●
●
●●
●●
●●
●●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●●
●
●●●● ●●
● ●●●●
●
●
●
●
●
●
●
● ●
●
●
●
●
●
●
● ●●
●
●
●
●
●●
●●
●●
●●●
●
●●●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●●
●
● ●●●●●●●●
●
●●
●●●
●●
●●
●
●
●
●
●
●
●●
●●●● ●●
●●
●
●
●●
●
●●
●
●●
● ●
●
●
●
●
●●
●
●●
●
●
●
●
●
●
●
●
●●●
●●
●
●
●
●
●
●
●
●
●
●
●●
●● ●●●● ●
●●●●●
●
●
●
●●●
●●
●
●
●
●
●
●
●●
●
●●
●
●
●
●
●●
● ●● ●
●
●
●
●
●
●
●
●
●
●
●●
●
● ● ●●●● ●
●●
●
●
●●
●●
● ●●
●●
●
●●●●
●●
●●
●
●
●
●●
●
●
●
●●
●●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●●●
●
●●
●
●
●
● ●●●●●●
●
●●
●
●
●●●
●
●
●
●
●
●
●
●
●
●
●●●●
●●
●●
●
● ● ●
●●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●● ●
●
●
●
● ● ●●●
●●
●●●●●
●
●●
●
●●●●●●
●●●●●●●
●
●
●
●●●●
●
●
●●
●
●
●●
●
●
●●
● ●
●● ● ●
● ●
●
●
●
●●●
●
●●
●
●●●
●
●
●●
●●
●
●
●●
●
●●
●●
●●
●●●●●●
●
●●
●●
● ● ●●●●● ● ●
●●
●
●●
●●●● ●●●● ●● ●● ●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●● ●●●●●●●●●●● ●● ● ● ● ● ● ●● ●●
●
● ●●●●
● ●●●●●●●●
●●
●●● ●● ●● ● ● ● ● ●
●●●●●●●●
●
●●
●●●
● ● ●●●●
●●
●
●●● ● ●●
●
●●● ● ● ● ● ●
●
● ●●
●●●●●●●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●● ●●● ●●●●●●●●●●●● ● ● ●● ●●
●
●
●
●
● ● ●●
●●
●●● ●●●●● ● ● ●
●●● ● ●●●●●●
●● ●●
●●● ● ●
●
●●
● ● ● ●●● ●● ●●
● ●● ●
●●●●●●●● ● ●●
● ● ● ●● ●●● ●●●
● ●●●● ●● ●● ●●●● ● ● ●●● ●
●
●● ●● ● ●●● ●● ●● ● ●●●●
● ●●
●
● ●● ● ●●●●●●●●●●●● ●●
● ●●●
●
●
●
●●●●● ● ● ● ●●●● ●● ● ●●
● ● ● ●● ● ●
●
● ● ● ●●● ● ●
●
●
●
●
● ●●
●
● ● ● ● ●●● ●●● ●● ● ● ●● ● ● ●
●
● ● ●● ● ● ● ● ●
●
●
●
●
●
●
●
● ●● ● ● ●
●
●
● ●
●
●●
●
●
● ●
●
●
●
●
●●
●● ● ● ●
●●
●
●
●
●
●●
●●

●●

(a)

(c)

(b)

Hashtag Questionability
Questionable

Reliable

Reliable

●●

Questionable

Fig. 4. Projections of Post-Hashtag bipartite networks. Top Left: representation of the projection that
contains only questionable hashtags, i.e., they are only used in posts from questionable sources. Top Right:
representation of the projection that contains only reliable hashtags, i.e., they are only used in posts from
reliable sources. Bottom: representation of the projection containing questionable and reliable posts which
have at least one hashtag in common.

4.2.1 Characterizing Commenting Behaviour for Questionable and Reliable posts. In order to
understand how news are perceived, we investigate the commenting behaviour of users by means
of the sentiment expressed in the comments on questionable and reliable posts. We first pre-process
the text of the comments via lemmatization and we use the Bing Lexicon [29], a list containing
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

Information Consumption and Social Response in a Segregated Environment: the Case of Gab1:9
around 6800 terms related to opinions and sentiments divided by category (Positive or Negative), to
obtain the sentiment of each comment. The sentiment si can be simply computed considering the
number of positive and negative terms, c i+ and c i− respectively, by means of the following equation:
si ≡

c i+ − c i−
.
c i+ + c i−

(2)

Density

1.0

0.5

0.0
Negative

Neutral
Sentiment
Questionable

Positive
Reliable

Fig. 5. Sentiment distribution for Questionable (red) and Reliable (blue) post’s comments.

Notice that si ∈ [−1, 1] for every i, where −1 means that the comment contains only negative
terms, 0 that terms are equally distributed between positives and negatives and +1 that the comment
contains only positive terms.
By computing the sentiment of comments on questionable and reliable posts, we obtain the
distribution shown in Figure 5. Noticeably, there is no difference between the sentiment of comments
under Questionable an Reliable sources. Furthermore, negative sentiment is what regulates user
comments, with less pronounced peaks in correspondence of positive and neutrals . To assess the
difference between the two distributions, we perform a Kolmogorov-Smirnov test [16] that reveals
no difference significant difference between the two distributions (p=0.73).
To provide further insights about the commenting behavior of users under questionable and
reliable posts, we model the persistence of users commenting repeatedly under a post of the same
category. The modeling is performed by means of Kaplan-Meier estimates of two survival functions:
the first relies on time span between user’s first and last comment, i.e., lifetime of a user with
respect to comments, whilst the second takes into account the number of comments of a users.
Figure 6 shows Kaplan-Meier estimates of survival functions grouped by category for the two cases.
Survival curves based on comments lifetime appear very similar (Figure 6a) , while the curves
computed by means of number of comments (Figure 6b) seem to present a slight lower survival
probability for comments to questionable posts. In spite of the latter observation, by performing a
LogRank test [35] we detect no significant difference between the two survival functions (p-values
≤ 0.05). Thus we can state that that the two categories are not significantly different in terms of
survival probabilities: questionable and reliable sourced are perceived in the same way by users in
Gab.
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:10

0.75

0.50

0.25

0.00

1.00
+
+
+
+
+
+
+
+
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++
+
+
+
+
++
++
++
++
++
++
++
++
++
++
++
+++
+++
++++
++++++++
++++ +

0

20

40
60
Survival Time

Survival probability

Survival probability

1.00

Etta et al.

0.75
+
+
+

0.50

++
++
++
+
++
++
++
++
++
+++
+++
+++++
++++
+++++
++++++
++ +++
++++

0.25

0.00
80

0

25

(a)

+++++
++++++
+ +++
+++ ++ +

50
75
Survival Time

+

100

(b)

+

Questionable

+

Reliable

Fig. 6. Panel a: Kaplan-Meier estimates of survival functions computed using user lifetime, i.e., time span
between user’s first and last comment. Panel b: Kaplan-Meier estimates of survival functions computed using
the number of comments per user. Distributions are statistically indistinguishable in both cases, revealing
the independence of comments’ persistence from source questionability.

5

CONCLUSIONS

In this work we investigate the consumption patterns of users in a segregated environment bringing
the COVID-19 topic as use case. We characterize users engagement on posts in terms of interaction
and how it evolves during time as the pandemic arises. Furthermore, we classified posts into
Questionable and Reliable categories depending on the questionability of the information source.
We investigate users endorsement to both categories in terms of social response and their evolution
over time, focusing on difference and similarities of users behavior. We also exploit a statistical
approach in order to build several hashtag networks divided by source questionability. We analyze
the hashtag networks from a topological perspective and discuss the differences related to source
type. Finally, we consider comments from both categories and study whether the questionability of
the information source influences the distribution of the comments sentiment and the persistence
in commenting of users. Our analysis shows that users prefer less cognitive demanding interactions
such as Likes and they attention respect to questionable and reliable sources changes over time:
initially, Gab users tend to prefer questionable sources but they switch to reliable ones as the
pandemic advances. In terms of hashtag associations through posts, the topological analysis reveals
significant differences between reliable and questionable sources in terms of both structure and
semantic content.
However, the distribution of the sentiment deriving from the analysis of the comments reveals a
rather similar pattern between reliable and questionable sources. Indeed, both distributions show
their peak in correspondence of negative sentiments revealing that the perception of the news
does not depend on the source type. Thus, our results show that the way in which users process
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

Information Consumption and Social Response in a Segregated Environment: the Case of Gab
1:11
information in a segregated environment such as Gab is homogeneous and does not depend on
the source. The unconcern of Gab users with respect to the source in terms of endorsement and
sentiment dynamics seems to provide further evidence for a mechanism of reinforcement that tend
to interpret every news within a collective narrative that is typically found in echo chambers.
REFERENCES
[1] [n.d.]. Gab. https://gab.com/
[2] Abdallah Alsaad, Abdallah Taamneh, and Mohamad Noor Al-Jedaiah. 2018. Does social media increase racist behavior?
An examination of confirmation bias theory. Technology in Society 55 (2018), 41–46.
[3] Atanas Atanasov, Gianmarco De Francisci Morales, and Preslav Nakov. 2019. Predicting the Role of Political Trolls in
Social Media. arXiv preprint arXiv:1910.02001 (2019).
[4] Christopher A Bail, Lisa P Argyle, Taylor W Brown, John P Bumpus, Haohan Chen, MB Fallin Hunzaker, Jaemin Lee,
Marcus Mann, Friedolin Merhout, and Alexander Volfovsky. 2018. Exposure to opposing views on social media can
increase political polarization. Proceedings of the National Academy of Sciences 115, 37 (2018), 9216–9221.
[5] Alessandro Bessi, Mauro Coletto, George Alexandru Davidescu, Antonio Scala, Guido Caldarelli, and Walter Quattrociocchi. 2015. Science vs conspiracy: Collective narratives in the age of misinformation. PloS one 10, 2 (2015),
e0118093.
[6] Alessandro Bessi, Fabiana Zollo, Michela Del Vicario, Antonio Scala, Guido Caldarelli, and Walter Quattrociocchi.
2015. Trend of narratives in the age of misinformation. PloS one 10, 8 (2015).
[7] Alexandre Bovet and Hernán A Makse. 2019. Influence of fake news in Twitter during the 2016 US presidential election.
Nature communications 10, 1 (2019), 1–14.
[8] Alexandre Bovet, Flaviano Morone, and Hernán A Makse. 2018. Validation of Twitter opinion trends with national
polling aggregates: Hillary Clinton vs Donald Trump. Scientific reports 8, 1 (2018), 1–16.
[9] Alex Burns and Ben Eltham. 2009. Twitter free Iran: An evaluation of Twitter’s role in public diplomacy and information
operations in Iran’s 2009 election crisis. (2009).
[10] Peter A Chew and Jessica G Turnley. 2017. Understanding Russian information operations using unsupervised
multilingual topic modeling. In International Conference on Social Computing, Behavioral-Cultural Modeling and
Prediction and Behavior Representation in Modeling and Simulation. Springer, 102–107.
[11] Wen-Ying Sylvia Chou, April Oh, and William MP Klein. 2018. Addressing health-related misinformation on social
media. Jama 320, 23 (2018), 2417–2418.
[12] Matteo Cinelli, Emanuele Brugnoli, Ana Lucia Schmidt, Fabiana Zollo, Walter Quattrociocchi, and Antonio Scala. 2020.
Selective exposure shapes the facebook news diet. PloS one 15, 3 (2020), e0229129.
[13] Matteo Cinelli, Mauro Conti, Livio Finos, Francesco Grisolia, Petra Kralj Novak, Antonio Peruzzi, Maurizio Tesconi,
Fabiana Zollo, and Walter Quattrociocchi. 2019. (Mis) Information Operations: An Integrated Perspective. Journal of
Information Warfare (2019).
[14] Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter Quattrociocchi, and Michele Starnini.
2020. Echo Chambers on Social Media: A comparative analysis. arXiv preprint arXiv:2004.09603 (2020).
[15] Matteo Cinelli, Walter Quattrociocchi, Alessandro Galeazzi, Carlo Michele Valensise, Emanuele Brugnoli, Ana Lucia
Schmidt, Paola Zola, Fabiana Zollo, and Antonio Scala. 2020. The covid-19 social media infodemic. arXiv preprint
arXiv:2003.05004 (2020).
[16] Aaron Clauset, Cosma Rohilla Shalizi, and M. E. J. Newman. 2009. Power-Law Distributions in Empirical Data. SIAM
Rev. 51, 4 (2009), 661–703. https://doi.org/10.1137/070710111 arXiv:https://doi.org/10.1137/070710111
[17] CNN. [n.d.]. Gab, the social network used by the Pittsburgh suspect, has been taken offline. ([n. d.]). https:
//edition.cnn.com/2018/10/29/tech/gab-offline-pittsburgh/index.html
[18] Mauro Conti, Daniele Lain, Riccardo Lazzeretti, Giulio Lovisotto, and Walter Quattrociocchi. 2017. It’s always April
fools’ day!: On the difficulty of social network misinformation classification via propagation features. In 2017 IEEE
Workshop on Information Forensics and Security (WIFS). IEEE, 1–6.
[19] Michela Del Vicario, Alessandro Bessi, Fabiana Zollo, Fabio Petroni, Antonio Scala, Guido Caldarelli,
H. Eugene Stanley, and Walter Quattrociocchi. 2016. The spreading of misinformation online. Proceedings of the National Academy of Sciences 113, 3 (2016), 554–559.
https://doi.org/10.1073/pnas.1517441113
arXiv:https://www.pnas.org/content/113/3/554.full.pdf
[20] Michela Del Vicario, Sabrina Gaito, Walter Quattrociocchi, Matteo Zignani, and Fabiana Zollo. 2017. News consumption
during the Italian referendum: A cross-platform analysis on facebook and twitter. In 2017 IEEE International Conference
on Data Science and Advanced Analytics (DSAA). IEEE, 648–657.
[21] Michela Del Vicario, Gianna Vivaldo, Alessandro Bessi, Fabiana Zollo, Antonio Scala, Guido Caldarelli, and Walter
Quattrociocchi. 2016. Echo chambers: Emotional contagion and group polarization on facebook. Scientific reports 6
, Vol. 1, No. 1, Article 1. Publication date: January 2016.

1:12

Etta et al.

(2016), 37825.
[22] Michela Del Vicario, Fabiana Zollo, Guido Caldarelli, Antonio Scala, and Walter Quattrociocchi. 2017. Mapping social
dynamics on Facebook: The Brexit debate. Social Networks 50 (2017), 6–16.
[23] Emilio Ferrara, Onur Varol, Clayton Davis, Filippo Menczer, and Alessandro Flammini. 2016. The rise of social bots.
Commun. ACM 59, 7 (2016), 96–104.
[24] Colin Gillespie. 2015. Fitting Heavy Tailed Distributions: The poweRlaw Package. Journal of Statistical Software,
Articles 64, 2 (2015), 1–16. https://doi.org/10.18637/jss.v064.i02
[25] Njagi Dennis Gitari, Zhang Zuping, Hanyurwimfura Damien, and Jun Long. 2015. A lexicon-based approach for hate
speech detection. International Journal of Multimedia and Ubiquitous Engineering 10, 4 (2015), 215–230.
[26] Nathaniel Gleicher. 2018. Taking Down More Coordinated Inauthentic Behavior: What Wefive Found So Far. Facebook
Newsroom (2018).
[27] Loni Hagen, Stephen Neely, Thomas E Keller, Ryan Scharf, and Fatima Espinoza Vasquez. 2020. Rise of the Machines?
Examining the Influence of Social Bots on a Political Discussion Network. Social Science Computer Review (2020),
0894439320908190.
[28] Roland Heickerö. 2010. Emerging cyber threats and Russian views on Information warfare and Information operations.
Defence Analysis, Swedish Defence Research Agency (FOI) Stockholm.
[29] Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. Proceedings of the ACM SIGKDD
International Conference on Knowledge (2004).
[30] Haroro J Ingram. 2015. The strategic logic of Islamic State information operations. Australian Journal of International
Affairs 69, 6 (2015), 729–752.
[31] Martinez-Romo J, Araujo L, Borge-Holthoefer J, Arenas A, Capitn Ja, and Cuesta Ja. 2011. Disentangling Categorical
Relationships Through a Graph of Co-Occurrences. Physical review. E, Statistical, nonlinear, and soft matter physics
(Oct. 2011). https://doi.org/10.1103/PhysRevE.84.046108
[32] Sara Levens, Omar ElTayeby, Tiffany Gallicano, Michael Brunswick, and Samira Shaikh. 2020. Using Information
Processing Strategies to Predict Message Level Contagion in Social Media. In Advances in Artificial Intelligence, Software
and Systems Engineering, Tareq Ahram (Ed.). Springer International Publishing, Cham, 3–13.
[33] Lucas Lima, Julio CS Reis, Philipe Melo, Fabricio Murai, Leandro Araujo, Pantelis Vikatos, and Fabricio Benevenuto.
2018. Inside the right-leaning echo chambers: Characterizing gab, an unmoderated social system. In 2018 IEEE/ACM
International Conference on Advances in Social Networks Analysis and Mining (ASONAM). IEEE, 515–522.
[34] CAR MacNulty and JJCH Ryan. 2016. Using Values-Based Cultural Data to Shape Information Operations Strategies.
Journal of Information Warfare 15, 3 (2016), 1–6.
[35] Richard Peto and Julian Peto. 1972. Asymptotically Efficient Rank Invariant Test Procedures. Journal
of the Royal Statistical Society: Series A (General) 135, 2 (1972), 185–198.
https://doi.org/10.2307/2344317
arXiv:https://rss.onlinelibrary.wiley.com/doi/pdf/10.2307/2344317
[36] Ana Lucı́a Schmidt, Fabiana Zollo, Michela Del Vicario, Alessandro Bessi, Antonio Scala, Guido Caldarelli, H Eugene
Stanley, and Walter Quattrociocchi. 2017. Anatomy of news consumption on Facebook. Proceedings of the National
Academy of Sciences 114, 12 (2017), 3035–3039.
[37] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake news detection on social media: A data
mining perspective. ACM SIGKDD Explorations Newsletter 19, 1 (2017), 22–36.
[38] Kate Starbird. 2019. Disinformationfis spread: bots, trolls and all of us. Nature 571, 7766 (2019), 449.
[39] Catherine A Theohary. 2011. Terrorist use of the internet: Information operations in cyberspace. DIANE Publishing.
[40] Michela Del Vicario, Walter Quattrociocchi, Antonio Scala, and Fabiana Zollo. 2019. Polarization and fake news: Early
warning of potential misinformation targets. ACM Transactions on the Web (TWEB) 13, 2 (2019), 1–22.
[41] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science 359, 6380 (2018),
1146–1151.
[42] Jeremy Waldron. 2012. The harm in hate speech. Harvard University Press.
[43] Edward Waltz. 1998. Information warfare: Principles and operations. Artech House Boston.
[44] Claire Wardle and Hossein Derakhshan. 2017. Information disorder: Toward an interdisciplinary framework for
research and policy making. Council of Europe report 27 (2017).
[45] Savvas Zannettou, Barry Bradlyn, Emiliano De Cristofaro, Haewoon Kwak, Michael Sirivianos, Gianluca Stringini,
and Jeremy Blackburn. 2018. What is Gab. Companion of the The Web Conference 2018 on The Web Conference 2018 WWW fi18 (2018). https://doi.org/10.1145/3184558.3191531
[46] Fabiana Zollo, Alessandro Bessi, Michela Del Vicario, Antonio Scala, Guido Caldarelli, Louis Shekhtman, Shlomo
Havlin, and Walter Quattrociocchi. 2017. Debunking in a world of tribes. PloS one 12, 7 (2017).

, Vol. 1, No. 1, Article 1. Publication date: January 2016.

