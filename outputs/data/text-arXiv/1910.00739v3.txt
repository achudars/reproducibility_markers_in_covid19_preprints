The OpenUAV Swarm Simulation Testbed: a Collaborative Design
Studio for Field Robotics

arXiv:1910.00739v3 [cs.RO] 2 Nov 2020

Harish Anand, Stephen A. Rees, Ashwin Jose, Sarah Bearman, Zhiang Chen,
Prasad Antervedi, Jnaneshwar Das
Abstract— Simulations play a crucial role in robotics research
and education. This paper presents the OpenUAV testbed, an
open-source, easy-to-use, web-based, and reproducible software
system that enables students and researchers to run robotic
simulations on the cloud. The key contributions of the paper
are threefold. First, OpenUAV saves students and researchers
from tedious and complicated software setup by providing webbrowser based Linux desktop sessions with robotics software
like Gazebo, ROS, PX4 vehicles, ground control software, and
swarm simulation capabilities. Second, a containerized desktop
session provides the necessary means to save an individual’s
research work with its dependencies for future reproducibility
of the work. Third, the platform provides a mechanism to
support photorealistic robotics simulations by combining Unity
game engine based camera rendering and Gazebo physics. The
paper describes a methodology for creating such a photorealistic
aquatic simulation for autonomous underwater vehicles. We
also present the various academic and research use-cases of
this platform to improve robotics education and research,
especially during times like the COVID-19 pandemic, when
virtual collaboration is necessary.
GitHub: https://github.com/Open-UAV/openuav-turbovnc
Webpage: https://openuav.us

I. I NTRODUCTION
The increasing shift in computing power to cloud-based
services is already evident in the gaming industry (Google
Stadia services), entertainment industry (streaming services),
and workplace communication platforms (Slack and Zoom
services) [1]. This push is especially relevant in our current
challenging times, such as the COVID-19 pandemic, where
remote work and virtual collaborations are necessary for field
robot experiments.
Robotics is one of those challenging fields where there is
always an interplay between hardware and software development. In addition to getting all the hardware components to
function together correctly, the software also faces challenging software setup and various task-specific configurations.
These software setup challenges increase tremendously when
many students and researchers engage in robotics software
development using their computers, which typically have
different operating systems and software versions. Hence we
designed a cloud-based solution that provides researchers and
students with an easy-to-use, reproducible, and web browserbased robotics simulation that can easily offer a collaborative
software development experience.
*This work was supported by NSF award CNS-1521617
Authors are with the School of Earth and Space Exploration, Tempe,
Arizona hanand4,aporuthu,sbearman,zchen256,lanterve,jdas5@asu.edu and
Stephen is a staff at Vanderbilt University, Nashville, Tennessee
stephen.a.rees@vanderbilt.edu

There is a growing demand for Unmanned Aircraft Systems (UAS) based imaging technology to provide highresolution spatial imaging for science applications [2, 3].
For example, UAS-based imaging technology is used in
geology to generate orthomosaic maps of fault scarp regions
to understand the influence of geomorphological surface
processes [4]. Applications such as autonomous outdoor
mapping, environmental monitoring, and disaster response
would benefit significantly from a photorealistic simulation
platform that can simulate environments like volcanic plumes
and coral reefs. Hence OpenUAV supports Unity game
engine, an easy-to-use, photorealistic rendering software that
can be configured to render various lighting, shadows, and
texture characteristics on objects.
The purpose of the earlier version of OpenUAV (referred
to as OpenUAV1) was to reduce the number of field trials
and crashes of UAS by implementing a simulation environment that allowed extensive testing and mission synthesis
of aerial vehicles [5]. This paper describes improvements
to OpenUAV1 by enabling researchers and students with
a web browser-based remote desktop environment, which
also supports Unity based photorealistic rendering for outdoor field experiment simulations. The current platform also
supports ground control software like QGroundControl for
controlling PX4’s aerial, underwater and ground vehicles [6,
7]. A comparison of OpenUAV1 and the latest OpenUAV
platform is given in TABLE 1.
We also present the NSF CPS Challenge 2020, a virtual
competition conducted in the OpenUAV platform that had
teams from different parts of the world compete on solving
challenges involving a heterogeneous team of PX4 vehicles.
We found that our web browser-based simulation platform
provided an easy alternative to the outdoor competition, as it
provided every team with access to GPU resources and ample
computing power. Three examples of OpenUAV simulations
accessed through a web browser are shown in Fig. 1.
II. R ELATED W ORK
Various robotic simulation packages exist for PX4 vehicle
simulations, and we take a look at some of those works that
also achieve photorealism and cloud simulation capabilities.
The following are some examples.
A. AirSim
AirSim is an open-source, cross-platform simulator built
on Unreal Engine 4 (UE4) that offers similar photorealistic simulations for drones and cars [10]. AirSim’s PX4

Fig. 1: A multi-UAS simulation controlled using QGroundControl is shown on the left panel. In the center panel, an
underwater coral reef world and an underwater vehicle is present. The right panel shows with RTAB-Map running on a PX4
Heron boat [8, 9].

Software-in-the-loop (SITL) module supports only drones
and cars. Like AirSim’s usage of UE4 to render photorealistic
scenes, we use Unity to create photorealistic environments.
In OpenUAV’s photorealistic simulations, Unity game objects are created using the robot models described in Unified
Robot Description Format (URDF) or Software Definition
Format (SDF) format.
B. FlightGoggles
FlightGoggles is a simulator that renders a virtual-reality
environment for aerial vehicles [11]. In FlightGoggles, the
sensor measurements are artificially rendered in real-time
while the vehicle vibrations and unsteady aerodynamics are
from the vehicle’s natural interactions. This is an exceptional
advantage of the FlightGoggles framework, where a combination of real physics with the Unity-based rendering of the
camera’s environment occurs. Photorealistic OpenUAV simulations use Unity to render the cameras, which is inspired
by the FlightGoggles approach.
C. The Construct Sim
The Construct Sim is an online robotics teaching platform
that provides web-based access to robotics simulators like
Gazebo with the Robot Operating System (ROS) support
[12]. They utilize Gzweb, a WebGL client for Gazebo,
for developing simulations. Some of the disadvantages we
identified while using Gzweb in OpenUAV1 include the lack
of an Integrated Development Environment (IDE) for programming and development, reduced capabilities compared
to gzclient, and lack of support for file transfer. Our goals
are similar to the Construct Sim, where we want to provide
robotics students with an online, easily accessible simulation
platform without getting bogged down by software configuration issues.
III. D ESIGN G OALS
As a remotely accessible, open-source simulation platform, OpenUAV’s main purpose has been to lower the
barrier to entry in research and development of autonomous
vehicles. To this end, we aim to satisfy the following
requirements:
• Easy-to-use: Provide students and researchers with a
remote desktop consisting of necessary robotics and

Tools
Visualization
Ground Control Support
Photorealism
Integrated Development
Environment
Remote
file sharing

OpenUAV1 [5]
Gzweb, Django
No
No

OpenUAV latest
NoVNC, TurboVNC
QgroundControl
Unity

No

Pycharm, Sublime

No

SSHFS support

TABLE I: Comparison of OpenUAV1 and the latest OpenUAV version.

programming software to simulate autonomous vehicles.
• Reproducible: Develop the capability to store student
and research work as compressed files to be used in the
future to recreate the same experiment.
• Web-based: Provide remote desktop sessions accessible
through web browsers to limit students’ local machine
requirements to a bare minimum.
• Photorealistic: Provide photorealistic outdoor environments for field robotic simulations.
Through the academic and research use cases, we found
further requirements such as daily backups of the student and
research work, replicating compute and memory constraints
comparable to typical PX4 vehicles in the simulation containers.
IV. S YSTEM D ESIGN
We classify the software components into three categories:
simulation components, virtualization components, and interactive components. This updated system design was inspired
by the works of Will Kessler and the Udacity team [13].
An overview of the latest OpenUAV simulation container is
shown in Fig. 2.
A. Simulation Components
Simulation has become a necessity to solve real world
problems in a safe and efficient manner. The software packages that enable simulation in OpenUAV are the following:
1) Gazebo and ROS: Gazebo is an open-source robotics
software used to design robots and environments and perform
realistic rigid body dynamic simulations [14]. The Robot
Operating System is a robotics message passing framework
designed to simplify programming for robots [15]. ROS

Fig. 2: Components of an OpenUAV container: The simulation components include Gazebo, Unity, ROS, PX4, and
QGroundControl. The user-interactive components consist of
NoVNC, TurboVNC, and SSH/SSHFS. NoVNC and SSHFS
are accessible on the OpenUAV’s machine using the container’s IP address with ports 40001 and 22.

and Gazebo enable students to take advantage of various
community-developed packages while learning robotics and
writing algorithms.
2) PX4 and QGroundControl: PX4 is an open-source
flight control software that supports aerial, ground, and
sea vehicles. It provides capabilities like state estimators,
software-in-the-loop simulations, sensor support, position,
velocity, and rate controllers. QGroundControl is a remote
flight monitoring and planning software, that communicates with any MavLINK enabled vehicle. Accessibility to
QGroundControl inside the OpenUAV allows students to run
simulations closer to how they would operate PX4 vehicles
in a field experiment.
3) Unity Game Engine and ROS-Sharp: Unity is a crossplatform game engine developed primarily for the creation of
2D, 3D, and virtual reality games [16]. We can render photorealistic scenes in Unity using its High Definition Rendering
Pipeline (HDRP), which includes advanced features like the
physically-based sky, subsurface scattering, and translucent
materials.
Unity provides a mechanism to test the field experiment
code written in the ROS-Gazebo framework in photorealistic
outdoor scenes. The cameras are rendered using the Unity
scene while still maintaining the physics from Gazebo. We
achieve this by replicating all the Gazebo robot models’ pose
as their corresponding pose in Unity and disabling Unity’s
physics and collisions for those models.
We use ROS-Sharp’s web socket based communication to
send pose and camera messages between Gazebo and Unity
[17]. The ROS-Sharp package also reads URDF and SDF
robot models into Unity as game objects. In Fig. 3, we
show the front and down camera view from the autonomous
underwater vehicle (AUV) using ROS image viewer and the
rendering of an underwater coral reef environment in Unity.

Fig. 3: Unity rendering of an underwater environment in
OpenUAV: The top image shows the rendering of underwater
coral reefs from the front and down cameras of an AUV. The
bottom image shows Unity updating the kinematics of the
AUV game object as per the Gazebo model states.

B. Virtualization Components
In OpenUAV, we have operating system level virtualization
to deliver software as packages called containers [18].
1) Docker: Container technology has become the preferred means of packaging and deploying applications.
Docker orchestration tool provides a necessary mechanism
to package the software, its libraries, and its dependencies
into a single container.
All OpenUAV containers have a shared network namespace and a common Xorg server with access to GPUs for
doing 3D renderings (GLX calls). Another advantage of
containers is the ability to configure resources allocated to
each container. These restrictions are useful for replicating
actual vehicle compute power in the simulation containers by
having similar memory constraints and compute capacity.
2) NGINX: Nginx is a web server that is used widely as
a reverse proxy and load balancer [19]. OpenUAV utilizes
Nginx as a reverse proxy to create multiple remote desktop sessions. Nginx also acts as a TCP streaming proxy
(ngx stream core module) for the SSH service inside the
container. However, we expose TCP streaming ports as per
user requirements on the OpenUAV server since it takes up
a dedicated port on the server machine.

Fig. 4: Nginx HTTP proxy and stream modules are used to proxy multiple HTTP sessions and SSH sessions to outside
users, respectively. A Domain Name System (DNS) resolver resolves the URL prefix cpsvo-<uniqueID> name to its
corresponding Docker network IP address. Web interface displays a Lubuntu desktop through NoVNC, and applications like
Unity and Gazebo are accessed through this interface.

Each user session is created using an OpenUAV container
with the name format as cpsvo-<uniqueID>, where
uniqueID is generated using a Universally Unique IDentifier
(UUID) function. The URL to access the Lubuntu desktop of this container is as follows cpsvo-<uniqueID>
.openuav.us. We achieve access to containers without
utilizing Docker’s port forwarding by having a DNS resolver
that maps each OpenUAV container name to its corresponding Docker network IP address. The DNS-based approach
results in reduced port management on the server machine.
Fig. 4 shows how each of these components interact with
each other.
C. Interactive Components
Here we describe the software components that enable
users to interact with the simulations running in containers.
Some of these technologies are used in remote computing
and High-Performance Computing (HPC) simulation services [20].
1) TurboVNC and VirtualGL: When used with VirtualGL,
TurboVNC provides a high performing and robust solution
for displaying 3D applications over different types of networks [21, 22]. TurboVNC’s JPEG compression algorithm
provides fast rendering of the Lubuntu desktop session to
any of the connected viewers [23]. The container applications
have access to a shared Xorg server, which renders the 2D
X commands and events.

VirtualGL enables the redirection of the OpenGL 3D
rendering commands (GLX calls) made by applications like
Gazebo or Unity to a 3D Xorg server with an attached GPU,
and the generated 2D framebuffer image gets displayed on
the TurboVNC virtual display.
2) NoVNC: NoVNC is a JavaScript-based Virtual Network Computing (VNC) application that provides access to
VNC sessions over the web browser [24]. NoVNC follows
the standard VNC protocol and has support for persistent
connection through WebSockets. The containers use the
NoVNC client to connect with the TurboVNC server. Nginx
proxies the NoVNC web interface of each container to the
users.
3) Secure Shell FileSystem (SSHFS): Secure Shell
FileSystem allows users to mount a remote file system using
the Secure Shell File Transfer Protocol (SFTP) [25]. Through
SSHFS, the OpenUAV allows users to utilize their local IDE
for code development.
V. U SE C ASES
A. Cyber-Physical Systems Virtual Organization
Cyber-Physical Systems Virtual Organization (CPS-VO)
is a collaboration among CPS professionals in academia,
government, and industry [26]. OpenUAV was integrated
as part of CPS-VO to facilitate students and researchers
from various institutions to use this robotics platform. CPSVO provides authentication and authorization for each user’s

Containers created

15

10

5

27
.0
9.
20
20

28
.0
8.
20
20

29
.0
7.
20
20

29
.0
6.
20
20

30
.0
5.
20
20

30
.0
4.
20
20

31
.0
3.
20
20

01
.0
3.
20
20

31
.0
1.
20
20

01
.0

1.
20
20

0

NSF CPS Challenge 2020 SES 494/598 SES 230 General Research Use
Fig. 5: OpenUAV containers created through CPS-VO from January 2020 to September 2020. X-axis represents the time
period from January 2020 to September 2020 and y-axis represents the number of containers students and researchers created
on each day. Students and researchers created a total of 136, 107, 46 and 56 containers during SES 494/598 course, NSF
CPS Challenge 2020, SES 230 course and for general research uses respectively.

Fig. 6: Demonstration of phase 2 implementation by a team
from ASU during NSF CPS Challenge 2020 in OpenUAV
platform [27].

simulations. To maintain a judicious usage of CPU and GPU
resources on the OpenUAV server, the CPS-VO lets students
suspend a simulation and resume back from the saved
simulation. Suspend and resume functionalities in CPS-VO
are implemented using Docker’s pause and unpause feature.
Students and researchers created a total of 345 containers
through CPS-VO from January 2020 to September 2020.
1) Educational Applications: A workflow was developed
where 35 students taking part in a field robotics course (SES
494/598 Autonomous Exploration Systems) at Arizona State
University (ASU) would register and have authorized access
to the OpenUAV platform [28, 29]. Simulations contained
software like Gazebo, ROS, PX4, and QGroundControl
configured correctly. We further added support for Python
IDE (PyCharm), text editors (Sublime Text 2), and Google
Chrome inside every session to improve students’ ease of
use.

The SES 494/598 data points in Fig. 5 represent the
136 containers created between January 14, 2020, and April
30, 2020, when the COVID-19 pandemic affected courses.
Most of these containers were created for robotics educational purposes during lecture hours and student assignment
submissions. We also find more active student engagement
during March 8-15, 2020, where course project discussions
began [28].
Through the coursework, we learned that the students
needed daily backups to avoid data loss. Utilizing Docker’s
commit feature, we saved students’ work every night as
Docker images. Additionally, the workflow from the CPSVO was modified to reduce accidental termination of sessions
and encouraged the use of the suspend and resume feature.
At the end of the coursework, we kept students work as
compressed files, which provided a necessary means to
reproduce their work in the future. A survey conducted at
the end of the course found 87.5% of the students were
satisfied with the overall experience of OpenUAV during the
pandemic, while others raised concerns regarding browsers
inside the container crashing when there were multiple tabs
opened.
An introduction to the python programming course (SES
230 Coding for Exploration) also utilized this platform for
programming and data science education [30]. We created
a Docker image specific for these students that contained
basic python programming environments and removed GPU
and VirtualGL components.
2) NSF CPS Challenge 2020: NSF CPS Challenge is a
yearly outdoor competition held at TIMPA Airfield, Arizona
[31, 30]. This year’s competition was made completely
virtual as it happened during the COVID-19 pandemic period. The NSF CPS Challenge 2020 focused on a Mars
2020 theme Perseverance and Ingenuity rover and drone

Fig. 7: The Unity photorealistic rendering of the AUV following the ASV is shown on the left panel. An RVIZ window
containing the AUV and ASV pose, along with the fiducial marker detections, is shown on the center panel. The right panel
shows the front camera view of the coral reef environment. The coral reef model belongs to Dr. John Burns, Multiscale
Environmental Graphical Analysis (MEGA) Lab at the University of Hawai‘i, Hilo.

duo [32]. Teams from universities worldwide would have
to simulate an autonomous science probe deployment and
recovery mission involving a heterogeneous team of a rover
and drone at the Jezero crater landing site.
During phase 1 of the competition, the teams wrote code
for probe deployment from a drone at a particular location,
and phase 2 had the teams recover these probes using a
drone and land on a moving rover. Fig. 6 shows the phase 2
implementation from one of the competition teams.
An easy-to-use, competition-specific Docker image was
created containing the Jezero crater model, PX4 vehicles,
sensor probe, and sample codes. We saved each teams
containers as compressed files for the reproducibility of their
submissions. The web-based architecture enabled students
from universities in India and Argentina to simulate various environments without powerful local compute machine
requirements. Further details regarding the competition and
each teams’ implementation code can be found here [31].
B. Research Applications
1) Photorealistic underwater coral reef environment:
A thesis on coordinated navigation and localization of an
AUV following an autonomous surface vehicle (ASV) was
presented using the OpenUAV framework [33]. An aquatic
environment was created using the Crest ocean rendering
implementation in Unity’s HDRP pipeline to address the
underwater perception challenges like light attenuation, scattering, reflections, and reef caustics [34].
For photorealistic rendering in Crest, the water texture
and material characteristics are adjusted to be more realistic by comparing it with actual underwater photos. The
coordinated localization module for an AUV is implemented
by attaching a fiducial marker of known dimensions to the
ASV’s underside. The upward-facing Unity camera attached
to the AUV game object captures the fiducial marker images.
The two major concerns when following this approach are
maintaining a metric scale for all Unity game objects and
calibrating the Unity cameras to create camera information
ROS topics. The ground truth AUV and ASV model pose
published by Gazebo were accessed to update their corresponding pose in the Unity environment using ROS-Sharp.
The Unity camera images are published through ROS-Sharp,

and the controller code used these images to follow the ASV.
The Unmanned Underwater Simulation (UUVSim) plugin
in Gazebo provided the underwater physics for the AUV
and ASV while the camera rendering was enhanced through
Unity support. Fig. 7 shows the photorealistic simulated
environment accessed through browsers. Further implementation details on the localization module, state estimator, and
coordinated navigation controller for AUV-ASV simulation
can be found in the thesis [33].
Through Unity, we can provide users with an easy-to-use
scene builder, material, and texture editor to develop complex
outdoor environments. It also supports Quixel Megascans, an
extensive library of worldwide photogrammetry and material
assets, which are valuable to researchers for creating realistic
outdoor environments [35].
2) Data Science: TagLab is an interactive AI-assisted
image annotation tool for semantic segmentation of coral reef
orthomosaics [36]. The AI-assisted annotation predictions
require TagLab software to have access to a GPU machine.
OpenUAV containers’ native support for GPU libraries converted the TagLab software as an online accessible annotation
tool. OpenUAV Docker images with TagLab were replicated
for multiple users, who used it to annotate different coral
reef species. The online accessibility meant that the users
can remotely annotate images on their laptops, which became
an immediate requirement during the pandemic. These data
science research needs showcase the versatile and easy-touse nature of the OpenUAV platform.
VI. C ONCLUSION
This paper presented OpenUAV as an easy-to-use, reproducible, and online platform for robotics simulations
in educational and research goals. The platform protects
its users from the time-consuming and complex software
setup by providing a containerized simulation that is also
reproducible. Through OpenUAV, the competed teams in the
NSF CPS Challenge designed and implemented controllers
for a heterogeneous team of PX4 vehicles in their field
robotics simulations. We presented various academic and
research use-cases of the OpenUAV platform and described
a method to do photorealistic simulations inside OpenUAV.

ACKNOWLEDGMENT
This work was supported in part by the National Science
Foundation award CNS-1521617. We would also like to
acknowledge the contributions and suggestions made by
students and researchers who participated in the SES 494/598
course, SES 230 course, NSF CPS Challenge, and CPS-VO
users. We also like to thank Dr. Roberta Martin, Associate
Professor, ASU Center for Global Discovery and Conservation Science, and Dr. John Burns, Assistant Professor, the
University of Hawai‘i at Hilo.
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

R EFERENCES
Google. Stadia: a new way to play. URL: https://
blog.google/products/stadia/stadiaa-new-way-to-play/ (visited on 10/28/2020).
Philipp Lottes et al. “UAV-based crop and weed
classification for smart farming”. In: 2017 IEEE International Conference on Robotics and Automation
(ICRA). IEEE. 2017, pp. 3024–3031.
Nassim Ammour et al. “Deep learning approach for
car detection in UAV imagery”. In: Remote Sensing
9.4 (2017), p. 312.
Zhiang Chen et al. “Geomorphological Analysis
Using Unpiloted Aircraft Systems, Structure from
Motion, and Deep Learning”. In: arXiv preprint
arXiv:1909.12874 (2019).
Matt Schmittle et al. “Openuav: A UAV testbed for the
CPS and robotics community”. In: 2018 ACM/IEEE
9th International Conference on Cyber-Physical Systems (ICCPS). IEEE. 2018, pp. 130–139.
Lorenz Meier, Dominik Honegger, and Marc Pollefeys. “PX4: A node-based multithreaded open source
robotics framework for deeply embedded platforms”.
In: 2015 IEEE international conference on robotics
and automation (ICRA). IEEE. 2015, pp. 6235–6240.
E Zurich. Qgroundcontrol: Ground control station for
small air land water autonomous unmanned systems.
2013. URL: http://qgroundcontrol.com.
Mathieu Labbé and François Michaud. “RTAB-Map as
an open-source lidar and visual simultaneous localization and mapping library for large-scale and long-term
online operation”. In: Journal of Field Robotics 36.2
(2019), pp. 416–446.
Jnaneshwar Das Sarah Bearman. RTABMap SLAM
with PX4 Heron boat in mock lake world with Tempe
Town lake coordinates. URL: https : / / www .
youtube.com/watch?v=u6Me2CHvLUg (visited
on 10/28/2020).
Shital Shah et al. “Airsim: High-fidelity visual and
physical simulation for autonomous vehicles”. In:
Field and service robotics. Springer. 2018, pp. 621–
635.
Winter Guerra et al. “FlightGoggles: Photorealistic
Sensor Simulation for Perception-driven Robotics using Photogrammetry and Virtual Reality”. In: arXiv
preprint arXiv:1905.11377 (2019).

[12]

[13]

[14]

[15]

[16]
[17]
[18]

[19]

[20]

[21]

[22]

[23]

[24]
[25]
[26]

[27]

[28]

Ricardo Tellez. “A thousand robots for each student:
Using cloud robot simulations to teach robotics”. In:
Robotics in Education. Springer, 2017, pp. 143–155.
Will Kessler. Building a GPU-enhanced Lubuntu
Desktop with nvidia-docker2. 2018. URL: https :
/ / github . com / willkessler / nvidia docker-novnc.
Nathan Koenig and Andrew Howard. “Design and
use paradigms for Gazebo, an open-source multi-robot
simulator”. In: 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE
Cat. No. 04CH37566). Vol. 3. IEEE. 2004, pp. 2149–
2154.
Morgan Quigley et al. “ROS: an open-source Robot
Operating System”. In: ICRA workshop on open
source software. Vol. 3. 3.2. Kobe, Japan. 2009, p. 5.
Unity Game Engine. 20202. URL: https : / /
unity.com/.
M Bischoff. Ros sharp. 2017.
Carl Boettiger. “An introduction to Docker for reproducible research”. In: ACM SIGOPS Operating
Systems Review 49.1 (2015), pp. 71–79.
Will Reese. “Nginx: the high-performance web server
and reverse proxy”. In: Linux Journal 2008.173
(2008), p. 2.
Karin Meier-Fleischer, Niklas Röber, and Michael
Böttinger. “Visualization in a Climate Computing
Centre”. In: EGU General Assembly Conference Abstracts. Vol. 16. 2014.
University of Cambridge. Connecting to CSD3 via
TurboVNC. URL: https://docs.hpc.cam.ac.
uk/hpc/user-guide/turbovnc.html (visited
on 09/14/2019).
Lien Deboosere et al. “Thin client computing solutions
in low-and high-motion scenarios”. In: International
Conference on Networking and Services (ICNS’07).
IEEE. 2007, pp. 38–38.
Quang Thai Ngo et al. “A remote display QoE
improvement scheme for interactive applications in
low network bandwidth environment”. In: Multimedia
Tools and Applications 76.21 (2017), pp. 22217–
22241.
Joel Martin et al. noVNC: HTML5 VNC Client. 2015.
URL : https://novnc.com/info.html.
Matthew E Hoskins. “Sshfs: super easy file access
over ssh”. In: Linux Journal 2006.146 (2006), p. 4.
Cyber-Physical Systems Virtual Organization. CyberPhysical Systems Virtual Organization. URL: https:
//cps-vo.org.
Darwin Mick Swastik Nandan and Rehan Guha. CPS
2020 Phase 2 - Attempt 3. URL: https://www.
youtube.com/watch?v=z6wtisuocoM (visited
on 10/28/2020).
Jnaneshwar Das. SES 494/598 Course. URL: https:
/ / web . asu . edu / sites / default / files /
jdas / files / 2020 _ ses _ 494 _ 598 _

[29]

[30]

[31]

[32]

[33]

[34]
[35]

[36]

autonomous _ exploration _ systems _ v4_ _sheet1.pdf (visited on 10/28/2020).
Ashwin Jose Poruthukaran. OpenUAV webpage. URL:
https : / / openuav . us / #cpsvo (visited on
10/28/2020).
CPS-VO. ASU SES 230 Coding for Exploration
Course. URL: https://cps- vo.org/group/
SES230 (visited on 10/28/2020).
CPS-VO. 2020 NSF Student CPS Challenge. URL:
https : / / cps - vo . org / group /
CPSchallenge (visited on 10/28/2020).
NASA. Mars 2020 Perseverance Rover. URL:
https://mars.nasa.gov/mars2020/ (visited
on 10/28/2020).
Harish Anand. “Coordinated Navigation and Localization of an Autonomous Underwater Vehicle Using
an Autonomous Surface Vehicle in the OpenUAV
Simulation Framework”. MS thesis. 2020, p. 61. ISBN:
9798664758115. URL: https : / / download .
openuas.us/Thesis.pdf.
Huw Bowles et al. “Crest: Novel Ocean Rendering
Techniques in an Open Source Framework”. In: 2017.
Galen Davis. “Quixel’s rebirth: megascans environment breakdown”. In: ACM SIGGRAPH 2019 RealTime Live! 2019, pp. 1–1.
Gaia Pavoni, Massimiliano Corsini, and Paolo
Cignoni. “A state of the art technology in large scale
underwater monitoring”. In: ERCIM News 2020.121
(2020).

