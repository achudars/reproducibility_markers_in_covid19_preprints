This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to
final publication. Citation information: M. Ahishali et al., "Advance Warning Methodologies for COVID-19 Using Chest X-Ray Images," in
IEEE Access, vol. 9, pp. 41052-41065, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3064927

Advance Warning Methodologies for
COVID-19 using Chest X-Ray Images
arXiv:2006.05332v6 [eess.IV] 18 Mar 2021

METE AHISHALI1 , AYSEN DEGERLI1 , MEHMET YAMAC1 , SERKAN KIRANYAZ2 , (Senior
Member, IEEE), MUHAMMAD E. H. CHOWDHURY2 , (Senior Member, IEEE), KHALID
HAMEED3 , TAHIR HAMID4, 5 , RASHID MAZHAR4 , MONCEF GABBOUJ1 , (Fellow, IEEE).
1

Faculty of Information Technology and Communication Sciences, Tampere University, 33720 Tampere, Finland (email: name.surname@tuni.fi)
Department of Electrical Engineering, Qatar University, 2713 Doha, Qatar (email: mkiranyaz@qu.edu.qa and mchowdhury@qu.edu.qa)
Reem Medical Center, Doha, Qatar (email: dr.khalid@reemmedicalcenter.com)
4
Hamad Medical Corporation Hospital, Doha, Qatar
5
Weill Cornell Medicine - Qatar, Doha, Qatar
2
3

Corresponding author: Mete Ahishali (e-mail: mete.ahishali@tuni.fi).
This work was supported by the Academy of Finland’s project AWcHA, Dn 334566.

ABSTRACT Coronavirus disease 2019 (COVID-19) has rapidly become a global health concern after its
first known detection in December 2019. As a result, accurate and reliable advance warning system for the
early diagnosis of COVID-19 has now become a priority. The detection of COVID-19 in early stages is not
a straightforward task from chest X-ray images according to expert medical doctors because the traces of
the infection are visible only when the disease has progressed to a moderate or severe stage. In this study,
our first aim is to evaluate the ability of recent state-of-the-art Machine Learning techniques for the early
detection of COVID-19 from chest X-ray images. Both compact classifiers and deep learning approaches
are considered in this study. Furthermore, we propose a recent compact classifier, Convolutional Support
Estimator Network (CSEN) approach for this purpose since it is well-suited for a scarce-data classification
task. Finally, this study introduces a new benchmark dataset called Early-QaTa-COV19a , which consists of
1065 early-stage COVID-19 pneumonia samples (very limited or no infection signs) labelled by the medical
doctors and 12 544 samples for control (normal) class. A detailed set of experiments shows that the CSEN
achieves the top (over 97%) sensitivity with over 95.5% specificity b . Moreover, DenseNet-121 network
produces the leading performance among other deep networks with 95% sensitivity and 99.74% specificity.
a The
b The

Early-QaTa-COV19 dataset is publicly shared at the repository https://www.kaggle.com/aysendegerli/qatacov19-dataset.
software implementations of the methods are available at https://github.com/meteahishali/methods-early-cov19.

INDEX TERMS COVID-19 Detection in Early Stages, Deep Learning, Machine Learning, Representation
based Classification.

I. INTRODUCTION

ORONAVIRUS disease 2019 (COVID-19) caused
by severe acute respiratory syndrome coronavirus-2
(SARS-CoV-2) has declared as pandemic by the World
Health Organization (WHO) on the 11th of March, 2020.
Although, infected patients tend to have mild and unspecific
symptoms [1] such as fever, myalgia or fatigue, and cough,
the disease affects seriously people in high-risk groups especially the elderly. Up to now, COVID-19 has caused more
than one-million fatalities.
There have been different detection methods for COVID19. In clinics, reverse transcription polymerase chain reaction

C

VOLUME 9, 2021

(RT-PCR) has been used and it holds the reference method
[1] for COVID-19 detection. It is also recommended by
WHO that a rapid collection of suitable specimens from
suspect cases should be made with RT-PCR like nucleic acid
amplification tests [2] and implies the vital role of RT-PCR to
prevent spreading of the disease. However, RT-PCR is known
to have a low sensitivity, and it is reported in [3] that RT-PCR
has around 30−60% total positive rate for throat samples, and
low positive rates occur especially in mild cases. To this end,
there are studies [4]–[6] that investigate the usage of ChestCTs and correlation between Chest-CT and RT-PCR tests as
diagnostic tools. It is stated in [4] that Chest-CT scans have
1

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

FIGURE 1. (first row) Samples of COVID-19 pneumonia with very limited or no visible sign of COVID-19, and (second row) normal (healthy) class from
Early-QaTa-COV19 dataset.

positive findings for 75% of negative RT-PCR samples, and
[5] suggests to repeat swap testing for the cases where CT
scans have suspicious finding even though RT-PCR results
are negative. Finally, [6] calculates the sensitivities of ChestCT and RT-PCR as 98 and 71%, respectively.
Although the above-mentioned studies propose to use
Chest-CT scans in epicenters rather than RT-PCR to detect
COVID-19 where RT-PCR has a low sensitivity for mild
cases, there are several limitations of CT scans such as the
time for image acquisition, the associated cost, and availability of CT devices. On the other hand, X-ray imaging is a
highly available and faster diagnostic tool. Unlike CTs, Xray imaging is also cheaper, and patients are less harmed
from radiation [7] during the acquisition process. Another
advantage is that there are portable X-ray devices, and hence,
as stated in [8], X-ray can reduce the risk of contamination
compared to CT for suspects where the person can spread the
disease in the transport route. Overall, chest X-ray images
can be an alternative for COVID-19 detection with other
diagnosis tools (for example, RT-PCR) especially in heavily
affected areas where the detection delay is critical and the
resources are limited.
The outbreak has brought the urgent need for an automated, accurate, and robust COVID-19 detection/recognition
system that can guide the practitioner to diagnose suspects
especially in early stages. For example, many countries suffer
from incorrect statistics because of the time-consuming part
of the manual diagnostic tools [9]. Although, there are existing studies for COVID-19 recognition using Chest-CT scans
such as [10], several studies [9], [11]–[14] propose to use Xray images for automated COVID-19 recognition because of
the aforementioned advantages of X-ray imaging. A detailed
survey study in [15] reviews COVID-19 detection approaches
using chest X-ray images and Chest-CT scans. Nevertheless,
all of them except [14] have been experimented over only
a small amount of data, e.g., the largest one includes only
a few hundreds of X-ray images with only few COVID-19
2

samples. To address this need, in an earlier study [14], we
have compiled QaTa-COV19 dataset with 462 chest X-ray
images from COVID-19 patients. Then, COVID-19 samples
are further populated to 2951 images in [16] with their
corresponding ground-truth segmentation masks indicating
the infected regions on the lungs.
As stated in [1], [4], early detection plays a vital role to
prevent spreading the disease by detecting infected people,
isolating them, starting the treatment, and preventing possible
secondary infections on the same patient. In this study, the
"early" term in the detection task is used in the following
sense: the selected COVID-19 chest X-ray images do not
have any Pneumonic changes on the lungs or they have very
limited signs that can easily be misinterpreted by the medical
doctors (MDs). Consequently, the early stage is not measured by the time, but rather with visibility of the infection
traces. On one hand, COVID-19 detection from chest Xray images is a straightforward task when it is already in
late-stage and the patient’s X-ray shows moderate or severe
signs of infection; hence, it is well-studied in the literature.
However, there is a lack of research on the automated early
detection of COVID-19 using X-ray images. This can be
due to the following reasons: during the early stage, the
detection can be difficult or perhaps not feasible at all even
for an expert MD using X-ray images. For example, in many
studies [1], [8], [17], it is stated that chest X-ray images are
not sensitive compared to CT scans for the early detection
where the symptoms are mild, and they further claim that
there can be traces of the infection that can only be detected
by MDs in severe patients. Therefore, in this study, our
first aim is to investigate state-of-the-art Machine Learning
(ML) approaches for their usability in advance warning for
COVID-19 using chest X-ray images. To accomplish this
objective, we have first compiled a new benchmark dataset
called Early-QaTa-COV19, which is formed from QaTaCOV19 with some additional images. For this purpose, Xray images from the COVID-19 patients who are in the early
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

stages of the disease are selected by a group of MDs. As some
of them shown in Fig. 1, these samples have limited or no
visible sign of COVID-19 pneumonia observed by the human
eye. Accordingly, the Early-QaTa-COV19 dataset consists
of 1065 COVID-19 samples (801 and 264 images with no
and limited infection signs, respectively) and 12544 samples
from the control (normal) class. Early-QaTa-COV19 dataset
has several unique properties: the first and foremost, it is
extracted from the largest benchmark dataset, QaTa-COV19,
ever formed in the World and further populated with new Xray images. Next, the dataset is the most diverse database
encapsulating X-ray images from numerous countries (e.g.
Italy, Spain, China, etc.) and different X-ray machines. Consequently, the images are in different quality, resolution, and
noise levels as shown in Fig. 2.
As a consequence of recent advances in Deep Learning,
techniques that are based on Convolutional Neural Networks (CNNs) have achieved state-of-the-art performances
in many computer vision tasks such as image segmentation, recognition, and object detection. However, there are
certain limitations on the approaches based on deep CNNs:
the requirement of a large dataset to achieve the required
generalization capability of such deep networks, and the
necessity of an additional graphical processing unit (GPU)
hardware to achieve reasonable inference time. Nevertheless,
there are existing studies addressing these drawbacks, for
example, the method in [18] is able to reduce the volume of
the training data by 10% using a semi-supervised based approach. Moreover, for the latter, the method in [19] proposes
a knowledge distillation approach to transfer CNN models to
source-limited devices where only light-weight models can
be fit and suitable for the inference. Next, the need for such
lightweight conversions is discussed in [20] for IoT devices.
Unlike deep learners, traditional supervised approaches
can also be utilized especially when the data is scarce. For
example, representation-based classification approaches consisting of Sparse Representation based Classification (SRC)
[21], [22] and Collaborative Representation based Classification (CRC) [23] are proven to perform well with a limited data. Accordingly, in the representation-based classification approaches, a dictionary D is formed by stacking
samples from the training set. Then, when a test sample
y is introduced, it is assumed that the query samples can
be represented as a linear combination of the atoms in D.
Therefore, the estimated representation coefficients, x̂ that
is obtained by solving y = Dx, carry enough information about the class of y. For example, SRC approaches
compute sparse solutions: the estimated x̂ has just enough
non-zero coefficients, where only corresponding samples
with the same query class in the dictionary D contributes.
As SRC approaches, [21], [22], provide slightly improved
results compared to CRC, they are iterative methods and
computationally complex. On the other hand, CRC provides
a non-iterative and a relatively faster alternative via leastsquare sense solution, yet it produces comparable results as
presented in [23].
VOLUME 9, 2021

FIGURE 2. Sample X-ray images from Early-QaTa-COV19 in different quality,
resolution and noise level and showing no or very limited sign of COVID-19
pneumonia.

Convolutional Support Estimator Network (CSEN) introduced in a recent work [24] is proposed to combine traditional representation-based classification with a learningbased methodology. We define the support set as the location
of non-zero elements in x. Accordingly, the support set is
more important than the exact values of x since it reveals
the class information of the query. It was validated in [24]
that CSENs provide a superior classification performance
and computational efficiency against other representationbased methods by directly learning the mapping from query
sample y to the corresponding support set from a small
amount of training data. Moreover, CSENs are evaluated in
our previous study [14] for COVID-19 recognition in the
benchmark QaTa-COV19 dataset where it has achieved over
98% sensitivity and 95% specificity for COVID-19 recognition. Therefore, with their capabilities of performing well
with limited training dataset, both traditional representationbased classifiers and CSENs are good candidates for EarlyQaTa-COV19 dataset.
Overall, in this study, we evaluate compact and deep
classifiers for a possible advance warning system to detect
early stages of COVID-19 from X-ray images using the
Early-QaTa-COV19 dataset. The evaluated methods include
compact and deep classifiers using the Early-QaTa-COV19
dataset. In the former group, SRC, CRC, CSEN, MultiLayer Perceptron (MLP), Support Vector Machine (SVM),
and k-Nearest Neighbor (k-NN) classifiers are evaluated. In
the latter group, we evaluate the following deep networks:
DenseNet-121 [25], ResNet-50 [26], and Inception-v3 [27]
networks.
In this manner, the contributions of this study can be
summarized as the following:
3

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

FIGURE 3. Feature extraction pipeline from the pre-trained DenseNet-121. 1024-D feature vectors are extracted for the compact classifiers trained for the early
detection of COVID-19.

We compile the world’s largest dataset Early-QaTaCOV19 for early COVID-19 detection with chest X-ray
images labelled by our group of MDs.
• This study investigates the feasibility of early detection
and advance warning for COVID-19 from chest X-ray
images, which exhibit limited or no sign of the infection
by the naked eye. To accomplish this task, in this study,
we perform an extensive set of comparative evaluations
among numerous state-of-the-art techniques over the
benchmark dataset compiled for this purpose.
• To this end, it is for the first time the CSEN approach
is compared against several state-of-the-art approaches
including deep CNNs by providing an extensive set of
evaluations.
The results demonstrate that it is possible to achieve a
robust and highly accurate early COVID-19 detection with a
tolerable false alarm rate by CSENs using the deep features,
whereas deep learners provide reduced sensitivity levels but
with improved specificity.
The rest of the paper is organized as follows: a brief
overview and preliminaries will be provided related to
generic sparse representation in Section II. Next, the state-ofthe-art classification methods used in this study are detailed
in Section III. The experimental results with the benchmark
Early-QaTa-COV19 dataset are presented in Section IV. Finally, Section VI concludes the paper.
•

II. BACKGROUND AND PRELIMINARIES

In this section, a brief overview will be provided for
the representation-based classification approaches used in
this study. Accordingly, we define the following notations:
Pn
p 1/p
kxk`np = ( i=1 |xi | )
is the `p -norm of a vector x ∈ Rn
where p ≥ 1. The `∞ -norm and `0 -norm are defined for
the vector x as kxk`n = maxi=1,...,n (|xi |) and kxk`n =
0
Pn
p ∞
limp→0 i=1 |xi | = #{j : xj 6= 0}, respectively.
Additionally, a signal s can be called as strictly k-sparse if
there is a proper domain Φ that can represent the signal with
less than k + 1 non-zero coefficients: s = Φ x where kxk0 ≤
k. In other words, the signal s can be represented in some
domain, i.e., Φ, using only small number of basis vectors.
Hence, we define a (sparse) support set of the signal x, Λ ⊂
{1, 2, 3, ..., n}, as Λ := {i : xi = 0} indexing the non-zero
coefficients of x which corresponds these basis components.
The signal, s, can be represented in a subspace A, i.e., y =
As. Accordingly, y can be sparse coded in the equivalent
4

dictionary, D, as follows:
y = As = AΦx = Dx,

(1)

where D ∈ Rm×n , and A ∈ Rm×d is the compression
matrix for m << d. If the signal x is k-sparse in a Φ
sparsifying basis, then, the solution of
min kxk0 subject to Dx = y
x

(2)

is unique if kxk0 ≤ k and m ≥ 2k [28]. Hence, it can be
said based on (2) that at least k-sparse signal pairs can be
distinguishable in the equivalent dictionary, D.
As the above-mentioned optimization problem is nonconvex, and NP-hard, its relaxation by `1 can be applied
which is the closest convex norm:
min kxk1 s.t. x ∈ f (y)
x

(3)

which is defined as Basis Pursuit [29] where f (y) =
{x : Dx = y}.
On the other hand, as previously discussed, in
representation-based classification [22]–[24], estimating the
support set, Λ, would be more beneficial than the signal
recovery. Let the support estimator be E(., .) for a linear
measurement scheme with an additive noise y = Dx + z:
Λ̂ = E (y, D)

(4)

where Λ̂ is the estimation.
In practice, the performance of the recovery of Λ is related with the recovery performance of the sparse signal in
traditional SE methods, since they are based on first applying
a signal recovery method, then, applying component-wise
thresholding over the estimated signal, x̂, to compute Λ̂.
However, in [24], we have shown that the direct recovery
most likely causes noisy estimation while CSEN is able to
learn sparse patterns and accomplish better SE compared to
the competing methods. The readers are referred to [24] for a
more detailed survey and evaluations on the support estimation performances indicating the limitations and drawbacks
of traditional methods compared to the proposed CSEN
approach.
III. METHODS FOR EARLY DETECTION OF COVID-19
A. COMPACT APPROACHES FOR EARLY DETECTION

In this section, we present the state-of-the-art methodologies
and explain our configurations for their application to early
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

FIGURE 4. Representation-based classification pipeline for the early detection of COVID-19 using chest X-ray images.

detection of COVID-19. First, we present a feature extraction
procedure along with the compact classifier approaches in
the first group, then a detailed discussion is provided on
the chosen deep networks for the early detection problem.
Note the fact that the methods in the first group are selected
considering their suitability for the early detection task where
the training data is scarce.
1) Feature extraction by DenseNet-121

Traditional ML approaches need feature extraction for classification. In accordance with the purpose of this study, we
consider the pre-trained DenseNet-121 models for the feature
extraction trained on Early-QaTa-COV19 and ChestX-ray14
datasets [30]. The ChestX-ray14 dataset consists of 14 different pathology classes. The provided pre-trained network
in [31] is initialized with ImageNet weights, and it is finetuned over 100 000 chest X-ray images. It is reported in [31]
that DenseNet-121 produces the best results on the ChestXray14 dataset, and it also achieves better performance levels
than radiologists’ average decisions.
In this study, the pre-trained two DenseNet-121 models
on Early-QaTa-COV19 and ChestX-ray14 datasets are used
to extract 1024-D feature vectors by taking the output after
global pooling just before the classification layer, which is
illustrated in Fig. 3. Then, a dimensionality reduction is
applied over the calculated features with principal component
analysis (PCA) by choosing the first 512 principal components. Hence, for a feature vector s ∈ Rd=1024 , the query
sample y = As ∈ Rm is computed, where A ∈ Rm×d
is PCA matrix computed over the training data and m < d.
Then, data normalization is applied over the calculated y to
have zero mean and unit variance for MLP, SVM, and k-NN
classifiers, and zero mean and unit-norm for SRC, CRC, and
CSEN approaches.

image classification [32], and human action recognition [33].
In the following, we briefly give more information about the
SRC scheme.
Since in representation-based classification techniques, the
signal x may not be exactly k-sparse due to the correlation
between the samples in the dictionary, one alternative approach may be to corrupt the original scheme with an additive
noise, z, : y = Dx + z. In this case, stable recovery of
the sparse signal can still be possible even though the exact
recovery is not possible, where x̂ obeys kx − x̂k ≤ κ kzk
holds for the stable solution for a small κ constant. For
example, using the Lasso formulation:
o
n
2
(5)
min kDx − yk2 + λ kxk1
x

it is shown in [34] that it is possible to recover the partial or
exact x in noise-free or noisy conditions, respectively.
The correlation between the samples of different classes
has led many approaches to use different strategy instead of
solving (5) directly. Accordingly, [22] proposes to use a fourstep approach as follows: i) The atoms of D and the query
sample y are normalized to have unit `2 -norm, (ii) Perform
sparse recovery: x̂ = arg minx kxk1 s.t ky − Dxk2 , (iii)
Compute the residuals using the corresponding estimated
coefficient x̂i for the class i: ei = ky − Di x̂i k2 (iv) Class
prediction: Class (y) = arg min (ei ). Since such a fourstep approach brings additional improvements in the performance, many SRC studies follow a similar approach such as
[32], [33].
3) Collaborative Representation based Classification (CRC)

The study in [23] proposes to use `2 -minimization instead of
`1 -minimization in (5):
o
n
2
2
(6)
x̂ = arg min ky − Dxk2 + λ kxk2
x

2) Sparse Representation based Classification (SRC)

In SRC, when a query sample y is introduced, it is expected
that the estimated sparse code x̂ should have a sufficient number of non-zero coefficients in the locations which correspond
to samples in the dictionary, D, with the same class of the
query y. SRC techniques are used in many different classification tasks such as face recognition in [22], hyperspectral
VOLUME 9, 2021

Hence, x̂ can be computed from the derived closed-form
−1
solution as x̂ = DT D + λIn×n
DT y. In other words,
instead of searching for a sparse solution, this approach
utilizes collaborative representation (as CRC term states)
among the atoms of the dictionary due to the least-square
sense minimization approach. Consequently, CRC is particularly faster compared to iterative `1 -minimization recovery
5

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

FIGURE 5. The CSEN approach for the early COVID-19 detection from chest X-ray images.

algorithms. The CRC is used in [23] by modifying the second
step of the previously mentioned four-step solution in Section
III-A2 by changing the estimation of x̂ with its closed-form
estimation. They also report in [23] that CRC performances
on different classification problems are comparable with `1 minimization based approaches (even better than some other
approaches) for high compression rates. In this work, as
presented in Fig. 4, we use both SRC and CRC approaches to
provide comparative evaluations.
4) Convolutional Support Estimator Networks (CSENs)

If the aim is to compute the support set rather than the exact
signal recovery, then, a compact support estimator should be
sufficient for this task. Moreover, in traditional approaches
where signal recovery is initially performed and then Λ̂ is
computed, as discussed in Section II, the performance of SE
depends on the recovery performance, which is not guaranteed in noisy cases or if x̂ is not exactly sparse (e.g., for
representation-based classification problems in which CRC
classifier utilizes from this case as stated in [23]). As the
recovery of partial [35]–[37] or complete [13], [35], [38],
[39] Λ is still possible in these cases, it is shown in [24]
that CSEN performs well in SE for these cases compared to
traditional methods where a SR technique is first applied on y
to compute x̂, then a thresholding is made over x̂ to estimate
support set, Λ̂.
The proposed CSEN network in [24] aims to compute
direct mapping from test sample y to its corresponding
support set Λ̂. Hence, the CSEN approach is faster than `1 minimization techniques that work in an iterative manner.
Moreover, CSENs have compact configurations with few
convolutional layers which also contribute to computational
efficiency. For example, ReconNet proposed in [40] originally for the signal recovery problem requires deeper network
structures compared to the SE task. For the SE, another
alternative is to use MLPs as the estimator networks. Similarly, such network is used in [41] for the recovery problem.
However, for SE tasks, it is observed in [24] that using
MLPs decreases the generalization capability and robustness
to noise. Overall, thanks to their compact structures, CSENs
can learn from a limited number of labelled data which is
exactly the case for an advance warning system for COVID6

19.
Accordingly, a SE network should compute a binary mask
n
v ∈ {0, 1} :

1
if i ∈ Λ
(7a)
vi =
0
else ,
(7b)
Thus, the support set would be Λ = {i ∈ {1, 2, .., n} : vi = 1}.
Correspondingly, the CSEN networks, P (y, D), produce
an output vector p such that pi ∈ [0, 1] is the probability
of each index being in Λ. Then, the estimated support set,
Λ̂ = { i ∈ { 1, 2, .., n} : pi > τ }, can be computed by
thresholding p with a fixed threshold, τ .
On the other hand, the input of the CSEN is the
proxy x̃ which is a coarse estimation of x as x̃ = DT y
−1
or DT D + λI
DT y. Inference on the proxy of x is
investigated by several studies for different applications,
for example, studies in [42]–[44] perform classification of
compressively sensed images using the proxy as input of
reconstruction-free frameworks.
Since CSEN networks consist of 2-D convolutional layers
as illustrated in Fig. 5, the proxy x̃ is reshaped to a 2-D
plane. Then, it is convolved with the weight kernels, W1 ,
connecting the input layer to the next layer with N filters to
form the input of the activation with the summation of weight
biases b1 :
F1 = {S(ReLu(bi1 + w1i ∗ x̃))}N
i=1 ,

(8)

where ReLu(x) = max(0, x), and S(.) is the up- or downsampling operation. Hence, the k th feature map of layer l
can be given as,
Nl−1

flk

=

S(ReLu(bkl

+

X

i
conv2D(wli,k , fl−1
,0 ZeroPad0 ))).

i=1

(9)
Overall, L layer CSEN will have the trainable weight
and
parameters {w, b} as follows: ΘCSEN =
 ibias
i i N2
i
i NL
1
{w1 , bi1 }N
i=1 , {w2 , b2 }i=1 , ...{wL , bL }i=1 .
Since samples from the same class are grouped together in
the representation-based classification, a group sparsity term
can be introduced in `1 -minimization problem given in (5) as
follows,
(
)
c
X
2
min kDx − yk2 + λ
kxGi k2
(10)
x

i=1
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

where the group of coefficients is represented by xGi for ith
class. Thus, the cost function would be the following for an
SE network:
c
X
X
2
E(x) =
(PΘ (x̃)p − vp ) + λ
PΘ (x̃)Gi 2 . (11)
p

i=1

where vp is the true binary mask indicating the sparse codes
of x and the output of the network is PΘ (x̃)p at pth pixel.
Although such a regularization technique may increase the
classification performance since it forces the network to
produce supports grouped together, the cost function in (11)
is approximated because of its computational complexity in
CSEN by inserting average pooling layers after the last convolutional layer. Afterwards, the categorical cross-entropy is
calculated as the cost of CSEN using the produced class probabilities obtained after SoftMax operation. Consequently, the
input output pair for the training of CSEN is (x̃, class(y)).
Since CSEN takes reshaped proxy x̃ as input, the corresponding indices of the atoms in the dictionary, D, are reordered to make sure that samples from the same classes
are grouped together in the reshaped 2-D plane. Note the
fact that the grouped samples would have different sizes
depending on the number of dictionary samples and classes
which also determines the definite input, output mask, and
average pooling stride sizes of the CSEN. The modified
CSEN configurations with dictionary sizes for the two-class
early detection problem will be given in Section IV. The
overall framework of CSEN in early detection of COVID-19
is presented in Fig. 5.
5) Multi-Layer Perceptrons (MLPs)

The MLP network used for the early detection task consists
of 3-hidden layers, where the details of its structure are
depicted in Fig. 6. Such network architecture is determined
by testing different network topologies with shallower or
deeper networks by performing parameter search. In the early
detection problem with MLP based classification, we follow
a slightly different approach compared to other presented
compact classifiers. The neurons connecting the input layer
to the first hidden layer are first initialized with A ∈ Rm×d
which is the PCA matrix computed for dimensionality reduction task of other classifiers. Then, all layers are trained
together including the PCA initialized layer. Such an ap-

proach provides a slightly improved performance and fair
comparison with other classifiers used in this study since they
also utilize the PCA technique.
6) Support Vector Machine (SVM)

The SVM topology is selected by performing grid-search
to find optimal hyper-parameters such as kernel type and
its parameters with the following setting and variations: the
kernel function {linear, polynomial, radial basis function
(RBF)}, kernel scale (γ parameter for the RBF kernel) in
the range [10−3 , 103 ] incremented in log-scale, polynomial
order {2, 3, 4}, and box constraint (C parameter) with logscale in the range [10−3 , 103 ]. Since this is a detection (binary
classification) problem, a single SVM suffices for the task.
7) k-Nearest Neighbor (k-NN)

Similarly, the optimal parameters are searched in the predefined grid to build a k-NN classifier with the best configuration. Accordingly, in the search space, the k-values are varied
with log-scale in the range [1, No /2], where No is the number
of observations in the train set, and the evaluated 11 different distance metrics are as follows: Euclidean, standardized
Euclidean, correlation, City-block, cosine, Chebyshev, Hamming, Minkowski, Mahalanobis, Jaccard, and Spearman.
B. DEEP LEARNING BASED EARLY DETECTION

Deep Learning methods, or specifically deep CNNs have
achieved elegant results in many computer vision tasks.
Hence, in this study, their learning capability should be
investigated for the early detection of COVID-19. Contrary
to the aforementioned compact classifiers, deep CNNs do
not need a prior feature extraction step since CNNs combine
feature extraction and classification in a single learning body
and jointly optimize them. In this group, we investigate three
recent deep configurations: DenseNet-121 [25], ResNet-50
[26], and Inception-v3 [27]. Accordingly, DenseNet-121,
ResNet-50, and Inception-v3 models are trained over the
Early-QaTa-COV19 dataset starting from their ImageNet
weights.
IV. EXPERIMENTAL RESULTS

In this section, first the benchmark dataset released along
with this study is introduced, and then the experimental
setup is presented. Finally, we provide an extensive set of
comparative evaluations over early detection performances of
the state-of-the-art methods covered in this study.
A. BENCHMARK DATASETS
1) QaTa-COV19 dataset

FIGURE 6. MLP framework used for the early detection of COVID-19.
VOLUME 9, 2021

The researchers of Qatar University and Tampere University
have compiled the largest COVID-19 dataset, called QaTaCOV19. In the dataset, there are 2951 COVID-19 positive Xray images that are collected from various publicly available
sources including BIMCV-COVID19+ [45], Hannover Medical School and Institute for Diagnostic and Interventional
7

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

Radiology [46], Italian Society of Medical and Interventional
Radiology (SIRM) COVID-19 Database [47], Chest Imaging
(Spain) at thread reader [48], Radiopaedia [49], and newsportals and online articles. The authors have also performed
the tedious task of indexing and collecting of X-ray images
from various published and preprint articles from China,
USA, Italy, Spain, South Korea, Taiwan for COVID-19 positive cases as well as online news-portals (until 20th of April,
2020).
Besides COVID-19 cases, there are 12 544 normal X-ray
images which are collected from various sources: Padchest
dataset [50], RSNA pneumonia detection challenge dataset
[51], Indiana Network for Patient Care [52], from the Department of Health and Human Services of Montgomery County
and from Shenzhen Hospital released in [53], and the Kaggle
chest X-ray database [54].
Correspondingly, both normal and COVID-19 samples are
from different gender, age-groups, ethnicity, and country.
Note the fact that since collected X-ray images are from
various publicly available datasets in different formats, we
have removed over-exposed and low-quality samples, and
duplicated samples are also removed using the structural
similarity index measure (SSIM).
2) Early-QaTa-COV19 dataset

This dataset is formed by selecting the early stages of
COVID-19 pneumonia from the enlarged version of QaTaCOV19 dataset that consists of 4603 COVID-19 positive
cases. Accordingly, constructed Early-QaTa-COV19 consists
of 1065 early-stage COVID-19 samples (no and very limited
infection signs on 801 and 264 images, respectively) labelled
by the MDs, and 12 544 samples for control (normal) class.
Note the fact that the selected samples are not quantified
based on their X-ray acquisition times, since they are selected
from COVID-19 positive patients by visual inspection; and
hence the early signs of the disease may be present at
any time independent from the patients’ symptoms. In fact,
patients can exhibit no symptoms at all, that is, they can
be asymptomatic. The dataset is highly unbalanced and this
particularly makes the early detection task harder for advance
warning. Furthermore, a high inter-class similarity exists in
the dataset as shown in Fig. 1. Finally, as illustrated in Fig.
2, there is a high intra-class dissimilarity among the images
since they are compiled from different sources.
B. EXPERIMENTAL SETUP

The comparative methods are evaluated by a 5-fold crossvalidation (CV) scheme over the Early-QaTa-COV19 dataset.
We have resized chest X-ray images to 224 × 224 in order to
fit the input dimensions to the state-of-the-art deep network
topologies. Table 1 shows the number of samples in each
fold, which we split the data into training and test (unseen
folds) sets by 80% and 20%, respectively. Accordingly, we
also provide an initial version of Early-QaTa-COV19 as a
sub-set of the original dataset. This version of the benchmark
8

dataset is proposed specifically for the methods that are wellsuited for scarce data.
TABLE 1. Number of samples per class and fold.

(a) Early-QaTa-COV19 Dataset
Class
Early Stage
COVID-19
Normal

Total Samples

Training Samples

Test Samples

1065

852

213

12 544

10 035

2509

(b) Initial Early-QaTa-COV19 Dataset
Class
Early Stage
COVID-19
Normal

Total Samples

Training Samples

Test Samples

175

140

35

1579

1263

316

Since the dataset is highly unbalanced, we have balanced
the training set by augmenting the data in order to have
an equal number of samples in each class. However, such
limited data augmentation for balancing is not enough for
deep CNNs when they are trained over the initial version
of the dataset. Hence, we augmented the training samples
up to 20 070 X-ray images for data balancing on EarlyQaTa-COV19, whereas data augmentation yields 20K images
for training deep CNNs on Initial Early-QaTa-COV19. The
data augmentation is performed by Image Data Generator in
Keras. We have augmented the X-ray images by randomly
rotating in 10 degrees of range and randomly shifting them
horizontally and vertically by 10%. The blank sections, after
rotating and shifting, are filled by the "nearest" mode.
For the CSEN approaches used in this study, we follow
the proposed configurations in [24]. Accordingly, there are
two compact networks: CSEN1 and CSEN2. CSEN1 has
only two hidden convolutional layers with 48 and 24 neurons, respectively, whereas CSEN2 consists of additional
max-pooling and transposed-convolutional layers with 24
neurons. Both networks use Rectified Linear unit (ReLu)
activation functions and 3 × 3 filter sizes. In addition to this
setup, the ReconNet [40] approach is modified to perform the
SE task as a deep version of the CSEN framework. ReconNet
is originally proposed for the signal recovery problem as a
non-iterative alternative to the traditional approaches, and it
achieves the state-of-the-art performance levels in compressive sensing applications as shown in [40]. The modified
ReconNet for SE has 6 fully convolutional layers, and it
does not have a denoiser layer as the first block and Blockmatching and 3D filtering (BM3D) operation (see [40]) at the
output. The input-output pair is also different (x̃, class(y)) to
train the network as the CSEN type of approach for the early
detection problem. Accordingly, its last layer is modified by
inserting an average-pooling layer to mimic the cost in (11),
and SoftMax to produce class probabilities.
The experimental evaluations of SRC, CRC, and k-NN
are performed on a PC with Intel ® i7 − 8650U CPU
and 32 GB system memory with MATLAB version 2019a,
whereas SVM is implemented with the same computer setup
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

but in Python. In the regularized least square solution of
CRC, the regularization parameter is searched in the range
[10−13 , 103 ] incremented in log-scale, then, it is fine-tuned
with λ∗ /10 steps. For the hyper-parameter selection of k-NN
and SVM classifiers, grid search is performed using another
5-fold stratified CV over the training sets of the previously
explained CV folds. Other approaches: MLP, CSEN, and
deep learning methods are implemented with the Tensorflow
library [55] using Python on NVidia ® TITAN-X GPU card.
The training procedures of MLP, CSEN and deep CNNs are
performed using ADAM optimizer [56] with their proposed
default momentum update parameters as β1 = 0.9 and
β2 = 0.999 using categorical cross-entropy loss function.
CSEN is trained for only 15 Back-Propagation epochs with a
learning rate, α = 10−4 , and a batch size, 32. On the other
hand, the MLP network and deep learners are trained with
α = 10−5 both for 10 epochs and with batch size 32.
C. RESULTS

For a possible advance warning system that can detect
COVID-19 in the early stages, we have analyzed and evaluated several ML approaches including compact classifiers:
SRC, CRC, CSEN, MLP, SVM, and k-NN, and deep CNNs:
DenseNet-121, ResNet-50, and Inception-v3 networks. For
SRC approach, we have investigated 8 different solvers:
OMP [57], Dalm [57], L1LS [58], ADMM [59], Homotopy
[60], GPSR [61], Palm [57], and `1 -magic [62]. In this study,
we report SRC results from only Dalm and Homotopy solvers
since others show poor performance in the detection task
(provides < 80% sensitivity).
In the representation-based classification approaches, the
dictionary is constructed by using all samples from the
balanced training set of each fold. Hence, Φ, has 10 035
and 1263 samples from each class of Early-QaTa-COV19
and its initial version, respectively. Next, the PCA matrix,
A, is applied for the dimensionality reduction, where the
compression ratio is CR = m/d = 0.5. The equivalent
dictionary, D, would have the size of 512 × 20070 and
512 × 2526 for the initial version. On the other hand, since
CSEN networks need additional training samples, we choose
only 625 samples per class to construct Φ and use the
remaining samples from the training set of each fold to train
CSENs in the experiments. Consequently,
−1 T the corresponding
denoiser matrix B = DT D + λI
D of size 1250×512
is used to perform coarse estimation for CSEN. The resulted
x̃ = By, x̃ ∈ Rn=1250 , is reshaped to 2-D plane with the
size of 25 × 50 in such a way that support sets from the
corresponding classes are grouped together which is then fed
to CSENs.
1) Results on Early-QaTa-COV19

The early detection performances of the compact classifiers
are given with their 95% confidence intervals (CIs) in Table
2a. Accordingly, CI can be estimated
for each performance
p
metric as follows: r = z accuracy(1 − accuracy)/N ,
where N is the number of samples for that particular perVOLUME 9, 2021

formance metric, and z is the level of significance that is
1.96 for 95% CI. Consequently, it is expected that the CIs for
sensitivity measure are larger due to the unbalanced data. The
presented results clearly indicate that CSENs achieve the top
sensitivities among other compact classifiers with acceptable
specificity rates. In particular, CSEN2 configuration achieves
over 97% sensitivity with a high specificity (> 95%). The
same denoiser matrix is also used in the CRC method which
is reported separately as the CRC-light version to observe if
the CSEN approach brings performance improvement. Since
representation-based classification approaches are known to
perform well in the limited-data scenarios, the second competitor is indeed the CRC approach from the first group
as expected. Note the fact that the CRC method provides
comparable classification performance for the early detection
with SRC methods. This may be explained in the following
way; in representation-based classification problems, it may
not be the sparsity that brings the information about the class
but the collaborative representation among the samples in the
dictionary. Similar findings are reported in [23] for the face
recognition problem.
TABLE 2. The average performances and their 95% confidence intervals
(CIs) of different approaches over 5-folds on Early-QaTa-COV19 for the early
detection of COVID-19 pneumonia from the normal chest X-ray images.
CRC-light uses the same Φ with CSENs, whereas CRC uses the complete
training set.

(a) Average detection performances of compact classifiers.

Method
SRC-Dalm
SRC-Hom.
CRC-light
CRC
CSEN1
CSEN2
ReconNet
MLP
SVM
k-NN

Accuracy
0.9852 ± 0.002
0.9778 ± 0.025
0.9730 ± 0.003
0.9678 ± 0.003
0.9513 ± 0.004
0.9566 ± 0.003
0.9322 ± 0.004
0.9699 ± 0.003
0.9830 ± 0.002
0.9741 ± 0.003

Sensitivity
0.8864 ± 0.019
0.9211 ± 0.016
0.9559 ± 0.012
0.9155 ± 0.017
0.970 ± 0.01
0.9728 ± 0.010
0.9662 ± 0.011
0.9352 ± 0.015
0.8892 ± 0.019
0.9305 ± 0.015

Specificity
0.9935 ± 0.001
0.9826 ± 0.002
0.9744 ± 0.003
0.9723 ± 0.003
0.9497 ± 0.004
0.9552 ± 0.004
0.9293 ± 0.005
0.9728 ± 0.003
0.9910 ± 0.002
0.9778 ± 0.003

(b) Average detection performances of deep CNNs.
Method
DenseNet-121
Inception-v3
ResNet-50

Accuracy
0.9937 ± 0.001
0.9791 ± 0.002
0.9884 ± 0.002

Sensitivity
0.9502 ± 0.013
0.8469 ± 0.022
0.9155 ± 0.017

Specificity
0.9974 ± 0.001
0.9904 ± 0.002
0.9946 ± 0.001

Table 2b presents the average detection performances of
deep CNNs. Although the best sensitivity is obtained using
CSENs, deep CNNs can also achieve quite high sensitivity
levels with almost no false alarms (specificity is ∼ 1). For
example, DenseNet-121 outperforms other deep networks
and produces a superior specificity of 99.74% but with a
reduced sensitivity than CSEN2. Moreover, the confusion
matrices, cumulated over the confusion matrix of each fold’s
test set, are presented in Table 3 for the two top-performers.
Accordingly, CSEN2 is able to detect 24 more early COVID19 cases than DenseNet-121.
9

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

FIGURE 7. False negatives of the CSEN1 and DenseNet-121* which is initialized with ChestX-ray14 weights and fine-tuned on Initial Early-QaTa-COV19.

TABLE 3. Leading compact CSEN and deep DenseNet-121 models’
cumulative confusion matrices on Early-QaTa-COV19.

(a) CSEN2 Confusion Matrix

CSEN2
Ground
Truth

Normal
COVID-19

Predicted
Normal COVID-19
11 982
562
29
1036

(b) DenseNet-121 Confusion Matrix

DenseNet-121
Ground
Truth

Normal
COVID-19

Predicted
Normal COVID-19
12 511
33
53
1012

2) Results on Initial Early-QaTa-COV19

Initial version of Early-QaTa-COV19 enables to benchmark
methods for the cases when the data is limited. To overcome
this limitation, a transfer learning technique can still be applied by the following: (i) using a suitable pre-trained model
without fine tuning to extract features which will be used by
a compact classifier that does not require a large amount of
training data, and (ii) using the pre-trained deep model as the
initialization, and then, performing fine-tuning with limited
data. In this manner, in the experiments with Initial EarlyQaTa-COV19, we use DenseNet-121 for extracting features
of the compact classifiers with the weights learned over
ChestX-ray14 dataset.
Experimental evaluations on Initial Early-QaTa-COV19
is important for a fair comparison between CSEN type of
networks with CRC and SRC methods. Because, even though
the dictionaries of the representation based approaches are
formed by using the complete training set, the more fair
comparison against CSENs can be performed by using a
small training set (for all methods) but still with the same
size with the dictionaries of CRC and SRC methods.
The early detection performances of the methods are given
in Table 4. It is clear that CSEN1 and ReconNet can achieve
the top sensitivity among all methods. However, ReconNet
suffers from relatively low specificity, which indicates a substantial amount of false positives. Note the fact that the CRC
method outperforms SRC methods on Initial Early-QaTaCOV19. Since the data is limited; and hence, the number of
10

atoms in the dictionary is smaller, we have observed much
higher performance gap between CRC and SRC compared to
the previous experiments on Early-QaTa-COV19 and other
classification problems reported in the previous studies [23],
[24]. Considering the second group of approaches based on
deep CNNs, DenseNet-121 is additionally initialized with
ChestX-ray14 weights, and it is fine-tuned over Initial EarlyQaTa-COV19. In this way, we also aim to investigate if the
ChestX-ray14 dataset improves the performance of the early
detection of COVID-19 by comparing the DenseNet-121
version which is trained directly from its ImageNet weights.
Indeed, initialization with ChestX-ray14 weights has slightly
improved the sensitivity but with a specificity of around
99.5%.
TABLE 4. The average performances and their 95% confidence intervals
(CIs) of different approaches over 5-folds on Initial Early-QaTa-COV19 for the
early detection of COVID-19 pneumonia from the normal chest X-ray images.
CRC-light uses the same Φ with CSENs, whereas CRC uses the complete
training set.

(a) Average detection performances of compact classifiers.

Method
SRC-Dalm
SRC-Hom.
CRC-light
CRC
CSEN1
CSEN2
ReconNet
MLP
SVM
k-NN

Accuracy
0.9818 ± 0.006
0.9481 ± 0.010
0.9783 ± 0.007
0.9823 ± 0.006
0.9635 ± 0.009
0.9248 ± 0.012
0.9424 ± 0.011
0.9584 ± 0.009
0.9681 ± 0.008
0.9458 ± 0.011

Sensitivity
0.9371 ± 0.036
0.8171 ± 0.057
0.9486 ± 0.033
0.9657 ± 0.027
0.9886 ± 0.016
0.9943 ± 0.011
0.9943 ± 0.011
0.9371 ± 0.036
0.9657 ± 0.027
0.9257 ± 0.039

Specificity
0.9867 ± 0.006
0.9626 ± 0.009
0.9816 ± 0.007
0.9842 ± 0.006
0.9607 ± 0.010
0.9171 ± 0.014
0.9367 ± 0.012
0.9607 ± 0.010
0.9683 ± 0.009
0.9481 ± 0.011

(b) Average detection performances of deep CNNs. DenseNet-121* is initialized with ChestX-ray14 weights.
Method

Accuracy

Sensitivity

Specificity

DenseNet-121*
DenseNet-121
Inception-v3
ResNet-50

0.9926 ± 0.004
0.9949 ± 0.003
0.9937 ± 0.004
0.9943 ± 0.004

0.9714 ± 0.025
0.9543 ± 0.031
0.9543 ± 0.031
0.9600 ± 0.029

0.9949 ± 0.004
0.9994 ± 0.001
0.9981 ± 0.002
0.9981 ± 0.002

Moreover, the false-negative X-ray images are given in
Fig. 7. Accordingly, DenseNet-121 initiliazed with ChestXray14 weights misses three more early case of COVID-19
than CSEN1, but it is able to provide much higher specificity
(the sensitivity for normal X-ray images). It is observed that
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

CSEN1 and DenseNet-121 are able to detect 39 and 38,
respectively, out of 40 early cases of COVID-19 that show
no visible sign of COVID-19 by a human eye.
3) Computational Complexity Analysis

To assess the computational complexity analysis of the compared methods, we first start with the number of trainable network parameters as presented in Table 5. Obviously CSENs
have a crucial advantage especially compared to the deep
CNNs in terms of computational complexity. As for time
complexity, Fig. 8 shows sensitivity versus computational
time for each method evaluated in this study. Note that the
computational times are evaluated on Initial Early-QaTaCOV19 dataset for representation based classification approaches including CRC, Dalm, and Homotopy since their
computational times are only comparable if Φ consists of
small number of atoms. Hence, the sensitivity levels on
the initial version of the dataset are given in Fig. 8. It is
observed that CSEN type of networks achieve computational
efficiency, and DenseNet-121 can achieve slightly inferior
sensitivity and it is still faster than some of the compact
classifiers.
TABLE 5. Number of trainable parameters of comparative models.

Model
CSEN1
CSEN2
ReconNet
MLP
DenseNet-121
ResNet-50
Inception-v3

Number of Parameters
11,089
16,297
22,914
672,706
6,955,906
23,538,690
21,772,450

Note the fact that even though CRC tends to provide
closed-form solution, because of the four-step classification
framework, which involves residual finding as discussed
in Section III, representation-based classification techniques
suffer from the highest time complexity in general. However,
CSENs use only the denoiser multiplication part of CRC,
x̃ = By, which requires an insignificant time (i.e., only
3.86 ms for a test set averaged over 5-folds). Finally, such
inference times for deep networks are valid if they can utilize
the recent GPU cards, whereas other methods do not require
additional hardware and can run on an ordinary computer.
This is a crucial advantage for those light-weight mobile
applications with a real-time analysis requirement.
V. LIMITATIONS OF THE STUDY

In this study, for the first time in the literature ML approaches
are applied for the early detection of COVID-19. On the
other hand, it can be said that the number of COVID-19
images may still be considered as a limitation considering
hundreds of thousands of samples in the existing datasets for
other applications. Moreover, another important drawback:
the decision of the methods is not easily accessible or interpretable at all since they are considered as black-box apVOLUME 9, 2021

FIGURE 8. Time complexity versus the sensitivity of all the evaluated
classifiers. Computational times are plotted in log-scale and measured for the
evaluation of test sets by averaging over 5-folds.

proaches. Of course, there are preliminary works of exploring
activation maps showing which locations actually activate the
networks’ decision. However, there is further study needed
to investigate their correctness. This will be the topic of
the future work. Nonetheless, automated methods can still
be employed due to their cost-effectiveness and speeds as
precautionary measure while waiting other diagnostic tools
such as CT-scans and RT-PCR. For example, one may utilize
evaluated methods for the early detection task especially in
the heavily effected places where the diagnosis based on CTscan or RT-PCR takes time.
VI. CONCLUSION

Since there is no known specific treatment for COVID-19, the
early detection of the disease plays a vital role in preventing
the spreading of the pandemic. Currently, RT-PCR is widely
used in the world for the diagnosis of COVID-19. However,
RT-PCR tests can easily miss a positive case (false negatives)
depending on the sample collection or the disease stage of
the patient. As an alternative, chest CT-scans have provided
satisfactory results and outperformed sensitivity levels of
RT-PCR. Nevertheless, in many areas where hospitals are
congested because of the pandemic, it may not be easy to
access such expensive and time-consuming equipment.
X-ray acquisition, however, is cheaper, easily accessible,
and the acquisition time is shorter than CT. Furthermore,
X-ray imaging can be applied with a greater ease since the
equipment is portable. This justifies our motivation to investigate the feasibility of an accurate, robust and fully-automatic
advance warning method for COVID-19 from chest X-ray
images. For this purpose, we first compiled the Early-QaTaCOV19 dataset which encapsulates the largest number of
COVID-19 patients who are in the early stages. Our findings
have clearly demonstrated the fact that early detection of
COVID-19 infestation from X-ray images can be performed
with a very high sensitivity and specificity. In other words,
even though it is a difficult or sometimes impossible task
for experts to detect COVID-19 infestation due to the early
stage of the disease, with a proper setup and training, some
particular compact and deep classifiers can accurately detect
the disease with tolerable false-positives. In particular, it
11

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

is observed that CSEN type of models provide the highest
sensitivity levels with > 97% while DenseNet-121 provides
a decreased sensitivity with a higher specificity. Among
those 40 X-ray images in Initial Early-QaTa-COV19 where
MDs have found no trace of COVID-19 infestation (and
hence naturally would mis-diagnose all of them as "normal"),
CSEN1 and DenseNet-121 can accurately identify 39 and 38
of them, respectively. Finally, both CSEN models have the
utmost computational efficiency especially when compared
to the CRC and deep networks. This makes them a feasible
solution for those low-cost/low-power portable applications.
REFERENCES
[1] Z. Y. Zu, M. D. Jiang, P. P. Xu, W. Chen, Q. Q. Ni, G. M. Lu, and
L. J. Zhang, “Coronavirus disease 2019 (COVID-19): A perspective from
China,” Radiology, vol. 296, no. 2, 2020, doi: 10.1148/radiol.2020200490.
[2] World Health Organization, “Laboratory testing for coronavirus disease
2019 (COVID-19) in suspected human cases: Interim guidance,” World
Health Organization, Tech. Rep., 2020.
[3] Y. Yang, M. Yang, C. Shen, F. Wang, J. Yuan, J. Li, M. Zhang, Z. Wang,
L. Xing, J. Wei et al., “Laboratory diagnosis and monitoring the viral
shedding of 2019-nCoV infections,” MedRxiv, 2020.
[4] T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao, Z. Sun,
and L. Xia, “Correlation of chest CT and RT-PCR testing in coronavirus
disease 2019 (COVID-19) in China: A report of 1014 cases,” Radiology,
vol. 296, no. 2, 2020, doi: 10.1148/radiol.2020200642.
[5] X. Xie, Z. Zhong, W. Zhao, C. Zheng, F. Wang, and J. Liu, “Chest CT for
typical 2019-nCoV pneumonia: Relationship to negative RT-PCR testing,”
Radiology, vol. 296, no.2, 2020, doi: 10.1148/radiol.2020200343.
[6] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, and W. Ji, “Sensitivity
of chest CT for COVID-19: Comparison to RT-PCR,” Radiology, vol. 296,
no. 2, 2020, doi: 10.1148/radiol.2020200432.
[7] D. J. Brenner and E. J. Hall, “Computed tomography—an increasing
source of radiation exposure,” N. Engl. J. Med., vol. 357, no. 22, pp. 2277–
2284, 2007.
[8] G. D. Rubin, C. J. Ryerson, L. B. Haramati, N. Sverzellati, J. P. Kanne,
S. Raoof, N. W. Schluger, A. Volpi, J.-J. Yim, I. B. Martin et al., “The role
of chest imaging in patient management during the COVID-19 pandemic:
A multinational consensus statement from the Fleischner Society,” Chest,
vol. 158, no. 1, pp. 106–116, 2020.
[9] M. E. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir,
Z. B. Mahbub, K. R. Islam, M. S. Khan, A. Iqbal, N. Al-Emadi
et al., “Can AI help in screening Viral and COVID-19 pneumonia?”
arXiv:2003.13145, 2020. [Online]. Available: https://arxiv.org/abs/2003.
13145
[10] S. Hu, Y. Gao, Z. Niu, Y. Jiang, L. Li, X. Xiao, M. Wang, E. F. Fang,
W. Menpes-Smith, J. Xia et al., “Weakly supervised deep learning for
COVID-19 infection detection and classification from CT images,” IEEE
Access, vol. 8, pp. 118 869–118 883, 2020.
[11] I. D. Apostolopoulos and T. A. Mpesiana, “COVID-19: Automatic detection from X-ray images utilizing transfer learning with convolutional
neural networks,” Phys. Eng. Sci. Med., vol. 43, pp. 635–640, 2020.
[12] L. O. Hall, R. Paul, D. B. Goldgof, and G. M. Goldgof, “Finding
COVID-19 from chest X-rays using deep learning on a small dataset,”
arXiv:2004.02060, 2020. [Online]. Available: https://arxiv.org/abs/2004.
02060
[13] M. Wainwright, “Information-theoretic bounds on sparsity recovery in the
high-dimensional and noisy setting,” in Proc. IEEE Int. Symp. Inf. Theory
(ISIT), 2007, pp. 961–965.
[14] M. Yamac, M. Ahishali, A. Degerli, S. Kiranyaz, M. E. H. Chowdhury,
and M. Gabbouj, “Convolutional sparse support estimator based COVID19 recognition from X-ray images,” arXiv:2005.04014, 2020. [Online].
Available: https://arxiv.org/abs/2005.04014
[15] M. Roberts, D. Driggs, M. Thorpe, J. Gilbey, M. Yeung, S. Ursprung, A. I.
Aviles-Rivero, C. Etmann, C. McCague, L. Beer et al., “Machine learning
for COVID-19 detection and prognostication using chest radiographs and
CT scans: A systematic methodological review,” arXiv:2008.06388, 2020.
[Online]. Available: https://arxiv.org/abs/2008.06388
[16] A. Degerli, M. Ahishali, M. Yamac, S. Kiranyaz, M. E. Chowdhury,
K. Hameed, T. Hamid, R. Mazhar, and M. Gabbouj, “COVID-19
12

[17]

[18]

[19]

[20]
[21]

[22]

[23]

[24]

[25]

[26]

[27]

[28]

[29]

[30]

[31]

[32]

[33]

[34]
[35]

[36]

[37]

infection map generation and detection from chest X-ray images,”
arXiv:2009.12698, 2020. [Online]. Available: https://arxiv.org/abs/2009.
12698
H. Y. F. Wong, H. Y. S. Lam, A. H.-T. Fong, S. T. Leung, T. W.-Y. Chin,
C. S. Y. Lo, M. M.-S. Lui, J. C. Y. Lee, K. W.-H. Chiu, T. Chung et al.,
“Frequency and distribution of chest radiographic findings in COVID19 positive patients,” Radiology, vol. 296, no. 2, 2020, doi: 10.1148/radiol.2020201160.
C. Wang, S. Dong, X. Zhao, G. Papanastasiou, H. Zhang, and G. Yang,
“SaliencyGAN: Deep learning semisupervised salient object detection in
the fog of IoT,” IEEE Trans. Ind. Informat., vol. 16, no. 4, pp. 2667–2676,
2019.
C. Wang, G. Yang, G. Papanastasiou, H. Zhang, J. Rodrigues, and V. Albuquerque, “Industrial cyber-physical systems-based cloud IoT edge for
federated heterogeneous distillation,” IEEE Trans. Ind. Informat., 2020,
doi: 10.1109/TII.2020.3007407.
A. Khattab and N. Youssry, “Machine learning for IoT systems,” in
Internet of Things (IoT). Springer, 2020, pp. 105–127.
J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, “Robust face
recognition via sparse representation,” IEEE Trans. Pattern Anal. Mach.
Intell., vol. 31, no. 2, pp. 210–227, 2008.
J. Wright, Y. Ma, J. Mairal, G. Sapiro, T. S. Huang, and S. Yan, “Sparse
representation for computer vision and pattern recognition,” Proc. IEEE,
vol. 98, no. 6, pp. 1031–1044, 2010.
L. Zhang, M. Yang, and X. Feng, “Sparse representation or collaborative
representation: Which helps face recognition?” in Proc. IEEE Int. Conf.
Comput. Vision (ICCV), 2011, pp. 471–478.
M. Yamac, M. Ahishali, S. Kiranyaz, and M. Gabbouj, “Convolutional
sparse support estimator network (CSEN) from energy efficient support
estimation to learning-aided compressive sensing,” arXiv:2003.00768,
2020. [Online]. Available: https://arxiv.org/abs/2003.00768
G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, “Densely
connected convolutional networks,” in Proc. IEEE Conf. Comput. Vision
and Pattern Recognit. (CVPR), 2017, pp. 4700–4708.
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in Proc. IEEE Conf. Comput. Vision and Pattern Recognit.
(CVPR), 2016, pp. 770–778.
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking
the inception architecture for computer vision,” in Proc. IEEE Conf.
Comput. Vision and Pattern Recognit. (CVPR), 2016, pp. 2818–2826.
D. L. Donoho and M. Elad, “Optimally sparse representation in general
(nonorthogonal) dictionaries via l1 minimization,” Proc. Nat. Acad. Sci.,
vol. 100, no. 5, pp. 2197–2202, 2003.
S. S. Chen, D. L. Donoho, and M. A. Saunders, “Atomic decomposition
by basis pursuit,” Soc. Ind. Appl. Math. Rev., vol. 43, no. 1, pp. 129–159,
2001.
X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers, “Chestxray8: Hospital-scale chest X-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases,” in
Proc. IEEE Conf. Comput. Vision and Pattern Recognit. (CVPR), 2017, pp.
2097–2106.
P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding,
A. Bagul, C. Langlotz, K. Shpanskaya et al., “Chexnet: Radiologistlevel pneumonia detection on chest X-rays with deep learning,”
arXiv:1711.05225, 2017. [Online]. Available: https://arxiv.org/abs/1711.
05225
W. Li and Q. Du, “A survey on representation-based classification and
detection in hyperspectral remote sensing imagery,” Pattern Recognit.
Lett., vol. 83, pp. 115–123, 2016.
T. Guha and R. K. Ward, “Learning sparse representations for human
action recognition,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 34, no. 8,
pp. 1576–1588, 2011.
E. J. Candes and Y. Plan, “A probabilistic and ripless theory of compressed
sensing,” IEEE Trans. Inf. Theory, vol. 57, no. 11, pp. 7235–7254, 2011.
J. Scarlett and V. Cevher, “Limits on support recovery with probabilistic
models: An information-theoretic framework,” IEEE Trans. Inf. Theory,
vol. 63, no. 1, pp. 593–620, 2016.
G. Reeves and M. Gastpar, “Sampling bounds for sparse support recovery
in the presence of noise,” in Proc. IEEE Int. Symp. Inf. Theory (ISIT), 2008,
pp. 2187–2191.
G. Reeves and M. C. Gastpar, “Approximate sparsity pattern recovery:
Information-theoretic lower bounds,” IEEE Trans. Inf. Theory, vol. 59,
no. 6, pp. 3451–3465, 2013.
VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

[38] W. Wang, M. J. Wainwright, and K. Ramchandran, “Information-theoretic
limits on sparse support recovery: Dense versus sparse measurements,” in
Proc. IEEE Int. Symp. Inf. Theory (ISIT), 2008, pp. 2197–2201.
[39] K. R. Rad, “Nearly sharp sufficient conditions on exact sparsity pattern
recovery,” IEEE Trans. Inf. Theory, vol. 57, no. 7, pp. 4672–4679, 2011.
[40] K. Kulkarni, S. Lohit, P. Turaga, R. Kerviche, and A. Ashok, “Reconnet:
Non-iterative reconstruction of images from compressively sensed measurements,” in Proc. IEEE Conf. Comput. Vision and Pattern Recognit.
(CVPR), 2016, pp. 449–458.
[41] M. Borgerding, P. Schniter, and S. Rangan, “Amp-inspired deep networks
for sparse linear inverse problems,” IEEE Trans. Signal Process., vol. 65,
no. 16, pp. 4293–4308, 2017.
[42] A. Değerli, S. Aslan, M. Yamac, B. Sankur, and M. Gabbouj, “Compressively sensed image recognition,” in Proc. Eur. Workshop Vis. Inf. Process.
(EUVIP), 2018, doi: 10.1109/EUVIP.2018.8611657.
[43] S. Lohit, K. Kulkarni, and P. Turaga, “Direct inference on compressive
measurements using convolutional neural networks,” in Proc. IEEE Int.
Conf. Image Process. (ICIP), 2016, pp. 1913–1917.
[44] D. T. Tran, M. Yamaç, A. Degerli, M. Gabbouj, and A. Iosifidis, “Multilinear compressive learning,” IEEE Trans. Neural Netw. Learn. Syst., 2020,
doi: 10.1109/TNNLS.2020.2984831.
[45] M. d. l. I. Vayá, J. M. Saborit, J. A. Montell, A. Pertusa, A. Bustos,
M. Cazorla, J. Galant, X. Barber, D. Orozco-Beltrán, F. Garcia et al.,
“BIMCV COVID-19+: A large annotated dataset of RX and CT images
from COVID-19 patients,” arXiv:2006.01174, 2020. [Online]. Available:
https://arxiv.org/abs/2006.01174
[46] “COVID-19 image repository,” https://github.com/ml-workgroup/
covid-19-image-repository, 2020, (accessed 16 September 2020).
[47] “COVID-19 database,” https://www.sirm.org/category/senza-categoria/
covid-19/, 2020, (accessed 16 September 2020).
[48] “COVID-19
Spain
CXR,”
https://threadreaderapp.com/thread/
1243928581983670272.html, 2020, (accessed 16 September 2020).
[49] “Radiopaedia COVID-19 CXR,” https://radiopaedia.org/playlists/25975?
lang=us, 2020, (accessed 16 September 2020).
[50] A. Bustos, A. Pertusa, J.-M. Salinas, and M. de la Iglesia-Vayá, “Padchest:
A large chest X-ray image dataset with multi-label annotated reports,”
Med. Image Anal., 2020, doi: 10.1016/j.media.2020.101797.
[51] “RSNA pneumonia detection challenge,” https://www.kaggle.com/c/
rsna-pneumonia-detection-challenge/overview, 2018, (accessed 22
September 2020).
[52] D. Demner-Fushman, M. D. Kohli, M. B. Rosenman, S. E. Shooshan,
L. Rodriguez, S. Antani, G. R. Thoma, and C. J. McDonald, “Preparing
a collection of radiology examinations for distribution and retrieval,” J.
Amer. Med. Inform. Assoc., vol. 23, no. 2, pp. 304–310, 2016.
[53] S. Jaeger, S. Candemir, S. Antani, Y.-X. J. Wáng, P.-X. Lu, and G. Thoma,
“Two public chest X-ray datasets for computer-aided screening of pulmonary diseases,” Quant. Imaging Med. Surg., vol. 4, no. 6, pp. 475–477,
2014.
[54] “Chest X-ray images (pneumonia),” https://www.kaggle.com/
paultimothymooney/chest-xray-pneumonia,
2018,
(accessed
16
September 2020).
[55] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro,
G. S. Corrado, A. Davis, J. Dean, M. Devin et al., “Tensorflow:
Large-scale machine learning on heterogeneous distributed systems,”
arXiv:1603.04467, 2016. [Online]. Available: https://arxiv.org/abs/1603.
04467
[56] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv:1412.6980, 2014. [Online]. Available: https://arxiv.org/abs/1412.
6980
[57] A. Y. Yang, Z. Zhou, A. G. Balasubramanian, S. S. Sastry, and Y. Ma, “Fast
l1 -minimization algorithms for robust face recognition,” IEEE Trans.
Image Process., vol. 22, no. 8, pp. 3234–3246, 2013.
[58] K. Koh, S.-J. Kim, and S. Boyd, “An interior-point method for large-scale
l1 -regularized logistic regression,” J. Mach. Learn. Res., vol. 8, pp. 1519–
1555, 2007.
[59] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein et al., “Distributed
optimization and statistical learning via the alternating direction method
of multipliers,” Found. Trends Mach. Learn., vol. 3, no. 1, 2011, doi:
10.1561/2200000016.
[60] D. M. Malioutov, M. Cetin, and A. S. Willsky, “Homotopy continuation
for sparse signal representation,” in Proc. IEEE Int. Conf. Acoust., Speech,
and Signal Process. (ICASSP), vol. 5, 2005, pp. 733–736.
[61] M. A. Figueiredo, R. D. Nowak, and S. J. Wright, “Gradient projection
for sparse reconstruction: Application to compressed sensing and other
VOLUME 9, 2021

inverse problems,” IEEE J. Sel. Topics Signal Process., vol. 1, no. 4, pp.
586–597, 2007.
[62] E. Candes and J. Romberg, “l1 -magic: Recovery of sparse signals via convex programming,” Caltech, Tech. Rep., 2005. [Online]. Available: https:
//statweb.stanford.edu/~candes/software/l1magic/downloads/l1magic.pdf

METE AHISHALI received the B.Sc. degree
(Hons.) in Electrical and Electronics Engineering from Izmir University of Economics, Izmir,
Turkey, in 2017, and the M.Sc. degree in Data
Engineering and Machine Learning from Tampere University, Tampere, Finland, in 2019. Since
2017, he has been working as a researcher in
Signal Analysis and Machine Intelligence research
group under the supervision of Prof. Gabbouj,
and he is currently pursing the Ph.D. degree in
Computing and Electrical Engineering at Tampere University. His research
interests are pattern recognition, machine learning, and semantic segmentation with applications in computer vision, remote sensing, and biomedical
images.

AYSEN DEGERLI received the B.Sc. degree
(Hons.) in Electrical and Electronics Engineering
from the Izmir University of Economics, Izmir,
Turkey, in 2017, and the M.Sc. degree (Hons.)
in Data Engineering and Machine Learning from
Tampere University, Tampere, Finland, in 2019,
where she is currently pursuing the Ph.D. degree
in Computing and Electrical Engineering. She is
currently a Doctoral Researcher in Signal Analysis
and Machine Intelligence research group led by
Prof. M. Gabbouj with Tampere University. Her research interests include
machine learning, compressive sensing, and biomedical image processing.

MEHMET YAMAC received his B.S. degree
in Electrical and Electronics Engineering from
Anadolu University, Eskisehir, Turkey, in 2009
the M.S. degree in Electrical and Electronics
Engineering from Bogazici University, Istanbul,
Turkey, in 2014. He was research and teaching
assistant at Bogazici University during 2012-2017.
He is currently a Ph.D. candidate at the Department of Computing Sciences, Tampere University,
Tampere, Finland. His research interests are computer and machine vision, machine learning and compressive sensing.
13

Ahishali et al.: Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

SERKAN KIRANYAZ (SM’13) is a Professor
in Qatar University, Doha, Qatar. He published
2 books, 5 book chapters, more than 70 journal
papers in high impact journals, and 100 papers in
international conferences. He made contributions
on evolutionary optimization, machine learning,
bio-signal analysis, computer vision with applications to recognition, classification, and signal processing. Prof. Kiranyaz has co-authored the papers
which have nominated or received the “Best Paper
Award” in ICIP 2013, ICPR 2014, ICIP 2015 and IEEE TSP 2018. He
had the most-popular articles in the years 2010 and 2016, and most-cited
article in 2018 in IEEE Transactions on Biomedical Engineering. During
2010-2015 he authored the 4th most-cited article of the Neural Networks
journal. His research team has won the 2nd and 1st places in PhysioNet
Grand Challenges 2016 and 2017, among 48 and 75 international teams,
respectively. In 2019, he won the “Research Excellence Award” and “Merit
Award” of Qatar University. His theoretical contributions to advance the current state of the art in modelling and representation, targeting high long-term
impact, while algorithmic, system level design and implementation issues
target medium and long-term challenges for the next five to ten years. He
in particular aims at investigating scientific questions and inventing cutting
edge solutions in “personalized biomedicine” which is in one of the most
dynamic areas where science combines with technology to produce efficient
signal and information processing systems meeting the high expectation of
the users

MUHAMMAD E. H. CHOWDHURY received
his B.Sc. degree and M.Sc. degree with record
marks from the department of Electrical and Electronics Engineering at the University of Dhaka,
Bangladesh. He acquired his Ph.D. degree from
the University of Nottingham, U.K. at 2014. He
is currently working as a full-time faculty at Electrical Engineering department, Qatar University.
He worked as Post-doctoral research fellow and
Hermes Fellow at the Sir Peter Mansfield Imaging Centre in the University of Nottingham, U.K. Prior to joining Qatar
University, he worked in several universities of Bangladesh. His current
research interests include biomedical instrumentation, machine learning,
signal processing, wearable sensors, medical image analysis, computer
vision, embedded system design, biomedical implants and simultaneous
EEG/fMRI. He has a patent and published 48 peer reviewed journal articles,
29 conference papers and two book chapters. Dr. Chowdhury is currently
running several NPRP and UREP grants from QNRF and internal grants
from Qatar University along with academic and government projects. He
has been involved in EPSRC, ISIF and EPSRC-ACC grants along with
different national and international projects. He has worked as consultant for
the projects entitled, “Driver Distraction Management Using Sensor Data
Cloud (2013-14, Information Society Innovation Fund (ISIF) Asia)”. He
has received ISIF Asia Community Choice Award 2013 for project entitled
“Design and Development of Precision Agriculture Information System
for Bangladesh”. He has recently won COVID-19 dataset award for his
contribution to fight against COVID-19. He is an active member of IEEE,
British Radiology, Institute of Physics, ISMRM and HBM. He is severing
as an Associate Editor for IEEE Access and Review Editor for Frontiers in
Neuroscience.

14

KHALID HAMEED is young enthusiastic doctor
with particular interest in Artificial intelligencebased work in the field of radiology. His recent publication includes X-ray imagining in
COVID-19. He is affiliated with Hamad Medical
corporation-Qatar and have worked at Reem Medical Center-Qatar.

TAHIR HAMID (MRCP-UK, FESC) has been
working as interventional cardiology consultant
at Heart Hospital, Hamad Medical Corporation,
Doha Qatar. He has been trained in United Kingdom and at University of Toronto, Canada. He
has about 27 publications and presented at various cardiology conferences. Currently, conducting randomized control trial about “pre-procedural
fasting in patients undergoing coronary interventions” at Toronto General Hospital, University of
Toronto. He has published the following study related to ECG monitoring
in patients with recurrent blackouts: “Prolonged implantable electrocardiographic monitoring indicates a high rate of misdiagnosis of epilepsy REVISE study”, Europace. Nov. 2012;14(11):1653-60. This study revolutionized the assessment of patient blackout who were wrongly labeled as
epileptics and were later found after prolonged monitoring, to have cardiac
rhythm related issues leading to blackouts. He is currently actively involved
in the research projects at Hamad Medical Corporation. He is currently
working on his project about external cardiopulmonary resuscitation devices
for patients who sustain cardiac arrests.

RASHID MAZHAR (MBBS, MCPS, FCPS,
FRCS-Glas, FRCS-Edinb.) has more than twenty
years of experience in the field of cardiothoracic
surgery. He is currently the head of the Thoracic
surgery section at the Hamad General hospital,
Doha, Qatar. Besides his surgical, clinical and
educational activities, he has a particular interest
and track record for collaborating with engineering colleagues to bring about user-end driven innovative solutions in his field of specialization.
Automation, objective monitoring and user-friendly signal processing are
his main areas of interest. Dr. Rashid is the winner of the Academic Health
System Innovation award in 2014 and 2015 by proposing “Oro-Tracheal
Defibrillator – a novel device to improve the outcome of CPR” and “Resuscitation Monitor - another novel device to improve the outcome of CPR”,
respectively. He recently filed the patent, “Q-Stent”: which is filed through
Academic Health System, HMC (PCT/IB2014/002337; WO/2016/012829).
The device is already in regular clinical use at HMC paediatric and adult
cardiac surgery.

VOLUME 9, 2021

Ahishali et al.:Advance Warning Methodologies for COVID-19 using Chest X-Ray Images

MONCEF GABBOUJ (F’11) is a wellestablished world expert in the field of image processing, and held the prestigious post of Academy
of Finland Professor during 2011-2015. He has
been leading the Multimedia Research Group for
nearly 25 years and managed successfully a large
number of projects in excess of 18M Euro. He
has supervised 45 PhD theses and over 50 MSc
theses. He is the author of several books and over
700 papers. His research interests include Big
Data analytics, multimedia content-based analysis, indexing and retrieval,
artificial intelligence, machine learning, pattern recognition, nonlinear signal
and image processing and analysis, voice conversion, and video processing
and coding. Dr. Gabbouj is a Fellow of the IEEE and member of the
Academia Europaea and the Finnish Academy of Science and Letters. He
is the past Chairman of the IEEE CAS TC on DSP and committee member
of the IEEE Fourier Award for Signal Processing. He served as associate
editor and guest editor of many IEEE, and international journals.

VOLUME 9, 2021

15

