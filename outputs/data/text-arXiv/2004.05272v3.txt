ORIGINAL RESEARCH ARTICLE
Modeling the Heterogeneity in COVID-19’s Reproductive Number
and Its Impact on Predictive Scenarios

arXiv:2004.05272v3 [stat.AP] 11 Jan 2021

Claire Donnata and Susan Holmesb
a

Department of Statistics, University of Chicago, 5747 S Ellis Ave, Chicago IL 60637, USA;
Department of Statistics, Stanford University, 390 Jane Stanford Way, Stanford CA 94305,
USA;
b

ARTICLE HISTORY
Compiled January 12, 2021
ABSTRACT
The correct evaluation of the reproductive number R for COVID-19 —which
characterizes the average number of secondary cases generated by each typical primary case— is central in the quantification of the potential scope of the pandemic
and the selection of an appropriate course of action. In most models, R is modeled as a universal constant for the virus across outbreak clusters and individuals
— effectively averaging out the inherent variability of the transmission process due
to varying individual contact rates, population densities, demographics, or temporal factors amongst many. Yet, due to the exponential nature of epidemic growth,
the error due to this simplification can be rapidly amplified and lead to inaccurate
predictions and/or risk evaluation. From the statistical modeling perspective, the
magnitude of the impact of this averaging remains an open question: how can this
intrinsic variability be percolated into epidemic models, and how can its impact on
uncertainty quantification and predictive scenarios be better quantified? In this paper, we propose to study this question through a Bayesian perspective, creating a
bridge between the agent-based and compartmental approaches commonly used in
the literature. After deriving a Bayesian model that captures at scale the heterogeneity of a population and environmental conditions, we simulate the spread of the
epidemic as well as the impact of different social distancing strategies, and highlight
the strong impact of this added variability on the reported results. We base our
discussion on both synthetic experiments — thereby quantifying of the reliability
and the magnitude of the effects — and real COVID-19 data. We emphasize that
the contribution of this paper focuses on discussing the importance of the impact of
R’s heterogeneity on uncertainty quantification from a statistical viewpoint, rather
than developing new predictive models.
KEYWORDS
Bayesian Statistics | Probabilistic Models| COVID-19
CONTACT Claire Donnat. Email: cdonnat@uchicago.edu

1. Introduction
First detected in Wuhan (Hubei Province, China) in December 2019, the current
COVID-19 pandemic has thrown the entire world in a state of turmoil, as governments
closely monitor the spread of the virus and have taken unprecedented measures to
contain and control outbreaks. In this context, the provision of accurate predictive
scenarios is crucial for informing policy makers and deciding on the best course of
action. Much attention has focused on the monitoring of one quantity: the pandemic’s
reproductive number R. This parameter is indeed key in almost all contagion models,
whether these scenarios are drawn using variants of the Susceptible-Exposed-InfectedRemoved (SEIR) deterministic equations [17, 21, 26, 31] or of exponential growth
models [34].

1.1. Reproductive Number(s)
By definition, the reproductive number R characterizes the expected number of secondary cases caused by an infectious patient. Experts usually contrast the basic reproductive number (typically denoted R0 ) — which assumes that the population is
completely susceptible and is well adapted to the modeling of a completely novel virus
— with the context-dependent effective Rt — which assumes a mixed population of
susceptible and immune hosts at time t, that varies with time and the implementation
of various policies. Regardless of these assumptions, another way of understanding these
reproductive numbers (denoted more generally as R throughout this paper) is through
their decomposition as the product of three terms [9]:
R = τ c̄DI

(1)

where τ is the transmissibility (i.e., probability of infection given contact between a
susceptible and infected individual), c̄ is the average number of contact per day between
susceptible and infected individuals, and DI is the duration of infectiousness — that is,
the number of days during which an infected patient can be expected to contaminate
others. R thus serves as an epidemiological metric to describe the propensity of the
epidemic to grow: the outbreak is expected to propagate if R is greater than 1, or to
naturally subside if R is strictly less than 1. As recently highlighted by Delameter et
al. [11], this coefficient inherently depends on some individual and local population
characteristics, as well as seasonal and environmental variables. In particular, as shown
in Eq. 1, R is intrinsically tied to temporal and spatially-varying factors, such as
a population’s age demographics and density, political or environmental variables,
cultural or social dynamics — all favoring or diminishing the rate of contacts c̄ between
individuals. This decomposition thus brings to light several sources of variability for R:

2

• Temporal variability: as time progresses and public policies (e.g, mask wearing,
social distancing, etc.) change, we expect the contact rate, as well as the transmissibility to vary — thereby introducing a change in the expected number of
secondary cases that R models.
• Subject variability: communities can be well modeled by social networks, in
which edges represent the contacts patterns. These models capture the important
heterogeneity in the population’s contact rates, typically correlated to one’s age,
profession, etc.
These sources of variability pose a serious challenge to epidemiological models,
particularly in light of the increasing accounts of super-spreading phenomena through
the literature [5, 14, 19, 27, 32]. Evidence seems to hint to the Pareto nature of the
reproductive number, with 10% of the individual cases potentially accounting for almost
80% of the virus spread [24]: the current pandemic appears to be driven by rare, yet
important contagion events. Scientific evidence thus points towards the huge variability
in the distribution of R, which should be considered as a random variable rather than
a fixed number.

1.2. Subject variability in epidemics models
Current epidemics models can generally be placed on either of the two ends of
a spectrum, depending on their ability to account for subject and environmental
heterogeneity. Indeed, while temporal variability is typically modeled using an effective
time-varying Rt instead of the constant R0 , other sources of heterogeneity are seldom
really accounted for by compartmental models, but can be included in agent-based
models — often at huge computational expenses.
Compartmental Models. Compartmental models for disease modeling are one of
the most popular frameworks for predicting the evolution of an epidemic. These models
build upon a division of the population into states or “compartments”, the evolution
of which being determined by a set of fixed, deterministic equations. In the case of
COVID-19, the Susceptible-Exposed-Infected-Removed (SEIR) model seems to have
been the most used among experts [7, 15, 16, 25, 31, 33]. In this setting, each group (or
community) k of size Nk is split in one of four different compartments : people are either
susceptible, exposed, infected or removed (including recoveries and deaths). In this class
of models, broadly speaking, the evolution of the populations in each compartment is
modeled through versions of the following set of differential equations:

3

(k)

dSk (t)
Sk (t) R0
Ik (t)
=−
dt
Nk DI
(k)

dEk (t)
Sk (t) R0
Ek (t)
=−
Ik (t) −
dt
Nk DI
DE
dIk (t)
Ek (t) Ik (t)
−
=
dt
DE
DI

(2)

where:
• Sk (t), Ek (t), Ik (t), and Rk (t) are the number of susceptible, latent, infectious, and
removed individuals at time t in group k;
• DE and DI are the mean latent (assumed to be the same as incubation) and
infectious period (equal to the serial interval minus the mean latent period);
(k)
• R0 is the basic reproductive number is population k.
In these models, the parameters DE and DI are typically fixed and taken from medical
(k)
reports – while R0 is inferred and fitted on the available data. While simple from both
a theoretical and computational perspective, this class of models exhibits nonetheless
several drawbacks. First of all, this deterministic set of equations does not provide any
natural uncertainty quantification — a crucial aspect of any model, especially given that
all the parameters that are fed into these equations are (informed) guesses, that come
with their own level of uncertainties. But the main drawback consists in these models’
agnosticism to population heterogeneity. Indeed, while temporal transmissibility is
captured by certain compartmental models, which have replaced the R0 with a contextdependent R, allowing to capture the variation of the transmissibility due to public
policies, seasonal effects, etc, the heterogeneity of the R in the population is seldom
considered. While some studies have introduced stochastic components in SEIR models
(for instance in the study of Ebola [22]), it is however not standard to take into account
any component of stochasticity in the reproductive number. As a way around this
heterogeneity, some [10, 12, 23] have divided compartments by stratifying with respect
to age to account for varying contact rates across age groups. Yet, this stratification
only takes into account one axis of variability (e.g., the age), and neglects other sources
of variance, such as people’s occupations, varying risk-exposure index, etc., — thus
failing to reproduce the variability that is observed in real life, and potentially hindering
the accuracy of any downstream analysis and predictive scenarios.
In fact, the “universal” R used in these epidemiological models to characterize the
disease can be thought of as a general summary statistic, averaged over individuals and
populations — thus discarding any form of local variability. In the standard framework,
the heterogeneity of R is partially accounted for by fitting the model to local data
(typically at the country or county level), but thus effectively (a) discarding information
that could be shared across groups by fitting each local model independently and (b) ne-

4

𝝀𝒈𝒕
Xg,t-3

Xg,t-2

Xg,t-1

Xgt

Incident cases

Time t

Individual behaviours

Group g

Figure 1. Plate model for simulating the transmission dynamics in agent-based models. At every time step,
individual behaviours are simulated to infer the number of contacts and new infections.

glecting the inherent variability in this coefficient at the individual level. The latter can
in particular become problematic, due to the exponential nature of the epidemics growth
— a phenomenon that we propose to investigate here. In other words, this class of model
typically works with a granularity at the group level (age group, etc.). Thus, while
this framework can capture global tendencies across individuals (social mores, policy
measures, etc), it is difficultly amenable to the incorporation of sufficient heterogeneity
(due to subject characteristics, environmental variables, etc.) in the reproductive number.
Agent-based Models. On the other extreme side of the spectrum, agent-based
models allow maximal flexibility by modeling the behavior of individual agents
[2, 6, 20, 28, 29]. In [2] and [6] for instance, the authors are able to leverage mobility
data (typically acquired using cellphone data) in order to simulate the interactions
(and thus, transmission dynamics) and analyze the impact of different social distancing
policies in the context of the COVID-19 outbreaks. Compared to the compartmental
models, the granularity for this class of models is at the individual level: all the
individual trajectories are computed in order to infer the transmission dynamics (see
Fig. 1). While able to capture the wide variability of behaviours, the success of such
models is contingent on (a) huge computational resources and data sources to simulate
individual behaviors and (b) quality data on mobility and behaviors on which to base
behavioral estimates. Moreover, these models make it more difficult to model the effect
of exterior variables, such as weather conditions, impacting all agents. Thus, while this
class of models allows for maximal subject heterogeneity, it does not lend itself to the
modeling of global tendencies across agents.
Given the limitations and cost of estimating behaviours at the agent-level, in
this paper, we propose to bridge these two classes of models through a Bayesian
approach that allows us to capture the effect of the variance in the reproductive
5

number on predictive scenarios, whilst remaining computationally tractable. The
main purpose of this paper is to understand the impact of this heterogeneity on
potential downstream epidemic scenarios. As such, our focus will be on quantifying the
impact of the heterogeneity on the distribution of projected case estimates, worst-case
scenarios, etc. In the first section, we will begin our discussion with a set of synthetic
experiments, which will allow us to quantify the discrepancy between the standard
“averaged” and our “distributional” reproductive numbers. In the second, we will present
a Bayesian model that we have found to be amenable to the modeling of COVID-19
trajectories observed in real life, and discuss the differences that it yields compared to
more standard SEIR models in the third, and its potential implications for policy makers.
Additional note. We emphasize that the randomness in the R that is being considered
here is solely due to population heterogeneity and potential environmental variables,
and not to measurement error. In other words, we assume that the cases are perfectly
observed, and that the variability might not be due to testing capacities and underreporting. Our Bayesian formalism could be extended to include this other level of
randomness, but for the purpose of this particular discussion, we focus on subject
heterogeneity, and leave the inclusion of measurement error to later improvements.

2. The impact of the added variability
Intuitively, the simplification of the distribution of Rs in a population to a constant
value can be justified by the assumption that the dynamics of the pandemic
are similarly described by the trajectory estimated using the average R, or the
average of the epidemic’s trajectories with varying R. Yet, because the number of
new cases each day depends exponentially on the history of the trajectory, this
averaging approximation might come at a huge accuracy cost in prediction models.
In this section, we aim to provide a more quantitative description of the potential effects of this additional variability on the model. Let us start with two naive experiments.
First Experiment: Inherent effect of the randomness on the model. In the
first experiment, we consider a simplified epidemic exponential growth model. Given the
value for the reproductive number R, each new infectious case i generates a Poisson(Ri )
number of new cases the following day. This simplified model amounts to considering
an instantaneous incubation period and a duration of infection of only one day. We can
model the variability in people’s secondary infection rates by considering the secondary
infections as Poisson-generated counts. At each time t, the number of new incident
cases the next day is thus generated as:
Xt+1 = Poisson(λt ),

6

E[λt ] = Xt E[R]

where λt is the total incidence rate on day t. Let us first study the heterogeneity in
reproductive numbers by comparing the baseline model (M0 ) in which R = R0 is
constant, to one where R is a random variable (Ma ) centered around the same value
R0 :
M0 :

Xt+1 = Poisson(Xt R0 )

vs

Ma :

Xt+1 = Poisson(λt ),

E[λt ] = Xt R0

where λt is the total aggregated reproductive number for day t, and is a function of
the number of cases Xt at day t. To understand the effect of the variance in λ, we
consider three probability distributions for λt , yielding different coefficients of variation
CV (defined as the ratio of standard deviation over mean, and which we use here as a
metric to characterize the dispersion of the distribution) for λt :
• M0 : Constant R, CV (λt ) = 0: in this “null” model, we assume that R is a fixed
P t (t)
quantity across subjects. The aggregated incidence rate λt = X
i=1 Ri for the
group of people infected at day t is given by: Rt = Xt R0 .
∆
• M1 : Variable R, limXt →∞ CV (λt ) = 0, with λt = Γ(αR0 Xt , α). This first alternative model is equivalent to considering that each infected case at day t has a
∆
random emission rate sampled from a Gamma distribution Ri = Γ(αR0 , α), so
PXt
∆
that: λt = i=1 Ri = Γ(Xt αR0 , α). In this scenario, on average, the aggregated
incidence rate λt for day t is the same as in model M0 , but the variance of the
model is given by Var[λt ] = XtαR0 . Thus, the variance of the model scales linearly
with the number of cases, while its coefficient of variation is: CV = √αR1 X and
0 t
tends to 0 as the number of cases increases.
∆
• M2 : Variable R, Constant CV (λt ), with λt = Γ(αR0 , α/Xt ). This model as(t)

sumes that each subject Ri
∆

on day t is Gamma(αR0 , α)-distributed, such that:

∆

λt = Xt Γ(αR0 , α) = Γ(αR0 , α/Xt ). In this scenario, the model has variance
2
1
Var[λt ] = XtαR0 , and constant coefficient of variation CV = √αR
.
0

These configurations allow us to study models with different levels of dispersion
around the expected mean R0 Xt – which we use to quantify the amount of subject
heterogeneity. We can further assume that, for simplification purposes, exactly 1% of
these incident cases will not recover from the disease, so that the cumulative number
P
of deaths at time t can be written as Dt = 0.01 ts=1 Xs . Using this very simple
generative model, we generate different epidemic trajectories assuming fixed R0 and
variable Rs.
The results of these simulations are displayed in Fig. 2. Based on those simulations,
we make the following observations.
(a) The inclusion of some amount of randomness alters the distribution of
the trajectories, especially in the tails. Fig. 2(A,B,D) show the 99% confidence
intervals of the trajectories at each time step, for a mean value of R0 ∈ {1, 1.5}, and
7

1e+03

1e+02
mean

Type
Constant R=1
Random
R=Gamma(10,10)

1e+01

1e+00
x

Median
Mean

0

25

50
x

75

100

(B) Constant CV: Comparison of the 99% confidence intervals for
the cumulative number of deaths, for constant R=1 vs random R.

(A) Decreasing CV: Comparison of the 99% confidence intervals for
the cumulative number of cases, for constant R=1 vs random R.
0.4

1e+8

0.3

Random R=Gamma(10,10)

0.2

Constant R=1.5

Type

n

density

type
1e+05

Constant R=1.5
Random
R=Gamma(15,10)

Random R=Gamma(15,10)
Constant R=1.0

0.1

0.0
25

50

75

Median
Mean

1e+02

0

100

(C) Constant CV: Comparison yof the distribution of the stopping time
(number of deaths reaching 5,000) for constant vs random R

10

20

30

40

50

(D) Constant CV: Comparison of the 99% confidence intervals for
the cumulative number of deaths, for constant R=1 vs random R.

Figure 2. Simulations of the different epidemic trajectories, using various models for the daily new incident
cases generation rate λt : a first benchmark model with constant, “averaged” R0 (Model M0 , shown in light red
on panels A, B and D, and in warm colors on panel C), a model with variable R and decreasing Coefficient of
Variation (CV) (Model M1 , with CV → 0, shown in teal on panel A), and a model with constant CV (Model
M2 , shown in teal on panels B and D, and on panel C). As a reminder, the coefficient of variation is defined as
the ratio of the standard deviation over the mean, and can be used as a way of quantifying the dispersion of the
model. We note in particular how seemingly alike the trajectories seem in average for R0 = 1 in models M0 and
M2 (panel B), but how substantially different their tail estimates are.

8

where the variable λt is sampled from models M0 , M1 and M2 . These figures highlight
that some of the most striking differences between models are located in the tails. In
particular, Fig. 2(B) presents a choice of parameters for model M2 for which, while the
mean number of cases appears to be similar, the tails (represented by the 99th quantile)
differ by orders of magnitude. This is an important observation: average predictions
for the fixed and variable R models can look seemingly the same, yet their associated
uncertainty estimates and catastrophic scenarios are radically different. This divergence
particularly striking between models M0 and M2 and increases for R0 = 1.5, a scenario
in which the pandemic is expected to rapidly increase.
(b) The higher the volatility of R, the greater the divergence with models
assuming constant R. The tail discrepancy between models M0 and M1 — whose
coefficient of variation tends to 0 as Xt increases — is less substantial than with model
M2 (with constant positive CV, independently of Xt ) : the 99th quantile for model M1
slowly diverges from M0 , but the difference after 100 time steps is only of the order of
25 percent (compared to orders of magnitude for M2 ). While intuitive, this is important
to note: the adequacy and impact of the averaging of the R made by SEIR models are
contingent on the R’s inherent subject variability in the population. The more volatile
the distribution of R, the greater the potential deviation of the epidemic trajectory
from the projected SEIR one.
(c) Worst-case scenarios are different – not only in magnitude, but also in
the events that they allow. Let us consider a specific event, which we choose here
to be “The number of deaths reaches 5,000”, and let us display in Fig. (Fig 2C) the
distribution of its associated stopping time. For M0 with R0 = 1, this stopping time
τ = min{t ∈ N : Dt ≥ 5, 000} is never reached. It is nonetheless reached in 0.19%
of cases using a varying R (with model M2 , in Fig 2C), thus making it a non-zero
probability event and enlarging the space of possible events. The variable-R model thus
presents a wider scope of worst-case scenarios than the ones predicted using a constant,
average R0 — a potentially crucial fact whilst having to decide on any type of policy.
Second Experiment: effect of the randomness on the estimation procedure.
We have shown that a constant R0 might lead to an incorrect model of the distribution
of probable epidemic trajectories – we now also assess how the error induced by
averaging is also reverberated in the estimation procedure. In this second experiment,
we simulate an exponential growth of the number of incident cases over the course
of 20 days using model M1 and a gamma-distributed R with shape 1.2 and rate 1.
This mimics a scenario under which R varies every day, thus accounting for some
temporal effects (weekend vs week days), subject-effects across newly infected cases,
etc. Let us now try to recover the reproductive number R using the Exponential
Growth model in the R-package R0. The average difference between the recovered
and true mean R0 over 1,000 simulations is 2.94 (with only 8.5 % coverage by the
recovered confidence intervals). This brings to light two new observations: (a) standard

9

R estimation procedures — which assume a constant fixed R — seem to perform even
less well with variable R, and (b) the usual confidence intervals are too narrow, and do
not correctly account for the high uncertainty of the predicted R value.
In light of these synthetic experiments, assuming the reproductive number R to be
constant comes at a huge cost in terms of accuracy of the reported predictive scenarios.
In particular, the worst-case scenarios associated to these predictions could be either
(i) too optimistic without appropriately characterizing their uncertainty, (ii) unable to
account for the existence of “super-spreaders” in the general population, and (iii) fail
to allow certain rare events leading to the formation of outbreaks — thus potentially
misleading policy makers and begging the question: for the analysis of real data, how
much variability do we need to account for in the modeling of R? Is the aggregated
version sufficient to provide informative scenarios, or is a hierarchical model preferable?
From a statistical viewpoint, accounting for the R’s variability is similar to using
a “random-effects” model — that is, endowing the reproductive number R with a
distribution and allowing it to vary across subjects. In this paper, we assume that
the distribution of R remains stationary over time. We fit the model over periods
of time where policies are expected to be similar, and where we do not expect a
dramatic change in the distribution of the reproductive number. Further extensions
of this model would include adding other independent variables. In particular, a more
granular estimation of the dependency of R on geographical, weekday, weather, and
other sources of information could make day-to-day variations in the R provide more
realistic epidemiological predictions of the outbreak propagation speed, as well as the
expected times before hospitals reach capacity — both crucial quantities for informing
policy makers as they arbitrate between different courses of action, especially as drastic
public health measures typically come at significant social and economical costs. We
do not focus on fitting any of these predictors here, nor we will fit a temporal trend
line to our estimation of R. We emphasize that our goal is not to come up with a new
model or definition for R, nor to pretend to a better predictive model than experts
in epidemiology. Rather, our focus is simply to assess – as statisticians – the effect of
this added variability in predictive scenarios, in order to better understand how this
variability is propagated in downstream analyses.
One of the hypotheses that we would like to test is if the heterogeneity of the R
coefficient can severely impact predictive scenarios for the outbreaks: how certain are
we about the predictions that we are making? In light of the observed heterogeneity of
the R’s, how confident are we of the transferability of a given policy in one country to
another?
Here, we deal with stochasticity and limited/missing data using a Bayesian perspective.
We begin by describing the Bayesian hierarchical model that we use to estimate the
varying reproductive number R. This approach provides a more natural framework
for uncertainty quantification through the provision of credible intervals. We show the

10

impact of this variability on the predictive scenarios and the effect of public policy
measures (e.g. social distancing or alternating lockdown days) that can be drawn using
these models. All of our experiments here are deployed on the current COVID-19
pandemic. The code and data used for this analysis are openly available on the authors’
Github1 .

3. Model and Theory
In this section, we begin by designing and fitting a Bayesian model to real COVID-19
data — which we will then use to evaluate the effects of different policies on outcomes
of interest (daily and cumulative number of cases).
Model. Our model is similar to the one previously used in the experimental section
of this paper and based on the non-parametric model developed by Fraser [13] and
later used for estimating the R0 in Cori et al [8]. This model is well-established and
implemented in the R-package EarlyR [30], and it has been used in recent studies [34] to
infer COVID 19’s R0 . Instead of explicitly modeling the exposed and infected periods
separately, this model foregoes the modeling of latent cases and relies solely on inferring
the number of new cases from previous observations using an “infectivity profile” [8]. In
this setting, each infected case is expected to contaminate on average of R0 patients (by
definition) — but the distribution of this number of new infections over the infectious
period is given by a probability distribution which only depends on the time s elapsed
since infection. One could indeed imagine a patient becoming increasingly contagious
over the first few days of the infection as the viral load builds up, and decreasingly so
after the peak of the illness. This infectious profile is typically modeled as the quantiles
from a gamma distribution. Since this quantity is generally unknown and hard to
estimate from available data, Cori et al [8] propose the use of the parameters of the
serial interval (for which we typically have much more substantial observational data
and means of estimation) as a good proxy.
We call Xt the number of new infectious cases each day, and let It be the number of
total new infections caused by the Xt subjects infected on day t (in short, It is the total
number of secondary cases due to the Xt new cases on day t). The incidence on day t
conditioned on the history of previously infected cases can be modeled by a Poisson
distribution of the form:
∀t ≤ T,

t−1
X
Xt ∼ Poisson(
ws It−s )
s=1

1 Code

and data at: https://github.com/donnate/heterogeneity_R0

11

with:

E[It ] = Xt−s E[Rt ].

(3)

This condition captures the fact that It is the sum of all the new cases generated
by each single patient. In the previous equation, ws = K−s+1
is a vector such that
K+1
2
P
s ws = 1. Note that, contrary to Cori et al [8],we have not taken ws to be the serial
interval. As detailed in Appendix ??, this choice of ws provides indeed a better fit to
the data.
The crux of the problem consists in specifying an adequate distribution for It , such
that it verifies the condition E[It ] = Xt E[Rt ]. We take It here to be gamma-distributed,
with shape and rate parameters a and b. While different choices of parametrizations
allow condition 3 to be satisfied, we opt for one that allowing the best fit and amount
of stochasticity:
∀g,

αg ∼ N (0, 1)
βg ∼ N (0, 1)

∀t, g,
∀t, g,

(4)

It,g ∼ Gamma((1 + eαg ), (1 + eβg )/Xt,g )
X
Xt,g ∼ Poisson(
wk It−k )
k

where the subscript g denotes the group and emphasizes the fact that each region/group
is fitted independently and where we have taken the shape a to have the form 1 + eα ,
and b to be parametrized as 1 + eβ . The full model is summarized by the plate model
provided in Figure 3. We also provide in the appendix a more detailed discussion on
the choice of the model, the choice of the priors, as well as all technical details related
to the fitting procedure, and focus in the main text on the analysis of the subsequent
results.
Interpretation of the model. This model (M1 ) is akin to a multiplicative model,
rather than an additive one (M0 , here provided for comparison):
∆

∆

M1 : λt = Xt Γ(a, b) = Γ(a, b/Xt )

vs

∆

M0 : λ t =

Xt
X

∆

Γ(a, b) = Γ(aXt , b)

i=1
β
with a = eα + 1 and
q b = e + 1. While intuitive, model M0 has a small coefficient
b
of variation CV = aX
(as discussed in section 2), and empirically fails to capture
t
the important amount of stochasticity observed in the real data. By comparison, the
selected model M1 assumes a multiplicative effect of Xt over R, It = R̄Xt and yields a
constant coefficient of variation (CV = a−1/2 ) and standard deviation scaling linearly
with the number of cases. This type of model (as shown in the appendix) provides a
better fit to the data, which could be due to the fact that it allows greater dispersion and

12

𝜶

𝒈

R𝒕"𝟑

Xg,t-3
Group g

𝜷

𝜷𝒈
𝜶𝒈
_{𝒕}
\𝒍𝒂𝒎𝒃𝒅𝒂_{𝒕}
= 𝒘^𝑻 = 𝒘^𝑻
𝝀𝒈𝒕
\𝑩𝒊𝒈( \𝑩𝒊𝒈(
𝒈
𝒈
R𝒕"𝟐
R𝒕"𝟏
\𝑮𝒂𝒎𝒎𝒂(
\𝑮𝒂𝒎𝒎𝒂(
𝑿_{𝒕
𝑿_{𝒕
Distribution of the sum of
individual R
− 𝒔}
− 𝒔}
\𝒂𝒍𝒑𝒉𝒂,
Xg,t-1 Incident cases
Xg,t-2 \𝒂𝒍𝒑𝒉𝒂,
\𝒃𝒆𝒕𝒂) \𝒃𝒆𝒕𝒂)
\𝑩𝒊𝒈)$$\𝑩𝒊𝒈)$$

Xgt

Time t

Figure 3. Plate model for the Bayesian Model described in Eq.3

to also allow to account for under-reporting and/or asymptomatic cases contributing to
the new incident cases through this multiplication.
Fitting real data: Results. We fit the previous model on 14 different areas across the
world, chosen arbitrarily by the authors but for which we expect diversity in policies,
environmental variables and social mores. To represent Europe, we selected France,
Germany, Italy, Spain, Sweden, Estonia and the United Kingdom. The United States
of America were arbitrarily chosen to be represented through three American states
(California, Florida, and Texas). We also selected two South American countries (Mexico
and Colombia), as well as South Korea and Russia. We use publicly available datasets
on the number of incident cases that we preprocess and smooth using 7-day rolling
averages (see Appendix A for further details). For each of these fourteen regions, we
split the data and fit the model independently on seven time ranges consisting of the
30 consecutive days from March 15th, to October 14th 2020. This splitting allows us
to train the model independently on shorter periods — thus allowing us to control for
policy changes or weather shifts. The fitting of this Bayesian model was performed
using Hamiltonian Monte Carlo[3, 18] with the Rstan R-library[4]. We refer the reader
to the appendix for further details on convergence diagnostics.
Assessing Goodness of Fit. Figures 4 and 5 show sample projected trajectories
across time for two countries (United Kingdom and Russia) by way of illustration.
The rest of the trajectories are provided as supplementary material on Github, along
with the code2 used to fit and generate these trajectories. To create these figures, we
generated Monte Carlo sample curves according to the model in Eq. 3 using seven days
of observations (shown in red on the figure) to predict the next 30 (shown in teal), and
the fitted parameters. At each sampling step, we reject new incidence numbers bigger
2 https://github.com/donnate/heterogeneity_R0

13

than 1% of the population. Our goal here is to assess the realism and goodness of fit of
our curves compared to the actual observed curve. We note that the actual observed
trajectories fit well within the bounds of what is predicted by our Monte Carlo samples
— thus indicating an agreement between our fitted model and the actual data and a
good coverage of the trajectories. To quantify model agreement further and benchmark
it against existing approaches, we also compare our predictions and confidence intervals
with ones predicted from the R-packages R0[1] and earlyR[30] packages, using their
corresponding Maximum-Likelihood estimators on the same training data. The results
are displayed in Table 1 for the period from mid-March to mid-April, and we show a
comparison of the scenarios predicted by both models in Fig. 8. Overall, we note the
consistency of the mean our estimates with the ones provided by the other R-packages.
This is reassuring, since all models are based on the same type of model formalism. The
main difference lies in the width of the confidence intervals that the Bayesian method
provides: as underlined by the second column in 1, the Bayesian model provides both
larger confidence intervals, from tens to hundreds-of-times wider that the confidence
intervals provided for R0 or earlyR. We also highlight that the confidence intervals
provided by the Maximum Likelihood SEIR estimator implemented inR0 are in fact
confidence intervals for a mean, constant R, whereas ours are for a distribution of Rs.
The confidence intervals for EarlyR are closer, yet still substantially shorter than the
ones provided by the Bayesian method. As a consequence, our model yields better
coverage of the observed trajectories (prediction 30 days ahead — see an example for
Florida in Fig. 8). In fact, in 72.5% of cases (across all time periods and all countries),
the observed trajectory (predicted 30 days ahead) is fully contained by the envelope
of sampled trajectories, compared to none for the EarlyR predictions. We conclude
that our model yields wider — but more realistic — estimates of the variability of
the reproductive number and consequently, a more accurate distribution of plausible
epidemic trajectories.
Country

Bayesian Mean Estimate

R0 ML- estimate

Ratio of Conf. Int. Width

earlyR ML- estimate

|CI|Bayesian
|CI|R0

Estonia
France
Germany
Italy
Russia
Spain
Sweden
UK
South Korea
California
Texas

1.31 ± 1.29
1.37 ± 1.37
1.91 ± 2.10
1.51 ± 1.30
1.63 ± 0.84
2.03 ± 2.23
1.18 ± 0.73
1.55 ± 1.06
0.58 ± 0.82
1.49 ± 1.20
1.58 ± 1.33

1.32 ± 0.048
1.38 ± 0.01
1.51 ± 0.005
1.23 ± 0.004
2.16 ± 0.042
0.99 ± 0.01
1.44 ± 0.02
1.67 ± 0.01
0.96 ± 0.018
1.84 ± 0.019
1.98 ± 0.03

26.9
137
420
325
20
223
36.5
58.9
45.6
63.2
44.3

Ratio of Conf. Int. Width
|CI|Bayesian
|CI|earlyR

4.5 ±1.2
1.8 ±0.08
2.1 ±0.07
NA
2.2 ±0.82
2.5±0.09
1.7±0.15
2.1±0.10
NA
1.9±0.28
2.1±0.79

1.1
18
26
NA
1.0
25
4.9
10
NA
4.3
1.7

Table 1. Comparison of the results across a subset of regions for the first phase of the epidemic. The first
column shows the mean (and 95% confidence interval) associated to our estimated Bayesian R, while the second
shows the estimate of the reproductive number obtained by Maximum-Likelihood estimation with the reference
R-packages R0 [1] and earlyR[30]. The third column provides an estimate of the ratio between the confidence
bands associated to both methods. The NAs in the table correspond to entries where the EarlyR algorithm has
failed to produce any result.

Analysis and Interpretation of the results. Having established the goodness
of fit of our model, we turn to the interpretation of the fitted parameters. Figure
14

6 shows the distribution of the median of the fitted R across countries and phases.
We note, consistently to what we had been expecting, that the median R dropped
considerably after the first month (probably due to the strict lockdowns that were put
in place roughly around mid-March in most of these regions), and has been plateauing
since then around the threshold value of 1 in almost all countries. This observation is
consistent with the lingering of the epidemic that we are currently observing, and the
relative stability of the pandemic in these different regions during the months of June
until September. To enrich the discussion, instead of focusing solely on the median
R, we provide a few examples of the boxplots of the distributions as a function of
time in Fig. 7. The last period of 30 days (mid-September to mid-October exhibits
mostly plateauing behaviors and occasional rises in the 95% quantile. As such, this
particular time frame — which could have acted as a precursor of the “second wave” of
the pandemic, observed from November on in man regions) — does not highlight any
significant uptake of activity of the pandemic in most countries.
We emphasize that the Bayesian model presented here provides a more complete
portrait of the situations across countries than most SEIR-based models. Indeed, by
considering a distribution, instead of the mean as a summary statistics, we are able to
view interesting behaviours and spot nuances in countries’ responses and handling of
the pandemic. In particular, as shown in Table 2, all countries (but Korea, for which the
epidemic has well under control mid-March) have managed to shrink the value of their
average R by an average of 0.55 points, yielding an average reduction of the R to 65%
of its original value. But perhaps more striking is the average 1.1 reduction for these
countries of the 95th quantile of the R (66% of its original value) — highlighting the
considerable reduction in the tail of the distribution. Not only do these numbers allow
us to better quantify the effects of the different measures on mitigating the spread of
the virus, it also allows to make more refined nuances between scenarios. For instance,
for some countries (e.g Spain or Germany), the average R has increased or remained
comparable from the summer period to the fall stage, but we also note a sizeable
reduction in the value of the 95th quantile: this seems to indicate a potential reduction
of “superspreader events”. This is potentially an encouraging sign for the handling of
the pandemic, and thus, yields a more balanced view of the situation of the pandemic
in these countries instead of the bleak picture provided by the sole examination of the
behavior of the mean. On the other hand, Texas for instance, has registered a 15%
increase in the value of its average R between summer and fall, but a 200% increase in
its 95th quantile — thus raising a warning signal for the potential resurgence of the
pandemic in this particular region.

15

Mean (95th q.)
California
Colombia
Estonia
Florida
France
Germany
Italy
Korea
Mexico
Russia
Spain
Sweden
Texas
UK

03-15-04/15
1.5 ( 2.7)
1.4 (2.5)
1.3 (3.1)
1.7 (3.2)
1.4 (2.7)
1.9 (3.9)
1.5 (2.7)
0.6 (1.4)
1.4 (2.5)
1.6 (2.4)
2.0 (4.3)
1.2 (1.8)
1.6 (2.9)
1.6 ( 2.6)

06/15-07/14
1.1 (1.6)
1.1 (1.5)
0.6 (1.5)
1.2 (1.7)
1.0 (2.6)
0.8 (1.7)
1.0 (1.9)
1.0 (1.8)
1.0 (1.3)
0.9(1.2)
1.1 (2.1)
1.0 (1.7)
1.1 (1.5)
1.0 (1.8)

09/15-10/14
1.0 (1.25)
0.97 (1.3)
1.0(2.0)
1.1 (1.6)
1.1 ( 1.9)
1.1 ( 1.49)
1.0 (1.5)
0.9 (1.6)
0.9 (2.1)
1.0 (1.3)
1.1 (1.7)
1.1 (1.7)
1.3 ( 3.0)
1.1 (1.7)

Table 2. Quantification of the evolution of the mean and 95th -quantile of the estimated distribution for R
across three different periods. Colors in the last two columns denote an increase (red) or decrease (green) of
more than 0.2 points from the previous column.

x 1000

Observations
Predictions

04.15 - 05.15

6

(30 days)

100

50

x 1000
8

Phase

150

4

03.15 - 04.15

.10
05

.05
05

.30
04

0
04
.2

.15

0.15 - 0
0
.15

6
4

2

.10
07

.05
07

.30
06

.25
06

06

.20

.15
06

06
. 10

06
. 05

05
.30

.25
05

05
.20

05
.15

05
.10

16

0
x 1000

.10

2

0

12

04

.10

05.15 - 06.15

4

x 1000

04

04
.10

04
.05

03
.30

x 1000

06

6

03
.25

x 1000

03
.20

03
.15

0

04
.25

2

0.15 - .15

08.15 - 09.15

40

8

20

4

.10
10

.05
10

.30
09

.25
09

.20
09

.15
09

.10
09

.10
09

.05
09

.30
08

05
8.2
5

.20
08

.15
08

08
5.1
0

0

Figure 4. Comparison of estimated trajectories for the United Kingdom vs the actual ones. Here, the
observation phase is in red, and the goal is to predict likely trajectories for the next 30 days, the observed one
being indicated in teal).

16

Phase

15000

Observation
First Month

10000

04.15
.15 - 05.15
0 .15

80000

60000

40000

5000
20000

03.15
.15 - 04.15
0 .15
0

05
-1
0

05

30

05
-

04
−

5
−2
04

04
−2
0

15

0

06.15
.15 - 07.15
0 .15

50000

04
−

−0
04

04
−1

5

0
03
−3

25
03
−

0
03

−2

5
−1
03

03
−1

0

0

0
−1
04

07.15
.15 - 0
08.15
.15

40000
20000
30000

20000

10000

10000

0

0
08

08

07

−0

−1

5

0
−3

5
−2
07

−2
0
07

5
−1
07

−1
07

07

08.15
.15 - 0
09.15
.15

40000

0

0
−1

5
−0
07

−3
0
06

5
−2
06

06

−2

0

5
−1
06

06

−1

0

0

09.15 - 10.15
.15

80000

60000
30000
40000

20000

−1
0
10

−0
5
10

0
−3
09

5
−2
09

−2
09

−1
09

0
09

−1

−1
0
09

5
−0
09

0
−3
08

−2
5

−2
08

08

0

0
−1
08

5

0

0

0

20000

10000

Figure 5. Comparison of estimated trajectories for Russia vs the actual ones. The observation phase is in red,
and the goal is to predict likely trajectories for the next 30 days (the observed one being indicated in teal).

Country
France

1.6

Germany
UK
Italy
Spain
1.2

median R

Estonia
Sweden
Russia
Korea
Colombia

0.8

Mexico
California
Texas
Florida
0.4
03/15−04/14

04/15−05/14

05/15−06/14

06/15−07/14

07/15−08/14

08/15−09/14

09/15−10/14

Figure 6. Trajectories of the median R (fitted on periods of 30 days, labeled on the x-axis) across countries,
as a function of time.

17

(A) South Korea
●

6

●
●
●

●

●

4

●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

2

value

●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●
●
●
●
●
●

stage
03/15−04/14
04/15−05/14
05/15−06/14
06/15−07/14
07/15−08/14
08/15−09/14
09/15−10/14

●
●
●
●
●
●

●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●

R=1

(B) Italy

09/15−10/14

08/15−09/14

07/15−08/14

06/15−07/14

05/15−06/14

04/15−05/14

03/15−04/14

0

●

stage

4

●
●
●

●
●
●
●
●
●
●
●
●
●

3

●

●

●
●
●
●

●

●
●
●
●
●
●

●

●
●
●
●
●
●
●
●
●
●
●
●
●

●

2

value

stage
03/15−04/14
04/15−05/14
05/15−06/14
06/15−07/14
07/15−08/14
08/15−09/14
09/15−10/14

●
●
●
●
●

●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●

●
●
●
●
●
●
●
●
●

1

R=1

●

●
●

stage

(C) Mexico

●

●
●

4

●
●
●

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●

●
●
●
●

3

●
●
●
●
●
●

●

●
●
●
●
●
●
●
●
●

2

value

09/15−10/14

08/15−09/14

07/15−08/14

06/15−07/14

05/15−06/14

04/15−05/14

03/15−04/14

0

●

●
●
●
●
●
●
●

●
●
●
●
●
●

●
●
●
●
●
●

●
●
●
●
●
●

●
●
●

●
●

1

R=1
●
●
●

●
●
●

09/15−10/14

08/15−09/14

07/15−08/14

06/15−07/14

05/15−06/14

04/15−05/14

03/15−04/14

0

●

stage
03/15−04/14
04/15−05/14
05/15−06/14
06/15−07/14
07/15−08/14
08/15−09/14
09/15−10/14

stage

Figure 7. Boxplots showing the distribution of R across three different countries and across phases. We note
in particular the variability of the spread of the distribution across time.

18

10000

New cases

Model
Bayesian
ML
Observed

Scenario
Average
Worst case

3000

1000

Sep 15

Oct 01

date

Oct 15

Figure 8. Comparison of the different predictive models for Florida. The light red color shows the 95th
quantile envelope associated to the Bayesian trajectories, while the green one is the envelope associated with the
predictions using the reference R-packages R0 and projections. The dashed line shows the worst case scenario
associated with each of these methods, while the blue represents the actual observations.

19

4. Evaluating the impact of adding heterogeneity in predictive scenarios.
The second stage of our analysis consists in using our fitted model for the heterogeneous
R to predict the impact of different strategies on the outcome of the epidemic. Indeed,
policy makers are currently faced with the difficult task of implementing efficient policies
to limit the spread of the virus, while arbitrating between societal and economical
costs. An inspection of the decomposition of the reproductive number provided in Eq.
1 exhibits why a policy geared towards a lowering of the daily contact rate c̄ should
efficiently limit the spread of the virus. The goal of this section is thus to quantify the
effect of governmental measures on slowing and mitigating the spread of the virus. Again,
we emphasize that our study does not aspire to provide state-of-the-art prediction
models, but rather to evaluate the effect of the additional variability on recommended
measures.
We model two types of interventions:
• ones that act on the tails of the distribution – that is, interventions geared
to mitigating the possibility of super-spreader events (concerts, transportation,
etc.). Such interventions are thus not targeted uniformly across the population,
but rather at the highest quantiles of the distribution of R. Concretely, based
on Eq. 1 and assuming that the variability in the transmissibility τ is less than
the one associate to the contact rate c, these measures can be understood as
capping the maximal contact rate. From the simulation perspective, we model
these intervention by capping the values of the R at different quantiles (the more
drastic the intervention, the higher the quantile).
• ones that are distributed uniformly on the population. These approaches
are geared towards a reduction of the R (or equivalently, the contact rate c) by
measures applicable to the entire population, by shrinking each individual contact
rate (e.g, mask wearing, generalized stay-at-home orders). From the simulation
perspective, we model this by a reduction of the mean of the distribution or
equivalently (i.e, we multiply the shape parameter of the gamma distribution by
a number less than one).
In this section, we refer to the stringency (value of the quantile or of the multiplicative
factor) as the “level” of the intervention. Note that actual real life interventions are often
a combination of both effects, but we find convenient in this study of the impact of the
heterogeneity onto the distribution to decouple the both. All the results can be found
in the supplementary materials on Github, and we provide in the main text illustration
of these simulated scenarios for the case of France in the first month (03/15-04/14).
Figure 9A shows the distribution of projected trajectories for measures aiming to
cap the distribution of the R at several pre-specified thresholds, whereas Fig. 9B shows
the distribution of these trajectories for measures reducing the value of the R as a
distribution (mean shrinkage). In other words, we aim to compare here measures that

20

are targeted at minimizing the highest contact rates on the left (restrictions on the
maximal gathering sizes, targeted lockdowns), to measures geared to minimizing the
entire distribution of contact rates (lockdowns, social distancing). We note that both
types of measures are efficient in reducing the spread of the epidemic (the more stringent
the intervention, the faster and better the effect). In particular, a capping of the R
to its 50th quantile (or to 50% of its original value) or less is efficient in making the
epidemic recede. Measures shrinking the distribution as a whole also appear to have a
faster effect: the epidemic receded within a month of an intervention reducing R to 40%
of its original value (magenta curves on Fig. 9B), whereas it appears to take between
one to two months for an intervention capping R to the 40th quantile of its original
distribution (light green curves on Fig. 9A).
However, given the costs and difficult logistics of stringent measures acting on the
whole distribution, it is important to quantify their optimality and efficiency with
respect to “tail interventions”, whose costs and burden on the population can potentially
be lighter. Fig.10 shows the average and 95th quantile (which we take as a measure
of the “worst-case scenarios) for the trajectories in France, while Table 3 quantifies
the efficiency of the different measures across countries in the first month of the
epidemic. Interestingly, the efficiency of the tail-oriented strategies are comparable to
the ones reducing the entire distribution: the strategy consisting in capping R to its
90th quantile already achieves a 78.5% reduction in France — more efficient than a
strategy involving reducing the R to 90% of its original value. As shown in Table 3,
this effect of course widely varies across countries, some measures being more efficient
in some countries than others. In Estonia for instance, a capping of the R distribution
at the 95th quantiles induces a reduction of 62.4% of the epidemic, but reducing the
mean to 95% of its original value only induces a decrease of 34.4%. In Russia, the
efficiency of these two measures is in fact reversed (34.8% vs 47% reduction). Finally,
Fig .11 highlights the importance of considering the distribution of R (rather than
solely its mean) to understand the efficiency of any given measure. Here, the projected
trajectories with mean-shrinkage measures are displayed for both California and Texas
(for the period from 09/15 to 10/14) — two states with similar median R values (Fig.6),
but different spreads ( see Table 2). While shrinking the mean by 25% is efficient in
California reducing the epidemic, it is insufficient for Texas. To conclude this section,
these experiments highlight two potential interesting facts: (a) the efficiency of the
measures is contingent on the distribution of the R, and not only its mean, and (b)
measures targeting the tails might have comparable average accuracy (Fig. .10A), whilst
better worst-case scenarios (Fig. 10B) than measures targeted at the mean. As such,
the heterogeneity of the distribution of R appears to take on a significant importance
in the type and scope of measures to be taken in order to control the epidemic.

21

Measure Type
40th quantile
50th quantile
75th quantile
95th quantile
Observed
No intervention

1e+05

New Cases

New Cases

1e+03

1e+03

(B) Shrinking Measures

(thresholding above a given quantile)

.10
04

04
.05

03
.30

03
.25

.10

03
.15

(A) Capping Measures

04

04
.05

03
.30

03
.25

03
.20

1e+01

03
.15

1e+01

Measure Type
40% of orginal mean
50% of orginal mean
75% of orginal mean
95% of orginal mean
Observed
No intervention

03
.20

1e+05

(reduce the mean to given %)

Figure 9. Comparison of the effect of the different types of interventions: ones acting on the tails of the
distributions (panel A) and others distributed uniformly on the distribution (panel (B).

Country
France
Germany
UK
Italy
Spain
Estonia
Sweden
Russia
South Korea
Mexico
Colombia
Texas
Florida
California

60th Q. Cap
99.0%
99.1%
92.6%
97.6%
94.3%
94.9%
87.5%
89.0%
38.7%
93.6%
83.3%
97.4%
97.8%
94.7%

0.6 × Mean
99.3%
98.6%
99.3%
99.4%
97.6%
93.6%
99.0%
99.5%
37.9%
98.8%
97.0%
99.3%
99.0%
99.2%

90th Q. Cap
78.5%
58.7%
55.8%
68.3%
21.8%
80.4%
49.9%
52.8%
29.2%
57.8%
43.9%
70.1%
73.0%
61.6%

0.9 × Mean
66.5%
44.8%
66.6%
66.7%
27.7%
61.2%
64.1%
70.7%
23.8%
65.4%
62.8%
72.8%
67.7%
67.4%

95th Q. Cap
58.4%
34.2%
35.6%
48.5%
10.2%
62.5%
31.1%
34.8%
21.9%
37.2%
29.7%
51.7%
53.0%
38.7%

0.95 × Mean
40.8 %
21.5 %
40. %
40.3 %
11.9 %
34.4 %
41.3 %
47.0 %
14.2 %
39.6 %
40.6 %
45.8 %
40.4 %
42.2 %

Table 3. Reduction in the final predicted incidence numbers of the first period (taken at day t = 30) achieved
30
by different measures compared to predicted baseline (no measures) scenarios: r = 1 − P(0)
. Comparison of the
P30

effect of capping at the {60, 90, 95}th quantiles, versus reducing the mean of the distribution to {60, 90, 95}% of
its original value.

22

1e+05

1e+05

Level

Level

No intervention

No intervention

1e+04

40th Quantile

40th Quantile

50th Quantile

50th Quantile

60th Quantile
1e+04

60th Quantile

65th Quantile

65th Quantile

75th Quantile

75th Quantile

85th Quantile

85th Quantile

90th Quantile

90th Quantile

95th Quantile

95th Quantile

99th Quantile

99th Quantile

40% of mean

40% of mean

50% of mean

50% of mean

60% of mean

60% of mean

75% of mean

75% of mean

85% of mean

85% of mean

90% of mean

90% of mean

1e+03

1e+03

1e+02
95% of mean

1e+02

95% of mean

Scenario

Scenario
Average

Average

Worst-case

Worst-case

1e+01

1e+01

Mar 09

Mar 16

Mar 23

Mar 30

Apr 06

(A) Average effect on the trajectory
(all interventions)

Mar 09

Apr 13

Mar 16

Mar 23

Mar 30

Apr 06

Apr 13

(B) Effect on the worst case scenario
(all interventions)

Figure 10. Comparisons of the different interventions on the distribution of the trajectories, represented by
its average on panel A, and its maximum (worst case) on panel B. Interestingly, the average scenarios in panel
A indicate that the two types of interventions yield comparable results (controlling for the level of stringency
of the measure), whilst tail-focused measures — in cooler colours— yield better worst-case (95th quantiles)
scenarios than mean-orientated ones, here displayed with warmer colours (panel B).

23

(A) California
new cases

10000

1000

Measure Type
40% of orginal mean
50% of orginal mean
75% of orginal mean
95% of orginal mean
Observed
No intervention

100

10

1
8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4
/0 9/0 9/1 9/1 9/1 9/1 9/1 9/1 9/1 9/1 9/1 9/1 9/2 9/2 9/2 9/2 9/2 9/2 9/2 9/2 9/2 9/2 9/3 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/1 0/1 0/1 0/1 0/1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1

(B) Texas

09

new cases

1e+05

Measure Type
40% of orginal mean
50% of orginal mean
75% of orginal mean
95% of orginal mean
Observed
No intervention

1e+03

1e+01

08

/
09

9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
/0 /1 /1 /1 /1 /1 /1 /1 /1 /1 /1 /2 /2 /2 /2 /2 /2 /2 /2 /2 /2 /3 /0 /0 /0 /0 /0 /0 /0 /0 /0 /1 /1 /1 /1 /1
09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 09 10 10 10 10 10 10 10 10 10 10 10 10 10 10

Figure 11. Comparison of the effect of the different types of interventions: California vs Texas, from 09/15 to
10/14. By Fig.6, both have similar median R and average R, but the spread of Texas is larger (see Table 2).
This highlights the importance of the distribution of the reproductive number R as a whole to determine the
efficiency of any given measure.

24

5. Conclusion
In conclusion, we have presented here an analysis targeted at assessing the impact of the
heterogeneity of the reproductive number in predictive epidemic scenarios. In particular,
we have shown that the modeling of this heterogeneity is crucial to correctly model
extreme scenarios and characterize their uncertainty. Indeed, using a Bayesian model, we
have shown that the added variability is necessary to (a) provide better coverage of the
confidence intervals, and thus, more appropriately quantify the uncertainty associated
to a certain prediction or the effect of a given policy and (b) explain rare events and
understand the formation of outbreaks — which averaged models would not allow and
which are nonetheless crucial elements to take into account when weighting different
scenarios.
Our analysis of the real data has also shown that considering the reproductive
number as a distribution allows us to draw interesting nuances and contrasts between
countries and stages of the epidemic, enabling to better capture the mean and
variability of the reproductive number in the population. This distinction is crucial
in assessing which are the most efficient preventive measures to be taken in order to
control the spread. This analysis also hints to the importance and efficiency of limiting
the upper tail of the distribution. We emphasize again that our study does not aspire
to draw predictive scenarios, but rather to understand how models and predictive
scenarios are truly impacted by the choice and inherent variability of the R – and the
great variability that we have imputed seems to highlight the need for a finegrain
analysis.
Further Discussion on the Variability of R. To continue building up this work, it
would be interesting to enrich our model for R with additional sources of information
and independent variables— thus controlling even better for the day-to-day variations
exhibited in our model fit for R, policies, weather conditions, etc. This would allow us
to build a deeper hierarchical model which we could fit on all of the countries at once
whilst controlling for these additional factors.
Disclaimer. This model is a tool for exploring the effect of uncertainties and variation
in the reproductive number R for the virus and the effect of this variability in different
types of interventions, but we do not claim to be predictive of disease dynamics for any
specific populations (credit to McGee et al. for disclaimer).

6. Bibliography

[1] R0: Estimation of R0 and Real-Time Reproduction Number from Epidemics, author = Pierre-Yves Boelle, Thomas Obadia, organization = https://CRAN.Rproject.org/package=R0, address = , year = 2015, url = https://CRAN.R-

25

project.org/package=R0,.
[2] M. Akbarpour, C. Cook, A. Marzuoli, S. Mongey, A. Nagaraj, M. Saccarola, P. Tebaldi,
S. Vasserman, and H. Yang. Socioeconomic network heterogeneity and pandemic policy
response. University of Chicago, Becker Friedman Institute for Economics Working Paper,
(2020-75), 2020.
[3] M. Betancourt. A conceptual introduction to hamiltonian monte carlo. arXiv preprint
arXiv:1701.02434, 2017.
[4] B. Carpenter, A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt,
M. Brubaker, J. Guo, P. Li, and A. Riddell. Stan: A probabilistic programming language. Journal of statistical software, 76(1), 2017.
[5] E. Cave. Covid-19 super-spreaders: Definitional quandaries and implications. Asian
Bioethics Review, page 1, 2020.
[6] S. L. Chang, N. Harding, C. Zachreson, O. M. Cliff, and M. Prokopenko. Modelling transmission and control of the covid-19 pandemic in australia. arXiv preprint arXiv:2003.10218,
2020.
[7] K. Chatterjee, K. Chatterjee, A. Kumar, and S. Shankar. Healthcare impact of covid-19
epidemic in india: A stochastic mathematical model. Medical Journal Armed Forces India,
2020.
[8] A. Cori, N. M. Ferguson, C. Fraser, and S. Cauchemez. A new framework and software
to estimate time-varying reproduction numbers during epidemics. American journal of
epidemiology, 178(9):1505–1512, 2013.
[9] D. J. Daley and J. Gani. Epidemic modelling: an introduction, volume 15. Cambridge
University Press, 2001.
[10] K. Deforche. An age-structured epidemiological model of the belgian covid-19 epidemic.
medRxiv, 2020.
[11] P. L. Delamater, E. J. Street, T. F. Leslie, Y. T. Yang, and K. H. Jacobsen. Complexity
of the basic reproduction number (r0). Emerging infectious diseases, 25(1):1, 2019.
[12] J. Dolbeault and G. Turinici. Heterogeneous social interactions and the covid-19 lockdown
outcome in a multi-group seir model. arXiv preprint arXiv:2005.00049, 2020.
[13] C. Fraser. Estimating individual and household reproduction numbers in an emerging
epidemic. PloS one, 2(8), 2007.
[14] A. Gómez-Carballa, X. Bello, J. Pardo-Seco, F. Martinón-Torres, and A. Salas. Mapping
genome variation of sars-cov-2 worldwide highlights the impact of covid-19 super-spreaders.
Genome Research, 30(10):1434–1448, 2020.
[15] A. Grant. Dynamics of covid-19 epidemics: Seir models underestimate peak infection rates
and overestimate epidemic duration. medRxiv, 2020.
[16] S. He, Y. Peng, and K. Sun. Seir modeling of the covid-19 and its dynamics. Nonlinear
Dynamics, pages 1–14, 2020.
[17] H. W. Hethcote. The mathematics of infectious diseases. SIAM review, 42(4):599–653,
2000.
[18] M. D. Hoffman and A. Gelman. The no-u-turn sampler: adaptively setting path lengths
in hamiltonian monte carlo. J. Mach. Learn. Res., 15(1):1593–1623, 2014.
[19] K. Hu, Y. Zhao, M. Wang, Q. Zeng, X. Wang, M. Wang, Z. Zheng, X. Li, Y. Zhang,
T. Wang, et al. Identification of a super-spreading chain of transmission associated with

26

covid-19. medRxiv, 2020.
[20] D. Kai, G.-P. Goldstein, A. Morgunov, V. Nangalia, and A. Rotkirch. Universal masking
is urgent in the covid-19 pandemic: Seir and agent based models, empirical validation,
policy recommendations. arXiv preprint arXiv:2004.13553, 2020.
[21] W. O. Kermack and A. G. McKendrick. A contribution to the mathematical theory of
epidemics. Proceedings of the royal society of london. Series A, Containing papers of a
mathematical and physical character, 115(772):700–721, 1927.
[22] P. E. Lekone and B. F. Finkenstädt. Statistical inference in a stochastic epidemic seir
model with control intervention: Ebola as a case study. Biometrics, 62(4):1170–1177, 2006.
[23] W. Lyra, J. D. do Nascimento, J. Belkhiria, L. de Almeida, P. P. Chrispim, and I. de Andrade. Covid-19 pandemics modeling with seir (+ caqh), social distancing, and age
stratification. the effect of vertical confinement and release in brazil. medRxiv, 2020.
[24] D. Mackenzie. Why coronavirus superspreaders may mean we avoid a deadly pandemic.
New Scientist.
[25] G. Pandey, P. Chaudhary, R. Gupta, and S. Pal. Seir and regression model based covid-19
outbreak predictions in india. arXiv preprint arXiv:2004.00958, 2020.
[26] J. M. Read, J. R. Bridgen, D. A. Cummings, A. Ho, and C. P. Jewell. Novel coronavirus 2019-ncov: early estimation of epidemiological parameters and epidemic predictions.
medRxiv, 2020.
[27] R. Read. A choir decided to go ahead with rehearsal. now dozens of members have covid-19
and two are dead. Los Angeles Times, 29, 2020.
[28] R. J. Rockett, A. Arnott, C. Lam, R. Sadsad, V. Timms, K.-A. Gray, J.-S. Eden, S. Chang,
M. Gall, J. Draper, et al. Revealing covid-19 transmission in australia by sars-cov-2
genome sequencing and agent-based modeling. Nature medicine, 26(9):1398–1404, 2020.
[29] P. C. Silva, P. V. Batista, H. S. Lima, M. A. Alves, F. G. Guimarães, and R. C. Silva.
Covid-abs: An agent-based model of covid-19 epidemic to simulate health and economic
effects of social distancing interventions. Chaos, Solitons & Fractals, 139:110088, 2020.
[30] P. N. Thibaut Jombart, Anne Cori. earlyR: Estimation of Transmissibility in the Early
Stages of a Disease Outbreak. https://CRAN.R-project.org/package=earlyR, 2017.
[31] J. T. Wu, K. Leung, and G. M. Leung. Nowcasting and forecasting the potential domestic
and international spread of the 2019-ncov outbreak originating in wuhan, china: a modelling
study. The Lancet, 2020.
[32] Y. Zhang, Y. Li, L. Wang, M. Li, and X. Zhou. Evaluating transmission heterogeneity
and super-spreading event of covid-19 in a metropolis of china. International Journal of
Environmental Research and Public Health, 17(10):3705, 2020.
[33] S. Zhao and H. Chen. Modeling the epidemic dynamics and control of covid-19 outbreak
in china. Quantitative Biology, pages 1–9, 2020.
[34] S. Zhao, Q. Lin, J. Ran, S. S. Musa, G. Yang, W. Wang, Y. Lou, D. Gao, L. Yang, D. He,
et al. Preliminary estimation of the basic reproduction number of novel coronavirus
(2019-ncov) in china, from 2019 to 2020: A data-driven analysis in the early phase of the
outbreak. International Journal of Infectious Diseases, 2020.

27

Appendix A. Appendix: Added variability in the infectious profile
COVID-19 Model Fitting: Convergence Diagnostics.
1. Choice of model. In this appendix, we discuss the choice of the model made in
Section 3. As discussed in Section 2, this choice is important, as it determines the
amount of variability of the distribution of R. All models are based on th following
assumptions:

Xt+1 ∼ Poisson(λt )

P
where λt = K
k=1 wk It−k . In particular, for the real data, we compared the following
four different models, and chose the one that provided the best fit to the data:
Model M1 . It ∼ Gamma(αXt , β) This is assuming each R is sampled from an indepedent gamma.
Model M2 . It ∼ Gamma(αXt , β/Xt ) This assumes that we have a multiplication
factor in front of the number of cases. As discussed in the main paper (section 3), this
might be more amenable to accounting for under reporting.
√
√
Model M3 . It ∼ Gamma(αXt It , β/ It ) This model is in a similar vein as the
previous, but allows less variance and has a smaller coefficient of variation. We have
fitted here using two versions of the w parameter, one similar to the approach suggested
by Cori et al [8], using the serial interval for COVID-19, and another (W = w1 ) using
the value of w suggested in the main text.
√
√
Model M4 . It ∼ Gamma(αXt It , β/ It ), w ∼ Dirichlet(w0 )
Here, we study model fit for the case of France, the UK and Germany. We base the
comparison if the different models on estimates of fit, and ability to reconstruct the
observed trajectory.
The model which minimizes the negative log-likelihood is thus the one with maximal
variability (model M2 ), with model 3 comes is a close second.
2. Numerical Procedure.
We fit the model using Hamiltonian Monte Carlo (No U Turn Samples) with the
R package the RStan [4]. We use 10 chains, with 5,000 warmup iterations and 1,000
sampling steps. Using these 10,000 posterior samples, we estimated the posterior median
of the posterior and 95% credible interval (CrI) for each time point.
We assessed convergence of the chains using the Gelman-Rubin convergence diagnostic,
that is, to assume convergence to the posterior, we ensured that R̂ ≤ 1.1 across all
chains and that the number of effective samples was more than 20% of the number of
samples. We also checked the mixing of all chains. The following plots show convergence
diagnostics for all the countries that were selected for the purpose of this analysis.
Data. The data that we used here consists in the new incident cases (as per the JHU

28

-lp__

10000

Model
Model 1
Model 2
Model 3
Model 3, w=w1
Model 4

3000

1000

model

Figure A1. Negative log-likelihood

29

1.006

Florida

Texas

California

Mexico

Colombia

Korea

Russia

Sweden

Estonia

Spain

Italy

UK

Germany

France

1.000

1.002

Rhat

1.004

Country
France
Germany
UK
Italy
Spain
Estonia
Sweden
Russia
Korea
Colombia
Mexico
California
Texas
Florida

country

Figure A2. R̂ for the different parameters in the model, across groups.

30

Florida

Texas

California

Mexico

Colombia

Korea

Russia

Sweden

Estonia

Spain

Italy

UK

Germany

France

10000

n_eff

20000

Country
France
Germany
UK
Italy
Spain
Estonia
Sweden
Russia
Korea
Colombia
Mexico
California
Texas
Florida

country

Figure A3. neff for the different parameters in the model, across groups.
Figure A4. Convergence Diagnostics

31

3

dataset). We use country (and in the case of the US, county) level data to fit the
different Rs. The data required a little bit of pre-processing, including:
• Converting the cumulative counts to daily incidence counts
• Thresholding to 0 the negative entries
• Using the 7-day rolling average counts to even out potential weekly (and weekend
effects) observable in the raw data.
Discussion and limitations. The dataset that we have consists only in the reported
cases and thus does not account for under-ascertainment of the number of cases. To
counteract this potential bias, a solution would be to use a method in the spirit of, and
try to find a probabilistic way.

3 The

data is publicly available at the following https://github.com/CSSEGISandData/COVID-19.

32

