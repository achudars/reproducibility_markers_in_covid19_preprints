NationalMood: Large-scale Estimation of People’s Mood from
Web Search Query and Mobile Sensor Data
Tadashi Okoshi

Keio University
Fujisawa, Japan
slash@sfc.keio.ac.jp

arXiv:2011.00665v2 [cs.CY] 3 Nov 2020

Hiroshi Kawane

Yahoo Japan Corporation
Tokyo, Japan
hkawane@yahoo-corp.jp

ABSTRACT
The ability to estimate current affective statuses of web users has
considerable potential towards the realization of user-centric opportune services. However, determining the type of data to be used for
such estimation as well as collecting the ground truth of such affective statuses are difficult in the real world situation. We propose a
novel way of such estimation based on a combinational use of user’s
web search queries and mobile sensor data. Our large-scale data
analysis with about 11,000,000 users and 100 recent advertisement
log revealed (1) the existence of certain class of advertisement to
which mood-status-based delivery would be significantly effective,
(2) that our “National Mood Score” shows the ups and downs of
people’s moods in COVID-19 pandemic that inversely correlated
to the number of patients, as well as the weekly mood rhythm of
people.

CCS CONCEPTS
• Human-centered computing → Smartphones; • Information systems → Web log analysis; Information systems applications.

KEYWORDS
mood estimation, web search, mobile sensing, COVID-19 analysis
ACM Reference Format:
Tadashi Okoshi, Wataru Sasaki, Hiroshi Kawane, and Kota Tsubouchi. .
NationalMood: Large-scale Estimation of People’s Mood from Web Search
Query and Mobile Sensor Data. In . ACM, New York, NY, USA, 9 pages.
https://doi.org/XXX

1

INTRODUCTION

The ability to determine current affective statuses of users has considerable potential to enable the provision of user-centric opportune
services tailored to specific user statuses. Web services, for example,
can be improved by adapting various types of parameters such as
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
,,
© Copyright held by the owner/author(s).
https://doi.org/XXX

Wataru Sasaki

Keio University
Fujisawa, Japan
wataruew@sfc.keio.ac.jp

Kota Tsubouchi

Yahoo Japan Corporation
Tokyo, Japan
ktsubouc@yahoo-corp.jp
the presentation timings, presentation tone, content, as well as content modality. When Alice has an emotionally negative status, the
news web service can highlight some interesting news or present
advertisements that can possibly cheer her up, thus attempting to
align itself with her emotions.
However, determining affective statuses of web users outside
a controlled in-lab configuration, particularly in real-world situations, is a difficult task. The first problem is on the type of data
from which the affective status of a user can be estimated.
Typically, sensing and determining the emotional state of a person require psycho-physiological data such as heart rate (HR) [22],
HRV, electrocardiogram (ECG), and electroencephalogram (EEG)
data [28, 32]. However, the collection of such data in real-world
conditions of mobile web users is not feasible owing to the low
penetration rate of such sensors in the society, additional burden
on users to use such devices, and lack of social acceptance to the
collection of such data. The second problem is on how the ground
truth label on the affective status of a user can be collected.
User annotation is widely used during the data-collection phase.
However, this approach is also not always effective owing to multiple possible causes such as the following: (1) the users may find it
cumbersome to answer repeated questions, and (2) the users may
forget to answer the questionnaire.
In this paper, as the first contribution, we show that we can
estimate the web users’ affective status (concretely, “mood”) in such
a condition, based on a novel combinational use of their web search
queries and mobile sensor data. To address the first problem, we
target users’ queries input to the web search engine as an easy-tocollect and noninvasive proxy feature to explain their mood states,
focusing on the fact that almost all the internet users regularly use
search engines in their daily lives. Because web services typically
store the historical log of users’ search queries at the server side,
its use can be started today without having to wait for the widespread adoption of new types of sensors. To address the second
problem, we use a novel two-step mood classification with different
types of models, namely the “Sensor Mood Model (SMM)” and
“search-Query Mood Model (QMM).”
Figure 1 illustrates our research structure. (1) First, we conduct a
preliminary data-collection study with 460 participants for 90 days
to collect their continuous sensor data from their smartphones;
periodic subjective evaluation of their mood as ground truth annotation was also performed. (2) Next, we build our first model

,,

Okoshi and Sasaki, et al.

(1) Data-Collection Study (Sec.4)

Continuous
Sensor Data

460 users
x
90 days

Data Collection
Smartphone App

Search queries (in their daily use)

(3) Evaluation

(2) Model Building (Sec .5)
[Ground truth label]
Mood values

Periodic answer about
current mood value

[Features]
Sensor-based features

SMM
(Sensor
Mood
Model)

OURBRAND
Search Engine

[Ground truth label]
User’s mood status
in the timing of each
search behavior

[Features]
Search log
(timestamp, keyword)

100 Recent
Advertisement Log
QMM
(search-Query
Mood
Model)
11 million users’
search query log

“Mood-Effective
Advertisement”
(Sec. 6)

“National Mood”
(Sec. 7)

Figure 1: Framework of this research
“SMM” that estimates the participant’s mood statuses from specific
temporal frames in which both sensor data and the user annotation
were successfully collected. With the built SSM, we can estimate
each participant’s mood status for all the time frames during the
data-collection study period. Then, by combining the web search
logs of the 460 participants during the study period and mood status
(based on both the users’ original annotation and SMM’s outputs),
we create our second model “QMM”, which estimates the mood of
a user from their search query data.
As our second contribution, we also show that the use of these
mood statuses in a web service (with more than 80 million users)
through the introduction of multiple evaluation parameters, including “Mood-Effective Advertisement” and “National Mood,” has
significant potential. To the best of our knowledge, this research is
the first to reveal this possibility.
First, by analyzing the existing server-side log data stored in our
web service, we investigate the relationship between multiple advertisement contents that we display to the users and the responses
of the users based on their derived moods. By analyzing the recent
logs of 100 advertisement projects, including when and who viewed
the advertisements and whether they clicked on them, we identified
the advertisement for which mood-based delivery will be effective.
We determined a certain class of advertisements where the mood
tendencies of users who clicked was more positive or negative than
a random distribution (Section 6).
Second, we examined the value of calculating the mood score
in nation-wide by using the proposed method in this research. We
calculated “the daily national mood score”, the average mood score
of about 11,000,000 users in Japan on a daily basis, and saw how
the score changes over time. Interestingly, we found that the score
based on our proposed algorithm shows the weekly rhythm of
people’s mood (that drops every 1st working day of the week and
increases again every weekend) (Section 7.3) and the longer-term
trace of people’s mood in the COVID-19 pandemic period in year
2020 that inversely correlated to the number of COVID-19 patients
(Section 7.4).
The remainder of this paper is organized as follows. Section 2
discusses related work. Section 3 describes our novel Yahoo! JAPAN
Emotion framework. Section 4 details data-collection study conducted for 90 days with 460 users. Section 5 describes model building from the collected data. Section 6 shows the results on “MoodEffective Advertisement” analysis. Section 7 shows our findings
from our “National Mood Score” analysis. Section 8 discusses our
further work. Section 9 concludes this paper.

2

RELATED WORK

Extensive studies on emotion began to be conducted in the 19th
century, with a well-known study conducted by Darwin [9]. Darwin says that emotion is a product of evolution and that emotions induce actions favorable to survival [7]. Numerous emotional
modalities and their respective physiological responses have been
studied [6, 27]. Emotional states are known to affect cognitive and
athletic abilities and are reported to affect both human-human and
human-machine interactions. Picard generalized this research field
as “affective computing” [26]. Many studies and systems have been
proposed to detect and utilize the emotions of users [5, 8, 14, 18, 29]
in this field. Several methods of determining user emotion have
been proposed, which focus on physical characteristics [13, 17], text
data [21, 31]. In our research, we focus on the mood status of users.
Mood is related but different from emotion in several aspects [2].
Mood is usually tend to last longer than emotion and is usually a
cumulative reaction while emotion is a more spontaneous reaction
or emotion caused by a particular event.
In recent years, various research have been conducted to estimate the mood state of the user by focusing on the sensors on
smartphones. Smartphones are equipped with multiple sensors
and can collect a wide variety of data, such as acceleration, rotation, location, and network connectivity. Also, smartphone can
now be considered indispensable to our lives with, for example,
more than 95% penetration rate in Japan. In addition, smartphonebased sensing do not require additional devices in sensing, such
as those for measuring heart rate, EEG or ECG, that may have
additional burden on the users. Owing to the rapid development
and spread of smartphones, various studies have been conducted
on the recognition and estimation of the mood status of a smartphone user. Most studies have constructed a classification model
that determines moods from the user’s contextual data obtained
from the smartphone sensor data and self-reporting annotation by
the user [19]. MoodScope [18] investigated the effects of the user
context on the mood of a user based on the smartphone sensor
data. In addition to emotion and mood, various types of internal
statuses of the users, such as “interruptibility” [24, 25], have been
recognized and estimated from the smartphone data. Other types of
sensing modality for emotion estimation is facial expressions in the
image data. Such research has been widely conducted [11], mainly
by using Facial Action Coding System [10]. And some research on
the smartphone [30] platform have been also performed recently.
In contrast to those previous works, our research highlights (1) its
novelty in the combined use of smartphone sensor data and web

NationalMood: Large-scale Estimation of People’s Mood from Web Search Query and Mobile Sensor Data

Yahoo! JAPAN
Service (1)

,,

Yahoo! JAPAN
Service (n)

Yahoo! JAPAN
Service (1)

Time left: 5:32

How are you in a mood now?

Yahoo! JAPAN Affective Service Framework

strong negative
negative

Yahoo! JAPAN Web Site

Server/cloud side

slight negative
neutral

Client/edge side

Yahoo! JAPAN mobiile application
Sensors

Context
information

Web browser

Notification saying “It’s 14:00
Please answer the
questionnaire.”

Desktop / mobile platform

User inputs

slight positive
positive
strong positive

User

Figure 2: Yahoo! JAPAN Affective Service Framework
search queries, and also a large-scale data collection study and data
analysis.
Focusing on the data on the web, researchers are currently working on estimating the emotional states of users by analyzing text
data on social networks such as Twitter [3, 31] and Facebook [15, 16].
These social network text data may contain sentences containing
the affective information of users. In this research, we focus on the
web search queries to estimate the users’ mood status since they
are easy-to-collect noninvasive type of data. In reality, it is difficult
to estimate the affective state directly by using such queries since
most of them comprise a few words and nouns. Again, our novel
approach focuses on a combination with different types of mood
estimation models from smartphone sensors and search queries.

3

YAHOO! JAPAN AFFECTIVE SERVICE
FRAMEWORK

Figure 2 shows the conceptual view “Yahoo! JAPAN Affective Service Framework” being developed on Yahoo! JAPAN web service.
Yahoo! JAPAN has a widely-known and widely-used web site in
Japanese market, with more than 70 Yahoo! JAPAN -branded services such as “search”, “news”, “shopping”, “auction”, “movie” and
“weather” and with the total number of 80 million registered users.
(Note that Japan’s national population is about 126 million.) In addition to the conventional web pages optimized both for PC and
mobile devices, Yahoo! JAPAN has its own smartphone application
both on iOS and Android platform. More than 60 million users are
using these applications, making them one of the most popular
smartphone applications in this country.
Our view around Yahoo! JAPAN Affective Service Framework is
as follows. At the server side, each of more than 70 Yahoo! JAPAN
services are logging users’ usage including page view and its duration, clicks, and various types of inputs including web search
keywords as the most major example of such kind. In addition, at
the users’ client side, our smartphone application can opportunistically collect various types of sensor data on the users’ smartphone,
given the users’ permission. Hence, with such multiple types of
input data both from the user’s client and server sides, we can
opportunistically estimates the user’s affective status by using the

Figure 3: Screenshot of Data Collection Application
machine learning techniques, and share the results with diverse Yahoo! JAPAN services on top of the that so that those services realize
service-specific affective-aware adaptation and optimization.

4

DATA COLLECTION STUDY

Towards the realization of such framework above, firstly collecting
data and the user’s subjective mood evaluation from the real-world
is inevitable. Thus, we first conducted a data-collection study with
460 users for 90 days. We collected continuous data from various
types of smartphone sensors as well as the user’s subjective mood
evaluation (up to 6 times a day) as the ground truth label.

4.1

Participants

For the study, participants were recruited through an external
agency. The recruitment criteria were as follows: (1) the age should
be in the range of 18-59 years, (2) must own an active Yahoo!
JAPAN registered account, (3) must have the ability to use the
Yahoo! JAPAN search functionality once or more times per week
and should have performed a search at least once in the last month,
(4) must own and use an Apple iOS smartphone as a private primary
phone in their daily life, and (5) must be a user of an iPhone 7 or
later and iOS version 12 or above. The participants were informed
that this study was “an experiment about your condition” during
the recruitment process.
A total of 460 users, consisting of university students, staff members, and research engineers aged between 19 and 54 years (average:36.92), were recruited.

4.2

Duration

The study was conducted for 90 days, from November 1, 2019 to
January 29, 2020.

4.3

Experimental Setup

We developed a dedicated smartphone application in this study,
as illustrated in Figure 3. The application was developed for the

,,

Okoshi and Sasaki, et al.

Table 1: Sensor Type and Sensing Frequency
Sensor Type

Sensing Frequency

Accelerometer
Barometer
Battery status
Location
Network type
Weather (from OpenWeather)
Screen status(On/Off)

10Hz
1Hz
1Hz
1/180Hz
(changed event-based)
1/60Hz
(changed event-based)

iOS platform owing to several reasons. First, the market share of
iOS is higher than that of Android in the Japanese market; thus,
the recruitment of participants is easier. Second, the number of
iPhone models (such as iPhone 7, 7Plus, 8, 8Plus, X, and 11) of
Apple is lower than that of Android phones (hundreds of models
by dozens of manufactures with different OS-level optimization
in power management, sensing, etc.). Thus, we can easily test the
application with such phone models to achieve higher execution
stability. Third, thanks to the iOS AWARE Framework [12, 23], we
can implement and deploy an application that can continuously
collect various sensor data in spite of the fact that iOS is a rather
strict environment as a sensing platform than Android.
Once the application is installed on the smartphone of a user,
it continuously collects multiple types of data from the embedded
sensors of the phone, as detailed in Table 1, and periodically uploads
the data to the server.
The application can also issue a notification (as shown on the
left-hand side of Figure 3) at the timings configured by the developer. Once the user responds to the notification, the application
opens a questionnaire, where the user can report his current mood
status on a 7-level Likert scale (1. strongly negative, 2. negative, 3.
moderately negative, 4. neutral, 5. moderately positive, 6. positive,
and 7. strongly positive).

4.4

Experimental Procedure

Our experimental procedure consisted of the following three parts:
(1) Each participant had a meeting with a study researcher at the
beginning of the study and received basic information and instructions about the study, which was followed by the signing of a consent form. Next, the participants were asked to install and launch
our software on their smartphones. They were asked to grant the
following permissions to the application: (1) mic, (2) push notification, (3) motion and fitness activity, and (4) location (configured as
“always”) data sensing feature of the iOS platform.
(2) After the initial meeting, the 30-day study period started.
During this period, a push notification appeared six times (at 8:00
AM, 10:00 AM, noon, 2:00 PM, 4:00 PM, and 6:00 PM) every day.
Each participant was asked to proceed with the survey within 2
hours after the delivery of each notification. When the participant
opened a notification, the application screen (Figure 3) appeared
and asked the affective mood of the user on the 7-level Likert scale.
The participant selected the status, and after a confirmation prompt,
the answer was submitted to the server.

Table 2: Extracted Features
Sensor Type

Number of Features

Representative Features

Accelerometer

23

(mean, std, median, min, max) magnitude
mean (each axis)
variance (each axis)
variance (each axis)
skew (each axis)
kurtosis(each axis)
correlation (xy, yz, zx)
covariance (xy, yz, zx)

Barometer

5

(mean, std, median, min, max) magnitude

Battery status

7

(mean, std, median, min, max) battery level
number of charge times
length of charge minutes

Location

12

location entropy
number of location transitions
moving time percent

Network type

5

number of WiFi connectivity established
number of mobile connectivity established
most frequent network type
rate of WiFi
rate of mobile network

Weather
(from OpenWeather)

50

weather type
(mean, std, median, min, max) temperature
(mean, std, median, min, max) humidity

Screen status(On/Off)

11

number of unlocks (per minute)
number of interaction (per minute)

4.5

Reward

We created an instant point reward system in the application. Each
participant scored 0, 20, 30, or 40 points for 0-3, 4, 5, or 6 answers,
respectively, in a day. The earned reward points were accumulated
throughout the study period. When a participant reached the configured minimum total reward points, i.e., 1500 points (by answering 4
answers every day for 75 days or 6 answers every day for 38 days),
they received a payment. They received an additional payment
when they exceeded 2000 points.

5

MODEL BUILDING

This section describes our model building of two different models,
Search Mood Model (SMM) and search-Query Mood Model (QMM)
respectively. As introduced and illustrated in Figure 1, SMM classifies user’s mood from a set of features computed from sensor data.
Using the built SMM model, having more training data, we build
QMM that estimates user’s mood from search queries.

5.1

Sensor Mood Model (SMM)

For building Search Mood Model (SMM), we follow an approach
with time-frame-based feature extraction of the time-series sensor data and their classification which are widely used in activity
recognition area [1].
5.1.1 Feature Extraction. First, we extracted features of each 3hour time window from the collected raw sensor data obtained from
our study with 460 users for 90 days. The features were extracted
for each sensor type. The types of extracted feature are different
depending on the sensor types. Table 2 summarizes the number of
features extracted along with several representative feature types.
5.1.2 Model Building. Then we constructed a supervised machine
learning model from frames base on the extracted feature vector
and a self-reported mood status as its ground truth label. In this

NationalMood: Large-scale Estimation of People’s Mood from Web Search Query and Mobile Sensor Data

Table 4: Performance of search-Query Mood Model (QMM)

Table 3: Performance of Search Mood Model (SMM)
Label

Precision

Recall

F1-score

-1
0
1

0.23
0.41
0.85

0.36
0.54
0.73

0.28
0.46
0.78

avg

0.72

0.67

0.69

QMM (with SMM (proposed))
QMM (without SMM)

model building, we treat the self-reported mood status as a threeclass classification problem. The collected mood answers (originally
in the 7-level Likert scale) were assigned to 3 different labels, −1
for “strongly negative”, “negative”, and “moderately negative”, 0 for
“neutral”, and +1 for “strongly positive”, “positive” and “moderately
positive.” We chose Random Forest [4] for the machine learning
algorithm which revealed the best classification performance compared with others.
5.1.3 Cross-validation Performance. According to a 10-fold crossvalidation for the built model, the model performs an accuracy
of 66.6 %. Table 3 shows the results of the overall performance
evaluation.

5.2

Query Mood Model (QMM)

QMM is a model that examines the relationship between a user’s
web search query and the user’s mood score during the search
behavior. After its training, it classifies the user’s mood score from
their search query data. Here, there can be two different types of
mood score, namely (a) the scores answered by the data collection
participants with questionnaire and (b) the scores estimated by
SMM based on the collected sensor data. In this section, we explain
the concept of QMM and how additional use of (b) increases the
performance of QMM.
5.2.1 Model Building. For each fixed time range (what we call
“session”), QMM gets trained from the data of a user’s mood score
and search behavior during the session.
To investigate the validity of the trained QMMs qualitatively,
we employed logistic regression, which is a typical example of a
“white box” model with high model interpretability, as a model.
Note that it is not necessary to specify the logistic regression as
training scheme in actual operation; we believe that non-linear
SVMs and decision tree-based regressions such as Xgboost (that
are specialized for performance) are also effective.
One session was defined as one record, and training was performed in the following regression equation.
(1)

where 𝑦 is the mood score and 𝜃𝑘 is the learned weight. 𝑥𝑘 is the
search query assigned to a feature, with 1 if it was searched in that
session and 0 if it was not. 𝑥𝑘 indicates only whether the query is
searched or not, not considering the number of searches.
5.2.2 Combination with SMM. In this training, sessions that do not
have both “search behavior” and “mood score” data will be treated
as “missing data”. Therefore, mood scores based on the users’ raw

# of data

accuracy

46,318
27,402

94%
87%

survey response data have the challenge in their limited number
of responses available for training. In such a situation, our SMM
model, along with collected sensor data, is an effective means of
increasing the number of mood scores to be used for the training.
Since the sensor is always on as long as the smartphone (with our
application) is on, SMM can be used to estimate a user’s mood
virtually for 24/7.
We use a session of 3 hour long. The search queries retrieved in
the three separated hours were used as features. Since SMM-based
mood scores are available for 24 hours a day, logically the length
of each session can be more short (fine-grained). However, if the
length is too short, there is a risk that the questionnaire-based
mood scores of the comparison method may become too sparse
to be learned. Hence, the sessions needed to be reasonably long.
From such discussion, we decided to use the session length of three
hours in this study.
5.2.3 Cross-validation Performance. We built 2 QMM models, one
trained only from the questionnaire answer data, and another one
with additional training data based on the SMM outputs.
For both models, the condition of the performance evaluation is
as follows. The data were randomly divided into 80% training data
and 20% evaluation data. Considering the effect of randomness, the
evaluations were conducted for 10 times. The training data were
balanced so that the amount of positive and negative data was the
same before training. For the evaluation data, we did not perform
balancing.
The results are shown in Table 4, which clearly confirms the effectiveness of SMM. Compared to our baseline QMM without SMM
use, the accuracy increases from 87% to 94% in case with additional
data brought by SMM. The table also shows that the number of
training data has been more than doubled by SMM, indicating that
the more than doubling of the dataset used for training by SMM
has contributed greatly to the significant improvement in prediction accuracy. From these results we conclude to adopt a QMM
trained with SMM in this research, and go on to our evaluation
experiments.

6
𝑦 = 𝜃 0 + 𝜃 1 𝑥 1 + 𝜃 2 𝑥 2 + · · · + 𝜃 𝑛 𝑥𝑛 ,

,,

EVALUATION 1: MOOD-EFFECTIVE
ADVERTISEMENT

To investigate how our mood model works effectively, we evaluated
it with our past web advertisement business cases. We conducted an
experiment on 100 advertisement cases that were actually delivered
to our users in the past. We examined the impression (the number
of times the advertisement was exposed to users) and click logs for
those 100 ads, and tested offline to see if there were ads that made
a difference in whether users clicked or not, depending on their
mood state just before their click.

,,

Dataset

6.2

Metrics

In this study, a pairwise method was used to investigate whether
there are ads that change the click state of an ad depending on the
user’s mood score. First, we organized the logs for the days the ads
were served and converted the data into a format of "timestamp,
the viewer’s user ID, if clicked/or not."
Then, for each day, we randomly select two records from all
the records. If only one of the two extracted records is a "clicked
log", we compare the mood scores of the two records each other.
We mark “positive” when the clicked user’s mood score is higher,
and vice versa. This pairwise extraction process was performed 100
million times for each day of the log, to determine whether each ad
was more likely to be clicked on when the user’s mood score was
positive or negative.

6.3

Result

6.3.1 Existence of “Mood-Effective Ads”. We show the result in
Figure 4. The x-axis is the number of days “positive” wins out of 14
days, while the y-axis shows the percentage of such advertisements
(among 100 ads). Two lines are depicted in the figure; they are (1)
the pairwise comparison result based on the actual estimated mood
scores and, and (2) a theoretical line that would be drawn if we
assume that the winner in each pairwise comparison attempt was
completely random (50% - 50%).
Firstly, as we can understand easily, the shapes of the graphs
(2) random theoretical values have a convex shape that expands
toward the center. In other words, the line (2) can be said to be the
result of a hypothetical experiment of 14 consecutive coin tosses.
Thus, obviously 14 consecutive win (or lose) out of 14 tries is an
very rare event. (The probability of a positive winning in all 14
days is about 0.01% when we randomly assign a score. This is the
probability of 1 out of every 10,000 ad serving.) Similarly, the same
kind probably with 13 wins (or losses) is about 0.1% (1 out of 1,000).
However, a clear difference can be observed when looking at the
actual data (1). The number of ads where the positive wins on all 14
days or loses on all 14 days can be found in about 1% (1 out of 100)
of the ads, if they would be served by the mood score. Furthermore,
the results with “more than 13 wins or losses” scored 6 (6%). We
also can observe that the shape of the line (1) convexity is spread

(1) Result with actual mood score
(%)

(2) Result with theoritical 50%-50% random winning chance
25

Rate of advertisements

The targeted dataset consisted of 100 ads served through Yahoo!
JAPAN ’s ad service. To ensure sufficient amount of impression
and click volume for the data analysis, the 100 ads were selected
from historical ad business data stored in our servers as the most
recent 100 projects with a delivery record of at least 14 days. The
targeted ads had at least about 5 billion user impression (view) and
about 3 million clicks during the 14 day period in total. User IDs
and timestamps for impressions and clicks on ads are respectively
stored in our server’s internal storage. Therefore, through the user
ID in each impression or click log, we can link the user’s history of
organic search behavior. Through think link, for each user, their
three-hourly mood score can be calculated by using our QMM
model. Finally, the results of this calculation can be used to analyze
whether or not a user in a certain mood state clicked on an ad when
they viewed it.

20
15
10
5
0
0

1

2 3 4 5 6 7 8 9 10 11 12 13 14
The number of days "positive" wins out of 14 days

Figure 4: Distribution
tive/Negative Ratio
0.120

Standard deviation

6.1

Okoshi and Sasaki, et al.

of

Advertisements

by

Posi-

0.106

0.100
0.080
0.060

0.035

0.040
0.020

0.012

0.010

100,000,000

200,000,000

0.004

0.003

0.000
1,000,000

10,000,000

500,000,000 1,000,000,000

Number of trials

Figure 5: Standard Deviation Values with Different Number
of Trials

out to look like it has been crushed to the side. From these results,
we can confirm that there are indeed certain advertisements that
are effective for delivery based on the recipients’ mood scores.
For the number of trials “100 million”, we tried several different
numbers and confirmed that the variability was sufficiently small
with this number of iteration. Figure 5 shows the standard deviation scores for the positive/negative judgment of the ads in case of
different number of trials in the pairwise comparison method. 5 ads
were arbitrarily selected, the metric was applied, and the standard
deviation of the scores of the positive/negative ratio was obtained.
As shown in the figure, the score obtained after one million trials
has 0.106, which means that the result may increase or decrease
by about 10%. On the other hand, with 100 million trials, the standard deviation was about 1.2%, which means that the score does
not change by more than that number of trials. At this level, we
determined that the score would be statistically reliable.
6.3.2 Detailed Ad Content Analysis. We further examined in detail
the ads that were more likely to be clicked on in the same emotional
state for more than 13 out of 14 days. Although we cannot provide

NationalMood: Large-scale Estimation of People’s Mood from Web Search Query and Mobile Sensor Data

7

EVALUATION 2: NATIONAL MOOD

The purpose of this experiment is to examine the value of calculating the mood score in nation-wide by using the proposed method.
Regarding the registered users of Yahoo! JAPAN , our internal data
on their demographics shows that almost all of them are geographically located in Japan. Therefore, by calculating and averaging the
mood scores of all those users on a given day, we can derive a value
that we call “the national mood score” of Japan on a daily basis.

7.1

Daily National Mood Score

In this evaluation, for each day of the given dataset, we (1) computed (individual) daily mood scores of approximately 11,000,000
Yahoo! JAPAN search users from their search query logs previously
acquired and stored, and (2) calculated the average of them. We
name this average score as “Daily National Mood Score”. Then, we
(3) examined the changes of this score over time. Note that the exact
number of the users for the calculation changed day by day, since
we targeted Yahoo! JAPAN registered users who used our search
engine for at least once, for each particular day.
For our 2 types of evaluation goals, we used two different datasets
with different periods and duration, as we present in Section 7.3
and 7.4.

7.2

Comparative Method

As described earlier, one of the challenges in this research is to show
the effectiveness of SMM when used inside the QMM training. Thus,
we compare (1) QMM with SMM as our proposed method and (2)
QMM without SMM as a comparative method in this evaluation.
Note that all the conditions (algorithm, hyper parameters, split ratio
between the data) are the same between these two methods.

7.3

Result 1: Weekly Mood Rhythm

The first case is an analysis of the trend of daily mood score for four
weeks. We want to see how national mood score changes within a
month, relatively a short term. For such analysis, we used a dataset
for the period from July 1, 2019 to July 28, 2019. We carefully chose
this period from the stored log to avoid including major news that
could have a significant impact on many users.
Figure 6 shows the resulted national mood scores for this period.
The x-axis represents the date while the y-axis represents the daily
score. A very interesting result we can read in the figure is that the
scores tend to be clearly positive on weekends and more negative
on Mondays when the workday begins (or Tuesdays when Monday
is a holiday on July 15).

Proposed method

Proposed method

2.52

National Mood Score

Comparative method

Comparative method

2.52

1.83

2.5

1.82

2.5

National Mood Score

examples of actual advertisements delivered due to the confidentiality of the business-related information, we found that the ads
that were most likely to be clicked on when the user was in a good
mood were those that contained the keywords "free" and "deals,"
and that many users were considering purchasing a product or
service in the future. On the other hand, the common denominator
of advertisements that were more likely to be clicked on when users
were in a bad mood was the content of the advertisements to relieve
users of their complaints. It is very interesting to note that there
were clear differences between the ad groups that were more likely
to be clicked on in good and bad moods.

,,

2.44

1.82

1.81

2.48

1.81

2.48
2.46

1.83

1.8

2.46
1.79

1.8

2.44
1.78

National
holiday

2.42

(Monday)

1.78

2.4

2.42

2.38

2.4

Week
end

Week
end

Week
end

Week
end

1.76

1.77
1.75

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28

Date (July 29)

2.38

1.76

1.75

1 26: 3Daily
4 5 6National
7 8 9 10Mood
11 12 13Score
14 15 16
18 19 20 21 22and
23 24 25 26 27 28
Figure
for17 Weekdays
Weekends
Date (July 29)

Although no ground truth data exists on nation-wide mood, this
tendency to feel better later in the week and then worse again on
Monday is considered to be a visceral result in a society where
many people work Monday through Friday, as there is the term
"Blue Monday." In fact, we have some facts that can explain this.
According to a white paper by the Ministry of Health, Labour and
Welfare [20], the highest number of suicides are on Mondays in
Japan. Another survey of 400 men and women, conducted by a
company, found that the highest number of respondents in all
age groups said they felt most depressed on Mondays 1 . On the
other hand, it’s easy to imagine the mood being more positive on
weekends and holidays.
The proposed method looks successfully expressing the rhythm
of the mood change over the weekdays and weekends in an instructive manner, while such rhythm is not very clear in the comparative
method. In particular, the proposed method is clearly showing the
depression on Monday (or Tuesday if Monday was a national holiday). From this result, we discuss that the proposed method is better
explaining the weekly mood rhythm than the comparative method.

7.4

1.79

1.77

Result 2: COVID-19 and National Mood

Our second evaluation aims to reveal how national mood score
changes in the COVID-19 pandemic situation in 2020. In this case,
we looked at the change in the daily national mood scores every
Sunday from the beginning of the year to the end of July, on two
different years 2018 and 2020. (The most recent stored historical data
for such a long term was the data on year 2018. Due to some internal
infrastructural change, we could not retrieve the equivalent data
for year 2019.) We chose Sundays since every Sunday is a holiday.
On the other hand, in the case of other days of the week, it was
assumed that the analysis results would be difficult to discuss due
to occasional holidays.
1 https://kyodonewsprwire.jp/release/201803262310

,,

Okoshi and Sasaki, et al.

1.02
1.01
1
0.99
0.98
0.97

1.04
1.03

State of
Emergency
finished
(May 14)

State of
Emergency
(April 7)

Proposed method

Comparative method

1.02
Proposed
methodApril 26 Comparative method

August10

1.01
1
0.99
0.98
0.97
0.96
0.95

01/05
01/12
01/19
01/26
02/02
02/09
02/16
02/23
03/01
03/08
03/15
03/22
03/29
04/05
04/12
04/19
04/26
05/03
05/10
05/17
05/24
05/31
06/07
06/14
06/21
06/28
07/05
07/12
07/19
07/26

1.03

Olympics
Paralympics
postponed
(March 24)

Relative National Mood Score

1.04

Public school
closed
(March 2)

Number of COVID-19 patients in Japan

Relative National Mood Score

First case
in Japan
(Jan. 16)

Date in Year 2020

0.96

01/05
01/12
01/19
01/26
02/02
02/09
02/16
02/23
03/01
03/08
03/15
03/22
03/29
04/05
04/12
04/19
04/26
05/03
05/10
05/17
05/24
05/31
06/07
06/14
06/21
06/28
07/05
07/12
07/19
07/26
08/02
08/09
08/16
08/23
08/30

0.95

Date in Year 2020
Figure 7: Relative National Mood Score and Number of COVID-19 Patients in Year 2020

On such dataset, we firstly calculated the national mood score
for each day of the period. Then, for each year, all the scores were
normalized to the score of the first Sunday of the year respectively.
The result is illustrated in Figure 7. The x-axis shows the date.
The lines represent the daily national mood scores. The value in
y-axis is “relative” compared to the score of the same day in year
2018. A value greater than 1 indicates a higher score in the same
period in 2020 than in 2018, and vice versa. The bar graph shows
the number of COVID-19 participants in Japan in 2020 [33].
Surprisingly, the results show that a peak of the waves of COVID19 infection spread and degradation of the national mood score are
synchronized. The peak of the COVID-19 first wave was April 26
(the number of the patients: 9,577). At exactly the same day, the
mood score decreased down to the bottom 0.983. The peak of the
second wave was August 10 (the number of the patients: 15,042).
The numbers around the second bottom of the score were 0.9943
(August 3) and 0.9948 (August 10). On the other hand, we can not
confirm such clear tendency in the comparative method.
It is very interesting to read the tendency for mood to become
more negative as the number of COVID-19 patients increases, and
more positive as the number of patients begins to decrease. In
2020, Japan had originally planned to host the Tokyo Olympics and
Paralympics. The mood in Japan was positive in the beginning of
the year. However, COVID-19 began to rage, the Olympics were
postponed, and various economic activities were restricted. The
number of corona cases began to rise in Japan, and the public was
frightened of it. Then, as the first wave subsided, the mood was
positive for the restoration of economic activity again. However,
when the second wave starts to occur, the mood goes negative
again. This graph looks to have successfully tracked the tumultuous
changes in Japanese people’s mood in 2020.

The most remarkable point on our model (with the proposed
model) is that the period of time when we collected sensor data
and search queries for the model building was from October to
December of 2019, which is before the COVID-19 pandemic. This
means that there is no possibility that the search queries in the
trained model contain rules, such as “A query COVID-19 is a negative feature for mood estimation”. Again, there is no ground truth
on “national mood”. However, from the fact that we can nevertheless observe the score trend inversely correlated with the number
of COVID-19 patients, we conclude that the national mood score
with the proposed method matches our intuition more.

8

LIMITATION AND FUTURE WORK

The next step in this study is the evaluation of the user’s sentiment
based on real services. Our plan is to develop an actual service that
can differentiate advertisements and recommendations based on
mood scores. However, there are three problems with this approach.
First, we need a method for estimating which advertisements are
relevant to what type of mood in advance. Once we build such a
methodology, it will be possible to evaluate the actual advertisements. Another task is to improve the model performance. In this
study, we adopted a white-box model to examine the effectiveness
of the model qualitatively. We hope to employ models focused on
precision and recall performance towards further performance improvement when we conduct real-world tests. Finally, classification
other affective statuses (beyond mood) should be possible. We expect that the same framework can be used to model a wide range of
affective statuses. Our future work includes building such models
and extensive evaluation of them on our services.

NationalMood: Large-scale Estimation of People’s Mood from Web Search Query and Mobile Sensor Data

9

CONCLUSION

Affection-awareness is one of the key components in the humancentric information service. However, particularly in the real-world
web field, estimating such statuses of the user is yet to be realized.
We proposed a novel way estimation methodology of web user’s
mood based a combinational use of their search queries and mobile
sensor data. Our extensive data analysis revealed multiple interesting results, including the existence of advertisements to which
mood-status-based delivery would be significantly effective, and
the changes of national mood scores in the weekly rhythm and in
the COVID-19 pandemic situation.

REFERENCES
[1] Ling Bao and Stephen S Intille. 2004. Activity recognition from user-annotated
acceleration data. In International conference on pervasive computing. Springer,
1–17.
[2] Christopher Beedie, Peter Terry, and Andrew Lane. 2005. Distinctions between
emotion and mood. Cognition & Emotion 19, 6 (2005), 847–878.
[3] Johan Bollen, Huina Mao, and Alberto Pepe. 2011. Modeling public mood and
emotion: Twitter sentiment and socio-economic phenomena. Icwsm 11 (2011),
450–453.
[4] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.
[5] Keng-hao Chang, Drew Fisher, John Canny, and Björn Hartmann. 2011. How’s my
mood and stress?: an efficient speech analysis library for unobtrusive monitoring
on mobile phones. In Proceedings of the 6th International Conference on Body
Area Networks. ICST (Institute for Computer Sciences, Social-Informatics and
Telecommunications Engineering), 71–77.
[6] Arthur D Craig. 2002. How do you feel? Interoception: the sense of the physiological condition of the body. Nature reviews neuroscience 3, 8 (2002), 655.
[7] Charles Darwin and Phillip Prodger. 1998. The expression of the emotions in man
and animals. Oxford University Press, USA.
[8] Liyanage C De Silva and Suen Chun Hui. 2003. Real-time facial feature extraction
and emotion recognition. In Information, Communications and Signal Processing,
2003 and Fourth Pacific Rim Conference on Multimedia. Proceedings of the 2003
Joint Conference of the Fourth International Conference on, Vol. 3. IEEE, 1310–1314.
[9] Paul Ekman. 2006. Darwin and facial expression: A century of research in review.
Ishk.
[10] Rosenberg Ekman. 1997. What the face reveals: Basic and applied studies of
spontaneous expression using the Facial Action Coding System (FACS). Oxford
University Press, USA.
[11] Beat Fasel and Juergen Luettin. 2003. Automatic facial expression analysis: a
survey. Pattern recognition 36, 1 (2003), 259–275.
[12] Denzil Ferreira, Vassilis Kostakos, and Anind K Dey. 2015. AWARE: mobile
context instrumentation framework. Frontiers in ICT 2 (2015), 6.
[13] Jorge Goncalves, Pratyush Pandab, Denzil Ferreira, Mohammad Ghahramani,
Guoying Zhao, and Vassilis Kostakos. 2014. Projective Testing of Diurnal Collective Emotion. In Proceedings of the 2014 ACM International Joint Conference on
Pervasive and Ubiquitous Computing (Seattle, Washington) (UbiComp ’14). ACM,
New York, NY, USA, 487–497.
[14] Iftikhar Ahmed Khan, Willem-Paul Brinkman, and Robert Hierons. 2013. Towards
estimating computer users’ mood from interaction behaviour with keyboard and
mouse. Frontiers of Computer Science 7, 6 (2013), 943–954.
[15] Adam DI Kramer. 2012. The spread of emotion via Facebook. In Proceedings of
the SIGCHI Conference on Human Factors in Computing Systems. ACM, 767–770.
[16] Adam DI Kramer, Jamie E Guillory, and Jeffrey T Hancock. 2014. Experimental
evidence of massive-scale emotional contagion through social networks. Proceedings of the National Academy of Sciences 111, 24 (2014), 8788–8790.
[17] Dong-Soo Kwon, Yoon Keun Kwak, Jong C Park, Myung Jin Chung, Eun-Sook
Jee, Kyung-Sook Park, Hyoung-Rock Kim, Young-Min Kim, Jong-Chan Park,
Eun Ho Kim, et al. 2007. Emotion interaction system for a service robot. In
Robot and Human interactive Communication, 2007. RO-MAN 2007. The 16th IEEE
International Symposium on. IEEE, 351–356.
[18] Robert LiKamWa, Yunxin Liu, Nicholas D Lane, and Lin Zhong. 2013. Moodscope:
Building a mood sensor from smartphone usage patterns. In Proceeding of the
11th annual international conference on Mobile systems, applications, and services.
ACM, 389–402.
[19] Yuanchao Ma, Bin Xu, Yin Bai, Guodong Sun, and Run Zhu. 2012. Daily mood
assessment based on mobile phone sensing. In Wearable and implantable body
sensor networks (BSN), 2012 ninth international conference on. IEEE, 142–147.
[20] Ministry of Health Labour and Welfare,JAPAN 2019. White paper on Suicide
Prevention in Japan. Ministry of Health Labour and Welfare,JAPAN. https:
//www.mhlw.go.jp/wp/hakusyo/jisatsu/19-2/index.html.

,,

[21] Saif M. Mohammad and Peter D. Turney. 2010. Emotions Evoked by Common
Words and Phrases: Using Mechanical Turk to Create an Emotion Lexicon. In
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to
Analysis and Generation of Emotion in Text (Los Angeles, California) (CAAGET
’10). Association for Computational Linguistics, Stroudsburg, PA, USA, 26–34.
[22] LJM Mulder. 1992. Measurement and analysis methods of heart rate and respiration for use in applied environments. Biological psychology 34, 2 (1992),
205–236.
[23] Yuuki Nishiyama, Denzil Ferreira, Yusaku Eigen, Wataru Sasaki, Tadashi Okoshi,
Jin Nakazawa, Anind K Dey, and Kaoru Sezaki. 2020. IOS Crowd–Sensing Won’t
Hurt a Bit!: AWARE Framework and Sustainable Study Guideline for iOS Platform.
In International Conference on Human-Computer Interaction. Springer, 223–243.
[24] Tadashi Okoshi, Kota Tsubouchi, and Hideyuki Tokuda. 2019. Real-World Product Deployment of Adaptive Push Notification Scheduling on Smartphones. In
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining. 2792–2800.
[25] Veljko Pejovic and Mirco Musolesi. 2014. InterruptMe : Designing Intelligent
Prompting Mechanisms for Pervasive Applications. In Proceedings of the 2014
ACM International Joint Conference on Pervasive and Ubiquitous Computing Adjunct Publication - UbiComp ’14. ACM Press, Seattle, WA, 395–906.
[26] Rosalind W Picard and Roalind Picard. 1997. Affective computing. Vol. 252. MIT
press Cambridge.
[27] Jean-P Royet, David Zald, Rémy Versace, Nicolas Costes, Frank Lavenne, Olivier
Koenig, and Rémi Gervais. 2000. Emotional responses to pleasant and unpleasant
olfactory, visual, and auditory stimuli: a positron emission tomography study.
Journal of Neuroscience 20, 20 (2000), 7752–7759.
[28] Kilseop Ryu and Rohae Myung. 2005. Evaluation of mental workload with a
combined measure based on physiological indices during a dual task of track
ing and mental arithmetic. International Journal of Industrial Ergonomics 35, 11
(2005), 991–1009.
[29] Jocelyn Scheirer, Raul Fernandez, Jonathan Klein, and Rosalind W Picard. 2002.
Frustrating the user on purpose: a step toward building an affective computer.
Interacting with computers 14, 2 (2002), 93–118.
[30] Myunghoon Suk and Balakrishnan Prabhakaran. 2015. Real-time facial expression
recognition on smartphones. In 2015 IEEE Winter Conference on Applications of
Computer Vision. IEEE, 1054–1059.
[31] Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan, and Amit P Sheth. 2012.
Harnessing twitter" big data" for automatic emotion identification. In Privacy,
Security, Risk and Trust (PASSAT), 2012 International Conference on and 2012
International Confernece on Social Computing (SocialCom). IEEE, 587–592.
[32] Glenn F Wilson. 2002. An analysis of mental workload in pilots during flight using
multiple psychophysiological measures. The International Journal of Aviation
Psychology 12, 1 (2002), 3–18.
[33] Yahoo! JAPAN Corporation 2020. Summary of new corona virus infections. Yahoo!
JAPAN Corporation. https://hazard.yahoo.co.jp/article/20200207.

