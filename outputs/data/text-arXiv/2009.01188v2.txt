arXiv:2009.01188v2 [cs.SI] 5 Sep 2020

A S TANCE DATA S ET ON P OLARIZED C ONVERSATIONS ON
T WITTER ABOUT THE E FFICACY OF H YDROXYCHLOROQUINE
AS A T REATMENT FOR COVID-19

Ece Çiğdem Mutlu1,∗, Toktam Oghaz2 , Jasser Jasser2 , Ege Tütüncüler1
Amirarsalan Rajabi2 , Aida Tayebi1 , Ozlem Ozmen1 , Ivan Garibay1,2,†
1
Department of Industrial Engineering
2
Department of Computer Science
{ece.mutlu, jasser.jasser, ege.tutunculer, igaribay, ozlem}@ucf.edu
{toktam}@cs.ucf.edu, {amirarsalan, aida.tayebi}@knights.ucf.edu

A BSTRACT
At the time of this study, the SARS-CoV-2 virus that caused the COVID-19 pandemic has spread
significantly across the world. Considering the uncertainty about policies, health risks, financial
difficulties, etc. the online media, specially the Twitter platform, is experiencing high volume of
activity related to this pandemic. Among the hot topics, the polarized debates about unconfirmed
medicines for the treatment and prevention of the disease have attracted significant attention from
online media users. In this work, we present a stance data set, COVID-CQ, of user-generated
content on Twitter in the context of COVID-19. We investigated more than 14 thousand tweets
and manually annotated the opinions of the tweet initiators regarding the use of “chloroquine” and
“hydroxychloroquine” for the treatment or prevention of COVID-19. To the best of our knowledge,
COVID-CQ is the first data set of Twitter users’ stances in the context of the COVID-19 pandemic,
and the largest Twitter data set on users’ stances towards a claim, in any domain. We have made this
data set available to the research community via GitHub3 . We expect this data set to be useful for
many research purposes, including stance detection, evolution and dynamics of opinions regarding
this outbreak, and changes in opinions in response to the exogenous shocks such as policy decisions
and events.

1

Introduction

By August 2020, about 20 million confirmed infected cases with SARS-CoV-2 virus have been reported worldwide.
Among the affected countries, the United States of America has reported the highest amount of infection, which is
about 5 million infected individuals. The rapid spread of the virus and the uncertainty and risks associated with the
COVID-19 pandemic has led institutions, policymakers, and individuals to seek drastic countermeasures against the
spread of this disease, while imposing the least costs [1]. For instance, many governments have taken severe responses
to contain the virus, such as lock down the infected regions and shuttering their economies for weeks, closing their
borders, and investing an unprecedented amount of funding on medical facilities and equipment. In the absence of a
vaccine, healthcare professionals resorted to alternative uses of existing drugs. Examples of such drugs are chloroquine
(CQ) and hydroxychloroquine (HCQ), which are immunosuppressive and anti-parasite drugs that have been in use to
treat malaria and lupus. Hydroxychloroquine is a less toxic metobolite of chloroquine and has been identified to have
less side effects [2]. Both of these drugs are included in the treatment regimen of COVID-19 patients by physicians
in Italy, France, and China, after some studies suggested that their use could be effective in inhibiting COVID-19
infections [3, 4].
∗

All authors contributed equally to this study.
Corresponding author: Ivan Garibay, igaribay@ucf.edu
3
https://github.com/eceveco/COVID-CQ

†

While the majority of these studies came under heavy criticism due to the lack of scientific rigor, such as unusually
small sample sizes and the absence of randomized trials, certain doctors, physicians and politicians quickly embraced
the idea that hydroxychloroquine could be a “miracle cure”. On the other hand, some studies have cautioned against the
use of chloroquine and hydroxychloroquine for the treatment of COVID-19 due to their hazardous side effects and their
inefficacy [5, 6]. In this information-scape of conflicting results and uncertainty, the unproven claim that Chlroquine
and hydroxychloroquine are cure for COVID-19 quickly spread in online social networks and mainstream media outlets.
In the White House press briefing dated March 19, 2020, hydroxychloroquine received endorsement from the US
Administration, which accelerated spread of the rumors concerning the effectiveness of hydroxychloroquine against the
disease. Thus, extensive polarization is observed on the effectiveness of these two drugs, specially, hydroxychloroquine,
while this polarization is fueled by societal, political, and medical discussions about these drugs.
Following these events and the political attention that hydroxychloroquine received, the claim that chloroquine and
hydroxychloroquine may be effective tools against COVID-19 created tensions in social media, with many people
posting about evidence for or against the effectiveness of both drugs, supporting or rejecting their use in a political tone,
or just making neutral remarks about the ongoing chloroquine/hydroxychloroquine and COVID-19 situation. In this
study, we aim to identify and analyze Twitter users’ stances about the rumor that chloroquine and hydroxychloroquine
are cure for the novel coronavirus. For this work, we define rumor as an unofficial story or piece of news that might
be true or invented, and quickly spreads from person to person, per Cambridge Dictionary. Our contributions are as
follows:
• We present a manually annotated Twitter stance data set for the unproven claim of “chloroquine/hydroxychloroquine are cure for the novel coronavirus”, that we call COVID-CQ and it is accessible to
the public from our GitHub repository4 .
• To the best of our knowledge, COVID-CQ is the first stance dataset regarding COVID-19. This data can be
used by the research community to analyze the dynamics of the opinions of social media users in a worldwide
pandemic.
• To the best of our knowledge, COVID-CQ is currently the largest human-labeled stance dataset on Twitter
conversations with more than 14 thousand stance labels towards a claim.
• The conducted annotation procedure includes joint annotation of tweets and shared URLs for disambiguation.
This technique allowed us to produce accurate annotations for a challenging dataset that requires deep
understanding of the content to identify the true stance of a tweet.

2

Related Work

Detecting opposite opinions in a polarized conversation towards a target subject is a sub-domain of sentiment analysis,
usually referred to as stance classification [7]. In stance classification, the subject under investigation is generally a
person, organization, policy, or opinion [8]. The importance of this field of research relies on its applications, including
the automatic extraction of attitudes and opinions towards events, and fake news or rumor identification [9]. Many
studies on the literature of fact checking consider applying stance classification on potentially related documents to
gain knowledge on varying sources of information, and predict the factuality of a claim according to the strength of
aggregated stances [10]. Generally, three stance classes have been considered in the literature for the task of stance
classification: i) positive (in favor), ii) negative (against), and iii) neutral (none or neither); however, some studies have
approached this classification by considering an extra class for the unrelated or irrelevant documents [11]. Despite the
common categorization of stances as mentioned earlier, the idea of relative classification of stances using a ranking
mechanism is proposed in [12]. The problem of stance classification was further evolved by the introduction of a
complementary task to stance classification, which focuses on the stances towards given claims rather than entities,
proposed in [13]. The first data set on stance classification towards claims was also proposed in [13], which introduced a
stance data set for 2,394 claims on Wikipedia articles. This data set is the most similar corpus to our data set. However,
our focus is on the Twitter platform.
Despite the existence of many stance data sets for polarized social media subjects, the available data sets are mostly
focused on multiple target subjects, which results in having a small number of samples for each of the stance classes. For
instance, the data set introduced in [14] only contains labels for 4,455 tweets regarding the US presidential candidates
for the 2016 election: “Donald Trump”, “Hillary Clinton”, “Ted Cruz”, and “Bernie Sanders” . Also, the SemEval-2016
Task 6 benchmark [15] only contains 4,870 tweets with stance labels for 6 targets: “Atheism”, “Climate Change is
a Real Concern”, “Feminist Movement”, “Hillary Clinton”, “Legalization of Abortion”, and “Donald Trump”. In
addition to having a small size, SemEval data set was collected via hashtag queries and only specific tweets in which
4

https://github.com/eceveco/COVID-CQ

2

the hashtag appeared at the end of the tweet were considered. However, we did not exclude any tweets from our
corpus. Our selection criteria is a simple keyword query of root. Another related data set to our work is the Stances in
Replies and Quites (SRQ) data set proposed in [16], which contains stance labels for approximately 5,200 replies and
quotes to root tweets regarding varying events, including: “Student Marches”, “Iran Deal”, and “Santa Fe Shooting”.
The largest stance data set for Twitter is proposed in [13], which contains stance labels for 51,284 tweets regarding 5
operations related to the health and entertainment industries. However, this data set does not investigate stances toward
any particular claims.
Another related data set to our work is the TweetsCOV19 benchmark proposed in [17], which contains the available
knowledge base of more than 8 million tweets, including the metadata of the tweets, besides the extracted entities,
hashtags, user mentions, sentiments, and URLs. In contrast with our work, this data set does not contain user stances
towards a claim or an entity.
Our proposed corpus differs from the reviewed data sets on various aspects. First, we only focus on the stances of
Twitter users towards a single claim of “chloroquine and Hydroxychloroqine are cure for the novel coronavirus”.
Second, focusing on a single claim, our data set can be used to investigate the dynamics of opinions over time towards
the use of these drugs, in response to the exogenous shocks such as academic publications and events. Thus, our data
set fills the gaps between the changes of opinions over time and stance classification, which is not possible to investigate
using existing stance data sets. Third, considering the challenges regarding the true inference of the underlying stance
in a short text, we approached the problem of stance annotation as a joint labeling of tweet and shared URLs if the tweet
is not self-explanatory. For instance, the Twitter platform imposes a maximum length of 280 characters for each tweet,
which leads to the ambiguity of short tweets and the challenges for the inference of the true stances. As a result of this
work, we aim to introduce new challenges to the field of artificial intelligence, particularly, to the design of stance data
intensive classification models, and to encourage the design of algorithms that consider the utilization of all sources of
information with the goal of achieving accurate stance classification of textual content.

3

Stance Annotation

Eisenberg and Finlayson define annotation as the "process of explicitly encoding information about a text that would
otherwise remain implicit" [18]. For this study, annotation is the record of the Twitter audiences’ stances about the
running debate of chloroquine and hydroxychloroquine as treatments for coronavirus. Our purpose is to create a
pure human-annotated data set rather than ML-based data set with or without supervision, as we believe that humanannotation renders further studies more robust and reliable. The annotation procedure was conducted by a team of
containing 6 graduate and 3 undergraduate students in order to reach a consensus on the annotation guideline. In our
annotation procedure, each student was asked to annotate the individual tweets as "Against","Favor" or "Neutral/None"
for the unproven claim of "chloroquine/hydroxychloroquine is cure for the novel coronavirus", relying on the wellknown rumor listing website of fullfact.org 5 as in Kwan et al.’s study [19]. We have done our analysis on online users’
conversations regarding topics related to the COVID-19 pandemic in the Twitter platform. The data was collected
using the Twitter API and Hydrator 6 as suggested in [20]. The detailed list of keywords being used for our data
collection is given in the cited study. We considered tweets only related to the specific rumor and filtered tweets which
include "hydroxychloroquine, chloroquine, and HCQ" as keywords for our queries, published between 04/01/2020
and 04/30/2020. This data set includes 98,671 tweets generated by 75,685 unique Twitter users. Since stances of the
retweets may be easily attained with assumptions, we focused only on the 14,374 unique tweets (tweets/mentions/replies)
generated by 11,552 unique users (The most active user has 91 user-generated contents.) to decrease the work-load.
Each of the investigated tweets is annotated by at least two different annotators. In the first round, the data was
partitioned into 15 different clusters according to the time of the information creation and the tweet clusters were
randomly assigned to the every possible combination of our annotator pairs. Thus, any possible biases due to annotatorpair match and time are prevented (Figure 1). Among all the performed annotations, the inter-annotator agreement on
this set was 87.37%, which demonstrates that our annotators were effectively educated before conducting the procedure.
In the second round, the remaining 12.63% of the data was assigned to a third annotator who was not being asked to
annotate that specific tweet for the first round. After labeling all tweets, the cosine similarity between td-idf tokenized
and vectorized tweet texts and their labels were compared based on the assumption that similar tweets are more likely
to have a similar stance. Then, all our annotators were asked to discuss their annotation and the reasoning behind their
decision, to reach a consensus on the inconsistent tweets. Thus, noisy labeling has been prevented.
Some of the challenges we faced while annotating this data are: i) Some of the tweets include irony/sarcasm; therefore,
the true label might be hard to catch when the annotator is focused on the sentiment of the tweet only. ii) Since this
5
6

https://fullfact.org
https://github.com/DocNow/hydrator

3

Data Partition
for Annotation

A1 A5 A3 A4 A2 A4 A4 A1 A6 A2 A3 A5 A2 A3 A1

Annotators

A2 A6 A5 A1 A3 A6 A5 A3 A2 A4 A4 A1 A5 A6 A6

Figure 1: A visualization of the distribution of our data set for stance annotation.
debate is based on a health-related claim, the stances of a large amount of investigated tweets were ambiguous when the
annotator only focused on the tweet text rather than a joint annotation of the tweet text and the shared URLs, if any. The
source of this ambiguity is that many Twitter users shared URLs to the academic studies and news websites. iii) Each
tweet can only contain up to 280 characters, which often poses a difficulty to fully understand the true meaning of the
message, due to Twitter users being constrained to writing a short text. To overcome these challenges, we investigated
the content of the URLs to understand the correct stances, only if the tweet text was not self-explanatory.

4

Annotation Guidelines

We asked our annotators to label each of the tweets in our corpus using one of the three labels: "Against", "Favor",
or "Neutral/None" regarding the unproven claim of "Hydroxychloroquine and chloroquine are cures for the novel
coronavirus.". To gain a deep understanding of the stances in tweets, and due to the high subjectivity related to this
classification method, the ambiguous tweets were being discussed in details among the annotation team. In the following
sub-sections, the three classification labels and their corresponding tweet examples are explained in more details.
I. AGAINST: This stance label was being used for the annotation of tweets that imply an opposition to the claim,
either directly or indirectly.
The stances of some of the tweets in this category are easily comprehensible as the tweet initiator expresses a
direct opposition against the claim. For instance: "I’m a physician. I would not take #Hydroxychloroquine for
#COVID-19.".
Some of the other tweets that were being identified as belonging to this category do not include personal
opinions. Instead, these tweets might contain URLs to the academic studies or news articles in which
hydroxychloroquine is demonstrated to be not effective against COVID-19, or simply contain the heading
of the news article. It is assumed that the tweet initiator aims to share this information since he/she opposes
the claim. An example of such a tweet is: "No evidence of clinical efficacy of hydroxychloroquine in patients
hospitalized for COVID-19 infection with oxygen requirement: results of a study using routinely collected data
to emulate a target trial | medRxiv".
Another example of expressing a counter attitude towards the aforementioned unproven claim, which was
frequently observed in our data set, is via rationalizing against the claim. For instance, we observed that many
Twitter users initiate contents that directly opposes the claim through expressing a reasoning, such as the
side-effects of the drugs, or indirectly, via sharing the headings of news articles that imply the same concept:
"French Hospital Stops Hydroxychloroquine Treatment for COVID-19 Patients Over Major Cardiac Risk",
"Mr. Trump himself has a small personal financial interest in Sanofi, the French drugmaker that makes
Plaquenil, the brand-name version of hydroxychloroquine.".
Some tweets, on the other hand, include sarcasm/irony, which challenge the understanding of the true stance
behind the textual content, even for human annotators. For instance: "This is why you don’t take your medical
advice from a reality TV host. #Hydroxychloroquine #COVID19".
II. FAVOR: This stance label was being used for the annotation of tweets that imply a support opinion towards
the claim, either directly or indirectly.
The stance label for some of the tweets in this category can be easily implied by the annotator, as the tweet initiator expresses a direct support in a straightforward language. For instance: "It is TIME to open up businesses
and schools again! Corona numbers are inflated and you know it! And...there’s a cure!...hydroxychloroquine!"
4

a.

b.

recovered

pandemic

rated

combination

give malaria

tested

research

help azithromycin
state
virus
drug cure democrat
fauci
hydro

results

vaccine

cdc

think

trump days
get treat save
death work
new

medical

people
reported

early

cases

patients covid

study
dr
life
like take
corona

sulfate

try

therapy

c

kills

fda

make trial

ask

end

rep

against
up

prevent

world right

doctors zinc via
why
ny

just
clinical

time

countries

well

need

prescribe

effective
positive

hospital

media

stop

china

president

cases
going start

like

right

many

fight

treatment success
started

killed

clinical

far

masks

day

ban

drug news
first

live

via

china
tablets
thanks

why

#covid

vaccine

ask

modi

touted

virus
infection

people

pm

@realdonaldtrump

retaliation

say

treatment
usa

corona

president

deaths

white

help

update

prescribed

look

evidence

american

small

#trump

suggests

say

french

vaccine

rate

tell

live

died

going

take

against

testing

get

need

makes
americans

problems

cause up lupus

trump news
via

shows

side

hype

trying

malaria

people death
company

potential
financial

donald

know

expert

why

treat
cure

touted

@realdonaldtrump

donald

care

claims

due

benefit just
work

study drug stop
think

higher

even

doses

inject

reports
approved

virus

risk warns time

kill

serious
disease

world

get just

give

trump

medical

export

weeks

treatment hospitals
effects patients heart
unproven
hope

report

million

think

up

data

effective medicine

symptoms

@realdonaldtrump

dr

#corona

trial

help

pandemic
supply

researchers

pushing dr president
trial doctor

fda covidsevere like

evidence

doses

cure

health

know

indian

malaria

know

years

request

national

hcq

time

make

prevent

global governor

die

doctors

disinfectant

against
patients work
covid
need
test
take treat india
study
fight

recommends

azithromycin

question lupus

trying

states

lives many

say go

back
thank

please

countries
house

hospitalized

survey

india

c.

good

azithromycin

shows infection approved
disease

followed

fox

clinical

trump's

miracle

medical
finds

pandemic
prevent

promoted
dangerous

Figure 2: This figure demonstrates the most frequently used keywords in each stance category: (a) favor, (b) neutral, (c)
against.
On the contrary to the above example, we observed that some of the tweet initiators convey their support of
the claim in an indirect manner via questioning the conditions against what it seems to be an obvious solution
to them. For instance: Why did Fauci CHEER when hydroxychloroquine was used in 2013 for MERS, but is
now skeptical for coronavirus?
III. NEUTRAL/NONE: This stance label is the last category in the annotation of our data set, and its label was
being used for the tweets that are neither in favor, nor against the aforementioned claim.
We observed that most of the tweets in this category fall into one of these groups: i) tweets that are in the form
of a question towards the truthiness of the claim, ii) tweets that convey a question with the aim of gaining more
knowledge on the topic, iii) tweets that are written as a statement in a pure neutral tone, iv) tweets that only
contain a neutral heading of a news article or an academic publication, and finally, v) tweets that contain the
query keywords; however, no clear relation between the claim under study and the tweet content were implied.
An example of the tweets which convey a question as in group ii discussed above, is: "What is #Hydroxychloroquine ??? How does it work a against #Covid-19??"
Finally, the tweets that are focused on the events related to the chloroquine/hydroxychloroquine drugs, rather
than a direct relation to the claim under study is: "India sends hydroxychloroquine to UAE for COVID-19
patients."

5

Data Set Description

The annotated COVID-CQ data set includes 14,374 original tweets (tweets/mentions/replies), which were generated by
11,552 unique users on Twitter. We excluded the retweets from our data set annotation. Table 1 illustrates the size of
our data set and the frequency of tweets for each class, in which the "Favor" class with containing 6841 tweets is the
largest class, followed by "Against" class with 4685 tweets, and finally, the smaller class is "Neutral" with 2848 tweets.
Table 1: The frequency of the annotated tweets belonging to each stance class
Stance

Number of Tweets

Neutral
Against
Favor
Total

2848
4685
6841
14374

To briefly provide information on the underlying topics in our corpus, we demonstrated the most frequently used words
for each stance category in Figure 2. These word clouds are achieved after preprocessing the textual content of the data
set, including the elimination of stopwords and the common domain words, such as chlorquine, hydroxychloroquine,
covid19, and coronavirus. A detailed explanation of text preprocessing and cleaning is provided in section 6. Despite
the high similarity of the content in our corpus, and the intertwined topics for all the three clusters (i.e. the topics
related to the available drugs, hospitalized patients, and the treatment methods), it is clearly observable that some of the
keywords have been appeared in a specific stance class in a higher frequency. Since a considerable number of tweets in
the Neutral/None class are related to the import of the hydroxychloroquine drug from India to the US, the word “India”
has appeared as one of the most frequent words in this class. For the Favor stance class, we observed that plenty of
5

tweets in this category are related to the effectiveness of hydroxychloroquine as combination with two other drugs, Zinc
and Azithromycin. Thus, the word cloud for the Favor class contains these keywords. Additionally, positive terms such
as “effective”, “help”, “save”, and “success” are also more observable in the textual content of this category. Finally, the
Against stance class has been observed to include words with a negative sentiment, including “risk”, “stop”, “warn”,
“kill”, and “death”.

Figure 3: The daily tweet counts in April 2020, classified into three categories: ’neutral’, ’against’, and ’favor’. The
black line refers to the ratio of the number of ’favor’ labeled tweets to the number of tweets with the ’against’ stance,
for a 3 day moving average.
Figure 3 represents the daily counts of tweets that are labeled as "Favor" (green), "Neutral" (gray), and "Against" (pink)
in a one month time period. As the month of April is the beginning of the chloroquine/hydroxychloroquine debate, the
fluctuation in the ratio between "Favor" to "Against" tweets are found as very drastic; the black line demonstrates the
3-day moving average of the ratio of # of "Favor" tweets to # of "Against" tweets. Therefore, this data set offers not
only a challenging corpus for the stance detection task, but also presents a drastic dynamic for the researchers who focus
on a better understanding of the information diffusion, polarization, and opinion changes over time, in their studies.
The prepared data set is available to the public via our GitHub repository, accessible on https://github.com/
eceveco/COVID-CQ. We adhere to Twitter’s terms and conditions by not providing the tweet JSON, but sharing the
stance labels with the tweet IDs, so that the tweets can be rehydrated from the Twitter API.
5.1

Major Events and Narratives

Throughout the COVID-19 pandemic, many news articles and research publications are being discussed among social
media users. Although many drugs made their path to mass clinical trials and researches across the world, the fierce
debates surrounding the drugs hydroxychloroquine are more frequently observable among political figures, medical
scientists, and social media users, while hydroxychloroquine is a less toxic metobolite of chloroquine and has been
identified to have less side effects [2]. As the COVID-CQ data set is focused on a month-length Twitter activities
regarding the COVID-19 pandemic, and particularly, on the chloroquine/Hydroxychloroqune conversations, this data
contains textual content in relation to many major events that occurred since the beginning of the pandemic up to the
end of April 2020. As discussed in [21], narrative summaries can be constructed from an ordered chain of individual
events with causality relationships amongst events, appeared within a specific topic. According to this definition, below
we briefly narrate the major events that are being discussed in the Twitter conversations in our data set. However, this
narration does not reflect authors’ personal opinions towards any of the reviewed events.
Amongst the narratives that are discussed in this data set while being occurred before April is the news related to the
results of a study published on March 20 regarding hydroxychloroquine to treat COVID-19 patients, which found
that treating patients with a combination of hydroxychloroquine and azithromycin results in a more efficient virus
6

elimination [22]. This combination of the drugs has been referred to as “game changer” and “beginning of the end of
the pandemic” by many Twitter users. However, plenty of studies later failed to replicate these results [23].
Examples of other events that attracted significant attention from Twitter users are the purchase of hydroxychloroquine
sulfate tablets by the Department of Veterans Affairs and the Bureau of Prisons in March 2020. We observed in our
data that the tweet initiators who propagated news on these events were referring to many news articles regarding this
narrative, including the articles published by New York Post7 and The Daily Beast8 . Further discussions in regards to
the purchase and storage of these drugs in our data set are related to the US government announcement of stockpiling the
drug hydroxychloroquine in late March, the event that according to Bloomberg9 was later followed by many hospitals
in the United States. Although a substantial number of users on social media only shared the URLs to news article
and/or included the headings on these topics, many individuals argued that the mass storage of the unproven drugs by
the US administration and hospitals might result in the deprivation of patients in true needs to access the drugs, such as
the Lupus patients who receive antimalarial drugs to ease their symptoms [24]. A Bloomberg article10 refers to this
issue as the shortage of the drug for Lupus patients, as a consequence of its high demand for COVID-19.
Another important event in March 2020 that affected the opinions on online social media was the Emergency Use
Authorization (EUA)11 for oral formulations of hydroxychloroquine sulfate and chloroquine phosphate by the Food and
Drug Administration (FDA), granted on March 28. We observed that this event attracted significant attention on Twitter
during April, and that it encouraged the appearance of a positive attitude towards the drugs.
On March 25, India that is one the largest manufacturers of the drug hydroxychloroquine, announced that the directorategeneral of foreign trade has prohibited the export of this drug to any other countries amid coronavirus outbreak 12 . This
decision was partially lifted on April 5 in response to a call from president Trump to Indian Prime Minister Narendra
Modi, according to BBC13 . Many Twitter users propagated the news on the lift of export ban for this drug by using
#retaliation.
In early April, the results from various clinical trials related to at least 15 different treatments were announced by many
news agencies. Among the news articles, an international poll from 2,171 physicians started to propagate in Twitter
conversations, in which 37% of doctors rated the drug hydroxychloroquine as the most effective therapy to combat the
virus. This report was also reflected by the New York Post14 on April 2.
On April 7, another rumor emerged, but this time regarding the immunity of patients with rheumatology illnesses
against the novel coronavirus, as a result of taking the drug hydroxychloroquine. The Twitter users started to propagate
this rumor after the rheumatologist, Dr. Daniel Wallance, mentioned in an interview with Dr. Oz on April 7 that out
of 800 patients who are taking the drug, none have been reported to contract the virus 15 . However, the controversial
reports appeared from late April, in some the patients with Lupus were being considered as to be at higher risks of
infection and development of severe symptoms for coronavirus16 .
The support of hydroxychloroquine during the white house press briefings on the coronavirus pandemic influenced the
opinions on Twitter negatively. Consequently, social media users started to relate political and/or financial benefits to
the support of the drug, which was also being discussed in many news articles, including what Washington Post calls
“the real reason behind hydroxychloroquine obsession”17 , published on April 7.
Despite the positive news regarding the efficiency of the drugs until the middle of April 2020, the results published in
a study of hundreds of patients at US Veterans Health Administration medical centers suggested that patients taking
hydroxychloroquine are no less likely to get infected by the virus, instead, the death rates in these peatiest have been
observed to be higher [25]. These results appeared in many news articles, including a CNN article18 published on April
21.

7

nypost.com/2020/04/07/federal-agencies-purchase-large-supply-of-hydroxychloroquine/
thedailybeast.com/the-bureau-of-prisons-just-bought-a-ton-of-hydroxychloroquine-trumps-covid-19-miracle-drug?ref=scroll
9
bloomberg.com/news/articles/2020-03-20/hospitals-stockpile-malaria-drug-trump-says-could-treat-covid-19
10
usatoday.com/story/news/health/2020/04/18/hydroxychloroquine-coronavirus-creates-shortage-lupus-drug/5129896002/
11
fda.gov/media/136534/download
12
statnews.com/pharmalot/2020/03/25/india-trump-hydroxychloroquine-coronavirus-covid19/
13
bbc.com/news/world-asia-india-52196730
14
nypost.com/2020/04/02/hydroxychloroquine-most-effective-coronavirus-treatment-poll/
15
youtube.com/watch?v=kd7Jec3pZBk
16
medicalnewstoday.com/articles/lupus-and-covid-19
17
washingtonpost.com/opinions/2020/04/07/real-reason-trump-is-obsessed-with-hydroxychloroquine/
18
cnn.com/2020/04/21/health/hydroxychloroquine-veterans-study/index.html
8

7

With respect to the the negative side effects of hydroxychloroquine that were reported in many research articles, the
FDA issued a warning about the use of this drug for COVID-19 patients on April 24, according to Time19 . The severe
negative effects reported for the use of this drug include abnormal heart rhythms that might threaten patients’ lives.
The FDA warning related to the use of antimalarial drugs to treat COVID-19 patients and the publication of academic
researches which reported the inefficacy of these drugs against the novel coronavirus caused the United States to be left
with massive supplies of hydroxychloroquine, the concern that was being reflected in many news websites at the end of
April, including the article published in USA Today20 in April 27. Finally, in June 2020 the FDA withdrawn the granted
emergency use authorization (EUA) for the drug hydroxychloroquine21 . However, the EUA withdrawal event does not
appear in our data set.

6

Annotation Assessment

After the preparation of the data set according to the annotation guidelines, we conducted extensive analysis on the
data to ensure the quality of the annotation, including the consistency of the stance labels in our corpus. In this
regard, we investigated the semantic similarity of the tweets via computing the pairwise cosine similarity on the vector
representation of the tweets. The Universal Sentence Encoder22 from the TensorFlow library was used to achieve the
semantic vector representations of the tweets. The sentence level embeddings provide high level sentence semantic
relationship, which enables the comparison of the similarity of tweet contents against each other to assure labeling
consistency. After the calculation of pairwise cosine similarity for the tweets in our corpus, we reevaluated the labels of
the tweets with ≥ 0.9 cosine similarity, where this threshold was being identified by human judgement via comparing
the tweet similarity results. The reevaluation procedure of the identified highly similar tweet contents include manual
investigation of these tweets by the annotators, such that the highly similar tweets that convey the same stance towards
the claim are categorized into the same stance class.
6.1

Stance Classification

To demonstrate the potential of evaluating many stance classification models using this data, and to evaluate the
quality of our data set, we conducted extensive analysis using six different classification methods. The implemented
models for this purpose include Multilayer Perceptron (MLP), Logistic Regression (LR), Support Vector Machine
(SVM), Multinomial Naive Bayes (MNB), Stochastic Gradient Descent (SGD), Gradient Boosting (GB), and finally,
Convolutional Neural Network (CNN). Furthermore, all the classification methods are compared for the computed
vector representations of word unigrams and bigrams using the term frequency-inverse document frequency (tf-idf).
The implemented Multilayer Perceptron contained 2 dense layers, the rectified linear unit (ReLU) as the activation
function, and the cross-entropy loss as the loss function. For the Logistic Regression classifier, the Limited-memory
Broyden Fletcher Goldfarb Shanno (lbfgs) was used as the solver. The Support Vector Machine model was implemented
with the linear kernel. For the Stochastic Gradient Descent model, the perceptron loss was used. In the implementation
of the Gradient Boosting model, the deviance loss was used for model optimization. Finally, the Convolutional Neural
Network (CNN) was implemented in two different ways to receive the inputs as vectors computed by one-hot encoding
and GloVe word embedding, both with 5 convolutional layers with kernel size of 3 and stride size of 2, and with
Exponential Linear Unit (ELU) activation function. The training stop criteria was to reach to a maximum number of
1000 iterations in training for all the classifiers.
6.2

Data Preprocessing

To prepare the input to the classifiers, we first filtered the tweets that were identified by Twitter to be in a different
language than in English. After excluding the non-English tweets, we removed any punctuation marks and non-Ascii
characters, and replaced the integers with their textual representation. Further preprocessing of the data include mapping
all the input text to lowercase format, followed by word stemming, lemmatization, and the removal of the stopwords.
Additionally, the URLs, hashtag signs (#xxx), and emoticons were removed to achieve a higher textual quality. It
should be noted that none of these classification methods have been trained or tested on the content of the shared URLs
as part of the input data. After this step, the term frequency-inverse document frequency (tf-idf) was used to generate
the vector representation of the input tweets. Using tf-idf, we generated a vector space with weighting scheme based on
19

time.com/5827085/fda-warning-hydroxychloroquine/
usatoday.com/story/news/politics/2020/04/27/coronavirus-states-stockpile-hydroxychloroquine-drug-trumptouted/3031660001/
21
fda.gov/media/136534/download
22
tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder
20

8

Table 2: The comparison of the results for 6 classifiers using tf-idf vectorization
Stochastic Gradient Descent (SGD)
Support Vector Machine (SVM)
Multilayer Perceptron (MLP)
Logistic Regression (LR)
Multinomial Naive Bayes (MNB)
Gradient Boosting Classifier (GB)

Unigram
0.7429
0.7651
0.7453
0.7683
0.7182
0.6764

Bigram
0.7439
0.7651
0.7457
0.7683
0.7182
0.6768

the frequency of unigrams and bigrams in a tweet relative to the total number of their frequencies in the entire data set.
Thus, tf-idf captures the most distinct words while ignoring the semantic or syntactic attributes. After this step, the
vectorized tweets were used as the input to all the classifiers. For the training and testing of all the models, we used
80% of the tweets in training, and the remaining of the tweets to evaluate the models.
6.3

Results

The comparison of the results for 6 classification models using our stance data set is provided in table 2. Among
the investigated classification methods, the Logistic Regression model achieved the best accuracy of 0.76 for both
accuracies when the feature vectors for the tweets were computed using unigrams and bigrams for tf-idf. The next best
performance was achieved by the SVM with very close performance to LR. The gradient boosting model achieved
the lowest performance for both unigram and bigram tf-idf vectorized inputs. Surprisingly, using the bigrams to
generate the tf-idf feature vectors did not affect the accuracy, observed for all models. However, despite the use of
general purpose classification methods than state-of-the-art stance detection models, and although the contents from the
URLs were not used for the evaluation of these classifiers, all of the models were able to classify the tweets with an
acceptable performance. For further analysis, we implemented a Convolutional Neural Network (CNN) classifier for
stance classification with one-hot encoding and GloVe vectorization of the words in tweets. This classifier achieved the
accuracy of 0.73 for both vectorization methods. Additionally, the stance classification using the MLP model was also
repeated for the one-hot encoded tweets. The achieved classification accuracy for this classifier was 0.75, which is
slightly improved comparing with the MLP model using the tf-idf feature vectors.

7

Discussion

In this work, we introduced a large data set of Twitter stances towards the unproven claim of “chloroquine and
hydroxychloroquine are cure for the new coronavirus”. Our data set, COVID-CQ, contains stance labels for more
than 14 thousand original tweets, after discarding the retweets. COVID-CQ defers from the existing corpus as the true
underlying stances in Twitter conversations have been identified via a joint annotation of tweets’ text and the shared
URLs when the tweets were not self-explanatory. Accordingly, our data set challenges the prediction models for the
tasks of stance detection, to incorporate further information besides the text of the tweets. We have made the annotated
corpus available to the public through our GitHub repository, in which the Tweet ids and the stance labels are provided
to the research community and the given information can be used for Tweet rehydration via the Twitter API. To the
best of our knowledge, COVID-CQ is the first data set regarding the stances towards the COVID-19 pandemic, besides
being the largest human annotated stance data set for social media on stances towards a claim.

Acknowledgments
The authors gratefully thank Mina Sonbol and Nicholas Wiesenthal who assisted in the annotation and analysis of the
data set.

References
[1] Amirarsalan Rajabi, Alexander V Mantzaris, Ece C Mutlu, and Ivan Garibay. Investigating dynamics of covid-19
spread and containment with agent-based modeling. medRxiv, 2020.
[2] Thomas J Stokkermans and Georgios Trichonas. Chloroquine and hydroxychloroquine toxicity. 2019.
9

[3] Jia Liu, Ruiyuan Cao, Mingyue Xu, Xi Wang, Huanyu Zhang, Hengrui Hu, Yufeng Li, Zhihong Hu, Wu Zhong,
and Manli Wang. Hydroxychloroquine, a less toxic derivative of chloroquine, is effective in inhibiting sars-cov-2
infection in vitro. Cell discovery, 6(1):1–4, 2020.
[4] Nicola Principi and Susanna Esposito. Chloroquine or hydroxychloroquine for prophylaxis of covid-19. The
Lancet Infectious Diseases, 2020.
[5] Muskaan Sachdeva, Asfandyar Mufti, Khalad Maliyar, Yuliya Lytvyn, and Jensen Yeung. Hydroxychloroquine
effects on psoriasis: a systematic review and a cautionary note for covid-19 treatment. Journal of the American
Academy of Dermatology, 2020.
[6] Matthieu Mahevas, Viet-Thi Tran, Mathilde Roumier, Amelie Chabrol, Romain Paule, Constance Guillaud,
Sebastien Gallien, Raphael Lepeule, Tali-Anne Szwebel, Xavier Lescure, et al. No evidence of clinical efficacy of
hydroxychloroquine in patients hospitalized for covid-19 infection with oxygen requirement: results of a study
using routinely collected data to emulate a target trial. MedRxiv, 2020.
[7] Yaakov HaCohen-Kerner, Ziv Ido, and Ronen Ya’akobov. Stance classification of tweets using skip char ngrams.
In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 266–278.
Springer, 2017.
[8] Parinaz Sobhani. Stance detection and analysis in social media. PhD thesis, Université d’Ottawa/University of
Ottawa, 2017.
[9] Ahmet Aker, Leon Derczynski, and Kalina Bontcheva. Simple open stance classification for rumour analysis.
arXiv preprint arXiv:1708.05286, 2017.
[10] Ramy Baly, Mitra Mohtarami, James Glass, Lluís Màrquez, Alessandro Moschitti, and Preslav Nakov. Integrating
stance detection and fact checking in a unified corpus. arXiv preprint arXiv:1804.08012, 2018.
[11] Isabelle Augenstein, Tim Rocktäschel, Andreas Vlachos, and Kalina Bontcheva. Stance detection with bidirectional
conditional encoding. arXiv preprint arXiv:1606.05464, 2016.
[12] Qiang Zhang, Emine Yilmaz, and Shangsong Liang. Ranking-based method for news stance detection. In
Companion Proceedings of the The Web Conference 2018, pages 41–42, 2018.
[13] Roy Bar-Haim, Indrajit Bhattacharya, Francesco Dinuzzo, Amrita Saha, and Noam Slonim. Stance classification
of context-dependent claims. In Proceedings of the 15th Conference of the European Chapter of the Association
for Computational Linguistics: Volume 1, Long Papers, pages 251–261, 2017.
[14] William Ferreira and Andreas Vlachos. Emergent: a novel data-set for stance classification. In Proceedings of the
2016 conference of the North American chapter of the association for computational linguistics: Human language
technologies, pages 1163–1168, 2016.
[15] Saif Mohammad, Svetlana Kiritchenko, Parinaz Sobhani, Xiaodan Zhu, and Colin Cherry. Semeval-2016 task
6: Detecting stance in tweets. In Proceedings of the 10th International Workshop on Semantic Evaluation
(SemEval-2016), pages 31–41, 2016.
[16] Ramon Villa-Cox, Sumeet Kumar, Matthew Babcock, and Kathleen M Carley. Stance in replies and quotes (srq):
A new dataset for learning stance in twitter conversations. arXiv preprint arXiv:2006.00691, 2020.
[17] Dimitar Dimitrov, Erdal Baran, Pavlos Fafalios, Ran Yu, Xiaofei Zhu, Matthäus Zloch, and Stefan Dietze.
Tweetscov19–a knowledge base of semantically annotated tweets about the covid-19 pandemic. arXiv preprint
arXiv:2006.14492, 2020.
[18] Joshua Eisenberg and Mark Finlayson. Annotation guideline no. 1: Cover sheet for narrative boundaries annotation
guide. Journal of Cultural Analytics, page 11199, 2019.
[19] Sejeong Kwon, Meeyoung Cha, and Kyomin Jung. Rumor detection over varying time windows. PloS one,
12(1):e0168344, 2017.
[20] Emily Chen, Kristina Lerman, and Emilio Ferrara. Tracking social media discourse about the covid-19 pandemic:
Development of a public coronavirus twitter data set. JMIR Public Health and Surveillance, 6(2):e19273, 2020.
[21] Toktam A. Oghaz, Ece Çiğdem Mutlu, Jasser Jasser, Niloofar Yousefi, and Ivan Garibay. Probabilistic model of
narratives over topical trends in social media: A discrete time model. In Proceedings of the 31st ACM Conference
on Hypertext and Social Media, HT ’20, page 281–290, New York, NY, USA, 2020. Association for Computing
Machinery.
[22] Philippe Gautret, Jean-Christophe Lagier, Philippe Parola, Line Meddeb, Morgane Mailhe, Barbara Doudier,
Johan Courjon, Valérie Giordanengo, Vera Esteves Vieira, Hervé Tissot Dupont, et al. Hydroxychloroquine and
azithromycin as a treatment of covid-19: results of an open-label non-randomized clinical trial. International
journal of antimicrobial agents, page 105949, 2020.
10

[23] Joshua Geleris, Yifei Sun, Jonathan Platt, Jason Zucker, Matthew Baldwin, George Hripcsak, Angelena Labella,
Daniel K Manson, Christine Kubin, R Graham Barr, et al. Observational study of hydroxychloroquine in
hospitalized patients with covid-19. New England Journal of Medicine, 2020.
[24] C Ponticelli and G Moroni. Hydroxychloroquine in systemic lupus erythematosus (sle). Expert opinion on drug
safety, 16(3):411–419, 2017.
[25] Joseph Magagnoli, Siddharth Narendran, Felipe Pereira, Tammy H Cummings, James W Hardin, S Scott Sutton,
and Jayakrishna Ambati. Outcomes of hydroxychloroquine usage in united states veterans hospitalized with
covid-19. Med, 2020.

11

