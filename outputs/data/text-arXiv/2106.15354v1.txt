June 30, 2021

arXiv:2106.15354v1 [cs.SI] 26 Jun 2021

Text Mining and Sentiment Analysis of
COVID-19 Tweets
Qihuang Zhang1 , Grace Y. Yi123 , Li-Pang Chen1 and Wenqing He1

Abstract
The human severe acute respiratory syndrome coronavirus 2 (SARS-Cov-2), causing the
COVID-19 disease, has continued to spread all over the world. It menacingly affects not
only public health and global economics but also mental health and mood. While the impact of the COVID-19 pandemic has been widely studied, relatively fewer discussions about
the sentimental reaction of the population have been available. In this article, we scrape
COVID-19 related tweets on the microblogging platform, Twitter, and examine the tweets
from Feb 24, 2020 to Oct 14, 2020 in four Canadian cities (Toronto, Montreal, Vancouver,
and Calgary) and four U.S. cities (New York, Los Angeles, Chicago, and Seattle). Applying
the Vader and NRC approaches, we evaluate the sentiment intensity scores and visualize
the information over different periods of the pandemic. Sentiment scores for the tweets
concerning three anti-epidemic measures, masks, vaccine, and lockdown, are computed for
comparisons. The results of four Canadian cities are compared with four cities in the United
States. We study the causal relationships between the infected cases, the tweet activities,
and the sentiment scores of COVID-19 related tweets, by integrating the echo state network
method with convergent cross-mapping. Our analysis shows that public sentiments regarding
COVID-19 vary in different time periods and locations. In general, people have a positive
mood about COVID-19 and masks, but negative in the topics of vaccine and lockdown. The
causal inference shows that the sentiment influences people’s activities on Twitter, which is
also correlated to the daily number of infections.
1
Department of Statistical and Actuarial Sciences, University of Western Ontario, London, Ontario,
Canada
2
Department of Computer Science, University of Western Ontario, London, Ontario, Canada
3
Corresponding author. Email: gyi5@uwo.ca

Keywords: COVID-19, Causal Inference, Echo State Network, Emotion, Sentiment Analysis, Text Mining.
Short title: Sentiment Analysis of COVID-19 Tweets SentiTwi

ii

1

Introduction

The COVID-19 disease, caused by the human severe acute respiratory syndrome coronavirus 2 (SARS-Cov-2), was declared to be a pandemic by the World Health Organization
(WHO) in March of 2020. This disease has caused over sixty-five million infections and
a half million deaths all over the world as of December 3, 2020. While extensive studies
have been conducted to examine various types of influence of COVID-19 on public health,
including the studies concerning the infected cases number and the fatality, investigations of
the impact of the pandemic on people’s emotion are relatively limited.
The first case of COVID-19 in Canada was reported in Toronto on January 25, 2020. To
prevent the spread of COVID-19, four most populated provinces in Canada have consecutively announced the “state of emergency” (displayed in Figure 1), taking the measures of
shutting down the public business, banning social gathering, encouraging social distancing,
and requiring the masks wearing in the public area, etc. As the situation of disease spreading
ameliorated during July and August, the “state of emergency” was relaxed to various extent
in different provinces. With the recent roaring number of newly infected cases, the “state of
emergence” has been restored again in all the four provinces.
While social distancing has been advocated and many people are taking the practice of
working at home, online communication tools such as social media have become active in
communication. The COVID-19 pandemic has become one of the most discussed topics on
the internet since it was first reported in January 2020 (Bhat et al. 2020). As the opinions and
feelings are freely and openly shared on the internet, it is interesting to conduct text mining
of the public information on the social media to extract useful messages. Text mining is a
commonly used technique to explore corpus, and common strategies of analyzing sentiments
can be found in Kwartler (2017, Ch.4). For an application of text mining to Twitter data,
Kumar et al. (2014) provided a comprehensive discussion together with detailed case studies.
Aflakparast et al. (2020) used the Bayesian fused graphical lasso to convert textual Twitter
data to understandable networks of terms that can signify important events.
For COVID-19 data, Tworowski et al. (2020) studied drug repository and applied text
mining methods to putative COVID-19 therapeutics. Khanday et al. (2020) employed text
1

Washington
Period 3

Period 2

Period 1

Illinois
Period 2

Period 1

Period 3

California
Period 1

Period 3

Period 2

New York
Period 2

Period 1

Period 3

Alberta
Period 1

Period 3

Period 2

Québec
Period 3

Period 2

Period 1

British Columbia
Period 2

Period 1

Period 3

Ontario
Period 1

Period 2

Feb 24

Mar 2

Feb 27
First case in
Quebec

Mar 01
First case in
New York
Feb 29

Washington
declared “State
of Emergency”

9

16

Mar 05
First case in
Alberta

30

Apr 6

13

May 4

27

11

18

25

Jun 1

8

Mar 17

Mar 12

Mar 07

New York Quebec declared
declared “State “State of
of Emergency” Emergency”
Mar 04

23

Period 3

Mar 09

California
Illinois declared
declared “State
“State of
of Emergency”
Emergency”

Ontario and Alberta
declared “State of
Emergency”

May 19

May 5

Illinois
reopening

Mar 18

British Columbia
declared “State of
Emergency”

May 1

Washington
reopening

May 11
Ontario and
Quebec reopen British Columbia
essential business
first stage
and elementary
reopening
schools

May 7

May 12

California
reopening

Alberta
reopening

Jun 8

New York first
stage reopening

Figure 1: The timeline of the measures, indicated by the three periods, which are taken by
the four provincial governments in Canada: Alberta, Quebec, British Columbia and Ontario
and four state governments in U.S.: Washington, Illinois, California, and New York.
mining methods to do preprocessing and extract relevant features, and then classified textual
clinical reports by using machine learning algorithms. Saire and Pineda-Briseno (2020) considered a case study to analyze the publications in Mexico and examined people’s behavior.
Most available work on COVID-19 data, however, presented on “exploratory data analysis”
such as standard word clouds and histograms of most posted words. In this article, we
conduct sentiment analysis (e.g., Pak and Paroubek 2010; Agarwal et al. 2011; Kouloumpis
et al. 2011) to understand the impact of COVID-19 on the emotion of the public.
While there has been some discussion about the public emotional reaction to the
COVID-19 pandemic using the text mining techniques based on the available platforms,
the existing research is subject to several limitations: (1) most studies conducted sentiment
analysis based on a single word and ignoring the interaction among words (e.g., Xue et al.
2020). For example, completely opposite meaning from the original word is expressed if this
word is combined with the word “not” or “no”; (2) most current studies (e.g., Lwin et al.
2020; Pastor 2020) only present the results without discussing its connection to the anti-

2

epidemic measures; (3) emotions of individuals change over time and differ from place to
place due to different levels of anti-epidemic measures but such features are not necessarily
incorporated in the most available studies; (4) only few studies (e.g., Zhou et al. 2020) consider the possible typos, slangs, word variation, abbreviation, and emoji, which commonly
appear in the casual environment of Twitter.
In this article, we mainly focus on two aspects of public sentiments regarding the
COVID-19 pandemic. The first questions is: “how do people react to the spread of COVID19 over time”? Specifically, we are interested in comparing the change of emotion in different
time periods based on tweets, and we also study the association between people’s reactions to
the COVID-19 and the number of daily reported infected cases. Second, multiple measures
have been implemented by the government to mitigate the virus spread, but it is still unclear
how serious people take those measures. We are also interested in people’s reactions by using
the keyword “lockdown”, “masks”, and “vaccine” in the analysis. To alleviate possible confounding effects associated underlying factors including culture, government practice, and
internet access regulations etc., here we restrict our analysis to the four cities of Canada,
Toronto, Montreal, Vancouver, and Alberta, which are mostly hit by COVID-19. We analyze
sentiments expressed in four cities of Canada on one of the most widely used social media
platform, Twitter – a microblog website, for the period of February 24, 2020, to October 14,
2020.
The remainder of the article is organized as follows. In Section 2, we discuss the study
design and the sentiment analysis method, which includes the procedure of text mining using
the Twitter data. In Section 3, we present the results of sentiment analysis using Twitter
text data of Canada. We compare the results over different periods. Further, we extend the
comparisons by contrasting the results for the four cities in the United States. In Section 4,
statistical models are built to analyze how the public emotion is associated with the daily
reported infected cases. Finally, we conclude the article in Section 5.

3

2

Methods

2.1

Study Design

Our Twitter data mining pipeline consists of a data preparation stage and a data analysis
stage, shown in Figure 2. The data preparation procedure includes data collection and
raw data cleaning. COVID-19 related tweets, published between February 24, 2020 and
October 14, 2020, are collected from four Canadian cities: Toronto, Montreal, Vancouver,
and Calgary, the representative cities of the four most populated provinces, Ontario, Quebec,
British Columbia, and Alberta, respectively. Four cities in the U.S.: New York, Los Angeles,
Seattle, and Chicago, are considered for comparison. We use the snscrape module on
Python 3.8 (https://github.com/JustAnotherArchivist/snscrape) to scrape the tweet
text online in the search of using the keyword “COVID-19”. All the appearing tweets that
are published within 50km of the center of each considered city are included in our analysis,
leading to 30,655 tweets in total for the four cities in Canada and 69,742 tweets in total
for the four cities in the United States. The data cleaning procedure is to be described in
detail in the following section; and the clean data are then analyzed using pandas package
of Python 3.8.

Data Quality
Control
Data Collection

Association
Studies

02
Sentiment
Analysis

01

Stage 1
Data Preperation

04

03

Stage 2
Data Analysis

Figure 2: A flowchart of Twitter data mining pipeline
The data analysis stage includes the construction of descriptive statistics characterizing
the topic popularity and public sentiment. We specifically compare the sentiment scores

4

within different regions dynamically with temporal effects incorporated. Furthermore, we
build a statistical model to study the association among the sentiment scores, Twitter activities, and the number of reported infected cases.

2.2

Data Cleaning

Applying the common standards (e.g., Stone et al. 2011; Xue et al. 2020), we first clean raw
data using the pandas module of Python 3.8, following Xue et al. (2020):
(1) The URLs, hashtag symbol “#” and symbol “@” are removed from the tweets in the
data set;
(2) The tweets written in a non-English language are removed;
(3) Meaningless characters, punctuation, and stop-words are removed from the dataset as
they do not contribute semantic meanings. Some examples are shown in Table 1.
Table 1: An example list of meaningless characters, punctuation, and stop-words

2.3

Character

Punctuation

Stop-words

**

,

I

SSS

()

me

=

;

myself

$

-

during

&

∼

before

Sentiment Analysis

Tweets are primarily connected with moods and sentiments. To reflect this feature, we carry
out sentiment analysis, which is a process of identifying an attitude of the author on a topic
that is being written about.
The evaluation of the sentimental effect is conducted by matching the words to the
existing lexicons (Jagdale et al. 2018) and look up for their sentiment score in the lexicon.
5

We firstly break each tweet into individual words, determine the sentiment score of each
word in the tweet, and then obtain the sentiment score for each tweet by adding those scores
for each word. Different lexicons have been proposed in the field of text mining. Some of the
lexicons are purely polarity-based (e.g., Liu and Zhang 2012), i.e. the sentiment is classified
as negative, neutral, or positive. Some lexicons, e.g., AFINE proposed by Nielsen (2011)
and the Valence Aware Dictionary and sEntiment Reasoner (Vader) proposed by Gilbert
and Hutto (2014), take the intensity of the sentiment into account, where the sentiment
intensity score is a scale ranged between a negative and a positive values. NRC Sentiment
and Emotion Lexicons (Mohammad and Turney 2013) consider each word to be one or a
combination of multiple moods, including anticipation, positive, negative, sadness, disgust,
joy, anger, surprise, fear, and trust. Table 2 shows examples of the lexicons of different
types.
Table 2: Examples of different lexicons: Vader, Bing and NRC
Vader
word

Bing
score

NRC

word

sentiment

word

sentiment

:-)

1.3

abominable

negative

abacus

trust

lmao

2.0

abominably

negative

abandon

fear

lol

2.9

abominate

negative

abandon

negative

abducted

-2.3

abomination

negative

abandon

sadness

abduction

-2.8

abort

negative

abandoned

anger

admonition

negative

accident

negative

agrees

1.5

alarm

-1.4

adorable

positive

accident

sadness

alarmed

-1.4

adore

positive

accident

surprise

alarmist

-1.1

adored

positive

accidental

fear

amaze

2.5

adorer

positive

accidental

negative

amort

-2.1

adoring

positive

accidental

surprise

In this article, we use Vader and NRC to characterize the sentiment and emotion of the
tweets, respectively. The Vader lexicon quantifies the sentiment into numeric scores which
6

can be used for further analysis, and the NRC lexicon provides detailed categories to describe
the mood in a refined fashion. The Vader lexicon is also specifically attuned to sentiments
expressed in social media. It contains the utf-8 encoded emojis and emoticons, which are
important features frequently used in the tweet texts (Gilbert and Hutto 2014). To conduct
sentiment analysis, polarity scores are identified for every single word in each tweet according
to the Vader lexicon, and the frequency of each mood in emotion categories appearing in
the text are identified according to the NRC lexicon. For the sentiment score obtained by
Vader, we calculate the average sentiment score of each tweet by first summing the scores
of each words in the tweet and then dividing by the total number of words in the tweet.
Following Gilbert and Hutto (2014), after calculating the sentiment scores, we further adjust
the calculated tweet-wise sentiment scores to incorporate the information related to negation
words (“not” and “n’t”), punctuation to intensify sentiments (e.g., “Good!!!”), conventional
use of word-shape to signal emphasis (e.g., using CAPITAL words), the word modifying the
intensity (e.g., “very”, “pretty”, etc.), and the conventional slangs and emoji (e.g, “lol”,“:)”).
For the case with “??”, we treat it as an intensified punctuation just like “!!”, but for the
case with “?”, we do not made any adjustment because of the uncertainty of being a real
question or a rhetorical question. After computing the positive, neutral and negative scores
for each tweet, we further calculate the compound score according to the rules in Gilbert
and Hutto (2014), and then normalize it to be between -1 (most extreme negative) and +1
(most extreme positive). These steps are implemented via the polarity scores() function
in the Vader module (https://github.com/cjhutto/vaderSentiment).
For the mood categories annotated by the NRC lexicon, the accumulating number of
counts of each emotion category for each tweet is also calculated. We further compute the
frequency, defined as the ratio of the counts of each emotion to the total word count in a
tweet using the NRClex() function in the python NRCLex module (https://github.com/
metalcorebear/NRCLex). For each word, the emotion is represented by a ten-dimensional
vector to reflect 10 different moods specified in Section 2.3, where each element is expressed
as the frequency of a mood, ranging from 0 (extremely lack of this emotion) to 1 (extremely
full of this emotion). As an example, sentiment analysis of the tweets on February 24, 2020
in Toronto, Canada is presented in Tables 3 and 4.
7

Table 3: Examples of COVID-19 related tweets collected in Toronto, on February 24, 2020
No.
1

Tweet
The trajectory of the coronavirus is unknown at this time and it’s possible that cases have
occurred in other countries that don’t have the proper tools to diagnose and contain it.

2

GIS real-time data map of coronovirus COVID19 from john hopkins

3

Fantastic thread by our Dr. Hota describing how the system works to protect Canadians

4

...and flights are still letting people in?

5

passenger on montreal to vancouver aircanada flight tested positive for coronavirus COVID-19

Table 4: Sentiment scores of the example tweets in Table 3
Vader Lexicon

NRC Lexicon

No. Negative Neutral Positive Compound

3

1

0

1

2

0

1

3

0

0.721

4

0

1

5

0

0.769

0

Anticipation Positive Negative Sadness Disgust Joy Anger Surprise Fear Trust

0

9

8

8

8

8

7

8

8

8

7

0

0

2

2

3

1

3

1

2

1

2

2

0.279

0.7351

3

4

5

4

2

3

3

2

3

4

0

0

3

4

4

4

4

4

4

3

4

3

0.231

0.5574

2

2

2

2

2

2

2

2

2

3

Descriptive Statistics

Before conducting text mining of tweets, we summarize demographic information of the
tweets data scraped online. The number of tweets reflects the popularity of a topic on
Twitter, and “like”, “replies” and “retweets” are three main activities for users to engage with
the tweet, whose counts are an indication of the impact of a tweet in generating discussions.
In Figures 4 and 5, we present the city-level trajectory of the number of tweets and of the
total number of likes, replies, and retweets for the COVID-19 associated tweets, together
with that of the daily number of reported infected cases for the province or states in which
the city is located.
Figures 4 and 5 show that the numbers of like, of reply and of retweet have a similar
trend, which are fairly similar to the number of tweets in the overall pattern. Those trajectories exhibit a reasonable commonality within a country, and the peaks for all the cities
in Canada and the U.S. appear nearly at the same time - around the middle of March,
2020. Interestingly, those peaks come prior to the peaks of the number of reported infected
cases, which may reflect that in the early stage of the virus spread in North America, the
COVID-19 outbreak in other countries in Asia and Europe has already stimulated a large
number of active discussions.

8

Figure 6 presents a heatmap of the daily average sentiment score for the eight cities
over time, where the darkness of the color shows the magnitude of the sentiments, with
orange color and green color representing positive and negative sentiments, respectively.
The heatmap is constructed using the geom tile() function in the R package ggplot2. The
sentiment change varies from city to city, not just from country to country. For the period
between the end of February and early March, except for Los Angeles, all the sentiments
in all other cities show overall negative patterns. Between the middle of March and early
June, all the cities show positive sentiments though the degree varies. After June, sentiment
reaction fluctuate noticeably from city to city, with all cities having varying negative patterns
in September, which is likely related to the second wave of a surging trend of COVID-19
cases. Overall, Toronto and New York remain consistently positive between the middle of
March and the beginning of September, whereas the other cities exhibit varying negative
sentiments intermittently.
To trace the change of sentiment scores in different cities over time, we summarize the
mean and standard deviation of tweetwise sentiment scores, stratified by city and the time
periods as in Figure 1. Table 5 reports on the results for the cities in Canada and U.S.A.
All the four Canadian cities and four U.S. cities have the largest sentiment scores for Period 2 (i.e., during the lockdown), which may indicate confidence and positive feelings about
COVID-19 during the lockdown period. In contrast, smaller mean scores in Period 1 than
in Period 2 may be related to the concern and the uncertainty about the disease in the early
stage of the pandemic. The sentiment scores in U.S. is more negative than those in Canada
in all the periods. While the mean scores differ in cities, the associated standard deviations
remain similar for different cities and different periods.
To closely understand how anti-epidemic measures may be related to the daily average
sentiment scores (obtained from Vader approach) of the tweets, we produce the heatmaps
for three keywords: “mask”, “vaccine”, and “lockdown”, and display them in Figures 7–9,
respectively. Opinions on “mask” are generally positive in Toronto but changes from time
to time in other three Canadian cities. Except for Seattle, opinions on “mask” appear to be
positive or neutral in other three U.S. cities. On the other hand, people generally tend to
have negative opinions on “vaccine” in most cities. For “lockdown”, opinions are generally
9

positive from March to May when most cities are in the lockdown status or emergency states
(Figure 1), whereas most Canadian cities (Vancouver, Montreal, and Calgary) and two US
cities (Seattle and Chicago) have negative sentiments after reopening. Among the three antiepidemic measures, “vaccine” has the most long-lasting negative views, showing the lack of
confidence in the development of the vaccine.
To closely visualize the change of the mood composition of the daily tweets over time, in
Figure 10, we present the density plots obtained from the NRC method. Overall, the changes
in Canadian cities seem to be more variable than U.S. cities, and the trend and trajectory
vary from city to city and from time to time. For example, from May to September, the
moods are slightly intensified in Vancouver, Montreal, and Calgary, whereas an opposite
trend is observed for Toronto and New York. Relative to other months, February is the
month that incur a large variation of the word frequency in each mood for most cities, which
may be attributed to the uncertainty and the lack of knowledge of COVID-19 in the early
stage of the pandemic.

4

Causal Inference

4.1

Examination Framework

With the descriptive analysis reported in Section 3, we are further interested in examining
the Vader sentiment scores in terms of the potential causal relationships. Specifically, here we
explore possible causal relationships of the daily number of reported infected cases with tweet
activities (e.g., tweet total counts, tweet like counts, tweet reply counts, and retweet counts)
and with sentiment scores of COVID-19 related tweets. We implement convergent cross
mapping (Ye et al. 2015), integrated with the echo state network approach (Lukoševičius
and Jaeger 2009), to explore the causal relationships.
Let X and Y denote the two variables whose causal relationship is of interest. It is our
goal to identify whether there is evidence to suggest a causal relationship between X and
Y by examining {Xt : t = 1, . . . , T } and {Yt : t = 1, . . . , T }, the time series of observations
for X and Y , respectively, where Xt and Yt are observed values of X and Y at time t,

10

respectively. For example, Xt represents the daily average sentiment score on day t and Yt
can be the number of tweets on day t.
The idea of the convergent cross mapping is that if Y is the cause of X, then the time
series {Yt : t = 1, . . . , T } of the causal variable Y can be recovered from the time series
{Xt : t = 1, . . . , T } of the effect variable X (Tsonis et al. 2018). To facilitate this rationale
and possible the lag effects, let τ denote the lag time, and we take Xt as the input data
and repeatedly fit the leaky echo state network model (Jaeger et al. 2007) to predict Yt+τ by
varying the value of τ , denoted Ŷt+τ . The detail is given in Section 4.2.
Now we describe the evaluation of the performance of the prediction of Yt+τ using the Xt .
For any given τ ≤ T , we compute the Pearson’s correlation coefficient between the predicted
time series Ybt+τ and their corresponding observations Yt+τ (Ye et al. 2015), denoted ρy (τ )
and given by
PT −h(τ )
ρy (τ ) =

where Ȳt+τ =

1
T −|τ |

PT −h(τ )
PT −h(τ )
Yt+τ Ybt+τ − t=1+|τ |−h(τ ) Yt+τ t=1+|τ |−h(τ ) Ybt+τ
qP
,
PT −h(τ )
¯
T −h(τ )
2
2
b
b
t=1+|τ |−h(τ ) (Yt+τ − Yt+τ )
t=1+|τ |−h(τ ) (Yt+τ − Ȳt+τ )
t=1+|τ |−h(τ )

PT −h(τ )

t=1+|τ |−h(τ )

PT −h(τ )
¯
1
b
Yt+τ , Ybt+τ = T −|τ
t=1+|τ |−h(τ ) Yt+τ , and
|


τ, if τ ≥ 0,
h(τ ) =

0, if τ < 0.

Likewise, taking Yt as the input data and Xt+τ as output labels, we fit another echo state
bt+τ . Then, for any given τ , we
network model in predicting the values of Xt+τ , denoted as X
bt+τ and Xt+τ , denoted as ρx (τ ).
compute the Pearson’s correlation coefficient between X
Following the lines of Ye et al. (2015) and Huang et al. (2020), we determine the causality
between X and Y according to the time lag τ so that ρx and ρy reach their peak values.
Specifically,
• If X causes Y and not vice versa, we expect the peak value of the ρx (τ ) to be located
in the positive domain, i.e., the corresponding τ is positive. Meanwhile, we expect the
peak value of the ρy (τ ) to be at a negative τ .
• If X and Y cause each other, both the peak values of the ρx (τ ) and the ρy (τ ) are
expected occur in the negative domain.
11

• If the coupling of X and Y has a delay effect, the lag positions of the peaks of the
ρx (τ ) and the ρy (τ ) are expected to be influenced by the delay time.
To study how ρx (τ ) and ρy (τ ) may change at different time lag τ , we consider the range
[−30, 30] for τ in the analysis in Section 4.3.

4.2

Echo State Network

As discussed in Section 4.1, the identification of the causality relationship between X and Y
is carried out by examining the Pearson correlation coefficient between the observed data, say
Yt+τ , and their predicted counterparts, say Ybt+τ , which are obtained by fitting a prediction
model connecting X and Y . While various modeling schemes may be considered for building
a prediction model, here we employ the echo state network approach for its good performance
in the prediction of non-linear time series data (Lukoševičius and Jaeger 2009).
The echo state network is basically composed of three layers: the input layer, the reservoir
layer, and the output layer (Figure 3). The input layer contains the input data and the output
layer is made up of the output labels. The reservoir layer consists of the hidden reservoir
neuron states, denoted ut , which form an N × 1 vector with N being a user-specified positive
integer. An N × N adjacent matrix, say A, is constructed to describe the connections among
the reservoir neurons.
The determination of the links among the three types of layers is carried out with two
procedures: the input-to-reservoir procedure and the reservoir-to-output procedure, which
are described as follows using the data:
• From the input layer to the reservoir layer:
For any t = 1, . . . , T , we construct the relationships between the impute data Xt and
(0)

the layers of hidden reservoir neuron states. Let ut denote the initial reservoir neuron
states, then we update the neuron states ut by
(0)

u∗t = tanh{Aut + Win Xt };
ut = (1 − ψ)ut−1 + ψu∗t ,

12

where ψ is the leaky parameter to be specified, and Win is an N × 1 matrix representing the weight to transform Xt from input layer to reservoir layer.
tanh(v) =

Here,

exp(v)−exp(−v)
.
exp(v)+exp(−v)

• From reservoir layer to output layer:
We compute the predicted output labels,
Ybt+τ = Wout ut ,
where Wout is an n×N matrix representing the weight matrix transform ut into output
layer.
In these steps, only the weights Wout need to be trained by minimizing the penalized loss
function
Ybt+τ − Yt+τ

2

+ α kWout k2 ,

where k·k2 represents the L2 -norm and α is the tuning parameter to be specified.
DESIGN

𝑢𝑡−1
𝑢𝑡

𝑌𝑡

𝑋𝑡

Input Layer

Reservoir Layer

Output Layer

Figure 3: The diagram of a leaky echo state network
The adjacent matrix A and the weight matrix Win are prespecified, which may be specified
using the following procedure. Let ps be a user-specified value between 0 and 1, let γ
be a user-determined positive scaling parameter determining the degree of nonlinearity in
13

the reservoir dynamics (Goudarzi et al. 2015); and let β be a pre-specified positive scaling
parameter. Generate a sequence of values, say v, independently from Uniform [−1, 1] and
a sequence of values, say s, independently from Bernoulli(ps ), and then we form the weight
matrix Win by letting its elements be given by γsv. The adjacent matrix A is formed similarly
with its element given by βsv. To ensure the echo state network to work properly, the effects
of initial conditions should vanish as the times series evolves (Jarvis et al. 2010), which is also
known as the echo state property. A necessary condition to ensure the echo state property is
that the largest eigenvalue of A, denoted λmax , is smaller than 1 (Jaeger et al. 2007). Here,
λmax , also called the “spectral radius” of A, determines the time range that the time series
data interact each other non-linearly. Such a property guides us to set a suitable value for
scale parameter β.
Treating variable Xt as the training data and Yt+τ as the output labels, we implement the
echo state network using the EchoTorch module (Schaetti 2018) in Python 3.8. To determine
suitable values of the tuning parameters λmax , ψ, N , ps , α, and γ, we take the leave-oneout cross-validation procedure. Specifically, we take the time series of seven cities as the
training data and the remaining one city as the testing data. The procedure is repeated by
leaving each city out as testing data once, where in each study, we record the normalized
root-mean-squared-error (NRMSE) (Lukoševičius and Jaeger 2009):
qP
T
2
b
t=1 (Yt − Yt ) /T
.
NRMSE =
PT
t=1 Yt /T
We conduct a grid search to find the optimal set of tuning parameters such that the NRMSE
are minimized.
Similarly, to study another direction of the causal relationship, the procedure described
above is repeated by switching X and Y .

4.3

Analysis Results

In this study, we examine possible causal relationships among the six features pairwisely:
COVID-19 daily infected cases; Vader sentiment scores; the daily number of tweets, and the
daily total number of likes, of retweets and of replies. Assuming that the causal relationships
14

among those features are the same for each city, we merge the data in all cities and consider
two directions of the relationship as explained in Section 4.1.
For illustrations of the implementation of the procedures described in Sections 4.1–4.2,
in Direction 1, let {Xt : t = 1, . . . , T } denote the time series of the daily average sentiment
scores in a city and let {Yt : t = 1, . . . , T } denote the time series of the daily tweet counts
of that city; and in Direction 2, we swap the Xt and Yt . According to the leave-one-out
cross-validation, we choose the tuning parameter λmax , ψ, N , ps , α, and γ, respectively, to
be 0.1, 0.5, 150, 0.1, 0.1, 0.9 in Direction 1, and 0.1, 0.9, 250, 0.7, 100 and 0.9 in Direction
2. Then using those identified optimal parameter values, we train the echo state network for
bt for both directions, respectively. The
Wout to the time series Xt and Yt to predict Ybt and X
predictions are repeated for all the cities considered in the study. Finally, for each τ ≤ T ,
we compute the Pearson’s correlation coefficient between Ybt+τ and Yt+τ , where Ybt+τ is the
predicted value corresponding to Yt+τ . In another direction, we compute the correlation
bt+τ and Xt+τ . We present the analysis results in Figure 11, which
coefficient between X
shows that in Direction 1, the Pearson’s correlation coefficient ρx reaches the peak at τ = 8,
whereas in Direction 2, the Pearson’s correlation coefficient ρy is peaked at τ = −5. This
suggests that the sentiment of COVID-19 is likely to cause the changes in the time series
of the tweet counts, but not vice versa. On the other hand, the small value of the peak of
the correlations (i.e., ρx = 0.006 and ρy = 0.169), indicate a weak relationship between the
infected case number and the tweet counts.
We repeat the analysis for each pair of features of our interest and identify the optimal
lag that achieves the highest correlation in each scenario, shown in Figure 13, which reveals
three findings: (i) the infected cases and COVID-19 sentiment scores have an instantaneous
bidirectional relationship as τ = 0 for both direction; (ii) the sentiment scores unidirectionaly cause the changes of the tweet-related features, including tweet, like, reply and retweet
counts; (iii) the tweet activity features, including tweet, like, reply, and retweet, are instantaneously related to each other. The messages in (ii) and (iii) are not surprising, but the
message (i) appears somewhat counter-intuitive. It is expected that the change of the number
of infected cases can influence people’s sentiment regarding COVID-19, but not necessarily
vice versa. However, closely examining the magnitude from the direction of sentiment scores
15

to infected cases, it is not as strong as the other way around. People’s sentiments about
COVID-19 may influence their personal activities which may, in turn, contribute more risk
of infection. The results of the causal relationships are summarized in Figure 12.

5

Discussion

The ongoing COVID-19 pandemic has presented tremendous challenges to the public and
it has significantly affected our daily life. It is important to study public sentiments in
reacting to anti-epidemic measures and evaluate the impact of the pandemic on the public
mental health. In this paper, we conduct sentiment analysis of the tweets in eight North
American cities on the topics of the COVID-19 spread, masks, lockdown, and vaccine. We
apply the echo state network and convergent cross-mapping to characterize possible causal
relationships among the relevant features.
Our visualization of sentiment scores provides intuitive information about people’s reaction to the virus spread as well as the implemented anti-epidemic measures. The descriptive
statistics reveal that the public sentiments vary in different periods of the pandemic. For
example, the sentiments become positive in Period 2 (during lockdown) after being negative in Period 1 (before lockdown) due to the uncertainty and lack of knowledge about the
disease. The sentiments also vary in different cities, not just in different countries. While
people are generally thinking positively about the mask usage, the sentimental reactions to
the vaccine and lockdown are much negative. Our analysis of the causal relationships shows
that the infected cases and COVID-19 sentiment scores are instantaneously correlated. The
sentiment influences the activities of Twitter users, such as publish, like, reply, or retweet a
tweet, which are also correlated with each other.
On the other hand, the analysis has the limitation that the full meaning of the sentences
is not deciphered, and thereby, care needs to be paid to interpret the negative sentiment
results. For instance, when interpreting negative sentiments of the “mask” related tweets,
one needs to consider two possible reasons; the negative opinions may arise from the usage
of masks as an anti-epidemic measure or the thoughts on other people who do not follow the
rules of mask-wearing. Although the two situations are reflecting completely opposite views
16

of the measures, their sentiment direction is the same and this difference cannot be directly
distinguished in the sentiment analysis. A more refined analysis is warranted in future work.

Funding
This research was supported by the Natural Sciences and Engineering Research Council of
Canada (NSERC). Yi is Canada Research Chair in Data Science (Tier 1). Her research was
undertaken, in part, thanks to funding from the Canada Research Chairs Program.

Acknowledgements
The authors would like to thank reviewers for their useful comments.

Contributions
The first two authors lead the project with equal contributions including writing the paper;
the last two authors participate in the project with equal contributions.

Competing Interests
The authors declare that they have no competing interests.

Availability of Data and Material
All codes and data involved in this paper are available on request from the authors.

17

References
Aflakparast, M., de Gunst, M., and van Wieringen, W. (2020). Analysis of twitter data with
the bayesian fused graphical lasso. PloS one, 15(7):e0235596.
Agarwal, A., Xie, B., Vovsha, I., Rambow, O., and Passonneau, R. J. (2011). Sentiment
analysis of twitter data. In Proceedings of the workshop on language in social media (LSM
2011).
Bhat, M., Qadri, M., Noor-ul Asrar Beg, M. K., Ahanger, N., and Agarwal, B. (2020).
Sentiment analysis of social media response on the COVID-19 outbreak. Brain, Behavior,
and Immunity, 87:136–137.
Gilbert, C. and Hutto, E. (2014). Vader: A parsimonious rule-based model for sentiment
analysis of social media text. In Eighth International Conference on Weblogs and Social
Media (ICWSM-14), volume 81.
Goudarzi, A., Shabani, A., and Stefanovic, D. (2015). Exploring transfer function nonlinearity in echo state networks. In 2015 IEEE Symposium on Computational Intelligence
for Security and Defense Applications (CISDA). IEEE.
Huang, Y., Fu, Z., and Franzke, C. L. (2020). Detecting causality from time series in a
machine learning framework. Chaos: An Interdisciplinary Journal of Nonlinear Science,
30(6):063116.
Jaeger, H., Lukoševičius, M., Popovici, D., and Siewert, U. (2007). Optimization and applications of echo state networks with leaky- integrator neurons. Neural Networks, 20(3):335
– 352.
Jagdale, R. S., Shirsat, V. S., and Deshmukh, S. N. (2018). Review on sentiment lexicons. In
2018 3rd International Conference on Communication and Electronics Systems (ICCES).
Jarvis, S., Rotter, S., and Egert, U. (2010). Extending stability through hierarchical clusters
in echo state networks. Frontiers in neuroinformatics, 4:11.

18

Khanday, A. M. U. D., Rabani, S. T., Khan, Q. R., Rouf, N., and Din, M. M. U. (2020).
Machine learning based approaches for detecting covid-19 using clinical text data. International Journal of Information Technology, 12(3):731–739.
Kouloumpis, E., Wilson, T., and Moore, J. (2011). Twitter sentiment analysis: The good
the bad and the omg! In Fifth International AAAI Conference on Weblogs and Social
Media. Citeseer.
Kumar, S., Morstatter, F., and Liu, H. (2014). Twitter data analytics. Springer.
Kwartler, T. (2017). Text mining in practice with R. John Wiley & Sons.
Liu, B. and Zhang, L. (2012). A survey of opinion mining and sentiment analysis. In Mining
Text Data. Springer.
Lukoševičius, M. and Jaeger, H. (2009). Reservoir computing approaches to recurrent neural
network training. Computer Science Review, 3(3):127–149.
Lwin, M. O., Lu, J., Sheldenkar, A., Schulz, P. J., Shin, W., Gupta, R., and Yang, Y.
(2020). Global sentiments surrounding the covid-19 pandemic on twitter: analysis of
twitter trends. JMIR public health and surveillance, 6(2):e19447.
Mohammad, S. M. and Turney, P. D. (2013). NRC emotion lexicon. National Research
Council, Canada.
Nielsen, F. Å. (2011). Afinn sentiment analysis in Python. http://www2.compute.dtu.dk/
pubdb/pubs/6010-full.html.
Pak, A. and Paroubek, P. (2010). Twitter as a corpus for sentiment analysis and opinion
mining. In LREc, volume 10.
Pastor, C. K. (2020). Sentiment analysis of filipinos and effects of extreme community
quarantine due to coronavirus (COVID-19) pandemic. Pandamic.
Saire, J. E. C. and Pineda-Briseno, A. (2020). Text mining approach to analyze coronavirus
impact: Mexico city as case of study. medRxiv.
19

Schaetti, N. (2018). Echotorch: Reservoir computing with pytorch. https://github.com/
nschaetti/EchoTorch.
Stone, B., Dennis, S., and Kwantes, P. J. (2011). Comparing methods for single paragraph
similarity analysis. Topics in Cognitive Science, 3(1):92–122.
Tsonis, A. A., Deyle, E. R., Ye, H., and Sugihara, G. (2018). Convergent Cross Mapping:
Theory and an Example. Springer International Publishing, Cham.
Tworowski, D., Gorohovski, A., Mukherjee, S., Carmi, G., Levy, E., Detroja, R., Mukherjee,
S. B., and Frenkel-Morgenstern, M. (2020). COVID-19 drug repository: text-mining the
literature in search of putative COVID-19 therapeutics. Nucleic acids research.
Xue, J., Chen, J., Chen, C., Zheng, C., Li, S., and Zhu, T. (2020). Public discourse and
sentiment during the COVID-19 pandemic: Using latent dirichlet allocation for topic
modeling on twitter. PLoS One, 15(9):e0239441.
Ye, H., Deyle, E. R., Gilarranz, L. J., and Sugihara, G. (2015). Distinguishing time-delayed
causal interactions using convergent cross mapping. Scientific Reports, 5:14750.
Zhou, J., Yang, S., Xiao, C., and Chen, F. (2020). Examination of community sentiment dynamics due to COVID-19 pandemic: a case study from australia. arXiv preprint
arXiv:2006.12185.

A

Appendix

20

Toronto

Vancouver

Montreal

Calgary
Infected Cases

1000
100
10
1

Tweets

100
10
1

Measure
Infected Cases

1000
Like

Count

10000

100
10

Tweets
Like
Reply

1

Retweet

1000
Reply

100
10
1
1000

Retweet

100
10
1
Apr

Jul

Oct

Apr

Jul

Oct

Apr

Jul

Oct

Apr

Jul

Oct

Date

Figure 4: The trajectory of provincial daily infected cases, daily number of tweets, total
counts of likes, reply and retweets of the COVID-19 related tweets for cities in Canada. To
properly present the trend, the y-axis is presented with logarithm transformation.

21

New York

Los Angeles

Seattle

Chicago
Infected Cases

10000
1000
100
10
1
1000

Tweets

100
10
1

Measure

1e+05
Like

Count

Infected Cases

1e+03
1e+01

Tweets
Like
Reply
Retweet

1000
Reply

100
10
1
10000

Retweet

1000
100
10
1
Apr

Jul

Oct

Apr

Jul

Oct

Apr

Jul

Oct

Apr

Jul

Oct

Date

Figure 5: The trajectory of provincial daily infected cases, daily number of tweets, total
counts of likes, reply and retweets of the COVID-19 related tweets for cities in United States.
To properly present the trend, the y-axis is presented with logarithm transformation.

22

23

Chicago

Seattle

Los Angeles

New York

Calgary

Montreal

Vancouver

Mar

Apr

May

Jun

Date

Jul

Aug

Sep

Oct

US

sentiment.

eight cities in the North America. The orange color denotes the positive sentiment and the green color represents the negative

−0.5

0.0

0.5

Sentiment
Score

Figure 6: The heatmap of the sentiment score of ”COVID19” related tweets calculated using Vader lexicon over time for the

city

Toronto

Canada

24

Chicago

Seattle

Los Angeles

New York

Calgary

Montreal

Vancouver

Mar

Apr

May

Jun

Date

Jul

Aug

Sep

Oct

US

sentiment.

cities in the North America. The orange color denotes the positive sentiment and the green color represents the negative

−0.5

0.0

0.5

Sentiment
Score

Figure 7: The heatmap of the sentiment score of “mask” related tweets calculated using Vader lexicon over time for the eight

city

Toronto

Canada

25

Chicago

Seattle

Los Angeles

New York

Calgary

Montreal

Vancouver

Mar

Apr

May

Jun

Date

Jul

Aug

Sep

Oct

US

sentiment.

eight cities in the North America. The orange color denotes the positive sentiment and the green color represents the negative

−0.5

0.0

0.5

Sentiment
Score

Figure 8: The heatmap of the sentiment score of “vaccine” related tweets calculated using Vader lexicon over time for the

city

Toronto

Canada

26

Chicago

Seattle

Los Angeles

New York

Calgary

Montreal

Vancouver

Mar

Apr

May

Jun

Date

Jul

Aug

Sep

Oct

US

sentiment.

eight cities in the North America. The orange color denotes the positive sentiment and the green color represents the negative

−0.5

0.0

0.5

Sentiment
Score

Figure 9: The heatmap of the sentiment score of “lockdown” related tweets calculated using Vader lexicon over time for the

city

Toronto

Canada

Table 5: The tweetwise sentiment scores for different cities in different time periods
Period

Period 1

Period 2

Period 3

Measure

Canada

United States

Calgary Montreal Toronto Vancouver

New York Los Angeles Seattle Chicago

Number of tweets

581

124

2203

878

614.00

129.00

50.00

196.00

Mean

0.12

0.04

0.09

0.13

0.02

0.05

-0.02

-0.01

s.d.

0.46

0.45

0.46

0.49

0.50

0.49

0.55

0.47

Number of tweets

1703

1601

9983

3237

25626.00

10924.00 3655.00 5359.00

Mean

0.15

0.12

0.20

0.20

0.12

0.10

0.13

0.12

s.d.

0.48

0.48

0.49

0.50

0.50

0.49

0.50

0.50

Number of tweets

907

1048

7011

1556

9634.00

Mean

0.09

0.11

0.15

0.11

0.06

0.05

0.05

0.08

s.d.

0.50

0.46

0.47

0.53

0.51

0.51

0.52

0.50

27

7710.00 2188.00 3657.00

28

0.0

0.4

0.0

0.2

0.4

0.0

0.2

0.4

0.0

0.2

0.4

Score

0.0

0.2

0.4

0.0

0.2

sadness

0.4

0.0

0.2

disgust

0.4

0.0

0.2

anger

Figure 10: The density graph of the distribution of the moods frequency for different cities over 234 days.

0.2

fear

0.4

Seattle

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

surprise

Los Angeles

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

anticipation

New York

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

trust

Calgary

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

joy

Montreal

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct

Vancouver

City

Toronto
Chicago

Positive

Negative

Mood
Direction

X:Sentiment Y:Tweets

X:Tweets Y:Sentiment

0.1
Optimal lag: −5

ρ

0.0

−0.1

−0.2
Optimal lag: 8

−0.3
−20

0

20

τ

−20

0

20

Figure 11: A plot of Pearson’s correlation coefficient over different choice of lag in the
inference of causal relationship between the infected cases and the tweet counts. The dash
vertical line refers to the choice of lag that achieve the peak of the correlation.

29

DESIGN

Tweet
Replies

Tweet
Retweets

Tweet Activities
Related Features
Public Health
Related Features
Infected
Cases

Tweet
Likes

Sentiment Related
Features
Bidirectional
Relationship

Tweet
Counts

Sentiment

Score

Unidirectional
Causal

Figure 12: A chart of causal relationships between the tweet activities, infected cases and
sentiment scores.

30

X:Infected Cases Y:Like

X:Like Y:Infected Cases

X:Infected Cases Y:Reply

X:Reply Y:Infected Cases

−0.10
0.000
−0.15

−0.025

ρ

ρ

Optimal lag: 0

−0.20

Optimal lag: −5

−0.050
−0.075

−0.25
Optimal lag: 0

Optimal lag: 1

−0.100

−0.30
−0.125
−20

0

20

τ

X:Infected Cases Y:Retweet

−20

0

20

−20

X:Retweet Y:Infected Cases

0

20

τ

X:Infected Cases Y:Tweets

−20

0

20

X:Tweets Y:Infected Cases

−0.05
−0.1
Optimal lag: −4
Optimal lag: −1

ρ

ρ

−0.10

−0.2

−0.3

−0.15

Optimal lag: 1
Optimal lag: 0

−0.4
−20

0

20

τ

X:Infected Cases Y:Sentiment

−20

0

20

−20

X:Sentiment Y:Infected Cases

0

20

τ

−20

X:Like Y:Reply

0

20

X:Reply Y:Like

0.5

0.1
0.4

ρ

ρ

Optimal lag: 0

0.0

0.3

Optimal lag: 0
Optimal lag: 0

0.2

Optimal lag: 0

−0.1

−20

0

20

τ

−20

X:Like Y:Retweet

0

0.1

20

−20

X:Retweet Y:Like

0

20

τ

−20

X:Like Y:Tweets

0

20

X:Tweets Y:Like

0.5
0.8

0.4

0.6

ρ

ρ

Optimal lag: 1

0.3

0.4

Optimal lag: 0
Optimal lag: 0

0.2

0.2

Optimal lag: 26

0.0

0.1
−20

0

20

τ

−20

X:Like Y:Sentiment

0

20

−20

X:Sentiment Y:Like

0

20

τ

−20

X:Reply Y:Retweet

0

20

X:Retweet Y:Reply

0.5

0.4

0.1

ρ

ρ

Optimal lag: −5

0.3

0.0

Optimal lag: 0
Optimal lag: 0

Optimal lag: 29

0.2

−0.1
−20

0

20

τ

−20

X:Like Y:Tweets

0

20

−20

X:Tweets Y:Like

0

20

τ

−20

X:Reply Y:Sentiment

0

20

X:Sentiment Y:Reply

0.8
0.1
0.6
Optimal lag: 1

ρ

ρ

Optimal lag: −5

0.4

0.0

0.2
−0.1

Optimal lag: 4

Optimal lag: 26

0.0
−20

0

20

τ

−20

X:Retweet Y:Tweets

0

20

−20

X:Tweets Y:Retweet

0

20

τ

−20

X:Retweet Y:Sentiment

0.6

0

20

X:Sentiment Y:Retweet

0.1

ρ

ρ

Optimal lag: 1

0.4

Optimal lag: −5

0.0
Optimal lag: 29

Optimal lag: 25

0.2
−0.1
−20

0

20

τ

−20

0

20

−20

0

20

τ

−20

0

20

Figure 13: Plots of Pearson’s correlation coefficient over different choice of lag in the inference
of causal relationships. The dash vertical line refers to the choice of lag that achieve the
peak of the correlation.

31

