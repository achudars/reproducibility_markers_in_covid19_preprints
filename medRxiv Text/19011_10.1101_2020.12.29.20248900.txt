medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Noname manuscript No.
(will be inserted by the editor)

Efficiency of Artificial Intelligence in Detecting
COVID-19 Pneumonia and Other Pneumonia Causes
by Quantum Fourier Transform Method
Erdi Acar · Bilge Öztoprak · Mustafa
Reşorlu · Murat Daş · İhsan Yılmaz ·
İbrahim Öztoprak

Received: date / Accepted: date

Abstract The new coronavirus (COVID-19) appeared in Wuhan in December
2019 and has been announced as a pandemic by the World Health Organization (WHO). Currently, this deadly pandemic has caused more than 1 million
deaths worldwide. Therefore, it is essential to detect positive cases as early as
possible to prevent the further spread of this outbreak. Currently, the most widely
used COVID-19 detection technique is a real-time reverse transcription-polymerase
chain reaction (RT-PCR). However, RT-PCR is time-consuming to confirm infection in the patient. Because RT-PCR is less sensitive, it provides high falsenegative results. Computed tomography (CT) is recommended as a solution to
this problem by healthcare professionals because of its higher sensitivity for early
and rapid diagnosis. In addition, radiation used in CT poses a serious threat to
patients. In this study, we propose a CNN-based method to distinguish COVID19 pneumonia from other types of viral and bacterial pneumonia using low-dose
CT images to reduce the radiation dose used in CT. In our study, we used a data
set consisting of 7717 CT images of 350 patients that we collected from Çanakkale
Onsekiz Mart University Research Hospital. We used a CNN-based network that
suppresses noise to remove interference from low-dose CT images. In the image
preprocessing phase, we provided lung segmentation from CT images and applied
quantum Fourier transform. By evaluating all possible variations of local knowledge at the same time with quantum Fourier transformation, the most informative
spatial information was extracted. In CNN-based architecture, we used pre-trained
ResNet50v2 as a feature extractor and fine-tune by training with our dataset. We
visualized the efficiency of the ResNet50v2 network using the t-SNE method. We
performed the classification process with a fully connected layer. We created a heat
map using the GradCam technique to see where the model focuses on the images
Erdi Acar
Dept. of Computer Engineering, Institute of Science, Çanakkale Onsekiz Mart University,
Çanakkale, Turkey
E-mail: erdiacar@stu.comu.edu.tr
Bilge Öztoprak
Dept. of Radiology, Faculty of Medicine, Çanakkale Onsekiz Mart University, Çanakkale,
Turkey
E-mail: bilgeoztoprak@gmail.com

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

2

Erdi Acar et al.

while classifying. In this experimental study, the results of 99.5%, 99.2%, 99.0%,
99.7%, and 99.1%, were obtained in the context of performance criteria such as
accuracy, precision, sensitivity, specificity, and f1 score, respectively. This study
revealed the artificial intelligence-based computer-aided diagnosis (CAD)system
as an effective and fast method to accurately diagnose COVID-19 pneumonia.
Keywords COVID-19 · Pneumonia · Deep Learning · CT Denoising · Quantum
Fourier Transform

1 Introduction
COVID-19 is a contagious disease caused by the mutant SARS-CoV-2 virus with
high mortality[1]. After the description of the first case in Wuhan, China in December 2019, it rapidly spread all over the world and announced to be a pandemic
by WHO on 11 March 2020. It causes a disease with a wide range of symptoms:
Mainly fever, cough, headache, weakness, sore throat, loss of taste and smell, diarrhea, chest pain, shortness of breath, feeling pressure on the chest, conjunctivitis,
skin eruptions, and discoloring in distal parts of extremities. Most of the patients
who tested positive for COVID-19 are either asymptomatic or have a mild disease
characterized by fever and dry cough. Elderly with chronic underlying diseases are
more prone to develop a serious disease. Mortality is mostly due to multiorgan
failure caused by the cytokine storm. Computed tomography (CT) is widely used
for the detection of lung lesions in highly suspected patients. It is also used in the
course of the disease to detect the extent of lung involvement and complications.
COVID-19 pneumonia is characterized by patchy areas of ground-glass opacity
(GGO) in both lungs predilecting peripheral areas of posterior and lower segments. In most advanced cases interlobular septal thickening accompanies GGOs
leading to the typical “crazy paving” pattern. Other findings include consolidation,
dilatation of vessels in the affected areas of lungs, subpleural bands, bronchiectasis,
hyperlucent areas in GGOs- the so-called vacuolar sign, air bronchograms, pleural and pericardial effusion, and enlarged lymph nodes[2]. As one would expect,
none of these findings is specific for COVID-19 pneumonia and there is considerable overlap between COVID-19 pneumonia and other infectious and noninfectious
lung diseases. Typical peripheral multifocal ground-glass appearance allow sitting
to be differentiated from bacterial pneumonia. However, it is difficult to distinguish
from other types of viral pneumonia and atypical pneumonia because of findings
that coincide [3, 4].
There have always been attempts to differentiate between diseases in radiology
since the vast majority of lesions on radiological images are nonspecific and it is
sometimes impossible to differentiate between different diseases manifesting as
similar radiological abnormalities.
Currently, the reverse transcription real-time fluorescent polymerase chain reaction (RT-PCR) test based on nucleic acid amplification test (NAAT) of respiratory tractor blood samples is used to diagnose a patient with symptoms of
COVID-19[5]. Nevertheless, its sensitivity and detection rate are low due to the
low viral load early. So, it is likely to give inaccurate results. In addition, it may
take time to yield the test result. The progression and severity of the infection
cannot be estimated since it gives only positive or negative results [6].

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

3

Chest radiography may be normal in early/mild disease. Thorax CT is more
sensitive than a chest x-ray for early COVID-19 diagnosis[7]. If a patient with suspected COVID-19 has negative test results but findings are present on CT imaging,
the patient should be quarantined, and the RT-PCR test is repeated. This rapid
isolation is crucial to proper patient care and disease control. Because it provides
fast and accurate results, CT plays an important role in the early diagnosis of
COVID-19 pneumonia. However, to obtain high-quality images, a high radiation
dose must be administered to patients. This entails a potential risk of genetic
damage and cancer related to the radiation, thus, finding a solution to minimize
radiation is crucial. One approach to reducing the risk of radiation is to use lower
levels of x-ray current, but quantum noise caused by an insufficient number of photons increases the noise and artifacts in low dose computed tomography (LDCT)
images. This could potentially impair diagnostic performance. Asa solution to this
problem, many methods have been designed for denoising LDCT images. These
methods generally fall into three categories: techniques based on sinogram filtering,
iterative reconstruction, and post-reconstruction image processing[8–10]. In addition, denoising algorithms using artificial deep neural networks have demonstrated
impressive performance capabilities in this context[8–17].
Recently, with the advancement of artificial intelligence technology and especially the development of convolutional neural networks, computer vision has led
to extraordinary developments. It is widely used in the medical field and provides
support for medical diagnosis. Additionally, due to the heavy workload on a large
number of infected patients and healthcare professionals, the artificial intelligencebased computer-aided system can speed up the diagnostic process. These systems
can provide an efficient diagnosis of the disease in a shorter time, such as the
lack and inability of radiologists during the pandemic crisis. It can also reduce the
need for human surveillance and identify details invisible to the human eye. Artificial intelligence (AI) technologies are rapidly developing in the area of medicine,
specifically in radiology, to overcome this challenge[18]. In this context, many deep
learning models have also been developed for the diagnosis of COVID-19[19–33].
The aim of this study is to test the effectiveness of AI distinguishing COVID19 pneumonia from other types of pneumonia by using low-dose CT images to
reduce the radiation used in CT. The paper is organized as follows. In section 2,
material and method are given. In section 3, obtained results are given. In section
4, discussion and concluding remarks are given with comparing the other studies
in the literature.

2 Material and Method
In this study, we used a data set consisting of 7717 CT images of 350 patients
obtained from C¸anakkale Onsekiz Mart University Research Hospital. We used
an LDCT noise removal deep model that removes noise from LDCT images. By
modifying the Bi-Directional ConvLSTM U-Net[34] architecture, we provided lung
segmentation with a deep neural network. We applied quantum Fourier transform[35] at the image pre-processing stage. We used ResNet50v2[36] architecture
as a feature extractor. We visualized the efficiency of the feature extractor using
t-Distributed Stochastic Neighbor Embedding (t-SNE)[37] on the resulting feature
vector. We used in-place / on-the-fly data augmentation[38] during training to in-

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

4

Erdi Acar et al.

(a)

(b)

(c)

(d)

Fig. 1 Sample images of classes within the dataset. a is an example of Bacterial Pneumonia.b
is an example of COVID-19. c is an example of Viral Pneumonia. d is an example of Normal.

crease the quality and robustness of the model instead of increasing the number
of data in the data set. We used the Gradcam[39] technique to visualize where the
model focuses on the images while classifying the images. We use a full connected
layer for classification. We evaluated performance results with accuracy, precision,
sensitivity, specificity, and f1-score.

2.1 Dataset
The dataset was collected from Çanakkale Onsekiz Mart University Research Hospital with ethical permissions. The dataset includes 1157 Bacterial pneumonia,
4387 COVID-19, 695 Viral pneumonia, and 2635 normal diagnosed 7717 lung CT
images in total. The images belong to 350 patients taken on different days during
the past one year and the images belonging to the COVID-19 class belong to patients with positive RT-PCR tests. Each of the images has a standard of 512x512
pixel size. An example of the dataset is given in Fig. 1. In addition, the distribution of images in the dataset is visualized in Fig. 2 using t-SNE which is a size
reduction technique that is well suited for visualizing high dimensional datasets.

2.2 Low Dose CT Simulation
The performance of deep learning models has always been debatable due to the
insufficiency of educational samples in medical datasets. A deep learning model
learns the distribution of all the training data it sees during the training process. If
there is not enough data to train the network, an over-fitting problem will occur.
Low-dose and normal-dose CT data are needed to train the low-dose CT noise
suppression network. However, it is not always possible to find such a dataset.
Therefore, we created the low dose CT dataset using the normal dose CT images
we had. The noise that occurs in CT images due to insufficient number of photons
in CT images taken by reducing radiation is ’quantum noise’. It is also known to
has Poisson noise and a Poisson distribution[40]. We applied the procedure of Zeng
et al.[41] to obtain LDCT image. We obtained sinogram data by applying Radon
transformation to NDCT images and added Poisson noise to that sinogram data
[42]. Then, we obtained LDCT images by applying inverse radon transform to the
Poisson noise-added sinogram data. LDCT sample images are given in Fig. 3.

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

5

Fig. 2 Distribution of the dataset visualized using t-SNE.

(a)

(b)

(c)

(d)

Fig. 3 LDCT sample images of classes within the dataset. a is an example of low dose bacterial
pneumonia.b is an example of low dose COVID-19. c is an example of low dose viral pneumonia.
d is an example of low dose normal.

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

6

Erdi Acar et al.

Table 1 Quantitative evaluation results for LDCT denoising network.
Train Size

Test Size

SSIM

PSNR

6174

1543

0.9726

36.95

2.3 Low Dose CT Denoising Architecture
We applied a deep residual neural network (ResNet) for image-to-image transformation in an attempt to predict full-dose CT from low-dose CT images. We modified the model proposed by Yang et al.[44] to remove noise. This network consists
of two parts: (1) Denoising network. (2) Perceptual loss calculator. Fig. 4 presents
the architecture of denoising employed in the current study. To learn denoising
images containing different structures and densities, a sufficiently deep network
to handle complexity is required. Some studies have indicated that networks with
more layers do not always perform well, and that training loss is increasing. As a
solution to this problem, He et al.[36] proposed a residual learning model. In our
work, we applied residual learning between the lower and upper layers. As shown
in Figure 4, the input image and output of layers 1, 2 and 3 are combined with
the output of layers 7, 6 and 5, respectively. These links pass the details of the
image to lower layers because the properties on the first layers contain more input
information.
In our study, the denoising network consists of 8 convolutional layers. We used
32 filters with 3x3 kernel size in the first 7 layers. We applied 3 convolutional
filters with 3x3 kernel size in the layer that is the output of the network only. We
applied batch normalization(BN) in 6 layers to speed up the training process. We
used Leak Rectified Linear Unit (LReLU) as the non-linear activation function
for the 8 convolutional layers. Also, we use dilation rate in each layer to increase
receptive field. The receptive field (RF) which is the region of the input image
used to calculate the output value. A larger receptive field means more contextual
information is captured than the input image.
Perceptual loss is calculated in the second part of the proposed network using
the VGG16 CNN architecture[43]. We started the VGG16 network with imagenet
weights, then retrained and fine-tuned the dataset. The output of the noise denoising network is fed as input to the VGG16 network and normal dose CT images
are provided as labels. Loss is calculated by using the features from the network
and back propagation is performed.
We used 80% of the dataset for training and 20% of the dataset for testing
the noise removal network. We used the Adam stochastic gradient algorithm to
optimize the model. The learning rate was started at 1e-3 and dynamically adjusted. Structural similarity index (SSIM) and peak signal-to-noise ratio (PSNR)
measurements were used in the quantitative evaluation of the predicted NDCT
images. Evaluation results are given in Table. 1.

2.4 Lung Segmentation
Since distinctive information of pneumonia is in the lungs on CT images, we apply
lung segmentation to obtain only the lung area. For segmentation, we applied a

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

7

Fig. 4 LDCT denoising deep learning network architecture

Table 2 Performance results for segmentation network.
Train Size

Test Size

Accuracy

Error Rate

S-Dice

5401

2316

0.9870

0.0325

0.9934

Fig. 5 The architecture of the segmentation network.

similar approach to BidirectionalConvLSTMU-Net architecture. The architecture
of the segmentation network is given in Fig. 5. We used 70% of the dataset for
training and 30% of the data set for testing in the training of the segmentation
network. We initially received the 1e-4 learning rate and dynamically reduced it.
We trained using the Adam stochastic optimization algorithm which was developed as a solution to the vanish gradient problem. The performance results of the
segmentation network are given in Table. 2.
We obtained an accuracy rate of 0.9870, error rate of 0.0325 and s-dice rate of
0.9934. The region of interest is obtained from the CT images using the Graphcut
image processing method. Sample images of the lung regions obtained after the
graphcut procedure are given in Fig. 6.
Then all images in the dataset are brought to 256x256 pixels in size and the
intensity pixel values of all images are normalized from [0,255] to the standard
normal distribution by min-max normalization to the intensity range of [0,1] as
follows.
xnorm =

x − xmin
xmax − xmin

(1)

where x is the pixel intensity. xmin and xmax are minimum and maximum intensity
values of the input image.

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

8

Erdi Acar et al.

(a)

(b)

(c)

(d)

Fig. 6 Sample lung regions obtained as a result of segmentation from the images in the data
set. a is an example of lung region for bacterial pneumonia.b is an example of lung region for
COVID-19. c is an example of lung region for viral pneumonia. d is an example of lung region
for normal.

2.5 Data Augmentation
The performance of deep learning neural networks often increases with the amount
of data available. Data augmentation is a technique of artificially generating new
training data from existing training data. Image data augmentation involves creating transformed versions of images in the training dataset that belong to the
same class as the original image. Conversions involve a number of operations from
the image manipulation area such as pan, rotate, zoom, and much more. The aim
is to increase the generalizability of the model while expanding the training data
set with new, reasonable examples.
Image data augmentation is applied to the training dataset. Given that network
is constantly seeing new, slightly modified versions of input data, the network can
learn more robust features. There are three types of data augmentation methods:
(1) Dataset generation and expanding an existing dataset. The problem with this
approach is that the generalization capability of the model may not fully increase.
(2) In-place/on-the-fly data augmentation. Using this type of data augmentation,
it is ensured that the network is trained to see new variations of data in each
epoch. This method increases the generalization ability of the model. (3) A hybrid
approach combining 1 and 2 approaches. We use an in-place / on-the-fly augmentation approach when training the network. In addition, we used flip left-right
(probability = 0.3) and rotate (probability = 0.4, max left rotation = 10, max
right rotation = 10) augmentation techniques.

2.6 Quantum Fourier Transform
Pattern recognition is currently applied in many fields such as medicine, space,
defense industry, security and sensor technologies. These processes take a long time
in conventional computers due to the increasing number of data. It is emphasized
that such problems can be solved more easily with quantum computers that are
still developing. In addition to such a situation, quantum machine learning can
improve machine learning performance and make it efficient due to quantum’s
superior properties such as entanglement and superposition. In the context of
quantum machine learning, relevant research is carried out on whether quantum
information brings a new perspective to how machines recognize patterns in data,

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

9

Fig. 7 Quantum fourier transform circuit.

whether they can learn from less training data, their ability to develop new machine
learning methods, or to identify[45, 46].
There are two different strategies when designing quantum machine algorithms.
The first is to translate classical machine learning models into quantum computing
language to achieve an algorithmic acceleration. The second is to combine classical
algorithms with quantum tools, keeping computational resources low. In our study,
we adopt the second approach and apply quantum fourier transform (QFT) in the
image preprocessing stage. QFT circuit is given in Fig. 7.
With QFT, any quantum state is moved into phase space. Thus, all possible
situations are easily recognized and calculated simultaneously with the effect of
the superposition state and semantically valuable information is extracted. Thus,
QFT can be used as a feature extractor.
For applying QFT, we first encode the image into a quantum circuit. QFT
application scheme is given in Fig. 8. We use a 4-qubit quantum circuit for the
2x2 kernel filter used in QFT. The quantum circuit we use consists of encoding
data, applying the quantum fourier transform, and a measurement process called
decoding. During the data coding phase, the Hadamard gate is applied to each
qubits and all qubits are brought into superposition. The input data is then encoded into the quantum circuit as parameters of the Ry gates. Then, CNOT gates
are applied between 1-2, 2-4 and 2-3 qubits so that each qubit becomes entangled
with each other and the data encoding phase is completed. In the second step,
the QFT circuit is applied. In the decoding stage, the measurement process is
performed to obtain the expected value of each qubit on the basis of Pauli-Z. The
measurement results are written into the feature matrix.

2.7 Framework of Proposed Deep Learning Model For Diagnostic
In the model, we used the ResNet50v2 network as a feature extractor. We used
2x2 kernel size in the QFT. In addition, we started the ResNet50v2 network with
imagenet weights. Then we applied the flatten layer, which converted the feature
matrix obtained from the feature extractor into a feature vector so that we could
feed it into the full connected layer. Then we applied dense layers (512, ReLu),

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

10

Erdi Acar et al.

Fig. 8 Quantum fourier transform implementation scheme.

Fig. 9 Framework of proposed deep learning network for diagnostic.

Batch Normalization (0.2), (256, ReLu), and (4, Softmax). We used the NDCT
dataset formed as a result of the output of the LDCT denoising network in the
training of the network. The architecture of the proposed model is given in Fig. 9.

3 Result
3.1 Performance Metrics
We reported the performance of the proposed model with accuracy, precision,
sensitivity, specificity and F1-score metrics. The confusion matrix used to explain
the performance of the classification model consists of true positive (TP), true
negative (TN), false positive (FP), and false negatives (FN).
Accuracy is a measure of how many correct predictions the classifier makes of
all test data and is defined as follows.
Accuracy =

TP + TN
TP + TN + F P + F N

(2)

Precision is an indication of how many of the positive classes are positively predicted r and is calculated as follows.
P recision =

TP
TP + F P

(3)

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

11

Table 3 Dataset distribution used for training and test.
Classes

Train Size 72%

Validation Size 8%

Test Size 20%

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Total

832
2326
500
1898
5556

93
258
56
210
617

232
646
139
527
1544

Sensitivity refers to how well anticipates those who are actually sick and is calculated as follows.
TP
Sensitivity =
(4)
TP + FN
Specificity is the proportion of people who test negatively among those who actually do not have the disease and is defined as:
Specif icity =

TN
TN + F N

(5)

Precision and sensitivity are two important measures and there is a trade-off between them. F1-Score is a good choice when you want to deal with this trade-off
and strike a balance between them. This score can be interpreted as a weighted
sensitivity and precision average and is defined as follows.
F 1 − Score = 2 ×

Sensitivity × P recision
Sensitivity + P recision

(6)

3.2 Experimental Results and Analysis
The dataset used in the training of the proposed model consists of NDCT images obtained in the output of the LDCT denoising network.We reserve %80 of
the dataset for training and %20 of the dataset for testing. The number of data
allocated for training, validation and testing is given in Table. 3. To speed up the
training phase, the images are scaled and the network takes a 256 x 256-pixel image as input. We optimize the network with the Adam optimization algorithm. We
start the learning rate at 0.001 and dynamically reduce it during training. Besides,
we apply early stopping when no increase is observed in the training process.
The architecture of the quantum fourier transform in the preprocessing stage
was run on the qiskit quantum simulator. For the rest of the model, we’re using
the TensorFlow interface. The study was carried out on a personal computer with
an Intel Xeon E3-1245 3.7 GHz processor, 48 GB RAM, and 2 GB Nvidia P400
graphics card.
The change of the training and validation phase of the proposed deep learning
model by epoch is given in Fig. 10. Loss denoted how the actual outcome differs
from the estimate. The loss is expected to be inversely proportional to the accuracy
of the model. Considering that the weights were randomly selected at the beginning
of the training from the graph in Fig. 10, it showed low accuracy and high loss
values as an indication that the network made false predictions. However, the
accuracy value showed higher values in the following periods, and the error rate

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

12

Erdi Acar et al.

Fig. 10 The change of the training and validation phase of the proposed deep learning model
by epoch.

Fig. 11 Confusion matrix values of the proposed model.

decreased. This indicated that the model was beginning to solve the classification
problem. We are started training 30 epochs in model training. After the 15th
epoch, the model reached the highest accuracy value and the lowest loss value.
After this epoch, it was seen that the performance did not improve.
The dataset used to show the efficiency of the ResNet50v2 feature extraction
network and its visualization using the test dataset t-SNE are given in Fig. 12.
Considering Fig.2 and Fig.12 comparatively, it can be observed that ResNet50v2
effectively extracts different features of the classes in the dataset in which it performs effectively.
The confusion matrix and performance results of the proposed model is given in
Fig. 11 and Table. 4 respectively. The overall performance results of the proposed
model are 99.5%, 99.2%, 99.0% 99.7%, 99.1% for accuracy, precision, sensitivity,
specificity, and F1-score, respectively.
To increase the interpretability of the model, we used the gradient-weighted
class activation mapping (GradCAM) method to visualize where the model focuses
on the CT images while making decisions. We created heat maps with this mapping
method. This method shows suspicious areas in COVID-19 and other pneumonia

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

13

Table 4 The results show performance results for the proposed model.
Accuracy:
Error Rate:

0.995
0.021

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Overall

Precision

Sensitivity

Specificity

F1-Score

0.996
0.994
0.979
1.000
0.992

0.987
0.997
0.979
1.000
0.990

0.999
0.991
0.998
1.000
0,997

0.991
0.995
0.979
1.000
0,991

(a)

(b)

Fig. 12 (a) is distribution of data set after feature extraction visualized using t-SNE. (b) is
distribution of test data set after feature extraction visualized using t-SNE.

images. Sample images for the heat map of COVID-19 and other pneumonia images
are given in Fig. 13

4 Discussion and Concluding Remarks
This is the first study to use quantum Fourier transform technique in computedaided diagnosis of COVID-19 pneumonia. Rapid diagnosis has a key role in the
control of infectious diseases and current pandemic of COVID-19. Due to the heavy
workload of a large number of infected patients and healthcare professionals, it is
predicted that the artificial intelligence-based computer-aided system can speed
up the diagnostic process. These systems can enable effective diagnosis of disease
in a shorter period of time, as in the case of lack and inability of radiologists during
a pandemic crisis. It can also reduce the need for human surveillance and identify
details invisible to the human eye.
Patients undergoing Computed Tomography (CT) scan are given a high radiation dose to obtain high-quality images. On the other hand, noise and artifacts
occur in CT images when the radiation dose is reduced. This directly affects diagnostic performance. As a solution to this problem, we use a CNN-based network

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

14

Erdi Acar et al.

(a)

(b)

(c)

Fig. 13 Sample images for the heat map of COVID-19 and other pneumonia images. (a)
is heat map of Bacterial Pnumonia. (b) is heat map of COVID-19.(c) is heat map of Viral
Pnumonia.

that suppresses noise to remove interference from low-dose CT (LDCT) images. In
this study, we proposed a CNN-based method to distinguish COVID-19 pneumonia
from other types of pneumonia using low-dose CT images to reduce the radiation
used in CT. This method is aimed to increase the diagnostic performance of LDCT
image, reduce interobserver and intraobserver variability, decrease the number of
false-negative and false-positive results, reduce time consumed in diagnosis, and
achieve standardization in evaluating and reporting radiological images. The accuracy, precision, sensitivity, specificity, and F1-score showed high performance of
the proposed technique.
Ozcan[47] used the transfer learning approach with 3 different pre-trained
GoogleNet, ResNet18, and ResNet50 CNN models to diagnose COVID-19 (131),
viral pneumonia (148), bacterial pneumonia (242), and normal (200) cases from
chest x-ray data. They have adopted the grid search method for hyperparameter
optimization. They achieved the highest performance on the test set (39 COVID19, 73 bacterial pneumonia, 60 viral pneumonia, and 44 normal) .The results of
the study are 97.5%accuracy, 95.9% precision, 97.2% sensitivity, 97.9% specificity
and 96.6% F1-score. Loey et al.[48] proposed a system for COVID-19 diagnosis using the Generative Adversarial Network(GAN) and pretrained CNN models with
deep transfer learning method. Their work is based on GoogleNet, ResNet18, and
AlexNet. Since the number of chest x-ray images for COVID-19 is low, their GAN
was used to generate more samples. Their accuracy, precision, sensitivity, and F1score Performance results on the test dataset(COVID- 19 (9), Viral Pneumonia
(9), Bacterial pneumonia (9), and Normal (9)) among the dataset with a total
of 306 images were 80.5%, 80.5%, 84.2%, and 82.4%, respectively. Khan et al.[26]
proposed a deep CNN architecture called CoroNet for diagnosing patients infected
with COVID-19 from chest X-ray radiographs. In their study, they used a total
of 1251 images of 284 COVID-19, 327 bacterial pneumonia, 330 viral pneumonia, and 310 normal patients. The dataset is divided by 80% and 20% for the
training and test set, respectively. They used a 4-fold cross-validation approach to
evaluate the performance of the 4-class model. The overall performance of the proposed system achieved 89.6% accuracy, 90.0% precision, 89.9% sensitivity, 96.4%
specificity, and 89.8% F1-score. Farooq and Hafeez [49] presented a deep learning scheme with a pre-trained ResNet-50 network to detect COVID-19 infected

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

15

Table 5 Comparison of dataset size between our study and other studies.
Study

Type of Images

COVID-19

Viral Pneumonia

Bacterial Penumonia

Normal

Total

Ozcan[47]

X-ray

131

148

242

200

721

Loey et al.[48]

X-ray

69

79

79

79

306

Khan et al.[26]

X-ray

284

327

330

310

1251

Farooq and Hafeez [49]

X-ray

68

660

931

1203

2862

Our Study

CT

4387

695

1157

2635

7717

patients called COVID-ResNet. The data set includes a total of 68 COVID-19,
1203 normal, 931 bacterial pneumonia, and 660 viral pneumonia cases. The overall performance of the proposed system achieved 95.0%, accuracy 96.8% precision
96.8% sensitivity, and 96.9% F1-score, respectively. Our study features the first
CNN-based application to use 4-class CT datasets (COVID-19, Viral Pneumonia,
Bacterial Pneumonia, and Normal) for the differential diagnosis of COVID-19 and
other types of pneumonia. Therefore, for comparison of our results with the current literature, we analyzed the studies in which 4-class chest x-ray datasets are
used. The comparison of datasets and performance results with other studies are
given in Table 5 and Table 6, respectively.
The performance of a model is measured by its ability to generalize over test
data. The data set we used for training in our study is 4-5 times larger than the
datasets used in other studies. In addition, their markable point is that the generalization ability of the model is tested on a data set that is approximately 3-4
times the dataset used in other studies. The results obtained according to the performance criteria in Table 6 show that our model is superior to other models. Since
any quantum state is moved into phase space with QFT, all possible situations are
easily recognized and calculated simultaneously with the effect of the superposition state, and semantically valuable information is extracted. Therefore, the use
of quantum Fourier transform in feature extraction makes a great contribution.

Funding
No payments or services have been received from a third party.

Conflict of interest
The authors declare that they have no conflict of interest.

References
1. Verity R, Okell L C, Dorigatti I, Winskill P, Whittaker C, Imai N et al, Estimates of the
severity of coronavirus disease 2019: a model-based analysis. The Lancet infectious diseases
(2020).

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

16

Erdi Acar et al.

Table 6 Comparison of performance results between our study and other studies.
Study

Accuracy(%)

Classes

Precision(%)

Sensitivity(%)

Specificity(%)

F1(%)

Test Size

Ozcan[47]

97.6

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Overall

100.0
97.5
97.6
95.2
95.9

97.3
100.0
93.2
100.0
97.2

na
na
na
na
97.9

98.6
98.7
95.3
97.5
96.6

73
39
60
44
216

Loey et al.[48]

80.5

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Overall

88.9
100.0
77.8
55.6
80.5

70.0
100.0
66.7
100.0
84.2

na
na
na
na
na

78.38
100.0
71.8
71.4
82.3

9
9
9
9
36

Khan et al.[26]

89.6

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Overall

86.85
93.17
84.1
95.25
90.0

95.9
98.25
82.1
93.5
89.92

95.0
97.9
94.8
98.1
96.4

86.3
95.61
83.1
94.3
89.8

na
na
na
na
na

Farooq and Hafeez[49]

95.0

Bacterial Pneumonia
COVID-19
Viral Pneumonia
Normal
Overall

95.6
100.0
92.7
99.1
96.8

97.1
100.0
93.9
96.5
96.8

na
na
na
na
na

96.3
100.0
93.3
97.8
96.9

246
8
234
149
637

Our Study

99.5

Bacterial Pneumoina
COVID-19
Viral Pneumonia
Normal
Overall

99.6
99.4
97.9
100.0
99.2

98.7
99.7
97.9
100.0
99.0

99.9
99.1
99.8
100.0
99.7

99.1
99.5
97.9
100.0
99.1

232
646
139
527
1544

2. Zhou S, Wang Y, Zhu T, Xia L, CT Features of Coronavirus Disease 2019 (COVID-19)
Pneumonia in 62 Patients in Wuhan, China. AJR Am J Roentgenol, 214, 1287-1294, (2020).
3. Rubin G D, Ryerson C J, Haramati L B, Sverzellati N, Kanne J P, Raoof S, Anderson
D J, The role of chest imaging in patient management during the COVID-19 pandemic: a
multinational consensus statement from the Fleischner Society. Chest, (2020).
4. Ng M Y, Lee E Y, Yang J, Yang F, Li X, Wang H et al, Imaging profile of the COVID-19
infection: radiologic findings and literature review. Radiology: Cardiothoracic Imaging, 2(1),
e200034, (2020).
5. Corman V M, Landt O, Kaiser M, Molenkamp R, Meijer A et al, Detection of 2019 novel
coronavirus (2019-nCoV) by real-time RT-PCR. Eurosurveillance, 25(3), 2000045, (2020).
6. Dai W C, Zhang H W, Yu J, Xu H J, Chen Het al, CT imaging and differential diagnosis
of COVID-19. Canadian Association of Radiologists Journal, 71(2), 195-200, (2020).
7. Weinstock M B, Echenique A N A, DABR J W R, Leib A et al, Chest x-ray findings in
636 ambulatory patients with COVID-19 presenting to an urgent care center: a normal chest
x-ray is no guarantee. J Urgent Care Med, 14(7), 13-8, (2020).
8. Gholizadeh-Ansari M, Alirezaie J, Babyn P, Deep learning for low-dose CT denoising using
perceptual loss and edge detection layer. Journal of digital imaging, 1-12, (2019).
9. Chen H, Zhang Y, Zhang W, Liao P, Li K, Zhou J, Wang G, Low-dose CT denoising with
convolutional neural network. In 2017 IEEE 14th International Symposium on Biomedical
Imaging (ISBI 2017) (pp. 143-146). IEEE, (2017).
10. Ehman E C, Yu L, Manduca A, Hara A K, Shiung M M, Jondal D et al, Methods for
clinical evaluation of noise reduction techniques in abdominopelvic CT. Radiographics, 34(4),
849-862, (2014).
11. Kang E, Min J, Ye J C, A deep convolutional neural network using directional wavelets
for low-dose X-ray CT reconstruction. Medical Physics, 44(10), 360-375, (2017).

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

Title Suppressed Due to Excessive Length

17

12. Yang Q, Yan P, Zhang Y, Yu H, Shi Y et al, Low-dose CT image denoising using a generative adversarial network with Wasserstein distance and perceptual loss. IEEE transactions
on medical imaging, 37(6), 1348-1357, (2018).
13. Yi X, Babyn P, Sharpness-aware low-dose CT denoising using conditional generative adversarial network. Journal of digital imaging, 31(5), 655-669, (2018).
14. You C, Yang Q, Shan, H, Gjesteby L, Li G et al, Structurally-sensitive multi-scale deep
neural network for low-dose CT denoising. IEEE Access, 6, 41839-41855, (2018).
15. Chen H, Zhang Y, Kalra M K, Lin F, Chen Y et al, Low-dose CT with a residual encoderdecoder convolutional neural network. IEEE transactions on medical imaging, 36(12), 25242535, (2017).
16. Wolterink J M, Leiner T, Viergever M A, Išgum I, Generative adversarial networks for
noise reduction in low-dose CT. IEEE transactions on medical imaging, 36(12), 2536-2545,
(2017).
17. Shiri I, Akhavanallaf A, Sanaat A, Salimi Y, Askari D et al, Ultra-low-dose chest CT
imaging of COVID-19 patients using a deep residual neural network. European Radiology,
1-12, (2020).
18. Naudé W, Artificial intelligence vs COVID-19: limitations, constraints and pitfalls, Ai and
Society, 1, (2020).
19. Toğaçar M, Ergen B, Cömert Z, COVID-19 detection using deep learning models to exploit
Social Mimic Optimization and structured chest X-ray images using fuzzy color and stacking
approaches. Computers in Biology and Medicine, 103805, (2020).
20. Ardakani A A, Kanafi A R, Acharya U R, Khadem N, Mohammadi A, Application of
deep learning technique to manage COVID-19 in routine clinical practice using CT images:
Results of 10 convolutional neural networks. Computers in Biology and Medicine, 103795,
(2020).
21. Xu X, Jiang X, Ma C, Du P, Li X, Lv S et al, A deep learning system to screen novel
coronavirus disease 2019 pneumonia. Engineering, (2020).
22. Nour M, Cömert Z, Polat K, A Novel Medical Diagnosis model for COVID-19 infection
detection based on Deep Features and Bayesian Optimization. Applied Soft Computing,
106580, (2020).
23. Panwar H, Gupta P K, Siddiqui M K, Morales-Menendez R, Singh V, Application of Deep
Learning for Fast Detection of COVID-19 in X-Rays using nCOVnet. Chaos, Solitons and
Fractals, 109944, (2020).
24. Ozturk T, Talo M, Yildirim E A, Baloglu U B, Yildirim O, Acharya U R, Automated
detection of COVID-19 cases using deep neural networks with X-ray images. Computers in
Biology and Medicine, 103792, (2020).
25. Toraman S, Alakus T B, Turkoglu I, Convolutional capsnet: A novel artificial neural
network approach to detect COVID-19 disease from X-ray images using capsule networks.
Chaos, Solitons and Fractals, 140, 110122, (2020).
26. Khan A I, Shah J L, Bhat M M, Coronet: A deep neural network for detection and diagnosis
of COVID-19 from chest x-ray images. Computer Methods and Programs in Biomedicine,
105581, (2020).
27. Ucar F, Korkmaz D, COVIDiagnosis-Net: Deep Bayes-SqueezeNet based Diagnostic of the
Coronavirus Disease 2019 (COVID-19) from X-Ray Images. Medical Hypotheses, 109761,
(2020).
28. Mahmud T, Rahman M A, Fattah S A, (2020). CovXNet: A multi-dilation convolutional
neural network for automatic COVID-19 and other pneumonia detection from chest X-ray
images with transferable multi-receptive feature optimization. Computers in biology and
medicine, 122, 103869, (2020).
29. Minaee S, Kafieh R, Sonka M, Yazdani S, Soufi G J, Deep-covid: Predicting covid-19 from
chest x-ray images using deep transfer learning. Medical Image Analysis, 65, 101794, (2020).
30. Song J, Wang H, Liu Y, Wu W, Dai G, Wu Z, Deng K, End-to-end automatic differentiation of the coronavirus disease 2019 (COVID-19) from viral pneumonia based on chest CT.
European journal of nuclear medicine and molecular imaging, 1-9, (2020).
31. Hemdan E E D, Shouman M A, Karar M E, Covidx-net: A framework of deep learning
classifiers to diagnose covid-19 in x-ray images. arXiv preprint arXiv:2003.11055, (2020).
32. Zheng C, Deng X, Fu Q, Zhou Q, Feng J, Ma H, Wang, X, Deep learning-based detection
for COVID-19 from chest CT using weak label. medRxiv, (2020).
33. Song Y, Zheng S, Li L, Zhang X, Zhang X, Huang Z, Chong Y, Deep learning enables
accurate diagnosis of novel coronavirus (COVID-19) with CT images. medRxiv, (2020).

medRxiv preprint doi: https://doi.org/10.1101/2020.12.29.20248900; this version posted January 4, 2021. The copyright holder for this
preprint (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in
perpetuity.
It is made available under a CC-BY-NC-ND 4.0 International license .

18

Erdi Acar et al.

34. Azad R, Asadi-Aghbolaghi M, Fathy M, Escalera S, Bi-directional ConvLSTM U-net with
Densley connected convolutions. In Proceedings of the IEEE International Conference on
Computer Vision Workshops, (2019).
35. Weinstein Y S, Pravia M A, Fortunato E M, Lloyd S, Cory D G, Implementation of the
quantum Fourier transform. Physical review letters, 86(9), 1889, (2001).
36. He K, Zhang X, Ren S, Sun J, Deep residual learning for image recognition. In Proceedings
of the IEEE conference on computer vision and pattern recognition, pp. 770-778, (2016).
37. Maaten L V D, Hinton G, Visualizing data using t-SNE. Journal of machine learning
research, 9(Nov), 2579-2605, (2018).
38. Shorten C, Khoshgoftaar T M, A survey on image data augmentation for deep learning.
Journal of Big Data, 6(1), 60, (2019).
39. Selvaraju R R, Cogswell M, Das A, Vedantam R, Parikh D, Batra D, Grad-cam: Visual
explanations from deep networks via gradient-based localization. In Proceedings of the IEEE
international conference on computer vision, pp. 618-626, (2017).
40. Wang J, Lu H, Liang Z, Eremina D, Zhang G, Wang S et al, An experimental study on
the noise properties of x-ray CT sinogram data in Radon space. Physics in Medicine and
Biology, 53(12), 3327, (2008).
41. Zeng D, Huang J, Bian Z, Niu S, Zhang H et al, A simple low-dose x-ray CT simulation
from high-dose scan. IEEE transactions on nuclear science, 62(5), 2226-2233, (2015).
42. Van Drongelen W, Signal processing for neuroscientists. Academic press, (2018).
43. Simonyan K, Zisserman A, Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, (2014).
44. Yang, Q, Yan P, Kalra M K, Wang G, CT image denoising with perceptive deep neural
networks. arXiv preprint arXiv:1702.07019, (2017).
45. Biamonte J, Wittek P, Pancotti N, Rebentrost P, Wiebe N et al, Quantum machine learning. Nature, 549(7671), 195-202, (2017).
46. Schuld M, Sinayskiy I, Petruccione F, An introduction to quantum machine learning.
Contemporary Physics, 56(2), 172-185, (2015).
47. Ozcan T, A Deep Learning Framework for Coronavirus Disease (COVID-19) Detection in
X-Ray Images, [Online]. Available: https://www.researchsquare.com/article/rs-26500/v1
48. Loey M, Smarandache F,M Khalifa N E, Within the Lack of Chest COVID-19 X-ray
Dataset: A Novel Detection Model Based on GAN and Deep Transfer Learning. Symmetry,
12(4), 651, (2020).
49. Farooq M, Hafeez A, Covid-resnet: A deep learning framework for screening of covid19
from radiographs. arXiv preprint arXiv:2003.14395, (2020).

