bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT
Scan Images Using Multi-image Augmented
Deep Learning Model
Kiran Purohit, Abhishek Kesarwani, Dakshina Ranjan Kisku, and Mamata
Dalui
Department of Computer Science and Engineering
National Institute of Technology, Durgapur
India
kiran.purohit789@gmail.com, keabhi20@gmail.com, drkisku@cse.nitdgp.ac.in,
and mamata.dalui@cse.nitdgp.ac.in

Abstract. COVID-19 is posed as very infectious and deadly pneumonia type disease until recent time. Despite having lengthy testing time,
RT-PCR is a proven testing methodology to detect coronavirus infection. Sometimes, it might give more false positive and false negative
results than the desired rates. Therefore, to assist the traditional RTPCR methodology for accurate clinical diagnosis, COVID-19 screening
can be adopted with X-Ray and CT scan images of lung of an individual. This image based diagnosis will bring radical change in detecting
coronavirus infection in human body with ease and having zero or near
to zero false positives and false negatives rates. This paper reports a
convolutional neural network (CNN) based multi-image augmentation
technique for detecting COVID-19 in chest X-Ray and chest CT scan
images of coronavirus suspected individuals. Multi-image augmentation
makes use of discontinuity information obtained in the filtered images for
increasing the number of effective examples for training the CNN model.
With this approach, the proposed model exhibits higher classification
accuracy around 95.38% and 98.97% for CT scan and X-Ray images
respectively. CT scan images with multi-image augmentation achieves
sensitivity of 94.78% and specificity of 95.98%, whereas X-Ray images
with multi-image augmentation achieves sensitivity of 99.07% and specificity of 98.88%. Evaluation has been done on publicly available databases
containing both chest X-Ray and CT scan images and the experimental
results are also compared with ResNet-50 and VGG-16 models.
Keywords: Coronavirus· CNN· Image Augmentation· X-Ray images· CT Scan images.

1

Introduction

Coronavirus disease or COVID-19 is an infectious disease which so far has infected millions of people and deaths are increasing day by day. Due to deadly
infectious nature of coronavirus, it is spreading rapidly among people who are

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

2

Kiran Purohit et al.

exposed to COVID-19 infected individuals
Due to unknown cause of pneumonia type infection and ability to generate
new strain by mutation, it is almost impossible to have a cure in the form of
vaccine or medicine for COVID-19 patients. In the affected countries, reverse
transcription polymerase chain reaction or RT-PCR has been adopted as standard diagnostic method to detect viral nucleic acid as coronavirus infection in
COVID-19 suspected individuals. The test takes 4-6 hours or even a whole day
to give the results. As the test takes more time to generate the result compared
to the time for spreading coronavirus among people and sometimes it gives false
positive and false negative results. The false negative rate for SARS-CoV-2 RTPCR testing is profoundly factor: most noteworthy in the initial 5 days after
exposure (up to 67%), and least on day 8 after exposure (21%). In view of this
investigation, the false negative rate for SARS-CoV-2 RT-PCR is very high, even
at its least on day 8 post-exposure, or 3 days after symptoms. At its best, one
out of five individuals associated with COVID-19 will test negative. RT-PCR
tests showed 5% false positives rates. Therefore, to test the COVID-19 infection rapidly and in more efficient way, chest X-Ray or/and CT scan images of
COVID-19 suspected individuals could be an answer. Moreover, time taken by
RT-PCR test, false positive errors and shortage of test kits compared to coronavirus infected persons make it inefficient.
In contrast, X-Ray and CT scan images are widely accepted traditional form

Fig. 1: (a-c) COVID-19 infected chest X-Ray images, (d-f) Pneumonia infected
chest X-Ray and (g-i) Normal chest X-Ray images [4].

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

3

of diagnosing individuals for a number of diseases is a common practice adopted
by radiologists and medics in healthcare and in medical imaging. The X-Ray
and CT scan technologies have been used for several decades since its inception
in medical diagnosis. In many highly affected regions or countries, it is difficult
to provide sufficient number of RT-PCR test kits for testing COVID-19 infection for thousands of corona suspected people. Therefore, to address this issue,
COVID detection can be made from chest X-Ray and CT scan images of corona
suspected individuals who are suffering from COVID-19 symptoms.
The previous investigations uncover that the contaminated patients display
distinct visual qualities in Chest X Ray pictures, as appeared in Figure 1. These
qualities regularly incorporate multi‐focal, reciprocal ground‐glass opacities and
inconsistent reticular (or reticulonodular) opacities in non-ICU patients, while
thick aspiratory unions in ICU patients. Nonetheless, the manual investigation of
these inconspicuous visual attributes on Chest X Ray pictures requires domain
expertise and is challenging. Also, the exponential increment in the quantity of
contaminated patients makes it hard to finish the finding in time, prompting
high bleakness and mortality.
For CT SCAN, imaging discoveries have mostly included single or numerous injuries, sketchy or segmental GGOs, and reticular markings that essentially
followed peribronchovascular and subpleural disseminations. Interlobular septal thickening may be available, and pleural emission and extended mediastinal
lymph hubs were infrequently observed.
To deal with the issues related to RT-PCR testing kit, we have come up
with a solution by developing an AI-based application with image processing
based multi-image augmentation technique for detecting COVID-19 infection in
corona suspected persons. With this integrated framework, both X-Ray and CT
scan images of chest can be tested for virus detection. This application makes
use of multiple representations having sharp discontinuity information of same
X-Ray and CT scan images, produced through first and second order derivative
operators, are mixed up with visible band X-Ray and CT scan images for training the convolutional neural network (CNN) based deep learning model. This
deep learning model has the ability to learn the underlying pattern of COVID-19
infected X-Ray and CT scan images in a more effective way from representative
images as well as original images of the same person used for training. Moreover,
with a simple configuration of CNN model, this work performs well for a range
of COVID-19 infected X-Ray and CT scan images of chest.
The main objective of using deep learning model [19] is to achieve higher
accuracy of classification with chest X-Ray and CT scan images by separating
the COVID-19 cases from non-COVID-19 cases. It is well-known that to train a
deep model, someone needs a large number of example images of both COVID19 and non-COVID-19 individuals for making the learning of the model about
the patterns more effective. To achieve this target, a number of representative
images are generated using sharpening filters technique driven by first and second order derivative operators [10] and then these discontinuity information of
the representations are mixed up with the original X-Ray and CT scan images

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

4

Kiran Purohit et al.

separately and further, these large number of multi-image augmentation is used
to train the CNN based deep learning model. The databases of X-Ray [6] and CT
scan [24] images are publicly available in GitHub repository for the purpose of
experiments. Both these datasets contain chest images of COVID-19 and nonCOVID-19 individuals. The X-Ray database contains 67 COVID images and
the same number of non-COVID images whereas CT scan database contains 345
COVID images and the same number of non-COVID images. To conduct the
experiment, images are down sampled to 50×50 dimension from their original
size. The random subsampling or holdout method is adopted to test the efficacy of the model. In holdout method, the whole dataset containing COVID
positive and negative samples are divided into a number of ratios. It has been
observed that when the number of training examples are increased, the model
exhibits higher classification accuracy. Moreover, this result exhibits more consistency while layers are being changed in CNN based deep model. To evaluate
the framework in a robust and effective way, a number of evaluation metrics such
as classification accuracy, loss, area under ROC curve (AUC), precision, recall,
F1 score and confusion matrix has been used. The values of these metrics have
been determined on different ratios of training and test samples considering a
number of layers in deep model. The model is correctly able to classify the chest
X-Ray and CT scan images of COVID-19 cases from non-COVID-19 cases.
The paper is organized as follows. Section 2 introduces the proposed model
to detect COVID-19 infections in CT Scan and X-Ray images of a chest. Section
3 presents experimental results, analysis and comparison among various deep
learning models. Concluding remarks are made in the last section.

2

Proposed Work

In order to detect COVID-19 in chest X-Ray and CT Scan images of a lung
the proposed work uses a number of sharpening filters such as Sobel, Prewitt,
Roberts, Scharr, Laplacian, Canny, and a novel filter Hybrid.
2.1

Hybrid filter generation

To strengthen the process of detecting the sharp discontinuity on X-ray and CT
Scan images, a novel edge detector is used, which is called Hybrid filter [1]. It uses
both Canny [10] and Sobel [10] detector to normalize the noise content as well
as provides the high frequency spatial information. This rare combination makes
the operator very much useful for edge detection as well as image segmentation
operations while texture properties of the image are enhanced. In this process,
texton image [11] is used for unique texture which is generated from derivative of
Gaussian [23]. Then the gradient of texton image is determined with the help of
paired disk masks. The paired disk masks are the pair of half disk binary images.
To get the texton gradient image, the pair of mask is convolved with the texton
image and the distance is calculated between two convolved images with the use

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

5

Filter Bank
K-means
Clustering

Texton Image
Grayscale

X2 Distance

Pair Disk Mask

Texton Gradient
Canny

w1 = 0.3

Sobel

w2 = 0.7

Hybrid Edge Detection

Fig. 2: Design Process of the Hybrid Edge Detection Operator
of Chi-square metric [13]. The output is obtained by the combination of Canny
operator, Sobel operator and texton gradient image as given in Equation 1.
O = T g × (w1 × Canny_image + w2 × Sobel_image)

(1)

where, O is the output image, T g is the texton gradient image and w1 and w2
are weights (w1 + w2 = 1). The design process of the Hybrid filter is shown in
Figure 2.
2.2

Multi-image representation

Sharpening of an image [10] expands the contrast between dark and bright areas
to draw out the features. Sharpening method uses a high pass kernel to an image.
Sharpening is only inverse to the blurring. We decrease the edge content in case
of blurring, and in sharpening, we increment the edge content. For noisy images,
firstly smoothing is done and then a sharpening filter is applied.
The majority of the information about the shape of an image is enclosed in
edges. Firstly, edges are distinguished in an image by the use of first and secondorder derivative operators [10] and afterwards by enhancing those edges, image
sharpness will increment and the image will become more clear. Consequently,
detection of COVID-19 infection on X-Ray and CT Scan images will be more
precise and accurate if we detect on the edged image.
The X-Ray [6] and CT scan [24] databases contain a smaller number of
images which may not be useful for training the CNN model. Moreover, with
small number of examples, desired classification accuracy may not be achieved.

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

6

Kiran Purohit et al.

So, to resolve this issue we apply multi-image augmentation by increasing the
number of examples as well as the diversity of available characteristics with XRay and CT Scan images. For multi-image augmentation, the input image is
converted into grayscale and Histogram Equalization is applied to correct the
contrast of input grayscale image. To achieve better image representation with
discontinuity information, a number of first and second order edge detection
operators such as Sobel, Prewitt, Roberts, Scharr, Laplacian, Canny, and newly
develop Hybrid are applied. Then, the results of edge detection operator are
appended to our dataset.

(a) Chest X-Ray and its Multiple Rep- (b) Chest X-Ray and its Multiple Repreresentations of a COVID-19 Non-Infected sentations of a COVID-19 Infected IndiIndividual.
vidual.

(c) Chest CT scan and its Multiple Rep- (d) Chest CT scan and its Multiple Representations of a COVID-19 Non-Infected resentations of a COVID-19 Infected IndiIndividual.
vidual.

Fig. 3: Multiple Representations of Chest X-Ray and CT scan images
Edge detection operators perform a crucial job in separating low-level features or discovering information of the lungs. An edge is a sharp discontinuity
change over the boundaries of the grey levels. In chest X-Ray and CT scan images, edges represent the lung boundaries, which occurs due to the change in the
grey levels at these lung boundaries. Edges are determined to filter out relatively
less basic and smaller details, for improving the processing speed, bringing down
the complexity without the loss of the necessary information. Here, significant
data is retained and non-essential data is separated out. We get more exact and
accurate outcomes if the processing is performed on these edged images. Thus
detection of COVID-19 infection on Chest X-Ray and CT Scan images is found
to be more precise if detected on the edged image.

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

7

The Figure 3(a) shows a chest X-Ray (top left) and its multiple representations obtained by applying sharpening filters, of a person not infected by
COVID-19 whereas the Figure 3(b) shows a chest X-Ray and its multiple representations obtained by applying sharpening filters, of COVID-19 infected person.
Figure 3(c) shows a chest CT scan image and its multiple representations obtained by applying sharpening filters, of a person not infected by COVID-19
whereas Figure 3(d) shows a chest CT scan image and its multiple representations obtained by applying sharpening filters, of COVID-19 infected person.
2.3

Training and classification of CNN based deep learning model

To perform training and classification with a multi-image augmented CNN model
the basic architecture of LeNet [7] model is exploited. It is used to predict COVID
and non-COVID cases from CT Scan and X-ray images of lungs. The deep CNN
model uses three layers such as convolutional, pooling and fully connected layers.
Two activation functions viz. RELU and sigmoid are used. RELU is used after
convolutional layer and sigmoid function is used for classification of test image
into COVID and non-COVID classes. Figure 4 shows the deep learning model
with a number of parameter. In the training stage, the standard stochastic gradient descent (SGD) optimizer with a batch size of 32 and a binary cross-entropy
based loss function are used. The learning rate is set to 0.01, which is linearly
decayed and the maximum epoch is set to 30. To conduct the experiment, images are down sampled to 50×50 dimension from their original size. The random
subsampling or holdout method is adopted to test the efficacy of the model. In
the holdout method, the whole dataset containing COVID positive and negative
samples is divided into a number of ratios like 90:10, 80:20, 70:30 and 60:40
as training and testing samples. In order to alleviate overfitting of the model,
multi-image augmentation is used for training the model using sharpening filters.
This augmentation generates a large number of representative images carrying
discontinuity information.
Steps for detection of coronavirus infection in X-Ray and CT Scan images
of the suspected individuals:
Step 1: Accept the coloured input images from the data set.
Step 2: Convert the image into grayscale.
Step 3: Down sample the images to 50 × 50 dimension from their original size.
Step 4: In CNN based deep learning model we choose layer_sizes = [32, 64, 128],
dense_layers = [0, 1, 2], and conv_layers = [1, 2, 3].
Step 5: Convolution with a 3 × 3 filter size is applied.
Step 6: Activation function RELU is used after convolutional layer.
Step 7: Then Max Pooling is applied with 2 × 2 filter size.
Step 8: Go to Step 5 if conv_layer − 1 > 0
Step 9: Flatten the matrix.
Step 10: Activation function Sigmoid is used for classification of test image into
COVID and non-COVID classes.
Step 11: In training stage, the standard first-order stochastic gradient descent

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

8

Kiran Purohit et al.

(a) Layer 32

(b) Layer 64

(c) Layer 128

Fig. 4: Convolution Neural Network of layer size 32, 64, and 128
optimizer with a batch size of 32, maximum epochs 30 and binary cross entropybased loss function are used.
Step 12: The random subsampling or holdout method is adopted. Whole dataset
is divided into a number of ratios like 90:10, 80:20, 70:30 and 60:40 as training
and testing samples.
Step 13: Various Evaluation Metrics are calculated such as classification accuracy, loss, area under ROC curve (AUC), precision, recall (Sensitivity), Specificity and F1 score.
Step 14: Once the model is trained, one can easily predict whether the individual is affected by Coronavirus infection or not.

3
3.1

Evaluation
Experimental protocol and metrics

The proposed multi-image augmented deep learning model, ResNet-50 and VGG16 all are implemented using python code in Jupyter Notebook and Keras package with TensorFlow [8] on Intel(R) Core(TM) i5-8365U Processor with NVIDIA
Geforce GTX 1050 graphical processing unit of 4GB and 16GB RAM. To evaluate the framework in a robust and effective way, a number of evaluation metrics
such as classification accuracy, loss, area under ROC curve (AUC), precision,
sensitivity, specificity and F1 score have been used. The values of these metrics
have been determined on different ratios of training and test samples considering a number of layers in deep model. The model is correctly able to classify the
chest X-Ray and CT scan images of COVID-19 cases from non-COVID-19 cases.

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

9

The evaluation protocol makes use of holdout method where the whole dataset
containing COVID positive and negative samples are divided into a number
of ratios. During testing, the layers are changed in the augmented based deep
learning model to realize the consistency of the model.
3.2

Experimental results

It has been observed that when the number of training examples are increased,
the model exhibits higher classification accuracy. For traditional train and test
ratio of 70:30 the classification accuracy is obtained around 95.38% and 98.97%
for CT scan and X-Ray images respectively. The data is randomly splited into
training and testing sets for evaluation. The experiment is conducted twice for
every split and it is noted that the accuracy of the model comes similar on both
evaluations. F1 scores remain slight similar and model loss (%) changes as the
layer size is increased while setting the layer size to different values. For less
training samples, a smaller layer size gives good results whereas if the training
samples are increased then more layers are required for better accuracy. The
proposed deep augmented model is also compared with ResNet-50 [2] and VGG16 [17] architecture.
Visual Geometry Group(VGG) a research group from Oxford University in
the United Kingdom proposed VGG networks. There are two commonly used
networks, i.e., VGG-19 and VGG-16, here ’19’ represents 19 deep layers consists
of 3 fully connected layers and 16 convolutional layers whereas the ’16’ means
3 fully connected layers and 13 convolutional layers. The size of input image in
this network is 224×224×3. VGG network uses the pre-trained model on the
ImageNet dataset which cannot improve the classification accuracy of COVID19 screening as it contains a new set of images with labels. ResNet is known as
”residual network” which contains two core factors, i.e., width and depth of the
neural network. These two core factors decide the complexity of the neural network. As the depth of a neural network increase, the training error increases. So,
the residual network is used to solve this problem and increase the network performance (precision and accuracy) as compared to the traditional neural model.
The commonly used residual networks are ResNet 18, 34 (2-deep layers) and
ResNet 50, 101, 152 (3-deep layers). ResNet does not perform well in our case
due to less amount of training datasets.
In this study, the proposed deep augmented model achieves the sensitivity of
99.07% when the ratio of train and test samples is 70:30 and specificity of 98.88%
when the ratio of train and test samples is 70:30 and layer size 32 on the X-Ray
dataset that contains 536 images of COVID-19 and 536 images non-COVID19 including augmented images. The CT Scan dataset contains 2760 images of
COVID-19 and 2760 images of non-COVID-19 individuals including augmented
images. The sensitivity of 94.78% and specificity of 95.98% are achieved when ratio of train and test samples is 70:30 and layer size is 64. The results are shown in
Table 1 and Table 2 for original and augmented images respectively. The model
is able to correctly classify the chest X-Ray and CT scan images of COVID-19
cases from non-COVID-19 cases. Figure 5 shows the confusion matrix for the

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

10

Kiran Purohit et al.

(a) X-Ray images without multi-image augmentation

(b) X-Ray images with multi-image augmentation

(c) CT Scan images without multi-image augmentation

(d) CT Scan images with multi-image augmentation

Fig. 5: Confusion Matrix of our model when train and test ratio is 70:30

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

11

Table 1: COVID-19 screening performance in Original images with CT Scan and
X-Ray datasets
CT Scan Images

Train-Test
60%-40%

X-Ray Images

Proposed
Resnet VGG
Layers
32
64
128
50
16

Proposed
Resnet VGG
Layers
32
64
128
50
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
70%-30%

88.7
31.45
94.5
0.86
92.17
85.22
0.89
32

90.87
36.13
95.2
0.9
92.17
89.57
0.91
64

87.68
65.75
93.5
0.89
85.51
89.86
0.87
128

88.7
70.9
88.7
0.91
85.5
91.88
0.88
50

78.7 98.51 99.25 98.51
45.73 6.49 2.59 13.16
78.7 99.9 100 98.5
0.72 0.97
1
0.97
93.62 100 98.51 100
63.76 97.01 100 97.01
0.81 0.99 0.99 0.99
16
32
64
128

50
23.89
50
0.5
1
0
0.67
50

98.51
6.25
98.5
0.97
100
97.01
0.99
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
80%-20%

89.57
29.79
94.8
0.91
87.25
91.88
0.89
32

92.03
26.81
95.9
0.93
91.01
93.04
0.92
64

90.29
50.84
95.7
0.87
95.07
85.51
0.91
128

78.84
15.6
78.8
0.71
97.39
60.28
0.82
50

77.54 99.25 97.1 100
45
5.21 12.09 2.22
77.5
100 99.8 100
0.76 0.99
1
1
81.15 100 94.03 100
73.91 98.51 100
100
0.78 0.99 0.97
1
16
32
64
128

50
55.6
50
0.5
88.05
11.94
0.64
50

98.51
6.19
98.5
0.97
100
97.01
0.99
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
90%-10%

94.06
18.93
98.1
0.93
95.07
93.04
0.94
32

95.22
17.16
98
0.95
95.65
94.78
0.95
64

94.35
41.09
96.8
0.94
94.78
93.91
0.94
128

93.48
28.3
93.5
0.93
94.49
92.46
0.94
50

78.7 99.25 97.01 99.25
42.97 3.84 6.27 12.05
78.7
100
100 98.6
0.72 0.99
1
0.99
93.04 100 94.03 100
64.34 98.51 100 98.51
0.81 0.99 0.97 0.99
16
32
64
128

51.49
10.57
51.5
1
2.98
1
0.06
50

98.51
5.02
98.5
0.97
100
97.01
0.99
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score

94.93
20.65
98.4
0.97
92.46
97.39
0.95

98.26
9.47
99.5
0.97
99.42
97.1
0.98

98.26
11.68
99
0.98
98.55
97.97
0.98

94.49
31.83
0.91
0.91
98.26
90.72
0.95

83.33 99.25 100 99.25
40.26 3.21 1.08
2.2
83.3
100
100
100
0.79 0.99
1
0.99
91.01 100
100
100
75.65 98.51 100 98.51
0.85 0.99
1
0.99

50
68.33
50
0.5
1
0
0.67

99.25
3.95
99.3
0.99
100
98.5
0.99

Table 2: COVID-19 screening performance in Augmented images with CT Scan
and X-Ray datasets
CT Scan Images

Train-Test
60%-40%

X-Ray Images

Proposed
Resnet VGG
Layers
32
64
128
50
16

Proposed
Resnet VGG
Layers
32
64
128
50
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
70%-30%

93.46
22.82
97.2
0.92
94.67
92.25
0.93
32

92.54
48.46
96.5
0.93
91.99
93.08
0.93
64

91.59
65.33
96
0.91
91.74
91.45
0.92
128

85.53
59.9
85.5
0.86
84.31
86.75
0.85
50

85.07 98.88 98.79 98.04
37.15 8.92 10.38 12.12
92
99.7 99.4 99.4
0.88 0.99 0.99 0.98
81.15 99.06 98.7 97.95
88.99 98.7 98.88 98.13
0.84 0.99 0.99 0.98
16
32
64
128

93.66
21.54
93.7
0.95
91.97
95.33
0.94
50

90.39
21.54
90.4
0.99
81.52
99.25
0.89
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
80%-20%

95.05
19.44
97.8
0.96
93.64
96.48
0.95
32

95.38
26.97
98.4
0.96
94.78
95.98
0.95
64

92.46
37.33
97.2
0.95
89.38
95.54
0.92
128

89.02
52.16
89
0.9
87.71
90.32
0.89
50

88.99 98.97 99.44 98.69
35.49 7.4
1.91 8.05
93.4 99.7 100 99.6
0.9
0.99
1
0.99
87.83 99.07 99.07 98.33
90.14 98.88 99.81 99.06
0.89 0.99 0.99 0.99
16
32
64
128

90.76
48.19
90.8
0.99
82.27
99.25
0.9
50

92.26
17.81
92.3
0.99
85.82
98.69
0.92
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score
90%-10%

96.47
13.79
98.6
0.96
96.73
96.2
0.96
32

96.99
16.39
99
0.97
97.39
96.6
0.97
64

95.45
21.58
98.2
0.95
95.83
95.07
0.95
128

92.75
31.42
92.7
0.94
90.83
94.65
0.93
50

91.16 99.07 98.88 99.16
26.25 7.63 5.18 4.87
97.1 99.5 99.7 99.8
0.96 0.99 0.99 0.99
86.38 99.25 99.25 99.44
95.94 98.88 98.52 98.89
0.91 0.99 0.99 0.99
16
32
64
128

96.18
20.58
96.2
0.99
92.91
99.44
0.96
50

93.1
17.35
93.1
0.97
88.99
97.2
0.93
16

Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score

98.5
7.27
99.4
0.98
98.69
98.29
0.98

98.41
8.75
99.6
0.98
98.37
98.44
0.97

96.9
13.84
99
0.96
97.5
96.3
0.97

96.09
14.8
96.1
0.95
96.88
95.3
0.96

92.61
22.28
97.8
0.9
96.23
88.99
0.93

93.38
24.7
93.4
0.89
99.44
87.31
0.94

93.84
16.41
93.8
0.98
89.92
97.76
0.94

100 99.63 99.63
3.66 2.57
2.5
100 99.9 100
1
1
1
100 99.63 99.44
100 99.63 99.81
1
1
1

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

12

Kiran Purohit et al.

standard ratio of train and test samples i.e., 70:30 for both CT Scan and X-Ray
images with multi-image augmentation and without multi-image augmentation
on three different architectures as proposed. ROC curves for CT Scan and X-Ray
images exhibiting higher accuracy when the ratio of train and test is 70:30 are
shown in Figure 6.

(a) CT Scan images with multi-image aug-(b) X-Ray images with multi-image augmentation having 64 layers when train andmentation having 32 layers when train and
test ratio is 70:30 (accuracy=95.38%)
test ratio is 70:30 (accuracy=98.97%)

Fig. 6: ROC curves
The ROC curve determined on X-Ray images with 64 layers are not shown
because it seems like an overfitting having area under the ROC curve as 1.
Table 3 shows the COVID-19 screening performance of models having higher
accuracy with different train-test values. Figure 7 shows the optimal accuracy
comparison between original and augmented techniques on both X-Ray and CT
Scan datasets. It is found that in X-Ray dataset, the accuracy slightly differs
in both original and augmented techniques due to less number of samples in
the dataset. Whereas, in CT Scan dataset, the augmented technique performed
with a number of representative images is found better than non-augmented
technique with original images. In Table 4 the classification accuracies obtained
by the proposed model and the existing models are shown. The existing models either used X-Ray images or CT Scan images for evaluation. Whereas, the
proposed augmented deep model has used both CT Scan and X-Ray images of
chest with quite large number of samples.
Hemdan et al. [12] developed a COVIDX-Net for detection of COVID-19 in
X-Ray images. An accuracy of 90% is obtained using 25 COVID-19 positive and
25 normal images. Wang and Wong [20] developed COVID-Net which is based
on deep neural network for detection of COVID-19. It achieved 92.4% accuracy
determined on 53 COVID-19 positive and 8066 normal X-Ray images. Ghoshal
et al. [9] used CNN model on 25 COVID-19 positive subjects and obtained the
accuracy of 92.9%. Ioannis et al. [3] used transfer learning on 224 COVID-19, 700
pneumonia, and 504 normal images. It obtained 98.75% accuracy for two class
and 93.48% accuracy for the three-class problem. Sethy and Behera [16] used

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

13

Table 3: COVID-19 screening performance of outperforming model with respect
to accuracy having different train and test values
Original

Train-Test
Model
Layers
Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score

Train-Test
Model
Layers
Accuracy (%)
Loss (%)
AUC (%)
Precision
Sensitivity (%)
Specificity (%)
F1 Score

Augmented

Original

Augmented

CT Scan

X-Ray
CT Scan
X-Ray
CT Scan
X-Ray
CT Scan
X-Ray
60%-40%
70%-30%
Proposed Proposed Proposed Proposed Proposed Proposed Proposed Proposed
64
64
32
32
64
128
64
64
90.87
36.13
95.2
0.9
92.17
89.57
0.91

99.25
2.59
100
1
98.51
100
0.99

93.46
22.82
97.2
0.92
94.67
92.25
0.93

98.88
8.92
99.7
0.99
99.06
98.7
0.99

92.03
26.81
95.9
0.93
91.01
93.04
0.92

100
2.22
100
1
100
100
1

95.38
26.97
98.4
0.96
94.78
95.98
0.95

99.44
1.91
100
1
99.07
99.81
0.99

Original
Augmented
Original
Augmented
CT Scan
X-Ray
CT Scan
X-Ray
CT Scan
X-Ray
CT Scan
X-Ray
80%-20%
90%-10%
Proposed Proposed Proposed Proposed Proposed Proposed Proposed Proposed
64
32
64
128
64
64
64
32
95.22
17.16
98
0.95
95.65
94.78
0.95

99.25
3.84
100
0.99
100
98.51
0.99

96.99
16.39
99
0.97
97.39
96.6
0.97

99.16
4.87
99.8
0.99
99.44
98.89
0.99

98.26
9.47
99.5
0.97
99.42
97.1
0.98

100
1.08
100
1
100
100
1

98.41
8.75
99.6
0.98
98.37
98.44
0.97

100
3.66
100
1
100
100
1

CNN models to obtain the image features and classified them by using Support Vector Machine (SVM). They attained 95.38% accuracy using SVM and
ResNet50 in combination with 50 images. Narin et al. [14] applied three different deep learning models, i.e., ResNet50, InceptionV3, and Inception-ResNetV2.
They achieved 98% accuracy using 50 COVID-19 positive chest X-ray images
and 50 normal images. Tulin et al. [15] applied a deep learning model called
DarkCovidNet for detection of COVID-19. They used 1125 images which include 125 COVID-19 positive, 500 pneumonia and 500 no-findings to train the
model and achieved accuracies of 98.08% and 87.02% for two and three classes
classification, respectively.

Fig. 7: COVID-19 screening accuracy

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

14

Kiran Purohit et al.

Wang et al. [21] achieved 82.9% accuracy by applying the modified Inception
(M-Inception) deep model using 195 COVID-19 positive and 258 normal CT Scan
images. Ying et al. [18] obtained 86% accuracy using 777 COVID-19 positive
and 708 normal CT Scan images, with a deep model made on the pre-trained
ResNet50, called DRE-Net. Xu et al. [22] achieved 86.7% accuracy for detection
of COVID-19 by applying ResNet coupled with 175 Healthy, 219 COVID-19
positive and 224 pneumonia CT Scan images. Zheng et al. [25] introduced a threedimensional deep CNN model for COVID-19 prediction and obtained 90.8%
accuracy using 313 COVID-19 positive and 229 COVID-19 negative CT Scan
images. Chen et al. [5] introduced a UNet++ Network for COVID-19 detection
and achieved 95.2% accuracy using 51 COVID-19 positive and 55 COVID-19
negative CT Scan images.

Table 4: Comparison among various deep learning based COVID-19 screening
techniques
Study

Images

Hemdan et al. [12]

X-Ray

Wang and Wong [20]

X-Ray

Ghoshal et al. [9]

X-Ray

Ioannis et al. [3]

X-Ray

Sethy et al. [16]

X-Ray

Narin et al. [14]

X-Ray

Tulin et al. [15]

X-Ray

Wang et al. [21]

CT Scan

Ying et al. [18]

CT Scan

Xu et al. [22]

CT Scan

Zheng et al. [25]

CT Scan

Chen et al. [5]

CT Scan

Proposed Study

X-ray
CT Scan

Subjects

Methodology

Covid-19(+ve) - 25
CovidX Network
Normal - 25
Covid-19(+ve) - 53
Healthy - 8066
Covid Network
Covid-19 (-ve) - 5526
Covid-19(+ve) - 25
Convolutional Neural Network
Others - #Not available
Covid-19(+ve) - 224
Healthy - 504
VGG-19 Network
Pneumonia - 700
Covid-19(+ve) -25
ResNet-50 and Support Vector Machine
Covid-19(-ve) - 25
Covid-19(+ve) - 50
ResNet-50 and Deep CNN
Covid-19(-ve) - 50
No Findings - 500
Covid-19(+ve) - 125
DarkCovidNet
Pneumonia - 500
Covid-19(+ve) - 195
M-Inception
Covid-19(-ve) - 258
Healthy - 708
DRE-Net
Covid-19(+ve) - 777
Healthy - 175
Covid-19(+ve) - 219
Location Attention + ResNet
Viral pneumonia - 224
Covid-19(+ve) - 313
3D Deep Network + UNet
Covid-19(-ve) - 229
Covid-19(+ve) - 51
UNet++ Network
Others - 55
Covid-19(+ve) - 536
Covid-19(-ve) - 536
Multi-image Augmentation + CNN
Covid-19(+ve) - 2760
Covid-19(-ve) - 2760

Accuracy (%)
90
92.4
92.9
93.48
95.38
98
98.08
82.9
86
86.7
90.8
95.2
99.44
95.38

Due to less number of X-Ray or CT Scan images that are used for training
the deep learning models, often exhibit the classification accuracies not upto
the mark. Whereas, the proposed augmented deep model uses large number of
X-Ray and CT Scan images for training. This multi-image augmentation has
driven the CNN to exhibit higher classification accuracies while a basic deep
learning architecture is used. Moreover, the proposed model is compared with
ResNet-50 and VGG-16 on the same set of X-Ray and CT Scan images. The
proposed augmented deep model outperforms ResNet-50 and VGG-16 as well as
the existing models too.

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

COVID-19 Detection on Chest X-Ray and CT Scan Images

4

15

Conclusion and Future Work

This paper has presented an augmented CNN to detect COVID-19 on chest
X-Ray and chest CT Scan images and classify from non-COVID-19 cases. The
proposed model need not require to extract the feature manually, it is automated
with end-to-end structure. Most of these previous studies have fewer examples
for training the deep models. In contrast, the proposed model has used a multiimage augmentation technique driven by first and second order derivative edge
operators and this augmentation generates a number of representative edged
images. This augmentation technique provides a sufficient number of images to
train the model, making the model robust. While, CNN is trained with this
augmented images, the classification accuracies of 99.44% for X-Ray images and
95.38% for CT Scan images are obtained. The experimental results are found to
be highly convincing and emerged as a useful application for COVID-19 screening on chest X-Ray and CT scan images of corona suspected individuals. The
subtle responses of various abnormalities like tuberculosis, pneumonia, influenza
and so forth confounds the classifier, restricting the performance of the system.
Future works may include detection of multiple conditions such as pneumonia,
bronchitis and tuberculosis along with COVID-19 of suspected individuals having respiratory illness.

References
1. Abhishek Kesarwani, Kiran Purohit, M.D., Kisku, D.R.: Measuring the degree of
suitability of edge detection operators prior to an application (2020)
2. Akiba, T., Suzuki, S., Fukuda, K.: Extremely large minibatch sgd: Training resnet50 on imagenet in 15 minutes. arXiv preprint arXiv:1711.04325 (2017)
3. Apostolopoulos, I.D., Mpesiana, T.A.: Covid-19: automatic detection from x-ray
images utilizing transfer learning with convolutional neural networks. Physical and
Engineering Sciences in Medicine p. 1 (2020)
4. Bahadur Chandra, T., Verma, K., Kumar Singh, B., Jain, D., Singh Netam, S.,
et al.: Coronavirus disease (covid-19) detection in chest x-ray images using majority
voting based classifier ensemble. Expert Syst Appl
5. Chen, J., Wu, L., Zhang, J., Zhang, L., Gong, D., Zhao, Y., Hu, S., Wang, Y.,
Hu, X., Zheng, B., et al.: Deep learning-based model for detecting 2019 novel
coronavirus pneumonia on high-resolution computed tomography: a prospective
study. MedRxiv (2020)
6. Cohen, J.P., Morrison, P., Dao, L.: Covid-19 image data collection. arXiv
2003.11597 (2020), https://github.com/ieee8023/covid-chestxray-dataset
7. El-Sawy, A., Hazem, E.B., Loey, M.: Cnn for handwritten arabic digits recognition
based on lenet-5. In: International conference on advanced intelligent systems and
informatics. pp. 566–575. Springer (2016)
8. Géron, A.: Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow:
Concepts, tools, and techniques to build intelligent systems. O’Reilly Media (2019)
9. Ghoshal, B., Tucker, A.: Estimating uncertainty and interpretability in deep learning for coronavirus (covid-19) detection. arXiv preprint arXiv:2003.10769 (2020)
10. Gonzalez, R.C., Woods, R.E., Eddins, S.L.: Digital image processing using MATLAB. Pearson Education India (2004)

bioRxiv preprint doi: https://doi.org/10.1101/2020.07.15.205567; this version posted October 19, 2020. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made
available under aCC-BY 4.0 International license.

16

Kiran Purohit et al.

11. He, C., Li, S., Liao, Z., Liao, M.: Texture classification of polsar data based on
sparse coding of wavelet polarization textons. IEEE Transactions on Geoscience
and Remote Sensing 51(8), 4576–4590 (2013)
12. Hemdan, E.E.D., Shouman, M.A., Karar, M.E.: Covidx-net: A framework of
deep learning classifiers to diagnose covid-19 in x-ray images. arXiv preprint
arXiv:2003.11055 (2020)
13. Liu, X., Wang, D.: A spectral histogram model for texton modeling and texture
discrimination. Vision Research 42(23), 2617–2634 (2002)
14. Narin, A., Kaya, C., Pamuk, Z.: Automatic detection of coronavirus disease (covid19) using x-ray images and deep convolutional neural networks. arXiv preprint
arXiv:2003.10849 (2020)
15. Ozturk, T., Talo, M., Yildirim, E.A., Baloglu, U.B., Yildirim, O., Acharya, U.R.:
Automated detection of covid-19 cases using deep neural networks with x-ray images. Computers in Biology and Medicine p. 103792 (2020)
16. Sethy, P.K., Behera, S.K.: Detection of coronavirus disease (covid-19) based on
deep features. Preprints 2020030300, 2020 (2020)
17. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
image recognition. arXiv preprint arXiv:1409.1556 (2014)
18. Song, Y., Zheng, S., Li, L., Zhang, X., Zhang, X., Huang, Z., Chen, J., Zhao,
H., Jie, Y., Wang, R., et al.: Deep learning enables accurate diagnosis of novel
coronavirus (covid-19) with ct images. medRxiv (2020)
19. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: Proceedings
of the IEEE conference on computer vision and pattern recognition. pp. 1–9 (2015)
20. Wang, L., Wong, A.: Covid-net: A tailored deep convolutional neural network
design for detection of covid-19 cases from chest x-ray images. arXiv preprint
arXiv:2003.09871 (2020)
21. Wang, S., Kang, B., Ma, J., Zeng, X., Xiao, M., Guo, J., Cai, M., Yang, J., Li, Y.,
Meng, X., et al.: A deep learning algorithm using ct images to screen for corona
virus disease (covid-19). MedRxiv (2020)
22. Xu, X., Jiang, X., Ma, C., Du, P., Li, X., Lv, S., Yu, L., Ni, Q., Chen, Y., Su, J.,
et al.: A deep learning system to screen novel coronavirus disease 2019 pneumonia.
Engineering (2020)
23. Zhang, B., Zhang, L., Zhang, L., Karray, F.: Retinal vessel extraction by matched
filter with first-order derivative of gaussian. Computers in biology and medicine
40(4), 438–445 (2010)
24. Zhao, J., Zhang, Y., He, X., Xie, P.: Covid-ct-dataset: a ct scan dataset about
covid-19. arXiv preprint arXiv:2003.13865 (2020)
25. Zheng, C., Deng, X., Fu, Q., Zhou, Q., Feng, J., Ma, H., Liu, W., Wang, X.: Deep
learning-based detection for covid-19 from chest ct using weak label. medRxiv
(2020)

